---
ver: rpa2
title: Can LLMs Learn to Map the World from Local Descriptions?
arxiv_id: '2505.20874'
source_url: https://arxiv.org/abs/2505.20874
tags:
- spatial
- distance
- training
- data
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Large Language Models (LLMs) were trained in two stages: first
  on fragmented spatial relational descriptions (distances and azimuths between POIs)
  and then on trajectory-based shortest path data. The models successfully inferred
  unseen POI relationships with low error (0.11% MRPE for distance, 0.79 for Spearman
  correlation on azimuth) and generalized shortest path planning to unseen POI pairs
  (83.63% exact match accuracy).'
---

# Can LLMs Learn to Map the World from Local Descriptions?

## Quick Facts
- **arXiv ID**: 2505.20874
- **Source URL**: https://arxiv.org/abs/2505.20874
- **Reference count**: 40
- **Primary result**: LLMs trained on fragmented spatial descriptions achieve 0.11% MRPE for distance inference and 83.63% exact match for unseen POI navigation

## Executive Summary
This paper investigates whether Large Language Models can construct global spatial representations from local descriptions. The authors train LLMs in two stages: first on fragmented spatial relational descriptions (distances and azimuths between POIs), then on trajectory-based shortest path data. The models successfully infer unseen POI relationships with low error (0.11% MRPE for distance, 0.79 for Spearman correlation on azimuth) and generalize shortest path planning to unseen POI pairs (83.63% exact match accuracy). Latent space analysis shows the models encode absolute coordinates and spatial geometry without explicit training, and can dynamically track position during navigation. However, robustness to path perturbations is limited and highly dependent on training data distribution, indicating fragmented rather than globally coherent spatial understanding.

## Method Summary
The authors use a synthetic 100×100 grid environment with 1024 POIs and 200 roads. They employ a two-stage continual pre-training approach on QWEN 2.5-0.5B: Stage 1 trains on relational spatial descriptions (pairwise distances and azimuths in templated natural language), while Stage 2 trains on trajectory descriptions converted from Dijkstra shortest paths. Training uses 4×A800 80G GPUs, batch size 128, learning rate 1e-4, and 10 epochs per stage. POI and road names are added as special tokens. MLP probes are trained to extract coordinates and spatial relationships from hidden states, with separate 80:20 train/test splits for perception and navigation tasks.

## Key Results
- Generalization to unseen POI pairs: 0.11% MRPE for distance, 0.79 Spearman correlation for azimuth
- Navigation accuracy: 83.63% exact match on unseen POI pairs with small start/end deviations (0.06 and 0.48)
- Latent representation quality: R²=1.00 for coordinate probing (CPT), 0.97 R² for dynamic position tracking
- Robustness limitations: 88% first-step failure under road perturbations, 27km average destination deviation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLMs construct coherent global spatial representations from fragmented local relational descriptions through implicit triangulation.
- **Mechanism**: The model receives pairwise distance and azimuth data between POIs (e.g., "distance from pi to pj is 2.5km, azimuth 135°"). Through continual pre-training on these relational constraints, the model internalizes a globally consistent coordinate system. The key is that overlapping relational descriptions (pi→pj, pj→pk, pi→pk) provide geometric constraints that the model resolves into absolute positions, as evidenced by: (1) generalization to unseen POI pairs with 0.11% distance MRPE, (2) MLP probes extracting absolute coordinates from hidden states (R²=1.00), and (3) latent vector distances correlating with actual Euclidean distances (Spearman >0.82).
- **Core assumption**: The relational descriptions contain sufficient geometric constraints (overlapping pairwise relations) for the model to triangulate absolute positions without explicit coordinate supervision.
- **Evidence anchors**:
  - [abstract]: "LLMs demonstrate strong generalization to unseen spatial relationships with low errors (e.g., 0.11% MRPE for distance) and encodes structured spatial representations aligned with real-world geometry"
  - [section 3.1]: "MODEL_per achieves low mean relative percentage errors—0.11% for distance and 0.71% for azimuth—demonstrating strong consistency with the ground truth"
  - [section 3.2]: "predictions from Probeloc yield low Mean Absolute Error, high R², and small Euclidean deviations, indicating that the last hidden states of MODEL_per effectively capture absolute coordinate information"
- **Break condition**: If training data has insufficient coverage of relational constraints between distant POIs (sparse connectivity in the relation graph), the model will fail to form coherent global maps, leading to inconsistent predictions across spatially separated regions.

### Mechanism 2
- **Claim**: LLMs extract road network topology from shortest-path trajectory sequences and generalize to novel navigation tasks through learned connectivity patterns.
- **Mechanism**: The model is trained on natural language trajectory descriptions (e.g., "Start at pi, go east on r3 for 3km, then north on r8 for 2km to reach pj"). These trajectories implicitly encode: (1) road connectivity (which roads intersect), (2) valid transitions (turning patterns at intersections), and (3) distance-direction relationships. The model generalizes by learning transition probabilities at intersections rather than memorizing specific routes, achieving 83.63% exact match on unseen POI pairs and dynamically tracking position during navigation (step-wise coordinate probing R²=0.97).
- **Core assumption**: Shortest-path descriptions contain sufficient topological information for the model to infer a complete road connectivity graph, not just memorize individual routes.
- **Evidence anchors**:
  - [abstract]: "LLMs can learn road connectivity from trajectory descriptions, enabling accurate path planning and dynamic spatial awareness during navigation"
  - [section 4.1]: "MODEL nav excels in shortest-path prediction, with an exact match accuracy of 83.63% and small start/end deviations (0.06 and 0.48, respectively)"
  - [section 4.2]: "at each step of the model's navigation, the absolute coordinate position can be clearly extracted from its hidden state (e.g., X-R² 0.05 → 0.97)"
- **Break condition**: If perturbations move the model to low-frequency intersections (turning points rarely seen in training), recovery fails catastrophically (only 11.85% FSA for road perturbations), indicating the model's road network understanding is fragmented and localized rather than comprehensive.

### Mechanism 3
- **Claim**: Continual pre-training develops structured latent spatial representations while supervised fine-tuning optimizes task performance at the cost of internal representation quality.
- **Mechanism**: CPT optimizes next-token prediction over the full sequence including POI names, forcing their embeddings to organize spatially to minimize loss. SFT only computes loss on answer tokens, leaving POI embeddings under-optimized. This creates a fundamental tradeoff: CPT achieves R²=1.00 for coordinate probing but 0.11% MRPE; SFT achieves 0.003% MRPE but R²=0.46 for coordinate probing and R²=-2.92 for compositional distance prediction from latent vectors. The structured latent space enables compositional spatial reasoning (combining POI representations to infer relationships) that SFT sacrifices for task accuracy.
- **Core assumption**: The model must actively process and predict POI name tokens during training to develop spatially structured representations; treating them as context-only tokens prevents spatial embedding formation.
- **Evidence anchors**:
  - [section 5]: "the POI name tokens in the SFT training process do not directly contribute to the loss calculation. Consequently, their embeddings are not explicitly optimized, leading to a lack of structured distribution in the latent space"
  - [Appendix E.1, Tables 14-16]: SFT achieves near-perfect prediction (0.003% MRPE) but latent probe performance degrades severely (coordinate R² drops from 1.00 to 0.46, compositional distance R² drops from 1.00 to -2.92)
  - [Figure 8]: CPT shows strong Spearman/Pearson correlations (0.82-0.91) for distance/angle consistency between latent vectors and actual locations; SFT shows near-zero correlations (0.03-0.07)
- **Break condition**: If you require both strong task performance and interpretable/compositional latent representations, neither pure CPT nor pure SFT suffices—you need hybrid approaches (e.g., multi-task objectives combining next-token prediction with answer generation).

## Foundational Learning

- **Concept: Probing methods for latent representations**
  - Why needed here: The paper's central evidence for "spatial cognition" comes from MLP probes extracting coordinates from hidden states (R²=1.00 for CPT, R²=0.46 for SFT). Without understanding probing methodology, you cannot evaluate whether the model truly "encodes" spatial information or whether the probe is learning the mapping independently.
  - Quick check question: If a linear probe achieves R²=0.97 and a nonlinear MLP probe achieves R²=1.00 for coordinate prediction from the same hidden states, what does this suggest about how spatial information is geometrically organized in the latent space?

- **Concept: Generalization vs memorization in structured domains**
  - Why needed here: The paper claims LLMs develop "global spatial cognition" rather than memorizing training pairs. Understanding how to test this (unseen POI pairs, held-out regions, Bridged vs Zero-Exposure settings) is critical for distinguishing true spatial understanding from pattern matching.
  - Quick check question: In the "Zero-Exposure" setting where held-out POIs never appear in trajectory training, why does Perception-MODEL_nav (trained on MODEL_per first) outperform Base-MODEL_nav? What does this tell you about the relationship between spatial perception and navigation?

- **Concept: Compositional representation learning**
  - Why needed here: The Probegeo experiment (concatenating two POI hidden states to predict distance/azimuth between them) tests whether representations are compositional. R²=1.00 for CPT vs R²=-2.92 for SFT reveals fundamentally different representation structures that simple accuracy metrics miss.
  - Quick check question: If Probegeo can predict distance between unseen POI pairs by concatenating their individual hidden states, what property must those hidden states possess? How would you test whether this compositionality extends to three-way spatial relationships?

## Architecture Onboarding

- **Component map**:
  Input Layer: Special tokens for POIs (p1...p1024) and roads (r1...r200)
  ↓
  Stage 1 - MODEL_per (Qwen2.5-0.5B + CPT):
  Input: "The distance from p_i to p_j is X km, azimuth is Y degrees"
  Output: Learns global coordinate encoding in POI embeddings
  Hardware: 4×A800 80G, batch=128, lr=1e-4, 10 epochs
  ↓
  Stage 2 - MODEL_nav (MODEL_per + CPT):
  Input: "Start at p_i, go [direction] on r_X for [distance]..."
  Output: Learns road connectivity + dynamic position tracking
  Hardware: 4×A800 80G, batch=128, lr=1e-4, 10 epochs
  ↓
  Probe Suite (diagnostic, not production):
  Probeloc: [POI hidden state] → MLP(128→64→2) → (x,y) coordinates
  Probegeo: [h_i ⊕ h_j] → MLP(128→64→2) → (distance, azimuth)
  Training: Adam, lr=0.001, L2=0.0001, 500 epochs, early stopping

- **Critical path**:
  1. **Tokenize environment**: Register POI names and road names as special tokens before any training
  2. **Generate relational data**: Compute all pairwise distances/azimuths for training split (80% of POI pairs), format with linguistic templates
  3. **Stage 1 CPT**: Train MODEL_per until validation loss plateaus (~10 epochs); verify generalization on held-out pairs
  4. **Generate trajectory data**: Run Dijkstra on road graph, convert to natural language instructions
  5. **Stage 2 CPT**: Initialize from MODEL_per, train MODEL_nav on trajectories
  6. **Probe training**: Train Probeloc/Probegeo on separate splits to diagnose representation quality

- **Design tradeoffs**:
  - **Model scale**: 0.5B chosen for interpretability; Appendix E.2 shows 1.5B and LLaMA-3.2-1B produce similar spatial cognition patterns, but larger models cost more without proportional gains
  - **Training strategy**: CPT gives compositional latent structure (Probegeo R²=1.00); SFT gives better task metrics (0.003% vs 0.11% MRPE) but destroys spatial compositionality (R²=-2.92). Cannot optimize both simultaneously with single-objective training.
  - **Environment complexity**: 100×100 grid with 1024 POIs and 200 roads balances experimental control with sufficient complexity; real-world scaling not addressed
  - **Evaluation split strategy**: 80:20 primary; 60:40 and 40:60 show graceful degradation but reveal data scaling requirements

- **Failure signatures**:
  1. **Perturbation cascade failure**: Road perturbation → 88% first-step failure → 27km average destination deviation. Signature: model selects invalid roads after perturbation, indicating location awareness loss
  2. **Frequency-dependent robustness**: As perturbation point frequency threshold increases from 1000 to 60000, FSA improves from ~50% to ~80%. Signature: model only "knows" high-traffic intersections; low-frequency regions are effectively unmapped
  3. **Direction vs distance asymmetry**: Direction perturbations cause 56km deviation; distance perturbations cause 20km. Signature: model over-relies on high-speed roads (more frequent in training), making it sensitive to direction changes that force exits onto slower roads
  4. **SFT latent collapse**: Coordinate probing R² drops from 1.00→0.46; compositional prediction R² drops from 1.00→-2.92. Signature: POI embeddings cluster randomly rather than organizing spatially; task accuracy hides representation degradation

- **First 3 experiments**:
  1. **Probe validation baseline**: Train Probeloc on untrained Qwen2.5-0.5B base model. Expected: R²≈0, MAE≈25-26, Euclidean distance≈39 (Table 2 "Base" row). This validates your probe implementation before investing in full training.
  2. **Generalization scaling test**: Train MODEL_per with 40:60 split instead of 80:20. Expected: MRPE degrades from 0.11% to 2.63% but remains functional (Table 1). If MRPE exceeds 10%, your training data may have insufficient relational connectivity.
  3. **Perturbation robustness baseline**: Sample 1000 correct MODEL_nav predictions, apply road perturbations at critical steps, measure FSA/SA/DD. Expected: FSA≈12%, SA≈63%, DD≈27km (Table 6). If FSA>25%, your model learned more robust representations—investigate what differed in training.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can models acquire robust spatial cognition without sacrificing their original general language capabilities?
- **Basis in paper**: [explicit] The Limitations section states, "How to balance the model’s general abilities with its internal spatial cognition remains an open research question," noting that the training process caused the model to lose general capabilities.
- **Why unresolved**: The current continual pre-training (CPT) framework optimizes for spatial accuracy at the expense of the model's pre-existing linguistic knowledge.
- **What evidence would resolve it**: A training methodology that achieves high spatial prediction accuracy while retaining performance on standard general language benchmarks (e.g., MMLU) compared to the base model.

### Open Question 2
- **Question**: What are the internal mechanisms by which LLMs utilize latent spatial representations to explicitly predict relative positions and trajectories?
- **Basis in paper**: [explicit] The Limitations section notes that while the model develops spatial understanding, "how it utilizes this spatial understanding information has not been fully analyzed," specifically regarding the link between latent representations and explicit outputs.
- **Why unresolved**: The study verifies that spatial information is encoded (via probing) but does not investigate the computational circuit that retrieves and processes this information for downstream tasks.
- **What evidence would resolve it**: Causal tracing or ablation studies that identify specific attention heads or neural sub-structures responsible for converting implicit coordinates into explicit path descriptions.

### Open Question 3
- **Question**: Can LLMs develop a continuous, comprehensive global map rather than a fragmented understanding dependent on training data frequency?
- **Basis in paper**: [inferred] The authors conclude that the model's understanding of the road network is "likely fragmented and localized" because its ability to recover from navigational perturbations is strictly correlated with the frequency of turning points in the training data.
- **Why unresolved**: The model demonstrates poor robustness (e.g., 11.85% FSA for road perturbations) in low-frequency areas, suggesting it relies on memorized patterns rather than a global cognitive map.
- **What evidence would resolve it**: High recovery rates and successful path re-planning in regions specifically excluded or under-represented in the training distribution.

## Limitations
- The spatial understanding appears fragmented rather than globally coherent—the model only robustly handles high-frequency intersections and fails catastrophically on low-frequency regions
- You cannot simultaneously achieve strong task performance and interpretable latent representations with current training approaches (CPT vs SFT tradeoff)
- The synthetic environment (100×100 grid with 1024 POIs) provides controlled experimental conditions but may not scale to real-world complexity

## Confidence
- **High Confidence**: LLMs can learn road connectivity from trajectory descriptions and generalize to novel navigation tasks (MRPE 0.11%, SPA 83.63%). The probe-based evidence for latent spatial encoding is methodologically sound and reproducible.
- **Medium Confidence**: The model develops structured latent spatial representations through CPT (Probegeo R²=1.00) and can dynamically track position during navigation (R²=0.97 for coordinate probing). However, perturbation experiments reveal significant fragility that limits practical deployment.
- **Low Confidence**: The claim of "global spatial cognition" is overstated. The model's performance degrades severely under path perturbations, particularly at low-frequency intersections, indicating fragmented rather than comprehensive spatial understanding.

## Next Checks
1. **Perturbation robustness scaling**: Systematically vary the frequency threshold for perturbation points (beyond the 1000-60000 range tested) to identify the exact frequency boundary where performance collapses. This will quantify the fragmentation of spatial understanding.
2. **Cross-environmental transfer**: Train MODEL_per on one synthetic environment and test generalization to structurally different environments (different grid sizes, POI densities, or road topologies) without additional training. This tests whether the model learns transferable spatial reasoning or environment-specific patterns.
3. **Hybrid training objective evaluation**: Implement a multi-task objective combining next-token prediction with answer generation and measure the tradeoff curve between task performance (MRPE) and representation quality (Probegeo R²). Identify if intermediate points exist between pure CPT and pure SFT performance.