---
ver: rpa2
title: Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning
arxiv_id: '2503.10304'
source_url: https://arxiv.org/abs/2503.10304
tags:
- agent
- equilibrium
- auto-bidding
- bidding
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Nash Equilibrium Constrained Bidding (NCB),
  a novel auto-bidding framework that integrates game-theoretic equilibrium guarantees
  with platform-wide optimization. NCB addresses the limitations of existing industrial
  auto-bidding methods by jointly considering fine-grained strategic interactions
  among advertisers and the platform's ecosystem-level objectives, specifically maximizing
  social welfare subject to Nash equilibrium constraints.
---

# Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning

## Quick Facts
- arXiv ID: 2503.10304
- Source URL: https://arxiv.org/abs/2503.10304
- Reference count: 40
- Key outcome: Introduces NCB framework achieving superior social welfare and equilibrium compliance in large-scale auto-bidding

## Executive Summary
This paper addresses the challenge of industrial auto-bidding by proposing Nash Equilibrium Constrained Bidding (NCB), a framework that jointly optimizes social welfare and maintains Nash equilibrium among advertisers. The key innovation is reformulating the complex bi-level auto-bidding problem into a tractable constrained optimization over bidding factors, enabling efficient gradient-based solution with rigorous convergence guarantees. NCB overcomes limitations of existing methods by explicitly considering strategic interactions among advertisers while maximizing platform-wide objectives.

## Method Summary
The NCB framework transforms the bi-level auto-bidding problem into optimizing bidding factors α_i subject to Nash equilibrium constraints using the Fischer-Burffenbach function. A penalty-based primal-dual gradient method solves this constrained problem, alternating between optimizing α (primal) and adjusting Lagrange multipliers λ (dual). The method achieves O(NK) complexity through pre-computation of aggregate quantities, making it scalable to industrial-scale systems. For practical deployment, a Causal Transformer predicts optimal α from observed impression features, trained via supervised learning on historical trajectories generated by the optimization algorithm.

## Key Results
- Achieves superior social welfare (SW=5572.3) and compliance rate (66.18%) compared to leading baselines AIGB, USCB, MAAB
- Maintains computational efficiency with complexity independent of advertiser count (O(NK))
- Demonstrates 80.14% compliance rate with higher penalty factor (ρ=100), though with reduced welfare (SW=4692.5)
- Shows practical viability through neural network implementation achieving comparable performance to hindsight-optimal baseline

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The bi-level auto-bidding problem can be reformulated as a constrained optimization over bidding factors α = {α_i}_{i=1}^N, enabling tractable gradient-based solution.
- **Mechanism:** Under the NE constraint, each agent's optimal bid follows b_{i,k} = α_i v_{i,k} (value-proportional bidding). The original bi-level problem with NK decision variables reduces to optimizing over N bidding factors, with NE constraints expressed via the Fischer-Burffenbach function h_i(α) = B_i - C_i(α) + A - α_i - √((B_i - C_i(α))^2 + (A - α_i)^2 + ε) = 0. This transforms non-smooth constraints into differentiable form.
- **Core assumption:** The value-proportional bidding structure (Eq. 3) holds under second-price auction dynamics with softmax allocation approximations. Assumption 3.5 (Self-Dominance) requires that each agent's own bids affect their cost more than others' bids: ∂C_i(α)/∂α_i > Σ_{j≠i} |∂C_i(α)/∂α_j|.
- **Evidence anchors:**
  - [abstract]: "recasts auto-bidding as a platform-wide optimization problem subject to Nash equilibrium constraints"
  - [section 3.1]: Theorem 3.1 establishes equivalence between Fischer-Burffenbach formulation and original NE constraints when ε = 0
  - [corpus]: Weak direct validation; related work (AIGB, V-CQL) uses similar value-proportional structures but without equilibrium constraints
- **Break condition:** The reformulation fails if agents' best responses deviate significantly from value-proportional bidding (e.g., under non-second-price auctions, strategic non-value-based bidding, or when Assumption 3.5 is violated in highly overlapping markets).

### Mechanism 2
- **Claim:** The penalty-based primal-dual gradient method converges to a KKT point of the constrained optimization problem, jointly satisfying equilibrium stability and social welfare optimality.
- **Mechanism:** The augmented Lagrangian L_ρ(α, λ) = Σ_i [R_i(α) + λ_i h_i(α)] - ρ/2 Σ_i h_i^2(α) combines standard Lagrangian with quadratic penalty. Primal updates (Eq. 14) optimize α via gradient ascent; dual updates (Eq. 15) adjust λ based on constraint violation. The penalty term ρ enforces feasibility while Lagrangian multipliers guide toward KKT conditions.
- **Core assumption:** Assumption 3.3 (Sufficient Primal Iterations) requires primal updates to reach stationarity ∇_α L_ρ(α^{t+1}, λ^t) = 0 before dual updates. Theoretical convergence (Theorem 3.6) requires ρ > Λ_{H_0}/(σ_{min}^2(J_H(α)) - H̄_1) where σ_{min}(J_H) > √H̄_1.
- **Evidence anchors:**
  - [abstract]: "penalty-based primal-dual gradient method with rigorous convergence guarantees"
  - [section 3.1.2]: Theorem 3.4 proves limit points are KKT points; Theorem 3.6 provides global convergence guarantee under penalty condition
  - [corpus]: No direct corpus validation; related equilibrium methods (ES algorithms) lack comparable convergence guarantees for large-scale systems
- **Break condition:** Convergence fails if penalty factor ρ is insufficient (violates Eq. 13), primal iterations are inadequate (violating Assumption 3.3), or the Jacobian J_H(α) becomes singular (when Self-Dominance assumption fails).

### Mechanism 3
- **Claim:** Computational complexity scales as O(T_A T_p N K) independent of agent count per-impression, enabling deployment in systems with thousands of advertisers.
- **Mechanism:** Pre-computation of aggregate quantities {S_k, W_k, v̄_k, U_k, Q_k, Q'_k} across all K impressions enables O(K) gradient computation per agent rather than naive O(NK). Key identities: S_k = Σ_j exp(α_j v_{j,k}/τ), W_k = Σ_j exp(α_j v_{j,k}/τ) α_j v_{j,k}, allowing m_{i,k} = (W_k - exp(α_i v_{i,k}/τ)α_i v_{i,k}) / (S_k - exp(α_i v_{i,k}/τ)) in O(1).
- **Core assumption:** Impressions can be processed in batches; the softmax temperature τ remains fixed; gradient computations require only aggregate statistics rather than pairwise agent interactions.
- **Evidence anchors:**
  - [abstract]: "computational complexity is independent of the number of advertisers"
  - [section 3.1.3]: Detailed complexity analysis showing Stage 1 (O(NK) for {p_{i,k}}, {m_{i,k}}, {C_i}), Stage 2 (O(NK) for gradients), Stage 3 (O(T_p NK) total primal, O(N) dual)
  - [corpus]: Related auto-bidding methods (USCB, MAAB) claim scalability but without explicit complexity analysis
- **Break condition:** Efficiency gains vanish if markets require fine-grained pairwise interaction modeling, if impression sequences cannot be batched (real-time streaming constraints), or if memory for O(NK) storage of {p_{i,k}, m_{i,k}} becomes prohibitive.

## Foundational Learning

- **Concept: Nash Equilibrium in Games**
  - **Why needed here:** The NCB framework treats auto-bidding as a non-cooperative game where each advertiser's bidding agent maximizes individual utility. NE provides the stability criterion—no agent should profit from unilateral deviation. Multiple NEs can exist (Example 3.2 shows two with 5.2% welfare difference), necessitating equilibrium selection.
  - **Quick check question:** Given bids b_i = α_i v_i for all agents, verify that no agent i can improve R_i by changing α_i while respecting budget constraint C_i ≤ B_i.

- **Concept: KKT Conditions for Constrained Optimization**
  - **Why needed here:** The paper proves convergence to KKT points (Theorem 3.4), which characterize optimality for constrained problems. Understanding stationarity ∇_α L = 0, primal feasibility h_i(α) = 0, and dual feasibility explains why the algorithm achieves both equilibrium compliance and welfare maximization.
  - **Quick check question:** For the constrained problem max_α Σ_i R_i(α) s.t. h_i(α) = 0, write the Lagrangian and state the KKT conditions at optimum.

- **Concept: Primal-Dual Gradient Methods**
  - **Why needed here:** Algorithm 1 alternates between primal updates (α via gradient ascent on L_ρ) and dual updates (λ via gradient descent). Understanding this interplay explains how penalty factor ρ and step sizes β, η control convergence speed and constraint satisfaction.
  - **Quick check question:** Explain why increasing penalty factor ρ improves constraint satisfaction but may slow convergence or cause numerical instability.

## Architecture Onboarding

- **Component map:**
  [Impression Stream] → [Feature Extraction] → [Neural Network M] → [α Prediction]
                                                  ↓
  [Pre-computation: Sk, Wk, Uk, Qk, Q'k] ← [Historical Trajectories]
                                                  ↓
  [Gradient Computation] → [Primal Update (α)] → [Dual Update (λ)] → [Bidding Policy]

- **Critical path:**
  1. Offline training: Run Algorithm 1 on historical trajectories to generate ground-truth α* labels
  2. Train neural network M to minimize ℓ_M = E[1/N Σ_i(α_{i,d} - M(x_{i,d}))^2]
  3. Online inference: At each of U time steps, observe incoming impressions, extract features x_i, predict α = {M(x_i)}_{i=1}^N, execute bids b_{i,k} = α_i v_{i,k}

- **Design tradeoffs:**
  - **Penalty factor ρ:** Higher ρ → better constraint satisfaction (higher Compliance Rate) but potentially lower Social Welfare. Table 1 shows ρ=10 gives SW=5572.3 with 66.18% compliance; ρ=100 gives SW=4692.5 with 80.14% compliance.
  - **Adjustment frequency:** More frequent recalibration (higher U) improves adaptability but increases computation. Paper uses U=96 adjustments per episode.
  - **Architecture choice:** Transformer vs. MLP vs. RNN—paper claims architecture-agnostic but uses 5-block Causal Transformer; no ablation provided.

- **Failure signatures:**
  - **Low Compliance Rate:** Indicates insufficient ρ or inadequate primal iterations; increase penalty factor or T_p.
  - **Diverging λ values:** Suggests infeasible problem (budgets cannot be simultaneously exhausted) or numerical instability; check budget feasibility and reduce step size η.
  - **Poor generalization in online deployment:** Training-validation gap indicates neural network overfits to historical patterns; increase training diversity or reduce model capacity.
  - **Gradient explosion:** May occur when τ is very small (softmax approaches hardmax); increase temperature or apply gradient clipping.

- **First 3 experiments:**
  1. **Validate Algorithm 1 convergence on small synthetic instance:** Reproduce Example 3.2 with N=3, K=10; verify Algorithm 1 finds one of the two known NEs; check that both NEs satisfy budget exhaustion and compare welfare values.
  2. **Ablation on penalty factor ρ:** Run Algorithm 1 on benchmark with ρ ∈ {10, 20, 50, 80, 100}; plot Social Welfare vs. Max Exploitability tradeoff curve; identify sweet spot for target compliance level.
  3. **Train and evaluate practical neural network:** Build the Transformer-based M using the paper's architecture; train on historical trajectories with varying K'_d/K_d ratios; measure online performance gap vs. hindsight-optimal Algorithm 1 baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the algorithm's convergence and stability degrade in "highly overlapping markets" where the Self-Dominance assumption (Assumption 3.5) is violated?
- **Basis in paper:** [explicit] The paper states: "While exceptions can arise in highly overlapping markets... this assumption captures a prevalent pattern."
- **Why unresolved:** The global convergence guarantee (Theorem 3.6) relies on the invertibility of the Jacobian matrix, which is strictly ensured by Assumption 3.5. The theoretical behavior is undefined when cross-agent cost interference exceeds self-marginal cost.
- **Evidence to resolve it:** Empirical analysis of convergence rates in synthetic environments specifically constructed to violate the diagonal dominance condition of the cost matrix.

### Open Question 2
- **Question:** Does the use of a softmax allocation rule as a differentiable approximation result in sub-optimal policies when deployed in standard second-price auctions with hard allocations?
- **Basis in paper:** [inferred] The method adopts a soft allocation rule p_{i,k} (Section 2) to facilitate gradient calculation, noting it approaches the deterministic rule as τ → 0.
- **Why unresolved:** The algorithm optimizes a smoothed proxy of the auction. The "sim-to-real" gap between the learned equilibrium in the smooth environment and the actual equilibrium in a hard allocation environment is not quantified.
- **Evidence to resolve it:** A comparison of Social Welfare and Compliance Rates when the policy trained with soft gradients is evaluated directly in a non-differentiable second-price auction simulation.

### Open Question 3
- **Question:** Does the restriction of the bidding policy to the linear form b_{i,k} = α_i v_{i,k} fail to capture more complex, welfare-maximizing equilibria?
- **Basis in paper:** [inferred] Theoretical derivation in Section 3.1 collapses the high-dimensional bi-level problem into an optimization over a single bidding factor α_i per agent.
- **Why unresolved:** While this reduction ensures computational tractability, it restricts the policy space. It is uncertain if the optimal linear equilibrium is significantly inferior to an equilibrium allowing non-linear value-based shading strategies.
- **Evidence to resolve it:** A theoretical counterexample or empirical demonstration where a non-linear policy profile achieves strictly higher social welfare while remaining at Nash Equilibrium compared to the best linear profile.

## Limitations
- The theoretical convergence guarantees rely heavily on Assumption 3.5 (Self-Dominance), which may fail in highly overlapping market segments
- The Fischer-Burffenbach reformulation assumes value-proportional bidding structure holds exactly, limiting generalization to non-second-price auction formats
- The practical neural network implementation depends on quality and diversity of historical trajectories for robust generalization

## Confidence

- **High Confidence:** The bi-level reformulation mechanism and computational complexity analysis (Mechanism 1 and 3) are well-specified with clear mathematical derivations and proofs
- **Medium Confidence:** The convergence guarantees for the primal-dual method (Mechanism 2) are theoretically sound but depend on several technical assumptions that may not hold in practice
- **Low Confidence:** The practical neural network implementation details (architecture specifics, training procedure, hyperparameter tuning) are insufficiently specified

## Next Checks

1. **Validate Assumption 3.5 empirically:** Generate synthetic market data with varying degrees of advertiser overlap and compute ∂C_i/∂α_i vs Σ_{j≠i}|∂C_i/∂α_j| to identify failure conditions where Self-Dominance breaks down

2. **Stress-test penalty factor sensitivity:** Run Algorithm 1 on benchmark with systematic variation of ρ across orders of magnitude; quantify the Social Welfare vs. Compliance Rate tradeoff and identify the critical threshold where constraint satisfaction dramatically improves

3. **Benchmark against alternative equilibrium methods:** Compare NCB against established equilibrium learning approaches (e.g., simultaneous best-response, gradient-based methods without NE constraints) to isolate the contribution of equilibrium compliance to observed performance gains