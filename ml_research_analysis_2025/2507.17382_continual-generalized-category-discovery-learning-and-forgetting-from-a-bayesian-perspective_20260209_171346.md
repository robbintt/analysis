---
ver: rpa2
title: 'Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian
  Perspective'
arxiv_id: '2507.17382'
source_url: https://arxiv.org/abs/2507.17382
tags:
- learning
- classes
- accuracy
- data
- vb-cgcd
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: VB-CGCD addresses continual generalized category discovery (C-GCD)
  by modeling class distributions via variational inference and mitigating forgetting
  through covariance-aware early stopping. The method uses self-supervised learning-based
  offline fine-tuning, self-corrective re-labeling, and nearest-class-mean classification
  with Mahalanobis distance to balance stability and plasticity.
---

# Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian Perspective

## Quick Facts
- arXiv ID: 2507.17382
- Source URL: https://arxiv.org/abs/2507.17382
- Reference count: 40
- VB-CGCD outperforms state-of-the-art by +15.21% final accuracy on standard benchmarks

## Executive Summary
VB-CGCD addresses continual generalized category discovery (C-GCD) by modeling class distributions via variational inference and mitigating forgetting through covariance-aware early stopping. The method uses self-supervised learning-based offline fine-tuning, self-corrective re-labeling, and nearest-class-mean classification with Mahalanobis distance to balance stability and plasticity. Experiments show VB-CGCD outperforms state-of-the-art by +15.21% final accuracy on standard benchmarks. In a challenging scenario with only 10% labeled data and 9 online sessions, it achieves 67.86% final accuracy, significantly higher than the previous state-of-the-art of 38.55%.

## Method Summary
VB-CGCD combines variational Bayesian distribution estimation with covariance-aware nearest-class-mean classification. The method first fine-tunes a frozen ViT-B/16 backbone on labeled data using contrastive and cross-entropy losses, then fits class distributions via stochastic variational inference (SVI) on the ELBO objective. During online learning, unlabeled data is clustered, pseudo-labeled, and reassigned using a merged MVN-NCM classifier that leverages Mahalanobis distance. An early stopping criterion monitors covariance ratios between new and old classes to prevent forgetting, halting SVI updates when the determinant ratio falls below a threshold. The approach balances stability (preserving old class knowledge) and plasticity (learning new classes) through this unified Bayesian framework.

## Key Results
- VB-CGCD achieves 67.86% final accuracy on CIFAR-100 with 10% labeled data and 9 online sessions, outperforming previous SOTA of 38.55%
- Outperforms state-of-the-art by +15.21% final accuracy on standard benchmarks
- Maintains strong performance across multiple datasets (CIFAR-100, TinyImageNet, ImageNet-100, CUB-200)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Variational Bayes distribution estimation provides noise-robust class modeling for continual learning
- Mechanism: Models each class as a multivariate normal distribution N(μk, Σk) optimized via stochastic variational inference (SVI) on the ELBO objective. The KL divergence penalty downweights outlier contributions from mislabeled samples while the reconstruction term captures true distribution structure.
- Core assumption: Class-conditional features follow approximately Gaussian distributions; labeled data per class is sufficient to estimate covariance
- Evidence anchors: [abstract] "integrates variational inference with covariance-aware nearest-class-mean classification...suppressing pseudo-label noise via stochastic variational updates"
- Break condition: If features are highly non-Gaussian or sample count per class < feature dimensions, covariance matrices become non-invertible

### Mechanism 2
- Claim: Covariance-aware early stopping prevents catastrophic forgetting by aligning new class covariance scales with old classes
- Mechanism: Monitors the ratio R = log[(k-1)det(Σk) / Σdet(Σi)] and halts training when R < ε. This prevents new class covariance from exceeding old class covariance, which asymmetrically increases Bhattacharyya distance and biases decision boundaries toward new classes.
- Core assumption: Forgetting is driven primarily by covariance mismatch rather than mean drift; old class distributions remain stable during new class learning
- Evidence anchors: [abstract] "revealing that covariance misalignment between old and new classes drives performance degradation"
- Break condition: If old class covariances were poorly estimated initially (e.g., limited labeled data), aligning to them propagates errors

### Mechanism 3
- Claim: Self-corrective re-labeling reduces pseudo-label noise by leveraging distribution distance
- Mechanism: Two-stage process: (1) Initial clustering assigns pseudo-labels to unlabeled data; (2) Merge pseudo-labeled distributions with old class distributions into unified MVN-NCM classifier, which reassigns labels based on Mahalanobis distance.
- Core assumption: Clustering errors are systematic rather than random—old class samples cluster near but not exactly on old class means
- Evidence anchors: [abstract] "adaptively aligns class distributions while suppressing pseudo-label noise"
- Break condition: If new class distributions genuinely overlap with old class distributions in feature space, re-labeling cannot disambiguate

## Foundational Learning

- Concept: **Variational Inference & ELBO**
  - Why needed here: Core optimization framework for distribution estimation; must understand trade-off between reconstruction (fit data) and KL penalty (regularization)
  - Quick check question: Given a mislabeled sample far from its assigned class mean, which ELBO term penalizes this more strongly?

- Concept: **Mahalanobis Distance vs. Euclidean Distance**
  - Why needed here: Classification uses Σ⁻¹-weighted distance; explains why covariance alignment matters for boundary stability
  - Quick check question: If all features have unit variance and are uncorrelated, how does Mahalanobis distance simplify?

- Concept: **Bhattacharyya Distance for Distribution Overlap**
  - Why needed here: Paper uses this to quantify class separability; early stopping targets minimizing this distance between old/new distributions
  - Quick check question: Two Gaussians with same mean but different covariances—what does Bhattacharyya distance measure?

## Architecture Onboarding

- Component map:
  ```
  [Labeled Data] → [Offline Fine-tuning: Contrastive + CE Loss]
                          ↓
  [Frozen ViT-B/16 Backbone] → [Feature Extraction h(x)]
                          ↓
              ┌───────────┴───────────┐
              ↓                       ↓
      [SVI Module]            [Clustering Module]
      (ELBO optimizer)        (k-means + silhouette)
              ↓                       ↓
      [Class Distributions]    [Pseudo-labels]
      N(μk, Σk)                       ↓
              └───────────┬───────────┘
                          ↓
                  [Re-labeling Layer]
                  (MVN-NCM classifier)
                          ↓
                  [Early Stopping Gate]
                  (check det(Σk) ratio)
                          ↓
                  [Final Class Distributions]
  ```

- Critical path: Offline fine-tuning → SVI initialization → Online clustering → Re-labeling → SVI update → Early stopping check

- Design tradeoffs:
  - **Full covariance vs. diagonal**: Full covariance captures feature correlations but requires O(d²) storage and inversion; diagonal is O(d) but loses correlation information
  - **Feature dimension**: Paper uses PCA to 384 dimensions; higher dimensions improve accuracy but increase storage and inversion cost
  - **Fine-tuning scope**: Only MLP/output layers updated; full fine-tuning risks feature drift but may improve discriminability

- Failure signatures:
  - **Non-invertible covariance**: Occurs when samples < features; manifests as NaN/Inf in distance computation
  - **Early stopping too aggressive**: New class accuracy plateaus low; old class accuracy stays high but overall accuracy suffers
  - **Re-labeling degrades performance**: Old class accuracy drops after re-labeling; indicates clustering quality too poor

- First 3 experiments:
  1. **Sanity check—Offline only**: Run SVI on labeled data only, verify MVN-NCM matches or exceeds prototype baseline
  2. **Ablation—Early stopping threshold**: Sweep ε ∈ {-2, -1, 0, 1, 2} on CIFAR-100; plot old/new/all accuracy to find Pareto frontier
  3. **Stress test—Limited labeled data**: Replicate b10t9 setting (10% labeled, 9 sessions); expect 67.86% on C100 vs Happy's 36.16%

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can hierarchical Bayesian priors or meta-learning strategies effectively improve covariance estimation accuracy in small-sample regimes?
- Basis in paper: [Explicit] The conclusion identifies small-sample covariance estimation as a specific limitation and suggests investigating hierarchical Bayesian priors
- Why unresolved: The current variational inference approach struggles to model distributions accurately when very few samples are available per class
- What evidence would resolve it: Demonstrated improvement in "Old" and "New" class accuracy on low-shot datasets compared to the current VB-MVN baseline

### Open Question 2
- Question: To what extent can deep clustering techniques reduce the model's sensitivity to initialization and noise in high-dimensional spaces?
- Basis in paper: [Explicit] The authors explicitly state that reliance on initial clustering quality impacts performance
- Why unresolved: The current use of standard k-means makes the system vulnerable to initialization variance and noise propagation
- What evidence would resolve it: Reduced variance in final accuracy across multiple runs and improved robustness in high-dimensional feature spaces

### Open Question 3
- Question: Can the estimation of the number of novel classes be refined to close the performance gap with the known-count scenario?
- Basis in paper: [Inferred] Appendix D.1 shows a ~5.66% drop in overall accuracy when the number of new categories is unknown
- Why unresolved: Errors in estimating the cluster count exacerbate pseudo-label noise, which degrades the subsequent variational inference updates
- What evidence would resolve it: An adaptive estimation method that achieves comparable accuracy to the "fixed count" baseline

## Limitations

- Gaussian distribution assumption for class features is unverified and may not hold for real-world data with heavy tails or multimodal structure
- Covariance-based Mahalanobis distance becomes theoretically unsound when feature distributions deviate significantly from normality
- Computational complexity scales poorly with feature dimensions due to full covariance matrix operations
- Offline fine-tuning assumes sufficient labeled data exists for meaningful distribution estimation

## Confidence

**High confidence**: The variational inference framework provides a principled approach to distribution estimation, and the overall experimental results show consistent improvements over baselines across multiple datasets and scenarios.

**Medium confidence**: The covariance-aware early stopping mechanism's effectiveness is supported by ablation studies, but the theoretical justification relies on assumptions about forgetting mechanisms that weren't directly validated.

**Low confidence**: Claims about the specific ε=0.01 threshold being optimal are based on limited parameter sweeps, and the method's robustness to varying feature dimensionalities or backbone architectures wasn't thoroughly explored.

## Next Checks

1. **Gaussian assumption validation**: Run kernel density estimation on class feature distributions to verify approximate normality. If features show significant non-Gaussian characteristics, the covariance-based Mahalanobis distance becomes theoretically unsound.

2. **Covariance vs. mean drift contribution**: Design an ablation where mean drift is explicitly controlled while covariance is frozen. Compare forgetting rates to isolate whether covariance misalignment or mean shift drives forgetting.

3. **Re-labeling quality assessment**: Track per-class accuracy changes before and after re-labeling to quantify whether improvements come from correctly reassigned samples or from incorrectly reassigned samples.