---
ver: rpa2
title: Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding
  with Large Language Models
arxiv_id: '2602.01969'
source_url: https://arxiv.org/abs/2602.01969
tags:
- table
- semantic
- hierarchical
- orthogonal
- structural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of complex table understanding
  for large language models (LLMs), focusing on tables with multi-level headers, merged
  cells, and irregular layouts. Existing approaches, such as table linearization and
  normalized grid modeling, struggle to capture hierarchical structures and cross-dimensional
  dependencies, leading to misalignment between structural semantics and textual representations.
---

# Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models

## Quick Facts
- **arXiv ID**: 2602.01969
- **Source URL**: https://arxiv.org/abs/2602.01969
- **Reference count**: 13
- **Primary result**: OHD outperforms existing table representation methods on complex table QA benchmarks (AITQA, HiTab).

## Executive Summary
This paper addresses the challenge of complex table understanding for large language models (LLMs), focusing on tables with multi-level headers, merged cells, and irregular layouts. Existing linearization and grid modeling approaches struggle to capture hierarchical structures and cross-dimensional dependencies, leading to misalignment between structural semantics and textual representations. The authors propose Orthogonal Hierarchical Decomposition (OHD), which decomposes tables into independent column and row hierarchies using Orthogonal Tree Induction (OTI). This is combined with a dual-pathway association protocol and an LLM-based semantic arbitrator to reconstruct semantic lineages. Experiments on AITQA and HiTab benchmarks demonstrate consistent improvements over existing methods.

## Method Summary
The OHD framework processes complex tables in three stages: (1) Orthogonal Tree Induction (OTI) builds separate column tree (Tcol) and row tree (Trow) structures using spatial-semantic co-constraints, ensuring only dimension-relevant headers act as branching nodes; (2) Dual-pathway association extracts semantic lineages for each cell by traversing both trees, serializing them as "Context → Key → Value" sequences; (3) An LLM-based semantic arbitrator synthesizes final representations from both pathways. The method requires pre-identified cell roles (Row Header, Column Header, Data) and uses an LLM predicate for semantic verification during tree construction.

## Key Results
- OHD achieves higher Exact Match (EM) scores than standard linearization, Markdown/HTML, and normalized grid methods on both AITQA and HiTab benchmarks.
- The dual-pathway lineage serialization format outperforms flat grid and Markdown representations, with EM gains up to 16.24 points on AITQA.
- Ablation studies confirm the importance of the LLM-based semantic predicate in OTI, with performance drops of 5.99-6.70 EM points when removed.

## Why This Works (Mechanism)

### Mechanism 1: Orthogonal Tree Induction (OTI)
- **Claim**: Decomposing tables into independent row and column hierarchies isolates structural noise from irregular layouts.
- **Mechanism**: OTI creates disjoint column tree ($T_{col}$) and row tree ($T_{row}$), enforcing "Semantic Agency" where only dimension-relevant headers branch.
- **Core assumption**: Table hierarchy can be validly represented as a tree where parent nodes semantically subsume children.
- **Evidence**: OTI method is explicitly described in the abstract and Section 3.1; ablations show geometric proximity alone is insufficient.

### Mechanism 2: Spatial-Semantic Subsumption Verification
- **Claim**: LLM validation of parent-child links corrects misleading spatial adjacency.
- **Mechanism**: Recent Spatial-Semantic Subsumption ($\sqsubseteq_{rss}$) requires both spatial containment and LLM-based semantic predicate ($P_{semantic}$) to form edges.
- **Core assumption**: LLM can accurately determine semantic entailment between short header texts in zero-shot settings.
- **Evidence**: Section 3.2 describes the predicate; ablation shows -5.99 EM drop on AITQA when removed.

### Mechanism 3: Dual-Pathway Lineage Serialization
- **Claim**: "Premise ⊕ (Attribute ⇒ Value)" format provides explicit semantic lineage, preventing structural collapse.
- **Mechanism**: Framework traverses primary tree for premise and orthogonal tree for attributes, combining into structured natural language.
- **Core assumption**: Explicitly stating hierarchical path reduces reasoning burden compared to grid coordinates.
- **Evidence**: Section 3.3 describes the approach; Table 2 shows significant EM drops when replaced with Markdown/HTML.

## Foundational Learning

- **Tree Induction & Spanning**
  - Why needed: OTI relies on sorting headers by spatial coordinates and linking via bounding box containment.
  - Quick check: Given header bounding boxes, can you write logic to determine if header A is a spatial parent of header B?

- **Semantic Entailment**
  - Why needed: $P_{semantic}$ predicate uses LLM to verify logical subsumption (e.g., "Is '2024 Details' a sub-category of 'Year'?").
  - Quick check: How would you prompt an LLM to return binary 1/0 for "Is X a sub-category of Y?" while minimizing false positives?

- **Context Window & Serialization Efficiency**
  - Why needed: Dual-pathway reconstruction generates text sequences; verbose serialization may overflow LLM context windows.
  - Quick check: Does "Context → Key → Value" format scale linearly or quadratically with number of data cells?

## Architecture Onboarding

- **Component map**: Categorized Table Input -> OTI Module (spatial sorting + LLM Predicate) -> Tree Structures ($T_{col}$, $T_{row}$) -> Serializer (dual-pathway traversal) -> Arbitrator (LLM synthesis)
- **Critical path**: Header Classification -> Predicate Verification. If cells are mislabeled or predicate fails, tree induction fails immediately.
- **Design tradeoffs**: Accuracy vs. Latency (LLM calls increase fidelity but preprocessing time); Verbosity vs. Clarity (longer prompts reduce reasoning errors).
- **Failure signatures**: Spurious Nesting (footnotes treated as leaves); Cyclic Dependencies (buggy spatial constraints); Token Explosion (lineage paths exceed prompt limits).
- **First 3 experiments**:
  1. Unit Test OTI: Input table from Figure 1(d) and verify "details in 2007" is not inducted as child of "year" due to semantic predicate override.
  2. Ablation on Serialization: Compare token length and LLM accuracy of "Dual-Path Lineage" vs. Markdown on HiTab subset.
  3. Predicate Sensitivity: Replace LLM-based $P_{semantic}$ with string-contains check to quantify neural verifier value.

## Open Questions the Paper Calls Out

- **Scalability to Ultra-Large Tables**: How does OHD scale to ultra-large-scale financial reports exceeding 50×50 cells? Current evaluation is limited to moderate-scale tables.
- **Multimodal Integration**: Can multimodal visual signals (e.g., borders, styling) enhance robustness of semantic agency identification in OTI?
- **Sensitivity to Cell Role Errors**: How sensitive is OTI to errors in upstream cell role classification (header vs. data)? Framework assumes perfect role labeling.

## Limitations
- Framework requires pre-identified cell roles (Row Header, Column Header, Data), creating dependency on external tools or manual annotation.
- LLM predicate effectiveness across diverse domains and languages is uncertain, potentially struggling with domain-specific terminology.
- Dual-pathway serialization may become prohibitively verbose for extremely large or deeply nested tables, exceeding context windows.

## Confidence
- **High Confidence**: Core orthogonal decomposition mechanism is well-specified and theoretically sound for capturing hierarchical structure.
- **Medium Confidence**: Experimental results on AITQA and HiTab benchmarks are convincing, contingent on successful cell role classification and semantic predicate accuracy.
- **Low Confidence**: Method's robustness to tables with irregular layouts beyond tested benchmarks and generalization to different languages/domains remain unverified.

## Next Checks
1. Implement and evaluate a cell role classification system on diverse complex tables to assess accuracy and impact on OHD performance.
2. Create benchmark of header pairs with known semantic relationships across domains/languages to test $P_{semantic}$ predicate accuracy and identify failure cases.
3. Systematically vary table size and depth, measuring token length and LLM reasoning accuracy of dual-path lineage vs. Markdown to identify efficiency thresholds.