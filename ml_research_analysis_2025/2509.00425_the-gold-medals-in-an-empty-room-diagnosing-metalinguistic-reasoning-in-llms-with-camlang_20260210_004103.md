---
ver: rpa2
title: 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs
  with Camlang'
arxiv_id: '2509.00425'
source_url: https://arxiv.org/abs/2509.00425
tags:
- camlang
- language
- reasoning
- grammar
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Camlang, a constructed language with explicit
  grammar rules and a bilingual dictionary, to evaluate whether large language models
  (LLMs) can acquire and apply linguistic competence through metalinguistic reasoning.
  Camlang is designed to be typologically plausible yet unattested, ensuring novelty
  and preventing reliance on pre-trained patterns.
---

# The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang

## Quick Facts
- arXiv ID: 2509.00425
- Source URL: https://arxiv.org/abs/2509.00425
- Reference count: 40
- Primary result: LLMs score 21-47% on Camlang tasks vs 85-98% on English, revealing gap in metalinguistic competence

## Executive Summary
This paper introduces Camlang, a constructed language designed to test whether large language models can acquire and apply linguistic competence through metalinguistic reasoning. Unlike natural languages where models can rely on pre-trained patterns, Camlang requires explicit learning of grammar rules and vocabulary from provided resources. The evaluation reveals a stark performance gap: while models excel on English questions (85-98% accuracy), their performance drops to 21-47% on Camlang tasks, far below human performance at 87%. Human verification shows that most model successes stem from shallow lexical alignment rather than systematic grammatical mastery, establishing Camlang as a cognitively grounded evaluation paradigm for exposing gaps in current LLM capabilities.

## Method Summary
The evaluation uses Camlang-CSQA-v0, a 47-question multiple-choice dataset adapted from CommonsenseQA and translated into the constructed language. Models are provided with a 453-sentence grammar book and 1,511-entry bilingual dictionary. Two zero-shot evaluation configurations are tested: tool-based (using File Search and Code Interpreter to access grammar and dictionary files) and context-based (prepending full resources as text). GPT-4o, GPT-o3, GPT-5, and DeepSeek-R1 are evaluated using exact match accuracy. Human verification protocol assesses parsing correctness, question meaning comprehension, and option evaluation through three metrics: SHV (shallow human verification), MHV (medium human verification), and LHV (literal human verification).

## Key Results
- LLMs achieve 85-98% accuracy on English CommonsenseQA vs 21-47% on Camlang translation
- Human performance on Camlang tasks reaches 87%, significantly outperforming all tested models
- Human verification reveals most model successes are due to shallow lexical alignment rather than grammatical mastery
- Tool-based lookup performs worse than context-based methods, suggesting models cannot effectively use grammatical rules for morphological analysis

## Why This Works (Mechanism)
The evaluation exposes fundamental limitations in how current LLMs acquire linguistic competence by forcing them to learn a completely novel language from explicit rules rather than relying on pre-trained patterns. Camlang's typologically plausible but unattested features prevent models from using memorized language patterns, requiring genuine metalinguistic reasoning. The constructed language's systematic grammar and vocabulary create a controlled environment where success requires understanding linguistic structures rather than pattern matching.

## Foundational Learning
- Metalinguistic reasoning: The ability to consciously understand and apply linguistic rules rather than relying on statistical patterns. Why needed: Current LLMs often succeed through memorization rather than genuine language understanding.
- Zero-shot evaluation: Testing models without fine-tuning or adaptation to specific tasks. Why needed: Ensures performance reflects general competence rather than task-specific optimization.
- Human verification protocols: Systematic evaluation of model outputs beyond simple accuracy metrics. Why needed: Reveals whether correct answers stem from genuine understanding or shallow pattern matching.
- Morphological analysis: Breaking down words into their constituent parts to understand meaning. Why needed: Essential for applying grammatical rules to novel surface forms.
- Typological plausibility: Language features that could exist in natural languages but haven't been attested. Why needed: Prevents models from using pre-existing knowledge while maintaining cognitive realism.

## Architecture Onboarding
Component map: Grammar Book (File) -> Dictionary (File) -> Question Processing -> Answer Selection -> Human Verification
Critical path: Models must first parse the grammar book, then use the dictionary to understand vocabulary, apply grammatical rules to analyze questions, and finally select correct answers based on this analysis.
Design tradeoffs: Tool-based vs context-based resource access - tools require models to manage file operations while context provides immediate access but increases prompt length.
Failure signatures: High exact match but low SHV indicates lexical shortcutting; tool-based underperformance suggests morphological analysis difficulties; systematic errors on specific grammatical constructions reveal structural misunderstandings.
First experiments: 1) Compare tool vs context accuracy to identify morphological analysis bottlenecks, 2) Test different prompt engineering approaches with explicit grammatical rule examples, 3) Evaluate model performance on progressively complex Camlang constructions to identify systematic weaknesses.

## Open Questions the Paper Calls Out
None

## Limitations
- Core Camlang resources (grammar book and dictionary) are withheld from public release, preventing independent validation
- Human verification protocols rely on subjective assessments that may not fully capture metalinguistic reasoning nuances
- Paper lacks detailed error analysis on specific Camlang constructions where models fail systematically

## Confidence
- High Confidence: Performance gap between English (85-98%) and Camlang (21-47%) is clearly demonstrated with quantitative evidence
- Medium Confidence: Shallow lexical alignment explanation is well-supported by human verification showing high EM but low SHV
- Low Confidence: Claims about fundamental limitations in LLM metalinguistic competence are difficult to validate without access to specific Camlang resources

## Next Checks
1. Request and independently verify the Camlang grammar book and dictionary to reproduce the exact evaluation setup
2. Implement human verification protocol on a subset of model outputs to assess inter-rater reliability
3. Test alternative LLM configurations (different temperature settings, few-shot examples with explicit grammatical rules) to determine whether performance gap is fundamental or potentially bridgeable