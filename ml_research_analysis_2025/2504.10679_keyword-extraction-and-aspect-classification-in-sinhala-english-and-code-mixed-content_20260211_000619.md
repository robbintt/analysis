---
ver: rpa2
title: Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed
  Content
arxiv_id: '2504.10679'
source_url: https://arxiv.org/abs/2504.10679
tags:
- keyword
- sinhala
- extraction
- banking
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of processing code-mixed and
  low-resource language banking content for brand reputation monitoring. A hybrid
  NLP framework was developed combining fine-tuned transformer models with domain-specific
  vocabularies for keyword extraction, irrelevant content filtering, and aspect classification.
---

# Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content

## Quick Facts
- arXiv ID: 2504.10679
- Source URL: https://arxiv.org/abs/2504.10679
- Reference count: 24
- Key outcome: Hybrid NLP framework achieves 91.2% English keyword extraction accuracy and 87.4% accuracy for Sinhala and code-mixed content using fine-tuned transformer models.

## Executive Summary
This study addresses the challenge of processing code-mixed and low-resource language banking content for brand reputation monitoring. The researchers developed a hybrid NLP framework combining fine-tuned transformer models with domain-specific vocabularies for keyword extraction, irrelevant content filtering, and aspect classification. The system processes YouTube comments and website reviews in English, Sinhala, and mixed-language formats, extracting relevant keywords and categorizing content into six banking-related aspects. Results demonstrate that fine-tuned models outperform traditional methods and generic LLMs in multilingual financial text analysis.

## Method Summary
The researchers implemented a hybrid NLP framework that processes banking-related content across three languages. For English keyword extraction, they combined SpaCy NER, FinBERT-enhanced KeyBERT, YAKE, and EmbedRank using a weighted scoring formula. For Sinhala and code-mixed content, they fine-tuned XLM-RoBERTa with a domain-specific financial vocabulary. Content filtering was performed using BERT-base-uncased models, and aspect classification used the same architectures. The system was trained on 6,000+ annotated banking comments and validated across multiple performance metrics.

## Key Results
- English keyword extraction achieved 91.2% accuracy using the hybrid approach
- Sinhala and code-mixed keyword extraction reached 87.4% accuracy with vocabulary boosting
- Content filtering achieved 85.2% accuracy for English and 88.1% for Sinhala
- Aspect classification accuracy was 87.4% for English and 85.9% for Sinhala

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Weighted Ensemble for English Keyword Extraction
- **Claim:** Combining statistical, graph-based, and transformer-based extraction methods with weighted scoring improves keyword accuracy.
- **Mechanism:** The system aggregates candidate keywords from YAKE, KeyBERT, EmbedRank, and SpaCy NER, then ranks them using a custom weighted score (2⋅YAKE + 3⋅KeyBERT + 4⋅EmbedRank) validated against financial vocabulary.
- **Evidence:** The abstract mentions this hybrid approach achieving 91.2% accuracy, and the methodology section defines the scoring formula.
- **Break condition:** If method weights are incorrect for different banking subdomains, the ranking may prioritize noise over relevant terms.

### Mechanism 2: Vocabulary-Boosted Cross-Lingual Transfer
- **Claim:** Integrating domain-specific vocabulary with fine-tuned multilingual transformers mitigates data sparsity in low-resource code-mixed text.
- **Mechanism:** Fine-tuned XLM-RoBERTa extracts terms, then applies a boosting function that doubles scores for terms matching the curated Sinhala financial vocabulary.
- **Evidence:** The abstract states this integration achieved 87.4% accuracy, and the methodology describes the boosting function.
- **Break condition:** If code-mixed content uses Romanized Sinhala not in the vocabulary, the boosting mechanism fails.

### Mechanism 3: Specialized Fine-Tuning vs. Zero-Shot LLMs
- **Claim:** Fine-tuned encoder models outperform general-purpose generative models in specific classification tasks within low-resource domains.
- **Mechanism:** Training BERT and XLM-RoBERTa on domain-specific annotated data enables learning banking-specific features that generic models miss.
- **Evidence:** The abstract notes BERT/XLM-R results were better than GPT-4o, SVM, and keyword-based filtering, supported by performance tables.
- **Break condition:** As general LLMs improve their reasoning or few-shot capabilities, the gap between fine-tuned encoders and generative models may close.

## Foundational Learning

- **Concept: Code-Mixing in NLP**
  - **Why needed here:** The paper handles Sinhala-English code-mixed text where monolingual tokenizers fail and grammar is non-standard.
  - **Quick check question:** How does a monolingual English tokenizer typically handle Sinhala script or Romanized Sinhala tokens?

- **Concept: Contextual vs. Statistical Keyword Extraction**
  - **Why needed here:** The architecture rejects pure frequency-based methods in favor of contextual embeddings to capture semantics over raw frequency.
  - **Quick check question:** Why would TF-IDF fail to identify a rare but critical term like "mortgage restructuring" in a short customer review?

- **Concept: Transfer Learning with Transformers**
  - **Why needed here:** The system relies on pre-trained models and fine-tunes them rather than training from scratch to solve the "low-resource" data problem.
  - **Quick check question:** What is the primary advantage of using XLM-RoBERTa over standard BERT for a Sinhala-English dataset?

## Architecture Onboarding

- **Component map:** Web Scraper -> Raw Text -> Cleaning/Deduplication -> Lane Split -> English Lane (SpaCy NER + FinBERT-KeyBERT + YAKE + EmbedRank -> Hybrid Scorer) / Sinhala/Code-Mixed Lane (XLM-RoBERTa Extractor + Vocabulary Booster) -> BERT-base/XLM-R Filtering -> BERT-base/XLM-R Aspect Classification

- **Critical path:** The Vocabulary Booster and Hybrid Scorer are the custom logic layers. Removing these components reverts the system to standard generic extraction.

- **Design tradeoffs:**
  - Complexity vs. Accuracy: Maintaining four extraction methods for English increases inference complexity but yields higher precision than a single LLM call.
  - Static vs. Dynamic Vocabulary: The Sinhala vocabulary boosting relies on a static dictionary, ensuring precision but potentially lacking recall for evolving slang.

- **Failure signatures:**
  - High False Negatives in Filtering: Overly aggressive BERT filtering might classify genuine complaints with informal language as irrelevant noise.
  - Vocabulary Mismatch: Romanized Sinhala failing to match the vocabulary dictionary, leading to low extraction scores.

- **First 3 experiments:**
  1. Ablation Study on Weights: Re-run English extraction with modified weights to verify sensitivity of the 91.2% accuracy claim.
  2. Script Variation Test: Input Romanized Sinhala into the pipeline to observe handling of Singlish versus native script.
  3. Adversarial Filtering: Test the filter's recall against spam comments using banking keywords to measure false positive rates.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can a sentiment classification module be effectively integrated for end-to-end aspect-based sentiment analysis of Sinhala-English financial discussions? (Basis: Future work identified in Conclusion for complete brand reputation monitoring.)

- **Open Question 2:** To what extent do explainability methods like SHAP and LIME improve transparency and stakeholder trust when applied to these multilingual transformer models? (Basis: Authors explicitly list this as future work to address "black box" concerns.)

- **Open Question 3:** Can the proposed hybrid framework be generalized to other low-resource languages like Tamil without significant accuracy loss? (Basis: Conclusion outlines plans for regional language expansion.)

## Limitations

- The 91.2% accuracy claim depends on specific weight assignments that may not generalize across different banking subdomains.
- The vocabulary-boosting mechanism assumes comprehensive coverage of financial terms, potentially failing with emerging slang or Romanized Sinhala.
- Classification accuracy metrics don't specify category distributions, potentially masking bias against minority aspect categories.

## Confidence

- **High Confidence:** General approach of fine-tuning transformer models for domain-specific classification tasks.
- **Medium Confidence:** Specific 91.2% English keyword extraction accuracy depends on weight assignments and vocabulary quality.
- **Medium Confidence:** 87.4% Sinhala keyword extraction accuracy assumes vocabulary comprehensiveness and effective code-mixing handling.
- **Medium Confidence:** Claims of outperforming GPT-4o lack detailed comparison methodology.

## Next Checks

1. **Weight Sensitivity Analysis:** Re-run English extraction with modified weights to verify the 91.2% accuracy is robust to parameter changes.
2. **Script Variation Testing:** Input Romanized Sinhala banking comments to measure performance degradation and determine if transliteration preprocessing is needed.
3. **Category Distribution Analysis:** Compute F1-scores for each aspect category to reveal potential bias masked by overall accuracy metrics.