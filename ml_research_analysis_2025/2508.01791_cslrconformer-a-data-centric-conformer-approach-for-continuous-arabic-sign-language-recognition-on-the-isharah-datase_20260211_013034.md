---
ver: rpa2
title: 'CSLRConformer: A Data-Centric Conformer Approach for Continuous Arabic Sign
  Language Recognition on the Isharah Datase'
arxiv_id: '2508.01791'
source_url: https://arxiv.org/abs/2508.01791
tags:
- sign
- recognition
- language
- data
- cslr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a data-centric approach for Continuous Arabic
  Sign Language Recognition using the Isharah dataset, achieving state-of-the-art
  performance. The method employs systematic feature engineering guided by Exploratory
  Data Analysis to identify communicative keypoints, reducing the feature space from
  86 to 82 keypoints.
---

# CSLRConformer: A Data-Centric Conformer Approach for Continuous Arabic Sign Language Recognition on the Isharah Datase

## Quick Facts
- arXiv ID: 2508.01791
- Source URL: https://arxiv.org/abs/2508.01791
- Reference count: 28
- Primary result: Achieved 5.60% WER on development set and 12.01% WER on test set, securing 3rd place in MSLR 2025 Challenge with 54.8% relative improvement over baseline

## Executive Summary
This paper presents a data-centric approach for Continuous Arabic Sign Language Recognition using the Isharah dataset, achieving state-of-the-art performance. The method employs systematic feature engineering guided by Exploratory Data Analysis to identify communicative keypoints, reducing the feature space from 86 to 82 keypoints. A robust preprocessing pipeline includes DBSCAN-based outlier filtering and spatial normalization. The novel CSLRConformer architecture adapts the Conformer model for sign language recognition, combining CNN layers for local temporal patterns with self-attention for global context modeling. The approach achieved a Word Error Rate of 5.60% on the development set and 12.01% on the test set, securing 3rd place in the MSLR 2025 Workshop Challenge and demonstrating a 54.8% relative improvement over baseline methods.

## Method Summary
The approach combines data-centric preprocessing with a novel Conformer architecture for Continuous Arabic Sign Language Recognition. Starting with 86 keypoints, the method uses EDA to identify and remove 4 low-activity keypoints, reducing the feature space to 82. DBSCAN filters outliers, and frame-level normalization handles signer variability. Dynamic features are engineered by concatenating position, velocity, and acceleration, creating 492-dimensional inputs. The CSLRConformer uses 8 Macaron-Net style blocks with CNN layers for local patterns and self-attention for global context, trained with CTC loss. SpecAugment and careful hyperparameter tuning complete the pipeline.

## Key Results
- Achieved 5.60% Word Error Rate on development set (single unseen signer)
- Achieved 12.01% Word Error Rate on test set (4 unseen signers)
- Secured 3rd place in MSLR 2025 Workshop Challenge
- Demonstrated 54.8% relative improvement over baseline methods

## Why This Works (Mechanism)

### Mechanism 1: Noise Suppression via Communicative Keypoint Isolation
The reduction from 86 to 82 keypoints improves generalization by filtering non-communicative or noisy body points rather than maximizing data retention. EDA quantifies keypoint displacement, filtering low-movement points likely representing torso/static body parts and inconsistent tracking via DBSCAN. This focuses learning capacity on communicative regions (hands/face), reducing the curse of dimensionality and noise.

### Mechanism 2: Hybrid Local-Global Temporal Context Modeling
The Conformer architecture (CNN + Self-Attention) outperforms standard RNNs or Transformers alone by simultaneously capturing fine motor movements and long-range syntactic dependencies. The "Macaron-Net-style" sandwich structure applies Feed-Forward modules for feature projection, Multi-Head Self-Attention for global sequence context, and Convolution for local positional invariance, addressing co-articulation effects where signs bleed into one another.

### Mechanism 3: Signer-Invariant Spatial Normalization
Spatial normalization relative to a calculated bounding box enables the model to generalize to unseen signers by decoupling gesture morphology from absolute body position. The pipeline normalizes keypoints based on a bounding box rather than a fixed skeleton origin, creating scale and translation invariance critical for signer-independent recognition where test subjects have different body geometries and distances from the camera.

## Foundational Learning

- **Connectionist Temporal Classification (CTC) Loss**
  - Why needed here: CSLR lacks explicit temporal boundaries between words. CTC allows the model to output a probability distribution over vocabulary for every frame and "collapses" repeats to form sentences without needing frame-level labels.
  - Quick check question: How does CTC handle the "blank" token during the collapse process to distinguish between repeated signs and single held signs?

- **Conformer Architecture (CNN + Attention)**
  - Why needed here: This is the core engine. Unlike LSTMs which process sequentially, or pure Transformers which are computationally heavy on long sequences, Conformers use convolutions to capture local "edges" in the signal before attending to global relationships.
  - Quick check question: Why is the convolution module placed between the two half-step Feed-Forward layers in the "sandwich" structure?

- **Keypoint-based SLR vs. RGB-based SLR**
  - Why needed here: This paper uses pre-extracted coordinates (86->82 points) rather than raw pixels. This reduces computational load but loses texture/non-manual cues (like cheek puffing) unless specifically encoded in the point map.
  - Quick check question: What specific non-manual markers (e.g., eyes, mouth) were retained in the 82-keypoint selection, and which were discarded?

## Architecture Onboarding

- **Component map:** Input (492-dim features: Pos+Vel+Acc) -> Temporal Subsampler (Conv, 4x reduction) -> Linear Projection + Pos Encoding -> [Conformer Block x 8] -> Classifier (Linear) -> CTC Loss

- **Critical path:** The feature engineering pipeline is the most brittle component. The model relies on the specific reduction to 82 keypoints via DBSCAN filtering. If the input data format changes (e.g., a different pose estimator), the "master mask" must be regenerated.

- **Design tradeoffs:**
  - Data Centric vs. Model Centric: The authors sacrificed raw information (4 keypoints) for data quality (noise reduction)
  - Subsampling: Reducing temporal length by 75% boosts speed and reduces memory for Attention but risks erasing micro-gestures
  - Feature Depth: Using 492 dimensions (Pos+Vel+Acc) triples input size but allows the Conformer to see "movement" explicitly rather than inferring it

- **Failure signatures:**
  - High Substitution/Deletion Rate: Observed in results (607 subs, 583 dels). Indicates the model struggles with "co-articulation" (blurred transitions) and temporal redundancy
  - Squeeze-and-Excite Collapse: The paper notes the SE-Conformer variant failed catastrophically (98.88% WER), suggesting that channel attention mechanisms may overfit to noise in this specific keypoint domain

- **First 3 experiments:**
  1. Validate the Keypoint Mask: Re-run the EDA displacement analysis on a random sample of the test set (if labels were available) or a hold-out set to verify that the "inactive" keypoints are consistently the same 4 points
  2. Ablation on Dynamics: Train a baseline using only Position features (164-dim) vs. Position+Velocity+Acceleration (492-dim) to quantify the value of the engineered dynamics
  3. Subsampling Sensitivity: Reduce the subsampling factor (e.g., from 4x to 2x) to see if the increased temporal resolution improves the "deletion" error rate for fast signs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can spatial augmentation techniques be developed to accommodate the unique structural properties of sign language keypoints?
- Basis in paper: [explicit] The conclusion states that future research must prioritize advanced spatial augmentations, as current methods are limited by structural ambiguities.
- Why unresolved: The lack of standardized keypoint indexing in the dataset prevents the implementation of anatomically-aware transformations like horizontal flipping.
- Evidence: The development of topology-based augmentation strategies that improve model robustness without violating skeletal constraints.

### Open Question 2
- Question: Does mapping unstructured keypoints to standardized skeletal representations improve generalization in signer-independent tasks?
- Basis in paper: [explicit] The authors identify "mapping unstructured keypoints to standardized skeletal representations" as a specific, promising direction for future work to enhance accuracy.
- Why unresolved: Current data lacks consistent indexing, forcing the model to learn from unstructured points rather than explicit anatomical relationships.
- Evidence: A standardized mapping protocol that leads to a measurable reduction in Word Error Rate on the unseen signer test set.

### Open Question 3
- Question: Can specific modeling techniques reduce the performance disparity between the single-signer development set and the multi-signer test set?
- Basis in paper: [inferred] The paper highlights a performance gap (5.60% vs. 12.01% WER) and attributes it to the challenge of four unseen signers in the test set versus one in development.
- Why unresolved: While the current architecture performs well, the significant drop in test performance indicates the model has not fully generalized across high signer variability.
- Evidence: A model architecture that achieves a test set WER statistically closer to the development set performance in the signer-independent split.

## Limitations
- The 86-to-82 keypoint reduction assumes low-movement keypoints are non-communicative noise, which may not generalize to sign languages with different body-part emphasis
- Significant performance gap between development (5.60% WER) and test sets (12.01% WER) indicates model struggles with signer variability despite spatial normalization
- Missing implementation details prevent exact reproduction: specific keypoint indices removed, DBSCAN parameters, convolution kernel sizes, and complete vocabulary

## Confidence

- **High Confidence:** The basic methodology of keypoint reduction via displacement analysis is sound and well-established in the literature. The use of CTC loss for sequence modeling is appropriate for CSLR tasks.

- **Medium Confidence:** The architectural design (Conformer with Macaron-Net structure) is theoretically justified and has shown success in other CSLR works. The feature engineering pipeline (position+velocity+acceleration) is a reasonable approach for capturing sign dynamics.

- **Low Confidence:** The specific performance metrics (5.60% dev, 12.01% test WER) and the claimed 54.8% relative improvement lack independent verification due to missing baseline methodology and implementation details.

## Next Checks

1. **Keypoint Mask Validation:** Re-run the displacement analysis on a held-out validation set to verify that the same 4 keypoints consistently show minimal movement across different signers and samples. This confirms the noise filtering assumption.

2. **Temporal Resolution Sensitivity:** Conduct experiments with varying subsampling factors (2x, 4x, 8x) to determine the optimal temporal resolution for distinguishing co-articulated signs while maintaining computational efficiency.

3. **Architecture Ablation Study:** Implement and compare against simpler architectures (LSTM with CTC, vanilla Transformer with CTC, CNN-only baseline) using identical preprocessing and training procedures to quantify the true contribution of the Conformer architecture.