---
ver: rpa2
title: Exploring the Structure of AI-Induced Language Change in Scientific English
arxiv_id: '2506.21817'
source_url: https://arxiv.org/abs/2506.21817
tags:
- words
- language
- focal
- changes
- frequency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study explores the structure of AI-induced language change
  in scientific English, focusing on the impact of Large Language Models (LLMs) on
  word frequency and semantic shifts. The research systematically analyzes synonym
  groups of widely discussed "spiking words" in scientific abstracts from PubMed,
  using part-of-speech tagging to differentiate between word forms.
---

# Exploring the Structure of AI-Induced Language Change in Scientific English

## Quick Facts
- arXiv ID: 2506.21817
- Source URL: https://arxiv.org/abs/2506.21817
- Reference count: 10
- Primary result: LLM-induced changes propagate through semantic clusters rather than replacing individual synonyms.

## Executive Summary
This study investigates how Large Language Models (LLMs) influence word frequency and semantic shifts in scientific English, using PubMed abstracts from 1975-2024. The research reveals that when focal words like "crucial" increase in usage, their semantic neighbors (e.g., "essential," "key") also trend upward, indicating semantic and pragmatic additions rather than lexical replacement. Additionally, the study identifies a significant decline in "important" usage, showing that decreasing words follow more complex, organic patterns compared to abrupt positive spikes. These findings suggest LLM-induced language change is additive and semantic rather than subtractive or purely lexical.

## Method Summary
The study analyzed 28.8 million PubMed abstracts (6.94B tokens) using spaCy POS-tagging to track word frequency changes from 1975-2024. Researchers identified 32 focal words from literature showing recent spiking patterns, extracted synonyms via Merriam-Webster API, and filtered them through GPT-4o-mini for academic relevance. They calculated occurrences per million (OPM) and percent change 2020-2024, then tested co-movement within semantic clusters. For declining words, they manually filtered unexplained decreases and cross-referenced against AI-generated abstracts to identify AI-underused terms.

## Key Results
- Semantic clusters shift together: When focal words spike, entire synonym groups increase rather than showing replacement patterns.
- LLMs prefer low-content style words: Adjectives, adverbs, and verbs show most spiking activity, while content nouns remain largely unaffected.
- Declining words follow organic patterns: Unlike abrupt positive spikes, decreasing words show gradual fluctuations consistent with natural language change.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-induced language change propagates through semantic clusters rather than replacing individual synonyms.
- Mechanism: When focal words like "crucial" spike in frequency, their semantic neighbors (e.g., "essential," "key") also increase rather than decrease. This suggests LLMs introduce semantic/pragmatic qualifications—adding emphasis—rather than substituting one term for another.
- Core assumption: These clustered increases reflect LLM influence, not coincidental organic shifts coinciding with LLM adoption timing.
- Evidence anchors:
  - [abstract] "entire semantic clusters often shift together, with most or all words in a group increasing in usage"
  - [section 2] Figure 1 shows "crucial" spiking while synonyms also trend upward; Table 1 documents multi-synonym increases (e.g., "significant ADJ" +27.42%, synonym "substantial" +53.18%)
  - [corpus] Related work "Examining Linguistic Shifts in Academic Writing Before and After the Launch of ChatGPT" confirms post-2022 lexical shifts; no direct corpus evidence on synonym co-movement
- Break condition: If synonyms of spiking words showed systematic decreases, the replacement hypothesis would hold instead.

### Mechanism 2
- Claim: AI-induced lexical change concentrates on low-content stylistic words (adjectives, adverbs, verbs) rather than content-bearing nouns.
- Mechanism: LLMs preferentially overuse "style words" that add qualification but minimal information. POS-tagging reveals nouns play almost no role except for rare cases like "potential NOUN."
- Core assumption: The observed POS distribution reflects LLM output preferences rather than domain-specific topic shifts in biomedical literature.
- Evidence anchors:
  - [section 2] "Many of our focal words were verbs, adverbs, and adjectives... apart from 'advancement,' nouns do not play any notable role"
  - [section 4] "All of our focal words were AI-overused, low content words"
  - [corpus] Weak corpus anchor—related papers don't specifically analyze POS distribution patterns
- Break condition: If content nouns showed comparable spiking patterns, the mechanism would need revision toward broader lexical disruption.

### Mechanism 3
- Claim: Decreasing lexical items follow organic, complex patterns rather than mirroring abrupt positive spikes.
- Mechanism: Unlike spiking words with step-function increases around 2022, declining words (e.g., "important ADJ" -23.43%) show gradual fluctuations over decades, consistent with normal language change dynamics.
- Core assumption: Absence of sharp negative spikes indicates LLM influence is additive (introducing preferences) rather than subtractive (suppressing terms).
- Evidence anchors:
  - [abstract] "analysis of 'collapsing' words reveals a more complex picture, which is consistent with organic language change"
  - [section 3] Figure 4 shows declining focal words with varied, non-mirror-image trajectories
  - [corpus] No direct corpus evidence on decline pattern structures
- Break condition: If systematic sharp negative spikes were found at scale, the asymmetric-change claim would weaken.

## Foundational Learning

- Concept: **Relative frequency as zero-sum dynamic**
  - Why needed here: Understanding why the "replacement hypothesis" was a plausible null—increases in one lexical item necessarily imply decreases elsewhere in the frequency distribution.
  - Quick check question: If "crucial" increases from 100 to 200 OPM, must another word decrease? Explain.

- Concept: **Part-of-speech (POS) tagging disambiguation**
  - Why needed here: The paper relies on distinguishing word forms (e.g., "potential NOUN" vs. "potential ADJ") to avoid collapsing distinct syntactic behaviors.
  - Quick check question: Why would analyzing "underscore" without POS tagging conflate two different linguistic phenomena?

- Concept: **Semantic vs. lexical change**
  - Why needed here: The central finding distinguishes whether LLMs change word choice (lexical substitution) or broader meaning/pragmatics (adding emphasis across related terms).
  - Quick check question: If "crucial" and "essential" both increase, is this lexical replacement or semantic/pragmatic addition?

## Architecture Onboarding

- Component map:
  PubMed API -> POS tagging with spaCy -> OPM calculation -> Change detection with chi-square -> Synonym extraction via Merriam-Webster -> LLM filtering with GPT-4o-mini -> Co-movement analysis

- Critical path:
  1. POS-tagged corpus -> 2. OPM calculation by lemma+POS -> 3. Identify spiking/declining candidates -> 4. Filter via AI-authored comparison -> 5. Cluster synonyms -> 6. Analyze co-movement patterns

- Design tradeoffs:
  - Using GPT-4o-mini to filter synonyms introduces potential circularity (AI judging AI-relevant terms)
  - PubMed biomedical focus limits generalizability; other domains may show different patterns
  - Chi-square on OPM may be sensitive to low-frequency items; rare words inflate significance

- Failure signatures:
  - If synonym selection over-includes/excludes academic terms, cluster analysis becomes noisy
  - If POS tagger misclassifies systematic categories (e.g., gerund vs. adjective), spurious trends emerge
  - If topic shifts (e.g., COVID-19) are not controlled, attribution to LLMs is confounded

- First 3 experiments:
  1. Replicate on non-biomedical corpus (e.g., arXiv) to test if semantic cluster co-movement generalizes across scientific domains.
  2. Control for topic confounds by regressing out domain-specific keyword spikes (e.g., pandemic terms) before computing residual frequency changes.
  3. Longitudinal spoken language comparison as suggested in paper—if written LLM-influenced shifts precede spoken changes, this strengthens causality claims; if not, the mechanism may be text-editing specific.

## Open Questions the Paper Calls Out

- Why do LLMs exhibit specific patterns of lexical over- and underuse, such as the preference for low-content "style words"?
  - The authors state, "A major question, beyond the scope of this paper, remains: Why do language models exhibit the observed patterns of over- and underuse?"
  - These words are not disproportionately frequent in the training data; while RLHF is a plausible contributor, it is not confirmed.
  - A comparative analysis of lexical frequency in base LLMs versus their preference-tuned (RLHF) counterparts could isolate where bias is introduced.

- To what extent are observed linguistic shifts caused by direct LLM usage versus indirect influence on human authors' internal language faculties?
  - The authors note, "One possibility is the direct use of LLM-generated language; another possibility is an indirect effect."
  - Written abstracts cannot distinguish between authors using ChatGPT directly versus adopting AI-preferred vocabulary after exposure.
  - Longitudinal analysis comparing spontaneous spoken language trends with written language trends could test this distinction.

- Do observed semantic and pragmatic shifts in synonym clusters generalize to other scientific disciplines or other languages?
  - The authors explicitly limit their scope to "biomedical and life sciences" and suggest future research should focus on other varieties, even other languages.
  - The study relied exclusively on PubMed abstracts, and LLMs may exhibit context-sensitive, domain-specific behaviors.
  - Replicating the methodology on corpora from other fields (e.g., computer science on arXiv) or cross-linguistic datasets would test generalizability.

## Limitations
- Causal attribution to LLMs versus domain/topic shifts remains uncertain without robust topic modeling controls.
- Synonym selection and filtering via LLM introduces potential circularity—AI-generated content may shape the definition of what counts as "academic" usage.
- POS-tagging errors on historical texts could misattribute trends, particularly for ambiguous forms like gerunds and adjectives.

## Confidence
- **High confidence**: The finding that spiking words show co-movement within semantic clusters (i.e., entire groups increase together rather than replacing each other).
- **Medium confidence**: The claim that LLMs overuse low-content style words (adjectives, adverbs, verbs) while content nouns remain largely unaffected—limited by weak corpus validation.
- **Medium confidence**: The conclusion that declining words follow organic, non-mirror-image patterns of increasing words—based on visual inspection rather than formal time-series modeling.

## Next Checks
1. Replicate the study on non-biomedical corpora (e.g., arXiv) to test if semantic cluster co-movement generalizes across scientific domains.
2. Control for domain-specific topic shifts by regressing out keyword spikes (e.g., pandemic terms) before computing residual frequency changes.
3. Compare longitudinal spoken language data (as suggested in the paper) to test whether written LLM-influenced shifts precede spoken changes, strengthening or weakening causality claims.