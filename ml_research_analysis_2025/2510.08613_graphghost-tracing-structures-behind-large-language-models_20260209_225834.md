---
ver: rpa2
title: 'GraphGhost: Tracing Structures Behind Large Language Models'
arxiv_id: '2510.08613'
source_url: https://arxiv.org/abs/2510.08613
tags:
- reasoning
- tokens
- graphghost
- token
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'GraphGhost is a graph-based framework for interpreting internal
  reasoning mechanisms in large language models. It models token interactions and
  neuron activations as graphs from two perspectives: a sample view tracing reasoning
  dependencies within individual predictions, and a dataset view aggregating recurring
  structural patterns across samples.'
---

# GraphGhost: Tracing Structures Behind Large Language Models

## Quick Facts
- **arXiv ID**: 2510.08613
- **Source URL**: https://arxiv.org/abs/2510.08613
- **Reference count**: 40
- **Primary result**: GraphGhost uses circuit tracing to build token-level attribution graphs that identify functionally important reasoning structures in LLMs, outperforming attention-based and random baselines in capturing reasoning dependencies.

## Executive Summary
GraphGhost introduces a graph-based framework for interpreting internal reasoning mechanisms in large language models by modeling token interactions and neuron activations as graphs. The framework constructs graphs from two perspectives: a sample view tracing reasoning dependencies within individual predictions, and a dataset view aggregating recurring structural patterns across samples. Using circuit tracing with trained transcoders per layer, GraphGhost captures how tokens merge semantically and how reasoning triggers emerge during generation. Quantitative experiments demonstrate that GraphGhost-identified tokens consistently outperform attention-based and random baselines in capturing functionally important reasoning structures, with significantly higher fidelity under low sparsity constraints. Perturbations to structurally critical nodes identified by GraphGhost measurably alter reasoning behavior, demonstrating that the framework captures meaningful internal structures governing LLM reasoning.

## Method Summary
GraphGhost constructs token-level attribution graphs using circuit tracing with per-layer transcoders that decompose dense MLP activations into sparse, interpretable features. The framework builds sample-level graphs by backward expansion from answer tokens through circuit-traced dependencies, then aggregates these into dataset-level views to identify recurring structural patterns. Graph-theoretic metrics (in-degree, PageRank) are used to identify functionally important nodes, with perturbation experiments validating their causal roles. The method operates on both sample and dataset levels, capturing how intermediate tokens are composed, propagated, and reused during reasoning in LLMs.

## Key Results
- GraphGhost-identified tokens achieve higher fidelity (0.28-0.58) than attention-based and random baselines when identifying functionally important reasoning structures
- High in-degree nodes (semantic merging points) and high PageRank nodes (reasoning triggers) show measurable impact on reasoning behavior when perturbed
- Dataset view reveals recurring structural patterns across reasoning samples, with specific token types (numbers, operators, discourse markers) showing distinct layer-wise distributions

## Why This Works (Mechanism)

### Mechanism 1: Circuit-Tracing Based Attribution Graph Construction
Transcoders decompose dense layer activations into sparse, interpretable features that enable construction of token-level attribution graphs. Each layer gets a trained transcoder that learns sparse feature representations reconstructing hidden activations. Logit-level contribution weights from transcoder features to final predictions create directed edges in the attributed graph. Core assumption: sparse feature representations faithfully approximate original MLP computation while being more interpretable.

### Mechanism 2: Sample-Level Backward Dependency Expansion
Tracing backward from answer tokens through circuit-traced dependencies captures reasoning-specific token interactions within individual predictions. Starting from final answer token, recursively apply circuit tracing to identify contributing tokens, adding newly discovered tokens to frontier until reaching question tokens. Core assumption: reasoning-relevant dependencies form connected subgraphs traceable from outputs back to inputs.

### Mechanism 3: Graph Structural Properties as Functional Importance Proxies
Node in-degree and PageRank scores on constructed graphs correlate with functional importance for reasoning behavior. High in-degree nodes represent semantic merging points (multiple tokens converging). High PageRank nodes represent reasoning triggers (influential tokens initiating reasoning chains). Perturbation experiments validate that muting these nodes alters outputs.

## Foundational Learning

- **Transcoders / Sparse Autoencoders**: Core technique for decomposing dense LLM activations into interpretable sparse features. GraphGhost relies entirely on transcoder-derived attribution graphs. Quick check: Can you explain how a transcoder differs from a standard autoencoder, and why sparsity is enforced?

- **Attribution Methods and Circuit Tracing**: GraphGhost builds on circuit tracing to identify token-level dependencies. Understanding attribution fundamentals (gradient-based, perturbation-based) contextualizes the approach. Quick check: What are the tradeoffs between attention-based attribution vs. logit-contribution-based attribution?

- **Graph Centrality Measures (In-Degree, PageRank)**: Used to identify functionally important nodes. In-degree captures merging behavior; PageRank captures global influence. Quick check: Why might PageRank be more suitable than simple degree for identifying reasoning triggers?

## Architecture Onboarding

- **Component map**: Transcoders (per-layer) -> Circuit Tracer -> Sample Graph Builder -> Dataset Aggregator -> Analysis Layer
- **Critical path**: 1) Train transcoders on target model activations, 2) Run inference with transcoders replacing MLP layers, 3) Execute circuit tracing per sample, 4) Aggregate to dataset level and compute structural metrics, 5) Validate via perturbation experiments
- **Design tradeoffs**: Sparsity vs. Coverage (higher L1 coefficient increases sparsity but may miss features), Node/Edge Ratio Thresholds (trade-off between graph completeness and noise), Sample vs. Dataset View (instance-specific vs. recurring patterns)
- **Failure signatures**: High transcoder reconstruction error (MSE > 0.001) → attribution graphs unreliable, Low fidelity even at high sparsity → graph construction not capturing relevant tokens, Graph density too high → thresholding may have failed
- **First 3 experiments**: 1) Transcoder Validation: Train on small dataset subset, verify MSE convergence (< 0.001) before full pipeline, 2) Sample View Sanity Check: Run on simple arithmetic example, verify number-related tokens appear and dependencies make intuitive sense, 3) Perturbation Baseline: Compare GraphGhost-identified nodes vs. random vs. attention-based nodes on fidelity/sparsity metrics

## Open Questions the Paper Calls Out

### Open Question 1
How does the noise inherent in current transcoder-based circuit tracing methods impact the false discovery rate of edges in GraphGhost, and can more precise tracers fundamentally alter the identified structural patterns? The authors acknowledge that current methods produce "noisy or incomplete" estimates, potentially yielding "missing or spurious edges," but they do not quantify this error margin or test alternative tracing architectures.

### Open Question 2
Do the structural mechanisms identified by GraphGhost, specifically "semantic merging" in middle layers and "reasoning triggers" in higher layers, generalize to creative or unstructured tasks, or are they unique to formal reasoning domains? The paper focuses exclusively on structured reasoning tasks (math, logic, science), leaving behavior in open-ended or creative generation unexplored.

### Open Question 3
Can the graph construction pipeline be optimized to reduce the substantial computational overhead, which currently requires up to 3 hours per sample, to enable dataset-scale analysis? The high time complexity serves as a practical bottleneck for the "dataset view" which requires aggregating structures across many samples.

## Limitations
- Transcoders must accurately reconstruct original MLP activations; high reconstruction error (MSE > 0.001) leads to noisy attribution graphs
- Current attribution tracing methods are acknowledged as noisy or incomplete, potentially missing critical dependencies or including spurious edges
- Computational overhead is substantial, requiring 0.5-3 hours per sample depending on reasoning length, limiting dataset-scale analysis

## Confidence

**High Confidence**:
- GraphGhost-identified tokens outperform attention-based and random baselines in capturing functionally important reasoning structures
- Perturbation experiments show measurable effects on reasoning behavior for structurally critical nodes
- The sample-level graph construction methodology is technically sound and reproducible

**Medium Confidence**:
- Graph-theoretic metrics (in-degree, PageRank) meaningfully correlate with functional importance in LLM reasoning
- Dataset-level aggregation reveals recurring structural patterns across reasoning samples
- The framework provides more principled insights than existing attention-based interpretability methods

**Low Confidence**:
- Transcoder-based attribution graphs faithfully capture the original MLP computation across all layers
- The backward expansion algorithm reliably identifies complete reasoning dependencies
- Graph structural properties can be used as universal proxies for functional importance across diverse LLM architectures

## Next Checks

1. **Transcoder Quality Validation**: Implement per-layer MSE monitoring during transcoder training across all model architectures. Compare dead feature rates with and without L1 regularization. Verify that reconstruction quality correlates with attribution graph reliability by measuring fidelity degradation when perturbing nodes identified by noisy vs. clean graphs.

2. **Graph Coverage Analysis**: Design controlled experiments using synthetic reasoning tasks with known ground truth dependencies. Systematically vary the backward expansion stopping criteria and measure recall/precision of identified reasoning paths. Compare GraphGhost's coverage against alternative attribution methods (integrated gradients, attention patterns) on the same tasks.

3. **Cross-Domain Generalization Test**: Apply GraphGhost to non-mathematical reasoning tasks (story completion, commonsense reasoning, creative writing). Measure whether the same graph structural properties (high in-degree, high PageRank) correlate with functional importance across domains. Analyze whether domain-specific graph patterns emerge in the dataset view aggregation.