---
ver: rpa2
title: Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient
  Combined Sewer Overflow Management
arxiv_id: '2508.13905'
source_url: https://arxiv.org/abs/2508.13905
tags:
- lstm
- energy
- transformer
- deployment
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents an automated energy-aware deployment framework
  for time-series forecasting models on embedded FPGAs, targeting resilient combined
  sewer overflow management. The framework addresses the challenge of reliable local
  forecasting during extreme weather events when cloud connectivity is disrupted.
---

# Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management

## Quick Facts
- arXiv ID: 2508.13905
- Source URL: https://arxiv.org/abs/2508.13905
- Reference count: 26
- Primary result: Automated framework achieves 0.370 mJ/inference Transformer accuracy (MSE 0.0376) vs 0.009 mJ/inference LSTM (14.89% less accurate)

## Executive Summary
This paper presents an automated deployment framework for energy-efficient time-series forecasting on embedded FPGAs, targeting combined sewer overflow management during extreme weather events when cloud connectivity fails. The framework integrates quantization-aware training, hardware-aware optimization, and multi-objective search to deploy lightweight Transformer and LSTM models on AMD Spartan-7 XC7S15 FPGAs. Experimental results demonstrate that 8-bit Transformer models achieve high accuracy (MSE 0.0376) at 0.370 mJ per inference, while 8-bit LSTM models consume over 40× less energy (0.009 mJ) but with 14.89% lower accuracy (MSE 0.0432).

## Method Summary
The framework combines PyTorch-based quantization-aware training with hardware-aware optimization using Optuna and NSGA-II for multi-objective search. Models are trained with integer-only quantization (4-8 bit), then deployed via ElasticAI.Creator to generate VHDL templates. RTL simulation extracts latency while Vivado synthesis estimates power consumption. The search jointly minimizes prediction error and energy consumption while ensuring resource constraints (8,000 LUTs, 360 Kbits BRAM, 20 DSPs) are met on the target Spartan-7 XC7S15 FPGA.

## Key Results
- 8-bit Transformer achieves MSE 0.0376 at 0.370 mJ/inference with n=24 input sequence
- 8-bit LSTM consumes 0.009 mJ/inference (40× less energy) with MSE 0.0432 (14.89% accuracy loss)
- Energy consumption scales non-linearly: Transformer increases 92.5× (0.004→0.370 mJ) from n=6 to n=24
- LSTM shows minimal accuracy gain with longer sequences (0.0433→0.0432) but modest energy increase (0.002→0.009 mJ)

## Why This Works (Mechanism)

### Mechanism 1: Integer-Only Quantization via QAT Preserves Accuracy Under Resource Constraints
During training, QAT simulates low-precision (4-8 bit) integer arithmetic, allowing models to learn quantization-resilient weights. This eliminates floating-point operations during inference, reducing memory footprint and enabling efficient fixed-point computation on FPGA fabric. The approach reports only 0.23-2.89% MSE increase for n=6 models versus FP32 baselines.

### Mechanism 2: Hardware-Aware Multi-Objective Configuration Search Navigates Accuracy-Energy Trade-offs
The Optuna-based pipeline with NSGA-II sampler explores configuration space (bitwidth, hidden size, learning rate, batch size) and filters candidates through RTL simulation (latency) and post-synthesis power estimation. Only resource-valid configurations appear on the Pareto front, enabling stakeholders to select based on accuracy/energy priorities.

### Mechanism 3: Input Sequence Length Drives Accuracy-Energy Trade-off Asymmetrically Across Architectures
Transformer self-attention complexity scales with sequence length, requiring more BRAM and compute. LSTM's recurrent processing handles longer sequences with linear scaling. Transformer energy increases from 0.004 mJ (n=6) to 0.370 mJ (n=24)—92.5× growth—while LSTM only increases from 0.002 mJ to 0.009 mJ.

## Foundational Learning

- Concept: Quantization-Aware Training (QAT)
  - Why needed here: Enables integer-only inference on FPGAs without floating-point units; PTQ alone caused unacceptable accuracy loss on small models.
  - Quick check question: Can you explain why simulating quantization during training preserves accuracy better than applying it post-training?

- Concept: Pareto Front Optimization
  - Why needed here: Multi-objective search (accuracy vs. energy) has no single optimum; Pareto fronts reveal trade-off configurations for stakeholder selection.
  - Quick check question: Given two configurations where A has lower MSE but higher energy than B, how do you determine if A dominates B?

- Concept: FPGA Resource Types (LUTs, BRAM, DSPs)
  - Why needed here: Deployment feasibility depends on fitting model within 8,000 LUTs, 360 Kbits BRAM, 20 DSPs on Spartan-7 XC7S15.
  - Quick check question: Which resource type primarily constrains matrix multiplication operations in neural network layers?

## Architecture Onboarding

- Component map:
  ElasticNode V5 RP2040 MCU -> AMD Spartan-7 XC7S15 FPGA -> PyTorch QAT -> ElasticAI.Creator -> VHDL templates -> GHDL RTL simulation -> Vivado synthesis -> Optuna search

- Critical path:
  1. Define model configuration space (bitwidth, hidden dim, input length, hyperparameters)
  2. Run QAT training with validation loss tracking
  3. Generate quantized integer-only model
  4. Produce VHDL via ElasticAI.Creator templates
  5. RTL simulation extracts latency (T)
  6. Vivado synthesis extracts power (P) and resource utilization
  7. Optuna computes energy (E = P × T), updates Pareto front
  8. Select deployment configuration based on accuracy/energy priority

- Design tradeoffs:
  - LSTM: 40× lower energy, 14.89% worse accuracy, 2× longer deployment pipeline runtime due to sequential computation simulation
  - Transformer: Higher accuracy with longer sequences, but energy scales non-linearly; faster convergence reduces operational costs
  - Bitwidth: 4-bit quantization fails for regression; 6-8 bit balances accuracy and resource usage

- Failure signatures:
  - "BRAM utilization exceeds 100%" → input sequence or model dimension too large for target FPGA
  - "Test MSE >> validation MSE" → overfitting or quantization mismatch between QAT simulation and actual inference
  - "Power estimation timeout" → RTL simulation too slow; reduce input length or model complexity for search phase

- First 3 experiments:
  1. Replicate n=6 Transformer configuration (b=6, dmodel=8) on ElasticNode V5; verify MSE within 5% of reported 0.0427 and energy near 0.004 mJ
  2. Run full Optuna search (10 trials minimum) for LSTM at n=12; confirm all 10 configurations deploy successfully and plot Pareto front
  3. Compare actual hardware power measurement vs. Vivado estimate for the n=24 Transformer; validate 5.8% deviation claim under 28°C ambient temperature

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework be extended to multi-step ahead forecasting while maintaining the energy-accuracy trade-offs observed in single-step prediction?
- Basis in paper: The authors note they "adopt a simpler one-step ahead approach" in contrast to prior work performing "12-step ahead forecasting," and state this formulation suits low-latency local scenarios.
- Why unresolved: Multi-step forecasting introduces additional complexity in both model architecture and quantization that may shift the Pareto-optimal configurations and energy consumption patterns.
- What evidence would resolve it: Deploying both architectures with multi-step prediction heads and measuring whether similar LSTM-Transformer trade-offs hold across prediction horizons.

### Open Question 2
- Question: How would the optimal model configurations and energy-accuracy trade-offs generalize to sewer systems with different hydraulic characteristics?
- Basis in paper: The evaluation uses a single dataset from one district (Vierlinden, Duisburg), but combined sewer systems vary significantly in basin geometry, catchment size, and rainfall patterns.
- Why unresolved: Model configurations optimized for one system's temporal patterns may not transfer to systems with different filling dynamics or overflow frequencies.
- What evidence would resolve it: Cross-validation across multiple municipal datasets from geographically and hydraulically diverse sewer systems.

### Open Question 3
- Question: Can the LSTM deployment pipeline runtime be reduced to match Transformer deployment times without sacrificing model quality?
- Basis in paper: The authors report that "the full deployment pipeline for a Transformer model completes up to 1 hour" while "the same pipeline for LSTM takes up to 2 hours due to the sequential nature of recurrent computations," limiting scalability.
- Why unresolved: The sequential computation pattern is inherent to LSTMs, but pipeline parallelization, improved simulation strategies, or hardware template optimization may address this bottleneck.
- What evidence would resolve it: Demonstrating modified deployment toolchains that achieve comparable LSTM deployment times while maintaining equivalent model accuracy and energy efficiency.

## Limitations

- Single dataset evaluation limits generalizability to different time-series domains and sewer system characteristics
- Hardware estimates depend on Vivado post-synthesis power reports that may not capture real-world thermal and supply voltage variations
- Framework assumes fixed one-step-ahead forecasting; extending to multi-step prediction would require architectural changes
- 5.8% power estimation error may accumulate in long-term operational planning
- No addressing of model drift over extended deployments for environmental monitoring applications

## Confidence

- **Integer-Only Quantization Mechanism**: High - Well-supported QAT results with 0.23-2.89% MSE increase align with established literature
- **Hardware-Aware Search Mechanism**: Medium - Logically sound pipeline but hardware metric correlation (2% latency, 5.8% power deviation) not validated across diverse conditions
- **Architecture Scaling Claims**: Medium - Internally consistent results reproducible on same dataset but may not generalize to different temporal characteristics

## Next Checks

1. **Dataset Generalization Test**: Deploy optimized n=6 Transformer and n=12 LSTM configurations on two additional public time-series datasets (energy consumption and medical monitoring) to verify MSE and energy metrics remain acceptable for regression tasks in different domains.

2. **Hardware Measurement Validation**: Build and measure the n=24 Transformer configuration on actual ElasticNode V5 hardware under varying ambient temperatures (20°C-35°C) to confirm power consumption stays within ±5.8% deviation from Vivado estimates.

3. **Multi-Step Forecasting Extension**: Modify framework to generate 6-step-ahead predictions instead of one-step, then re-run Optuna search for both architectures at n=12 to assess whether accuracy-energy trade-offs shift significantly for this common operational requirement.