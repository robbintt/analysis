---
ver: rpa2
title: 'Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction
  for Large-Scale Matching'
arxiv_id: '2502.20687'
source_url: https://arxiv.org/abs/2502.20687
tags:
- diffusion
- user
- module
- item
- two-tower
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of two-tower models in large-scale
  matching by proposing T2Diff, a generative cross-interaction decoupling architecture.
  The key innovation is using a diffusion module to reconstruct the next positive
  user intention and a mixed-attention mechanism to facilitate comprehensive cross-interaction
  between user and item representations.
---

# Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction for Large-Scale Matching

## Quick Facts
- arXiv ID: 2502.20687
- Source URL: https://arxiv.org/abs/2502.20687
- Reference count: 40
- Two-tower architecture with diffusion-based cross-interaction outperforms state-of-the-art by up to 22.27% on ML-1M

## Executive Summary
This paper addresses the fundamental limitation of two-tower models in large-scale matchingâ€”their inability to capture cross-feature interactions between user and item representations without sacrificing inference efficiency. The authors propose T2Diff, which introduces a diffusion module to reconstruct the next positive user intention and a mixed-attention mechanism to facilitate comprehensive cross-interaction. The key innovation is using drift-based diffusion (reconstructing temporal differences between behaviors) rather than raw item embeddings, combined with a stop-gradient mechanism to decouple optimization objectives. Extensive experiments on ML-1M, KuaiRand, and industrial datasets demonstrate significant performance improvements while maintaining comparable inference efficiency.

## Method Summary
T2Diff combines a diffusion module for temporal drift reconstruction with a mixed-attention mechanism for cross-interaction. The diffusion module captures the difference between adjacent user behaviors and reconstructs the next positive item representation using a U-Net architecture with exponential noise scheduling. The mixed-attention module processes the current session combined with the reconstructed next item, using target-attention to extract high-order features from historical behaviors. A stop-gradient mechanism decouples the diffusion module's reconstruction loss from the main tower's ranking loss, preventing optimization conflicts. The model is trained end-to-end with a combined loss function balancing recommendation accuracy and reconstruction fidelity.

## Key Results
- T2Diff achieves up to 22.27% improvement in MRR@20 on ML-1M compared to state-of-the-art two-tower methods
- On KuaiRand, T2Diff improves MRR@100 by 4.08% over baselines
- A/B testing on a large-scale short-video platform shows 10.98% increase in effective view rate and improved user engagement metrics
- Inference efficiency remains comparable to standard two-tower models (0.68ms per sample with T=50 diffusion steps)

## Why This Works (Mechanism)

### Mechanism 1: Drift-Based Diffusion for Intent Reconstruction
The model reconstructs the temporal drift between adjacent user behaviors rather than absolute item representations. By calculating the element-wise difference $z_0 = x_{n+1} - x_n$ and using a U-Net to denoise this drift vector, the diffusion model learns to generate more accurate predictions of the next positive behavior. This approach assumes that user interest shifts follow a simpler distribution than absolute item embeddings, making the denoising task more tractable.

### Mechanism 2: Generative Cross-Interaction (Early Interaction)
The reconstructed next positive behavior ($\hat{x}_{n+1}$) is concatenated with the user's current session and used as a query in a mixed-attention module. This allows the user embedding to be shaped by the anticipated target before the final scoring, effectively achieving "early interaction" within the efficiency constraints of a two-tower architecture. The mixed-attention combines self-attention for the session and target-attention for historical behaviors.

### Mechanism 3: Decoupled Optimization via Stop-Gradient
A stop-gradient mechanism isolates the diffusion module from the backpropagation of the main tower's softmax loss. This prevents conflicting gradient signals between the reconstruction objective (learning temporal drift) and the ranking objective (optimizing recommendation accuracy). The diffusion module is trained solely on the KL reconstruction loss, while the tower benefits from the reconstructed features without interference.

## Foundational Learning

- **Concept: Denoising Diffusion Probabilistic Models (DDPM)**
  - Why needed here: T2Diff relies on the reverse process of a diffusion model to generate the "next positive intention." Understanding the noise schedule ($\beta_t$) and the reverse step (Equation 17) is critical for debugging the generation quality.
  - Quick check question: Can you explain why the paper uses an *exponential* noise schedule instead of a linear one? (Hint: See Table 3).

- **Concept: Late vs. Early Interaction**
  - Why needed here: The paper frames its contribution as solving the "Late Interaction" limitation of standard two-tower models. You must understand that "Late" means interaction only happens at the final dot product, while "Early" (achieved here via Mixed-Attention) involves feature mixing in the hidden layers.
  - Quick check question: How does T2Diff achieve "Early Interaction" without merging the two towers (which would destroy inference efficiency)?

- **Concept: Target-Attention vs. Self-Attention**
  - Why needed here: The Mixed-Attention module uses a hybrid approach. It uses self-attention for the current session but *target-attention* for the historical sequence. The "Target" is the output of the session self-attention.
  - Quick check question: In Equation 20, what serves as the Query ($Q$) when extracting interest from the historical sequence $X_{history}$?

## Architecture Onboarding

- **Component map:** User Tower (Mixed-Attention Module + Diffusion Module) -> User Embedding -> Inner Product with Item Embedding (Item Tower)
- **Critical path:**
  1. Drift Preparation: Concatenate history ($X_{1:n}$) and target ($x_{n+1}$). Compute drift $z_0$.
  2. Diffusion Reverse: Sample noise $z_T$ -> U-Net -> Reconstruct $\hat{z}_0$ -> Derive $\hat{x}_{n+1}$.
  3. Feature Crossing: Concatenate session ($X_{session}$) + $\hat{x}_{n+1}$.
  4. Embedding: Use result to query history ($X_{history}$) via Target-Attention -> Final User Embedding.
- **Design tradeoffs:**
  - Inference Latency vs. Quality: The diffusion step count ($T$) is the primary lever. The paper sets $T=50$ as a balance. $T=200$ offers marginal accuracy gains (+0.015 MRR) but increases latency by ~338% (Table 4).
  - Drift vs. Raw: The model computes diffusion on the *difference* of embeddings, not the embeddings themselves. This lowers the complexity of the distribution the U-Net must learn.
- **Failure signatures:**
  - Divergent Loss: If $L_{KL}$ drops but $L_{TOWER}$ stagnates, the diffusion module is learning drift patterns that do not help ranking (feature misalignment).
  - Performance Collapse: If inference time explodes, check if the U-Net is being triggered per-item rather than per-user (it should be per-user).
- **First 3 experiments:**
  1. Ablate Drift Preparation (W/O DP): Run the model diffusing raw embeddings instead of drift vectors. Verify if the paper's claim of "easier to model" holds (Section 5.1.4 shows a drop in performance without DP).
  2. Hyperparameter Scan on $T$: Test $T \in \{10, 50, 100, 200\}$ on a validation set to find the specific latency/accuracy knee-point for your hardware.
  3. Stop-Gradient Validation: Train two versions: one with stop-gradient and one without. Compare training stability and final MRR to validate the "gradient counteraction" claim.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the diffusion reverse process be optimized to achieve the accuracy of high-step counts (e.g., T=200) without the associated latency penalties?
- **Basis in paper:** [explicit] Section 5.1.5 notes that while T=200 yields the optimal MRR, it "significantly amplified the inference time... which could impede the practical utility," forcing a compromise at T=50.
- **Why unresolved:** The authors identified the trade-off but did not explore accelerated sampling techniques (e.g., DDIM, consistency distillation) that might decouple step count from inference time.
- **What evidence would resolve it:** Experiments applying accelerated diffusion samplers to T2Diff, demonstrating T=200-level accuracy at T=50-level latency.

### Open Question 2
- **Question:** Is the U-Net architecture the most efficient backbone for the diffusion approximator compared to sequential architectures like Transformers or SSMs?
- **Basis in paper:** [inferred] Section 4.2.1 justifies the U-Net choice for its convolutional kernels, yet the paper compares T2Diff against Mamba4Rec, highlighting the efficiency of State Space Models (SSMs) for sequences.
- **Why unresolved:** The paper ablates hyper-parameters and noise schedules but treats the U-Net approximator as a fixed component, leaving its architectural efficiency unverified.
- **What evidence would resolve it:** Ablation studies replacing the U-Net approximator with Mamba or Transformer blocks to compare reconstruction fidelity and inference speed.

### Open Question 3
- **Question:** How robust is the "drift preparation" mechanism ($X_{t+1} - X_t$) when user behavior sequences are sparse or exhibit erratic intent shifts?
- **Basis in paper:** [inferred] Section 4.2 posits that diffusing the "drift" is easier than the raw sequence, relying on the assumption that adjacent behaviors share "temporal continuity" (Section 4.3).
- **Why unresolved:** If user intent shifts abruptly or interactions are infrequent, the element-wise subtraction could result in noisy or meaningless drift vectors, potentially degrading reconstruction quality.
- **What evidence would resolve it:** Performance evaluation on datasets specifically characterized by session fragmentation or high sparsity, analyzing the variance of the generated drift vectors.

## Limitations
- The drift-based reconstruction assumes temporal continuity in user behavior, which may fail with erratic or sparse sequences
- The U-Net architecture for diffusion is underspecified, making it difficult to assess practical latency claims
- The stop-gradient mechanism assumes no useful gradient information flows from ranking to reconstruction, which is not empirically validated

## Confidence
- **High Confidence:** The core empirical findings (performance improvements on ML-1M and KuaiRand) are well-supported by the experimental results presented
- **Medium Confidence:** The theoretical mechanism (drift-based diffusion + mixed-attention) is plausible but relies on several untested assumptions about user behavior distributions
- **Low Confidence:** The scalability claims to industrial settings and specific latency numbers depend heavily on implementation details not provided in the paper

## Next Checks
1. **Gradient Conflict Validation:** Train T2Diff with and without the stop-gradient mechanism while monitoring both $L_{KL}$ and $L_{TOWER}$ convergence curves to empirically verify whether gradient conflict exists and whether decoupling is beneficial.
2. **Drift Distribution Analysis:** Conduct an ablation study comparing diffusion on raw embeddings versus drift vectors across datasets with varying levels of user behavior stochasticity to test whether the "easier to model" claim holds universally.
3. **Cross-Dataset Generalization:** Evaluate T2Diff on datasets with different characteristics (e.g., sequential recommendation datasets like YooChoose, or image retrieval datasets) to assess whether the performance gains transfer beyond the two public datasets tested.