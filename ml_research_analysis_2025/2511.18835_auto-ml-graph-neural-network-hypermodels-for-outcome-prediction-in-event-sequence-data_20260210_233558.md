---
ver: rpa2
title: Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence
  Data
arxiv_id: '2511.18835'
source_url: https://arxiv.org/abs/2511.18835
tags:
- graph
- data
- process
- predictive
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HGNN(O), an AutoML framework for outcome
  prediction on event-sequence data that combines four GNN architectures (One-Level,
  Two-Level, Two-Level Pseudo Embedding, and Two-Level Embedding) with six canonical
  GNN operators (GCNConv, GraphConv, SAGEConv, TAGConv, ChebConv, and GINConv). The
  framework employs Bayesian optimization with pruning and early stopping to automatically
  tune architectures and hyperparameters without manual configuration.
---

# Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence Data

## Quick Facts
- arXiv ID: 2511.18835
- Source URL: https://arxiv.org/abs/2511.18835
- Reference count: 18
- Primary result: HGNN(O) achieves >0.98 accuracy on balanced data and F1 up to 0.86 on imbalanced data via AutoML GNN search.

## Executive Summary
This paper presents HGNN(O), an AutoML framework for outcome prediction in event-sequence data using graph neural networks. The approach automatically explores a design space of four GNN architectures combined with six canonical GNN operators via Bayesian optimization. The framework is evaluated on two real-world event logs (Traffic Fines and Patients), showing strong performance without manual hyperparameter tuning. Notably, it achieves high accuracy on balanced datasets and robust F1 scores on highly imbalanced data without explicit imbalance handling.

## Method Summary
HGNN(O) constructs directed, weighted graphs from event logs, where nodes encode both event-level and case-level attributes, and edges capture temporal order with weights based on normalized time gaps. The framework defines four GNN architectures (One-Level, Two-Level, Two-Level Pseudo Embedding, and Two-Level Embedding) and applies six standard GNN operators. Bayesian optimization with pruning and early stopping is used to automatically search over architecture and hyperparameter space. The best model is selected via validation performance and retrained for final evaluation.

## Key Results
- Traffic Fines dataset: accuracy of 0.986–0.993 on balanced classification.
- Patients dataset: weighted F1 scores of 0.76–0.87 on highly imbalanced 6-class prediction.
- AutoML search identified T-GNN + GINConv as best on balanced data and T-GNN + GraphConv on imbalanced data.
- No explicit imbalance handling required for strong minority-class performance.

## Why This Works (Mechanism)
The framework leverages GNNs to model temporal and structural dependencies in event sequences by encoding both case-level and event-level attributes into node features. Weighted edges encode time gaps, allowing the model to capture temporal dynamics. The AutoML component enables efficient exploration of the large design space without manual tuning, while early stopping and pruning improve search efficiency. The combination of multiple architectures and operators allows the system to adapt to different data characteristics.

## Foundational Learning
- **Graph construction from event logs**: Convert traces into directed, weighted graphs with node features and time-based edge weights; needed to represent event sequences as structured data for GNNs; quick check: verify graph connectivity and edge weight distribution.
- **Weighted GNN operators**: Modify standard GNN layers (GCN, SAGE, etc.) to incorporate edge weights derived from time gaps; needed to model temporal dynamics; quick check: compare outputs of weighted vs unweighted operators.
- **Bayesian optimization with pruning**: Use Optuna to efficiently search over architecture and hyperparameter space with early stopping; needed to avoid manual tuning and reduce computational cost; quick check: confirm top-k trials are stable across multiple runs.

## Architecture Onboarding
- **Component map**: Event log → Graph construction → GNN architecture (O/T/TP/TE) + GNN operator → Global pooling → Concatenation with sequence features → FC classifier.
- **Critical path**: Graph construction → AutoML search (architecture/operator + hyperparameters) → Model selection and retraining → Evaluation.
- **Design tradeoffs**: AutoML reduces manual tuning but increases computational cost; weighted operators capture temporal dynamics but add implementation complexity; no explicit imbalance handling simplifies pipeline but may limit minority-class performance.
- **Failure signatures**: Poor accuracy may indicate incorrect graph construction (e.g., missing or misweighted edges); low F1 on imbalanced data may suggest model collapse to majority class; unstable search results may indicate insufficient trials or poor sampler/pruner settings.
- **First experiments**: 1) Build graph pipeline and visualize sample graphs; 2) Implement and test one weighted GNN operator; 3) Run a small-scale AutoML search with fixed architecture to validate pipeline.

## Open Questions the Paper Calls Out
None

## Limitations
- Key implementation details (weighted operator formulations, exact graph construction rules, hyperparameter ranges) are underspecified, hindering exact reproduction.
- Performance is reported only on two proprietary datasets; lack of standard benchmark (e.g., BPIC 2012) limits external validation.
- No explicit handling of class imbalance may limit robustness on highly skewed data in other domains.

## Confidence
- **High confidence**: The methodological approach (HGNN(O) framework) is clearly described and internally consistent.
- **Medium confidence**: General pipeline is reproducible, but performance replication uncertain without exact parameter values and implementation details.
- **Low confidence**: Precise definition of weighted GNN operators and event-to-graph mapping, which are critical for faithful reproduction.

## Next Checks
1. Implement and validate weighted GNN operators using normalized time gaps as edge weights, comparing against unweighted baselines.
2. Apply the reproduced pipeline to BPIC 2012 (A, B, or C) to enable comparison with prior PPM work.
3. Conduct ablation studies to quantify the impact of event-level features on predictive performance.