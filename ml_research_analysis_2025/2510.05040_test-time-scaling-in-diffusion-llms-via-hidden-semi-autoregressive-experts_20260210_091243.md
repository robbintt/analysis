---
ver: rpa2
title: Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts
arxiv_id: '2510.05040'
source_url: https://arxiv.org/abs/2510.05040
tags:
- block
- arxiv
- tokens
- reasoning
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies test-time scaling in diffusion-based large language
  models (dLLMs) by examining how different token unmasking orders affect performance.
  It identifies that dLLMs implicitly learn a mixture of semi-autoregressive experts
  during training, with different masking schedules revealing different specialized
  behaviors.
---

# Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts

## Quick Facts
- **arXiv ID**: 2510.05040
- **Source URL**: https://arxiv.org/abs/2510.05040
- **Reference count**: 40
- **Key outcome**: Introduces HEX inference method that ensembles across heterogeneous block schedules, boosting GSM8K accuracy from 24.72% to 88.10%

## Executive Summary
This paper explores test-time scaling in diffusion-based large language models (dLLMs) by examining how different token unmasking orders affect performance. The authors discover that dLLMs implicitly learn a mixture of semi-autoregressive experts during training, with different masking schedules revealing specialized behaviors. To leverage this, they propose HEX (Hidden Semi-Autoregressive EXperts), a training-free inference method that ensembles outputs from multiple block schedules through majority voting. HEX significantly outperforms fixed-schedule inference and achieves state-of-the-art results on reasoning tasks like GSM8K, MATH, ARC-C, and TruthfulQA.

## Method Summary
The paper investigates test-time scaling in diffusion-based LLMs by analyzing how different token unmasking schedules affect model performance. The authors identify that dLLMs implicitly learn a mixture of semi-autoregressive experts during training, with different masking schedules revealing different specialized behaviors. To address the limitation of committing to a single inference schedule, they introduce HEX (Hidden Semi-Autoregressive EXperts), which ensembles across heterogeneous block schedules through majority voting. This training-free approach allows the model to leverage the full range of learned behaviors without requiring additional fine-tuning.

## Key Results
- GSM8K reasoning accuracy improves from 24.72% to 88.10% using HEX
- MATH benchmark accuracy increases from 16.40% to 40.00%
- ARC-C performance jumps from 54.18% to 87.80%
- TruthfulQA accuracy improves from 28.36% to 57.46%
- HEX outperforms top-K margin inference and GRPO fine-tuned models

## Why This Works (Mechanism)
The paper proposes that dLLMs learn a mixture of semi-autoregressive experts during training, where different masking schedules reveal different specialized behaviors. By committing to a single fixed inference schedule, performance collapses because it fails to leverage this latent ensemble. HEX addresses this by ensembling across heterogeneous block schedules through majority voting, allowing the model to access the full range of learned behaviors. This approach effectively scales test-time compute by exploring multiple inference paths without additional training.

## Foundational Learning
- **Diffusion Models**: Why needed - Core architecture being analyzed; Quick check - Understand forward noising and reverse denoising process
- **Semi-Autoregressive Decoding**: Why needed - Key insight about implicit expert learning; Quick check - Compare with fully autoregressive and fully parallel decoding
- **Masking Schedules**: Why needed - Central to understanding performance differences; Quick check - Analyze how different block sizes affect generation
- **Majority Voting Ensembles**: Why needed - Core mechanism of HEX; Quick check - Verify voting aggregation across multiple outputs
- **Test-Time Scaling**: Why needed - Broader context of inference optimization; Quick check - Compare with other test-time scaling methods like best-of-N sampling

## Architecture Onboarding

**Component Map**: Diffusion Model -> Masking Schedule -> Hidden Expert Behavior -> Majority Voting Ensemble

**Critical Path**: Input text → Noising function → Reverse diffusion with specific masking schedule → Generate tokens → Majority voting across schedules → Final output

**Design Tradeoffs**: Fixed schedule (simple but suboptimal) vs. HEX (complex but leverages full model capacity); Single schedule (faster but less accurate) vs. multiple schedule ensemble (slower but significantly more accurate)

**Failure Signatures**: Performance collapse when using single fixed masking schedule; Inconsistent outputs across different masking patterns indicating lack of expert coordination

**First 3 Experiments**: 1) Compare GSM8K accuracy across different fixed masking schedules to verify performance variation, 2) Implement HEX with 2-3 masking schedules and measure accuracy gains, 3) Evaluate HEX on non-reasoning tasks to test generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Causal interpretation of expert specialization relies on behavioral evidence rather than direct architectural analysis
- Majority voting treats all schedules equally without accounting for potentially varying reliability
- Experimental scope limited to four benchmark tasks, unclear if gains generalize to other domains

## Confidence

**High confidence**: Empirical observation of performance drops under fixed masking schedules is well-supported; HEX implementation details are sufficiently specified; Strong performance gains relative to baseline inference methods are well-documented.

**Medium confidence**: Interpretation of semi-autoregressive expert learning is plausible but relies on behavioral rather than direct architectural evidence; Claim of establishing a "new paradigm" may be somewhat overstated.

**Low confidence**: Comparison to GRPO fine-tuned models lacks sufficient detail about baselines and computational budgets for full evaluation.

## Next Checks
1. **Architectural validation**: Use activation visualization or probing techniques to directly verify whether different masking schedules activate distinct subnetworks or representations

2. **Schedule reliability weighting**: Implement and evaluate a weighted ensemble variant of HEX that assigns different confidence scores to outputs from different masking schedules based on their historical reliability

3. **Cross-domain generalization**: Test HEX on non-mathematical and non-reasoning tasks (code generation, dialogue, long-form summarization) to assess transfer to other LLM application domains and identify domain-specific limitations