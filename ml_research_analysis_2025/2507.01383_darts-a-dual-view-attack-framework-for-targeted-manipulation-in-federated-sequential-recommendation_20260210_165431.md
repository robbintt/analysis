---
ver: rpa2
title: 'DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated
  Sequential Recommendation'
arxiv_id: '2507.01383'
source_url: https://arxiv.org/abs/2507.01383
tags:
- attack
- recommendation
- federated
- item
- darts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DARTS, a dual-view attack framework designed
  to enhance targeted item promotion in federated sequential recommendation systems.
  The method combines an explicit substitution strategy that replaces vulnerable items
  in user sequences with ones more likely to boost the target item's score, and an
  implicit contrastive learning approach that increases embedding similarity between
  interacted and target items.
---

# DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation

## Quick Facts
- arXiv ID: 2507.01383
- Source URL: https://arxiv.org/abs/2507.01383
- Reference count: 40
- Primary result: DARTS achieves ER@10 > 0.99 on ML-1M with 0.05-0.1% malicious clients, outperforming baselines by 30-100x

## Executive Summary
This paper introduces DARTS, a dual-view attack framework designed to enhance targeted item promotion in federated sequential recommendation systems. The method combines an explicit substitution strategy that replaces vulnerable items in user sequences with ones more likely to boost the target item's score, and an implicit contrastive learning approach that increases embedding similarity between interacted and target items. Experiments on ML-1M and Steam datasets with SASRec and BERT4Rec models show that DARTS significantly outperforms baseline attacks like Random Attack, Explicit Boosting, and A-ra, achieving exposure rates (ER@10) above 0.99 even with as few as 0.05-0.1% malicious clients. The authors also propose a mixed-RFA defense mechanism that combines weighted averaging and geometric median to mitigate attacks, demonstrating effectiveness at low malicious client ratios but reduced protection at higher ratios. Ablation studies confirm that both the explicit and implicit strategies are critical to the attack's success.

## Method Summary
DARTS operates in federated sequential recommendation by having malicious clients generate poisoned gradients through two complementary strategies. The explicit strategy identifies the most vulnerable item in a user sequence via gradient magnitude analysis, then substitutes it with an adversarial item that is both cosine-similar to the perturbed embedding and maximizes the target item's prediction score. The implicit strategy uses contrastive learning, treating the target embedding as anchor, the mean of interacted embeddings as positive, and random non-interacted embeddings as negatives to increase embedding similarity. These gradients are combined and submitted to the server, which aggregates them using either FedAvg or a mixed-RFA defense that combines weighted averaging and geometric median. The framework is evaluated on ML-1M and Steam datasets with SASRec and BERT4Rec models under varying malicious client ratios.

## Key Results
- DARTS achieves ER@10 > 0.99 on ML-1M with only 0.05-0.1% malicious clients, outperforming baselines by 30-100x
- Explicit substitution strategy alone (S-FSR) underperforms full DARTS, confirming both explicit and implicit components are critical
- Mixed-RFA defense with λ=0.3 effectively reduces ER at 0.05% malicious ratio but fails at 0.2% ratio
- SASRec (unidirectional) is significantly more vulnerable than BERT4Rec (bidirectional) under the same attack budget

## Why This Works (Mechanism)

### Mechanism 1
Replacing a single strategically-chosen item in a user sequence can significantly increase the target item's predicted score. The substitution algorithm computes gradients of the cross-entropy loss w.r.t. input embeddings to identify the most vulnerable item (highest gradient magnitude), then replaces it with an adversarial item that (a) is cosine-similar to the perturbed embedding and (b) maximizes the target item's prediction score among top-T candidates. This works because the gradient signal accurately reflects each item's influence on the target prediction, and candidate items with high post-perturbation similarity exist in the item catalog.

### Mechanism 2
Contrastive learning between target-item embeddings and interacted-item embeddings amplifies targeted promotion beyond explicit substitution alone. By treating the target embedding as anchor, mean of interacted embeddings as positive, and sampled non-interacted embeddings as negatives, the InfoNCE-style cross-entropy loss increases similarity between target and interacted representations. This indirectly boosts the target's score during federated aggregation because embedding proximity learned via contrastive loss transfers to higher recommendation scores after gradient aggregation.

### Mechanism 3
Model architecture strongly affects vulnerability: unidirectional attention models (SASRec) are more susceptible than bidirectional models (BERT4Rec) under the same attack budget. Bidirectional context enables the model to reconstruct or downweight local perturbations using both past and future tokens, reducing impact of a single substituted item. This observed robustness gap suggests that bidirectional models have superior capacity to mitigate inaccuracies through context reconstruction.

## Foundational Learning

- **Federated averaging (FedAvg) gradient aggregation**: Needed to understand how DARTS poisoned gradients survive aggregation and influence the global model. Quick check: Can you sketch how weighted averaging of client gradients updates the global model, and why small malicious fractions can still dominate if gradients are amplified?
- **Attention-based sequential recommendation (Transformer decoders, causal vs bidirectional)**: Needed to understand where attention concentrates and how substitution effectiveness varies by position. Quick check: For a given target position, does the model attend more to recent vs distant items, and how would that change which item is "most vulnerable"?
- **Contrastive learning objectives (InfoNCE-style)**: Needed to understand how the implicit strategy manipulates embedding geometry to boost target scores. Quick check: If you increase similarity between anchor and positive while pushing negatives away, what happens to downstream cosine-similarity-based scoring?

## Architecture Onboarding

- **Component map**: Local sequence → embedding → forward pass → gradient w.r.t. embeddings → vulnerability ranking → constrained substitution → BCE loss L_attack → poisoned gradients (explicit path). Same embedding layer → contrastive sampling (anchor/positive/negatives) → L_con → combined L_total → poisoned gradients (implicit path). Server path: FedAvg or mixed-RFA aggregation → global model update.
- **Critical path**: The gradient w.r.t. input embeddings (Δx) drives both vulnerability identification and the embedding-space perturbation that informs substitution; any change breaking differentiability here disables the explicit view.
- **Design tradeoffs**: Substitution constrained by cosine similarity τ preserves plausibility but limits candidate pool; relaxing τ may improve attack success but risk detectability. Contrastive negative sample count (P) controls gradient variance; too few → noisy direction; too many → compute cost. Mixed-RFA λ balances robustness (GM term) vs utility (average term); low λ favors robustness but may hurt benign performance.
- **Failure signatures**: ER@10 remains near zero despite 0.1-0.5% malicious clients (likely model is bidirectional or aggregation is robust). HR@10 drops sharply while ER increases (attack overtly distorts ranking, potentially triggering detection). Substitution finds no candidates above τ (item catalog lacks semantically similar items).
- **First 3 experiments**: 1) Reproduce baseline vs DARTS on SASRec with ML-1M at 0.1% malicious clients; log ER@5/10/20 and HR@10 to validate paper's numbers. 2) Ablate implicit component: run S-FSR (no contrastive loss) under same conditions; expect reduced ER per Table 5. 3) Test mixed-RFA defense at λ=0.3 with 0.05% and 0.2% malicious clients; confirm near-zero ER at 0.05% and breakdown at 0.2% as reported.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can model-specific attack strategies be further developed to target the unique architectures of diverse sequential recommenders? Basis: The conclusion explicitly states the aspiration to "stimulate deeper investigations into model-specific attack strategies tailored for federated recommendation platforms." Why unresolved: While DARTS is effective, the authors frame the current work as a general baseline for FSR attacks rather than an exhaustive exploration of architecture-specific vulnerabilities.

- **Open Question 2**: How can defense mechanisms be enhanced to maintain robustness when malicious client ratios exceed the low thresholds currently tested? Basis: The paper notes that the mixed-RFA defense fails at a 0.2% malicious ratio and that defenses may "struggle" when "substantial" user data is compromised. Why unresolved: The proposed defense is effective only at very low ratios (e.g., 0.05-0.1%), creating a vulnerability window when attackers control slightly larger fractions of the user base.

- **Open Question 3**: Does the bidirectional architecture consistently confer robustness against dual-view attacks in other sequential recommendation models? Basis: The authors observe that BERT4Rec exhibits superior resilience compared to SASRec due to its "inherent bidirectional architecture," but do not test if this applies generally. Why unresolved: The comparison is limited to two specific models (SASRec and BERT4Rec), leaving it unclear if the robustness is a fundamental property of bidirectionality or specific to BERT4Rec's implementation.

## Limitations

- Attack effectiveness hinges on single-item substitution without exploring whether multiple substitutions or sequential attacks would amplify success further
- Mixed-RFA defense is effective only at very low malicious client ratios (<0.2%) and lacks scalability to higher attack intensities
- Model architecture-driven robustness claims (SASRec vs BERT4Rec) are based on limited testing and may not generalize to other architectures or datasets

## Confidence

- **High**: The explicit substitution strategy's effectiveness (gradient-based vulnerability identification and constrained replacement) is well-supported by algorithm details and ablation results
- **Medium**: The implicit contrastive learning contribution is demonstrated via ablation (S-FSR vs full DARTS) but lacks external validation or comparison with other contrastive mechanisms
- **Low**: The generalizability of architecture-driven robustness claims (SASRec vs BERT4Rec) is limited by lack of external replication or broader architectural testing

## Next Checks

1. **Architecture robustness replication**: Test DARTS against a third sequential model (e.g., GRU4Rec) with varying sequence lengths and attention mechanisms to verify if unidirectional models remain consistently more vulnerable than bidirectional ones
2. **Defense scalability test**: Implement and compare mixed-RFA with coordinate-wise median and Krum aggregation under increasing malicious client ratios (0.1%, 0.5%, 1%, 2%) to assess relative robustness and scalability
3. **Substitute pool analysis**: Systematically vary the similarity threshold τ and top-T candidate size to quantify the trade-off between substitution plausibility and attack success rate, identifying the optimal balance for practical deployment