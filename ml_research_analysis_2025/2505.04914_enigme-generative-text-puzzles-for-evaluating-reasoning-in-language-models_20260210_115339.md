---
ver: rpa2
title: 'Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models'
arxiv_id: '2505.04914'
source_url: https://arxiv.org/abs/2505.04914
tags:
- reasoning
- language
- these
- puzzles
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces enigme, an open-source library for generating
  text-based puzzles to evaluate reasoning capabilities in transformer-decoder language
  models. The author identifies a critical gap in current LLM evaluation: existing
  benchmarks often test memorization rather than genuine reasoning, and they fail
  to probe the architectural limitations of these models.'
---

# Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models

## Quick Facts
- arXiv ID: 2505.04914
- Source URL: https://arxiv.org/abs/2505.04914
- Authors: John Hawkins
- Reference count: 30
- Primary result: Introduces enigme library generating text puzzles to evaluate reasoning beyond memorization in LLMs

## Executive Summary
This paper introduces enigme, an open-source library for generating text-based puzzles to evaluate reasoning capabilities in transformer-decoder language models. The author identifies a critical gap in current LLM evaluation: existing benchmarks often test memorization rather than genuine reasoning, and they fail to probe the architectural limitations of these models. To address this, the paper proposes a systematic approach to designing reasoning tasks based on the latent variable structure of transformers, focusing on patterns that require 2D visualization and physical-world reasoning beyond simple sequential token processing.

## Method Summary
The enigme library generates three categories of puzzles—numeric, sequence, and physics—each with increasing complexity through dimensionality parameters. These puzzles are designed to challenge models' abilities in pattern recognition, world-model building, and naive physics reasoning. The generation process is template-based with parameter control, allowing for an estimated 10^6 to 10^62 possible variations per category. The paper demonstrates that these puzzles can test reasoning abilities that go beyond template matching, addressing limitations in current LLM evaluation methods. The open-source enigme application is available on PyPI and GitHub, providing researchers with a tool to benchmark reasoning capabilities in LLMs and future AI architectures.

## Key Results
- Introduces template-based procedural generation with 10^6 to 10^62 variations per puzzle category
- Proposes puzzles requiring 2D visualization and 3D pattern interpretation to test transformer architectural limitations
- Physics puzzles demand naive physics reasoning to test world-model building capabilities
- Available as open-source Python package with CLI interface for generating reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task design informed by transformer architectural constraints can reveal genuine reasoning limitations versus memorization.
- Mechanism: Transformers process tokens through parallel attention mechanisms combined with positional embeddings that encode sequential structure. By designing puzzles where the solution requires interpreting text as 2D spatial arrangements or 3D pattern slices (rather than sequential token relationships), the tasks expose whether models can construct internal representations beyond their sequential bias.
- Core assumption: The latent variable space learned by transformers has structural limitations that systematically affect certain types of reasoning.
- Evidence anchors:
  - [abstract]: "Consideration of the latent variable structure of transformer-decoder models allows us to design reasoning tasks that should probe the boundary of their capacity to reason."
  - [section I.A]: "The patterns require visuualisation across 2 dimensions, and in some cases require abstraction by considering the text as slices of a 3d pattern."
  - [corpus]: Related work (Gendron et al., cited as [27]) confirms LLMs perform poorly on visual tasks converted to text-based patterns, supporting the architectural constraint hypothesis.

### Mechanism 2
- Claim: Procedural generation with extreme variation counts (10^6 to 10^62) prevents memorization-based solutions that plague static benchmarks.
- Mechanism: Template-based generation with randomized parameters creates sufficiently large solution spaces that memorization becomes computationally infeasible. Each puzzle instance is novel while maintaining structural similarity, allowing controlled evaluation of generalization.
- Core assumption: Memorization requires repeated exposure to specific patterns; sufficiently large variation spaces exceed models' capacity to store solution templates.
- Evidence anchors:
  - [section I]: "The evaluation of logical reasoning can be broken into different modes... Even on these ideal tasks, it appears that performance can depend on arbitrary factors like the order in which premises are presented, supporting the idea that what is happening is template matching as opposed to genuine reasoning."
  - [Table I]: Numeric puzzles offer up to 4.8×10^9 variations; sequence puzzles up to 2.3×10^62 variations.
  - [corpus]: Sudoku-Bench (arXiv:2505.16135) similarly addresses memorization in reasoning benchmarks, suggesting this is a recognized problem across evaluation approaches.

### Mechanism 3
- Claim: Physics-based puzzles test "naive physics" world-model building, probing whether models can infer physical rules from limited examples.
- Mechanism: Physics puzzles present ASCII sequences depicting object behavior (momentum, collision, boundary interactions). Solving requires abductive inference of underlying physical rules and extrapolation to novel states—capabilities distinct from pattern matching.
- Core assumption: Genuine reasoning requires constructing internal world models that support counterfactual prediction, not just statistical pattern completion.
- Evidence anchors:
  - [section II]: "These puzzles demand a form of naive physics reasoning that we hypothesize is essential to inference of a world model from data."
  - [section I.A]: "Our tasks are all built around pattern recognition and reasoning tasks that should emulate simple world-model building, the formation of abstractions that are manipulated mentally and intuitive physics reasoning."

## Foundational Learning

- Concept: **Transformer latent variable structure**
  - Why needed here: The paper's entire hypothesis rests on designing tasks that expose limitations in how attention mechanisms and positional embeddings encode information.
  - Quick check question: Can you explain why pure sequential token processing struggles with 2D spatial relationships encoded in text?

- Concept: **Abductive reasoning (inference to best explanation)**
  - Why needed here: Sequence and physics puzzles require inferring minimal rules from sparse examples—understanding this reasoning mode helps interpret what successful puzzle-solving indicates.
  - Quick check question: How does abduction differ from deduction when identifying patterns in limited example sequences?

- Concept: **Template-based procedural generation**
  - Why needed here: Understanding how parameterized templates enable controlled variation is essential for extending the library or designing comparable evaluation frameworks.
  - Quick check question: What tradeoffs exist between template rigidity (ensuring solvability) and variation diversity (preventing memorization)?

## Architecture Onboarding

- Component map:
  - Puzzle generators (3 classes): numeric -> sequence -> physics—each with dimensionality parameters (1d, 2d, 3d)
  - Template engine: Parameterized text substitution with controlled randomization
  - Solution validator: Programmatic verification (ground truth generated alongside puzzles)
  - CLI interface: PyPI package with commands like enigme numeric 2d

- Critical path:
  1. Define puzzle class and dimensionality → 2. Initialize random parameters from predetermined distributions → 3. Generate structure (data object with background/foreground characters) → 4. Apply transformation rules → 5. Output puzzle + solution key

- Design tradeoffs:
  - ASCII-only format limits expressiveness but ensures text-only LLM compatibility
  - Template-based generation guarantees solvability but may constrain pattern diversity
  - Extreme variation counts (10^62) provide theoretical memorization protection but practical testing uses subsets

- Failure signatures:
  - Models showing high variance on isomorphic problems (same structure, different surface features) suggests template-matching rather than reasoning
  - Performance collapses when premise order changes (observed in prior work, cited as [26])
  - Success on sequence puzzles but failure on physics puzzles may indicate pattern recognition without world-model construction

- First 3 experiments:
  1. Baseline establishment: Run multiple LLM families (different architectures/sizes) on all three puzzle classes across dimensionalities to identify systematic performance gaps.
  2. Memorization probe: Generate puzzles with identical structure but surface variation (different characters, same rules); measure performance consistency to detect template-matching behavior.
  3. Transfer test: Train/fine-tune models on one dimension level, evaluate on higher dimensions to assess whether learned rules generalize or remain surface-bound.

## Open Questions the Paper Calls Out
None

## Limitations
- Direct empirical validation missing: The paper establishes theoretical foundation but lacks comprehensive experimental results showing how LLMs actually perform on these puzzles.
- Physics puzzle complexity underspecified: Specific physical rules, their complexity levels, and scaling with dimensionality are not detailed.
- Variation count theoretical vs practical: Extremely large variation counts are based on combinatorial calculations but need empirical validation of their effectiveness in preventing memorization.

## Confidence
- **High confidence**: The theoretical framework linking transformer architecture to reasoning limitations is well-established in the literature.
- **Medium confidence**: The claim that 2D/3D pattern puzzles can reveal genuine reasoning versus memorization is plausible but requires empirical validation.
- **Low confidence**: The assertion that physics puzzles specifically test "naive physics" world-model building is weakly supported without detailed specifications and systematic evaluation.

## Next Checks
1. Benchmark LLM performance: Run comprehensive evaluations across multiple LLM architectures (GPT, Claude, Llama variants) on all three puzzle categories and dimensionalities.
2. Transfer learning experiments: Train models on lower-dimensional puzzles and test their ability to generalize to higher dimensions.
3. Ablation study on variation counts: Systematically reduce variation counts while maintaining puzzle solvability to find the threshold where memorization becomes feasible.