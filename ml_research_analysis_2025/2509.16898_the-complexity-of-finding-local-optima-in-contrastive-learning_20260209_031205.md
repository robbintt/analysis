---
ver: rpa2
title: The Complexity of Finding Local Optima in Contrastive Learning
arxiv_id: '2509.16898'
source_url: https://arxiv.org/abs/2509.16898
tags:
- local
- contrastive
- triplets
- learning
- triplet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper establishes that finding local optima in various contrastive
  learning objectives is computationally intractable, settling a fundamental question
  in optimization of these widely-used machine learning techniques. The core method
  involves constructing polynomial-time reductions from known hard problems (LocalMaxCut
  for discrete settings and QuadraticProgram-KKT for continuous settings) to contrastive
  learning objectives, proving PLS-hardness for triplet maximization problems and
  CLS-hardness for Triplet Loss minimization.
---

# The Complexity of Finding Local Optima in Contrastive Learning

## Quick Facts
- **arXiv ID**: 2509.16898
- **Source URL**: https://arxiv.org/abs/2509.16898
- **Reference count**: 40
- **Primary result**: Finding local optima in various contrastive learning objectives is computationally intractable, establishing PLS-hardness for triplet maximization and CLS-hardness for Triplet Loss minimization.

## Executive Summary
This paper establishes that finding local optima in contrastive learning objectives is computationally intractable, proving PLS-hardness for triplet maximization problems and CLS-hardness for Triplet Loss minimization. The authors construct polynomial-time reductions from known hard problems (LocalMaxCut and QuadraticProgram-KKT) to contrastive learning objectives, showing that no polynomial-time algorithm can find local optima unless PLS ⊆ P or CLS ⊆ P. Experimental validation confirms that instances created through these reductions exhibit exponential slow convergence behavior, matching the theoretical predictions.

## Method Summary
The paper employs gadget-based complexity reductions to encode hard optimization problems within contrastive learning objectives. For discrete objectives, LocalMaxCut instances are transformed into triplet maximization problems using boundary and structure constraints with hierarchical weights. For continuous objectives, quadratic programs are encoded through carefully constructed triplet collections where the Triplet Loss gradient matches the original quadratic's gradient. The reductions preserve local optimality structure, ensuring that local optima in the transformed problem correspond to local optima in the original.

## Key Results
- Contrastive triplet maximization problems are PLS-hard, inheriting local search complexity from LocalMaxCut
- Triplet Loss minimization is CLS-hard, as it can simulate arbitrary quadratic programs
- Even if PLS ⊆ P or CLS ⊆ P, certain instances require exponential time for local search algorithms to converge
- Experimental validation shows hard instances exhibit exactly the same exponential slow convergence across different contrastive learning formulations

## Why This Works (Mechanism)

### Mechanism 1: PLS-Reduction via Gadget Construction for Discrete Objectives
The reduction constructs boundary points with heavy-weight constraints (M > W, where W is total edge weight) that force non-boundary points into specific geometric regions, encoding a graph cut. Type A constraints (edge triplets) map graph edges to contrastive constraints. Type B constraints with dominating weights ensure local optima must satisfy the boundary structure. Local improvements in the embedding correspond exactly to vertex flips improving the cut value. Core assumption: PLS ⊈ P. Break condition: If PLS ⊆ P, or if weight hierarchy fails (M ≤ Σ edge weights), boundary constraints become negotiable and the encoding breaks.

### Mechanism 2: CLS-Reduction via Quadratic Program Encoding
Decompose quadratic form into triples of variables. For each triple (x, y, z), construct 12 weighted contrastive triplets (including duals) whose combined loss gradient matches the quadratic's gradient. Cross-term dependencies create interacting constraints resolved by solving a linear system for weights. Pivot points A=0, B=1/2 prevent trivial solutions (all-zeros embedding). Core assumption: CLS ⊈ P; margin α = 1 ensures loss function is active on [0,1]³ domain. Break condition: If margin α doesn't satisfy (ai − aj)² − (ai − ak)² + 1 ≥ 0 for all valid triplets, or if the linear system for weights has no feasible solution.

### Mechanism 3: Exponential Convergence via Structure-Preserving Transformations
Monien-Tscheuschner graphs have a specific exponential path from certain initial cuts to any local optimum. The PLS-reductions preserve not just computational equivalence but the exact sequence of improving moves because gadget constraints maintain the same objective improvement structure (edge constraint satisfaction maps to cut improvement). Core assumption: Local search initialized from specific adversarial configurations. Break condition: Random initialization — experiments show quick convergence from random starts, suggesting hard instances are initialization-sensitive.

## Foundational Learning

- **Concept: PLS (Polynomial Local Search) Complexity Class**
  - Why needed here: Establishes that "verifying local optimality is easy" ≠ "finding local optimum is easy." PLS captures problems with poly-time neighbor checking but potentially hard fixed-point computation.
  - Quick check question: If you can verify in polynomial time that no single-vertex flip improves a cut, does that guarantee you can find such a cut in polynomial time?

- **Concept: Gadget-Based Complexity Reductions**
  - Why needed here: The entire proof strategy encodes one hard problem inside another while preserving the *local* (not global) optimality structure — this differs from standard NP-reductions.
  - Quick check question: In the d=1 reduction, if weight M ≤ W (total edge weight), what happens to the boundary constraint guarantees?

- **Concept: KKT Stationary Points vs. Local Minima**
  - Why needed here: For continuous CLS-hardness, "local optimum" means first-order stationary points (fixed points of gradient descent), not necessarily local minima.
  - Quick check question: Why does the Triplet Loss reduction require *two* pivot points (A, B) rather than one? What trivial solutions emerge with fewer pivots?

## Architecture Onboarding

- **Component map:**
  ```
  LocalMaxCut → [Type A: Edge triplets (u, X+, v−)] → Contrastive Instance
               [Type B: Boundary triplets, weight M]
               [Type C: Structure triplets, d>2]
  
  QuadraticProgram → [12 triplets per 3 vars] → Triplet Loss Instance
                    [Linear system for weights]
                    [Pivot constraints A, B]
  ```

- **Critical path:**
  1. Weight hierarchy selection: M₃ > M₄ > ... > M > Σ edge weights (ensures boundary constraints dominate)
  2. Gadget construction: Place boundary points, encode edges, add structure constraints
  3. Local optimality correspondence proof: Show any local optimum of gadget maps to local optimum of original problem

- **Design tradeoffs:**
  - Higher weights M → stronger enforcement but numerical instability in floating-point
  - More dimensions d → simpler gadgets (equilateral simplices) but larger instance size
  - d=1 → minimal instance but requires reflection segments (Y′Z′) for encoding

- **Failure signatures:**
  - Quick convergence from random init → easy instance or local optimum not encoding full problem
  - Type B constraints violated in "local optimum" → M insufficient or stuck in spurious basin
  - Gradient oscillation without progress → cycling near non-optimal KKT point boundary

- **First 3 experiments:**
  1. Reproduce exponential scaling: Generate Monien-Tscheuschner LocalMaxCut instances (n=37 to 429), reduce to LocalContrastive-Euclidean-1D, measure iterations vs. n. Expected: exponential growth matching Table 1 (63 to 1.7M iterations).
  2. Validate move-sequence preservation: Log which triplet becomes satisfied/unsatisfied at each iteration. Verify sequence matches the original LocalMaxCut flip sequence exactly.
  3. Quantify initialization sensitivity: For each hard instance, run 100 trials from random initial embeddings. Compare iteration counts to adversarial initialization. Hypothesis: random init converges orders of magnitude faster, confirming worst-case hardness is initialization-dependent.

## Open Questions the Paper Calls Out

- **Open Question 1**: Are the worst-case hardness results for finding local optima in contrastive learning persistent in the average case, or do randomly generated instances admit efficient local search algorithms?
  - Basis in paper: [explicit] "The main interesting future direction is to examine whether our negative results are persistent in the average case."
  - Why unresolved: The paper proves PLS/CLS-hardness via worst-case constructions, but empirical observation notes random configurations usually converge quickly, suggesting a gap between worst-case and average-case behavior.
  - What evidence would resolve it: A theoretical characterization of average-case complexity for natural random triplet distributions, or empirical studies across diverse random instance families demonstrating polynomial convergence with high probability.

- **Open Question 2**: Can random initialization or other specific initialization strategies generally avoid the exponential convergence time observed in worst-case instances?
  - Basis in paper: [explicit] "Understanding whether random initialization (or other strategies) is generally sufficient to avoid such worst-case dynamics remains an open question."
  - Why unresolved: Experiments show hard instances are sensitive to starting point, but no theoretical guarantees exist for whether principled initialization schemes provably avoid worst-case behavior.
  - What evidence would resolve it: Provable bounds showing that random initialization leads to polynomial-time convergence with high probability over reasonable instance distributions.

- **Open Question 3**: Does smoothed analysis apply to contrastive learning objectives, where small random perturbations to input data yield improved local search guarantees?
  - Basis in paper: [explicit] "Another interesting perspective to study for contrastive objectives, is so-called smoothed analysis (Spielman and Teng, 2009), where the input data are slightly perturbed by random noise, and many algorithms... seem to get much better guarantees compared to worst-case inputs."
  - Why unresolved: Smoothed analysis has improved understanding of algorithms like Simplex, but has not been studied for contrastive learning objectives.
  - What evidence would resolve it: Theoretical bounds on expected convergence time under smoothed input models, or counterexamples showing hardness persists even under perturbation.

- **Open Question 4**: What is the quality gap between local optima and global optima in contrastive learning objectives, and can this gap be bounded?
  - Basis in paper: [explicit] "An important future direction is to argue about the quality of local solutions."
  - Why unresolved: The paper focuses on computational complexity of finding any local optimum, not on approximation guarantees relative to global optima.
  - What evidence would resolve it: Approximation ratios showing local optima achieve bounded multiplicative or additive guarantees versus global optima, or hardness of approximation results for local solutions.

## Limitations

- The reductions rely on specific adversarial initializations — exponential convergence only occurs from carefully chosen starting points, while random initialization converges quickly
- The complexity reductions assume infinite precision arithmetic; numerical stability with floating-point weights M and M' remains unverified
- The Monien-Tscheuschner hard instances are referenced but not fully specified in the paper, requiring reconstruction from external sources

## Confidence

- **High Confidence**: PLS-hardness of triplet maximization (Section 3.1) — the reduction is explicit with verifiable weight hierarchies and correspondence proofs
- **Medium Confidence**: CLS-hardness of Triplet Loss minimization (Section 4) — the 12-triplet construction per quadratic term is novel and technically complex, with potential edge cases in weight feasibility
- **Low Confidence**: Practical implications — while theoretical hardness is proven, the initialization sensitivity suggests real-world instances may be much easier than worst-case bounds indicate

## Next Checks

1. **Numerical Precision Validation**: Re-implement the d=1 reduction with floating-point weights M and M' at varying magnitudes. Test whether boundary constraints remain satisfied within tolerance and whether local optima still encode the original problem correctly
2. **Randomization Robustness Test**: For each hard instance, run 100 trials with random initial embeddings. Measure iteration distributions and compare to adversarial initialization. Quantify the gap between worst-case and average-case behavior
3. **Weight Hierarchy Sensitivity**: Systematically vary the ratio M/(Σ edge weights) in the d=1 reduction. Identify the minimum threshold where boundary constraints fail and local optima no longer correspond to valid graph cuts