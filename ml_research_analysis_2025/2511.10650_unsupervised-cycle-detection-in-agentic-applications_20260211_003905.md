---
ver: rpa2
title: Unsupervised Cycle Detection in Agentic Applications
arxiv_id: '2511.10650'
source_url: https://arxiv.org/abs/2511.10650
tags:
- cycle
- agentic
- call
- agent
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of detecting hidden execution cycles
  in agentic applications powered by LLMs, which silently consume resources without
  triggering explicit errors. The authors propose an unsupervised framework combining
  structural and semantic analysis.
---

# Unsupervised Cycle Detection in Agentic Applications

## Quick Facts
- **arXiv ID:** 2511.10650
- **Source URL:** https://arxiv.org/abs/2511.10650
- **Reference count:** 13
- **Primary result:** Unsupervised hybrid framework combining structural and semantic analysis achieves F1 score of 0.72 for detecting hidden execution cycles in agentic systems

## Executive Summary
This paper addresses the critical problem of detecting hidden execution cycles in agentic applications powered by LLMs, which silently consume resources without triggering explicit errors. The authors propose an unsupervised framework that combines structural analysis of call stack patterns with semantic analysis of output similarity. Evaluated on 1,575 trajectories from a LangGraph-based stock market application, the hybrid approach significantly outperforms individual structural (F1: 0.08) and semantic methods (F1: 0.28), demonstrating the effectiveness of combining structural and semantic cues for detecting both explicit and hidden cycles in agentic systems.

## Method Summary
The unsupervised framework detects bad cycles through a hybrid approach: first applying CDCS to identify statistically significant repeating subsequences in temporal call stack sequences (frequency > μ + k·σ), then confirming candidates using CDSA to measure cosine similarity between sibling node outputs (threshold > φ). The method processes agent execution trajectories as spans with trace_id, span_id, parent_span_id, operation, input, and output fields. The hybrid pipeline achieves computational efficiency by using the structural method as a first-pass filter before applying the more expensive semantic analysis only to candidate cycles.

## Key Results
- Hybrid approach achieves F1 score of 0.72 (precision: 0.62, recall: 0.86) on 1,575 trajectories
- Structural methods alone (CDDAG, CDCS) achieve poor performance (F1: 0.08)
- Semantic similarity alone (CDSA) achieves moderate performance (F1: 0.28)
- Method effectively detects both explicit loops and hidden cycles with redundant content generation

## Why This Works (Mechanism)

### Mechanism 1: Structural Pattern Detection via Temporal Call Stack Analysis
The approach converts trajectories into ordered call stack sequences and identifies contiguous subsequences appearing multiple times. A subsequence S is classified as cyclic if its frequency w(S) > μ + k·σ, where μ and σ are computed from the frequency distribution of all subsequences. This captures explicit repetitive patterns in execution flow. The method assumes bad cycles manifest as statistically abnormal repetition frequencies distinct from normal operational patterns.

### Mechanism 2: Semantic Redundancy Detection via Sibling Node Similarity
Computes cosine similarity between output embeddings of sibling nodes (nodes sharing the same parent) in the DAG. If similarity exceeds threshold φ, the subgraph is flagged as exhibiting a bad cycle. Restricting comparisons to siblings reduces computational cost from O(n²) to O(log(n)²). The method assumes information flowing upward from leaves to parents means highly similar sibling outputs likely yield similar ancestors, indicating lack of progressive value creation.

### Mechanism 3: Hybrid Multi-Stage Confirmation
Combines structural detection with semantic confirmation to achieve higher precision than either approach alone by filtering false positives. First applies computationally efficient call stack analysis (CDCS) to identify candidate cycles with high recall. Then applies semantic similarity analysis only to detected candidates to confirm repetitive content, rejecting cases where structural repetition serves legitimate purposes. The method assumes bad cycles require both structural repetition AND semantic redundancy.

## Foundational Learning

- **Concept: Observability in Distributed Systems**
  - **Why needed here:** Understanding how traces, spans, and parent-child relationships form the data model for agentic trajectory analysis
  - **Quick check question:** Can you explain the relationship between trace_id, span_id, and parent_span_id in a distributed trace?

- **Concept: Statistical Anomaly Detection**
  - **Why needed here:** The threshold mechanism (μ + k·σ) relies on understanding how statistical outliers are identified in frequency distributions
  - **Quick check question:** If you increase parameter k from 0.5 to 1.5, would you expect precision to increase or decrease, and why?

- **Concept: Semantic Embeddings and Similarity Metrics**
  - **Why needed here:** The semantic component uses vector embeddings and cosine similarity to measure content redundancy between spans
  - **Quick check question:** Why might cosine similarity on raw embeddings fail to distinguish numerical time-series data from different companies?

## Architecture Onboarding

- **Component map:** Data Layer (Trajectory collector → Span storage) -> Structural Analyzer (CDDAG + CDCS) -> Semantic Analyzer (Embedding generator + sibling similarity) -> Orchestrator (Hybrid pipeline) -> Output (Binary classification)
- **Critical path:** 1) Ingest trajectory spans and construct DAG representation 2) Build temporal call stack sequence ordered by creation time 3) Run CDCS with threshold μ + 0.5·σ to identify candidate cycles 4) For each candidate, compute semantic similarity between sibling outputs 5) Apply semantic threshold s > 0.83 for final confirmation 6) Return classification with identified cyclic subgraphs
- **Design tradeoffs:** Threshold selection affects precision-recall tradeoff; embedding model choice impacts semantic analysis; sibling-only comparison reduces computation but may miss patterns; unsupervised approach avoids training data but may underperform supervised alternatives
- **Failure signatures:** High false positives on stock time-series data (cosine similarity issues); missed cycles with different arguments (structural methods fail); parameter sensitivity causes large swings in performance
- **First 3 experiments:** 1) Baseline validation: Run all four methods on 100 held-out trajectories with manual labels 2) Threshold sensitivity analysis: Vary k from 0.2 to 1.5 and s from 0.80 to 0.90 to generate precision-recall curves 3) Domain transfer test: Apply framework to different agentic application (not stock market) with 200+ trajectories

## Open Questions the Paper Calls Out

**Open Question 1:** How can semantic similarity analysis be modified to effectively distinguish between distinct numerical time-series data in agentic outputs? The current approach using cosine similarity on numerical JSON data produces high false positives, failing to capture mathematical differences between time-series.

**Open Question 2:** Does the hybrid framework maintain high detection performance across diverse agentic architectures and LLM providers? The reported F1 score of 0.72 is derived exclusively from 1,575 trajectories of a single LangGraph-based stock market application, raising questions about generalizability.

**Open Question 3:** Can the detection framework be adapted for real-time intervention to terminate cycles before they exhaust resources? While the paper defines the problem as resource wastage and mentions future "real-time" integration, the current methodology analyzes complete trajectories post-hoc.

## Limitations
- Structural methods struggle with legitimate repetitive patterns and numerical time-series data
- Semantic similarity approach shows significant domain dependency and fails on numerical outputs
- Hybrid threshold tuning complexity with conflicting values reported and no clear combination logic

## Confidence

**High Confidence Claims:**
- Hybrid approach significantly outperforms individual structural and semantic methods
- Methodology effectively detects both explicit and hidden cycles in agentic systems
- Computational efficiency of CDCS as first-pass filter is validated

**Medium Confidence Claims:**
- Unsupervised framework's general applicability across different agentic applications
- Specific threshold values as optimal for all domains
- Assumption that structural repetition plus semantic redundancy is necessary and sufficient for bad cycle detection

**Low Confidence Claims:**
- Performance in domains outside the stock market application
- Scalability to applications with significantly larger or more complex trajectory graphs
- Robustness to variations in span representation and agent architecture patterns

## Next Checks
1. **Cross-domain transferability test:** Apply the framework to a non-financial agentic application (e.g., customer service chatbot or code generation system) with 200+ trajectories. Compare F1 scores against the reported 0.72 baseline and identify domain-specific failure modes.

2. **Parameter sensitivity analysis:** Systematically vary k (0.2→1.5) and s (0.80→0.90) parameters across the full dataset to generate precision-recall curves. Identify the stability region where performance remains robust and determine if optimal parameters differ significantly from reported values.

3. **Time-series adaptation experiment:** Implement a specialized numerical similarity metric for stock time-series data and compare against cosine similarity. Measure reduction in false positives specifically for financial trajectories and evaluate whether hybrid performance improves when using domain-appropriate semantic measures.