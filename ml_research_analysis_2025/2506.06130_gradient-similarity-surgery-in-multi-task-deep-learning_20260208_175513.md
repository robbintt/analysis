---
ver: rpa2
title: Gradient Similarity Surgery in Multi-Task Deep Learning
arxiv_id: '2506.06130'
source_url: https://arxiv.org/abs/2506.06130
tags:
- gradient
- learning
- sam-gs
- tasks
- multi-task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of conflicting gradients in multi-task
  deep learning, where gradients from different tasks with varying magnitudes or directions
  interfere with each other during optimization. The authors propose SAM-GS (Similarity-Aware
  Momentum Gradient Surgery), a novel gradient surgery method that uses a gradient
  magnitude similarity measure to detect conflicts and adaptively modulate gradient
  updates.
---

# Gradient Similarity Surgery in Multi-Task Deep Learning

## Quick Facts
- arXiv ID: 2506.06130
- Source URL: https://arxiv.org/abs/2506.06130
- Reference count: 40
- Primary result: SAM-GS achieves lower mean ranking and better task balance than state-of-the-art methods on multi-task problems, especially with more than two tasks.

## Executive Summary
This paper introduces SAM-GS (Similarity-Aware Momentum Gradient Surgery), a novel gradient surgery method for multi-task deep learning that addresses gradient conflicts arising from varying task magnitudes. The method detects magnitude conflicts using a similarity measure and applies conditional gradient equalization, while using similarity-modulated momentum regularization to stabilize optimization. Experiments on synthetic problems and real-world benchmarks (CityScapes, NYU-v2, CelebA) demonstrate that SAM-GS achieves comparable or improved performance over state-of-the-art methods, particularly excelling in scenarios with more than two tasks.

## Method Summary
SAM-GS detects gradient conflicts by computing pairwise magnitude similarity between task gradients, aggregated as Ψ. When Ψ < γ (threshold), it applies gradient equalization to balance task contributions; otherwise, it modulates momentum influence based on similarity. The method maintains task-specific momentum estimates and a running average of (1−Ψ)² to scale momentum regularization. This approach combines two mechanisms: momentum regularization for stable updates during high similarity, and gradient equalization to prevent domination by high-magnitude tasks. The method is implemented as a custom optimizer compatible with existing deep learning frameworks.

## Key Results
- SAM-GS achieves lower mean ranking (MR) than competing methods across multi-task benchmarks
- The method demonstrates superior task balance, with Δm% improvements over single-task baselines
- Performance is particularly strong in multi-task scenarios (>2 tasks) where traditional methods struggle with conflict resolution
- On CityScapes, SAM-GS shows degraded performance compared to angle-focused methods, attributed to inter-sample conflicts

## Why This Works (Mechanism)

### Mechanism 1: Gradient Magnitude Similarity for Conflict Detection
- Claim: Detecting magnitude disparities between task gradients identifies when one task will dominate optimization, enabling targeted intervention.
- Mechanism: Computes pairwise magnitude similarity ψ(gᵢ, gⱼ) = 2‖gᵢ‖₂‖gⱼ‖₂ / (‖gᵢ‖₂² + ‖gⱼ‖₂²), aggregated as Ψ across all task pairs. When Ψ < γ (threshold), magnitude conflict is declared and equalization triggers.
- Core assumption: Magnitude conflicts (not angle-based) are the primary cause of task domination in MTL; angle conflicts mainly slow convergence without preventing it.
- Evidence anchors:
  - [section 2.1]: "A magnitude gradient conflict occurs when the gradients associated with different tasks have significantly varying magnitudes. This imbalance can cause the model to prioritise certain tasks over others."
  - [section 4]: "SAM-GS ignores angle-based gradient conflicts and introduces two mechanisms: momentum regularisation and gradients equalisation."
  - [corpus]: Related work (Gradient Deconfliction via Orthogonal Projections) confirms conflicting gradients degrade MTL, though focuses on directional conflicts rather than magnitude.

### Mechanism 2: Conditional Gradient Equalization
- Claim: Equalizing gradient magnitudes when conflicts are detected produces a balanced update direction not dominated by any single task.
- Mechanism: When Ψ < γ, computes wₖ = ‖gₖ‖₂ / (‖gₖ‖₂²) · gₖ, normalizing each task's contribution before aggregation. The sum is then scaled by average magnitude to preserve step size.
- Core assumption: Equal magnitude contributions lead to fairer multi-task optimization; the average magnitude scaling prevents near-zero updates.
- Evidence anchors:
  - [section 4, Algorithm 1]: Lines 12-13 show the equalization formula triggered when Ψ < γ.
  - [Figure 1c]: Illustrates how magnitude conflict causes domination and how equalization corrects it.
  - [corpus]: Assumption—no direct corpus comparison of magnitude equalization vs. other conflict resolution strategies found.

### Mechanism 3: Similarity-Modulated Momentum Regularization
- Claim: Scaling momentum influence by gradient similarity enables conservative updates during conflict and accelerated learning during alignment.
- Mechanism: Maintains EMA hₜ of (1 − Ψ)². Momentum term mₖ,ₜ is divided by √ĥₜ + ε, so low similarity (high 1−Ψ) increases regularization, reducing momentum's influence. High similarity preserves momentum's full effect.
- Core assumption: Momentum is trustworthy when task gradients agree; during conflict, it should be dampened to avoid amplifying instability.
- Evidence anchors:
  - [section 4]: "ht acts as a regularisation term, where, if the gradients are dissimilar, the momentum is trusted less."
  - [Algorithm 1]: Line 15 shows wₖ = |cmₖ,ₜ| / (√bht + ε) when Ψ ≥ γ.
  - [corpus]: SAMO paper similarly modulates optimization based on task conflict detection, though uses sharpness-aware perturbation rather than momentum scaling.

## Foundational Learning

- Concept: Multi-task gradient conflict (angle vs. magnitude)
  - Why needed here: SAM-GS explicitly addresses magnitude conflicts while ignoring angle conflicts; understanding the distinction is essential for applying the method correctly.
  - Quick check question: Given two task gradients with cosine similarity −0.3 and magnitude ratio 10:1, which conflict type does SAM-GS respond to?

- Concept: Exponential Moving Average (EMA) for momentum
  - Why needed here: Both task momentum (mₖ,ₜ) and similarity coefficient (hₜ) use EMA with different β parameters; understanding decay rates is critical for hyperparameter tuning.
  - Quick check question: If β₁ = 0.9, approximately how many steps does it take for the momentum to reflect 50% of a sustained gradient change?

- Concept: Bias correction in Adam-family optimizers
  - Why needed here: Algorithm 1 applies bias correction (ĉmk,t, bht) to counteract initialization at zero; skipping this degrades early training.
  - Quick check question: Why does the bias correction term include (1 − βᵗ) in the denominator?

## Architecture Onboarding

- Component map:
  Input: K task losses {L₁...Lₖ} → compute per-task gradients gₖ → Similarity module: compute all pairwise ψ(gᵢ, gⱼ), aggregate to Ψ → Branch decision: Ψ < γ? → Equalization branch; else → Momentum regularization branch → Equalization branch: Normalize magnitudes, sum, scale by average → Momentum branch: Scale by similarity-modulated momentum term → Output: Aggregated update direction for parameter update

- Critical path:
  1. Gradient computation for all K tasks (must be batched efficiently)
  2. Pairwise magnitude similarity computation (O(K²) but K typically small)
  3. Threshold comparison and branch selection
  4. Weighted gradient aggregation

- Design tradeoffs:
  - γ threshold: Low γ → rare equalization, faster but may miss conflicts; high γ → frequent equalization, more stable but may over-flatten. Paper finds γ ≈ 0.9 works best across benchmarks.
  - β₁ vs. β₂: β₁ = 0.9 for gradient momentum (standard); β₂ = 0.9–0.99 for similarity coefficient—slower decay smooths similarity estimates.
  - Angle conflicts ignored: Reduces complexity but may underperform on datasets where inter-sample directional conflicts dominate (e.g., CityScapes per paper results).

- Failure signatures:
  - One task consistently outperforms others while rest stagnate → γ may be too high, or magnitude conflict not the root cause.
  - Training instability with oscillating losses → β₂ too low, causing hₜ to fluctuate rapidly.
  - No improvement over simple linear sum → check if Ψ is consistently high (tasks already balanced) or implementation error in similarity computation.

- First 3 experiments:
  1. Reproduce synthetic problem (Section 5.1) with varying initial points to verify conflict detection and trajectory behavior before real data.
  2. Ablation on γ ∈ {0, 0.1, 0.5, 0.9, 1.0} on NYU-v2 (3 tasks) to find dataset-specific threshold; log Ψ distribution to understand conflict frequency.
  3. Compare SAM-GS vs. LS+Adam baseline on CelebA (40 tasks) with identical architecture; if Δm% improvement < 2%, inspect per-task performance for imbalance patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can formal theoretical convergence guarantees be derived for the SAM-GS optimization method?
- Basis in paper: [explicit] The conclusion states, "Future work may include a theoretical analysis of convergence to provide optimisation guarantees."
- Why unresolved: The method is heuristic, relying on empirical validation without a formal mathematical proof that the gradient surgery operations (equalisation and momentum modulation) lead to stable convergence.
- What evidence would resolve it: A mathematical proof establishing convergence bounds under standard smoothness assumptions.

### Open Question 2
- Question: How can the method be improved to handle strict stationary states, specifically saddle points?
- Basis in paper: [explicit] The authors identify a need for "analysis of the current limitations to address strict stationary states such as saddle points, where task gradients have very similar magnitude and opposite directions."
- Why unresolved: SAM-GS relies on magnitude dissimilarity to trigger conflict resolution; saddle points, having similar magnitudes, may bypass this detection mechanism while still stalling optimization.
- What evidence would resolve it: An algorithmic extension capable of detecting and escaping saddle points, validated on synthetic landscapes designed to trap gradient-based methods.

### Open Question 3
- Question: Does the intentional exclusion of angle-based conflict resolution limit performance on specific datasets like CityScapes?
- Basis in paper: [inferred] In Section 5.2, the authors note inferior performance on CityScapes compared to angle-focused methods (Aligned-MTL), hypothesizing that "inter-sample conflicts [angle-based] are more relevant" in that context.
- Why unresolved: SAM-GS assumes magnitude conflicts are the "core difficulty" and ignores angle conflicts, but this trade-off appears to degrade performance in certain 2-task scenarios.
- What evidence would resolve it: A hybrid variant of SAM-GS that incorporates angle-awareness, showing improved performance on the CityScapes benchmark.

## Limitations
- The method shows degraded performance on CityScapes compared to baselines, attributed to inter-sample conflicts that SAM-GS does not address.
- The gradient equalization formula in Algorithm 1 appears inconsistent with the textual description, creating uncertainty about exact implementation.
- The claim about CityScapes performance being caused by inter-sample conflicts lacks systematic validation.

## Confidence
- **High confidence**: The core mechanism of using magnitude similarity for conflict detection and conditional equalization is well-specified and theoretically sound. The synthetic problem results clearly demonstrate the conflict detection capability.
- **Medium confidence**: The experimental methodology and hyperparameter settings are detailed enough for reproduction, though some ambiguities exist. The superiority on multi-task scenarios (>2 tasks) is supported by rankings but could benefit from deeper analysis of failure cases.
- **Low confidence**: The exact implementation of the gradient equalization branch due to the apparent discrepancy between Algorithm 1 and the text description. The claim about CityScapes performance being caused by inter-sample conflicts lacks systematic validation.

## Next Checks
1. Reproduce the synthetic problem (Section 5.1) with varying initial points to verify conflict detection and trajectory behavior before real data experiments.
2. Run an ablation study on NYU-v2 with γ ∈ {0, 0.1, 0.5, 0.9, 1.0} to determine dataset-specific threshold sensitivity and log Ψ distribution to understand conflict frequency patterns.
3. Implement the gradient equalization branch by testing both the Algorithm 1 formula and the textual description (scaled by average magnitude) to identify which version produces the reported results.