---
ver: rpa2
title: 'From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise
  Data'
arxiv_id: '2509.21324'
source_url: https://arxiv.org/abs/2509.21324
tags:
- data
- retrieval
- knowledge
- reasoning
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a five-level framework (L1-L5) for classifying
  Retrieval-Augmented Generation (RAG) systems by the complexity of data modalities
  and reasoning they support, from basic text retrieval (L1) to general intelligence
  (L5). It proposes structure-aware data representation, mixture of spaces, and adaptive
  chain of actions as core techniques for enabling L4 (reflective and reasoned knowledge)
  capabilities.
---

# From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data

## Quick Facts
- arXiv ID: 2509.21324
- Source URL: https://arxiv.org/abs/2509.21324
- Reference count: 4
- Primary result: L4 RAG system achieved 82.74% accuracy on DelucionQA, outperforming L1 and L2 systems by 18.91 and 12.54 percentage points respectively.

## Executive Summary
This paper introduces a five-level framework (L1-L5) for classifying Retrieval-Augmented Generation (RAG) systems by the complexity of data modalities and reasoning they support, from basic text retrieval (L1) to general intelligence (L5). The framework addresses the gap in RAG research where enterprise documents often contain mixed modalities (text, tables, diagrams) and require multi-step reasoning. The authors propose three core techniques—Structure-Aware Data Representation, Mixture of Spaces, and Adaptive Chain of Actions—to enable L4 (reflective and reasoned knowledge) capabilities. Evaluated across four datasets representing increasing complexity, the L4 system (Corvic AI) demonstrated significant accuracy improvements, particularly on complex reasoning tasks.

## Method Summary
The paper evaluates RAG systems on Question Answering across four enterprise datasets: DelucionQA (text-only, L1), FinTabNet (tables, L2), DMV Handbooks, and Architectural Manuals (L3/L4). The study compares three baseline systems (LangChain L1, Azure AI Search L2, OpenAI RAG L2) against a proprietary L4 system (Corvic AI). All systems use GPT-4.1 for final answer generation, isolating retrieval performance. The L4 system employs Structure-Aware Data Representation for parsing PDFs into enriched intermediate forms, Mixture of Spaces for multi-modal indexing, and Adaptive Chain of Actions for dynamic query planning. Evaluation uses the ragas library with gemini-2.0-flash as judge, measuring accuracy percentage.

## Key Results
- L4 system (Corvic AI) achieved 82.74% accuracy on DelucionQA, outperforming L1 (63.83%) by 18.91 percentage points
- On FinTabNet, L4 achieved 63.83% accuracy versus L2's 44.29%, demonstrating 19.54 percentage point improvement on table-based reasoning
- Performance gains increased with task complexity: L4 showed 9.68 percentage point advantage on DMV Handbooks and 13.66 on Architectural Manuals
- L4 system demonstrated increasing advantage as task complexity grew, validating the framework's progression

## Why This Works (Mechanism)

### Mechanism 1: Redundancy via Multi-Space Retrieval (Mixture of Spaces)
- Claim: If retrieval accuracy is bottlenecked by single-vector semantic similarity, then indexing data into multiple parallel spaces (semantic, structural, metadata) may improve recall by providing alternative retrieval pathways.
- Mechanism: The system constructs distinct indices for the same content. A query that fails to match in semantic space (e.g., specific terminology mismatch) might match via structural space (e.g., section hierarchy) or metadata space (e.g., title tags), allowing the retrieval logic to fall back or merge results from these diverse views.
- Core assumption: Relevant context is often signaled by non-semantic features (layout, hierarchy) that are lost in dense vector compression.
- Evidence anchors:
  - [section 4.2] "The Mixture of Spaces (MoS) approach builds multiple parallel representations... if a semantic search misses a passage, a structural or metadata search may still retrieve it."
  - [section 5.3] "...retrieving through multiple views... collectively reduces hallucinations and incomplete answers..."
  - [corpus] VDocRAG (neighbor) supports the efficacy of retrieving over visually-rich/mixed modalities, implying multi-view approaches aid complex documents.
- Break condition: If the query intent is purely semantic and structural context adds noise, or if the fusion logic (e.g., Reciprocal Rank Fusion) fails to prioritize the correct space.

### Mechanism 2: Grounding via Structure-Aware Data Representation
- Claim: If enterprise documents contain critical information in tables, diagrams, or nested hierarchies, then converting raw text/chunks into a unified, enriched intermediate representation improves the fidelity of retrieved context.
- Mechanism: The ingestion pipeline parses PDFs not just as text blocks but as structured objects (hierarchies, tables, cross-references). This allows the retriever to access "field-level" or "section-level" granularity rather than generic chunks, aligning the context window with the document's actual logic.
- Core assumption: LLMs perform better when context preserves the structural relationships (e.g., a table row staying with its header) found in the source.
- Evidence anchors:
  - [abstract] "...featuring Structure-Aware Data Representation... enabling multi-modal retrieval..."
  - [section 4.1] "...parses each document into an enriched intermediate form encoding: Document hierarchies... Embedded tables..."
  - [corpus] Implicitly supported by the general move toward visually-rich document parsing seen in VDocRAG.
- Break condition: If the parser fails to correctly identify the hierarchy or table structure (e.g., OCR errors), resulting in garbled structural metadata.

### Mechanism 3: Error Recovery via Adaptive Chain of Actions (ACoA)
- Claim: If single-pass retrieval is insufficient for complex reasoning, then a dynamic, agentic loop that reflects on retrieved context and revises the retrieval strategy can improve final answer accuracy.
- Mechanism: Instead of a linear "retrieve-then-read" pipeline, the system dynamically plans a sequence of actions. If the initial context is judged insufficient (reflection), the system generates new queries, selects different tools/spaces, or re-executes steps (re-planning).
- Core assumption: The overhead of multiple retrieval steps is acceptable and that the "reflection" logic accurately identifies when context is missing.
- Evidence anchors:
  - [abstract] "...Adaptive Chain of Actions... reflective reasoning."
  - [section 4.3] "Adaptive Chain of Actions can: Select the optimal retrieval spaces... re-plan and re-execute retrieval steps..."
  - [corpus] Dep-Search (neighbor) aligns with "dependency-aware reasoning traces," suggesting iterative search is effective for complex tasks.
- Break condition: If the reflection module hallucinates a "gap" that doesn't exist (over-correction) or fails to identify a real gap, or if latency constraints prohibit iterative loops.

## Foundational Learning

- Concept: **RAG Capability Levels (L1-L5)**
  - Why needed here: The paper frames the entire problem space not by model size, but by the complexity of data and reasoning (L1: Surface Text vs. L4: Reflective/Agentic). Understanding this taxonomy is prerequisite to diagnosing system requirements.
  - Quick check question: Does your use case require looking up a fact (L1) or synthesizing an answer from a table and a paragraph while verifying consistency (L3/L4)?

- Concept: **Agentic Reflection / Self-Correction**
  - Why needed here: The proposed L4 architecture relies on the system's ability to critique its own retrieval results. Without understanding feedback loops, one cannot evaluate the Adaptive Chain of Actions.
  - Quick check question: How does the system know if the retrieved context is "good enough" before generating an answer?

- Concept: **Multi-Modal Parsing**
  - Why needed here: A key differentiator in the paper is handling non-text elements (tables, diagrams) as first-class citizens. Standard chunking strategies fail here.
  - Quick check question: If you feed a complex financial PDF with tables into a standard vector store, what specific information is most likely to be lost?

## Architecture Onboarding

- Component map: Ingestion (Structure-Aware Parser) -> Storage (Mixture of Spaces) -> Runtime (Adaptive Chain of Actions)
- Critical path: The **Structure-Aware Data Representation** (Ingestion). If the parser fails to identify a table or hierarchy correctly, the MoS has no structural signal to index, and the ACoA cannot retrieve precise sections.
- Design tradeoffs:
  - **Latency vs. Accuracy**: ACoA allows for multiple retrieval iterations (reflection), increasing time-to-first-token but improving answer quality on complex queries (L3/L4).
  - **Generic vs. Specific**: L1 systems (LangChain) are faster to implement but fail on "enterprise complexity" (tables/charts); L4 systems require heavy ingestion preprocessing.
- Failure signatures:
  - **L1/L2 failures**: "Contextually wrong passages" (semantic similarity matches incorrect meanings) or "Over-summarization errors" (missing table details).
  - **L4 failures**: "Runaway loops" (reflection endlessly searching) or "Parser drift" (misinterpreting a diagram as text).
- First 3 experiments:
  1. **Baseline Validation**: Run the simple **DelucionQA** (Text/L1) dataset to ensure the system handles basic semantic retrieval correctly.
  2. **Structure Stress Test**: Run **FinTabNet** (Tables/L2) to verify that the Structure-Aware parser is correctly extracting and indexing table data, comparing performance against a naive text-chunker.
  3. **Reasoning Stress Test**: Run **DMV Handbooks** or **Architectural Manuals** (L3/L4) to validate the Adaptive Chain of Actions. Measure if the system successfully initiates a second retrieval step when the first fails to find an explicit answer.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of an L4 system specifically compare against a system classified at L3 (Implicative Knowledge) on the proposed benchmarks?
  - Basis in paper: [explicit] The authors state in the Scope section (Page 9) that future work will "include L3 baselines," as the current study only evaluates L1, L2, and L4 systems.
  - Why unresolved: The experimental gap between L2 and L4 makes it difficult to isolate the marginal utility of "reflective" reasoning (L4) versus "implicative" synthesis (L3).
  - Evidence: Benchmark results comparing Corvic AI against a representative L3 system on datasets like FinTabNet and DMV Handbooks.

- **Open Question 2**: What are the accuracy–latency–cost trade-offs associated with the L4 "Mixture of Spaces" and "Adaptive Chain of Actions" architectures?
  - Basis in paper: [explicit] The paper notes in the Scope section (Page 9) that future work is needed to "map accuracy–latency–cost trade-offs more completely."
  - Why unresolved: While the paper demonstrates accuracy improvements (up to 18.91 percentage points), it does not quantify the computational overhead or latency penalties introduced by the complex L4 pipeline.
  - Evidence: Targeted ablation studies reporting inference time, token consumption, and operational costs relative to simpler L1/L2 pipelines.

- **Open Question 3**: Does the five-level framework and the L4 architecture's advantage persist when evaluating strictly structured or native multi-modal corpora?
  - Basis in paper: [explicit] Page 8 notes that the study focused on "datasets primarily comprised of unstructured data," and Section 6 states future work will "extend to structured and multi-modal corpora."
  - Why unresolved: The current datasets (PDFs) act as containers for mixed modalities, but the framework's efficacy on pure structured data (e.g., SQL data warehouses) remains unverified.
  - Evidence: Evaluation results on datasets containing purely structured schemas or native high-fidelity images without OCR artifacts.

## Limitations
- The exact implementation details of the Corvic AI system's Structure-Aware Data Representation and Adaptive Chain of Actions remain proprietary, limiting direct reproducibility of the L4 system.
- Performance claims for L4 (82.74%, 63.83%, 79.44%, 65.12%) are based on a proprietary system, so these represent theoretical upper bounds for the proposed architecture rather than independently verified results.
- The paper does not specify the exact parsing libraries or chunking parameters used for the baselines, which may affect direct comparison.
- Evaluation relies on an LLM-as-a-judge (gemini-2.0-flash), introducing potential variability in scoring.

## Confidence
- **High Confidence**: The five-level RAG capability framework (L1-L5) taxonomy is logically consistent and supported by clear definitions distinguishing data modality and reasoning complexity.
- **Medium Confidence**: The core mechanisms (Mixture of Spaces, Structure-Aware Data Representation, Adaptive Chain of Actions) are theoretically sound and align with related work, though specific implementation details are proprietary.
- **Low Confidence**: Exact performance numbers for the proprietary Corvic AI system, as they cannot be independently verified without access to the implementation.

## Next Checks
1. **Baseline Reproduction**: Implement and evaluate the L1 (LangChain) and L2 (OpenAI/Azure) baselines on the DelucionQA dataset to establish baseline performance and verify the evaluation pipeline.
2. **Structure Parsing Validation**: Run FinTabNet with the baseline systems to confirm they fail on table-based questions, demonstrating the need for Structure-Aware parsing.
3. **Iterative Retrieval Analysis**: For DMV Handbooks/Architectural Manuals, instrument the Adaptive Chain of Actions to log whether and when reflection triggers additional retrieval steps, validating the mechanism beyond just final accuracy scores.