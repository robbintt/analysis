---
ver: rpa2
title: 'A Survey on Tabular Data Generation: Utility, Alignment, Fidelity, Privacy,
  and Beyond'
arxiv_id: '2503.05954'
source_url: https://arxiv.org/abs/2503.05954
tags:
- data
- tabular
- synthetic
- which
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive overview of deep generative
  models for tabular data synthesis, focusing on four key requirements: utility (predictive
  performance on downstream tasks), alignment (adherence to domain-specific constraints),
  fidelity (statistical similarity to real data), and privacy (protection against
  re-identification and disclosure). The authors categorize existing methods by the
  primary requirement they address and the underlying model architecture (e.g., GANs,
  diffusion models, LLMs).'
---

# A Survey on Tabular Data Generation: Utility, Alignment, Fidelity, Privacy, and Beyond

## Quick Facts
- arXiv ID: 2503.05954
- Source URL: https://arxiv.org/abs/2503.05954
- Reference count: 7
- One-line primary result: Comprehensive survey categorizing deep generative models for tabular data synthesis by their ability to satisfy utility, alignment, fidelity, and privacy requirements.

## Executive Summary
This survey provides a systematic overview of deep generative models for synthetic tabular data generation, organizing 20+ approaches by their primary focus among four key requirements: utility (predictive performance), alignment (domain constraints), fidelity (statistical similarity), and privacy (protection against attacks). The authors identify a critical gap: no existing model successfully integrates all four requirements, revealing the field's fragmentation. They provide a practical guide for practitioners to select appropriate models and evaluation metrics based on their specific needs, while highlighting future research directions including hybrid techniques and standardized evaluation frameworks.

## Method Summary
The survey methodology involves systematically categorizing existing tabular data generation approaches by their underlying architecture (GANs, VAEs, diffusion models, LLMs, etc.) and their primary focus among four requirements. For each requirement, the authors define specific evaluation metrics: utility via Train-on-Synthetic-Test-on-Real (TSTR) protocols, alignment via constraint violation rates, fidelity via statistical distance measures, and privacy via membership/attribute attack metrics. The survey reviews literature to map models to their strengths and limitations, creating a comprehensive taxonomy that serves as a decision framework for practitioners.

## Key Results
- No existing model successfully integrates all four core requirements (utility, alignment, fidelity, privacy) simultaneously
- Alignment has emerged as a critical requirement, with only C-DGM and DGM+DRL providing guarantees
- The field faces a significant evaluation challenge due to the diversity of metrics and lack of standardized benchmarks
- Hybrid techniques combining different architectural approaches are anticipated to drive future versatile models

## Why This Works (Mechanism)

### Mechanism 1: Requirements-Driven Filtering
- **Claim:** Effective tabular data synthesis selection relies on filtering models by use-case requirements (Privacy, Utility, Fidelity, Alignment) rather than just architectural novelty, as no single model currently optimizes all dimensions.
- **Mechanism:** The survey framework decouples the "What" (requirements) from the "How" (architecture). By mapping 20+ models to their primary focus (e.g., CTGAN for Fidelity, PATE-GAN for Privacy), it reveals that specialized models outperform generalists in specific niches. For instance, models optimized for utility often fail alignment checks, while privacy-focused models may sacrifice fidelity.
- **Core assumption:** A practitioner's primary constraint (e.g., regulatory privacy vs. model accuracy) is the dominant variable for model selection.
- **Evidence anchors:**
  - [abstract] "We group the approaches... based on the primary type of requirements they address."
  - [page 7, Figure 2] Visualizes the fragmentation where no model covers all four requirement bubbles.
  - [corpus] "Synthetic Tabular Data Generation: A Comparative Survey..." (arXiv:2507.11590) reinforces the difficulty of balancing these trade-offs.
- **Break condition:** If a use case demands simultaneous optimization of all four requirements (e.g., high-fidelity, private, aligned, and useful data), this filtering mechanism exposes the lack of a viable solution (Gap identified in Section 8).

### Mechanism 2: Constraint Enforcement via Output Space Restriction
- **Claim:** Ensuring synthetic data satisfies logical domain constraints (Alignment) requires restricting the model's output distribution mathematically, rather than relying on the model to learn boundaries implicitly.
- **Mechanism:** Layer-based methods (e.g., C-DGM, DGM+DRL) insert a differentiable, acyclic layer immediately before the output. This layer projects the generated sample into a feasible region defined by linear inequalities (e.g., `min_hemoglobin < max_hemoglobin`), guaranteeing violations are mathematically impossible.
- **Core assumption:** Domain knowledge can be expressed as linear inequalities or disjunctions of inequalities.
- **Evidence anchors:**
  - [page 4] "The layer can be added on top of any deep generative model (DGM)... [restricting] the output space... to coincide with the space defined by the constraints."
  - [page 5, Table 1] Shows C-DGM and DGM+DRL are the only methods providing guarantees ("✓ ✓") for alignment.
- **Break condition:** If constraints are non-linear or cannot be reduced to quantifier-free real linear constraints, the specific DRL mechanism described may not apply without modification.

### Mechanism 3: Differential Privacy via Aggregated Gradients
- **Claim:** Privacy preservation against membership inference attacks is achieved by limiting the sensitivity of the training process to any single real data point.
- **Mechanism:** Models like PATE-GAN or CTAB-GAN+ integrate Differential Privacy (DP) by aggregating signals from multiple "teacher" discriminators trained on disjoint data subsets and adding noise, or by using DP-SGD (Differentially Private Stochastic Gradient Descent) to clip and noise gradients. This ensures the generator learns the distribution without memorizing specific records.
- **Core assumption:** The privacy budget (epsilon) can be tolerated regarding the drop in utility/fidelity.
- **Evidence anchors:**
  - [page 6] "PATE-GAN relies on a modified Private Aggregation of Teacher Ensemble (PATE) mechanism to ensure that the discriminator is differentially private."
  - [page 6] CTAB-GAN+ addresses privacy by "training a discriminator using differential private-SGD."
  - [corpus] "When Tables Leak..." (arXiv:2512.08875) highlights risks in LLM-based generation, reinforcing the need for robust DP mechanisms.

## Foundational Learning

- **Concept: Train on Synthetic, Test on Real (TSTR)**
  - **Why needed here:** This is the standard evaluation protocol for "Utility" (Section 3.1). Without understanding that synthetic data is used for training while real data is withheld for testing, one cannot validate if the synthetic data captures predictive signal.
  - **Quick check question:** If I train a classifier on synthetic data and test it on synthetic data, am I measuring utility effectively? (Answer: No, you must test on held-out real data).

- **Concept: Mode Collapse (in GANs)**
  - **Why needed here:** A critical failure mode discussed in Fidelity (Section 5.2). It occurs when a GAN generator produces limited varieties of samples, failing to capture the full diversity of the real tabular data (e.g., generating only one category for a categorical feature).
  - **Quick check question:** Why does CTGAN use mode-specific normalization? (Answer: To handle multi-modal continuous features and prevent the generator from ignoring less frequent modes).

- **Concept: Mixed-Type Data**
  - **Why needed here:** Tabular data uniquely combines continuous, categorical, and binary variables. Standard deep learning architectures often assume one type (e.g., images are continuous).
  - **Quick check question:** Why is treating a categorical variable (e.g., "Red", "Blue") as continuous problematic for a generator? (Answer: It implies an ordering and distance relationship that doesn't exist, harming fidelity).

## Architecture Onboarding

- **Component map:**
  - **Input:** Real Tabular Data $D$ (Mixed types)
  - **Preprocessor:** Type-specific encodings (e.g., Gumbel-Softmax for categories, Variational Gaussian Mixture for continuous modes)
  - **Core Generator:** GAN, VAE, Diffusion, or LLM backbone
  - **Constraint Layer (Optional):** Enforces logical rules (e.g., C-DGM)
  - **Output:** Synthetic Data $D'$

- **Critical path:**
  1. **Define Requirement:** Determine if Privacy, Alignment, or Utility is the priority
  2. **Select Architecture:** Use Table 1. (e.g., Diffusion for high fidelity, PATE-GAN for privacy, C-DGM for alignment)
  3. **Evaluation:** Run TSTR for utility; run Constraint Violation Rate (CVR) for alignment; run Distance to Closest Record (DCR) for privacy

- **Design tradeoffs:**
  - **Speed vs. Quality:** Diffusion models (e.g., TabDDPM) generally offer higher fidelity and utility but have "slow" generation times compared to GANs (Table 1)
  - **Privacy vs. Utility:** Adding noise for privacy (DP) typically degrades the statistical fidelity and predictive utility of the data
  - **Guarantees vs. Flexibility:** Hard constraint layers (C-DGM) guarantee alignment but restrict the output space, which might theoretically lower maximum fidelity if the real data borders the constraint boundaries

- **Failure signatures:**
  - **Low Utility:** TSTR accuracy is significantly lower than "Train on Real Test on Real"
  - **Mode Collapse:** Synthetic data has lower variance or missing categories compared to real data
  - **Privacy Leakage:** Low "Distance to Closest Record" (DCR) indicates synthetic points are too similar to real points
  - **Logical Inconsistencies:** Non-zero Constraint Violation Rate (CVR) in standard GANs/VAEs

- **First 3 experiments:**
  1. **Baseline Utility Check:** Implement CTGAN or TVAE on a dataset; evaluate using the TSTR protocol against a baseline classifier (e.g., XGBoost)
  2. **Alignment Stress Test:** Generate data with a standard model, measure Constraint Violation Rate (CVR), then compare against a constrained model (C-DGM) if logical rules exist
  3. **Privacy Attack Simulation:** Train a standard generator, then perform a simple "Distance to Closest Record" (DCR) analysis to see if synthetic rows reveal real outliers

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can a single deep generative model be developed that successfully integrates all four core requirements (utility, alignment, fidelity, and privacy) without significant trade-offs?
- **Basis in paper:** [explicit] The authors state in Section 8 that "Figure 2 reveals a striking gap: no existing model successfully integrates all the core requirements we consider."
- **Why unresolved:** Current models prioritize individual objectives (typically utility or privacy), leading to specialized but fragmented approaches that lack broad applicability.
- **What evidence would resolve it:** The proposal of a model that achieves state-of-the-art performance across metrics for all four requirements simultaneously on standard benchmarks.

### Open Question 2
- **Question:** How can hybridization of techniques be utilized to balance competing requirements and drive the development of more versatile models?
- **Basis in paper:** [explicit] The authors anticipate that "hybridization of techniques will drive the development of more versatile models" to address the challenge of balancing competing requirements.
- **Why unresolved:** Existing approaches are often architecture-specific (e.g., GAN-only, Diffusion-only) and struggle with the inherent trade-offs between fidelity, utility, and privacy.
- **What evidence would resolve it:** Research demonstrating a hybrid architecture (e.g., combining diffusion models with constraint layers) that outperforms single-architecture baselines on multi-objective optimization tasks.

### Open Question 3
- **Question:** How can the field establish a standardized evaluation framework given the current "sheer diversity" of metrics?
- **Basis in paper:** [explicit] The introduction notes that the "sheer diversity of these metrics has made it increasingly difficult to assess and compare different synthesisers in a standardised manner."
- **Why unresolved:** Different papers utilize different subsets of metrics, and fidelity metrics often fail to predict downstream utility, making fair comparison difficult for practitioners.
- **What evidence would resolve it:** The adoption of a unified benchmark suite or protocol that correlates specific metric improvements with success in real-world deployment scenarios.

## Limitations
- The survey identifies no existing model satisfies all four requirements simultaneously, but practical severity across domains needs more empirical validation
- Evaluation metrics for alignment are evolving and may not capture all constraint types, especially non-linear or temporal dependencies
- Privacy evaluation remains challenging due to difficulty simulating realistic attack scenarios and lack of standardized benchmarks

## Confidence
- **High**: The framework for categorizing models by primary requirement and architecture is well-supported by the survey's systematic review of 20+ methods
- **Medium**: The claim that no model currently satisfies all four requirements is strongly supported, but the practical severity of this limitation across domains needs more empirical validation
- **Medium**: The mechanism for constraint enforcement via output space restriction is clearly described, but its effectiveness on complex, non-linear constraints is less certain

## Next Checks
1. Implement and compare a baseline GAN (e.g., CTGAN) against a constrained model (e.g., C-DGM) on a dataset with known logical rules to measure the practical impact of alignment guarantees
2. Evaluate a privacy-focused model (e.g., PATE-GAN) on the same dataset to quantify the utility cost of differential privacy and test against simple membership inference attacks
3. Conduct a controlled experiment to measure mode collapse in a standard GAN versus a diffusion model (e.g., TabDDPM) on a multi-modal tabular dataset, using fidelity metrics like Wasserstein distance and JSD