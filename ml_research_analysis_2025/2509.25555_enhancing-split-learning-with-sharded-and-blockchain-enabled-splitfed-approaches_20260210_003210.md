---
ver: rpa2
title: Enhancing Split Learning with Sharded and Blockchain-Enabled SplitFed Approaches
arxiv_id: '2509.25555'
source_url: https://arxiv.org/abs/2509.25555
tags:
- learning
- server
- training
- clients
- bsfl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses scalability and security challenges in collaborative
  learning frameworks like Federated Learning (FL) and Split Learning (SL). SL suffers
  from slow training times, while FL imposes heavy computational burdens on clients.
---

# Enhancing Split Learning with Sharded and Blockchain-Enabled SplitFed Approaches

## Quick Facts
- arXiv ID: 2509.25555
- Source URL: https://arxiv.org/abs/2509.25555
- Reference count: 31
- Primary result: SSFL improves SplitFed performance by 31.2% and scalability by 85.2%; BSFL increases poisoning resilience by 62.7% while maintaining superior performance

## Executive Summary
This paper addresses scalability and security challenges in collaborative learning frameworks by proposing two novel approaches. Sharded SplitFed Learning (SSFL) improves computational efficiency by distributing the Split Learning server workload across multiple parallel shards, reducing bottlenecks and improving performance by 31.2% with 85.2% better scalability. Blockchain-enabled SplitFed Learning (BSFL) enhances security by replacing the centralized FL server with a blockchain-based architecture and committee-driven consensus mechanism, achieving 62.7% greater resilience to data poisoning attacks while maintaining superior performance. BSFL represents the first end-to-end decentralized SplitFed Learning system implemented with blockchain technology.

## Method Summary
The authors propose two complementary solutions to Split Learning limitations. SSFL partitions clients into groups (shards), each with a dedicated server that processes forward/backward passes in parallel, with a federated server aggregating shard outputs using FedAvg to address imbalanced learning rates. BSFL replaces the central FL server with a blockchain network where a committee of nodes evaluates model updates using validation loss, selecting top-K models through median scoring for aggregation. Both approaches were implemented using PyTorch, Flask, and Hyperledger Fabric, with experiments conducted on Fashion MNIST distributed in Non-IID fashion across 9 or 36 nodes.

## Key Results
- SSFL improves performance by 31.2% and scalability by 85.2% through parallel sharding of SplitFed servers
- BSFL achieves 62.7% greater resilience to data poisoning attacks while maintaining superior performance compared to centralized approaches
- BSFL is the first blockchain-enabled framework to implement an end-to-end decentralized SplitFed Learning system

## Why This Works (Mechanism)

### Mechanism 1: Sharded Parallelism for Computational Offloading
Distributing the server-side workload of Split Learning across multiple parallel shards reduces round-trip time and computational bottlenecks. In SplitFed Learning, a single server processes smashed data from all clients, creating a bottleneck. SSFL partitions clients into groups, each with a dedicated server that processes forward/backward passes in parallel, with a federated server aggregating the shard outputs. The dataset and model can be partitioned such that the overhead of aggregating shard updates is significantly lower than the latency avoided by parallelizing server-side inference and gradient computation.

### Mechanism 2: Federated Averaging for Learning Rate Synchronization
Aggregating shard-level server models stabilizes convergence by mitigating the "imbalanced learning rate" problem inherent in standard Split Learning. In standard SL, the server model updates more frequently than client models (once per batch vs. once per epoch). SSFL applies FedAvg to the shard server models, effectively averaging their weight updates to smooth the update trajectory and prevent the server model from advancing too rapidly relative to the clients. The imbalanced update frequency is a primary cause of performance degradation in scalable SL, and applying standard federated averaging to server-side weights is sufficient to correct this imbalance.

### Mechanism 3: Committee-Driven Median Filtering for Byzantine Resilience
Replacing a central aggregator with a blockchain committee scoring updates by validation loss filters poisoned models without trusting a central entity. In BSFL, a committee of nodes validates model updates from other shards using a local validation set, assigning scores based on validation loss. The system uses the median of these scores to rank updates, selecting only the top K models for aggregation. This prevents a single malicious actor or a minority of colluding actors from injecting backdoored weights. Honest committee members hold validation data representative enough to detect performance drops caused by poisoning, and the median statistic is robust against up to 50% malicious scorers.

## Foundational Learning

- **Concept: Split Learning (SL) Architecture**
  - Why needed: The paper builds upon SL's core feature—splitting a model between client and server to save client compute. Understanding "smashed data" (intermediate activations) is required to see why sharding the server solves a bottleneck.
  - Quick check: Can you explain why sending smashed data from many clients to a single server creates a sequential bottleneck in standard Split Learning?

- **Concept: Federated Averaging (FedAvg)**
  - Why needed: SSFL relies on FedAvg not just for client updates, but critically for aggregating server-side shard models to solve the "imbalanced learning rate" issue.
  - Quick check: How does averaging model weights ($W_{t+1} = \frac{1}{n}\sum W_i$) differ from averaging data, and why does it help convergence here?

- **Concept: Blockchain Consensus & Smart Contracts**
  - Why needed: BSFL decentralizes the "FL Server" logic. You must understand that smart contracts act as the automated aggregator and that committee consensus replaces the trusted administrator.
  - Quick check: In a "trustless" system, how does a committee agree on the validity of a model update without a central auditor?

## Architecture Onboarding

- **Component map:**
  - Clients -> Shard Servers -> FL Server (SSFL) or Blockchain Network (BSFL)

- **Critical path:**
  1. Assignment: Clients handshake with a Shard Server (SSFL) or are assigned via smart contract (BSFL)
  2. Local Training: Client processes data → Smashed Data (A). Sends A to Shard Server
  3. Server Processing: Shard Server completes forward pass → Loss → Backprop. Updates local server weights. Sends gradients (dA) back to Client
  4. Client Update: Client updates local weights using received gradients
  5. Global Aggregation:
     - SSFL: Shard servers send weights to Central FL Server → FedAvg
     - BSFL: Shard servers propose models to Blockchain → Committee scores them → Smart contract aggregates Top-K

- **Design tradeoffs:**
  - SSFL vs. BSFL: SSFL offers low latency (31.2% faster) but retains a central point of failure. BSFL removes the central point of failure and adds poisoning defense (+62.7%) but introduces blockchain communication overhead (higher round-trip time)
  - K Selection: Selecting a small K (number of winners) improves robustness against bad models but may discard useful, slightly noisy updates, slowing convergence

- **Failure signatures:**
  - Performance Plateau in SSFL: Likely caused by high Non-IID data between shards; check if "imbalanced update" logic is too aggressive
  - Stalling in BSFL: Consensus failure; check if the committee size (N) is too small or if the median score calculation is deadlocking in the smart contract
  - Memory Overflow on Shard Server: The batch size of incoming smashed data from parallel clients exceeds server RAM

- **First 3 experiments:**
  1. Baseline Sanity Check: Run standard SplitFed (SFL) vs. the proposed SSFL on Fashion MNIST (as done in paper) to verify that round completion time drops as shard count increases
  2. Scalability Stress Test: Fix the total number of clients (e.g., 100) but vary the number of shards (1 vs. 5 vs. 10) to find the inflection point where coordination overhead outweighs parallelism gains
  3. Poisoning Injection (BSFL only): Introduce a fixed percentage of malicious clients (e.g., 30%) submitting random noise as updates. Measure if the "Top-K" committee mechanism successfully filters these out compared to the median test loss

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does extending the SSFL and BSFL frameworks to support multi-part model splits (dividing the model into three or more segments) impact the trade-off between client-side computational load and data privacy?
- Basis in paper: Section VIII-A states that while the current study uses two parts, extending to multi-part splits could improve privacy by keeping labels local, but requires assessing the increased computational burden on clients
- Why unresolved: The authors implemented only a two-part split where batch targets are shared with the server; the specific resource costs and privacy benefits of the multi-part alternative are proposed but untested
- What evidence would resolve it: Comparative experiments measuring client CPU/memory usage and susceptibility to label inference attacks in a three-part split versus the standard two-part implementation

### Open Question 2
- Question: How can the committee consensus evaluation mechanism be adapted to effectively assess model updates in generative applications using metrics like Feature Likelihood Divergence (FLD) or Fréchet Inception Distance (FID)?
- Basis in paper: Section VIII-B notes that validation loss is limited to tasks with labels and suggests adapting the evaluation mechanism for generative models using FLD or FID
- Why unresolved: The current BSFL framework relies on validation loss or accuracy for its smart contract scoring system, which cannot be directly applied to generative tasks where labels are absent
- What evidence would resolve it: A modified BSFL implementation where the `Evaluate` function utilizes FID/FLD, demonstrating successful convergence and robustness in a generative adversarial network (GAN) setting

### Open Question 3
- Question: Can an advanced committee election algorithm that explicitly accounts for nodes' heterogeneous computational capabilities improve the efficiency and fairness of the BSFL framework?
- Basis in paper: Section VI-D acknowledges that selecting committee members based purely on previous scores might assign server duties to resource-constrained clients, conflicting with the goal of split learning
- Why unresolved: The current design assumes nodes are capable of server duties or selects them blindly/randomly; the authors suggest a capability-aware selection algorithm as a refinement but do not implement it
- What evidence would resolve it: Simulation results in a network with heterogeneous devices (e.g., mixed mobile and desktop nodes) showing that a capability-aware selection algorithm reduces round completion times and node dropouts compared to the baseline score-based selection

## Limitations
- The paper's empirical claims rely on unlisted hyperparameters (optimizer, learning rate, batch size, local epochs), making faithful reproduction challenging
- The Non-IID distribution strategy is vaguely defined, limiting the ability to reproduce the exact experimental conditions
- Performance gains (31.2% and 85.2%) are only demonstrated on Fashion MNIST, limiting generalizability to other datasets and tasks

## Confidence
- **High**: The conceptual mechanism of sharding SplitFed servers for parallelism is sound and aligns with distributed systems principles
- **Medium**: The claim of 62.7% poisoning resilience is plausible given median filtering, but the lack of baseline comparison (e.g., Krum, Median) and detailed threat model reduces confidence
- **Low**: The exact implementation details for hyperparameters, Non-IID skew method, and committee scoring algorithm are insufficient for precise replication

## Next Checks
1. **Hyperparameter Sensitivity**: Run SSFL with varied learning rates and local epochs to identify the configuration that achieves the claimed 31.2% performance gain
2. **Robustness to Non-IID Extremes**: Test SSFL on highly skewed Non-IID data (e.g., Dirichlet-α=0.1) to see if the "imbalanced update" averaging still converges
3. **Byzantine Resilience Benchmark**: Compare BSFL's "Top-K" median filtering against standard Byzantine-tolerant FL methods (e.g., Krum, Median) under controlled poisoning attacks (e.g., 30% malicious clients)