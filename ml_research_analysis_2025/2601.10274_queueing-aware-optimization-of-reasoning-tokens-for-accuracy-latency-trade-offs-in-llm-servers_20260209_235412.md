---
ver: rpa2
title: Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs
  in LLM Servers
arxiv_id: '2601.10274'
source_url: https://arxiv.org/abs/2601.10274
tags:
- accuracy
- time
- reasoning
- tokens
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a queueing-aware optimization framework for
  allocating reasoning tokens across heterogeneous query types in LLM servers. The
  authors formulate a convex optimization problem that balances accuracy gains against
  latency penalties by selecting per-task reasoning-token budgets under stability
  constraints.
---

# Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers

## Quick Facts
- arXiv ID: 2601.10274
- Source URL: https://arxiv.org/abs/2601.10274
- Reference count: 23
- One-line primary result: Heterogeneous per-task token allocation significantly outperforms uniform budgeting in balancing accuracy gains against latency penalties under M/G/1 queueing constraints.

## Executive Summary
This paper presents a queueing-aware optimization framework for allocating reasoning tokens across heterogeneous query types in LLM servers. The authors formulate a convex optimization problem that balances accuracy gains against latency penalties by selecting per-task reasoning-token budgets under stability constraints. They prove the objective is strictly concave, derive KKT conditions leading to a projected fixed-point iteration with convergence guarantees, and provide a globally convergent projected gradient method. Numerical results using Qwen3-8B on six datasets demonstrate that heterogeneous token allocation significantly outperforms uniform budgeting, achieving optimal trade-offs between accuracy and latency.

## Method Summary
The authors formulate a queueing-aware convex optimization problem that selects per-task reasoning-token budgets (ℓₖ) to maximize a weighted combination of accuracy and penalize latency. They fit accuracy models pₖ(ℓₖ) = Aₖ(1 - e⁻ᵇᵏˡᵏ) + Dₖ and latency models tₖ(ℓₖ) = t₀ₖ + cₖℓₖ for each task type, then solve the resulting strictly concave objective using projected fixed-point iteration (with Lambert W) or projected gradient ascent. The framework assumes Poisson arrivals, FIFO discipline, and M/G/1 queue dynamics, with stability constraint λE[S] < 1.

## Key Results
- Heterogeneous token allocation achieves 15-30% better objective value than uniform budgeting across six datasets
- Projected gradient ascent converges reliably when fixed-point iteration contraction condition fails
- Queueing delay couples token allocations across task types, making the optimization interactive
- Accuracy saturates exponentially with token count, validating diminishing returns assumption

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Heterogeneous per-task token allocation outperforms uniform budgeting when task types exhibit different accuracy-latency trade-off curves.
- **Mechanism:** Each task type k has a unique accuracy function pₖ(ℓₖ) = Aₖ(1 - e⁻ᵇᵏˡᵏ) + Dₖ with diminishing returns. Tasks with high bₖ (rapid saturation) receive fewer tokens; tasks with high Aₖ and moderate bₖ receive more. The optimizer allocates tokens where marginal accuracy gain exceeds marginal latency penalty from queueing.
- **Core assumption:** Accuracy curves are well-approximated by exponential saturation; service time is affine in tokens (tₖ = t₀ₖ + cₖℓₖ).
- **Evidence anchors:**
  - [abstract] "heterogeneous token allocation significantly outperforms uniform budgeting"
  - [Section IV, Fig. 3] Uniform ℓ=500 degrades objective from queueing; ℓ=0 sacrifices accuracy; optimal heterogeneous allocation achieves best J(ℓ)
  - [corpus] Weak direct evidence; neighbor papers discuss adaptive reasoning but not queueing-coupled optimization
- **Break condition:** If accuracy curves do not exhibit diminishing returns, or if service time is highly nonlinear in tokens, the concavity guarantee fails.

### Mechanism 2
- **Claim:** Queueing delay couples token allocations across task types via the Pollaczek-Khinchine formula.
- **Mechanism:** Under FIFO, mean waiting time is E[W] = λE[S²]/(2(1-λE[S])). Increasing any ℓₖ raises both E[S] and E[S²], inflating waiting time for all queries. This coupling makes the optimization problem interactive—optimal ℓₖ depends on all other ℓⱼ.
- **Core assumption:** Arrivals are Poisson; service times are independent; FIFO discipline; system is stable (λE[S] < 1).
- **Evidence anchors:**
  - [abstract] "the mean system time depends on the first and second moments of the resulting service-time distribution"
  - [Section II-A, Eq. 5–6] Explicit Pollaczek-Khinchine formulation
  - [corpus] Yang et al. [2] (cited in paper) validates M/G/1 modeling for LLM inference with variable token lengths
- **Break condition:** If arrivals are bursty (not Poisson) or service discipline changes (e.g., priority queuing), the coupling structure changes.

### Mechanism 3
- **Claim:** Strict concavity of J(ℓ) guarantees a unique global optimum obtainable via projected fixed-point or gradient ascent.
- **Mechanism:** Hessian of waiting time is positive definite (proven via Cauchy-Schwarz); accuracy term is concave; thus J(ℓ) is strictly concave. KKT conditions yield a projected fixed-point iteration using Lambert-W function; if Jacobian norm L∞ < 1, this contracts to the optimum. Otherwise, projected gradient ascent with step size η < 2/Lⱼ converges globally.
- **Core assumption:** Continuous relaxation of integer tokens is valid; rounding loss is bounded.
- **Evidence anchors:**
  - [Section III-A, Lemma 1] Proof of strict concavity via Hessian analysis
  - [Section III-C, Lemma 2] Sufficient condition for contraction: L∞ < 1
  - [Section III-D, Lemma 3] Global Lipschitz constant Lⱼ for gradient ascent step-size bound
  - [corpus] No direct external validation of this specific optimization structure
- **Break condition:** If stability region boundary is approached (λE[S] → 1), gradients explode and algorithms may diverge.

## Foundational Learning

- **Concept: M/G/1 Queueing and Pollaczek-Khinchine Formula**
  - Why needed here: The latency model hinges on computing mean waiting time from service-time moments. Without this, the coupling between token allocation and queueing delay is opaque.
  - Quick check question: Given arrival rate λ=0.1 and service-time moments E[S]=5s, E[S²]=30s², compute E[W].

- **Concept: Concave Optimization and KKT Conditions**
  - Why needed here: The paper proves strict concavity to guarantee unique optima and derives algorithms from KKT conditions.
  - Quick check question: For a concave function f(x) on a convex set, why does any point satisfying ∇f=0 (with constraints) yield a global maximum?

- **Concept: Fixed-Point Iteration and Contraction Mappings**
  - Why needed here: The paper's primary algorithm is a projected fixed-point iteration; convergence requires understanding contraction conditions.
  - Quick check question: If mapping T has Lipschitz constant L<1 in some norm, how many iterations are needed to reduce error by factor 10?

## Architecture Onboarding

- **Component map:** Query classifier → Token budget allocator → LLM inference engine → Queue manager
- **Critical path:** 1) Offline: Fit accuracy models pₖ(ℓ) and latency models tₖ(ℓ) per task type using empirical measurements 2) Offline: Run projected gradient ascent to compute optimal ℓ*ₖ for given λ and α 3) Online: Classify incoming query → apply precomputed ℓ*ₖ → execute inference
- **Design tradeoffs:** Higher α weights accuracy over latency (suitable for high-stakes tasks); higher λ (arrival rate) forces lower token budgets to maintain stability; integer rounding via exhaustive 2ᴺ search vs. simple rounding (complexity vs. optimality)
- **Failure signatures:** Queue blowup: λE[S] ≥ 1 triggers instability; latency grows unbounded; Suboptimal allocation: Poor accuracy model fits lead to wrong token budgets; Algorithm non-convergence: If contraction condition fails and step size too large, gradient ascent oscillates
- **First 3 experiments:** 1) Fit accuracy and latency models on your own task mixture; validate that exponential saturation and affine latency hold empirically 2) Run the projected gradient ascent algorithm with your fitted parameters; verify convergence by checking J(ℓ) monotonicity 3) Deploy uniform vs. optimal heterogeneous allocation in a simulated queue (10k queries, Poisson arrivals); compare average accuracy and 95th-percentile latency

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the optimal token allocation strategy change in a multi-server LLM deployment (e.g., M/G/c or distributed inference) compared to the single-server M/G/1 model analyzed?
- **Basis in paper:** [inferred] The system model explicitly restricts the analysis to a "single LLM server" (Page 1), which simplifies the queueing dynamics but limits applicability to distributed serving clusters.
- **Why unresolved:** The objective function and stability conditions rely specifically on the Pollaczek-Khinchine formula for the M/G/1 queue, which does not generalize trivially to parallel servers where load balancing introduces additional complexity.
- **What evidence would resolve it:** An extension of the convex optimization framework to an M/G/c queueing model or simulation results validating the allocation policy in a multi-server setup.

### Open Question 2
- **Question:** How would alternative service disciplines, such as priority queuing or processor sharing, impact the optimal heterogeneous token allocation and the resulting accuracy-latency trade-off?
- **Basis in paper:** [inferred] The analysis explicitly assumes a "first-in, first-out (FIFO) service discipline" (Abstract).
- **Why unresolved:** The mean system time formula derived from the Pollaczek-Khinchine formula is specific to FIFO; different scheduling policies alter the relationship between service time variance and waiting time, potentially shifting the optimal token budget.
- **What evidence would resolve it:** A derivation of the waiting time penalty under alternative scheduling disciplines and a comparative analysis of the resulting optimal token budgets.

### Open Question 3
- **Question:** Can the optimization framework be adapted to an online setting where query arrival rates and task type priors are unknown or time-varying?
- **Basis in paper:** [inferred] The problem formulation assumes queries "occur with a known prior probability" and arrival rates are fixed parameters (Section II).
- **Why unresolved:** The KKT conditions and projected gradient method require known, fixed parameters; dynamic or unknown statistics could violate the stability constraint λE[S] < 1 or shift the optimal solution faster than the fixed-point iteration converges.
- **What evidence would resolve it:** Development of an online or adaptive optimization algorithm that estimates these statistics in real-time while maintaining queue stability and convergence guarantees.

## Limitations
- The exponential saturation form for accuracy curves is assumed but not externally validated across diverse model architectures
- Strict concavity proof depends on affine service time assumption that may break down at extreme token allocations
- Fixed-point iteration convergence requires condition L∞ < 1 that is sufficient but not necessary, with limited characterization of performance when this fails

## Confidence
**High Confidence**: The queueing theory foundations (Pollaczek-Khinchine formula, M/G/1 stability conditions) are well-established and correctly applied. The coupling mechanism between token allocation and system latency through service-time moments is sound.

**Medium Confidence**: The optimization framework and algorithm design are theoretically rigorous, with clear proofs of concavity, KKT conditions, and convergence guarantees. However, the practical performance depends heavily on model fitting quality and the validity of continuous relaxation assumptions.

**Low Confidence**: The empirical validation is limited to six datasets with a single model (Qwen3-8B). The claim of "significant" improvement over uniform allocation needs broader validation across different model families, task mixtures, and operating conditions. The 10K-query simulation may not capture long-term stability effects or rare but impactful queue behaviors.

## Next Checks
1. **Model-agnostic validation**: Replicate the accuracy and latency model fitting using a different LLM (e.g., Llama-3 or GPT-4) on the same six datasets. Compare whether the exponential saturation form holds and whether the fitted parameters lead to similar optimization outcomes. This tests whether the framework generalizes beyond a single model architecture.

2. **Extreme-load stress test**: Systematically vary the arrival rate λ from 0.01 to 0.99 (approaching stability boundary) while keeping other parameters fixed. Measure algorithm convergence behavior, final objective value J(ℓ), and queue stability metrics (mean waiting time, 95th percentile latency). This validates whether the convergence guarantees hold under stress and identifies failure modes near the stability boundary.

3. **Robustness to model misspecification**: Generate synthetic accuracy curves that deviate from exponential saturation (e.g., sigmoidal with different steepness, piecewise linear, or curves with local maxima). Run the optimization framework on these synthetic curves and measure the suboptimality gap between the computed solution and the true optimum. This quantifies the framework's sensitivity to accuracy model misspecification and establishes when the approach breaks down.