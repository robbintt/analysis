---
ver: rpa2
title: Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed
  Variational Autoencoder Mixture Model
arxiv_id: '2509.15124'
source_url: https://arxiv.org/abs/2509.15124
tags:
- data
- mixture
- disease
- usion
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BrainPhys, a physics-informed variational
  autoencoder (VAE) mixture model designed to identify mechanistic subtypes of neurodegenerative
  diseases from neuroimaging data. The core innovation lies in modeling multiple underlying
  partial differential equations (PDEs) simultaneously using a mixture framework,
  enabling the model to capture heterogeneous disease dynamics within the same population.
---

# Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model

## Quick Facts
- arXiv ID: 2509.15124
- Source URL: https://arxiv.org/abs/2509.15124
- Reference count: 28
- Primary result: Physics-informed VAE mixture model identifies distinct mechanistic subtypes in Alzheimer's disease using tau and amyloid PET imaging data

## Executive Summary
This paper introduces BrainPhys, a novel physics-informed variational autoencoder (VAE) mixture model designed to identify mechanistic subtypes of neurodegenerative diseases from neuroimaging data. The core innovation lies in modeling multiple underlying partial differential equations (PDEs) simultaneously using a mixture framework, enabling the model to capture heterogeneous disease dynamics within the same population. BrainPhys infers both the mixture weights indicating which PDE component best explains each subject and interpretable latent parameters such as diffusion and reaction rates from PET imaging data.

The approach addresses key challenges in mechanistic modeling, including model misspecification and degeneracy, by allowing for multiple possible PDE structures rather than assuming a single mechanistic form. When applied to combined tau and amyloid PET data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), the model found evidence supporting a 2-component mixture model, suggesting distinct mechanistic subtypes within the cohort. The method successfully recovers known ground truth parameters from synthetic data and demonstrates higher model evidence when both PDE components are used compared to single-mechanism models.

## Method Summary
BrainPhys is a physics-informed variational autoencoder mixture model that learns mechanistic subtypes of neurodegeneration by simultaneously modeling multiple underlying partial differential equations. The model uses a mixture framework where each component represents a different PDE structure (e.g., diffusion-only vs. reaction-diffusion). During training, the VAE learns to map imaging data to latent parameters that characterize the underlying physics of disease progression. The mixture component assignments indicate which mechanistic subtype best explains each subject's disease pattern. The model is trained using variational inference with evidence lower bound (ELBO) optimization, and it can recover interpretable parameters like diffusion rates and reaction rates from the latent space. The approach was validated on synthetic data with known ground truth before being applied to real-world tau and amyloid PET data from ADNI.

## Key Results
- Successfully recovered correct PDE components and their parameters from synthetic data with known ground truth
- Found highest model evidence (ELBO = 2.07 × 10^6) with a 2-component mixture model on ADNI tau and amyloid PET data
- Single-component models (reaction-diffusion only: 1.96 × 10^6, diffusion only: 2.03 × 10^6) showed lower evidence than the mixture approach
- Identified distinct mechanistic subtypes within the ADNI cohort, suggesting heterogeneous disease dynamics

## Why This Works (Mechanism)
The method works by addressing a fundamental limitation in current mechanistic modeling approaches: the assumption of a single underlying PDE structure across heterogeneous populations. By using a mixture framework, BrainPhys can simultaneously learn multiple mechanistic patterns from the same dataset, allowing it to capture different disease dynamics that may coexist within a population. The physics-informed component ensures that the learned latent parameters have direct biological interpretation as quantities like diffusion and reaction rates. The variational autoencoder architecture enables efficient learning of these parameters from high-dimensional imaging data while maintaining uncertainty quantification through the probabilistic framework. The mixture weights provide a natural way to assign subjects to different mechanistic subtypes based on which PDE component best explains their observed disease patterns.

## Foundational Learning
1. **Partial Differential Equations in neurodegeneration**: Why needed - To mathematically model the spatiotemporal spread of pathological proteins; Quick check - Can the PDE accurately describe observed disease progression patterns in specific brain regions?
2. **Variational Autoencoder inference**: Why needed - To learn latent parameters from high-dimensional imaging data efficiently; Quick check - Does the ELBO converge during training and capture meaningful structure in the data?
3. **Mixture models for heterogeneity**: Why needed - To capture multiple mechanistic subtypes within the same population; Quick check - Does the model correctly identify known subtypes in synthetic data?
4. **Evidence lower bound (ELBO) optimization**: Why needed - To balance reconstruction accuracy with latent parameter regularization; Quick check - Does model selection using ELBO correctly identify the appropriate number of mixture components?
5. **Physics-informed modeling**: Why needed - To ensure learned parameters have biological interpretability; Quick check - Do the latent parameters correspond to known biological quantities like diffusion coefficients?

## Architecture Onboarding

Component map: PET data -> VAE encoder -> Mixture component selection -> Latent parameters -> PDE modeling -> Reconstruction

Critical path: The encoder maps imaging data to latent space, the mixture component determines which PDE structure to use, the latent parameters are transformed through the chosen PDE to generate predictions, and the decoder reconstructs the imaging data for comparison with observations.

Design tradeoffs: The mixture approach trades computational complexity for the ability to capture heterogeneity, while the physics-informed component trades flexibility for interpretability and biological relevance.

Failure signatures: Poor reconstruction quality suggests inadequate latent parameter learning, while unstable mixture assignments may indicate insufficient model capacity or noisy data