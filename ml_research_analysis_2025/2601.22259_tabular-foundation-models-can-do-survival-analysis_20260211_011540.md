---
ver: rpa2
title: Tabular Foundation Models Can Do Survival Analysis
arxiv_id: '2601.22259'
source_url: https://arxiv.org/abs/2601.22259
tags:
- survival
- time
- dynamic
- static
- setting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a classification-based framework for survival
  analysis that transforms time-to-event outcomes into binary classification problems
  by discretizing event times. This approach enables tabular foundation models (TFMs)
  to perform survival analysis through in-context learning without requiring explicit
  training or specialized loss functions.
---

# Tabular Foundation Models Can Do Survival Analysis

## Quick Facts
- arXiv ID: 2601.22259
- Source URL: https://arxiv.org/abs/2601.22259
- Authors: Da In Kim; Wei Siang Lai; Kelly W. Zhang
- Reference count: 40
- Primary result: Off-the-shelf TFMs with classification formulation outperform classical and deep learning baselines on 53 real-world survival datasets

## Executive Summary
This paper demonstrates that tabular foundation models (TFMs) can perform survival analysis through a novel classification-based framework that discretizes time-to-event outcomes into binary classification problems. By leveraging pretrained representations and in-context learning, TFMs achieve strong performance across multiple survival metrics without requiring specialized training or loss functions. The framework naturally handles right-censored observations and is theoretically justified under standard censoring assumptions.

## Method Summary
The authors propose transforming survival analysis into a sequence of binary classification tasks by discretizing event times into K intervals. Each observation becomes a sequence of binary predictions indicating whether the event occurs in each time interval, with censored observations treated as having missing labels at certain time points. This formulation enables the use of off-the-shelf TFMs for survival analysis through in-context learning without additional training. The approach proves theoretically sound, showing that minimizing binary cross-entropy loss recovers true survival probabilities under conditional independent censoring assumptions.

## Key Results
- TFMs with classification formulation achieved average C-Index of 0.677, Integrated AUC of 0.729, and Integrated Brier Score of 0.166 on 43 static datasets
- The approach proved particularly effective in small-data regimes, leveraging pretrained representations without requiring survival-specific training
- Classification-based method outperformed classical models (Cox PH, Random Survival Forest) and deep learning baselines across multiple metrics

## Why This Works (Mechanism)
The framework works by converting continuous survival prediction into discrete-time classification, enabling TFMs to leverage their powerful representation learning capabilities. The classification formulation naturally handles censoring by treating censored observations as having missing labels beyond their censoring time. Under standard censoring assumptions, the theoretical analysis proves that minimizing binary cross-entropy recovers true survival probabilities as sample size increases.

## Foundational Learning
- **Survival analysis fundamentals**: Understanding time-to-event modeling, censoring mechanisms, and survival/reliability functions is essential for applying this framework
  - Quick check: Can you explain the difference between Kaplan-Meier estimator and Cox proportional hazards?
- **Tabular foundation models**: Familiarity with pretrained transformer architectures for tabular data (MITRA, TabPFN, etc.) and their in-context learning capabilities
  - Quick check: What distinguishes TFMs from traditional deep learning approaches for tabular data?
- **Binary classification to survival conversion**: The mathematical transformation of survival probabilities into sequential binary predictions and back
  - Quick check: How does discretization granularity affect the approximation quality of survival curves?

## Architecture Onboarding

**Component map**: Raw features -> TFM encoder -> Sequence of binary classifiers -> Survival probabilities

**Critical path**: Feature encoding through TFM → Time interval discretization → Binary classification sequence → Survival probability calculation via cumulative product

**Design tradeoffs**: Discretization granularity vs. computational complexity; fixed vs. adaptive time intervals; handling of missing values in context windows

**Failure signatures**: Poor calibration when censoring is informative; boundary effects at discretization points; degraded performance with highly imbalanced event rates

**Three first experiments**:
1. Compare survival probability estimates from discretized TFMs against Kaplan-Meier curves on a small clinical dataset
2. Evaluate sensitivity to discretization granularity by varying K on a benchmark survival dataset
3. Test in-context learning performance across TFMs with different pretraining objectives on a standard survival benchmark

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can fine-tuning TFMs to explicitly optimize for ranking objectives (e.g., C-Index) improve discrimination performance over the classification-based BCE loss?
- Basis in paper: Authors state: "Directions for future work include (1) exploring fine-tuning and training TFMs explicitly for survival analysis, e.g., to explicitly optimize for ranking or C-Index."
- Why unresolved: Current framework uses BCE loss which correlates strongly with calibration (IBS) but only moderately with ranking (C-Index), as shown in Figure 3.
- What evidence would resolve it: Train TFMs with survival-specific ranking losses and compare C-Index against the BCE baseline across the same 43 datasets.

### Open Question 2
- Question: How can the discretized classification framework be extended to continuous-time survival modeling without losing TFM compatibility?
- Basis in paper: Listed as future work: "(2) investigating ways to leverage TFMs for continuous time survival modeling."
- Why unresolved: Current method partitions time into K intervals, introducing boundary effects and requiring granularity choices.
- What evidence would resolve it: Develop a continuous-time adaptation and evaluate whether it maintains competitive performance while eliminating discretization artifacts.

### Open Question 3
- Question: Can TFMs enable causal treatment effect estimation for time-to-event outcomes with right-censoring?
- Basis in paper: Authors propose "(3) leveraging TFMs for treatment effect analysis in time-to-event outcomes, a common use case for survival analysis."
- Why unresolved: Treatment effect estimation requires handling confounding and censoring simultaneously; current framework only addresses prediction.
- What evidence would resolve it: Extend the classification framework to estimate treatment-specific survival curves and compare against established causal survival methods.

### Open Question 4
- Question: How robust is the classification-based approach when the conditional independent censoring assumption is violated?
- Basis in paper: Theoretical consistency (Theorem 3.1) depends on Assumption 2.1, but real-world censoring may be informative.
- Why unresolved: Violations could bias survival probability estimates, yet this was not empirically tested.
- What evidence would resolve it: Simulate datasets with varying degrees of informative censoring and measure degradation in calibration and discrimination.

## Limitations
- Discretization of continuous time introduces computational complexity and potential boundary effects
- Theoretical assumptions require conditional independent censoring, which may not hold in practice
- Evaluation primarily limited to tabular data, with potential limitations for other data modalities

## Confidence
- **High confidence**: Mathematical proof that BCE minimization recovers true survival probabilities under standard censoring assumptions
- **Medium confidence**: Empirical demonstration of TFM performance across 53 datasets, though improvement magnitude varies
- **Medium confidence**: Claims about small-data regime effectiveness are supported but could benefit from more systematic investigation

## Next Checks
1. **Temporal Granularity Sensitivity Analysis**: Systematically evaluate how different discretization schemes affect model performance across datasets with varying event time distributions to identify optimal discretization strategies.

2. **Cross-Modality Validation**: Apply the classification-based framework to non-tabular survival analysis tasks (e.g., medical imaging or text-based clinical notes) to assess generalizability beyond the current tabular focus.

3. **Censoring Mechanism Robustness**: Test model performance under varying censoring rates and mechanisms (non-random censoring) to validate theoretical assumptions about censoring independence in practical scenarios.