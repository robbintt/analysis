---
ver: rpa2
title: 'Jawaher: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking'
arxiv_id: '2503.00231'
source_url: https://arxiv.org/abs/2503.00231
tags:
- proverbs
- cultural
- arabic
- alefisolated
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Jawaher, a new benchmark for assessing Large
  Language Models' (LLMs) ability to comprehend and interpret Arabic proverbs. Jawaher
  includes 10,037 proverbs from 20 Arabic dialects, each paired with idiomatic translations
  and explanations in English and Arabic.
---

# Jawaher: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking

## Quick Facts
- **arXiv ID**: 2503.00231
- **Source URL**: https://arxiv.org/abs/2503.00231
- **Reference count**: 40
- **One-line result**: New benchmark for evaluating LLMs' understanding of Arabic proverbs across 20 dialects, revealing strong translation performance but weak cultural explanation generation.

## Executive Summary
Jawaher introduces a new benchmark for assessing Large Language Models' ability to comprehend and interpret Arabic proverbs. The dataset includes 10,037 proverbs from 20 Arabic dialects, each paired with idiomatic translations and explanations in English and Arabic. Extensive experiments on both open-source (Llama, Gemma) and closed-source (GPT-4o, Gemini, Claude, Cohere) models reveal that while LLMs perform well in idiomatic translation tasks, they struggle significantly with providing culturally nuanced and contextually relevant explanations.

## Method Summary
The Jawaher benchmark uses a zero-shot evaluation setup where models are prompted to translate Arabic proverbs to English and generate explanations in both languages. The evaluation uses 10 samples per dialect (200 total) from the dataset, which contains proverbs paired with English translations (equivalent, meaning, literal) and explanations. Models are tested using both automatic metrics (BERTScore for all tasks, BLEURT for English tasks) and human evaluation on 1-5 scales for accuracy, idiomaticity, clarity, correctness, depth, and cultural relevance.

## Key Results
- LLMs achieve high idiomatic translation scores (GPT-4o: 4.81/5 idiomaticity) but significantly lower scores for cultural explanations
- Arabic explanation task performance drops across all models (BERTScore F1: 66-69)
- Human evaluation reveals models consistently fail to capture stories behind proverbs and provide culturally relevant context
- Dialectal variations impact performance, with some dialects showing stronger representation than others

## Why This Works (Mechanism)

### Mechanism 1: Cultural Idiomatic Mapping via Bilingual Anchors
- Claim: Providing both idiomatic English translations and native-language (Arabic) explanations creates a bilingual anchor that improves translation accuracy even when cultural nuance is missed.
- Mechanism: The dataset pairs each proverb with an English equivalent (idiomatic), English explanation, and Arabic explanation. Models likely leverage the Arabic explanation (high-resource context via code-mixing or cross-lingual transfer) and the English translation to produce fluent outputs.
- Core assumption: LLMs perform better on translation when grounded by source-language context, even for figurative language, relying on pattern matching between the proverb and its provided translations.
- Evidence anchors: Abstract confirms models generate idiomatically accurate translations but struggle with culturally nuanced explanations. Section 5.2 shows higher idiomaticity scores for translation tasks.

### Mechanism 2: Explaining via Contextual Expansion
- Claim: The task of generating explanations is harder because it requires retrieving and synthesizing implicit cultural/historical context not present in the proverb text itself.
- Mechanism: Models must perform contextual expansion, retrieving world knowledge associated with the proverb's keywords and synthesizing it. Failure indicates lack of specific cultural world knowledge.
- Core assumption: Successful explanation generation requires a knowledge base that includes cultural narratives and historical anecdotes behind the proverbs.
- Evidence anchors: Section 3.2 describes explanations cover "stories behind the proverbs," and Section 5.2 reports models don't include these stories in outputs.

### Mechanism 3: Dialectal Clustering Reveals Cultural Knowledge Organization
- Claim: Embedding-based clustering of proverbs reveals that cultural themes and dialectal similarities are correlated, providing a way to measure cultural representation in model latent space.
- Mechanism: Multilingual text embedding models and dimensionality reduction visualize proverbs, finding clusters corresponding to themes and dialect groups.
- Core assumption: The structure of the embedding space reflects the model's learned organization of cultural and linguistic concepts.
- Evidence anchors: Section 3.1 shows Figure 3 reveals groupings representing different themes, and Figure 4 illustrates shared cultural themes and regional variation across dialects.

## Foundational Learning

- **Concept**: Figurative Language Processing
  - Why needed: The entire paper focuses on proverbs, a form of non-literal language. Understanding idiomatic vs. literal meaning is essential.
  - Quick check: What is the difference between an idiom and a proverb? (A proverb is a complete sentence expressing a general truth, while an idiom is a phrase with non-compositional meaning.)

- **Concept**: Cross-Lingual Transfer & Multilingual LLMs
  - Why needed: The work evaluates mLLMs (Llama, GPT-4o, etc.). The core problem is the "cultural gap" where Anglo-centric biases reduce performance on non-Western languages.
  - Quick check: Why might a model trained predominantly on English data struggle with an Arabic proverb? (Lack of cultural training data, biases in alignment, and weaker representations for low-resource dialects.)

- **Concept**: Benchmarking Paradigms (Zero-shot, Automatic vs. Human Eval)
  - Why needed: The paper uses zero-shot setup to test "inherent capacity" and employs both automatic metrics and human evaluation with specific criteria.
  - Quick check: Why is BLEURT alone insufficient for evaluating proverb explanations? (It measures semantic similarity to a reference but can miss nuances in cultural relevance, detail, and "correctness" as defined by human experts.)

## Architecture Onboarding

- **Component map**: Jawaher Dataset (10,037 proverbs) -> Zero-shot Prompting (Figure 5 template) -> Model Inference (Llama/Gemma/GPT-4o/Gemini/Claude/Cohere) -> Evaluation (Automatic: BERTScore/BLEURT, Human: 1-5 scales)

- **Critical path**:
  1. Data Ingestion: Sample proverbs from each dialect
  2. Prompting: Format proverb into zero-shot prompt
  3. Inference: Get model output for translation and explanation tasks
  4. Evaluation: Compute automatic metrics and run human evaluation
  5. Analysis: Correlate model performance with dialect, theme, and task type

- **Design tradeoffs**:
  - Including equivalent, meaning, and literal translations enriches dataset but complicates consistent evaluation
  - Zero-shot approach tests inherent knowledge but may underestimate model potential after adaptation
  - Human evaluation criteria (5-point scale for "cultural relevance") is subjective

- **Failure signatures**:
  - Translation Failure: Literal translation that misses idiomatic meaning (low idiomaticity score)
  - Explanation Failure: Short, generic outputs lacking detail or missing historical/cultural backstory
  - Dialectal Failure: Model performs well on MSA-like proverbs but fails on highly dialectal ones

- **First 3 experiments**:
  1. Baseline Reproduction: Run zero-shot prompt on small sample (10 proverbs from 5 dialects) with Gemma-2 and GPT-4o, compute BLEURT/BERTScore
  2. Human-AI Alignment Check: Run same outputs through LLM-as-judge using evaluation criteria, compare to human results to quantify alignment gap
  3. Dialectal Difficulty Probe: Group dataset by dialect cluster, run Arabic explanation task with GPT-4o, plot performance (BERTScore) per cluster

## Open Questions the Paper Calls Out

- **Open Question 1**: Does fine-tuning LLMs on proverb-specific datasets significantly enhance their performance on explanation tasks compared to zero-shot baselines?
  - Basis: Section 7 notes future work could explore fine-tuning to enhance performance
  - Why unresolved: Unclear if low scores in "depth and detail" are fundamental limitations or result of evaluation setting
  - What evidence would resolve: Comparison of BERTScore and human evaluation metrics between zero-shot and fine-tuned models

- **Open Question 2**: To what extent do dedicated Arabic-centric LLMs outperform general multilingual models in capturing dialect-specific nuances and historical contexts?
  - Basis: Section 7 notes models used are not fully optimized for Arabic or dialectal variations
  - Why unresolved: Paper benchmarks general models but doesn't test Arabic-native models
  - What evidence would resolve: Benchmarking Arabic-native models (Jais, ACEGPT) on Jawaher using "Cultural Relevance and Sensitivity" criteria

- **Open Question 3**: Can advanced prompting strategies (e.g., Chain-of-Thought) bridge the performance gap between high idiomatic translation scores and low cultural explanation scores?
  - Basis: Conclusion highlights models excel at translation but struggle to generate explanations capturing "stories behind the proverbs"
  - Why unresolved: Unclear if cultural knowledge is missing from weights or if standard prompt fails to elicit deep reasoning
  - What evidence would resolve: Evaluating different prompt engineering techniques to see if "Correctness" and "Cultural Relevance" scores improve without retraining

## Limitations

- Zero-shot setup may underestimate LLM capabilities; fine-tuning or retrieval augmentation could improve performance on explanation tasks
- Human evaluation criteria are subjective and not fully validated beyond inter-annotator agreement scores
- Dataset limited to 10 samples per dialect for evaluation, which may not fully capture dialectal variation

## Confidence

- **High**: Core finding that LLMs struggle with culturally nuanced explanations (Section 5.2) is well-supported by human evaluation scores
- **Medium**: Mechanism that bilingual anchors improve translation but not explanation is plausible but not directly tested
- **Medium**: Embedding-based clustering analysis provides suggestive evidence of cultural organization but doesn't validate model internal representations

## Next Checks

1. **Prompt Ablation Study**: Systematically remove Arabic explanation from prompt and re-run translation task to test if bilingual anchor is critical for idiomaticity
2. **Dialectal Performance Mapping**: Run Arabic explanation task on all 200 samples and plot performance (BERTScore) by dialect cluster to confirm hypothesis about low-resource dialect performance
3. **RAG Evaluation**: Implement retrieval-augmented generation pipeline using Jawaher's explanations as knowledge base and re-evaluate explanation quality to quantify gap between zero-shot and retrieval-augmented performance