---
ver: rpa2
title: The influence of missing data mechanisms and simple missing data handling techniques
  on fairness
arxiv_id: '2503.07313'
source_url: https://arxiv.org/abs/2503.07313
tags:
- fairness
- imputation
- missing
- data
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how missing data mechanisms and handling
  methods affect fairness in machine learning algorithms. Using three benchmark fairness
  datasets (German Credit, Adult Income, COMPAS), the authors artificially create
  missing values under MCAR, MAR, and MNAR mechanisms, then apply listwise deletion
  and single imputation methods (mode, regression, knn).
---

# The influence of missing data mechanisms and simple missing data handling techniques on fairness

## Quick Facts
- arXiv ID: 2503.07313
- Source URL: https://arxiv.org/abs/2503.07313
- Reference count: 4
- The paper investigates how missing data mechanisms and handling methods affect fairness in machine learning algorithms

## Executive Summary
This study examines how different missing data mechanisms (MCAR, MAR, MNAR) and simple handling techniques impact fairness in machine learning models. Using three benchmark datasets (German Credit, Adult Income, COMPAS), the authors artificially create missing values and apply listwise deletion and single imputation methods before training various models. The research reveals that the missingness mechanism significantly influences fairness outcomes, with MAR mechanism having particularly pronounced effects when missingness occurs in outcome-related variables. The findings demonstrate that simpler methods like listwise deletion and mode imputation often achieve higher fairness metrics than more complex approaches, though sometimes at the cost of reduced accuracy.

## Method Summary
The study uses three benchmark fairness datasets and artificially introduces missing values according to MCAR, MAR, and MNAR mechanisms. Listwise deletion and single imputation methods (mode, regression, knn) are applied to handle the missing data. Four classification models (logistic regression, random forests, boosting, SVM) are trained and evaluated for both accuracy and fairness using demographic parity, equality of opportunity, and predictive equality metrics. The analysis examines how different combinations of missing data mechanisms and handling techniques affect fairness outcomes across the datasets.

## Key Results
- MAR mechanism significantly impacts fairness when missingness occurs in outcome-related variables
- Listwise deletion and mode imputation often yield higher fairness than knn imputation, albeit with potential accuracy trade-offs
- Mode imputation combined with MAR mechanism shows consistently high fairness across datasets
- Fairness effects are highly dependent on the specific dataset being used

## Why This Works (Mechanism)
The interaction between missing data mechanisms and handling techniques affects the representativeness and bias of the training data, which directly influences model fairness. When data is missing not at random (MNAR) or missing at random (MAR) with respect to sensitive attributes or outcomes, improper handling can amplify existing biases. Simpler methods like listwise deletion may inadvertently preserve fairness by maintaining the original data distribution, while complex imputation methods may introduce additional bias through the imputation process itself.

## Foundational Learning
- **Missing Data Mechanisms**: Understanding MCAR, MAR, and MNAR is crucial because different mechanisms require different handling approaches to maintain fairness. Quick check: Identify which mechanism applies to your dataset before choosing handling method.
- **Fairness Metrics**: Demographic parity, equality of opportunity, and predictive equality measure different aspects of algorithmic fairness. Quick check: Select metrics aligned with your specific fairness goals and regulatory requirements.
- **Imputation Methods**: Simple methods (listwise deletion, mode) versus complex methods (knn, multiple imputation) have different trade-offs for fairness. Quick check: Compare fairness outcomes across different imputation methods before finalizing approach.

## Architecture Onboarding
**Component Map**: Data preprocessing -> Missing data handling -> Model training -> Fairness evaluation
**Critical Path**: Missing data mechanism identification → Appropriate handling technique selection → Model training → Fairness metric calculation
**Design Tradeoffs**: Simpler methods may preserve fairness but sacrifice accuracy; complex methods may improve accuracy but introduce bias
**Failure Signatures**: Unchecked MNAR/MAR mechanisms leading to biased imputation and degraded fairness metrics
**First Experiments**: 1) Compare fairness outcomes across MCAR, MAR, MNAR mechanisms with identical handling methods, 2) Test listwise deletion vs. mode imputation on MAR mechanism datasets, 3) Evaluate knn imputation impact on demographic parity across all three datasets

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Artificial generation of missing values may not reflect real-world missing data patterns, potentially limiting generalizability
- Focus on simple imputation methods excludes more sophisticated approaches like multiple imputation
- Analysis limited to three specific datasets and four model types, which may not generalize across all domains

## Confidence
- High confidence: MAR mechanism significantly impacts fairness when missingness occurs in outcome-related variables
- Medium confidence: Simpler methods like listwise deletion and mode imputation often yield higher fairness than complex methods like knn
- Medium confidence: Fairness effects are dataset-dependent

## Next Checks
1. Validate findings on additional real-world datasets with naturally occurring missing data rather than artificially induced missingness
2. Extend analysis to include multiple imputation and machine learning-based imputation methods to assess if findings hold
3. Test across a broader range of machine learning algorithms including deep learning models to examine generalizability