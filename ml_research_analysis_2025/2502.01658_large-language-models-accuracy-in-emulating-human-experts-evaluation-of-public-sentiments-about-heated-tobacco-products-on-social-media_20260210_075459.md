---
ver: rpa2
title: Large Language Models' Accuracy in Emulating Human Experts' Evaluation of Public
  Sentiments about Heated Tobacco Products on Social Media
arxiv_id: '2502.01658'
source_url: https://arxiv.org/abs/2502.01658
tags:
- messages
- anti
- sentiment
- accuracy
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the accuracy of Large Language Models (LLMs),
  specifically GPT-3.5 and GPT-4 Turbo, in replicating human sentiment analysis of
  social media messages about heated tobacco products (HTPs). Using 1,000 human-labeled
  messages (500 from Facebook and 500 from Twitter), the models classified messages
  into anti-HTP, pro-HTP, and neutral categories.
---

# Large Language Models' Accuracy in Emulating Human Experts' Evaluation of Public Sentiments about Heated Tobacco Products on Social Media

## Quick Facts
- arXiv ID: 2502.01658
- Source URL: https://arxiv.org/abs/2502.01658
- Authors: Kwanho Kim; Soojong Kim
- Reference count: 40
- Primary result: GPT-4 Turbo achieved 81.7% accuracy for Facebook and 77.0% for Twitter in sentiment analysis of HTP-related social media messages

## Executive Summary
This study evaluated Large Language Models (LLMs) for replicating human sentiment analysis of social media messages about heated tobacco products (HTPs). Using 1,000 human-labeled messages, the research compared GPT-3.5 and GPT-4 Turbo in classifying messages into anti-HTP, pro-HTP, and neutral categories. GPT-4 Turbo significantly outperformed GPT-3.5, achieving 81.7% accuracy for Facebook and 77.0% for Twitter. The study found that GPT-4 Turbo's accuracy plateaued at just three response instances, reaching 99% of the accuracy achieved with twenty instances.

## Method Summary
The study used 1,000 human-labeled social media messages (500 Facebook long-form, 500 Twitter short-form) pre-categorized into anti-HTP, pro-HTP, neutral, mixed, and irrelevant categories. The researchers implemented a zero-shot prompting approach using a standardized prompt template with coding instructions. GPT-3.5 and GPT-4 Turbo were accessed via API to generate multiple response instances (m=1, 3, 5, 7, 9, 11, 20) per message. Machine decisions were determined through majority voting across response instances, with tie-breaking via additional random sampling. Accuracy was calculated as the mean human-machine concurrence across 1,000 iterations for each m value.

## Key Results
- GPT-4 Turbo achieved 81.7% accuracy for Facebook and 77.0% for Twitter, significantly outperforming GPT-3.5 (61.2% and 57.0%, respectively)
- GPT-4 Turbo demonstrated high accuracy with just three response instances, reaching 99% of the accuracy of twenty instances
- GPT-4 Turbo showed consistent accuracy across sentiment categories, while GPT-3.5 had lower accuracy for pro-HTP and neutral messages
- Neutral sentiment classification remained more challenging for both models, with ~15-20% lower accuracy compared to polarized categories

## Why This Works (Mechanism)

### Mechanism 1: Majority Voting for Stochastic Output Stabilization
LLMs generate variable outputs due to probabilistic token selection. By generating multiple independent responses and selecting the majority label, random classification errors are suppressed while consistent predictions are reinforced. The study shows accuracy improves with more instances, though GPT-4 Turbo reaches 99% of maximum accuracy with just m=3.

### Mechanism 2: Architecture-Specific Classification Capability
GPT-4 Turbo's superior architecture (improved training data, larger parameters, enhanced instruction-following) translates to better semantic understanding of nuanced sentiment expressions. This manifests as higher overall accuracy and reduced false "irrelevant" classifications compared to GPT-3.5.

### Mechanism 3: Category-Specific Accuracy Variance
Neutral sentiment classification remains consistently more difficult than polarized sentiment due to lack of explicit affective markers. GPT-4 Turbo achieved ~68-70% accuracy on neutral messages versus ~79-86% for anti/pro categories, stemming from definitional ambiguity and factual statements being misinterpreted as positive.

## Foundational Learning

- **Latent Coding / Content Analysis**: Sentiment analysis requires inferring underlying attitudes from text rather than keyword matching. Understanding this interpretive nature is essential for grasping why human-GPT comparison matters and why inter-coder reliability (Cohen's Kappa = .885-.938) is the benchmark.
  - Quick check: Can you explain why sentiment classification requires interpretive judgment rather than purely keyword matching?

- **Probabilistic Token Generation in LLMs**: The methodology of using multiple response instances relies on understanding that LLMs are non-deterministic samplers from learned probability distributions over vocabulary.
  - Quick check: If you prompt an LLM twice with identical input, why might you get different outputs?

- **Majority Voting / Ensemble Methods**: The core innovation aggregates multiple stochastic outputs to stabilize predictions, requiring understanding trade-offs between computational cost (more API calls) and accuracy gains.
  - Quick check: Why does majority voting work better when the correct answer appears in >50% of individual samples?

## Architecture Onboarding

- **Component map**: Human labeling -> Prompt construction -> Multi-instance LLM inference -> Majority aggregation -> Accuracy calculation -> Category-specific analysis
- **Critical path**: Human labeling → Prompt construction → Multi-instance LLM inference → Majority aggregation → Accuracy calculation → Category-specific analysis
- **Design tradeoffs**:
  1. **m value selection**: Higher m increases accuracy but with diminishing returns; m=3 achieves ~99% of m=20 accuracy for GPT-4 Turbo
  2. **Prompt fidelity vs optimization**: Using identical coding scheme as humans enables direct comparison but may underperform optimized prompts with examples
  3. **Model selection**: GPT-4 Turbo more accurate but higher cost; GPT-3.5 shows category bias (over-classifying as NEU/IR)

- **Failure signatures**:
  1. **Systematic neutral bias**: GPT-3.5 misclassifies ~25% of anti messages, with 61% of errors labeled NEU
  2. **Category imbalance**: Pro messages have lower accuracy than anti in GPT-3.5 (54.4% vs 75.5% for Facebook)
  3. **Neutral underperformance**: Both models show ~15-20% lower accuracy on NEU vs anti/pro
  4. **Irrelevant over-classification**: GPT-3.5 labels 19% of relevant messages as IR; GPT-4 Turbo reduces this to ~1%

- **First 3 experiments**:
  1. **Establish baseline with m=3**: Run GPT-4 Turbo on 100-message sample with 3 response instances; verify accuracy approaches 80% threshold before scaling to full dataset
  2. **Category-specific error analysis**: Manually review 20 NEU misclassifications to identify patterns (e.g., factual statements with positive-coded words like "patented" being misclassified as PRO)
  3. **Prompt variant test**: Compare current zero-shot prompt against few-shot prompt with 2-3 labeled examples per category on held-out 50-message subset to quantify potential accuracy gains

## Open Questions the Paper Calls Out

### Open Question 1
What mechanisms drive the lower accuracy in neutral sentiment classification compared to anti- and pro-HTP classifications, and how can these discrepancies be mitigated? The study identified that neutral messages are often misinterpreted as positive or irrelevant, but did not analyze the specific linguistic features causing this bias.

### Open Question 2
Does few-shot prompting significantly improve LLM accuracy in sentiment analysis compared to the zero-shot approach utilized in this study? The research restricted its method to instructions mirroring the human codebook to ensure direct comparability, leaving the impact of providing labeled examples untested.

### Open Question 3
Do specialized medical LLMs (e.g., Med-PaLM, BioMedLM) outperform general-purpose models like GPT-4 Turbo in analyzing public health sentiment on social media? The research focused exclusively on OpenAI's general-purpose GPT models due to their accessibility and popularity, without evaluating domain-specific alternatives.

### Open Question 4
Can a hybrid human-LLM coding procedure effectively optimize the trade-off between annotation accuracy and labor efficiency? The study evaluated LLMs as standalone classifiers against a human ground truth, but did not test iterative workflows where humans intervene only on low-confidence or split decisions.

## Limitations
- The study only evaluated zero-shot prompting without exploring few-shot or fine-tuned approaches that might yield higher accuracy
- Performance may not generalize to other public health topics or different social media platforms not included in the study
- No assessment of computational cost-benefit trade-offs for generating multiple response instances

## Confidence

- **High Confidence**: GPT-4 Turbo significantly outperforms GPT-3.5 for HTP sentiment classification (81.7% vs 61.2% for Facebook; 77.0% vs 57.0% for Twitter)
- **Medium Confidence**: GPT-4 Turbo's accuracy is consistent across sentiment categories, though neutral messages show systematically lower performance (~68-70%)
- **Medium Confidence**: The claim that m=3 achieves 99% of m=20 accuracy for GPT-4 Turbo is based on the specific dataset and may not generalize

## Next Checks

1. **Cross-Domain Validation**: Test GPT-4 Turbo's performance on sentiment analysis of social media messages about other controversial public health topics (e.g., COVID-19 vaccines, vaping) to assess generalizability beyond HTPs.

2. **Cost-Benefit Analysis**: Conduct a resource utilization study comparing accuracy gains against computational costs for different values of m, determining the optimal trade-off point for practical implementation.

3. **Prompt Optimization Study**: Compare zero-shot prompting (as used in this study) against few-shot prompting with labeled examples to quantify potential accuracy improvements and determine if the 81.7% benchmark can be exceeded with minimal additional effort.