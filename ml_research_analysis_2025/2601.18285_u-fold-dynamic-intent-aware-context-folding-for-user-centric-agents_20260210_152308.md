---
ver: rpa2
title: 'U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents'
arxiv_id: '2601.18285'
source_url: https://arxiv.org/abs/2601.18285
tags:
- user
- context
- u-fold
- agent
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "U-Fold introduces a dynamic, intent-aware context-folding framework\
  \ for user-centric LLM agents that retains the full dialogue and tool-call history\
  \ but constructs a compact working context at each turn using two lightweight modules:\
  \ (1) Conversation Summarization, which tracks dialogue evolution and maintains\
  \ an up-to-date to-do list, and (2) Dynamic Data Extraction, which selectively retrieves\
  \ task-relevant structured information from tool outputs. Experiments on \U0001D70F\
  -bench, \U0001D70F\xB2-bench, and VitaBench show U-Fold consistently outperforms\
  \ ReAct (71.4% win rate in long-context settings) and prior folding baselines (up\
  \ to +27.0%), particularly in long, noisy, multi-turn tasks."
---

# U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents

## Quick Facts
- arXiv ID: 2601.18285
- Source URL: https://arxiv.org/abs/2601.18285
- Reference count: 15
- Primary result: U-Fold achieves 71.4% win rate in long-context settings, outperforming ReAct by up to 27.0% on ðœ-bench, ðœÂ²-bench, and VitaBench

## Executive Summary
U-Fold introduces a dynamic context-folding framework for LLM agents that maintains full dialogue history while constructing compact working contexts per turn. The approach uses two lightweight modules: Conversation Summarization that tracks dialogue evolution with explicit to-do lists, and Dynamic Data Extraction that selectively retrieves task-relevant structured information from tool outputs. Experiments demonstrate U-Fold's superiority over ReAct and prior folding baselines, particularly in long, noisy, multi-turn tasks, by reducing comprehension and omission errors through intent-aligned summaries.

## Method Summary
U-Fold addresses context explosion in user-centric agents by retaining full interaction history while generating dynamic working contexts each turn. It employs a Conversation Summarization module that outputs narrative summaries plus explicit to-do lists of pending objectives, and a Dynamic Data Extraction module that filters tool outputs to retain only fields relevant to the current to-do list. The framework maintains a "cold storage" of raw interaction logs while feeding the agent a "hot" context that prevents irreversible information loss seen in static summarization approaches.

## Key Results
- U-Fold achieves 71.4% win rate in long-context settings, significantly outperforming ReAct baseline
- Outperforms prior folding baselines by up to +27.0% on benchmark tasks
- Ablation studies confirm both Conversation Summarization and Dynamic Data Extraction modules are essential for performance gains
- Particularly effective in long, noisy, multi-turn tasks where traditional agents struggle with context management

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Re-Extraction from Full History
U-Fold maintains complete interaction history while generating per-turn working contexts, preventing the irreversible information loss of static summarization. When new intent is detected, the data extraction module re-queries full history to pull relevant past details that might have been omitted in general summaries. This approach assumes the cost of maintaining history and re-processing is lower than the error cost of re-asking users or failing tasks due to lost context.

### Mechanism 2: Explicit To-Do List Generation for Intent Tracking
The summarization module decomposes user intent into structured to-do lists, reducing drift in multi-turn conversations compared to narrative summaries alone. This structured state helps distinguish between "what was discussed" and "what remains to be done," aligning planning logic with evolving user goals. The approach assumes the LLM can accurately infer latent goals and decompose complex requests into actionable sub-tasks.

### Mechanism 3: Structure-Aware Noise Filtering
The extraction module selectively filters tool outputs to preserve decision-critical data while cutting token count more effectively than text truncation. By filtering raw tool observations to keep only parameters relevant to the current to-do list, U-Fold preserves essential information while reducing context size. This assumes utility of tool outputs is strictly determined by current intent state, making irrelevant fields safe to discard from immediate reasoning context.

## Foundational Learning

- **Concept: ReAct Loop (Reasoning + Acting)**
  - Why needed: U-Fold is an optimization layer on standard ReAct agents; understanding base context growth cost is essential to value folding mechanism
  - Quick check: Can you trace how a standard ReAct agent accumulates tokens over 10 turns of tool calls?

- **Concept: Context Window vs. Working Memory**
  - Why needed: U-Fold distinguishes between model's hard limit (window) and information currently useful for inference (working context)
  - Quick check: Why does smaller "working context" improve reasoning accuracy even if full context fits in window?

- **Concept: POMDP (Partially Observable Markov Decision Process)**
  - Why needed: The paper formally models agent environment as POMDP; understanding "state" vs. "observation" clarifies why "Summary + To-Do" is state approximation
  - Quick check: In U-Fold, does "Summarized Context" represent full state S or just observation history O?

## Architecture Onboarding

- **Component map:** Full History Store -> Summarization Module -> Extraction Module -> Agent Core
- **Critical path:** New User Query -> Summarizer updates intent state -> Extractor pulls relevant tool data -> Agent Core decides action. Latency dominated by 3 sequential LLM calls per turn.
- **Design tradeoffs:** 
  - Latency vs. Recall: U-Fold adds 2 inference steps per turn to improve recall, introducing noticeable "thinking" delay in streaming chat
  - Module Sizing: Same backbone suggested for all modules, but smaller models (Qwen3-4B) struggle with extraction, potentially requiring larger "Better Folder"
- **Failure signatures:**
  - Infinite Loop: Agent Core fails to find tool ID in Filtered Context and keeps calling same retrieval tool
  - Intent Drift: Summarization Module fails to update To-Do list after user correction, causing pursuit of obsolete goal
  - Extraction Hallucination: Extraction module includes incorrect values or IDs, leading to invalid actions
- **First 3 experiments:**
  1. Baseline Context Growth: Run standard ReAct agent on VitaBench "In-store" scenario until context limit hit, logging token count growth curve
  2. Ablation on Extraction: Disable Data Extraction module, feed full tool logs to agent, measure drop in success rate on OTA domain
  3. Hard Setting Stress Test: Run U-Fold on "Hard" setting (inflated tool outputs), compare "Win Rate" vs. "Token Usage" against ReAct baseline

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness contingent on summarization and extraction modules' ability to accurately track intent and filter relevant information
- Vulnerable to "Extraction Hallucination" where incorrect values/IDs lead to invalid agent actions
- Assumes tool outputs can be meaningfully decomposed into structured fields, which may not hold for all API types or unstructured data

## Confidence
- **High Confidence:** Core mechanism of dynamic context folding is well-grounded in prior work on context management for long-horizon agents; ablation studies provide strong evidence for both module contributions
- **Medium Confidence:** Claim that U-Fold reduces comprehension and omission errors is supported by error analysis, but specific error categories and quantification could be more detailed
- **Low Confidence:** Paper does not provide rigorous analysis of computational overhead from additional LLM calls; scalability to very long histories is not thoroughly explored

## Next Checks
1. **Latency Benchmarking:** Measure end-to-end latency of U-Fold vs standard ReAct agent on same benchmarks, accounting for summarization and extraction costs to quantify trade-off between improved recall and increased response time
2. **History Size Stress Test:** Systematically vary conversation history length and measure impact on extraction module accuracy and overall U-Fold success rate to reveal scalability limits
3. **Generalization to Unstructured Data:** Evaluate U-Fold on dataset with unstructured tool outputs (natural language descriptions) to assess extraction module robustness and identify failure modes