---
ver: rpa2
title: 'Beyond Self-Consistency: Loss-Balanced Perturbation-Based Regularization Improves
  Industrial-Scale Ads Ranking'
arxiv_id: '2502.18478'
source_url: https://arxiv.org/abs/2502.18478
tags:
- regularization
- learning
- data
- lspr
- ranking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Loss-Balanced Small Perturbation Regularization
  (LSPR), a novel perturbation-based regularization method designed for industrial-scale
  ads ranking systems. LSPR differs from Self-Consistency Regularization (SCR) by
  perturbing data points and including them in training with reduced weights rather
  than adding an auxiliary loss term.
---

# Beyond Self-Consistency: Loss-Balanced Perturbation-Based Regularization Improves Industrial-Scale Ads Ranking

## Quick Facts
- arXiv ID: 2502.18478
- Source URL: https://arxiv.org/abs/2502.18478
- Reference count: 11
- Primary result: LSPR achieves 0.1%-0.2% relative NE gains in industrial-scale ads ranking

## Executive Summary
This work introduces Loss-Balanced Small Perturbation Regularization (LSPR), a novel perturbation-based regularization method designed for industrial-scale ads ranking systems. LSPR differs from Self-Consistency Regularization (SCR) by perturbing data points and including them in training with reduced weights rather than adding an auxiliary loss term. The method was successfully deployed in a billion-scale recommendation system, addressing challenges such as multiple surfaces, geological locations, and diverse clients. Experiments demonstrated that LSPR consistently outperformed SCR across various setups, achieving 0.1%-0.2% relative Normalized Entropy (NE) gains in offline experiments. Online testing further validated these improvements, with a 0.1%-0.2% relative gain in top-line metrics. LSPR's simplicity, requiring only three hyperparameters, makes it scalable and effective for large-scale industrial applications. This is the first successful integration of perturbation-based regularization in industrial-scale recommendation systems, offering a promising direction for improving generalization and robustness in ads ranking.

## Method Summary
LSPR implements perturbation-based regularization by creating perturbed copies of training data (Gaussian noise for dense features, dropout for sparse features) and including them in the training batch with reduced loss contribution λ < 1. The perturbed samples use the same supervised loss and label as originals but scaled down, creating a weighted-loss approach rather than SCR's auxiliary loss formulation. This maintains better gradient alignment with optimal parameters while providing regularization benefits. The method requires only three hyperparameters: dense feature perturbation scale, sparse feature dropout rate, and loss weight λ.

## Key Results
- LSPR achieved 0.1%-0.2% relative Normalized Entropy gains in offline experiments
- Online testing validated improvements with 0.1%-0.2% relative gain in top-line metrics
- LSPR consistently outperformed SCR baseline across different model architectures and ranking stages
- Successfully deployed in billion-scale recommendation system with diverse clients and geographical locations

## Why This Works (Mechanism)

### Mechanism 1
LSPR improves generalization by treating perturbed samples as weighted training examples rather than enforcing prediction consistency through auxiliary loss. Creates perturbed copies of training data, then includes them in the training batch with reduced loss contribution λ < 1. This reduces disruption to primary learning dynamics while still providing regularization benefit.

### Mechanism 2
LSPR achieves better gradient alignment with optimal model parameters than SCR. Numerical analysis on linear models shows LSPR's weight updates maintain higher cosine similarity to optimal weight W* and lower trace-norm error compared to SCR. SCR's auxiliary MSE loss pushes gradient direction away from supervised objective; LSPR keeps gradients aligned while adding regularization.

### Mechanism 3
Effective regularization for hybrid feature types requires distribution-matched perturbation strategies. Dense features receive Gaussian noise injection; sparse features receive dropout masking. This preserves distributional semantics while introducing perturbations. SCR applied same strategy but with auxiliary loss; LSPR reuses perturbation methods with weighted-loss approach.

## Foundational Learning

- **Self-Consistency Regularization (SCR)**: Why needed here: SCR is the direct predecessor and comparison baseline; understanding its auxiliary-loss approach clarifies why LSPR's weighted-loss alternative was designed. Quick check: Why might minimizing MSE between original and perturbed predictions conflict with minimizing supervised loss on sparse-label data?

- **Noise Injection as Regularization**: Why needed here: Paper cites Bishop (1995) showing training with noise ≈ Tikhonov regularization; foundational theory explaining LSPR's effectiveness. Quick check: How does adding noise to inputs during training mathematically relate to L2 weight regularization in linear models?

- **Multi-stage Ads Ranking Architecture**: Why needed here: LSPR was evaluated across retrieval, early ranking, and final ranking with different gains (0.14%-0.35%); stage-specific model complexity affects regularization impact. Quick check: Why might simpler early-stage models benefit more from perturbation regularization than complex final-stage rankers?

## Architecture Onboarding

- **Component map**: Perturbation generator -> Loss combiner -> Training loop
- **Critical path**: 1. Sample training batch 2. Generate perturbations matching feature distributions 3. Forward pass on both original and perturbed batches 4. Combine losses with weight λ for perturbed portion 5. Standard gradient update
- **Design tradeoffs**: Memory vs. batch size (doubles effective batch size), λ tuning (start small, increase gradually), ω tuning (recommend ω≈0.1 for stability), simplicity vs. complexity (only 3 hyperparameters)
- **Failure signatures**: No convergence/divergence (λ too high or ω too large), no metric gain (perturbations don't match feature distributions), training instability (batch size doubling without infrastructure scaling)
- **First 3 experiments**: 1. Single-stage offline test: Implement LSPR on final-stage ranker with λ=0.1, ω=0.1; measure NE against production baseline 2. Hyperparameter sweep: Grid search λ∈{0.001, 0.01, 0.1} × ω∈{0.05, 0.1, 0.2}; validate NE improvements 3. Online A/B test: Deploy best configuration to 1% traffic; monitor top-line metrics for 0.1%-0.2% relative improvement

## Open Questions the Paper Calls Out

- Can utilizing perturbation-dependent weights for noisy samples yield better performance than the uniform weighting currently employed in LSPR?
- Does the optimization trajectory and weight alignment advantage of LSPR demonstrated in linear models hold true for the deep, non-linear architectures used in production?
- What is the precise trade-off between the computational overhead of doubled batch sizes and the metric gains provided by LSPR in resource-constrained environments?

## Limitations

- Performance may be architecture-dependent; the paper doesn't fully explore how results vary across different model architectures
- Requires careful tuning of perturbation parameters (ω for noise scale, dropout rates for sparse features)
- Computational overhead of doubling batch size may not be justified for smaller-scale recommendation systems
- Theoretical guarantees from linear model analysis may not transfer to complex deep neural networks

## Confidence

- **High Confidence**: LSPR's basic mechanism and successful deployment in production systems with documented offline and online metric improvements
- **Medium Confidence**: Theoretical analysis showing better gradient alignment compared to SCR, though generalization to complex deep networks requires empirical validation
- **Medium Confidence**: Claim that perturbation-based regularization is novel for industrial-scale recommendation systems, though comprehensive literature review on prior attempts is limited

## Next Checks

1. **Architecture Transferability Test**: Implement LSPR on different recommendation model architectures (DHEN, DCN, simple MLP) using the same dataset to quantify architecture-specific performance variations

2. **Perturbation Sensitivity Analysis**: Systematically vary Gaussian noise scales (ω∈{0.05, 0.1, 0.2, 0.5}) and dropout rates across feature types while measuring convergence stability and final NE to establish robust parameter ranges

3. **Scale-Impact Study**: Deploy LSPR on progressively smaller recommendation systems (from million to billion scale) to determine the minimum viable scale where perturbation regularization provides meaningful ROI considering computational overhead