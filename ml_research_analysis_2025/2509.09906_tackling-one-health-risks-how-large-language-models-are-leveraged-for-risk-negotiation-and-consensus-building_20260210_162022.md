---
ver: rpa2
title: 'Tackling One Health Risks: How Large Language Models are leveraged for Risk
  Negotiation and Consensus-building'
arxiv_id: '2509.09906'
source_url: https://arxiv.org/abs/2509.09906
tags:
- negotiation
- issue
- risk
- stakeholders
- issues
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces an AI-assisted negotiation framework that
  integrates large language models (LLMs) and multi-agent modeling into risk analysis.
  The approach enables stakeholders to simulate negotiations, systematically model
  dynamics, and evaluate solution impacts under time constraints and information overload.
---

# Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building

## Quick Facts
- arXiv ID: 2509.09906
- Source URL: https://arxiv.org/abs/2509.09906
- Reference count: 0
- This study introduces an AI-assisted negotiation framework that integrates large language models (LLMs) and multi-agent modeling into risk analysis, successfully facilitating stakeholder consensus in two One Health scenarios.

## Executive Summary
This study presents a novel framework that leverages large language models and multi-agent modeling to enhance risk negotiation and consensus-building in One Health contexts. The approach addresses critical challenges in traditional risk assessment methods, including stakeholder complexity, time constraints, and information overload. By simulating stakeholder negotiations through AI agents and providing structured dialogue tools, the framework enables systematic evaluation of solutions and their impacts.

The framework was tested in two real-world scenarios: prudent use of biopesticides and targeted wild animal population control. Results demonstrated its effectiveness in facilitating stakeholder consensus while maintaining transparency and enabling customization for different contexts. The open-source, web-based design makes it accessible for broader application across various risk assessment domains.

## Method Summary
The framework combines large language models with multi-agent modeling to simulate stakeholder negotiations and facilitate consensus-building. It integrates scenario modeling, solution proposal, and impact assessment tools into a cohesive system. The approach uses LLM-generated agents to represent different stakeholder perspectives, enabling structured dialogue and systematic evaluation of proposed solutions. The system operates through a web-based interface that allows stakeholders to interact with the negotiation process and visualize outcomes.

## Key Results
- Successfully facilitated stakeholder consensus in two real Health scenarios (biopesticide use and wild animal population control)
- Demonstrated effectiveness in handling complex multi-stakeholder negotiations under time constraints
- Provided structured approach to evaluating solution impacts and trade-offs
- Open-source implementation enables customization and broader application

## Why This Works (Mechanism)
The framework works by creating a structured environment where stakeholder perspectives can be systematically explored and negotiated. Large language models generate realistic stakeholder agents that can articulate positions, propose solutions, and engage in dialogue. The multi-agent modeling component simulates negotiation dynamics, allowing stakeholders to understand different viewpoints and identify common ground. This systematic approach reduces cognitive load and provides clear visualization of consensus-building progress.

## Foundational Learning
1. Multi-agent systems for stakeholder representation
   - Why needed: To simulate diverse perspectives and negotiation dynamics
   - Quick check: Can the system accurately represent different stakeholder positions?

2. LLM-based scenario generation
   - Why needed: To create realistic negotiation contexts and solution proposals
   - Quick check: Do generated scenarios align with real-world constraints?

3. Consensus visualization tools
   - Why needed: To track progress and identify areas of agreement/disagreement
   - Quick check: Can stakeholders easily interpret consensus metrics?

## Architecture Onboarding

Component Map:
Stakeholder Interface -> LLM Agent System -> Multi-Agent Negotiation Engine -> Consensus Visualization -> Impact Assessment Module

Critical Path:
Stakeholder input -> Agent generation -> Negotiation simulation -> Consensus evaluation -> Impact assessment

Design Tradeoffs:
- Accuracy vs. speed in agent generation
- Complexity vs. usability in interface design
- Detail level vs. cognitive load in visualization

Failure Signatures:
- Agent responses becoming inconsistent or nonsensical
- Consensus metrics showing unrealistic convergence
- Impact assessments missing critical factors

First Experiments:
1. Test agent consistency across multiple negotiation rounds
2. Validate consensus metrics against known outcomes
3. Verify impact assessment accuracy for simple scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Limited testing to only two real-world scenarios, raising questions about generalizability
- No detailed validation of AI-generated outputs against human expert judgments
- Potential LLM hallucination risks not explicitly addressed

## Confidence

**High confidence**: The technical implementation of the multi-agent negotiation framework and its ability to facilitate structured dialogue among stakeholders

**Medium confidence**: The framework's effectiveness in achieving consensus in real-world scenarios, given the limited number of case studies

**Low confidence**: The framework's robustness against LLM hallucinations and its ability to handle highly complex, multi-stakeholder negotiations with conflicting values

## Next Checks
1. Conduct systematic testing across diverse One Health scenarios with varying stakeholder numbers and conflict complexity to evaluate framework generalizability
2. Implement and evaluate hallucination detection mechanisms specifically for negotiation-related outputs in the multi-agent system
3. Perform comparative analysis between AI-assisted negotiations and traditional human-mediated consensus-building processes to quantify effectiveness and efficiency gains