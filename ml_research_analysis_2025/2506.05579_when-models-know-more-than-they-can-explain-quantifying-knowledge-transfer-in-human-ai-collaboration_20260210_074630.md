---
ver: rpa2
title: 'When Models Know More Than They Can Explain: Quantifying Knowledge Transfer
  in Human-AI Collaboration'
arxiv_id: '2506.05579'
source_url: https://arxiv.org/abs/2506.05579
tags:
- human
- arxiv
- knowledge
- problems
- math
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study introduces KITE, a framework for evaluating knowledge
  transfer in human-AI collaboration through a two-phase protocol: collaborative ideation
  with an AI followed by independent problem-solving. Across 578 problem-solving sessions
  with 118 participants, the research found that while model benchmark performance
  correlates with collaborative outcomes, the relationship is inconsistent with significant
  outliers, indicating that knowledge transfer requires dedicated optimization.'
---

# When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration

## Quick Facts
- **arXiv ID:** 2506.05579
- **Source URL:** https://arxiv.org/abs/2506.05579
- **Reference count:** 40
- **Primary result:** Knowledge transfer from AI models to humans requires dedicated optimization beyond model benchmark performance

## Executive Summary
This study introduces KITE (Knowledge Transfer Evaluation Framework), a novel protocol for measuring how effectively AI models transfer knowledge during human-AI collaboration. The framework uses a two-phase approach where participants first collaborate with an AI model to solve problems, then attempt to solve similar problems independently. Across 578 sessions with 118 participants, the research reveals that higher model benchmark performance does not guarantee better knowledge transfer. Some models like Claude-3.7-Sonnet enabled collaborative outcomes exceeding solo capabilities, while others like Gemini-2.5-Pro showed reduced collaborative efficacy despite superior benchmarks. The findings highlight that effective human-AI collaboration requires optimization beyond raw model performance.

## Method Summary
The study employed a two-phase protocol where participants first collaborated with an AI model to solve a problem, then attempted to solve a related problem independently. This design aimed to measure actual knowledge transfer rather than just collaborative success. The research tested four models (Claude-3.5-Sonnet, Claude-3.7-Sonnet, GPT-4o, and Gemini-2.5-Pro) across math and coding domains with 118 participants. The collaborative sessions were analyzed for both objective outcomes (problem-solving success rates) and subjective measures (user preferences, perceived helpfulness). The study also examined correlations between model benchmark performance and collaborative efficacy to identify gaps in knowledge transfer capabilities.

## Key Results
- Model benchmark performance correlates with collaborative outcomes but shows significant outliers, indicating inconsistent knowledge transfer
- Some models (Claude-3.7-Sonnet) enabled collaborative outcomes exceeding what either party could achieve alone
- Higher-performing models like Gemini-2.5-Pro showed reduced collaborative efficacy despite superior benchmarks
- User preferences for models varied by domain and skill hierarchy, with strategic guidance valued in coding and intuitive framing preferred in mathematics

## Why This Works (Mechanism)
Unknown: The study did not explicitly identify the cognitive or communicative mechanisms underlying successful knowledge transfer in human-AI collaboration. The findings suggest that factors beyond raw model capability influence transfer effectiveness, but specific mechanisms remain unelaborated.

## Foundational Learning
Why needed: Understanding the gap between model capabilities and effective knowledge transfer requires examining the cognitive and communicative processes involved in human-AI collaboration.
Quick check: Compare pre- and post-collaboration performance metrics across different model types and domains.

## Architecture Onboarding
Component map: Human participant -> AI model (collaborative phase) -> Independent problem-solving phase -> Knowledge transfer measurement
Critical path: Collaborative ideation -> Model reasoning explanation -> User internalization -> Independent application
Design tradeoffs: Balancing model capability with communicative effectiveness vs. optimizing for either dimension alone
Failure signatures: Overreliance on AI, misaligned representations, ineffective scaffolding
First experiments: 1) Cross-domain replication to test generalizability, 2) Longitudinal tracking of individual skill development, 3) Blinded model identification studies

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly identify specific open questions beyond the general need for further research on knowledge transfer mechanisms and domain generalizability.

## Limitations
- Experimental tasks may not generalize beyond the specific math and coding domains tested
- Post-collaboration measurements may conflate knowledge transfer with practice effects or increased confidence
- Limited model diversity may not capture the full range of collaborative patterns across different architectures

## Confidence
- High confidence: Core finding that model benchmark performance does not reliably predict collaborative efficacy
- Medium confidence: Qualitative patterns of user preferences and interaction styles
- Medium confidence: KITE framework validity pending external validation
- Low confidence: Generalizability of domain-specific findings to broader contexts

## Next Checks
1. Replicate the study with additional problem domains (e.g., creative writing, scientific reasoning) to test domain generality of knowledge transfer patterns
2. Conduct longitudinal studies tracking individual participants' skill development over multiple sessions to distinguish knowledge transfer from practice effects
3. Implement blinded model identification studies where participants solve problems with identical prompting strategies to isolate model capabilities from presentation effects