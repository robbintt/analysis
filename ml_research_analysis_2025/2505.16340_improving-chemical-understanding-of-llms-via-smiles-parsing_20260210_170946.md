---
ver: rpa2
title: Improving Chemical Understanding of LLMs via SMILES Parsing
arxiv_id: '2505.16340'
source_url: https://arxiv.org/abs/2505.16340
tags:
- smiles
- molecular
- tasks
- parsing
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of LLMs' inability to understand
  molecular structures encoded in SMILES strings, limiting their use in molecular
  science tasks. To overcome this, the authors propose CLEANMOL, a framework that
  introduces five deterministic SMILES parsing tasks (functional group matching, ring
  counting, chain length measurement, canonicalization, and fragment assembly) to
  provide explicit structural supervision.
---

# Improving Chemical Understanding of LLMs via SMILES Parsing

## Quick Facts
- **arXiv ID:** 2505.16340
- **Source URL:** https://arxiv.org/abs/2505.16340
- **Reference count:** 39
- **Primary result:** CLEANMOL framework improves SMILES parsing accuracy and achieves state-of-the-art performance on molecular tasks in Mol-Instructions benchmark

## Executive Summary
This paper addresses the fundamental limitation of LLMs in understanding molecular structures encoded in SMILES strings, which hampers their application in molecular science tasks. The authors propose CLEANMOL, a framework that introduces five deterministic SMILES parsing tasks to provide explicit structural supervision. These tasks—functional group matching, ring counting, chain length measurement, canonicalization, and fragment assembly—are designed to improve graph-level molecular comprehension. The framework employs a two-stage training pipeline with task-adaptive data pruning and curriculum learning. Results demonstrate significant improvements in SMILES parsing accuracy and competitive performance on downstream molecular tasks like retrosynthesis and reaction prediction.

## Method Summary
CLEANMOL is a two-stage framework that first pretrains models on five deterministic SMILES parsing tasks (functional group matching, ring counting, chain length measurement, canonicalization, and fragment assembly) using automatically annotated data from ZINC250k. The framework employs task-adaptive data pruning to select mid-difficulty molecules and uses curriculum learning for optimal training progression. Models are then fine-tuned on downstream molecular tasks. The approach uses LoRA fine-tuning with specific hyperparameters and focuses exclusively on 2D molecular topology without incorporating 3D conformational information or stereochemistry.

## Key Results
- CLEANMOL achieves 0.933 average accuracy on SMILES parsing tasks compared to 0.740 for bottom-difficulty and 0.893 for top-difficulty pruning
- The framework reaches state-of-the-art or competitive performance on Mol-Instructions benchmark for retrosynthesis, reagent prediction, and forward reaction prediction
- Multi-task learning improves 4 out of 5 parsing tasks compared to single-task training
- Task-adaptive pruning significantly outperforms random sampling strategies

## Why This Works (Mechanism)

### Mechanism 1
CLEANMOL uses deterministic structural supervision tasks (functional group matching, ring counting, canonicalization) that provide unambiguous gradient signals for learning SMILES-to-graph mapping, avoiding the noisy training signals from ambiguous pretraining objectives like masked token prediction where multiple valid completions exist.

### Mechanism 2
Task-adaptive data pruning selects molecules that maximize learning signal per training step by scoring molecules using task-specific difficulty heuristics (functional group count, ring count, SMILES length) and retaining mid-difficulty samples while pruning extremely easy or hard cases.

### Mechanism 3
Multi-task joint training on parsing tasks creates transferable structural representations where knowledge transfers across tasks—ring counting reinforces canonicalization, functional group matching supports fragment assembly—leading to improved performance across all tasks except chain length measurement.

## Foundational Learning

- **Concept:** SMILES notation and non-contiguous substructure encoding
  - **Why needed here:** SMILES represents molecular graphs as linear strings where connected atoms may appear far apart (ring closure digits, branches in parentheses), making understanding this grammar prerequisite to all CLEANMOL tasks
  - **Quick check question:** In `c1ccccc1`, which tokens represent the ring closure? (Answer: the two `1`s connect the first and last carbon, forming a 6-membered ring despite only 5 characters between them.)

- **Concept:** Molecular graph invariants and canonicalization
  - **Why needed here:** Canonicalization task requires understanding that the same molecule has multiple valid SMILES but only one canonical form, testing whether models learn permutation-invariant molecular identity
  - **Quick check question:** Would `CCO` and `OCC` canonicalize to the same SMILES? (Answer: Yes—both represent ethanol.)

- **Concept:** Curriculum learning principles
  - **Why needed here:** CLEANMOL's data pruning and ordering strategy assumes that learning progresses better when examples increase gradually in complexity
  - **Quick check question:** Why might training on extremely hard examples first fail? (Answer: Model lacks foundational representations to extract signal; gradients may be uninformative or contradictory.)

## Architecture Onboarding

- **Component map:** Raw SMILES (ZINC250k) -> RDKit annotation pipeline -> CLEANMOL Dataset (250K examples, 5 tasks) -> Task-adaptive pruning by difficulty scores -> Pruned training set (50K per task) -> Stage 1: LoRA fine-tuning on parsing tasks -> Structure-aware pretrained model -> Stage 2: Task-specific fine-tuning -> Downstream model (retrosynthesis, reagent prediction, forward prediction)

- **Critical path:** Stage 1 pretraining is the lever—if parsing accuracy is low, downstream transfer will be limited. Verify parsing task accuracy reaches >0.85 before Stage 2.

- **Design tradeoffs:**
  - Deterministic vs. generative pretraining: CLEANMOL uses classification/regression tasks, not molecular generation. This improves parsing but may not directly improve generation fluency
  - 2D topology only: No 3D conformers, stereochemistry detail, or electronic properties. Paper explicitly notes this limitation
  - Task-specific difficulty heuristics: Rule-based (e.g., ring count) rather than learned; may miss subtle structural complexity

- **Failure signatures:**
  - Parsing accuracy plateaus <0.70: Check data quality—RDKit may generate inconsistent annotations for edge cases
  - Multi-task training degrades single-task performance: Reduce learning rate or increase LoRA rank; task interference may dominate
  - Downstream transfer shows no gain: Verify Stage 1 achieved high parsing accuracy; if so, the downstream task may require knowledge beyond 2D structure

- **First 3 experiments:**
  1. Reproduce SMILES parsing baseline: Fine-tune Llama3.1-8B on single-task ring counting (50K molecules). Target: >0.85 accuracy. This validates the annotation pipeline and training setup
  2. Ablate pruning strategy: Compare random vs. mid-difficulty pruning on ring counting. Expect ~5-10% accuracy gap if mechanism holds
  3. Test transfer to held-out downstream task: After Stage 1 multi-task pretraining, fine-tune on retrosynthesis (Mol-Instructions). Compare against baseline without CLEANMOL pretraining. Look for improvement in Exact Match and fingerprint similarity metrics

## Open Questions the Paper Calls Out

- **Open Question 1:** Does the performance improvement from CLEANMOL scale effectively to Large Language Models (LLMs) with significantly larger parameter counts (e.g., 70B or beyond)?
  - **Basis in paper:** The authors state in the Limitations section, "It remains to be seen whether our framework scales effectively to larger models (e.g., 70B or beyond)."
  - **Why unresolved:** Computational constraints limited experiments to models with up to 7.5B–8B parameters; behavior on frontier-scale models is unknown
  - **What evidence would resolve it:** Pre-training a 70B+ parameter model using the CLEANMOL dataset and evaluating its performance on the Mol-Instructions benchmark compared to smaller counterparts

- **Open Question 2:** Can the SMILES parsing framework be extended to capture 3D conformational information or nuanced chemical features like stereochemistry?
  - **Basis in paper:** The Limitations section notes that current tasks "do not incorporate 3D conformational information" and "do not capture more nuanced chemical features such as stereochemistry"
  - **Why unresolved:** Proposed tasks rely on 2D topological graph analysis, which inherently excludes spatial and electronic context required for many biological and physicochemical applications
  - **What evidence would resolve it:** Development and integration of deterministic parsing tasks for 3D coordinates or stereochemical markers, followed by evaluation on structure-sensitive downstream tasks

- **Open Question 3:** How does model performance saturate or improve when the CLEANMOL pre-training dataset is expanded significantly beyond 250K molecules?
  - **Basis in paper:** The authors acknowledge that "further studies on larger-scale datasets are necessary to assess the robustness and scalability" of the approach
  - **Why unresolved:** While experiments showed improvement with data scaling, the dataset size was relatively modest compared to the potential scale of available chemical space
  - **What evidence would resolve it:** Generating CLEANMOL annotations for a massive corpus (e.g., millions of molecules) and analyzing the resulting performance curve on downstream tasks

## Limitations

- The framework focuses exclusively on 2D molecular topology without incorporating 3D conformational information or stereochemistry
- Performance scaling to larger models (70B+ parameters) remains untested and uncertain
- Difficulty heuristics for task-adaptive pruning may not generalize well beyond drug-like molecules in ZINC250k

## Confidence

- **High confidence:** SMILES parsing task performance - Deterministic nature of tasks makes accuracy measurement straightforward with consistent improvements over baselines
- **Medium confidence:** Task-adaptive pruning effectiveness - Mid-difficulty pruning shows 15-20% accuracy gains, but heuristic-based difficulty scores lack external validation
- **Low confidence:** Downstream molecular reasoning transfer - CLEANMOL achieves SOTA or competitive results, but absolute performance gaps are modest and driving factors unclear

## Next Checks

1. **Validate difficulty heuristic correlation:** Compute actual human or algorithmic difficulty scores for 100 randomly selected molecules across the difficulty spectrum. Test whether RDKit-based heuristics correlate with true parsing complexity measured by model training dynamics or human evaluation.

2. **Ablate task composition:** Train separate models on individual CLEANMOL tasks versus the full multi-task setup. Measure parsing accuracy per task and test downstream transfer on held-out molecular reasoning tasks to isolate whether compositional transfer is real.

3. **Test on out-of-distribution molecules:** Evaluate CLEANMOL-pretrained models on molecular structures from different chemical spaces (natural products, polymers, organometallics) not well-represented in ZINC250k. Compare parsing accuracy and downstream task performance to assess generalizability.