---
ver: rpa2
title: 'CoLLMLight: Cooperative Large Language Model Agents for Network-Wide Traffic
  Signal Control'
arxiv_id: '2503.11739'
source_url: https://arxiv.org/abs/2503.11739
tags:
- traffic
- signal
- uni00000013
- lane
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoLLMLight is a cooperative LLM agent framework for network-wide
  traffic signal control that addresses the lack of inter-agent coordination in existing
  approaches. It constructs a spatiotemporal graph to capture traffic dynamics and
  spatial relationships, uses a complexity-aware reasoning mechanism to dynamically
  adapt reasoning depth based on traffic conditions, and employs a fine-tuning strategy
  with simulation-driven data collection and environmental feedback to build a lightweight
  LLM.
---

# CoLLMLight: Cooperative Large Language Model Agents for Network-Wide Traffic Signal Control

## Quick Facts
- arXiv ID: 2503.11739
- Source URL: https://arxiv.org/abs/2503.11739
- Authors: Zirui Yuan; Siqi Lai; Hao Liu
- Reference count: 40
- Primary result: Achieves up to 25.17% reduction in average waiting time compared to the second-best performance in complex coordination scenarios

## Executive Summary
CoLLMLight introduces a cooperative LLM agent framework for network-wide traffic signal control that addresses the lack of inter-agent coordination in existing approaches. It constructs a spatiotemporal graph to capture traffic dynamics and spatial relationships, uses a complexity-aware reasoning mechanism to dynamically adapt reasoning depth based on traffic conditions, and employs a fine-tuning strategy with simulation-driven data collection and environmental feedback to build a lightweight LLM. Extensive experiments on synthetic and real-world datasets show CoLLMLight outperforms state-of-the-art methods, achieving up to 25.17% reduction in average waiting time compared to the second-best performance in complex coordination scenarios.

## Method Summary
CoLLMLight fine-tunes a Llama 3.1-8B model via LoRA (rank=8, α=16, lr=1e-4) in two stages: (1) Reasoning chain optimization with GPT-4o-generated labels, and (2) Policy refinement with environmental feedback using a 5-timestep horizon. The framework uses lane-level observations to construct a spatiotemporal graph, then applies complexity-aware reasoning with three strategies based on congested neighboring lanes (n_c). The model is trained on simulation-generated data (2,802 + 552 trajectories) and evaluated on real-world datasets including Jinan (12 intersections), Hangzhou (16), and New York (196).

## Key Results
- Achieves up to 25.17% reduction in average waiting time compared to the second-best performance
- Outperforms state-of-the-art methods in both synthetic and real-world traffic scenarios
- 8B model performs comparably or better than larger models (70B+) in cooperative TSC tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can reason about network-wide traffic coordination when spatial relationships and temporal dynamics are explicitly structured and verbalized.
- Mechanism: A directed subgraph G=(V,L) captures lane connectivity between intersections. Historical interactions over time window Δt (traffic observations + signal configurations) are collected. Both are converted to human-readable prompts enabling the LLM to (1) analyze current conditions, (2) predict future states under different signals, and (3) select the optimal signal for network-wide improvement.
- Core assumption: Verbalized graph structures preserve sufficient information for LLMs to reason about traffic dependencies; LLMs can predict downstream effects accurately.
- Evidence anchors:
  - [abstract] "constructs a spatiotemporal graph to capture traffic dynamics and spatial relationships among neighboring intersections, enabling the LLM to reason about complex traffic interactions"
  - [section 3.1.2] "To capture the temporal pattern of congestion propagation, we collect historical traffic interactions over fixed time windows Δt"
  - [corpus] Related work "Joint-Local Grounded Action Transformation" addresses sim-to-real transfer but doesn't use LLMs; "Convergence of Multiagent Learning Systems" uses MARL without explicit graph verbalization.
- Break condition: When graph verbalization loses critical dependency information; when prediction horizon exceeds LLM's reasoning capacity; when neighboring intersection data is stale or incomplete.

### Mechanism 2
- Claim: Computational efficiency can be optimized by dynamically adapting reasoning depth to real-time traffic complexity without sacrificing decision quality.
- Mechanism: A congestion risk coefficient n_c counts critical neighboring lanes that are congested or at risk. Three reasoning strategies: (1) n_c=0: skip analysis and prediction entirely, (2) n_c=1: local analysis only, no future state prediction, (3) n_c>1: full cooperative decision-making with analysis, prediction, and signal comparison.
- Core assumption: The congestion risk coefficient accurately reflects actual coordination complexity; simpler reasoning suffices for low-complexity scenarios.
- Evidence anchors:
  - [abstract] "complexity-aware reasoning mechanism that dynamically adapts reasoning depth based on real-time traffic conditions"
  - [section 3.2] Figure 5 shows variants with different reasoning strategies—the full three-strategy approach (Ours) achieves lower ATT with competitive inference time compared to single-strategy variants
  - [corpus] Weak direct evidence—no corpus papers explicitly address adaptive reasoning depth for LLM-based TSC.
- Break condition: When n_c misclassifies complexity (e.g., n_c=1 but cascading effects require full reasoning); when occupancy threshold α is poorly calibrated; when rapid condition changes outpace classification updates.

### Mechanism 3
- Claim: A lightweight LLM (8B parameters) can match or exceed larger models in cooperative TSC through simulation-driven fine-tuning with environmental feedback.
- Mechanism: Two-stage fine-tuning: (1) Reasoning chain optimization—GPT-4o generates structured summaries (n_c, analysis); simulator provides ground-truth future states; pseudo-golden signal selected by minimizing 5-step queue length. (2) Policy refinement—LLM decisions are simulated, environment feedback Q (inverse queue length) ranks outcomes, best trajectories become training data. LoRA fine-tuning applied with rank=8, α=16.
- Core assumption: GPT-4o summaries and simulation-based pseudo-labels provide high-quality supervision; 5-step queue minimization is a valid proxy for optimal signal selection; iterative refinement converges to better policies.
- Evidence anchors:
  - [abstract] "fine-tuning strategy with simulation-driven data collection and environmental feedback to build a lightweight LLM"
  - [section 3.3.2] Equation 13: feedback function Q is inverse of overall queue length at neighboring intersections after 5 timesteps
  - [section 4.4.2, Table 3] Ablation shows w/o reasoning optimization degrades performance in complex scenarios (NY); w/o policy refinement performs well on simple networks but struggles with high coordination complexity
  - [corpus] "FitLight: Federated Imitation Learning" addresses RL training costs but doesn't use LLM-based reasoning chains.
- Break condition: When simulation dynamics diverge from real-world conditions; when GPT-4o summaries contain hallucinations; when feedback signal Q doesn't correlate with actual traffic efficiency.

## Foundational Learning

- **Traffic Signal Control fundamentals (phases, pressure, queue dynamics)**
  - Why needed here: The framework assumes familiarity with signal phases (ETWT, NTST, etc.), lane-level observations (queue length, occupancy, waiting time), and how signals affect downstream flow. Without this, the spatiotemporal graph and reasoning prompts will be opaque.
  - Quick check question: Can you explain why releasing lane ET when its downstream is at 90% occupancy might cause queue spillback?

- **Chain-of-Thought reasoning and inference-time scaling**
  - Why needed here: The complexity-aware mechanism is a form of adaptive CoT—understanding why longer reasoning chains help in complex scenarios but waste resources in simple ones is essential for tuning the three-strategy approach.
  - Quick check question: What is the trade-off between CoT length and inference latency in real-time control systems?

- **LoRA fine-tuning and supervised learning with pseudo-labels**
  - Why needed here: The framework fine-tunes a lightweight model using LoRA on simulation-generated data. Understanding rank, scaling factor, and when pseudo-labels can degrade performance is critical for avoiding hallucination amplification.
  - Quick check question: If simulation-generated labels have systematic bias, how would that manifest in the fine-tuned model's behavior?

## Architecture Onboarding

- **Component map:**
CityFlow Simulator → Observation Collection → Spatiotemporal Graph G → Prompt Verbalization → Complexity Classifier (n_c) → No-Coop/Simple/Complex → Signal Selection via LLM → Signal Execution → Environment Feedback Q → Policy Refinement

- **Critical path:**
  1. Observation collection (must capture all relevant lanes + neighbors within threshold α)
  2. Complexity classification (incorrect n_c → wrong reasoning strategy → poor decisions or wasted compute)
  3. Reasoning chain execution (in complex mode: analysis → prediction → comparison → decision)
  4. Policy refinement loop (feedback Q must be collected over sufficient time window T)

- **Design tradeoffs:**
  - α (communication threshold): Higher α filters more lanes → faster inference but risks missing critical dependencies
  - Δt (historical window): Larger Δt → more context but linear increase in prompt tokens and potential noise
  - Feedback horizon: 5-step queue minimization balances short-term optimization vs. planning horizon
  - Model size: 8B chosen for efficiency; larger models (70B+) shown in Table 2 don't consistently outperform fine-tuned 8B

- **Failure signatures:**
  - Hallucination in traffic analysis: LLM fabricates lane conditions not in observation data—check for consistency between prompt and reasoning chain
  - Stale neighbor information: High-latency communication causes outdated occupancy values—monitor Δt vs. actual update frequency
  - Misclassified complexity: n_c=0 assigned to congested intersections—verify occupancy thresholds match actual congestion patterns
  - Feedback loop divergence: Policy refinement degrades performance—check if Q signal correlates with ATT/AWT in held-out scenarios

- **First 3 experiments:**
  1. **Validate complexity classification:** Run on Jinan dataset (low ICI) and New York dataset (high ICI). Compare n_c distribution against ground-truth coordination needs. Hypothesis: n_c should correlate with ICI.
  2. **Ablate reasoning depth systematically:** For a single intersection, manually vary reasoning strategy while holding conditions constant. Measure ATT impact and inference time. Identify the complexity boundary where simplified reasoning fails.
  3. **Test sim-to-real gap:** Train on Syn-Train, evaluate zero-shot on Hangzhou. Compare against MaxPressure baseline. If performance degrades significantly, inspect where simulation dynamics diverge (e.g., vehicle behavior, signal timing).

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on simulation-driven fine-tuning raises questions about sim-to-real transfer—performance on synthetic data may not generalize to real-world traffic patterns
- Effectiveness of complexity-aware reasoning depends heavily on accurate congestion risk coefficient classification, but the paper doesn't validate whether n_c correlates with actual coordination needs
- The 8B model's performance edge over larger models is impressive but may not hold under different traffic regimes or network topologies

## Confidence
- **High confidence**: The cooperative mechanism (graph construction + reasoning) is well-specified and the synthetic dataset results are reproducible
- **Medium confidence**: Real-world dataset performance claims are supported but depend on CityFlow configuration matching actual conditions
- **Low confidence**: Generalization to unseen traffic patterns and long-term deployment stability remain untested

## Next Checks
1. **Validate complexity classification**: Run on Jinan dataset (low ICI) and New York dataset (high ICI). Compare n_c distribution against ground-truth coordination needs. Hypothesis: n_c should correlate with ICI.
2. **Ablate reasoning depth systematically**: For a single intersection, manually vary reasoning strategy while holding conditions constant. Measure ATT impact and inference time. Identify the complexity boundary where simplified reasoning fails.
3. **Test sim-to-real gap**: Train on Syn-Train, evaluate zero-shot on Hangzhou. Compare against MaxPressure baseline. If performance degrades significantly, inspect where simulation dynamics diverge (e.g., vehicle behavior, signal timing).