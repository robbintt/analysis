---
ver: rpa2
title: 'dgMARK: Decoding-Guided Watermarking for Diffusion Language Models'
arxiv_id: '2601.22985'
source_url: https://arxiv.org/abs/2601.22985
tags:
- beam
- dgmark
- watermarking
- language
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: dgMARK introduces a decoding-guided watermarking approach for discrete
  diffusion language models that avoids probability reweighting by steering the unmasking
  order toward positions whose high-reward tokens satisfy a parity constraint derived
  from a secret hash. This method is compatible with common decoding strategies and
  can be strengthened using a one-step lookahead beam search variant.
---

# dgMARK: Decoding-Guided Watermarking for Diffusion Language Models

## Quick Facts
- arXiv ID: 2601.22985
- Source URL: https://arxiv.org/abs/2601.22985
- Reference count: 40
- Primary result: Decoding-guided watermarking for dLLMs that steers unmasking order using parity constraints, achieving TPR=100% at FPR=1% with minimal quality loss

## Executive Summary
dgMARK introduces a novel watermarking approach for discrete diffusion language models that exploits decoding order sensitivity rather than probability reweighting. By steering the unmasking order toward positions whose high-reward tokens satisfy a parity constraint derived from a secret hash, the method creates a detectable statistical signal while preserving the model's learned distributions. The approach demonstrates strong detectability (TPR=100% at FPR=1% with 3-beam search) and minimal text quality degradation (PPL increases under 1.0 for most configurations), while maintaining robustness under token-level edits and paraphrasing attacks.

## Method Summary
dgMARK leverages the order sensitivity of discrete diffusion language models to create a watermarking channel. Instead of modifying token probabilities like traditional KGW-style watermarking, dgMARK steers the unmasking order by selecting positions where the highest-reward token satisfies a parity condition derived from a secret hash function. The decoder computes candidates for all masked positions, filters to those satisfying the parity constraint, and selects the highest-reward among them. Detection occurs via statistical analysis of parity-matching rates, using z-tests for clean text and sliding-window detectors for edited text. The method is compatible with common decoding strategies and can be strengthened using a one-step lookahead beam search variant.

## Key Results
- Strong detectability: TPR=100% at FPR=1% with 3-beam search on benchmark datasets
- Minimal quality degradation: PPL increases under 1.0 for most configurations
- Robustness: Maintains detectability under token-level edits and paraphrasing attacks
- Order-sensitive: Effective specifically because dLLMs exhibit decoding order sensitivity unlike autoregressive models

## Why This Works (Mechanism)

### Mechanism 1: Order Sensitivity Creates a Watermarking Channel
The gap between ideal order-invariance and practical order-sensitivity in dLLMs creates a usable watermarking channel. While theory predicts the factorization should hold for any permutation, imperfect training causes different decoding strategies to yield different outputs, exposing decoding order as a control knob distinct from probability reweighting.

### Mechanism 2: Parity Constraint Steering Without Probability Reweighting
Guiding which position to unmask next—rather than which token to select—induces elevated parity-matching rates while leaving learned distributions unchanged. A hash function partitions the vocabulary into parity-matching sets per position, and the decoder prioritizes indices whose predicted tokens satisfy the parity condition.

### Mechanism 3: Statistical Detection via Binomial Deviation
Watermarked sequences exhibit parity-matching rates systematically above 0.5, detectable via z-test with controllable false positive rates. Under non-watermarked generation, parity matches follow Binomial(n, 0.5), while watermarking shifts this mean upward. A sliding-window detector aggregates local statistics to handle index shifts from insertions/deletions.

## Foundational Learning

- **Discrete Diffusion Language Models (dLLMs)**: Why needed here: dgMARK exploits the order-agnostic property unique to dLLMs; autoregressive models generate left-to-right and lack this degree of freedom. Quick check: Why can a masked dLLM reveal tokens at position 5 before position 2, while an autoregressive model cannot?

- **Watermarking via Probability Biasing (KGW-style)**: Why needed here: dgMARK positions itself against this paradigm; understanding green/red list boosting clarifies what dgMARK avoids. Quick check: In KGW, how does hashing the previous token to partition vocabulary create a detectable signal, and why does this require left-to-right order?

- **Binomial Hypothesis Testing**: Why needed here: Detection relies on z-scores; deployment requires understanding FPR/TPR tradeoffs and threshold selection. Quick check: For n=200 tokens with 120 parity matches, compute the z-score. Is this significant at z=4.0?

## Architecture Onboarding

- **Component map**: Hash function f(v, ξ) -> Parity sets (G_i, R_i) -> Decoding strategy F -> Candidate filter -> One-step lookahead -> Detectors

- **Critical path**:
  1. Initialize y ← [MASK]^n, I ← ∅
  2. Per step: F produces (r_j, v_j) for all j ∉ I
  3. Filter C ← {j | v_j ∈ G_j}; if C=∅, C ← all unrevealed
  4. Select k* = argmax_{j∈C} r_j (or argmax g(j) for beam search)
  5. Commit y[k*] ← v[k*], update I
  6. Detection: compute z-score from parity-matching count G

- **Design tradeoffs**:
  - Beam size k: Higher k → stronger detectability but ~2.7× latency at k=3
  - Block size: 16–32 tokens balances embedding strength with generation stability
  - Sampling: Multinomial gives stronger signals than greedy but +0.2–0.8 PPL increase

- **Failure signatures**:
  - Short outputs (<100 tokens): TPR drops to ~60–80% at FPR=1%
  - Code generation (HumanEval): Largest quality drop due to low-entropy domain
  - Paraphrasing with order diversity (DIPPER-2): AUC drops to ~0.7–0.8
  - Large block sizes (64, 128): Many sequences terminate early at <50 tokens

- **First 3 experiments**:
  1. **Baseline reproduction**: Run dgMARK (k=1,3) on C4 with LLaDA-1.5, measure TPR@FPR∈{1%,0.1%} and PPL delta vs. non-watermarked
  2. **Beam size ablation**: Fix multinomial sampling, vary k∈{1,3,5,8}, plot TPR@FPR=1% against PPL
  3. **Robustness stress test**: Generate 300 sequences, apply token edits (ε∈{0.1,0.3) and DIPPER-1 paraphrasing, evaluate sliding-window detection (w=8,16,32)

## Open Questions the Paper Calls Out

### Open Question 1
Will dgMARK remain effective as dLLM training improves and models approach true order-invariance? The watermarking channel fundamentally exploits a gap between ideal and practical model behavior, which may diminish as models achieve better order-invariance.

### Open Question 2
Can detection reliability for short outputs (n < 100 tokens) be improved without requiring aggregation across multiple responses? Statistical tests on parity-matching rates inherently require sufficient samples, and the paper does not propose mechanisms to amplify signal strength for short sequences.

### Open Question 3
Does replacing the simple modulo hash with a cryptographically secure PRF meaningfully improve resilience against adversarial reverse-engineering? The paper states compatibility with PRFs but does not empirically validate whether this stronger security claim holds against attacks.

### Open Question 4
How robust is dgMARK against targeted attacks designed to detect and disrupt decoding-order-based watermarks? While tested against generic post-editing, the paper does not evaluate against adversaries who know the watermarking mechanism and optimize attacks accordingly.

## Limitations

- Statistical power constraints limit effectiveness for short sequences (<100 tokens)
- Domain-specific quality degradation, particularly in low-entropy domains like code generation
- Computational overhead from beam search variants (2.7×-3.8× latency)
- Reliance on relative token position preservation for robustness against paraphrasing

## Confidence

- **High Confidence**: Decoding order sensitivity creates usable channels; parity-matching detection provides reliable baseline; quality degradation remains minimal; robustness against token-level edits
- **Medium Confidence**: Sliding-window detection under paraphrasing; one-step lookahead beam search trade-offs; block sizes 16-32 provide stable performance
- **Low Confidence**: Generalization to non-English languages; performance under sophisticated adversarial attacks; scalability to very long sequences

## Next Checks

1. **Statistical Power Characterization**: Systematically measure TPR/FPR across sequence lengths from 50-1000 tokens, generating detection curves that quantify the minimum sequence length required for reliable watermarking (target: TPR≥95% at FPR≤1% for n≥200).

2. **Adversarial Attack Benchmark**: Implement a comprehensive attack suite including synonym replacement with POS preservation, sentence shuffling, and structured paraphrasing, measuring AUC degradation and identifying attack vectors that most effectively remove the watermark.

3. **Cross-Domain Quality Impact Analysis**: Evaluate PPL increases across diverse domains (medical, legal, technical writing, poetry) to establish domain-specific quality degradation thresholds and identify which content types are unsuitable for watermarking under this approach.