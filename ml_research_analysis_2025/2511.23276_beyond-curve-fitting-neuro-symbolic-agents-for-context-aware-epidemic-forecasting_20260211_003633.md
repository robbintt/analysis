---
ver: rpa2
title: 'Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting'
arxiv_id: '2511.23276'
source_url: https://arxiv.org/abs/2511.23276
tags:
- forecast
- hfmd
- agent
- forecasting
- school
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a two-agent hierarchical framework for context-aware
  epidemic forecasting, specifically for Hand, Foot, and Mouth Disease (HFMD). The
  framework separates contextual interpretation from probabilistic forecasting: an
  LLM-based Event Interpreter ingests external signals like weather and school calendars,
  producing a scalar transmission impact score; a neuro-symbolic Forecast Generator
  then combines this with historical case counts to generate calibrated probabilistic
  forecasts.'
---

# Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting

## Quick Facts
- **arXiv ID**: 2511.23276
- **Source URL**: https://arxiv.org/abs/2511.23276
- **Reference count**: 40
- **Primary result**: Two-agent framework achieves competitive MAE while providing calibrated 90% prediction intervals (coverage 0.85-1.00) for HFMD forecasting.

## Executive Summary
This paper introduces a two-agent hierarchical framework for context-aware epidemic forecasting, specifically for Hand, Foot, and Mouth Disease (HFMD). The framework separates contextual interpretation from probabilistic forecasting: an LLM-based Event Interpreter ingests external signals like weather and school calendars, producing a scalar transmission impact score; a neuro-symbolic Forecast Generator then combines this with historical case counts to generate calibrated probabilistic forecasts. Evaluated on HFMD datasets from Hong Kong (90 weeks) and Lishui, China (33 weeks), the approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art foundation model performance while yielding context-aware forecasts aligned with public health workflows.

## Method Summary
The method employs a two-agent hierarchical architecture where Agent 1 (Event Interpreter) converts heterogeneous external signals into a scalar transmission impact score $I_t \in [-1.0, 1.0]$ using an LLM with RAG grounding, while Agent 2 (Forecast Generator) combines this with historical case counts to produce calibrated probabilistic forecasts via negative binomial distribution. The system processes weekly HFMD case counts alongside daily weather data (aggregated to weekly), school calendar information, and government surveillance bulletins. RAG knowledge base uses China CDC guidelines chunked and embedded with all-MiniLM-L6-v2, stored in FAISS with top-k=2 retrieval. Rolling 1-week-ahead forecasts are evaluated over 33 weeks (Lishui) and 90 weeks (Hong Kong) using MAE, RMSE, CRPS, and 90% prediction interval coverage as metrics.

## Key Results
- Competitive point forecasting accuracy with MAE of 4.12 (Hong Kong) and 3.89 (Lishui) vs baseline models
- Robust 90% prediction interval coverage of 0.85-1.00 compared to baseline coverage < 0.35
- Human-interpretable rationales generated through the hierarchical architecture
- Ablation study shows Agent 1 contributes 0.5 MAE reduction and RAG improves stability

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Decoupling of Semantic and Numerical Reasoning
- Claim: Separating context interpretation (Agent 1) from time-series forecasting (Agent 2) allows the system to incorporate qualitative drivers that purely numerical models miss
- Mechanism: Agent 1 ingests unstructured external signals and compresses them into a scalar Transmission Impact Score ($I_t$). Agent 2 uses this score to modulate the trajectory derived from historical case counts
- Core assumption: Causal drivers of HFMD can be effectively compressed into a single scalar without losing critical informational nuance
- Evidence anchors: [abstract] "...two-agent hierarchical framework... decoupling contextual interpretation from probabilistic forecasting"; [results] Ablation study shows removing Agent 1 increases MAE from 4.12 to 4.62

### Mechanism 2: Distributional Calibration via Overdispersion Modeling
- Claim: Mapping neural outputs to a Negative Binomial distribution provides robust prediction intervals superior to classical Gaussian assumptions
- Mechanism: Agent 2 estimates historical volatility ($v$) and receives an uncertainty score ($u$) from the LLM, mapped via moment matching to Negative Binomial parameters
- Core assumption: Negative Binomial distribution is a sufficient approximation for the true underlying data generating process of HFMD case counts
- Evidence anchors: [methods] "...calibrated into probabilistic predictions using Poisson/negative binomial likelihoods"; [results] Table 2 & 3 show baselines often have coverage < 0.35, while proposed framework achieves 0.85-1.00

### Mechanism 3: Inference-Time RAG Grounding
- Claim: Retrieval-Augmented Generation stabilizes the Event Interpreter by anchoring reasoning in specific epidemiological guidelines
- Mechanism: Before generating an impact score, Agent 1 queries a vector database of guidelines using dynamically constructed queries, forcing the LLM to justify its score based on retrieved domain knowledge
- Core assumption: Relevant domain knowledge for current week's context exists in the pre-constructed guideline corpus
- Evidence anchors: [methods] "Disabling RAG-based guideline retrieval ('No-RAG') caused the LLM to reason more cautiously... resulting in dampened peak responses"; [results] Table 4 shows "No-RAG" configuration increases MAE to 4.82 vs 4.12

## Foundational Learning

**Negative Binomial Distribution**
- Why needed here: HFMD case counts are discrete, non-negative, and often "bursty" (overdispersed). Standard regression assumes constant variance, leading to narrow, incorrect confidence intervals
- Quick check question: Can you explain why a Poisson distribution might fail to model epidemic counts during an outbreak surge?

**Scalarization of Context**
- Why needed here: The architecture relies on compressing complex multi-modal inputs into a single $I_t$ value to drive the forecaster
- Quick check question: What are the potential information bottlenecks when reducing a complex "school opening during a heatwave" event to a single number between -1 and 1?

**Moment Matching**
- Why needed here: Agent 2 translates LLM outputs into the statistical parameters required for the probabilistic distribution
- Quick check question: How do you map a target mean and variance to the parameters of a Negative Binomial distribution?

## Architecture Onboarding

**Component map**: External Signals (Weather CSVs, School Calendar JSONs, Government Reports) -> Agent 1 (LLM + FAISS Vector Index) -> JSON output ($I_t$, confidence, rationale) -> Agent 2 (LLM + Statistical Core) -> Negative Binomial Parameters -> Quantile Forecasts (Q05, Q50, Q95)

**Critical path**: Evidence Pack Construction -> RAG Retrieval -> LLM Impact Score Generation ($I_t$) -> Trajectory Forecasting -> Distributional Calibration

**Design tradeoffs**:
- Latency vs. Explainability: The system requires two sequential LLM calls, increasing latency compared to a single TimesFM pass, but gains human-readable rationales
- Stability vs. Reactivity: The "lag policy" (enforcing a 1-week delay for school effects) stabilizes forecasts but may cause the model to react slowly to sudden immediate shocks

**Failure signatures**:
- Stuck at Neutral: Agent 1 consistently outputs $I_t \approx 0$ and low confidence (0.4) due to missing external data or poor retrieval
- Over-smoothing: Agent 2 ignores the $I_t$ signal and outputs a flat line near the historical mean if volatility is misestimated
- Inconsistent lag handling: Forecasts misaligned if Agent 2 ignores lag_rationale

**First 3 experiments**:
1. Context Ablation: Run pipeline with Agent 1 disabled (set $I_t=0$) to quantify semantic reasoning layer contribution on MAE
2. Lag Sensitivity: Test different `impact_lag_weeks` (0, 1, 2) to verify the paper's claim that HFMD reacts with a 1-week delay
3. Distributional Check: Compare empirical coverage of 90% PI against Gaussian baseline to validate Negative Binomial assumption on Lishui dataset

## Open Questions the Paper Calls Out

**Open Question 1**: Does the hierarchical neuro-symbolic architecture maintain competitive accuracy and calibration when extended to multi-step forecasting horizons (h > 1)?
- Basis in paper: [explicit] "Future extensions include multi-step forecasting," noting current experiments were restricted to one-week horizon ($h=1$)
- Why unresolved: Error propagation in LLM-based Event Interpreter or recursive uncertainty scaling in Forecast Generator may degrade performance over longer horizons
- What evidence would resolve it: Empirical results from rolling evaluations with $h=4$ and $h=8$ on Hong Kong and Lishui datasets

**Open Question 2**: How can the framework resolve divergent internal reasoning when different LLM backbones interpret conflicting drivers inconsistently?
- Basis in paper: [explicit] Case study (Section 3.5) highlights that GPT-5.1, Qwen3, and DeepSeek produced markedly different forecasts and rationales for same inflection point
- Why unresolved: Paper identifies divergence as systematic but does not propose mechanism to align or validate "correct" reasoning chain against ground truth
- What evidence would resolve it: Benchmark dataset with expert-annotated transmission impact scores and rationale ground truths

**Open Question 3**: Can smaller, open-weight models replace commercial frontier models in the Event Interpreter role without sacrificing reasoning fidelity?
- Basis in paper: [explicit] Framework is "constrained by... computational and reproducibility limits of commercial LLM APIs"
- Why unresolved: Study relied exclusively on high-capability proprietary models; unknown if smaller models can adhere to strict JSON output constraints and complex lag-policy logic
- What evidence would resolve it: Performance benchmarks using distilled or sub-10B parameter models on prompt adherence and impact scoring tasks

## Limitations

- Framework performance on other epidemic diseases beyond HFMD remains untested, limiting generalizability claims
- RAG grounding effectiveness depends heavily on quality and coverage of pre-constructed guideline corpus
- Paper does not report computational costs or inference latency, making real-world deployment feasibility difficult to assess

## Confidence

- **High confidence**: Architectural separation of semantic interpretation from numerical forecasting is clearly specified and supported by ablation results
- **Medium confidence**: Distributional calibration via Negative Binomial modeling is theoretically sound and shows improved coverage vs. baselines
- **Medium confidence**: Two-region evaluation demonstrates proof-of-concept but small sample size (33 weeks for Lishui) limits statistical power

## Next Checks

1. **Cross-disease validation**: Apply framework to at least one other epidemic disease (e.g., Influenza, Dengue) to test scalarization mechanism's generalizability beyond HFMD
2. **RAG robustness test**: Systematically remove specific guideline topics from retrieval corpus and measure degradation in MAE to quantify RAG's true contribution to stability
3. **Distributional assumption check**: For each forecast origin, plot empirical vs. predicted interval coverage across deciles to identify systematic miscalibration in Negative Binomial mapping, especially at distribution tails