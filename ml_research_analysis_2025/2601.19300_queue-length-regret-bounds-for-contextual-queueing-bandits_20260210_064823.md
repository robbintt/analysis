---
ver: rpa2
title: Queue Length Regret Bounds for Contextual Queueing Bandits
arxiv_id: '2601.19300'
source_url: https://arxiv.org/abs/2601.19300
tags:
- queue
- lemma
- length
- regret
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces contextual queueing bandits, a new framework
  for scheduling jobs with heterogeneous contexts while learning unknown service rates.
  The authors address the challenge of queue length regret when different policies
  may process jobs in different orders, leading to misaligned queue states.
---

# Queue Length Regret Bounds for Contextual Queueing Bandits

## Quick Facts
- arXiv ID: 2601.19300
- Source URL: https://arxiv.org/abs/2601.19300
- Reference count: 40
- Primary result: Introduces contextual queueing bandits with regret bounds of $\tilde{O}(T^{-1/4})$ for stochastic contexts and $O(\log^2 T)$ for adversarial contexts

## Executive Summary
This paper introduces contextual queueing bandits, a new framework for scheduling jobs with heterogeneous contexts while learning unknown service rates. The authors address the challenge of queue length regret when different policies may process jobs in different orders, leading to misaligned queue states. To tackle this, they propose policy-switching queues with a sophisticated coupling argument that allows decomposing queue length regret into the short-term effect of suboptimal choices and their long-term impact on queue state differences. Their algorithm CQB-ε achieves a regret upper bound of $\tilde{O}(T^{-1/4})$, which vanishes for large T, while CQB-Opt achieves $O(\log^2 T)$ for adversarial contexts. The key technical contribution is understanding how instantaneous regret and queue state misalignment propagate through the system, enabling the first provably decaying regret bound in contextual queueing bandit settings.

## Method Summary
The paper proposes two algorithms: CQB-ε for stochastic contexts and CQB-Opt for adversarial contexts. Both use logistic bandit estimation with UCB-style exploration. CQB-ε employs a two-phase approach with pure exploration followed by ε-greedy UCB, while CQB-Opt uses a weighted process analysis for adversarial contexts. The key innovation is the policy-switching queue framework with coupling arguments that decompose queue length regret into manageable components, enabling rigorous regret analysis despite queue state misalignment.

## Key Results
- CQB-ε achieves $\tilde{O}(T^{-1/4})$ queue length regret for stochastic contexts, decaying to zero as T grows
- CQB-Opt achieves $O(\log^2 T)$ regret for adversarial contexts
- First provably decaying regret bound in contextual queueing bandit settings
- Novel coupling argument enables tractable regret decomposition despite queue state misalignment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Policy-switching queues enable tractable regret decomposition despite queue state misalignment.
- Mechanism: Define $Q(t_1, t_2)$ as queue length at $t_2$ under policy $\pi$ from 1 to $t_1$ then optimal $\pi^*$ from $t_1+1$ to $t_2-1$. Telescoping sum gives $R_T = \sum_{t=1}^{T-1} \mathbb{E}[Q(t,T) - Q(t-1,T)]$, turning a hard alignment problem into bounding differences between consecutive policy-switching queues differing by exactly one round.
- Core assumption: Coupling process preserves marginals; departure disagreement events capture regret contribution.
- Evidence anchors: [abstract] "propose the idea of policy-switching queues equipped with a sophisticated coupling argument... novel queue length regret decomposition framework" [section 4] Lemma 4.1 shows $\psi(t,T) \in \{-1, 0, 1\}$, Lemma 4.2 bounds $\mathbb{E}[\psi(t,T)] \leq \sqrt{m_t}\sqrt{\delta_t}$

### Mechanism 2
- Claim: Decaying queue length regret ($\tilde{O}(T^{-1/4})$) emerges from opposite monotonicity between instantaneous service-rate gap ($m_t$) and long-term queue-difference impact ($\delta_t$).
- Mechanism: CQB-ε's two-phase design (pure exploration → ε-greedy UCB) ensures: (1) $m_t$ non-increasing as parameter estimates improve; (2) $\delta_t$ non-decreasing as earlier disagreements propagate longer. Chebyshev's sum inequality bounds $R_T \leq (\sum M_t)(\sum \Delta_t)/T$.
- Core assumption: Assumptions 3.1–3.4 hold; uncertainty term $\|x\|_{V_{t-1,k}^{-1}}$ controllable after τ rounds.
- Evidence anchors: [abstract] "CQB-ε, achieves a regret upper bound of $\tilde{\mathcal{O}}(T^{-1/4})$... understanding how suboptimal job-server pair choices propagate through queue dynamics" [section 5] Theorem 5.5 proof sketch uses Chebyshev's sum inequality

### Mechanism 3
- Claim: Bounding bad rounds via elliptical potential lemma controls uncertainty under adversarial contexts.
- Mechanism: Define bad rounds as $\|x_t\|_{V_{t-1,k_t}^{-1}} > \epsilon/(4\beta_{t-1,k_t})$. Counting version of elliptical potential lemma gives $|B'| \leq O(d^2 \log^2(T)/\epsilon^2)$ (Proposition 6.1). Weighted process $V(t) = \alpha^{-B'(t-1)} e^{\eta Q(t)}$ handles randomness of bad-round occurrence.
- Core assumption: Assumption 3.4 (traffic slack $\epsilon > 0$) persists even under adversarial contexts.
- Evidence anchors: [section 6] Proposition 6.1; Lemma 6.2 mirrors Lemma 5.4 with $\omega' = O(d^2 \log^2(T)/\epsilon^3)$ threshold

## Foundational Learning

- **Logistic bandits (GLM-UCB)**: Service rates $\mu(x^\top \theta^*_k)$ use logistic link; parameter estimation and confidence bounds inherit from logistic bandit literature (Lemma 5.1). Quick check: Can you derive the prediction error bound $|\mu(x^\top \hat{\theta}_{t-1,k}) - \mu(x^\top \theta^*_k)| \leq \beta_{t-1,k} \|x\|_{V_{t-1,k}^{-1}}$?

- **Elliptical potential lemma**: Sums of $\min\{1, \|x_t\|_{V_{t-1,k_t}^{-1}}^2\}$ appear in regret bounds; lemma bounds them as $O(d \log(T))$. Quick check: Why does $\sum_{t=1}^T \min\{1, \|x_t\|_{V_{t-1}^{-1}}^2\} \leq 2d \log(1 + T/(d\lambda))$ hold?

- **Queueing stability and drift analysis**: Negative drift $E[A(t) - D(t) | F_t] \leq -\epsilon/2$ in good rounds ensures queue doesn't explode; tail bounds on $Q(t)$ derive from exponential supermartingale arguments (Lemma C.6). Quick check: How does the weighted process $V(t)$ differ from standard Foster-Lyapunov drift analysis?

## Architecture Onboarding

- **Component map**: Arrivals → Queue State → Job-Server Pair Selection → Service Attempt → Departure Update → Queue State Update

- **Critical path**: 
  1. Pure exploration (CQB-ε only): Round-robin server assignment on arrivals until $\tau = O(d \log(T)/(\sigma_0^4 \epsilon^2))$
  2. Action selection: Maximize $\mu(x^\top \hat{\theta}_{t-1,k}) + \beta_{t-1,k} \|x\|_{V_{t-1,k}^{-1}}$ over $(x,k) \in X_t \times [K]$
  3. Feedback & update: Observe $r_t \in \{0,1\}$; update $\hat{\theta}_{t,k}$, $V_{t,k} = V_{t-1,k} + x_t x_t^\top$ for selected $k=k_t$
  4. Coupling for analysis: When computing $\psi(t,T)$, share $U_{i,1}, U_{i,2}$ across $Q^+(t), Q^-(t)$

- **Design tradeoffs**: 
  - CQB-ε vs. CQB-Opt: $\tilde{O}(T^{-1/4})$ decay (stochastic contexts) vs. $O(\log^2 T)$ polylog (adversarial contexts)
  - Pure-exploration length $\tau$: Larger $\tau$ reduces uncertainty but delays exploitation
  - Exploration rate $\varepsilon = T^{-1/2}$: Balances parameter estimation and exploitation

- **Failure signatures**: 
  - Linear queue growth: Check if traffic slack $\epsilon$ violated or parameter estimates diverged
  - Non-monotonic regret: Under adversarial contexts, switch to CQB-Opt
  - Multi-queue explosion: Coupling argument fails; $\psi(t,T)$ unbounded

- **First 3 experiments**:
  1. Stochastic context validation: Generate i.i.d. features; run CQB-ε with $K=5, d=5, T=5000, \lambda=0.7, \epsilon=0.1$. Plot $Q(T)$ vs. $T$
  2. Adversarial context test: Worst-case feature sequence; run CQB-Opt; expect $Q(T) = O(\log^2 T)$
  3. Ablation on $\varepsilon$: Vary $\varepsilon \in \{T^{-1/4}, T^{-1/2}, T^{-3/4}\}$ for CQB-ε

## Open Questions the Paper Calls Out

- What are the fundamental lower bounds for queue length regret in the contextual queueing bandit setting?
- Can the framework be extended to systems with multiple queues?
- How can operational constraints, such as maximum waiting time, be integrated into the scheduling policy?

## Limitations

- The coupling-based regret decomposition breaks down for multi-queue systems where queue length differences can grow unboundedly
- Stochastic context assumption for CQB-ε's $\tilde{O}(T^{-1/4})$ decay is restrictive; adversarial contexts require slower $O(\log^2 T)$ algorithm
- Both algorithms require prior knowledge of traffic slack $\epsilon$, which may not be available in practice

## Confidence

- **High confidence**: Regret decomposition framework using policy-switching queues (Lemmas 4.1-4.2, section 4 analysis)
- **Medium confidence**: CQB-ε's $\tilde{O}(T^{-1/4})$ regret bound. Theoretical justification but practical significance depends on context distribution
- **Medium confidence**: CQB-Opt's adversarial context performance. Standard elliptical potential argument but weighted process analysis adds complexity

## Next Checks

1. Test the coupling argument on a two-queue system with cross-server routing to verify whether $\psi(t,T)$ remains bounded or grows linearly

2. Implement an adaptive scheme to estimate traffic slack $\epsilon$ online rather than requiring it as input, evaluating performance with mis-specified $\epsilon$

3. Systematically vary context generation from i.i.d. stochastic to adversarial, quantifying the transition point where CQB-ε performance degrades and CQB-Opt becomes necessary