---
ver: rpa2
title: 'FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models'
arxiv_id: '2502.14940'
source_url: https://arxiv.org/abs/2502.14940
tags:
- conflict
- maps
- inpainting
- building
- facade
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents FacaDiffy, a novel method for inpainting unseen
  facade parts in 2D conflict maps derived from LoD2 building models and laser scanning
  point clouds. The core idea leverages a personalized Stable Diffusion model to complete
  conflict maps by addressing occlusions caused by vegetation and other obstacles
  during data collection.
---

# FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models

## Quick Facts
- arXiv ID: 2502.14940
- Source URL: https://arxiv.org/abs/2502.14940
- Reference count: 15
- Key outcome: 22% increase in detection rate for high-definition 3D semantic building reconstruction using inpainted conflict maps

## Executive Summary
FacaDiffy addresses the challenge of inpainting occluded facade regions in 2D conflict maps derived from LoD2 building models and laser scanning point clouds. The method leverages personalized Stable Diffusion models trained on synthetic conflict maps to complete these maps, which are crucial for automatic LoD3 reconstruction and other applications like solar potential analysis. Extensive experiments demonstrate that FacaDiffy outperforms baseline inpainting methods, achieving a 22% increase in detection rate for 3D semantic building reconstruction compared to incomplete conflict maps.

## Method Summary
FacaDiffy combines deterministic ray-casting to generate conflict maps from LoD2 models and MLS point clouds, with a personalized Stable Diffusion inpainting model. The approach first creates synthetic conflict maps using procedural city generators and annotated facade images, then fine-tunes a pre-trained SD model using DreamBooth. During inference, ray analysis identifies occluded regions in real conflict maps, which are then completed using the personalized diffusion model with text prompt conditioning. The method addresses the scarcity of real LoD3 ground truth by leveraging scalable synthetic data generation while maintaining semantic consistency through prompt engineering.

## Key Results
- 22% increase in detection rate for LoD3 reconstruction compared to incomplete conflict maps
- Outperforms baseline methods (Telea, Navier-Stokes, LaMa GAN) on SSIM, LPIPS metrics
- 192 synthetic conflict maps achieve better LPIPS scores than 228 real annotated maps
- Personalization reduces LPIPS by 0.10 on tree-shaped masks compared to pre-trained model

## Why This Works (Mechanism)

### Mechanism 1
Personalizing Stable Diffusion with domain-specific synthetic conflict maps improves inpainting quality over pre-trained models. DreamBooth fine-tuning adapts the pre-trained `sd-v1.5-inpaint` model to the binary conflict map domain by learning structural priors (symmetry, consistency) from synthetically generated facades. This reduces domain discrepancy between natural image priors and abstract conflict map patterns.

### Mechanism 2
Deterministic ray-casting converts sparse point clouds into structured conflict maps that serve as geometric priors for inpainting. Rays from viewpoint `v` to point `p` intersect LoD2 surfaces. Intersection distance classifies each surface point: confirmed (within tolerance), conflicted (exceeds tolerance, indicating openings), or unknown (occluded). These binary masks define inpainting regions with geometric grounding.

### Mechanism 3
Text prompt conditioning enforces semantic consistency (symmetry, structure) in inpainted regions. The prompt "Black background with white patches that are consistent and symmetric to the rest of the image" guides the diffusion process toward structured completions rather than arbitrary fills. Cross-attention layers condition denoising on this textual embedding.

## Foundational Learning

- **Concept:** Stable Diffusion latent diffusion models
  - **Why needed here:** The core inpainting engine operates in latent space (VAE-encoded), not pixel space. Understanding the encoder-decoder pipeline, U-Net denoising, and cross-attention is essential for debugging inpainting artifacts.
  - **Quick check question:** Can you explain why SD operates in latent space rather than pixel space, and how this affects mask propagation during inpainting?

- **Concept:** DreamBooth personalization with prior-preservation loss
  - **Why needed here:** Prevents catastrophic forgetting of pre-trained knowledge while adapting to conflict map domain. Prior-preservation loss maintains diversity in generated samples.
  - **Quick check question:** What is the role of the "class-specific prior preservation" images in DreamBooth, and how does LoRA-based fine-tuning reduce parameter updates?

- **Concept:** Ray-casting and point cloud geometry (LoD2/CityGML)
  - **Why needed here:** Conflict map computation requires understanding how semantic 3D city models (CityGML LoD2) represent building surfaces and how mobile laser scanning (MLS) point clouds are geo-referenced.
  - **Quick check question:** Given a viewpoint `v` and point `p`, what are the three possible intersection scenarios with a LoD2 wall surface, and how does tolerance `t` account for sensor noise?

## Architecture Onboarding

- **Component map:** [LoD2 Model + MLS Point Cloud] → [Ray Casting Engine] → [Conflict Map + Binary Mask] → [Random3Dcity + CMP Facades] → [Synthetic Conflict Maps] → [DreamBooth Personalization] → [FacaDiffy Model] → [Incomplete Conflict Map + Mask] → [SD-Inpainting] → [Completed Conflict Map]

- **Critical path:**
  1. Generate synthetic conflict maps (192 samples, ~1-2 hours on single GPU)
  2. Fine-tune `sd-v1.5-inpaint` with DreamBooth (follow `diffusers` library implementation)
  3. Run deterministic ray-casting on target LoD2 + point cloud pair
  4. Apply personalized model with fixed text prompt

- **Design tradeoffs:**
  - `ndiv` (triangle subdivision): Higher values increase resolution but linearly increase ray-casting cost; default `ndiv=8` balances ~1cm resolution with compute
  - Synthetic vs. real training data: Real LoD3 ground truth is scarce; synthetic data scales but may not capture all architectural variations
  - Binary vs. color-coded conflict maps: Binary simplifies diffusion task but loses semantic class distinctions (windows vs. doors)

- **Failure signatures:**
  - **High IoU but low semantic validity:** Traditional methods (Telea, Navier-Stokes) achieve high IoU by inpainting large continuous regions but violate structural semantics
  - **Tree-shaped mask artifacts:** Pre-trained SD struggles with irregular occlusions; personalized model reduces LPIPS by 0.10
  - **Small window misses:** Top-row windows in Figure 6 remain undetected; suggests resolution or mask dilation limitations

- **First 3 experiments:**
  1. **Baseline comparison on CMP-extended:** Run all methods on 228 annotated images with randomly generated masks. Measure SSIM, IoU, LPIPS. Expected: FacaDiffy achieves SSIM ≥0.91, LPIPS ≤0.08 on random masks.
  2. **Ablation on synthetic data quantity:** Train with 5, 192, and 228 conflict maps (synthetic vs. real). Evaluate on tree-shaped masks. Expected: More synthetic data reduces LPIPS (0.18 → 0.11).
  3. **End-to-end LoD3 reconstruction impact:** Apply inpainted conflict maps to building 23 reconstruction pipeline. Measure detection rate, false alarm rate, and Hausdorff distance against ground-truth LoD3. Expected: +22% detection rate, ~0% change in false alarm rate.

## Open Questions the Paper Calls Out

- **Open Question 1:** To what degree do synthetically generated conflict maps resemble real-world conflict maps, and does this domain gap limit generalization?
  - **Basis in paper:** The authors state in Section 5.2 that "The degree to which the synthetically generated conflict maps resemble real conflict maps requires further investigation."
  - **Why unresolved:** While the synthetic pipeline successfully trains the model, the visual and statistical fidelity of these maps to complex real-world occlusions has not been quantified.
  - **What evidence would resolve it:** A comparative study measuring the distributional shift between synthetic and real conflict map features, potentially using feature-level metrics like FID.

- **Open Question 2:** How can the deterministic ray analysis be adapted to handle transparent facade structures and extruded elements encasing corners?
  - **Basis in paper:** Section 5.2 lists "intricate transparent facade structures and buildings with extruded facade elements that encase corners" as specific limitations of the ray analysis approach.
  - **Why unresolved:** The current ray-casting method assumes opacity and simple planar intersections, causing it to fail on glass surfaces or complex geometry where rays behave unpredictably.
  - **What evidence would resolve it:** An updated ray-tracing heuristic or probabilistic model that successfully identifies conflicts in glass-heavy or geometrically complex facades.

- **Open Question 3:** What is the quantitative impact of completed conflict maps on downstream simulations, specifically solar potential estimation and wind flow?
  - **Basis in paper:** The Conclusion states: "Future work will explore the completed conflict maps in the various application pipelines, such as solar potential estimation of facades and wind flow simulations."
  - **Why unresolved:** The current evaluation is limited to geometric reconstruction metrics rather than the accuracy of physical simulations derived from the reconstructed models.
  - **What evidence would resolve it:** A comparative study showing error reduction in solar irradiance or wind drag calculations when using FacaDiffy-enhanced LoD3 models versus standard LoD2 models.

## Limitations

- **Synthetic data distribution uncertainty:** The claim that 192 synthetic conflict maps outperform 228 real annotated maps relies on the assumption that Random3Dcity-generated facades accurately represent real-world architectural diversity.
- **Single prompt generalization:** The effectiveness of the single heuristic prompt across diverse architectural styles (Gothic, Art Deco, modernist) is untested.
- **Limited end-to-end evaluation scope:** The 22% detection rate improvement is demonstrated only on one building (building 23), requiring broader validation across entire cities.

## Confidence

- **High confidence:** The deterministic ray-casting pipeline for generating conflict maps is well-specified and reproducible with the given parameters (t=0.7m, ndiv=8).
- **Medium confidence:** The personalization approach is supported by LPIPS metrics and ablation studies, but the synthetic data assumption introduces uncertainty.
- **Low confidence:** The text prompt's universality and the 22% detection rate improvement are promising but require broader validation across architectural styles and geographic regions.

## Next Checks

1. **Architectural style generalization:** Evaluate FacaDiffy on a diverse dataset including Gothic cathedrals, Art Deco skyscrapers, and modernist buildings. Compare performance with European LoD2 models to test prompt and synthetic data robustness.

2. **Synthetic data ablation with architectural constraints:** Generate synthetic conflict maps with varying window densities and symmetry levels. Analyze how these factors affect inpainting quality to identify synthetic data limitations.

3. **Large-scale urban deployment:** Apply FacaDiffy to an entire city block (e.g., Munich's inner city). Measure computational efficiency and detection rate consistency across hundreds of buildings to assess scalability.