---
ver: rpa2
title: 'Merge Now, Regret Later: The Hidden Cost of Model Merging is Adversarial Transferability'
arxiv_id: '2509.23689'
source_url: https://arxiv.org/abs/2509.23689
tags:
- attack
- attacks
- adversarial
- test
- transfer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Model merging is increasingly used as an alternative to multi-task
  learning, but its security against adversarial transfer attacks remains underexplored.
  This study investigates the transferability of adversarial examples across merged
  models using 8 merging methods, 7 datasets, and 6 attack strategies across 336 attack
  settings.
---

# Merge Now, Regret Later: The Hidden Cost of Model Merging is Adversarial Transferability

## Quick Facts
- arXiv ID: 2509.23689
- Source URL: https://arxiv.org/abs/2509.23689
- Reference count: 40
- Primary result: Merged models show over 95% vulnerability to adversarial transfer attacks, challenging assumptions of inherent robustness

## Executive Summary
Model merging is increasingly used as an alternative to multi-task learning, but its security against adversarial transfer attacks remains underexplored. This study investigates the transferability of adversarial examples across merged models using 8 merging methods, 7 datasets, and 6 attack strategies across 336 attack settings. The authors challenge the prevailing notion that model merging provides free adversarial robustness by demonstrating that merged models are highly vulnerable to transfer attacks. Key findings include: stronger merging methods increase vulnerability to transfer attacks; mitigating representation bias via representation surgery increases vulnerability when the surrogate is a fine-tuned model; and despite being the weakest method, weight averaging is the most vulnerable to transfer attacks.

## Method Summary
The study evaluates adversarial transferability across merged models through extensive empirical analysis. Researchers employed 8 different model merging techniques including weight averaging, SLUF, MAD, and representation surgery, applied across 7 diverse datasets. They conducted experiments using 6 different attack strategies including white-box and black-box approaches. The evaluation measured transfer attack success rates across 336 distinct attack settings, comparing merged models against their constituent models to quantify relative vulnerability. The study specifically examines how different merging methods affect adversarial transferability, with particular attention to representation bias mitigation techniques.

## Key Results
- Merged models demonstrate over 95% relative transfer attack success rates across tested scenarios
- Stronger merging methods correlate with increased vulnerability to transfer attacks
- Weight averaging, despite being the weakest merging method, shows highest vulnerability to transfer attacks
- Representation surgery increases vulnerability when the surrogate model is fine-tuned

## Why This Works (Mechanism)
The increased vulnerability of merged models to transfer attacks stems from the fundamental nature of how model merging works. When models are merged, their decision boundaries and feature representations are combined in ways that create smoother transitions between classes, making it easier for adversarial perturbations to transfer across models. The merging process effectively averages out the unique defensive characteristics that individual models might have developed, creating a more homogeneous target that is easier to attack through transfer learning.

## Foundational Learning
- **Adversarial Transferability**: Why needed - Understanding how attacks transfer between models is crucial for assessing real-world security risks. Quick check - Can an adversarial example crafted for one model fool another?
- **Model Merging Methods**: Why needed - Different merging techniques create different architectural and representational characteristics. Quick check - How do weight averaging and representation surgery differ in their approach?
- **White-box vs Black-box Attacks**: Why needed - Different attack scenarios require different defensive strategies. Quick check - What information does the attacker have access to in each scenario?
- **Representation Surgery**: Why needed - This technique specifically addresses bias in merged models but has unintended security consequences. Quick check - How does modifying feature representations affect adversarial vulnerability?
- **Fine-tuning Dynamics**: Why needed - The state of the surrogate model significantly impacts transfer attack success. Quick check - Does a fine-tuned model create more transferable attacks than a frozen one?

## Architecture Onboarding

Component Map: Model -> Merging Method -> Dataset -> Attack Strategy -> Transfer Success Rate

Critical Path: Model Selection -> Merging Method Application -> Adversarial Example Generation -> Transfer Attack Evaluation -> Success Rate Measurement

Design Tradeoffs: The study must balance comprehensive evaluation across multiple methods and datasets with computational feasibility. Including more merging methods increases coverage but requires more resources. Similarly, testing across multiple datasets provides generalizability but increases experimental complexity.

Failure Signatures: High transfer success rates indicate vulnerability, particularly when exceeding 95% relative success. Unexpected results like weight averaging being most vulnerable despite being weakest method suggest complex interactions between merging methods and attack transferability.

First Experiments:
1. Compare transfer success rates between merged models and their constituent models using the same attack method
2. Evaluate how different merging strengths affect transfer attack vulnerability across all datasets
3. Test representation surgery's impact on transfer vulnerability when surrogate models are fine-tuned vs frozen

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Experimental scope limited to classification tasks, limiting generalizability to other domains
- Evaluation focuses primarily on white-box and black-box transfer attacks, with limited exploration of adaptive or defense-aware attack strategies
- Claims about practical implications of vulnerability differences across merging methods require more nuanced interpretation

## Confidence

High Confidence:
- Merged models are "highly vulnerable to transfer attacks" with "over 95% relative transfer attack success rates" - supported by extensive experimental data across multiple datasets and attack methods

Medium Confidence:
- "Stronger merging methods increase vulnerability" - statistically significant but practical implications unclear
- Weight averaging is "most vulnerable" despite being weakest method - intriguing finding requiring further investigation

## Next Checks

1. Test merged models against adaptive attacks specifically designed to exploit the unique vulnerabilities of merged architectures

2. Evaluate the transferability phenomenon across different model architectures and domains beyond image classification

3. Investigate whether the observed vulnerabilities persist when merged models undergo additional fine-tuning or regularization specifically targeting adversarial robustness