---
ver: rpa2
title: 'Generative adversarial networks vs large language models: a comparative study
  on synthetic tabular data generation'
arxiv_id: '2502.14523'
source_url: https://arxiv.org/abs/2502.14523
tags:
- data
- synthetic
- tabular
- gpt-4o
- ctgan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study compares zero-shot synthetic tabular data generation
  using GPT-4o (plain-language prompting) against CTGAN (fine-tuned GAN model) across
  three open-access datasets. GPT-4o generated high-fidelity data without access to
  real-world data or fine-tuning, outperforming CTGAN in preserving means, 95% confidence
  intervals, and bivariate correlations.
---

# Generative adversarial networks vs large language models: a comparative study on synthetic tabular data generation

## Quick Facts
- arXiv ID: 2502.14523
- Source URL: https://arxiv.org/abs/2502.14523
- Authors: Austin A. Barr; Robert Rozman; Eddie Guo
- Reference count: 29
- Primary result: GPT-4o outperforms CTGAN in correlation preservation for synthetic tabular data generation using zero-shot prompting

## Executive Summary
This study benchmarks zero-shot synthetic tabular data generation using GPT-4o with plain-language prompts against a fine-tuned CTGAN baseline. GPT-4o demonstrated superior correlation preservation (CorrelationSimilarity scores consistently above 0.97) while requiring no access to real data or fine-tuning. The LLM approach offers an accessible alternative to traditional generative models, though it shows mixed performance in distributional accuracy compared to CTGAN. The results highlight the potential of large language models for synthetic data generation in scenarios where access to real data is limited or privacy concerns exist.

## Method Summary
The study compared zero-shot synthetic data generation using GPT-4o against CTGAN across three open-access datasets. GPT-4o was prompted with natural language descriptions containing means, standard deviations, ranges, and significant bivariate correlations (absolute value >0.20) for obfuscated column names. CTGAN was trained on real data using MinMaxScaler normalization and 3000-5000 epochs. Both methods generated equivalent sample sizes and amplified samples (n=1000). Synthetic data was validated using SDMetrics library metrics including StatisticSimilarity, CorrelationSimilarity, KSComplement, BoundaryAdherence, and NewRowSynthesis.

## Key Results
- GPT-4o achieved correlation similarity scores consistently above 0.97 across all datasets
- CTGAN demonstrated better distributional fidelity (KSComplement) but weaker correlation preservation
- GPT-4o generated data without access to real-world data or fine-tuning
- Boundary adherence violations occurred in GPT-4o outputs but were correctable through explicit constraints

## Why This Works (Mechanism)

### Mechanism 1: Statistical Property Encoding Through Natural Language
Plain-language prompts containing descriptive statistics enable zero-shot synthetic tabular data generation without access to real data. GPT-4o encodes statistical specifications (means, standard deviations, ranges, correlations) as natural language constraints and generates data satisfying these properties by leveraging pre-trained knowledge of numerical relationships and tabular structures.

### Mechanism 2: Explicit Correlation Specification Outperforms Implicit Learning
Specifying bivariate correlations directly in prompts yields more accurate preservation than GAN-based models that must infer correlations from training data. GPT-4o receives explicit correlation coefficients as generation constraints and produces data satisfying these relationships, while CTGAN must learn correlations from limited training samples.

### Mechanism 3: Distribution-Statistics Trade-off in Zero-Shot Generation
Zero-shot LLM generation prioritizes summary statistic fidelity at the cost of distributional accuracy compared to data-trained generative models. GPT-4o optimizes for explicitly specified constraints (means, correlations) but lacks implicit learning of distributional shapes (skewness, kurtosis, multimodality), while CTGAN directly learns full distributions from data through adversarial training.

## Foundational Learning

- **Concept: Zero-shot generation**
  - Why needed here: The paper's central claim is that GPT-4o generates synthetic data without examples or fine-tuning, fundamentally different from GANs requiring training data access.
  - Quick check question: Why does zero-shot generation improve accessibility but potentially limit distributional accuracy compared to trained models?

- **Concept: Fidelity dimensions (statistical vs distributional)**
  - Why needed here: GPT-4o excels at preserving means and correlations but underperforms on KSComplement, indicating distinct quality dimensions that must be evaluated separately.
  - Quick check question: Can a synthetic dataset have perfect mean preservation (StatisticSimilarity=1.0) but fail a Kolmogorov-Smirnov test? Explain how.

- **Concept: Privacy-utility trade-off in synthetic data**
  - Why needed here: The paper claims GPT-4o preserves privacy (NewRowSynthesis=1.0) while maintaining fidelity, but this trade-off is fundamental to synthetic data evaluation.
  - Quick check question: What does NewRowSynthesis=1.0 indicate about the relationship between synthetic and real records, and why might CTGAN show lower scores?

## Architecture Onboarding

- **Component map:**
  - Prompt Engineering -> LLM Generation -> Validation -> Baseline Comparison
  - (Prompt specifications) -> (GPT-4o inference) -> (SDMetrics evaluation) -> (CTGAN training)

- **Critical path:**
  1. Compute real data statistics → univariate (mean, SD, range) and bivariate (correlations with |r|≥0.20)
  2. Construct prompt → obfuscate column names (X1, X2...), specify all statistical constraints
  3. Generate → new session, memory disabled, output as .xlsx or .csv
  4. Validate → SDMetrics fidelity metrics + privacy metrics
  5. Compare → train CTGAN baseline on same real data, generate equivalent sample sizes

- **Design tradeoffs:**
  - GPT-4o: Higher accessibility (no ML expertise), superior correlation preservation, zero data access required, weaker distribution fidelity, possible boundary violations
  - CTGAN: Better distribution preservation, requires RWD access (privacy risk), requires hyperparameter tuning, potential training data memorization
  - Sample amplification: GPT-4o maintains fidelity at n=1000; CTGAN may memorize records at amplified sizes

- **Failure signatures:**
  - Boundary violations: GPT-4o generated negative petal widths (Iris n=150) — indicates insufficient constraint encoding
  - Distribution mismatch: KSComplement consistently lower for GPT-4o across all datasets
  - Cross-generation replication: Fish Measurements showed row overlap between independent GPT-4o trials (mechanism unclear)
  - Training memorization: CTGAN replicated one full record from RWD (Iris n=1000)

- **First 3 experiments:**
  1. Reproduce the correlation preservation finding using the Iris dataset with obfuscated column names; verify CorrelationSimilarity exceeds 0.97 as reported.
  2. Test whether adding skewness/kurtosis specifications to prompts improves KSComplement scores, addressing the distributional weakness.
  3. Validate boundary adherence improvement by adding explicit constraints (e.g., "all measurements must be positive real numbers") and measuring reduction in BoundaryAdherence violations.

## Open Questions the Paper Calls Out

### Open Question 1
Can incorporating higher-order statistical moments (e.g., kurtosis, skewness) into plain-language prompts improve the preservation of distributional characteristics in LLM-generated synthetic data? The authors note that "measures which quantify distributional characteristics (i.e., kurtosis, skewness) may be included in prompts" to address the mixed performance in retaining distributional fidelity compared to CTGAN.

### Open Question 2
How does zero-shot LLM-generated data perform in downstream machine learning tasks compared to data generated by CTGAN? The Discussion states that "evaluations on the applicability of LLM-generated data toward training ML models is necessary" and suggests using "train-synthetic-test-real" approaches.

### Open Question 3
To what extent does the specific ordering of prompt components and the provision of descriptive statistics influence the fidelity of the generated tabular data? The authors state, "it remains unclear how prompting order, content, and provided descriptive statistics affects the fidelity and utility of generated datasets," and suggest performing ablation studies.

## Limitations

- GPT-4o shows weaker distributional fidelity (KSComplement) compared to CTGAN despite superior correlation preservation
- Study uses only three small, well-behaved datasets limiting generalizability to complex, high-dimensional, or non-Gaussian data
- Boundary adherence violations occur but can be corrected through explicit constraints in prompts

## Confidence

- **High confidence**: Correlation preservation superiority of GPT-4o (CorrelationSimilarity consistently >0.97 across datasets)
- **Medium confidence**: Privacy preservation claims (NewRowSynthesis=1.0) based on three datasets with limited size and diversity
- **Medium confidence**: Accessibility advantage of zero-shot generation, though long-term cost-effectiveness requires further evaluation
- **Low confidence**: Generalizability to complex, high-dimensional, or non-Gaussian data distributions

## Next Checks

1. Test whether explicitly specifying skewness and kurtosis values in prompts improves KSComplement scores by 0.1 or more, addressing the current distributional weakness.

2. Validate the correlation preservation finding on at least two additional datasets with non-Gaussian distributions (e.g., power-law, multimodal) to assess generalizability beyond the current well-behaved datasets.

3. Systematically test whether increasing prompt complexity (adding more statistical constraints) degrades correlation preservation or introduces boundary violations, establishing the limits of the zero-shot approach.