---
ver: rpa2
title: 'Feedstack: Layering Structured Representations over Unstructured Feedback
  to Scaffold Human AI Conversation'
arxiv_id: '2506.03052'
source_url: https://arxiv.org/abs/2506.03052
tags:
- feedback
- design
- conversation
- principles
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Feedstack, a speculative interface designed
  to layer structured representations over unstructured feedback conversations between
  users and AI systems. The core idea is to scaffold exploration, reflection, and
  shared understanding by making implicit design principles explicit through interactive
  affordances like chapters, bookmarks, and highlights.
---

# Feedstack: Layering Structured Representations over Unstructured Feedback to Scaffold Human AI Conversation

## Quick Facts
- arXiv ID: 2506.03052
- Source URL: https://arxiv.org/abs/2506.03052
- Reference count: 40
- Primary result: Layered structures can enhance learning by surfacing tacit knowledge and supporting deeper reflection in AI feedback conversations.

## Executive Summary
Feedstack introduces a speculative interface that layers structured representations over unstructured feedback conversations between users and AI systems. The system scaffolds exploration, reflection, and shared understanding by making implicit design principles explicit through interactive affordances like chapters, bookmarks, and highlights. In formative studies with novice designers, participants reported improved awareness of design principles and greater engagement with feedback content, appreciating the ability to revisit key parts of the conversation and explore underlying concepts post-interaction.

## Method Summary
Feedstack was implemented as a web interface with React.js frontend, Django backend, and OpenAI API integration. The system analyzes conversation in real-time to identify design principles, generating chapter content and highlighting key terms. Two formative studies (n=8 each) used think-aloud protocols and semi-structured interviews with novice designers interacting with a mock conversation based on real user utterances. Reflexive thematic analysis examined participant reflections on learning, exploration, and engagement.

## Key Results
- Participants reported improved awareness of design principles and greater engagement with feedback content
- Users appreciated ability to revisit key parts of conversation and explore underlying concepts post-interaction
- Layered structures showed potential for surfacing tacit knowledge and supporting deeper reflection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layering structured representations over dialogue may help surface tacit design principles that would otherwise remain implicit in unstructured conversation.
- Mechanism: Chapters externalize design principles in real-time using an LLM to analyze conversation content, transforming implicit mentions into explicit, navigable learning objects. This creates a shared representation visible to both user and system.
- Core assumption: Learners struggle to extract high-level principles from linear dialogue without external scaffolding; explicit categorization reduces this cognitive burden.
- Evidence anchors:
  - [abstract]: "layered structures can enhance learning by surfacing tacit knowledge and supporting deeper reflection"
  - [section 4.2.1]: "the Chapters externalize the design principles that often remain tacit or implicit within natural language exchanges"
- Break condition: If users ignore the side panel or if LLM-generated chapter labels are inaccurate/misaligned with user mental models, the externalization may add noise rather than clarity.

### Mechanism 2
- Claim: Spatial and temporal navigation affordances (bookmarks, scrub bar) support reflection by enabling users to revisit and compare multiple instances of principle application.
- Mechanism: Bookmarks visually mark where specific principles were discussed, allowing rapid re-location. Per variation theory, juxtaposing multiple examples helps learners notice subtle differences in interpretation across contexts.
- Core assumption: Reflection requires revisiting prior content; linear scroll-based interfaces inhibit comparison and pattern recognition.
- Evidence anchors:
  - [section 4.1.1]: "Juxtaposing these instances allows learners to notice subtle differences in interpretation and application across contexts"
  - [section 5.2.3]: P8 shared, "It's great for navigating through the conversation without scrolling. I'd probably use this feature more after the conversation when I'm implementing changes."
- Break condition: If conversation length is short or principles are discussed only once, bookmark utility diminishes; if markers are visually cluttered, cognitive load may increase.

### Mechanism 3
- Claim: Visual highlighting of key terms draws attention to principle-relevant language, potentially reinforcing recognition and recall via dual coding.
- Mechanism: Highlights apply visual cues (color/emphasis) to text-based feedback, creating parallel visual and verbal representations. Per dual-coding theory, this may improve comprehension and retention.
- Core assumption: Users benefit from visual signal amplification; without it, key terms may be lost in conversational noise.
- Evidence anchors:
  - [section 4.3.1]: "Drawing on dual-coding theory, the highlights augment text-based feedback with visual cues"
  - [section 5.2.2]: P7 noted, "I just noticed the other instances of balance that are highlighted. It's nice to see how the feedback ties into the principles."
- Break condition: If highlights are over-applied or poorly targeted, visual noise may distract rather than guide; user control (toggle on/off) mitigates this but adds interaction overhead.

## Foundational Learning

- Concept: **Design critique and feedback literacy**
  - Why needed here: Feedstack assumes users understand the purpose of design feedback and can recognize that feedback connects to broader principles. Without this, the Chapters and Highlights features may appear as arbitrary categorizations.
  - Quick check question: Can you explain the difference between surface-level feedback ("move this button") and principle-grounded feedback ("improve visual hierarchy to guide attention")?

- Concept: **Shared representations in mixed-initiative systems**
  - Why needed here: The system relies on a visible, mutual representation (Chapters) that both user and AI "share." Understanding this concept helps clarify why externalization matters for alignment.
  - Quick check question: In a human-AI collaborative tool, what would happen if the system's internal state was not visible to the user?

- Concept: **Research-through-design and design probes**
  - Why needed here: The paper explicitly positions Feedstack as a speculative probe, not a validated product. Interpreting the findings requires understanding this methodological stance.
  - Quick check question: What is the difference between a design probe intended to generate insights and a system intended for production deployment?

## Architecture Onboarding

- Component map:
  - Design panel (A) -> displays user's uploaded design artifact
  - Chat panel (B) -> central conversational interface with LLM
  - Chapters panel (C) -> side panel with expandable accordions for each principle
  - Principle toggles (E) -> controls at chat top to enable/disable highlighting
  - Bookmarks (F) -> markers on scrub bar indicating principle discussion points
  - Emerging topics (L) -> suggested related but undiscussed topics (updated prototype)
  - Conversational cues (L) -> suggested user utterances to guide exploration
  - Referencing conversation (M) -> navigation within Chapters linking to feedback instances

- Critical path:
  1. User uploads design artifact → displayed in design panel
  2. User initiates feedback conversation in chat panel
  3. LLM analyzes incoming dialogue → identifies design principles in real-time
  4. Identified principles populate Chapters panel with generated learning materials
  5. Relevant key terms in chat are highlighted based on active toggles
  6. Bookmarks appear on scrub bar at timestamps where principles are discussed
  7. User can click bookmarks to navigate, expand chapters to learn, or toggle highlights to manage cognitive load

- Design tradeoffs:
  - Structure vs. fluidity: More scaffolding (chapters, highlights) risks disrupting natural dialogue flow; the paper explicitly aims to preserve open-ended conversation
  - Automation vs. accuracy: LLM-generated chapters and highlights may mislabel content; opacity signaling topic frequency is a proxy, not a guarantee of relevance
  - Cognitive load vs. visibility: Showing all principles and highlights simultaneously may overwhelm; collapsibility and toggles are mitigations but require active user management
  - Speculative vs. evaluable: Research-through-design prioritizes insight generation over hypothesis testing; this limits generalizable claims about efficacy

- Failure signatures:
  - Users ignore side panels and interact only with linear chat → scaffolding provides no benefit
  - LLM misidentifies principles → chapters and highlights create confusion rather than clarity
  - Highlight density too high → users report visual overwhelm and disable the feature
  - Short conversations yield insufficient bookmark density → navigation affordances appear empty
  - Users expect clickable highlights to provide definitions → interaction model mismatch causes frustration

- First 3 experiments:
  1. **A/B comparison with baseline chatbot**: Measure whether Feedstack users demonstrate improved recall and application of design principles in a post-task assessment compared to a linear ChatGPT interface.
  2. **Highlight density threshold study**: Systematically vary the number of highlighted terms to identify the point at which user-reported cognitive load increases without corresponding learning gains.
  3. **Mislabeling robustness test**: Introduce controlled LLM categorization errors and observe whether users detect and correct them, or whether errors degrade trust and learning outcomes.

## Open Questions the Paper Calls Out
- Does Feedstack improve design learning outcomes compared to standard chatbot interfaces?
- How do layered structures perform during real-time LLM conversations rather than pre-populated mock interactions?
- What level of structured scaffolding optimally supports reflection without disrupting conversational fluidity?
- Do the observed benefits generalize to expert designers or to feedback domains beyond visual design?

## Limitations
- Studies measured self-reported awareness and engagement, not objective improvements in design skills or knowledge retention over time
- User study used fictional conversation rather than live AI interaction, avoiding real-time generation challenges
- Research-through-design approach prioritizes insight generation over hypothesis testing, limiting generalizable claims

## Confidence
- High confidence: Technical implementation of layered interface elements is well-specified and demonstrates clear interaction design principles
- Medium confidence: Formative study results showing improved awareness and engagement are credible but limited by sample size and lack of comparison group
- Low confidence: Claims about long-term learning benefits and principle internalization remain speculative without follow-up studies or transfer task assessments

## Next Checks
1. **A/B comparison with baseline chatbot**: Measure whether Feedstack users demonstrate improved recall and application of design principles in a post-task assessment compared to a linear ChatGPT interface.
2. **Highlight density threshold study**: Systematically vary the number of highlighted terms to identify the point at which user-reported cognitive load increases without corresponding learning gains.
3. **Long-term retention assessment**: Conduct a delayed post-test (e.g., 2 weeks after interaction) to measure whether participants retain and can apply design principles without tool support.