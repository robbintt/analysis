---
ver: rpa2
title: 'Known Meets Unknown: Mitigating Overconfidence in Open Set Recognition'
arxiv_id: '2511.13775'
source_url: https://arxiv.org/abs/2511.13775
tags:
- unknown
- known
- samples
- classes
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses overconfidence in open set recognition, where
  models incorrectly assign high confidence to unknown samples that are semantically
  similar to known classes. The authors propose a two-component framework to mitigate
  this issue.
---

# Known Meets Unknown: Mitigating Overconfidence in Open Set Recognition

## Quick Facts
- arXiv ID: 2511.13775
- Source URL: https://arxiv.org/abs/2511.13775
- Authors: Dongdong Zhao; Ranxin Fang; Changtian Song; Zhihui Liu; Jianwen Xiang
- Reference count: 38
- Primary result: Achieves 95.27% accuracy on GAS, 99.96% on SCADA, and 99.66% on ELECTRA datasets using perturbation-based uncertainty estimation with two-stage detection

## Executive Summary
This paper addresses overconfidence in open set recognition, where models incorrectly assign high confidence to unknown samples that are semantically similar to known classes. The authors propose a two-component framework that first applies controllable parameter perturbations to generate diverse predictions and quantify predictive uncertainty, then employs a two-stage unknown detection process. The method leverages the fact that known samples exhibit larger output variations under perturbations while unknown samples show more consistent predictions. Experiments on three public datasets demonstrate superior performance compared to state-of-the-art methods, with accuracy improvements of 6.22% on GAS and 2.67% on ELECTRA datasets.

## Method Summary
The method combines perturbation-based uncertainty estimation with a two-stage detection framework. First, Gaussian noise is injected into model parameters across multiple perturbations to estimate predictive uncertainty. Samples with low uncertainty are tentatively classified as unknown. Second, a two-stage detection process refines these decisions: Stage 1 uses ISDA with GMM soft assignment to align subclass distributions, and Stage 2 employs a Decision Tree to classify remaining candidates. The approach requires dataset-specific hyperparameter tuning including perturbation count B, noise scale λ, uncertainty threshold μ*, and subclass counts H₁ and H₂.

## Key Results
- Accuracy improvements of 6.22% on GAS dataset and 2.67% on ELECTRA dataset compared to state-of-the-art methods
- Overall accuracy scores reaching 95.27% on GAS, 99.96% on SCADA, and 99.66% on ELECTRA
- Demonstrates effectiveness in detecting unknown samples that are semantically similar to known classes

## Why This Works (Mechanism)

### Mechanism 1: Perturbation-Based Uncertainty Inversion
- Claim: Known and unknown samples exhibit inverted uncertainty patterns under parameter perturbations—known samples show higher uncertainty while unknown samples show lower, more consistent uncertainty.
- Mechanism: Gaussian noise ε ~ N(0, σ²) is injected into model parameters across B independent perturbations. Predictive uncertainty μ(x) is computed as the squared difference between perturbed predictions and the original prediction in logit space. The logit transformation linearizes probability differences for more stable uncertainty measurement.
- Core assumption: Known samples lie on learned manifolds that are disrupted by perturbations, producing larger output variations, while unknown samples produce consistent outputs because they lack learned manifold structure.

### Mechanism 2: Progressive Refinement Through Threshold-Guided Partitioning
- Claim: A two-stage detection process with hard threshold filtering followed by classifier-based refinement improves discrimination when uncertainty alone is insufficient.
- Mechanism: Stage 1 uses uncertainty threshold μ* to partition samples into clear unknowns and candidates. ISDA with GMM soft assignment performs subclass-level distribution alignment on merged known/unknown data. Stage 2 trains a Decision Tree on ISDA outputs to refine remaining candidates.
- Core assumption: Low-uncertainty unknown samples are reliably separable and can serve as training signal for subsequent classifiers; ambiguous samples benefit from learned decision boundaries rather than threshold-based rules.

### Mechanism 3: Subclass Distribution Alignment via ISDA-GMM
- Claim: Modeling each class as multiple subclasses with probabilistic assignment improves separability for overlapping distributions.
- Mechanism: ISDA splits each known class into H₂ subclasses and unknown data into H₁ subclasses, performing distribution alignment in feature space. GMM replaces hard K-means for smoother boundaries. Gaussian Naïve Bayes provides calibrated probabilities for downstream use.
- Core assumption: Known classes may have multi-modal distributions that benefit from subclass decomposition; GMM soft assignment prevents boundary artifacts from hard clustering.

## Foundational Learning

- **Concept: Manifold Hypothesis in Deep Learning**
  - Why needed here: The entire perturbation-based uncertainty mechanism relies on the idea that models learn manifold structures of training data; perturbations disrupt these structures differentially for known vs. unknown samples.
  - Quick check question: Can you explain why a sample that lies on the learned data manifold would respond differently to parameter perturbations than one that lies off-manifold?

- **Concept: Open Set Recognition vs. Closed-Set Classification**
  - Why needed here: OSR requires simultaneous known-class classification AND unknown rejection; this dual objective differs fundamentally from standard classification and motivates the two-stage detection architecture.
  - Quick check question: Why can't we simply use low softmax confidence as an unknown detection threshold? What failure mode does this create?

- **Concept: Uncertainty Quantification via Ensembling/Perturbation**
  - Why needed here: The paper uses parameter perturbation as a lightweight alternative to Bayesian uncertainty estimation; understanding why prediction variance correlates with epistemic uncertainty is essential.
  - Quick check question: How does perturbation-based uncertainty differ from entropy-based confidence, and why might the former better separate known/unknown samples?

## Architecture Onboarding

- **Component map:**
Input -> Trained CNN Classifier C
         ↓
    [Perturbation Module] → B perturbed models {C₁...C_B}
         ↓                        ↓
    Original prediction    B perturbed predictions
         ↓                        ↓
         └──────── Uncertainty μ(x) computation ──────────┘
                                  ↓
                    ┌─────────────┴─────────────┐
                    ↓                           ↓
              μ ≤ μ* (clear unknown)      μ > μ* (candidate)
                    ↓                           ↓
                 Assign K+1              Stage 1: ISDA
                                              ↓
                                    ┌─────────┴─────────┐
                                    ↓                   ↓
                              ISDA=1 (unknown)    ISDA=0 (known candidate)
                                    ↓                   ↓
                               Assign K+1         Stage 2: DT
                                                        ↓
                                              ┌─────────┴─────────┐
                                              ↓                   ↓
                                          DT=1 (unknown)     DT=0 (known)
                                              ↓                   ↓
                                         Assign K+1        Classify via C

- **Critical path:** Uncertainty threshold μ* → quality of PL set → ISDA training data quality → DT boundary refinement. Errors in early stages compound.

- **Design tradeoffs:**
  - B (perturbation count): More samples improve uncertainty reliability but increase inference cost. Paper finds B=7-9 optimal; B>9 shows diminishing returns from over-smoothing.
  - λ (noise scale): Too small → insufficient discrimination; too large → model robustness collapses. Must balance perturbation strength against model stability.
  - H₂ (subclass count): Dataset-dependent. Compact classes (GAS) prefer H₂=1; diverse classes (ELECTRA) benefit from H₂=5.
  - μ* threshold: Paper shows relative robustness, but aggressive thresholds risk contaminating PL with known samples.

- **Failure signatures:**
  - High accuracy but low TDR: Threshold μ* too aggressive, missing unknowns
  - Low accuracy on compact datasets (like GAS): H₂ overspecified, fragmenting representations
  - Uncertainty distributions overlapping: Inter-class overlap too severe; consider data-level interventions
  - DT stage dominates classifications: ISDA failing to provide useful signal; check PL quality

- **First 3 experiments:**
  1. **Baseline perturbation validation:** On a held-out validation set, visualize uncertainty distributions for known vs. unknown samples. Confirm inverted pattern (known=high, unknown=low) before proceeding. If distributions overlap significantly, adjust λ before tuning other parameters.
  2. **Ablation by stage:** Run "Perturbation Only" → "w/o ISDA" → "w/o DT" → Full pipeline. Quantify each stage's contribution. Per Table II, expect largest gains on datasets with overlap (GAS: 72.96% → 95.27%).
  3. **H₂ sensitivity sweep:** For each dataset, test H₂ ∈ {1, 2, 3, 4, 5}. Plot accuracy curves. Expect decreasing trend for compact classes (GAS), stable/increasing for diverse classes (ELECTRA, SCADA). Use this to characterize your data's intra-class variability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive perturbation strategies improve performance and scalability compared to the current fixed-noise approach?
- Basis in paper: The conclusion states that "Future work will focus on exploring adaptive perturbation strategies... to further improve scalability."
- Why unresolved: The current method relies on a fixed noise scale factor (λ) and a fixed number of perturbations (B), which requires manual tuning via grid search for different datasets.
- What evidence would resolve it: A dynamic mechanism that adjusts perturbations based on input characteristics, demonstrating superior or equivalent performance without requiring dataset-specific hyperparameter tuning.

### Open Question 2
- Question: How can the framework be extended to distinguish between multiple distinct unknown classes rather than treating them as a single category?
- Basis in paper: The conclusion proposes "clustering-based techniques to... enable fine-grained recognition of unknown classes."
- Why unresolved: The current methodology models all unknown samples as a single "unknown" class (K+1) and lacks the capacity to differentiate between various semantic types of unknown instances.
- What evidence would resolve it: An extension of the two-stage detection module that successfully clusters rejected samples into semantically meaningful sub-groups consistent with ground-truth labels.

### Open Question 3
- Question: Does the predictive uncertainty behavior generalize to standard visual benchmarks (e.g., CIFAR, TinyImageNet) or natural image datasets?
- Basis in paper: The experiments are restricted to industrial control and traffic datasets (SCADA, GAS, ELECTRA), whereas the related work discusses standard computer vision applications.
- Why unresolved: It is unclear if the core assumption—that known samples exhibit larger output variations under perturbation than unknowns—holds true for high-dimensional natural image manifolds.
- What evidence would resolve it: Experimental results on standard OSR vision benchmarks showing that the uncertainty distributions for known and unknown classes remain separable.

## Limitations

- The perturbation-based uncertainty mechanism relies heavily on the manifold hypothesis assumption, which may not hold when unknown samples are semantically close to known classes, requiring careful threshold tuning.
- The framework requires dataset-specific hyperparameter tuning (particularly λ, μ*, and H₂), limiting its generalizability without extensive calibration for each new dataset.
- The comparison to a limited set of baselines leaves questions about whether performance gains are due to specific architectural choices or simply better hyperparameter tuning.

## Confidence

- **High confidence:** The perturbation-based uncertainty estimation mechanism is well-grounded in established deep learning theory and produces the expected inverted uncertainty patterns in experiments.
- **Medium confidence:** The two-stage detection process demonstrates improved performance, but the contribution of each component (ISDA vs. DT) is not fully isolated, and the method's robustness to threshold selection (μ*) is only partially explored.
- **Medium confidence:** The subclass distribution alignment via ISDA-GMM shows dataset-dependent benefits, but the theoretical justification for the specific subclass counts and the replacement of hard K-means with GMM lacks extensive validation.

## Next Checks

1. Test the perturbation-based uncertainty mechanism on a dataset where unknown samples are intentionally drawn from the same semantic distribution as known classes (e.g., OOD CIFAR-10 using CIFAR-100 unknowns) to verify the inverted uncertainty pattern breaks down as expected.

2. Perform a systematic ablation study comparing the two-stage approach against simpler single-stage classifiers with learned uncertainty thresholds to quantify the marginal benefit of the progressive refinement.

3. Evaluate the method's sensitivity to hyperparameter choices by conducting a grid search across λ, μ*, and H₂ values to map the performance landscape and identify regions where the method is robust versus fragile.