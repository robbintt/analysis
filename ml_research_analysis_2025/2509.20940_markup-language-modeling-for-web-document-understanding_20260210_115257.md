---
ver: rpa2
title: Markup Language Modeling for Web Document Understanding
arxiv_id: '2509.20940'
source_url: https://arxiv.org/abs/2509.20940
tags:
- product
- markuplm
- information
- data
- review
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the challenge of extracting detailed, up-to-date
  product information from shopping review websites to support applications like customer
  analysis and product recommendation. To address this, the authors fine-tune MarkupLM
  on product data from review sites of varying sizes and develop a variant called
  MarkupLM++, which extends predictions to internal nodes of the DOM tree.
---

# Markup Language Modeling for Web Document Understanding

## Quick Facts
- arXiv ID: 2509.20940
- Source URL: https://arxiv.org/abs/2509.20940
- Reference count: 0
- Primary result: Fine-tuned MarkupLM++ achieves 0.906 precision, 0.724 recall, and 0.805 F1 for product attribute extraction from review sites.

## Executive Summary
This paper addresses the challenge of extracting product information from shopping review websites by fine-tuning MarkupLM, a model that jointly encodes DOM structure and text. The authors develop MarkupLM++, which extends predictions to internal DOM nodes, enabling direct extraction of attributes stored in non-leaf positions. Experiments show that larger and more diverse training sets improve accuracy, and internal node inclusion helps specific attributes like product links at the cost of slight overall performance drops. The final model achieves strong extraction performance with precision 0.906, recall 0.724, and F1 0.805.

## Method Summary
The authors fine-tune MarkupLM on product data from review sites of varying sizes, extending predictions to internal DOM nodes to recover attributes stored in non-leaf positions. They insert internal HTML tags as tokens and compute multi-label cross-entropy loss directly on nodes, resolving the mismatch between token-level predictions and node-level annotations. The approach is evaluated across multiple domains with different DOM structures, comparing leaf-only and internal-node prediction variants.

## Key Results
- Fine-tuning MarkupLM on larger and more diverse training sets improves extraction accuracy (micro-F1 from 0.746 to 0.805).
- Including internal nodes improves recall for product links (0.632 vs 0.339) and product review F1 (0.922), though overall F1 slightly decreases.
- The final model achieves precision 0.906, recall 0.724, and F1 0.805 on product attribute extraction.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint encoding of DOM structure (via XPath embeddings) with text tokens enables the model to learn which structural positions tend to contain target attributes.
- Mechanism: MarkupLM represents each node by concatenating an XPath embedding (tag and subscript embeddings passed through a feed-forward network) with its text embedding, then processes the combined sequence with a transformer. The XPath provides positional priors while the transformer learns contextual semantics.
- Core assumption: Product attributes correlate with specific structural patterns across domains; XPath patterns generalize beyond surface text.
- Evidence anchors:
  - [abstract] "We fine-tuned MarkupLM on product data gathered from review sites of different sizes."
  - [section 2, p.2] "MarkupLM ... processes a node represented by both an XPath embedding and its text. The XPath embedding is created by embedding each tag and subscript separately, concatenating them, and passing them through a feed-forward neural network."
  - [corpus] Related work on markup-based extraction (e.g., MarkupDM, WebFormer) similarly relies on structural signals; corpus FMR range 0.35–0.58 suggests moderate cross-paper consistency but not uniform replication.
- Break condition: When sites radically diverge in DOM conventions (e.g., single-page apps with dynamic `div` nesting), XPath priors may not transfer and performance degrades.

### Mechanism 2
- Claim: Scale and domain diversity in fine-tuning data improve extraction accuracy by exposing the model to more attribute realization patterns.
- Mechanism: Increasing the number of domains and samples broadens the distribution of valid XPath–attribute mappings the model observes, reducing overfitting to site-specific quirks and improving generalization to unseen domains.
- Core assumption: Attribute semantics share cross-domain regularities; more diverse training yields better coverage of these regularities.
- Evidence anchors:
  - [abstract] "Our experiments show that using larger and more diverse training sets improves extraction accuracy overall."
  - [section 4.2, p.5–6] Comparing MarkupLM p-17 (micro-F1 0.746) to MarkupLM p-48 (micro-F1 0.805) shows substantial improvement from larger training sets.
  - [corpus] No direct corpus replication of the scaling claim for this specific task; related web extraction work focuses on architecture, not training set scaling—evidence is paper-internal.
- Break condition: When new domains use unseen attribute schemas or radically different naming conventions, scale alone may not close the gap without schema alignment or few-shot adaptation.

### Mechanism 3
- Claim: Inserting internal HTML nodes as tokens enables direct node-level predictions, which can recover attributes stored in non-leaf positions.
- Mechanism: MarkupLM++ augments the input sequence with tag tokens and computes multi-label cross-entropy loss directly on nodes rather than aggregating token-level predictions. This resolves the level-mismatch problem where annotations apply to nodes but baseline predictions apply to tokens.
- Core assumption: Some product attributes are structurally located at internal nodes; the pre-trained transformer can adapt to tag tokens despite not being pre-trained on them.
- Evidence anchors:
  - [abstract] "We also find that including internal nodes helps with some product attributes, although it leads to a slight drop in overall performance."
  - [section 3, p.3–4] "The idea is inserting the internal nodes (HTML tags) to the input text to MarkupLM as new tokens."
  - [section 4, p.4; Table 2, p.5] MarkupLM++ achieves higher recall for product link (0.632 vs. 0.339) and best F1 for product review (0.922) among the three models.
  - [corpus] No direct replication of internal-node insertion in neighbors; mechanism evidence is paper-internal.
- Break condition: Adding internal nodes exponentially increases prediction targets; with fixed training data, sparsity can reduce overall accuracy. Without pre-training on internal nodes, the model may underperform on average metrics.

## Foundational Learning

- Concept: DOM tree structure and XPath notation
  - Why needed here: MarkupLM's core innovation is encoding structural position via XPath; without understanding DOM hierarchy and XPath syntax, one cannot interpret why certain nodes are prioritized or how predictions map to page elements.
  - Quick check question: Given an XPath `/html/body/div[2]/span[1]`, can you identify the corresponding node's position in the DOM tree?

- Concept: Token-level vs. node-level sequence labeling
  - Why needed here: The paper explicitly contrasts token-level prediction (baseline MarkupLM) with node-level prediction (MarkupLM++) and discusses aggregation and mismatch issues.
  - Quick check question: If a model predicts labels per token but annotations are per node, what post-processing step is required to align them?

- Concept: Fine-tuning transfer learning
  - Why needed here: The method builds on a pre-trained MarkupLM (trained on 24M Common Crawl pages) and fine-tunes on product review domains; understanding transfer assumptions is critical for reproducing or extending results.
  - Quick check question: What could go wrong if the pre-training distribution (general web pages) differs significantly from the fine-tuning distribution (product review sites)?

## Architecture Onboarding

- Component map:
  Pre-trained RoBERTa-based MarkupLM with XPath embeddings -> Input pipeline (DOM parsing to XPath extraction to text+XPath sequence) -> Prediction head (token-level for baseline, node-level for MarkupLM++ via direct node loss) -> Post-processing (XPath normalization, nested-content removal, product grouping)

- Critical path:
  1. Crawl and parse HTML -> extract DOM and XPath
  2. Generate input sequences (with or without internal node tokens)
  3. Fine-tune MarkupLM(MarkupLM++) on labeled product attributes
  4. Run inference -> post-process predictions -> group by product

- Design tradeoffs:
  - Leaf-only vs. internal-node prediction: Leaf-only (p-48) yields higher average metrics; internal-node (MarkupLM++) improves recall for attributes in non-leaf positions but reduces overall F1 due to sparsity
  - Training set size vs. annotation cost: Larger, more diverse sets improve performance (p-17 -> p-48) but require more labeling effort
  - Pre-training compatibility: MarkupLM was not pre-trained on internal nodes; fine-tuning alone may be insufficient for optimal internal-node predictions

- Failure signatures:
  - Low recall for product links in p-48 (0.339) despite high precision -> indicates target attribute is in an internal node that gets pruned
  - Zero F1 for rare attributes (e.g., product_bottom_line_label) -> attribute absent in training/test domains or severely underrepresented
  - Mis-grouped attributes on list pages -> post-processing required to associate predictions with the correct product container

- First 3 experiments:
  1. **Baseline replication**: Fine-tune MarkupLM on the p-17 dataset; verify micro-F1 is approximately 0.746 and identify which attributes underperform
  2. **Internal-node ablation**: Retain internal nodes (MarkupLM++ setup) on the p-48 dataset; confirm recall gains for product links and compare overall F1 drop
  3. **Domain generalization test**: Hold out 5 unseen domains (as in p-48 setup); measure zero-shot performance degradation and analyze which attributes transfer poorly

## Open Questions the Paper Calls Out
None

## Limitations
- Cross-domain generalizability is uncertain as the paper doesn't test on radically different DOM structures or attribute schemas
- Internal node inclusion improves recall for specific attributes but reduces overall performance due to prediction sparsity
- The model wasn't pre-trained on internal nodes, potentially limiting optimal node-level prediction performance

## Confidence
- **High confidence** in larger, more diverse training sets improving extraction accuracy (supported by direct micro-F1 comparisons: 0.746 → 0.805)
- **Medium confidence** in internal node inclusion helping some attributes (attribute-specific improvements but overall F1 drop)
- **Low confidence** in broader cross-domain generalization claims (no testing on radically divergent schemas)

## Next Checks
1. **Zero-shot cross-schema evaluation**: Hold out 5 domains with entirely different attribute schemas and measure extraction performance without fine-tuning
2. **Internal node pre-training ablation**: Pre-train a variant of MarkupLM on internal node tokens and compare fine-tuned performance on node-level predictions to current approach
3. **Dynamic DOM robustness test**: Evaluate the model on single-page applications with dynamically generated DOM structures to assess XPath-based generalization under structural variation