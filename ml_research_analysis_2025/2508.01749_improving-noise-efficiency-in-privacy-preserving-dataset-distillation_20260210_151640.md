---
ver: rpa2
title: Improving Noise Efficiency in Privacy-preserving Dataset Distillation
arxiv_id: '2508.01749'
source_url: https://arxiv.org/abs/2508.01749
tags:
- dataset
- noise
- privacy
- subspace
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of creating compact, private synthetic
  datasets through dataset distillation while maintaining strong privacy guarantees.
  The authors introduce Dosser, a framework that decouples the sampling and optimization
  stages (DOS) to reduce cumulative noise and improve signal utilization.
---

# Improving Noise Efficiency in Privacy-preserving Dataset Distillation

## Quick Facts
- arXiv ID: 2508.01749
- Source URL: https://arxiv.org/abs/2508.01749
- Reference count: 40
- Authors: Runkai Zheng; Vishnu Asutosh Dasu; Yinong Oliver Wang; Haohan Wang; Fernando De la Torre
- One-line primary result: Dosser achieves 10.0% accuracy improvement over state-of-the-art in DP dataset distillation under strict privacy budget (ε=1, δ=10⁻⁵)

## Executive Summary
This paper tackles the challenge of creating compact, private synthetic datasets through dataset distillation while maintaining strong privacy guarantees. The authors introduce Dosser, a framework that decouples the sampling and optimization stages (DOS) to reduce cumulative noise and improve signal utilization. They also propose subspace-based error reduction (SER) using auxiliary data to enhance signal-to-noise ratios by projecting training signals onto informative subspaces. Evaluated on CIFAR-10, MNIST, and FashionMNIST under a strict privacy budget of (ε=1, δ=10⁻⁵), Dosser achieves a 10.0% accuracy improvement over the state-of-the-art with 50 images per class and 8.3% improvement using just one-fifth the distilled set size. These results demonstrate Dosser's superior ability to balance privacy and utility in private dataset distillation.

## Method Summary
Dosser introduces a novel framework that decouples sampling from optimization (DOS) and employs subspace-based error reduction (SER) to improve signal-to-noise ratios in differentially private dataset distillation. The method first extracts and privatizes training signals in a dedicated sampling stage, then repeatedly uses these precomputed signals for extended optimization iterations. SER further enhances utility by projecting signals into an informative subspace learned from auxiliary data, concentrating signal power on high-utility dimensions before DP noise is added. This combination allows Dosser to achieve better convergence and higher accuracy while operating under strict privacy constraints.

## Key Results
- Dosser achieves 10.0% accuracy improvement over state-of-the-art with 50 images per class on CIFAR-10, MNIST, and FashionMNIST
- Dosser attains 8.3% accuracy improvement while using only one-fifth the distilled set size compared to baseline methods
- Under strict privacy budget (ε=1, δ=10⁻⁵), Dosser demonstrates superior balance of privacy and utility in dataset distillation

## Why This Works (Mechanism)

### Mechanism 1
Decoupling sampling and optimization allows extended optimization without additional noise, improving convergence under a fixed privacy budget. The framework first samples and privatizes training signals in a dedicated sampling stage, then repeatedly uses these precomputed signals for many optimization iterations. This breaks the forced 1:1 relationship between sampling steps (which cost privacy) and optimization steps (which do not). Core assumption: optimization can achieve better convergence on the distilled dataset if given more iterations, and precomputed noisy signals remain sufficiently informative for these additional iterations. Break condition: if optimization requires signals to be freshly sampled at each step, the benefits of decoupling will degrade.

### Mechanism 2
Projecting training signals onto an informative subspace increases the signal-to-noise ratio, reducing the impact of DP noise on estimation accuracy. An auxiliary dataset (from a generative model) is used to identify principal components that capture informative signal variance. Training signals are projected into this lower-dimensional subspace before DP noise is added, concentrating signal power in fewer dimensions while isotropic DP noise spreads across all dimensions. Core assumption: the auxiliary dataset distribution aligns sufficiently with the private dataset such that the discovered subspace captures informative dimensions for the private data. Break condition: if the auxiliary dataset poorly represents the private data distribution, projection error may outweigh SNR gains.

### Mechanism 3
The combination of DOS and SER provides synergistic benefits: DOS enables more optimization iterations, while SER ensures those iterations are more effective by operating on higher-quality signals. DOS produces a fixed set of DP-protected signals that can be reused, while SER enhances the quality of each signal by projecting it onto an informative subspace. Together, they maximize utility extracted from the limited privacy budget. Core assumption: the benefits of SER compound with the benefits of DOS rather than interfering with each other. Break condition: if the subspace projection distorts signal properties essential for extended optimization, the combined benefit may diminish.

## Foundational Learning

**Differential Privacy (DP) Basics (Gaussian Mechanism, Composition, Sensitivity)**
- Why needed: The entire method is built on providing (ε, δ)-DP guarantees. You must understand how noise is calibrated to sensitivity, how composition accumulates privacy loss, and why post-processing preserves privacy.
- Quick check: If you perform k queries on a private dataset, each with noise σ calibrated for a single query, is the overall privacy guarantee still (ε, δ)? If not, what happens to ε?

**Dataset Distillation Paradigms (Distribution/Gradient Matching)**
- Why needed: Dosser builds upon distribution matching methods like NDPDC. Understanding the core idea—optimizing synthetic data to match signals from real data—is essential to grasp what DOS is decoupling and what SER is enhancing.
- Quick check: In gradient matching, what objective is the synthetic dataset being optimized to minimize?

**Subspace Methods (PCA) and Signal-to-Noise Ratio (SNR)**
- Why needed: SER relies on PCA to find an "informative subspace." You need to understand how PCA identifies directions of maximal variance and why projecting data into a lower-dimensional subspace can improve SNR when additive noise is isotropic.
- Quick check: If a signal lies entirely in a 3D subspace of a 100D space, and you add Gaussian noise to all 100 dimensions, will the SNR improve after projecting back to the 3D subspace? Why or why not?

## Architecture Onboarding

**Component Map:**
Auxiliary Data Generator -> Subspace Discovery (SER) -> Sampling Stage (DOS) -> Optimization Stage (DOS)

**Critical Path:**
1. Generate or obtain a suitable auxiliary dataset
2. Run Subspace Discovery to precompute projection matrices for each sampling iteration
3. Execute the Sampling Stage to build the DP-protected signal store. This is the only step that directly queries the private data
4. Execute the Optimization Stage for many more iterations, using only data from the signal store

**Design Tradeoffs:**
1. Privacy Budget Split (SER): Allocating more budget to auxiliary data generation (ε₁) leaves less for distillation (ε₂). Empirically, a 20%/80% split worked well for MNIST/FashionMNIST
2. Subspace Dimension (SER): Smaller dimension improves noise reduction but increases projection error. A U-shaped MSE curve is observed
3. Sampling vs. Optimization Iterations (DOS): I₁ (sampling) consumes privacy budget; I₂ (optimization) does not. You can set I₂ ≫ I₁ to improve convergence without extra privacy cost
4. Auxiliary Data Source: Using a foundation model incurs no privacy cost but may have distribution mismatch. Training a DP generative model uses part of the budget but ensures better alignment

**Failure Signatures:**
1. Synthetic images look noisy or fail to converge: Likely I₂ is too low, or the learning rate during optimization needs adjustment
2. Accuracy plateaus or degrades with increasing subspace dimension: The subspace dimension is too large, providing little noise-reduction benefit, or the auxiliary data is not representative
3. Performance is poor despite tuning: The auxiliary dataset distribution is too different from the private data, causing high projection error

**First 3 Experiments:**
1. Baseline Reproduction: Implement the ablated "baseline without DOS and SER" on a simple dataset (MNIST) to establish a performance baseline and verify the DP accounting
2. DOS-Only Ablation: Fix I₁ and increase I₂ to observe the accuracy gain from decoupling. Plot accuracy vs. I₂ to find a point of diminishing returns
3. SER-Only Ablation with Ideal Auxiliary Data: Use the test set or a non-private copy of the training set as auxiliary data to establish an upper bound on SER's potential

## Open Questions the Paper Calls Out

**Open Question 1:** How can the Decoupled Optimization and Sampling (DOS) framework be adapted for dataset distillation methods that rely on pre-trained models or trajectory matching rather than randomly initialized networks? The current Dosser implementation and noise analysis are tailored to signals extracted from randomly initialized networks, which exhibit different noise sensitivity compared to the pre-trained features used in state-of-the-art large-scale distillation.

**Open Question 2:** How does the performance of Subspace-based Error Reduction (SER) degrade when the auxiliary dataset distribution significantly diverges from the private dataset in specialized domains? SER relies on projecting signals onto a subspace learned from auxiliary data. Theorem 1 shows that "Projection Error" increases with misalignment between the auxiliary and private datasets, but the specific tolerance for distribution shift in specialized fields remains unexplored.

**Open Question 3:** Is there a theoretically optimal method to determine the privacy budget split (ε₁ vs. ε₂) between training the auxiliary generative model and the distillation process? The authors rely on empirical tuning to select the budget split, noting that an 0.8:0.2 split is a "good trade-off" without deriving this analytically. There is a complex trade-off where allocating more budget to the auxiliary model improves the subspace, while allocating more to distillation improves signal fidelity.

## Limitations

- SER assumes the auxiliary dataset distribution aligns well with the private dataset; poor alignment leads to projection error that can negate SNR gains
- DOS assumes the precomputed noisy signals remain informative for extended optimization iterations; if optimization requires fresh signal sampling, the benefits of decoupling may diminish
- The paper does not explore alternative projection methods beyond PCA, nor does it analyze how SER performs when the auxiliary data is from a fundamentally different domain

## Confidence

- **High:** The DOS mechanism (decoupling sampling and optimization) is well-established in privacy-preserving pipelines, and the paper's implementation follows this principle correctly
- **Medium:** The SER mechanism (subspace projection for SNR improvement) is theoretically sound and supported by the formal MSE decomposition, but its empirical effectiveness depends heavily on auxiliary data quality
- **Medium:** The synergistic claim (DOS + SER) is supported by ablation studies, but the evidence is limited to the specific datasets and hyperparameters tested

## Next Checks

1. **Auxiliary Data Quality Sensitivity:** Systematically vary the auxiliary dataset (e.g., using test set as auxiliary, using domain-shifted auxiliary) to quantify the impact of distribution mismatch on SER performance

2. **Projection Method Comparison:** Replace PCA with other dimensionality reduction techniques (e.g., random projection, autoencoders) to test if the SNR improvement is specific to PCA or a general property of subspace projection

3. **Signal Freshness Requirement:** Implement a variant of DOS where signals are resampled at regular intervals during optimization to test if the precomputed signals in the original DOS truly remain informative for all I₂ iterations