---
ver: rpa2
title: Semantic Similarity in Radiology Reports via LLMs and NER
arxiv_id: '2510.03102'
source_url: https://arxiv.org/abs/2510.03102
tags:
- reports
- report
- radiology
- similarity
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of evaluating semantic differences
  between preliminary and final radiology reports to support junior radiologist training.
  The authors propose Llama-EntScore, a hybrid method combining Named Entity Recognition
  (NER) with Llama 3.1 to compute similarity scores and provide interpretable feedback.
---

# Semantic Similarity in Radiology Reports via LLMs and NER

## Quick Facts
- arXiv ID: 2510.03102
- Source URL: https://arxiv.org/abs/2510.03102
- Authors: Beth Pearson; Ahmed Adnan; Zahraa S. Abdallah
- Reference count: 28
- Primary result: Llama-EntScore achieves 67% exact-match accuracy and 93% accuracy within ±1 of radiologist-provided ground truth scores for semantic similarity between preliminary and final radiology reports.

## Executive Summary
This paper addresses the challenge of evaluating semantic differences between preliminary and final radiology reports to support junior radiologist training. The authors propose Llama-EntScore, a hybrid method combining Named Entity Recognition (NER) with Llama 3.1 to compute similarity scores and provide interpretable feedback. NER extracts clinical entities from reports, while the LLM assesses contextual agreement between shared entities. The method introduces an Entity-Based Semantic Agreement Score (ESAS) that weighs missing, mismatched, and surplus entities based on clinical significance. Evaluated on 115 anonymized report pairs, Llama-EntScore achieves 67% exact-match accuracy and 93% accuracy within ±1 of radiologist-provided ground truth scores, outperforming standalone LLMs and NER approaches. The approach also generates detailed explanations and entity visualizations to aid educational feedback, though computational efficiency remains a limitation for large-scale deployment.

## Method Summary
The Llama-EntScore method processes paired preliminary and final radiology reports through a hybrid pipeline. First, SciSpacy's large core model extracts clinical entities from both reports. Entities are then matched between reports using exact matching and cosine similarity for unmatched pairs. For shared entities, Llama-3.1-Instruct-8B classifies whether each entity is used in the same or different clinical context through a simple prompt. Based on these classifications and entity presence/absence, the Entity-Based Semantic Agreement Score (ESAS) is computed using weighted penalties: W_missing=2, W_mismatch=1.5, W_surplus=1. The formula is N_match / (N_match + Σ(W_c × N_c)). Finally, the LLM generates an explanation anchored by the numerical score, focusing on technical details to reduce hallucinations. The method also produces entity visualizations categorizing findings as matched, mismatched, missing, or surplus.

## Key Results
- Llama-EntScore achieves 67% exact-match accuracy and 93% accuracy within ±1 of radiologist-provided ground truth scores on 115 report pairs.
- The hybrid method outperforms standalone LLMs (43-57% exact-match accuracy) and word-for-word comparison approaches.
- Computational overhead is substantial at 90 seconds per report pair on RTX 2080 Ti, compared to 2-5 seconds for simpler methods.

## Why This Works (Mechanism)

### Mechanism 1: Entity-Grounded Semantic Comparison
Restricting semantic comparison to clinically relevant entities (via NER) improves alignment with expert judgment compared to free-form text analysis. NER extracts a constrained set of domain-specific terms from both reports, and the LLM evaluates contextual agreement only for these shared entities, reducing noise from stylistic variations.

### Mechanism 2: Context-Aware Discrepancy Weighting via LLMs
LLMs can successfully categorize how a shared clinical entity is used (e.g., negated, severity change), providing nuanced discrepancy types that pure NER overlap cannot detect. For entities identified in both reports, a lightweight LLM prompt classifies the nature of their agreement, which feeds into a weighted penalty scheme in the ESAS formula.

### Mechanism 3: Score-Anchored Explanation Generation
Providing the LLM with a pre-computed similarity score as part of the prompt for generating an explanation reduces hallucinations and produces more technically grounded, educational feedback. The numerical ESAS score is first computed, then injected into a second prompt asking the LLM to justify it, constraining the LLM's reasoning.

## Foundational Learning

- **Named Entity Recognition (NER) in Biomedical Domains**: Core to extracting the "atoms" of comparison (clinical entities). General-purpose NER fails on radiology jargon. The method relies on `en_core_sci_lg` from SciSpacy. Quick check: Can you list two challenges specific to biomedical NER that don't exist in general news text NER?

- **Entity-Based Semantic Agreement Score (ESAS)**: This is the novel metric proposed. Understanding its formula and tunable weights is essential for adapting the system to different training priorities or datasets. Quick check: If a preliminary report misses a critical finding entirely, while another report includes a correct but differently-worded finding, which category ("missing" vs "mismatched") should receive a higher penalty weight, and why according to the paper?

- **Hybrid Architectures (Symbolic + Neural)**: The paper's core contribution is not a better LLM or NER alone, but their combination. Understanding how to chain structured, symbolic extraction with probabilistic, neural reasoning is the key architectural insight. Quick check: What is the specific role of the NER component versus the LLM component in the Llama-EntScore architecture?

## Architecture Onboarding

- **Component map**: Input -> NER Extractor -> Entity Matcher -> Context Classifier -> ESAS Calculator -> Explanation Generator -> Visualization Module -> Output

- **Critical path**: The sequential dependency from NER Extractor -> Entity Matcher -> Context Classifier is critical. An error in NER (missed entity) propagates downstream, meaning it's never matched or classified, directly affecting the ESAS numerator and denominator.

- **Design tradeoffs**:
  - Accuracy vs. Computational Efficiency: The hybrid method is more accurate (67% vs 43-57%) but much slower (90s/pair on RTX 2080 Ti) than standalone LLM or word-for-word comparison.
  - Specificity vs. Generality: The weighting scheme allows tuning for specific training goals but requires manual calibration for new contexts.

- **Failure signatures**:
  - Consistently High Scores with Known Errors: Likely indicates NER model is missing entities, or LLM context classifier is failing to detect negations/severity changes.
  - Vague or Generic Explanations: Suggests the LLM is ignoring the score anchor or the prompt needs refinement to enforce technical focus.
  - Very Slow Processing (>90s/pair): Could indicate inefficient prompt engineering, model loading overhead, or suboptimal batching in the LLM calls.

- **First 3 experiments**:
  1. **Baseline Replication**: Run the provided code on the sample report pairs to reproduce the 67% exact-match accuracy and observe the output format (score + explanation + visualization).
  2. **Sensitivity Analysis of Weights**: Systematically vary one weight (e.g., W_missing from 1.5 to 2.5) while holding others constant to observe impact on score distribution and alignment with ground truth.
  3. **Ablation of Context Classification**: Replace the LLM context classifier with a simple "same" (assume all shared entities match context) or "different" (assume all shared entities mismatch) rule to quantify the LLM's specific contribution to accuracy over the NER baseline.

## Open Questions the Paper Calls Out

- **Fine-tuning NER on domain-specific radiology corpora**: To what extent does fine-tuning the NER component on domain-specific radiology corpora improve the Entity-Based Semantic Agreement Score (ESAS) accuracy relative to the standard SciSpacy model?

- **Reducing computational overhead**: Can the computational overhead of the Llama-EntScore method be reduced to support near real-time clinical integration without degrading performance?

- **Expanding difference classification schema**: Does expanding the difference classification schema beyond the four current categories to include attributes like severity and anatomical location improve correlation with radiologist evaluations?

- **Generalizability of penalty weights**: Are the heuristic penalty weights (W_missing=2, W_mismatch=1.5, W_surplus=1) generalizable across different imaging modalities (e.g., MRI vs. Ultrasound)?

## Limitations

- **Data and Generalizability Constraints**: The evaluation corpus consists of only 115 anonymized report pairs from two institutions, limiting confidence in external validity and raising concerns about whether the 67% exact-match performance would hold in broader deployment.

- **Model Architecture Limitations**: The hybrid approach shows substantial computational overhead (90 seconds per report pair) compared to standalone LLM methods (2-5 seconds), creating scalability barriers for clinical deployment.

- **Clinical Relevance Uncertainties**: While the weighted penalty scheme is claimed to reflect clinical significance, there is no explicit validation that these weights align with radiologist priorities for training feedback.

## Confidence

- **Hybrid NER-LLM Methodology**: Medium - The mechanism is logically coherent and the quantitative improvement over baselines is demonstrated, but the small evaluation set and lack of cross-validation reduce confidence in the generalizability of the 67% accuracy claim.

- **Clinical Interpretability of Explanations**: Low - While the paper claims explanations are more "technically grounded" due to score anchoring, there is no direct evidence that these explanations are clinically meaningful, actionable, or preferred by radiologist educators over simpler alternatives.

- **Computational Efficiency**: High - The timing measurements are clearly stated (90s vs 2-5s for baselines), and the hardware specifications are provided, making this limitation assessment highly confident.

## Next Checks

1. **Cross-Validation on Expanded Dataset**: Replicate the study on a larger, multi-institutional dataset with published inter-rater reliability metrics to establish whether the 67% exact-match accuracy holds across different reporting styles, institutions, and radiology subspecialties.

2. **Ablation Study of Entity Categories**: Systematically remove each entity category (matched, mismatched, missing, surplus) from the ESAS calculation to quantify the individual contribution of each component and determine whether the current weighting scheme is optimal for training feedback.

3. **Clinical Utility Evaluation**: Conduct a user study with radiologist educators to assess whether the generated explanations are perceived as useful for trainee feedback, comparing them directly against explanations from simpler baselines or human-generated feedback.