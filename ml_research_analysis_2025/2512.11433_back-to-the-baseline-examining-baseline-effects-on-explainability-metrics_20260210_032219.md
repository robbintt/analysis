---
ver: rpa2
title: 'Back to the Baseline: Examining Baseline Effects on Explainability Metrics'
arxiv_id: '2512.11433'
source_url: https://arxiv.org/abs/2512.11433
tags:
- baseline
- baselines
- information
- methods
- deletion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the instability of faithfulness metrics for
  attribution methods in XAI, focusing on the Insertion and Deletion metrics. The
  core problem is that the choice of baseline function, used to replace important
  pixels in the input image, significantly impacts the ranking of attribution methods.
---

# Back to the Baseline: Examining Baseline Effects on Explainability Metrics

## Quick Facts
- arXiv ID: 2512.11433
- Source URL: https://arxiv.org/abs/2512.11433
- Reference count: 40
- Primary result: Baseline choice significantly impacts faithfulness metric rankings of attribution methods

## Executive Summary
This work addresses the instability of faithfulness metrics for attribution methods in XAI, focusing on the Insertion and Deletion metrics. The core problem is that the choice of baseline function, used to replace important pixels in the input image, significantly impacts the ranking of attribution methods. This instability arises because different baselines favor different attribution methods, leading to unreliable comparisons. The authors propose two desiderata for a good baseline: efficient information removal and maintaining the data distribution (low Out-Of-Distribution score). They demonstrate that current baselines fail to satisfy both criteria, creating a trade-off between information removal and distributional shift. To overcome this limitation, they introduce a novel model-dependent baseline generated using feature visualization techniques. This baseline is optimized to produce zero activations in the penultimate layer of the model, effectively removing information while remaining within the data distribution. The proposed model-dependent baseline is shown to provide a better trade-off between information removal and OOD score compared to existing baselines, leading to more reliable and stable rankings of attribution methods and improving the evaluation of their faithfulness.

## Method Summary
The authors systematically evaluate how different baseline functions affect the stability of faithfulness metrics for attribution methods. They propose two key desiderata for baselines: efficient information removal and maintaining the data distribution. Through experiments, they demonstrate that existing baselines fail to satisfy both criteria simultaneously. To address this limitation, they introduce a model-dependent baseline generated using feature visualization techniques, specifically optimized to produce zero activations in the penultimate layer of the model. This approach aims to remove information effectively while remaining within the data distribution. The proposed baseline is evaluated against existing methods across multiple attribution techniques, showing improved trade-offs between information removal and distributional preservation.

## Key Results
- Different baseline functions cause significant rank instability in faithfulness metrics across attribution methods
- Current baselines exhibit a fundamental trade-off between information removal and distributional preservation
- The proposed model-dependent baseline achieves better balance between these two criteria
- Model-dependent baselines lead to more reliable and stable rankings of attribution methods
- Feature visualization-based baseline generation effectively removes information while maintaining data distribution

## Why This Works (Mechanism)
The model-dependent baseline works by directly targeting the model's internal representations rather than just the input space. By optimizing to produce zero activations in the penultimate layer, it removes information in a way that's specifically tailored to how the model processes inputs. This approach bypasses the trade-off faced by traditional baselines that must choose between complete information removal (like black images) and distributional similarity (like blurred images). The feature visualization technique allows the baseline to find input patterns that the model has learned to ignore, effectively neutralizing the model's response while staying within realistic image distributions.

## Foundational Learning
- Attribution methods (why needed: core subject of evaluation; quick check: can list at least 3 common methods like Grad-CAM, Integrated Gradients, LIME)
- Faithfulness metrics (why needed: evaluation framework being studied; quick check: can explain what insertion and deletion metrics measure)
- Feature visualization (why needed: technique used to generate model-dependent baselines; quick check: can describe what feature visualization aims to achieve)
- Distributional shift (why needed: key concept for evaluating baseline quality; quick check: can explain how to measure whether an image is out-of-distribution)
- Model internals and penultimate layer (why needed: target for baseline optimization; quick check: can locate and describe the penultimate layer in a typical CNN architecture)

## Architecture Onboarding
Component map: Input image -> Attribution method -> Importance map -> Baseline function -> Modified image -> Model prediction
Critical path: Baseline selection → Metric computation → Attribution ranking
Design tradeoffs: Information removal vs. distributional preservation
Failure signatures: Rank instability across baselines, poor correlation between metrics
First experiments: 1) Compare ranking stability across 3 different baselines, 2) Measure OOD scores for common baselines, 3) Evaluate feature visualization convergence for model-dependent baseline generation

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to image classification tasks, generalizability to other domains unclear
- Focus on insertion and deletion metrics excludes other evaluation approaches
- Feature visualization approach requires access to model internals, not suitable for black-box systems
- Evaluation conducted on ResNet-50 and ImageNet only, broader validation needed

## Confidence
The identification of baseline-induced instability in faithfulness metrics (High confidence): The empirical evidence across multiple attribution methods and baselines demonstrates consistent ranking shifts, providing robust support for this claim.
The proposed desiderata for baselines (Medium confidence): While the information removal and distributional preservation criteria are well-motivated theoretically, the specific quantification through OOD scores may not capture all relevant aspects of what makes a baseline "good" for different evaluation contexts.
The effectiveness of the model-dependent baseline (Medium confidence): The results show improved trade-offs compared to existing baselines, but the evaluation is limited to a specific architecture (ResNet-50) and dataset (ImageNet), warranting broader validation.

## Next Checks
1. Evaluate the model-dependent baseline across diverse model architectures (Vision Transformers, MobileNet) and datasets (CIFAR-10, medical imaging) to test generalizability.
2. Compare the proposed baseline against recently developed alternatives like semantic inpainting or GAN-based approaches to establish relative performance.
3. Conduct user studies to determine whether more stable metric rankings translate to better human understanding and trust in explanations.