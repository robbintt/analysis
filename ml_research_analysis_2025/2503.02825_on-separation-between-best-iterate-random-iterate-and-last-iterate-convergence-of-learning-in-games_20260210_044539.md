---
ver: rpa2
title: On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate Convergence
  of Learning in Games
arxiv_id: '2503.02825'
source_url: https://arxiv.org/abs/2503.02825
tags:
- convergence
- have
- omwu
- dualitygap
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes convergence properties of Optimistic Multiplicative
  Weights Update (OMWU) in two-player zero-sum games. The key problem is understanding
  whether OMWU achieves uniform random-iterate or best-iterate convergence despite
  recent results showing it lacks uniform last-iterate convergence.
---

# On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate Convergence of Learning in Games

## Quick Facts
- arXiv ID: 2503.02825
- Source URL: https://arxiv.org/abs/2503.02825
- Reference count: 40
- Primary result: OMWU achieves O(T^{-1/6}) best-iterate convergence in 2×2 games but has Ω(1/log T) random-iterate convergence

## Executive Summary
This paper analyzes convergence properties of Optimistic Multiplicative Weights Update (OMWU) in two-player zero-sum games, focusing on the distinction between best-iterate, random-iterate, and last-iterate convergence. The authors prove that OMWU lacks polynomial uniform random-iterate convergence despite achieving polynomial best-iterate convergence, demonstrating a fundamental separation between these convergence modes. Through a novel two-phase analysis connecting random-iterate convergence to dynamic regret, they establish O(T^{-1/6}) best-iterate convergence for 2×2 games while also proving Ω(1/log T) lower bounds for random-iterate convergence. This work challenges the conventional wisdom that these convergence modes are essentially equivalent.

## Method Summary
The paper employs a two-phase analysis framework to study OMWU convergence. The global phase establishes universal random-iterate convergence bounds via a connection to dynamic regret and interval regret, yielding O(T^{-1/4}δ^{-1/2}) where δ is the minimum equilibrium probability. The initial phase shows OMWU achieves fast convergence to iterates with duality gap O(δ), with all initial iterates having best-iterate convergence rate of O(log²t/t). Combining these phases through a min{δ, T^{-1/4}δ^{-1/2}} bound yields the final O(T^{-1/6}) best-iterate rate. Lower bounds are established through explicit hard instance game constructions.

## Key Results
- OMWU has Ω(1/log T) uniform random-iterate convergence even for 2×2 games, proving no polynomial rate exists
- OMWU achieves O(T^{-1/6}) uniform best-iterate convergence for 2×2 games with fully-mixed Nash equilibrium
- These results demonstrate a separation between best-iterate and random-iterate convergence that was previously unknown

## Why This Works (Mechanism)

### Mechanism 1: Two-Phase Analysis for Best-Iterate Convergence
- Claim: OMWU achieves O(T^{-1/6}) uniform best-iterate convergence in 2×2 games with fully-mixed Nash equilibrium.
- Mechanism: The analysis decomposes into (1) a global phase that bounds universal random-iterate convergence at O(T^{-1/4}δ^{-1/2}) via dynamic regret, and (2) an initial phase that shows OMWU reaches an iterate with duality gap O(δ) with fast Õ(1/t) best-iterate rates. Combining min{δ, T^{-1/4}δ^{-1/2}} yields δ-independent O(T^{-1/6}).
- Core assumption: The game has a fully-mixed Nash equilibrium with minimum probability δ > 0; step size η ≤ 1/10.
- Evidence anchors:
  - [abstract] "Our analysis uncovers a new connection to dynamic regret and presents a novel two-phase approach to best-iterate convergence"
  - [Section 4.1] "Combining the analysis in the initial phase and the global phase as follows: min{DualityGap(xT1, yT1), 1/T Σ DualityGap} ≤ min{δ, O(T^{-1/4}δ^{-1/2})} ≤ O(T^{-1/6})"
  - [corpus] Limited direct corpus support; one neighbor paper ("From Average-Iterate to Last-Iterate Convergence") studies related convergence reductions but doesn't validate this specific two-phase mechanism.
- Break condition: If δ can be arbitrarily small relative to T, the two-phase balance may not yield polynomial rates; the bound is proven only for 2×2 games.

### Mechanism 2: Dynamic Regret ↔ Random-Iterate Convergence Connection
- Claim: The sum of duality gaps equals social dynamic regret, enabling random-iterate convergence bounds via interval regret analysis.
- Mechanism: Proposition 1 shows Σ DualityGap(xt, yt) = Σ max_z ⟨F(zt), zt - z⟩ = RT_x + RT_y (social dynamic regret). OMWU's interval regret is O(1/δ) for any interval (Lemma 3), and loss variation is O(√|I| log d) (Lemma 4). Optimal partitioning yields O(T^{3/4}δ^{-1/2}) social dynamic regret, hence O(T^{-1/4}δ^{-1/2}) random-iterate convergence.
- Core assumption: Fully-mixed equilibrium exists; OMWU step size η ≤ 1/8.
- Evidence anchors:
  - [Section 4.2] "We prove a random-iterate convergence rate of O(T^{-1/4}δ^{-1/2})... To prove the result, we leverage the connection between random-iterate convergence, dynamic regret, and interval regret"
  - [Proposition 1] "PT_t=1 DualityGap(xt, yt) = RT_x({xt★}) + RT_y({yt★})"
  - [corpus] No corpus papers explicitly validate this dynamic regret connection for OMWU.
- Break condition: If interval regret scales worse than O(1/δ) or variation is super-linear, the partitioning argument fails.

### Mechanism 3: Lower Bound via Hard Instance Games Aδ
- Claim: OMWU has Ω(1/log T) uniform random-iterate convergence even for 2×2 games, proving no polynomial rate exists.
- Mechanism: For the hard game Aδ (Eq. 1), the authors show there exists T = O(f_R(δ)/δ) such that Θ(1/δ) consecutive iterations each have duality gap ≥ c₂ > 0 (Theorem 7). For entropy regularizer, f_R(δ) ≤ log(1/δ), yielding average gap Ω(1/log T). This blocks polynomial random-iterate rates.
- Core assumption: Constant step size η ≤ 1/(4L) where L is regularizer Lipschitz constant; regularizer satisfies Assumptions 2-3.
- Evidence anchors:
  - [Theorem 1] "For two-player zero-sum games with loss matrix A ∈ [0, 1]^{2×2}, the uniform random-iterate convergence rate of OMWU with any constant step size η ≤ 1/2 is Ω(1/log T)"
  - [Section 3.1] "We show that for some T = Ω(1/δ) iterations, there will be a block of Θ(1/δ) iterations each with a constant duality gap"
  - [corpus] No corpus papers address random-iterate lower bounds for OMWU specifically.
- Break condition: If adaptive step sizes or different regularizers are used, f_R(δ) may change, potentially improving rates.

## Foundational Learning

- Concept: **No-regret learning and Multiplicative Weights Update (MWU)**
  - Why needed here: OMWU (Optimistic MWU) extends MWU with a "predictable sequence" term; understanding MWU's regret guarantees is prerequisite.
  - Quick check question: Can you explain why MWU achieves O(√T) external regret and how optimism modifies the update?

- Concept: **Duality gap as equilibrium proximity measure**
  - Why needed here: All convergence results are stated in terms of duality gap; this is the paper's central metric.
  - Quick check question: For a strategy profile (x, y), what does DualityGap(x, y) = 0 imply, and why is max_y' x^TAy' - min_x' x'^TAy the right measure?

- Concept: **Three convergence modes: last-iterate vs. random-iterate vs. best-iterate**
  - Why needed here: The paper's main contribution is proving separation between these modes; understanding their hierarchy is essential.
  - Quick check question: Why does last-iterate convergence imply random-iterate convergence, but the reverse doesn't hold?

## Architecture Onboarding

- Component map: Entropy regularizer and negative loss -> OMWU update rule -> Duality gap computation -> Two-phase analysis -> Best-iterate rate
- Critical path: (1) Implement OMWU update with entropy regularizer -> (2) Track duality gap at each iteration -> (3) For analysis, partition iterates into initial phase [1, T1] and global phase [T1+1, T] -> (4) Apply min{δ, T^{-1/4}δ^{-1/2}} to get O(T^{-1/6})
- Design tradeoffs:
  - Universal vs. uniform bounds: Universal bounds allow δ-dependence (easier to prove); uniform bounds must be δ-independent (harder, may not exist)
  - 2×2 vs. general games: Best-iterate result proven only for 2×2; generalization to d1×d2 remains open
  - Constant vs. adaptive step size: All results assume constant η; adaptive schemes may change convergence behavior
- Failure signatures:
  - No polynomial random-iterate rate: If average duality gap decays slower than any polynomial (e.g., Ω(1/log T)), the algorithm lacks practical random-iterate guarantees
  - δ-dependence explosion: If δ → 0, universal bounds become vacuous; uniform bounds are needed for ill-conditioned games
  - Last-iterate divergence: Prior work (Cai et al., 2024) showed OMWU can have Ω(1) last-iterate gap; this paper confirms random-iterate also fails but best-iterate succeeds
- First 3 experiments:
  1. Validate lower bound: Run OMWU on Aδ with varying δ ∈ {10^{-2}, 10^{-3}, 10^{-4}}, plot average duality gap vs. T; confirm Ω(1/log T) scaling
  2. Verify two-phase behavior: On 2×2 games with fully-mixed equilibria, track min duality gap; observe transition from initial-phase Õ(1/t) to global-phase T^{-1/6}
  3. Compare with OGDA: Run both OMWU and OGDA on same game instances; contrast that OGDA has identical rates for all three convergence modes while OMWU shows separation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can OMWU achieve polynomial uniform best-iterate convergence for general d₁×d₂ matrix games beyond the 2×2 case?
- Basis in paper: [explicit] "Whether obtaining polynomial best-iterate convergence for OMWU in the general case is an interesting open question for future works." Also: "Extending our positive result beyond the 2-by-2 case is an interesting future direction."
- Why unresolved: The current analysis relies heavily on the structure of 2×2 games and the affine transformation properties that simplify the initial phase analysis. The two-phase approach may not directly generalize.
- What evidence would resolve it: Either a proof establishing a polynomial rate for general games, or a lower bound construction showing that polynomial best-iterate convergence is impossible beyond 2×2.

### Open Question 2
- Question: Is the O(T^{-1/6}) best-iterate convergence rate for OMWU in 2×2 games tight, or can it be improved?
- Basis in paper: [inferred] The rate arises from balancing δ and T^{-1/4}δ^{-1/2} in the two-phase analysis, yielding min{δ, T^{-1/4}δ^{-1/2}} = T^{-1/6}. No lower bound on best-iterate convergence is provided.
- Why unresolved: The paper only provides an upper bound; no matching lower bound for best-iterate convergence is established.
- What evidence would resolve it: A lower bound construction showing Ω(T^{-1/6}) is necessary, or an improved analysis yielding a faster rate.

### Open Question 3
- Question: Do there exist learning algorithms that simultaneously achieve polynomial rates for all three convergence modes (last-iterate, random-iterate, and best-iterate) while maintaining OMWU's other desirable properties?
- Basis in paper: [explicit] The paper shows OGDA has similar rates across modes but "no algorithm was known to exhibit a separation between these three convergence modes" prior to this work. The implicit question is whether OMWU's unfavorable random-iterate behavior is fundamental or algorithm-specific.
- Why unresolved: The lower bounds apply specifically to OMWU and certain OFTRL variants; the broader landscape of possible algorithms remains unexplored.
- What evidence would resolve it: Design of a new algorithm with polynomial uniform guarantees across all three modes, or a universal lower bound showing such algorithms cannot exist.

## Limitations
- The analysis is limited to two-player zero-sum games with fully-mixed Nash equilibria
- Lower bounds rely on specific game constructions that may not generalize to broader game classes
- Best-iterate result proven only for 2×2 games, leaving open whether similar rates hold for larger games

## Confidence
- High: Random-iterate lower bound (Ω(1/log T)) - explicit construction and analysis
- Medium: Best-iterate rate (O(T^{-1/6})) - two-phase analysis is sound but delicate
- Medium: Dynamic regret connection - established framework but novel application to OMWU

## Next Checks
1. Test OMWU on games with varying δ values to empirically verify the Ω(1/log T) random-iterate lower bound across different equilibrium compositions
2. Implement the two-phase analysis framework on 3×3 games to check whether the O(T^{-1/6}) best-iterate rate extends beyond 2×2 games
3. Compare the random-iterate convergence of OMWU with Optimistic Gradient Descent Ascent (OGDA) on identical game instances to confirm the separation result