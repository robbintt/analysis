---
ver: rpa2
title: 'Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects
  Multilingual Sense Disambiguation in LLMs'
arxiv_id: '2510.03762'
source_url: https://arxiv.org/abs/2510.03762
tags:
- few-shot
- language
- sense
- prompting
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how imbalanced few-shot prompting strategies\
  \ affect multilingual Word Sense Disambiguation (WSD) performance in Large Language\
  \ Models. Using the GLOSSGPT method, we evaluate the impact of different sampling\
  \ approaches\u2014highest, lowest, and average frequency sharing\u2014on WSD accuracy\
  \ across five languages (English, German, Spanish, French, Italian) using GPT-4o\
  \ and LLaMA-3.1-70B."
---

# Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs

## Quick Facts
- arXiv ID: 2510.03762
- Source URL: https://arxiv.org/abs/2510.03762
- Authors: Deshan Sumanathilaka; Nicholas Micallef; Julian Hough
- Reference count: 10
- Key outcome: This study investigates how imbalanced few-shot prompting strategies affect multilingual Word Sense Disambiguation (WSD) performance in Large Language Models. Using the GLOSSGPT method, we evaluate the impact of different sampling approaches—highest, lowest, and average frequency sharing—on WSD accuracy across five languages (English, German, Spanish, French, Italian) using GPT-4o and LLaMA-3.1-70B. Results show that English WSD remains robust against sampling imbalances, while multilingual performance is significantly affected by prompt balance. Average frequency sharing generally performs best for English, German, and French, while highest frequency sharing benefits Spanish and Italian. This highlights the importance of balanced, language-specific few-shot strategies for effective multilingual WSD, emphasizing that model performance depends heavily on sampling design rather than model size alone.

## Executive Summary
This study investigates how different few-shot prompting strategies with imbalanced training data affect multilingual Word Sense Disambiguation (WSD) performance in Large Language Models (LLMs). The researchers evaluated three sampling approaches—highest, lowest, and average frequency sharing—across five European languages (English, German, Spanish, French, Italian) using both GPT-4o and LLaMA-3.1-70B. Their findings reveal that while English WSD performance remains stable across different sampling strategies, multilingual WSD performance varies significantly depending on the balance of the few-shot examples provided. The study demonstrates that prompt balance is crucial for effective multilingual WSD, with different languages responding best to different sampling strategies—average frequency sharing generally performs best for English, German, and French, while highest frequency sharing benefits Spanish and Italian. These results highlight the importance of language-specific sampling strategies for few-shot learning in multilingual contexts.

## Method Summary
The researchers employed the GLOSSGPT method for few-shot WSD, using a multilingual dataset (MultiLexNorm) covering five languages: English, German, Spanish, French, and Italian. They tested three different sampling strategies for creating few-shot prompts: highest frequency sharing (selecting examples with the most common sense distributions), lowest frequency sharing (selecting examples with the least common sense distributions), and average frequency sharing (selecting examples with average sense distributions). The evaluation was conducted using two LLM models: GPT-4o and LLaMA-3.1-70B. Performance was measured using WSD accuracy as the primary metric, comparing how each sampling strategy affected model performance across the different languages.

## Key Results
- English WSD performance remains robust against sampling imbalances, maintaining stable accuracy across all tested conditions
- Multilingual WSD performance is significantly affected by prompt balance, with different languages responding best to different sampling strategies
- Average frequency sharing generally performs best for English, German, and French, while highest frequency sharing benefits Spanish and Italian

## Why This Works (Mechanism)
The effectiveness of different sampling strategies depends on how well the few-shot examples represent the underlying sense distribution patterns in each language. When examples are selected based on highest frequency sharing, the model is exposed to the most common sense patterns, which may be particularly useful for languages like Spanish and Italian where dominant sense patterns are more predictive. Conversely, average frequency sharing provides a balanced view of the sense distribution, which benefits languages with more complex or balanced sense distributions like English, German, and French. The robust performance of English WSD across all conditions suggests that high-resource languages have more consistent sense patterns that are easier for models to learn from imbalanced data. The language-specific variations indicate that the effectiveness of sampling strategies depends on the inherent characteristics of each language's sense distribution and the model's ability to generalize from the provided examples.

## Foundational Learning

**Word Sense Disambiguation (WSD)**: The task of determining the correct meaning of a word based on context. Why needed: Core task being evaluated in this study. Quick check: Can the model correctly identify different senses of polysemous words like "bank" (financial institution vs. river bank)?

**Few-shot Learning**: Training models using a limited number of examples. Why needed: The study specifically examines how different few-shot strategies affect performance. Quick check: Does the model maintain performance when trained with only 5-10 examples per class?

**Prompt Engineering**: The design and optimization of input prompts for LLMs. Why needed: Different sampling strategies represent different prompt engineering approaches. Quick check: How does changing the order or selection of examples affect model output?

**Multilingual NLP**: Natural language processing across multiple languages. Why needed: The study compares performance across five different languages. Quick check: Does the model maintain similar performance levels across all tested languages?

**Frequency Distribution**: The statistical distribution of word senses in language data. Why needed: Different sampling strategies target different parts of the frequency distribution. Quick check: What percentage of instances belong to the most common sense versus less common senses?

## Architecture Onboarding

**Component Map**: GLOSSGPT method -> Few-shot prompt generation -> LLM inference -> WSD accuracy evaluation

**Critical Path**: Few-shot prompt generation (sampling strategy selection) -> LLM inference (sense disambiguation) -> Accuracy evaluation (comparison with ground truth)

**Design Tradeoffs**: The study balances between using high-resource (English) and lower-resource languages, comparing a large commercial model (GPT-4o) with an open-source model (LLaMA-3.1-70B), and testing multiple sampling strategies to find optimal approaches for different languages.

**Failure Signatures**: Poor multilingual performance indicates ineffective sampling strategies for that language; consistent English performance across strategies suggests robustness to imbalance; significant drops in accuracy suggest the sampling strategy poorly represents the target sense distribution.

**3 First Experiments**:
1. Test the three sampling strategies (highest, lowest, average frequency sharing) on a single language (e.g., English) to establish baseline performance patterns
2. Compare GPT-4o and LLaMA-3.1-70B performance on the same sampling strategy to assess model-specific differences
3. Evaluate a mixed sampling strategy that combines elements of all three approaches to determine if hybrid strategies offer advantages

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses only on five European languages from the same language family, limiting generalizability to typologically diverse languages
- Evaluation relies on a single WSD dataset (MultiLexNorm), which may not capture the full complexity of multilingual sense disambiguation tasks
- Only two LLM models (GPT-4o and LLaMA-3.1-70B) are tested, which may not represent the broader landscape of available models

## Confidence
**High confidence**: The observation that English WSD performance remains robust against sampling imbalances across all tested conditions
**Medium confidence**: The finding that multilingual WSD performance is significantly affected by prompt balance, particularly for non-English languages
**Medium confidence**: The recommendation for language-specific sampling strategies, though this requires further validation across more diverse language pairs and tasks

## Next Checks
1. Test the sampling strategies across a broader range of languages, including non-European and low-resource languages, to assess cross-linguistic generalizability
2. Evaluate performance on multiple WSD datasets and other multilingual NLP tasks to determine if findings extend beyond the current experimental setup
3. Compare the proposed sampling strategies against alternative few-shot prompting approaches, such as dynamic prompt selection or curriculum learning methods, to establish relative effectiveness