---
ver: rpa2
title: Reproducing and Extending Causal Insights Into Term Frequency Computation in
  Neural Rankers
arxiv_id: '2510.06728'
source_url: https://arxiv.org/abs/2510.06728
tags:
- term
- query
- document
- neural
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study reproduces and extends causal interpretability research
  on neural ranking models, validating that TAS-B encodes term-frequency information
  consistent with IR axioms. Using activation patching on Passage-Retrieval MS-MARCO,
  the authors localize term-frequency tracking to specific attention heads (0.9, 1.6,
  2.3) rather than the four heads identified in the original study.
---

# Reproducing and Extending Causal Insights Into Term Frequency Computation in Neural Rankers

## Quick Facts
- arXiv ID: 2510.06728
- Source URL: https://arxiv.org/abs/2510.06728
- Authors: Cile van Marken; Roxana Petcu
- Reference count: 40
- Primary result: Activation patching identifies different attention heads than original study for term-frequency tracking in TAS-B neural ranker

## Executive Summary
This study reproduces and extends causal interpretability research on neural ranking models, validating that TAS-B encodes term-frequency information consistent with IR axioms. Using activation patching on Passage-Retrieval MS-MARCO, the authors localize term-frequency tracking to specific attention heads (0.9, 1.6, 2.3) rather than the four heads identified in the original study. They extend the framework to examine TFC2 axiom, which describes diminishing returns of query term frequency on ranking. Experiments reveal that while the model tracks frequency information, it doesn't consistently adhere to TFC1 axiom when terms are repeatedly appended.

## Method Summary
The study employs activation patching, a causal intervention technique, to identify which neural components cause term-frequency effects on relevance scoring. The method constructs diagnostic datasets with controlled variations: baseline documents contain a filler token, while perturbed documents have query terms injected. Three forward passes per sample (baseline, perturbed with caching, patched) enable quantifying each component's causal contribution via normalized score recovery. The approach extends the original framework to test both TFC1 (more term matches increase relevance) and TFC2 (marginal relevance gain decreases with additional matches) axioms, using logarithmic curve fitting to characterize sublinear behavior.

## Key Results
- Activation patching localizes term-frequency tracking to attention heads 0.9, 1.6, and 2.3 (not the four heads from original study)
- TFC2 experiments show sublinear behavior for K ≤ 5 with logarithmic fits (R² ≥ 0.92) for heads 1.0, 1.9, 1.6, and 0.9
- TFC1 axiom violations increase from 8% to 39% as term frequency increases beyond K > 5
- Information flows from duplicate term attention in early layers to CLS aggregation in layers 4-5

## Why This Works (Mechanism)

### Mechanism 1: Activation Patching for Causal Attribution
- Claim: Replacing activations between controlled input pairs isolates the causal contribution of specific model components to relevance scoring.
- Mechanism: Three-pass procedure—(1) baseline run with X_baseline records reference score; (2) perturbed run with X_perturbed caches activations; (3) patched run injects cached activations into baseline forward pass. The normalized score difference `(patched - baseline) / (perturbed - baseline)` quantifies how much the patched component recovers baseline performance (1 = full recovery, 0 = no effect).
- Core assumption: The clean/perturbed document pair differs only on the feature of interest (term frequency), and intervening on the responsible component will partially restore baseline ranking behavior.
- Evidence anchors:
  - [abstract] "Using activation patching on Passage-Retrieval MS-MARCO, the authors localize term-frequency tracking to specific attention heads"
  - [Section 3.1.1] Detailed procedure description; "a value of 1 indicates that the intervention increases the ranking score so that it fully recovers the performance"
  - [corpus] Related work "Interpreting Multilingual and Document-Length Sensitive Relevance Computations" confirms reproducibility of this causal intervention framework for neural retrieval
- Break condition: If baseline/perturbed documents are nearly identical (as occurred in TFC1-R where only ~10% of documents had actual replacements), the score difference denominator approaches zero, causing numerical instability and unreliable attribution.

### Mechanism 2: Residual Stream Aggregation via CLS Token
- Claim: Term-frequency signals computed by early-layer attention heads propagate through the residual stream and consolidate in the CLS token representation at layers 4-5.
- Mechanism: Heads 0.9 and 1.6 attend to duplicate query term occurrences in early layers; head 2.3 shifts attention toward CLS in later layers. This creates a path: injected token → duplicate term attention → CLS aggregation → final relevance score. The residual stream enables information composition across layers without explicit routing.
- Core assumption: The ranking score is computed from the CLS pooled representation, so information must accumulate there to affect the output.
- Evidence anchors:
  - [Section 4.1] "term-frequency information is aggregated into the CLS token in layers 4 and 5, aligning with expectations as the ranking score is computed from a pooled representation"
  - [Figure 3 description] "heads 0.9 and 1.6 primarily attend to other occurrences of the selected query term... head 2.3 shifts attention towards the CLS token"
  - [corpus] Limited direct corpus evidence for this specific aggregation pattern; related work focuses on intervention methods rather than architectural flow
- Break condition: If term injection location changes (append vs. prepend), attention patterns shift—prepended tokens receive disproportionate attention from the same heads, suggesting position-sensitivity that may not generalize to mid-document insertions.

### Mechanism 3: Sublinear Dampening via Logarithmic Head Response
- Claim: For the TFC2 axiom (diminishing returns), specific attention heads (1.0, 1.9, 1.6, 0.9) exhibit logarithmic response curves where marginal relevance gain decreases as term frequency increases.
- Mechanism: When K ≤ 5 additional query terms are appended, these heads' patching impact follows `a·log(x) + b` with R² ≥ 0.92. The logarithmic function is provably sublinear (grows asymptotically slower than linear). Beyond K > 5, the model "discards" injected token information and shifts attention to non-selected query terms (tok_qterm−), implementing a saturation/regularization effect.
- Core assumption: The TFC2 axiom (sublinear growth) is the correct normative behavior for IR systems, and neural rankers that exhibit it are performing "proper" relevance computation.
- Evidence anchors:
  - [Section 4.2] "Averaging the impact of attention heads 1.0 and 1.9 over the top ranking documents reveals that the observed trend follows a logarithmic function... with an R² value of 0.98"
  - [Section 4.2] Mathematical derivation proving logarithmic functions are sublinear via l'Hôpital's rule
  - [corpus] Related work "Pathway to Relevance: How Cross-Encoders Implement a Semantic Variant of BM25" provides corroborating context that neural rankers approximate classical IR scoring functions
- Break condition: When K > 5, ~39% of document pairs violate TFC1 entirely (perturbed score < baseline), making TFC2 analysis unreliable. The unnatural document construction (repeated term appending) may fall outside training distribution, causing out-of-distribution behavior rather than revealing true model properties.

## Foundational Learning

- Concept: Causal Mediation Analysis
  - Why needed here: Distinguishes correlation from causation in interpretability. Probing classifiers can detect that a feature is *present* in representations, but only intervention methods (activation patching) establish that the feature *causes* the model's output.
  - Quick check question: If you patch an attention head's activations and the ranking score doesn't change, what can you conclude about that head's role?

- Concept: IR Axioms (TFC1/TFC2)
  - Why needed here: These formalize expected ranking behavior. TFC1: more term matches → higher relevance. TFC2: marginal relevance gain decreases with additional matches. They serve as the ground truth for evaluating whether neural rankers compute relevance "correctly."
  - Quick check question: If a document has 5 occurrences of a query term and another has 6, TFC2 predicts which difference is larger: going from 1→2 occurrences or 5→6?

- Concept: Residual Stream in Transformers
  - Why needed here: The paper shows information flows from attention heads → residual stream → CLS token. Understanding residual connections (additive information flow) explains how early-layer computations (heads 0.9, 1.6) affect late-layer outputs without direct connections.
  - Quick check question: If you wanted to intervene on information that has already passed through multiple layers, where in the residual stream would you patch?

## Architecture Onboarding

- Component map:
  - Input: Query + Document pairs → tokenized with CLS (start) and SEP (separator) tokens
  - 6-layer transformer (TAS-B), 12 attention heads per layer
  - Key heads identified: 0.9, 1.6, 2.3 (TFC1); 1.0, 1.9, 1.6, 0.9 (TFC2)
  - Output: CLS token representation → pooled → relevance score
  - Token categories for analysis: tok_CLS, tok_inj (injected), tok_qterm+ (matching query terms), tok_qterm− (non-selected query terms), tok_other, tok_SEP

- Critical path:
  1. Construct diagnostic dataset: baseline (filler token) vs. perturbed (query term injected)
  2. Run three forward passes per sample (baseline, perturbed with caching, patched)
  3. Compute normalized score recovery per component
  4. Filter: Only include document pairs where perturbed score > baseline score (TFC1 adherence)
  5. Fit logarithmic curves to patching impact vs. K (term frequency)

- Design tradeoffs:
  - Filler token choice: 'a' is semantically neutral but may still affect document statistics; alternative would be MASK token or random tokens
  - Query selection: Using top-100 documents from highest-scoring queries biases toward clear causal signals but may not represent typical retrieval scenarios
  - K upper bound: K=10 chosen because relevance gains < 0.5% beyond this; but this truncates analysis of higher-frequency behavior

- Failure signatures:
  - Noisy/unstable patching scores → check if baseline/perturbed documents are actually different (TFC1-R had ~90% identical pairs)
  - Negative patching recovery → model may be attending to position rather than content (prepend vs. append discrepancy)
  - High TFC1 violation rate at high K → likely out-of-distribution behavior from unnatural term repetition

- First 3 experiments:
  1. **Sanity check**: Reproduce TFC1-I append experiment with the corrected baseline (filler token at same position). Verify that patching tok_inj at heads 0.9, 1.6, 2.3 recovers ≥ 0.5 of the baseline-perturbed score gap for top-10% ranked documents.
  2. **Position sensitivity test**: Compare TFC1-I append vs. prepend on the same query set. Quantify the attention pattern shift—specifically, how much does tok_qterm+ contribution decrease when injected token appears first?
  3. **TFC2 head validation**: For K=1 through K=5, plot absolute patching impact for heads 1.0, 1.9, 1.6, 0.9. Fit logarithmic curve and verify R² > 0.90. Check whether the curve flattens (violates TFC1) or continues sublinear growth (adheres to TFC2).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can diagnostic dataset creation be improved by incorporating document-specific query term selection instead of applying the same perturbation to all retrieved documents for a given query?
- Basis in paper: [explicit] "The current approach of selecting a single query term per query and applying it to the top 100 relevant documents might be oversimplified, as it fails to account for document-specific term interactions and context."
- Why unresolved: Current methodology selects one query term globally based on highest average score change, ignoring how term importance varies across different document contexts.
- What evidence would resolve it: Experiments comparing global vs. document-specific term selection showing whether localized term choices improve activation patching precision or reveal different attention head behaviors.

### Open Question 2
- Question: How does unnatural term repetition in diagnostic datasets affect neural ranker behavior, and what alternative perturbation methods would produce more ecologically valid experiments?
- Basis in paper: [explicit] "the influence of term repetition on neural ranker models could use investigation, as the current diagnostic datasets contain unnatural text" and TFC2 experiments "generate documents with unnatural term repetitions that likely fall outside the model's training distribution."
- Why unresolved: Appending query terms K times creates out-of-distribution inputs that may trigger model behaviors unrelated to actual term-frequency processing.
- What evidence would resolve it: Comparing activation patching results between current append-based perturbations and alternative methods (e.g., selecting documents with naturally varying term frequencies) to assess whether head localization differs.

### Open Question 3
- Question: Why do neural ranking models increasingly violate the TFC1 axiom (from 8% to 39%) as query term frequency increases, despite encoding term-frequency information in specific attention heads?
- Basis in paper: [inferred] from the finding that "an increasing portion of document pairs did not adhere to the TFC1 axiom... This rate grew logarithmically with K" while simultaneously identifying heads that encode term-frequency information consistent with TFC2.
- Why unresolved: The paper demonstrates both that models track frequency information causally AND that they violate axiomatic expectations at higher frequencies, but does not explain this contradiction.
- What evidence would resolve it: Analysis of whether violating document pairs share characteristics (e.g., specific term types, document lengths) or whether the identified attention heads behave differently for violating vs. adhering pairs.

### Open Question 4
- Question: To what extent do the identified attention heads (0.9, 1.6, 2.3 for TFC1; 1.0, 1.9, 1.6, 0.9 for TFC2) generalize across different neural ranking architectures beyond TAS-B?
- Basis in paper: [inferred] from the methodology being limited to "TAS-B model, which has 6 layers and 12 attention heads" and the acknowledgment that results depend on diagnostic dataset design.
- Why unresolved: All experiments use a single model architecture; whether these are TAS-B-specific mechanisms or general neural ranking phenomena remains unknown.
- What evidence would resolve it: Replicating activation patching experiments on architectures like ColBERT, SPLADE, or larger transformer-based rankers to determine if homologous heads encode similar term-frequency behaviors.

## Limitations

- Dataset quality issues: Only ~10% of document pairs in TFC1-R were actually different, causing unreliable normalization and unstable head attribution
- Out-of-distribution behavior: Unnatural term repetition likely triggers model behaviors unrelated to true term-frequency processing
- Position sensitivity: Attention patterns differ significantly between appended vs. prepended tokens, suggesting the method may capture positional encoding effects
- Single architecture limitation: All experiments use TAS-B, making generalization to other neural rankers uncertain

## Confidence

- **High Confidence**: TFC2 sublinear behavior detection (R² ≥ 0.92 for logarithmic fits) and the general finding that term-frequency information flows through specific attention heads to affect CLS representations
- **Medium Confidence**: Head identification for TFC1 (0.9, 1.6, 2.3 vs. original four heads), as this depends on unstable score normalization in the TFC1-R dataset
- **Low Confidence**: Claims about TFC1 violations at high K (>5) and whether these represent true model behavior versus OOD artifacts

## Next Checks

1. **Dataset Quality Validation**: Re-run TFC1-R experiments with stricter document-pair filtering (≥5 actual term replacements) and verify whether head attributions stabilize. Compare against random baseline to rule out statistical noise.

2. **Naturalistic Dataset Construction**: Replace term repetition with document expansion (adding relevant context containing query terms) to test whether TFC1 violations persist in more realistic scenarios. This addresses the OOD concern while maintaining controlled frequency variation.

3. **Alternative Intervention Methods**: Apply minimal-context ablation (removing surrounding context while preserving the injected token) to disentangle position vs. content effects. Compare attention patterns between prepended vs. mid-document injected tokens to quantify position sensitivity.