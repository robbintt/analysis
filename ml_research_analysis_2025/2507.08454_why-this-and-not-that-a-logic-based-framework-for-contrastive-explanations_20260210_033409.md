---
ver: rpa2
title: Why this and not that? A Logic-based Framework for Contrastive Explanations
arxiv_id: '2507.08454'
source_url: https://arxiv.org/abs/2507.08454
tags:
- problem
- size
- contrastive
- formulas
- explanation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a logic-based framework for contrastive explanations
  addressing questions of the form "Why P but not Q?". The authors formalize several
  problems including contrastive explanation, global contrastive explanation, minimal
  separator, counterfactual contrastive explanation, and counterfactual difference.
---

# Why this and not that? A Logic-based Framework for Contrastive Explanations

## Quick Facts
- arXiv ID: 2507.08454
- Source URL: https://arxiv.org/abs/2507.08454
- Authors: Tobias Geibinger; Reijo Jaakkola; Antti Kuusisto; Xinghan Liu; Miikka Vilander
- Reference count: 26
- Key outcome: Introduces a logic-based framework for contrastive explanations addressing "Why P but not Q?" questions with computational complexity analysis

## Executive Summary
This paper presents a formal logic-based framework for generating contrastive explanations that address questions of the form "Why P but not Q?". The authors formalize several key problems including contrastive explanation, global contrastive explanation, minimal separator, counterfactual contrastive explanation, and counterfactual difference. The framework computes causes for both the target outcome P and the alternative outcome Q, explicitly comparing their differences to generate meaningful explanations. By bridging logic-based explainable AI with existing notions of contrastive explanations, the work provides both theoretical foundations and practical implementations for generating meaningful explanations comparing why certain outcomes occur while others do not.

## Method Summary
The framework formalizes contrastive explanation problems using propositional logic, computing causes for both P and Q to explicitly compare their differences. The authors implement their problems using Answer Set Programming (ASP) and demonstrate practical applications on real-world datasets including Iris, Wine, and Glass classification problems. The approach captures cardinality-minimal versions of existing contrastive explanations in propositional logic and provides extensive computational complexity analysis, proving most problems are Σ₂^P-complete. The implementation leverages ASP solvers to find minimal causes and separators, enabling practical generation of contrastive explanations for classification tasks.

## Key Results
- Framework captures cardinality-minimal versions of existing contrastive explanations in propositional logic
- Most problems are proven to be Σ₂^P-complete through rigorous complexity analysis
- Practical implementation demonstrated on Iris, Wine, and Glass classification datasets
- Successfully bridges logic-based explainable AI with established contrastive explanation notions

## Why This Works (Mechanism)
The framework works by formalizing contrastive explanation as a logical problem where causes for both the actual outcome P and the alternative outcome Q are computed and compared. By explicitly representing both outcomes and finding minimal causes (separators) between them, the framework can generate explanations that highlight the specific differences leading to P rather than Q. The use of Answer Set Programming enables efficient computation of minimal solutions, while the logical formalization ensures rigorous guarantees about the explanations generated.

## Foundational Learning
1. **Propositional Logic Formulas** - Why needed: Foundation for representing outcomes P and Q; Quick check: Can express simple logical relationships between variables
2. **Answer Set Programming (ASP)** - Why needed: Enables efficient computation of minimal causes and separators; Quick check: Can find minimal models satisfying logical constraints
3. **Complexity Classes (Σ₂^P)** - Why needed: Characterizes computational difficulty of finding contrastive explanations; Quick check: Understands relationship between NP and higher complexity classes
4. **Minimal Separators** - Why needed: Identifies critical differences between P and Q; Quick check: Can find smallest set of literals distinguishing two logical formulas
5. **Counterfactual Reasoning** - Why needed: Enables generation of "what-if" explanations; Quick check: Can compute minimal changes needed to achieve alternative outcome
6. **Cardinality Minimization** - Why needed: Ensures explanations are concise and interpretable; Quick check: Can find minimal cardinality solutions to logical problems

## Architecture Onboarding

Component Map:
User Query -> Logical Formalization -> ASP Solver -> Minimal Causes -> Explanation Generation

Critical Path:
1. Parse user's contrastive question "Why P but not Q?"
2. Formalize P and Q as propositional logic formulas
3. Compute minimal causes for both P and Q using ASP
4. Identify minimal separator between P and Q
5. Generate human-readable explanation highlighting differences

Design Tradeoffs:
- ASP-based implementation enables precise minimal solutions but may limit scalability
- Propositional logic provides computational guarantees but lacks expressiveness of first-order logic
- Cardinality minimization ensures concise explanations but may miss important contextual information
- Theoretical rigor provides formal guarantees but may sacrifice some practical usability

Failure Signatures:
- No solution found when P and Q are logically equivalent
- Exponentially large separators when P and Q differ on many variables
- ASP solver timeouts on complex formulas with many variables
- Explanations that are technically correct but difficult for humans to interpret

First Experiments:
1. Test on simple logical formulas where manual verification is possible
2. Compare explanations generated for Iris dataset against known feature importance
3. Evaluate scalability by testing on progressively larger propositional formulas

## Open Questions the Paper Calls Out
None

## Limitations
- ASP-based implementation may not scale well to large datasets or complex formulas
- Complexity results limited to propositional logic; extension to more expressive logics remains open
- Limited empirical validation beyond three benchmark datasets
- No comparisons with alternative explanation methods in terms of human interpretability

## Confidence

High:
- Complexity analysis is rigorous and well-established
- Framework builds on established formalisms in logic and explainable AI
- Theoretical guarantees about minimal solutions are formally proven

Medium:
- Practical applicability given limited empirical validation
- Explanation quality and human interpretability not formally evaluated
- Scalability of ASP implementation to real-world applications

## Next Checks
1. Benchmark the framework against alternative contrastive explanation methods using human evaluation studies to assess explanation quality and interpretability.
2. Test scalability on larger datasets with more complex formulas to determine practical limits of the Answer Set Programming implementation.
3. Extend the framework to handle more expressive logics (e.g., first-order logic) and evaluate whether the complexity results still hold or require adjustment.