---
ver: rpa2
title: 'SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and
  Memory-Guided Writing'
arxiv_id: '2508.14317'
source_url: https://arxiv.org/abs/2508.14317
tags:
- subsection
- writing
- generation
- survey
- section
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SurveyGen-I is an end-to-end framework for automatic academic survey
  generation that addresses the challenges of maintaining coherence across long multi-section
  surveys and providing comprehensive citation coverage. The system combines coarse-to-fine
  retrieval, adaptive planning, and memory-guided generation to produce high-quality
  surveys.
---

# SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing

## Quick Facts
- arXiv ID: 2508.14317
- Source URL: https://arxiv.org/abs/2508.14317
- Reference count: 40
- Key outcome: SurveyGen-I achieves 8.5% improvement in content quality and 27% increase in citation density compared to previous works

## Executive Summary
SurveyGen-I is an end-to-end framework for automatic academic survey generation that addresses the challenges of maintaining coherence across long multi-section surveys and providing comprehensive citation coverage. The system combines coarse-to-fine retrieval, adaptive planning, and memory-guided generation to produce high-quality surveys. It uses multi-stage literature retrieval at both survey and subsection levels, PlanEvo for dynamic planning and outline evolution, and CaM-Writing for citation-aware subsection generation with memory guidance. Experimental results across four scientific domains demonstrate significant improvements over existing methods.

## Method Summary
SurveyGen-I addresses the challenges of automatic survey generation through a three-stage approach: multi-stage literature retrieval, dynamic planning with PlanEvo, and memory-guided generation with CaM-Writing. The retrieval stage employs both coarse-to-fine literature search and multi-hop retrieval to gather comprehensive academic papers. PlanEvo generates and evolves survey outlines by integrating both retrieved and non-retrieved knowledge. CaM-Writing produces citation-aware subsections while maintaining consistency through memory-guided generation. The framework is designed to handle the unique challenges of survey writing, including maintaining coherence across sections and ensuring comprehensive citation coverage.

## Key Results
- Achieves 8.5% improvement in content quality over previous methods
- Increases citation density by 27% compared to baselines
- Generates surveys with more than twice as many distinct references

## Why This Works (Mechanism)
SurveyGen-I addresses the inherent challenges of survey generation by combining three key mechanisms: comprehensive literature retrieval, dynamic planning, and memory-guided writing. The multi-stage retrieval ensures both breadth and depth of literature coverage, while PlanEvo's evolving plans allow the system to adapt its structure based on retrieved knowledge. The CaM-Writing module integrates citations naturally while maintaining coherence through memory guidance. This approach tackles the coherence challenge by allowing plans to evolve and the citation challenge by incorporating retrieval-aware generation.

## Foundational Learning
**Multi-hop retrieval** - why needed: To capture comprehensive literature coverage beyond immediate citations; quick check: Verify that retrieved papers form logical citation chains
**Dynamic planning** - why needed: To adapt survey structure based on evolving understanding of the literature; quick check: Ensure plan evolution maintains logical flow
**Memory-guided generation** - why needed: To maintain consistency across long-form survey sections; quick check: Verify cross-section coherence and citation consistency

## Architecture Onboarding

**Component Map:**
Seed papers -> Coarse-to-fine retrieval -> Multi-hop retrieval -> PlanEvo -> CaM-Writing -> Generated survey

**Critical Path:**
Seed papers → Coarse-to-fine retrieval → PlanEvo → CaM-Writing → Final survey generation

**Design Tradeoffs:**
The framework trades computational efficiency for comprehensiveness, using multiple retrieval stages and memory-guided generation. This approach prioritizes quality and coherence over speed, making it suitable for research contexts where accuracy is paramount.

**Failure Signatures:**
- Insufficient literature coverage due to poor seed papers
- Inconsistent survey structure from inadequate plan evolution
- Missing citations from incomplete retrieval or generation errors

**First 3 Experiments to Run:**
1. Test retrieval coverage with varying numbers of seed papers
2. Evaluate plan evolution effectiveness with different update frequencies
3. Assess citation integration quality across different scientific domains

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies primarily on automated metrics without extensive human evaluation
- Performance may be limited in rapidly evolving or highly interdisciplinary research areas
- System effectiveness depends heavily on quality of initial seed papers

## Confidence
- High Confidence: The retrieval framework's multi-stage approach and CaM-Writing module's citation integration
- Medium Confidence: The claimed improvements in content quality (8.5%) and citation coverage (27% increase)
- Low Confidence: The assertion that SurveyGen-I produces "high-quality" surveys without comprehensive human evaluation

## Next Checks
1. Conduct comprehensive human evaluation studies with domain experts to assess the coherence, accuracy, and usefulness of generated surveys
2. Test the system's performance on interdisciplinary research topics and rapidly evolving fields
3. Compare the PlanEvo-generated outlines with those created by human experts to validate conceptual relationship capture