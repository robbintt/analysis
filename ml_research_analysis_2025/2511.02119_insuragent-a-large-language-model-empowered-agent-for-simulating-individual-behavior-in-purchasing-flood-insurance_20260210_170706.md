---
ver: rpa2
title: 'InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual
  Behavior in Purchasing Flood Insurance'
arxiv_id: '2511.02119'
source_url: https://arxiv.org/abs/2511.02119
tags:
- flood
- insurance
- probability
- purchase
- insuragent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "InsurAgent is an LLM-empowered agent that simulates individual\
  \ flood insurance purchase decisions by integrating empirical survey data and contextual\
  \ information. It comprises five modules\u2014perception, retrieval, reasoning,\
  \ action, and memory\u2014and uses retrieval-augmented generation to align with\
  \ population-level purchase probabilities."
---

# InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance

## Quick Facts
- **arXiv ID:** 2511.02119
- **Source URL:** https://arxiv.org/abs/2511.02119
- **Reference count:** 5
- **Primary result:** LLM agent accurately estimates flood insurance purchase probabilities with R² = 0.778 and MAE = 0.0240, outperforming state-of-the-art LLMs

## Executive Summary
InsurAgent is a five-module LLM agent that simulates individual flood insurance purchase decisions by integrating empirical survey data with contextual information. The agent uses retrieval-augmented generation to ground LLM outputs in observed population statistics, achieving superior accuracy compared to vanilla LLMs while maintaining interpretability. By incorporating both structured survey variables and unstructured contextual factors through chain-of-thought reasoning, InsurAgent can model individual decisions and track behavioral trajectories over time.

## Method Summary
The approach employs a five-module architecture: Perception extracts structured and unstructured profile information; Retrieval queries a vector database of empirical survey statistics for baseline probabilities; Reasoning uses chain-of-thought to adjust these baselines based on contextual factors; Action outputs final probability with rationale; Memory tracks temporal decision evolution. The system is built on Llama-3.3 70B and calibrated using Monte Carlo simulation of 10 million synthetic individuals derived from a 2017 U.S. Gulf Coast survey. Performance is evaluated against benchmark marginal and bivariate probabilities with R² = 0.778 and MAE = 0.0240.

## Key Results
- Achieves R² = 0.778 and MAE = 0.0240 for probability estimation, outperforming vanilla LLMs (negative R²)
- Accurately predicts both marginal and bivariate probabilities across 10 demographic and risk perception factors
- Successfully extrapolates beyond survey data to incorporate contextual factors like occupation and flood experience
- Models dynamic behavioral trajectories over time with memory module tracking attitude changes

## Why This Works (Mechanism)

### Mechanism 1: RAG for Quantitative Grounding
Standard LLMs exhibit a "knowledge-to-action gap"—they possess qualitative logic but fail at quantitative precision. The Retrieval Module injects empirical survey statistics into prompt context, forcing the LLM to anchor outputs to observed data rather than internal priors. This works when user profiles contain factors within the database schema.

### Mechanism 2: Heuristic Extrapolation via Chain-of-Thought (CoT)
The Reasoning Module uses structured CoT to process contextual signals intractable for regression models. A 4-step synthesis guides the LLM: identify factors, estimate statistical baseline, adjust using common sense, finalize probability. This depends on LLM's internal logic aligning with human behavioral reality.

### Mechanism 3: Episodic Memory for Dynamic Consistency
The Memory Module maintains history of life events that influence current risk perception. Reasoning traces and outcomes are archived with timestamps and fed back into subsequent turns, enabling path-dependent decision simulation. This assumes cumulative life events can be effectively synthesized in a single context window.

## Foundational Learning

- **Concept: Monte Carlo Synthesis**
  - Why needed here: Shao et al. provided regression coefficients, not raw probabilities. Authors simulated 10 million agents to reverse-engineer marginal/bivariate probabilities for RAG database.
  - Quick check question: Why could authors not simply plug regression coefficients directly into LLM prompt?

- **Concept: Prompt Engineering (Role-Playing)**
  - Why needed here: Agent relies on "first-person role-playing" to elicit subjective decisions rather than encyclopedic answers.
  - Quick check question: How does prompt structure prevent LLM from outputting "It depends" or generic safety warning?

- **Concept: Behavioral Calibration**
  - Why needed here: Raw LLMs are risk-averse (~80% purchase rates). Calibration forces alignment with low real-world uptake (~25%).
  - Quick check question: If RAG database showed 90% purchase rate, would LLM still output ~25%? (No, should align with data)

## Architecture Onboarding

- **Component map:** Perception -> Retrieval -> Reasoning -> Action -> Memory
- **Critical path:** User Profile Input → Perception extracts variables → Retrieval searches DB for baseline stats → Reasoning adjusts baseline using context → Action outputs probability
- **Design tradeoffs:**
  - RAG vs. Fine-tuning: Authors chose RAG for interpretability and ease of updating data
  - Marginal vs. Joint Probabilities: DB stores mostly marginal probabilities; LLM must "guess" interaction effects, introducing error but allowing flexibility
- **Failure signatures:**
  - Anchoring Failure: LLM ignores retrieved 20% probability and outputs 80%
  - Statistical Hallucination: LLM invents statistic when DB returns null
  - Memory Drift: Agent forgets initial profile in long trajectories
- **First 3 experiments:**
  1. Ablation Test: Remove RAG module and verify performance drops from R²=0.778 to negative R²
  2. Boundary Testing: Input "statistically impossible" profile and check graceful handling
  3. Temporal Loop: Run "Roller Coaster" scenario and plot curve, verifying event responses

## Open Questions the Paper Calls Out
None

## Limitations
- Results may not generalize beyond 2017 U.S. Gulf Coast survey data to other regions or flood risk contexts
- Extrapolation capability depends entirely on LLM's "common sense" without empirical validation for most contextual adjustments
- Five-module architecture may produce inconsistent behavior when edge cases arise at module boundaries

## Confidence
- **High confidence:** InsurAgent's RAG grounding successfully aligns LLM outputs with survey-derived marginal probabilities (R² = 0.778, MAE = 0.0240)
- **Medium confidence:** Agent's CoT reasoning produces qualitatively reasonable extrapolations for contextual factors not in survey
- **Low confidence:** Episodic memory module produces reliable long-term behavioral trajectories across multiple temporal events

## Next Checks
1. Cross-regional validation: Test InsurAgent on flood insurance survey data from different geographic region to assess generalizability
2. Individual-level accuracy assessment: Compare predictions against actual individual purchase decisions from original survey rather than aggregated probabilities
3. Extrapolation error bounds: Systematically vary contextual factors beyond survey scope and measure prediction deviation from human expert judgments