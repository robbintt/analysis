---
ver: rpa2
title: LUT-Compiled Kolmogorov-Arnold Networks for Lightweight DoS Detection on IoT
  Edge Devices
arxiv_id: '2601.08044'
source_url: https://arxiv.org/abs/2601.08044
tags:
- detection
- inference
- accuracy
- batch
- int8
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying effective Denial-of-Service
  (DoS) intrusion detection on resource-constrained IoT edge devices. The core method
  involves compiling Kolmogorov-Arnold Networks (KANs) by replacing runtime B-spline
  evaluation with precomputed lookup tables (LUTs) and linear interpolation, achieving
  deterministic and fast inference.
---

# LUT-Compiled Kolmogorov-Arnold Networks for Lightweight DoS Detection on IoT Edge Devices

## Quick Facts
- arXiv ID: 2601.08044
- Source URL: https://arxiv.org/abs/2601.08044
- Reference count: 21
- Achieves 99.0% accuracy on CICIDS2017 DoS with 68× speedup via LUT-compiled KANs

## Executive Summary
This paper presents a method to enable real-time Denial-of-Service (DoS) intrusion detection on resource-constrained IoT edge devices by compiling Kolmogorov-Arnold Networks (KANs) into lookup tables (LUTs). The approach replaces expensive runtime B-spline evaluations with precomputed quantized tables and linear interpolation, achieving dramatic inference speedup while maintaining high detection accuracy. A lightweight KAN model with 50K parameters achieves 99.0% accuracy on the CICIDS2017 DoS dataset, and after LUT compilation with resolution L=8, maintains 98.96% accuracy with 68× speedup at batch size 256 and over 5000× speedup at batch size 1, with only 2× memory overhead.

## Method Summary
The method trains a KAN model on the CICIDS2017 DoS dataset with 78 flow-level features, then compiles the learned B-spline functions into LUTs with configurable resolution L. During compilation, each spline function is sampled at L discrete points per segment, quantized to int8 values, and stored with segment boundaries. At inference, spline evaluation becomes a simple table lookup plus linear interpolation, eliminating the need for recursive basis function computation. The paper evaluates multiple LUT resolutions, quantization schemes, and out-of-bounds policies to establish accuracy-latency-memory Pareto frontiers, identifying L=8 as optimal for balancing performance and resource usage.

## Key Results
- 99.0% accuracy baseline on CICIDS2017 DoS with 50K parameter KAN
- 68× speedup at batch size 256 and over 5000× speedup at batch size 1 with L=8 LUT compilation
- Maintains 98.96% accuracy (F1 degradation <0.0004) with only 2× memory overhead
- L=8 identified as sweet spot where accuracy plateaus while memory overhead remains minimal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing runtime B-spline evaluation with precomputed lookup tables dramatically reduces inference latency while preserving accuracy.
- Mechanism: B-spline evaluation at runtime requires knot interval search, recursive basis function computation across k+1 levels, and coefficient aggregation. LUT compilation precomputes spline values at L discrete points per segment, reducing inference to table indexing plus one linear interpolation operation.
- Core assumption: The learned spline functions are fixed at deployment time and their shape does not need to adapt online.
- Evidence anchors: Abstract states LUT compilation "dramatically reduces inference latency while preserving detection quality"; Section III.C details runtime B-spline evaluation costs.
- Break condition: If the application requires online spline adaptation, LUT compilation would require frequent recompilation, negating latency benefits.

### Mechanism 2
- Claim: KANs achieve competitive accuracy with significantly fewer parameters than MLPs by placing learnable univariate functions on edges rather than fixed activations on nodes.
- Mechanism: The Kolmogorov-Arnold representation theorem guarantees multivariate continuous functions can be decomposed into superpositions of univariate functions. KANs implement this by learning ϕ_ij(x) = α_ij·b(x) + β_ij·s_j(x) per edge, where the spline branch captures task-specific nonlinearities that would otherwise require wider/deeper MLP architectures.
- Core assumption: The target function is well-approximated by compositions of univariate functions per the Kolmogorov-Arnold theorem.
- Evidence anchors: Abstract states KANs "achieve competitive accuracy with significantly fewer parameters"; Section I explains the architectural difference enabling parameter efficiency.
- Break condition: If the underlying function has strong multivariate interactions that cannot decompose into univariate components, KAN expressivity advantages diminish.

### Mechanism 3
- Claim: LUT resolution (L) provides a controllable knob for trading accuracy against memory and latency.
- Mechanism: Higher L values sample the spline more densely, reducing interpolation error at linear memory cost. The paper shows accuracy plateaus near L=8 for CICIDS2017, with diminishing returns beyond L=16. At L=8, F1 degradation is <0.0004 from float baseline with 2× memory overhead.
- Core assumption: The input distribution at deployment falls within the trained spline domain; out-of-bounds samples are rare or handled gracefully.
- Evidence anchors: Abstract states "model maintains 98.96% accuracy (F1 degradation <0.0004) after LUT compilation with resolution L=8"; Section V.C shows F1 degradation decreasing with increasing L.
- Break condition: For datasets with different spline complexity or input distributions, the optimal L value may shift. The paper notes 2.3% OOB rate in CICIDS2017; higher OOB rates may require more robust boundary handling.

## Foundational Learning

- Concept: **B-spline basis functions and recursive evaluation**
  - Why needed here: Understanding why native B-spline evaluation is slow (recursive Cox-de Boor algorithm) motivates the LUT compilation approach.
  - Quick check question: Given a cubic B-spline (k=3) with 8 control points, how many recursive levels and basis function evaluations are required per input?

- Concept: **Linear interpolation as function approximation**
  - Why needed here: The LUT approach approximates continuous spline values via piecewise linear interpolation; understanding error bounds helps predict accuracy loss.
  - Quick check question: For a function with maximum second derivative f'' in interval [a,b] with L sample points, what is the maximum linear interpolation error?

- Concept: **Quantization schemes (symmetric int8 vs asymmetric uint8)**
  - Why needed here: The paper compares two quantization approaches for storing LUT values; selection affects both memory and numerical stability.
  - Quick check question: For a spline segment with values ranging from -2.5 to 3.5, which quantization scheme provides better dynamic range utilization?

## Architecture Onboarding

- Component map:
  Input (78 features) → KAN Layer 1 (32 neurons, 78×32=2496 edge functions) → KAN Layer 2 (16 neurons, 32×16=512 edge functions) → Output (1 neuron, 16 edge functions)

- Critical path:
  1. Train KAN model using PyKAN with B-spline evaluation
  2. Compile: For each edge, sample spline at L points per segment, quantize to int8/uint8
  3. Export: Store LUT arrays + segment boundaries + scale factors
  4. Infer: Index → interpolate → aggregate → sigmoid → threshold

- Design tradeoffs:
  | Resolution L | Accuracy | Memory | Speedup (bs=256) |
  |--------------|----------|--------|------------------|
  | 2            | 98.74%   | 1.0×   | 61-68×           |
  | 8 (recommended) | 98.96% | 2.0× | 63×              |
  | 64           | 98.98%   | 11.3×  | 58×              |

- Failure signatures:
  - Accuracy drops below 98.5%: L likely too low (<4) or OOB handling mismatched to data
  - Latency higher than expected: Check that Numba JIT compilation completed; verify single-threaded execution
  - Recall shifts after compilation: Threshold sensitivity from spline approximation perturbation; re-evaluate threshold on validation data

- First 3 experiments:
  1. Reproduce baseline: Train KAN on CICIDS2017 DoS subset, verify 99.0% accuracy, measure native B-spline latency at batch=1 and batch=256
  2. LUT sweep: Compile with L∈{2,4,8,16}, measure accuracy/latency/memory, identify Pareto-optimal point for your hardware
  3. OOB robustness test: Apply distribution shift (e.g., scale features by 1.5×), compare zero_spline vs clip_x policies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LUT-compiled KAN inference efficiency and energy consumption translate to actual ARM-based IoT hardware compared to the x86 workstation results?
- Basis in paper: [explicit] The authors state that "Rigorous energy profiling with hardware power meters on target ARM platforms remains important future work" and note their evaluation relies on x86 hardware.
- Why unresolved: The study simulates IoT constraints on a high-performance AMD Ryzen CPU; actual edge devices have different cache hierarchies and SIMD capabilities that may affect the 68× speedup claims.
- What evidence would resolve it: Latency benchmarks and direct power measurements (joules per inference) performed on common ARM-based IoT gateways or microcontrollers.

### Open Question 2
- Question: Can quantization-aware training (QAT) mitigate the accuracy degradation observed at very low LUT resolutions (e.g., L < 4)?
- Basis in paper: [explicit] The authors explicitly list a plan to "explore quantization-aware training for improved low-resolution performance" in the future work section.
- Why unresolved: The current pipeline applies LUT compilation post-training, which results in F1 degradation (e.g., -0.0026 at L=2).
- What evidence would resolve it: A comparison of accuracy-latency curves for models trained with LUT-aware loss functions versus the standard post-training compilation method.

### Open Question 3
- Question: Does the LUT-KAN efficiency generalize to more modern or diverse intrusion detection datasets beyond CICIDS2017?
- Basis in paper: [explicit] The authors acknowledge that "Validation on NSL-KDD, UNSW-NB15, CICDDoS2019 would strengthen generalizability claims."
- Why unresolved: The study relies exclusively on the CICIDS2017 DoS subset; it is unknown if the 50K parameter model capacity and LUT approximation hold up against newer attack vectors found in CICDDoS2019.
- What evidence would resolve it: Reproducing the experimental Pareto frontier analysis on the specified alternative datasets to verify if accuracy and speedup remain consistent.

## Limitations
- Dataset generalizability remains untested beyond CICIDS2017 DoS subset; performance on other DoS datasets or non-DoS attack types is unknown
- The L=8 optimal resolution is dataset-specific and may not transfer to datasets with different spline complexity or input distributions
- Hardware dependency: While results are CPU-only, performance scaling across different CPU architectures and instruction sets is not characterized

## Confidence
- **High Confidence**: Speedup claims (68× at bs=256, 5000× at bs=1) and memory overhead (2× at L=8) are well-supported by systematic evaluation across resolutions
- **Medium Confidence**: Accuracy retention claims (99.0% baseline, 98.96% with LUT) are robust for CICIDS2017 DoS but may not generalize
- **Low Confidence**: Claims about deployment on arbitrary IoT edge devices without further characterization of computational constraints and real-world latency under varying load conditions

## Next Checks
1. **Cross-dataset validation**: Evaluate LUT-compiled KAN on alternative DoS datasets (e.g., BoT-IoT, TON_IoT) to assess generalizability
2. **End-to-end latency measurement**: Profile complete packet-to-detection pipeline including feature extraction on target IoT hardware to validate real-world timing
3. **Stress testing under distribution shift**: Apply controlled feature distribution perturbations (scaling, rotation) to quantify OOB handling robustness beyond the reported 2.3% baseline rate