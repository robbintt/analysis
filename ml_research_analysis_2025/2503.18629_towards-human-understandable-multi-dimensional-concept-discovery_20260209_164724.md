---
ver: rpa2
title: Towards Human-Understandable Multi-Dimensional Concept Discovery
arxiv_id: '2503.18629'
source_url: https://arxiv.org/abs/2503.18629
tags:
- concept
- concepts
- hu-mcd
- image
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces HU-MCD, a framework for discovering human-understandable
  concepts in CNNs that addresses two key challenges: concept understandability and
  explanation faithfulness. HU-MCD uses the Segment Anything Model for interpretable
  segmentation, employs CNN-specific input masking to avoid noise from rescaling/inpainting,
  and extends the Multi-Dimensional Concept Discovery framework with completeness
  guarantees.'
---

# Towards Human-Understandable Multi-Dimensional Concept Discovery

## Quick Facts
- arXiv ID: 2503.18629
- Source URL: https://arxiv.org/abs/2503.18629
- Reference count: 40
- Outperforms state-of-the-art methods in human understandability (70.24% vs 42.93% ACE vs 31.22% MCD prediction accuracy)

## Executive Summary
This paper introduces HU-MCD, a framework for discovering human-understandable concepts in CNNs that addresses two key challenges: concept understandability and explanation faithfulness. HU-MCD uses the Segment Anything Model for interpretable segmentation, employs CNN-specific input masking to avoid noise from rescaling/inpainting, and extends the Multi-Dimensional Concept Discovery framework with completeness guarantees. Experiments on ImageNet1k show HU-MCD outperforms state-of-the-art methods in human understandability and explanation faithfulness in both Concept Deletion and Concept Insertion benchmarks. Human subject studies confirm that HU-MCD concepts are more recognizable and consistently described than alternatives, while C-Deletion/C-Insertion experiments validate that concept importance scores faithfully represent model reasoning.

## Method Summary
HU-MCD discovers concepts through a pipeline that begins with SAM-based segmentation to generate interpretable masks, followed by CNN-specific input masking where both image and mask propagate through convolutional layers. Sparse Subspace Clustering groups segment embeddings into clusters, which are then decomposed via PCA into concept subspaces with an orthogonal complement for residuals. Concept relevance is computed by projecting classification weights onto these subspaces, ensuring completeness. The method uses ResNet50 on ImageNet1k, with 400 training images per class for concept discovery and 10 CIFAR-10-like classes for evaluation.

## Key Results
- Human prediction accuracy: 70.24% for HU-MCD vs 42.93% ACE vs 31.22% MCD
- C-Deletion benchmark: Maintains 0.8 accuracy with 80% pixels masked
- Completeness scores range 0.65–0.79 across classes

## Why This Works (Mechanism)

### Mechanism 1: SAM-based Human-Interpretable Segmentation
- Claim: Using SAM for concept identification produces segments that humans can consistently recognize and describe.
- Mechanism: SAM, being trained on human-annotated segmentation data, produces masks that align with human perceptual boundaries rather than arbitrary superpixels or grid patches. These semantically meaningful segments are then clustered using SSC based on their feature representations.
- Core assumption: Segments that humans perceive as coherent objects/parts correspond to concepts the model internally encodes.
- Evidence anchors:
  - [abstract] "HU-MCD uses the Segment Anything Model for interpretable segmentation"
  - [section 4.1] "The reason for the improved distinguishability of concepts can be attributed to the usage of SAM, which is trained on human-annotated segmentation masks and thus produces interpretable segments"
  - [section 4.1] Human study shows 70.24% prediction accuracy for HU-MCD vs 42.93% ACE vs 31.22% MCD
  - [corpus] FACE paper (arXiv 2510.11675) similarly addresses alignment between extracted concepts and model decision-making

### Mechanism 2: CNN-Specific Input Masking
- Claim: Propagating masks alongside inputs through CNN layers preserves prediction fidelity while avoiding artifacts from inpainting and rescaling.
- Mechanism: Instead of filling masked regions with baseline colors (which the paper notes "are not truly neutral"), both the input image and mask propagate through each convolutional layer. Neighborhood padding at mask boundaries prevents over-aggressive removal while discarding activations that depend solely on masked regions.
- Core assumption: The hierarchical receptive field expansion in CNNs allows distinguishing mask-dependent from input-dependent activations.
- Evidence anchors:
  - [abstract] "employs CNN-specific input masking to avoid noise from rescaling/inpainting"
  - [section 3.1] "rather than inserting a baseline color, both the input image and an accompanying mask are propagated through each layer"
  - [supplementary Figure 7] C-Deletion/Insertion benchmarks show input masking outperforms both inpainting strategies
  - [corpus] Background Bias paper (arXiv 2504.08602) discusses how baseline regions can bias post-hoc concept embeddings

### Mechanism 3: Completeness Relation via Subspace Decomposition
- Claim: Decomposing the feature space into multi-dimensional concept subspaces ensures concept importance scores sum exactly to model outputs.
- Mechanism: SSC clusters segment embeddings; PCA derives cluster bases; an orthogonal complement captures residuals. Concept relevance is computed by projecting classification weights/activations onto these subspaces, with summation guaranteeing reconstruction of original logits.
- Core assumption: Concepts occupy low-dimensional linear subspaces discoverable through clustering.
- Evidence anchors:
  - [abstract] "extends the Multi-Dimensional Concept Discovery framework with completeness guarantees"
  - [section 3.2] "summing these relevance contributions precisely reconstructs the full logit value, satisfying a completeness criterion"
  - [Table 2] Completeness scores range 0.65–0.79 across classes
  - [corpus] V-CEM paper (arXiv 2504.03978) addresses performance-intervenability trade-offs in concept-based models

## Foundational Learning

- Concept: **Sparse Subspace Clustering (SSC)**
  - Why needed here: Groups segment embeddings by assuming data lies on a union of low-dimensional subspaces, enabling concept discovery without arbitrary cluster counts.
  - Quick check question: Why would SSC outperform K-means when concept representations are linear rather than spherical clusters?

- Concept: **Completeness in C-XAI**
  - Why needed here: The paper's theoretical differentiator; ensures concept importance scores are sufficient statistics for recovering model predictions.
  - Quick check question: Does "completeness" mean all concepts are semantically correct, or that they jointly reconstruct the prediction?

- Concept: **Input Masking in CNNs**
  - Why needed here: Core technical innovation; requires understanding how convolution receptive fields expand and how to track mask dependencies through layers.
  - Quick check question: Why does neighborhood padding (averaging unmasked boundary pixels) preserve more shape information than zero-padding?

## Architecture Onboarding

- Component map:
  SAM masks → CNN forward with masking → SSC clustering → PCA → relevance scoring
  - Mask quality directly drives interpretability (70% vs 31% human accuracy over MCD)
  - Input masking determines faithfulness (maintains 0.8 accuracy with 80% pixels masked in C-Deletion)

- Critical path:
  SAM masks → CNN forward with masking → SSC clustering → PCA → relevance scoring
  - Mask quality directly drives interpretability (70% vs 31% human accuracy over MCD)
  - Input masking determines faithfulness (maintains 0.8 accuracy with 80% pixels masked in C-Deletion)

- Design tradeoffs:
  - **Padding extent**: More padding preserves context but removes shape; paper applies masking only after first conv layer (7×7 kernel) to balance
  - **Cluster count**: Uses average SAM segments per image vs fixed counts (10–25 in prior work); adapts to class-specific structure
  - **Segment size threshold**: 1% minimum coverage filters noise but may exclude small informative features

- Failure signatures:
  - Non-coherent concepts: segments clustered together without visual similarity (see Limitations)
  - High intra-concept description similarity with low inter-concept distinction (MCD showed 0.41 vs 0.38)
  - Completeness scores below 0.65 indicate important features trapped in orthogonal complement

- First 3 experiments:
  1. Visualize SAM masks vs ACE superpixels on held-out ImageNet classes to verify segment quality improvement
  2. Run C-Deletion comparison (inpainting vs input masking) to quantify faithfulness gains on a new class
  3. Compute completeness scores; if below 0.6, inspect orthogonal complement features to identify missed concepts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can concept relevance scores be accurately quantified at intermediate layers followed by non-linear operations?
- Basis in paper: [explicit] The authors note a technical limitation where experiments are restricted to layers followed solely by linear operations. They suggest future research could "approximate the remainder of the model with a linear model."
- Why unresolved: The current decomposition framework relies on linear mappings to compute local relevance scores, making it incompatible with the non-linear activations (e.g., ReLU) present in deeper intermediate layers.
- What evidence would resolve it: A successful implementation of a linear approximation technique for non-linear layers that maintains the completeness relation and passes C-Deletion/Insertion benchmarks.

### Open Question 2
- Question: Can HU-MCD be effectively adapted to non-visual data modalities, such as text?
- Basis in paper: [explicit] In the Limitations section, the authors state that the general idea applies to other data types and that "future research [could] adapt HU-MCD to other modalities."
- Why unresolved: The framework currently relies heavily on the Segment Anything Model (SAM) for visual segmentation and a specific masking scheme for CNNs, neither of which directly translates to sequential or textual data structures.
- What evidence would resolve it: A modified version of the framework that identifies human-understandable concepts in text classifiers (e.g., identifying phrases or syntactic structures) while maintaining faithfulness metrics comparable to the visual results.

### Open Question 3
- Question: Does HU-MCD maintain its superior human understandability when applied to fine-grained classification tasks?
- Basis in paper: [explicit] The authors acknowledge their user study included only ten classes and suggest that "future research can extend the evaluation of HU-MCD to... more fine-grained classes."
- Why unresolved: It is unclear if the high prediction accuracy (70.24%) in the user study holds when visual distinctions between classes are subtle, potentially leading to less distinguishable concept clusters.
- What evidence would resolve it: Human subject study results on fine-grained datasets (e.g., bird species classification) showing that participants can still distinguish concepts with statistically significant accuracy over baselines.

## Limitations
- SSC clustering can group semantically dissimilar segments, particularly for abstract concepts like "container ship" where texture-based clusters may not align with human understanding
- Human study sample size and demographic diversity are not specified, raising questions about generalizability of the 70.24% accuracy claim
- The input masking technique's effectiveness depends on careful padding implementation details that are only partially specified

## Confidence
- **High Confidence**: CNN-specific input masking mechanism and its superiority over inpainting methods (supported by C-Deletion/Insertion benchmarks)
- **Medium Confidence**: SAM-based segmentation improvements (human study shows clear advantage but lacks demographic details)
- **Medium Confidence**: Completeness relation implementation (mathematical soundness demonstrated but semantic validity uncertain)
- **Low Confidence**: SSC clustering's ability to discover truly semantically coherent concepts across all classes

## Next Checks
1. Reconstruct SSC clustering behavior: Vary cluster count k across fixed values (10, 15, 20, 25) on the same class and visualize resulting concept prototypes to quantify coherence degradation when departing from the paper's adaptive approach.

2. Test completeness sensitivity: Systematically reduce the number of PCA components retained per cluster and measure how completeness scores and human prediction accuracy trade off, identifying the minimum dimensionality where concepts remain interpretable.

3. Validate input masking implementation: Implement zero-padding and mean-padding baselines alongside the CNN-specific masking, then compare C-Deletion curves across all 10 classes to verify the 80% pixel masking threshold consistently maintains 0.8 accuracy.