---
ver: rpa2
title: 'Social media polarization during conflict: Insights from an ideological stance
  dataset on Israel-Palestine Reddit comments'
arxiv_id: '2502.00414'
source_url: https://arxiv.org/abs/2502.00414
tags:
- language
- performance
- ideological
- stance
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses ideological stance detection in highly polarized
  social media contexts, specifically analyzing 9,969 Reddit comments related to the
  Israel-Palestine conflict. The research employs a comprehensive comparative analysis
  of machine learning, pre-trained language models, neural networks, and large language
  models (LLMs) with various prompt engineering strategies.
---

# Social media polarization during conflict: Insights from an ideological stance dataset on Israel-Palestine Reddit comments

## Quick Facts
- arXiv ID: 2502.00414
- Source URL: https://arxiv.org/abs/2502.00414
- Reference count: 40
- This study achieves 74.08% accuracy on three-class ideological stance detection using Mixtral 8x7B with two-stage prompting

## Executive Summary
This paper addresses ideological stance detection in highly polarized social media contexts, specifically analyzing 9,969 Reddit comments related to the Israel-Palestine conflict. The research employs a comprehensive comparative analysis of machine learning, pre-trained language models, neural networks, and large language models (LLMs) with various prompt engineering strategies. The proposed method using Mixtral 8x7B with Scoring and Reflective Re-read prompting achieved the highest performance, with an accuracy of 74.08%, macro precision of 73.25%, macro recall of 73.09%, and macro F1-score of 72.93%. The dataset and methodology are publicly available for further exploration and validation.

## Method Summary
The study uses Mixtral 8x7B via Huggingface with a two-stage "Scoring and Reflective Re-read" prompting approach. First, the model assigns numerical scores (1-5) to each stance category, creating explicit uncertainty calibration. The second stage re-evaluates the text with these scores as context, allowing the model to reconsider edge cases before committing to a final classification. The dataset consists of 9,969 manually annotated Reddit comments from Oct 2023–Aug 2024, with 70/15/15 train/val/test split (6,978/1,495/1,496). Text is truncated to 700 characters, and evaluation uses macro-averaged precision, recall, F1-score, and accuracy.

## Key Results
- Mixtral 8x7B with Scoring + Reflective Re-read achieved 74.08% accuracy and 72.93% macro F1
- Two-stage prompting improved Neutral class F1 from 0.50 to 0.61 (23% relative gain)
- Mixtral 8x7B zero-shot outperformed all other models: 68.30% vs. Mistral 7B's 52.07% and DistilBERT's 56.95%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage scoring with reflective re-reading improves ideological stance detection over single-pass classification
- Mechanism: The model first assigns numerical scores (1-5) to each stance category, creating explicit uncertainty calibration. The second stage re-evaluates the text with these scores as context, allowing the model to reconsider edge cases before committing to a final classification.
- Core assumption: Explicit numerical confidence articulation forces more deliberate reasoning than direct classification.
- Evidence anchors:
  - [abstract]: "Scoring and Reflective Re-read prompting achieved the highest performance, with an accuracy of 74.08%"
  - [section]: Table 5 shows Neutral class F1 improved from 0.5000 to 0.6151—a 23% relative gain—suggesting the mechanism specifically helps with ambiguous cases
  - [corpus]: Related work on conversational stance detection (arXiv:2403.11145) identifies multi-party discussion contexts as challenging, but does not test scoring-based approaches
- Break condition: If computational cost of two-stage prompting exceeds latency budgets, or if single-stage classification already achieves >85% accuracy on similar tasks

### Mechanism 2
- Claim: Mixture-of-Experts architecture captures nuanced political language better than dense models of comparable active parameters
- Mechanism: Mixtral 8x7B activates only 13B parameters per forward pass while having access to 8 specialized expert networks. This may allow different experts to specialize in different rhetorical patterns (e.g., one expert for explicit stance markers, another for implicit framing).
- Core assumption: Political stance detection benefits from parameter specialization rather than dense computation.
- Evidence anchors:
  - [abstract]: Mixtral 8x7B achieved 68.30% zero-shot accuracy vs. Mistral 7B's 52.07%
  - [section]: Table 2 shows Mixtral outperformed all neural networks (best BiLSTM: 54.14%) and pre-trained models (best DistilBERT: 56.95%)
  - [corpus]: Corpus evidence on MoE for stance detection is absent; related papers focus on fine-tuning dense models
- Break condition: If inference cost per token makes deployment infeasible, or if task-specific fine-tuning of smaller dense models matches performance

### Mechanism 3
- Claim: In-context examples provide diminishing returns for highly polarized, context-specific stance detection
- Mechanism: One-shot prompting helped some models (Gemma 7B: 47.39% → 61.61%) but additional examples did not consistently improve performance. The task may require domain-specific reasoning that generic examples cannot convey within context windows.
- Core assumption: Political stance in conflict contexts depends on implicit knowledge not easily communicated through few-shot examples.
- Evidence anchors:
  - [section]: Table 2 shows Mistral 7B three-shot (55.60%) barely improved over zero-shot (52.07%); Gemma 7B five-shot (62.19%) was similar to one-shot (61.61%)
  - [section]: "API limit on the Huggingface Hub restricted its use" for Mixtral few-shot experiments
  - [corpus]: arXiv:2506.14645 fine-tunes LLMs for polarized discourse, suggesting fine-tuning may be preferred over prompting for this domain
- Break condition: If task-specific instruction tuning or retrieval-augmented examples change this pattern

## Foundational Learning

- Concept: **Stance Detection vs. Sentiment Analysis**
  - Why needed here: Stance detection identifies position toward a specific target (Israel/Palestine), not just positive/negative sentiment. A comment can be negative toward both sides or neutral in sentiment but still position-taking.
  - Quick check question: Would a comment expressing anger at both Israel and Hamas be classified as negative sentiment, neutral stance, or something else?

- Concept: **Sparse Mixture of Experts (SMoE)**
  - Why needed here: Mixtral's architecture routes tokens to different expert sub-networks, enabling larger effective capacity without proportional compute increase.
  - Quick check question: If 8 experts exist but only 2 are activated per token, what is the relationship between total parameters and active parameters?

- Concept: **Macro-averaged Metrics for Multi-class Imbalance**
  - Why needed here: Dataset has 4,947 Pro-Israel, 2,591 Pro-Palestine, 2,431 Neutral samples. Macro averaging ensures the smaller Neutral class receives equal weight in evaluation.
  - Quick check question: Why would accuracy alone be misleading if the model simply predicted "Pro-Israel" for all inputs?

## Architecture Onboarding

- Component map:
```
Input Text → Truncation (700 chars) → LLM (Mixtral 8x7B) → Two-Stage Prompting
                                                          ├─ Stage 1: Score each stance 1-5
                                                          └─ Stage 2: Re-read + classify
                                                                 ↓
                                                         Output: {Pro-Israel, Pro-Palestine, Neutral}
```

- Critical path:
  1. Text preprocessing and truncation must preserve stance signals (keywords like "StandWithIsrael" or "FreePalestine")
  2. Scoring prompt must elicit calibrated numerical responses
  3. Re-read stage must receive both original text and scores as context

- Design tradeoffs:
  - Two-stage prompting doubles API calls and latency vs. single-pass
  - Mixtral 8x7B requires more GPU memory than Mistral 7B or Gemma 7B
  - Zero-shot avoids example selection bias but provides no task calibration

- Failure signatures:
  - Neutral class systematically misclassified (baseline Mixtral: 0.50 F1) → indicates model defaults to polarized categories
  - Scores clustering around middle values (e.g., all 3s) → prompt not eliciting discriminating judgments
  - Performance gap between zero-shot and one-shot >15% → task definition ambiguous to model

- First 3 experiments:
  1. Replicate Scoring + Reflective Re-read on a held-out subset to validate 74% accuracy claim; measure per-class precision/recall
  2. Ablate each stage: test scoring-only (take highest score as prediction) vs. re-read-only vs. combined
  3. Test whether the scoring mechanism transfers to other polarized topics (e.g., corpus neighbor on Iran-Israel YouTube comments, arXiv:2510.00021) using same prompt template

## Open Questions the Paper Calls Out

- How does the performance of the proposed Mixtral 8x7B model with Scoring and Reflective Re-read prompting change when applied to multilingual social media datasets?
- To what extent do cross-cultural differences influence the detection of ideological stance, particularly regarding the "Neutral" class?
- What are the potential ethical risks and biases introduced by deploying these high-performance stance detection models in active conflict zones?

## Limitations
- Performance claims based on single conflict domain (Israel-Palestine) may not generalize to other polarized domains
- Class imbalance (4,947 Pro-Israel vs 2,431 Neutral) may affect practical deployment performance
- Two-stage prompting doubles computational cost and latency compared to single-pass classification

## Confidence

**High Confidence**
- Mixtral 8x7B outperforms other tested models on this specific dataset
- Two-stage prompting with scoring improves performance over single-pass classification for this task
- Macro-averaged metrics are appropriate for this imbalanced dataset

**Medium Confidence**
- The scoring mechanism's improvement (74.08% vs 68.30% zero-shot) generalizes to other ideological stance detection tasks
- Mixtral's MoE architecture specifically benefits stance detection more than dense models of similar active parameter count
- In-context examples provide diminishing returns for highly polarized stance detection

**Low Confidence**
- The exact prompt templates produce consistent results across different LLM implementations
- Performance gains would be maintained with different random seeds or dataset splits
- The two-stage mechanism's computational overhead is justified by performance gains in practical applications

## Next Checks

1. **Cross-Domain Validation**: Test the Scoring + Reflective Re-read mechanism on the DIVERSE dataset of YouTube video comment stances (arXiv:2510.00021) to validate generalization beyond the Israel-Palestine context.

2. **Ablation Study on Prompt Components**: Conduct controlled experiments ablating each component (scoring-only vs re-read-only vs combined, different scoring scales, scoring order) to isolate contribution of each mechanism.

3. **Real-World Deployment Simulation**: Evaluate model performance on temporally separated data (2024 Q3 comments) and shorter text segments (300 characters) to assess robustness to input variations and adversarial examples.