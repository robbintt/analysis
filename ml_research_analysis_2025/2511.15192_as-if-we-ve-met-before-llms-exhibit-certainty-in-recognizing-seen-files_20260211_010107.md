---
ver: rpa2
title: 'As If We''ve Met Before: LLMs Exhibit Certainty in Recognizing Seen Files'
arxiv_id: '2511.15192'
source_url: https://arxiv.org/abs/2511.15192
tags:
- uncertainty
- seen
- unseen
- files
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COPYCHECK, the first framework leveraging
  uncertainty estimation to detect whether copyrighted content was used in LLM training
  sets. The method transforms LLM overconfidence from a limitation into an asset by
  capturing uncertainty patterns that distinguish between "seen" (training data) and
  "unseen" (non-training data) content.
---

# As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files

## Quick Facts
- arXiv ID: 2511.15192
- Source URL: https://arxiv.org/abs/2511.15192
- Reference count: 40
- Introduces COPYCHECK, achieving 90.1% balanced accuracy on LLaMA 7B for detecting copyrighted content in training data

## Executive Summary
This paper presents COPYCHECK, a novel framework that leverages uncertainty estimation to detect copyrighted content in LLM training sets. By exploiting the differential uncertainty patterns between seen and unseen data, the method transforms LLM overconfidence from a limitation into an asset. The framework demonstrates over 90% relative improvement compared to state-of-the-art baselines, achieving 90.1% balanced accuracy on LLaMA 7B and 91.6% on LLaMA2 7B, with strong generalizability across different model architectures.

## Method Summary
COPYCHECK uses a two-fold strategy: strategic segmentation of files into smaller snippets to amplify uncertainty signals, and uncertainty-guided unsupervised clustering to eliminate threshold tuning. The method fine-tunes target LLMs using Bayesian uncertainty estimation techniques (BLoB, MCD, or Ensemble) for one epoch, generates multiple prediction samples per snippet, computes 13 uncertainty metrics across three methods, reduces dimensionality via PCA, and applies unsupervised clustering to separate seen from unseen files based on their uncertainty representations.

## Key Results
- Achieves 90.1% balanced accuracy on LLaMA 7B and 91.6% on LLaMA2 7B
- Outperforms state-of-the-art baselines by over 90% relative improvement
- Maintains high performance (85%+) on GPT-J 6B, demonstrating strong architectural generalizability
- Black-box API-only performance drops to ~68%, highlighting white-box advantage

## Why This Works (Mechanism)

### Mechanism 1: Differential Uncertainty as Membership Signal
LLMs exhibit systematically lower uncertainty when processing training data versus non-training data, creating a detectable signal for membership inference. This occurs because training data receives dual exposure (pre-training + fine-tuning) versus single exposure for unseen data, creating measurable divergence in prediction consistency across sampled outputs.

### Mechanism 2: Snippet Segmentation for Sample Augmentation
Dividing files into smaller snippets reduces dependence on large-scale ground truth data while amplifying detectable uncertainty signals. Long files produce aggregated predictions that smooth over local variations, while segmentation creates more samples per file, enabling max-pooling to capture the most informative uncertainty spikes.

### Mechanism 3: Threshold-Free Clustering Eliminates Distribution Assumptions
Unsupervised clustering adapts to data distributions without requiring empirically tuned thresholds that assume identical train/test distributions. Traditional MIAs use fixed thresholds calibrated on one dataset, failing when applied to different distributions, while GMM/K-Means/Hierarchical clustering adaptively separate files into two groups based on the actual uncertainty distribution.

## Foundational Learning

- **Aleatoric vs. Epistemic Uncertainty**: Needed to understand why COPYCHECK computes both types—aleatoric captures data complexity (seen data = lower complexity to model), epistemic captures model knowledge gaps. Quick check: Would a model show higher aleatoric or epistemic uncertainty for a text in a language it was never trained on?

- **Membership Inference Attacks (MIAs)**: Needed to understand COPYCHECK as a file-level MIA approach and why uncertainty offers an alternative path. Quick check: Why are shadow-model-based MIAs impractical for LLMs with 7B+ parameters?

- **Bayesian Deep Learning Approximations**: Needed to understand the three uncertainty estimation methods (BLoB, MCD, Ensemble) that all approximate Bayesian inference. Quick check: How does keeping dropout active during inference enable uncertainty estimation?

## Architecture Onboarding

- **Component map**: Input Files → Snippet Segmentation (512 words) → Fine-tune Target LLM with Uncertainty Method → Generate N=10 predictions per snippet → Compute 13 uncertainty metrics × 3 methods = 39 features → PCA → 10 dimensions → Max-pool across snippets → File-level vector → Unsupervised Clustering → Seen/Unseen labels

- **Critical path**: The uncertainty estimation fine-tuning phase is most sensitive—incorrect setup (e.g., too many epochs) collapses the seen/unseen distinction. After 1 epoch, check violin plots of aleatoric uncertainty—seen snippets should cluster near 0, unseen near 0.1-0.3.

- **Design tradeoffs**:
  | Choice | Benefit | Cost |
  |--------|---------|------|
  | BLoB | Best distinction (lowest overlap) | Requires custom LoRA implementation |
  | MCD | Simplest to implement | Slightly worse than BLoB |
  | Ensemble | Strong on small N_unseen | 10× compute (150 min vs 15 min) |
  | GMM clustering | Probabilistic assignments | Assumes Gaussian-ish distributions |
  | K-Means | Fast, simple | Hard assignments, sensitive to initialization |

- **Failure signatures**:
  - High false positives: Clustering assigns unseen to "seen" cluster—check for class imbalance (N_unseen > 30)
  - Near-chance accuracy (50%): Uncertainty signal collapsed—verify fine-tuning didn't run >2 epochs
  - Black-box performance drop: API-only mode achieves only ~68%—this is expected, not a bug

- **First 3 experiments**:
  1. Reproduce the empirical analysis (Figure 1): Fine-tune LLaMA-7B on BookMIA with N_unseen=10, 1 epoch, using MCD. Generate violin plots of aleatoric uncertainty for seen vs. unseen snippets.
  2. Ablate uncertainty vs. probability features: Run COPYCHECK (GMM) on BookMIA with N_unseen=20. Compare against Min-K% Prob baseline. Verify >30 point gap in balanced accuracy.
  3. Test generalization to new architecture: Apply the full pipeline to GPT-J 6B on the same BookMIA split. Target: >85% balanced accuracy.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the framework be adapted to detect partial copyright infringement, such as short quoted passages within larger, unseen files? The current method uses max pooling to aggregate snippet signals into a single file-level label, which likely washes out the uncertainty signal from small, partially exposed sections.

- **Open Question 2**: Can black-box prompt-based uncertainty estimation techniques achieve performance parity with white-box access for copyright detection? Black-box settings rely on noisy semantic prompt variations rather than direct internal logit variance, limiting the signal-to-noise ratio required for reliable clustering.

- **Open Question 3**: How robust is the uncertainty separation signal against training-time defenses such as differential privacy or deduplication? Defensive techniques like differential privacy are designed to flatten the distribution of model outputs, which may eliminate the distinct uncertainty gap between seen and unseen data clusters.

## Limitations
- The uncertainty distinction between seen and unseen data diminishes with increased fine-tuning epochs, requiring precise control of the fine-tuning phase
- The framework shows degraded performance when the suspected set contains high proportions of unseen files (>30 unseen out of 50)
- The clustering-based approach assumes separability of uncertainty distributions, which may not hold for highly overlapping distributions

## Confidence
- **High confidence**: The differential uncertainty signal exists and is measurable, supported by empirical plots and consistent performance across datasets (90%+ balanced accuracy in most configurations)
- **Medium confidence**: The transferability to API-only settings and black-box LLMs, as reported ~68% accuracy represents a significant drop from white-box performance
- **Low confidence**: The long-term stability of uncertainty signals across model versions and training paradigms remains unclear

## Next Checks
1. **Epoch sensitivity test**: Reproduce the empirical analysis (Figure 1) with fine-tuning for 1, 2, and 3 epochs on BookMIA with N_unseen=10. Verify that aleatoric uncertainty separation diminishes significantly after 2+ epochs.
2. **API-only validation**: Apply the clustering pipeline to an API-only setting using OpenAI GPT-4 or Claude API. Target: confirm ~68% balanced accuracy for suspected sets with N_unseen=20.
3. **Adversarial robustness test**: Introduce adversarial examples designed to minimize uncertainty signal. Test whether COPYCHECK's balanced accuracy drops below 70% on BookMIA with N_unseen=10.