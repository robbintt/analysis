---
ver: rpa2
title: Incorporating Expert Knowledge into Bayesian Causal Discovery of Mixtures of
  Directed Acyclic Graphs
arxiv_id: '2510.06735'
source_url: https://arxiv.org/abs/2510.06735
tags:
- expert
- causal
- graph
- prior
- bayesian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of incorporating expert knowledge
  into Bayesian causal discovery of mixtures of directed acyclic graphs (DAGs), particularly
  in heterogeneous settings. It proposes a novel method, VaMSL, which extends the
  differentiable Bayesian structure learning (DiBS) method to infer mixtures of causal
  Bayesian networks (CBNs) while incorporating expert feedback.
---

# Incorporating Expert Knowledge into Bayesian Causal Discovery of Mixtures of Directed Acyclic Graphs

## Quick Facts
- arXiv ID: 2510.06735
- Source URL: https://arxiv.org/abs/2510.06735
- Authors: Zachris Björkman; Jorge Loría; Sophie Wharrie; Samuel Kaski
- Reference count: 37
- One-line primary result: VaMSL achieves improved structure learning performance compared to competing methods like GMMs and causal k-means when incorporating expert knowledge.

## Executive Summary
This paper addresses the challenge of incorporating expert knowledge into Bayesian causal discovery of mixtures of directed acyclic graphs (DAGs) in heterogeneous settings. The authors propose VaMSL, which extends the differentiable Bayesian structure learning (DiBS) method to infer mixtures of causal Bayesian networks while incorporating expert feedback. The key innovation is constructing an informative graph prior that incorporates elicited expert feedback using Bayesian experimental design principles to optimally select queries. Experiments on synthetic data and a breast cancer dataset demonstrate that VaMSL, when informed by expert knowledge, achieves improved structure learning performance compared to competing methods.

## Method Summary
The method extends DiBS to handle mixtures of causal Bayesian networks through a variational approach using Coordinate Ascent Variational Inference (CAVI). It maintains K sets of graph particles representing different components and alternates between updating assignment probabilities based on how well each component explains observations, and updating component graph particles via Stein Variational Gradient Descent (SVGD). Expert knowledge is incorporated through an informative graph prior constructed by mapping expert probabilities to pseudo-counts using a Beta-Binomial conjugate model, with Bayesian Experimental Design (BED) used to optimally select queries that maximize Expected Information Gain.

## Key Results
- VaMSL achieves higher classification accuracy and lower Structural Hamming Distance (SHD) than single-graph DiBS in two-component synthetic settings
- Expert-informed VaMSL outperforms both the blind version and competing methods like GMMs and causal k-means
- BED-based query selection strategy demonstrates superior performance compared to random querying in reducing SHD

## Why This Works (Mechanism)

### Mechanism 1: Expert Prior Injection via Imaginary Observations
If expert feedback is modeled as the outcome of hypothetical "idealized experiments" (imaginary observations), soft constraints can be translated into informative latent graph priors that bias the search space without ruling out solutions. The method maps an expert's probabilistic belief $\psi_{ij}^*$ to pseudo-counts $(n_{ij}, k_{ij})$ using a Beta-Binomial conjugate model. These pseudo-counts define an "elicitation likelihood" $p(K_{ij}|G(Z)_{ij})$ which is multiplied with the base DiBS prior, effectively shifting the latent embedding $Z$ such that the resulting "soft graph" aligns with expert probabilities.

### Mechanism 2: Optimal Query Selection via Expected Information Gain (EIG)
If queries are selected to maximize the Expected Information Gain (EIG) between the current latent graph posterior and potential expert responses, the system converges to the true structure with fewer queries compared to random selection. The system treats the expert query as an experiment $\xi_{ij}$, simulates responses using a Beta distribution centered on the current edge probability $G(Z)_{ij}$, and calculates the EIG for all possible edges to select the one where the expert's answer is expected to reduce posterior uncertainty the most.

### Mechanism 3: Heterogeneity Resolution via Variational Mixtures
If data is generated by a mixture of distinct CBNs (heterogeneous subpopulations), extending differentiable structure learning (DiBS) to a mixture model (VaMSL) via Coordinate Ascent Variational Inference (CAVI) allows simultaneous clustering and structure learning. The method maintains $K$ sets of graph particles (components) and in the CAVI loop: (1) assignment probabilities $q(c_n)$ are updated based on how well each component explains observation $x_n$; (2) component graph particles $Z_k$ are updated via SVGD to better fit their assigned sub-populations.

## Foundational Learning

- **Concept: Variational Inference (VI) & ELBO** - Why needed here: VaMSL is fundamentally a variational method. To understand how the model learns, one must grasp that it maximizes the Evidence Lower Bound (ELBO) rather than sampling directly from the posterior. Quick check question: Can you explain why maximizing the ELBO is equivalent to minimizing the KL-divergence between the approximate posterior $q$ and the true posterior?

- **Concept: Stein Variational Gradient Descent (SVGD)** - Why needed here: The "differentiable" part of DiBS/VaMSL relies on SVGD to move a set of particles (representing graph distributions) using gradients. This bridges discrete graph space and continuous optimization. Quick check question: How does SVGD differ from standard Stochastic Gradient Descent in terms of maintaining a distribution over solutions rather than a single point estimate?

- **Concept: Bayesian Experimental Design (BED)** - Why needed here: This explains the "active" part of the expert loop. BED provides the theoretical justification for why EIG is the correct utility function to minimize uncertainty. Quick check question: In the context of this paper, what specific "experiment" does the design strategy optimize?

## Architecture Onboarding

- **Component map:** VaMSL Inference Core (CAVI) -> Expert Interface (BED logic + Prior Constructor) -> Generative Model (mixture likelihood)
- **Critical path:** Init: Initialize $K$ sets of particles $Z^{(p)}_k$ → CAVI Loop: Update responsibilities (Eq. 7) → Update mixing weights (Eq. 8) → Update particles (Eq. 9-12) → Expert Loop: Interrupt optimization → Compute EIG for all edges → Query expert → Update Prior (Eq. 4) → Resume CAVI
- **Design tradeoffs:** Linear vs. Non-linear (Neural Network) parameters vastly increase search space complexity and computational load; Hard vs. Soft Constraints (hard constraints reduce search space size immediately while soft constraints allow for uncertain knowledge but require more optimization steps); Particle Count (higher $P$ improves posterior approximation but scales complexity $O(KP^2dl)$)
- **Failure signatures:** Label Switching (components swapping identities between CAVI iterations); Component Collapse (one component receives zero responsibility); High ESHD (if annealing is too fast, the model may converge to cyclic or suboptimal graphs)
- **First 3 experiments:** 1) Sanity Check: Run VaMSL on synthetic single component data to verify expert-informed version converges to lower ESHD than blind version; 2) Mixture Stress Test: Generate data from 2 distinct linear Gaussian BNs and check if VaMSL with $K=2$ matches paper's improvement over GMM; 3) Ablation on Prior Strength: Vary prior hyperparameters $\alpha_0, \beta_0$ and observe if highly informative prior hurts performance when simulated expert is unreliable

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the VaMSL framework be extended to model assignment probabilities that depend on covariates rather than assuming exchangeable observations? The current generative model assumes fixed mixing weights $\pi$ independent of observation features, which limits applicability in settings where subpopulations vary systematically with observed covariates.

- **Open Question 2:** Can the Bayesian Experimental Design (BED) querying strategy retain its efficacy when substituting a human expert with a Large Language Model (LLM)? The current simulator assumes a Beta-distributed response based on ground truth, whereas LLMs may exhibit hallucinations or systematic biases that violate these assumed response distributions.

- **Open Question 3:** How can the model robustly identify mixture components without relying on the expert to visually resolve label switching? Relying on an expert to distinguish components by visual inspection limits the method's scalability and its validity as a fully unsupervised causal discovery technique.

## Limitations

- The method assumes expert feedback can be modeled as probabilistic beliefs from hypothetical experiments, which may not capture all forms of domain expertise
- Computational complexity scales quadratically with particle count (O(KP²dl)), potentially limiting applicability to very large networks
- Performance heavily depends on accurate simulation of expert responses during BED query selection, which could be problematic with real human experts who may provide inconsistent or context-dependent feedback

## Confidence

- High confidence: The mechanism for incorporating soft constraints via imaginary observations (Mechanism 1) is well-grounded theoretically with clear mathematical formulation
- Medium confidence: The EIG-based query selection (Mechanism 2) shows strong results in simulations but may not generalize to real expert interactions where response distributions are unknown
- Medium confidence: The VaMSL mixture model (Mechanism 3) effectively handles heterogeneity in synthetic data, though performance on real-world datasets with unknown ground truth remains to be fully validated

## Next Checks

1. Test the method's robustness when the expert simulator is deliberately misspecified (e.g., using r=0.6 instead of r=0.9) to evaluate real-world applicability
2. Evaluate component collapse prevention by deliberately setting very aggressive annealing schedules and observing whether random restarts successfully recover distinct components
3. Compare EIG-based query selection against domain-expert-driven query selection on the breast cancer dataset to validate the theoretical query strategy in practice