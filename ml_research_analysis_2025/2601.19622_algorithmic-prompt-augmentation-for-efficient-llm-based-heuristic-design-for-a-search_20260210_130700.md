---
ver: rpa2
title: Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for
  A* Search
arxiv_id: '2601.19622'
source_url: https://arxiv.org/abs/2601.19622
tags:
- heuristic
- heuristics
- problem
- search
- algorithmic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that large language models (LLMs) can autonomously
  design effective A guiding heuristics for complex combinatorial optimization problems.
  Building on the Evolution of Heuristics (EoH) framework, we introduce Algorithmic-Contextual
  EoH (A-CEoH), a novel prompt augmentation strategy that embeds the A code structure
  directly into LLM prompts.
---

# Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search

## Quick Facts
- **arXiv ID:** 2601.19622
- **Source URL:** https://arxiv.org/abs/2601.19622
- **Reference count:** 40
- **One-line primary result:** Embedding A* algorithm code into LLM prompts (A-CEoH) improves heuristic quality, and combining algorithmic and problem-specific context (PA-CEoH) further enhances performance, with smaller coding models outperforming larger general models when prompts are well-structured.

## Executive Summary
This study demonstrates that large language models can autonomously design effective A* guiding heuristics for complex combinatorial optimization problems. Building on the Evolution of Heuristics (EoH) framework, the authors introduce Algorithmic-Contextual EoH (A-CEoH), a novel prompt augmentation strategy that embeds the A* code structure directly into LLM prompts. Experiments on the Unit-Load Pre-Marshalling Problem and the Sliding Puzzle Problem show that incorporating algorithmic context leads to strong improvements in heuristic quality compared to the original EoH baseline. When both algorithmic and problem-specific augmentations were combined in PA-CEoH, results improved further for the UPMP, demonstrating that these contexts provide complementary benefits.

## Method Summary
The paper introduces a novel prompt augmentation strategy for LLM-based heuristic design in A* search. The approach extends the Evolution of Heuristics framework by embedding algorithmic context (the A* driver code) into prompts, allowing the LLM to leverage in-context learning about the execution environment. Three strategies are tested: A-CEoH (algorithmic context only), P-CEoH (problem description only), and PA-CEoH (both combined). The method uses an evolutionary loop where the LLM generates heuristics based on prompts containing parent heuristics, task descriptions, and the appropriate context. Heuristics are evaluated by running them within the A* algorithm on training instances, with fitness scores based on solution quality relative to lower bounds. The approach is tested on UPMP (warehouse logistics) and SPP (sliding puzzle) using three different LLMs including Qwen2.5-Coder:32b and GPT4o.

## Key Results
- Embedding A* code into prompts (A-CEoH) significantly improves heuristic quality compared to the original EoH baseline
- Combining algorithmic and problem-specific context (PA-CEoH) provides complementary benefits, with further improvements for UPMP
- The smaller coding-oriented model Qwen2.5-Coder:32b performed on par with or better than the much larger GPT4o:2024-08-06 across both problem domains
- LLM-generated heuristics outperformed human-designed A* guiding heuristics from the literature

## Why This Works (Mechanism)

### Mechanism 1: Algorithmic Context Provides Precise Specification
Embedding the A* algorithm's source code directly into the LLM prompt improves heuristic quality by providing a precise specification of the execution environment. The algorithmic context shows how `h(n)` is called within `f(n) = g(n) + h(n)`, how nodes are expanded via `get_neighbors()`, and how the goal is defined by `is_goal()`. This leverages the LLM's code comprehension abilities for in-context learning, ensuring generated heuristics are syntactically and semantically compatible with the driver code.

### Mechanism 2: Complementary Benefits of Multiple Contexts
Algorithmic context (how the heuristic is used) and problem-specific context (what the problem means) provide complementary benefits. Algorithmic context ensures generated code is well-integrated with the search loop and fast enough for repeated calls, while problem-specific context provides semantic grounding about what state features are predictive of cost. PA-CEoH combines both, allowing the LLM to use semantic insights to build heuristics that fit algorithmic constraints.

### Mechanism 3: Context Quality Outweighs Model Size
Smaller, coding-specialized models can match or outperform larger general-purpose models when prompts are enriched with structured, domain-specific context. General-purpose models may rely on sparse internal knowledge for niche problems, while explicit context acts as powerful external memory. A smaller model specialized for code can more efficiently exploit structured information than a larger model distracted by broader, less relevant pre-training data.

## Foundational Learning

**Concept: A* Search Algorithm**
*Why needed:* Understanding the interplay between `g(n)` (path cost) and `h(n)` (estimated cost to goal) in `f(n)` is essential for grasping what makes a heuristic effective. A* uses `f(n) = g(n) + h(n)` to evaluate nodes, where admissibility of `h(n)` guarantees optimal solutions.
*Quick check:* What property must a heuristic satisfy to guarantee an optimal solution in A*, and how does overestimating `h(n)` affect the search?

**Concept: In-Context Learning (ICL)**
*Why needed:* A-CEoH relies on ICL, where the LLM learns from the prompt's context without weight updates. The model learns to "program" by analogy to provided examples of the A* driver code.
*Quick check:* How does LLM performance typically change as the number and relevance of examples in a prompt are increased, and what are its limits?

**Concept: Evolutionary Computation (EoH)**
*Why needed:* The paper uses an evolutionary loop to iteratively improve heuristics. Understanding population, fitness function, and operators (mutation, crossover) is required to interpret the experimental setup.
*Quick check:* What is the role of the "fitness function" in an evolutionary algorithm, and how is it calculated for a heuristic in this paper?

## Architecture Onboarding

**Component map:** Prompt Builder -> LLM Heuristic Generator -> Evaluator -> Programs Database -> (back to Prompt Builder)

**Critical path:**
1. **Initialization:** Prompt Builder uses strategy I1 to create initial heuristics; Evaluator scores them
2. **Selection & Evolution:** For each generation, system selects parents; Prompt Builder constructs new prompts using strategies E1, E2, M1, or M2, embedding parent code and full context
3. **Evaluation & Update:** LLM generates offspring; Evaluator scores them; Programs Database updates, retaining top performers

**Design tradeoffs:**
- Context Richness vs. Token Cost: Adding full A* code and descriptions increases input tokens (PA-CEoH ~2x tokens of baseline), raising API costs and latency
- General vs. Specialized Models: Smaller coding models can outperform larger generalists but may lack broad reasoning for novel problems
- Exploration vs. Exploitation: EoH balances via different prompt strategies (E1/E2 for exploration, M1/M2 for exploitation)

**Failure signatures:**
- Syntax/Runtime Errors: Generated code is invalid or crashes during evaluation
- Interface Mismatch: Generated function signature doesn't match A* driver expectations
- Stagnation: Population fitness plateaus due to local optima or insufficient context inspiration
- Inadmissible Heuristics: Generated heuristics may sacrifice optimality guarantees for speed

**First 3 experiments:**
1. **Baseline (EoH) Run:** Execute standard EoH framework on target problem without contextual augmentation
2. **A-CEoH Ablation:** Run experiment with only algorithmic context (A* driver code) added to prompt; compare against baseline
3. **Model & Augmentation Comparison:** Execute both P-CEoH and PA-CEoH using smaller coding model (Qwen2.5-Coder) and compare performance against baseline from larger model

## Open Questions the Paper Calls Out

**Open Question 1:** Can the algorithmic context strategy be effectively transferred to other search frameworks?
*Basis:* The conclusion states future work will extend the "problem-agnostic idea of algorithmic context" to "other algorithmic frameworks such as large neighborhood search." This remains unresolved as the current study validated the approach exclusively on A* search implementations.

**Open Question 2:** Is the performance of A-CEoH robust across a wider range of combinatorial optimization domains?
*Basis:* The conclusion outlines future work extending the method to "additional combinatorial problems." This is unresolved as the study was limited to two specific domains: UPMP and SPP.

**Open Question 3:** Why does the combination of problem-specific and algorithmic context (PA-CEoH) fail to outperform algorithmic context alone (A-CEoH) for well-studied problems?
*Basis:* The authors note that for SPP, PA-CEoH did not exceed A-CEoH performance, unlike UPMP results, but don't explain the underlying cause. It's unclear if this is due to redundancy in context for "canonical" problems or an interaction effect with the specific LLM used.

## Limitations
- The exact prompt templates and problem descriptions for P-CEoH are not fully specified in the paper, requiring reliance on the referenced repository
- Fitness computation for UPMP depends on a problem-specific lower bound referenced from [25] without explicit formula
- While token counts are reported, the impact of context length on LLM performance (attention span, relevance) is not deeply analyzed

## Confidence

**High Confidence:** The core finding that embedding algorithmic context improves heuristic quality is well-supported by direct comparisons between EoH and A-CEoH in Figures 5a and 5b.

**Medium Confidence:** The claim that PA-CEoH provides complementary benefits for UPMP is supported by results, but the lack of synergy for SPP and absence of deeper analysis on why contexts interact differently across problems introduces uncertainty.

**Medium Confidence:** The claim that Qwen2.5-Coder:32b outperforms GPT4o is supported, but the comparison is limited to a single coding-specialized model versus one generalist; broader ablation over model families would strengthen this claim.

## Next Checks

1. **Ablation on Context Granularity:** Systematically remove parts of the A* driver (e.g., only keep `get_neighbors()` vs. full code) to determine which elements of algorithmic context are most critical for performance gains.

2. **Cross-Domain Transfer Test:** Apply the same PA-CEoH strategy to a third, structurally different problem (e.g., 8-puzzle or TSP) to test whether the observed synergy generalizes beyond UPMP and SPP.

3. **Extended Runtime Analysis:** Increase the maximum number of generations or evaluation budget (e.g., 100 generations or 10 minutes per instance) to check if fitness improvements plateau or continue, providing insight into scalability.