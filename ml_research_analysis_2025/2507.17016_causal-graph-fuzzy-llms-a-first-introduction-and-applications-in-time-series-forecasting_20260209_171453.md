---
ver: rpa2
title: 'Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series
  Forecasting'
arxiv_id: '2507.17016'
source_url: https://arxiv.org/abs/2507.17016
tags:
- time
- series
- forecasting
- fuzzy
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents CGF-LLM, a new framework for time series forecasting
  that combines fuzzy time series (FTS), causal graphs, and large language models
  (LLMs). The method converts numerical time series into interpretable linguistic
  representations using fuzzification and causal analysis, then feeds these into GPT-2
  to generate forecasts.
---

# Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series Forecasting

## Quick Facts
- **arXiv ID**: 2507.17016
- **Source URL**: https://arxiv.org/abs/2507.17016
- **Reference count**: 40
- **Primary result**: Novel framework combining fuzzy time series, causal graphs, and LLMs achieves up to 36× token reduction and superior NRMSE accuracy on four multivariate datasets

## Executive Summary
This paper introduces CGF-LLM, a novel framework that combines fuzzy time series (FTS) partitioning, causal graph discovery via PCMCI, and large language models (LLMs) for time series forecasting. The method converts numerical time series into interpretable linguistic fuzzy labels, identifies causal relationships between variables, and uses a fine-tuned GPT-2 to generate forecasts from these causal fuzzy patterns. The approach achieves superior accuracy compared to standard LLM methods while dramatically reducing computational overhead through efficient linguistic tokenization.

## Method Summary
CGF-LLM is a MISO (Multiple-Input Single-Output) time series forecasting framework that integrates three key components: (1) PyFTS for fuzzification, converting numerical values into fuzzy linguistic sets using triangular membership functions with K=30 partitions; (2) PCMCI algorithm via Tigramite for causal discovery, identifying temporal causal parents while avoiding spurious correlations; and (3) a fine-tuned GPT-2 model with attention pooling and MLP regression head. The framework processes four multivariate datasets (Economic/Bitcoin, Energy/Wind Power, IoT/Household Electricity, and Climatic/Solar Radiation) using 10 sliding windows with 80/20 train-test splits, evaluating performance via NRMSE across 20 epochs of fine-tuning.

## Key Results
- CGF-LLM achieved NRMSE values ranging from 0.027 to 0.094 across four datasets, significantly outperforming standard LLM approaches
- The fuzzy linguistic representation reduced token count by approximately 36× compared to raw numerical encoding
- No-freezing fine-tuning strategy consistently outperformed frozen models, with notable accuracy gains on Energy (NRMSE 0.066 vs 0.153)
- Computational efficiency gains were most pronounced on the largest IoT dataset (100,000 samples, 14 variables)

## Why This Works (Mechanism)

### Mechanism 1
Converting numerical time series into linguistic fuzzy labels significantly reduces token count and computational overhead compared to raw numerical string encoding. The fuzzification process maps continuous values (e.g., "23.5") to short, repetitive linguistic labels (e.g., "f1"). Since LLM tokenizers split complex numerical strings into multiple tokens but often map common short words to single tokens, this reduces the sequence length the attention mechanism must process.

### Mechanism 2
Structuring input via causal discovery (PCMCI) likely improves forecasting accuracy by filtering out spurious correlations and isolating the true temporal parents of the target variable. The PCMCI algorithm identifies a causal graph by testing conditional independence. By feeding only the causally relevant lagged variables into the LLM prompt, the model focuses its attention capacity on genuine drivers rather than noise.

### Mechanism 3
Fine-tuning the entire GPT-2 model (No Freezing) enables better adaptation to the specific "language" of fuzzy causal rules than training only a regression head. The "No Freezing" strategy updates the transformer's internal weights, allowing the self-attention mechanism to learn complex dependencies between the fuzzy causal tokens. In contrast, freezing preserves the original NLP-biased weights, which may not align with the rigid logical structure of fuzzy time series rules.

## Foundational Learning

- **Concept: Fuzzy Time Series (FTS) Partitioning**
  - **Why needed here**: You cannot interpret the model's inputs or outputs without understanding how the "Universe of Discourse" (numerical range) is sliced into fuzzy sets (e.g., "low", "medium") and converted to membership vectors.
  - **Quick check question**: If a value is exactly on the boundary between two fuzzy sets, how does the membership function determine its degree of belonging?

- **Concept: PCMCI (PC algorithm with Momentary Conditional Independence)**
  - **Why needed here**: This is the "Causal Graph" engine. You must understand that it removes links based on conditional independence tests to distinguish true parents from mere correlates.
  - **Quick check question**: Why does PCMCI perform the MCI test after the PC1 algorithm? (Hint: To remove false positives caused by autocorrelation).

- **Concept: Attention Pooling in Regression Heads**
  - **Why needed here**: The paper uses an "attention-based pooling step" to convert the LLM's variable-length sequence output into a single vector for the final numerical prediction.
  - **Quick check question**: Why is attention pooling often preferred over simple mean pooling or using the final token's embedding when aggregating temporal features?

## Architecture Onboarding

- **Component map**: Preprocessing Layer (PyFTS + Tigramite) -> Text Constructor (Prompt Generation) -> GPT-2 Backbone -> Output Head (Attention Pooling -> MLP -> Scalar Output)

- **Critical path**:
  1. Define Universe of Discourse (UoD) and partition into K sets
  2. Run PCMCI to identify causal parents for the target variable
  3. Construct text dataset using only causally relevant fuzzy lags
  4. Fine-tune GPT-2 (No Freezing recommended) to minimize MSE on the defuzzified output

- **Design tradeoffs**:
  - Partition Count (K=30): Higher K increases resolution but creates longer sequences and risks data sparsity in fuzzy rules
  - Freezing vs. No Freezing: No Freezing yields better accuracy but requires significantly more compute and VRAM

- **Failure signatures**:
  - Stagnant Forecasts: Model predicts mean value repeatedly (coarse partitioning or empty causal graph)
  - High Error on Volatile Data: Model fails on Economic/Bitcoin dataset (fuzzy logic struggles with non-stationary noise)

- **First 3 experiments**:
  1. Tokenization Efficiency Test: Verify the 36× reduction by comparing token counts between raw numbers and fuzzy labels
  2. Causal Ablation: Compare performance with PCMCI enabled vs. all-lags input to test causal filtering value
  3. Freezing Sensitivity: Train frozen vs. full fine-tuning models on Energy dataset to reproduce NRMSE gap

## Open Questions the Paper Calls Out

- **Open Question 1**: To what extent can automated hyperparameter optimization improve CGF-LLM performance compared to the empirically fixed values used in the study?
  - **Basis**: Authors suggest optimizing model hyperparameters via auto ML as future work
  - **Why unresolved**: Current values like partition count and lag window were selected empirically based on computational cost
  - **What evidence would resolve it**: Comparative analysis of NRMSE using AutoML-tuned parameters versus manual baseline

- **Open Question 2**: Does the CGF-LLM framework's efficiency and accuracy transfer to larger or more recent LLM architectures, such as GPT-3 or GPT-4?
  - **Basis**: Authors explicitly identify exploring GPT-3, GPT-4 as key research avenue
  - **Why unresolved**: Study exclusively utilized GPT-2; unverified if benefits persist with different tokenizers or attention mechanisms
  - **What evidence would resolve it**: Replication using larger models on same datasets to compare NRMSE and token reduction ratios

- **Open Question 3**: Can the proposed architecture be effectively adapted for Multiple-Input Multiple-Output (MIMO) forecasting tasks?
  - **Basis**: Authors note future work may extend CGF-LLM to support multiple-output forecasting tasks
  - **Why unresolved**: Current architecture designed as MISO system, limiting application to predicting only endogenous variable Y^0
  - **What evidence would resolve it**: Modified output layer generating vector forecasts evaluated on multivariate datasets requiring simultaneous multi-variable prediction

## Limitations

- Limited External Validation: Only evaluated on four public datasets; performance on noisy, non-stationary, or high-frequency data remains unknown
- Reproducibility Gaps: Missing critical implementation details including GPT-2 variant, exact prompt templates, and defuzzification procedures
- Computational Trade-offs: No detailed analysis of computational costs or exploration of partial fine-tuning/adapter approaches for different deployment scenarios

## Confidence

**High Confidence**:
- Fuzzy linguistic representation reduces token count compared to raw numerical strings
- Causal filtering improves accuracy by removing spurious correlations
- General architecture combining FTS, causal graphs, and LLMs is novel and plausible

**Medium Confidence**:
- Specific NRMSE values and efficiency gains are accurate (dependent on unreported implementation details)
- Full fine-tuning is consistently better than freezing across all datasets
- 36× token reduction claim (requires verification of exact prompt format and tokenizer behavior)

**Low Confidence**:
- Performance claims on Economic/Bitcoin dataset (highest error suggests potential weaknesses)
- Generalizability to datasets with different characteristics (frequency, stationarity, noise levels)
- Scalability to very high-dimensional time series (>14 variables)

## Next Checks

1. **Tokenization Efficiency Validation**: Implement exact prompt generation and verify 36× token reduction by comparing token counts between raw numerical strings and fuzzy linguistic representations using GPT-2 tokenizer.

2. **Causal Ablation Study**: Create modified version removing PCMCI causal filtering (uses all lags instead) and compare performance on at least two datasets to isolate whether causal graph component actually contributes to accuracy improvements.

3. **Parameter Sensitivity Analysis**: Systematically vary K (10-50 partitions) and τmax (5-30 lag range) on one dataset to identify optimal values and understand how sensitive the method is to these critical hyperparameters.