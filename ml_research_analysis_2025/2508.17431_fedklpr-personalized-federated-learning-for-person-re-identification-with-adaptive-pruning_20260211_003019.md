---
ver: rpa2
title: 'FedKLPR: Personalized Federated Learning for Person Re-Identification with
  Adaptive Pruning'
arxiv_id: '2508.17431'
source_url: https://arxiv.org/abs/2508.17431
tags:
- pruning
- fedklpr
- learning
- federated
- aggregation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces FedKLPR, a federated learning framework
  for person re-identification that addresses two key challenges: statistical heterogeneity
  across clients with non-IID data distributions and communication overhead from transmitting
  large models. FedKLPR introduces four main innovations: KL-Divergence Regularization
  Loss (KLL) to align local and global feature distributions and improve convergence
  stability; KL-Divergence-Prune Weighted Aggregation (KLPWA) that combines distributional
  similarity and pruning ratios for more efficient aggregation; Sparse Activation
  Skipping (SAS) to exclude pruned parameters during aggregation and preserve important
  weights; and Cross-Round Recovery (CRR) to prevent accuracy degradation from pruning
  through a two-stage verification process.'
---

# FedKLPR: Personalized Federated Learning for Person Re-Identification with Adaptive Pruning

## Quick Facts
- **arXiv ID:** 2508.17431
- **Source URL:** https://arxiv.org/abs/2508.17431
- **Reference count:** 40
- **Primary result:** Reduces communication cost by 33%-38% on ResNet-50 while maintaining model accuracy within 1% degradation compared to state-of-the-art methods

## Executive Summary
FedKLPR introduces a federated learning framework for person re-identification that addresses statistical heterogeneity across clients with non-IID data distributions and communication overhead from transmitting large models. The framework combines KL-Divergence Regularization Loss to align local and global feature distributions, KL-Divergence-Prune Weighted Aggregation that integrates pruning ratios and distributional similarity, Sparse Activation Skipping to preserve important parameters during aggregation, and Cross-Round Recovery to prevent accuracy degradation from pruning. Experimental results on eight benchmark datasets demonstrate superior performance particularly on smaller datasets while enabling significant model compression through adaptive pruning.

## Method Summary
FedKLPR implements an unsupervised federated learning system for person re-identification using ResNet-50/34 backbones with camera-aware contrastive loss enhanced by KL-divergence regularization. The framework employs memory banks with proxy storage, DBSCAN clustering for pseudo-labels, and unstructured pruning controlled by a two-stage verification process. Local training incorporates KL-divergence loss to minimize feature distribution divergence from the global model, while aggregation uses weighted combinations of KL-divergence similarity and pruning ratios. Sparse activation skipping excludes zero-valued parameters during aggregation, and cross-round recovery prevents accuracy collapse through dynamic pruning control.

## Key Results
- Reduces communication cost by 33%-38% on ResNet-50 and 20%-40% on ResNet-34 across benchmark datasets
- Maintains model accuracy within 1% degradation compared to state-of-the-art methods
- Achieves superior performance on smaller datasets (iLIDS-VID, VIPeR, CUHK01, 3DPeS) through effective pruning control
- Demonstrates effectiveness of KL-divergence regularization in mitigating statistical heterogeneity effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KL-Divergence Regularization Loss (KLL) may reduce local model drift under non-IID conditions by explicitly penalizing distributional divergence from the global model.
- Mechanism: The loss term $L_{KL}$ is added to the camera-aware contrastive loss during local training, minimizing $D_{KL}(P_{M_k^t}(D_{batch}) \| P_{M_k^{t-1}}(D_{batch}))$. Unlike cosine similarity which captures only angular differences, KL divergence measures shape and dispersion differences in feature distributions.
- Core assumption: Local and global feature distributions can be meaningfully aligned through KL minimization without destroying client-specific discriminative information.
- Evidence anchors:
  - [abstract] "KL-Divergence Regularization Loss (KLL) constrains local models by minimizing the divergence from the global feature distribution, effectively mitigating the effects of statistical heterogeneity"
  - [section III.C] "By minimizing KL divergence during training, we enforce alignment between local and global feature distributions, thereby mitigating excessive model drift"
  - [corpus] FedAPA (arXiv:2502.07456) similarly addresses heterogeneous data in federated learning through adaptive aggregation, suggesting heterogeneity mitigation is an active research concern
- Break condition: If δ (regularization coefficient) is set too high, local models may over-constrain toward global distribution, losing personalization—especially harmful when client data has genuinely unique characteristics.

### Mechanism 2
- Claim: KL-Divergence-Prune Weighted Aggregation (KLPWA) appears to prioritize clients contributing both high information gain (measured via KL divergence) and structural compactness (measured via pruning ratio).
- Mechanism: Aggregation weight combines two components: (1) $f_k^t / f^t$ where $f_k^t = D_{KL}$ between pre/post training feature distributions, and (2) $W_k = P_k^2 / P_t$ where $P_k$ is pruning ratio. Final aggregation: $M_g^t = \gamma \sum \frac{f_k^t}{f^t} M_k^t + \delta \sum W_k M_k^t$.
- Core assumption: Clients with higher pruning ratios have models more structurally aligned with the global model, making their contributions more reliable.
- Evidence anchors:
  - [abstract] "KL-Divergence-Prune Weighted Aggregation (KLPWA) integrates pruning ratio and distributional similarity into the aggregation process"
  - [section III.D.2] "A higher pruning ratio indicates that the client's model retains fewer parameters, implying greater structural similarity and alignment with the global model"
  - [corpus] No direct corpus evidence for pruning-ratio-weighted aggregation in Re-ID; this appears novel
- Break condition: Assumption that higher pruning ratio implies better alignment may fail if aggressive pruning removes client-specific discriminative features rather than redundant ones.

### Mechanism 3
- Claim: Sparse Activation Skipping (SAS) likely prevents dilution of important parameters when aggregating heterogeneously-pruned models by excluding zero-valued weights from averaging.
- Mechanism: During aggregation, SAS tracks which clients have non-zero values for each parameter position. Aggregated value is computed only over contributing clients, then normalized by their combined weights (not total client count).
- Core assumption: Pruned (zero-valued) parameters should not influence the aggregated value, as they represent intentionally removed weights.
- Evidence anchors:
  - [abstract] "Sparse Activation Skipping (SAS) mitigates the dilution of critical parameters during the aggregation of pruned client models by excluding zero-valued weights from the update process"
  - [section III.E] "SAS identifies pruned parameters and excludes them from the aggregation process... ensures that the contributions of important weights are preserved and not diluted by zero-valued parameters"
  - [corpus] No corpus papers discuss sparse activation skipping in federated aggregation
- Break condition: If clients have highly non-overlapping pruned parameter sets, the global model may receive inconsistent gradient signals across rounds, potentially destabilizing convergence.

### Mechanism 4
- Claim: Cross-Round Recovery (CRR) conditionally prevents accuracy collapse by requiring both training stability and post-pruning accuracy verification before allowing further pruning.
- Mechanism: Two-stage check: Stage 1 requires $Acc^t \geq Acc_{th}$ AND $Acc^t - Acc^{t-1} \leq \delta_{rd}$; Stage 2 requires $Acc_{pr} - Acc^t \leq \delta_{ep}$. Pruning only proceeds if both pass.
- Core assumption: Model needs to recover performance across federated aggregation rounds before additional pruning, not just within a single round.
- Evidence anchors:
  - [abstract] "Cross-Round Recovery (CRR) introduces a dynamic pruning control mechanism that halts pruning when necessary, enabling deeper compression while maintaining model accuracy"
  - [section III.F] "Unlike conventional pruning methods that assess performance drop within a single training round, CRR additionally considers the effects of multi-round aggregation"
  - [section IV.E ablation] Combining PRAW with CRR proves effective in maintaining accuracy on small-scale datasets including CUHK03, VIPeR, CUHK01, and 3DPeS
- Break condition: If target accuracy threshold $Acc_{th}$ is set too conservatively, pruning may stall early, limiting communication savings; if too aggressive, may allow irreversible accuracy degradation.

## Foundational Learning

- **KL Divergence as Distributional Distance**
  - Why needed here: Understanding why KL divergence captures more information than cosine similarity for measuring client-server distribution mismatch is essential for grasping KLL and KLAW design.
  - Quick check question: Given two Gaussian distributions with same mean but different variances, would cosine similarity of their mean vectors detect the difference? Would KL divergence?

- **Unstructured Pruning with Pruning Masks**
  - Why needed here: SAS relies on the fact that different clients may prune different parameter indices; understanding mask-based pruning is prerequisite to implementing parameter exclusion during aggregation.
  - Quick check question: If Client A prunes parameter indices [0, 5, 10] and Client B prunes [5, 15, 20], which parameters should contribute to the aggregated global model at index 5?

- **Federated Averaging with Non-Uniform Weights**
  - Why needed here: KLPWA modifies standard FedAvg by replacing dataset-size weights with combined KL-divergence and pruning-ratio weights; understanding base FedAvg is necessary.
  - Quick check question: In standard FedAvg, if Client 1 has 1000 samples and Client 2 has 100 samples, what weight does each client receive? How does this change with KLPWA?

## Architecture Onboarding

- **Component map:**
  - Client-side: Local CNN backbone (ResNet-50/34) -> Memory bank with proxy storage -> DBSCAN clustering for pseudo-labels -> Camera-aware contrastive loss + KLL -> Unstructured pruning with CRR control -> Upload model + mask + pruning ratio + KLAW
  - Server-side: Receive client uploads -> Compute PRAW from pruning ratios -> Combine KLAW + PRAW via KLPWA -> Aggregate using SAS (skip zero entries) -> Distribute global model -> Client applies local mask for personalization

- **Critical path:**
  1. KLAW computation requires extracting features from SAME validation batch before and after local training (consistency critical)
  2. CRR Stage 2 requires inference on validation set pre/post pruning within the same round
  3. SAS normalization must divide by sum of weights for contributing clients only (not all K clients)

- **Design tradeoffs:**
  - **δ (KLL coefficient)**: Paper uses 0.13; higher values improve convergence stability but risk over-regularization on heterogeneous clients
  - **Target pruning ratio vs. communication budget**: 70% target pruning may not be achievable on all datasets without accuracy loss; CRR may halt early
  - **γ vs. δ in KLPWA**: Balances knowledge gain (KLAW) vs. structural consistency (PRAW); paper doesn't specify exact values beyond "sum to 1"

- **Failure signatures:**
  - Accuracy collapse on small datasets (iLIDS-VID, VIPeR) without CRR/PRAW combination -> indicates pruning too aggressive without recovery mechanism
  - Communication cost not decreasing -> CRR may be rejecting all pruning attempts; check $Acc_{th}$ threshold
  - Global model performance worse than worst client -> SAS may be miscalculating normalization; verify weight summation

- **First 3 experiments:**
  1. **Ablation on single component**: Run FedKLPR with only KLL+KLAW (no pruning) on ResNet-50 across all 8 datasets to verify baseline improvement over FedCAPR; expect ~1-7% Rank-1 gains per Table II
  2. **Pruning-only baseline**: Add unstructured pruning without PRAW/SAS/CRR; expect significant accuracy drops on small datasets (6-12%) per Table VII row 3
  3. **Full system with CRR threshold sweep**: Vary $Acc_{th}$ from baseline accuracy to baseline+5% on VIPeR (smallest challenging dataset); plot final accuracy vs. communication cost to find operating point

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedKLPR perform in large-scale cross-device scenarios with thousands of clients and high dropout rates?
- Basis in paper: [inferred] The experimental setup in Section IV limits evaluation to a "cross-silo" scenario of only eight clients, leaving performance in high-client regimes unverified.
- Why unresolved: The complexity of computing KLPWA and the stability of the CRR mechanism under partial client participation (common in cross-device FL) are unknown.
- What evidence would resolve it: Empirical evaluation on federated benchmarks with significantly larger client pools and varying participation ratios.

### Open Question 2
- Question: Can FedKLPR be extended to structured pruning to enable actual on-device inference acceleration?
- Basis in paper: [inferred] The paper focuses on "unstructured pruning" (Section III.F) which reduces communication cost but often fails to reduce latency on standard hardware.
- Why unresolved: Unstructured sparsity requires specialized hardware or libraries to translate weight reduction into speedups; standard GPUs execute pruned models slowly.
- What evidence would resolve it: A modified framework utilizing structured pruning masks with accompanying latency and energy consumption benchmarks on edge devices.

### Open Question 3
- Question: Are the proposed KLL and KLPWA mechanisms effective when applied to modern architectures like Vision Transformers (ViT)?
- Basis in paper: [inferred] Section IV.A.2 restricts the backbone analysis to ResNet-50 and ResNet-34.
- Why unresolved: Transformers exhibit different feature distribution characteristics and over-pruning sensitivities compared to CNNs; the KLL alignment might require different regularization strengths.
- What evidence would resolve it: Experimental results applying FedKLPR to ViT or MobileNet backbones on the same Re-ID datasets.

## Limitations
- Experimental evaluation limited to small-scale benchmark datasets with only 8 clients, raising questions about scalability to realistic federated scenarios
- Communication cost reduction metrics assume unstructured pruning without considering structured alternatives that might offer better hardware acceleration
- Several hyperparameters (CRR thresholds, KLPWA balancing coefficients) are not fully specified, making exact reproduction challenging

## Confidence
- **High Confidence**: Core pruning mechanism (SAS) and CRR implementation are technically sound and well-described; communication cost reduction figures appear reliable given the methodology
- **Medium Confidence**: KL-Divergence Regularization Loss effectiveness is supported by ablation studies, but the distributional alignment mechanism could be more rigorously analyzed; weighted aggregation benefits are demonstrated but the optimal weight balance remains heuristic
- **Low Confidence**: Claims about superiority on small datasets rely heavily on specific hyperparameter tuning; generalization to larger-scale deployments is not validated

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary CRR thresholds ($Acc_{th}$, $\delta_{rd}$, $\delta_{ep}$) across all datasets to identify robust operating points and quantify stability margins
2. **Cross-Dataset Generalization**: Train FedKLPR on a subset of datasets (e.g., 4 clients) and test transfer learning performance on held-out datasets to validate personalization claims beyond one-client-per-dataset scenario
3. **Scalability Benchmark**: Simulate federated scenarios with 50-100 virtual clients using stratified data sampling from the available datasets to evaluate performance degradation and communication efficiency at scale