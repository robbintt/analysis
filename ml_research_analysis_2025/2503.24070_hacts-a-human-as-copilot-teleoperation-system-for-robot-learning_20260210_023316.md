---
ver: rpa2
title: 'HACTS: a Human-As-Copilot Teleoperation System for Robot Learning'
arxiv_id: '2503.24070'
source_url: https://arxiv.org/abs/2503.24070
tags:
- learning
- hacts
- robot
- data
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HACTS introduces a low-cost, bilateral teleoperation system enabling
  real-time joint synchronization between a robot arm and human operator hardware.
  By providing immediate mechanical feedback, it allows the human to act as a copilot,
  intervening during autonomous execution to collect high-quality action-correction
  data.
---

# HACTS: a Human-As-Copilot Teleoperation System for Robot Learning

## Quick Facts
- arXiv ID: 2503.24070
- Source URL: https://arxiv.org/abs/2503.24070
- Reference count: 29
- Primary result: Improves imitation learning success rates by 20-30% and enables zero-shot generalization to unseen object placements using low-cost bilateral teleoperation

## Executive Summary
HACTS introduces a low-cost, bilateral teleoperation system enabling real-time joint synchronization between a robot arm and human operator hardware. By providing immediate mechanical feedback, it allows the human to act as a copilot, intervening during autonomous execution to collect high-quality action-correction data. Implemented with 3D-printed parts and servo motors, it costs under $300. In imitation learning experiments, HACTS-ACT improved success rates from 40% to 70% on failure correction tasks and enabled zero-shot generalization to unseen object placements, achieving 30-50% success where baselines failed. In reinforcement learning, RLPD-HACTS achieved 80% success after 45 minutes of online training, with decreasing intervention length over time. The system is compatible with most robotic platforms and offers a scalable, affordable solution for enhancing robot learning through interactive human feedback.

## Method Summary
HACTS implements a leader-follower teleoperation system with bilateral joint synchronization, using kinematically equivalent hardware to mirror the robot's structure. The system enables seamless human intervention during autonomous execution by continuously relaying robot joint positions back to the operator hardware. Data is collected during intervention episodes where the human corrects autonomous policy failures, creating action-correction datasets. The system was evaluated using ACT (Action Chunking Transformer) and RLPD (Reinforcement Learning with Policy Distillation) algorithms, demonstrating improved learning performance through correction data integration.

## Key Results
- HACTS-ACT improved imitation learning success rates from 40% to 70% on failure correction tasks
- Enabled zero-shot generalization to unseen object placements, achieving 30-50% success where baselines failed
- RLPD-HACTS achieved 80% success after 45 minutes of online training, with decreasing intervention length over time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bilateral joint synchronization enables seamless human intervention during autonomous robot execution.
- Mechanism: The system maintains bidirectional position flow—leader-to-follower for teleoperation, follower-to-leader for reverse synchronization. When the robot operates autonomously, its joint positions are continuously relayed back to the teleoperation hardware, allowing the human to perceive robot state kinesthetically and intervene without position mismatch.
- Core assumption: Position-based feedback (vs. force/tactile) is sufficient for effective intervention and is more broadly compatible with standard robot arms.
- Evidence anchors:
  - [abstract] "enables the human copilot to intervene seamlessly while collecting action-correction data"
  - [section III.A] "HACTS operates as a leader-follower system with bilateral position control, enabling both leader-to-follower and follower-to-leader synchronization"
  - [corpus] Weak direct comparison—Bi-ACT [5] explored bilateral control but required force feedback; HACTS simplifies to position-only.
- Break condition: If task requires force-sensitive feedback (e.g., contact-rich assembly), position-only synchronization may be insufficient without additional sensing.

### Mechanism 2
- Claim: Action-correction data collected during failure recovery is more informative per trajectory than uniform expert demonstrations.
- Mechanism: HACTS captures intervention trajectories specifically when the policy fails or faces OOD scenarios. These trajectories contain recovery actions that explicitly address failure modes, creating a non-uniform data distribution weighted toward challenging states.
- Core assumption: Policy failure modes are learnable from correction demonstrations; the underlying IL/RL algorithm can effectively utilize mixed-quality data.
- Evidence anchors:
  - [abstract] "improves imitation learning success rates by 20-30% across three manipulation tasks"
  - [section IV.C] "HACTS-ACT achieved higher success rates than full-ACT in all three tasks, due to including more demonstrations in scenarios where pre-ACT models often failed"
  - [corpus] RoboCopilot (2503.07771) demonstrates similar intervention-based learning gains; "Real-world Reinforcement Learning from Suboptimal Interventions" (2512.24288) confirms value of correction data in RL.
- Break condition: If correction data contains inconsistent strategies across operators, policy may learn conflicting behaviors; requires filtering or standardization.

### Mechanism 3
- Claim: Kinematically equivalent leader device reduces cognitive load and improves control precision.
- Mechanism: The teleoperation hardware mirrors the robot's kinematic structure (scaled DH parameters), establishing joint-to-joint correspondence. This eliminates IK/FK computation latency and allows operators to control individual joints intuitively.
- Core assumption: Joint-level control is preferable to end-effector control for manipulation tasks requiring dexterity.
- Evidence anchors:
  - [section III.B] "The kinematically equivalent structure is derived from the Denavit–Hartenberg parameters, with the lengths scaled by a factor"
  - [section II.A] "Traditional teleoperation systems...can only control the end-effector pose...which limits the expression of human operators"
  - [corpus] ALOHA and Gello (referenced in paper) validate kinematic equivalence approach; corpus lacks direct comparison data.
- Break condition: If target robot has significantly different kinematics (e.g., 7-DOF vs. 6-DOF), direct joint mapping fails and requires retargeting logic.

## Foundational Learning

- Concept: **Leader-Follower Teleoperation**
  - Why needed here: HACTS is fundamentally a leader-follower architecture; understanding this paradigm is prerequisite to grasping bilateral control.
  - Quick check question: Can you explain why unilateral leader-follower systems prevent seamless intervention?

- Concept: **Imitation Learning (ACT and Diffusion Policy)**
  - Why needed here: The paper evaluates HACTS using ACT and DP; understanding action chunking and diffusion-based policies is required to interpret results.
  - Quick check question: How does action chunking in ACT handle temporal consistency, and why might it struggle with dynamic disturbances?

- Concept: **Off-Policy RL with Demonstrations (RLPD)**
  - Why needed here: RLPD-HACTS combines offline demonstrations with online human corrections; understanding off-policy learning with mixed data sources is essential.
  - Quick check question: Why does RLPD require a replay buffer, and how does human intervention data integrate into the training loop?

## Architecture Onboarding

- Component map:
  - Leader device (7x DYNAMIXEL motors) -> Robot arm (UR5) -> Sensing (336 wrist + 336L external cameras) -> Compute (RTX 4090) -> Interface (Bus Servo Adapter + foot pedal) -> Software stack (DYNAMIXEL API)

- Critical path:
  1. Motor initialization and offset calibration
  2. Bidirectional position streaming (robot ↔ leader device)
  3. Mode switching via foot pedal (autonomous ↔ teleoperation)
  4. Data recording during intervention (state, action, correction flag)

- Design tradeoffs:
  - **XL430 vs. XL330 motors**: XL430 provides higher torque for base joints but increases cost and weight; paper uses hybrid approach.
  - **Position-only vs. force feedback**: Simplifies compatibility but limits usefulness for contact-rich tasks.
  - **3D-printed frame**: Low cost and customizable, but less durable than machined components.

- Failure signatures:
  - **Synchronization lag**: If communication latency exceeds ~50ms, intervention feels disconnected; check USB bandwidth.
  - **Motor overheating**: XL430 motors under continuous load may thermal-throttle; monitor temperature during extended sessions.
  - **Offset drift**: If calibration is incorrect, leader device positions won't map to robot; re-run calibration procedure.

- First 3 experiments:
  1. **Validate bilateral sync**: Command robot to move autonomously; verify leader device mirrors positions without human input. Check latency < 30ms.
  2. **Collect 10 intervention trajectories**: Run pre-trained policy, intervene on failures, verify data logs include correction flags and timestamped actions.
  3. **Train HACTS-ACT on single task**: Replicate SteamBun or similar task with 50 expert + 50 intervention trajectories; compare success rate against full-ACT baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the HACTS architecture be effectively scaled to robot arms with significantly different kinematic structures (e.g., 7-DoF or mobile manipulators) without suffering from workspace mismatch or control instability?
- Basis in paper: [explicit] The authors state in Section III.B that components "can easily be extended to other robot arms since we only need to synchronize position information," but the experiments are restricted to the UR5.
- Why unresolved: While the hardware is customizable, the software efficacy and "kinematic equivalence" were only validated on a single 6-DoF industrial arm configuration.
- What evidence would resolve it: Successful deployment and maintenance of bilateral synchronization on a 7-DoF arm or a quadruped-mounted manipulator.

### Open Question 2
- Question: How does the absence of force feedback in HACTS impact performance limits in contact-rich tasks that require precise compliance control?
- Basis in paper: [inferred] The introduction notes that existing bilateral systems use "tactile and force feedback," but HACTS relies solely on "bilateral joint synchronization" to keep costs low.
- Why unresolved: The paper demonstrates success in a "CloseBin" task, but does not analyze scenarios where force sensing is critical (e.g., fragile object handling or assembly), leaving the performance gap relative to force-feedback systems unknown.
- What evidence would resolve it: A comparative study against force-feedback teleoperation systems on high-precision insertion or polishing tasks.

### Open Question 3
- Question: Can learning algorithms be specifically optimized to better distinguish between "copilot" correction data and standard expert demonstration data?
- Basis in paper: [explicit] The conclusion suggests that "further model optimization and careful integration design of human feedback" will play a significant role in advancing robot learning.
- Why unresolved: The current experiments utilize standard ACT, DP, and RLPD, which treat intervention data essentially as regular trajectory data, potentially missing the opportunity to weight corrective signals differently.
- What evidence would resolve it: Developing a loss function or training pipeline that uniquely weights intervention frames to accelerate recovery learning.

## Limitations
- Position-only feedback may be insufficient for contact-rich tasks requiring force-sensitive interaction
- Performance depends heavily on operator expertise with no evaluation of training effects or consistency across multiple operators
- Kinematic equivalence assumption may break down for robots with significantly different joint structures or degrees of freedom

## Confidence

**High confidence**: Mechanical design and bilateral synchronization mechanism
- Hardware implementation is straightforward and well-documented

**Medium confidence**: Learning performance claims
- Results show consistent improvement but depend on specific task configurations and operator skill

**Low confidence**: Generalization across robot platforms and task domains
- Limited validation on different robot architectures and task types

## Next Checks
1. Test HACTS on a 7-DOF robot arm (e.g., Franka Emika) to validate kinematic retargeting capabilities
2. Evaluate operator consistency by collecting data from 5+ operators on identical failure scenarios
3. Implement force feedback augmentation and compare performance on a contact-rich task (e.g., peg insertion) against position-only baseline