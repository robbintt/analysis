---
ver: rpa2
title: Uncovering the Spectral Bias in Diagonal State Space Models
arxiv_id: '2508.20441'
source_url: https://arxiv.org/abs/2508.20441
tags:
- initialization
- diagonal
- state
- frequency
- s4d-dfout
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates diagonal state space models (SSMs) from
  a frequency perspective, uncovering how initialization schemes affect their ability
  to capture long-range dependencies. The authors observe that current diagonal SSM
  initialization methods, such as S4D-Lin and S4D-Inv, entangle decay and frequency
  through discretization, leading to sensitivity to the discretization step and uneven
  spectral coverage.
---

# Uncovering the Spectral Bias in Diagonal State Space Models

## Quick Facts
- **arXiv ID**: 2508.20441
- **Source URL**: https://arxiv.org/abs/2508.20441
- **Reference count**: 40
- **One-line result**: Novel initialization scheme S4D-DFouT achieves state-of-the-art results on Long Range Arena, including first successful training from scratch on PathX-256

## Executive Summary
This paper investigates diagonal State Space Models (SSMs) from a frequency perspective, uncovering how initialization schemes affect their ability to capture long-range dependencies. The authors observe that current diagonal SSM initialization methods entangle decay and frequency through discretization, leading to sensitivity to the discretization step and uneven spectral coverage. To address these issues, they propose S4D-DFouT, a novel initialization scheme defined directly in the discrete domain that ensures uniform spectral coverage and reduces sensitivity to discretization. By synchronizing pole placements across SSMs within a layer, S4D-DFouT enables more effective scaling and achieves state-of-the-art results on the Long Range Arena benchmark, including the first successful training from scratch on the challenging PathX-256 dataset.

## Method Summary
The authors propose S4D-DFouT, a novel initialization scheme for diagonal State Space Models that defines poles directly in the discrete frequency domain rather than discretizing continuous-time poles. The method initializes eigenvalues as λ_n = exp(-ξ/2 + i·2πn/N), where ξ is a learnable decay parameter and n indexes the frequency grid. For layers with H parallel SSMs, phase offsets φ_h = 2π(h-1)/(NH) ensure uniform spectral coverage across all feature dimensions. This approach decouples decay and frequency parameters, reduces sensitivity to discretization step size, and enables more effective scaling compared to baseline methods like S4D-Lin and S4D-Inv.

## Key Results
- S4D-DFouT achieves 87.89% accuracy on PathX-256, the first successful training from scratch on this challenging dataset
- The method demonstrates reduced sensitivity to discretization step size compared to continuous-time initialization schemes
- Layer-wise synchronization of pole placements enables more effective scaling and prevents frequency competition across parallel SSMs
- S4D-DFouT maintains performance with shorter convolution kernels, revealing local attention biases in previous methods

## Why This Works (Mechanism)

### Mechanism 1: Discretization Entangles Decay and Frequency
When continuous poles λ = -α + iω undergo zero-order hold discretization, both decay and frequency components scale linearly with the discretization step Δ: λ̄ = exp(-αΔ + iωΔ). This entanglement prevents independent control of temporal decay and resonant frequencies, creating sensitivity to the chosen discretization step.

### Mechanism 2: Uniform Spectral Coverage Through Discrete Pole Placement
S4D-DFouT places poles uniformly on a regular grid in the discrete frequency domain: λ_n = exp(-ξ/2 + i·2πn/N). This ensures complete coverage of [0, 2π) while the shared damping ξ independently governs memory retention, satisfying the non-aliasing condition from Lemma 1.

### Mechanism 3: Layer-wise Synchronization Prevents Frequency Competition
An S4 layer contains H parallel SSMs. Layer-wise synchronization assigns phase offsets φ_h = 2π(h-1)/(NH) to each SSM, creating a combined uniform grid of size NH across [0, 2π). This prevents multiple SSMs from competing at nearly identical frequencies.

## Foundational Learning

- **Concept: Zero-Order Hold (ZOH) Discretization**
  - Why needed here: Understanding how continuous-time differential equations become discrete-time recurrence relations explains the entanglement problem at the core of this paper
  - Quick check question: Given a continuous pole λ = -0.5 + iπ and Δ = 0.1, compute the discrete pole λ̄ after ZOH discretization

- **Concept: Pole-Zero Analysis and Frequency Response**
  - Why needed here: The paper frames SSM behavior in terms of pole placement on the complex plane and resulting frequency response; understanding H(e^iθ) is essential for interpreting Figure 2 and Lemma 1
  - Quick check question: If all poles lie on the unit circle (|λ_n| = 1), what does this imply about system stability and frequency selectivity?

- **Concept: Discrete Fourier Transform (DFT) Basis**
  - Why needed here: S4D-DFouT reduces to the DFT when ξ = 0; understanding this limiting case clarifies why the initialization is called "universal"
  - Quick check question: Why does the "half-plane" variant (Section 4.2) require only N/2 + 1 poles for real-valued inputs?

## Architecture Onboarding

- **Component map**: Continuous initialization path (baseline) -> Define Λ in continuous time -> Apply ZOH with learnable Δ -> Train with coupled decay/frequency parameters; Discrete initialization path (S4D-DFouT) -> Define Λ̄ directly on unit circle -> Set uniform frequency grid + learnable ξ -> Train with decoupled parameters; Layer synchronization module -> Computes phase offsets φ_h for H parallel SSMs to maximize combined spectral coverage

- **Critical path**: Initialize eigenvalues using Eq. 10 (single SSM) or Eq. 11 (layer-wise) -> Forward pass computes convolution kernel K via Vandermonde multiplication -> Learnable ξ (and optionally C, B) updates through backpropagation -> Monitor H∞-norm per SSM to identify active vs. dormant modes

- **Design tradeoffs**: Full vs. half-plane initialization (half-plane reduces state dimension by 2× for real inputs but constrains flexibility); Random Δ sampling (baseline) vs. uniform grid (DFouT) (baseline hedges against unknown timescales but risks aliasing; DFouT guarantees coverage but may waste modes); Synchronized vs. independent SSM initialization (synchronization maximizes coverage but reduces per-SSM autonomy)

- **Failure signatures**: Collapsed spectral coverage (if Δ is too small in baseline methods, all poles cluster near low frequencies); Aliasing artifacts (if Δ is too large, modes fold onto each other); Dormant SSMs (large portions of deeper layers show near-zero H∞-norm); Local attention bias (on serialized images, kernels peak at row-stride intervals rather than capturing global structure)

- **First 3 experiments**: Continuous copying task (Section 5.1) -> Train single SSM (N=1024) on delay-1000 task with varying Δ. Verify S4D-Lin fails when Δ ≠ 2/τ while S4D-DFouT succeeds across all Δ; sCIFAR with truncated kernels (Section 5.2) -> Train model while progressively reducing kernel length. Confirm performance is maintained down to 32 coefficients, revealing local bias; LRA PathX-128 ablation (Section 5.3, Figure 6) -> Compare S4D-Lin, S4D-Inv, and S4D-DFouT across varying Δ_max/ξ_max ranges. Verify DFouT's reduced sensitivity to hyperparameter selection

## Open Questions the Paper Calls Out

### Open Question 1
Does the S4D-DFouT initialization scheme improve the efficiency and performance of diagonal State Space Models in Large Language Model (LLM) architectures? The authors explicitly state they did not explore their proposed initialization in the context of textual data and LLMs, which they leave for future study.

### Open Question 2
Why does the uniform spectral coverage of S4D-DFouT fail to enhance performance on tasks with permuted inputs like psCIFAR, where it achieves only 65.7% accuracy? The paper notes a limitation where the proposed initialization did not help in solving the more challenging problem of permuted psCIFAR.

### Open Question 3
How can the Long Range Arena (LRA) benchmark be redesigned to prevent models from exploiting local inductive biases or specific frequency alignments? The authors conclude that the intrinsic difficulty of LRA tasks may be overestimated and argue for new benchmarks that cannot be circumvented through the presented learning biases.

## Limitations
- The paper focuses exclusively on diagonal SSMs, leaving open questions about how these initialization insights might transfer to full-rank or kernel-based variants
- The synchronized initialization approach assumes that feature dimensions benefit from shared spectral coverage, which may not hold for all data modalities
- The reliance on specific hyperparameter ranges (ξ ∈ [0.001, 0.1]) suggests the method may have limited robustness outside these bounds

## Confidence

- **High**: The observation that continuous-time discretization entangles decay and frequency parameters is mathematically sound and directly supported by the ZOH discretization formula
- **Medium**: The claim that uniform spectral coverage is universally beneficial assumes that task-relevant frequencies are unknown a priori
- **Low**: The assertion that layer-wise synchronization "prevents multiple machines from competing" lacks quantitative analysis showing this competition actually occurs in baseline methods

## Next Checks

1. Conduct controlled ablation studies on PathX-128 and PathX-256 varying only the initialization scheme (S4D-Lin vs S4D-DFouT) while keeping all other architectural and training parameters fixed to isolate the initialization effect

2. Analyze the learned pole distributions after training for different initialization methods to verify that S4D-DFouT maintains more uniform spectral coverage throughout training compared to baselines

3. Test the method's sensitivity to the ξ initialization range by systematically varying the bounds and measuring performance degradation to establish the robustness limits of the proposed approach