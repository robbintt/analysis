---
ver: rpa2
title: 'From Text to Trajectories: GPT-2 as an ODE Solver via In-Context'
arxiv_id: '2508.03031'
source_url: https://arxiv.org/abs/2508.03031
tags:
- gpt-2
- learning
- error
- in-context
- slope
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that GPT-2 models can learn to solve ordinary
  differential equations (ODEs) through in-context learning by encoding ODEs and their
  solutions as sequential prompts. Experiments show GPT-2 achieves exponential accuracy
  gains with increasing context length, with convergence rates comparable to or better
  than classical Euler methods.
---

# From Text to Trajectories: GPT-2 as an ODE Solver via In-Context

## Quick Facts
- arXiv ID: 2508.03031
- Source URL: https://arxiv.org/abs/2508.03031
- Authors: Ziyang Ma; Baojian Zhou; Deqing Yang; Yanghua Xiao
- Reference count: 40
- Primary result: GPT-2 models achieve exponential accuracy gains with increasing context length when solving ODEs via in-context learning

## Executive Summary
This paper demonstrates that GPT-2 models can learn to solve ordinary differential equations (ODEs) through in-context learning by encoding ODEs and their solutions as sequential prompts. Experiments show GPT-2 achieves exponential accuracy gains with increasing context length, with convergence rates comparable to or better than classical Euler methods. The model generalizes to out-of-distribution problems and maintains stability across parameter distribution shifts, with deeper architectures showing stronger extrapolation capabilities. The study suggests Transformer-based models may serve as universal numerical solvers beyond traditional NLP tasks, though limitations remain in high-precision scenarios.

## Method Summary
The approach encodes ODE parameters and solutions as sequential prompts for GPT-2, treating the model as a "meta-ODE solver" that learns differential dynamics through in-context learning. Each input sequence contains ODE parameters, evaluation times, and discrete solution steps, while the output is the trajectory prediction. The model is trained using sliced-MSE loss with curriculum learning that progressively increases context length and dimension. Training uses GPT-2 variants (12 or 24 layers) with AdamW optimization and a three-phase learning rate schedule. The framework demonstrates exponential convergence with context length and maintains stability in stiff ODE regions where classical explicit methods fail.

## Key Results
- GPT-2 achieves exponential accuracy gains with increasing context length, with convergence rates comparable to or better than classical Euler methods
- Deeper architectures (24-layer) show stronger extrapolation capabilities on out-of-distribution parameter distributions
- Neural solvers maintain stability in stiff ODE regions where explicit Euler methods fail
- Model generalizes to out-of-distribution problems with moderate parameter shifts

## Why This Works (Mechanism)

### Mechanism 1
The Transformer learns a mapping from parameterized initial conditions to trajectory steps, functioning as a "meta-ODE solver" rather than merely pattern matching. The model processes input sequences containing ODE parameters and outputs solution points, with attention inferring underlying differential dynamics to predict the next step. This works because ODE solution dynamics can be represented as a learnable function class within the Transformer's parametric capacity.

### Mechanism 2
The architecture achieves exponential convergence rates by utilizing the full history of the trajectory through self-attention, effectively implementing an implicit variable-step solver. Unlike classical Euler methods that rely on fixed-step local updates, the global context from attention allows adaptive refinement of predictions as context length increases, achieving error decay faster than linear methods.

### Mechanism 3
Deeper architectures improve out-of-distribution generalization by learning more robust representations of the parameter space. Deeper layers allow the model to disentangle complex nonlinear interactions between parameters, enabling stability when parameters shift beyond the training range.

## Foundational Learning

- **Concept**: Initial Value Problems (IVPs)
  - **Why needed here**: The paper frames ODE solving specifically as IVPs requiring both differential equation parameters and initial values
  - **Quick check question**: Can you explain why an ODE solver needs both the differential equation parameters and the initial value to generate a trajectory?

- **Concept**: In-Context Learning (ICL)
  - **Why needed here**: This is the core capability being tested - distinguishing between learning weights and learning from context
  - **Quick check question**: If you feed a model a sequence of (x, y) pairs at inference time without backpropagation, what mechanism allows it to predict y for a new x?

- **Concept**: Euler Methods (Explicit vs. Implicit)
  - **Why needed here**: The paper benchmarks GPT-2 against these classical numerical methods, requiring understanding of their error bounds
  - **Quick check question**: Why does the explicit Euler method struggle with "stiff" differential equations compared to implicit methods or the adaptive approach suggested for Transformers?

## Architecture Onboarding

- **Component map**: Data Generation -> Serialization -> Curriculum Training -> GPT-2 Backbone -> Sliced-MSE Loss
- **Critical path**: 1) Generate synthetic ODE instances using solve_ivp, 2) Flatten parameters and solution steps into 1D sequence, 3) Train GPT-2 using sliced-MSE with curriculum schedule
- **Design tradeoffs**: Depth vs. Generalization (24L better OOD but diminishing returns), Precision vs. Stability (neural solvers stable but lose high-precision capabilities)
- **Failure signatures**: Precision ceiling around 10^-3, slope volatility under large parameter shifts, model fails to capture logical parameter relationships
- **First 3 experiments**: 1) Baseline reproduction with 12L GPT-2 on Simple-IVP verifying exponential slope, 2) Ablation on depth comparing 12L vs 24L on First-Order Linear ODEs, 3) Stiffness test comparing GPT-2 stability against Implicit Euler

## Open Questions the Paper Calls Out

- Can the conjectured exponential convergence rate of Transformers solving ODEs be formally proven?
- How do specific architectural components like positional encoding and attention masking impact numerical solving capabilities?
- Do larger or more modern Transformer architectures exhibit improved ODE solving performance or better high-precision stability compared to GPT-2?

## Limitations
- Neural solver achieves relative errors around 10^-3, orders of magnitude worse than classical solvers reaching 10^-8 machine precision
- Exponential convergence claim lacks rigorous proofs explaining why Transformers achieve this rate
- OOD performance degrades with extreme parameter shifts, limiting extrapolation beyond moderate distribution shifts

## Confidence

**High Confidence**:
- GPT-2 can learn to solve first-order linear ODEs through in-context learning
- Exponential error reduction with increasing context length is reproducible
- Deeper architectures show improved OOD generalization over shallower ones
- Neural solvers maintain stability in stiff ODE regions where explicit Euler fails

**Medium Confidence**:
- Convergence rates are "comparable to or better than" classical methods for stability but not final precision
- The model functions as a "meta-ODE solver" rather than pattern matching
- Depth improves generalization patterns with diminishing returns

**Low Confidence**:
- Transformers may serve as "universal numerical solvers" beyond NLP - overgeneralization from limited ODE class
- Specific convergence rate of O(e^-kN) with claimed slope values lacks theoretical justification
- Attention enables "adaptive" solving strategies without mechanistic proof

## Next Checks

1. **Rigorous Convergence Analysis**: Implement formal error bounds for the Transformer-based solver and prove whether exponential convergence O(e^-kN) holds under specific conditions, comparing against theoretical bounds for classical methods.

2. **Precision-Accuracy Tradeoff Quantification**: Systematically measure the stability-accuracy frontier by testing on increasingly stiff ODEs, quantifying exactly where neural solvers outperform classical methods and where they fail to match precision requirements.

3. **Attention Mechanism Dissection**: Analyze attention weight patterns during inference to verify whether the model truly implements adaptive step strategies or simply memorizes trajectory patterns, using techniques like attention visualization and ablations.