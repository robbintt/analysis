---
ver: rpa2
title: Training Flow Matching Models with Reliable Labels via Self-Purification
arxiv_id: '2509.19091'
source_url: https://arxiv.org/abs/2509.19091
tags:
- spfm
- training
- conditional
- data
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Self-Purifying Flow Matching (SPFM), a method
  to improve the quality of training datasets for conditional generative models by
  automatically identifying and filtering unreliable samples. The approach uses the
  difference between conditional and unconditional flow-matching losses to detect
  mislabeled or noisy data, allowing the model to train more robustly without relying
  on external modules or pretrained networks.
---

# Training Flow Matching Models with Reliable Labels via Self-Purification

## Quick Facts
- **arXiv ID:** 2509.19091
- **Source URL:** https://arxiv.org/abs/2509.19091
- **Authors:** Hyeongju Kim; Yechan Yu; June Young Yi; Juheon Lee
- **Reference count:** 0
- **Primary Result:** SPFM improves training robustness by identifying and filtering unreliable samples, achieving state-of-the-art TTS performance with 6.86% WER on TITW-Hard.

## Executive Summary
This paper introduces Self-Purifying Flow Matching (SPFM), a method to improve the quality of training datasets for conditional generative models by automatically identifying and filtering unreliable samples. The approach uses the difference between conditional and unconditional flow-matching losses to detect mislabeled or noisy data, allowing the model to train more robustly without relying on external modules or pretrained networks. Evaluated on synthetic 2D datasets with noisy labels and the real-world TITW text-to-speech dataset, SPFM consistently improved performance, reducing word error rates and enhancing speech quality. On TITW, it established a new state-of-the-art, notably decreasing WER from 7.60% to 6.86% on the challenging TITW-Hard split, while also increasing perceptual quality metrics.

## Method Summary
SPFM works by comparing the conditional flow-matching loss to the unconditional loss during training. After a warm-up period, if the conditional loss exceeds the unconditional loss for a sample, the method flags the condition as potentially unreliable and switches that sample's training objective from conditional to unconditional. This prevents the model from learning incorrect label-to-data mappings while still utilizing the sample for learning the data distribution. The method uses classifier-free guidance and evaluates the loss differential at an interpolation time of t'=0.5, which the paper identifies as the most discriminative point.

## Key Results
- On synthetic 2D datasets with 40% label noise, SPFM successfully recovered clean data distributions while baseline models produced corrupted outputs.
- On the TITW TTS dataset, SPFM reduced WER from 7.60% to 6.86% on the TITW-Hard split, establishing a new state-of-the-art.
- SPFM increased perceptual quality metrics (UTMOS, DNSMOS) compared to baseline models.
- The method worked without requiring external modules, pretrained models, or manual data filtering.

## Why This Works (Mechanism)

### Mechanism 1: Loss Differential as a Noisy Label Proxy
- **Claim:** If the conditional flow-matching loss exceeds the unconditional loss ($L_{cond} > L_{uncond}$), the associated label is likely mislabeled or unreliable.
- **Mechanism:** In Flow Matching, a correct condition $c$ typically provides disambiguating signal, lowering the velocity prediction error compared to a blind (unconditional) guess. If the condition is wrong, it acts as adversarial noise, increasing error relative to the unconditional baseline. Comparing these losses effectively isolates samples where the label hurts rather than helps prediction.
- **Core assumption:** A correctly labeled sample will consistently have lower conditional loss than unconditional loss after an initial warm-up period.

### Mechanism 2: Dynamic Mode Switching (Self-Purification)
- **Claim:** Switching the training objective for suspicious samples from conditional to unconditional prevents the model from overfitting to incorrect label-to-data mappings without discarding the data sample entirely.
- **Mechanism:** Instead of removing a sample $(x_1, c)$ when $c$ is flagged as unreliable, the method trains on $x_1$ using only the unconditional objective $L_{uncond}$. This retains the sample's contribution to modeling the data distribution $p(x)$ while preventing the corruption of the conditional distribution $p(x|c)$.

### Mechanism 3: Mid-Point Interpolation Discrimination
- **Claim:** Evaluating the loss differential at a specific interpolation time ($t'=0.5$) provides the most robust signal for distinguishing correct vs. incorrect labels.
- **Mechanism:** At low $t'$ (near noise), signals are weak; at high $t'$ (near data), the model relies less on the condition. At $t' \approx 0.5$, the model maximally leverages the condition to denoise, making the error gap between a helpful condition and a harmful one most distinct.

## Foundational Learning

- **Concept: Flow Matching (FM) / Conditional Vector Fields**
  - **Why needed here:** SPFM is built specifically for Flow Matching. Understanding that FM learns a vector field $v$ to transport noise to data is required to interpret the "velocity prediction loss" used for purification.
  - **Quick check question:** Can you explain why minimizing the difference between the model-predicted velocity and the data-to-noise difference $(x_1 - x_0)$ defines the training objective?

- **Concept: Classifier-Free Guidance (CFG)**
  - **Why needed here:** SPFM requires an unconditional path to exist for comparison. Understanding that models are trained with a probability of dropping the condition ($c \to \emptyset$) is essential to grasp where $L_{uncond}$ comes from.
  - **Quick check question:** In standard CFG, how is the unconditional vector field $v_\theta(x_t, t, \emptyset)$ used during inference, and how does SPFM repurpose it during training?

- **Concept: Label Noise Robustness**
  - **Why needed here:** Contextualizes why simply training on all data is insufficient. SPFM assumes the model will initially fit clean data faster than noisy data (Early Learning phenomenon), enabling the loss gap to appear.
  - **Quick check question:** Why might a neural network initially fit correctly labeled samples before memorizing mislabeled ones?

## Architecture Onboarding

- **Component map:** Base Model -> Dual-Head Forward Pass -> Purification Gate -> Optimizer
- **Critical path:**
  1. **Warm-up:** Train standard FM for $N$ iterations (e.g., 40k) to stabilize losses.
  2. **Purification Step:**
     - Sample batch.
     - Forward pass with $c$ and $\emptyset$.
     - Compute $L_{cond}$ and $L_{uncond}$ at $t'=0.5$.
     - **Decision:** If $L_{cond} > L_{uncond}$, reject $c$ and backprop only $L_{uncond}$ for that sample.
  3. **Optimization:** Update weights using the selected loss.

- **Design tradeoffs:**
  - **Warm-up duration:** Too short leads to false positives (flagging good data); too long risks overfitting to bad labels before purification starts.
  - **Static Threshold:** The paper uses a binary threshold ($>$). This is simpler but may be less robust than a percentile-based or margin-based threshold.

- **Failure signatures:**
  - **Model ignoring condition:** If the threshold is too aggressive or warm-up too short, almost all data becomes unconditional.
  - **Degraded performance on clean data:** Indicates that valid samples are being flagged as noisy (False Positives).
  - **No reduction in WER/Classification Error:** Suggests the loss differential at $t'=0.5$ is not discriminative for the specific data modality.

- **First 3 experiments:**
  1. **Synthetic Validation:** Replicate the 2D spiral/two-circle experiment with 40% label noise to visualize if SPFM recovers the distinct shapes.
  2. **Hyperparameter Sweep ($t'$):** Test $t' \in \{0.1, 0.3, 0.5, 0.7, 0.9\}$ on a held-out validation set to confirm 0.5 is the optimal discrimination point for your specific data (as per Section 6.4).
  3. **Ablation on Warm-up:** Compare performance activating SPFM at 10% vs 25% vs 50% of total training steps to find the stability point where the loss gap becomes meaningful.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can adaptive thresholds or evaluation across multiple timesteps improve the detection accuracy of unreliable labels compared to the fixed criterion ($L_{cond} - L_{uncond} > 0$) at $t'=0.5$?
- **Basis in paper:** Section 7 (Limitations) states that exploring alternative approaches such as adaptive thresholds or evaluation across multiple timesteps could improve performance but was beyond the scope of the paper.
- **Why unresolved:** The current method relies on a manually selected interpolation time and a binary threshold, which may not be optimal for all data distributions.
- **What evidence would resolve it:** Ablation studies comparing the fixed $t'=0.5$ strategy against methods utilizing multi-timestep aggregation or learned adaptive thresholds on the TITW dataset.

### Open Question 2
- **Question:** How does SPFM generalize to high-dimensional modalities outside of speech synthesis, such as image or video generation?
- **Basis in paper:** Section 7 notes that experiments primarily focused on TTS, and evaluating performance on a broader range of real-world datasets is necessary to understand generalization capabilities.
- **Why unresolved:** The method has only been validated on 2D synthetic data and the specific audio domain of the TITW dataset.
- **What evidence would resolve it:** Application of SPFM to standard image synthesis benchmarks (e.g., CIFAR-10 or ImageNet with synthetic label noise) demonstrating comparable purification performance.

### Open Question 3
- **Question:** At what noise ratio does the self-purification mechanism fail to converge?
- **Basis in paper:** The synthetic experiments utilized a fixed 40% noise ratio; the paper does not establish the upper bound of noise the model can tolerate before the loss difference signal becomes indistinguishable.
- **Why unresolved:** It is unclear if the "self-purifying" signal remains reliable when the dataset is dominated by mislabeled samples (e.g., >60% noise).
- **What evidence would resolve it:** Experiments on synthetic datasets with incrementally increasing noise ratios to identify the breaking point of the purification logic.

## Limitations
- The method's performance on non-speech conditional generation tasks (e.g., image-to-image translation) is not demonstrated.
- The paper does not explore failure modes for datasets with >60% label noise, where unconditional training might dominate and dilute conditional specificity.
- The choice of t'=0.5 is presented as optimal but lacks theoretical justification for why this specific interpolation point is universally best.

## Confidence
- **High:** The synthetic 2D experiments clearly validate the core mechanism (loss differential at t'=0.5 discriminates clean from corrupted labels).
- **Medium:** The TITW TTS results are compelling but depend on external architectural details and may not generalize to other conditional generation tasks.
- **Medium:** The claim that SPFM works "without additional modules or pretrained models" is accurate, but the method still requires careful hyperparameter tuning (warm-up duration, t' value).

## Next Checks
1. **Noise Robustness Boundary:** Systematically evaluate SPFM on synthetic datasets with 20%, 40%, 60%, and 80% label noise to identify the failure threshold where unconditional training dominates.
2. **Cross-Domain Generalization:** Apply SPFM to a different conditional generation task (e.g., text-to-image or image segmentation) with known label noise to test whether the t'=0.5 heuristic transfers.
3. **Theoretical Analysis of t' Selection:** Investigate whether the optimal t' value correlates with specific properties of the flow-matching vector field (e.g., magnitude of velocity, curvature of trajectories) rather than being a fixed hyperparameter.