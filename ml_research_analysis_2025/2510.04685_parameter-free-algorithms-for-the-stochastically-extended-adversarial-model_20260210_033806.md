---
ver: rpa2
title: Parameter-free Algorithms for the Stochastically Extended Adversarial Model
arxiv_id: '2510.04685'
source_url: https://arxiv.org/abs/2510.04685
tags:
- algorithm
- regret
- online
- have
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops the first parameter-free algorithms for the
  Stochastically Extended Adversarial (SEA) model, which bridges adversarial and stochastic
  online convex optimization. The key challenge addressed is that existing SEA algorithms
  require prior knowledge of domain diameter D and Lipschitz constant G, limiting
  their practical applicability.
---

# Parameter-free Algorithms for the Stochastically Extended Adversarial Model

## Quick Facts
- arXiv ID: 2510.04685
- Source URL: https://arxiv.org/abs/2510.04685
- Authors: Shuche Wang; Adarsh Barik; Peng Zhao; Vincent Y. F. Tan
- Reference count: 40
- Primary result: First parameter-free algorithms for the Stochastically Extended Adversarial model, achieving comparator-adaptive regret bounds without prior knowledge of domain diameter or Lipschitz constant

## Executive Summary
This paper develops the first parameter-free algorithms for the Stochastically Extended Adversarial (SEA) model, which bridges adversarial and stochastic online convex optimization. The key challenge addressed is that existing SEA algorithms require prior knowledge of domain diameter D and Lipschitz constant G, limiting their practical applicability. The authors leverage Optimistic Online Newton Step (OONS) as a base algorithm and develop two parameter-free methods: CA-OONS for unknown D (but known G) and CLA-OONS for both D and G unknown.

## Method Summary
The paper introduces three main algorithms. First, OONS serves as the base algorithm with adaptive second-order updates using matrix A_t that captures gradient variation. Second, CA-OONS uses a multi-scale expert ensemble (MsMwC) framework with N = ⌈log T⌉ base learners operating at geometrically increasing domain scales, achieving comparator-adaptive regret. Third, CLA-OONS extends CA-OONS by adding gradient clipping and adaptive domain estimation to handle unknown Lipschitz constants, using truncated gradients and doubling-based domain estimates.

## Key Results
1. CA-OONS (unknown D, known G): E[R_T(u)] = Õ(∥u∥₂² + ∥u∥₂(√σ²₁:ₜ + √Σ²₁:ₜ)), achieving comparator-adaptivity
2. CLA-OONS (both D and G unknown): E[R_T(u)] ≤ Õ(∥u∥₂²(√σ²₁:ₜ + √Σ²₁:ₜ) + G²∥u∥₂² + ∥u∥₄² + G∥u∥₃²/₂ + G²√σ₁:ₜ + G₁:ₜ)
3. Both algorithms maintain effectiveness without requiring prior knowledge of problem parameters while achieving regret bounds that depend on problem-specific quantities σ²₁:ₜ (cumulative stochastic variance) and Σ²₁:ₜ (cumulative adversarial variation)

## Why This Works (Mechanism)

### Mechanism 1: Optimistic Online Newton Step with Adaptive Second-Order Updates
- Claim: OONS achieves σ²_{1:T} and Σ²_{1:T}-dependent regret bounds without fixed step-size tuning by leveraging accumulated gradient covariance information.
- Mechanism: Maintains matrix A_t = 4z₁²I + Σᵢ₌₁ᵗ⁻¹ ηᵢ(∇ᵢ - mᵢ)(∇ᵢ - mᵢ)ᵀ + 4η_t z_t²I that captures the geometry of observed gradient variations. The optimistic prediction m_t = ∇f_{t-1}(x_{t-1}) provides a hint about the next gradient, enabling the regret bound to include a negative stability term -z₁² Σ||x_t - x_{t-1}||²₂ that cancels movement costs. Adaptive step-size η_t = min{1/(64Dz_T), 1/D·√(Σ||g_s - m_s||²₂)} adjusts to observed variation.
- Core assumption: Expected functions F_t are L-smooth (Assumption 2.3) and convex (Assumption 2.4); bounded gradient norms for the known-G case.
- Evidence anchors:
  - [abstract]: "leveraging the Optimistic Online Newton Step (OONS) algorithm to eliminate the need for these parameters"
  - [Section 3, Theorem 3.1]: Provides the RVU-style bound with negative stability term -z₁² Σ||x_t - x_{t-1}||²₂
  - [corpus]: Limited direct corpus evidence for OONS-SEA combination; related work on ONS exists (Hazan et al. 2007 cited)
- Break condition: If accumulated gradient matrix A_t becomes ill-conditioned or if gradient norms exceed z_t bounds consistently, the O(√ln(Tη₁z_T/z₁)/η_T) term dominates.

### Mechanism 2: Multi-Scale Expert Ensemble with Correction Terms
- Claim: A hierarchical ensemble of base learners operating at geometrically increasing domain scales can achieve comparator-adaptive regret without knowing the domain diameter D.
- Mechanism: Creates N = ⌈log T⌉ base learners, each constrained to X_j = {x : ||x||₂ ≤ D_j = 2ʲ}. The meta-algorithm MsMwC uses entropy regularizer with correction terms a_t,j = 32β_{t,j}(ℓ^t_j - h^t_j)² that provide the RVU property at the meta level. The three-layer structure (meta-top → meta-middle → base) ensures that the appropriate scale learner receives most weight. For any comparator u, let i be the smallest index with ||u||₂ ≤ D_i ≤ 2||u||₂; the regret then scales as Õ(||u||²₂ + ||u||₂(√σ² + √Σ²)).
- Core assumption: Known Lipschitz constant G; loss ranges |ℓ^t_j| ≤ GD_j bounded per-expert.
- Evidence anchors:
  - [abstract]: "comparator-adaptive algorithm... achieving an expected regret bound of Õ(||u||₂² + ||u||₂(√σ² + √Σ²))"
  - [Section 4.1, Lemma D.1]: Shows meta-regret bound of O(D_iΓᵢ + √(Γᵢ Σ(ℓ^t_i - h^t_i)²))
  - [corpus]: Chen et al. [10] MsMwC algorithm has 68 citations; foundational for multi-scale learning
- Break condition: If ||u||₂ > D_max = 2^N, the linear fallback bound 2G||u||₂² applies, degrading performance for very large comparators.

### Mechanism 3: Gradient Clipping with Adaptive Domain Estimation
- Claim: Truncated gradients and doubling-based domain estimates enable fully parameter-free operation when both D and G are unknown.
- Mechanism: Maintains running gradient norm bound B_t = max_{s≤t} ||g_s - m_s||₂. Constructs truncated gradient ĝ_t = m_t + (B_{t-1}/B_t)(g_t - m_t) satisfying ||ĝ_t - m_t||₂ ≤ B_{t-1}, providing the prescient "hint" the algorithm needs. Domain estimate D_t doubles when D_t < √(Σᵢ₌₁ᵗ ||g_s||²₂ / max_{k≤s} ||g_k||₂), ensuring at most O(log T) resets. The split into M intervals allows independent OONS runs per interval with appropriate local bounds.
- Core assumption: The doubling condition eventually stabilizes; gradients don't grow faster than exponentially in log T.
- Evidence anchors:
  - [Section 4.2]: "A simple approach to handling the unknown gradient norms... relies on a gradient-clipping reduction"
  - [Theorem 4.5]: Regret bound Õ(||u||₂²(√σ² + √Σ²) + G²||u||₂² + ||u||₂⁴ + √σ_{1:T} + G_{1:T})
  - [corpus]: Cutkosky [25] gradient-clipping reduction cited; corpus shows related parameter-free work by Cutkosky & Orabona
- Break condition: The additional terms G²||u||₂² + ||u||₂⁴ + G||u||₂^{3/2} in CLA-OONS (vs. just ||u||₂² in CA-OONS) indicate degradation when comparator norm is large and Lipschitz constant unknown.

## Foundational Learning

- Concept: **Expected Regret in the SEA Model**
  - Why needed here: The paper optimizes E[R_T(u)] = E[Σ(f_t(x_t) - f_t(u))] where expectation is over stochastic loss sampling. Unlike standard OCO with deterministic losses, SEA randomness requires understanding conditional variance σ²_t = sup_x E[||∇f_t(x) - ∇F_t(x)||²₂] and adversarial variation Σ²_t = sup_x ||∇F_t(x) - ∇F_{t-1}(x)||²₂.
  - Quick check question: Why does the SEA model use expected regret rather than high-probability regret, and what does σ²_{1:T} = T/n vs. êσ²_{1:T} ≥ (1-e^{-1})T (Proposition A.1) tell us about variance measure selection?

- Concept: **RVU Property and Negative Stability Terms**
  - Why needed here: The Regret Bounded by Variation in Utilities (RVU) property—regret of form α + βΣ||u_t - u_{t-1}||² - γΣ||x_t - x_{t-1}||²—is central to achieving σ²_{1:T}-scaling. The negative term -γΣ||x_t - x_{t-1}||² cancels the L²Σ||x_t - x_{t-1}||² term from smoothness analysis (Lemma C.5), which is why OONS succeeds where OMD fails for unbounded domains.
  - Quick check question: Trace how the negative stability term in Theorem 3.1 cancels the movement cost term 2LD√(Σ||x_t - x_{t-1}||²₂) that appears when bounding gradient variation.

- Concept: **Bregman Divergence with Adaptive Regularizer**
  - Why needed here: OONS uses ψ_t(x) = ½||x||²_{A_t} where A_t evolves based on observed gradients. The Bregman divergence D_{ψ_t}(x, y) = ψ_t(x) - ψ_t(y) - ⟨∇ψ_t(y), x - y⟩ defines the proximal geometry. Lemma C.1 (Bregman Proximal Inequality) is the workhorse for regret decomposition, giving ⟨g_t, x_{t+1} - u⟩ ≤ D_ψ(u, x_t) - D_ψ(u, x_{t+1}) - D_ψ(x_t, x_{t+1}).
  - Quick check question: Why does using A_t (rather than fixed identity matrix I) allow removing explicit D-dependence from the regret bound?

## Architecture Onboarding

- Component map:
  Top Layer: MsMwC-Master (Algorithm 3)
    └── Expert set S = {k : ∃j, GD_j ≤ 2^{k-2} ≤ GD_j√T}
    └── Step-sizes β_k = 1/(32·2^k)
    └── Manages p_t ∈ Δ_S (distribution over experts)
  
  Middle Layer: MsMwC per expert k ∈ S
    └── Operates on subset Z_k = {j : GD_j ≤ 2^{k-2}}
    └── Produces w^k_t ∈ Δ_N (weights over base learners)
    └── Final output: w_t = Σ_k p_{t,k} w^k_t
  
  Base Layer: N = ⌈log T⌉ OONS instances
    └── Domain constraint ||x||₂ ≤ D_j = 2^j
    └── Adaptive step-size η^j_t per (6)
    └── Matrix A_t update via outer products
  
  Gradient Processor (CLA-OONS only):
    └── B_t = max_{s≤t} ||g_s - m_s||₂
    └── Clipped gradient ĝ_t = m_t + (B_{t-1}/B_t)(g_t - m_t)
    └── Domain doubling check and reset

- Critical path:
  1. Per-round compute: g_t = ∇f_t(x_t) → m_t = g_{t-1} → A_t update → argmin solve → weight aggregation
  2. Matrix inversion bottleneck: Sherman-Morrison-Woodbury reduces O(d³) to O(d²) per step
  3. Memory: O(d²) for A_t, O(Nd) for base learner states, O(|S|·N) for meta state

- Design tradeoffs:
  - Bound tightness vs. generality: CA-OONS achieves cleaner Õ(||u||₂² + ||u||₂√(σ²+Σ²)) but needs G; CLA-OONS handles both unknown but adds ||u||₂⁴, G||u||₂^{3/2}, √σ_{1:T} + G_{1:T} terms
  - Expert count vs. gradient queries: N = ⌈log T⌉ experts require O(log T) gradient evaluations per round; reducing to O(1) is noted as future work
  - Second-order vs. first-order: OONS uses O(d²) memory/time; sketching or sparsity exploitation needed for high dimensions

- Failure signatures:
  - Unbounded comparator: If ||u||₂ >> D_max, regret degrades to O(G||u||₂²) rather than O(||u||₂√(σ²+Σ²))
  - Non-smooth expected functions: The L-smoothness assumption (2.3) is required for Lemma C.5 decomposition; non-smooth case breaks the RVU cancellation
  - Numerical overflow in A_t: If η_t z_t² grows large, matrix entries overflow; need careful normalization

- First 3 experiments:
  1. Controlled SEA variance study: Construct synthetic problem with tunable σ²_{1:T} and Σ²_{1:T}. Sample f_t = F_t + ξ_t where F_t varies adversarially with controlled Σ² and ξ_t is zero-mean noise with variance σ². Verify E[R_T]/(||u||₂√(σ²+Σ²)) → constant.
  2. Expert count ablation: Run CA-OONS with N ∈ {1, 3, 5, 7, ⌈log T⌉} on a problem with ||u||₂ = 2^5. Plot regret vs. N to confirm N needs to exceed log₂(||u||₂) for optimal performance, and validate the 2G||u||₂² fallback for N < log₂(||u||₂).
  3. Dimensional scaling benchmark: Implement O(d²) Sherman-Morrison-Woodbury updates vs. naive O(d³) matrix inversion in dimensions d ∈ {50, 100, 200, 500, 1000}. Measure wall-clock time and verify log|A_T| computation doesn't overflow for T = 10^4 rounds.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the regret dependence on the comparator norm be improved from $\tilde{O}(\|u\|_2^2)$ to $\tilde{O}(\|u\|_2)$ in the setting where both domain diameter $D$ and Lipschitz constant $G$ are unknown?
- **Basis in paper:** [explicit] Section 5 states, "we would like to improve the regret's dependence on $\|u\|_2$ when both D and G are unknown."
- **Why unresolved:** The current CLA-OONS algorithm achieves $\tilde{O}(\|u\|_2^2(\sqrt{\sigma^2_{1:T}} + \sqrt{\Sigma^2_{1:T}}))$. Achieving $\tilde{O}(\|u\|_2)$ is challenging because utilizing the negative stability term in the RVU property is difficult when the domain is potentially unbounded.
- **What evidence would resolve it:** A new parameter-free algorithm for the SEA model that achieves a regret bound linear in $\|u\|_2$ without knowledge of $D$ or $G$, or a lower bound proof establishing the necessity of the quadratic dependence.

### Open Question 2
- **Question:** Is it possible to reduce the gradient query complexity of the comparator-adaptive algorithm (CA-OONS) from $O(\log T)$ to $O(1)$ per round?
- **Basis in paper:** [explicit] Section 5 lists as a future direction: "reduce the number of gradient queries in CA-OONS from O(log T) to O(1), thus enhancing its efficiency."
- **Why unresolved:** The current meta-algorithm requires maintaining $N = \lceil \log T \rceil$ base learners, necessitating a gradient query for each base learner to update its state, which creates a logarithmic overhead in computational cost.
- **What evidence would resolve it:** A modified meta-learning framework or algorithm that aggregates base learners in a manner that requires only a single gradient calculation per iteration while maintaining the same regret guarantees.

### Open Question 3
- **Question:** Can high-probability (or variance-sensitive) regret guarantees be derived for the parameter-free SEA model?
- **Basis in paper:** [explicit] Section 5 notes, "An additional open direction is to move beyond expected regret and derive high-probability... guarantees for the SEA model in the parameter-free setting."
- **Why unresolved:** Current analyses focus on expected regret $E[R_T(u)]$. Deriving concentration results that retain the fine-grained dependence on $\sigma^2_{1:T}$ and $\Sigma^2_{1:T}$ without incurring suboptimal logarithmic inflation appears non-trivial.
- **What evidence would resolve it:** A theoretical analysis providing a bound of the form $P(R_T(u) \le B) \ge 1 - \delta$ that holds for the proposed parameter-free algorithms, specifically adapting the variance-like quantities to the high-probability setting.

## Limitations
- The theoretical framework assumes L-smoothness of expected functions and convexity, which may not hold in practice.
- The gradient clipping mechanism in CLA-OONS introduces additional regret terms that could dominate the main regret bound for large comparators.
- The meta-base framework with N = ⌈log T⌉ experts requires O(log T) gradient evaluations per round, which may be computationally prohibitive for real-time applications.

## Confidence
- **High confidence**: The comparator-adaptive regret bound Õ(||u||₂² + ||u||₂(√σ²_{1:T} + √Σ²_{1:T})) for CA-OONS, as it follows established MsMwC framework with proven guarantees.
- **Medium confidence**: The fully parameter-free CLA-OONS regret bound, as it depends on gradient clipping approximations and domain doubling conditions that may not hold tightly in practice.
- **Low confidence**: Practical performance on high-dimensional problems (d > 1000), as the O(d²) per-iteration complexity with Sherman-Morrison-Woodbury updates may become prohibitive and the negative stability terms may not cancel effectively in ill-conditioned settings.

## Next Checks
1. **Empirical variance scaling study**: Implement synthetic SEA problems with controlled σ²_{1:T} and Σ²_{1:T} values. Run CA-OONS and verify that E[R_T]/||u||₂ converges to a constant multiple of √(σ²_{1:T} + Σ²_{1:T}) across different variance regimes.
2. **Gradient clipping sensitivity analysis**: Test CLA-OONS on problems with varying gradient norms (G_t) and compare regret against CA-OONS. Quantify when the additional terms G²||u||₂² + ||u||₂⁴ + G||u||₂^{3/2} + √σ_{1:T} + G_{1:T} dominate the main regret bound.
3. **Dimensional scaling experiment**: Implement OONS with both naive O(d³) matrix inversion and O(d²) Sherman-Morrison-Woodbury updates. Measure wall-clock time and regret quality for d ∈ {50, 100, 200, 500, 1000} over T = 10⁴ rounds to identify practical dimension limits.