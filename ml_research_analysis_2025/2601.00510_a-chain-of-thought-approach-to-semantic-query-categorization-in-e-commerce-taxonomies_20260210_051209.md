---
ver: rpa2
title: A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce
  Taxonomies
arxiv_id: '2601.00510'
source_url: https://arxiv.org/abs/2601.00510
tags:
- query
- category
- categories
- semantic
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses semantic query categorization in e-commerce
  taxonomies, aiming to improve search relevance by mapping user queries to relevant
  leaf categories. The proposed Chain-of-Thought Breadth-First Search (CoT BFS) method
  combines tree search with LLM semantic scoring to navigate hierarchical taxonomies
  and identify semantically aligned categories.
---

# A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies

## Quick Facts
- arXiv ID: 2601.00510
- Source URL: https://arxiv.org/abs/2601.00510
- Reference count: 13
- Outperforms k-NN baseline by +89.8% F1 and +86.1% precision on human-annotated data

## Executive Summary
This paper introduces Chain-of-Thought Breadth-First Search (CoT BFS), a method that uses large language models (LLMs) to map user queries to relevant leaf categories in hierarchical e-commerce taxonomies. The approach navigates taxonomies using semantic scoring at each node, significantly outperforming a k-NN embedding baseline across multiple metrics including F1, precision, recall, and retrieval performance. The method also supports context learning for accessory/complementary intent and enables taxonomy diagnostics by identifying gaps. CoT BFS achieves high accuracy while maintaining efficiency by visiting only 1.7%-24.8% of taxonomy nodes.

## Method Summary
The CoT BFS method maps user queries to leaf categories in hierarchical taxonomies by combining tree search with LLM semantic scoring. Starting from the root, the algorithm performs BFS, scoring all children at each node using an LLM with a Chain-of-Thought prompt that includes the query, current path, and parent/child descriptions. Two thresholds are applied: a selection threshold (9) for choosing top children and a minimum threshold (8) for pruning. Scores are mapped to a standard normal distribution, and children are pruned if they fall below (mean + 0.9Ã—std) AND their original score is below the minimum threshold. The process iterates until reaching leaf nodes, which are then rescored and returned as final predictions. A k-NN baseline uses sentence-BERT embeddings with cosine similarity for comparison.

## Key Results
- +89.8% improvement in F1 score and +86.1% improvement in precision on human-annotated test data
- +109.7% improvement in sample aggregation F1 on human-annotated data and +96.7% on LLM-annotated data
- +72% higher retrieval recall and +34% better relevance scores in retrieval tests
- Efficient: visits only 1.7%-24.8% of taxonomy nodes while maintaining high accuracy

## Why This Works (Mechanism)
The method leverages LLMs' semantic understanding to navigate hierarchical taxonomies through contextual scoring at each node, rather than relying solely on static embeddings. By combining breadth-first search with dual-threshold pruning based on both relative and absolute scores, CoT BFS effectively filters irrelevant branches while maintaining semantic alignment with user intent. The Chain-of-Thought prompting provides context about the current path and category descriptions, enabling the LLM to make more informed scoring decisions. This approach naturally captures semantic relationships and context (e.g., accessory intent) that pure embedding methods miss, while the pruning strategy ensures computational efficiency by limiting node exploration to semantically promising paths.

## Foundational Learning
**E-commerce taxonomy hierarchies**: Tree structures organizing products into categories and subcategories; needed to understand the problem domain and evaluation metrics. Quick check: Verify the taxonomy follows a tree structure with parent-child relationships.
**LLM Chain-of-Thought prompting**: Structured prompts that guide models through reasoning steps; needed for effective semantic scoring at each taxonomy node. Quick check: Confirm the prompt includes query, path context, and category descriptions.
**Breadth-First Search (BFS)**: Tree traversal algorithm exploring all siblings before moving deeper; needed for systematic node exploration. Quick check: Ensure BFS correctly explores all children at each level before descending.
**Semantic scoring with LLMs**: Using LLMs to rate relevance on a numerical scale; needed for navigation decisions. Quick check: Verify LLM outputs are properly mapped to the 1-10 scale.
**Dual-threshold pruning**: Combining relative (z-score based) and absolute thresholds for filtering; needed to balance recall and precision. Quick check: Confirm pruning criteria are correctly applied at each level.
**k-NN with sentence-BERT**: Embedding-based similarity search using pre-trained models; needed as baseline comparison. Quick check: Verify cosine similarity is computed correctly on embeddings.

## Architecture Onboarding

**Component map**: User query -> Taxonomy tree structure -> LLM scoring prompt -> BFS traversal with dual-threshold pruning -> Leaf node collection -> Final rescoring -> Category predictions

**Critical path**: The critical path involves generating the LLM prompt with context, performing BFS traversal with scoring and pruning at each level, and finally rescoring the surviving leaf nodes. The LLM prompt generation and scoring are the most computationally intensive steps.

**Design tradeoffs**: BFS provides better recall and balanced pruning compared to DFS, but may explore more nodes. The dual-threshold pruning balances between strict filtering (high precision) and lenient filtering (high recall). Using LLM scoring provides superior semantic understanding but at higher computational cost compared to embedding-based methods.

**Failure signatures**: Empty predictions occur when no level-1 categories exceed the minimum threshold (observed in 3,110/25,000 queries with stringent thresholds). LLM instruction-following errors occur when models modify category names instead of reproducing exact names (4% failure rate). Poor performance indicates thresholds are too stringent or the taxonomy lacks relevant categories.

**First experiments**: 1) Implement BFS traversal on a small taxonomy with mock scoring to verify node exploration order. 2) Test dual-threshold pruning on a single branch to confirm correct application of both relative and absolute criteria. 3) Compare LLM scoring outputs with embedding-based similarity scores on sample queries to quantify semantic differences.

## Open Questions the Paper Calls Out
**Open Question 1**: How do the proposed scalable hybrid approaches (CoT-k-NN and k-NN-search + LLM) perform in live production environments regarding latency and user engagement? The authors state AB-tests are planned for the scalable methods presented in section 2.3, but these have not yet been validated against business metrics or production constraints.

**Open Question 2**: Can the selection and minimum thresholds be adapted dynamically to maintain performance as query distributions and taxonomies shift over time? The paper notes these hyperparameters need periodic validation but does not propose a mechanism for automatic or continuous adjustment.

**Open Question 3**: Does the absolute-threshold CoT DFS method provide superior taxonomy diagnostics compared to the relative-threshold CoT BFS? The paper briefly references CoT DFS as a variant left out due to space constraints, without providing comparative data on diagnostic utility.

## Limitations
- Evaluation relies on proprietary eBay taxonomy data and internal human judgment annotations that are not publicly available
- The k-NN baseline uses sentence-BERT with cosine similarity, which may not capture the full spectrum of embedding-based approaches
- LLM-based scoring introduces potential biases through prompt engineering choices that are not fully specified

## Confidence
- **High confidence**: CoT BFS achieves significantly better F1, precision, and recall metrics compared to the k-NN baseline on both human-judged and LLM-judged data, and demonstrates improved retrieval recall and relevance scores
- **Medium confidence**: The claim about context learning (identifying accessory/complementary intent) and taxonomy diagnostics is supported by qualitative examples but lacks quantitative validation across diverse taxonomies
- **Low confidence**: The specific prompt engineering details and threshold calibration procedures are not fully specified, making it difficult to reproduce the exact performance without access to the original implementation

## Next Checks
1. Reimplement CoT BFS using an open e-commerce taxonomy (e.g., Amazon product graph subset) and validate the claimed performance improvements against a k-NN baseline with sentence-BERT embeddings
2. Conduct ablation studies to quantify the contribution of each component: (a) the dual-threshold pruning strategy versus single threshold, (b) LLM semantic scoring versus embedding-based similarity, and (c) the breadth-first versus depth-first traversal order
3. Test the method's robustness to different LLM models and prompt variations to establish whether the performance gains are model-dependent or represent a general improvement in query categorization methodology