---
ver: rpa2
title: Explainable Unsupervised Multi-Anomaly Detection and Temporal Localization
  in Nuclear Times Series Data with a Dual Attention-Based Autoencoder
arxiv_id: '2509.12372'
source_url: https://arxiv.org/abs/2509.12372
tags:
- data
- attention
- reactor
- time
- anomaly
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of unsupervised anomaly detection
  and temporal localization in nuclear time-series data from reactor radiation sensors.
  The proposed solution employs a Long Short-Term Memory (LSTM) autoencoder enhanced
  with a dual attention mechanism that operates in both feature and temporal dimensions.
---

# Explainable Unsupervised Multi-Anomaly Detection and Temporal Localization in Nuclear Times Series Data with a Dual Attention-Based Autoencoder

## Quick Facts
- arXiv ID: 2509.12372
- Source URL: https://arxiv.org/abs/2509.12372
- Reference count: 40
- LSTM autoencoder with dual attention achieves 95% accuracy in localizing spike anomalies in nuclear reactor radiation sensor data

## Executive Summary
This study introduces a novel framework for unsupervised anomaly detection and temporal localization in nuclear reactor time-series data using a Long Short-Term Memory (LSTM) autoencoder enhanced with dual attention mechanisms. The approach operates on multivariate radiation sensor readings from the PUR-1 research reactor, identifying anomalous patterns through reconstruction error while simultaneously localizing both the affected sensors and the timing of anomalies. The dual attention mechanism assigns weights to both individual sensors (feature attention) and specific timesteps (temporal attention), enabling precise explainability that is critical for nuclear safety monitoring where root cause identification is essential.

The framework was validated using real-world reactor data augmented with artificial anomalies including sensor drifts, individual spikes, and concurrent overlapping events. The dual attention mechanism successfully identified anomalous sensors and localized anomaly timing within a single unified network, achieving 95% accuracy for spike event localization. This approach addresses a critical gap in nuclear monitoring systems by providing not just anomaly detection but also actionable information about which sensors are affected and when the anomalies occurred, enabling faster diagnosis and response to potential reactor issues.

## Method Summary
The method employs an LSTM autoencoder with dual Bahdanau attention operating on the latent space representation of multivariate time-series data. The architecture processes 20-second sliding windows (advanced by 1-second steps) across 6 radiation sensor features from the PUR-1 reactor. During training, the model learns compressed representations of normal reactor behavior exclusively from operational data spanning 10 power cycles. The feature attention module assigns weights to individual sensors based on their deviation from learned correlations, while temporal attention highlights specific timesteps where anomalies occur. Inference produces both reconstruction error for detection and attention weight matrices for sensor identification and temporal localization, all without requiring labeled anomaly data.

## Key Results
- The dual attention LSTM autoencoder successfully detected and localized anomalies including drifted sensor readings, individual spikes, and concurrent overlapping anomalous events
- Feature attention effectively identified affected sensors by assigning higher weights to radiation sensors exhibiting abnormal patterns
- Temporal attention precisely located anomaly timing by highlighting specific timesteps with lower attention weights, achieving 95% accuracy in spike event localization
- The unified framework provided both detection and localization capabilities within a single network, eliminating the need for separate detection and analysis pipelines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The LSTM autoencoder learns compressed representations of normal reactor behavior that fail to reconstruct anomalous patterns, enabling unsupervised detection without labeled anomalies.
- Mechanism: During training on normal operational data (~50,000 seconds across 10 power cycles), the encoder compresses multivariate sensor sequences into a latent space; the decoder learns to reconstruct only patterns consistent with normal operation. At inference, deviations from learned correlations (e.g., radiation readings inconsistent with reactor power) produce high reconstruction error or attention-weight changes.
- Core assumption: Normal operational data spans the full range of legitimate sensor correlations; anomalies violate these learned relationships in detectable ways.
- Evidence anchors:
  - [abstract] "The framework includes not only detection but also localization of the event and was evaluated using real-world datasets... The network is trained exclusively on normal reactor data collected under various operating conditions."
  - [section III.A] "10 full-power cycle datasets were collected... The purpose of using a large dataset is to allow the algorithm to learn the typical behavior of the radiation detectors under a variety of reactor conditions."
  - [corpus] Limited direct corpus validation; neighbor papers focus on reinforcement learning and state estimation rather than AE-based anomaly detection.
- Break condition: If anomalous events fall within the statistical variability of normal training data, reconstruction error may not distinguish them (false negatives). Conversely, novel but legitimate operational modes may trigger false alarms.

### Mechanism 2
- Claim: Feature attention weights act as sensor-level anomaly indicators by assigning higher weights to features deviating from normal correlations.
- Mechanism: The feature-attention module computes alignment scores between the latent representation and each input feature via learned functions, producing softmax-normalized weights. When a sensor exhibits patterns inconsistent with learned correlations, the model increases its feature attention weight during reconstruction, flagging it as anomalous.
- Core assumption: Anomalous sensors require disproportionate model attention during reconstruction compared to normal sensors.
- Evidence anchors:
  - [abstract] "The feature attention assigns weights to radiation sensors exhibiting abnormal patterns."
  - [section III.D] "The feature-attention module learns to assign weights to the individual features of an input sequence, enabling the model to emphasize the most relevant features that affect the reconstruction."
  - [section IV.III] "The feature attention assigns higher weights to the sensor of interest during the falsification period... This behavior indicates that the model identifies the sensor as potentially exhibiting an abnormal pattern."
  - [corpus] No direct corpus validation for feature attention in nuclear anomaly detection.
- Break condition: If multiple sensors drift simultaneously in correlated ways, feature attention may distribute weights evenly without clear localization.

### Mechanism 3
- Claim: Temporal attention provides fine-grained time localization by assigning lower weights to timesteps containing anomalous values, reflecting reduced model confidence in those regions.
- Mechanism: The temporal-attention module computes weights across all timesteps in the sliding window (20 seconds). Anomalous timesteps receive lower attention weights because the model treats them as less reliable for accurate reconstruction—the model "downweights" inputs it cannot confidently integrate into its learned normal representation.
- Core assumption: The model expresses uncertainty about anomalous regions through reduced temporal attention rather than increased attention.
- Evidence anchors:
  - [abstract] "Temporal attention highlights specific timesteps where irregularities occur, enabling precise localization."
  - [section IV.II] "The time attention displays lower values precisely at the timesteps where falsifications occur."
  - [section IV.III] "The framework assigns lower importance to the ram pool sensor between 150 and 200 seconds during reconstruction... corresponding to a detection accuracy of 95%."
  - [corpus] Weak corpus evidence; neighbor papers do not address temporal attention for anomaly localization.
- Break condition: Gradual drift anomalies may not produce sharp temporal attention transitions; boundary detection may miss first/last few seconds (as observed with 95% accuracy).

## Foundational Learning

- Concept: **LSTM Autoencoders**
  - Why needed here: Core architecture for learning temporal dependencies in multivariate time series and detecting anomalies via reconstruction error.
  - Quick check question: Can you explain why an autoencoder trained only on normal data will produce higher reconstruction error for anomalous inputs?

- Concept: **Bahdanau (Additive) Attention**
  - Why needed here: Mathematical foundation for both feature and temporal attention mechanisms; understanding alignment scores and softmax normalization is essential for interpreting attention weights.
  - Quick check question: How does softmax normalization ensure attention weights sum to 1, and why does this enable interpretability as relative importance?

- Concept: **Sliding Window Time Series Processing**
  - Why needed here: The model processes data in 20-second windows advanced by 1-second steps; understanding tensor dimensions (batch × window × features) is critical for implementation.
  - Quick check question: Given a 300-second dataset with 6 features and window size 20, how many input tensors will be generated with a 1-second step size?

## Architecture Onboarding

- Component map:
  Input layer -> Encoder (LSTM 64→32) -> Latent space (64) -> Dual attention (feature + temporal) -> Decoder (LSTM 32→64) -> Output

- Critical path:
  1. Data preprocessing (Min-Max normalization using 3-year sensor ranges)
  2. Tensor creation via sliding window
  3. Hyperparameter tuning (random grid search, 30 combinations, validation MSE minimization)
  4. Training on normal data only (80/20 train/validation split)
  5. Inference with attention weight extraction for interpretation

- Design tradeoffs:
  - Window size 20 seconds balances temporal context vs. detection latency
  - Applying attention at latent space (vs. encoder/decoder) reduces noise sensitivity but may miss fine-grained input patterns
  - Unsupervised training avoids labeling requirements but cannot distinguish anomaly types

- Failure signatures:
  - Uniform attention weights across all sensors → model sees no anomalies (could be true negative or missed detection)
  - High feature attention but uniform temporal attention → sensor-level anomaly without clear time bounds (possible drift)
  - Opposing feature/temporal attention patterns → normal (feature attention high, temporal attention uniform) vs. anomalous (feature attention high, temporal attention low at specific timesteps)

- First 3 experiments:
  1. Reproduce baseline validation: Train on normal PUR-1 data, verify uniform attention weights on held-out normal sequences.
  2. Inject controlled anomalies: Create synthetic drifts/spikes in individual sensors and verify feature attention increases for affected sensors while temporal attention decreases at anomalous timesteps.
  3. Test correlation sensitivity: Inject correlated anomalies (e.g., elevated radiation with elevated power) and verify model correctly classifies as normal based on learned correlation patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model's localization performance degrade as the ratio of compromised sensors to normal sensors increases?
- Basis in paper: [explicit] The authors state: "As future work, we aim to investigate how the number of falsified sensors affects the performance of the attention-based AE."
- Why unresolved: The current study validates the framework using cases where anomalies affect a minority of features (e.g., 1 out of 6 sensors). It is unclear if the attention mechanism can isolate anomalies if a majority of sensors are concurrently compromised, which might skew the learned "normal" baseline.
- What evidence would resolve it: A sensitivity analysis benchmarking temporal localization accuracy (e.g., IoU score) while systematically increasing the percentage of simultaneously falsified sensors from 10% to over 50% of the total feature space.

### Open Question 2
- Question: Can the dual attention mechanism distinguish between physical sensor anomalies and cybersecurity threats (e.g., false data injection)?
- Basis in paper: [explicit] The conclusion notes: "We plan to examine whether the proposed attention mechanism can also be leveraged to detect and localize cybersecurity threats within the PUR-1 infrastructure."
- Why unresolved: The paper validates detection using physical anomalies (drifts and spikes), but it is unknown if malicious data injections designed to mimic operational transients would trigger similar attention patterns or evade detection.
- What evidence would resolve it: Comparative results showing the framework's false negative rate against adversarial attacks or replay attacks compared to the current results for physical sensor faults.

### Open Question 3
- Question: Does the framework maintain robust performance on complex, naturally occurring reactor faults, or is it biased toward the synthetic anomalies used for validation?
- Basis in paper: [inferred] The paper validates the model using "artificial" spikes and drifts injected into real data, acknowledging the "scarcity of abnormal events" as a general challenge in the field.
- Why unresolved: Real-world hardware failures often exhibit complex, non-stationary noise or gradual degradation patterns that may differ significantly from the simple synthetic spikes and linear drifts used in the test cases.
- What evidence would resolve it: Evaluation of the model on historical datasets containing actual, documented component failures or operational upsets (e.g., actual sensor failures recorded during PUR-1 history) rather than simulated data.

## Limitations
- The paper provides strong validation on a single real-world reactor dataset but lacks comparative analysis against established unsupervised anomaly detection methods
- The claim that feature attention weights exceeding 1.0 indicate anomalies is unexplained given softmax normalization constraints
- The 95% accuracy metric is specific to spike localization and may not generalize to other anomaly types or gradual drift scenarios

## Confidence
- **High confidence**: LSTM autoencoder architecture and dual attention mechanism design (well-documented and consistent with established methods)
- **Medium confidence**: Anomaly detection performance on PUR-1 data (limited to single reactor dataset, artificial anomalies)
- **Low confidence**: Cross-dataset generalization and ability to distinguish anomaly types without additional classification layers

## Next Checks
1. Test model performance on cross-reactor datasets to assess generalizability beyond PUR-1 operational conditions
2. Implement quantitative anomaly detection thresholds using reconstruction error and attention weights, then evaluate precision-recall tradeoffs
3. Compare against established baselines (Isolation Forest, One-Class SVM, traditional reconstruction-based AE) on the same anomaly types to establish relative performance