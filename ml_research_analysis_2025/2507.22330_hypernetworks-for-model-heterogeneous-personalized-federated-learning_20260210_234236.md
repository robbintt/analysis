---
ver: rpa2
title: Hypernetworks for Model-Heterogeneous Personalized Federated Learning
arxiv_id: '2507.22330'
source_url: https://arxiv.org/abs/2507.22330
tags:
- clients
- learning
- client
- federated
- experiments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses model-heterogeneous personalized federated
  learning (MH-pFL), where clients have different model architectures and data distributions.
  The authors propose MH-pFedHN, a framework using a server-side hypernetwork to generate
  personalized parameters for each client's heterogeneous model.
---

# Hypernetworks for Model-Heterogeneous Personalized Federated Learning

## Quick Facts
- **arXiv ID:** 2507.22330
- **Source URL:** https://arxiv.org/abs/2507.22330
- **Reference count:** 40
- **Primary result:** Proposes MH-pFedHN and MH-pFedHNGD frameworks for model-heterogeneous personalized federated learning, achieving state-of-the-art accuracy (e.g., 68.3% on CIFAR-100) using hypernetworks to generate personalized parameters for diverse client architectures.

## Executive Summary
This paper tackles the challenge of model-heterogeneous personalized federated learning (MH-pFL), where clients have different neural network architectures and non-IID data distributions. The authors introduce MH-pFedHN, a framework using a server-side hypernetwork that generates personalized parameters for each client's unique model via client-specific embedding vectors. To improve efficiency and knowledge sharing, clients with similar parameter counts share hypernetwork heads. An enhanced version, MH-pFedHNGD, integrates a lightweight global model for knowledge distillation, improving generalization. Extensive experiments on EMNIST, CIFAR-10/100, and Tiny-ImageNet show the methods outperform state-of-the-art baselines, even in highly heterogeneous and non-IID settings.

## Method Summary
The proposed method centers on a server-side hypernetwork that generates personalized model parameters for heterogeneous client architectures. Each client is assigned learnable embedding vectors based on its model's parameter count. The hypernetwork, composed of a shared feature extractor and multiple output heads, processes these embeddings to produce parameters tailored to each client's model size and structure. Clients with similar parameter counts share hypernetwork heads, enabling efficient knowledge sharing and reduced computation. MH-pFedHNGD extends this by adding a lightweight global model (also generated by the hypernetwork) that acts as a teacher via knowledge distillation, improving generalization. The server updates the hypernetwork and embeddings using gradients from client updates, while preserving client privacy by not requiring disclosure of model architectures.

## Key Results
- MH-pFedHNGD achieves 68.3% accuracy on CIFAR-100 with 50 clients under non-IID conditions, surpassing state-of-the-art baselines by 2-4 percentage points.
- Both MH-pFedHN and MH-pFedHNGD outperform alternatives in both homogeneous and heterogeneous model settings across EMNIST, CIFAR-10/100, and Tiny-ImageNet datasets.
- Head-sharing strategy reduces server-side computation and memory, enabling efficient scaling to many clients with diverse architectures.
- The lightweight global model in MH-pFedHNGD provides effective regularization and generalization via knowledge distillation, especially in non-IID settings.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A server-side hypernetwork can generate personalized parameters for heterogeneous client models via client-specific embedding vectors.
- **Mechanism:** The server maintains a hypernetwork with a shared feature extractor and multiple output heads. Each client is assigned embedding vectors based on its model's parameter count. The hypernetwork processes these embeddings and outputs parameter subsets, which are truncated or concatenated to match the client's model size.
- **Core assumption:** Meaningful model parameters can be effectively generated by a hypernetwork conditioned on compact, learnable embeddings that capture client-specific needs.
- **Evidence anchors:**
  - [abstract]: "...propose MH-pFedHN, which leverages a server-side hypernetwork that takes client-specific embedding vectors as input and outputs personalized parameters tailored to each clientâ€™s heterogeneous model."
  - [section 3.2]: "...the personalized model parameters for client i are generated as follows: $\theta_i := \text{concat}(\theta^1_i, \dots, \theta^{\tau_i}_i)[1:K_i]$"
- **Break condition:** Fails if embedding vectors cannot uniquely and effectively distinguish between optimal parameter configurations for different client tasks/architectures, or if hypernetwork capacity is insufficient.

### Mechanism 2
- **Claim:** Grouping clients with similar model sizes to share hypernetwork heads promotes knowledge sharing and reduces computation.
- **Mechanism:** Clients with similar parameter counts are assigned the same embedding vectors and share a specific head in the hypernetwork. This allows one forward pass through the shared head to generate parameter subsets for multiple clients simultaneously.
- **Core assumption:** Clients with similar model sizes benefit from sharing knowledge and have similar enough architectural needs that a shared generation head is effective.
- **Evidence anchors:**
  - [abstract]: "...introduce a multi-head structure within the hypernetwork, allowing clients with similar model sizes to share heads."
  - [section 3.2]: "...clients with similar parameter counts share the same customized embedding vectors... a shared head $\phi_{H_l}$ is created for clients with the same embedding vectors..."
- **Break condition:** Fails if model size is a poor proxy for architectural or data similarity, leading to negative transfer.

### Mechanism 3
- **Claim:** A lightweight global model, generated by the same hypernetwork, improves generalization by acting as a teacher in knowledge distillation and providing an additional gradient signal for the hypernetwork.
- **Mechanism:** MH-pFedHNGD introduces a global model whose parameters are also generated by the hypernetwork using global embedding vectors. Clients train this global model on their data, and the global model then guides personalized model training via knowledge distillation (KL-divergence loss).
- **Core assumption:** A single lightweight global model can capture generalizable features relevant to all clients and its soft labels provide a useful learning signal to regularize personalized models.
- **Evidence anchors:**
  - [abstract]: "...MH-pFedHNGD, which integrates an optional lightweight global model to improve generalization."
  - [section 3.3]: "This plug-in component on the server side is directly generated by our hypernetwork... enables it to learn a more comprehensive data distribution... global model can serve as a teacher model... assist in the training via knowledge distillation..."
- **Break condition:** Fails if data distributions across clients are extremely disparate, making a single global model an ineffective or misleading teacher for some clients.

## Foundational Learning

### Concept: Hypernetworks
- **Why needed here:** This is the core engine of the proposed framework. A hypernetwork is a neural network that generates the weights (parameters) for another neural network (the target network). Understanding how weights are generated from inputs (embeddings) is crucial.
- **Quick check question:** How does a hypernetwork differ from a meta-learning algorithm like MAML?

### Concept: Knowledge Distillation
- **Why needed here:** MH-pFedHNGD relies on knowledge distillation where a "teacher" model (the global model) guides the training of a "student" model (the personalized client model) by matching soft output distributions.
- **Quick check question:** Why might soft labels from a teacher be more useful than hard ground-truth labels for transfer learning?

### Concept: Federated Learning (FL) Non-IID Setting
- **Why needed here:** The paper specifically targets "non-IID" (non-Independent and Identically Distributed) data, where data distributions vary across clients. This is the core problem personalization aims to solve.
- **Quick check question:** In a federated setting with non-IID data, why does a single global model often perform poorly on individual clients?

## Architecture Onboarding

### Component map:
- **Server:**
  - Hypernetwork (Feature Extractor $\phi_f$): Learnable weights shared across all clients.
  - Hypernetwork Heads ($\{\phi_{H_l}\}$): Learnable output heads, each shared by clients with similar model sizes.
  - Embedding Store: Stores learnable client-specific embedding vectors $\{v_i\}$ and global embedding vectors $v_g$.
- **Client:**
  - Personalized Model: Heterogeneous architecture defined locally by client. Receives parameters $\theta_i$ from server.
  - Global Model (optional in MH-pFedHNGD): Lightweight model architecture (e.g., LeNet). Receives parameters $w_g$ from server.

### Critical path:
1. **Initialization:** Server initializes hypernetwork and embeddings. Clients register their model's parameter count $K_i$.
2. **Round (MH-pFedHN):**
   a. Server generates $\theta_i = h(v_i; \phi)[1:K_i]$ for each client.
   b. Client trains model with $\theta_i$ on local data, computes update $\Delta\theta_i$.
   c. Client sends $\Delta\theta_i$ to server.
   d. Server updates $\phi$ and $v_i$ using $\Delta\theta_i$.
3. **Round (MH-pFedHNGD):**
   a. Server generates global model $w_g = h(v_g; \phi)[1:K_g]$.
   b. Clients train $w_g$, send update $\Delta w_g$.
   c. Server updates $\phi$ and $v_g$ using $\Delta w_g$.
   d. Server generates personalized $\theta_i$. Clients train $\theta_i$ using local loss plus distillation loss against $w_g$.
   e. Clients send $\Delta\theta_i$, server updates $\phi$ and $v_i$.

### Design tradeoffs:
- **MH-pFedHN vs. MH-pFedHNGD:** The latter adds a global distillation step, improving accuracy and generalization but increasing communication (extra round) and client computation.
- **Head Sharing Granularity:** More sharing (grouping clients into fewer heads) reduces server-side memory and computation but risks negative transfer if grouped clients are too dissimilar.
- **Global Model Size:** A lightweight global model (e.g., LeNet) reduces overhead but may have limited capacity to represent complex shared knowledge.

### Failure signatures:
- **Divergence:** Loss explodes or NaNs. Check hypernetwork learning rate and gradient clipping.
- **Negative Transfer:** Performance drops compared to purely local training. Investigate head groupings; consider isolating problematic clients into their own head.
- **Slow Convergence:** Distillation is not helping. Check distillation temperature and the balance factor ($\lambda$) between local and distillation loss.

### First 3 experiments:
1. Establish a baseline with MH-pFedHN on a simple dataset (e.g., EMNIST or CIFAR-10) with a few (e.g., 10) clients using homogeneous LeNet models. Verify the basic hypernetwork update loop works and accuracy improves over FedAvg.
2. Introduce model heterogeneity: Assign different model architectures (e.g., LeNet, VGG, ResNet) to different clients. Run MH-pFedHN. Verify that the server can generate parameters of different sizes and shapes for the correct clients.
3. Enable the MH-pFedHNGD enhancement. Compare its accuracy and convergence speed against the baseline from experiment 2. Experiment with the distillation temperature and balance factor to see their impact.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the accuracy gap between homogeneous and heterogeneous model settings be effectively closed in hypernetwork-based federated learning?
- **Basis in paper:** [Explicit] The Conclusion states, "switching from homogeneous models to heterogeneous models within the same settings can lead to a decline in accuracy, which represents a challenge that we aim to address in future research."
- **Why unresolved:** The experimental results (Tables 1 vs. 2) consistently show that heterogeneous configurations yield lower accuracy than homogeneous ones, indicating that current knowledge fusion techniques are insufficient for fully bridging architectural diversity.
- **What evidence would resolve it:** A modified framework or loss function that achieves statistical parity (or improvement) in heterogeneous settings compared to the homogeneous baseline on complex datasets like Tiny-ImageNet.

### Open Question 2
- **Question:** How can the global model in MH-pFedHNGD be adapted to provide meaningful knowledge distillation for clients with completely unseen architectural structures?
- **Basis in paper:** [Explicit] Section 5 notes that when generalizing to new architectures, "the assistance provided by the global model is limited, and the learning during the generalization process primarily relies on the data distribution itself."
- **Why unresolved:** The current lightweight global model (LeNet-based) lacks the capacity or feature alignment necessary to act as an effective teacher for novel, potentially more complex architectures not present during hypernetwork training.
- **What evidence would resolve it:** Demonstrating that a global model can significantly accelerate convergence or boost accuracy for unseen architectures compared to training from scratch (MH-pFedHN) without manual head fine-tuning.

### Open Question 3
- **Question:** Is grouping clients for head sharing based solely on parameter count optimal, or does it obscure semantic structural differences that harm performance?
- **Basis in paper:** [Inferred] The paper groups clients by parameter count ($K_i$) to share heads ($\phi^H_l$). However, Appendix C.5 suggests that for models with identical parameter counts but different structures (e.g., VGG vs. MLP), using separate heads performs slightly better, implying the current grouping heuristic is approximate.
- **Why unresolved:** The server is restricted from knowing model architectures for privacy, forcing a reliance on parameter count, which may group incompatible feature extractors.
- **What evidence would resolve it:** A privacy-preserving mechanism that clusters clients by structural topology or feature statistics rather than just parameter volume, resulting in higher accuracy without compromising privacy constraints.

## Limitations
- **Parameter count grouping:** Using parameter count as the sole criterion for head-sharing may lead to negative transfer if clients with similar sizes have vastly different architectural structures.
- **Global model capacity:** The lightweight global model may lack the capacity to effectively distill knowledge for clients with highly complex or unseen architectures.
- **Privacy of embeddings:** The paper does not explicitly address the privacy implications of sharing embedding vectors, which could potentially leak information about client model architectures or data distributions.

## Confidence

- **High Confidence:** The overall framework design and the empirical superiority of MH-pFedHNGD over baselines on standard datasets (CIFAR-100, Tiny-ImageNet) are well-supported by the results presented.
- **Medium Confidence:** The mechanism of using parameter count for head-sharing is validated but could be brittle in more complex scenarios; the effectiveness of the lightweight global model for distillation is demonstrated but its impact varies with data heterogeneity.
- **Low Confidence:** The theoretical guarantees for convergence and generalization in the presence of extreme model heterogeneity and severe non-IID data distributions are not provided.

## Next Checks

1. **Ablation on Head-Sharing Criteria:** Systematically test the impact of head-sharing by grouping clients based on criteria other than parameter count (e.g., model depth, number of convolutional layers) to identify the most robust grouping heuristic.
2. **Stress Test on Model Diversity:** Evaluate the framework with an extreme mix of model architectures (e.g., including transformers or fully connected networks) to identify the breaking point of the head-sharing and hypernetwork generation mechanisms.
3. **Privacy Analysis of Embeddings:** Conduct a formal privacy analysis (e.g., membership inference, model inversion) on the server-side embedding vectors to quantify the potential for information leakage and test the effectiveness of potential mitigation strategies like differential privacy.