---
ver: rpa2
title: 'PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese
  Pharmaceutical Shipping Documents'
arxiv_id: '2512.23714'
source_url: https://arxiv.org/abs/2512.23714
tags:
- pharmaship
- reading
- document
- order
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PharmaShip introduces a Chinese pharmaceutical shipping document
  dataset designed to test pre-trained text-layout models under noisy OCR and heterogeneous
  templates. The dataset covers sequence entity recognition (SER), relation extraction
  (RE), and reading order prediction (ROP) tasks, using an entity-centric evaluation
  protocol to reduce architectural confounds.
---

# PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents

## Quick Facts
- arXiv ID: 2512.23714
- Source URL: https://arxiv.org/abs/2512.23714
- Authors: Tingwei Xie; Tianyi Zhou; Yonghong Song
- Reference count: 24
- One-line primary result: PharmaShip introduces a Chinese pharmaceutical shipping document dataset with entity-centric annotation, testing models under noisy OCR and heterogeneous templates across SER, RE, and ROP tasks.

## Executive Summary
PharmaShip introduces a novel Chinese pharmaceutical shipping document dataset designed to test pre-trained text-layout models under realistic conditions of noisy OCR and heterogeneous templates. The benchmark covers three tasks—sequence entity recognition, relation extraction, and reading order prediction—using an entity-centric evaluation protocol that reduces architectural confounds. Experiments with five baselines, including LiLT, LayoutLMv3-base, and GeoLayoutLM with RORE enhancements, demonstrate that pixel features and explicit geometry provide complementary inductive biases. However, neither alone is sufficient; injecting reading-order-oriented regularization consistently improves SER and EL performance. ROP is accurate at the word level but challenging at the segment level due to boundary ambiguity and long-range crossings.

## Method Summary
PharmaShip consists of 161 annotated scanned Chinese pharmaceutical shipping documents, covering 11,295 segments, 66,961 words, 10,090 entities, 5,005 QA relations, and 17,419 reading-order links. Three tasks are defined: Semantic Entity Recognition (SER) for token-level classification, Relation Extraction/Entity Linking (EL) for QA pair prediction, and Reading Order Prediction (ROP) for directed acyclic graph links over segments. Five baselines are evaluated: LiLT, LayoutLMv3-base-chinese, GeoLayoutLM, and RORE-enhanced variants. Positional embeddings are expanded from 512 to 2048 to prevent truncation, and class-weighted optimization with positive/negative pair rebalancing is applied for relation tasks. Evaluation uses entity-centric F1 as the primary metric.

## Key Results
- RORE enhancements consistently improve SER and EL performance across backbone architectures, with F1 gains of +0.57 to +1.19 for SER and +1.04 to +1.28 for EL.
- Pixel-aware models (LayoutLMv3) and geometry-aware models (GeoLayoutLM) provide complementary inductive biases, with RORE rebalancing precision and recall.
- ROP achieves high word-level accuracy (88.48 F1) but struggles at segment-level (70.84 F1), reflecting boundary ambiguity and long-range dependencies.
- Expanding positional embedding coverage from 512 to 2048 stabilizes predictions and reduces truncation artifacts for long-form documents.

## Why This Works (Mechanism)

### Mechanism 1
Reading-order-oriented regularization (RORE) consistently improves SER and EL performance across different backbone architectures. RORE injects sequence-aware constraints by modeling reading order as directed edges (ISDR formulation), which discourages implausible token paths and spurious proximity-based relations. The paper states RORE "yields the most robust configuration" by "discouraging implausible token paths and enforcing coherent edges." Core assumption: Documents follow human-readable sequential patterns that can be captured as directed acyclic graphs; these patterns generalize across heterogeneous templates. Evidence: Table III shows F1 gains: RORE-LayoutLMv3 improves SER by +0.57 and EL by +1.28; RORE-GeoLayoutLM improves SER by +1.19 and EL by +1.04. Break condition: If documents have highly irregular or non-linear reading flows (e.g., purely spatially-organized dashboards), ISDR assumptions may not hold.

### Mechanism 2
Expanding positional embedding coverage from 512 to 2048 tokens stabilizes predictions and reduces late-page errors. Chinese business documents frequently exceed 512 tokens. Default truncation removes late-page entities and long-range dependencies. Extended positions preserve complete context without architectural changes beyond initialization. Core assumption: The initialization scheme for new positions (following each repository's default policy) integrates smoothly; model capacity is sufficient to utilize longer sequences. Evidence: "we expand the positional embedding length from 512 to 2048 for all three backbones and fine-tune end-to-end, ensuring that no training or validation sample is truncated." Break condition: If documents exceed 2048 tokens or if memory constraints force aggressive batching, benefits may diminish; longer sequences may introduce attention dilution.

### Mechanism 3
Pixel features and explicit geometry provide complementary inductive biases, but neither alone is sufficient for robust pharmaceutical document understanding. Pixel-aware models (LayoutLMv3) capture visual texture and rendered features, yielding higher recall. Geometry-aware models (GeoLayoutLM) encode explicit spatial relations, yielding higher precision. RORE bridges both by adding sequence-level guidance. Core assumption: OCR quality is sufficient for bounding-box alignment; visual features add signal beyond what layout coordinates provide. Evidence: "geometry-only models tend to be precision-leaning, pixel-aware models recall-leaning, and RORE rebalances both." Break condition: If OCR noise is severe enough that bounding boxes are unreliable, geometry-aware advantages erode; if images are low-resolution, pixel features lose discriminative power.

## Foundational Learning

- **Entity-centric annotation vs. block-level annotation**: Why needed here: PharmaShip decouples semantic labels from visual regions, removing "false coupling" that causes models to overfit to proximity heuristics. Understanding this distinction is critical for interpreting why performance drops on PharmaShip compared to FUNSD/CORD. Quick check: Can you explain why a model trained on block-level annotations might incorrectly link two adjacent fields that belong to different semantic categories?

- **Immediate Succession During Reading (ISDR) graph formulation**: Why needed here: ROP is modeled as predicting directed edges between segments, not as a linear sorting task. This graph-based approach captures multi-directional reading behavior in dense tabular layouts. Quick check: How does representing reading order as a DAG differ from representing it as a linear sequence, and what types of documents benefit from the DAG approach?

- **Positional embedding expansion in transformers**: Why needed here: Standard pre-trained models use 512-position limits; long-form Chinese documents exceed this. Understanding how to extend positions (initialization, fine-tuning strategy) is essential for replicating results. Quick check: What happens to late-page entities if you apply a 512-position model to a 1500-token document without modification?

## Architecture Onboarding

- **Component map**: OCR tokens/bounding boxes → Backbone (LiLT, LayoutLMv3, GeoLayoutLM) → Task heads (SER, EL/RE, ROP) → RORE enhancement (optional) → Output predictions

- **Critical path**: 1. Obtain OCR tokens and bounding boxes (standardized across all models) 2. Expand positional embeddings from 512 to 2048; initialize new positions per repository defaults 3. Apply class-weighted optimization for RE/ROP to address "no-relation" overfitting 4. Fine-tune with early stopping (max 500 epochs, patience 50)

- **Design tradeoffs**: LayoutLMv3: Best SER baseline, strong pixel features, but requires image rendering. GeoLayoutLM: Best EL on some benchmarks, explicit geometry helps precision, but larger model (399M params). LiLT: Lightest, no pixel dependency, but trails on PharmaShip by 5–9 F1. RORE variants: Consistent +1 F1 improvement but add auxiliary task complexity.

- **Failure signatures**: Truncation warnings during preprocessing → positional coverage insufficient. High recall, low precision on EL → proximity-based spurious links; consider RORE. ROP word-level F1 ~88 but segment-level F1 ~70 → boundary ambiguity expected; do not over-interpret segment-level scores. Model overfits to "no-relation" class → check class balancing in loss function.

- **First 3 experiments**: 1. Baseline reproduction: Run LayoutLMv3-base-chinese on PharmaShip SER/EL with default 512 positions; observe truncation rate and late-page errors. Then expand to 2048 and compare. 2. RORE ablation: Compare LayoutLMv3 vs. RORE-LayoutLMv3 on EL task; isolate whether gains come from sequence constraints vs. increased parameters. 3. Modality comparison: Run LiLT (no pixels), LayoutLMv3 (pixels), and GeoLayoutLM (explicit geometry) on the same split; analyze precision-recall tradeoffs per task to confirm complementary biases.

## Open Questions the Paper Calls Out

### Open Question 1
Can segment-level reading order prediction accuracy be substantially improved through architectural innovations or enhanced annotation schemes? Basis in paper: [explicit] The authors state "ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings" and identify "segment-level reading order and long-range dependencies across dense, multi-field pages" as remaining challenges. Why unresolved: Word-level ROP achieves 88.48 F1 with LayoutLMv3, but segment-level drops to 70.84 F1—a 17.64 point gap indicating fundamental difficulty with boundary detection and cross-sequence ordering. What evidence would resolve it: Demonstrating architectures or auxiliary supervision signals that close the word-to-segment ROP gap by at least 10 F1 points while maintaining SER and EL performance.

### Open Question 2
To what extent do the reading-order-oriented regularization gains observed on PharmaShip transfer to other domains with heterogeneous layouts? Basis in paper: [inferred] The paper demonstrates RORE improvements on PharmaShip and general VrDU benchmarks, but all tested documents share form-like structures; the authors claim sequence-aware constraints are "transferable" without validating on fundamentally different document genres. Why unresolved: RORE effectiveness was validated only on forms, receipts, and shipping documents—domains where tabular layouts and field-grouping patterns may share structural regularities that amplify reading-order benefits. What evidence would resolve it: Cross-domain experiments showing consistent RORE improvements on document types with different reading conventions (e.g., multi-column magazines, technical manuals, or handwritten correspondence) without domain-specific fine-tuning.

### Open Question 3
What is the optimal positional embedding capacity for long-form document understanding, and does the 512-to-2048 expansion introduce new trade-offs? Basis in paper: [inferred] The authors expand positional coverage from 512 to 2048 to prevent truncation and stabilize late-page predictions, but do not systematically ablate intermediate values or analyze whether longer sequences dilute attention quality. Why unresolved: While 2048 prevents truncation, it remains unclear whether this capacity is necessary, sufficient, or potentially harmful to attention distribution over extended sequences—especially given memory and compute constraints. What evidence would resolve it: Ablation experiments across positional lengths (512, 1024, 2048, 4096) measuring SER, EL, and ROP F1 alongside attention entropy analysis to detect dispersion or focusing artifacts.

### Open Question 4
How does OCR noise type and severity interact with reading-order regularization effectiveness? Basis in paper: [inferred] The paper mentions PharmaShip is designed to "stress-test" models under noisy OCR, yet the experiments report aggregated results without analyzing whether RORE's benefits are uniform across OCR quality levels or concentrated in specific error regimes. Why unresolved: Reading-order supervision could either compensate for OCR errors by providing structural context or be undermined by missegmented tokens; the interaction remains uncharacterized. What evidence would resolve it: Stratified evaluation grouping samples by OCR confidence scores or error types, reporting RORE gains per stratum to identify where reading-order supervision is most beneficial or potentially counterproductive.

## Limitations

- **Limited domain specificity**: The dataset size (161 documents) is modest, and results may not generalize to broader document types or larger corpora beyond pharmaceutical shipping documents.
- **Weak corpus support for core mechanisms**: The three key mechanisms (RORE benefits, positional expansion gains, modality complementarity) are supported primarily by the authors' own experiments rather than external validation.
- **Unclear robustness to severe OCR noise**: The paper assumes OCR quality is sufficient for layout and geometry modeling, but real-world pharmaceutical shipping documents often have stamps, handwritten entries, and degraded scans.

## Confidence

- **High Confidence**: The dataset construction (161 documents, 11,295 segments, 66,961 words) and basic task definitions (SER, EL, ROP) are clearly specified and reproducible. The core claim that PharmaShip provides a challenging benchmark for Chinese pharmaceutical shipping documents is well-supported.
- **Medium Confidence**: The empirical finding that RORE consistently improves SER and EL performance is supported by Table III, but the mechanism's generalizability beyond this domain and dataset is not established. Similarly, the positional expansion from 512 to 2048 tokens is clearly implemented, but its necessity is inferred from truncation artifacts rather than systematic analysis.
- **Low Confidence**: The claim that pixel features and explicit geometry provide complementary inductive biases is supported only by relative performance trends within the authors' experiments. No ablation studies isolate the contribution of each modality, and no external comparisons validate these modality-specific advantages.

## Next Checks

1. **Cross-domain robustness test**: Apply RORE-LayoutLMv3 to a non-pharmaceutical structured document dataset (e.g., FUNSD or CORD) and measure whether the sequence-aware regularization consistently improves SER and EL, or if gains are domain-specific.

2. **OCR noise sensitivity analysis**: Intentionally degrade OCR quality (e.g., by adding synthetic noise or using lower-resolution scans) and measure the impact on bounding-box alignment accuracy and downstream task performance, especially for geometry-aware models.

3. **Modality ablation study**: Run controlled experiments comparing LayoutLMv3 with (a) pixels removed, (b) geometry removed, and (c) both removed, to isolate the individual and combined contributions of pixel features and explicit geometry to SER, EL, and ROP performance.