---
ver: rpa2
title: 'Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis
  From Intrinsic Measures to Zero-shot Retrieval Outcomes'
arxiv_id: '2506.06506'
source_url: https://arxiv.org/abs/2506.06506
tags:
- group
- valence
- bias
- intrinsic
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study quantifies how intrinsic biases in vision-language models
  (VLMs) propagate to downstream tasks. It introduces a controlled framework that
  correlates intrinsic SC-EAT bias measures in model representations with extrinsic
  bias outcomes in zero-shot text-to-image (TTI) and image-to-text (ITT) retrieval
  tasks.
---

# Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes

## Quick Facts
- arXiv ID: 2506.06506
- Source URL: https://arxiv.org/abs/2506.06506
- Authors: Kshitish Ghate; Tessa Charlesworth; Mona Diab; Aylin Caliskan
- Reference count: 34
- Primary result: Intrinsic biases in VLM representations consistently correlate with zero-shot retrieval bias outcomes (ρ = 0.83 ± 0.10)

## Executive Summary
This study systematically quantifies how biases embedded in vision-language model (VLM) representations propagate to downstream zero-shot retrieval tasks. Using a controlled framework, the authors measure intrinsic bias via SC-EAT effect sizes and extrinsic bias via zero-shot text-to-image and image-to-text retrieval outcomes. Across 114 analyses spanning multiple models and experimental conditions, the research demonstrates that biases in model embeddings directly manifest in retrieval outputs, with larger models showing stronger propagation. The findings reveal systematic bias propagation patterns, including reduced propagation robustness for underrepresented groups.

## Method Summary
The study employs a controlled framework measuring intrinsic bias through SC-EAT effect sizes computed from cosine similarities between social group embeddings and valence attribute sets. Extrinsic bias is measured through zero-shot retrieval in shared embedding spaces, where mean valence of retrieved items or proportion of correctly identified group items serves as the metric. The propagation of bias is quantified by correlating intrinsic and extrinsic measures using Spearman's ρ. The framework evaluates three VLMs (CLIP-B-32, CLIP-L-14, BLIP-2) across eight experimental conditions, using morphed CFD images, OASIS valence-rated images, and template-based text prompts.

## Key Results
- Consistently high positive correlations between intrinsic and extrinsic bias measures (ρ = 0.83 ± 0.10) across 114 analyses
- Larger, higher-performing models exhibit stronger bias propagation (CLIP-L-14: ρ up to 0.88 vs CLIP-B-32: ρ = 0.80)
- Underrepresented groups experience less robust propagation, leading to more variable and skewed retrieval outcomes
- Bias propagation patterns are consistent across both text-to-image and image-to-text retrieval directions

## Why This Works (Mechanism)

### Mechanism 1: Shared Representational Space Enables Direct Bias Manifestation
Intrinsic biases measured in VLM embeddings propagate directly to zero-shot retrieval outputs because both tasks operate on the same learned representations without fine-tuning intermediaries. The SC-EAT quantifies associations between social group embeddings and valence attribute embeddings, and retrieval cosine similarity rankings on these same embeddings produce outputs that reflect the pre-existing association structure.

### Mechanism 2: Model Scale Amplifies Propagation Strength
Larger, higher-performing VLMs exhibit stronger bias propagation because scaling improves the model's capacity to encode and propagate any signal—including valence and group associations—more robustly. This increases both baseline task performance and bias correlation.

### Mechanism 3: Underrepresentation Creates Asymmetric Propagation Robustness
Marginalized/underrepresented groups show less robust signal propagation, leading to more variable and skewed retrieval outcomes. "Markedness" makes some identities more distinctive in training data, potentially increasing propagation for those groups, while other underrepresented groups have weaker learned representations, reducing propagation consistency.

## Foundational Learning

- **Concept: Single Category Embedding Association Test (SC-EAT)**
  - Why needed: This is the intrinsic bias measurement; you must understand how it computes effect sizes from cosine similarities
  - Quick check: Given target embedding *w* and attribute sets A (positive words) and B (negative words), can you compute whether the effect size indicates positive or negative bias toward *w*?

- **Concept: Zero-Shot Retrieval in Joint Embedding Spaces**
  - Why needed: The extrinsic bias measure depends on how VLMs retrieve text/images via embedding similarity without task-specific training
  - Quick check: In image-to-text retrieval, what determines the ranking of retrieved sentences for a given image?

- **Concept: Valence as a Bias Dimension**
  - Why needed: The paper uses human-rated valence scores as the primary attribute axis for measuring biased associations
  - Quick check: Why is valence (vs. other attributes) appropriate for measuring stereotyped attitudes toward social groups?

## Architecture Onboarding

- **Component map:**
  - Input datasets (CFD images, OASIS images, NRC-VAD lexicon, group label sentences) -> VLMs (CLIP-B-32, CLIP-L-14, BLIP-2) -> Intrinsic measurement (SC-EAT effect size via cosine similarity) -> Extrinsic measurement (mean valence or group proportion via retrieval) -> Propagation metric (Spearman's ρ correlation)

- **Critical path:**
  1. Encode all images and text sentences into embeddings using the target VLM
  2. For each social group, compute SC-EAT effect sizes against valence or group attribute sets
  3. Perform retrieval for each item; compute extrinsic metric
  4. Correlate intrinsic and extrinsic scores using Spearman's ρ
  5. Stratify by group, model, and direction to identify systematic patterns

- **Design tradeoffs:**
  - Morphed images vs. real images: Morphs increase sample size but may introduce artifacts; confine morphs within demographic groups to minimize contamination
  - Template-based text vs. natural text: Templates control semantics but may reduce ecological validity
  - Top-k=500 retrieval: Balances statistical power with computational cost; smaller k may miss relevant items, larger k dilutes signal

- **Failure signatures:**
  - Low or negative ρ: Suggests intrinsic bias does not manifest in retrieval (possible fine-tuning, architectural mismatch, or broken implementation)
  - High variance across templates: Indicates template choice is not neutral; revisit template selection
  - Near-zero group SC-EAT for all groups: May indicate embedding collapse or incorrect attribute set construction

- **First 3 experiments:**
  1. Baseline valence-valence (1*-a): Retrieve text for OASIS images; correlate image SC-EAT valence with mean retrieved text valence. Expect ρ ≈ 0.84–0.88.
  2. Baseline group-group (2*-a): Retrieve text for CFD images; correlate group SC-EAT with proportion of correctly identified group sentences. Expect ρ ≈ 0.76–0.94 with group-level variance.
  3. Primary bias propagation (1-a): Retrieve text for CFD images; correlate valence SC-EAT (group→valence) with mean retrieved text valence. Expect ρ ≈ 0.78–0.91; check for lower correlations among "Asian Men" and "Black Men" in BLIP-2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent do specific pretraining factors—such as data composition, model objectives, and architectural constraints—causally drive the observed bias propagation in encoder-based VLMs?
- Basis: The authors state that "pinpointing the exact origin of these biases... is distinct from measuring if and how biases appear" and list these specific mechanisms for future delineation
- Why unresolved: This study focused on quantifying the correlation between intrinsic and extrinsic bias rather than isolating causal origins
- What evidence would resolve it: Ablation studies that systematically vary pretraining data composition, learning objectives, and architectures to observe changes in bias propagation metrics

### Open Question 2
- Question: Can debiasing interventions effectively interrupt bias propagation in zero-shot retrieval without degrading model performance in downstream generative tasks?
- Basis: The authors note that using findings to "develop methods to debias... validated in further downstream tasks such as text-to-image generations presents another important avenue for exploration"
- Why unresolved: The current study analyzes retrieval tasks; the efficacy and trade-offs of these debiasing methods on generative tasks remain unverified
- What evidence would resolve it: Experiments applying proposed debiasing techniques to VLMs and evaluating both bias metrics in retrieval and quality metrics in text-to-image generation

### Open Question 3
- Question: Do the patterns of bias propagation observed in English-centric VLMs hold across different languages and cultural contexts?
- Basis: The authors list the "focus on English-only VLMs" as a limitation, noting that "interpretation of social groups and valence can vary across different languages and cultures"
- Why unresolved: The study relied on US-based datasets and English lexicons, potentially reinforcing a Western-centric perspective on bias
- What evidence would resolve it: Application of the described bias propagation framework to multilingual VLMs using culturally diverse datasets for social groups and valence ratings

## Limitations

- The analysis focuses exclusively on zero-shot tasks without fine-tuning intermediaries, limiting applicability to real-world deployment scenarios
- The observed correlation strength may partly reflect shared embedding space artifacts rather than genuine bias propagation mechanisms
- The study's reliance on morphed images and template-based text may not fully capture the complexity of real-world bias manifestations

## Confidence

- High: Central claim of systematic bias propagation (ρ = 0.83 ± 0.10 across 114 analyses)
- Medium: Larger models exhibit stronger bias propagation (limited model comparison scope)
- Medium: Underrepresented groups experience less robust propagation (relies on inferred underrepresentation)

## Next Checks

1. Test correlation patterns in fine-tuned VLMs to determine if mechanisms generalize beyond zero-shot settings
2. Analyze actual training data distribution to verify hypothesized underrepresentation effects rather than relying on Ngram statistics
3. Evaluate cross-modal bias propagation by testing whether text-to-image biases mirror image-to-text patterns in the same models