---
ver: rpa2
title: 'Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport
  Phenomena'
arxiv_id: '2505.06123'
source_url: https://arxiv.org/abs/2505.06123
tags:
- wasserstein
- transport
- distance
- data
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work proposes a method to explain Wasserstein distances,\
  \ which are widely used for comparing distributions in fields like physics, medicine,\
  \ and machine learning. The key idea is to treat the Wasserstein distance as a neural\
  \ network and apply Explainable AI techniques\u2014specifically Layer-wise Relevance\
  \ Propagation (LRP)\u2014to attribute the distance to specific data components like\
  \ features or data points."
---

# Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena

## Quick Facts
- **arXiv ID:** 2505.06123
- **Source URL:** https://arxiv.org/abs/2505.06123
- **Authors:** Philip Naumann; Jacob Kauffmann; Grégoire Montavon
- **Reference count:** 40
- **Primary Result:** Method to explain Wasserstein distances by treating them as neural networks and applying Layer-wise Relevance Propagation (LRP) to attribute transport to features and data points.

## Executive Summary
This paper introduces WaX, a method to explain Wasserstein distances by reinterpreting the transport calculation as a two-layer neural network and applying XAI techniques like Layer-wise Relevance Propagation (LRP). This allows practitioners to understand which features or data points contribute most to observed distribution shifts. The approach is validated across multiple datasets and Wasserstein configurations, showing high accuracy compared to baselines. An extension called U-WaX identifies interpretable subspaces underlying transport phenomena, demonstrated in biological aging and image dataset comparison use cases.

## Method Summary
WaX decomposes the Wasserstein distance calculation into a two-layer neural network: Layer 1 computes pairwise Minkowski distances between source and target data points, and Layer 2 performs weighted pooling using the optimal coupling matrix from optimal transport. Layer-wise Relevance Propagation (LRP) is then applied backward through this graph to attribute the total distance to individual features and data points while preserving a conservation property. The method uses hyperparameters α=p and β=min(p+2,q) for stability. U-WaX extends this by optimizing orthogonal projection matrices to discover interpretable subspaces that capture distinct components of the transport phenomena.

## Key Results
- WaX consistently outperforms baselines (MeanShift, Gradient-based methods) in explaining Wasserstein distances across multiple datasets and parameter configurations
- The method satisfies key technical desiderata including conservation of relevance and accuracy in explaining transport phenomena
- U-WaX successfully identifies interpretable subspaces in the Abalone dataset, revealing distinct subgroups associated with different biological factors (age vs. weight)
- Real-world applications demonstrate insights into biological aging processes and differences between large image datasets (CelebA vs. LFW)

## Why This Works (Mechanism)

### Mechanism 1: The Neuralization of Optimal Transport
Reinterpreting the Wasserstein distance calculation as a two-layer neural network enables the application of gradient-based attribution methods to a distance metric that is not natively a neural network. The method decomposes the Wasserstein calculation into Layer 1 (computing pairwise Minkowski distances) and Layer 2 (weighted pooling using the optimal coupling γ*). This creates a directed acyclic graph where the output can be backpropagated to inputs. The optimal coupling γ* is treated as a constant weight matrix during the backward pass, meaning the explanation explains the distance given the optimal transport plan.

### Mechanism 2: Conservation of Relevance
Enforcing a conservation property (∑R_input = ∑R_output) ensures the explanation fully accounts for the magnitude of the distribution shift without "inventing" relevance. The LRP rules redistribute the scalar output W_p layer-by-layer to inputs such that total relevance is preserved. This prevents the "shifting" or "dilution" of importance scores common in simple gradient methods. A valid explanation for a scalar metric must be decomposable into additive parts that sum to the whole.

### Mechanism 3: Subspace Disentanglement via Tailedness
Complex, heterogeneous shifts can be separated into interpretable, orthogonal components by optimizing for "tailedness" rather than data variance. U-WaX extends the architecture by inserting an orthogonal matrix U and optimizes subspaces to maximize the r-norm of transport distances (tailedness), which isolates directions where transport is "sharp" or impactful, effectively separating distinct sub-shifts (e.g., age vs. weight in abalones).

## Foundational Learning

- **Concept: Optimal Transport (OT) & Couplings (γ*)**
  - **Why needed here:** WaX does not explain the data directly; it explains the model of the data shift. You must understand that γ* represents the "flow" of mass from source to target to interpret why specific instance pairs are attributed high relevance.
  - **Quick check question:** If two distributions overlap perfectly, what happens to the Wasserstein distance and the resulting relevance scores? (Answer: Both should approach zero).

- **Concept: Layer-wise Relevance Propagation (LRP)**
  - **Why needed here:** This is the engine of the explanation. Unlike gradients (which show sensitivity), LRP shows contribution based on conservation.
  - **Quick check question:** Why is the conservation property (∑R_i = Output) critical for determining which features "cause" a high distance?

- **Concept: Minkowski Distance (L_q norms)**
  - **Why needed here:** The "physics" of the explanation depend on the ground metric (q) and distance exponent (p). High p focuses on bottlenecks/outliers; low p focuses on average shifts.
  - **Quick check question:** How does increasing p (e.g., from 1 to 10) change the sensitivity of the Wasserstein distance to outliers, and how should that change your interpretation of WaX attributions?

## Architecture Onboarding

- **Component map:** Input distributions (μ, ν) -> Optimal Transport Solver -> WaX Core (Neuralization: Input → Pairwise Distances → Weighted Sum) -> Attribution Engine (LRP backward pass) -> Output relevances
- **Critical path:** The computational bottleneck is typically the OT Solver (calculating γ*). The WaX explanation itself is computationally cheap (essentially a gradient evaluation) once γ* is known, as stated in Section IV ("fast... without incurring any significant computational overhead").
- **Design tradeoffs:**
  - Hyperparameters (p, q): High values make the model sensitive to outliers and bottlenecks; low values provide a smoother explanation of global shifts.
  - Heuristic (α, β): The paper recommends α=p, β=min(p+2,q) for stability. Deviating from this risks gradient instability or loss of interpretability.
- **Failure signatures:**
  - Interpreting Data vs. Model: A high relevance score for a feature means it contributes to the distance, not necessarily that it has high variance.
  - Sensitivity to Regularization: If using Sinkhorn, high entropic regularization blurs the coupling, potentially diluting the "bottleneck" signals WaX is designed to detect.
- **First 3 experiments:**
  1. Sanity Check (Conservation): Apply WaX to a simple synthetic dataset (e.g., two separated Gaussians). Verify that summing all pixel/feature relevances equals the computed Wasserstein distance exactly.
  2. Hyperparameter Sensitivity: Run WaX on the "bottleneck" fluid example (Fig 1) with varying p values. Confirm that higher p attributes more relevance to the bottleneck region.
  3. Subspace Discovery: Run U-WaX on a dataset with known distinct subgroups (e.g., the Abalone dataset) to see if the unsupervised subspaces align with known biological factors (age vs. sex).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the WaX framework be extended to explain Gromov-Wasserstein distances?
- **Basis in paper:** [explicit] The Conclusion states: "This may include extending WaX to Gromov-Wasserstein distances [62] (and its extensions [63]), which allow transport across unregistered spaces..."
- **Why unresolved:** The current WaX method relies on a primal formulation of optimal transport based on direct pairwise distances. Gromov-Wasserstein distances compare the structures of metric spaces (distances between distances), requiring a fundamentally different computational graph structure for relevance propagation.
- **Evidence:** A successful derivation of propagation rules for quadratic loss functions over relational matrices, maintaining the conservation property for structural transport.

### Open Question 2
- **Question:** Can WaX be adapted to account for temporal dynamics and causality in transport models?
- **Basis in paper:** [explicit] The Conclusion suggests: "...achieving finer characterizations by adapting it to more advanced transport models, e.g. accounting for temporal dynamics and causality [64], appears to be another interesting future direction."
- **Why unresolved:** The current method analyzes static snapshots of distributions (source and target). Integrating time-series constraints or causal graphs into the explanation requires modifying the neuralization step to handle trajectory regularization or causal penalties, which are absent in the current two-layer network structure.
- **Evidence:** A modified WaX algorithm that attributes relevance to specific temporal constraints or causal paths in a dynamic optimal transport setting.

### Open Question 3
- **Question:** Can the method's conservation property be preserved when applying WaX to unbalanced optimal transport?
- **Basis in paper:** [inferred] The Conclusion encourages exploring "more advanced formulations that address their limitations (cf. [58]–[60])," specifically citing works on unbalanced transport. Section III highlights that current WaX explanations satisfy the "conservation property" (∑R = W_p).
- **Why unresolved:** Unbalanced optimal transport allows for mass creation or destruction (non-conservation of mass) to handle varying population sizes. It is unclear if standard Layer-wise Relevance Propagation (LRP) rules, which strictly conserve relevance, can accurately explain a model that inherently violates mass conservation.
- **Evidence:** Derivation of modified propagation rules that mathematically account for relaxation terms (e.g., KL divergence regularization on marginal errors) in unbalanced OT.

## Limitations
- The core neuralization approach assumes the optimal coupling γ* can be treated as a constant weight matrix, which may break down with highly regularized or approximate solvers.
- The conservation property depends on numerical stability that could fail with degenerate distance matrices.
- The subspace disentanglement assumes linear, orthogonal factors underlying the shift, which may not hold for complex, correlated phenomena.

## Confidence

- **High Confidence:** The basic WaX architecture (Mechanisms 1-2) is well-specified and theoretically grounded in established XAI literature. The conservation property and neuralization approach are clearly defined.
- **Medium Confidence:** The empirical validation shows consistent performance across datasets, but the evaluation metrics (SRG, cosine similarity) are proxy measures that don't directly validate the interpretability of the attributions.
- **Low Confidence:** The U-WaX extension for subspace discovery relies on assumptions about the linear structure of transport phenomena that may not generalize to all real-world shifts.

## Next Checks

1. **Conservation Verification:** Apply WaX to synthetic datasets with known distances and verify that summed relevances exactly equal the computed Wasserstein distance across varying dataset sizes and parameter settings.
2. **Solver Sensitivity:** Compare WaX attributions using exact vs. regularized (Sinkhorn) optimal transport solvers to quantify the impact of solver choice on explanation quality.
3. **Factor Correlation Test:** Apply U-WaX to datasets with known correlated factors (e.g., height and weight) to assess whether the subspace discovery can handle non-orthogonal underlying phenomena.