---
ver: rpa2
title: 'DATS: Distance-Aware Temperature Scaling for Calibrated Class-Incremental
  Learning'
arxiv_id: '2509.21161'
source_url: https://arxiv.org/abs/2509.21161
tags:
- calibration
- task
- temperature
- classes
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of post-hoc uncertainty calibration
  in continual learning, where models learn incrementally from sequences of new classes
  and suffer from catastrophic forgetting. Existing calibration methods rely on a
  single shared temperature across tasks, ignoring task-specific variability and leading
  to unstable calibration errors.
---

# DATS: Distance-Aware Temperature Scaling for Calibrated Class-Incremental Learning

## Quick Facts
- arXiv ID: 2509.21161
- Source URL: https://arxiv.org/abs/2509.21161
- Reference count: 23
- Addresses post-hoc uncertainty calibration in continual learning, reducing calibration error fluctuations across tasks

## Executive Summary
This paper tackles the challenge of post-hoc uncertainty calibration in class-incremental learning, where models learn from sequences of new classes and suffer from catastrophic forgetting. Existing calibration methods rely on a single shared temperature across tasks, leading to unstable calibration errors due to task-specific variability. The authors propose Distance-Aware Temperature Scaling (DATS), which infers task proximity using prototype-based distance estimation from a calibration buffer and assigns adaptive temperatures without requiring task labels at test time. Empirical evaluation on standard image benchmarks and imbalanced biomedical datasets demonstrates consistent reduction in miscalibration across tasks.

## Method Summary
DATS introduces a novel approach to temperature scaling for calibrated class-incremental learning by incorporating task proximity information. The method maintains a small calibration buffer and computes prototype-based distances between tasks to infer their relative proximity. Instead of using a single global temperature, DATS assigns adaptive temperatures to different tasks based on their estimated distance from previously seen tasks. This distance-aware mechanism enables more stable calibration across the continual learning sequence without requiring task labels during inference, addressing the limitations of existing post-hoc calibration techniques that ignore task-specific variability.

## Key Results
- DATS consistently reduces miscalibration across tasks compared to state-of-the-art approaches
- The method avoids large fluctuations in calibration error that plague existing techniques
- Demonstrated effectiveness on both standard image classification benchmarks and imbalanced biomedical datasets
- Shows particular advantage in safety-critical deployment scenarios where calibration stability is crucial

## Why This Works (Mechanism)
DATS works by recognizing that different tasks in continual learning have varying degrees of similarity, which existing calibration methods ignore by using a single shared temperature. By estimating task proximity through prototype-based distances from a calibration buffer, DATS can assign appropriate temperatures that reflect the underlying task structure. This distance-aware calibration prevents the instability observed when applying uniform calibration across heterogeneous tasks, leading to more reliable uncertainty estimates throughout the learning sequence.

## Foundational Learning
- **Class-Incremental Learning**: Learning new classes sequentially without revisiting old ones; needed to understand the continual learning setting and catastrophic forgetting problem
- **Temperature Scaling**: Post-hoc method for calibrating model confidence scores; quick check: verify it improves reliability by scaling logits
- **Calibration Buffer**: Small set of stored examples used for calibration; quick check: ensure buffer is representative of the task distribution
- **Prototype-Based Distance**: Distance measure using class prototypes; quick check: validate distance correlates with task similarity
- **Catastrophic Forgetting**: Phenomenon where models forget previous tasks when learning new ones; quick check: monitor performance on old tasks
- **Uncertainty Calibration**: Aligning predicted confidence with true correctness probability; quick check: use metrics like Expected Calibration Error (ECE)

## Architecture Onboarding
- **Component Map**: Input Images -> Feature Extractor -> Classifier -> Calibration (DATS) -> Calibrated Probabilities
- **Critical Path**: Feature extraction → classification → temperature scaling (with distance estimation) → calibrated output
- **Design Tradeoffs**: Fixed vs adaptive temperatures; using task labels vs distance estimation; buffer size vs calibration quality
- **Failure Signatures**: Large calibration error fluctuations across tasks; poor performance on buffer samples; miscalibration on imbalanced datasets
- **First Experiments**: 1) Evaluate calibration error stability across tasks, 2) Compare with baseline temperature scaling methods, 3) Test on imbalanced datasets

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Unclear robustness when applied to non-image domains beyond vision tasks
- Limited ablation study on distance function and buffer size sensitivity
- Performance under extreme class imbalance or very long task sequences not extensively explored
- Computational overhead during inference not analyzed, potentially limiting deployment in resource-constrained settings

## Confidence
- Image classification benchmarks (CIFAR-10, CIFAR-100, TinyImageNet): High
- Imbalanced biomedical datasets (BloodCell, SkinLesions): Medium
- Scalability to long task sequences and extreme imbalance: Low
- Computational efficiency at inference: Low

## Next Checks
1. Evaluate DATS on non-image domains (e.g., NLP or tabular data) to test generalizability beyond vision tasks
2. Systematically vary the calibration buffer size and distance function alternatives to assess robustness and sensitivity
3. Measure and report inference-time computational overhead to quantify practical deployment feasibility