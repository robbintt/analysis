---
ver: rpa2
title: Memory-Centric Embodied Question Answering
arxiv_id: '2505.13948'
source_url: https://arxiv.org/abs/2505.13948
tags:
- memory
- question
- information
- answering
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses inefficiencies in Embodied Question Answering
  (EQA) by introducing a memory-centric framework that integrates structured memory
  storage, dynamic updating, and adaptive retrieval across all modules (planner, stopping,
  answering). It employs viewpoint-contrastive memory updates and entropy-based retrieval
  to ensure minimal yet sufficient information for reasoning.
---

# Memory-Centric Embodied Question Answering

## Quick Facts
- arXiv ID: 2505.13948
- Source URL: https://arxiv.org/abs/2505.13948
- Reference count: 40
- Introduces MT-HM3D benchmark with 1,587 QA pairs for multi-target memory-requiring EQA tasks

## Executive Summary
This paper addresses fundamental inefficiencies in Embodied Question Answering by introducing a memory-centric framework that integrates structured memory storage, dynamic updating, and adaptive retrieval across all agent modules. The approach employs viewpoint-contrastive memory updates and entropy-based retrieval to ensure minimal yet sufficient information for reasoning. The proposed MT-HM3D benchmark specifically evaluates multi-target memory requirements. Experiments demonstrate significant improvements over baselines, achieving 9.9% higher success rates on MT-HM3D and state-of-the-art performance on OpenEQA.

## Method Summary
The method integrates a memory module across all EQA components (planner, stopping, answering) rather than limiting it to the answering module. The memory system stores structured observations as vector embeddings and retrieves them via entropy-adaptive queries. Updates use viewpoint-contrastive rules based on position, rotation, and similarity thresholds to prevent redundancy. The planner uses memory to avoid revisiting explored regions, the stopping module checks if relevant information has been gathered, and the answering module grounds responses in accumulated observations. The framework employs YOLOv11 for object detection, CLIP-ViT-Large for unified encoding, and Faiss for vector search.

## Key Results
- 9.9% improvement in success rate on MT-HM3D benchmark
- 9.1% improvement on HM-EQA benchmark
- Achieves state-of-the-art performance on OpenEQA dataset
- Reduces normalized steps from 0.61 to 0.40 on MT-HM3D through memory-guided exploration

## Why This Works (Mechanism)

### Mechanism 1: Cross-Module Memory Integration
Providing memory access to all modules reduces redundant exploration by enabling each component to make informed decisions. The planner uses historical context to avoid re-exploring known regions, the stopping module checks if question-relevant information has already been gathered, and the answering module grounds responses in accumulated observations. Evidence shows S+A+P configuration achieves 41.95% success on MT-HM3D versus 30.22% baseline.

### Mechanism 2: Viewpoint-Contrastive Memory Update
A three-rule gating mechanism prevents redundant memory entries while capturing novel observations. Updates trigger only when position/rotation thresholds are exceeded AND similarity checks pass, with existing entries replaced rather than appended. This approach controls memory library size while maintaining relevant information. The combination of SSIM and semantic feature similarity effectively identifies redundant observations.

### Mechanism 3: Entropy-Based Adaptive Retrieval
Query feature entropy dynamically adjusts retrieval threshold and k-value to retrieve "minimal yet sufficient" memory. High entropy queries (ambiguous) retrieve broader memory sets while low entropy queries (specific) use tighter matching. This prevents both information loss from overly strict retrieval and noise from overly broad retrieval. K=4 is optimal for fixed settings, but adaptive selection improves performance without manual tuning.

## Foundational Learning

- **Frontier-based exploration**: Understanding frontier cells (free cells adjacent to unknown cells) is prerequisite to understanding how memory modifies exploration decisions. Quick check: Given a 2D occupancy grid, can you identify frontier cells and rank them by information gain vs. navigation cost?

- **Retrieval-Augmented Generation (RAG) for multimodal data**: The memory module stores structured text + image features and retrieves via cosine similarity. Quick check: How would you construct a query embedding that retrieves memories semantically related to "blue sofa in living room"?

- **Structural Similarity Index (SSIM)**: Memory update rule integrates SSIM with semantic similarity for perceptual image comparison. Quick check: Why might SSIM alone fail to detect semantic duplicates (e.g., same object from different angles), and how does the paper address this?

## Architecture Onboarding

- **Component map**: Observation → Object detection → Structured text generation → Memory update check → Memory retrieval (per module) → VLM inference → Action/Answer
- **Critical path**: The agent continuously updates memory based on new observations, retrieves relevant memories for each module's specific query, and uses the combined context for VLM reasoning to make navigation or answering decisions
- **Design tradeoffs**: Fixed vs. dynamic k (fixed simpler but suboptimal); replace vs. append on update (replace controls size but may discard context); per-module queries vs. shared query (per-module more precise but complex)
- **Failure signatures**: Redundant exploration (planner ignores memory), premature stopping (stopping module retrieves insufficient memory), memory bloat (update thresholds too loose), empty retrieval (entropy thresholds too strict)
- **First 3 experiments**:
  1. Reproduce ablation on MT-HM3D with memory disabled for each module to validate cross-module contribution (~11% success gain expected)
  2. Sensitivity analysis on update thresholds (β_p: 1m-10m, β_r: 5°-30°) to identify stable operating region
  3. K-value validation on MT-HM3D (k ∈ {0, 2, 4, 8, 12}) to confirm K≈4 optimal, then enable entropy-based k to verify performance

## Open Questions the Paper Calls Out

### Open Question 1
How can a dynamic memory window be implemented to replace fixed K-value retrieval strategies to better adapt to varying query complexities? The current entropy-based linear adjustment may not be optimal, as fixed K values often lead to suboptimal performance. Evidence would come from comparative study of adaptive K-selection algorithms against current baseline on MT-HM3D.

### Open Question 2
Can memory retrieval be optimized to better exploit Spatial LLMs' spatial reasoning capabilities? Current retrieval may fail to trigger spatial potential of these models. Evidence would come from ablation study with memory queries structured to extract spatial relations rather than object attributes on MT-HM3D "Relationship" category.

### Open Question 3
To what extent does the viewpoint-contrastive update rule degrade in highly dynamic environments with frequent object appearance changes? Current rule may fail to distinguish legitimate environment changes from perceptual noise. Evidence would come from evaluation of memory update success rate in simulated environment with moving objects or lighting changes.

## Limitations

- Data accessibility concerns: MT-HM3D dataset construction described but availability unclear, with manual filtering step introducing reproducibility risk
- Cross-module memory contribution isolation: Individual module contributions not independently validated beyond current S→S+A→S+A+P ablation
- Threshold sensitivity: Viewpoint-contrastive update parameters and entropy thresholds may not generalize across environment scales without recalibration

## Confidence

- **High confidence**: Cross-module memory integration reduces redundant exploration (supported by 9.9% success gain and step reduction metrics)
- **Medium confidence**: Viewpoint-contrastive update prevents memory bloat while capturing novel observations (partially supported by ablation)
- **Low confidence**: Entropy-based adaptive retrieval consistently improves performance across query types (limited by single dataset evaluation)

## Next Checks

1. **Memory access isolation test**: Disable memory for each module independently on MT-HM3D to quantify individual contributions beyond current ablation

2. **Threshold generalization study**: Evaluate memory update thresholds and entropy parameters across HM-EQA and OpenEQA environments to assess cross-dataset robustness

3. **Memory library size analysis**: Monitor vector library growth during MT-HM3D episodes and measure retrieval latency to confirm replace-on-update strategy effectively controls memory footprint without degrading performance