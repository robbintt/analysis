---
ver: rpa2
title: Merging of Kolmogorov-Arnold networks trained on disjoint datasets
arxiv_id: '2512.18921'
source_url: https://arxiv.org/abs/2512.18921
tags:
- training
- number
- kans
- layer
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes strategies to accelerate training of Kolmogorov-Arnold
  networks (KANs) using the Newton-Kaczmarz method. Three main improvements are introduced:
  (i) a pre-training procedure tailored to the NK update structure, (ii) concurrent
  training on disjoint data subsets with subsequent model merging, and (iii) FPGA-based
  parallelisation.'
---

# Merging of Kolmogorov-Arnold networks trained on disjoint datasets

## Quick Facts
- **arXiv ID:** 2512.18921
- **Source URL:** https://arxiv.org/abs/2512.18921
- **Reference count:** 17
- **Primary result:** Up to 30× speedup via concurrent training on disjoint datasets with parameter averaging

## Executive Summary
This paper introduces a method to accelerate Kolmogorov-Arnold network (KAN) training using the Newton-Kaczmarz optimization approach. The key innovation is concurrent training on disjoint data subsets followed by parameter averaging, which achieves significant speedups while maintaining comparable accuracy. The approach is validated across three benchmark datasets with speedups reaching 30× over sequential CPU execution. An FPGA implementation demonstrates hardware-level acceleration potential with sub-millisecond training times.

## Method Summary
The method trains multiple copies of a KAN model concurrently on disjoint data partitions using the Newton-Kaczmarz (NK) update rule. Each model processes its assigned batch independently using piecewise-linear basis functions. After each training pass, models are merged through simple parameter averaging. This process repeats for multiple rounds until convergence. The approach exploits KAN's additive structure where parameters represent basis function values at interpolation nodes, making averaging a natural merge operation. An FPGA implementation achieves fixed, low-latency processing by exploiting the independence of basis function evaluations within each layer.

## Key Results
- 30× speedup achieved on Det5 dataset (10M records) using 6 threads
- Pearson correlation maintained at 96.8% (vs 97.1% sequential baseline) for Det4 with 6 threads
- FPGA implementation achieves 0.06144 ms execution time per record on modest hardware
- Near-linear strong and weak scaling demonstrated across increasing thread counts

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** KANs trained on disjoint subsets can be merged via simple parameter averaging with controlled accuracy loss.
- **Mechanism:** KAN parameters represent values of basis functions at interpolation nodes. Since the underlying functions g_i,j are additive, averaging node values across models trained on different subsets approximates the function that would be learned from the union of data.
- **Core assumption:** Each disjoint subset is sufficiently representative of the modeled system's input-output distribution.
- **Evidence anchors:**
  - [abstract] "KANs are particularly well suited for federated learning and can be merged through simple parameter averaging."
  - [section 3.2] "The models are merged into a single model simply by computing the mean value of every parameter."
  - [corpus] Moderate support: Federated KAN papers corroborate that KANs support averaging-based aggregation.
- **Break condition:** Accuracy degrades as batch count increases (Table 3: 96.8% → 94.5% from 1 to 6 threads).

### Mechanism 2
- **Claim:** The Newton-Kaczmarz method with piecewise-linear bases enables fast, layer-wise sequential updates that parallelize across data records.
- **Mechanism:** NK updates parameters record-by-record using local linear approximations, avoiding expensive gradient computations. This structure allows different model copies to process different records independently between merge points.
- **Core assumption:** The sequential dependency of updates can be relaxed by periodic synchronization without fundamentally breaking convergence.
- **Evidence anchors:**
  - [section 2] Describes the update rules: "G_new = G_old + μ(z_i - ẑ_i)(1-f)" and Jacobian-based target propagation.
  - [section 3.1] Notes convergence was proven in prior work [3].
  - [corpus] Weak: Corpus papers focus on federated aggregation strategies, not the NK optimizer specifically.
- **Break condition:** If merges are too infrequent relative to dataset size, parallel models diverge; if too frequent, synchronization overhead dominates.

### Mechanism 3
- **Claim:** FPGA implementation achieves fixed, low-latency processing per record by exploiting independence of basis function evaluations within each layer.
- **Mechanism:** Within a layer, each g_i,j(y_j) is independent, enabling concurrent evaluation. Sequential stages are bounded by layer count, not layer size. Fixed-point arithmetic with power-of-2 divisions (bit shifts) avoids expensive operations.
- **Core assumption:** Piecewise-linear bases are acceptable for the application, or can be post-converted to smoother bases.
- **Evidence anchors:**
  - [section 3.3] "Each layer of KAN consists in evaluation of the independent functions... can be performed concurrently."
  - [section 4.5] "6144 cycles... at 100 MHz... execution time is 0.06144 ms."
  - [corpus] Weak: Corpus mentions KANELE for inference acceleration but not on-device training.
- **Break condition:** Model size exceeds available FPGA resources.

## Foundational Learning

- **Concept:** KAN architecture as additive function composition
  - **Why needed here:** Understanding equations 1-2 is essential before reasoning about merging. KANs compute outputs by summing learned univariate functions of each input, unlike MLPs that multiply learned weights.
  - **Quick check question:** Given a 2-layer KAN with 3 inputs and 2 outputs in the first layer, how many functions g_i,j must be learned?

- **Concept:** Kaczmarz method for solving linear systems
  - **Why needed here:** The NK training method iteratively projects onto solution hyperplanes defined by each training record. This differs fundamentally from gradient descent and explains why sequential processing is natural but parallelization requires merging.
  - **Quick check question:** Why does the Kaczmarz method update one record at a time rather than using batches?

- **Concept:** Fixed-point arithmetic and bit shifts for division
  - **Why needed here:** FPGA efficiency depends on avoiding floating-point and division. Choosing Δy as a power of 2 enables binary shifts.
  - **Quick check question:** If Δy = 0.125, what bit-width and shift amount would you use for a 16-bit fixed-point representation?

## Architecture Onboarding

- **Component map:**
  Training Loop -> Data Partitioner -> Model Replicator -> Parallel Trainers -> Merger -> Convergence Check
  
  FPGA Data Path (per record) -> Input -> Forward Pass -> Residual Compute -> Backward Pass -> Parameter Update

- **Critical path:**
  1. Pre-train two-layer submodels to initialize deeper networks
  2. Partition data into representative batches
  3. Run parallel NK training for one pass per batch
  4. Merge via parameter averaging
  5. Repeat rounds until validation metric threshold

- **Design tradeoffs:**
  | Choice | Increases | Decreases |
  |--------|-----------|-----------|
  | More threads | Speedup | Accuracy (merging noise) |
  | Larger batches | Accuracy per round | Parallelism |
  | More rounds | Final accuracy | Total speedup |
  | FPGA vs CPU | Latency per record | Model size flexibility |

- **Failure signatures:**
  - Accuracy plateaus below target: batch size too small, subsets non-representative
  - Speedup saturates before expected: synchronization (merge) overhead dominates
  - FPGA timing violations: combinational path too long; reduce precision or pipeline stages
  - Training diverges: learning rate (μ) too high for fixed-point representation

- **First 3 experiments:**
  1. **Baseline single-thread:** Run Det4 example with provided C++ code, confirm ~6.5s, ~97% Pearson.
  2. **Strong scaling sweep:** On 1-6 threads, measure time and accuracy for fixed total records. Identify the thread count where accuracy drop exceeds acceptable threshold.
  3. **Batch size sensitivity:** Fix thread count at 4, vary batch size from 3K to 50K records. Plot accuracy vs. speedup to find the Pareto frontier.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the theoretical or heuristic relationship between the number of batches, batch size, and the optimal convergence rate for a given dataset?
- **Basis in paper:** [explicit] The authors state, "Therefore, there should be an optimal number of batches," noting performance depends on these parameters, but provide only empirical tuning.
- **Why unresolved:** The paper tests specific combinations but does not derive a generalizable rule for selecting these parameters a priori.
- **What evidence would resolve it:** A mathematical derivation or heuristic predicting the optimal batch configuration based on dataset statistics.

### Open Question 2
- **Question:** Can the accuracy degradation caused by increasing the number of parallel batches be mitigated through alternative merging algorithms?
- **Basis in paper:** [explicit] The authors note, "one may expect increasing error with the number of batches," observing accuracy drops (e.g., 96.8% to 94.5%) currently compensated by increasing epochs.
- **Why unresolved:** The current method relies on simple parameter averaging; it is unknown if weighted averaging or other strategies could preserve accuracy without extra computation.
- **What evidence would resolve it:** Demonstration of a merging strategy that maintains high accuracy at high thread counts without increasing the number of training rounds.

### Open Question 3
- **Question:** Does the fixed-point FPGA implementation maintain accuracy and resource efficiency when scaling to the larger models (e.g., Det5) used in software benchmarks?
- **Basis in paper:** [inferred] The FPGA tests were limited to small datasets while software tests included large-scale tasks like Det5.
- **Why unresolved:** It is unverified if the fixed-point arithmetic approximations and hardware resource constraints limit the scalability of the hardware implementation.
- **What evidence would resolve it:** Successful synthesis and benchmarking of the FPGA implementation on the Det5 dataset with a comparison of resource utilization.

## Limitations
- Accuracy degradation occurs as thread count increases (96.8% → 94.5% from 1 to 6 threads)
- Critical hyperparameters (learning rate, initialization, pre-training configurations) are underspecified
- Assumes data partitions are sufficiently representative; non-IID distributions may cause merging artifacts

## Confidence
- **High Confidence:** The basic mechanism of parallel training with periodic merging is valid and demonstrably effective for speedups up to 30×
- **Medium Confidence:** The accuracy-speedup tradeoff curve is well-characterized but dataset-dependent
- **Low Confidence:** Long-term convergence behavior beyond tested epoch ranges is not established

## Next Checks
1. **Convergence stability test:** After achieving target accuracy through merging, continue training the merged model for 50+ additional epochs to verify that accuracy does not degrade or oscillate
2. **Non-IID partition robustness:** Create deliberately skewed data partitions and measure accuracy degradation compared to IID splits
3. **Architecture scaling study:** Test the method on deeper KANs (3+ layers) and wider networks to identify scaling limits and potential bottlenecks in the merging process