---
ver: rpa2
title: Improving LLMs with a knowledge from databases
arxiv_id: '2506.05560'
source_url: https://arxiv.org/abs/2506.05560
tags:
- rules
- knowledge
- association
- llms
- will
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes enhancing LLM performance on database queries
  by integrating interpretable knowledge from enhanced association rules. The authors
  extract rules from datasets using the CleverMiner package, convert them into natural
  language sentences, and embed them into LLMs via Retrieval-Augmented Generation
  (RAG).
---

# Improving LLMs with a knowledge from databases

## Quick Facts
- arXiv ID: 2506.05560
- Source URL: https://arxiv.org/abs/2506.05560
- Authors: Petr Máša
- Reference count: 5
- Primary result: RAG-enhanced method significantly improves answer quality for complex multi-attribute queries and is safer by avoiding runtime code execution.

## Executive Summary
This paper proposes enhancing LLM performance on database queries by integrating interpretable knowledge from enhanced association rules. The authors extract rules from datasets using the CleverMiner package, convert them into natural language sentences, and embed them into LLMs via Retrieval-Augmented Generation (RAG). They evaluate this approach using a UK traffic accident dataset and compare it with ChatGPT using agents. The results show that the RAG-enhanced method significantly improves answer quality, particularly for complex multi-attribute queries, with notable improvements in zero-shot performance. The method is also safer as it avoids running external code.

## Method Summary
The method involves mining enhanced association rules from a UK traffic accident dataset using CleverMiner with the 4ft-Miner pattern. Rules are filtered by support and "above average difference" (aad) thresholds, then converted to natural language sentences via a Rule-to-Text module. These sentences are embedded into an RAG system, which retrieves relevant rules when users ask similar questions. The LLM then generates answers based on the retrieved rules, avoiding the need for runtime code execution or fine-tuning.

## Key Results
- RAG-enhanced method significantly improves answer quality for complex multi-attribute queries compared to ChatGPT with agents.
- Zero-shot performance is notable, with a small model (deepseek 1.5B) providing useful answers without agents or fine-tuning.
- The method is safer as it eliminates runtime code execution, reducing risks of harmful code or syntax errors.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pre-computing statistical relationships as natural language rules enables LLMs to answer complex multi-attribute queries without runtime code execution.
- **Mechanism:** Enhanced association rules extract conditional relationships from data with quantifiers like confidence and "above average difference" (aad). These are converted to sentences ("If X then Y occurs more likely") and retrieved via RAG when semantically similar questions are asked. This bypasses the need for the LLM to perform multi-attribute aggregation or join operations at inference time.
- **Core assumption:** The LLM can correctly interpret natural-language-encoded statistical relationships without further numerical reasoning.
- **Evidence anchors:** [abstract] "The results show that the RAG-enhanced method significantly improves answer quality, particularly for complex multi-attribute queries." [section 3, methodology] Describes the pipeline: rule mining → text conversion → RAG embedding; shows example rule transformation from `Driver_Age_Band(16-20 21-25 26-35) & Sex(Male) & Area(2,Rural) => Severity(Fatal)` to natural sentence. [corpus] No direct corpus support for association-rule-to-RAG pipelines; related RAG papers focus on document retrieval, not structured rule extraction.
- **Break condition:** If queries require numerical precision beyond relative terms ("more likely"), the coarse quantifier-to-language mapping may degrade accuracy.

### Mechanism 2
- **Claim:** Zero-shot improvement emerges because rule sentences use the same token vocabulary as natural questions, improving embedding similarity and retrieval relevance.
- **Mechanism:** The Rule-to-Text module transforms categorical conditions (e.g., "Speed_limit(60)", "Sex(Male)") into natural phrases ("speed limit is 60", "driver is Male"). When users ask similar questions, the embedding overlap between query and rule-sentences increases, enabling correct retrieval without fine-tuning.
- **Core assumption:** The embedding model captures semantic equivalence between user queries and rule sentences despite phrasing differences.
- **Evidence anchors:** [section 3, p.8] "This way of separating categories uses the same tokens, so it might also be beneficial for RAG embeddings." [section 4.3, experiments] Deepseek 1.5B with RAG provided useful zero-shot answers with only 21 rules, without agents or fine-tuning. [corpus] Parametric RAG (arXiv:2501.15915) discusses embedding-based retrieval optimization but not rule-to-text token alignment.
- **Break condition:** If rule sentences are overly technical or use non-intuitive phrasing, retrieval relevance may drop.

### Mechanism 3
- **Claim:** Eliminating runtime code execution (via agents) reduces safety risks while maintaining query capability through pre-computed knowledge.
- **Mechanism:** Traditional agent-based systems generate and execute SQL or Python at query time, risking harmful code, syntax errors, or resource overload. The proposed method pre-computes all patterns offline and serves them as static text via RAG, removing the execution surface entirely.
- **Core assumption:** The pre-computed rule set covers the query distribution sufficiently; queries outside the rule patterns will fail gracefully.
- **Evidence anchors:** [abstract] "The method is also safer as it avoids running external code." [section 1, introduction] "risks of inappropriate queries built by automated way (syntactically incorrect, not powerful enough or even risk of harmful code generation)." [corpus] RAG-Stack (arXiv:2510.20296) discusses RAG quality but does not address safety from code execution.
- **Break condition:** If users require ad-hoc aggregations not covered by pre-mined rules (e.g., "average accident count per hour on Tuesdays"), the system cannot answer without fallback to agents.

## Foundational Learning

- **Concept:** Association rules and quantifiers (support, confidence, lift, aad)
  - **Why needed here:** Understanding how rules represent statistical relationships and how "above average difference" (aad) captures relative risk compared to baseline.
  - **Quick check question:** Given a rule with confidence 3.0% and baseline 1.9%, what is the aad? (Answer: ~0.58 or 58% increase)

- **Concept:** RAG architecture (chunking, embedding, retrieval)
  - **Why needed here:** The method relies on RAG to retrieve relevant rule sentences; understanding context window limits and retrieval ranking is essential.
  - **Quick check question:** Why are documents split into overlapping chunks in RAG? (Answer: To ensure relevant context isn't split across chunk boundaries and to fit within context window limits.)

- **Concept:** Enhanced association rules (4ft-Miner pattern)
  - **Why needed here:** The paper uses 4ft-Miner, which supports conjunctions, disjunctions, and interval literals—not just simple itemsets.
  - **Quick check question:** What does `Driver_Age_Band(16 - 20 21 - 25 26 - 35)` represent in a 4ft-Miner antecedent? (Answer: A disjunction or sequence of age bands, interpretable as ages 16-35.)

## Architecture Onboarding

- **Component map:** Source database → CleverMiner (rule mining with 4ft-Miner pattern, quantifier thresholds) → Rule list (e.g., 511 rules) → Rule-to-Text converter (natural language sentences) → Text document → RAG system (embedding + retrieval) → LLM (generates answer from retrieved rules)

- **Critical path:** Rule mining quality (pattern coverage, quantifier thresholds) → Sentence clarity (token alignment with query vocabulary) → RAG retrieval relevance → LLM synthesis accuracy

- **Design tradeoffs:**
  - **Rule count vs. specificity:** Fewer rules (e.g., 21 with base≥4000, aad≥1.3) yield specific but narrow coverage; more rules (e.g., 7224 with base≥300, aad≥0.5) yield broader coverage but more generic answers.
  - **Quantifier thresholds:** Higher aad filters for stronger effects but may miss nuanced patterns; lower aad includes weaker signals, increasing noise.
  - **Safety vs. flexibility:** Pure RAG is safer but less flexible than agents; hybrid approaches (rule mining as an agent) could combine both.

- **Failure signatures:**
  - **Too few rules:** Answers are overly specific, missing general patterns (observed with 21 rules).
  - **Too many rules:** Answers become generic; LLM defaults to single-attribute summaries rather than multi-attribute combinations (observed with 7224 rules).
  - **Poor rule-to-text mapping:** If sentences use technical notation instead of natural language, retrieval and LLM interpretation degrade.

- **First 3 experiments:**
  1. **Baseline test:** Upload dataset to ChatGPT with agents; ask "On which circumstances occur fatal accidents more than usual?" Expect 1D profiling, limited multi-attribute insight.
  2. **RAG-enhanced test:** Upload rule-sentence document to ChatGPT via RAG; ask same question. Expect identification of multi-attribute combinations (e.g., "male, rural, motorcycle >500cc").
  3. **Small-model test:** Use local model (e.g., deepseek 1.5B) with RAG and rule document; compare answer quality to ChatGPT with agents to validate zero-shot improvement without agents.

## Open Questions the Paper Calls Out
None

## Limitations
- Rule coverage depends entirely on pre-mining; queries requiring ad-hoc aggregations or non-mined attribute combinations cannot be answered without fallback agents.
- The RAG-retrieved rules are still subject to the LLM's reasoning limits—if the rules are too abstract or phrased ambiguously, synthesis may fail.
- The method assumes categorical data; continuous variables must be binned, which can obscure fine-grained patterns.

## Confidence
- **High confidence:** The safety benefit of eliminating runtime code execution is clearly supported by the design and stated motivation.
- **Medium confidence:** The qualitative improvement in answer quality for complex multi-attribute queries is demonstrated but not quantitatively measured; the single user question limits generalizability.
- **Medium confidence:** Zero-shot performance gains are observed in the small-model experiment but would benefit from broader evaluation across more models and datasets.

## Next Checks
1. **Quantify improvement:** Apply a structured evaluation (e.g., answer relevance scoring by multiple raters) to measure the magnitude of quality gains over agents.
2. **Test robustness:** Evaluate the method on datasets with mixed categorical and continuous variables to assess binning impact on rule quality.
3. **Validate coverage:** Identify and attempt to answer queries outside the mined rule patterns to characterize failure modes and determine when agents remain necessary.