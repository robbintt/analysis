---
ver: rpa2
title: 'InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large
  Language Models'
arxiv_id: '2501.12231'
source_url: https://arxiv.org/abs/2501.12231
tags:
- tasks
- video
- task
- conference
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InsTALL is a context-aware instructional video assistant that integrates
  procedural task graphs with multimodal large language models to enable real-time
  assistance for multi-step tasks. By leveraging a procedural graph constructed from
  instructional videos, InsTALL enhances task recognition, action recognition, action
  prediction, and plan prediction capabilities beyond what LLMs can achieve alone.
---

# InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models

## Quick Facts
- arXiv ID: 2501.12231
- Source URL: https://arxiv.org/abs/2501.12231
- Reference count: 40
- Key outcome: Context-aware instructional video assistant that integrates procedural task graphs with multimodal LLMs to achieve state-of-the-art performance on task recognition, action recognition, action prediction, plan prediction, and error detection tasks.

## Executive Summary
InsTALL is a context-aware instructional video assistant that leverages procedural task graphs constructed from instructional videos to enhance multi-modal large language models (MLLMs) for real-time task assistance. By injecting explicit graph context during both training and inference, InsTALL significantly improves performance on five main tasks (task recognition, action recognition, action prediction, plan prediction, and plan prediction+) and two error detection tasks. The system demonstrates state-of-the-art accuracy on both COIN and CrossTask datasets, with 98.9% task recognition accuracy on COIN and 99.6% on CrossTask. The approach reduces the reasoning burden on LLMs by providing structured context, making it a robust solution for visually aware task assistance.

## Method Summary
InsTALL combines CLIP ViT-L-336 visual encoder, temporal pooling, 2-layer MLP projector, and Mistral-7B-Instruct LLM with LoRA (rank=128, scaling=256) to create a unified multi-task model. The system constructs procedural task graphs from training videos, where nodes represent step annotations and edges represent temporal transitions. At inference, it maintains an online sub-path through the graph by mapping predicted action text to graph nodes via one-hot similarity. The model is trained on 245K multi-task samples with task-specific prompts for different objectives, using cross-entropy losses. Training involves 2 epochs with batch size 128 and gradient accumulation of 16, taking approximately 12 hours on 8×A100 GPUs.

## Key Results
- Achieves 98.9% task recognition accuracy on COIN and 99.6% on CrossTask
- Outperforms existing methods across five main tasks and two error detection tasks
- Spatial pooling outperforms flatten/average aggregation in temporal processing
- Graph injection significantly improves performance compared to LLM-only approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting explicit procedural task graph G into MLLM context reduces reasoning burden and improves recognition/prediction performance versus relying on LLM's internal planning.
- Mechanism: Constructs directed graph G=(V_G, E_G) from training videos, maintains online sub-path Ĝ_t by mapping predicted action text to graph nodes via one-hot similarity, and conditions generation on visual/textual inputs and current graph context.
- Core assumption: MLLM can reliably map free-form text outputs to graph nodes and graph structure generalizes to unseen test videos.
- Evidence anchors: Abstract mentions automatic graph extraction; Section 4.2 describes graph injection; related work (TaskGraph [7]) uses graphs without MLLM integration.

### Mechanism 2
- Claim: Single MLLM with task-specific prompts and LoRA adapters enables unified multi-task performance without catastrophic forgetting.
- Mechanism: Uses distinct prompts (Q_TR, Q_AR, Q_AP, Q_PP) to steer model behavior, optimizes cross-entropy objectives for each task, and applies LoRA to all linear layers in Mistral-7B-Instruct.
- Core assumption: Task prompts sufficiently disambiguate objectives and LoRA capacity is adequate without overfitting.
- Evidence anchors: Section 3 defines objectives and Section 4.1 details LoRA configuration.

### Mechanism 3
- Claim: Procedural graph enables synthesis of diverse dialogue templates (negative-choice, multiple-choice) creating richer training data for online streaming assistance.
- Mechanism: Traverses graph to generate multi-turn dialogues with negative nodes and multiple-choice samples from neighbors, training model to respond appropriately.
- Core assumption: Graph structure yields plausible negative and alternative steps reflecting real user interactions.
- Evidence anchors: Abstract mentions real-time user query response; Section 4.3 describes dialog templates and Section 4.4 covers error detection tasks.

## Foundational Learning

- Concept: **Procedural Graphs (Task Graphs)**
  - Why needed here: Core to InsTALL's context injection; encodes step sequences and dependencies extracted from instructional videos.
  - Quick check question: Given a cooking task video, can you list nodes as steps (e.g., "crack egg") and edges as observed transitions?

- Concept: **Multi-modal LLM Adapter Architectures (e.g., LLaVA-style)**
  - Why needed here: InsTALL uses visual encoder + temporal aggregator + MLP projector + LLM backbone; understanding token flow is essential.
  - Quick check question: Explain how CLIP ViT-L frame embeddings are projected to LLM token space via MLP and interleaved with text tokens.

- Concept: **Parameter-Efficient Fine-Tuning (LoRA)**
  - Why needed here: Enables training on 245K multi-task samples without full retraining; rank/scaling choice is critical.
  - Quick check question: Describe how LoRA adds low-rank matrices to linear layers and how rank=128, scaling=256 affects capacity.

## Architecture Onboarding

- Component map:
  CLIP ViT-L-336 → temporal pooling → 2-layer MLP → Mistral-7B-Instruct with LoRA → text response

- Critical path:
  1. Video frames → CLIP → temporal pooling → MLP → frame tokens
  2. Frame tokens + task prompt tokens + (optional) graph context tokens → LLM
  3. LLM → text response → mapped to graph node (if building Ĝ_t) → update Ĝ for next step

- Design tradeoffs:
  - **Temporal Aggregation**: Pooling vs. flattening vs. averaging (Table 4)—pooling chosen to avoid overwhelming LLM
  - **Graph Source**: Full training set vs. retrieved videos vs. WikiHow (Table 6)—full set better for AP/PP; retrieved better for AR on COIN
  - **Backbone Size**: Mistral-7B vs. Llama-3-8B—smaller but competitive with graph augmentation

- Failure signatures:
  - **Node Mapping Failure**: Free-form text output doesn't match any graph node → Ĝ_t not updated → stale context
  - **Task Prompt Confusion**: Model outputs action prediction when asked for task recognition → prompt design issue
  - **Temporal Overload**: Using flatten aggregation (Table 4) → LLM overwhelmed, performance drops
  - **Graph Noise**: Incorrect edges from noisy annotations → erroneous plan prefixes → wrong predictions

- First 3 experiments:
  1. **Validate Temporal Aggregation**: Compare pooling vs. averaging vs. flattening on AR/AP/PP/TR using COIN
  2. **Ablate Graph Context**: Run InsTALL (VQ) vs. (VQG) on all tasks
  3. **Test Graph Source Sensitivity**: Build G from retrieved videos vs. full training set vs. WikiHow and evaluate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the compounding of errors across prediction steps be effectively mitigated to improve the efficacy of long-horizon plan prediction in procedural task assistants?
- Basis in paper: The authors state in the Future Works section that "errors compound across prediction steps, limiting their efficacy on plan prediction."
- Why unresolved: The auto-regressive nature of the model means early mistakes cascade into future predictions, and the paper does not propose a mechanism to correct this drift.
- What evidence would resolve it: A modified architecture or inference strategy (e.g., global re-planning or constrained beam search) that demonstrates stable performance over significantly longer task horizons without accuracy degradation.

### Open Question 2
- Question: What specific methods for incorporating structured knowledge could enable LLMs to more faithfully follow the dependencies encoded in procedural graphs?
- Basis in paper: The conclusion notes that "the model cannot faithfully follow the dependencies in the graph" and suggests improving ways to incorporate structured knowledge.
- Why unresolved: While the graph provides context, the LLM still generates tokens auto-regressively and can violate logical constraints provided by the graph structure.
- What evidence would resolve it: A training objective or attention mechanism that enforces graph constraints during generation, resulting in measurable reduction in invalid step transitions.

### Open Question 3
- Question: How robust is the node mapping mechanism when the LLM produces textual descriptions that deviate significantly from the fixed vocabulary of the pre-constructed procedural graph?
- Basis in paper: The method relies on one-hot similarity mapping to project free-form LLM text outputs onto graph nodes.
- Why unresolved: LLMs often produce synonyms or paraphrases; if generated text does not semantically match a node in V_G closely enough, online graph path construction may fail or select wrong node.
- What evidence would resolve it: An error analysis quantifying the rate of "mapping failures" where LLM's textual output falls outside acceptable similarity threshold for graph nodes.

## Limitations
- Graph construction quality heavily depends on consistency and accuracy of step annotations in training videos
- Effectiveness of task-specific prompts crucial but exact templates not fully specified
- Limited empirical evidence on efficacy of graph-synthesized dialogues for error detection

## Confidence
- **High Confidence**: Task Recognition (TR) and Action Recognition (AR) performance claims
- **Medium Confidence**: Action Prediction (AP) and Plan Prediction (PP) performance claims
- **Low Confidence**: Graph-synthesized dialogue quality and error detection task performance

## Next Checks
1. **Graph Construction Robustness**: Assess InsTALL's performance sensitivity to variations in procedural graph structure by injecting noise and evaluating impact on AP and PP tasks
2. **Prompt Design Ablation**: Perform systematic ablation study on task-specific prompts to test different formulations and measure impact on task disambiguation
3. **Dialogue Quality Assessment**: Evaluate quality of graph-synthesized dialogues through human evaluations or automated metrics to assess plausibility for error detection tasks