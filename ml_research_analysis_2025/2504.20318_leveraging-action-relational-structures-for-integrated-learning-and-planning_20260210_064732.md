---
ver: rpa2
title: Leveraging Action Relational Structures for Integrated Learning and Planning
arxiv_id: '2504.20318'
source_url: https://arxiv.org/abs/2504.20318
tags:
- search
- action
- heuristics
- state
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces partial-space search, a novel search space
  for classical planning that leverages the relational structure of PDDL action schemas.
  Unlike traditional state-space search, partial-space search explores the hierarchy
  of partially instantiated actions, allowing earlier pruning of poor actions and
  reducing branching factors.
---

# Leveraging Action Relational Structures for Integrated Learning and Planning

## Quick Facts
- arXiv ID: 2504.20318
- Source URL: https://arxiv.org/abs/2504.20318
- Reference count: 10
- Primary result: Introduces partial-space search that outperforms state-of-the-art ML-based heuristic on IPC 2023 learning track and surpasses LAMA on combined benchmarks

## Executive Summary
This paper introduces partial-space search, a novel search space for classical planning that leverages the relational structure of PDDL action schemas. Unlike traditional state-space search, partial-space search explores the hierarchy of partially instantiated actions, allowing earlier pruning of poor actions and reducing branching factors. The authors propose action set heuristics that evaluate sets of actions in a state, demonstrating how to convert existing heuristics and introducing novel graph representations for learning action set heuristics from scratch. The resulting planner, LazyLifted, achieves state-of-the-art performance on both IPC 2023 learning track benchmarks and high-branching factor domains.

## Method Summary
The paper proposes a novel planning approach that operates in a "partial-space" rather than traditional state-space. This method decomposes the planning process by instantiating action schemas parameter-by-parameter, creating a hierarchy of partial actions. To guide this search, the authors introduce action set heuristics that evaluate sets of actions rather than single actions. They demonstrate two approaches: restriction heuristics that modify the planning task to evaluate action sets, and learned graph-based heuristics using Weisfeiler-Lehman algorithms on Action-Object-Atom Graphs (AOAG) and Action Effect Graphs (AEG). The LazyLifted planner integrates partial-space search with learned action set heuristics, achieving superior performance on high-branching factor domains while maintaining competitive results on standard IPC benchmarks.

## Key Results
- LazyLifted outperforms state-of-the-art ML-based heuristic on IPC 2023 learning track benchmarks
- On combined IPC and high-branching factor benchmarks, partial-space search reduces branching factor by 88% while increasing expansions by ~7x
- LazyLifted surpasses LAMA performance on the combined benchmark set
- Training with partial-space search generates datasets that are on average 2.62 times larger, encoding more granular optimal decisions

## Why This Works (Mechanism)

### Mechanism 1: Branching Factor Decomposition via Partial Actions
Partial-space search improves efficiency in high-branching domains by breaking a single large expansion step into a hierarchy of smaller decisions, allowing for early pruning of sub-trees. Instead of generating all ground actions at once, it traverses a "partial action tree" by instantiating action schemas one parameter at a time. If a partial action is deemed poor by the heuristic, the entire sub-tree of ground actions beneath it is pruned without explicit evaluation. This works when the branching factor is sufficiently high that the overhead of multiple smaller heuristic evaluations is lower than generating and evaluating all successors in standard state-space search.

### Mechanism 2: Action Set Heuristic Generalization
The paper introduces Action Set Heuristics that evaluate a state and a partial action (representing a set of ground actions). This is implemented via restriction heuristics (modifying PDDL to restrict available actions) and learned graphs (creating graph representations that encode relational structure of the action set). This shifts the speed-vs-informedness trade-off toward informedness by evaluating the intersection of effects/applicability rather than single specific actions. The approach works when a heuristic can meaningfully estimate the value of a set of actions with related effects.

### Mechanism 3: Training Data Densification
Decomposing planning problems into partial-space trajectories generates significantly larger and denser training datasets. A single ground action in a training plan is converted into a sequence of partial actions, creating intermediate "optimal decision" steps. This provides the model with granular supervision on how to construct the action, not just which action to pick. The approach works when learning benefits from "density of optimal decisions" and the domain has sufficient complexity to make this densification meaningful rather than redundant.

## Foundational Learning

- **Concept: PDDL Action Schemas & Grounding**
  - Why needed: The core innovation relies on manipulating the structure of lifted action schemas (variables) before they are grounded (bound to objects). You must understand the difference to follow the partial-action tree.
  - Quick check: Given a schema `Move(robot, loc)` and objects `{r1}, {A, B}`, list the partial actions derived from the root node.

- **Concept: Lifted Planning vs. Grounded Planning**
  - Why needed: LazyLifted operates without fully grounding the task upfront. It uses partial instantiation to manage the search space, which is critical for the "High Branching Factor" results.
  - Quick check: Why does standard grounding fail or become inefficient in domains with high branching factors?

- **Concept: Weisfeiler-Lehman (WL) Algorithm**
  - Why needed: The learned heuristics rely on the WL algorithm to generate feature vectors from the graph representations (AOAG/AEG). Understanding this helps explain why the graphs are structured the way they are.
  - Quick check: What structural property of the graph does the WL algorithm capture to differentiate between states/action sets?

## Architecture Onboarding

- **Component map:** LazyLifted (planner) -> Partial-Space Search (GBFS over partial action tree) -> Action Set Heuristic (evaluates State, PartialAction) -> Graph Generators (AOAG/AEG) -> Linear Program (optimizes ranking weights)

- **Critical path:** Training: Plan traces → Partial Action Sequences → Graphs → WL Features → Weights w; Inference: State s → Generate children in Partial Tree → Compute Heuristic for partial nodes → Prune/Select

- **Design tradeoffs:**
  - AOAG vs. AEG: AOAG (shallow, action nodes) better for high-branching domains where effect intersection is ambiguous; AEG (deep, effect nodes) better for IPC domains with lower branching but complex state dynamics
  - Fixed Argument Ordering: Assumes fixed order for instantiating arguments, restricting search space flexibility but ensuring the tree is manageable

- **Failure signatures:**
  - Low-Branching Slowdown: If IPC coverage drops significantly compared to State-Space search, the overhead of managing the partial tree is too high for the domain complexity
  - AEG Ambiguity Collapse: In high-branching Warehouse domain, if AEG performs poorly, the "intersection of effects" likely resulted in empty sets or generic features that failed to distinguish good partial actions from bad ones

- **First 3 experiments:**
  1. Isolate Search Space: Compare State-Space vs. Partial-Space using the same Restriction Heuristic on the "Warehouse" domain to verify if PSS alone handles high branching better
  2. Validate Training Density: Train a heuristic on a small training set using PSS-generation vs. standard generation. Check if the PSS-trained model generalizes better to larger test instances
  3. AOAG vs. AEG Profile: Run both graph representations on "Transport-Full" (High branching) and "Satellite" (IPC) to confirm the hypothesis that shallow embeddings suit HBF while deep embeddings suit IPC

## Open Questions the Paper Calls Out

- **Open Question 1:** Can partial-space search be effectively extended to other planning paradigms, such as numeric planning or planning under uncertainty? The current definition relies on the discrete, static structure of PDDL action schemas, which differs significantly from the continuous or probabilistic dynamics of these paradigms.

- **Open Question 2:** Can the partial-space search strategy be adapted to avoid the performance degradation observed on domains with low branching factors? While partial-space search reduces the branching factor, the overhead of expanding partial actions increases the total number of evaluations, hurting performance when the original branching factor is already low.

- **Open Question 3:** Does integrating established LAMA techniques, such as preferred operators and multi-queue search, yield cumulative performance improvements when applied to partial-space search? It is unclear if heuristics designed for partial-action sets are compatible with the preferred operator mechanisms used in state-space planners like LAMA.

## Limitations
- Performance degradation in domains with naturally low branching factors suggests limited domain generality
- The fixed argument ordering assumption may limit applicability in domains requiring flexible parameter binding
- The paper doesn't address computational overhead of generating and processing action set graphs during search

## Confidence
- **High Confidence:** Branching factor reduction (88% on combined benchmarks) is well-supported by empirical results
- **Medium Confidence:** Generalization ability of action set heuristics across domains requires further validation
- **Low Confidence:** Theoretical justification for training data densification assumes more granular optimal decisions always improve learning quality, but lacks empirical validation across diverse domain complexities

## Next Checks
1. **Domain Transferability Test:** Train LazyLifted on Warehouse domain and evaluate zero-shot transfer performance on other high-branching factor domains
2. **Scalability Analysis:** Measure wall-clock time and memory usage as problem size scales in Warehouse domain with varying numbers of objects
3. **Parameter Sensitivity Study:** Systematically vary the number of graph features and WL iterations to determine impact on heuristic quality and computational efficiency