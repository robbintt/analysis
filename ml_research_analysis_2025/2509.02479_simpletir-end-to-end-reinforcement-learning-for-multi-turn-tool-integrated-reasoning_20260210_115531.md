---
ver: rpa2
title: 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated
  Reasoning'
arxiv_id: '2509.02479'
source_url: https://arxiv.org/abs/2509.02479
tags:
- reasoning
- training
- sqrt
- multi-turn
- simpletir
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SimpleTIR tackles instability in multi-turn tool-integrated reasoning\
  \ by filtering out trajectories containing \"void turns\"\u2014responses that yield\
  \ neither complete code nor a final answer. This prevents harmful gradients from\
  \ low-probability tokens caused by distributional drift from external tool feedback,\
  \ which compound over turns and lead to training collapse."
---

# SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning

## Quick Facts
- arXiv ID: 2509.02479
- Source URL: https://arxiv.org/abs/2509.02479
- Reference count: 40
- Primary result: Filters "void turns" to stabilize multi-turn tool-integrated reasoning, improving AIME24 performance from 22.1 to 50.5

## Executive Summary
SimpleTIR addresses instability in multi-turn tool-integrated reasoning by filtering out trajectories containing "void turns"—responses that yield neither complete code nor a final answer. This prevents harmful gradients from low-probability tokens caused by distributional drift from external tool feedback, which compound over turns and lead to training collapse. Applied to Qwen2.5-7B, SimpleTIR stabilizes training and improves AIME24 performance from 22.1 to 50.5, while also encouraging diverse reasoning patterns like cross-validation and self-correction.

## Method Summary
SimpleTIR introduces a trajectory filtering mechanism that removes any reasoning path containing "void turns"—intermediate responses that neither produce valid code nor reach a final answer. This addresses the distributional drift problem in multi-turn tool-integrated reasoning, where each tool call introduces feedback from external environments that can lead to compounding errors across turns. The method is implemented as a plug-and-play component that can be integrated with existing reinforcement learning frameworks for tool use, requiring only modification of the trajectory collection and filtering process during training.

## Key Results
- Improves AIME24 performance from 22.1 to 50.5 on Qwen2.5-7B
- Outperforms baselines in both single-turn and multi-turn settings
- Encourages diverse reasoning patterns including cross-validation and self-correction
- Compatible with existing RL stabilization techniques

## Why This Works (Mechanism)
The method works by preventing harmful gradient updates that occur when the model encounters void turns during training. In multi-turn tool-integrated reasoning, each external tool call introduces distributional drift—the feedback from tools creates token distributions that differ from the model's pre-training distribution. When void turns occur, they produce low-probability tokens that, if used for gradient updates, can destabilize training. By filtering these trajectories, SimpleTIR ensures that only productive reasoning paths contribute to learning, preventing the compounding of errors across multiple turns.

## Foundational Learning

**Reinforcement Learning with Tool Integration**: Why needed - Tool-integrated reasoning requires RL frameworks that can handle external feedback loops. Quick check - Verify the agent can successfully call tools and incorporate their outputs into reasoning.

**Distributional Drift in Multi-Turn Reasoning**: Why needed - Each tool interaction shifts token distributions away from pre-training. Quick check - Measure KL divergence between pre-training and tool-augmented distributions.

**Trajectory Filtering in RL**: Why needed - Not all reasoning paths are equally valuable for learning. Quick check - Analyze the ratio of void turns to productive turns in training data.

**Code Generation as Reasoning Proxy**: Why needed - Code serves as executable intermediate reasoning steps. Quick check - Verify generated code produces correct intermediate results.

**Multi-Turn Reasoning Stability**: Why needed - Errors compound across turns without proper filtering. Quick check - Monitor training stability metrics across different turn counts.

## Architecture Onboarding

**Component Map**: Environment -> Tool Executor -> Model -> Reward Function -> Filter -> Trainer

**Critical Path**: Model generates reasoning steps → Tools execute and return feedback → Filter removes void turns → Trainer updates model parameters

**Design Tradeoffs**: Complete trajectory exclusion vs. partial credit assignment; strict filtering vs. tolerance for exploration failures; simplicity vs. potential information loss from discarded samples.

**Failure Signatures**: Training collapse with increasing void turns; performance degradation on multi-turn tasks; loss of reasoning diversity; convergence to degenerate solutions.

**Three First Experiments**:
1. Compare training stability with and without void turn filtering on simple multi-step reasoning tasks
2. Measure the impact of different filtering thresholds on final performance
3. Analyze reasoning pattern diversity with and without SimpleTIR across multiple reasoning domains

## Open Questions the Paper Calls Out
None

## Limitations
- Strong reliance on trajectory filtering may lose valuable information from discarded samples
- Assumes void turns are always detrimental, potentially excluding valid reasoning paths
- Demonstrated primarily on Qwen2.5-7B with AIME24 data, limiting generalization claims

## Confidence
- AIME24 performance improvement from 22.1 to 50.5: **High**
- General plug-and-play compatibility: **Medium**
- Encouragement of diverse reasoning patterns: **Medium**

## Next Checks
1. Conduct ablation studies systematically varying the void turn filtering threshold to quantify the trade-off between stability and information retention
2. Test SimpleTIR across multiple model families (not just Qwen2.5-7B) and diverse reasoning benchmarks to establish broader generalization
3. Implement a mechanism to preserve some void turn trajectories with lower weighting rather than complete exclusion, to assess whether partial information retention improves learning efficiency