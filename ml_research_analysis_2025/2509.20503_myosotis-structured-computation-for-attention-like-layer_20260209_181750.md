---
ver: rpa2
title: 'Myosotis: structured computation for attention like layer'
arxiv_id: '2509.20503'
source_url: https://arxiv.org/abs/2509.20503
tags:
- layer
- matrix
- tree
- input
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Myosotis (Myo), a novel structured computation
  layer for sequence-to-sequence mapping inspired by the efficient inversion of tree-structured
  matrices. The authors address the quadratic scaling issue in attention layers by
  combining sparsity and recurrence concepts, allowing for linear complexity in both
  time and space with respect to sequence length.
---

# Myosotis: structured computation for attention like layer

## Quick Facts
- arXiv ID: 2509.20503
- Source URL: https://arxiv.org/abs/2509.20503
- Authors: Evgenii Egorov; Hanno Ackermann; Markus Nagel; Hong Cai
- Reference count: 40
- Primary result: Novel tree-structured computation layer achieving linear complexity for sequence-to-sequence mapping, performing on par with or slightly better than S5 when using tree-structure-aware flattening

## Executive Summary
This paper introduces Myosotis (Myo), a structured computation layer for sequence-to-sequence mapping that addresses the quadratic scaling issue in attention layers. The method combines sparsity and recurrence concepts through a tree graph structure where each vertex has associated matrices facilitating upward and downward message passing. Myo achieves linear complexity in both time and space with respect to sequence length by implicitly computing dense interactions through solving a linear system defined by a sparse tree structure.

## Method Summary
Myosotis is a tree-structured computation layer where each vertex in a fixed tree graph has associated matrices (A_v, B_v, C_v) that facilitate upward and downward message passing. The layer computes outputs by solving a linear system T_G x = u, where T_G is a sparse tree-structured matrix. The solution is decomposed into an "Upward Traverse" (leaves to root) and a "Backward Traverse" (root to leaves), enabling parallel computation across tree levels. For images, Myo uses quad trees with Morton ordering to preserve spatial locality, while for text it uses binary trees. The method generalizes standard State Space Models as a special case and can incorporate domain knowledge through graph structure.

## Key Results
- Achieves linear complexity (O(L) time and space) for sequence-to-sequence mapping through tree-structured computation
- On image classification (MNIST, CIFAR), performs on par with or slightly better than S5 when using tree-structure-aware flattening (Morton ordering)
- Without structure-aware flattening, performs comparably to SSM-based approaches
- Generalizes standard State Space Models as a special case (chain graph)
- Provides detailed implementation guidance and pseudo-code for forward pass computation

## Why This Works (Mechanism)

### Mechanism 1: Implicit Dense Interaction via Sparse Solver
The layer achieves global context aggregation without quadratic pairwise computation by solving a linear system defined by a sparse tree structure. Instead of computing a dense attention matrix K, the method constructs a sparse, tree-structured matrix T_G based on graph G. The output is computed by solving T_G x = u. While T_G is sparse (linear memory), its inverse (T_G^{-1}), which represents the actual interaction weights, is dense. The solver acts as an implicit computation of this dense interaction.

### Mechanism 2: Parallelized Message Passing (Upward/Downward Traverses)
Computational efficiency is achieved by reformulating Gaussian elimination on the tree as parallelizable message-passing steps. The solution to T_G x = u is decomposed into an "Upward Traverse" (leaves to root) and a "Backward Traverse" (root to leaves). Children nodes modify their coefficients and send messages to their parent (Upward), then the root is solved first and parent states are passed down to solve children (Downward). These computations are independent across equidistant from root children-parent groups, enabling parallel processing.

### Mechanism 3: Topological Alignment (Morton Ordering)
Performance gains over standard SSMs are observed when the data flattening order respects the inductive bias of the tree structure (spatial locality). For 2D images, standard "snake" flattening breaks spatial locality. Myo uses "Morton ordering" (Z-order), which preserves 2D locality in 1D sequences, aligning with the tree's hierarchical aggregation logic. This is critical for the Image classification experiments.

## Foundational Learning

- **Concept: Associative Scan (Parallel Prefix Sum)** - Needed to understand why Myo's upward/downward traverse is the equivalent operation for tree structures compared to SSMs' associative scans. Quick check: How does an associative scan turn a sequential dependency x_t = f(x_{t-1}, u_t) into a parallel operation?

- **Concept: Gaussian Elimination on Sparse Matrices** - Essential for understanding the upward/downward traverse as resembling Gaussian elimination/substitution. Quick check: Why does the fill-in property of Gaussian elimination usually destroy sparsity, and how does the tree structure in Myo prevent this?

- **Concept: Z-Order Curve (Morton Ordering)** - Critical data pre-processing step for the Image classification experiments. Without this, the "Tree" structure in Myo is effectively random regarding image patches. Quick check: How does a Z-order curve map a 2D coordinate (x, y) to a 1D index while preserving locality better than a raster scan?

## Architecture Onboarding

- **Component map:** Input Layer -> Tree Definition -> Parameters (A_v, B_v, C_v per vertex) -> Solver (Upward Pass -> Root Solve -> Downward Pass) -> Output

- **Critical path:** The sequential dependency flows from Leaf → Root → Leaf. The latency is bounded by the depth of the tree (O(log_k L)).

- **Design tradeoffs:** Chain vs. Tree: A Chain graph makes Myo equivalent to a bidirectional SSM (slower, O(L) depth). A Tree provides O(log L) depth but imposes a spatial hierarchy that may not fit text semantics as well. Branching Factor: Higher branching (e.g., Quad tree) reduces depth but increases the dimensionality of the internal node states and the computational width of the message passing.

- **Failure signatures:** Performance drop on "Snake" order (if dataloader uses standard rasterization instead of Z-order), Training Instability (check diagonal dominance and initialization of B and C), Memory Bottleneck (storage for intermediate states in upward pass).

- **First 3 experiments:**
  1. Sanity Check (Chain): Implement Myo with a Chain graph (2-children tree) on a copy task. Verify it behaves like a known SSM (S4/S5) to validate the solver math.
  2. Ablation (Ordering): Train on CIFAR using (a) Snake flattening and (b) Morton flattening. Quantify the accuracy gap to confirm the structural induction hypothesis.
  3. Speed Benchmark: Profile the Upward/Downward scan against a standard associative scan. Confirm the wall-clock time scales linearly with sequence length L.

## Open Questions the Paper Calls Out

### Open Question 1
Can the Myo layer achieve competitive performance on long-range dependency tasks without relying on structure-aware data flattening (e.g., Morton ordering)? The paper demonstrates clear advantages only when using Morton ordering for images, but does not propose a mechanism to bridge the performance gap for generic sequential data where such structure is absent.

### Open Question 2
Does enforcing the symmetric constraint (C^†_v = B_v) on the interaction matrices limit the theoretical representational capacity of the layer? The constraint is imposed for stability, reducing the parameter space, but the paper does not investigate if this reduction harms the model's ability to approximate complex functions.

### Open Question 3
Does the Myo layer provide practical wall-clock speedups during training compared to highly optimized SSM implementations? While the paper claims theoretical time complexity of O(log_k L) for perfect trees, it only reports accuracy metrics, omitting training latency or throughput benchmarks against baselines like S5.

## Limitations

- Architecture specificity: Performance gains are highly dependent on tree structure choice and data flattening method, with benefits only demonstrated when tree topology matches data geometry
- Empirical validation scope: Limited to simple image classification and synthetic benchmarks, with modest improvements over S5 that may not justify implementation complexity
- Scalability assumptions: Theoretical linear complexity may not translate to practical efficiency due to constant factors and parallel hardware requirements

## Confidence

**High confidence (8/10)**: The mathematical framework for tree-structured matrix inversion is sound and the derivation of the upward/downward traversal algorithm is rigorous.

**Medium confidence (6/10)**: The claim that Myo achieves comparable or slightly better performance than S5 is supported by experimental results, but the margin of improvement is small and highly dependent on data preprocessing choices.

**Low confidence (4/10)**: The assertion that the approach generalizes well to diverse sequence modeling tasks is speculative, as experiments do not demonstrate effectiveness on complex real-world datasets.

## Next Checks

- **Check 1: Robustness to ordering variations**: Systematically compare Myo performance across multiple data flattening strategies (snake, Morton, Hilbert, random) on CIFAR to quantify the sensitivity to structural alignment.

- **Check 2: Cross-domain generalization**: Implement Myo on a standard NLP task (e.g., WikiText-103 or GLUE benchmark) where the assumed spatial hierarchy is absent. Compare performance against S5 and attention-based models.

- **Check 3: Memory and speed profiling**: Conduct detailed profiling of the upward/downward traversal implementation across different sequence lengths and branching factors. Measure actual memory usage and wall-clock time versus theoretical complexity.