---
ver: rpa2
title: Risks of Cultural Erasure in Large Language Models
arxiv_id: '2501.01056'
source_url: https://arxiv.org/abs/2501.01056
tags:
- city
- language
- cultural
- cities
- represented
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies cultural erasure in large language models, focusing
  on omission and simplification of cultural representations. The authors analyze
  LLM outputs describing global cities and travel recommendations, finding that African
  and Asian cities are underrepresented or presented with narrow economic narratives
  compared to European and North American cities which are associated with culture.
---

# Risks of Cultural Erasure in Large Language Models

## Quick Facts
- arXiv ID: 2501.01056
- Source URL: https://arxiv.org/abs/2501.01056
- Authors: Rida Qadri; Aida M. Davani; Kevin Robinson; Vinodkumar Prabhakaran
- Reference count: 40
- Primary result: LLMs systematically omit or oversimplify cultural representations, with African/Asian cities associated with economy while European/North American cities linked to culture.

## Executive Summary
This paper investigates cultural erasure in large language models through analysis of how they describe global cities and recommend travel destinations. The authors find systematic underrepresentation of African and Asian cities, with models associating these regions primarily with economic narratives while Western contexts receive rich cultural descriptions. When recommending travel destinations, entire regions like Central Africa and the Caribbean are frequently omitted from suggestions, while Western European cities dominate recommendations despite containing small percentages of their regional populations.

The study reveals that LLMs reproduce and amplify existing media biases, presenting "single stories" about non-Western cultures that risk further marginalizing already underrepresented groups in digital knowledge systems. The research highlights that even when models mention cities from underrepresented regions, they often present one-dimensional views focused on economic metrics rather than cultural richness, demonstrating both omission and simplification forms of erasure.

## Method Summary
The study employed two complementary approaches to evaluate cultural erasure. Study 1 analyzed LLM outputs describing 50 global cities across 8 thematic dimensions (culture, economy, demography, geography, government, history, industry, political situation, social issues) using 5 prompt templates with 10 samples each (2,500 total). Study 2 examined travel recommendation patterns across 7 interest cues and 4 application contexts, generating 10 samples per query (280 total). Both studies used PaLM and PaLM 2 models with documented temperature and sampling parameters, with Study 1 relying on human crowdworker annotation and Study 2 using automated city extraction with author review.

## Key Results
- African and Asian cities are underrepresented in LLM outputs and primarily associated with economic narratives rather than cultural descriptions
- Entire regions including Central Africa, the Caribbean, and Polynesia are frequently omitted from travel recommendations
- Western European cities like London and Paris dominate recommendations despite containing less than 10% of their regional populations
- LLMs replicate historical media biases, presenting simplified "single stories" about non-Western cultures that echo colonial-era representations

## Why This Works (Mechanism)

### Mechanism 1: Training Data Distribution Imbalance → Omission
Underrepresentation in training corpora leads to complete absence in generated outputs for certain regions. LLMs learn token co-occurrence patterns from internet-sourced training data. Regions with sparse digital footprint have fewer tokens and weaker associations, resulting in zero probability of recommendation when models sample from learned distributions. Break condition: targeted fine-tuning or retrieval augmentation explicitly compensating for sparse training data would weaken or eliminate omission patterns.

### Mechanism 2: Media Bias Amplification → Representational Simplification
Models replicate historical media patterns where Western contexts associate with "culture" and non-Western contexts with "economy/development." Training data encodes centuries of colonial-era representational patterns. Next-token prediction selects continuations that match statistically dominant narrative frames, reinforcing thematic associations: European cities → art, museums, architecture; African cities → GDP, poverty, economic growth. Break condition: prompt-based mitigations successfully intervening in thematic association patterns would show reduced culture/economy disparity.

### Mechanism 3: Token Frequency Dominance → Within-Region Homogenization
Even when regions appear, a single high-frequency entity monopolizes representation. Sampling from softmax distributions over city tokens favors highest-probability candidates. London (100% of Northern Europe) and Paris (94% of Western Europe) dominate despite each containing <10% of regional population. Break condition: increased temperature/diversity parameters or nucleus sampling explicitly penalizing repetition would increase within-region diversity.

## Foundational Learning

- **Concept: Symbolic Annihilation (Media Studies)**
  - Why needed here: Provides theoretical framework distinguishing *omission* (complete absence) from *simplification* (reductive presence). Essential for understanding why "some representation ≠ fair representation."
  - Quick check question: If a model mentions Lagos but only in contexts of poverty/GDP, is this omission or simplification?

- **Concept: "Single Story" Narrative Pattern**
  - Why needed here: Explains why statistical parity is insufficient—quality and thematic diversity of representation matters. Adichie's framework connects representational patterns to colonial power structures.
  - Quick check question: What thematic associations does the model produce for cities in Africa versus Europe?

- **Concept: Training Data Distribution vs. Sampling Diversity**
  - Why needed here: Distinguishes data-level interventions (collect more diverse training data) from inference-level interventions (adjust temperature, use nucleus sampling, retrieval augmentation).
  - Quick check question: Would increasing sampling temperature fix omission, simplification, both, or neither?

## Architecture Onboarding

- **Component map:** Input prompts → LLM (PaLM/PaLM 2) → Generated text → Thematic annotation + geographic extraction → Statistical analysis

- **Critical path:**
  1. Define geographic unit of analysis (cities → proxy for cultural communities)
  2. Design prompt templates covering cultural discovery contexts
  3. Sample outputs with documented temperature/top-k settings
  4. Extract geographic references (automated heuristics + human review)
  5. Annotate thematic content (crowdworkers or trained raters)
  6. Compute: (a) p(region) for omission, (b) thematic score distributions for simplification, (c) within-region diversity for homogenization

- **Design tradeoffs:**
  - City as unit: Standardized globally, but imperfect proxy for cultural/ethnic groups
  - Crowdworker annotation: Scalable but may lack nuanced sociocultural knowledge for distant contexts
  - Single model evaluation: Controlled comparison vs. limited generalizability across architectures

- **Failure signatures:**
  - p(region) = 0 for multiple sub-regions (omission)
  - Culture/economy thematic ratio < 1.0 for African/Asian cities, > 1.0 for European/North American cities (simplification)
  - Single city > 80% of within-region references (homogenization)
  - Safety mitigations targeting stereotypes do not resolve thematic imbalance

- **First 3 experiments:**
  1. **Baseline audit:** Run the paper's two study designs (city description + travel recommendation) on your target model with identical prompts, compute p(region) and thematic scores for culture vs. economy.
  2. **Temperature/diversity sweep:** Repeat travel recommendation task with temperature values [0.5, 0.7, 1.0, 1.5] and nucleus sampling (p=[0.9, 0.95]), measure impact on within-region diversity and omission rates.
  3. **Targeted retrieval augmentation:** For prompts returning zero-representation regions, prepend retrieved context about underrepresented cities from curated sources, measure whether p(region) increases and whether thematic diversity improves.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do culturally specific or local annotators identify different thematic representations compared to general crowd workers?
- Basis in paper: The authors state a limitation that "crowd annotators may lack nuanced sociocultural knowledge required to accurately evaluate themes of representation across such different places and cultures."
- Why unresolved: The study relied on annotators recruited from India who may not possess specific local knowledge for all 50 global cities analyzed.
- What evidence would resolve it: A comparative study using the same model outputs evaluated by annotators who are residents or cultural experts of the specific cities being coded.

### Open Question 2
- Question: Do other commercial LLM APIs exhibit similar omission rates for specific regions like Central Africa and the Caribbean?
- Basis in paper: The authors note, "we evaluate one language model and one API, and other system may have different forms of cultural erasure."
- Why unresolved: The study focused exclusively on the PaLM and PaLM 2 models, leaving the behavior of other major architectures (e.g., GPT, Claude, Llama) unknown regarding this specific travel omission pattern.
- What evidence would resolve it: Replicating the "Study 2" methodology (travel recommendations) across a diverse set of current commercial model APIs and comparing the empirical probability of references to underrepresented regions.

### Open Question 3
- Question: Does the "single story" dynamic differ when the unit of analysis is shifted from cities to ethnic or religious groups?
- Basis in paper: The paper mentions that "this methodology is general and can be repeated on a variety of identity markers," but concedes the tasks and metrics reflect only a "limited subset of cultural representations."
- Why unresolved: Cities were chosen as a standardized proxy, but it remains unclear if the same economic vs. cultural thematic split occurs when the model describes non-geographic social groupings.
- What evidence would resolve it: Applying the thematic coding framework (Culture vs. Economy) to model outputs generated in response to prompts asking for descriptions of specific ethnic or religious communities.

## Limitations
- The study relies on cities as proxies for cultural communities, which may not fully capture cultural diversity or represent ethnic/religious groups
- Crowdworker annotations may lack nuanced sociocultural knowledge required to accurately evaluate themes across diverse global contexts
- The analysis is limited to PaLM and PaLM 2 models, leaving uncertainty about whether other architectures exhibit identical erasure patterns
- While correlation between training data patterns and erasure outcomes is established, causation from training data distribution to model behavior is not definitively proven

## Confidence
- **High confidence**: The documented patterns of omission (zero probability for Central Africa, Caribbean, Polynesia) and simplification (culture/economy thematic ratios) are directly observable from reported statistics and align with known training data biases
- **Medium confidence**: The mechanisms linking training data distribution to erasure outcomes are plausible but not definitively proven within the study—alternative explanations cannot be ruled out
- **Medium confidence**: The claim that models amplify historical media biases follows logically from observed single-story patterns but requires additional evidence to establish amplification versus mere replication

## Next Checks
1. **Multi-model replication**: Run the exact study designs across multiple LLM architectures (GPT, Claude, LLaMA) to test whether erasure patterns persist independently of model family
2. **Fine-tuning intervention**: Fine-tune a base model with balanced geographic representation data and repeat the studies to measure changes in omission and simplification rates
3. **Community validation**: Engage cultural experts from underrepresented regions to review model outputs for accuracy, nuance, and harmful stereotyping beyond the paper's quantitative metrics