---
ver: rpa2
title: Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM
  Inference Latency
arxiv_id: '2505.17074'
source_url: https://arxiv.org/abs/2505.17074
tags:
- inference
- requests
- time
- speculative
- scheduling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of scheduling inference requests
  in large language model (LLM) serving systems that use speculative decoding. The
  key difficulty is that request execution time depends on both the predicted output
  length and the token acceptance rate of the verification process, making accurate
  estimation difficult.
---

# Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency

## Quick Facts
- **arXiv ID:** 2505.17074
- **Source URL:** https://arxiv.org/abs/2505.17074
- **Reference count:** 13
- **Key result:** LAPS-SD reduces average inference latency by ~39% compared to state-of-the-art methods

## Executive Summary
This paper addresses the challenge of scheduling inference requests in LLM serving systems that use speculative decoding. The execution time of requests is unpredictable due to variable token acceptance rates during the verification process. The authors propose LAPS-SD (Least-Attained/Perceived-Service for Speculative Decoding), a semi-clairvoyant scheduling algorithm that adaptively manages requests using multiple priority queues. The algorithm leverages the observation that token acceptance rates become stable over time, allowing it to switch between non-preemptive and preemptive scheduling strategies. Experimental results demonstrate significant latency improvements over existing methods.

## Method Summary
LAPS-SD is a multi-queue scheduling algorithm designed specifically for speculative decoding systems. It maintains K priority queues with exponentially increasing thresholds, where each queue j has a threshold of Sup_j = M^(j-1) × Sup_1. Requests are initially placed in the first queue using a Least-Attained-Service (LAS) strategy without preemption to avoid high overhead costs. As token acceptance rates stabilize over time, requests transition to a "perceptible" state where they are scheduled using Shortest-Job-First (SJF) with preemption. The algorithm monitors acceptance rate variance over consecutive rounds to detect stability, at which point it estimates execution time and moves requests to appropriate queues based on predicted completion time. This adaptive approach balances the need for accurate scheduling with the overhead costs of frequent preemption.

## Key Results
- LAPS-SD reduces average inference latency by approximately 39% compared to state-of-the-art scheduling methods
- Optimal number of priority queues (K) varies inversely with request load (K=6 for 10 requests, K=4 for 30 requests)
- Preemption overhead reaches ~14% at 500 tokens but remains manageable with proper queue management

## Why This Works (Mechanism)
LAPS-SD works by exploiting the temporal stability of token acceptance rates in speculative decoding. In the early stages of request processing, acceptance rates are highly variable and unpredictable, making execution time estimation unreliable. During this phase, the algorithm uses a non-preemptive LAS strategy to avoid costly preemption overhead. As requests progress and acceptance rates stabilize, the system transitions to SJF scheduling with preemption, enabling more accurate job ordering. This semi-clairvoyant approach allows the scheduler to make informed decisions when possible while minimizing overhead when predictions are unreliable.

## Foundational Learning

**Speculative Decoding** - A technique where a smaller, faster model (SSM) generates tokens speculatively, which are then verified by the larger LLM. *Why needed:* Forms the basis of the scheduling problem and introduces the acceptance rate variability that makes scheduling challenging. *Quick check:* Verify that the system uses both an SSM (LLaMA-68M) and LLM (LLaMA-7B) as specified.

**Token Acceptance Rate** - The probability that the LLM accepts tokens generated by the SSM during verification. *Why needed:* This rate determines execution time and is the key metric for detecting scheduling stability. *Quick check:* Monitor acceptance rate variance over time to identify when it stabilizes.

**KV Cache Switching Overhead** - The computational cost of switching between different inference requests due to cache invalidation. *Why needed:* This overhead makes preemption expensive and must be minimized through intelligent scheduling. *Quick check:* Measure preemption frequency and calculate switching cost ratio.

## Architecture Onboarding

**Component Map:** LLM (LLaMA-7B) <- Verification Engine <- Scheduler (LAPS-SD) -> SSM (LLaMA-68M) -> Request Queue

**Critical Path:** Request arrival → SSM token generation → LLM verification → Cache update → Output delivery

**Design Tradeoffs:** The algorithm trades off preemption accuracy against overhead costs. Early-stage non-preemptive scheduling sacrifices optimal ordering for lower overhead, while late-stage preemptive SJF sacrifices overhead for better ordering accuracy.

**Failure Signatures:** High preemption frequency (>14% overhead), poor execution time estimation (>10% error), and unstable acceptance rate detection can all degrade performance.

**First Experiments:**
1. Implement basic LAPS-SD with K=4 queues and monitor acceptance rate stability detection accuracy
2. Measure execution time estimation error against ground truth across all three datasets
3. Compare average latency against FCFS, LAS, and LP-SJF baselines under varying request loads

## Open Questions the Paper Calls Out

**Open Question 1:** How does LAPS-SD perform with batch sizes greater than 1? The paper assumes batch size of 1 for clear presentation but claims it can be extended. Experimental results with batch sizes of 2, 4, and 8 are needed to measure performance and memory overhead.

**Open Question 2:** Can the number of priority queues (K) be dynamically adapted in real-time? Figure 6 shows optimal K varies with request load, but the algorithm uses static K. An adaptive mechanism that adjusts K based on queue depth could potentially outperform any static configuration.

**Open Question 3:** Is the stability detection heuristic robust across diverse prompt types? The paper uses specific γ and δ thresholds to detect stability, but complex tasks might exhibit noisy acceptance rates that fluctuate even late in generation. Sensitivity analysis across different datasets is needed.

## Limitations

- The paper assumes batch size of 1, limiting applicability to real-world serving systems that typically use batching
- Stability detection parameters (γ, δ) and queue scaling factor M are not specified, creating uncertainty in reproduction
- Output length prediction model details are incomplete, requiring assumptions about implementation
- The algorithm's performance with batch sizes greater than 1 is not experimentally validated

## Confidence

- **Medium** confidence in the 39% latency reduction claim due to unspecified algorithm parameters
- **Medium** confidence in the multi-queue adaptive scheduling approach due to clear architecture but unclear operational details
- **High** confidence in the problem formulation and general methodology

## Next Checks

1. Implement LAPS-SD with multiple parameter configurations (different M values, γ/δ combinations) to determine which settings reproduce the reported performance, then verify against the paper's claims

2. Compare acceptance rate stability detection accuracy by logging actual vs. predicted stability points across all datasets to ensure the scheduling transitions occur at appropriate times

3. Benchmark the complete system (LLaMA-68M SSM + LLaMA-7B LLM) with all three datasets under varying concurrency levels (10-50 requests) to verify the 39% improvement over LAS and LP-SJF baselines is consistently achievable