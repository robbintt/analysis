---
ver: rpa2
title: 'RealGen: Photorealistic Text-to-Image Generation via Detector-Guided Rewards'
arxiv_id: '2512.00473'
source_url: https://arxiv.org/abs/2512.00473
tags:
- image
- arxiv
- generation
- images
- reward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'RealGen addresses the lack of photorealism in modern text-to-image
  models by introducing a detector-guided reward mechanism that quantifies AI artifacts
  using both semantic-level and feature-level synthetic image detectors. The method
  employs a two-stage optimization pipeline: first optimizing an LLM for prompt refinement
  to generate richer descriptions, then optimizing a diffusion model via GRPO to reduce
  artifacts and enhance realism.'
---

# RealGen: Photorealistic Text-to-Image Generation via Detector-Guided Rewards

## Quick Facts
- **arXiv ID:** 2512.00473
- **Source URL:** https://arxiv.org/abs/2512.00473
- **Reference count:** 40
- **Key outcome:** RealGen achieves state-of-the-art photorealism with 96.73% win rate against GPT-5 and 50.15% against real images on RealBench

## Executive Summary
RealGen addresses the persistent challenge of photorealism in text-to-image generation by introducing a detector-guided reward mechanism that quantifies AI artifacts at both semantic and feature levels. The method employs a two-stage optimization pipeline: first refining prompts through LLM fine-tuning to generate richer descriptions, then optimizing a diffusion model via GRPO to reduce artifacts and enhance realism. RealGen demonstrates superior performance on the proposed RealBench benchmark and the HPDv2 Photo subset, outperforming leading models like GPT-Image-1, Qwen-Image, and FLUX-Krea with comprehensive detector scores and FID metrics.

## Method Summary
RealGen introduces a detector-guided reward mechanism that leverages two specialized AI artifact detectors (Forensic-Chat and OmniAID) to quantify and reduce synthetic image artifacts. The method employs a two-stage optimization pipeline: first optimizing an LLM for prompt refinement to generate richer, more detailed descriptions that guide image generation, then optimizing a diffusion model using GRPO (Group Relative Policy Optimization) to directly minimize detector-identified artifacts. This approach creates a feedback loop where artifact detection informs reward signals that drive model improvements, resulting in images that achieve state-of-the-art photorealism across multiple evaluation benchmarks.

## Key Results
- Achieves 96.73% win rate against GPT-5 and 50.15% against real images on RealBench benchmark
- Outperforms leading models on HPDv2 Photo subset with detector scores of 71.34 (Forensic-Chat) and 56.93 (OmniAID)
- Demonstrates state-of-the-art FID of 11.12 and CLIP-S score of 76.05 on RealBench

## Why This Works (Mechanism)
The detector-guided reward mechanism works by quantifying AI artifacts at multiple levels, providing specific feedback that guides the optimization process. The two-stage pipeline separates prompt refinement from image generation optimization, allowing each component to specialize in its respective task. LLM prompt refinement generates richer descriptions that provide better guidance for image generation, while GRPO optimization directly targets artifact reduction based on detector feedback. This creates a synergistic effect where improved prompts lead to better initial image quality, and detector-guided rewards further refine the output to achieve photorealistic results.

## Foundational Learning
- **Diffusion Models:** Generative models that denoise random noise into coherent images through a reverse diffusion process; needed for understanding the base architecture being optimized
- **GRPO (Group Relative Policy Optimization):** A reinforcement learning algorithm that optimizes policy gradients using group comparisons; needed to understand how the diffusion model is fine-tuned
- **AI Artifact Detection:** Methods for identifying synthetic image characteristics that distinguish AI-generated content from real photographs; needed to understand the reward mechanism
- **Prompt Engineering:** The process of crafting detailed text descriptions to guide image generation; needed to understand the LLM refinement stage
- **Forensic-Chat & OmniAID:** Specific AI artifact detection models used as reward functions; needed to understand the evaluation and optimization criteria
- **CLIP Embeddings:** Contrastive Language-Image Pretraining representations used for semantic similarity scoring; needed to understand CLIP-S metric

## Architecture Onboarding

**Component Map:** LLM Prompt Refiner -> Diffusion Model Generator -> Detector Reward System -> GRPO Optimizer

**Critical Path:** User Prompt → LLM Refinement → Diffusion Generation → Artifact Detection → Reward Calculation → Model Update

**Design Tradeoffs:** Two-stage optimization (prompt refinement + image generation) versus end-to-end training; specialized artifact detectors versus general quality metrics; computational cost versus performance gains

**Failure Signatures:** Over-optimization to specific detectors leading to poor generalization; prompt over-refinement causing loss of user intent; computational bottlenecks in training pipeline

**First Experiments:**
1. Evaluate baseline diffusion model performance on RealBench without any optimization
2. Test LLM prompt refinement alone on existing prompts to measure quality improvement
3. Run detector-guided reward optimization on a small dataset subset to validate the mechanism

## Open Questions the Paper Calls Out
None

## Limitations
- Detector-guided reward system may overfit to specific artifact types detected by Forensic-Chat and OmniAID
- Two-stage optimization pipeline requires substantial computational resources (7 days on 4 A100-80G GPUs)
- RealBench benchmark may not fully represent real-world deployment scenarios despite comprehensive dataset combination

## Confidence
- **High confidence:** Core technical contribution and superiority on established benchmarks (RealBench, HPDv2 Photo)
- **Medium confidence:** Generalization claims due to dependence on specific artifact detectors and benchmark performance
- **Medium confidence:** Practical applicability given significant computational requirements for training

## Next Checks
1. Test RealGen's performance against additional AI artifact detection systems beyond Forensic-Chat and OmniAID
2. Evaluate the trained RealGen model on out-of-distribution prompts and real-world applications
3. Conduct ablation studies isolating the contributions of LLM prompt refinement versus diffusion model optimization