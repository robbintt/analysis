---
ver: rpa2
title: 'The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction'
arxiv_id: '2507.13732'
source_url: https://arxiv.org/abs/2507.13732
tags:
- legal
- judges
- case
- judicial
- court
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates whether individual judges\u2019 decision-making\
  \ patterns significantly influence legal outcomes, challenging the assumption that\
  \ judges are neutral variables applying the law uniformly. Using machine learning,\
  \ the research predicts child custody outcomes in French appellate courts by comparing\
  \ models trained on individual judges\u2019 past rulings (specialist models) with\
  \ a judge-agnostic model trained on aggregated data (generalist model)."
---

# The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction

## Quick Facts
- **arXiv ID**: 2507.13732
- **Source URL**: https://arxiv.org/abs/2507.13732
- **Authors**: Guillaume Zambrano
- **Reference count**: 40
- **Primary result**: Specialist models trained on individual judges' rulings outperform generalist models by up to 10 percentage points in F1 score (92.85% vs 82.63%)

## Executive Summary
This study challenges the assumption that judges are neutral variables applying the law uniformly by investigating whether individual judges' decision-making patterns significantly influence legal outcomes. Using machine learning on French appellate child custody cases, the research compares specialist models trained on individual judges' past rulings with a judge-agnostic model trained on aggregated data. The results show that specialist models consistently outperform the generalist model, with top-performing models achieving F1 scores as high as 92.85% compared to the generalist model's 82.63%. This demonstrates that judicial identity plays a measurable role in legal outcomes, providing empirical support for legal realism and highlighting the importance of modeling individual judicial behavior in legal judgment prediction.

## Method Summary
The study uses a machine learning pipeline to predict child custody outcomes in French appellate courts. The method involves extracting structured features from unstructured legal text using Llama 3.3 70B with schema-constrained prompting, partitioning data by individual judges (specialist models) versus aggregated data (generalist model), and training multiple classifiers (Random Forest, XGBoost, SVM) on the extracted features. The pipeline handles class imbalance through targeted oversampling and undersampling, and evaluates performance using macro-averaged F1 scores with both in-domain and cross-domain testing to assess judge-specific patterns.

## Key Results
- Specialist models consistently outperform the generalist model, with top F1 scores reaching 92.85% versus 82.63% for the generalist approach
- Cross-domain testing shows sharp performance declines when specialist models are applied to other judges' data, demonstrating non-transferable decision patterns
- LLM-based feature extraction achieves comparable performance to human expert annotation (F1 0.92 for Father Custody vs human 0.74)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Individual judges exhibit stable, learnable decision-making patterns that generalist models fail to capture
- **Mechanism**: The authors partition data by judicial identity and train specialist models on individual judges' histories, learning judge-specific weightings of legal factors
- **Core assumption**: A judge's past ruling behavior is a reliable proxy for their future behavior (stability of judicial disposition)
- **Evidence anchors**: Specialist models outperform generalist by 10 percentage points in F1 score; different algorithms converge on similar conclusions
- **Break condition**: If specialist models perform worse than or equal to the generalist model on their own test sets, the mechanism is invalid

### Mechanism 2
- **Claim**: LLMs can reliably automate the "annotation bottleneck" for structured legal feature extraction
- **Mechanism**: Llama 3.3 70B uses schema-constrained prompting to extract categorical variables from unstructured text into a strict JSON format
- **Core assumption**: The semantic understanding of the LLM is sufficient to map legal narrative variations to a fixed ontology without hallucination
- **Evidence anchors**: LLM data extraction is comparable to human expert annotation with F1 0.92 for Father Custody vs human 0.74
- **Break condition**: If the F1 score for LLM extraction falls significantly below human inter-annotator agreement

### Mechanism 3
- **Claim**: Judicial patterns are non-transferable; a model trained on Judge A will fail to generalize to Judge B
- **Mechanism**: Cross-domain testing applies specialist models to other judges' test sets, with performance drops indicating distinctiveness
- **Core assumption**: Legal Idealism (uniform application of law) is false; judges function as independent decision variables
- **Evidence anchors**: Sharp declines across domains demonstrate idiosyncratic rules; diagonal dominance in cross-domain matrix shows lack of transferability
- **Break condition**: If specialist models maintain high performance on other judges' data, the "Judge Variable" is negligible

## Foundational Learning

- **Concept**: Legal Realism vs. Formalism
  - **Why needed**: The experimental design tests if outcomes are determined by the law (Formalism/Generalist model) or the individual judge (Realism/Specialist model)
  - **Quick check**: Does the generalist model outperform the specialist models, suggesting the law is applied uniformly?

- **Concept**: Schema-Constrained Prompting
  - **Why needed**: The pipeline relies on the LLM outputting strict JSON with closed ontologies; understanding this constraint is vital for debugging extraction failures
  - **Quick check**: Why does the author prefer a minimal prompt with a JSON schema over a detailed prompt with examples?

- **Concept**: Macro-Averaged F1 Score
  - **Why needed**: The dataset is heavily imbalanced (Mother custody is ~67%, Shared is ~10%); Macro-F1 ensures the model isn't just guessing the majority class
  - **Quick check**: If a model predicts "Mother" for every case, why would the accuracy be high but the Macro-F1 be low?

## Architecture Onboarding

- **Component map**: JURICA database (PDF/Text) -> Pseudonymization Module -> Llama 3.3 (70B) -> Scikit-learn (RF, XGB, SVC) -> Macro-F1 Evaluation
- **Critical path**: The Data Partitioning and Extraction Phase requires correctly bucketing cases by Judge_ID, balancing training data (Mother reduced to 34-40%), and optimizing for Macro-F1 using stratified k-fold cross-validation
- **Design tradeoffs**:
  - Specialist models achieve higher peak accuracy (up to 92%) but require >300 historical samples per judge
  - Generalist models are robust (82%) and universal but miss individual nuances
  - Feature-based ML is chosen over pure text-based to avoid spurious stylistic cues that might leak outcomes
- **Failure signatures**:
  - High accuracy (>80%) but very low Macro-F1 (<60%) indicates class imbalance dominance
  - Cross-domain models performing suspiciously well suggests data leakage
  - LLM extraction F1 dropping for Trial Court outcomes vs Appeal Court indicates difficulty with complex procedural history
- **First 3 experiments**:
  1. Replicate extraction baseline using "Prompt#1" on the Gold Standard subset to verify LLM extraction F1 matches claims
  2. In-Domain vs. Generalist A/B Test: Train Random Forest on "Generic" bucket vs "Anatole" bucket, confirm Anatole's F1 is significantly higher
  3. Cross-Domain Matrix: Take "Anatole" model and run on "Babiche" test set, verify performance drop (e.g., from ~83% to ~76%)

## Open Questions the Paper Calls Out

- **Question**: Does the "judge variable" effect generalize to other legal domains and judicial systems beyond French child custody cases?
- **Question**: What explains the "dysfunctional" specialist models that underperform expectations (e.g., Dacrons, Faubers, Hauynes with XGB)?
- **Question**: Why do behavioral features (abuse, neglect, addiction) show minimal predictive importance despite their theoretical legal salience?
- **Question**: Are individual judges' decision-making patterns stable over time, or do they evolve with experience, precedent, or institutional changes?

## Limitations

- Analysis restricted to French appellate child custody cases (2007-2017), limiting cross-jurisdictional applicability
- LLM extraction pipeline relies on proprietary Llama 3.3 70B without detailed error analysis for complex procedural histories
- Pseudonymization prevents validation of whether identified patterns reflect genuine judicial disposition versus case selection effects

## Confidence

- **High Confidence**: Specialist vs. generalist performance comparison demonstrates measurable judge effects (92.85% vs 82.63% F1)
- **Medium Confidence**: Mechanism explaining judge-specific decision patterns through learned feature weightings is plausible but not fully validated
- **Low Confidence**: Cross-domain transfer tests conclusively prove non-transferability; alternative explanations cannot be ruled out

## Next Checks

1. Replicate the specialist vs. generalist comparison on a held-out test set to confirm the 10-point F1 gap is not due to overfitting
2. Conduct ablation studies removing individual feature clusters to identify which legal factors drive judge-specific patterns
3. Test the LLM extraction pipeline on French trial court rulings (more complex than appeals) to validate robustness claims