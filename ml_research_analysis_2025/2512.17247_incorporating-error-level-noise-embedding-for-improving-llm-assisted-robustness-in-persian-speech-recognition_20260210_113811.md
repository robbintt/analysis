---
ver: rpa2
title: Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness
  in Persian Speech Recognition
arxiv_id: '2512.17247'
source_url: https://arxiv.org/abs/2512.17247
tags:
- noise
- speech
- error
- correction
- persian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of robust Automatic Speech Recognition
  (ASR) in noisy environments, particularly for low-resource languages like Persian.
  The authors propose a noise-sensitive ASR error correction framework that leverages
  multiple hypotheses from a modified Whisper-large decoder and introduces Error Level
  Noise (ELN) embeddings to capture semantic- and token-level disagreement across
  hypotheses.
---

# Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition

## Quick Facts
- arXiv ID: 2512.17247
- Source URL: https://arxiv.org/abs/2512.17247
- Reference count: 25
- Primary result: ELN-conditioned LLM reduces Persian WER from 31.10% to 24.84% on noisy test set

## Executive Summary
This paper addresses robust ASR for Persian speech in noisy environments by introducing Error Level Noise (ELN) embeddings that capture disagreement across multiple ASR hypotheses. The authors propose a noise-sensitive error correction framework where LLaMA-2-7B is fine-tuned to condition on ELN vectors alongside N-best hypotheses, enabling the LLM to reason about hypothesis reliability during correction. Experimental results demonstrate significant WER reduction on a challenging mixed-noise Persian test set, outperforming both raw Whisper and fine-tuned text-only baselines.

## Method Summary
The approach uses fine-tuned Whisper-large to generate 5-best hypotheses per utterance via beam search. ELN vectors are computed as mean pairwise squared differences between sentence-BERT embeddings (semantic level) and token embeddings (local level), capturing noise-induced uncertainty through hypothesis disagreement. These ELN vectors are projected via MLP to LLM embedding space and prepended as prefix tokens to the input prompt. LLaMA-2-7B with LoRA fine-tuning is trained on Common Voice Persian augmented with MUSAN noise at various SNR levels. The model learns to use ELN magnitude and structure to weight hypothesis reliability during correction, achieving improved robustness compared to both zero-shot and fine-tuned text-only approaches.

## Key Results
- ELN-conditioned model achieves 24.84% WER on Mixed Noise test set vs 31.10% baseline (Raw Whisper)
- Outperforms fine-tuned text-only baseline (30.79% WER) by significant margin
- ELN magnitude correlates with WER degradation, though reliability breaks down at extreme values (>20)
- Text-only ELN approach outperforms audio-based methods (RobustGER) on English VB-DEMAND task

## Why This Works (Mechanism)

### Mechanism 1: Disagreement-Based Noise Proxy
ELN vectors quantify variance across N-best hypotheses as a proxy for noise-induced uncertainty. Higher disagreement between hypothesis embeddings indicates greater acoustic degradation and transcription uncertainty.

### Mechanism 2: Noise-Conditioned LLM Reasoning
ELN embeddings are projected to LLM embedding space and prepended as prefix tokens, allowing the model to learn how disagreement patterns map to correction strategies for unreliable hypotheses.

### Mechanism 3: Text-Only Noise Representation
The approach captures noise effects through linguistic disagreement alone, avoiding computational complexity of audio-level noise distillation while maintaining correction effectiveness.

## Foundational Learning

- **N-best Hypothesis Lists and Beam Search Decoding**: Required to generate multiple hypotheses per utterance for ELN computation; beam search provides ranked alternatives.
  - Quick check: Why would greedy decoding (1-best) fail to support ELN-based correction?

- **Sentence Embeddings (Sentence-BERT)**: Used to project hypotheses into fixed-dimensional semantic space for computing sentence-level ELN.
  - Quick check: How would you compute semantic variance across 5 hypotheses using their embedding vectors?

- **Prefix/Prompt Embedding Conditioning**: ELN vectors are injected as learnable prefix tokens rather than concatenated to text, allowing LLM to attend to noise information before processing hypotheses.
  - Quick check: Why might prepending ELN embeddings outperform appending them after the hypotheses?

## Architecture Onboarding

- **Component map**: ASR Frontend → Text Normalization → ELN Extractor → MLP Projection → LLaMA-2-7B + LoRA
- **Critical path**: Noisy audio → Whisper beam search → 5 normalized hypotheses → Sentence-BERT/token embeddings → ELN computation → MLP projection → LLaMA-2-7B (ELN prefix + hypotheses) → corrected text
- **Design tradeoffs**: 5-best vs larger N (cost vs signal quality); sentence vs token-level ELN (semantic vs local uncertainty); text-only vs multimodal (simplicity vs acoustic cues)
- **Failure signatures**: Base model degradation (64.58% WER); fine-tuned plateau (~30.79% WER); high ELN variance at extreme magnitudes (>20) causing unreliable predictions
- **First 3 experiments**:
  1. Baseline replication: Run Persian Whisper-large on Mixed Noise test set; confirm ~31% WER and generate 5-best lists
  2. ELN ablation: Train three variants—sentence-only ELN, token-only ELN, and combined; compare WER on SNR=5dB and SNR=10dB
  3. Cross-noise generalization: Train on SNR=5dB data only, evaluate on Mixed Noise and Clean; measure ELN-WER correlation across conditions

## Open Questions the Paper Calls Out

- **Cross-lingual generalization**: Whether ELN-conditioned correction transfers to other languages without language-specific fine-tuning
- **Real-world noise evaluation**: Performance on authentic noisy Persian speech with dialectal variation versus synthetic MUSAN noise
- **Architecture transferability**: Whether ELN conditioning effectiveness extends to other LLM families beyond LLaMA-2-7B
- **Optimal N-best selection**: The ideal number of hypotheses for ELN computation and its sensitivity to performance

## Limitations

- Evaluation limited to Persian Common Voice data (~90 hours) and synthetic MUSAN noise, not representing real-world acoustic diversity
- Several implementation details unspecified: MLP architecture, LoRA hyperparameters, batch sizes, and Sentence-BERT model variant
- Performance degrades at extreme ELN magnitudes (>20), indicating breakdown in uncertainty calibration under severe noise

## Confidence

- **High**: ELN-conditioned model achieves significantly lower WER (24.84%) vs baseline (31.10%) and fine-tuned text-only (30.79%)
- **Medium**: Correlation between ELN magnitude and WER; text-only ELN sufficiency based on English VB-DEMAND comparison
- **Low**: ELN magnitude reliably reflects utterance difficulty across diverse conditions; avoiding computational overhead of audio-level features

## Next Checks

1. **Cross-Lingual Generalization Test**: Apply trained Persian ELN-conditioned model to English/other language ASR with synthetic noise; measure ELN-WER correlation and correction transfer without language-specific fine-tuning.

2. **Real-World Noise Evaluation**: Test system on audio from actual noisy environments (cafes, streets, transportation) versus synthetic MUSAN noise; compare ELN distributions and correction effectiveness between conditions.

3. **ELN Signal Analysis**: Conduct controlled ablation varying N-best hypotheses (n=3, 5, 7, 10); measure trade-off between ELN signal quality and computational cost to determine minimum hypotheses for 95% maximum improvement.