---
ver: rpa2
title: 'From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World
  Navigation Task'
arxiv_id: '2502.16690'
source_url: https://arxiv.org/abs/2502.16690
tags:
- spatial
- grid
- units
- agent
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper investigates how LLMs represent spatial information\
  \ in text-based navigation tasks. It evaluates six LLaMA-3 models (1B to 90B parameters)\
  \ on a 5\xD75 grid-world task using six different spatial information representations\
  \ (SIRs)."
---

# From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task

## Quick Facts
- arXiv ID: 2502.16690
- Source URL: https://arxiv.org/abs/2502.16690
- Reference count: 40
- Primary result: Cartesian spatial representations yield highest navigation success rates; abstract spatial features encoded in intermediate layers are partially invariant to representation format.

## Executive Summary
This paper investigates how large language models (LLMs) represent and process spatial information through a controlled grid-world navigation task. The study compares six LLaMA-3 models (1B to 90B parameters) on navigation tasks using six different spatial information representations, finding that Cartesian formats consistently outperform topographic and textual representations. Probing the LLaMA-3.1-8B model reveals that internal units encoding spatial features like agent position and action correctness are primarily located in intermediate layers and show partial invariance across representation formats. A subset of these units also activate during unrelated spatial reasoning tasks, suggesting the existence of abstract spatial models within LLMs that generalize beyond specific input formats.

## Method Summary
The study employs a 5×5 grid-world navigation task (GWSOT) where models must navigate from a starting position to a goal using four directional actions. Six spatial information representations (SIRs) are tested: Cartesian (JSON coordinates, chess notation), topographic (symbol grid, word grid), and textual (row/column descriptions). The LLaMA-3.1-8B model is probed using linear regression to identify units encoding spatial features, with cross-SIR consistency tests determining abstract spatial encoding. Performance is measured via success rate, path efficiency, and probing R² scores for grid configuration prediction.

## Key Results
- Cartesian SIRs consistently outperformed topographic and textual SIRs across all model sizes (p < .001)
- Spatial feature encoding units are predominantly located in intermediate layers (8-22)
- 286 core units encoding action correctness also activate during unrelated spatial reasoning tasks
- No units were found encoding specific grid cells across all SIRs, unlike biological place cells

## Why This Works (Mechanism)

### Mechanism 1: Cartesian Spatial Encoding Advantage
- Explicit coordinate representations enable more reliable spatial navigation than topographic or prose descriptions by allowing direct arithmetic comparison rather than requiring the model to infer spatial structure from text layout.
- Core assumption: LLMs have stronger pre-existing circuits for numerical comparison operations than for parsing 2D structure from text layout.
- Evidence anchors: Cartesian SIRs consistently outperformed other formats across model sizes (p < .001); limited direct corpus support for representation format comparisons.
- Break condition: Advantage may weaken for egocentric reasoning tasks requiring relative rather than allocentric coordinates.

### Mechanism 2: Abstract Spatial Feature Encoding in Intermediate Layers
- Middle layers (8-22) extract higher-level spatial abstractions that are partially invariant to input format, with early layers processing format-specific patterns.
- Core assumption: Middle layers specialize in conceptual abstraction, consistent with prior interpretability work showing higher-level features emerge there.
- Evidence anchors: 448 parameters significantly correlated with agent's x position across all SIR types; predominantly in intermediate and deeper layers.
- Break condition: No units encode specific grid cells across all SIRs—abstraction holds for continuous features (x, y, boundary), not discrete locations.

### Mechanism 3: Task-Independent Spatial Reasoning Units
- 286 core units (layers 12-22) encode abstract spatial relationships and respond preferentially to spatial vs. non-spatial questions in separate tasks.
- Core assumption: These units function as general-purpose spatial reasoning circuits, not task-specific pattern matchers.
- Evidence anchors: Distribution of correlation coefficients significantly higher than zero for spatial vs. non-spatial prompts (W = 16634, p = 0.005).
- Break condition: Ablation of these units reduced success rate only marginally (59% → 55%), suggesting they are sufficient but not necessary.

## Foundational Learning

- Concept: Linear Probing
  - Why needed here: The paper's core method—fitting linear regressions from activations to spatial features—requires understanding what high R² implies about information encoding.
  - Quick check question: If a linear probe achieves R² = 0.45 on layer 10 but R² = 0.20 on layer 30, what does this suggest about where spatial information is most accessible?

- Concept: Representation Invariance
  - Why needed here: The paper's main theoretical claim depends on finding units that encode space "regardless of how that information is represented"—this is tested via cross-SIR significance.
  - Quick check question: Why is finding units significant across all six SIRs stronger evidence for "abstract spatial encoding" than units significant within one SIR?

- Concept: Layer Specialization in Transformers
  - Why needed here: Results consistently show spatial units concentrated in intermediate layers, aligning with prior work on where conceptual features emerge.
  - Quick check question: If spatial units were found primarily in layers 0-5, what alternative explanation would you consider?

## Architecture Onboarding

- Component map: Input layer (6 SIR formats) -> LLaMA-3.1-8B processing -> action token generation -> activation extraction -> linear probing analysis -> unit correlation testing -> cross-SIR validation -> ablation testing

- Critical path:
  1. Run 100 navigation trials per SIR (600 total), collecting activations at each layer during action generation
  2. Fit linear models: activations → 50-dim grid configuration (25 agent + 25 goal binary indicators)
  3. For each unit, test correlation with spatial features (x-position, y-position, boundary, action correctness) per SIR
  4. Apply Bonferroni correction, then AND across SIR masks to find invariant units
  5. Validate invariant units on unrelated spatial reasoning dataset (200 spatial + 200 non-spatial prompts)

- Design tradeoffs:
  - Simple 5×5 grid enables controlled probing but limits claims about complex environments
  - 8B model chosen for tractability; larger models not probed due to compute constraints
  - Bonferroni correction is conservative—may miss weaker but real spatial encodings
  - Ablation of all JSON-correlated units (59.7% of model) broke coherence, limiting causal inference

- Failure signatures:
  - No units encode specific grid cells across all SIRs (unlike biological "place cells")
  - Cross-SIR R² drops sharply when training/testing across different SIR classes
  - 1B/3B models near random (~10%) for non-Cartesian SIRs
  - Ablating 286 core spatial units produced minimal performance change

- First 3 experiments:
  1. Replicate 6-SIR comparison on 7×7 grid with static obstacles to test whether Cartesian advantage persists under complexity.
  2. Probe LLaMA-3.1-70B on a subset of layers (e.g., 0, 8, 16, 24, 31) to verify spatial unit distribution scales with model size.
  3. Upweight core spatial units (multiply activations by scalar >1) during navigation to test whether enhanced spatial circuits improve performance on harder tasks.

## Open Questions the Paper Calls Out

- **Complexity Scaling**: Do abstract spatial units become necessary for navigation in more complex environments (obstacles, multiple goals, 3D spaces)? Ablation experiments showed minimal performance impact (59%→55%) when silencing abstract spatial units in the simple 5×5 grid, suggesting they are not strictly necessary for easy tasks. Evidence would require ablation studies on spatial navigation tasks with obstacles, larger grids, or 3D environments.

- **Model Scale Effects**: How do internal spatial representations change or remain invariant as model scale increases beyond 8B parameters? Only LLaMA-3.1-8B was probed due to computational constraints; behavioral data shows performance scales with model size but internal mechanisms at larger scales remain unexplored. Evidence would require probing experiments on 70B and 90B models using the same methodology.

- **Multimodal Integration**: How does integrating visual input with textual spatial representations affect the formation and use of abstract spatial models? Current study only compared text-based representations; multimodal spatial reasoning remains unexplored. Evidence would require comparing probing results from vision-language models on spatial tasks with and without visual input.

## Limitations

- The 5×5 grid with a single static goal represents a highly constrained environment that may not capture how LLMs handle more complex spatial reasoning tasks.
- The absence of spatial units encoding specific grid cells across all SIRs suggests the current approach may only capture coarse spatial representations rather than fine-grained spatial memory.
- The ablation results present a paradox: while the paper identifies 286 "core" spatial units, ablating them produces only marginal performance changes (59% → 55%), suggesting either distributed encoding or that identified units are associative rather than causal.

## Confidence

- **High Confidence**: Cartesian representations outperform topographic and textual formats for grid navigation (supported by consistent performance differences across all six model sizes with p < .001).
- **Medium Confidence**: Abstract spatial features are encoded in intermediate layers and show partial invariance to input format (demonstrated through units correlating with agent position across SIRs, though cross-SIR generalization is limited).
- **Low Confidence**: The identified 286 core spatial units represent a sufficient mechanism for abstract spatial reasoning (contradicted by ablation results showing minimal performance impact).

## Next Checks

1. **Complexity Scaling Test**: Replicate the 6-SIR comparison on a 7×7 grid with static obstacles to determine whether Cartesian advantage persists under increased spatial complexity and whether more units encoding specific grid cells emerge.

2. **Causal Intervention Validation**: Implement targeted unit amplification (increasing activations of the 286 core units by 2-3×) during navigation to test whether enhanced spatial circuits improve performance on harder tasks, providing stronger causal evidence than ablation alone.

3. **Cross-Domain Spatial Generalization**: Test whether units significant for grid navigation also correlate with spatial features in a completely different spatial task (e.g., 2D maze navigation or spatial reasoning word problems) to better establish true abstract spatial reasoning capability.