---
ver: rpa2
title: 'One Set to Rule Them All: How to Obtain General Chemical Conditions via Bayesian
  Optimization over Curried Functions'
arxiv_id: '2502.18966'
source_url: https://arxiv.org/abs/2502.18966
tags:
- optimization
- number
- figure
- reaction
- benchmark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of identifying general chemical
  reaction conditions that perform well across multiple substrates, a critical need
  in pharmaceutical and materials research. The authors formulate this as an optimization
  problem over curried functions, where the goal is to find parameters that maximize
  an aggregated objective function across a set of tasks (substrates).
---

# One Set to Rule Them All: How to Obtain General Chemical Conditions via Bayesian Optimization over Curried Functions

## Quick Facts
- **arXiv ID**: 2502.18966
- **Source URL**: https://arxiv.org/abs/2502.18966
- **Reference count**: 40
- **Primary result**: Sequential acquisition strategies that decouple parameter and substrate selection perform comparably to complex joint optimization approaches in finding general chemical reaction conditions

## Executive Summary
This paper addresses the challenge of identifying chemical reaction conditions that perform well across multiple substrates, a critical need in pharmaceutical and materials research. The authors formulate this as an optimization problem over curried functions, where the goal is to find parameters that maximize an aggregated objective function across a set of tasks (substrates). Through systematic benchmarking on four real-world chemical reaction datasets, they demonstrate that simple sequential acquisition strategies that decouple parameter and substrate selection perform comparably to more complex joint optimization approaches, while exploratory acquisition functions are the most critical factor for successful optimization.

## Method Summary
The method uses Bayesian optimization with partial monitoring to optimize chemical reaction conditions across multiple substrates. A Gaussian Process surrogate model is defined over the joint space of conditions and substrates, with molecular fingerprints used to represent substrates. The algorithm selects the next condition using an exploratory acquisition function (typically UCB), then selects the substrate to evaluate it on using a separate acquisition function. The aggregated objective (typically mean yield across substrates) is estimated through Monte Carlo integration over the posterior distribution. The approach is implemented in the open-source CurryBO library, which extends BoTorch with curried function capabilities.

## Key Results
- Optimization over multiple substrates yields more transferable optima compared to single-substrate optimization
- Simple sequential acquisition strategies perform comparably to more complex joint optimization approaches
- The choice of acquisition function for parameter selection significantly impacts performance, with more explorative strategies showing better results
- The proposed method successfully identifies general conditions that transfer well to held-out test substrates

## Why This Works (Mechanism)

### Mechanism 1: Latent Generality via Curried Functions
The framework defines a generality metric over a discrete task space (substrates) and treats the joint space as a function generator. By using a surrogate model to infer the posterior distribution of the aggregated objective based on sparse, partial observations, the optimizer can estimate how a condition performs across all tasks even if it has only been tested on a few. This allows optimization of a latent generality metric without exhaustive evaluation of all tasks.

### Mechanism 2: Efficiency of Sequential Decoupling
Decoupling the selection of conditions and substrates using simple one-step lookahead acquisition performs comparably to complex joint optimization strategies. The paper posits that in partial monitoring, the cost of picking a suboptimal substrate for a specific iteration is low because the primary driver of optimization is updating the joint model. This reduces computational overhead without significantly sacrificing sample efficiency.

### Mechanism 3: Exploration-Biased Robustness
High exploration in the condition space is the most critical factor for finding general optima. In "needle in a haystack" chemical spaces where most conditions fail, the partial monitoring scenario leads to noisy uncertainty estimates. Exploitative strategies tend to overfit to early successes on limited substrates, while exploratory acquisition functions force the algorithm to map the viable "general" region broadly before refining.

## Foundational Learning

- **Concept: Gaussian Processes (GPs) over Joint Spaces**
  - **Why needed here**: You must understand how to construct a kernel that combines continuous/discrete conditions with molecular representations of substrates to model the joint space
  - **Quick check question**: Can you explain how a Tanimoto kernel on molecular fingerprints would interact with a standard RBF kernel on temperature in a GP surrogate?

- **Concept: Partial Monitoring**
  - **Why needed here**: This is the formal constraint of the problem—you cannot observe the "true" objective (generality) directly; you only observe a sample. You need to understand how to estimate the aggregated objective via Monte Carlo integration over the posterior.
  - **Quick check question**: Why is optimizing the aggregated objective harder than standard optimization when you can only query single pairs?

- **Concept: Acquisition Functions (UCB vs. EI)**
  - **Why needed here**: The paper emphasizes that the choice of acquisition function (specifically exploratory ones like UCB) is more impactful than the complexity of the strategy.
  - **Quick check question**: In the context of partial monitoring, why might Expected Improvement perform worse than Upper Confidence Bound if the surrogate's uncertainty estimates are poorly calibrated?

## Architecture Onboarding

- **Component map**: GP surrogate -> Posterior Aggregator -> Acquisition Policy (sequential) -> Benchmark Oracle
- **Critical path**:
  1. Receive partial observation (condition, substrate, yield)
  2. Update GP surrogate on joint space
  3. Aggregate: Compute posterior distribution for aggregated objective across all substrates
  4. Select condition: Optimize UCB over aggregated posterior to propose next condition
  5. Select substrate: Optimize Posterior Variance to propose next substrate
  6. Query benchmark oracle for (condition, substrate) and update model

- **Design tradeoffs**: Sequential vs. Joint acquisition (Sequential performs comparably with lower compute cost); Aggregation definition (Mean vs. Threshold optimization); Exploration factor β in UCB acquisition
- **Failure signatures**: Mode Collapse (repeated substrate selection); Overfitting to Noise (poor test performance); Stagnation (early plateau in GAP score)
- **First 3 experiments**:
  1. Sanity Check: Run Random and Single Substrate baselines on augmented benchmark to confirm generality gap
  2. Ablation on Exploration: Implement SEQ 1LA-UCB-PV and sweep UCB parameter β (0.5 vs 5.0) to verify higher exploration improves GAP score
  3. Strategy Comparison: Compare sequential strategy (SEQ 1LA-UCB-PV) against Bandit algorithm on 50-experiment budget

## Open Questions the Paper Calls Out
- Does developing tighter coupling mechanisms between the condition space and substrate space improve the efficacy of two-step lookahead acquisition strategies?
- To what extent does the choice of molecular representation and surrogate model architecture impact the sample efficiency of generality-oriented optimization?
- Is the finding that exploratory acquisition functions are the most critical factor for success robust across different problem formulations, specifically for "min" (robust) aggregation?

## Limitations
- The curried function formulation assumes the aggregation metric adequately captures "generality," which may not hold for all chemical optimization scenarios
- Sequential decoupling's effectiveness relies on weak coupling between conditions and substrates, which may not hold in cases where specific conditions only work for specific substrates
- The paper uses augmented datasets to simulate more realistic scenarios, but the quality of these synthetic data depends on the Random Forest emulators' training

## Confidence
- **High confidence**: Sequential acquisition strategy's comparable performance to joint optimization, and importance of exploration in acquisition functions
- **Medium confidence**: Claim that curried functions enable optimization of latent generality metrics
- **Low confidence**: Specific exploration-exploitation balance is optimal across all chemical domains

## Next Checks
1. **Mechanism validation**: Test whether curried function framework's generality estimates correlate with actual performance on held-out substrates when using different chemical representations
2. **Generalization testing**: Apply sequential acquisition strategy to a fifth, independently generated chemical dataset to verify performance benefits hold beyond original four benchmarks
3. **Robustness analysis**: Systematically vary the exploration factor β in UCB acquisition across a wider range to map sensitivity of GAP score improvements to exploration intensity