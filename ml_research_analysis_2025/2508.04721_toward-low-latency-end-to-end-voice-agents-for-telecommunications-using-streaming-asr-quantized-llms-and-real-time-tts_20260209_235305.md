---
ver: rpa2
title: Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming
  ASR, Quantized LLMs, and Real-Time TTS
arxiv_id: '2508.04721'
source_url: https://arxiv.org/abs/2508.04721
tags:
- real-time
- streaming
- pipeline
- latency
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a low-latency end-to-end voice agent pipeline
  tailored for telecommunications, integrating streaming ASR, a quantized LLM, retrieval-augmented
  generation, and real-time TTS. It uses a multi-threaded architecture with 4-bit
  quantization and sentence-level streaming to achieve response times below 1 second,
  with an average total latency of 0.94 seconds.
---

# Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS

## Quick Facts
- arXiv ID: 2508.04721
- Source URL: https://arxiv.org/abs/2508.04721
- Authors: Vignesh Ethiraj; Ashwath David; Sidhanth Menon; Divya Vijay
- Reference count: 7
- One-line primary result: Pipeline achieves sub-1-second latency (0.94s avg) for telecom voice agents using 4-bit quantized LLM and sentence-level streaming.

## Executive Summary
This paper presents a low-latency end-to-end voice agent pipeline for telecommunications, integrating streaming ASR, a 4-bit quantized LLM, retrieval-augmented generation over telecom documents, and real-time TTS. The system is evaluated on a custom dataset of 500 telecom-related utterances from RFC documents, achieving an average total latency of 0.94 seconds. Key mechanisms include sentence-level streaming to overlap LLM generation and TTS synthesis, 4-bit quantization for memory efficiency, and a multi-threaded producer-consumer architecture with binary serialization. The pipeline demonstrates strong semantic preservation (cosine similarity of 0.87) and is positioned for real-time telecom applications like customer support and diagnostics.

## Method Summary
The pipeline processes audio through a Conformer-CTC streaming ASR model to generate transcripts, which are embedded and used to retrieve relevant telecom documents via FAISS similarity search. A 4-bit quantized LLM (TSLAM-Mini-2B) generates responses using the retrieved context, while a PunctuatedBufferStreamer detects sentence boundaries and pushes them to a thread-safe queue. TTS synthesis begins immediately on the first complete sentence while LLM continues generating, reducing Time-to-First-Audio. The system is implemented in Python using PyTorch, HuggingFace Transformers, and NVIDIA Triton Inference Server, deployed on an NVIDIA H100 GPU with 80GB memory.

## Key Results
- End-to-end latency of 0.94 seconds on average, with maximum observed latency of 3.154 seconds.
- LLM generates tokens at an average of 80 tokens/sec, with RAG retrieval latency of 0.008 seconds and TTS synthesis latency of 0.29 seconds.
- Cosine similarity between input and output transcripts is 0.87, indicating strong semantic preservation.
- Real-Time Factor (RTF) remains below 1.0, confirming real-time feasibility.

## Why This Works (Mechanism)

### Mechanism 1: Sentence-Level Streaming Overlaps LLM and TTS Execution
Streaming complete sentences to TTS while LLM continues generation reduces time-to-first-audio. The PunctuatedBufferStreamer class detects sentence boundaries via regex-based punctuation detection, placing serialized sentences into a thread-safe queue. TTS consumes this queue in FIFO order while LLM produces, enabling parallel execution.

### Mechanism 2: 4-Bit Quantization Reduces Memory and Inference Latency
4-bit post-training quantization via BitsAndBytes reduces GPU memory footprint and LLM inference time without substantial quality loss. Quantization compresses model weights from 16-bit to 4-bit, reducing memory bandwidth requirements and enabling faster matrix operations on GPU tensor cores optimized for lower precision.

### Mechanism 3: Producer-Consumer Threading with Binary Serialization Minimizes Inter-Module Blocking
Multi-threaded execution with non-blocking queues and msgpack binary serialization reduces end-to-end pipeline latency by ~0.8–1.0 seconds. LLM and TTS run in separate threads coordinated via a thread-safe queue. TTS thread is pre-warmed before LLM output arrives. Binary serialization reduces data transfer overhead between modules.

## Foundational Learning

- **Concept: Connectionist Temporal Classification (CTC)**
  - Why needed here: The ASR module (TTE) uses Conformer-CTC for frame-synchronous streaming output without explicit alignment.
  - Quick check question: Can you explain why CTC enables streaming output where attention-based encoder-decoder models might not?

- **Concept: Producer-Consumer Concurrency Pattern**
  - Why needed here: Core architectural pattern coordinating LLM output streaming to TTS via thread-safe queues.
  - Quick check question: What happens if the consumer (TTS) processes faster than the producer (LLM) generates sentences?

- **Concept: Dense Vector Retrieval (FAISS)**
  - Why needed here: RAG module retrieves telecom documents via inner-product search over T-VEC embeddings.
  - Quick check question: Why does normalized inner-product approximate cosine similarity for retrieval ranking?

## Architecture Onboarding

- **Component map:**
  Audio Input → TTE ASR → Transcript → T-VEC Embedding → FAISS Retrieval
  Contextualized Prompt ← Retrieved Chunks
  LLM generation (4-bit) → Sentence Queue → T-Synth TTS → Audio Output

- **Critical path:** ASR (0.05s) → RAG (0.008s) → LLM generation (0.67s) → TTS synthesis (0.29s) = ~0.94s total mean latency. LLM dominates.

- **Design tradeoffs:**
  - 4-bit quantization trades potential quality degradation for ~40% latency reduction (assumption: acceptable for telecom QA).
  - Sentence-level streaming vs. token-level: sentence boundaries simplify TTS prosody but delay first-audio vs. token-chunked synthesis.
  - Single-node H100 deployment vs. distributed: simplifies coordination but limits horizontal scalability.

- **Failure signatures:**
  - Latency spikes >3s: likely GPU scheduling jitter or memory pressure.
  - Cosine similarity drops <0.7: ASR transcription errors propagating to RAG retrieval quality.
  - TTFA >1s: TTS warm-up incomplete or queue blocking on LLM generation stalls.

- **First 3 experiments:**
  1. Latency breakdown profiling: Run 100 utterances, log per-component timing to confirm LLM remains bottleneck; test with/without 4-bit quantization.
  2. Streaming granularity test: Compare sentence-level vs. fixed 5-token chunk streaming on TTFA and audio naturalness.
  3. ASR error injection: Synthesize noisy/degraded audio inputs to measure cosine similarity degradation and retrieval failure rates.

## Open Questions the Paper Calls Out
- Future work should consider adopting larger or more specialized ASR models to improve transcription quality and semantic similarity.
- The pipeline's performance in multilingual environments with varying syntax and morphological complexity remains unexplored.
- The impact of 4-bit quantization on factual accuracy and hallucination rates in RAG responses has not been assessed.

## Limitations
- Proprietary models (TTE, T-VEC, TSLAM-Mini-2B, T-Synth) are not publicly available, preventing direct reproduction.
- The 500-utterance dataset and code repository are not linked; paper claims open-sourcing but no URL given.
- RAG configuration details (chunk size, overlap, k neighbors, prompt template) not specified.

## Confidence
- **Low latency (0.94s avg, <1s total)**: Medium confidence. Supported by detailed per-component profiling and real-time factor <1.0, but dependent on proprietary optimized models.
- **Semantic preservation (cosine similarity 0.87)**: Low confidence. Metric computed on unknown dataset with no inter-annotator agreement or baseline comparison reported.
- **Sentence-level streaming benefit**: Medium confidence. Mechanism described clearly and aligns with prior work (i-LAVA), but no ablation vs. token-level streaming is provided.
- **4-bit quantization viability**: Medium confidence. Cited performance retention (>95%) is plausible per BitsAndBytes literature, but no quality degradation analysis on telecom domain is shown.

## Next Checks
1. **Ablation study on streaming granularity**: Implement both sentence-level and fixed-token chunk streaming (e.g., 5 tokens) on a public telecom QA dataset. Measure TTFA, audio naturalness (via MOS), and latency. This isolates the claimed benefit of sentence-level TTS initiation.
2. **Open-model pipeline replication**: Substitute proprietary components with open equivalents (Conformer-CTC ASR, MiniLM embeddings, 4-bit Phi-2/Gemma LLM, Piper TTS). Profile end-to-end latency and compare against claimed 0.94s. This tests whether the architecture, not just the models, drives performance.
3. **Error robustness analysis**: Inject varying levels of ASR noise (e.g., 5-20% word error rate) into the pipeline. Measure degradation in cosine similarity and retrieval recall. This validates the claim that telecom-specific jargon ensures robust semantic alignment under real-world conditions.