---
ver: rpa2
title: Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks
arxiv_id: '2508.13744'
source_url: https://arxiv.org/abs/2508.13744
tags:
- image
- multi-image
- focus
- information
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies and addresses cross-image information leakage
  in large vision-language models (LVLMs), where visual cues from multiple images
  become entangled during multi-image inference, leading to degraded performance.
  To mitigate this, the authors propose FOCUS, a training-free decoding strategy that
  sequentially masks all but one image with random noise, guiding the model to focus
  on individual images.
---

# Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks

## Quick Facts
- arXiv ID: 2508.13744
- Source URL: https://arxiv.org/abs/2508.13744
- Reference count: 8
- The paper proposes FOCUS, a training-free decoding strategy that mitigates cross-image information leakage in LVLMs for multi-image tasks, achieving up to +32.1% improvement on VisMin benchmark.

## Executive Summary
Large Vision-Language Models (LVLMs) suffer from cross-image information leakage during multi-image inference, where visual cues from different images become entangled, leading to degraded performance on tasks requiring image distinction. The authors identify this problem through systematic evaluation across multiple benchmarks and propose FOCUS, a training-free decoding strategy that addresses this issue without requiring architectural changes or additional training. FOCUS achieves significant improvements across four multi-image benchmarks and three major LVLM families by implementing a sequential masking approach combined with contrastive refinement.

## Method Summary
FOCUS addresses cross-image information leakage through a training-free decoding strategy that sequentially processes each image while masking others with random noise. The method works by first generating focused inferences where only one image is visible at a time, then aggregating these logits with a noise-only reference input to enable contrastive refinement. This approach effectively suppresses residual signals from masked images without requiring any model retraining or architectural modifications. The technique is validated across multiple LVLM families including InternVL3, Qwen2.5-VL, and LLaVA-OneVision, demonstrating consistent performance improvements on various multi-image reasoning benchmarks.

## Key Results
- Up to +32.1% improvement in Image score and +29.9% in Group score on VisMin benchmark
- Up to +18.8% improvement in Image score and +16.8% in Group score on Winoground benchmark
- Consistent performance gains across four multi-image benchmarks (Winoground, VisMin, Mantis-Eval, MuirBench) and three LVLM families

## Why This Works (Mechanism)
The method works by preventing token-level entanglement during the decoding process of LVLMs when processing multiple images. By sequentially masking all but one image with random noise, FOCUS forces the model to focus on individual images rather than allowing visual cues to mix across images. The contrastive refinement step, which uses a noise-only reference input, further suppresses any residual signals from the masked images that might still leak through. This approach effectively breaks the cross-image dependency that causes performance degradation in standard multi-image inference.

## Foundational Learning

**Cross-Image Information Leakage**: The phenomenon where visual information from multiple images becomes entangled during LVLM inference, causing confusion between distinct visual concepts across images. Needed because understanding this problem is crucial for improving multi-image reasoning capabilities. Quick check: Observe performance degradation when LVLMs process multiple related images versus single images.

**Contrastive Refinement**: A technique that uses reference inputs (in this case, noise-only images) to help distinguish between relevant and irrelevant information during inference. Needed to effectively suppress residual signals from masked images. Quick check: Compare logits with and without noise reference to verify signal suppression.

**Training-Free Decoding Strategies**: Methods that improve model performance without requiring additional training or architectural modifications. Needed to provide practical solutions that can be applied to existing LVLMs. Quick check: Verify that the original model weights remain unchanged after applying the strategy.

## Architecture Onboarding

**Component Map**: Input images -> Sequential masking with random noise -> Focused individual inferences -> Logits aggregation -> Contrastive refinement with noise reference -> Final output

**Critical Path**: The sequential masking and focused inference steps are critical, as they directly address the cross-image leakage problem by isolating visual information from each image before aggregation.

**Design Tradeoffs**: The method trades computational efficiency (multiple inference passes) for improved accuracy, versus a single-pass approach that suffers from information leakage. The use of random noise masking versus more sophisticated attention-based masking represents another key tradeoff.

**Failure Signatures**: The approach may fail when images share very similar visual features, when the random noise pattern inadvertently correlates with image content, or when the aggregation step cannot effectively combine the focused inferences.

**First Experiments**: 
1. Test FOCUS on a simple two-image comparison task to verify basic functionality
2. Compare performance with and without noise reference to validate contrastive refinement
3. Evaluate the impact of different noise patterns on masking effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- The underlying cause of cross-image leakage remains somewhat speculative, with the exact mechanisms not fully characterized
- Performance gains are primarily measured through standard evaluation metrics, with effectiveness on complex real-world scenarios not demonstrated
- The method's robustness across diverse image domains and task complexities could be further explored

## Confidence
- High confidence in the existence of cross-image leakage phenomenon: Well-demonstrated across multiple models and benchmarks with consistent degradation patterns
- Medium confidence in FOCUS effectiveness: Significant improvements shown, but relies on specific masking strategy with potential edge cases
- Medium confidence in interpretation of results: Contrastive refinement appears effective, but alternative explanations for gains cannot be fully ruled out

## Next Checks
1. Test FOCUS on extended context scenarios with 4+ images to evaluate scalability and potential performance degradation in longer inference chains
2. Evaluate the method's robustness across diverse image domains (medical, satellite, artistic) beyond the standard benchmarks to assess generalizability
3. Conduct human evaluation studies to verify that improvements in metrics translate to meaningful qualitative improvements in multi-image reasoning capabilities