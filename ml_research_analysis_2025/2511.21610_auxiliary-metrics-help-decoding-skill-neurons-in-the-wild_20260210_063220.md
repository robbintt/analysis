---
ver: rpa2
title: Auxiliary Metrics Help Decoding Skill Neurons in the Wild
arxiv_id: '2511.21610'
source_url: https://arxiv.org/abs/2511.21610
tags:
- neurons
- language
- prompt
- neuron
- soft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a lightweight method to identify neurons
  encoding specific skills in large language models (LLMs). The approach trains soft
  prompts and correlates neuron activations with auxiliary metrics such as external
  labels or model confidence scores.
---

# Auxiliary Metrics Help Decoding Skill Neurons in the Wild

## Quick Facts
- arXiv ID: 2511.21610
- Source URL: https://arxiv.org/abs/2511.21610
- Reference count: 9
- One-line primary result: Lightweight method identifies skill neurons via soft prompt training and correlation with auxiliary metrics across diverse tasks

## Executive Summary
This paper introduces a method to identify neurons encoding specific skills in large language models by training soft prompts and correlating neuron activations with auxiliary metrics like labels, confidence, or loss. The approach successfully detects sparse, interpretable skill neurons across tasks including open-ended generation, natural language inference, and arithmetic reasoning. Notably, it uncovers previously unknown model heuristics in arithmetic without manual token aggregation. Results demonstrate the framework's ability to reveal fine-grained linguistic skills and model behaviors across diverse tasks.

## Method Summary
The method trains soft prompts on frozen LLMs to elicit task-specific activation patterns, then identifies skill-related neurons by computing Pearson correlation between FFN neuron activations and auxiliary metrics. For each task, learnable prompt tokens are optimized while the model remains frozen, positioned after the instruction to attend to input via causal attention. Neuron activations are extracted on validation samples and correlated with chosen metrics (labels, loss, or confidence). Top-K neurons by absolute correlation are selected as skill-related, revealing sparse subsets of neurons encoding specific abilities.

## Key Results
- Successfully identifies skill neurons across binary classification (Skill-Mix), NLI (HANS), and arithmetic tasks
- Reveals sparse neuron populations encoding specific skills, distinguishable from bulk distribution
- Discovers previously unknown arithmetic heuristics using loss as unsupervised metric
- Demonstrates method works without manual token aggregation, unlike prior approaches

## Why This Works (Mechanism)

### Mechanism 1: Soft Prompt as Task-Specific Activation Probe
Soft prompts trained on frozen models elicit task-specific activation patterns in skill-related neurons without modifying model weights. Learnable prompt tokens are optimized to minimize task loss while the pretrained model remains frozen. The soft prompt, positioned after the instruction, attends to input via causal attention and routes processing through neurons encoding relevant skills. The core assumption is that the pretrained model already encodes target skills; soft prompts selectively activate these existing pathways.

### Mechanism 2: Correlation-Based Neuron Selection via Auxiliary Metrics
Pearson correlation between neuron activations and auxiliary metrics (labels, confidence, loss) identifies neurons whose activity co-varies with task-relevant behavior. For each neuron, activations on soft prompt positions across validation are computed, then correlated with a chosen metric. Neurons with highest absolute correlation are selected as skill-related. The core assumption is that neurons encoding a skill will show systematic activation differences correlated with metric variation.

### Mechanism 3: Sparse Skill Neuron Detection
Skill-encoding neurons are rare within the full neuron population; high-correlation neurons form a sparse subset distinguishable from the bulk distribution. Correlation values across all neurons follow a heavy-tailed distribution. A threshold (e.g., top-10) separates high-correlation skill neurons from the majority with near-zero correlation. The core assumption is that skills are encoded in localized, specialized neurons rather than distributed broadly across the network.

## Foundational Learning

- **Concept: Soft Prompt Tuning**
  - Why needed here: The method depends entirely on soft prompts for task adaptation without weight updates; understanding how learned prompt tokens condition model behavior is essential.
  - Quick check question: Why does the method place soft prompts *after* the instruction rather than before?

- **Concept: Feed-Forward Network (FFN) Neuron Activation**
  - Why needed here: The method probes FFN neurons specifically; you must understand the neuron definition and activation computation to implement or extend this work.
  - Quick check question: Given the LLaMA FFN formula FFN(h) = W³(SiLU(W²h) ⊙ (W¹h)), what constitutes "neuron i" and its activation?

- **Concept: Correlation vs. Causation in Interpretability**
  - Why needed here: The paper explicitly limits claims to correlation; misunderstanding this could lead to overconfident conclusions about neuron function.
  - Quick check question: What intervention experiment would be needed to establish that a detected neuron *causes* rather than merely correlates with a skill?

## Architecture Onboarding

**Component map:**
Input instruction x -> [Embedding layer] -> [Soft prompt tokens p₁...pₗ] -> [Transformer layers: Attention + FFN] -> FFN neurons -> Activations a_{l,i,k}(x) -> [Correlation computer] -> Top-K neuron selection

**Critical path:**
1. Train soft prompt on S_train with frozen model weights (AdamW, lr=3e-3, 20 soft tokens per paper)
2. Forward-pass S_val with trained prompt; extract FFN activations at each soft prompt position
3. Compute auxiliary metric m for each validation sample (label, loss, or confidence)
4. Compute Pearson correlation per neuron per position; take max across positions
5. Select neurons exceeding correlation threshold

**Design tradeoffs:**
- **K (neurons selected):** Lower K = higher precision but may miss relevant neurons; higher K = more coverage but includes noise
- **Soft prompt length (l):** More positions = more activation data, but longer training and potential overfitting
- **Metric choice:** Labels require annotation; loss/confidence are annotation-free but may capture confounding factors
- **Position aggregation (max vs. mean):** Max captures any position with signal; mean may dilute sparse strong signals

**Failure signatures:**
- Flat correlation distribution (no high-correlation tail) → model lacks skill, or metric doesn't capture skill, or prompt training failed
- Many neurons exceed threshold → skill may be distributed; consider lowering K or investigating overlap
- Selected neurons activate on spurious patterns → metric is confounded (e.g., detecting length instead of reasoning)
- Activation distributions don't separate by skill → probe may be detecting something other than the intended skill

**First 3 experiments:**
1. **Reproduce Skill-Mix binary classification:** Train soft prompt on spatial reasoning vs. metaphor generation; verify top-correlated neuron shows separated activation distributions by skill class (cf. Figure 2)
2. **HANS heuristic probing:** Use lexical overlap heuristic as metric; confirm sparse high-correlation neurons (check correlation histogram shape matches Figure 4) and verify activation differs across heuristics
3. **Unsupervised arithmetic shortcut discovery:** Use per-sample loss as metric on BigBench arithmetic; inspect top-activating samples to identify emergent patterns (e.g., last-digit multiplication shortcut in Figure 5)

## Open Questions the Paper Calls Out

**Open Question 1:** Do the identified high-correlation neurons causally control the execution of specific skills, or are they merely epiphenomenal byproducts of other internal processes?
- Basis in paper: The Conclusion states, "we encourage future work exploring the causal influence of these identified neurons," and Section 5 explicitly notes the framework discovers correlations but leaves causality to future work.
- Why unresolved: The current methodology relies exclusively on computing Pearson correlations between activations and auxiliary metrics; it does not perform intervention studies (e.g., ablation or activation patching) to verify if manipulating these neurons changes the output.
- What evidence would resolve it: Results from causal intervention experiments, such as ablating the identified "shortcut" neurons to see if the model ceases to use the heuristic, or amplifying "skill" neurons to see if they trigger the skill in unrelated contexts.

**Open Question 2:** How robust are the identified skill neurons to variations in the soft prompt initialization and training process?
- Basis in paper: Section 5 lists "dependence on the quality of prompt tuning" as a limitation, and Section 2.1 notes that the method trains "l randomly initialized vectors."
- Why unresolved: The paper does not analyze whether different random seeds or prompt lengths result in the same set of neurons being identified as high-correlation "skill neurons."
- What evidence would resolve it: A consistency analysis measuring the overlap (e.g., Jaccard index) of neurons identified across multiple training runs with different random seeds.

**Open Question 3:** Can the identified shortcut neurons be targeted for suppression to force the model to rely on robust reasoning rather than heuristics?
- Basis in paper: The paper identifies neurons for a "previously unknown shortcut" in arithmetic (Section 3, RQ3), but stops short of testing if suppressing this neuron eliminates the shortcut behavior.
- Why unresolved: The paper focuses on the "observation stage" (Section 1); it demonstrates the ability to *find* neurons but does not validate the utility of these findings for model correction or repair.
- What evidence would resolve it: An experiment where the identified arithmetic shortcut neuron is inhibited (e.g., set to zero) during inference, followed by an evaluation of whether the model's accuracy on standard arithmetic problems improves or degrades.

## Limitations

- **Metric validity concerns**: Assumes per-sample loss directly reflects heuristic use in unsupervised arithmetic discovery, validated only by manual inspection of top samples
- **Soft prompt dependency**: No ablation showing whether correlation patterns are genuine skill encodings or artifacts of the soft prompt training process
- **No causal validation**: All claims are correlational; no ablation studies to verify identified neurons actually cause observed behaviors

## Confidence

**High confidence**: Technical implementation of Pearson correlation-based neuron selection and demonstration that auxiliary metrics can provide supervision for neuron identification are sound and well-supported.

**Medium confidence**: Claims about sparse neuron populations are supported by correlation distribution visualizations but lack quantitative comparison to null distributions or rigorous sparsity measurement.

**Low confidence**: Claims about discovering previously unknown model heuristics rely entirely on qualitative inspection without systematic verification that identified neurons are actually responsible for the behavior.

## Next Checks

**Check 1: Causal intervention validation**: For each identified skill neuron set, perform activation ablation by setting neuron activations to zero during inference on held-out test samples. Measure performance degradation specifically for the target skill while controlling for general capability loss.

**Check 2: Soft prompt ablation study**: Compare correlation-based neuron identification results when using (a) trained soft prompts, (b) random soft tokens, (c) no soft prompt, and (d) multiple random initializations of soft prompts to determine whether correlation patterns are genuine skill encodings or artifacts.

**Check 3: Null model and sparsity quantification**: Generate null distributions by shuffling auxiliary metrics across samples and recomputing correlation distributions. Compute statistical tests comparing real vs. null distributions and quantify sparsity as fraction of neurons exceeding correlation thresholds.