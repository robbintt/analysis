---
ver: rpa2
title: 'VC-Agent: An Interactive Agent for Customized Video Dataset Collection'
arxiv_id: '2509.21291'
source_url: https://arxiv.org/abs/2509.21291
tags:
- video
- user
- agent
- videos
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces VC-Agent, an interactive MLLM-based system\
  \ for efficient customized video dataset collection. The agent addresses the challenge\
  \ of manually collecting large-scale, specialized video datasets by enabling iterative\
  \ user interactions\u2014initial query, confirmation, and comments\u2014to progressively\
  \ refine collection criteria."
---

# VC-Agent: An Interactive Agent for Customized Video Dataset Collection

## Quick Facts
- arXiv ID: 2509.21291
- Source URL: https://arxiv.org/abs/2509.21291
- Reference count: 24
- Primary result: MLLM-based interactive agent achieves 64.82% IoU vs 50.42% for top MLLMs in customized video dataset collection

## Executive Summary
This paper introduces VC-Agent, an interactive MLLM-based system designed to address the challenge of manually collecting large-scale, specialized video datasets. The system enables iterative user interactions—initial query, confirmation, and comments—to progressively refine collection criteria through a three-stage workflow. The backend employs two novel policies: a Template-Based Acceptance Policy and an Attribute-Aware Rejection Policy, both dynamically updated using user feedback. Extensive experiments on a new benchmark of 10K videos demonstrate that VC-Agent outperforms traditional video retrieval methods and MLLMs, achieving 64.82% IoU versus 50.42% for top MLLMs. User studies show significant time savings (486 hours for 335K videos) and high data quality, validating its practical utility for customized video dataset collection.

## Method Summary
VC-Agent is an interactive MLLM-based system that enables efficient customized video dataset collection through iterative user interactions. The system operates through a three-stage workflow: initial query, confirmation, and comments, allowing users to progressively refine collection criteria. The backend implements two novel policies—Template-Based Acceptance Policy and Attribute-Aware Rejection Policy—that are dynamically updated using user feedback. The Template-Based Acceptance Policy uses structured templates to guide video acceptance decisions, while the Attribute-Aware Rejection Policy focuses on identifying and filtering out videos that don't meet specific attribute requirements. These policies work together to optimize the video selection process based on user preferences and feedback, significantly improving collection efficiency and quality compared to traditional methods.

## Key Results
- VC-Agent achieves 64.82% IoU versus 50.42% for top MLLMs in customized video dataset collection
- User studies demonstrate significant time savings of 486 hours for collecting 335K videos
- Extensive experiments on a new 10K video benchmark show VC-Agent outperforms traditional video retrieval methods

## Why This Works (Mechanism)
The VC-Agent system works by combining iterative human feedback with intelligent policy-based decision making. The three-stage interaction workflow (query, confirmation, comments) creates a feedback loop where user preferences are progressively refined. The Template-Based Acceptance Policy provides structured guidance for video acceptance, ensuring consistency in selection criteria, while the Attribute-Aware Rejection Policy specifically targets unwanted attributes for removal. This dual-policy approach, combined with dynamic updates based on user feedback, creates a system that learns and adapts to user preferences over time, resulting in more accurate and efficient video dataset collection compared to static retrieval methods or pure MLLM approaches.

## Foundational Learning
- **Multi-modal Large Language Models (MLLMs)**: AI models that can process and generate both text and visual content; needed for understanding video content and user queries; quick check: verify model supports both text and video input/output
- **Template-Based Policy Systems**: Structured approaches for decision-making using predefined templates; needed for consistent acceptance criteria; quick check: ensure templates cover all relevant video attributes
- **Iterative Feedback Loops**: Systems that continuously refine outputs based on user input; needed for progressive improvement of collection criteria; quick check: validate feedback is being properly incorporated into policy updates
- **Attribute-Aware Filtering**: Techniques for identifying and filtering based on specific attributes; needed for precise rejection of unwanted content; quick check: confirm attribute detection accuracy meets requirements
- **User Interaction Design**: Frameworks for structuring human-AI collaboration; needed to create effective three-stage workflow; quick check: verify each interaction stage provides clear value to users
- **Video Dataset Collection Metrics**: Evaluation methods for measuring collection quality and efficiency; needed to benchmark system performance; quick check: ensure metrics align with actual collection goals

## Architecture Onboarding

Component Map: User Interface -> VC-Agent Core -> Template-Based Acceptance Policy -> Attribute-Aware Rejection Policy -> Video Database

Critical Path: User provides initial query → VC-Agent processes query → Template-Based Acceptance Policy evaluates videos → Attribute-Aware Rejection Policy filters unwanted videos → User provides confirmation/comments → Policies update based on feedback → Repeat cycle

Design Tradeoffs: The system trades off computational overhead from iterative feedback and policy updates against improved collection accuracy and user satisfaction. The three-stage workflow adds complexity but enables more precise control over collection criteria. The dual-policy approach increases implementation complexity but provides more nuanced decision-making compared to single-policy systems.

Failure Signatures: 
- Policy update delays causing user frustration
- Template rigidity preventing adaptation to nuanced user preferences
- Attribute detection errors leading to incorrect video rejections
- Feedback loop breakdown from poor user interface design
- Performance degradation with very large video datasets

First 3 Experiments to Run:
1. Baseline comparison with traditional video retrieval methods on small dataset (100 videos)
2. A/B test comparing single-policy vs dual-policy approaches on medium dataset (1K videos)
3. User study measuring time savings and quality improvements on full benchmark (10K videos)

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on a single 10K video benchmark, limiting generalizability to diverse video domains
- Time savings results based on specific user study setup may not be reproducible across different user groups
- Implementation details of the Template-Based Acceptance Policy and Attribute-Aware Rejection Policy are not fully elaborated

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance improvements over traditional methods | High |
| Time savings in user studies | Medium |
| Generalizability across domains | Medium |
| Policy mechanism effectiveness | Medium |

## Next Checks
1. Conduct cross-domain validation using multiple video datasets from different domains to assess generalizability of VC-Agent's performance improvements
2. Perform a multi-site user study with diverse participants to verify the reported time savings and quality improvements across different user groups and collection scenarios
3. Implement a detailed ablation study focusing on the Template-Based Acceptance Policy and Attribute-Aware Rejection Policy components to quantify their individual contributions to overall performance