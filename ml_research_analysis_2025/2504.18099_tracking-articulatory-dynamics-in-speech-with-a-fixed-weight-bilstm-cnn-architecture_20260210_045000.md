---
ver: rpa2
title: Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture
arxiv_id: '2504.18099'
source_url: https://arxiv.org/abs/2504.18099
tags:
- speech
- articulatory
- features
- speaker
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a stacked BiLSTM-CNN architecture for predicting
  tongue and lip articulatory features from speech acoustics. The BiLSTM captures
  temporal dependencies in acoustic data, while a 1D CNN with fixed weights performs
  post-processing smoothing to ensure realistic articulatory trajectories.
---

# Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture

## Quick Facts
- **arXiv ID**: 2504.18099
- **Source URL**: https://arxiv.org/abs/2504.18099
- **Reference count**: 40
- **Primary result**: Fixed-weight BiLSTM-CNN architecture achieves PCC 0.810 and RMSE 0.761 mm for speaker-dependent acoustic-to-articulatory inversion.

## Executive Summary
This paper introduces a stacked BiLSTM-CNN architecture for predicting tongue and lip articulatory features from speech acoustics. The BiLSTM captures temporal dependencies in acoustic data, while a 1D CNN with fixed weights performs post-processing smoothing to ensure realistic articulatory trajectories. Experiments are conducted using two EMA datasets (MOCHA and USC-TIMIT) representing UK and US English speakers, respectively. The model is evaluated in speaker-dependent, speaker-independent, corpus-dependent, and cross-corpus scenarios. Results show that fixed-weight initialization in the smoothing CNN consistently improves performance, achieving higher Pearson Correlation Coefficients (PCC) and lower Root Mean Square Errors (RMSE) compared to adaptive initialization.

## Method Summary
The approach uses 429-dimensional acoustic features (39 MFCCs × 11 context frames) as input to a dense layer (400 units, ReLU), followed by stacked bidirectional LSTM layers (400 units each) to model temporal dependencies. A dense layer reduces dimensionality to 16 before passing through a 1D CNN smoothing layer with fixed weights derived from a low-pass filter. The architecture processes frame-level data (25ms, 10ms hop) and predicts 16 articulatory features including 12 EMA sensor coordinates and 4 derived tract variables. Training uses batch size 8, early stopping (patience=7), and Z-score normalization of EMA trajectories.

## Key Results
- Speaker-dependent mode: PCC 0.810, RMSE 0.761 mm with fixed-weight CNN
- Speaker-independent mode: PCC 0.799, RMSE 0.768 mm with fixed-weight CNN
- Cross-corpus mode: PCC 0.24-0.35, RMSE 3.69-3.88 mm (significant degradation)
- Fixed-weight CNN consistently outperforms adaptive initialization across all evaluation scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fixed-weight initialization in the smoothing CNN improves articulatory trajectory prediction compared to adaptive (random) initialization.
- Mechanism: A pre-initialized low-pass filter (derived from a windowed sinc function with Hanning window) provides strong inductive bias for smooth, physically plausible trajectories. By freezing these weights, the model is constrained to produce temporally coherent outputs rather than overfitting to jagged predictions.
- Core assumption: Articulatory movements inherently exhibit smooth, continuous trajectories; abrupt discontinuities in predictions reflect modeling artifacts, not genuine physiology.
- Evidence anchors:
  - [abstract] "fixed-weight initialization in the smoothing CNN consistently improves performance, achieving higher Pearson Correlation Coefficients (PCC) and lower Root Mean Square Errors (RMSE)"
  - [section 6.2] "fixed weight initialization strategy involved keeping the best-performing weight in the low-pass filter frozen"
  - [corpus] Weak direct corpus support—no neighbor papers specifically validate fixed-weight smoothing in AAI; mechanism remains architecture-specific claim.
- Break condition: If target articulatory data contains high-frequency components beyond typical physiological range (e.g., pathological tremor), fixed smoothing may over-regularize and obscure genuine signal.

### Mechanism 2
- Claim: Stacked BiLSTM layers enable effective temporal dependency modeling for acoustic-to-articulatory mapping.
- Mechanism: Bidirectional processing captures both preceding and following acoustic context at each time step, addressing the one-to-many nature of acoustic-articulatory mapping where future sounds influence current articulation (coarticulation).
- Core assumption: Acoustic features within an 11-frame context window (±5 frames) provide sufficient temporal information for articulatory estimation at the central frame.
- Evidence anchors:
  - [abstract] "BiLSTM captures temporal dependencies in acoustic data"
  - [section 6.1] "BiLSTM to learn the dynamic property of the training data through the forward and backward direction"
  - [corpus] Neighbor paper "Discovering dynamical laws for speech gestures" supports dynamical modeling approaches but does not directly validate BiLSTM for AAI.
- Break condition: If sequence lengths exceed training distribution significantly, or if real-time inference requires causal-only processing, bidirectional architecture becomes inapplicable.

### Mechanism 3
- Claim: Fixed-weight smoothing provides greater benefit when training and test data share linguistic/phonetic characteristics.
- Mechanism: Fixed weights encode corpus-invariant smoothing priors; performance gains manifest in speaker-dependent, corpus-dependent, and speaker-independent modes where articulatory patterns remain within learned distribution. Cross-corpus scenarios violate this, reducing fixed-weight advantage.
- Core assumption: Smoothing requirements are relatively consistent across speakers within the same linguistic variety; cross-dialect differences require adaptive capacity.
- Evidence anchors:
  - [section 8.3] "fixed weight initialization has shown better performance in those scenarios where test set have linguistic or phonetic relation with the training set"
  - [section 8.3] Cross-corpus: RMSE 3.69/3.88 mm, PCC 0.24/0.35—performance collapses regardless of initialization
  - [corpus] No direct corpus validation of this generalization boundary; neighbor papers do not address cross-corpus AAI transfer.
- Break condition: When deployment corpus differs substantially from training corpus in accent, speaking rate, or recording conditions, fixed-weight benefits diminish; domain adaptation required.

## Foundational Learning

- Concept: **Acoustic-to-Articulatory Inversion (AAI)**
  - Why needed here: The entire paper addresses this inverse mapping problem; understanding its one-to-many, nonlinear nature is prerequisite.
  - Quick check question: Can you explain why multiple articulatory configurations might produce similar acoustic outputs?

- Concept: **Recurrent neural network temporal modeling**
  - Why needed here: BiLSTM architecture assumes familiarity with sequence modeling, gate operations (forget, input, output), and bidirectional processing.
  - Quick check question: What information does the backward pass in LSTM provide that a unidirectional LSTM cannot access?

- Concept: **Low-pass filtering and trajectory smoothing**
  - Why needed here: The fixed-weight CNN implements a learnable smoothing filter; understanding frequency-domain implications helps diagnose over-smoothing vs. under-smoothing.
  - Quick check question: Why might a cutoff frequency of 25 Hz be appropriate for articulatory trajectories but inappropriate for acoustic signals?

## Architecture Onboarding

- Component map: Acoustic input → Dense(400, ReLU) → BiLSTM(400) → BiLSTM(400) → Dense(16) → 1D CNN smoothing → Articulatory output
- Critical path: Acoustic input → Dense → BiLSTM (forward + backward) → Dense → CNN smoothing → Articulatory output. The fixed-weight CNN is non-trainable; all learning occurs in Dense and BiLSTM layers.
- Design tradeoffs:
  - **Fixed vs. adaptive smoothing weights**: Fixed provides regularization and faster convergence; adaptive offers flexibility for atypical data.
  - **Batch size 8 vs. larger**: Smaller batches improved speaker-dependent performance but increased training variance; paper selected 8 empirically.
  - **Context window size (11 frames)**: Wider context improves prediction but increases latency and computational cost.
- Failure signatures:
  - Jagged, discontinuous predicted trajectories suggest CNN smoothing not applied or weights incorrectly initialized
  - High RMSE with high PCC in cross-corpus mode indicates systematic offset (domain mismatch) rather than trajectory shape error
  - Slow convergence beyond 30 epochs suggests learning rate or batch size issues; early stopping should trigger
- First 3 experiments:
  1. **Reproduce speaker-dependent baseline**: Train on single speaker (e.g., MOCHA speaker 1), test on held-out utterances. Verify PCC ≈ 0.81, RMSE ≈ 0.76 mm with batch size 8, fixed-weight CNN.
  2. **Ablate fixed-weight vs. adaptive**: Run identical configuration with randomly initialized, trainable CNN weights. Expect lower PCC and longer convergence (paper reports adaptive: SD PCC 0.799 vs. fixed 0.810).
  3. **Cross-corpus stress test**: Train on MOCHA (UK English), test on USC-TIMIT (US English). Expect severe degradation (PCC 0.24–0.35) confirming limited cross-dialect generalization; use as baseline for future domain adaptation work.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can domain adaptation techniques be specifically tailored to improve cross-corpus generalization between datasets with significant phonetic and linguistic differences, such as UK and US English?
- Basis in paper: [explicit] The conclusion states: "To enhance cross-corpus performance, domain adaptation techniques or corpus-specific model fine-tuning will be explored."
- Why unresolved: The experiments showed that cross-corpus performance (CC) is significantly worse (PCC ~0.24-0.35) than corpus-dependent performance, and the current architecture does not account for the linguistic mismatches between the MOCHA and USC-TIMIT corpora.
- What evidence would resolve it: A study implementing domain adaptation (e.g., adversarial training or feature mapping) during the training phase, resulting in statistically significant improvements in PCC and RMSE when testing the model on the opposing corpus.

### Open Question 2
- Question: Can the proposed fixed-weight smoothing CNN effectively track the articulatory dynamics of pathological or disordered speech, which may violate the model's foundational assumption of smooth, continuous trajectories?
- Basis in paper: [inferred] The introduction explicitly lists "evaluation of pathological subjects" and "detection and treatment of speech disorders" as applications. However, the methodology relies on the assumption that "articulatory movements exhibit a smooth and sequential pattern," which may not hold true for dysarthric or ataxic speech.
- What evidence would resolve it: Evaluation of the BiLSTM-CNN model on datasets containing pathological speech (e.g., dysarthria) to determine if the fixed-weight smoothing introduces excessive lag or loses critical pathological "jagged" features compared to adaptive smoothing.

### Open Question 3
- Question: Does the fixed-weight initialization strategy transfer effectively to languages with different phonotactic constraints or articulatory kinetics, such as tonal languages or those with distinct syllable structures?
- Basis in paper: [inferred] The study is restricted to English datasets (MOCHA and USC-TIMIT). The conclusion attributes cross-corpus failure to "linguistic and phonetic parameters," suggesting the fixed weights might be overfit to the temporal dynamics of English phonemes.
- What evidence would resolve it: Replicating the experimental setup on a non-English EMA corpus (e.g., Mandarin or Arabic) and comparing the performance delta between fixed and adaptive weight initialization to see if the benefits persist.

## Limitations

- Cross-corpus generalization severely limited, with PCC dropping to 0.24-0.35 when transferring between UK and US English datasets
- Fixed-weight initialization mechanism lacks detailed specification of exact kernel parameters and derivation process
- Architecture assumes stationary articulatory dynamics within each corpus, potentially limiting adaptability to speakers with atypical articulation patterns

## Confidence

**High Confidence**: Speaker-dependent performance claims (PCC 0.810, RMSE 0.761mm) with controlled initialization; ablation showing fixed-weight superiority in speaker-dependent and speaker-independent modes; general BiLSTM temporal modeling effectiveness.

**Medium Confidence**: Cross-corpus performance characterization; interpretation that fixed-weight benefits depend on linguistic/phonetic similarity between training and test sets; generalization of smoothing filter effectiveness across diverse speaking styles.

**Low Confidence**: Exact fixed-weight CNN initialization procedure; optimal cutoff frequency selection rationale (25Hz); robustness to speakers with non-standard articulatory patterns.

## Next Checks

1. **Reproduce speaker-dependent baseline**: Train on single MOCHA speaker, verify PCC ≈ 0.81 and RMSE ≈ 0.76mm using batch size 8 and fixed-weight CNN initialization.

2. **Cross-corpus adaptation experiment**: Apply domain adaptation techniques (e.g., adversarial training or feature normalization) to improve USC-TIMIT performance when trained on MOCHA data.

3. **Fixed-weight sensitivity analysis**: Systematically vary the smoothing filter cutoff frequency and kernel size to determine optimal parameters and identify breaking points where over-regularization occurs.