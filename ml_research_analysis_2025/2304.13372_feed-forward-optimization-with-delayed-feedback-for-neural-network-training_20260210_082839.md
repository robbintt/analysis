---
ver: rpa2
title: Feed-Forward Optimization With Delayed Feedback for Neural Network Training
arxiv_id: '2304.13372'
source_url: https://arxiv.org/abs/2304.13372
tags:
- error
- training
- feedback
- neural
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Feed-Forward with delayed Feedback (F3),
  a novel backpropagation-free training algorithm for deep neural networks that addresses
  both weight transport and update locking problems. F3 approximates gradients using
  fixed random feedback weights and delayed error information from the previous epoch,
  enabling parameter updates during the forward pass without a backward pass.
---

# Feed-Forward Optimization With Delayed Feedback for Neural Network Training

## Quick Facts
- **arXiv ID**: 2304.13372
- **Source URL**: https://arxiv.org/abs/2304.13372
- **Reference count**: 0
- **Primary result**: Novel backpropagation-free training algorithm achieving up to 56% smaller gap to backpropagation compared to biologically plausible alternatives

## Executive Summary
This paper introduces Feed-Forward with delayed Feedback (F3), a novel backpropagation-free training algorithm that addresses both weight transport and update locking problems in deep neural networks. F3 approximates gradients using fixed random feedback weights and delayed error information from the previous epoch, enabling parameter updates during the forward pass without a backward pass. The method demonstrates significant performance improvements over other biologically plausible approaches while maintaining theoretical guarantees that updates descend toward minimizing the loss function.

## Method Summary
F3 is a backpropagation-free training algorithm that computes weight updates during the forward pass using approximated gradient signals. The method uses fixed random feedback matrices to approximate error signals, which are derived from delayed error information stored from the previous epoch. This eliminates the need for a backward pass and enables immediate weight updates after each layer's forward computation. The algorithm maintains theoretical guarantees that updates move in descending directions toward minimizing the loss, while significantly reducing computational overhead compared to traditional backpropagation.

## Key Results
- Reduces gap to backpropagation by up to 56% for classification and 96% for regression tasks compared to other biologically plausible approaches
- Demonstrates robustness to network depth, outperforming backpropagation in depth scaling while degrading more slowly than other alternatives
- Successfully applies to complex architectures including Vision Transformers, showing broader applicability than previous methods

## Why This Works (Mechanism)

### Mechanism 1: Delayed Error as Approximate Gradient Signal
Error information from the previous epoch provides sufficiently correlated directional information to guide current updates. The algorithm stores per-sample error vectors during epoch t, then uses B_i^T * e_t-1 to approximate δh_i during epoch t+1's forward pass, decoupling gradient computation from current forward pass completion.

### Mechanism 2: Fixed Random Feedback Alignment
Fixed random feedback matrices B_i can substitute for symmetric weight transport, with forward weights W_i aligning to enable effective credit assignment. The alignment dynamics proven for linear layers extend to non-linear networks in practice, with certain initialization schemes (Kaiming, trinomial) working effectively while others (binomial, ±I) fail.

### Mechanism 3: Forward-Pass-Only Weight Updates
Computing weight updates during the forward pass eliminates backward-pass memory buffering and computational overhead. After computing each layer's output, the algorithm immediately computes and applies weight updates using approximated gradients, requiring fewer operations per epoch than backpropagation.

## Foundational Learning

### Concept: Credit Assignment Problem
Why needed here: F3 fundamentally addresses how to attribute error to parameters without backpropagation's exact gradient computation.
Quick check question: Why does delaying the error by one epoch still provide useful credit assignment signals?

### Concept: Feedback Alignment Theory
Why needed here: Understanding why random fixed weights can substitute for weight-symmetric feedback enables debugging initialization choices.
Quick check question: What properties must feedback weight matrices have for alignment to emerge? (Hint: sign diversity, non-zero density)

### Concept: Update Locking vs Weight Transport
Why needed here: These are the two biological implausibilities F3 claims to solve; distinguishing them clarifies design goals.
Quick check question: Which problem does DFA solve but DRTP doesn't, and vice versa? Why does F3 solve both?

## Architecture Onboarding

### Component Map
Input x → [Layer 1: W1, B1] → h1 → [Layer 2: W2, B2] → h2 → ... → [Layer K: WK] → y
              ↑                        ↑                                      ↑
           e_{t-1}                  e_{t-1}                                e_{t-1}
              │                        │                                      │
           B1^T*e                    B2^T*e                              (δy directly)

### Critical Path
1. Initialize B_i ~ Kaiming-uniform or trinomial {-1,0,1}; initialize e_0 = y* (targets)
2. Per-sample forward pass: For each layer i, compute h_i, then δh_i = B_i^T * e_{t-1}, then δW_i and update W_i immediately
3. After forward pass completes, compute e_t[x] = y* - y and store for next epoch
4. Repeat with newly stored errors

### Design Tradeoffs
| Choice | Benefit | Cost |
|--------|---------|------|
| Store per-sample errors | Exact sample-wise feedback | O(C × |X|) memory for dataset |
| F3-Error vs F3-Loss | Better classification performance | Loss variant equivalent for regression up to scaling |
| Delayed vs current error | Eliminates update locking | One-epoch lag in feedback |

### Failure Signatures
- High loss with binomial/±I B_i: Feedback matrices lack necessary diversity
- Degradation in very deep networks: Slower than DFA but better than BP
- Softmax transformation reduces accuracy: Over-smoothing error signal
- Transformer training instability: Sensitive to input/output encoding

### First 3 Experiments
1. MNIST baseline replication: Train 1-hidden-layer MLP (500 units, tanh) comparing F3-Error vs DRTP vs DFA. Expect ~2.7% test error for F3 vs 4.3% for DRTP.
2. Feedback initialization ablation: Compare Kaiming, trinomial, binomial, and ±I on MNIST. Verify trinomial ≈ Kaiming >> binomial, ±I.
3. Depth scaling test: Train networks with 1, 5, 10, 25, 50, 100 layers on SGEMM regression. Confirm F3 degrades slower than BP but DFA remains most robust to depth.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical alignment guarantee only covers linear layers, extension to non-linear networks is empirical
- Method shows sensitivity to architectural choices and may not generalize seamlessly to arbitrary architectures
- Memory overhead for storing per-sample errors across epochs could be prohibitive for large datasets

## Confidence
- **High Confidence**: Forward-pass-only update mechanism is well-established and trivially implementable; empirical performance gains are consistently demonstrated
- **Medium Confidence**: Fixed random feedback alignment theory has strong theoretical backing for linear cases; delayed error approximation quality shows good correlation empirically but lacks theoretical bounds
- **Low Confidence**: Computational efficiency claims require careful benchmarking against modern hardware-aware implementations

## Next Checks
1. Formal extension of alignment theory: Prove Theorem 4's 90° bound for networks with common non-linearities through layer-wise analysis or numerical verification
2. Memory efficiency analysis: Benchmark the memory overhead of per-sample error storage against alternative approaches for datasets ranging from MNIST to ImageNet
3. Architectural robustness testing: Systematically evaluate F3 on architectures with skip connections, batch normalization, and attention mechanisms to identify required modifications