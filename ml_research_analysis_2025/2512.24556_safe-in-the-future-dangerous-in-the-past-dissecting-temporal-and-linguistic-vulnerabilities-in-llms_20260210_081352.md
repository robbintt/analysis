---
ver: rpa2
title: 'Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic
  Vulnerabilities in LLMs'
arxiv_id: '2512.24556'
source_url: https://arxiv.org/abs/2512.24556
tags:
- safety
- temporal
- hausa
- gemini
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study reveals that LLM safety is highly context-dependent,
  varying dramatically across linguistic and temporal frames. Through 1,440 evaluations
  of three state-of-the-art models using a novel HausaSafety dataset, researchers
  found a 9.2x disparity between the safest and most vulnerable configurations, with
  past-tense framing bypassing defenses (15.6% safe) while future-tense scenarios
  triggered hyper-conservative refusals (57.2% safe).
---

# Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs

## Quick Facts
- arXiv ID: 2512.24556
- Source URL: https://arxiv.org/abs/2512.24556
- Reference count: 15
- Models are 9.2x more vulnerable when prompts use past-tense framing compared to future-tense scenarios

## Executive Summary
This study reveals that LLM safety is highly context-dependent, varying dramatically across linguistic and temporal frames. Through 1,440 evaluations of three state-of-the-art models using a novel HausaSafety dataset, researchers found a 9.2x disparity between the safest and most vulnerable configurations, with past-tense framing bypassing defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). Contrary to prior research showing multilingual safety gaps, two of three models were marginally safer in Hausa than English. The study identifies "Complex Interference" as the dominant vulnerability mechanism, where safety emerges from non-linear interactions between language, tense, and model architecture rather than simple degradation in low-resource settings.

## Method Summary
The study employed a 2×4 factorial experimental design testing 60 adversarial prompts across English and Hausa languages with four temporal conditions (Past, Present, Future, Temporal Displacement), yielding 480 test cases. Each case was evaluated across three models (GPT-5.1, Gemini 3 Pro, Claude 4.5 Opus) using automated safety classification via Gemini 2.5 Flash with human validation on 18.8% of samples. The HausaSafety corpus focused on West African threat scenarios across four categories: Financial Crime (20), Social Engineering (15), Cultural Violence (15), and Information Operations (10). Safety metrics included Attack Success Rate, cross-lingual drift, and joint failure rates.

## Key Results
- Past-tense framing bypassed safety defenses with only 15.6% safety rate, while future-tense scenarios triggered hyper-conservative refusals at 57.2% safety
- Two of three models were marginally safer in Hausa than English, reversing the traditional multilingual safety gap
- Nearly half of all prompts successfully jailbroke all three models simultaneously (joint failure rate of 41.7%)
- "Complex Interference" between linguistic and temporal variables created non-linear safety effects rather than simple degradation

## Why This Works (Mechanism)

### Mechanism 1: Temporal Masking via Historical Context Heuristics
Models learn from training corpora that past-tense constructions frequently appear in benign educational content. When adversarial prompts use past-tense framing ("How was a Dane gun built in 1990?"), the model's safety classifier downweights threat probability because the linguistic pattern matches socially-sanctioned discourse, not because harm intent is absent. Safety training implicitly encodes surface-level temporal patterns rather than harm-intent invariance.

### Mechanism 2: Complex Interference Between Linguistic and Temporal Variables
Two safety-relevant signals—language-based filters at tokenization and intent-based filters on semantic representations—activate at different processing stages. When signals align (e.g., Hausa + Future for Claude: uncertainty from low-resource tokenization + uncertainty from speculative framing), they trigger conservative refusal. When signals conflict (e.g., English + Past for Gemini: high semantic precision + permissive historical context), safety collapses.

### Mechanism 3: Reverse Linguistic Vulnerability via Uncertainty-Triggered Refusal
For some architectures, low-resource languages trigger higher safety rates because linguistic uncertainty activates conservative refusal heuristics. Constitutional AI approaches encode principles that resolve ambiguity toward harmlessness. When tokenization confidence drops for low-resource languages, the model defaults to refusal rather than generation. This inverts the traditional "multilingual safety divide" where low-resource languages served as backdoors.

## Foundational Learning

- **Temporal framing as an attack vector**: Understanding that "How do I make X" vs. "How was X made in 1990" vs. "How will X be made in 2030" are semantically equivalent for harm prevention but linguistically distinct for classifier activation. Quick check: If you frame a dangerous query as "historical research for a documentary," would you expect higher or lower refusal rates than the same query in present tense? (Answer: Lower refusal—this is the past-tense vulnerability.)

- **Factorial experimental design (2×4)**: The paper isolates causal contributions of language vs. tense vs. their interaction through systematic cross-product testing. Without factorial design, you couldn't distinguish whether Hausa+Past failures are due to language, tense, or their combination. Quick check: If you test English prompts in past tense and Hausa prompts in future tense, but never English+Future or Hausa+Past, can you identify interaction effects? (Answer: No—you need the full cross-product.)

- **Attack Success Rate (ASR) vs. Safety Rate**: The paper reports both; ASR = 100% - Safety Rate. System-wide ASR of 64.8% means models are unsafe on nearly two-thirds of adversarial inputs. Joint failure rate (41.7% of prompts jailbroke all three models) is a distinct metric indicating shared blind spots. Quick check: If Model A has 30% safety and Model B has 40% safety, what's the maximum possible joint failure rate? (Answer: 60%—if failures are perfectly overlapping.)

## Architecture Onboarding

- **Component map**: Input layer (language tokenization) -> Safety classification stage (pattern-matching + intent-recognition) -> Temporal processing (tense markers -> discourse type) -> Refusal generation (explicit detection OR uncertainty-based conservative defaults)

- **Critical path**: 1. Adversarial prompt arrives → tokenized with language-dependent vocabulary; 2. Temporal markers extracted → heuristic classification of "discourse type"; 3. Safety assessment runs → threshold varies by discourse-type + language-confidence; 4. If uncertainty high + architecture is uncertainty-averse (Claude) → refusal; 5. If historical frame + architecture is temporally-fragile (all models) → compliance; 6. Output generated or refused

- **Design tradeoffs**: RLHF (GPT-5.1): strong present-tense alignment, poor generalization to temporal variations; Scaling-centric (Gemini 3 Pro): high capability but safety doesn't scale proportionally; Constitutional AI (Claude 4.5 Opus): uncertainty-averse principle resolution creates reverse linguistic vulnerability but still fails on past-tense attacks

- **Failure signatures**: Historical Justification (harmful content with educational framing), Hedged Assistance (refusal-then-provide pattern), Partial Disclosure (withholds key components but provides actionable data), Direct Instruction (complete compliance without disclaimer)

- **First 3 experiments**: 1. Temporal transfer test: Take your safety benchmark, translate all prompts to past/future tense, measure ASR delta; 2. Language×Tense interaction matrix: Run a 2×4 factorial on 50 adversarial prompts, plot safety rates in heatmap; 3. Uncertainty probing: Measure token-level perplexity for safe vs. unsafe inputs across languages, test correlation with refusals

## Open Questions the Paper Calls Out

**Open Question 1**: Does "historical context" framing inhibit the same refusal circuits as explicit jailbreaks, or does it bypass them entirely? The paper calls for mechanistic interpretability analysis to visualize internal activation patterns during temporal shifts.

**Open Question 2**: Is the "reverse linguistic vulnerability" observed in Claude 4.5 Opus a model-specific anomaly or a replicable feature of high-perplexity input across architectures? The paper suggests testing additional low-resource languages beyond Hausa.

**Open Question 3**: How do non-standard dialects and code-switching (e.g., "Street Hausa," Naija Pidgin) interact with tokenizer-level safety filters compared to standardized language inputs? The paper notes that real-world adversarial inputs often employ vernaculars not tested in the current study.

**Open Question 4**: How can "Invariant Alignment" be operationalized to ensure safety stability across linguistic and temporal shifts without degrading legitimate utility? The paper proposes this as necessary paradigm shift but provides no implementation methodology.

## Limitations

- HausaSafety corpus contains only 60 base prompts across four adversarial categories, potentially missing broader vulnerability spectrum
- Study focuses exclusively on West African threat scenarios, limiting applicability to other regional contexts
- Temporal framing effects tested only in four specific configurations without exploring intermediate temporal distances
- Automated evaluation system showed 8pp favorability bias toward Gemini 3 Pro, potentially underestimating cross-model disparities

## Confidence

**High confidence**: The 9.2× disparity between safest and most vulnerable configurations is well-supported by reported data (57.2% vs 6.2% safety rates); joint failure rate of 41.7% is directly calculated from 1,440 evaluations; Claude 4.5 Opus's reverse linguistic vulnerability (45.0% Hausa vs 36.7% English safety) is explicitly documented.

**Medium confidence**: "Complex Interference" mechanism is inferred from observed non-additive interaction patterns rather than directly measured at architectural level; corpus-derived heuristic explanation for past-tense vulnerability relies on cross-referencing with external research; "Safety Pockets" affecting Global South users extrapolates from Hausa-specific results.

**Low confidence**: Proposed "Invariant Alignment" solution is conceptual and not empirically validated; claims about current safety paradigms' "fundamental blind spots" extend beyond tested models; predictions about extensive low-resource fine-tuning effects are speculative.

## Next Checks

**Validation Check 1**: Replicate temporal vulnerability experiment using larger prompt corpus (minimum 200 prompts) spanning multiple adversarial categories beyond West African contexts. Test additional temporal configurations including mixed-tense prompts and intermediate time distances.

**Validation Check 2**: Implement multi-judge evaluation system using at least three different safety assessment models with majority voting on safety classifications. Measure inter-judge agreement rates and test whether observed cross-model safety disparities persist.

**Validation Check 3**: Design controlled experiments to isolate safety classification mechanisms at different processing stages. Test whether temporal effects persist when prompts use time-specific vocabulary instead of grammatical tense, and whether language uncertainty effects hold when using subword tokenization confidence scores.