---
ver: rpa2
title: 'From large language models to multimodal AI: A scoping review on the potential
  of generative AI in medicine'
arxiv_id: '2502.09242'
source_url: https://arxiv.org/abs/2502.09242
tags:
- medical
- language
- multimodal
- clinical
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This scoping review systematically examined the evolution of generative
  AI in medicine, focusing on the shift from text-only large language models (LLMs)
  to multimodal AI systems. Analyzing 144 studies published between 2020 and 2024,
  the review found a significant trend toward multimodal models that integrate medical
  images, clinical text, and structured data.
---

# From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine

## Quick Facts
- **arXiv ID**: 2502.09242
- **Source URL**: https://arxiv.org/abs/2502.09242
- **Reference count**: 40
- **Key outcome**: The review found a significant trend toward multimodal AI models that integrate medical images, clinical text, and structured data, demonstrating promise in diagnostic support and workflow automation, though challenges remain in data integration, interpretability, and ethical considerations.

## Executive Summary
This scoping review systematically examined the evolution of generative AI in medicine, focusing on the shift from text-only large language models to multimodal AI systems. Analyzing 144 studies published between 2020 and 2024, the review identified a significant trend toward models that integrate medical images, clinical text, and structured data. These multimodal systems show promise in enhancing diagnostic support, automating clinical workflows, and improving report generation. However, key challenges persist around integrating heterogeneous data types, improving model interpretability, addressing ethical concerns, and validating AI systems in real-world clinical settings.

## Method Summary
The scoping review analyzed 144 studies published between 2020 and 2024, systematically examining the evolution of generative AI in medicine from text-only large language models to multimodal AI systems. The analysis focused on identifying trends, capabilities, and challenges in the field, with particular attention to how different AI approaches handle various types of medical data and their potential applications in clinical settings.

## Key Results
- Significant trend toward multimodal models integrating medical images, clinical text, and structured data
- Demonstrated promise in enhancing diagnostic support, automating clinical workflows, and improving report generation
- Key challenges remain in data integration, model interpretability, ethical concerns, and real-world clinical validation

## Why This Works (Mechanism)
Multimodal AI systems work by integrating multiple data types (text, images, structured data) through unified architectures that can process and correlate heterogeneous medical information. These systems leverage the complementary strengths of different data modalities - images provide visual context, text captures clinical narratives, and structured data offers standardized measurements. By combining these inputs, multimodal models can generate more comprehensive clinical insights than single-modality approaches.

## Foundational Learning
- **Multimodal fusion techniques**: Why needed - to combine different data types effectively; Quick check - evaluate how well the model integrates image features with textual embeddings
- **Cross-modal attention mechanisms**: Why needed - to identify relevant relationships between different data types; Quick check - assess attention weight distributions across modalities
- **Medical domain adaptation**: Why needed - to ensure models understand medical-specific terminology and context; Quick check - evaluate performance on domain-specific benchmarks
- **Clinical workflow integration**: Why needed - to ensure AI outputs align with existing clinical processes; Quick check - assess time savings and usability in simulated clinical scenarios
- **Ethical framework implementation**: Why needed - to address bias, privacy, and accountability concerns; Quick check - audit model outputs for demographic disparities
- **Interpretability methods for multimodal systems**: Why needed - to build trust and enable clinical validation; Quick check - evaluate explanation quality across different data modalities

## Architecture Onboarding
**Component map**: Data ingestion -> Preprocessing pipeline -> Multimodal fusion module -> Clinical reasoning layer -> Output generation -> Validation interface

**Critical path**: Medical data → Preprocessing → Multimodal integration → Clinical inference → Actionable output

**Design tradeoffs**: Flexibility vs. computational efficiency, comprehensive data integration vs. model complexity, clinical accuracy vs. interpretability

**Failure signatures**: Poor performance on underrepresented conditions, bias in demographic subgroups, inability to handle missing data modalities, generation of clinically implausible outputs

**First experiments**:
1. Benchmark multimodal performance against single-modality baselines on standardized medical datasets
2. Evaluate cross-modal attention patterns to verify meaningful data integration
3. Test model robustness to missing or incomplete data across different modalities

## Open Questions the Paper Calls Out
The review highlights several open questions including: how to effectively integrate heterogeneous data types in real-world clinical environments, what evaluation metrics best capture clinical utility beyond technical performance, how to ensure adequate representation across diverse patient populations in training datasets, and what governance frameworks are needed for responsible deployment of multimodal AI in healthcare settings.

## Limitations
- Review scope may not capture very recent developments in this rapidly evolving field
- Analysis based on published literature may miss ongoing unpublished research or proprietary systems
- Limited empirical data on how effectively multimodal systems handle real-world clinical complexity
- Does not provide systematic evaluation of how different approaches address ethical concerns and interpretability issues

## Confidence
- **High confidence** in identifying the overall trend from LLMs to multimodal AI systems
- **Medium confidence** in claims about diagnostic support and workflow automation potential
- **Medium confidence** in identifying challenges around data integration and ethical considerations
- **Low confidence** in the relative effectiveness of different multimodal approaches due to limited comparative studies

## Next Checks
1. Conduct empirical validation studies comparing multimodal AI performance against single-modality approaches across diverse clinical settings
2. Develop and test standardized evaluation frameworks that assess both technical performance and clinical utility of multimodal systems
3. Perform systematic audits of dataset diversity and representation to identify potential biases in multimodal medical AI training data