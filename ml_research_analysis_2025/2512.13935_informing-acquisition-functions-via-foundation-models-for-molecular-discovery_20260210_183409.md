---
ver: rpa2
title: Informing Acquisition Functions via Foundation Models for Molecular Discovery
arxiv_id: '2512.13935'
source_url: https://arxiv.org/abs/2512.13935
tags:
- cluster
- rounds
- time
- llmat
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces LLMAT, a likelihood-free Bayesian optimization
  method that leverages both general LLMs and chemistry foundation models to inform
  acquisition functions in molecular discovery. The approach partitions the molecular
  search space into a tree structure with local acquisition functions, enabling efficient
  candidate selection via Monte Carlo Tree Search.
---

# Informing Acquisition Functions via Foundation Models for Molecular Discovery

## Quick Facts
- arXiv ID: 2512.13935
- Source URL: https://arxiv.org/abs/2512.13935
- Reference count: 40
- Key outcome: Introduces LLMAT, a likelihood-free Bayesian optimization method that uses LLMs and chemistry foundation models to inform acquisition functions in molecular discovery, substantially improving scalability, robustness, and sample efficiency.

## Executive Summary
This paper presents LLMAT, a novel Bayesian optimization framework for molecular discovery that leverages large language models (LLMs) and foundation models to inform acquisition functions. The method addresses scalability challenges in BO by combining likelihood-free density ratio estimation with hierarchical tree partitioning and LLM-based clustering. By using binary classifiers to estimate acquisition functions directly and incorporating statistical cluster selection, LLMAT achieves superior sample efficiency and runtime performance compared to traditional BO approaches on six molecular datasets.

## Method Summary
LLMAT implements likelihood-free Bayesian optimization by estimating acquisition functions through density ratio classification rather than surrogate modeling. The method partitions the candidate space into a tree structure using MCTS, where each node contains a binary classifier that estimates local acquisition functions. Foundation models (T5-Chem, MolFormer) extract molecular features, with optional LoRA fine-tuning for adaptation. LLM-based clustering (using GPT-4o) groups candidates by predicted property levels, and Welch's ANOVA statistically prunes low-potential clusters. Meta-learning (Reptile) stabilizes classifier training across tree nodes when data is scarce.

## Key Results
- LLMAT outperforms traditional BO methods on six molecular discovery benchmarks in terms of GAP and average regret metrics
- LLM-based clustering improves computational efficiency by reducing acquisition function evaluations to promising candidate subsets
- The hierarchical tree structure with local acquisition functions provides more refined search than global single-model approaches
- Sample efficiency improvements are particularly pronounced in early optimization rounds with limited observations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Likelihood-free BO may improve sample efficiency by bypassing surrogate model learning and directly estimating acquisition functions via density ratio classification.
- **Mechanism:** Binary classifiers estimate p(y > τ|x, D_t), which is proportional to the γ-relative density ratio between promising (y > τ) and non-promising (y ≤ τ) regions. The acquisition function α(x) = π_θ(x)/(1-π_θ(x)) captures this ratio without explicit posterior inference.
- **Core assumption:** The binary classification objective with utility-weighted labels sufficiently approximates the true acquisition function landscape.
- **Evidence anchors:** [section 3.1] "Likelihood-free AF is defined as: α(x; D_t, τ) := π_θ*(x)/(1-π_θ*(x))" shows equivalence between density ratio and Probability of Improvement.

### Mechanism 2
- **Claim:** Hierarchical tree partitioning appears to enable more refined acquisition function estimates in promising regions compared to global single-model approaches.
- **Mechanism:** Binary classifiers recursively bifurcate candidate space (Ω_k → Ω_{2k+1} ∪ Ω_{2k+2}), learning local acquisition functions at each node. UCB-based path selection balances exploration-exploitation through the tree.
- **Core assumption:** Local models in partitioned subspaces generalize better than a single global model, especially with high-dimensional LLM features.
- **Evidence anchors:** [section 4.1] "Each node Ω_k is recursively bifurcated into two subsets using a binary classifier π_{θ_k}" with leaf-node AFs showing narrower confidence regions.

### Mechanism 3
- **Claim:** LLM-based clustering may provide property-relevant grouping that improves both computational efficiency and BO performance when combined with statistical cluster selection.
- **Mechanism:** General LLMs (GPT-4o, DeepSeek) cluster molecules by predicted property levels (0-4 scale). Welch's ANOVA + Games-Howell post-hoc tests identify and prune clusters with statistically lower property values.
- **Core assumption:** LLMs trained on chemical corpora capture sufficient structure-property relationships to produce meaningful coarse-grained property rankings.
- **Evidence anchors:** [figure 1] LLM rankings preserve relative ordering despite inaccurate absolute values, with LLM clustering outperforming K-means on GAP metric at p=0.

## Foundational Learning

- **Concept: Acquisition Functions as Expected Utility**
  - Why needed here: LLMAT reformulates AF estimation as classification; understanding the standard BO framework reveals what's being approximated.
  - Quick check question: Can you explain why EI, PI, and UCB can all be expressed as E_y~p(y|x,D)[u(y;τ)] for different utility functions u?

- **Concept: Density Ratio Estimation via Classification**
  - Why needed here: The core technical innovation converts AF computation into a binary classification problem.
  - Quick check question: Why does p(c=1|x) = γ·g(x)/(γ·g(x) + (1-γ)·l(x)) where g, l are densities of promising/non-promising regions?

- **Concept: Meta-learning with Sequential Reptile**
  - Why needed here: Stabilizes classifier training across tree nodes when per-node data is scarce.
  - Quick check question: How does updating the meta-parameters as θ ← θ + η(θ_k - θ) differ from standard gradient descent?

## Architecture Onboarding

- **Component map:** Input Molecules (SMILES) → Foundation Model (T5-Chem/MolFormer) → Binary Classifiers → Tree Partition (MCTS) → LLM Clustering (GPT-4o) → Statistical Test (Welch's ANOVA) → Candidate Selection

- **Critical path:** The AF prediction at inference follows: (1) route unseen candidates through tree via classifiers, (2) select path via UCB, (3) backtrack if no candidates at leaf, (4) intersect with statistically selected clusters, (5) rank by local AF.

- **Design tradeoffs:**
  - Tree depth (L): Deeper trees → more refined AFs but higher variance. Paper finds L=1-2 optimal depending on PEFT vs fixed features.
  - Quantile γ: Controls exploration-exploitation. γ=0.5 (median split) is default; lower γ focuses on extreme improvements.
  - p-value for cluster pruning: p=0 retains all clusters; p=0.05 aggressively prunes but may remove promising regions.

- **Failure signatures:**
  - AF collapse: All candidates receive near-identical α(x) values → check classifier calibration, increase training epochs or reduce learning rate.
  - Empty intersection: Ω_selected ∩ Ω_cluster = ∅ → backtracking should activate; if persistent, loosen p-value or adjust tree depth.
  - Cluster imbalance: LLM assigns >80% of candidates to one cluster → prompt may be poorly specified; verify cluster-property correlation in held-out data.

- **First 3 experiments:**
  1. Validate density ratio approximation: On synthetic 1D function (e.g., Levy-1D as in paper), compare classifier-derived α(x) against ground-truth AF from GP surrogate. Plot both to verify shape matching.
  2. Ablate tree depth: Run L=0 (flat), L=1, L=2 on a single dataset (e.g., Redox-mer) with fixed features. Measure GAP trajectory and training time to confirm depth-performance tradeoff.
  3. Test cluster selection sensitivity: Compare LLM clustering vs K-means vs no clustering on the Kinase dataset (largest, 10,449 molecules). Measure: (a) prediction time reduction, (b) GAP at round 50, (c) number of clusters retained at each p-value.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does utilizing explicit chain-of-thought (CoT) prompting strategies improve the property-awareness of LLM clustering compared to the simple prompts currently evaluated?
- Basis in paper: [Explicit] Section F (Limitations) states that the LLM-clustering method is currently evaluated using simple prompts but notes it "could be... enhanced with explicit chain-of-thought designs" in future work.
- Why unresolved: The current experimental setup relies on standard instructional prompts (Appendix C) without exploring reasoning-based prompting techniques.
- What evidence would resolve it: Comparative experiments measuring clustering correlation with ground-truth property values and final BO regret when using CoT versus standard prompting.

### Open Question 2
- Question: To what extent does the LLM-based clustering performance transfer to other frontier foundation models (e.g., DeepSeek R1, GPT-5) without significant prompt re-engineering?
- Basis in paper: [Explicit] Section F identifies extending the clustering method to other models like "GPT-5 or DeepSeek R1" as a task left for future work.
- Why unresolved: The study primarily relies on ChatGPT/GPT-4o for the clustering experiments, leaving the robustness of the prompt strategy across different model architectures untested.
- What evidence would resolve it: Benchmarks of LLMAT performance (GAP and regret metrics) using clusters generated by various other distinct LLMs using the same prompt templates.

### Open Question 3
- Question: Does incorporating observed property queries alongside initial dataset samples into the clustering prompts refine the search space partition?
- Basis in paper: [Explicit] Section F suggests that "prompts could also be refined by incorporating queries alongside the initial datasets," but this was not implemented.
- Why unresolved: The current clustering approach prompts the LLM to cluster based on general chemical knowledge rather than conditioning it on specific observed data from the active learning loop.
- What evidence would resolve it: Ablation studies comparing standard zero-shot clustering against few-shot prompting that includes examples of high/low property molecules in the prompt.

### Open Question 4
- Question: How can the likelihood-free acquisition function and tree partitioning approach be adapted to handle multi-objective optimization with competing chemical properties?
- Basis in paper: [Inferred] The paper briefly visualizes an "extension to multi-objective optimization" in the Appendix (Fig. 42) but focuses the main methodology and experiments on single-objective tasks.
- Why unresolved: The proposed density ratio formulation is designed for scalar utility functions; the interaction between tree partitions and a Pareto front is not rigorously explored.
- What evidence would resolve it: A formal extension of the LLMAT algorithm for vector-valued objectives and experimental validation on datasets with competing properties (e.g., redox potential vs. solvation energy).

## Limitations

- The LLM-based clustering effectiveness depends heavily on prompt engineering quality and the LLM's domain knowledge, with limited validation of whether clusters capture true structure-property relationships
- Statistical pruning of clusters risks eliminating genuinely promising candidates, particularly in early BO rounds when observations are sparse
- Computational overhead of maintaining and traversing a tree of classifiers, especially with PEFT fine-tuning, remains poorly characterized despite claims of improved scalability

## Confidence

- **High confidence:** The core likelihood-free BO mechanism (density ratio estimation via classification) is well-established in prior literature and the paper's implementation follows standard practices
- **Medium confidence:** Claims about LLM clustering improvements are moderately supported by GAP metrics but lack ablation studies on cluster quality and depend heavily on prompt engineering
- **Medium confidence:** The sample efficiency improvements over baselines are demonstrated empirically but could reflect hyperparameter tuning differences rather than fundamental algorithmic advantages

## Next Checks

1. **Cluster quality validation:** Generate a held-out test set of molecules with oracle property values. Apply the LLM clustering pipeline and measure: (a) clustering purity (do clusters group by property value?), (b) cluster stability across different LLM runs, (c) correlation between cluster mean property values and actual values. Compare against K-means clustering on T5-Chem features.

2. **Tree depth sensitivity analysis:** Systematically vary tree depth L from 0 to 3 on at least two representative datasets (one small, one large). For each depth, measure: (a) average GAP at round 50, (b) training time per round, (c) number of candidates evaluated per round. Plot these to verify the claimed tradeoff between refinement and computational cost.

3. **Density ratio approximation fidelity:** On a synthetic 1D optimization problem (e.g., Levy function), compare the acquisition function estimated via binary classification against the ground-truth PI/EI computed from a GP surrogate. Plot both functions and compute their correlation coefficient. Repeat with varying sample sizes (n=10, 50, 100) to assess estimator convergence.