---
ver: rpa2
title: 'Programming by Examples Meets Historical Linguistics: A Large Language Model
  Based Approach to Sound Law Induction'
arxiv_id: '2501.16524'
source_url: https://arxiv.org/abs/2501.16524
tags:
- lambda
- sound
- data
- change
- basicaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to sound law induction by
  formulating it as Programming by Examples (PBE) with Large Language Models (LLMs).
  The authors create a conceptual framework distinguishing structure vs.
---

# Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction

## Quick Facts
- **arXiv ID:** 2501.16524
- **Source URL:** https://arxiv.org/abs/2501.16524
- **Reference count:** 14
- **Primary result:** PySLICoder achieves 6% higher pass rate than previous best with one-third the parameters

## Executive Summary
This paper formulates historical linguistics' sound law induction as a Programming by Examples (PBE) task for Large Language Models. By creating a framework distinguishing structure vs. substance in synthetic data generation, the authors identify an optimal "middle-ground" approach that combines realistic linguistic inputs with structurally random programs. This leads to PySLICoder, an open-source model that outperforms larger models by leveraging GPT-4o-generated synthetic data, establishing a new state-of-the-art for automated sound law discovery.

## Method Summary
The authors frame sound law induction as PBE by representing linguistic sound changes as executable Python code using a `BasicAction` class. They generate synthetic training data through four methods varying in structure (random vs. real programs) and substance (random vs. realistic inputs), discovering that RP-LI (Random Programs + LLM-generated Nonce Inputs) performs best. A 6.7B Magicoder model is fine-tuned on this data and achieves superior performance on a benchmark of 85 historical sound laws compared to larger open-source models and GPT-4o itself.

## Key Results
- PySLICoder achieves 52.8% pass rate on single-law benchmark, outperforming previous best by 6%
- Model uses only one-third the parameters of previous best (6.7B vs 22B)
- RP-LI synthetic data method shows consistent superiority across ablation studies
- Random program structure prevents overfitting to historical biases while realistic inputs maintain linguistic validity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fine-tuning on a "middle-ground" distribution of realistic inputs (substance) but structurally random programs (low bias) improves generalization for low-resource PBE tasks better than fully realistic or fully random data.
- **Mechanism:** The authors posit that while substantive inputs (pronounceable nonce words) align the input distribution ($P_X$) with the evaluation benchmark, structurally random programs preserve diversity in the program distribution ($P_\rho$). Conversely, using "real" sound laws (IDP-PI) introduces pernicious biases or lacks the diversity required for the model to learn robust inductive reasoning, causing performance degradation.
- **Core assumption:** The model benefits from recognizing valid linguistic surface forms (inputs) but suffers when the target logic (programs) is drawn from a narrow, sparse set of historical examples.
- **Evidence anchors:**
  - [Abstract] "...find that a middle-ground approach with realistic but diverse inputs performs best."
  - [Section 6.1] "We note that the choice of inputs among poc or ptk doesnâ€™t affect the trend... IDP-PI < RP-RI < RP-PI < RP-LI."
  - [Section 7] "...randomness prevents the models from acquiring pernicious biases from too-uniform sets of actual rules."
- **Break condition:** If the evaluation tasks required highly specific, exception-heavy logic not covered by random structural sampling, the "diverse/random" program bias would likely fail to induce the necessary specific rules.

### Mechanism 2
- **Claim:** Formulating linguistic sound changes as executable Python code (PBE) allows code-specialized LLMs to leverage pre-trained reasoning capabilities for a domain-specific scientific task.
- **Mechanism:** By mapping the linguistic concept of "sound laws" to a Python class (`BasicAction`), the task enters the domain of code generation. The LLM does not need to learn the concept of "historical linguistics" from scratch; it applies existing code synthesis capabilities to string manipulation problems.
- **Core assumption:** Sound laws can be losslessly represented as ordered string rewrite functions (regex-like operations) without requiring external knowledge bases during inference.
- **Evidence anchors:**
  - [Section 1] "In writing these cascades of sound laws, Neogrammarian linguists were essentially writing programs..."
  - [Section 4.1] "To frame the task of SLI-as-PBE, LLMs are instructed to create sound law programs using a specific format, captured by a class called BasicAction."
  - [Corpus] Neighbor paper "LLM-Guided Compositional Program Synthesis" supports the premise that LLMs can effectively handle PBE tasks when guided.
- **Break condition:** If the linguistic evolution requires context-sensitive transformations that cannot be expressed by the finite-state/regular-expression logic implied by `BasicAction`, the mechanism fails to capture the phenomenon.

### Mechanism 3
- **Claim:** Synthetic data generation using a stronger "teacher" model (GPT-4o) allows a smaller "student" model (PySLICoder/Magicoder) to exceed the performance of larger open-source models.
- **Mechanism:** The process distills the reasoning capabilities of GPT-4o into the smaller model by fine-tuning the student on the specific input-output-program triplets generated by the teacher. This specializes the student for the SLI distribution, overcoming its general pre-training limitations.
- **Core assumption:** The teacher model generates syntactically correct and logically valid programs that serve as high-quality ground truth for the student.
- **Evidence anchors:**
  - [Section 6.2] "PySLICoder-RP-LI-gpt-4o attains the best overall performance among open-source models... with a third of the parameters."
  - [Section 4.3] "...determine the best condition for creating synthetic data and use it train a strong open source LLM..."
- **Break condition:** If the student model capacity is too small to memorize or generalize the diverse reasoning patterns generated by the much larger teacher, performance saturates or degrades.

## Foundational Learning

- **Concept: Programming by Examples (PBE)**
  - **Why needed here:** This is the core problem formulation. You must understand that the model receives input strings (protoforms) and output strings (reflexes) and must hallucinate a program that bridges them, rather than just translating text.
  - **Quick check question:** Given input `["tap"]` and output `["top"]`, is the valid program `a -> o / _ p` or just `tap -> top`? (The former is the PBE target).

- **Concept: Inductive Bias in Synthetic Data**
  - **Why needed here:** The paper's central finding relies on trading off "structure" (randomness) vs. "substance" (realism). Understanding inductive bias explains why adding realism (substance) to *programs* hurts performance (overfitting) while adding it to *inputs* helps.
  - **Quick check question:** Why might training a model only on actual historical laws (IDP-PI) make it worse at discovering *new* laws? (Answer: It overfits to known history/lacks diversity).

- **Concept: IPA and PanPhon**
  - **Why needed here:** The inputs are not standard text but International Phonetic Alphabet (IPA) sequences. The tokenization and "pronounceability" of nonce words are critical features.
  - **Quick check question:** Why is `mtkekst` a bad input for this task compared to `sunt`? (Answer: The former violates phonotactics/substance, which the model uses as a signal).

## Architecture Onboarding

- **Component map:** Input Processor (PanPhon tokenization) -> Prompt Constructor (BasicAction template) -> LLM Engine (Magicoder/PySLICoder) -> Executor (Python sandbox) -> Reward/Eval (Levenshtein distance)

- **Critical path:** Synthetic Data Generation (RP-LI) -> SFT Fine-tuning -> Inference (Prompt + I/O) -> Python Execution -> Reward Calculation

- **Design tradeoffs:**
  - RP-LI vs. IDP-PI: Trading program diversity (RP-LI is better) for program realism (IDP-PI is worse). The paper chooses diversity.
  - Parameter Count vs. Data Quality: Using 6.7B model + GPT-4o data is preferred over using a 22B model (Codestral) off-the-shelf.

- **Failure signatures:**
  - Syntax Errors: The LLM generates malformed `BasicAction` code.
  - Self-Feeding: The generated rule applies iteratively to its own output (the `BasicAction` class specifically implements a two-stage process to suppress this).
  - Distribution Mismatch: If fine-tuned on IDP-PI (real laws), the model fails to generalize to the evaluation set (pass rate drops to ~39-50%).

- **First 3 experiments:**
  1. Verify the Baseline: Run stock Magicoder-6.7B on the "single law" benchmark to confirm the <3% pass rate reported in Table 2.
  2. Ablate Input Substance: Fine-tune two adapters: one on RP-RI (random strings) and one on RP-LI (nonce words). Verify the ~6% performance gap (Table 1).
  3. Check Program Diversity: Visualize rules generated by IDP-PI vs RP-LI. Confirm that IDP-PI produces repetitive rule types (Table 10) while RP-LI produces diverse context windows (Table 11).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the optimal synthetic data distribution (RP-LI) identified for sound law induction generalize effectively to other Programming by Examples (PBE) domains like general string manipulation or data wrangling?
- Basis in paper: [explicit] The Conclusion states the authors plan to "explore if our findings generalize to other PBE domains like general string manipulation and data wrangling."
- Why unresolved: The current study is restricted to the specific linguistic domain of sound laws, and it is unclear if the "middle-ground" inductive bias (realistic inputs, random programs) applies to non-linguistic code generation tasks.
- What evidence would resolve it: Benchmark comparisons of models fine-tuned on RP-LI style data versus standard datasets in domains outside of historical linguistics.

### Open Question 2
- Question: Are the relative performance rankings of the synthetic data conditions (IDP-PI < RP-RI < RP-PI < RP-LI) consistent across different base model architectures?
- Basis in paper: [explicit] The Limitations section notes that all fine-tuning experiments used Magicoder-6.7B and asks "if the observations related to the fine-tuning data would hold for other similarly smaller code models as well."
- Why unresolved: Model architectures and pre-training corpora differ; the specific "substance vs. structure" trade-off might manifest differently in models like DeepSeekCoder or Qwen2.5-Coder.
- What evidence would resolve it: Replicating the four-condition fine-tuning experiment using alternative base models to verify if RP-LI remains the superior condition.

### Open Question 3
- Question: Can the performance gap between the "student" model (PySLICoder) and the "teacher" model (GPT-4o) be closed or reversed by scaling the volume of synthetic training data?
- Basis in paper: [explicit] The Conclusion highlights the plan to "explore scaling up the synthetic data to analyze... if the fine-tuned model can surpass the model used to generate the training data."
- Why unresolved: The current study used a small dataset (2.5k instances), resulting in the student model underperforming the teacher; it is unknown if this is a data scarcity issue or a fundamental limitation.
- What evidence would resolve it: Training curves showing PySLICoder performance as the synthetic dataset size increases from thousands to hundreds of thousands of samples.

## Limitations
- The evaluation relies on a curated benchmark of 85 historical sound laws, which may not capture the full diversity of real-world linguistic phenomena.
- The synthetic data generation pipeline depends on GPT-4o as a "teacher" model, creating potential distributional drift if different strong LLMs are used.
- The paper does not report on the qualitative validity of the generated sound laws - while they execute correctly, their linguistic plausibility remains untested by domain experts.

## Confidence
- **High Confidence:** The core finding that RP-LI outperforms other synthetic data generation methods on the controlled benchmark, supported by systematic ablation studies across four methods (RP-LI, RP-RI, IDP-PI, RP-PI) and repeated experiments.
- **Medium Confidence:** The claim that randomness in program structure prevents pernicious biases, as this relies on indirect evidence (performance differences) rather than explicit analysis of bias mechanisms.
- **Low Confidence:** The generalization claim to "real-world" historical linguistics applications, as the evaluation is confined to a single benchmark with controlled complexity.

## Next Checks
1. **Distribution Analysis:** Compare the distribution of rule types, contexts, and target segments in the IDP-PI (real laws) vs RP-LI (random laws) training data to quantify the claimed "pernicious biases" and diversity differences.
2. **Qualitative Expert Review:** Have historical linguists evaluate a sample of generated sound laws from PySLICoder for both functional correctness and linguistic plausibility, particularly for complex multi-context rules.
3. **Cross-Teacher Validation:** Generate synthetic data using alternative strong LLMs (e.g., Claude-3, GPT-4 Turbo) as the teacher to test the robustness of the RP-LI method's superiority across different data generation sources.