---
ver: rpa2
title: 'GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns'
arxiv_id: '2505.23630'
source_url: https://arxiv.org/abs/2505.23630
tags:
- gender
- french
- sentence
- noun
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GeNRe is the first French gender-neutral rewriting system using
  collective nouns. It combines a rule-based system with fine-tuned language models
  and an instruct-based model.
---

# GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns

## Quick Facts
- arXiv ID: 2505.23630
- Source URL: https://arxiv.org/abs/2505.23630
- Authors: Enzo Doyen; Amalia Todirascu
- Reference count: 20
- First French gender-neutral rewriting system using collective nouns

## Executive Summary
GeNRe introduces the first French gender-neutral rewriting system that replaces masculine plural generics with gender-fixed collective nouns. The system combines a rule-based approach using spaCy dependency parsing with morphological inflection, fine-tuned language models, and an instruct-based model (Claude 3 Opus). A manually curated dictionary of 315 collective noun pairs enables systematic gender neutralization while preserving semantic meaning. The rule-based system achieves the best performance metrics, demonstrating that structured linguistic approaches outperform end-to-end neural models for this specific task.

## Method Summary
GeNRe uses a manually curated dictionary of 315 French collective noun pairs to replace masculine plural member nouns with gender-neutral collective nouns. The rule-based system employs spaCy for dependency detection and the `inflecteur` module for morphological re-inflection, automatically adjusting determiners, adjectives, past participles, and pronouns to match the new noun's gender and number. Fine-tuned T5 and M2M100 models were trained on 60k RBS-generated sentence pairs. Claude 3 Opus was tested with three prompt variants: BASE (unconstrained generation), DICT (explicit target noun), and CORR (error correction). The system addresses the gender bias inherent in French masculine generics by leveraging the fact that collective nouns have fixed grammatical gender independent of referent gender.

## Key Results
- Rule-based system achieves best performance: 3.81% WER, 99.05 cosine similarity
- Claude 3 Opus with dictionary lookup achieves close results: 4.45% WER, 93.52 BLEU
- Fine-tuned models show lower performance: 5.4-5.5% WER for T5 and M2M100
- Systematic errors occur in numerical constructions and complex syntactic contexts

## Why This Works (Mechanism)

### Mechanism 1: Collective Nouns as Epicene Strategy
Replacing masculine plural member nouns with gender-fixed collective nouns neutralizes grammatical gender while preserving semantic reference to groups. French collective nouns have fixed gender independent of referent gender, allowing syntactic elements to be re-inflected accordingly. This eliminates masculine generics while maintaining semantic reference. The core assumption is semantic appropriateness, which fails in contexts like numerical structures ("millions de soldats" → "*millions de l'armée").

### Mechanism 2: Structured Dependency Detection and Inflection
Rule-based dependency detection plus morphological re-inflection yields higher accuracy than end-to-end neural models. The system uses spaCy for parsing and explicitly identifies syntactically related words, then applies inflection rules via `inflecteur`. This structured approach outperforms neural models because it directly addresses the morphological agreement cascade required when replacing nouns. Parser errors and incomplete inflection rules can break this mechanism.

### Mechanism 3: Constrained Instruct Model Generation
Instruct-based models with explicit dictionary lookup achieve near-rule-based performance without engineered pipelines. Claude 3 Opus receives the target collective noun explicitly in the prompt, constraining generation and reducing hallucination. This approach leverages the model's grammatical competence while avoiding the need for complex rule engineering. Unconstrained prompts produce semantic errors from inappropriate collective noun generation.

## Foundational Learning

- **Masculine generics in gendered languages**: French uses masculine as "default" for mixed groups, creating cognitive bias. Understanding this motivates neutralization approaches. Quick check: Does "les professeurs" refer only to male teachers, or can it include women? What cognitive effect does this have?

- **Syntactic agreement (concord)**: Replacing a noun triggers cascading changes requiring all syntactically related words to be re-inflected for gender and number. Quick check: If "les soldats sont partis" becomes "l'armée...", how many words must change and why?

- **Collective nouns as epicene strategy**: Unlike visibilization techniques, collective nouns don't alter spelling or introduce new punctuation, making them less contentious for native speakers. Quick check: Why might "lectorat" be more acceptable than "lecteur·rices"?

## Architecture Onboarding

- **Component map**: Dictionary (315 CN-member pairs) -> Dependency Detection (spaCy + custom rules) -> Generation (`inflecteur` + custom handlers) -> Neural Models (T5, M2M100) or Instruct Model (Claude 3 Opus)

- **Critical path**: Detect member noun -> Extract syntactic dependencies -> Replace with CN and adjust determiner -> Re-inflect all dependencies -> Apply corrections for past participles and object pronouns

- **Design tradeoffs**: RBS offers highest accuracy and interpretability but requires manual rule maintenance; fine-tuned models provide faster inference and generalization but lower accuracy; instruct models need no training but require API access and are costly

- **Failure signatures**: SEM errors (asemantic constructions), VERB/ADJ agreement errors (plural→singular mismatches), MISID_NOUN (noun/adjective ambiguity), GEN_FAILURE (wrong language tokens or special character issues)

- **First 3 experiments**: 1) Dictionary coverage test: Run RBS on sample, manually count unmatched masculine plurals; 2) Dependency detection ablation: Compare spaCy-only vs. spaCy + custom rules on held-out sentences; 3) Instruct prompt comparison: Test BASE vs. DICT instructions on 100 sentences

## Open Questions the Paper Calls Out

- **Question 1**: Does the use of collective nouns for gender neutralization effectively reduce cognitive gender bias in readers compared to masculine generics or visibilization techniques? The study evaluates linguistic metrics but not psycholinguistic impact on human cognitive bias.

- **Question 2**: Can the integration of contextual or semantic analysis frameworks resolve asemantic constructions caused by strict dictionary-based replacement? The current system lacks semantic validation for contextual naturalness.

- **Question 3**: Why did fine-tuning language models on rule-based data fail to improve performance, and could different training strategies bridge this gap? The paper reports negative results but doesn't explain why neural models underperformed.

## Limitations
- Dictionary coverage limits applicability, with systematic failures in numerical constructions
- Automatic metrics don't capture human judgment on naturalness and acceptability
- Instruct-based models require expensive API calls and raise reproducibility concerns
- Corpus evaluation may not capture edge cases in real-world spoken or informal French

## Confidence
- **High confidence** in RBS mechanism superiority over fine-tuned models
- **Medium confidence** in cross-linguistic validity given similar approaches in Italian and German
- **Medium confidence** in instruct model results due to API dependency and prompt sensitivity
- **Low confidence** in semantic appropriateness across all contexts due to systematic failures

## Next Checks
1. Human evaluation study: Recruit native speakers to rate naturalness and semantic appropriateness of 100 RBS outputs versus baseline masculine generics

2. Dictionary expansion test: Identify masculine plurals lacking mappings in test data, manually add 50-100 new pairs, and measure performance improvement

3. Real-world application pilot: Apply GeNRe to actual French news articles or government documents, analyzing both technical performance and potential sociolinguistic resistance