---
ver: rpa2
title: 'Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure
  in Multilingual LLMs'
arxiv_id: '2510.26024'
source_url: https://arxiv.org/abs/2510.26024
tags:
- layer
- transfer
- language
- cultural
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the tension between cross-lingual knowledge
  transfer and cultural localization in multilingual language models. While cross-lingual
  alignment improves factual transfer across languages, it often erodes the model's
  ability to provide culturally specific responses.
---

# Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs

## Quick Facts
- arXiv ID: 2510.26024
- Source URL: https://arxiv.org/abs/2510.26024
- Authors: HyoJung Han; Sweta Agrawal; Eleftheria Briakou
- Reference count: 40
- Primary result: Surgical Steering improves both cross-lingual transfer and cultural localization by applying different steering interventions at distinct model layers.

## Executive Summary
This work addresses the tension between cross-lingual knowledge transfer and cultural localization in multilingual language models. While cross-lingual alignment improves factual transfer across languages, it often erodes the model's ability to provide culturally specific responses. To balance these competing goals, the authors propose a layer-specific steering approach that applies different steering interventions at distinct model layers: one for universal transfer and another for cultural localization. Empirical results show that this method improves both cross-lingual transfer and cultural localization across six languages, outperforming standard alignment techniques. The findings reveal that cultural knowledge is not permanently lost during alignment but can be partially recovered through targeted steering, though some cultural nuance remains irrecoverably diminished.

## Method Summary
The authors propose Surgical Steering (SUR), which applies two distinct steering vectors at different layers during inference: EN-steering at layer 20 for transfer and LOC-steering at layer 28 for localization. Steering vectors are extracted from contrastive activation pairs (100 samples) using contextualized vs. decontextualized queries for localization and parallel queries across languages for transfer. The method leverages the observation that universal and cultural knowledge reside in partially separable subspaces across model layers, with perpendicularity increasing at deeper layers. This layer separation mitigates interference between transfer and localization objectives, enabling simultaneous improvement on both metrics.

## Key Results
- Surgical Steering outperforms single-layer approaches, moving models toward the "Desirable Quadrant" where both transfer and localization improve
- Cultural knowledge is recoverable but not fully restorable - heavily-aligned models show partial irreversible loss
- Layer 20 is optimal for EN-steering (universal transfer) while layer 28 is optimal for LOC-steering (cultural localization)
- The method works across four different cross-lingual alignment baselines (MIST, CLO, MIDALIGN, EN-steering)

## Why This Works (Mechanism)

### Mechanism 1: Layer-Specific Encoding of Universal vs. Cultural Knowledge
- Claim: Universal factual knowledge and culturally-specific knowledge reside in partially separable subspaces across model layers.
- Mechanism: PCA projections show that on universal tasks (GMMLU), language representations merge starting at middle layers (≈20). On cultural tasks (BLEND), representations remain separable until deeper layers (≈28). The perpendicularity analysis confirms EN-steering and LOC-steering vectors approach orthogonality at layer 28 (~82°) but are more aligned at layer 20 (~47%).
- Core assumption: The steering vectors approximate meaningful directions in representation space that generalize beyond the extraction dataset.
- Evidence anchors:
  - "while universal transfer (EN-steering) is most effective in the middle layers (peaking at layer 20), cultural localization (LOC-steering) performs optimally in the deeper layers (peaking at layer 28)"
  - Shows layer-wise PCA with different convergence patterns for GMMLU vs BLEND
  - Veselovsky et al. (2025) demonstrates localized cultural knowledge is controllable via steering
- Break condition: If EN and LOC steering vectors become highly correlated (>0.7 cosine similarity) at all layers, the disentanglement fails.

### Mechanism 2: Cultural Knowledge Suppression, Not Erasure
- Claim: Cross-lingual alignment suppresses rather than permanently destroys cultural knowledge representations.
- Mechanism: LOC-steering applied to CLA-trained models recovers 5-8% BLEND accuracy, demonstrating that cultural representations remain accessible. However, recovery is incomplete - SUR-steering on heavily-aligned models shows smaller gains than on MIST, indicating partial irreversible loss.
- Core assumption: The LOC-steering vector direction points toward a "cultural subspace" that CLA partially deactivates but doesn't destroy.
- Evidence anchors:
  - "cultural knowledge is not permanently erased but—at least to an extent—suppressed, capable of being reactivated through targeted steering"
  - Shows LOC-steering improves BLEND by +1.22% while EN-steering degrades it by -0.45%
- Break condition: If LOC-steering fails to improve BLEND accuracy on any CLA model, suppression hypothesis is falsified.

### Mechanism 3: Steering Vector Interference Mitigation via Layer Separation
- Claim: Applying EN-steering and LOC-steering at different layers reduces mutual interference compared to single-layer application.
- Mechanism: When both vectors are applied at the same layer, they compete. Surgical steering applies EN-steering at layer 20 and LOC-steering at layer 28, exploiting the perpendicularity discovered in Mechanism 1. This yields simultaneous improvements on both axes.
- Core assumption: The sequential application doesn't introduce nonlinear interactions that nullify earlier interventions.
- Evidence anchors:
  - Shows SUR-steering consistently outperforms single-vector steering, moving models toward the "Desirable Quadrant"
  - "applying LOC-steering at a deeper layer (e.g., 28) significantly boosts performance on culturally situated questions without degrading universal transfer performance"
- Break condition: If SUR-steering performance equals or underperforms the best single-vector approach on either axis, the interference-mitigation claim fails.

## Foundational Learning

- **Activation Steering / Contrastive Activation Addition**
  - Why needed here: Core intervention technique; requires understanding how to extract steering vectors from contrastive pairs and apply them during inference.
  - Quick check question: Given contrastive pairs (x_EN, x_XX), how do you compute v_EN and apply it to a new input?

- **Cross-Lingual Alignment Objectives**
  - Why needed here: Paper evaluates 4 CLA methods (MIST, MIDALIGN, CLO, EN-steering); understanding their loss functions explains why they cause cultural erasure.
  - Quick check question: Why does MIDALIGN's explicit alignment loss cause more cultural erasure than MIST's implicit alignment?

- **Transfer-Localization Trade-off Frontier**
  - Why needed here: Paper's central framing; quantifies the trade-off as ΔGMMLU vs ΔBLEND relative to unaligned baseline.
  - Quick check question: In the transfer-localization plane, which quadrant represents the goal of Surgical Steering?

## Architecture Onboarding

- **Component map:**
  - Data Preparation: OpenAssistantXX (6 languages) + FLORES → Training data
  - Model Training: Gemma-3-12B with CLA methods (MIST/MIDALIGN/CLO/EN-steering)
  - Vector Extraction: Dev set contrastive pairs → EN-vector (Layer 20) and LOC-vector (Layer 28)
  - Surgical Inference: h̃_l = h_l + γ·v_EN at layer 20, h̃_l = h_l + γ·v_LOC at layer 28
  - Evaluation: GMMLU (universal) + BLEND (cultural) with decontextualized prompts

- **Critical path:**
  1. Prepare parallel datasets: OpenAssistantXX (6 languages), FLORES for alignment training; BLEND with decontextualization
  2. Train CLA models (MIST/MIDALIGN/CLO) or use unaligned baseline
  3. Extract steering vectors from Dev1 (100 samples)
  4. Validate layer selection on Dev2 (100 samples)
  5. Apply SUR-steering at inference: h̃_l = h_l + γ·v_EN at layer 20, h̃_l = h_l + γ·v_LOC at layer 28

- **Design tradeoffs:**
  - γ scaling: Paper uses γ=2 for EN-steering; higher values increase transfer but risk oversteering
  - Extraction dataset size: 100 samples is minimal; larger extraction sets may improve vector quality
  - Layer granularity: Paper uses single layers (20, 28); multi-layer steering ranges could provide finer control

- **Failure signatures:**
  - Over-convergence: CLO/MIDALIGN show saturated transfer; SUR-steering gains are smaller
  - Incomplete recovery: Post-SUR-steering BLEND scores never reach unaligned baseline for heavily-aligned models
  - Language asymmetry: Korean/Chinese show transfer degradation even with steering

- **First 3 experiments:**
  1. Reproduce layer-wise perpendicularity: Extract EN and LOC vectors at layers 16-32; compute S_PER; verify peak at ~28
  2. Ablate γ scaling: Run SUR-steering with γ ∈ {0.5, 1.0, 2.0, 4.0}; plot transfer-localization curves
  3. Cross-model transfer: Extract vectors from MIST; apply to CLO and MIDALIGN; measure if vectors generalize

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What determines whether specific cultural knowledge is recoverable through steering versus permanently erased during alignment?
- Basis in paper: The authors state "cultural knowledge is not permanently erased...though some cultural nuance remains irrecoverably diminished" and that "some cultural nuances are irretrievably lost, highlighting a persistent and perhaps unavoidable cost."
- Why unresolved: The paper demonstrates partial recovery but does not characterize which types of cultural knowledge survive alignment versus those that are lost.
- What evidence would resolve it: Fine-grained analysis mapping specific cultural knowledge types to their recoverability; mechanistic interpretability studies tracking how different cultural representations change through alignment training.

### Open Question 2
- Question: How does the optimal layer for transfer versus localization steering generalize across different model architectures and scales?
- Basis in paper: The layer-specific findings are demonstrated only on Gemma3 12B with 48 layers, with no experiments on other architectures.
- Why unresolved: Architectural differences in how models encode multilingual and cultural information could shift where transfer and localization are optimally steerable.
- What evidence would resolve it: Replication of the surgical steering approach across diverse model families and scales, comparing layer-wise perpendicularity and steering effectiveness.

### Open Question 3
- Question: Can the transfer-localization trade-off be fundamentally eliminated through modified alignment objectives, or is residual cultural loss inherent to representational convergence?
- Basis in paper: The conclusion states "the fundamental trade-off persists" and that "some cultural nuances are irretrievably lost," but this may reflect current methods' limitations rather than a fundamental constraint.
- Why unresolved: Surgical steering improves the trade-off but does not achieve simultaneous maximization of both dimensions.
- What evidence would resolve it: Exploration of culturally-aware pre-training or alignment objectives that explicitly preserve localized knowledge subspaces during convergence.

## Limitations
- Steering vectors extracted from small datasets (100 samples) may not generalize to full test distribution
- Cross-model transfer of steering vectors is not thoroughly validated
- Irreversible cultural loss in heavily-aligned models suggests fundamental trade-off cannot be fully eliminated
- Language asymmetry shows some languages experience transfer degradation even with steering

## Confidence
- **High Confidence:** Empirical observation that Surgical Steering outperforms single-layer approaches on both transfer and localization metrics
- **Medium Confidence:** Mechanism claim that cultural knowledge is "suppressed not erased" - recovery evidence is compelling but irreversible loss in heavily-aligned models remains unexplained
- **Low Confidence:** Generalizability of steering vectors across different CLA methods - cross-model transfer is not thoroughly validated

## Next Checks
1. **Generalization Test:** Extract EN and LOC vectors from MIST; apply to CLO and MIDALIGN. Measure performance degradation to quantify vector specificity vs. generalizability.
2. **Dataset Size Sensitivity:** Systematically vary the extraction dataset size (10, 50, 100, 500 samples) and measure impact on steering effectiveness. Identify minimum viable sample size for reliable vector extraction.
3. **Alternative Layer Configurations:** Explore multi-layer steering ranges (e.g., EN at layers 18-22, LOC at 26-30) to determine if sequential application introduces nonlinear interference not captured by single-layer analysis.