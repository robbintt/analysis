---
ver: rpa2
title: 'ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated
  Learning in Brain Imaging Analysis'
arxiv_id: '2502.12180'
source_url: https://arxiv.org/abs/2502.12180
tags:
- modality
- learning
- data
- cluster
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modality incompleteness in
  multimodal federated learning for brain imaging analysis, where different institutions
  may have access to different imaging modalities (e.g., MRI, PET) due to privacy
  concerns or device limitations. The proposed ClusMFL framework introduces a realistic
  simulation of client-level and instance-level modality incompleteness, going beyond
  the oversimplified assumptions of existing work.
---

# ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis

## Quick Facts
- arXiv ID: 2502.12180
- Source URL: https://arxiv.org/abs/2502.12180
- Reference count: 28
- Primary result: Outperforms state-of-the-art methods in multimodal FL for brain imaging under severe modality incompleteness

## Executive Summary
ClusMFL addresses the challenge of modality incompleteness in multimodal federated learning for brain imaging analysis, where different institutions may have access to different imaging modalities (e.g., MRI, PET) due to privacy concerns or device limitations. The framework introduces a realistic simulation of client-level and instance-level modality incompleteness, going beyond oversimplified assumptions in existing work. By leveraging the FINCH clustering algorithm to construct cluster centers for each modality-label pair, ClusMFL enables fine-grained data distribution representation and cross-modal knowledge transfer through supervised contrastive learning and modality-aware aggregation strategies.

## Method Summary
ClusMFL employs two modality-specific encoders (for MRI and PET) and a classifier to handle 3-class classification (HC/MCI/AD) on the ADNI dataset with 915 participants. The method uses FINCH clustering to generate cluster centers for each modality-label pair, which serve as fine-grained distribution proxies and missing modality substitutes. Local training involves supervised contrastive loss with global cluster centers and modality completion loss using cluster centers as proxies. Server-side aggregation employs modality-aware weighting based on instance counts. The framework is evaluated under varying levels of modality incompleteness with 10 clients, 30 communication rounds, and 5-fold cross-validation.

## Key Results
- Achieves F1 score of 56.17% under moderate incompleteness (α=0.4, β=0.2), outperforming baselines
- Demonstrates superior precision, recall, accuracy, and AUC across varying levels of modality incompleteness
- Shows particularly strong performance in scenarios with substantial modality gaps where single-modality clients dominate

## Why This Works (Mechanism)

### Mechanism 1: Cluster Centers as Fine-Grained Distribution Proxies
- Using multiple cluster centers per class-modality pair provides more representative data distribution approximations than single averaged prototypes
- FINCH clustering automatically identifies K clusters per modality-label pair without requiring k as a hyperparameter
- Core assumption: feature space contains meaningful sub-structures within each class that are destroyed by mean-aggregation but preserved through multi-center representation

### Mechanism 2: Supervised Contrastive Alignment with Global Cluster Knowledge
- Contrastive learning against global cluster centers regularizes encoders to produce label-aligned features even under severe modality incompleteness
- Local feature embeddings are concatenated with global cluster centers; supervised contrastive loss pulls same-label embeddings together and pushes different-label embeddings apart
- Core assumption: global cluster centers provide a stable reference frame that persists across rounds and compensates for local data deficiencies

### Mechanism 3: Cluster Centers as Missing Modality Proxies
- Weighted averaging over predictions using cluster centers as missing-modality substitutes enables meaningful gradient signals for single-modality instances
- For a PET-only instance, the missing MRI embedding is approximated by iterating over MRI cluster centers for that label
- Core assumption: label-consistent cluster centers from one modality occupy a shared semantic space with the missing modality's true features

### Mechanism 4: Modality-Aware Aggregation
- Weighting encoder aggregation by per-client modality instance counts prevents over-representation from modality-skewed clients
- PET encoder aggregation uses weights proportional to ni_P / nP_total; MRI encoder uses ni_M / nM_total
- Core assumption: instance count is a reasonable proxy for data quality/contribution value within a modality

## Foundational Learning

- **Supervised Contrastive Learning (Khosla et al., 2020)**
  - Why needed here: Core training objective that aligns features using label information rather than augmentation-derived positives
  - Quick check question: Given a batch with labels [0, 0, 1, 1], can you identify which samples are positives for index 0 in supervised contrastive loss?

- **FINCH Clustering (Sarfraz et al., 2019)**
  - Why needed here: Parameter-free clustering method that determines cluster count automatically via first-neighbor relations
  - Quick check question: How does FINCH determine the number of clusters without an explicit k parameter?

- **Federated Aggregation Strategies (FedAvg, FedProx)**
  - Why needed here: Baseline understanding of how model parameters are aggregated across clients
  - Quick check question: In FedAvg, how are client weights computed, and what happens when clients have non-IID data distributions?

## Architecture Onboarding

- **Component map:** Each client computes local cluster centers/sizes via FINCH on current encoder features → Server concatenates all client clusters → constructs global cluster pool Cglobal, Sglobal → distributes back to clients → Clients receive global clusters and compute contrastive loss against them → Single-modality instances use global clusters as missing-modality proxies for L_MC → Server aggregates encoders with modality-aware weights, classifier with instance weights

- **Critical path:** 
  1. Each client computes local cluster centers/sizes via FINCH on current encoder features
  2. Server constructs global cluster pool Cglobal, Sglobal
  3. Clients receive global clusters and compute contrastive loss against them
  4. Single-modality instances use global clusters as missing-modality proxies for L_MC
  5. Server aggregates encoders with modality-aware weights, classifier with instance weights

- **Design tradeoffs:**
  - Cluster granularity vs. communication cost: More clusters per client increases upload bandwidth but provides finer distribution representation
  - Proxy quality vs. alignment dependency: Cluster proxies avoid generative model instability but require well-aligned cross-modal features
  - MAA simplicity vs. quality weighting: Count-based aggregation ignores data quality; more sophisticated contribution metrics could improve but add complexity

- **Failure signatures:**
  - Stale clusters: If Cglobal is not refreshed frequently, contrastive loss optimizes toward outdated targets → training divergence or plateau
  - Empty cluster centers for rare labels: Low-prevalence classes may produce few/no clusters → L_MC becomes undefined or noisy for those labels
  - Modality collapse under extreme incompleteness: If α, β → 1 (nearly all single-modality), proxy-based gradients may not provide sufficient signal for encoder learning

- **First 3 experiments:**
  1. Reproduce Table I baseline comparison with α=0.4, β=0.2; verify ClusMFL achieves reported F1 ~56.17% within standard deviation
  2. Ablate cluster count impact: Replace FINCH with fixed-k k-means (k=1, 3, 5 per class); measure performance change to test whether automatic k-selection is critical
  3. Stress test extreme incompleteness: Set α=0.8, β=0.6; compare ClusMFL vs. best baseline to identify break point where framework degrades sharply

## Open Questions the Paper Calls Out
- Future research will explore the incorporation of additional modalities to further enhance the proposed framework's applicability

## Limitations
- Computational overhead introduced by FINCH clustering and supervised contrastive learning
- No validation of FINCH clustering stability across heterogeneous client distributions
- Framework's effectiveness depends on strong cross-modal feature alignment without empirical verification

## Confidence

- **High confidence:** Modality-aware aggregation mechanism (straightforward weighted averaging based on instance counts)
- **Medium confidence:** Supervised contrastive learning with global cluster centers (well-established technique, but FINCH-specific application unvalidated)
- **Low confidence:** Cluster centers as missing modality proxies (mechanism is novel but lacks external validation or sensitivity analysis)

## Next Checks

1. **Cluster Stability Analysis:** Track FINCH cluster count and center consistency across communication rounds and clients; identify when cluster instability correlates with performance degradation

2. **Proxy Quality Evaluation:** Measure cross-modal feature alignment (e.g., modality-to-modality classification accuracy) to verify that cluster centers from one modality are semantically meaningful proxies for the other

3. **Extreme Incompleteness Stress Test:** Systematically vary α and β from 0.2 to 0.8 in 0.1 increments; identify the precise threshold where ClusMFL performance collapses compared to baselines