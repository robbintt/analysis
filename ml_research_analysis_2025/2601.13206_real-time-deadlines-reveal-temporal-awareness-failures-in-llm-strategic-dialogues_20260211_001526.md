---
ver: rpa2
title: Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues
arxiv_id: '2601.13206'
source_url: https://arxiv.org/abs/2601.13206
tags:
- time
- negotiation
- agents
- temporal
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLMs generate text token-by-token but real-world interaction unfolds
  in continuous time. This paper investigates whether LLM agents can track elapsed
  time and adapt their behavior under real-time deadlines.
---

# Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues

## Quick Facts
- arXiv ID: 2601.13206
- Source URL: https://arxiv.org/abs/2601.13206
- Authors: Neil K. R. Sehgal; Sharath Chandra Guntuku; Lyle Ungar
- Reference count: 17
- Primary result: LLMs achieve ≥95% deal closure under turn limits but only 4% under time limits without temporal feedback, rising to 32% with explicit remaining-time updates.

## Executive Summary
This paper investigates whether large language models can track elapsed time and adapt behavior under real-time deadlines in strategic negotiations. Through a controlled negotiation paradigm with multi-issue contracts and strict time limits, the study reveals that LLMs fail to internally track continuous time across turns. While achieving near-perfect deal closure under turn-based constraints, they closed deals in only 4% of time-limited negotiations without feedback, rising to 32% with explicit remaining-time updates. The findings demonstrate that current LLMs lack internal temporal tracking mechanisms for continuous time in strategic interactions unless explicitly signaled.

## Method Summary
The study uses a bilateral, multi-issue hiring negotiation scenario where two LLM agents (Manager vs. Candidate) bargain under strict real-time deadlines (240s, 300s, 360s). Agents output structured JSON containing messages, proposals, and acceptance flags. Time elapses based on a speech latency model of 150 words per minute applied only to natural language message fields. Three conditions are tested: Control (one-time budget disclosure), Time-Aware (per-turn remaining seconds prefix), and Urgency (per-turn qualitative urgency cues). The protocol runs 100 negotiations per condition per scenario, measuring deal closure rates, offer acceptance odds, and joint payoff.

## Key Results
- LLMs achieve ≥95% deal closure under turn limits but only 4% under time limits without temporal feedback
- Explicit remaining-time updates increase deal closure to 32% (708% relative improvement) and offer acceptance odds sixfold
- Urgency cues outperform numeric countdowns, suggesting the bottleneck is mapping time pressure to strategy rather than accessing countdown values
- Effects replicate across models, latency assumptions, and negotiation scenarios

## Why This Works (Mechanism)

### Mechanism 1: Externalized Temporal State Compensates for Absent Internal Clock
- Claim: LLMs lack internal time tracking but can condition behavior on temporal state when explicitly injected
- Mechanism: Without explicit remaining time in observations, models cannot maintain time representation, breaking strategic adaptation. Injecting τ_t as per-turn prefix restores representational substrate for downstream adaptation
- Core assumption: Models can parse and incorporate numeric temporal cues into policy when in-context
- Evidence: 32% vs. 4% deal closure with remaining-time updates; offers 6.38x more likely to be accepted with temporal feedback

### Mechanism 2: Urgency Cues Outperform Numeric Countdowns by Reducing Cognitive Translation Cost
- Claim: Qualitative urgency signals yield higher closure than numeric countdowns by bypassing temporal mapping
- Mechanism: URGENCY provides direct behavioral prompts without requiring numeric representation, turn estimation, or concession scheduling
- Core assumption: Models have stronger priors between urgency language and strategic behaviors than numeric time values
- Evidence: URGENCY > TIME-AWARE > CONTROL deal closure rates; superiority indicates bottleneck is mapping time pressure to strategy, not accessing countdown

### Mechanism 3: Turn-Based Constraints Align with Token-Discrete Generation, Enabling Strategic Competence
- Claim: Near-perfect performance under turn limits vs. failure under time limits reveals intact strategic reasoning, broken temporal representation
- Mechanism: LLMs operate over token sequences; turn limits are discrete and observable. Time limits require external integration of budget, latency, and elapsed time—architecture provides no native mechanism for this
- Core assumption: 5-9 utterances in time-limited negotiations provide comparable deal closure opportunity as turn-limited conditions
- Evidence: 99% agreement with 5 turns; all 5 negotiations without agreement ended via BATNA invocation before turn exhaustion

## Foundational Learning

- **Concept: BATNA (Best Alternative to a Negotiated Agreement)**
  - Why needed here: Agents can terminate negotiation by accepting BATNA (worth 4,500 points), explaining some negotiations ending without deals
  - Quick check question: If an agent's current offer is worth 4,000 points and their BATNA is worth 4,500 points, should they accept the offer?

- **Concept: General-Sum Negotiation with Integrative Potential**
  - Why needed here: Multi-issue hiring negotiation has compatible issues beyond zero-sum price bargaining, making temporal pressure consequential for discovering mutual gains
  - Quick check question: In zero-sum negotiation, time pressure primarily affects concession size. What additional effect does time pressure have in multi-issue integrative negotiation?

- **Concept: Speech Latency Modeling (150 WPM)**
  - Why needed here: Word count converted to elapsed time at 150 WPM creates tradeoff between message elaboration and time consumption
  - Quick check question: If an agent generates a 150-word message, how many seconds of the time budget does this consume?

## Architecture Onboarding

- **Component map:** Negotiation engine -> Agent wrapper -> Latency model -> Temporal treatment injector
- **Critical path:**
  1. Initialize agents with role prompts, payoff tables, BATNA values, and treatment condition
  2. First agent generates message + proposal → latency deducted → remaining time updated
  3. Second agent receives (prefix + opponent message + proposal) → generates response → latency deducted
  4. Repeat until acceptance, BATNA invocation, or timeout
  5. Record outcome, joint payoff, utterance count

- **Design tradeoffs:**
  - Structured JSON vs. free-form: Enables reliable parsing but constrains natural language
  - 150 WPM latency vs. no latency: Approximates human pacing but confounds verbosity with time pressure
  - Within-model vs. human baseline: Isolates mechanism but limits ecological validity

- **Failure signatures:**
  - CONTROL condition: High utterance count (~7) but 4% deal closure → agents continue until timeout without recognizing urgency
  - Excessive reasoning tokens: 2,500+ per utterance → time budget exhausted in 1-2 turns → no iterative offers
  - Claude Sonnet-4.5 reasoning disabled: 0% closure in both conditions → strategic competence is bottleneck, not temporal awareness

- **First 3 experiments:**
  1. Replicate CONTROL vs. TIME-AWARE contrast with target model using "New Recruit" scenario (7 issues, 300s deadline, 100 negotiations per condition)
  2. Test prefix position effects: (a) time prefix at start, (b) immediately before opponent message, (c) after opponent message
  3. Vary latency assumptions: 150 WPM, 0 latency, and 75 WPM to verify temporal deficit isn't latency artifact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can architectural modifications or specialized training objectives enable LLMs to develop robust internal time tracking without external feedback?
- Basis: Conclusion suggests architectural modifications or time-sensitive training objectives may be needed
- Why unresolved: Current architectures generate tokens discretely, failing to represent continuous time
- Evidence needed: Experiments with temporal positional embeddings or time-aware fine-tuning on negotiation tasks

### Open Question 2
- Question: How does LLM temporal adaptation compare to human performance under identical real-time constraints?
- Basis: Limitations note lack of human baseline and suggest replicating human deadline effects
- Why unresolved: Study focused on within-model comparisons rather than human benchmarking
- Evidence needed: Human participants using same negotiation interface and latency rules

### Open Question 3
- Question: Do temporal awareness failures persist or change in long-horizon interactions or multi-party settings?
- Basis: Limitations note longer tasks may reveal different temporal failure modes and real-world dynamics involve multi-party interactions
- Why unresolved: Study restricted to short-horizon bilateral negotiations
- Evidence needed: Extending to longer durations and multi-agent scenarios

## Limitations
- Primary mechanism relies on numeric temporal prefixes being parsed under time pressure; cannot confirm effects generalize without exact GPT-5.1 model access
- Speech-latency model (150 WPM) introduces confound between verbosity and time consumption that may not map to human temporal cognition
- Controlled scenarios may not capture complexity of real-world strategic interactions with competing information streams

## Confidence
- **High confidence**: Dissociation effect (near-perfect under turns vs. near-zero under time) is robust across models and scenarios
- **Medium confidence**: Explicit temporal state enables strategic adaptation, but exact mechanism remains partially unspecified
- **Low confidence**: Superiority of urgency cues over numeric countdowns lacks theoretical grounding in cognitive load theory

## Next Checks
1. Cross-model replication: Test CONTROL vs. TIME-AWARE contrast with GPT-4o, Claude-3.5-Sonnet, and Llama-3.1-70B to determine if deficit is architecture-specific
2. Real-time human-in-the-loop validation: Replace speech-latency model with actual human response timing to confirm effects aren't simulation artifacts
3. Attention visualization: Use attention-weight analysis to verify temporal prefixes are incorporated into strategic reasoning pathway, not merely appended to context