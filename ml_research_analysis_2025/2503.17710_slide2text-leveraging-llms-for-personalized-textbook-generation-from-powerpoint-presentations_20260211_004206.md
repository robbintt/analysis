---
ver: rpa2
title: 'Slide2Text: Leveraging LLMs for Personalized Textbook Generation from PowerPoint
  Presentations'
arxiv_id: '2503.17710'
source_url: https://arxiv.org/abs/2503.17710
tags:
- content
- slide2text
- generation
- educational
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Slide2Text, an AI-powered system that automates
  the conversion of PowerPoint presentations into customized textbooks using Large
  Language Models (LLMs). The system extracts slide content via OCR and Python-PPTX,
  generates structured textbook content with RAG-enhanced LLM generation, and offers
  flexible customization options including multilingual support.
---

# Slide2Text: Leveraging LLMs for Personalized Textbook Generation from PowerPoint Presentations

## Quick Facts
- **arXiv ID:** 2503.17710
- **Source URL:** https://arxiv.org/abs/2503.17710
- **Reference count:** 3
- **Primary result:** AI-powered system converting PowerPoint presentations into structured, multilingual textbooks using LLMs with RAG and OCR

## Executive Summary
Slide2Text is an AI-driven system that automates the conversion of PowerPoint presentations into customized textbooks. The system extracts content via OCR and Python-PPTX, generates structured textbook content with RAG-enhanced LLM generation, and offers flexible customization options including multilingual support. Evaluation through a case study at a Japanese university demonstrated Slide2Text's effectiveness in producing high-quality textbooks in both English and Japanese, validated through automated and expert assessments.

## Method Summary
The system extracts slide content using `python-pptx` for text/metadata and `pytesseract` for OCR on images, storing results in JSON format. It implements RAG using `PyMuPDF` for PDF extraction, `LangChain RecursiveCharacterTextSplitter` for chunking (~200 chars), `text-embedding-ada-002` for embeddings stored in FAISS, and hybrid retrieval with Google Custom Search API. Multi-model LLM generation (GPT-4o, DeepSeek V3) creates chapter-wise content using persona prompts combined with retrieved context. The Flask backend includes Redis caching for performance.

## Key Results
- Successfully generated high-quality textbooks in both English and Japanese from PPT presentations
- Validated through automated LLM evaluation (DeepSeek, GPT-4o) and human expert review
- Demonstrated effectiveness in a case study at a Japanese university
- Supports flexible customization including multilingual output

## Why This Works (Mechanism)
Slide2Text works by combining structured extraction, knowledge retrieval, and LLM generation in a pipeline that maintains content fidelity while adding educational structure. The system leverages OCR to capture embedded text in images, uses RAG to ground generation in relevant academic sources, and employs multi-model LLMs to generate coherent textbook chapters. The hybrid retrieval approach combines local FAISS-based search with Google Search results, weighted by relevance scoring, to provide comprehensive context for generation.

## Foundational Learning

**Python-PPTX**: Extracting slide text, titles, and metadata from PowerPoint files - needed for structured content ingestion, quick check: verify JSON output matches source presentation structure.

**Pytesseract (OCR)**: Converting image-based slide content to text - needed for capturing embedded diagrams/charts, quick check: compare OCR output against ground truth for sample slides.

**LangChain + FAISS**: Implementing vector-based retrieval for RAG - needed for grounding LLM generation in domain-specific knowledge, quick check: measure retrieval precision@k for relevant academic content.

**Prompt Engineering**: Crafting persona-driven system prompts for textbook generation - needed to ensure consistent textbook style and structure, quick check: test different persona prompts on sample slides.

**Flask + Redis**: Building a scalable web API with caching - needed for serving the textbook generation service, quick check: benchmark response times with concurrent requests.

## Architecture Onboarding

**Component Map**: PPTX files -> Python-PPTX + Pytesseract -> JSON extraction -> FAISS vector store (with PyMuPDF PDF ingestion) + Google Search API -> LLM (GPT-4o/DeepSeek) -> Textbook chapters -> PDF/Markdown output

**Critical Path**: Extraction (OCR + Metadata) → RAG Retrieval (FAISS + Search) → Chapter-wise Generation (LLM with persona prompts) → Assembly (PDF/Markdown compilation)

**Design Tradeoffs**: Independent chapter generation avoids context window overflow but risks narrative fragmentation; 200-character chunks balance retrieval precision with context management; hybrid RAG adds breadth but introduces complexity in relevance scoring.

**Failure Signatures**: Garbled text in output indicates OCR issues; irrelevant citations suggest RAG retrieval problems; incomplete sentences indicate context window overflow; inconsistent style suggests prompt engineering issues.

**First Experiments**:
1. Process a simple 5-slide presentation with text-only content and verify JSON extraction structure
2. Test FAISS retrieval with a small set of domain-specific PDFs and measure precision@k
3. Generate a single textbook chapter from one slide with known content to validate prompt effectiveness

## Open Questions the Paper Calls Out

**Open Question 1**: Does the use of LLM-generated personalized textbooks result in significantly higher learning gains and motivation compared to traditional static materials? The paper identifies this as the core research question but lacks complete statistical results from the proposed controlled experiment comparing knowledge mastery and motivation scale outcomes.

**Open Question 2**: Can advanced multi-turn contextual generation strategies effectively maintain logical coherence across complex, interdisciplinary textbook chapters? The current independent segmentation approach may fragment narrative flow, requiring comparative evaluation of proposed multi-turn approaches.

**Open Question 3**: To what extent does the integration of domain-specific knowledge graphs improve the accuracy and semantic depth of generated content compared to RAG alone? The current vector-based retrieval may lack structured relational context needed for complex knowledge representation.

## Limitations

- Key implementation details remain underspecified, including slide-to-chapter segmentation logic and hybrid RAG weighting algorithm
- Exact prompt templates and persona definitions used for LLM generation are not provided
- Evaluation lacks detailed statistical analysis and sample size information from the case study
- No performance benchmarks or resource requirements provided for different presentation sizes

## Confidence

**High confidence** in core architectural approach (extraction + RAG + generation pipeline), **Medium confidence** in evaluation results (automated + expert validation but limited methodology details), **Low confidence** in scalability claims (no processing time or performance data provided).

## Next Checks

1. **Reproduce RAG retrieval quality**: Implement hybrid retrieval system and measure precision@k across 10+ diverse presentation topics to verify relevance improvements.

2. **Validate OCR robustness**: Process 5+ presentations with complex images and compare pytesseract output against ground truth to assess impact on textbook quality.

3. **Benchmark LLM context handling**: Test generation pipeline with presentations of varying lengths (10, 50, 100+ slides) to identify context window limitations and retrieval noise effects on coherence.