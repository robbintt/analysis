---
ver: rpa2
title: A Comparative Analysis of Interpretable Machine Learning Methods
arxiv_id: '2601.00428'
source_url: https://arxiv.org/abs/2601.00428
tags:
- regression
- methods
- interpretable
- performance
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a large-scale comparative evaluation of 16
  interpretable machine learning methods across 216 real-world tabular datasets, spanning
  both regression and classification tasks. The methods range from classical linear
  models and decision trees to modern approaches like Explainable Boosting Machines,
  Symbolic Regression, and Generalized Optimal Sparse Decision Trees.
---

# A Comparative Analysis of Interpretable Machine Learning Methods

## Quick Facts
- arXiv ID: 2601.00428
- Source URL: https://arxiv.org/abs/2601.00428
- Reference count: 10
- 16 interpretable ML methods evaluated across 216 real-world tabular datasets

## Executive Summary
This study presents the largest-scale comparative evaluation of interpretable machine learning methods to date, examining 16 techniques across 216 real-world tabular datasets for both regression and classification tasks. The evaluation systematically varies dataset characteristics including dimensionality, sample size, linearity, and class imbalance to provide practical guidance for model selection. Results demonstrate clear performance hierarchies, with Explainable Boosting Machines (EBMs) achieving superior predictive accuracy in regression tasks, while classification results show less pronounced differences among top-performing methods. The study also reveals significant computational trade-offs, with more expressive interpretable models requiring substantially longer training times.

## Method Summary
The authors conducted a comprehensive evaluation of 16 interpretable machine learning methods including classical approaches (linear models, decision trees) and modern techniques (EBMs, Symbolic Regression, IGANNs, Generalized Optimal Sparse Decision Trees). Methods were assessed across 216 real-world tabular datasets using both in-sample and out-of-sample performance metrics. The evaluation stratified results by key dataset characteristics: dimensionality, sample size, linearity, and class imbalance. Performance was measured using standard metrics (R² for regression, accuracy/F1 for classification), with computational time recorded for each method. The large sample size enables robust statistical comparisons and identification of systematic performance patterns across different data regimes.

## Key Results
- Explainable Boosting Machines achieved the strongest predictive accuracy in regression tasks across diverse datasets
- Symbolic Regression and Interpretable Generalized Additive Neural Networks excel in non-linear regimes
- Generalized Optimal Sparse Decision Trees show pronounced sensitivity to class imbalance
- Performance differences are less pronounced in classification, with EBM leading overall
- More expressive interpretable methods require significantly longer computation times

## Why This Works (Mechanism)
The large-scale comparative approach enables identification of systematic performance patterns that would be obscured in smaller evaluations. By stratifying results across diverse dataset characteristics, the study reveals how different interpretable methods respond to specific data properties. The combination of classical and modern interpretable techniques captures the trade-off space between model simplicity and predictive power, while the real-world dataset corpus ensures practical relevance of findings.

## Foundational Learning
- **Interpretability vs Performance Trade-off**: Understanding that more interpretable models often sacrifice predictive accuracy; quick check: compare R² scores across model families
- **Dataset Characteristic Impact**: Recognizing how dimensionality, sample size, linearity, and class imbalance affect different model types; quick check: examine stratified performance plots
- **Computational Complexity**: Appreciating that model expressiveness comes with computational cost; quick check: review training time distributions across methods
- **Model Calibration**: Importance of well-calibrated probability estimates for decision-making; quick check: verify calibration curves for top-performing models

## Architecture Onboarding
- **Component Map**: Data Preprocessing -> Model Training -> Performance Evaluation -> Statistical Analysis
- **Critical Path**: Dataset selection and preprocessing → Method implementation → Cross-validation → Metric computation → Statistical comparison
- **Design Tradeoffs**: Expressiveness vs interpretability vs computational cost; generalization vs dataset-specific optimization
- **Failure Signatures**: Poor performance on high-dimensional data (sparse trees), class imbalance sensitivity (GOSDT), computational bottlenecks (EBMs)
- **First Experiments**: 1) Replicate EBM performance on regression datasets, 2) Test symbolic regression on known non-linear functions, 3) Evaluate sparse trees under varying class imbalance ratios

## Open Questions the Paper Calls Out
None

## Limitations
- Confidence in classification results is Medium due to less pronounced performance differences
- Uncertainty remains regarding generalizability to non-tabular data formats
- Study does not address model calibration or uncertainty quantification

## Confidence
- **Regression findings**: High confidence given large sample size and clear performance rankings
- **Classification results**: Medium confidence due to less pronounced differences and potential confounding factors
- **Computational expense findings**: High confidence given systematic timing measurements across all methods

## Next Checks
1. Replicate key findings on an independent corpus of tabular datasets, particularly testing class imbalance sensitivity of sparse decision trees
2. Conduct ablation studies to isolate the contribution of specific model components to performance differences
3. Evaluate methods on datasets with extreme class imbalance ratios and very high dimensionality to test robustness boundaries