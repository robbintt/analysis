---
ver: rpa2
title: Analysis of heart failure patient trajectories using sequence modeling
arxiv_id: '2511.16839'
source_url: https://arxiv.org/abs/2511.16839
tags:
- clinical
- after
- one-year
- initial
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: A systematic ablation study was conducted to empirically evaluate
  the performance of six sequence models (BERT, XLNet, ModernBERT, Llama, Mamba, Mamba2)
  across three one-year prediction tasks (clinical instability, mortality after initial
  HF hospitalization, mortality after latest hospitalization) using a large Swedish
  heart failure cohort (N=42,820). Models were compared across various settings including
  input tokenization, model architecture configurations (context length and model
  size), temporal preprocessing techniques, and data availability.
---

# Analysis of heart failure patient trajectories using sequence modeling

## Quick Facts
- arXiv ID: 2511.16839
- Source URL: https://arxiv.org/abs/2511.16839
- Reference count: 40
- Llama consistently achieved the highest predictive discrimination and best calibration across all tasks and ablations

## Executive Summary
This systematic ablation study empirically evaluates six sequence models (BERT, XLNet, ModernBERT, Llama, Mamba, Mamba2) for predicting clinical outcomes in heart failure patients using Swedish EHR data. The study examines various design choices including tokenization, model architecture configurations, temporal preprocessing, and data availability across three one-year prediction tasks. Llama emerges as the top performer, achieving superior predictive discrimination and calibration while demonstrating efficient representation learning that allows it to outperform larger models with less training data.

## Method Summary
The study uses a Swedish heart failure cohort (N=42,820) from in-hospital EHRs (2015–2023), extracting diagnoses, vital signs, laboratories, medications, and procedures. Patient sequences are constructed with right-sided, chronological ordering and various temporal preprocessing strategies. Six architectures are compared: Transformers (BERT, XLNet), Transformers++ (ModernBERT, Llama), and Mambas (Mamba, Mamba2). Models are pre-trained using Next Token Prediction (NTP) or Masked Language Modeling (MLM) objectives, then fine-tuned for binary classification tasks. Performance is evaluated using AUPRC, AUROC, and Brier score across three tasks: clinical instability, mortality after initial HF hospitalization, and mortality after latest hospitalization.

## Key Results
- Llama consistently achieved the highest predictive discrimination (AUPRC) and best calibration across all tasks
- Mamba-based models outperformed traditional Transformers (BERT, XLNet) in all settings
- Llama and Mamba achieved superior performance using 25% less training data than other models
- Smaller model configurations (Tiny, Small) often surpassed larger Transformers, with performance gains primarily driven by extended context length rather than increased model complexity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Next-token prediction (NTP) with Llama/Mamba architectures outperforms masked language modeling (MLM) with BERT for EHR-based outcome prediction.
- **Mechanism:** NTP is an autoregressive objective that forces the model to learn sequential dependencies, where past events must predict future ones. This aligns directly with the temporal nature of patient trajectories. Llama and Mamba architectures incorporate modern improvements like rotary positional embeddings (RoPE) and pre-normalization (RMSNorm), which more effectively capture and stabilize learning from these sequential dependencies compared to BERT's older design.
- **Core assumption:** The performance gain is primarily driven by the NTP objective's fit with sequential data and Llama/Mamba's architectural efficiencies, not just hyperparameter tuning.
- **Evidence anchors:**
  - [abstract] "Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas."
  - [section] "models that are trained on the NTP objective achieve better results compared to models trained on MLM... Llama and Mamba architectures incorporate improvements... over Transformers" (from Discussion, Section 5).
  - [corpus] "Generative pre-trained transformers (GPT) can leverage this data to predict future events" (arXiv:2503.05893) supports the use of generative, autoregressive models for event prediction. "ClinNoteAgents" (arXiv:2512.07081) also applies LLMs to a similar heart failure readmission task.
- **Break condition:** If BERT with MLM and temporal tokens (e.g., [ATT]) had consistently matched or outperformed Llama's NTP, this mechanism would be unsupported.

### Mechanism 2
- **Claim:** Prioritizing a longer context length (C) over a larger model size (S) yields greater predictive gains for EHR sequence modeling.
- **Mechanism:** A longer context length allows the model to ingest a larger portion of a patient's longitudinal history, capturing more relevant, potentially long-range dependencies that are critical for outcomes like mortality. Smaller model configurations (Tiny, Small) are less prone to overfitting on the relatively limited data of specialized cohorts, making them more computationally efficient and stable.
- **Core assumption:** The marginal predictive value of including older clinical events in the sequence exceeds the marginal value of increased model parameter complexity for this dataset size.
- **Evidence anchors:**
  - [abstract] "Both architectures demonstrate efficient representation learning, with smaller configurations surpassing larger Transformers. Llama requires 25% less training data to achieve comparable performance."
  - [section] "S-Llama delivers a strong performance that is robust for any C across all tasks... suggesting that performance gains stem primarily from data quantity (extended C) as opposed to enriched representation capacity (increased S)." (from Results, Section 4.1.2 and Discussion).
  - [corpus] Neighbor papers like "From EHRs to Patient Pathways" (arXiv:2506.04831) focus on modeling longitudinal health trajectories, implicitly highlighting the importance of capturing long sequences.
- **Break condition:** If Medium or Large model configurations consistently provided substantial gains over Small models across all context lengths, model size would be a more critical factor.

### Mechanism 3
- **Claim:** Temporal aggregation of clinical events improves model performance by extending the effective longitudinal history captured within a fixed token limit.
- **Mechanism:** Instead of a raw cutoff that discards older events, aggregation (e.g., averaging within 1-2 day windows) compresses recent, high-frequency events like vital signs. This compression frees up tokens, allowing the sequence to extend further back in time and capture a longer, more informative patient history for the same context length (C=512).
- **Core assumption:** A summarized, lower-resolution view of recent, repetitive events retains sufficient predictive information while enabling the capture of older, potentially critical events that would otherwise be lost.
- **Evidence anchors:**
  - [abstract] "using aggregation for temporal preprocessing" is part of the recommended design principles.
  - [section] "Aggregations, which trade increased temporal resolution for a lower proportion of tokens, show a promising direction... Llama and Mamba tend to yield better performances for aggregated sequences." (from Discussion, Section 5). The paper states: "a cutoff history is a suboptimal design choice."
  - [corpus] Weak direct evidence. One neighbor paper (arXiv:2508.16054) notes EHRs are complex data sources requiring sophisticated modeling, which supports the need for advanced preprocessing techniques like aggregation.
- **Break condition:** If truncation to only recent events (e.g., Ht=0 or Ht≤1y) consistently outperformed all aggregation strategies, the benefit of extending history via compression would be negated.

## Foundational Learning

- **Concept: Next-Token Prediction (NTP) Objective**
  - **Why needed here:** The paper identifies NTP as a core reason for Llama/Mamba's superior performance over BERT (which uses MLM). Understanding this autoregressive objective is essential for grasping how the models leverage the temporal sequence of patient events.
  - **Quick check question:** Can you explain why predicting the next token in a patient's timeline is a more suitable pre-training task for EHR data than randomly masking and predicting tokens?

- **Concept: Context Length vs. Model Size**
  - **Why needed here:** A central, non-obvious finding is that for this EHR task, extending the context length is more beneficial than increasing model parameters. This is a critical design principle for engineers implementing similar systems.
  - **Quick check question:** According to the paper's findings, if you had to choose between doubling the model's parameter count or doubling the number of input tokens (context length), which would likely yield a greater performance improvement?

- **Concept: Tokenization and Temporal Embeddings**
  - **Why needed here:** The paper's ablations on token granularity (e.g., ICD-10 code levels) and temporal preprocessing (e.g., [ATT] tokens, aggregation) are foundational to how raw EHR data is represented and fed into the model.
  - **Quick check question:** How did the study represent the time gap between a patient's hospital visits in the input sequence?

## Architecture Onboarding

- **Component map:**
  - Data Layer: EHRs -> Feature Extraction (DX, VIT, LAB, MED, PRO) -> Tokenization & Embedding (aggregating clinical concepts, demographics, time, position)
  - Model Layer: Architecture Selection (e.g., Llama, Mamba) -> Pre-training (on NTP objective) -> Fine-tuning (for binary classification)
  - Output Layer: A two-layer feedforward classification head applied to the final token's hidden state to predict a probability

- **Critical path:**
  1. **Data Curation:** Extract structured EHR data and curate for the heart failure cohort
  2. **Sequence Construction:** Build right-sided, chronologically sorted patient sequences, applying chosen temporal preprocessing (cutoff vs. aggregation)
  3. **Tokenization:** Convert events into a shared vocabulary, creating rich embeddings that include token type, demographics, and temporal information
  4. **Pre-training:** Train a sequence model (e.g., Small-Llama) from scratch using the NTP objective on all patient sequences
  5. **Fine-tuning:** Add a classification head and fine-tune the pre-trained model on the labeled clinical task (e.g., 1-year mortality)
  6. **Evaluation:** Assess using AUPRC (primary), AUROC, and Brier score

- **Design tradeoffs:**
  - **Context Length:** Longer sequences capture more history but increase computational cost. The paper recommends C=512 as a practical and effective choice
  - **Model Size:** Larger models risk overfitting. The paper recommends Small-sized configurations for a better stability-efficiency balance
  - **Temporal Preprocessing:** Aggregation extends history but at the cost of fine-grained detail. A cutoff preserves detail but sacrifices older data
  - **Feature Granularity:** Finer-grained measurements help, but the most detailed diagnosis codes (ICD-10 level 4) can sometimes degrade performance

- **Failure signatures:**
  - **Performance Plateau:** The model fails to improve even with more data or a larger size, suggesting it has captured the available signal or is overfitting
  - **Unstable Training:** Loss is erratic, especially with larger model configurations, indicating training instability
  - **Baseline Dominance:** If a simple XGBoost model consistently outperforms the sequence model, it suggests the temporal modeling or tokenization is not effectively capturing additional predictive value

- **First 3 experiments:**
  1. **Ablate Preprocessing:** Compare a baseline cutoff (C=512) with temporal aggregation (w=1d) to validate the finding that extending history is beneficial
  2. **Ablate Context Length:** Train a Small-Llama model at C=128, C=256, and C=512 to confirm that performance scales more with context than model size
  3. **Ablate Data Scarcity:** Train the best configuration on 25%, 50%, 75%, and 100% of the data to measure its data efficiency and verify the claim of strong performance with less data

## Open Questions the Paper Calls Out

- **Question:** To what extent do the performance advantages of Llama and Mamba over BERT generalize to heart failure cohorts outside of Sweden or to patient populations with different chronic diseases?
- **Question:** How does the ranking of model architectures change when context lengths significantly exceed 512 tokens, particularly regarding Mamba's theoretical efficiency advantages?
- **Question:** Does the fusion of unstructured data sources, such as clinical text notes or cardiac imaging parameters, improve the predictive performance of the Llama architecture beyond the structured EHR data used in this study?
- **Question:** Why does the inclusion of procedure codes (PRO) and the highest level of ICD-10 diagnostic granularity lead to performance deterioration, and can semantic code embeddings mitigate this?

## Limitations
- Findings are based on a single Swedish heart failure cohort, limiting generalizability to other populations and healthcare systems
- Temporal aggregation strategy requires careful calibration of window sizes that may vary across different clinical contexts
- The ablation study focuses on architectural and preprocessing choices but does not explore hyperparameter optimization

## Confidence
- **High Confidence**: Llama consistently outperforming other architectures across all tasks and settings
- **Medium Confidence**: NTP objectives outperforming MLM for EHR data, Llama requiring 25% less training data
- **Low Confidence**: Optimal temporal preprocessing strategy, underlying reasons for PRO performance degradation

## Next Checks
1. Apply the best-performing Llama configuration to heart failure cohorts from different healthcare systems to test generalizability
2. Replace binned discretization with continuous embeddings for laboratory values to assess improvement in predictive performance
3. Evaluate model performance on streaming EHR data with varying update frequencies to determine effectiveness of temporal aggregation strategy