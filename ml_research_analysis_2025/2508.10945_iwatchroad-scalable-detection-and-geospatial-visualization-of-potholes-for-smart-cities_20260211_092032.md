---
ver: rpa2
title: 'iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for
  Smart Cities'
arxiv_id: '2508.10945'
source_url: https://arxiv.org/abs/2508.10945
tags:
- detection
- pothole
- road
- potholes
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents iWatchRoad, a complete end-to-end system for
  automated pothole detection, GPS tagging, and real-time geospatial visualization
  on OpenStreetMap. It addresses the challenge of maintaining road safety and infrastructure
  in India, where potholes cause significant accidents and vehicle damage.
---

# iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities

## Quick Facts
- arXiv ID: 2508.10945
- Source URL: https://arxiv.org/abs/2508.10945
- Reference count: 19
- Key outcome: Automated pothole detection, GPS tagging, and real-time geospatial visualization using YOLO fine-tuned on Indian road data

## Executive Summary
iWatchRoad presents a complete end-to-end system for automated pothole detection, GPS tagging, and real-time geospatial visualization on OpenStreetMap. The system addresses the challenge of maintaining road safety and infrastructure in India, where potholes cause significant accidents and vehicle damage. It leverages a large self-annotated dataset of over 7,000 Indian road frames and fine-tunes the YOLO model for robust pothole detection under diverse conditions. The system employs OCR to extract timestamps from dashcam footage and synchronizes them with GPS logs for accurate geotagging, storing detected potholes and metadata in a database for visualization on a user-friendly web interface.

## Method Summary
The method combines YOLOv8 fine-tuned on the BharatPotHole dataset (7,000+ Indian road frames) with OCR timestamp extraction and GPS synchronization. Dashcam videos are processed frame-by-frame, with YOLO detecting potholes and EasyOCR extracting timestamps from video overlays. These timestamps are matched against external GPS logs to assign precise coordinates to each detection. The system stores detections in SQLite with Base64-encoded frames and provides visualization through a Django backend, React-TypeScript frontend, and Leaflet.js mapping on OpenStreetMap. Negative sample integration during training helps reduce false positives from visually similar road features.

## Key Results
- Achieves improved detection accuracy under challenging Indian road conditions (low light, rain, rural/urban environments)
- Provides government-compatible outputs for road assessment and maintenance planning
- Demonstrates cost-effective, hardware-efficient scalability for urban and rural road management

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning YOLO on domain-specific Indian road data improves detection accuracy under challenging conditions. The BharatPotHole dataset exposes the model to diverse road types, lighting conditions, and weather scenarios unique to Indian environments, enabling learning of discriminative features for authentic potholes versus visually similar artifacts.

### Mechanism 2
OCR-extracted timestamps synchronized with GPS logs enable accurate geotagging of detected potholes. EasyOCR extracts embedded timestamps from video frames, which are matched against external GPS logger records to assign precise coordinates to each detection.

### Mechanism 3
Negative sample integration reduces false positive detections from visually similar road features. Including frames with shadows, cracks, debris, petroleum stains, and utility covers (without pothole annotations) trains the model to discriminate based on authentic pothole morphology rather than simplistic dark-surface pattern recognition.

## Foundational Learning

- **YOLO object detection architecture**: Understanding single-stage detection pipeline is essential for debugging and improving model performance. Quick check: Can you explain how YOLO predicts bounding boxes and class probabilities in a single forward pass?

- **OCR fundamentals and regex parsing**: Timestamp extraction from dashcam overlays uses EasyOCR with custom regex. Quick check: How would you handle OCR errors where ":" is misrecognized as ". " in a timestamp string?

- **GPS coordinate systems and temporal synchronization**: Geotagging requires matching video frame timestamps to GPS log entries. Quick check: Given a 5h 30m 44s offset between GPS (UTC) and dashcam (IST), how would you align timestamps programmatically?

## Architecture Onboarding

- **Component map**: Data Collection -> Preprocessing -> Detection Module -> Geospatial Tagging -> Storage -> Visualization

- **Critical path**: Video input → Frame extraction → YOLO detection (bounding boxes + confidence) → OCR timestamp extraction → GPS matching (coordinate assignment) → Database storage → Web visualization (OSM markers with popups)

- **Design tradeoffs**: Consumer-grade dashcam + GPS vs. LiDAR/stereo cameras (lower cost, reduced depth info); Base64 frame encoding in SQLite vs. file system storage (simpler deployment, larger database); 30 FPS processing vs. frame sampling (higher coverage, spatial redundancy addressed via Haversine deduplication at 2.5m threshold)

- **Failure signatures**: Low-light or rain conditions cause model confidence drops; timestamp format variation breaks regex parser; GPS signal jitter causes coordinate precision issues; high FPS redundancy creates clustered map markers

- **First 3 experiments**: 1) Validate detection on held-out test split measuring precision/recall across lighting conditions; 2) Test OCR timestamp extraction accuracy across dashcam overlay formats; 3) End-to-end geotagging accuracy test with known dashcam video + GPS log

## Open Questions the Paper Calls Out

- Can multi-modal sensor fusion or 3D reconstruction improve pothole depth estimation and severity classification beyond 2D bounding-box analysis? The current system relies on 2D bounding boxes and confidence scores lacking volumetric data.

- Can the synchronization between OCR-extracted video timestamps and GPS logs be automated to handle variable hardware clocks without manual calibration? The system currently depends on specific regex patterns and a fixed manual offset.

- Can longitudinal data analysis of detected potholes accurately predict road degradation rates and contractor performance? The current implementation focuses on real-time detection lacking long-term temporal data required for predictive modeling.

## Limitations

- Performance is tightly coupled to Indian road conditions with limited validation on other geographic regions
- Key architectural parameters (YOLO variant, OCR ROI coordinates, severity scoring rules) are underspecified
- Database storage approach using Base64-encoded frames may face scalability limits for large-scale deployments

## Confidence

- **High Confidence**: Core architecture combining YOLO fine-tuning with domain-specific data, OCR timestamp extraction, and GPS synchronization is well-documented and mechanistically sound
- **Medium Confidence**: Detection accuracy claims rely on the BharatPotHole dataset but lack independent validation; severity classification mechanism is mentioned but not specified
- **Low Confidence**: Claims about government compatibility and real-world deployment scale are not substantiated with deployment case studies

## Next Checks

1. Deploy the trained model on pothole detection datasets from non-Indian road environments and measure performance degradation to validate domain-specificity claims

2. Create test videos with timestamp overlay variations and measure OCR extraction accuracy to verify regex parser robustness

3. Benchmark the system with continuous dashcam footage processing to measure database growth rate, query performance, and visualization responsiveness, identifying bottlenecks in the Base64 storage approach