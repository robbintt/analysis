---
ver: rpa2
title: Towards Understanding the Benefit of Multitask Representation Learning in Decision
  Process
arxiv_id: '2503.00345'
source_url: https://arxiv.org/abs/2503.00345
tags:
- learning
- function
- representation
- task
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the analysis of multitask representation learning
  (MRL) to general non-linear representations, filling a gap where previous works
  either assumed linear functions or pre-known representations. The authors propose
  the Generalized Functional Upper Confidence Bound (GFUCB) algorithm, which learns
  a shared representation function from a non-linear class using multi-head function
  space.
---

# Towards Understanding the Benefit of Multitask Representation Learning in Decision Process

## Quick Facts
- arXiv ID: 2503.00345
- Source URL: https://arxiv.org/abs/2503.00345
- Reference count: 40
- One-line primary result: GFUCB algorithm achieves regret bounds that scale with the number of tasks M rather than M^2, outperforming independent learning

## Executive Summary
This paper bridges the gap between theoretical analysis and practical implementation of multitask representation learning (MRL) for decision processes. While prior work focused either on linear functions or assumed pre-known representations, this work analyzes non-linear representations learned from scratch. The authors propose GFUCB, an algorithm that learns a shared representation function from a non-linear class using multi-head function space, and prove it achieves regret bounds that scale favorably with the number of tasks. The key insight is that joint training of the shared feature extractor accelerates confidence set convergence, reducing sample complexity compared to learning tasks independently.

## Method Summary
The paper proposes GFUCB (Generalized Functional Upper Confidence Bound), which learns a shared representation function from a non-linear class using multi-head function space. The algorithm operates in two stages per decision step: first, it performs empirical risk minimization to fit the representation and head weights to historical data; second, it performs optimistic search within a confidence set using gradient-based approximation. For contextual bandits, the network uses 2 convolutional layers followed by 2 fully connected layers with 10-dimensional output. For linear MDPs, the network uses 3 convolutional layers followed by 2 MLP layers with 256-dimensional output. The method leverages Eluder dimension to quantify the complexity of the non-linear function class and incorporates optimism in the face of uncertainty for efficient exploration.

## Key Results
- GFUCB achieves regret upper bound of Õ(√(MTd(Mk + log N(Φ)))) for contextual bandits
- For linear MDPs, regret bound is Õ(√(MHTdk + MH√(T)log N(Φ) + MHT√(d)))
- Joint training of shared representation accelerates confidence set convergence, reducing sample complexity by factor of M
- Theoretical analysis explains conditions for successful transfer learning: new task must be linear combination of old tasks with sufficient pretraining coverage

## Why This Works (Mechanism)

### Mechanism 1
Joint training of a shared representation accelerates the convergence of the confidence set, which directly reduces sample complexity compared to learning tasks independently. Because the shared feature extractor receives samples from all M tasks simultaneously, the algorithm locates the ground truth function in a compact multihead function space rather than a massive independent space. This reduces the confidence set width β_t by a factor of M relative to the independent case.

### Mechanism 2
Using a shared non-linear backbone with linear heads restricts the function search space, allowing the agent to generalize across tasks with fewer samples than required to learn a general non-linear function from scratch. The architecture utilizes a "multihead function class" where the complex non-linear mapping is shared, and task-specific adaptations are linear transformations. This structure enforces a strong inductive bias that significantly lowers the covering number of the function class.

### Mechanism 3
Transfer learning efficiency relies on the new task being a linear combination of previously learned tasks and the training data having sufficient coverage. The framework treats transfer learning as a misspecified linear bandit problem. If the new task's parameters lie in the span of the pre-trained tasks' parameters, the pre-trained representation is sufficient. The regret scales inversely with the square root of pretraining steps T, provided the training data covers the inputs encountered in the new task.

## Foundational Learning

- **Eluder Dimension**: Quantifies the complexity of the non-linear function class (e.g., neural networks). Replaces simple linear dimension measures to determine how many samples are needed to "pin down" a function's value across the state space. Quick check: Can you explain why a function class with high Eluder dimension might require exponentially more samples to learn than a linear class?

- **Inherent Bellman Error (IBE)**: Captures the approximation error when fitting a value function in MDP settings. Generalizes "Linear MDP" to settings where the representation is approximate rather than perfect. Quick check: If the IBE is high, does increasing the number of tasks M help reduce the regret, or does the error term dominate?

- **Optimism in the Face of Uncertainty (OFUL)**: The algorithmic principle driving exploration. The agent selects actions that have the highest potential value within the current confidence set, ensuring efficient exploration of uncertain states. Quick check: How does the width of the confidence set (β_t) directly influence the exploration bonus and resulting regret?

## Architecture Onboarding

- **Component map**: Raw state-action pairs -> Shared CNN backbone (φ) -> Multi-head weights (W) -> Task-specific value predictions

- **Critical path**: 
  1. Empirical Risk Minimization: Solve for φ̂ and Ŵ to minimize prediction error on history
  2. Confidence Estimation: Calculate set width β_t (requires estimating Eluder dimension/covering number)
  3. Optimistic Search: Perform constrained optimization (gradient descent with clipping) to find the action maximizing the optimistic value within F_t

- **Design tradeoffs**: 
  - Theoretical vs. Practical β_t: The theoretical β_t depends on the intractable covering number N(Φ). Practically, the paper approximates this using a clipping mechanism (PPO-style) to implicitly constrain the search space
  - Exploration Strategy: Exact optimization over the abstract function set is intractable; the implementation approximates this by searching in a small neighborhood of f̂_t using gradient methods

- **Failure signatures**: 
  - Gradient Conflict: If tasks are highly dissimilar, gradients for the shared backbone may counteract each other, stalling convergence
  - Transfer Stagnation: If pretraining coverage κ is low, the regret on new tasks remains high (linear in t) regardless of training steps

- **First 3 experiments**: 
  1. Baseline Efficiency: Run GFUCB on M=1, 5, 10 tasks (MNIST bandit) to confirm that average regret decreases as M increases
  2. Transfer Capability: Pretrain on M tasks, freeze the backbone, and run LinUCB on M+1 tasks to verify if regret scales with 1/√T (pretraining steps)
  3. Ablation on Optimism: Implement the algorithm with a fixed bonus vs. the gradient-based optimistic search to confirm that the implicit bonus mechanism effectively drives exploration

## Open Questions the Paper Calls Out

1. **MDP Transfer Extension**: Can the transfer learning regret bounds be formally extended to the multitask Linear MDP setting? Section 6.2 Remark states "Our analysis can also be easily extended to MDPs... we leave it to future work." The paper provides theoretical guarantees for transfer learning in contextual bandits but only outlines the mechanism for MDPs without formal regret analysis.

2. **Computational Efficiency**: Can the intractable optimization subproblems in GFUCB be solved computationally efficiently without sacrificing the theoretical regret guarantees? Section 4.2 notes the optimization is NP-hard and assumes a "computational oracle," while Appendix E relies on gradient-based heuristics (clipping) that are approximations.

3. **Approximate Transferability**: How does the transfer learning performance degrade if the new task's value function lies outside the linear span of the training tasks? Section 6.1 Assumption 3.1 requires the new task to be a linear combination of training tasks, which is a "necessary" but potentially strict condition.

## Limitations
- Strong assumptions about shared representation structure and linear task combinations may not hold in real-world scenarios
- Theoretical confidence set width calculation depends on intractable covering number estimation
- Gradient conflict between dissimilar tasks can stall learning of the shared representation

## Confidence
- **High**: The mechanism by which joint training reduces confidence set size through multi-head function space compression is well-supported by theoretical analysis and empirical validation
- **Medium**: The transfer learning framework's conditions for success (task span and training data coverage) are clearly stated, but their practical verification remains challenging
- **Low**: The exact implementation details of the PPO-style clipping mechanism for confidence set approximation are not fully specified, creating potential reproducibility issues

## Next Checks
1. **Gradient Conflict Analysis**: Systematically test GFUCB with increasingly dissimilar task pairs to quantify the point at which shared representation training becomes detrimental

2. **Transfer Robustness Testing**: Design experiments where pretraining tasks intentionally violate Assumption 3.1 (non-linear combinations) to empirically measure the breakdown point of transfer performance

3. **Confidence Set Coverage**: Implement the theoretical confidence set width calculation and compare against the practical clipping implementation to quantify the approximation gap