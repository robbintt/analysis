---
ver: rpa2
title: Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation
arxiv_id: '2601.10109'
source_url: https://arxiv.org/abs/2601.10109
tags:
- skill
- skills
- data
- training
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of efficient knowledge distillation
  for reasoning models, where standard fine-tuning methods require large-scale data
  and overlook the latent skill structure within training examples. The authors propose
  a skill-centric distillation framework that leverages hierarchical skill trees to
  select training data based on the student model's per-skill weaknesses and incorporates
  explicit skill chains into the training process.
---

# Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation

## Quick Facts
- arXiv ID: 2601.10109
- Source URL: https://arxiv.org/abs/2601.10109
- Reference count: 14
- Using only 1,000 examples from a 100K corpus, the method improves Avg@8 accuracy by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five math reasoning benchmarks, outperforming random data selection baselines.

## Executive Summary
This paper addresses the problem of efficient knowledge distillation for reasoning models, where standard fine-tuning methods require large-scale data and overlook the latent skill structure within training examples. The authors propose a skill-centric distillation framework that leverages hierarchical skill trees to select training data based on the student model's per-skill weaknesses and incorporates explicit skill chains into the training process. Using only 1,000 examples from a 100K corpus, the method improves Avg@8 accuracy by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five math reasoning benchmarks, outperforming random data selection baselines. The approach demonstrates that aligning training with model weaknesses and embedding skill structures enhances both efficiency and interpretability in reasoning model distillation.

## Method Summary
The proposed skill-aware distillation framework operates through two key innovations: hierarchical skill tree construction and skill-aware data selection. The method first builds a hierarchical skill tree by clustering reasoning problems based on their required skills, creating a structured representation of the reasoning landscape. During data selection, the framework identifies the student model's weaknesses across different skill clusters and prioritizes examples from weak skill areas. The training process then incorporates explicit skill chain information, guiding the model to recognize and apply appropriate reasoning sequences. This approach contrasts with traditional random data selection methods by focusing computational resources on areas where the model needs improvement most.

## Key Results
- Improves Avg@8 accuracy by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five math reasoning benchmarks
- Achieves these improvements using only 1,000 examples from a 100K corpus
- Outperforms random data selection baselines by targeting model weaknesses through skill-aware training

## Why This Works (Mechanism)
The effectiveness of this approach stems from aligning training data selection with the model's actual weaknesses rather than treating all examples equally. By constructing hierarchical skill trees, the framework captures the latent structure within reasoning problems, allowing for targeted improvement in specific reasoning capabilities. The incorporation of skill chains during training helps the model recognize and apply appropriate reasoning sequences, addressing a fundamental limitation of standard fine-tuning approaches that often treat problems as isolated instances rather than recognizing their underlying skill dependencies.

## Foundational Learning
- **Hierarchical clustering of reasoning problems**: Groups problems by required skills to create structured skill representations
  - Why needed: Enables identification of skill-specific weaknesses and targeted improvement
  - Quick check: Verify that clusters capture meaningful distinctions in problem-solving approaches

- **Skill weakness identification**: Measures model performance across different skill clusters to prioritize training data
  - Why needed: Ensures computational resources focus on areas where improvement will have maximum impact
  - Quick check: Compare selected data distribution against random selection across skill categories

- **Skill chain incorporation**: Integrates explicit skill sequence information during training
  - Why needed: Helps models recognize and apply appropriate reasoning sequences rather than treating problems in isolation
  - Quick check: Validate that models learn to follow skill chains in test examples

## Architecture Onboarding

Component map: Skill Tree Construction -> Weakness Analysis -> Data Selection -> Skill Chain Incorporation -> Fine-tuning

Critical path: The core workflow involves constructing skill hierarchies, analyzing model weaknesses, selecting targeted examples, incorporating skill chains during training, and performing efficient fine-tuning.

Design tradeoffs: The framework balances between comprehensive skill coverage and targeted improvement, requiring careful threshold setting for weakness identification. The hierarchical structure must be sufficiently granular to capture meaningful skill distinctions while remaining computationally tractable.

Failure signatures: Poor skill tree construction may lead to ineffective targeting, random selection may fail to address actual weaknesses, and improper skill chain incorporation could confuse rather than guide the model.

First experiments:
1. Validate skill tree construction by testing whether similar problems cluster together and whether clusters correspond to meaningful skill categories
2. Test weakness identification accuracy by comparing predicted weaknesses against actual performance gaps
3. Evaluate whether skill chain incorporation improves reasoning sequence recognition compared to standard fine-tuning

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to larger datasets and different reasoning domains remains unexplored
- The hierarchical skill tree construction methodology is not fully detailed, raising questions about generalizability across different reasoning tasks
- The approach focuses exclusively on Qwen3-4B and Qwen3-8B models, limiting conclusions about cross-architecture applicability

## Confidence
- High confidence: The core empirical findings showing +1.6% and +1.4% improvements on tested benchmarks using 1,000 examples
- Medium confidence: The claim that skill structure alignment improves both efficiency and interpretability, as interpretability claims lack direct validation
- Medium confidence: The scalability implications from 1,000 to 100K examples, as larger-scale validation is not presented

## Next Checks
1. Test the skill-aware distillation framework on non-mathematical reasoning tasks (e.g., commonsense reasoning, code generation) to evaluate cross-domain generalizability
2. Conduct ablation studies removing the skill chain incorporation to isolate its contribution versus data selection alone
3. Perform long-term stability analysis to determine if skill-aware fine-tuning maintains performance advantages after extended training or across different model scales