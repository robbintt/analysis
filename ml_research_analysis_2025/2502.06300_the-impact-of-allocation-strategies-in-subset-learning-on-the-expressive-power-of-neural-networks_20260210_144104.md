---
ver: rpa2
title: The impact of allocation strategies in subset learning on the expressive power
  of neural networks
arxiv_id: '2502.06300'
source_url: https://arxiv.org/abs/2502.06300
tags:
- weights
- allocation
- learnable
- linear
- equations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how the allocation of a limited number of learnable
  weights in neural networks affects their expressive power. Using a teacher-student
  setup, the authors define a match probability to quantify the likelihood that a
  student network with a fixed allocation of learnable weights can replicate the teacher's
  outputs.
---

# The impact of allocation strategies in subset learning on the expressive power of neural networks

## Quick Facts
- **arXiv ID:** 2502.06300
- **Source URL:** https://arxiv.org/abs/2502.06300
- **Reference count:** 40
- **Primary result:** Allocation strategies significantly impact neural network expressive power, with distributed weights generally outperforming concentrated allocations

## Executive Summary
This paper studies how the allocation of a limited number of learnable weights in neural networks affects their expressive power. Using a teacher-student setup, the authors define a match probability to quantify the likelihood that a student network with a fixed allocation of learnable weights can replicate the teacher's outputs. They prove conditions for "maximal" and "minimal" allocations in linear recurrent and feedforward networks, showing that allocations tend to be more expressive when learnable weights are distributed throughout the network rather than concentrated in specific regions. For suboptimal allocations, heuristic principles are proposed to estimate their expressivity. These principles extend to shallow ReLU networks as well. The findings are validated through empirical experiments, demonstrating that distributing learnable weights more broadly generally enhances the network's expressive power.

## Method Summary
The authors evaluate expressivity using a student-teacher framework where the student has r = m × d learnable weights while the rest are fixed. Match probability (MP) measures the probability that the student can exactly match teacher outputs on m samples. For linear models, they use second-order optimization (fsolve) to solve the resulting polynomial systems, while shallow ReLU networks use AdaHessian optimizer. Weight scaling ensures variance stability. The method involves defining architecture parameters, selecting allocations based on theoretical theorems, attempting exact matching, and aggregating success counts over 1,000 trials.

## Key Results
- Distributed allocations achieve higher match probability than concentrated allocations in linear recurrent and feedforward networks
- Maximal allocations occur when exactly Tb weights per row (or Td per column) are used across r/Tb rows (or r/Td columns)
- Learning recurrent weights creates polynomial systems requiring second-order optimization, while decoder/encoder learning reduces to linear systems
- Heuristic principles for suboptimal allocations extend to shallow ReLU networks with AdaHessian optimization

## Why This Works (Mechanism)

### Mechanism 1
Match probability quantifies expressive power by measuring the likelihood that a student can exactly replicate teacher outputs. Given allocation A with r learnable weights and constant weights cW elsewhere, match probability MP(A) = Pr[∃W ∈ RA;cW s.t. MW(X) = MW*(X)] computes whether the constrained student can solve the system of equations needed to match teacher outputs on m samples.

### Mechanism 2
Distributed allocations achieve higher match probability because each row/column can participate in only a limited number of independent equations (Tb equations per row, Td per column in LRNNs). Concentrating learnable weights in few rows/columns wastes variables—some equations become overdetermined while others lack free variables. Distribution ensures each variable addresses unique constraints.

### Mechanism 3
Learning decoder/encoder weights reduces to linear systems; learning recurrent weights creates polynomial systems with intermediate match probabilities. The decoder (D) and encoder (B) appear linearly in output Y = D·[polynomial in W]·B·X. When only D or B is learned, the problem is linear. When W is learned, powers of W create degree-T polynomials. Introducing auxiliary variables F transforms polynomial equations into mixed linear-quadratic systems; more distributed allocations yield more linear equations, increasing solvability.

## Foundational Learning

- **Student-teacher framework**: Why needed here - The entire expressivity analysis depends on comparing a constrained student to a fully-parameterized teacher with identical architecture. Quick check - Can you explain why MP would be ill-defined if student and teacher had different architectures?
- **Kronecker product and vectorization**: Why needed here - Proofs use vec(ABC) = (C^T ⊗ A)vec(B) to transform matrix equations into linear systems. Quick check - Given W ∈ R^{d×n} and X ∈ R^{n×m}, write WX = Y in vectorized form.
- **Linear recurrent neural network dynamics**: Why needed here - The output Y = D·Σ_t W^{T-t+1}·B·X_t determines the polynomial structure when learning W. Quick check - For T=3, expand the recursion to show where degree-3 terms in W arise.

## Architecture Onboarding

- **Component map**: Encoder B (n×b) -> Recurrent W (n×n) -> Decoder D (d×n)
- **Critical path**:
  1. Determine r = dm (minimum learnable weights needed)
  2. Choose which components to learn (decoder → encoder → recurrent in order of simplicity)
  3. For recurrent learning, allocate uniformly across r/Tb rows OR r/Td columns
  4. Verify no row/column exceeds its equation budget
- **Design tradeoffs**:
  - Decoder-only learning: Simpler (linear), but expressivity limited to output transformations
  - Encoder-only learning: Linear but requires careful row/column balance (Tm/Td constraints)
  - Recurrent learning: Most expressive for temporal dynamics, but requires polynomial optimization (second-order methods)
  - Mixed allocations: Can combine, but each component's constraints apply independently
- **Failure signatures**:
  - MP = 0 for valid r: Check for concentrated allocations (e.g., >Tb weights in one row)
  - Optimizer fails to converge: Recurrent learning requires second-order methods (fsolve or AdaHessian); first-order methods fail on exact matching
  - Variance explosion in hidden states: Sample weights with variance σ²/n for n-dimensional matrices
- **First 3 experiments**:
  1. Linear estimator warm-up: Implement Section 2.1 toy example with d=2, m=2, r=4. Verify that equal division across rows yields MP=1; shifting one weight between rows yields MP=0.
  2. Small LRNN recurrent test: Use n=2, T=2, b=d=1, m=2. Compare diagonal vs. off-diagonal allocations; expect MP ≈ 0.74-0.83, not 0 or 1.
  3. Scaling test: For n∈{8,12,16}, plot MP vs. fraction of learned rows. Verify transition at r/Tb rows using second-order optimization.

## Open Questions the Paper Calls Out

### Open Question 1
How do specific allocation strategies affect the generalization error and trainability of neural networks, distinct from their theoretical expressive power? The authors state their analysis "primarily focuses on expressivity, which does not encompass other important aspects of network performance, such as generalization or optimization, and these should be explored in future work."

### Open Question 2
Do the "rule of thumb" principles for distributing learnable weights hold theoretically for deeper non-linear architectures (e.g., deep ReLU networks) and structured datasets? The paper notes that "many results were derived for simplified architectures" and assumptions of i.i.d inputs, explicitly calling for future work to "extend these results numerically and theoretically to more complex architectures and structured datasets."

### Open Question 3
Are the optimal allocations identified by the match probability framework practically learnable using standard gradient descent? In the Methods section, the authors note that "Standard gradient descent failed to find a solution" in their experiments because the models were not overparameterized, forcing them to use second-order optimization methods.

## Limitations
- The match probability framework assumes Gaussian weight priors and linear independence of samples/outputs, which may not hold in practical settings
- While linear cases have rigorous proofs, polynomial systems from recurrent weight learning rely more on empirical observations about second-order solvers
- Heuristic principles for suboptimal allocations lack formal justification and depend on numerical experiments
- AdaHessian-based validation for ReLU networks may not perfectly align with the theoretical MP metric designed for linear systems

## Confidence
- Mechanism 1 (match probability definition): **High** - Formal definition with clear mathematical framework
- Mechanism 2 (distributed allocations superior): **High** - Proven via Theorems 3.4-3.5 with sharp thresholds
- Mechanism 3 (linear vs polynomial systems): **Medium** - Theoretical basis for linear cases, but polynomial case relies more on empirical solver behavior
- Heuristic principles for suboptimal allocations: **Low** - Empirical observations without formal proofs

## Next Checks
1. Test allocation principles on non-Gaussian weight distributions (e.g., uniform, Bernoulli) to verify robustness of the distribution advantage beyond Gaussian assumptions
2. Implement first-order optimizer baseline on polynomial systems to confirm second-order methods are indeed necessary for exact matching, not just more efficient
3. Extend match probability framework to non-linear activation functions beyond ReLU (e.g., tanh, sigmoid) to test generalizability of the expressivity quantification approach