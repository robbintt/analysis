---
ver: rpa2
title: 'Nationality and Region Prediction from Names: A Comparative Study of Neural
  Models and Large Language Models'
arxiv_id: '2601.08692'
source_url: https://arxiv.org/abs/2601.08692
tags:
- prediction
- nationality
- neural
- region
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive comparison of neural models
  and large language models (LLMs) on nationality and region prediction from personal
  names. Six neural models (SVM, fastText, CNN, BiLSTM, CANINE, XLM-RoBERTa) and six
  LLM prompting strategies (Zero-shot, Few-shot, Chain-of-Thought, Self-Consistency,
  Least-to-Most, Self-Reflection) were evaluated across three granularity levels using
  a dataset of 99 nationalities.
---

# Nationality and Region Prediction from Names: A Comparative Study of Neural Models and Large Language Models

## Quick Facts
- arXiv ID: 2601.08692
- Source URL: https://arxiv.org/abs/2601.08692
- Authors: Keito Inoshita
- Reference count: 39
- Primary result: LLMs (0.776 accuracy) significantly outperformed neural models (0.481 accuracy) on nationality prediction from names

## Executive Summary
This paper presents a comprehensive comparison of neural models and large language models (LLMs) on nationality and region prediction from personal names. Six neural models (SVM, fastText, CNN, BiLSTM, CANINE, XLM-RoBERTa) and six LLM prompting strategies (Zero-shot, Few-shot, Chain-of-Thought, Self-Consistency, Least-to-Most, Self-Reflection) were evaluated across three granularity levels using a dataset of 99 nationalities. Results show LLMs significantly outperformed neural models, with Self-Reflection achieving 0.776 accuracy on nationality prediction versus 0.481 for the best neural model (SVM). The performance gap narrowed as granularity became coarser (0.074 difference at 6-region level). Error analysis revealed LLMs made "near-miss" errors predicting correct regions even when nationality was wrong, while neural models showed more cross-regional errors and bias toward high-frequency classes.

## Method Summary
The study evaluated six neural models (SVM with character n-grams, fastText, CNN, BiLSTM, CANINE, XLM-RoBERTa) and six LLM prompting strategies (Zero-shot, Few-shot, Chain-of-Thought, Self-Consistency, Least-to-Most, Self-Reflection) on nationality prediction from names. The name2nat dataset contained 75,345 samples across 99 nationalities (500-800 samples each), stratified into Head/Mid/Tail frequency groups. Models were evaluated at three granularity levels: 99 nationalities, 14 regions, and 6 continents. Neural models used character-level features and standard training procedures, while LLMs (GPT-4.1-mini) were prompted with various strategies and requested JSON output for automated parsing. Evaluation metrics included Accuracy, Macro-F1, and Precision@k, with frequency-stratified analysis to reveal bias patterns.

## Key Results
- LLMs significantly outperformed neural models on nationality prediction (Self-Reflection: 0.776 accuracy vs. SVM: 0.481)
- The performance gap narrowed at coarser granularity levels (6-region: 0.074 difference between best LLM and neural model)
- LLMs showed "near-miss" error patterns (correct region but wrong nationality) while neural models exhibited more cross-regional errors
- Neural models demonstrated better frequency robustness than LLMs, with SVM showing only 0.001 accuracy drop between Head and Tail groups

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs outperform neural models on fine-grained nationality prediction by leveraging world knowledge acquired during pre-training.
- **Mechanism:** LLMs encode structured knowledge about name-nationality relationships (e.g., "-ovich is a patronymic suffix typical of Slavic languages") from massive pre-training corpora. This enables inference beyond surface character patterns to cultural-linguistic understanding.
- **Core assumption:** The performance gap stems from world knowledge rather than model scale alone.
- **Evidence anchors:**
  - [abstract] "LLMs have the potential to address these challenges by leveraging world knowledge acquired during pre-training"
  - [Section 4.2] Self-Reflection achieved 0.776 accuracy vs. SVM 0.481—a 0.295 difference
  - [Section 5.1] "LLMs' nationality prediction capability is based on world knowledge acquired during pre-training rather than fitting to training data"
- **Break condition:** If pre-training corpora lack diverse name-nationality mappings (e.g., underrepresented languages), world knowledge degrades. [Section 4.4] shows LLM Macro-F1 drops from ~0.35-0.44 (Head) to ~0.26-0.31 (Tail) for low-frequency nationalities.

### Mechanism 2
- **Claim:** Neural models achieve competitive performance at coarse granularity through character pattern matching alone.
- **Mechanism:** Character n-grams (1-4 grams in SVM) capture suffix/prefix patterns that correlate with broad geographical regions (e.g., "-ez" → Spanish-speaking regions). At 6-region granularity, character patterns provide sufficient signal.
- **Core assumption:** Coarse-grained regions share distinctive character-level features that don't require cultural knowledge.
- **Evidence anchors:**
  - [Section 4.3] Performance gap narrows to 0.074 at 6-region level (Few-shot 0.854 vs. XLM-RoBERTa 0.780)
  - [Section 5.1] "At coarse granularity such as 6-region prediction, information obtained from character patterns is sufficient to achieve high performance"
  - [corpus] Corpus evidence is weak—related papers focus on LLM bias rather than neural model mechanisms
- **Break condition:** Fails for nationalities with overlapping character patterns within the same region (e.g., Belarusian vs. Ukrainian). [Section 4.5] shows XLM-RoBERTa misclassifies 16% of Belarusian as Russian.

### Mechanism 3
- **Claim:** Self-Reflection prompting improves LLM accuracy by enabling self-correction of initial predictions.
- **Mechanism:** The model generates an initial prediction, then evaluates its confidence and considers alternatives before finalizing. This catches overconfident errors where initial pattern-matching led to incorrect conclusions.
- **Core assumption:** LLMs can reliably assess their own prediction confidence and identify when reconsideration is warranted.
- **Evidence anchors:**
  - [Section 4.2] Self-Reflection achieved highest LLM performance (0.776 accuracy, 0.782 Macro-F1)
  - [Section 3.2.2] "If confidence is low or alternative candidates exist, the final prediction is output after reconsideration"
  - [corpus] No corpus papers validate self-reflection specifically for name-based tasks
- **Break condition:** Self-correction may propagate errors if the model fixates on incorrect hypotheses during reasoning. [Section 5.1] notes Chain-of-Thought's explicit reasoning increased "risk of fixating on incorrect hypotheses."

## Foundational Learning

- **Concept: Character-level N-gram Features**
  - Why needed here: Names are short strings; character n-grams capture suffix/prefix patterns that distinguish nationalities without requiring word tokenization.
  - Quick check question: Given "Tanaka Taro," what 2-grams would a character-level model extract?

- **Concept: Hierarchical Classification Granularity**
  - Why needed here: The study evaluates predictions at three levels (99 nationalities → 14 regions → 6 continents); understanding hierarchical mapping is essential for interpreting "near-miss" errors.
  - Quick check question: If a model predicts Korean but the true label is Japanese, is this correct at the region level?

- **Concept: Frequency Stratified Analysis**
  - Why needed here: Class imbalance is inherent (high-frequency nationalities dominate); Head/Mid/Tail analysis reveals bias patterns that accuracy alone masks.
  - Quick check question: Why might Macro-F1 show frequency bias when Accuracy doesn't?

## Architecture Onboarding

- **Component map:** name2nat dataset → stratified sampling (Head/Mid/Tail) → train/dev/test split (8:1:1) → neural models (SVM, fastText, CNN, BiLSTM, CANINE, XLM-RoBERTa) OR LLM pipeline (GPT-4.1-mini API → prompting strategies → JSON parsing) → three-granularity evaluation (99 classes → 14 regions → 6 continents)

- **Critical path:**
  1. Data preprocessing with 800-sample cap per nationality, 500-sample minimum threshold
  2. Model training (neural) or prompt design (LLM) with region-aware examples
  3. Three-granularity evaluation with frequency-stratified analysis

- **Design tradeoffs:**
  - SVM: Best frequency robustness (∆H-T = 0.001) but lower absolute accuracy
  - Pre-trained models (CANINE, XLM-RoBERTa): Higher accuracy but 20%+ performance drop for Tail nationalities
  - LLMs: Highest accuracy (0.776) with near-miss error patterns, but API cost and frequency bias in Macro-F1

- **Failure signatures:**
  - Neural cross-regional errors: South American nationalities misclassified as Mexican (high-frequency bias)
  - LLM overgeneralization: "Jordan Williams" → American (defaulting to most common nationality for ambiguous English names)
  - Least-to-Most error propagation: 0.619 accuracy in 99-class task due to hierarchical errors compounding

- **First 3 experiments:**
  1. Establish neural baseline with SVM (character 1-4 grams) and measure Head/Mid/Tail accuracy to assess frequency robustness
  2. Run LLM Zero-shot on 100 samples across frequency bins; verify JSON parsing compliance and measure region-level accuracy for "near-miss" analysis
  3. Compare Self-Reflection vs. Zero-shot on a held-out subset of Tail nationalities; quantify whether self-correction reduces cross-regional errors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the superior performance and "near-miss" error patterns of LLMs generalize across different model architectures (e.g., Claude, Gemini, Llama)?
- Basis in paper: [explicit] The authors note "LLM evaluation is limited to a single model, GPT-4.1-mini" and call for "generalizing findings through comparison using multiple LLMs."
- Why unresolved: Variations in pre-training corpora and model architectures may result in different bias patterns or accuracy levels not captured by testing a single model.
- What evidence would resolve it: A comparative evaluation of nationality prediction accuracy and error types across a diverse set of state-of-the-art open and closed LLMs.

### Open Question 2
- Question: How does model performance change when predicting nationality from names in their original scripts (e.g., Cyrillic, CJK) versus romanized inputs?
- Basis in paper: [explicit] The authors state "evaluation targets are limited to English (romanized) names" and acknowledge that "evaluation using original scripts... has not been conducted."
- Why unresolved: Original scripts contain orthographic clues that may significantly alter task difficulty and the relative advantage of LLMs over neural baselines.
- What evidence would resolve it: Replication of the study's experiments using a multi-script dataset containing non-Latin characters to compare against the romanized baseline.

### Open Question 3
- Question: Can a hybrid ensemble approach effectively combine the "near-miss" accuracy of LLMs with the frequency robustness of simpler neural models?
- Basis in paper: [explicit] The conclusion proposes the "development of hybrid methods that leverage the complementary characteristics" of LLMs and neural models.
- Why unresolved: LLMs show degradation for low-frequency nationalities (Tail group), whereas SVMs show high robustness; it is unknown if they can dynamically correct each other's weaknesses.
- What evidence would resolve it: Implementation and evaluation of an ensemble model (e.g., confidence-based switching) analyzed specifically across Head, Mid, and Tail frequency groups.

## Limitations
- Prompt template specification is unclear, creating significant reproducibility barriers
- GPT-4.1-mini model access and exact configuration parameters are unspecified
- Evaluation granularity definitions and region-to-continent mapping are not fully specified

## Confidence
- **High confidence:** Neural model performance comparisons (SVM 0.481 vs. XLM-RoBERTa 0.695) are directly verifiable from specified character n-gram configurations
- **Medium confidence:** LLM performance advantage (0.776 vs. 0.481) is supported by systematic evaluation but depends on unstated prompt template variations
- **Low confidence:** Self-Reflection mechanism's superiority over other prompting strategies is plausible but not directly verifiable without exact prompt templates

## Next Checks
- **Validation 1:** Replicate the SVM baseline using character 1-4 grams with 50K feature limit and Platt scaling. Verify frequency-stratified accuracy shows the reported robustness (∆H-T = 0.001) to confirm neural model methodology is correctly understood.
- **Validation 2:** Implement Zero-shot prompting with exact nationality list inclusion and JSON output format. Run on 100 samples across Head/Mid/Tail frequencies to establish baseline LLM performance and verify "near-miss" error patterns before attempting complex prompting strategies.
- **Validation 3:** Create the complete 99-nationality to 14-region mapping using external geographical knowledge bases (e.g., UN M.49 codes). Validate region predictions on 20 samples to ensure the error analysis framework is correctly applied before interpreting cross-regional error patterns.