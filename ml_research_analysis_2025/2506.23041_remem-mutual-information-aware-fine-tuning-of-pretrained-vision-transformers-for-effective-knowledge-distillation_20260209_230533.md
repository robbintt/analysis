---
ver: rpa2
title: 'ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers
  for Effective Knowledge Distillation'
arxiv_id: '2506.23041'
source_url: https://arxiv.org/abs/2506.23041
tags:
- pretrained
- teacher
- student
- distillation
- mutual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of effective knowledge distillation
  from strong pretrained Vision Transformers (ViTs) to smaller task-specific models,
  where distillation effectiveness drops significantly with increasingly strong teachers.
  The authors propose ReMem, a mutual information-aware fine-tuning approach that
  combines Sharpness-Aware Minimization (SAM) with MLP block reweighting.
---

# ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation

## Quick Facts
- arXiv ID: 2506.23041
- Source URL: https://arxiv.org/abs/2506.23041
- Reference count: 40
- Key outcome: ReMem improves student model performance across 16 diverse image classification datasets by addressing the mutual information bottleneck in strong ViT teachers

## Executive Summary
ReMem addresses a critical challenge in knowledge distillation: as Vision Transformer teachers become stronger through pretraining on larger datasets, their effectiveness at transferring knowledge to smaller students paradoxically decreases. The authors identify that this occurs because top MLP blocks in strong ViTs develop sparse activation patterns (expertness) that reduce mutual information with inputs, making teacher outputs less informative for students. ReMem combines Sharpness-Aware Minimization (SAM) with MLP block reweighting to recover this lost mutual information, enabling effective distillation from larger and stronger teacher models that would otherwise harm student performance.

## Method Summary
ReMem fine-tunes pretrained ViT teachers using two complementary techniques: (1) MLP reweighting that downweights top layers' contributions to the residual connection, reducing the bottleneck effect of expert neurons, and (2) SAM optimization with large perturbation sizes (ρ ≳ 0.05) that preserve input-specific information in teacher representations. The method fine-tunes teachers on downstream datasets, then distills to smaller student models using standard KD losses. MLP reweighting applies a layer-wise scaling factor α < 1 to MLP blocks, while SAM uses perturbations much larger than typical generalization settings to encourage representations that maintain mutual information with inputs.

## Key Results
- ReMem consistently improves student accuracy across 16 diverse image classification datasets
- Achieves up to 78.5% accuracy on CIFAR-100 with ViT-L teacher versus 73.7% without ReMem
- Enables effective distillation from larger ViT models and those pretrained on larger-scale datasets
- Works across various student architectures including MobileNetV2 and EfficientNetV2

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SAM with large perturbation sizes improves mutual information between teacher outputs and inputs, leading to better distillation.
- **Mechanism:** SAM optimization with ρ ≳ 0.05 encourages representations that preserve input-specific information rather than collapsing to sparse expert patterns.
- **Core assumption:** Mutual information between teacher outputs and inputs is a limiting factor for knowledge transfer.
- **Evidence anchors:** Figure 2 shows SAM with large ρ reaches better pareto-front on the information plane; Figure 3 shows student test error drops significantly with SAM at ρ=0.05.
- **Break condition:** Less effective on small or highly-imbalanced datasets where mutual information-aware optimization fails to help.

### Mechanism 2
- **Claim:** Top MLP blocks in strong pretrained ViTs develop high "expertness"—sparse activation patterns that bottleneck mutual information.
- **Mechanism:** Each top MLP neuron activates for only a small subset of inputs, making similar inputs activate the same neurons → outputs become nearly indistinguishable → mutual information drops.
- **Core assumption:** The information bottleneck from expertness is irreversible through standard fine-tuning without intervention.
- **Evidence anchors:** Figure 4 shows pruning top MLP blocks causes sharp increase in mutual information; Figure 5 shows expertness increases with pretrained model strength.
- **Break condition:** If the downstream dataset is small or long-tailed, the expert structure may already be fixed.

### Mechanism 3
- **Claim:** Downweighting top MLP blocks is a simple, effective heuristic to recover mutual information without training.
- **Mechanism:** Replace standard residual connection with weighted version where top layers are exponentially downweighted more than bottom layers.
- **Core assumption:** The harmful mutual information loss is localized primarily to top MLP blocks.
- **Evidence anchors:** Table 10 shows "Reweight MLP only" improves student accuracy from 63.6 → 65.1; combined with SAM reaches 68.1.
- **Break condition:** If the teacher model is already weak, MLP reweighting may not be needed.

## Foundational Learning

- **Concept:** **Mutual Information I(X; F_T)** — the amount of information about input X preserved in teacher outputs F_T.
  - **Why needed here:** The core thesis is that distillation fails when I(X; F_T) is too low, because the teacher provides no more signal than hard labels.
  - **Quick check question:** Can you explain why a teacher with near-zero mutual information would be no better than training the student with only hard labels?

- **Concept:** **Sharpness-Aware Minimization (SAM)** — an optimizer that minimizes worst-case loss within a perturbation radius ρ of the weights.
  - **Why needed here:** SAM is repurposed here not for generalization but to encourage representations that are robust to perturbation and thus retain more input information.
  - **Quick check question:** What is the typical perturbation size ρ for generalization vs. what the paper uses for mutual information improvement?

- **Concept:** **Expertness in MLP blocks** — the degree to which neurons activate selectively for specific input subpopulations, mimicking Mixture-of-Experts.
  - **Why needed here:** Explains why top MLP blocks become bottlenecks for mutual information.
  - **Quick check question:** If two inputs activate exactly the same neuron in an MLP block, what happens to the mutual information of that block's output?

## Architecture Onboarding

- **Component map:** Pretrained ViT -> SAM fine-tuning (ρ ≈ 0.05-0.5) -> MLP reweighting (α ≈ 0.8-0.9) -> Distillation to student

- **Critical path:**
  1. Load pretrained ViT (e.g., ViT-B from Augreg)
  2. Apply MLP reweighting with α (typically 0.8–0.9) before fine-tuning
  3. Fine-tune with SAM (ρ ≈ 0.05–0.5) on downstream dataset
  4. Early-stop at multiple checkpoints; select based on best student after distillation

- **Design tradeoffs:**
  - Larger ρ → higher mutual information but potentially worse teacher accuracy
  - Smaller α → more downweighting of MLP → more mutual information recovery but risk of underfitting
  - ReMem often hurts teacher accuracy but improves student accuracy

- **Failure signatures:**
  - Student worse than vanilla fine-tuning → check if downstream dataset is too small (<3K samples) or highly imbalanced
  - No improvement from reweighting → verify α is applied to MLP blocks only, not attention
  - Teacher accuracy collapses → ρ may be too large; try ρ ∈ {0.05, 0.005}

- **First 3 experiments:**
  1. **Baseline comparison:** Fine-tune ViT-B on CIFAR-100 vanilla vs. ReMem (SAM ρ=0.05, α=0.8), then distill to ResNet-18. Expect ~2–3% student gain.
  2. **Ablation:** Run SAM-only and MLP-reweighting-only variants on CIFAR-100 + Flowers. Confirm each contributes independently.
  3. **Scale test:** Apply ReMem to ViT-L vs. ViT-B teachers. Verify that the larger teacher now yields better students than the smaller teacher.

## Open Questions the Paper Calls Out

- **Curriculum control adaptation:** Can ReMem be adapted as a curriculum control mechanism to gradually increase teacher difficulty during distillation, and would this be more effective than sequential learning from small-to-large models? The authors propose this idea but leave it for future work due to limited computation resources.

## Limitations

- The empirical claims rely on unstated assumptions about data augmentation, exact ViT checkpoint versions, and SAM implementation details
- The theoretical bounds on mutual information depletion are analytical but may not capture all practical scenarios
- The claim that SAM with large ρ is uniquely effective for mutual information recovery lacks comparison to other information-theoretic regularization methods

## Confidence

- **High Confidence:** The empirical observation that stronger pretrained teachers often yield worse distillation results; the effectiveness of SAM with ρ ≳ 0.05 for improving mutual information
- **Medium Confidence:** The analytical connection between expertness and mutual information depletion; the claim that ReMem enables effective distillation from larger teachers
- **Low Confidence:** The assertion that MLP reweighting is a "simple and effective" alternative to SAM; the specific claim about "emergent Mixture-of-Experts" structure being irreversible

## Next Checks

1. **Cross-architecture validation:** Apply ReMem to non-ViT architectures (e.g., MLP-Mixer, ConvNeXt) to test whether MLP expertness is a general phenomenon or specific to ViT's MLP structure.

2. **Information-theoretic ablation:** Replace SAM with alternative mutual information maximization techniques (e.g., MINE-based regularization) to determine if large ρ SAM is uniquely effective or if any MI-preserving fine-tuning works.

3. **Data regime stress test:** Systematically vary dataset size and class balance to identify precise failure boundaries for ReMem, particularly on datasets with <1K samples or extreme long-tail distributions where the paper reports limited effectiveness.