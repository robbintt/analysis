---
ver: rpa2
title: Adapting Large Language Models to Emerging Cybersecurity using Retrieval Augmented
  Generation
arxiv_id: '2510.27080'
source_url: https://arxiv.org/abs/2510.27080
tags:
- retrieval
- arxiv
- cybersecurity
- hybrid
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of adapting large language models
  (LLMs) to emerging cybersecurity threats, focusing on improving knowledge retention
  and temporal reasoning. The core method introduces a hybrid sparse-dense retriever
  that combines BM25 keyword-based retrieval, FAISS-based semantic retrieval, and
  regular expression matching for CVE identifiers, aiming to enhance context grounding
  for LLMs in cyber threat intelligence tasks.
---

# Adapting Large Language Models to Emerging Cybersecurity using Retrieval Augmented Generation

## Quick Facts
- arXiv ID: 2510.27080
- Source URL: https://arxiv.org/abs/2510.27080
- Authors: Arnabh Borah; Md Tanvirul Alam; Nidhi Rastogi
- Reference count: 40
- Primary result: Hybrid sparse-dense retriever achieves 72.7% accuracy on KCV dataset and 92.2% on CWET dataset

## Executive Summary
This paper addresses the challenge of adapting large language models to emerging cybersecurity threats by introducing a hybrid sparse-dense retriever that combines BM25 keyword-based retrieval, FAISS-based semantic retrieval, and regular expression matching for CVE identifiers. The approach aims to improve context grounding and knowledge retention for LLMs in cyber threat intelligence tasks. The study demonstrates that this hybrid method outperforms both baseline LLM-only and baseline RAG approaches on cybersecurity question answering tasks, with particular emphasis on CVE and CWE identification.

## Method Summary
The paper introduces a hybrid retrieval-augmented generation framework for cybersecurity question answering that combines three retrieval strategies: dense semantic retrieval using FAISS with mxbai-embed-large-v1 embeddings, sparse keyword retrieval using BM25, and regex-based matching for CVE identifiers with a +1.0 score boost. The method uses LangChain's RecursiveCharacterTextSplitter for document chunking (512 character chunks with 20 character overlap) and employs Llama-3-8B-Instruct as the base model. The hybrid approach normalizes and combines retrieval scores using a weighted combination, with optimal temperature settings of 0.01 for improved accuracy. The framework was evaluated on the KCV and CWET datasets from the SECURE benchmark.

## Key Results
- Hybrid retriever achieves 72.7% accuracy on KCV dataset versus 59.2% for no-RAG and 57.6% for baseline RAG
- Hybrid retriever achieves 92.2% accuracy on CWET dataset versus 84.5% for baseline RAG
- Lower temperature settings (0.01) significantly improve accuracy compared to default settings

## Why This Works (Mechanism)
The hybrid retriever addresses the context grounding challenge in LLMs for cybersecurity by combining multiple complementary retrieval signals. Dense retrieval captures semantic relationships between queries and documents, sparse retrieval provides keyword-based precision for specific terms and identifiers, and regex matching ensures critical CVE identifiers are always retrieved. This multi-faceted approach reduces the risk of missing important context that any single retrieval method might overlook, particularly in the domain-specific language and identifier-heavy nature of cybersecurity content.

## Foundational Learning
- **BM25 sparse retrieval**: Why needed - provides keyword-based precision for specific cybersecurity terms and identifiers; Quick check - verify document ranking matches expected keyword matches
- **FAISS dense retrieval**: Why needed - captures semantic relationships beyond exact keyword matches; Quick check - ensure embeddings reflect domain-specific terminology relationships
- **Regex CVE matching**: Why needed - guarantees retrieval of critical vulnerability identifiers regardless of semantic similarity; Quick check - test regex pattern against various CVE identifier formats
- **Hybrid score normalization**: Why needed - enables meaningful combination of different score distributions from multiple retrievers; Quick check - verify score ranges are properly normalized before combination
- **Temperature optimization**: Why needed - balances exploration and exploitation in model responses for accuracy; Quick check - test different temperature settings to observe accuracy impact

## Architecture Onboarding

**Component Map**
Document Corpus -> Text Splitter -> Embedding Store -> Dense Retriever -> BM25 Retriever -> Regex Matcher -> Score Normalizer -> Hybrid Combiner -> LLM -> Answer

**Critical Path**
Query -> Hybrid Retriever (Dense + Sparse + Regex) -> Document Context -> LLM Processing -> Answer Generation

**Design Tradeoffs**
- Chunk size vs context completeness: 512 chars balances granularity with retrieval precision
- Embedding model choice: mxbai-embed-large-v1 selected for balance of quality and resource requirements
- Temperature setting: 0.01 optimal for accuracy but may reduce response diversity
- Retrieval depth: k=3 balances retrieval comprehensiveness with noise reduction

**Failure Signatures**
- Low accuracy despite correct implementation: likely due to document chunking that breaks key context or embedding model misalignment
- No improvement over baseline RAG: suggests hybrid components aren't properly integrated or weighted
- Inconsistent results across runs: indicates temperature or random seed issues

**3 First Experiments**
1. Baseline RAG implementation: Chunk documents, embed with FAISS, retrieve top-3, test on sample questions
2. Component ablation: Test dense-only, sparse-only, and regex-only retrieval to quantify individual contributions
3. Hybrid parameter tuning: Vary α weighting parameter to find optimal sparse-dense combination

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the hybrid retrieval framework maintain performance on cybersecurity datasets that lack explicit identifiers, such as unstructured threat advisories or malware reports?
- Basis in paper: The authors state in Section 7 that the framework is currently limited to CVE/CWE contexts and "future work should test the approach in a broader range of security-related datasets, including those without explicit identifiers."
- Why unresolved: The current performance boost relies heavily on regex matching for specific IDs; it is unclear if the semantic component is robust enough for free-form threat intelligence.
- What evidence would resolve it: Benchmark results on non-identifier CTI corpora (e.g., narrative incident reports) showing the hybrid method outperforming baselines without regex support.

### Open Question 2
- Question: Is the proposed hybrid approach effective across different LLM families and scales beyond the Llama-3-8B-Instruct model?
- Basis in paper: Section 7 notes that the study is "restricted to Llama-3-8B-Instruct" and lists "evaluating the framework across different model families and scales" as a specific future direction.
- Why unresolved: The specific temperature settings and retrieval weights may be overfitted to the reasoning patterns of the 8B parameter model.
- What evidence would resolve it: Comparative accuracy results using the framework with larger models (e.g., Llama-3-70B) or different architectures (e.g., Mistral, GPT-4) on the same SECURE benchmark.

### Open Question 3
- Question: Can extending the regular expression matcher to include CWE, ATT&CK, and CAPEC taxonomies further improve retrieval precision?
- Basis in paper: Section 7 identifies that the "current regex matcher is limited to CVE patterns" and suggests extending capability to "other identifiers such as CWE, ATT&CK, CAPEC."
- Why unresolved: While CVE regex proved effective for vulnerability tasks, the utility of similar hard filters for tactic-based or weakness-based queries remains unverified.
- What evidence would resolve it: Ablation studies showing increased accuracy on CWE-specific tasks (like CWET) or attack-pattern datasets when the expanded regex set is applied.

## Limitations
- Implementation details for hybrid score weighting lack precision, particularly the α parameter controlling sparse-dense score combination
- Observed accuracy improvements represent incremental rather than transformative gains (15.1 percentage point increase on KCV)
- Study focuses exclusively on Llama-3-8B-Instruct model, limiting generalizability to other architectures

## Confidence

**High confidence**: The core methodology combining BM25, FAISS embeddings, and regex matching for CVE retrieval is technically sound and well-described. The empirical finding that lower temperatures improve accuracy is consistently supported across experiments.

**Medium confidence**: The accuracy improvements on KCV (72.7%) and CWET (92.2%) datasets are methodologically valid, though the modest gains over baseline RAG raise questions about practical significance versus complexity trade-offs.

**Low confidence**: The generalizability of results beyond Llama-3-8B-Instruct models and the specific cybersecurity domains tested remains uncertain without broader validation.

## Next Checks
1. Implement the hybrid retriever with varying α values (0.3-0.7 range) to determine optimal weighting for sparse-dense combination
2. Test alternative embedding models (e.g., bge-large-en-v1.5, all-MiniLM-L6-v2) to verify the modest impact finding holds across different embedding architectures
3. Conduct ablation studies removing individual components (BM25, FAISS, regex) to quantify each contribution to the 72.7% accuracy improvement