---
ver: rpa2
title: Bio-Inspired Artificial Neural Networks based on Predictive Coding
arxiv_id: '2508.08762'
source_url: https://arxiv.org/abs/2508.08762
tags:
- posterior
- parameters
- variational
- generative
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Predictive Coding (PC) as a biologically plausible
  alternative to backpropagation (BP) for training artificial neural networks. PC
  updates weights using only local information, aligning with Hebbian synaptic plasticity,
  in contrast to BP which relies on global error signals.
---

# Bio-Inspired Artificial Neural Networks based on Predictive Coding

## Quick Facts
- arXiv ID: 2508.08762
- Source URL: https://arxiv.org/abs/2508.08762
- Authors: Davide Casnici; Charlotte Frenkel; Justin Dauwels
- Reference count: 12
- Primary result: PC achieves comparable classification accuracy to BP but requires 30× more FLOPs and only half the parameters for compression tasks

## Executive Summary
This tutorial-style paper presents Predictive Coding (PC) as a biologically plausible alternative to backpropagation for training neural networks. PC derives from variational inference principles and implements local Hebbian synaptic plasticity, eliminating the need for global error propagation. The framework maintains two neuron populations (value and error neurons) that iteratively optimize a variational free energy objective. Experimental results demonstrate that PC matches BP performance on standard image classification and compression tasks while using fewer generative parameters, though at significantly higher computational cost due to its iterative inference phase.

## Method Summary
The PC framework implements a hierarchical generative model with variational inference. During training, neural activity (variational parameters ϕ) iteratively converges to equilibrium by maximizing the Negative Free Energy (NFE), while weights (generative parameters Θ) update using local Hebbian rules derived from NFE gradients. The method uses a two-phase cycle: (1) inference—clamp inputs/targets and iteratively update ϕ for 10-35 steps until convergence, (2) learning—update Θ using the converged ϕ. The approach assumes Gaussian generative models with Dirac delta variational posteriors, enabling tractable optimization through local gradient computations.

## Key Results
- PC matches BP classification accuracy (~98% MNIST, ~77% CIFAR-10) but requires ~30× more FLOPs
- PC compression autoencoders use only half the generative parameters (326k vs 652k for MNIST) with comparable MSE
- Performance degrades significantly on deep networks (>7 layers) and complex datasets

## Why This Works (Mechanism)

### Mechanism 1: Variational Free Energy as a Tractable Objective
PC transforms intractable Bayesian inference into tractable optimization by bounding the Kullback-Leibler divergence. The Negative Free Energy (NFE) simultaneously lower-bounds the model evidence and upper-bounds the DKL between the true posterior and a variational approximation, allowing the network to minimize surprise by maximizing NFE using only local gradient information. The Dirac delta variational posterior approximation assumes the true posterior is tightly peaked around the mode.

### Mechanism 2: Local Hebbian Synaptic Plasticity via Error-Value Decomposition
Weight updates depend exclusively on pre-synaptic activity (ϕℓ), post-synaptic error (ϵℓ-1), and local Jacobians (f'), eliminating global error propagation. The network maintains value neurons encoding posterior modes and error neurons encoding precision-weighted prediction errors. Weight updates follow: ΔΘℓ ∝ f'(Θℓϕℓ) ⊙ ϵℓ-1 ϕℓᵀ, where all quantities are locally available at the synapse. This assumes a hierarchical Gaussian generative model with mean-field variational factors.

### Mechanism 3: Iterative Inference Phase as Temporal Separation of Timescales
PC separates neural activity optimization (fast timescale) from synaptic weight updates (slow timescale), implementing an Expectation-Maximization algorithm. During inference, variational parameters iteratively converge to equilibrium via gradient ascent on NFE. Only after convergence are generative parameters updated, preventing overfitting to individual noisy stimuli. This assumes the inference phase reaches sufficient equilibrium before weight updates.

## Foundational Learning

- **Variational Inference and the ELBO**: PC is mathematically grounded in VI; understanding how NFE/ELBO bounds the DKL is essential. Quick check: Given a posterior p(x|s) and variational approximation q(x;ϕ), write the decomposition of ln p(s) into ELBO + DKL(q∥p).

- **Entropy, Cross-Entropy, and KL Divergence**: The NFE objective decomposes into entropy and cross-entropy terms; understanding these clarifies what PC optimizes. Quick check: Why is cross-entropy H(p,q) minimized when q matches p, and how does DKL(p∥q) quantify the gap?

- **Matrix Calculus for Quadratic Forms**: All PC update rules derive from gradients of precision-weighted quadratic forms; facility with these derivatives enables implementation. Quick check: Compute ∂/∂x of (x-μ)ᵀΣ⁻¹(x-μ) and ∂/∂μ of the same expression.

## Architecture Onboarding

- **Component map**: Input → Value neurons (ϕℓ) ↔ Error neurons (ϵℓ) → Output, with generative parameters (Θℓ) mapping between hierarchical levels and covariance matrices (Σℓ) providing precision weighting.

- **Critical path**: 1) Initialize network with random Θℓ, 2) For each sample: clamp input/target, 3) Run inference: iterate ϕℓ update for 10-35 steps until convergence, 4) Compute weight gradients using converged ϕ*, 5) Update Θℓ via gradient ascent on NFE, 6) Repeat for multiple epochs.

- **Design tradeoffs**: Biological plausibility vs computational efficiency (30× more FLOPs), parameter efficiency vs inference overhead (2.5× longer training), uncertainty representation vs numerical stability (Σℓ learning risks divergence), scalability vs depth (performance degrades beyond 5-7 layers).

- **Failure signatures**: Gradient explosion when Σℓ diagonal entries approach zero (NaN losses), inference non-convergence (suboptimal weight updates), scalability collapse on deep networks (>7 layers), memory overhead from variational parameters (43k extra for CIFAR-10).

- **First 3 experiments**: 1) MNIST classification with 2-3 layer MLP, 10 inference steps, expect ~98% accuracy within 0.2 p.p. of BP, 2) Compression autoencoder comparison: BP encoder-decoder (652k params) vs PC folded network (326k params) on MNIST, comparable MSE with ~2.5× training time, 3) Depth scaling test: increase FashionMNIST network depth from 3 to 8 layers, identify layer count where PC accuracy drops >2% relative to BP.

## Open Questions the Paper Calls Out

- How can PC be modified to match BP efficiency and performance on large-scale datasets and deep architectures? The conclusion states improving efficiency and performance on large-scale tasks remains an open challenge due to iterative inference overhead.

- How can covariance matrices be learned in PC without violating locality or causing numerical instability? Learning precision involves computing inverses, which requires non-local information and risks divergence when variances approach zero.

- Can PC's local learning rules translate into superior energy efficiency on neuromorphic hardware compared to GPU implementations? While PC is biologically plausible, iterative inference may negate efficiency gains on standard hardware.

## Limitations

- Scalability limitations beyond shallow networks where PC performance degrades significantly compared to BP
- Biological plausibility advantage comes at substantial computational cost (30× more FLOPs)
- Fixed covariance assumption (Σ=Identity) may limit representational capacity for complex data distributions

## Confidence

- **High confidence**: Variational free energy optimization mechanism (explicit mathematical derivation and clear variational inference alignment)
- **Medium confidence**: Local Hebbian updates (clear derivation but implementation details like precision scaling are underspecified)
- **Medium confidence**: Classification performance claims (comparable accuracy shown but lacks statistical significance testing)
- **Low confidence**: Compression parameter efficiency claims (only demonstrated on MNIST without state-of-the-art comparison)

## Next Checks

1. Test PC on CIFAR-100 classification to verify scalability limitations beyond CIFAR-10
2. Implement covariance learning (non-identity Σ) and measure impact on both accuracy and numerical stability
3. Compare PC compression performance against modern autoencoder architectures (VAEs, normalizing flows) using standard metrics like bits-per-pixel