---
ver: rpa2
title: Learning Sequential Decisions from Multiple Sources via Group-Robust Markov
  Decision Processes
arxiv_id: '2602.01825'
source_url: https://arxiv.org/abs/2602.01825
tags:
- robust
- uncertainty
- algorithm
- suboptimality
- offline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of learning robust sequential
  decision-making policies from multi-site offline datasets that share a common structure
  but exhibit heterogeneity. To model cross-site uncertainty, the authors propose
  a group-linear distributionally robust MDP (DRMDP) framework, where all sites share
  a common feature map and the transition kernels and expected reward functions are
  linear in these shared features.
---

# Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes

## Quick Facts
- **arXiv ID**: 2602.01825
- **Source URL**: https://arxiv.org/abs/2602.01825
- **Reference count**: 3
- **Primary result**: Proposes a group-robust DRMDP framework with feature-wise uncertainty sets and pessimism for multi-site offline RL

## Executive Summary
This paper addresses the challenge of learning robust sequential decision-making policies from heterogeneous multi-site offline datasets. The authors propose a group-robust Markov decision process framework that shares a common feature map across sites while allowing site-specific transition and reward parameters. By introducing feature-wise (d-rectangular) uncertainty sets and a pessimism-based offline algorithm, they achieve provable suboptimality bounds under robust partial coverage assumptions. The method explicitly handles cross-site uncertainty through row-wise minimization aggregation and data-dependent pessimism penalties.

## Method Summary
The proposed method operates on K sites with shared feature map φ(s,a), where each site k provides N_k offline trajectories. The algorithm performs per-site ridge regression to estimate site-specific parameters, then aggregates via row-wise minimization across sites to form a feature-wise worst-case estimate. A data-dependent pessimism penalty is computed from the diagonals of inverse design matrices. The method includes a cluster-level extension that pools similar sites to improve sample efficiency. The core algorithm uses backward induction with pessimistic value updates, and the theoretical analysis provides suboptimality bounds under a robust partial coverage assumption.

## Key Results
- Introduces feature-wise (d-rectangular) uncertainty sets that preserve tractable robust Bellman recursions
- Proposes a pessimism-based offline algorithm with ridge regression and row-min aggregation
- Proves suboptimality bounds under robust partial coverage assumption
- Demonstrates improved performance over naive pooling in heterogeneous multi-site settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Feature-wise (d-rectangular) uncertainty sets enable tractable robust planning by avoiding NP-hardness of general non-rectangular robust MDPs.
- **Mechanism**: The framework allows the adversary to select worst-case models independently for each feature dimension, preserving decomposability of Bellman backups for standard dynamic programming.
- **Core assumption**: Transition dynamics and rewards are linear in the shared feature map, and independent feature-wise uncertainty approximates true constraints.
- **Evidence anchors**: Abstract states tractable Bellman recursions are preserved; Section 2.2 shows robust Bellman operator maintains linear structure via w_h.
- **Break condition**: If underlying MDP dynamics are highly non-linear or feature correlations are essential, the relaxation may yield overly conservative or invalid policies.

### Mechanism 2
- **Claim**: Row-min aggregation across sites provides robust performance against worst-case site heterogeneity.
- **Mechanism**: Instead of averaging or pooling, the algorithm computes site-specific ridge regression estimates and takes minimum value for each feature dimension, optimizing for worst-case site configuration.
- **Core assumption**: Shared feature space exists where worst-case combination of site parameters represents plausible adversary boundary.
- **Evidence anchors**: Abstract mentions row-wise minimization aggregation; Section 2.3 defines ŵ_h = rowmin{ν̂_h^1, ..., ν̂_h^K}.
- **Break condition**: If optimal policy is site-specific and not unimodal across group, row-min aggregation degrades to weakest site logic.

### Mechanism 3
- **Claim**: Data-dependent pessimism penalty mitigates spurious correlation and overestimation errors in offline RL.
- **Mechanism**: The algorithm penalizes Q-value updates by Γ_h(s,a) = β⟨φ(s,a), m_h⟩, where m_h captures maximum uncertainty across sites from inverse covariance diagonals.
- **Core assumption**: Robust Partial Coverage assumption holds - offline datasets sufficiently cover state-action space induced by robust optimal policy.
- **Evidence anchors**: Abstract mentions data-dependent pessimism penalty from inverse design matrix diagonals; Section 4.3 shows failure without penalty.
- **Break condition**: If offline data coverage is extremely poor, penalty dominates value estimates, leading to overly conservative policies.

## Foundational Learning

- **Concept**: Linear Markov Decision Processes (Linear MDPs)
  - **Why needed here**: The entire framework rests on transitions and rewards being linear functions of feature map φ(s,a).
  - **Quick check question**: Can you verify if the transition matrix P(s'|s,a) can be decomposed into φ(s,a)^T μ(s') for some measure μ?

- **Concept**: Distributionally Robust Optimization (DRO)
  - **Why needed here**: Standard RL minimizes expected loss; this paper uses DRO to minimize worst-case expected loss over uncertainty set of site distributions.
  - **Quick check question**: How does the "uncertainty set" U_h in this paper differ from a standard confidence interval used in typical exploration?

- **Concept**: Offline RL & Pessimism
  - **Why needed here**: In offline settings, agent cannot explore; pessimism principle penalizes uncertain values to prevent exploiting erroneously high-value actions.
  - **Quick check question**: Why does the algorithm penalize Bellman update specifically using diagonals of inverse design matrix, rather than full matrix norm?

## Architecture Onboarding

- **Component map**: Input -> Site Estimators -> Robust Aggregator -> Value Updater
- **Critical path**: Calculation of site-level covariance matrices Λ^k_h and inversion to find (Λ^k_h)^{-1}, which directly dictate pessimism penalty magnitude and policy robustness.
- **Design tradeoffs**:
  - Site-wise vs. Cluster: Pooling similar sites reduces variance but introduces bias if within-cluster heterogeneity is high; site-wise processing has zero bias but high variance if local N_k is small.
  - Conservativeness (β): Higher β ensures safety but lowers average reward by over-penalizing plausible good actions.
- **Failure signatures**:
  - Singularity/Instability: If per-site data is too small, Λ^k_h may be near-singular, causing penalty term to explode and kill Q-values.
  - Cold Start on Features: If a feature is active in optimal path but missing in all site datasets, algorithm cannot learn it; uncertainty penalty will be maximal.
- **First 3 experiments**:
  1. Vary N_min: Plot Suboptimality vs. Minimum Sample Size on log-log scale to verify O(1/√N_min) convergence rate.
  2. Ablate Pessimism: Run with penalty scaling c=0 vs. c>0 on "hard" instance with trap actions to confirm greedy approach fails.
  3. Heterogeneity Stress Test: Compare Algorithm 1 (Site-wise) vs. Naive Pooling vs. Cluster-level as site heterogeneity increases.

## Open Questions the Paper Calls Out
- Can representation learning be integrated into this framework to automatically learn the feature map and mitigate model misspecification bias?
- Are there tighter approximations for the non-rectangular cross-site convex hull that reduce conservatism while preserving computational tractability?
- How sensitive is the cluster-level extension to errors or noise in prior knowledge regarding site similarity and cluster assignments?

## Limitations
- The theoretical guarantees depend on the "Robust Partial Coverage" assumption, which requires sufficient coverage of the state-action space induced by the robust optimal policy.
- The specific mechanism for generating heterogeneous Beta parameters and the feature map φ(s,a) remains underspecified, potentially affecting reproducibility.
- The feature-wise uncertainty set may be overly conservative for problems where feature correlations are essential to safety constraints.

## Confidence

- **High Confidence**: The core theoretical framework (linear MDP + d-rectangular uncertainty + ridge regression) is mathematically sound with well-established convergence rates.
- **Medium Confidence**: The practical efficacy of feature-wise aggregation over naive pooling is convincing but may not generalize to all heterogeneity types.
- **Medium Confidence**: The pessimism penalty based on inverse design matrix diagonals is novel but not benchmarked against alternative uncertainty quantification methods.

## Next Checks

1. **Assumption Stress Test**: Systematically vary distributional shift between behavior policy and robust optimal policy to identify when "Robust Partial Coverage" assumption breaks down.

2. **Penalty Ablation Study**: Compare diagonal-based pessimism penalty to alternative uncertainty measures (trace of inverse covariance, ensemble disagreement) to determine optimal method.

3. **Real-World Transferability**: Apply method to real-world multi-site dataset (healthcare or robotics) with known heterogeneity to validate theoretical robustness translates to practical gains.