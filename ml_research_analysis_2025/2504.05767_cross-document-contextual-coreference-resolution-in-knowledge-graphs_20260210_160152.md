---
ver: rpa2
title: Cross-Document Contextual Coreference Resolution in Knowledge Graphs
arxiv_id: '2504.05767'
source_url: https://arxiv.org/abs/2504.05767
tags:
- resolution
- coreference
- knowledge
- contextual
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of resolving coreferences across
  multiple documents in knowledge graphs. The authors propose a novel method that
  utilizes a dynamic linking mechanism to connect textual mentions to structured knowledge
  representations.
---

# Cross-Document Contextual Coreference Resolution in Knowledge Graphs

## Quick Facts
- arXiv ID: 2504.05767
- Source URL: https://arxiv.org/abs/2504.05767
- Reference count: 5
- Primary result: Achieved 73.9 F1 on CoNLL-2012 and 80.2 precision on ThaiCoref using Llama-3 embeddings

## Executive Summary
This paper addresses the challenge of resolving coreferences across multiple documents in knowledge graphs. The authors propose a novel method that utilizes a dynamic linking mechanism to connect textual mentions to structured knowledge representations. By leveraging contextual embeddings and graph-based inference techniques, the approach effectively captures relationships and interactions among entities, enhancing the accuracy of coreference resolution. Evaluations on benchmark datasets demonstrate significant improvements over traditional methods, with the proposed technique achieving substantial gains in both precision and recall metrics.

## Method Summary
The method combines contextual embeddings with knowledge graph-based inference to resolve cross-document coreferences. It extracts textual mentions from documents, computes similarity scores between mentions and knowledge graph entities, and applies dynamic linking via argmax selection. A graph-based message passing mechanism refines entity representations through iterative neighbor aggregation, followed by threshold-based filtering to determine final coreference relations. The approach uses Llama-3 and GPT-3.5 models fine-tuned with learning rate 3e-5 for 10 epochs with batch size 32.

## Key Results
- Achieved 73.9 F1 score on CoNLL-2012 benchmark
- Reached 80.2 precision on ThaiCoref dataset
- Outperformed baseline methods CorefUD and ThaiCoref across multiple evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Linking via Contextual Similarity
Linking textual mentions to knowledge graph entities through similarity scoring improves cross-document coreference identification. For each mention mi, compute similarity S(mi, ej) = f(mi, ej, G) using contextual embeddings derived from both the mention and knowledge graph context. Select the entity via argmax over candidates. The core assumption is that contextual embeddings from knowledge graphs capture semantic relationships that disambiguate mentions across documents better than text-only approaches.

### Mechanism 2: Graph-Based Message Passing for Representation Refinement
Iterative message passing through knowledge graph neighbors refines entity embeddings for better coreference decisions. Update entity embeddings via h_i^(t+1) = Σ W·h_j^(t) + b over neighbors N(vi). Continue until convergence or fixed iterations. Final decision uses relevance scoring R(hi, hj). The core assumption is that entity relationships in the KG encode useful inductive bias that propagates through connected nodes.

### Mechanism 3: Threshold-Based Coreference Filtering
Applying a similarity threshold θ filters weak links, improving precision in resolved coreference relations. Define resolved relations as R = {(ei, ej) | S(mi, ei) > θ}. Only high-confidence links survive. The core assumption is that similarity scores are calibrated such that a global threshold meaningfully separates true from false coreferences.

## Foundational Learning

- Concept: **Coreference Resolution**
  - Why needed here: The core task—determining whether different textual mentions refer to the same entity across documents.
  - Quick check question: Given "Apple announced earnings" and "The company released a new product," can you identify what "The company" refers to?

- Concept: **Knowledge Graph Embeddings**
  - Why needed here: Entities and relationships must be represented numerically for similarity computation and message passing.
  - Quick check question: How would you represent (Entity: Paris, Relation: capital_of, Entity: France) as learnable vectors?

- Concept: **Message Passing / Graph Neural Networks**
  - Why needed here: The paper's inference mechanism relies on iterative neighbor aggregation to refine entity representations.
  - Quick check question: In a graph with nodes A-B-C, what information does node A receive after two message-passing steps?

## Architecture Onboarding

- Component map: Mention Extractor -> Embedding Module -> Dynamic Linker -> Graph Inference Engine -> Coreference Decider
- Critical path: Mention extraction → embedding → linking → graph propagation → threshold decision
- Design tradeoffs:
  - Larger KG improves coverage but increases inference latency
  - Higher threshold improves precision at recall cost
  - More message-passing iterations improve refinement but scale quadratically with neighbors
- Failure signatures:
  - Low recall on sparse mentions → threshold too aggressive or KG missing entities
  - High latency → unbounded message passing or large candidate sets
  - Cross-document inconsistencies → KG lacks inter-document relation types
- First 3 experiments:
  1. Replicate Llama-3 on CoNLL-2012 with default θ; verify ~73.9 F1 matches Table 1.
  2. Ablate message passing (set iterations=0) to isolate dynamic linking contribution.
  3. Sweep θ ∈ [0.3, 0.5, 0.7, 0.9] on SP-10K to characterize precision-recall tradeoff curve.

## Open Questions the Paper Calls Out

### Open Question 1
How can the computational complexity of the graph-based inference mechanism be reduced to facilitate scaling to datasets significantly larger than those currently tested? The authors state that "the computational complexity involved in graph-based inference, which could become a bottleneck when scaling to larger datasets."

### Open Question 2
To what extent does the performance of the dynamic linking mechanism degrade when processing documents containing sparse or poorly defined entity mentions? The paper notes that "the effectiveness of the dynamic linking mechanism may diminish in cases where the entity mentions are sparse or poorly defined in the text."

### Open Question 3
What alternative strategies are required to ensure the model generalizes effectively to document types or domains that differ significantly from the training data? The authors highlight that "if the training data is limited in diversity or context, the model may struggle to generalize across various document types or domains."

## Limitations
- Performance degrades significantly when entity mentions are sparse or knowledge graph entities lack contextual information
- Computational costs scale with graph size and neighbor count during message passing
- Threshold-based filtering requires careful calibration and may not generalize across domains

## Confidence
- Mechanism 1 (Dynamic Linking): High - Well-specified with clear equations and empirical validation
- Mechanism 2 (Graph Inference): Medium - Core concept is clear but implementation details (iteration count, convergence criteria) are unspecified
- Mechanism 3 (Threshold Filtering): Low - Only conceptually described without detailed calibration methodology

## Next Checks
1. Conduct ablation studies isolating each mechanism's contribution to verify the claimed performance improvements
2. Test the method on datasets with intentionally sparse mentions to characterize the lower bound of practical applicability
3. Evaluate computational scaling by measuring inference time on progressively larger knowledge graphs to establish practical limits