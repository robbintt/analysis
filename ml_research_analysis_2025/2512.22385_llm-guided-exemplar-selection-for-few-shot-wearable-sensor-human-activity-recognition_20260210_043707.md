---
ver: rpa2
title: LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition
arxiv_id: '2512.22385'
source_url: https://arxiv.org/abs/2512.22385
tags:
- activity
- exemplar
- selection
- semantic
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study proposes an LLM-Guided Exemplar Selection framework for
  few-shot wearable-sensor human activity recognition. It integrates semantic reasoning
  from LLMs with geometric and structural cues to improve exemplar selection, addressing
  limitations of purely geometric methods.
---

# LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition

## Quick Facts
- arXiv ID: 2512.22385
- Source URL: https://arxiv.org/abs/2512.22385
- Authors: Elsen Ronando; Sozo Inoue
- Reference count: 40
- Primary result: Achieves 88.78% macro F1-score on UCI-HAR using LLM-guided exemplar selection for few-shot HAR

## Executive Summary
This study introduces an LLM-Guided Exemplar Selection framework that enhances few-shot human activity recognition from wearable sensors by integrating semantic reasoning from large language models with geometric and structural cues. The approach addresses limitations of purely geometric exemplar selection methods by leveraging LLM-generated semantic priors to identify representative and diverse samples. Evaluated on the UCI-HAR dataset, the framework demonstrates significant performance improvements over traditional baselines while maintaining computational efficiency, making it particularly valuable for scenarios with limited labeled data.

## Method Summary
The framework combines semantic reasoning from GPT-4 with geometric and structural cues for exemplar selection in few-shot HAR. It uses LLM-generated semantic priors to understand activity relationships, PageRank centrality to assess sample importance, and facility-location optimization to ensure diversity. The method addresses limitations of purely geometric approaches by incorporating semantic understanding of activities, enabling more effective selection of representative samples when labeled data is scarce. The approach maintains computational efficiency while achieving superior performance compared to random sampling and k-center baselines.

## Key Results
- Achieves 88.78% macro F1-score on UCI-HAR dataset
- Outperforms random sampling and k-center baselines
- Ablation studies confirm complementary roles of semantic priors, PageRank centrality, and facility-location optimization

## Why This Works (Mechanism)
The framework works by bridging the gap between raw sensor data and semantic understanding of human activities. LLMs provide rich semantic priors about activity relationships that geometric methods cannot capture, while PageRank centrality identifies structurally important samples within the data manifold. Facility-location optimization ensures selected exemplars are both representative and diverse. This multi-faceted approach compensates for the limitations of each individual component, creating a synergistic selection process that captures both the geometric structure of the data and the semantic relationships between activities.

## Foundational Learning

**Wearable-Sensor HAR**: Activity recognition using accelerometer/gyroscope data from devices like smartwatches.
- Why needed: Core application domain for the proposed framework
- Quick check: Understanding how sensor data captures movement patterns

**Few-shot Learning**: Learning from very limited labeled examples (typically 1-10 per class).
- Why needed: Framework specifically addresses scenarios with scarce labeled data
- Quick check: Knowing how models generalize from minimal examples

**Large Language Models**: AI models trained on vast text corpora that can understand and generate human language.
- Why needed: Provide semantic understanding of activity relationships
- Quick check: Familiarity with GPT-4 and semantic reasoning capabilities

**Graph Centrality Measures**: Metrics that identify important nodes in network structures.
- Why needed: PageRank centrality assesses sample importance in data manifold
- Quick check: Understanding how centrality relates to representativeness

## Architecture Onboarding

**Component Map**: Sensor Data -> Feature Extraction -> LLM Semantic Analysis -> PageRank Scoring -> Facility-Location Optimization -> Selected Exemplars -> Classification Model

**Critical Path**: The exemplar selection pipeline (sensor data through facility-location optimization) is the critical path, as it directly determines which samples are used for training the final classifier.

**Design Tradeoffs**: 
- Semantic reasoning provides rich priors but introduces LLM dependency and potential cost
- PageRank centrality adds structural insight but requires graph construction
- Facility-location optimization ensures diversity but adds computational complexity

**Failure Signatures**:
- Poor semantic priors from LLM lead to suboptimal exemplar selection
- Over-reliance on geometric structure without semantic context
- Insufficient diversity in selected exemplars causing overfitting

**First Experiments**:
1. Compare exemplar selection quality using only semantic vs. only geometric methods
2. Test framework with different numbers of selected exemplars (5, 10, 15)
3. Evaluate performance across different activity categories in UCI-HAR

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions in the provided content.

## Limitations

- Evaluated only on UCI-HAR dataset, limiting generalizability to other HAR domains
- Reliance on GPT-4 introduces potential cost and accessibility barriers
- Computational overhead from LLM inference not explicitly quantified
- Semantic priors may not accurately reflect relationships for specialized activities

## Confidence

**Major Claims and Confidence Assessment**

| Claim | Confidence |
|-------|------------|
| LLM-guided semantic reasoning significantly improves exemplar selection (88.78% macro F1) | High |
| Framework is robust under limited labeled data | Medium |
| Approach adapts to different activity sets | Low |

## Next Checks

1. Evaluate framework performance on multiple HAR datasets (Opportunity, PAMAP2) to assess cross-dataset generalization

2. Conduct controlled experiments varying the number of labeled examples (1-shot, 5-shot, 10-shot) to quantify robustness under different data scarcity levels

3. Measure and report actual computational overhead from LLM inference (latency, API costs) during exemplar selection to validate efficiency claims