---
ver: rpa2
title: Semi-supervised CAPP Transformer Learning via Pseudo-labeling
arxiv_id: '2602.01419'
source_url: https://arxiv.org/abs/2602.01419
tags:
- data
- transformer
- capp
- oracle
- manufacturing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a semi-supervised learning approach for transformer-based
  high-level Computer-Aided Process Planning (CAPP), addressing data scarcity in industrial
  settings. The method uses a learned oracle to filter and validate model-generated
  sequences, which are then incorporated into retraining to improve generalization
  without manual labeling.
---

# Semi-supervised CAPP Transformer Learning via Pseudo-labeling

## Quick Facts
- arXiv ID: 2602.01419
- Source URL: https://arxiv.org/abs/2602.01419
- Reference count: 23
- Primary result: Oracle-filtered pseudo-labeling improves transformer-based CAPP accuracy, especially in low-resource settings (up to 11% gain for 1% training data)

## Executive Summary
This work introduces a semi-supervised learning approach for transformer-based high-level Computer-Aided Process Planning (CAPP), addressing data scarcity in industrial settings. The method uses a learned oracle to filter and validate model-generated sequences, which are then incorporated into retraining to improve generalization without manual labeling. Experiments on small-scale datasets with simulated ground truth show consistent accuracy gains over baseline and random augmentation, with the strongest improvements in low-resource settings (up to 11% increase for 1% training data). The approach demonstrates practical potential for data-scarce manufacturing environments by enabling automatic processing of new data and selective augmentation to reduce error propagation.

## Method Summary
The method trains a GPT-2 style decoder-only transformer on labeled CAPP data, then extracts 132 features from prediction logits (including confidence patterns, entropy, perplexity, probability margins, Gini coefficients, KL divergence, and temporal dynamics). An XGBoost oracle classifier is trained on these features to distinguish correct from incorrect sequences. The oracle filters predictions on unseen parts, and validated sequences are added to the training set for one-shot retraining. The approach is evaluated across four training splits (1%, 2.5%, 5%, 10%) and compared against baseline retraining and random augmentation.

## Key Results
- Oracle-filtered augmentation consistently outperforms baseline retraining and random augmentation
- Largest accuracy gains occur in low-resource settings (up to 11% for 1% training data, 5% for 2.5%, 1.6% for 5%, 0.5% for 10%)
- Oracle accuracy ranges from 80% (capp1) to 99.54% (capp10), demonstrating strong filtering capability
- Method shows practical potential for data-scarce manufacturing environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: An oracle trained on transformer behavior data can identify correct predictions on unseen parts better than relying on model confidence alone.
- Mechanism: The oracle learns from labeled examples (training and validation sets) to recognize patterns in transformer outputs that distinguish correct from incorrect sequences. It extracts 132 features including confidence patterns, entropy measures, probability margins, and temporal dynamics from step-wise logits, then uses these to classify predictions as likely correct or incorrect.
- Core assumption: Patterns in model behavior (confidence, uncertainty, decision quality) during generation correlate with output correctness in ways that transfer to unseen inputs.
- Evidence anchors:
  - [abstract] "An oracle, trained on available transformer behaviour data, filters correct predictions from unseen parts"
  - [section 2.2] "Rather than relying solely on the transformer's own confidence, the oracle provides an external judgment trained on labeled examples"
  - [corpus] Weak direct corpus support; related work on pseudo-labeling (Goyal et al., Zelikman et al.) uses confidence filtering rather than learned oracles.
- Break condition: If oracle accuracy drops significantly on out-of-distribution parts, filtered sequences may introduce systematic errors. The paper reports oracle accuracy ranging from 80% (capp1) to 99.54% (capp10), suggesting performance depends on base model quality.

### Mechanism 2
- Claim: Selective augmentation via oracle filtering improves retraining more than random augmentation or retraining alone.
- Mechanism: By adding only sequences the oracle judges correct, the augmented training set expands coverage of the input distribution while minimizing label noise. This contrasts with random augmentation, which may include incorrect pseudo-labels that degrade learning.
- Core assumption: The oracle's false positive rate (incorrect sequences labeled as correct) is sufficiently low that net information gain outweighs noise introduced.
- Evidence anchors:
  - [abstract] "consistent accuracy gains over baseline and random augmentation"
  - [section 3, Results] "Random and oracle-based augmentation outperform retraining without additional data... with the oracle consistently yielding the best results"
  - [corpus] Semi-supervised regression work (arxiv:2510.15266) notes pseudo-labeling effectiveness depends on filtering quality; noisy labels can degrade models.
- Break condition: If oracle precision is low, incorrect pseudo-labels propagate errors. The paper does not report precision/recall breakdowns, only overall oracle accuracy.

### Mechanism 3
- Claim: Low-resource settings benefit more from oracle-filtered augmentation than high-resource settings.
- Mechanism: Weaker baseline models have poorer coverage of the input distribution. Augmentation with correct pseudo-labels fills gaps more impactfully than for models already near saturation.
- Core assumption: The relative gain from additional correct training examples diminishes as the base model approaches its capacity-limited performance ceiling.
- Evidence anchors:
  - [abstract] "strongest improvements in low-resource settings (up to 11% increase for 1% training data)"
  - [section 3, Results] "Accuracy gains are most pronounced in low-resource settings: about 11% for capp1, 5% for capp2.5, 1.6% for capp5, and 0.5% for capp10"
  - [corpus] Semi-supervised masked autoencoder work (arxiv:2601.20072) similarly shows largest gains when labeled data is scarce.
- Break condition: If the base model is too weak to generate any correct predictions on unseen data, the oracle has nothing valid to select. Assumption: some correct predictions exist even in low-resource regimes.

## Foundational Learning

- Concept: **Autoregressive sequence generation with transformers**
  - Why needed here: The CAPP transformer generates process plans token-by-token conditioned on part encodings; understanding how logits and probabilities flow through generation is essential for feature extraction.
  - Quick check question: Given a sequence of logits L = [l₁, l₂, ..., lₜ], can you explain how softmax converts these to probabilities and how autoregressive decoding uses previous tokens to condition next predictions?

- Concept: **Pseudo-labeling and semi-supervised learning**
  - Why needed here: The core method relies on using model predictions as training data; understanding error propagation risks in naive approaches motivates why oracle filtering matters.
  - Quick check question: Why might adding all high-confidence predictions to training data still introduce harmful label noise?

- Concept: **Binary classification evaluation (accuracy, precision, recall)**
  - Why needed here: The oracle is a binary classifier; its accuracy affects augmentation quality. The paper reports only aggregate accuracy—understanding what this hides (class imbalance, precision vs. recall) is critical for deployment.
  - Quick check question: If an oracle has 90% accuracy but 50% precision on the positive class, what happens when you retrain on its "correct" predictions?

## Architecture Onboarding

- Component map:
  - **CAPP Transformer**: GPT-2 style decoder-only transformer that takes tokenized part encodings and generates process sequences autoregressively.
  - **Feature Extraction Pipeline**: Collects step-wise logits from transformer, computes 132 features across categories (confidence patterns, uncertainty quantification, decision quality, distribution properties, temporal dynamics, sequence-level patterns, padded sequences).
  - **Oracle Classifier**: XGBoost binary classifier trained to predict whether a generated sequence is correct based on extracted features.
  - **Augmentation & Retraining Loop**: Filters predictions via oracle, adds validated sequences to training set, retrains transformer once.

- Critical path: Train transformer on labeled data → Extract features from predictions on validation data → Train oracle on features with correctness labels → Generate predictions on unseen parts → Extract features → Oracle filters → Augment training set → Retrain transformer.

- Design tradeoffs:
  - Oracle complexity vs. interpretability: XGBoost chosen for classification; authors note other classifiers could work, but interpretability of feature importance may be lost with more complex models.
  - One-shot retraining vs. iterative: Paper uses single retraining; iterative pseudo-labeling could amplify gains or errors depending on oracle reliability.
  - Feature dimensionality: 132 features may include redundant or noisy signals; feature selection not explored.

- Failure signatures:
  - Oracle accuracy drops sharply on out-of-distribution parts (e.g., novel geometries not represented in training).
  - Retrained transformer performance degrades, suggesting pseudo-label noise outweighs signal.
  - High oracle accuracy but low transformer improvement suggests features don't capture correctness-relevant patterns (overfitting to training behavior).

- First 3 experiments:
  1. **Baseline reproduction**: Train CAPP transformer on capp1 (1% data), measure sequence accuracy. Retrain on same data (no augmentation) to quantify retraining-only gains.
  2. **Oracle training and validation**: Extract features from transformer predictions, train XGBoost oracle with train/validation split, measure oracle accuracy on held-out test predictions. Check precision and recall separately.
  3. **Controlled augmentation comparison**: For each data regime (1%, 2.5%, 5%, 10%), run three conditions: (a) retrain baseline, (b) random augmentation with N sequences, (c) oracle-filtered augmentation with N sequences. Compare sequence accuracy to replicate the paper's Figure 2 trend.

## Open Questions the Paper Calls Out
- **Open Question 1**: What alternative oracle architectures or feature extraction approaches would improve filtering accuracy and downstream CAPP transformer performance? The conclusion states "Future work will explore alternative oracle designs."
- **Open Question 2**: Would iterative pseudo-labeling across multiple retraining cycles compound improvements or amplify error propagation? The methodology uses only one-shot retraining, but self-training literature suggests iterative refinement may help—or hurt if oracle errors accumulate.
- **Open Question 3**: How does oracle training data overlap with transformer training data affect oracle bias and generalization? The oracle is trained on "the transformer's training and validation data," creating potential circularity where the oracle learns to replicate transformer errors rather than independently judge correctness.

## Limitations
- **Dataset transparency**: Core experimental results depend on a CAPP dataset with part encodings and process sequences generated via rules-based algorithm, but exact data size, vocabulary, tokenization scheme, and part encoding format remain unspecified.
- **Feature engineering opacity**: The 132 features extracted from logits lack detailed formulas or implementation guidance, creating ambiguity in replication.
- **Oracle calibration**: While oracle accuracy is reported, precision and recall metrics are absent, obscuring the false positive rate critical for understanding whether noise in pseudo-labels undermines gains.

## Confidence
- **High Confidence**: Oracle-filtered augmentation outperforms baseline retraining in controlled experiments. This is directly supported by experimental results and is internally consistent.
- **Medium Confidence**: Oracle-filtered augmentation outperforms random augmentation. While results show this trend, the mechanism depends on dataset specifics and oracle calibration details not fully specified.
- **Medium Confidence**: Largest gains occur in low-resource settings (up to 11% for 1% data). This is supported by results, but assumes oracle maintains sufficient accuracy even with weaker base models.
- **Low Confidence**: Practical potential for data-scarce manufacturing environments. This extrapolates from simulated experiments to real-world deployment without validation on actual industrial data.

## Next Checks
1. **Oracle precision validation**: Reproduce oracle training and evaluate precision and recall separately on validation set. Confirm that false positive rate is sufficiently low to justify using oracle-filtered predictions for retraining.
2. **Feature robustness check**: Systematically vary feature extraction parameters (e.g., normalization, padding) and measure impact on oracle accuracy. Identify which feature subsets drive performance to assess redundancy and noise.
3. **Iterative vs. one-shot comparison**: Implement iterative pseudo-labeling (retrain → regenerate → filter → augment → retrain) and compare final accuracy against one-shot retraining to determine if gains compound or degrade over cycles.