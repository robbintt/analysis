---
ver: rpa2
title: 'CCS: Controllable and Constrained Sampling with Diffusion Models via Initial
  Noise Perturbation'
arxiv_id: '2502.04670'
source_url: https://arxiv.org/abs/2502.04670
tags:
- diffusion
- sampling
- noise
- target
- perturbation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of controllable and constrained
  sampling from diffusion models, aiming to generate samples that match specific statistical
  properties while maintaining high sample quality. The key insight is that perturbations
  to the initial noise in diffusion models lead to approximately linear changes in
  the generated samples.
---

# CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation

## Quick Facts
- arXiv ID: 2502.04670
- Source URL: https://arxiv.org/abs/2502.04670
- Authors: Bowen Song; Zecheng Zhang; Zhaoxu Luo; Jason Hu; Wei Yuan; Jing Jia; Zhengxu Tang; Guanyang Wang; Liyue Shen
- Reference count: 28
- One-line primary result: Demonstrates that perturbing initial noise in diffusion models leads to approximately linear changes in generated samples, enabling controlled sampling with desired statistical properties.

## Executive Summary
This paper addresses the problem of controllable and constrained sampling from diffusion models, aiming to generate samples that match specific statistical properties while maintaining high sample quality. The key insight is that perturbations to the initial noise in diffusion models lead to approximately linear changes in the generated samples. Based on this observation, the authors propose a novel Controllable and Constrained Sampling (CCS) method that uses spherical interpolation to perturb the initial noise vector. They also develop a controller algorithm that can adjust the perturbation scale to achieve a desired level of diversity while ensuring the sample mean is close to a target image.

## Method Summary
CCS leverages the observation that small perturbations to the initial noise vector in diffusion models result in approximately linear changes in the generated output. The method uses spherical linear interpolation (slerp) to perturb the initial noise while maintaining its norm, avoiding the quality degradation that occurs with simple vector addition. A controller algorithm performs binary search on the perturbation scale to achieve target diversity levels. For latent diffusion models with classifier-free guidance, a partial inversion variant (P-CCS) is introduced to handle the reconstruction error between the original and reconstructed images.

## Key Results
- CCS achieves superior performance in controllability compared to baseline methods while maintaining high image quality and diversity
- The method demonstrates effective control over sample mean and diversity metrics across multiple datasets including FFHQ-256, CIFAR-10, and Celeba-HQ
- CCS shows promise for applications like image editing by allowing precise control over generated sample statistics

## Why This Works (Mechanism)

### Mechanism 1
The relationship between initial noise perturbation scale and the change in generated output is approximately linear in diffusion ODE sampling. Under the assumption of a second-order differentiable score function, a small perturbation λ to the initial noise x_T results in a linearly scaled perturbation γ_0(x_T) to the output x_0. This allows predictable control over output diversity by scaling input noise.

### Mechanism 2
Spherical interpolation (slerp) preserves sample quality by keeping the perturbed noise vector on the high-probability hypersphere. Standard Gaussian vectors concentrate on a hypersphere of radius √d, and slerp maintains this norm while introducing controlled variation, unlike simple addition which pushes the vector off the sphere.

### Mechanism 3
A binary search controller can precisely tune the perturbation scale (C_0) to achieve a target statistical property. Because of the linear response, diversity scales predictably with the angle C_0, allowing the controller to sample batches, measure MSE, and adjust C_0 until the target is reached.

## Foundational Learning

- **DDIM (Denoising Diffusion Implicit Models) & Probability Flow ODEs**: The linearity claim relies on the deterministic nature of the ODE formulation. The deterministic backward process maps a specific noise vector x_T to a specific image x_0 deterministically.
  - Quick check: Does the linearity claim hold if you use a stochastic DDPM sampler? (Hint: Check Section 3.1 regarding the deterministic backward process).

- **Spherical Linear Interpolation (Slerp)**: This geometric operation perturbs noise while maintaining constant velocity along the hypersphere. It differs from standard vector addition by preserving the norm of the original vector.
  - Quick check: Why does simple linear interpolation (ax + by) between two equal-norm vectors potentially degrade diffusion sample quality?

- **Gaussian Concentration of Measure**: In high dimensions, Gaussian distribution mass concentrates near the surface of the hypersphere rather than the center. The diffusion model expects inputs from a specific radius, and deviating from this moves the input into "out-of-distribution" territory.
  - Quick check: In high dimensions (e.g., d=50,000), is the Gaussian distribution mass concentrated in the center of the ball or near the surface?

## Architecture Onboarding

- Component map: Inverter (image → noise) -> Perturber (slerp on noise) -> Controller (binary search) -> Sampler (noise → image)
- Critical path: The Inverter. For pixel-space models, exact inversion is possible. For Latent Diffusion, exact inversion fails due to CFG and autoencoder errors, requiring P-CCS with intermediate timestep t0=45.
- Design tradeoffs: Exactness vs. Diversity (increasing C_0 increases diversity but moves samples further from target mean); Speed vs. Stability (controller requires multiple sampling iterations)
- Failure signatures: Blurry/Noisy Mean (caused by using linear addition instead of Spherical Interpolation); Inversion Drift (in conditional models, full inversion results in reconstructed target not matching original)
- First 3 experiments: 1) Validate Linearity by plotting L2 distance vs sin(C_0) for R^2 > 0.95; 2) Ablation on Interpolation comparing PSNR of sample mean; 3) Controller Accuracy testing convergence to target rMSE within tolerance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- The theoretical framework relies on strong assumptions about score function differentiability that may not hold universally
- Spherical interpolation assumes the original noise vector lies on a hypersphere, which may not be strictly true for all diffusion implementations
- The controller algorithm requires multiple sampling iterations, making it computationally expensive for real-time applications

## Confidence
- High Confidence: Empirical demonstration of linearity between input noise perturbation and output diversity across multiple datasets
- Medium Confidence: Theoretical proofs regarding spherical interpolation preserving sample quality, limited by assumptions about Gaussian concentration
- Medium Confidence: Controller algorithm's ability to achieve target diversity levels, with some variability in convergence speed

## Next Checks
1. Test linearity claim with conditional diffusion models across different CFG scales to identify where the linear relationship breaks down
2. Evaluate spherical interpolation's quality preservation by measuring FID scores when generating diverse samples versus target images
3. Benchmark controller convergence time and accuracy across different target diversity levels and model architectures to establish robustness boundaries