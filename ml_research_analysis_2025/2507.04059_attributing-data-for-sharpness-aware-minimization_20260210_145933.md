---
ver: rpa2
title: Attributing Data for Sharpness-Aware Minimization
arxiv_id: '2507.04059'
source_url: https://arxiv.org/abs/2507.04059
tags:
- data
- influence
- training
- sam-hif
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper develops data attribution methods for Sharpness-Aware
  Minimization (SAM), addressing the challenge of evaluating training data influence
  in SAM''s bilevel optimization structure. The authors propose two novel influence
  function-based approaches: SAM-HIF, which uses Hessian information for a closed-form
  estimation of data influence, and SAM-GIF, which leverages gradient trajectory information
  during training for more accurate and efficient assessment.'
---

# Attributing Data for Sharpness-Aware Minimization

## Quick Facts
- arXiv ID: 2507.04059
- Source URL: https://arxiv.org/abs/2507.04059
- Reference count: 40
- Key outcome: Achieves 94.97% accuracy on CIFAR-10 with 4.89s runtime vs 3516.74s for retraining

## Executive Summary
This paper addresses the challenge of evaluating training data influence in Sharpness-Aware Minimization (SAM) through two novel influence function-based approaches. The authors develop SAM-HIF, which uses Hessian information for closed-form estimation, and SAM-GIF, which leverages gradient trajectory information during training. Both methods significantly reduce computation time compared to retraining while maintaining comparable accuracy. The methods prove effective for identifying mislabeled data, model editing, and enhancing interpretability across four datasets.

## Method Summary
The paper develops data attribution methods for SAM by extending influence functions to handle SAM's bilevel optimization structure. SAM-HIF provides a closed-form estimation using modified Hessian information, while SAM-GIF accumulates gradient contributions across training checkpoints. Both methods approximate leave-one-out retraining without actual retraining. The approaches are validated on CIFAR-10/100, MiniImageNet, and MNIST datasets, demonstrating significant runtime improvements (3500s → 12s) while maintaining accuracy above 94.9%.

## Key Results
- SAM-GIF achieves 94.97% accuracy on CIFAR-10 vs 95.00% for retraining with 4.89s vs 3516.74s runtime
- Both methods reduce computation time from hours to seconds while maintaining comparable accuracy
- SAM-GIF detects over 90% of noisy data at a 40% removal rate
- Methods effective for identifying mislabeled data, model editing, and enhancing interpretability across four datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAM-HIF approximates leave-one-out retrained model parameters for SAM using a closed-form Hessian-based expression
- Mechanism: Derives modified influence function incorporating both direct influence on model parameters and indirect influence through perturbation changes using SAM-HIF(x_k, y_k) = -(H_ω + H_ω · dê(ω*)/dω)^{-1} · ∇L^S_k(ω* + ê(ω*))
- Core assumption: Taylor expansion around optimal parameters remains valid; perturbation gradient dê/dω can be approximated from Equation (6)'s closed-form
- Evidence anchors: [abstract] comprehensive closed-form measure; [section 4.1, Theorem 4.5] complete derivation with perturbation-coupled Hessian term
- Break condition: When optimal perturbation ê(ω) cannot be approximated well by Equation (6), or when Hessian inversion becomes numerically unstable

### Mechanism 2
- Claim: SAM-GIF provides more accurate and efficient influence estimation by leveraging gradient trajectory information from checkpoints
- Mechanism: Accumulates influence by summing gradient contributions across training steps: SAM-GIF_{SGD}(x_k, y_k) = Σ_{t=0}^{T-1} η_t B_{k,t} ∇_ω L^S_k(ω_t + ê(ω_t))
- Core assumption: Gradient trajectory checkpoints adequately capture training dynamics; omitted Hessian term in derivation has negligible impact
- Evidence anchors: [abstract] utilizes gradient trajectory information; [section 4.2, Theorem 4.6] complete derivation for SGD setting; [Table 1] 94.97% accuracy vs 95.00% for retrain
- Break condition: When training checkpoints are too sparse, or when SGD batch sampling makes influence estimates too noisy for rarely sampled points

### Mechanism 3
- Claim: Influence Scores derived from SAM-HIF/SAM-GIF can identify valuable vs. harmful training data through validation set performance correlation
- Mechanism: IS(x,y) = Σ_{(x,y)∈D_val} ∇ℓ(x,y;ω*) · IF(x,y) approximates change in validation loss when removing training point
- Core assumption: First-order Taylor approximation of loss change is sufficient; validation set is representative
- Evidence anchors: [section 4.3.2, Theorem 4.8] derivation connecting IF to Influence Score; [Figure 1b] 90%+ noisy data detection at 40% removal rate
- Break condition: When validation set is unrepresentative, or when model is severely overfitted making gradient-based approximations unreliable

## Foundational Learning

- Concept: **Influence Functions (robust statistics)**
  - Why needed here: Core mathematical framework enabling parameter change estimation without retraining; understanding IF_{classic}(z_m) ≈ -H^{-1}·∇ℓ(z_m) is prerequisite for SAM-HIF derivation
  - Quick check question: Can you explain why influence functions avoid retraining by using Hessian-vector products?

- Concept: **Sharpness-Aware Minimization (bilevel optimization)**
  - Why needed here: SAM's inner maximization (finding worst perturbation) and outer minimization create coupled dependencies that break classical IF assumptions; understanding Algorithm 1 is essential
  - Quick check question: Why does SAM's two-step structure (perturbation finding → gradient descent) complicate data attribution?

- Concept: **Neumann Series Approximation**
  - Why needed here: Enables efficient H^{-1}·v computation without explicit Hessian storage; critical for SAM-HIF scalability
  - Quick check question: How does truncating the Neumann series at order J trade accuracy for memory efficiency?

## Architecture Onboarding

- Component map: Input: SAM-trained model ω*, training data S, query point (x_k, y_k) → SAM-HIF Path or SAM-GIF Path → Approximated ω_{-k} ≈ ω* - IF(x_k, y_k)
- Critical path:
  1. Verify SAM training used Algorithm 1 (standard SAM) — other variants may not match derivations
  2. Check checkpoint availability → selects HIF vs GIF path
  3. For GIF: ensure checkpoint granularity (ablation shows 10+ checkpoints improves accuracy to ~0.9497)
  4. For HIF: set Neumann truncation order J (trade-off vs accuracy)
- Design tradeoffs:
  | Method | Accuracy (CIFAR-10) | Runtime | Prerequisites |
  |--------|---------------------|---------|---------------|
  | Retrain | 0.9500 | 3516.74s | None (ground truth) |
  | SAM-HIF (Fast) | 0.9323 | 11.07s | Trained model only |
  | SAM-HIF | 0.9443 | 41.50s | Trained model only |
  | SAM-GIF | 0.9497 | 4.89s | Checkpoints required |
- Failure signatures:
  - SAM-HIF underestimates influence when perturbation gradient dê/dω is misestimated
  - SAM-GIF noisy for low-frequency data points (few B_{k,t}=1 occurrences)
  - Both methods degrade when SAM wasn't actually used (standard SGD training)
  - Influence Score inversion: negative IS but removal hurts → validation set bias
- First 3 experiments:
  1. Sanity check: Compute IS for all training points, remove top-10% most valuable; verify accuracy drop matches retrain baseline (target: <0.02 difference per Table 1)
  2. Noise injection: Corrupt 10% labels, compute IS, remove lowest-IS points; verify 90%+ noise detection at 40% removal (replicate Figure 1b)
  3. Checkpoint ablation: Test SAM-GIF with 3, 5, 10 checkpoints; confirm accuracy converges toward retrain as checkpoints increase (replicate Figure 12a pattern)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the SAM-HIF estimation when the assumption that the gradient sign remains unchanged during data removal is violated?
- Basis: Section 4.1 states approximation of perturbation derivative based on assumption that sign of gradient ∇_w L_S(ω, 0) remains unchanged under removal of one data point
- Why unresolved: Paper relies on this assumption for SAM-HIF derivation but does not provide theoretical analysis or empirical bounds on error when assumption does not hold
- What evidence would resolve it: Theoretical analysis quantifying error bounds relative to gradient sign flips, or empirical evaluations on datasets designed to induce gradient sign instability

### Open Question 2
- Question: What is the theoretical impact on approximation error when omitting the second Hessian term in the SAM-GIF derivation?
- Basis: Section 4.2 notes omission of second Hessian term (Σ H_{t,0} ...) in SAM-GIF derivation to reduce calculation complexity
- Why unresolved: Experiments show SAM-GIF is accurate, but paper does not quantify theoretical trade-off between computational gain and resulting approximation error
- What evidence would resolve it: Theoretical comparison between full gradient-based influence formulation and truncated SAM-GIF, specifically bounding dropped error term

### Open Question 3
- Question: Can the proposed data attribution methods be effectively adapted for adaptive or efficient variants of SAM, such as ASAM or EfficientSAM?
- Basis: Section 2 discusses variants like Adaptive SAM (ASAM) and EfficientSAM, but derivations for SAM-HIF and SAM-GIF are strictly based on canonical SAM formulation
- Why unresolved: ASAM adjusts perturbation region based on weight scale, EfficientSAM uses random perturbations; these changes alter derivatives required for influence functions
- What evidence would resolve it: Derivations of modified influence functions accounting for adaptive calculation of ρ in ASAM or stochastic approximation in EfficientSAM, accompanied by validation experiments

## Limitations
- SAM-HIF relies on accurate Hessian inverse-vector products which remain computationally challenging even with Neumann series approximation
- SAM-GIF's accuracy depends heavily on checkpoint frequency and distribution, with sparse checkpoints potentially missing critical gradient changes
- Both methods inherit limitations from classical influence function theory including sensitivity to Hessian conditioning and the assumption that small perturbations in parameters translate linearly to loss changes

## Confidence
- High Confidence: Runtime improvements (3500s → 12s) and accuracy maintenance (>94.9%) for SAM-GIF on CIFAR-10, as these are directly measured quantities with clear baselines
- Medium Confidence: Effectiveness of Influence Scores for identifying mislabeled data, as experiments show correlation but don't prove causation
- Low Confidence: SAM-HIF approximation quality for leave-one-out retraining, as modified Hessian term H_ω·dê/dω introduces additional uncertainty not fully characterized

## Next Checks
1. **Perturbation Sensitivity Analysis**: Systematically vary SAM's ρ parameter and measure how HIF and GIF accuracy change, establishing conditions under which each method remains reliable
2. **Real-World Noise Detection**: Apply method to dataset with known label errors (e.g., CIFAR-10.1) and measure precision/recall for detecting mislabeled examples across different noise rates
3. **Cross-Dataset Generalization**: Test same trained SAM model on multiple validation sets to quantify how representative Influence Scores are when validation data distribution shifts from training data