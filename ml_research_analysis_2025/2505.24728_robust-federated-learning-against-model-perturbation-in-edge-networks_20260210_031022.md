---
ver: rpa2
title: Robust Federated Learning against Model Perturbation in Edge Networks
arxiv_id: '2505.24728'
source_url: https://arxiv.org/abs/2505.24728
tags:
- perturbations
- smrfl
- local
- perturbation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses robustness of federated learning (FL) under
  non-malicious perturbations (communication noise, quantization, differential privacy)
  in edge networks. Existing methods struggle because perturbations persist throughout
  training and degrade performance.
---

# Robust Federated Learning against Model Perturbation in Edge Networks

## Quick Facts
- arXiv ID: 2505.24728
- Source URL: https://arxiv.org/abs/2505.24728
- Reference count: 18
- Key outcome: SMRFL achieves O(1/√R) convergence rate under perturbations, outperforming FedAvg, Scaffold, and Feddyn on MNIST and CIFAR-10

## Executive Summary
This paper addresses the robustness of federated learning (FL) under non-malicious perturbations (communication noise, quantization, differential privacy) in edge networks. Existing FL methods struggle because perturbations persist throughout training and degrade performance. The authors propose SMRFL, a Sharpness-Aware Minimization-based FL method that encourages convergence to flat minima in the loss landscape, reducing sensitivity to perturbations. SMRFL solves a min-max problem to minimize worst-case loss within a neighborhood of the model parameters. Theoretical analysis shows SMRFL achieves O(1/√R) convergence rate, matching unperturbed FL. Experiments on MNIST and CIFAR-10 with CNN and ResNet18 architectures show SMRFL significantly outperforms FedAvg, Scaffold, and Feddyn under downlink, uplink, and combined perturbation scenarios, achieving higher test accuracy and faster convergence. SMRFL is robust even with non-IID data.

## Method Summary
SMRFL addresses FL robustness under persistent perturbations by incorporating Sharpness-Aware Minimization (SAM) into the federated learning framework. The method solves a min-max optimization problem where the inner maximization finds the worst-case perturbation within a neighborhood of the current model parameters, and the outer minimization updates the model to minimize this worst-case loss. This approach encourages convergence to flat minima in the loss landscape, which are inherently more robust to perturbations. The method is designed to handle both downlink (server-to-client) and uplink (client-to-server) perturbations, as well as their combinations. SMRFL maintains the same communication pattern as standard FL while providing theoretical guarantees for convergence under perturbations.

## Key Results
- SMRFL achieves O(1/√R) convergence rate under perturbations, matching unperturbed FL theoretical guarantees
- Outperforms FedAvg, Scaffold, and Feddyn by 2-10% higher test accuracy on MNIST and CIFAR-10 under various perturbation scenarios
- Demonstrates robustness to non-IID data distributions while maintaining superior performance
- Shows faster convergence compared to baseline methods across downlink, uplink, and combined perturbation settings

## Why This Works (Mechanism)
SMRFL leverages the principle that flat minima in the loss landscape are more robust to perturbations than sharp minima. By incorporating Sharpness-Aware Minimization into federated learning, the method explicitly searches for parameters that minimize the worst-case loss within a neighborhood, effectively finding flatter regions of the loss surface. This approach is particularly effective for non-malicious perturbations because it anticipates and mitigates their effects during training rather than trying to compensate after the fact. The min-max formulation ensures that the learned model remains stable even when small perturbations are applied, making it inherently robust to communication noise, quantization errors, and differential privacy mechanisms commonly used in edge networks.

## Foundational Learning

**Federated Learning**: Distributed machine learning framework where multiple clients collaboratively train a model under the coordination of a central server while keeping data localized. Why needed: Understanding the standard FL setup and communication patterns is essential for appreciating how SMRFL modifies the training process. Quick check: Can you explain the difference between local and global model updates in FL?

**Sharpness-Aware Minimization (SAM)**: Optimization technique that encourages convergence to flat minima by minimizing the maximum loss within a neighborhood of the current parameters. Why needed: SAM is the core mechanism that provides robustness to perturbations by finding flatter regions of the loss landscape. Quick check: How does SAM differ from standard gradient descent in terms of the optimization objective?

**Non-convex Optimization**: Mathematical framework for optimizing functions that are not convex, common in deep learning where loss surfaces have complex geometries. Why needed: Understanding non-convex optimization is crucial for interpreting the theoretical convergence analysis and the practical behavior of SMRFL. Quick check: What are the implications of non-convexity for convergence guarantees in FL?

## Architecture Onboarding

**Component Map**: Clients (with local data) -> Local SAM updates -> Server aggregation -> Global model update -> Neighborhood search (inner maximization) -> Worst-case loss minimization (outer minimization)

**Critical Path**: The critical path involves the min-max optimization where each client performs SAM-based local updates, sends models to the server, which aggregates them and performs the outer minimization. The inner maximization (neighborhood search) is the computational bottleneck but is essential for finding robust solutions.

**Design Tradeoffs**: SMRFL trades increased computational complexity per iteration (due to the inner maximization) for improved robustness and convergence properties. The method requires additional hyperparameter tuning for the neighborhood size in SAM, which balances robustness against computational cost. The theoretical convergence guarantee comes at the cost of assuming smooth non-convex objectives, which may not fully capture deep neural network behavior.

**Failure Signatures**: If the neighborhood size in SAM is too small, the method may not provide sufficient robustness; if too large, it may converge slowly or get stuck in poor local minima. Poor performance on highly non-IID data or with extreme perturbation magnitudes may indicate that the min-max formulation needs adjustment. Computational bottlenecks during the inner maximization step could limit scalability to larger models or higher-dimensional parameter spaces.

**3 First Experiments**: 1) Compare SMRFL vs FedAvg on MNIST with 10% downlink perturbation to verify basic robustness improvement. 2) Test convergence speed under combined downlink/uplink perturbations with varying magnitudes. 3) Evaluate performance degradation as neighborhood size in SAM increases to understand the computational-robustness tradeoff.

## Open Questions the Paper Calls Out

The paper acknowledges that while SMRFL demonstrates strong performance on standard vision datasets, its effectiveness on more complex domains and larger-scale federated settings remains to be investigated. The assumption that perturbations are non-malicious and bounded, while reasonable for many edge computing scenarios, excludes adversarial attacks that require different defense mechanisms. The computational overhead of the min-max optimization, particularly the inner maximization step, could pose challenges in resource-constrained edge environments when scaling to larger models or higher-dimensional parameter spaces. Additionally, while the theoretical analysis provides O(1/√R) convergence guarantees, these assumptions may not fully capture the behavior of deep neural networks in practice.

## Limitations

- Theoretical analysis assumes convex or smooth non-convex objectives, which may not fully capture deep neural network behavior
- Evaluation limited to standard vision datasets (MNIST, CIFAR-10) and may not generalize to more complex domains
- Computational overhead of min-max optimization could limit scalability in resource-constrained edge environments
- Assumes non-malicious, bounded perturbations and does not address adversarial attacks

## Confidence

- Theoretical convergence analysis: High
- Experimental performance claims: Medium
- Generalizability to complex scenarios: Low

## Next Checks

1. Evaluate SMRFL on larger-scale federated learning benchmarks with heterogeneous client devices and real-world communication constraints
2. Test robustness against adversarial perturbations and compare with specialized adversarial defense methods
3. Investigate computational overhead of the min-max optimization in resource-constrained edge environments