---
ver: rpa2
title: Do LLMs Encode Frame Semantics? Evidence from Frame Identification
arxiv_id: '2509.19540'
source_url: https://arxiv.org/abs/2509.19540
tags:
- frame
- framenet
- definitions
- frames
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates whether large language models (LLMs) inherently\
  \ encode knowledge of frame semantics, focusing on the task of frame identification\u2014\
  selecting the correct semantic frame for a target word in context. Using the FrameNet\
  \ lexical resource, the authors evaluate LLMs under prompt-based inference and find\
  \ that they can perform frame identification effectively even without explicit task-specific\
  \ supervision."
---

# Do LLMs Encode Frame Semantics? Evidence from Frame Identification

## Quick Facts
- arXiv ID: 2509.19540
- Source URL: https://arxiv.org/abs/2509.19540
- Reference count: 31
- Primary result: LLMs achieve SOTA frame identification accuracy (91.7-91.9%) with minimal supervision and can generate useful frame definitions

## Executive Summary
This paper investigates whether large language models inherently encode knowledge of frame semantics through the lens of frame identification. Using the FrameNet lexical resource, the authors evaluate both prompt-based inference and fine-tuning approaches on Llama-3.1-8B. They find that LLMs can perform frame identification effectively even without explicit supervision, achieving strong results on in-domain benchmarks (91.7% on FrameNet 1.5, 91.9% on FrameNet 1.7) and demonstrating generalization to out-of-domain datasets (80.7% on YAGS, 49.6% on Artifacts). The models can also generate semantically coherent frame definitions that maintain task performance when substituted for gold definitions.

## Method Summary
The authors employ two complementary approaches: prompt-based inference using Llama-3.1-8B-Instruct (both zero-shot and few-shot with 5 demonstrations) and fine-tuning using Llama-3.1-8B with LoRA adaptation (rank=16, alpha=32, 3 epochs, lr=2e-5). The task involves selecting the correct semantic frame for a target word in context from candidate frames, with inputs formatted as QA-style prompts containing frame names, definitions, and lexical unit descriptions. Evaluation spans FrameNet 1.5 and 1.7 datasets plus out-of-domain benchmarks YAGS and Artifacts.

## Key Results
- Fine-tuned models achieve SOTA performance: 91.7% on FrameNet 1.5 and 91.9% on FrameNet 1.7
- Strong generalization: 80.7% accuracy on YAGS and 49.6% on Artifacts out-of-domain datasets
- Generated frame definitions maintain comparable performance when substituted for gold definitions
- LU definitions consistently improve accuracy across prompt types, with Direct-QA achieving best few-shot result (83.5%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs encode latent frame-semantic knowledge accessible via lightweight prompting, without task-specific supervision
- **Mechanism:** Pre-training on diverse text exposes the model to implicit frame-semantic patterns, which prompting retrieves by framing frame identification as a structured selection task
- **Core assumption:** Frame-semantic regularities in pre-training data are sufficiently frequent and consistent for the model to internalize
- **Evidence anchors:** Zero-shot Direct-QA achieves 81.7% on FN 1.7; few-shot reaches 83.5%; related work (Exploring In-Context Learning for Frame-Semantic Parsing) similarly finds ICL effective for FSP tasks
- **Break condition:** If zero-shot accuracy dropped to random-baseline levels (~0.1%), the latent-encoding claim would be falsified

### Mechanism 2
- **Claim:** Lexical Unit (LU) definitions provide semantic cues that stabilize disambiguation, especially for ambiguous targets
- **Mechanism:** LU definitions anchor the model's reasoning by explicitly describing context-sensitive word senses, reducing reliance on ambiguous frame names alone
- **Core assumption:** The model can interpret and match definition semantics to sentential context
- **Evidence anchors:** Adding LU definitions consistently improves accuracy in both prompt types; Direct-QA with Frame Names & LU Defs achieves best few-shot result (83.5%); on ambiguous cases, LU definitions yield +3.1% zero-shot improvement over frame names alone
- **Break condition:** If LU definitions degraded or failed to improve performance, the mechanism would not hold

### Mechanism 3
- **Claim:** QA-style fine-tuning with LoRA aligns model outputs to the frame identification task, improving both in-domain accuracy and out-of-domain generalization
- **Mechanism:** Fine-tuning computes logits over restricted label tokens using cross-entropy loss, teaching the model to map context+target+definitions to correct frame labels
- **Core assumption:** The frame inventory and definition format in training data are sufficiently representative of test distributions
- **Evidence anchors:** Fine-tuning improves accuracy to 91.7% (FN 1.5) and 91.9% (FN 1.7), matching SOTA; fine-tuned model generalizes to YAGS (80.7%) and Artifacts (49.6%), outperforming zero-shot baselines
- **Break condition:** If fine-tuning failed to improve over prompting baselines, or generalization collapsed on OOD datasets, the mechanism would be questionable

## Foundational Learning

- **Concept: Frame Semantics**
  - **Why needed here:** Frame identification requires understanding that words evoke situation-specific frames with participant roles
  - **Quick check question:** Given "The restaurant serves 50 customers nightly," does "serves" evoke *Capacity* or *Assistance*? Why?

- **Concept: Lexical Units (LUs)**
  - **Why needed here:** LUs link word forms to context-sensitive senses and frames, explicitly used as model inputs
  - **Quick check question:** What LU does "serve.v" correspond to under the *Assistance* frame?

- **Concept: Contextual Disambiguation**
  - **Why needed here:** Frame identification is fundamentally a disambiguation task—selecting among candidate frames based on sentential context
  - **Quick check question:** If a target word has 5 candidate frames, what contextual signals help select the correct one?

## Architecture Onboarding

- **Component map:** FrameNet data → QA-style prompt formatting → Llama-3.1-8B-Instruct (prompting) or Llama-3.1-8B (fine-tuning with LoRA) → JSON output parsing → accuracy evaluation

- **Critical path:** 1) Prepare FrameNet data → format as QA instances with candidate frames and definitions 2) Design prompt template (Direct-QA with LU definitions recommended) 3) Fine-tune with LoRA, constraining output vocabulary to label tokens 4) Evaluate in-domain (FN 1.5/1.7) and OOD (YAGS, Artifacts)

- **Design tradeoffs:** Zero-shot is faster (~83% accuracy) but fine-tuning reaches SOTA (~92%); adding definitions improves performance but increases token cost; Artifacts tests phrase-level reasoning without context; expect lower accuracy (~50%)

- **Failure signatures:** 296 agreeing wrong predictions with FIDO indicate systematic confusion on subtle frame distinctions; generated definitions may lack role-structure precision though remain functionally usable

- **First 3 experiments:** 1) Baseline prompt ablation: Run Simple vs. Direct-QA prompts with varying granularity on FN 1.7 test set 2) Fine-tuning sweep: Train LoRA with rank ∈ {4, 8, 16, 32} and report in-domain and YAGS accuracy 3) Definition substitution test: Replace gold definitions with LLM-generated definitions and measure frame ID accuracy drop

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can LLMs effectively perform the other subtasks of frame-semantic parsing, specifically target identification and argument identification, using the latent frame-semantic knowledge observed in frame identification?
- **Basis in paper:** The authors state in the Limitations section that their "analysis is confined to the Frame Identification task, with the other key components of Frame Semantic Parsing left unaddressed in this study."
- **Why unresolved:** While the paper demonstrates strong capabilities in disambiguating frames, it does not evaluate the model's ability to first detect frame-evoking words or extract semantic roles
- **What evidence would resolve it:** An evaluation of the fine-tuned or prompted Llama models on the full frame-semantic parsing pipeline, specifically measuring performance on target and argument identification against FrameNet annotations

### Open Question 2
- **Question:** Does the frame-semantic encoding in LLMs generalize to multilingual contexts and alternative frame ontologies such as PropBank?
- **Basis in paper:** The authors explicitly state: "It remains an open question to extend LLM-based frame identification to multilingual contexts... alternative frame ontologies... or broader frame-driven language systems."
- **Why unresolved:** The study is restricted to English and the FrameNet 1.5/1.7 inventories; it is unclear if the latent knowledge is specific to the FrameNet schema or represents a general semantic capability transferable to other formalisms
- **What evidence would resolve it:** Zero-shot or fine-tuned evaluations of the model on multilingual FrameNet datasets or datasets annotated with PropBank frames

### Open Question 3
- **Question:** Can controlled generation techniques improve the structural fidelity and role-awareness of LLM-generated frame definitions to match curated lexical resources?
- **Basis in paper:** The Conclusion notes that while generated definitions are coherent, they "often [lack] the precision... and role-structure sensitivity of curated FrameNet definitions" and suggests future work explore "controlled definition generation techniques that enforce conciseness and role-structure fidelity."
- **Why unresolved:** The current zero-shot generation method produces useful but often loosely structured or hallucinated definitions, limiting their utility as a formal lexical resource
- **What evidence would resolve it:** A comparison of frame definitions generated via controlled methods against gold definitions, specifically measuring the accuracy of included Frame Elements and adherence to FrameNet stylistic guidelines

### Open Question 4
- **Question:** What is the intrinsic linguistic quality of LLM-generated frame definitions compared to gold standards, beyond their extrinsic utility in frame identification?
- **Basis in paper:** The Limitations section notes that the "quantitative evaluation of LLM-generated frame definitions is limited to their impact on the Frame Identification task; a more rigorous human annotation-based evaluation would provide deeper insights."
- **Why unresolved:** The paper proves generated definitions are useful for the downstream task (extrinsic) but leaves open the question of whether they are accurate descriptions of the semantic frame (intrinsic)
- **What evidence would resolve it:** A human evaluation study where linguists or annotators rate the generated definitions on correctness, completeness, and clarity relative to the gold-standard FrameNet definitions

## Limitations
- The study is confined to frame identification and does not address other components of frame-semantic parsing like target and argument identification
- Generalization to Artifacts (49.6%) reveals significant domain gap when contextual sentences are absent
- The mechanism by which LLMs acquire frame-semantic knowledge from pre-training remains implicit and not empirically validated

## Confidence
- **High Confidence:** The claim that fine-tuned LLMs achieve SOTA performance on FrameNet benchmarks (91.7% and 91.9%) is well-supported by direct experimental results with clear metrics
- **Medium Confidence:** The assertion that LLMs encode latent frame-semantic knowledge is plausible given zero-shot performance, but the underlying acquisition mechanism is not empirically validated
- **Medium Confidence:** The effectiveness of LU definitions in improving disambiguation is demonstrated, but the paper does not explore whether this benefit stems from semantic understanding or pattern matching

## Next Checks
1. **Pre-training Data Analysis:** Analyze a sample of the model's pre-training corpus to quantify the frequency and consistency of frame-semantic patterns, testing whether sufficient exposure exists to explain the observed capabilities
2. **Knowledge Probing:** Design controlled experiments that systematically remove sentential context to determine whether the model relies on contextual cues or has internalized frame knowledge that generalizes to isolated phrases
3. **Mechanism Dissection:** Compare model performance on ambiguous targets where correct frames differ only in subtle role structures versus cases where surface lexical cues strongly indicate the correct frame, to distinguish between deep semantic understanding and shallow pattern matching