---
ver: rpa2
title: 'An Explainable and Fair AI Tool for PCOS Risk Assessment: Calibration, Subgroup
  Equity, and Interactive Clinical Deployment'
arxiv_id: '2511.11636'
source_url: https://arxiv.org/abs/2511.11636
tags:
- pcos
- calibration
- clinical
- accuracy
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops an explainable and fairness-audited machine
  learning framework for PCOS risk assessment. It trains and calibrates Random Forest,
  SVM, and XGBoost models with both Platt scaling and isotonic regression, achieving
  a high accuracy of 90.8% with a Random Forest model.
---

# An Explainable and Fair AI Tool for PCOS Risk Assessment: Calibration, Subgroup Equity, and Interactive Clinical Deployment

## Quick Facts
- arXiv ID: 2511.11636
- Source URL: https://arxiv.org/abs/2511.11636
- Authors: Asma Sadia Khan; Sadia Tabassum
- Reference count: 38
- Primary result: 90.8% accuracy Random Forest model with SHAP-explainable, fairness-audited PCOS risk assessment deployed via Streamlit interface

## Executive Summary
This study develops an explainable and fairness-audited machine learning framework for PCOS risk assessment. It trains and calibrates Random Forest, SVM, and XGBoost models with both Platt scaling and isotonic regression, achieving a high accuracy of 90.8% with a Random Forest model. SHAP analysis reveals follicle count, weight gain, and menstrual irregularity as the most influential features, aligning with Rotterdam diagnostic criteria. Fairness audits show strong performance in women aged 25-35 but reduced accuracy in younger women (<25), highlighting age-related disparities. A Streamlit-based web interface enables real-time risk assessment, interactive 'what-if' analysis, and clinical usability.

## Method Summary
The framework trains Random Forest, SVM, and XGBoost models on a Kaggle PCOS dataset (541 instances, 40 features) using stratified 80/20 train-test splits. Preprocessing includes standard scaling of continuous features while preserving binary encodings. Models are calibrated using both Platt scaling and isotonic regression via CalibratedClassifierCV. SHAP TreeExplainer provides feature attribution aligned with Rotterdam criteria, while Fairlearn MetricFrame evaluates subgroup equity across age, BMI, and demographic factors. The Random Forest model achieves 90.8% accuracy with isotonic calibration, and the system is deployed as an interactive Streamlit web interface.

## Key Results
- Random Forest with isotonic calibration achieves 90.8% accuracy, 0.0678 Brier Score, and 0.0666 ECE
- SHAP analysis identifies follicle count, weight gain, and menstrual irregularity as top features, matching Rotterdam criteria
- Subgroup analysis reveals strong performance in women aged 25-35 but drops to 69.2% accuracy in women under 25
- Streamlit interface enables real-time risk assessment with interactive what-if analysis capabilities

## Why This Works (Mechanism)

### Mechanism 1: Probabilistic Calibration for Clinical Reliability
If post-hoc calibration (specifically Isotonic Regression) is applied, raw model scores are mapped to reliable probabilities, reducing the risk of overconfident clinical decisions. Tree-based models like Random Forest often produce overconfident or distorted probability distributions. Isotonic Regression fits a non-parametric mapping function to these scores, correcting non-linear distortions. This aligns the "predicted risk" (e.g., 80%) with the "observed frequency" (actual positive rate), measured here by Brier Score and Expected Calibration Error (ECE). Core assumption: Assumes the validation data distribution is representative of the deployment environment; calibration quality degrades if the underlying data drifts.

### Mechanism 2: Clinical Alignment via Feature Attribution (SHAP)
If the model's internal decision logic relies on features established in clinical guidelines (Rotterdam criteria), it is more likely to be clinically valid and generalizable. SHAP (SHapley Additive exPlanations) decomposes predictions into additive feature contributions. By validating that the "most influential features" (highest mean absolute SHAP values) correspond to known diagnostic markers (follicle count, menstrual irregularity), the system filters for "right reasons" learning rather than spurious correlations. Core assumption: Alignment with the Rotterdam criteria implies the model is capturing the underlying pathophysiology rather than dataset-specific artifacts.

### Mechanism 3: Disparity Detection via Subgroup Stratification
Even if overall accuracy is high (>90%), performance can collapse for specific demographic subgroups if not explicitly audited. The framework evaluates metrics (Accuracy, Precision, Recall) not just globally, but within stratified "sensitive groups" (e.g., Age < 25). This exposes "hidden stratifications" where the model fails to generalize, often due to under-representation or distinct physiological presentations in the training data. Core assumption: Assumes that defined subgroups (e.g., Age < 25 vs. 25–35) are homogenous enough to identify bias, though intersectional biases (e.g., young AND lean) may still be hidden.

## Foundational Learning

- **Concept: Calibration (Brier Score & ECE)**
  - Why needed here: High accuracy doesn't guarantee trustworthy probabilities. A model can be "right" 90% of the time but output 99% confidence for wrong guesses. Clinical tools require calibrated probabilities to assess risk severity.
  - Quick check question: If a model predicts 70% risk for 10 patients, exactly how many should actually have the condition for the model to be considered "calibrated"?

- **Concept: TreeExplainer (SHAP)**
  - Why needed here: Random Forests are ensemble methods and difficult to interpret directly. TreeExplainer allows for exact computation of Shapley values in polynomial time, making "global importance" and "local explanation" feasible for clinical adoption.
  - Quick check question: Why is global feature importance alone insufficient for explaining a specific patient's diagnosis?

- **Concept: Fairness Auditing (MetricFrame)**
  - Why needed here: Standard evaluation averages performance across all data points. Fairness auditing requires disaggregated metrics to ensure the model serves minority populations equitably.
  - Quick check question: A model has 99% accuracy. Group A has 100% accuracy, Group B has 0% accuracy. How is this possible? (Hint: Class imbalance or group size).

## Architecture Onboarding

- **Component map:** Raw Data -> Scaling -> RF Model -> Isotonic Calibration -> SHAP Explanation -> Fairness Audit -> Streamlit Interface
- **Critical path:** The path from Raw Data -> Scaling -> RF Model -> Isotonic Calibration determines the validity of the risk score. If scaling is applied to binary features (error mentioned in pre-processing), or if calibration fails, the clinical output is invalid.
- **Design tradeoffs:** SVM achieved lower calibration error (ECE 0.0541) but was rejected in favor of Random Forest (ECE 0.0666) because RF integrates more natively with SHAP for explainability. Isotonic is more flexible (non-parametric) but risks overfitting on small datasets; Platt is more rigid (sigmoid). This study found Isotonic generally superior for RF and SVM.
- **Failure signatures:** High Accuracy, Low Calibration: Model discriminates well but outputs extreme probabilities (e.g., 0.99 vs 0.01) that do not match true likelihoods. Age-based Performance Drop: Drastic accuracy drop (to ~69%) for patients < 25 years old indicates the model cannot detect early-stage or atypical presentations common in younger cohorts.
- **First 3 experiments:** 1. Calibration Validation: Train RF with and without Isotonic Regression. Plot Calibration Curves and calculate ECE to verify the curve aligns with the diagonal. 2. SHAP Consistency Check: Run shap.Explainer on the trained model. Verify that "Follicle Count" and "Weight Gain" are the top features. If "Patient ID" or unrelated features appear, investigate data leakage. 3. Subgroup Stress Test: Filter the test set for Age < 25. Calculate Recall and Precision specifically for this slice to reproduce the 69% accuracy finding and determine if it meets minimum clinical safety thresholds.

## Open Questions the Paper Calls Out

### Open Question 1
Can the inclusion of insulin sensitivity markers (e.g., HOMA-IR) improve the detection of lean PCOS phenotypes? The current study utilized a dataset that lacked these specific metabolic markers, potentially limiting precision for non-obese subgroups. A comparative study retraining the model with HOMA-IR features and evaluating the resulting precision and recall specifically for normal-BMI patients would resolve this.

### Open Question 2
Does the integration of longitudinal cycle tracking and AMH levels mitigate the observed accuracy drop in women under 25? The current model relied on static clinical inputs which performed poorly (69.2% accuracy) in the youngest age subgroup. Retraining the model on a cohort enriched with time-series menstrual data and Anti-Müllerian Hormone (AMH) levels to measure subgroup accuracy improvements would resolve this.

### Open Question 3
Does the framework maintain its calibration and fairness properties when deployed in geographically or ethnically distinct populations? The use of a "single dataset with limited demographic diversity" as a limitation, while the tool's scalability to low-resource settings is mentioned. PCOS diagnostic criteria and phenotypic expression can vary significantly across different ethnic and geographic groups, raising concerns about external validity. External validation studies on datasets from diverse regions (e.g., non-Indian cohorts) using the reported Expected Calibration Error (ECE) and subgroup accuracy metrics would resolve this.

## Limitations
- Subgroup performance disparity for age <25 (69.2% accuracy) represents a significant clinical safety concern, yet the paper does not investigate whether this stems from dataset imbalance, physiological differences in presentation, or model architecture limitations.
- While calibration metrics demonstrate reasonable probability reliability, the paper lacks temporal validation to confirm calibration stability over time or across different clinical settings beyond the single Kerala dataset source.
- The fairness audit framework identifies disparities but doesn't prescribe remediation strategies or quantify the clinical impact of these disparities on misdiagnosis rates and subsequent treatment delays.

## Confidence
- **High Confidence:** Model achieves stated accuracy (90.8%) and calibration metrics with Random Forest and Isotonic Regression; SHAP feature importance correctly identifies clinically relevant markers aligned with Rotterdam criteria.
- **Medium Confidence:** Subgroup performance metrics and disparity findings are reproducible given proper data stratification, but the clinical significance and remediation of these disparities require further investigation.
- **Low Confidence:** The generalizability of findings beyond the Kerala dataset and the long-term clinical impact of deploying this system without addressing age-related performance gaps.

## Next Checks
1. **Dataset Representation Analysis:** Calculate the exact distribution of age, BMI categories, and PCOS severity across the 541 samples to quantify potential representation gaps for younger patients and minority subgroups.
2. **Temporal Validation Study:** Apply the trained model to a temporally separated subset of the same dataset (e.g., data from different years) to assess calibration drift and performance stability over time.
3. **Intersectional Fairness Audit:** Beyond single-dimension subgroup analysis, evaluate model performance across intersectional combinations (e.g., Age < 25 AND BMI < 25) to identify hidden stratifications not captured in the current framework.