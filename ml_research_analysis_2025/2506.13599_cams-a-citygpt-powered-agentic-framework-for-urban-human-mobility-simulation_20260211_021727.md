---
ver: rpa2
title: 'CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation'
arxiv_id: '2506.13599'
source_url: https://arxiv.org/abs/2506.13599
tags:
- mobility
- urban
- patterns
- knowledge
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CAMS, a CityGPT-powered agentic framework
  for urban human mobility simulation. The method integrates large language models
  with urban spatial knowledge to address limitations in traditional data-driven approaches.
---

# CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation

## Quick Facts
- arXiv ID: 2506.13599
- Source URL: https://arxiv.org/abs/2506.13599
- Reference count: 40
- Key outcome: Introduces CAMS, a CityGPT-powered agentic framework that generates realistic urban human mobility trajectories without external geospatial data, achieving superior performance on multiple metrics compared to existing methods.

## Executive Summary
This paper introduces CAMS, a CityGPT-powered agentic framework for urban human mobility simulation. The method integrates large language models with urban spatial knowledge to address limitations in traditional data-driven approaches. CAMS comprises three modules: MobExtractor extracts and synthesizes mobility patterns from user profiles, GeoGenerator leverages an enhanced CityGPT to generate urban geospatial knowledge, and TrajEnhancer improves trajectory realism through direct preference optimization. Experiments on real-world datasets (Tencent and ChinaMobile) show CAMS achieves superior performance without relying on externally provided geospatial information. The framework demonstrates better performance on metrics like distance, radius, and spatial-temporal visits distribution, with CMRR scores of 0.5208 and 0.7125 on the two datasets respectively. The approach establishes a new paradigm for integrating urban-knowledgeable LLMs with agentic frameworks for human mobility simulation.

## Method Summary
CAMS is a three-module framework that generates realistic human mobility trajectories in urban environments. The MobExtractor compresses raw trajectories into linguistic patterns and synthesizes new patterns for users with limited historical data using profile-aware feature fusion. The GeoGenerator employs an enhanced CityGPT fine-tuned on POI-centric navigation data, using a macro-to-micro cascaded generation system to determine anchor points and generate geospatial knowledge without external tool calls. The TrajEnhancer refines generated trajectories through Direct Preference Optimization, aligning outputs with real trajectory distributions to improve spatiotemporal continuity.

## Key Results
- CAMS achieves CMRR scores of 0.5208 and 0.7125 on Tencent and ChinaMobile datasets respectively, outperforming baselines including ST-RNN, DeepMove, and Transformer-based methods
- The framework demonstrates superior performance on distribution metrics (Distance, Radius, SI, SD, STVD, FVLoc, ActProb, DARD) without relying on externally provided geospatial information
- CityGPT fine-tuned on hierarchical spatial data shows better geographic validity than general-purpose LLMs, with the specialized 8B model outperforming 70B+ models on location hallucination metrics

## Why This Works (Mechanism)

### Mechanism 1: Semantic Pattern Condensation
Converting raw trajectories into linguistic mobility patterns enables data-efficient simulation for new users via semantic feature fusion. The MobExtractor employs a dual-phase architecture that first compresses trajectory data into natural language rules and user profile correlations, then synthesizes patterns for new users by retrieving similar template users and fusing their profile features, rather than relying on sparse trajectory histories.

### Mechanism 2: Urban Knowledge Grounding via Specialized Foundation Models
General-purpose LLMs hallucinate urban locations; fine-tuning on hierarchical spatial data grounds the model in real geography. GeoGenerator uses an enhanced CityGPT fine-tuned on POI-centric navigation data with 10,000 QA pairs, employing a macro-to-micro cascaded generation system to determine anchor points through the model's internalized urban constraints rather than external tool calls.

### Mechanism 3: Iterative Preference Alignment (DPO)
Standard generation often lacks spatiotemporal continuity; Direct Preference Optimization (DPO) aligns generated trajectories with collective human mobility distributions. TrajEnhancer treats trajectory generation as a preference learning problem, constructing a dataset where real trajectories are positive samples and unaligned model outputs are negative samples, with iterated training cycles progressively refining the model's understanding of spatial continuity.

## Foundational Learning

- **Concept: Direct Preference Optimization (DPO)**
  - Why needed here: Used to refine the raw outputs of the CityGPT agent without a complex reinforcement learning pipeline, aligning the model's output distribution with real-world mobility statistics
  - Quick check question: How does the choice of negative samples (synthetic vs. random) affect the model's convergence in this specific urban context?

- **Concept: Hierarchical Spatial Representation**
  - Why needed here: CAMS rejects coordinates in favor of "Admin → Subdistrict → Street → POI" representation, understanding how LLMs process nested semantic hierarchies is crucial for debugging location hallucinations
  - Quick check question: Why would a model perform better with "Street A, District B" versus "40.7128° N, 74.0060° W"?

- **Concept: Agentic Reflection Cycles**
  - Why needed here: The GeoGenerator uses Reasoning → Execution → Reflection to align individual choices with collective distributions
  - Quick check question: What specific metric triggers the "reflection" phase to adjust the next generation step?

## Architecture Onboarding

- **Component map:** User Profiles + Sparse Trajectories → MobExtractor → GeoGenerator → TrajEnhancer → Realistic Trajectories
- **Critical path:** The CityGPT Fine-tuning (Section 2.2.2) is the bottleneck. Without the specific POI-centric QA dataset, the base LLM suffers from high hallucination rates, rendering the simulation unrealistic.
- **Design tradeoffs:** The paper argues a specialized 8B model (CityGPT) outperforms general 70B+ models on geographic validity, trading general reasoning power for domain accuracy. Using text-based patterns instead of numeric embeddings improves interpretability but may lose fine-grained spatial precision.
- **Failure signatures:** Low TVR indicates the model is hallucinating location names; check the fine-tuning alignment. High JSD in Radius/Distance suggests the DPO alignment failed to curb unrealistic travel distances.
- **First 3 experiments:**
  1. Run baseline Llama3.1-8B vs. CityGPT on a simple "locate nearby POI" task to confirm the TVR delta
  2. Disable the "reflection with collective distribution" in Anchor Location Extractor and measure the drift in home/work location clustering
  3. Run a single DPO cycle vs. the full 3-cycle approach to visualize the drop in JSD for "Step Distance" and "Radius"

## Open Questions the Paper Calls Out
None explicitly called out in the provided content.

## Limitations
- The framework's performance in cities not included in the CityGPT fine-tuning corpus remains untested, creating uncertainty about generalizability
- Computational cost and latency for city-wide simulation at scale are not reported, leaving deployment feasibility unclear
- The framework may struggle to capture emergent collective behaviors and dynamic inter-agent interactions, as trajectory generation is primarily driven by individual reasoning rather than real-time interaction

## Confidence
- **High Confidence**: The three-module architecture design and the general approach of using semantic patterns instead of raw coordinates for LLM interaction are well-specified and theoretically sound
- **Medium Confidence**: The DPO mechanism for trajectory refinement and the CityGPT fine-tuning approach are described sufficiently for understanding, but critical implementation details remain unspecified
- **Low Confidence**: The exact construction of the CityGPT fine-tuning dataset and the specific prompts/templates used for mobility pattern extraction are not fully specified, making faithful reproduction challenging

## Next Checks
1. **TVR Validation**: Run baseline Llama3.1-8B and CityGPT on location validation tasks to empirically verify the claimed improvement in Toponym Valid Ratio before proceeding with full framework implementation.
2. **Fine-tuning Data Reconstruction**: Attempt to reconstruct the 10,000 QA fine-tuning dataset using OSM and Foursquare data with the described "macro-to-micro" hierarchical approach to assess whether the methodology produces usable geographic knowledge in the LLM.
3. **DPO Iteration Analysis**: Implement a simplified version with only one DPO iteration cycle and compare distribution metrics against the three-cycle approach to quantify the marginal benefit of additional training iterations on trajectory realism.