---
ver: rpa2
title: 'ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart
  Question Answering'
arxiv_id: '2506.10116'
source_url: https://arxiv.org/abs/2506.10116
tags:
- chart
- reasoning
- data
- echarts
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ChartReasoner, a code-driven two-stage framework
  for enhancing visual reasoning over charts by bridging the visual-textual modality
  gap. It first trains Chart2Code to convert chart images into structured ECharts
  code, preserving layout and semantics, and then synthesizes a 140K-sample reasoning
  dataset (ChartThink) from existing benchmarks.
---

# ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering

## Quick Facts
- arXiv ID: 2506.10116
- Source URL: https://arxiv.org/abs/2506.10116
- Reference count: 37
- Claims state-of-the-art open-source performance on ChartQA benchmarks using fewer parameters

## Executive Summary
ChartReasoner introduces a two-stage framework for enhancing visual reasoning over charts by converting chart images to structured ECharts code and then applying long-chain reasoning. The approach first trains Chart2Code to convert chart images into executable ECharts code, preserving layout and semantics. It then synthesizes a 140K-sample reasoning dataset (ChartThink) from existing benchmarks by filtering generated reasoning traces based on answer correctness. The final model is trained using supervised fine-tuning and reinforcement learning with GRPO, achieving state-of-the-art performance among open-source models on four ChartQA benchmarks while approaching GPT-4o-level performance on out-of-domain tasks.

## Method Summary
ChartReasoner uses a code-driven two-stage framework: first, Chart2Code converts chart images into structured ECharts code, bridging the visual-textual modality gap; second, ChartThink synthesizes a reasoning dataset by generating long-chain reasoning traces over chart code and filtering by answer correctness. The final model is trained via supervised fine-tuning and GRPO to refine reasoning outputs, achieving state-of-the-art performance on ChartQA benchmarks with fewer parameters than competing models.

## Key Results
- Achieves state-of-the-art performance among open-source models on four ChartQA benchmarks
- Approaches GPT-4o-level performance on out-of-domain tasks
- Uses fewer parameters than competing models while maintaining strong performance

## Why This Works (Mechanism)

### Mechanism 1: Code-Driven Modality Bridging
Converting chart images to structured ECharts code preserves more layout, semantic, and quantitative information than lossy image-to-text serialization. Chart2Code acts as a high-fidelity "transport layer" that maps visual encodings into executable symbolic representations, allowing downstream reasoning to operate on complete, structured data rather than incomplete textual descriptions.

### Mechanism 2: Reasoning Trace Distillation via Verified Answer Filtering
Generating reasoning traces over code representations and filtering by answer correctness produces higher-quality training data than unfiltered generation. The ChartThink pipeline uses a long-chain reasoning LLM to produce (reasoning, answer) pairs conditioned on chart code, retaining only samples where the predicted answer matches ground truth.

### Mechanism 3: GRPO for Reasoning Refinement
Reinforcement learning with Group Relative Policy Optimization (GRPO) after SFT reduces over-generation and improves output conciseness without sacrificing accuracy. GRPO generates multiple candidate responses per input and optimizes via intra-group normalization, using rule-based rewards for accuracy, format, and length.

## Foundational Learning

- **Concept: ECharts Specification Format**
  - Why needed here: Chart2Code outputs ECharts (JavaScript-based charting library) code; understanding its structure (option objects, series, axes, data arrays) is required to debug reconstruction failures.
  - Quick check question: Given a simple bar chart image, can you manually write the corresponding ECharts option object with correct data encoding?

- **Concept: Chain-of-Thought vs Long-Chain Reasoning**
  - Why needed here: The paper distinguishes shallow CoT (few-step prompts) from long-chain reasoning (multi-step, structured deduction); this distinction informs data synthesis design.
  - Quick check question: What is the difference between a 2-step CoT prompt and a 10-step long-chain reasoning trace for computing a derived statistic from a multi-series chart?

- **Concept: Group Relative Policy Optimization (GRPO)**
  - Why needed here: The second training stage uses GRPO, not standard PPO; understanding intra-group normalization and multi-sample comparison is essential for implementing or modifying the RL phase.
  - Quick check question: How does GRPO differ from PPO in how it computes advantages across candidate outputs?

## Architecture Onboarding

- **Component map**: Chart2Code (image→code VLM) → ChartThink synthesizer (code + question → reasoning trace via external LLM) → ChartReasoner (final multimodal model trained SFT→GRPO). Datasets: Chart2Code dataset (110K image-code pairs), ChartThink (140K image-question-reasoning-answer tuples).

- **Critical path**: (1) Chart2Code reconstruction quality directly determines reasoning input fidelity; (2) Reasoning trace quality (verified by answer correctness) determines SFT effectiveness; (3) GRPO reward design determines final output conciseness. Failure at stage (1) propagates through all downstream steps.

- **Design tradeoffs**: ECharts vs Python/Matplotlib as target code format (ECharts chosen for web-render versatility; Python may be more familiar); strict answer-match filtering vs soft reward-based filtering (strict chosen for precision, may reduce dataset diversity); 7B model vs larger backbone (computational constraints; scaling effects unknown).

- **Failure signatures**: (1) Chart2Code produces syntactically valid but semantically wrong code (axes swapped, data transposed) → downstream reasoning is misinformed; (2) Scatter/line charts show lower reconstruction accuracy (dense overlapping points) → expect degraded QA on these types; (3) Over-reasoning persists after GRPO → reward functions may not adequately penalize verbosity.

- **First 3 experiments**:
  1. **Chart2Code validation**: Render Chart2Code outputs and compute GPT-4V similarity scores against originals; stratify by chart type to identify weak categories.
  2. **Ablation on filtering threshold**: Train ChartReasoner-SFT with relaxed answer-matching (e.g., accepting answers within numerical tolerance) vs strict exact match; compare downstream benchmark accuracy.
  3. **GRPO reward sensitivity**: Vary reward weights for accuracy vs length; measure tradeoff between answer correctness and reasoning conciseness on a held-out validation set.

## Open Questions the Paper Calls Out
None

## Limitations
- The fidelity of Chart2Code's visual-to-code conversion is never directly validated through human evaluation or systematic ablation
- Dataset filtering mechanism (retaining only samples where generated answers match ground truth) may create selection bias that inflates model performance
- ECharts as the target code format introduces domain-specific constraints; reasoning performance may degrade for visual elements outside ECharts' expressive range

## Confidence
- High confidence: Overall framework architecture and code-as-bridge concept for visual reasoning
- Medium confidence: Effectiveness of answer-match filtering for producing high-quality reasoning traces
- Medium confidence: GRPO's contribution to reasoning refinement based on reported ablation
- Low confidence: Claim of being "first" to apply long-chain reasoning to charts without systematic survey of prior work

## Next Checks
1. **Human evaluation of Chart2Code fidelity**: Recruit annotators to compare rendered Chart2Code outputs against original chart images across different chart types, measuring semantic and layout preservation.

2. **Ablation study on dataset filtering**: Train models using ChartThink datasets with varying filtering thresholds (strict match, numerical tolerance, no filtering) and measure the tradeoff between dataset size and downstream benchmark performance.

3. **Out-of-distribution generalization test**: Evaluate ChartReasoner on charts using different styling conventions, color schemes, or chart types not well-represented in the training data (e.g., radar charts, 3D charts).