---
ver: rpa2
title: Codifying Character Logic in Role-Playing
arxiv_id: '2505.07705'
source_url: https://arxiv.org/abs/2505.07705
tags:
- scene
- codified
- profile
- character
- profiles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Codified Profiles, a structured approach for
  role-playing that encodes character logic into executable functions to improve consistency,
  updatability, and controllable randomness compared to traditional prompt-based methods.
  The system compiles natural language character descriptions into deterministic control
  logic using semantic condition checks, enabling persistent and interpretable behavior.
---

# Codifying Character Logic in Role-Playing

## Quick Facts
- **arXiv ID**: 2505.07705
- **Source URL**: https://arxiv.org/abs/2505.07705
- **Reference count**: 40
- **Primary result**: Codified profiles improve role-playing consistency, achieving 69.28% NLI score versus 65.28% for textual profiles, with even stronger gains for smaller models.

## Executive Summary
This paper introduces Codified Profiles, a structured approach for role-playing that encodes character logic into executable functions rather than relying on prompt-based methods. The system compiles natural language character descriptions into deterministic control logic using semantic condition checks, enabling persistent and interpretable behavior. Experiments on a new benchmark of 83 characters and 5,141 scenes from Fandom demonstrate significant improvements in role-playing performance, with codified profiles achieving higher NLI scores and enabling smaller models to match larger ones when combined with codified logic.

## Method Summary
The approach converts natural language character profiles into executable Python functions through a codification engine (GPT-4.1). These functions use a `parse_by_scene` structure with embedded `check_condition` helper functions that answer semantic questions about scenes. The role-playing LLM (Llama-3.1-8B) receives the scene plus triggered statements from the codified profile to generate responses. The system includes an optional distilled condition checker (DeBERTa-0.1B) trained on labeled examples for efficiency. Characters are segmented at the paragraph level, and the framework supports profile evolution through storyline-based updates when NLI contradictions are detected.

## Key Results
- Codified profiles achieve 69.28% average NLI score versus 65.28% for textual profiles on the Fandom benchmark
- 1B-parameter models with codified profiles perform comparably to 8B-parameter models with textual profiles
- Hybrid ensemble of text and code profiles further improves performance across diverse character types
- The approach successfully addresses LLM biases in randomness generation and improves behavioral consistency

## Why This Works (Mechanism)

### Mechanism 1: Reasoning Offloading via Discriminative Conditioning
The system shifts the burden from generative reasoning to discriminative classification by compiling character logic into explicit condition checks. Instead of prompting an LLM to "think" through a scene using a long textual profile, the system pre-compiles logic into a function that forces the LLM to only output probabilities for "yes/no/unknown" tokens. This assumes LLMs are more reliable at binary classification tasks than open-ended generative planning. Evidence shows codified profiles enable 1B-parameter models to match 8B+Text performance.

### Mechanism 2: Hard Determinism for Behavioral Consistency
Executable control structures enforce behavioral persistence better than soft semantic attention over text prompts. Textual profiles rely on the LLM's attention mechanism to recall and apply rules, which is subject to probability and context-window noise. Codified profiles use hard logic: if `check_condition` returns True, a specific statement is guaranteed to be appended to triggered statements. This separates "what describes the character" from "what the character must do," ensuring character fidelity through explicit rule adherence.

### Mechanism 3: Externalized Stochasticity
Explicit randomization functions (e.g., `random.choice`) simulate specific behavioral probability distributions more accurately than LLM temperature settings. LLMs have inherent biases in their output distribution. By replacing LLM sampling decisions with Python's `random` library, the system bypasses the model's learned priors and enforces mathematically precise distributions. This addresses the need for variability that contradicts the LLM's natural statistical tendencies.

## Foundational Learning

- **Neuro-Symbolic Integration (Program-of-Thoughts)**: The paper treats the LLM as a semantic sensor inside a Python script. Understanding how neural probabilities map to boolean logic is crucial. *Quick check*: How does `check_condition` convert continuous LLM logits into a discrete Boolean value for the `if` statement?

- **Chain-of-Thought vs. Compilation**: Standard prompting uses runtime CoT (expensive, inconsistent). This paper uses "Compilation" (converting text to code once). *Quick check*: In this architecture, when does the majority of the "reasoning" about character rules occurâ€”during the user interaction or before it?

- **Natural Language Inference (NLI)**: The evaluation relies entirely on NLI scores rather than exact string matches. *Quick check*: If the model generates a response that is "neutral" to the ground truth, how does the NLI scorer penalize it compared to a "contradiction"?

## Architecture Onboarding

- **Component map**: Codification Engine (Pre-process) -> Runtime Executor -> Semantic Condition Checker -> Role-Play LLM
- **Critical path**: The Condition Checker is explicitly noted as a potential bottleneck. The proposed optimization is distilling this capability into a 0.1B model (DeBERTa), which preserves logic execution speed.
- **Design tradeoffs**: Paragraph-level segmentation is recommended (Sections too broad, Sentences too granular). Code is harder to update than text, requiring the "Evolving by Storyline" feedback loop where NLI failures trigger code updates.
- **Failure signatures**: Watch for infinite loops from excessive `check_condition` calls, fragile logic branching from poorly phrased questions, and information loss during codification of nuanced emotional content.
- **First 3 experiments**: 1) Reproduce the "Paper-Scissors-Stone" Test to verify LLM bias and `random.choice` fixes. 2) Implement Condition Checker Distillation by replacing heavy LLM calls with fine-tuned BERT. 3) Run an evolving profile test (e.g., Tyrion Lannister) to verify the "Issue Detection Prompt" successfully patches faulty logic.

## Open Questions the Paper Calls Out

1. **Hybrid strategies for emotional vs. logical characters**: How can hybrid approaches balance the interpretability of codified profiles with the fidelity of textual profiles, particularly for emotionally expressive characters? The paper notes codified profiles excel for logic-heavy characters while textual profiles perform better for emotionally expressive ones.

2. **World-level role-playing extension**: Can codified profiles support world-level role-playing by codifying environmental rules, societal structures, or magical systems? The paper suggests this as a promising direction for narrative simulation but lacks benchmarks for environmental reactivity.

3. **Additional operators for complex behaviors**: What operators beyond `check_condition` would enable arithmetic reasoning, skill activation, or spatial navigation in role-playing? The framework could include arithmetic operations for health management, procedures for skill activation, or functions for spatial movement.

## Limitations

- Benchmark curation bias from specific anime/light novel sources may limit generalizability to broader character types
- Heavy dependency on GPT-4.1's codification accuracy without error rate analysis for the conversion step
- Fragility in the `check_condition` function with 70.53% consistency between GPT-4.1 and distilled checker, raising concerns about cascading errors
- Limited treatment of dynamic characters that evolve significantly over time or exhibit complex psychological development

## Confidence

**High Confidence**: The reasoning offloading and behavioral consistency mechanisms are well-supported by empirical results (69.28% vs 65.28% NLI scores, 1B model parity with 8B+Text models).

**Medium Confidence**: The externalized stochasticity mechanism is theoretically sound with convincing evidence from the "Paper-Scissors-Stone" test, but practical value depends on whether characters actually require precise probability distributions.

**Low Confidence**: The approach's scalability to diverse character types, complex emotional states, and evolving personalities remains unproven, particularly given the focus on anime/light novel characters with relatively straightforward behavioral patterns.

## Next Checks

1. **Error propagation analysis**: Systematically inject errors into `check_condition` outputs (e.g., flip 10% of responses) and measure how this affects downstream role-playing quality to quantify logic chain brittleness.

2. **Cross-domain character testing**: Apply codified profiles to characters from literature, film, or historical figures with complex psychological profiles to assess domain generalization limits compared to the anime/light novel baseline.

3. **Dynamic character evolution test**: Implement a character that undergoes significant personality change (e.g., Walter White from Breaking Bad) to test whether the codified profile can handle evolution through the "Evolving by Storyline" mechanism or fails catastrophically when character logic fundamentally shifts.