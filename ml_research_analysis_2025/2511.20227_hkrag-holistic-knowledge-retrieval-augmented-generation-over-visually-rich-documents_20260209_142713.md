---
ver: rpa2
title: 'HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over Visually-Rich
  Documents'
arxiv_id: '2511.20227'
source_url: https://arxiv.org/abs/2511.20227
tags:
- knowledge
- documents
- retrieval
- document
- hkrag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces HKRAG, a novel framework for Retrieval-Augmented
  Generation (RAG) over visually-rich documents (VRDs) that addresses the critical
  problem of existing methods'' bias towards retrieving only salient knowledge while
  neglecting fine-print details. HKRAG proposes two key components: a Hybrid Masking-based
  Holistic Retriever that employs explicit masking strategies to separately model
  and enhance both salient and fine-print knowledge, and an Uncertainty-guided Agentic
  Generator that dynamically assesses retrieval uncertainty and adaptively integrates
  knowledge streams.'
---

# HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over Visually-Rich Documents

## Quick Facts
- arXiv ID: 2511.20227
- Source URL: https://arxiv.org/abs/2511.20227
- Reference count: 40
- Key outcome: HKRAG achieves state-of-the-art performance on DocumentVQA benchmarks by addressing bias toward salient knowledge through hybrid masking and uncertainty-guided generation

## Executive Summary
This paper introduces HKRAG, a novel framework for Retrieval-Augmented Generation over visually-rich documents that addresses the critical problem of existing methods' bias towards retrieving only salient knowledge while neglecting fine-print details. HKRAG proposes two key components: a Hybrid Masking-based Holistic Retriever that employs explicit masking strategies to separately model and enhance both salient and fine-print knowledge, and an Uncertainty-guided Agentic Generator that dynamically assesses retrieval uncertainty and adaptively integrates knowledge streams. Extensive experiments on four DocumentVQA benchmarks demonstrate that HKRAG achieves new state-of-the-art performance in both zero-shot and supervised settings, showing consistent improvements across single-pool and all-pool retrieval settings.

## Method Summary
HKRAG uses Phi3-V as its backbone vision-language model, fine-tuned with a hybrid masking strategy that combines dense and sparse alignment losses to separate salient and fine-print knowledge. The framework employs an agentic generation pipeline with four agents: Pruner (selects minimal sufficient documents), Judger (calculates normalized entropy to route queries), Decoupler (performs iterative reasoning to mine fine-print details anchored on salient knowledge), and Summarizer (final synthesis). The retriever is fine-tuned using LoRA with AdamW optimizer, batch size 64, for 1 epoch, while the generator uses an uncertainty threshold of 0.8 to decide when to invoke deeper reasoning.

## Key Results
- Achieves 87.6 nDCG@5 on ChartQA and 82.1 nDCG@5 on SlideVQA in zero-shot scenarios
- Reaches 72.4% accuracy on InfoVQA and 57.8% on DUDE in supervised settings
- Demonstrates consistent improvements across both single-pool and all-pool retrieval settings
- Outperforms existing methods by addressing the inadequate holistic-knowledge problem in VRD RAG

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Masking for Salient/Fine-Print Separation
Explicitly masking document embeddings to separate salient and fine-print signals mitigates retrieval bias. The Hybrid Masking-based Holistic Retriever computes a correlation matrix between query and document embeddings, generating dense masks to amplify high-correlation (salient) features and sparse masks to preserve low-correlation (fine-print) features. These masks modulate the InfoNCE loss, forcing the encoder to align queries with both prominent and detailed visual elements.

### Mechanism 2: Uncertainty-Guided Query Routing
Using answer entropy to route queries prevents unnecessary complex reasoning on simple queries. The Uncertainty-guided Agentic Generator calculates normalized entropy of token probabilities from initial generation. Low entropy (LQP) skips complex reasoning, while high entropy (HQP) routes to iterative reasoning loops, reserving computational resources for queries where retrieved context is ambiguous.

### Mechanism 3: Anchored Fine-Print Extraction
Anchoring fine-print extraction on salient context improves retrieval of subtle details. The Decoupler agent uses readily available salient knowledge as an anchor to guide iterative mining of fine-print knowledge, preventing conflation of general context with specific details and ensuring semantic coherence during detail extraction.

## Foundational Learning

- **Concept:** InfoNCE / Contrastive Loss
  - **Why needed here:** The paper modifies standard InfoNCE loss using masks ($L_{DIN}, L_{SIN}$). Understanding contrastive learning is essential for grasping how the hybrid mask changes gradient updates for fine-print features.
  - **Quick check question:** How does applying a binary mask $M_H$ to the document embedding $v_d$ before computing the similarity score $sim(v_q, v_d \cdot M_H)$ change the gradient update for "fine-print" features?

- **Concept:** Entropy in Sequence Generation
  - **Why needed here:** The "Judger" agent relies on normalized entropy $H'(\hat{w})$ to route the query. Distinguishing between "probability of a token" and "entropy of a sequence" is critical for tuning the uncertainty threshold.
  - **Quick check question:** If a model generates an answer with probability distribution $P = [0.9, 0.05, 0.05]$ over tokens, is the entropy high or low? Would the Judger route this to the Decoupler?

- **Concept:** Visual Document Understanding (VRD) Challenges
  - **Why needed here:** The paper targets the "modality gap" in text-centric RAG. Understanding that OCR often misses layout/visual context explains why the paper uses a vision-language model (Phi3V) rather than a text encoder.
  - **Quick check question:** Why does the paper argue that concatenating retrieved text (standard RAG) is insufficient for charts or infographics?

## Architecture Onboarding

- **Component map:** Phi3-V -> Hybrid Masking module -> Fine-tuned Encoder -> Pruner -> Judger -> Decoupler -> Summarizer
- **Critical path:** The quality of the Hybrid Mask ($M_H$). If the mask does not successfully isolate sparse/dense features during training, the Retrieval top-k will be biased, and the Generator's Decoupler will have nothing to work with.
- **Design tradeoffs:**
  - Fixed Top-k vs. Dynamic Pruner: Moves away from fixed top-k to a "minimal sufficient set," trading retrieval recall precision for reduced noise in the generator context window
  - Masking Complexity: Introducing sparse/dense masks adds computational overhead to the retrieval step compared to standard vector search
- **Failure signatures:**
  - High Latency: Likely caused by Decoupler entering infinite loops or too many iterations because the Judger threshold is too sensitive
  - Saliency Bias Persists: If $\alpha$ is set incorrectly, the mask may fail to preserve low-correlation features, resulting in retrieval of only headlines/large text
- **First 3 experiments:**
  1. Retrieval Ablation: Run the retriever with only Dense Loss ($L_{DIN}$) vs. only Sparse Loss ($L_{SIN}$) to verify both are necessary for performance jump
  2. Threshold Sensitivity: Vary the uncertainty threshold $h$ (currently 0.8) to observe trade-off between accuracy and average latency
  3. Visual Masking Validation: Visualize the $M_H$ mask on sample documents to confirm Dense regions align with headlines/charts and Sparse regions align with footnotes/axis labels

## Open Questions the Paper Calls Out

- **Question:** How does HKRAG's performance degrade on documents where "fine-print" importance is not correlated with visual saliency or layout features (e.g., uniform-density legal contracts)?
- **Question:** Does the iterative reasoning process in the "Decoupler" agent increase the risk of hallucination compared to single-pass generation when retrieval noise is high?
- **Question:** Is the fixed uncertainty threshold ($h=0.8$) universally optimal across different document domains, or does it require dynamic calibration?

## Limitations
- Assumes statistical separability of "salient" and "fine-print" features in embedding space may not hold across all document types
- Critical hyperparameters (α and β) remain unspecified, making exact reproduction challenging
- Entropy-based uncertainty routing may fail when model is "confidently wrong" (low entropy but incorrect answer)

## Confidence
- **High Confidence:** Core architecture design and empirical results showing consistent improvements across four benchmarks
- **Medium Confidence:** Theoretical justification for separating salient and fine-print signals, though effectiveness depends on undisclosed hyperparameters
- **Low Confidence:** Claim about Decoupler's anchored fine-print extraction mechanism lacks implementation details

## Next Checks
1. Conduct quantitative analysis of correlation score distributions to verify statistical separability of "salient" and "fine-print" features
2. Systematically vary uncertainty threshold (h) and sparse mask loss weight (β) to identify optimal settings and trade-offs
3. Visualize learned hybrid masks on sample documents to confirm alignment with intuitive notions of "salient" versus "fine-print"