---
ver: rpa2
title: Probabilistic Forecasting for Building Energy Systems using Time-Series Foundation
  Models
arxiv_id: '2506.00630'
source_url: https://arxiv.org/abs/2506.00630
tags:
- energy
- forecasting
- data
- chronos
- building
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the use of time-series foundation models
  (TSFMs) for probabilistic forecasting in building energy systems, particularly when
  limited data from the target building is available. The study evaluates three TSFMs
  (Moirai, TimesFM, Chronos) and compares their zero-shot performance with full and
  parameter-efficient fine-tuning approaches, including low-rank adaptation (LoRA),
  against state-of-the-art deep forecasting models like DeepAR, N-BEATS, and TFT.
---

# Probabilistic Forecasting for Building Energy Systems using Time-Series Foundation Models

## Quick Facts
- arXiv ID: 2506.00630
- Source URL: https://arxiv.org/abs/2506.00630
- Reference count: 24
- Fine-tuned TSFMs outperform state-of-the-art models in building energy forecasting with limited data

## Executive Summary
This paper investigates time-series foundation models (TSFMs) for probabilistic forecasting in building energy systems, particularly when limited target building data is available. The study evaluates three TSFMs (Moirai, TimesFM, Chronos) and compares their zero-shot performance with full and parameter-efficient fine-tuning approaches, including low-rank adaptation (LoRA), against state-of-the-art deep forecasting models. Experiments use real-world data from a commercial net-zero energy building across multiple zones and seasons. Results show that while zero-shot TSFMs are generally suboptimal, fine-tuning—especially with LoRA—significantly improves forecasting accuracy while reducing computational costs.

## Method Summary
The study fine-tunes time-series foundation models (TSFMs) including Chronos, Moirai, and TimesFM using low-rank adaptation (LoRA) on building energy data from a commercial net-zero energy building. The methodology employs 15-minute sampled data with 24-hour context windows to forecast 6-hour horizons. LoRA ranks of 4, 16, and 64 are tested during fine-tuning. The approach is compared against zero-shot TSFM performance and traditional deep learning models (DeepAR, N-BEATS, TFT) trained from scratch using GluonTS. Training uses 3 months of data with testing on the subsequent 40 workdays per season.

## Key Results
- Zero-shot TSFM performance is generally suboptimal compared to models specifically trained on downstream datasets
- Fine-tuning with LoRA substantially reduces computational costs without sacrificing accuracy
- Fine-tuned TSFMs consistently outperform benchmarks in accuracy, robustness, and generalization, even with limited training data

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning TSFMs significantly outperforms zero-shot inference for building energy forecasting. Pre-training exposes the model to diverse temporal patterns across domains, but zero-shot fails when distribution shift between pre-training and target building data is large. Fine-tuning adapts the model's learned representations to domain-specific patterns (e.g., work-week periodicity, occupancy schedules) by updating weights on limited target data. The target building signals must share latent structure with pre-training data for this to work effectively.

### Mechanism 2
LoRA-based fine-tuning achieves comparable or better accuracy than full fine-tuning while reducing computational cost. LoRA constrains weight updates to a low-rank subspace, preserving pre-trained knowledge while adapting query/value projections in attention layers. This prevents overfitting on small datasets and reduces trainable parameters. The task-specific adaptations must lie in a low-dimensional subspace of the full parameter space for LoRA to be effective.

### Mechanism 3
TSFMs degrade more gracefully than traditional deep models under limited training data (<2 months). Pre-training provides informative priors that regularize learning. When target data is scarce, the model can leverage cross-domain patterns learned during pre-training rather than overfitting to limited samples. Pre-training datasets must contain sufficient diversity to provide useful priors for downstream tasks.

## Foundational Learning

- **Concept: Zero-shot vs. Fine-tuning**
  - Why needed here: The paper's central comparison; zero-shot means using pre-trained weights directly, fine-tuning means updating weights on target data.
  - Quick check question: Can you explain why zero-shot fails when context windows are too short?

- **Concept: Transformer Self-Attention**
  - Why needed here: All three TSFMs use transformer architectures; LoRA modifies attention weights.
  - Quick check question: What do Q, K, V matrices represent, and where does LoRA inject adaptations?

- **Concept: Probabilistic Forecasting Metrics**
  - Why needed here: Paper evaluates both point (MASE, RMSSE) and distributional metrics (wQL, MSIS); understanding these is essential for interpreting results.
  - Quick check question: Why does MSIS penalize both wide prediction intervals and missed observations differently?

## Architecture Onboarding

- **Component map:** Input (context window C=96 timesteps) → TSFM Encoder (pre-trained transformer: Moirai/TimesFM/Chronos) → [LoRA adapters: ω_Q + δω_Q, ω_V + δω_V] (if fine-tuning) → Probabilistic Head → Output distribution π_θ(→Y_{t,H}|←Y_{t,C})

- **Critical path:**
  1. Select TSFM (Chronos recommended based on paper's zero-shot comparison)
  2. Prepare data: 15-min intervals, 24-hr context → 6-hr prediction
  3. Fine-tune with LoRA (rank r=4–16, 1000 iterations)
  4. Evaluate on held-out test periods (40 workdays per season)

- **Design tradeoffs:**
  - Context length vs. compute: Longer context improves zero-shot (3–5 days optimal) but increases O(C²) attention cost
  - LoRA rank vs. expressiveness: Lower rank (r=4) reduces FLOPS 33%, speeds training 2.3×; higher rank gives marginal gains
  - FullFT vs. PEFT: FullFT risks overfitting on small data; PEFT preserves pre-trained knowledge

- **Failure signatures:**
  - High zero-shot error with 24-hr context → extend to 3–5 days
  - FullFT underperforms PEFT → model overfitting, reduce rank or use PEFT
  - Performance degrades on unseen zones → increase fine-tuning data diversity

- **First 3 experiments:**
  1. **Baseline zero-shot:** Run Chronos/Moirai/TimesFM with 24-hr context on held-out test data; measure MASE/wQL
  2. **Context ablation:** Vary context window (1, 3, 5, 20 days) to find optimal zero-shot context length
  3. **LoRA fine-tuning:** Fine-tune Chronos with LoRA r=4 on 3 months data; compare FullFT vs. PEFT on accuracy and training time

## Open Questions the Paper Calls Out
1. Can TSFMs be effectively adapted for multivariate forecasting to capture correlations among multiple building signals?
2. Does integrating TSFMs into real-time control frameworks like Model Predictive Control (MPC) improve policy optimality without compromising safety?
3. Do fine-tuned TSFMs generalize effectively to diverse building types and climatic conditions beyond a commercial net-zero office building?

## Limitations
- Limited evaluation across diverse building types (single commercial building dataset)
- No comparison with ensemble methods or hybrid TSFM+traditional approaches
- Uncertainty around optimal LoRA rank selection across different energy signals

## Confidence
- **High confidence:** LoRA fine-tuning outperforms zero-shot and traditional models; computational efficiency claims
- **Medium confidence:** Claims about graceful degradation with limited data; cross-zone generalization benefits
- **Low confidence:** Comparative rankings of different TSFMs (Chronos vs Moirai vs TimesFM) without broader domain testing

## Next Checks
1. Test performance on multi-building datasets to verify generalization claims across different building typologies and operational patterns
2. Conduct systematic ablation studies varying LoRA rank and training duration to optimize the trade-off between accuracy and computational efficiency
3. Evaluate robustness to data quality issues (missing values, sensor drift) that commonly occur in real building management systems