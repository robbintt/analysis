---
ver: rpa2
title: Measuring Informativeness Gap of (Mis)Calibrated Predictors
arxiv_id: '2507.12094'
source_url: https://arxiv.org/abs/2507.12094
tags:
- predictor
- predictors
- informativeness
- calibrated
- calibration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a decision-theoretic framework for comparing
  the informativeness of predictors, including those that may be miscalibrated. The
  core contribution is the informativeness gap, which quantifies the maximum normalized
  payoff advantage one predictor offers over another across all decision-making tasks.
---

# Measuring Informativeness Gap of (Mis)Calibrated Predictors

## Quick Facts
- **arXiv ID**: 2507.12094
- **Source URL**: https://arxiv.org/abs/2507.12094
- **Reference count**: 40
- **Primary result**: Introduces a decision-theoretic framework quantifying the maximum normalized payoff advantage one predictor offers over another across all decision-making tasks, even when both are miscalibrated.

## Executive Summary
This paper introduces the informativeness gap as a decision-theoretic measure for comparing probabilistic predictors, including those that may be miscalibrated. The core contribution is a framework that quantifies the maximum normalized payoff advantage one predictor offers over another across all decision-making tasks. The authors provide a dual characterization showing this gap equals a relaxed variant of the earth mover's distance between prediction distributions. This measure is complete, sound, and can be estimated sample-efficiently. Experiments with LLM-based forecasters demonstrate that the informativeness gap offers a more decision-relevant alternative to traditional metrics like Brier score and ECE, providing a principled lens for evaluating how calibration post-processing affects downstream decision usefulness.

## Method Summary
The paper uses a decision-theoretic framework where the informativeness gap between two predictors is defined as the maximum normalized payoff advantage one offers over the other across all decision-making tasks. For estimation, the authors develop a sample-efficient approach using the calibration-adjusted super-cumulative distribution function (CA-SCDF) representation, which converts the infinite-dimensional optimization into a one-dimensional maximization. The method requires prediction-outcome pairs for both predictors and can be computed by discretizing thresholds over the probability interval. The framework is validated on weather and Bitcoin prediction tasks using four LLM-based forecasters (GPT-4o-mini, DeepSeek-V3.2, Gemini 2.0 Flash-Lite, Qwen-Plus) with specific JSON-mode prompting to extract calibrated probabilities.

## Key Results
- The informativeness gap provides a complete decision-theoretic order for comparing predictors, subsuming existing measures like U-Calibration and Calibration Decision Loss
- The gap admits a dual characterization as a relaxed earth mover's distance, enabling efficient computation and sample-efficient estimation with O(1/ε²) samples
- Experiments show the gap is more decision-relevant than traditional metrics like Brier score and ECE, particularly for evaluating calibration post-processing effects
- LLM-based predictors exhibit varying informativeness profiles where miscalibrated predictors can outperform calibrated ones in decision-making tasks

## Why This Works (Mechanism)

### Mechanism 1: Decision-Theoretic Gap via Normalized Payoff Supremum
- **Claim**: The informativeness gap quantifies the maximum decision-relevant advantage one predictor offers over another, even when both are miscalibrated.
- **Mechanism**: InfoGap[μ,ν] = sup over all payoff-normalized decision problems of (Payoff[μ] - Payoff[ν]), where normalization constrains |u(a,1)−u(a,0)|≤1. This captures worst-case utility advantage across tasks where a decision-maker naively best-responds to predictions.
- **Core assumption**: Decision-makers trust and best-respond to provided predictions; the normalization bounds preserve meaningful cross-task comparison without collapsing to Blackwell's all-utility-functions definition.
- **Evidence anchors**:
  - [abstract]: "defined as the maximum normalized payoff advantage one predictor offers over the other across all decision-making tasks"
  - [Section 2.2, Definition 2.2]: Formal definition with bounded utility difference constraint
  - [corpus]: Related work on U-Calibration (Kleinberg et al.) and Calibration Decision Loss (Hu & Wu) use similar decision-theoretic foundations, but InfoGap generalizes both by comparing arbitrary predictor pairs
- **Break condition**: If decision-makers don't follow best-response behavior, or if the normalization is inappropriate for the application domain, the decision-relevance of the gap may be compromised.

### Mechanism 2: Dual Characterization via Relaxed Earth Mover's Distance
- **Claim**: The optimization over all decision problems has a dual formulation as a relaxed earth mover's distance between prediction distributions.
- **Mechanism**: Strong duality transforms the supremum over 1-Lipschitz convex interim utility functions into an infimum over transportation plans. The key insight is that the coupling constraint can be relaxed to a flow conservation constraint, incorporating calibration adjustments through outcome functions κ_μ(p), κ_ν(p).
- **Core assumption**: The true outcome frequencies conditional on predictions are well-defined and can be estimated; the linear program has strong duality.
- **Evidence anchors**:
  - [abstract]: "equivalent to a relaxed variant of the earth mover's distance (EMD) between prediction distributions"
  - [Section 3, Theorem 3.1]: Proves InfoGap[μ,ν] = REMD[f_μ,f_ν] for perfectly calibrated predictors via strong duality
  - [Section 4, Theorem 4.1]: Extends to REMD^MISC[f_μ,f_ν,κ_μ,κ_ν] for miscalibrated predictors with CA-SCDF representation
  - [corpus]: Blasiok et al. (2023) on distance-to-calibration uses related EMD concepts; the "Persuasive Calibration" paper (arXiv 2504.03211) shares decision-theoretic calibration themes
- **Break condition**: The dual characterization fails if the primal optimization doesn't satisfy strong duality conditions, or if the flow set constraints are inappropriate for the predictor structures.

### Mechanism 3: Sample-Efficient Estimation via CA-SCDF Representation
- **Claim**: InfoGap can be estimated with O(1/ε²) samples using the calibration-adjusted super-cumulative distribution function representation.
- **Mechanism**: The CA-SCDF formulation S_μ(t) + ∫₀ᵗ(p−κ_μ(p))·f_μ(p)dp converts the infinite-dimensional LP into a one-dimensional maximization over thresholds t∈[0,1]. Both function families {(t−p)+} and {(p−y)·1{p≤t}} have pseudo-dimension 1, enabling uniform convergence with polynomial samples.
- **Core assumption**: Samples are drawn i.i.d. from the prediction-only access model; the function classes have bounded complexity.
- **Evidence anchors**:
  - [Section 5, Theorem 5.1]: Explicit sample complexity O(1/ε²·ln(1/δ)) with concrete estimator construction
  - [Section 4, Definition 4.2]: CA-SCDF definition showing how calibration error integrates into the SCDF
  - [corpus]: Weak corpus evidence—no prior work directly on CA-SCDF representation found; this appears to be a novel structural contribution of the paper
- **Break condition**: Estimation accuracy degrades if κ_μ(p) is highly non-smooth (requiring many samples per prediction value) or if samples are not drawn i.i.d. from the target distribution.

## Foundational Learning

### Concept 1: Blackwell Informativeness and Partial Orders
- **Why needed here**: InfoGap generalizes the classical Blackwell framework from perfectly calibrated predictors to miscalibrated ones. Understanding that Blackwell informativeness provides only a partial order (not all predictors are comparable) motivates the need for a cardinal measure like InfoGap.
- **Quick check question**: If predictor μ is Blackwell more informative than ν, what is InfoGap[ν,μ]? Answer: Zero (Proposition 2.4).

### Concept 2: Calibration Error vs. Decision Loss
- **Why needed here**: Traditional measures like ECE quantify miscalibration but don't directly capture decision usefulness. The paper's example (weather predictor ν calibrated but uninformative vs. μ₁ miscalibrated but informative) shows why calibration alone is insufficient for deployment decisions.
- **Quick check question**: Can a miscalibrated predictor yield higher expected utility than a perfectly calibrated one? Answer: Yes—the paper's Example 1.1 demonstrates this explicitly.

### Concept 3: Earth Mover's Distance (Wasserstein Distance)
- **Why needed here**: The dual characterization of InfoGap uses a relaxed EMD variant. Understanding EMD as an optimal transportation cost between distributions helps interpret REMD's role and why the relaxation is necessary for decision-relevance.
- **Quick check question**: Why can't standard EMD[f_μ,f_ν] replace InfoGap[μ,ν]? Answer: The multiplicative gap can be arbitrarily large (Example 3.3: EMD can be 0.25 while InfoGap is 0).

## Architecture Onboarding

### Component Map
[Sample Access] → [Empirical Distributions] → [CA-SCDF Estimation]
                                              ↓
[Decision Problem Specification] → [LP Formulation] → [InfoGap Computation]
                                              ↑
[Outcome Function Estimation κ_μ(p)] ─────────┘

### Critical Path
1. **Data collection**: Gather prediction-outcome pairs (p_i, y_i) for both predictors μ, ν under prediction-only access
2. **Distribution estimation**: Compute empirical CDFs F_μ, F_ν and outcome frequencies κ_μ(p), κ_ν(p) (e.g., via binning)
3. **CA-SCDF computation**: For each threshold t, compute S_μ(t) + ∫₀ᵗ(p−κ_μ(p))·f_μ(p)dp and similarly for ν
4. **Maximization**: Find t* = argmax_t(CA-SCDF_μ(t) - CA-SCDF_ν(t)); InfoGap = 2 × this maximum

### Design Tradeoffs
- **Binning granularity vs. sample efficiency**: Finer bins for κ_μ(p) estimation improve accuracy but require more samples; paper's O(1/ε²) bound assumes sufficient data per prediction region
- **Coupling set vs. flow set**: Standard coupling Π(f_μ,f_ν) yields a metric (EMD) but can be arbitrarily far from InfoGap (Proposition 4.3); flow set is correct but more complex to optimize
- **Directionality**: InfoGap[μ,ν] ≠ InfoGap[ν,μ] in general; both directions may be needed for full comparison

### Failure Signatures
- **Zero or near-zero InfoGap when predictors differ significantly**: Check if outcome function estimation failed (insufficient samples per prediction bin)
- **InfoGap exceeds theoretical bounds (>1)**: Verify utility normalization constraint implementation
- **CA-SCDF curves don't match empirical reliability diagrams**: Debug outcome frequency estimation

### First 3 Experiments
1. **Validation on synthetic data**: Generate predictors with known InfoGap (e.g., Example 1.1 variants) and verify estimator convergence vs. ground truth computed via LP
2. **Sensitivity to sample size**: Plot estimation error |InfoGap - ĬnfoGap| vs. n to validate O(1/ε²) sample complexity empirically
3. **Comparability analysis**: For a set of real predictors (e.g., LLM forecasters), compute pairwise InfoGap matrices and measure fraction of s-comparable pairs vs. tolerance s (replicating Figure 3 methodology)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can InfoGap-regularization be extended to non-parametric post-processing steps like discretization?
- Basis: [explicit] Page 36 suggests "extending InfoGap-relevant design beyond the scaling step, for example, to discretization choices".
- Why unresolved: Empirical results show regularization improves parametric methods (e.g., temperature scaling) but has limited impact on scaling binning due to the subsequent discretization.
- What evidence would resolve it: Development of a discretization algorithm that minimizes InfoGap degradation while maintaining calibration.

### Open Question 2
- Question: What is the theoretical connection between the InfoGap flow set and mechanism design flow constraints?
- Basis: [explicit] Page 22 states: "We conjecture that there might be a deeper connection between our model and the mechanism design model, which we leave for future work."
- Why unresolved: The paper notes the structural similarity of the "flow conservation" constraints to mechanism design but does not prove a formal link.
- What evidence would resolve it: A formal reduction or duality proof mapping the InfoGap optimization problem to a mechanism design problem (e.g., revenue maximization).

### Open Question 3
- Question: Does the multiplicative informativeness gap admit a similar dual characterization to the additive version?
- Basis: [explicit] Page 4 defines the multiplicative gap but states: "However, we focus on and study the additive version".
- Why unresolved: The paper's main theoretical contribution (Theorem 4.1) characterizes the additive gap; the multiplicative variant's properties remain unexplored.
- What evidence would resolve it: A dual characterization for the multiplicative gap or sample complexity bounds for its estimation.

## Limitations
- **Sparse prediction regions**: Sample efficiency claims may not hold when predictors output only extreme probabilities or when events are rare
- **Computational complexity**: The flow-set optimization for REMD^MISC is more complex than standard EMD, potentially limiting scalability
- **Limited experimental scope**: Only four LLM models tested on two datasets, making generalizability to other domains uncertain

## Confidence

**High Confidence**: The decision-theoretic foundation and dual characterization (Mechanism 1 and 2) are mathematically rigorous, with formal proofs provided for the main theorems. The connection to existing calibration literature is well-established.

**Medium Confidence**: The sample-efficient estimation framework (Mechanism 3) appears sound, but practical implementation details like binning strategy and handling of sparse prediction regions could affect performance. The theoretical O(1/ε²) bound assumes ideal conditions that may not hold in practice.

**Low Confidence**: The experimental results on real LLM forecasters are limited in scope. With only four models tested on two datasets, the generalizability to other domains and model types remains uncertain. The comparison with traditional metrics (Brier score, ECE) is informative but doesn't establish causal relationships between InfoGap and downstream decision performance.

## Next Checks

1. **Robustness to sparse predictions**: Test the estimator on synthetic data where one predictor outputs only extreme probabilities (near 0 or 1) to validate sample efficiency claims under challenging conditions.

2. **Decision-making simulation**: Create a controlled decision task where the "optimal" predictor is known, then measure whether InfoGap correctly identifies it while traditional metrics fail, as suggested by Example 1.1.

3. **Cross-dataset generalization**: Apply the framework to a third dataset (e.g., medical diagnosis predictions or sports outcomes) to assess whether the observed advantages over Brier score and ECE persist across domains.