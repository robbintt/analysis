---
ver: rpa2
title: A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic Data Collection
  in Multi-Agent Collaborative Environments Driven by LLMs
arxiv_id: '2502.00022'
source_url: https://arxiv.org/abs/2502.00022
tags:
- human
- workload
- data
- performance
- wella
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel method for automating the collection
  of human reliability analysis (HRA) data in multi-agent collaborative environments
  using fine-tuned large language models (LLMs). Traditional HRA data collection methods
  are labor-intensive and fail to capture dynamic features, prompting the development
  of the WELLA (Workload Estimation with LLMs and Agents) framework.
---

# A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic Data Collection in Multi-Agent Collaborative Environments Driven by LLMs

## Quick Facts
- arXiv ID: 2502.00022
- Source URL: https://arxiv.org/abs/2502.00022
- Reference count: 40
- Primary result: LLM-driven framework WELLA achieves R² of 0.9012 and RMSE of 8.1507 for dynamic HRA workload estimation

## Executive Summary
This study introduces WELLA, a novel framework that automates human reliability analysis (HRA) data collection in multi-agent collaborative environments using fine-tuned large language models (LLMs). Traditional HRA methods are labor-intensive and struggle to capture dynamic behavioral features. WELLA addresses these limitations by training LLMs on real-world operational data from high-temperature gas-cooled reactors (HTGRs), enabling dynamic simulation of human behavior and cognitive load in real-time. The framework provides accurate, flexible, and scalable workload estimates that outperform existing commercial LLM-based methods.

The research demonstrates that WELLA achieves superior prediction accuracy with a positive R² of 0.9012, RMSE of 8.1507, and MAE of 4.7000 in workload estimation tasks. This advancement significantly enhances safety and decision-making capabilities in complex, multi-agent systems by providing more reliable HRA data collection through automated synthetic data generation.

## Method Summary
WELLA employs fine-tuned large language models trained on real-world operational data from high-temperature gas-cooled reactors (HTGRs). The framework dynamically simulates human behavior and cognitive load in multi-agent collaborative environments through scenario-based synthetic data collection. The LLM is specifically trained to capture workload estimation patterns that reflect real operational conditions, enabling the system to generate accurate and dynamic HRA data without the labor-intensive processes required by traditional methods.

## Key Results
- Achieved positive R² of 0.9012 for workload estimation accuracy
- Demonstrated RMSE of 8.1507 and MAE of 4.7000 in prediction tasks
- Outperformed existing commercial LLM-based methods in HRA data collection accuracy

## Why This Works (Mechanism)
The WELLA framework leverages fine-tuned LLMs trained on domain-specific operational data to capture complex patterns in human behavior and cognitive load within multi-agent systems. By using real HTGR operational data for training, the model develops contextual understanding of how operators respond to various scenarios, enabling accurate workload estimation that reflects actual operational conditions. The LLM's ability to process and generate natural language descriptions of scenarios allows for dynamic simulation of human responses that traditional rule-based systems cannot achieve.

## Foundational Learning
- HTGR operational data: Essential for training LLMs on realistic human behavior patterns; quick check: verify data represents diverse operational scenarios
- Multi-agent collaborative dynamics: Understanding how multiple agents interact affects workload distribution; quick check: validate agent interaction modeling accuracy
- Cognitive load measurement: Critical for HRA accuracy; quick check: ensure cognitive load metrics align with established psychological models
- Scenario-based synthetic data generation: Enables scalable HRA data collection; quick check: verify synthetic data diversity matches real-world variability
- LLM fine-tuning methodology: Necessary for adapting general models to domain-specific tasks; quick check: assess fine-tuning effectiveness through ablation studies

## Architecture Onboarding
- Component map: HTGR operational data -> LLM fine-tuning -> Scenario generation -> Workload estimation -> HRA output
- Critical path: Data preprocessing -> Model training -> Scenario simulation -> Real-time workload prediction
- Design tradeoffs: Model complexity vs. inference speed; data quantity vs. training time; accuracy vs. generalization
- Failure signatures: Poor performance on rare scenarios; bias toward common patterns; overfitting to training data
- First experiments: 1) Validate baseline LLM performance on held-out HTGR data, 2) Test scenario generation diversity across operational conditions, 3) Compare workload predictions against human expert assessments

## Open Questions the Paper Calls Out
None provided in source material.

## Limitations
- Evaluation limited to HTGR operational data, restricting generalizability to other domains
- No comparative analysis against non-LLM baseline methods to isolate LLM contribution
- Scalability claims not empirically validated across different system sizes or complexity levels

## Confidence
- Workload estimation accuracy metrics (R², RMSE, MAE): **High**
- Dynamic simulation capability: **Medium** (based on limited temporal validation)
- Scalability claims: **Low** (not empirically validated)
- Generalization beyond HTGR context: **Low** (single-domain validation)

## Next Checks
1. Conduct cross-domain validation using HRA datasets from different industries (aviation, chemical processing) to assess generalizability
2. Implement ablation studies comparing WELLA against traditional HRA methods and non-LLM machine learning approaches to isolate the contribution of LLM technology
3. Perform stress testing with adversarial scenarios and rare event simulations to evaluate robustness in safety-critical edge cases