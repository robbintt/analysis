---
ver: rpa2
title: 'Transportability without Graphs: A Bayesian Approach to Identifying s-Admissible
  Backdoor Sets'
arxiv_id: '2505.12801'
source_url: https://arxiv.org/abs/2505.12801
tags:
- data
- backdoor
- sabs
- causal
- s-admissible
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Bayesian method to identify s-admissible
  backdoor sets for causal effect transportability without requiring the causal graph.
  The method leverages both observational data from the target domain and experimental
  data from a source domain, using the latter to inform the former via a Bayesian
  feature selection framework.
---

# Transportability without Graphs: A Bayesian Approach to Identifying s-Admissible Backdoor Sets

## Quick Facts
- **arXiv ID**: 2505.12801
- **Source URL**: https://arxiv.org/abs/2505.12801
- **Reference count**: 40
- **Key outcome**: Proposes a Bayesian method to identify s-admissible backdoor sets for causal effect transportability without requiring the causal graph, achieving AUCs up to 0.93 in simulated data.

## Executive Summary
This paper addresses the problem of estimating causal effects from a source domain to a target domain without access to the underlying causal graph. The authors develop a Bayesian method that identifies s-admissible backdoor sets (sABS) by leveraging both observational data from the target domain and experimental data from the source domain. The approach reframes transportability as a Bayesian feature selection problem, where the marginal likelihood of experimental data given observational data determines whether a conditioning set is s-admissible. The method achieves strong performance in both identification (AUC up to 0.93) and estimation (competitive binary cross-entropy) while avoiding the need for causal graph specification.

## Method Summary
The method identifies s-admissible backdoor sets through a two-step process. First, it learns the Markov boundary of the outcome variable from observational data in the target domain. Second, it performs a greedy search over subsets of this boundary to find the set that maximizes the marginal likelihood of experimental data given observational data. The core algorithm computes the posterior probability that a candidate set is an sABS by comparing the marginal likelihood of experimental data under the hypothesis that the set is s-admissible versus not s-admissible. For discrete data, closed-form Bayesian Dirichlet (BD) score formulas are used, while mixed data relies on MCMC sampling. The search terminates when no single-variable change improves the score, returning the set with highest posterior probability above a threshold.

## Key Results
- Achieves AUCs up to 0.93 in simulated data for identifying s-admissible backdoor sets
- Outperforms baseline methods in semi-synthetic experiments on the Hillstrom dataset
- Successfully rejects non-s-admissible sets (false positive rate near 0) across multiple experimental scenarios
- Demonstrates competitive binary cross-entropy scores compared to alternative approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: s-admissible backdoor sets can be found within the Markov boundary of the outcome
- Mechanism: The paper proves (Theorem 3) that if an s-admissible backdoor set (sABS) exists, a subset can always be found within the Markov boundary of the outcome variable, MB(Y). This drastically reduces the combinatorial search space for candidate conditioning sets.
- Core assumption: Faithfulness of the distribution to the causal graph (selection diagram)
- Evidence anchors:
  - [abstract] "We prove that if an s-admissible backdoor set exists, it can be found within the Markov boundary of the outcome, reducing the search space."
  - [Page 6] "Theorem 3. If there exists a set Z ⊂ O that is sABS for X, Y with respect to D, there exists a set Z* ⊆ MBG(Y) that is sABS for X, Y, with respect to D."
- Break condition: If faithfulness is violated, the Markov boundary learned from data may not correspond to the true MB(Y), potentially missing a valid sABS or including spurious variables.

### Mechanism 2
- Claim: Transportability can be reframed as a Bayesian feature selection problem
- Mechanism: The method compares the marginal likelihood of experimental data (De) given observational data (D*o) under two hypotheses: H=hZ (the set Z is an sABS) and H=¬hZ (Z is not an sABS). If Z is an sABS, P(Y|do(X),Z,s) = P(Y|X,Z,s*), meaning the source experimental and target observational conditional outcome distributions are the same. This allows the observational data to serve as a strong prior for evaluating the experimental likelihood, making it a Bayesian model comparison.
- Core assumption: sABS-faithfulness (Assumption 2), which rules out accidental cancellation of confounding and transportability biases
- Evidence anchors:
  - [abstract] "We develop a greedy algorithm that reframes transportability as a feature selection problem, selecting conditioning sets that maximize the marginal likelihood of experimental data given observational data."
  - [Page 5, Eq 4 & 5] Details the Bayes rule application and marginal likelihood computation P(De|D*o, HZ)
- Break condition: If experimental and observational sample sizes are extremely imbalanced in a way not handled by the Bayesian prior, or if the distributions are misspecified (e.g., non-conjugate with poor sampling), the marginal likelihood comparison may be unreliable.

### Mechanism 3
- Claim: A greedy search over subsets of the Markov boundary maximizes the probability of finding an optimal sABS
- Mechanism: Algorithm 2 (FindsABS) performs a greedy forward-backward search, adding or removing variables from the Markov boundary of Y. It scores candidate sets using the ProbsABS subroutine (computing P(hZ|De, D*o) via marginal likelihoods). The search terminates when no single-variable change improves the score, returning the set with the highest posterior probability above a threshold.
- Core assumption: The greedy search will not get stuck in a poor local optimum
- Evidence anchors:
  - [Page 6-7, Algorithm 2] "Algorithm 2 begins by identifying the Markov Boundary of Y... and then performs a greedy search to find the sABS Z* that maximizes the marginal likelihood..."
  - [Page 7, Theorem 5] Provides asymptotic guarantees that adding an irrelevant variable decreases the score, supporting the search's tendency toward parsimonious sets
- Break condition: The greedy nature means it may miss the globally optimal sABS if the scoring landscape is highly non-monotonic with respect to set inclusion.

## Foundational Learning

- Concept: **Backdoor Criterion and s-Admissibility**
  - Why needed here: The entire method is predicated on finding a set Z that satisfies both conditions simultaneously (Definition 1, sABS). Understanding these graphical criteria is necessary to interpret what the algorithm is trying to find and why it matters for unbiased estimation across domains.
  - Quick check question: If a set Z blocks all backdoor paths from treatment X to outcome Y in a graph G, does it guarantee that the causal effect of X on Y is transportable to a different domain G*? Why or why not?

- Concept: **Bayesian Model Comparison via Marginal Likelihood**
  - Why needed here: The core algorithmic innovation is using the marginal likelihood of experimental data to compare the "sABS" vs. "not sABS" hypotheses. One must understand how P(Data|Model) serves as a model selection score that naturally penalizes complexity.
  - Quick check question: In Bayesian model comparison, what happens to the marginal likelihood of a model that is flexible enough to fit any dataset versus a more constrained, simpler model when both fit the data equally well?

- Concept: **Markov Boundary (MB)**
  - Why needed here: The method's key efficiency gain (Theorem 3) is restricting the search for an sABS to the Markov boundary of Y. Knowing what the MB is (parents, children, and co-parents/spouses of Y) explains why it's a bounded and relevant set of variables to consider.
  - Quick check question: What are the three types of variables that constitute the Markov boundary of a node in a Bayesian network?

## Architecture Onboarding

- Component map: Data Input (D*o, De) -> Markov Boundary Learning -> ProbsABS Scoring (called within Greedy Search) -> Optimal Z* Selection -> Final Estimator

- Critical path: The method takes observational data from the target domain and experimental data from the source domain, learns the Markov boundary of the outcome, performs greedy search to identify the optimal sABS using Bayesian scoring, and finally estimates the causal effect using the identified set.

- Design tradeoffs:
  - **Greedy Search vs. Exhaustive Search**: The paper chooses greedy search for scalability (avoiding 2^|O| combinations). The tradeoff is the risk of getting stuck in a local optimum, though Theorem 5 offers some asymptotic reassurance about parsimony.
  - **Discrete Data Formulas (BD score) vs. General (MCMC)**: The paper provides closed-form BD-score-based formulas for discrete data (Theorem 4,5), which are faster and allow for clean asymptotic proofs. For mixed data, it resorts to MCMC sampling (Algorithm 1), which is more computationally intensive and relies on sampling quality. The choice impacts computational cost and theoretical guarantees.
  - **P(hZ|D*o) Prior**: The method uses an uninformative 0.5 prior for P(hZ|D*o), arguing that observational data alone is insufficient to determine s-admissibility. A more informative prior could speed up convergence but would require strong domain knowledge not assumed by the paper.

- Failure signatures:
  - **Failure to Reject**: The algorithm returns a set with high probability when it should not (false positive). This is mitigated asymptotically by Theorem 4 but can occur in finite samples. A signature would be high cross-entropy on a held-out experimental test set from the target domain.
  - **Search Convergence to ∅ or Full Set**: The search might converge to the empty set or the full Markov boundary if the scoring function fails to distinguish subtle differences, indicating the ProbsABS scores are too close to call.
  - **MCMC Non-Convergence**: For mixed data, if the MCMC sampler in Algorithm 1 fails to converge, the estimated P(De|D*o, hZ) will be unreliable, leading to incorrect posterior probabilities and thus a wrong sABS selection.

- First 3 experiments:
  1. **Reproduce Simulation on Figure 1a (Case 1)**: Generate binary treatment/outcome and continuous covariates Z, W as described in Section 13.2. Use the provided closed-form formulas (Table 1) or logistic regression setup. Verify that ProbsABS assigns a high posterior probability to the ground truth sABS {Z, W} and that FindsABS successfully identifies it.
  2. **Scalability and Ablation (Varying |O|)**: Extend the simulation to 10 variables as in Section 13.4. Measure the runtime of FindsABS as the number of variables in the Markov boundary grows. Ablate the Markov boundary restriction by allowing search over all O to quantify the speedup.
  3. **Semi-Synthetic Hillstrom Data (Scenario 1)**: Use the MineThatData Email dataset as in Section 6. Inject bias into a specific subgroup (Mode 1). Run ProbsABS on the full feature set and verify it correctly assigns low probability to it being an sABS (i.e., correctly rejects the hypothesis). Compare the rejection rate against the Bias-test baseline for different sample sizes.

## Open Questions the Paper Calls Out

- **Handling sample selection bias**: The paper explicitly lists "handling sample selection bias (common in clinical trials with strict inclusion/exclusion criteria)" as future work, noting that the current framework does not account for internal sampling mechanisms inherent in many RCTs.

- **Extending theoretical guarantees**: While Theorems 4 and 5 establish asymptotic convergence for discrete data, the experimental evaluation utilizes mixed data types, leaving the theoretical consistency of logistic regression likelihoods for continuous outcomes unproven.

## Limitations

- **Reliance on Markov boundary identification**: The method's effectiveness depends on correctly identifying the Markov boundary of Y from observational data, which can be challenging in high-dimensional settings or when the faithfulness assumption is violated.

- **MCMC sampling variability**: For mixed data, the method relies on MCMC sampling to compute marginal likelihoods, introducing sampling variability that is not fully characterized and may affect identification reliability.

- **Greedy search limitations**: The greedy search strategy, while computationally efficient, may miss the globally optimal sABS in complex scoring landscapes where the optimal set is not reachable through incremental additions or removals.

## Confidence

- **High confidence**: The theoretical results (Theorems 3, 4, 5) proving the Markov boundary restriction and asymptotic properties are mathematically sound given the stated assumptions.
- **Medium confidence**: The experimental results showing AUC up to 0.93 and competitive BCE scores, as these depend on implementation details (MCMC convergence, baseline algorithms) that may vary.
- **Medium confidence**: The claim that observational data can serve as a sufficient prior for experimental likelihood comparison, as this depends heavily on the balance of sample sizes and the quality of the Bayesian model specification.

## Next Checks

1. **Ablation on Markov Boundary Restriction**: Run the greedy search over the full covariate set O (not just MB(Y)) in simulation to quantify the speedup gained by the restriction and verify it doesn't miss the true sABS.

2. **Finite Sample Robustness**: Systematically vary the ratio of N_e to N_o* (e.g., N_e=50, N_o*=500 vs. N_e=1000, N_o*=5000) in simulation to identify the minimum experimental sample size required for reliable identification (AUC > 0.8).

3. **MCMC Convergence Diagnostics**: For the mixed data experiments, report and monitor Gelman-Rubin R-hat statistics and effective sample sizes for all logistic model parameters to ensure the likelihood estimates are reliable.