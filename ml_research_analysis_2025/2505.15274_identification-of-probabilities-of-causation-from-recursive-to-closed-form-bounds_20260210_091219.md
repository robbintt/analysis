---
ver: rpa2
title: 'Identification of Probabilities of Causation: from Recursive to Closed-Form
  Bounds'
arxiv_id: '2505.15274'
source_url: https://arxiv.org/abs/2505.15274
tags:
- ykxk
- bounds
- probability
- pearl
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying multi-valued probabilities
  of causation (PoCs) in Structural Causal Models (SCMs) using only experimental and
  observational data, without structural restrictions. The authors extend PoCs beyond
  binary settings by deriving closed-form bounds for a representative family of discrete
  PoCs, introducing equivalence classes to reduce arbitrary PoC queries and a replaceability
  principle to transfer bounds across value permutations.
---

# Identification of Probabilities of Causation: from Recursive to Closed-Form Bounds

## Quick Facts
- **arXiv ID**: 2505.15274
- **Source URL**: https://arxiv.org/abs/2505.15274
- **Reference count**: 40
- **Primary result**: Derives closed-form bounds for multi-valued probabilities of causation that are simpler and tighter than existing recursive bounds, verified up to n=4 dimensions.

## Executive Summary
This paper addresses the challenge of identifying multi-valued probabilities of causation (PoCs) in Structural Causal Models (SCMs) using only experimental and observational data, without structural restrictions. The authors extend PoCs beyond binary settings by deriving closed-form bounds for a representative family of discrete PoCs, introducing equivalence classes to reduce arbitrary PoC queries and a replaceability principle to transfer bounds across value permutations. The primary results include closed-form theoretical bounds that are simpler to compute than existing recursive bounds, empirical verification of soundness across all dimensions and tightness in low-dimensional cases (up to n=4) via Balke's linear programming method, simulation results showing consistent tightening of recent recursive bounds with average improvements in bound tightness across multiple dimensional settings, and practical applicability demonstrated through medical and educational examples showing how the bounds capture cross-world response patterns invisible to marginal comparisons. The authors conjecture that the proposed bounds are complete in general, though a formal proof remains open.

## Method Summary
The paper develops closed-form bounds for multi-valued probabilities of causation (PoCs) including PNS(k), PSub(k,p), PRep(k,q), and PN(k,p,q) in SCMs. The method uses experimental data (interventional probabilities P(y_x)) and observational data (joint probabilities P(x,y)) as inputs. The approach introduces equivalence classes to reduce arbitrary discrete PoCs to a representative family, applies replaceability principles to handle value permutations, and computes bounds using analytical formulas derived from Fréchet inequalities. For validation, the authors compare their bounds against Balke's linear programming method for tightness verification in low dimensions (n≤4) and against recent recursive bounds from Li & Pearl (2024) for improvement assessment.

## Key Results
- Closed-form theoretical bounds for multi-valued PoCs that are simpler to compute than existing recursive bounds
- Empirical verification of soundness across all dimensions and tightness in low-dimensional cases (up to n=4) via Balke's linear programming method
- Simulation results showing consistent tightening of recent recursive bounds with average improvements in bound tightness across multiple dimensional settings
- Practical applicability demonstrated through medical and educational examples showing how the bounds capture cross-world response patterns invisible to marginal comparisons

## Why This Works (Mechanism)

### Mechanism 1: Representational Reduction via Equivalence Classes
Arbitrary discrete probabilities of causation (PoCs) do not require unique bound derivations; they can be mapped to a representative family of canonical forms to inherit existing bounds. The paper establishes **Equivalence Classes** (Theorem 6), allowing queries where treatment and outcome variables have mismatched cardinalities (e.g., |X| ≠ |Y|) to be treated as boundary cases of a standardized n×n problem. This reduction prevents the combinatorial explosion of deriving bounds for every possible variable configuration. The underlying SCM supports well-defined counterfactuals (Y_x = y) such that mapping "empty" or "forced" values in the extended variable space preserves the original probability structure.

### Mechanism 2: Analytical Tightening via Closed-Form Constraints
Closed-form expressions derived from Fréchet inequalities yield tighter bounds than recursive formulations because they explicitly optimize the feasible region intersection. Unlike recursive bounds (Li & Pearl, 2024) which propagate uncertainty sequentially, the proposed closed-form bounds (Theorems 2–5) compute the direct intersection of probability constraints (e.g., max(0, P(y_x) - P(y))). This avoids the "drift" or slack introduced by iterative approximations, resulting in narrower intervals. The experimental (P(y_x)) and observational (P(x,y)) data are consistent with a unified data-generating process (compatibility).

### Mechanism 3: Generalization via the Replaceability Principle
Bounds for any permutation of treatment values can be derived by simple variable substitution without re-running the identification proof. The **Replaceability Principle** (Theorem 7) posits that the bound structure is invariant to the specific indices of the values y_i and x_j within the probability expression P(y_1^{x_1}, ..., y_k^{x_k}). This allows the "representative family" to cover all n! permutations of treatment-outcome responses. The causal mechanism is invariant to the labeling of the discrete states (i.e., there is no inherent ordinal structure in the SCM that breaks symmetry).

## Foundational Learning

- **Concept: Structural Causal Models (SCMs) & Counterfactuals**
  - **Why needed here:** The entire framework relies on the definition of probabilities like P(y_1^{x_1}, y_2^{x_2})—the probability that Y=y_1 if X=x_1 AND Y=y_2 if X=x_2. This "cross-world" quantity is only well-defined within the SCM semantics (potential outcomes).
  - **Quick check question:** Can you explain why P(y_1^{x_1}, y_2^{x_2}) cannot be estimated directly from a standard randomized controlled trial (RCT)?

- **Concept: Partial Identification & Bounding**
  - **Why needed here:** The paper deals with "bounds" rather than point estimates. Understanding that PoCs are generally unidentifiable (impossible to pin down to a single number) from observational and experimental data alone is crucial to appreciating the value of "tightening" the bounds.
  - **Quick check question:** If the lower bound of a PoC is 0.5, does this mean the treatment causes the effect for exactly 50% of the population?

- **Concept: Fréchet Inequalities**
  - **Why needed here:** The proofs for the closed-form bounds (Appendix A) heavily utilize Fréchet inequalities (e.g., P(A, B) ≥ P(A) + P(B) - 1) to aggregate constraints from different data sources.
  - **Quick check question:** How does the Fréchet upper bound min(P(A), P(B)) differ from simply assuming independence P(A)P(B)?

## Architecture Onboarding

- **Component map:** Input Layer (P(y_x), P(x,y)) -> Preprocessing (Equivalence/Replaceability) -> Computation Engine (closed-form formulas) -> Output (bounds [L,U])
- **Critical path:** The **Equivalence Class** logic (Theorem 6) is the most fragile step. If the dimensionality reduction (padding variables) is implemented incorrectly, the resulting bounds will be theoretically valid but practically useless (extremely loose).
- **Design tradeoffs:**
  - **Closed-form vs. LP:** The paper trades the absolute rigor of Linear Programming (LP)—which guarantees tightness for a specific instance—for the computational speed and generality of closed-form formulas.
  - **Generality vs. Precision:** By assuming no structural restrictions, the bounds are widely applicable but potentially looser than methods that assume specific graph structures (e.g., no unobserved confounders).
- **Failure signatures:**
  - **Infeasible Inputs:** If input probabilities violate basic constraints (e.g., P(y|x) > 1), the engine should flag incompatibility.
  - **Vacuous Bounds:** If the system returns [0, 1], it indicates the data is entirely uninformative for the specific counterfactual query (a valid but null result).
  - **Conjecture Over-reach:** In high dimensions (n > 4), treat the "tightness" claim with caution; the paper only empirically verifies tightness up to n=4.
- **First 3 experiments:**
  1. **Unit Test (Medical Example):** Replicate the calculation in Section 4.1 (P(y_3^{x_1}, y_1^{x_2}, y_2^{x_3})) to verify the system produces [0.509, 0.588] and confirms the improvement over the recursive bounds [0.428, 0.588].
  2. **Dimension Sweep:** Run the simulation pipeline from Section 5 for n=3 and n=4. Verify that the closed-form bounds match the "Gold Standard" LP bounds (Balke's method) to within machine precision, confirming the conjecture in low dimensions.
  3. **Permutation Stress Test:** Generate a random query involving non-canonical indices (e.g., P(y_5^{x_1}, y_2^{x_3})) and verify that the **Replaceability** module correctly swaps indices to apply Theorem 2 before returning the result.

## Open Questions the Paper Calls Out

### Open Question 1
Are the proposed closed-form bounds for multi-valued probabilities of causation complete (tight) for all dimensions? The authors "conjecture that this tightness extends to all dimensions," but currently only verify tightness empirically up to n=4. A formal proof showing the closed-form expressions match Balke's linear programming bounds for arbitrary n, or a counter-example where the bounds are loose, would resolve this.

### Open Question 2
How can covariates and explicit causal graphs be integrated to sharpen identification? The conclusion states that "Incorporating covariates and explicit causal graphs may further tighten bounds... is an important next step." Derivation of new bound expressions that include covariate terms and a demonstration of strictly narrower intervals compared to the baseline method would resolve this.

### Open Question 3
Can Monotonic Incremental Treatment Effect (MITE) or similar structural constraints be used to derive refined bounds? The conclusion identifies "Integrating Monotonic Incremental Treatment Effect (MITE)... is a promising direction" and notes that finding interpretable structural conditions is challenging. A framework that derives narrower bounds under MITE or specific partial-order constraints in the multi-valued regime would resolve this.

## Limitations
- Completeness conjecture remains unproven beyond low dimensions (n ≤ 4)
- Assumes compatibility between experimental and observational data distributions
- Does not incorporate covariate information or explicit causal graph structure
- The replaceability principle assumes symmetry that may not hold with ordinal treatment structures

## Confidence
- **High Confidence:** Soundness of bounds across all dimensions (Theorem 1 guarantees validity)
- **Medium Confidence:** Tightness claims in low dimensions (n ≤ 4) with empirical validation
- **Medium Confidence:** Average improvements over recursive bounds in simulations
- **Low Confidence:** Completeness conjecture for general n

## Next Checks
1. **Rigorous Completeness Proof:** Extend Balke's LP validation to n=5,6 and attempt constructive proof of optimality
2. **Stress Test Compatibility:** Systematically generate incompatible distributions to test robustness of feasibility assumptions
3. **Ordinal Extension:** Implement a specialized version incorporating ordinal treatment structure and measure the bound tightening versus the generic approach