---
ver: rpa2
title: Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models
arxiv_id: '2511.00053'
source_url: https://arxiv.org/abs/2511.00053
tags:
- forecast
- forecasting
- wang
- learning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies two key issues in training time-series forecasting
  models: overlooking label autocorrelation effects and failing to assign heterogeneous
  task weights to different forecast horizons. The authors propose a quadratic-form
  weighted training objective that simultaneously addresses both issues by learning
  a weighting matrix to model label autocorrelation (off-diagonal elements) and heterogeneous
  task weights (diagonal elements).'
---

# Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models

## Quick Facts
- **arXiv ID:** 2511.00053
- **Source URL:** https://arxiv.org/abs/2511.00053
- **Reference count:** 40
- **Primary result:** QDF reduces MSE by 5.9-7.4% compared to standard direct forecasting on ECL dataset

## Executive Summary
This paper identifies two key issues in training multi-step time-series forecasting models: overlooking label autocorrelation effects and failing to assign heterogeneous task weights to different forecast horizons. The authors propose a quadratic-form weighted training objective that simultaneously addresses both issues by learning a weighting matrix to model label autocorrelation (off-diagonal elements) and heterogeneous task weights (diagonal elements). They introduce the Quadratic Direct Forecast (QDF) learning algorithm, which adaptively updates this weighting matrix during training. Experiments show that QDF consistently improves performance across multiple state-of-the-art forecasting models and datasets, achieving state-of-the-art results.

## Method Summary
The method introduces a quadratic-form weighted training objective for multi-step time-series forecasting. A learnable weighting matrix $\Sigma$ is optimized through bilevel optimization: the inner loop updates model parameters using a fixed $\Sigma$, while the outer loop updates $\Sigma$ based on validation performance. The weighting matrix captures both label autocorrelation (off-diagonal elements) and heterogeneous task weights (diagonal elements). To ensure positive semi-definiteness, $\Sigma$ is reparameterized via Cholesky decomposition. The final model is trained using the learned $\Sigma$ on the full training set.

## Key Results
- QDF consistently improves performance across multiple state-of-the-art forecasting models
- On ECL dataset, QDF reduces MSE by 5.9-7.4% compared to standard direct forecasting
- QDF achieves state-of-the-art results on multiple benchmark datasets
- Ablation studies show both diagonal and off-diagonal components contribute to performance gains

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Modeling the correlation between errors at different future steps reduces the bias inherent in standard Mean Squared Error (MSE) training.
- **Mechanism:** Standard MSE assumes errors are independent (diagonal covariance). The paper proposes a quadratic-form objective where off-diagonal elements in the weighting matrix $\Sigma^{-1}$ capture the autocorrelation structure of the label sequence. By minimizing this coupled error, the optimizer accounts for the statistical dependency between future time steps.
- **Core assumption:** The forecast errors follow a multivariate Gaussian distribution where the covariance structure is non-trivial (non-diagonal) even when conditioned on history.
- **Evidence anchors:**
  - [Abstract] "Specifically, the off-diagonal elements of the weighting matrix account for the label autocorrelation effect."
  - [Section 3.1] Theorem 3.1 derives the loss as a Negative Log-Likelihood (NLL) involving $\Sigma^{-1}$.
  - [Corpus] The corpus identifies "temporal coherence" as a challenge in direct forecasting (e.g., "Back to the Future"), but does not explicitly validate the specific quadratic weighting mechanism.
- **Break condition:** If forecast errors are truly independent (diagonal conditional covariance), the off-diagonal optimization adds unnecessary complexity without performance gains.

### Mechanism 2
- **Claim:** Assigning non-uniform weights to different forecast horizons improves generalization by prioritizing harder or more informative steps.
- **Mechanism:** The mechanism treats multi-step forecasting as a multi-task learning problem. Instead of weighting $t+1$ and $t+96$ equally, the algorithm learns diagonal elements of $\Sigma^{-1}$ to assign specific weights to specific horizons, potentially emphasizing steps with higher uncertainty or signal complexity.
- **Core assumption:** Different future steps contribute differently to the generalization error, and a static, global weighting scheme is sufficient to capture this heterogeneity.
- **Evidence anchors:**
  - [Section 4.4] Ablation study (QDFâ€ ) shows that enabling heterogeneous task weights (diagonal only) improves performance over standard Direct Forecast (DF).
  - [Abstract] "...non-uniform diagonals are expected to match the most preferable weights of the forecasting tasks."
  - [Corpus] Weak support; related work discusses multi-horizon stability but not explicit learned weighting.
- **Break condition:** If the optimal task weighting is highly dynamic (sample-dependent rather than dataset-dependent), a global weighting matrix will underfit the required objective function.

### Mechanism 3
- **Claim:** Optimizing the weighting matrix via bi-level optimization ensures the objective function targets generalization rather than just fitting the training distribution.
- **Mechanism:** The algorithm splits data into $D_{in}$ and $D_{out}$. The inner loop trains the forecast model $g_\theta$ on $D_{in}$ using a fixed $\Sigma$. The outer loop updates $\Sigma$ based on the performance of the updated model on $D_{out}$. This mimics meta-learning, where the "loss function itself" is learned to minimize holdout error.
- **Core assumption:** The gradient from the outer loop can effectively propagate through the inner loop's training step to yield a meaningful update for $\Sigma$.
- **Evidence anchors:**
  - [Section 3.2] Definition 3.2 formally defines the bilevel optimization problem.
  - [Section 4.6] Comparisons with MAML and Reptile show that while meta-learning methods work, the specific QDF implementation (targeting generalization on a static task) outperforms generic meta-learners.
  - [Corpus] Weak direct evidence; "Epistemic Error Decomposition" discusses error sources, but not this specific optimization strategy.
- **Break condition:** If the validation set $D_{out}$ is not representative of the test distribution (distribution shift), the learned weighting matrix will be miscalibrated for actual inference.

## Foundational Learning

- **Concept: Multivariate Gaussian Negative Log-Likelihood**
  - **Why needed here:** The theoretical justification for the entire QDF method rests on Theorem 3.1, which reframes forecasting loss as the NLL of a multivariate Gaussian. Without this, the quadratic form is just an arbitrary matrix operation.
  - **Quick check question:** Can you explain why minimizing $(Y - \hat{Y})^T \Sigma^{-1} (Y - \hat{Y})$ is equivalent to maximizing the likelihood of the prediction under a Gaussian assumption?

- **Concept: Bi-level Optimization (Meta-Learning)**
  - **Why needed here:** The training process is not a simple gradient descent. It involves an "inner loop" (model training) nested inside an "outer loop" (weight matrix update). Understanding this hierarchy is critical to implementing the Algorithm 1 correctly.
  - **Quick check question:** In the outer loop, do we update $\Sigma$ to minimize the loss on $D_{out}$ directly, or to minimize how the *inner-loop-trained model* performs on $D_{out}$? (Answer: The latter).

- **Concept: Cholesky Decomposition**
  - **Why needed here:** The covariance matrix $\Sigma$ must be positive semi-definite. The paper uses Cholesky factorization ($\Sigma = LL^T$) to reparameterize the optimization as unconstrained, ensuring numerical stability and valid covariance matrices during gradient descent.
  - **Quick check question:** Why can't we just gradient descent on the elements of $\Sigma$ directly without reparameterization? (Answer: Gradient steps might violate the positive semi-definite property, breaking the statistical validity of the covariance matrix).

## Architecture Onboarding

- **Component map:**
  1. Forecast Model ($g_\theta$) -> Processes history $X$
  2. Weighting Matrix ($\Sigma$) -> $T \times T$ matrix reparameterized via lower-triangular matrix $L$
  3. Objective Calculator -> Computes quadratic loss $L_{\Sigma} = (Y - \hat{Y})^T \Sigma^{-1} (Y - \hat{Y})$
  4. Meta-Optimizer -> Orchestrates inner/outer loop updates

- **Critical path:**
  1. **Initialization:** Split training data into $K$ folds. Initialize $\Sigma = I$.
  2. **Inner Loop:** Sample a batch from $D_{in}$. Compute loss $L_{\Sigma}$. Update model weights $\theta$.
  3. **Outer Loop:** Sample a batch from $D_{out}$. Compute loss $L_{\Sigma}$ using the *updated* model. Backpropagate gradients through the inner loop update to adjust $\Sigma$.
  4. **Final Training:** Once $\Sigma$ converges, freeze it and train the final model on the full training set using $L_{\Sigma}$.

- **Design tradeoffs:**
  - **Static vs. Dynamic $\Sigma$:** The paper learns a *static* matrix for the whole dataset. This is computationally cheaper but less flexible than generating a dynamic weighting per sample (e.g., via a hyper-network, noted as a limitation in the conclusion).
  - **Approximation:** Algorithm 1 approximates the bi-level gradient. Exact differentiation through the full inner-loop training is memory-intensive; typically, only the "last step" or a "short trajectory" is unrolled.

- **Failure signatures:**
  - **Matrix Divergence:** If the diagonal of $L$ becomes negative or $\Sigma$ becomes ill-conditioned, the loss becomes unstable.
  - **Overfitting Outer Loop:** If $D_{out}$ is too small, $\Sigma$ will overfit to that specific holdout set, failing on the actual test set.
  - **No Improvement:** If the base model already captures dependencies well or the data has low autocorrelation, the overhead of QDF yields diminishing returns.

- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Generate data with a known non-diagonal covariance structure. Verify that QDF recovers a $\Sigma$ resembling the ground truth and outperforms MSE.
  2. **Ablation (Diagonal vs. Off-Diagonal):** Run QDF on the ECL dataset with two restrictions: (a) only learn diagonal elements, (b) only learn off-diagonal elements. Compare against the full QDF to quantify the value of "Heterogeneous Weights" vs. "Autocorrelation Modeling."
  3. **Visual Inspection:** Visualize the learned $\Sigma^{-1}$ matrix. Check if the diagonal weights decay (higher uncertainty for long-term) and if off-diagonals show structure (e.g., bands indicating periodicity).

## Open Questions the Paper Calls Out
- **Can the quadratic-form objective be effectively generalized to other domains with label autocorrelation, such as user rating prediction or dense image prediction?**
  - **Basis in paper:** [explicit] The "Limitations & future works" section explicitly identifies extending QDF to these related fields as a valuable direction for future investigation.
  - **Why unresolved:** The current study restricts empirical validation to time-series forecasting datasets (ETT, ECL, Weather, PEMS).
  - **What evidence would resolve it:** Experimental results demonstrating performance improvements when applying the QDF objective to recommender systems or computer vision benchmarks.

- **Would replacing the static weighting matrix with a hyper-network to generate input-dependent learning objectives yield further performance gains?**
  - **Basis in paper:** [explicit] The authors note that relying on a fixed quadratic objective limits flexibility and suggest employing a hyper-network as a promising enhancement.
  - **Why unresolved:** The current implementation learns a single, static global weighting matrix ($\Sigma$) that does not adapt to specific input instances.
  - **What evidence would resolve it:** A comparison of the static QDF against a hyper-network variant on diverse datasets to measure the benefit of input-dependent weighting.

## Limitations
- The theoretical justification assumes forecast errors follow a multivariate Gaussian distribution, which may not hold for real-world time-series data
- The method learns a static weighting matrix $\Sigma$ that may not capture sample-specific dependencies as effectively as dynamic weighting
- The effectiveness of bi-level optimization depends heavily on having representative validation sets; distribution shift can lead to miscalibrated weighting matrices

## Confidence
- **High Confidence:** The experimental results showing consistent improvements across multiple datasets and state-of-the-art models are well-supported and reproducible
- **Medium Confidence:** The theoretical justification via multivariate Gaussian NLL is sound, but the practical assumption about error distributions in real-world data requires further validation
- **Medium Confidence:** The mechanism of learned heterogeneous task weights improving performance is demonstrated through ablation studies, but the specific patterns in the learned $\Sigma^{-1}$ matrices are not deeply analyzed

## Next Checks
1. **Synthetic Data Verification:** Generate synthetic time-series data with known non-diagonal covariance structure. Train QDF and verify that the learned $\Sigma$ matrix recovers the ground-truth covariance structure, demonstrating the method's ability to correctly model label autocorrelation.
2. **Dynamic vs. Static Weighting Comparison:** Implement a dynamic version of QDF where $\Sigma$ is generated per sample via a hyper-network. Compare performance against the static QDF to quantify the potential gains from sample-specific weighting.
3. **Error Distribution Analysis:** For the ECL dataset, analyze the empirical distribution of forecast errors across different horizons. Test whether the errors approximately follow a multivariate Gaussian distribution and whether the off-diagonal elements of $\Sigma^{-1}$ capture meaningful autocorrelation patterns.