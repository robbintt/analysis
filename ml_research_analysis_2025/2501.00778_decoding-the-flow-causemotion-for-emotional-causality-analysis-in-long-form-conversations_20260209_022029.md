---
ver: rpa2
title: 'Decoding the Flow: CauseMotion for Emotional Causality Analysis in Long-form
  Conversations'
arxiv_id: '2501.00778'
source_url: https://arxiv.org/abs/2501.00778
tags:
- causal
- emotional
- dialogue
- reasoning
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of long-sequence emotional causality
  reasoning in extended dialogues, where large language models struggle to capture
  intricate emotional relationships and global context. The proposed CauseMotion framework
  integrates Retrieval-Augmented Generation (RAG) with multimodal fusion, incorporating
  audio features such as vocal emotion, emotional intensity, and speech rate into
  textual modalities.
---

# Decoding the Flow: CauseMotion for Emotional Causality Analysis in Long-form Conversations

## Quick Facts
- **arXiv ID**: 2501.00778
- **Source URL**: https://arxiv.org/abs/2501.00778
- **Reference count**: 39
- **Primary result**: Proposed CauseMotion framework achieves 8.7% improvement in causal accuracy over baseline GLM-4 and surpasses GPT-4o by 1.2% on DiaASQ dataset.

## Executive Summary
The paper addresses long-sequence emotional causality reasoning in extended dialogues where large language models struggle to capture intricate emotional relationships and global context. The proposed CauseMotion framework integrates Retrieval-Augmented Generation (RAG) with multimodal fusion, incorporating audio features such as vocal emotion, emotional intensity, and speech rate into textual modalities. This approach enriches semantic representations and enables the inference of complex emotional causal chains spanning multiple conversational turns. CauseMotion achieves state-of-the-art performance on the DiaASQ dataset, with the CauseMotion-GLM-4 variant outperforming GPT-4o across all metrics.

## Method Summary
CauseMotion uses a sliding window mechanism to segment long dialogues and build a dialogue knowledge base with multimodal embeddings. Audio features (vocal emotion, intensity, speech rate) extracted via SenseVoice encoder are converted to textual descriptions and concatenated with dialogue text. RAG retrieves contextually relevant segments via cosine similarity for the current window. The LLM extracts sextuplets (Holder, Target, Aspect, Opinion, Sentiment, Rationale) from the enriched context. Causal chains are constructed using weighted combination of semantic consistency, temporal constraints, and rationale alignment scores.

## Key Results
- CauseMotion-GLM-4 achieves 8.7% improvement in causal accuracy over original GLM-4 model
- Outperforms GPT-4o by 1.2% across all metrics on DiaASQ dataset
- Achieves Emotional Causality Reasoning Chain Accuracy of 0.574 on ATLAS dataset
- Demonstrates state-of-the-art performance in extracting complex emotional causal relationships in long dialogues

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: RAG with sliding window enables long-range dependency capture in dialogues exceeding typical LLM context windows.
- **Mechanism**: Dialogue segmented into overlapping time windows populating a dialogue knowledge base. RAG retrieves contextually similar segments via cosine similarity, providing distant but relevant context to current window during inference.
- **Core assumption**: Semantic similarity (via cosine similarity on embeddings) correlates with causal relevance—Assumption not validated against alternatives.
- **Evidence anchors**: Abstract states RAG with sliding window "effectively retrieves and leverages contextually relevant dialogue segments"; Section III defines window construction and RAG retrieval.

### Mechanism 2
- **Claim**: Audio features converted to textual descriptions enhance emotion-cause extraction accuracy.
- **Mechanism**: SenseVoice extracts emotion vector, intensity, and speech rate; converted to text descriptions and concatenated with dialogue text before embedding.
- **Core assumption**: Textualized audio features preserve sufficient paralinguistic signal for LLMs to reason about emotional causality—Assumption feature-to-text conversion may lose nuance.
- **Evidence anchors**: Abstract mentions "enriches semantic representations by incorporating audio-derived features"; Section III-A defines audio feature extraction and fusion.

### Mechanism 3
- **Claim**: Causal chain construction using weighted combination of semantic consistency, temporal constraints, and rationale alignment enables multi-hop emotional causality inference.
- **Mechanism**: Three independent scores computed: Semantic (opinion-sentiment cosine similarity), Temporal (exponential decay on time gap), Rationale (NLI model probability). Edges weighted as: Weight(eij) = α·Semantic + β·Temporal + γ·Rationale.
- **Core assumption**: Linear combination with tunable weights adequately models causal strength—Assumption weight values not reported.
- **Evidence anchors**: Section III-C defines scoring functions; Section IV reports Causal Chain Score metric achieving 0.574 with CauseMotion-GLM-4.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Long dialogues (70-300 turns) exceed typical LLM context windows (~4-128K tokens); RAG provides dynamic context retrieval without truncation.
  - Quick check question: Given a 200-turn dialogue where Turn 5 contains an insult and Turn 150 shows resentment, would a standard LLM without RAG capture this dependency? (Answer: Likely no—exceeds effective context length.)

- **Concept: Multimodal Feature Fusion**
  - Why needed here: Text alone under-specifies emotional state (same words can express different emotions); audio provides prosodic cues humans naturally use.
  - Quick check question: If a speaker says "I'm fine" with slow speech rate and low intensity, what might the audio reveal that text misses? (Answer: Potential sadness or resignation, contradicting literal text.)

- **Concept: Sextuple Emotion Annotation Schema**
  - Why needed here: Fine-grained extraction (Holder, Target, Aspect, Opinion, Sentiment, Rationale) enables structured causal analysis rather than coarse sentiment classification.
  - Quick check question: Why is "Rationale" necessary for causal chain construction? (Answer: Provides explicit reasoning link between emotional state and cause, enabling NLI-based validation.)

## Architecture Onboarding

- **Component map**: Input Dialogue + Audio → SenseVoice Encoder → Audio Features (ei, θi, ri) → Textualization + Concatenation → Multimodal Embedding Em → [Dialogue KB + Prompts] → Current Window Wj → RAG Retrieval (cosine sim) → Retrieved Context Cj → LLM (GLM-4/Qwen/LLaMA) → Sextuple Extraction Qj → Three-Score Causal Linking → Causal Graph G

- **Critical path**: Audio feature extraction → Knowledge base construction → RAG retrieval quality → LLM extraction accuracy. The 8.7% improvement over baseline GLM-4 is primarily attributable to RAG and multimodal augmentation jointly—ablation isolating individual contributions not fully reported.

- **Design tradeoffs**:
  - Window size k: Larger windows capture more context but increase retrieval noise; smaller windows lose dependencies—Assumption: optimal k not reported.
  - Textualization of audio vs. direct embedding: Textualization enables compatibility with closed-source LLMs but may lose signal; direct embedding requires model parameter access.
  - Weight parameters (α, β, γ): Manually tuned or learned? Paper does not specify optimization method.

- **Failure signatures**:
  - Low Causal Chain Accuracy with high individual sextuple extraction: Indicates retrieval or linking failure, not extraction failure.
  - High Temporal Score but low Semantic Score: Model finds time-adjacent events but misidentifies causal relationship.
  - Performance drop on ATLAS vs. DiaASQ: ATLAS has longer sequences (70-300 vs. DiaASQ's shorter dialogues), revealing long-range dependency limitations.

- **First 3 experiments**:
  1. **Ablation baseline**: Run CauseMotion with RAG disabled (random retrieval) to isolate RAG contribution. Compare Causal Chain Accuracy against full system.
  2. **Window size sensitivity**: Test k ∈ {5, 10, 20, 50} on ATLAS validation set. Plot Causal Chain Accuracy vs. window size to identify retrieval precision-recall tradeoff.
  3. **Modality contribution**: Run with (a) text-only, (b) text + vocal emotion, (c) text + all audio features. Measure delta in Sentiment F1 and Causality Chain Accuracy to quantify multimodal contribution.

## Open Questions the Paper Calls Out

**Open Question 1**: How can the CauseMotion framework be effectively adapted to specialized domains (e.g., legal proceedings, therapeutic sessions, or technical support) where emotional causality patterns and terminology differ significantly from general conversational scenarios?

**Open Question 2**: What biases or artifacts might LLM-assisted synthetic dialogue generation introduce into the ATLAS-6 dataset, and how do these affect generalizability to real-world emotional causality patterns?

**Open Question 3**: Why does CauseMotion improve performance for GLM-4 but degrade performance for other models like Qwen2.5-72B, and what architectural characteristics predict compatibility?

**Open Question 4**: What is the optimal strategy for fusing audio-derived emotional features with textual representations—current text-based conversion versus direct embedding-level fusion—and how much information is lost when encoding continuous acoustic signals as discrete textual descriptions?

## Limitations

- Key parameters (sliding window size, weight values for causal scoring, NLI model specification) remain unspecified, making exact replication challenging
- Performance improvement combines contributions from multiple mechanisms without clear ablation isolating individual effects
- Textualization of audio features may lose critical paralinguistic information without empirical comparison to direct audio embeddings

## Confidence

- **High Confidence**: Core technical approach (RAG + multimodal fusion + causal chain construction) is well-specified and achieves state-of-the-art results; sextuple annotation schema and evaluation metrics are clearly defined
- **Medium Confidence**: Specific parameter values and optimization process not reported; superiority claims over GPT-4o rely on unspecified parameters
- **Low Confidence**: Causal relevance assumption (semantic similarity = causal relevance) lacks direct validation; multimodal fusion approach lacks direct corpus validation for this specific application

## Next Checks

1. **Ablation study of RAG contribution**: Run CauseMotion with RAG disabled (random context retrieval) on ATLAS validation set. Compare Causal Chain Accuracy against full system to isolate RAG's specific contribution to the 8.7% improvement over baseline GLM-4.

2. **Window size sensitivity analysis**: Systematically test sliding window sizes k ∈ {5, 10, 20, 50} on the ATLAS dataset. Plot Causal Chain Accuracy vs. window size to identify the optimal tradeoff between context coverage and retrieval precision, and to understand the long-range dependency limitations.

3. **Modality contribution quantification**: Implement three variants—(a) text-only, (b) text + vocal emotion only, (c) text + all audio features (emotion, intensity, speech rate). Measure the delta in Sentiment F1 and Causal Chain Accuracy across variants to quantify the specific contribution of each multimodal feature type to overall performance.