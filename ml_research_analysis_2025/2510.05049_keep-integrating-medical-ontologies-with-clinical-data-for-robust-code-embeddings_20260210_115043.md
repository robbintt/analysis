---
ver: rpa2
title: 'KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings'
arxiv_id: '2510.05049'
source_url: https://arxiv.org/abs/2510.05049
tags:
- embeddings
- data
- keep
- medical
- relationships
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KEEP bridges knowledge graph embeddings with clinical data by using
  graph structure to initialize embeddings, then refining them through regularized
  training on patient records. This approach preserves ontological relationships while
  incorporating empirical patterns.
---

# KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings

## Quick Facts
- **arXiv ID:** 2510.05049
- **Source URL:** https://arxiv.org/abs/2510.05049
- **Reference count:** 40
- **Primary result:** KEEP outperforms traditional methods in both intrinsic (semantic similarity) and extrinsic (clinical prediction) evaluations, with mean AUPRC rank 1.62 and intrinsic rank 1.19

## Executive Summary
KEEP bridges knowledge graph embeddings with clinical data by using graph structure to initialize embeddings, then refining them through regularized training on patient records. This approach preserves ontological relationships while incorporating empirical patterns. In intrinsic evaluations, KEEP outperformed both traditional methods (GloVe, Node2Vec) and language models in capturing semantic relationships (average rank 1.19, p=0.01). In extrinsic clinical prediction tasks, KEEP achieved the highest AUPRC (mean rank 1.62, p=0.02) and showed consistent superiority across test loss, AUC, MCC, and F1 metrics. The method requires minimal computational resources and can be generated without task-specific training, making it accessible for resource-constrained healthcare settings.

## Method Summary
KEEP uses a two-stage approach to generate medical code embeddings. First, it generates embeddings from a knowledge graph (using node2vec random walks on the OMOP ontology's hierarchical relationships). Then it employs regularized training on patient records to adaptively integrate empirical patterns while preserving ontological relationships. The method modifies GloVe's objective with an L2 regularization term that anchors embeddings to their knowledge graph origins, creating a tunable continuum between purely knowledge-based and purely data-driven representations. The regularization parameter λ controls this balance, with higher values preserving more ontological structure for data-scarce settings.

## Key Results
- Intrinsic evaluation: Average rank 1.19 for semantic relationship identification (p=0.01 vs. baselines)
- Extrinsic evaluation: Mean rank 1.62 for AUPRC across clinical prediction tasks (p=0.02)
- Consistent superiority across all metrics: test loss, AUC, MCC, F1, and AUPRC
- Robust performance for rare codes through knowledge graph anchoring
- <2 hours runtime on single NVIDIA L40S GPU

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Knowledge graph initialization provides semantically meaningful anchor points that prevent catastrophic forgetting during empirical refinement.
- **Mechanism:** The L2 regularization term $\lambda \sum_{i=1}^V |w_i - w^{n2v}_i|^2$ creates an elastic constraint tethering final embeddings to their ontological origins. When GloVe optimizes co-occurrence patterns, rare codes with limited empirical data retain biologically grounded representations from node2vec rather than collapsing toward noise or overfitting to sparse signals.
- **Core assumption:** Ontological relationships encode valid biomedical structure that should persist even when empirical data is limited.
- **Evidence anchors:** [abstract] "KEEP first generates embeddings from knowledge graphs, then employs regularized training on patient records to adaptively integrate empirical patterns while preserving ontological relationships"; [section 4.3] "This formulation provides two key technical advantages. It maintains robust representations for rare codes by anchoring their embeddings to biologically meaningful dimensions"
- **Break condition:** If empirical patterns systematically contradict ontological structure (e.g., comorbidities that violate taxonomic assumptions), regularization strength must decrease or embeddings may poorly fit real-world data.

### Mechanism 2
- **Claim:** Complete patient history co-occurrence matrices capture disease relationships that knowledge graphs miss, particularly context-dependent and emergent associations.
- **Mechanism:** While knowledge graphs encode pre-defined relationships (hierarchical "is-a" connections), co-occurrence statistics from EHR capture pragmatic associations: which conditions actually appear together in practice, treatment patterns, and population-specific comorbidities. GloVe's training objective forces embeddings to encode these empirical similarities as geometric proximity.
- **Core assumption:** Co-occurrence frequency meaningfully reflects clinical association strength; high co-occurrence indicates genuine medical relationship rather than documentation artifact.
- **Evidence anchors:** [abstract] "knowledge graph-based approaches capture formal relationships but miss real-world patterns"; [section 3.1] "These relationships provide valuable domain knowledge but... do not capture the full complexity of relationships or empirically observed patterns, which can vary across healthcare settings"
- **Break condition:** If co-occurrence patterns reflect billing practices, documentation habits, or institutional artifacts rather than true clinical relationships, empirical refinement may encode systematic bias.

### Mechanism 3
- **Claim:** The $\lambda$ parameter creates a tunable continuum between purely knowledge-based and purely data-driven representations, allowing institution-specific calibration.
- **Mechanism:** By controlling regularization strength, institutions balance prior knowledge (universally valid ontology) against local empirical patterns (population-specific). High $\lambda$ suits data-scarce settings where ontological structure should dominate; low $\lambda$ favors rich local data. This makes KEEP adaptable across resource contexts without architectural changes.
- **Core assumption:** An optimal $\lambda$ exists that maximizes downstream task performance; this optimum may vary by task, dataset, and institution.
- **Evidence anchors:** [section 7] "Healthcare systems with limited patient data can emphasize knowledge graphs through a higher $\lambda$ value, while those with rich clinical data might benefit from a lower $\lambda$"; [section 4.3] "$\lambda$ serving as the control parameter... effectively creates a continuum between purely knowledge-based and purely data-driven representations"
- **Break condition:** If optimal $\lambda$ varies dramatically across different downstream tasks or code domains (diagnoses vs. procedures), single global $\lambda$ may be suboptimal.

## Foundational Learning

- **Concept:** Knowledge graph embeddings (node2vec, random walk-based methods)
  - **Why needed here:** KEEP's first stage requires understanding how biased random walks capture graph structure and how skip-gram models translate walks into dense vectors preserving neighborhood similarity.
  - **Quick check question:** Given a medical ontology with "Type 2 Diabetes" connected to "Diabetes Mellitus" via "is-a" relationship, what would node2vec learn about their embeddings?

- **Concept:** Co-occurrence matrix factorization (GloVe objective)
  - **Why needed here:** The second stage modifies GloVe's weighted least squares objective; understanding how $\log X_{ij}$ encodes co-occurrence strength and how $f(X_{ij})$ prevents frequent pairs from dominating is essential.
  - **Quick check question:** Why does GloVe weight co-occurrences non-linearly ($f(X_{ij})$ weighting), and what happens if rare code pairs are not upweighted?

- **Concept:** Regularization as knowledge preservation (L2 penalty on embedding drift)
  - **Why needed here:** KEEP's core innovation is the regularization term preventing catastrophic forgetting; this requires understanding how L2 penalties constrain parameter updates toward initialization values.
  - **Quick check question:** If $\lambda = 0.001$ vs. $\lambda = 0.1$, which setting more strongly preserves ontological structure, and what's the tradeoff for rare codes?

## Architecture Onboarding

- **Component map:** [OMOP Knowledge Graph] → node2vec random walks → [Initial Embeddings W^n2v] → [GloVe with L2 reg] → [Final Embeddings W]

- **Critical path:**
  1. Extract hierarchical relationships from OMOP CONCEPT_ANCESTOR table (max depth 5 from root)
  2. Generate node2vec embeddings (100-dim, 750 walks/node, walk length 30)
  3. Construct patient-level co-occurrence matrix (require ≥2 occurrences per diagnosis)
  4. Initialize GloVe with node2vec embeddings, train with modified objective ($\lambda = 10^{-3}$)
  5. Validate via Resnik similarity correlation (graph structure) and co-occurrence correlation (empirical patterns)

- **Design tradeoffs:**
  - **Depth limit (5 levels):** Reduces computational cost but may lose granularity for specific conditions
  - **Patient-level vs. visit-level co-occurrence:** Reduces sparsity but loses temporal progression signals
  - **Disease-only scope:** Simplifies implementation but excludes medication/procedure relationships
  - **Single $\lambda$ for all codes:** Uniform regularization but may over/under-constrain codes with varying data availability

- **Failure signatures:**
  - Embeddings cluster by documentation frequency rather than clinical meaning → co-occurrence dominates, $\lambda$ too low
  - Rare condition embeddings remain unchanged from initialization despite relevant empirical data → regularization too strong
  - Poor transfer to new institution → overfit to source institution's coding patterns, need higher $\lambda$
  - Semantic similarity tests fail despite good prediction performance → ontological structure lost, regularization insufficient

- **First 3 experiments:**
  1. **Ablation on $\lambda$:** Train KEEP with $\lambda \in \{0, 10^{-5}, 10^{-3}, 10^{-1}, 1\}$; measure Resnik similarity correlation and downstream AUPRC to identify optimal balance point and validate regularization mechanism.
  2. **Rare code stress test:** Identify codes with <100 patient occurrences; compare KEEP embeddings against pure node2vec and pure GloVe to verify rare code protection claim using intrinsic evaluation (semantic relationship identification).
  3. **Cross-institution transfer:** Train embeddings on UK Biobank, evaluate prediction tasks on MIMIC-IV without retraining; compare against dataset-specific embeddings to assess generalization and identify institutional drift patterns.

## Open Questions the Paper Calls Out

- **Question:** Does incorporating non-hierarchical relationships (e.g., causal, associative) from medical ontologies into the knowledge graph improve the quality of KEEP embeddings compared to the current hierarchical-only approach?
  - **Basis in paper:** [explicit] Section 7.2 states the current implementation utilizes only hierarchical 'is-a' relationships, omitting other clinical connections that could provide richer representations.
  - **Why unresolved:** The authors restricted the graph structure to "is-a" relationships for computational efficiency and abstraction, leaving the utility of complex relationship types untested.
  - **What evidence would resolve it:** Comparative evaluation of embeddings generated from multi-relational graphs versus the hierarchical baseline on intrinsic similarity tasks and downstream prediction accuracy.

- **Question:** Can integrating visit-level temporal information into the co-occurrence matrix enhance the model's ability to capture disease progression dynamics?
  - **Basis in paper:** [explicit] Section 7.2 notes the current approach aggregates complete patient histories, which fails to capture temporal dynamics, and suggests visit-level analysis as a future improvement.
  - **Why unresolved:** Aggregating data reduces matrix sparsity but discards the chronological order of clinical events, which is critical for modeling disease trajectories.
  - **What evidence would resolve it:** Results from a modified KEEP framework that preserves temporal sequence in the co-occurrence matrix, evaluated on time-sensitive clinical prediction tasks.

- **Question:** Does extending KEEP to include multi-domain concepts (medications, labs, procedures) yield more robust patient representations than the current disease-only focus?
  - **Basis in paper:** [explicit] Section 7.2 highlights that focusing solely on disease codes provides a limited view of patient health and suggests future work should explore multiple domains.
  - **Why unresolved:** The current study limited scope to condition concepts to manage complexity; the interaction between disease codes and other domains within the KEEP framework remains unexplored.
  - **What evidence would resolve it:** Performance benchmarks of multi-domain KEEP embeddings on clinical tasks requiring integration of diagnosis, medication, and lab data.

## Limitations

- Implementation details remain underspecified, particularly around the dense roll-up procedure for ancestor traversal and exact co-occurrence windowing logic
- Single global λ parameter may not optimally balance knowledge preservation and empirical fitting across different code types and institutional contexts
- Study focuses on disease codes only, limiting generalizability to the full clinical concept space including medications and procedures

## Confidence

- **High confidence:** Intrinsic evaluation results showing semantic relationship preservation, extrinsic task superiority (AUPRC, AUC, MCC), and computational efficiency claims
- **Medium confidence:** Regularization mechanism's effectiveness for rare codes and cross-institutional transfer capabilities
- **Low confidence:** Optimal λ selection and the assumption that a single parameter works across all downstream tasks

## Next Checks

1. **λ sensitivity analysis:** Systematically vary λ from 0 to 1 in log scale, measure impact on both Resnik similarity (ontological preservation) and AUPRC (task performance) to identify optimal tradeoff and validate the regularization mechanism.
2. **Cross-institutional transfer test:** Train KEEP embeddings on UK Biobank, evaluate on MIMIC-IV without retraining, comparing against institution-specific embeddings to quantify generalization capability and identify systematic differences in coding patterns.
3. **Rare code ablation study:** Isolate codes with <100 occurrences, compare KEEP against pure node2vec and pure GloVe using intrinsic semantic similarity tasks to empirically verify the rare code protection claim.