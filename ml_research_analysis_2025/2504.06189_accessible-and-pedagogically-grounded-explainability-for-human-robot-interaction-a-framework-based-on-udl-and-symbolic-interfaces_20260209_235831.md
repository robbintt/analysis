---
ver: rpa2
title: 'Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction:
  A Framework Based on UDL and Symbolic Interfaces'
arxiv_id: '2504.06189'
source_url: https://arxiv.org/abs/2504.06189
tags:
- robot
- explanation
- design
- user
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of making robot explainability
  accessible to users with diverse cognitive, communicative, and learning needs by
  integrating Universal Design for Learning (UDL) principles with symbolic communication
  strategies. The authors propose a multimodal explanation framework using Asterics
  Grid and ARASAAC pictograms, implemented through a lightweight HTTP-to-ROS 2 bridge
  for real-time interaction.
---

# Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction: A Framework Based on UDL and Symbolic Interfaces

## Quick Facts
- arXiv ID: 2504.06189
- Source URL: https://arxiv.org/abs/2504.06189
- Reference count: 16
- Authors: Francisco J. Rodríguez Lera; Raquel Fernández Hernández; Sonia Lopez González; Miguel Angel González-Santamarta; Francisco Jesús Rodríguez Sedano; Camino Fernandez Llamas
- Primary result: Multimodal explanation framework integrating UDL principles with symbolic communication using Asterics Grid and ARASAAC pictograms for accessible HRI

## Executive Summary
This paper presents a framework for making robot explainability accessible to users with diverse cognitive, communicative, and learning needs by integrating Universal Design for Learning (UDL) principles with symbolic communication strategies. The authors propose a multimodal explanation system using Asterics Grid and ARASAAC pictograms, implemented through a lightweight HTTP-to-ROS 2 bridge for real-time interaction. The framework emphasizes bidirectional explainability where both robot transparency and user understanding are actively aligned, often with the support of a human mediator such as a teacher. The approach is validated through practical examples of customizable communication boards designed to support shared understanding and improve mental model alignment in educational and assistive contexts.

## Method Summary
The framework implements a five-stage HTTP-to-ROS 2 bridge architecture where Asterics Grid interfaces send HTTP POST requests to a Flask server, which converts these to ROS 2 messages published to the `/asterics_commands` topic. The robot responds by mapping its internal states to semantic concepts that are translated into ARASAAC pictograms for display. The system uses symbolic communication strategies to facilitate alignment of mental models between robot and user, with UDL principles enabling multiple means of representation and expression. The bidirectional nature allows users to query or correct robot behavior via the grid interface, with a human mediator often playing an essential role in supporting shared understanding.

## Key Results
- Successfully implemented HTTP-to-ROS 2 bridge enabling web-based control of robots using Asterics Grid interface
- Demonstrated practical examples of customizable communication boards with ARASAAC pictograms for navigation scenarios
- Established framework architecture supporting bidirectional explainability with human mediator integration
- Showcased real-time semantic mapping from robot internal states to accessible symbolic representations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** High-iconicity symbolic interfaces (ARASAAC) reduce cognitive load and bridge the "perceptual belief" gap more effectively than text or speech alone for users with diverse cognitive needs.
- **Mechanism:** The framework replaces abstract linguistic reasoning with concrete visual stimuli by mapping internal robot states directly to pictograms with proven high transparency, bypassing potential language or abstract reasoning deficits.
- **Core assumption:** Users possess the visual processing capability to distinguish and interpret the specific pictograms used, and the iconicity translates directly to functional understanding in robotics contexts.
- **Evidence anchors:** [abstract] "...symbolic communication strategies to facilitate the alignment of mental models..."; [Page 1] "...ARASAAC pictograms... exhibit a high degree of iconicity..."; [corpus] NIM: Neuro-symbolic Ideographic Metalanguage paper supports ideographic languages overcoming literacy barriers.
- **Break condition:** If the robot's internal state becomes too complex or abstract and lacks a distinct visual metaphor, the mapping degrades, potentially confusing the user.

### Mechanism 2
- **Claim:** Universal Design for Learning (UDL) principles enable the system to sustain "mental model alignment" by offering multiple means of representation and expression.
- **Mechanism:** The system implements UDL to create a bidirectional feedback loop where users can query or correct robot behavior via the grid, revealing the user's current mental model to the mediator/robot for immediate correction of misalignments.
- **Core assumption:** The bidirectional channel effectively signals user misunderstanding or intent faster than observation alone, and interface latency is low enough to support real-time dialogue.
- **Evidence anchors:** [Page 4] "Explainability is not a one-way function but a bidirectional process..."; [Page 3, Table I] "5.1 Varied Queries... User presses 'Why did you stop?'..."; [corpus] DiverseClaire reinforces UDL value in computational contexts.
- **Break condition:** If the user lacks motor control or communicative intent to trigger input methods, bidirectionality collapses into passive broadcast.

### Mechanism 3
- **Claim:** Decoupling the robot's internal reasoning from the user interface via a semantic abstraction layer allows for context-aware scaffolding.
- **Mechanism:** A lightweight HTTP-to-ROS 2 bridge decouples heavy robotics middleware from the front-end interface, allowing the robot to publish semantic events rather than raw data, enabling the interface to present pedagogically appropriate versions without rewriting core control code.
- **Core assumption:** The semantic mapping layer accurately captures causality of robot behavior, and the Flask bridge maintains sufficient real-time performance to feel like synchronous conversation.
- **Evidence anchors:** [Page 4] "This design offers several advantages: it is platform-agnostic, modular..."; [Page 5] "The explanation pipeline consists of three layers: Semantic Mapping..."; [corpus] Explicit World Models for Reliable Human-Robot Collaboration supports semantic modeling necessity.
- **Break condition:** If network latency spikes or the Flask server bottlenecks, explanations may arrive after robot state changes, severing causal link between action and explanation.

## Foundational Learning

- **Concept: The Perceptual Belief Attribution Problem**
  - **Why needed here:** This is the core theoretical problem the paper attempts to solve - you cannot design explanation logic without understanding that users don't intuitively know what the robot "sees" or "knows."
  - **Quick check question:** Can you explain why a robot stopping for an unseen obstacle might confuse a user who thinks the robot is broken?

- **Concept: ROS 2 Topics and Publisher/Subscriber Model**
  - **Why needed here:** The architecture relies on a bridge pushing messages to a specific ROS 2 topic (`/asterics_commands`). Understanding this decoupling is essential for debugging the interface.
  - **Quick check question:** If the Flask server sends a message to `/asterics_commands`, but the robot doesn't move, what is the first component you check?

- **Concept: AAC (Augmentative and Alternative Communication)**
  - **Why needed here:** The user interface is built on Asterics Grid, an AAC tool. Understanding constraints and usage patterns of pictogram-based communication is vital to avoid over-complicating explanation boards.
  - **Quick check question:** Why might a literal translation of "Localizing via LiDAR" fail on a pictogram board, and how should it be simplified?

## Architecture Onboarding

- **Component map:** Asterics Grid → HTTP POST → Flask server → ROS 2 publisher → `/asterics_commands` topic → Robot Behavior Node → State Change → Semantic Mapping → Grid Update
- **Critical path:** User Click (Grid) → HTTP POST → Flask Server → ROS 2 Publisher → `/asterics_commands` Topic → Robot Behavior Node → State Change → Semantic Mapping → Grid Update
- **Design tradeoffs:** HTTP/Flask creates potential latency bottleneck and security vulnerability compared to native ROS 2 bridges, but allows any web-enabled device to control robot without complex configuration; restricting explanations to finite pictograms limits expressiveness but ensures 100% accessibility.
- **Failure signatures:** Stale State (Grid shows "Moving" when robot stopped - likely lost message); Unresponsive Input (User presses "Stop" and robot continues - check Flask server logs); Visual Confusion (User repeatedly pressing "Why?" without changing behavior - semantic mapping too abstract).
- **First 3 experiments:** 1) Loopback Latency Test - measure HTTP-to-ROS 2 message time to ensure <200ms; 2) Semantic mapping validation - verify correct ARASAAC pictogram appears for specific robot states; 3) Bidirectional Stress Test - rapidly alternate "Start" and "Stop" commands to verify bridge handles queued messages correctly.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent does the proposed UDL-grounded framework improve mental model alignment and trust for users with diverse cognitive needs compared to standard HRI interfaces?
- **Basis in paper:** [explicit] Authors state that "Future developments include deployments in educational and assistive contexts" and note current work is "the first step before deploying robots in different classrooms."
- **Why unresolved:** Paper validates framework only through technical implementation details and prototypical examples, lacking empirical data from intended user populations.
- **What evidence would resolve it:** Quantitative results from user studies measuring task performance, trust metrics, and mental model accuracy in real-world educational settings.

### Open Question 2
- **Question:** How can adaptive models be integrated to dynamically personalize explanation complexity and modality based on real-time interaction history?
- **Basis in paper:** [explicit] Conclusion explicitly lists "the integration of adaptive models to personalize explanations based on user profiles and interaction history" as future development.
- **Why unresolved:** Current implementation relies on static or pre-configured communication boards rather than algorithmic personalization that evolves during interaction.
- **What evidence would resolve it:** Functioning system demonstration where robot automatically adjusts vocabulary, speed, or symbolic density based on user engagement signals or comprehension errors.

### Open Question 3
- **Question:** How does the inclusion of a human mediator (teacher/caregiver) quantitatively impact the effectiveness of bidirectional explainability and user autonomy?
- **Basis in paper:** [inferred] Authors explicitly argue that "the role of a human mediator... may be essential to support shared understanding," yet framework architecture focuses heavily on direct robot-user interface loop.
- **Why unresolved:** While framework allows for mediator, paper doesn't define specific metrics or mechanisms to evaluate if mediation is strictly necessary or how it augments robot's transparency.
- **What evidence would resolve it:** Comparative studies analyzing success rates in collaborative tasks performed with vs. without mediator present to facilitate explanation process.

## Limitations
- Framework's effectiveness highly dependent on mediator's ability to translate complex robot behaviors into appropriate pictogram sequences, creating potential bottleneck in explanation pipeline
- Bidirectional nature assumes users can initiate queries via grid interface, which may not hold for individuals with severe motor or cognitive impairments
- Paper provides no quantitative validation of mental model alignment - claimed improvements in user understanding based on qualitative examples rather than measured outcomes

## Confidence
- **High confidence:** Architectural feasibility of HTTP-to-ROS 2 bridge and technical integration of Asterics Grid with ARASAAC pictograms (explicitly specified and implementable)
- **Medium confidence:** UDL-based pedagogical benefits (UDL well-established in education, but specific application to robot explainability lacks empirical validation)
- **Low confidence:** Scalability of symbolic interfaces for complex robot behaviors (paper demonstrates only simple navigation scenarios without addressing nuanced or emergent decision-making)

## Next Checks
1. **Mental model assessment study**: Conduct controlled experiments measuring user understanding before and after interacting with explanation system using standardized comprehension tests rather than qualitative observation alone
2. **Symbol transparency validation**: Perform systematic testing across diverse user groups to verify ARASAAC pictograms maintain consistent iconicity and comprehension levels when applied to robotics-specific concepts versus original AAC contexts
3. **Latency impact analysis**: Measure correlation between HTTP bridge latency (targeting <200ms) and user perception of explanation quality, determining maximum acceptable delay before bidirectional feel breaks down