---
ver: rpa2
title: 'GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on
  OpenStreetMap'
arxiv_id: '2601.07375'
source_url: https://arxiv.org/abs/2601.07375
tags:
- navigation
- instruction
- agent
- instructions
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GROKE, a vision-free LLM-based system for
  evaluating navigation instructions using OpenStreetMap data. The core idea is to
  treat an agent's success at following an instruction as a proxy for the instruction's
  navigability, avoiding the computational and licensing costs of visual simulators.
---

# GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap

## Quick Facts
- arXiv ID: 2601.07375
- Source URL: https://arxiv.org/abs/2601.07375
- Reference count: 40
- Key result: Vision-free LLM-based navigation instruction evaluation achieves 68.5% NE reduction vs baselines using OpenStreetMap data

## Executive Summary
This paper introduces GROKE, a vision-free system for evaluating navigation instructions using OpenStreetMap data and Large Language Models. The approach treats an agent's success at following instructions as a proxy for instruction quality, avoiding the computational and licensing costs of visual simulators. Through ablation studies, GROKE demonstrates that structured JSON spatial representations and hierarchical sub-instruction planning substantially outperform grid-based and visual graph formats. The system achieves 74% success rates with navigation errors as low as 41.3 meters on the Map2Seq dataset.

## Method Summary
GROKE operates by representing environments as topological graphs from OpenStreetMap, then using LLMs to execute navigation instructions through a two-stage process. First, instructions are decomposed into atomic sub-goals with explicit state tracking. Second, the system constructs JSON-formatted spatial contexts containing visible nodes, POIs, and directional branches. The Navigator Agent uses this structured input to predict navigation actions. The framework evaluates instructions through automated metrics (Navigation Error, Success Rate, nDTW) that correlate with human judgments, decoupling instruction quality assessment from visual perception challenges.

## Key Results
- 68.5% reduction in Navigation Error compared to baseline agents
- Success Rates up to 74% on Easy/Medium instructions
- Navigation Error as low as 41.3 meters on Map2Seq dataset
- Structured JSON representations outperform grid-based formats (63.0% vs 10.0% SR)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured JSON representations of spatial graphs enable more reliable LLM navigation reasoning than grid-based or visual graph formats.
- Mechanism: JSON's hierarchical organization separates nodes, connections, and POIs into discrete parseable sections, reducing cognitive load of extracting spatial relationships from dense text or ASCII matrices.
- Core assumption: LLMs perform better when spatial information is presented in hierarchically structured schemas rather than linear narratives or 2D grid encodings.
- Evidence anchors: [abstract] structured JSON and textual formats outperform grid-based and visual graph representations; [section A.1] Grid representation yields 175.4m NE vs 68.4m for JSON; JSON achieves 63.0% SR vs 10.0% for grid.

### Mechanism 2
- Claim: Decomposing navigation instructions into atomic sub-goals with explicit state tracking improves execution accuracy, especially for complex multi-step directions.
- Mechanism: The Sub-instruction Agent segments instructions into MOVE_FORWARD, TURN_LEFT, TURN_RIGHT primitives with status flags (TODO, IN_PROGRESS, COMPLETED).
- Core assumption: LLMs struggle with multi-step instruction tracking without external state management; explicit iteration counters prevent errors in repeated movements.
- Evidence anchors: [abstract] hierarchical architecture combines sub-instruction planning with topological graph navigation; [section A.2] LLM Divider achieves 53.8% SR on Hard instructions vs 23.1% for complete instruction approach.

### Mechanism 3
- Claim: Agent execution metrics (NE, SR, nDTW) serve as valid proxies for human judgments of instruction navigability when visual perception noise is removed.
- Mechanism: By operating purely on OSM graph topology and POI data, the system isolates linguistic/structural instruction quality from visual recognition failures.
- Core assumption: Instruction clarity can be evaluated independently of visual grounding; OSM-visible landmarks capture sufficient semantic content for realistic navigation guidance.
- Evidence anchors: [abstract] agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability; [section 4.2] NE correlates with human annotations at r = -0.31 (p < 0.01).

## Foundational Learning

- Concept: **Topological Graph Navigation**
  - Why needed here: The system represents environments as graphs G = (V, E, P) where navigation is waypoint selection rather than continuous control.
  - Quick check question: Given a graph node with degree > 2, how would you determine which outgoing edge corresponds to a "turn left" instruction?

- Concept: **Dynamic Time Warping for Path Fidelity**
  - Why needed here: SDTW and nDTW measure how closely the agent's trajectory matches ground truth, not just goal arrival.
  - Quick check question: Why would Success Rate alone be insufficient for evaluating whether an instruction was followed correctly?

- Concept: **Chain-of-Thought Reasoning Budgets**
  - Why needed here: Gemini-3's "thinking" process consumes 13K-22K tokens per episode; understanding the cost-accuracy tradeoff is critical for deployment.
  - Quick check question: What is the marginal token cost of reducing Navigation Error by 1 meter according to the paper's analysis?

## Architecture Onboarding

- Component map:
  - Sub-instruction Agent -> Visible Area Construction -> Navigator Agent

- Critical path:
  1. Landmark grounding via fuzzy matching (RapidFuzz) against OSM POI tags
  2. Sub-instruction decomposition with explicit iteration counters
  3. JSON spatial context construction (nodes, intersections, branches, POIs)
  4. Navigator prediction with COMPLETED/IN_PROGRESS status
  5. Termination check: all sub-goals complete OR max steps (100) OR max retries (15)

- Design tradeoffs:
  - **JSON vs Textual**: JSON shows better recovery from deviations (OSR 74% vs 67%) but minimal SR difference on Easy/Medium tasks
  - **High vs Low thinking**: High thinking achieves 75% SR vs 69% for Low, but consumes 41K vs 33K tokens
  - **LLM vs Rule-based divider**: LLM divider shows 39.7% SR improvement on Hard instructions but adds API cost

- Failure signatures:
  - Spatial Grounding failures (17/37 errors): POI not detected or wrong semantic mapping
  - Spatial Enumeration errors (6/37): Miscounting repeated landmarks ("3rd light")
  - Overshoot failures: Agent treats reference landmark as destination rather than waypoint
  - Turn prevention: Agent turns at landmark visibility rather than proceeding to landmark location first

- First 3 experiments:
  1. Replicate the JSON vs Grid comparison on 20 Map2Seq samples to confirm representation sensitivity on your target LLM
  2. Test sub-instruction divider with/without iteration counters on instructions containing "pass N lights" patterns
  3. Run correlation analysis between automated metrics and human ratings on a held-out set to validate the Agent-as-Judge proxy before scaling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the superior performance of structured JSON spatial representations generalize across diverse Large Language Model architectures, or is it an artifact of the specific training distribution of Gemini-3 Pro?
- Basis in paper: The "Limitations" section states the authors have not established if the preference for hierarchical data is universal and calls for future work to verify findings across a broader spectrum of models.
- Why unresolved: The ablation study comparing textual, JSON, Graphviz, and grid formats was restricted to the Gemini-3 Pro architecture.
- What evidence would resolve it: Replicating the spatial representation ablation study using open-weights and other proprietary LLMs (e.g., Llama, GPT-4) to compare Navigation Error and Success Rate metrics.

### Open Question 2
- Question: Can domain-specific Small Language Models (SLMs) trained via teacher-student distillation approximate GROKE's navigation performance while eliminating the latency and high token costs of high-reasoning models?
- Basis in paper: The "Conclusions & Future work" section explicitly aims to reduce computational overhead by using distillation to create compact models for edge deployment.
- Why unresolved: The current framework relies on "High" thinking configurations in Gemini-3 Pro, consuming roughly 41,347 tokens per episode, which hinders scalability and large-scale deployment.
- What evidence would resolve it: Training a student model on the execution traces generated by GROKE and evaluating its Navigation Error and Success Rate against the teacher model to quantify the performance-efficiency trade-off.

### Open Question 3
- Question: How can the evaluation framework be extended to validate navigation instructions that rely on purely visual cues (e.g., "red door," "graffiti wall") which are absent from OpenStreetMap data?
- Basis in paper: The "Limitations" section notes the vision-free approach restricts evaluation to structural navigability, failing to validate instructions dependent on non-encoded visual features.
- Why unresolved: The system operates solely on symbolic OSM representations (nodes, edges, POIs), creating a blind spot for environmental features not captured in standard map schemas.
- What evidence would resolve it: Developing a hybrid approach that integrates visual data (e.g., street-level imagery) for semantic grounding of visual descriptors and testing its correlation with human navigability ratings.

## Limitations

- Reliance on OSM data completeness - instructions referencing visual-only landmarks cannot be evaluated
- Computational intensity - each evaluation requires 13K-22K tokens, making large-scale assessment expensive
- Potential overfitting to Gemini-3's reasoning patterns, with no testing on other LLM architectures
- Limited exploration of failure modes in instructions with conditional logic or interdependent sub-steps

## Confidence

- Representation effects (JSON vs grid): High confidence - large performance gaps with clear evidence
- Instruction decomposition mechanism: Medium confidence - limited error analysis scope
- Proxy metric validity: Low confidence - small human-annotation sample (49 instructions) and lack of cross-dataset validation

## Next Checks

1. Cross-architectural validation on GPT-4o and Claude-3 to test JSON representation advantage generalization
2. Expanded human evaluation on 200+ instructions across multiple datasets to strengthen proxy metric validity claims
3. Ablation study isolating the contribution of OSM data quality vs instruction clarity by comparing GROKE performance on complete vs artificially degraded OSM graphs