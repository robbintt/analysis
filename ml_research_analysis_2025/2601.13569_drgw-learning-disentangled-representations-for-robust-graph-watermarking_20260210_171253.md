---
ver: rpa2
title: 'DRGW: Learning Disentangled Representations for Robust Graph Watermarking'
arxiv_id: '2601.13569'
source_url: https://arxiv.org/abs/2601.13569
tags:
- graph
- watermark
- uni00000013
- drgw
- structural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DRGW introduces a disentangled representation learning framework
  for graph watermarking that separates structural information from watermark carriers.
  The method employs an adversarially trained encoder to extract invariant structural
  representations while deriving independent watermark carriers, a graph-aware invertible
  neural network for lossless watermark embedding, and a structure-aware editor for
  robust discrete graph modifications.
---

# DRGW: Learning Disentangled Representations for Robust Graph Watermarking

## Quick Facts
- **arXiv ID:** 2601.13569
- **Source URL:** https://arxiv.org/abs/2601.13569
- **Reference count:** 40
- **Primary result:** Achieves near-perfect watermark detectability (AUC ≥ 0.998) with minimal fidelity loss (0.72% on link prediction)

## Executive Summary
DRGW introduces a disentangled representation learning framework for graph watermarking that separates structural information from watermark carriers. The method employs an adversarially trained encoder to extract invariant structural representations while deriving independent watermark carriers, a graph-aware invertible neural network for lossless watermark embedding, and a structure-aware editor for robust discrete graph modifications. Experimental results demonstrate DRGW achieves near-perfect watermark detectability (AUC ≥ 0.998) while maintaining superior transparency with minimal fidelity loss (0.72% on link prediction performance) and exceptional robustness against structural perturbations and adversarial attacks. The framework successfully addresses the fundamental challenges of information entanglement and discretization-induced watermark degradation in graph watermarking.

## Method Summary
DRGW operates through a three-stage training pipeline that first disentangles graph structure from watermark carriers using contrastive learning and orthogonality constraints, then employs a graph-aware invertible neural network for lossless watermark embedding in continuous latent space, and finally uses a structure-aware editor to convert continuous modifications into discrete graph edits that preserve both utility and watermark integrity. The framework trains on 18 datasets across social, academic, knowledge, and other graph categories, achieving robust watermarking through a 4-layer GIN encoder, 8-layer Graph-aware INN, and 3-layer MLP editor with specific hyperparameters including watermark dimension 128, strength α=0.1, and edit budget k=0.1%.

## Key Results
- Near-perfect watermark detectability (AUC ≥ 0.998) across all tested datasets
- Superior transparency with minimal fidelity loss (0.72% on link prediction performance)
- Exceptional robustness against structural perturbations and adversarial attacks
- Maintains performance across 18 datasets spanning 6 graph categories

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Separating graph representation into invariant structure and independent carrier subspaces preserves utility while providing a vessel for watermarks.
- **Mechanism:** A GIN-based encoder uses contrastive learning (Eq. 4) to force the structural representation ($h_s$) to be robust against augmentations (node dropping/edge adding). Simultaneously, an orthogonality constraint ($L_{ortho}$, Eq. 5) minimizes mutual information between $h_s$ and the watermark carrier ($h_w$), theoretically satisfying the data processing inequality (Eq. 2).
- **Core assumption:** Graph utility is primarily defined by structural properties that can be distilled into a single invariant vector $h_s$, leaving $h_w$ as a "residual" subspace capable of carrying independent information.
- **Evidence anchors:**
  - [abstract] "...adversarially trained encoder... derives a statistically independent watermark carrier..."
  - [section 4.2.1] "...modifications to the watermark carrier $h_w$ have a minimal effect on the invariant structural representation $h_s$..."
- **Break condition:** If the orthogonality loss ($L_{ortho}$) fails to converge, information couples back into $h_w$, causing watermark modifications to degrade link prediction performance (transparency loss).

### Mechanism 2
- **Claim:** A Graph-aware Invertible Neural Network (INN) provides a lossless channel that maximizes watermark signal integrity before discretization.
- **Mechanism:** The INN acts as a bijective mapping conditioned on $h_s$. It maps the carrier $h_w$ to a latent Gaussian distribution, adds the watermark ($z_w = f_{INN} + \alpha w$, Eq. 7), and maps it back. Because the transformation is invertible (lossless), the watermark signal is preserved in the continuous domain without the "information bottleneck" typical of VAEs.
- **Core assumption:** The conditioning on $h_s$ allows the INN to learn a transformation that is robust to graph perturbations, rather than just a generic reversible flow.
- **Evidence anchors:**
  - [abstract] "...graph-aware invertible neural network for lossless watermark embedding..."
  - [section 4.2.2] "...embedding transformation must be perfectly reversible... compels the use of an INN."
- **Break condition:** If the Jacobian determinant in the INN becomes unstable or the conditioning fails, the inverse mapping ($f^{-1}_{INN}$) will produce a noisy carrier, reducing detectability.

### Mechanism 3
- **Claim:** A structure-aware editor resolves the "discretization-induced degradation" by converting continuous watermark signals into durable discrete graph edits.
- **Mechanism:** Instead of decoding the graph (which treats watermarks as noise), the editor predicts "editing scores" for edges based on both $h_s$ and the modified carrier $\tilde{h}_w$ (Eq. 8). It selects the Top-$k$ highest-scoring edges to flip, explicitly optimizing the location of the watermark bits to survive quantization.
- **Core assumption:** The editor can identify edges that are "safe" to flip (minimal utility impact) while retaining the watermark signal.
- **Evidence anchors:**
  - [abstract] "...structure-aware editor that resolves the issue of latent modifications into discrete graph edits..."
  - [section 4.2.3] "A standard graph decoder... treat[s] the low-magnitude watermark signal as noise... Our editor is purpose-built... to maximize watermark preservation."
- **Break condition:** If the editor selects edges randomly or relies on unstable nodes (e.g., low-degree nodes prone to deletion), the watermark is lost during the continuous-to-discrete conversion.

## Foundational Learning

- **Concept: Disentangled Representation Learning**
  - **Why needed here:** To understand why the model splits the latent space into $h_s$ (structure) and $h_w$ (watermark) rather than using a holistic embedding.
  - **Quick check question:** Does the orthogonality constraint ($L_{ortho}$) ensure that changing the watermark vector $w$ leaves the structural vector $h_s$ unchanged?

- **Concept: Invertible Neural Networks (Normalizing Flows)**
  - **Why needed here:** To grasp how the framework ensures "lossless" embedding, contrasting with lossy autoencoders used in other latent-space methods.
  - **Quick check question:** Can you explain how the log-determinant of the Jacobian ($\log|\det J|$) in Eq. 6 allows for a bijective (reversible) mapping?

- **Concept: Graph Isomorphism Networks (GIN)**
  - **Why needed here:** The paper uses GIN as the backbone for the encoder; understanding its aggregation properties is key to understanding how it processes graph topology.
  - **Quick check question:** Why is the GIN architecture (sum aggregation) preferred here over mean aggregation (GCN) for capturing structural identity?

## Architecture Onboarding

- **Component map:** Encoder (GIN backbone -> Projection Heads -> $h_s$, $h_w$) -> Embedder (Graph-aware INN -> Latent Shift (+αw) -> Inverse INN ($\tilde{h}_w$)) -> Editor (MLP Score Predictor -> Top-k Mask -> Adjacency Update (ΔE))

- **Critical path:** The 3-stage training protocol (Appendix B.2) is the most critical constraint. Train Encoder for disentanglement/contrast (1000 epochs), then train INN/Editor for reconstruction (2000 epochs), then fine-tune entire system for adversarial robustness (3000 epochs). Warning: Do not attempt end-to-end training from scratch; the components rely on staged stabilization.

- **Design tradeoffs:**
  - **Robustness vs. Transparency:** Controlled by hyperparameters α (embedding strength) and k (editing budget).
  - **Evidence:** Section 5.2/Fig 3 shows a "sweet spot"; increasing α boosts robustness but linearly increases fidelity loss.

- **Failure signatures:**
  - **High Utility Loss (>2%):** Likely failure of the orthogonality constraint ($L_{ortho}$) or excessive editing budget (k).
  - **Low Detectability (AUC < 0.8):** Check if the INN training converged (check NLL loss) or if the Editor is discarding the watermark as noise (check ablation in Table 3).
  - **Collapse on Regular Graphs:** The "Towards" baseline fails here; if DRGW fails on Road Networks, check if the structural augmentations in Stage 1 are too aggressive for grid-like topologies.

- **First 3 experiments:**
  1. **Verify Disentanglement:** Visualize $h_s$ and $h_w$ using t-SNE (as in Fig. 4) to ensure they form distinct clusters and are not entangled.
  2. **Ablate the Editor:** Replace the Structure-aware Editor with a standard MLP decoder (recreate "w/o Editor" in Table 3) to measure the drop in robustness (AUC) and confirm the discretization hypothesis.
  3. **Parameter Sweep:** Run a grid search on α ∈ [0.05, 0.2] and k ∈ [0.05%, 0.2%] to plot the fidelity-robustness frontier (recreate Fig. 3) for your specific dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the disentanglement framework be extended to explicitly model rich node and edge semantics in heterogeneous graphs?
- **Basis in paper:** [explicit] Section 6 states that a "compelling direction for future work is to explicitly model rich node and edge semantics" using "type-aware disentanglement" to isolate watermarks from complex, type-specific information.
- **Why unresolved:** The current framework focuses primarily on topological structure and general graph types. Heterogeneous graphs (e.g., knowledge graphs with diverse relation types) contain semantic complexities that current disentanglement methods may not fully isolate, potentially compromising transparency.
- **What evidence would resolve it:** Demonstration of a modified DRGW architecture that maintains high watermark detectability and low fidelity loss on heterogeneous benchmark datasets without manual feature engineering.

### Open Question 2
- **Question:** What is the theoretical upper bound of the watermark capacity relative to the carrier subspace expressivity and editing budget?
- **Basis in paper:** [explicit] Section 6 notes that "effective watermark capacity is bounded not by the watermark dimension $w$ alone, but by the expressivity of the carrier subspace $h_w$ and the editor's budget $k$."
- **Why unresolved:** The paper empirically validates a fixed capacity (128 dimensions) but does not provide a theoretical method to maximize payload size based on the constraints of the carrier subspace or the structural budget $k$.
- **What evidence would resolve it:** A formal analysis defining the relationship between carrier dimension, budget $k$, and recoverable bits, or an algorithmic approach to maximizing bit-depth without exceeding the fidelity loss threshold.

### Open Question 3
- **Question:** How can the framework be adapted for streaming or dynamically evolving graph structures common in web applications?
- **Basis in paper:** [inferred] The paper focuses on static graph snapshots. However, the Introduction highlights that graph data is foundational to "social network analysis" and "recommendation systems," which are inherently dynamic.
- **Why unresolved:** The current disentangled encoder relies on a fixed structural representation $h_s$. In a dynamic setting, the structure evolves, potentially invalidating the invariant representation or the embedded watermark over time.
- **What evidence would resolve it:** An extension of the DRGW pipeline that allows for incremental updates to the watermark or structural representation as edges/nodes change, without retraining the entire model.

## Limitations

- The orthogonal disentanglement assumption lacks direct empirical validation beyond internal metrics, with no measurements of actual mutual information reduction between $h_s$ and $h_w$.
- The framework's effectiveness against targeted attacks where adversaries know the watermark location strategy is not rigorously tested - only random perturbation robustness is evaluated.
- The generalizability claim to "18 datasets across 6 categories" is weak, as detailed results are only reported on 4 datasets (Cora, Citeseer, Pubmed, Amazon) with others appearing in supplementary materials.

## Confidence

- **High Confidence:** The core experimental results showing superior robustness vs. baselines (NearDrop, GraphWater) and the mathematical framework for the 3-stage training pipeline.
- **Medium Confidence:** The mechanism claims around disentanglement orthogonality and discretization resolution, which rely heavily on internal validation without strong external corroboration in the corpus.
- **Low Confidence:** The generalizability claim to "18 datasets across 6 categories" - the paper only reports detailed results on 4 datasets with others appearing in supplementary materials.

## Next Checks

1. **Measure Mutual Information:** Compute the actual mutual information between $h_s$ and $h_w$ during training to verify the orthogonality constraint is achieving statistical independence, not just low correlation.

2. **Test Against Known-Strategy Attacks:** Design an attack where the adversary knows DRGW's watermark location strategy (top-k scoring edges) and attempts to specifically remove or corrupt these edges while preserving graph utility.

3. **Ablate the Conditioning Mechanism:** Remove the conditioning on $h_s$ from the INN and compare robustness/utility metrics to isolate whether the "graph-awareness" provides measurable benefit beyond a standard normalizing flow.