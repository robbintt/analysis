---
ver: rpa2
title: Generating Poisoning Attacks against Ridge Regression Models with Categorical
  Features
arxiv_id: '2501.07275'
source_url: https://arxiv.org/abs/2501.07275
tags:
- features
- poisoning
- categorical
- data
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses poisoning attacks against ridge regression
  models with both numerical and categorical features. It introduces a novel mixed-integer
  bilevel optimization formulation that explicitly models categorical features using
  SOS-1 constraints and optimizes them directly rather than treating them as continuous
  variables.
---

# Generating Poisoning Attacks against Ridge Regression Models with Categorical Features

## Quick Facts
- arXiv ID: 2501.07275
- Source URL: https://arxiv.org/abs/2501.07275
- Reference count: 34
- This paper introduces a novel mixed-integer bilevel optimization formulation for poisoning attacks against ridge regression models with both numerical and categorical features, using SOS-1 constraints and an iterative flipping heuristic (IFCF).

## Executive Summary
This paper addresses the challenge of poisoning attacks against ridge regression models when categorical features are present. The authors develop a mixed-integer bilevel optimization formulation that explicitly models categorical features using SOS-1 constraints, rather than treating them as continuous variables and rounding. They derive bounds for lower-level variables through sensitivity analysis and propose an iterative algorithm (IFCF) that combines local numerical optimization with categorical feature flipping. Experiments on House Price and Healthcare datasets show that IFCF improves the mean squared error (MSE) of poisoning attacks compared to existing benchmarks.

## Method Summary
The paper formulates poisoning attacks as a bilevel optimization problem where the attacker (upper level) modifies training data to maximize model error, while the model (lower level) minimizes error on the poisoned data. Categorical features are modeled using one-hot encoding with SOS-1 constraints for mutual exclusivity. The authors derive bounds for regression weights using SVD sensitivity analysis and reformulate the bilevel problem using KKT conditions. Since exact MINLP solvers are intractable for this problem, they propose an iterative heuristic (IFCF) that alternates between optimizing numerical features using local NLP solvers and flipping categorical features based on weight sensitivity.

## Key Results
- IFCF improves MSE of poisoning attacks compared to benchmarks, with average improvements of 2-8.8% on training data and 3-5.2% on testing data
- The Shifting Attack Strategy (SAS) outperforms the Iterative Attack Strategy (IAS) by 2-8.8% on training data and 3-5.2% on testing data
- The advantage of IFCF scales with the number of categorical features, with larger improvements on datasets with more categorical variables

## Why This Works (Mechanism)

### Mechanism 1: Explicit Modeling of Categorical Features via SOS-1 Constraints
Modeling categorical variables as binary decisions within Special Ordered Sets (SOS-1) theoretically produces stronger poisoning attacks than relaxing them to continuous variables and rounding. The paper uses one-hot encoding for categorical features, enforcing mutual exclusivity via set-partitioning constraints, treating the selection of a category as a discrete optimization decision rather than a continuous approximation.

### Mechanism 2: Variable Bounding via Sensitivity Analysis
Bounding the lower-level regression weights is required to make the single-level reformulation solvable and to tighten the convex relaxation of the bilinear terms. The authors derive bounds for the regression coefficients using the closed-form solution of ridge regression and Weyl's inequality, separating the influence of the poisoning samples from the clean data to limit how far weights can shift.

### Mechanism 3: Iterative Flipping of Categorical Features (IFCF)
A heuristic that alternates between optimizing numerical features and "flipping" categorical features based on weight sensitivity can solve the intractable MINLP problem practically. Since exact MINLP solvers fail on large datasets, the IFCF algorithm solves the continuous relaxation to find weights, identifies which categorical weights push prediction error most effectively, and flips the binary variables to select those categories.

## Foundational Learning

- **Concept: Bilevel Optimization**
  - Why needed here: The core mathematical structure of a poisoning attack is hierarchical: the attacker (Upper Level) modifies data to maximize error, knowing the model (Lower Level) will subsequently minimize error on that modified data.
  - Quick check question: Can you explain why a standard constrained optimization solver cannot solve a bilevel problem directly without reformulation?

- **Concept: Ridge Regression (Regularized Least Squares)**
  - Why needed here: The "follower" in this architecture is a Ridge Regression model. The paper relies on the closed-form solution of this model to derive the variable bounds and KKT conditions.
  - Quick check question: How does the regularization parameter λ affect the invertibility of the matrix and the stability of the weights?

- **Concept: KKT Conditions (Karush-Kuhn-Tucker)**
  - Why needed here: To solve the bilevel problem, the paper replaces the lower-level minimization problem with its KKT optimality conditions, converting the hierarchical problem into a single-level Mathematical Program with Equilibrium Constraints (MPEC).
  - Quick check question: In the context of the lower-level regression problem, what does the stationarity condition ∇L = 0 physically represent regarding the model weights?

## Architecture Onboarding

- **Component map:** Data Preprocessor -> SAS Engine (Numerical) -> Categorical Flipper (Heuristic) -> Bounds Calculator
- **Critical path:** Initialize Poison Samples → Run SAS (Optimize Numericals) → Extract Weights → Check Categorical Sensitivity → Flip Categories → Re-solve Ridge Regression → Loop until convergence
- **Design tradeoffs:** Exactness vs. Speed - the IFCF algorithm is a heuristic that finds a feasible solution but doesn't guarantee global optimality. Batch Size - the SAS algorithm depends on batch size, with smaller batches allowing finer-grained attacks but increasing computation time.
- **Failure signatures:** Solver Stalling - if using a standard MINLP solver on the KKT reformulation, the process will hang at the initial LP relaxation for datasets with >3 poisoning samples. SAS Stagnation - if regularization λ is set very high, the SAS algorithm provides negligible improvement over baseline.
- **First 3 experiments:**
  1. Baseline Reproduction: Implement IAS vs. SAS using only numerical features to verify improvement in MSE and computation time.
  2. Hyperparameter Sensitivity: Test IFCF across varying poisoning rates (4% to 20%) and regularization values to observe when attack effectiveness degrades.
  3. Ablation on Categoricals: Run IFCF on datasets with many vs. few categorical features to confirm advantage scales with categorical variables.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can poisoning attacks be extended to manipulate hyperparameter selection (e.g., regularization λ) in addition to model parameters?
- Basis in paper: The authors state that currently poisoning data samples are not taken into account when finding the optimal hyperparameter λ, but it would be interesting to explore how poisoning attacks can be designed to also affect hyperparameter selection.
- Why unresolved: The current formulation assumes λ is fixed before poisoning; integrating hyperparameter selection adds another optimization layer and complexity.
- What evidence would resolve it: A trilevel or modified bilevel formulation that successfully degrades model performance by jointly optimizing poisoning samples and targeting hyperparameter selection.

### Open Question 2
- Question: Can upper bounds be derived to certify the quality (optimality gap) of the heuristic poisoning attacks?
- Basis in paper: The authors note they know attacks are stronger than existing ones but don't know how close they are to the optimal solution, suggesting extending the solution method to include upper bounds that certify attack quality.
- Why unresolved: The MINLP problem is computationally intractable for realistic sizes; the IFCF heuristic provides no optimality guarantees.
- What evidence would resolve it: A bounding procedure that provides provable upper bounds on the maximum achievable MSE, enabling quantification of the heuristic's optimality gap.

### Open Question 3
- Question: How can exact solution algorithms scale to larger datasets with many categorical features?
- Basis in paper: The authors identify that the main challenge with exact approaches lies in the computational complexity introduced by the mixed-integer bilevel structure, especially as the number of categorical variables increases.
- Why unresolved: Current commercial solvers fail beyond toy instances; existing bilevel algorithms either require restrictive assumptions or are impractical for this MINLP structure.
- What evidence would resolve it: A scalable exact or branch-and-bound method with valid cuts that can solve problems with more than 3 poisoning samples and many categorical features to proven optimality within reasonable time.

### Open Question 4
- Question: Can defense strategies be formally developed using a trilevel optimization framework built upon this attack model?
- Basis in paper: The authors propose that this model can be used as the foundation for building and testing defense strategies, potentially as the two lower levels of a trilevel optimization problem.
- Why unresolved: Moving from bilevel attack formulation to trilevel defender-attacker-learner structure introduces additional computational and theoretical challenges.
- What evidence would resolve it: A trilevel formulation with a tractable reformulation and empirical demonstration that the derived defense strategy effectively mitigates poisoning attacks.

## Limitations
- The effectiveness of IFCF critically depends on the quality of bounds derived from sensitivity analysis, but sensitivity analyses showing how often these bounds exclude the optimal solution are not reported.
- The claim that SOS-1 constraints produce stronger attacks than continuous relaxation is not empirically validated against direct comparisons with rounded continuous solutions.
- The heuristic nature of categorical flipping means there is no guarantee of finding the global optimum, particularly when categorical features exhibit strong correlations.

## Confidence

- **High Confidence:** The theoretical framework using KKT conditions for bilevel optimization and the closed-form solution for ridge regression bounds are mathematically sound and well-established.
- **Medium Confidence:** The iterative flipping heuristic (IFCF) improves MSE compared to baselines on tested datasets, but the magnitude of improvement may vary with different data distributions and poisoning strategies.
- **Low Confidence:** The claim that SOS-1 constraints produce stronger attacks than continuous relaxation is not empirically validated against direct comparisons with rounded continuous solutions.

## Next Checks

1. **Bound Sensitivity Analysis:** Systematically vary the regularization parameter λ and measure how often the derived bounds exclude the optimal attack solution on held-out validation data.

2. **Correlation Impact Test:** Design synthetic datasets with varying degrees of correlation between categorical features to quantify how this affects the convergence and effectiveness of the IFCF algorithm.

3. **Global Optimality Gap:** Implement a small-scale exact solver (e.g., for datasets with ≤5 poisoning samples) to measure the optimality gap between IFCF solutions and proven global optima.