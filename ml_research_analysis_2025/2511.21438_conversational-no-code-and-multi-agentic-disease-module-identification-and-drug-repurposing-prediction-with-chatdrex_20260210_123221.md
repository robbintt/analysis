---
ver: rpa2
title: Conversational no-code and multi-agentic disease module identification and
  drug repurposing prediction with ChatDRex
arxiv_id: '2511.21438'
source_url: https://arxiv.org/abs/2511.21438
tags:
- nedrex
- chatdrex
- agent
- disease
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ChatDRex is a multi-agent conversational system that enables non-experts
  to perform network-based drug repurposing analyses using natural language. It integrates
  schema-constrained knowledge graph queries, network module expansion (DIAMOnD),
  drug prioritization (TrustRank, Closeness Centrality), functional coherence validation
  (DIGEST), and literature mining into a unified workflow.
---

# Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex

## Quick Facts
- arXiv ID: 2511.21438
- Source URL: https://arxiv.org/abs/2511.21438
- Reference count: 40
- ChatDRex achieves Tool-Accuracy ≥0.99 for core network tools and F₁ = 0.74 for knowledge graph queries

## Executive Summary
ChatDRex is a multi-agent conversational system enabling non-experts to perform network-based drug repurposing analyses through natural language. It integrates schema-constrained knowledge graph queries, network module expansion (DIAMOnD), drug prioritization (TrustRank, Closeness Centrality), functional coherence validation (DIGEST), and literature mining into a unified workflow. Evaluation shows high tool-accuracy (≥0.99) for core network tools, F₁ = 0.74 for knowledge graph queries, and reliable result interpretation, though automatic summarization of structured enrichment outputs remains a bottleneck. ChatDRex thus bridges complex bioinformatics tools and end users, accelerating hypothesis generation in drug repurposing research.

## Method Summary
ChatDRex is built on a multi-agent architecture using LangChain4j and Quarkus framework, with a Planning agent orchestrating specialized agents for knowledge graph querying, network analysis, functional enrichment, and literature mining. The system uses gpt-oss:20b via self-hosted Ollama with OpenWebUI, sharing unified control loops including few-shot prompting, memory management, and external tool integration. Knowledge graph queries are schema-constrained and translated to deterministic Cypher queries against Neo4j, while network tools (DIAMOnD, TrustRank, Closeness Centrality) produce deterministic outputs interpreted by the LLM. The system achieves high accuracy for computational tasks but shows reduced reliability for interpreting structured enrichment results from DIGEST.

## Key Results
- Deterministic network tools (DIAMOnD, TrustRank, Closeness Centrality) achieve Tool-Accuracy ≥0.99
- Schema-constrained knowledge graph queries achieve F₁ = 0.74 accuracy
- DIGEST functional coherence analysis shows Answer-Accuracy of 0.68 (human expert) vs 0.29 (LLM-as-Judge)
- End-to-end drug repurposing workflows demonstrated for Huntington's disease

## Why This Works (Mechanism)

### Mechanism 1
Schema-constrained knowledge graph querying reduces hallucinations by binding LLM outputs to a fixed ontology. User queries are decomposed into typed subquestions, enriched via embedding-based node matching against the NeDRex KG schema, then translated into deterministic Cypher queries executed on Neo4j. This grounds responses in verifiable graph traversals rather than free-form LLM generation. Core assumption: The KG schema adequately covers biomedical entities relevant to drug repurposing queries. Evidence anchors: Abstract states integration of schema-constrained queries with reliable result interpretation; section confirms query generation guided by known NeDRex schema reduces hallucinations; corpus reference to VitaGraph paper supports KG-based grounding. Break condition: Queries requiring entities or relationships absent from the NeDRex KG schema will fail or trigger fallback to GraphRAG, with uncertain quality.

### Mechanism 2
Multi-agent task decomposition enables reliable orchestration of specialized bioinformatics tools. A central Planning agent routes user requests to specialized agents (NeDRex, DIGEST, Research, etc.) based on task type. Each agent handles a narrow subtask using Chain-of-Thought reasoning, reducing cognitive load per agent and improving tool selection accuracy. Core assumption: Task boundaries are sufficiently clear for the Planning agent to route correctly. Evidence anchors: Abstract describes flexible multi-agent design assigning specific tasks to specialized agents; section reports network-based tools achieving near-perfect Tool-Accuracy (≥0.99); corpus reference to MARBLE paper supports multi-agent reasoning for bioinformatics workflows. Break condition: Ambiguous natural language requests may propagate misrouting through multi-step workflows, degrading downstream outputs.

### Mechanism 3
Deterministic backend tools with LLM interpretation create a hybrid reliability profile—strong for computation, weaker for narrative synthesis. Core algorithms (DIAMOnD, TrustRank, Closeness Centrality) produce deterministic outputs that the LLM passes through with minimal interpretation. DIGEST enrichment requires the LLM to summarize structured statistical outputs into natural language, introducing an abstraction layer where accuracy drops. Core assumption: Users can distinguish between reliable computational outputs and interpretive summaries. Evidence anchors: Section states final outcomes for network expansion and prioritization tools are determined directly by underlying API outputs; DIGEST shows reduced Answer-Accuracy (0.68 manual, 0.29 LLM-as-Judge) despite factually correct underlying information; corpus reference to "How Well Do LLMs Understand Drug Mechanisms?" paper documents similar LLM reasoning limitations in drug domains. Break condition: Complex enrichment outputs with multiple pathways will produce unreliable natural language summaries; manual verification remains necessary.

## Foundational Learning

- Concept: **Knowledge Graphs and Cypher Query Language**
  - Why needed here: ChatDRex's KG agent translates natural language to Cypher queries against Neo4j. Understanding node/edge schemas, traversal patterns, and query structure is essential to debug routing failures.
  - Quick check question: Given a Neo4j graph with `(:Drug)-[:TARGETS]->(:Protein)-[:ASSOCIATED_WITH]->(:Disease)`, write a Cypher query returning drugs targeting proteins associated with "Alzheimer's disease."

- Concept: **Network Medicine Fundamentals (seed genes, disease modules, PPI networks)**
  - Why needed here: DIAMOnD expands seed genes into disease modules based on connectivity in protein-protein interaction networks. TrustRank and Closeness Centrality rank drugs by network proximity.
  - Quick check question: Explain why a disease module identified by DIAMOnD might contain genes not previously linked to the disease in literature.

- Concept: **Multi-Agent LLM Architectures (planning, tool-calling, memory)**
  - Why needed here: ChatDRex uses a Planning agent to orchestrate specialized agents with short-term and long-term memory. Understanding agent coordination, tool selection, and context compression is critical for extending the system.
  - Quick check question: What happens if two specialized agents return conflicting information? How would you detect and resolve this?

## Architecture Onboarding

- Component map: User query → Planning Agent → (NeDRex KG → NeDRex Agent → DIGEST Agent → Research Agent) → Finalize Agent → Response
- Critical path: The parenthesized agents execute conditionally based on workflow needs, with Planning agent routing queries to specialized agents based on N-step decision process
- Design tradeoffs:
  - Tool accuracy vs. interpretive flexibility: Deterministic tools (≥0.99 accuracy) traded against DIGEST interpretation (0.68 manual accuracy)
  - Schema constraint vs. coverage: Fixed NeDRex schema reduces hallucinations but limits query scope; GraphRAG fallback adds flexibility at cost of traceability
  - Memory compression vs. context retention: Summary agent reduces tokens but may lose critical context across long sessions
- Failure signatures:
  - KG queries returning empty results with spelling variations (embedding enrichment should mitigate; if not, fallback triggers)
  - DIGEST summaries contradicting enrichment statistics (LLM-as-Judge scores 0.29 vs. expert 0.68—manual review required)
  - Planning agent stuck in routing loop (check N-step limit configuration; default N=6)
  - Hallucination guardrail blocking valid outputs (review output guardrail thresholds)
- First 3 experiments:
  1. Run the Huntington's disease workflow end-to-end (Figure 5). Verify: seed gene retrieval → DIAMOnD expansion (20 genes) → DIGEST coherence (empirical p-values) → TrustRank drug ranking. Compare tool outputs against manual API calls.
  2. Test KG agent with intentionally misspelled disease names (e.g., "Alzhimers" vs. "Alzheimer's"). Measure embedding-based node matching success rate and fallback frequency.
  3. Compare DIGEST Answer-Accuracy between LLM-as-Judge evaluation and human expert review using 10 enrichment results. Quantify the discrepancy and identify summary patterns causing mismatches.

Assumption: The public instance (apps.cosy.bio/chatdrex) reflects the evaluated architecture; local deployments may require BYOK API configuration.

## Open Questions the Paper Calls Out

### Open Question 1
How can automated evaluation metrics be refined to align with human expert judgment when assessing LLM summaries of structured enrichment results? Basis in paper: The authors observe a "pronounced mismatch" where the automated LLM-as-a-Judge scored DIGEST summaries at 0.29 accuracy, while manual expert evaluation yielded 0.68. Why unresolved: Current automatic evaluation schemes struggle to assess structured enrichment outputs expressed in natural language, often penalizing factually correct content. What evidence would resolve it: Development of a benchmark where automated evaluation scores show high statistical correlation with human expert assessments for functional coherence summaries.

### Open Question 2
How can the system improve the "interface" between deterministic statistical tools and natural language narrative explanation? Basis in paper: The Conclusion identifies a specific "bottleneck at the interface between the statistics of the deterministic tools and the narrative explanation" affecting the DIGEST agent. Why unresolved: Translating structured coherence scores and p-values into scientifically nuanced text introduces an abstraction layer prone to interpretation errors. What evidence would resolve it: An increase in the Answer-Accuracy of the DIGEST agent to levels comparable with the network tools (≥0.95) without requiring manual verification.

### Open Question 3
Can schema-constrained query generation be optimized to consistently resolve complex natural language queries into accurate knowledge graph lookups? Basis in paper: The Results section notes "remaining challenges in consistently resolving complex Neo4j queries derived from natural language" despite achieving an F₁-score of 0.74. Why unresolved: Ambiguities in natural language input and the complexity of mapping them to strict Cypher constraints limit the reliability of the Knowledge Graph agent. What evidence would resolve it: An increase in the Call-Accuracy F₁-score for the NeDRex KG agent significantly above 0.74 on a dataset of complex, multi-hop biomedical questions.

## Limitations
- Schema coverage limits query scope—entities or relationships outside the NeDRex KG schema will fail or trigger unreliable GraphRAG fallback
- DIGEST enrichment interpretation shows significant gap between LLM-as-Judge (0.29) and human expert (0.68) accuracy
- Ambiguous natural language requests may propagate misrouting errors through the multi-agent workflow

## Confidence
- **High Confidence**: Deterministic backend tools (DIAMOnD, TrustRank, Closeness Centrality) with Tool-Accuracy ≥0.99; schema-constrained KG querying mechanism reducing hallucinations
- **Medium Confidence**: Multi-agent orchestration effectiveness (based on related MARBLE paper FMR=0.53); overall system integration and end-to-end workflow reliability
- **Low Confidence**: DIGEST enrichment interpretation accuracy; GraphRAG fallback quality for out-of-schema queries; generalization to disease domains beyond NeDRex KG coverage

## Next Checks
1. **Schema Coverage Test**: Systematically evaluate KG agent performance on 50 disease-gene associations, comparing schema-constrained query success rate against GraphRAG fallback quality scores. Measure hallucination incidence and traceability.
2. **Multi-Agent Robustness**: Design 20 ambiguous user queries that could route to multiple agents. Test Planning agent accuracy and measure downstream impact on tool selection and result quality.
3. **DIGEST Interpretation Validation**: Compare LLM-as-Judge evaluation against 3 independent human experts on 30 enrichment results. Identify specific summary patterns causing interpretation failures and test guardrail improvements.