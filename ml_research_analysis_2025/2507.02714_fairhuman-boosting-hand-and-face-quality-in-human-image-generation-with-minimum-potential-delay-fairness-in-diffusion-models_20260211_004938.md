---
ver: rpa2
title: 'FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum
  Potential Delay Fairness in Diffusion Models'
arxiv_id: '2507.02714'
source_url: https://arxiv.org/abs/2507.02714
tags:
- generation
- image
- human
- images
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of generating high-quality\
  \ human images, particularly in local regions such as faces and hands, by proposing\
  \ FairHuman\u2014a multi-objective fine-tuning framework for diffusion models. The\
  \ core idea is to treat human image generation as a multi-objective optimization\
  \ problem, constructing separate loss functions for global image quality, face details,\
  \ and hand details."
---

# FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models

## Quick Facts
- **arXiv ID**: 2507.02714
- **Source URL**: https://arxiv.org/abs/2507.02714
- **Reference count**: 40
- **Primary result**: Proposes FairHuman, a multi-objective fine-tuning framework for diffusion models that significantly improves face and hand quality in human images while maintaining overall image quality through dynamic gradient weighting.

## Executive Summary
This paper addresses the challenge of generating high-quality human images, particularly in local regions such as faces and hands, by proposing FairHuman—a multi-objective fine-tuning framework for diffusion models. The core idea is to treat human image generation as a multi-objective optimization problem, constructing separate loss functions for global image quality, face details, and hand details. To achieve balanced optimization across these objectives, the authors incorporate the Minimum Potential Delay (MPD) fairness principle, which dynamically allocates gradient weights during training. FairHuman is applied to both LoRA and ControlNet modules of Stable Diffusion XL. Experiments show significant improvements in regional detail quality (faces and hands) while maintaining overall image quality. The method outperforms existing approaches like MoLE and ControlNet variants in both general and controllable generation scenarios, with superior metrics in Human Preference Score, ImageReward, and detection confidence for hands and faces.

## Method Summary
FairHuman treats human image generation as a multi-objective optimization problem with three distinct loss functions: global image quality (standard diffusion loss), face detail quality (masked MSE loss), and hand detail quality (masked MSE loss). The key innovation is the Minimum Potential Delay (MPD) fairness principle, which dynamically computes gradient weights to ensure balanced optimization across these objectives. The framework is implemented through parameter-efficient fine-tuning of LoRA and ControlNet adapters while keeping the Stable Diffusion XL backbone frozen. The MPD weights are computed using the formula W = (G^TG)^(-2/3)·1, where G contains the gradients of the three loss functions. This approach forces the model to optimize for small but important details that contribute little to the global loss but are critical for human perception.

## Key Results
- Significant improvements in hand and face detection confidence compared to baseline SDXL and MoLE approaches
- Better performance in Human Preference Score (HPS) and ImageReward metrics while maintaining competitive FID scores
- Outperforms ControlNet-Union in controllable generation scenarios while using fewer parameters
- Maintains overall image quality while achieving superior regional detail quality

## Why This Works (Mechanism)

### Mechanism 1: Multi-Objective Loss Decomposition with Regional Masking
- Claim: Separating global and local (face, hand) generation objectives via masked loss functions focuses learning on under-optimized regions.
- Mechanism: The standard diffusion loss (global MSE) is supplemented with two region-specific losses. Masks (m_f, m_h) derived from pre-annotated positional priors isolate face and hand regions in the latent space, creating distinct optimization targets (l_face, l_hand) alongside the global objective (l_global). This forces the model to attend to small, high-frequency details that contribute little to the global loss.
- Core assumption: The pre-trained backbone model (e.g., SDXL) already possesses the latent capability to generate plausible faces and hands but fails to apply it when these regions are small parts of a larger scene due to gradient competition.
- Evidence anchors:
  - [abstract]: "...we first construct three learning objectives: a global objective derived from the default diffusion objective function and two local objectives for hands and faces based on pre-annotated positional priors."
  - [section 3.2]: "...we construct the following optimization objectives for both local and global generation tasks, respectively: l_global(θ)...; l_face(θ)...; l_hand(θ)..."
  - [corpus]: Neighbor paper "MGHanD" (arXiv:2503.08133) confirms persistent difficulty with hands in diffusion models, validating the need for focused guidance.

### Mechanism 2: Minimum Potential Delay (MPD) Fairness for Dynamic Gradient Weighting
- Claim: A dynamic weighting strategy based on MPD fairness ensures balanced optimization across objectives with different learning difficulties.
- Mechanism: Instead of fixed weights, the update direction d is computed as a weighted sum of task gradients (∇l_i). The weights W are derived by minimizing the "potential delay" for all tasks, formally solved as W = (G(θ)^TG(θ))^(-2/3) 1. This explicitly up-weights objectives with slower progress (smaller gradient contributions), which are typically the hard local tasks.
- Core assumption: The gradients for global, face, and hand objectives are linearly independent, satisfying MPD's prerequisites. Faces and hands are inherently harder to optimize than global structure in human image generation.
- Evidence anchors:
  - [abstract]: "...we derive the optimal parameter updating strategy under the guidance of the Minimum Potential Delay (MPD) criterion..."
  - [section 3.3]: "By optimizing Eq.(4), the potential delay of l_1(θ), l_2(θ), l_3(θ) can be minimized simultaneously... The corresponding potential delay is 1/||proj_∇l_i(θ)(d)||."
  - [corpus]: No direct evidence in corpus for MPD in diffusion, marking this as a novel cross-domain application from network resource allocation.

### Mechanism 3: Parameter-Efficient Fine-Tuning (PEFT) with Frozen Backbone
- Claim: Applying the multi-objective optimization to lightweight adapters (LoRA, ControlNet) preserves the backbone's general knowledge while efficiently injecting regional expertise.
- Mechanism: The backbone model's parameters θ_base are frozen. The MPD-guided updates d are applied only to the parameters of auxiliary modules (θ_update for LoRA or ControlNet). This prevents catastrophic forgetting of global generation capabilities while learning the new regional objectives.
- Core assumption: The frozen backbone provides a sufficiently strong foundation for general image synthesis, and the adapters have enough capacity to model the residual correction needed for detailed local regions.
- Evidence anchors:
  - [section 3.4]: "...we opt to deploy our method in LoRA[10] and ControlNet[50] while freezing the parameters of the backbone model."
  - [section 4.2, Table 4]: Comparison with MoLE shows FairHuman (using a single LoRA) requires less memory and inference time than a multi-module expert approach, suggesting efficient parameter specialization.

## Foundational Learning

**Concept: Multi-Objective Optimization (MOO) and Pareto Optimality**
- Why needed here: To understand that FairHuman treats image generation not as a single task but as competing tasks (global vs. local). A solution is Pareto optimal if no single objective can be improved without degrading another.
- Quick check question: Why can't a simple weighted sum of losses (L_total = αL_global + βL_local) guarantee Pareto optimality?

**Concept: Latent Diffusion Models (LDMs) and VAE Encoder Spaces**
- Why needed here: The loss functions are computed in the latent space (z_t), not pixel space. Understanding how regional masks are reshaped to latent shapes (as per inpainting methods) is critical for implementation.
- Quick check question: How does operating in the VAE's latent space affect the computation of the regional MSE loss for faces and hands?

**Concept: Gradient Surgery / Manipulation in Multi-Task Learning**
- Why needed here: The MPD method is a form of gradient manipulation. Understanding that conflicts in multi-task learning often arise from opposing gradient directions helps contextualize why a fairness-aware update direction is needed.
- Quick check question: In standard multi-task learning, what problem arises when the gradients of two tasks point in opposite directions?

## Architecture Onboarding

**Component map:**
Data Pre-processing (annotation generation) -> FairHuman Controller (mask generation, loss computation) -> MPD Optimizer (gradient weighting) -> LoRA/ControlNet (parameter update) -> Frozen SDXL Backbone (forward pass)

**Critical path:**
1. **Data Pre-processing**: Extract/correct bounding boxes for face/hands. Generate caption, pose, and depth maps.
2. **Training Step**: Forward pass through backbone + adapter. Compute 3 losses using global and masked noise predictions.
3. **Optimization**: Backpropagate 3 losses to get 3 gradients. Feed gradients into MPD computation to get update vector d. Update only adapter weights.

**Design tradeoffs:**
- **Rank/Capacity vs. Overfitting**: Higher LoRA rank (e.g., 256) captures more detail but increases risk of overfitting and compute.
- **MPD vs. Fixed Weights**: MPD balances learning dynamically but adds computational overhead to each optimization step compared to a simple weighted sum.
- **Single vs. Multi-Module**: FairHuman uses a single module for joint optimization (more efficient) vs. MoLE's separate modules (potentially more specialized but heavier).

**Failure signatures:**
- **Mode Collapse/Regression**: Global image quality degrades significantly (check HPS/CLIP scores) -> MPD weights may be too biased toward local tasks.
- **Regional Artifacts**: Hands/faces still distorted or disjoint -> Mask generation is inaccurate, or MPD is not sufficiently up-weighting local gradients.
- **Optimization Instability**: Loss oscillates or NaNs -> Gradient magnitudes are exploding; check the conditioning of the Gram matrix in MPD calculation.

**First 3 experiments:**
1. **Ablation Study (Single vs. Multi-Objective)**: Train LoRA with only global loss vs. global + unweighted local losses vs. global + local + MPD. Validate hypothesis that MPD provides a crucial balance.
2. **Component Validation (LoRA Rank)**: Train LoRA with ranks [64, 128, 256] on a small subset. Evaluate regional detection confidence to find the inflection point for capacity.
3. **Baseline Comparison (Qualitative)**: Generate a fixed set of 50 challenging whole-body prompts. Run SDXL, MoLE, and FairHuman. Perform a blind user study focused specifically on hand and face realism to confirm the key outcome.

## Open Questions the Paper Calls Out

**Open Question 1**
- **Question**: Can the FairHuman multi-objective framework be effectively extended to optimize generation quality for other fine-grained human attributes, such as feet or eyes?
- **Basis in paper**: [explicit] The Conclusion states: "For future work, we plan to further design and optimize corresponding objective functions for more attributes related to humans, such as feet and eyes."
- **Why unresolved**: The current study limits the local optimization objectives to hands and faces. Extending to other body parts requires constructing specific mask-based loss functions and verifying if the MPD fairness strategy can balance these new gradients against global and existing local objectives.
- **What evidence would resolve it**: Experimental results showing the application of the framework to datasets annotated for feet/eyes, with corresponding improvements in regional detection confidence or FID scores for those specific body parts.

**Open Question 2**
- **Question**: Would incorporating aesthetic or human preference feedback into the multi-objective optimization improve performance in preference-based metrics (HPS, ImageReward) without sacrificing anatomical plausibility?
- **Basis in paper**: [inferred] In the Quantitative Analysis (Table 1), the authors note that ControlNet-Union scores higher in HPS/IR because it uses "aesthetic and preference feedback learning," whereas FairHuman focuses on "realism and plausibility." This implies a potential trade-off that has not yet been unified.
- **Why unresolved**: The current loss functions (l_global, l_face, l_hand) are based on MSE and do not explicitly account for abstract human preferences or aesthetics, creating a gap in preference-based benchmarks.
- **What evidence would resolve it**: Ablation studies adding a preference-based loss term as a fourth objective within the MPD framework, demonstrating improved HPS/ImageReward scores while maintaining high hand/face detection confidence.

**Open Question 3**
- **Question**: How robust is the MPD fairness optimization to noise or inaccuracies in the pre-annotated positional priors used to generate local masks?
- **Basis in paper**: [inferred] The method relies on "pre-annotated positional priors" to construct masks for local losses (l_face, l_hand). The authors mention filtering datasets to ensure quality, but do not analyze how the gradient weighting behaves if the mask misaligns with the actual region of interest.
- **Why unresolved**: The effectiveness of the local objective functions is strictly dependent on the accuracy of the bounding box annotations. If the "hand" mask captures background noise or misses fingers, the MPD gradient weighting might optimize for the wrong features.
- **What evidence would resolve it**: Experiments measuring generation quality (FID, detection confidence) when training with synthetically perturbed or noisy bounding box annotations to simulate imperfect data.

## Limitations
- The method's effectiveness is strictly dependent on accurate face/hand detection and annotation, which may fail on unusual poses or occlusions.
- The MPD fairness principle, while theoretically sound, represents a novel cross-domain application and its effectiveness beyond human image generation remains unproven.
- The paper does not address potential trade-offs between regional detail quality and global image coherence in more challenging scenarios (e.g., complex backgrounds or extreme lighting conditions).

## Confidence

**High Confidence**: The multi-objective loss decomposition with regional masking is a sound approach, well-grounded in existing diffusion model fine-tuning practices. The observed improvements in face and hand quality are likely attributable to this mechanism.

**Medium Confidence**: The application of MPD fairness for dynamic gradient weighting is theoretically sound but represents a novel cross-domain application. While the experimental results are positive, the sensitivity of this method to the correlation structure of gradients across tasks requires further investigation.

**Medium Confidence**: The PEFT approach using LoRA and ControlNet is a standard and effective strategy. The reported efficiency gains over MoLE are plausible, but a more comprehensive ablation study on different adapter capacities would strengthen this claim.

## Next Checks

1. **MPD Sensitivity Analysis**: Conduct an ablation study comparing FairHuman with fixed-weight multi-objective training across varying levels of task gradient correlation. This will validate the necessity and robustness of the MPD weighting strategy.

2. **Detector Robustness Test**: Evaluate FairHuman's performance on a dataset with intentionally challenging face/hand annotations (occluded, extreme poses, unusual lighting). This will assess the method's resilience to annotation noise.

3. **Cross-Domain Application**: Apply the FairHuman framework (loss decomposition + MPD weighting) to a different generation task, such as enhancing animal faces or product details. This will test the generalizability of the core mechanisms beyond human images.