---
ver: rpa2
title: Race, Ethnicity and Their Implication on Bias in Large Language Models
arxiv_id: '2601.12868'
source_url: https://arxiv.org/abs/2601.12868
tags:
- black
- asian
- china
- native
- white
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work presents a mechanistic interpretability study of how\
  \ race and ethnicity are represented and operationalized within large language models.\
  \ Using two public datasets\u2014one for toxicity-related generation and one for\
  \ clinical narrative understanding\u2014the authors analyze three open-source models\
  \ (Qwen2.5-7B, Mistral-7B, Llama-3.1-8B) with a reproducible pipeline combining\
  \ probing, neuron-level attribution, and targeted intervention."
---

# Race, Ethnicity and Their Implication on Bias in Large Language Models

## Quick Facts
- arXiv ID: 2601.12868
- Source URL: https://arxiv.org/abs/2601.12868
- Reference count: 15
- Primary result: Race/ethnicity representations are distributed across many neurons rather than localized, and neuron-level interventions reduce but don't eliminate bias

## Executive Summary
This paper presents a mechanistic interpretability study examining how race and ethnicity are represented and operationalized within large language models. Using two public datasets (ToxiGen for toxicity-related generation and C-REACT for clinical narrative understanding), the authors analyze three open-source models (Qwen2.5-7B, Mistral-7B, Llama-3.1-8B) with a reproducible pipeline combining probing, neuron-level attribution, and targeted intervention. They find that demographic information is distributed across internal units with substantial cross-model variation, and that race/ethnicity representations are decomposed into multiple semantic facets (e.g., explicit group labels, geographic terms, cultural identifiers). Some units encode stereotype-related associations, and identical demographic cues can induce qualitatively different behaviors across models. Interventions suppressing highly active neurons reduce bias but leave substantial residual effects, suggesting that behavioral rather than representational change is needed.

## Method Summary
The authors develop a pipeline to identify and intervene on race-encoding neurons in LLMs. They train linear probes on final-layer residual streams to extract race directions, then compute cosine similarity between each neuron's output vector and probe directions to rank neurons by their contribution to racial representations. Top-k neurons are verified via Logit Lens to confirm semantic alignment, then subjected to activation suppression interventions. The intervention multiplies positive activations by negative factors (e.g., -5) to make targeted neurons' contributions subtractive. This approach is applied to three 7-8B parameter models on two datasets, measuring bias reduction through classification accuracy changes and analyzing residual effects.

## Key Results
- Race/ethnicity representations are distributed across many MLP neurons rather than localized to a small set of units
- Direct neurons encoding explicit demographic terms show stronger causal influence on bias than indirect neurons encoding geographic/cultural proxies
- Interventions reduce but don't eliminate bias, with 20-37% residual errors persisting after neuron suppression
- Cross-model variation exists in how race/ethnicity is represented and operationalized, with identical cues producing different behaviors

## Why This Works (Mechanism)

### Mechanism 1: Distributed Multi-Faceted Demographic Encoding
Race/ethnicity representations are decomposed across many MLP neurons into distinct semantic facets rather than localized to a small set of units. MLP layers function as key-value memories; individual neurons encode specific semantic dimensions (geographic terms, cultural identifiers, demographic labels, historical associations) that collectively represent racial concepts. The paper shows neurons like `MLP.v325691` encoding "Chinese, China, Beijing" while `MLP.v3114299` encodes Chinese surnames ("Li, yuan, Dong, Huang").

### Mechanism 2: Probe-Derived Direction Alignment for Neuron Identification
Linear probes trained on final-layer residual streams extract race directions that can identify which MLP neurons write to demographic-relevant subspaces. Probes learn weight vectors `w_c` for each race class c. Cosine similarity between each neuron's output vector `v_j` and `w_c` ranks neurons by their contribution to racial representations. Logit Lens verification (`z_probe = W_U * w_c`) confirms semantic alignment before selection.

### Mechanism 3: Activation Suppression Reduces but Does Not Eliminate Bias
Sign-flipping activations of race-encoding neurons reduces classification bias but leaves substantial residual effects, indicating biased behavior cannot be fully controlled by manipulating identifiable neurons alone. Interventions multiply positive activations by negative factors (e.g., -5), making targeted neurons' contributions subtractive. Direct neurons (encoding explicit demographic terms) show stronger causal influence than indirect neurons (encoding geographic/cultural proxies).

## Foundational Learning

- **Concept: SwiGLU MLP Architecture**
  - Why needed here: The paper analyzes MLP output vectors `v_j` from the down-projection matrix; understanding `MLP(x) = (SwiGLU(xW_gate) ⊙ (xW_up)) W_down` is essential for interpreting how neurons contribute to the residual stream.
  - Quick check question: In SwiGLU, what determines whether a neuron's contribution is added to or subtracted from the residual stream?

- **Concept: Linear Probing**
  - Why needed here: The entire neuron identification pipeline depends on training probes `W_Race` that classify race from residual stream representations.
  - Quick check question: If a probe achieves 90% accuracy on held-out data, does this guarantee the probe direction corresponds to how the model internally uses demographic information? (Answer: No—probes can exploit correlations the model doesn't causally use.)

- **Concept: Logit Lens / Unembedding Projection**
  - Why needed here: The method projects neuron output vectors to vocabulary space to verify semantic content (e.g., confirming a neuron encodes "Japanese, Japan, Tokyo" rather than noise).
  - Quick check question: When `W_U * v_j` produces top tokens including geographic and demographic terms, what does this indicate about the neuron's functional role?

## Architecture Onboarding

- **Component map:**
  Input Text → Residual Stream (Layers 0..L-1) → Linear Probe Training → MLP Layers (final 4) → Neuron Output Vectors v_j → Cosine Similarity with Probe Directions → Top-k Neurons → Logit Lens Verification → Activation Analysis (group-specific responses) → Intervention (sign-flip × amplification factor) → Behavioral Change Measurement

- **Critical path:** Probe training → neuron ranking → Logit Lens filtering → activation pattern validation → intervention tuning. Skipping Logit Lens verification risks intervening on neurons that happen to align with probe directions but encode unrelated concepts.

- **Design tradeoffs:**
  - Higher amplification factors (10, 20) achieve similar bias reduction but cause model instability (63% "Unknown" outputs at factor 20 for Qwen)
  - Direct neurons: stronger behavioral effect but require explicit demographic terminology in training data
  - Indirect neurons: broader coverage of proxy cues but weaker causal influence and residual bias remains

- **Failure signatures:**
  - High "Unknown" response rates indicate excessive amplification destabilizing generation
  - Diagonal activation patterns not appearing suggests probe learned spurious directions
  - Intervention improving one group while degrading another indicates non-isolated demographic pathways

- **First 3 experiments:**
  1. Replicate probe training on ToxiGen with 5-way classification; verify accuracy matches reported ~75% macro-F1 before proceeding to neuron identification.
  2. Extract top-20 neurons per race group for a single model; use Logit Lens to confirm semantic alignment (e.g., Asian neurons should project to Asian/Chinese/Japan-related tokens, not random vocabulary).
  3. Run intervention on C-REACT indirect mentions with amplification factor 5; confirm Direct neuron intervention eliminates dominant error pattern (e.g., White→Asian for Llama) while measuring "Unknown" response rate as stability check.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can bias mitigation approaches systematically address residual bias that persists after neuron-level suppression?
- Basis in paper: The authors state that "interventions suppressing such neurons reduce bias but leave substantial residual effects" and conclude that "biased behavior in LLMs cannot be fully explained or controlled by manipulating a small set of identifiable neurons alone."
- Why unresolved: The neuron-level intervention framework achieves only partial behavioral correction; the distributed nature of demographic information means suppressing identified neurons leaves other encoding pathways active.
- What evidence would resolve it: Development of intervention methods that achieve near-complete bias elimination, or identification of the mechanisms sustaining residual bias beyond identified neurons.

### Open Question 2
- Question: What mechanisms determine when benign demographic representations become inappropriately operationalized as task-specific bias?
- Basis in paper: The authors observe that "the presence of such representations is not inherently problematic. Rather, bias arises from how these representations are operationalized during inference."
- Why unresolved: The paper identifies this distinction but does not characterize the conditions or circuit-level mechanisms that cause representations to be selectively reused in biased ways.
- What evidence would resolve it: Causal analysis identifying the attention or routing mechanisms that selectively amplify demographic representations in task-irrelevant contexts.

### Open Question 3
- Question: Do the findings on distributed demographic encoding generalize across model scales, architectures, and training regimes?
- Basis in paper: The study examines only three 7-8B parameter models from different geographic contexts; the generalizability to larger models, different architectures, or proprietary systems remains untested.
- Why unresolved: Model-specific localization was required even among similar-scale models, suggesting encoding patterns may vary substantially with architecture and training data.
- What evidence would resolve it: Replication of the probing and intervention pipeline across models spanning 1B-100B+ parameters and diverse architectures (e.g., MoE, dense).

## Limitations
- The intervention approach reduces but doesn't eliminate bias, with 20-37% residual errors persisting after neuron suppression
- Cross-model variation is documented but generalizability to larger models and different architectures remains untested
- The causal relationship between probe directions and model behavior during generation is partially demonstrated, relying on assumptions about probe validity

## Confidence

**High Confidence** (mechanistic evidence strong, direct measurements):
- Race/ethnicity representations are distributed across MLP neurons rather than localized
- Direct neurons encoding explicit demographic terms show stronger causal influence than indirect neurons
- Intervention reduces but does not eliminate bias, with residual effects persisting across models

**Medium Confidence** (evidence present but methodological assumptions required):
- Probe directions accurately capture model-internal demographic processing pathways
- Logit Lens verification reliably confirms neuron semantic content
- Cross-model variation reflects fundamental architectural differences rather than training artifacts

**Low Confidence** (minimal direct evidence, speculative extensions):
- Distributed representation finding generalizes to larger or differently architected models
- Residual bias indicates need for behavioral rather than representational interventions (this is an interpretation rather than a proven conclusion)

## Next Checks
1. **Probe-to-Behavior Causal Validation**: Ablate the top-20 identified neurons and measure changes in generation behavior beyond the C-REACT and ToxiGen evaluation sets. Test whether behavioral changes align with expected demographic processing shifts, confirming that probe directions capture causally relevant representations.

2. **Intervention Transferability Test**: Apply the same direct and indirect neuron interventions across all three models on a held-out evaluation set (e.g., demographic generalization tests). Measure whether the relative performance gap between direct and indirect interventions persists, validating that the mechanistic distinction is not model-specific.

3. **Residual Bias Decomposition**: Systematically identify which demographic groups show persistent bias after intervention by analyzing error patterns. Determine whether residual effects concentrate in specific race categories or represent more general degradation, clarifying whether incomplete suppression or fundamental architectural limitations drive the remaining bias.