---
ver: rpa2
title: Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large
  Language Models
arxiv_id: '2503.07693'
source_url: https://arxiv.org/abs/2503.07693
tags:
- seidr
- program
- gpt-3
- tournament
- experiments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SEIDR, a multi-agent framework for autonomous
  program synthesis using large language models. SEIDR iteratively generates, executes,
  and debugs code, addressing the "near-miss syndrome" where generated code closely
  resembles correct solutions but fails unit tests due to minor errors.
---

# Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models

## Quick Facts
- **arXiv ID:** 2503.07693
- **Source URL:** https://arxiv.org/abs/2503.07693
- **Reference count:** 24
- **One-line primary result:** SEIDR framework solves 18 C++ and 20 Python problems on PSB2 benchmark using Llama 3-8B, achieving 84.2% pass@100 on HumanEval-C++

## Executive Summary
This paper introduces SEIDR, a multi-agent framework that addresses the "near-miss syndrome" in LLM-based program synthesis, where generated code compiles but fails tests due to minor logic errors. The framework iteratively generates, executes, and debugs code using five specialized agents: Synthesize, Execute, Instruct, Debug, and Rank. Experiments demonstrate that SEIDR outperforms conventional LLM use and genetic programming approaches on both PSB2 and HumanEval-X benchmarks, with particular success in solving problems that conventional methods struggle with.

## Method Summary
SEIDR employs a multi-agent architecture that iteratively improves candidate solutions through a cycle of synthesis, execution, and debugging. The framework generates initial code candidates, executes them against unit tests to capture errors, translates runtime feedback into natural language instructions, and uses an instruction-tuned LLM to repair the code. The process uses beam search with configurable tree arity to balance exploration (generating new candidates) and exploitation (repairing existing ones). The system incorporates both static and LLM-generated instruction mechanisms, and employs tournament or lexicase selection strategies to rank candidates based on test pass rates.

## Key Results
- SEIDR solves 18 C++ and 20 Python problems on PSB2 benchmark, outperforming conventional LLM use and genetic programming
- On HumanEval-C++, SEIDR with Llama 3-8B achieves 84.2% pass@100, significantly higher than GPT-3.5's 73.2%
- Tree arity of 10 yields optimal results (19/25 problems solved), demonstrating the effectiveness of hybrid repair-replace strategies
- Lexicase selection improves C++ results for GPT-3.5 but shows no clear advantage across all configurations

## Why This Works (Mechanism)

### Mechanism 1
The framework addresses near-miss syndrome by converting runtime feedback into natural language instructions that an instruction-tuned LLM can use for targeted repairs. The Execute agent captures stderr and failing I/O pairs, while the Instruct agent translates these signals into bug summaries like "Fix {stderr}" or "It must return {O} for input {I}". The Debug LLM then conditions on this summary to edit the code. This mechanism assumes the LLM has sufficient reasoning capabilities to map textual error descriptions to correct code edits. The system fails if instructions are ambiguous or errors are structural rather than logical.

### Mechanism 2
SEIDR employs a hybrid search strategy controlled by tree arity (N), balancing repair of existing candidates with generation of new ones. With N=10, the framework generates multiple repairs for a candidate before discarding it, outperforming pure repair (N=1) or pure generation (N=∞) approaches. This assumes the solution space is dense enough that a near-miss program is a better starting point than random initialization. The mechanism fails if sampling strategy doesn't produce diverse repairs, causing the beam to collapse into identical code.

### Mechanism 3
The framework uses lexicase selection to maintain candidates that solve different subsets of tests, potentially improving robustness compared to tournament selection based on average pass rate. Lexicase iteratively filters candidates by shuffling tests and selecting those that pass each test in sequence, preserving specialist programs for specific edge cases. This assumes partial solutions can be assembled into complete solutions, though results show this depends heavily on problem landscape and selection strategy.

## Foundational Learning

- **Concept: Instruction Fine-Tuning**
  - **Why needed here:** The framework relies on the Debug LLM understanding commands like "Modify the code as {bug_summary}" rather than just completing code. You must distinguish between base code models and instruction/chat models.
  - **Quick check question:** Can the model accept a prompt containing code and a specific edit command, or does it only autocomplete the code?

- **Concept: Evolutionary Search (Genetic Programming)**
  - **Why needed here:** SEIDR is structurally a genetic algorithm where "mutation" is performed by an LLM. Understanding concepts like population size, selection pressure, and fitness functions is required to tune hyperparameters.
  - **Quick check question:** If I set the "tree arity" to 1, what kind of search algorithm does this degenerate into? (Answer: Depth-first / Random walk).

- **Concept: Unit Testing & I/O Specification**
  - **Why needed here:** The "fitness" of a program is determined solely by hidden unit tests. The framework requires a validation set to rank candidates and a test set for final evaluation.
  - **Quick check question:** How does the framework handle a program that compiles but produces the wrong output? (Answer: It uses the I/O pair to generate a debug instruction).

## Architecture Onboarding

- **Component map:** Problem description + I/O examples -> Prompt Template -> SYNTHESIZE -> EXECUTE -> INSTRUCT -> DEBUG -> RANK -> New population
- **Critical path:** The INSTRUCT agent. If the bug summary is generic, the Debug LLM cannot fix it. The translation of specific failure signals to precise instructions drives repair success.
- **Design tradeoffs:**
  - Tree Arity (N) vs. Budget: Higher N explores more repairs per candidate but consumes token budget faster
  - Static vs. LLM Instruction: INSTRUCT_static is cheaper/faster; INSTRUCT_LLM is smarter but slower/more expensive
  - Tournament vs. Lexicase: Tournament optimizes for average performance; Lexicase optimizes for coverage of edge cases
- **Failure signatures:**
  - Infinite Repair Loops: Code oscillates between two buggy states
  - Early Convergence: All candidates become identical (low temperature or low arity)
  - Syntax Cascades: Minor fix introduces syntax error that LLM fails to correct
- **First 3 experiments:**
  1. Baseline (Single-Shot): Run only SYNTHESIZE agent to establish "near-miss" frequency
  2. Ablation (Arity): Compare SEIDR with Tree Arity = 1 vs Tree Arity = 10 on failed baseline problems
  3. Instruction Stress Test: Compare INSTRUCT_static vs INSTRUCT_LLM to determine if complex bugs require natural language summarization

## Open Questions the Paper Calls Out

- **Open Question 1:** How can instructions be optimally engineered to maximize program repair performance in instruction-tuned LLMs?
  - **Basis:** The introduction explicitly states that due to the "free-form nature" of instructions, "how one should engineer instructions that maximize repair performance is an open question."
  - **Why unresolved:** While the study tests static templates and LLM-generated explanations, it does not conduct a comprehensive exploration of diverse prompt engineering strategies for the repair agent.
  - **What evidence would resolve it:** A systematic evaluation comparing various prompt engineering techniques specifically tailored for the SEIDR debugging loop.

- **Open Question 2:** How does the SEIDR framework scale to large-context projects or production-level software compared to competitive programming tasks?
  - **Basis:** The authors note in the Future Work section that further research is needed on "benchmarks with more tests... as well as the framework's comparison on large-context projects."
  - **Why unresolved:** The current study is limited to PSB2 and HumanEval-X, which focus on function-level synthesis rather than file-level or repository-level complexity.
  - **What evidence would resolve it:** Applying SEIDR to benchmarks requiring cross-file dependencies or complex project structures to measure scalability.

- **Open Question 3:** Is there a universally optimal tree arity (repair-replace trade-off) for SEIDR, or is it dependent on the specific LLM architecture?
  - **Basis:** The results show that while Codex performed best with tree arity 10, newer models like GPT-3.5 and Llama 3 showed "no distinct trend" or "leading tree arity."
  - **Why unresolved:** The inconsistency in optimal hyperparameters across different models suggests the "repair-replace trade-off" is not solved for all LLMs, potentially requiring model-specific tuning.
  - **What evidence would resolve it:** A hyperparameter sensitivity analysis across a wider range of open and closed-source models to identify if optimal arity correlates with model capacity or training data.

## Limitations

- The precise selection criteria for validation test cases from PSB2's 1M training set remain unspecified
- The implementation details of "spring sampling" batching for API efficiency are not fully documented
- The truncation strategy when prompts exceed token limits during debugging is unspecified
- The framework's performance on large-context projects or production-level software remains untested

## Confidence

- **High Confidence:** The core multi-agent framework architecture and its iterative nature are well-specified and reproducible
- **Medium Confidence:** The reported performance improvements over baselines are supported by experimental results, though hyperparameter sensitivity shows variability
- **Low Confidence:** The generalizability of lexicase selection benefits beyond the C++ domain with GPT-3.5 remains uncertain given mixed results across problem types

## Next Checks

1. **Ablation Study:** Run SEIDR with tree arity=1 (repair-only) vs. arity=10 (hybrid) on a subset of failed baseline problems to verify search mechanism adds value
2. **Instruction Comparison:** Compare INSTRUCT_static ("Make sure I → O") vs. INSTRUCT_LLM (generated explanation) to determine if complex bugs require natural language summarization
3. **Validation Set Sensitivity:** Test SEIDR with different validation set selection strategies (first N vs. random N) to assess impact on repair success rates