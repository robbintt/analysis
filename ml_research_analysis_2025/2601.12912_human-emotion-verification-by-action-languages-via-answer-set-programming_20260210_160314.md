---
ver: rpa2
title: Human Emotion Verification by Action Languages via Answer Set Programming
arxiv_id: '2601.12912'
source_url: https://arxiv.org/abs/2601.12912
tags:
- mental
- emotion
- holds
- action
- states
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces C-MT, an action language for modeling human
  mental state dynamics, especially emotions, using Answer Set Programming (ASP).
  C-MT formalizes mental states as multi-dimensional configurations and incorporates
  novel constructs like "forbids to cause" to encode constraints on state transitions
  derived from psychological theories such as Appraisal Theory of Emotion, Hedonic
  and Utilitarian Emotion Regulation.
---

# Human Emotion Verification by Action Languages via Answer Set Programming

## Quick Facts
- arXiv ID: 2601.12912
- Source URL: https://arxiv.org/abs/2601.12912
- Reference count: 40
- Primary result: Introduces C-MT, an action language for modeling human mental state dynamics, especially emotions, using Answer Set Programming (ASP).

## Executive Summary
This paper presents C-MT, an action language that extends Answer Set Programming (ASP) to model and verify human mental state dynamics, particularly emotions, in human-agent interactions. The framework formalizes mental states as multi-dimensional configurations based on appraisal theory, allowing agents to reason about the emotional consequences of their actions. By incorporating novel constraints that filter action trajectories, C-MT enables verification of controlled agent behavior and comparison of psychological theories through trajectory analysis. Experiments demonstrate the framework's ability to distinguish between different emotion regulation strategies and validate their impact on mental state evolution.

## Method Summary
The C-MT framework represents mental states as multi-dimensional configurations of appraisal variables (need consistency, goal consistency, accountability, control potential) rather than discrete emotional labels. Actions influence these variables individually, and the system uses Answer Set Programming to generate and verify action trajectories. Novel "forbids to cause" constraints are implemented as ASP integrity constraints to filter trajectories that would induce unwanted mental state transitions based on psychological theories like Hedonic and Utilitarian Emotion Regulation. The approach allows comparison of different psychological theories by analyzing the reachable state space under their respective constraints.

## Key Results
- HER-based constraints allow broader emotional reachability than UER-based constraints across 512 test cases
- Distinct patterns of mental state evolution were identified between Hedonic and Utilitarian Emotion Regulation strategies
- The framework successfully filtered invalid trajectories while maintaining computational tractability (solving times 0.009-0.046 sec)
- ASP's non-monotonic reasoning effectively handled the indeterminacy of mental state evolution

## Why This Works (Mechanism)

### Mechanism 1
The framework enables verification of human-agent interaction by abstracting mental states into multi-dimensional vectors (fluents) derived from psychological theory, rather than discrete labels. Mental states are represented as configurations of appraisal variables (need consistency, goal consistency, accountability, control potential). Actions influence these variables individually, and transitions resulting in negative or unsafe emotions are flagged. Core assumption: Roseman's Appraisal Theory sufficiently captures the causal determinants of emotional states. Evidence: Abstract states "formalize mental states, such as emotions, as multi-dimensional configurations." Break condition: If emotional responses depend on variables not included in the fluent set, the model may misclassify mental states.

### Mechanism 2
The novel "forbids to cause" construct acts as a trajectory filter, pruning action sequences that induce unwanted mental state transitions. This rule is implemented as an ASP integrity constraint: if fluents $g$ hold at time $t$, the solver strictly prevents fluents $f$ from holding at time $t+1$. This allows distinct belief graphs (e.g., Hedonic vs. Utilitarian) to be layered over the same domain description, changing the reachable state space without rewriting action preconditions. Core assumption: Principles of change correctly identify which transitions are "forbidden" for specific users or contexts. Evidence: Abstract mentions "forbids to cause... enables the modeling of principles for valid transitions." Break condition: Over-specified constraints can make the action theory inconsistent (UNSATISFIABLE).

### Mechanism 3
Answer Set Programming provides the necessary non-monotonic reasoning to handle the indeterminacy of mental state evolution and generate verifiable trajectories. The system maps action theories to logic programs, generating multiple "answer sets" representing distinct possible trajectories. This allows skeptical or credulous reasoning about potential futures. Core assumption: State space complexity remains computationally tractable for the ASP solver. Evidence: Section 4 states C-MT is "built on top of answer set programming (ASP)" and section 7 reports solving times of 0.009-0.046 sec. Break condition: Exponential growth in fluents or plan length could prevent real-time solutions.

## Foundational Learning

**Answer Set Programming (ASP)**: This is the computational engine. Understanding "answer sets" (stable models) is required to interpret the output (trajectories) and debug constraints. Quick check: Can you explain the difference between a traditional procedural program and a declarative logic program where the solution is a "set of beliefs"?

**Appraisal Theory of Emotion (Roseman)**: This provides the ontology (fluents) for the system. You must understand why the system tracks "goal consistency" rather than just "happiness." Quick check: How does the relationship between "need consistency" and "goal consistency" distinguish a positive emotion from a negative one in this framework?

**Action Languages (C+ / C-TAID)**: C-MT is an extension of these languages. Understanding concepts like "inertial fluents" (values that persist unless changed) and "static causal laws" is vital for reading the domain descriptions. Quick check: What does it mean for a fluent to be "inertial" in the context of a state transition system?

## Architecture Onboarding

**Component map**: Domain Description (D_MT) -> Belief Graph (BG) -> Solver (Clingo) -> Output (Answer sets/trajectories)

**Critical path**: Mapping a psychological theory (e.g., "Hedonic Regulation aims to maximize positive emotion") into a specific set of `forbids to cause` rules (e.g., `ne:high forbids to cause go:low`). If this translation is incorrect, the verification is invalid.

**Design tradeoffs**:
- HER vs. UER Constraints: HER constraints allow broader reachability but focus on immediate comfort. UER constraints are stricter but prioritize long-term utility.
- Plan Length: Shorter plans (e.g., n=6) are solvable in milliseconds but may miss long-term side effects.

**Failure signatures**:
- UNSATISFIABLE: Constraints are too restrictive; no valid path exists from s_0 to s_goal.
- Invariant Violation: A generated trajectory contains a state transition that violates the safety property, indicating a bug in the causal laws or constraints.

**First 3 experiments**:
1. **Sanity Check (Invariance)**: Encode the "Anger" state and verify that no HER-compliant trajectory can reach it from a "Joy" start state (reproducing the "UNSATISFIABLE" result from Table 3).
2. **Reachability Analysis**: Run a sweep of all 16Ã—16 emotion pairs with UER constraints to reproduce the reachability graph (Figure 6), confirming the solver correctly filters the state space.
3. **Dialogue Verification**: Implement the example from Section 8. Feed a specific sequence of "chatbot" actions and verify if the resulting mental state trajectory violates the `EI_UER` as predicted.

## Open Questions the Paper Calls Out

**Open Question 1**: How can probabilistic or possibilistic reasoning be integrated into C-MT to handle uncertainty in mental state transitions? The current framework uses classical ASP which handles non-determinism but lacks mechanisms to quantify the likelihood of specific mental state changes. This could be resolved with probabilistic ASP (P-ASP) extensions empirically evaluated for improved robustness.

**Open Question 2**: How can weights be assigned to fluents, actions, and transition rules to model varying degrees of influence on mental states? The existing implementation treats causal influences as binary, not distinguishing between strong versus minor perturbations. This could be resolved with cardinality or weighted rules to prioritize trajectories based on cumulative emotional impact strength.

**Open Question 3**: How can mental-state fluents be elicited from real-world observations to bridge the gap between psychological theory and interactive prototypes? Current case studies rely on synthetic data rather than dynamically extracting appraisal dimensions from unstructured human interaction. This could be resolved with an interactive prototype that extracts appraisal variables from user dialogue or behavior in real-time.

## Limitations
- The framework's effectiveness depends heavily on the accuracy of Roseman's Appraisal Theory, which may not fully capture all causal determinants of human emotional responses.
- The system assumes emotional responses can be adequately represented by four appraisal variables, potentially missing other relevant factors like physiological arousal or context-specific variables.
- Scalability to more complex domains with larger numbers of fluents or longer plan horizons remains untested and may face computational challenges.

## Confidence
- **High Confidence**: The computational mechanism using ASP to generate and verify action trajectories is well-established and correctly implemented, evidenced by consistent solving times (0.009-0.046 sec) and successful reproduction of key results.
- **Medium Confidence**: The translation of psychological theories (HER and UER) into formal `forbids to cause` constraints is logical but requires validation against human judgment in real-world scenarios.
- **Low Confidence**: The assumption that a fixed set of four appraisal variables is sufficient to model the full spectrum of human emotions and their transitions is a significant simplification that may limit applicability.

## Next Checks
1. **Psychological Theory Validation**: Conduct a user study comparing the framework's predicted emotional trajectories against human subjects' reported emotional responses in controlled scenarios to validate the accuracy of the chosen appraisal variables and their causal relationships.

2. **Constraint Sensitivity Analysis**: Systematically vary the strictness of the `forbids to cause` constraints and measure the impact on plan existence (UNSAT vs. SAT rates) and the diversity of generated trajectories to determine the optimal balance between safety and reachability.

3. **Scalability Benchmark**: Test the framework with a significantly larger number of fluents (e.g., 20+ appraisal variables) and longer plan horizons (e.g., t_max=20) to assess computational feasibility and identify potential bottlenecks in the ASP solving process.