---
ver: rpa2
title: 'XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain
  Generalization and Rare Class Detection in Medical Imaging'
arxiv_id: '2601.02008'
source_url: https://arxiv.org/abs/2601.02008
tags:
- medical
- knowledge
- learning
- deep
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: XAI-MeD introduces a neuro-symbolic framework that integrates expert
  medical knowledge with deep learning for domain generalization and rare-class detection.
  By encoding clinical rules as logical connectives over atomic propositions and fusing
  them with neural representations through an adaptive routing mechanism guided by
  Entropy Imbalance Gain (EIG) and Rare-Class Gini, the framework improves both robustness
  and interpretability.
---

# XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging

## Quick Facts
- arXiv ID: 2601.02008
- Source URL: https://arxiv.org/abs/2601.02008
- Reference count: 3
- Improves cross-domain accuracy by 6% and rare-class F1 by 10% over deep learning baselines

## Executive Summary
XAI-MeD is a neuro-symbolic framework that integrates expert medical knowledge with deep learning for domain generalization and rare-class detection in medical imaging. The system encodes clinical rules as logical connectives over atomic propositions and fuses them with neural representations through an adaptive routing mechanism guided by Entropy Imbalance Gain (EIG) and Rare-Class Gini. Experiments on ten multi-center datasets across two clinically significant tasks—Seizure Onset Zone localization and Diabetic Retinopathy grading—demonstrate superior performance compared to state-of-the-art deep learning baselines, with the framework also generating human-understandable explanations validated by medical experts.

## Method Summary
XAI-MeD combines deep learning feature extraction with expert knowledge encoded as logical rules, creating a hybrid inference pipeline. The framework uses an adaptive routing mechanism (EKSAII) that recursively partitions data by selecting the optimal classifier based on Entropy Imbalance Gain, which prioritizes rare-class separability. Clinical rules are encoded as logical connectives over atomic propositions extracted by auxiliary models (YOLO for lesion detection, U-Net for anatomical segmentation), then combined with neural features through weighted satisfaction scores. The system employs ten specialized binary classifiers organized in a decision tree structure, with a large language model generating natural language explanations from the final diagnostic output.

## Key Results
- 6% improvement in cross-domain accuracy compared to standalone deep learning models
- 10% improvement in rare-class F1 score, with Diabetic Retinopathy Grade 3 improving from 45.2% to 56.01%
- Demonstrated effectiveness across ten multi-center datasets for both SOZ localization and DR grading tasks

## Why This Works (Mechanism)

### Mechanism 1
Symbolic knowledge components act as regularizers that improve robustness to distribution shifts by constraining the hypothesis space. Clinical rules encoded as logical connectives force the model to learn features aligned with pathophysiological reasoning rather than dataset-specific correlations. The weighted satisfaction scores (S_ClassX = Σw_i·s_i) provide an interpretable signal that remains stable across imaging protocols. This works under the assumption that expert-derived rules capture domain-invariant diagnostic patterns, though the benefit degrades if auxiliary detectors fail on new imaging protocols.

### Mechanism 2
Entropy Imbalance Gain (EIG) enables adaptive classifier selection that prioritizes rare-class separability. EIG(M_d) = η_R - η_Md quantifies how much a classifier reduces maximum class entropy imbalance, with higher EIG indicating better rare-class representation. The algorithm recursively partitions data by selecting the classifier with maximum EIG, cascading when Gini impurity exceeds threshold τ_g. This mechanism assumes classifiers with higher EIG on training data will maintain rare-class advantages on unseen domains, though it may fail if rare-class instances have fundamentally different feature distributions in the target domain.

### Mechanism 3
Hierarchical decision tree with class-specialized binary classifiers improves rare-class detection over monolithic multi-class models. Ten binary classifiers (5 ViT-based M_d, 5 knowledge-based M_k) are organized into a decision tree via EKSAII, creating specialized paths for different DR grades rather than competing in shared representation space. This approach assumes binary classifiers trained on one-vs-rest formulations can achieve better separation than multi-class classifiers when classes are imbalanced, though error propagation through early decision nodes can prevent recovery.

## Foundational Learning

- **Neuro-symbolic integration**: Understanding how neural feature extraction and symbolic reasoning can be combined, rather than treated as post-hoc explanation. Quick check: Can you explain the difference between using symbolic rules for post-hoc interpretability vs. using them as part of the inference pipeline?

- **Entropy-based class imbalance metrics**: EIG is derived from local density estimation and class entropy; understanding these foundations is necessary to debug classifier selection. Quick check: Given a classifier that achieves 90% accuracy but misclassifies all rare-class samples, would it have high or low EIG?

- **Decision tree routing (Hunt's algorithm)**: The EKSAII algorithm extends Hunt's algorithm for adaptive expert selection. Quick check: How does Hunt's algorithm handle ties when selecting splitting criteria, and how does EKSAII modify this for classifier selection?

## Architecture Onboarding

- **Component map**: Raw images → DL Branch (ViT/CNN) + Knowledge Branch (YOLO/U-Net + XGBoost) → EKSAII Router (EIG computation) → Fusion Layer (weighted combination) → LLM Explainer (natural language output)

- **Critical path**: 1) Define atomic propositions for domain (Table 1 format) 2) Implement K_X(·) extraction functions (requires auxiliary models) 3) Train binary classifiers for each class 4) Run EKSAII to construct decision tree on validation set 5) Deploy fixed tree for inference (no re-routing at test time)

- **Design tradeoffs**: Interpretability vs. coverage (fixed rule sets cannot capture edge cases; LLM-based rule induction suggested), auxiliary model dependency (YOLO/U-Net quality directly affects symbolic branch; weak supervision alternatives noted), computational cost (10 binary classifiers + routing overhead vs. single multi-class model)

- **Failure signatures**: Low EIG for all classifiers (class imbalance too severe or feature extraction failing), high Gini at leaf nodes (need deeper tree or additional classifiers), large accuracy gap between SDG and MDG (symbolic features not truly domain-invariant), LLM explanations inconsistent with routing decisions (check knowledge feature extraction pipeline)

- **First 3 experiments**: 1) Ablation by branch: Train M_d only, M_k only, and fused model on single domain; test on held-out domain to isolate symbolic regularization effect 2) EIG sensitivity analysis: Manually vary τ_g threshold and measure impact on rare-class recall vs. overall accuracy 3) Cross-domain auxiliary model test: Evaluate YOLO lesion detector on all target domains before full pipeline

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework's reliance on auxiliary supervised models (e.g., YOLO, U-Net) be replaced by weakly or self-supervised learning methods to eliminate the need for expensive manual annotations? The current system architecture requires explicit, structured feature extraction to feed the symbolic branch, which currently necessitates distinct supervised models.

### Open Question 2
Can large language models effectively automate the induction of clinical rules from unstructured medical corpora to dynamically expand the symbolic knowledge base? The current symbolic branch relies on fixed, expert-defined rule sets which cannot adapt to edge cases or novel clinical scenarios not present during initial knowledge engineering.

### Open Question 3
How does the recursive partitioning strategy of the EKSAII algorithm handle multi-label clinical scenarios where a single instance exhibits multiple concurrent pathologies? The described algorithm routes an instance down a specific branch based on maximum Entropy Imbalance Gain, which may force a hard decision that misses co-occurring conditions.

## Limitations
- Relies on auxiliary supervised models (YOLO, U-Net) requiring expensive manual annotations
- Fixed rule sets cannot capture all clinically relevant edge cases or novel scenarios
- Performance depends on auxiliary model generalization across imaging protocols
- No online adaptation mechanism for distribution shifts beyond training domains

## Confidence

- High: Symbolic components act as regularizers for domain generalization (ablation study evidence)
- High: EIG-based routing improves rare-class detection (quantitative improvement in DR Grade 3)
- Medium: Fixed rule sets cover clinically relevant edge cases (assumes complete knowledge capture)
- Medium: Auxiliary models generalize across domains (assumes detector robustness)
- Low: LLM explanations consistently match clinical reasoning (no human validation reported)

## Next Checks

1. Evaluate YOLO/U-Net auxiliary models on all target domains to quantify cross-domain performance degradation before full pipeline deployment
2. Perform stress testing by introducing concept drift (not just covariate shift) in rare-class instances to assess EIG-based routing limits
3. Conduct blinded clinical expert review of LLM-generated explanations against ground truth routing decisions to validate interpretability claims