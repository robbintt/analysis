---
ver: rpa2
title: 'MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models'
arxiv_id: '2509.24779'
source_url: https://arxiv.org/abs/2509.24779
tags:
- page
- mars-fm
- cited
- training
- dynamics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MSM-Emulators, a new class of generative models
  that learn to sample transitions across discrete states defined by a Markov State
  Model (MSM) rather than fixed-lag time transitions. This approach addresses data
  imbalance in MD data by focusing on state-to-state transitions rather than frame-to-frame
  transitions, enabling better learning of rare conformational changes.
---

# MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models

## Quick Facts
- arXiv ID: 2509.24779
- Source URL: https://arxiv.org/abs/2509.24779
- Reference count: 40
- Key outcome: Generative model that learns state-to-state transitions via Markov State Models, enabling 600x faster molecular dynamics sampling while outperforming existing MD emulators on structural observables

## Executive Summary
MarS-FM introduces a novel generative modeling approach for molecular dynamics (MD) simulations that leverages Markov State Models (MSMs) to address data imbalance issues in MD datasets. By learning transitions between discrete conformational states rather than fixed-lag time transitions, the method enables more effective sampling of rare conformational changes. The framework, instantiated as MARS-FM, uses Flow Matching optimization to generate protein conformations significantly faster than traditional MD simulations while maintaining or improving accuracy on key structural metrics.

## Method Summary
The approach defines a new class of generative models called MSM-Emulators that learn to sample transitions across discrete states defined by a Markov State Model rather than fixed-lag time transitions. This addresses the fundamental data imbalance problem in MD data where common transitions are overrepresented compared to rare conformational changes. The authors instantiate this framework with MARS-FM, which is optimized using Flow Matching—a technique that trains the model to predict intermediate states in a gradual transformation process rather than directly mapping from noise to target conformations. The method discretizes the conformational space using MSMs, then learns conditional generative models for transitions between these states, enabling more efficient exploration of the conformational landscape.

## Key Results
- Generates conformations over 600x faster than traditional MD simulations
- Outperforms existing MD-Emulators on structural observables including RMSD, radius of gyration, and secondary structure content
- Demonstrates superior generalization for capturing large conformational changes like protein unfolding events
- Maintains strong performance across different sample budgets and diverse protein domains

## Why This Works (Mechanism)
The method works by reframing the generative modeling problem from frame-to-frame transitions to state-to-state transitions. Traditional MD emulators suffer from severe data imbalance because most transitions in MD trajectories are between similar conformations, while rare but important transitions (like folding/unfolding) are underrepresented. By using MSMs to discretize the conformational space into metastable states, the model can learn more balanced transition probabilities between distinct conformational basins. This allows the generative model to focus on the structurally meaningful transitions that define the protein's functional dynamics, rather than being overwhelmed by the trivial local fluctuations that dominate raw MD data.

## Foundational Learning
- **Markov State Models (MSMs)**: Why needed - To discretize continuous conformational space into discrete states for balanced learning; Quick check - Verify state decomposition captures metastable conformations through implied timescales analysis
- **Flow Matching**: Why needed - To optimize generative models by predicting intermediate states rather than direct mapping; Quick check - Monitor training loss convergence and intermediate state quality
- **Conformational sampling**: Why needed - To explore protein folding landscape and rare events; Quick check - Compare generated ensemble coverage against reference MD using RMSD distributions
- **Data imbalance in MD**: Why needed - To understand why traditional frame-based approaches fail for rare events; Quick check - Analyze transition frequency distributions in training data
- **Generative modeling**: Why needed - To create new conformations without expensive MD simulations; Quick check - Validate generated structures using physics-based energy calculations
- **Protein structural observables**: Why needed - To quantitatively assess generation quality; Quick check - Compare RMSD, radius of gyration, and secondary structure content against ground truth

## Architecture Onboarding

**Component map:** Protein conformations -> MSM discretization -> State transition pairs -> Flow Matching model -> Generated conformations

**Critical path:** Raw MD trajectory → MSM construction → State assignment → Transition pair extraction → Flow Matching training → Generation inference

**Design tradeoffs:** Uses discrete state discretization (MSM) for balanced learning vs continuous space approaches that struggle with data imbalance; Flow Matching provides stable training vs direct generation approaches; focuses on structural accuracy vs dynamical properties

**Failure signatures:** Generated conformations show unrealistic geometries (high energy, violated constraints); poor coverage of rare conformational states; failure to capture large-scale structural changes; mode collapse producing only similar conformations

**3 first experiments:**
1. Verify MSM discretization captures metastable states by computing implied timescales and comparing to reference MD
2. Test generation quality on simple helical peptide before scaling to complex proteins
3. Compare transition probability distributions between generated and reference data for key state pairs

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on pre-computed MSMs for state discretization, limiting applicability to systems where building reliable MSMs is challenging
- Evaluation focuses primarily on equilibrium structural properties rather than kinetic observables critical for drug discovery applications
- Validation of rare event sampling remains somewhat limited in scope despite claims of superior generalization

## Confidence

**High Confidence:**
- Generation speed claims (600x faster than MD) are well-supported by experimental data
- Basic structural accuracy metrics show statistically significant improvements over baselines

**Medium Confidence:**
- Claims about superior generalization for rare events like unfolding are supported but could benefit from additional statistical validation
- Advantage of state-based transition learning over frame-based approaches is demonstrated but could be strengthened with ablation studies

## Next Checks
1. Validate kinetic properties by computing transition rates and autocorrelation functions for key observables, comparing against reference MD trajectories to ensure dynamical consistency
2. Test the framework's performance on systems with multiple metastable states where the MSM discretization becomes non-trivial, particularly focusing on state definition sensitivity
3. Evaluate the approach on protein-ligand binding/unbinding processes where rare event sampling is critical, measuring convergence of binding kinetics against enhanced sampling methods