---
ver: rpa2
title: Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models
arxiv_id: '2504.11431'
source_url: https://arxiv.org/abs/2504.11431
tags:
- topic
- discourse
- words
- gender
- women
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work examines masculine defaults in spoken content and large\
  \ language models (LLMs) by analyzing gendered discourse patterns in 15,117 podcast\
  \ episodes. Using a two-part framework, it first discovers gendered discourse words\
  \ through topic modeling (LDA and BERTopic) and gender segmentation, then measures\
  \ their representation in LLM embeddings (OpenAI\u2019s text-embedding-3-large)\
  \ via a novel Discourse Word-Embedding Association Test (D-WEAT)."
---

# Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models

## Quick Facts
- **arXiv ID:** 2504.11431
- **Source URL:** https://arxiv.org/abs/2504.11431
- **Reference count:** 27
- **Primary result:** Masculine discourse words are more stably represented in LLM embeddings than feminine discourse words, creating representational harm.

## Executive Summary
This work identifies masculine defaults in spoken content by analyzing 15,117 podcast episodes to discover gendered discourse patterns. Using a two-part framework combining topic modeling and gender segmentation, the authors identify masculine and feminine discourse words (like "going" vs. "like") and measure their representation in LLM embeddings. The study finds that masculine discourse words are more prevalent in high-value domains like business and technology, and are represented more stably in LLM embeddings, potentially creating a "cost of entry" for women in these fields.

## Method Summary
The study employs a Gendered Discourse Correlation Framework (GDCF) that transcribes podcast audio, segments it by speaker gender using inaSpeechSegmenter, and applies Latent Dirichlet Allocation to discover discourse topics. These topics are correlated with gender to form masculine and feminine discourse word lists. A novel Discourse Word-Embedding Association Test (D-WEAT) then measures embedding stability by calculating the cosine similarity shift when discourse words are swapped in sentence pairs, comparing movement toward gendered attribute vectors.

## Key Results
- Masculine discourse words are prevalent in business, technology/politics, and video games domains
- Masculine discourse words show more stable representation in LLM embeddings than feminine words
- The embedding disparity constitutes a masculine default that may reward masculine speech patterns in downstream tasks

## Why This Works (Mechanism)

### Mechanism 1: Discourse-Gender Correlation via Segmentation
The GDCF framework transcribes audio, segments by speaker gender using inaSpeechSegmenter, and applies LDA to isolate discourse markers that correlate with binary gender categories. The paper assumes the first 30 seconds accurately represent episode gender makeup and that binary gender classification via voice pitch is sufficient.

### Mechanism 2: Embedding Stability and Representational Robustness
D-WEAT measures cosine similarity shift when swapping discourse words in sentence pairs. The finding suggests masculine words anchor embeddings more firmly, causing less drift than feminine words. The paper equates this stability with better downstream performance, rewarding masculine speech patterns.

### Mechanism 3: Domain-Specific Masculine Defaults
Masculine discourse patterns correlate positively with high-value domains like business and technology. The mechanism suggests linguistic "cost of entry" for these domains includes adopting masculine speech patterns, creating a feedback loop where the standard communication style is masculine.

## Foundational Learning

- **Concept: Word Embedding Association Test (WEAT)**
  - Why needed here: D-WEAT extends WEAT. Understanding the original metric is required to interpret how swapping target words and measuring distance to attribute words quantifies bias.
  - Quick check question: How does cosine similarity between a target sentence embedding and gendered attribute vectors change when a discourse word is swapped?

- **Concept: Latent Dirichlet Allocation (LDA) vs. Contextual Embeddings**
  - Why needed here: LDA focuses on high-frequency discourse words that contextual methods like TF-IDF or BERTopic would dampen or ignore.
  - Quick check question: Why might a topic model focusing on low-frequency content words fail to capture high-frequency discourse markers?

- **Concept: Binary Gender Approximation in Audio**
  - Why needed here: GDCF relies on inaSpeechSegmenter, which approximates gender based on audio signals, forcing binary classification that limits study scope.
  - Quick check question: What are failure modes of classifying gender solely based on audio pitch/features in diverse speaker populations?

## Architecture Onboarding

- **Component map:** WhisperX (transcriber) -> inaSpeechSegmenter (gender segmenter) -> LDA/BERTopic (topic modeler) -> D-WEAT (embedding evaluator)
- **Critical path:** Gender Segmenter accuracy is the upstream dependency. If segmentation is noisy, derived word lists are invalid, rendering D-WEAT results meaningless.
- **Design tradeoffs:**
  - LDA vs. BERTopic: LDA provided more consistent isolation of discourse words while BERTopic results varied heavily based on UMAP settings
  - Binary vs. Spectrum: System enforces binary gender framework to align with existing WEAT methodologies and tool limitations
- **Failure signatures:**
  - Conflation of Content and Discourse: If LDA mixes content words into discourse topics, domain correlation results become circular
  - Static Word Lists: Derived word lists are specific to 2019-2020 podcast corpus and may not generalize
- **First 3 experiments:**
  1. Validate segmentation stability by manually verifying 30-second window accuracy
  2. Ablate topic modeling by comparing LDA topics against manually curated discourse markers
  3. Replicate D-WEAT movement by swapping "like" and "going" in novel sentences

## Open Questions the Paper Calls Out

### Open Question 1
How does implementing context-aware discourse word replacement affect D-WEAT measurements compared to random replacement? The current random replacement creates synthetic sentences that may lack semantic naturalness, potentially confounding bias measurement with semantic incoherence.

### Open Question 2
Does the identified instability of feminine discourse embeddings directly degrade performance on downstream tasks? While the paper demonstrates masculine words have more stable embeddings, it doesn't empirically verify if this "reward" translates to superior accuracy in real-world applications.

### Open Question 3
How can the GDCF framework be extended to analyze gendered discourse in non-binary and intersectional contexts? The current framework relies on inaSpeechSegmenter, which approximates gender via binary sex classification, lacking capability to model spectrums.

## Limitations

- **Binary Gender Assumption:** Framework relies on binary gender segmentation using audio pitch, excluding non-binary speakers and potentially misclassifying atypical pitch
- **Corpus Representation:** 15,117 podcast episodes (2019-2020) may not represent current discourse patterns or other media types
- **Discourse Word Generalization:** Word lists are derived from this specific corpus and may not transfer to other languages, formal writing, or cultural contexts

## Confidence

- **High Confidence:** Methodology for discovering gendered discourse words through topic modeling and gender segmentation is sound and reproducible
- **Medium Confidence:** Finding that masculine discourse words show more stable embeddings than feminine words is supported, though practical significance requires validation
- **Low Confidence:** Claim that masculine discourse constitutes a "reward" or "cost of entry" for high-value domains relies on sociological assumptions not directly validated

## Next Checks

1. **Segmentation Accuracy Validation:** Manually verify gender segmentation accuracy on 50 randomly selected episodes by comparing inaSpeechSegmenter output with actual speaker identities
2. **Domain Correlation Robustness:** Replicate domain correlation analysis using balanced dataset (equal male/female hosts) in business/tech domains
3. **Embedding Stability Replication:** Test D-WEAT stability findings across three different embedding models (OpenAI, Cohere, Sentence-BERT) to determine if masculine word stability is model-specific