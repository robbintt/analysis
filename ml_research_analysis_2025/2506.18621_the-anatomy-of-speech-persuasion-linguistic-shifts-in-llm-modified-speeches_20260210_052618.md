---
ver: rpa2
title: 'The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches'
arxiv_id: '2506.18621'
source_url: https://arxiv.org/abs/2506.18621
tags:
- persuasiveness
- features
- public
- count
- discourse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how large language models understand and
  manipulate persuasiveness in public speaking. The researchers prompted GPT-4o to
  enhance or diminish persuasiveness in French speech transcripts from the 3MT competition,
  then analyzed linguistic shifts using a novel feature set incorporating rhetorical
  devices and discourse markers.
---

# The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches

## Quick Facts
- **arXiv ID**: 2506.18621
- **Source URL**: https://arxiv.org/abs/2506.18621
- **Reference count**: 14
- **Primary result**: GPT-4o applies systematic stylistic modifications rather than human-like optimization when enhancing speech persuasiveness

## Executive Summary
This study investigates how large language models understand and manipulate persuasiveness in public speaking. The researchers prompted GPT-4o to enhance or diminish persuasiveness in French speech transcripts from the 3MT competition, then analyzed linguistic shifts using a novel feature set incorporating rhetorical devices and discourse markers. Results showed GPT-4o employs a "peripheral-route" persuasion strategy focused on emotional and stylistic cues rather than substantive argumentation, systematically increasing lexical diversity while reducing syntactic and discourse complexity.

The findings reveal that GPT-4o's approach to persuasion differs fundamentally from human rhetorical strategies, favoring surface-level modifications like emotional language and interrogative/imperative structures over deeper argumentative enhancements. This peripheral-route strategy suggests LLMs may optimize for identifiable persuasive markers rather than genuinely improving argumentative quality, raising important questions about the nature of AI-mediated persuasion and its implications for public communication.

## Method Summary
The researchers used GPT-4o to process French speech transcripts from the 3MT competition, generating modified versions with either enhanced or diminished persuasiveness based on specific prompts. They developed a novel linguistic feature set combining rhetorical devices and discourse markers to analyze systematic differences between original, upgraded, and downgraded transcripts. The analysis examined patterns across multiple linguistic dimensions including emotional content, syntactic complexity, lexical diversity, and structural elements like interrogative and imperative constructions.

## Key Results
- GPT-4o increases lexical diversity while reducing syntactic and discourse complexity when enhancing persuasiveness
- Upgraded transcripts feature more emotional language and interrogative/imperative structures
- Downgraded versions are more neutral with declarative and conditional constructions
- LLM employs systematic stylistic modifications rather than human-like optimization of argumentation

## Why This Works (Mechanism)
GPT-4o's peripheral-route persuasion strategy works by identifying and amplifying surface-level linguistic markers associated with persuasive speech rather than engaging with the substantive content or logical structure of arguments. This approach leverages the model's pattern recognition capabilities to apply consistent stylistic modifications that statistically correlate with perceived persuasiveness, such as emotional language and direct address structures. The strategy is computationally efficient and leverages the model's training on persuasive text patterns, though it may not produce genuinely improved argumentation.

## Foundational Learning
**Rhetorical Devices**: Linguistic techniques used to enhance persuasion through style, structure, or emotional appeal. Needed to understand how persuasion operates at the linguistic level; quick check: identify examples in famous speeches.

**Peripheral-route Persuasion**: A persuasion strategy that relies on surface-level cues rather than argument quality (as opposed to central-route persuasion). Needed to contextualize LLM's approach; quick check: compare emotional vs. logical appeals in marketing.

**Discourse Markers**: Words or phrases that structure discourse and signal relationships between ideas. Needed to analyze organizational patterns in persuasive speech; quick check: catalog common markers in academic writing.

**Lexical Diversity**: The range and variety of vocabulary used in a text. Needed to measure linguistic sophistication and engagement; quick check: calculate type-token ratio in sample texts.

**Syntactic Complexity**: The structural complexity of sentence constructions. Needed to assess cognitive load and rhetorical sophistication; quick check: analyze sentence length and clause structure in different genres.

**Persuasive Strategy Optimization**: The process of systematically modifying text to enhance persuasive effectiveness. Needed to understand how LLMs approach persuasion tasks; quick check: compare human vs. AI persuasion strategies.

## Architecture Onboarding

**Component Map**: Speech Transcripts -> GPT-4o Prompting System -> Modified Transcripts -> Linguistic Feature Extraction -> Statistical Analysis -> Persuasion Strategy Classification

**Critical Path**: The analysis pipeline from original speech transcripts through GPT-4o modification to final classification of persuasion strategy represents the core workflow, with the linguistic feature extraction serving as the critical analytical component.

**Design Tradeoffs**: The study prioritized systematic, automated analysis over nuanced human evaluation, trading depth of interpretation for breadth of pattern detection across multiple linguistic features.

**Failure Signatures**: The approach may miss context-dependent rhetorical effects, fail to capture delivery aspects of speech, and potentially misclassify persuasion strategies that rely on cultural or situational nuances not captured in the feature set.

**First Experiments**:
1. Test the same prompting strategy on a different LLM architecture to compare persuasion approaches
2. Apply the feature extraction pipeline to English speech transcripts to assess cross-linguistic validity
3. Conduct a small-scale human evaluation study to validate automated persuasiveness ratings

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis limited to French speech transcripts from 3MT competition, limiting generalizability
- GPT-4o behavior represents only one specific LLM implementation
- Automated feature extraction may miss nuanced rhetorical effects or context-dependent persuasive elements
- Study examined only textual modifications without considering delivery aspects like vocal tone or body language

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| GPT-4o employs peripheral-route persuasion strategy | Medium-High |
| GPT-4o applies systematic stylistic modifications rather than human-like optimization | Medium |
| Linguistic patterns observed are consistent and meaningful | Medium-High |

## Next Checks
1. Conduct human evaluation studies where participants rate the persuasiveness of original, upgraded, and downgraded transcripts to validate the automated feature-based analysis
2. Test whether similar linguistic patterns emerge when applying the same prompts to other LLM architectures (e.g., Claude, Llama) and across multiple languages
3. Expand the feature set to include pragmatic markers and context-dependent rhetorical devices that may capture more sophisticated persuasive strategies beyond surface-level linguistic modifications