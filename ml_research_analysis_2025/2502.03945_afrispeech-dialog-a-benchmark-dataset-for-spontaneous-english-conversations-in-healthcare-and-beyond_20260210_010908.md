---
ver: rpa2
title: 'Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations
  in Healthcare and Beyond'
arxiv_id: '2502.03945'
source_url: https://arxiv.org/abs/2502.03945
tags:
- medical
- speech
- arxiv
- summary
- conversations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Afrispeech-Dialog, a benchmark dataset of
  50 simulated African-accented English conversations in healthcare and general domains.
  The dataset is used to evaluate state-of-the-art speaker diarization, ASR, and LLM-based
  summarization models.
---

# Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond

## Quick Facts
- arXiv ID: 2502.03945
- Source URL: https://arxiv.org/abs/2502.03945
- Reference count: 40
- Primary result: Introduces benchmark dataset of 50 African-accented English conversations; shows 10%+ performance degradation for ASR/diarization vs. native accents.

## Executive Summary
This paper introduces Afrispeech-Dialog, a benchmark dataset of 50 simulated African-accented English conversations in healthcare and general domains. The dataset is used to evaluate state-of-the-art speaker diarization, ASR, and LLM-based summarization models. Speaker diarization models achieved DERs ranging from 16.27% to 26.87%, with performance degrading by 10%+ compared to native accents. ASR models showed WERs of 20.38%-86.34%, with open-source models performing better than wav2vec2. LLM summarization models achieved BERTScores of 85.48%-91.34% when using human transcripts, with a 2-5 point drop when using ASR transcripts. The results highlight challenges in accented speech recognition and the impact of ASR errors on downstream tasks.

## Method Summary
The Afrispeech-Dialog dataset contains 50 long-form audio files (~7 hours total) of simulated 2-person conversations, with 9 medical and 21 general domain files containing accurate timestamps for diarization evaluation. The pipeline evaluates speaker diarization (DER, collar=0.0), ASR (WER), and LLM summarization (BERTScore, LLM-as-Judge, human eval) on chunked 30-second audio segments. Models tested include Pyannote, Titanet-L for diarization; Whisper, wav2vec2 for ASR; and GPT-4o, Llama-3.1 for summarization. The dataset is simulated using patient cards and trained actors, with human transcripts providing ground truth.

## Key Results
- Speaker diarization DERs: 16.27% to 26.87%, degrading by 10%+ vs. native accents
- ASR WERs: 20.38% to 86.34%, with open-source models outperforming wav2vec2
- LLM summarization BERTScores: 85.48% to 91.34% (human transcripts) vs. 2-5 point drop (ASR transcripts)
- Medical domain consistently underperforms general domain across all tasks

## Why This Works (Mechanism)

### Mechanism 1: Accent Mismatch and Domain Complexity Drive ASR Degradation
- **Claim:** State-of-the-art ASR models show a 5-20 percentage point performance drop on African-accented English conversations, with an additional penalty for medical terminology.
- **Mechanism:** Models trained predominantly on high-resource, native-accented corpora fail to generalize to the phonological, prosodic, and lexical characteristics of African-accented English. This mismatch is amplified in the medical domain due to the density of specialized jargon and numerical entities.
- **Core assumption:** The performance gap is primarily caused by a distributional shift in acoustic features and vocabulary, rather than by recording quality.
- **Evidence anchors:**
  - [abstract]: "...discover a 10%+ performance degradation."
  - [section 5.2, Table 5]: Reports WERs of 20.38%-86.34%, noting a "5 to 20 point (absolute) performance drop" versus datasets like AMI and VoxPopuli, and a ~5% penalty for medical conversations.
  - [corpus]: Related work (AfriSpeech-MultiBench) supports the domain-generalization challenge in African-accented ASR.
- **Break condition:** If models are fine-tuned on a sufficiently large dataset of African-accented medical speech, the performance gap would narrow significantly.

### Mechanism 2: Conversation Structure Impacts Speaker Diarization Accuracy
- **Claim:** Speaker diarization models perform significantly better on general, spontaneous conversations than on structured medical consultations.
- **Mechanism:** The paper suggests that the relaxed, spontaneous nature of general conversations results in clearer speaker turns for models to segment. In contrast, the more formal, structured nature of medical interactions, despite fewer overall turns, presents specific challenges for speaker boundary detection.
- **Core assumption:** Informal conversational dynamics paradoxically provide clearer segmentation cues than formal, structured interactions in this dataset context.
- **Evidence anchors:**
  - [section 5.1]: "The models consistently performed better on general domain conversations compared to medical conversations, likely due to their relaxed structure and fewer interruptions."
  - [section 5.1, Table 4]: Titanet-L DER is 12.28% (General) vs. 34.64% (Medical).
  - [corpus]: Evidence from corpus neighbors on how conversation structure affects diarization is weak or missing.
- **Break condition:** If diarization models are trained on clinical dialogues with explicit turn-taking labels, the DER gap between medical and general conversations would decrease.

### Mechanism 3: Error Propagation in Cascading Pipelines Degrades Downstream Summaries
- **Claim:** Transcription errors propagate through the ASR-to-LLM pipeline, causing a measurable 2-5 point drop in downstream medical summarization quality.
- **Mechanism:** Imperfect ASR transcripts introduce noise that obscures critical clinical details. When these noisy transcripts are used for summarization, the LLM's ability to accurately retrieve and reason over key information is compromised, a nuance not fully captured by semantic similarity metrics like BERTScore.
- **Core assumption:** An LLM's summarization accuracy is bounded by the fidelity of its input; it cannot reliably reconstruct information that is missing or severely distorted.
- **Evidence anchors:**
  - [abstract]: "...with a 2-5 point drop when using ASR transcripts."
  - [section 5.5]: "LLM-Eval-M scores are on average 2 to 5 points lower than LLM-Eval-H. This indicates that ASR errors... may limit the summarization ability of LLMs..."
  - [corpus]: Evidence on cascading error propagation from corpus neighbors is weak or missing.
- **Break condition:** The performance drop can be mitigated by using a higher-quality ASR model or an intermediate error-correction module.

## Foundational Learning

- **Concept: Word Error Rate (WER) and Diarization Error Rate (DER)**
  - **Why needed here:** These are the primary metrics for evaluating the pipeline's front-end. Understanding their components (insertions/deletions vs. speaker misattribution) is essential for diagnosing system failures.
  - **Quick check question:** If an ASR transcript has 10 substitutions and 2 deletions in a 100-word reference, what is the WER? (Answer: 12%)

- **Concept: Cascading vs. End-to-End Architectures**
  - **Why needed here:** The paper evaluates a sequential pipeline (Diarization → ASR → LLM). Understanding this architecture is key to analyzing how errors compound across stages.
  - **Quick check question:** In a cascading pipeline, if the ASR misspells a drug name, will the LLM summarizer most likely use the correct name? (Answer: Unlikely, unless it has strong correction capabilities).

- **Concept: LLM Evaluation Metrics (BERTScore vs. LLM-as-Judge)**
  - **Why needed here:** The paper uses multiple evaluation methods with different strengths (semantic similarity vs. factual accuracy). Distinguishing them is crucial for interpreting the nuanced summarization results.
  - **Quick check question:** Which method is better for detecting a hallucinated diagnosis: BERTScore or an LLM-as-Judge with a specific factual accuracy criterion? (Answer: LLM-as-Judge).

## Architecture Onboarding

- **Component map:** Audio → Diarization → ASR → LLM Summarization
- **Critical path:** Audio → Diarization → ASR → LLM Summarization. The utility of the final summary is critically dependent on the accuracy of the preceding stages.
- **Design tradeoffs:**
  - **Simulated vs. Real Data:** Simulated data enables controlled scenarios (patient cards) but may lack the noise and interruption complexity of real-world clinical dialogues.
  - **BERTScore vs. LLM-as-Judge:** BERTScore is automated but can miss factual errors. LLM-as-Judge is slower but better aligned with clinical accuracy criteria.
  - **Model Selection:** Open-source models (e.g., Llama) offer transparency, while closed-source models (e.g., GPT-4o) show higher performance on this benchmark.
- **Failure signatures:**
  - **ASR Failure:** High WER on medical jargon (e.g., "paracetamol" → "para see tamol")
  - **Diarization Failure:** High DER on short, overlapping interjections (e.g., "mm-hmm")
  - **Summarization Failure:** Hallucinations in the LLM output, especially from noisy ASR transcripts
- **First 3 experiments:**
  1. **ASR Baseline:** Run Whisper-large-v3 on a sample of medical and general audio. Calculate and compare WER to confirm the domain gap.
  2. **Pipeline Error Analysis:** Run the full pipeline on a single conversation. Compare the LLM summary generated from the *human* transcript vs. the *ASR* transcript to quantify error propagation.
  3. **Diarization Fine-tuning:** Fine-tune a lightweight diarization model on a subset of Afrispeech-Dialog to improve performance on medical turn-taking patterns. Evaluate DER change.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does ASR and diarization performance generalize from simulated African-accented conversations to real-world clinical dialogues with natural interruptions and background noise?
  - **Basis in paper:** [explicit] The Limitations section states that simulated conversations "may not fully reflect the complexity of real-world natural dialogues where several interruptions, distractions and background noise are more typical," and calls for future research to "incorporate real-world data."
  - **Why unresolved:** The 50 conversation dataset was entirely simulated using patient/topic cards and trained actors; no real-world clinical recordings were evaluated.
  - **What evidence would resolve it:** Comparative benchmarking on a matched set of real African clinical conversations showing whether DER and WER patterns persist or worsen.

- **Open Question 2:** What specific ASR error types (medical entities, numerical values, or general vocabulary) most drive the 2–5 point drop in downstream summarization quality?
  - **Basis in paper:** [inferred] The authors report that LLM-Eval scores drop 2–5 points when using ASR transcripts versus human transcripts, and earlier work notes "accented medical jargon such as medication names, diagnoses, and density of numerical entities," but the exact error-to-summary-failure mapping is not analyzed.
  - **Why unresolved:** No error analysis links particular ASR mistake categories to summarization failures or to the six clinical evaluation criteria.
  - **What evidence would resolve it:** An error-type propagation study correlating ASR substitution/insertion/deletion patterns with per-criterion summarization score changes.

- **Open Question 3:** Can fine-tuning diarization and ASR models on African-accented conversational data close the observed 10%+ performance gap relative to native-accent benchmarks?
  - **Basis in paper:** [explicit] The abstract notes a "10%+ performance degradation" relative to native accents, and the Conclusion emphasizes the need to "improve accented conversational ASR in the African context."
  - **Why unresolved:** All experiments used off-the-shelf pretrained models without any accent-specific adaptation or fine-tuning.
  - **What evidence would resolve it:** Fine-tuning experiments on African-accented conversational speech, followed by re-benchmarking on Afrispeech-Dialog and native-accent datasets to measure gap reduction.

- **Open Question 4:** To what extent does the limited age diversity of contributors affect model generalization to broader African speaker populations?
  - **Basis in paper:** [explicit] The Limitations section notes that "the age range of contributors does not accurately reflect the diversity of real-world speaker populations, potentially impacting the generalizability of the results."
  - **Why unresolved:** No age demographics are reported, and no experiments stratify performance by age group.
  - **What evidence would resolve it:** Age-annotated speaker metadata and stratified WER/DER analysis across age bands to quantify performance variance.

## Limitations

- Simulated data may not capture real-world conversational complexity including natural interruptions and background noise
- Age range of contributors doesn't reflect broader African speaker population diversity
- DER results use strict collar=0.0 metric, potentially inflating performance gaps
- Evaluation relies heavily on automated metrics that may miss clinically relevant summarization quality aspects

## Confidence

- **High Confidence:** The core observation that African-accented English poses challenges for ASR models is well-supported by the 5-20 point WER degradation relative to native accents and similar datasets.
- **Medium Confidence:** The mechanism linking conversation structure to diarization performance (Mechanism 2) is plausible but requires additional evidence from real clinical dialogues to confirm.
- **Medium Confidence:** The error propagation claim (Mechanism 3) is supported by the 2-5 point BERTScore drop, but the clinical significance of this difference remains unclear without more targeted evaluation metrics.

## Next Checks

1. Conduct ablation studies on the impact of specific medical terminology density on WER by systematically varying jargon content in test samples
2. Evaluate the same pipeline on a small sample of real clinical dialogues (if available) to assess the simulation-to-reality gap
3. Implement a targeted factual accuracy evaluation for medical summaries, focusing on key clinical entities rather than semantic similarity