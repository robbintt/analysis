---
ver: rpa2
title: 'ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation'
arxiv_id: '2506.18095'
source_url: https://arxiv.org/abs/2506.18095
tags:
- image
- generation
- arxiv
- chen
- janus-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ShareGPT-4o-Image, a dataset of 91K high-quality
  synthetic image-text pairs distilled from GPT-4o-Image, aimed at democratizing advanced
  image generation capabilities for open-source models. The dataset includes 45K text-to-image
  and 46K text-and-image-to-image pairs, covering diverse visual content and editing
  tasks.
---

# ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation

## Quick Facts
- arXiv ID: 2506.18095
- Source URL: https://arxiv.org/abs/2506.18095
- Reference count: 32
- One-line primary result: Janus-4o, fine-tuned on 91K high-quality synthetic image-text pairs, achieves strong improvements over its predecessor on GenEval (+4 points) and DPG-Bench (+1.6 points) benchmarks.

## Executive Summary
This paper introduces ShareGPT-4o-Image, a dataset of 91K high-quality synthetic image-text pairs distilled from GPT-4o-Image, aimed at democratizing advanced image generation capabilities for open-source models. The dataset includes 45K text-to-image and 46K text-and-image-to-image pairs, covering diverse visual content and editing tasks. Using this data, the authors fine-tune Janus-Pro to create Janus-4o, a multimodal model that supports both generation modes. Janus-4o achieves strong improvements over its predecessor on GenEval (+4 points) and DPG-Bench (+1.6 points) benchmarks, and excels in image editing tasks on ImgEdit-Bench despite training on only 91K samples and 6 hours on 8 GPUs. Human evaluations also favor Janus-4o's outputs for instruction fidelity and visual quality. The work demonstrates that high-quality synthetic data can effectively transfer proprietary model capabilities to open models, enabling scalable and efficient training of advanced multimodal generative systems.

## Method Summary
The authors construct ShareGPT-4o-Image by using Gemini-Pro-2.5 to synthesize diverse prompts, which are then used to generate high-fidelity images with GPT-4o-Image. They fine-tune Janus-Pro-7B on this dataset using joint training for both text-to-image and text-and-image-to-image tasks. The training employs strategic masking (10% for text in T2I, 50% for input image tokens in TI2I) and uses a unified autoregressive Transformer architecture. The model is trained for 3 epochs with learning rate 5×10⁻⁶ on 8×A800 GPUs for 6 hours, achieving strong performance across multiple benchmarks.

## Key Results
- Janus-4o achieves +4 points improvement on GenEval benchmark over base Janus-Pro
- Janus-4o achieves +1.6 points improvement on DPG-Bench benchmark
- Janus-4o excels in image editing tasks on ImgEdit-Bench across 8 categories
- Model trains efficiently on only 91K samples for 6 hours on 8 GPUs

## Why This Works (Mechanism)

### Mechanism 1: High-Quality Synthetic Data Distillation
The effectiveness stems from distilling GPT-4o-Image's superior instruction-following and photorealism capabilities into Janus-Pro through supervised fine-tuning on curated synthetic data. The two-stage generation pipeline (prompt-first and image-first) ensures diverse, high-quality training samples.

### Mechanism 2: Unified Architecture for Dual-Modal Generation
Janus-4o extends the autoregressive Transformer paradigm to handle both text-to-image and text-and-image-to-image tasks within a single model by formulating both as next-token prediction problems.

### Mechanism 3: Strategic Input Masking for Task-Specific Learning
Distinct masking strategies (10% text masking for T2I, 50% input image token masking for TI2I) force the model to learn task-specific dependencies rather than overfitting to inputs.

## Foundational Learning

**Concept:** Autoregressive Image Generation
- Why needed here: Janus-4o generates images by treating them as sequences of discrete tokens, similar to how LLMs generate text.
- Quick check question: How is an image represented and generated in an autoregressive model like Janus-4o?

**Concept:** Knowledge Distillation
- Why needed here: The entire ShareGPT-4o-Image project is based on distilling the capabilities of the proprietary GPT-4o-Image model into an open-source one.
- Quick check question: What is the primary goal of using synthetic data generated by GPT-4o-Image to train Janus-4o?

**Concept:** Classifier-Free Guidance (CFG)
- Why needed here: The paper uses a modified CFG during inference to control generation strength and adherence to input.
- Quick check question: What is the purpose of scaling the difference between conditional and unconditional logits during inference?

## Architecture Onboarding

**Component map:**
Text Prompt + (Optional) Input Image -> Text Tokenizer + Image Tokenizer/Codebook -> Text Embedding + Image Token Embedding + Semantic Image Encoder (E) -> Unified Autoregressive Transformer (Janus-Pro-7B) -> Next Token Prediction

**Critical path:** For TI2I task: Input image is processed via tokenization (X) and semantic encoding (E), combined with text tokens (S), fed into Transformer, which autoregressively generates edited image tokens.

**Design tradeoffs:** The unified architecture trades potential raw power of specialized models for flexibility of a single MLLM. Training on only 91K samples achieves efficiency but may limit robustness to long-tail scenarios.

**Failure signatures:**
- Copy Task Failure: Model outputs input image unchanged, indicating failure to learn edit instruction
- Instruction Ignorance: Model modifies image in ways not specified by prompt
- Artifacts/Distortion: Generated image has visual glitches indicating tokenizer or generation issues

**First 3 experiments:**
1. Ablate Masking Ratios: Systematically vary the masking percentage for input image tokens in TI2I task (0%, 25%, 50%, 75%) to find optimal balance
2. Generalization Test: Evaluate on held-out editing instructions not in training dataset to assess generalization
3. Compare T2I vs. TI2I Synergy: Train separate models for each task and compare to unified Janus-4o

## Open Questions the Paper Calls Out
- The authors acknowledge they have not performed post-hoc filtering of images based on perceived bias and encourage further research into dataset characteristics including systematic bias audits.

## Limitations
- Effectiveness relies heavily on quality of synthetic dataset without adequate discussion of potential biases or artifacts from GPT-4o-Image distillation
- 91K sample scale represents significant reduction from standard practices, raising questions about robustness and long-tail scenario handling
- Paper focuses on technical performance metrics without addressing ethical considerations around synthetic data generation and democratization implications

## Confidence

**High Confidence:** The claim that fine-tuning with ShareGPT-4o-Image dataset improves Janus-Pro's performance on GenEval and DPG-Bench benchmarks is supported by concrete numerical improvements (+4 points on GenEval, +1.6 points on DPG-Bench).

**Medium Confidence:** The assertion that unified architecture effectively supports both T2I and TI2I tasks is reasonable but lacks ablation studies comparing against specialized models.

**Low Confidence:** The claim that this approach "democratizes" advanced image generation capabilities is more of a value judgment than a technical claim, without addressing potential barriers to adoption or misuse concerns.

## Next Checks
1. Conduct systematic evaluation of ShareGPT-4o-Image dataset to identify potential biases or artifacts introduced during GPT-4o-Image distillation process, particularly examining whether prompt-first and image-first pipelines create systematic coverage gaps or representational biases.

2. Test Janus-4o's performance on highly specific or unusual prompts not well-represented in the training dataset to assess limitations of training on only 91K samples versus larger, more diverse datasets.

3. Evaluate potential misuse scenarios and ethical implications of democratizing advanced image generation capabilities, including content authenticity verification challenges and potential for generating misleading or harmful imagery.