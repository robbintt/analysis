---
ver: rpa2
title: Efficiently Enhancing General Agents With Hierarchical-categorical Memory
arxiv_id: '2505.22006'
source_url: https://arxiv.org/abs/2505.22006
tags:
- memory
- learning
- agent
- task
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EHC introduces a hierarchical memory retrieval and task-category
  oriented learning framework to enable general-purpose multi-modal agents to learn
  without parameter updates. The Hierarchical Memory Retrieval (HMR) module uses a
  dual-pool architecture to efficiently store and retrieve relevant memories, while
  the Task-Category Oriented Experience Learning (TOEL) module classifies experiences
  and extracts patterns across task categories.
---

# Efficiently Enhancing General Agents With Hierarchical-categorical Memory

## Quick Facts
- arXiv ID: 2505.22006
- Source URL: https://arxiv.org/abs/2505.22006
- Reference count: 0
- Primary result: EHC improves accuracy by 7.8% on GQA and 4.0% on NLVR2 over baseline without parameter updates.

## Executive Summary
This paper proposes EHC (Efficiently Enhancing General Agents with Hierarchical-categorical Memory), a memory-augmented agent framework that combines hierarchical memory retrieval and task-category oriented learning to enhance multi-modal agents without parameter updates. The system uses a dual-pool architecture to efficiently store and retrieve relevant memories, while a task-category oriented learning module classifies experiences and extracts patterns across task categories. Experiments on GQA, NLVR2, RefCOCO, and MagicBrush datasets demonstrate state-of-the-art performance improvements, particularly 7.8% on GQA and 4.0% on NLVR2 over baseline, showing enhanced adaptability and interpretability for complex multi-modal tasks.

## Method Summary
EHC introduces two core modules: (1) HMR (Hierarchical Memory Retrieval) with a dual-pool architecture (fast-access RAM pool + external database) using LRU eviction, retrieving top-k examples based on similarity thresholds; (2) TOEL (Task-Category Oriented Experience Learning) that collects trajectories, classifies them using predefined categories with BERT embedding correction, and generates insights from contrastive experience pairs. The system performs inference by classifying tasks, retrieving category-specific trajectories and insights, and prompting an LLM. Baseline comparisons use CLOVA toolkit with LLaMA2-7B and Mistral-7B LLMs, initialized with 5 examples per category.

## Key Results
- EHC achieves 7.8% higher accuracy on GQA and 4.0% higher accuracy on NLVR2 compared to baseline.
- Ablation shows +HMR+TOEL configuration achieves 68.4% accuracy on GQA versus 60.2% baseline.
- The hierarchical memory system demonstrates effective scalability without memory capacity constraints.

## Why This Works (Mechanism)

### Mechanism 1
A hierarchical dual-pool memory architecture enables efficient retrieval while maintaining scalability for continuous learning. The HMR module maintains frequently-accessed memories in a fixed-capacity fast-access pool using LRU eviction, migrating colder entries to a scalable external database. Retrieval first queries the fast pool; only if insufficient matches are found does it fall back to the database, amortizing retrieval cost.

### Mechanism 2
Task-category classification reduces cross-task interference and improves retrieval relevance. TOEL combines predefined task categories with LLM-generated labels, then refines via BERT embedding similarity and cosine matching. Memories are partitioned into category-specific pools, ensuring retrieved in-context examples share task structure with the current query.

### Mechanism 3
Category-specific insight distillation from contrastive experience pairs improves decision quality without parameter updates. For each category, TOEL forms intra-category success-failure pairs and cross-category comparison groups, prompting the LLM to generate actionable insights. Insights are weighted and updated via ADD/EDIT/UPVOTE/DOWNVOTE operations, filtering low-quality knowledge.

## Foundational Learning

- **In-Context Learning (ICL)**: Why needed - EHC relies on retrieving trajectory examples as few-shot context; understanding ICL limits (context window, example ordering) is essential. Quick check - Can you explain why increasing retrieved examples beyond a point may hurt LLM performance?

- **Memory-Augmented Agents**: Why needed - The HMR dual-pool design assumes familiarity with external memory systems (vector DBs, caching policies). Quick check - What is the tradeoff between retrieval latency and memory capacity in a two-tier memory system?

- **Contrastive Learning from Trajectories**: Why needed - TOEL uses success-failure contrast pairs; understanding how positive/negative examples shape LLM reasoning is critical. Quick check - How might failure trajectories mislead an LLM if not properly filtered?

## Architecture Onboarding

- **Component map**: Task → TOEL Classifier → Category ck → HMR retrieves top-k from Mck → LLM + insights + trajectories → Output

- **Critical path**: 1) Task arrives; TOEL classifies into category ck. 2) HMR retrieves top-k relevant trajectories from Mck (Mmem first, then Mdb). 3) Insights ˆιck combined with trajectories and template prompt LLM. 4) On success/failure, trajectory stored; if failure, reflection triggers; on max attempts, stored as failure experience. 5) Periodic insight distillation updates weighted insight pool.

- **Design tradeoffs**: Capacity C (larger Mmem reduces DB queries but increases RAM cost); Category granularity (more categories reduce interference but fragment data and slow insight generalization); Insight weight decay rate (fast decay removes noisy insights but may discard slow-to-validate patterns); Retrieval threshold θ (higher threshold improves precision but may return insufficient examples).

- **Failure signatures**: High DB query frequency (Mmem capacity too small or θ too aggressive); Category misclassification spikes (LLM labeling unstable; check BERT correction effectiveness); Insight pool grows unbounded (weight decay too slow or DOWNVOTE not triggered); Retrieved examples irrelevant (embedding space misaligned; consider fine-tuning retriever).

- **First 3 experiments**: 1) Ablate HMR: Set C=∞ (no eviction) to isolate TOEL contribution; expect higher latency, similar accuracy if retrieval quality unchanged. 2) Category granularity sweep: Reduce categories from 7 to 3; measure accuracy drop on diverse tasks to identify interference. 3) Inspection of insight quality: Manually evaluate top-weighted insights per category for semantic coherence and actionability; correlate with per-category performance deltas.

## Open Questions the Paper Calls Out

### Open Question 1
Can the TOEL module autonomously generate and adapt to task categories not present in the initial predefined set? The paper relies on predefined categories based on domain analysis, implying a static taxonomy that may not cover unknown future tasks. Experiments on out-of-distribution tasks would verify if the system creates new category clusters rather than forcing fit into existing ones.

### Open Question 2
How does EHC perform on non-visual general-purpose tasks, such as text-only reasoning or embodied robotics? Despite claiming to build "general-purpose" agents, the experimental validation is restricted to multi-modal visual benchmarks. Benchmarking EHC on non-visual datasets or continuous control environments would validate its generality.

### Open Question 3
How does retrieval latency scale with the Deep-Retrieval Memory Pool size, and does it bottleneck real-time interaction? The paper claims to "mitigate memory redundancy" but focuses on accuracy metrics without analyzing the latency trade-offs of database queries versus the fixed-capacity RAM pool. Complexity analysis and wall-clock time measurements as the external database grows would quantify efficiency.

## Limitations
- Performance bounds under distributional shift remain unclear, as the paper does not report zero-shot or few-shot generalization performance.
- Category definition brittleness may cause misclassification for ambiguous or multi-category tasks, but this scenario is not explored.
- Insight quality dependency on LLM is not validated, as the paper does not report sensitivity to LLM model choice or semantic coherence of generated insights.

## Confidence
- **High confidence**: The hierarchical dual-pool memory architecture (HMR) is technically sound and well-supported by related work on memory-augmented agents.
- **Medium confidence**: The category-based retrieval and insight distillation (TOEL) framework is plausible but lacks direct validation of insight quality and generalization across task categories.
- **Low confidence**: The claim of "state-of-the-art" performance is weakly supported, as comparisons are limited to CLOVA baseline and ablation variants without direct comparison to concurrent or prior state-of-the-art methods.

## Next Checks
1. **Category granularity ablation**: Systematically reduce the number of task categories from 7 to 3 and measure accuracy on diverse datasets (GVA, NLVR2, MagicBrush). Identify the point where performance drops sharply, indicating category interference.

2. **Insight quality inspection**: Manually evaluate top-weighted insights per category for semantic coherence, actionability, and alignment with task semantics. Correlate insight quality scores with per-category performance deltas to assess insight contribution.

3. **Memory capacity sweep**: Vary the fast-access pool capacity C (e.g., 10, 50, 100 memories) and measure retrieval latency, DB query frequency, and accuracy. Identify the optimal C balancing speed and performance, and test LRU vs. LFU eviction.