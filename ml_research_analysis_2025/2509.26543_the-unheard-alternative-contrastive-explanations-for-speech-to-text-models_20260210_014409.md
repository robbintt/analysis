---
ver: rpa2
title: 'The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models'
arxiv_id: '2509.26543'
source_url: https://arxiv.org/abs/2509.26543
tags:
- explanations
- gender
- language
- contrastive
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first method for contrastive explanations
  in speech-to-text (S2T) models, addressing the challenge of explaining why models
  generate one word over another. The core method builds on perturbation-based feature
  attribution by aggregating subword-level probabilities into word-level probabilities
  and introducing a relative scoring function that quantifies probability changes
  between target and foil words.
---

# The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models

## Quick Facts
- arXiv ID: 2509.26543
- Source URL: https://arxiv.org/abs/2509.26543
- Reference count: 40
- Introduces the first method for contrastive explanations in speech-to-text models

## Executive Summary
This paper presents a novel method for generating contrastive explanations in speech-to-text (S2T) models, addressing the fundamental challenge of explaining why models generate one word over another. The approach builds on perturbation-based feature attribution, aggregating subword-level probabilities into word-level probabilities and introducing a relative scoring function that quantifies probability changes between target and foil words. Through a case study on gender assignment in speech translation, the method demonstrates superior ability to isolate gender-relevant features compared to traditional difference-based approaches, achieving high coverage and flip rates for feminine predictions when top features are progressively deleted.

## Method Summary
The method introduces contrastive explanations for S2T models by extending perturbation-based feature attribution techniques. It aggregates subword-level probabilities into word-level probabilities and implements a relative scoring function that compares probability changes between target and foil words. This approach overcomes limitations of previous difference-based scoring functions that fail to produce truly contrastive explanations. The method is evaluated through a case study on gender assignment in speech translation, where it successfully isolates gender-relevant features with coverage rates above 30% and flip rates over 70% for feminine predictions when progressively deleting top features.

## Key Results
- Introduces first method for contrastive explanations in S2T models
- Relative scoring function produces distinctly different saliency maps compared to non-contrastive approaches
- Achieves coverage rates above 30% and flip rates over 70% for feminine predictions in gender assignment case study

## Why This Works (Mechanism)
The method works by quantifying how probability distributions shift between target and foil words when features are perturbed. The relative scoring function captures the relative change in probabilities rather than absolute differences, which better isolates contrastive aspects of word generation. This approach successfully focuses on the specific features that distinguish between word choices rather than features that affect overall prediction confidence.

## Foundational Learning
- Subword tokenization: Needed to understand how S2T models process speech at the token level; Quick check: Verify understanding of BPE or WordPiece tokenization schemes
- Perturbation-based attribution: Core technique for feature importance; Quick check: Confirm understanding of how feature deletion affects model outputs
- Contrastive explanations: Framework for explaining word choices; Quick check: Distinguish between "why A" vs "why A instead of B" explanations
- Probability aggregation: Method for combining subword probabilities; Quick check: Understand how to aggregate token probabilities into word-level scores
- Saliency mapping: Visualization of feature importance; Quick check: Interpret heatmaps showing feature relevance
- Gender assignment in translation: Specific linguistic phenomenon studied; Quick check: Know how gender agreement works in target languages

## Architecture Onboarding

**Component map:** Speech input -> Feature extractor -> S2T model -> Subword probabilities -> Word-level aggregation -> Perturbation module -> Relative scoring -> Saliency maps

**Critical path:** Feature perturbation → Probability change calculation → Relative scoring function → Saliency map generation → Feature importance ranking

**Design tradeoffs:** Relative scoring vs difference-based scoring (better contrast but potentially noisier); Feature deletion vs gradient-based methods (more interpretable but computationally expensive); Word-level vs subword-level explanations (more human-readable but potentially less precise)

**Failure signatures:** If relative scoring produces uniform saliency maps, check for numerical instability in probability calculations; If coverage rates are low, verify feature perturbation implementation; If flip rates don't increase with feature deletion, check aggregation method

**3 first experiments:**
1. Apply perturbation to individual subwords and verify probability changes
2. Test relative scoring function on synthetic probability distributions
3. Validate word-level aggregation by comparing to subword-level explanations

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation relies heavily on a single case study (gender assignment in speech translation)
- May not capture complex interactions between features that influence word choice
- Relative scoring function lacks theoretical grounding for why it should outperform difference-based approaches in all contexts

## Confidence
- Confidence in core contribution (introducing contrastive explanations to S2T): **High**
- Confidence in relative scoring function's superiority: **Medium**
- Confidence in method's broader applicability: **Low**

## Next Checks
1. Apply the method to contrastive explanations for other linguistic phenomena (e.g., tense selection, lexical choice between synonyms) to assess generalizability
2. Conduct ablation studies comparing the relative scoring function against difference-based approaches across multiple model architectures and tasks
3. Evaluate the perturbation-based approach's ability to capture feature interactions by testing on cases where multiple features jointly influence word choice