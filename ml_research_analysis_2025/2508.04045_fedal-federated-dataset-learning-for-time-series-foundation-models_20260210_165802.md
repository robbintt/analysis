---
ver: rpa2
title: 'FeDaL: Federated Dataset Learning for Time Series Foundation Models'
arxiv_id: '2508.04045'
source_url: https://arxiv.org/abs/2508.04045
tags:
- series
- time
- learning
- forecasting
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of training Time Series Foundation
  Models (TSFMs) under federated learning, where dataset-wise heterogeneity introduces
  domain biases that hinder generalization. The proposed Federated Dataset Learning
  (FeDaL) framework explicitly mitigates both local and global biases through two
  complementary mechanisms: Domain Bias Elimination (DBE) and Global Bias Elimination
  (GBE).'
---

# FeDaL: Federated Dataset Learning for Time Series Foundation Models

## Quick Facts
- arXiv ID: 2508.04045
- Source URL: https://arxiv.org/abs/2508.04045
- Reference count: 40
- Key outcome: FeDaL achieves up to 27.62% relative MSE reduction in imputation and 8.86% improvement in representation learning compared to state-of-the-art federated TSFM methods

## Executive Summary
This paper addresses the challenge of training Time Series Foundation Models (TSFMs) under federated learning, where dataset-wise heterogeneity introduces domain biases that hinder generalization. The proposed Federated Dataset Learning (FeDaL) framework explicitly mitigates both local and global biases through two complementary mechanisms: Domain Bias Elimination (DBE) and Global Bias Elimination (GBE). DBE disentangles client-specific biases using time series decomposition, while GBE employs server-side gradient correction and core-set tuning to align client contributions. Experiments across eight real-world datasets spanning forecasting, imputation, classification, and anomaly detection tasks show that FeDaL consistently outperforms 54 baselines.

## Method Summary
FeDaL implements a decoder-only Transformer backbone with patch-level masking for masked reconstruction. The key innovation is the DBE block that decomposes latent representations into trend and seasonal components via moving average, estimates a local bias vector, and injects it back while regularizing against global bias. The server-side GBE maintains a state vector to correct client updates and uses privacy-preserving core-set tuning with Fourier amplitude perturbation and latent alignment. The method is trained using FedAvg-style aggregation with these corrections, employing convex fusion of the tuned and global models.

## Key Results
- FeDaL achieves up to 27.62% relative MSE reduction in imputation tasks
- FeDaL shows 8.86% improvement in representation learning compared to state-of-the-art federated TSFM methods
- First federated scaling analysis reveals that increasing data size, client count, and participation rate all improve model generalization under decentralized settings

## Why This Works (Mechanism)

### Mechanism 1: Latent Bias Disentanglement via Decomposition
- **Claim:** Explicitly modeling and separating domain-specific bias from temporal content in the latent space improves local representation quality.
- **Mechanism:** The model decomposes latent representations into trend ($h_{trend}$) and seasonal ($h_{season}$) components using moving averages. It averages these to estimate a local bias vector ($\hat{b}_p$). This vector is injected into the reconstruction path, while a regularization loss aligns it with a global reference, forcing the backbone to learn domain-invariant features.
- **Core assumption:** Domain biases in time series can be approximated as additive or persistent directional deviations in the latent space that are separable via decomposition.
- **Evidence anchors:**
  - [Section 3.1] "DBE block... decomposes the latent representation... into context-agnostic components... from which a trainable local bias vector is estimated."
  - [Abstract] "DBE disentangles client-specific biases using time series decomposition."
  - [Corpus] Limited direct corpus evidence on *federated* decomposition; related work in "Understanding the Implicit Biases of Design Choices for Time Series Foundation Models" discusses general bias challenges but not the specific FeDaL decomposition mechanism.
- **Break condition:** If domain biases are multiplicative or non-stationary (shifting unpredictably) rather than persistent additive offsets, the averaging mechanism may fail to capture them accurately.

### Mechanism 2: Server-Side Gradient Drift Correction
- **Claim:** Maintaining a server-side state vector to correct client updates mitigates global representation drift caused by heterogeneous optimization paths.
- **Mechanism:** The server maintains a state vector $s$ that tracks the accumulated difference between local updates and the global model. During aggregation, this state is used to correct the global update ($\theta_g$), stabilizing convergence without requiring client-side changes to the optimizer.
- **Core assumption:** Heterogeneity causes drift that is systematic and trackable, allowing a linear correction term to effectively counteract divergence.
- **Evidence anchors:**
  - [Section 3.2] "We maintain a server-side state vector $s$ that accumulates client-server gradient differences... [serving] as a correction term during global aggregation."
  - [Figure 3 (Right)] Shows that removing "Correction" increases reconstruction MSE significantly.
  - [Corpus] "A Comparative Study on How Data Normalization Affects Zero-Shot Generalization" highlights the difficulty of cross-domain alignment, implying the need for correction mechanisms.
- **Break condition:** If the client heterogeneity is extreme to the point where gradient directions are orthogonal rather than merely divergent, a single global correction vector may over-correct or destabilize learning.

### Mechanism 3: Privacy-Preserving Semantic Core-set Tuning
- **Claim:** Fine-tuning the global model on compressed, perturbed client data summaries (core-sets) refines global alignment without raw data exposure.
- **Mechanism:** Clients construct core-sets by matching gradients of a small subset to the full batch. To preserve privacy, they apply a Fourier-based perturbation (amplitude noise) and then realign the latent representation with the original batch semantics. The server aggregates these core-sets for a final tuning step.
- **Core assumption:** The phase of the Fourier transform encodes high-level temporal semantics sufficient for foundation model tuning, allowing amplitude to be discarded/noised.
- **Evidence anchors:**
  - [Section 3.2] "We perturb only the amplitude in the frequency domain... while the phase... encodes high-level temporal semantics."
  - [Figure 7] T-SNE visualization shows the perturbed core-set retains cluster consistency despite visual displacement.
  - [Corpus] No direct corpus evidence for this specific Fourier/core-set hybrid method in TSFMs.
- **Break condition:** If a task relies heavily on amplitude-specific features (e.g., precise magnitude scaling for forecasting) rather than phase/pattern, the perturbed core-set may lose critical tuning information.

## Foundational Learning

- **Concept: Federated Averaging (FedAvg) & Non-IID Data**
  - **Why needed here:** FeDaL is built upon FedAvg but addresses its core failure mode: performance degradation when client data is Non-IID (domain heterogeneous).
  - **Quick check question:** How does FeDaL modify the standard FedAvg aggregation logic to handle domains with different physical constraints? (Answer: It doesn't change aggregation directly, but modifies the local representation learning and adds global correction).

- **Concept: Time Series Decomposition (Trend-Seasonal)**
  - **Why needed here:** The Domain Bias Elimination (DBE) module relies on decomposing *latent* vectors into trend and seasonality to isolate bias.
  - **Quick check question:** In the DBE block, is decomposition applied to the raw input time series or the latent representation?

- **Concept: Foundation Model Pre-training (Masked Autoencoders)**
  - **Why needed here:** The base objective is masked reconstruction (like BERT for time series). Understanding the reconstruction loss is vital to seeing how "bias injection" aids the model.
  - **Quick check question:** What metric is used to evaluate the quality of the federated representation learning during pre-training? (Answer: Reconstruction MSE).

## Architecture Onboarding

- **Component map:**
  - Client-Side: Decoder-only Transformer Backbone -> DBE Block (Decomposition -> Bias Estimation -> Injection) -> Projection Head
  - Server-Side: Aggregator -> GBE Correction (State Vector) -> GBE Core-set Tuner (Fourier Perturbation -> Latent Alignment)

- **Critical path:**
  1. Local: Batch Input -> Masking -> Encoder -> Latent Decomp (Trend/Season) -> Calculate Bias $\hat{b}_p$ -> Inject Bias -> Decode
  2. Upload: Send weights ($\theta_i$) + Core-set ($C_i$)
  3. Global: Aggregate -> Apply State Correction -> Tune on Core-sets -> Fuse Weights ($\alpha$-blending)

- **Design tradeoffs:**
  - Decomposition Period ($\tau$): Setting $\tau$ too low might capture noise as seasonality; too high might miss fine-grained biases
  - Core-set Size ($K$): Larger $K$ improves tuning but increases communication costs and privacy risk (more raw data information leaked)
  - Perturbation Strength ($\epsilon$): High noise protects privacy but destroys semantic fidelity required for server tuning

- **Failure signatures:**
  - "Bias Collapse": If alignment loss $\lambda$ is too high, local bias vectors converge to zero or a single value, failing to capture domain nuance
  - "Core-set Drift": If Fourier perturbation misaligns semantics, server tuning degrades the global model rather than refining it (catastrophic forgetting)
  - "Correction Divergence": If $\beta$ in GBE is too large, the server state vector over-amplifies client drift, causing global model instability

- **First 3 experiments:**
  1. DBE Ablation: Train FeDaL without the DBE block on a highly heterogeneous dataset (e.g., different sampling rates). Expect significant MSE rise compared to full FeDaL.
  2. Core-set Privacy Utility: Vary perturbation $\epsilon$ and measure the trade-off between core-set semantic alignment loss and reconstruction quality.
  3. Scaling Behavior: Fix data volume but vary client count (e.g., 30 vs 174 clients). Verify if generalization improves strictly due to client diversity (domain coverage) as claimed.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the superior parameter efficiency of FeDaL hold when scaling the model architecture to sizes comparable to large-scale centralized foundation models (e.g., >1 billion parameters)?
- **Basis in paper:** [inferred] Appendix C.5 compares FeDaL (28M parameters) against Time-MoE (up to 2.4B parameters), claiming better efficiency. However, the experiments do not validate if the federated scaling behaviors improve or degrade when the model capacity itself is massively increased.
- **Why unresolved:** The scaling analysis (Section 4.3) varies data size and client count, but fixes the model architecture.
- **What evidence would resolve it:** Experiments running FeDaL with transformer architectures scaling from 100M to 1B+ parameters on the same LOTSA dataset, comparing convergence speed and final performance against centralized baselines of identical size.

### Open Question 2
- **Question:** How does the fixed decomposition period $\tau$ in the Domain Bias Elimination (DBE) module impact performance when clients possess time series with extreme differences in sampling frequencies (e.g., milliseconds vs. months)?
- **Basis in paper:** [inferred] The paper identifies "Temporal Resolution Bias" (Introduction) as a key challenge. However, the implementation (Appendix B) fixes the decomposition granularity $\tau=4$ for all clients, which may not optimally disentangle trend/seasonality for highly heterogeneous sampling rates.
- **Why unresolved:** The ablation study (Figure 3) tests removing DBE but does not analyze the sensitivity of the decomposition hyperparameter $\tau$ across clients with different resolutions.
- **What evidence would resolve it:** An analysis of reconstruction MSE on clients grouped by sampling frequency while varying $\tau$, or the implementation of an adaptive $\tau$ per client.

### Open Question 3
- **Question:** What are the formal differential privacy guarantees for the Fourier-based amplitude perturbation mechanism used in Global Bias Elimination (GBE), and how does the noise intensity $\epsilon$ theoretically affect convergence?
- **Basis in paper:** [inferred] Section 3.2 claims the Fourier-based perturbation "preserves privacy" by masking raw details. However, the paper provides no formal privacy budget (e.g., $\epsilon$-DP) or theoretical bound on how the added noise in Eq. (11) influences the gradient matching objective in Eq. (6).
- **Why unresolved:** The paper evaluates utility (performance) but treats privacy as a heuristic feature of the core-set generation rather than a formally constrained variable.
- **What evidence would resolve it:** A theoretical analysis deriving the privacy loss of the amplitude perturbation, or empirical attacks reconstructing raw data from the uploaded core-sets $C'$ to verify the robustness of the semantic masking.

## Limitations
- The decomposition assumption (that domain biases are additive and separable) may not hold for all real-world time series with multiplicative or non-stationary biases
- The Fourier perturbation method for privacy is innovative but lacks direct validation from the corpus, raising questions about its robustness across diverse temporal patterns
- Lack of complete architectural specifications (backbone dimensions), detailed domain partitioning schemes, and exact hyperparameter values for core-set tuning and EMA smoothing

## Confidence

**High**: Claims regarding FeDaL's relative performance improvements over baselines (up to 27.62% MSE reduction) are supported by extensive experimentation across multiple datasets and tasks.

**Medium**: The mechanism of DBE via latent decomposition is theoretically sound but relies on assumptions about bias characteristics that require further validation on extreme domain shifts.

**Low**: The privacy guarantees and semantic preservation of the Fourier-perturbed core-set method lack direct corpus support and require empirical validation beyond the provided t-SNE visualization.

## Next Checks

1. **Bias Structure Validation**: Apply FeDaL to a dataset with known multiplicative or highly non-stationary biases (e.g., financial data with regime shifts) to test if DBE decomposition remains effective or requires adaptation.

2. **Core-set Semantic Fidelity**: Conduct controlled experiments varying perturbation strength ($\epsilon$) and measuring not just reconstruction loss but also task-specific performance (e.g., forecasting accuracy) degradation to quantify the privacy-utility tradeoff.

3. **Correction Stability Test**: Implement FeDaL with extreme heterogeneity (e.g., clients from vastly different physical domains) and monitor server state vector behavior and global model convergence to identify potential divergence thresholds for the GBE correction mechanism.