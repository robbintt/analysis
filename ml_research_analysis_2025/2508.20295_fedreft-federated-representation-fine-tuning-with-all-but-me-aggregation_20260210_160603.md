---
ver: rpa2
title: 'FedReFT: Federated Representation Fine-Tuning with All-But-Me Aggregation'
arxiv_id: '2508.20295'
source_url: https://arxiv.org/abs/2508.20295
tags:
- fedreft
- client
- clients
- arxiv
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adapting representation fine-tuning
  (ReFT) to federated learning (FL) environments, where data heterogeneity and communication
  constraints hinder the direct application of centralized ReFT. To tackle this, the
  authors propose FedReFT, a novel framework that fine-tunes hidden representations
  via sparse intervention layers, making it lightweight and suitable for edge devices.
---

# FedReFT: Federated Representation Fine-Tuning with All-But-Me Aggregation

## Quick Facts
- **arXiv ID**: 2508.20295
- **Source URL**: https://arxiv.org/abs/2508.20295
- **Reference count**: 40
- **Primary result**: Achieves state-of-the-art performance in federated ReFT while being 1-49x more parameter-efficient than LoRA-based methods

## Executive Summary
This paper introduces FedReFT, a federated learning framework for representation fine-tuning that addresses the challenges of data heterogeneity and communication constraints in FL environments. The framework employs sparse intervention layers for lightweight fine-tuning of hidden representations and introduces an All-But-Me (ABM) aggregation strategy using geometric median to robustly combine client updates while avoiding semantic misalignment. FedReFT also incorporates an adaptive mixing mechanism inspired by Test-Time Computing to dynamically balance local and global knowledge during inference. Extensive experiments across 12 datasets demonstrate superior performance compared to leading federated learning approaches while maintaining significant parameter efficiency.

## Method Summary
FedReFT combines representation fine-tuning with federated learning by introducing sparse intervention layers that modify hidden representations rather than model weights, making it suitable for edge devices with limited resources. The framework's key innovation is the All-But-Me aggregation strategy, which computes the geometric median of updates from all clients except the current one, preventing semantic misalignment when clients have heterogeneous data. During inference, an adaptive mixing mechanism dynamically combines local and global knowledge using a Test-Time Computing-inspired approach, allowing the model to adjust to varying data distributions across clients. This design enables effective fine-tuning of large language models in federated settings while maintaining computational efficiency and robustness to data heterogeneity.

## Key Results
- Achieves state-of-the-art performance across commonsense reasoning, arithmetic reasoning, and GLUE benchmarks
- Demonstrates 1-49x parameter efficiency improvement over LoRA-based federated learning methods
- Shows robustness to data heterogeneity through All-But-Me aggregation strategy
- Maintains competitive performance while reducing communication overhead

## Why This Works (Mechanism)
FedReFT works by fine-tuning representations rather than model weights, which reduces the number of parameters that need to be communicated and updated in federated settings. The All-But-Me aggregation strategy prevents semantic misalignment by excluding the current client's update when computing the global model, ensuring that each client receives unbiased global knowledge. The adaptive mixing mechanism allows dynamic adjustment between local and global knowledge during inference, helping the model adapt to heterogeneous data distributions across clients. By combining these elements, FedReFT achieves effective representation learning in federated environments while maintaining computational efficiency and robustness to data heterogeneity.

## Foundational Learning
- **Representation Fine-Tuning (ReFT)**: Fine-tuning hidden representations instead of model weights to achieve parameter efficiency; needed because full fine-tuning is computationally expensive in FL
- **Geometric Median**: A robust aggregation method that finds the median point in multidimensional space; needed to prevent semantic misalignment in heterogeneous FL scenarios
- **Test-Time Computing (TTC)**: Dynamic adjustment of model behavior during inference based on input characteristics; needed to balance local and global knowledge in heterogeneous environments
- **Sparse Intervention Layers**: Small trainable modules that modify intermediate representations; needed to achieve parameter efficiency while maintaining performance
- **Semantic Misalignment**: When client models learn different semantic spaces due to data heterogeneity; needs to be addressed to ensure effective FL aggregation
- **Parameter Efficiency**: Minimizing the number of trainable parameters while maintaining performance; critical for deployment on resource-constrained edge devices

## Architecture Onboarding

**Component Map**: Client models with intervention layers -> Local fine-tuning -> All-But-Me aggregation -> Global model -> Adaptive mixing -> Inference

**Critical Path**: Data input -> Intervention layers -> Local fine-tuning -> ABM aggregation -> Global update -> Adaptive mixing -> Output prediction

**Design Tradeoffs**: The framework trades some model expressiveness for parameter efficiency by using sparse intervention layers instead of full fine-tuning, and accepts the computational overhead of geometric median calculation for improved robustness to semantic misalignment.

**Failure Signatures**: Performance degradation when semantic misalignment is severe, convergence issues when the number of clients is very large, and potential overfitting when adaptive mixing favors local knowledge too heavily.

**First Experiments**:
1. Evaluate parameter efficiency by comparing trainable parameters between FedReFT and LoRA-based methods
2. Test robustness to semantic misalignment by training on artificially heterogeneous datasets
3. Validate adaptive mixing effectiveness by comparing performance with and without dynamic adjustment

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Limited exploration of failure modes under severe semantic misalignment between clients
- No convergence guarantees provided for the All-But-Me aggregation strategy
- Insufficient characterization of performance across varying numbers of clients and data distributions
- Missing ablation study to isolate contributions of individual components (ABM aggregation, adaptive mixing)

## Confidence
- **High confidence**: Parameter efficiency claims and comparison with LoRA baselines
- **Medium confidence**: Robustness of All-But-Me aggregation across diverse federated scenarios
- **Medium confidence**: Generalizability of results to datasets outside evaluated task categories

## Next Checks
1. Conduct experiments with extreme label distribution skew to test robustness of All-But-Me aggregation when some clients have highly specialized knowledge
2. Perform an ablation study comparing FedReFT with and without adaptive mixing mechanism to isolate its contribution to performance gains
3. Test FedReFT on datasets with concept drift over time to evaluate ability to maintain performance in non-stationary federated environments