---
ver: rpa2
title: 'StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?'
arxiv_id: '2510.02209'
source_url: https://arxiv.org/abs/2510.02209
tags:
- arxiv
- agents
- trading
- financial
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces StockBench, a benchmark designed to evaluate
  large language model (LLM) agents in realistic stock trading environments. Unlike
  existing financial benchmarks that focus on static question-answering, StockBench
  simulates multi-month trading scenarios where agents make sequential buy, sell,
  or hold decisions based on daily market data including prices, fundamentals, and
  news.
---

# StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?

## Quick Facts
- arXiv ID: 2510.02209
- Source URL: https://arxiv.org/abs/2510.02209
- Reference count: 16
- Most LLM agents fail to beat buy-and-hold baseline in realistic trading simulation

## Executive Summary
This paper introduces StockBench, a benchmark designed to evaluate large language model (LLM) agents in realistic stock trading environments. Unlike existing financial benchmarks that focus on static question-answering, StockBench simulates multi-month trading scenarios where agents make sequential buy, sell, or hold decisions based on daily market data including prices, fundamentals, and news. The benchmark evaluates performance using financial metrics like cumulative return, maximum drawdown, and Sortino ratio. Experiments with state-of-the-art models including GPT-5, Claude-4, Qwen3, Kimi-K2, and GLM-4.5 show that most agents fail to outperform a simple buy-and-hold baseline, despite strong performance on financial QA tasks. Several models demonstrate potential for higher returns and better risk management, but the results highlight that static financial knowledge does not necessarily translate to profitable trading strategies. The authors release StockBench as an open-source resource to advance research in LLM-powered financial agents.

## Method Summary
StockBench evaluates LLM agents on sequential stock trading decisions over 82 trading days using top 20 DJIA stocks. Agents receive daily market data (prices, fundamentals, news) and make buy/sell/hold decisions through a 4-stage workflow: portfolio overview, stock analysis, decision generation, and execution/validation. The benchmark uses March-July 2025 data to avoid contamination, with $100,000 initial capital and 32K token context. Performance is measured using cumulative return, maximum drawdown, and Sortino ratio, with a composite rank calculated from z-scores. The equal-weight buy-and-hold baseline achieved 0.4% return with -15.2% maximum drawdown.

## Key Results
- Most state-of-the-art LLM agents (GPT-5, Claude-4, Qwen3, Kimi-K2, GLM-4.5, DeepSeek) fail to outperform the 0.4% buy-and-hold baseline
- All agents achieved lower maximum drawdown (-11% to -14%) than passive baseline (-15.2%), indicating better risk management
- Reasoning-tuned Qwen3-235B-Ins underperformed its base version, showing reasoning capability doesn't guarantee better trading
- Multi-modal information integration showed mixed benefits, with performance varying significantly across models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-modal information integration improves trading decisions over single-source inputs
- Mechanism: Agents combine quantitative signals (prices, fundamentals) with qualitative signals (news sentiment, events) to generate more informed buy/sell/hold decisions
- Core assumption: News and fundamental data provide complementary, non-redundant signals for price prediction
- Evidence anchors:
  - [abstract] "Agents receive daily market signals -- including prices, fundamentals, and news -- and must make sequential buy, sell, or hold decisions."
  - [Section 4.3] Ablation study shows Kimi-K2 return drops from 1.9% to 0.6% when both news and fundamentals removed; GPT-OSS-120B drops from -1.2% to -3.4%
  - [corpus] Related paper "Trade in Minutes!" notes similar multi-signal integration for quantitative trading systems
- Break condition: If news and fundamentals are highly correlated or provide conflicting signals, integration may not improve decisions

### Mechanism 2
- Claim: Continuous sequential decision-making enables adaptive risk management
- Mechanism: Daily rebalancing allows agents to reduce exposure during downturns and capitalize on trends, resulting in lower maximum drawdowns than passive strategies
- Core assumption: LLMs can translate reasoning about market conditions into timely position adjustments
- Evidence anchors:
  - [abstract] "Simulates multi-month trading scenarios where agents make sequential buy, sell, or hold decisions"
  - [Section 3.2] All LLM agents achieved lower max drawdown (-11% to -14%) than passive baseline (-15.2%), indicating effective downside risk mitigation
  - [corpus] "When Agents Trade" paper similarly finds live sequential trading enables adaptive behavior
- Break condition: If transaction costs, slippage, or execution delays are introduced, frequent rebalancing may erode returns

### Mechanism 3
- Claim: Reasoning capabilities do not directly transfer to profitable trading decisions
- Mechanism: Strong performance on static reasoning tasks (math, coding) does not guarantee effective decision-making in noisy, dynamic environments where signal-to-noise ratios are low
- Core assumption: Trading requires different cognitive skills than QA tasks
- Evidence anchors:
  - [Section 3.2] "Reasoning model does not guarantee better performance... Qwen3-235B-Ins outperforms its reasoning-tuned version with lower maximum drawdown (-11.2% vs -14.9%)"
  - [Section 1] "Excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies"
  - [corpus] TradeTrap paper examines reliability issues in LLM trading agents, suggesting reasoning alone is insufficient
- Break condition: If domain-specific fine-tuning on trading data were applied, reasoning models might show improved transfer

## Foundational Learning

- Concept: **Financial Risk Metrics (Maximum Drawdown, Sortino Ratio)**
  - Why needed here: StockBench evaluates agents on risk-adjusted returns, not just profitability. Understanding downside risk metrics is essential for interpreting why some models rank higher despite lower returns
  - Quick check question: If Model A has 3% return with -12% max drawdown, and Model B has 2.5% return with -10% max drawdown, which has better risk-adjusted performance according to the Sortino ratio?

- Concept: **Data Contamination in Financial ML**
  - Why needed here: The benchmark explicitly uses March-July 2025 data to avoid overlap with LLM training corpora. Understanding why this matters is critical for designing valid trading experiments
  - Quick check question: Why would testing an LLM on 2021 stock data potentially inflate performance estimates?

- Concept: **Sequential vs Single-Shot Decision Making**
  - Why needed here: StockBench evaluates 82 consecutive trading days with portfolio state carryover. This differs fundamentally from QA benchmarks where each question is independent
  - Quick check question: How might a bad decision on Day 10 affect performance on Day 50?

## Architecture Onboarding

- Component map:
  - Data Loader -> Portfolio Overview -> Stock Analysis -> Decision Generation -> Execution/Validation -> Portfolio Update

- Critical path:
  1. Load daily data for all 20 stocks (prices, 7-day action history, 5 recent news articles)
  2. Agent generates portfolio overview and selects stocks for deep analysis
  3. Agent receives fundamental data (market cap, P/E, dividend yield, 52-week range)
  4. Agent outputs JSON with buy/sell/hold decisions and dollar targets
  5. System validates liquidity constraints, converts to shares at opening price
  6. If validation fails, agent must revise; if passes, portfolio updates and simulation advances

- Design tradeoffs:
  - **Minimal workflow** vs complex multi-agent systems: Paper intentionally keeps workflow simple to avoid inductive bias favoring certain models
  - **5 news articles** vs full corpus: Balances information coverage against context window limits and API costs
  - **DJIA top 20** vs broader universe: Ensures data availability and reduces noise from low-liquidity stocks
  - **Assumption**: Equal-weight buy-and-hold is treated as baseline; alternative baselines (momentum, mean-reversion) not tested

- Failure signatures:
  - **Arithmetic errors**: Incorrect share calculation from dollar amounts (more common in instruct models)
  - **Schema errors**: JSON format violations preventing parsing (more common in reasoning/"thinking" models due to over-complex outputs)
  - **Scalability collapse**: Performance degrades as portfolio size increases from 5â†’30 stocks (Table 3 shows coefficient of variation increases dramatically)
  - **Regime sensitivity**: Models that perform well in upturns may fail in downturns (Figure 4 shows rank reversals)

- First 3 experiments:
  1. **Baseline replication**: Run buy-and-hold equal-weight strategy on the 20 DJIA stocks to confirm the 0.4% return and -15.2% max drawdown benchmark
  2. **Ablation on information sources**: Test a single model (e.g., Kimi-K2) with full inputs, news-only, fundamentals-only, and neither to quantify contribution of each signal type
  3. **Error rate profiling**: Run multiple trials of the same model with different random seeds to measure variance in decisions and identify whether failures are systematic (schema issues) or stochastic (decision variability)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can LLM agents be improved to navigate bearish market conditions effectively?
- Basis in paper: [explicit] The authors state in Section 4.4 that "LLM agents may struggle to navigate bearish markets, highlighting a key area for future improvement" after observing that all agents failed to outperform the passive baseline during downturn periods.
- Why unresolved: The paper identifies the problem but does not propose or test solutions for improving bear-market performance.
- What evidence would resolve it: Experiments showing LLM agents consistently matching or exceeding baseline returns during sustained market downturns, potentially through modified training, prompting strategies, or architectural changes.

### Open Question 2
- Question: How can the scalability challenge be addressed so LLM agents maintain performance as portfolio size increases?
- Basis in paper: [explicit] Section 4.1 states "Scalability is inherently challenging" and shows performance degradation with more stocks; larger models like Kimi-K2 show more robustness but still decline.
- Why unresolved: The paper documents the scaling problem but offers no mechanism to overcome it beyond using larger models.
- What evidence would resolve it: Demonstrating stable or improving returns and manageable variance as portfolio sizes grow from 5 to 30+ stocks, possibly via hierarchical decision-making or specialized multi-asset architectures.

### Open Question 3
- Question: What novel agent architectures or training paradigms could bridge the gap between strong financial QA performance and profitable trading strategies?
- Basis in paper: [explicit] The authors conclude that "excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies" and call for exploring "novel agent architectures" in future work.
- Why unresolved: Current models excel at knowledge tasks but fail in dynamic environments; the disconnect remains unexplained and unaddressed.
- What evidence would resolve it: Agents trained with market simulation, reinforcement learning, or temporal reasoning that achieve both high QA scores and trading returns surpassing buy-and-hold baselines.

### Open Question 4
- Question: Can the trade-off between reasoning models' lower arithmetic errors and higher schema errors be resolved for reliable trading execution?
- Basis in paper: [inferred] Figure 3 shows thinking models make fewer arithmetic errors but more schema/format errors than instruct models, creating a reliability dilemma.
- Why unresolved: Neither model type achieves both low reasoning errors and high format adherence.
- What evidence would resolve it: A unified approach achieving both error rates below 2%, ensuring accurate calculations and consistent JSON outputs for real-world deployment.

## Limitations

- **Data period specificity**: The benchmark uses a narrow 5-month window (March-July 2025) that may not generalize across market regimes
- **Prompt template opacity**: Exact prompt structures are not disclosed, making it difficult to reproduce results or optimize agent performance
- **Single baseline comparison**: Only equal-weight buy-and-hold is used as baseline, limiting the ability to assess agent capabilities against alternative strategies

## Confidence

**High confidence**: The experimental finding that most state-of-the-art LLM agents fail to outperform the buy-and-hold baseline. This is directly supported by comprehensive results across multiple models (GPT-5, Claude-4, Qwen3 variants, Kimi-K2, GLM-4.5, DeepSeek) showing negative or marginal returns compared to the 0.4% baseline.

**Medium confidence**: The claim that reasoning capabilities do not directly translate to profitable trading decisions. While supported by the Qwen3-235B-Ins vs reasoning-tuned version comparison, this conclusion depends on the specific trading environment and may not hold across different market conditions or with domain-specific fine-tuning.

**Low confidence**: The assertion that multi-modal information integration significantly improves trading decisions. The ablation study shows Kimi-K2 performance deterioration when removing news/fundamentals, but the effect size varies substantially across models (GPT-OSS-120B shows -1.2% to -3.4% drop vs Kimi-K2's 1.9% to 0.6% drop), suggesting model-specific rather than universal benefits.

## Next Checks

1. **Cross-regime robustness test**: Rerun the benchmark on historical data from different market periods (2008 crisis, 2020 COVID crash, 2021 bull market) to assess whether performance patterns hold across market regimes and identify regime-specific failure modes.

2. **Alternative baseline comparison**: Implement and compare against multiple passive strategies including momentum-weighted portfolios, sector rotation, and equal-weight sector-based portfolios to establish whether LLM agents capture any systematic market patterns beyond simple heuristics.

3. **Prompt engineering ablation**: Systematically vary prompt templates for the decision generation stage (minimal instructions, detailed reasoning chain, hybrid approaches) across a subset of models to quantify the impact of prompt design on schema compliance, arithmetic accuracy, and overall trading performance.