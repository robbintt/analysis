---
ver: rpa2
title: 'When AI companions become witty: Can human brain recognize AI-generated irony?'
arxiv_id: '2510.17168'
source_url: https://arxiv.org/abs/2510.17168
tags:
- irony
- human
- type
- people
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether people adopt the intentional stance
  toward AI-generated irony during language comprehension. Participants read ironic
  and literal statements attributed to either AI or human sources while EEG data were
  recorded.
---

# When AI companions become witty: Can human brain recognize AI-generated irony?

## Quick Facts
- **arXiv ID:** 2510.17168
- **Source URL:** https://arxiv.org/abs/2510.17168
- **Reference count:** 0
- **Primary result:** People show reduced neural signatures of intentional stance adoption toward AI-generated irony compared to human-generated irony.

## Executive Summary
This study investigated whether people adopt the intentional stance toward AI-generated irony during language comprehension using EEG. Participants read ironic and literal statements attributed to either AI or human sources while neural activity was recorded. Results showed that people were less likely to attribute AI-generated incongruities to deliberate communication, instead favoring explanations of computational errors. Neural responses revealed attenuated P200 and P600 effects for AI-generated irony compared to human-generated irony, indicating reduced early incongruity detection and effortful reanalysis. These effects were modulated by individual perceptions of AI sincerity and trustworthiness, with more anthropomorphic views leading to stronger neural responses.

## Method Summary
The study used a 2×2 factorial design with 64 participants (59 after exclusion) reading Chinese dialogue sets containing ironic and literal statements attributed to AI or human sources. EEG data was recorded at 512 Hz using 128 channels with a bandpass filter of 0.1-30 Hz. Participants judged contextual congruence after each dialogue. ERP components P200 (150-300ms) and P600 (600-1000ms) were extracted from central ROI channels. Linear mixed-effects models analyzed Type × Source interactions with random effects for Participant, Item, and Channel.

## Key Results
- P200 amplitude was significantly smaller for AI irony (0.20 μV) than human irony (0.50 μV), indicating reduced early incongruity detection
- P600 amplitude was significantly smaller for AI irony (0.34 μV) than human irony (0.78 μV), suggesting reduced effortful reanalysis of incongruity as intentional
- Individual perceptions of AI sincerity and trustworthiness modulated ERP amplitudes, with more anthropomorphic views showing stronger neural responses

## Why This Works (Mechanism)

### Mechanism 1: Source-Modulated Early Semantic Processing (P200 Attenuation)
- Claim: The brain allocates less early attentional resources to semantic incongruity when the source is perceived as AI rather than human
- Core assumption: Reduced P200 reflects genuinely different pre-attentional processing, not just conscious strategy differences
- Evidence: P200 effect significantly smaller for AI irony (0.20 μV) than human irony (0.50 μV)

### Mechanism 2: Reduced Intentional Reanalysis (P600 Attenuation)
- Claim: The brain invests fewer resources in reinterpreting apparent semantic errors as intentional irony when the source is AI
- Core assumption: P600 amplitude directly indexes intentionality attribution rather than general difficulty or surprise
- Evidence: P600 effect significantly smaller for AI irony (0.34 μV) than human irony (0.78 μV)

### Mechanism 3: Individual Difference Modulation via Anthropomorphic Mental Models
- Claim: Pre-existing beliefs about AI sincerity and trustworthiness calibrate the degree of intentional stance adoption
- Core assumption: Causality runs from beliefs to neural responses, not from neural responses to post-hoc belief reports
- Evidence: Both P200 and P600 amplitudes to AI-generated irony increased among participants who perceived AI as more sincere

## Foundational Learning

- **Event-Related Potentials (ERPs) and their time course**
  - Why needed: Understanding P200, P300, and P600 components is essential to interpret when and how source attribution affects processing stages
  - Quick check: If P600 is reduced but P200 is intact, what does this imply about the stage at which intentional stance adoption operates?

- **Intentional Stance and Theory of Mind**
  - Why needed: The paper operationalizes "treating AI as a social agent" via mental state attribution during irony comprehension
  - Quick check: Distinguish "mindless anthropomorphism" from "mindful anthropomorphism"—which predicts stronger ERP differences between AI and human sources?

- **Irony Comprehension as an Experimental Paradigm**
  - Why needed: Irony requires distinguishing intentional contradictions from errors, making it a clean test case for intentionality attribution
  - Quick check: Why is irony better suited than, say, metaphor or humor for isolating intentionality attribution versus general figurative language processing?

## Architecture Onboarding

- **Component map:**
  - Source Attribution Layer -> Early Incongruity Detection (P200) -> Context Updating (P300) -> Intentional Reanalysis (P600) -> Behavioral Attribution

- **Critical path:**
  1. Source attribution → 2. Early incongruity detection (P200) → 3. Context updating (P300) → 4. Intentional reanalysis (P600) → 5. Behavioral attribution (irony vs. error)

- **Design tradeoffs:**
  - Between-participants source manipulation reduces demand effects but limits within-subject comparisons
  - Excluding trials based on post-hoc attribution improves signal cleanliness but risks circularity
  - Mandarin-only stimuli limit cross-linguistic generalizability

- **Failure signatures:**
  - P200/P600 amplitude differences without behavioral attribution differences → neural effects may not translate to conscious judgment
  - Manipulation check failures → source attribution manipulation invalid
  - Excessive trial rejection (>30%) → insufficient signal-to-noise ratio

- **First 3 experiments:**
  1. Replicate with within-participants source manipulation to isolate individual differences from condition effects
  2. Add a "random text generator" control condition to distinguish AI-specific processing from general non-human agent processing
  3. Longitudinal design tracking whether repeated AI exposure shifts P200/P600 amplitudes over time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would repeated, prolonged exposure to sophisticated AI interlocutors shift neural processing patterns toward those observed for human interlocutors, or is the reduced intentional stance toward AI stable?
- Basis: The authors note that "processing patterns evolve dynamically as people update their mental models of AI capabilities" but the study design is cross-sectional
- Resolution: A longitudinal study tracking the same participants' neural responses to AI-generated irony over extended periods of regular AI interaction

### Open Question 2
- Question: Would the attenuated P200 and P600 effects for AI-generated irony generalize to other forms of non-literal language such as metaphor, indirect speech acts, or humor?
- Basis: The authors acknowledge irony was chosen as "an ideal paradigm" but do not test whether source-specific processing extends to other communicative phenomena
- Resolution: Replication of the paradigm using metaphors, indirect requests, or other non-literal stimuli attributed to AI versus human sources

### Open Question 3
- Question: What specific behavioral or design characteristics of AI systems would enable full intentional stance adoption—can manipulations of AI behavior causally increase human-like neural processing?
- Basis: The conclusion states that "achieving genuine social agency requires more than linguistic competence; it necessitates a shift in how humans perceive and attribute intentionality to artificial agents"
- Resolution: Experimental manipulation of AI behavioral cues combined with neural measures

## Limitations

- Between-subjects design for source attribution limits direct comparisons of individual differences
- Post-hoc trial exclusion based on attribution judgments introduces circularity and reduces statistical power
- Only tested Mandarin Chinese stimuli, limiting cross-linguistic generalizability

## Confidence

**High Confidence:**
- AI-generated irony produces smaller P200 and P600 amplitudes than human-generated irony
- Individual perceptions of AI sincerity correlate with stronger neural responses to AI irony
- Behavioral attribution patterns show reduced intentional stance toward AI sources

**Medium Confidence:**
- P200 attenuation reflects genuinely reduced early semantic incongruity detection
- P600 attenuation indexes reduced intentionality attribution rather than general processing difficulty
- The link between individual beliefs and neural responses reflects causal mental model effects

**Low Confidence:**
- The findings generalize to non-linguistic AI interactions (visual, auditory, or multimodal)
- Long-term AI exposure would shift neural processing patterns toward human-like responses
- The results apply to future AI systems with enhanced social capabilities

## Next Checks

1. **Replication with Within-Subjects Design:** Implement within-participants source manipulation where the same stimuli are attributed to both AI and human sources across different blocks
2. **Control Condition for Non-Intentional Agents:** Add a "random text generator" condition that produces semantically anomalous but non-ironic statements
3. **Longitudinal Exposure Study:** Track neural responses to AI-generated irony across multiple sessions with increasing exposure to AI systems