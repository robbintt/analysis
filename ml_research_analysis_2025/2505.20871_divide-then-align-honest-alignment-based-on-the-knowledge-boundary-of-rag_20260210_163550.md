---
ver: rpa2
title: 'Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG'
arxiv_id: '2505.20871'
source_url: https://arxiv.org/abs/2505.20871
tags:
- knowledge
- answer
- boundary
- retrieval
- when
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of retrieval-augmented generation\
  \ (RAG) systems that are conditioned to generate answers even when queries fall\
  \ outside the combined knowledge boundary of both the model\u2019s parametric knowledge\
  \ and retrieved passages. To solve this, the authors propose Divide-Then-Align (DTA),\
  \ a systematic post-training approach that divides data into four knowledge quadrants\
  \ based on whether queries lie within the model\u2019s parametric knowledge and\
  \ retrieval knowledge boundaries."
---

# Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG

## Quick Facts
- **arXiv ID**: 2505.20871
- **Source URL**: https://arxiv.org/abs/2505.20871
- **Reference count**: 37
- **Primary result**: DTA achieves F1 up to 66.6 and AF1 up to 63.3 by teaching RAG models when to answer versus abstain

## Executive Summary
This paper addresses the problem of retrieval-augmented generation (RAG) systems that generate answers even when queries fall outside their combined knowledge boundary. The authors propose Divide-Then-Align (DTA), a post-training approach that divides data into four knowledge quadrants based on whether queries lie within the model's parametric knowledge and retrieval knowledge boundaries. By constructing tailored preference data for each quadrant and applying Direct Preference Optimization (DPO), DTA teaches models to respond with "I don't know" when appropriate while maintaining answer quality. Experiments on three datasets show significant improvements in both answer quality (F1 up to 66.6) and abstention quality (AF1 up to 63.3).

## Method Summary
DTA works by first dividing data samples into four knowledge quadrants based on parametric knowledge boundary (KBparam) and retrieval knowledge boundary (KBr) determination. For each quadrant, tailored preference pairs are constructed (ground truth vs. wrong answers or "I don't know"). The model is then trained using a multi-objective loss combining DPO for preference learning, SFT on chosen responses, and an auxiliary classification loss for boundary awareness. This approach enables the model to learn when to answer versus abstain based on the intersection of its parametric knowledge and retrieved context.

## Key Results
- Achieves F1 score of 66.6 on NQ dataset, outperforming baselines (RAAT 62.4, Ret-Robust 61.3)
- Achieves AF1 score of 63.3 on WebQ dataset, demonstrating strong abstention capability
- Maintains DR of 68.9 and CUR of 52.8, showing effective retrieval utilization despite improved honesty
- Ablation studies confirm SFT loss is critical for preventing quality collapse when teaching abstention

## Why This Works (Mechanism)

### Mechanism 1: Quadrant-Based Preference Alignment
DTA partitions queries into four knowledge quadrants and applies DPO with tailored preference pairs for each quadrant. This enables models to learn when to answer versus abstain by optimizing for correct behavior in each knowledge state. The approach relies on accurate quadrant labeling using lexical matching for parametric knowledge and GPT-4o evaluation for retrieval coverage.

### Mechanism 2: Multi-Objective Training for Balanced Abstention and Accuracy
The method combines DPO loss with supervised fine-tuning (SFT) on chosen responses and an auxiliary quadrant classification loss. This combination preserves answer quality while teaching appropriate abstention. Loss weighting (β, γ) permits stable trade-off between answer metrics (F1) and abstention metrics (AF1).

### Mechanism 3: Dual-Boundary Modeling Over Single-Boundary Heuristics
DTA defines the RAG knowledge boundary as the union of parametric and retrieval boundaries, yielding more honest behavior than using either alone. This approach prevents unnecessary abstentions or forced hallucinations that occur with single-boundary methods.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: DTA specifically targets RAG systems where external context supplements parametric knowledge
  - Quick check question: Can you explain how retrieved passages interact with a model's internal weights during generation?

- **Concept: Direct Preference Optimization (DPO)**
  - Why needed here: DTA builds on DPO to align model outputs with preference pairs rather than using reinforcement learning with a separate reward model
  - Quick check question: What quantity does DPO optimize, and how does it relate to reward differences?

- **Concept: Knowledge Boundary**
  - Why needed here: The central thesis is recognizing and respecting when neither parametric nor retrieval knowledge suffices
  - Quick check question: If a query falls outside KBparam but within KBr, should the model answer or abstain?

## Architecture Onboarding

- **Component map**: KBparam estimator (lexical match) -> KBr estimator (GPT-4o) -> Quadrant label assignment -> Preference pair construction -> Multi-objective DPO training -> Quadrant-stratified evaluation

- **Critical path**: 
  1. Run KBparam and KBr determination to tag each sample
  2. Construct preference pairs for each quadrant (GT, IDK, WA1, WA2 templates)
  3. Train with combined LDPO + β·LSFT + γ·Lclass
  4. Evaluate on quadrant-stratified test splits

- **Design tradeoffs**:
  - IDK-ratio: Higher ratios improve AF1 but may reduce DR/CUR
  - Loss weights: Strong SFT weight stabilizes chosen-response quality
  - Labeling reliability: Lexical matching may misjudge paraphrased correct answers

- **Failure signatures**:
  - Over-abstention: High ARec but low APrec and F1
  - Under-abstention: Near-zero AF1
  - Collapsed DR/CUR: Model avoids using retrieval

- **First 3 experiments**:
  1. Replicate KBparam/KBr labeling on held-out subset to validate quadrant distributions
  2. Train DTA with default hyperparameters and compare against baselines
  3. Run ablation: w/o SFT, w/o ✘✘ samples, and single-boundary variants

## Open Questions the Paper Calls Out

- **Open Question 1**: How can knowledge boundary determination be improved beyond sampling-based approaches that may not capture the true parametric knowledge boundary across different prompting strategies?
  - Basis: Current sampling with lexical matching is acknowledged as imperfect with ~90% consistency with human evaluation

- **Open Question 2**: How effectively does DTA generalize to highly specialized domains (medical, legal, financial) beyond general open-domain QA?
  - Basis: PubMedQA experiments show distribution shift affects performance (Acc drops from 64.1 to 56.6)

- **Open Question 3**: What mechanisms can mitigate the trade-off between abstention capability and retrieval handling (DR/CUR) when enhancing model honesty?
  - Basis: DTA improves AF1 but reduces DR and CUR compared to baselines

## Limitations

- Boundary estimation relies on imperfect methods (lexical matching, GPT-4o evaluation) whose error rates are not fully characterized
- Performance depends on carefully tuned hyperparameters that may not generalize across different domains or model architectures
- The approach increases computational cost through GPT-4o API calls and more complex training objectives

## Confidence

- **High Confidence**: Experimental results showing DTA outperforming baselines on combined metrics are well-supported
- **Medium Confidence**: Theoretical framing of knowledge boundaries is sound but practical implementation relies on imperfect estimators
- **Medium Confidence**: Specific hyperparameter choices appear effective but optimality and transferability are uncertain

## Next Checks

1. **Boundary Estimator Reliability Test**: Replicate KBparam and KBr labeling on held-out test data with manual annotations to quantify labeling error rates

2. **Cross-Domain Generalization**: Apply DTA to biomedical or legal documents to evaluate whether the quadrant-based approach transfers beyond Wikipedia-based QA

3. **Cost-Benefit Analysis**: Measure computational cost of DTA approach relative to performance gains and explore lighter-weight boundary estimators