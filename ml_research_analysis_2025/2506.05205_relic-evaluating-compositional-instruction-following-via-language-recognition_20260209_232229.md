---
ver: rpa2
title: 'RELIC: Evaluating Compositional Instruction Following via Language Recognition'
arxiv_id: '2506.05205'
source_url: https://arxiv.org/abs/2506.05205
tags:
- grammar
- rule-based
- gpt-4
- example
- string
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RELIC introduces a synthetic framework for evaluating compositional
  instruction following using context-free grammar recognition. Models must determine
  whether strings are derivable from grammars without examples or fine-tuning.
---

# RELIC: Evaluating Compositional Instruction Following via Language Recognition

## Quick Facts
- arXiv ID: 2506.05205
- Source URL: https://arxiv.org/abs/2506.05205
- Reference count: 40
- Models show near-chance accuracy on complex grammars despite strong performance on simpler ones

## Executive Summary
RELIC introduces a synthetic framework for evaluating compositional instruction following using context-free grammar recognition. The framework generates controllable grammars and evaluation strings to test whether models can determine if strings are derivable without examples or fine-tuning. Despite the apparent simplicity of the task, even state-of-the-art models like GPT-4.1, o3/o4-mini, Gemma 3, and DeepSeek-R1 perform near-chance on complex grammars. The work provides both empirical evidence of performance degradation with complexity and theoretical arguments about transformer limitations for in-context CFG recognition.

## Method Summary
The RELIC framework generates synthetic CFGs in Chomsky Normal Form with controllable complexity parameters. For each grammar, positive examples are sampled via uniform PCFG derivation while negative examples are generated through unigram sampling with rejection of accidentally parseable strings. Models are evaluated in zero-shot setting with prompts containing only the grammar rules and target string. Performance is measured using class-balanced accuracy and macro F1, analyzed as functions of grammar complexity (number of non-lexical productions) and string length. The framework provides both empirical results and theoretical analysis of transformer limitations for in-context CFG recognition.

## Key Results
- Model accuracy degrades predictably with both grammar complexity and string length, following a log-linear relationship
- Even top models (GPT-4.1, o3/o4-mini, Gemma 3, DeepSeek-R1) achieve near-chance accuracy on complex grammars
- Qualitative analysis reveals models abandon correct rule-based strategies in favor of shallow heuristics as task difficulty increases
- Theoretical analysis suggests in-context CFG recognition is beyond standard transformer capabilities without substantial test-time compute

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task complexity is a primary driver of model performance degradation.
- Mechanism: The RELIC framework generates grammars and evaluation strings with controllable complexity. Model accuracy is predicted by two main factors: the number of grammar rules (instruction set complexity) and the length of the string to be evaluated (task complexity). As these variables increase, the compositional reasoning required appears to exceed the model's capabilities, leading to a predictable drop in performance.
- Core assumption: A model's ability to follow instructions degrades log-linearly as the number of rules it must compose increases.
- Evidence anchors:
  - [abstract] "...accuracy can be reliably predicted from the complexity of the grammar and the individual example strings."
  - [section 5.2] "...performance on RELIC-500 decreases as a function of a grammar's complexity... and as example length ℓ increases."
  - [corpus] This focus on complexity aligns with other work. For example, the LexInstructEval benchmark evaluates fine-grained lexical instruction following, and LIFEBench finds that LLMs struggle with following explicit length instructions, suggesting performance on simple-seeming constraints can be surprisingly poor, a finding consistent with the difficulty of compositional tasks. The paper "When Thinking Fails" also notes that reasoning can negatively impact instruction following.

### Mechanism 2
- Claim: Models abandon correct multi-step strategies in favor of shallow heuristics as task difficulty increases.
- Mechanism: On simpler tasks, models can successfully implement a rule-based strategy, such as building a parse tree. However, analysis of chain-of-thought reasoning shows that as task complexity grows, models switch to relying on heuristics (e.g., checking for the presence of certain symbols) instead of completing the full derivation, leading to errors.
- Core assumption: The chain-of-thought generated by the model is a faithful representation of its internal reasoning process.
- Evidence anchors:
  - [abstract] "Qualitative analysis of model reasoning reveals reliance on shallow heuristics for difficult cases, while correct strategies are often abandoned."
  - [section 6.1] Describes an example where DSR1 identifies a correct strategy but then backtracks to using string length as a heuristic, leading to an incorrect conclusion.
  - [corpus] The provided corpus does not offer detailed evidence on this specific mechanism of strategy-switching.

### Mechanism 3
- Claim: In-context CFG recognition is theoretically beyond standard transformer capabilities without sufficient test-time compute.
- Mechanism: The paper posits that in-context CFG recognition falls into complexity classes likely beyond standard fixed-depth transformers. While chain-of-thought (CoT) could theoretically allow a solution, it would require the number of CoT tokens to grow polynomially (e.g., cubically) with input length. Empirically, models do not generate sufficient CoT tokens for complex inputs, leading to failure.
- Core assumption: The theoretical complexity of the task as formulated maps to the practical limitations of current transformer LLMs.
- Evidence anchors:
  - [abstract] "Theoretical results suggest that in-context CFG recognition is beyond standard transformer capabilities without substantial test-time compute, which models fail to exhibit on complex inputs."
  - [section 7.3] "Thus, under standard complexity conjectures, fixed-depth transformers cannot solve the in-context recognition task for general CFGs without using CoT."
  - [corpus] Corpus papers do not address this theoretical mechanism.

## Foundational Learning

- Concept: **Context-Free Grammars (CFGs) and Chomsky Normal Form (CNF)**
  - Why needed here: RELIC generates task instances using CFGs in CNF. Understanding how a string is derived from a grammar via production rules is essential to grasp what the model is being asked to do.
  - Quick check question: Given a simple CNF grammar `S -> A B`, `A -> 'a'`, `B -> 'b'`, can you show the derivation for the string "a b"?

- Concept: **Chain-of-Thought (CoT) and Test-Time Compute**
  - Why needed here: The paper's theoretical argument hinges on the ability of CoT to expand the computational power of transformers. The analysis also investigates if models use CoT tokens correctly as task complexity scales.
  - Quick check question: Explain how generating more intermediate tokens (CoT) could allow a model to solve a problem that is more computationally complex than a single forward pass would allow.

- Concept: **Heuristic vs. Rule-Based Reasoning**
  - Why needed here: A core finding is that models switch from correct rule-based parsing to incorrect heuristics. Distinguishing between a full derivation and a shortcut based on surface-level features is critical for interpreting model behavior.
  - Quick check question: A model rejects a string because it doesn't contain a symbol that isn't even in the grammar's rules. Is this an example of rule-based or heuristic reasoning?

## Architecture Onboarding

- Component map:
    1.  **Grammar Generator:** A stochastic process (adapted from Clark, 2017) that creates CFGs with controllable numbers of terminals, non-terminals, and production rules. It produces grammars in Chomsky Normal Form.
    2.  **Example Sampler:** For each grammar, this component generates positive strings by sampling from the grammar (treated as a PCFG) and negative strings by sampling from a unigram model over the terminal vocabulary, rejecting any that are accidentally parseable.
    3.  **Prompting Interface:** A zero-shot prompt constructor that presents the grammar rules and a candidate string, instructing the model to classify it without examples.
    4.  **Evaluator:** Parses the model's response to classify it as 'Yes', 'No', or 'unknown'.

- Critical path: The robustness of the evaluation depends on the Grammar Generator's ability to create instances of precise difficulty and the Example Sampler's ability to create negative samples that are not trivially distinguishable. The analysis of model reasoning then depends on interpreting the chain-of-thought output.

- Design tradeoffs:
    *   **Synthetic vs. Natural Language:** RELIC uses synthetic grammars to ensure controllability and avoid data contamination, but this sacrifices the nuance and ambiguity of natural language instructions.
    *   **Negative Sampling:** Sampling negatives from a unigram model is simple but may create statistical differences from positive samples, which a heuristic-based model could exploit. The paper notes this as a limitation, suggesting future work on more adversarial negative sampling.

- Failure signatures:
    *   Models exhibit a strong bias towards predicting one class (positive or negative), especially as example length increases.
    *   Test-time compute (CoT length) peaks early and then *decreases* for longer, more complex inputs, indicating the model has given up on a systematic strategy.
    *   Reasoning traces show the model abandoning a correct strategy mid-process.

- First 3 experiments:
    1.  **Baseline & Scaling:** Evaluate a set of LLMs (e.g., from the GPT family) on the released RELIC-500 benchmark to establish the baseline relationship between model size/architecture and performance on grammars of varying complexity.
    2.  **Ablation on Grammar Properties:** Generate controlled sets of grammars where only one parameter (e.g., number of non-lexical productions) is varied. Evaluate models to isolate the impact of each parameter on performance and test the log-linear degradation claim.
    3.  **Qualitative Analysis of Reasoning:** Manually inspect chain-of-thought outputs for a subset of examples (both correct and incorrect) across different complexity levels. Categorize the strategies used (rule-based vs. heuristic) to validate the finding that models switch strategies as difficulty increases.

## Open Questions the Paper Calls Out

- **Can models maintain above-chance performance if negative examples are sampled adversarially to minimize statistical differences from positive examples?**
  - The authors state that negative samples may contain "statistical differences" enabling heuristics, and propose exploring "more adversarial negative sampling methods" as future work.

- **Does enforcing a minimum chain-of-thought (CoT) length that scales with input complexity force models to apply correct parsing strategies rather than abandoning them?**
  - Section 7.3 notes that correct parsing theoretically requires CoT lengths to grow substantially (roughly cubically), but models actually generate fewer tokens for longer inputs.

- **How does model performance degrade when extending the RELIC framework to context-sensitive grammars (CSGs) or grammars with ε productions?**
  - Section 7.4 lists "generalizing to probabilistic CFGs or context-sensitive grammars" and including "CFGs with ε productions" as natural extensions of the framework.

## Limitations
- External validity of synthetic grammars as proxies for real-world compositional instruction following remains unproven
- Negative sampling approach may create artificial signal through distributional differences rather than genuine grammatical understanding
- Theoretical complexity argument makes strong assumptions about how transformers process information

## Confidence

**High confidence** in the empirical finding that model performance degrades predictably with grammar complexity and string length. The controlled synthetic setting and systematic variation of parameters provide strong evidence for this relationship.

**Medium confidence** in the mechanism that models abandon correct strategies for heuristics. While qualitative analysis supports this claim, the chain-of-thought interpretation relies on assumptions about faithfulness of reasoning traces that are difficult to verify conclusively.

**Low confidence** in the theoretical argument about transformer limitations for CFG recognition. The complexity analysis makes strong assumptions about how transformers process information, and the connection between worst-case complexity bounds and practical performance remains speculative.

## Next Checks

1. Evaluate models on RELIC grammars with adversarial negative sampling that matches the statistical distribution of positive examples to test whether models rely on distributional heuristics.

2. Test whether providing explicit chain-of-thought scaffolding (e.g., "First, identify all non-terminals that can generate substrings of length 1...") improves performance on complex grammars, validating the test-time compute hypothesis.

3. Compare RELIC performance to models' ability on natural language compositional tasks with similar logical structure but different surface form to assess external validity of the synthetic benchmark.