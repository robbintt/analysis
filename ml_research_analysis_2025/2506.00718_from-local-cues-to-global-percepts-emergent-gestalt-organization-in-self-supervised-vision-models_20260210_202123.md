---
ver: rpa2
title: 'From Local Cues to Global Percepts: Emergent Gestalt Organization in Self-Supervised
  Vision Models'
arxiv_id: '2506.00718'
source_url: https://arxiv.org/abs/2506.00718
tags:
- figure
- global
- disrt
- image
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether modern deep vision models exhibit
  Gestalt-like perception, where local visual cues are integrated into coherent global
  structures. The authors show that Vision Transformers trained with Masked Autoencoding
  (MAE) display internal activation patterns aligned with Gestalt principles such
  as closure, convexity preference, and figure-ground segregation.
---

# From Local Cues to Global Percepts: Emergent Gestalt Organization in Self-Supervised Vision Models

## Quick Facts
- arXiv ID: 2506.00718
- Source URL: https://arxiv.org/abs/2506.00718
- Reference count: 40
- Models trained with Masked Autoencoding (MAE) exhibit Gestalt-like perception and outperform supervised models on global structure tasks

## Executive Summary
This paper investigates whether modern deep vision models exhibit Gestalt-like perception, where local visual cues are integrated into coherent global structures. The authors show that Vision Transformers trained with Masked Autoencoding (MAE) display internal activation patterns aligned with Gestalt principles such as closure, convexity preference, and figure-ground segregation. To evaluate global spatial sensitivity systematically, they introduce DiSRT, a benchmark that tests a model's ability to detect distortions in global spatial relationships while preserving local textures. Results show that self-supervised models (MAE, CLIP) outperform supervised baselines and even exceed human performance on DiSRT.

## Method Summary
The paper introduces the DiSRT (Distortion in Spatial Relationship Task) benchmark, which tests a model's ability to detect spatial distortions in images where local textures are preserved but global relationships are altered. The benchmark uses texture synthesis to create three images where two share the same global spatial arrangement while one is distorted. Models must identify the odd image out based on global structure rather than local texture. The authors evaluate multiple architectures including ViT, ConvNeXt, and MAE-trained variants, analyzing both quantitative DiSRT performance and qualitative activation patterns for Gestalt phenomena like Kanizsa figures and convexity preferences.

## Key Results
- Self-supervised models (MAE, CLIP) outperform supervised baselines on DiSRT, with MAE showing superior performance across architectures
- ConvNeXt models trained with MAE exhibit Gestalt-compatible representations, demonstrating global sensitivity is not exclusive to transformer architectures
- Classification finetuning substantially degrades DiSRT performance, particularly in deeper layers
- Top-K activation sparsity can partially restore global sensitivity in classification-finetuned models, improving DiSRT scores from ~70 to ~95

## Why This Works (Mechanism)

### Mechanism 1
MAE training objectives preserve global structure sensitivity across network layers because masked autoencoding requires models to infer missing image regions from visible context. This reconstruction pressure forces intermediate layers to maintain global spatial relationship information throughout the forward pass, as the task cannot be solved using local texture cues alone.

### Mechanism 2
Top-K activation sparsity may partially recover global sensitivity in classification-finetuned models by eliminating weakly activated neurons that encode task-irrelevant information. By retaining only the top K% of activations per channel and zeroing the rest, this mechanism appears to suppress noise and redundant feature responses that may have accumulated during classification training.

### Mechanism 3
Classification finetuning degrades global spatial sensitivity because the discriminative objective incentivizes shortcut learning based on local texture features. Classification tasks can often be solved by detecting diagnostic local features without requiring global structure understanding, progressively overwriting or attenuating global structure representations in deeper layers.

## Foundational Learning

- **Gestalt Principles of Perception**: Why needed - to understand evaluation criteria for perceptual organization. Quick check - Can you explain why perceiving a Kanizsa triangle requires integrating information across spatially separated edge cues?

- **Masked Autoencoding (MAE) Training Objective**: Why needed - the central claim is that MAE training promotes global structure sensitivity. Quick check - How does masking ~75% of image patches create pressure for global context modeling?

- **Principal Component Analysis (PCA) for Activation Visualization**: Why needed - the paper uses PCA projections of internal activations to visualize figure-ground separation and Gestalt compliance. Quick check - Why does a consistent PCA basis across images allow comparison of figure-ground assignments?

## Architecture Onboarding

- **Component map**: Texture synthesis module → distorted image generator → oddity detection task → cosine distance metric → accuracy scoring
- **Critical path**: Generate spatial-distortion images using Gram matrix matching → extract representations from target layer → compute pairwise cosine distances → compare accuracy against human baseline
- **Design tradeoffs**: 10 steps (fast but approximate) vs. 100 steps (accurate but ~55s/image on V100) for texture synthesis; final layer vs. intermediate layers for evaluation; layer-specific vs. uniform Top-K sparsity thresholds
- **Failure signatures**: DiSRT accuracy at chance (~33%) indicates reliance on local texture only; sharp accuracy drop in later layers indicates supervised finetuning has overwritten global representations; Top-K providing no improvement suggests global information was not preserved in weights
- **First 3 experiments**: 1) Replicate DiSRT evaluation on pretrained ViT-MAE vs supervised ViT; 2) Visualize layer-wise DiSRT scores to identify degradation point; 3) Apply Top-K sparsity to classification-finetuned ConvNeXt and measure DiSRT score recovery

## Open Questions the Paper Calls Out

### Open Question 1
Why does combining mask image modeling (MIM) with contrastive learning (as in DINOv2) hinder global structural awareness, whereas applying them separately yields superior results? The authors state in the supplementary material that one investigation direction is to see why combining these approaches hinders performance while applying them separately produces superior results.

### Open Question 2
Why do models trained with supervised learning capture global structural information in early layers but subsequently discard it in deeper layers? Regarding the drop in DiSRT score in deeper layers of supervised models, the authors note it ponders the question of why the information was once captured but later on was 'given-up' in the bottom-up process.

### Open Question 3
Is the observed relationship between global structure sensitivity (measured by DiSRT) and Gestalt-like perception causal or merely correlational? The authors state in the discussion that while their study establishes a link between global structure sensitivity and Gestalt-like behaviors, it remains correlational rather than causal.

## Limitations
- DiSRT benchmark uses synthetic texture-distorted images that may not fully capture real-world Gestalt perception complexity
- Top-K sparsity mechanism requires layer-specific hyperparameter tuning, raising practical applicability concerns
- Classification finetuning degradation pattern doesn't explore alternative finetuning strategies that might preserve global sensitivity

## Confidence
- **High Confidence**: MAE training promotes global structure sensitivity (consistent DiSRT improvements across architectures)
- **Medium Confidence**: Top-K sparsity can restore global sensitivity in classification-finetuned models (mechanism plausible but requires careful tuning)
- **Medium Confidence**: Supervised classification objectives inherently degrade global spatial representations (strong evidence but limited exploration of alternatives)

## Next Checks
1. Apply DiSRT methodology to natural images with embedded Gestalt illusions to verify synthetic texture distortion correlates with natural Gestalt perception
2. Test DiSRT performance across additional architectures (Swin Transformers, MLPs) trained with MAE to determine architecture-agnostic emergence
3. Evaluate models trained with contrastive objectives (MoCo, SimCLR) or self-prediction tasks on DiSRT to determine if MAE's reconstruction objective is uniquely effective