---
ver: rpa2
title: Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE
arxiv_id: '2506.11673'
source_url: https://arxiv.org/abs/2506.11673
tags:
- inlp
- leace
- information
- target
- amnesic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the effectiveness of different information
  removal techniques in Amnesic Probing, a method for analyzing causal relationships
  between linguistic properties and model behavior. The study compares Iterative Nullspace
  Projection (INLP) against Mean Projection (MP) and LEACE on three linguistic properties
  (dependency, fine-grained part-of-speech, and coarse-grained part-of-speech).
---

# Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE

## Quick Facts
- arXiv ID: 2506.11673
- Source URL: https://arxiv.org/abs/2506.11673
- Authors: Alicja Dobrzeniecka; Antske Fokkens; Pia Sommerauer
- Reference count: 16
- Primary result: Mean Projection and LEACE outperform Iterative Nullspace Projection in Amnesic Probing by removing target information more precisely with less collateral damage to embedding space.

## Executive Summary
This paper investigates the effectiveness of different information removal techniques in Amnesic Probing, a method for analyzing causal relationships between linguistic properties and model behavior. The study compares Iterative Nullspace Projection (INLP) against Mean Projection (MP) and LEACE on three linguistic properties (dependency, fine-grained part-of-speech, and coarse-grained part-of-speech). Results show that MP and LEACE remove target information more precisely than INLP, causing less distortion to the embedding space while achieving comparable or better removal of the target property. In information control tests, MP and LEACE showed smaller drops in performance compared to random projections, while INLP showed larger drops. In selectivity control tests, MP and LEACE recovered performance closer to original levels when gold labels were added. These findings demonstrate that MP and LEACE are superior alternatives to INLP for Amnesic Probing applications.

## Method Summary
The paper compares three linear projection methods for removing target linguistic properties from neural embeddings in Amnesic Probing. INLP iteratively trains SVM classifiers and removes learned directions (n=20 iterations, resulting in 779-765 total projections). MP computes class mean differences (wi = ui - ur) and applies single orthogonal projection (41-45 directions). LEACE uses a closed-form projection derived from Belrose et al. (2024). The methods are evaluated on BERT embeddings from Universal Dependencies English data for dependency, fine-grained part-of-speech, and coarse-grained part-of-speech properties. Removal effectiveness is verified by probing classifier accuracy dropping to majority baseline, while control tests assess information relevance and selectivity.

## Key Results
- MP and LEACE remove target information more precisely than INLP, causing less distortion to the embedding space while achieving comparable or better removal of the target property
- In information control tests, MP and LEACE showed smaller drops in performance compared to random projections, while INLP showed larger drops
- In selectivity control tests, MP and LEACE recovered performance closer to original levels when gold labels were added, indicating less collateral damage to non-target information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear projection methods can remove target linguistic properties from neural embeddings by projecting representations into subspaces where the property becomes linearly inseparable.
- Mechanism: Each method identifies directions encoding target information, then applies orthogonal projection to the nullspace of those directions. MP computes w_i = u_i - u_r (class mean minus remaining-class mean) for each target class; LEACE derives a closed-form projection; INLP iteratively trains SVM classifiers and removes learned directions.
- Core assumption: Target linguistic properties are linearly encoded in the embedding space and can be captured by specific geometric directions.
- Evidence anchors:
  - [abstract]: "Amnesic probing is a technique used to examine the influence of specific linguistic information on the behaviour of a model. This involves identifying and removing the relevant information."
  - [section 2.2]: "MP requires only one projection per class and the number of directions to be removed is stable and equal to the number of target classes."
  - [corpus]: "Slowing Learning by Erasing Simple Features" (arXiv:2502.02820) derives QLEACE, a closed-form quadratic erasure method, supporting the broader validity of linear concept removal.
- Break condition: If target information is encoded nonlinearly or entangled with other properties in ways not captured by linear subspaces.

### Mechanism 2
- Claim: Single-projection methods (MP, LEACE) cause less collateral distortion than iterative methods because fewer projections preserve more of the original embedding geometry.
- Mechanism: INLP applies projections iteratively (n=20 iterations in Elazar et al. 2021), which can require hundreds of total projections (779 for dependency, 765 for f-pos). MP and LEACE use exactly C projections (C = number of classes). Fewer projections means lower rank reduction and higher cosine similarity between original and modified embeddings.
- Core assumption: Each projection introduces some unintended modification; cumulative modifications scale with projection count.
- Evidence anchors:
  - [abstract]: "It has been shown that Iterative Nullspace Projection (INLP)...introduces random modifications to representations when eliminating target information."
  - [Table 12]: INLP reduces matrix rank by 617-629 vs. MP reducing by 12-16; cosine similarity after INLP is 0.31-0.37 vs. 0.80-0.91 for MP.
  - [corpus]: Weak/no direct corpus evidence comparing iteration counts across methods.
- Break condition: If class distributions overlap substantially such that single projections cannot fully remove target separability.

### Mechanism 3
- Claim: Control tests (information control and selectivity control) distinguish genuine causal attribution from artifact-induced performance changes.
- Mechanism: Information control compares target removal against random projection baseline; if target is causally relevant, its removal should hurt more. Selectivity control adds gold labels back; if only target was removed, performance should recover.
- Core assumption: The removal method itself does not independently degrade the main task beyond target information removal.
- Evidence anchors:
  - [section 3, Step 2]: "When INLP is used to remove dependencies or f-pos, more damage is done by applying the same amount of random projections in our experiments. This check shows that we cannot establish a causal link."
  - [Table 4]: Gold label addition restores accuracy to 95-96% for MP/LEACE vs. 87-96% for INLP, indicating INLP removed additional useful information.
  - [corpus]: "How Reliable are Causal Probing Interventions?" (arXiv:2408.15510) questions theoretical bases of causal probing methods—reliability remains actively debated.
- Break condition: If the removal method introduces artifacts that independently affect the main task (observed with INLP).

## Foundational Learning

- Concept: Orthogonal Projection and Nullspace
  - Why needed here: All three methods project embeddings into nullspaces where target information becomes linearly inseparable. Understanding projection geometry is essential for interpreting results.
  - Quick check question: Given a direction vector w, can you compute the projection matrix P that removes variation along w while preserving orthogonal directions?

- Concept: Linear Separability and Probing Classifiers
  - Why needed here: Removal success is measured by probing classifier accuracy dropping toward majority baseline. Paper uses linear classifiers as proxies for information presence.
  - Quick check question: If a linear classifier achieves 90% on a 12-class problem (random baseline ~8%), what does accuracy dropping to 26% after projection indicate?

- Concept: Causal Intervention vs. Correlation in Model Analysis
  - Why needed here: Amnesic probing aims to establish causal relationships through intervention (removal), not just correlational probing. High probing accuracy alone doesn't prove causal use.
  - Quick check question: Why does high probing accuracy for a property not prove the model causally depends on that information?

## Architecture Onboarding

- Component map:
  - Embedding extraction (BERT layers, 768-dim) -> Projection matrix computation (varies: class means for MP, iterative SVM for INLP, closed-form for LEACE) -> Intervention application (matrix multiplication) -> Probing classifier (linear, verifies removal) -> Main task evaluator (LM accuracy, D_KL divergence) -> Control test suite (random baseline, gold label restoration)

- Critical path:
  1. Extract embeddings -> 2. Verify target is probeable (>75% accuracy) -> 3. Compute projection matrix -> 4. Apply projection -> 5. Verify removal (accuracy ≈ majority baseline) -> 6. Run main task -> 7. Compare vs. random projection baseline -> 8. Test gold label recovery

- Design tradeoffs:
  - MP: Simple, efficient (one projection per class), heuristic; sensitive to outliers affecting class means
  - LEACE: Theoretically grounded (proves complete linear erasure), more computationally intensive
  - INLP: Established baseline but high iteration counts (240-779 projections) cause substantial collateral damage
  - Recommendation: Start with MP for efficiency; validate with LEACE if control tests indicate issues

- Failure signatures:
  - Information control failure: Random projections cause more damage than target removal (INLP on dep/f-pos)
  - Low cosine similarity (INLP: 0.31-0.37 vs. MP: 0.80-0.91) indicates excessive space distortion
  - Large rank reduction (INLP: 617-629 vs. MP: 12-16) signals information loss beyond target
  - Gold label restoration fails to recover performance (indicates non-target damage)

- First 3 experiments:
  1. Reproduce vanilla probing: Extract BERT embeddings, train linear classifier on dependency labels, confirm >75% accuracy before intervention.
  2. Apply MP intervention: Compute class means, derive single projection, apply to embeddings; verify probing accuracy drops near majority baseline while cosine similarity remains >0.80.
  3. Run information control: Compare LM performance after MP vs. same number (41) of random projections; target removal should show larger drop if causally relevant.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can outlier detection and removal methods improve MP's robustness when class distributions contain extreme values?
- Basis in paper: [explicit] The authors state MP is "sensitive to outliers, as the mean of a class can be affected significantly by extreme values" and suggest "this limitation is manageable and can potentially be addressed by outlier detection methods."
- Why unresolved: The paper identifies this vulnerability but does not implement or test any outlier handling techniques.
- What evidence would resolve it: Experiments comparing MP performance with and without outlier preprocessing (e.g., using IQR-based filtering or robust estimators) across properties with varying class imbalance.

### Open Question 2
- Question: Do MP and LEACE maintain their superiority over INLP on non-syntactic linguistic properties (e.g., named entities, phrase boundaries)?
- Basis in paper: [explicit] The authors note "the experiments carried out in this paper included only a limited set of linguistic properties" and could not test on NER, phrase start, and phrase end due to unavailable data.
- Why unresolved: The original Elazar et al. (2021) paper found INLP did not yield clear results for these properties, but MP and LEACE were not evaluated on them.
- What evidence would resolve it: Running the same amnesic probing framework with MP and LEACE on NER and phrase structure tasks using compatible datasets.

### Open Question 3
- Question: How well do MP and LEACE generalize to other model architectures beyond BERT?
- Basis in paper: [inferred] The paper acknowledges "limited scope" and that "the method behaves differently on other properties or models" remains possible. Experiments were conducted only on masked and unmasked BERT variants.
- Why unresolved: Different architectures encode linguistic information differently; results may not transfer to models with different attention mechanisms, layer structures, or training objectives.
- What evidence would resolve it: Systematic comparison across diverse architectures (e.g., GPT-style, RoBERTa, multilingual models) using the same probing framework.

## Limitations

- Limited evaluation to English UD data only, which may not represent the full diversity of linguistic phenomena or languages
- Reliance on linear classifiers as probes assumes that linear separability adequately captures information presence, which may not hold for all linguistic properties
- No testing on non-linear probing methods or information removal techniques

## Confidence

- High confidence: MP and LEACE cause less embedding space distortion than INLP (supported by cosine similarity and rank reduction metrics)
- Medium confidence: MP and LEACE achieve comparable or better target removal effectiveness (consistent across all three properties)
- Medium confidence: Control test interpretations (artifact detection relies on specific experimental setup assumptions)

## Next Checks

1. Test the methods on non-English UD datasets to assess cross-linguistic generalization
2. Compare with non-linear probing classifiers to verify that linear separability assumptions hold
3. Conduct ablation studies varying random seeds and initialization to assess stability of iteration counts and performance metrics