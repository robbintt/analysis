---
ver: rpa2
title: 'CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation
  with Smart Meter Data'
arxiv_id: '2601.10494'
source_url: https://arxiv.org/abs/2601.10494
tags:
- consumer
- clustering
- consumers
- data
- crocs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CROCS is a two-stage clustering framework for segmenting electricity
  consumers based on smart meter data. It addresses limitations in existing methods
  such as inadequate intra-consumer variability representation, rigid temporal alignment,
  sensitivity to anomalies, and poor scalability.
---

# CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation with Smart Meter Data

## Quick Facts
- arXiv ID: 2601.10494
- Source URL: https://arxiv.org/abs/2601.10494
- Reference count: 40
- Primary result: Framework outperforms existing methods in capturing asynchronous consumer similarity, handling outliers, and scaling to large datasets

## Executive Summary
CROCS addresses limitations in existing consumer segmentation methods by implementing a two-stage clustering framework that captures both intra-consumer behavioral diversity and inter-consumer behavioral similarities. The framework first constructs Representative Load Sets (RLS) for each consumer by clustering their daily load profiles, then clusters consumers based on these RLS using a novel Weighted Sum of Minimum Distances (WSMD) measure. Experiments demonstrate superior performance in recovering ground-truth clusters, handling outlier contamination, and identifying both synchronous and asynchronous behavioral similarities in real-world smart meter data.

## Method Summary
CROCS processes half-hourly smart meter data by first extracting and min-max normalizing daily load profiles (DLPs) for each consumer. In Stage 1, each consumer's DLPs are clustered using DTW-2 distance with k-medoids or HAC-Ward to create an RLS of medoid prototypes. Stage 2 computes pairwise WSMD distances between all consumer RLSs, then clusters consumers using HAC-Ward or k-medoids on the resulting distance matrix. An optional Refined RLS (RRLS) stage applies Leiden community detection to identify shared behavioral modes within clusters. The framework deliberately overestimates k in Stage 1 to ensure behavioral diversity coverage.

## Key Results
- Outperformed existing methods in synthetic data experiments with up to 0.999 Adjusted Rand Index
- Demonstrated robustness to outlier contamination up to 50% without significant performance degradation
- Identified ~7.7% of consumer pairs with similar behavioral distributions but low temporal alignment, versus only 0.6% with high alignment
- Achieved equivalent reconstruction quality to global clustering methods while enabling natural parallelization

## Why This Works (Mechanism)

### Mechanism 1
Overestimating k uniformly across all consumers preserves behavioral diversity without requiring per-consumer optimization. The WSMD distance weights prototypes by cluster membership size, so split behavioral modes collectively receive similar total weight as single clusters would. Core assumption: consumers exhibit a bounded number of distinct behavioral modes. Break condition: if outliers dominate a consumer's DLP distribution (>80%), the RLS may contain primarily anomalous prototypes.

### Mechanism 2
WSMD set-to-set distance enables detection of consumers with similar behavioral patterns expressed on different calendar days (asynchronous similarity). By comparing prototype sets rather than temporally-aligned sequences, WSMD evaluates behavioral overlap independent of when patterns occur. Core assumption: behavioral similarity for DSM/DR applications depends on pattern repertoire and prevalence, not temporal coincidence. Break condition: if two consumers share patterns with identical shapes but inverted temporal sequencing, downstream DR programs requiring synchronized load reduction may not benefit.

### Mechanism 3
Local RLS representations provide better reconstruction of intra-consumer variability than global representations (GPF) at equivalent or lower computational cost. Each consumer's RLS is computed independently (O(p²) per consumer, parallelizable), while GPF requires joint clustering of all consumer DLPs (O(m²p²)). Core assumption: consumer-specific patterns may not appear in global cluster centers. Break condition: if consumers share nearly identical behavioral patterns, local RLS computation wastes resources where global prototypes would suffice.

## Foundational Learning

- **Hierarchical vs. Partitional Clustering Tradeoffs**: CROCS can use either HAC-Wa or k-medoids in both stages; understanding their differences (determinism, complexity, cluster shape assumptions) affects practical deployment. Quick check: For a dataset with unknown cluster structure and need for reproducibility, which algorithm properties would you prioritize?

- **Time Series Distance Measures (Euclidean vs. DTW)**: The paper uses DTW with a 1-hour warping window to handle temporal misalignment within daily profiles, while ED is used for reconstruction error evaluation. Quick check: Why would DTW be preferred over Euclidean distance when clustering daily load profiles from households with varying peak times?

- **External Validity Indices (ARI, AMI, PSI)**: Synthetic data experiments rely on these metrics to measure cluster recovery; understanding their complementarity prevents over-reliance on any single metric. Quick check: If ARI is high but PSI is low for a clustering result, what might this indicate about the recovered partition structure?

## Architecture Onboarding

- **Component map**: DLP extraction -> Min-max normalization -> DTW-2 distance matrix -> HAC-Wa or KMd clustering -> Medoid extraction -> RLS output -> WSMD distance computation -> Distance matrix -> Clustering algorithm -> Consumer partition -> (Optional) Prototype graph -> Community detection -> Hyperprototype extraction

- **Critical path**: 1) DLP extraction and normalization (determines all downstream quality) 2) Stage 1 clustering algorithm selection and k parameter (controls RLS fidelity) 3) WSMD implementation (core innovation; must correctly weight by n_a^i cluster sizes) 4) Stage 2 clustering (produces final segmentation)

- **Design tradeoffs**: Higher k improves behavioral coverage but increases O(k²m²) stage-2 complexity; HAC-Wa is deterministic and faster for fixed k while KMd provides medoids directly; medoid prototypes are more robust to outliers than means; min-max normalization preserves relative amplitude within profiles.

- **Failure signatures**: Excessive empty clusters in RLS indicates k too high for sparse DLP data; consumer clusters with no dominant hyperprototypes suggests community detection resolution parameter too high; WSMD distances all similar indicates RLS prototypes not discriminative; quadratic memory failure in Stage 2 suggests m too large.

- **First 3 experiments**: 1) Validate Stage 1 k-sensitivity by running CROCS with k ∈ {5, 10, 15, 20, 25} and plotting ARI vs. k on held-out synthetic data. 2) Compare WSMD to baseline set distances (Hausdorff, SMD, average linkage) on synthetic data with n_O ∈ {0, 20, 40} outliers. 3) Profile computational scaling by timing Stage 1 and Stage 2 separately for m ∈ {1000, 5000, 10000} consumers with p=90 days.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can RRLS computation be optimized to scale more efficiently with large consumer populations without sacrificing behavioral interpretability? Based on Section 7.1, which identifies the community detection algorithm as less efficient than primary stages and suggests assessing trade-offs with lightweight alternatives.

- **Open Question 2**: Which data normalization procedures (z-normalization, unit-norm, or selective schemes) best preserve relevant information for different downstream applications within CROCS? Based on Section 7.1 noting little systematic understanding of when alternatives to min-max normalization are preferred.

- **Open Question 3**: Can CROCS be hybridized with time-series forecasting tasks to improve prediction accuracy for individual consumers or aggregate loads? Based on Section 7.1 proposing utilizing Stage 1 prototypes as "natural primitives for next-day prediction" and Stage 2 clusters for aggregate-level forecasting.

## Limitations

- Framework robustness to severe outlier contamination (>50% anomalous DLPs) remains partially untested
- Assumes half-hourly sampling; performance with coarser temporal resolution requires validation
- Computational complexity of RRLS extraction may limit scalability for populations >10,000 consumers

## Confidence

- **High Confidence**: Stage 1 RLS construction effectively captures intra-consumer variability; WSMD set-to-set distance enables asynchronous similarity detection; computational complexity analysis is sound
- **Medium Confidence**: Framework robustness to outlier contamination across all consumer types; scalability to populations >10,000 consumers; RRLS extraction consistently identifies meaningful behavioral modes
- **Low Confidence**: Performance with non-residential consumers; effectiveness when behavioral modes change seasonally; generalization to other time series domains

## Next Checks

1. **Outlier Stress Test**: Generate synthetic datasets with 0%, 25%, 50%, 75%, and 90% outliers per consumer. Measure ARI and reconstruction error to identify failure thresholds.

2. **Temporal Resolution Sensitivity**: Run CROCS on the same datasets with 1-hour vs. 30-minute sampling. Compare cluster recovery and computational requirements to validate temporal assumptions.

3. **Commercial Consumer Validation**: Apply CROCS to a mixed residential/commercial dataset. Compare segmentation quality and behavioral mode counts between consumer types to test framework generalizability.