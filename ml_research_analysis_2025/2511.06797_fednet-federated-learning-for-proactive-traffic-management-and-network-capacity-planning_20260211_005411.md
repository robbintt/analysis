---
ver: rpa2
title: 'FedNET: Federated Learning for Proactive Traffic Management and Network Capacity
  Planning'
arxiv_id: '2511.06797'
source_url: https://arxiv.org/abs/2511.06797
tags:
- traffic
- prediction
- network
- links
- link
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedNET addresses the problem of proactive traffic management in
  large-scale communication networks by leveraging federated learning to predict node-level
  traffic patterns and identify high-risk links without exposing sensitive network
  data. The core method uses a distributed LSTM model trained via FedAvg aggregation
  to forecast traffic over multiple time horizons, mapping node-level predictions
  to link-level utilization using routing information.
---

# FedNET: Federated Learning for Proactive Traffic Management and Network Capacity Planning

## Quick Facts
- arXiv ID: 2511.06797
- Source URL: https://arxiv.org/abs/2511.06797
- Reference count: 37
- Key outcome: FL achieves traffic prediction accuracy close to centralized training (R² >0.92 for short horizons, ~0.45-0.55 for 3-day forecasts) while preserving privacy

## Executive Summary
FedNET proposes a federated learning framework for proactive traffic management in optical networks, using distributed LSTM models trained via FedAvg to predict node-level traffic patterns and identify high-risk links. The system trains locally on each node's traffic data without exposing raw data, achieving accuracy comparable to centralized training while reducing communication overhead. Evaluation on a 9-node BRAIN topology shows strong performance for short prediction horizons (R² >0.92) and effective identification of high-utilization links through a Link Utilization Score that combines traffic intensity and variability.

## Method Summary
FedNET employs a 2-layer LSTM encoder-decoder architecture trained using FedAvg aggregation across network nodes. Each node preprocesses its traffic data through 6-hour averaging, IQR-based outlier removal, 28-sample moving average smoothing, and StandardScaler normalization. The model predicts p future time steps from h historical inputs, with predictions mapped to link-level utilization using shortest-path routing assumptions. Link Utilization Scores combine normalized mean traffic and standard deviation to rank high-risk links for proactive capacity planning.

## Key Results
- FL achieves R² scores exceeding 0.92 for short prediction horizons (1-4 time steps) comparable to centralized training
- Prediction accuracy remains around 0.45-0.55 for longer horizons up to 3 days (h=12,p=12)
- The framework consistently identifies high-risk links well in advance, with predicted and actual top-6 lists showing ≥4/6 overlap
- Model shows higher sensitivity to prediction window length than history window length

## Why This Works (Mechanism)

### Mechanism 1
Federated learning with FedAvg aggregation achieves traffic prediction accuracy comparable to centralized training while preserving data privacy and reducing communication overhead. Each network node trains a local LSTM model on its own traffic data, then transmits only model weights to a central server for weighted aggregation based on dataset size. This iterative process allows the global model to learn from distributed data without centralizing sensitive traffic patterns.

### Mechanism 2
Prediction accuracy degrades predictably with longer prediction horizons due to autoregressive error propagation, with the model more sensitive to prediction window length than history window length. The LSTM generates multi-step forecasts by predicting p future values from h historical inputs, where errors compound across time steps. Longer history windows provide more context but don't directly reduce the error accumulation in the forward prediction direction.

### Mechanism 3
Node-level traffic forecasts combined with routing information enable early identification of high-risk links through a Link Utilization Score that captures both predicted load intensity and temporal variability. For each source-destination pair, predicted traffic is distributed across routing paths, with link-level traffic computed by summing contributions from all traversing flows. LUS combines normalized mean traffic and standard deviation with weighting factor β=0.5 to rank links by composite risk score.

## Foundational Learning

- **Federated Learning with FedAvg**: Understanding weighted aggregation (α_k = |D_k|/N) is essential for debugging convergence and diagnosing client contribution imbalances
- **LSTM for Multi-Step Time Series Forecasting**: Understanding sequence-to-sequence prediction with history window h and prediction horizon p is critical for interpreting accuracy tradeoffs
- **Graph Topology and Link-Level Traffic Aggregation**: Understanding how flows aggregate on shared links is necessary to interpret LUS rankings

## Architecture Onboarding

- **Component map**: Central Server (SDN Orchestrator) -> Local Nodes (9 clients) -> LSTM Model -> Routing Module -> LUS Calculator
- **Critical path**: Data preprocessing → Global model distribution → Local training → Weight aggregation → Multi-step prediction → Link mapping → Risk ranking
- **Design tradeoffs**: History window vs accuracy (diminishing returns beyond h=4), prediction horizon vs utility (earlier warning vs lower accuracy), privacy vs routing precision (uniform splitting vs traffic matrices), communication rounds vs convergence (50 rounds used)
- **Failure signatures**: Model divergence (wild client R² variance), stale rankings (predicted vs actual link list divergence), convergence failure (plateauing global loss), temporal misalignment (aggregation sequence issues)
- **First 3 experiments**: Baseline replication with h=1,p=1; horizon sensitivity sweep (p ∈ {1,4,8,12}); link ranking validation for h=12,p=12

## Open Questions the Paper Calls Out

- **Traffic matrix incorporation**: How would actual source-destination traffic matrices affect link-level utilization prediction accuracy versus uniform distribution assumptions?
- **Fairness-aware aggregation**: What are the effects of fairness-aware schemes on prediction robustness across heterogeneous clients in larger network topologies?
- **LUS weighting strategies**: What alternative weighting strategies for the Link Utilization Score could better adapt to specific network conditions?
- **Real-time integration**: Can real-time integration with active traffic engineering controllers achieve proactive control without unacceptable latency?

## Limitations

- Architecture underspecification: LSTM hidden layer dimensions and RepeatVector configuration not provided
- Routing assumption validity: Uniform traffic splitting may not reflect actual network conditions
- Dataset accessibility: Specific SNDlib BRAIN topology and traffic matrices require particular version access

## Confidence

- **High confidence**: FedAvg aggregation achieves accuracy close to centralized training (R² comparisons in Table I)
- **Medium confidence**: Multi-step prediction accuracy degrades with horizon due to error propagation (consistent pattern across all (h,p) combinations in Table II)
- **Medium confidence**: Link utilization ranking effectively identifies high-risk links (Table III shows strong alignment between predicted and actual top-6 lists)

## Next Checks

1. **Architecture sensitivity**: Systematically vary LSTM hidden units (32, 64, 128) and RepeatVector depth to identify impact on R² scores, particularly for h=12,p=12 where accuracy drops below 0.7
2. **Routing realism**: Replace uniform splitting with weighted source-destination distributions based on historical traffic matrices (when available) and measure impact on LUS ranking accuracy
3. **Communication efficiency**: Profile communication rounds 1-50 to identify convergence patterns and determine if fewer rounds could achieve comparable accuracy with reduced overhead