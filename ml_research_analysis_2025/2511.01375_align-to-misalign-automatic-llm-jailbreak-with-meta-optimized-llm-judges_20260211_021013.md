---
ver: rpa2
title: 'Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges'
arxiv_id: '2511.01375'
source_url: https://arxiv.org/abs/2511.01375
tags:
- prompts
- scoring
- jailbreak
- template
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces AMIS, a meta-optimization framework for
  jailbreaking LLMs that jointly evolves attack prompts and scoring templates. The
  method employs a bi-level structure: in the inner loop, jailbreak prompts are iteratively
  refined using dense feedback from a fixed scoring template, while in the outer loop,
  the template itself is optimized to better align with actual attack success rates.'
---

# Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges

## Quick Facts
- arXiv ID: 2511.01375
- Source URL: https://arxiv.org/abs/2511.01375
- Reference count: 40
- Primary result: AMIS achieves 88.0% attack success rate on Claude-3.5-Haiku and 100.0% on Claude-4-Sonnet

## Executive Summary
This paper introduces AMIS, a meta-optimization framework for automatically jailbreaking large language models by jointly evolving adversarial prompts and scoring templates. The method operates in a bi-level optimization structure, where inner-loop prompt refinement is guided by a fixed template, and outer-loop template optimization aligns with real attack success rates. Evaluations show AMIS achieves state-of-the-art attack success rates, significantly outperforming prior methods on both closed and open models. The framework also demonstrates improved prompt transferability across different model families.

## Method Summary
AMIS uses a bi-level optimization framework where the inner loop iteratively refines jailbreak prompts using dense feedback from a fixed scoring template, while the outer loop optimizes the template itself to better align with actual attack success rates. This dual optimization approach enables both effective prompt generation and template adaptation, resulting in improved attack performance. The method was evaluated on AdvBench and JBB-Behaviors datasets across multiple LLM models including Claude-3.5-Haiku, Claude-4-Sonnet, GPT-4o, GPT-4, and Llama-3.1-70B-Instruct.

## Key Results
- Achieved 88.0% attack success rate on Claude-3.5-Haiku and 100.0% on Claude-4-Sonnet
- Outperformed prior methods on AdvBench and JBB-Behaviors benchmarks
- Demonstrated improved prompt transferability when optimized on strongly aligned models

## Why This Works (Mechanism)
The bi-level optimization structure allows for simultaneous refinement of both the attack prompts and the evaluation criteria used to judge their effectiveness. By meta-optimizing the scoring template to better reflect actual attack success, the framework creates a more accurate feedback loop for prompt evolution. The dataset-level template evolution is critical for achieving high attack success rates, as it ensures the optimization process is grounded in real-world effectiveness rather than fixed evaluation criteria.

## Foundational Learning
- **Bi-level optimization**: Two nested optimization loops (inner for prompt refinement, outer for template adaptation) - needed to jointly optimize prompts and evaluation criteria; quick check: verify nested loops execute without conflict
- **Template scoring**: Automated evaluation criteria for measuring prompt effectiveness - needed to provide dense feedback for optimization; quick check: ensure scoring aligns with actual attack success
- **Prompt transferability**: Ability of optimized prompts to work across different model architectures - needed to demonstrate generalization; quick check: test optimized prompts on unseen models
- **Meta-optimization**: Optimization of optimization parameters (the scoring template itself) - needed to create adaptive evaluation criteria; quick check: verify template updates improve alignment with success rates
- **Adversarial prompt generation**: Creating inputs designed to bypass model safety filters - needed as the primary attack mechanism; quick check: confirm generated prompts bypass safety measures
- **Dataset-level evolution**: Optimizing templates using entire datasets rather than individual examples - needed for robust template learning; quick check: compare dataset-level vs. example-level template optimization

## Architecture Onboarding

**Component map**: Scoring Template -> Prompt Generator -> LLM Model -> Success Feedback -> Template Optimizer -> Scoring Template

**Critical path**: Scoring Template provides feedback to Prompt Generator, which creates prompts tested on LLM Model, success feedback updates Template Optimizer, which refines Scoring Template

**Design tradeoffs**: Fixed template during inner loop provides stability but may limit adaptation; dataset-level template evolution improves performance but increases computational cost

**Failure signatures**: Low ASR across models indicates poor template optimization; poor transferability suggests overfitting to specific model alignment strategies

**First experiments**:
1. Run baseline prompt generation without template optimization to establish performance floor
2. Implement inner-loop prompt refinement only to isolate template optimization impact
3. Test prompt transferability from one model family to another to measure generalization

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation limited to specific model families, potentially limiting generalizability claims
- Computational overhead of bi-level optimization not assessed for practical deployment
- No analysis of cross-lingual or cross-cultural attack transferability
- Template meta-optimization may overfit to benchmark-specific harms

## Confidence

High: Quantitative ASR results and ablation findings on tested models; methodology for bi-level optimization; prompt transferability trends within the tested model set.

Medium: Generalizability claims across model families and real-world deployment; impact of template evolution on attack robustness beyond benchmarks.

Low: Claims of universal jailbreak effectiveness, applicability to non-English harms, and transferability to models outside the tested set.

## Next Checks
1. Validate template meta-optimization on a separate, held-out set of unseen harmful prompts and model families to test robustness and avoid benchmark overfitting.
2. Conduct cross-lingual and cross-cultural transfer experiments to assess whether attacks generalize beyond English and Western-centric harms.
3. Measure computational overhead and runtime efficiency of AMIS in real-time adversarial settings to determine practical deployment viability.