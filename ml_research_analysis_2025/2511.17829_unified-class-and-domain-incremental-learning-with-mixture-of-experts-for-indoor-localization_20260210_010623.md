---
ver: rpa2
title: Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor
  Localization
arxiv_id: '2511.17829'
source_url: https://arxiv.org/abs/2511.17829
tags:
- localization
- learning
- indoor
- region
- moelo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MOELO introduces a unified continual learning framework for indoor
  localization that jointly addresses domain-incremental and class-incremental learning
  scenarios. It employs a mixture-of-experts architecture with an equiangular tight
  frame-based gating mechanism to dynamically route Wi-Fi RSS fingerprints to region-specific
  experts, enabling efficient adaptation to both new devices and new indoor locations.
---

# Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization

## Quick Facts
- arXiv ID: 2511.17829
- Source URL: https://arxiv.org/abs/2511.17829
- Authors: Akhil Singampalli; Sudeep Pasricha
- Reference count: 32
- Key outcome: Introduces MOELO, a unified continual learning framework for indoor localization addressing both domain-incremental and class-incremental learning with mixture-of-experts architecture

## Executive Summary
MOELO presents a novel unified continual learning framework for indoor localization that simultaneously addresses domain-incremental and class-incremental learning challenges. The framework employs a mixture-of-experts architecture with an equiangular tight frame-based gating mechanism to dynamically route Wi-Fi RSS fingerprints to region-specific experts, enabling efficient adaptation to both new devices and new indoor locations. A shared encoder produces device-invariant latent representations while balanced replay prototypes maintain knowledge retention across incremental updates. Experimental results demonstrate significant improvements over state-of-the-art frameworks, achieving up to 25.6× lower mean localization error and 44.5× lower worst-case error across diverse buildings and mobile devices.

## Method Summary
MOELO leverages a mixture-of-experts (MoE) architecture with an equiangular tight frame (ETF)-based gating mechanism to route Wi-Fi RSS fingerprints to region-specific experts for indoor localization. The framework employs a shared encoder that generates device-invariant latent representations, enabling robust performance across different mobile devices. For continual learning, MOELO implements balanced replay with prototypes to retain knowledge across incremental updates while minimizing forgetting. The architecture is specifically designed to handle both class-incremental scenarios (new locations) and domain-incremental scenarios (new devices) within a unified framework. The ETF-based gating mechanism provides a theoretically sound approach for dynamic routing, while the balanced replay strategy ensures stable performance during incremental learning phases.

## Key Results
- Achieves up to 25.6× lower mean localization error compared to state-of-the-art frameworks
- Reduces worst-case localization error by up to 44.5× across diverse buildings and devices
- Demonstrates 21.5× less forgetting during incremental learning phases
- Maintains compact model footprint and low inference latency suitable for resource-limited mobile devices

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to dynamically route inputs to specialized experts based on spatial regions, while maintaining device-invariant representations through a shared encoder. The ETF-based gating mechanism provides principled routing decisions that balance load across experts, preventing catastrophic forgetting during incremental updates. The balanced replay mechanism ensures that knowledge from previous domains and classes is retained through carefully selected prototypes, enabling stable performance as new data arrives.

## Foundational Learning
- **Mixture of Experts**: Multiple specialized neural networks that handle different aspects of the input space, needed to manage diverse indoor environments and device types; quick check: verify expert specialization through activation analysis
- **Equiangular Tight Frames**: Mathematical constructs for optimal vector arrangement in high-dimensional spaces, needed for principled gating decisions; quick check: validate ETF orthogonality and tightness properties
- **Continual Learning**: Learning paradigm where models incrementally update with new data while retaining old knowledge, needed for real-world deployment scenarios; quick check: measure forgetting rates across incremental steps
- **Domain Generalization**: Ability to perform well on unseen domains, needed for handling new devices; quick check: test on devices not seen during training
- **Prototype-based Replay**: Selective memory mechanism using representative samples, needed for efficient knowledge retention; quick check: analyze prototype diversity and representativeness

## Architecture Onboarding
- **Component Map**: Input Wi-Fi RSS -> Shared Encoder -> ETF Gating -> Expert Routers -> Expert Networks -> Output Fusion -> Location Estimate
- **Critical Path**: Wi-Fi RSS fingerprints → Shared Encoder → ETF Gating → Expert Selection → Expert Inference → Location Prediction
- **Design Tradeoffs**: Balanced replay vs. storage efficiency, expert specialization vs. model complexity, gating precision vs. computational overhead
- **Failure Signatures**: Catastrophic forgetting during rapid domain shifts, expert collapse when gating fails, degraded performance with highly similar indoor environments
- **First Experiments**: 1) Ablation study removing ETF gating to quantify routing benefits, 2) Test with varying numbers of experts to find optimal specialization, 3) Evaluate replay buffer size impact on forgetting rates

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to Wi-Fi RSS fingerprinting, may not generalize to other localization modalities like BLE beacons or visual SLAM
- Impressive error reduction claims (25.6× lower mean error) should be contextualized against specific experimental conditions and datasets
- ETF gating mechanism may introduce computational overhead affecting real-time performance on severely resource-constrained devices
- Balanced replay assumes sufficient historical data availability, which may be limited in practical scenarios with storage constraints

## Confidence
- **Error Reduction Claims**: High confidence for Wi-Fi RSS fingerprinting domain tested, Medium confidence for broader localization contexts
- **Forgetting Mitigation**: High confidence based on experimental results, Medium confidence for long-term deployment scenarios
- **Framework Design Principles**: High confidence in mixture-of-experts architecture and ETF gating mechanism
- **Generalization to Other Modalities**: Low confidence due to evaluation being specific to Wi-Fi RSS fingerprinting

## Next Checks
1. Evaluate MOELO's performance on multi-modal localization systems combining Wi-Fi with inertial sensors or visual data to assess cross-modal generalization
2. Conduct stress testing under realistic constraints including varying signal-to-noise ratios, device heterogeneity beyond those tested, and limited storage for prototype replay
3. Perform ablation studies to quantify the individual contributions of the ETF gating mechanism versus alternative gating strategies in terms of both accuracy and computational efficiency