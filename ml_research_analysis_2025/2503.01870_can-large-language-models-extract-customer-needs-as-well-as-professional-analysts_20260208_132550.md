---
ver: rpa2
title: Can Large Language Models Extract Customer Needs as well as Professional Analysts?
arxiv_id: '2503.01870'
source_url: https://arxiv.org/abs/2503.01870
tags:
- analysts
- customer
- professional
- llms
- product
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study examines whether Large Language Models (LLMs) can automatically
  extract customer needs (CNs) from qualitative data. Researchers compared a fine-tuned
  LLM (SFT LLM) with professional analysts and a baseline LLM.
---

# Can Large Language Models Extract Customer Needs as well as Professional Analysts?

## Quick Facts
- arXiv ID: 2503.01870
- Source URL: https://arxiv.org/abs/2503.01870
- Authors: Artem Timoshenko; Chengfeng Mao; John R. Hauser
- Reference count: 0
- Primary result: Fine-tuned LLM performs as well as or better than professional analysts in extracting customer needs from qualitative data.

## Executive Summary
This study investigates whether Large Language Models (LLMs) can automatically extract customer needs (CNs) from qualitative data as effectively as professional analysts. Researchers developed a fine-tuned LLM (SFT LLM) and compared its performance against both a baseline LLM and human analysts in a blind evaluation. The SFT LLM successfully identified well-formulated, sufficiently specific CNs that were justified by source content without hallucinations. It also captured a broader range of needs including emotional and niche requirements, and scaled efficiently to larger datasets. These results suggest that SFT LLMs can automate CN extraction, reducing manual effort while maintaining or improving insight quality for product development and marketing strategy.

## Method Summary
The researchers fine-tuned a Vicuna 13B LLM using 1,549 professionally-labeled CN-verbatim pairs from 10 VOC studies across various product categories. They included 11,975 uninformative sentences as negative examples to reduce hallucinations. The model was trained using DeepSpeed on 4× A100 GPUs for approximately 8 hours. At inference, a special tag `<GPT-VOC>` plus product category conditioned the model for CN extraction. Performance was evaluated through blind professional analyst review across three dimensions: whether the output was a valid CN, sufficiently specific, and followed from the source verbatim. The SFT LLM was tested on held-out product categories (wood stain, oral care) not present in the training data.

## Key Results
- SFT LLM performs as well or better than professional analysts in blind evaluation for identifying well-formulated, sufficiently specific CNs that follow from source material
- No evidence of hallucinations in SFT LLM outputs; baseline LLM without fine-tuning was less accurate and specific
- SFT LLM captured broader range of CNs including emotional and niche needs, and scaled efficiently to larger datasets

## Why This Works (Mechanism)

### Mechanism 1: Task-Specific Fine-Tuning Transfers Professional Standards
Fine-tuning with professionally-identified CNs teaches the LLM to formulate customer needs at the correct level of abstraction—not too generic, not too specific—following industry conventions. SFT adjusts model parameters via backpropagation on matched CN-verbatim pairs, teaching abstractive summarization that captures "jobs to be done" rather than surface-level opinions or solutions. Core assumption: patterns in professional CN formulation are learnable from ~1,500 examples and generalize to unseen product categories.

### Mechanism 2: Balanced Negative Examples Control Hallucination Rate
Including uninformative sentences as "negative" examples during training calibrates the model's threshold for valid CNs, reducing hallucinations. The training signal teaches the model to recognize when source material contains no actionable need and return `[]` rather than forcing an extraction. Core assumption: an optimal balance exists between positive and negative examples—too many negatives cause false negatives (missed CNs), too few cause hallucinations.

### Mechanism 3: Special Token Tagging Conditions Task Behavior
Prepending a unique special tag (`<GPT-VOC>`) and product category to each prompt conditions the model to invoke its fine-tuned CN-extraction behavior. During fine-tuning, the model learns to associate the special tag with the specific task distribution, enabling standardized shorthand prompt at inference. Core assumption: the model can bind arbitrary tokens to task-specific behaviors through supervised exposure.

## Foundational Learning

- **Abstractive Summarization**: CN extraction requires generating conceptual statements that may not appear verbatim in source text. Quick check: Given a review stating "the brush shuts off after 2 minutes but the 30 second timer is missing," can you distinguish between an extractive summary and an abstractive CN formulation?

- **Customer Needs vs. Solutions/Opinions/Targets**: The core challenge is separating underlying benefits ("jobs to be done") from stated solutions, product attributes, or sentiment. Quick check: A customer says "I wish stores would stock the amber color in gallon size." Is this a CN, a solution, or an opinion? What would a properly formulated CN look like?

- **Supervised Fine-Tuning vs. Prompt Engineering**: The Base LLM with prompt engineering failed to meet professional standards; understanding why SFT succeeds where prompting fails informs architecture decisions. Quick check: Why might in-context examples in a prompt be insufficient for tasks requiring consistent adherence to domain-specific output conventions?

## Architecture Onboarding

- **Component map**: Foundational LLM (Vicuna 13B) -> Training data pipeline (1,549 CN-verbatim pairs + negative examples) -> Fine-tuning infrastructure (DeepSpeed, 4× A100 GPUs) -> Inference (standardized prompt with `<GPT-VOC>` tag) -> Evaluation (blind professional analyst review)

- **Critical path**: 1) Curate professionally-labeled CN-verbatim pairs (rare, often proprietary) 2) Construct balanced negative examples (uninformative sentences → `[]`) 3) Fine-tune with supervised learning; validate on held-out data to calibrate negative ratio 4) Deploy with standardized prompt structure including special tag

- **Design tradeoffs**: More negative examples → fewer hallucinations but higher false negative rate; Processing full corpus vs. sampled subset → more coverage but more redundancy to winnow; Model size (13B vs 7B vs 33B) → capability vs. inference cost

- **Failure signatures**: Outputs too generic ("ease of use") → undertrained or poor training-data specificity; Outputs conflate solutions with needs → training data may lack clear distinction examples; Hallucinations (CNs not grounded in source) → insufficient negative examples; Inconsistent behavior across categories → special tag not used

- **First 3 experiments**: 1) Held-out category validation: Apply SFT model to a product category excluded from training to test generalization 2) Negative-ratio sweep: Systematically vary negative-to-positive example ratios and measure hallucination rate vs. recall 3) Blind human baseline comparison: Run professional analysts rating CNs from SFT LLM, Base LLM, and humans blind to source

## Open Questions the Paper Calls Out

### Open Question 1
Can machine-based clustering methods effectively automate the winnowing and affinitization (grouping) of customer needs into hierarchical structures? Current methods like topic modeling and keyword searches fail to capture semantic nuance required for professional hierarchy construction, leaving this as manual task. Evidence needed: algorithm that organizes raw SFT LLM outputs into primary, secondary, and tertiary hierarchies with high agreement compared to professional structures.

### Open Question 2
Can machine learning models accurately prioritize extracted customer needs based on importance rather than simple proxies like frequency or sentiment? SFT LLMs extract CNs but do not prioritize them, and frequency/sentiment are weakly correlated with actual importance. Evidence needed: model generating importance scores for CNs that correlate strongly with "ground truth" importance data from quantitative surveys or market performance.

### Open Question 3
Do SFT LLMs generalize across different industry standards for customer needs, or are they prone to overfitting to specific linguistic style of training firm? Paper relies on training data from single partner firm with specific definitions, while noting analyst training varies firm-to-firm. Evidence needed: cross-validation study where SFT LLM trained on Firm A's data is evaluated on Firm B's data to check if performance degrades due to style mismatch.

## Limitations
- Proprietary training data (1,549 CN-verbatim pairs) limits reproducibility and independent validation
- Long-tail generalization to entirely novel domains remains untested
- Blind evaluation relies on subjective judgments of CN quality by professional analysts

## Confidence

- **High Confidence**: SFT LLM performs as well or better than professional analysts on three evaluation dimensions (is CN, specific enough, follows from verbatim) in blind evaluation
- **Medium Confidence**: Fine-tuned model can scale efficiently to larger datasets and capture broader range of CNs including emotional and niche needs
- **Low Confidence**: Claim that SFT LLMs can effectively automate CN extraction across all qualitative data sources and product categories without significant human oversight

## Next Checks
1. **Cross-Domain Generalization Test**: Apply SFT model to qualitative data from industries entirely excluded from original training (e.g., B2B software, medical devices) to assess performance on truly novel domains
2. **Hallucination Audit**: Systematically analyze model outputs on known uninformative text to quantify hallucination rates and validate negative-example balancing mechanism across different ratios
3. **Comparative Cost-Benefit Analysis**: Measure time and resources required to curate professional CN training data versus efficiency gains from automated extraction, including validation overhead and quality control processes