---
ver: rpa2
title: Subject-independent Classification of Meditative State from the Resting State
  using EEG
arxiv_id: '2504.18095'
source_url: https://arxiv.org/abs/2504.18095
tags:
- classification
- architecture
- meditation
- inter-subject
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of classifying meditative states
  from resting states using EEG data, with a focus on achieving subject-independent
  (inter-subject) classification. The authors propose three architectures: CSP-LDA,
  CSP-LDA-LSTM, and SVD-NN.'
---

# Subject-independent Classification of Meditative State from the Resting State using EEG

## Quick Facts
- arXiv ID: 2504.18095
- Source URL: https://arxiv.org/abs/2504.18095
- Reference count: 40
- Primary result: SVD-NN architecture achieves 96.4% accuracy for inter-subject classification of meditative states

## Executive Summary
This paper addresses the challenge of classifying meditative states from resting states using EEG data, with a focus on achieving subject-independent (inter-subject) classification. The authors propose three architectures: CSP-LDA, CSP-LDA-LSTM, and SVD-NN. CSP-LDA uses Common Spatial Pattern for feature extraction and Linear Discriminant Analysis for classification. CSP-LDA-LSTM employs CSP for feature extraction, LDA for dimensionality reduction, and LSTM networks for classification, modeling the binary classification problem as a sequence learning problem. SVD-NN uses Singular Value Decomposition to select the most relevant components of the EEG signals and a shallow neural network for classification. The CSP-LDA-LSTM architecture achieved the best performance with 98.2% accuracy for intra-subject classification, while the SVD-NN architecture provided significant performance with 96.4% accuracy for inter-subject classification. These results are comparable to the best-reported accuracies in the literature for intra-subject classification, indicating the robustness and ability to generalize across different subjects.

## Method Summary
The study employs three classification architectures on 54 subjects performing Rajyoga meditation (eyes-open) versus resting state. EEG data is downsampled to 128 Hz, notch filtered, and processed with ICA for ocular artifact removal. The data is filtered into four frequency bands (Alpha: 8-13 Hz, Beta: 13-25 Hz, Low Gamma: 25-45 Hz, High Gamma: 45-64 Hz). CSP-LDA extracts log-variance features from 10 CSP filter pairs and classifies with LDA. CSP-LDA-LSTM uses the same features but feeds them to an LSTM with 200 hidden units. SVD-NN flattens epochs, reshapes to 384 columns, applies truncated SVD (k=247 for beta band inter-subject), and classifies with a shallow neural network. Intra-subject evaluation uses 10-fold CV while inter-subject uses Leave-One-Subject-Out cross-validation.

## Key Results
- CSP-LDA-LSTM achieves 98.2% accuracy for intra-subject classification using high-gamma band
- SVD-NN achieves 96.4% accuracy for inter-subject classification using beta band
- SVD-NN fails on gamma bands (39.2-59.8% accuracy), while CSP-based methods prefer high-gamma band
- Regularized CSP performs no better than classical CSP for this dataset

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** CSP-LDA-LSTM achieves superior intra-subject classification by modeling meditation detection as a sequence learning problem rather than static feature classification.
- **Mechanism:** CSP extracts discriminative spatial patterns from EEG by maximizing variance ratio between meditation and resting classes. LDA projects the 20-dimensional log-variance features to 1D. LSTM then learns temporal dependencies across sequential 64-sample epochs, capturing how meditation-related patterns evolve over time.
- **Core assumption:** Meditative states produce consistent spatial patterns with temporal structure that differs systematically from resting states within the same individual.
- **Evidence anchors:**
  - [abstract] "CSP-LDA-LSTM Architecture employs CSP for feature extraction, LDA for dimensionality reduction, and long short-term memory (LSTM) networks for classification, modeling the binary classification problem as a sequence learning problem."
  - [section III-B] "The resulting values are presented as sequence data to a single-layer LSTM with 200 hidden units... Adam optimizer is employed, and the learning rate used is 0.001."
  - [corpus] Weak direct support; corpus papers focus on motor imagery and emotion recognition, not meditation sequence modeling.
- **Break condition:** If inter-subject variability in spatial patterns exceeds within-subject temporal consistency, sequence modeling alone cannot generalize across individuals.

### Mechanism 2
- **Claim:** SVD-based low-rank approximation denoises EEG by retaining signal components with higher SNR, enabling subject-invariant feature extraction.
- **Mechanism:** SVD decomposes the EEG matrix X = UΣV^T. The assumption is that meditation-relevant signal occupies a lower-dimensional subspace, while noise distributes uniformly across all orthogonal directions. By truncating to k singular values where SNR is highest, the reconstructed signal retains discriminative information while suppressing subject-specific noise.
- **Core assumption:** Meditation-related electrophysiological activity lies in a subspace whose dimension is less than the full recorded EEG, and this subspace is consistent across subjects.
- **Evidence anchors:**
  - [section III-C] "If X is corrupted with an additive noise distributed across the directions of the tensors u_i v_i^T, the signal-to-noise ratio (SNR) of each component... decreases with decreasing values of σ_i."
  - [section III-C] "It is reasonable to assume that the actual electrophysiological signal corresponding to meditation lies in a subspace whose dimension is less than that of the recorded EEG."
  - [corpus] "Inter- and Intra-Subject Variability in EEG: A Systematic Survey" documents the challenge of inter-subject variability, supporting the need for denoising approaches.
- **Break condition:** If optimal k varies substantially across subjects (indicating inconsistent subspace dimensionality), a fixed k will underperform on held-out subjects.

### Mechanism 3
- **Claim:** Architecture-specific frequency band selection reflects different feature extraction strategies: CSP-based methods favor high-gamma band while SVD-NN favors beta band.
- **Mechanism:** CSP optimizes spatial filters to maximize class separability on selected channels—higher frequencies (high gamma: 45-64 Hz) show larger power differences between meditation and rest. SVD uses all channels; beta band (13-25 Hz) benefits from excluding alpha-band occipital activity present during eyes-open states.
- **Core assumption:** The discriminative information distribution across frequency bands depends on whether the architecture selects channels (CSP) or uses all channels (SVD).
- **Evidence anchors:**
  - [section IV-A] "CSP-based architectures perform better with the high-gamma band, suggesting notable gamma-band power differences between meditation and rest."
  - [section IV-A] "SVD-NN performs best with the beta band, likely due to its ability to exclude neural activities from the alpha band in the occipital lobe during eyes-open meditation."
  - [corpus] "AGTCNet" notes subject-invariant BCI systems remain challenging, consistent with frequency-band variability across subjects.
- **Break condition:** If meditation type changes (e.g., eyes-closed meditation), alpha band may become discriminative, invalidating beta-only selection for SVD-NN.

## Foundational Learning

- **Concept: Common Spatial Pattern (CSP)**
  - **Why needed here:** CSP is the primary feature extractor for two of three architectures; understanding how it maximizes variance ratio between classes is essential.
  - **Quick check question:** Given two covariance matrices for meditation and resting states, what objective does CSP optimize?

- **Concept: Singular Value Decomposition (SVD) for Denoising**
  - **Why needed here:** SVD-NN relies on truncated SVD as a denoising mechanism; misunderstanding this leads to incorrect k selection.
  - **Quick check question:** Why does truncating to larger singular values improve SNR under the uniform noise assumption?

- **Concept: Leave-One-Subject-Out Cross-Validation**
  - **Why needed here:** Inter-subject evaluation uses LOSO to simulate deployment on unseen subjects; understanding this prevents data leakage.
  - **Quick check question:** In LOSO with 54 subjects, how many training rounds occur, and what data comprises each test set?

## Architecture Onboarding

- **Component map:**
  - CSP-LDA: EEG epochs → Band-pass filter → CSP (spatial filtering, 10 filter pairs) → Log-variance features (20-dim) → LDA classifier
  - CSP-LDA-LSTM: EEG epochs (64 samples) → CSP (10 filter pairs) → Log-variance (20-dim) → LDA (1-dim projection) → LSTM (200 hidden units, 20 epochs)
  - SVD-NN: EEG epochs → Flatten to column vectors → Stack by class → Reshape to 384 columns → Truncated SVD reconstruction → Shallow NN (64/32 → 8 → 1, ReLU, sigmoid)

- **Critical path:** For inter-subject deployment, use SVD-NN with beta band. Validate optimal k on a held-out portion of training data before applying to all LOSO rounds.

- **Design tradeoffs:**
  - CSP-LDA: Fast, interpretable, but poor inter-subject generalization (66.7-73.5% across bands)
  - CSP-LDA-LSTM: Best intra-subject (98.2%), moderate inter-subject (94.1%), requires more training time
  - SVD-NN: Best inter-subject (96.4%), but gamma bands fail (39.2-59.8%), hyperparameter k requires validation

- **Failure signatures:**
  - CSP-based methods on inter-subject: Drop from ~98% to ~70-94% indicates subject-specific spatial patterns not generalizing
  - SVD-NN on gamma bands: Near-chance accuracy (39.2-59.8%) suggests high-frequency noise dominates singular values
  - Regularization not helping: TR-CSP performs no better than classical CSP, suggesting penalty on spatial vector elements is unnecessary for this task

- **First 3 experiments:**
  1. Replicate intra-subject CSP-LDA-LSTM on high-gamma band with 10-fold CV; expect 98.2 ± 0.5% accuracy.
  2. Replicate inter-subject SVD-NN on beta band with LOSO; validate k=247 singular values on 10% training split; expect 96.4 ± 0.6%.
  3. Ablation: Test SVD-NN inter-subject with varying k (100, 150, 200, 247, 300) to verify optimal k selection is not overfit to validation set.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the proposed architectures (specifically SVD-NN and CSP-LDA-LSTM) effectively generalize to classify meditative states in practices that utilize eyes-closed protocols?
  - **Basis:** The authors note Rajyoga is practiced with eyes open, unlike most other meditations, and state methods need separate testing for other meditation types.
  - **Why unresolved:** Current study limited to Rajyoga where alpha band is less discriminative; unknown if Beta band optimization holds when Alpha band activity increases during eyes-closed meditation.
  - **Resolution path:** Test trained models on open-source datasets of eyes-closed meditation (Zen, Vipassana) without retraining, or re-evaluate frequency band importance in eyes-closed setting.

- **Open Question 2:** Can the classification confidence of the subject-independent models serve as a reliable quantitative biomarker for meditation depth or expertise?
  - **Basis:** Introduction states a high inter-subject system may be used for grading meditation depth of novice meditators.
  - **Why unresolved:** Current study validates on experts (4-43 years experience) using binary classification; not tested whether deeper meditation yields higher confidence or if novices generate distinct features.
  - **Resolution path:** Correlation analysis between classifier output probability and independent measures of meditation depth across varying expertise levels.

- **Open Question 3:** What explains the contradictory dependency on frequency bands between CSP-based architectures (optimal in High Gamma) and SVD-NN architecture (optimal in Beta), and can these approaches be unified?
  - **Basis:** Discussion notes CSP-LDA-LSTM improves with higher frequencies, peaking in High Gamma, while SVD-NN performs best in Beta and fails in Gamma bands.
  - **Why unresolved:** Paper hypothesizes difference stems from CSP optimizing selected channels vs. SVD using all channels, but exact mechanism remains unidentified.
  - **Resolution path:** Ablation study analyzing singular vectors selected by SVD in Gamma band compared to spatial filters generated by CSP.

## Limitations

- Critical reshape logic: SVD-NN requires flattening EEG epochs and reshaping to 384 columns, but the mathematical mapping from 64 channels × 128 samples = 8192 values to 384 columns is not specified, creating a fundamental reproducibility barrier.
- Sequence definition ambiguity: CSP-LDA-LSTM reduces epoch length to 64 samples but does not explicitly define how many consecutive blocks form one sequence input to the LSTM.
- Hyperparameter optimization concerns: Optimal k=247 singular values for SVD-NN beta band was selected on training data; without independent validation, this risks overfitting to the specific dataset.

## Confidence

- **High confidence:** CSP-LDA-LSTM achieves 98.2% intra-subject accuracy on high-gamma band (well-specified methodology, clear validation protocol).
- **Medium confidence:** SVD-NN achieves 96.4% accuracy for inter-subject classification on beta band (performance claim clear, but critical reshape logic missing).
- **Low confidence:** Generalization of these architectures to other meditation types or EEG datasets (no cross-dataset validation reported).

## Next Checks

1. **Validate reshape logic:** Test SVD-NN inter-subject classification with different reshape strategies (e.g., 64×6, 32×12, 16×24) and compare performance to determine which produces the reported 96.4% accuracy.
2. **Cross-dataset generalization:** Apply the best-performing architectures (CSP-LDA-LSTM for intra-subject, SVD-NN for inter-subject) to an independent meditation EEG dataset to assess true subject-independent performance.
3. **Optimal k sensitivity:** Perform k-parameter sensitivity analysis on SVD-NN inter-subject classification using beta band, testing k values from 100-300 to verify that k=247 is genuinely optimal rather than overfit.