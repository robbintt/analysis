---
ver: rpa2
title: Aligning ESG Controversy Data with International Guidelines through Semi-Automatic
  Ontology Construction
arxiv_id: '2509.10922'
source_url: https://arxiv.org/abs/2509.10922
tags:
- principles
- news
- these
- such
- principle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a semi-automatic method to align unstructured
  ESG controversy data with international normative frameworks like the UN Global
  Compact. The approach uses lightweight ontology design combined with large language
  models to convert abstract principles into structured RDF templates and then extract
  relevant information from news articles to populate a knowledge graph.
---

# Aligning ESG Controversy Data with International Guidelines through Semi-Automatic Ontology Construction

## Quick Facts
- **arXiv ID:** 2509.10922
- **Source URL:** https://arxiv.org/abs/2509.10922
- **Reference count:** 30
- **Primary result:** Semi-automatic ontology construction aligns ESG news with UN Global Compact principles, achieving precision 0.56 and accuracy 0.91 on 200 samples.

## Executive Summary
This study presents a semi-automatic method to align unstructured ESG controversy data with international normative frameworks like the UN Global Compact. The approach uses lightweight ontology design combined with large language models to convert abstract principles into structured RDF templates and then extract relevant information from news articles to populate a knowledge graph. Manual evaluation on 200 samples showed precision of 0.56 and accuracy of 0.91 when applied to GPT-4o mini-extracted data, outperforming a simple one-shot baseline. The method enables principled reasoning over ESG violations and supports alignment of ESG news content with formal regulatory standards, addressing the gap between proprietary ESG taxonomies and high-level sustainability frameworks.

## Method Summary
The method constructs a meta-ontology extending Schema.org with ESG-specific classes, then prompts LLMs to generate 30 violation patterns (Entity A, Action, Entity B) from UNGC principles. These patterns are promoted to RDFS classes and used to extract named entities and relationships from filtered news articles, populating an RDF knowledge graph that links violations to specific UNGC principles. The pipeline includes two-stage LLM filtering for relevance and sentiment, followed by structured extraction of controversy-related triples.

## Key Results
- Precision of 0.56 and accuracy of 0.91 achieved on 200 manual evaluation samples using GPT-4o mini
- Outperformed one-shot baseline (precision 0.29, accuracy 0.78) by using structured ontology patterns
- Successfully populated knowledge graph linking 181 controversy pairs to 10 UNGC principles

## Why This Works (Mechanism)

### Mechanism 1
Decomposing abstract normative principles into structured relational patterns (triples) improves precision by constraining extraction to specific semantic structures. The LLM generates three concrete "violation patterns" per principle as (Entity A, Action, Entity B) triples, which the extraction phase matches exactly. This filters out irrelevant semantic variations that generic prompts might capture.

### Mechanism 2
Promoting extracted patterns to formal ontology classes (rdfs:Class) enables type-level consistency checks that reduce false positives. Instead of treating patterns as transient strings, the method instantiates them as persistent classes within an ontology, forcing adherence to defined schema and limiting the LLM's tendency to hallucinate arbitrary relations.

### Mechanism 3
Pre-filtering news streams for negative sentiment and corporate relevance is a necessary prerequisite for high-accuracy controversy detection. The two-stage filter concentrates the LLM's probability mass on identifying which violation occurred rather than determining if a violation occurred at all, significantly reducing noise in the extraction process.

## Foundational Learning

- **Resource Description Framework (RDF) & Knowledge Graphs**: The paper relies on RDF triples to store extracted entities and violation patterns. Understanding that data is stored as a graph of relationships, not just rows, is essential.
  - Quick check: How does representing a "violation" as an RDF Class differ from storing it as a text tag in a database?

- **UNGC (United Nations Global Compact)**: This is the target schema for the entire extraction process. The system's success depends on mapping messy news text to these 10 specific abstract principles.
  - Quick check: Why is mapping unstructured news to the UNGC considered harder than mapping to a standard industry taxonomy?

- **Precision vs. Recall in LLM Extraction**: The paper explicitly trades high recall for higher precision (0.56 vs 0.29 baseline). You must understand this trade-off to interpret the "success" of the method.
  - Quick check: In a compliance context, why might a user prefer higher precision (fewer false alarms) over higher recall (catching every potential violation)?

## Architecture Onboarding

- **Component map:** Webz.io (Negatively framed news) -> LLM Filter (English + corporate/ESG relevance) -> Ontology Generator (UNGC Text -> 30 ESGViolationActionPattern Classes) -> Extraction Engine (Filtered Text + Pattern Classes -> RDF Triples) -> Knowledge Graph

- **Critical path:** The generation of the 30 violation patterns is the linchpin. If these patterns do not semantically cover the UNGC principles, the subsequent extraction steps will fail to map news correctly.

- **Design tradeoffs:** Structured ontologies outperform simple one-shot prompting in precision (0.56 vs 0.29) and accuracy (0.91 vs 0.78), but one-shot retains higher recall (0.85 vs 0.41). GPT-4o mini provided the broadest candidate pool for evaluation, while GPT-4.1 was more conservative.

- **Failure signatures:** False positives from broad interpretation (e.g., general working conditions â†’ forced labor) and false negatives from nuanced language (e.g., "surveillance" not mapped to human rights violations).

- **First 3 experiments:**
  1. Validate the 30 LLM-generated patterns against source UNGC text for semantic alignment
  2. Compare "one-shot" vs "ontology" methods on 50 articles for False Positive density
  3. Disable the "negatively framed" filter to quantify precision drop and processing cost increase

## Open Questions the Paper Calls Out

- Can the constructed knowledge graph be effectively utilized for tracking ESG trends and predicting future risk events?
  - The authors state in the conclusion that these applications are supported by the graph but "leave for future work."
  - This remains unresolved because the current study focused strictly on extraction methodology, not downstream predictive tasks.
  - A follow-up study demonstrating improved performance of temporal risk prediction models would resolve this.

- Are the observed cross-principle infringement patterns and violation transition probabilities robust when applied to a larger dataset?
  - The authors note that "a larger dataset would be needed to confirm the robustness of these findings" regarding the transition heatmap.
  - This remains unresolved because the current analysis is based on limited pairs (181).
  - Validation using a significantly larger corpus of ESG news articles would resolve this.

- Can the extraction method be refined to better capture violations described through indirect or nuanced language?
  - The evaluation notes lower recall for certain principles due to "indirect or nuanced language that implies rather than states a violation."
  - This remains unresolved because the current prompting strategy relies on matching specific relational patterns.
  - A comparative analysis testing LLM reasoning capabilities on false negative subsets would resolve this.

## Limitations

- Performance metrics are based on manual evaluation of only 200 samples, representing a small fraction of the processed corpus
- Reliance on negatively framed news articles introduces potential bias, possibly missing controversies in neutral/positive contexts
- The approach requires significant manual intervention for pattern validation and evaluation, limiting scalability compared to fully automated systems

## Confidence

**High Confidence**: The structured ontology approach outperforms simple one-shot prompting in precision (0.56 vs 0.29) and accuracy (0.91 vs 0.78). The filtering mechanism effectively reduces false positives.

**Medium Confidence**: The claim that the system enables principled reasoning over ESG violations is supported by knowledge graph construction, but practical utility for compliance decision-making requires further validation. The precision-recall trade-off is well-demonstrated.

**Low Confidence**: Scalability to larger corpora and performance across different languages/cultural contexts has not been demonstrated. Long-term maintenance of the ontology as UNGC principles evolve is an open question.

## Next Checks

1. **Pattern Coverage Validation**: Conduct comprehensive semantic analysis of the 30 LLM-generated patterns against all UNGC principle descriptions to identify gaps or over-broad interpretations.

2. **Bias Assessment**: Test the system on a balanced dataset containing positive, neutral, and negative framing to quantify performance degradation when removing the negatively-framed article filter.

3. **Regulatory Alignment Audit**: Map the extracted knowledge graph triples back to specific regulatory violations in major ESG frameworks (e.g., EU Taxonomy, SEC climate disclosure rules) to validate practical utility for compliance monitoring.