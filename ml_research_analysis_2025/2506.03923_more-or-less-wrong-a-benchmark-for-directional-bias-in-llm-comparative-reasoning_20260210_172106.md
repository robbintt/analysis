---
ver: rpa2
title: 'More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning'
arxiv_id: '2506.03923'
source_url: https://arxiv.org/abs/2506.03923
tags:
- more
- framing
- less
- equal
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models exhibit systematic reasoning biases when
  exposed to comparative linguistic framing, with models' predictions shifting toward
  the direction implied by words like "more," "less," or "equal," even when the underlying
  quantitative comparison remains unchanged. To investigate this effect, we constructed
  a benchmark of 300 controlled comparison scenarios, each evaluated across 14 prompt
  variants and three LLM families.
---

# More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning

## Quick Facts
- arXiv ID: 2506.03923
- Source URL: https://arxiv.org/abs/2506.03923
- Reference count: 14
- Large language models exhibit systematic reasoning biases when exposed to comparative linguistic framing

## Executive Summary
This paper introduces a benchmark to systematically evaluate how large language models exhibit directional reasoning biases when exposed to comparative linguistic framing. The authors constructed 300 controlled comparison scenarios and evaluated them across 14 prompt variants and three LLM families. Their findings reveal that LLMs consistently shift predictions toward the direction implied by words like "more," "less," or "equal," even when the underlying quantitative comparison remains unchanged. The study demonstrates that subtle linguistic cues and identity references can interact to produce measurable reasoning disparities, with framing terms consistently and predictably biasing model outputs, reaching up to 94% error rates in some cases.

## Method Summary
The authors constructed a benchmark of 300 controlled comparison scenarios, each evaluated across 14 prompt variants and three LLM families. The scenarios were designed to test how LLMs respond to comparative linguistic framing using terms like "more," "less," and "equal." They systematically varied the presence of demographic identity terms (e.g., "woman," "Black person") to assess interaction effects with framing terms. The evaluation included testing chain-of-thought prompting and structured output formats to understand mitigation strategies. Error rates were measured across different prompt conditions to quantify the magnitude and consistency of directional bias.

## Key Results
- Framing terms consistently and predictably bias model outputs, with directional error rates reaching up to 94% in some cases
- Chain-of-thought prompting mitigates but does not eliminate these biases
- Including demographic identity terms amplifies framing effects, with error rates increasing by up to 30 percentage points compared to neutral templates

## Why This Works (Mechanism)
The paper reveals that LLMs are sensitive to comparative linguistic framing, where words like "more," "less," or "equal" create directional anchors that influence reasoning outcomes. This occurs because LLMs, trained on vast text corpora, have learned statistical associations between these framing terms and subsequent comparative structures. The mechanism involves the model's attention patterns and next-token prediction being influenced by the framing context, leading to systematic prediction shifts even when quantitative information remains constant. The amplification of effects when demographic identity terms are included suggests that LLMs have learned complex associations between identity markers and comparative reasoning patterns.

## Foundational Learning

1. **Comparative Reasoning in LLMs** - Why needed: Understanding how LLMs process numerical comparisons and relative judgments. Quick check: Does the model correctly identify which of two quantities is larger without linguistic framing?

2. **Linguistic Framing Effects** - Why needed: Recognizing how subtle word choices influence model predictions. Quick check: Does adding "more" or "less" to a comparison prompt change the model's output?

3. **Demographic Bias Amplification** - Why needed: Identifying how identity terms interact with reasoning biases. Quick check: Does including identity markers increase error rates beyond what framing alone produces?

4. **Chain-of-Thought Prompting** - Why needed: Understanding mitigation strategies for reasoning biases. Quick check: Does requiring step-by-step reasoning reduce directional bias compared to direct prediction?

5. **Benchmark Construction** - Why needed: Creating controlled test scenarios to isolate specific effects. Quick check: Can the benchmark consistently reproduce framing effects across different model families?

## Architecture Onboarding

Component Map: Benchmark Generator -> LLM Family -> Prompt Variants -> Output Analysis -> Error Rate Calculation

Critical Path: The benchmark scenarios flow through each LLM family, with each scenario tested across all 14 prompt variants. The critical path involves scenario generation, model inference, output parsing, and statistical analysis of directional bias patterns.

Design Tradeoffs: The study balances controlled experimental conditions with ecological validity. Synthetic scenarios provide precise control over variables but may not capture all real-world complexity. The choice of 14 prompt variants allows comprehensive coverage of framing conditions but increases experimental complexity.

Failure Signatures: High directional error rates (>50%) indicate strong framing bias. Error amplification when identity terms are present signals interaction effects between framing and demographic variables. Persistence of bias despite chain-of-thought prompting suggests deep-seated associative patterns in model weights.

First Experiments:
1. Test baseline performance on comparison scenarios without any framing terms to establish reference error rates
2. Evaluate individual framing terms ("more," "less," "equal") in isolation to measure their specific directional effects
3. Test the interaction between demographic identity terms and framing by comparing error rates with and without identity markers

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text.

## Limitations

- The benchmark uses 300 synthetic comparison scenarios, which may not capture the full complexity of real-world reasoning contexts
- The specific demographic identities tested may not represent the full range of demographic variables that could interact with linguistic framing
- Results show systematic bias toward framing terms, but the magnitude of these effects may vary across different domains or reasoning types not represented in the dataset

## Confidence

- High confidence in the core finding that LLMs exhibit measurable directional bias in response to comparative framing terms
- Medium confidence in the interaction effects between framing and demographic identity terms, given the limited scope of identities tested
- Low confidence in claims about the universality of these effects across all reasoning domains and LLM architectures

## Next Checks

1. Test the benchmark across a broader range of real-world comparison scenarios to assess ecological validity
2. Systematically vary demographic identity terms and demographic combinations to map the full interaction space
3. Evaluate whether alternative prompting strategies beyond chain-of-thought (such as self-consistency or structured reasoning) provide better bias mitigation