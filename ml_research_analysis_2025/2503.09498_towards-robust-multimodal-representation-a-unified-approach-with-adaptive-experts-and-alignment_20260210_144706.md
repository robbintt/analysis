---
ver: rpa2
title: 'Towards Robust Multimodal Representation: A Unified Approach with Adaptive
  Experts and Alignment'
arxiv_id: '2503.09498'
source_url: https://arxiv.org/abs/2503.09498
tags:
- data
- modalities
- local
- learning
- representation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of missing multimodal data in
  healthcare, particularly for cancer subtyping, by proposing a novel deep learning
  framework called MoSARe. MoSARe integrates adaptive expert selection, cross-modal
  attention, and contrastive learning to handle incomplete multimodal data while maintaining
  high diagnostic accuracy.
---

# Towards Robust Multimodal Representation: A Unified Approach with Adaptive Experts and Alignment

## Quick Facts
- arXiv ID: 2503.09498
- Source URL: https://arxiv.org/abs/2503.09498
- Authors: Nazanin Moradinasab; Saurav Sengupta; Jiebei Liu; Sana Syed; Donald E. Brown
- Reference count: 36
- Primary result: MoSARe framework achieves superior cancer subtyping performance on multimodal data with missing modalities

## Executive Summary
This paper addresses the challenge of missing multimodal data in healthcare, particularly for cancer subtyping, by proposing a novel deep learning framework called MoSARe. MoSARe integrates adaptive expert selection, cross-modal attention, and contrastive learning to handle incomplete multimodal data while maintaining high diagnostic accuracy. The model processes histopathology images, RNA-seq data, and clinical reports, extracting global and local feature representations using specialized preprocessing pipelines. Key components include a Mixture of Experts (MoE) mechanism for adaptive feature selection, symmetric aligning for modality consistency, and multi-prototype contrastive learning for enhanced feature discriminability. MoSARe outperforms existing models in both complete and incomplete data scenarios across three cancer subtyping datasets (BRCA, RCC, NSCLC), achieving superior classification performance with metrics like AUC, F1-score, and accuracy.

## Method Summary
MoSARe is a deep learning framework that processes histopathology images (via UNI/ViT), RNA-seq data (via MLP), and clinical reports (via ModernBERT) to perform cancer subtyping. The method extracts both global representations (using ABMIL for images, 3-layer MLP for RNA, sentence transformers for text) and local representations (using GMM with 16 components for all modalities). These features are fused through Cross-Modal Attention blocks, processed by a Mixture of Experts layer (5 experts, Top-K=2) for adaptive selection, and aligned using symmetric and multi-prototype contrastive learning. Missing modalities are handled through decoupled reconstruction from aggregated representations. The model is trained with a combined loss function including classification, reconstruction, and contrastive terms, with contrastive learning starting after a 10-epoch warm-up.

## Key Results
- Outperforms existing models on cancer subtyping across BRCA, RCC, and NSCLC datasets in both complete and incomplete data scenarios
- Maintains high diagnostic accuracy with 30-50% missing modalities through decoupled reconstruction
- Achieves superior classification performance with metrics including AUC, F1-score, and accuracy
- Demonstrates robustness to varying levels of data incompleteness in real-world healthcare settings

## Why This Works (Mechanism)

### Mechanism 1
Sparse expert routing enables the model to handle variable information density and missingness by selectively activating the most relevant feature pathways. A Mixture of Experts (MoE) layer with a gating network (Router) selects the Top-K experts (K=2 out of 5) to process local representations (e.g., GMM means from WSI patches). This suppresses redundant or noisy features while preserving informative local signals. Core assumption: Discriminative information is concentrated in specific subspaces of the input features, which can be identified dynamically, and local features (clusters) are sufficient statistics for the modality.

### Mechanism 2
Decoupled reconstruction allows the model to synthesize missing modality features from the shared latent space, preventing the performance degradation typically caused by data dropout. The model aggregates available modalities into a unified vector ($X_{agg}$). A decoder (two-layer perceptron) attempts to "decouple" this aggregated vector back into modality-specific spaces. When a modality is missing ($M_{pre}=0$), the model uses this reconstruction rather than a zero-vector or noise. Core assumption: The aggregated multimodal representation contains sufficient cross-modal correlations to approximate the geometry of the missing modality's feature space.

### Mechanism 3
Enforcing bidirectional alignment between individual modalities and the aggregated representation prevents feature collapse and ensures consistency when input sources vary. The model uses Symmetric Contrastive Learning (SymCL) to align the aggregated representation $X_{agg}$ with individual modality features (e.g., $X_{WSI}$). It also uses Multi-Prototype Contrastive Learning (MCL) with GMMs to model class distributions and pull features toward positive prototypes. Core assumption: The "global" aggregated view should be consistent with "local" modality-specific views, and class distributions are multimodal (better modeled by GMMs than single centroids).

## Foundational Learning

- **Concept**: Multiple Instance Learning (MIL)
  - Why needed here: Histopathology images (WSIs) are gigapixel-sized and cannot be processed directly. The paper treats a slide as a "bag" of 256x256 patches and uses ABMIL (Attention-Based MIL) to compress this into a single global vector.
  - Quick check question: Can you explain how the attention weights in ABMIL determine which patches are "positive instances" for cancer subtyping?

- **Concept**: Gaussian Mixture Models (GMM)
  - Why needed here: The paper uses GMMs not just for alignment, but to create "local representations" (cluster centers) for WSIs and Text. This reduces the sequence length of the data while preserving tissue heterogeneity.
  - Quick check question: Why might K-means initialization (used here) be insufficient for clustering complex, high-dimensional histology features compared to a learned approach?

- **Concept**: Cross-Modal Attention (CMA)
  - Why needed here: Simple concatenation (late fusion) fails to capture interactions between genes and tissue appearance. CMA allows the model to query features in one modality (e.g., RNA) based on the context of another (e.g., WSI).
  - Quick check question: In Eq. 3, how does the dot product $(X_{WSI})^\top X_{RNA}$ determine which RNA features are relevant to the current WSI context?

## Architecture Onboarding

- **Component map**: UNI (ViT) -> ABMIL -> Global WSI; MLP -> Global RNA; ModernBERT -> Global Text; GMM (16 components) -> Local features for all; Cross-Modal Attention blocks -> Fusion; MoE (5 experts, Top-K=2) -> Adaptive selection; Decoupled MLPs -> Reconstruction; Contrastive heads (SymCL & MCL) -> Alignment

- **Critical path**: The Decoupled Reconstruction (Eq. 14) is the critical failure point. You must verify that $X_{rec}$ (reconstructed features) have similar norm and distribution to $X_{cma}$ (real features). If the reconstructor outputs noise, the final MoE aggregation will fail when data is missing.

- **Design tradeoffs**:
  - Fixed Components (C=16): The authors acknowledge fixing the number of GMM components to 16 is a limitation; it may be too few for complex tissues or too many for simple text reports.
  - Reconstruction vs. Generation: The model "reconstructs" features in latent space, not raw pixels/genes. This is computationally cheaper but loses pixel-level interpretability of the "imputed" data.

- **Failure signatures**:
  - Modality Collapse: During incomplete training, the model learns to ignore the reconstructed modality entirely (gating weights → 0).
  - Over-regularization: The alignment loss (λ1, λ2) dominates the classification loss, leading to well-clustered but class-indistinguishable features.

- **First 3 experiments**:
  1. Baseline Sanity Check: Run the model on complete data (0% masking) to verify the CMA and MoE integration matches or exceeds the ABMIL/SNN baselines reported in Table 1.
  2. Masking Ablation: Implement the "Masked Train - Unmasked Test" scenario (Table 2) with 30% masking. Monitor the reconstruction loss (L_rec) to ensure it converges; if it diverges, the decoupled reconstructor is failing.
  3. Component Ablation: Disable the MCL (Multi-Prototype Contrastive Learning) by setting λ2=0 to verify its impact on the F1-score, specifically on the imbalanced BRCA dataset.

## Open Questions the Paper Calls Out
The paper acknowledges several limitations and areas for future investigation: the impact of varying the number of GMM components (C) beyond the fixed value of 16 used in current experiments; the model's robustness to Missing Not At Random (MNAR) patterns where modality absence correlates with patient demographics or disease severity; and the potential adaptation of the unified representation learning approach for continuous outcome predictions such as survival analysis.

## Limitations
- Fixed GMM components (C=16) may lead to suboptimal solutions for different datasets with varying tissue heterogeneity
- Performance under Missing Not At Random (MNAR) patterns not evaluated, though real-world clinical data often exhibits such biases
- Current framework optimized for classification tasks; extension to continuous outcomes like survival analysis remains unexplored

## Confidence
- **High confidence**: The core mechanisms of Mixture of Experts routing, decoupled reconstruction, and symmetric alignment are well-specified and theoretically sound, with clear empirical improvements demonstrated.
- **Medium confidence**: The integration of cross-modal attention with MoE and the specific handling of missing modalities through reconstruction appears robust, though dependent on precise hyperparameter tuning not fully specified.
- **Low confidence**: Exact reproduction is uncertain due to missing architectural details in the MLP layers, GMM initialization, and contrastive learning parameters that could materially affect results.

## Next Checks
1. **Baseline verification**: Implement the complete-data (0% masking) scenario to verify CMA + MoE integration matches or exceeds reported ABMIL/SNN baselines in Table 1 before testing incomplete scenarios.
2. **Reconstruction stability**: During 30% masking experiments, monitor the reconstruction loss (L_rec) convergence. If it diverges, the decoupled reconstructor architecture requires adjustment.
3. **Component ablation**: Systematically disable Multi-Prototype Contrastive Learning (set λ2=0) to isolate its contribution to F1-score improvements, particularly on the imbalanced BRCA dataset.