---
ver: rpa2
title: 'Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of
  LLMs for Information Retrieval: An Italian Healthcare Use Case'
arxiv_id: '2512.04834'
source_url: https://arxiv.org/abs/2512.04834
tags:
- llms
- comorbidities
- accuracy
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the zero-shot multilingual capability of six
  open-source large language models (LLMs) in extracting comorbidities from Italian
  Electronic Health Records (EHRs). The research aimed to determine if LLMs could
  replace traditional regular expression-based approaches for information retrieval
  in healthcare.
---

# Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case

## Quick Facts
- **arXiv ID:** 2512.04834
- **Source URL:** https://arxiv.org/abs/2512.04834
- **Reference count:** 30
- **Primary result:** Zero-shot LLMs cannot reliably substitute regular expression approaches for comorbidity extraction from Italian EHRs.

## Executive Summary
This study evaluates whether open-source large language models can extract comorbidities from Italian Electronic Health Records in a zero-shot multilingual setting. The research compares six LLMs against traditional regex-based approaches across 8,223 Italian EHRs for five key comorbidities. Results show that while some models achieve reasonable accuracy for specific conditions, none consistently match the performance of established pattern-matching methods. The study concludes that current zero-shot LLMs are not reliable substitutes for traditional approaches in critical healthcare information extraction tasks.

## Method Summary
The study employed zero-shot inference using six open-source LLMs (OpenLLaMA 3B/7B, Mistral 7B, Mixtral 8x7B, Qwen2.5 3B/7B) to classify comorbidities from Italian EHR free-text. Each comorbidity was processed individually per EHR record to avoid task interference. Performance was evaluated against regex-based automated annotations (8,223 records) and manual clinician annotations (100 records) using accuracy, precision, recall, F1-score, and confusion matrices. The on-premises deployment with HPC/GPUs ensured data privacy compliance.

## Key Results
- Mistral 7B achieved the highest overall accuracy (82.67%) but still underperformed regex baselines
- Qwen2.5 models showed precision/recall of 0 across most comorbidities, failing to produce true positives
- Larger models like Mixtral 8x7B (33.13% accuracy) underperformed smaller Mistral 7B
- All models exhibited systematic failures in imbalanced classification scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Zero-shot multilingual transfer underperforms on domain-specific clinical text in non-English languages.
- **Mechanism:** LLMs trained on general multilingual corpora exhibit distribution shift when applied to Italian clinical EHRs, which contain specialized terminology, abbreviations, and linguistic patterns not well-represented in pretraining data.
- **Core assumption:** The gap stems from insufficient exposure to Italian clinical language during pretraining, not from architectural limitations.
- **Evidence anchors:**
  - [abstract] "LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases"
  - [section 5.1] Qwen2.5 models "could not produce true positive class when automated data was compared" with precision/recall of 0 across most comorbidities
  - [corpus] Related work (Leveraging Open-Source LLMs for Clinical Information Extraction) similarly finds proprietary LLMs outperform open-source models in clinical NLP, suggesting domain knowledge gaps
- **Break condition:** Performance degrades further on low-resource clinical languages or rare comorbidities with fewer training exemplars in pretraining corpora.

### Mechanism 2
- **Claim:** Larger model size does not guarantee better multilingual clinical information extraction.
- **Mechanism:** Domain-specific knowledge density matters more than raw parameter count; Mixtral 8x7B (MoE architecture) underperformed Mistral 7B, suggesting expert routing or training data composition may not align with clinical Italian.
- **Core assumption:** The relationship between scale and performance is domain-dependent and language-dependent.
- **Evidence anchors:**
  - [section 5.1] Mixtral 8x7B achieved 33.13% overall accuracy vs regex, while Mistral 7B achieved 82.67%
  - [section 5.1] "Mistral model family generally show a decrease in the classification accuracy w.r.t regular expression results of the comorbidities as the model size increases"
  - [corpus] Weak direct evidence on MoE for clinical multilingual tasks; assumption based on this paper's findings
- **Break condition:** Scale benefits may re-emerge with domain-specific fine-tuning or when task complexity exceeds a threshold not tested here.

### Mechanism 3
- **Claim:** Surface-level accuracy metrics mask systematic classification failures in imbalanced clinical datasets.
- **Mechanism:** Models exploit class imbalance by predicting majority class (negative for comorbidity) or defaulting to positive predictions, achieving high accuracy without semantic understanding.
- **Core assumption:** Confusion matrix analysis reveals true model behavior beyond aggregate accuracy.
- **Evidence anchors:**
  - [section 5.2] OpenLLaMA 3B "always classifies the comorbidities as positives" on manual annotation subset; Mistral 7B "classifying most of comorbidities as negatives"
  - [section 5.1] OpenLLaMA 3B had perfect recall (1.0) but very low precision across comorbidities
  - [corpus] Statement-Tuning paper notes encoder-only models struggle with zero-shot generalization, paralleling these zero-shot LLM limitations
- **Break condition:** Balanced evaluation sets or per-class F1 thresholds would expose this behavior earlier in deployment pipelines.

## Foundational Learning

- **Concept: Zero-shot transfer in multilingual NLP**
  - Why needed here: The paper evaluates whether models can extract Italian clinical information without Italian-specific training; understanding this helps set realistic expectations for cross-lingual deployment.
  - Quick check question: Can you explain why a model trained on 90% English data might fail on Italian clinical text even if it's labeled "multilingual"?

- **Concept: Precision-recall tradeoff in imbalanced classification**
  - Why needed here: With 856 positive vs 7,367 negative cases for atrial fibrillation, aggregate accuracy is misleading; precision and F1 are critical for healthcare reliability.
  - Quick check question: If a model predicts "no comorbidity" 100% of the time on a dataset with 10% positive rate, what accuracy does it achieve? Why is this problematic?

- **Concept: On-premises vs API-based LLM deployment**
  - Why needed here: Healthcare data privacy constraints forced open-source, on-premises deployment; this limits model selection and requires understanding tradeoffs.
  - Quick check question: What are two tradeoffs between using GPT-4 via API versus Mistral 7B on-premises for processing patient records?

## Architecture Onboarding

- **Component map:** ETL Pipeline (Oracle + Python) -> Anamnesis dataframe (hospital ID, EHR free text) -> Regex Annotation Layer -> Baseline classification for 5 comorbidities -> Manual Annotation Layer -> 100 false-classified samples validated by clinicians -> LLM Inference Layer -> 6 models, zero-shot, one comorbidity per inference -> Evaluation Layer -> Accuracy, precision, recall, F1, confusion matrices

- **Critical path:**
  1. Data ingestion via ETL (8,223 records)
  2. Regex pattern matching (baseline labels)
  3. Manual validation of false negatives (ground truth subset)
  4. LLM inference per comorbidity per record
  5. Metric computation against both regex and manual labels

- **Design tradeoffs:**
  - Single-comorbidity inference increases accuracy but multiplies inference cost by 5x
  - Regex requires domain expert time for pattern creation; LLMs require no upfront rules but fail silently
  - On-premises deployment ensures privacy but limits model selection to open-source

- **Failure signatures:**
  - Model always predicts class 0 or class 1 -> check confusion matrix, not just accuracy
  - F1 = 0 despite non-zero accuracy -> model missing all true positives
  - Large accuracy gap between automated and manual comparison -> model exploiting class imbalance

- **First 3 experiments:**
  1. Replicate zero-shot inference with Mistral 7B on a 100-sample subset; verify confusion matrix patterns match paper findings (majority negative predictions).
  2. Test whether few-shot prompting (2-3 Italian clinical examples per comorbidity) improves F1 scores without fine-tuning.
  3. Implement a hybrid approach: use regex as primary classifier, LLM as secondary validator on regex-negative cases to catch false negatives.

## Open Questions the Paper Calls Out

- **Question:** Would in-context learning (ICL) or fine-tuning enable open-source LLMs to match or exceed regular expression performance for Italian EHR comorbidity extraction?
- **Basis in paper:** [explicit] Conclusion states: "In the future, we will explore In-Context learning (ICL) approaches and will also consider fine-tuning an LLM model for IR from EHRs to improve its language processing capabilities and enhance trustworthiness."
- **Why unresolved:** The study only evaluated zero-shot settings; no adaptation techniques were tested.
- **What evidence would resolve it:** Comparative evaluation of ICL (few-shot prompting) and fine-tuned models against the same regexp and manual annotation baselines.

- **Question:** How do closed-source multilingual LLMs (e.g., GPT-4, Gemini, Claude) compare to open-source alternatives for Italian healthcare information extraction?
- **Basis in paper:** [inferred] Paper explicitly excluded closed-source models due to privacy/on-premises requirements (Section 4), leaving their relative performance unknown.
- **Why unresolved:** Privacy constraints prevented direct comparison; closed-source models may have stronger multilingual capabilities.
- **What evidence would resolve it:** Benchmarking closed-source models on the same 8,223 EHR dataset (or synthetic equivalent) against regexp and manual annotations.

- **Question:** Can prompt engineering techniques enable non-expert clinical users to achieve reliable zero-shot extraction performance?
- **Basis in paper:** [inferred] Authors deliberately avoided prompt optimization to simulate real clinician usage, noting "different prompt engineering approaches could be employed to increase the accuracy" (Section 6).
- **Why unresolved:** The study used a standard prompt without optimization; the gap between naive and engineered prompts remains unquantified.
- **What evidence would resolve it:** Systematic evaluation of prompt engineering strategies (chain-of-thought, role prompting, examples) with the same models and dataset.

- **Question:** Do LLMs generalize to other languages and healthcare documentation styles beyond Italian EHRs in this specific hospital system?
- **Basis in paper:** [inferred] Title asks "Are LLMs Truly Multilingual?" but experiments are limited to Italian EHRs from a single institution (IRCCS Humanitas).
- **Why unresolved:** No cross-lingual or cross-institutional validation was performed.
- **What evidence would resolve it:** Replicating the methodology on EHRs in other languages (e.g., Spanish, German) and different healthcare systems.

## Limitations
- Single Italian healthcare institution dataset limits generalizability to other clinical languages and domains
- Zero-shot approach without prompt tuning may underestimate LLM potential despite reflecting real-world privacy constraints
- Regex baseline may be imperfect and not represent optimal rule-based approaches

## Confidence
- **High confidence:** LLMs cannot consistently match regex performance for Italian clinical information extraction
- **Medium confidence:** Larger models do not guarantee better multilingual clinical information extraction performance
- **Low confidence:** Mistral 7B is the "best overall performer" - depends heavily on chosen evaluation methodology

## Next Checks
1. **Prompt optimization validation:** Test whether carefully engineered few-shot prompts or chain-of-thought reasoning templates improve F1 scores for the most challenging comorbidities (particularly kidney failure and COPD) without requiring full fine-tuning.

2. **Cross-institutional generalization test:** Apply the same evaluation framework to EHR data from a different Italian healthcare provider or a different clinical domain to assess whether the observed LLM limitations are universal or institution-specific.

3. **Hybrid approach evaluation:** Implement a two-stage classification system where regex patterns handle obvious cases while LLMs process ambiguous cases, measuring whether this combination outperforms either approach alone in terms of both accuracy and clinical completeness.