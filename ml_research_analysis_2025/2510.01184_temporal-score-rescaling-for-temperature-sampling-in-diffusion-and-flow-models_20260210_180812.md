---
ver: rpa2
title: Temporal Score Rescaling for Temperature Sampling in Diffusion and Flow Models
arxiv_id: '2510.01184'
source_url: https://arxiv.org/abs/2510.01184
tags:
- sampling
- diffusion
- distribution
- score
- flow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Temporal Score Rescaling (TSR), a training-free\
  \ method to control the sampling diversity of denoising diffusion and flow matching\
  \ models. The key insight is that rescaling the learned score functions at each\
  \ denoising step enables \"local\" temperature scaling\u2014controlling sample variance\
  \ around local modes while preserving global distribution structure."
---

# Temporal Score Rescaling for Temperature Sampling in Diffusion and Flow Models

## Quick Facts
- **arXiv ID:** 2510.01184
- **Source URL:** https://arxiv.org/abs/2510.01184
- **Reference count:** 40
- **Primary result:** Training-free temporal score rescaling method that improves sampling diversity control across diffusion and flow matching models for 5 diverse tasks

## Executive Summary
This paper introduces Temporal Score Rescaling (TSR), a training-free method to control the sampling diversity of denoising diffusion and flow matching models. The key insight is that rescaling the learned score functions at each denoising step enables "local" temperature scaling—controlling sample variance around local modes while preserving global distribution structure. The method applies to both deterministic and stochastic samplers and works with any pre-trained model without requiring fine-tuning.

The authors derive a time-dependent score rescaling function, validated on toy data (mixture of Gaussians, 2D distributions) and then applied to five diverse tasks: image generation (Stable Diffusion), protein design, depth estimation, pose prediction, and robot manipulation. Across these applications, TSR consistently improves performance by sampling from sharper (depth/pose) or slightly flatter (image generation) distributions than the training data.

## Method Summary
TSR rescales the learned score function at each denoising step using a time-dependent factor $r_t(k, \sigma)$ derived from the signal-to-noise ratio (SNR). For noise-prediction models, the predicted noise is scaled as $\tilde{\epsilon} = r_t \cdot \epsilon_\theta$. For flow-matching velocity prediction, the score is computed from velocity, rescaled, then converted back. The method preserves global multimodal structure while adjusting local variance, and is compatible with both deterministic (ODE) and stochastic (SDE) samplers.

## Key Results
- 2.3% improvement in depth estimation metrics (AbsRel, δ1)
- Better pose prediction accuracy with reduced mean angular error
- 1.87 FID and 0.25 CLIP score improvement in image generation
- Increased protein designability scores while preserving diversity
- Demonstrated superiority over Constant Noise Scaling (CNS) in preserving global mode structure

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Scaling the learned score function by a time-dependent factor controls the local variance of the sampled distribution.
- **Mechanism:** The method derives a linear relationship between the score of the original data distribution and the score of a "locally scaled" distribution (where variance $\Sigma$ is scaled by $1/k$ while preserving means). By multiplying the model's output score $\nabla \log p_t(x)$ by a rescaling factor $r_t(k, \sigma)$ at each step, the sampler effectively draws samples from this sharper ($k>1$) or flatter ($k<1$) distribution.
- **Core assumption:** The data distribution can be locally approximated as a mixture of well-separated Gaussians, such that the score relationship derived for a single Gaussian holds locally.
- **Break condition:** If modes are not well-separated or the distribution is highly non-Gaussian locally, the approximation error increases.

### Mechanism 2
- **Claim:** TSR preserves global multimodal structure better than Constant Noise Scaling (CNS).
- **Mechanism:** Unlike CNS, which applies a constant noise reduction that suppresses exploration globally, TSR uses a signal-to-noise ratio (SNR) dependent schedule. This allows the sampler to maintain sufficient noise for global exploration early in the process (high $t$) while sharpening modes locally later (low $t$), preventing mode collapse.
- **Core assumption:** The variance of the data distribution $\sigma$ (or an effective surrogate) is known or estimated to set the schedule sensitivity.
- **Break condition:** If the hyperparameter $\sigma$ is set too large, rescaling may occur too early, potentially affecting global structure.

### Mechanism 3
- **Claim:** The method is compatible with both deterministic (ODE) and stochastic (SDE) samplers.
- **Mechanism:** Since diffusion and flow models ultimately rely on predicting a score (or a linearly related quantity like velocity $v$ or noise $\epsilon$), TSR operates by simply rescaling this predicted vector. It does not rely on injecting noise (unlike MCMC correctors), making it applicable to deterministic solvers like DDIM or Euler ODE.
- **Core assumption:** The conversion between the model's prediction parameterization (e.g., $v$-prediction vs $\epsilon$-prediction) and the score is linear.
- **Break condition:** If the sampler implementation does not expose the raw score/velocity prediction for rescaling before the update step, integration is blocked.

## Foundational Learning

- **Concept:** **Score Functions ($\nabla_x \log p(x)$)**
  - **Why needed here:** The entire method hinges on manipulating the "score," which points towards higher probability density. You must understand that diffusion models learn this vector field to reverse noise into data.
  - **Quick check question:** Does the model predict the image pixels directly, or the gradient direction (score) to denoise them?

- **Concept:** **Signal-to-Noise Ratio (SNR) in Forward Processes**
  - **Why needed here:** The rescaling factor $r_t$ is a function of $\eta_t = \alpha_t^2 / \sigma_t^2$ (SNR). You need to grasp that as time $t$ evolves, the balance between signal (data) and noise changes, dictating when to apply sharpening.
  - **Quick check question:** At which timestep $t$ (early or late) does the noisy data look most like pure Gaussian noise?

- **Concept:** **Flow Matching vs. Diffusion Parameterization**
  - **Why needed here:** The paper applies TSR to Flow Matching (predicting velocity $v$) and Diffusion (predicting noise $\epsilon$). Implementing the method requires converting these outputs to scores.
  - **Quick check question:** In Flow Matching, is the model predicting the noise $\epsilon$ or the velocity $v$ of the probability flow?

## Architecture Onboarding

- **Component map:** Pre-trained model -> TSR Module (computes $r_t$) -> Rescaled score/velocity -> Sampler
- **Critical path:**
  1. Identify the model type (Diffusion vs. Flow) to select the correct score conversion formula (Eq. 7 vs Eq. 9).
  2. Calculate SNR $\eta_t$ at the current timestep.
  3. Compute $r_t$ and multiply the model output.
  4. Pass rescaled output to the standard sampler.
- **Design tradeoffs:**
  - **$k > 1$ (Sharpening):** Reduces variance, improves precision (better for Depth/Pose). Risk: Over-confident wrong predictions.
  - **$k < 1$ (Flattening):** Increases variance, improves diversity/detail (better for Image Generation). Risk: Noisy/artifacted outputs.
  - **$\sigma$ Parameter:** Controls *when* rescaling happens. Low $\sigma$ acts only at the final steps; high $\sigma$ acts earlier.
- **Failure signatures:**
  - **Mode Collapse:** If implemented incorrectly (e.g., like CNS), valid diverse samples disappear.
  - **Gradient Explosion/Diminution:** If $r_t$ calculation is numerically unstable at extreme $t$.
  - **Incompatibility:** Applying noise scaling logic (CNS) to a deterministic ODE sampler will simply fail or yield poor results.
- **First 3 experiments:**
  1. **Toy Validation:** Train a small 2D diffusion model on a Swiss Roll or Checkerboard. Apply TSR with varying $k$ to visually confirm modes are preserved (unlike CNS) while tightness changes.
  2. **Deterministic Sampler Check:** Run Stable Diffusion 3 (Flow Matching) with Euler ODE. Apply TSR ($k \approx 0.93$) and check if FID improves without changing inference steps.
  3. **Precision Task Ablation:** Run a depth estimation model (e.g., Marigold). Set $k > 1$ and verify if AbsRel error decreases compared to standard DDIM.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can TSR be extended to perform global temperature scaling that alters the relative weights of distribution modes, rather than only adjusting the local variance around them?
- **Basis in paper:** [explicit] The authors state in the discussion that "TSR can only alter the 'local' sampling... TSR does not change the weights of the components in a gaussian mixture, only the variance."
- **Why unresolved:** The current mathematical formulation scales the score based on time-dependent noise levels, which inherently preserves the global structure and relative probability of modes learned during training.
- **What evidence would resolve it:** A derivation of a score rescaling function that modifies the probability mass assigned to distinct modes in a multi-modal distribution without requiring model retraining.

### Open Question 2
- **Question:** Can theoretical guarantees for TSR be established for general data distributions beyond the mixture of well-separated isotropic Gaussians?
- **Basis in paper:** [explicit] The authors note that "theoretical guarantees are limited to simpler settings and one may be able to derive a better algorithm for different distributions."
- **Why unresolved:** The current proof relies on the assumption that modes are sufficiently separated to treat them as isolated Gaussian components during the diffusion process.
- **What evidence would resolve it:** A theoretical analysis bounding the approximation error for arbitrary complex distributions, such as continuous manifolds or significantly overlapping modes.

### Open Question 3
- **Question:** How can the optimal rescaling factor $k$ be determined automatically or adaptively for specific tasks, particularly when the base model exhibits low success rates?
- **Basis in paper:** [inferred] The authors observe that using a shared $k$ parameter worsened performance on robot manipulation tasks where the base policy was already weak, suggesting the fixed hyperparameter was suboptimal for those specific instances.
- **Why unresolved:** The current method treats $k$ as a global user-defined hyperparameter, which may fail when the underlying policy's uncertainty or correctness varies significantly across tasks.
- **What evidence would resolve it:** A method that dynamically adjusts $k$ based on the input condition or the model's estimated uncertainty, resulting in recovered or improved performance on low-confidence tasks.

## Limitations
- Assumes data distribution can be locally approximated as mixture of well-separated Gaussians, limiting effectiveness for highly overlapping modes
- Requires careful tuning of hyperparameter $\sigma$ that depends on specific model's noise schedule
- Requires access to raw score/velocity predictions which may not be exposed in all implementations

## Confidence
- **High Confidence:** The core mechanism of temporal score rescaling and its compatibility with both diffusion and flow matching models is well-established through theoretical derivation and empirical validation across five diverse tasks.
- **Medium Confidence:** The superiority over Constant Noise Scaling (CNS) is demonstrated, but the comparison is primarily qualitative in the toy experiments.
- **Medium Confidence:** The claim that TSR is "orthogonal" to classifier-free guidance is supported by the image generation results, but interaction effects with other sampling techniques are not thoroughly explored.

## Next Checks
1. **Cross-Domain Robustness Test:** Apply TSR to a model trained on a distribution with highly overlapping modes (e.g., MNIST digits with significant class overlap) to test the well-separated mode assumption. Compare mode coverage and sample quality against baseline and CNS.

2. **Parameter Sensitivity Analysis:** Systematically vary both $k$ and $\sigma$ across a wider range for each task, creating response surface plots. This would identify optimal regions and test the stability of the claimed improvements.

3. **Integration with Classifier Guidance:** Apply TSR in conjunction with classifier-free guidance on a conditional generation task (e.g., text-to-image with Stable Diffusion). Measure whether the improvements from TSR are additive or multiplicative with guidance weights.