---
ver: rpa2
title: Online Multi-Class Selection with Group Fairness Guarantee
arxiv_id: '2510.21055'
source_url: https://arxiv.org/abs/2510.21055
tags:
- algorithm
- fairness
- online
- allocation
- fractional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies the online multi-class selection problem (OMcS)
  with group fairness constraints, where agents arrive sequentially and must be allocated
  limited resources while maintaining fairness across multiple classes. The work addresses
  two key limitations in prior literature: (1) lack of a lossless rounding scheme
  to convert fractional to integral solutions without performance loss, and (2) the
  challenge of handling agents belonging to multiple classes simultaneously.'
---

# Online Multi-Class Selection with Group Fairness Guarantee

## Quick Facts
- **arXiv ID**: 2510.21055
- **Source URL**: https://arxiv.org/abs/2510.21055
- **Reference count**: 40
- **Primary result**: Proposes relax-and-round framework with lossless online rounding for online multi-class selection with group fairness guarantees

## Executive Summary
This paper addresses the online multi-class selection problem with group fairness constraints, where agents arrive sequentially and must be allocated limited resources while maintaining fairness across multiple classes. The authors tackle two key limitations in prior work: the lack of a lossless rounding scheme to convert fractional to integral solutions without performance loss, and the challenge of handling agents belonging to multiple classes simultaneously. They propose a relax-and-round framework with novel algorithms that achieve optimal trade-offs between fairness and efficiency, including both deterministic and randomized approaches for quantity-based and utility-based fairness metrics.

## Method Summary
The authors present a relax-and-round framework for online multi-class selection with group fairness. The method consists of two phases: (1) a relaxation phase using carefully designed threshold functions to compute fractional allocations that balance fairness and efficiency, and (2) a lossless online rounding scheme that converts these fractional decisions to integral ones while preserving expected performance. For quantity-based fairness (GFQ), they use a set-aside mechanism that reserves capacity for fairness constraints before efficiency-driven allocation. For utility-based proportional fairness (β-PF), they employ multiple threshold functions with a parameter b controlling the fairness-efficiency trade-off. The framework also includes a learning-augmented variant that incorporates untrusted machine learning predictions to improve fairness while maintaining worst-case guarantees.

## Key Results
- Proposes a lossless online rounding scheme that converts fractional allocations to integral ones without expected performance degradation
- Achieves optimal competitive ratios for both quantity-based and utility-based group fairness constraints
- Introduces learning-augmented variant (LiLA) that improves fairness when advice is accurate while maintaining worst-case guarantees
- Handles agents belonging to multiple classes simultaneously through synchronized utilization tracking

## Why This Works (Mechanism)

### Mechanism 1
The lossless online rounding scheme converts fractional allocation decisions to integral ones without expected performance degradation. The ROUNDING procedure maintains synchronization between fractional utilization level z_t and integral item index κ_t. When the fractional solution allocates item ⌈z_{t-1}⌉, the rounding allocates that item with probability x̃_t/(⌈z_{t-1}⌉ - z_{t-1}). When fractional allocation crosses an integer boundary, the algorithm either completes the current item with probability 1 or transitions to the next item with a computed probability that preserves expectation. This ensures the integral algorithm achieves the same expected performance as any fractional solution.

### Mechanism 2
The set-aside mechanism guarantees quantity-based fairness by reserving capacity before efficiency-driven allocation. Reserve M = Σm_j units for GFQ constraints. Accept the first m_j agents from each class unconditionally. Allocate remaining B-M items via threshold-based decisions. For β-PF, use K + K(K-1)/2 + 1 threshold functions (class-specific, pairwise, global) with parameter b ∈ [0,1] controlling fairness-efficiency trade-off. As b → 1, the allocation is governed solely by the global threshold function; as b → 0, the algorithm excludes the global threshold function entirely.

### Mechanism 3
The learning-augmented variant (LiLA) improves fairness when advice is accurate while maintaining worst-case guarantees. At each time step, compute robust decision x̄_t from the base algorithm and predicted decision x̂_t from advice. Combine as x_t = ρx̂_t + (1-ρ)x̄_t where ρ = (β/(1+ϵ) - 1)/(β-1). When ϵ → 0, ρ → 1 (trust advice); when ϵ = β-1, ρ → 0 (ignore advice). This achieves (1+ϵ)-consistency and (1+ϵ)(β-1)/ϵ-robustness for proportional fairness.

## Foundational Learning

- **Competitive Ratio (CR):**
  - Why needed here: CR = OPT(I)/E[ALG(I)] quantifies worst-case efficiency loss; all fairness guarantees are conditioned on achieving target CR.
  - Quick check question: Can you explain why competitive ratio ≥ 1 for maximization problems?

- **Online Selection with Irrevocable Decisions:**
  - Why needed here: Agents arrive sequentially; decisions cannot be undone. This distinguishes OMcS from offline fair allocation.
  - Quick check question: Why does adversarial arrival order make fairness harder than random order?

- **Proportional Fairness (β-PF):**
  - Why needed here: Core fairness metric; ensures average utility ratio across classes stays within β factor.
  - Quick check question: How does β-PF relate to Nash Social Welfare?

## Architecture Onboarding

- **Component map:**
  Set-Aside Manager -> Fractional Solver -> Rounding Module -> Threshold Function Generator -> LiLA Combiner

- **Critical path:** Agent arrival → Set-Aside Manager check → (constraint unsatisfied: accept) / (satisfied: Fractional Solver → Rounding Module) → output decision

- **Design tradeoffs:**
  - GFQ vs. β-PF: GFQ simpler but rigid; β-PF flexible but requires tuning b
  - Deterministic vs. Randomized: Deterministic optimal for GFQ but worse CR in small inventory; randomized matches fractional CR
  - Consistency vs. Robustness in LiLA: Lower ϵ improves performance with good advice but risks worse guarantees with bad advice

- **Failure signatures:**
  - Rounding divergence: E[ALG(I)] ≠ fractional utility → check ROUNDING probability calculations
  - GFQ violation: Class j receives < m_j → check if M > B or early arrivals misclassified
  - β-PF degradation: Empirical β > theoretical β(b) → verify threshold function parameters
  - LiLA catastrophic failure: ϵ too small + adversarial advice → robustness unbounded

- **First 3 experiments:**
  1. Validate lossless rounding: Run Algorithm 1 vs. FRAC-GFQ on synthetic data; compare E[Σv_t·x_t] to fractional utility. Expect < 1% gap.
  2. Test fairness-efficiency trade-off: Vary b ∈ {0, 0.25, 0.5, 0.75, 1.0} in R-SETASIDE-PF; measure α(b) and β(b). Verify Pareto frontier.
  3. Stress-test LiLA: Vary adversarial probability ξ ∈ [0,1] and ϵ ∈ [0.1, β-1]; plot consistency vs. robustness. Identify operating points where LiLA outperforms robust-only baseline.

## Open Questions the Paper Calls Out

### Open Question 1
Can the relax-and-round framework and lossless rounding scheme be extended to handle non-adversarial arrival models, such as the random order model or stochastic i.i.d. settings? The current analysis and threshold functions are explicitly designed for adversarial inputs to guarantee worst-case competitive ratios, and it is unclear if the structure of the set-aside mechanism remains optimal under distributional assumptions.

### Open Question 2
Is it possible to generalize the lossless online rounding scheme and fairness guarantees to multi-resource settings, such as combinatorial auctions? The current model assumes a single resource type (B units), and the lossless rounding scheme relies on tracking a single cumulative utilization level z_t, which does not directly map to multi-dimensional resource constraints.

### Open Question 3
How do the proposed fairness guarantees translate to mechanism design settings where agents are strategic and may misreport their valuations or class memberships? The current model assumes agents truthfully report valuations v_t and label sets J_t; strategic behavior requires incentive compatibility constraints which may conflict with the set-aside mechanism's allocation rules.

### Open Question 4
Can the algorithms maintain optimal competitive ratios if the fluctuation ratios θ_j are unknown or if the valuation bounds are incorrect? The design of the threshold functions and the admission logic heavily depend on these pre-defined bounds; if θ_j is misspecified, the competitive analysis and fairness guarantees may no longer hold.

## Limitations

- The rounding scheme assumes independent random seeds per round for non-reusable resources, which may be computationally expensive in practice
- The exact implementation details for computing threshold functions in β-PF and the numerical solver for the equation system in Theorem 3.1 are not provided
- The framework assumes agents truthfully report valuations and class memberships, without addressing strategic behavior

## Confidence

- **High Confidence**: The set-aside mechanism for GFQ and the theoretical competitive ratio guarantees are well-established
- **Medium Confidence**: The randomized algorithms achieve the same competitive ratios as fractional solutions, but empirical validation is needed
- **Low Confidence**: Implementation details for computing threshold functions and the numerical solver are not provided

## Next Checks

1. Implement Algorithm 1 + Algorithm 2 and compare E[Σv_t·x_t] against fractional utility on synthetic data with θ_j = {5, 10, 15}, B = 100. Expect < 1% gap.

2. Vary b ∈ {0, 0.25, 0.5, 0.75, 1.0} in R-SETASIDE-PF and measure α(b) and β(b). Verify empirical Pareto frontier matches theoretical bounds.

3. Simulate adversarial advice with probability ξ ∈ [0,1] and vary ϵ ∈ [0.1, β-1]. Plot consistency vs. robustness metrics and compare against robust-only baseline.