---
ver: rpa2
title: Mechanistic Insights into Grokking from the Embedding Layer
arxiv_id: '2505.15624'
source_url: https://arxiv.org/abs/2505.15624
tags:
- train
- uniform
- embedding
- random
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Mechanistic Insights into Grokking from the Embedding Layer

## Quick Facts
- **arXiv ID:** 2505.15624
- **Source URL:** https://arxiv.org/abs/2505.15624
- **Authors:** H. V. AlquBoj; Hilal AlQuabeh; Velibor Bojkovic; Munachiso Nwadike; Kentaro Inui
- **Reference count:** 40
- **Primary result:** Embedding layers introduce optimization challenges that delay generalization in grokking scenarios.

## Executive Summary
This paper investigates why grokking—a phenomenon where models suddenly generalize after prolonged overfitting—is triggered by the embedding layer in neural networks. Through a combination of theoretical analysis and empirical experiments on modular arithmetic tasks, the authors identify two key mechanisms: rare token stagnation due to sparse gradient updates combined with uniform weight decay, and bilinear coupling between embeddings and subsequent linear layers that creates optimization difficulties. They propose an adaptive learning rate strategy (Adam-LR) that scales the embedding learning rate to mitigate these effects and accelerate convergence.

## Method Summary
The authors study grokking behavior in two-layer MLPs trained on modular arithmetic tasks (addition, multiplication, division, and squared sum modulo a prime). They compare models with and without embedding layers, analyze the update dynamics of token embeddings under different sampling strategies (uniform, random, and skewed), and propose an adaptive learning rate approach (Adam-LR) that scales the embedding learning rate relative to the weight matrix. Experiments measure training and validation accuracy over time to observe grokking patterns, with the Adam-LR variant adjusting the learning rate ratio based on spectral properties of the embedding and weight matrices.

## Key Results
- Embedding layers introduce delayed generalization (grokking) in modular arithmetic tasks.
- Rare tokens stagnate due to sparse gradient updates and uniform weight decay, creating a delay in learning.
- Bilinear coupling between embeddings and first linear layer introduces saddle points and optimization difficulties.
- Adam-LR (scaling embedding learning rate by factor of 10) accelerates convergence and mitigates grokking delays.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding layers induce delayed generalization (grokking) because rare tokens undergo stagnation due to the interaction between sparse gradient updates and uniform weight decay.
- **Mechanism:** In a mini-batch, only present tokens receive gradient updates. Tokens absent from the batch are updated *only* via weight decay (shrinking them). If a token $i$ has low sampling probability $p_i$, the expected update $\mathbb{E}[\Delta e_i] \approx -\eta\lambda e_i$ (decay) dominates over the gradient term $-\eta p_i \nabla L$. This imbalance prevents rare tokens from learning useful representations until late in training.
- **Core assumption:** The model uses standard gradient descent with weight decay and non-uniform token sampling.
- **Evidence anchors:**
  - [abstract]: "Embedding update dynamics, where rare tokens stagnate due to sparse gradient updates and weight decay."
  - [section 4.1]: "While gradients contribute to tokens only probabilistically, weight decay affects all embeddings uniformly... $p_i$ plays important role in reduction of the expected loss."
  - [corpus]: Related work "Tracing the Path to Grokking" highlights embedding variance, supporting the centrality of embedding dynamics, though it does not validate the specific decay-to-gradient ratio.
- **Break condition:** If the dataset is small enough that every token appears in every batch ($p_i \approx 1$), or if weight decay is set to zero, this stagnation mechanism should disappear.

### Mechanism 2
- **Claim:** The "bilinear coupling" between the embedding matrix $E$ and the first linear layer $W$ introduces optimization difficulties (saddle points) that delay convergence.
- **Mechanism:** The forward pass involves a product $W \cdot E$. This bilinearity means the gradient for $E$ depends on $W$ and vice versa. The curvature of the loss landscape differs significantly between $E$ and $W$ (spectral heterogeneity), creating saddle points where standard optimizers stall.
- **Core assumption:** The model architecture concatenates an embedding lookup with an immediate linear projection (e.g., MLP or Transformer attention input).
- **Evidence anchors:**
  - [abstract]: "Bilinear coupling... introduces saddle points and increases sensitivity to initialization."
  - [section 4.3]: "In bilinear models... embedding gradients are tightly coupled... poor updates to $E$ degrade $W$, and vice versa."
  - [corpus]: Related paper "Why Transformers Need Adam" supports the existence of block heterogeneity in Hessians, consistent with the "bilinear coupling" landscape described here.
- **Break condition:** If the interaction is linearized (e.g., freezing one layer) or if the layers are excessively regularized to behave independently, the coupling effect breaks down.

### Mechanism 3
- **Claim:** Accelerating convergence requires balancing the effective update magnitudes by scaling the learning rate ratio $\frac{\eta_E}{\eta_W}$ relative to the spectral norms of the weights.
- **Mechanism:** Because $\|\nabla E\| \propto \sigma_{\max}(W)$ and $\|\nabla W\| \propto \sigma_{\max}(E)$, the "speed" of learning differs. To equalize updates, the learning rate for embeddings $\eta_E$ must compensate for the spectral difference and update frequency.
- **Core assumption:** Standard initialization results in $\sigma_{\max}(E) \gg \sigma_{\max}(W)$, or updates frequencies $f_W > f_E$.
- **Evidence anchors:**
  - [abstract]: "We prove that an adaptive learning rate ratio... mitigates bilinear coupling effects."
  - [proposition 4.1]: Derives the ratio $c \propto \frac{\sigma_{\max}(E)}{\sigma_{\max}(W)} \cdot \frac{f_W}{f_E}$.
  - [section 5.2]: Empirical results show Adam-LR (scaling $\eta_E$ by factor 10) accelerates grokking compared to standard Adam.
- **Break condition:** If initialization schemes are changed such that spectral norms are already balanced, or if an optimizer automatically adapts per-parameter learning rates perfectly (though the authors argue standard Adam is insufficient here).

## Foundational Learning

- **Concept:** **Bilinear Optimization Landscapes**
  - **Why needed here:** To understand why the interaction between $E$ and $W$ is harder to optimize than a standard linear layer, creating saddle points rather than simple convex basins.
  - **Quick check question:** How does the Hessian spectrum of a bilinear product ($W \cdot E$) differ from that of a single linear layer applied to fixed inputs?

- **Concept:** **Spectral Norm / Singular Values ($\sigma_{\max}$)**
  - **Why needed here:** The paper's core remedy relies on balancing learning rates based on the largest singular values of the embedding and weight matrices. Without this, one cannot implement the proposed fix.
  - **Quick check question:** If $\sigma_{\max}(E)$ is significantly larger than $\sigma_{\max}(W)$, how does this affect the magnitude of the gradients flowing through $W$ versus $E$?

- **Concept:** **Token Sampling Probability & Variance**
  - **Why needed here:** Mechanism 1 relies entirely on the mismatch between uniform weight decay and probabilistic (sparse) gradient updates for rare tokens.
  - **Quick check question:** In a dataset with 100 tokens, if token $A$ appears in 50% of samples and token $B$ in 0.1%, how does the expected update step for $B$ differ from $A$ under weight decay?

## Architecture Onboarding

- **Component map:** Input tokens → Embedding layer ($E$) → Bilinear interface with first linear layer ($W$) → Output layer → Optimizer (Adam-LR)
- **Critical path:** Monitor the **gradient variance** and **Hessian eigenvalues** of the embedding layer ($E$) relative to the first linear layer ($W$). If $E$'s updates are sparse (due to sampling) or small (due to spectral mismatch), convergence stalls.
- **Design tradeoffs:**
  - **Uniform vs. Random Sampling:** Uniform sampling (covering all tokens) minimizes variance and speeds up grokking (evidence: Section 5.1), but may be infeasible for massive vocabularies.
  - **High $\eta_E$ vs. Stability:** Increasing the embedding learning rate ($c \approx 10$) accelerates convergence but risks instability if set too high (sensitivity shown in Figure 5).
- **Failure signatures:**
  - **Stagnant Rare Tokens:** Training accuracy reaches 100% quickly, but validation accuracy remains at random chance for $10^4$+ steps (Grokking).
  - **Embedding Collapse:** If weight decay is too high and sampling probability is too low, rare token embeddings may shrink to near-zero vectors.
- **First 3 experiments:**
  1. **Ablation (One-hot vs. Embedding):** Replicate Figure 2. Train an MLP on modular arithmetic with one-hot inputs (no embedding) vs. learned embeddings to confirm that embeddings introduce the grokking delay.
  2. **Frequency Analysis:** Plot the L2 norm of embeddings for "frequent" vs. "rare" tokens over time to verify that rare tokens are decaying/stagnating while frequent ones are learning (validating Mechanism 1).
  3. **LR Ratio Sensitivity:** Implement the proposed Adam-LR strategy. Run a sweep on the ratio $c = \eta_E / \eta_W$ (e.g., $1, 5, 10, 20$) to see if $c \approx 10$ minimizes grokking delay on your specific dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do the embedding-weight coupling dynamics and the Adam-LR optimizer transfer to Transformer architectures, where bilinear interactions in attention mechanisms introduce additional structural complexity?
- **Basis in paper:** [explicit] The Discussion states: "it leaves open how these insights transfer to more complex architectures such as Transformers... Extending our framework to the Transformer setting is a promising direction for future work."
- **Why unresolved:** The paper deliberately restricts analysis to MLPs to isolate coupling effects, avoiding attention's added complexity.
- **What evidence would resolve it:** Experiments applying Adam-LR to Transformer attention layers, measuring convergence and generalization on comparable tasks.

### Open Question 2
- **Question:** What is the principled theoretical basis for selecting the learning rate ratio c = η_E/η_W across varying architectures, embedding dimensions, and task complexities beyond the empirically chosen c = 10?
- **Basis in paper:** [inferred] Proposition 4.1 gives proportionality involving singular values and update frequencies, but the specific value c = 10 is set empirically via sensitivity analysis without theoretical justification.
- **Why unresolved:** The proposition provides proportionality, not exact values; sensitivity analysis shows optimal c varies by task without a principled selection mechanism.
- **What evidence would resolve it:** Theoretical convergence rate analysis as a function of c, validated across architectures with varying singular value ratios.

### Open Question 3
- **Question:** How do weight decay λ and token sampling probability p_i jointly determine embedding convergence time and generalization behavior?
- **Basis in paper:** [explicit] Page 6 states: "the dependence on p_i is coupled with weight decay, which explains why these two parameters are important to study more deeply to draw a conclusion about grokking."
- **Why unresolved:** The paper analyzes mechanisms separately; Equation 6 shows coupling but doesn't yield a closed-form relationship.
- **What evidence would resolve it:** Systematic experiments varying λ and p_i jointly, combined with theoretical bounds on their coupled effects.

### Open Question 4
- **Question:** Do the observed embedding dynamics and bilinear coupling effects extend to natural language and non-algorithmic domains where token frequencies follow complex distributions (e.g., Zipfian)?
- **Basis in paper:** [inferred] All experiments use algorithmic datasets; Appendix C.3 notes frequency localization diminishes in complex tasks like modular division, suggesting limits of the current analysis.
- **Why unresolved:** Claims are validated only on synthetic algorithmic tasks with controlled token distributions; real-world distributions may exhibit different dynamics.
- **What evidence would resolve it:** Experiments on NLP tasks with natural token frequency distributions, comparing grokking dynamics to algorithmic settings.

## Limitations
- Theoretical analysis assumes simplified bilinear model (MLP with single embedding layer), may not generalize to Transformers.
- Connection between toy modular arithmetic tasks and real-world grokking scenarios is asserted but not empirically validated beyond synthetic domain.
- Adam-LR fix shows empirical acceleration but robustness across different dataset sizes, embedding dimensions, and architectures is not demonstrated.

## Confidence
- **Mechanism 1 (Rare token stagnation):** Medium - Theory is mathematically sound given assumptions, supported by ablation experiments, but relies on idealized conditions.
- **Mechanism 2 (Bilinear coupling/saddle points):** Medium - Existence of coupling and potential optimization difficulties is well-grounded, but lacks direct empirical evidence (e.g., Hessian spectra).
- **Mechanism 3 (Adaptive learning rate):** High - Theoretical derivation is rigorous, and empirical results strongly support the claim.

## Next Checks
1. **Hessian Spectrum Analysis:** Compute and visualize the Hessian eigenvalues for the embedding and weight matrices during training to directly test whether bilinear coupling creates pathological saddle points.
2. **Frequency-Based Embedding Dynamics:** For a given dataset, classify tokens by frequency and plot the L2 norm of their embeddings over training time to verify rare tokens are decaying/stagnating while frequent tokens are learning.
3. **Architecture Ablation:** Replace the MLP with a Transformer encoder (or another non-bilinear architecture) and test whether Adam-LR strategy and observed grokking dynamics still hold.