---
ver: rpa2
title: 'Accounting for Uncertainty in Machine Learning Surrogates: A Gauss-Hermite
  Quadrature Approach to Reliability Analysis'
arxiv_id: '2509.18128'
source_url: https://arxiv.org/abs/2509.18128
tags:
- uncertainty
- reliability
- form
- https
- epistemic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of reliability analysis when
  using machine learning surrogates that introduce epistemic uncertainty alongside
  aleatory input uncertainty. The proposed Gauss-Hermite quadrature approach decouples
  these nested uncertainties by computing conditional failure probabilities using
  FORM/SORM and integrating them over epistemic uncertainty realizations.
---

# Accounting for Uncertainty in Machine Learning Surrogates: A Gauss-Hermite Quadrature Approach to Reliability Analysis

## Quick Facts
- **arXiv ID:** 2509.18128
- **Source URL:** https://arxiv.org/abs/2509.18128
- **Reference count:** 40
- **Key outcome:** Gauss-Hermite quadrature reliability method reduces relative error from 28.27% to 1.28% compared to direct FORM when model uncertainty is significant.

## Executive Summary
This paper addresses reliability analysis when machine learning surrogates introduce epistemic uncertainty alongside aleatory input uncertainty. The proposed approach uses Gauss-Hermite quadrature to decouple these nested uncertainties by computing conditional failure probabilities using FORM/SORM and integrating them over epistemic uncertainty realizations. Three numerical examples demonstrate the method's effectiveness, showing significant accuracy improvements over traditional approaches while maintaining computational efficiency.

## Method Summary
The Gauss-Hermite Quadrature Reliability Method (GH-QRM) computes probability of failure by integrating conditional failure probabilities across epistemic uncertainty realizations. For each Gauss-Hermite quadrature node, the method uses FORM/SORM to compute conditional failure probability given a fixed epistemic realization, then aggregates these using quadrature weights. The approach handles numerical instability near training points through U_Y capping at ±4, preventing sharp peaks in the integration boundary while preserving MPP search validity.

## Key Results
- Example 1: Reduced relative error from 28.27% to 1.28% compared to direct FORM when model uncertainty was significant
- Example 2: Improved accuracy from 8.32% to 6.29% relative error using FORM-GQ method
- Example 3: GQ-based method consistently outperformed Z-based approaches across all reliability techniques, with FORM-GQ reducing error from 17.09% to 1.47%

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoupling aleatory and epistemic uncertainties via Gauss-Hermite quadrature improves failure probability accuracy.
- **Mechanism:** The method computes conditional failure probabilities $F_{Y|U_Y}(y)$ for fixed realizations of epistemic uncertainty using standard FORM/SORM, then integrates these over the epistemic distribution using quadrature weights.
- **Core assumption:** The surrogate's predictive distribution is Gaussian.
- **Evidence anchors:** Abstract states the method "evaluates conditional failure probabilities under aleatory uncertainty using First and Second Order Reliability Methods and then integrates these probabilities across realizations of epistemic uncertainty."
- **Break condition:** If the surrogate's predictive distribution is substantially non-Gaussian, the uniform transformation and standard normal weights may introduce bias.

### Mechanism 2
- **Claim:** Capping $U_Y$ values at ±4 prevents numerical instability when surrogate predictive variance is small.
- **Mechanism:** When $\sigma_Y$ is small near training points, capping bounds probabilities to $[\Phi(-4), \Phi(4)] \approx [3.2 \times 10^{-5}, 0.99997]$, stabilizing the MPP search while preserving accuracy.
- **Core assumption:** The true reliability index $\beta$ falls within the capped range.
- **Evidence anchors:** Section 3.2 explains that capping "does not affect the MPP search as long as the reliability index β falls within the capped probability of failure range."
- **Break condition:** If failure probabilities beyond the cap range are critical, widening the cap may be needed.

### Mechanism 3
- **Claim:** The coefficient of variation (cov) of conditional failure probabilities quantifies model uncertainty impact.
- **Mechanism:** The method computes both mean and variance of conditional failure probabilities across quadrature nodes. Large cov indicates epistemic uncertainty significantly affects reliability predictions.
- **Core assumption:** Variability in conditional $p_f$ across epistemic realizations meaningfully reflects uncertainty in the true failure probability.
- **Evidence anchors:** Section 3.3 states "A larger cov indicates greater variability in the predicted probability of failure due to model uncertainty, implying that the prediction is less reliable."
- **Break condition:** If cov is dominated by quadrature approximation error rather than true epistemic variability, design decisions based on it may be misguided.

## Foundational Learning

- **Concept:** First/Second Order Reliability Methods (FORM/SORM)
  - **Why needed here:** The proposed method wraps around FORM/SORM; you must understand MPP search and reliability index $\beta$.
  - **Quick check question:** Given a limit-state function $g(X)$ and random input $X \sim N(0,1)$, where is the Most Probable Point for $P(g(X) < 0)$?

- **Concept:** Gaussian Process predictive distribution
  - **Why needed here:** The method assumes the surrogate provides both mean $\mu_Y(X)$ and variance $\sigma_Y^2(X)$.
  - **Quick check question:** Why does a GP's predictive variance decrease near training points even if the mean prediction has error?

- **Concept:** Gauss-Hermite quadrature
  - **Why needed here:** The integration $F_Y(y) = \int w(u_Y)\phi(u_Y)du_Y$ uses Gauss-Hermite nodes and weights.
  - **Quick check question:** For a smooth integrand with Gaussian weight, how does error typically scale with the number of quadrature points?

## Architecture Onboarding

- **Component map:** GP Surrogate -> Isoprobabilistic Transform -> FORM/SORM Solver -> Gauss-Hermite Integrator -> CoV Calculator
- **Critical path:** Train GP → Select quadrature order $m$ → For each node $v_i$: compute conditional $p_f$ via FORM/SORM → Weight and sum → Report mean $p_f$ and cov
- **Design tradeoffs:**
  - Higher quadrature order $m$: Better accuracy, more FORM/SORM calls (linear cost increase)
  - Tighter capping (e.g., ±5 vs ±4): Wider probability range, potential numerical issues near peaks
  - FORM vs SORM: SORM adds curvature correction; more accurate for nonlinear limit-states but slightly higher cost
- **Failure signatures:**
  - Sharp peaks in boundary plot: $\sigma_Y$ too small; check capping is active
  - cov >> 1: Model uncertainty dominates; surrogate is untrustworthy near failure region
  - Negative or NaN probabilities: Integration instability; verify GP provides valid positive $\sigma_Y$ everywhere
- **First 3 experiments:**
  1. Validate on known problem: Replicate Example 1 with 3 training points; confirm FORM-GQ reduces error vs direct FORM
  2. Sensitivity to quadrature order: Run Example 2 with $m = 3, 5, 10, 15$; plot $p_f$ vs $m$ to identify convergence point
  3. Stress test with sparse training: Reduce Example 3 training data from 10 to 5 points; observe how cov increases

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the GH-QRM framework be extended to system-level reliability problems with multiple failure modes and correlated component responses?
- **Basis in paper:** The conclusion states: "Future research will extend the proposed method to engineering design problems characterized by multiple responses or multiple surrogate models, with the central challenge being the identification of the joint distribution of all outputs under uncertainty."
- **Why unresolved:** The current methodology only addresses static, component-level problems with a single limit-state function.

### Open Question 2
- **Question:** What is the optimal selection strategy for the number of Gauss-Hermite quadrature points (m) given problem-specific characteristics?
- **Basis in paper:** Section 3.2.1 states "Choose m based on the desired accuracy. Common values range from 5 to 20" but provides no systematic guidance linking problem features to optimal m.
- **Why unresolved:** The paper demonstrates accuracy improvements but does not characterize the trade-off between computational cost and accuracy across different problem types.

### Open Question 3
- **Question:** How does the GH-QRM framework perform with non-Gaussian surrogate models (e.g., Bayesian neural networks, ensemble methods)?
- **Basis in paper:** The methodology relies explicitly on GP models with Gaussian predictive distributions, but the introduction claims applicability to "neural networks, or other machine learning architectures."
- **Why unresolved:** The quadrature integration assumes standard normal weighting; non-Gaussian predictive distributions require transformation or alternative quadrature schemes not addressed.

## Limitations
- The method's accuracy critically depends on the GP surrogate's predictive distribution being Gaussian.
- The capping heuristic at ±4 U_Y values lacks theoretical justification for extreme reliability regimes (p_f < 10⁻⁵).
- Computational cost scales linearly with quadrature order m, but no guidance is provided on optimal m selection.

## Confidence

- **High Confidence:** The decoupling mechanism is theoretically sound and numerical examples demonstrate consistent improvement over baseline methods.
- **Medium Confidence:** The capping heuristic shows practical effectiveness but lacks rigorous validation for tail probabilities beyond the cap range.
- **Low Confidence:** The method's performance with non-Gaussian predictive distributions or highly multimodal failure regions is not explored.

## Next Checks

1. **Non-Gaussian Stress Test:** Apply the method to a problem with known non-Gaussian surrogate uncertainty (e.g., using a Student-t process) and compare accuracy degradation against the Gaussian assumption baseline.

2. **Extreme Reliability Verification:** For a problem targeting p_f < 10⁻⁶, test whether the ±4 cap introduces bias by comparing against analytical solutions or high-precision MCS, and evaluate alternative capping strategies.

3. **Quadrature Order Sensitivity:** Systematically vary m from 3 to 25 on Example 3, measuring both accuracy convergence and computational cost to establish practical guidelines for m selection based on input dimensionality and epistemic uncertainty magnitude.