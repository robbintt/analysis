---
ver: rpa2
title: 'From scratch to silver: Creating trustworthy training data for patent-SDG
  classification using Large Language Models'
arxiv_id: '2509.09303'
source_url: https://arxiv.org/abs/2509.09303
tags:
- patent
- patents
- sdgs
- labels
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of mapping patents to SDGs without
  large labeled datasets. It proposes a weak supervision framework using LLM-extracted
  semantic concepts (functions, solutions, applications) to align patents with SDG-tagged
  scientific publications.
---

# From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models

## Quick Facts
- arXiv ID: 2509.09303
- Source URL: https://arxiv.org/abs/2509.09303
- Reference count: 16
- LLM-extracted semantic concepts enable effective SDG classification without large labeled datasets

## Executive Summary
This study addresses the challenge of mapping patents to Sustainable Development Goals (SDGs) in the absence of large labeled training datasets. The researchers propose a weak supervision framework that leverages Large Language Models (LLMs) to extract semantic concepts from patent abstracts, including functions, solutions, and applications. By aligning these concepts with SDG-tagged scientific publications, the method generates soft, multi-label SDG relevance scores for patents. The approach demonstrates superior performance compared to keyword, transformer, and zero-shot LLM baselines, with macro recall of 0.711 and micro recall of 0.902. Network modularity analysis confirms stronger thematic, cognitive, and organizational coherence than traditional CPC or NPL-based labels, validating the quality of novel SDG assignments.

## Method Summary
The proposed method uses LLM-extracted semantic concepts to enable SDG classification in low-supervision settings. The approach begins with semantic concept extraction from patent abstracts, focusing on functions, solutions, and applications. These concepts are then aligned with SDG-tagged scientific publications to create a weak supervision signal. The system generates soft, multi-label SDG relevance scores through this alignment process. Network modularity analysis serves as a validation mechanism, comparing thematic coherence against traditional classification approaches. The method demonstrates that LLM-derived semantic features can effectively bridge the gap between patents and SDGs without requiring extensive labeled training data.

## Key Results
- Outperforms keyword, transformer, and zero-shot LLM baselines with macro recall 0.711 and micro recall 0.902
- Network modularity analysis shows stronger thematic, cognitive, and organizational coherence than CPC or NPL-based labels
- Successfully demonstrates LLM-derived semantic features enable effective SDG classification in low-supervision settings

## Why This Works (Mechanism)
The mechanism works by leveraging LLM capabilities to extract rich semantic information from patent texts that traditional keyword approaches miss. Functions, solutions, and applications capture the underlying purpose and implementation of patented innovations in ways that directly map to SDG objectives. By using scientific publications tagged with SDGs as anchor points, the system creates meaningful semantic bridges between patent content and development goals. The weak supervision approach circumvents the need for extensive manual labeling while maintaining classification quality through the contextual richness of LLM-extracted features.

## Foundational Learning
- LLM semantic extraction capabilities: Understanding how LLMs identify and categorize functions, solutions, and applications from text is crucial for reproducing and extending this work. Quick check: Can the LLM consistently extract relevant semantic concepts across different technical domains?
- Weak supervision principles: The framework relies on noisy but abundant unlabeled data combined with limited high-quality labeled examples. Quick check: Does the quality of the weak supervision signal degrade significantly with noisier input data?
- Network modularity analysis: Used to validate thematic coherence of SDG assignments, providing a quantitative measure of classification quality. Quick check: Can modularity scores reliably distinguish between meaningful and spurious SDG associations?

## Architecture Onboarding

Component map: Patent abstracts -> LLM semantic extraction -> Function/Solution/Application concepts -> Alignment with SDG-tagged publications -> Soft SDG relevance scores -> Classification output

Critical path: The core workflow depends on accurate semantic extraction followed by effective alignment with SDG-tagged scientific literature. Any failure in the LLM extraction step propagates through the entire pipeline, making concept extraction reliability paramount.

Design tradeoffs: The approach trades potential precision from supervised learning for scalability and adaptability through weak supervision. While this enables SDG classification without large labeled datasets, it may sacrifice some classification accuracy compared to fully supervised approaches with extensive training data.

Failure signatures: Poor semantic concept extraction from patents, misalignment between extracted concepts and SDG-tagged publications, or insufficient coverage of SDG-tagged scientific literature in relevant technical domains could all compromise classification quality. The network modularity validation may also fail to detect subtle classification errors that maintain thematic coherence while missing true SDG associations.

First experiments: 1) Test LLM concept extraction consistency across different patent domains 2) Validate alignment accuracy between patent concepts and SDG-tagged publications 3) Compare modularity scores across different classification approaches to establish baseline performance

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on quality of LLM-extracted semantic concepts without validation of optimal concept selection
- Limited baseline comparisons that don't explore full landscape of classification approaches
- Potential overfitting to specific patent sample and SDG-tagged publication selection

## Confidence

High confidence in the general methodology's effectiveness for SDG classification
Medium confidence in the specific semantic concept selection and extraction process
Medium confidence in the comparative performance claims due to limited baseline exploration
Low confidence in the universal applicability of the network modularity validation approach

## Next Checks
1. Conduct ablation studies testing different combinations and numbers of semantic concepts to determine optimal feature selection
2. Validate the approach on diverse patent samples across different technical domains and time periods
3. Compare results against additional classification methods, including supervised learning approaches with limited labeled data