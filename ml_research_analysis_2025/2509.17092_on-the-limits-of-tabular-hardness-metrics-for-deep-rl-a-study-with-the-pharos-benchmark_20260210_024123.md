---
ver: rpa2
title: 'On the Limits of Tabular Hardness Metrics for Deep RL: A Study with the Pharos
  Benchmark'
arxiv_id: '2509.17092'
source_url: https://arxiv.org/abs/2509.17092
tags:
- state
- tabular
- hardness
- learning
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether tabular hardness metrics can be
  adapted to guide non-tabular benchmarking in deep RL. While tabular settings benefit
  from well-understood hardness measures like MDP diameter and suboptimality gaps,
  deep RL lacks a practically applicable theory of hardness.
---

# On the Limits of Tabular Hardness Metrics for Deep RL: A Study with the Pharos Benchmark

## Quick Facts
- **arXiv ID:** 2509.17092
- **Source URL:** https://arxiv.org/abs/2509.17092
- **Reference count:** 40
- **Key outcome:** Tabular hardness metrics fail to predict deep RL performance due to representation hardness dominance

## Executive Summary
This paper investigates whether established tabular hardness metrics (diameter, suboptimality gaps) can guide deep RL benchmarking. The study reveals that deep RL performance is dominated by representation hardness - the difficulty of extracting features from observations - rather than the structural difficulty of the underlying MDP. The authors introduce pharos, a new open-source library for principled RL benchmarking that enables systematic control over both environment structure and agent representations. Through extensive case studies, they demonstrate that tabular metrics offer limited insight into deep RL difficulty and highlight the need for new, representation-aware hardness measures.

## Method Summary
The authors introduce pharos, a library for constructing scalable tabular representations of non-tabular MDPs using depth-first search with disk-backed hash maps (RocksDB). They compute exact tabular hardness metrics (diameter, suboptimality gaps) for environments with millions of states. The study trains DQN and PPO agents (via Stable Baselines3) on four environment classes (simple_grid, frozen_lake, freeway, breakout) using both pixel images and state vector observations. Performance is evaluated through cumulative regret and return, with linear regression models correlating tabular metrics against deep RL regret.

## Key Results
- Deep RL agent performance is dominated by representation hardness rather than structural MDP complexity
- The same underlying MDP poses vastly different challenges depending on whether agents receive state vectors or pixel-based observations
- Tabular hardness metrics poorly predict deep RL agent performance (R² < 0.2) when using image observations
- Linear models of tabular metrics can predict regret for vector-based observations but fail for image-based tasks

## Why This Works (Mechanism)

### Mechanism 1: Representation Hardness Dominance
- **Claim:** Deep RL performance is determined primarily by the observation space rather than structural MDP difficulty
- **Core assumption:** The difficulty of extracting features from observations is orthogonal to exploring state space
- **Evidence:** Abstract shows same MDP poses different challenges with vector vs. pixel inputs; Section 4.2 discusses neural network smoothness bias
- **Break condition:** Using tabular algorithms or perfect representation encoding removes this factor

### Mechanism 2: Disaggregation of State-Action Dependencies
- **Claim:** Tabular metrics fail because they assume independence between state-action pairs
- **Core assumption:** Generalization in neural networks follows an unpredictable trajectory
- **Evidence:** Section 2.3 explains how function approximation violates tabular assumptions; Section 4.3.1 shows poor linear fit
- **Break condition:** Using infinite-capacity networks or perfectly aligned linear assumptions

### Mechanism 3: Scalable Tabular Surrogates via DFS
- **Claim:** Computationally feasible to calculate exact tabular metrics for millions of states
- **Core assumption:** Disk I/O is the limiting factor, not RAM
- **Evidence:** Section 3.3 describes DFS with RocksDB for visited states; Algorithm 1 outlines the approach
- **Break condition:** Continuous or extremely high-dimensional state spaces preventing discrete hashing

## Foundational Learning

- **Concept: MDP Diameter & Visitation Complexity**
  - **Why needed here:** Baseline hardness metric the paper argues is insufficient
  - **Quick check question:** Can you explain why a large diameter implies high visitation complexity but not necessarily high estimation complexity?

- **Concept: Inductive Bias in Neural Networks**
  - **Why needed here:** Explains performance gap between vector and image inputs
  - **Quick check question:** Why would a CNN struggle to learn a mapping from a random sparse vector representation?

- **Concept: Suboptimality Gaps**
  - **Why needed here:** Primary estimation complexity metric investigated
  - **Quick check question:** If an environment has a large suboptimality gap, is it easier or harder for an agent to distinguish optimal actions?

## Architecture Onboarding

- **Component map:** State Space Builder (DFS with RocksDB) -> Analysis Module (computes metrics) -> Environment Wrapper (decouples dynamics from observations) -> Agent Interface (SB3 wrapper)
- **Critical path:** Initialization of State Space Builder; disk I/O saturation or buggy transitions halt the pipeline
- **Design tradeoffs:** Disk vs. RAM (speed for scale), determinism requirement (stochastic environments increase complexity)
- **Failure signatures:** Low correlation (R² < 0.2) confirms thesis; memory overflow indicates non-terminating or oversized state space; representation inversion shows inductive bias mechanism active
- **First 3 experiments:**
  1. Run Tabular Q-learning on simple_grid and freeway to establish structural hardness ground truth
  2. Train DQN on same freeway instance with raw pixel vs. normalized vector observations to visualize representation gap
  3. Aggregate results across environment classes and fit linear model Regret ~ Diameter + Gap to verify poor fit

## Open Questions the Paper Calls Out

- **Open Question 1:** Can we develop tractable, non-tabular hardness measures that explicitly quantify representation complexity?
- **Open Question 2:** Can practical approximations, such as neural surrogates, make theoretical hardness measures tractable for complex environments?
- **Open Question 3:** How do different neural network architectures and their inductive biases interact with representation hardness?
- **Open Question 4:** Does the dominance of representation hardness over tabular metrics generalize across a wider variety of environment classes and agent algorithms?

## Limitations

- Limited number of environment classes (Grid, Freeway, Breakout) and agent algorithms (primarily DQN, PPO)
- Correlation analysis without establishing causation between representation hardness and performance gaps
- Theoretical framework relies on deterministic transitions; stochastic environments remain untested

## Confidence

- **High:** Tabular metrics poorly predict deep RL performance (R² < 0.2)
- **Medium:** Representation hardness dominance mechanism (primarily empirical evidence)
- **Low:** Generalizability to other deep RL architectures beyond DQN/PPO with CNNs

## Next Checks

1. **Hyperparameter Sensitivity:** Reproduce linear regression analysis while varying DQN learning rates and network architectures to test persistence of representation hardness effects

2. **Alternative Representation Spaces:** Test correlation framework with Fourier features, random projections, and other non-pixel representations to isolate CNN-specific inductive biases

3. **Stochastic Environment Extension:** Implement tabular hardness computation for stochastic transitions to test scalability beyond deterministic cases