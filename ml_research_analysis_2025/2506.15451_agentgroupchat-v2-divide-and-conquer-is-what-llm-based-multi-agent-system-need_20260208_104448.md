---
ver: rpa2
title: 'AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System
  Need'
arxiv_id: '2506.15451'
source_url: https://arxiv.org/abs/2506.15451
tags:
- agent
- group
- task
- agents
- multi-agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AgentGroupChat-V2, a large language model-based
  multi-agent system designed to address key challenges in system architecture, cross-domain
  generalizability, and performance guarantees. The framework employs a divide-and-conquer
  fully parallel architecture that decomposes user queries into hierarchical task
  forest structures, enabling dependency management and distributed concurrent processing.
---

# AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need

## Quick Facts
- **arXiv ID:** 2506.15451
- **Source URL:** https://arxiv.org/abs/2506.15451
- **Authors:** Zhouhong Gu; Xiaoxuan Zhu; Yin Cai; Hao Shen; Xingzhou Chen; Qingyi Wang; Jialin Li; Xiaoran Shi; Haoran Guo; Wenxuan Huang; Hongwei Feng; Yanghua Xiao; Zheyu Ye; Yao Hu; Shaosheng Cao
- **Reference count:** 10
- **Key outcome:** Introduces a large language model-based multi-agent system achieving 91.50% accuracy on GSM8K, 30.4% on AIME, and 79.20% pass@1 on HumanEval through divide-and-conquer parallel architecture with specialized roles.

## Executive Summary
This paper presents AgentGroupChat-V2, a multi-agent system that addresses key challenges in LLM-based collaborative reasoning through hierarchical task decomposition and specialized role assignment. The framework employs a three-tier architecture that decomposes complex queries into task forests for parallel execution, while an adaptive collaboration engine dynamically selects heterogeneous LLM combinations based on task characteristics. Extensive experiments demonstrate superior performance across mathematical reasoning, code generation, and domain-specific tasks, with accuracy improvements becoming increasingly pronounced as task difficulty increases.

## Method Summary
AgentGroupChat-V2 implements a divide-and-conquer fully parallel architecture consisting of three components: Query Manager (frontend) decomposes user queries into hierarchical task trees, Task Manager (central coordinator) maintains task forest state and manages dependencies, and Group Manager (execution layer) instantiates agents with specialized roles for distributed processing. The system uses Qwen2.5-72B-Instruct and Llama-3.1-70B-Instruct-Turbo models, with agents executing in sequential perceive-decide-act cycles within group chats. Key innovations include adaptive collaboration engines that select heterogeneous LLM combinations, and agent organization optimization through divide-and-conquer approaches for efficient problem decomposition.

## Key Results
- Achieves 91.50% accuracy on GSM8K (5.6 percentage points above best baseline)
- Reaches 30.4% accuracy on competition-level AIME (nearly doubles other methods)
- Attains 79.20% pass@1 on HumanEval, demonstrating effectiveness in code generation tasks
- Performance advantages increase with task difficulty, exceeding 11 percentage points on Level 5 MATH problems
- Specialized role division improves performance by 21 percentage points compared to homogeneous configurations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hierarchical task decomposition into task forests enables parallel execution and reduces cognitive load per agent.
- **Mechanism:** Query Manager parses queries into tree-structured tasks with parent-child dependencies. Independent branches execute concurrently through distributed Group Managers while dependent tasks await prerequisites.
- **Core assumption:** Complex tasks can be meaningfully decomposed into semi-independent subtasks without losing solution coherence.
- **Evidence anchors:** Abstract states divide-and-conquer architecture enables dependency management and distributed concurrent processing. Section III.A-B details task tree decomposition and bidirectional parent-child relationships forming complete task dependency graph. DynTaskMAS uses similar dynamic task graphs for parallel LLM multi-agent systems.

### Mechanism 2
- **Claim:** Specialized role assignment creates complementary expertise that improves with agent count, whereas homogeneous agents degrade through redundancy.
- **Mechanism:** Agents receive distinct functional identities (error detection, logical reasoning, computational verification) with dedicated scratch space and objectives.
- **Core assumption:** LLMs can adopt and maintain role-specific behavior through prompt-based identity assignment.
- **Evidence anchors:** Section VI.B, Finding 7 shows specialized roles improve while homogeneous configurations deteriorate with more agents. Table VI lists specialized roles including error detection specialist and computational specialist. AgentNet emphasizes decentralized coordination but not role specialization effects.

### Mechanism 3
- **Claim:** Moderate dialogue depth optimally integrates diverse perspectives; excessive rounds induce decision complexity without quality gains.
- **Mechanism:** Sequential agent perception-decision-action cycles allow early rounds to integrate specialized insights while later rounds produce diminishing returns.
- **Core assumption:** Task completion can be detected before reaching maximum rounds through early termination.
- **Evidence anchors:** Section VI.B, Finding 9 shows 3 rounds optimal for specialized roles (58% accuracy vs 52% at 2 rounds and 49% at 5 rounds). Algorithm 1 implements explicit early termination when tasks complete.

## Foundational Learning

- **Concept: Task Dependency Graphs**
  - **Why needed here:** Framework relies on representing queries as forests of tasks with explicit dependencies. Understanding DAGs, topological ordering, and parallel vs. sequential execution paths is essential for configuring Task Manager behavior.
  - **Quick check question:** Given tasks A→B, A→C, B→D, C→D, which tasks can execute concurrently?

- **Concept: Chain-of-Thought vs. ReAct vs. Multi-Agent Paradigms**
  - **Why needed here:** Baselines include Naive-CoT, ReAct, and debate-based multi-agent systems. Understanding when each applies prevents misapplying framework to unsuitable tasks.
  - **Quick check question:** For single-step factual lookup, which paradigm minimizes unnecessary overhead?

- **Concept: Role-Based Prompt Engineering**
  - **Why needed here:** Specialized agents derive behavior from role prompts in scratch space. Effective role definition requires specifying objectives and constraints that produce complementary behaviors.
  - **Quick check question:** If two agents both receive "math expert" prompts, what collaboration failure mode should you expect?

## Architecture Onboarding

- **Component map:** Query Manager -> Task Manager -> Group Manager
- **Critical path:** 1) Query received by Query Manager 2) Task decomposition creates task tree 3) Task Manager identifies ready tasks 4) Group Manager instantiates agents with roles 5) Group chat executes Algorithm 1 6) Results propagate up task tree 7) Completed task tree returned to Query Manager
- **Design tradeoffs:** More agents help specialized roles (+7 percentage points) but hurt homogeneous roles (-8.7% from 2 to 5 agents). 3 rounds optimal for specialized roles; 2 rounds for simpler patterns. Finer decomposition enables parallelism but increases coordination overhead.
- **Failure signatures:** Worse than single-agent on commonsense tasks indicates over-decomposition; pass@k improves less than baselines at high k suggests constrained solution diversity; accuracy degrades with agent addition indicates role homogeneity.
- **First 3 experiments:** 1) Baseline comparison on held-out math problems vs. Naive-CoT and AutoGen 2) Role configuration ablation comparing specialized vs. general roles 3) Task type boundary test on HellaSwag vs. GSM8K

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the system architecture incorporate a pre-processing mechanism to dynamically switch between single-agent and multi-agent modes to prevent performance degradation on simple commonsense reasoning tasks?
- **Basis in paper:** Finding 3 notes the framework's divide-and-conquer approach fragments straightforward questions into unnecessary subtasks, causing underperformance on HellaSwag (70.3% vs 73.7%).
- **Why unresolved:** Current design defaults to complex divide-and-conquer regardless of query simplicity, lacking a mechanism to bypass heavy orchestration when counter-productive.
- **What evidence would resolve it:** Comparative analysis showing modified framework matches or exceeds Naive baseline on HellaSwag while retaining superior performance on GSM8K/AIME.

### Open Question 2
- **Question:** To what extent can "Specialized Role" definitions be automated or generated on-the-fly for novel domains rather than requiring manual prompt engineering?
- **Basis in paper:** Table VI and Finding 7 demonstrate massive disparity between General Role and Specialized Role configurations (32.5% vs 53.5% avg accuracy with 5 agents), but specialized prompts appear manually crafted for math domain.
- **Why unresolved:** Paper validates utility of specialized roles but does not propose method for deriving roles dynamically for unseen task types.
- **What evidence would resolve it:** Experiment where role prompts are generated by LLM based solely on task description, achieving performance parity with manually configured specialized roles.

### Open Question 3
- **Question:** Does positive correlation between number of specialized agents and performance persist beyond five agents, or does communication overhead eventually cause performance plateau or decline?
- **Basis in paper:** Ablation study limited to 2-5 agents. Finding 8 claims AGC-V2 effectively coordinates large-scale agent teams, but data only confirms upward trend up to 5 agents.
- **Why unresolved:** Unclear if divide-and-conquer coordination scales linearly or faces complexity ceiling similar to General Role degradation.
- **What evidence would resolve it:** Experimental results extending ablation study to 10, 20, and 50 agents on MATH-100 dataset to map scaling curve.

## Limitations
- Architecture introduces significant coordination overhead through three-tier design that is not quantified in computational cost
- Framework's advantage on complex tasks appears to come at cost of increased complexity compared to single-agent approaches for straightforward queries
- Scalability of Group Manager instances across distributed servers remains unproven

## Confidence

**High confidence** in hierarchical task decomposition enabling parallel execution gains—follows directly from architecture specification and supported by 5.6 percentage point improvement over baselines on GSM8K.

**Medium confidence** in role specialization claims—paper shows specialized roles outperform homogeneous configurations by up to 21 percentage points, but relies on LLMs maintaining distinct behavioral patterns through prompt-based identity assignment which may vary across model versions and domains.

**Low confidence** in dialogue depth optimization—Finding 9 reports optimal 3 rounds for specialized roles but appears dataset-specific and lacks cross-domain validation. Early termination may prematurely truncate tasks requiring deeper iterative refinement.

## Next Checks
1. **Coordination overhead quantification**: Measure end-to-end latency and computational cost (API calls, memory usage) for AgentGroupChat-V2 vs. single-agent baselines on identical problem sets to verify performance gains justify architectural complexity.

2. **Role fidelity stress test**: Conduct controlled experiments where two agents receive identical "math expert" prompts vs. specialized prompts across 100 problems, measuring redundancy metrics (Jaccard similarity of outputs) to confirm claimed degradation from homogeneity.

3. **Task type boundary validation**: Systematically test framework across HellaSwag (commonsense), GSM8K (multi-step math), and single-step arithmetic to identify exact crossover point where decomposition overhead exceeds benefits.