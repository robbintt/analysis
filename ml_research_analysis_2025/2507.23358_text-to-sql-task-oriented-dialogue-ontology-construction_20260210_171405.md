---
ver: rpa2
title: Text-to-SQL Task-oriented Dialogue Ontology Construction
arxiv_id: '2507.23358'
source_url: https://arxiv.org/abs/2507.23358
tags:
- dialogue
- ontology
- user
- teqodo
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces TeQoDO, a method that autonomously constructs\
  \ task-oriented dialogue (TOD) ontologies using large language models (LLMs) without\
  \ any supervision or training data. The approach leverages SQL programming capabilities\
  \ and modular TOD concepts\u2014such as dialogue state tracking and dialogue success\u2014\
  to iteratively build and update a structured database from dialogue data."
---

# Text-to-SQL Task-oriented Dialogue Ontology Construction

## Quick Facts
- **arXiv ID:** 2507.23358
- **Source URL:** https://arxiv.org/abs/2507.23358
- **Reference count:** 38
- **Primary result:** Unsupervised TOD ontology construction using SQL and LLMs outperforms supervised methods on MultiWOZ and SGD.

## Executive Summary
This paper introduces TeQoDO, a method that autonomously constructs task-oriented dialogue (TOD) ontologies using large language models (LLMs) without any supervision or training data. The approach leverages SQL programming capabilities and modular TOD concepts—such as dialogue state tracking and dialogue success—to iteratively build and update a structured database from dialogue data. TeQoDO outperforms recent supervised methods like DORE and GenDSI on ontology construction tasks, achieving continuous F1 scores of 65.25 on MultiWOZ and 61.64 on Schema-Guided Dialogue (SGD). The method also generalizes to large-scale ontology datasets from Wikipedia and arXiv, showing competitive performance despite being unsupervised.

## Method Summary
TeQoDO is an unsupervised pipeline that constructs TOD ontologies from raw dialogue data using SQL and LLMs. It iteratively processes each dialogue through three steps: (1) Query the current SQLite database schema to retrieve relevant domains, slots, and values; (2) Simulate dialogue state tracking to distinguish existing from new information; (3) Generate SQL update queries (CREATE, INSERT, UPDATE) incorporating dialogue success prompts. The method maps TOD hierarchy (Domains → Slots → Values) to SQL structures (Tables → Columns → Values), leveraging the LLM's pre-existing SQL competence. GPT-4o-mini is used as the LLM, and evaluation uses continuous F1 based on semantic similarity.

## Key Results
- TeQoDO achieves continuous F1 scores of 65.25 on MultiWOZ and 61.64 on SGD, outperforming supervised baselines DORE and GenDSI.
- SQL error ratio drops from 30.45% to 7.76% when adding dialogue success prompts.
- Adding dialogue state tracking improves continuous F1 from 50.1 to 58.8 on MultiWOZ.
- TeQoDO generalizes to large-scale ontology datasets from Wikipedia and arXiv with competitive performance.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SQL syntax acts as a strong structural prior for LLMs, reducing prompt engineering burden compared to natural language schema definitions.
- **Mechanism:** Maps TOD hierarchy (Domains → Slots → Values) directly to SQL structures (Tables → Columns → Values), leveraging LLM's pre-training on code.
- **Core assumption:** LLM has sufficient SQL competence without fine-tuning.
- **Evidence:** SQL improves ontology quality when LLMs interact with a DB; reduces need for textual prompts.
- **Break condition:** Degrades for ontologies exceeding 3 hierarchy levels.

### Mechanism 2
- **Claim:** Simulating DST as intermediate step improves SQL precision by grounding LLM in current schema.
- **Mechanism:** Forces model to formulate DST label based on existing DB content before generating updates.
- **Core assumption:** LLM can accurately summarize dialogue state using only provided schema.
- **Evidence:** Adding DST step improves continuous F1 from 50.1 to 58.8; prevents duplicate entries.
- **Break condition:** Less valuable if dialogue context exceeds LLM window or schema is empty.

### Mechanism 3
- **Claim:** Prompting for "dialogue success" reduces SQL execution errors by constraining objective function.
- **Mechanism:** Update prompt explicitly instructs generating queries such that "user's goal... can be successfully fulfilled."
- **Core assumption:** LLM understands TOD task success concept well enough to influence SQL generation.
- **Evidence:** Adding "Success" drops SQL error ratio from 30.45% to 7.76%.
- **Break condition:** Ambiguous or multi-turn goals may bias ontology toward short-term utility.

## Foundational Learning

- **Concept: Task-Oriented Dialogue (TOD) Ontology**
  - **Why needed:** System outputs structured graph (Domains, Slots, Values) rather than unstructured text.
  - **Quick check:** If user says "I need a cheap flight to Paris," what are Domain, Slot, and Value?

- **Concept: Dialogue State Tracking (DST)**
  - **Why needed:** Method uses DST as reasoning step to stabilize SQL generation.
  - **Quick check:** If DB has "Price=cheap" and user says "Actually, make it expensive," INSERT new row or UPDATE existing?

- **Concept: SQL CRUD Operations**
  - **Why needed:** Pipeline relies entirely on generating valid CREATE, SELECT, INSERT, and UPDATE statements.
  - **Quick check:** Difference between ALTER TABLE and UPDATE when adding new slot vs. new value?

## Architecture Onboarding

- **Component map:** Raw dialogue history -> LLM (with specific stages) -> SQLite Database (persistent storage)
- **Critical path:** "Query Update" loop; if LLM fails to retrieve correct schema in Step 1, DST will be empty, leading to duplicate table creation in Step 3.
- **Design tradeoffs:** Unsupervised vs. supervised (trades accuracy for zero-shot adaptation); SQL rigidity (enforces structure but limits hierarchy depth).
- **Failure signatures:** Schema proliferation (100+ tables for domain needing 5); SQL syntax errors (>20% indicate model too small or missing success prompt).
- **First 3 experiments:**
  1. Run TeQoDO on 5 MultiWOZ dialogues; verify distinct tables for "Hotel" and "Train" vs. merged generic table.
  2. Run with "Direct Update" baseline (no querying/DST); compare number of tables created.
  3. Use generated SQLite DB to manually query for slot from test dialogue; does query return expected entity?

## Open Questions the Paper Calls Out
None

## Limitations
- SQL structural prior constrains method to shallow ontologies (3-level hierarchies), struggling with complex taxonomies.
- "Dialogue success" prompt effectiveness not independently validated beyond error rate reduction.
- Performance on noisy, real-world dialogues outside controlled test sets remains unproven.
- Continuous F1 metric depends on all-MiniLM-L6-v2 embeddings and chosen threshold, which may not generalize.

## Confidence

- **High Confidence:** SQL-based pipeline reduces table proliferation (168 vs. 6 tables on MultiWOZ); ablation results for DST and success prompts are internally consistent.
- **Medium Confidence:** Claims about SQL as "structural prior" lack direct experimental comparison to non-SQL schema definitions; downstream DST performance matching ground truth is promising but based on single dataset.
- **Low Confidence:** Generalization to large-scale datasets (Wikipedia, arXiv) mentioned but not quantitatively detailed.

## Next Checks
1. **Hierarchy Depth Test:** Run TeQoDO on TOD dataset with nested slot hierarchies (e.g., "Hotel -> Room -> Amenities") and measure schema collapse or misrepresentation.
2. **SQL Prompt Ablation:** Remove "dialogue success" instruction from update prompt; quantify changes in SQL error rate and ontology coherence on MultiWOZ.
3. **Cross-Dataset Transfer:** Apply MultiWOZ-trained TeQoDO pipeline (without retraining) to new TOD dataset (e.g., M2M); evaluate continuous F1 degradation to assess zero-shot adaptability.