---
ver: rpa2
title: 'Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained
  2D Foundation Models'
arxiv_id: '2507.08254'
source_url: https://arxiv.org/abs/2507.08254
tags:
- raptor
- medical
- volumes
- random
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Raptor introduces a train-free method for generating semantically
  rich embeddings from volumetric medical data by leveraging pretrained 2D foundation
  models. It extracts visual tokens from individual cross-sections of medical volumes
  using a frozen image encoder, then compresses them spatially with random projections
  to significantly reduce computational complexity while retaining semantic information.
---

# Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models

## Quick Facts
- **arXiv ID:** 2507.08254
- **Source URL:** https://arxiv.org/abs/2507.08254
- **Reference count:** 40
- **Primary result:** Train-free method achieves +3% to +14% improvement over state-of-the-art methods requiring medical pretraining across ten diverse medical volume tasks

## Executive Summary
Raptor introduces a novel train-free approach for generating semantically rich embeddings from 3D medical volumes by leveraging pretrained 2D foundation models. The method extracts visual tokens from individual cross-sections of medical volumes using a frozen image encoder, then compresses them spatially with random projections to significantly reduce computational complexity while retaining semantic information. Extensive experiments on ten diverse medical volume tasks show Raptor achieves superior performance over state-of-the-art methods that require extensive medical pretraining, all without any training on the target data.

## Method Summary
Raptor processes 3D medical volumes by extracting slices along three orthogonal axes (axial, coronal, sagittal) and encoding each 2D slice using a frozen pretrained 2D vision transformer (DINOv2-L). The method then aggregates slice-level embeddings through mean-pooling along each axis and applies random projections to compress the high-dimensional token space. The resulting embeddings are concatenated across all three axes to form a fixed-length representation suitable for downstream tasks. During inference, only a simple linear probe or shallow MLP is trained on the frozen embeddings, making the approach highly data-efficient and computationally lightweight compared to traditional 3D models that require extensive medical pretraining.

## Key Results
- Achieves +3% SuPreM, +6% MISFM, +10% Merlin, +13% VoCo, and +14% SLIViT improvements across ten diverse medical volume tasks
- Sub-cubic computational scaling with input size, making it feasible for large volumetric datasets
- Superior performance in data-scarce regimes, with particularly strong results when training data is limited
- Model-agnostic design allows application to any volumetric data without architectural modifications

## Why This Works (Mechanism)

### Mechanism 1: Triaxial 2D Foundation Model Transfer
Semantic features from pretrained 2D vision models can be triangulated across three orthogonal views to approximate 3D volumetric understanding without 3D-specific training. Raptor applies a frozen 2D encoder (DINOv2-L) to all slices along three axes of a 3D volume, capturing different cross-sectional features where spatial relationships lost in one view may be recoverable in another.

### Mechanism 2: Random Projection for Train-Free Compression
Random projections preserve sufficient pairwise distance relationships (per Johnson-Lindenstrauss lemma) to maintain class separability while reducing dimensionality by 50× or more, without requiring data-dependent fitting. This allows aggressive compression of the 3×D×d×p² tensor to a manageable size while retaining semantic structure.

### Mechanism 3: Mean-Pooling Aggregation for Global Volume Representation
Averaging slice-level embeddings along each axis produces a stable global representation that captures dominant semantic features while filtering out slice-specific noise. This assumes semantically meaningful features manifest consistently across multiple slices while irrelevant variations average out.

## Foundational Learning

- **Concept: Vision Transformer (ViT) Patch Embeddings**
  - **Why needed here:** Raptor relies on DINOv2-L, a ViT, to extract patch-level embeddings from 2D slices. Understanding how ViTs partition images into patches and project them to token vectors is essential for interpreting the intermediate tensor shape.
  - **Quick check question:** Can you explain why a 256×256 image processed by a ViT with patch size 16 produces 16×16=256 patches?

- **Concept: Random Projection and Johnson-Lindenstrauss Lemma**
  - **Why needed here:** The core innovation is using random projections for compression. Understanding JL lemma's guarantee that distances are approximately preserved with sufficient projection dimension explains why K=10-100 works despite 50× compression.
  - **Quick check question:** If you project n=10,000 points from d=1000 dimensions to K=100, what distortion ε can you expect with high probability (order-of-magnitude)?

- **Concept: Foundation Models and Transfer Learning**
  - **Why needed here:** Raptor's premise is that DINOv2, trained on natural images, transfers to medical volumes. Understanding why large-scale self-supervised models learn universal visual primitives clarifies when this transfer succeeds or fails.
  - **Quick check question:** Why might a model trained on ImageNet struggle with MRI scans despite both being images? What properties of DINOv2's training might mitigate this?

## Architecture Onboarding

- **Component map:** Input Volume Loader -> Triaxial Slice Extractor -> Frozen DINOv2-L Encoder -> Mean-Pooling Aggregator -> Random Projection Module -> Flattening & Output -> Downstream Head

- **Critical path:** Input → Slice Extraction (CPU-bound, parallelizable) → DINOv2 Encoding (GPU-bound, bottleneck) → Aggregation/Projection (CPU, negligible cost). Optimization target: Batch slice encoding to maximize GPU utilization.

- **Design tradeoffs:**
  - **K (projection dimension):** Higher K (100) → better performance, larger embeddings; Lower K (10) → 10× smaller, marginal accuracy loss. Recommendation: Start with K=10 for rapid iteration, scale to K=100 for final benchmarks.
  - **Encoder choice:** DINOv2-L (304M params) → best performance; Alternatives (CLIP, SAM, MedSAM) tested but underperformed.
  - **Slice resolution:** Paper uses 256² slices; lower resolutions reduce GPU load but may lose fine details.

- **Failure signatures:**
  - Low AUROC on sparse/localized features: Indicates mean-pooling is diluting signal. Mitigation: Consider weighted pooling or attention-based aggregation.
  - High variance across seeds (K < 10): Random projection instability. Mitigation: Increase K to ≥100 or ensemble multiple seeds.
  - Poor performance on fracture-like datasets: Smoothness assumption violation (αj < 0). Mitigation: Use per-patch projections without slice averaging.

- **First 3 experiments:**
  1. Reproduce 3D MedMNIST baseline: Train linear probe on Raptor embeddings for OrganMNIST. Target: AUROC > 0.99.
  2. Ablate projection dimension: Compare K ∈ {1, 5, 10, 50, 100, 150} on Synapse dataset. Plot AUROC vs. K, confirm plateau at K≈100.
  3. Test data efficiency: Subsample training data (10, 50, 100, 500 samples) on Synapse, compare to SuPreM/MISFM baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can Raptor be extended to multimodal tasks or non-medical volumetric domains effectively?
- **Basis in paper:** The authors state, "Extending our framework beyond healthcare applications is a promising direction," and mention promise for "multimodal integration."
- **Why unresolved:** The study exclusively evaluates medical volumes (CT/MRI) using DINOv2. It is unclear if the 2D-to-3D projection effectively captures the geometry of natural scenes or aligns with text/clinical reports without fine-tuning.
- **What evidence would resolve it:** Experiments applying Raptor to natural 3D scene datasets (e.g., autonomous driving) or evaluations on vision-language tasks (e.g., volume-to-text retrieval).

### Open Question 2
- **Question:** How can the axial sampling strategy be refined to improve performance on datasets with sparse or irregular features, such as Fracture3D?
- **Basis in paper:** The Discussion notes that "modest performance on select datasets (e.g. Fracture3D) suggests... refining the axial sampling strategy could further improve downstream results."
- **Why unresolved:** The current 3-axis orthogonal sampling may miss features oriented obliquely, and the "smoothness" required for effective mean aggregation may not hold for discontinuous trauma features.
- **What evidence would resolve it:** Ablation studies using dense sampling, oblique planes, or adaptive sampling strategies that improve detection of high-frequency, localized pathologies.

### Open Question 3
- **Question:** Can the compression mechanism be adapted to preserve small spatial features that are currently lost?
- **Basis in paper:** Table 8 shows that performance in the "Size" simulation drops sharply (to near chance) for small features (8px–16px), suggesting the current projection or ViT patching loses high-frequency details.
- **Why unresolved:** The method relies on patch-based ViTs (e.g., patch size 16) and random projections which may average out small, critical signals before they can be decoded.
- **What evidence would resolve it:** Integration with multi-scale or high-resolution foundation models, or a modified projection technique that explicitly preserves high-frequency spatial components.

## Limitations

- **Assumption sensitivity:** Performance critically depends on three assumptions that may fail in pathological cases: semantic features decompose into transferable 2D patterns, slice embeddings change smoothly enough for mean-pooling, and random projections preserve task-relevant distances.
- **Evaluation scope:** All experiments use 3D MedMNIST datasets with relatively small volumes (up to 256³) and limited clinical diversity; no validation on full-resolution clinical scans.
- **Architectural rigidity:** While presented as "model-agnostic," the fixed triaxial encoding and mean-pooling architecture may not capture volumetric relationships optimally.

## Confidence

**High confidence** (supported by extensive experimental evidence):
- Train-free embeddings outperform state-of-the-art methods requiring medical pretraining (+3% to +14% across ten tasks)
- Sub-cubic computational scaling (critical path is slice encoding, not volumetric processing)
- Data efficiency advantages (superior performance with limited training data)

**Medium confidence** (evidence present but with caveats):
- Universal transferability of DINOv2 to diverse medical imaging modalities (tested on CT, MRI, X-ray, but limited to 3D MedMNIST)
- Random projection preserves semantic distances (theoretically sound via JL lemma, empirically validated for K≥100, but no ablation on medical-specific distance preservation)
- Mean-pooling effectively captures global volume semantics (works well for organ/nodule classification but fails on sparse features like fractures)

**Low confidence** (limited or no experimental support):
- Scalability to full clinical resolution volumes (512³ or larger) without architectural modifications
- Performance on complex volumetric tasks beyond simple classification (segmentation, anomaly localization, temporal tracking)
- Robustness to varying slice thickness and resolution across different medical scanners

## Next Checks

1. **Clinical resolution validation:** Apply Raptor to full-resolution clinical CT/MRI volumes (512³ or larger) from real hospital datasets. Measure memory usage, inference time, and classification accuracy compared to baseline methods. This tests the claimed sub-cubic scaling and practical deployment feasibility.

2. **Task complexity extension:** Evaluate Raptor on volumetric segmentation and anomaly detection tasks (not just classification). Compare against task-specific 3D foundation models like MedNeXt, BEIT-3D, and MedPT. This validates whether train-free embeddings generalize beyond simple categorization.

3. **Architectural flexibility study:** Systematically compare Raptor's mean-pooling against attention-based aggregation (DinoAtten3D) and learned pooling strategies across diverse medical datasets. Measure performance on datasets with varying smoothness properties (αj) and feature sparsity. This determines when the fixed architecture succeeds or fails.