---
ver: rpa2
title: 'QuantAgents: Towards Multi-agent Financial System via Simulated Trading'
arxiv_id: '2510.04643'
source_url: https://arxiv.org/abs/2510.04643
tags:
- market
- risk
- trading
- financial
- strategy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces QuantAgents, a multi-agent financial system
  that integrates simulated trading to enhance investment decision-making. Unlike
  existing LLM-based financial agents that rely on post-reflection learning, QuantAgents
  incorporates simulated trading to enable forward-looking market analysis and risk
  assessment.
---

# QuantAgents: Towards Multi-agent Financial System via Simulated Trading

## Quick Facts
- arXiv ID: 2510.04643
- Source URL: https://arxiv.org/abs/2510.04643
- Reference count: 28
- Primary result: Multi-agent system with simulated trading achieves ~300% return on NASDAQ-100 (2010-2023), outperforming all baselines

## Executive Summary
QuantAgents introduces a multi-agent financial system that integrates simulated trading to enhance investment decision-making through forward-looking analysis. Unlike traditional LLM-based financial agents that rely solely on post-reflection learning, QuantAgents incorporates simulated trading to enable agents to test strategies in a risk-free environment before real-world execution. The system comprises four specialized agents—simulated trading analyst, risk control analyst, market news analyst, and manager—who collaborate through weekly meetings and risk alert protocols. Extensive experiments on NASDAQ-100 data demonstrate superior performance with nearly 300% overall return, while live trading in Chinese markets (Q3 2024-Q1 2025) achieved returns of 111.87% (A-stocks) and 97.69% (HK-stocks).

## Method Summary
QuantAgents is a reinforcement learning-based multi-agent system that uses four specialized agents to manage a NASDAQ-100 portfolio. The system employs GPT-4o as the reasoning engine for each agent, which interact through three structured meeting types: Market Analysis, Strategy Development, and Risk Alert. A key innovation is the simulated trading component, where the simulated trading analyst backtests strategies before execution. The system uses a dual reward mechanism that provides feedback from both real-world trading performance and simulated trading accuracy, encouraging predictive decision-making. Agents access three types of memory (Market Information, Strategy, and Report) through vector embeddings, and execute actions using 26 specialized tools for technical analysis, sentiment assessment, and risk evaluation.

## Key Results
- Achieves nearly 300% overall return on NASDAQ-100 data (2010-2023), outperforming all baseline models
- Superior risk-adjusted returns with Sharpe Ratio of 1.22 and maximum drawdown (MDD) of 8.8%
- Exceptional live trading performance in Chinese markets: 111.87% return (A-stocks) and 97.69% return (HK-stocks) during Q3 2024-Q1 2025

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A multi-agent system incorporating simulated trading can improve financial decision-making over post-reflection methods.
- Mechanism: Specialized agents collaborate through structured meetings while a simulated trading analyst tests strategies in a risk-free environment. A dual reward mechanism provides feedback from both real-world performance and simulated trading accuracy.
- Core assumption: Forward-looking analysis via simulated trading provides better predictive signals than post-hoc reflection alone.
- Evidence anchors: Extensive experiments show QuantAgents achieves superior performance with nearly 300% return; ablation studies demonstrate the contribution of each meeting type.

### Mechanism 2
- Claim: Structured inter-agent collaboration via specialized meetings improves risk management and strategy robustness.
- Mechanism: Three meeting types (Market Analysis, Strategy Development, Risk Alert) enforce separation of concerns, with the Manager synthesizing advice from specialized agents.
- Core assumption: Division of labor and structured communication protocol leads to more robust decisions than a single generalist agent.
- Evidence anchors: Meeting protocols are detailed in section 3.4; ablation study shows full system with all three meetings outperforms partial combinations.

### Mechanism 3
- Claim: A dual reward mechanism from real and simulated trading encourages more predictive decision-making.
- Mechanism: The system's policy is optimized for both real-world returns and accuracy in simulated trading, with adaptive weighting balancing these rewards.
- Core assumption: Strategies that perform well in simulation are more likely to succeed in reality, and the reward structure can effectively align agent behavior.
- Evidence anchors: Dual reward and adaptive weighting are explicitly defined in equations (5) and (6); the system incentivizes agents to receive feedback on both performance fronts.

## Foundational Learning

- **Reinforcement Learning (RL) in Finance**: The framework uses policy optimization to update trading strategies based on dual rewards from real and simulated performance. Quick check: How is the state defined for the trading agent, and what constitutes an episode?
- **Large Language Model (LLM) Agents**: Each agent uses GPT-4o for reasoning tasks like news analysis and market condition assessment. Quick check: How does the system parse LLM output into structured actions for execution?
- **Financial Backtesting and Simulation**: The entire premise relies on simulated trading to test strategies before real-world execution. Quick check: Why is a temporal split crucial for evaluating a trading strategy's performance?

## Architecture Onboarding

- **Component map**: Data ingestion (prices, news) → Individual Agent Analysis & Memory Retrieval → Coordination via Meetings → Manager synthesis → Execute action → Observe reward → Update policy and memory
- **Critical path**: The system processes market data, each agent analyzes using specialized tools and memory, weekly meetings coordinate strategy development, the Manager executes trades based on dual-reward policy, and the system updates based on observed performance
- **Design tradeoffs**: Multi-agent complexity provides interpretability through audit trails but is harder to debug than single agents; GPT-4o dependency creates cost concerns but enables effective reasoning; simulation fidelity impacts predictive power but may introduce overfitting
- **Failure signatures**: High RAM triggers indicate excessive risk-aversion; divergent agent advice can cause execution stalls; memory retrieval drift degrades reasoning quality
- **First 3 experiments**:
  1. Baseline Reproduction: Verify reported Total Return and Sharpe Ratio on NASDAQ-100 test set (2021-2023) against Buy-and-Hold
  2. Ablation of Simulated Trading: Disable simulated trading component and dual reward to isolate forward-looking analysis contribution
  3. Stress Test via Risk Alerts: Inject high-volatility data to trigger Risk Alert Meetings and verify risk mitigation execution

## Open Questions the Paper Calls Out

- **Question**: How does QuantAgents perform across diverse global markets with varying liquidity and regulatory structures?
- **Basis**: The authors state in the Limitations section they plan to validate across global markets but current experiments are limited to NASDAQ-100, A-shares, and HK-stocks
- **Question**: To what extent does pre-training data leakage in the LLM backbone inflate backtest performance compared to live results?
- **Basis**: The paper acknowledges backtesting may be affected by potential LLM information leakage, though live trading showed strong results
- **Question**: How sensitive is the dual-reward mechanism to the fidelity of the simulated trading environment regarding market friction and slippage?
- **Basis**: The paper defines simulated trading rewards based on backtesting but does not detail transaction costs or market impact modeling

## Limitations
- Performance achieved on limited market (NASDAQ-100) with unverified generalization to other markets
- Reliance on GPT-4o creates significant cost dependency ($0.17/day reported) and closed-source limitations
- Simulated trading effectiveness depends on backtesting environment fidelity, which is not fully specified regarding transaction costs and slippage
- Live trading results in Chinese markets lack independent verification and represent a limited timeframe

## Confidence
- **High Confidence**: Multi-agent coordination mechanism (structured meetings, agent specialization) is well-specified and reproducible
- **Medium Confidence**: Dual reward mechanism's contribution supported by ablation studies, but impact depends on simulation fidelity
- **Low Confidence**: Live trading results in Chinese markets lack independent verification and limited timeframe

## Next Checks
1. **Out-of-Sample Market Test**: Apply QuantAgents to S&P 500 or FTSE 100 to verify cross-market generalization using same methodology
2. **Simulation Fidelity Audit**: Conduct sensitivity analysis by varying transaction cost assumptions and backtesting parameters to quantify impact on performance
3. **Real-Time Robustness Test**: Deploy simplified version with smaller language model to assess whether performance advantage persists under practical constraints