---
ver: rpa2
title: Bayesian Evaluation of Large Language Model Behavior
arxiv_id: '2511.10661'
source_url: https://arxiv.org/abs/2511.10661
tags:
- evaluation
- text
- input
- bayesian
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a Bayesian framework for quantifying uncertainty
  in evaluating black-box large language model (LLM) systems, addressing the challenge
  of statistical uncertainty quantification in LLM evaluations that often rely on
  binary assessments of outputs. The core method uses independent Beta priors on per-input
  behavior probabilities, with binomial likelihoods to model observed binary outcomes
  from multiple stochastic generations per input.
---

# Bayesian Evaluation of Large Language Model Behavior

## Quick Facts
- arXiv ID: 2511.10661
- Source URL: https://arxiv.org/abs/2511.10661
- Reference count: 40
- Presents Bayesian framework for quantifying uncertainty in LLM evaluations using Beta-binomial models and sequential input selection

## Executive Summary
This work introduces a Bayesian framework for quantifying statistical uncertainty in black-box LLM evaluations that rely on binary assessments of outputs. The core approach uses independent Beta priors on per-input behavior probabilities with binomial likelihoods from multiple stochastic generations per input, yielding closed-form posterior distributions. The framework addresses the challenge that standard LLM evaluations using deterministic decoding fail to capture uncertainty from probabilistic text generation, and provides uncertainty quantification for various aggregation functions of interest including threshold-based counts, means, and minima. The authors demonstrate the approach through two case studies on pairwise preference evaluation and refusal rate measurement, showing how the Bayesian perspective reveals behaviors hidden by greedy decoding.

## Method Summary
The method places independent Beta(α_m, β_m) priors on per-input behavior probabilities θ_m, observes binary labels from n_m stochastic generations per input, and updates to Beta(α_m + r_m, β_m + n_m − r_m) posteriors via conjugacy. For aggregation, threshold-based counts follow Poisson binomial distributions with computable variance, while mean/min aggregations require Monte Carlo. The framework optionally includes sequential input selection algorithms (greedy and Thompson sampling) that actively choose which inputs to evaluate next based on expected variance reduction in the target aggregation. This allows more efficient evaluation when input behaviors are heterogeneous, potentially reducing the number of generations needed to achieve desired uncertainty levels.

## Key Results
- Beta-binomial conjugacy enables closed-form posterior updates without MCMC
- Poisson binomial aggregation provides closed-form variance for threshold-based counts
- Sequential algorithms (greedy and Thompson sampling) can reduce evaluation costs by 30-50% when input behaviors are heterogeneous
- Bayesian analysis reveals that outputs deemed non-refusing under greedy decoding may still have significant refusal probabilities under stochastic generation
- Sequential methods show minimal benefit when most inputs have homogeneous behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Independent Beta-binomial models per input capture output-level stochastic uncertainty and yield closed-form posteriors.
- Mechanism: Place Beta(α_m, β_m) prior on each per-input behavior probability θ_m; observe binary labels from multiple stochastic generations; Beta-binomial conjugacy gives posterior Beta(α_m + r_m, β_m + n_m − r_m) without MCMC.
- Core assumption: Binary outcomes per generation are conditionally independent given θ_m, and θ_m are independent across inputs.
- Evidence anchors:
  - [abstract] "The core method uses independent Beta priors on per-input behavior probabilities, with binomial likelihoods to model observed binary outcomes from multiple stochastic generations per input."
  - [Section 3] "Given the conjugacy of the Beta prior/binomial likelihood, this results in M independent Beta posterior distributions, one per θ_m: p(θ_m|r_m, α_m, β_m) = Beta(α_m + r_m, β_m + n_m − r_m)."
  - [corpus] Corpus does not provide external validation of the Beta-binomial assumption for LLM outputs; independence across inputs is assumed but not empirically tested against hierarchical alternatives.
- Break condition: If outputs across inputs are dependent (e.g., semantically similar prompts induce correlated behaviors), per-input independence assumption underestimates aggregate uncertainty.

### Mechanism 2
- Claim: Aggregations of interest (e.g., counts of inputs exceeding a threshold) have computable uncertainty via the Poisson binomial distribution.
- Mechanism: Each θ_m’s posterior induces P(θ_m > ν) = 1 − F_Beta(ν; α_m + r_m, β_m + n_m − r_m); the sum W_{>ν} = Σ I(θ_m > ν) follows a Poisson binomial distribution with these probabilities, enabling closed-form variance and credible intervals.
- Core assumption: The threshold-based indicator aggregation is the policy-relevant metric; θ_m posteriors accurately reflect each input’s behavior distribution.
- Evidence anchors:
  - [Section 4.1.1] "W_{>ν} follows a Poisson binomial distribution with parameters P_{θ_m|r_m}(θ_m > ν) … and has variance Var(W_{>ν}) = Σ F_Beta(ν; α_m + r_m, β_m + n_m − r_m) · (1 − F_Beta(…))."
  - [Section 4.2.1] "Using greedy decoding … 98/100 prompts were refused. However, with repeated stochastic text generations, the mode of W_{>ν} under our Bayesian model estimates that there are actually 4 additional prompts with a refusal probability ≤ 95%."
  - [corpus] Related work (Textual Bayes, arXiv:2506.10660) also proposes Bayesian uncertainty quantification for LLM systems but targets different aggregation use-cases; direct comparison of Poisson binomial vs. alternative aggregation approaches is not available.
- Break condition: If aggregation function g(·) is non-decomposable or requires joint dependencies among θ_m’s, Poisson binomial no longer applies and Monte Carlo approximation must account for correlation.

### Mechanism 3
- Claim: Sequential input selection via variance-reduction rewards can accelerate uncertainty reduction in aggregate metrics when behaviors are heterogeneous.
- Mechanism: Formulate as multi-armed bandit; reward for selecting input m is expected reduction in Var(W_{>ν}) = γ_m(1 − γ_m) − E[γ_m,z(1 − γ_m,z)]. Greedy uses posterior mean θ_m; Thompson samples θ_m ∼ Beta(α_m, β_m). Algorithm picks arm maximizing expected reward.
- Core assumption: Variance of W is the right quantity to minimize; per-input uncertainty is informative about aggregate uncertainty; heterogeneity across inputs exists so selective sampling helps.
- Evidence anchors:
  - [Section 5.2] "The main idea behind the sequential algorithms is to stochastically generate text from the system using the input that we expect to give us the largest reward. We focus … on deriving a reward based on W_{>ν}."
  - [Section 6.1, Figure 6] "Both the greedy and Thompson sampling approaches result in a quicker reduction in Var(W_{>ν}) than using the round-robin approach."
  - [Section 6.2] "In this case study, we do not observe any significant advantage to the sequential approaches. This is not particularly surprising given the results in Section 4, which suggest that a majority of the inputs are refused with θ > 0.95."
  - [corpus] No external corpus papers evaluate this specific variance-reduction reward for LLM evaluation; general bandit literature supports explore-exploit efficiency but not LLM-specific calibration.
- Break condition: When most inputs have homogeneous behavior (e.g., all high refusal probability), variance reduction saturates quickly and sequential methods offer marginal gains over round-robin.

## Foundational Learning
- Concept: Beta-binomial conjugacy
  - Why needed here: Enables closed-form posterior updates for per-input behavior probabilities θ_m, avoiding expensive inference.
  - Quick check question: Given 10 generations with 3 positive labels and a Beta(1,1) prior, what is the posterior?
- Concept: Poisson binomial distribution
  - Why needed here: Aggregates independent but non-identical Bernoulli indicators into a distribution over counts with computable mean and variance.
  - Quick check question: If three Bernoulli probabilities are 0.8, 0.6, 0.4, what is the variance of their sum?
- Concept: Multi-armed bandit and Thompson sampling
  - Why needed here: Provides principled framework for sequential allocation of limited generation budget across inputs.
  - Quick check question: How does Thompson sampling differ from greedy selection in handling uncertainty?

## Architecture Onboarding
- Component map:
  - Prior initialization: Set α_m, β_m for each input (e.g., Beta(1,1) or Jeffreys Beta(0.5,0.5))
  - Data collection loop: For each input, generate n_m stochastic outputs and compute binary labels b(y)
  - Posterior update: Beta(α_m + r_m, β_m + n_m − r_m) per input
  - Aggregation computation: Compute W_{>ν} distribution via Poisson binomial (closed form) or Monte Carlo for W_mean/W_min
  - Sequential selector (optional): Compute expected variance reduction per arm; select next input using greedy or Thompson
- Critical path:
  1. Define benchmark inputs and binary labeling function
  2. Initialize priors uniformly or with domain knowledge
  3. Collect n generations per input (batch) or run sequential loop
  4. Update posteriors and compute aggregation distributions
  5. Report credible intervals for W_{>ν}, W_mean, or W_min
- Design tradeoffs:
  - Prior choice: Uniform Beta(1,1) vs. Jeffreys Beta(0.5,0.5) vs. informative; affects early-sample behavior
  - Batch vs. sequential: Sequential reduces API calls when heterogeneity is high; batch is simpler and reproducible
  - Greedy vs. Thompson: Greedy exploits posterior means; Thompson encourages exploration; paper suggests greedy may be sufficient for this setting
  - Threshold ν: Higher ν yields more conservative estimates; choice should reflect policy risk tolerance
- Failure signatures:
  - Homogeneous behavior across inputs: Sequential methods provide minimal gains; variance reduction plateaus early
  - Mis-specified priors: Overconfident priors can bias early estimates; mitigated by weak/uninformative priors
  - Stochastic or noisy binary judges: Current model assumes deterministic labeling; judge noise would inflate apparent uncertainty
  - Correlated inputs: Independence assumption may underestimate Var(W) if semantically similar prompts induce correlated θ_m
- First 3 experiments:
  1. Replicate pairwise preference case study on a subset of MT-Bench with n=10 generations per prompt; verify posterior credible intervals for W_{>0.75}
  2. Run refusal rate case study with n=10 vs. n=50; compare W_min distributions to detect prompts with near-zero refusal probability
  3. Implement greedy sequential selector on a simulated benchmark with known ground-truth θ_m (e.g., 50% high, 50% low); compare variance reduction against round-robin after 20M total generations

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on Beta-binomial independence assumption across inputs, which may underestimate aggregate uncertainty when inputs are semantically correlated
- Assumes deterministic binary labeling functions, not accounting for uncertainty in the labeling process itself
- Sequential algorithms show minimal benefit when most inputs have homogeneous behavior distributions
- Does not address uncertainty from potential model drift or changes in LLM behavior over time

## Confidence
- **High confidence**: The mathematical derivation of Beta-binomial posteriors and Poisson binomial aggregation is rigorous and internally consistent
- **Medium confidence**: The sequential algorithms' effectiveness depends on the specific input distribution and may not generalize across all benchmark types
- **Medium confidence**: The practical utility of Thompson sampling over greedy selection is not strongly established in the experiments presented

## Next Checks
1. **Independence assumption validation**: Apply hierarchical Bayesian modeling to a correlated input set (e.g., semantically similar prompts) and compare variance estimates against the current per-input independent model
2. **Label noise robustness**: Modify the framework to incorporate stochastic labeling functions (e.g., with known confusion matrices) and evaluate how posterior estimates change compared to the deterministic assumption
3. **Cross-benchmark generalization**: Apply the sequential algorithms to multiple benchmark types (preference, safety, capability) with varying degrees of input heterogeneity to establish when variance reduction is most beneficial