---
ver: rpa2
title: Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal
  Development Mechanism
arxiv_id: '2504.05621'
source_url: https://arxiv.org/abs/2504.05621
tags:
- learning
- tasks
- pruning
- task
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study addresses the challenge of enabling artificial neural\
  \ networks to continuously learn multiple cognitive functions efficiently, similar\
  \ to the human brain, while minimizing energy consumption and preventing catastrophic\
  \ forgetting. The authors propose a Continual Learning of Multiple Cognitive Functions\
  \ with Brain-inspired Temporal Development Mechanism (TD-MCL) that mimics the brain\u2019\
  s developmental process, where connections between cognitive modules evolve progressively\
  \ from basic to advanced functions."
---

# Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism

## Quick Facts
- arXiv ID: 2504.05621
- Source URL: https://arxiv.org/abs/2504.05621
- Reference count: 40
- The study proposes TD-MCL, achieving 68.88% average accuracy across 9 tasks on PMI dataset with exponential network compression, outperforming SOR-SNN by 6.15%.

## Executive Summary
The paper addresses the challenge of enabling artificial neural networks to continuously learn multiple cognitive functions with high efficiency and minimal energy consumption. Inspired by human brain development, the authors propose a Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism (TD-MCL) that mimics progressive neural connectivity formation. The method uses evolutionary algorithms to grow long-range connections between task modules and feedback-guided local pruning to reduce redundancy, achieving exponential reduction in network size while maintaining or improving task performance without relying on regularization, replay, or freezing strategies.

## Method Summary
The method implements a progressive neural architecture where each new task adds a new module while evolving long-range connections to previous modules through an evolutionary algorithm. The architecture uses Spiking Neural Networks (SNNs) with adaptive threshold neurons and incorporates a feedback-guided local pruning mechanism based on Hebbian traces. The evolutionary controller dynamically updates connection probabilities based on task performance, while the pruning mechanism removes redundant connections within modules. This approach enables continual learning by allowing the network to grow new capacity for new tasks while pruning unused capacity from previous tasks, achieving both plasticity and stability.

## Key Results
- TD-MCL achieves 68.88% average accuracy across 9 tasks on PMI dataset
- Exponential reduction in network size while maintaining/improving performance
- Outperforms existing methods (SOR-SNN) by 6.15% in accuracy
- Eliminates catastrophic forgetting without regularization, replay, or freezing

## Why This Works (Mechanism)
The method works by mimicking the brain's developmental process where connections form progressively from basic to advanced cognitive functions. The evolutionary algorithm grows beneficial long-range connections between task modules, allowing knowledge transfer across tasks. The feedback-guided pruning mechanism removes redundant connections based on their actual contribution to task performance, preventing resource waste. This combination allows the network to maintain essential knowledge while freeing resources for new learning, achieving the balance between plasticity and stability that enables effective continual learning.

## Foundational Learning
- **Progressive Neural Architecture**: Sequential addition of task-specific modules with evolving connections - needed for enabling new capacity without destroying old knowledge - quick check: verify module growth follows task sequence
- **Evolutionary Algorithm for Connection Growth**: Uses task performance to guide which long-range connections to form - needed for discovering beneficial feature transfer pathways - quick check: measure connection formation rate vs accuracy gain
- **Hebbian-Based Pruning Mechanism**: Removes connections based on firing history and selection counts - needed for efficient resource allocation and preventing redundancy - quick check: track pruning rate vs parameter reduction
- **Spiking Neural Networks with Adaptive Thresholds**: Discrete spike-based computation with learnable membrane dynamics - needed for energy-efficient inference and temporal processing - quick check: compare energy consumption vs standard SNNs

## Architecture Onboarding

- Component map:
  - Task Modules: Horizontally-expanded ResNet18 blocks (e.g., `B^t_1`...`B^t_4`) for each task `t`
  - Long-range Connectors: Adaptive, evolved connections between blocks 2-4 of new task modules and blocks of previous task modules, governed by probability vectors `P^t,k_b`
  - Local Pruner: Feedback-guided mechanism applying inhibition/pruning to weights within a task module using thresholds derived from Hebbian traces and evolutionary selection counts
  - Evolutionary Controller: Online algorithm updating `P` (connection probabilities) based on loss performance from current task
  - PLIF Neurons: Core units with learnable membrane time constants `Ï„` that convert input into discrete spikes

- Critical path:
  1. New task `t` data arrives
  2. New module `B^t` is instantiated (grows)
  3. Evolutionary controller proposes long-range connections to previous modules
  4. Network is trained with surrogate gradients
  5. Evolutionary controller updates `P` based on loss
  6. Local pruner evaluates all prior task modules using updated global knowledge and local traces, applies pruning
  7. The sparse, integrated network proceeds to task `t+1`

- Design tradeoffs:
  - **Plasticity vs. Stability**: Aggressive pruning (high plasticity) frees resources for new tasks but risks erasing rare-but-important memories (low stability)
  - **Connection Sparsity vs. Reuse**: Enforcing high sparsity (~50%) in long-range connections saves computation but may prevent discovery of beneficial but non-obvious feature transfers
  - **Task Order**: Performance is coupled to the curriculum; a poor ordering cannot be recovered by the algorithm

- Failure signatures:
  - **Runaway Forgetting**: Accuracy on early tasks collapses immediately after a new task is learned. Indicates pruning thresholds are too aggressive or long-range connections are creating negative interference
  - **Stagnation on New Tasks**: Accuracy on later, complex tasks fails to improve beyond baseline. Indicates long-range connections are failing to form or are too sparse to transfer useful features
  - **No Network Compression**: The parameter count of early modules does not decrease over time. Indicates the pruning criterion (`H_ij` and `E^k_b`) is not identifying any connections as redundant

- First 3 experiments:
  1. **Baseline Sanity Check**: Implement only the progressive module growth without any long-range connections or pruning. Compare accuracy and parameter count on the PMI dataset to a standard multi-head model to isolate the contribution of each component
  2. **Connection Ablation**: Fix the long-range connections to be fully connected instead of evolved. Compare accuracy, training time, and final network sparsity against the adaptive evolutionary method to measure efficiency gains
  3. **Pruning Sensitivity**: Run TD-MCL with different pruning aggressiveness (e.g., scaling the threshold in Eq. 12) and plot the trade-off curve between final average accuracy across all 9 tasks and the final total parameter count. Identify the point of catastrophic failure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the TD-MCL mechanism be effectively scaled to large-scale architectures, such as Mixture-of-Experts (MoE) models?
- Basis in paper: The discussion states that incorporating dynamic structural reorganization into large-scale networks is a "promising direction for future research," specifically citing DeepSeek's MoE as a potential application
- Why unresolved: The current study validates the method using ResNet18 on Spiking Neural Networks (SNNs); scaling to massive parameter counts introduces optimization challenges not yet addressed
- What evidence would resolve it: Successful implementation of TD-MCL in a large MoE-based Transformer, demonstrating improved energy efficiency and continual learning capabilities

### Open Question 2
- Question: How robust is the TD-MCL algorithm when tasks are presented in a random or non-developmental order?
- Basis in paper: The paper assumes a "simple to complex" progression based on infant development, and the experiments strictly follow this sequence; however, real-world continual learning often involves unpredictable task sequences
- Why unresolved: The reliance on "foundational primary functions" to support complex ones implies a dependency on order which has not been stress-tested against random presentation
- What evidence would resolve it: Experiments on the PMI dataset with shuffled task sequences to measure performance retention and knowledge transfer efficiency

### Open Question 3
- Question: Does the feedback-guided pruning mechanism preserve critical knowledge when scaled to hundreds of tasks?
- Basis in paper: The introduction highlights that the human brain learns "hundreds of cognitive functions," yet the experimental validation covers only nine tasks
- Why unresolved: The "exponential reduction in network size" might eventually delete necessary plasticity or critical pathways if applied over a much longer task sequence
- What evidence would resolve it: Long-term experiments with 50+ tasks analyzing the correlation between cumulative pruning rates and the degradation of initial task performance

## Limitations
- Computational overhead of evolutionary algorithm scales quadratically with number of modules
- Pruning mechanism assumes stable firing patterns during training, which may not hold in noisy environments
- Performance demonstrated only on specific cross-domain dataset without extensive testing across varied data distributions

## Confidence

- **High Confidence**: The core claim that TD-MCL achieves exponential network compression while maintaining task performance is well-supported by the experimental results. The comparison with SOR-SNN shows a clear improvement of 6.15% accuracy.
- **Medium Confidence**: The assertion that the method prevents catastrophic forgetting is supported, but the long-term stability across many more tasks remains untested. The pruning mechanism's effectiveness in preserving critical knowledge while reducing redundancy is demonstrated but needs broader validation.
- **Low Confidence**: The biological plausibility claims linking the algorithm to human brain development are speculative, as the paper does not provide neuroscientific evidence for the specific connection patterns or developmental timing proposed.

## Next Checks
1. **Robustness to Task Order**: Systematically vary the sequence of tasks in the PMI dataset and measure the impact on final accuracy and network compression. This would reveal whether the evolutionary algorithm can compensate for suboptimal curricula.
2. **Generalization to New Domains**: Evaluate TD-MCL on a separate continual learning benchmark (e.g., Split CIFAR-100 or CORe50) to test whether the performance gains transfer beyond the PMI dataset.
3. **Memory Overhead Analysis**: Profile the memory usage of the evolutionary controller and Hebbian trace buffers during training to quantify the practical computational cost of the proposed method compared to simpler baselines.