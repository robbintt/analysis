---
ver: rpa2
title: Instruction-aware User Embedding via Synergistic Language and Representation
  Modeling
arxiv_id: '2510.11016'
source_url: https://arxiv.org/abs/2510.11016
tags:
- user
- representation
- learning
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of existing user representation
  models, which struggle with generalizability across domains and sensitivity to noisy
  behavioral signals. The authors propose InstructUE, an instruction-aware user embedding
  foundation model that leverages large language models (LLMs) to generate general
  and instruction-aware user representations.
---

# Instruction-aware User Embedding via Synergistic Language and Representation Modeling

## Quick Facts
- arXiv ID: 2510.11016
- Source URL: https://arxiv.org/abs/2510.11016
- Reference count: 40
- Key outcome: Proposed InstructUE model achieves significant improvements in user prediction, marketing, and recommendation tasks across multiple domains through instruction-aware user embedding.

## Executive Summary
This paper addresses the limitations of existing user representation models, which struggle with generalizability across domains and sensitivity to noisy behavioral signals. The authors propose InstructUE, an instruction-aware user embedding foundation model that leverages large language models (LLMs) to generate general and instruction-aware user representations. InstructUE introduces a multi-encoder architecture with a lightweight adapter that efficiently processes heterogeneous data from six different sources while preserving their structural characteristics. Additionally, it proposes a novel contrastive-autoregressive training framework that bridges language and representation spaces through a curated UserQA dataset. The contrastive-autoregressive training framework simultaneously leverages autoregressive learning to capture domain knowledge in language space and contrastive learning to align user-text embeddings in representation space, thereby enhancing the instruction-awareness and noise-robustness of user embeddings. Extensive experiments on real-world applications demonstrate that InstructUE significantly outperforms existing methods across multiple domains including user prediction, marketing, and recommendation scenarios, with instruction-aware user modeling effectively achieving instruction-guided denoising of user information in specific scenarios.

## Method Summary
InstructUE addresses the challenge of creating generalizable user embeddings that can adapt to different downstream tasks through natural language instructions. The model processes six types of heterogeneous user data (PayBill, Mini Program, SPM, Search sequences, and Tabular features) using a multi-encoder architecture where each modality has its own encoder connected to a lightweight adapter. A special <USER> token at the end of the sequence serves as the user embedding, extracted from the final hidden state. The model is trained using a contrastive-autoregressive framework that combines autoregressive next-token prediction with InfoNCE contrastive loss, aligning user embeddings with answer embeddings. Training uses the UserQA dataset with 200M samples, employing LoRA fine-tuning on a Qwen2.5-0.5B-Instruct backbone for 150k steps. The model achieves instruction-awareness by conditioning representations on natural language instructions, enabling dynamic, task-specific embeddings that can effectively denoise user information in specific scenarios.

## Key Results
- InstructUE outperforms existing methods across multiple domains including user prediction, marketing, and recommendation scenarios
- Instruction-aware user modeling achieves effective instruction-guided denoising of user information in specific scenarios
- The contrastive-autoregressive training framework enhances both instruction-awareness and noise-robustness of user embeddings

## Why This Works (Mechanism)
The effectiveness of InstructUE stems from its ability to bridge language and representation spaces through synergistic training. By leveraging LLMs' instruction-following capabilities, the model can generate task-specific user representations that adapt to different downstream objectives. The contrastive-autoregressive framework simultaneously captures domain knowledge through autoregressive learning in language space while aligning user-text embeddings in representation space through contrastive learning. This dual approach ensures that user embeddings are both semantically meaningful and semantically aligned with natural language instructions. The multi-encoder architecture with lightweight adapters preserves the structural characteristics of heterogeneous data sources while enabling efficient processing. The use of a special <USER> token for embedding extraction ensures that the final representation captures the entire user profile while maintaining task-specific focus based on the instruction context.

## Foundational Learning
- **Contrastive Learning**: Used to align user embeddings with answer embeddings in representation space; needed to ensure semantic consistency between user representations and natural language instructions; quick check: verify embedding alignment through nearest neighbor search
- **Autoregressive Language Modeling**: Captures domain knowledge in language space through next-token prediction; needed to maintain semantic richness and contextual understanding; quick check: evaluate perplexity on held-out UserQA samples
- **Multi-modal Fusion**: Processes heterogeneous user data sources through modality-specific encoders with adapters; needed to preserve structural characteristics while enabling joint representation; quick check: compare performance with and without modality adapters
- **Instruction Tuning**: Conditions user embeddings on natural language instructions; needed to achieve task-specific representations and instruction-guided denoising; quick check: test with manual vs. synthetic instructions
- **Adapter-based Transfer Learning**: Lightweight parameter-efficient fine-tuning of LLM backbone; needed for efficient adaptation to user embedding task; quick check: measure parameter count vs. full fine-tuning
- **InfoNCE Loss with False-negative Masking**: Contrastive objective with same-side negatives and false-negative filtering; needed to improve embedding quality by avoiding contradictory negative samples; quick check: analyze impact of false-negative threshold on downstream performance

## Architecture Onboarding

**Component Map**: User Data -> Multi-Encoder Architecture -> Adapter Layers -> LLM Backbone -> <USER> Token Extraction -> Contrastive-Autoregressive Training -> User Embedding

**Critical Path**: The critical path flows from heterogeneous user data through modality-specific encoders, adapter layers for projection to LLM space, the LLM backbone processing with instruction context, and finally extracting the user embedding from the <USER> token's final hidden state. The contrastive-autoregressive training framework then optimizes this representation through joint autoregressive and contrastive objectives.

**Design Tradeoffs**: The multi-encoder approach with adapters provides flexibility and efficiency but adds complexity compared to single-encoder architectures. Using a special <USER> token for embedding extraction simplifies the process but may limit the representation to only the final token's context. The joint training framework balances language modeling with representation learning but requires careful hyperparameter tuning to prevent one objective from dominating.

**Failure Signatures**: Performance degradation occurs when manual instructions don't align with business definitions, indicating sensitivity to instruction quality. Using average pooling instead of the final <USER> token causes representation collapse, highlighting the importance of proper embedding extraction. The model may also struggle with truly unseen domains despite its generalizability claims, suggesting limitations in the synthetic UserQA data's coverage.

**First Experiments**: 
1. Implement the multi-encoder architecture with adapter modules and verify that each modality's data is properly processed and projected to the LLM space
2. Test the contrastive-autoregressive training framework with a small subset of UserQA data to ensure both objectives contribute to model learning
3. Conduct an ablation study comparing the special <USER> token embedding extraction method against alternative approaches like mean pooling or CLS token

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies entirely on held-out datasets from the same industrial source, raising questions about external validity and generalizability to truly unseen domains
- The paper does not report ablation studies isolating the contribution of the contrastive-autoregressive framework from the multi-encoder architecture
- The synthesis methodology for UserQA data is only briefly described, with limited detail on quality control or bias mitigation in LLM-generated instruction-answer pairs

## Confidence

**High confidence**: The technical implementation of the multi-encoder architecture with adapter modules and the joint contrastive-autoregressive training framework is clearly specified and reproducible. The superiority over baseline models in the reported evaluation scenarios is well-supported by quantitative metrics (AUC, KS).

**Medium confidence**: The claim of achieving instruction-awareness through language-guided denoising is supported by controlled comparisons but depends heavily on the quality and consistency of synthesized UserQA data. The practical utility across diverse real-world applications is demonstrated but not independently validated.

**Low confidence**: The scalability claims regarding computational efficiency are based on internal benchmarks without comparison to standardized metrics or alternative implementations. The long-term stability of embeddings under concept drift is not evaluated.

## Next Checks

1. Conduct external validation on open benchmark datasets (e.g., Amazon, MovieLens) to assess generalizability beyond the industrial test scenarios
2. Perform ablation studies systematically removing either the contrastive loss or autoregressive component to quantify their individual contributions to performance gains
3. Implement and test a controlled noise injection framework across different instruction types to measure robustness bounds and identify failure modes systematically