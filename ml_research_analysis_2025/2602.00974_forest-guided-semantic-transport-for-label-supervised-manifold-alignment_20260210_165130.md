---
ver: rpa2
title: Forest-Guided Semantic Transport for Label-Supervised Manifold Alignment
arxiv_id: '2602.00974'
source_url: https://arxiv.org/abs/2602.00974
tags:
- alignment
- batch
- domains
- semantic
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FoSTA (Forest-guided Semantic Transport Alignment),
  a scalable framework for label-supervised manifold alignment that addresses limitations
  of Euclidean-based methods when features are weakly related to the task. FoSTA leverages
  forest-induced geometry through semi-supervised RF-GAP proximities to denoise intra-domain
  structure and recover task-relevant manifolds.
---

# Forest-Guided Semantic Transport for Label-Supervised Manifold Alignment

## Quick Facts
- arXiv ID: 2602.00974
- Source URL: https://arxiv.org/abs/2602.00974
- Reference count: 40
- This paper introduces FoSTA (Forest-guided Semantic Transport Alignment), a scalable framework for label-supervised manifold alignment that addresses limitations of Euclidean-based methods when features are weakly related to the task.

## Executive Summary
FoSTA (Forest-guided Semantic Transport Alignment) addresses label-supervised manifold alignment by leveraging forest-induced geometry through semi-supervised RF-GAP proximities to denoise intra-domain structure and recover task-relevant manifolds. The method constructs semantic representations from label-informed forest affinities and aligns them via fast hierarchical semantic transport using HiRef. Extensive comparisons on synthetic benchmarks show FoSTA improves correspondence recovery and label transfer compared to established baselines, particularly in challenging feature-split scenarios. In single-cell integration tasks, FoSTA demonstrates strong biological preservation across various simulated batch effects while maintaining competitive batch correction performance, with an average ranking of first in biological conservation metrics and third in batch correction.

## Method Summary
FoSTA aligns two domains (source fully labeled, target partially labeled) without known pointwise correspondences using shared label space. The method first computes semi-supervised RF-GAP intra-domain affinities, then builds C-dimensional semantic profiles per sample via class-weighted aggregation and L2-normalization. These profiles are aligned using HiRef to obtain a sparse transport matrix, which is then propagated through intra-domain affinities to construct a dense cross-domain graph. Finally, a joint embedding is computed using Landmark PHATE. The approach scales near-linearly in time and memory, making it suitable for large-scale data integration.

## Key Results
- FoSTA improves correspondence recovery and label transfer compared to established baselines, particularly in challenging feature-split scenarios
- In single-cell integration tasks, FoSTA demonstrates strong biological preservation with average ranking of first in biological conservation metrics
- The method maintains competitive batch correction performance, ranking third overall while prioritizing biological structure preservation
- FoSTA scales near-linearly in time and memory, making it suitable for large-scale data integration

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Replacing Euclidean geometry with forest-based proximities (RF-GAP) likely filters out nuisance variation when features are only weakly related to the task.
- **Mechanism**: Random Forests partition data based on information gain relative to labels. RF-GAP proximities define "closeness" based on leaf co-occurrence weighted by out-of-bag status. This implicitly downweights features irrelevant to the label, constructing a task-relevant manifold that Euclidean distances (which treat all features equally) miss.
- **Core assumption**: The label information provided is sufficient for the underlying forest model to learn meaningful decision boundaries that generalize to unlabeled data.
- **Break condition**: If the feature space is extremely high-dimensional with very sparse signal, the Random Forest may fail to find robust splits, yielding noisy proximities that degrade alignment.

### Mechanism 2
- **Claim**: Mapping samples to a low-dimensional "semantic profile" allows FoSTA to bypass the heterogeneity of raw feature spaces during alignment.
- **Mechanism**: Instead of matching points based on raw coordinates (which may differ across modalities), FoSTA projects points into a shared space defined by their affinity to class labels (C-dimensional vector). It then uses HiRef (hierarchical optimal transport) to match these profiles. This abstracts domain-specific noise into a unified semantic representation.
- **Core assumption**: The class labels available in the source and target domains share a sufficiently similar underlying distribution or semantic structure.
- **Break condition**: If the target domain contains classes completely absent from the source domain labels (or vice versa), the semantic vectors will have mismatched dimensions or zero overlap, breaking the transport cost calculation.

### Mechanism 3
- **Claim**: Propagating the sparse transport map through intra-domain affinities creates a dense, robust cross-domain graph.
- **Mechanism**: The optimal transport solver (HiRef) produces a sparse, bijective mapping. FoSTA relaxes this rigid assignment by multiplying the transport matrix $T$ with the intra-domain affinities $W$. This allows "neighbors of matched points" to feel the alignment force, effectively smoothing the correspondence across the manifold.
- **Core assumption**: The intra-domain affinities accurately reflect local geometric structure; if they are noisy, propagation will amplify errors.
- **Break condition**: If the transport map $T$ is significantly incorrect (e.g., matching wrong classes), propagation will create cross-domain bridges between unrelated clusters, destroying the manifold structure.

## Foundational Learning

- **Concept: RF-GAP Proximities**
  - **Why needed here**: This acts as the "geometry engine" of the paper. Unlike standard Random Forest proximity, RF-GAP corrects for bias using out-of-bag samples.
  - **Quick check question**: Can you explain why a standard Random Forest proximity matrix might be biased compared to RF-GAP, particularly regarding training samples?

- **Concept: Semi-Supervised Manifold Alignment**
  - **Why needed here**: The paper operates in the gap between "unsupervised" (no info) and "fully supervised" (anchor points). It uses labels to guide geometry without needing point-to-point pairs.
  - **Quick check question**: How does label supervision differ from anchor supervision in the context of aligning two datasets?

- **Concept: Hierarchical Optimal Transport (HiRef)**
  - **Why needed here**: Standard OT is $O(N^3)$. HiRef provides the scalability ($O(N \log N)$) necessary for the "large-scale" claim in the abstract by recursively partitioning the problem.
  - **Quick check question**: Why is solving a global Optimal Transport problem computationally prohibitive, and how does a hierarchical solver approximate it?

## Architecture Onboarding

- **Component map**: Inputs -> RF-GAP Geometry Engine -> Semantic Encoder -> HiRef Solver -> Integrator -> Joint Embedding
- **Critical path**: The **Geometry Engine (RF-GAP)** is the most sensitive component. If the forest is undertrained or labels are too sparse, the proximities $W$ will not reflect the task-relevant manifold, causing the subsequent transport $T$ to match noise.
- **Design tradeoffs**:
  - **Bio Conservation vs. Batch Mixing**: The paper explicitly prioritizes biological conservation (preserving local structure) over aggressive batch mixing. This is a feature, not a bug.
  - **Speed vs. Precision**: Using HiRef allows near-linear scaling but enforces a bijection assumption (one-to-one mapping), which may be suboptimal if domains have different class balances.
- **Failure signatures**:
  - **"Streaking" in embeddings**: Visualized points form lines rather than clusters; suggests the transport map $T$ is failing to find confident matches.
  - **High FOSCTTM (Fraction of Samples Closer Than True Match)**: Indicates the geometry $W$ is failing to separate classes before transport.
  - **Memory Overflow**: While the method is near-linear, storing the full affinity $W$ for extremely large $N$ ($>100k$) without sparse optimizations will crash.
- **First 3 experiments**:
  1. **Validate Geometry**: Train RF-GAP on a single domain. Visualize the affinity matrix $W$ vs. a Euclidean distance matrix. Confirm that $W$ respects label boundaries better than Euclidean distance.
  2. **Transport Sanity Check**: Run FoSTA on synthetic "blobs" data with distinct classes. Verify that the transport matrix $T$ aligns Class A (Domain 1) strictly with Class A (Domain 2).
  3. **Ablation on Noise**: Replicate the "add noise" experiment from Section 4.1. Add Gaussian noise to one domain and confirm that FoSTA maintains high label transfer accuracy while baselines degrade.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can FoSTA be extended to handle domains with partially overlapping label spaces, where some classes exist in only one domain?
- **Basis in paper**: [explicit] The authors state in the conclusion: "Extending FoSTA to partially overlapping label spaces... remains an important direction for future work."
- **Why unresolved**: The current formulation assumes shared label sets across domains (C={1,...,C} for both domains), which may not hold in real-world scenarios where different domains capture distinct but related phenomena.
- **What evidence would resolve it**: A modified formulation that accommodates class-conditioned semantic representations with partial overlap, validated on benchmark datasets with controlled label space discrepancies and measured via label transfer accuracy.

### Open Question 2
- **Question**: What strategies can effectively extend FoSTA to imbalanced domain sizes where n≠m?
- **Basis in paper**: [explicit] Appendix D states: "We leave a full treatment of imbalanced domain alignment within the FoSTA framework for future work."
- **Why unresolved**: The current bijective formulation via HiRef assumes balanced domains. Proposed strategies (subsampling, dummy points, feature-space oversampling, or leaf-space augmentation) are sketched but untested.
- **What evidence would resolve it**: Comparative evaluation of different imbalanced-domain strategies on datasets with known size ratios, measuring correspondence recovery (FOSCTTM) and label transfer accuracy across varying n:m ratios.

### Open Question 3
- **Question**: How sensitive is FoSTA's performance to the quality and hyperparameters of the underlying random forest model?
- **Basis in paper**: [explicit] The conclusion identifies "dependence on the quality of the underlying forest model" as a limitation.
- **Why unresolved**: While RF-GAP proximities are shown to be effective, the method's robustness to forest hyperparameters (number of trees, depth, minimum leaf size) or to poorly-trained forests remains uncharacterized.
- **What evidence would resolve it**: Ablation studies varying forest hyperparameters systematically and evaluating downstream alignment quality; analysis of failure modes when forests are underfit or overfit.

## Limitations
- The method's performance critically depends on the quality of the underlying Random Forest model, with no characterization of hyperparameter sensitivity
- Current formulation assumes shared label spaces across domains, limiting applicability to real-world scenarios with partial label overlap
- Bijective transport assumption via HiRef may be suboptimal for imbalanced domain sizes, with no tested strategies for handling n≠m cases

## Confidence
- **High**: Synthetic benchmark results where ground truth correspondence exists and can be directly measured
- **Medium**: Single-cell biological integration results where no single "ground truth" exists and metrics provide indirect validation
- **Low**: Near-linear scaling claim due to underspecified HiRef implementation details and lack of open-source implementation

## Next Checks
1. Replicate the RF-GAP affinity visualization to confirm it outperforms Euclidean distance in preserving label boundaries under noise
2. Test FoSTA on a domain adaptation task where source/target labels have non-overlapping classes to expose the semantic representation limitation
3. Profile memory usage on datasets with N > 50k samples to verify the near-linear scaling claim