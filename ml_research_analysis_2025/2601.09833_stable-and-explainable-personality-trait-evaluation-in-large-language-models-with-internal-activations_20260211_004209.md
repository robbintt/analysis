---
ver: rpa2
title: Stable and Explainable Personality Trait Evaluation in Large Language Models
  with Internal Activations
arxiv_id: '2601.09833'
source_url: https://arxiv.org/abs/2601.09833
tags:
- persona
- trait
- pvni
- variants
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Persona-Vector Neutrality Interpolation (PVNI),
  an internal-activation-based method for stable and explainable personality trait
  evaluation in large language models. PVNI extracts a persona vector associated with
  a target personality trait from the model's internal activations using contrastive
  prompts, then estimates the neutral trait score by interpolating along the persona
  vector.
---

# Stable and Explainable Personality Trait Evaluation in Large Language Models with Internal Activations

## Quick Facts
- arXiv ID: 2601.09833
- Source URL: https://arxiv.org/abs/2601.09833
- Reference count: 40
- Primary result: PVNI achieves lowest variance in personality trait evaluation across diverse LLMs compared to existing methods

## Executive Summary
This paper introduces Persona-Vector Neutrality Interpolation (PVNI), a method for stable and explainable personality trait evaluation in large language models using internal activations. PVNI extracts persona vectors from contrastive prompt responses and estimates neutral trait scores through linear interpolation along these vectors. The approach provides both stability (lower variance across prompt variants) and interpretability (geometric interpretation of trait positions in activation space). Extensive experiments demonstrate PVNI's superiority over existing methods in producing consistent personality trait evaluations across diverse models and prompt types.

## Method Summary
PVNI extracts a persona vector associated with a target personality trait from model internal activations using contrastive prompts (positive, negative, and neutral). For each trait, it computes mean hidden states from responses to these prompts, defines the persona vector as the difference between positive and negative means, and projects the neutral representation onto this axis. The projection coefficient is then used to interpolate between judge-scored anchor points, yielding a stable estimate of the neutral trait score. This process is repeated for each Big Five trait to construct a complete personality profile.

## Key Results
- PVNI achieves substantially lower standard deviation in trait scores across questionnaire and role-play prompt variants compared to existing methods
- The method demonstrates consistent stability advantages across diverse LLMs including Qwen-2.5-7B, Llama-3-8B, and Mistral-7B
- Theoretical analysis establishes effectiveness and generalization properties through linear persona direction theory

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Persona Vector Extraction
The difference between mean hidden states for trait-promoting versus trait-avoiding prompts defines a direction in representation space corresponding to the target trait. For each trait, responses under positive, negative, and neutral prompts are generated; mean hidden states are computed at a fixed layer and token position; and the persona vector is defined as the difference between positive and negative mean hidden states. This works because personality traits correspond to consistent, extractable directions in the model's internal activation space that persist across semantically equivalent prompts. If the model lacks a consistent internal representation for the target trait, or if positive/negative prompts elicit highly overlapping hidden states, the extracted direction may be dominated by noise rather than trait signal.

### Mechanism 2: Projection-Based Weight Interpolation
The relative position of a neutral prompt's representation along the persona axis—computed via vector projection—yields a stable interpolation weight for estimating prompt-neutral trait scores. The neutral vector is defined as the difference between neutral and negative mean hidden states, and the projection coefficient is computed as the dot product ratio between the neutral and persona vectors. This works because the neutral prompt's representation lies approximately along the line segment connecting positive and negative prompt representations in the trait subspace. If trait effects are curved, multi-modal, or context-dependent in a way that places neutral behavior off the positive–negative axis, projection-based interpolation may systematically misestimate the neutral score.

### Mechanism 3: Linear Theory of Persona Directions
Persona-induced activation shifts behave approximately as linear directional amplifiers, justifying vector arithmetic for trait evaluation and composition. Under assumptions of local linearity and well-trained persona adaptation, persona vectors act as directional amplifiers that selectively boost the trait-component of the hidden state, yielding near-linear additivity in persona editing. This works because hidden-state variation for persona effects concentrates in a low-dimensional subspace with sparse, approximately aligned updates. If persona directions exhibit strong nonlinear interactions or the residual term dominates, composition and negation guarantees degrade; orthogonal trait assumptions may not hold empirically.

## Foundational Learning

- **Concept: Contrastive representation analysis**
  - Why needed here: PVNI isolates trait directions by computing differences between activations under opposing prompt conditions, requiring understanding of how averaging and differencing reveal structure in high-dimensional spaces.
  - Quick check question: Why does computing mean hidden states over multiple inputs before differencing produce more robust persona vectors than single-example differences?

- **Concept: Vector projection and linear interpolation**
  - Why needed here: The core PVNI computation projects the neutral vector onto the persona axis and uses the resulting scalar coefficient for interpolation, requiring fluency with dot products and geometric interpretation.
  - Quick check question: If coef = 0.3, what does this imply about the neutral representation's position relative to the negative and positive anchor representations?

- **Concept: Local linearity in deep representations**
  - Why needed here: The theoretical justification assumes that within a neighborhood of the activation space, persona score changes are approximately linear in the perturbation direction, despite global nonlinearity.
  - Quick check question: Why might high-dimensional neural representations exhibit approximately linear structure along certain semantically meaningful directions even though the overall mapping is nonlinear?

## Architecture Onboarding

- **Component map:** Hidden-state extractor -> Mean activation computation -> Persona vector module -> Interpolation module -> Judge API -> Trait score output

- **Critical path:**
  1. Design or select contrastive prompts for each of the Big Five traits
  2. For each trait: generate responses under pos/neg/neu prompts, extract activations, judge pos/neg responses
  3. Compute mean activations, persona and neutral vectors, projection coefficient
  4. Interpolate between scored anchors to obtain ŝ^i(M); assemble into Big Five profile

- **Design tradeoffs:**
  - Layer selection: The paper uses a fixed layer but does not extensively ablate; earlier layers may capture syntax, later layers more semantic trait signals
  - Prompt ensemble size: Larger ensembles reduce variance but increase compute and judge costs; paper uses 10 variants
  - Judge choice: Absolute scores depend on judge preferences; PVNI's primary claim is variance reduction across prompt variants, not judge-invariant calibration

- **Failure signatures:**
  - High variance despite PVNI: May indicate poorly designed contrastive prompts, weak trait representation in the model, or inconsistent judge behavior
  - Coefficient consistently clipped at 0 or 1: Neutral representation lies outside the pos–neg segment; check prompt neutrality or consider multi-anchor calibration
  - Strong cross-trait correlation: Persona directions are not independent; interpretation as distinct traits becomes confounded

- **First 3 experiments:**
  1. **Baseline replication on open-source model**: Run PVNI on Qwen-2.5-7B for all five traits; compare variance (std across variants) against self-report and open-ended methods using the paper's protocol
  2. **Layer ablation study**: Repeat PVNI extracting activations from layers {8, 16, 24, 32}; plot how ŝ^i and variance change by layer to identify optimal extraction depth
  3. **Prompt ensemble sensitivity**: Run PVNI with 5, 10, and 20 prompt variants; measure variance reduction scaling to assess cost–stability tradeoffs

## Open Questions the Paper Calls Out

- **Open Question 1:** How can PVNI be adapted to handle personality traits where the neutral representation does not lie linearly on the axis between positive and negative anchors?
  - Basis in paper: The authors state that "neutrality may not lie on the pos–neg axis" in cases of curved or multi-modal trait effects, and identify "extending PVNI to multi-anchor or nonlinear calibration" as a necessary direction
  - Why unresolved: The current algorithm relies on a linear projection coefficient which assumes colinearity; this assumption fails if the geometry of the neutral state is non-linear relative to the contrastive prompts
  - What evidence would resolve it: A modification of the algorithm using non-linear manifolds or multiple anchors that yields lower error rates than the standard linear interpolation for traits known to have complex representations

- **Open Question 2:** Can the dependency on external API judges for score anchoring be removed or significantly reduced while maintaining evaluation stability?
  - Basis in paper: The Conclusion explicitly lists "reduce reliance on external judges" as a goal for future work, and the Limitations section suggests exploring "distilling a stable judge" or "multi-judge ensembles"
  - Why unresolved: PVNI currently requires an external judge to generate the positive and negative score anchors used for the final interpolation, introducing cost and potential bias
  - What evidence would resolve it: A comparative study showing that a self-supervised internal metric can replace the external judge score anchors without increasing the standard deviation across prompt variants

- **Open Question 3:** Does the stability of PVNI generalize to complex agentic settings, such as multilingual contexts, tool-augmented interactions, or multi-turn dialogues?
  - Basis in paper: The authors note in the Limitations section that experiments were "largely in a single-turn format" and results "may not fully transfer to multilingual settings, long conversations, or tool-augmented agents"
  - Why unresolved: The theoretical linearity assumptions were validated primarily on single-turn English text; the geometry of hidden states may change dynamically during extended tool use or code-switching
  - What evidence would resolve it: Reproducing the low-variance results of Table 1 on a dataset of multi-turn conversations or multilingual prompts, confirming that the persona vectors remain stable

## Limitations
- The method assumes personality traits correspond to consistent directions in activation space, which may not hold for traits with high contextual dependency
- Performance depends critically on the choice of judge API, with results potentially not generalizing to different judge models or prompting strategies
- The linear interpolation assumption may break down for traits where neutral representations do not lie approximately along the positive-negative axis in activation space

## Confidence
- **Low** for the claim that PVNI provides stable personality trait evaluation across all contexts
- **Medium** for PVNI's stability advantages over existing methods
- **Medium** for the interpretability of PVNI's projections

## Next Checks
1. **Cross-judge validation**: Run PVNI with multiple judge APIs (different models, different prompting strategies) to assess whether stability improvements persist independent of judge choice
2. **Alternative task generalization**: Apply PVNI to personality evaluation in text-to-image generation models or other generative AI systems to test whether the method generalizes beyond LLMs
3. **Layer-depth sensitivity analysis**: Systematically vary the extraction layer across the full depth of the model and measure how persona vector stability and interpolation accuracy change