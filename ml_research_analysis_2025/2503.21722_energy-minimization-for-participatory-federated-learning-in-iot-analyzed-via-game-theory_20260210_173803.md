---
ver: rpa2
title: Energy Minimization for Participatory Federated Learning in IoT Analyzed via
  Game Theory
arxiv_id: '2503.21722'
source_url: https://arxiv.org/abs/2503.21722
tags:
- nodes
- energy
- learning
- data
- incentive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses energy minimization in participatory federated
  learning (FL) for IoT systems, where nodes decide whether to participate in training
  rounds to minimize both task duration and energy consumption. A game-theoretic approach
  is proposed where nodes independently optimize their participation probability to
  balance local costs (energy, computation) against benefits (faster convergence,
  incentives).
---

# Energy Minimization for Participatory Federated Learning in IoT Analyzed via Game Theory

## Quick Facts
- arXiv ID: 2503.21722
- Source URL: https://arxiv.org/abs/2503.21722
- Reference count: 29
- Game-theoretic approach achieves PoA close to 1 with AoI-based incentives, improving from 1.28 without incentives

## Executive Summary
This paper addresses energy minimization in participatory federated learning (FL) for IoT systems by formulating participation as a game-theoretic optimization problem. Nodes independently decide whether to participate in training rounds to minimize both task duration and energy consumption. The authors propose a utility function that balances expected rounds to convergence, participation costs, and Age of Information (AoI)-based incentives. Through analytical derivation of Nash equilibria and numerical validation on CIFAR-10 with ResNet-18, the work demonstrates that AoI incentives can effectively counteract the tragedy of the commons, reducing the Price of Anarchy from 1.28 to approximately 1 while significantly improving participation rates.

## Method Summary
The approach formulates FL participation as a static game where each node maximizes utility u_i = -E[D] - γ·log(E[δ_i]) - c·p_i, balancing expected rounds to target accuracy against participation costs and AoI incentives. Nodes compute participation probabilities p_i that form Nash equilibria by solving ∂u_i/∂p_i = 0. The expected duration E[D] follows a Poisson-Binomial distribution based on participation probabilities, and total energy scales linearly with rounds. The CIFAR-10 dataset is split evenly across 50 nodes, with ResNet-18 models trained using FedAvg (E=5 local epochs). Energy is measured using the codecarbon library, and PoA quantifies the efficiency gap between distributed and centralized solutions.

## Key Results
- Without incentives (γ=0), Nash equilibrium yields p≈0.24 participation probability and PoA=1.28
- With AoI-based incentives (γ≈0.6), participation increases to p≈0.6 and PoA approaches 1
- Expected rounds to convergence decrease from 74.5 to 32 as participation increases from 0.1 to 0.69
- Total energy consumption follows approximately linear relationship with task duration

## Why This Works (Mechanism)

### Mechanism 1: Distributed Participation via Utility-Based Nash Equilibrium
Individual nodes independently compute participation probabilities that converge to a stable equilibrium without centralized coordination. Each node solves a local utility optimization problem where utility = -expected_rounds - cost×participation + incentive×participation_frequency. Nodes find Nash Equilibrium by solving ∂u_i/∂p_i = 0, yielding symmetric equilibrium p* where all nodes use the same probability. Core assumption: nodes have complete information about system parameters and behave rationally with identical cost structures.

### Mechanism 2: Age of Information (AoI) Incentive Offsets Participation Cost
AoI-based incentives counteract the tragedy of the commons by rewarding frequent participation, improving system efficiency from PoA=1.28 to PoA≈1. Expected AoI E[δ_i] = 1/p_i - 1/2 decreases as participation probability increases. The incentive term -γ·log(E[δ_i]) in the utility function increases utility for higher participation, offsetting the cost term -c·p_i. Core assumption: incentive weight γ is appropriately calibrated to balance cost c, with nodes valuing AoI reduction equivalently to energy savings.

### Mechanism 3: Energy Minimization Through Expected Round Reduction
Total energy consumption is approximately linear in the number of training rounds, so minimizing expected rounds to convergence also minimizes energy. Expected rounds E[D] follows Poisson-Binomial distribution based on participation probabilities. Higher average participation reduces expected rounds (e.g., p=0.69 → 32 rounds vs. p=0.1 → 74.5 rounds). Energy = (training + transmission + idle energy) × rounds. Core assumption: linear relationship between rounds and total energy, with per-round energy dominated by fixed costs rather than participation-dependent variable costs.

## Foundational Learning

- **Nash Equilibrium and Price of Anarchy**
  - Why needed here: Core analytical framework for evaluating distributed vs. centralized participation decisions; PoA quantifies efficiency loss from selfish behavior.
  - Quick check question: If all nodes reduce participation from p=0.6 to p=0.3 to save individual costs, what happens to total system rounds and each node's eventual utility?

- **Federated Averaging (FedAvg) Algorithm**
  - Why needed here: The underlying FL algorithm determines how participation affects convergence; nodes train locally for E epochs then transmit model updates.
  - Quick check question: Why does FedAvg require a minimum number of participating nodes per round to achieve target accuracy within reasonable time?

- **Age of Information (AoI)**
  - Why needed here: Provides the incentive signal; measures freshness of node's last contribution to the global model.
  - Quick check question: How does expected AoI change as a node's participation probability increases from 0.2 to 0.8?

## Architecture Onboarding

- Component map:
  - End nodes: Sensing/computing devices with local datasets, decision module for utility computation, energy monitoring
  - Central server (sink): Aggregates model updates via FedAvg, broadcasts global model, tracks validation accuracy
  - Communication layer: IEEE 802.11ax wireless links (RTS/CTS/ACK handshake, ~44MB model transmission)
  - Decision module: Computes p_i by solving ∂u_i/∂p_i = 0 given parameters (c, γ, convergence model)

- Critical path:
  1. Server broadcasts global model to all N nodes
  2. Each node i independently samples participation decision from Bernoulli(p_i)
  3. Participating nodes train for E local epochs, transmit updates
  4. Server aggregates updates, evaluates validation accuracy
  5. Repeat until target accuracy T_acc achieved for 3 consecutive rounds

- Design tradeoffs:
  - Higher γ (incentive weight) → higher participation but potential utility penalty at very high participation
  - Higher c (cost factor) → lower participation, higher PoA without incentives
  - Larger N (nodes) → better convergence but more coordination overhead
  - Symmetric assumption → simpler analysis but less realistic for heterogeneous IoT

- Failure signatures:
  - PoA > 1.5: Indicates incentive mechanism is under-calibrated or costs are too high
  - Participation probability → 0: Tragedy of the commons; nodes free-ride without contributing
  - Validation accuracy never reaches target: Insufficient average participation; model trapped in local minima
  - Energy variance >> mean: Unstable participation pattern; consider enforcing minimum participation constraints

- First 3 experiments:
  1. **Baseline characterization**: Run FL with fixed participation probabilities p ∈ {0.1, 0.3, 0.5, 0.7}, measure rounds-to-convergence and total energy. Fit polynomial model d(p) for utility calculations.
  2. **NE validation without incentives**: Set γ=0, vary cost c ∈ {0, 1, 2, 3, 4}. Compute NE participation p* analytically, verify via simulation that nodes converge to p*. Measure resulting PoA.
  3. **Incentive mechanism tuning**: Set c=1, sweep γ ∈ {0, 0.3, 0.6, 1.0}. For each γ, compute NE and measure participation rate and PoA. Identify γ that achieves PoA closest to 1.0 while maintaining participation > 0.5.

## Open Questions the Paper Calls Out
None

## Limitations
- The symmetric node assumption with identical cost structures is highly idealized for real IoT deployments where devices have heterogeneous capabilities and energy budgets.
- The polynomial model mapping participation probability to expected rounds is empirically derived but its coefficients and sensitivity are not fully specified.
- The incentive weight γ appears to be empirically calibrated rather than analytically derived from the cost-benefit structure.

## Confidence
- **High confidence**: The game-theoretic framework (Nash equilibrium computation, utility formulation) and the linear relationship between rounds and energy are well-established concepts with clear analytical derivations.
- **Medium confidence**: The empirical results showing PoA reduction from 1.28 to 1 with AoI incentives, while plausible, depend on specific parameter choices and the polynomial model fit that are not fully detailed.
- **Low confidence**: The claim that all nodes behave symmetrically with identical cost structures is highly idealized for real IoT deployments where devices have heterogeneous capabilities and energy budgets.

## Next Checks
1. **Parameter sensitivity analysis**: Systematically vary the polynomial coefficients in the d(p) model by ±10% and recompute Nash equilibria and PoA. Determine if the qualitative findings (PoA improvement with AoI incentives) hold across reasonable model perturbations.

2. **Heterogeneous node validation**: Extend the game-theoretic model to handle nodes with different cost parameters ci and incentive weights γi. Solve for asymmetric Nash equilibria and compare PoA to the symmetric case to quantify robustness to node heterogeneity.

3. **Dynamic participation simulation**: Implement a more realistic scenario where nodes join and leave based on AoI thresholds rather than fixed probabilities. Measure whether the incentive mechanism still achieves PoA≈1 under these dynamic conditions and whether convergence stability is maintained.