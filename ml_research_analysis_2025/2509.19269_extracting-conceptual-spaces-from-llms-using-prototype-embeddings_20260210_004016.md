---
ver: rpa2
title: Extracting Conceptual Spaces from LLMs Using Prototype Embeddings
arxiv_id: '2509.19269'
source_url: https://arxiv.org/abs/2509.19269
tags:
- dataset
- embeddings
- protosim
- predicted
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to extract conceptual spaces from
  large language models (LLMs) by using prototype embeddings. The key idea is to model
  perceptual features using embeddings of prototype descriptions (e.g., "a very sweet
  food") and fine-tune the LLM to align these prototype embeddings with entity embeddings.
---

# Extracting Conceptual Spaces from LLMs Using Prototype Embeddings

## Quick Facts
- arXiv ID: 2509.19269
- Source URL: https://arxiv.org/abs/2509.19269
- Reference count: 40
- Primary result: ProtoSim achieves state-of-the-art results in ranking entities along conceptual space dimensions using prototype embeddings

## Executive Summary
This paper introduces ProtoSim, a method to extract conceptual spaces from large language models by modeling perceptual features through prototype embeddings. The approach verbalizes features as prototype descriptions (e.g., "a very sweet food"), extracts their embeddings, and fine-tunes the LLM to align these prototype embeddings with entity embeddings. Experiments on multiple datasets demonstrate that ProtoSim outperforms both pre-trained and fine-tuned LLM-based embedding models, achieving superior accuracy in ranking entities along conceptual dimensions and predicting degrees of features with strong correlation to human ratings.

## Method Summary
The method verbalizes perceptual features as prototype descriptions and extracts their embeddings from an LLM. A classification loss aligns prototype embeddings with entity centroids using a synthetic dataset of 123 properties, while a ranking loss improves ordinal discrimination between entity pairs. The model uses EOL-style prompts with category prefixes for entities and last-token normalization. Training combines classification and ranking objectives, with fine-tuning showing substantial improvements over pre-trained models.

## Key Results
- ProtoSim achieves 72.6% average accuracy on Taste dataset, outperforming pre-trained models (53.5%)
- Strong correlation (0.752) between predicted sweetness degrees and human ratings
- Llama3-8B outperforms larger models (Mistral-24B, Qwen3-14B) for ProtoSim
- Classification loss is the primary driver; ranking loss provides marginal, often non-significant improvements

## Why This Works (Mechanism)

### Mechanism 1
Prototype embeddings encode perceptual features as directions in embedding space. The LLM verbalizes features as prototype descriptions (e.g., "a very sweet food"), whose embeddings serve as feature vectors. Entity rankings are computed via dot products with these prototype embeddings. Core assumption: the LLM has pre-trained perceptual knowledge that can be elicited through appropriate prompting. Break condition: if prototype and entity embeddings occupy disjoint subspaces, dot products become uninformative.

### Mechanism 2
Fine-tuning aligns prototype and entity embedding subspaces via a classification loss. Using a synthetic dataset (123 properties from GPT-4o), the loss maximizes similarity between prototype embeddings and entity centroids while minimizing similarity to negative properties. This pulls prototype embeddings into the entity subspace. Core assumption: alignment generalizes from 123 synthetic properties to unseen features. Break condition: overfitting occurs if dataset exceeds 150 examples.

### Mechanism 3
A secondary ranking loss improves feature-specific discriminability. Given entity pairs with known ordering, the ranking loss scales the difference by α and applies sigmoid, encouraging correct ordinal relationships. Core assumption: perceptual feature rankings transfer across domains. Break condition: if classification alignment is sufficient, ranking loss adds noise without benefit.

## Foundational Learning

- Concept: **Conceptual Spaces (Gärdenfors, 2000)**
  - Why needed here: The paper's goal is to extract geometric representations where dimensions correspond to perceptual features, not distributional semantics.
  - Quick check question: Can you explain why emb("banana") · emb("a very sweet food") should reflect sweetness, not just textual association?

- Concept: **Embedding Alignment / Subspace Mismatch**
  - Why needed here: Pre-trained LLMs embed prototype descriptions and entities in different subspaces, requiring explicit alignment.
  - Quick check question: Why might "a very sweet food" and "banana" have dissimilar embeddings in a pre-trained model despite semantic relatedness?

- Concept: **Contrastive Learning Objectives (Classification + Ranking)**
  - Why needed here: The method combines classification loss (centroid alignment) and ranking loss (ordinal relationships).
  - Quick check question: How does the temperature T in the classification loss affect gradient sharpness?

## Architecture Onboarding

- Component map: Entity encoder -> Prototype encoder -> Classification head -> Ranking head
- Critical path: 1) Verbalize entity as "[Category] [Item]", 2) Extract emb(entity), 3) Verbalize feature as prototype description, 4) Extract emb(prototype), 5) Compute classification + ranking losses, 6) Rank entities by similarity scores
- Design tradeoffs: Classification-only vs. Classification + Ranking (ranking adds marginal gains); Model size (Llama3-8B outperforms larger models); Pre-trained embedding models underperform fine-tuned LLMs
- Failure signatures: Negative requirements fail ("without cranberry sauce"); Lexical overlap distracts ("brown rice" in query); Single-aspect focus ignores other aspects; Intermediate values compressed in predictions
- First 3 experiments: 1) Reproduce Table 1 Taste dataset (53.5% → 72.4%), 2) Ablate classification dataset size (100-150 examples optimal), 3) Evaluate generalization (train on Taste+Rocks+Odour, test on Music: 63.8%)

## Open Questions the Paper Calls Out
None

## Limitations

- Generalizability across features and domains is limited, with abstract features showing significant performance degradation
- Reliance on 123 synthetically generated training examples with no human verification of quality
- Numerical prediction accuracy shows systematic under-prediction of intermediate values

## Confidence

- Claim 1: ProtoSim outperforms baseline embedding models (High confidence)
- Claim 2: Fine-tuning alignment is necessary and effective (High confidence)
- Claim 3: Ranking loss provides marginal additional benefit (Medium confidence)

## Next Checks

1. **Feature Type Ablation Study**: Systematically evaluate ProtoSim across perceptual, abstract, and mixed feature types to quantify performance degradation patterns.

2. **Dataset Size Sensitivity Analysis**: Conduct experiments varying training examples (25-250) to map overfitting threshold and determine minimum viable dataset size.

3. **Cross-Domain Transfer Robustness**: Train on all perceptual datasets and evaluate on Music/Tag Genome with systematic variation of training domain coverage to quantify domain-specificity.