---
ver: rpa2
title: 'JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus'
arxiv_id: '2508.16303'
source_url: https://arxiv.org/abs/2508.16303
tags:
- patent
- sentence
- pairs
- translation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We constructed JaParaPat, a Japanese-English parallel corpus of
  over 300 million sentence pairs from patent applications published in Japan and
  the U.S. from 2000 to 2021.
---

# JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus

## Quick Facts
- arXiv ID: 2508.16303
- Source URL: https://arxiv.org/abs/2508.16303
- Reference count: 0
- Primary result: 300M+ sentence pairs from patent families, 20 BLEU improvement over web-crawled data

## Executive Summary
JaParaPat is a Japanese-English parallel corpus of over 300 million sentence pairs extracted from patent applications published in Japan and the U.S. from 2000 to 2021. The corpus was constructed by mining patent family information from EPO's DOCDB to align 1.4 million document pairs, then extracting sentence pairs using a two-pass translation-based alignment method. Experimental results demonstrate that JaParaPat significantly improves patent translation accuracy by 20 BLEU points compared to web-crawled corpora, with translation-based alignment yielding higher quality than dictionary-based methods.

## Method Summary
The corpus construction involved three main steps: document alignment using EPO DOCDB patent family information to link Japanese and US patent documents across Paris and PCT filing routes, text extraction from patent XML files focusing on title, abstract, description, and claims while excluding mathematical expressions and figures, and sentence alignment using a two-pass approach that first bootstraps from dictionary-based alignment then refines with translation-based alignment using Bleualign. The final corpus contains approximately 337 million Japanese-English sentence pairs, with metadata including IPC codes and alignment scores.

## Key Results
- Translation-based alignment yielded higher quality than dictionary-based methods (63.4/53.0 vs 62.6/51.5)
- JaParaPat improved patent translation accuracy by 20 BLEU points compared to web-crawled corpus
- Adding 22M web-crawled sentence pairs to JaParaPat improved translation accuracy on out-of-domain test sets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translation-based sentence alignment yields higher-quality parallel sentence pairs than dictionary-based alignment for patent documents.
- Mechanism: A neural machine translation model is first bootstrapped from an initial dictionary-based alignment. This model is then used to score and align sentence pairs, capturing context and phrase-level semantics that rigid dictionary lookups miss.
- Core assumption: The bootstrapped translation model achieves sufficient accuracy to identify correct alignments before being applied to the full corpus.
- Evidence anchors:
  - [abstract] "...translation-based alignment yielded higher quality than dictionary-based methods."
  - [section] "When we use translation-based sentence alignment, we collected more sentence pairs (34M to 43M) with higher quality (62.6/51.5 to 63.4/53.0) than dictionary-based sentence alignment" (Section 5.3, Table 5).
  - [corpus] Weak direct corpus support for the mechanism beyond reported BLEU scores; related work mentions computational expense trade-offs for alternative embedding-based methods.
- Break condition: If the initial dictionary-based corpus is too noisy to train a coherent bootstrapping model, the translation-based alignment may propagate and amplify errors.

### Mechanism 2
- Claim: Adding a large-scale, domain-specific parallel corpus (JaParaPat) to general web-crawled data significantly improves translation accuracy on patent texts.
- Mechanism: The in-domain patent corpus fine-tunes the model on technical terminology and legal phraseology, while the web-crawled data provides general fluency and diversity, improving robustness.
- Core assumption: The test sets are representative of the target domain and are not contaminated by overlap with the training data, which would artificially inflate scores.
- Evidence anchors:
  - [abstract] "Experimental results show that JaParaPat improved patent translation accuracy by 20 BLEU points compared to a web-crawled corpus..."
  - [section] "...when we added 22M web-crawled sentence pairs of JParaCrawl to 337M patent sentence pairs of JaParaPat, the translation accuracy of test2 and ASPEC increased, suggesting that the patent sentence pairs lack diversity." (Section 5.4)
  - [corpus] No direct corpus signal on the mechanism; evidence is based on experimental results within the paper.
- Break condition: If the web-crawled data contains significant contradictory or low-quality examples, it may negate the benefits of in-domain fine-tuning.

### Mechanism 3
- Claim: Exhaustive mining of patent applications via both Paris and PCT routes creates a larger and more diverse parallel corpus than single-route approaches.
- Mechanism: Using EPO's DOCDB, document pairs are identified across different filing routes (jp-us, jp-x-us, us-jp, pct), maximizing the number of parallel documents available for alignment.
- Core assumption: The patent family information in DOCDB reliably indicates that documents are direct translations of each other.
- Evidence anchors:
  - [abstract] "We extracted approximately 1.4M Japanese-English document pairs... based on the patent families..."
  - [section] "The ratio of Paris routes to PCT routes in the parallel corpus is almost one-to-one..." (Section 4.1)
  - [corpus] Neighbor papers suggest value in multi-source patent data but do not directly confirm this specific mining mechanism's superiority.
- Break condition: If patent family links in DOCDB are outdated or incomplete, potentially available parallel documents will be missed.

## Foundational Learning

- Concept: **Patent Family**
  - Why needed here: This is the core entity for document alignment. Understanding that a family groups patents for the same invention filed in different countries is essential to grasp the corpus's origin.
  - Quick check question: How does a "Paris route" patent family differ from a "PCT route" family in terms of how the priority date is established?

- Concept: **Sentence Alignment in Parallel Corpora**
  - Why needed here: The paper argues its key improvement comes from a specific sentence alignment method. Grasping the difference between dictionary-based and translation-based alignment is critical.
  - Quick check question: What is the "bootstrapping" step in the translation-based alignment method described, and why is it necessary?

- Concept: **Transformer Model Scaling and Data Diversity**
  - Why needed here: The results tie model performance to data volume and diversity (patent vs. web), connecting to broader NMT concepts.
  - Quick check question: Why does adding web-crawled data to the patent data sometimes improve scores on out-of-domain test sets like ASPEC, as noted in the paper?

## Architecture Onboarding

- Component map:
  - Input Sources: JPO Patent Data (XML) -> USPTO Patent Data (XML) -> EPO DOCDB (XML)
  - Data Processing Pipeline:
    1. Document Alignment Module: Parses XMLs, queries DOCDB for families, links JP-US document pairs
    2. Text Extraction Module: Extracts text from `<p>` tags for title, abstract, description, claims
    3. Sentence Segmentation Module: Uses `split-sentences.perl` (Moses)
    4. Sentence Alignment Module (Two-Pass): Dictionary-based alignment -> Train NMT on output + JParaCrawl -> Refine with Bleualign
  - Output: Parallel corpus files (`.txt`, `.align`) and metadata (IPC codes)

- Critical path: The **two-pass sentence alignment** is the critical path. The final corpus quality hinges on the success of the bootstrapped translation model in the second pass.

- Design tradeoffs:
  - Translation-based vs. Embedding-based Alignment: The paper chooses translation-based (Bleualign) for a balance of speed and accuracy over more computationally expensive embedding-based methods (e.g., Vecalign).
  - Patent vs. Web Data Mix: The tradeoff is between high-accuracy in-domain data (patent) and diverse general-domain data (web), with experiments showing a combination is often best for robustness.
  - Paris vs. PCT Routes: The Paris route offers more document pairs, while the PCT route offers more sentence pairs due to a higher likelihood of direct translation.

- Failure signatures:
  - Low BLEU scores: Indicates poor alignment or insufficient bootstrapping data.
  - Many-to-many alignment files: Overly complex alignments in the `.align` files may signal noise.
  - Perplexity divergence: High perplexity on a held-out set during translation model training suggests data quality issues or hyperparameter problems.

- First 3 experiments:
  1. Replicate the alignment improvement: Train a baseline dictionary-based model and a bootstrapped translation-based model on a small data subset. Compare the number of extracted sentence pairs and their alignment quality.
  2. Data composition ablation: Train translation models on three data configurations: (a) Web-only (JParaCrawl), (b) Patent-only (JaParaPat subset), and (c) Web+Patent. Compare BLEU scores on the provided test sets.
  3. Route-specific analysis: Train separate models on data from the Paris route and the PCT route. Evaluate each on test sets from both routes to quantify domain differences.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does translation accuracy scale with increased model parameters when trained on the full JaParaPat dataset compared to the standard Transformer Big architecture?
- Basis in paper: [explicit] The Conclusion states future work includes "increasing the number of parameters in the translation model... with reference to the study of data scaling laws."
- Why unresolved: The experiments were limited to the Transformer Big model; the authors did not test if larger models would utilize the 300M+ sentence pairs more effectively to boost BLEU scores further.
- What evidence would resolve it: Training and evaluating models with significantly larger parameter counts (e.g., LLMs) on the JaParaPat corpus to plot scaling curves.

### Open Question 2
- Question: Can a targeted noise filtering mechanism improve the quality of the parallel corpus beyond the current translation-based alignment?
- Basis in paper: [explicit] The Conclusion lists "designing a filter to remove noise in the parallel corpus to improve translation accuracy" as a specific direction for future work.
- Why unresolved: While the authors note that translation-based alignment is superior to dictionary-based methods, they did not implement specific filters to remove misaligned or low-quality sentence pairs that may still exist.
- What evidence would resolve it: A comparative study measuring BLEU/COMET scores of models trained on the raw corpus versus a filtered version using techniques like language identification or embedding similarity thresholds.

### Open Question 3
- Question: To what extent does "post-editing bias" influence the automatic evaluation of patent translation models trained on this corpus?
- Basis in paper: [inferred] Section 5.3 observes significant score variance between test sets from different translation companies and speculates that "post-editing bias may be a problem in the future" as more companies use machine translation post-editing.
- Why unresolved: The paper identifies the potential issue where training data may contain artifacts of machine translation, but it does not quantify or correct for this bias in the evaluation of JaParaPat.
- What evidence would resolve it: An analysis of translation outputs for "translationese" artifacts and human evaluations to determine if high BLEU scores correlate with actual human preference or merely reflect post-editing styles.

## Limitations

- The paper's alignment quality claims rely on bootstrapping from dictionary-based methods, but details on handling out-of-vocabulary terms during this phase are not specified.
- The reported 20 BLEU point improvement compared to web-crawled data is substantial and may be partially attributable to test set overlap or domain specificity rather than alignment quality alone.
- While translation-based alignment is superior to dictionary-based methods, the paper did not implement specific filters to remove misaligned or low-quality sentence pairs that may still exist.

## Confidence

- **High Confidence:** Document alignment methodology using EPO DOCDB patent families is well-specified and reproducible.
- **Medium Confidence:** Sentence alignment improvement claims are supported by reported metrics but lack transparency on dictionary limitations and bootstrapping robustness.
- **Medium Confidence:** Translation quality improvements are demonstrated on provided test sets, but generalizability to other domains remains uncertain.

## Next Checks

1. **Replication of Alignment Quality:** Train both dictionary-based and bootstrapped translation-based models on a small data subset. Compare extracted sentence pair counts and alignment quality metrics (precision/recall) to verify the reported improvement from 62.6/51.5 to 63.4/53.0.

2. **Data Composition Ablation Study:** Train three separate models using (a) Web-only data (JParaCrawl), (b) Patent-only data (JaParaPat subset), and (c) Combined data. Evaluate all three on both in-domain and out-of-domain test sets to isolate the contribution of domain-specific vs. general data.

3. **Route-Specific Domain Analysis:** Train separate models on Paris route data and PCT route data. Evaluate each model on both route test sets to quantify and characterize domain differences between the two patent filing pathways.