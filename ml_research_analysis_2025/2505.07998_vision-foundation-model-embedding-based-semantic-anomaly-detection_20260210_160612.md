---
ver: rpa2
title: Vision Foundation Model Embedding-Based Semantic Anomaly Detection
arxiv_id: '2505.07998'
source_url: https://arxiv.org/abs/2505.07998
tags:
- anomaly
- detection
- semantic
- nominal
- anomalies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes two vision embedding-based approaches for semantic
  anomaly detection and localization in autonomous systems. The methods leverage DINOv2
  embeddings, either at the patch level or aggregated by object instances via OWLv2
  and SAM2, to compare runtime observations against a database of nominal scenarios.
---

# Vision Foundation Model Embedding-Based Semantic Anomaly Detection

## Quick Facts
- arXiv ID: 2505.07998
- Source URL: https://arxiv.org/abs/2505.07998
- Reference count: 36
- One-line primary result: DINOv2-based embedding methods achieve F1=0.51 overall for semantic anomaly detection in CARLA-simulated autonomous driving scenarios.

## Executive Summary
This work proposes two vision embedding-based approaches for semantic anomaly detection and localization in autonomous driving. The methods leverage DINOv2 embeddings, either at the patch level or aggregated by object instances via OWLv2 and SAM2, to compare runtime observations against a database of nominal scenarios. A simple spatial filtering step suppresses false positives from isolated high-scoring patches. Evaluated on CARLA-simulated data, the instance-based method with filtering achieves F1-scores comparable to GPT-4o while providing precise spatial localization.

## Method Summary
The approach extracts DINOv2 patch embeddings from input images and computes anomaly scores via maximum cosine similarity to a cached database of nominal embeddings. For instance-level detection, OWLv2 proposes bounding boxes which SAM2 segments, and DINOv2 embeddings within each mask are averaged. Anomaly scores are computed as the negated maximum similarity to nominal patches, thresholded at an α-quantile from leave-one-out validation, and filtered to remove small connected components. The method operates entirely on precomputed embeddings, enabling efficient real-time inference.

## Key Results
- Instance-based method with filtering achieves F1=0.51 overall (0.62 for traffic lights, 0.23 for stop signs, 0.45 for OOD objects)
- Patch-level method FPR=0.36 vs instance-level FPR=0.17 with filtering
- Method provides precise spatial localization via connected component analysis
- Outperforms GPT-4o baseline on traffic light and OOD object detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DINOv2 patch embeddings encode semantic regularities that separate nominal scene configurations from contextually invalid object combinations.
- Mechanism: Self-supervised vision transformers trained at internet scale learn emergent object-centric features without explicit labels. When queried at patch level (256 patches × 384 dims per image), embeddings cluster semantically similar regions. Anomaly scoring computes max cosine similarity between each runtime patch and all cached nominal patches, negated to produce dissimilarity. Patches with no close nominal match receive high scores.
- Core assumption: Semantic anomalies manifest as embedding-space outliers relative to nominal experience; visual novelty correlates with contextual invalidity.
- Evidence anchors:
  - [abstract] "leverage the semantic priors of state-of-the-art vision foundation models"
  - [section III-B.1] "DINOv2 produces 256 patch embeddings per image... each representing a 14 × 14 pixel region"
  - [corpus] THEMIS (arXiv:2510.03911) demonstrates foundation model embeddings transfer pretrained knowledge to anomaly detection tasks, though in time series domain
- Break condition: If anomalies comprise familiar objects in familiar configurations (e.g., novel truck model carrying standard traffic light), patch-level embeddings may not capture contextual violation.

### Mechanism 2
- Claim: Instance-level aggregation via OWLv2 + SAM2 improves detection of semantic anomalies by enforcing object-centric comparison units.
- Mechanism: OWLv2 generates open-vocabulary bounding box proposals; SAM2 produces instance masks from these prompts. DINOv2 patch embeddings within each mask are averaged to form a single instance embedding. This reduces spurious high scores from isolated patches and forces comparison at semantically meaningful granularity.
- Core assumption: Semantic anomalies involve complete objects in invalid contexts; averaging embeddings within instances preserves diagnostic signal while suppressing patch-level noise.
- Evidence anchors:
  - [abstract] "aggregated by object instances via OWLv2 and SAM2, to compare runtime observations against a database of nominal scenarios"
  - [section IV-A] "detecting full anomalies (e.g., traffic light and truck) that are often missed or partially detected by the patch-embedding-based method"
  - [corpus] SAVANT (arXiv:2510.18034) addresses semantic anomalies in driving but uses different VLM approach; no direct corpus evidence for instance aggregation specifically
- Break condition: Oversegmentation from detector false positives fragments objects, creating anomalous-appearing segments (noted in appendix V-E).

### Mechanism 3
- Claim: Post-hoc spatial filtering suppresses false positives from isolated high-scoring patches without altering anomaly scoring logic.
- Mechanism: Connected component analysis on binary anomaly map removes regions below pixel threshold. This targets noise from small nominal elements underrepresented in database (e.g., vegetation patches, distant signs) rather than genuine anomalies which typically span multiple patches or complete instances.
- Core assumption: True semantic anomalies produce spatially coherent detections; isolated pixels reflect database coverage gaps or embedding noise.
- Evidence anchors:
  - [abstract] "A simple filtering step suppresses false positives from isolated high-scoring patches"
  - [section III-B.3] "removes small connected components from the binary anomaly map based on a pixel threshold"
  - [corpus] No direct corpus evidence for this specific filtering technique
- Break condition: If anomalies are genuinely small (distant object, partial occlusion), filtering may eliminate true positives.

## Foundational Learning

- Concept: **Vision Transformer (ViT) patch embeddings**
  - Why needed here: The method operates on DINOv2's 256 patch-level embeddings per image; understanding spatial correspondence between patches and image regions is essential for interpreting anomaly heatmaps.
  - Quick check question: Given a 224×224 input image and 14×14 pixel patches, how many patches are produced and what spatial resolution does each represent?

- Concept: **Open-vocabulary object detection (OWLv2)**
  - Why needed here: The instance-based variant depends on OWLv2's ability to propose bounding boxes for arbitrary objects without class constraints; detector failures directly cause downstream segmentation errors.
  - Quick check question: How does an open-vocabulary detector differ from a fixed-class detector like YOLO, and what failure modes might emerge on synthetic data?

- Concept: **k-nearest-neighbor anomaly scoring**
  - Why needed here: Anomaly detection uses maximum cosine similarity to nominal cache rather than learned classifiers; threshold selection and database composition directly control detection behavior.
  - Quick check question: If the nominal database contains 10,000 patch embeddings and runtime produces 256 patches per image, how many similarity comparisons occur per frame?

## Architecture Onboarding

- Component map:
  - Offline: DINOv2 encoder → nominal image database → patch embedding cache (N × 256 × 384 tensors)
  - Runtime: Input image → DINOv2 encoder → patch embeddings (256 × 384) → [branch A: direct patch comparison] OR [branch B: OWLv2 boxes → SAM2 masks → instance aggregation] → k-NN similarity scoring → threshold → binary anomaly map → connected component filtering → output (detection + localization)

- Critical path: Embedding extraction (DINOv2 forward pass) dominates latency; k-NN search scales with database size but is parallelizable across patches.

- Design tradeoffs:
  - Patch-level: Faster (no detector/segmentation), better for OOD objects, higher FPR (0.36 vs 0.17)
  - Instance-level: Better semantic anomaly F1 (0.51 vs 0.36 overall), sharper localization, dependent on detector quality
  - Filtering: Reduces FPR but risks missing small anomalies; threshold requires empirical tuning per scenario

- Failure signatures:
  - High FPR on underrepresented nominal elements (vegetation, buildings) → database coverage gap
  - Oversegmented false positives → OWLv2 hallucinating boxes on synthetic imagery
  - Missed stop-sign-on-billboard anomalies → embeddings may not distinguish context (F1=0.23)
  - Score distribution overlap between nominal and anomaly → threshold misalignment across scenarios (Fig. 5)

- First 3 experiments:
  1. **Database ablation**: Vary nominal set size (100, 500, 1000, 5000 images) and measure F1/FPR trajectory to identify minimum viable coverage.
  2. **Filtering threshold sweep**: Plot IoU, F1, TPR, FPR against pixel threshold (10, 50, 100, 200 pixels) per scenario to find scenario-robust setting.
  3. **Latency profiling**: Measure end-to-end inference time for patch-only vs. instance pipeline on target hardware; identify if detector/segmentation overhead violates real-time constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating scene structure into a graph-based representation preserve sufficient global context to detect anomalies defined by atypical object combinations?
- Basis in paper: [explicit] The conclusion states that analyzing embeddings in isolation might lose global context and suggests "incorporating embeddings and scene structure into a graph-based representation" as future work.
- Why unresolved: The current implementation aggregates embeddings by patch or instance but does not explicitly model the spatial or semantic relationships between objects, which is necessary to identify contextually invalid arrangements.
- What evidence would resolve it: A comparative evaluation showing that a graph-based variant significantly improves F1-scores on the "Stop Sign on Billboard" scenario compared to the instance-based method.

### Open Question 2
- Question: To what extent can energy-based models or other adaptive scoring mechanisms align the score distributions of diverse anomaly types to stabilize threshold selection?
- Basis in paper: [explicit] The paper notes that different anomaly types yield different score ranges, complicating the selection of a single threshold. The authors propose adopting "more adaptive scoring mechanisms, such as energy-based models" in future work.
- Why unresolved: The current fixed-threshold approach forces a trade-off between TPR and FPR that varies significantly across scenarios (e.g., Stop Signs vs. OOD objects).
- What evidence would resolve it: Demonstration of a scoring method that minimizes the variance in separation between nominal and anomalous scores across all evaluated scenarios (Traffic Lights, Stop Signs, OOD).

### Open Question 3
- Question: How robust is the instance-based detection pipeline when the object detector (OWLv2) is replaced by models fine-tuned on driving data to reduce over-segmentation?
- Basis in paper: [inferred] The appendix notes that OWLv2 produces false positives and overlapping detections on CARLA images, leading to oversegmentation by SAM2, which the authors identify as a performance bottleneck.
- Why unresolved: The current evaluation relies on a general-purpose detector (OWLv2) that struggles with the specific domain, potentially lowering the upper bound of the anomaly detector's performance.
- What evidence would resolve it: An ablation study comparing the anomaly detection F1-scores using the current OWLv2 backbone versus a driving-specific or fine-tuned object detector.

### Open Question 4
- Question: Does the domain shift between synthetic training data (CARLA) and real-world environments significantly degrade the semantic expressiveness of the DINOv2 embeddings used in this framework?
- Basis in paper: [inferred] The authors identify domain shift as a likely cause for GPT-4o's failure to detect certain anomalies, but the embedding-based method is only evaluated on simulated data, leaving its real-world transferability unproven.
- Why unresolved: Foundation models may encode different priors for synthetic textures versus real-world visuals, potentially altering the distance metrics used for anomaly scoring.
- What evidence would resolve it: Evaluation of the framework on real-world driving datasets (e.g., Cityscapes or Waymo Open Dataset) with injected semantic anomalies to verify if the embedding distance distributions hold.

## Limitations
- Relies on synthetic CARLA data which may not capture real-world visual complexity and anomaly diversity
- Hyperparameters (anomaly thresholds, filtering thresholds) are not specified and require empirical tuning
- Instance-level detection depends heavily on OWLv2 and SAM2 performance, which may degrade on synthetic imagery
- Database coverage gaps for underrepresented nominal elements can cause false positives
- Method's generalization to real-world scenarios with different lighting, weather, and object appearances remains untested

## Confidence
- Medium for core claim: Demonstrated only on synthetic data
- High for technical feasibility: Direct DINOv2 usage
- Medium for instance-level benefits: Detector quality directly impacts performance
- Medium for filtering effectiveness: Specific thresholds not provided

## Next Checks
1. **Real-world transfer**: Evaluate instance-based method on real autonomous driving datasets (nuScenes, Waymo) to assess performance degradation and false positive patterns
2. **Database coverage analysis**: Systematically ablate nominal database size and composition to identify minimum viable coverage and measure impact on F1/FPR trade-offs
3. **Threshold sensitivity study**: Perform comprehensive sweeps of anomaly threshold α-quantile and spatial filtering pixel thresholds across all scenarios to identify robust hyperparameter settings