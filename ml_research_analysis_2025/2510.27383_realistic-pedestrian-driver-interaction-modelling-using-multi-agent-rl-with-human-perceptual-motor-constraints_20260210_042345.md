---
ver: rpa2
title: Realistic pedestrian-driver interaction modelling using multi-agent RL with
  human perceptual-motor constraints
arxiv_id: '2510.27383'
source_url: https://arxiv.org/abs/2510.27383
tags:
- pedestrian
- vehicle
- constraints
- interaction
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study presents a multi-agent reinforcement learning framework\
  \ that integrates human-like perceptual and motor constraints to model pedestrian-vehicle\
  \ interactions at unsignalised crossings. Four model variants\u2014No Constraint\
  \ (NC), Motor Constraint (MC), Visual Constraint (VC), and Visual and Motor Constraint\
  \ (VMC)\u2014were evaluated on a real-world dataset using behavioural, kinematic,\
  \ and trajectory-based metrics."
---

# Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints

## Quick Facts
- **arXiv ID**: 2510.27383
- **Source URL**: https://arxiv.org/abs/2510.27383
- **Reference count**: 23
- **Primary result**: VMC model with visual and motor constraints achieves highest similarity to human pedestrian-driver interactions at unsignalised crossings

## Executive Summary
This study presents a multi-agent reinforcement learning framework that integrates human-like perceptual and motor constraints to model pedestrian-vehicle interactions at unsignalised crossings. Four model variants—No Constraint (NC), Motor Constraint (MC), Visual Constraint (VC), and Visual and Motor Constraint (VMC)—were evaluated on a real-world dataset using behavioural, kinematic, and trajectory-based metrics. The VMC model, which includes both visual and motor constraints, achieved the highest similarity to human data, outperforming other RL variants and a behavioural cloning model. Motor constraints produced smoother movements reflecting human speed adjustments, while visual constraints introduced perceptual uncertainty, leading to more cautious and variable behaviour. This work demonstrates that multi-agent RL with human constraints is a promising approach for simulating realistic road user interactions, particularly in data-limited settings.

## Method Summary
The framework uses multi-agent reinforcement learning to model pedestrian-driver interactions at unsignalised crossings. Four model variants were implemented: No Constraint (NC) with no human limitations, Motor Constraint (MC) incorporating human speed/acceleration limits, Visual Constraint (VC) adding perceptual uncertainty through random noise, and Visual and Motor Constraint (VMC) combining both constraints. Models were trained using real-world trajectory data and evaluated against human behavioural patterns using similarity metrics. A behavioural cloning baseline was included for comparison. The framework captures both agents' decision-making processes while respecting human perceptual and motor limitations.

## Key Results
- VMC model achieved highest similarity to human data across all evaluation metrics
- Motor constraints produced smoother, more human-like movement patterns
- Visual constraints introduced perceptual uncertainty, resulting in more cautious and variable behaviour
- VMC outperformed both other RL variants and behavioural cloning baseline

## Why This Works (Mechanism)
The framework works by explicitly incorporating human limitations into the decision-making process of both agents. Motor constraints prevent unrealistic acceleration and speed profiles, while visual constraints simulate human perceptual uncertainty through noise injection. This combination creates behaviour that more closely matches human patterns observed in real-world data, particularly in terms of cautious decision-making and smooth movement trajectories.

## Foundational Learning
- **Multi-agent reinforcement learning**: Enables simultaneous modelling of pedestrian and driver decision-making processes. Needed to capture the interactive nature of road user behaviour. Quick check: Verify that both agents' policies are learned concurrently rather than sequentially.
- **Human perceptual constraints**: Simulates realistic visual processing limitations through noise injection. Needed to model uncertainty in human perception of distance, speed, and timing. Quick check: Confirm noise parameters align with empirical human visual perception studies.
- **Human motor constraints**: Limits agent movement to biologically plausible speeds and accelerations. Needed to prevent unrealistic motion patterns that would diverge from human behaviour. Quick check: Validate constraint parameters against biomechanical human movement data.

## Architecture Onboarding
- **Component map**: Real-world data -> Preprocessing -> Multi-agent RL training -> Model variants (NC, MC, VC, VMC) -> Evaluation metrics -> Behavioural comparison
- **Critical path**: Data preprocessing → RL training → Constraint application → Behavioural evaluation → Similarity assessment
- **Design tradeoffs**: Simplicity vs. realism (fewer constraints = simpler but less human-like), computational cost vs. accuracy (more constraints = higher cost but better behavioural match)
- **Failure signatures**: Overly aggressive behaviour (insufficient constraints), unrealistic smooth trajectories (excessive motor constraints), unpredictable decisions (inappropriate visual noise levels)
- **Three first experiments**: 1) Test framework on signalised crossing data, 2) Compare visual noise parameters against controlled human perception experiments, 3) Validate motor constraints using biomechanical walking studies

## Open Questions the Paper Calls Out
None

## Limitations
- Single dataset from one unsignalised crossing limits generalizability to other intersection types
- Behavioural cloning baseline performs poorly, suggesting evaluation may not fully capture realistic interactions
- Visual constraint noise parameters lack empirical validation from human perception studies
- Motor constraints may reflect regularization rather than true human biomechanics

## Confidence
- Model performance claims (High): Quantitative metrics clearly demonstrate VMC's superiority over other variants
- Human-like behaviour claims (Medium): Trajectories match human data, but underlying behavioural realism remains partially unverified
- Generalizability claims (Low): Limited to one dataset and crossing type, making broader claims speculative

## Next Checks
1. Test framework on multiple intersection types (signalised crossings, roundabouts) to assess generalizability
2. Compare perceptual noise parameters against empirical human visual perception data from controlled experiments
3. Validate motor constraint parameters using biomechanical studies of human walking speed and acceleration patterns