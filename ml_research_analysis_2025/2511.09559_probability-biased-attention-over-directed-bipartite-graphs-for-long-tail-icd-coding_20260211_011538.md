---
ver: rpa2
title: Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD
  Coding
arxiv_id: '2511.09559'
source_url: https://arxiv.org/abs/2511.09559
tags:
- codes
- code
- graph
- attention
- co-occurrence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the long-tail problem in automated ICD coding,
  where rare disease codes lack sufficient training data. The authors propose a method
  that models fine-grained co-occurrence relationships among codes using a Directed
  Bipartite Graph Encoder.
---

# Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding

## Quick Facts
- arXiv ID: 2511.09559
- Source URL: https://arxiv.org/abs/2511.09559
- Reference count: 36
- Primary result: SOTA Macro-F1 on long-tail ICD coding via probability-biased attention over directed bipartite graphs

## Executive Summary
This paper addresses the long-tail problem in automated ICD coding by proposing a Directed Bipartite Graph Encoder that models fine-grained co-occurrence relationships among codes. The method uses directed edges from common to rare codes weighted by discretized conditional co-occurrence probabilities, injecting these as learnable attention biases. The authors also leverage a large language model to generate comprehensive code descriptions, enriching embeddings with clinical context. Experiments on three benchmark datasets demonstrate state-of-the-art performance, particularly in Macro-F1, a key metric for long-tail classification.

## Method Summary
The approach consists of three main components: (1) LLM-generated comprehensive descriptions for each ICD code, encoded with GatorTron to create enriched initial embeddings; (2) a Directed Bipartite Graph Encoder where edges flow from common to rare codes and are weighted by discretized conditional co-occurrence probabilities; and (3) a multi-label attention mechanism that aggregates document and code representations for final prediction. The probability-biased attention replaces Graphormer's spatial encoding with domain-specific co-occurrence strength, enabling rare codes to benefit from statistically related common neighbors while preventing noise from propagating in the reverse direction.

## Key Results
- State-of-the-art Macro-F1 performance on MIMIC-III-ICD-9, MIMIC-IV-ICD-9, and MIMIC-IV-ICD-10
- Notable improvements specifically for rare code prediction, addressing the long-tail distribution
- Effective integration of LLM-generated descriptions improves initial code embeddings with clinical context
- Probability discretization into learnable bins successfully captures comorbidity patterns

## Why This Works (Mechanism)

### Mechanism 1: Probability-Biased Attention via Discretized Co-occurrence
The model discretizes conditional co-occurrence probabilities (P(common|rare)) into learnable bins, creating a probability-biased attention term that enriches rare code representations. This mechanism assumes co-occurrence statistics capture clinically meaningful comorbidity patterns that generalize from common to rare codes. The discretization replaces Graphormer's shortest-path-distance bias with domain-specific relational strength, though it may collapse to uninformative biases if statistics are too sparse.

### Mechanism 2: Directed Bipartite Information Flow
By constraining information flow exclusively from common to rare codes, the architecture prevents rare-code noise from polluting common-code representations while enabling comorbidity aggregation. This assumes rare codes benefit from common-code signals but reverse flow is harmful or unnecessary. The directional restriction may limit the model if rare codes have strong predictive signals for other rare codes that are currently blocked.

### Mechanism 3: LLM-Enriched Code Descriptions as External Knowledge
GPT-4o-generated comprehensive descriptions provide clinical context and comorbidity cues that improve initial code embeddings beyond simple synonym lists. The model assumes LLM-generated text captures clinically relevant semantics not present in code names or ontology synonyms. However, if the LLM hallucinates incorrect comorbidities or descriptions diverge from actual clinical usage, embeddings may mislead the model.

## Foundational Learning

- **Graph Attention Networks with Structural Bias**: Understanding standard GAT and Graphormer's spatial encoding is prerequisite for grasping how probability-based bias injection differs from edge features. Quick check: Can you explain how adding a learnable bias b_φ(i,j) to attention scores differs from using edge features directly?

- **Long-Tail Learning and Macro-Averaged Metrics**: The entire motivation hinges on rare-code performance; Macro-F1 is the key evaluation metric. Quick check: Why does Macro-F1 penalize models that perform well only on frequent classes more than Micro-F1?

- **Multi-Label Classification with Extreme Label Spaces**: ICD coding involves 8K–26K labels per document; standard softmax is inapplicable. Quick check: How does binary cross-entropy with sigmoid activation handle multi-label prediction differently from softmax cross-entropy?

## Architecture Onboarding

- **Component map**: Document Encoder (GatorTron) -> Code Encoder (GPT-4o descriptions + GatorTron) -> Directed Bipartite Graph Encoder (probability-biased attention) -> Multi-Label Attention + Classification
- **Critical path**: LLM descriptions → code embeddings → graph attention with probability bias → rare code enrichment → document-code attention → predictions
- **Design tradeoffs**: B bins (5/10/15) - more bins = finer granularity but risk overfitting; Graph layers (1/2/3) - 2 layers slightly better Macro-F1 but 1 layer chosen for efficiency; Frozen vs. fine-tuned code encoder - frozen to save GPU memory but may limit adaptation
- **Failure signatures**: Macro-F1 stagnant despite Micro-F1 improving → probability bias not helping rare codes; Training divergence with NaN losses → -∞ mask overflow in attention; Poor generalization to unseen rare codes → LLM descriptions may not cover test-set codes
- **First 3 experiments**: (1) Run ProBias(MI) baseline (mutual information graph, no direction/bias) to establish floor performance; (2) Ablation sequence: MI→DI (add directional flow), DI→DI+CE (add co-occurrence encoding), DI+CE→full (add LLM descriptions) to isolate contributions; (3) Hyperparameter sweep: vary bin count B ∈ {5,10,15} and graph layers L ∈ {1,2,3} on MIMIC-III-ICD-9 dev set

## Open Questions the Paper Calls Out

### Open Question 1
Can a learnable continuous mapping function effectively replace the discretized probability binning in the co-occurrence encoder? The authors state future work could explore "a learnable mapping function that operates directly on these continuous values" rather than binning them. The current quantile binning method collapses fine-grained probability values into coarse bins, potentially losing subtle variations in comorbidity strength. Empirical results comparing performance of a model using learned continuous bias function against current binned approach on Macro-F1 would resolve this.

### Open Question 2
Does a gating mechanism improve the integration of LLM-generated descriptions with formal medical ontologies? The authors suggest integrating a gating mechanism to "dynamically fuse these LLM-derived descriptions with original code names or ontological concepts." While LLM descriptions improve performance, they may introduce noise or hallucinations; the optimal balance between descriptive richness and formal precision has not been established. Ablation studies demonstrating performance differences when using dynamic gating layer would resolve this.

### Open Question 3
Does the strict unidirectional information flow from common to rare codes limit the model's ability to capture bidirectional diagnostic dependencies? The paper restricts directed bipartite graph to edges flowing only from common to rare codes to enrich rare representations, assuming information primarily flows from frequent to infrequent conditions. The paper does not justify why reverse edges are excluded; rare underlying etiologies often predict common symptoms, and blocking this flow could degrade common code representations. Comparative analysis of model performance between current unidirectional architecture and bidirectional variant would resolve this.

## Limitations
- The directed bipartite flow assumption (common→rare beneficial, rare→common harmful) remains untested against undirected alternatives
- LLM-generated code descriptions are essential but not released, requiring costly regeneration that may vary
- Probability discretization may collapse fine-grained comorbidity patterns into uninformative bins for extremely rare codes
- The model's performance heavily depends on the accuracy and comprehensiveness of external knowledge sources

## Confidence

- **High Confidence**: Experimental methodology and evaluation protocol using standard MIMIC datasets and proper train/val/test splits
- **Medium Confidence**: Core mechanism of probability-biased attention via discretized co-occurrence bins should work as described, effectiveness depends on co-occurrence statistics quality
- **Medium Confidence**: Directed bipartite architecture will improve rare code representations, but superiority over undirected alternatives untested
- **Low Confidence**: LLM knowledge injection effectiveness cannot be fully verified without access to exact generated descriptions or independent validation

## Next Checks

1. **Sanity Check on Probability Binning**: Implement Algorithm 1 to verify P=1 values are correctly assigned to bin B and zero probabilities are handled separately; log bin distributions to confirm they reflect meaningful co-occurrence strength.

2. **Directional Flow Ablation**: Compare full directed bipartite model against undirected version on MIMIC-III-ICD-9 validation set; measure whether removing directionality improves or harms Macro F1, particularly for rare codes.

3. **LLM Description Sensitivity**: Replace GPT-4o-generated descriptions with original code names/synonyms or different LLM (e.g., GPT-3.5) with same prompt template; measure impact on rare code Macro F1 to quantify dependence on external knowledge quality.