---
ver: rpa2
title: 'We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental
  Time Series Classification'
arxiv_id: '2601.10312'
source_url: https://arxiv.org/abs/2601.10312
tags:
- learning
- time
- series
- causal
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses domain-incremental time series classification
  (DI-TSC), where models must continually adapt to new domains while retaining performance
  on previous ones. The authors propose DualCD, a dual causal disentanglement framework
  that extracts class-invariant causal features from time series data to improve robustness
  in domain-incremental scenarios.
---

# We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental Time Series Classification

## Quick Facts
- **arXiv ID**: 2601.10312
- **Source URL**: https://arxiv.org/abs/2601.10312
- **Reference count**: 40
- **Key outcome**: DualCD framework achieves 3.16%-9.00% accuracy improvement and 3.52%-20.65% relative forgetting reduction over state-of-the-art methods across four time series classification datasets

## Executive Summary
This paper addresses domain-incremental time series classification (DI-TSC), where models must continually adapt to new domains while retaining performance on previous ones. The authors propose DualCD, a dual causal disentanglement framework that extracts class-invariant causal features from time series data to improve robustness in domain-incremental scenarios. The method combines orthogonal feature disentanglement with a dual causal intervention mechanism that generates perturbed samples to eliminate intra-class and inter-class confounding features. Experimental results demonstrate that DualCD significantly outperforms 12 baseline methods across four benchmark datasets (HAR, HHAR, ISRUC-S3, Sleep-EDF), achieving accuracy improvements of 3.16%-9.00% over state-of-the-art approaches while reducing relative forgetting by 3.52%-20.65%. The framework also shows broad compatibility when integrated with various time series classification models and introduces a novel Performance-aware Relative Forgetting metric for more comprehensive evaluation.

## Method Summary
DualCD addresses domain-incremental time series classification by learning to disentangle causal features from spurious domain-specific features. The framework uses a temporal encoder to produce representations, then applies orthogonal feature disentanglement via negatively correlated sigmoid masks to separate causal (Z_R) and spurious (Z_I) components. A dual causal intervention mechanism then generates perturbed samples by swapping spurious features within the same class (intra-class) and replacing spurious features with causal features from other classes (inter-class). The model is trained to predict original labels using only causal features from these perturbed samples, forcing the network to rely on domain-invariant causal features. This approach requires no data replay and works with any time series classification backbone.

## Key Results
- DualCD achieves 3.16%-9.00% accuracy improvements over state-of-the-art methods across four datasets
- Relative forgetting is reduced by 3.52%-20.65% compared to baselines
- The framework shows broad compatibility, working with DLinear, PatchTST, and DisMS-TS backbones
- DualCD achieves the best overall performance in 7 out of 8 evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1: Orthogonal Feature Disentanglement
- Claim: Partitioning temporal representations into causal and spurious components via negatively correlated sigmoid masks may improve domain robustness.
- Mechanism: A single-layer MLP generates an intermediate score vector M from representation Z. Sigmoid(M) produces M_R (causal mask) while Sigmoid(-M) produces M_I (spurious mask). Element-wise multiplication yields Z_R = M_R ⊙ Z and Z_I = M_I ⊙ Z. Orthogonality ensures non-overlapping feature sets.
- Core assumption: Causal features for class discrimination exist in a subspace separable from domain-specific spurious features via linear projection.
- Evidence anchors:
  - [abstract] "DualCD first introduces a temporal feature disentanglement module to capture class-causal features and spurious features."
  - [section 4.3.1] "The orthogonality of these matrices ensures that the resulting feature sets are non-overlapping."
  - [corpus] Weak direct evidence; related work (REAL, DualCP) addresses feature separation but not via orthogonal masks for time series.

### Mechanism 2: Intra-Class Causal Intervention
- Claim: Perturbing spurious features within the same class while preserving causal features may force the model to rely on causal features for prediction.
- Mechanism: For sample i, replace Z_I^(i) with Z_I^(i') sampled from another same-class sample. Reconstruct Z̃_intra = Z_R^(i) + Z_I^(i'), then compute cross-entropy loss with original label y^(i). This simulates do-intervention on spurious features.
- Core assumption: Within-class spurious feature variation approximates the distribution of confounders that cause domain shift.
- Evidence anchors:
  - [abstract] "This mechanism constructs variant samples by combining the current class's causal features with intra-class spurious features."
  - [section 4.4.2] "We randomly select spurious features from other intra-class samples to replace the original spurious features."
  - [corpus] Causal intervention strategies appear in related work (semantic shift estimation via dual-projection) but not specifically for intra-class time series perturbation.

### Mechanism 3: Inter-Class Causal Contrast
- Claim: Replacing spurious features with causal features from other classes may sharpen inter-class decision boundaries.
- Mechanism: For sample i, replace Z_I^(i) with Z_R^(¬i) sampled from a different class. Reconstruct Z̃_inter = Z_R^(i) + Z_R^(¬i), train model to predict original label y^(i). Forces causal features Z_R^(i) to override conflicting information from Z_R^(¬i).
- Core assumption: Causal features from different classes provide informative negative signals that strengthen discriminability.
- Evidence anchors:
  - [abstract] "...and with causal features from other classes. The causal intervention loss encourages the model to accurately predict the labels of these variant samples based solely on the causal features."
  - [section 4.4.3] "To generate causal features that are clearly distinguishable from those of other classes, we randomly sample the causal features of a sample from any other class."
  - [corpus] Inter-class contrastive strategies appear in exemplar-free CIL (REAL, semantic shift estimation) but using causal features as explicit negative perturbations is novel to this framework.

## Foundational Learning

- **Catastrophic Forgetting in Neural Networks**
  - Why needed here: DualCD explicitly targets forgetting in domain-incremental settings; understanding the stability-plasticity tradeoff clarifies why disentanglement helps.
  - Quick check question: Can you explain why fine-tuning on new domains degrades performance on old domains without explicit regularization?

- **Causal Inference Basics (do-calculus, confounding)**
  - Why needed here: The paper frames feature perturbation as causal intervention; grasping confounding clarifies why spurious features harm generalization.
  - Quick check question: What does P(Y|do(X)) represent, and how does it differ from P(Y|X)?

- **Time Series Representation Learning (CNN/RNN/Transformer encoders)**
  - Why needed here: DualCD is model-agnostic but requires understanding how encoders produce Z; disentanglement operates on this latent space.
  - Quick check question: Given a multivariate time series of shape (L, M), what does the encoder output Z typically represent dimensionally?

## Architecture Onboarding

- **Component map:**
  Temporal Encoder ψ(·) -> Disentanglement MLP -> Orthogonal Masks M_R, M_I -> Feature Split Z_R (causal), Z_I (spurious) -> Intra-class Perturbation (swap Z_I) -> Inter-class Perturbation (swap Z_I with Z_R) -> Classifier φ(·)

- **Critical path:**
  Forward pass: X -> ψ -> Z -> MLP -> M -> M_R, M_I -> Z_R, Z_I -> [perturbations] -> φ -> logits
  
  Loss computation: L = λ·L_intra + (1-λ)·L_inter (no standard CE on original Z required; paper uses perturbed samples)

- **Design tradeoffs:**
  - λ (default 0.5): Higher values emphasize intra-class robustness; lower values emphasize inter-class discrimination. Paper finds 0.3–0.5 optimal across datasets.
  - Mask temperature: Sigmoid produces soft masks; hard thresholding could improve separation but may lose gradient signal.
  - Backbone choice: Simpler models (DLinear) show larger gains from DualCD; complex models (PatchTST) have less headroom but still benefit.

- **Failure signatures:**
  - Accuracy collapses after domain 2–3: Disentanglement may be collapsing to trivial solutions (all features in Z_R or Z_I). Check mask entropy.
  - PRF improves but ACC degrades: Model may be overly conservative, ignoring informative spurious features that aid classification.
  - Large performance gap between validation and test: Overfitting to perturbation distribution; reduce λ or add standard CE loss.

- **First 3 experiments:**
  1. **Sanity check on single domain:** Train DualCD on D1 only. Verify Z_R clusters by class (t-SNE) while Z_I shows domain-wise spread. This validates disentanglement before incremental setup.
  2. **Ablation on perturbation types:** Run three variants—intra-only (λ=1), inter-only (λ=0), both (λ=0.5)—on HAR dataset with 5 domains. Expect both to outperform neither, combination to be best or comparable.
  3. **Cross-backbone validation:** Integrate DualCD with two backbones (e.g., DLinear and PatchTST) on HHAR. Measure ACC, RF, PRF. Verify gains are consistent, confirming model-agnostic claim.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the DualCD framework be adapted for cross-dataset scenarios where time series variables differ in semantics and quantity?
- **Basis in paper:** [explicit] The Conclusion states: "it cannot be directly extended to cross-dataset scenarios due to discrepancies in the number and semantics of time series variables."
- **Why unresolved:** The current feature disentanglement module assumes a consistent feature dimension and semantic structure across all domains, which breaks when transferring knowledge to entirely different datasets.
- **What evidence would resolve it:** A study integrating variable alignment techniques or semantic mapping layers into DualCD, demonstrating performance retention across datasets with disjoint feature spaces.

### Open Question 2
- **Question:** Is the linear orthogonal disentanglement strategy sufficient for separating features that are non-linearly entangled in complex time series data?
- **Basis in paper:** [inferred] Section 4.3.1 describes the disentanglement module using a single MLP layer and negatively correlated soft masks, implying a potentially linear separation of causal and spurious features.
- **Why unresolved:** Time series data often involves complex, non-linear interactions between signal and noise; a simple element-wise masking strategy may fail to disentangle highly correlated features effectively.
- **What evidence would resolve it:** Ablation studies comparing the current linear disentanglement against non-linear alternatives (e.g., hypernetworks or attention-based separators) on synthetic datasets with controlled non-linear entanglement.

### Open Question 3
- **Question:** How does the optimal weighting hyperparameter $\lambda$ (balancing intra-class and inter-class intervention) correlate with the magnitude of domain shift?
- **Basis in paper:** [inferred] Section 5.4 shows that the optimal $\lambda$ varies significantly (0.3 for Sleep-EDF vs. 0.5 for others), suggesting the balance depends on dataset characteristics not fully explored.
- **Why unresolved:** The paper does not provide a theoretical or empirical guideline for selecting $\lambda$ a priori based on the nature of the incremental domains.
- **What evidence would resolve it:** An analysis plotting the optimal $\lambda$ against quantitative domain divergence metrics (e.g., KL divergence or Maximum Mean Discrepancy) to derive a selection heuristic.

## Limitations

- The framework cannot be directly extended to cross-dataset scenarios due to discrepancies in the number and semantics of time series variables
- The paper does not report computational overhead compared to baseline methods, making deployment cost-benefit analysis difficult
- No ablation studies on mask temperature or hard vs soft masking strategies

## Confidence

- **High Confidence**: The framework's architecture and training procedure are clearly specified with code available
- **Medium Confidence**: Performance improvements are statistically significant, but the exact contribution of each mechanism (disentanglement vs dual intervention) is unclear
- **Low Confidence**: The claim that DualCD "learns" causal features rather than finding correlated patterns that happen to work in these datasets

## Next Checks

1. Conduct ablation studies isolating disentanglement effectiveness by training with only Z_R or only Z_I to measure individual contributions
2. Verify causal feature claims through intervention experiments: measure if removing estimated spurious features actually changes predictions on new domains
3. Test computational overhead by measuring training time per epoch compared to baseline methods on the same hardware