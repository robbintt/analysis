---
ver: rpa2
title: 'When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method
  with LLM and Pseudo Label'
arxiv_id: '2507.18153'
source_url: https://arxiv.org/abs/2507.18153
tags:
- class
- label
- noise
- nodes
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GraphALP addresses class-imbalanced graph node classification with
  noisy labels by integrating LLM-based oversampling with dynamic pseudo-labeling.
  It generates synthetic minority nodes via LLM to balance class distribution while
  reducing label noise, then employs confidence-weighted pseudo-labeling to enhance
  supervision.
---

# When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method with LLM and Pseudo Label

## Quick Facts
- arXiv ID: 2507.18153
- Source URL: https://arxiv.org/abs/2507.18153
- Authors: Riting Xia; Rucong Wang; Yulin Liu; Anchen Li; Xueyan Liu; Yan Zhang
- Reference count: 14
- Primary result: GraphALP achieves up to 75.95% accuracy and 74.88% G-mean on benchmark datasets, outperforming state-of-the-art methods by 2.84%-8.03% across metrics.

## Executive Summary
GraphALP addresses class-imbalanced graph node classification with noisy labels by integrating LLM-based oversampling with dynamic pseudo-labeling. It generates synthetic minority nodes via LLM to balance class distribution while reducing label noise, then employs confidence-weighted pseudo-labeling to enhance supervision. A secondary LLM-guided oversampling mitigates skew from pseudo-labels. On benchmark datasets (Cora, CiteSeer, Pubmed, Wiki-CS), GraphALP achieves up to 75.95% accuracy and 74.88% G-mean, outperforming state-of-the-art methods by 2.84%-8.03% across metrics, demonstrating robust performance under varying imbalance and noise ratios.

## Method Summary
GraphALP tackles node classification on class-imbalanced graphs with noisy labels through a three-stage approach: (1) LLM-based oversampling generates synthetic minority node text via DeepSeek-Chat, encoded by jina-embedding-v3 to create balanced class distributions with accurate labels; (2) Self-supervised pre-training with Graph Autoencoder (GAE) and Autoencoder (AE) learns robust node representations using reconstruction losses; (3) Fine-tuning with confidence-weighted pseudo-labeling and weighted cross-entropy loss, where high-confidence pseudo-labels are assigned and a secondary LLM-guided oversampling rebalances any class skew introduced by pseudo-labeling.

## Key Results
- Achieves 75.95% accuracy and 74.88% G-mean on benchmark datasets
- Outperforms state-of-the-art methods by 2.84%-8.03% across metrics
- Demonstrates robust performance under varying imbalance ratios and noise levels

## Why This Works (Mechanism)

### Mechanism 1
LLM-based synthetic minority oversampling balances class distributions while introducing fewer erroneous labels than interpolation-based methods. A Large Language Model generates descriptive text for synthetic nodes conditioned on minority class labels, which a Language Model then encodes into feature vectors. This creates new, accurately labeled minority nodes independent of potentially noisy original nodes. The mechanism fails if nodes lack textual attributes or if semantic gaps between generated and real node text are too large.

### Mechanism 2
Dynamically weighted pseudo-labeling on class-balanced graphs provides high-confidence supervisory signals that reduce effective label noise. After graph augmentation, a GNN classifier predicts labels for unlabeled nodes, assigning pseudo-labels to those exceeding a confidence threshold. Class-weighted cross-entropy loss prevents the model from ignoring minority classes during pseudo-label selection. The mechanism fails if confidence scores are unreliable or the GNN is overconfident in errors.

### Mechanism 3
Secondary LLM-guided oversampling corrects class distribution skew introduced by pseudo-labeling itself. The pseudo-labeling process may assign more labels to majority classes even with weighting, so another round of LLM-based synthetic minority node generation rebalances the training set before final classification. This step is redundant if pseudo-labeling doesn't significantly bias class distribution or adds excessive computational overhead.

## Foundational Learning

- **Graph Neural Networks (GNNs) & Message Passing**: GraphALP relies on a GNN (GraphSAGE) for classification and pseudo-label generation. Understanding neighbor aggregation is essential. Quick check: How does a GNN update a target node's representation using its neighbors' features?

- **Class Imbalance & Oversampling (e.g., SMOTE)**: The paper challenges traditional oversampling methods that propagate noise, proposing an LLM-based alternative. Quick check: Why can interpolating between existing minority nodes (as in SMOTE) be problematic when those nodes have noisy labels?

- **Learning with Noisy Labels**: Standard training fails with randomly flipped labels (uniform noise). The method uses pseudo-labeling to "clean" data. Quick check: What is the difference between uniform (symmetric) and class-conditional (asymmetric) label noise?

## Architecture Onboarding

- **Component map**: LLM & LM Module -> Graph Autoencoder (GAE) Pre-trainer -> Weighted Pseudo-label Generator -> Secondary Rebalancer
- **Critical path**: Prompt LLM for minority text → Encode with LM → Add to graph → Pre-train GAE for robust embeddings → Train weighted GNN classifier → Extract pseudo-labels (if confidence > threshold) → Re-balance with LLM if needed → Final GNN training
- **Design tradeoffs**: LLM Quality vs. Cost (better LLMs increase latency/cost); Confidence Threshold (higher yields cleaner but fewer pseudo-labels); Synthetic Node Count (aggressive oversampling can cause overfitting to LLM artifacts)
- **Failure signatures**: Semantic Drift (synthetic embeddings cluster separately in t-SNE); Pseudo-label Collapse (model assigns majority class to almost all unlabeled nodes); No Improvement (performance identical to vanilla GNN)
- **First 3 experiments**: 1) LLM Ablation: Replace LLM-based oversampling with SMOTE to quantify benefit on minority class accuracy; 2) Threshold Sensitivity: Grid search confidence threshold (τ ∈ [0.5, 0.95]) and plot noise ratio vs. accuracy; 3) Noise Robustness Test: Inject varying uniform label noise (10%, 30%, 50%) and compare degradation curves against NRGNN

## Open Questions the Paper Calls Out

### Open Question 1
How does GraphALP perform under instance-dependent or structural label noise patterns rather than uniform random noise? The methodology explicitly uses "Uniform Noise" where labels are randomly flipped, which simplifies complex real-world noise structures where label errors often correlate with node features or topology. The confidence-weighted pseudo-labeling assumes high confidence correlates with correct labels, an assumption that may fail with adversarially structured noise. Evaluation on datasets with synthetic instance-dependent noise or naturally occurring noisy labels (e.g., WebKB) would test robustness beyond random flipping.

### Open Question 2
What is the impact of LLM "hallucinations" or semantic drift on synthetic minority node quality? The paper assumes LLM produces "label-accurate minority nodes" relying on the LLM's internal knowledge to generate valid text attributes for specific class labels. If LLM generates text that is plausible but semantically divergent from true data distribution, it could introduce "semantic noise" that misleads the GNN encoder. Qualitative and quantitative analysis of synthetic node text (e.g., using perplexity or human evaluation) and ablation studies comparing LLM-generated nodes against ground-truth minority nodes would measure information fidelity.

### Open Question 3
Can the framework adapt for non-text-attributed graphs where node features are continuous vectors or categorical data without semantic descriptions? The data augmentation module relies on a pipeline of `LLM -> Text -> SentenceBERT` to generate and embed synthetic nodes, restricting applicability to text-attributed graphs. The prompt engineering strategy is designed to generate text (titles/abstracts); it's unclear how to prompt an LLM to synthesize non-linguistic feature vectors (e.g., chemical fingerprints) while maintaining semantic consistency. Extension to non-text benchmarks using LLM to generate structural descriptions or logical rules mapped to feature vectors would verify adaptability.

## Limitations
- Method critically depends on availability of rich textual attributes for each node, unverified for purely structural graphs
- Performance gains demonstrated primarily on citation networks and one Wikipedia dataset, generalization to other graph types uncertain
- Pseudo-labeling confidence threshold and synthetic node generation scale are hyperparameters not fully specified, suggesting sensitivity to tuning
- Paper does not provide runtime or memory cost estimates for LLM-based oversampling, which could be a significant barrier for large graphs

## Confidence
- **High**: Method's architecture is clearly defined and empirical results show consistent improvements over baselines on reported datasets
- **Medium**: Core claim that LLM-generated text produces fewer noisy labels than interpolation-based methods is logically sound but not directly benchmarked against synthetic text ablation
- **Low**: Claim that secondary LLM-guided oversampling is necessary is based on an ablation but lacks analysis of pseudo-label distribution shift that justifies necessity

## Next Checks
1. **Ablation Study**: Replace LLM-based oversampling with standard interpolation method (e.g., SMOTE) on same datasets to quantify specific contribution of LLM-generated text to label quality and final accuracy
2. **Noise Robustness**: Systematically vary label noise ratio (10%, 30%, 50%) and plot accuracy/G-mean curves for GraphALP against strong graph noise-robust baseline (e.g., NRGNN) to test noise tolerance claim
3. **Generalization Test**: Apply GraphALP to non-text-attributed graph dataset (e.g., molecular graph benchmark) to verify method's reliance on textual attributes and performance drop in their absence