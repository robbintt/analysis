---
ver: rpa2
title: On the Role of Domain Experts in Creating Effective Tutoring Systems
arxiv_id: '2510.01432'
source_url: https://arxiv.org/abs/2510.01432
tags:
- systems
- could
- system
- experts
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This position paper argues for greater integration of expert-specified
  knowledge in AI for education systems. It presents two approaches: (1) using explainable
  AI techniques combined with expert-specified rules to automatically generate lessons,
  and (2) leveraging expert-defined curricula to structure adaptive tutoring systems.'
---

# On the Role of Domain Experts in Creating Effective Tutoring Systems

## Quick Facts
- arXiv ID: 2510.01432
- Source URL: https://arxiv.org/abs/2510.01432
- Reference count: 28
- Primary result: Position paper advocating for expert knowledge integration in AI tutoring systems through lesson generation and curriculum-structured POMDPs

## Executive Summary
This position paper argues that domain experts are essential for creating effective AI-driven tutoring systems, particularly in high-stakes domains like education. The authors present two complementary approaches: using explainable AI techniques combined with expert-specified rules to automatically generate lessons from classifier outputs, and leveraging expert-defined curricula to structure adaptive tutoring systems. Through a pollinator identification case study for citizen science organizations, they demonstrate how existing training materials can serve as a rich source of expert knowledge. The paper emphasizes that expert involvement ensures accurate, appropriately scaffolded lessons and enables more efficient algorithm design by reducing computational complexity.

## Method Summary
The proposed approach combines expert knowledge extraction, machine learning, and adaptive tutoring. Expert-provided rules about problem-solving are integrated with novel explainable AI (XAI) techniques to automatically generate pedagogically appropriate lessons from classifier outputs. For adaptive tutoring, expert-specified hierarchical curricula are used to structure POMDP-based systems, constraining belief spaces to improve computational efficiency. The method leverages existing training materials from citizen science organizations as sources of domain expertise, using public datasets like iNaturalist for classifier training. The system operates through a pipeline where XAI detects relevant concepts in images, expert rules map these to lessons, and curriculum constraints guide the adaptive tutoring policy.

## Key Results
- Expert-specified rules combined with XAI can generate pedagogically appropriate lessons from classifier outputs
- Hierarchical curricula can reduce POMDP belief-space complexity for more efficient adaptive tutoring
- Existing volunteer training materials can serve as valuable sources of domain expertise for AI systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expert-specified rules combined with XAI techniques can automatically generate pedagogically appropriate lessons from classifier outputs.
- Mechanism: The system uses XAI methods (feature attribution, concept-based explanation) to identify which features or concepts the classifier used for a prediction. Expert-provided rules—expressed in terms of those same concepts—determine which explanation to surface and how to frame it as a lesson. Uncertainty estimates flag cases where the classifier may be wrong, preventing misleading instruction.
- Core assumption: Expert identification rules can be expressed using concepts that XAI methods can reliably detect in classifier outputs.
- Evidence anchors:
  - [abstract]: "we will discuss how one could use expert specified rules about solving specific problems along with novel XAI techniques to automatically generate lessons"
  - [section 2]: Shows wasp classification example where "pinched-waist" concept must be both detectable by XAI and specified in expert rules; notes uncertainty can be used to ensure lesson accuracy
  - [corpus]: Neighbor papers discuss knowledge elicitation but do not directly validate this specific lesson-generation pipeline
- Break condition: If concept classifiers have low fidelity, or if expert rules reference concepts the XAI cannot detect, generated lessons become disconnected from actual image content.

### Mechanism 2
- Claim: Hierarchical curriculum structures can reduce POMDP belief-space complexity enough to make adaptive tutoring computationally tractable.
- Mechanism: Expert-defined prerequisite relationships between concepts (e.g., "identify bee/wasp/fly before learning genus") constrain the sequence of possible learner states. This reduces the number of expertise levels the POMDP policy must reason about at any point, shrinking the belief space and improving computational efficiency.
- Core assumption: Domain concepts have learnable prerequisite relationships that experts can accurately specify.
- Evidence anchors:
  - [abstract]: "expert specified curriculum for learning a target concept can help develop adaptive tutoring systems, that can not only provide a better learning experience, but could also allow us to use more efficient algorithms"
  - [section 3]: "identifying hierarchies between concepts and the order in which they need to be taught could go a long way in simplifying the set of possible expertise levels"; cites prior work showing computational advantages in other settings
  - [corpus]: No direct empirical validation in neighbors; Paper 13030 addresses curriculum modeling for personalization but not POMDP efficiency
- Break condition: If prerequisite relationships are incorrectly specified, or if learners frequently violate expected learning sequences, the POMDP policy may query or teach at inappropriate levels.

### Mechanism 3
- Claim: Domain expertise for tutoring systems can be extracted from materials organizations already produce for volunteer training, reducing knowledge engineering burden.
- Mechanism: Citizen science groups already create onboarding slides, identification guides, and curricula for volunteers. These existing artifacts provide the rules, concept hierarchies, and teaching content needed for the AI system. Public datasets (e.g., iNaturalist) supply training images; volunteer pools can provide additional annotations.
- Core assumption: Organizations have documented their domain knowledge in forms that can be adapted to AI-usable representations without excessive transformation effort.
- Evidence anchors:
  - [section 4]: "this is a set of information that is commonly provided to community scientists as part of their onboarding training"; references actual Native Bee Watch training slides
  - [section 4]: Notes morphospecies/concept classifiers can be trained from iNaturalist data; existing teaching materials can be reused for POMDP lesson content
  - [corpus]: Paper 80248 notes that expert knowledge typically resides with few experts and creates bottlenecks; Paper 99643 discusses LLM-assisted knowledge elicitation but targets visualization domains
- Break condition: If domain knowledge is primarily tacit (undocumented) or if existing materials use terminology inconsistent with classifier-detectable concepts, substantial manual translation is required.

## Foundational Learning

- **Partially Observable Markov Decision Processes (POMDPs)**
  - Why needed here: The proposed adaptive tutoring system uses POMDPs to model uncertainty about learner knowledge and select optimal teaching actions. Understanding belief states, observations, and policy computation is essential for implementing or debugging this component.
  - Quick check question: In a tutoring POMDP, what does the "belief state" represent and why does it expand as concepts increase?

- **Explainable AI (XAI) Methods**
  - Why needed here: The architecture repurposes XAI techniques (designed for debugging) for pedagogical explanation generation. Distinguishing feature attribution from concept-based explanation is necessary to select appropriate methods.
  - Quick check question: What is the difference between a feature attribution explanation and a concept-based explanation for an image classifier?

- **Concept Hierarchies and Prerequisite Structures**
  - Why needed here: The curriculum-driven approach assumes concepts can be ordered by prerequisite relationships. Understanding how to elicit and represent these hierarchies is critical for both the POMDP structuring and lesson sequencing.
  - Quick check question: How would you represent "must identify bee/wasp/fly before identifying genus" as a formal prerequisite constraint?

## Architecture Onboarding

- Component map:
  - Image/Concept Classifiers -> XAI Module -> Expert Rules Database -> Curriculum Hierarchy -> POMDP Policy Engine -> Lesson Renderer

- Critical path:
  1. Elicit or extract expert rules and curriculum hierarchy from existing training materials
  2. Train concept and morphospecies classifiers using labeled images (public datasets + volunteer annotations)
  3. Validate that XAI-detected concepts align with concepts referenced in expert rules
  4. Encode curriculum as POMDP state/action structure; initialize transition probabilities and objective function
  5. Integrate POMDP policy outputs with XAI module to select and format lessons
  6. Deploy with learner feedback loop to refine POMDP parameters over time

- Design tradeoffs:
  - Granularity of concept hierarchy: More granular curricula provide finer adaptation but increase POMDP belief-space complexity
  - Classifier accuracy vs. lesson safety: High uncertainty thresholds prevent misleading lessons but may reduce system responsiveness
  - Expert effort front-loading vs. ongoing maintenance: Initial investment in structured knowledge capture reduces downstream manual intervention but requires upfront expert availability
  - General XAI methods vs. custom concept detectors: Off-the-shelf XAI reduces development effort but may not align with domain-specific pedagogical concepts

- Failure signatures:
  - Concept mismatch: XAI surfaces concepts learners don't recognize (e.g., "pinched-waist" without definition); indicates missing prerequisite content
  - Belief collapse: POMDP policy oscillates between expertise levels without converging; may indicate noisy observations or incorrect curriculum structure
  - Lesson incoherence: Generated lessons reference concepts the classifier didn't actually use; indicates misalignment between expert rules and XAI outputs
  - Expert bottleneck: System requires continuous expert input to handle edge cases; suggests insufficient upfront knowledge capture

- First 3 experiments:
  1. Concept alignment audit: Train classifiers on pollinator images; run XAI on held-out examples; manually verify that XAI-detected concepts match those referenced in expert identification rules. Measure alignment rate and identify systematic gaps.
  2. Curriculum-constrained POMDP scalability test: Implement POMDP with and without curriculum constraints on a simplified concept hierarchy (5-10 concepts). Compare policy computation time and belief-state dimensionality to quantify computational gains.
  3. Lesson generation pilot with uncertainty filtering: Generate lessons for a small set of images with varying classifier confidence. Have domain experts rate lesson accuracy and pedagogical appropriateness; correlate ratings with uncertainty thresholds to calibrate filtering criteria.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we build tools that allow education experts (distinct from domain experts) to integrate pedagogical best practices into the knowledge collected for AI systems?
- Basis in paper: [explicit] Page 6 notes, "there is a question about whether we can build tools that can help education experts introduce best practices into the knowledge we collect."
- Why unresolved: The paper recommends building better tooling but does not present a specific interface or methodology for bridging the gap between domain knowledge and educational design.
- What evidence would resolve it: The development and successful validation of an interface that enables education experts to modify or structure domain expert inputs effectively.

### Open Question 2
- Question: Does the use of expert-specified hierarchical curricula in POMDP-based tutoring systems yield the expected computational advantages in educational settings?
- Basis in paper: [inferred] Page 5 states that structuring belief spaces with curricula "has shown to provide computational advantages in other settings, and we expect it to carry over in this new setting."
- Why unresolved: The paper provides a theoretical argument and a diagram (Fig 2) but lacks empirical benchmarks proving that this structure reduces computational costs in the proposed tutoring domain.
- What evidence would resolve it: Performance benchmarks comparing the computation time and policy generation efficiency of curriculum-structured POMDPs against standard POMDPs in a live tutoring system.

### Open Question 3
- Question: Does the automatic generation of lessons using expert rules and XAI techniques result in better learning outcomes than standard XAI methods?
- Basis in paper: [inferred] Page 4 argues that standard XAI methods are "insufficient" for learners and proposes a pipeline using expert rules, but provides no user study data.
- Why unresolved: The paper posits that expert-augmented lessons are better but relies on a single visual example (Figure 1) rather than comparative experimental data.
- What evidence would resolve it: A comparative user study measuring learner retention and identification accuracy between groups receiving standard XAI explanations versus the proposed expert-rule-based lessons.

## Limitations
- The paper lacks empirical validation of the proposed lesson-generation pipeline and computational efficiency claims
- Key implementation details for the POMDP formulation, classifier training, and XAI integration are unspecified
- The assumed availability of expert knowledge in reusable formats may not generalize across domains

## Confidence
- **High confidence**: The value of integrating domain expertise into tutoring systems; the identified bottleneck of knowledge engineering in AI education
- **Medium confidence**: The feasibility of extracting expert knowledge from existing volunteer training materials; the computational benefits of curriculum constraints on POMDPs (based on related work)
- **Low confidence**: The specific mechanisms for aligning XAI outputs with expert rules; the robustness of concept-based explanations for diverse learner backgrounds; the generalizability of the citizen science training materials approach

## Next Checks
1. Conduct a concept alignment audit to verify that XAI methods can reliably detect the visual concepts experts reference in identification rules.
2. Implement a curriculum-constrained POMDP on a simplified concept hierarchy to measure computational efficiency gains empirically.
3. Pilot the lesson-generation pipeline with domain experts to evaluate accuracy and pedagogical appropriateness of generated content under varying classifier confidence thresholds.