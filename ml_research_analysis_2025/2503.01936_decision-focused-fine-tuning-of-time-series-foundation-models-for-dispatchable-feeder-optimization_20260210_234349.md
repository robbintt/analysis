---
ver: rpa2
title: Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable
  Feeder Optimization
arxiv_id: '2503.01936'
source_url: https://arxiv.org/abs/2503.01936
tags:
- fine-tuning
- optimization
- forecast
- learning
- foundation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Decision-Focused Fine-Tuning (DFF), a method
  that integrates decision-focused learning with parameter-efficient fine-tuning (PEFT)
  to improve forecasts for energy optimization problems. DFF uses a surrogate neural
  network to align model training with downstream optimization objectives, such as
  minimizing costs in dispatchable feeder scheduling.
---

# Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization

## Quick Facts
- arXiv ID: 2503.01936
- Source URL: https://arxiv.org/abs/2503.01936
- Reference count: 40
- DFF reduces average daily total costs by 9.45% compared to prediction-focused fine-tuning and by 20.26% compared to zero-shot forecasting

## Executive Summary
This paper introduces Decision-Focused Fine-Tuning (DFF), a method that integrates decision-focused learning with parameter-efficient fine-tuning (PEFT) to improve forecasts for energy optimization problems. DFF uses a surrogate neural network to align model training with downstream optimization objectives, such as minimizing costs in dispatchable feeder scheduling. The approach is applied to Moirai, a time series foundation model, using LoRA and DoRA PEFT methods. Evaluated on the Ausgrid solar home electricity dataset, DFF significantly reduces average daily total costs compared to prediction-focused fine-tuning and zero-shot forecasting.

## Method Summary
DFF combines decision-focused learning with parameter-efficient fine-tuning by using a surrogate neural network to approximate the non-differentiable optimization landscape of downstream decision costs. The method trains PEFT adapters (LoRA or DoRA) attached to the frozen Moirai foundation model by backpropagating through the surrogate network's cost predictions. The surrogate is pre-trained on historical optimization runs from buildings 1-50, then frozen during fine-tuning. Global DFF trains on multiple buildings simultaneously for scalability, while local DFF trains separately for each building for better performance.

## Key Results
- DFF reduces average daily total costs by 9.45% compared to prediction-focused fine-tuning and by 20.26% compared to zero-shot forecasting
- Local fine-tuning achieves lower costs (€12.75) than global fine-tuning (€13.15-13.18) but requires training per building
- Global fine-tuning shows higher variance (std 0.14-0.20) compared to local (std 0.03-0.04)
- LoRA (0.64% parameters) performs equivalently to DoRA (0.68% parameters) for this task

## Why This Works (Mechanism)

### Mechanism 1: Surrogate Neural Network for Non-Differentiable Optimization
A surrogate neural network enables gradient-based optimization of non-differentiable downstream decision costs by approximating the optimization landscape. The value function that returns forecast value is not differentiable because it requires solving an optimization problem. The surrogate learns to approximate this landscape from historical optimization runs, allowing gradients to flow through it back to the PEFT adapter weights. This aligns weight updates with decision cost reduction rather than prediction error.

### Mechanism 2: Parameter-Efficient Fine-Tuning for Foundation Models
Parameter-efficient fine-tuning (PEFT) preserves foundation model generalization while enabling task-specific adaptation with minimal trainable parameters. LoRA decomposes weight updates into low-rank matrices (W' = W₀ + BA where r ≪ min(d,k)), and DoRA extends this with a learnable magnitude vector. Only the low-rank components are trained (<0.7% of total parameters), constraining adaptation to a low-dimensional subspace that reduces overfitting risk while allowing decision-focused adjustments.

### Mechanism 3: Non-Linear Correlation Between Forecast Errors and Decision Costs
Forecast quality metrics (MAE, MSE) do not linearly correlate with decision costs in optimization problems with battery flexibility. The dispatchable feeder problem has asymmetric costs—imbalance costs heavily penalize deviations from the schedule. MAE minimization can produce outliers that exceed battery flexibility, incurring high imbalance costs. The surrogate network learns the actual cost landscape, which is non-convex and instance-dependent.

## Foundational Learning

- **Decision-Focused Learning vs Prediction-Focused Learning**
  - Why needed here: Standard forecasting optimizes MAE/MSE, which are proxies that may not correlate with downstream decision value. DFL directly optimizes the decision objective. Without this distinction, you may fine-tune a model to worse decision outcomes despite improved forecast accuracy.
  - Quick check question: Can you articulate why a forecast with lower MAE might produce higher battery scheduling costs? (Answer: MAE-optimized forecasts may have outliers that exceed flexibility constraints, causing high imbalance penalties.)

- **Surrogate Loss Functions for Non-Differentiable Optimization**
  - Why needed here: The dispatchable feeder optimization is a two-level non-convex problem. You cannot backpropagate through its solution. Surrogate networks approximate the cost landscape, enabling gradient-based learning.
  - Quick check question: Given historical (forecast, actual, cost) tuples, how would you train a surrogate network? What input features would it need? (Answer: Train via supervised learning on cost outcomes. Inputs: forecast values, exogenous factors like state-of-charge estimates, time features.)

- **Low-Rank Adaptation for Foundation Models**
  - Why needed here: Foundation models like Moirai have 91M+ parameters. Full fine-tuning is computationally expensive and risks catastrophic forgetting. LoRA/DoRA enable efficient adaptation by learning low-rank deltas.
  - Quick check question: If LoRA uses rank r=8 on a 1024×1024 weight matrix, how many trainable parameters are added? (Answer: 2 × 1024 × 8 = 16,384 parameters vs 1,048,576 original.)

## Architecture Onboarding

- **Component map:**
  - Moirai Foundation Model (frozen) -> PEFT Adapter (LoRA/DoRA, trainable) -> Surrogate Neural Network (frozen) -> Dispatchable Feeder Optimizer

- **Critical path:**
  1. Pre-train surrogate networks on historical building data (buildings 1-50) using ground-truth prosumption and resulting costs
  2. Initialize PEFT adapter (LoRA/DoRA) attached to Moirai's attention layers
  3. Forward pass: Moirai generates forecast → surrogate predicts cost → backpropagate ∂cost/∂forecast through surrogate → update PEFT weights
  4. Evaluate on test buildings (101-300) by running actual dispatchable feeder optimization with forecasts

- **Design tradeoffs:**
  - **Local vs Global fine-tuning**: Local achieves lower costs (€12.75) but requires training per instance. Global trains once but has higher variance (std 0.14-0.20 vs 0.03-0.04). Choose global for scalability >200 instances; local for <50 high-value instances.
  - **LoRA vs DoRA**: DoRA adds magnitude learning but minimal performance difference observed. LoRA is more parameter-efficient (0.64% vs 0.68%). Choose LoRA unless preliminary tests show DoRA advantage.
  - **Surrogate ensemble size**: Paper uses 5 networks. More ensembles reduce variance but increase inference cost during fine-tuning.

- **Failure signatures:**
  - MAE fine-tuned models worse than zero-shot: Indicates mismatch between MAE objective and decision cost structure; switch to MSE or surrogate loss
  - High standard deviation in global fine-tuning: Suggests surrogate does not generalize uniformly across building types; consider clustering buildings and training cluster-specific surrogates
  - Surrogate validation loss diverging: Surrogate is overfitting to training buildings; increase data augmentation or reduce network capacity

- **First 3 experiments:**
  1. **Surrogate validation check**: Train surrogate on buildings 1-50, validate on 51-100. Report MSE between predicted and actual dispatch costs. If MSE > threshold, debug feature engineering before proceeding.
  2. **Ablation: Loss function comparison**: Fine-tune Moirai with LoRA (global mode) using MAE, MSE, and surrogate losses. Compare average daily total costs on buildings 101-300. Expect ordering: surrogate < MSE < MAE < zero-shot.
  3. **Scalability boundary test**: Identify minimum number of buildings needed for stable global DFF. Train global DFF on subsets {5, 10, 25, 50} buildings, evaluate on held-out buildings. Plot cost reduction vs training set size to find the point of diminishing returns.

## Open Questions the Paper Calls Out
None

## Limitations
- The surrogate network assumes stable cost structures (α=10 imbalance penalty); changes to this parameter would require retraining the surrogate
- Global fine-tuning shows higher variance (std 0.14-0.20) compared to local (std 0.03-0.04), suggesting potential generalization gaps across building types
- The paper does not perform ablation studies on LoRA rank (r=8) or surrogate ensemble size (5 networks), leaving these hyperparameters potentially suboptimal

## Confidence
- **High**: Decision-focused fine-tuning improves optimization outcomes over prediction-focused methods (validated on 200+ test buildings)
- **Medium**: LoRA vs DoRA performance equivalence (minimal differences observed but not exhaustively tested)
- **Medium**: Surrogate network generalization (trained on 50 buildings, validated on 250, but performance on new building types unknown)

## Next Checks
1. **Surrogate validation check**: Train surrogate on buildings 1-50, validate on 51-100. Report MSE between predicted and actual dispatch costs. If MSE exceeds threshold, debug feature engineering before proceeding.
2. **Ablation: Loss function comparison**: Fine-tune Moirai with LoRA (global mode) using MAE, MSE, and surrogate losses. Compare average daily total costs on buildings 101-300. Expect ordering: surrogate < MSE < MAE < zero-shot.
3. **Scalability boundary test**: Train global DFF on subsets {5, 10, 25, 50} buildings, evaluate on held-out buildings. Plot cost reduction vs training set size to find the point of diminishing returns.