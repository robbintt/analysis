---
ver: rpa2
title: 'SIGN: Schema-Induced Games for Naming'
arxiv_id: '2510.21855'
source_url: https://arxiv.org/abs/2510.21855
tags:
- schema
- agreement
- naming
- agents
- population
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores how structured communication schemas can steer
  convention formation among LLM agents in a naming game. The authors introduce Schema-Induced
  Games for Naming (SIGN), where agents must reply in a fixed JSON-like format, and
  compare this to unconstrained natural language and a sliding-window variant.
---

# SIGN: Schema-Induced Games for Naming

## Quick Facts
- arXiv ID: 2510.21855
- Source URL: https://arxiv.org/abs/2510.21855
- Authors: Ryan Zhang; Herbert Woisetschläger
- Reference count: 4
- Primary result: Schema-induced communication achieves up to 5.8× higher population agreement (0.61-0.64) compared to unconstrained natural language (0.11-0.33) in LLM naming games.

## Executive Summary
This study demonstrates that minimal structural priors in communication formats can dramatically improve convention formation among LLM agents in naming games. By constraining agents to reply in a fixed JSON-like format (@say{name: Ck}), the authors show that schema-induced communication achieves substantially higher population agreement and converges with an order of magnitude fewer tokens than unconstrained natural language or memory-enhanced variants. The benefits hold across different model families and population sizes, suggesting that structured templates act as effective coordination mechanisms.

## Method Summary
The study implements a population naming game where N agents (12-24) must converge on shared naming conventions from a fixed lexicon of M=12 names. Agents are paired randomly each round and must propose names for their partner. Three conditions are tested: natural language (unconstrained), natural language with sliding window memory, and schema-induced communication requiring fixed JSON-like format. The schema condition uses regex parsing with one retry on non-compliance, then random fallback. Population agreement, token efficiency, and variance are measured across 300 rounds with three random seeds per configuration.

## Key Results
- Schema condition achieves 5.8× higher population agreement (0.61-0.64) versus unconstrained natural language (0.11-0.33)
- Schema converges with an order of magnitude fewer tokens to reach 50% agreement
- Schema maintains lower variance across runs and holds across different model families and mixed populations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Schema formats reduce interpretation ambiguity between sender and receiver agents
- Mechanism: The fixed `@say{name: Ck}` template provides an explicit, regex-parsable handle for lexicon entries, eliminating the need for agents to infer intent from free-form text
- Core assumption: LLMs generate more consistent outputs when constrained to structured templates than unconstrained natural language
- Evidence anchors: Abstract states minimal structure acts as a simple control knob for efficient coordination; section notes structured templates improve reasoning and reliability
- Break condition: If agents produce high rates of non-compliant outputs (>20%) requiring retry or random fallback, schema benefits would degrade

### Mechanism 2
- Claim: Schema induction reduces token-level search variance, accelerating convention lock-in
- Mechanism: Constraining valid outputs to a narrow template space reduces effective vocabulary at each turn, lowering probability of divergent proposals
- Core assumption: Reduced output variance at individual-agent level translates to faster population-level agreement
- Evidence anchors: Abstract notes schema achieves up to 5.8× higher agreement; section shows standard deviation decreases over time
- Break condition: If lexicon size scales dramatically beyond tested values, template constraints may not prevent combinatorial explosion

### Mechanism 3
- Claim: Schema provides a shared structural prior that acts as a coordination focal point
- Mechanism: All agents receive same format specification, creating Schelling-like focal point that aligns expectations before any interaction
- Core assumption: Agents treat schema as fixed convention rather than negotiable element
- Evidence anchors: Abstract states minimal structural priors effectively control multi-agent coordination; section shows gains come mainly from schema induction
- Break condition: If agents instructed to negotiate or modify schema itself, fixed-prior assumption fails

## Foundational Learning

- **Naming Game Dynamics**: The paper builds on canonical naming game where agents propose names and adopt partner names on mismatch. Understanding baseline dynamics is essential to interpret schema intervention.
  - Quick check: In standard naming game with no memory, what happens to population agreement as rounds increase?

- **Lose-Shift Probability (α)**: Parameter controlling how readily agents adopt partner's name after disagreement. Schema benefits hold across α ∈ {0.5, 0.75, 0.9}, but higher α slightly reduces agreement.
  - Quick check: If α=1.0 (always adopt partner's name), would you expect faster or slower convergence than α=0.5?

- **Lexicon and Memory Window**: Lexicon L defines valid names (M=12 options); memory window K determines how many past interactions influence proposals. Schema effects persist across K=5 and K=10.
  - Quick check: Why might increasing K provide diminishing returns once convention is partially established?

## Architecture Onboarding

- **Component map**: Agent Pool -> Pairing Engine -> Proposal Generator -> Schema Parser -> Fallback Handler -> Adoption Logic -> Memory Update -> Repeat
- **Critical path**: 1) Agents paired → 2) Each forms proposal from partner-only memory → 3) Parser extracts name (or triggers fallback) → 4) Names compared → 5) If mismatch, probabilistic adoption → 6) Memory updated → 7) Repeat for T rounds
- **Design tradeoffs**: Schema strictness vs. agent autonomy; memory window size vs. token costs; population scale vs. generalization
- **Failure signatures**: High non-compliance rate (>10% rounds requiring fallback) suggests ambiguous schema instructions; flat agreement curve indicates pairing/adoption bugs; high variance suggests under-constrained process
- **First 3 experiments**: 1) Replicate N=12, K=5, α=0.75 configuration with 3 seeds to verify agreement reaches ~0.60 range under Schema; 2) Test looser schema (any JSON with "name" key) vs. strict `@say{...}` format; 3) Vary M ∈ {6, 12, 24, 48} to identify where schema benefits degrade

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does response consistency enforced by schemas limit performance on tasks requiring flexible or creative communication?
- Basis: Authors state testing whether schema consistency may limit broader tasks is a key direction
- Why unresolved: Study only examines naming games where constrained output formats are beneficial
- What evidence would resolve it: Experiments applying schema-induced communication to open-ended tasks (creative writing, brainstorming) comparing output diversity and quality

### Open Question 2
- Question: How does schema-induced convention formation scale to populations beyond 24 agents?
- Basis: Future work includes studies of larger populations and varied lexicon sizes
- Why unresolved: Experiments limited to N ∈ {12, 24} agents
- What evidence would resolve it: Experiments with populations of 50, 100, or 500 agents measuring agreement, convergence time, and token efficiency scaling curves

### Open Question 3
- Question: Can schema-based coordination mechanisms transfer to complex collaborative tasks such as distributed planning or collaborative coding?
- Basis: Abstract states results point toward broader applications beyond naming game; introduction mentions collaborative coding and planning as target domains
- Why unresolved: Naming games involve simple lexical agreement; whether structured priors similarly improve coordination in multi-step, hierarchical tasks is untested
- What evidence would resolve it: Multi-agent experiments on collaborative tasks (code generation, task decomposition) comparing schema-constrained vs. unconstrained communication

## Limitations
- Specific prompt templates and exact extraction/decoding logic for NL and NL-SW conditions are not fully specified, making exact reproduction challenging
- Results limited to naming games with fixed lexicons (M=12) and relatively small populations (N≤24); scaling behavior beyond these parameters is unknown
- Study does not explore whether agents might learn to "game" the schema format or whether schema compliance could be gamed through adversarial generation strategies

## Confidence
- **High Confidence**: Schema-induced communication achieves substantially higher population agreement (0.61-0.64) compared to unconstrained natural language (0.11-0.33) under tested conditions
- **Medium Confidence**: Order-of-magnitude token efficiency improvement for schema conditions holds across different model families and mixed populations, though exact mechanism remains somewhat speculative
- **Low Confidence**: Claims about minimal structural priors as a "simple control knob" for multi-agent coordination would require testing across diverse coordination tasks beyond naming games

## Next Checks
1. **Syntax Sensitivity Test**: Systematically vary schema format (different JSON structures, natural language templates) to identify which elements are critical for observed benefits
2. **Lexicon Scaling Experiment**: Extend experiments to lexicons of size M ∈ {6, 24, 48, 96} to determine where schema benefits begin to degrade
3. **Adversarial Compliance Test**: Introduce small fraction of "malicious" agents that generate plausible but incorrect schema-compliant messages to test robustness to targeted misinformation