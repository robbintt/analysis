---
ver: rpa2
title: In-Context Learning for Seismic Data Processing
arxiv_id: '2512.11575'
source_url: https://arxiv.org/abs/2512.11575
tags:
- data
- seismic
- learning
- contextseisnet
- processing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ContextSeisNet, an in-context learning approach
  for seismic demultiple processing that addresses the challenge of spatially inconsistent
  results across neighboring seismic gathers. The method conditions predictions on
  a support set of spatially related example pairs from neighboring CDP gathers and
  their corresponding labels, enabling task-specific processing behavior at inference
  time without retraining.
---

# In-Context Learning for Seismic Data Processing

## Quick Facts
- **arXiv ID:** 2512.11575
- **Source URL:** https://arxiv.org/abs/2512.11575
- **Reference count:** 33
- **Primary result:** ContextSeisNet achieves superior lateral consistency in seismic demultiple processing using in-context learning with 90% less training data than U-Net baselines.

## Executive Summary
ContextSeisNet introduces an in-context learning approach for seismic demultiple processing that addresses the challenge of spatially inconsistent results across neighboring seismic gathers. The method conditions predictions on a support set of spatially related example pairs from neighboring CDP gathers, enabling task-specific processing behavior at inference time without retraining. By leveraging CrossBlocks to perform cross-convolutions between query images and support examples, the model exploits spatial correlations among neighboring gathers while maintaining data efficiency.

## Method Summary
ContextSeisNet implements in-context learning for seismic demultiple processing by conditioning predictions on spatially related support sets from neighboring CDP gathers. The approach uses CrossBlocks to perform cross-convolutions between query seismic gathers and support examples, enabling the model to learn spatial correlations without retraining. This design allows the network to achieve superior lateral consistency compared to traditional methods while requiring significantly less training data. The flexible prompting strategy integrates traditional processing methods with deep learning capabilities, providing user control over outputs.

## Key Results
- Achieves superior lateral consistency compared to both traditional Radon demultiple and U-Net baselines on field data
- Delivers improved near-offset performance and more complete multiple removal
- Demonstrates 90% reduction in training data requirements while maintaining comparable field data performance

## Why This Works (Mechanism)
The mechanism works by conditioning predictions on spatially related support sets from neighboring CDP gathers, allowing the model to exploit local spatial correlations that traditional methods miss. The CrossBlocks architecture performs cross-convolutions between query images and support examples, effectively transferring contextual information from known good examples to the target gather. This in-context learning approach enables task-specific behavior at inference time without retraining, addressing the fundamental challenge of spatially inconsistent processing results across seismic surveys.

## Foundational Learning
- **Seismic demultiple processing**: Essential for removing unwanted reflections in seismic data; needed because multiples obscure primary reflections and degrade imaging quality; quick check: verify multiple removal effectiveness on synthetic data with known multiples.
- **CDP gathers and spatial consistency**: Common Depth Point gathers represent seismic data from same subsurface point; needed because spatial correlation between neighboring gathers enables transfer learning; quick check: measure correlation coefficients between adjacent CDP gathers.
- **In-context learning**: Few-shot learning paradigm using support sets for conditioning; needed to avoid retraining while adapting to local conditions; quick check: test performance with varying support set sizes.
- **Cross-convolution operations**: Mathematical framework for combining query and support examples; needed to propagate spatial information between gathers; quick check: validate cross-convolution implementation on synthetic paired data.
- **Radon transform demultiple**: Traditional frequency-wavenumber filtering method; needed as baseline comparison for demonstrating improvements; quick check: compare multiple attenuation results on same dataset.

## Architecture Onboarding

**Component Map:** Seismic gather -> CrossBlocks (query + support set) -> Conditioned prediction -> Multiple removal output

**Critical Path:** Query gather input → CrossBlock processing with support examples → Feature fusion → Final prediction output

**Design Tradeoffs:** The cross-convolution approach trades increased inference-time computation for improved spatial consistency and reduced training data requirements. Larger support sets improve consistency but increase computational overhead linearly.

**Failure Signatures:** Poor lateral consistency when support sets contain mismatched geological conditions; degraded performance with noisy support examples; computational bottlenecks with excessive support set sizes.

**First Experiments:**
1. Validate cross-convolution operation on synthetic paired data with known spatial relationships
2. Test performance sensitivity to support set size and composition on a single CDP gather
3. Compare inference time and memory usage against standard U-Net with varying support set configurations

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Generalizability to different geological settings beyond Gulf of Mexico remains unproven
- Computational overhead of cross-convolution operations during inference not quantified
- Long-term stability across extended seismic surveys has not been demonstrated

## Confidence

| Claim | Confidence |
|-------|------------|
| Superior lateral consistency vs U-Net baselines | High |
| 90% data efficiency gains while maintaining performance | Medium |
| Flexible prompting provides meaningful user control | Low |

## Next Checks
1. Test ContextSeisNet on seismic datasets from different geological basins (e.g., North Sea, West Africa) to assess cross-domain generalization capabilities.
2. Conduct ablation studies comparing inference time and memory requirements between ContextSeisNet and standard U-Net implementations across varying support set sizes.
3. Evaluate prediction stability by analyzing spatial consistency metrics across extended 2D seismic lines spanning tens of kilometers with varying acquisition parameters.