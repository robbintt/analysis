---
ver: rpa2
title: Efficient Knowledge Graph Unlearning with Zeroth-order Information
arxiv_id: '2508.14013'
source_url: https://arxiv.org/abs/2508.14013
tags:
- unlearning
- graph
- data
- information
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an efficient method for removing sensitive
  data from knowledge graphs while maintaining model performance. The key innovation
  is approximating influence functions using Fisher information matrices and zeroth-order
  optimization, eliminating the need for computationally expensive gradient and Hessian
  calculations.
---

# Efficient Knowledge Graph Unlearning with Zeroth-order Information

## Quick Facts
- **arXiv ID:** 2508.14013
- **Source URL:** https://arxiv.org/abs/2508.14013
- **Reference count:** 40
- **Primary result:** Achieves up to 90% reduction in runtime and memory usage for KG unlearning while maintaining competitive model performance.

## Executive Summary
This paper presents ZeroFisher, an efficient method for removing sensitive data from knowledge graph embeddings without full retraining. The approach leverages Fisher information matrices and zeroth-order optimization to approximate influence functions, dramatically reducing computational overhead. Experiments on FB15K237 and YAGO3 datasets demonstrate that ZeroFisher outperforms state-of-the-art graph unlearning techniques in both efficiency and effectiveness across triplet, entity, and relation unlearning tasks.

## Method Summary
ZeroFisher approximates influence functions using Fisher Information Matrices (FIM) and zeroth-order optimization to bypass expensive gradient and Hessian calculations. The method extracts a K-hop neighborhood around deleted entities/relations, estimates gradients using finite differences (two forward passes), and computes inverse-Hessian vector products using the Woodbury matrix identity. This enables efficient parameter updates without constructing computational graphs, achieving 90% runtime and memory reductions compared to baselines while maintaining unlearning quality on FB15K237 and YAGO3 datasets.

## Key Results
- Reduces runtime by up to 90% compared to retraining baselines
- Achieves 25% lower GPU memory usage than state-of-the-art methods
- Maintains competitive MRR and Hit@10 scores on link prediction tasks
- Outperforms GIF and KGIF baselines in both efficiency and effectiveness

## Why This Works (Mechanism)

### Mechanism 1
The inverse Hessian-vector product (IHVP) required for influence estimation is approximated using the Fisher Information Matrix (FIM) without expensive second-order derivatives. By leveraging the observation that for probabilistic models, the empirical Fisher matrix is equivalent to the Hessian of the loss, and combining this with the Woodbury matrix identity to decompose the large Hessian into a diagonal term plus a low-rank term ($H \approx vv^\top + \gamma I$), the method solves $H^{-1}v$ analytically in $O(n)$ rather than $O(n^3)$. This relies on the assumption that the loss function is smooth and the model's conditional distribution matches the training data distribution sufficiently for the Fisher-Hessian equivalence to hold.

### Mechanism 2
First-order gradients are approximated using zeroth-order information (function evaluations) to bypass the memory overhead of backpropagation on large graphs. Instead of computing $\nabla L(\theta)$ via automatic differentiation, the method uses a central difference approximation: $v \approx \frac{L(\theta+\epsilon) - L(\theta-\epsilon)}{2\epsilon}$. This requires only two forward passes to estimate the gradient direction for the influence function, avoiding the construction of the computational graph. The perturbation $\epsilon$ must be small enough to ignore higher-order terms in the Taylor expansion, yet large enough to avoid numerical underflow.

### Mechanism 3
Unlearning is restricted to a K-hop neighborhood around the deleted triplet to maintain scalability. The method assumes that the influence of a deleted triplet decays rapidly with graph distance, restricting parameter updates to entities and relations within the K-hop regime of the deletion request while treating the rest of the graph as static. This assumes knowledge graph dependencies are local and long-range semantic dependencies are negligible for the purpose of immediate unlearning.

## Foundational Learning

- **Concept**: **Knowledge Graph Embeddings (KGE)**
  - **Why needed here**: The paper targets unlearning in embedding models (TransH, RotatE) rather than raw databases. Understanding how entities and relations are mapped to vectors is essential to interpret how parameter changes affect "forgotten" knowledge.
  - **Quick check question**: Given a triplet $(h, r, t)$, does the unlearning algorithm modify the raw graph topology or the vector representations of $h$, $r$, and $t$?

- **Concept**: **Influence Functions**
  - **Why needed here**: This is the theoretical basis of the paper. Instead of retraining, influence functions measure how much model parameters would shift if a data point were removed. Understanding this helps explain why approximating $H^{-1}$ is critical.
  - **Quick check question**: Why is calculating the exact inverse Hessian $H^{-1}$ computationally prohibitive for large KG models?

- **Concept**: **Zeroth-Order Optimization**
  - **Why needed here**: This is the engine of efficiency. Understanding that the model is updated using only "forward passes" (loss scores) rather than gradients is key to grasping the memory savings.
  - **Quick check question**: How does the central difference method approximate a gradient using only the loss values $L(\theta+\epsilon)$ and $L(\theta-\epsilon)$?

## Architecture Onboarding

- **Component map**: Input Layer (Unlearning request + K-hop Subgraph extraction) -> Gradient Estimator (Zeroth-order module computing finite differences) -> Curvature Estimator (Fisher Information Matrix module approximating Hessian inverse) -> Updater (Parameter adjustment step using estimated influence vector)

- **Critical path**: The sequence from K-hop extraction $\to$ Zeroth-order Gradient Calculation $\to$ Fisher IHVP computation. The efficiency gain relies on never entering the standard Autograd backpropagation path.

- **Design tradeoffs**:
  - **Memory vs. Accuracy**: The damping term $\gamma$ and noise term $\epsilon$ control the stability of the approximation. Lower $\epsilon$ improves gradient accuracy but risks numerical instability; higher $\gamma$ stabilizes updates but may underestimate the true influence.
  - **Locality vs. Completeness**: A smaller K-hop value increases speed but risks "over-unlearning" or missing structural corrections in distant nodes.

- **Failure signatures**:
  - **Performance Collapse**: MRR/Hit@10 drops significantly below the "Retrain" baseline, indicating the approximation error accumulated or the K-hop regime was too small.
  - **OOM (Out of Memory)**: If K-hop is set too large or the embedding dimension is high, constructing the perturbed embeddings for the finite difference might still exceed memory.
  - **Oscillation**: Loss or accuracy fluctuates wildly if the damping term $\gamma$ is too low or the noise $\epsilon$ is too high.

- **First 3 experiments**:
  1. **Triplet Unlearning Sanity Check**: Delete 5% of triplets from FB15K237 using TransE. Compare runtime and MRR against the "Retrain" baseline to verify efficiency vs. quality.
  2. **Memory Profiling (Ablation)**: Run ZeroFisher vs. GIF vs. KGIF on YAGO3. Monitor GPU memory usage specifically during the IHVP calculation step to validate the memory reduction claims.
  3. **Hyperparameter Sensitivity**: Vary the damping term $\gamma$ (e.g., 1.00 vs 1.04) and plot the Hit@10 convergence over iterations to identify the stable operating region.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the completeness of machine unlearning be verified beyond standard performance metrics, given the unreliability of current inference attacks? The authors note there is currently no strong evaluation metric in machine unlearning and that Member Inference Attacks barely outperform random guessing for most settings.

- **Open Question 2**: To what extent does the accuracy of the zeroth-order approximation degrade when deleting large batches of data where the Taylor expansion assumptions are violated? While empirically successful, the paper does not provide a theoretical error bound for the approximation when the "small perturbation" assumption is violated by large-scale deletions.

- **Open Question 3**: Can optimal transport or distribution alignment be integrated into this framework to provide better theoretical guarantees for unlearning? The authors suggest introducing distribution alignment or optimal transport into machine unlearning could yield broader conclusions across KGs.

## Limitations
- The Fisher-Hessian equivalence assumption may not hold for highly non-convex loss landscapes
- Zeroth-order gradient approximation accuracy degrades with high-dimensional embedding spaces
- K-hop locality assumption may fail for densely connected knowledge graphs with critical long-range dependencies

## Confidence
- **High Confidence**: Runtime and memory efficiency claims are well-supported by experimental design and Figure 2
- **Medium Confidence**: Unlearning quality metrics show competitive performance but evaluated on only two datasets
- **Low Confidence**: Method's behavior under extreme conditions (very large K-hop requests, highly non-convex loss surfaces, or graphs with complex hub structures) is not characterized

## Next Checks
1. **Stress Test K-hop Locality**: Systematically vary K from 1 to 5 hops and measure unlearning quality degradation on a graph with known long-range dependencies to verify the proposed K value maintains both efficiency and completeness.

2. **Validate Fisher-Hessian Equivalence**: On a synthetic KG with controlled non-convexity, compare the empirical Fisher matrix to the true Hessian to measure approximation error and correlate it with unlearning performance degradation.

3. **Scale to Larger KGs**: Apply ZeroFisher to a larger KG (e.g., Wikidata or Freebase) and measure runtime/memory scaling to verify that O(n) complexity holds and identify the maximum KG size where the method remains practical compared to retraining baselines.