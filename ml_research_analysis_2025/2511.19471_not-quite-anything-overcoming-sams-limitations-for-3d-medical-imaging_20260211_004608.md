---
ver: rpa2
title: 'Not Quite Anything: Overcoming SAMs Limitations for 3D Medical Imaging'
arxiv_id: '2511.19471'
source_url: https://arxiv.org/abs/2511.19471
tags:
- segmentation
- u-net
- foundation
- volume
- sam-2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Foundation segmentation models like SAM and SAM-2 perform poorly
  on brain MRIs due to low contrast and lack of sharp boundaries in structures like
  the caudate and thalamus. Instead of fine-tuning these models, the authors propose
  treating the foundation model's output as an additional input channel alongside
  the MRI to highlight regions of interest.
---

# Not Quite Anything: Overcoming SAMs Limitations for 3D Medical Imaging

## Quick Facts
- arXiv ID: 2511.19471
- Source URL: https://arxiv.org/abs/2511.19471
- Authors: Keith Moore
- Reference count: 20
- One-line primary result: Achieves ~96% volume accuracy on basal ganglia segmentation by treating foundation model outputs as synthetic imaging channels

## Executive Summary
Foundation segmentation models like SAM and SAM-2 perform poorly on brain MRIs due to low contrast and lack of sharp boundaries in structures like the caudate and thalamus. Instead of fine-tuning these models, the authors propose treating the foundation model's output as an additional input channel alongside the MRI to highlight regions of interest. They generate SAM-2 prompts using a lightweight 3D U-Net trained on MRI segmentation, though the U-Net's guesses are often imprecise but usually in the correct region. The edges of the foundation model guesses are smoothed using a signed distance map to improve alignment with the MRI. This compositional approach avoids modifying foundation weights and adapts to domain shift without retraining. The method achieves approximately 96% volume accuracy on basal ganglia segmentation, which is sufficient for studying longitudinal volume changes. The approach is faster, more label-efficient, and robust to out-of-distribution scans compared to traditional methods.

## Method Summary
The method treats foundation model outputs (SAM-2 or DINO) as synthetic imaging modalities rather than final predictions. A lightweight 3D U-Net generates prompts (bounding boxes and 5 points per slice) from MRI data. These prompts are passed to a frozen foundation model, producing segmentation masks that are processed with signed distance maps (10-voxel sigmoid blur) to create soft boundary representations. The original T1 MRI and processed foundation guess are stacked as dual-channel input for a student 3D U-Net (~3M params) that learns to integrate both signals. Training uses dynamic loss that shifts from DICE to boundary loss during optimization. The approach requires only ~100 labeled MRIs for training and avoids modifying foundation model weights.

## Key Results
- Achieves 0.96 volume accuracy on basal ganglia segmentation using SAM-2 + signed distance maps
- Foundation model outputs function as synthetic imaging channels, improving volume alignment
- Method is robust to distribution shift, though performance degrades from 0.96 to 0.82 on pediatric ABCD dataset
- Label efficiency demonstrated with <30 minutes training on 100 MRIs
- Signed distance map with 10-voxel blur significantly improves results over raw masks

## Why This Works (Mechanism)

### Mechanism 1
Treating foundation model outputs as synthetic imaging modalities enables domain adaptation without weight modification. SAM-2's imprecise segmentation masks function like T2 or FLAIR sequences—providing coarse spatial priors that a 3D U-Net learns to integrate with raw MRI. The student model learns correlations between the noisy "attention signal" and true boundaries. Core assumption: foundation model errors are systematic rather than random—it must localize the correct region even if boundaries are wrong. Evidence: foundation model output is treated as an additional input channel and passed alongside the MRI to highlight regions of interest. Break condition: if foundation model outputs are spatially uncorrelated with target structures (random noise), the student cannot learn useful mappings.

### Mechanism 2
Signed distance maps with localized edge blur improve volumetric alignment by providing consistent gradient signals at boundaries. Converting binary masks to distance-based representations with sigmoid falloff (10-voxel band) creates soft gradients at boundaries. Combined with dynamic loss (DICE → boundary), this guides optimization toward volumetric accuracy even with imprecise edges. Core assumption: volume accuracy matters more than pixel-perfect boundaries for downstream clinical tasks. Evidence: Restricting the blur to a 10-voxel band around the boundary yielded substantially better results. Break condition: if clinical application requires precise boundary localization (e.g., surgical planning), SDM may mask edge errors that matter.

### Mechanism 3
Imprecise prompts from prior models remain effective because the student U-Net learns spatial correlations across slices rather than relying on single-slice accuracy. The prompt generator U-Net provides bounding boxes and point prompts that need only be "in the right region." The 3D student reconstructs correct structures by integrating 3D spatial context with the foundation's coarse localization. Core assumption: target structures have consistent 3D morphology that the student can learn from training data. Evidence: As long as the foundation model's output overlapped the general region, the 3D U-Net learned the correct structure. Break condition: if prompt generator consistently misses the target region entirely, foundation model outputs become irrelevant.

## Foundational Learning

- **Concept: Multi-channel medical imaging (T1, T2, FLAIR)**
  - Why needed here: The paper's core insight relies on understanding that radiologists use multiple acquisition sequences as channels to resolve ambiguity. Without this, the "synthetic modality" framing won't make sense.
  - Quick check question: Can you explain why T1 and T2 images of the same brain look different, and why both are clinically useful?

- **Concept: U-Net encoder-decoder architecture with skip connections**
  - Why needed here: The student model is a 3D U-Net. Understanding how skip connections preserve spatial information while decoder upsamples is essential for debugging segmentation failures.
  - Quick check question: Draw a U-Net architecture and explain what information flows through skip connections vs. the bottleneck.

- **Concept: Signed distance functions for boundary representation**
  - Why needed here: The SDM post-processing is critical to the method's success. Understanding how distance transforms represent shape boundaries differently than binary masks is required for implementation.
  - Quick check question: Given a binary mask, how would you compute the signed distance at a pixel inside vs. outside the mask?

## Architecture Onboarding

- **Component map:**
  - Prompt Generator: Prior 3D U-Net → outputs bounding boxes + 5 points/slice
  - Foundation Model: Frozen SAM-2/MedSAM/DINO → outputs 2D segmentation masks
  - Post-processor: Contour selection + SDM with 10-voxel sigmoid blur
  - Volume Reconstructor: Stacks 2D masks → 3D NiFTI volume
  - Student Model: Lightweight 3D U-Net (~3M params) → final segmentation
  - Data Augmentation: MONAI transforms (RandomGamma, GaussianNoise, affine)

- **Critical path:**
  1. Train prompt generator on labeled MRIs (can be different dataset)
  2. Generate prompts → run foundation inference → collect masks
  3. Apply SDM post-processing to masks
  4. Stack T1 + processed mask as dual-channel input
  5. Train student 3D U-Net with dynamic loss (DICE → boundary)

- **Design tradeoffs:**
  - SDM blur width: Broader = smoother gradients but misaligned with DICE; paper found 10-voxel band optimal
  - Foundation model choice: SAM-2 best results; DINO offers prompt-free but lower accuracy (Vol Acc 0.65 vs 0.96)
  - Training data: Method tolerates distribution shift (BRATS → ABCD) but requires some labeled anchors

- **Failure signatures:**
  - Low volume accuracy (<85%): Check prompt generator is localizing correct region; may need retraining
  - High DICE but low Vol Acc: SDM parameters may be wrong; verify 10-voxel band implementation
  - Edge errors >2 pixels consistently: Expected for low-contrast structures; may need edge-weighted loss
  - Training divergence: Verify dynamic loss transition (σ(loss₁ - 0.5) weighting) is implemented correctly

- **First 3 experiments:**
  1. Baseline replication: Train 3D U-Net on T1+T2 (without foundation input) to establish volume accuracy baseline on your dataset
  2. Foundation channel ablation: Compare T1+SAM-2-guess vs. T1+zeros to isolate contribution of synthetic modality
  3. SDM parameter sweep: Test blur widths (5, 10, 20 voxels) to validate 10-voxel finding on your target structures

## Open Questions the Paper Calls Out

### Open Question 1
Does the compositional "has-a" adaptation strategy generalize effectively to anatomical structures or imaging modalities beyond basal ganglia segmentation? Basis in paper: The conclusion states, "Whether this generalizes remains open." Why unresolved: The experiments were restricted to subcortical structures in BRATS21 and ABCD datasets. What evidence would resolve it: Application of the architecture to diverse segmentation tasks (e.g., abdomen or lung) with similar efficiency.

### Open Question 2
Can prompt-free DINO attention be optimized to match prompt-based performance via specific loss function or learning rate adjustments? Basis in paper: Appendix A.4 notes DINO results could improve with "a stronger focus in the loss function," identifying this as a "next step." Why unresolved: The authors observed promising results but did not conduct the specific tuning experiments. What evidence would resolve it: Ablation studies on loss weighting and learning rates specifically for the DINO channel inputs.

### Open Question 3
Can edge precision be significantly improved without sacrificing the volume accuracy or label-efficiency of the student model? Basis in paper: Section 5.2 notes "Edge Uncertainty Remains" and suggests improvement requires "higher weighting on edge losses," implying a trade-off not yet explored. Why unresolved: The current Signed Distance Map (SDM) approach prioritized volume alignment over precise edge localization. What evidence would resolve it: Experiments using boundary-weighted losses to evaluate the trade-off between edge precision and volume metrics.

## Limitations

- Architectural specifics remain underspecified (exact U-Net configurations, filter counts, padding strategy)
- Prompt generation methodology lacks precision in point sampling criteria and jitter parameters
- Distribution shift handling is incompletely validated with substantial performance degradation on pediatric dataset
- Label efficiency claims lack quantitative comparison with fine-tuning baselines

## Confidence

**High Confidence:** The compositional approach and signed distance map smoothing mechanism are well-supported by experimental results. The 96% volume accuracy claim on BRATS21 is internally consistent.

**Medium Confidence:** The generalization claims across distribution shifts are plausible but not thoroughly validated. The assertion that this approach is "more label-efficient" lacks quantitative comparison with fine-tuning baselines.

**Low Confidence:** The exact implementation details for prompt generation and U-Net architecture are insufficient for direct reproduction without significant engineering effort.

## Next Checks

1. **Prompt sampling sensitivity analysis:** Systematically vary the point sampling strategy (number of points, foreground/background ratio, jitter magnitude) to quantify impact on final segmentation accuracy.

2. **Cross-domain robustness test:** Evaluate the method on a held-out domain-shifted dataset (different age groups, pathology types, or imaging protocols) with and without limited fine-tuning to assess true generalization capability.

3. **Architectural ablation study:** Test alternative student model architectures (UNETR, Swin-UNETR, standard 3D U-Net with different depths) while keeping the compositional framework constant to isolate architectural contribution from the methodological innovation.