---
ver: rpa2
title: Rapid Overfitting of Multi-Pass Stochastic Gradient Descent in Stochastic Convex
  Optimization
arxiv_id: '2505.08306'
source_url: https://arxiv.org/abs/2505.08306
tags:
- will
- lemma
- epoch
- such
- oracle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We study the out-of-sample performance of multi-pass stochastic\
  \ gradient descent (SGD) in stochastic convex optimization (SCO). While one-pass\
  \ SGD achieves the optimal \u0398(1/\u221An) excess population loss, we show that\
  \ in the non-smooth case, just one additional pass with the standard step size \u03B7\
  \ = \u0398(1/\u221An) can lead to population loss as large as \u03A9(1)."
---

# Rapid Overfitting of Multi-Pass Stochastic Gradient Descent in Stochastic Convex Optimization

## Quick Facts
- **arXiv ID:** 2505.08306
- **Source URL:** https://arxiv.org/abs/2505.08306
- **Reference count:** 40
- **Primary result:** Multi-pass SGD overfits rapidly after the first epoch, achieving population loss Ω(1) in the non-smooth case.

## Executive Summary
This paper studies the out-of-sample performance of multi-pass stochastic gradient descent (SGD) in stochastic convex optimization (SCO). While one-pass SGD achieves the optimal Θ(1/√n) excess population loss, the authors demonstrate a sharp phase transition: just one additional pass with the standard step size η = Θ(1/√n) can lead to population loss as large as Ω(1). More generally, for T total steps, the population loss from the second pass onward is of order Θ(1/(ηT) + η√T), revealing a fundamental trade-off between optimization and generalization. This rapid overfitting occurs across different multi-pass schemes including without-replacement and with-replacement sampling.

## Method Summary
The paper establishes lower bounds on the population risk of multi-pass SGD through a sample-dependent oracle construction. The method involves creating a distribution over data subsets where a carefully designed oracle can remain inactive during the first epoch (achieving zero regret) but then guide the iterates toward a "bad" empirical risk minimizer after the first pass. The analysis considers non-smooth convex loss functions with bounded domains and uses suffix averaging for output. The reduction from the oracle to the standard SGD setting shows this overfitting phenomenon is fundamental to the multi-pass setting, not an artifact of the construction.

## Key Results
- One-pass SGD with η = Θ(1/√n) achieves optimal excess population loss Θ(1/√n)
- Multi-pass SGD (K≥2) with the same step size suffers population loss Ω(1)
- From the second pass onward, population loss is Θ(1/(ηT) + η√T), revealing a trade-off between optimization and generalization
- Lower bound on empirical risk (generalization gap) is Ω(η√n) for one-pass SGD in high dimension
- The overfitting occurs for without-replacement, with-replacement, and arbitrary multi-pass schemes

## Why This Works (Mechanism)

### Mechanism 1: Phase Transition in Generalization
The paper establishes that one-pass SGD achieves optimal generalization through online-to-batch arguments that rely on independent samples at each iteration. However, this guarantee collapses once an example is seen more than once. After the first epoch, the population excess risk is governed by a different term, Θ(1/(ηT) + η√T), which can be as large as Ω(1) with the canonical step size. This reveals a fundamental shift in the theoretical tools needed to explain performance: generalization bounds based on stability become tight after the second pass, while the optimal performance in the first pass is only explained by online-to-batch arguments which collapse immediately after the first pass.

### Mechanism 2: Memorization and Convergence to Bad Minimizers
The rapid overfitting is driven by the algorithm's ability to memorize the training set and converge to a "bad" empirical risk minimizer. The proof technique constructs a sample-dependent oracle that provides no useful gradient information during the first epoch, keeping iterates at the initial point. After seeing the entire training set, the oracle uses the memorized data to identify a specific "bad" vector u₀ that is an empirical risk minimizer but has high population risk. From the second epoch onward, the oracle provides gradients that guide SGD iterates toward this u₀. This demonstrates that once the training set is memorized, subsequent gradient steps can be steered towards an overfitting solution, revealing a fundamental issue with multi-pass SGD in overparameterized regimes.

### Mechanism 3: Optimization-Generalization Trade-off
The derived asymptotic bound Θ(1/(ηT) + η√T) quantifies the fundamental trade-off between optimization and generalization error from the second epoch onward. The first term, 1/(ηT), represents the optimization error which decreases with more steps and larger step size. The second term, η√T, represents the generalization error which increases with both step size and number of steps. This formula reveals that after the first pass, practitioners must choose a step size that balances faster convergence with slower increase in overfitting. This trade-off is captured by stability arguments and optimization guarantees for suffix-averaged iterates.

## Foundational Learning

- **Concept: Stochastic Convex Optimization (SCO)**
  - Why needed here: SCO is the fundamental framework defining the problem setting: minimizing a convex, Lipschitz loss function over a bounded convex domain using samples from a distribution. The paper's main contributions are formalized as bounds on the population excess risk within this model.
  - Quick check question: Can you explain the goal of a learning algorithm in the SCO framework? (Answer: To minimize the population loss F(w) = E_z~Z[f(w,z)] based on a finite sample, where f is convex and Lipschitz).

- **Concept: Generalization Gap and Population vs. Empirical Risk**
  - Why needed here: The paper's central finding is a sharp distinction between the first and later epochs of multi-pass SGD. This distinction is measured by the difference between empirical risk (performance on training data) and population risk (expected performance on new data). The rapid overfitting observed is precisely the divergence of these two quantities.
  - Quick check question: If a model achieves zero training error (empirical risk), does it guarantee good performance on new data? Why or why not? (Answer: No. If the model "memorizes" the training data, the generalization gap becomes large, meaning the population risk remains high).

- **Concept: Online-to-Batch Conversion / Stochastic Approximation**
  - Why needed here: This is the primary theoretical tool used to explain why one-pass SGD achieves optimal generalization. The paper highlights that this approach, which relies on regret analysis with independent samples, effectively "collapses" once an example is seen more than once (in a second epoch). Understanding this is key to grasping the paper's core insight.
  - Quick check question: What is the key assumption for online-to-batch analysis that is violated when running multiple epochs? (Answer: The assumption that at each iteration t, the algorithm receives an independent sample from the data distribution).

## Architecture Onboarding

- **Component map:**
  SGD Process -> Data Selection Scheme -> Oracle -> Output Averaging
  (where SGD Process is the iterative update rule, Data Selection Scheme dictates which sample is used at each step, Oracle provides sub-gradients, and Output Averaging produces the final model)

- **Critical path:**
  1. Initialize: Start with initial parameter vector w₀ (usually zero)
  2. First Pass (Epoch 1): Iterate through training set once, achieving optimal generalization via stochastic approximation
  3. Transition: First pass completes; algorithm has "touched" and potentially "memorized" entire training set
  4. Second Pass Onwards (Epoch 2+): Continue iterating on same data; first-pass guarantees no longer apply; iterates can be driven toward solution that minimizes empirical risk but has high population risk

- **Design tradeoffs:**
  - One-Pass vs. Multi-Pass: One-pass SGD gives provably optimal generalization but uses each sample once; multi-pass SGD enables further empirical risk minimization but introduces rapid overfitting
  - Step-Size (η) vs. Epochs (K): The bound Θ(1/(ηT) + η√T) shows a trade-off where smaller η reduces generalization error but slows convergence
  - Without vs. With-Replacement: Without-replacement sampling (reshuffling) is standard in practice; the paper shows both schemes exhibit same asymptotic lower bounds after one epoch

- **Failure signatures:**
  - "Phase Transition": Sudden degradation in out-of-sample performance after first epoch, potentially to Ω(1) loss with standard step size
  - "Memorization" without Generalization: Algorithm minimizes training loss but fails to improve or worsens performance on unseen data
  - Stability Bound Vacuousness: Generalization bounds based on algorithmic stability become non-informative for large step sizes and multiple epochs needed for optimization

- **First 3 experiments:**
  1. Replicate the Phase Transition: Implement multi-pass SGD on non-smooth convex problem with n samples, run for K=2 epochs with step size η = c/√n, plot population risk after each epoch to observe transition from Θ(1/√n) to Ω(1)
  2. Impact of Step-Size: Using same setup, run for multiple passes with varying step sizes η ∈ {1/√n, 1/n, 1/n^1.5}, compare final population risk to validate trade-off in Θ(1/(ηT) + η√T) bound
  3. Empirical vs. Population Risk Divergence: Extend first experiment by plotting both empirical training risk and population risk over multiple epochs to demonstrate "memorization" where training risk decreases while population risk diverges

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can tight population risk bounds be established for multi-pass SGD in the smooth stochastic convex optimization setting?
- **Basis in paper:** [explicit] Section 1.2 states "Establishing population risk bound for multi-pass SGD in the analogous smooth setting remains an interesting open question that is likely to require significantly different techniques than those used in the non-smooth case."
- **Why unresolved:** Current lower bound constructions and analysis techniques rely heavily on non-smoothness and do not trivially extend to smooth cases.
- **What evidence would resolve it:** A formal proof of lower bounds for the smooth case, or an upper bound demonstrating different generalization rate compared to non-smooth case.

### Open Question 2
- **Question:** Does rapid overfitting occur in settings where uniform convergence holds, such as with low-norm linear predictors?
- **Basis in paper:** [explicit] Section 1.2 asks "...it is an interesting question whether our results could be reproduced in settings where uniform convergence holds (e.g., low-norm linear predictors with a Lipschitz loss), and the generalization gap is necessarily small."
- **Why unresolved:** Paper's construction leverages large generalization gap; unclear if overfitting mechanism persists when generalization gap is inherently small.
- **What evidence would resolve it:** Derivation of paper's lower bounds within framework enforcing uniform convergence, or proof showing small generalization gaps mitigate specific overfitting phenomenon.

### Open Question 3
- **Question:** What is the precise rate of overfitting development during the second pass of SGD?
- **Basis in paper:** [explicit] Section 1.2 highlights need "to precisely characterize the rate at which overfitting develops during the second pass," noting current results only become effective at end of second epoch.
- **Why unresolved:** Standard generalization bounds are vacuous at start of second pass, and standard regret analysis fails because it relies on independent samples not present in second pass.
- **What evidence would resolve it:** Refined theoretical analysis providing non-vacuous bounds on population risk for initial steps of second epoch, bridging gap between first pass and end of second epoch.

## Limitations
- The analysis critically depends on non-smoothness of loss functions; smooth case remains open
- Lower bound construction requires overparameterized regime (d = eO(n)) and is challenging to verify empirically
- Analysis assumes suffix averaging for output; behavior with other strategies may differ
- Practical implications for typical deep learning settings with smooth losses are unclear

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Separation between one-pass and multi-pass SGD performance | High |
| Derived asymptotic bound Θ(1/(ηT) + η√T) for second epoch onward | High |
| Mechanism of "memorization" leading to overfitting via oracle reduction | Medium |
| Phase transition at first epoch is robust finding | Medium |
| Practical implications for typical deep learning settings | Low |

## Next Checks

1. **Empirical Phase Transition:** Implement multi-pass SGD on non-smooth convex problem (e.g., absolute loss) and empirically verify sharp degradation in population risk after first epoch with canonical step size η = Θ(1/√n).

2. **Step-Size Trade-off Verification:** Conduct experiments varying step size η across multiple epochs to empirically validate derived trade-off captured in bound Θ(1/(ηT) + η√T), observing balance between optimization progress and overfitting.

3. **Smooth vs. Non-Smooth Comparison:** Extend empirical study to include smooth convex loss functions (e.g., squared loss) to investigate whether rapid overfitting phenomenon observed for non-smooth functions also manifests in smooth setting, or if behavior is fundamentally different.