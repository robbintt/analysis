---
ver: rpa2
title: Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models
arxiv_id: '2506.23731'
source_url: https://arxiv.org/abs/2506.23731
tags:
- image
- watermark
- images
- watermarking
- wiar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates watermark radioactivity in image generative\
  \ models, a property critical for tracking unauthorized use of generated images.\
  \ While watermarking is effective for detecting direct misuse, it fails when watermarked\
  \ images are used as training data unless the watermark persists through training\
  \ and remains detectable in outputs\u2014a property called radioactivity."
---

# Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models

## Quick Facts
- arXiv ID: 2506.23731
- Source URL: https://arxiv.org/abs/2506.23731
- Reference count: 40
- Primary result: WIAR is the first radioactive watermarking scheme for image autoregressive models, achieving 30-40% TPR@FPR=1% detection rates

## Executive Summary
This paper addresses a critical gap in watermarking technology for image generative models by developing WIAR, the first radioactive watermarking method for image autoregressive models (IARs). While existing watermarking techniques can detect direct misuse of generated images, they fail when watermarked images are used as training data unless the watermark persists through training—a property called radioactivity. The authors demonstrate that diffusion models (DMs) exhibit no radioactivity due to latent space encoding and noising-denoising processes, while IARs previously had no radioactive watermarking solutions. WIAR overcomes this by embedding watermarks into token distributions at inference time without retraining, enabling robust provenance tracking and preventing unauthorized reuse of generated images.

## Method Summary
The authors propose WIAR (Watermark for Image Autoregressive models), which adapts LLM watermarking techniques to the autoregressive paradigm of IARs. The method embeds watermarks by perturbing token distributions during inference time, specifically targeting the conditional probability predictions that IARs use to generate images token by token. Unlike previous approaches that require retraining or work only on latent spaces, WIAR operates directly on the autoregressive generation process. The watermark is embedded through subtle modifications to the probability distributions of predicted tokens, making it detectable while maintaining image quality. The method is designed to be robust against various attacks including Gaussian noise, JPEG compression, cropping, and resizing, while preserving the radioactivity property needed for effective provenance tracking through fine-tuning scenarios.

## Key Results
- WIAR achieves detection rates of 30-40% TPR@FPR=1% in IARs, significantly above random guessing (1%)
- No radioactivity observed in diffusion models (LDMs) across three evaluated methods (UI, IA, SL)
- WIAR maintains high image quality with minimal degradation (FID and IS metrics comparable to unwatermarked outputs)
- WIAR shows robustness against standard attacks including noise addition, compression, and geometric transformations
- The method does not transfer to LDMs due to fundamental differences in their training processes

## Why This Works (Mechanism)
WIAR works by embedding watermarks into the token distribution predictions of autoregressive image models during inference. The key insight is that IARs generate images by predicting one token at a time based on conditional probability distributions, which provides an opportunity to subtly modify these distributions to encode watermark information. By perturbing the probability scores of predicted tokens in a systematic way, WIAR creates a detectable pattern that persists through the autoregressive generation process. The method leverages the sequential nature of IAR generation, where each prediction depends on previous tokens, allowing the watermark to be distributed throughout the entire generation process rather than being localized to specific regions. This distribution-based approach ensures that the watermark remains detectable even after various transformations while maintaining the visual quality of generated images.

## Foundational Learning

**Autoregressive Image Generation**
- Why needed: IARs generate images token by token, making them fundamentally different from diffusion models
- Quick check: Verify understanding of how pixel/ token prediction sequences work in IARs vs. DMs

**Token Distribution Perturbation**
- Why needed: The core mechanism by which WIAR embeds watermarks without retraining
- Quick check: Confirm that watermarking occurs at probability distribution level, not raw output

**Radioactivity Property**
- Why needed: Essential for watermark persistence through training/fine-tuning cycles
- Quick check: Distinguish between basic watermark detection and radioactive watermark detection

**Detection Metrics (TPR@FPR)**
- Why needed: Standard evaluation framework for watermarking effectiveness
- Quick check: Understand why 30-40% detection is significant vs. 1% random guessing baseline

## Architecture Onboarding

**Component Map**
IAR Model -> Token Distribution Prediction -> WIAR Perturbation Module -> Watermarked Image Generation

**Critical Path**
Input prompt → Token sequence generation → Conditional probability prediction → WIAR watermark embedding → Final image output

**Design Tradeoffs**
- Inference-time embedding vs. retraining (WIAR chooses former for practicality)
- Distribution perturbation strength vs. image quality preservation
- Watermark detectability vs. robustness to attacks

**Failure Signatures**
- Loss of radioactivity in diffusion models due to latent space encoding
- Quality degradation when watermark strength is too high
- Reduced detectability under aggressive attack scenarios

**First Experiments**
1. Test WIAR on a simple IAR model with synthetic watermark patterns
2. Compare detection rates with and without WIAR under controlled attack conditions
3. Measure quality metrics (FID, IS) across different watermark strength settings

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- WIAR does not work for diffusion models due to fundamental architectural differences
- Limited evaluation of transferability to other autoregressive architectures beyond IARs
- No extensive testing against adaptive attackers who specifically target watermark removal
- Potential scalability concerns when applying to larger, more complex autoregressive models

## Confidence

**High Confidence:**
- Experimental results demonstrating WIAR's radioactivity preservation in IARs
- Clear evidence that LDMs exhibit no radioactivity across multiple methods
- Robustness results against standard attacks are well-supported

**Medium Confidence:**
- Generalization of WIAR to other autoregressive architectures
- Quality preservation claims based on FID/IS metrics
- Theoretical adaptation of LLM watermarking principles to IARs

## Next Checks
1. Test WIAR's transferability to other autoregressive architectures (e.g., transformer-based image generators)
2. Conduct ablation studies varying watermark embedding strength across different image complexity levels
3. Evaluate WIAR's performance under adaptive attacker scenarios targeting watermark removal during fine-tuning