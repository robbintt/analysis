---
ver: rpa2
title: Decomposing Direct and Indirect Biases in Linear Models under Demographic Parity
  Constraint
arxiv_id: '2511.11294'
source_url: https://arxiv.org/abs/2511.11294
tags:
- bias
- linear
- fairness
- unfairness
- mean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a post-processing framework that decomposes
  bias in linear models into direct (sensitive-attribute) and indirect (correlated-features)
  components under demographic parity constraints. The method provides closed-form
  expressions for group-conditional model coefficients and analytically characterizes
  how fairness constraints reshape them.
---

# Decomposing Direct and Indirect Biases in Linear Models under Demographic Parity Constraint

## Quick Facts
- arXiv ID: 2511.11294
- Source URL: https://arxiv.org/abs/2511.11294
- Reference count: 40
- Authors: Bertille Tierny; Arthur Charpentier; François Hu
- Primary result: Framework decomposes bias into direct (sensitive-attribute) and indirect (correlated-features) components under demographic parity constraints

## Executive Summary
This work introduces a post-processing framework that decomposes bias in linear models into direct and indirect components under demographic parity constraints. The method provides closed-form expressions for group-conditional model coefficients and analytically characterizes how fairness constraints reshape them. It enables feature-level interpretation of fairness interventions and reveals how bias persists or shifts through correlated variables. The approach requires no retraining and offers actionable insights for model auditing.

## Method Summary
The method fits any linear model to obtain base coefficients, then applies closed-form transformations to enforce demographic parity. For a given ε∈[0,1], it constructs group-conditional predictors using convex combinations of group-specific and population-wide moments. The framework decomposes total unfairness into four additive components: direct mean bias (γ²Var(S)), indirect mean bias (Var(⟨μ(S),β⟩)), interaction terms (2γCov(S,⟨μ(S),β⟩)), and structural bias from covariance differences (Var(√(β^TΣ(s)β))). This enables both fairness mitigation and interpretable auditing of bias sources.

## Key Results
- Achieves 43-74% reductions in unfairness on benchmark datasets (CRIME, LAW, GOSSIS) while maintaining acceptable predictive performance
- Framework is agnostic to fitting procedure and works with any standard linear model (OLS, Ridge, Lasso)
- Decomposes total unfairness into four distinct components enabling targeted intervention strategies
- Provides closed-form expressions for group-conditional coefficients without requiring retraining

## Why This Works (Mechanism)

### Mechanism 1: Group-Conditional Standardization with Population Moment Interpolation
- Claim: Enforcing demographic parity requires transforming predictions through within-group standardization followed by controlled re-scaling toward population averages.
- Mechanism: First standardizes each group's predictions to zero mean and unit variance using group-specific parameters (μ(s), σ(s)), then re-scales and shifts using convex combinations of group-specific and population-wide moments. The ε parameter controls interpolation: at ε=0, predictions use only global moments (exact fairness); at ε=1, predictions use only group-specific moments (maximum accuracy, no fairness constraint).
- Core assumption: Features X|S=s follow Gaussian distributions with group-specific means μ(s) and covariances Σ(s); the Bayes optimal predictor is linear.
- Evidence anchors: [Section 4.4, Proposition 5] Derives f*ε(x,s) = σ(s)ε × [⟨x-μ(s),β*⟩/σ(s)f*] + μ(s)ε where moments are convex combinations (1-√ε)×global + √ε×group-specific.
- Break condition: When feature distributions are heavily non-Gaussian or multimodal, the standardization transformation may not achieve intended distributional alignment across groups.

### Mechanism 2: Four-Component Bias Decomposition via Wasserstein Distance
- Claim: Total unfairness decomposes into additive contributions from four distinct sources, enabling targeted intervention.
- Mechanism: The Wasserstein-2 based unfairness measure U(f) decomposes into First-Moment Disparity (FMD) and Second-Moment Disparity (SMD). FMD further splits into Direct Mean (γ²Var(S)), Indirect Mean (Var(⟨μ(S),β⟩)), and Interaction (2γCov(S,⟨μ(S),β⟩)). SMD captures Indirect Structural Bias (Var(√(β^TΣ(s)β))) from group-varying covariances. This decomposition is exact under the Gaussian assumption.
- Core assumption: Linear predictor with coefficients (β, γ, β₀); features have group-conditional distributions with potentially different means and covariances.
- Evidence anchors: [Section 5.1, Proposition 6] "U(f) = γ²Var(S) + Var(⟨μ(S),β⟩) + 2γCov(S,⟨μ(S),β⟩) + Var(√(β^TΣ(s)β))"
- Break condition: When features are highly correlated across groups in complex, non-linear ways, the structural bias term's square-root nonlinearity makes additive interpretation less reliable without Taylor approximation.

### Mechanism 3: Post-Processing Coefficient Reshaping Without Retraining
- Claim: Fair linear models can be constructed by applying closed-form coefficient transformations to any pre-trained linear model, avoiding costly retraining.
- Mechanism: Given base model coefficients (β*, γ*, β₀*), the fair predictor constructs group-conditional coefficients β(s)ε = (σ(s)ε/σ(s)f*)β* and intercepts β(s)0,ε = μ(s)ε - (σ(s)ε/σ(s)f*)⟨μ(s),β*⟩. The scaling factor compensates for structural covariance differences; the intercept corrects for mean-based biases. This is applied post-hoc to any linear model (OLS, Ridge, Lasso).
- Core assumption: Access to estimated base model coefficients and ability to compute group-conditional statistics from training or holdout data.
- Evidence anchors: [Section 6] "Our framework is agnostic to the fitting procedure; any standard method, such as OLS or penalized version (Ridge, Lasso), is applicable"
- Break condition: When group-conditional statistics (μ(s), Σ(s)) cannot be reliably estimated due to small group sample sizes, coefficient adjustments become unstable.

## Foundational Learning

- Concept: **Wasserstein-2 Distance and Barycenters**
  - Why needed here: The unfairness measure U(f) is defined via Wasserstein-2 distance between group-conditional prediction distributions and their barycenter; understanding this is essential for interpreting why the decomposition works and how Strong DP differs from Weak DP.
  - Quick check question: If two distributions have the same mean but different variances, would the Wasserstein-2 distance between them be zero?

- Concept: **Demographic Parity: Weak vs. Strong**
  - Why needed here: The paper enforces Strong DP (full distribution independence), not just Weak DP (mean independence); this distinction explains why structural bias from covariance differences matters even when group means are equalized.
  - Quick check question: A model satisfies Weak DP (equal mean predictions across groups) but predictions have different variances per group. Does it satisfy Strong DP?

- Concept: **Group-Weighted R² (GWR²) vs. Global R²**
  - Why needed here: The divergence between GWR² and global R² signals structural mismatch between the model and group-level data patterns; this diagnostic is critical for auditing whether fairness interventions maintain adequate fit per group.
  - Quick check question: A model has global R² = 0.7 but GWR² = 0.5. What does this indicate about model fit across groups?

## Architecture Onboarding

- Component map:
  1. Base Model Estimator -> Group Statistics Module -> Conditional Score Moments -> Fair Predictor Assembly -> Bias Decomposition Analyzer

- Critical path:
  1. Fit base linear model → obtain (β̂, γ̂, β̂₀)
  2. Compute group-conditional statistics from training data
  3. Calculate σ̂(s)_f = √(β̂^T Σ̂(s) β̂) and μ̂(s)_f = ⟨μ̂(s),β̂⟩ + γ̂s + β̂₀
  4. For chosen ε, compute σ(s)_ε and μ(s)_ε
  5. Apply transformation: f̂_ε(x,s) = σ(s)_ε × [(⟨x-μ̂(s),β̂⟩)/σ̂(s)_f] + μ(s)_ε

- Design tradeoffs:
  - ε selection: Lower ε → more fairness, less accuracy; validated trade-off frontier shown in Figure 5
  - Gaussian assumption: Required for exact optimality; empirical robustness demonstrated on non-Gaussian real data but not guaranteed
  - Group size requirements: Small minority groups → unstable Σ̂(s) estimates → unreliable coefficient adjustments
  - Feature correlation handling: Full decomposition requires Taylor approximation when features are correlated (Section 5.2)

- Failure signatures:
  - High GWR² vs. Global R² gap: Indicates model captures group-specific structure poorly; check Appendix E, Proposition 16
  - Unfairness not decreasing with ε → 0: May indicate non-Gaussian distributions or estimation errors in group statistics
  - Coefficient adjustments explode: Check for near-singular Σ̂(s) matrices or very small σ̂(s)_f values
  - KS test remains high despite DP constraint: Suggests higher-moment disparities persist; verify Strong DP vs Weak DP distinction

- First 3 experiments:
  1. Synthetic validation with controlled bias: Generate data with known T = (T_y, T_mean, T_std, T_corr); verify decomposition correctly attributes bias sources (replicate Figure 2)
  2. ε-sweep on real benchmark: On CRIME dataset, trace risk-fairness frontier by varying ε ∈ [0,1]; compare to CS22 and FS23 baselines (Table 2 pattern)
  3. Coefficient shift analysis: On a dataset with known indirect bias, visualize how β(s)ε and β(s)0,ε differ from base coefficients; verify sensitive attribute coefficient nullification and group-specific scaling (replicate Figure 7)

## Open Questions the Paper Calls Out
None

## Limitations
- Framework's validity depends on Gaussian assumption for feature distributions, which may not hold in real-world scenarios with non-linear relationships or heavy-tailed distributions
- Small group sample sizes lead to unstable covariance matrix estimates that propagate through coefficient adjustment mechanism
- Decomposition's additive interpretation becomes approximate rather than exact when features exhibit complex correlation structures across groups
- Post-processing approach cannot recover information that was never present in the base model

## Confidence
- **High Confidence**: Post-processing mechanism (Mechanism 3) and implementation details have strong empirical support from experiments on synthetic and real-world datasets
- **Medium Confidence**: Four-component bias decomposition (Mechanism 2) is theoretically sound under Gaussian assumptions, but practical utility when assumptions are violated requires further validation
- **Medium Confidence**: Group-conditional standardization mechanism (Mechanism 1) is well-specified mathematically, but behavior on non-Gaussian or multimodal distributions remains empirically underexplored

## Next Checks
1. Validate the framework on synthetic datasets with heavy-tailed distributions (e.g., t-distribution with low degrees of freedom) and compare decomposition accuracy against the Gaussian baseline to quantify breakdown conditions
2. Systematically vary minority group sample sizes (10%, 5%, 1% of total) and measure coefficient adjustment stability and unfairness reduction effectiveness to establish minimum viable group sizes
3. Construct synthetic datasets with known non-linear feature interactions across groups and evaluate whether the decomposition still provides actionable insights or requires alternative formulations