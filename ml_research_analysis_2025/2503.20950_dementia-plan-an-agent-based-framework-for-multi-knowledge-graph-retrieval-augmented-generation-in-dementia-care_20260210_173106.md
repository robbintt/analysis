---
ver: rpa2
title: 'DEMENTIA-PLAN: An Agent-Based Framework for Multi-Knowledge Graph Retrieval-Augmented
  Generation in Dementia Care'
arxiv_id: '2503.20950'
source_url: https://arxiv.org/abs/2503.20950
tags:
- dementia
- memory
- patient
- care
- patients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DEMENTIA-PLAN is an LLM-based framework for dementia care that
  integrates multiple knowledge graphs (daily routines and life memories) with a self-reflection
  planning agent. The system generates empathetic, contextually appropriate responses
  to patient queries while continuously optimizing retrieval strategies through adaptive
  weighting and keyword expansion.
---

# DEMENTIA-PLAN: An Agent-Based Framework for Multi-Knowledge Graph Retrieval-Augmented Generation in Dementia Care

## Quick Facts
- arXiv ID: 2503.20950
- Source URL: https://arxiv.org/abs/2503.20950
- Reference count: 16
- Primary result: LLM-based dementia care system integrates daily routine and life memory graphs with a self-reflection planning agent to generate empathetic, contextually appropriate responses, achieving near-human performance in emotional resonance while maintaining high factual accuracy.

## Executive Summary
DEMENTIA-PLAN is an LLM-based framework designed to generate empathetic, factually accurate responses for dementia patients by integrating daily routine and life memory knowledge graphs through a self-reflection planning agent. The system continuously optimizes retrieval strategies via adaptive weighting and keyword expansion to improve response quality. Evaluation against gold standard responses shows significant improvements across empathy, memory support, safety, and problem-solving dimensions, with the full model achieving near-human performance in emotional resonance.

## Method Summary
DEMENTIA-PLAN combines two knowledge graphs—daily routine graphs and life memory graphs—with a self-reflection planning agent. The agent decomposes patient queries into semantic components, searches both graphs with adaptive weighting, evaluates retrieval efficiency via LLM scoring, and iteratively adjusts weights and keywords to improve relevance. The framework generates responses or follow-up prompts based on retrieved information. Evaluation uses automated metrics (ROUGE-1, BERTScore) and LLM-based judgment across five dimensions (Coherence, Empathy, Memory Support, Emotional Safety, Problem Solving) compared against human gold standards.

## Key Results
- Significant improvement in empathy score: 7.56 → 8.48
- Memory support enhancement: 6.03 → 7.88
- Safety dimension increase: 8.71 → 9.44
- Problem-solving improvement: 8.01 → 8.60
- Near-human performance in emotional resonance achieved

## Why This Works (Mechanism)
The framework works by integrating structured patient knowledge (daily routines and life memories) with an LLM-driven self-reflection agent that iteratively optimizes retrieval. By decomposing queries, scoring retrieved nodes, and adaptively adjusting search parameters when efficiency drops below threshold, the system ensures responses are both factually grounded and emotionally appropriate. The multi-KG approach allows the agent to draw from both temporal activity patterns and personal history, creating richer, more contextually aware interactions.

## Foundational Learning
- Knowledge Graph Construction: Patient data organized into structured graphs with nodes for entities and edges for relationships; needed to provide structured, retrievable patient context; quick check: verify graph schemas contain expected entity types and temporal attributes.
- Query Decomposition: Breaking patient questions into semantic components (person, location, item, event); needed to target specific knowledge graph sections; quick check: ensure decomposition correctly identifies all components in sample queries.
- Adaptive Retrieval Weighting: Dynamically adjusting graph search weights based on retrieval efficiency; needed to balance relevance between daily routines and life memories; quick check: confirm weights shift appropriately when initial retrieval yields low relevance.
- LLM-Based Efficiency Scoring: Using LLM evaluation to measure retrieval effectiveness; needed to trigger adaptive improvements; quick check: validate that low η scores correlate with poor response quality.
- Iterative Keyword Expansion: Expanding search terms when retrieval underperforms; needed to capture semantic variations; quick check: verify expanded keywords improve node retrieval relevance.

## Architecture Onboarding

**Component Map:** Patient Query → Query Decomposition → Multi-KG Retrieval → Node Scoring → Efficiency Evaluation → (If η < θ) → Weight Adjustment + Keyword Expansion → Response Generation

**Critical Path:** The core loop is: decompose query → retrieve from both KGs with current weights → score nodes → evaluate efficiency → if below threshold, reflect and adjust → repeat until threshold met or max attempts reached → generate final response.

**Design Tradeoffs:** Uses synthetic GPT-generated data for training/evaluation (enables controlled experimentation but may not capture real-world dementia speech irregularities); employs LLM-based evaluation (scalable but potentially biased); balances between empathy and factual accuracy through iterative refinement.

**Failure Signatures:** Retrieval returns irrelevant nodes causing hallucinated responses; iterative reflection loop fails to converge or degrades quality; keyword expansion introduces noise rather than useful synonyms.

**First Experiments:** 1) Test query decomposition on sample confused questions to verify component extraction; 2) Run single KG retrieval with fixed weights to establish baseline relevance; 3) Evaluate efficiency scoring mechanism by comparing LLM-judged relevance across different retrieval outputs.

## Open Questions the Paper Calls Out
1. How can DEMENTIA-PLAN be extended to support dynamic multi-turn conversations that update knowledge graphs in real-time based on patient feedback? The current framework focuses on single-turn interactions; implementing real-time graph updates during conversation remains undeveloped.
2. Does integration of medical knowledge graphs capturing psychological and physical health states improve holistic care provision? Current implementation lacks medical data layer required to assess overall well-being.
3. How does reliance on synthetic GPT-generated data impact generalizability to real-world dementia patient interactions? Synthetic confusion patterns may not capture actual dementia speech irregularities, potentially inflating performance metrics.

## Limitations
- Major hyperparameters unspecified: efficiency threshold θ, max attempts M, top-k node selection, semantic similarity computation method
- Exact prompt templates for decomposition, evaluation, reflection, weight adjustment, and keyword expansion not provided
- DementiaGraph dataset not publicly released, preventing full validation
- LLM backbone for planning agent unspecified (different from GPT-4-mini and GPT-4o-mini used elsewhere)

## Confidence
- Reproducing retrieval and evaluation pipeline: Medium (algorithmic framework clear but implementation details missing)
- Validating claimed improvements across all five dimensions: Low (evaluation dataset and gold standards inaccessible)
- Verifying adaptive weighting mechanism: Medium (described but parameters unspecified)

## Next Checks
1. Request or reconstruct the DementiaGraph dataset with patient profiles, activity logs, and interview summaries to enable end-to-end testing
2. Implement and test the self-reflection planning agent with assumed parameters (θ=0.7, M=3) and monitor η convergence across iterations to verify adaptive weighting mechanism
3. Evaluate generated responses using available LLM judges on the five dimensions (Coherence, Empathy, Memory Support, Emotional Safety, Problem Solving) and compare against reported improvements to confirm performance gains