---
ver: rpa2
title: A Multi-agent Large Language Model Framework to Automatically Assess Performance
  of a Clinical AI Triage Tool
arxiv_id: '2510.26498'
source_url: https://arxiv.org/abs/2510.26498
tags:
- performance
- were
- consensus
- ensemble
- llama3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether an ensemble of multiple LLM agents
  could provide more reliable assessment of a clinical AI triage tool compared to
  a single LLM. The research evaluated nine LLM models (including eight open-source
  models and one commercial model) to analyze radiology reports from 29,766 non-contrast
  head CT exams for intracranial hemorrhage detection.
---

# A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool

## Quick Facts
- arXiv ID: 2510.26498
- Source URL: https://arxiv.org/abs/2510.26498
- Authors: Adam E. Flanders; Yifan Peng; Luciano Prevedello; Robyn Ball; Errol Colak; Prahlad Menon; George Shih; Hui-Ming Lin; Paras Lakhani
- Reference count: 40
- Primary result: Ensemble of 9 LLM agents achieved MCC of 0.571, outperforming single LLMs (MCC 0.543) for automated assessment of clinical AI triage tool performance

## Executive Summary
This study investigated whether an ensemble of multiple LLM agents could provide more reliable assessment of a clinical AI triage tool compared to a single LLM. The research evaluated nine LLM models (including eight open-source models and one commercial model) to analyze radiology reports from 29,766 non-contrast head CT exams for intracranial hemorrhage detection. The ensemble approach showed superior performance, with the highest AUC (0.78) achieved by Llama3.3:70b and GPT-4o, and an ideal consensus configuration (Full-9 Ensemble) achieving an MCC of 0.571.

The findings demonstrate that using a multi-agent LLM framework provides a more consistent and reliable method for deriving ground truth in retrospective evaluation of clinical AI triage tools compared to relying on a single LLM. The approach addresses the challenge of manual chart review being time-consuming and expensive while providing a scalable solution for automated performance assessment of clinical AI tools.

## Method Summary
The study deployed nine LLM models to analyze radiology report impressions from 29,766 non-contrast head CT exams across 14 hospitals, evaluating their ability to detect intracranial hemorrhage compared to a commercial AI tool (Viz.AI). Eight open-source models (Llama3.2:1b, Llama3.2:3b, CodeLlama:7b, Llama3.1:8b, Granite3-dense:2b, Llama3.3:70b, Granite3-dense:8b, DeepSeek-r1) and one commercial model (GPT-4o) were used with a multi-shot prompt requesting JSON output with hemorrhage boolean and subtype fields. The ensemble approach used consensus voting thresholds (4+/8 for 8-model consensus, 5+/9 for Full-9 ensemble) and compared performance metrics against a manually reviewed reference standard of 1,490 reports.

## Key Results
- Full-9 Ensemble achieved highest MCC of 0.571 (95% CI: 0.563-0.579), outperforming GPT-4o alone (MCC 0.543)
- Top-3 ensemble configuration achieved MCC of 0.561, demonstrating robustness of ensemble approach
- Llama3.3:70b and GPT-4o achieved highest AUC of 0.78 for ICH detection
- Ensemble approach showed superior pairwise agreement metrics (Cohen's Kappa and Jaccard similarity) compared to individual models

## Why This Works (Mechanism)
The multi-agent ensemble framework works by leveraging the complementary strengths of different LLM architectures and sizes to provide more robust and consistent ground truth extraction. By combining multiple independent assessments through consensus voting, the approach reduces individual model biases and errors, particularly for complex clinical judgments that require nuanced understanding of radiology reports. The ensemble voting mechanism effectively filters out idiosyncratic errors from single models while amplifying consistent, accurate assessments across the model population.

## Foundational Learning
- **Multi-agent consensus voting**: Combining multiple independent model assessments through voting thresholds improves reliability and reduces individual model bias; check by comparing ensemble performance metrics against individual model baselines.
- **JSON schema standardization**: Structured output format (boolean hemorrhage + subtype) enables consistent aggregation across diverse LLM architectures; verify by testing schema compliance across all models.
- **Bootstrap confidence intervals**: Resampling techniques provide statistical validation of performance differences between ensemble configurations; confirm by checking bootstrap distribution stability across multiple runs.
- **Clinical ground truth extraction**: Automated assessment of radiology reports for clinical AI tool evaluation requires understanding of medical terminology and context; validate by comparing automated assessments against manual review gold standard.
- **Multi-shot prompting**: Providing examples within prompts improves consistency of LLM outputs for specialized tasks; test by comparing performance with and without example prompts.
- **Consensus threshold optimization**: Selecting appropriate voting thresholds (4+/8 vs 5+/9) significantly impacts ensemble performance; experiment by varying thresholds and measuring impact on accuracy metrics.

## Architecture Onboarding
- **Component map**: Report corpus -> LLM inference (9 models) -> JSON output parsing -> Consensus voting -> Performance metrics vs manual review
- **Critical path**: Radiology report → LLM inference → Structured JSON → Ensemble aggregation → Metric computation → Statistical validation
- **Design tradeoffs**: Larger models (Llama3.3:70b) provide better individual performance but increase computational cost; smaller models add diversity but may introduce noise; ensemble size vs consensus threshold balance affects accuracy vs reliability.
- **Failure signatures**: Near-random performance (AUC 0.50) from smaller models indicates prompt comprehension issues; inconsistent JSON schema suggests output format problems; low consensus agreement reveals ambiguous cases requiring manual review.
- **3 first experiments**: 1) Test single LLM performance on subset to establish baseline, 2) Validate JSON parsing and schema compliance across all models, 3) Run ensemble voting with varying thresholds on test set to identify optimal configuration.

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary dataset prevents independent verification of the 29,766 report analyses and Viz.AI tool outputs
- Manual review reference standard excluded 236 ambiguous cases from 1,726 reviewed, potentially biasing performance estimates
- Consensus threshold selection (4+/8, 5+/9) appears arbitrary and could significantly impact performance metrics

## Confidence
- **Dataset availability**: Low - proprietary clinical dataset not publicly accessible
- **Method reproducibility**: Medium - prompt details referenced but not fully specified in manuscript
- **Performance claims**: Medium - bootstrap validation supports statistical significance but clinical significance requires further validation

## Next Checks
1. Replicate the ensemble framework using publicly available radiology report datasets (e.g., MIMIC-CXR) to verify the performance gains are not dataset-specific
2. Conduct ablation studies testing different consensus thresholds and voting schemes to establish robustness of the ensemble approach
3. Evaluate the ensemble's performance on reports from institutions not represented in the original 14-hospital sample to assess generalizability