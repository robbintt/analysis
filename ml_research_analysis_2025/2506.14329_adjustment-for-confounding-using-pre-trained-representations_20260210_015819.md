---
ver: rpa2
title: Adjustment for Confounding using Pre-Trained Representations
arxiv_id: '2506.14329'
source_url: https://arxiv.org/abs/2506.14329
tags:
- pre-trained
- confounding
- estimation
- representations
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how to estimate causal effects when confounding
  information is contained in high-dimensional non-tabular data like images and text.
  The authors develop theoretical conditions under which pre-trained neural network
  representations can be used for valid causal inference, showing that neural networks
  can adapt to the intrinsic low dimensionality of these representations to achieve
  fast convergence rates.
---

# Adjustment for Confounding using Pre-Trained Representations

## Quick Facts
- arXiv ID: 2506.14329
- Source URL: https://arxiv.org/abs/2506.14329
- Authors: Rickmer Schulte; David Rügamer; Thomas Nagler
- Reference count: 40
- Primary result: Pre-trained neural network representations enable valid causal inference when confounding information is contained in high-dimensional non-tabular data like images and text.

## Executive Summary
This paper addresses the challenge of estimating causal effects when confounding information is embedded in high-dimensional non-tabular data such as images and text. The authors develop theoretical conditions under which pre-trained neural network representations can be used for valid causal inference, showing that neural networks can adapt to the intrinsic low dimensionality of these representations to achieve fast convergence rates. They demonstrate empirically that Double Machine Learning using pre-trained representations yields unbiased estimates with valid confidence intervals, while standard methods fail when applied directly to raw high-dimensional data. The experiments on both text and image data show that pre-training is crucial for effective confounding adjustment.

## Method Summary
The method involves extracting latent representations from pre-trained models (BERT for text, DenseNet-121 for images) and using these representations as confounders in Double Machine Learning (DML) to estimate Average Treatment Effects (ATE). The approach leverages the low intrinsic dimensionality of pre-trained representations and the ability of neural networks to adapt to this structure. The method uses cross-fitting to estimate nuisance functions (propensity scores and outcome regressions) with neural networks, then computes the ATE using an orthogonal score function to remove regularization bias.

## Key Results
- Neural networks achieve fast convergence rates on pre-trained representations by adapting to intrinsic dimensionality rather than ambient dimension
- Pre-trained representations serve as valid adjustment sets when they capture sufficient confounding information
- Standard methods like Lasso and Random Forests fail on latent features due to non-identifiability under invertible linear transformations
- Empirical results show unbiased ATE estimates with valid confidence intervals using DML with pre-trained representations, while naive methods fail

## Why This Works (Mechanism)

### Mechanism 1: Intrinsic Dimensionality Adaptation
Neural network estimators achieve fast convergence rates for nuisance function estimation on pre-trained representations by adapting to the data's intrinsic dimension rather than its ambient dimension. High-dimensional non-tabular data lies on a low-dimensional manifold, and pre-trained representations preserve this structure. The authors prove that NNs can exploit this structure to converge at rates dependent on the manifold dimension, satisfying DML rate requirements. The intrinsic dimension assumption is critical - if it's too high or sample size too small, convergence rates will degrade.

### Mechanism 2: ILT Robustness
Neural networks are robust to non-identifiability of pre-trained representations (specifically invertible linear transformations), whereas traditional sparse estimators fail. Latent features are identifiable only up to ILTs (rotations), and structural assumptions like sparsity or additivity are not invariant under these transformations. Therefore, methods like Lasso or Random Forests fail to consistently estimate nuisance functions on these representations, while NNs are shown to be insensitive to these transformations.

### Mechanism 3: P-validity of Representations
Pre-trained representations serve as valid adjustment sets if they capture sufficient information about the outcome and treatment, enabling standard DML identification theory. The paper formalizes a sufficiency condition (P-validity) for representations. If a representation captures the confounding information, replacing the original confounders with this representation allows for ATE identification. The core assumption is that unconfoundedness holds given the representation.

## Foundational Learning

- **Double Machine Learning (DML)**: Needed to estimate ATEs with valid confidence intervals when using machine learning models to estimate nuisance functions. Quick check: Why does simply plugging ML predictions into a final regression yield biased confidence intervals?

- **Intrinsic Dimensionality & Manifold Hypothesis**: Needed to justify why neural networks can learn effectively from high-dimensional representations where theoretical bounds based on ambient dimension would otherwise forbid it. Quick check: If data lies on a 10-dimensional manifold inside a 1000-dimensional space, which dimension determines the difficulty of learning?

- **Identifiability & Invertible Linear Transformations (ILTs)**: Needed to understand why standard regression techniques fail on latent features and why architectural invariance is critical. Quick check: If you rotate a sparse dataset, is it still sparse? Why does this matter for feature selection?

## Architecture Onboarding

- **Component map:** Input (non-tabular confounder W, Treatment T, Outcome Y) -> Encoder (pre-trained model φ -> Latent Representation Z) -> Nuisance Estimators (NNs via cross-fitting -> Propensity Score m(Z) and Outcome Regression g(Z)) -> Aggregator (DML orthogonal score -> ATE Estimate θ̂)

- **Critical path:** Select pre-trained encoder matching confounding domain, extract frozen features, use cross-fitting to train NN nuisance estimators, compute ATE using orthogonal score to remove regularization bias.

- **Design tradeoffs:** Pre-trained vs. scratch - training CNNs from scratch on raw images fails due to sample size; pre-trained features are strictly required. NN vs. Lasso/RF on latents - Lasso/RF fail because they assume sparsity/additivity which is destroyed by ILTs inherent in latent space; NNs are required for robustness.

- **Failure signatures:** "Naive" bias (strong negative/positive bias if W is ignored), "Lasso/RF on Latents" failure (unbiased point estimates possible but confidence intervals often undercover or estimates remain biased), "Small Sample/Scratch" failure (training end-to-end without pre-training leads to high variance and bias).

- **First 3 experiments:**
  1. Run DML on a dataset where confounding is a simple function of labels, comparing Linear DML vs. Lasso DML to demonstrate sparsity assumption failure in latent space.
  2. Estimate the intrinsic dimension (d_M) of pre-trained representations using MLE or lPCA to verify the low-dimensionality assumption.
  3. Compare ATE estimation using pre-trained features vs. CNN trained from scratch on raw data to demonstrate necessity of transfer learning.

## Open Questions the Paper Calls Out

- **Multiple Modalities:** How does the presence of multiple non-tabular modalities (e.g., images and text jointly) influence ATE estimation and the required structural assumptions? The current framework is restricted to a single source of confounding.

- **Other Causal Parameters:** Can the theoretical guarantees be extended to other causal parameters like ATT or CATE? The paper focuses on ATE, but different target parameters require different influence functions and rate conditions.

- **Verifying P-validity:** How can researchers empirically verify the P-validity or sufficiency of a specific pre-trained representation before conducting the causal analysis? The paper assumes this holds but lacks diagnostic methods to test it.

## Limitations

- Intrinsic dimensionality assumption (d_M << d) is critical but difficult to verify empirically for real-world data
- P-validity condition for pre-trained representations is assumed rather than proven for specific architectures
- Sample size requirements for achieving fast convergence rates remain unspecified and may be prohibitive for very high-dimensional data

## Confidence

- **High:** DML validity under pre-trained representations - well-established statistical theory
- **Medium:** Intrinsic dimensionality preservation - supported by theory but empirical verification is limited
- **Low:** P-validity of specific pre-trained models - assumed rather than proven for real-world cases

## Next Checks

1. Apply MLE or PCA-based methods to estimate d_M of pre-trained representations to verify the low-dimensionality assumption required for fast convergence rates.

2. Test whether representations from pre-trained models on unrelated tasks still capture confounding information by comparing ATE estimates to oracle benchmarks.

3. Systematically vary sample sizes to identify minimum requirements for achieving theoretical convergence rates, particularly for high-dimensional data where d_M may approach d.