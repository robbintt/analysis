---
ver: rpa2
title: Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery
arxiv_id: '2509.23003'
source_url: https://arxiv.org/abs/2509.23003
tags:
- system
- systems
- sps-gan
- space
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Symplectic Phase Space GAN (SPS-GAN), a generative
  model for capturing dynamics of multiple mechanical systems and discovering system
  symmetries without prior knowledge of configuration spaces. The core method uses
  a conditional GAN backbone with a Hamiltonian Neural Network recurrent module to
  ensure physically plausible latent trajectories, while a cyclic coordinate loss
  encourages sparse representation of configuration spaces.
---

# Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery

## Quick Facts
- arXiv ID: 2509.23003
- Source URL: https://arxiv.org/abs/2509.23003
- Reference count: 40
- This paper introduces Symplectic Phase Space GAN (SPS-GAN), a generative model for capturing dynamics of multiple mechanical systems and discovering system symmetries without prior knowledge of configuration spaces.

## Executive Summary
This paper introduces Symplectic Phase Space GAN (SPS-GAN), a generative model that captures dynamics of multiple mechanical systems and discovers system symmetries without prior knowledge of configuration spaces. The core method uses a conditional GAN backbone with a Hamiltonian Neural Network recurrent module to ensure physically plausible latent trajectories, while a cyclic coordinate loss encourages sparse representation of configuration spaces. SPS-GAN achieves trajectory prediction accuracy on par with supervised HNNs across five benchmark systems, correctly identifying the minimal degrees of freedom for each system.

## Method Summary
SPS-GAN is a conditional GAN that generates physically plausible trajectories for multiple dynamical systems. It combines a generator with a Hamiltonian Neural Network (HNN) recurrent module and Leapfrog integration to evolve latent states, ensuring energy conservation. The model uses a cyclic coordinate loss to discover minimal degrees of freedom by penalizing changes in momentum. Conditioning on system labels and physical parameters enables a single generator to model multiple distinct dynamical systems. The method achieves trajectory prediction accuracy comparable to supervised HNNs while discovering system symmetries.

## Key Results
- Achieves trajectory prediction accuracy on par with supervised HNNs across five benchmark systems (mass-spring oscillator, ideal pendulum, double pendulum, two-body, and three-body systems)
- Correctly identifies the minimal degrees of freedom for each system through cyclic coordinate loss
- Generates physically plausible videos with significantly better Fréchet Video Distance than baseline physics-informed models
- Successfully generalizes to unseen system parameters and discovers system symmetries

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding Hamiltonian dynamics in the latent space enforces energy conservation and physical consistency.
- **Mechanism:** The generator learns a neural Hamiltonian $H_\theta$ and evolves the latent state $z_t$ using symplectic Leapfrog integration of Hamilton's equations. This inductive bias constrains the latent trajectories to lie on constant energy manifolds.
- **Core assumption:** The underlying physical systems are conservative (Hamiltonian) or can be approximated as such in the latent space.
- **Evidence anchors:** Mentions "Hamiltonian Neural Network recurrent module to ensure physically plausible latent trajectories" [abstract]; describes the latent motion model evolving via Hamilton's equations [section 4.2]; details the use of Leapfrog integration to preserve quadratic invariance [section 3.2].

### Mechanism 2
- **Claim:** The Cyclic Coordinate Loss functions as a sparsity-inducing regularizer to discover the minimal degrees of freedom (DOF).
- **Mechanism:** The loss $L_{cyclic} = \sum |\dot{p}_i|$ penalizes changes in momentum. To minimize this loss, the network effectively removes coordinates from the Hamiltonian representation, forcing the latent space to compress to the minimal DOF required to explain the dynamics.
- **Core assumption:** The system possesses symmetries or constraints that reduce the effective dimensionality of the configuration space.
- **Evidence anchors:** "cyclic coordinate loss encourages sparse representation of configuration spaces" [abstract]; derives the loss term from the definition of cyclic coordinates [section 4.3]; shows PCA eigenvalue analysis confirming correct identification of low-dimensional latent spaces [section 5.1].

### Mechanism 3
- **Claim:** Conditioning on system labels and physical parameters enables a single generator to model multiple distinct dynamical systems.
- **Mechanism:** The generator and HNN are conditioned on a vector $\xi$ (system label, mass, length, etc.). This allows the shared network weights to modulate their behavior, mapping the same noise distribution to different "configuration spaces" based on the context $\xi$.
- **Core assumption:** There exist shared features across physical systems that benefit from a joint representation, or the model has sufficient capacity to multiplex distinct dynamics.
- **Evidence anchors:** "capture dynamics of multiple systems, and generalize to unseen physical parameters" [abstract]; defines the configuration map $f(\epsilon_m, \xi)$ conditioned on system parameters [section 4.1]; demonstrates the model disentangling and generating trajectories for five distinct systems simultaneously [section 5.1].

## Foundational Learning

- **Concept:** Hamiltonian Mechanics & Symplectic Integration
  - **Why needed here:** The core of the model is the HNN. You must understand that Hamiltonian dynamics conserve energy and that symplectic integration (like Leapfrog) prevents "energy drift" over long trajectories.
  - **Quick check question:** Why does the paper use Leapfrog integration instead of standard Euler updates for the latent state?

- **Concept:** Cyclic Coordinates (Ignorable Coordinates)
  - **Why needed here:** This is the theoretical basis for the "symmetry discovery." You need to understand that if the Hamiltonian $H$ does not depend on a coordinate $q$, the conjugate momentum $p$ is constant.
  - **Quick check question:** If $\dot{p}_k = 0$ for a specific dimension $k$, what does that imply about the contribution of $q_k$ to the system's total energy?

- **Concept:** Conditional GANs (cGANs)
  - **Why needed here:** The model is generative. You need to understand how the discriminator forces the generator to produce realistic data and how conditioning ($\xi$) steers this generation to specific physical systems.
  - **Quick check question:** How does the discriminator ensure the generated trajectory matches the specific system parameters provided in the conditioning vector?

## Architecture Onboarding

- **Component map:**
  - Input: Noise $\epsilon_m$ (motion), $\epsilon_c$ (content) + Conditioning $\xi$ (system params)
  - Config Map (MLP): $f(\epsilon_m, \xi) \to z_0$ (Initial latent state $q_0, p_0$)
  - HNN (MLP): Computes $H_\theta(z, \xi)$
  - Integrator (Leapfrog): Evolves $z_0 \to \{z_t\}$ using gradients $\nabla H_\theta$
  - Decoder (MLP/CNN): Maps latent states $\{z_t, \epsilon_c\} \to$ Cartesian Trajectory / Video
  - Loss: $L_{total} = L_{GAN} + \lambda_{cyclic} L_{cyclic}$

- **Critical path:** The **Cyclic Coordinate Loss** (Eq. 8). This is the novel component. If implemented incorrectly, the model will fail to discover the reduced DOF and may learn noisy latent representations.

- **Design tradeoffs:**
  - **Latent Size ($d_{lat}$):** The paper uses 20. It must be larger than the max expected DOF of the systems.
  - **Assumption of Separability:** The HNN assumes $H = T(p) + V(q)$. This simplifies integration but restricts the class of Hamiltonians the model can learn.

- **Failure signatures:**
  - **Non-sparse latent space:** If $L_{cyclic}$ is too weak, PCA of the latent space will show many active dimensions.
  - **Energy Drift:** If the integrator step size $\Delta t$ is too large or the HNN is under-trained, the generated trajectories will diverge from physically valid paths.
  - **Mode Collapse:** The GAN generates the same trajectory for different noise inputs $\epsilon_m$.

- **First 3 experiments:**
  1. **Sanity Check (Single System):** Train SPS-GAN-traj on the mass-spring system. Plot the generated trajectory and the energy $H(t)$. Verify the energy is constant and the trajectory is a sine wave.
  2. **Symmetry Discovery (Ablation):** Train on the two-body system. Run PCA on the latent codes. Verify that the effective dimension is 1 (radial motion). Then, set $\lambda_{cyclic} = 0$ and verify the latent dimension expands (failure case).
  3. **Generalization Test:** Train on pendulums with lengths $L \in [0.5, 1.5]$. Test on an unseen length $L=2.0$. Check if the generated frequency scales correctly with the physical parameter.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does replacing the standard RNN-based discriminator with one embedding general Hamiltonian structure improve the model's ability to enforce physical consistency?
- **Basis in paper:** The authors state in the "Future Work" section, "Future work will investigate embedding general Hamiltonian structure in the discriminator," noting that existing work has used Hamiltonians as discriminators for quantum applications.
- **Why unresolved:** The current architecture relies on a standard recurrent discriminator which may not optimally enforce the physical constraints inherent in the generator's latent space.
- **What evidence would resolve it:** Comparative benchmarks showing reduced FVD or improved energy conservation metrics when using a Hamiltonian-structured discriminator versus the current RNN implementation.

### Open Question 2
- **Question:** Can the framework be adapted to learn minimal latent representations for non-conservative systems (e.g., systems with friction or damping)?
- **Basis in paper:** In Appendix C.3, the authors show that for a damped pendulum (a non-Hamiltonian system), the model fails to identify the minimal degrees of freedom, learning a 3-dimensional space instead of the expected 1-dimensional one.
- **Why unresolved:** The cyclic coordinate loss and HNN backbone are derived from Hamiltonian mechanics, which assumes energy conservation (no dissipation).
- **What evidence would resolve it:** A modified loss function or architecture that successfully yields the correct minimal latent dimensionality for benchmark non-conservative systems, such as the damped pendulum or systems with external forcing.

### Open Question 3
- **Question:** How effectively can the symmetries and representations discovered by SPS-GAN be transferred to downstream tasks like energy-based control?
- **Basis in paper:** The authors note in "Limitations" and "Future Work" that they "do not extend to use the learned representations for additional tasks," but propose that "Future work will focus on applying the proposed method on unknown systems to discover hidden symmetries that can be used in downstream tasks such as energy based control."
- **Why unresolved:** While the model generates plausible trajectories, the utility of the discovered latent configuration space for solving control problems on unknown systems remains untested.
- **What evidence would resolve it:** Demonstrating that the latent symmetries discovered by SPS-GAN improve the sample efficiency or stability of a reinforcement learning agent or model predictive controller managing a physical system.

## Limitations

- **Model Architecture Gaps:** Key details missing for faithful reproduction include exact discriminator architectures, conditioning embedding mechanisms, CNN decoder and video discriminator architectures, and weight initialization schemes.
- **Energy Conservation Assumption:** The model relies on the system being Hamiltonian or approximable as such. The paper explicitly notes failure for dissipative systems with high friction, limiting applicability to non-conservative dynamics.
- **Generality of Cyclic Loss:** While the cyclic coordinate loss successfully discovers minimal DOF in benchmark systems, its effectiveness across diverse physical domains with complex symmetries remains untested.

## Confidence

- **High Confidence:** The core mechanism of embedding Hamiltonian dynamics via HNN with symplectic integration is well-supported by the literature and the paper's implementation details.
- **Medium Confidence:** The cyclic coordinate loss is theoretically sound and shows empirical success in identifying DOF, but the exact weighting and its sensitivity to system complexity are not fully explored.
- **Medium Confidence:** The multi-system generalization via conditioning is plausible and demonstrated, but the paper doesn't test the limits of system diversity or the capacity required to multiplex highly distinct dynamics.

## Next Checks

1. **Architecture Reproduction Test:** Implement the full SPS-GAN-traj model following the paper's specifications, using the HGN dataset. Compare 30-step trajectory MSE and FVD against the reported baselines (HNN, NeuralODE). Verify energy conservation in generated trajectories.

2. **Cyclic Loss Ablation Study:** Train SPS-GAN on the two-body system with λ_cyclic=0.03 and λ_cyclic=0. Train both models, perform PCA on latent codes, and verify that the model with cyclic loss discovers the 1D (radial) latent space while the ablation learns a higher-dimensional representation.

3. **Generalization to Unseen Parameters:** Train SPS-GAN on pendulum systems with lengths L ∈ [0.5, 1.5]. Test on an unseen length L=2.0. Verify that the generated trajectories have the correct frequency scaling (T ∝ √L) and that the latent space correctly adapts to the new parameter without retraining.