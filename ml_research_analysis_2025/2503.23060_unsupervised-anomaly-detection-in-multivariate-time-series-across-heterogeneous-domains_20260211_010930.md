---
ver: rpa2
title: Unsupervised Anomaly Detection in Multivariate Time Series across Heterogeneous
  Domains
arxiv_id: '2503.23060'
source_url: https://arxiv.org/abs/2503.23060
tags:
- anomaly
- data
- methods
- domain
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of unsupervised anomaly detection
  in multivariate time series data under domain shifts, a common challenge in AIOps
  where normal behavior patterns change across different operational contexts. The
  authors propose Domain-Invariant VAE for Anomaly Detection (DIVAD), which learns
  domain-invariant representations by disentangling input data into domain-specific
  and domain-invariant factors.
---

# Unsupervised Anomaly Detection in Multivariate Time Series across Heterogeneous Domains

## Quick Facts
- arXiv ID: 2503.23060
- Source URL: https://arxiv.org/abs/2503.23060
- Reference count: 40
- Outperforms best existing unsupervised AD method by 20% and 15% improvements in maximum peak F1-scores (0.79 and 0.76 vs 0.66)

## Executive Summary
This paper addresses unsupervised anomaly detection in multivariate time series data under domain shifts, a common challenge in AIOps where normal behavior patterns change across different operational contexts. The authors propose Domain-Invariant VAE for Anomaly Detection (DIVAD), which learns domain-invariant representations by disentangling input data into domain-specific and domain-invariant factors. The method uses a multi-encoder architecture with variational autoencoders and incorporates domain classification to encourage domain invariance. Evaluation on the Exathlon benchmark shows that DIVAD variants significantly outperform the best existing unsupervised AD method, achieving 20% and 15% improvements in maximum peak F1-scores (0.79 and 0.76 vs 0.66). Additional experiments on the Application Server Dataset demonstrate the broader applicability of the approach, with DIVAD variants outperforming the state-of-the-art method in 92% of test cases.

## Method Summary
DIVAD learns domain-invariant representations by disentangling input data into domain-specific and domain-invariant factors using a multi-encoder VAE architecture. The model encodes each input into two latent representations: z_d (domain-specific) and z_y (domain-invariant), with the assumption that anomalies primarily affect domain-invariant properties. Domain classification is incorporated as an auxiliary task to encourage z_d to capture domain information, indirectly enforcing domain-invariance for z_y. Anomaly scores are derived from the domain-invariant latent distribution (z_y) and are more robust to domain shift than scores from input space. The method includes two variants: DIVAD-G using a fixed Gaussian prior and DIVAD-GM using a learned Gaussian Mixture prior for improved expressiveness.

## Key Results
- DIVAD variants achieve 20% and 15% improvements in maximum peak F1-scores (0.79 and 0.76) compared to the best existing unsupervised AD method (0.66)
- DIVAD-GM consistently outperforms DIVAD-G by 1.5-2% peak F1-score on Exathlon benchmark
- On the Application Server Dataset, DIVAD variants outperform the state-of-the-art method in 92% of test cases
- DIVAD shows superior cross-domain generalization performance compared to baseline VAE and other state-of-the-art methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DIVAD separates input data into domain-invariant and domain-specific latent factors.
- Mechanism: A multi-encoder VAE architecture disentangles factors: z_d conditioned on domain d, and z_y assumed independent of d. The generative model assumes x is caused by independent z_d and z_y, with z_y used for anomaly detection.
- Core assumption: Observed data distributions are determined by independent domain-specific and domain-invariant factors.
- Evidence anchors:
  - [abstract] "learns domain-invariant representations by disentangling input data into domain-specific and domain-invariant factors"
  - [section] Section 5.1: "our model assumes that the observed variable x is caused by two independent latent factors z_d and z_y"
  - [corpus] CICADA similarly uses cross-domain interpretable coding for anomaly detection, supporting the disentanglement approach.

### Mechanism 2
- Claim: Domain classification encourages z_d to capture domain information, indirectly enforcing domain-invariance for z_y.
- Mechanism: A domain classification head L_d is trained on z_d to predict the source domain, pushing domain-relevant signals into z_d while leaving z_y domain-agnostic.
- Core assumption: Domain labels for training data are available and domains are separable in the latent space.
- Evidence anchors:
  - [abstract] "incorporates domain classification to encourage domain invariance"
  - [section] Section 5.2: "we add to maximum likelihood the following domain classification objective"
  - [corpus] No direct corpus evidence for this specific mechanism; related cross-domain methods may use adversarial alignment but not explicit domain classification in this architecture.

### Mechanism 3
- Claim: Anomaly scores derived from the domain-invariant latent distribution (z_y) are more robust to domain shift than scores from input space.
- Mechanism: After training, test samples are mapped to z_y via the encoder; anomaly scores are computed as negative log-likelihood under a prior or aggregated posterior estimate.
- Core assumption: Anomalies affect domain-invariant properties, and normal behavior in z_y space has a learnable distribution that generalizes across domains.
- Evidence anchors:
  - [abstract] "outperform the best existing unsupervised AD method, achieving 20% and 15% improvements in maximum peak F1-scores"
  - [section] Section 5.3: "derive the anomaly score of a sample as the negative log-likelihood of f_y(x) with respect to the prior p(z_y)"
  - [corpus] Related benchmarks like mTSBench evaluate MTS-AD across domains, but do not isolate this specific scoring mechanism.

## Foundational Learning

- **Variational Autoencoders (VAEs) and the ELBO**
  - Why needed here: DIVAD builds on VAE architecture and loss; understanding ELBO terms is essential to interpret training and debug latent space issues.
  - Quick check question: Can you explain why the ELBO is a lower bound on the marginal likelihood and how β-VAE modifies it?

- **Domain Generalization vs. Domain Adaptation**
  - Why needed here: The paper frames the problem as domain generalization (no target domain data at training), which constrains design choices.
  - Quick check question: What is the key difference between domain generalization and domain adaptation in terms of data requirements?

- **Feature Disentanglement**
  - Why needed here: DIVAD's core innovation is disentangling domain-specific and domain-invariant factors; understanding how independence constraints enable this is critical.
  - Quick check question: In a disentangled representation, what does it mean for two latent factors to be independent, and how might an auxiliary classifier encourage it?

## Architecture Onboarding

- **Component map:**
  - Input x → Encoder NN_φy → z_y (domain-invariant)
  - Input x → Encoder NN_φd → z_d (domain-specific)
  - z_d → Domain Classifier NN_ωd → domain prediction
  - z_d, z_y → Decoder NN_θyd → reconstruction x̂
  - z_d → Domain Prior Network NN_θd → p(z_d|d)

- **Critical path:**
  1. Forward pass: encode input x to z_d, z_y; decode reconstruction; compute ELBO terms and domain classification loss.
  2. Backward pass: update all networks jointly with combined loss L = L_ELBO + α_d·L_d.
  3. Inference: encode test sample to z_y only; compute anomaly score via negative log-likelihood.

- **Design tradeoffs:**
  - DIVAD-G vs. DIVAD-GM: Fixed Gaussian prior vs. learned Gaussian Mixture prior; GM is more expressive but adds parameters and complexity.
  - Prior vs. aggregated posterior scoring: Aggregated posterior addresses "holes" but requires separate density estimation; prior-based is simpler but may mismatch the encoded distribution.
  - Point vs. sequence modeling: Sequence variants (recurrent) add temporal modeling but may be harder to disentangle.

- **Failure signatures:**
  - Poor domain separation: z_d clusters do not align with domain labels (visualize with t-SNE).
  - Anomaly signal loss: z_y encodings of anomalies overlap significantly with normal data (KDE plots show high overlap).
  - Training instability: ELBO or L_d diverges; check α_d weighting and learning rate.
  - Over-regularization: High β forces z_y to match prior too strictly, losing discriminative power for anomalies.

- **First 3 experiments:**
  1. Disentanglement check: Train on labeled source domains; visualize z_d and z_y embeddings (t-SNE) colored by domain. Expect distinct domain clusters for z_d, mixed for z_y.
  2. Scoring strategy comparison: For a held-out test domain, compare prior-based vs. aggregated posterior scoring using peak F1-score. Expect aggregated posterior to help DIVAD-G more.
  3. Domain generalization test: Train on a subset of source domains, test on unseen target domains; compare DIVAD variants against a standard VAE baseline. Expect DIVAD to maintain or improve F1-score as target domains diverge.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DIVAD be extended to a weakly-supervised setting that combines explicit normal behavior shift modeling with robustness to removing anomaly signals when a few labeled anomalies are available?
- Basis in paper: [explicit] The conclusion explicitly states: "Our future research directions include a weakly-supervised extension of DIVAD, combining its explicit modeling of normal behavior shifts with a higher robustness to removing anomaly signals enabled by a few training anomalies."
- Why unresolved: The current DIVAD formulation is purely unsupervised, and incorporating labeled anomalies while maintaining domain generalization capabilities requires new theoretical and architectural extensions.
- What evidence would resolve it: A modified DIVAD architecture and training objective that incorporates labeled anomalies, evaluated on benchmarks showing improved anomaly detection while maintaining domain generalization performance.

### Open Question 2
- Question: What explainability mechanisms can be integrated into DIVAD to identify the reasons behind detected anomalies in multivariate time series?
- Basis in paper: [explicit] The conclusion explicitly states: "enhancing the model with explainability, indicating the reasons behind anomalies, which will be key to widespread adoption in real-world use cases."
- Why unresolved: The current DIVAD architecture focuses on detection accuracy but provides no interpretability of which features or temporal patterns contribute to anomaly scores.
- What evidence would resolve it: An extended DIVAD framework with attribution methods (e.g., feature importance scores, temporal contribution analysis) validated through human evaluation studies with domain experts.

### Open Question 3
- Question: Why do sequence modeling DIVAD variants underperform point modeling variants, and how can domain-invariant sequential patterns be learned more effectively?
- Basis in paper: [inferred] Section 6.2.4 states that "sequence modeling DIVAD variants could not" outperform TranAD, and Appendix D notes "the heightened challenge of learning domain-invariant patterns in the sequential setting."
- Why unresolved: The paper identifies that sequential patterns learned to be domain-invariant may also be shared between normal data and specific anomaly types, effectively removing anomalous signals.
- What evidence would resolve it: Architectural modifications (e.g., attention mechanisms, contrastive learning) that explicitly preserve anomaly-discriminative temporal features while achieving domain invariance.

## Limitations

- The paper does not provide complete details on domain ID assignment for the Exathlon benchmark, making exact replication challenging.
- The evaluation focuses heavily on the Exathlon benchmark, with limited ablation studies on the disentanglement mechanism itself or sensitivity to hyperparameters.
- The broader applicability claim based on the Application Server Dataset results is supported but with limited detail on this dataset and experimental setup.

## Confidence

- **High Confidence:** The core mechanism of using multi-encoder VAE with domain classification to encourage domain-invariant representations.
- **Medium Confidence:** The claimed 20-15% improvements in peak F1-scores are supported by the Exathlon results, but the lack of detailed domain partitioning reduces generalizability confidence.
- **Medium Confidence:** The broader applicability claim based on the Application Server Dataset results is supported (92% improvement rate), but the paper provides limited detail on this dataset.

## Next Checks

1. **Disentanglement Validation:** Train DIVAD on labeled source domains and visualize t-SNE embeddings of z_d and z_y, verifying that z_d clusters by domain while z_y does not.

2. **Cross-Domain Generalization Test:** Train on a subset of source domains (e.g., 15 of 22) and evaluate on held-out target domains, comparing DIVAD variants against a standard VAE baseline to confirm domain generalization capability.

3. **Mechanism Ablation Study:** Remove the domain classification component (set α_d=0) and retrain, measuring the impact on cross-domain F1-scores to validate that domain classification is critical for the claimed improvements.