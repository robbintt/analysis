---
ver: rpa2
title: Autoregressive Surrogate Modeling of the Solar Wind with Spherical Fourier
  Neural Operator
arxiv_id: '2511.20830'
source_url: https://arxiv.org/abs/2511.20830
tags:
- solar
- sfno
- wind
- available
- radius
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first autoregressive machine learning
  surrogate for steady-state solar wind radial velocity using the Spherical Fourier
  Neural Operator (SFNO). The model iteratively predicts solar wind conditions in
  segments, improving accuracy in distant regions compared to single-step approaches.
---

# Autoregressive Surrogate Modeling of the Solar Wind with Spherical Fourier Neural Operator

## Quick Facts
- arXiv ID: 2511.20830
- Source URL: https://arxiv.org/abs/2511.20830
- Authors: Reza Mansouri; Dustin Kempton; Pete Riley; Rafal Angryk
- Reference count: 39
- One-line primary result: SFNO achieves better mean squared error than HUX baseline while improving accuracy in distant regions through autoregressive rollout

## Executive Summary
This work introduces the first autoregressive machine learning surrogate for steady-state solar wind radial velocity using the Spherical Fourier Neural Operator (SFNO). The model iteratively predicts solar wind conditions in segments, improving accuracy in distant regions compared to single-step approaches. Trained on MAS MHD simulation data, the SFNO outperforms the numerical HUX baseline in mean squared error and edge-specific metrics while providing a flexible, data-driven alternative for space weather forecasting. The 5-radius SFNO variant achieved the best overall performance, with prediction errors increasing during periods of high solar activity, highlighting the model's ability to capture complex solar wind dynamics.

## Method Summary
The approach uses SFNO to predict solar wind radial velocity from 30 R⊙ to 1 AU in an autoregressive manner. Instead of predicting all 139 radii in one step, the model predicts a limited segment (5, 10, or 20 radii) and feeds the last predicted radius back as input for the next iteration. This rollout strategy improves accuracy at distant regions. The SFNO uses 8 layers with 256 channels, employing spherical harmonic transforms instead of standard FFTs to respect the spherical geometry. Teacher forcing accelerates training by using ground truth data during autoregressive steps. The model is trained on MAS MHD simulation data from 1975-2025, split into training (CR 1625-2169) and test (CR 2170-2293) sets.

## Key Results
- The 5-radius SFNO achieved the best overall performance across MSE and edge-specific metrics
- SFNO outperformed the HUX numerical baseline in global mean squared error
- Prediction errors increased during periods of high solar activity, correlating with sunspot counts
- Shorter predictive horizons (5 radii) provided better accuracy than single-step prediction of all 139 radii

## Why This Works (Mechanism)

### Mechanism 1
Spherical Harmonic Transform (SHT) enables the model to respect rotational symmetry inherent in spherical solar wind domains. The SFNO performs spectral convolutions in the spherical harmonic domain rather than Cartesian Fourier space, ensuring rotational equivariance. This means the learned representations are consistent regardless of longitude rotation, which is physically appropriate for heliospheric simulations where no longitudinal direction is privileged.

### Mechanism 2
Autoregressive rollout with limited predictive horizons (5-20 radii per step) improves accuracy at distant radial positions compared to single-step prediction of all 139 radii. Rather than predicting the entire radial range from 30R⊙ to 1 AU in one forward pass, the model predicts a small segment (e.g., 5 radii), feeds the last predicted radius back as input, and repeats. This localizes the learning problem and reduces error compounding.

### Mechanism 3
Teacher forcing during training (using ground-truth MAS data as autoregressive inputs) accelerates convergence compared to feeding model predictions back during training. During training, the model receives the true velocity field at each autoregressive step rather than its own noisy predictions. This prevents error compounding in the backward pass and provides stable gradients.

## Foundational Learning

- **Spherical Harmonic Transform (SHT)**: Needed to understand how SFNO operates in spherical domains rather than flat images. Quick check: Why does SHT use Gauss-Legendre sampling in latitude rather than equiangular grids, and what determines the maximum number of modes (110 in this paper)?
- **Autoregressive Error Accumulation**: Needed to understand why shorter predictive horizons reduce long-range error. Quick check: What happens to prediction variance as you increase the number of autoregressive steps from 7 (5-radius horizon) to 14 (10-radius horizon) to 28 (20-radius horizon)?
- **Neural Operator Fundamentals**: Needed to understand SFNO's discretization-invariant properties. Quick check: How does a spectral convolution in SFNO differ from a standard convolutional layer, and why does this enable zero-shot super-resolution in some neural operator applications?

## Architecture Onboarding

- **Component map**: Input velocity field (30R⊙) -> Encoder MLP -> 8 SFNO layers with spectral convolutions -> Decoder MLP -> Predicted radii -> Last predicted radius fed back as input -> Repeat until 1 AU
- **Critical path**: Input velocity field (30R⊙) → Encoder → 8 SFNO layers with spectral convolutions → Decoder → Predicted radii → Last predicted radius fed back as input → Repeat until 1 AU
- **Design tradeoffs**: 5 radii = best accuracy, most inference steps; 20 radii = faster inference, higher error; 139 radii = single-step, worst accuracy at distance
- **Failure signatures**: MSE and edge-specific MSE both spike during high solar activity; high-gradient regions show elevated errors; single-step model produces blurry predictions at distant radii; HUX-f baseline outperforms SFNO in some high-gradient regions
- **First 3 experiments**: 1) Replicate 5-fold cross-validation on training split with 4/8 layers and 64/128/256 channels; 2) Train models with 5, 10, 15, and 20-radius horizons on same data and evaluate on test set; 3) Partition test set into high-activity and low-activity periods and compare SFNO vs. HUX-f error distributions

## Open Questions the Paper Calls Out

### Open Question 1
Does extending the surrogate model to include additional physical variables, such as plasma density (ρ), improve the prediction accuracy of radial velocity or provide a more complete description of solar wind dynamics? The authors state future work will focus on integrating additional variables such as plasma density ρ. This question remains unresolved as the current study is restricted to modeling the radial velocity field (vᵣ) only.

### Open Question 2
Can physics-informed training strategies significantly reduce errors in high-gradient regions and improve the model's physical consistency? The authors propose exploring physics-informed training to deepen the model's physical understanding. The current model uses a purely data-driven L2 loss, which may not sufficiently penalize physically unrealistic smoothness in shock fronts.

### Open Question 3
What domain-specific evaluation metrics can better capture the quality of solar wind predictions than standard MSE? The results section states that the small metric differences among SFNOs highlight the need for more suitable evaluation metrics for this physical phenomenon. Standard metrics like MSE and Earth Mover's Distance showed minimal differentiation between various autoregressive horizon lengths.

### Open Question 4
How can model architecture or training be adapted to maintain prediction accuracy during periods of high solar activity? Figure 11 shows that both SFNO and baseline errors rise and fall in sync with sunspot counts, suggesting the model struggles with the increased structural complexity of active periods. The current training strategy does not appear to equalize performance across the solar cycle.

## Limitations

- Performance degrades during high solar activity periods, indicating limitations in capturing extreme or rapidly varying conditions
- Optimal predictive horizon (5 radii) was determined empirically and may not generalize to different spatial resolutions or physical regimes
- Teacher forcing during training introduces potential distribution shift concerns between training and inference that were not fully validated

## Confidence

- **High confidence**: SFNO architecture's ability to outperform HUX baseline in global MSE metrics; empirical finding that 5-radius predictive horizons yield optimal accuracy; core claim that autoregressive rollout improves distant-region predictions versus single-step approaches
- **Medium confidence**: Generalizability of 5-radius optimum to different resolutions or physical conditions; stability of predictions during extended autoregressive rollouts; claim that SFNO provides a "flexible, data-driven alternative" without quantifying deployment costs
- **Low confidence**: Claim that SFNO "captures complex solar wind dynamics" without establishing what specific physical processes are represented; absence of ablation studies on spectral mode selection or architectural hyperparameters

## Next Checks

1. **Cross-resolution validation**: Train and test SFNO models on downsampled and upsampled MAS grids (e.g., 70×56×64 and 280×222×256) to verify the 5-radius optimum and accuracy advantages hold across different resolutions
2. **Scheduled sampling experiment**: Replace teacher forcing with scheduled sampling during training (linearly increasing from 0% to 100% model predictions) and compare test-time accuracy degradation to assess distribution shift impacts
3. **Physics-constrained ablation**: Add L2 regularization on velocity divergence and cross-helicity to the loss function, then compare against the unconstrained SFNO to determine if explicit physical constraints improve predictions in high-gradient regions where the model currently struggles