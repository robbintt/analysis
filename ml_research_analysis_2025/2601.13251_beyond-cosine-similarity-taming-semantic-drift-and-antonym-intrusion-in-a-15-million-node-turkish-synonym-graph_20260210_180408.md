---
ver: rpa2
title: 'Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a
  15-Million Node Turkish Synonym Graph'
arxiv_id: '2601.13251'
source_url: https://arxiv.org/abs/2601.13251
tags:
- semantic
- synonym
- cluster
- training
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper tackles the challenge of building a large-scale, antonym-free
  synonym graph by addressing the fundamental limitation of embedding models: they
  conflate synonyms with antonyms and co-hyponyms under cosine similarity. To solve
  this, the authors develop a three-stage pipeline: (1) generate a large-scale, high-quality
  labeled dataset of 843k semantic relations using LLM-augmentation and dictionary
  integration; (2) train a three-way semantic relation classifier that achieves 90%
  macro-F1 (with 94% F1 on antonyms and co-hyponyms) to filter out non-synonyms; and
  (3) introduce a novel soft-to-hard clustering algorithm that uses topological voting
  to resolve polysemy and prevent semantic drift via intersection-ratio thresholds
  and confidence-based seeding.'
---

# Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph

## Quick Facts
- **arXiv ID:** 2601.13251
- **Source URL:** https://arxiv.org/abs/2601.13251
- **Reference count:** 29
- **Primary result:** 15M-term Turkish synonym graph with 2.9M clusters, 90% macro-F1 three-way classifier, explicit antonym filtering via intersection-ratio thresholds

## Executive Summary
The paper addresses the fundamental limitation of embedding models: conflating synonyms with antonyms and co-hyponyms under cosine similarity. To solve this, the authors develop a three-stage pipeline: (1) generate a large-scale, high-quality labeled dataset of 843k semantic relations using LLM-augmentation and dictionary integration; (2) train a three-way semantic relation classifier that achieves 90% macro-F1 (with 94% F1 on antonyms and co-hyponyms) to filter out non-synonyms; and (3) introduce a novel soft-to-hard clustering algorithm that uses topological voting to resolve polysemy and prevent semantic drift via intersection-ratio thresholds and confidence-based seeding. The result is a high-precision Turkish synonym graph of 2.9 million clusters from 15 million terms, with strong handling of morphosyntactic richness and domain-specific terminology.

## Method Summary
The authors construct a three-stage pipeline: first, they create 843k labeled semantic relations using LLM synthesis (98% synthetic, 2% dictionary-verified) from 110k expert-curated Turkish legal terms; second, they train a turkish-e5-large three-way classifier (Synonym/Antonym/Co-hyponym) achieving 90% macro-F1 to distinguish true synonyms from confusable relations; third, they build the synonym graph using FAISS retrieval (cosine ≥0.70) filtered by the classifier (confidence ≥0.70), then apply soft-to-hard clustering with intersection ratio ≥0.51 and topological voting to resolve polysemy. The final output is a JSON file containing 2.9 million clusters with parent selection based on dictionary entries and centroid-based fallback.

## Key Results
- 843k labeled semantic relation pairs (827k synthetic + 16k dictionary)
- Three-way classifier achieves 90% macro-F1 (94% F1 on antonyms and co-hyponyms)
- 15M terms reduced to 2.9M high-precision synonym clusters (median size 3, mean 4.58)
- Intersection-ratio threshold of ≥0.51 effectively prevents semantic drift chains

## Why This Works (Mechanism)

### Mechanism 1: Explicit Relation Classification Replaces Similarity Thresholding
- Claim: A trained three-way classifier can distinguish synonyms from antonyms and co-hyponyms more reliably than cosine similarity thresholds.
- Mechanism: The classifier learns decision boundaries over tokenized pair representations, capturing relational polarity (synonym vs. antonym) and categorical specificity (synonym vs. co-hyponym) that distributional similarity obscures.
- Core assumption: Labeled semantic relation data reflects true distinctions, and the model generalizes beyond training distribution.
- Evidence anchors:
  - [abstract] "three-way semantic relation discriminator that achieves 90% macro-F1... with 94% F1 on antonyms and co-hyponyms"
  - [section 4.3/Table 4] Per-class F1: Synonym 0.83, Antonym 0.92, Co-hyponym 0.94
  - [corpus] Related work (Bhav-Net, arXiv:2508.15792) confirms antonym-synonym distinction benefits from explicit architectures; corpus shows this is an active problem space but limited direct benchmarks for Turkish.
- Break condition: If classifier confidence calibration drifts (e.g., high confidence on systematic errors), filtering will admit false positives or reject valid synonyms.

### Mechanism 2: Intersection-Ratio Thresholds Interrupt Semantic Drift Chains
- Claim: Requiring ≥0.51 intersection ratio between a term's synonyms and cluster members prevents weak transitive chains from expanding clusters semantically.
- Mechanism: A term joins cluster C only if most of C's members are already its synonyms, blocking "bridge" terms that connect distant senses via one or two edges.
- Core assumption: Valid synonym clusters exhibit dense internal connectivity; drift paths are sparsely connected.
- Evidence anchors:
  - [abstract] "intersection-ratio thresholds and confidence-based seeding"
  - [section 3.5/Algorithm 1] Formal threshold: |synonyms(t) ∩ members(C)| / |members(C)| > 0.51
  - [corpus] SDEC (arXiv:2508.15823) notes high-dimensional semantic clustering challenges; doesn't directly validate this threshold.
- Break condition: If genuine synonym sets are sparse (low-density domains), the threshold may over-prune valid members.

### Mechanism 3: Topological Voting Resolves Polysemy Without Sense Induction
- Claim: A three-level voting scheme (majority rule → specificity → deterministic tiebreak) assigns polysemous terms to single clusters while preserving recall.
- Mechanism: Soft clustering permits temporary multi-cluster membership; voting uses synonym overlap counts and cluster size to select final assignment.
- Core assumption: Polysemous terms have asymmetric synonym distributions across senses (one sense dominates by neighbor count).
- Evidence anchors:
  - [abstract] "topological voting to resolve polysemy"
  - [section 3.5] "Majority Rule: arg max_C |synonyms(t) ∩ members(C)|; Specificity Principle: arg min_C |C|"
  - [corpus] No direct corpus validation for this specific voting scheme; Watset (Ustalov et al., 2017) cited as sense-aware alternative but noted computationally impractical at scale.
- Break condition: If a term's senses are equally well-represented in the graph, voting may arbitrarily select wrong sense.

## Foundational Learning

- **Distributional Hypothesis and Its Limits**
  - Why needed here: Cosine similarity fails because antonyms and co-hyponyms share contexts with synonyms.
  - Quick check question: Can you explain why "hot" and "cold" might have high cosine similarity despite opposite meanings?

- **Transitivity in Graph Clustering**
  - Why needed here: Semantic drift arises when valid local edges create invalid global chains.
  - Quick check question: Given edges (A→B, B→C, C→D) where each pair is similar, what could go wrong if you assume transitivity holds?

- **Soft vs. Hard Clustering Trade-offs**
  - Why needed here: Hard partitions misassign polysemous terms; soft clustering requires resolution.
  - Quick check question: What information would you need to decide which cluster "yüz" (face/100) belongs to?

## Architecture Onboarding

- **Component map:**
  turkish-e5-large fine-tuning -> FAISS GPU index -> Three-way classifier -> Confidence + symmetry + conflict filters -> Soft-to-hard clustering (intersection ratio ≥0.51 + topological voting) -> Parent selection -> JSON output

- **Critical path:**
  1. Dataset quality → classifier accuracy → edge filtering quality
  2. Intersection-ratio threshold → cluster coherence vs. recall
  3. Voting logic → polysemy resolution correctness

- **Design tradeoffs:**
  - Recall vs. precision: Initial cosine threshold 0.70 (permissive) compensated by strict classifier filtering
  - Scale vs. sense induction: Soft-to-hard approach approximates sense-awareness without full Watset-style cost
  - LLM labels vs. human curation: 827k synthetic + 16k dictionary pairs; assumes LLM reliability (validated downstream by 90% F1)

- **Failure signatures:**
  - High classifier confidence but low synonym F1 → label noise in training data
  - Large clusters (>50 members) → intersection ratio too low or voting not triggered
  - Asymmetric edge predictions → conflict filter may discard valid pairs if classifier is inconsistent on (A,B) vs. (B,A)

- **First 3 experiments:**
  1. Ablate the intersection-ratio threshold (test 0.40, 0.51, 0.70) on a held-out cluster quality metric (e.g., manual annotation of 500 random clusters).
  2. Evaluate classifier calibration: plot confidence vs. accuracy on a stratified validation subset to confirm 0.70 threshold appropriateness.
  3. Test voting logic on known polysemous terms (e.g., "yüz") and compare sense assignment against manual gold labels.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed pipeline generalize to other morphologically rich, low-resource languages beyond Turkish?
- Basis in paper: [explicit] Future work states: "extending the approach to additional morphologically rich languages" and claims methodology requires only "FastText embeddings, LLM API access, and basic dictionary resources—components available for hundreds of languages."
- Why unresolved: The entire experimental validation is on Turkish only; no cross-linguistic experiments were conducted.
- What evidence would resolve it: Application of the same pipeline to languages like Finnish, Hungarian, or Arabic, reporting F1 scores and cluster quality metrics.

### Open Question 2
- Question: How reliable are LLM-generated semantic relation labels without direct human verification?
- Basis in paper: [inferred] 98% of the training data (827k/843k pairs) comes from Gemini 2.5-Flash with only 16k dictionary-verified pairs. While the classifier achieves 90% F1, this doesn't validate the ground truth quality of LLM labels.
- Why unresolved: No human evaluation of LLM-generated labels is reported; classifier performance reflects train-test consistency, not label accuracy.
- What evidence would resolve it: Human annotation sample of LLM-generated pairs, measuring inter-annotator agreement against LLM labels.

### Open Question 3
- Question: How should the synonym graph be updated dynamically as terminology evolves?
- Basis in paper: [explicit] Future work mentions "developing dynamic update mechanisms to maintain temporal validity as terminology evolves."
- Why unresolved: The current pipeline is static; no incremental update or temporal validity mechanism is proposed or tested.
- What evidence would resolve it: A temporal evaluation measuring cluster decay and proposing/evaluating an incremental update strategy.

### Open Question 4
- Question: How sensitive are the clustering results to the 0.51 intersection ratio threshold and 0.70 confidence threshold?
- Basis in paper: [inferred] The paper fixes these thresholds without ablation; the intersection ratio of ≥0.51 is presented as preventing "weak transitive chains" but alternative values are not explored.
- Why unresolved: No ablation study on threshold sensitivity is reported.
- What evidence would resolve it: Systematic ablation varying thresholds and reporting cluster coherence metrics (e.g., intra-cluster similarity, antonym intrusion rate).

## Limitations

- The 90% macro-F1 classifier performance relies on synthetic LLM-generated labels without independent human validation, creating potential label noise not captured by F1 metrics.
- The intersection-ratio threshold of 0.51 is empirically chosen but not systematically validated across different domains or languages; semantic drift prevention effectiveness is assumed rather than proven through ablation studies.
- Polysemy resolution via topological voting lacks gold-standard evaluation—while the mechanism is logically sound, actual sense assignment accuracy for highly polysemous words remains unmeasured.

## Confidence

- **High confidence:** The three-stage pipeline architecture is coherent and addresses documented weaknesses in embedding-based clustering. The 90% F1 classifier performance on antonyms and co-hyponyms is verifiable through reported metrics.
- **Medium confidence:** The intersection-ratio threshold effectively prevents semantic drift as claimed, though the specific 0.51 value lacks systematic justification. The topological voting mechanism for polysemy is reasonable but unvalidated on gold standards.
- **Low confidence:** Claims about handling "15 million terms" at scale are based on computational feasibility rather than empirical quality assessment of the full graph. The final graph quality (2.9M clusters) is asserted without independent evaluation.

## Next Checks

1. Perform ablation study on intersection-ratio threshold (test 0.40, 0.51, 0.70) using manual annotation of 500 randomly sampled clusters to measure semantic drift vs. recall trade-offs.
2. Conduct independent human evaluation of classifier-labeled pairs (e.g., 1000 random pairs) to validate the 90% F1 claim and detect systematic labeling errors in the synthetic dataset.
3. Evaluate polysemy resolution accuracy on known polysemous terms (e.g., "yüz") by comparing topological voting assignments against expert-annotated sense distinctions.