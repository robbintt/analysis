---
ver: rpa2
title: Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace
arxiv_id: '2508.05661'
source_url: https://arxiv.org/abs/2508.05661
tags:
- search
- image
- visual
- retrieval
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a scalable visual search system for Mercari\u2019\
  s consumer-to-consumer marketplace using zero-shot vision-language models. The system\
  \ employs multilingual SigLIP embeddings and dimensionality reduction (768D \u2192\
  \ 128D) to balance retrieval effectiveness and efficiency."
---

# Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace

## Quick Facts
- arXiv ID: 2508.05661
- Source URL: https://arxiv.org/abs/2508.05661
- Authors: Andre Rusli; Shoma Ishimoto; Sho Akiyama; Aman Kumar Singh
- Reference count: 10
- Primary result: 13.3% improvement in nDCG@5 over fine-tuned baseline

## Executive Summary
This paper presents a scalable visual search system for Mercari's C2C marketplace using zero-shot vision-language models. The system employs multilingual SigLIP embeddings with dimensionality reduction (768D → 128D) to balance retrieval effectiveness and efficiency. A one-week A/B test demonstrated substantial improvements: 40.9% increase in transactions per user, 34.1% higher conversion rate, and 46.6% more item views through image search.

## Method Summary
The system uses zero-shot vision-language models (SigLIP) to generate embeddings for product images, which are then reduced from 768 dimensions to 128 dimensions for efficient retrieval. The approach leverages multilingual embeddings to handle Mercari's diverse marketplace. Offline evaluation on 10,000 search sessions showed a 13.3% improvement in nDCG@5 compared to a fine-tuned baseline model.

## Key Results
- 13.3% improvement in nDCG@5 over fine-tuned baseline in offline evaluation
- 40.9% increase in transactions per user in one-week A/B test
- 34.1% higher conversion rate and 46.6% more item views via image search

## Why This Works (Mechanism)
The zero-shot approach eliminates the need for category-specific training data while maintaining high retrieval quality. By using vision-language models, the system can understand semantic relationships between products beyond simple visual similarity. The dimensionality reduction from 768D to 128D enables efficient real-time retrieval without significant quality loss. Multilingual embeddings handle the diverse product descriptions in Mercari's marketplace.

## Foundational Learning
- **Vision-language models**: Combine visual and textual understanding in a single model. Needed for capturing semantic relationships between products. Quick check: Test retrieval on visually similar but semantically different items.
- **Dimensionality reduction**: Techniques to compress high-dimensional embeddings while preserving similarity relationships. Required for efficient similarity search at scale. Quick check: Compare retrieval quality at different dimensions (64D, 128D, 256D).
- **Offline evaluation metrics**: nDCG, recall@k measure retrieval effectiveness. Essential for comparing different approaches before deployment. Quick check: Validate metric improvements correlate with business outcomes.
- **A/B testing framework**: Controlled experiments to measure real-world impact. Critical for proving business value of technical improvements. Quick check: Ensure statistical significance with proper sample sizes.
- **Embedding-based retrieval**: Use vector similarity for search instead of traditional keyword matching. Enables visual search without text metadata. Quick check: Compare with text-only retrieval baseline.
- **Multilingual embeddings**: Handle multiple languages in a single model. Necessary for global marketplaces with diverse sellers and buyers. Quick check: Test retrieval quality across different language pairs.

## Architecture Onboarding

**Component map**: User Image -> SigLIP Model -> 768D Embedding -> Dimensionality Reduction -> 128D Embedding -> Vector Database -> Retrieved Products

**Critical path**: Image upload → SigLIP embedding generation → 128D projection → vector similarity search → result ranking → display to user

**Design tradeoffs**: Zero-shot approach trades potential fine-tuning gains for flexibility and lower maintenance. Dimensionality reduction sacrifices some precision for retrieval speed. The system focuses solely on image search, potentially missing users who prefer text queries.

**Failure signatures**: Poor retrieval for entertainment/character goods due to identity matching challenges. Performance degradation when visual features are insufficient to distinguish similar products. Limited effectiveness for new categories without representative training images.

**First 3 experiments**:
1. Compare different dimensionality reduction techniques (PCA, product quantization) on retrieval quality
2. Test retrieval performance across different product categories to identify weak spots
3. Evaluate the impact of image quality/resolution on embedding quality and retrieval results

## Open Questions the Paper Calls Out
None

## Limitations
- Dimensionality reduction approach lacks comparative analysis of alternative compression strategies
- System relies solely on image search without incorporating textual or hybrid retrieval methods
- Identity matching remains challenging for entertainment and character goods categories

## Confidence
- 13.3% nDCG@5 improvement: High
- 40.9% increase in transactions per user: High
- 34.1% higher conversion rate: High
- Dimensionality reduction effectiveness: Medium
- Long-term sustainability of improvements: Medium

## Next Checks
1. Conduct a longer-term A/B test (minimum 4 weeks) to assess sustained performance and seasonality effects
2. Evaluate the system's robustness across diverse marketplace categories, particularly entertainment and character goods where identity matching remains challenging
3. Benchmark alternative dimensionality reduction techniques (e.g., PCA, product quantization) to optimize the trade-off between retrieval quality and computational efficiency