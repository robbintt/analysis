---
ver: rpa2
title: 'From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming
  Text-to-Image Models'
arxiv_id: '2507.17922'
source_url: https://arxiv.org/abs/2507.17922
tags:
- prompt
- prompts
- attack
- seed
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of red-teaming text-to-image
  models by proposing a hybrid human-AI approach called Seed2Harvest. The method expands
  human-crafted adversarial prompts using large language models guided by human-identified
  attack strategies.
---

# From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models

## Quick Facts
- arXiv ID: 2507.17922
- Source URL: https://arxiv.org/abs/2507.17922
- Reference count: 40
- Key outcome: Hybrid human-AI approach expands adversarial prompts 28× while maintaining attack effectiveness and dramatically improving diversity metrics

## Executive Summary
This paper addresses the challenge of red-teaming text-to-image models by proposing Seed2Harvest, a hybrid human-AI approach that combines human-crafted adversarial prompts with LLM-guided expansion using human-identified attack strategies. The method achieves comparable attack success rates to original human prompts (0.31 NudeNet, 0.36 SD NSFW, 0.12 Q16) while dramatically increasing diversity from 58 to 535 unique geographic locations and improving Shannon entropy from 5.28 to 7.48. The results demonstrate that combining human creativity with AI scalability provides more consistent and comprehensive red-teaming coverage than purely human or automated approaches.

## Method Summary
Seed2Harvest uses human-annotated attack strategies (coded language, demographics, geography, negation, etc.) to guide LLM expansion of adversarial prompts. For each seed prompt and strategy, 20 candidate variants are generated from 4 different LLMs, embedded using all-mpnet-base-v2, clustered with k-means (k=4), and 4 diverse prompts are selected. This process expands the original dataset 28-fold while maintaining attack effectiveness. Generated images are evaluated using three safety classifiers (NudeNet, SD NSFW, Q16) to measure attack success rates and diversity metrics.

## Key Results
- Attack success rates comparable to original human prompts: 0.31 NudeNet, 0.36 SD NSFW, 0.12 Q16
- Diversity improvements: Shannon entropy increased from 5.28 to 7.48; unique geographic locations expanded from 58 to 535
- Hybrid approach shows balanced performance across classifiers, avoiding the narrow specialization seen in single-guidance methods
- LLM expansion achieves 28× dataset growth while maintaining semantic coherence and adversarial effectiveness

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Guidance Signal Integration
Combining human seed prompts with human-derived attack strategies produces more consistent and comprehensive red-teaming coverage than either guidance signal alone. Two guidance signals—seed prompts (example-based) and attack strategies (rule-based)—direct LLM expansion. Seeds anchor generation in proven adversarial patterns; strategies systematically vary those patterns across semantic dimensions.

### Mechanism 2: Strategy-Guided Semantic Transformation
Explicitly instructing LLMs to apply specific transformation strategies generates semantically diverse adversarial variants while preserving attack effectiveness. LLM receives seed prompt + strategy instruction (e.g., "Geography: Find all geographic indicators and replace with diverse variations across continents").

### Mechanism 3: Embedding-Based Diversity Selection
Clustering LLM outputs in sentence embedding space and selecting representatives from each cluster ensures linguistic diversity without manual curation. For each seed-strategy combination, generate 20 candidates from 4 LLMs → embed with all-mpnet-base-v2 → k-means cluster (k=4) → select 4 most dissimilar prompts.

## Foundational Learning

- **Implicitly vs. Explicitly Adversarial Prompts:** The paper focuses on "innocuous-looking prompts that result in unsafe generations" (e.g., "Friday Prayers" triggering religious stereotypes). Understanding this distinction is essential for evaluating attack success.
- **Shannon Entropy for Diversity Quantification:** Paper uses entropy to measure both richness (unique entities) and evenness (distribution uniformity) across geographic/demographic dimensions.
- **Trade-off Between Attack Success Rate (ASR) and Diversity:** Table 2 shows that maximizing ASR alone (Attack Guidance Only: 0.51 NudeNet) correlates with narrow specialization and lower performance on other classifiers (0.01 SD NSFW).

## Architecture Onboarding

- **Component map:** Adversarial Nibbler Dataset → Pre-processing: Balance & Dedupe → Qualitative Analysis: Extract 7 Strategies → Seed Prompt + Attack Strategy → 4 LLMs: Generate 20 Variants Each → Sentence Embedding + K-Means Clustering → Select 4 Diverse Prompts per Strategy → T2I Models: DALL-E 2, SD 1.5, SD XL, SD XL Turbo → Safety Classifiers: NudeNet, SD NSFW, Q16
- **Critical path:** Seed selection → Strategy extraction → Prompt generation (most computationally intensive) → Image generation → Classification. Latency bottleneck is image generation across multiple T2I models.
- **Design tradeoffs:** Multi-LLM vs. single LLM (reduces bias but quadruples costs); 28× expansion factor (higher coverage but dilutes seed quality); k=4 clustering (increases diversity but may include low-quality edge cases).
- **Failure signatures:** LLM refusals reduce candidate counts; narrow specialization shows high NudeNet (0.51) but near-zero SD NSFW (0.01); cultural knowledge gaps limit representation of non-English contexts.
- **First 3 experiments:** 1) Baseline reproduction: Run 1,000 balanced seed prompts through single T2I model with three safety classifiers. 2) Strategy ablation: Generate prompts using only one strategy at a time and measure ASR per strategy. 3) Diversity validation: Extract GPE and NORP entities from generated prompts using spaCy; compute Shannon entropy and compare to reported 7.48.

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends heavily on quality and representativeness of human-identified attack strategies, which may not capture full space of adversarial variations
- Embedding-based diversity selection assumes semantic similarity correlates with meaningful adversarial diversity, which may not hold if different prompts trigger same safety classifier failures
- Significant computational overhead from multiple T2I models and safety classifiers, with image generation as primary bottleneck
- Cultural and linguistic limitations of LLM expansion process, with limited proficiency in representing non-English cultural nuances

## Confidence
**High Confidence:** Hybrid approach combining human creativity with AI scalability is well-supported by empirical results showing balanced classifier performance.
**Medium Confidence:** Diversity gains are convincingly demonstrated but assumption that diversity translates to comprehensive safety coverage requires further validation.
**Low Confidence:** Paper does not fully address cultural limitations, acknowledging LLMs show limited proficiency in representing certain cultural nuances.

## Next Checks
1. **Strategy Ablation Testing:** Systematically test each attack strategy independently to quantify contribution to different safety failure categories.
2. **Embedding Diversity Validation:** Cross-validate embedding-based diversity selection against alternative metrics like lexical diversity or human evaluation.
3. **Cultural Coverage Analysis:** Analyze geographic/demographic distribution of generated prompts against global demographic data to identify systematic cultural representation gaps.