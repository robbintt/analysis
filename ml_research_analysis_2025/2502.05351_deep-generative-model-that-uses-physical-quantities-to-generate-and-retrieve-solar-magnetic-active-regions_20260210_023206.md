---
ver: rpa2
title: Deep Generative model that uses physical quantities to generate and retrieve
  solar magnetic active regions
arxiv_id: '2502.05351'
source_url: https://arxiv.org/abs/2502.05351
tags:
- data
- physical
- real
- images
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a deep generative model pipeline to create and
  retrieve solar magnetic active regions using physical quantities. The authors train
  a GAN on SHARP solar magnetic patch data, then use SVMs to map physical parameters
  (total unsigned field, polarity separation, field near polarity inversion lines)
  to GAN latent space directions.
---

# Deep Generative model that uses physical quantities to generate and retrieve solar magnetic active regions

## Quick Facts
- arXiv ID: 2502.05351
- Source URL: https://arxiv.org/abs/2502.05351
- Reference count: 1
- Key outcome: GAN-SVM-SimSiam pipeline generates solar magnetic patches with controlled physical properties and retrieves real matches with Pearson correlation ~0.78-0.79 for total unsigned field.

## Executive Summary
This paper presents a deep generative model pipeline that creates and retrieves solar magnetic active regions using physical quantities. The authors train a GAN on SHARP solar magnetic patch data, then use SVMs to map physical parameters (total unsigned field, polarity separation, field near polarity inversion lines) to GAN latent space directions. This allows physically interpretable generation of magnetic patches that can be smoothly varied along specific physical parameters. They also train a SimSiam self-supervised model to find matches between generated patches and real data in the latent space.

## Method Summary
The method involves training a GAN to generate 128×128 solar magnetic patches from 100-dimensional latent vectors. The GAN is trained on SHARP data for 200 epochs with a CNN decoder/generator and discriminator. After training, 10,000 images are generated and physical parameters (TUF, PSEP, R) are computed. Linear SVMs are trained on these parameters (median-split binary labels) to extract decision boundary normal vectors that define latent directions for parameter manipulation. A SimSiam model is trained on real SHARP patches to learn 100-dimensional invariant representations for retrieval. Generated patches are encoded and matched to real data via cosine similarity.

## Key Results
- GAN successfully generates realistic magnetic patches that can be smoothly varied along physical parameters using SVM-derived latent directions
- Generated patches retrieve real matching data with strong correlations: Pearson ~0.78-0.79 for total unsigned field, ~0.73 for R, ~0.28 for PSEP, ~0.69-0.72 for other metrics
- Conditional manipulation via orthogonal decomposition partially decouples correlated parameters like TUF and R
- SimSiam representations enable effective retrieval despite geometric variations (translation, rotation, zoom)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Training SVMs on GAN latent vectors with binary labels yields decision boundary normals corresponding to physically meaningful directions in latent space.
- **Mechanism:** The GAN's generator learns to map latent vectors to magnetic patches that implicitly encode physical properties. By generating 10,000 images, computing physical parameters, and training SVMs to separate high/low values in latent space, the hyperplane normal vector $\hat{n}_p$ defines a direction along which that parameter changes. Shifting a latent vector as $z_{shift} = z + \epsilon\hat{n}$ produces images with smoothly varying physical properties.
- **Core assumption:** The GAN has captured physical structure in its latent space such that physical parameters vary smoothly and approximately linearly along some latent directions.
- **Evidence anchors:** SVM decision boundaries successfully separate high/low physical parameter values in latent space, enabling controlled manipulation.

### Mechanism 2
- **Claim:** Conditional manipulation via orthogonal decomposition can disentangle correlated physical parameters during latent space navigation.
- **Mechanism:** Physical parameters are often correlated (e.g., TUF and R). The paper uses orthogonal projection: $\hat{n}_{new} = \hat{n}_{TUF} - (\hat{n}_{TUF} \cdot \hat{n}_R)\hat{n}_R$ to remove the component of one direction from another. For multiple constraints, they use subspace projection $x - A(A^TA)^{-1}A^Tx$ where $A$ contains conditional boundary vectors.
- **Core assumption:** The SVM-derived directions span a space where physical parameters can be approximately independently controlled via linear combinations.
- **Evidence anchors:** Positive shifts along $\hat{n}_U$ increases R, but orthogonal decomposition partially mitigates this effect.

### Mechanism 3
- **Claim:** SimSiam-trained representations enable generated images to retrieve real observations with matching physical properties.
- **Mechanism:** SimSiam learns 100-dimensional latent representations invariant to specified augmentations (translation, zoom, rotation, flip). By encoding both generated queries and real SHARP patches into this shared space, nearest-neighbor search via negative cosine similarity retrieves real patches with similar morphology and physical characteristics.
- **Core assumption:** The SSL-learned representations capture physically relevant features such that semantically similar magnetic patches cluster together regardless of minor geometric variations.
- **Evidence anchors:** 2-dimensional histogram of TUF shows one-to-one correspondence between generated queries and real matches (Pearson ~0.78-0.79).

## Foundational Learning

- **Concept: Generative Adversarial Networks (GANs)**
  - **Why needed here:** Core of the pipeline; generates synthetic magnetic patches from noise vectors.
  - **Quick check question:** Can you explain why the discriminator's ability to distinguish real from fake improves the generator's outputs?

- **Concept: Support Vector Machines and hyperplane decision boundaries**
  - **Why needed here:** Maps physical parameters to latent directions; requires understanding of how SVMs find separating hyperplanes and how normal vectors define boundary directions.
  - **Quick check question:** Given a trained linear SVM separating two classes, how would you extract the direction vector normal to the decision boundary?

- **Concept: Self-supervised learning and contrastive objectives**
  - **Why needed here:** SimSiam learns representations without labels using augmentation invariance; understanding negative cosine similarity loss is essential.
  - **Quick check question:** Why does minimizing negative cosine similarity between augmented views of the same image encourage invariant representations?

## Architecture Onboarding

- **Component map:** GAN Generator (100D noise → 128×128 patch) -> SVM Module (extract latent directions) -> SimSiam Backbone (learn invariant representations) -> Retrieval Module (cosine similarity search)

- **Critical path:**
  1. Train GAN on SHARP patches (200 epochs, batch 32, lr 0.0005)
  2. Generate 10,000 images → compute physical parameters → train SVMs
  3. Train SimSiam on SHARP patches with augmentation pipeline
  4. For inference: sample $z$ → shift via SVM direction → generate → encode → retrieve nearest real match

- **Design tradeoffs:**
  - **Latent dimension (100D):** Higher dimensions may capture more variability but make SVM boundary learning harder
  - **SVM vs. regression for latent mapping:** Binary classification chosen; regression could enable quantitative control but may be less robust
  - **Augmentation range:** Rotation ±20°, zoom 0.8-1.2; broader ranges may break physical meaning (e.g., large rotations flip polarity interpretation)

- **Failure signatures:**
  - GAN mode collapse: limited diversity in generated patches
  - SVM overfitting: decision boundaries that don't generalize to held-out latent vectors
  - SimSiam collapse: trivial solutions where all inputs map to same representation
  - Poor retrieval correlation: Pearson <0.5 suggests latent space misalignment

- **First 3 experiments:**
  1. **GAN quality validation:** Generate 100 random patches; compute TUF distribution and compare to SHARP training data distribution to verify coverage
  2. **SVM direction sanity check:** For each SVM, generate a base image, shift along $\hat{n}_p$ with $\epsilon \in \{-2, -1, 0, 1, 2\}$, verify parameter $p$ changes monotonically
  3. **Retrieval calibration:** Generate 100 queries with known TUF values; retrieve matches; plot generated vs. retrieved TUF; target Pearson >0.7

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the latent space shifts be calibrated to exact physical units (e.g., Maxwells) rather than arbitrary vector magnitudes?
- **Basis in paper:** The authors state, "In the future, we would like to improve our software to use numerical values of physical parameters (e.g., calibrate the change... to the value in actual physical units in Mx)."
- **Why unresolved:** The current implementation shifts the latent vector $z$ by an arbitrary $\epsilon$ along a normal vector, which changes the physical quantity qualitatively but does not equate to a specific physical unit.
- **What evidence would resolve it:** A derived function mapping $\epsilon$ to $\Delta$Mx that generates images with the predicted magnetic flux within a defined error margin.

### Open Question 2
- **Question:** Does the low retrieval correlation for polarity separation (PSEP) arise specifically from the metric's sensitivity to complex multipolar regions?
- **Basis in paper:** The authors note the "relatively poor correlation in PSEP" (0.28) is likely due to "small-scale features and complex multipolar regions that drive the calculation of field-strength-weighted centroids," suggesting "A better polarity separation measure should cause an improvement."
- **Why unresolved:** The current centroid-based metric becomes unstable in complex regions where distinct poles are difficult to define, whereas the generative model may handle these structures better than the metric does.
- **What evidence would resolve it:** Re-evaluating retrieval performance using a polarity metric robust to structural complexity, resulting in a significantly higher correlation coefficient.

### Open Question 3
- **Question:** Can the entanglement of physical parameters (e.g., Total Unsigned Field and R) in the latent space be fully resolved?
- **Basis in paper:** The authors observe that "physical properties are often entangled" and their conditional manipulation method using orthogonal decomposition only "partially mitigated" the issue.
- **Why unresolved:** The SVM-derived linear directions in the high-dimensional latent space may not perfectly align with the non-linear, coupled manifolds representing distinct physical features.
- **What evidence would resolve it:** A manipulation method that alters one parameter (e.g., TUF) while demonstrating statistically zero variance in dependent parameters (e.g., R) across the generated dataset.

## Limitations
- Linear SVM boundaries may not capture complex non-linear relationships between physical parameters and latent space directions
- Orthogonal decomposition for conditional manipulation only partially decouples correlated parameters like TUF and R
- SimSiam retrieval effectiveness depends heavily on augmentation pipeline and may not generalize to all magnetic configurations

## Confidence
- **High Confidence:** GAN's ability to generate realistic magnetic patches and the overall pipeline architecture (GAN → SVM → SimSiam)
- **Medium Confidence:** The effectiveness of linear SVM directions for physical parameter manipulation is demonstrated but may not generalize to all parameter combinations or extreme values
- **Medium Confidence:** SimSiam retrieval performance (Pearson ~0.78-0.79 for TUF) is promising but requires validation on independent datasets and with different augmentation strategies

## Next Checks
1. **Parameter Entanglement Analysis:** Systematically evaluate parameter correlation changes during latent traversals along single SVM directions to quantify entanglement and validate orthogonal decomposition effectiveness
2. **Cross-Validation of Retrieval:** Test retrieval performance on held-out SHARP regions not seen during SimSaim training to assess generalization to novel magnetic configurations
3. **Alternative Parameter Mapping:** Compare SVM-based linear mapping with regression-based approaches to determine if non-linear parameter control improves physical property manipulation precision