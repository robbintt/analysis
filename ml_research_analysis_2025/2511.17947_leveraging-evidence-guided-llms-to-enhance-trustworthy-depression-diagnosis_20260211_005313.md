---
ver: rpa2
title: Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression Diagnosis
arxiv_id: '2511.17947'
source_url: https://arxiv.org/abs/2511.17947
tags:
- reasoning
- diagnostic
- diagnosis
- score
- egdr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a two-stage framework to improve the trustworthiness
  and transparency of LLM-based depression diagnosis. The first stage, Evidence-Guided
  Diagnostic Reasoning (EGDR), uses structured prompts to guide LLMs in generating
  diagnostic hypotheses aligned with DSM-5 criteria.
---

# Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression Diagnosis

## Quick Facts
- arXiv ID: 2511.17947
- Source URL: https://arxiv.org/abs/2511.17947
- Reference count: 31
- Primary result: EGDR improves accuracy by up to 45% over baselines; DCS improves by up to 36% with optimal KAS/LCS weighting.

## Executive Summary
This paper introduces a two-stage framework to improve the trustworthiness and transparency of LLM-based depression diagnosis. The first stage, Evidence-Guided Diagnostic Reasoning (EGDR), uses structured prompts to guide LLMs in generating diagnostic hypotheses aligned with DSM-5 criteria. The second stage, Diagnosis Confidence Scoring (DCS), evaluates these hypotheses using Knowledge Attribution Score (KAS) and Logic Consistency Score (LCS). Tested on the D4 dataset with pseudo-labels, EGDR improved accuracy by up to 45% over baselines, with DCS increasing by up to 36%. On OpenBioLLM, accuracy rose from 0.31 to 0.76 and DCS from 0.50 to 0.67. On MedLlama, DCS improved from 0.58 (CoT) to 0.77. The framework offers interpretable, clinically grounded AI-assisted diagnosis.

## Method Summary
The framework consists of two stages: EGDR and DCS. EGDR uses structured multi-turn prompts to extract symptoms from dialogue, retrieve DSM-5 knowledge graph triplets, evaluate diagnostic criteria, check exclusion criteria, and output a diagnosis with reasoning. DCS evaluates this reasoning using KAS, which quantifies factual grounding by comparing claims against DSM-5 triplets, and LCS, which enforces rule-based diagnostic validity. The framework was tested on four LLMs (MedLlama, Claude, DeepSeek, OpenBioLLM, Gemini) using the D4 dataset with GPT-4o-mini pseudo-labels.

## Key Results
- EGDR improved accuracy by 36% on MedLlama (0.58→0.77 DCS) and 45% on OpenBioLLM (0.31→0.76 accuracy)
- DCS achieved optimal performance at λ=0.75 (KAS:LCS=3:1), with mean DCS of 0.94 at λ=1
- DCS correlated with accuracy: high DCS cases showed correct diagnoses; low DCS cases often reflected incomplete symptom extraction or KG coverage gaps

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured evidence-guided prompting improves diagnostic accuracy by interleaving symptom extraction with criterion-based reasoning.
- Mechanism: EGDR decomposes diagnosis into sequential steps—symptom extraction from dialogue, criterion matching via knowledge graph, exclusion verification, and final synthesis—forcing the LLM to ground each inference in DSM-5 entities rather than free-form reasoning.
- Core assumption: LLMs perform better when reasoning is explicitly scaffolded by domain knowledge structures rather than left implicit.
- Evidence anchors:
  - [abstract] "EGDR guides LLMs to generate structured diagnostic hypotheses by interleaving evidence extraction and logical reasoning, grounded in DSM-5 criteria."
  - [section IV-B] "The most substantial improvement is observed in OpenBioLLM, where EGDR achieves a 0.45 gain in accuracy over Direct prompting (0.76 vs. 0.31)."
  - [corpus] Related work (MLlm-DR, arXiv:2507.05591) similarly finds that multimodal LLMs require structured pathways for explainable depression recognition.
- Break condition: If DSM-5 knowledge graph triplets are incomplete or symptom descriptions in dialogue are ambiguous, retrieval may fail to match relevant criteria.

### Mechanism 2
- Claim: Knowledge Attribution Score (KAS) quantifies factual grounding by comparing decomposed claims against retrieved DSM-5 triplets.
- Mechanism: Claims are decomposed into atomic units, matched to knowledge graph triplets via entity extraction (NER) and semantic similarity (BERT embeddings), then classified as attributable, extrapolatory, contradictory, or no attribution before aggregation via sigmoid.
- Core assumption: Claim-level verification against structured knowledge correlates with diagnostic validity.
- Evidence anchors:
  - [section III-B] "KAS measures the factual alignment of individual diagnostic claims with the DSM-5 knowledge graph, combining symbolic matching and neural semantic similarity."
  - [section IV-D] "At λ=1 (KAS only), mean DCS reaches 0.9382, but this can reflect locally plausible yet globally inconsistent outputs."
  - [corpus] Corpus lacks direct replications of KAS-style triplet attribution for diagnosis; closest is ClaimVer (cited) for general claim verification.
- Break condition: If claims use paraphrased medical terminology not captured in the knowledge graph, semantic similarity may yield false positives.

### Mechanism 3
- Claim: Logic Consistency Score (LCS) enforces rule-based diagnostic validity beyond individual claim accuracy.
- Mechanism: DSM-5 criteria are encoded as executable functions checking symptom counts, core symptom presence, and exclusions; LLM reasoning traces are evaluated against these rules on a 0–3 scale.
- Core assumption: Valid diagnosis requires global logical coherence, not just locally correct claims.
- Evidence anchors:
  - [section III-B] "Each DSM-5 disorder criterion is encoded as an executable function that explicitly captures the required symptom count, presence of core symptoms, and any exclusionary conditions."
  - [section V] "At λ=0 (LCS only), the mean DCS drops to 0.57, showing that LCS alone is brittle."
  - [corpus] No corpus papers implement LCS-style rule verification for DSM-5 logic; related work focuses on retrieval or prompting, not executable criterion encoding.
- Break condition: If symptom extraction from dialogue is incomplete, logic verification will correctly penalize but cannot recover missing evidence.

## Foundational Learning

- Concept: **DSM-5 Diagnostic Criteria Structure**
  - Why needed here: EGDR and LCS both rely on understanding that DSM-5 diagnoses require specific symptom counts, mandatory core symptoms, and exclusion rules.
  - Quick check question: Can you name the minimum symptom count and core symptom requirement for Major Depressive Disorder diagnosis?

- Concept: **Knowledge Graph Triplet Representation**
  - Why needed here: KAS uses entity-relation-entity triplets (e.g., "MDD → has symptom → depressed mood") for retrieval and matching.
  - Quick check question: How would you represent "MDD excludes substance-induced depressive disorder" as a triplet?

- Concept: **Claim Decomposition and Verification**
  - Why needed here: KAS requires breaking diagnostic reasoning into atomic, verifiable claims before matching to knowledge.
  - Quick check question: Given the reasoning "Patient has 4 symptoms over 2 weeks, meeting MDD criteria," what atomic claims would you extract?

## Architecture Onboarding

- Component map:
  Input: Multi-turn patient-clinician dialogue D
  Stage 1 (EGDR): LLM with structured prompt → symptom extraction → KG retrieval → criterion evaluation → exclusion check → diagnosis + reasoning R
  Stage 2 (DCS): R → NER entity extraction → triplet retrieval (WoolNet) → claim decomposition → KAS (semantic + symbolic scoring) + LCS (rule execution) → weighted aggregation → DCS score
  Output: Diagnosis label + confidence score (0–1)

- Critical path:
  1. Dialogue → symptom extraction (must capture all relevant symptoms)
  2. Symptoms → KG triplet retrieval (must return correct disorder candidates)
  3. R → claim decomposition (claims must be atomic and verifiable)
  4. Claims → KAS/LCS scoring (both must align for high DCS)

- Design tradeoffs:
  - **α (TMS weight)**: Higher α favors semantic similarity (more forgiving to paraphrase), lower α favors entity precision (stricter). Paper uses α=0.5.
  - **λ (DCS aggregation)**: Higher λ trusts KAS (local claim accuracy), lower λ trusts LCS (global logic). Paper uses λ=0.75.
  - **Assumption**: Pseudo-labels from GPT-4o-mini serve as reliable ground truth; this is unvalidated against human experts.

- Failure signatures:
  - Low KAS + high LCS: Claims are logically coherent but not grounded in DSM-5 knowledge (hallucinated rationale).
  - High KAS + low LCS: Individual claims are accurate but overall logic fails (e.g., symptom count below threshold).
  - Both low: Model failed to extract symptoms or match criteria; check dialogue quality and prompt structure.

- First 3 experiments:
  1. **Reproduce EGDR on D4 subset (n=100)**: Implement the 5-step prompt pipeline (Figure 2), compare Direct vs. CoT vs. EGDR accuracy on pseudo-labels.
  2. **Ablate α and λ**: Sweep α ∈ {0.25, 0.5, 0.75} and λ ∈ {0.25, 0.5, 0.75} to observe DCS distribution shifts; verify paper's claim that α=0.5, λ=0.75 is optimal.
  3. **Case-level DCS analysis**: Select 5 correct and 5 incorrect predictions; manually inspect KAS/LCS component scores to validate that DCS discriminates diagnostic validity as claimed.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but acknowledges limitations including reliance on pseudo-labels rather than human expert annotations, potential biases in evaluation, and the need for validation on alternative clinical domains.

## Limitations
- Relies on pseudo-labels from GPT-4o-mini rather than human expert annotations, potentially introducing systematic biases
- DSM-5 knowledge graph coverage and triplet extraction methodology are not fully specified, limiting generalizability
- WoolNet triplet retrieval system is referenced but not described, limiting reproducibility

## Confidence
- **High confidence**: EGDR prompting structure improves diagnostic accuracy over baselines (45% gain on OpenBioLLM, 36% on MedLlama) - supported by direct comparisons in Table III
- **Medium confidence**: DCS effectively discriminates trustworthy diagnoses from unreliable ones - based on relative performance of ablated versions, though absolute calibration against human experts is unknown
- **Low confidence**: The framework generalizes beyond depression diagnosis and the specific D4 dataset - requires validation on alternative clinical domains and real-world diagnostic labels

## Next Checks
1. **Ground truth validation**: Compare EGDR/DCS outputs against a subset of D4 dialogues annotated by multiple human clinicians to assess alignment with expert diagnosis and calibration of confidence scores
2. **Ablation on knowledge graph coverage**: Systematically remove symptom-criterion triplets from the KG and measure degradation in KAS/LCS to quantify dependence on knowledge completeness
3. **Cross-dataset evaluation**: Apply the framework to MDDial or other clinical dialogue datasets with multi-diagnosis labels to test robustness across diagnostic categories and dialogue styles