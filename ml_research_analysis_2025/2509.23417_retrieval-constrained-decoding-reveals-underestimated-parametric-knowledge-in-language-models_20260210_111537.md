---
ver: rpa2
title: Retrieval-Constrained Decoding Reveals Underestimated Parametric Knowledge
  in Language Models
arxiv_id: '2509.23417'
source_url: https://arxiv.org/abs/2509.23417
tags:
- knowledge
- decoding
- language
- what
- llama-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Retrieval-Constrained Decoding (RCD), a\
  \ decoding strategy that improves the factual accuracy of language model outputs\
  \ by constraining generation to unique, disambiguated surface forms from a knowledge\
  \ base. The method addresses the issue of standard evaluations underestimating models\u2019\
  \ parametric knowledge due to alternative phrasing or partial correctness in answers."
---

# Retrieval-Constrained Decoding Reveals Underestimated Parametric Knowledge in Language Models

## Quick Facts
- **arXiv ID**: 2509.23417
- **Source URL**: https://arxiv.org/abs/2509.23417
- **Reference count**: 40
- **Primary result**: RCD improves factual accuracy by constraining outputs to unique surface forms from a knowledge base

## Executive Summary
This paper introduces Retrieval-Constrained Decoding (RCD), a decoding strategy that improves the factual accuracy of language model outputs by constraining generation to unique, disambiguated surface forms from a knowledge base. The method addresses the issue of standard evaluations underestimating models' parametric knowledge due to alternative phrasing or partial correctness in answers. RCD is evaluated using YAGO-QA, a new dataset of 19,137 general knowledge questions derived from YAGO, and compared against a challenging domain-specific KAMEL dataset. Across models from 135M to 70B parameters, RCD consistently outperforms vanilla decoding, with Llama-3.1-70B improving from 32.3% to 46.0% F1 on YAGO-QA. The results demonstrate that RCD elicits significantly more factual knowledge from language models than standard decoding, revealing that their parametric knowledge has been underestimated in prior evaluations.

## Method Summary
RCD works by first retrieving all objects associated with the subject-relation pair from a knowledge base, then using these unique surface forms as constraints during decoding. The method modifies the decoding process by maintaining a list of acceptable answer forms and rejecting any generation that doesn't match one of these forms. This approach addresses the problem of surface form variation in knowledge base questions, where the same fact can be expressed using different phrasings. The evaluation uses exact string matching against these unique surface forms to determine correctness, providing a more rigorous assessment of factual accuracy than traditional metrics that might accept partial or paraphrased answers.

## Key Results
- Llama-3.1-70B improves from 32.3% to 46.0% F1 on YAGO-QA using RCD
- Consistent improvements across seven models from 135M to 70B parameters
- RCD reduces answer ambiguity by enforcing exact surface form matching from knowledge bases
- Performance gains are particularly pronounced for complex questions requiring precise factual recall

## Why This Works (Mechanism)
RCD works by addressing the surface form mismatch problem in knowledge base question answering. Standard decoding allows language models to generate answers in any phrasing, but knowledge bases often store facts using specific, disambiguated surface forms. By constraining generation to these exact forms, RCD eliminates ambiguity and ensures that answers can be directly matched against the ground truth. This mechanism reveals that many language models actually possess the correct parametric knowledge but fail to express it in the exact form required by standard evaluations.

## Foundational Learning
- **Surface form matching**: Understanding how knowledge bases store facts using specific phrasings rather than semantic representations
- **Knowledge base structure**: Familiarity with how subject-relation-object triples are stored and retrieved
- **Decoding constraints**: Understanding how to modify generation processes to enforce specific output patterns

## Architecture Onboarding
The paper doesn't explicitly describe the underlying model architectures beyond mentioning specific models used (Llama-3.1-70B, etc.). The RCD method is implemented as a decoding-time modification that works with any autoregressive language model. The key architectural consideration is that RCD requires access to a knowledge base for retrieving surface forms, but doesn't require changes to the model's weights or training process. The method is compatible with standard transformer-based architectures and can be applied during inference without architectural modifications.

## Open Questions the Paper Calls Out
- How does RCD perform on open-domain question answering tasks beyond structured knowledge bases?
- Can the method be extended to handle more flexible surface form variations while maintaining precision?
- What is the computational overhead of retrieving and matching surface forms during decoding?
- How does RCD compare to other methods for improving factual accuracy in language model outputs?

## Limitations
- The method requires access to a comprehensive knowledge base with disambiguated surface forms
- Exact string matching may be overly strict for some applications where semantic equivalence should be accepted
- The approach may not generalize well to domains where surface form variation is more extensive or where knowledge bases are incomplete
- Computational overhead from knowledge base retrieval during decoding
- May not address cases where the model genuinely lacks the parametric knowledge

## Confidence
High confidence in the reported results based on the systematic evaluation across multiple models and datasets. The method's effectiveness is demonstrated through controlled experiments with clear baselines and metrics.

## Next Checks
- Verify the implementation details of the surface form retrieval and matching process
- Examine the specific improvements for different question types and complexity levels
- Investigate the computational overhead introduced by the knowledge base retrieval step
- Analyze failure cases where RCD doesn't improve performance to understand its limitations