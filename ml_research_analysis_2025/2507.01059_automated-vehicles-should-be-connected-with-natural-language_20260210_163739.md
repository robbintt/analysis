---
ver: rpa2
title: Automated Vehicles Should be Connected with Natural Language
arxiv_id: '2507.01059'
source_url: https://arxiv.org/abs/2507.01059
tags:
- driving
- communication
- arxiv
- language
- ieee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that natural language is the ideal communication
  medium for multi-agent collaborative driving, addressing limitations of existing
  approaches (raw sensor data, neural network features, perception results) that suffer
  from bandwidth inefficiency, information loss, and interoperability challenges.
  Natural language offers semantic richness with bandwidth efficiency, adaptive communication
  under variable conditions, model-agnostic interoperability across heterogeneous
  agents, seamless integration with existing human-oriented traffic systems, and human-compatible
  communication for transparency.
---

# Automated Vehicles Should be Connected with Natural Language

## Quick Facts
- arXiv ID: 2507.01059
- Source URL: https://arxiv.org/abs/2507.01059
- Authors: Xiangbo Gao; Keshu Wu; Hao Zhang; Kexin Tian; Yang Zhou; Zhengzhong Tu
- Reference count: 40
- Primary result: Natural language is proposed as the ideal communication medium for multi-agent collaborative driving, addressing bandwidth inefficiency, information loss, and interoperability challenges of existing approaches.

## Executive Summary
This paper argues that natural language is the optimal communication medium for multi-agent collaborative driving. The authors contend that traditional approaches—sharing raw sensor data, neural network features, or perception results—suffer from bandwidth inefficiency, information loss, and interoperability challenges. Natural language offers semantic richness with bandwidth efficiency, adaptive communication under variable conditions, model-agnostic interoperability across heterogeneous agents, seamless integration with existing human-oriented traffic systems, and human-compatible communication for transparency. The approach transforms collaborative driving from reactive perception-data sharing into proactive coordination through explicit intent communication.

## Method Summary
The paper proposes using Large Vision-Language Models (LVLMs) to encode perception and intent into natural language messages for V2X communication between autonomous vehicles and infrastructure. No specific implementation details, model architectures, training procedures, or evaluation benchmarks are provided. The approach conceptualizes language as a universal interface that bridges perception and planning through explicit intent communication, enabling vehicles to share intentions, reasoning, and decisions directly rather than exchanging raw sensor data or intermediate features.

## Key Results
- Natural language may achieve higher semantic density per byte than raw sensor data or neural features, potentially mitigating bandwidth bottlenecks in dense V2X networks
- Natural language functions as a model-agnostic protocol, allowing heterogeneous agents (different sensors/manufacturers) to collaborate without shared feature spaces
- Explicit communication of intent and rationale shifts the system from reactive perception sharing to proactive negotiation, improving safety in complex scenarios

## Why This Works (Mechanism)

### Mechanism 1: Semantic Compression for Bandwidth Constrained Channels
Natural language may achieve higher semantic density per byte than raw sensor data or neural features, potentially mitigating bandwidth bottlenecks in dense V2X networks. By compressing environmental states and intentions into text strings (e.g., "cyclist on right shoulder"), the system transmits only information relevant to decision-making rather than exhaustive pixel or point cloud data. Core assumption: LVLMs can reliably encode perception into text and decode text back into actionable planning constraints without critical information loss.

### Mechanism 2: Universal Interoperability Layer
Natural language functions as a model-agnostic protocol, allowing heterogeneous agents (different sensors/manufacturers) to collaborate without shared feature spaces. Agents use internal LVLMs to translate proprietary sensor data into a shared linguistic ontology. This bypasses the need for backward alignment or feature harmonization required by intermediate fusion methods. Core assumption: All participating agents possess LVLMs with sufficient grounding capabilities to interpret a shared vocabulary consistently.

### Mechanism 3: Intent Bridging for Proactive Coordination
Explicit communication of intent and rationale shifts the system from reactive perception sharing to proactive negotiation, improving safety in complex scenarios. Vehicles transmit future actions ("Entering now") and causal reasoning ("yielding because..."), allowing recipients to run context-aware prediction and game-theoretic planning rather than relying solely on trajectory extrapolation. Core assumption: The communication latency of generating and parsing intent messages is lower than the planning horizon required to act on them.

## Foundational Learning

- **Concept: Collaborative Perception Fusion Stages**
  - Why needed: The paper critiques "early" (raw), "intermediate" (features), and "late" (perception results) fusion. Understanding these is required to grasp why authors propose "decision-level" linguistic fusion.
  - Quick check: Can you distinguish why "intermediate fusion" fails in heterogeneous environments compared to a linguistic approach?

- **Concept: V2X Communication Constraints (DSRC/5G)**
  - Why needed: The argument for language rests on bandwidth scarcity. One must understand that as agent count rises, per-agent bandwidth drops, making raw data infeasible.
  - Quick check: Why does the per-agent data budget decrease as the number of connected agents increases, and how does language claim to solve this?

- **Concept: LVLM Grounding**
  - Why needed: The proposed architecture relies on Vision-Language Models to "ground" text in visual reality. Without this capability, text messages are unmoored from physical truth.
  - Quick check: What does "grounding" mean in the context of an LVLM receiving a text prompt like "car ahead" and sensor data?

## Architecture Onboarding

- **Component map:** Perception Module -> LVLM Encoder -> V2X Transmitter -> LVLM Decoder -> Planner
- **Critical path:** The LVLM Grounding Loop. The system fails if the LVLM cannot map a textual warning ("stalled car") to specific geometric coordinates in the local map.
- **Design tradeoffs:**
  - Precision vs. Interpretability: Text is human-readable and compact but may lack the metric precision of floating-point coordinates (e.g., "nearby" vs. 2.3m)
  - Latency vs. Reasoning: Generating complex rationale messages takes longer than sending a bounding box array
- **Failure signatures:**
  - Semantic Drift: Agents acting on slightly different interpretations of the same word (e.g., "approaching rapidly")
  - Silent Hallucination: LVLM generates plausible but factually incorrect text based on sensor noise
- **First 3 experiments:**
  1. Bandwidth Stress Test: Measure packet size and transmission time for equivalent scene descriptions using Bounding Boxes vs. Natural Language under 5G constraints
  2. Heterogeneity Simulation: Connect two agents with different sensor suites (e.g., LiDAR-only vs. Camera-only) and verify if they can coordinate a merge using only text messages
  3. Intent Prediction Accuracy: Compare trajectory prediction error when using "Perception Results" vs. "Explicit Intent Text" in a simulated unsignalized intersection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can natural language communication systems for autonomous vehicles achieve the precision required for safety-critical driving decisions while maintaining semantic flexibility?
- Basis in paper: The authors acknowledge the critique that "natural language is inherently ambiguous and imprecise compared to structured numeric representations" and respond that "domain-specific language use in driving can achieve high precision through consistent terminology and contextual grounding" but do not specify how this precision is achieved or measured.
- Why unresolved: The paper provides examples but no systematic framework for ensuring consistent interpretation across heterogeneous agents, particularly for spatial descriptions like "nearby" or temporal references like "approaching rapidly."
- What evidence would resolve it: Empirical validation showing that LVLM-equipped vehicles achieve consistent, safety-sufficient interpretation of natural language commands across varied agents and scenarios.

### Open Question 2
- Question: What security mechanisms can effectively authenticate natural language messages and prevent adversarial manipulation in open V2X communication systems?
- Basis in paper: The authors pose: "As natural language becomes a universal communication media... would it be more vulnerable to spoofing, semantic manipulation, or adversarial attacks?" and call for "future researches should focus on finding new methods... to enhance the system security."
- Why unresolved: The paper only suggests mimicking human trust patterns (e.g., deferring to uniformed police) but provides no technical framework for verifying message authenticity or detecting semantic attacks.
- What evidence would resolve it: A validated security protocol that can authenticate natural language messages and detect adversarial manipulations while preserving interoperability benefits.

### Open Question 3
- Question: How should hybrid communication approaches optimally combine natural language with structured numeric data to preserve both semantic richness and precision?
- Basis in paper: The authors acknowledge that "optimal collaborative driving will require hybrid communication approaches" and concede that "direct exchange of precise numeric data (e.g., GPS coordinates for path planning) may complement language-based communication," but do not specify the architecture or decision logic for such hybrid systems.
- Why unresolved: No framework exists for determining when to use language versus structured data, how to synchronize both modalities, or how to handle conflicts between them.
- What evidence would resolve it: A system architecture and empirical comparison showing improved safety and efficiency from hybrid approaches versus pure language or pure structured communication.

## Limitations
- The critical assumption about LVLM grounding reliability and the absence of semantic drift remains untested
- The potential latency penalty of LVLM inference for encoding/decoding messages may exceed real-time constraints
- The interoperability claim assumes all agents interpret shared vocabulary identically, which may not hold across heterogeneous agents

## Confidence
- **High confidence:** The fundamental observation that existing collaborative driving methods face bandwidth constraints and interoperability challenges is well-established in the literature
- **Medium confidence:** The claim that natural language offers bandwidth efficiency relative to raw sensor data is supported by the cited comparison, though specific implementation details would strengthen this claim
- **Low confidence:** The safety benefits of intent-based communication over reactive perception sharing are asserted but not demonstrated

## Next Checks
1. **LVLM Grounding Precision Test:** Conduct controlled experiments measuring the correlation between LVLM-generated text descriptions and ground truth spatial coordinates
2. **Latency Profiling Under Load:** Measure end-to-end latency for language-based messages at varying network loads and agent densities
3. **Semantic Consistency Across Heterogeneous Agents:** Deploy language-based coordination between agents with different sensor suites and quantify semantic drift