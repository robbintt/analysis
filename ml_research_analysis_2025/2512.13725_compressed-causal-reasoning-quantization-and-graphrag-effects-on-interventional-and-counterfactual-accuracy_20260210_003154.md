---
ver: rpa2
title: 'Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional
  and Counterfactual Accuracy'
arxiv_id: '2512.13725'
source_url: https://arxiv.org/abs/2512.13725
tags:
- causal
- reasoning
- quantization
- counterfactual
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study systematically evaluates how low-precision quantization\
  \ and graph-structured retrieval augmentation affect causal reasoning in large language\
  \ models across Pearl\u2019s three causal levels: association, intervention, and\
  \ counterfactual inference. Using Llama-3-8B and a 3,000-sample stratified causal\
  \ benchmark, we find that overall causal reasoning accuracy remains stable under\
  \ NF4 quantization with less than 1% degradation, though interventional reasoning\
  \ shows the highest sensitivity to precision loss."
---

# Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy

## Quick Facts
- **arXiv ID**: 2512.13725
- **Source URL**: https://arxiv.org/abs/2512.13725
- **Authors**: Steve Nwaiwu; Nipat Jongsawat; Anucha Tungkasthan
- **Reference count**: 23
- **One-line primary result**: Llama-3-8B shows <1% causal reasoning accuracy loss under NF4 quantization, with GraphRAG partially recovering interventional reasoning degradation.

## Executive Summary
This study systematically evaluates how low-precision quantization and graph-structured retrieval augmentation affect causal reasoning in large language models across Pearl's three causal levels: association, intervention, and counterfactual inference. Using Llama-3-8B and a 3,000-sample stratified causal benchmark, we find that overall causal reasoning accuracy remains stable under NF4 quantization with less than 1% degradation, though interventional reasoning shows the highest sensitivity to precision loss. GraphRAG using ground-truth causal facts improves NF4 interventional accuracy by 1.7%, partially offsetting compression-related degradation. Counterfactual benchmarks like CRASS show no sensitivity to quantization, suggesting limited diagnostic power for causal brittleness. These findings demonstrate that low-precision models can reliably perform causal reasoning, with graph-structured retrieval offering targeted stabilization for interventional queries.

## Method Summary
The study evaluates Llama-3-8B under three precision modes (BF16, INT8, NF4) using zero-shot greedy decoding on CLadder (3,000 stratified samples, 1,000 per rung) and CRASS benchmarks. NF4 quantization uses BitsAndBytes with BF16 activations. GraphRAG retrieves ground-truth causal facts using MiniLM embeddings indexed in FAISS, prepending top-K=3 facts to queries. Performance is measured by rung-level accuracy with 1,000 bootstrap resamples for confidence intervals.

## Key Results
- NF4 quantization causes <1% overall degradation in causal reasoning accuracy across all three Pearlian rungs
- GraphRAG improves NF4 interventional accuracy by 1.7% (Rung 2), partially offsetting compression-related degradation
- CRASS counterfactual benchmark shows no sensitivity to quantization, indicating limited diagnostic power for causal brittleness
- Rung 2 (Intervention) shows highest variance across precision modes (σ² = 1.1 × 10⁻³) and is most sensitive to compression

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Causal reasoning in 8B-parameter models appears robust to aggressive weight compression (NF4), showing <1% degradation.
- **Mechanism**: Precision reduction (BF16 → NF4) truncates weight information, but for models of this scale, the resulting representational noise does not systematically破坏 the specific circuits used for causal association or counterfactuals.
- **Core assumption**: The model relies on distributed representations where small perturbations average out, rather than precise single-value logic gates.
- **Evidence anchors**:
  - [abstract] "NF4 showing less than 1% overall degradation."
  - [section 6.2] "Causal accuracy remains stable, with differences below 0.5%... confidence intervals overlap."
  - [corpus] Weak direct link; neighbor papers discuss causal reasoning complexity but not quantization robustness.
- **Break condition**: This stability may not hold for smaller models (<7B) or quantization methods that perturb activation dynamics more aggressively than weight-only NF4.

### Mechanism 2
- **Claim**: Graph-structured retrieval (GraphRAG) selectively stabilizes interventional reasoning (Rung 2) under compression.
- **Mechanism**: Externalizing causal facts into a retrieved prompt reduces the model's burden to "recall" structural dependencies from compressed internal weights. It substitutes internal recall with external context, specifically aiding the manipulation tasks required for interventions.
- **Core assumption**: The bottleneck for interventional queries in compressed models is the fidelity of structural recall, not the reasoning capacity itself.
- **Evidence anchors**:
  - [abstract] "GraphRAG... improves NF4 interventional accuracy by 1.7%, partially offsetting compression-related degradation."
  - [section 6.4] "GraphRAG yields a statistically significant improvement in interventional accuracy... ∆R2 = +0.017."
  - [corpus] "Executable Counterfactuals" suggests external structure (code) aids causal reasoning, supporting the externalization hypothesis.
- **Break condition**: If the retrieval index is noisy or the causal graph is incomplete, the "context injection" could introduce conflicting signals, degrading rather than aiding reasoning.

### Mechanism 3
- **Claim**: Counterfactual benchmarks (CRASS) show no sensitivity to quantization because they measure narrative plausibility rather than structural inference.
- **Mechanism**: CRASS queries are often solvable via surface-level semantic heuristics (e.g., "Is this sentence reasonable?"). Since quantization largely preserves semantic proximity, performance remains static even if the model's ability to simulate precise causal worlds is impaired.
- **Core assumption**: Existing commonsense benchmarks fail to force the model to engage in rigorous "abduction" or "intervention" steps, masking potential brittleness.
- **Evidence anchors**:
  - [abstract] "CRASS show no sensitivity to quantization, suggesting limited diagnostic power for causal brittleness."
  - [section 7.5] "CRASS primarily evaluates plausibility-based counterfactual reasoning... limited sensitivity... in comparison to structurally grounded benchmarks."
  - [corpus] "Canonical Representations of Markovian Structural Causal Models" emphasizes rigorous counterfactual definitions, contrasting with the simpler plausibility checks described here.
- **Break condition**: If a benchmark requires formal counterfactual consistency (e.g., CLadder Rung 3), this "stability" would likely disappear, revealing actual degradation.

## Foundational Learning

- **Concept**: **Pearl's Causal Ladder (Rungs 1–3)**
  - **Why needed here**: The paper decomposes performance by causal level (Association, Intervention, Counterfactual). Without this, you cannot understand why GraphRAG helps Rung 2 but not Rung 1.
  - **Quick check question**: Does "If I press the button, does the light turn on?" require Rung 1, 2, or 3 reasoning? (Answer: Rung 2, Intervention).

- **Concept**: **Quantization-Induced Drift**
  - **Why needed here**: The study measures how weight precision (BF16 vs NF4) alters causal logic. Understanding that NF4 is a 4-bit representation helps contextualize why <1% degradation is surprising.
  - **Quick check question**: If a model drops from 0.507 to 0.501 accuracy on a task, is that statistically significant in this context? (Answer: Likely no, given the reported overlapping confidence intervals).

- **Concept**: **GraphRAG (Graph Retrieval-Augmented Generation)**
  - **Why needed here**: This is the mitigation strategy. It differs from standard RAG by retrieving structured "causal facts" rather than general text passages.
  - **Quick check question**: In this paper, does GraphRAG improve the model's *internal* reasoning or provide *external* context? (Answer: External context; the model's weights are frozen).

## Architecture Onboarding

- **Component map**: Llama-3-8B -> BitsAndBytes Quantization -> CLadder/CRASS Benchmark -> (Optional) GraphRAG Retrieval -> Greedy Decoding -> Accuracy Evaluation

- **Critical path**: Load Quantized Model -> Stratify Benchmark -> (Optional) Retrieve Top-K Causal Facts -> Construct Prompt -> Greedy Decoding -> Exact Match Evaluation

- **Design tradeoffs**:
  - *Precision vs. Stability*: NF4 offers memory efficiency but introduces variance in interventional reasoning; GraphRAG recovers this at the cost of retrieval latency
  - *Benchmark Depth*: CLadder offers structural sensitivity but is synthetic; CRASS is naturalistic but metrically "blind" to compression faults

- **Failure signatures**:
  - **False Negative**: CRASS accuracy remains constant (0.267) across all precisions, failing to flag that the model might be reasoning poorly
  - **High Variance**: Rung 2 (Intervention) shows highest variance across precision modes (σ² = 1.1 × 10⁻³), signaling it is the "canary in the coal mine" for compression faults

- **First 3 experiments**:
  1. **Baseline Drift Check**: Run BF16 vs. NF4 on the 3k CLadder set; verify if Rung 2 variance exceeds Rung 1/3 as claimed
  2. **Retrieval Ablation**: Implement the GraphRAG loop with K=0 (control), K=1, and K=3 on the NF4 model specifically for Rung 2 queries to replicate the +1.7% delta
  3. **Benchmark Sensitivity**: Compare the model on a formal counterfactual subset (CLadder Rung 3) vs. CRASS to confirm the "plausibility heuristic" hypothesis (CRASS should stay flat; CLadder Rung 3 should fluctuate)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Does the observed causal reasoning robustness under NF4 quantization generalize to larger-scale models (e.g., 70B+ parameters) and multimodal architectures?
- **Basis in paper**: [explicit] "Our analysis focuses on Llama-3-8B. Larger-scale models may exhibit different robustness or drift characteristics under quantization, but such experiments are beyond the scope of this study."
- **Why unresolved**: Only one model scale was tested; deeper architectures may introduce additional brittleness not visible at 8B scale.
- **What evidence would resolve it**: Replicate the stratified CLadder evaluation across BF16, INT8, and NF4 for models at 70B, 175B, and multimodal variants, comparing QCD values across scales.

### Open Question 2
- **Question**: Can structurally sensitive counterfactual benchmarks be developed that reliably detect quantization-induced causal drift where plausibility-based benchmarks like CRASS fail?
- **Basis in paper**: [explicit] "CRASS exhibits no measurable sensitivity to quantization... indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization-induced reasoning drift."
- **Why unresolved**: Current benchmarks either lack explicit causal structure (CRASS) or may still insufficiently cover temporal, multi-step, and procedural counterfactuals.
- **What evidence would resolve it**: Construct benchmarks with explicit causal graphs, nested interventions, and temporal counterfactuals; demonstrate significant performance variance across precision modes.

### Open Question 3
- **Question**: Would dynamic or temporal causal graphs in GraphRAG provide greater stabilization for interventional and counterfactual reasoning than the static fact retrieval tested?
- **Basis in paper**: [explicit] "Our GraphRAG implementation retrieves ground-truth causal facts represented as static statements... [and] does not capture the complexity of real causal knowledge graphs, such as temporal dynamics, procedural dependencies, or hierarchical causal mechanisms."
- **Why unresolved**: Only static ground-truth facts were evaluated; richer graph structures remain unexplored for causal stabilization under compression.
- **What evidence would resolve it**: Compare GraphRAG performance using dynamic temporal graphs versus static facts on the same causal benchmarks under NF4 quantization.

### Open Question 4
- **Question**: How does causal reasoning performance under quantization behave under sampling-based inference or chain-of-thought prompting compared to greedy decoding?
- **Basis in paper**: [explicit] "All evaluations use greedy decoding... this choice does not reflect performance under sampling-based inference or chain-of-thought prompting, which may interact differently with quantization and retrieval augmentation."
- **Why unresolved**: Greedy decoding eliminates stochastic variance but may mask interaction effects between quantization noise and sampling-based reasoning strategies.
- **What evidence would resolve it**: Replicate experiments using nucleus sampling and chain-of-thought prompting, comparing rung-level accuracy and variance against greedy baselines.

## Limitations
- **Benchmark Representativeness**: The CLadder benchmark, while stratified, is synthetically constructed and may not fully capture real-world causal reasoning complexity, particularly for Rung 3 counterfactuals where evaluation may not probe true abduction-based reasoning.
- **Quantization Method Specificity**: Findings are specific to NF4 quantization via BitsAndBytes and may not generalize to other quantization schemes (e.g., AWQ, GPTQ) or different architectural properties.
- **GraphRAG Dependency on Gold Facts**: The positive effect of GraphRAG relies on retrieving "gold" causal facts; in real-world deployment with incomplete or noisy causal graphs, the observed benefits may be reduced or reversed.

## Confidence
- **High Confidence**: NF4 quantization shows <1% overall degradation in causal accuracy across all rungs; CRASS benchmark shows no sensitivity to quantization, indicating limited diagnostic power for causal brittleness
- **Medium Confidence**: GraphRAG improves NF4 interventional accuracy by 1.7% on CLadder; Rung 2 (Intervention) shows highest variance across precision modes and is most sensitive to compression
- **Low Confidence**: The stability of counterfactual reasoning under quantization extends to real-world applications; the mechanisms proposed for why GraphRAG helps interventional reasoning would generalize to non-causal RAG tasks

## Next Checks
1. **Benchmark Generalization Test**: Evaluate the same quantization and GraphRAG pipeline on a naturalistic causal reasoning dataset (e.g., REALM-Causal or custom domain-specific causal queries) to verify that CLadder findings transfer beyond synthetic benchmarks.

2. **Ablation on Retrieval Quality**: Implement GraphRAG with progressively noisier or incomplete causal graphs (e.g., remove 20%, 50%, 80% of edges) to determine the minimum viable graph quality for maintaining the 1.7% interventional accuracy gain.

3. **Quantization Scheme Comparison**: Repeat the core experiment (BF16 vs NF4) using a different quantization method (e.g., AWQ or GPTQ) on Llama-3-8B to determine whether the observed <1% stability is specific to BitsAndBytes NF4 or a more general property of 8B models under weight compression.