---
ver: rpa2
title: 'KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance
  of Large Language Models'
arxiv_id: '2501.02711'
source_url: https://arxiv.org/abs/2501.02711
tags:
- knowledge
- graph
- path
- paths
- completion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KG-CF addresses the challenge of applying LLMs to ranking-based
  knowledge graph completion tasks. The framework uses LLMs to filter irrelevant graph
  context, training a sequence classifier to eliminate redundant paths and a BERT
  model for path scoring.
---

# KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models

## Quick Facts
- arXiv ID: 2501.02711
- Source URL: https://arxiv.org/abs/2501.02711
- Reference count: 37
- Primary result: Achieves Hits@1 scores of 67.5%, 62.3%, and 73.1% on WN18RR, FB15K-237, and NELL-995 in transductive settings

## Executive Summary
KG-CF addresses the challenge of applying LLMs to ranking-based knowledge graph completion tasks by decomposing the problem into context filtering and ranking. The framework uses LLMs to filter irrelevant graph context, training a sequence classifier to eliminate redundant paths and a BERT model for path scoring. This approach avoids direct LLM ranking, which is problematic for numerical outputs. Evaluated on WN18RR, FB15K-237, and NELL-995 datasets, KG-CF achieves strong performance and demonstrates the effectiveness of separating context filtering from ranking.

## Method Summary
KG-CF uses LLMs to filter irrelevant contexts from knowledge graphs, then trains a BERT model on the filtered paths for ranking-based KGC. The pipeline consists of BFS-based path sampling, LLM-based relevance labeling, LSTM-based context filtering, and BERT-based scoring. The framework separates context filtering from ranking, allowing LLMs to contribute reasoning strength while avoiding their weakness in numerical output generation. The approach achieves strong performance by removing noisy paths before PLM scoring.

## Key Results
- Hits@1 scores of 67.5%, 62.3%, and 73.1% on WN18RR, FB15K-237, and NELL-995 in transductive settings
- Inductive setting performance of 78.5%, 51.2%, and 79.5% on the same datasets
- Performance gains plateau at path length 3, with diminishing returns beyond that
- Ablation studies confirm effectiveness of filtering both positive and negative paths

## Why This Works (Mechanism)

### Mechanism 1: Task Decomposition—Filtering vs. Ranking
Separating context filtering from ranking allows LLMs to contribute reasoning strength while avoiding their weakness in numerical output generation. LLMs evaluate whether inference paths are relevant to candidate triplets, producing binary labels rather than plausibility scores. This task aligns with LLMs' strengths in semantic judgment while avoiding the cumulative sequence errors documented in autoregressive number generation.

### Mechanism 2: Knowledge Distillation via Sequence Classifier
A lightweight LSTM can approximate LLM filtering decisions, reducing inference cost while preserving filtering quality. The LLM labels a sampled subset of paths, and an LSTM sequence classifier is trained on these labels using cross-entropy loss. At scale, the classifier filters paths without LLM calls, making the approach computationally tractable.

### Mechanism 3: Filtered Context Improves PLM Scoring
Removing irrelevant paths before PLM scoring reduces noise and improves ranking accuracy. BERT receives only paths classified as relevant for positive triplets and irrelevant for negative triplets. The PLM outputs a score via sigmoid, and the maximum path score per candidate determines ranking.

## Foundational Learning

- **Knowledge Graph Completion (KGC) task types**
  - Why needed here: The paper explicitly distinguishes classification (binary true/false) from ranking (ordering candidates by plausibility). Understanding this distinction is essential to grasp why direct LLM application fails.
  - Quick check question: Given query (Japan, Capital, ?) and candidates [Tokyo, Paris, Berlin], would a classification model output differ from a ranking model output?

- **Inference paths in KGs**
  - Why needed here: The framework represents context as paths from head to tail entity. Path formulation and BFS sampling are foundational to the entire pipeline.
  - Quick check question: For triplet (Biden, PresidentOf, USA), what constitutes a valid inference path versus an irrelevant one?

- **Knowledge distillation from LLMs**
  - Why needed here: The sequence classifier is trained on LLM-generated labels. Understanding teacher-student distillation clarifies why this reduces cost without requiring LLM at inference.
  - Quick check question: If the LLM teacher has 90% accuracy on path relevance and the student LSTM achieves 85%, what is the tradeoff in filtering quality versus inference speed?

## Architecture Onboarding

- **Component map:**
  1. Path Sampler: BFS extraction of paths from head to tail (up to max length m)
  2. LLM Labeler: Produces binary relevance labels for sampled paths (offline)
  3. Sequence Classifier (LSTM): Trained on LLM labels; filters paths at scale
  4. PLM Scorer (BERT): Trained on filtered paths; outputs ranking scores
  5. Ranking Aggregator: Takes max path score per candidate entity

- **Critical path:**
  1. Sample paths for training triplets
  2. Run LLM labeling (one-time, computationally expensive)
  3. Train LSTM classifier on labeled paths
  4. Use classifier to filter all paths (positive and negative samples)
  5. Train BERT on filtered dataset
  6. At inference: sample paths → filter with classifier → score with BERT → rank by max score

- **Design tradeoffs:**
  - Path length vs. computational cost: Longer paths provide more context but grow exponentially. Paper shows diminishing returns beyond length 3.
  - Filtering threshold: Higher threshold retains more paths (more signal, more noise); lower threshold is more aggressive (less noise, potential signal loss).
  - LLM sampling budget: Algorithm 1 limits paths per relation (n). Too few samples underfits the classifier; too many increases labeling cost.

- **Failure signatures:**
  - Empty path set at inference: If no paths pass filtering, the model assigns lowest score. Indicates over-aggressive threshold or sparse graph.
  - Performance drop with anonymous entities: Ablation (-te) shows significant decline when entity names are masked, indicating reliance on textual semantics rather than pure topology.
  - Inductive instability: Table II shows higher variance on FB15K-237 inductive setting, suggesting generalization challenges on some relation types.

- **First 3 experiments:**
  1. Reproduce ablation on WN18RR: Run KG-CF, KG-CF-pf (no positive filtering), and KG-CF-nf (no negative filtering) to validate that filtering contributes measurably to Hits@1.
  2. Path length sweep: Train separate models with max path lengths 2, 3, 4, 5 on a single dataset. Confirm performance plateaus at length 3 as reported in Figure 2.
  3. Classifier quality audit: Sample 100 filtered paths and manually assess whether LSTM classifier decisions align with semantic relevance. Identify systematic misclassification patterns (e.g., paths with rare entities).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does KG-CF performance change if simple reasoning paths are replaced with richer context types like ego-graphs?
- Basis in paper: Section VI (Limitations) explicitly states, "new context type selection (e.g. ego-graph) can be a future direction that is worthwhile to explore."
- Why unresolved: The current framework implementation is restricted to linear reasoning paths and does not integrate structural neighborhood information like subgraphs.
- What evidence would resolve it: Empirical results from modifying the KG-CF pipeline to accept ego-graphs as input context, compared against the current trajectory-based baselines.

### Open Question 2
- Question: Can the framework be modified to effectively utilize reasoning paths longer than length 3 without suffering from diminishing returns or reduced short-range reasoning?
- Basis in paper: Section IV.E notes that increasing path length from 2 to 3 boosts performance, but returns diminish beyond that. It also states, "training on longer paths may reduce the model's ability to reason over shorter paths."
- Why unresolved: The paper identifies this scalability plateau but does not propose a mechanism to balance the noise in longer contexts with the need for deeper reasoning.
- What evidence would resolve it: A variation of the sequence classifier or attention mechanism that shows consistent performance improvements with path lengths of 4, 5, or more.

### Open Question 3
- Question: To what extent does the model rely on the LLM's internal parametric knowledge (via entity names) rather than the logical topology of the graph structure?
- Basis in paper: The "Trajectory Entities" ablation study (Section IV.D) replaced entity names with anonymous labels, resulting in a significant performance drop. The authors suggest this confirms "data leakage" where internal LLM knowledge assists reasoning.
- Why unresolved: The paper highlights this dependency as a factor in performance but does not isolate whether the model learns structural logic or primarily acts as a semantic matcher.
- What evidence would resolve it: Experiments on knowledge graphs with out-of-vocabulary or purely synthetic identifiers to test the model's pure structural reasoning capabilities.

## Limitations

- The specific LLM model and prompt template for path labeling are not specified, which critically affects filtering quality.
- The framework shows performance drops in inductive settings, suggesting the LSTM classifier may overfit to entity names rather than structural patterns.
- Scalability claims (diminishing returns at path length 3) are based on experiments but may not generalize to all KG structures.

## Confidence

- **High:** The core claim that LLMs are better at binary relevance judgment than numerical ranking is well-supported by literature and aligns with known LLM limitations.
- **Medium:** The distillation approach (LSTM mimicking LLM) is plausible and effective in the reported results, but the specific implementation details matter significantly.
- **Low:** The scalability claims (diminishing returns at path length 3) are based on experiments but may not generalize to all KG structures.

## Next Checks

1. **Ablation Reproduction:** Re-run KG-CF, KG-CF-pf, and KG-CF-nf on WN18RR to confirm that context filtering measurably improves Hits@1.
2. **Path Length Sweep:** Train models with max path lengths 2, 3, 4, 5 on one dataset to verify performance plateaus at length 3.
3. **Classifier Quality Audit:** Sample 100 filtered paths and manually assess LSTM classifier decisions for alignment with semantic relevance; identify systematic misclassification patterns.