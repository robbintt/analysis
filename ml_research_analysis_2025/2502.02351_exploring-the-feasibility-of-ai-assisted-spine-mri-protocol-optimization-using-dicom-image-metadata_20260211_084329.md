---
ver: rpa2
title: Exploring the Feasibility of AI-Assisted Spine MRI Protocol Optimization Using
  DICOM Image Metadata
arxiv_id: '2502.02351'
source_url: https://arxiv.org/abs/2502.02351
tags:
- image
- quality
- data
- performance
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the feasibility of using AI to optimize
  MRI protocols by analyzing DICOM metadata from spine MRI sequences. A methodology
  was developed to train five AI models (Logistic Regression, Decision Trees, Random
  Forest, Gradient Boosting, and Multilayer Perceptron) to classify image quality
  based on acquisition parameters.
---

# Exploring the Feasibility of AI-Assisted Spine MRI Protocol Optimization Using DICOM Image Metadata

## Quick Facts
- arXiv ID: 2502.02351
- Source URL: https://arxiv.org/abs/2502.02351
- Reference count: 40
- Five AI models (Logistic Regression, Decision Trees, Random Forest, Gradient Boosting, and Multilayer Perceptron) achieved F1-scores between 77% and 93% for datasets with 292 or more instances in classifying spine MRI image quality

## Executive Summary
This study explores the feasibility of using AI to optimize MRI protocols by analyzing DICOM metadata from spine MRI sequences. Researchers developed a methodology to train five different AI models to classify image quality based on acquisition parameters, achieving promising results with F1-scores between 77% and 93% for adequately sized datasets. SHAP analysis revealed that parameters such as percent phase field of view, field of view, and repetition time consistently influenced image quality across all datasets. The models aligned with MRI theory, demonstrating their potential to assist medical physicists in quality control and protocol optimization, offering a practical tool for improving image quality and efficiency in clinical MRI settings.

## Method Summary
The methodology involved developing a pipeline to extract DICOM metadata from spine MRI sequences and train five AI classification models. The dataset was split into training and testing subsets to evaluate model performance. Five algorithms were employed: Logistic Regression, Decision Trees, Random Forest, Gradient Boosting, and Multilayer Perceptron. Model performance was assessed using F1-scores, while SHAP (SHapley Additive exPlanations) analysis was used to identify which acquisition parameters most influenced image quality predictions. The approach focused on understanding how different acquisition parameters affect image quality to optimize MRI protocols.

## Key Results
- AI models achieved F1-scores between 77% and 93% for datasets containing 292 or more instances
- SHAP analysis consistently identified percent phase field of view, field of view, and repetition time as key parameters influencing image quality
- Model predictions aligned with established MRI physics principles, validating the approach

## Why This Works (Mechanism)
The approach works because DICOM metadata contains comprehensive information about MRI acquisition parameters that directly influence image quality. By training AI models on this metadata alongside quality labels, the system learns the complex relationships between protocol settings and resulting image quality. SHAP analysis provides interpretability by revealing which specific parameters drive quality outcomes, enabling targeted protocol optimization.

## Foundational Learning
- **DICOM Metadata**: Standardized format for medical imaging data containing acquisition parameters - needed for extracting protocol information; quick check: verify all relevant tags are captured
- **MRI Physics Parameters**: TR, FOV, pFOV affect signal-to-noise ratio and spatial resolution - needed to understand quality drivers; quick check: confirm parameters align with theoretical expectations
- **SHAP Analysis**: Game theory-based method for interpreting ML model predictions - needed to identify parameter importance; quick check: validate SHAP values are consistent across datasets
- **Protocol Optimization**: Systematic adjustment of acquisition parameters to improve image quality - needed for clinical application; quick check: test optimized protocols produce higher quality images
- **Classification Metrics**: F1-score balances precision and recall for imbalanced datasets - needed for model evaluation; quick check: ensure metrics are calculated correctly

## Architecture Onboarding
Component Map: DICOM Extraction -> Preprocessing -> Model Training -> SHAP Analysis -> Quality Classification
Critical Path: DICOM metadata extraction and preprocessing is the foundation, as model performance depends entirely on the quality and completeness of this data.
Design Tradeoffs: Balanced model selection (five different algorithms) versus computational efficiency - using multiple models provides robustness but increases training time and complexity.
Failure Signatures: Poor performance on small datasets (<292 instances), inconsistent SHAP analysis results, or parameter importance rankings that contradict MRI physics principles indicate model reliability issues.
First Experiments: 1) Validate DICOM metadata extraction pipeline with test images, 2) Run SHAP analysis on a small subset to confirm parameter identification, 3) Compare model predictions against expert radiologist assessments.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability across different MRI manufacturers and clinical sites remains uncertain
- Dataset composition may not capture full variability of spine MRI protocols in diverse clinical settings
- Performance metrics were primarily evaluated on relatively small sample sizes, raising questions about real-world applicability

## Confidence
- Model performance metrics (F1-scores 77-93%): Medium - Results are encouraging but limited by dataset size and diversity
- Parameter importance findings (pFOV, FOV, TR): High - These align with established MRI physics principles
- Clinical applicability and workflow integration: Low - Insufficient evidence on real-world implementation

## Next Checks
1. Test model performance across multiple MRI manufacturers and scanner generations to assess cross-platform reliability
2. Conduct prospective clinical trials measuring actual protocol optimization outcomes and efficiency gains
3. Evaluate model performance with datasets exceeding 1000 instances to ensure stability at scale