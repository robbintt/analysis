---
ver: rpa2
title: 'MASTER: Multi-Agent Security Through Exploration of Roles and Topological
  Structures -- A Comprehensive Framework'
arxiv_id: '2505.18572'
source_url: https://arxiv.org/abs/2505.18572
tags:
- role
- agent
- system
- attack
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MASTER introduces the first comprehensive framework for Multi-Agent
  System (MAS) security research, addressing the heightened risks arising from role
  heterogeneity and complex topological structures in MAS. The framework combines
  automated MAS construction, information-flow-based interaction, and adaptive attack
  strategies that exploit role and topology information to generate targeted, domain-specific
  attacks.
---

# MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework

## Quick Facts
- arXiv ID: 2505.18572
- Source URL: https://arxiv.org/abs/2505.18572
- Reference count: 40
- Primary result: Introduces first comprehensive framework for MAS security, demonstrating role and topology-aware attacks achieve >90% success rates while hierarchical defenses reduce to <20%

## Executive Summary
MASTER presents the first comprehensive framework for Multi-Agent System (MAS) security research, addressing heightened risks from role heterogeneity and complex topological structures. The framework combines automated MAS construction, information-flow-based interaction, and adaptive attack strategies that exploit role and topology information to generate targeted, domain-specific attacks. Experimental results across 25 scenarios and seven application domains show that role and topological information significantly enhance attack success rates (ASR), with some models achieving over 90% ASR, while also improving adversarial role consistency and harmful team collaboration. Corresponding defense strategies, including prompt leakage detection, hierarchical monitoring, and preemptive defenses, substantially reduce ASR below 20% and enhance MAS resilience.

## Method Summary
The framework constructs MAS with specified agent counts and topologies, assigning roles and capabilities through system prompts. Agents interact via information flow propagation where each agent collects responses from neighbors, combines task information with neighbor outputs and memory, then generates responses. The attack strategy employs probing to extract system information, injection to embed malicious traits with backdoor triggers, and activation to produce harmful outputs. Defense mechanisms include prompt leakage detection, hierarchical monitoring based on agent criticality, and preemptive defenses with safety constraints. The framework evaluates ASR, role consistency, and cooperation metrics across diverse topologies and application domains.

## Key Results
- Role and topological information significantly enhance attack success rates, with some models achieving over 90% ASR
- Defense strategies reduce ASR below 20% while improving MAS resilience
- Chain topology shows lowest vulnerability (~35% ASR) while Hierarchy topology shows highest (~80% ASR)
- Model sensitivity to topologies varies significantly, with GPT-4o showing low sensitivity and Llama3-70B showing high sensitivity

## Why This Works (Mechanism)

### Mechanism 1: Topology-Governed Information Flow Propagation
- **Claim**: MAS security vulnerabilities scale with connectivity; attack success increases as malicious information propagates through the agent network.
- **Mechanism**: The framework models MAS as a directed graph G=(V,E) with adjacency matrix A. Agents only activate when receiving inputs from neighbors (Eq. 4-5). This creates propagation pathways where compromised agents influence downstream agents through accumulated context in P(t)_i = T ∪ O(t-1)_i ∪ R(t-1)_i ∪ M(t-1)_i.
- **Core assumption**: Agents incorporate untrusted neighbor outputs into their reasoning without independent verification.
- **Evidence anchors**:
  - [abstract]: "role and topological information significantly enhancing adversarial role consistency and harmful team cooperation"
  - [section 3.2.3]: Agents collect responses from adjacent agents; if O(t)_i is non-empty, they combine task, neighbor responses, previous response, and memory to construct input
  - [corpus]: G-Safeguard (arXiv:2502.11127) confirms "vulnerability to adversarial attacks propagates through the network topology"
- **Break condition**: If agents sanitize or validate neighbor inputs before integration, or if topology limits connectivity (Chain topology showed lowest ASR per Figure 5).

### Mechanism 2: Role-Consistent Trait Injection Amplifies Attack Efficacy
- **Claim**: Attacks that maintain agent role consistency while injecting adversarial traits achieve higher success rates than generic jailbreaks.
- **Mechanism**: The injection stage (Eq. 9-10) uses domain classification C_LLM(I) to select scenario-specific dark traits Y, then embeds them with backdoor triggers. During activation (Eq. 11-12), role and topology information {T_role, T_topo} = E(I) reinforces traits, producing coherent harmful outputs aligned with agent specialization.
- **Core assumption**: LLMs prioritize instruction-following over safety when instructions appear role-appropriate and contextually grounded.
- **Evidence anchors**:
  - [section 3.2.4]: "System information reinforces these traits by integrating with original role configurations and enhancing malicious inter-agent collaboration"
  - [Table 2]: Ablation shows removing role information drops role consistency from 95.4 to 67.2-80.1; removing topology drops cooperation from 85.2 to 40.8
  - [corpus]: Exposing Weak Links (arXiv:2511.10949) finds "adversarial success depends on role-specific vulnerabilities"
- **Break condition**: If defense mechanisms detect trait injection patterns or if agents have hard-coded safety constraints independent of role prompts.

### Mechanism 3: Hierarchical Criticality-Based Defense Allocation
- **Claim**: Stratified monitoring based on agent importance achieves efficient security without exhaustive checking.
- **Mechanism**: Agents ranked by L_i = H(v_i) receive monitoring frequencies p_i. High-importance agents (e.g., central nodes in Star/Hierarchy topologies) receive more frequent supervision. Monitor agents issue warnings P_w when detecting risky behavior (Eq. 13).
- **Core assumption**: Attack impact correlates with agent centrality; compromising high-importance nodes causes disproportionate system damage.
- **Evidence anchors**:
  - [section 3.2.5]: "Agents with higher importance receive more frequent interaction monitoring, thereby enhancing the interaction security of the MAS"
  - [Table 3]: Hierarchical Defense reduces ASR from 77.1% to 9.0% by Turn 8
  - [corpus]: Limited corpus evidence on hierarchical defense specifically; primarily from this paper
- **Break condition**: If attackers target low-monitoring peripheral agents to establish footholds before propagating to central nodes.

## Foundational Learning

- **Concept: Graph Topology in Multi-Agent Systems**
  - **Why needed here**: The paper explicitly tests 6 topologies (Chain, Tree, Star, Circle, Hierarchy, Complete) showing ASR varies from ~35% (Chain) to ~80% (Hierarchy) depending on connectivity patterns.
  - **Quick check question**: Given a 5-agent system where agent 0 connects to all others but others only connect to neighbors, which topology is this and what's its expected relative vulnerability?

- **Concept: LLM System Prompts and Role Definitions**
  - **Why needed here**: Role assignment phase generates S_i for each agent defining capabilities, responsibilities, and behavioral constraints. These prompts are attack targets during probing.
  - **Quick check question**: What information in an agent's system prompt would be most valuable for crafting a role-consistent attack?

- **Concept: Backdoor Triggers in LLM Prompts**
  - **Why needed here**: The injection stage embeds dormant malicious traits activated by specific triggers (T_trigger = "Hey buddy"), inspired by DeepInception methodology.
  - **Quick check question**: How would you detect if a deployed agent contains a dormant backdoor trigger waiting for activation?

## Architecture Onboarding

- **Component map**: User Request → MAS Constructor → (Topology Selection + Role Assignment) → MAS Instance → Interaction Mechanism → Agent Activation → Response Generation → [Attack Module ← Probing Info] → [Defense Module ← Detection Signals] → Trait Injection → Activation → Evaluation ← ASR + Role Consistency + Cooperation Metrics

- **Critical path**: The probing stage must complete n rounds of saturated information exchange (Eq. 8) before trait injection. Incomplete probing yields insufficient I for adaptive trait selection, reducing attack efficacy.

- **Design tradeoffs**:
  - **Preemptive Defense (offline)** vs **Hierarchical Defense (online)**: Preemptive adds defense prompts to S_i at construction time (lower runtime cost, less adaptive); Hierarchical requires real-time monitoring agents (higher cost, catches novel attacks)
  - **Topology selection**: Chain minimizes attack surface (lowest ASR) but limits collaboration; Complete maximizes capability but highest vulnerability
  - **Memory persistence**: Longer memory M(t)_i enables richer context for both legitimate tasks and attack propagation

- **Failure signatures**:
  - ASR plateaus below expected: Probing stage incomplete, or agent system prompts lack exploitable role information
  - Role consistency drops: T_role embedding failed; check E(I) function output
  - Defense triggers false positives: Leakage detection threshold too aggressive; adjust detector D sensitivity
  - Cooperation scores low despite successful ASR: T_topo missing topology information or adjacency matrix incorrect

- **First 3 experiments**:
  1. **Baseline topology comparison**: Construct identical 5-agent MAS across all 6 topologies with GPT-4o, run attack strategy, measure ASR by Turn 8 to validate Chain < Hierarchy vulnerability claim
  2. **Defense ablation**: Apply each defense strategy independently (Leakage-only, Hierarchical-only, Preemptive-only) on vulnerable configuration (Hierarchy + Gemini-2.5-Pro), compare ASR reduction efficiency
  3. **Propagation degree analysis**: Vary attack propagation levels (1-5 agents initially compromised) on Complete topology, plot ASR growth curve to validate "faster ASR growth in early rounds at higher levels" claim (Figure 3)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the integration of real-world environment interaction capabilities (such as API calling and function execution) alter the vulnerability of Multi-Agent Systems (MAS) to role- and topology-based attacks compared to text-only simulations?
- **Basis in paper**: [explicit] The "Limitations" section explicitly states that "research on MAS capable of interacting with real-world environments remains limited" and calls for future work on "environment-interactive MAS."
- **Why unresolved**: The current study restricts its experimental scope to text-based interactions and simulation modeling, explicitly excluding agents that invoke APIs or execute functions in external environments.
- **What evidence would resolve it**: Security evaluations of MAS agents equipped with tool-use or function-calling privileges, specifically measuring the impact of physical-world actions on Attack Success Rates (ASR).

### Open Question 2
- **Question**: To what extent does the explicit obfuscation of topological structures or role definitions hinder the efficacy of the proposed scenario-adaptive attack strategies?
- **Basis in paper**: [inferred] The "Probing Stage" of the methodology relies on agents accurately outputting their roles and neighboring agent information via a self-introduction template to construct the attack.
- **Why unresolved**: The framework assumes the attacker can successfully extract detailed system information (I) through probing. It is unclear if the attack remains effective if the system implements counter-measures to block this information leakage.
- **What evidence would resolve it**: Experimental results where the "Probing Stage" is restricted or returns obfuscated data, analyzing the corresponding drop in Attack Success Rate and adversarial role consistency.

### Open Question 3
- **Question**: What are the quantitative trade-offs between the computational overhead of the proposed Hierarchical Monitoring defense and the resulting security robustness in large-scale MAS?
- **Basis in paper**: [inferred] The "Defense Strategy" section claims the hierarchical monitoring achieves a "trade-off between efficiency and security," but the experiments primarily report Attack Success Rates rather than efficiency metrics like latency or token consumption.
- **Why unresolved**: While the defense effectively lowers ASR, the resource cost of deploying supervisory agents and frequent interaction monitoring is not quantified, leaving the practical scalability of the defense unproven.
- **What evidence would resolve it**: Performance benchmarks quantifying latency, inference time, and token costs for MAS protected by Hierarchical Monitoring versus unprotected baselines under high-concurrency workloads.

### Open Question 4
- **Question**: Do the observed variations in topological vulnerability (e.g., Chain vs. Hierarchy) persist consistently across different underlying LLM architectures, or are they artifacts of specific instruction-following sensitivities?
- **Basis in paper**: [inferred] The paper notes in the results that "Model sensitivity to topologies varies," with GPT-4o showing low sensitivity while Llama3-70B shows high sensitivity.
- **Why unresolved**: The study reports the phenomenon of varying topological safety but does not provide a mechanistic explanation for why certain model architectures exhibit strong topology-dependent vulnerability while others do not.
- **What evidence would resolve it**: A cross-model ablation study analyzing the correlation between specific LLM architectural traits (e.g., attention mechanisms, alignment methods) and their susceptibility to topological jailbreaking.

## Limitations

- **Simulation Fidelity**: Framework relies on controlled LLM API calls rather than real-world MAS deployments, limiting transfer to operational systems
- **Attack Generalization**: Effectiveness may not transfer equally to proprietary or fine-tuned LLMs with custom safety layers
- **Defense Completeness**: Proposed defenses reduce but don't eliminate vulnerabilities; adaptive countermeasures not explored

## Confidence

- **Simulation Fidelity**: Medium - experimental results show strong statistical significance within controlled parameters, but real-world agent interactions may exhibit different dynamics
- **Attack Generalization**: Low-Medium - results depend heavily on open-source model behavior patterns
- **Defense Completeness**: Medium - defensive effectiveness is well-demonstrated within tested scenarios

## Next Checks

1. **Real-World Deployment Test**: Deploy the framework on a physical MAS (e.g., robotics swarm or enterprise automation system) to validate simulation-to-reality transfer and measure attack success under operational constraints

2. **Adaptive Defense Evaluation**: Implement a dynamic defense system that learns from attack patterns and adjusts monitoring thresholds in real-time, then measure whether this reduces ASR below 5% across all tested topologies

3. **Cross-Model Generalization Study**: Test the complete attack-defense cycle across at least 10 different LLM architectures (including proprietary models) to establish whether ASR patterns hold consistently or vary significantly by model family