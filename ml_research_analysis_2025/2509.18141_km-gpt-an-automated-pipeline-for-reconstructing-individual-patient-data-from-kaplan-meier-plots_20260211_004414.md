---
ver: rpa2
title: 'KM-GPT: An Automated Pipeline for Reconstructing Individual Patient Data from
  Kaplan-Meier Plots'
arxiv_id: '2509.18141'
source_url: https://arxiv.org/abs/2509.18141
tags:
- survival
- km-gpt
- curves
- data
- plots
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KM-GPT is a fully automated pipeline for reconstructing individual
  patient data (IPD) from Kaplan-Meier (KM) survival plots. It uses advanced image
  preprocessing, multi-modal AI reasoning with GPT-5, and iterative reconstruction
  algorithms to convert published KM plots into structured IPD without manual input.
---

# KM-GPT: An Automated Pipeline for Reconstructing Individual Patient Data from Kaplan-Meier Plots

## Quick Facts
- arXiv ID: 2509.18141
- Source URL: https://arxiv.org/abs/2509.18141
- Authors: Yao Zhao; Haoyue Sun; Yantian Ding; Yanxun Xu
- Reference count: 40
- Primary result: Fully automated reconstruction of IPD from KM plots with 99.6% image processing success and median IAE of 0.018

## Executive Summary
KM-GPT is a fully automated pipeline that reconstructs individual patient data (IPD) from Kaplan-Meier survival plots without manual intervention. The system combines advanced image preprocessing, multi-modal AI reasoning with GPT-5, and iterative reconstruction algorithms to convert published KM plots into structured IPD. It achieves high accuracy on both synthetic data (median IAE 0.018) and real clinical KM plots from metastatic breast cancer studies, enabling secondary analyses and meta-analyses that were previously impossible without access to raw patient-level data.

## Method Summary
KM-GPT uses a multi-stage approach: image preprocessing with super-resolution and adaptive thresholding, parameter extraction via OCR and GPT-5 multi-modal reasoning, IPD extraction through curve digitization and clustering, and iterative reconstruction using the iKM algorithm to reconcile curve shapes with risk table counts. The pipeline is designed to handle diverse plot formats and extract both survival curves and number-at-risk information to reconstruct individual patient-level survival data.

## Key Results
- 99.6% image processing success rate on diverse KM plot formats
- 100% accuracy in extracting axis parameters and risk tables
- Median integrated absolute error of 0.018 in survival curve reconstruction on synthetic data
- Accurate reconstruction of median survival times from real clinical KM plots
- Enables secondary analyses including biomarker-stratified meta-analyses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid OCR + LLM reasoning resolves visual-semantic ambiguities in KM plots better than either modality alone.
- Mechanism: OCR extracts structured tokens (axis labels, risk table values) with high precision but lacks contextual understanding. GPT-5 receives both the base64-encoded image and OCR tokens, using cross-modal attention to disambiguate unclear features—matching curve colors to group labels, validating extracted numbers against visual patterns, and resolving overlapping elements.
- Core assumption: OCR errors are detectable when cross-referenced against visual context; GPT-5's multi-modal attention can bridge these modalities reliably.
- Evidence anchors:
  - [abstract]: "MMPU... hybrid architecture that fuses classical optical character recognition (OCR) with modern multi-modal AI reasoning powered by GPT-5"
  - [section 2.2]: "GPT-5 processes these OCR outputs with the original image through its unified multi-modal attention architecture... performs semantic and visual reasoning jointly to resolve KM-specific ambiguities"
  - [corpus]: Related work on "Leveraging Vision Capabilities of Multimodal LLMs for Automated Data Extraction from Plots" supports this hybrid approach but doesn't validate the specific KM plot domain.
- Break condition: If OCR quality degrades severely (e.g., very low-resolution scans), the token-level errors may propagate even with LLM correction; if GPT-5's vision encoding fails to preserve spatial relationships, cross-modal alignment degrades.

### Mechanism 2
- Claim: Image preprocessing with super-resolution and adaptive thresholding enables robust feature extraction across heterogeneous plot formats.
- Mechanism: ESPCN (super-resolution) upscales images 2x before processing. Laplacian sharpening enhances high-frequency edges (curve boundaries, thin axis lines). Adaptive thresholding with Gaussian weighting handles variable lighting in risk table regions, while global thresholding suffices for high-contrast axis labels. Denoising removes compression artifacts.
- Core assumption: The transformations preserve semantic content while improving signal-to-noise ratio for downstream OCR and curve detection.
- Evidence anchors:
  - [section 2.1]: "image resolution is improved using the efficient sub-pixel convolutional neural network (ESPCN) model... enhancing the image resolution by a factor of 2"
  - [section 2.2]: "For risk tables, we adopt adaptive thresholding with Gaussian weighting... For axis label regions, we instead apply global thresholding"
  - [corpus]: No direct corpus validation for this specific preprocessing chain on medical plots.
- Break condition: Over-sharpening introduces artifacts that OCR interprets as characters; adaptive thresholding fails when risk tables have inconsistent background shading within a single image.

### Mechanism 3
- Claim: Iterative alignment of digitized survival curves with risk tables yields IPD that preserves both curve shape and reported risk sets.
- Mechanism: Pixel-level curve coordinates are mapped to (time, survival probability) via affine transformation from axis calibration. K-medoids clustering separates curves; k-NN resolves overlapping segments. The iKM iterative algorithm then reconciles event/censoring assignments to match extracted number-at-risk values while maintaining curve fidelity.
- Core assumption: The risk table values are accurate and temporally aligned with the curve; small digitization errors average out during iterative reconciliation.
- Evidence anchors:
  - [section 2.3]: "iterative event reconstruction algorithm from iKM... iteratively reconciles event and censoring assignments to ensure reconstructed risk sets match reported values"
  - [section 4.2.2]: "median IAE of 0.018 (95% CI: 0.002–0.088), demonstrating its overall accuracy in reconstructing survival curves"
  - [corpus]: The "PISA" pipeline addresses survival analysis but targets model selection, not IPD reconstruction—no direct validation.
- Break condition: When risk tables are incomplete or misaligned with curve timepoints, the iterative algorithm produces inconsistent IPD; tail regions with sparse events show elevated error (noted in Section 4.2.2).

## Foundational Learning

- Concept: **Kaplan-Meier Estimator**
  - Why needed here: KM-GPT reconstructs IPD by inverting the KM product-limit estimator; understanding how KM curves encode survival probability and censoring is essential to grasp what the pipeline recovers.
  - Quick check question: Given a KM curve dropping from 1.0 to 0.6 at t=10 with 5 events, what's the implied number at risk just before t=10?

- Concept: **Multi-Modal Vision-Language Models**
  - Why needed here: MMPU relies on GPT-5's ability to process images and text jointly; understanding how vision encoders map to token embeddings clarifies why OCR + image together outperform either alone.
  - Quick check question: If OCR extracts "100" from a blurry axis label but the visual context suggests "10.0", how would a multi-modal model resolve this?

- Concept: **Iterative Reconstruction (iKM Algorithm)**
  - Why needed here: The IPD reconstruction isn't direct inversion—it's iterative optimization matching curve shape to risk table counts. Understanding this explains why accuracy varies with censoring patterns.
  - Quick check question: Why does the iKM algorithm need both the survival curve coordinates AND the number-at-risk table, rather than just the curve?

## Architecture Onboarding

- Component map: Input Image → [Data Validation: InputGuard/GPT-5] → [Image Processing: ESPCN → Resize → Sharpen → Denoise] → [MMPU: OCR + GPT-5 multi-modal reasoning] → JSON config → [IPD Extraction: Axis calibration, K-medoids, k-NN overlap resolution] → [IPD Reconstruction: iKM iterative alignment] → CSV output

- Critical path: MMPU is the bottleneck—OCR quality + GPT-5 reasoning directly determine whether downstream reconstruction even initiates. If axis calibration fails here, all subsequent steps produce garbage.

- Design tradeoffs:
  - Full automation vs. human-in-the-loop: InputGuard provides feedback but users can manually crop/erase before processing—trading scalability for edge-case handling.
  - Generalization vs. domain-specificity: Thresholding strategies are tuned for KM plots specifically; won't transfer to generic chart extraction.
  - LLM dependency: Pipeline requires OpenAI API access; no offline fallback.

- Failure signatures:
  - 99.6% success rate means ~0.4% fail at image processing—look for digitization errors where MMPU-extracted parameters mismatch OCR values.
  - Elevated IAE in "tail effect" scenarios: curves nearing x-axis cause pixel confusion between curve and axis.
  - Multi-arm plots with similar colors: K-medoids clustering degrades when chroma differences are minimal.

- First 3 experiments:
  1. Reproduce synthetic data evaluation: Generate 20 KM plots with known parameters (n=200, median survival=12mo, censoring=30%), run through KM-GPT, compute IAE against ground truth. Verify median IAE ≈ 0.018.
  2. Ablate MMPU: Replace GPT-5 multi-modal reasoning with OCR-only extraction. Measure axis/risk table extraction accuracy drop—expect degradation on ambiguous plots.
  3. Test boundary conditions: Feed low-resolution scans (<150 DPI) and plots with monochromatic curves (style-only differentiation). Document failure modes for future robustness improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can improved axis calibration algorithms effectively mitigate reconstruction errors in the tail regions of Kaplan-Meier curves where event data is sparse?
- Basis in paper: [explicit] The authors identify that "reconstruction accuracy is particularly vulnerable in the tail regions" and state that "Addressing this limitation is a priority... [to] develop improved axis calibration strategies" (Page 28).
- Why unresolved: Current methods struggle to distinguish curve pixels from axis elements in later follow-up periods when the survival curve approaches zero and visual data is limited.
- What evidence would resolve it: Demonstration of significantly reduced variance in median survival estimates for heavily censored datasets or curves with flat segments near the median threshold.

### Open Question 2
- Question: How can automated pipelines reliably differentiate survival curves in monochromatic plots that rely on line styles (e.g., dashed vs. solid) rather than color?
- Basis in paper: [explicit] The authors state, "we plan to develop more advanced algorithms capable of reliably processing monochromatic KM plots, where group distinctions are indicated by line styles rather than colors" (Page 29).
- Why unresolved: The current KM-GPT pipeline uses color-space partitioning (HSL clustering) to group pixels, which fundamentally fails when curves are distinguished only by texture or pattern.
- What evidence would resolve it: Successful application of a new method to a benchmark set of monochromatic plots, achieving accuracy comparable to the current color-based results.

### Open Question 3
- Question: Can the system be extended to extract and process Kaplan-Meier plots directly from full PDF trial reports while automatically aligning them with textual study characteristics?
- Basis in paper: [explicit] The authors list "direct extraction and processing of KM plots from PDF trial reports" and "automatic alignment... with reported study characteristics" as an important future direction (Page 29).
- Why unresolved: This requires bridging the gap between unstructured document navigation (finding the figure in a PDF) and the current structured image-processing pipeline, adding a layer of semantic document understanding.
- What evidence would resolve it: An end-to-end workflow that accepts a clinical trial PDF file as input and outputs structured individual patient data correctly labeled with subgroup criteria extracted from the text.

## Limitations

- GPT-5 dependency creates reproducibility barriers since the model is not publicly available for independent validation
- Tail region reconstruction shows systematic degradation when curves approach the x-axis with sparse events
- Current color-based clustering fails on monochromatic plots that distinguish groups using line styles rather than colors

## Confidence

- **High confidence**: Image preprocessing pipeline (ESPCN, Laplacian sharpening, adaptive thresholding) - these are standard computer vision techniques with established performance
- **Medium confidence**: Parameter extraction accuracy (axis calibration, risk tables) - reported as 100% but depends on OCR quality and GPT-5 reasoning which are not independently reproducible
- **Medium confidence**: Synthetic data evaluation (IAE = 0.018) - controlled environment with known ground truth, but may not reflect real-world plot variability
- **Low confidence**: Real-world clinical performance claims - limited to 4 metastatic breast cancer studies without comprehensive external validation across diverse cancer types and publication sources

## Next Checks

1. **Reproduce synthetic evaluation**: Generate 20 KM plots with known parameters (n=200, median survival=12mo, censoring=30%), process through KM-GPT using GPT-4 Vision instead of GPT-5, and compute IAE. Verify if median IAE remains near 0.018 with the substitute model.

2. **Test real clinical plots across cancer types**: Apply KM-GPT to 10 KM plots from different cancer types (lung, colorectal, prostate) and publication years (spanning 2010-2023). Compare reconstructed median survival times against reported values and assess inter-study variability.

3. **Evaluate failure modes systematically**: Create a benchmark set of challenging KM plots including: (a) low-resolution scans (<150 DPI), (b) monochromatic curves with style-only differentiation, (c) incomplete risk tables, and (d) multi-arm plots with similar colors. Document success rates and error patterns for each category.