---
ver: rpa2
title: Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language
  Model Feedback
arxiv_id: '2511.22307'
source_url: https://arxiv.org/abs/2511.22307
tags:
- case
- feedback
- composition
- page
- compositions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a multi-agent, text gradient-driven framework
  for conditional generation of double perovskite (DP) materials, integrating LLM-based
  self-evaluation, domain knowledge-informed feedback, and ML surrogate-based feedback.
  The framework improves the thermodynamic stability of generated compositions by
  iteratively refining them through feedback loops, achieving over 98% compositional
  validity and up to 54% stable or metastable candidates.
---

# Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback

## Quick Facts
- arXiv ID: 2511.22307
- Source URL: https://arxiv.org/abs/2511.22307
- Reference count: 40
- Primary result: Multi-agent text gradient framework improves DP stability from 43% (LLM-only) to 54% (with knowledge feedback)

## Executive Summary
This work introduces a multi-agent framework for conditional generation of double perovskite materials that uses LLM-based self-evaluation, domain knowledge feedback, and ML surrogate predictions to iteratively refine compositions. The system achieves over 98% compositional validity and up to 54% stable or metastable candidates, outperforming both LLM-only baselines (43%) and prior GAN-based approaches (27%). The framework demonstrates that natural language feedback can serve as an effective optimization signal in materials discovery, particularly when combined with domain-specific heuristics and data-driven surrogates.

## Method Summary
The framework uses three incremental cases: (1) zero-shot LLM generation, (2) LLM with LLM-based feedback, and (3) LLM with domain knowledge feedback. An additional variant integrates ML-based feedback via CrabNet surrogate. The system iteratively refines candidate compositions through a feedback loop where evaluators assess properties, text gradient agents translate feedback into modification instructions, and the proposal agent generates new candidates. Key components include a tolerance factor heuristic for domain knowledge, a CrabNet surrogate for ML feedback, and DFT validation via VASP/PBE-GGA. The framework operates on 5 natural language queries targeting different stability, element, and perovskite-type conditions.

## Key Results
- 54% of generated compositions are stable or metastable (energy above hull < 0.05 eV/atom) with knowledge feedback
- 98%+ compositional validity across all cases
- ML-based gradients enhance performance in in-distribution regions but degrade in out-of-distribution regimes
- Systematic improvement over LLM-only baseline (43%) and prior GAN-based results (27%)

## Why This Works (Mechanism)

### Mechanism 1: Iterative Text Gradient Refinement
The system treats natural language critique as a pseudo-gradient, allowing iterative correction of compositional errors. An LLM-based Evaluator assesses proposed compositions, and a Text Gradient Agent translates this into actionable modification instructions, enabling the Proposal Agent to improve subsequent iterations. This closes the loop for constraint satisfaction, achieving ~54% stability versus ~43% with zero-shot generation. The core assumption is that LLMs possess sufficient chemical reasoning to interpret evaluative feedback without weight updates.

### Mechanism 2: Domain Knowledge Steering
Explicit domain knowledge (tolerance factor heuristic) serves as a feedback signal that steers the model toward thermodynamically favorable regions more effectively than LLM reasoning alone. The new tolerance factor constrains search space to physically plausible geometries, biasing probabilistic generation toward stable configurations. The heuristic threshold of < 4.18 correlates with stability, though strict adherence can cause the agent to violate other constraints like perovskite type.

### Mechanism 3: ML Surrogate Reliability Gradient
ML predictor (CrabNet) provides stability probability acting as data-driven gradient. Within in-distribution regions (chemically similar to training data), the gradient is reliable and improves performance. In out-of-distribution regimes, surrogate uncertainty increases, potentially generating misleading text gradients that misdirect the Proposal Agent. This explains degraded stability in rare-earth and chalcogenide compositions where the surrogate's predictions become unreliable.

## Foundational Learning

- **Text Gradients**: Natural language suggestions derived from feedback (e.g., "reduce ionic radius") that serve as optimization primitives. Why needed: This is the core optimization mechanism distinct from numerical gradients. Quick check: How does the system translate calculated losses into prompts for the next iteration?

- **In-Context Learning (ICL)**: LLM improvement without weight updates using prompt history. Why needed: Understanding ICL is necessary to see why storing rejected candidates prevents repetitive errors. Quick check: Does the model fine-tune on new stable compounds or use prompt history?

- **In-Distribution vs Out-of-Distribution**: Critical for diagnosing failure modes. Why needed: Distinguishes between LLM reasoning failures and ML surrogate extrapolation failures. Quick check: If the agent generates a compound with rare earth elements not seen during surrogate training, should you trust the ML-based text gradient?

## Architecture Onboarding

- **Component map**: User Query → Condition Extractor → Proposal Agent → [Evaluation Loop: Evaluate → Gradient → Repropose] → POSCAR Formatter → DFT Verification
- **Critical path**: The iterative evaluation-refinement loop where each agent's output feeds into the next, with history buffer preventing repetitive errors
- **Design tradeoffs**: Stability vs Diversity (strict feedback yields higher stability but higher rejection rates), Speed vs Reliability (ML feedback adds overhead and OOD risk)
- **Failure signatures**: Condition Drift (satisfies stability but violates perovskite type), OOD Hallucination (invalid structures from false surrogate predictions)
- **First 3 experiments**:
  1. Baseline ablation: Run Query 1 (Halide) with only LLM Evaluator vs Knowledge Evaluator to measure energy above hull delta
  2. OOD stress test: Generate rare-earth compositions (Query 5) with ML feedback enabled vs disabled to verify degradation
  3. Constraint balancing: Introduce conflicting constraints ("Stable Chalcogenide") to observe if Knowledge Gradient causes perovskite-type violations

## Open Questions the Paper Calls Out

### Open Question 1: Gradient Weighting
How can multiple text gradients (LLM, knowledge, ML) be systematically weighted to avoid conflicts when optimizing competing constraints? The paper uses simple concatenation but notes strict knowledge constraints led to higher rejection rates, underscoring need for principled gradient balancing.

### Open Question 2: Adaptive Surrogate Refinement
Can adaptive surrogate model refinement extend ML-based gradient reliability into OOD compositional regions? The paper suggests combining selective data acquisition with iterative model refinement, noting Query 2 and 5 showed marked F1-score degradation (~0.4-0.5 vs ~0.85-0.88 ID).

### Open Question 3: Database-Guided Hull Energy
Would integrating real-time database queries to assess phase competition improve energy-above-hull optimization? The paper identifies hull energy as more comprehensive than formation energy but current feedback only indirectly guides it.

### Open Question 4: Framework Generalization
How does the framework generalize to materials classes beyond double perovskites? While natural extension is claimed to single perovskites and anti-perovskites, each class has distinct stability heuristics and surrogate data availability varies.

## Limitations

- LLM feedback quality not quantified with error rate statistics or ablation studies
- Tolerance factor heuristic not validated as optimal constraint against alternatives
- ML surrogate performance in OOD regions demonstrated but underlying causes not thoroughly analyzed
- History buffer effectiveness in preventing repetitive errors asserted but not empirically demonstrated

## Confidence

- **High confidence**: Comparative performance metrics (54% vs 43% vs 27%) and systematic ablation across cases
- **Medium confidence**: Mechanism explaining ML feedback degradation in OOD regions relies on general surrogate principles
- **Low confidence**: Claim that history buffer prevents repetitive errors lacks empirical failure rate statistics

## Next Checks

1. **Gradient translation accuracy**: Implement logging to track how often LLM-generated text gradients successfully improve compositions versus leading to dead ends or condition violations
2. **OOD surrogate uncertainty**: For queries 2 and 5, compare ML-predicted stability scores with actual DFT validation across a grid of candidates to quantify surrogate hallucination extent
3. **Heuristic constraint optimization**: Systematically vary the tolerance factor threshold (4.18) and observe impact on both stability rates and perovskite-type condition satisfaction to identify constraint conflicts