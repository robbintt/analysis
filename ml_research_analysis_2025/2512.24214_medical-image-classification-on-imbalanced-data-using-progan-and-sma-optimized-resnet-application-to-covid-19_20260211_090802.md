---
ver: rpa2
title: 'Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized
  ResNet: Application to COVID-19'
arxiv_id: '2512.24214'
source_url: https://arxiv.org/abs/2512.24214
tags:
- images
- covid-19
- network
- dataset
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of imbalanced data in medical
  image classification, specifically for COVID-19 detection from chest X-ray (CXR)
  images. A progressive generative adversarial network (ProGAN) is proposed to generate
  synthetic CXR images for underrepresented classes, combined with a weighted approach
  to integrate synthetic and real data.
---

# Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized ResNet: Application to COVID-19

## Quick Facts
- arXiv ID: 2512.24214
- Source URL: https://arxiv.org/abs/2512.24214
- Reference count: 40
- The study achieves 95.5% accuracy for four-class COVID-19 CXR classification and 98.5% for binary classification using ProGAN-generated synthetic data and SMA-optimized ResNet50V2.

## Executive Summary
This paper addresses the challenge of classifying imbalanced medical imaging data, specifically for COVID-19 detection from chest X-ray images. The authors propose a progressive generative adversarial network (ProGAN) to generate synthetic CXR images for underrepresented classes, combined with a weighted approach to integrate synthetic and real data. Hyperparameter optimization of the classifier (ResNet50V2) is performed using the Slime Mould Algorithm (SMA). The model is evaluated on a large, imbalanced CXR dataset containing four classes: COVID-19, Normal, Viral Pneumonia, and Lung Opacity. Results show that the optimized model with synthetic data injection achieves 95.5% accuracy for four-class classification and 98.5% accuracy for binary classification. The approach effectively mitigates class imbalance and enhances classification performance, demonstrating its potential for reliable COVID-19 detection in medical imaging.

## Method Summary
The methodology combines progressive GAN training for synthetic data generation with meta-heuristic hyperparameter optimization. First, separate ProGANs are trained for each minority class (COVID-19, Viral Pneumonia, Lung Opacity) using progressive resolution growth from 7×7 to 224×224 with WGAN-GP loss. Synthetic images are generated and injected using complementary frequency weights to balance the dataset. The ResNet50V2 classifier is then optimized using SMA to find optimal learning rate, dropout, and synthetic injection ratio. The final model is trained on the combined real and synthetic data with 10-fold cross-validation, where test sets contain only real images to ensure fair evaluation.

## Key Results
- Achieved 95.5% accuracy for four-class classification (COVID-19, Normal, Viral Pneumonia, Lung Opacity)
- Achieved 98.5% accuracy for binary classification (COVID-19 vs Normal)
- Outperformed baseline models including standard ResNet50V2, VGG16, and InceptionV3
- Demonstrated effectiveness of weighted synthetic data injection with optimal SIIR ratio of 0.20

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Progressive training of GANs stabilizes synthetic medical image generation for minority class augmentation.
- **Mechanism:** ProGAN starts at low resolution (7×7) and progressively doubles through 6 stages to 224×224. Each stage adds convolutional blocks to generator and discriminator. This allows the network to learn coarse features first, then refine details, reducing training instability common in medical GANs.
- **Core assumption:** Lower-resolution images contain learnable CXR features that transfer to higher resolutions.
- **Evidence anchors:**
  - [abstract]: "proposing a progressive generative adversarial network to generate synthetic data to supplement the real ones"
  - [section 4, Table 5-6]: Shows 6-stage progression with epoch counts increasing [250, 300, 350, 400, 450, 500] as resolution grows
  - [corpus]: Paper 55989 confirms ProGAN as augmentation baseline for medical imaging
- **Break condition:** If critic-generator loss fails to converge at later stages (observed in stages 5-6 per Figure 7-8), synthetic images may lack discriminative features.

### Mechanism 2
- **Claim:** Weighted synthetic injection inversely proportional to class frequency reduces classifier bias toward majority classes.
- **Mechanism:** Calculate complementary frequency (n_normal - n_label) for each underrepresented class, then compute injection weight proportional to this gap. More synthetic images are added to smaller classes. The SIIR parameter (optimized to 0.20) controls overall synthetic-to-real ratio.
- **Core assumption:** Synthetic images from minority classes carry equivalent discriminative information to real images.
- **Evidence anchors:**
  - [abstract]: "weighted approach to combine synthetic data with real ones before inputting it into a deep network classifier"
  - [section 3.1, Equations 1-7]: Formal derivation of complementary frequency and injection weights
  - [corpus]: Paper 111180 confirms GAN-based minority class oversampling improves medical classification
- **Break condition:** If SIIR exceeds ~0.40, accuracy degrades (Table 9 shows VGG16 drops from 89.98% at SIIR=0.20 to 87.87% at SIIR=0.60).

### Mechanism 3
- **Claim:** Meta-heuristic hyperparameter optimization (SMA) finds classifier configurations that manual tuning would miss.
- **Mechanism:** Slime Mould Algorithm explores search space using population-based oscillation dynamics. Optimizes learning rate (bounds: 1e-5 to 1e-3), dropout rate (0.05 to 0.25), and SIIR (0 to 0.5) by minimizing classifier validation loss over 250 epochs.
- **Core assumption:** The SMA search dynamics generalize to this 3-dimensional hyperparameter space.
- **Evidence anchors:**
  - [abstract]: "multi-objective meta-heuristic population-based optimization algorithm is employed to optimize the hyper-parameters"
  - [section 4, Table 3]: SMA parameters (population=15, epochs=250, objective=classifier loss)
  - [corpus]: No direct corpus evidence for SMA specifically; paper states "As of writing this paper, the proposed methods were not used in other studies"
- **Break condition:** If optimized learning rate (7.26e-5) is too conservative, convergence may be slow; if too aggressive, may overshoot optima.

## Foundational Learning

- **Concept: Class Imbalance in Medical Imaging**
  - Why needed here: Dataset has severe imbalance (Viral Pneumonia: 6.35% vs Normal: 48.15%). Without intervention, classifier learns majority features dominantly.
  - Quick check question: Given a 4-class dataset with frequencies [3616, 10192, 1345, 6012], which class would a standard cross-entropy loss prioritize?

- **Concept: Wasserstein Loss with Gradient Penalty (WGAN-GP)**
  - Why needed here: ProGAN uses WGAN-GP to stabilize GAN training. Standard GAN loss causes mode collapse—synthetic images lack diversity.
  - Quick check question: Why does Wasserstein distance provide more meaningful gradients than JS-divergence when real and synthetic distributions don't overlap?

- **Concept: Progressive Growing in GANs**
  - Why needed here: Direct training at 224×224 is unstable. Progressive growing allows stable learning of hierarchical features from coarse to fine.
  - Quick check question: If you skip stages and train directly at 112×112, what artifacts would you expect in generated images?

## Architecture Onboarding

- **Component map:**
  ProGAN (per class, 4 total)
    ├── Generator: Latent(112×1×1) → TConv2D → Upsample blocks → ToRGB(3×224×224)
    └── Critic: Image(3×224×224) → Conv2D + Downsample blocks → Score(1×1×1)

  ResNet50V2 Classifier (ImageNet pretrained)
    ├── Input: 224×224×3 (real + weighted synthetic)
    ├── Backbone: ResNet50V2 (frozen initial layers, fine-tuned later)
    └── Head: GlobalAvgPool → Dropout(0.17) → Dense(4)

  SMA Optimizer
    └── Search space: [LR, Dropout, SIIR] with bounds [[1e-5, 0.05, 0], [1e-3, 0.25, 0.5]]

- **Critical path:**
  1. Train 4 separate ProGANs (one per class) → generate ~40K synthetic images
  2. Calculate injection weights per class using complementary frequency formula
  3. Run SMA optimization (250 epochs, 15 population) to find optimal LR/Dropout/SIIR
  4. Train final ResNet50V2 with optimized hyperparameters on combined dataset
  5. Evaluate using 10-fold cross-validation on REAL images only (synthetic excluded from test)

- **Design tradeoffs:**
  - ProGAN stages: More stages = higher quality but more VRAM and training time. Authors reduced batch size from 256 to 8 across stages.
  - SIIR ratio: Higher = better balance but risk of synthetic artifacts dominating. Optimal was 0.20, not 0.50+.
  - SMA population: Larger = better exploration but slower. 15 chosen empirically, authors note "not the most efficient."

- **Failure signatures:**
  - Non-convergent critic/generator loss at later ProGAN stages (Figure 7-8): indicates insufficient network capacity or wrong hyperparameters
  - Synthetic images visually indistinguishable from noise: latent space too small or training epochs insufficient
  - Classifier accuracy plateaus or drops with synthetic data: SIIR too high or ProGAN mode collapse

- **First 3 experiments:**
  1. Train ProGAN for single class (e.g., COVID-19) through all 6 stages; visualize synthetic images at each stage to verify progressive quality improvement
  2. Implement SIIR sweep (0.00 to 0.40) with fixed ResNet50V2 on 2-class problem; plot accuracy vs. SIIR to reproduce optimal ~0.20 finding
  3. Run SMA optimization with reduced epochs (50 vs. 250) to quantify convergence speed vs. hyperparameter quality tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would combining the ProGAN synthetic data augmentation approach with the unified 15,000-image balanced dataset from Badawi et al. further improve classification performance beyond the current 95.5% accuracy?
- Basis in paper: [explicit] The authors state: "However, for future work on developing our method described in this paper, we believe that combining our approach with their compiled dataset would undoubtedly enhance the performance of classifiers significantly."
- Why unresolved: Badawi et al.'s study was published after this research was completed, so the combined approach has not been tested.
- What evidence would resolve it: Experimental results comparing classification metrics when the ProGAN-SMA method is applied to the 15,000-image balanced dataset versus the current 21,165-image imbalanced dataset.

### Open Question 2
- Question: What specific architectural modifications to the ProGAN generator and critic networks would improve loss convergence during the higher-resolution training stages (112×112 and 224×224)?
- Basis in paper: [explicit] The authors note that "in the final stages (Specifically stage #5 and stage #6) of training the ProGAN network, the loss values do not tend to be balanced and converge" and list potential causes including "Insufficient capacity of the generator and critic networks" and "The structure of the generator and critic networks are not expedient."
- Why unresolved: The paper identifies the convergence problem but does not implement or test solutions.
- What evidence would resolve it: Ablation studies testing different network depths, filter counts, or architectural variants showing improved Wasserstein loss convergence at stages 5-6.

### Open Question 3
- Question: What is the optimal configuration of SMA hyperparameters (population size, epoch count, search bounds) for classifier optimization, and how much performance gain could be achieved?
- Basis in paper: [explicit] The authors state: "Albeit, the selected values are not the most efficient ones; thus, they could be improved to enhance the performance of the optimization algorithm" regarding the SMA parameters in Table 3.
- Why unresolved: The paper uses empirically chosen SMA values without systematic hyperparameter tuning of the optimizer itself.
- What evidence would resolve it: Grid search or meta-optimization experiments over SMA parameters demonstrating improved classifier accuracy compared to the current 95.5% (4-class) result.

## Limitations

- Lack of ablation studies on individual components (ProGAN vs. other GANs, SMA vs. random search) to isolate their contributions to the reported performance gains.
- No statistical significance testing is reported to validate that the improvements over baselines are meaningful.
- The claim of novelty is limited since the components (ProGAN, SMA, class imbalance handling) are well-established individually.

## Confidence

- **High:** Accuracy metrics (95.5% 4-class, 98.5% binary) are reproducible given the specified dataset and methodology.
- **Medium:** The ProGAN implementation details are sufficient for replication, but visual quality of generated images is not objectively evaluated.
- **Low:** The novelty contribution and statistical significance of improvements over baselines are unclear.

## Next Checks

1. **Ablation Study:** Run experiments with (a) real data only, (b) synthetic data injection without optimization, (c) SMA-optimized ResNet without synthetic data, to isolate component contributions.
2. **Statistical Validation:** Perform paired t-tests or McNemar's test on 10-fold cross-validation results to confirm significant improvement over baseline classifiers.
3. **Synthetic Data Quality:** Compute Fréchet Inception Distance (FID) or Inception Score (IS) for generated images to objectively measure ProGAN output quality.