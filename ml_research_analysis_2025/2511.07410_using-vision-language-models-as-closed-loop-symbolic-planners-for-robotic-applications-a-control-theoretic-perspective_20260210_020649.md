---
ver: rpa2
title: 'Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic
  Applications: A Control-Theoretic Perspective'
arxiv_id: '2511.07410'
source_url: https://arxiv.org/abs/2511.07410
tags:
- planner
- task
- planners
- vlms
- symbolic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates using vision-language models (VLMs) as closed-loop
  symbolic planners for robotic applications. The authors conduct controlled experiments
  comparing open-loop and closed-loop planners across four task environments and three
  VLMs, focusing on control horizon and warm-starting effects.
---

# Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective

## Quick Facts
- arXiv ID: 2511.07410
- Source URL: https://arxiv.org/abs/2511.07410
- Reference count: 39
- Primary result: Closed-loop VLM planning consistently outperforms open-loop planning due to VLM inference errors, with warm-starting providing consistent improvements in both geometric and logical reasoning.

## Executive Summary
This paper investigates using vision-language models (VLMs) as closed-loop symbolic planners for robotic manipulation tasks. The authors conduct controlled experiments comparing open-loop (plan once, execute fully) versus closed-loop (replan based on updated state) planners across four task environments and three VLMs. They focus on how control horizon length and warm-starting (providing prior plans and execution feedback) affect performance. The key finding is that closed-loop planning is consistently better than open-loop, even in static environments, primarily due to VLM inference errors that replanning can recover from. Warm-starting significantly improves both geometric and logical reasoning capabilities, while control horizon choice has minimal impact when warm-starting is properly utilized.

## Method Summary
The study uses a hierarchical framework where VLMs generate symbolic plans (sequences of parameterized pick/place actions) that are then executed by a motion planner. The planners are tested in four environments (CUBE-EASY, YCB-EASY, YCB-MEDIUM, YCB-HARD) with three zero-shot VLMs (GPT-4.1-mini, Gemini-2.5-flash, Llama-4-Maverick). Five planner variants are compared: open-loop (OL), closed-loop with short (2 steps), half, and full control horizons, with and without warm-starting. Warm-starting provides the VLM with previous plans and execution statuses. The study uses 50 randomized trials per scenario and measures Task Completion Rate (primary), Goal Achieved Rate (geometric), Correct Final Logical Plan Rate (logical), and Positive/Negative Logical Correction Rates, with statistical significance testing at α=0.05.

## Key Results
- Closed-loop planning consistently outperforms open-loop planning across all environments and VLMs, even in static environments
- Warm-starting improves performance in 21 out of 24 scenarios with an average improvement of 28.2%
- Control horizon choice does not significantly impact performance when warm-starting is used
- CL-SHORT achieves the best Task Completion Rate in 10 of 12 scenarios, but only 2 results are statistically significant

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Closed-loop planning recovers from VLM inference errors that would otherwise cause task failure, even when the environment is static.
- Mechanism: Each replanning iteration provides the VLM with updated observations, allowing it to detect and correct misplaced objects or constraint violations from prior plan execution. This is analogous to feedback control compensating for plant uncertainty.
- Core assumption: VLMs produce imperfect plans on the first attempt but can recognize and fix errors when given fresh observations.
- Evidence anchors:
  - [abstract] "closed-loop planning is consistently better than open-loop, even in static environments, due to VLM inference errors"
  - [section 4.1] "closed-loop is still preferred even when the environment is static, largely because VLMs do not always generate goal-achieving and constraint-satisfying plans"
  - [corpus] ViPlan benchmark (arXiv:2505.13180) explores VLM-grounded symbolic planning, providing complementary evidence that visual grounding improves plan correctness, though it does not directly study closed-loop error recovery.
- Break condition: If VLM inference errors are systematic (e.g., consistent misidentification of objects) rather than stochastic, replanning may not converge to correct plans.

### Mechanism 2
- Claim: Warm-starting improves both geometric and logical reasoning by anchoring the replan to a prior plan and execution feedback.
- Mechanism: By providing the previously generated plan and execution statuses (success/failure of each action), the VLM can incrementally repair rather than regenerate from scratch. This reduces the probability of compounding errors across multiple independent queries.
- Core assumption: The VLM can correctly interpret execution feedback and make targeted adjustments rather than wholesale replans.
- Evidence anchors:
  - [abstract] "warm-starting consistently improves both geometric and logical reasoning capabilities"
  - [section 4.3] "warm-starting variants are better in 21 out of 24 scenarios (13 of the 21 results are statistically significant) with an average improvement of 28.2%"
  - [corpus] Hierarchical Planning with Knowledge Graph-RAG (arXiv:2504.04578) discusses plan refinement through iterative retrieval, which is conceptually related but does not directly study warm-starting with execution feedback.
- Break condition: If the prior plan contains foundational logical errors (e.g., wrong object ordering), warm-starting may bias the VLM toward perpetuating rather than correcting these errors.

### Mechanism 3
- Claim: Control horizon choice does not substantially impact performance when warm-starting is properly utilized.
- Mechanism: With warm-starting, the planner inherits a reasonable prior plan at each replan step. Shorter horizons provide more replan opportunities but also more chances for the VLM to introduce errors; these effects largely cancel out.
- Core assumption: Warm-starting effectively constrains the search space so that additional replanning opportunities do not yield marginal benefits.
- Evidence anchors:
  - [abstract] "Shorter control horizons do not significantly improve performance"
  - [section 4.2] "CL-SHORT achieves the best Task Completion Rate in 10 of the scenarios, but only 2 of the results are statistically significant"
  - [corpus] Constrained Natural Language Action Planning (arXiv:2510.06357) addresses hallucination and error propagation in LLM planners, but does not specifically examine control horizon effects.
- Break condition: In dynamic environments (explicitly excluded from this study), shorter control horizons may become necessary to track environmental changes.

## Foundational Learning

- **Model Predictive Control (MPC)**
  - Why needed here: The paper frames closed-loop VLM planning as analogous to MPC, where a planner repeatedly generates trajectories and executes a subset before replanning. Understanding MPC provides intuition for why control horizon and warm-starting are relevant parameters.
  - Quick check question: In MPC, what happens to the control trajectory at each time step after a portion is executed?

- **Open-loop vs. Closed-loop Planning**
  - Why needed here: The core comparison in the paper is between open-loop (plan once, execute fully) and closed-loop (replan based on updated state). This distinction is fundamental to interpreting the experimental results.
  - Quick check question: Why might a closed-loop controller outperform an open-loop controller even when the environment model is perfect?

- **Warm-starting in Iterative Optimization**
  - Why needed here: Warm-starting is a standard technique in optimization where a previous solution initializes the next solve. The paper adapts this concept to VLM planning by feeding prior plans and execution results into subsequent prompts.
  - Quick check question: How does warm-starting differ from simply constraining the solution space?

## Architecture Onboarding

- Component map: VLM Planner -> Prompt Constructor -> Execution Monitor -> Motion Planner -> Robot Trajectory -> Physical Execution

- Critical path:
  1. VLM receives task description, object positions (via images), and available primitives (pick, place)
  2. VLM generates a symbolic plan (sequence of parameterized actions)
  3. Motion planner translates each action into a robot trajectory
  4. After executing N actions (control horizon), or on execution failure, the system replans with warm-starting
  5. Warm-starting prompt includes: previous plan, execution status per action, and current observation

- Design tradeoffs:
  - Shorter control horizon → more replanning opportunities but more VLM queries and potential error accumulation
  - Warm-starting → improves geometric reasoning and reduces negative corrections but may bias toward suboptimal prior plans
  - Zero-shot vs. fine-tuned VLMs → paper uses zero-shot; fine-tuning on planning tasks may change the relative importance of warm-starting

- Failure signatures:
  - Geometric failures: objects placed outside target regions or colliding with each other (check Goal Achieved Rate)
  - Logical failures: constraint violations in object ordering or placement (check Correct Final Logical Plan Rate)
  - Warm-starting collapse: non-warm-starting variants show dramatic performance drops (e.g., Gemini in CUBE-EASY, Llama in YCB-MEDIUM in Table 2 and Table 3)

- First 3 experiments:
  1. Reproduce the open-loop vs. closed-loop comparison on CUBE-EASY with GPT-4.1-mini, measuring both Task Completion Rate and Goal Achieved Rate to distinguish geometric vs. logical failures.
  2. Ablate warm-starting on CL-SHORT planner across all four environments: compare full warm-starting (plan + execution status), partial warm-starting (plan only), and no warm-starting.
  3. Test a hybrid control horizon: replan after 1 step for the first half of the task, then switch to full-horizon to see if early frequent replanning combined with later stability improves performance over uniform horizons.

## Open Questions the Paper Calls Out
- **Open Question 1**: Does VLM fine-tuning for embodied planning improve symbolic planner performance over zero-shot usage? The paper recognizes that training procedures could have profound impacts on VLM planner performance but only tested off-the-shelf VLMs without domain-specific training.
- **Open Question 2**: How do control horizon and warm-starting effects generalize to dynamic environments with object motion or insertion? The study deliberately excluded dynamic environments to avoid obscuring the investigation of static environment behavior.
- **Open Question 3**: Can systematic prompt engineering improve logical constraint satisfaction, which showed no significant gains from closed-loop planning? The authors did not perform extensive prompt engineering and acknowledge that language steerability could significantly impact VLM planner performance.

## Limitations
- Results are based on controlled experiments with static environments, which may overstate the benefits of closed-loop planning in real-world scenarios
- Only short-horizon tasks (5-10 steps) were tested, so applicability to long-horizon problems remains uncertain
- The study uses zero-shot VLMs without domain-specific fine-tuning, which may not represent the performance of specialized planning models

## Confidence
- High confidence: Closed-loop planning outperforms open-loop planning due to VLM inference errors, and warm-starting consistently improves performance across scenarios
- Medium confidence: Control horizon choice has minimal impact when warm-starting is used, as this conclusion relies on statistical significance tests that show mixed results
- Medium confidence: Geometric and logical reasoning improvements from warm-starting, as the distinction between these failure modes depends on accurate measurement of the Goal Achieved Rate and Correct Final Logical Plan Rate metrics

## Next Checks
1. Test planner variants in dynamic environments where objects move independently of the robot's actions to validate the closed-loop advantage beyond static VLM errors
2. Implement a fine-tuned VLM variant specifically trained on planning tasks and compare its performance with zero-shot VLMs to assess whether warm-starting remains equally important
3. Conduct ablation studies on the warm-starting prompt components (previous plan vs. execution status) to quantify their individual contributions to performance improvements