---
ver: rpa2
title: 'Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language
  Models'
arxiv_id: '2503.17142'
source_url: https://arxiv.org/abs/2503.17142
tags:
- compositional
- embeddings
- image
- visual
- decomposable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether visual embeddings from vision-language
  models (VLMs) exhibit compositional structures analogous to those observed in text
  embeddings. The authors propose Geodesically Decomposable Embeddings (GDE), a framework
  that approximates image representations using geometry-aware compositional structures
  in the latent space, addressing challenges of noise and sparsity in visual data.
---

# Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models

## Quick Facts
- arXiv ID: 2503.17142
- Source URL: https://arxiv.org/abs/2503.17142
- Reference count: 40
- Primary result: Introduces Geodesically Decomposable Embeddings (GDE) that achieves state-of-the-art performance in compositional classification and group robustness tasks using minimal labeled data

## Executive Summary
This paper investigates whether visual embeddings from vision-language models (VLMs) exhibit compositional structures analogous to those observed in text embeddings. The authors propose Geodesically Decomposable Embeddings (GDE), a framework that approximates image representations using geometry-aware compositional structures in the latent space, addressing challenges of noise and sparsity in visual data. GDE leverages Riemannian geometry to decompose visual concepts into primitive directions representing individual attributes and objects, then recomposes them via geodesic operations. Experimental results show GDE achieves stronger performance than linear decomposition baselines, particularly on compositional classification and group robustness tasks, while also enabling generation of novel compositional images using diffusion models.

## Method Summary
The method extracts image embeddings from a frozen CLIP model, computes an intrinsic mean on the hypersphere via gradient descent, maps embeddings to a tangent space using logarithmic maps, calculates primitive direction vectors through weighted averaging in tangent space, and recomposes new vectors by summing primitives and mapping back via exponential maps. The framework is training-free and handles noise through CLIP-based relevance weighting of image embeddings.

## Key Results
- GDE achieves stronger performance than linear decomposition baselines in compositional classification, particularly on UT-Zappos dataset where it improves over zero-shot CLIP by a large margin (AUC ratio 317.9%)
- GDE demonstrates state-of-the-art performance in group robustness tasks, achieving higher worst-group accuracy than task-specific methods while using minimal labeled data
- The framework enables generation of novel compositional images using diffusion models, validating that decomposed embeddings encode semantically meaningful information about composite concepts

## Why This Works (Mechanism)

### Mechanism 1: Geodesic Decomposition in Tangent Space
The paper proposes that visual embeddings of compositional concepts lie on a Riemannian manifold (a hypersphere) rather than a linear Euclidean space, and can be decomposed by projecting them into a tangent space where primitives combine additively. The method maps normalized image embeddings to a tangent plane at the intrinsic mean μ using a logarithmic map, approximates complex concepts as the sum of primitive direction vectors in this linearized space, and maps back to the manifold via an exponential map. This approach avoids the geometric distortion that occurs when assuming linearity in curved embedding spaces.

### Mechanism 2: Noise Filtering via Image-to-Text Relevance Weighting
The paper suggests that noise in visual data can be mitigated by weighting the contribution of specific image embeddings based on their semantic alignment with the target concept. Instead of treating all images of a concept equally, the method uses a noise distribution derived from CLIP image-to-text probabilities, giving higher weight to embeddings that score higher against the text prompt for their class. This effectively filters out "noisy" outlier images by leveraging the pre-trained CLIP model's similarity score as a proxy for signal-to-noise ratio.

### Mechanism 3: Sparsity Robustness via Shared Primitive Directions
The framework handles missing compositional combinations by learning primitive directions independently, allowing synthesis of embeddings for unseen pairs. The optimization solves for primitive vectors by averaging across all available samples containing that primitive, enabling the vector for "red" in "red car" to be derived from other contexts like "red apple" and combined with "dog" from "brown dog" to synthesize "red dog" even if this exact combination was absent from training data.

## Foundational Learning

- **Concept:** Riemannian Manifolds & Hyperspheres
  - **Why needed here:** Standard vector arithmetic assumes a flat (Euclidean) space. CLIP embeddings are normalized, forcing them onto the surface of a sphere. Understanding that the "shortest path" is a curve (geodesic) and operations must happen in the "tangent plane" is central to this paper's contribution over linear methods.
  - **Quick check question:** Why can't we just add the vector for "red" and "car" directly in the embedding space according to this paper? (Answer: Because the space is curved; addition must happen in the tangent space and be projected back).

- **Concept:** Intrinsic Mean vs. Arithmetic Mean
  - **Why needed here:** To define the origin of the tangent space, one must find the "center" of the data on the manifold. A simple average minimizes Euclidean distance, whereas the intrinsic mean minimizes geodesic distance, which is required for the geometric decomposition to be valid.
  - **Quick check question:** How is the "context" or center of the decomposition (μ) calculated differently here than in a standard average? (Answer: It minimizes squared geodesic distance on the manifold, often via gradient descent).

- **Concept:** Compositional Zero-Shot Learning (CZSL)
  - **Why needed here:** The primary evaluation task. It frames the problem as recognizing unseen combinations of seen primitives (attributes + objects). Without this concept, the utility of the decomposition mechanism is unclear.
  - **Quick check question:** In the UT-Zappos dataset, if the model sees "rubber boots" and "leather shoes" during training, what capability is being tested during inference? (Answer: Recognizing "leather boots" or "rubber shoes" as unseen compositions).

## Architecture Onboarding

- **Component map:** Input images -> CLIP Encoder -> Intrinsic Mean computation -> Log map to tangent space -> Primitive direction calculation -> Sum primitives -> Exp map back to manifold -> Composed embedding
- **Critical path:** The Intrinsic Mean calculation. If this converges poorly or is inaccurate, the tangent space projection (Log map) will distort distances, and the primitive directions will be misaligned.
- **Design tradeoffs:**
  - Geodesic (GDE) vs. Linear (LDE): GDE is computationally heavier (requires iterative solving for mean and log/exp maps) but captures the spherical geometry of normalized embeddings. LDE is faster but performs significantly worse on visual data.
  - Uniform vs. Weighted Noise: Uniform weighting is simpler but treats background noise as signal. CLIP-score weighting requires a temperature hyperparameter sweep but improves robustness.
- **Failure signatures:**
  - Geometry Mismatch: If "Linear Decomposable Embeddings" (LDE) performs comparably to GDE, the embeddings may not be strictly spherical, or the cone effect is negligible.
  - Mean Collapse: If the intrinsic mean algorithm fails to converge (e.g., points are dispersed > π/2 radians apart), the tangent projection becomes undefined/unstable.
  - Spurious Correlations: In generated images, if "inflated" + "boat" results in a "round object" rather than a boat shape, the primitive vectors have captured dataset bias rather than the semantic attribute.
- **First 3 experiments:**
  1. Visualizing Structure (Sanity Check): Replicate Figure 3. Plot PCA projections of the tangent vectors for a small 2 × 2 set (e.g., Waterbirds). Verify that as you increase images/sample (k), the points form a parallelogram. This confirms the "geodesic decomposability" hypothesis.
  2. Comparison to Linear Baseline: Run Compositional Classification on UT-Zappos. Compare GDE vs. LDE. A significant gap (e.g., +20% AUC) validates the necessity of the Riemannian formulation.
  3. Debiasing Stress Test: Run group robustness on Waterbirds/CelebA. Compare against "CLIP Zero-Shot". Success is indicated by a high "Worst Group" (WG) accuracy, proving the decomposition successfully isolated the object class from the spurious background attribute.

## Open Questions the Paper Calls Out

### Open Question 1
Can the computational efficiency of GDE be improved by approximating the intrinsic mean using a subset of input embeddings without significant performance degradation? The paper notes that GDE is significantly slower than linear methods due to the cost of computing the intrinsic mean and suggests that approximating μ with a smaller subset could drastically improve efficiency, but this trade-off remains untested.

### Open Question 2
Can GDE-generated embeddings effectively serve as synthetic data to train or augment downstream models for compositional zero-shot learning? While the paper demonstrates that the embeddings can be decoded into high-quality images via Stable Diffusion, it does not validate whether these synthetic representations actually improve the learning dynamics of other models.

### Open Question 3
How robust is the geodesic decomposition to high levels of noise or ambiguity where the "closeness assumption" (points within a geodesic ball of radius π/2) is violated? The paper assumes points lie within a ball of radius π/2 to guarantee a unique intrinsic mean, but real-world datasets might contain outliers or ambiguous concepts that violate this geometric constraint, potentially destabilizing the decomposition.

## Limitations

- The framework's performance depends heavily on the quality of text prompts provided, and poorly designed prompts could lead to spurious primitive directions that fail to capture true compositional semantics
- The assumption that CLIP similarity scores reliably indicate signal-to-noise ratios in visual data may break down for abstract or culturally-specific attributes
- While qualitative image generation results support the framework's ability to produce images, they don't fully establish whether the resulting compositions capture intended semantic relationships or merely reproduce surface-level correlations

## Confidence

**High Confidence:** The framework's superior performance over linear decomposition baselines (LDE) in compositional classification tasks is well-supported by ablation studies and direct comparisons. The mathematical formulation of geodesic operations on hyperspheres is sound and internally consistent.

**Medium Confidence:** The claims about state-of-the-art debiasing performance and worst-group accuracy improvements are supported by experimental results but depend on dataset-specific prompt engineering. The assumption that CLIP similarity scores reliably indicate signal-to-noise ratios in visual data is plausible but not extensively validated across diverse visual domains.

**Low Confidence:** The interpretation that decomposed embeddings encode semantically meaningful information about composite concepts, while supported by qualitative image generation results, lacks rigorous quantitative validation. The claim that primitives are truly context-independent across different visual compositions remains largely unverified.

## Next Checks

1. **Geometric Sensitivity Analysis:** Systematically vary the intrinsic mean convergence tolerance and temperature parameters for noise distribution across all datasets. Plot performance degradation curves to identify which parameters are most critical and whether the method shows brittle behavior under hyperparameter perturbations.

2. **Cross-Modal Primitive Consistency:** Extract primitive directions from CLIP visual embeddings and from CLIP text embeddings of the same compositional concepts. Compute correlation coefficients between corresponding primitive vectors across modalities to validate whether the geometric decomposition captures consistent semantic primitives regardless of input modality.

3. **Adversarial Prompt Testing:** Design deliberately misleading text prompts that are semantically related but visually irrelevant to the target concepts. Run the GDE framework with these prompts and measure performance degradation. This would test the robustness of the noise filtering mechanism and whether it can distinguish between genuine compositional semantics and spurious correlations induced by prompt engineering.