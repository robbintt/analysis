---
ver: rpa2
title: Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis
arxiv_id: '2512.04967'
source_url: https://arxiv.org/abs/2512.04967
tags:
- retinal
- classes
- disease
- learning
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of retinal disease diagnosis
  under data scarcity and class imbalance, particularly in multi-disease datasets
  like RFMiD. To tackle this, the authors propose a balanced few-shot episodic learning
  framework combining balanced episodic sampling, targeted augmentation (including
  CLAHE), and a ResNet-50 encoder.
---

# Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis

## Quick Facts
- arXiv ID: 2512.04967
- Source URL: https://arxiv.org/abs/2512.04967
- Authors: Jasmaine Khale; Ravi Prakash Srivastava
- Reference count: 16
- Primary result: 90.0% accuracy and 89.3% macro F1-score in best-performing episodes on RFMiD top 10 disease classes

## Executive Summary
This study addresses retinal disease diagnosis under data scarcity and class imbalance, particularly in multi-disease datasets like RFMiD. The authors propose a balanced few-shot episodic learning framework combining balanced episodic sampling, targeted augmentation (including CLAHE), and a ResNet-50 encoder. The framework achieves 90.0% accuracy and 89.3% macro F1-score in best-performing episodes, with average performance around 44.0% accuracy and 38.46% macro F1-score. The approach demonstrates improved robustness and fairness across both majority and minority disease categories, reducing bias and enhancing diagnostic reliability in data-constrained clinical settings.

## Method Summary
The framework uses Prototypical Networks with a ResNet-50 encoder pretrained on ImageNet. Training follows a 5-way 5-shot episodic paradigm with balanced class sampling to ensure equal participation of all classes. Images are preprocessed with CLAHE and augmented with color jittering, rotation, and horizontal flipping. The model is trained for 50 epochs with 1,000 episodes per epoch, using cosine similarity for distance measurement and Adam optimizer with learning rate 1e-3. Evaluation uses 1,000 test episodes on the top 10 disease classes from RFMiD.

## Key Results
- Best episode performance: 90.0% accuracy and 89.3% macro F1-score
- Average episode performance: 44.0% accuracy and 38.46% macro F1-score
- AUC range: 0.63-0.66 across test episodes
- Balanced sampling reduces majority-class bias and improves minority-class detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Balanced episodic sampling reduces majority-class bias in few-shot learning for imbalanced medical datasets.
- Mechanism: By uniformly sampling classes at episode construction time, rare diseases (e.g., ODE, BRVO) appear with equal frequency as common diseases (e.g., DR, MH), forcing the encoder to learn discriminative features for all classes rather than overfitting to high-frequency categories.
- Core assumption: The bottleneck in minority-class performance is underrepresentation during training, not inherent feature difficulty.
- Evidence anchors:
  - [abstract] "balanced episodic sampling, ensuring equal participation of all classes in each 5-way 5-shot episode"
  - [Section 4.4.2] "classes are sampled uniformly, ensuring that rare classes (e.g., ODE, ODP, BRVO) appear with the same frequency as common classes (e.g., DR, MH)"
  - [corpus] Related work on class imbalance in DR grading (arXiv:2507.17121) supports augmentation+transfer learning for imbalance but does not evaluate episodic sampling directly.
- Break condition: If class prototypes are inherently noisier for rare diseases due to intra-class variability rather than sample count, balanced sampling alone cannot close the performance gap.

### Mechanism 2
- Claim: CLAHE-based preprocessing improves prototype quality for subtle retinal disease features.
- Mechanism: Contrast Limited Adaptive Histogram Equalization enhances local contrast, making fine-grained lesions (microaneurysms, hemorrhages, vessel abnormalities) more visible in the embedding space, which yields more representative prototypes—especially for minority classes where augmentation enriches diversity.
- Core assumption: Subtle pathological features are the primary discriminative signal, and contrast enhancement preserves rather than distorts them.
- Evidence anchors:
  - [abstract] "targeted augmentation, including Contrast Limited Adaptive Histogram Equalization (CLAHE) and color/geometry transformations, to improve minority-class diversity"
  - [Section 4.2.4] "CLAHE proved particularly beneficial for classes where subtle lesions or vessel abnormalities are primary discriminative features"
  - [corpus] CLAHE-CapsNet study (PLOS ONE 2023) reports similar contrast-enhancement benefits for OCT classification, supporting transferability of this preprocessing choice.
- Break condition: If CLAHE introduces artifacts or over-enhances noise in low-quality fundus images, prototype quality may degrade rather than improve.

### Mechanism 3
- Claim: Cosine similarity as a distance metric stabilizes few-shot classification under embedding magnitude variability.
- Mechanism: Medical images exhibit varying intensity scales due to acquisition conditions; cosine similarity normalizes magnitude, making class comparisons more robust than Euclidean distance.
- Core assumption: Embedding direction encodes disease-relevant information while magnitude encodes acquisition artifacts or noise.
- Evidence anchors:
  - [Section 4.2.3] "Cosine similarity was chosen over Euclidean distance because it is less sensitive to variations in embedding magnitude, which are common in medical image data"
  - [Section 4.2.3] "This choice consistently yielded higher accuracy in our experiments, especially with the ResNet-50 backbone"
  - [corpus] No direct corpus comparison of cosine vs. Euclidean in retinal FSL; this remains an architecture-specific claim.
- Break condition: If magnitude itself carries diagnostic signal (e.g., lesion brightness correlates with severity), normalizing it away could hurt performance.

## Foundational Learning

- Concept: **N-way K-shot episode structure**
  - Why needed here: The entire training/evaluation paradigm is episodic; without understanding support/query splits, you cannot debug episode construction or interpret results.
  - Quick check question: Can you explain why a 5-way 5-shot episode contains 25 support images and 10 query images?

- Concept: **Prototypical Networks**
  - Why needed here: Classification is performed by comparing query embeddings to class prototypes (mean support embeddings); understanding this is essential for modifying the distance metric or regularization.
  - Quick check question: How would prototype quality change if one support sample were mislabeled?

- Concept: **Long-tail class imbalance**
  - Why needed here: RFMiD has 46 classes with extreme skew; recognizing how imbalance distorts standard training motivates balanced sampling and augmentation strategies.
  - Quick check question: Why would accuracy be misleading as a sole metric on a dataset where DR has 300+ images and ODE has ~58?

## Architecture Onboarding

- Component map: Input (224×224 fundus images) -> CLAHE preprocessing -> Encoder (ResNet-50) -> Prototype computation (mean of K support embeddings) -> Cosine similarity classifier -> Output (predicted class)

- Critical path: 1. Balanced class sampling -> 2. Augmented support/query construction -> 3. Encoder forward pass -> 4. Prototype computation -> 5. Cosine similarity ranking -> 6. Loss/backprop through encoder

- Design tradeoffs:
  - **ResNet-34 vs. ResNet-50**: ResNet-50 provides finer-grained features but higher compute; paper reports 44% → 90% accuracy gain in best episodes.
  - **5-way vs. higher-way**: 5-way balances difficulty and feasibility; higher-way increases task hardness but may improve generalization.
  - **Episode count (100 train vs. 1000 test)**: Low training episode count may underconstrain the encoder; test episodes show high variance (44% avg, 90% best).

- Failure signatures:
  - High variance between episodes (90% best vs. 44% average) -> underfitting or insufficient training episodes.
  - Minority-class confusion with visually similar diseases (e.g., ODC confused with DR/TSLN) -> prototype overlap in embedding space.
  - AUC plateau at 0.63–0.66 -> embedding discriminability ceiling reached.

- First 3 experiments:
  1. **Ablate balanced sampling**: Run with random (unbalanced) episode sampling; expect majority-class accuracy to rise, minority-class F1 to drop.
  2. **Ablate CLAHE**: Train without CLAHE preprocessing; compare per-class precision/recall, especially for subtle-lesion diseases (DR, RNV).
  3. **Increase training episodes**: Train with 500–1000 episodes instead of 100; evaluate whether average accuracy converges closer to best-episode performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the balanced episodic framework maintain robustness when extended to the full RFMiD dataset containing all 46 disease classes?
- Basis in paper: [inferred] Section 4.3 explicitly restricts the study to the top 10 classes "to avoid the extreme sparsity of rare categories," leaving the model's efficacy on the complete long-tail distribution untested.
- Why unresolved: It is unclear if the prototype construction remains stable for the 36 excluded categories with minimal samples.
- What evidence would resolve it: Benchmarking the 5-way 5-shot accuracy on the full 46-class dataset, specifically analyzing per-class sensitivity for the bottom-tier diseases.

### Open Question 2
- Question: What specific regularization or architectural modifications are required to reduce the large performance gap between best-case (90%) and average (44%) accuracy?
- Basis in paper: [inferred] Section 5.1 highlights substantial "fluctuations depending on the sampled classes," and Section 5.3 notes that "additional refinements... are required" to achieve reliable clinical stability.
- Why unresolved: The current Prototypical Network implementation exhibits high variance, suggesting the learned embeddings lack sufficient robustness across different episode compositions.
- What evidence would resolve it: A study analyzing the standard deviation of episode accuracies with and without embedding variance regularization techniques.

### Open Question 3
- Question: How does the single-label classification constraint impact diagnostic performance on the multi-label cases prevalent in the RFMiD dataset?
- Basis in paper: [inferred] Section 2.3 states that labels are "multi-label in nature," yet the problem definition in Section 4.1 formulates the prediction as a single-class arg max.
- Why unresolved: Forcing a single prediction may penalize the model for correctly detecting co-occurring pathologies (e.g., Diabetic Retinopathy with Macular Hole).
- What evidence would resolve it: Evaluation using multi-label metrics such as mean Average Precision (mAP) rather than single-label accuracy.

## Limitations

- Limited generalizability beyond RFMiD: Performance gains are demonstrated only on RFMiD's top 10 classes; results may not transfer to other retinal datasets with different class distributions or image characteristics.
- Unclear impact of CLAHE parameters: The paper does not specify CLAHE hyperparameters (clip limit, tile grid size), leaving ambiguity about whether reported improvements are tied to specific settings.
- High episode-to-episode variance: The 90% best vs. 44% average accuracy gap suggests potential instability; it's unclear whether this reflects task difficulty or insufficient training episodes.

## Confidence

- **High confidence**: Balanced episodic sampling improves fairness across classes; CLAHE preprocessing benefits subtle-lesion diseases; cosine similarity stabilizes few-shot classification under embedding magnitude variability.
- **Medium confidence**: The 90% best-episode accuracy is achievable and not an outlier; the framework generalizes to multi-disease retinal diagnosis; minority-class performance gains are robust across disease categories.
- **Low confidence**: Claims about outperforming human experts; exact causes of high episode variance; long-term clinical reliability in real-world settings.

## Next Checks

1. **Ablate balanced sampling**: Run experiments with random (unbalanced) episode sampling to quantify the contribution of balanced sampling to minority-class performance.
2. **Sweep CLAHE parameters**: Systematically vary CLAHE clip limit and tile grid size to identify optimal settings and assess robustness to parameter choice.
3. **Increase training episodes**: Train with 500-1000 episodes instead of 100 to determine if average accuracy converges closer to best-episode performance and reduce variance.