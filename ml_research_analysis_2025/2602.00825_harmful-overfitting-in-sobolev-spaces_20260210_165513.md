---
ver: rpa2
title: Harmful Overfitting in Sobolev Spaces
arxiv_id: '2602.00825'
source_url: https://arxiv.org/abs/2602.00825
tags:
- overfitting
- sobolev
- lemma
- then
- spaces
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the generalization behavior of Sobolev-space\
  \ interpolators in the presence of label noise. It shows that approximately norm-minimizing\
  \ interpolators in W^{k,p}(R^d) with kd/p suffer from harmful overfitting: even\
  \ as the training sample size n\u2192\u221E, the generalization error remains bounded\
  \ below by a positive constant with high probability."
---

# Harmful Overfitting in Sobolev Spaces

## Quick Facts
- **arXiv ID**: 2602.00825
- **Source URL**: https://arxiv.org/abs/2602.00825
- **Reference count**: 40
- **Primary result**: Approximately norm-minimizing interpolators in Sobolev spaces W^{k,p}(R^d) with k>d/p suffer harmful overfitting: generalization error remains bounded below by a positive constant even as n→∞.

## Executive Summary
This paper proves that approximately norm-minimizing interpolators in Sobolev spaces W^{k,p}(R^d) exhibit harmful overfitting when k>d/p, meaning the generalization error remains bounded away from zero even as training sample size grows. The result extends prior work limited to Hilbert spaces (p=2) to all p∈[1,∞), and applies to a broad class of data distributions with label noise. The key insight is that smoothness bias alone does not guarantee benign overfitting in Sobolev spaces - norm minimization can lead to persistent excess risk.

## Method Summary
The paper analyzes approximately norm-minimizing (γ-ANM) interpolators that minimize the Sobolev W^{k,p} norm subject to interpolating training data. The analysis constructs bump functions to bound the minimum-norm solution, identifies subsets of noisy training points with sufficient nearest-neighbor separation, and uses Sobolev inequalities to show that smooth interpolators cannot correct predictions in neighborhoods around these points without violating norm constraints. This leads to accumulated excess risk that remains constant as n→∞.

## Key Results
- Approximately norm-minimizing interpolators in W^{k,p}(R^d) with k>d/p exhibit harmful overfitting: generalization error remains bounded below by Cγ^{-pd/(kp-d)} with high probability.
- The result holds for all p∈[1,∞), extending prior work limited to Hilbert spaces (p=2).
- The analysis applies to a broad class of data distributions with label noise satisfying bounded density and conditional distribution regularity.
- The harmful overfitting stems from a geometric obstruction: around separated noisy training points, smooth interpolators must incur regret in neighborhoods whose total probability mass is independent of n.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Approximately norm-minimizing (γ-ANM) interpolators in Sobolev spaces $W^{k,p}(\mathbb{R}^d)$ with $k > d/p$ exhibit harmful overfitting: generalization error remains bounded below by a positive constant even as $n \to \infty$.
- Mechanism: The norm-minimization inductive bias forces the interpolator to be smooth, but around noisy training points with sufficient nearest-neighbor separation, the interpolator cannot simultaneously maintain small norm and correct predictions in surrounding neighborhoods. This leads to accumulated excess risk around a non-negligible fraction of training points.
- Core assumption: Label noise (Assumption 3.5): with probability at least $\rho$, a training label $y_i$ incurs conditional loss at least $\sigma$ above the Bayes-optimal. Also requires regularity of marginal distribution (Assumption 3.3) and conditional distribution (Assumption 3.2).
- Evidence anchors:
  - [abstract] "approximately norm-minimizing interpolators... exhibit harmful overfitting: even as the training sample size $n \to \infty$, the generalization error remains bounded below by a positive constant with high probability."
  - [section 3.2, Theorem 3.7] "For all $\gamma$-ANM solutions $f_\gamma$: $\mathbb{E}[\ell(f_\gamma(x), y) - \ell(f_{\text{Bayes}}(x), y)|X,y] \geq C\gamma^{-pd/(kp-d)}$"
  - [corpus] Related work on benign/harmful overfitting in kernels and neural networks, but no direct corpus evidence for the Sobolev-space-specific geometric mechanism.
- Break condition: If the function space does not satisfy Sobolev-type inequalities, or if the data distribution violates density boundedness (Assumption 3.3), or if label noise is absent/structured differently.

### Mechanism 2
- Claim: The harmful overfitting stems from a geometric obstruction: around sufficiently separated noisy training points, any smooth interpolator must incur regret in a neighborhood whose total probability mass is independent of $n$.
- Mechanism: The proof constructs "harmful neighborhoods" using Sobolev inequalities (Corollary 4.5) to bound the oscillation of smooth functions. Around each noisy point with large nearest-neighbor radius $\delta_i$, the interpolator cannot deviate much from the noisy label within a ball of radius $\propto \gamma^{-p/(kp-d)} n^{-1/d}$, leading to persistent regret.
- Core assumption: The data distribution has bounded density (Assumption 3.3: $c_D \leq p_x(x_0) \leq C_D$), ensuring neighborhoods of fixed Euclidean volume also have fixed probability mass.
- Evidence anchors:
  - [section 4, proof overview] "Show that around these points, any $\gamma$-ANM solution must be smooth enough not to violate the minimum-norm bound, and thus accumulates generalization error around these points."
  - [appendix C.4, Corollary 4.5] $|u(x_1) - u(x_0)|^p \lesssim_{k,d,p} \delta^{kp-d} \|u\|_{W^{k,p}(B(x_0,2\delta))}^p$.
  - [corpus] Related work on interpolation in kernel/Sobolev spaces, but the geometric-neighborhood construction via Sobolev inequalities is not directly evidenced in corpus.
- Break condition: If the Sobolev embedding fails ($k \leq d/p$), or if the domain $\Omega$ is not a $W^{1,p}$-extension domain, or if nearest-neighbor radii $\delta_i$ scale differently with $n$.

### Mechanism 3
- Claim: The result extends beyond Hilbert spaces ($p=2$) to all $p \in [1,\infty)$, and beyond exact norm-minimizers to all $\gamma$-ANM interpolators, broadening the class of solutions subject to harmful overfitting.
- Mechanism: By working with $\gamma$-ANM solutions (whose norm is within factor $\gamma$ of minimum), the analysis applies to any interpolator selected by a smoothness bias, not just the exact minimum-norm solution. The proof does not rely on kernel methods or linearity, enabling extension to non-Hilbert $W^{k,p}$ spaces.
- Core assumption: The interpolator satisfies the $\gamma$-ANM condition: $\|f\|_{W^{k,p}} \leq \gamma \|f^*\|_{W^{k,p}}$, and $k \in (d/p, 1.5d/p)$ (smooth enough for embedding but not too smooth relative to dimension).
- Evidence anchors:
  - [abstract] "Our results hold for arbitrary values of $p \in [1,\infty)$, in contrast to prior results studying the Hilbert space case ($p=2$) using kernel methods."
  - [section 1, contributions] "We consider approximately norm-minimizing (ANM) interpolators rather than just norm-minimizing interpolators."
  - [corpus] Prior work (Rakhlin & Zhai 2019, Buchholz 2022) on kernel regression in Sobolev spaces is limited to $p=2$ or restricted parameter ranges; this paper generalizes.
- Break condition: If $p \to \infty$ or $p$ is outside $[1,\infty)$, or if $k$ is outside $(d/p, 1.5d/p)$, or if the interpolator is not $\gamma$-ANM (e.g., if explicit regularization beyond norm is used).

## Foundational Learning

- **Sobolev spaces and norms**: Why needed here - The entire analysis is framed in Sobolev spaces $W^{k,p}(\mathbb{R}^d)$, which quantify smoothness via norms of derivatives. Understanding these spaces is essential to grasp what "norm-minimizing interpolation" means and why $k > d/p$ is critical for pointwise evaluation. Quick check question: For a function $f \in W^{k,p}(\mathbb{R}^d)$, what does the norm $\|f\|_{W^{k,p}}$ include, and why does $k > d/p$ matter for interpolation?

- **Benign vs. harmful overfitting**: Why needed here - The paper's main claim is a negative result: harmful overfitting occurs in Sobolev-space interpolation. Understanding this taxonomy frames the significance of the contribution. Quick check question: In the taxonomy of Mallinar et al. (2022), how does "harmful overfitting" differ from "benign" and "tempered" overfitting, and what does the paper show for Sobolev interpolators?

- **Norm-minimizing interpolation**: Why needed here - The studied solutions minimize (or approximately minimize) the Sobolev norm subject to interpolating the data. This is the inductive bias whose generalization behavior is analyzed. Quick check question: Why is minimum-norm interpolation in $W^{k,p}$ nonlinear for $p \neq 2$, and how does the $\gamma$-ANM definition generalize beyond exact minimizers?

## Architecture Onboarding

- **Component map**: Sobolev space $W^{k,p}(\mathbb{R}^d)$ with $k > d/p$ -> Data model: bounded open $\Omega \subset \mathbb{R}^d$ with bounded density and label noise -> Loss function $\ell$ -> Interpolator: $\gamma$-ANM solution -> Bayes-optimal function $f_{\text{Bayes}} \in W^{k,p}(\mathbb{R}^d)$

- **Critical path**:
  1. Bound minimum-norm solution norm using bump functions and concentration (Corollary 4.3).
  2. Identify a large subset $B$ of training points that are noisy, have sufficiently large nearest-neighbor radii, and bounded labels (Lemma 4.4).
  3. For each point in $B$, use Sobolev inequalities to show the interpolator cannot deviate much from the noisy label in a neighborhood, incurring regret.
  4. Aggregate regret over all points in $B$; the total probability mass of harmful neighborhoods is $\gtrsim \gamma^{-pd/(kp-d)}$, independent of $n$.

- **Design tradeoffs**:
  - Choice of $p$: $p=2$ (Hilbert space) is tractable via kernel methods, but $p \neq 2$ requires nonlinear analysis; the result holds for all $p$.
  - Smoothness $k$: Must satisfy $k > d/p$ for embedding, but the lower bound improves as $k$ increases; the analysis restricts $k < 1.5d/p$.
  - Data distribution: Bounded density (Assumption 3.3) is geometrically convenient but may limit applicability to heavy-tailed data.

- **Failure signatures**:
  - Generalization error plateaus at a positive constant as $n$ increases, even with smooth interpolants and smooth Bayes-optimal function.
  - No consistency: interpolators do not converge to Bayes-optimal predictor in $L^2(\mu)$ or expected loss.

- **First 3 experiments**:
  1. **Vary $p$**: Implement $\gamma$-ANM interpolation in $W^{k,p}$ for $p=1,2,3$ on synthetic data with label noise; verify lower bound on generalization error scales as $\gamma^{-pd/(kp-d)}$.
  2. **Vary noise level $\sigma$**: Test if the constant $C$ in the lower bound depends on noise level (Assumption 3.5); expect larger $\sigma$ leads to larger lower bound.
  3. **Vary dimension $d$ and smoothness $k$**: Check if the exponent $-pd/(kp-d)$ changes as predicted; for fixed $k/p$, higher $d$ may worsen overfitting, while higher $k$ (relative to $d/p$) may mitigate it.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does harmful overfitting persist in Sobolev spaces when using classification-type loss functions (e.g., logistic or hinge loss) rather than regression losses?
- Basis in paper: [explicit] The conclusion states that the paper considers regression-type losses where $\ell(\hat{y}, y)=0$ iff $\hat{y}=y$, and suggests "future work could investigate classification-type loss functions."
- Why unresolved: The current proofs rely on the specific structure of regression losses to define conditional loss and regret around data points, which may not translate directly to the discrete nature of classification targets.
- What evidence would resolve it: A theoretical extension of Theorem 3.7 to classification losses, or a counter-example showing consistent interpolation is possible in Sobolev spaces for classification tasks.

### Open Question 2
- Question: What is the generalization behavior in the intermediate regime between fixed dimension and the very high-dimensional setting ($d \gg n$)?
- Basis in paper: [explicit] The conclusion notes that while the paper addresses fixed dimension and cites work on very high dimensions, "the intermediate regime... remains an open area of investigation."
- Why unresolved: The proof techniques rely on fixed-dimension geometric volume arguments that break down in high-dimensional settings, while high-dimensional analyses often require assumptions not met in fixed dimensions.
- What evidence would resolve it: A theoretical characterization of the generalization error as a function of the ratio $d/n$ that bridges the constant lower bound (fixed $d$) and benign overfitting (large $d$) regimes.

### Open Question 3
- Question: Can the harmful overfitting result be extended to other function spaces that satisfy similar local oscillation control inequalities?
- Basis in paper: [explicit] The conclusion suggests the arguments, which "depend on local control of the oscillation of functions," "could potentially be extended to other function spaces."
- Why unresolved: The proof relies heavily on specific Sobolev embedding theorems and inequalities (Morrey's inequality) which must be verified for other spaces (e.g., Besov spaces) to ensure the volume-averaging argument holds.
- What evidence would resolve it: A generalization of the main theorem to abstract function spaces satisfying specific local smoothness constraints, or a specific proof for an alternative space like Besov spaces.

### Open Question 4
- Question: Does harmful overfitting occur for all smoothness parameters $k > d/p$, or is the restriction $k < 1.5d/p$ in Theorem 3.7 necessary?
- Basis in paper: [inferred] The main theorem (Theorem 3.7) restricts the smoothness parameter to $k \in (d/p, 1.5d/p)$, whereas the definition of the Sobolev space allows for any $k > d/p$.
- Why unresolved: The constraint appears technical, likely related to the decay rates of bump function norms or the volume of intersection with the domain boundary in the proof. It is unclear if higher smoothness ($k \ge 1.5d/p$) enables benign overfitting or if this is merely a limitation of the current proof technique.
- What evidence would resolve it: A proof of Theorem 3.7 for $k \ge 1.5d/p$, or the construction of a specific norm-minimizing interpolator that generalizes well (benign overfitting) in the high-smoothness regime.

## Limitations

- The analysis relies heavily on Sobolev inequalities and bounded density assumptions, which may not hold for all realistic data distributions.
- The proof constructs harmful neighborhoods around noisy training points, but this geometric argument depends critically on the data having bounded density and the smoothness $k$ being in a specific range.
- The result is asymptotic and probabilistic, showing that with high probability a lower bound holds, but does not provide tight constants or explicit convergence rates for the generalization gap.

## Confidence

- **High confidence**: The mechanism that smooth interpolators cannot simultaneously fit noisy labels and maintain small Sobolev norm in neighborhoods of separated training points is mathematically sound and well-supported by the Sobolev inequality argument (Corollary 4.5).
- **Medium confidence**: The extension to all $p \in [1,\infty)$ beyond the Hilbert space case is valid in principle, but the nonlinear nature of $W^{k,p}$ for $p \neq 2$ makes the general construction less explicit and more technically involved.
- **Medium confidence**: The claim that approximately norm-minimizing interpolators (not just exact minimizers) exhibit harmful overfitting is reasonable given the $\gamma$-ANM framework, but the practical implications for how interpolators are selected in practice remain somewhat abstract.

## Next Checks

1. **Distribution sensitivity test**: Implement $\gamma$-ANM interpolation on synthetic data with varying density profiles (bounded vs. heavy-tailed) to verify whether the harmful overfitting lower bound persists when the bounded density assumption is violated.

2. **Smoothness parameter sweep**: For fixed dimension and noise level, vary $k$ across the range $(d/p, 1.5d/p)$ to empirically verify that the lower bound on generalization error improves as $k$ increases, as predicted by the $-pd/(kp-d)$ exponent.

3. **Alternative norm minimization**: Compare $\gamma$-ANM interpolation in $W^{k,p}$ to interpolators minimizing other smoothness-promoting norms (e.g., total variation) on the same noisy data to determine whether Sobolev-specific geometric properties are essential to the harmful overfitting phenomenon.