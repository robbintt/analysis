---
ver: rpa2
title: 'Taggus: An Automated Pipeline for the Extraction of Characters'' Social Networks
  from Portuguese Fiction Literature'
arxiv_id: '2508.03358'
source_url: https://arxiv.org/abs/2508.03358
tags:
- character
- characters
- taggus
- extraction
- pipeline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Taggus, an automated pipeline designed to
  extract social networks from Portuguese literary fiction. The pipeline combines
  part-of-speech tagging, heuristic-based filtering, and external data sources to
  identify characters and their interactions.
---

# Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature

## Quick Facts
- arXiv ID: 2508.03358
- Source URL: https://arxiv.org/abs/2508.03358
- Reference count: 25
- Primary result: Automated Portuguese character extraction pipeline achieving 94.1% F1-score

## Executive Summary
Taggus is an automated pipeline designed to extract social networks from Portuguese literary fiction by identifying characters, resolving co-references, and detecting interactions. The pipeline combines part-of-speech tagging with heuristic filtering and external data sources to outperform state-of-the-art tools like spaCy's NER model and ChatGPT on Portuguese text. Taggus achieves 94.1% F1-score for character extraction and 75.9% F1-score for interaction detection on a manually annotated corpus of 11 Portuguese novels.

## Method Summary
Taggus processes Portuguese novels through a multi-stage pipeline: initial POS tagging with LX-Tagger, heuristic-based filtering to remove non-person entities, co-reference resolution using token matching and diminutive lists, and interaction detection via 3-sentence co-occurrence windows. The system uses external databases for Portuguese names and locations, applies six sequential filters to clean extracted entities, and generates weighted character interaction networks. Performance was evaluated against spaCy NER and ChatGPT on manually annotated chapters from 19th-century Portuguese novels.

## Key Results
- Character extraction achieves 94.1% F1-score, outperforming spaCy NER by 50.7%
- Interaction detection achieves 75.9% F1-score, outperforming ChatGPT by 22.3%
- Pipeline reduces false positives significantly compared to standard NER approaches
- High precision maintained across multiple 19th-century Portuguese literary works

## Why This Works (Mechanism)

### Mechanism 1: Multi-Stage POS-Based Entity Extraction with Heuristic Filtering
Taggus outperforms standard NER for Portuguese character extraction by using POS tagging combined with language-specific heuristic filters rather than off-the-shelf neural NER alone. LX-Tagger identifies proper name sequences using title and name patterns. Six sequential heuristic filters remove non-person entities: title presence detection, verb-based presence indicators, spaCy re-tagging, geographic database filtering, lowercase token removal, and first-name database validation. This approach addresses systematic false positives from standard NER trained on non-literary domains.

### Mechanism 2: Co-occurrence Window for Interaction Detection
A 3-sentence co-occurrence window captures the majority of character interactions in Portuguese novels with acceptable false positive rates. When two character name references appear within a sliding window of 3 sentences, an interaction edge is created with weight incremented. This captures both direct dialogue and narrative descriptions of character proximity. The 3-sentence window was determined to balance capturing interactions while minimizing false positives.

### Mechanism 3: Name Variation Clustering via Token Matching and Diminutives
Hierarchical token matching combined with a diminutive/nickname database resolves most co-references for Portuguese character names. Names are sorted by token count (longest first), then iteratively matched so shorter variations are grouped with longer canonical forms. A manually-curated diminutive list merges related groups. First-person narrator handling adds pronoun resolution when specified. This rule-based approach captures Portuguese naming conventions without requiring deep semantic understanding.

## Foundational Learning

- **Concept: Named Entity Recognition (NER) vs. POS Tagging for Entity Extraction**
  - Why needed here: Taggus uses POS tagging rather than standard NER as its primary extraction method; understanding why NER fails for Portuguese literary text is essential.
  - Quick check question: Given a sentence "O Dr. Fernando saiu de Lisboa," what would spaCy's NER likely extract, and what would LX-Tagger's POS pattern matching extract?

- **Concept: Co-occurrence Networks and Window Size Selection**
  - Why needed here: The choice of 3-sentence window is a key design decision with direct impact on precision/recall tradeoffs for interaction detection.
  - Quick check question: If you increased the co-occurrence window from 3 to 10 sentences, would precision likely increase or decrease? What about recall?

- **Concept: Co-reference Resolution and Name Variation Grouping**
  - Why needed here: Characters appear under multiple name forms (full name, first name only, title+name, nicknames); grouping these is necessary before interaction counting.
  - Quick check question: In the name "Sr. João da Silva," which tokens would match against "João Silva" under Taggus's sorting and matching algorithm?

## Architecture Onboarding

- **Component map**: Input Layer -> POS Tagging (LX-Tagger) -> Pattern Matching (5 tag patterns) -> Heuristic Filters (6 stages) -> Co-reference Resolution (6 steps) -> Interaction Detection (3-sentence window) -> Output Layer (weighted character network graph)
- **Critical path**: POS Pattern Extraction -> Heuristic Filtering -> Co-reference Resolution -> Interaction Detection. Failures in early stages propagate; a missed character name cannot generate interactions.
- **Design tradeoffs**: Precision vs. Recall (discarding characters appearing <3 times removes false positives but sacrifices minor characters), Simplicity vs. Coverage (rule-based diminutive list is maintainable but incomplete), Static vs. Dynamic Networks (current implementation generates static book-level networks)
- **Failure signatures**: Low recall in chapters with many minor characters, Religious references misclassified as characters, Location names with person-name tokens cause false positives, ChatGPT comparison shows inconsistent precision/recall across chapters
- **First 3 experiments**:
  1. Ablation test on heuristic filters: Disable each of the 6 filters individually and measure precision/recall impact on the 11-chapter corpus
  2. Window size sensitivity analysis: Test co-occurrence windows of 1, 3, 5, 7, and 10 sentences on interaction detection F1-score
  3. Error analysis on false positives: Manually categorize remaining false positives in character extraction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can advanced anaphoric resolution techniques be integrated into Taggus to correctly attribute pronouns to character entities without introducing significant noise?
- Basis in paper: The authors state that "Anaphoric resolution for co-reference remains challenging, even for English models," and that "no satisfactory results have been achieved" in their testing.
- Why unresolved: The current pipeline largely excludes pronouns to minimize false positives, resulting in incomplete networks that miss interactions where characters are referred to by "he" or "she."
- What evidence would resolve it: Successful integration of a pronoun-resolution module that maintains the pipeline's high precision (>90%) while increasing recall in the manually annotated chapters.

### Open Question 2
- Question: Can semantic or verb-based interaction detection methods yield higher precision than the co-occurrence sliding window approach currently employed?
- Basis in paper: The authors acknowledge the "imprecise nature" of co-occurrence detection is known and assert that "future exploration in this matter is needed."
- Why unresolved: Taggus currently defines interactions simply as characters appearing within a 3-sentence window, which captures non-interactive co-presence (false positives) and lowers the F1-score to 75.9%.
- What evidence would resolve it: A comparative benchmark showing that detecting interactions via specific action verbs or dialogue structures reduces false positives and increases the interaction F1-score above the current 75.9% baseline.

### Open Question 3
- Question: To what extent does Taggus generalize to contemporary Portuguese literature given its reliance on historical naming conventions and lexicons?
- Basis in paper: The authors note the evaluation corpus is limited to 19th-century works and that "Taggus has yet to be tested with more modern and contemporary books."
- Why unresolved: The pipeline relies on heuristics and name databases derived from or suited to 19th-century literary styles (e.g., "Esteiros"), which may not align with modern naming trends or informal slang.
- What evidence would resolve it: Evaluation results from a corpus of 21st-century Portuguese novels showing that the current heuristic filters maintain similar performance metrics.

## Limitations
- Evaluation corpus consists of only 11 novels from a single literary collection, limiting external validity
- Rule-based approach lacks semantic understanding and cannot resolve complex co-references like pronouns or invented character names
- Diminutive list is manually curated and incomplete, potentially missing less common name variations
- Geographic filtering may incorrectly remove legitimate character names that coincide with location names

## Confidence
- Character extraction F1-score (94.1%): **High** - Well-validated against manual annotations with clear improvement over baseline
- Interaction detection F1-score (75.9%): **Medium** - Validated but window size selection lacks corpus-level justification
- Improvement over spaCy NER (50.7%): **High** - Clear quantitative difference with statistical significance
- Improvement over ChatGPT (22.3%): **Medium** - Single-shot comparison may not reflect optimal prompt engineering

## Next Checks
1. **Cross-corpus validation**: Test Taggus on Portuguese literary works from different time periods, genres, and authors to assess performance stability across diverse writing styles
2. **Window size sensitivity analysis**: Systematically vary the co-occurrence window (1, 3, 5, 7, 10 sentences) on the full annotated corpus to determine optimal tradeoff between precision and recall for interaction detection
3. **Error type distribution analysis**: Manually categorize all false positives and false negatives from the 11-chapter evaluation to identify systematic failure patterns and prioritize filter development