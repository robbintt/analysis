---
ver: rpa2
title: 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language
  Models'
arxiv_id: '2406.15781'
source_url: https://arxiv.org/abs/2406.15781
tags:
- process
- anomalies
- anomaly
- business
- trace
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DABL, a novel approach for detecting semantic
  anomalies in business processes using fine-tuned large language models. The method
  generates training data from 143,137 real-world process models, simulating ordering
  and exclusion anomalies.
---

# DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models

## Quick Facts
- **arXiv ID:** 2406.15781
- **Source URL:** https://arxiv.org/abs/2406.15781
- **Reference count:** 16
- **Primary result:** F1-score of 96.87% and accuracy of 97.03% on known processes; F1-score of 91.88% and accuracy of 92.39% on unseen processes

## Executive Summary
This paper introduces DABL, a novel approach for detecting semantic anomalies in business processes using fine-tuned large language models. The method generates training data from 143,137 real-world process models, simulating ordering and exclusion anomalies. DABL achieves an F1-score of 96.87% and accuracy of 97.03% on known processes, and F1-score of 91.88% and accuracy of 92.39% on unseen processes, outperforming state-of-the-art semantic anomaly detection methods. The approach also provides interpretable explanations for detected anomalies in natural language, offering valuable insights for process improvement.

## Method Summary
DABL uses fine-tuned large language models to detect semantic anomalies in business process traces by processing complete traces rather than event pairs, enabling capture of long-distance dependencies. The approach generates synthetic training data from 143,137 real-world process models, creating both normal traces through playout and anomalous traces via five ordering anomaly types (Skip, Insert, Rework, Early, Late) and exclusion anomalies by converting exclusive process nodes to parallel nodes. The model is fine-tuned using QLoRA on Llama 2-Chat 13B with 1.57M generated traces formatted as instruction-following conversations, enabling both classification and natural language explanation generation.

## Key Results
- DABL achieves F1-score of 96.87% and accuracy of 97.03% on test set D2 containing traces from seen processes
- DABL achieves F1-score of 91.88% and accuracy of 92.39% on test set D1 containing traces from unseen processes
- The approach provides interpretable natural language explanations for detected anomalies, outperforming state-of-the-art semantic anomaly detection methods

## Why This Works (Mechanism)

### Mechanism 1: Trace-Level Processing for Long-Distance Dependencies
- **Claim:** Processing complete traces (rather than event pairs) enables the model to capture long-distance dependencies that existing semantic methods miss.
- **Mechanism:** The paper converts entire traces into question-answer prompts (e.g., "In the following business process trace... Is this trace normal or anomalous?"), allowing the LLM to attend across all activities simultaneously via transformer attention patterns.
- **Core assumption:** Long-distance semantic relationships (e.g., "reject application" should exclude downstream "send acceptance pack") are learnable from structural patterns in training data.
- **Evidence anchors:** [Abstract]: "current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies"; [Page 3]: "our DABL incorporates the entire trace into a novel prompt, allowing the LLMs to capture long-distance dependencies"

### Mechanism 2: Synthetic Anomaly Generation from Process Models
- **Claim:** Synthetic anomaly generation from structured process models creates learnable semantic patterns without requiring labeled real-world anomalies.
- **Mechanism:** The authors playout 143,137 process models to generate normal traces, then apply five ordering anomaly types (skip, insert, rework, early, late) and exclusion anomalies via process tree manipulation (replacing exclusive nodes × with parallel nodes ∧). Each anomaly is paired with a natural language cause description.
- **Core assumption:** Anomalies simulated from structural process knowledge transfer to real-world semantic violations.
- **Evidence anchors:** [Page 4]: "We collect 143,137 real-world process models... generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies"; [Page 5-6]: Detailed anomaly type definitions with cause templates

### Mechanism 3: Domain-Specific Fine-Tuning of General-Purpose LLMs
- **Claim:** Domain-specific fine-tuning injects business process semantic knowledge into general-purpose LLMs, overcoming zero-shot limitations.
- **Mechanism:** QLoRA fine-tuning (4-bit quantization with LoRA adapters) on Llama 2-Chat 13B using 1.57M generated traces formatted as instruction-following conversations. The model learns both classification ("normal/anomalous") and explanation generation from cause annotations.
- **Core assumption:** The pre-trained LLM's language understanding provides a substrate that can be specialized without catastrophic forgetting.
- **Evidence anchors:** [Page 6]: "fine-tune the Llama 2-Chat 13B model... using QLoRA... to create a generic model capable of detecting semantic anomalies"; [Page 7-8]: F1 of 91.88% on unseen processes (D1), 96.87% on seen processes (D2)

## Foundational Learning

- **Concept: Business Process Model and Trace**
  - **Why needed here:** The paper assumes familiarity with BPMN process models, workflow nets, and how traces represent process instances. Understanding playout (generating valid execution paths from a model) is essential for grasping the training data pipeline.
  - **Quick check question:** Given a process model with activities A→B→C where B and C are in parallel, what traces are valid?

- **Concept: Semantic vs. Statistical Anomaly Detection**
  - **Why needed here:** The paper's core argument is that frequency-based detection conflates "infrequent" with "anomalous." Understanding this distinction explains why DABL focuses on semantic relationships (e.g., mutual exclusion) rather than rarity.
  - **Quick check question:** If activity sequence "approve request → reject request" appears in 5% of traces, is it anomalous from a statistical view? From a semantic view?

- **Concept: Parameter-Efficient Fine-Tuning (QLoRA)**
  - **Why needed here:** The paper uses QLoRA rather than full fine-tuning. Understanding quantization (4-bit) and LoRA (low-rank adapters) is needed to replicate or modify the training approach.
  - **Quick check question:** Why might QLoRA be preferred over full fine-tuning for a 13B parameter model on a single 48GB GPU?

## Architecture Onboarding

- **Component map:** [Process Model Collection: BPMAI, FBPM, SAP-SAM] -> [Normal Trace Generation: 1.57M traces from 143K models] -> [Training Data: traces + labels + cause descriptions] -> [Fine-tuning: Llama 2-Chat 13B + QLoRA] -> [DABL Model: binary classification + natural language explanation]

- **Critical path:**
  1. Process model quality filtering (BPMN, English, sound workflow net) — garbage models produce noisy training data
  2. Anomaly simulation correctness — exclusion anomalies require accurate process tree conversion; ordering anomalies must avoid generating traces that are actually valid
  3. Cause template quality — natural language explanations must be consistent and learnable

- **Design tradeoffs:**
  - **Synthetic vs. real anomalies:** Training on simulated anomalies enables scale (1.57M traces) but may not cover all real-world patterns. The paper acknowledges this limitation (Page 8).
  - **Single vs. multi-anomaly interpretation:** DABL interprets one anomaly type per inference; multi-anomaly traces require iterative fixing and re-querying (Page 8).
  - **Generalization vs. specialization:** Pre-trained DABL works zero-shot but may struggle with idiosyncratic organizational processes (Page 8).

- **Failure signatures:**
  - Low precision on custom processes: Model over-generalizes from training domains
  - Nonsensical explanations: Cause generation degrades when trace length approaches context limit
  - Missed exclusion anomalies: Process tree conversion failed or exclusive branches not captured

- **First 3 experiments:**
  1. **Baseline validation:** Run DABL on the provided test datasets (D1 for generalization, D2 for seen-process performance) and verify F1 scores are within 2% of reported values (91.88% and 96.87%).
  2. **Ablation on training data scale:** Fine-tune on 10% and 50% of training data to measure sensitivity to process model coverage. Hypothesis: performance on D1 (unseen processes) degrades more than D2.
  3. **Real-world stress test:** Apply DABL to a domain not well-represented in BPMAI/FBPM/SAP-SAM (e.g., manufacturing IoT event logs from corpus neighbor "Detecting Process Activities from Sensor Streams"). Evaluate whether semantic patterns transfer or if domain-specific fine-tuning is required.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the model be enhanced to simultaneously detect and explain multiple co-occurring anomaly types within a single trace without requiring iterative re-input?
  - **Basis in paper:** [explicit] The authors state in the Limitations section that "when multiple anomaly types occur within a trace, DABL can still classify the trace as an anomaly but can only interpret one type of anomaly at a time."
  - **Why unresolved:** The current training data generation and model architecture appear optimized for single-cause attribution, necessitating a manual loop where the trace must be fixed and re-input to identify subsequent errors.
  - **What evidence would resolve it:** A modified training objective and output format that allows the generation of a structured list of distinct semantic violations (e.g., exclusion and ordering anomalies) in a single inference pass.

- **Open Question 2:** To what extent does the inclusion of imprecise process models (precision < 1) in the training data impact the model's ability to distinguish between valid unseen behavior and semantic anomalies?
  - **Basis in paper:** [explicit] The authors note that "the precision of the collected process model may not be equal to 1, which means it might allow traces not observed in the original process," potentially impacting training data quality.
  - **Why unresolved:** The paper demonstrates high performance but does not quantify the noise introduced by "unobserved but allowed" traces being treated as ground truth during the fine-tuning of the Large Language Model.
  - **What evidence would resolve it:** An ablation study comparing the performance of models trained exclusively on high-precision verified models versus the current dataset containing "fluffy" (less precise) process models.

- **Open Question 3:** How can the zero-shot approach be adapted to effectively distinguish between common-sense semantic anomalies and valid deviations in highly customized or idiosyncratic business processes?
  - **Basis in paper:** [explicit] The authors acknowledge in the Limitations that the "open-source model may struggle with traces that, while irregular from a common-sense perspective, are normal within their customized processes."
  - **Why unresolved:** The model relies on general semantic knowledge derived from broad training data, which may conflict with specific, non-standard organizational rules that differ from common process logic.
  - **What evidence would resolve it:** A method for injecting process-specific constraints or performing efficient few-shot adaptation that reduces false positives in specialized domains without full retraining.

## Limitations

- **Synthetic training data transferability:** The paper acknowledges that synthetic anomaly generation may not capture all real-world semantic violations, and performance on truly unlabeled real-world data with known ground truth anomalies has not been validated.
- **Process model quality and representativeness:** The training relies on 143,137 process models from public repositories, but the paper does not analyze whether these models adequately represent the diversity of real-world business processes across industries and organizational contexts.
- **Exclusion anomaly detection dependency:** The exclusion anomaly detection mechanism depends on accurate process tree conversion from workflow nets, which the paper cites but does not validate for accuracy or discuss edge cases.

## Confidence

- **High Confidence (95%+):** The technical methodology for fine-tuning LLMs using QLoRA is well-established and the reported classification metrics (F1-scores of 91.88% and 96.87%) are internally consistent with the described experimental setup. The mechanism of capturing long-distance dependencies through trace-level prompting is theoretically sound given transformer architecture properties.
- **Medium Confidence (70-95%):** The claimed superiority over state-of-the-art semantic anomaly detection methods is based on comparisons with specific published approaches, but the paper does not provide ablation studies isolating the contribution of each architectural choice.
- **Low Confidence (30-70%):** The generalizability of results to truly unseen business domains and the effectiveness of natural language explanations for end-user process improvement have not been validated beyond the reported test sets. The synthetic training data may create blind spots for anomalies not covered by the five ordering types or simple exclusion patterns.

## Next Checks

1. **Cross-domain generalization test:** Apply DABL to process logs from a domain absent in the training corpus (e.g., manufacturing IoT sensor streams or healthcare clinical workflows) and measure performance degradation. Compare against fine-tuning DABL on domain-specific process models to quantify transfer learning effectiveness.

2. **Real anomaly validation study:** Collaborate with organizations to obtain real-world process traces with verified semantic anomalies (not synthetically generated). Evaluate DABL's detection accuracy and explanation quality on these authentic anomalies, comparing against human expert assessments.

3. **Ablation of synthetic data contribution:** Train and evaluate DABL variants using only a subset of synthetic anomaly types (e.g., ordering anomalies only, or exclusion anomalies only) to determine which anomaly categories contribute most to overall performance and whether certain types are over-represented in the training data.