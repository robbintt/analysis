---
ver: rpa2
title: A Complete Pipeline for deploying SNNs with Synaptic Delays on Loihi 2
arxiv_id: '2510.13757'
source_url: https://arxiv.org/abs/2510.13757
tags:
- delays
- loihi
- networks
- neuromorphic
- spiking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents a complete pipeline for training and deploying
  Spiking Neural Networks (SNNs) with synaptic delays on neuromorphic hardware. The
  authors combine efficient event-based training using EventProp on GPUs with deployment
  on Intel's Loihi 2 neuromorphic chip for keyword recognition tasks.
---

# A Complete Pipeline for deploying SNNs with Synaptic Delays on Loihi 2

## Quick Facts
- arXiv ID: 2510.13757
- Source URL: https://arxiv.org/abs/2510.13757
- Reference count: 26
- Key outcome: First demonstration of SNNs with trained synaptic delays deployed on Loihi 2 for speech recognition, achieving up to 26.9% accuracy improvement and 18× speedup with 250× energy reduction versus GPU.

## Executive Summary
This work presents a complete pipeline for training and deploying Spiking Neural Networks (SNNs) with learnable synaptic delays on neuromorphic hardware. The authors combine efficient event-based training using EventProp on GPUs with deployment on Intel's Loihi 2 chip for keyword recognition tasks. Their method demonstrates that incorporating synaptic delays significantly improves classification accuracy compared to architectures without delays, particularly for feedforward networks (up to 26.9% improvement on the Spiking Speech Commands dataset). The pipeline achieves near-identical accuracy between GPU and Loihi 2 implementations while providing substantial performance benefits: classification on Loihi 2 is up to 18× faster and uses 250× less energy than on an NVIDIA Jetson Orin Nano. This represents the first demonstration of deploying SNN models with trained delays on neuromorphic hardware for speech recognition, enabling practical, energy-efficient edge computing solutions for voice-controlled applications.

## Method Summary
The pipeline combines GPU-based EventProp training with neuromorphic deployment on Loihi 2. Training uses mlGeNN with Leaky Integrate-and-Fire neurons, exponential synapses, and 8-bit weight quantization for hardware deployment. The method employs single-layer recurrent or two-layer feedforward architectures with 512-1024 hidden neurons, trained on Spiking Heidelberg Digits (SHD) and Spiking Speech Commands (SSC) datasets with 700 input channels from an artificial cochlea model. Models use non-firing output neurons with max voting on exponentially weighted voltage integrals, target firing rate of 14 Hz, and timesteps of 1-2 ms. Delays are clamped to a maximum of 62 timesteps to match Loihi 2 hardware constraints. Trained models are exported to NetX format and deployed on Loihi 2 via NxKernel, with benchmarking against NVIDIA Jetson Orin Nano.

## Key Results
- Feedforward networks with delays achieved 26.9% higher accuracy than without delays on Spiking Speech Commands dataset
- Loihi 2 deployment achieved 18× faster classification and 250× lower energy consumption compared to NVIDIA Jetson Orin Nano
- Recurrent networks with delays showed 1.8% accuracy improvement over no-delay variants on Spiking Heidelberg Digits
- Energy Delay Product was 4,500× lower on Loihi 2 versus GPU implementation

## Why This Works (Mechanism)
The performance gains stem from the combination of efficient event-based training with EventProp and the exploitation of temporal dynamics through synaptic delays. EventProp enables gradient computation through discrete spiking events rather than continuous activation functions, making it compatible with neuromorphic hardware constraints. Synaptic delays allow the network to process temporal patterns more effectively by introducing controlled time shifts in signal propagation, which is particularly valuable for speech recognition where temporal context is crucial. The quantization to 8-bit weights for Loihi 2 deployment reduces memory footprint and enables efficient parallel processing on neuromorphic cores while maintaining accuracy through careful scaling.

## Foundational Learning
- **EventProp**: Gradient computation through discrete spiking events rather than continuous activations. Needed for efficient training of SNNs compatible with neuromorphic hardware. Quick check: Verify gradients flow through spike timing changes during backpropagation.
- **LIF Neurons**: Leaky Integrate-and-Fire neurons with exponential synapses. Standard choice for neuromorphic deployment due to biological plausibility and computational efficiency. Quick check: Monitor membrane potential dynamics and spike generation patterns.
- **NetX Format**: Standardized neural network exchange format for neuromorphic deployment. Enables seamless transition from training to hardware execution. Quick check: Validate model structure and parameter ranges after conversion.
- **NxKernel**: Runtime system for executing NetX models on Loihi 2. Provides the interface between trained models and neuromorphic hardware. Quick check: Confirm successful model loading and execution on hardware.
- **8-bit Quantization**: Weight precision reduction for efficient hardware deployment. Balances accuracy preservation with memory and computational efficiency on neuromorphic cores. Quick check: Compare fp32 vs int8 simulation accuracy before hardware deployment.
- **Exponentially Weighted Voltage Integrals**: Non-firing output neuron readout mechanism. Enables classification without requiring output neuron spiking. Quick check: Verify voting mechanism correctly identifies maximum response.

## Architecture Onboarding
- **Component Map**: GPU Training (mlGeNN + EventProp) -> NetX Export -> Loihi 2 Deployment (NxKernel)
- **Critical Path**: Training with delays → Quantization → Hardware deployment → Benchmarking
- **Design Tradeoffs**: Delay constraints (62 timesteps) limit temporal modeling capacity vs. hardware compatibility; 8-bit quantization reduces accuracy slightly but enables efficient deployment; recurrent vs. feedforward architectures balance temporal modeling vs. parameter efficiency
- **Failure Signatures**: Accuracy degradation when delays approach hardware limit; quantization artifacts causing performance gaps; deployment failures due to NetX format incompatibility
- **First Experiments**: 1) Train baseline SNN without delays on SHD dataset; 2) Train SNN with delays on same dataset and compare accuracy; 3) Deploy delay-enabled model on Loihi 2 and verify accuracy preservation

## Open Questions the Paper Calls Out
The paper explicitly identifies three key directions for future work: (1) Exploring whether sparsely connected SNNs with delays maintain high performance on temporally complex tasks and understanding the accuracy-energy trade-off on Loihi 2; (2) Investigating whether complex neuron models (e.g., adaptive or resonate-and-fire) combined with synaptic delays can outperform standard LIF models on neuromorphic hardware; (3) Developing methods to mitigate the ~5% accuracy gap caused by the 62-timestep hardware constraint for tasks requiring precise long-term temporal information.

## Limitations
- The 62-timestep delay constraint on Loihi 2 may limit performance on tasks requiring longer temporal dependencies
- The pipeline requires INRC membership and specific hardware access for Loihi 2 deployment
- Exact training hyperparameters and seeds are not fully specified, potentially affecting reproducibility
- The study focuses on keyword recognition tasks, limiting generalizability to other domains

## Confidence
- **High**: Accuracy improvements with delays are robust within experimental setup
- **Medium**: Energy and latency gains depend on specific hardware configuration and baseline comparison
- **Low**: Generalizability beyond tested tasks and datasets remains uncertain

## Next Checks
1. Reproduce the training pipeline on SHD/SSC datasets with varied seeds to confirm reported accuracy ranges
2. Compare 8-bit quantized mlGeNN simulation with fp32 baseline to assess quantization impact on accuracy
3. Benchmark energy and latency on Loihi 2 against other edge devices (e.g., Raspberry Pi 4, Intel Core i7) for broader context