---
ver: rpa2
title: 'AgentSM: Semantic Memory for Agentic Text-to-SQL'
arxiv_id: '2601.15709'
source_url: https://arxiv.org/abs/2601.15709
tags:
- agent
- reasoning
- exploration
- arxiv
- text-to-sql
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AgentSM, a framework that enables agents
  to reuse reasoning steps across related Text-to-SQL tasks within the same database.
  By exploiting the inherent repetition in data exploration, AgentSM synthesizes,
  stores, and retrieves structured trajectories to substantially reduce redundant
  exploration and improve execution efficiency.
---

# AgentSM: Semantic Memory for Agentic Text-to-SQL

## Quick Facts
- **arXiv ID**: 2601.15709
- **Source URL**: https://arxiv.org/abs/2601.15709
- **Reference count**: 40
- **Primary result**: 44.8% execution accuracy on Spider 2.0 Lite with 25% reduction in trajectory length and 35% accuracy improvement over baseline

## Executive Summary
AgentSM introduces a semantic memory framework that enables agents to reuse reasoning steps across related Text-to-SQL tasks within the same database. By exploiting the inherent repetition in data exploration, AgentSM synthesizes, stores, and retrieves structured trajectories to substantially reduce redundant exploration and improve execution efficiency. The framework also introduces composite tools that combine frequently co-occurring tool sequences, streamlining decision-making and reducing agent steps. On the Spider 2.0 Lite benchmark, AgentSM achieves an execution accuracy of 44.8%, reducing average trajectory length by 25% and improving accuracy by 35% compared to standard coding agents.

## Method Summary
AgentSM employs a two-agent architecture where a planner agent manages high-level reasoning while delegating fine-grained schema exploration to a schema-linking agent. The system captures prior execution traces as structured programs, storing them in markdown format with semantic headers. When processing new queries, the planner retrieves relevant trajectories via semantic similarity and reads them before reasoning. Composite tools are dynamically constructed from frequently co-occurring tool sequences, compressing multiple reasoning steps into single atomic actions. The framework uses MiniLM-L6-v2 embeddings with FAISS for similarity search and runs on the smolagents framework with Claude API access.

## Key Results
- **44.8% execution accuracy** on Spider 2.0 Lite benchmark
- **25% reduction** in average trajectory length compared to baseline
- **35% accuracy improvement** over standard coding agents
- **Strong performance** on large, complex schemas and diverse SQL dialects

## Why This Works (Mechanism)

### Mechanism 1: Structured Trajectory Reuse Eliminates Redundant Exploration
Providing agents with structured trajectories from semantically similar prior queries reduces exploration steps and improves accuracy. Trajectories are synthesized offline, classified into phases (exploration, execution, validation), stored in structured markdown format, and retrieved via question similarity. The planner agent reads relevant trajectory segments before reasoning, avoiding repeated schema inspection. This works because data exploration patterns are transferable across semantically similar questions on the same database schema.

### Mechanism 2: Composite Tools Reduce Planning Variance and Step Count
Aggregating frequently co-occurring tool sequences into single composite tools reduces trajectory length and execution variance. Tool usage is analyzed across trajectories; sequences exceeding a support threshold are merged. This compresses multiple reasoning steps into one atomic action. This works because certain tool sequences are deterministic and universally applicable across phases (exploration, validation).

### Mechanism 3: Dual-Agent Architecture Isolates Exploration from Reasoning
Delegating fine-grained schema exploration to a specialized schema-linking agent prevents planner context drift. Planner agent manages high-level reasoning; schema-linking agent operates within a small step budget for vector search and join validation, returning structured findings to the planner. This works because exploration can be completed in a bounded number of steps, and inter-agent communication overhead is acceptable.

## Foundational Learning

- **ReAct Agent Loop (Reasoning-Action-Observation)**: AgentSM's planner and schema-linking agents both follow ReAct-style cycles. Understanding this pattern is prerequisite to grasping how trajectories are formed.
  - Quick check: Can you trace how an observation (e.g., SQL error) feeds into the next reasoning step?

- **Schema Linking in Text-to-SQL**: The schema-linking agent's primary job is mapping question tokens to database elements. Without understanding this bottleneck, the architecture's division of labor is unclear.
  - Quick check: Given a question "highest revenue by region" and schema with tables `sales`, `regions`, `products`, which tables/columns would schema linking identify?

- **Vector Similarity Retrieval**: Both trajectory selection (question similarity) and schema exploration (table/column retrieval) rely on embedding-based search.
  - Quick check: Why would semantic similarity between questions correlate with overlapping exploration trajectories?

## Architecture Onboarding

- **Component map**: Planner Agent -> Trajectory Retrieval -> Schema-Linking Agent -> Composite Tools -> SQL Execution -> Validation
- **Critical path**: Incoming question → retrieve most similar trajectory from same database → Planner reads structured trajectory (exploration phase) → If schema unclear → invoke schema-linking agent → Planner generates SQL using composite tools where applicable → Execute SQL with self-refinement on errors → Validate and output results
- **Design tradeoffs**: Two agents vs. monolithic chosen to isolate exploration (trades coordination overhead for context clarity); Markdown vs. JSON trajectories chosen for human readability (both outperform raw logs); Fixed step budget prevents runaway exploration but may miss complex schemas
- **Failure signatures**: High Snowflake error rate (44% of failures) with nested schemas → schema-linking gaps; Step budget exhaustion (5% of Snowflake failures) → exploration too costly; Domain-specific databases (github_repos, idc) at 14-40% accuracy → insufficient trajectory coverage or domain mismatch
- **First 3 experiments**: 
  1. Trajectory format ablation: Compare raw logs vs. markdown vs. JSON on held-out subset; measure step count and accuracy
  2. Composite tool coverage analysis: Log tool sequences on 50 questions; identify top co-occurring pairs and construct 2-3 composite tools; measure step reduction
  3. Schema-linking budget sweep: Vary schema-linking agent step limit (3, 5, 8); measure accuracy vs. latency tradeoff on nested-schema databases

## Open Questions the Paper Calls Out

### Open Question 1
Can finer-grained trajectory retrieval strategies (schema-level or plan-based alignment) improve accuracy without missing essential reasoning context? The current semantic similarity-based retrieval may retrieve suboptimal trajectories, but finer-grained methods risk excluding useful context, and the tradeoff remains unexplored.

### Open Question 2
How can shared memory be effectively implemented for multi-agent Text-to-SQL systems without introducing retrieval inefficiency, consistency issues, or error propagation? AgentSM deliberately uses two tightly coupled agents to avoid context fragmentation, but scaling to more agents would require shared memory mechanisms not yet designed.

### Open Question 3
What architectural or memory enhancements would enable trajectory reuse to benefit queries requiring complex mathematical operations or intricate CTE reasoning? Current trajectory reuse captures exploration patterns but not abstract reasoning templates for mathematical or nested-query logic.

## Limitations
- Composite tool construction methodology lacks detailed specification of co-occurrence threshold τ
- Schema linking in nested schemas causes significant failures (30% of Snowflake failures)
- Synthetic trajectory coverage remains limited for domain-specific databases (14-40% accuracy)

## Confidence
- **High Confidence**: Structured trajectory reuse mechanism (25% step reduction, 35% accuracy improvement)
- **Medium Confidence**: Composite tools show strong effect sizes but lack detailed construction methodology
- **Medium Confidence**: Dual-agent architecture is theoretically sound but trade-offs need more evaluation

## Next Checks
1. **Trajectory Format Ablation Study**: Compare raw vs. markdown vs. JSON trajectories on held-out subset to verify 0% vs. 25% step reduction finding
2. **Composite Tool Coverage Analysis**: Log tool sequences across 50 questions to identify co-occurring patterns and measure step reduction when applying composite tools
3. **Schema-Linking Budget Sweep**: Vary schema-linking agent's step limit (3, 5, 8 steps) on nested-schema databases to measure accuracy-latency tradeoffs