---
ver: rpa2
title: Estimation of Treatment Effects in Extreme and Unobserved Data
arxiv_id: '2506.14051'
source_url: https://arxiv.org/abs/2506.14051
tags:
- extreme
- assumption
- treatment
- estimation
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses estimating treatment effects on rare, high-impact
  events by combining causal inference and extreme value theory. It introduces the
  Normalized Extreme Treatment Effect (NETE), a causal estimand capturing how interventions
  shift the tail average of outcome distributions.
---

# Estimation of Treatment Effects in Extreme and Unobserved Data

## Quick Facts
- arXiv ID: 2506.14051
- Source URL: https://arxiv.org/abs/2506.14051
- Authors: Jiyuan Tan; Jose Blanchet; Vasilis Syrgkanis
- Reference count: 35
- Key outcome: Introduces NETE to estimate treatment effects on rare events via EVT; shows EVT-DR estimator outperforms naive methods in synthetic and semi-synthetic experiments.

## Executive Summary
This paper tackles the challenge of estimating treatment effects for rare, high-impact events by combining causal inference with extreme value theory. The authors introduce the Normalized Extreme Treatment Effect (NETE), which captures how interventions shift the tail average of outcome distributions. By modeling rare events via multivariate regular variation, they achieve identification by separating spectral measure estimation from tail-index estimation, enabling efficient inference. The proposed doubly robust (EVT-DR) estimator, backed by non-asymptotic error bounds, demonstrates superior performance over naive estimators in both synthetic and semi-synthetic experiments.

## Method Summary
The method estimates NETE through a two-stage process: first, nuisance functions (propensity scores and pseudo-outcomes) are estimated using a data split; second, extreme samples above a data-driven threshold are used to compute spectral and tail-moment components. The doubly robust estimator combines pseudo-outcome regression with inverse propensity weighting, while an adaptive Hill estimator selects the threshold based on Pareto-tail stability. The final NETE estimate multiplies the spectral effect by a tail-moment factor derived from the estimated tail index.

## Key Results
- EVT-DR estimator achieves lowest MSE in most synthetic configurations, closely matching ground truth NETE
- EVT-IPW and EVT-DR significantly outperform naive estimators (MSE up to 100x smaller) when Pareto assumptions hold
- In semi-synthetic wavesurge data, EVT-DR deviates least from test-set estimates while capturing meaningful treatment effects on extreme events

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating spectral measure estimation from tail-index estimation enables efficient inference on extreme treatment effects.
- Mechanism: Multivariate regular variation implies asymptotic independence of norm and angular component, allowing NETE to decompose into spectral and tail-moment terms, each estimated separately.
- Core assumption: U is multivariate regularly varying and independent of (X, D); asymptotic homogeneity with known growth exponent α.
- Evidence anchors: [abstract] identification via separation; [Section 3.2] Proposition 3.3 decomposition; [corpus] limited support for EVT-DR decomposition.
- Break condition: If α ≥ β, the moment term diverges and NETE is undefined.

### Mechanism 2
- Claim: Doubly robust estimation provides sample-efficient extreme effect estimation with provable non-asymptotic rates.
- Mechanism: EVT-DR combines pseudo-outcome regression with IPW correction; nuisance errors enter multiplicatively (√Rp·Rg) rather than additively under DML cross-fitting.
- Core assumption: Exogeneity, overlap with clipped propensity, Pareto-type tails for non-asymptotic bounds.
- Evidence anchors: [Section 3.3] Error bound structure; [Section 4.1] EVT-DR achieves smallest MSE; [corpus] related DR theory without EVT.
- Break condition: If propensity estimates approach boundaries or ĝ poorly extrapolates, bias dominates.

### Mechanism 3
- Claim: Adaptive threshold selection via Hill estimator balances bias-variance tradeoff under unknown tail index.
- Mechanism: Adaptive Hill estimator selects k by stability; optimal threshold depends on "Pareto-ness" parameter s, with two regimes based on s and β.
- Core assumption: Pareto-type model class with parameter s; von Mises condition on ∥U∥.
- Evidence anchors: [Section 3.2] Algorithm 1 adaptive Hill; [Corollary 3.6] threshold rules; [corpus] no corpus papers on adaptive EVT in causal settings.
- Break condition: If U lacks Pareto-type tails, Hill estimator converges to 0 and threshold selection becomes unstable.

## Foundational Learning

- Concept: **Multivariate regular variation**
  - Why needed here: The entire identification strategy relies on asymptotic independence of radial and angular components.
  - Quick check question: Given a 2D random vector U, does n·P(∥U∥/b_n > r, U/∥U∥ ∈ A) converge to a product measure ν_β × S(A)?

- Concept: **Potential outcomes and ATE identification**
  - Why needed here: NETE extends ATE to conditional extreme events; g-formula and exogeneity underpin causal interpretation.
  - Quick check question: If Y(1),Y(0) ⊥ D | X fails due to unobserved confounding, does NETE retain a causal interpretation?

- Concept: **Double machine learning (DML) / orthogonalization**
  - Why needed here: DR estimator's non-asymptotic rate depends on nuisance errors entering multiplicatively rather than additively.
  - Quick check question: In equation 3.6, why does the term (D_i − p̂(X_i))/[p̂(X_i)(1−p̂(X_i))] orthogonalize the estimator against propensity misspecification?

## Architecture Onboarding

- Component map: Data splitter -> Nuisance learners (propensity, pseudo-outcome) -> Tail-index estimator -> Threshold selector -> NETE aggregator
- Critical path: Nuisance estimation (D₁) → threshold selection (D₂ summary stats) → spectral estimation (D₂ extreme samples) → tail-index estimation (D₂ norms) → final NETE = η̂ · μ̂
- Design tradeoffs: Higher threshold → lower bias but higher variance; DR vs IPW → robustness vs simplicity; sample splitting → reduced overfitting but halved effective sample size
- Failure signatures: MSE increasing with n (Assumption 3.4 violated); extreme NETE values (>10× expected); empty index set I (threshold too high); μ̂_n divergence (α̂_n · ĝ_n ≥ 1)
- First 3 experiments: 1) Synthetic Pareto validation with known NETE = 1/(1−α/β); 2) Threshold sensitivity analysis across wide range; 3) Misspecification stress test with Pareto mixture

## Open Questions the Paper Calls Out
- Develop a more adaptive method for choosing thresholds to optimize bias-variance tradeoff
- Estimate the scaling exponential α with rigorous theoretical guarantees rather than heuristics
- Extend non-asymptotic error bounds to general regularly varying distributions without strict Pareto-type assumption

## Limitations
- Theoretical identification requires strict multivariate regular variation and Pareto-type tails; violations could invalidate decomposition and threshold rules
- Nuisance estimation quality is critical; poor overlap or high-dimensionality could cause bias to dominate regardless of EVT structure
- Semi-synthetic real-data experiment uses opaque preprocessing and black-box U estimation, making error decomposition ambiguous

## Confidence
- **High confidence**: Identification argument via asymptotic independence is mathematically rigorous under stated assumptions; synthetic experiments confirm theoretical MSE rates
- **Medium confidence**: Doubly robust estimator's non-asymptotic bound is valid, but practical performance depends heavily on nuisance quality and overlap
- **Low confidence**: Semi-synthetic real-data conclusions weakened by opaque preprocessing, black-box U estimation, and lack of baseline comparisons

## Next Checks
1. **Assumption violation test**: Replace Pareto-generated U with heavy-tailed but non-Pareto distribution (e.g., log-normal mixture); run EVT-DR with fixed threshold rule and compare MSE to naive estimators
2. **Overlap sensitivity**: Systematically vary propensity clipping threshold c (e.g., c ∈ {0.01, 0.05, 0.1}) and re-run EVT-DR; track how MSE and μ̂_n stability degrade as overlap shrinks
3. **Threshold stability sweep**: For fixed synthetic data, sweep t across wide range (0.5t_n to 2t_n); plot bias-variance tradeoff and identify where EVT-DR MSE diverges from oracle performance