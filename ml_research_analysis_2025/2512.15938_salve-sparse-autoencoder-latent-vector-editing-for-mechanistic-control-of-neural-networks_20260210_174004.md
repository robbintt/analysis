---
ver: rpa2
title: 'SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of
  Neural Networks'
arxiv_id: '2512.15938'
source_url: https://arxiv.org/abs/2512.15938
tags:
- feature
- class
- features
- latent
- suppression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SALVE introduces a framework that bridges mechanistic interpretability
  and model editing by discovering interpretable features via sparse autoencoders,
  validating them with Grad-FAM visualizations, and enabling permanent weight-space
  interventions. The method learns a sparse, model-native feature basis without supervision
  and uses this to perform continuous modulation of class-defining and cross-class
  features.
---

# SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks

## Quick Facts
- arXiv ID: 2512.15938
- Source URL: https://arxiv.org/abs/2512.15938
- Reference count: 40
- Key outcome: SALVE introduces a framework that bridges mechanistic interpretability and model editing by discovering interpretable features via sparse autoencoders, validating them with Grad-FAM visualizations, and enabling permanent weight-space interventions. The method learns a sparse, model-native feature basis without supervision and uses this to perform continuous modulation of class-defining and cross-class features. It derives a critical suppression threshold αcrit to quantify class reliance on dominant features, supporting robustness diagnostics. Experiments on ResNet-18 and ViT-B/16 demonstrate consistent, interpretable control over model behavior. SALVE offers a principled pathway from feature discovery to actionable, permanent model edits, advancing transparent and controllable AI systems.

## Executive Summary
SALVE introduces a framework that combines sparse autoencoders (SAEs) and latent vector editing to achieve interpretable and permanent control over neural network behavior. By learning a sparse, model-native feature basis through SAEs and validating it with Grad-FAM visualizations, SALVE enables precise modulation of class-defining features. The method introduces a critical suppression threshold αcrit to quantify a model's reliance on dominant features, providing a tool for robustness diagnostics. Experiments on ResNet-18 and ViT-B/16 demonstrate consistent and interpretable suppression of target classes, offering a principled pathway from feature discovery to actionable model edits.

## Method Summary
SALVE discovers interpretable features via sparse autoencoders (SAEs) trained on model activations, validates them with Grad-FAM visualizations, and performs permanent weight-space interventions to modulate class behavior. The method fine-tunes vision models (ResNet-18, ViT-B/16) on Imagenette, extracts penultimate-layer activations, and trains SAEs with L₁ sparsity to learn a sparse feature basis. Dominant features per class are identified from class-conditional mean latent activations, and weight modulation is applied using decoder columns to suppress or enhance target classes. The critical suppression threshold αcrit quantifies class reliance on dominant features, enabling robustness diagnostics. Experiments show consistent, interpretable control over model behavior with minimal off-target effects.

## Key Results
- SALVE achieves interpretable suppression of target classes in ResNet-18 and ViT-B/16 with minimal off-target effects.
- The critical suppression threshold αcrit quantifies class reliance on dominant features, supporting robustness diagnostics.
- SALVE offers a principled pathway from feature discovery to permanent, actionable model edits, advancing transparent and controllable AI systems.

## Why This Works (Mechanism)
SALVE works by leveraging sparse autoencoders to discover interpretable, model-native features from neural network activations. These features are validated using Grad-FAM visualizations to ensure they align with semantic concepts. By modulating the decoder weights associated with dominant features, SALVE enables precise, permanent interventions in the model's weight space. The critical suppression threshold αcrit quantifies how much a class relies on a given feature, providing a diagnostic tool for robustness. This approach bridges mechanistic interpretability and model editing, offering a principled method for controllable AI systems.

## Foundational Learning
- **Sparse Autoencoders (SAEs):** Unsupervised models that learn a sparse, low-dimensional representation of high-dimensional data. Why needed: To discover interpretable, model-native features from neural network activations. Quick check: Verify reconstruction loss is low (< 0.1) and features are sparse.
- **L₁ Sparsity Regularization:** Encourages sparsity in the latent representation by penalizing the absolute values of latent activations. Why needed: To ensure the learned features are interpretable and disentangled. Quick check: Confirm latent activations are mostly zero with a few dominant values.
- **Grad-FAM Visualizations:** A technique to visualize and validate the semantic meaning of discovered features. Why needed: To ensure the SAE-learned features align with interpretable concepts. Quick check: Confirm visualizations match expected semantic patterns.
- **Weight Modulation:** Adjusting model weights to permanently alter behavior based on learned features. Why needed: To enable actionable, interpretable model edits. Quick check: Verify class accuracy changes as expected with intervention strength α.
- **Critical Suppression Threshold (αcrit):** A metric quantifying a class's reliance on a dominant feature. Why needed: To diagnose robustness and guide interventions. Quick check: Ensure αcrit values are consistent across samples within a class.
- **Decoder Column Weighting:** Using decoder weights to identify and modulate feature importance. Why needed: To target specific features for suppression or enhancement. Quick check: Confirm dominant features align with class-conditional mean latent activations.

## Architecture Onboarding
- **Component Map:** ResNet-18/ViT-B/16 -> Fine-tuning -> Activation Extraction -> SAE Training -> Feature Validation (Grad-FAM) -> Weight Modulation -> Suppression Evaluation
- **Critical Path:** SAE training and weight modulation are the core components; failure here breaks the framework.
- **Design Tradeoffs:** Standard SAE vs. advanced variants (e.g., Gated, Top-k) for feature separation; latent dimension affects granularity vs. reconstruction quality.
- **Failure Signatures:** Poor SAE reconstruction (high MSE) → features don't capture semantics; weak suppression → wrong dominant feature identified or weak sparsity.
- **First Experiments:**
  1. Fine-tune ResNet-18 on Imagenette and extract penultimate-layer activations.
  2. Train SAE with L₁ sparsity and validate reconstruction quality.
  3. Compute class-conditional mean latent activations and identify dominant features per class.

## Open Questions the Paper Calls Out
- **Open Question 1:** Does the critical suppression threshold (αcrit) quantitatively correlate with adversarial vulnerability, such that samples with low αcrit are more susceptible to attacks? The paper introduces αcrit as a diagnostic but does not validate it against adversarial robustness benchmarks.
- **Open Question 2:** Do advanced SAE architectures (e.g., Gated, Top-k, JumpReLU) improve SALVE's intervention precision on high-diversity datasets compared to the standard ℓ₁-regularized autoencoder? The paper suggests evaluating these variants but does not test them.
- **Open Question 3:** Can weight modulation be adapted for deeper layers to alter core concept formation rather than just modifying final output combinations? The paper suggests this as a future direction but does not demonstrate it.

## Limitations
- **SAE Latent Dimension Unspecified:** Critical for reconstruction quality and feature granularity, but not provided in the paper.
- **Activation Maximization Hyperparameters Missing:** Details like λL₂, λTV, iterations, and augmentations are not specified, affecting feature visualization fidelity.
- **Numerical αcrit Implementation Unclear:** Root-finding tolerances and search bounds are not detailed, potentially leading to inconsistent thresholds.

## Confidence
- **High:** Concept of sparse autoencoder feature discovery + permanent weight-space modulation for mechanistic control.
- **Medium:** Framework applicability to vision models (ResNet-18, ViT) and qualitative suppression effects.
- **Low:** Quantitative αcrit values, exact suppression thresholds, and detailed feature visualization fidelity without SAE and optimization details.

## Next Checks
1. Re-run SAE training with latent_dim ∈ [64, 128, 256] to empirically determine optimal reconstruction quality and feature sparsity.
2. Perform sensitivity analysis on αcrit computation by varying root-finding tolerance and bracketing range; compare results against reported thresholds.
3. Validate activation maximization outputs with different λL₂/λTV and augmentation parameters to ensure consistent interpretability of discovered features.