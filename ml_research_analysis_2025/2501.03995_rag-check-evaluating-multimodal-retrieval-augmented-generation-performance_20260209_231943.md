---
ver: rpa2
title: 'RAG-Check: Evaluating Multimodal Retrieval Augmented Generation Performance'
arxiv_id: '2501.03995'
source_url: https://arxiv.org/abs/2501.03995
tags:
- image
- each
- response
- query
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses hallucination issues in multimodal retrieval-augmented
  generation (RAG) systems by introducing a framework called RAG-Check that evaluates
  both the retrieval relevance and generated response accuracy. The core method involves
  training two neural network models: a Relevance Score (RS) model that assesses how
  relevant retrieved pieces are to user queries, and a Correctness Score (CS) model
  that evaluates the accuracy of generated response statements against the retrieved
  context.'
---

# RAG-Check: Evaluating Multimodal Retrieval Augmented Generation Performance

## Quick Facts
- arXiv ID: 2501.03995
- Source URL: https://arxiv.org/abs/2501.03995
- Reference count: 21
- RAG-Check introduces a framework with Relevance Score and Correctness Score models to evaluate multimodal RAG systems, achieving 91% alignment with human judgments

## Executive Summary
This paper addresses hallucination issues in multimodal retrieval-augmented generation (RAG) systems by introducing RAG-Check, a framework that evaluates both retrieval relevance and generated response accuracy. The core method involves training two neural network models: a Relevance Score (RS) model that assesses how relevant retrieved pieces are to user queries, and a Correctness Score (CS) model that evaluates the accuracy of generated response statements against the retrieved context. The framework was validated on a 5000-sample human-annotated database, demonstrating superior performance compared to existing methods for evaluating multimodal RAG systems.

## Method Summary
RAG-Check addresses multimodal RAG evaluation through a two-model approach. The Relevance Score (RS) model fine-tunes LLaVA-1.5 to classify whether retrieved images are relevant to query statements, while the Correctness Score (CS) model fine-tunes VILA to assess if generated statements are accurate given the retrieved context. The framework uses a 121K sample dataset (101K train, 10K val, 10K test) constructed from COCO images and ChatGPT-derived statements, with additional 5,000 human-annotated samples for validation. Statements are partitioned into atomic components via GPT-3.5, and subjective/objective classification is performed using a rule-based algorithm to handle subjective statements appropriately. Both models are trained with modified RLHF loss using A100 GPUs.

## Key Results
- RS model outperforms CLIP-based similarity by 20% in matching human preferences
- CS model achieves 91% alignment with human judgments on correctness evaluation
- Binary classification accuracy of approximately 88% on test data
- Threshold of η = 0.7 used for binary classification decisions

## Why This Works (Mechanism)
The framework works by decomposing the complex RAG evaluation problem into two simpler, orthogonal tasks: relevance assessment and correctness verification. By training separate models for these distinct aspects, RAG-Check can provide granular evaluation rather than a single holistic score. The use of modified RLHF loss helps the models learn from relative preferences between positive and negative samples, improving their ability to distinguish subtle differences in relevance and correctness.

## Foundational Learning
- **Modified RLHF Loss**: Uses -log(σ(y_sp) - σ(y_sn)) to maximize margin between positive and negative samples; needed for effective pairwise learning; quick check: verify loss decreases during training
- **Statement Partitioning**: Uses GPT-3.5 to split responses into atomic statements; needed to evaluate correctness at granular level; quick check: manually verify partitioned statements make sense
- **Subjective/Objective Classification**: Rule-based algorithm using modal verbs and hedging phrases; needed to handle statements that cannot be objectively verified; quick check: test algorithm on edge cases
- **CLIP/ViL encoders**: Vision-language models used as backbones; needed for multimodal understanding; quick check: verify embeddings capture visual-semantic relationships
- **Binary Classification Thresholding**: Uses η = 0.7 threshold for final decisions; needed to convert continuous scores to binary judgments; quick check: plot ROC curve to validate threshold choice

## Architecture Onboarding
- **Component Map**: COCO Images -> GPT-4o Statement Generation -> Triplet Dataset -> RS/CS Model Training -> Evaluation
- **Critical Path**: Data construction (COCO + GPT-4o) → Statement partitioning (GPT-3.5) → RS/CS model training (modified RLHF) → Human alignment evaluation
- **Design Tradeoffs**: Separate RS and CS models provide granularity but increase complexity vs. single holistic evaluator; rule-based subjective classification is interpretable but may miss nuanced cases
- **Failure Signatures**: RS model collapsing to 0.5 scores indicates poor margin learning; CS model misclassifying subjective statements suggests incomplete keyword lists
- **First Experiments**: 1) Train RS model on small subset and compare to CLIP baseline; 2) Test subjective/objective classifier on manual samples; 3) Validate CS model handles multiple images correctly

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset construction details are underspecified, particularly GPT-4o prompt engineering and sampling strategy
- Human-annotated evaluation samples are not publicly available, limiting independent verification
- Modified RLHF loss implementation details and specific training hyperparameters beyond learning rate are not fully specified
- Rule-based subjective/objective classification may not capture all nuanced cases

## Confidence
- High confidence: The core methodology of training separate RS and CS models for multimodal RAG evaluation is well-specified and theoretically sound
- Medium confidence: The comparison to CLIP-based similarity and claimed 20% improvement is plausible but difficult to verify without access to exact evaluation dataset
- Low confidence: Absolute performance numbers and human alignment metrics cannot be fully validated without access to the 5,000 human-annotated samples

## Next Checks
1. Implement the subjective/objective classification algorithm and validate its accuracy on a small manually-labeled test set to ensure it correctly partitions statements before proceeding with CS model training

2. Train the RS model using a subset of the COCO dataset and compare its binary classification accuracy against a baseline CLIP similarity score on a held-out validation set to verify the 20% improvement claim is reproducible

3. Conduct a small-scale human evaluation comparing RS and CS model outputs against human judgments on 100 samples to independently verify the reported 91% alignment metric