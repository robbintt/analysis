---
ver: rpa2
title: 'SafePred: A Predictive Guardrail for Computer-Using Agents via World Models'
arxiv_id: '2602.01725'
source_url: https://arxiv.org/abs/2602.01725
tags:
- risk
- task
- action
- agent
- long-term
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of long-term risks in computer-using
  agents (CUAs) that arise from actions appearing safe in the short term but causing
  harmful delayed consequences. The core method idea is a predictive guardrail framework
  called SafePred that leverages a world model to predict both short- and long-term
  risks, then translates these predictions into actionable decision guidance through
  a risk-to-decision loop.
---

# SafePred: A Predictive Guardrail for Computer-Using Agents via World Models
## Quick Facts
- arXiv ID: 2602.01725
- Source URL: https://arxiv.org/abs/2602.01725
- Reference count: 36
- SafePred achieves over 97.6% safety performance across benchmarks while improving task utility by up to 21.4%

## Executive Summary
This paper introduces SafePred, a predictive guardrail system for computer-using agents (CUAs) that addresses the critical challenge of long-term risk prediction. Traditional CUAs focus on immediate task completion without considering delayed consequences, leading to actions that appear safe in the short term but cause harmful outcomes later. SafePred leverages a world model to predict both immediate and long-term risks by simulating future states, then translates these predictions into actionable decision guidance through a risk-to-decision loop.

The framework demonstrates significant improvements in both safety and utility, achieving over 97.6% safety performance while improving task completion by up to 21.4% compared to reactive baselines. A lightweight SafePred-8B model trained on just 1.5K samples achieves safety performance comparable to Deepseek-V3.2, making it practical for real-world deployment. The system addresses a fundamental gap in CUA safety by moving beyond reactive approaches to proactive risk management.

## Method Summary
SafePred implements a two-stage predictive guardrail framework that combines world model simulation with risk-to-decision translation. The system first predicts short- and long-term risks by simulating future states using a world model trained on diverse GUI interactions. These risk predictions are then converted into actionable decision guidance through a specialized translation mechanism that enables agents to proactively avoid harmful actions. The framework is evaluated across multiple benchmarks including Windows GUI, web environments, and system file operations, demonstrating consistent safety improvements while maintaining or enhancing task utility. A key innovation is the lightweight SafePred-8B variant that achieves competitive performance with minimal training data, making the approach scalable and practical.

## Key Results
- Achieves over 97.6% safety performance across multiple benchmarks
- Improves task utility by up to 21.4% compared to reactive baselines
- Lightweight SafePred-8B trained on 1.5K samples achieves safety performance comparable to Deepseek-V3.2

## Why This Works (Mechanism)
SafePred works by fundamentally changing how computer-using agents assess risk. Rather than evaluating actions based solely on immediate outcomes, it uses a world model to simulate future states and predict both short-term and long-term consequences. This predictive capability allows the system to identify actions that might seem safe initially but could lead to harmful outcomes over time. The risk-to-decision loop translates these predictions into concrete guidance that agents can use to modify their behavior proactively. By combining simulation-based risk assessment with actionable decision guidance, SafePred bridges the gap between understanding potential risks and actually preventing them in practice.

## Foundational Learning
- **World models in AI safety**: These are learned simulators that can predict future states of an environment. SafePred needs this to forecast long-term consequences of actions that aren't immediately apparent. Quick check: Can the world model accurately simulate complex GUI interactions across different platforms?

- **Risk-to-decision translation**: This converts predicted risks into specific actionable guidance for agents. It's essential because simply knowing risks isn't sufficient - agents need concrete instructions on how to avoid them. Quick check: Does the translation mechanism produce clear, implementable guidance for diverse risk scenarios?

- **Predictive guardrails**: Unlike reactive safety measures that respond to problems after they occur, predictive guardrails anticipate and prevent issues. SafePred needs this to address long-term risks that develop over time. Quick check: How far into the future can SafePred reliably predict risks while maintaining accuracy?

- **Multi-stage evaluation frameworks**: These assess both immediate task completion and long-term safety outcomes. SafePred requires this to demonstrate improvements in both dimensions simultaneously. Quick check: Do benchmark tasks adequately represent real-world complexity and potential failure modes?

## Architecture Onboarding
**Component Map**: World Model -> Risk Predictor -> Risk-to-Decision Translator -> Agent Decision Layer
**Critical Path**: The core pipeline flows from world model simulation through risk prediction to decision translation, with each stage depending on the previous one's output quality.
**Design Tradeoffs**: The framework balances between comprehensive risk prediction and computational efficiency, with the lightweight SafePred-8B variant sacrificing some modeling capacity for faster inference and lower resource requirements.
**Failure Signatures**: System failures typically manifest as either missed long-term risks (false negatives) or overly conservative decision guidance that reduces task utility (false positives), often stemming from world model limitations or translation inaccuracies.
**3 First Experiments**: 1) Test world model accuracy on novel GUI patterns not seen during training 2) Evaluate risk-to-decision translation quality with adversarial input sequences 3) Measure performance degradation when deployed across different operating systems

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation primarily focuses on desktop GUI applications without validation on mobile or cross-platform environments
- World model effectiveness heavily depends on training data quality and diversity, with the lightweight model trained on only 1.5K samples
- No systematic evaluation of limitations when dealing with novel UI patterns or highly dynamic interfaces

## Confidence
- High confidence in the core technical approach (world model + risk-to-decision loop) as the methodology is well-defined and internally consistent
- Medium confidence in the 97.6% safety performance claim, based on controlled benchmark evaluations
- Medium confidence in the 21.4% utility improvement, as comparisons are made against "reactive baselines" without detailed characterization

## Next Checks
1. Deploy SafePred in real-world usage scenarios across multiple platforms (desktop, mobile, web) to validate cross-platform generalization and measure performance degradation
2. Conduct stress testing with adversarial inputs and novel UI patterns to quantify world model failure modes and safety fallback mechanisms
3. Perform longitudinal studies to verify that predicted long-term risks actually materialize in practice through A/B testing with and without SafePred deployed