---
ver: rpa2
title: 'FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning'
arxiv_id: '2510.27359'
source_url: https://arxiv.org/abs/2510.27359
tags:
- selection
- parameter
- parameters
- fine-tuning
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the memory and efficiency bottleneck in selection-based
  parameter-efficient fine-tuning (PEFT) methods, particularly GPS, which requires
  a full backward pass for parameter selection, leading to high memory usage. The
  authors propose FPS (Feedforward-based Parameter Selection), a gradient-free approach
  that ranks parameters by the product of their magnitudes and corresponding input
  activations during a single forward pass.
---

# FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning

## Quick Facts
- **arXiv ID:** 2510.27359
- **Source URL:** https://arxiv.org/abs/2510.27359
- **Reference count:** 34
- **Primary result:** Gradient-free parameter selection method achieving 9× memory reduction and 2× speed improvement while matching GPS accuracy

## Executive Summary
This paper addresses the memory bottleneck in selection-based parameter-efficient fine-tuning (PEFT) methods, particularly GPS, which requires a full backward pass for parameter selection. The authors propose FPS (Feedforward-based Parameter Selection), a gradient-free approach that ranks parameters by the product of their magnitudes and corresponding input activations during a single forward pass. This joint consideration of pre-trained weights and downstream data properties enables FPS to identify important parameters without backpropagation. Evaluated on 24 visual tasks from FGVC and VTAB-1k benchmarks using ViT-B/16, FPS achieves performance comparable to GPS while reducing peak memory usage by nearly 9× and accelerating parameter selection by about 2×.

## Method Summary
FPS introduces a two-stage process for efficient parameter selection in PEFT. First, during the selection phase, it computes an importance score for each parameter as the product of its magnitude and the magnitude of its corresponding input activation, averaged across the dataset. This is done in a single forward pass without computing gradients, eliminating the memory overhead of storing intermediate activations for backpropagation. The top-k parameters are selected using neuron-level granularity (top-k per neuron rather than per layer). In the second fine-tuning phase, only these selected parameters are updated while the rest are frozen. The method uses ℓ1-norm for magnitude calculations and selects approximately 0.77% of total parameters to match GPS settings.

## Key Results
- Achieves comparable accuracy to GPS across 24 visual tasks (FGVC and VTAB-1k)
- Reduces peak GPU memory usage by nearly 9× during parameter selection
- Accelerates parameter selection by approximately 2×
- Maintains similar fine-tuning performance with only 0.77% of parameters being updated

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The product of weight magnitude and input activation magnitude serves as a sufficient proxy for parameter importance during fine-tuning.
- **Mechanism:** FPS posits that a parameter is "important" if it represents a strong pre-trained feature (high weight magnitude) that is actively utilized by the downstream task (high activation magnitude). By multiplying these terms, the method filters out large weights that are never activated (irrelevant features) and highly active inputs connected to small weights (weak influence).
- **Core assumption:** The influence of a parameter on the loss landscape can be approximated by local magnitude statistics rather than global gradient flow.
- **Evidence anchors:** Abstract states "...ranks parameters by the product of their magnitudes and corresponding input activations..."; Section 3 defines importance score as the product of magnitude and corresponding input activation.
- **Break condition:** May fail when small weights gate critical signals in complex tasks.

### Mechanism 2
- **Claim:** Computing importance solely during the forward pass eliminates the memory bottleneck associated with storing intermediate activations for backpropagation.
- **Mechanism:** Standard selection methods like GPS require a backward pass to compute gradients, necessitating storing activation maps for all layers. FPS computes the importance score on-the-fly using the current activation and discards it immediately after the forward pass.
- **Core assumption:** The selection phase can be decoupled from gradient storage requirements without degrading the quality of the selected subset.
- **Evidence anchors:** Abstract mentions "...reducing peak memory usage by nearly 9x..."; Section 1 asks "can we bypass this issue with a gradient-free approach?"
- **Break condition:** If implementation retains the computation graph, memory savings will vanish.

### Mechanism 3
- **Claim:** Aggregating importance scores over the dataset (Expectation) stabilizes selection against batch-level noise.
- **Mechanism:** Rather than selecting parameters based on a single batch, FPS averages the product |w| · |a| across the dataset, ensuring selected parameters are consistently active across the task distribution.
- **Core assumption:** The mean magnitude of activations is a robust indicator of a neuron's relevance to the task manifold.
- **Evidence anchors:** Section 3 mentions "...average this product across all samples."; Appendix A.1 mentions stability across ℓ1 and ℓ2 norms.
- **Break condition:** Simple averaging might suppress features critical for minority modes in extremely noisy or multimodal datasets.

## Foundational Learning

### Concept: Backpropagation Memory Profile
- **Why needed here:** To understand why GPS is memory-inefficient - training memory is dominated by intermediate activations stored for the chain rule, not just model weights.
- **Quick check question:** Why does increasing batch size linearly increase memory usage during standard training, and how does FPS decouple from this?

### Concept: Parameter-Efficient Fine-Tuning (PEFT) Paradigms
- **Why needed here:** The paper positions itself against "Addition-based" (Adapters/LoRA) and "Selection-based" (GPS/Bias) methods. Understanding this taxonomy is required to see why FPS solves the engineering complexity of Adapters and the memory cost of GPS.
- **Quick check question:** Does FPS add new parameters to the architecture, or does it modify the trainability of existing ones?

### Concept: Magnitude-based Pruning vs. Selection
- **Why needed here:** FPS uses a magnitude-like metric for selection (tuning), not pruning (removing). Distinguishing "identifying important weights to update" from "identifying unimportant weights to delete" is crucial.
- **Quick check question:** In FPS, once the top 0.77% of parameters are selected, what happens to the remaining 99.23%? (Answer: They are frozen, not deleted).

## Architecture Onboarding

### Component map:
Data Loader -> Forward Pass (with activation capture) -> Accumulator (running sum of |w| · |a|) -> Selector (Top-k operation) -> Masking (binary mask for optimizer)

### Critical path:
The calculation of the importance score must happen strictly during the forward pass. The implementation must ensure gradients are not computed or stored during this phase (Selection Phase), distinct from the subsequent Fine-Tuning Phase.

### Design tradeoffs:
- **Layer-level vs. Neuron-level:** Neuron-level selection gives better results per ablation by ensuring uniform distribution across the network
- **ℓ1 vs ℓ2:** Both perform similarly; ℓ1 (absolute value) is used for simplicity

### Failure signatures:
- **OOM during selection:** Likely still computing gradients; verify `torch.no_grad()` is active
- **Performance Collapse:** Check if weight magnitudes were ignored; Appendix A.2 shows this drops accuracy significantly
- **Skewed Selection:** Using layer-level selection on deep layers may under-represent earlier layers; stick to neuron-level

### First 3 experiments:
1. **Memory Verification:** Profile peak GPU memory of GPS vs FPS on ViT-B/16 with fixed batch size to reproduce ~9× reduction
2. **Metric Ablation:** Run FPS on CUB-200 using (a) Weight-only, (b) Activation-only, and (c) Product to verify performance drop in Table A.1
3. **Hyperparameter Sensitivity:** Vary selection budget k to verify if 0.77% is robust or task-sensitive

## Open Questions the Paper Calls Out
- **Open Question 1:** Can incorporating distributional statistics beyond simple magnitude products improve FPS's parameter selection accuracy? The conclusion states future work may refine the magnitude-based score with distributional statistics.
- **Open Question 2:** Does FPS maintain its efficiency-accuracy tradeoff when applied to large language models or multimodal architectures? The evaluation is restricted to ViT-B/16 on 24 visual classification tasks.
- **Open Question 3:** Can the parameter budget k be determined adaptively per task rather than set as a fixed hyperparameter? The constrained optimization formulation treats k as a predefined hyperparameter without guidance for selection across diverse tasks.

## Limitations
- The magnitude×activation heuristic may not capture complex nonlinear importance patterns in tasks requiring precise credit assignment
- The 0.77% parameter selection ratio appears optimal but lacks systematic sensitivity analysis across diverse tasks
- While memory reduction is impressive (~9×), the absolute memory savings depend heavily on model size and batch dimensions

## Confidence
- **High confidence:** FPS achieves substantial memory reduction (9×) and selection acceleration (2×) compared to gradient-based methods - directly measured and reproducible
- **Medium confidence:** FPS achieves comparable accuracy to GPS across the tested 24 tasks - validated empirically but limited to specific ViT architecture and task domains
- **Medium confidence:** The magnitude×activation heuristic is sufficient for parameter importance ranking - theoretically sound but not rigorously compared against alternative heuristics

## Next Checks
1. **Architecture Generalization Test:** Apply FPS to other transformer variants (DeiT, ConvNeXT) and foundation models (CLIP, MAE) to verify the magnitude×activation heuristic generalizes beyond ViT-B/16
2. **Gradient Quality Analysis:** Quantitatively compare the selected parameter subsets from FPS vs GPS using correlation metrics or downstream performance when fine-tuning with different budgets
3. **Extreme Task Transfer:** Test FPS on tasks with significant domain shift from ImageNet-21K (medical imaging, satellite imagery) where pre-trained feature relevance may be more nonlinear