---
ver: rpa2
title: 'FusionLog: Cross-System Log-based Anomaly Detection via Fusion of General
  and Proprietary Knowledge'
arxiv_id: '2511.05878'
source_url: https://arxiv.org/abs/2511.05878
tags:
- logs
- anomaly
- knowledge
- proprietary
- general
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FusionLog is a zero-label cross-system log-based anomaly detection
  method that addresses the mismatch between general and proprietary knowledge in
  target systems. The method uses semantic routing to partition unlabeled target logs
  into "general logs" and "proprietary logs," then applies meta-learning on general
  logs and multi-round knowledge distillation with LLM for proprietary logs.
---

# FusionLog: Cross-System Log-based Anomaly Detection via Fusion of General and Proprietary Knowledge

## Quick Facts
- arXiv ID: 2511.05878
- Source URL: https://arxiv.org/abs/2511.05878
- Reference count: 40
- Achieves over 90% F1-score in fully zero-label cross-system anomaly detection settings

## Executive Summary
FusionLog addresses the challenge of transferring anomaly detection models from a labeled source system to an unlabeled target system by recognizing that logs contain both general patterns shared across systems and proprietary patterns unique to each system. The method uses a training-free semantic router to partition target logs based on similarity to source system events, then applies meta-learning to the general logs and multi-round knowledge distillation with an LLM for the proprietary logs. This hybrid approach significantly outperforms state-of-the-art methods in zero-label cross-system transfer, achieving over 90% F1-score across three public datasets.

## Method Summary
FusionLog operates through three phases: First, it preprocesses logs using Drain parser and embeds events with 300-dimensional semantic embeddings. Second, it applies semantic routing to partition unlabeled target logs into "general" (high similarity to source) and "proprietary" (low similarity) categories using cosine similarity thresholds. Third, it trains a small model via meta-learning on general logs while using multi-round collaborative knowledge distillation where an LLM generates pseudo-labels for proprietary logs, filtered by a small model's confidence thresholds, to gradually refine the detection capability.

## Key Results
- Achieves over 90% F1-score in fully zero-label cross-system settings
- Outperforms state-of-the-art methods (FreeLog, RAGLog) by 5-8% F1-score on HDFS→BGL transfer
- Shows effectiveness across three public datasets: HDFS, BGL, and OpenStack

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Semantic routing minimizes negative transfer by isolating system-specific "proprietary" logs from cross-system "general" logs.
- **Mechanism:** A training-free router computes cosine similarity between target log sequence embeddings and source system event prototypes, routing sequences below threshold τ to proprietary path.
- **Core assumption:** General logs share sufficient semantic overlap with source logs to be captured by cosine similarity on event embeddings.
- **Evidence anchors:** Abstract mentions "training-free router based on semantic similarity"; Section 3.2 details the routing threshold mechanism.
- **Break condition:** If target system's proprietary logs are semantically adversarial (high similarity but opposite label distribution), routing will fail.

### Mechanism 2
- **Claim:** Meta-learning enables a small model to inherit general anomaly patterns from source system and apply them to target's general logs without target labels.
- **Mechanism:** Uses adversarial unsupervised domain adaptation (maximizing domain confusion) combined with classification loss on labeled source data.
- **Core assumption:** Domain-invariant feature space exists where general anomaly patterns are consistent across systems.
- **Evidence anchors:** Abstract states "system-agnostic representation meta-learning... inheriting general anomaly patterns"; Section 3.3 describes domain classifier training.
- **Break condition:** If source system lacks diversity (e.g., only normal logs), meta-learned features won't generalize.

### Mechanism 3
- **Claim:** LLM collaboration with small model iteratively filters pseudo-labels via confidence thresholds to distill proprietary knowledge without ground truth.
- **Mechanism:** LLM provides pseudo-labels using RAG; small model filters by agreement and confidence; clean samples fine-tune small model and update RAG knowledge base iteratively.
- **Core assumption:** LLM possesses sufficient prior knowledge to label proprietary logs better than random guessing.
- **Evidence anchors:** Abstract mentions "multi-round collaborative knowledge distillation"; Section 3.4 details the filtering criteria and iterative process.
- **Break condition:** If LLM hallucinates consistently on specific proprietary patterns and small model initially agrees, errors will be reinforced.

## Foundational Learning

- **Concept: Log Parsing (Drain)**
  - **Why needed here:** Raw logs are unstructured text; architecture requires discrete "events" and embeddings for semantic similarity routing.
  - **Quick check question:** Can you explain how Drain extracts an event template from a raw log line like "Connection timed out at 12:00"?

- **Concept: Meta-Learning (MAML-like optimization)**
  - **Why needed here:** General Log branch relies on learning initialization that adapts to target system efficiently, not training static classifier.
  - **Quick check question:** How does the "support set" vs. "query set" split in meta-training differ from standard train/test splits?

- **Concept: Knowledge Distillation**
  - **Why needed here:** Proprietary Log branch transfers reasoning capability of LLM (Teacher) to Small Model (Student) for efficient inference.
  - **Quick check question:** In standard distillation, what is the role of "soft labels" (logits) vs. hard labels used in FusionLog's pseudo-labeling approach?

## Architecture Onboarding

- **Component map:** Preprocessing (Drain Parser → Embedding Layer) → Router (Cosine Similarity Calculator → Threshold Gate) → General Branch (GRU + Attention Meta-Learned → Anomaly Classifier) → Proprietary Branch (LLM + RAG Database ↔ Small Model) → Fusion (Unified inference output)

- **Critical path:** 1) Phase 1: Unlabeled target logs → Embedding → Similarity Check → Split into General/Proprietary 2) Phase 2a: Train SM on General logs + Source logs via Meta-Learning 3) Phase 2b: LLM labels Proprietary logs → SM filters/validates → Retrain SM → Update RAG (repeat N rounds) 4) Inference: New logs routed to specific branch models

- **Design tradeoffs:**
  - **Router Threshold (τ):** Low threshold increases General volume (efficient) but risks negative transfer; high threshold increases Proprietary volume (expensive LLM usage) but ensures safety. Paper sets τ to "mean" similarity.
  - **Dynamic Threshold (ε):** Starts high (0.9) to ensure purity, decreases to capture more data as model improves. Static thresholds caused training to stagnate.

- **Failure signatures:**
  - **Stagnant Distillation:** Clean pool stops growing early (LLM and SM disagreeing consistently or SM confidence dropping).
  - **Routing Skew:** All logs go to Proprietary (check source embeddings or threshold too high).
  - **Performance Drop on General Logs:** Indicates meta-learning failed to align domains (check source data compatibility).

- **First 3 experiments:**
  1. **Threshold Sensitivity (Ablation):** Vary routing threshold τ (0.5 to 0.7) on HDFS→BGL; observe General/Proprietary ratio and respective F1-scores.
  2. **Distillation Rounds:** Plot "Clean Ratio" vs. "Round Number" (Fig 4); verify dynamic threshold allows clean pool to grow unlike static threshold.
  3. **Zero-Label Baseline Comparison:** Run FusionLog vs. FreeLog (no proprietary handling) and RAGLog (no meta-learning) on HDFS→BGL transfer.

## Open Questions the Paper Calls Out

- **Can incorporating multi-modal data sources, such as source code, documentation, and configuration files, improve the extraction of proprietary knowledge compared to log-text-only approaches?**
  - Basis in paper: Authors plan to "incorporate proprietary knowledge from multiple modalities... to better capture system-specific anomalies."
  - Why unresolved: Current implementation relies solely on log event embeddings without utilizing structural code or configuration data.
  - What evidence would resolve it: Experiments showing performance improvements when FusionLog is augmented with source code or configuration analysis on proprietary log subsets.

- **How can the semantic routing mechanism be refined to move beyond simple cosine similarity thresholds for more precise partitioning of general and proprietary logs?**
  - Basis in paper: Authors explicitly aim to "develop more precise semantic routing mechanisms for distinguishing general from proprietary logs" in future work.
  - Why unresolved: Current method uses fixed threshold τ on semantic similarity, which may lack nuance for edge cases or complex semantic overlaps.
  - What evidence would resolve it: Comparative study evaluating learned routing mechanism against current training-free threshold approach across heterogeneous datasets.

- **Is the performance of FusionLog sensitive to the quality of the LLM's initial pseudo-labels, and does error propagation occur if the dynamic threshold decays too rapidly?**
  - Basis in paper: Paper notes dynamic threshold ε decreases with model performance but relies on assumption that early LLM labels for clean pool are accurate enough.
  - Why unresolved: While paper shows improved accuracy over rounds, it doesn't analyze scenarios where LLM is systematically biased in first iteration.
  - What evidence would resolve it: Ablation study simulating noisy LLM initial labels to observe recovery capability of multi-round distillation process.

## Limitations

- Semantic routing mechanism may fail when target systems contain proprietary patterns semantically similar to source patterns but functionally different
- LLM performance in proprietary knowledge distillation depends on availability of sufficient domain-relevant information in source system's logs for RAG retrieval
- Method requires source system to have sufficient labeled diversity to enable effective meta-learning transfer

## Confidence

- **High confidence:** Effectiveness of hybrid architecture (meta-learning for general logs + LLM distillation for proprietary logs) is well-supported by experimental results showing >90% F1-score across three datasets.
- **Medium confidence:** Dynamic threshold strategy for distillation shows promise but lacks extensive ablation studies to prove superiority over alternative strategies.
- **Low confidence:** Assumption that semantic similarity via cosine distance is sufficient for routing decisions across diverse system types has limited empirical validation.

## Next Checks

1. **Routing Robustness Test:** Conduct controlled experiments where target systems contain adversarial proprietary patterns (semantically similar but functionally opposite to source) to evaluate whether cosine similarity router fails as predicted.

2. **Meta-Learning Sensitivity Analysis:** Vary source system's label distribution (e.g., only normal logs vs. balanced) to quantify how source diversity impacts general branch's performance on target systems.

3. **LLM Knowledge Base Dependency:** Systematically remove source logs most relevant to proprietary patterns and measure degradation in distillation quality to validate RAG dependency claim.