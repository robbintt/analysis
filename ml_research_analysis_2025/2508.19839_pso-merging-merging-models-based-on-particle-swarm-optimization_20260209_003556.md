---
ver: rpa2
title: 'PSO-Merging: Merging Models Based on Particle Swarm Optimization'
arxiv_id: '2508.19839'
source_url: https://arxiv.org/abs/2508.19839
tags:
- merging
- wang
- zhang
- expert
- particle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PSO-Merging, a novel data-driven model merging
  method based on Particle Swarm Optimization (PSO) to construct multitask models
  by integrating multiple expert models. Unlike gradient-based methods that are computationally
  expensive or existing gradient-free methods that require many iterations, PSO-Merging
  leverages PSO to efficiently explore the parameter space.
---

# PSO-Merging: Merging Models Based on Particle Swarm Optimization

## Quick Facts
- arXiv ID: 2508.19839
- Source URL: https://arxiv.org/abs/2508.19839
- Reference count: 40
- Primary result: PSO-Merging outperforms baseline merging methods on average multitask performance while showing rapid convergence and scalability to large models

## Executive Summary
This paper introduces PSO-Merging, a novel data-driven model merging method based on Particle Swarm Optimization (PSO) to construct multitask models by integrating multiple expert models. Unlike gradient-based methods that are computationally expensive or existing gradient-free methods that require many iterations, PSO-Merging leverages PSO to efficiently explore the parameter space. The method initializes a swarm with pre-trained models, expert models, and sparsified versions of expert models, then iteratively updates particles using fitness evaluations based on average multitask performance. Experiments on Flan-T5-Base, Llama-2-13B, Llama-3-8B, and Mistral-7B-v0.3 demonstrate that PSO-Merging outperforms baseline merging methods on average scores and achieves significant improvements on specific tasks.

## Method Summary
PSO-Merging employs Particle Swarm Optimization to merge multiple fine-tuned expert models into a unified multitask model. The method initializes a swarm consisting of pre-trained models, expert models, and sparsified expert models as particles. Each particle represents a candidate merged model, and PSO iteratively updates particles through position and velocity adjustments based on individual and global best solutions. The fitness function evaluates average multitask performance across optimization sets. Sparsification addresses parameter conflicts by zeroing conflicting parameters during initialization. The process continues until convergence, yielding a merged model that balances performance across multiple tasks while maintaining computational efficiency compared to gradient-based approaches.

## Key Results
- PSO-Merging achieves superior average multitask performance compared to baseline merging methods across multiple model architectures
- The method demonstrates rapid convergence and scalability, successfully merging up to four large expert models
- PSO-Merging shows strong performance on specific tasks while maintaining competitive overall averages, though some individual tasks show regression

## Why This Works (Mechanism)
PSO-Merging leverages the global search capability of Particle Swarm Optimization to explore the parameter space efficiently without requiring gradient computations. By initializing particles with diverse model states (pre-trained, expert, and sparsified versions), the algorithm can escape local optima and find better parameter combinations for multitask learning. The fitness function based on average multitask performance guides the swarm toward solutions that balance capabilities across all tasks. Sparsification helps resolve parameter conflicts by preventing certain parameters from interfering with each other during the merging process, allowing the PSO to focus on finding complementary parameter combinations.

## Foundational Learning
- **Particle Swarm Optimization**: A population-based optimization algorithm where particles move through search space guided by personal and global best solutions; needed to efficiently explore parameter space without gradients
- **Model Merging Fundamentals**: The process of combining multiple fine-tuned models into a unified multitask model; needed to understand how different expert capabilities can be integrated
- **Parameter Conflict Resolution**: Techniques for handling conflicting parameter updates when merging models; needed because different tasks may optimize the same parameters in opposing directions
- **Fitness Function Design**: How to evaluate and compare different merged model configurations; needed to guide the PSO toward optimal solutions
- **Sparsification Techniques**: Methods for selectively zeroing parameters to reduce interference; needed to address parameter conflicts during merging
- **Multitask Learning Trade-offs**: Balancing performance across multiple tasks versus optimizing for individual tasks; needed to understand the optimization objectives

## Architecture Onboarding

**Component Map:** Expert Models → Sparsification Layer → PSO Swarm Initialization → Fitness Evaluation → PSO Update Rules → Merged Model

**Critical Path:** The fitness evaluation step is the computational bottleneck, requiring inference on optimization sets for all particles in each iteration. This determines overall runtime and scalability.

**Design Tradeoffs:** The paper trades computational efficiency (avoiding gradient calculations) for potentially suboptimal convergence compared to gradient-based methods, but claims faster overall convergence than other gradient-free approaches. The sparsification technique adds initialization complexity but helps resolve parameter conflicts.

**Failure Signatures:** Performance degradation on specific individual tasks despite improved average performance indicates that the fitness function may not adequately balance task-specific requirements. Slow convergence or stagnation suggests PSO parameters may need adjustment.

**First Experiments:**
1. Test PSO-Merging with two expert models on a simple task pair to verify basic functionality and convergence behavior
2. Compare fitness evaluation time against gradient computation time for the same merging problem
3. Conduct ablation study on sparsification percentage to determine optimal conflict resolution parameters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PSO-Merging be extended to merge experts from different base models or entirely different architectures?
- Basis in paper: The limitations section states: "The feasibility of merging experts based on distinct base models (e.g. Mistral-7B-v0.3 and Llama-2-7B) or even different architectures (e.g. Mistral-7B-v0.3 and Llama-3-8B) still remains unexplored."
- Why unresolved: All experiments merge experts fine-tuned from the same base model; cross-architecture merging requires parameter alignment across different dimensional spaces and architectural configurations.
- What evidence would resolve it: Successful merging of experts from models with different architectures (e.g., Mistral and Llama) with quantitative performance metrics comparing against single-task experts.

### Open Question 2
- Question: How does the computational cost of PSO-Merging scale with the number of experts and model size?
- Basis in paper: The paper claims efficiency advantages over gradient-based methods and compares to Evo, but only provides memory requirements (14GB for three 7B models) without detailed runtime analysis or scaling curves.
- Why unresolved: Fitness evaluations require inference on optimization sets for all particles; the relationship between number of experts, optimization steps, and wall-clock time remains unquantified.
- What evidence would resolve it: Runtime benchmarks across varying numbers of experts (2, 4, 8, 16) and model sizes, comparing evaluation counts and convergence speed against baseline methods.

### Open Question 3
- Question: What causes the performance degradation on specific individual tasks despite improved average performance?
- Basis in paper: Table 1 shows PSO-Merging achieves 68.17 on CoLA versus Task Arithmetic's 69.13, and Table 2 shows MBPP scores dropping from 42.40 (Task Arithmetic) to 41.20 (PSO-Merging) for Mistral-7B-v0.3, even while average scores improve.
- Why unresolved: The paper optimizes for average multitask fitness but does not analyze why certain tasks regress or whether task-specific conflicts persist in the merged solution.
- What evidence would resolve it: Per-task ablation studies showing which expert parameters dominate the merged model, or analysis of parameter interference patterns across task pairs.

## Limitations
- The evaluation lacks comprehensive runtime analysis and computational overhead measurements compared to baseline methods
- Limited ablation studies on key design choices like population size, PSO parameters, and initialization strategies
- The comparison with gradient-based methods doesn't account for potential optimizations or hardware-specific advantages
- The method's scalability beyond four expert models remains unverified

## Confidence
**High confidence in:** The technical feasibility of using PSO for model merging and the basic experimental setup methodology.

**Medium confidence in:** Claims about computational efficiency gains relative to gradient-based methods, as the paper doesn't provide comprehensive runtime comparisons across different hardware configurations.

**Low confidence in:** The generality of sparsification as a solution for parameter conflicts across diverse model architectures, given limited ablation studies.

## Next Checks
1. Conduct runtime efficiency benchmarks comparing PSO-Merging against gradient-based methods across multiple hardware configurations, measuring both wall-clock time and computational resource usage during the merging process.

2. Perform systematic ablation studies varying PSO hyperparameters (population size, learning rates, inertia weight) to quantify their impact on convergence speed and final model performance.

3. Test the approach's scalability by attempting to merge more than four expert models, documenting how performance and computational requirements scale with increasing model count.