---
ver: rpa2
title: Privacy-Preserving Fair Synthetic Tabular Data
arxiv_id: '2503.02968'
source_url: https://arxiv.org/abs/2503.02968
tags:
- data
- privacy
- synthetic
- fairness
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating synthetic tabular
  data that preserves both privacy and fairness while maintaining utility. The proposed
  model, PF-WGAN, is a privacy-preserving and fair synthetic tabular data generator
  based on the WGAN-GP model.
---

# Privacy-Preserving Fair Synthetic Tabular Data

## Quick Facts
- **arXiv ID:** 2503.02968
- **Source URL:** https://arxiv.org/abs/2503.02968
- **Reference count:** 40
- **One-line primary result:** PF-WGAN generates synthetic tabular data that balances utility, privacy, and fairness better than state-of-the-art models

## Executive Summary
This paper proposes PF-WGAN, a model for generating synthetic tabular data that simultaneously preserves privacy and fairness while maintaining utility. The approach modifies the WGAN-GP architecture by incorporating identifiability-based privacy constraints and demographic parity fairness constraints directly into the loss function. The model outperforms existing synthetic data generators on three of four tested datasets in terms of fairness, while providing better privacy protection than WGAN and TabFairGAN, though it is less protective than the privacy-focused ADS-GAN.

## Method Summary
PF-WGAN extends WGAN-GP by adding privacy and fairness loss components to the generator's objective. The privacy loss measures distance between generated and real samples to reduce re-identification risk, while the fairness loss enforces demographic parity between sensitive groups. The model uses a warm-start training approach, initially training with only the WGAN-GP loss before activating privacy and fairness constraints. Inputs undergo quantile transformation for numerical features and one-hot encoding for categorical features. The generator employs Gumbel-Softmax for categorical outputs, and the critic uses linear layers with LeakyReLU activation.

## Key Results
- PF-WGAN achieves better fairness performance than competing models on three of four datasets
- The model provides improved privacy protection compared to WGAN and TabFairGAN
- PF-WGAN demonstrates a more balanced trade-off between utility, privacy, and fairness than state-of-the-art approaches

## Why This Works (Mechanism)

### Mechanism 1: Distance-Based Privacy Regularization
The model reduces re-identification risk by penalizing the generator for producing samples too close to real data points. An identifiability loss term calculates weighted distance between generated and real samples, forcing the generator to increase separation while maintaining distribution fidelity.

### Mechanism 2: Demographic Parity Enforcement
The model enforces fairness by penalizing the generator when positive outcome probabilities differ between sensitive groups. A fairness loss term calculates the difference in outcome rates between privileged and unprivileged groups, requiring the generator to equalize these rates.

### Mechanism 3: Deferred Constraint Activation (Warm-Start)
The model preserves utility by delaying privacy and fairness constraint application until after initial distribution learning. Training begins with standard WGAN-GP loss, with privacy and fairness losses activated only after a warm-up period, allowing the generator to first capture data distribution characteristics.

## Foundational Learning

- **Wasserstein GAN with Gradient Penalty (WGAN-GP)**: Serves as the base architecture providing stable training environment; differs from standard GANs by using Wasserstein distance and gradient penalty for Lipschitz continuity enforcement.
- **Identifiability Score**: Distance-based privacy metric measuring re-identification risk as proximity between synthetic and real records; differs from differential privacy which adds noise for theoretical guarantees.
- **Demographic Parity (Statistical Parity)**: Mathematical fairness definition requiring positive outcome probability independence from sensitive attributes; focuses on rate equality rather than outcome count equality.

## Architecture Onboarding

- **Component map**: Generator (G) -> Critic (C) -> Loss Aggregator -> Generator
- **Critical path**: Data Prep (Quantile + One-hot) → Warm-up Phase (WGAN-GP only) → Constrained Phase (Add Privacy/Fairness losses) → Evaluation (Identifiability, Accuracy/F1, Demographic Parity)
- **Design tradeoffs**: Chose identifiability over differential privacy to preserve utility despite lacking formal guarantees; uses single generator/critic pair to reduce complexity versus multi-network approaches
- **Failure signatures**: NaN loss from division-by-zero in fairness calculation; utility collapse from excessive privacy weight; categorical mode collapse from unstable softmax
- **First 3 experiments**: 1) Baseline WGAN-GP reproduction on Adult dataset, 2) Loss ablation (privacy-only, fairness-only) to isolate impacts, 3) Hyperparameter sweep of λ_p and λ_f to map Pareto frontier

## Open Questions the Paper Calls Out

- **Open Question 1**: Can PF-WGAN withstand specific adversarial attacks like membership inference, attribute inference, and linkage attacks? The authors note lack of attack-based evaluation methods.
- **Open Question 2**: How can the model be adapted to support multiple sensitive attributes and alternative fairness definitions like equalized odds? Current implementation handles only single sensitive attributes with demographic parity.
- **Open Question 3**: Can differential privacy be integrated into PF-WGAN to provide formal guarantees while mitigating utility degradation? Authors identify this as valuable future direction despite potential trade-offs.

## Limitations

- Privacy assessment relies solely on distance-based identifiability scores rather than active adversarial simulations
- Fairness implementation restricted to narrow demographic parity definition, not accounting for alternative fairness notions
- Limited architectural details provided for critical hyperparameters and network configurations

## Confidence

- **High Confidence**: Core mechanism of combining WGAN-GP with explicit privacy and fairness loss terms is well-defined and technically sound
- **Medium Confidence**: Performance improvements over baselines are plausible but depend on unreported hyperparameters
- **Low Confidence**: Privacy comparison claims based on identifiability metric alone may not capture full spectrum of privacy risks

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary privacy and fairness weights to map trade-off frontier and test robustness of claimed balanced performance
2. **Robustness to Data Distribution**: Evaluate on datasets with varying class imbalance and correlation structures to test fairness and privacy guarantees across scenarios
3. **Comparison Against Alternative Fairness Metrics**: Assess using metrics beyond demographic parity (equalized odds, counterfactual fairness) to determine generalizability of performance