---
ver: rpa2
title: State-Inference-Based Prompting for Natural Language Trading with Game NPCs
arxiv_id: '2507.07203'
source_url: https://arxiv.org/abs/2507.07203
tags:
- uni00000013
- state
- price
- dialogue
- trading
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: State-Inference-Based Prompting (SIBP) enables reliable natural
  language trading with game NPCs by autonomously inferring dialogue states and enforcing
  context-specific rules. The methodology decomposes trading into six states and implements
  context-aware item referencing and placeholder-based price calculations within a
  unified prompt framework.
---

# State-Inference-Based Prompting for Natural Language Trading with Game NPCs

## Quick Facts
- **arXiv ID:** 2507.07203
- **Source URL:** https://arxiv.org/abs/2507.07203
- **Reference count:** 36
- **Primary result:** SIBP achieves >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision for natural language trading with game NPCs.

## Executive Summary
State-Inference-Based Prompting (SIBP) addresses the challenge of enabling reliable natural language trading interactions with game NPCs using large language models. The method decomposes trading into six discrete states and employs explicit state inference, context-aware data referencing, and deferred computation via placeholders. By enforcing procedural rules and restricting data access based on dialogue state, SIBP prevents common LLM failures like item hallucinations and calculation errors. Evaluation across 100 trading dialogues demonstrates high compliance rates while maintaining computational efficiency compared to alternative reasoning approaches.

## Method Summary
SIBP constructs a unified prompt incorporating system instructions, game item lists, character inventory, and dialogue history. The approach uses four key elements: basic state definitions, state transition conditions, directives to identify the previous state, and directives to respond including the previous state. During trading states, the NPC references only sellable inventory items, while calculations are deferred by generating placeholders replaced by deterministic post-processing. This framework ensures procedural compliance and eliminates LLM arithmetic errors through systematic separation of generation and computation.

## Key Results
- Achieves 99.7% calculation precision by offloading math to deterministic post-processing
- Maintains >97% state transition compliance across 100 trading dialogues
- Demonstrates >95% sellable item response rate, preventing inventory hallucinations

## Why This Works (Mechanism)

### Mechanism 1: State Transition Enforcement via Explicit Context Tracing
Forcing the LLM to explicitly identify and output the previous dialogue state before generating a new response achieves higher procedural compliance than relying on implicit context understanding. The prompt requires a `last_trade_context` field in the output JSON, acting as a forced re-read of history to ensure the model acknowledges mandatory sequences like `OFFER_SELL → CHECK_CONFIRMATION → CONFIRM_SELL` before generating new tokens. This works if the LLM has sufficient context window and instruction-following capability to reliably parse the provided history.

### Mechanism 2: Context-Specific Data Referencing (Dual-Inventory)
Conditioning access to specific datasets based on inferred dialogue state reduces item hallucinations. The prompt separates `<GAME_ITEMS_LIST>` (world knowledge) from `<CHARACTER_INVENTORY>` (transactional data), restricting the model to only reference inventory items with quantity > 0 during trading states. This constrains the token generation probability space to valid assets only, assuming the LLM can strictly follow negative constraints without mixing semantic knowledge from the broader game list.

### Mechanism 3: Deferred Computation via Placeholder Post-processing
Generating a placeholder token instead of a calculated number, with deterministic system post-processing, achieves near-perfect calculation accuracy regardless of LLM arithmetic capability. In the `OFFER_SELL` state, the prompt instructs output of `__PRICE__` instead of a sum, which the system then calculates and replaces. This bypasses the LLM's probabilistic weakness in multi-step arithmetic, assuming the model reliably outputs the specific placeholder string exactly as defined.

## Foundational Learning

- **Concept: Finite State Machines (FSM) in Dialogue Management**
  - *Why needed here:* SIBP maps unstructured natural language to a structured graph of states. Understanding FSMs is required to debug why the model might transition incorrectly (e.g., skipping `CHECK_CONFIRMATION`).
  - *Quick check question:* "Why does SIBP define `CHECK_CONFIRMATION` as a mandatory node rather than allowing a direct transition from `OFFER_SELL` to `CONFIRM_SELL`?"

- **Concept: Context Window & Attention Mechanisms**
  - *Why needed here:* The system relies on the LLM "attending" to the `DIALOGUE_HISTORY` to infer the previous state. If the history is truncated or attention diffuses, state inference fails.
  - *Quick check question:* "What happens to the 'Directive to Identify Previous State' if the relevant turn falls out of the context window?"

- **Concept: Deterministic Post-processing vs. Generative Output**
  - *Why needed here:* The high precision (99.7%) is achieved not by the LLM, but by the external system handling the math. One must distinguish between what the LLM *generates* (text) and what the system *enforces* (logic).
  - *Quick check question:* "Why is the `__PRICE__` mechanism superior to asking the LLM to 'think step-by-step' for calculation?"

## Architecture Onboarding

- **Component map:** Prompt Constructor → LLM Inference Engine → State Validator & Post-Processor
- **Critical path:** User Input → Prompt Constructor (Inject History & Inventory) → LLM (Infer State + Generate JSON) → Post-Processor (Math Check + Placeholder Replacement) → Game State Update
- **Design tradeoffs:**
  - **Strictness vs. Fluidity:** The strict 6-state decomposition ensures safety but may make the NPC feel robotic if transition rules are too rigid.
  - **Latency vs. Accuracy:** The `SIBP+PPP` approach avoids high latency of Chain-of-Thought reasoning by offloading logic, but requires maintaining a parsing layer.
- **Failure signatures:**
  - **State Drift:** Model outputs `SHOW_INVENTORY` despite user agreeing to buy, often due to weak "Directive to Identify Previous State."
  - **Inventory Hallucination:** NPC offers items not in `CHARACTER_INVENTORY`, indicating failure in state-specific data referencing.
  - **Placeholder Corruption:** Output contains `__PRICE__` in final text, meaning post-processor failed to match and replace the token.
- **First 3 experiments:**
  1. **Compliance Ablation:** Run 50 dialogues with Element 4 disabled to verify the predicted drop in State Transition Compliance Rate.
  2. **Math Stress Test:** Force a scenario with 5+ items in cart. Compare `SIBP` vs. `SIBP+PPP` failure rates to validate the 99.7% precision claim.
  3. **Inventory Boundary Test:** Ask for a "sellable" item while in `NONE` state to see if model incorrectly triggers `TRADE` logic or leaks inventory data.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does SIBP performance degrade when item inventories expand significantly to approach or exceed the LLM's context window limits?
  - *Basis:* Authors state future work must "rigorously evaluate the scalability... across... substantially larger item inventories."
  - *Why unresolved:* Current evaluation used limited inventory (52 items), methodology relies on injecting full inventory list into prompt context.
  - *What evidence would resolve it:* Results showing state compliance and referencing accuracy rates as inventory scales from hundreds to thousands of items.

- **Open Question 2:** Can SIBP maintain high state compliance (>97%) when deployed on small language models (SLMs) suitable for resource-constrained environments?
  - *Basis:* Section 5.2 explicitly identifies need to explore "effectiveness with smaller language models (SLMs)" to reduce latency and cost.
  - *Why unresolved:* Primary experiments utilized Gemini 2.5-flash and pro models; while one test with 2.0-flash showed promise, consistent adherence on smaller, cheaper models is not yet verified.
  - *What evidence would resolve it:* Comparative benchmark of SIBP's state transition compliance rate running on models with parameter counts under 7B.

- **Open Question 3:** Does the SIBP framework extend effectively to "player selling" scenarios without requiring architectural changes to state transition logic?
  - *Basis:* Section 3.2.1 explicitly defines scope as "focusing on player buying from an NPC," with five specific sub-states for this flow.
  - *Why unresolved:* Current state definitions are oriented around NPC offloading goods; it's unclear if prompt design can handle inversion of asset ownership logic without redefining core state machine.
  - *What evidence would resolve it:* Experiment applying identical SIBP prompt structure to scenario where player attempts to sell loot to NPC, measuring rule adherence and pricing accuracy.

## Limitations

- Evaluation confined to specific model (gemini-2.5-flash-preview-04-17) and synthetic dataset of 52 game items, with unknown robustness to model variations and scalability to larger item catalogs.
- Placeholder mechanism assumes deterministic post-processing without token collisions; accidental generation of similar tokens could break calculation flow.
- State enforcement designed for fixed 6-state FSM, but real-world dialogues may involve emergent states (lore questions, combat interruptions) not explicitly handled.

## Confidence

- **High Confidence (>95%):** 99.7% calculation precision using placeholder mechanism - deterministic and verifiable.
- **Medium Confidence (75-95%):** >97% state compliance and >95% referencing accuracy - depend on model's instruction-following capability.
- **Low Confidence (<75%):** "Computationally efficient" claim - latency comparison only shown for one model, commercial context requirements not addressed.

## Next Checks

1. **Model Generalization Test:** Reproduce experiment using different LLM (e.g., GPT-4, Llama-3) with same SIBP prompt to verify gains are not model-specific.

2. **Scalability Stress Test:** Increase `CHARACTER_INVENTORY` from 20 to 200 items and rerun dialogues to track if "Directive to Identify Previous State" remains effective when context history grows.

3. **Real-World Integration Test:** Deploy SIBP NPC in commercial game with live players to record frequency of failure signatures in actual use, revealing whether synthetic evaluation overestimates real-world reliability.