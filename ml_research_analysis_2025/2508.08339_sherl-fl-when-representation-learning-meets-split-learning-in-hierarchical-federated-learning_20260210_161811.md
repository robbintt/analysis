---
ver: rpa2
title: 'SHeRL-FL: When Representation Learning Meets Split Learning in Hierarchical
  Federated Learning'
arxiv_id: '2508.08339'
source_url: https://arxiv.org/abs/2508.08339
tags:
- learning
- edge
- hsfl
- data
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SHeRL-FL, a federated learning framework
  that integrates split learning and representation learning within a hierarchical
  structure. By splitting the model functionally across client, edge, and cloud tiers,
  and adding contrastive learning at edge servers, the approach reduces communication
  overhead and improves representation alignment.
---

# SHeRL-FL: When Representation Learning Meets Split Learning in Hierarchical Federated Learning

## Quick Facts
- arXiv ID: 2508.08339
- Source URL: https://arxiv.org/abs/2508.08339
- Authors: Dung T. Tran; Nguyen B. Ha; Van-Dinh Nguyen; Kok-Seng Wong
- Reference count: 8
- One-line result: Achieves >90% reduction in data transmission compared to centralized FL and HierFL while maintaining competitive accuracy

## Executive Summary
This paper introduces SHeRL-FL, a federated learning framework that integrates split learning and representation learning within a hierarchical structure. By splitting the model functionally across client, edge, and cloud tiers, and adding contrastive learning at edge servers, the approach reduces communication overhead and improves representation alignment. The method avoids transmitting cloud-to-edge gradients, enhancing privacy and scalability. Experiments on CIFAR-10, CIFAR-100, HAM10000, and ISIC-2018 demonstrate that SHeRL-FL achieves over 90% reduction in data transmission compared to centralized FL and HierFL, and over 50% compared to SplitFed, while maintaining competitive or better accuracy. Memory usage per client remains low and stable. Ablation studies confirm that both role-aware splitting and contrastive loss are critical for these gains, especially under non-IID data conditions. The framework offers a practical, communication-efficient solution for large-scale federated learning in resource-constrained and privacy-sensitive environments.

## Method Summary
SHeRL-FL partitions a neural network into three functional segments: shallow layers on resource-constrained clients, intermediate layers on edge servers, and the final classification head on the cloud. Clients send smashed data (intermediate activations) and labels to edge servers, which compute a supervised contrastive loss to align representations locally. Gradients flow back from the edge to clients, enabling updates without cloud interaction. The cloud aggregates edge models periodically using task loss, while edges aggregate client models at intermediate intervals. This decoupling eliminates cloud-to-edge gradient transmission, reducing communication overhead and privacy risks. The framework uses Adam optimizer with learning rate 1e-4, 200 communication rounds, and 10% client sampling rate across 200 clients and 10 edge servers.

## Key Results
- Reduces data transmission by over 90% compared to centralized FL and HierFL, and over 50% compared to SplitFed
- Maintains competitive accuracy on CIFAR-10, CIFAR-100, HAM10000, and ISIC-2018 datasets
- Achieves low and stable memory usage per client (~380MB)
- Ablation confirms role-aware splitting and contrastive loss are critical for performance gains

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Local Supervision via Contrastive Learning
Applying contrastive loss at the edge server enables local gradient updates for clients without requiring backward passes from the cloud, significantly reducing communication overhead. Clients send smashed data (intermediate activations) and labels to edge servers. The edge computes a margin-based contrastive loss that maximizes inter-class distance and minimizes intra-class distance. Gradients are backpropagated from the edge to the clients immediately, allowing the client-side model to update based on local representation alignment rather than a global task loss. The core assumption is that intermediate features contain sufficient semantic information to permit meaningful class separation at the edge layer without access to the final classification head.

### Mechanism 2: Role-Aware Functional Splitting
Partitioning the network based on semantic functional roles (e.g., textures vs. high-level concepts) rather than just device memory constraints stabilizes hierarchical aggregation. The framework assigns shallow layers (low-level features) to resource-constrained clients and deeper layers (high-level representations) to edge servers. This "role-aware" alignment ensures that the smashed data exchanged between tiers is semantically consistent, reducing variance during edge aggregation. The core assumption is that there exists a specific cut point in the backbone architecture that optimally balances computational load reduction with the preservation of feature hierarchy.

### Mechanism 3: Privacy via Gradient Isolation
Eliminating cloud-to-edge gradient transmission mitigates specific privacy risks (e.g., gradient inversion attacks) and bandwidth bottlenecks. The cloud server calculates the task loss but does not return gradients to the edge. Instead, it only aggregates model weights periodically. The edge acts as the "supervisor" for the client, breaking the end-to-end gradient chain from cloud to client. The core assumption is that global model convergence can be maintained through weight aggregation alone, even though the lower tiers never receive direct error signals from the final task loss computed at the cloud.

## Foundational Learning

- **Concept: Split Learning (SL) & Smashed Data**
  - **Why needed here:** SHeRL-FL builds on SL. You must understand that clients do not send raw images; they send "smashed data" (activations from a cut layer) to offload computation.
  - **Quick check question:** Can you identify which layer in ResNet-18 would serve as a "smashed data" output for transmission?

- **Concept: Supervised Contrastive Learning (SupCon)**
  - **Why needed here:** This is the engine of the SHeRL-FL edge server. Unlike standard loss which penalizes wrong classes, contrastive loss actively structures the feature space by pulling same-class samples together.
  - **Quick check question:** In Equation 1, what happens to the loss if two samples are from the same class ($y_{ij}=0$) but have a large cosine distance?

- **Concept: Non-IID Data Distribution**
  - **Why needed here:** The paper claims specific gains in Non-IID settings (where clients have biased data distributions). Understanding how local contrastive loss handles class imbalance is key to interpreting the results.
  - **Quick check question:** If Client A has only cats and Client B has only dogs, why might standard FedAvg fail while a hierarchical contrastive approach might succeed?

## Architecture Onboarding

- **Component map:** Client (shallow layers) -> Edge Server (mid-layers + contrastive loss) -> Cloud Server (task head)
- **Critical path:** Client forwards smashed data and labels to edge, edge computes contrastive loss and backpropagates to client, edge aggregates client weights every $t_1$ rounds, edge forwards detached features to cloud, cloud computes task loss and aggregates edge weights every $t_2$ rounds
- **Design tradeoffs:**
  - Sync intervals ($t_1, t_2$): Longer intervals reduce communication but risk "client drift" where local models diverge
  - Margin ($m$): Table 5 suggests $m=0.5$ is optimal; larger margins over-penalize, smaller margins fail to separate classes
- **Failure signatures:**
  - Accuracy Plateau: If the split point is too early, smashed data lacks semantic info and contrastive loss fails to correlate with the task
  - Divergence: In extreme Non-IID cases, if $t_1$ is too large, local contrastive objectives may create clusters inconsistent with global task structure
- **First 3 experiments:**
  1. Baseline Integrity: Run the split architecture without contrastive loss to isolate the gain strictly from the representation learning objective
  2. Hyperparameter Sweep ($m$): Validate the margin $m$ on a held-out validation set at the Edge server to prevent under-clustering or over-clustering
  3. Ablation on Split Point: Move the cut layer deeper/shallower to verify the "Role-Aware" claimâ€”does the semantic alignment actually matter, or is any split sufficient?

## Open Questions the Paper Calls Out

### Open Question 1
Can an adaptive partitioning strategy outperform the fixed, heuristic role-aware splitting used in SHeRL-FL under varying system constraints? The authors state that "The current role-aware split is fixed and heuristic; adaptive partitioning could improve efficiency in varied environments." This remains unresolved because the current implementation relies on a static architecture where model segments are pre-defined based on functional roles rather than dynamically adjusted. Evidence would come from evaluating SHeRL-FL with a dynamic splitting algorithm against the static baseline across heterogeneous environments with fluctuating bandwidth and device capabilities.

### Open Question 2
Can self-supervised learning objectives effectively replace the current supervised contrastive loss to remove the dependency on labeled data at the edge? The paper notes that "Contrastive learning assumes labeled edge data, which may limit applicability; self-supervised alternatives are a potential extension." This remains unresolved because the current framework calculates contrastive loss using class labels to determine sample similarity, necessitating ground truth availability at the edge server. Evidence would come from experimental results comparing the performance of SHeRL-FL using self-supervised methods (e.g., SimCLR) against the current supervised approach on unlabeled datasets.

### Open Question 3
How does real-world network latency affect the actual time-to-accuracy and deployment efficiency of SHeRL-FL compared to theoretical communication savings? The authors acknowledge that "real network latency tests would further strengthen deployment practicality" despite the reduction in communication volume. This remains unresolved because the experiments simulate communication costs based on data volume and do not measure wall-clock time involving network delays, jitter, or packet loss. Evidence would come from deployment of the framework on a physical testbed measuring convergence time and latency under real network conditions.

## Limitations

- Exact layer indices for role-aware splitting are not specified, requiring empirical tuning that may affect reproducibility
- Non-IID data partitioning strategy (Dirichlet concentration parameter) remains unspecified
- Edge server memory requirements for contrastive loss computation are unstated despite client RAM being quantified

## Confidence

- **High:** Communication overhead reduction claims (>90% vs. centralized FL) - directly supported by Table 1 metrics
- **Medium:** Privacy benefits from gradient isolation - theoretical reduction of attack surface but no empirical gradient inversion tests shown
- **Low:** Role-aware splitting advantage - ablation shows improvement but does not isolate whether this is truly functional or simply architectural

## Next Checks

1. **Layer Cut Sensitivity:** Systematically vary the split point between client/edge tiers across multiple datasets to quantify the impact on accuracy vs. communication trade-off
2. **Gradient Drift Analysis:** Monitor feature representation alignment between edge and cloud tiers throughout training to empirically validate that contrastive loss prevents drift without end-to-end gradients
3. **Memory Scaling Study:** Profile edge server memory usage under different batch sizes and pair sampling strategies for contrastive loss to establish practical deployment limits