---
ver: rpa2
title: Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics
  from Open Web Data
arxiv_id: '2601.12856'
source_url: https://arxiv.org/abs/2601.12856
tags:
- dengue
- hotspot
- singapore
- transmission
- mobility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a framework to uncover hidden transmission
  links between urban regions by modeling how dengue hotspot formation in one area
  is influenced by epidemic dynamics in neighboring regions. The method uses gradient
  descent to learn spatiotemporal parameters from publicly available dengue case data,
  enabling one-week-ahead hotspot forecasting with an average F-score of 0.79 (up
  to 0.83 during COVID-19 disruptions).
---

# Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data

## Quick Facts
- arXiv ID: 2601.12856
- Source URL: https://arxiv.org/abs/2601.12856
- Reference count: 37
- One-line primary result: Achieved 0.79 F-score for one-week-ahead dengue hotspot forecasting in Singapore using open web data, with learned transmission network aligning with commuting flows.

## Executive Summary
This study introduces a framework to uncover hidden transmission links between urban regions by modeling how dengue hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. The method uses gradient descent to learn spatiotemporal parameters from publicly available dengue case data, enabling one-week-ahead hotspot forecasting with an average F-score of 0.79 (up to 0.83 during COVID-19 disruptions). The learned transmission network aligns closely with commuting flows, revealing the interpretable role of human mobility in citywide dengue spread. This scalable, low-cost approach transforms open web-based case data into a predictive and explanatory resource for public health planning and early intervention.

## Method Summary
The framework converts weekly dengue case counts into binary hotspot states (c=3 cases) and uses gradient descent to learn a spatial transmission matrix P and temporal weights w from four weeks of historical hotspot data. The objective function combines mean squared error with L1/L2 regularization to ensure sparsity and stability. The model forecasts next-week hotspots by applying the learned parameters to current hotspot data, with results validated against ground truth. SSIM analysis confirms the learned network structure remains stable across weeks.

## Key Results
- Achieved average F-score of 0.79 for one-week-ahead hotspot forecasting (up to 0.83 during COVID-19 disruptions)
- Learned transmission network shows high similarity to actual commuting flows in Singapore
- Model stability confirmed with SSIM ≈ 0.96 across consecutive weeks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Modeling hotspot formation as a weighted combination of historical spatial states allows for one-week-ahead forecasting using only open case data.
- **Mechanism:** The framework represents the current hotspot status y as a function of the previous H weeks of hotspot data (Y^H) transformed by a learnable spatial matrix (P) and temporal weights (w). By minimizing the error between observed and estimated hotspots via gradient descent, the system learns the specific influence strength between regions.
- **Core assumption:** Four weeks of history (H=4) is sufficient to capture relevant epidemic dynamics and that latent spatial dependencies remain relatively stable week-to-week.
- **Evidence anchors:** Abstract states "four weeks of hotspot history are sufficient to achieve an average F-score of 0.79." Section 3.3 describes utilizing latent associations in hotspot dynamics for forecasting.

### Mechanism 2
- **Claim:** Latent transmission links inferred solely from case data correlate with physical human mobility patterns, suggesting the model captures human-mediated spread.
- **Mechanism:** The model learns a transmission matrix P without mobility inputs. When compared against ground-truth commuting flows (G_M), the learned matrix (G_L) shows high spatial similarity, implying gradient descent successfully attributes case emergence to importation from connected regions.
- **Core assumption:** Long-distance dengue transmission is primarily driven by human movement rather than mosquito flight, and this signal is distinct enough to be mined from case counts alone.
- **Evidence anchors:** Abstract states "the learned network aligns closely with commuting flows, revealing the interpretable role of human mobility." Section 4.4 compares spreading network with commuting flows showing significant similarities.

### Mechanism 3
- **Claim:** Regularization ensures the learned transmission network is sparse and stable, preventing overfitting to noisy weekly case fluctuations.
- **Mechanism:** The loss function includes L1 and L2 norms (λ₁, λ₂). L1 forces the spatial matrix P to be sparse (setting weak links to zero), enhancing interpretability. Stability is verified by SSIM of P across weeks being ≈ 0.96.
- **Core assumption:** The underlying transmission network changes slowly relative to the weekly case reports.
- **Evidence anchors:** Section 3.4 describes L1 norm regularization for sparse matrix acquisition. Section 4.3 shows SSIM values approximate to 0.96, indicating matrix P^t is quite stable.

## Foundational Learning

- **Concept:** **Sparse Regularization (L1 Norm)**
  - **Why needed here:** To force the model to identify a few key "source" regions driving spread rather than assigning small credit to every neighbor, making the transmission map interpretable.
  - **Quick check question:** If you remove the L1 penalty, would the resulting transmission matrix likely be dense (all regions affecting all regions) or sparse?

- **Concept:** **Structural Similarity Index (SSIM)**
  - **Why needed here:** The paper uses SSIM to prove that the learned spatial parameters (P) are not just random weekly artifacts but represent a consistent underlying structure.
  - **Quick check question:** Why is SSIM a better metric for comparing the learned matrices of two weeks than simple Mean Squared Error (MSE)?

- **Concept:** **Hotspot Thresholding**
  - **Why needed here:** The model converts raw case counts into binary states (Hotspot vs. Non-Hotspot) based on a count c (e.g., ≥3 cases). This defines the target variable for the gradient descent.
  - **Quick check question:** If the threshold c is set too low (e.g., 1 case) in a dense city, what happens to the specificity of the "Hotspot" definition?

## Architecture Onboarding

- **Component map:** CSV data (Address → Lat/Long → Subzone mapping) → Preprocessing (Aggregation + Hotspot labeling) → Learning Core (Gradient Descent optimizing P and w) → Output Layer (One-week forecast + Network Graph) → Validation Module (SSIM calculator + Correlation Analysis)

- **Critical path:** The Spatiotemporal Pattern Learning (Section 3.4). If the learning rate or regularization hyperparameters (λ₁, λ₂) are misconfigured, the matrix P will either fail to converge or overfit, rendering both forecasts and network interpretation useless.

- **Design tradeoffs:**
  - **Simplicity vs. Granularity:** The model uses only open web data (addresses/dates) rather than rich, private mobile data. This increases scalability/scarcity but may miss finer mobility nuances.
  - **Binary Classification:** Defining hotspots as binary (0/1) simplifies the problem to classification but discards the magnitude of outbreak severity (e.g., 3 cases vs. 30 cases are both "1").

- **Failure signatures:**
  - **Oscillating SSIM:** If P^t changes drastically every week (low SSIM), the model is chasing noise rather than structure.
  - **Majority Class Collapse:** If Precision drops significantly, the model is likely flagging too many areas as hotspots; check if the threshold μ_x + σ_x in Eq. 2 is appropriate for the current case volume.

- **First 3 experiments:**
  1. **Baseline Replication:** Run the model on the 2013-2018 dataset with H=4; verify if F-score ≈ 0.79 is reproducible.
  2. **Hyperparameter Sensitivity:** Ablate λ₁ and λ₂ to observe the shift in network sparsity (how many links in P are non-zero).
  3. **Disruption Test:** Train on pre-2020 data and test specifically on the "Circuit Breaker" period (April-June 2020) to measure performance drop and recovery time.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the framework maintain high forecasting performance when applied to other dengue-endemic cities with different urban structures or lower data quality?
- **Basis in paper:** The authors state in the Discussion that "The proposed model hence may be applied to other urban areas with appropriate adjustments," but the study is restricted to Singapore.
- **Why unresolved:** The model is validated solely on Singapore's specific urban planning zones (subzones) and high-quality open web data; it is unknown if the method is robust to the coarser spatial units or reporting delays common in other regions.
- **What evidence would resolve it:** Successful replication of the hotspot forecasting and network learning in a distinct urban environment (e.g., a city in Latin America or another part of Southeast Asia) with varying data granularity.

### Open Question 2
- **Question:** How do extreme mobility disruptions, such as the COVID-19 "circuit breaker," alter the stability and structure of the learned transmission network P^t?
- **Basis in paper:** The Discussion notes that "Revealing how the CB measurements impact the dengue spreading is pivotal," acknowledging that the 2020 outbreak coincided with lockdowns.
- **Why unresolved:** While the paper shows the model remained predictive (F-score 0.83), it lacks the real-time 2020 mobility data necessary to compare the *learned* transmission network against the *actual* disrupted human movement patterns.
- **What evidence would resolve it:** A comparative analysis using real-time mobility datasets from 2020 to quantify the deviation between the learned transmission links and actual commuting flows during the lockdown.

### Open Question 3
- **Question:** Does the intentional exclusion of explicit ecological variables (e.g., rainfall, temperature) limit the model's ability to generalize to climates with distinct seasonality?
- **Basis in paper:** The Methodology explicitly states the choice to "intentionally omit explicit ecological factors," arguing they are implicitly captured by recent hotspot history in Singapore's year-round tropical climate.
- **Why unresolved:** In seasonal climates, mosquito viability is not constant; relying solely on past case data may fail to predict outbreaks triggered by environmental changes that do not immediately reflect in prior hotspot history.
- **What evidence would resolve it:** Ablation studies in seasonal environments comparing the current model's performance against versions that include explicit meteorological covariates.

## Limitations
- Learning rate and exact convergence criteria for gradient descent are unspecified, potentially affecting reproducibility
- No explicit handling of missing/incomplete weekly data snapshots is described
- Model performance during acute, non-stationary disruptions beyond the COVID-19 example is not characterized

## Confidence
- **High Confidence:** The framework's core mechanism of using historical hotspot states and gradient descent to learn spatial-temporal parameters is clearly described and reproducible
- **Medium Confidence:** The alignment of the learned transmission network with commuting flows is supported by visual comparison, but lacks rigorous statistical validation
- **Medium Confidence:** The stability of the learned matrix (SSIM ≈ 0.96) is claimed but relies on internal validation without external comparison

## Next Checks
1. **Baseline Replication:** Re-run the model on the 2013-2018 dataset with H=4; verify if F-score ≈ 0.79 is reproducible
2. **Hyperparameter Sensitivity:** Ablate λ₁ and λ₂ to observe the shift in network sparsity (how many links in P are non-zero)
3. **Disruption Test:** Train on pre-2020 data and test specifically on the "Circuit Breaker" period (April-June 2020) to measure performance drop and recovery time