---
ver: rpa2
title: 'Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty
  Markers to Implicit Reasoning Pathways'
arxiv_id: '2511.04506'
source_url: https://arxiv.org/abs/2511.04506
tags:
- finding
- uncertainty
- phrases
- each
- findings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work quantifies explicit and implicit uncertainty in radiology
  reports by introducing a two-part framework: an LLM-based system that assigns continuous
  probability values to findings with hedging phrases, and a pathway expansion approach
  that reconstructs omitted diagnostic sub-findings from expert-defined diagnostic
  pathways for 14 common chest X-ray conditions. Applying these methods to the Lunguage
  dataset of 1,473 structured chest X-ray reports produces Lunguage++, which adds
  continuous uncertainty measures and 4,761 inferred sub-findings to 2,639 original
  findings, enabling more faithful representation of radiological reasoning and supporting
  uncertainty-aware AI development.'
---

# Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways

## Quick Facts
- arXiv ID: 2511.04506
- Source URL: https://arxiv.org/abs/2511.04506
- Reference count: 0
- Primary result: Quantifies explicit and implicit uncertainty in radiology reports using LLM-based probability mapping and diagnostic pathway expansion

## Executive Summary
This work introduces Lunguage++, an enhanced version of the Lunguage chest X-ray report dataset that captures both explicit and implicit clinical uncertainty. The framework quantifies uncertainty by mapping hedging phrases to continuous probability values using an LLM-based ranking system, and reconstructs omitted diagnostic sub-findings through expert-defined hierarchical pathways. Applied to 1,473 chest X-ray reports, the approach adds probability scores to 2,639 original findings and infers 4,761 additional sub-findings, creating a richer representation of radiological reasoning for uncertainty-aware AI development.

## Method Summary
The framework operates in two parallel modules: explicit uncertainty quantification and implicit reasoning expansion. For explicit uncertainty, hedging phrases are extracted and ranked using a TrueSkill algorithm that aggregates pairwise comparisons from four LLMs. These ranks are then calibrated to continuous probabilities using anchor points from radiologist input. For implicit uncertainty, expert-defined diagnostic pathways (DAGs) are used to match stated findings to diseases and recursively expand them to characteristic sub-findings, with uncertainty propagating down the hierarchy. The combined output creates Lunguage++, which preserves the original structured data while adding probabilistic measures and inferred findings.

## Key Results
- Expert agreement with reference ranking achieves Fleiss' κ=0.72
- Sigmoid calibration produces probability range p_bottom=0.170 to p_top=0.839
- 2,639 original findings expanded to 4,761 inferred sub-findings
- Conflict rate between original and inferred findings reduced from 3.2% to 0% via resolution rules

## Why This Works (Mechanism)

### Mechanism 1: LLM-Based Comparative Ranking for Hedging Phrases
The system leverages LLMs to perform pairwise comparisons between hedging phrases rather than asking for direct probability scores, which are noisy. Using TrueSkill algorithm, these comparisons aggregate into a stable global ranking where each phrase receives a "skill" score (μ) representing its relative certainty. This approach assumes LLMs possess sufficient latent knowledge of clinical linguistics to approximate expert preferences.

### Mechanism 2: Expert-Anchored Sigmoid Calibration
Raw TrueSkill scores (μ) are mapped to [0,1] probabilities using a sigmoid function p = 1/(1 + e^(-α(μ - μ_0))). The parameters α (steepness) and μ_0 (inflection point) are solved using two anchor points: radiologists manually assign probability ranges to the top-ranked phrase ("most likely") and bottom-ranked phrase ("less likely"), ensuring the final probabilities reflect clinical reality.

### Mechanism 3: Hierarchical Pathway Expansion (Implicit Inference)
Diagnostic reasoning is formalized as hierarchical DAGs where diseases imply sub-findings with high probability (>80%). The framework matches report findings to pathway roots and recursively expands them to leaf nodes, with uncertainty propagating downwards - if a diagnosis is tentative (p=0.6), inferred sub-findings inherit the same probability. This assumes radiological reasoning is compositional and deductive.

## Foundational Learning

- **Concept: Bayesian Rating Systems (e.g., TrueSkill)**
  - Why needed here: Aggregates noisy pairwise LLM comparisons into robust global ranking
  - Quick check question: How does the "uncertainty" (σ) in a TrueSkill score change as a phrase undergoes more comparisons?

- **Concept: Directed Acyclic Graphs (DAGs) in Knowledge Representation**
  - Why needed here: Formalizes diagnostic pathways used to expand implicit reasoning
  - Quick check question: Why is the "acyclic" property critical for ensuring the diagnostic expansion algorithm terminates?

- **Concept: Probability Calibration**
  - Why needed here: Translating relative ranks into absolute probabilities requires anchoring to known scale
  - Quick check question: If the sigmoid function were unanchored (no expert input), what would the resulting probability values represent?

## Architecture Onboarding

- **Component map:** Input Layer (Lunguage dataset) → Explicit Uncertainty Module (Vocabulary Extractor → Ranking Engine → Fitting Loop → Calibrator) → Implicit Uncertainty Module (Pathway Matcher → Recursive Expander → Conflict Resolver) → Output (Lunguage++)

- **Critical path:** The Explicit Uncertainty pipeline is computational bottleneck, requiring ~25 LLM calls per finding-sentence pair through iterative comparisons against reference ranking. Optimizing opponent selection strategy using "draw probability" is essential for cost management.

- **Design tradeoffs:** Using 4 LLMs for consensus provides robustness but costs $0.045/pair; single model cheaper but potentially less calibrated. Pathway expansion offers high recall for classic presentations but may hallucinate findings for atypical cases.

- **Failure signatures:** Ranking instability if finding-sentence pair oscillates without converging; conflict loops between expansions resolved by certainty priority; context bleeding when single probability applied to multi-finding sentences.

- **First 3 experiments:**
  1. Ablate LLM consensus by running reference ranking with single model vs ensemble, comparing against expert ground truth
  2. Test calibration sensitivity by varying anchor phrases to assess probability distribution shifts
  3. Stress test conflict resolution with synthetic reports containing known contradictions

## Open Questions the Paper Calls Out

- **Open Question 1:** Can visual grounding mechanisms reconcile conflicts between pathway-inferred findings and actual image evidence? The current framework relies on text-based logic without visual verification capabilities.

- **Open Question 2:** Does modeling non-uniform probabilistic propagation for sub-findings improve diagnostic accuracy? The current implementation assigns uniform probability to all child nodes, overlooking that some signs may be more definitive than others.

- **Open Question 3:** To what extent does continuous uncertainty quantification improve prediction of downstream clinical outcomes? While the resource is created, its value for predicting patient trajectories beyond standard binary labels remains unproven.

## Limitations

- Probability mapping depends heavily on two anchor phrases, which may be context-dependent and unrepresentative of full hedging vocabulary
- Pathway expansion assumes idealized hierarchical reasoning that may not hold for complex cases with comorbidities
- LLM reliability for subtle medical hedging distinctions remains a potential source of error despite ensemble approach

## Confidence

- Explicit uncertainty quantification: High confidence - framework produces continuous probabilities with strong expert validation (κ=0.72)
- Implicit reasoning pathway expansion: Medium confidence - mechanism sound but assumes idealized diagnostic reasoning
- Clinical utility: Medium confidence - dataset enhancement technically robust but real-world clinical impact unproven

## Next Checks

1. **Anchor phrase sensitivity analysis:** Test how probability distributions change when using different anchor phrases to assess calibration robustness
2. **Conflict resolution stress test:** Create synthetic reports with known contradictions to verify conflict resolution rules correctly prioritize explicit findings
3. **Cross-institutional validation:** Apply framework to chest X-ray reports from different institution to test generalizability beyond MIMIC-CXR dataset