---
ver: rpa2
title: 'Enhancing Explainability in Solar Energetic Particle Event Prediction: A Global
  Feature Mapping Approach'
arxiv_id: '2511.09475'
source_url: https://arxiv.org/abs/2511.09475
tags:
- events
- solar
- event
- data
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the interpretability challenge in solar energetic
  particle (SEP) event prediction by developing a global feature mapping approach.
  The proposed method integrates a sliding-window multivariate time series forest
  classifier (Slim-TSF) with global explainability techniques to provide transparent
  insights into model predictions.
---

# Enhancing Explainability in Solar Energetic Particle Event Prediction: A Global Feature Mapping Approach

## Quick Facts
- arXiv ID: 2511.09475
- Source URL: https://arxiv.org/abs/2511.09475
- Reference count: 40
- Primary result: The P3 proton flux channel (≥10 MeV) consistently demonstrates the highest relevance for SEP forecasting across bootstrap iterations

## Executive Summary
This study develops a global feature mapping approach to address interpretability challenges in solar energetic particle (SEP) event prediction. The framework integrates a sliding-window multivariate time series forest classifier (Slim-TSF) with global explainability techniques, aggregating feature importance across bootstrap iterations to identify key predictive parameters. Experimental results show that model performance significantly improves with shorter lead times, achieving optimal skill scores when predictions are made within 5-60 minutes of event onset. The approach successfully bridges the gap between data-driven predictions and physical understanding, making SEP forecasts more interpretable and actionable for space weather operations.

## Method Summary
The method employs a Slim-TSF classifier that uses interval-based features extracted from sliding windows across all univariate time series (P3, P5, P7 proton flux channels and X-ray data). Statistical features including mean, standard deviation, and slope are computed for each time interval, and a Random Forest classifier is trained on these aggregated features. Global explainability is achieved through bootstrap sampling, where feature importance (measured via Gini impurity reduction) is computed repeatedly across multiple iterations and aggregated to reveal globally relevant predictive features. The framework is validated on the GSEP dataset containing 244 strong and 189 weak SEP events from solar cycles 22-24, with varying observation windows (6, 8, 10 hours) and lag windows (5-180 minutes).

## Key Results
- P3 proton flux channel (≥10 MeV) consistently emerges as the most important feature across all bootstrap iterations and lag windows
- Model skill scores (TSS, HSS, GSS) show significant improvement with shorter lag times, with optimal performance at 5-60 minutes before event onset
- Binary classification (Strong vs. Weak) achieves higher skill scores than broader Event vs. No-Event classification
- Cumulative feature importance aggregation effectively identifies stable predictive features while suppressing noise from subsample variability

## Why This Works (Mechanism)

### Mechanism 1: Cumulative Feature Importance Aggregation via Bootstrapping
- Claim: Aggregating feature importance across multiple bootstrap iterations reveals globally relevant predictive features while dampening noise from individual subsample variability.
- Mechanism: The framework repeatedly subsamples the dataset with replacement, computing feature importance (via Gini impurity reduction) at each iteration. Importance scores are summed across all iterations to produce a cumulative distribution, amplifying features that consistently contribute and suppressing those that appear significant only in specific subsamples.
- Core assumption: Truly predictive features will demonstrate stable importance across diverse data subsets, while spurious correlations will exhibit high variance across bootstrap iterations.
- Evidence anchors: [abstract] "By aggregating feature importance across multiple bootstrap iterations, the framework identifies key predictive parameters"; [Section III.B] "By summing the importance scores across all iterations, we construct a cumulative importance distribution that reflects global relevance rather than local variability"

### Mechanism 2: Interval-Based Statistical Feature Extraction for Multivariate Time Series
- Claim: Extracting statistical features (mean, standard deviation, slope) from sliding windows across all univariate time series enables the classifier to capture both individual channel dynamics and cross-channel interactions.
- Mechanism: The Slim-TSF approach applies a multi-scale sliding window to each proton flux channel (P3, P5, P7) and X-ray data, computing interval features (fmean, fstd, fslope) plus transformed features (max, min, mean via localized pooling). A Random Forest classifier is then trained on the complete feature set from all variables.
- Core assumption: Discriminative information for SEP prediction is encoded in statistical properties of time intervals rather than requiring point-by-point sequence modeling.
- Evidence anchors: [Section III.A] "It employs a multi-scale sliding windows approach that makes use of interval-based features extracted from all univariate time series"; [Section III.A] Equations 1-3 define fmean, fstd, and fslope extraction

### Mechanism 3: Temporal Proximity Effect on Predictive Skill
- Claim: Model skill scores (TSS, HSS, GSS) improve as the lag window shortens (5-60 minutes before event onset), suggesting precursor signals become more discriminative closer to event initiation.
- Mechanism: The experimental design varies observation windows (6, 8, 10 hours) and lag windows (5-180 minutes). Shorter lag times reduce the temporal gap between observed data and event onset, capturing more immediate precursor signatures in proton flux channels.
- Core assumption: SEP precursor signals are temporally localized and degrade in predictability as distance from event onset increases.
- Evidence anchors: [Section IV.D] "TSS, HSS, and GSS consistently indicate that the model's predictive accuracy and reliability reduced as the lag window increased"; [Section IV.D, Fig. 2] Skill scores plotted against lag time show consistent decline from 5 to 180 minutes

## Foundational Learning

- Concept: Random Forest Feature Importance (Gini Impurity)
  - Why needed here: The global explainability mechanism relies on understanding how decision trees quantify feature contributions via impurity reduction.
  - Quick check question: Can you explain why a feature with high cumulative Gini reduction across bootstrap iterations is considered more "globally important" than one with high importance in only a few iterations?

- Concept: Bootstrap Aggregation (Bagging)
  - Why needed here: The framework uses bootstrap sampling to generate multiple feature rankings; understanding variance reduction via aggregation is essential.
  - Quick check question: How does aggregating feature importance across bootstrap iterations differ from simply running the model once on the full dataset?

- Concept: Time Series Classification Skill Scores (TSS, HSS, GSS)
  - Why needed here: Model evaluation uses domain-specific skill scores; interpreting these correctly is critical for assessing predictive capability.
  - Quick check question: For an imbalanced SEP dataset with rare "strong" events, why might TSS be preferred over raw accuracy?

## Architecture Onboarding

- Component map: Data Ingestion -> Windowing Module -> Feature Extraction (Slim-TSF) -> Classification (Random Forest) -> Explainability Layer -> Evaluation Module
- Critical path: Data ingestion → Window configuration → Interval feature extraction → Random Forest training → Bootstrap aggregation (N iterations) → Cumulative importance scoring → Skill score evaluation
- Design tradeoffs:
  - Shorter lag windows improve skill but reduce forecast lead time (operational warning window shrinks)
  - Cumulative aggregation stabilizes importance rankings but increases computational cost with iteration count
  - Interval-based features sacrifice temporal ordering for computational efficiency and interpretability
  - Binary classification (Strong vs. Weak) achieves higher skill than broader Event vs. No-Event classification
- Failure signatures:
  - High variance in feature importance across bootstrap iterations suggests unstable or spurious feature rankings
  - Skill scores near zero or negative indicate model performs no better than random baseline
  - Near-zero importance for all features except one may indicate data leakage or insufficient feature diversity
  - Performance collapse at longer lag windows is expected; abrupt non-monotonic drops may indicate data quality issues
- First 3 experiments:
  1. **Baseline validation**: Replicate the Strong vs. Weak classification with 6-hour observation window and 5-minute lag window; verify TSS/HSS values match reported ranges (~0.6-0.8) to confirm implementation correctness.
  2. **Bootstrap iteration sensitivity**: Run the global explainability pipeline with 10, 100, and 1000 bootstrap iterations; confirm P3 flux channel importance stabilizes and ranking variance decreases as iteration count increases.
  3. **Lag window ablation**: Fix observation window at 8 hours and systematically vary lag window (5, 15, 30, 60, 120, 180 minutes); plot TSS/HSS curves to verify the reported performance degradation pattern and identify optimal operational lag threshold.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating additional solar and heliospheric parameters beyond GOES proton/X-ray fluxes improve forecast skill at longer lead times (>60 minutes)?
- Basis in paper: [explicit] The authors state that "further exploration of additional solar and heliospheric parameters" could offer improvements, and results show performance significantly degrades as lag windows extend beyond 60 minutes.
- Why unresolved: The current study only examines GOES P3, P5, P7 channels and X-ray flux; precursor signals may exist in CME properties, magnetic field measurements, or solar radio flux that become identifiable earlier.
- What evidence would resolve it: Systematic experiments adding parameters such as CME speed, shock characteristics, and magnetic connectivity metrics, with skill scores reported across the same lag windows.

### Open Question 2
- Question: Why do higher-energy proton flux channels (P5 ≥50 MeV, P7 ≥100 MeV) demonstrate near-zero predictive importance, and does this hold across different modeling frameworks?
- Basis in paper: [explicit] The authors note that P5 and P7 showed minimal importance and suggest "future studies might explore their role under different modeling frameworks or in combination with other observational parameters."
- Why unresolved: It is unclear whether the low importance is intrinsic to SEP physics, specific to the Slim-TSF classifier, or due to correlations with P3 that mask their contribution.
- What evidence would resolve it: Comparative analysis using alternative ML architectures (e.g., deep learning, gradient boosting) with feature ablation studies specifically targeting P5 and P7 contributions.

### Open Question 3
- Question: How robust is the global feature mapping approach when applied to spatially distributed observations from multiple vantage points in the heliosphere?
- Basis in paper: [explicit] The conclusion identifies "expanding the interpretability framework to incorporate spatially and temporally distributed observations" as a future research direction. [inferred] The introduction notes SEP characteristics vary with observer location due to magnetic connectivity differences.
- Why unresolved: The current framework is validated only on near-Earth GOES data; it is unknown whether P3 remains the dominant feature from other heliospheric positions.
- What evidence would resolve it: Validation using multi-spacecraft datasets (e.g., Parker Solar Probe, Solar Orbiter, STEREO) with feature importance compared across vantage points.

## Limitations
- Performance degradation at longer lead times (>60 minutes) limits operational forecasting capabilities
- The framework only validates on near-Earth GOES observations, not multi-spacecraft distributed measurements
- Bootstrap-based explainability may introduce computational latency incompatible with real-time operational requirements

## Confidence

- **High Confidence**: The P3 proton flux channel consistently emerging as the most important feature across bootstrap iterations; the temporal proximity effect showing degraded performance at longer lag windows
- **Medium Confidence**: The Slim-TSF feature extraction approach's sufficiency for capturing SEP precursor signals; the generalizability of results across different observation window lengths
- **Low Confidence**: Exact quantitative performance metrics (specific TSS/HSS values) without full experimental details; the stability of feature rankings at different bootstrap iteration counts

## Next Checks

1. **Convergence Analysis**: Perform bootstrap iterations at 50, 200, 500, and 1000 counts to verify P3 feature importance stabilizes and ranking variance decreases monotonically, confirming the aggregation approach effectively suppresses noise.

2. **Temporal Generalization Test**: Apply the trained model to SEP events from solar cycle 24 (if not already included) or hold out one complete solar cycle during training to assess temporal generalization beyond the reported 1986-2018 coverage.

3. **Hyperparameter Sensitivity Analysis**: Systematically vary Random Forest parameters (n_estimators: 100-1000, max_depth: 10-50) and sliding window sizes (30-300 minutes) to quantify their impact on both predictive skill scores and feature importance stability.