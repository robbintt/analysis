---
ver: rpa2
title: 'XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented
  Generation for Software Security'
arxiv_id: '2510.19006'
source_url: https://arxiv.org/abs/2510.19006
tags:
- malware
- code
- xgen-q
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces XGen-Q, a domain-adaptive LLM for malware
  analysis built on Qwen-Coder and pretrained on over one million malware samples.
  It combines retrieval-augmented generation with a two-stage prompt strategy to produce
  both interpretable forensic reports and actionable classification labels.
---

# XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security

## Quick Facts
- **arXiv ID**: 2510.19006
- **Source URL**: https://arxiv.org/abs/2510.19006
- **Reference count**: 40
- **Primary result**: XGen-Q achieves significantly lower perplexity than baselines, with best performance of 1.53 perplexity on assembly and 1.59 on source code.

## Executive Summary
XGen-Q is a domain-adaptive LLM framework for malware analysis built on Qwen-Coder, pretrained on over one million malware samples. It combines retrieval-augmented generation with a two-stage prompt strategy to produce both interpretable forensic reports and actionable classification labels. Experiments demonstrate significantly lower perplexity than baselines across both source and assembly code, indicating strong generalization to unseen samples.

## Method Summary
XGen-Q uses Qwen2.5-Coder-1.5B-Instruct as a base model, undergoing domain-specific pretraining via Causal Language Modeling on the SBAN dataset containing over one million malware samples. The framework employs a two-stage prompt approach: first generating structured forensic analysis (Conclusion, Reasoning, Evidence), then synthesizing this into a final classification label. RAG injects context-relevant cybersecurity keywords from MITRE ATT&CK during inference. The pipeline is orchestrated using LangChain/LlamaIndex for inference.

## Key Results
- Achieves perplexity of 1.53 on assembly code and 1.59 on source code
- Demonstrates strong generalization to unseen malware samples
- Combines interpretable forensic reports with actionable classification labels

## Why This Works (Mechanism)

### Mechanism 1: Domain-Specific Pretraining for Pattern Recognition
Continued pretraining on malware-specific corpora lowers perplexity and improves modeling of obfuscated code patterns compared to general-purpose code models. The model undergoes CLM on the SBAN dataset, shifting its prior probability distribution to favor tokens and structures found in malicious software.

### Mechanism 2: RAG-Guided Semantic Enrichment
Injecting context-relevant cybersecurity keywords via RAG grounds the inference process, improving the model's ability to reason about specific malicious behaviors. Input code is vectorized to query MITRE ATT&CK, with top 10 retrieved behavior keywords injected into the prompt.

### Mechanism 3: Two-Stage Prompting for Separation of Concerns
Decoupling detailed forensic analysis from final classification enhances interpretability and allows for modular verification. Prompt 1 forces structured reasoning generation, while Prompt 2 synthesizes this into a final label, preventing post-hoc hallucination.

## Foundational Learning

- **Causal Language Modeling (CLM)**: Why needed - The paper uses CLM for domain adaptation to predict next tokens based on previous ones, learning malware syntax. Quick check - How does the model's objective function change when moving from general pretraining to domain-specific pretraining on malware?

- **Perplexity as a Quality Metric**: Why needed - The primary quantitative result is lower perplexity, measuring how "surprised" a model is by test data. Quick check - If XGen-Q has perplexity of 1.53 on assembly code, does that mean it classifies correctly, or simply predicts the next assembly instruction with high confidence?

- **Retrieval-Augmented Generation (RAG)**: Why needed - The architecture relies on querying external knowledge (MITRE ATT&CK) during inference. Understanding vector embedding matching is critical. Quick check - What happens to the RAG mechanism if the input code snippet is too short to generate a distinctive semantic vector?

## Architecture Onboarding

- **Component map**: Base Model (Qwen2.5-Coder-1.5B-Instruct) -> Adapter (Domain-specific weights via CLM) -> Retriever (Vector store index of MITRE ATT&CK) -> Orchestrator (LangChain/LlamaIndex pipeline)

- **Critical path**: 1) Input: Raw source or assembly code snippet. 2) Retrieval: Code -> Embedding -> Vector Search -> Top-10 Keywords. 3) Prompting: Keywords + Code -> Prompt 1 -> Structured Analysis. 4) Synthesis: Structured Analysis -> Prompt 2 -> Final Label (Malware/Benign/Partially Malicious).

- **Design tradeoffs**: Model size chosen at 1.5B parameters for computational efficiency over larger variants. Optimizes for low perplexity (distribution modeling) as proxy for classification accuracy.

- **Failure signatures**: Keyword mismatch leading to incoherent analysis, obfuscation drift causing perplexity spikes, reasoning disconnect where Stage 1 hallucinations are faithfully summarized in Stage 2.

- **First 3 experiments**: 1) RAG Ablation: Disable RAG and compare perplexity/classification quality. 2) Cross-Family Generalization: Train on N-1 families, test on held-out family. 3) Prompt Inversion: Swap Prompt 1 and 2 to test hallucination reduction.

## Open Questions the Paper Calls Out

1. Can XGen-Q utilize continual learning strategies to incrementally update its internal knowledge for emerging threats without requiring full retraining?
2. Does the integration of multi-modal inputs, specifically dynamic execution traces and binary metadata, significantly enhance detection performance over static analysis alone?
3. To what extent does the achieved reduction in perplexity correlate with practical improvements in classification accuracy and quality of forensic explanations?

## Limitations
- Low perplexity indicates learned statistical distribution but doesn't guarantee effective detection without corresponding classification metrics
- RAG mechanism vulnerable to misalignment when code is heavily obfuscated or lacks clear semantic tokens
- Two-stage prompt effectiveness in reducing hallucination not rigorously tested against alternative architectures

## Confidence
- **High Confidence**: Domain-specific pretraining mechanism and its contribution to lowering perplexity
- **Medium Confidence**: RAG-based behavior extraction and two-stage prompting likely improve interpretability, but lack quantitative ablation studies
- **Low Confidence**: "Strong generalization to unseen samples" claim based on perplexity alone, without cross-family or temporal validation

## Next Checks
1. Run RAG ablation test by disabling the RAG component and comparing perplexity and classification accuracy
2. Conduct cross-family generalization test by training on N-1 malware families and testing on the held-out family
3. Perform prompt inversion experiment by swapping Prompt 1 and 2 to verify hallucination reduction