---
ver: rpa2
title: 'LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review
  Synthesis'
arxiv_id: '2511.06000'
source_url: https://arxiv.org/abs/2511.06000
tags:
- demographic
- prompt
- across
- systematic
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates whether large language models (LLMs) preserve
  age-related demographic information in biomedical systematic review summaries. We
  introduce DemogSummary, an age-stratified dataset of systematic reviews and primary
  studies across child, adult, and older adult populations.
---

# LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis

## Quick Facts
- **arXiv ID:** 2511.06000
- **Source URL:** https://arxiv.org/abs/2511.06000
- **Reference count:** 29
- **Primary result:** Demographic fidelity in LLM-generated biomedical summaries is lowest for adult-focused reviews, with higher hallucination rates compared to child and older adult populations.

## Executive Summary
This study evaluates whether large language models (LLMs) preserve age-related demographic information in biomedical systematic review summaries. We introduce DemogSummary, an age-stratified dataset of systematic reviews and primary studies across child, adult, and older adult populations. We propose the Demographic Salience Score (DSS) to measure entity-level retention, omission, and hallucination of age-related content. Three LLMs—Qwen, Longformer, and GPT-4.1 Nano—were evaluated. Results show that demographic fidelity is lowest for adult-focused summaries, with higher hallucination rates. GPT-4.1 Nano and Longformer outperformed Qwen in retaining demographic entities, though all models exhibited limitations. Age-aware prompting improved specificity but did not consistently enhance fidelity. The findings highlight the need for fairness-aware evaluation frameworks in biomedical NLP to ensure accurate representation of population-specific information.

## Method Summary
The study introduces DemogSummary, an age-stratified dataset of 44 systematic reviews (14 adult, 15 child, 15 older adult) with ~1,200 primary studies from PubMed, Cochrane, and Web of Science. Demographic entities are extracted using rule-based regex and LLM-assisted NER with 98% validation accuracy. Three LLMs (Qwen2.5-14B, Longformer LED-large-16384, GPT-4.1-nano) generate summaries under regular and age-aware prompting conditions. Demographic Salience Score (DSS) quantifies entity-level retention, omission, and hallucination using semantic similarity matching (threshold 0.7). Standard metrics (BLEU, BERTScore, BARTScore, FactCC) complement DSS evaluation.

## Key Results
- Adult-focused summaries show lowest demographic fidelity with higher hallucination rates than child and older adult populations
- GPT-4.1 Nano and Longformer outperform Qwen in retaining demographic entities
- Age-aware prompting improves specificity but increases hallucination for Qwen and maintains high omission for Longformer
- BLEU/BERTScore show minimal demographic variation while DSS reveals systematic disparities

## Why This Works (Mechanism)

### Mechanism 1: Demographic Salience Score (DSS) for Entity-Level Fidelity Assessment
- **Claim:** DSS quantifies demographic retention by combining entity matching with hallucination penalties, enabling detection of representational bias that surface metrics miss.
- **Mechanism:** DSS extracts demographic entities from both gold-standard reviews and generated summaries using rule-based patterns plus LLM-assisted NER. It computes Entity Retention Score (ERS) as the proportion of gold entities preserved, applies a Hallucination Penalty (HP) for unmatched entities, and includes an Over-length Penalty (OP) to prevent gaming via verbosity.
- **Core assumption:** Demographic fidelity can be captured through discrete entity extraction and semantic similarity matching (threshold 0.7).
- **Evidence anchors:**
  - [abstract] "We propose the Demographic Salience Score (DSS) to measure entity-level retention, omission, and hallucination of age-related content."
  - [section 5.2] DSS formulation: DSS = α × ERS − γ × HP_adj, normalized to [0,1]
  - [corpus] Weak direct corpus support; related work on bias detection exists but not for this specific metric.

### Mechanism 2: Population-Specific Retention Disparities
- **Claim:** LLMs exhibit systematic representational bias where "default" populations (adults) receive lower demographic fidelity than "marked" populations (children, older adults).
- **Mechanism:** Adults are treated as the implicit default in biomedical corpora, making age descriptors linguistically redundant. Models consequently deprioritize explicit age markers during summarization, while children and older adults—statistically "marked" categories—retain higher entity salience.
- **Core assumption:** Training data distributions encode population salience hierarchies that persist through inference.
- **Evidence anchors:**
  - [abstract] "demographic fidelity is lowest for adult-focused summaries, with higher hallucination rates"
  - [section 6] "adult summaries particularly error-prone and underrepresented populations more likely to be hallucinated"
  - [corpus] Related work on age-related cognitive decline (arxiv:2511.21164) shows demographic-specific AI design considerations, supporting population-salience hypothesis.

### Mechanism 3: Age-Aware Prompting Induces Specificity-Hallucination Tradeoffs
- **Claim:** Explicit demographic prompting increases entity specificity but amplifies model-specific failure modes (hallucination for Qwen, omission for Longformer).
- **Mechanism:** Age-aware prompting shifts generation distribution toward demographic terms, increasing recall of fine-grained descriptors. However, models with weaker grounding (Qwen) fabricate plausible but unsupported entities, while models with conservative generation (Longformer) maintain low hallucination at the cost of coverage.
- **Core assumption:** Prompt-based demographic attention is orthogonal to entity grounding capabilities.
- **Evidence anchors:**
  - [abstract] "Age-aware prompting improved specificity but did not consistently enhance fidelity"
  - [section 6] "QWEN shows high sensitivity to age-aware prompting... at the cost of increased hallucination"
  - [corpus] No direct corpus evidence for this specific prompting mechanism in biomedical contexts.

## Foundational Learning

- **Concept:** Representational vs. Allocative Bias (Crawford 2017 framework)
  - **Why needed here:** The paper explicitly adopts this distinction; understanding that representational bias concerns omission/misrepresentation rather than resource allocation is essential for interpreting DSS as a fairness metric.
  - **Quick check question:** If an LLM correctly identifies a treatment as effective for adults but omits child-specific contraindications, which bias type does this exemplify?

- **Concept:** Multi-Document Summarization as Narrative Synthesis Approximation
  - **Why needed here:** The task design treats systematic review synthesis as MDS; evaluation presupposes this mapping is valid for biomedical evidence synthesis.
  - **Quick check question:** What distinguishes narrative synthesis from simple concatenation or extraction-based summarization?

- **Concept:** Entity-Level Evaluation vs. Surface Metrics
  - **Why needed here:** BLEU/BERTScore showed minimal variation across demographics while DSS revealed systematic disparities; understanding why surface metrics fail for bias detection is critical.
  - **Quick check question:** Why might a high BERTScore coexist with complete omission of demographic entities?

## Architecture Onboarding

- **Component map:** Source review selection -> Primary study retrieval -> Demographic annotation -> Summary generation -> Entity extraction from outputs -> DSS computation -> Statistical testing (Kruskal-Wallis + Dunn's post-hoc)
- **Critical path:** Source review selection → Primary study retrieval → Demographic annotation → Summary generation → Entity extraction from outputs → DSS computation → Statistical testing (Kruskal-Wallis + Dunn's post-hoc)
- **Design tradeoffs:**
  - **Dataset scale:** 44 reviews is modest but each contains many primary studies; authors argue this reflects systematic review nature. Tradeoff: statistical power vs. annotation depth.
  - **DSS weights (α=γ=2):** Balances retention emphasis with hallucination penalty. Sensitivity analysis shows local stability but alternative weightings may suit different priorities.
  - **Semantic threshold (0.7):** Permissive matching enables synonym capture but may miss fine-grained distinctions. Stricter thresholds reduce DSS scores.
- **Failure signatures:**
  - **Negative DSS:** Qwen achieved unnormalized DSS of -0.55 to -2.49, indicating hallucination penalty exceeded retention score
  - **High variance in ERS:** Longformer showed wide IQR in adult retention (Figure 3a), suggesting inconsistent entity grounding
  - **Verbose hallucination:** Models generating >750 tokens triggered over-length penalty, often伴随 high HP scores
- **First 3 experiments:**
  1. **Baseline calibration:** Run all three models on 5 reviews per age group with regular prompting; compute DSS with default α=γ=2, threshold=0.7. Verify adult group shows lowest DSS.
  2. **Prompt sensitivity:** Apply age-aware prompting to same subset; measure ΔERS, ΔHP, ΔDSS per model. Confirm Qwen hallucination increase and Longformer omission stability.
  3. **Threshold sweep:** Vary semantic similarity threshold from 0.5–0.9 on GPT outputs; plot DSS curve to validate robustness claim (should show gradual decline, not sharp inflection).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the root causes of lower demographic fidelity in adult-focused summaries compared to child and older adult populations?
- **Basis in paper:** [explicit] The limitations section states "the causes of observed disparities remain under explored."
- **Why unresolved:** The study quantifies disparities but does not investigate whether they stem from training data composition, linguistic priors, or model architecture.
- **What evidence would resolve it:** Ablation studies controlling for training corpus age distribution, or analysis of attention patterns on age-related tokens across demographic groups.

### Open Question 2
- **Question:** What bias mitigation strategies can effectively reduce demographic hallucination and omission in biomedical summarisation?
- **Basis in paper:** [explicit] The authors explicitly state "the study does not investigate bias mitigation methods, limiting its prescriptive value for fairness-oriented applications."
- **Why unresolved:** While age-aware prompting showed mixed effects, no targeted debiasing approaches were tested.
- **What evidence would resolve it:** Experiments applying techniques such as counterfactual data augmentation, constrained decoding, or demographic-aware fine-tuning, evaluated using DSS.

### Open Question 3
- **Question:** How does DSS-based demographic fidelity extend to other demographic attributes beyond age, such as gender or ethnicity?
- **Basis in paper:** [inferred] The authors note DSS is "generalisable to other demographic dimensions" but only validate it on age-related content. Other biases (race, gender) are mentioned in related work but not evaluated.
- **Why unresolved:** DemogSummary is age-stratified only; no experiments confirm whether the metric captures retention and hallucination for non-age attributes.
- **What evidence would resolve it:** Construction of a gender- or ethnicity-stratified dataset and re-evaluation of models using the DSS framework.

## Limitations
- **Dataset scale:** 44 systematic reviews, while carefully curated, limits generalizability across medical domains
- **Entity extraction reliability:** Depends on regex and LLM-based NER accuracy, though validated at 98% on 60-sample audit
- **DSS thresholds:** Semantic similarity threshold (0.7) and weights (α=γ=2) are somewhat arbitrary and may affect cross-model comparability
- **Task approximation:** Assumes systematic review synthesis is well-approximated by multi-document summarization

## Confidence
- **High Confidence:** Population-specific retention disparities (adult vs. marked groups), DSS metric validity for bias detection, and prompt-induced specificity-hallucination tradeoff (Qwen-specific)
- **Medium Confidence:** Absolute DSS scores across models, threshold sensitivity claims, and generalizability beyond DemogSummary
- **Low Confidence:** Exact prompt templates' influence, corpus-level explanations for adult retention gaps, and whether DSS captures all forms of demographic misrepresentation

## Next Checks
1. **Threshold Robustness Test:** Sweep semantic similarity threshold (0.5–0.9) on GPT outputs and plot DSS curves to confirm gradual decline without sharp inflection points
2. **Dataset Expansion:** Replicate DSS computation on a larger set of systematic reviews (e.g., 100+) to test if adult retention gaps persist at scale
3. **Prompt Grounding Experiment:** Modify age-aware prompts to include grounding constraints (e.g., "only include demographic terms present in source") and measure changes in ERS/HP for Qwen and Longformer