---
ver: rpa2
title: On VLMs for Diverse Tasks in Multimodal Meme Classification
arxiv_id: '2505.20937'
source_url: https://arxiv.org/abs/2505.20937
tags:
- meme
- vlms
- memes
- text
- understanding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study systematically evaluates vision-language models (VLMs)
  for meme classification tasks, including sarcasm, offensiveness, and sentiment detection.
  Three experimental strategies are explored: diverse prompting (zero/few-shot with
  chain-of-thought), LoRA fine-tuning, and a novel approach combining VLM-generated
  explanations with LLM fine-tuning.'
---

# On VLMs for Diverse Tasks in Multimodal Meme Classification

## Quick Facts
- **arXiv ID**: 2505.20937
- **Source URL**: https://arxiv.org/abs/2505.20937
- **Reference count**: 35
- **Primary result**: VLMs struggle with nuanced meme classification tasks, but prompting strategies and explanation-based fine-tuning significantly improve performance

## Executive Summary
This study systematically evaluates vision-language models (VLMs) for meme classification across three complex tasks: sarcasm detection, offensiveness detection, and sentiment classification. The researchers compare three experimental approaches: diverse prompting strategies including chain-of-thought reasoning, LoRA fine-tuning, and a novel method that combines VLM-generated explanations with LLM fine-tuning. VLMs show limited capability in handling nuanced multimodal content like sarcasm and offensiveness when used directly. However, structured prompting approaches demonstrate substantial improvements, with chain-of-thought reasoning proving particularly effective. The study introduces a new CoVExFiL approach that leverages VLM explanations to fine-tune smaller LLMs, achieving significant performance gains across all three tasks.

## Method Summary
The research explores three distinct strategies for meme classification using VLMs. First, diverse prompting approaches are tested, including zero-shot, few-shot, and chain-of-thought (CoT) prompting with varying complexity levels. Second, LoRA fine-tuning is applied to adapt VLMs to the specific meme classification tasks. Third, and most innovatively, the CoVExFiL method generates explanations from VLMs for each meme, then uses these explanations to fine-tune smaller, more efficient LLMs. The study evaluates these approaches across multiple VLMs and three meme datasets focused on sarcasm, offensiveness, and sentiment detection, measuring performance improvements and identifying optimal configurations for each task.

## Key Results
- VLMs show significant limitations in nuanced meme classification tasks like sarcasm and offensiveness detection
- Three-step chain-of-thought prompting improves performance across all tasks, particularly for complex reasoning
- CoVExFiL approach achieves substantial gains: 26.24% improvement for sentiment, 8.34% for sarcasm, and 3.52% for offensiveness classification
- Explanation-based fine-tuning outperforms direct VLM adaptation and LoRA fine-tuning across all evaluated tasks

## Why This Works (Mechanism)
VLMs inherently struggle with nuanced multimodal content because they lack specialized training for complex social and contextual understanding present in memes. The proposed mechanisms address this through structured reasoning and knowledge transfer. Chain-of-thought prompting forces VLMs to decompose complex classification tasks into sequential reasoning steps, improving their ability to capture subtle contextual cues. The CoVExFiL approach works by extracting the multimodal reasoning capability of VLMs and transferring it to smaller, more efficient LLMs through explanation-based fine-tuning. This knowledge distillation process allows the strengths of large VLMs to be leveraged while maintaining computational efficiency.

## Foundational Learning
- **Chain-of-thought prompting**: Why needed - Enables systematic decomposition of complex classification tasks into sequential reasoning steps. Quick check - Test different CoT complexity levels (1-3 steps) and measure impact on nuanced classification accuracy.
- **Vision-Language Model integration**: Why needed - Handles multimodal content by jointly processing visual and textual meme components. Quick check - Evaluate performance with visual-only, text-only, and multimodal inputs to quantify multimodal benefit.
- **Knowledge distillation through explanations**: Why needed - Transfers complex reasoning capabilities from large models to smaller, efficient models. Quick check - Compare performance when using explanations vs. direct fine-tuning on same dataset.
- **LoRA fine-tuning**: Why needed - Adapts pre-trained models to specific tasks with minimal parameter updates. Quick check - Measure parameter efficiency and performance trade-offs against full fine-tuning.

## Architecture Onboarding
Component map: Meme input -> VLM/LLM processing -> Classification output
Critical path: Input meme → Multimodal encoding → Prompting/Fine-tuning → Classification decision
Design tradeoffs: Large VLMs offer better performance but higher computational cost vs. smaller LLMs with explanation-based fine-tuning offering efficiency gains
Failure signatures: Poor performance on sarcasm/offensiveness indicates limitations in contextual understanding; CoT prompting failures suggest reasoning decomposition issues
First experiments:
1. Baseline evaluation of VLMs on all three tasks without any prompting or fine-tuning
2. A/B testing of different chain-of-thought complexity levels (1-step vs 3-step) on sarcasm detection
3. Comparison of CoVExFiL vs LoRA fine-tuning performance on sentiment classification task

## Open Questions the Paper Calls Out
The study identifies several open questions regarding the generalizability of their findings. These include whether the observed improvements hold across different meme datasets and cultural contexts, how the quality of VLM-generated explanations affects downstream performance, and whether the CoVExFiL approach can be effectively scaled to larger VLMs and more complex classification tasks. The authors also note the need for cross-cultural and multilingual evaluations to assess VLM capabilities across diverse meme contexts.

## Limitations
- Evaluation limited to specific meme datasets, potentially restricting generalizability to broader meme domains
- Focus on three specific classification tasks may not capture full spectrum of multimodal meme understanding challenges
- Performance improvements show task-dependent effectiveness, with sentiment classification benefiting more than sarcasm and offensiveness detection
- Computational costs and real-world deployment considerations are not addressed

## Confidence
**High Confidence**: VLMs struggle with nuanced meme classification tasks (sarcasm, offensiveness) - well-supported by experimental results across multiple datasets and VLMs. Structured prompting strategies consistently outperform direct VLM adaptation.

**Medium Confidence**: CoVExFiL approach shows strong results but effectiveness depends on explanation generation quality. Magnitude of improvements appears robust but may be sensitive to specific implementation.

**Low Confidence**: General superiority claims for explanation-based fine-tuning over LoRA fine-tuning are limited by specific implementation choices and may not hold across different VLM architectures.

## Next Checks
1. Cross-dataset validation: Evaluate CoVExFiL approach across additional meme datasets from different cultural contexts and meme platforms
2. Ablation study on explanation quality: Systematically vary quality and format of VLM-generated explanations to quantify impact on LLM fine-tuning performance
3. Scalability assessment: Measure computational requirements and performance trade-offs when scaling CoVExFiL approach to larger VLMs and more complex tasks