---
ver: rpa2
title: 'ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain
  Visual Decoding'
arxiv_id: '2510.27128'
source_url: https://arxiv.org/abs/2510.27128
tags:
- subjects
- should
- brain
- data
- fmri
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ZEBRA introduces the first zero-shot cross-subject fMRI-to-image
  reconstruction framework. It disentangles brain representations into subject-invariant
  and semantic-specific components using adversarial training and residual decomposition.
---

# ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding

## Quick Facts
- arXiv ID: 2510.27128
- Source URL: https://arxiv.org/abs/2510.27128
- Authors: Haonan Wang; Jingyu Lu; Hongrui Li; Xiaomeng Li
- Reference count: 40
- Key outcome: First zero-shot cross-subject fMRI-to-image reconstruction framework achieving 0.153 PixCorr, 0.384 SSIM, and 81.8% AlexNet(5) accuracy

## Executive Summary
ZEBRA introduces a novel zero-shot cross-subject fMRI-to-image reconstruction framework that addresses the fundamental challenge of subject-specific variability in brain encoding. The method disentangles brain representations into subject-invariant and semantic-specific components through adversarial training and residual decomposition. This enables direct generalization to unseen subjects without fine-tuning, making ZEBRA the first truly universal brain visual decoder. The framework achieves performance approaching fully fine-tuned models while maintaining semantic fidelity and filtering subject-specific noise.

## Method Summary
ZEBRA tackles cross-subject generalization by separating brain representations into two distinct components: subject-invariant semantic features and subject-specific neural patterns. The framework employs an adversarial training strategy where a discriminator distinguishes between subject-specific and subject-invariant representations, while the generator learns to produce both components. A residual decomposition module further refines this separation by isolating the truly universal semantic content from individual neural idiosyncrasies. This dual-component approach allows the model to reconstruct images from fMRI data of entirely new subjects without any adaptation, representing a significant advance over traditional fine-tuning approaches.

## Key Results
- Achieves 0.153 Pearson Correlation and 0.384 SSIM on zero-shot cross-subject decoding
- Reaches 81.8% AlexNet(5) accuracy, matching fully fine-tuned model performance
- Outperforms existing zero-shot baselines while eliminating need for subject-specific adaptation

## Why This Works (Mechanism)
ZEBRA succeeds by recognizing that visual perception contains both universal semantic patterns shared across individuals and unique neural signatures specific to each person. By explicitly modeling this duality through adversarial disentanglement, the framework can isolate the universal components necessary for image reconstruction while discarding subject-specific noise. The residual decomposition ensures that only truly invariant features are used for cross-subject generalization, preventing overfitting to individual neural patterns. This architectural separation enables the model to generalize to unseen subjects while maintaining reconstruction quality comparable to subject-specific fine-tuning.

## Foundational Learning
1. **fMRI-to-Image Reconstruction** - Converting brain activity patterns into visual representations requires understanding the complex relationship between neural encoding and visual perception. This is essential because fMRI provides indirect measurements of brain activity that must be translated into meaningful visual content.

2. **Zero-Shot Cross-Subject Generalization** - Traditional approaches require subject-specific fine-tuning, but zero-shot methods must learn universal representations. This capability is critical for practical deployment where training on new subjects is infeasible.

3. **Adversarial Disentanglement** - Using adversarial training to separate subject-invariant from subject-specific features allows the model to identify truly universal semantic content. This technique is needed to overcome the inherent variability in individual brain encoding patterns.

4. **Residual Decomposition** - Isolating residual components helps separate universal semantic features from individual neural idiosyncrasies. Quick check: verify that residual components capture subject-specific variance while main components preserve semantic content.

5. **Cross-Modal Semantic Alignment** - Aligning brain representations with image features across subjects requires robust feature extraction methods. This ensures that semantic meaning is preserved regardless of individual neural encoding differences.

## Architecture Onboarding

**Component Map:** fMRI input -> Brain Encoder -> Adversarial Discriminator -> Semantic Generator -> Image Decoder

**Critical Path:** The most performance-critical components are the brain encoder and adversarial discriminator, which must accurately separate subject-invariant features from noise. The semantic generator then transforms these features into reconstruction-ready representations, while the image decoder produces the final visual output.

**Design Tradeoffs:** The framework balances between preserving sufficient semantic information for accurate reconstruction and filtering subject-specific noise that would prevent generalization. Using adversarial training adds complexity but enables more robust feature separation compared to simple regularization approaches.

**Failure Signatures:** Poor cross-subject performance indicates inadequate separation of subject-invariant features, often manifesting as blurry reconstructions or failure to capture semantic content. Overfitting to training subjects shows as excellent performance on seen subjects but catastrophic failure on unseen ones.

**Three First Experiments:**
1. Test zero-shot generalization on held-out subjects to verify cross-subject performance claims
2. Conduct ablation studies removing the adversarial discriminator to assess its contribution to feature separation
3. Evaluate reconstruction quality using both quantitative metrics (PixCorr, SSIM) and qualitative visual comparisons

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation primarily on healthy young adults limits generalizability to broader populations
- Theoretical guarantees for feature disentanglement are not formally proven
- Computational efficiency claims lack comprehensive hardware-specific benchmarking

## Confidence
- Cross-subject generalization performance (High confidence) - Well-supported by ablation studies across unseen subjects
- Disentanglement effectiveness (High confidence) - Demonstrated through quantitative metrics and visualizations
- Comparison to fine-tuned models (Medium confidence) - Assumes optimal fine-tuning was achieved
- Computational efficiency claims (Medium confidence) - Supported by elimination of fine-tuning, but lacks detailed benchmarks

## Next Checks
1. Test ZEBRA on datasets with broader demographic diversity (age ranges, neurological conditions, cultural backgrounds) to verify robustness beyond the NSD cohort.

2. Conduct ablation studies with different brain encoding layers to determine the optimal balance between semantic preservation and subject-specific noise filtering.

3. Implement and evaluate ZEBRA on multimodal neuroimaging data (fMRI + EEG) to assess cross-modal generalization capabilities.