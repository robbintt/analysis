---
ver: rpa2
title: What Can We Actually Steer? A Multi-Behavior Study of Activation Control
arxiv_id: '2511.18284'
source_url: https://arxiv.org/abs/2511.18284
tags:
- steering
- activation
- behaviors
- across
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how activation steering effectiveness varies
  across 50 diverse behaviors spanning personality traits, misalignment behaviors,
  persona archetypes, style cues, and public figures. The authors conduct systematic
  experiments examining steering coefficient optimization, vector properties, and
  data requirements.
---

# What Can We Actually Steer? A Multi-Behavior Study of Activation Control

## Quick Facts
- arXiv ID: 2511.18284
- Source URL: https://arxiv.org/abs/2511.18284
- Authors: Tetiana Bas; Krystian Novak
- Reference count: 4
- One-line primary result: Steering matches or exceeds prompting baselines for internal traits (Personality: 90.8 vs 87.9; Misalignment: 71.3 vs 69.4) but significantly underperforms on knowledge-dependent categories like Public Figures (51.4 vs 89.1)

## Executive Summary
This paper systematically evaluates activation steering across 50 diverse behaviors, revealing that steering effectiveness is highly behavior-dependent. The authors find that trait expression follows an inverted-U curve with respect to steering coefficient strength, while coherence and relevance decline monotonically. Steering vectors from larger datasets enable more aggressive steering without quality degradation, and vector separation metrics fail to predict steering success. The study demonstrates that steering is a powerful tool for modulating internal dispositions but ineffective for injecting external knowledge or maintaining complex identities.

## Method Summary
The study evaluates activation steering on Llama 3.1 8B across 50 behaviors using contrastive activation addition (CAA). For each behavior, 5 positive and 5 negative prompt pairs are constructed, with activations extracted at layer 15. Steering vectors are computed as mean differences between positive and negative activations, then added to the residual stream during inference. A grid search over coefficients 1-20 identifies the inverted-U peak for trait expression. GPT-4.1 serves as an automated judge scoring trait adherence, coherence, and relevance on a 0-100 scale. Results are compared against prompting baselines using Llama 3.1 8B and GPT-4.

## Key Results
- Trait expression follows an inverted-U curve with steering coefficient strength, while coherence and relevance decline monotonically
- Larger training datasets enable more aggressive steering without quality degradation, despite decreasing raw activation differences
- Steering matches or exceeds prompting baselines for internal traits (Personality: 90.8 vs 87.9; Misalignment: 71.3 vs 69.4) but significantly underperforms on knowledge-dependent categories like Public Figures (51.4 vs 89.1)
- Vector separation metrics fail to predict steering success (Pearson r=-0.045), leaving practitioners without reliable pre-selection methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Trait expression follows an inverted-U curve with a steering coefficient strength, while coherence and relevance decline monotonically.
- Mechanism: Small-to-moderate coefficients bias activations toward target behavior without disrupting the generation process. Beyond the optimal point, the perturbation grows large enough to destabilize the residual stream, causing output degradation even as the target trait signal strengthens relative to other features.
- Core assumption: The steering vector encodes a meaningful behavioral direction rather than noise; model quality degradation stems from perturbation magnitude, not vector quality.
- Evidence anchors:
  - [abstract] "We find that trait expression follows an inverted-U curve with a steering coefficient strength."
  - [section 4.2.1] "Trait expression exhibits an inverted-U response: it rises at small coefficients and peaks at low–moderate values, then declines as coefficients grow. Coherence and relevancy drop sharply and monotonically with stronger steering, approaching zero at large coefficients."
  - [corpus] Limited direct confirmation; related work (Soo et al. 2025) reports non-linear effectiveness scaling but doesn't replicate the inverted-U specifically.
- Break condition: If the vector encodes spurious correlations rather than the target concept, increasing coefficient may amplify confounding behaviors before trait expression improves.

### Mechanism 2
- Claim: Activation steering functions as a dispositional modulator for internal traits but cannot inject propositional (factual) knowledge.
- Mechanism: Internal dispositions—personality dimensions, misalignment tendencies—appear encoded as dense, continuous directions in activation space that can be shifted via vector addition. Propositional knowledge (biographical facts, domain expertise) relies on sparse subgraphs that require context activation; steering cannot trigger these knowledge retrieval pathways without degrading coherence.
- Core assumption: The model's knowledge is stored in discrete circuits rather than continuously parameterized directions; steering vectors operate on the output distribution's "how" but not "what" regarding factual content.
- Evidence anchors:
  - [abstract] "Steering matches or exceeds prompting baselines for internal traits... but significantly underperforms on knowledge-dependent categories like Public Figures (51.4 vs 89.1)."
  - [section 7.1] "We posit that activation steering functions primarily as a dispositional modulator rather than a propositional injector... adding a 'Marie Curie vector' does not activate the necessary subgraph of biographical knowledge if it is not already present in the context."
  - [corpus] No direct corpus confirmation of dispositional vs. propositional dichotomy; this appears to be the paper's novel theoretical contribution.
- Break condition: If knowledge is densely encoded in certain layers or can be activated via steering at different depths, layer-specific steering might overcome this limitation.

### Mechanism 3
- Claim: Larger training datasets enable higher steering coefficients before quality collapse, even though raw activation differences between positive/negative examples decrease with sample size.
- Mechanism: More contrastive examples reduce variance in the estimated steering direction, producing a more stable vector that generalizes better. The direction's signal-to-noise ratio matters more than the raw magnitude of the mean difference vector.
- Core assumption: Steering quality depends primarily on directional accuracy rather than vector norm; noise in small-sample vectors limits coefficient scaling.
- Evidence anchors:
  - [abstract] "Vector separation metrics fail to predict steering success, while larger training datasets enable more aggressive steering without quality degradation."
  - [section 4.2.3] "Despite decreasing raw activation differences between positive/negative examples as sample size grows (consistent with regression to the mean), steering quality improves. This shows that stability from larger sample sizes outweighs raw vector magnitude."
  - [corpus] Corpus evidence is sparse; related work on data scaling requirements for steering vectors remains limited.
- Break condition: If training examples are not semantically diverse, larger datasets may average toward generic directions rather than the target behavior.

## Foundational Learning

- **Concept: Residual Stream and Activation Space**
  - Why needed here: Steering operates by adding vectors to the residual stream at specific layers. Without understanding that activations represent superposed features, you cannot reason about why vector addition affects behavior.
  - Quick check question: Can you explain why adding a vector at layer 15 changes output behavior without modifying weights?

- **Concept: Contrastive Activation Addition (CAA)**
  - Why needed here: This is the baseline method used throughout. You need to understand that steering vectors are computed as (mean positive activations) - (mean negative activations) to isolate the target concept direction.
  - Quick check question: Given 5 positive examples and 5 negative examples with their activations, how would you compute a steering vector?

- **Concept: Coherence vs. Trait Expression Trade-off**
  - Why needed here: The core finding is that these metrics respond differently to coefficient strength. Optimization requires balancing behavioral control against output quality.
  - Quick check question: If you observe trait expression of 85 but coherence of 40, what does this indicate about your steering coefficient?

## Architecture Onboarding

- **Component map:** Contrastive dataset -> Vector extraction (mean difference at layer 15) -> Steering application (add scaled vector) -> GPT-4.1 judge evaluation
- **Critical path:** Define behavior category -> Construct contrastive prompt pairs -> Extract activations and compute steering vector -> Grid search coefficients (1-20) -> Evaluate trade-off between trait expression and coherence/relevance
- **Design tradeoffs:**
  - Coefficient selection: Higher = stronger trait expression but lower coherence/relevance
  - Dataset size: More examples = more aggressive steering possible, but diminishing returns
  - Layer selection: Layer 15 chosen based on prior work; different behaviors may localize at different depths (acknowledged limitation)
  - Vector separation: Cannot be used to predict steering success; ignore this metric during vector selection
- **Failure signatures:**
  - Knowledge-dependent behaviors (public figures): Steering score ~51 vs. prompting ~89 → avoid steering for factual personas
  - High coefficients: Coherence/relevance approach zero → cap coefficients before quality collapse
  - Small datasets (N=10): Quality collapse occurs at lower coefficients → collect 100+ examples for aggressive steering
- **First 3 experiments:**
  1. **Coefficient sweep**: For a target behavior, run grid search over coefficients 1-20 measuring trait expression, coherence, and relevance. Identify the inverted-U peak and quality collapse threshold.
  2. **Data scaling test**: For the same behavior, extract steering vectors using 10, 50, and 100 contrastive examples. Compare maximum viable coefficient and peak trait expression at each scale.
  3. **Behavior category validation**: Test steering on one internal trait (e.g., neuroticism) and one knowledge-dependent target (e.g., Albert Einstein). Confirm the dispositional vs. propositional effectiveness gap replicates.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can sophisticated vector diagnostics or non-linear relationships better predict steering success than simple vector separation metrics?
- Basis in paper: [explicit] The authors conclude Section 6 by stating, "Future work should explore whether more sophisticated vector diagnostics or non-linear relationships might better predict steerability."
- Why unresolved: The study found that raw Euclidean norms (vector separation) had near-zero correlation (Pearson $r=-0.045$) with actual steering performance, leaving practitioners without a reliable way to pre-select effective vectors.
- What evidence would resolve it: Discovery of a metric (e.g., non-linear dimensionality reduction features or probe-based metrics) that shows a statistically significant correlation with downstream trait expression scores.

### Open Question 2
- Question: Does behavior-specific layer selection improve steering performance for currently "unsteerable" categories like Public Figures?
- Basis in paper: [inferred] In the Limitations section (Section 8), the authors note they restricted steering to Layer 15 and hypothesize that "different behaviors are localized at different depths (e.g., syntax at lower layers, abstract traits at higher layers)."
- Why unresolved: The poor performance on knowledge-heavy categories (Public Figures) may be an artifact of a fixed intervention layer rather than a fundamental limit of the method, as relevant biographical knowledge might be encoded at different depths.
- What evidence would resolve it: Experiments sweeping intervention layers for "Public Figure" behaviors that yield significantly higher trait scores than the fixed-layer baseline.

### Open Question 3
- Question: How does steering effectiveness scale with model size and representation disentanglement for knowledge-heavy behaviors?
- Basis in paper: [inferred] The authors state in Section 8 that "Larger models with more disentangled representations might exhibit different responses to knowledge-heavy steering," acknowledging the single-model limitation.
- Why unresolved: It is unclear if the failure to steer Public Figures is inherent to the method or if larger models with better-structured knowledge representations would allow for successful "propositional injection."
- What evidence would resolve it: Comparative scaling curves showing steering success rates for knowledge-dependent personas across models of varying sizes (e.g., 8B vs 70B parameters).

## Limitations
- The core theoretical claim about dispositional vs. propositional knowledge dichotomy lacks direct empirical validation
- Layer 15 was chosen arbitrarily without behavior-specific localization analysis
- Results rely entirely on GPT-4.1 automated judge without human evaluation validation
- Generalization beyond the 50 studied behaviors to broader steering targets remains untested

## Confidence

- **High confidence**: The inverted-U curve relationship between steering coefficient and trait expression (directly observed across behaviors with consistent patterns)
- **Medium confidence**: The claim that steering is ineffective for knowledge-dependent behaviors (performance gap is clear but mechanism is theoretical)
- **Medium confidence**: The finding that larger datasets enable more aggressive steering (supported but mechanism is not fully explained)
- **Low confidence**: The dispositional vs. propositional knowledge theoretical framework (novel theoretical contribution without direct validation)

## Next Checks

1. **Layer Localization Experiment**: Systematically test steering at layers 5, 10, 15, 20, and 25 for a subset of behaviors to identify whether different behavior categories localize at different depths, and whether this explains performance variations.

2. **Human Evaluation Validation**: Conduct human rating studies for 5-10 behaviors across different categories (personality, misalignment, public figures) to validate that GPT-4.1 judge scores correlate with human judgments of trait adherence, coherence, and relevance.

3. **Mechanism Probing for Knowledge Steering**: Design experiments to test whether steering can be made effective for knowledge-dependent behaviors through alternative approaches: (a) steering at multiple layers simultaneously, (b) using context-specific steering vectors conditioned on biographical information, or (c) combining steering with retrieval-augmented generation.