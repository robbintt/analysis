---
ver: rpa2
title: 'GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation
  of LLMs'
arxiv_id: '2505.10143'
source_url: https://arxiv.org/abs/2505.10143
tags:
- evidence
- llms
- generation
- arxiv
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GE-Chat, a knowledge graph-enhanced retrieval-augmented
  generation (RAG) framework to improve the trustworthiness of LLM responses by providing
  evidence-based answer generation. When a user uploads a document, GE-Chat constructs
  a knowledge graph to enhance the RAG agent's responses.
---

# GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs

## Quick Facts
- arXiv ID: 2505.10143
- Source URL: https://arxiv.org/abs/2505.10143
- Authors: Longchao Da; Parth Mitesh Shah; Kuan-Ru Liou; Jiaxing Zhang; Hua Wei
- Reference count: 26
- Key outcome: GE-Chat consistently improves evidence retrieval performance compared to original LLMs, with higher evidence scores measuring both relevance and conciseness of generated evidence.

## Executive Summary
This paper proposes GE-Chat, a knowledge graph-enhanced retrieval-augmented generation (RAG) framework to improve the trustworthiness of LLM responses by providing evidence-based answer generation. When a user uploads a document, GE-Chat constructs a knowledge graph to enhance the RAG agent's responses. It leverages Chain-of-Thought (CoT) reasoning elicitation, n-hop subgraph searching, and entailment-based sentence generation to accurately retrieve evidence. The framework addresses the challenge of LLM hallucinations by grounding responses to original document content with sentence-level precision. Experiments on a dataset of 1000 cases across 10 categories show that GE-Chat consistently improves evidence retrieval performance compared to original LLMs.

## Method Summary
GE-Chat constructs a knowledge graph from uploaded documents through entity extraction and relation probing, then uses this structured representation to enhance evidence retrieval. For each query, the system generates Chain-of-Thought reasoning steps, matches these to KG entities, performs n-hop subgraph searching to retrieve relevant chunks, and applies entailment-based sentence selection to identify the most relevant evidence. The evidence selection optimization balances semantic relevance against verbosity using an objective function that combines entailment probability with length penalty. The entire pipeline is designed to provide sentence-level source attribution that grounds LLM responses in original document content.

## Key Results
- GE-Chat improves evidence retrieval performance compared to original LLMs
- Evidence scores combine cosine similarity with conciseness ratio to measure relevance
- Experiments conducted on 1000 cases across 10 categories with human-annotated ground truth
- Framework achieves higher evidence scores by providing sentence-level fine-grained identification

## Why This Works (Mechanism)

### Mechanism 1
Structured knowledge graphs enable more precise evidence retrieval than direct chunk-based RAG by capturing entity-relationship semantics. When a document is uploaded, entities are extracted and relations are probed to construct a KG. During querying, CoT-derived reasoning steps are matched to KG entities, and n-hop subgraph searching retrieves connected context, anchoring generated content to source chunks.

### Mechanism 2
CoT elicitation provides a reasoning scaffold that improves traceability from answer back to source content. A structured template prompts the LLM to output not just an answer but explicit reasoning steps. Each step is then entity-matched against the KG, enabling retrieval of specific supporting chunks rather than relying on the LLM's internal source attribution.

### Mechanism 3
Entailment-based sentence selection with length penalty produces concise, relevant evidence sentences better than chunk-level highlighting. For each chunk retrieved via subgraph search, an NLI model scores each sentence's entailment probability against the answer sentence. An objective function F(s) = α·prob(s|S') - β·len(s) balances semantic relevance against verbosity, selecting the optimal evidence sentence.

## Foundational Learning

- Concept: Knowledge Graph Construction (entity extraction, relation probing)
  - Why needed here: GE-Chat's entire evidence pipeline depends on accurate KG construction. If entities or relations are missing, subsequent subgraph searches fail.
  - Quick check question: Given a sample document, can you list the key entities and their relations? Would a missing relation break multi-hop retrieval?

- Concept: Chain-of-Thought (CoT) Prompting
  - Why needed here: CoT provides the reasoning trace that anchors evidence retrieval. Understanding how to elicit and parse CoT is essential for debugging entity-matching failures.
  - Quick check question: Can you identify when CoT reasoning diverges from actual evidence sources? What template modifications might improve alignment?

- Concept: Natural Language Inference (NLI) / Entailment
  - Why needed here: The evidence selection optimization relies on NLI scores. Understanding entailment vs. contradiction vs. neutrality helps diagnose why certain sentences are selected.
  - Quick check question: Given an answer sentence and three candidate evidence sentences, which would an NLI model rank highest for entailment? Why might length penalty change the ranking?

## Architecture Onboarding

- Component map: Document Ingestion -> Chunking -> Entity Extraction -> Relation Probing -> KG Storage -> Query Pipeline -> CoT Generation -> Entity Matching -> N-hop Subgraph Search -> Chunk Retrieval -> Evidence Selection -> NLI Entailment Scoring -> Optimization -> Best Sentence Selection -> Return (Answer + Evidence)

- Critical path: Document upload triggers KG construction (offline/preprocessing) -> User query triggers CoT generation (online) -> CoT entities mapped to KG nodes (online) -> N-hop search retrieves source chunks (online) -> NLI scoring + optimization selects evidence sentences (online, per-chunk, low latency claimed)

- Design tradeoffs: KG construction latency vs. query-time efficiency: KG is prebuilt, shifting cost to ingestion; N-hop depth (k=2 in implementation): Deeper hops capture more context but increase retrieval noise; α/β weighting (both 0.5): Higher α favors relevance, higher β favors conciseness; domain-specific tuning may be needed; Chunk size: Smaller chunks enable finer evidence but may fragment entity context

- Failure signatures: Missing evidence: Entity extraction failed to capture key terms; check KG completeness; Overly broad evidence: N-hop search retrieved too many chunks; consider reducing k or tightening entity matching; Irrelevant evidence: NLI model scored non-entailing sentences highly; inspect entailment logits and α/β balance; No CoT alignment: LLM generated reasoning steps with no document entities; improve CoT template or use stronger instruction-following model

- First 3 experiments: KG Completeness Audit: On a sample document, manually verify that key entities and relations are captured. Measure recall against ground-truth entity list; CoT-to-Entity Trace: For 10 queries, trace each CoT step to its matched KG entity. Identify steps with no matches and analyze causes (extraction gap vs. CoT hallucination); Evidence Selection Ablation: Compare F(s) selection against (a) random sentence from chunk, (b) first sentence, (c) chunk-level return. Measure Evidence_score (cosine similarity × conciseness) to quantify improvement.

## Open Questions the Paper Calls Out

### Open Question 1
How does GE-Chat's evidence retrieval performance scale with document length and complexity across different question types (Synthesis, Structure, Term Explanation)? The dataset includes three document length categories and three question types, but the paper does not report performance breakdowns by these dimensions.

### Open Question 2
Is the fixed 2-hop sub-graph search depth optimal, or should hop depth be adaptive based on question complexity or graph density? The paper states "k = 2 in our implementation" but provides no ablation study comparing different hop depths.

### Open Question 3
Are the fixed weights (α=β=0.5) in the evidence optimization function optimal across all domains, or should domain-specific tuning be applied? The balance between meaningfulness and conciseness may vary by domain.

### Open Question 4
How robust is GE-Chat to knowledge graph construction errors, particularly entity extraction failures or incorrect relation probing? The framework depends entirely on LLM-constructed knowledge graphs, but no analysis examines how KG quality affects downstream evidence retrieval accuracy.

## Limitations
- The framework's performance hinges on the assumption that KG entities and CoT reasoning steps align perfectly, but no analysis addresses partial matches or entity ambiguity
- The n-hop subgraph depth (k=2) appears arbitrary without sensitivity analysis
- The Evidence_score metric combines relevance and conciseness multiplicatively, making it difficult to diagnose whether improvements come from better relevance or shorter evidence

## Confidence
- **High**: The overall architecture (KG + CoT + NLI evidence selection) is technically sound and follows established RAG patterns
- **Medium**: The novel combinations (CoT entity matching, F(s) optimization) likely work but need component-level validation
- **Low**: Claims about superiority over existing Graph-RAG methods lack ablation studies showing which components drive improvements

## Next Checks
1. Entity Extraction Audit: Manually annotate 50 entities in 5 sample documents and measure recall against GE-Chat's KG construction output to quantify coverage gaps
2. CoT Alignment Study: For 20 queries, have human annotators rate whether each CoT step has corresponding evidence in the source document, measuring alignment accuracy
3. Evidence Selection Ablation: Compare F(s) evidence selection against baseline methods (first sentence, random sentence, chunk-level return) on the same 1000-case dataset to isolate the contribution of the optimization function