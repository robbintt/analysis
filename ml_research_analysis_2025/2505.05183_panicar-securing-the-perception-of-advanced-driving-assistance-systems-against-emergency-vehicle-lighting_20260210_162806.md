---
ver: rpa2
title: 'PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against
  Emergency Vehicle Lighting'
arxiv_id: '2505.05183'
source_url: https://arxiv.org/abs/2505.05183
tags:
- emergency
- vehicle
- lighting
- object
- confidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PaniCar is a digital phenomenon where activated emergency vehicle
  lighting causes object detector confidence scores to fluctuate below detection thresholds,
  potentially causing autonomous vehicles to fail to detect nearby objects. This vulnerability
  poses safety and security risks for advanced driving assistance systems (ADAS).
---

# PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting

## Quick Facts
- arXiv ID: 2505.05183
- Source URL: https://arxiv.org/abs/2505.05183
- Reference count: 40
- Primary result: Caracetamol framework improves YOLOv3 and Faster R-CNN average confidence scores by 0.20 and reduces fluctuation ranges by 0.33 while maintaining real-time processing speeds.

## Executive Summary
PaniCar is a digital phenomenon where emergency vehicle lighting causes object detector confidence scores to fluctuate below detection thresholds, potentially causing autonomous vehicles to fail to detect nearby objects. This vulnerability poses safety and security risks for advanced driving assistance systems (ADAS). The phenomenon occurs because flare from emergency vehicle lighting changes the tonal distribution of detected objects over time, affecting detector performance. Testing on seven commercial ADAS systems and four popular object detectors revealed consistent detection loss, particularly in dark conditions. To address this, Caracetamol was developed - a framework that combines a CycleGAN-based denoiser, fine-tuned object detectors, and an aggregation layer to stabilize detection confidence while maintaining real-time processing requirements.

## Method Summary
The Caracetamol framework mitigates the PaniCar phenomenon by running parallel detection streams: an original detector on raw frames and a fine-tuned detector on denoised frames. The CycleGAN denoiser maps flare-affected images to clean images through unpaired image-to-image translation. Object detectors (YOLOv3, SSD, Faster R-CNN) are fine-tuned on augmented datasets (Berkeley-MFA or Berkeley-CycleGAN) created by overlaying synthetic emergency lighting on night images from BDD100K. The combiner layer aggregates detections from both paths. The system was evaluated on 243 YouTube videos of emergency vehicles and custom recordings from seven ADAS systems, measuring average confidence, minimum confidence bounds, fluctuation ranges, and FPS.

## Key Results
- Caracetamol improved YOLOv3 and Faster R-CNN average confidence scores by 0.20
- Reduced confidence bounds by 0.33 and fluctuation ranges by 0.33
- Maintained 30-50 FPS processing speeds on RTX-3090/6000 GPUs
- SSD showed less improvement (0.49→0.56) compared to YOLO and Faster R-CNN

## Why This Works (Mechanism)

### Mechanism 1: Tonal Distribution Shift from Emergency Vehicle Flare
Emergency vehicle lighting introduces flare artifacts that alter the RGB tonal distribution of detected objects, causing object detectors to produce fluctuating confidence scores. The pulsating high-intensity light creates lens flare that temporally modulates pixel intensity distribution, causing learned feature representations to mismatch.

### Mechanism 2: Frequency-Locked Confidence Oscillation
The confidence score fluctuation frequency correlates with emergency vehicle lighting pattern frequency, creating predictable detection gaps. Emergency vehicle lights flash at specific frequencies (~1.3 Hz), and the object detector's confidence signal exhibits the same frequency component when confidence dips below detection thresholds.

### Mechanism 3: Dual-Path Detection with Denoised Augmentation
Caracetamol runs two parallel detection streams: the original frame through the original detector and a denoised frame through a detector fine-tuned on augmented emergency-lighting data. A combiner layer aggregates outputs, with the CycleGAN denoiser learning to map flare-affected images to clean images through unpaired image-to-image translation.

## Foundational Learning

- **Object Detection Confidence Thresholding**
  - Why needed: PaniCar exploits the gap between detector confidence scores and fixed detection thresholds. Understanding that detectors output continuous scores which are binarized by thresholds explains why fluctuation causes intermittent detection loss.
  - Quick check: If an object detector outputs confidence scores of [0.85, 0.45, 0.72, 0.38] across four consecutive frames with a detection threshold of 0.5, in how many frames is the object detected?

- **Lens Flare as Optical Artifact**
  - Why needed: The root cause is an optical physics phenomenon - light scattering within the lens system creates artifacts that the detector interprets as part of the scene. Hardware-level phenomena require different mitigation strategies than algorithm-level adversarial perturbations.
  - Quick check: Would improving the object detector's architecture alone eliminate lens flare, or would optical/hardware solutions also be required?

- **CycleGAN for Unpaired Image-to-Image Translation**
  - Why needed: Caracetamol's denoiser uses CycleGAN because paired training data (same scene with/without flare) is unavailable. CycleGAN learns bidirectional mappings using cycle-consistency loss.
  - Quick check: Why can't a standard supervised CNN be trained for flare removal in this application, and what advantage does CycleGAN provide?

## Architecture Onboarding

- **Component map:**
  Input Frame → CycleGAN Denoiser → Fine-tuned Detector → Combiner Layer → Output Detections
  Input Frame → Original Detector → Combiner Layer

- **Critical path:**
  1. Frame acquisition at 30-60 FPS
  2. Parallel execution: (a) denoiser preprocessing + fine-tuned detection, (b) original detection
  3. Detection aggregation before downstream ADAS decision-making
  4. Latency budget: <33ms per frame for 30 FPS target

- **Design tradeoffs:**
  - Latency vs. Accuracy: Denoiser adds 15-25% overhead; YOLO path achieves 38-50 FPS, Faster R-CNN path achieves 27-33 FPS
  - Dataset Augmentation Method: Manual Flasher Augmentation (MFA) achieved better results than CycleGAN-based synthesis for training
  - Detector Choice: Faster R-CNN shows higher baseline confidence (0.63) and post-mitigation confidence (0.81) vs YOLOv3 (0.50→0.71), but YOLO is faster

- **Failure signatures:**
  - Detection loss during emergency vehicle encounters manifests as confidence scores dipping below threshold at ~1.3 Hz intervals
  - SSD showed less improvement with Caracetamol compared to YOLO and Faster R-CNN
  - SOTA flare removal methods showed insufficient average confidence (<0.6) and excessive latency (>40ms)

- **First 3 experiments:**
  1. Reproduce baseline PaniCar behavior: Record video of a vehicle with emergency lighting in dark conditions; run YOLOv3/Faster R-CNN on frames; plot confidence score time series and FFT to confirm ~1.3 Hz frequency component.
  2. Evaluate denoiser in isolation: Pass emergency-lighting-affected frames through the CycleGAN denoiser without fine-tuning; measure whether standard COCO-pretrained detector confidence improves.
  3. Ablate augmentation strategy: Train separate detector copies on Berkeley-MFA vs Berkeley-CycleGAN datasets; compare average confidence, minimum confidence, and confidence range on held-out YouTube test videos.

## Open Questions the Paper Calls Out

### Open Question 1
Can the Caracetamol framework be adapted to significantly improve the performance of SSD-based object detectors, which showed minimal gains compared to YOLO and Faster R-CNN? The authors note SSD improvements were "less significant" and leave improving on SSD for future work.

### Open Question 2
To what extent do the PaniCar vulnerability and the Caracetamol mitigation transfer to the proprietary, black-box object detectors deployed in commercial Level 2 ADAS? The transferability to Tesla's object detectors must be examined due to discrepancies between tested open-source models and deployed industry systems.

### Open Question 3
Can detection confidence be significantly improved by fine-tuning object detectors on a large dataset of authentic emergency vehicle lighting at night, rather than the synthetic/CycleGAN-augmented datasets used in this study? Improved results could be obtained using actual images of emergency vehicles with activated lighting at night.

### Open Question 4
What specific technical factors prevented integrated RADAR systems from detecting parked emergency vehicles during documented incidents, and does the PaniCar phenomenon affect sensor fusion logic? The reason why integrated RADAR did not detect parked emergency vehicles should be analyzed to understand the full picture.

## Limitations

- The combiner layer's aggregation logic is described but not algorithmically specified, limiting reproducibility
- The generalizability claim that Caracetamol prevents "mission-critical object detection failures" is extrapolated from a specific frequency pattern without testing diverse emergency vehicle light patterns
- SSD showed minimal improvement with Caracetamol compared to YOLO and Faster R-CNN, requiring further optimization

## Confidence

- **High Confidence**: The PaniCar phenomenon itself and baseline detection failure rates are well-supported by quantitative evidence (Figure 3, Table 2). The FFT correlation between lighting frequency and confidence oscillation (1.3 Hz) is convincingly demonstrated.
- **Medium Confidence**: Caracetamol's effectiveness metrics are reported with specific numbers but rely on evaluation datasets not fully specified. The claim that MFA augmentation outperforms CycleGAN synthesis is supported but based on limited comparisons.
- **Low Confidence**: The claim that Caracetamol prevents "mission-critical object detection failures" across all emergency lighting scenarios is extrapolated from a specific frequency pattern (1.3 Hz) without testing diverse emergency vehicle light patterns or environmental conditions.

## Next Checks

1. **Reproduce frequency-domain analysis**: Record emergency vehicle lighting at various frame rates and exposure settings; verify the 1.3 Hz correlation persists across different camera configurations and lighting patterns.

2. **Test combiner layer alternatives**: Implement multiple aggregation strategies (union, weighted averaging, NMS-based) and measure their impact on detection accuracy and latency to determine optimal combiner design.

3. **Evaluate diverse emergency lighting**: Test Caracetamol against police vehicles, fire trucks, and ambulances using different light patterns (strobe, rotating beacons, LED bars) to assess robustness beyond the 1.3 Hz pattern used in development.