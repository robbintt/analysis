---
ver: rpa2
title: 'The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution
  in LLMs'
arxiv_id: '2511.14777'
source_url: https://arxiv.org/abs/2511.14777
tags:
- state
- reasoning
- accuracy
- llms
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Finite-State Machine (FSM) execution as a
  controlled, interpretable benchmark to evaluate the procedural reasoning capacity
  of large language models (LLMs). By isolating execution from planning and eliminating
  world knowledge, FSMs provide a minimal testbed where correctness is unambiguous
  and task complexity is precisely quantifiable.
---

# The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs

## Quick Facts
- **arXiv ID:** 2511.14777
- **Source URL:** https://arxiv.org/abs/2511.14777
- **Reference count:** 3
- **Primary result:** FSM benchmark exposes systematic LLM degradation in long-horizon procedural reasoning despite local accuracy

## Executive Summary
This paper introduces Finite-State Machine (FSM) execution as a controlled benchmark to evaluate the procedural reasoning capacity of large language models. By isolating execution from planning and eliminating world knowledge, FSMs provide a minimal testbed where correctness is unambiguous and task complexity is precisely quantifiable. The authors measure both Turn Accuracy (per-step correctness) and Task Accuracy (cumulative long-horizon correctness) to disentangle local computation from global state maintenance. Experiments across multiple models reveal systematic degradation in accuracy as task horizon or branching factor increases, with larger models showing improved local fidelity but persistent brittleness in multi-step reasoning. Notably, performance collapses when rule retrieval involves high branching factors, and externalized intermediate steps are essential for multi-action instructions. These results expose an "illusion of procedural reasoning," where LLMs mimic algorithmic behavior in short contexts but fail to sustain coherent execution over extended horizons. FSM-based evaluation offers a transparent framework for diagnosing and improving the algorithmic reliability of LLMs.

## Method Summary
The authors design a benchmark using deterministic finite-state machines where LLMs must execute state transitions based on provided rules without access to external knowledge or planning capabilities. The FSMs are constructed with controlled complexity through adjustable horizons (number of steps) and branching factors (number of possible transitions per state). Models are evaluated on both per-step Turn Accuracy and cumulative Task Accuracy to measure local computation fidelity versus sustained multi-step reasoning. The benchmark isolates procedural execution by providing explicit transition rules and removing ambiguity about correct outputs, creating an interpretable environment where failure modes can be precisely diagnosed.

## Key Results
- Systematic degradation in accuracy as task horizon increases, with larger models showing better local fidelity but persistent multi-step brittleness
- Performance collapses when rule retrieval involves high branching factors, exposing limitations in information retrieval during execution
- Externalized intermediate reasoning steps are essential for correct execution of multi-action instructions
- Turn Accuracy remains high while Task Accuracy drops sharply in long-horizon tasks, revealing an "illusion of procedural reasoning"

## Why This Works (Mechanism)

## Foundational Learning
- **FSM execution as controlled benchmark**: Isolates procedural reasoning from planning and world knowledge to measure pure execution capability
- **Turn vs Task Accuracy distinction**: Separates local computation fidelity from cumulative multi-step reasoning to expose failure modes
- **Branching factor impact**: Measures how rule retrieval complexity affects execution performance
- **Externalized reasoning**: Evaluates whether showing intermediate steps improves multi-action instruction execution
- **Horizon scaling effects**: Quantifies how step count influences accuracy degradation
- **Why needed**: These concepts provide precise vocabulary for diagnosing LLM procedural reasoning limitations
- **Quick check**: Can you explain why a model might score high on Turn Accuracy but low on Task Accuracy?

## Architecture Onboarding

**Component Map**: FSM Rules -> LLM Execution -> State Transitions -> Accuracy Metrics

**Critical Path**: Rule parsing → State tracking → Action selection → Transition validation

**Design Tradeoffs**: Deterministic FSMs enable clean measurement but limit real-world applicability; explicit rule provision removes planning but may overestimate capabilities

**Failure Signatures**: High Turn Accuracy + Low Task Accuracy indicates local computation success but global reasoning failure; performance collapse at high branching factors reveals retrieval limitations

**First Experiments**:
1. Compare Turn vs Task Accuracy across different model sizes to verify local vs global reasoning patterns
2. Test execution accuracy at varying branching factors to measure rule retrieval impact
3. Evaluate performance with vs without externalized intermediate steps to assess reasoning scaffolding benefits

## Open Questions the Paper Calls Out
None

## Limitations
- Controlled FSMs constrain external validity by isolating execution from planning and real-world knowledge integration
- Focus on deterministic FSMs may not reflect performance in stochastic or partially observable environments common in practical applications
- Temperature=0 decoding may not represent typical deployment conditions where stochasticity aids exploration

## Confidence
- **High confidence**: FSM benchmark design provides clean measurement of procedural execution; systematic degradation with increased horizon and branching factor is reliably observed
- **Medium confidence**: "Illusion of procedural reasoning" interpretation holds for benchmarked conditions but may not generalize to stochastic or noisy environments
- **Medium confidence**: Externalized intermediate steps are essential for multi-action instructions, though mechanism (memory augmentation vs. improved prompting) remains unclear

## Next Checks
1. Evaluate FSM execution under stochastic decoding settings to assess robustness to sampling variability and alignment with practical deployment conditions
2. Test model performance on partially observable or stochastic FSM variants to determine whether observed brittleness extends to more realistic agentic scenarios
3. Compare performance when intermediate reasoning steps are generated vs. when they are provided as ground truth to isolate whether the benefit stems from improved prompting or genuine memory augmentation