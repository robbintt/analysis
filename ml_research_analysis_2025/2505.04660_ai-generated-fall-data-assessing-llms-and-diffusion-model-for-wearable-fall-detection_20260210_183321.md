---
ver: rpa2
title: 'AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall
  Detection'
arxiv_id: '2505.04660'
source_url: https://arxiv.org/abs/2505.04660
tags:
- data
- synthetic
- fall
- datasets
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores using Large Language Models (LLMs) to generate
  synthetic fall data for wearable fall detection systems. The authors evaluate text-to-motion
  models (T2M, SATO, ParCo) and text-to-text models (GPT4o, GPT4, Gemini) against
  diffusion-based synthetic data generation (Diffusion-TS) to assess their alignment
  with real accelerometer distributions and impact on LSTM-based fall detection.
---

# AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall Detection

## Quick Facts
- arXiv ID: 2505.04660
- Source URL: https://arxiv.org/abs/2505.04660
- Authors: Sana Alamgeer; Yasine Souissi; Anne H. H. Ngu
- Reference count: 40
- Key outcome: LLM-generated synthetic data improves fall detection in low-frequency datasets but shows instability at high frequencies, with text-to-motion models outperforming text-to-text models in biomechanical realism

## Executive Summary
This study evaluates Large Language Models (LLMs) and diffusion models for generating synthetic accelerometer data to augment wearable fall detection systems. The authors compare text-to-motion models (T2M, SATO, ParCo) and text-to-text models (GPT4o, GPT4, Gemini) against diffusion-based synthetic data generation (Diffusion-TS) across four real-world datasets. Results show that LLM-generated data can enhance detection performance, particularly in low-frequency settings (20Hz), but struggles with distributional alignment and stability in high-frequency datasets (200Hz). Text-to-motion models capture biomechanical patterns better than text-to-text approaches, though diffusion methods still achieve superior statistical alignment.

## Method Summary
The study generates synthetic fall accelerometer data using three approaches: text-to-motion models (T2M-GPT, SATO, ParCo) that create joint trajectories converted to acceleration via discrete derivatives, text-to-text models (GPT4o, GPT4, Gemini) that generate sensor data directly via prompting, and Diffusion-TS that learns temporal patterns from real data. Four datasets are used: SmartFallMM (32Hz, wrist/hip), KFall (100Hz, waist), UMAFall (20Hz, wrist/waist), and SisFall (200Hz, waist). Synthetic data is generated using 50 human-designed fall prompts, then combined with 60% ADL and 20% real fall data for training. Performance is evaluated using LSTM classifiers (128 units) with Leave-Two-Out cross-validation and F1-score for fall detection, compared against Jensen-Shannon Divergence and Coverage metrics.

## Key Results
- LLM-generated data improved fall detection in low-frequency datasets (20Hz) but showed instability in high-frequency datasets (200Hz)
- Text-to-motion models outperformed text-to-text models in capturing realistic biomechanical patterns
- Diffusion-TS achieved best distributional alignment but didn't always improve downstream classification due to limited diversity
- LLM-generated data showed dataset-dependent effectiveness, with performance varying by sensor placement and sampling rate

## Why This Works (Mechanism)

### Mechanism 1
Text-to-motion models capture joint-specific biomechanical variations better than text-to-text models by generating 3D joint trajectories from motion datasets, which are then converted to accelerometer data. This works because the motion priors learned from general human motion datasets transfer to fall-specific dynamics without fine-tuning, though instability occurs when sampling rates exceed the model's native temporal resolution.

### Mechanism 2
Few-shot prompting improves text-to-text model output realism at low frequencies by providing 5 example fall samples as context, but introduces noise at high frequencies due to the models' inability to maintain precision across more data points. The LLM's pattern-matching on few-shot examples generalizes to produce statistically similar sequences, but this breaks down when examples don't match the target dataset's fall type diversity.

### Mechanism 3
Diffusion-TS achieves best distributional alignment by learning the temporal patterns and distribution of real fall data through denoising, but doesn't always improve downstream classification because it replicates learned patterns rather than introducing novel fall dynamics. The assumption that distributional similarity translates to improved model generalization fails when the baseline dataset has complex fall patterns that synthetic data doesn't structurally match.

## Foundational Learning

- **Accelerometer Signal Representation**: Understanding how 3-axis accelerometer data captures human movement as time-series, and how sampling rate affects temporal granularity. Quick check: Given a 20Hz sensor, how many samples are captured during a 4-second fall event?

- **Text-to-Motion vs Text-to-Text Generation Paradigms**: The paper evaluates fundamentally different approaches—one generates motion sequences that must be post-processed, the other generates sensor data directly. Quick check: Why might a model trained on HumanML3D (full-body motion) struggle to produce realistic wrist-only accelerometer data?

- **Distributional Alignment Metrics (JSD, Coverage)**: The paper uses Jensen-Shannon Divergence and Coverage to quantify how closely synthetic data matches real data distributions. Quick check: If a model achieves low JSD but low Coverage, what does this indicate about the synthetic data?

## Architecture Onboarding

- **Component map**: Data Generation Layer (text-to-motion models → joint extraction → acceleration computation; text-to-text models → direct CSV generation via prompting) → Baseline Datasets (SMM, KFall, UMAFall, SisFall) → Evaluation Pipeline (LSTM classifier with Leave-Two-Out cross-validation) → Comparison Benchmark (Diffusion-TS)

- **Critical path**: 1. Select baseline dataset → identify sensor placement and sampling rate 2. Generate synthetic falls using appropriate model class 3. Augment training data (60% ADL, 20% real falls, 20% synthetic falls) 4. Train LSTM classifier → evaluate on held-out subjects

- **Design tradeoffs**: Text-to-motion offers better biomechanical realism but requires joint index selection and acceleration derivation; text-to-text provides direct output but struggles with temporal precision; Diffusion-TS achieves best statistical alignment but may lack fall-specific diversity; zero-shot is faster but less realistic while few-shot improves realism at low frequencies but introduces noise at high frequencies

- **Failure signatures**: Performance degradation with left wrist sensors (low motion variability), reverse trend in few-shot at 100Hz+ (noise amplification), mismatch between fall representation (impact-only vs transitional movements)

- **First 3 experiments**: 1. Replicate UMAFall experiment (20Hz, waist sensor) with text-to-motion T2M model to verify +16-28% F1-score improvement 2. Test few-shot vs zero-shot prompting on high-frequency dataset (SisFall at 200Hz) to observe noise introduction effect 3. Fine-tune text-to-motion model on real fall data subset, then evaluate cross-dataset generalization

## Open Questions the Paper Calls Out

### Open Question 1
Can fine-tuning text-to-motion models on limited real-world fall datasets enable them to generate biomechanically accurate, demographic-specific (e.g., elderly) fall data? This remains unresolved because pre-trained LLMs failed to differentiate age-specific patterns statistically, and collecting real elderly data is ethically problematic. Evidence would be a fine-tuned model generating statistically distinct distributions for different age groups that improves detection on elderly-specific datasets.

### Open Question 2
What architectural modifications are required to ensure LLMs generate stable, high-fidelity synthetic data for high-frequency sensors (e.g., 200Hz)? This is unresolved because models performed well at 20Hz but showed instability and performance drops at 200Hz due to lost specificity. Evidence would be a model generating 200Hz data maintaining low JSD and improving F1-scores comparable to low-frequency improvements.

### Open Question 3
Can lightweight generative models be optimized for edge devices to generate reliable synthetic data without cloud-based API dependencies? This remains open because reliance on chatbot APIs introduces variability, and marginal performance gains are often lost during model quantization for wearable deployment. Evidence would be a locally fine-tuned model running on a wearable prototype generating effective synthetic data without cloud connectivity.

## Limitations

- Model-specific inference details missing for text-to-motion models and Diffusion-TS architecture
- Dataset-specific performance variability highly dependent on sensor placement and sampling rate
- Few-shot prompt selection ambiguity significantly impacts results, especially at high frequencies
- Left wrist sensors show particularly weak performance due to low motion variability and representation mismatch

## Confidence

- **High confidence**: Text-to-motion models produce more realistic biomechanical data than text-to-text models; diffusion-TS achieves best distributional alignment; LLM-generated data improves fall detection in low-frequency datasets (20Hz)
- **Medium confidence**: Few-shot prompting improves realism but introduces noise at high frequencies; LLM-generated data is less effective than diffusion-based methods overall; performance degradation with left wrist sensors
- **Low confidence**: Cross-dataset generalization of LLM-generated data; optimal sensor placement for synthetic data augmentation; stability of LLM approaches at 50-100Hz range

## Next Checks

1. Replicate the UMAFall experiment (20Hz, waist sensor) with text-to-motion T2M model to verify the +16-28% F1-score improvement pattern reported.

2. Test few-shot vs zero-shot prompting on a high-frequency dataset (e.g., SisFall at 200Hz) to observe the noise introduction effect and validate the reverse trend observation.

3. Fine-tune a text-to-motion model on a small subset of real fall data from one dataset, then evaluate cross-dataset generalization to SMM and SisFall to assess transfer learning potential.