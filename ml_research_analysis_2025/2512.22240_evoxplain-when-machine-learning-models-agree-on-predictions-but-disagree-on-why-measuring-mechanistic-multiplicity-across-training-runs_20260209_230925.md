---
ver: rpa2
title: 'EvoXplain: When Machine Learning Models Agree on Predictions but Disagree
  on Why -- Measuring Mechanistic Multiplicity Across Training Runs'
arxiv_id: '2512.22240'
source_url: https://arxiv.org/abs/2512.22240
tags:
- explanation
- across
- evoxplain
- training
- basins
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EvoXplain is a diagnostic framework that quantifies the stability
  of machine learning explanations across repeated training runs. Instead of assuming
  a single, stable explanation, EvoXplain treats explanations as samples from the
  training pipeline and clusters them to detect whether multiple distinct explanatory
  modes exist.
---

# EvoXplain: When Machine Learning Models Agree on Predictions but Disagree on Why -- Measuring Mechanistic Multiplicity Across Training Runs

## Quick Facts
- arXiv ID: 2512.22240
- Source URL: https://arxiv.org/abs/2512.22240
- Reference count: 6
- Models frequently produce two or more well-separated explanation basins, even at near-identical hyperparameter configurations

## Executive Summary
EvoXplain is a diagnostic framework that quantifies the stability of machine learning explanations across repeated training runs. Instead of assuming a single, stable explanation, EvoXplain treats explanations as samples from the training pipeline and clusters them to detect whether multiple distinct explanatory modes exist. Applied to Logistic Regression and Random Forests on Breast Cancer and COMPAS datasets, the method reveals that high predictive accuracy does not imply explanation stability. Models frequently produce two or more well-separated explanation basins, even at near-identical hyperparameter configurations, with normalized mechanistic entropy near maximal values (0.83–0.94).

## Method Summary
EvoXplain measures explanation stability by running multiple training instantiations of the same model class on identical train-test splits, then clustering the resulting SHAP-based feature attributions. For each split, R=1000 models are trained with varying regularization strengths, SHAP values are computed on the test set, and global importance vectors are ℓ2-normalized. K-means clustering (k=2,…,K_max) identifies distinct explanation basins, with silhouette scores determining whether multiplicity exists. Normalized mechanistic entropy quantifies the degree of explanation diversity, and disagreement scores measure prediction variance across models for individual instances.

## Key Results
- On Breast Cancer, 76 test instances showed probability disagreement exceeding 0.1, and the maximum observed disagreement reached 0.68, despite comparable accuracy
- Even linear models exhibited structured, low-dimensional explanation manifolds with recurrent basins, confirming that multiplicity is a property of the training pipeline rather than noise
- Models frequently produce two or more well-separated explanation basins, even at near-identical hyperparameter configurations, with normalized mechanistic entropy near maximal values (0.83–0.94)

## Why This Works (Mechanism)
EvoXplain works by treating explanation vectors as samples from a training pipeline distribution and applying unsupervised clustering to detect multimodality. The method assumes that if explanations cluster into distinct basins with high silhouette scores, this indicates genuine mechanistic multiplicity rather than noise. By normalizing explanation vectors and using silhouette-based thresholding, the framework distinguishes between stable multiplicity (well-separated basins) and stochastic variation (single basin with high variance).

## Foundational Learning
- **SHAP attribution**: Local feature importance scores explaining individual predictions; needed because global explanation vectors require aggregation across samples
- **ℓ2 normalization**: Ensures clustering operates on explanation direction rather than magnitude; quick check: verify all vectors have unit norm
- **Silhouette score**: Measures cluster separation quality; needed to distinguish true multiplicity from noise; quick check: plot S(k) curves to verify peak locations
- **Normalized mechanistic entropy**: Quantifies diversity across basins; needed to provide scalar measure of multiplicity; quick check: verify H∈[0,1] and compute baseline for uniform distribution
- **k-means clustering**: Assumes spherical explanation basins; needed for efficient computation; quick check: compare silhouette scores across different k values
- **Basin support**: Fraction of models in each cluster; needed to quantify relative prevalence of explanation modes; quick check: verify ∑support=1 across basins

## Architecture Onboarding
**Component Map**: Data -> Train R models -> Compute SHAP -> ℓ2-normalize explanations -> Cluster with k-means -> Compute silhouette scores -> Determine k* and entropy

**Critical Path**: The clustering step is most sensitive to hyperparameters; silhouette threshold τ=0.25 determines whether multiplicity is detected. If all runs collapse to k*=1, verify that C varies across runs; fixed regularization yields single basin.

**Design Tradeoffs**: K-means assumes spherical basins and equal variance; alternative methods (hierarchical clustering) may better capture non-spherical explanation manifolds but increase computational cost. The silhouette threshold is arbitrary and may not generalize across datasets.

**Failure Signatures**: 
- All runs collapse to k*=1: indicates insufficient hyperparameter variation or normalization issues
- Silhouette scores much lower than reported (0.76–0.82 for Breast Cancer): suggests explanation vectors are not properly normalized or SHAP computation errors
- High entropy but k*=1: indicates single basin with high internal variance rather than true multiplicity

**First Experiments**:
1. Run EvoXplain on Breast Cancer with fixed C=1.0 for all R models; expect k*=1 as control
2. Apply EvoXplain to synthetic dataset with known ground-truth causal structures to validate basin interpretation
3. Compare k-means clustering with hierarchical agglomerative clustering on same explanation vectors

## Open Questions the Paper Calls Out
- Do models that function similarly, internally follow the same mechanism, or do they split into distinct explanatory modes at scale?
- Does mechanistic multiplicity persist when operationalizing interpretability through non-attribution methods, such as counterfactuals or symbolic rules?
- Do the discovered explanation basins correspond to distinct, verifiable causal mechanisms, or are they artifacts of the optimization landscape?

## Limitations
- Silhouette threshold of 0.25 for detecting multiple basins is arbitrary and may not generalize; sensitivity analysis needed
- Fixed hyperparameter grid for Logistic Regression may not fully explore solution space; random sampling could provide better coverage
- Novel normalized mechanistic entropy metric is not benchmarked against established diversity measures

## Confidence
- Core claim (explanation multiplicity is structural property): Medium
- Specific entropy values and basin counts: Medium
- Generalization to other datasets and model classes: Low
- Causal interpretation of basins: Low

## Next Checks
1. Re-run EvoXplain with silhouette thresholds τ∈{0.15, 0.20, 0.30} to test sensitivity of k* and entropy to this hyperparameter
2. Replace k-means clustering with hierarchical agglomerative clustering (Ward linkage) and compare basin counts and supports
3. Apply the pipeline to a different tabular dataset (e.g., UCI Adult) with a Random Forest to assess whether multiplicity is dataset-specific or a general ML phenomenon