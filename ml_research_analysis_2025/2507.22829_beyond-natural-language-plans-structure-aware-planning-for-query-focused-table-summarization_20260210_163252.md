---
ver: rpa2
title: 'Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused
  Table Summarization'
arxiv_id: '2507.22829'
source_url: https://arxiv.org/abs/2507.22829
tags:
- table
- plan
- execution
- query
- structured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles query-focused table summarization, where the
  challenge is generating concise summaries tailored to user queries from tabular
  data. Existing methods rely on natural language plans, which are ambiguous and hinder
  reliable execution, especially in multi-table scenarios.
---

# Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization

## Quick Facts
- arXiv ID: 2507.22829
- Source URL: https://arxiv.org/abs/2507.22829
- Authors: Weijia Zhang; Songgaojun Deng; Evangelos Kanoulas
- Reference count: 9
- One-line primary result: SPaGe achieves up to 45.7 BLEU and 73.4 METEOR on QFMTS with 98.2% execution success rate

## Executive Summary
This paper addresses query-focused table summarization by introducing TaSoF, a structured plan format, and SPaGe, a framework that uses structured planning and graph-based execution. Existing methods rely on natural language plans, which are ambiguous and hinder reliable execution, especially in multi-table scenarios. SPaGe outperforms prior models on three benchmarks (FeTaQA, QTSumm, QFMTS), achieving significant gains in both execution success rate (98.2%) and summary quality metrics.

## Method Summary
SPaGe is a three-phase framework that uses GPT-4o-mini for structured planning, graph-based execution, and summary generation. The planner generates TaSoF plans - structured class instances with five explicit attributes (ID, OPERATION, SOURCE, CONDITION, OUTPUT) using nine predefined operations. The executor builds a dependency DAG from SOURCE fields, enables parallel SQL generation and execution, and returns intermediate tables. The summary generator synthesizes natural language from the final execution table. Table linearization uses schema plus top-k rows to reduce token costs while maintaining reasoning performance.

## Key Results
- SPaGe achieves 45.7 BLEU and 73.4 METEOR on QFMTS, outperforming prior models
- Structured plans (TaSoF) achieve 98.2% execution success rate vs 95.1% (QPL) and 94.4% (QDMR)
- Graph-based execution reduces average cycles by ~28% on QFMTS (multi-table) compared to sequential execution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured plan formats (TaSoF) improve execution reliability by eliminating linguistic ambiguity inherent in natural language plans.
- Mechanism: Each reasoning step is formalized as a Step class with five explicit attributes (ID, OPERATION, SOURCE, CONDITION, OUTPUT), constraining the output space and providing unambiguous schema links for subsequent SQL generation.
- Core assumption: LLMs can reliably generate structured class instances when provided with a clear schema, and this structured representation translates more accurately to executable SQL than free-form natural language descriptions.
- Evidence anchors:
  - [abstract] "NL plans are inherently ambiguous and lack structure, limiting their conversion into executable programs like SQL"
  - [Section 6.2, Table 4] TaSoF achieves 98.2% execution success rate vs. 95.1% (QPL) and 94.4% (QDMR)
  - [Section 6.4, Table 5] Qualitative examples show NL plans fail due to semantic mismatch (e.g., "duration" not in schema) and incorrect dependency handling; TaSoF explicitly maps to existing columns and step references
  - [corpus] Weak direct corpus support; related work on structured planning (NL2FLOW, CoPERLex) addresses planning formalization but not table-specific execution
- Break condition: If LLM fails to adhere to the structured schema (hallucinates invalid operations or columns), the mechanism degrades to NL-plan reliability levels.

### Mechanism 2
- Claim: Graph-based execution with DAG construction enables parallel processing of independent steps, reducing total execution cycles.
- Mechanism: The executor parses SOURCE fields to identify inter-step dependencies, constructs a directed acyclic graph where edges represent data flow, and executes steps in parallel when they share no dependencies. Execution cycles equal the longest path length in the DAG rather than the total step count.
- Core assumption: Steps in multi-table scenarios frequently operate on independent input tables or intermediate results, creating parallelizable opportunities.
- Evidence anchors:
  - [Section 4.3] "An edge eij exists if the output table from step si is used as input to step sj"
  - [Section 6.3, Figure 4] Graph-based execution reduces average cycles by ~28% on QFMTS (multi-table) compared to sequential execution
  - [Section 6.3] "This improvement is due to QFMTS involving multi-table inputs, where steps are more likely to operate on different input or intermediate tables"
  - [corpus] No corpus papers directly address DAG-based parallel execution for table reasoning
- Break condition: If most steps are serially dependent (long dependency chains), parallelization gains diminish toward zero.

### Mechanism 3
- Claim: Schema-only (or top-k row) table linearization retains reasoning performance while reducing token costs.
- Mechanism: Instead of linearizing entire tables, only column headers and the top-k rows (k ≪ m) are included in the LLM prompt. The schema provides sufficient grounding for operation planning while dramatically reducing input length.
- Core assumption: Query-relevant information for planning is primarily derived from column names and schema structure, not from exhaustive row inspection.
- Evidence anchors:
  - [Section 4.2] "Our experiments show that the table schema (i.e., column headers) plays the most critical role"
  - [Section 4.2] "Including only the top-k rows (k ≪ m) retains performance while significantly reducing token usage"
  - [corpus] No direct corpus validation; related work (MultiTabQA, FACTS) uses full table linearization or alternative encoding strategies
- Break condition: If query-relevant information is distributed across rare rows not captured in top-k sampling, planning quality may degrade.

## Foundational Learning

- Concept: SQL Query Generation from Structured Specifications
  - Why needed here: The executor must convert each TaSoF step (operation, source, condition, output) into valid SQL. Understanding how mapping operations (Scan, Join, Aggregate, etc.) translate to SQL clauses is essential for debugging execution failures.
  - Quick check question: Given a step with OPERATION="Join", SOURCE=["Step1", "Step2"], CONDITION="Step1.ID = Step2.DeptID", what SQL JOIN clause would this generate?

- Concept: Directed Acyclic Graphs (DAG) and Topological Execution
  - Why needed here: The framework models plan steps as DAG nodes and executes them in topological order with parallel dispatch for independent nodes. Understanding cycle detection and longest-path computation is required to implement the execution scheduler.
  - Quick check question: Given steps A→C, B→C, B→D with no other dependencies, which steps can execute in parallel, and how many cycles are needed?

- Concept: Structured Output / Constrained Decoding for LLMs
  - Why needed here: The planner must generate valid TaSoF instances (JSON-like class instances with specific fields). Modern LLMs support structured output modes (e.g., JSON schema, function calling) that enforce schema adherence.
  - Quick check question: If an LLM generates a step with OPERATION="Merge" (not in the 9 allowed operations), what failure mode would occur and how would you detect it?

## Architecture Onboarding

- Component map:
  - Planner (LLM-based) -> Executor (LLM + code interpreter) -> Summary Generator (LLM)
  - Critical path: Table linearization (schema + top-k rows) -> Structured planning with schema-constrained LLM output -> DAG construction from SOURCE field references -> Parallel SQL generation and execution per DAG level -> Summary synthesis from final result table

- Critical path:
  1. Table linearization (schema + top-k rows)
  2. Structured planning with schema-constrained LLM output
  3. DAG construction from SOURCE field references
  4. Parallel SQL generation and execution per DAG level
  5. Summary synthesis from final execution table

- Design tradeoffs:
  - Schema-only vs. full table: Reduces tokens but may miss row-specific patterns; paper claims schema is most critical but provides no ablation values for k
  - SQL vs. Python execution: SQL chosen for database compatibility; Python would offer more flexibility but less standardization
  - 9 fixed operations vs. open-ended: Constrained operation set improves reliability but may limit expressiveness for edge-case queries

- Failure signatures:
  - Invalid operation: LLM generates operation not in Table 1 -> execution fails at SQL generation
  - Missing step reference: SOURCE references non-existent step ID -> DAG construction error
  - Schema hallucination: CONDITION references column not in table schema -> SQL execution error
  - Cycle in dependencies: If SOURCE creates circular reference -> DAG assumption violated (paper states DAG but does not describe cycle handling)

- First 3 experiments:
  1. Ablation on k (rows included): Vary k ∈ {0, 1, 3, 5, 10} and measure BLEU/ROUGE/METEOR and token count to validate the claim that schema + minimal rows suffices.
  2. Plan format comparison with error analysis: Run SPaGe with TaSoF vs. QPL vs. QDMR on held-out queries; categorize execution failures (syntax errors, schema errors, dependency errors) to isolate where structure helps most.
  3. Parallelization efficiency benchmark: On multi-table datasets, measure wall-clock time for sequential vs. DAG execution across varying plan depths (2–10 steps) to quantify efficiency gains beyond cycle counts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the SPaGe framework be adapted to outperform prompt-based models on datasets with complex, non-standard table structures, such as those with multi-level or nested headers?
- Basis in paper: [explicit] The authors note in the results that prompt-based models outperform SPaGe on QTSumm because "Tables... often have multi-level and nested headers. SQL queries struggle with these complex structures," limiting the effectiveness of the program-augmented approach.
- Why unresolved: The current execution relies on SQL generation, which is inherently suited for standard relational tables but brittle for nested schemas.
- What evidence would resolve it: Demonstrating a modified execution engine (e.g., using Python Pandas or hierarchical querying) that closes the performance gap with prompt-based methods on the QTSumm benchmark.

### Open Question 2
- Question: Can the TaSoF structured planning paradigm be effectively transferred to other table-reasoning tasks, such as Question Answering or Fact Verification, without significant architectural changes?
- Basis in paper: [inferred] The related work section identifies "table question answering" and "table fact verification" as critical challenges in table understanding, yet the experiments are restricted solely to query-focused summarization.
- Why unresolved: The summary generation phase is specific to the current task; it is unclear if the intermediate structured plans are sufficiently expressive to support final outputs that are discrete answers or boolean verifications.
- What evidence would resolve it: Applying the SPaGe framework to benchmarks like TabFact or WikiTQ and reporting comparable success rates in execution and answer accuracy.

### Open Question 3
- Question: How robust is the structured planning generation when using smaller, open-source LLMs compared to the GPT-4o-mini backbone used in the study?
- Basis in paper: [inferred] The implementation explicitly uses `gpt-4o-mini` for the planner, executor, and generator. It is unstated whether smaller models can reliably adhere to the strict TaSoF class schema required for high execution success rates.
- Why unresolved: The structured output capability of larger proprietary models may be a hidden prerequisite for the 98.2% execution success rate; smaller models may hallucinate invalid attributes.
- What evidence would resolve it: An ablation study replacing GPT-4o-mini with models like Llama-3-8B or Mistral-7B to measure the drop in valid SQL generation and execution success.

## Limitations

- The paper does not provide ablation studies for the top-k row parameter k, making it difficult to quantify the exact tradeoff between token efficiency and reasoning performance.
- The mechanism for cycle detection and handling in the DAG scheduler is not described, despite the paper assuming DAG structure.
- The code interpreter implementation details and error recovery strategy are unspecified, which could significantly impact the reported 98.2% execution success rate.

## Confidence

- **High confidence** in the structured plan format improving execution reliability (98.2% vs 95.1% ESR with strong empirical evidence and clear mechanism)
- **Medium confidence** in graph-based parallel execution efficiency gains (reported cycle reduction but lacks wall-clock timing data and describes no cycle handling)
- **Low confidence** in schema-only linearization sufficiency (claims schema is most critical but provides no ablation values for k parameter)

## Next Checks

1. Run SPaGe with TaSoF vs QPL vs QDMR on held-out queries; categorize execution failures (syntax errors, schema errors, dependency errors) to isolate where structure helps most
2. Measure wall-clock time for sequential vs DAG execution across varying plan depths (2–10 steps) on multi-table datasets to quantify efficiency gains beyond cycle counts
3. Vary k ∈ {0, 1, 3, 5, 10} in table linearization and measure BLEU/ROUGE/METEOR and token count to validate the claim that schema + minimal rows suffices