---
ver: rpa2
title: 'SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific
  Trajectory'
arxiv_id: '2508.11290'
source_url: https://arxiv.org/abs/2508.11290
tags:
- over-refusal
- task
- steering
- layer
- harmful
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SafeConstellations addresses LLM over-refusal by steering internal
  representations through task-specific trajectory analysis. The method identifies
  distinct "constellation" patterns in embedding space for each task and selectively
  adjusts model behavior at key layers during inference.
---

# SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory

## Quick Facts
- **arXiv ID:** 2508.11290
- **Source URL:** https://arxiv.org/abs/2508.11290
- **Reference count:** 10
- **Primary result:** Reduces LLM over-refusal by up to 73% while maintaining model utility, with minimal impact on general task performance like MMLU.

## Executive Summary
SafeConstellations addresses the over-refusal problem in large language models by steering internal representations through task-specific trajectory analysis. The method identifies distinct "constellation" patterns in embedding space for each task type and selectively adjusts model behavior at key layers during inference. By tracking these patterns and applying targeted steering, the approach reduces over-refusal rates by up to 72.92% while maintaining model utility on general tasks like MMLU.

## Method Summary
The method constructs a memory bank of task-specific trajectory patterns by analyzing hidden states at each layer for benign and over-refusal responses. During inference, it identifies the task, dynamically selects the most effective layers for steering, computes trajectory health to modulate intervention intensity, and applies steering vectors to guide representations toward non-refusal pathways. The approach uses adaptive layer selection and intensity modulation to avoid the utility degradation seen in fixed-layer interventions.

## Key Results
- Over-refusal reduction of 72.92% on tested tasks (sentiment analysis, translation, RAG-QA)
- MMLU accuracy maintained at 46.57% for LLaMA-3.1-8B-Instruct
- Dynamic layer selection outperforms fixed-layer approaches by 66.67 percentage points in over-refusal reduction

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs encode task identity via consistent internal trajectory patterns across layers, enabling task-specific steering without disrupting general capabilities.
- **Mechanism:** Hidden representations at each layer form distinct "constellation" patterns for each task type. These trajectories are invariant to input content and cluster tightly by task. Steering vectors computed as the difference between target (non-refusal) and over-refusal centroids guide representations toward non-refusal pathways.
- **Core assumption:** Task identity crystallizes in late-layer representations and is separable from lexical features that trigger safety mechanisms.
- **Evidence anchors:**
  - [abstract]: "LLMs follow distinct 'constellation' patterns in embedding space as representations traverse layers, with each task maintaining consistent trajectories that shift predictably between refusal and non-refusal cases."
  - [section 3.2]: "Figure 2 shows that both trajectories belonging to the same task cluster tightly, validating that LLMs encode task identity beyond raw lexical features."
  - [corpus]: Related work (Gueta et al. 2023) found that LLMs encode task-specific information in weight space.
- **Break condition:** If trajectories for different tasks overlap significantly or if steering vectors harm benign-refusal separation, the mechanism fails.

### Mechanism 2
- **Claim:** Trajectory health assessment enables adaptive steering intensity, applying stronger intervention when representations are closer to refusal centroids and backing off when aligned with target behavior.
- **Mechanism:** At inference, the method computes trajectory health as a normalized difference between cosine similarity to target centroid and cosine similarity to refusal centroid. Steering intensity is modulated by (1 - Health), meaning interventions are stronger when representations drift toward refusal patterns.
- **Core assumption:** The cosine distance between current hidden state and pre-computed centroids reliably indicates behavioral intent before output generation.
- **Evidence anchors:**
  - [section 3.3]: "Steering intensity is then set by λ(ℓ) = λ₀(1 − Health(ℓ)) · Confidence · κ(ℓ)"
  - [section 5]: "Including trajectory health assessment reduces over-refusal cases by 2.08%."
  - [corpus]: No direct corpus evidence for trajectory-health modulation.
- **Break condition:** If health scores become unreliable, steering may under- or over-correct.

### Mechanism 3
- **Claim:** Dynamic layer selection identifies layers with highest steering potential per-instance, avoiding fixed-layer interventions that either under-perform or degrade utility.
- **Mechanism:** For each input, layers are ranked by steering potential, which measures relative proximity to refusal vs. target centroids. Top K' = 4 layers are selected. Additionally, pre-computed effectiveness scores rank layers by separation magnitude normalized by cluster variance.
- **Core assumption:** Not all layers contribute equally to refusal decisions; mid-to-late layers and final normalization layers are more consequential for behavioral outcomes.
- **Evidence anchors:**
  - [section 3.2]: "Only the top-K layers (K = 5) are retained per task."
  - [section 5, Table 2]: "Fixed Layers [15,20,25,30]" achieves only 6.25% reduction with MMLU drop to 39.20%; dynamic selection achieves 72.92% reduction with no MMLU drop.
  - [corpus]: Related work "Jailbreak Antidote" (Shen et al. 2025) found safety-critical representations are sparsely distributed.
- **Break condition:** If dynamically selected layers vary inconsistently across inputs or tasks, steering becomes unpredictable.

## Foundational Learning

- **Concept: Representation Steering**
  - **Why needed here:** SafeConstellations modifies hidden states during inference; understanding how activation interventions affect output requires grasp of steering vector mechanics.
  - **Quick check question:** Given steering vector v = c_target − c_refusal, what happens if λ is too large? (Answer: representations overshoot target region, causing incoherent outputs or utility collapse.)

- **Concept: Embedding Space Geometry**
  - **Why needed here:** The method relies on computing centroids, cosine similarities, and trajectory distances; intuition for high-dimensional clustering is essential.
  - **Quick check question:** Why does the paper use cosine similarity rather than Euclidean distance for trajectory health? (Answer: Cosine similarity normalizes for magnitude, focusing on directional alignment.)

- **Concept: Over-Refusal Phenomenon**
  - **Why needed here:** Understanding why models refuse benign inputs clarifies what steering must correct.
  - **Quick check question:** If a model refuses "Translate to Spanish: 'How to kill a Python process'" but answers "Translate to Spanish: 'How to terminate a Python program'", what does this suggest about the refusal trigger? (Answer: Keyword-level matching on "kill" rather than semantic intent understanding.)

## Architecture Onboarding

- **Component map:**
  1. Memory Bank (M): Stores per-task centroids, steering vectors, and effectiveness scores
  2. Task Identification Module: Computes average cosine similarity between input trajectory and stored task trajectories
  3. Dynamic Layer Selector: Ranks layers by steering potential and selects K' = 4 layers per inference
  4. Steering Applicator: Applies h̃(ℓ) = h(ℓ) + λ(ℓ) · v_t / ||v_t|| at selected layers; gated by confidence threshold and benign-task check

- **Critical path:**
  1. Forward pass computes hidden trajectory {h^(ℓ)} for input x ⊕ t
  2. Task identification: if confidence < 0.85 OR task ∉ T_benign → return original response
  3. Layer selection: compute Pot(ℓ) for all layers, select top 4
  4. Per-layer: compute Health(ℓ), derive λ(ℓ), apply steering
  5. Continue forward pass with modified representations

- **Design tradeoffs:**
  - K vs. K': Memory bank stores K=5 layers per task; steering uses K'=4 dynamically
  - λ₀ base intensity: Set to 0.3 with depth-dependent multipliers
  - Task scope: Rephrasing excluded from T_benign due to ambiguous intent

- **Failure signatures:**
  - Garbled/repetitive output: Indicates λ too high or steering applied at wrong layers
  - No reduction in over-refusal: Confidence threshold too strict or centroids poorly separated
  - MMLU drop: Over-aggressive steering contaminates general representations

- **First 3 experiments:**
  1. Reproduce constellation visualization: Run UMAP on hidden states for translation task with benign/harmful inputs
  2. Ablate dynamic layer selection: Compare K'=4 dynamic vs. fixed layers [15,20,25,30]
  3. Stress-test confidence threshold: Vary τ from 0.70 to 0.95

## Open Questions the Paper Calls Out
- Can the trajectory-steering approach generalize to mitigate other undesirable behaviors, such as hallucination or bias, beyond over-refusal?
- Does SafeConstellations preserve semantic coherence in complex generation tasks better than standard MMLU utility metrics suggest?
- Can adversarial prompts be engineered to mimic the trajectory patterns of benign tasks to bypass the safety mechanisms?

## Limitations
- The method's generalizability to novel task types and robustness against adversarial inputs remain unproven
- Reliance on LLM-as-judge for both training data labeling and evaluation introduces potential circularity
- Performance on general tasks like MMLU is measured on a relatively small subset (29/30 samples)

## Confidence
- **High confidence:** The trajectory-based task identification mechanism works for the tested tasks as evidenced by consistent clustering patterns and the 72.92% over-refusal reduction
- **Medium confidence:** The adaptive steering intensity via trajectory health assessment provides meaningful improvement (2.08% additional reduction)
- **Low confidence:** The method's generalizability to novel task types and its robustness against adversarial inputs that may exploit trajectory patterns remain unproven

## Next Checks
1. Stress-test trajectory stability: Generate 1000 benign and 1000 harmful inputs for each task type, compute their trajectories, and measure inter-class variance
2. Ablate task identification reliability: Systematically remove 25%, 50%, and 75% of training samples from each task type and measure how confidence threshold τ=0.85 affects steering coverage and over-refusal reduction
3. Cross-model transferability: Apply steering vectors trained on LLaMA-3.1-8B-Instruct to Qwen1.5-7B-Chat (and vice versa) without retraining