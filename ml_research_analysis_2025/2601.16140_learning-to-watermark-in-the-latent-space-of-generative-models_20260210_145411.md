---
ver: rpa2
title: Learning to Watermark in the Latent Space of Generative Models
arxiv_id: '2601.16140'
source_url: https://arxiv.org/abs/2601.16140
tags:
- latent
- watermarking
- post-hoc
- watermark
- distilled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DISTSEAL, a unified framework for latent
  space watermarking that works across both diffusion and autoregressive generative
  models. The key innovation is training post-hoc watermarking models in the latent
  space of generative models, then distilling these latent watermarkers either into
  the generative model itself or into the latent decoder to enable in-model watermarking.
---

# Learning to Watermark in the Latent Space of Generative Models

## Quick Facts
- arXiv ID: 2601.16140
- Source URL: https://arxiv.org/abs/2601.16140
- Reference count: 37
- Primary result: Achieves up to 20× speedup over pixel-space watermarking while maintaining competitive robustness through latent space watermarking

## Executive Summary
This paper introduces DISTSEAL, a unified framework for latent space watermarking that works across both diffusion and autoregressive generative models. The key innovation is training post-hoc watermarking models in the latent space of generative models, then distilling these latent watermarkers either into the generative model itself or into the latent decoder to enable in-model watermarking. The approach achieves competitive robustness compared to pixel-space baselines while offering up to 20× speedup during inference. Critically, the experiments show that distilling latent watermarkers is more effective than distilling pixel-space ones, achieving state-of-the-art in-model watermarking for open-source generative models.

## Method Summary
DISTSEAL operates by first training a post-hoc latent watermark embedder and extractor in the compressed latent space of a generative model. The embedder modifies latents by adding small perturbations conditioned on a watermark message, while the extractor recovers the message from watermarked latents or generated images. The framework then distills this watermarking capability into the generative model itself through fine-tuning on watermarked latents, or into the latent decoder through training with reconstruction and extraction losses. For diffusion models, this involves fine-tuning the transformer on watermarked latents; for autoregressive models, it can be applied either before or after quantization, with different tradeoffs for each approach.

## Key Results
- Achieves up to 20× speedup during inference compared to pixel-space watermarking baselines
- DISTSEAL distilled models maintain high watermark robustness (94.78% accuracy) while preserving visual quality (FID 10.90)
- Latent watermarker distillation outperforms pixel-space distillation, achieving 96.77% accuracy vs 92.95% with better FID scores
- The framework successfully handles both continuous latent spaces (diffusion models) and discrete token sequences (autoregressive models)

## Why This Works (Mechanism)

### Mechanism 1: Latent Space Embedding Efficiency
Operating in compressed latent space enables faster watermarking with competitive robustness compared to pixel-space methods. The embedder W_θ modifies latent representations z → z_w = z + εW_θ(z, m) where z ∈ R^{h×w×c} with h < H, w < W. Lower spatial resolution (e.g., 8×8×128 vs 512×512×3) reduces computational cost while the decoder's learned reconstruction preserves watermark signal through to pixel space. Core assumption: The autoencoder's decoder faithfully propagates latent perturbations to detectable pixel patterns without excessive distortion.

### Mechanism 2: Generative Model Distillation via Watermarked Targets
Fine-tuning generative models on watermarked latents produces models that inherently generate watermarked outputs. Replace training targets z with z_w from post-hoc embedder, then fine-tune G_ϕ using L_gen = L_recon(G_ϕ(x), z_w). The model learns to predict/produce watermarked latents during generation, embedding the watermark into the generation process itself. Core assumption: The generative model can learn to produce outputs in the distribution of watermarked latents without quality degradation.

### Mechanism 3: Decoder Distillation with Reconstruction + Extraction Loss
Distilling latent watermarkers into the decoder preserves watermark patterns better than distilling pixel-space watermarkers. Train decoder D using L_dist = L_rec(D_o(z_w), D(z)) + λ_w L_w(E_θ(D(z)), m). The reconstruction term ensures the decoder learns to reproduce the watermarked image patterns; the extraction term reinforces detectability. Latent watermarkers produce more structured perturbations that decoders can learn vs. pixel watermarkers' high-frequency patterns. Core assumption: The decoder has sufficient capacity to learn the mapping from non-watermarked latents to watermarked outputs.

## Foundational Learning

- **Concept: Variational Autoencoders (VAE) and Latent Representations**
  - Why needed here: The entire method operates on compressed latent representations; understanding encoder-decoder architecture, latent space properties, and quantization (for autoregressive models) is essential.
  - Quick check question: Given an image of 256×256 pixels, what is the spatial dimension of latents if the autoencoder uses 16× downsampling?

- **Concept: Watermark Extraction and Robustness Evaluation**
  - Why needed here: Must understand bit accuracy metrics, augmentation-based robustness testing (valuemetric, geometric, compression attacks), and the tradeoff between imperceptibility and detectability.
  - Quick check question: Why might a watermark survive JPEG compression but fail under combined crop+brightness+compression attacks?

- **Concept: Knowledge Distillation**
  - Why needed here: Core technique for transferring post-hoc watermarker capabilities into generative models or decoders; involves training a student model to match teacher outputs.
  - Quick check question: What is the difference between using reconstruction loss alone vs. adding an extraction loss during decoder distillation?

## Architecture Onboarding

- **Component map:** Post-hoc latent watermarker (Embedder W_θ + Extractor E_θ) → Generative models (DCAE diffusion or RAR-XL autoregressive) → Distillation targets (G_ϕ or D)

- **Critical path:**
  1. Train post-hoc latent watermarker on ImageNet (600k steps, discriminator after 200k steps)
  2. Generate watermarked latents using fixed message m
  3. Fine-tune generative model on watermarked latents (100k steps for diffusion, 10k for AR) OR fine-tune decoder with L_rec + L_w (10k steps)
  4. Evaluate with FID/IS for quality; bit accuracy under transformations for robustness

- **Design tradeoffs:**
  - **Generative model vs. decoder distillation:** Gen model = easier optimization, better visual quality, vulnerable to LoRA forgetting; Decoder = more persistent against gen model changes, requires λ_w and λ_p tuning
  - **Before vs. after quantization (AR models):** Before quant = suitable for generative model distillation but lower robustness (90.60% vs 93.96%); After quant = higher robustness but only works for decoder distillation

- **Failure signatures:**
  - PSNR alone is misleading for latent watermarking (lower PSNR but comparable FID)
  - Pixel watermarker distillation fails with reconstruction-only loss (51.38% accuracy)
  - Excessive extractor weight causes overfitting to identity at expense of transformation robustness
  - Watermark forgetting under LoRA fine-tuning on non-watermarked data

- **First 3 experiments:**
  1. Replicate post-hoc latent vs. pixel comparison on DCAE: train both watermarkers with identical schedules, measure bit accuracy and FID on 50k generated images
  2. Distill latent watermarker into DCAE diffusion model: fine-tune on watermarked latents for 100k steps, verify robustness retention (target: ~95% avg accuracy)
  3. Compare decoder distillation with and without extraction loss: test λ_w ∈ {0, 0.1, 0.5} to identify overfitting threshold on combined transformations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can latent space watermarking be effectively extended to video generative models while maintaining the computational efficiency advantages observed for images?
- Basis in paper: The authors state: "As future work, we plan to extend our method to video generative models, as latent watermarking could offer a significant speedup compared to watermarking every frame with pixel watermarking."
- Why unresolved: Video introduces temporal consistency requirements and larger latent representations that may affect both watermark robustness and distillation effectiveness differently than static images.
- What evidence would resolve it: Experiments on video diffusion/autoregressive models measuring speedup, robustness to temporal augmentations, and watermark consistency across frames.

### Open Question 2
- Question: How can the robustness of DISTSEAL against strong geometric transformations be improved, potentially through combination with post-hoc synchronization methods?
- Basis in paper: The authors note: "Our method is still not robust enough against very strong attacks such as some geometric transformations, for which we are exploring the combination with post-hoc synchronisation methods."
- Why unresolved: Geometric transformations like rotation and cropping remain challenging for latent watermarks, and the proposed combination with synchronization methods has not yet been validated.
- What evidence would resolve it: Benchmarks showing improved geometric attack robustness when combining DISTSEAL with synchronization methods like those from Fernandez et al. (2025).

### Open Question 3
- Question: Can watermark forgetting during LoRA fine-tuning be prevented while maintaining the ability to customize generative models?
- Basis in paper: The authors identify this as a limitation: "distilling into the generative transformers is susceptible to forgetting the watermark when fine-tuned on non-watermarked data."
- Why unresolved: LoRA fine-tuning on non-watermarked data causes significant watermark degradation, creating a tension between model customizability and watermark persistence.
- What evidence would resolve it: Methods that preserve watermark detection accuracy above 90% after LoRA fine-tuning, or alternative fine-tuning approaches that maintain watermark integrity.

## Limitations

- Decoder capacity constraints limit effectiveness of decoder distillation for some architectures
- Watermark forgetting occurs during LoRA fine-tuning on non-watermarked data
- Quantization constraints create tradeoffs between robustness and applicability of distillation methods

## Confidence

- **High confidence**: Latent space watermarking provides 20× speedup with competitive robustness
- **High confidence**: Decoder distillation with extraction loss outperforms pixel-space distillation
- **Medium confidence**: Generative model distillation balances quality and robustness, but with known vulnerability to forgetting
- **Low confidence**: Generalization to unseen models and real-world conditions

## Next Checks

1. Evaluate watermark persistence under sequential fine-tuning: Apply multiple rounds of LoRA fine-tuning on non-watermarked data to quantify forgetting rate and test mitigation strategies.
2. Benchmark on diverse model architectures: Test DISTSEAL on additional diffusion (e.g., Stable Diffusion) and autoregressive models (e.g., Llama) to assess architectural generalizability.
3. Stress-test under real-world attack scenarios: Deploy the distilled models in a mock production setting with user-generated adversarial transformations to measure practical robustness limits.