---
ver: rpa2
title: Curiosity Driven Knowledge Retrieval for Mobile Agents
arxiv_id: '2601.19306'
source_url: https://arxiv.org/abs/2601.19306
tags:
- knowledge
- agent
- agents
- appcards
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a curiosity-driven knowledge retrieval framework
  for mobile agents, addressing the challenge of incomplete knowledge and weak generalization
  in complex applications. The core method quantifies uncertainty during execution
  as a curiosity score, triggering external knowledge retrieval when it exceeds a
  threshold.
---

# Curiosity Driven Knowledge Retrieval for Mobile Agents

## Quick Facts
- **arXiv ID:** 2601.19306
- **Source URL:** https://arxiv.org/abs/2601.19306
- **Reference count:** 40
- **Primary result:** Introduces curiosity-driven knowledge retrieval framework achieving 88.8% success rate on AndroidWorld with GPT-5

## Executive Summary
This paper presents a curiosity-driven knowledge retrieval framework for mobile agents that addresses incomplete knowledge and weak generalization in complex applications. The method quantifies epistemic uncertainty during execution as a curiosity score, triggering external knowledge retrieval when it exceeds a threshold. Retrieved content is organized into structured AppCards encoding functional semantics, parameter conventions, and interaction patterns. The agent selectively integrates relevant AppCards into its reasoning process to compensate for knowledge blind spots. Evaluation on the AndroidWorld benchmark demonstrates consistent improvements across backbone models, with GPT-5 achieving a new state-of-the-art success rate of 88.8%.

## Method Summary
The framework formalizes uncertainty during execution as a curiosity score using tail-adjusted Jensen-Shannon divergence between prior predictive and posterior distributions. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, the agent selectively integrates relevant AppCards into its reasoning process. The approach is particularly effective for multi-step and cross-application tasks, reducing ambiguity, shortening exploration, and supporting stable execution trajectories.

## Key Results
- Achieves 88.8% success rate on AndroidWorld benchmark with GPT-5, setting new state-of-the-art
- AppCards are particularly effective for multi-step and cross-application tasks
- Framework reduces ambiguity, shortens exploration, and supports stable execution trajectories
- Knowledge integration effectiveness varies significantly with backbone model capacity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Quantifying epistemic uncertainty via distributional divergence provides a principled signal for when to seek external knowledge.
- **Mechanism:** The agent generates a prior predictive distribution P for the next interface state given current state and action. After observing the actual state, it produces a posterior distribution Q. The tail-adjusted Jensen-Shannon divergence between P and Q measures information gain—larger divergence indicates greater knowledge deficit. This cumulative uncertainty triggers retrieval when exceeding threshold τ.
- **Core assumption:** Token-level distributional divergence correlates with functional knowledge gaps about application behavior.
- **Evidence anchors:**
  - [abstract] "formalizes uncertainty during execution as a curiosity score... when this score exceeds a threshold, the system retrieves external information"
  - [section 3.2] Equations 5-9 define JS*-divergence with tail adjustment; Equation 10 defines cumulative uncertainty accumulation
  - [corpus] Related work "In-Context Curiosity" (arxiv:2510.00347) similarly uses curiosity signals for decision-pretrained transformers, suggesting cross-domain validity of the approach
- **Break condition:** If prior-posterior divergence reflects UI randomness rather than knowledge gaps (e.g., dynamic content, animations), the curiosity signal becomes noisy and retrieval triggers become spurious.

### Mechanism 2
- **Claim:** Structured knowledge representations (AppCards) enable selective, interpretable injection of application-specific semantics into agent reasoning.
- **Mechanism:** Retrieved content from documentation, code repositories, and historical trajectories is consolidated into modular AppCards encoding: (1) functional semantics, (2) input/output constraints, (3) interface-to-function mappings, (4) interaction patterns. Only relevant AppCards are injected into the system prompt based on task requirements.
- **Core assumption:** Compressing heterogeneous sources into unified structured format preserves critical information while reducing context window burden.
- **Evidence anchors:**
  - [abstract] "Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns"
  - [section 3.3] "Each AppCard is constructed for a single application with the objective of compressing unstructured information into modular knowledge units"
  - [appendix B] Concrete AppCard examples for Gallery, VLC, OsmAnd, Contacts, Pro Expense applications
  - [corpus] Mobile-Agent-RAG (arxiv:2511.12254) similarly addresses "excessive reliance on static, internal knowledge" via contextual knowledge, providing convergent evidence
- **Break condition:** If AppCards become stale (app updates) or incomplete (undocumented features), injected knowledge misaligns with actual interface behavior.

### Mechanism 3
- **Claim:** Backbone model capacity strongly moderates the effectiveness of external knowledge integration.
- **Mechanism:** The framework provides identical AppCards across models, but utilization varies. Stronger models (GPT-5: 84.5%→88.8%) reliably absorb and apply structured knowledge; weaker models (Grok-4-Fast: 61.2%→60.3%) may fail to integrate or misapply AppCards, especially on hard tasks.
- **Core assumption:** Knowledge injection benefits scale with model reasoning capability rather than being universally applicable.
- **Evidence anchors:**
  - [section 4.2] "Grok-4-fast decreases from 61.2% to 60.3% in version v0.3.9, showing no benefit from AppCards... For weaker or stylistically mismatched models, AppCards may not be fully utilized"
  - [section 4.3, table 2] GPT-5 improves on hard tasks by 21 percentage points; Grok-4-fast declines by 21 points on hard tasks with AppCards
  - [corpus] Corpus evidence is weak on this specific mechanism—no direct replication of model-dependent knowledge integration effects found in neighbor papers
- **Break condition:** If model-appcard alignment issues are systematic rather than capacity-related, simply using stronger models won't resolve integration failures.

## Foundational Learning

- **Concept: Jensen-Shannon Divergence**
  - Why needed here: Core mathematical tool for measuring distributional difference between prior predictions and posterior observations; must understand symmetry and boundedness advantages over KL divergence.
  - Quick check question: Can you explain why JS divergence is preferred over KL divergence when both P and Q are uncertain estimates?

- **Concept: Epistemic vs. Aleatoric Uncertainty**
  - Why needed here: The framework specifically targets epistemic uncertainty (knowledge gaps reducible through information) rather than aleatoric (inherent randomness); confusion between these leads to misdiagnosing failures.
  - Quick check question: If an app shows a random advertisement each launch, would this increase the curiosity score, and should it trigger retrieval?

- **Concept: Discounted Cumulative Sum**
  - Why needed here: Equation 10 accumulates uncertainty with temporal decay (γ); understanding why single-step signals are insufficient and how discounting balances recent vs. historical uncertainty.
  - Quick check question: Why accumulate curiosity scores rather than trigger retrieval on any single high-uncertainty step?

## Architecture Onboarding

- **Component map:** Uncertainty Estimation → Threshold Check → Retrieval → AppCard Construction → Prompt Injection → Action Generation
- **Critical path:** Uncertainty Estimation → Threshold Check → Retrieval → AppCard Construction → Prompt Injection → Action Generation. The curiosity score computation (prior/posterior distribution extraction and JS* calculation) is the computational bottleneck.
- **Design tradeoffs:**
  - Threshold τ: Lower = more retrieval, higher context usage; Higher = fewer interventions, risk of missed knowledge gaps
  - Top-K token selection: Larger K = finer-grained divergence; Smaller K = noisier OTHER bucket
  - Tail adjustment λ: Controls sensitivity to distribution tails vs. main tokens
  - AppCard granularity: Detailed cards improve accuracy but consume context window
- **Failure signatures:**
  - Looping behavior without retrieval trigger: Threshold τ too high for task difficulty
  - Performance degradation with AppCards (Grok-4 pattern): Model-appcard misalignment, especially on hard tasks
  - Spurious retrieval on dynamic content: Curiosity signal not distinguishing epistemic gaps from UI randomness
  - Stale AppCard guidance: App updated but AppCard not regenerated
- **First 3 experiments:**
  1. **Baseline curiosity calibration:** Run agent on AndroidWorld without AppCards, log curiosity scores per step; visualize distribution to set informed threshold τ
  2. **Single-source ablation:** Build AppCards from only D_web, only D_git, only D_traj; compare success rates to identify most valuable knowledge source
  3. **Model-appcard compatibility test:** For a fixed set of AppCards, evaluate multiple backbone models (different capability tiers) on hard cross-app tasks; plot improvement vs. baseline model capability to validate the capacity-dependence hypothesis

## Open Questions the Paper Calls Out
None

## Limitations
- Framework effectiveness highly dependent on backbone model capacity, with weaker models showing performance degradation
- Threshold-based curiosity mechanism may trigger spurious retrievals on applications with inherently random UI elements
- AppCards risk becoming stale when applications update, potentially misguiding the agent with outdated information

## Confidence
- **High Confidence:** The core mechanism of using uncertainty-driven retrieval for knowledge gaps (Mechanism 1) and the effectiveness of AppCards for strong models on AndroidWorld (Mechanism 2) are well-supported by empirical results.
- **Medium Confidence:** The model capacity dependence (Mechanism 3) is demonstrated but requires further validation across different model families and task domains.
- **Low Confidence:** The generalizability of the curiosity signal to distinguish epistemic from aleatoric uncertainty in diverse application contexts remains largely untested.

## Next Checks
1. **Curiosity Signal Validation:** Run controlled experiments on applications with known random UI elements to quantify false positive retrieval rates and refine the tail-adjusted JS* divergence to better distinguish knowledge gaps from inherent randomness.
2. **AppCard Update Mechanism:** Implement and evaluate an automated AppCard refresh system that detects application version changes and triggers knowledge regeneration, measuring impact on long-term agent performance.
3. **Cross-Domain Transfer:** Apply the framework to non-mobile domains (e.g., web automation, robotics) to test whether the curiosity-driven retrieval and AppCard structure generalize beyond Android applications.