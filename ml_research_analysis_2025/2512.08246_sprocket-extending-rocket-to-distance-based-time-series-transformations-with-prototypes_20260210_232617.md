---
ver: rpa2
title: 'SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With
  Prototypes'
arxiv_id: '2512.08246'
source_url: https://arxiv.org/abs/2512.08246
tags:
- distance
- sprocket
- page
- time
- ensemble
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SPROCKET integrates distance-based prototype features into convolutional
  time series classification, creating a hybrid approach that combines ROCKET's random
  convolutional kernels with elastic and non-elastic distance measures computed between
  prototypes and transformed series. On 98 UCR benchmark datasets, SPROCKET alone
  does not outperform existing convolutional methods, but ensembles containing SPROCKET
  (MR-HY-SP and MR-SP) achieve the highest average rankings among convolutional algorithms,
  surpassing previous state-of-the-art HYDRA-MR.
---

# SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With Prototypes

## Quick Facts
- **arXiv ID:** 2512.08246
- **Source URL:** https://arxiv.org/abs/2512.08246
- **Authors:** Nicholas Harner
- **Reference count:** 40
- **Primary result:** Ensembles containing SPROCKET achieve the highest average rankings among convolutional algorithms on 98 UCR benchmark datasets, surpassing HYDRA-MR

## Executive Summary
SPROCKET extends the ROCKET framework by integrating distance-based prototype features into convolutional time series classification. The approach applies ROCKET's random convolutional kernels to time series, then computes elastic (MSM) or non-elastic (Euclidean) distances between each transformed series and a set of randomly selected prototypes from the transformed space. While SPROCKET alone doesn't outperform existing convolutional methods, ensembles combining SPROCKET with MultiROCKET and HYDRA (MR-HY-SP and MR-SP) achieve state-of-the-art average rankings on the UCR benchmark. The Euclidean distance variant offers substantial computational efficiency while maintaining competitive accuracy, demonstrating that prototype-based distance features meaningfully complement convolutional features in ensemble settings.

## Method Summary
SPROCKET creates a hybrid time series classification approach by combining ROCKET's random convolutional kernels with distance-based features computed between prototypes and transformed series. The method applies K=512 random convolutional kernels to all time series, producing transformed representations. From these transformed outputs, M=⌈log4(|X|)⌉ prototypes are selected per kernel using random sampling. Distances (defaulting to MSM with Sakoe-Chiba window ⌊√l⌋, but also tested with Euclidean) are computed between each instance and all prototypes, creating a feature matrix of shape (n_samples, K×M). A RidgeClassifierCV is trained on these distance features. For ensemble methods, SPROCKET features are concatenated with MultiROCKET and HYDRA features, and a single RidgeCV classifier is trained on the combined representation. The approach is evaluated on 98 UCR benchmark datasets with standard train/test splits via Aeon Toolkit.

## Key Results
- Ensembles containing SPROCKET (MR-HY-SP and MR-SP) achieve the highest average rankings among convolutional algorithms on 98 UCR datasets
- Euclidean distance variant is ~67× faster than MSM variant while maintaining competitive accuracy
- SPROCKET alone does not outperform existing convolutional methods, but provides complementary features that enhance ensemble performance
- MR-HY-SP and MR-SP ensembles surpass previous state-of-the-art HYDRA-MR in average ranking

## Why This Works (Mechanism)
SPROCKET works by creating a rich feature representation that combines the local pattern detection capabilities of convolutional kernels with global similarity information captured through prototype distances. The random convolutional kernels extract diverse features from time series, while the distance computations to prototypes capture relative positioning in the transformed space. This hybrid representation provides complementary information: convolutional features capture local temporal patterns while prototype distances capture global structure and similarity relationships. In ensemble settings, these additional distance-based features provide information orthogonal to what convolutional features capture, leading to improved classification performance when combined with existing state-of-the-art methods.

## Foundational Learning
- **ROCKET random convolutional kernels**: Essential for understanding the base transformation; check by verifying kernel generation parameters match ROCKET's implementation
- **Elastic distance measures (MSM)**: Required for understanding distance computation; check by confirming MSM implementation matches UCR distance implementation
- **Prototype-based classification**: Core concept for distance features; check by verifying prototype selection and distance matrix construction
- **Ridge regression for time series**: Important for understanding classifier choice; check by confirming RidgeClassifierCV parameters match paper specifications
- **Time series ensemble methods**: Necessary for understanding MR-HY-SP and MR-SP construction; check by verifying feature concatenation and single classifier training
- **UCR archive benchmark protocols**: Critical for proper evaluation; check by confirming dataset loading and train/test split handling via Aeon Toolkit

## Architecture Onboarding

**Component Map:** Time Series -> ROCKET Kernels -> Transformed Series -> Prototype Selection -> Distance Computation -> Feature Matrix -> Ridge Classifier

**Critical Path:** Kernel transformation → Prototype distance computation → Feature matrix construction → Classifier training/evaluation

**Design Tradeoffs:** Elastic distances (MSM) provide better accuracy but are computationally expensive (~67× slower); Euclidean offers efficiency but may sacrifice some discriminative power. Logarithmic prototype scaling balances feature richness against computational cost.

**Failure Signatures:** Excessive runtime with elastic distances; memory overflow on large datasets; poor accuracy when distance features don't capture meaningful similarities.

**First Experiments:**
1. Implement SPROCKET with Euclidean distance only to verify basic functionality and confirm computational efficiency
2. Test prototype count sensitivity by varying M parameter on small dataset
3. Evaluate ensemble performance by comparing MR-HY-SP with and without SPROCKET features

## Open Questions the Paper Calls Out

**Open Question 1:** Can principled prototype selection strategies (e.g., K-Means++) improve accuracy enough to justify their added computational cost compared to random sampling? The paper deliberately restricted to random sampling as a baseline, noting K-Means++ would approximately double distance calculations required.

**Open Question 2:** How does SPROCKET scale to long time series (length > 500), and can approximation methods mitigate the computational burden? The computational complexity of elastic distances made testing on long series infeasible for this initial study.

**Open Question 3:** What is the theoretical relationship between SPROCKET's prototype features and traditional nearest-neighbor classification? The current paper is empirical proof-of-concept without theoretical justification for why prototype features are effective.

**Open Question 4:** Does the ⌈log4(|X|)⌉ heuristic for the number of prototypes generalize, or do alternative scaling strategies provide better accuracy-efficiency trade-offs? The paper uses fixed function for experimental stability but does not tune or ablate this hyperparameter.

## Limitations
- SPROCKET alone does not outperform existing convolutional methods, requiring ensemble configurations for state-of-the-art performance
- Computational complexity scales super-linearly with time series length, limiting testing to series length ≤500
- Exact ROCKET kernel parameterization details are inherited but not restated, creating implementation ambiguity
- Distance normalization procedures and multivariate handling aggregation methods remain unspecified

## Confidence
- **High Confidence**: Ensemble performance claims (MR-HY-SP and MR-SP achieving top rankings) and computational efficiency comparison between Euclidean and MSM variants
- **Medium Confidence**: Individual SPROCKET performance claims and the assertion that prototype features "meaningfully complement" convolutional features
- **Low Confidence**: The theoretical justification for M=⌈log4(|X|)⌉ prototype selection and the exact impact of different distance measures on classification boundaries

## Next Checks
1. Implement both Euclidean and MSM variants and verify the reported 67× runtime difference on representative datasets
2. Test whether the M=⌈log4(|X|)⌉ prototype formula consistently produces optimal results across dataset sizes
3. Evaluate the sensitivity of ensemble performance to the inclusion/exclusion of SPROCKET features in MR-HY-SP configurations