---
ver: rpa2
title: EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition
arxiv_id: '2512.23526'
source_url: https://arxiv.org/abs/2512.23526
tags:
- recognition
- emotion
- egda
- learning
- cross-session
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a graph-guided domain adaptation framework
  (EGDA) for robust cross-session EEG-based emotion recognition. The proposed method
  addresses the challenge of distribution mismatch across recording sessions by jointly
  aligning marginal and class-conditional distributions while preserving local sample
  relationships through graph regularization.
---

# EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition

## Quick Facts
- **arXiv ID:** 2512.23526
- **Source URL:** https://arxiv.org/abs/2512.23526
- **Reference count:** 22
- **Primary result:** EGDA achieves cross-session emotion recognition accuracies of 81.22%, 80.15%, and 83.27% on SEED-IV dataset

## Executive Summary
This paper introduces EGDA, a graph-guided domain adaptation framework for cross-session EEG-based emotion recognition. The method addresses the distribution mismatch between labeled source sessions and unlabeled target sessions by jointly aligning marginal and class-conditional distributions while preserving local sample relationships through graph regularization. EGDA employs an iterative pseudo-labeling strategy combined with within-class scatter minimization to stabilize conditional alignment. Experimental results demonstrate superior performance compared to baseline methods on the SEED-IV dataset.

## Method Summary
EGDA learns a projection matrix that simultaneously aligns source and target distributions using Maximum Mean Discrepancy (MMD) while preserving local data structure through graph Laplacian regularization. The framework iteratively updates pseudo-labels for the unlabeled target data using a 1-Nearest Neighbor classifier and refines the similarity graph. The optimization balances distribution alignment, graph regularization, and source-domain compactness through a generalized eigenvalue problem. The method is evaluated on cross-session emotion recognition tasks using the SEED-IV dataset with 4 emotion classes across 3 transfer scenarios.

## Key Results
- EGDA achieves 81.22%, 80.15%, and 83.27% accuracy across three cross-session transfer tasks on SEED-IV
- Gamma frequency band identified as most discriminative for emotion recognition
- Prefrontal, central-parietal, and temporal brain regions critical for emotion recognition performance
- Superior performance compared to baseline domain adaptation methods

## Why This Works (Mechanism)
EGDA works by creating a shared feature subspace where the statistical distributions of source and target EEG data are aligned while preserving the local geometric structure of the data. The method addresses the fundamental challenge of domain shift in cross-session EEG analysis by using MMD to minimize both marginal and conditional distribution differences, while graph regularization ensures that the semantic relationships between samples are maintained. The iterative pseudo-labeling strategy progressively refines the alignment by improving the target domain labels, and the within-class scatter minimization stabilizes the learning process by encouraging compact class representations in the source domain.

## Foundational Learning
- **Concept: Maximum Mean Discrepancy (MMD)**
  - Why needed here: This is the core metric used to measure and minimize the statistical distance between source and target EEG feature distributions in the learned subspace.
  - Quick check question: Can you explain how MMD quantifies distribution difference using kernel methods?

- **Concept: Graph Laplacian Regularization**
  - Why needed here: This mathematical tool encodes the assumption that data points close in the input space should remain close in the learned subspace, preserving the EEG's local geometric structure.
  - Quick check question: How does the Laplacian matrix \( L \) derived from a similarity graph enforce smoothness in a function?

- **Concept: Expectation-Maximization (EM)**
  - Why needed here: The model uses an EM-like iterative strategy to alternate between optimizing the projection subspace (M-step) and estimating pseudo-labels for the unlabeled target data (E-step).
  - Quick check question: In this context, what is considered the "latent variable" in the EM formulation?

## Architecture Onboarding

**Component Map:**
Input: Source EEG features \( X_s \) (labeled), Target EEG features \( X_t \) (unlabeled) -> Subspace Learning Module: Learns projection matrix \( A \) by solving a generalized eigenvalue problem that balances distribution alignment, graph regularization, and source scatter minimization -> Graph Construction Module: Learns an adaptive similarity matrix \( S \) and computes the Laplacian matrix \( L_s \) to encode local data structure -> Pseudo-Labeling Module: A 1-Nearest Neighbor classifier that assigns and iteratively refines labels for the target domain based on the current subspace projection -> Output: Final target emotion labels \( Y_t \) and the transferable projection matrix \( A \).

**Critical Path:**
The entire framework is an iterative loop. The sequence is: 1) Initialize graph \( S \) and matrices; 2) **Update Projection A** by solving the eigenvalue problem; 3) **Update Pseudo-labels** for target data using a 1-NN classifier in subspace \( A \); 4) **Update Graph S** and Laplacian \( L_s \) in the new subspace; 5) Repeat until the maximum number of iterations is reached.

**Design Tradeoffs:**
- **Alignment vs. Structure:** The model must balance minimizing distribution discrepancy (MMD terms) against preserving the original data's neighborhood relationships (graph Laplacian term). Over-emphasizing alignment could distort the semantic structure.
- **Stability vs. Complexity:** Using only source-domain scatter for compactness (not target) stabilizes learning but ignores target class structure. A simpler 1-NN classifier for pseudo-labels is efficient but may be less robust than a complex classifier.
- **Efficiency:** The method avoids complex metric learning (unlike CPTML) for better computational efficiency but may sacrifice some representational power.

**Failure Signatures:**
- **Performance Collapse:** Accuracy drops or plateaus early if the initial pseudo-labels are too noisy, causing the conditional alignment to fail.
- **Over-regularization:** If the graph regularization parameter \( \mu \) is too high, the model may fail to adapt, keeping features too similar to their original state and not aligning domains.
- **Sensitivity:** Erratic results across different random seeds or train/test splits could indicate high sensitivity to the initialization of \( S \) or the hyperparameters.

**First 3 Experiments:**
1. **Baseline Comparison:** Replicate the cross-session transfer tasks (Session 1→2, 1→3, 2→3) on the SEED-IV dataset. Compare accuracy against non-adaptive and basic domain adaptation baselines (e.g., TCA, JDA) to isolate the value of each component.
2. **Component Ablation:** Run the full EGDA model, then systematically disable key components: (a) remove graph regularization (\( \mu=0 \)), (b) remove within-class scatter minimization (\( \beta=0 \)), (c) use random pseudo-labels. Quantify the performance drop to validate each mechanism's contribution.
3. **Parameter Sensitivity Analysis:** Fix all parameters and vary one at a time (e.g., \( \alpha, \beta, \mu \)) to observe its effect on accuracy. Identify the stable operating ranges for each hyperparameter to guide practical tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the EGDA framework maintain robust performance when applied to cross-subject transfer, where inter-domain discrepancies are typically larger than in cross-session scenarios?
- **Basis in paper:** [inferred] The Introduction explicitly identifies subject variability as a major challenge distinct from session variability, yet the experimental setup in Section IV-A restricts evaluation to "subject-dependent, cross-session settings."
- **Why unresolved:** The model's within-class scatter minimization relies on source-domain statistics; it is unclear if this constraint stabilizes alignment when the target domain possesses a fundamentally different physiological structure (a new subject).
- **What evidence would resolve it:** Reporting classification accuracies on the SEED-IV dataset using a leave-one-subject-out (LOSO) cross-validation strategy.

### Open Question 2
- **Question:** Is the identified importance of the Gamma frequency band a generalizable neurophysiological marker or a feature specific to the SEED-IV dataset's experimental conditions?
- **Basis in paper:** [inferred] The Abstract and Section IV-D conclude that the Gamma band is the "most discriminative," but this finding is derived exclusively from the SEED-IV dataset (15 subjects watching video clips).
- **Why unresolved:** Different emotional elicitation protocols (e.g., music, recall) or EEG devices may exhibit different frequency characteristics, and the model's performance has not been validated on external datasets.
- **What evidence would resolve it:** Applying EGDA to a distinct EEG emotion dataset (e.g., DEAP or AMIGOS) and verifying if the Gamma band retains the highest feature importance weight.

### Open Question 3
- **Question:** Is the iterative optimization of the projection matrix and similarity graph computationally efficient enough for real-time emotion recognition applications?
- **Basis in paper:** [inferred] Section IV-B notes that the baseline method CPTML has high accuracy but involves "considerable computational complexity, which may limit scalability," yet the paper does not provide a time-complexity analysis for EGDA.
- **Why unresolved:** EGDA requires an EM-like loop to update pseudo-labels and the graph Laplacian; the convergence speed and computational load relative to streaming EEG data rates remain unquantified.
- **What evidence would resolve it:** Reporting the training time and convergence iterations for EGDA compared to baseline methods, or implementing an online version of the algorithm.

### Open Question 4
- **Question:** How sensitive is the iterative pseudo-labeling strategy to the initial quality of target domain labels, particularly under severe class imbalance?
- **Basis in paper:** [inferred] Section I states the framework employs an "iterative pseudo-labeling strategy to progressively refine class-level alignment," while the Related Work section notes that similar methods (like JAGP) suffer from error accumulation.
- **Why unresolved:** While EGDA claims to stabilize this via graph regularization, the paper does not analyze failure cases where initial pseudo-labels are predominantly incorrect, potentially reinforcing bias.
- **What evidence would resolve it:** An ablation study analyzing accuracy trends when initializing the target pseudo-labels with varying levels of random noise or systematic bias.

## Limitations
- Reported accuracies depend heavily on SEED-IV dataset characteristics and may not generalize to other EEG datasets
- Hyperparameter selection process using random sampling lacks rigorous justification
- 1-NN pseudo-labeling strategy is susceptible to error propagation that could degrade performance over iterations
- Method requires labeled source data, limiting applicability to scenarios where source labels are unavailable

## Confidence
- **High Confidence:** The mathematical formulation of MMD-based distribution alignment and graph Laplacian regularization is well-established and correctly implemented.
- **Medium Confidence:** Cross-session performance improvements over baseline methods are demonstrated, but the contribution of individual components (graph regularization vs. conditional alignment) is not isolated through rigorous ablation studies.
- **Low Confidence:** Claims about specific brain regions (prefrontal, central-parietal, temporal) being critical lack supporting evidence from the paper and may be conflating correlation with causation.

## Next Checks
1. **Cross-Dataset Generalization:** Test EGDA on a different EEG emotion dataset (e.g., DEAP) with different channel configurations to assess robustness beyond SEED-IV.
2. **Component Ablation Study:** Systematically disable graph regularization and within-class scatter minimization to quantify their individual contributions to performance gains.
3. **Convergence Analysis:** Monitor pseudo-label accuracy across iterations to identify potential error propagation and determine optimal stopping criteria.