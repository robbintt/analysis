---
ver: rpa2
title: Gender-Neutral Machine Translation Strategies in Practice
arxiv_id: '2506.15676'
source_url: https://arxiv.org/abs/2506.15676
tags:
- gender
- gender-neutral
- translation
- response
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates gender-neutral translation in machine translation
  (MT) systems, focusing on preserving gender ambiguity in source text to avoid misgendering.
  The authors assess 21 MT systems across three language directions (English to Icelandic,
  Czech, and Spanish) using a controlled test suite of paired inputs with determined
  and ambiguous gender.
---

# Gender-Neutral Machine Translation Strategies in Practice

## Quick Facts
- arXiv ID: 2506.15676
- Source URL: https://arxiv.org/abs/2506.15676
- Reference count: 16
- Most MT systems show strong masculine default response to gender ambiguity, with only small number demonstrating non-zero gender-neutral response triggered mainly by active gender ambiguity (e.g., using "they")

## Executive Summary
This paper evaluates gender-neutral translation in machine translation systems by measuring their sensitivity to gender ambiguity when translating from English to grammatical gender languages (Icelandic, Czech, Spanish). Using a controlled test suite of paired inputs with determined and ambiguous gender, the authors assess 21 MT systems across three language directions. The primary finding is that most systems default to masculine translations under ambiguity, while only a small handful show gender-neutral responses, primarily triggered by active gender ambiguity (singular "they"). The study identifies five observed gender-neutral translation strategies and highlights the need for improvement in gender-neutral translation, particularly in adopting strategies like gender-neutral adjectives and alternative morphology.

## Method Summary
The study uses the WMT24 "Gender Resolution in Speaker-Listener Dialogue Roles" test suite with 17,946 source adjectives across three language directions. Templated paired inputs differ only in determined vs. ambiguous gender (e.g., "I'm stubborn, I said to him" vs. "I'm stubborn, I said"). The evaluation measures baseline gender neutrality (NDet), default masculine response (∆M), and gender-neutral response (∆N) by comparing adjective translations across paired conditions. Gender declension is determined via dictionary lookup, and the study categorizes five gender-neutral strategies: N1 (neutral adjectives), N2 (neuter case), N3 (alternative parts of speech), N4 (English substitution), N5 (alternative morphology).

## Key Results
- Most MT systems show strong masculine default response to gender ambiguity across all three target languages
- Only a small handful of systems demonstrate non-zero gender-neutral response, triggered mainly by active gender ambiguity (e.g., using "they")
- No significant gender-neutral response observed for passive ambiguity by omission (first/second person pronouns)
- Gender-neutral adjective selection appears to operate at a first-order translation decision stage, with gender agreement as second-order

## Why This Works (Mechanism)

### Mechanism 1
Active gender ambiguity (singular "they") triggers gender-neutral translation responses more effectively than passive ambiguity by omission. Explicit gender-ambiguous pronouns provide a clear lexical signal that the system can associate with neutrality-preserving strategies, whereas first/second-person pronouns ("I", "you") lack this association in training data. This works because systems have encountered "they" as singular in training corpora with sufficient gender-neutral target language examples to form the association.

### Mechanism 2
The masculine default response operates independently of gender-neutral strategy availability. When gender agreement cannot be resolved from context, systems fall back to masculine forms as the statistically dominant grammatical variant in training data, even when gender-neutral synonyms exist in vocabulary. This occurs because masculine forms are overrepresented in parallel training corpora relative to feminine and neutral alternatives.

### Mechanism 3
Gender-neutral translation requires a two-stage decision: adjective selection (first-order) followed by gender agreement resolution (second-order). Systems first select a lexical item based on semantic equivalence, then apply morphological agreement. Gender-neutral adjectives require selection at the first stage; alternative strategies (neuter case, morphology) operate at the second stage. The two stages are processed sequentially with limited feedback between them.

## Foundational Learning

- **Grammatical vs. Notional Gender Languages**: The paper's core challenge—English (notional, minimal gender marking) to Icelandic/Czech/Spanish (grammatical gender with agreement requirements)—defines the problem space. Quick check: In which target language does Spanish differ from Icelandic/Czech regarding available neuter grammatical cases?

- **Gender Agreement Resolution**: Understanding that adjectives must agree with referent gender in target languages, and that this agreement is the measured outcome variable. Quick check: If an English source says "I'm stubborn" spoken by a person of unknown gender, what must the MT system decide to translate correctly into Spanish?

- **Paired Input Evaluation Design**: The methodology uses minimally differing input pairs (determined vs. ambiguous gender) to isolate sensitivity to ambiguity while controlling for all other factors. Quick check: Why can't we evaluate gender-neutral response using only ambiguous inputs without the determined-gender baseline?

## Architecture Onboarding

- Component map: Test suite generator -> Translation extractor -> Dictionary lookup module -> Metric calculator -> Baseline vs. response analyzer
- Critical path: 1) Generate paired inputs (determined/ambiguous) identical except for gender cues 2) Collect translations from target MT systems 3) Extract adjectives and classify by gender/strategy via dictionary lookup 4) Compare neutrality rates across paired conditions 5) Identify which systems show ∆N > 0 and which strategies drive the response
- Design tradeoffs: Templated vs. natural inputs (controlled pairs enable clean measurement but may not reflect real-world complexity); Dictionary vs. classifier lookup (dictionary is more interpretable but limited to in-vocabulary items); Adjective-only focus (isolates second-order gender effects but misses first-order issues)
- Failure signatures: High NDet with ∆N ≈ 0 (system uses neutral strategies by default, not in response to ambiguity); Large positive ∆M (masculine default dominates; system fails ambiguity sensitivity test); Strategy inconsistency across languages (system has capability but lacks cross-lingual generalization)
- First 3 experiments: 1) Baseline audit: Run the paired input test suite on your MT system; compute NDet and ∆N across all three target languages to establish current performance 2) Ambiguity type comparison: Compare system response to passive ambiguity ("I/you" templates) vs. active ambiguity ("they" templates) to identify which signals trigger neutrality 3) Prompting intervention test: For LLM-based systems, test whether chain-of-thought prompting or explicit gender-neutrality instructions increase ∆N, and which strategy types (N1-N5) are most responsive

## Open Questions the Paper Calls Out

### Open Question 1
What specific system properties enable non-zero gender-neutral responses in the minority of successful MT systems? The study evaluated system outputs but did not analyze the internal architectures, training data, or alignment techniques of the successful systems (e.g., Claude-3.5, Aya23). A comparative analysis or ablation study of system components would resolve this.

### Open Question 2
Should the ideal evaluation metric for gender-inclusive MT prioritize high baseline neutrality or high gender-neutral response? The paper notes a trade-off exists where enforcing neutrality might impact translation quality, but the optimal balance between sensitivity (response) and consistency (baseline) remains undefined. User studies measuring perceived harm and translation quality scores would resolve this.

### Open Question 3
Can controlled templated inputs be effectively utilized as training data to improve gender-neutral translation in complex scenarios? The current study used templates only for evaluation, not for improving model behavior. Results from fine-tuning models on the paired templated dataset and measuring performance improvements on the GeNTE benchmark would resolve this.

## Limitations
- Dictionary-based gender classification limits strategy detection to in-vocabulary items, potentially missing morphological variants or multi-word translations
- Paired input design may not fully capture real-world translation scenarios where gender ambiguity arises from more complex discourse contexts
- Focus on adjective translations may underrepresent gender issues in other grammatical categories

## Confidence
- **High confidence**: Masculine default response finding is well-supported by consistent patterns across all 21 systems and three target languages; active gender ambiguity triggers more gender-neutral responses than passive ambiguity
- **Medium confidence**: Gender-neutral adjective selection operating at first-order decision stage is plausible but based on indirect evidence; distinction between baseline neutrality and sensitivity response (NDet vs. ∆N) is well-supported but practical implications need further validation
- **Low confidence**: Effectiveness of specific gender-neutral strategies (N2-N5) varies significantly across languages and systems, making generalizable claims difficult to substantiate

## Next Checks
1. **Dictionary robustness test**: For a subset of translations, manually verify dictionary-assigned gender classifications against human judgment to quantify error rates and identify systematic mismatches
2. **Real-world corpus validation**: Apply the same gender-neutral detection pipeline to a sample of authentic dialogue corpora with naturally occurring gender ambiguity to assess ecological validity of the templated test suite results
3. **Intervention efficacy study**: Test whether explicit prompting for gender neutrality in LLM-based systems increases ∆N beyond what's observed from passive/ambiguous input differences, and measure which strategy types show the most improvement