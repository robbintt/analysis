---
ver: rpa2
title: 'GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement
  and Preservation'
arxiv_id: '2511.00097'
source_url: https://arxiv.org/abs/2511.00097
tags:
- graph
- domains
- domain
- learning
- graphkeeper
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GraphKeeper, the first method addressing
  catastrophic forgetting in graph domain-incremental learning (Domain-IL), a critical
  yet unexplored problem with the rise of graph foundation models (GFMs). GraphKeeper
  tackles embedding shifts and decision boundary deviations by combining domain-specific
  parameter-efficient fine-tuning with intra- and inter-domain disentanglement, alongside
  a deviation-free knowledge preservation mechanism based on ridge regression.
---

# GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation

## Quick Facts
- **arXiv ID**: 2511.00097
- **Source URL**: https://arxiv.org/abs/2511.00097
- **Reference count**: 40
- **Primary result**: Achieves 6.5%~16.6% improvement over runner-up with negligible forgetting in graph domain-incremental learning

## Executive Summary
GraphKeeper addresses the critical problem of catastrophic forgetting in graph domain-incremental learning (Domain-IL), a challenge that emerges with the proliferation of graph foundation models (GFMs). The method introduces a novel approach that combines domain-specific parameter-efficient fine-tuning with intra- and inter-domain disentanglement techniques, complemented by a deviation-free knowledge preservation mechanism based on ridge regression. By tackling both embedding shifts and decision boundary deviations, GraphKeeper enables continuous learning across graph domains while maintaining strong performance on previously learned tasks.

The framework demonstrates particular strength in handling scenarios where graph domains are unobservable, employing domain-aware distribution discrimination to maintain performance without explicit domain labels. Experimental results validate GraphKeeper's effectiveness across multiple benchmarks, showing substantial improvements over existing methods while preserving knowledge from prior domains with minimal forgetting. The method's design also allows for seamless integration with representative GFMs, highlighting its practical applicability in real-world scenarios where domain boundaries may be ambiguous or continuously evolving.

## Method Summary
GraphKeeper operates through a three-pronged approach to address catastrophic forgetting in graph domain-incremental learning. First, it employs domain-specific parameter-efficient fine-tuning to adapt the model to new graph domains while preserving parameters learned from previous domains. Second, it implements intra- and inter-domain disentanglement mechanisms that separate domain-specific features from domain-invariant knowledge, preventing interference between different graph domains. Third, it utilizes a ridge regression-based knowledge preservation mechanism that maintains a deviation-free representation of previously learned knowledge, allowing the model to access and utilize past information when learning new domains. The method also incorporates domain-aware distribution discrimination for scenarios where graph domains are not explicitly observable, enabling the model to distinguish between different domain distributions during the learning process.

## Key Results
- Achieves 6.5%~16.6% improvement over runner-up methods across multiple graph domain-incremental learning benchmarks
- Demonstrates negligible forgetting, maintaining strong performance on previously learned domains while adapting to new ones
- Successfully integrates with representative GFMs, showing broad applicability across different graph neural network architectures

## Why This Works (Mechanism)
GraphKeeper addresses catastrophic forgetting through a multi-faceted approach that targets the root causes of knowledge interference in domain-incremental learning. The domain-specific parameter-efficient fine-tuning ensures that adaptations to new domains do not overwrite or interfere with parameters critical for previous domains. The disentanglement mechanisms separate domain-specific features from domain-invariant knowledge, creating distinct representation spaces that prevent cross-domain interference. The ridge regression-based knowledge preservation mechanism maintains a stable reference point for previously learned knowledge, allowing the model to correct for deviations that might occur during fine-tuning. Together, these components create a robust framework that can continuously learn across graph domains while preserving performance on prior tasks.

## Foundational Learning

**Graph Neural Networks (GNNs)**: Neural networks designed to operate on graph-structured data, learning node representations by aggregating information from neighboring nodes. *Why needed*: Forms the foundation for processing graph data in domain-incremental learning scenarios. *Quick check*: Verify that the base GNN architecture can handle varying graph sizes and structures across different domains.

**Catastrophic Forgetting**: The phenomenon where neural networks rapidly lose previously learned information when trained on new tasks or domains. *Why needed*: Understanding this problem is crucial for developing effective continual learning solutions. *Quick check*: Measure performance degradation on previous domains after training on new ones to confirm catastrophic forgetting occurs.

**Domain-Incremental Learning**: A continual learning scenario where data arrives in distinct domains or tasks sequentially, with only current domain data available for training. *Why needed*: This is the specific learning paradigm GraphKeeper addresses. *Quick check*: Ensure the evaluation protocol correctly simulates the sequential arrival of graph domains with appropriate data isolation.

## Architecture Onboarding

**Component Map**: Input Graphs -> Domain Disentanglement -> Ridge Regression Knowledge Preservation -> Parameter-Efficient Fine-Tuning -> Output Predictions

**Critical Path**: The most critical path involves the integration of domain disentanglement with knowledge preservation. During domain adaptation, the model must simultaneously maintain separated representations for different domains while ensuring the preserved knowledge remains accessible and accurate through the ridge regression mechanism.

**Design Tradeoffs**: The primary tradeoff involves balancing the complexity of disentanglement mechanisms against computational efficiency. More sophisticated disentanglement may improve performance but at the cost of increased computational overhead. The ridge regression-based preservation adds storage and computational requirements but provides superior knowledge retention compared to simpler approaches.

**Failure Signatures**: Potential failures include domain entanglement where features from different domains interfere, leading to degraded performance across domains. Another failure mode is knowledge preservation drift, where the ridge regression model fails to accurately represent previously learned knowledge, causing the model to overwrite important information during fine-tuning.

**First Experiments**: 1) Test domain disentanglement effectiveness by measuring feature separation between domains using domain classification accuracy. 2) Validate knowledge preservation by comparing performance on previous domains before and after fine-tuning on new domains. 3) Assess parameter efficiency by measuring the number of additional parameters required per new domain compared to full fine-tuning.

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

The method assumes that domains are either known or can be reasonably clustered, which may not hold in real-world scenarios where domain boundaries are ambiguous or continuously evolving. The ridge regression-based knowledge preservation mechanism, while theoretically sound, may struggle with extremely large-scale graph datasets due to computational constraints in maintaining and updating the preservation model across numerous domains.

## Confidence

**High Confidence**: The experimental results showing 6.5%~16.6% improvement over baseline methods are well-supported by the reported metrics and ablation studies. The claim that GraphKeeper addresses catastrophic forgetting in graph domain-incremental learning is substantiated by the empirical evidence.

**Medium Confidence**: The assertion that GraphKeeper is "the first method" addressing this specific problem, while likely accurate given the stated novelty, requires verification against the broader literature on continual learning for graph neural networks.

**Low Confidence**: The claim about "seamless integration" with representative GFMs needs more empirical validation across diverse GFM architectures beyond those tested in the experiments.

## Next Checks

1. **Cross-Domain Robustness Test**: Evaluate GraphKeeper's performance when domain boundaries are intentionally blurred or when domains are introduced in non-sequential order to assess robustness to domain ambiguity.

2. **Scalability Analysis**: Conduct experiments with datasets containing 10+ domains and millions of nodes to validate the computational feasibility of the ridge regression-based knowledge preservation mechanism.

3. **GFM Architecture Diversity**: Test GraphKeeper's integration capabilities with additional GFM architectures (e.g., Graphormer, DeeperGCN) not included in the original experiments to confirm the claimed broad applicability.