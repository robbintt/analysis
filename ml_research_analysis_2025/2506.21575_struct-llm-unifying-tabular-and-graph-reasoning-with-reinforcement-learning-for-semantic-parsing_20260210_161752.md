---
ver: rpa2
title: 'STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning
  for Semantic Parsing'
arxiv_id: '2506.21575'
source_url: https://arxiv.org/abs/2506.21575
tags:
- query
- training
- cypher
- reasoning
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: STRuCT-LLM jointly trains large language models on Text-to-SQL
  and Text-to-Cypher tasks using reinforcement learning with Chain-of-Thought supervision.
  The approach introduces a topology-aware reward function for Cypher based on graph
  edit distance, enabling fine-grained optimization in graph-structured parsing.
---

# STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing

## Quick Facts
- arXiv ID: 2506.21575
- Source URL: https://arxiv.org/abs/2506.21575
- Reference count: 40
- Primary result: QwQ-32B achieves 13.5% relative improvement on Spider and 73.1% on Text2Cypher compared to baselines

## Executive Summary
STRuCT-LLM is a unified semantic parsing framework that jointly trains large language models on Text-to-SQL and Text-to-Cypher tasks using reinforcement learning with Chain-of-Thought supervision. The approach introduces a topology-aware reward function for Cypher based on graph edit distance, enabling fine-grained optimization in graph-structured parsing. Models are trained with interleaved SQL and Cypher data to encourage cross-formalism transfer. Results show substantial improvements across multiple benchmarks, with strong zero-shot generalization to QA tasks.

## Method Summary
STRuCT-LLM employs a two-stage training process: first, supervised fine-tuning (SFT) on synthetic Chain-of-Thought traces generated from 24 SQL datasets and Neo4j Text-to-Cypher data; second, reinforcement learning using Group Relative Policy Optimization (GRPO) with three reward functions. The rewards include an LLM judge (o3-mini), string matching, and structural rewards (component-level F1 for SQL, Graph Edit Distance for Cypher). The model learns to generate intermediate reasoning traces before producing final queries, creating a compositional scaffold that transfers to downstream QA tasks. Training uses equal weights for all reward components without adaptive tuning.

## Key Results
- QwQ-32B achieves 13.5% relative improvement on Spider compared to baselines
- 73.1% improvement on Text2Cypher benchmark
- Strong zero-shot generalization: 8.5% improvement on TableBench and 1.7% on CR-LT-KGQA without QA-specific training
- Cross-formalism transfer shows synergy: outperforms single-task models on both formalisms

## Why This Works (Mechanism)

### Mechanism 1: Cross-Formalism Structural Transfer
Joint training on SQL and Cypher induces shared structural abstractions, enabling bidirectional skill transfer even without shared schemas. By interleaving data from both formalisms during SFT and RL, the model generalizes beyond surface-level syntax, learning domain-agnostic operations like schema grounding, filtering, and pattern matching.

### Mechanism 2: Topology-Aware Reward Optimization
A continuous reward function based on Graph Edit Distance provides superior optimization signals for Cypher generation compared to binary execution accuracy. The $R_{GED}$ reward normalizes structural differences between predicted and gold subgraphs, allowing GRPO to assign fine-grained credit to nearly-correct graph topologies.

### Mechanism 3: Compositional Scaffolding via CoT
Enforcing Chain-of-Thought reasoning during training allows the model to decompose complex queries into executable steps, improving generalization to unseen QA tasks. The model learns a general "reasoning process" for structured data, not just query syntax, translating to better zero-shot performance.

## Foundational Learning

- **Concept: Group Relative Policy Optimization (GRPO)**
  - Why needed: Core RL algorithm that compares multiple generated outputs against each other to compute relative advantages, reducing need for a separate value model
  - Quick check: Can you explain how GRPO calculates the advantage $A_i$ differently than standard PPO?

- **Concept: Graph Edit Distance (GED)**
  - Why needed: Metric powering the topology-aware reward; counts minimum operations to transform one graph into another
  - Quick check: Why would a GED-based reward provide a better gradient signal for a Cypher query than a simple string match?

- **Concept: Property Graphs vs. Relational Tables**
  - Why needed: The paper relies on synergy between these two data models; need to map SQL Rows $\rightarrow$ Nodes and SQL Foreign Keys $\rightarrow$ Edges
  - Quick check: How does the concept of a "Join" in SQL translate to Cypher syntax?

## Architecture Onboarding

- **Component map:** Data Curation (24 SQL datasets + Neo4j Text-to-Cypher) -> SFT Stage (CoT traces) -> RL Stage (GRPO with rewards) -> Evaluation (Spider/BIRD/Text2Cypher/QA)

- **Critical path:** The Reward Engine (Section 3.3.2). If the $R_{GED}$ calculation is flawed or the LLM Judge is inconsistent, the RL loop collapses.

- **Design tradeoffs:** Joint vs. Single Training (improves generalization but adds complexity); Reward Composition (equal weights vs. adaptive tuning)

- **Failure signatures:** Catastrophic Forgetting (SQL regresses while Cypher improves); Reward Hacking (syntactic complexity over correctness); CoT Hallucination (disconnected reasoning steps)

- **First 3 experiments:**
  1. Reward Ablation (111 vs 110 vs 101) to verify contribution of structural reward vs. string matching
  2. Cross-Domain Transfer Test: Train on SQL only, evaluate on Cypher (and vice versa) to quantify inductive bias transfer
  3. Schema Scaling: Test on SM3 to verify generalization to unseen query language (MQL)

## Open Questions the Paper Calls Out

### Open Question 1
Does joint training on SQL and Cypher generalize to structurally distinct query languages like SPARQL or MQL without task-specific fine-tuning? The authors note future work includes support for additional query languages, and SM3 evaluation shows significantly weaker performance on MQL compared to trained formalisms.

### Open Question 2
How should reward weights be adaptively tuned for optimal performance across SQL and Cypher tasks? The current approach uses uniform weights (w1=w2=w3=1) without tuning, with adaptive weights remaining future work.

### Open Question 3
Can the topology-aware reward be extended to incorporate query execution efficiency and computational cost? The current GED-based reward optimizes for structural correctness but may reward computationally expensive queries.

### Open Question 4
Does the approach maintain performance when schemas are incomplete, noisy, or dynamically changing? The model assumes schema-aware inputs and has not been tested in interactive or schema-free settings.

## Limitations

- Scalability concerns with Graph Edit Distance computation on large property graphs
- Cross-formalism transfer claims rely heavily on synthetic CoT data quality and unverified structural isomorphism
- Zero-shot generalization gains suggest task-specific fine-tuning may still be needed for optimal downstream performance

## Confidence

- **High confidence**: Joint training methodology and GRPO implementation details are well-specified and reproducible; ablation studies provide strong empirical support
- **Medium confidence**: Cross-formalism transfer claims are supported by relative improvements but boundary conditions and failure patterns need further characterization
- **Medium confidence**: Zero-shot generalization results are promising but absolute performance levels and scaffold effectiveness versus additional training data remain to be fully validated

## Next Checks

1. **Reward Function Ablation**: Replicate Table B1 to verify independent contribution of each reward component under varying weights, particularly testing whether GED reward remains beneficial with computational constraints.

2. **Cross-Domain Transfer Boundary**: Train STRuCT-LLM on SQL only, evaluate on Cypher (and vice versa) using same metrics to quantify inductive bias transfer and identify failure patterns.

3. **Schema Complexity Scaling**: Test on SM3 and additional unseen query languages to verify structural reasoning generalizes beyond Neo4j Text-to-Cypher dataset or simply memorizes syntax patterns.