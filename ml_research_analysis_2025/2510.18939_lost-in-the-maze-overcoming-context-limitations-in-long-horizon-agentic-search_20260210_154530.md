---
ver: rpa2
title: 'Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search'
arxiv_id: '2510.18939'
source_url: https://arxiv.org/abs/2510.18939
tags:
- search
- tool
- answer
- agent
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SLIM (Simple Lightweight Information Management) addresses context
  limitations in long-horizon agentic search by separating search and browse tools
  while periodically summarizing search trajectories. This design keeps context concise
  while enabling longer, more focused searches.
---

# Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search

## Quick Facts
- arXiv ID: 2510.18939
- Source URL: https://arxiv.org/abs/2510.18939
- Reference count: 40
- SLIM achieves 56% accuracy on BrowseComp and 31% on HLE, outperforming open-source frameworks by 8-10 points while using 4-6x fewer tool calls

## Executive Summary
SLIM (Simple Lightweight Information Management) addresses critical context limitations in long-horizon agentic search by separating search and browse tools while periodically summarizing search trajectories. This design keeps context concise while enabling longer, more focused searches. With o3 as the base model, SLIM achieves 56% accuracy on BrowseComp and 31% on HLE, outperforming all open-source frameworks by 8 and 4 absolute points respectively, while using 4-6x fewer tool calls. The framework shows consistent performance across different base models including o4-mini and Claude-4-Sonnet. Trajectory-level analysis reveals SLIM exhibits fewer hallucinations (19% vs 47% for SEARCH-O1) and better context management, though it still faces challenges with abstention and answer identification. The work also introduces an automated trajectory analysis pipeline and error taxonomy for characterizing long-horizon agentic search systems.

## Method Summary
SLIM implements a simple yet effective architecture for long-horizon agentic search by separating search and browse tools while incorporating periodic trajectory summarization. The search tool returns only (title, URL, snippet) tuples, keeping context concise and avoiding irrelevant content accumulation. The browse tool is called selectively on promising URLs and returns only the query-relevant section via ROUGE-L scoring against chunks. Every 50 tool calls, the entire conversation history is compressed via LLM summarization and replaces the trajectory, allowing longer exploration while staying within context limits. This design reduces hallucinations by 28 percentage points compared to baselines while using 4-6x fewer tool calls.

## Key Results
- SLIM achieves 56% accuracy on BrowseComp and 31% on HLE with o3 base model, outperforming open-source frameworks by 8 and 4 absolute points
- The framework uses 4-6x fewer tool calls than REACT-style agents while maintaining superior performance
- SLIM exhibits 19% hallucination rate compared to 47% for SEARCH-O1, demonstrating the effectiveness of selective evidence gathering
- Consistent performance across different base models including o3, o4-mini, and Claude-4-Sonnet

## Why This Works (Mechanism)

### Mechanism 1: Tool Separation Reduces Context Noise
- Claim: Separating search and browse into distinct tools reduces irrelevant content accumulation in the context window.
- Mechanism: The search tool returns only (title, URL, snippet) tuples rather than full page content. The browse tool is then called selectively on promising URLs, returning only the query-relevant section via ROUGE-L scoring against chunks. This prevents the "scrape everything" pattern that fills context with noise.
- Core assumption: Models can effectively judge relevance from snippets alone to guide subsequent browse decisions.
- Evidence anchors:
  - [abstract]: "separates retrieval into distinct search and browse tools"
  - [section 4]: "the search tool only returns a short snippet of each result, keeping the output concise and avoiding wasting context and tool calls on irrelevant content"
  - [corpus]: Related work (Laser, ToolScope) also emphasizes structured tool design for long-horizon tasks, supporting this design pattern.
- Break condition: If queries require information not visible in snippets (e.g., deeply nested content), the model may fail to identify relevant URLs to browse.

### Mechanism 2: Periodic Trajectory Summarization Maintains Concise Context
- Claim: Summarizing the entire trajectory every n turns allows longer exploration while staying within context limits.
- Mechanism: After every n tool calls (default n=50), the full conversation history is compressed via LLM summarization and replaces the trajectory. This differs from prior work that summarizes only search results per-turn—SLIM summarizes the *task trajectory*, preserving strategic context while discarding detail.
- Core assumption: Summaries retain sufficient signal for continued reasoning; summarization losses don't compound catastrophically.
- Evidence anchors:
  - [abstract]: "periodically summarizes the trajectory, keeping context concise while enabling longer, more focused searches"
  - [section 4]: "we summarize the entire conversation history after every n turns of tool calls and replace the trajectory with the summary"
  - [corpus]: Weak direct evidence—MemoBrain and Agentic Memory papers address memory management but use different architectures.
- Break condition: If critical intermediate facts are lost during summarization, the agent may pursue redundant or incorrect paths.

### Mechanism 3: Reduced Hallucination via Selective Evidence Gathering
- Claim: The selective browse pattern reduces hallucination rates by grounding outputs in actually-retrieved content.
- Mechanism: By choosing which URLs to browse based on snippet assessment, SLIM reduces exposure to irrelevant/noisy content that might trigger parametric knowledge leakage. The model only sees content it actively selected, creating tighter grounding.
- Core assumption: Lower exposure to irrelevant content correlates with lower hallucination; the mechanism is causal not coincidental.
- Evidence anchors:
  - [abstract]: "SLIM exhibits fewer hallucinations (19% vs 47% for SEARCH-O1)"
  - [section 6.2]: "SLIM's advantage in performance could be attributed to the notably reduced hallucination rate"
  - [corpus]: No direct corpus validation of this specific mechanism.
- Break condition: If the model fails to browse necessary pages, it may still hallucinate from parametric knowledge or abstain.

## Foundational Learning

- Concept: **Tool Budget vs. Context Window Trade-off**
  - Why needed here: SLIM's core insight is that existing frameworks waste tool calls scraping irrelevant content, which then fills context. Understanding this trade-off is essential to motivate the design.
  - Quick check question: Why does increasing tool budget not always improve performance in REACT-style agents?

- Concept: **Snippet-based Relevance Judgment**
  - Why needed here: SLIM's browse tool depends on the model's ability to judge URL relevance from short snippets. This is a learned capability that may vary across models.
  - Quick check question: What information is lost when relying only on search result snippets for relevance decisions?

- Concept: **Trajectory Compression Fidelity**
  - Why needed here: Summarization is lossy; understanding what information is preserved vs. discarded is critical for debugging failure modes.
  - Quick check question: If a trajectory contains 5 key facts discovered at turns 10, 25, 40, 55, and 70, what happens after summarization at turn 50?

## Architecture Onboarding

- Component map:
  - Query enters -> Search Tool (Serper API) returns (title, URL, snippet)
  - Model decides browse vs. search vs. answer
  - If browse: Browse Tool (crawl4ai scraper) returns relevant chunk via ROUGE-L scoring
  - Every n=50 turns: Summarization Module (same base LLM) compresses trajectory
  - Continue until Final Answer or budget exhausted

- Critical path:
  1. Query enters → LLM decides search vs. browse vs. answer
  2. If search: results populate context as snippets only
  3. If browse: model specifies (URL, query) → returns relevant chunk
  4. Every n turns: context is compressed via summarization
  5. Continue until Final Answer or budget exhausted

- Design tradeoffs:
  - Summarization frequency (n=25 vs. 50 vs. token-threshold): More frequent = shorter context but higher compression loss risk. Ablation shows n=25 underperforms n=50.
  - Browse chunk size (L=3K vs. 10K vs. 20K): Larger = more context per browse but faster context growth. Ablation shows L=3K competitive with lower cost.
  - Number of search results (k=10 vs. 20): More results = more options but more tokens. Ablation shows k=20 doesn't consistently help.

- Failure signatures:
  - **Exceed context**: REACT pattern (scrape all URLs) → context overflow
  - **Exceed budget**: SEARCH-O1 pattern (many unnecessary scrapes) → tool exhaustion
  - **Early stopping**: HF-ODR pattern (manager gives up prematurely)
  - **High abstention**: SLIM pattern at 27.7% (Table 4) → model not confident to answer
  - **Answer ignored**: SLIM at 30.7% → found answer but didn't synthesize correctly

- First 3 experiments:
  1. **Reproduce the BrowseComp outcome analysis** (Figure 3): Run REACT, SEARCH-O1, and SLIM with matched budgets; categorize outcomes to verify the failure mode distributions match the paper's claims.
  2. **Ablate summarization timing**: Compare n=50 (default) vs. token-threshold triggers (32K/64K) on a 50-sample subset to validate the heuristic choice.
  3. **Inspect answer-ignored cases**: For trajectories where ground truth was present but not used (30.7% for SLIM), manually examine 5-10 examples to understand if summarization is the culprit or if the model simply fails to recognize relevance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can long-horizon agentic search systems be improved to reduce abstention rates while maintaining accuracy?
- Basis in paper: [explicit] "Notably, despite the improvements on hallucination, SLIM still suffers from high abstention rates... We leave these improvements to future work."
- Why unresolved: SLIM achieves 19% hallucination but 27.7% abstention; models refuse to answer when uncertain instead of leveraging additional tool calls.
- What evidence would resolve it: A method that reduces abstention rate below 10% on BrowseComp without increasing hallucination rates.

### Open Question 2
- Question: How can agents better identify and extract correct answers when they appear in long search trajectories?
- Basis in paper: [explicit] "SLIM is more prone to ignoring the groundtruth answers" and "a promising direction... is to enable language models to better identify the correct answer from long trajectories."
- Why unresolved: Analysis shows 69.7% of SLIM's incorrect trajectories contained the groundtruth answer in tool responses but the model failed to identify it.
- What evidence would resolve it: Techniques that reduce the "answer ignored" rate from 30.7% to under 15%.

### Open Question 3
- Question: What training or architectural improvements could close the performance gap between SLIM and task-specific trained systems like OpenAI Deep Research?
- Basis in paper: [inferred] SLIM achieves 56% on BrowseComp vs OpenAI DR's 51.5%, but on HLE SLIM gets 31% vs Grok-4's 38.6%, suggesting different systems excel on different task types.
- Why unresolved: SLIM relies on prompting and tool design rather than reinforcement learning or specialized training for agentic search.
- What evidence would resolve it: A training procedure that improves SLIM's HLE performance to match or exceed proprietary systems while maintaining tool efficiency.

## Limitations
- The framework's reliance on snippet-based relevance judgment introduces uncertainty about whether all queries can be effectively handled without full-page previews
- The analysis assumes that hallucination reduction is primarily due to selective content exposure, but this causal link isn't directly tested
- The summarization mechanism, while showing improved performance, hasn't been evaluated for information fidelity across different query types or domains

## Confidence
- **High Confidence**: Performance improvements on BrowseComp and HLE datasets (56% and 31% accuracy with o3) - these are direct, measurable outcomes with clear baselines
- **Medium Confidence**: Reduced hallucination rates (19% vs 47%) - while measured, the causal mechanism isn't independently validated and could be influenced by other factors
- **Medium Confidence**: Tool call efficiency (4-6x fewer calls) - measured but doesn't account for potential quality differences in individual tool calls
- **Low Confidence**: Generalizability across base models - while tested on o3, o4-mini, and Claude-4-Sonnet, the dataset scope and query diversity are limited

## Next Checks
1. **Causal hallucination analysis**: Design a controlled experiment comparing SLIM against a variant that uses full-page scraping for the same URLs to isolate whether selective browsing specifically reduces hallucination rates, or if the effect is due to other factors like reduced context noise.

2. **Summarization fidelity evaluation**: Implement a blind test where human evaluators compare ground truth trajectories with SLIM's summarized versions to quantify information loss and identify which types of facts (dates, entities, relationships) are most vulnerable to summarization compression.

3. **Cross-domain robustness test**: Apply SLIM to a non-web domain requiring tool use (e.g., scientific literature search, code repository exploration) to evaluate whether the snippet-based relevance judgment and selective browsing patterns transfer beyond the web search context where the framework was developed.