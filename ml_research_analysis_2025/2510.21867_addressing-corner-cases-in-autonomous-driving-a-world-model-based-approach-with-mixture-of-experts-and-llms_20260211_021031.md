---
ver: rpa2
title: 'Addressing Corner Cases in Autonomous Driving: A World Model-based Approach
  with Mixture of Experts and LLMs'
arxiv_id: '2510.21867'
source_url: https://arxiv.org/abs/2510.21867
tags:
- scenarios
- driving
- prediction
- world
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces WM-MoE, a world model-based framework for
  motion forecasting in autonomous driving, designed to address the challenge of corner-case
  scenarios that are rare but safety-critical. WM-MoE integrates perception, memory,
  and decision modules, using a Mixture-of-Experts (MoE) network to specialize in
  different interaction regimes and a lightweight temporal tokenizer to map trajectories
  and context into a frozen large language model (LLM) feature space.
---

# Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs

## Quick Facts
- arXiv ID: 2510.21867
- Source URL: https://arxiv.org/abs/2510.21867
- Reference count: 40
- Primary result: WM-MoE consistently outperforms state-of-the-art baselines in accuracy, robustness under data-missing conditions, and handling of corner cases across four real-world datasets and a new nuScenes-corner benchmark.

## Executive Summary
This paper introduces WM-MoE, a world model-based framework for motion forecasting in autonomous driving that addresses the challenge of rare but safety-critical corner-case scenarios. The framework integrates perception, memory, and decision modules using a Mixture-of-Experts network for specialized handling of different interaction regimes and a lightweight temporal tokenizer to map trajectories into a frozen large language model feature space. The approach enhances long-term reasoning and injects commonsense priors without extensive LLM training. Evaluated on four real-world datasets and a new nuScenes-corner benchmark, WM-MoE consistently outperforms state-of-the-art baselines in accuracy, robustness under data-missing conditions, and handling of corner cases.

## Method Summary
WM-MoE employs a three-module architecture: Perception compresses multimodal inputs (agent trajectories, map vectors, BEV images) into scene encodings; Memory integrates intention-aware queries and LLM-enhanced features through cross-attention and temporal tokenization; Decision runs MoE-based trajectory decoding with Laplace uncertainty. The framework uses a frozen GPT-2 backbone with a lightweight temporal tokenizer (two-layer MLP, D=64) and an MoE decoder with 4 experts. Training employs multi-task loss (regression + classification) with Adam optimizer and cosine annealing learning rate schedule across datasets (nuScenes: 120 epochs, batch size 32; others: 12 epochs, batch size 128).

## Key Results
- WM-MoE achieves 4.3% improvement in minADE5 on nuScenes compared to state-of-the-art GOHOME
- On nuScenes-corner benchmark, WM-MoE outperforms GOHOME by 13.2% in minADE5 and 13.1% in minADE10
- WM-MoE maintains accuracy with up to 60% missing data in nuScenes, outperforming baselines in robustness
- MoE ablation shows degradation from 1.38 to 1.86 minADE5 (+34.8%) on Turning scenarios
- Frozen LLM + tokenizer outperforms LoRA-finetuned baselines (minADE5 1.17 vs 1.27)

## Why This Works (Mechanism)

### Mechanism 1
The MoE decoder enables specialized handling of corner cases by learning scenario-specific dynamics without degrading common-case performance. A router computes softmax-normalized weights over K experts based on scene representations; all expert outputs are aggregated, allowing fine-grained, weighted specialization. Experts learn nuanced dynamics of rare interaction regimes in the world model's latent space.

### Mechanism 2
The temporal tokenizer projects trajectories and context into a frozen LLM feature space, injecting commonsense priors that improve long-horizon reasoning without task-specific LLM training. Normalized trajectory encodings are concatenated and passed through MLPs to form LLM-compatible tokens; a frozen GPT-2 backbone processes these, and an output projection aligns features back to the world model's latent dimension.

### Mechanism 3
The world model architecture (Perception-Memory-Decision) enables counterfactual rollouts that improve prediction under uncertainty by maintaining a compact, temporally consistent latent scene state. The latent state supports simulating plausible futures conditioned on actions, allowing the model to evaluate outcomes of potential maneuvers.

## Foundational Learning

- **World Models in Autonomous Systems**
  - Why needed here: WM-MoE is explicitly brain-inspired, framing prediction as latent-state simulation; understanding world models clarifies why the architecture separates perception, memory, and decision.
  - Quick check question: Can you explain how a world model differs from a standard discriminative forecaster in terms of what it represents and how it generalizes?

- **Mixture-of-Experts (MoE) and Routing**
  - Why needed here: The MoE decoder is central to corner-case handling; understanding routing, expert capacity, and load balancing is essential to diagnose and tune specialization.
  - Quick check question: In MoE, what happens if the router collapses (e.g., all scenes routed to one expert), and how would you detect it from loss curves or expert histograms?

- **Temporal Tokenization for Multimodal LLMs**
  - Why needed here: The tokenizer aligns trajectory data with a frozen LLM; understanding tokenization and modality alignment helps debug misalignment and evaluate whether priors are effectively transferred.
  - Quick check question: Why might a frozen LLM with a carefully designed tokenizer outperform a LoRA-finetuned LLM on a long-tail forecasting task?

## Architecture Onboarding

- **Component map**: Historical states + map + BEV → Perception → scene encoding → Memory (queries + LLM tokens) → intention-aware + language-informed features → Cross-modal fusion → Mamba → MoE decoder → multimodal trajectories

- **Critical path**: 1) Perception compresses inputs into scene encoding; 2) Memory integrates intention-aware queries and LLM-enhanced features; 3) Decision fuses features and runs MoE decoding with Laplace uncertainty; 4) Router weights determine expert contributions for final forecasts

- **Design tradeoffs**: Lightweight GPT-2 (0.11B) chosen for real-time inference vs larger models' marginal accuracy gains (~29× slower); MoE expert count K=4 optimal (fewer underfit, more cause redundancy); frozen LLM + tokenizer preserves priors vs LoRA fine-tuning; BEV adds local geometry (12-18% ADE degradation when removed)

- **Failure signatures**: Stationary-to-overtake intent shift (underestimates acceleration/merge); unusual maneuvers (reverse, bus stop) with weak map/agent cues; ambiguous histories collapsing to dominant training mode

- **First 3 experiments**: 1) MoE ablation on nuScenes-corner with K∈{2,3,4,5,6} and without MoE; 2) Tokenizer alignment sanity check replacing with random projection; 3) Data-missing robustness test with 1-3 dropped frames vs baselines

## Open Questions the Paper Calls Out

- **Unstructured Environments**: Can WM-MoE maintain robust performance in highly unstructured or out-of-distribution environments, such as rural roads or mixed-modal traffic, which lack the structured lane geometry present in current benchmarks?

- **Larger Foundation Models**: Can larger foundation models be integrated into the world model to enhance semantic reasoning without violating the stringent real-time latency constraints required for safety-critical autonomous driving?

- **Causal Reasoning**: Does the incorporation of explicit causal reasoning modules or counterfactual consistency checks reduce error rates in scenarios where the model currently defaults to common patterns due to ambiguous motion history?

## Limitations
- Architecture reproducibility gaps in BEV CNN backbone, MoE router initialization, and temporal tokenizer normalization procedures
- Benchmark novelty concerns due to incomplete nuScenes-corner split creation methodology details
- Real-world generalization uncertainty without closed-loop testing in simulators or actual vehicles
- Dataset bias limitations from heavy reliance on HD maps and BEV inputs for unmapped environments

## Confidence
**High Confidence**: Core architectural framework is well-specified and technically sound; ablation studies provide strong internal evidence; performance improvements over baselines are statistically significant.

**Medium Confidence**: Frozen LLM priors claims supported by internal ablation but lack external validation; paper doesn't provide detailed error analysis of where LLM priors help versus mislead.

**Low Confidence**: Corner-case handling claims rely heavily on nuScenes-corner benchmark without closed-loop performance or extensive real-world validation; doesn't address distributional shifts between benchmarks and actual driving environments.

## Next Checks
1. **Closed-Loop Performance Validation**: Implement WM-MoE in CARLA simulator with challenging corner-case scenarios (occluded crosswalks, construction zones, erratic pedestrians); measure collision rate, comfort scores, and success rate.

2. **Distributional Robustness Testing**: Systematically generate adversarial corner-case scenarios by perturbing common patterns; evaluate WM-MoE's performance degradation compared to baselines and test uncertainty calibration.

3. **Expert Specialization Analysis**: Log and visualize MoE routing decisions across corner-case categories; create confusion matrix showing expert-corner case handling; perform ablation studies removing specific experts to quantify individual contributions.