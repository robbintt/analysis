---
ver: rpa2
title: Automated Explanation of Machine Learning Models of Footballing Actions in
  Words
arxiv_id: '2504.00767'
source_url: https://arxiv.org/abs/2504.00767
tags:
- shot
- feature
- goal
- features
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of making machine learning models
  in football analytics more interpretable and actionable for coaches. It proposes
  a novel "wordalisation" approach that combines logistic regression modeling with
  large language models to generate natural language descriptions of shot quality
  and contributing factors.
---

# Automated Explanation of Machine Learning Models of Footballing Actions in Words

## Quick Facts
- arXiv ID: 2504.00767
- Source URL: https://arxiv.org/abs/2504.00767
- Authors: Pegah Rahimian; Jernej Flisar; David Sumpter
- Reference count: 8
- One-line primary result: Novel "wordalisation" approach generates natural language descriptions of shot quality from logistic regression models, achieving high engagement while maintaining interpretability for football coaches.

## Executive Summary
This paper addresses the challenge of making machine learning models in football analytics more interpretable and actionable for coaches. It proposes a novel "wordalisation" approach that combines logistic regression modeling with large language models to generate natural language descriptions of shot quality and contributing factors. The method extracts features from shot data, trains an expected goals model, and uses the coefficients to explain how factors like distance, angle, and defensive pressure contribute to scoring probability. These explanations are then transformed into engaging narratives through carefully engineered prompts. Evaluation shows the approach achieves a balance between accuracy (correctly identifying feature contributions) and engagement (interesting descriptions), with case 4 (full wordalisation) achieving the highest engagement while maintaining good accuracy. The method bridges the gap between technical modeling and practical coaching communication, with applications extending beyond shots to other football actions.

## Method Summary
The wordalisation pipeline extracts 11 features from StatsBomb shot data (distance, angle, defensive pressure, etc.), trains separate logistic regression models per competition (filtering features with R>0.8 correlation or p>0.05), and calculates mean-centered feature contributions to log-odds. These numerical outputs are transformed into natural language through a four-step LLM prompt process: system role definition, knowledge base injection (43 Q&A pairs), synthesized text generation with percentile categorization, and few-shot examples. The approach prioritizes interpretability over model accuracy, enabling coaches to understand why shots have certain scoring probabilities relative to competition context.

## Key Results
- Case 4 (full wordalisation with all prompt steps) achieved the highest engagement score while maintaining second-highest accuracy
- Competition-specific models enable contextually relevant explanations (e.g., "closer than average" relative to same competition)
- Feature contribution calculations based on logistic regression coefficients provide interpretable, mathematically grounded explanations
- Wordalisations successfully balance technical accuracy with engaging, coach-friendly narratives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Logistic regression coefficients provide directly interpretable feature contributions when features are mean-centered.
- Mechanism: The log-odds formulation `log-odds(x) = β₀ + Σβⱼxⱼ` allows each feature's contribution to be isolated as `βⱼ · x̃ⱼ` (where `x̃ⱼ` is mean-centered). This quantifies how much a specific shot deviates from the dataset average for each feature.
- Core assumption: Linearity in log-odds space adequately captures the relationship between features and goal probability; feature correlations have been adequately addressed through selection.
- Evidence anchors:
  - [section 2.3]: "We calculate the contribution of each feature to the log-odds by first mean-centering the feature values... ensuring that each feature's contribution is measured relative to its baseline value."
  - [section 4]: "The linear nature of the logistic regression ensures that we make a correct interpretation of the variables."
  - [corpus]: Limited direct validation in corpus; related work (Anzer & Bauer 2021) uses SHAP for non-linear models, suggesting coefficient-based interpretability is specific to linear models.
- Break condition: When features have high multicollinearity that wasn't removed (the paper dropped features with R > 0.8, but residual correlation may remain), coefficient interpretation becomes unreliable. Also breaks if the true relationship is strongly non-linear.

### Mechanism 2
- Claim: Structured four-step prompt engineering (identity → knowledge → data → instructions) converts numerical model outputs into coherent natural language while preserving accuracy.
- Mechanism: Each step scaffolds the LLM's generation: (1) system prompt sets role as "shot commentator," (2) Q&A pairs establish domain knowledge and response style (43 examples provided), (3) synthesized text translates numbers to football concepts using percentile-based categories, (4) few-shot examples demonstrate the desired narrative format.
- Core assumption: The LLM can faithfully follow multi-step instructions without hallucinating details not present in the synthesized text; the percentile thresholds (±0.1 log-odds) correctly separate "contributing" from "neutral" features.
- Evidence anchors:
  - [abstract]: "uses the co-efficients of this regression model to write sentences describing how factors (such as distance, angle and defensive pressure) contribute"
  - [section 2.4]: "We categorize the xG values based on predefined percentiles into five categories: 'slim chance' for the 25th percentile... 'excellent chance' for values above the 90th percentile"
  - [section 3.4]: "Case 4 (i.e., full wordalisation)... achieves the second-highest accuracy while maintaining the highest engagement score"
  - [corpus]: Caut et al. [2025] introduced wordalisation for player scouting rankings, but this extension to model explanation is novel.
- Break condition: When the LLM adds details not grounded in the synthesized text (hallucination), or when the threshold-based filtering (±0.1) excludes features that coaches consider important but have small mathematical contributions.

### Mechanism 3
- Claim: Separate models fitted per competition enable context-relative explanations that coaches find more meaningful than universal models.
- Mechanism: Rather than one global xG model, the pipeline fits independent logistic regressions to each of six competitions. Feature contributions are calculated relative to shots within that competition, making explanations like "closer than average" contextually appropriate.
- Core assumption: Within-competition shot distributions are sufficiently different that competition-specific models add value; sample sizes within each competition are adequate for stable coefficient estimation.
- Evidence anchors:
  - [section 2.2]: "This means we fit different expected goal models independently to each of the six competitions... Our aim is not to build the 'best' expected goals model but to be able to explain the probability of scoring a particular shot relative to other shots in the same competition."
  - [corpus]: No direct corpus validation of competition-specific vs. global models for explainability.
- Break condition: When a competition has insufficient shots (small sample size leading to unstable coefficients), or when comparing shots across competitions becomes necessary (the model doesn't support this).

## Foundational Learning

- **Logistic regression and log-odds interpretation**
  - Why needed here: The entire explainability mechanism relies on understanding that coefficients represent change in log-odds per unit change in feature. Without this, the contribution calculations are opaque.
  - Quick check question: If a feature has coefficient β = -0.5 and a shot's mean-centered value is 2 units above average, what is the feature's contribution to log-odds? (Answer: -1.0)

- **Percentile-based categorization**
  - Why needed here: Converting continuous xG values (e.g., 0.14) to qualitative labels ("high-quality chance") is the bridge between model output and natural language.
  - Quick check question: Given thresholds at 0.028, 0.056, 0.096, and 0.3, how would you categorize an xG of 0.07? (Answer: "decent chance" - between 50th and 75th percentile)

- **Few-shot prompting structure**
  - Why needed here: Understanding why "tell it what it knows" and "tell it how to answer" are separate steps helps debug when the LLM produces off-target responses.
  - Quick check question: What is the difference between providing Q&A pairs (step 2) and providing output examples (step 4)? (Answer: Q&A pairs establish domain knowledge; output examples establish format and style)

## Architecture Onboarding

- **Component map:**
StatsBomb API -> Feature Generator -> Logistic Regression (per competition) -> Contribution Calculator -> Text Synthesizer <- Percentile thresholds <- Q&A Knowledge Base + Few-shot Examples -> LLM Prompt Constructor -> Natural Language Output

- **Critical path:** The feature-to-text synthesis (Section 2.4, "Tell it what data to use") is the most fragile step. Errors in percentile categorization or contribution thresholding propagate directly to the LLM and cannot be corrected downstream.

- **Design tradeoffs:**
  - Logistic regression vs. more accurate models: Paper explicitly trades some accuracy for interpretability. Section 2.2: "For our study interpretability is emphasised because we want to build wordalisations."
  - Competition-specific vs. global models: More contextually relevant explanations, but cannot compare across competitions.
  - Threshold ±0.1 for contributions: Arbitrary but motivated; smaller values barely shift probability, larger values may omit relevant context.

- **Failure signatures:**
  - LLM output contradicts synthesized text -> Check prompt construction; LLM may be ignoring instructions
  - All shots have similar descriptions -> Check contribution distribution; features may not vary much in dataset
  - Negative contributions described as positive -> Check sign consistency between coefficient calculation and text mapping functions
  - Low accuracy scores for Case 4 -> Examine whether few-shot examples match the evaluation distribution

- **First 3 experiments:**
  1. **Reproduce contribution plots** for the two shots in Figure 3 using the provided code (github.com/Peggy4444/shotsGPT) to verify the feature contribution calculation matches the paper's visualization.
  2. **Ablate prompt steps**: Generate descriptions using only steps 1+3 (skip knowledge and few-shot) and compare engagement/accuracy to full Case 4 to quantify each component's contribution.
  3. **Test threshold sensitivity**: Vary the ±0.1 contribution threshold (try ±0.05 and ±0.2) and measure how accuracy and description length change to validate the paper's somewhat arbitrary choice.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's reliance on logistic regression coefficients assumes linear relationships and no significant multicollinearity
- The ±0.1 contribution threshold for feature selection appears somewhat arbitrary, and the paper acknowledges this could be refined
- Competition-specific models, while contextually relevant, cannot support cross-competition comparisons which may limit broader tactical analysis

## Confidence

- **High Confidence**: The logistic regression contribution calculation mechanism (Mechanism 1) is mathematically sound and directly verifiable through the provided code. The percentile categorization system is straightforward and reproducible.
- **Medium Confidence**: The prompt engineering approach (Mechanism 2) is well-structured but depends heavily on the specific LLM's adherence to instructions, which can vary. The competition-specific model benefits are plausible but not directly validated against global models.
- **Low Confidence**: The claim that this approach significantly bridges the technical-practical communication gap is supported by user studies (implied by engagement scores) but not directly tested with actual coaches.

## Next Checks

1. **Cross-validation of coefficients**: Apply k-fold cross-validation to the logistic regression models to ensure coefficient stability across different training subsets, particularly for competitions with smaller sample sizes.
2. **Threshold sensitivity analysis**: Systematically test the ±0.1 contribution threshold across a range (e.g., ±0.05 to ±0.3) to quantify its impact on both accuracy and engagement scores, and determine if the current choice is optimal.
3. **Coach validation study**: Conduct a small-scale user study with football coaches to assess whether the wordalised explanations actually improve understanding and decision-making compared to traditional xG tables or visualizations.