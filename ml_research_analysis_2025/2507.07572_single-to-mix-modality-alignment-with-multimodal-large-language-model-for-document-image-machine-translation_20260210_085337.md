---
ver: rpa2
title: Single-to-mix Modality Alignment with Multimodal Large Language Model for Document
  Image Machine Translation
arxiv_id: '2507.07572'
source_url: https://arxiv.org/abs/2507.07572
tags:
- image
- translation
- m4doc
- mllm
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces M4Doc, a framework that leverages multimodal
  large language models (MLLMs) to enhance document image machine translation (DIMT)
  performance. The core idea is a "single-to-mix modality alignment" strategy, where
  an image-only encoder is aligned with MLLM's multimodal representations during training,
  enabling a lightweight DIMT model to capture visual-textual correlations without
  the computational cost of using MLLMs at inference.
---

# Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation

## Quick Facts
- arXiv ID: 2507.07572
- Source URL: https://arxiv.org/abs/2507.07572
- Reference count: 40
- Primary result: Achieves SOTA DIMT performance with +4.30 BLEU in-domain, +5.54 BLEU cross-domain, using MLLM distillation for efficiency

## Executive Summary
M4Doc introduces a novel "single-to-mix modality alignment" strategy that leverages a multimodal large language model (MLLM) to enhance document image machine translation (DIMT). By aligning an image-only encoder to the MLLM's multimodal representations during training, M4Doc enables a lightweight model to capture visual-textual correlations without the computational cost of using MLLMs at inference. Experiments demonstrate state-of-the-art translation quality, significant improvements over cascade and end-to-end baselines, and enhanced generalization in challenging scenarios like long contexts and complex layouts.

## Method Summary
M4Doc employs a teacher-student framework where a frozen MLLM acts as the teacher and a lightweight DIMT model serves as the student. During training, the MLLM receives both image and ground-truth text, while the student encoder receives only the image. An alignment loss (cosine similarity) is minimized between the student's representation and the MLLM's multimodal representation, enabling the student to infer textual context from visual features alone. At inference, the MLLM is discarded, maintaining computational efficiency while preserving the learned multimodal knowledge. The framework uses a dual-encoder architecture with a separate alignment encoder and image encoder, combined with a modified Transformer decoder featuring dual cross-attention modules.

## Key Results
- Achieves state-of-the-art BLEU scores: +4.30 over DIMTDA in-domain, +5.54 in cross-domain zero-shot settings
- Outperforms cascade and end-to-end baselines by significant margins across multiple metrics (BLEU, COMET, STEDS)
- Demonstrates improved generalization in challenging scenarios including long contexts and complex layouts
- Maintains high inference efficiency by discarding the MLLM during inference

## Why This Works (Mechanism)

### Mechanism 1: Representation Distillation via Single-to-Mix Alignment
The framework forces a "single-to-mix" alignment where the student encoder receives only an image while the teacher MLLM receives both image and ground-truth text. By minimizing the distance between their representations, the student learns to predict textual semantics from visual features alone, effectively compressing multimodal reasoning into a visual encoder.

### Mechanism 2: Decoupled Inference for Efficiency and Generalization
The MLLM is used only during training as a guide, then discarded at inference. The lightweight encoder learns to mimic the MLLM's rich representations, inheriting its generalization ability (cross-domain/complex layouts) without the latency penalty of using the full MLLM.

### Mechanism 3: Separated Encoder Pathways to Prevent Task Interference
The model uses two distinct visual pathways: one for standard image encoding and another for alignment with MLLM representations. Ablation studies show forcing a single encoder to do both degrades performance, likely because direct translation and abstract multimodal alignment have conflicting feature requirements.

## Foundational Learning

**Knowledge Distillation (Representation Alignment)**: The core technique of matching internal hidden states between teacher and student models. Quick check: Why does the paper use Cosine Similarity instead of MSE for the alignment loss?

**Multimodal vs. Cross-Modal Inputs**: Understanding the asymmetry where teacher sees (Image + Text) but student sees only (Image). Quick check: What specific input format is used for the MLLM to generate the target representation?

**Transformer Decoder with Dual Cross-Attention**: The translation decoder is modified to attend to both standard image features and aligned multimodal features. Quick check: In the decoder layer, does self-attention come before or after cross-attention for the two image streams?

## Architecture Onboarding

**Component map**: MLLM (Teacher) -> Alignment Encoder -> Image Encoder -> Translation Decoder

**Critical path**:
1. Training: Image & Text to MLLM → Get $H_{MLLM}$
2. Image to Alignment Enc → Get $H_{Align}$
3. Image to Image Enc → Get $H_{Image}$
4. Calculate $L_{align}$ (Cosine between $H_{MLLM}$ and $H_{Align}$)
5. Decoder generates translation using $H_{Align}$ and $H_{Image}$
6. Calculate $L_{trans}$ (Cross Entropy)
7. Update weights (MLLM frozen)
8. Inference: Drop MLLM. Run Alignment Enc, Image Enc, Decoder

**Design tradeoffs**: MLLM selection significantly impacts performance (document-focused vs. natural image MLLMs). Loss weighting ($\alpha$) balances translation and alignment losses; $\alpha=1.0$ found optimal.

**Failure signatures**: Representation collapse if dimensions don't match via projection; modality mismatch if MLLM prompts differ from training; ablation logic shows merging encoders degrades BLEU scores.

**First 3 experiments**:
1. Sanity Check Alignment: Train only Alignment Encoder (freeze decoder) to validate student can mimic teacher
2. Ablation Run: Full model vs. model without Alignment Encoder on validation set
3. Cross-Domain Test: Evaluate on Political Report subset vs. in-domain test set

## Open Questions the Paper Calls Out
- **Region-specific translation**: The authors plan to explore integrating user prompts to translate specific image regions rather than full-page translation
- **OCR noise robustness**: How robust is the alignment encoder when the teacher MLLM is provided with noisy OCR text rather than ground truth text during training?
- **Teacher parameter freezing**: To what extent does freezing the MLLM teacher parameters limit the student model's ability to learn specialized document translation features?

## Limitations
- Does not specify exact implementation details of the dual cross-attention modules added to the decoder
- Performance heavily depends on selecting an appropriate MLLM (document-focused vs. natural image focused)
- Claims of efficiency gains are inferred rather than empirically measured with latency comparisons

## Confidence
**High Confidence**: Core mechanism of using alignment loss to distill MLLM representations is clearly described and supported by ablation studies
**Medium Confidence**: Specific contribution of dual cross-attention modules and optimal alignment loss weight (α=1.0) supported by ablation, but exact architectural details remain unclear  
**Low Confidence**: Generalization to unseen domains based on limited dataset testing without confidence intervals or statistical significance tests

## Next Checks
1. Implement missing details of dual cross-attention modules and verify reported BLEU improvements are reproducible
2. Test M4Doc on a different DIMT benchmark (e.g., Flickr30k Entities, XTD) to assess generalization beyond DoTA and DITrans datasets
3. Measure actual inference latency (milliseconds per example) compared to full MLLM-based baselines to validate efficiency claims