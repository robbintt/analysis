---
ver: rpa2
title: Understanding and Enhancing the Planning Capability of Language Models via
  Multi-Token Prediction
arxiv_id: '2509.23186'
source_url: https://arxiv.org/abs/2509.23186
tags:
- token
- prediction
- layer
- transfer
- reachability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how Multi-Token Prediction (MTP) can improve
  the ability of large language models to learn transitive relations, which are essential
  for planning tasks. The authors theoretically analyze a simplified Transformer model
  to show that MTP enables learning of both adjacency and reachability beyond what
  standard next-token prediction achieves.
---

# Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction

## Quick Facts
- **arXiv ID**: 2509.23186
- **Source URL**: https://arxiv.org/abs/2509.23186
- **Reference count**: 40
- **One-line primary result**: MTP with Next-Token Injection (NTI) and Transformer transfer layer achieves up to 71.32% accuracy on degree-2 paths in synthetic graphs, significantly outperforming standard next-token prediction (63.80%).

## Executive Summary
This paper investigates how Multi-Token Prediction (MTP) can enhance large language models' ability to learn transitive relations essential for planning tasks. The authors theoretically analyze a simplified Transformer model to show that MTP enables learning of both adjacency and reachability beyond what standard next-token prediction achieves. They propose two architectural enhancements - Next-Token Injection (NTI) for stabilizing transfer layer learning, and a Transformer-based transfer layer for better modeling of multi-step relations. Experiments on synthetic graphs and Blocksworld planning benchmark demonstrate significant accuracy improvements, particularly for complex transitive paths.

## Method Summary
The authors propose enhancing Transformers for planning by using Multi-Token Prediction (MTP) to predict not just the next token but multiple future tokens simultaneously. They analyze a simplified Transformer model to show that MTP's transfer layer learns multi-step adjacency information, enabling the backbone to capture transitive reachability beyond direct training examples. Two architectural enhancements are introduced: Next-Token Injection (NTI) which injects ground-truth next tokens into the transfer layer input to stabilize learning, and a Transformer-based transfer layer to better model multi-hop relations. The approach is evaluated on synthetic directed acyclic graphs and the Blocksworld planning benchmark.

## Key Results
- MTP with NTI and Transformer transfer layer achieves 71.32% accuracy on degree-2 paths in synthetic graphs vs. 63.80% with baseline next-token prediction
- On Blocksworld with 100 training samples, MTP-6L-NTI reaches 98.33% accuracy vs. 89.20% for standard fine-tuning
- NTI consistently improves performance, especially on degree-2 and degree-3 paths where transitive reasoning is critical
- Linear transfer layers show limitations compared to Transformer-based transfer layers for modeling multi-hop relations

## Why This Works (Mechanism)

### Mechanism 1: Transfer Layer Approximation of Graph Adjacency
The transfer layer ($W_T$) in MTP learns to approximate the graph's adjacency matrix (or its powers), enabling encoding of multi-hop transitions. By optimizing the 2nd-step loss, gradient updates $W_T$ based on prediction error, increasing weights corresponding to intermediate node transitions. If the backbone correctly predicts next-step node $d$, increasing $W_T(d,k')$ enables learning the adjacency between $d$ and $k'$. Core assumption: simplified theoretical analysis holds for standard Transformers. Break condition: if backbone fails to predict intermediate node $d$ correctly, transfer layer receives corrupted input.

### Mechanism 2: Gradient Composition for Transitive Reachability
MTP enables backbone to learn unobserved transitive reachability ($A \to C$) by composing observed reachability ($A \to B$) with learned adjacency ($B \to C$) via 2nd-step supervision. The 2nd-step loss propagates gradients to backbone's reachability matrix ($W_V$). When transfer layer ($W_T$) signals strong connection $k \to k'$ and target is reachable from $k'$, loss reinforces connection $k \to \text{target}$ in backbone, even if path wasn't in training data. Core assumption: transfer layer has captured true adjacency relationships. Break condition: if "spurious adjacency" problem dominates signal in $W_M$, backbone may overfit to incorrect paths.

### Mechanism 3: Next-Token Injection (NTI) as Supervision Shortcut
NTI adds ground-truth next token embedding (scaled by learnable factor $k$) to backbone's hidden state, creating residual connection that allows transfer layer to be optimized directly on correct structural transitions even if backbone's intermediate output is uncertain. This creates shortcut for gradient flow, bypassing backbone prediction noise. Core assumption: access to ground-truth next tokens during training; $k$ balances internal representation and external supervision effectively. Break condition: if injection weight $k$ is too high, model may ignore backbone representation, leading to overfitting or failure to generalize.

## Foundational Learning

- **Concept: Transitive vs. Direct Reachability**
  - Why needed here: Core problem is standard models memorize direct edges but fail to compose them into paths
  - Quick check question: If a model sees paths $A \to B$ and $B \to C$, can it infer path from $A$ to $C$ without explicit training on $A \to C$ sequence?

- **Concept: Multi-Token Prediction (MTP) Objective**
  - Why needed here: This is the intervention - must understand loss function is sum of cross-entropies for $t+1, t+2, \dots$
  - Quick check question: How does calculating loss on $t+2$ differ from chaining two next-token predictions?

- **Concept: Transformer Linear Algebra Decomposition**
  - Why needed here: Paper reduces Transformers to matrix multiplications ($W_M, W_V, W_T$) to prove learning dynamics
  - Quick check question: In simplified model, does output logit depend more on current token (adjacency) or target token (reachability)?

## Architecture Onboarding

- **Component map**: Input -> Backbone (GPT-style) -> [If Training: Add NTI] -> Transfer Layer ($W_T$) -> Logits -> Loss

- **Critical path**: Input $\to$ Backbone ($h_n$) $\to$ [If Training: Add NTI] $\to$ Transfer Layer ($W_T$) $\to$ Logits $\to$ Loss

- **Design tradeoffs**:
  - *Linear vs. Transformer Transfer Layer*: Linear is efficient but limited in expressivity; Transformer transfer layers capture multi-hop relations better but add compute overhead
  - *NTI*: Improves accuracy significantly but requires modification of training loop to inject ground truth

- **Failure signatures**:
  - Degree-2/3 Performance Collapse: Model works on training paths but fails on transitive compositions
  - Graph Size Saturation: Performance degrades on graphs with $>300$ nodes if embedding dimension isn't scaled
  - Spurious Edges: Weight analysis shows high values for non-existent edges if backbone prediction is too noisy

- **First 3 experiments**:
  1. Replicate Degree Hierarchy: Train 1-token vs. 2-token model on 100-node synthetic DAG. Verify 1-token fails on Degree-2 paths while 2-token improves.
  2. NTI Ablation: Run MTP with and without NTI on Blocksworld task. Plot accuracy against training set size to see if NTI stabilizes low-data regimes.
  3. Transfer Layer Analysis: Visualize projected transfer matrix ($W_t W_T W_o$) to verify if it resembles ground-truth adjacency matrix.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can continuous and ambiguous real-world tasks be effectively abstracted into discrete state representations for multi-step prediction? The current study relies on synthetic directed acyclic graphs and discrete Blocksworld state space. Successful application to continuous domains like robotic motion planning without manual discretization would resolve this.

- **Open Question 2**: Can the Next-Token Injection (NTI) mechanism be extended to generate guiding signals in unsupervised settings? Current NTI implementation relies on injecting ground-truth next token during training, requiring explicit supervision. An unsupervised variant maintaining or improving planning accuracy without ground-truth token injection would resolve this.

- **Open Question 3**: How can the proposed transfer layer architecture be combined with explicit planning modules like chain-of-thought or backtracking search? The conclusion suggests combining transfer layer with explicit planning modules to enhance framework. A hybrid system where MTP transfer layers augment chain-of-thought reasoning or search heuristics would demonstrate superior performance.

## Limitations
- Theoretical analysis relies on strong simplifying assumptions (linear attention, single-layer Transformers) that may not hold for deeper architectures
- No evidence of scalability to larger, more complex planning domains beyond Blocksworld
- Improvements demonstrated only on structured planning tasks with explicit transitive relationships, not general language tasks
- Performance degrades on larger graphs unless embedding dimensions are scaled proportionally, suggesting higher computational requirements

## Confidence

**High Confidence (8-10/10)**: Experimental results showing MTP outperforming next-token prediction on synthetic graphs and Blocksworld tasks are well-documented and reproducible.

**Medium Confidence (5-7/10)**: Theoretical analysis provides plausible explanation for why MTP works, but simplifying assumptions limit generalizability. Mechanism claims are logically consistent but not empirically validated across different architectures.

**Low Confidence (1-4/10)**: Claims about MTP's effectiveness in real-world planning domains beyond Blocksworld, and its benefits for general language tasks, are not supported by evidence presented.

## Next Checks

1. **Architecture Ablation Study**: Test whether theoretical benefits of MTP hold when relaxing simplifying assumptions by comparing performance across: (a) 1-layer vs. 12-layer Transformers, (b) attention-free vs. attention-based models, and (c) different embedding dimension scales.

2. **Transfer Layer Analysis**: Conduct systematic analysis of what transfer layer actually learns by: (a) visualizing learned weight matrices $W_T$ for different step sizes, (b) testing whether transfer layer can be transferred between different graphs while maintaining performance, and (c) analyzing impact of randomizing transfer layer weights during training.

3. **Generalization Stress Test**: Evaluate MTP on planning tasks with: (a) cycles and non-DAG structures, (b) noisy or incomplete training data where some transitive relationships are missing, and (c) larger state spaces (500+ nodes) to test scalability claims.