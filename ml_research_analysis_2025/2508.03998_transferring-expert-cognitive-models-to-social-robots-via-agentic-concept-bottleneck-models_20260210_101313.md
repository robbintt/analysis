---
ver: rpa2
title: Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck
  Models
arxiv_id: '2508.03998'
source_url: https://arxiv.org/abs/2508.03998
tags:
- intervention
- social
- facilitator
- group
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of augmenting human facilitators
  in group intervention sessions by introducing a social robot co-facilitator powered
  by a concept bottleneck model (CBM). The core innovation lies in a transfer learning
  framework that distills the broad social understanding of a foundation model into
  a transparent CBM, enabling interpretable, real-time decision-making.
---

# Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2508.03998
- Source URL: https://arxiv.org/abs/2508.03998
- Reference count: 0
- Social robot co-facilitator with interpretable concept bottleneck model achieves near-perfect recall (0.991) in predicting intervention needs and transferring expert facilitation knowledge to novices

## Executive Summary
This paper addresses the challenge of augmenting human facilitators in group intervention sessions by introducing a social robot co-facilitator powered by a concept bottleneck model (CBM). The core innovation lies in a transfer learning framework that distills the broad social understanding of a foundation model into a transparent CBM, enabling interpretable, real-time decision-making. The system predicts the need for intervention and generates actionable recommendations using human-understandable concepts such as participant engagement and sentiment.

The research demonstrates that the CBM significantly outperforms direct zero-shot FM predictions, successfully transfers expert facilitation knowledge to novices, and allows real-time human correction of its reasoning. The approach combines the generalization power of large language models with the transparency and efficiency of concept bottleneck architectures, creating a practical solution for real-world group facilitation scenarios.

## Method Summary
The authors developed a two-stage transfer learning framework to distill a foundation model's capabilities into a transparent concept bottleneck model. First, they fine-tuned a foundation model (FM) on a small dataset of group intervention transcripts to predict expert facilitator actions. Then, they used the FM as a teacher to train a CBM that operates on interpretable social concepts like participant engagement, sentiment, and speaking dynamics. The CBM generates both predictions and human-understandable explanations, enabling real-time intervention decisions and allowing facilitators to correct the model's reasoning through interactive feedback. The system was evaluated in both simulated and real-world settings with novice facilitators.

## Key Results
- CBM achieved near-perfect recall of 0.991 in predicting intervention needs, significantly outperforming direct zero-shot FM predictions
- Successful transfer of expert facilitation knowledge to novice facilitators, reducing the performance gap between experienced and inexperienced facilitators
- Real-time human correction capability demonstrated, with facilitators able to override CBM recommendations and improve system performance over time
- Robust generalization across different group dynamics and intervention types

## Why This Works (Mechanism)
The CBM architecture works by creating an interpretable bottleneck between raw input data (transcripts) and final predictions. By explicitly modeling human-understandable concepts like engagement levels and sentiment, the model can generate explanations for its decisions that facilitators can verify and correct. The transfer learning approach allows the CBM to leverage the FM's broad social understanding while maintaining the efficiency and transparency needed for real-time deployment. The agentic component enables the system to adapt its recommendations based on facilitator feedback, creating a collaborative human-AI partnership.

## Foundational Learning

**Concept Bottleneck Models** - Why needed: To create interpretable AI systems where decisions can be traced through human-understandable concepts rather than opaque neural network layers. Quick check: Can the model's reasoning be verified by domain experts?

**Transfer Learning** - Why needed: To efficiently adapt pre-trained models to specific domains with limited labeled data. Quick check: Does fine-tuning improve performance on domain-specific tasks?

**Foundation Models** - Why needed: To leverage large-scale pre-training for generalization across diverse social scenarios. Quick check: Does the FM capture nuanced social dynamics beyond task-specific training?

**Human-AI Collaboration** - Why needed: To combine AI efficiency with human expertise and contextual understanding. Quick check: Does real-time correction improve system performance over time?

## Architecture Onboarding

**Component Map:** Transcripts -> Concept Extractor -> CBM Reasoning Layer -> Intervention Prediction -> Real-time Feedback Loop

**Critical Path:** Raw transcript data flows through concept extraction, which feeds into the CBM's reasoning layer. The CBM generates predictions and explanations, which are presented to facilitators for potential correction. Corrections update the model through online learning.

**Design Tradeoffs:** The system trades some prediction accuracy for interpretability and real-time responsiveness. The CBM is smaller and faster than the FM but may miss some nuanced patterns that the FM captures.

**Failure Signatures:** Poor concept extraction from transcripts, misinterpretation of social dynamics, over-reliance on historical patterns that don't apply to new group dynamics, failure to incorporate real-time feedback effectively.

**First 3 Experiments:**
1. Baseline comparison: CBM vs. direct FM predictions on held-out test data
2. Knowledge transfer evaluation: Novice facilitator performance with vs. without CBM assistance
3. Real-time correction impact: System performance improvement rate with facilitator feedback

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on relatively small dataset (64 sessions from 2-3 senior facilitators) that may limit generalizability
- CBM's reliance on transcripts could miss non-verbal cues crucial in social facilitation
- Lacks long-term evaluation of sustained effectiveness after initial knowledge transfer
- Real-time correction capability demonstrated but not systematically evaluated for frequency or impact

## Confidence

**High Confidence:** CBM outperforming direct FM predictions (0.991 recall), measurable knowledge transfer from senior to novice facilitators

**Medium Confidence:** Real-time correction capability and human oversight effectiveness, robustness across different group dynamics

**Low Confidence:** Long-term impact on group outcomes, scalability to diverse intervention types, generalization to facilitators without foundational training

## Next Checks

1. Conduct longitudinal studies tracking CBM-assisted novice facilitators over 6-12 months to assess sustained knowledge transfer and evolving effectiveness
2. Expand testing to diverse intervention types (conflict resolution, team building) and cultural contexts to evaluate generalization limits
3. Implement A/B testing comparing CBM-assisted sessions against traditional facilitator-only sessions with objective outcome measures (behavioral changes, session completion rates)