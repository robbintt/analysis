---
ver: rpa2
title: 'Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network
  for Semi-supervised 3D Medical Image Segmentation'
arxiv_id: '2502.11456'
source_url: https://arxiv.org/abs/2502.11456
tags:
- segmentation
- medical
- image
- learning
- pseudo-labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semi-supervised 3D medical
  image segmentation by improving the quality of pseudo-labels generated in consistency-based
  learning. The key contributions include a Cooperative Rectification Learning Network
  (CRLN) that leverages learned class prototypes as external priors to rectify pseudo-labels
  at the voxel level, a Dynamic Interaction Module (DIM) that facilitates pairwise
  and cross-class interactions between prototypes and multi-resolution image features,
  and a Collaborative Positive Supervision (CPS) mechanism that enhances uncertain
  region discrimination through unassertive positive samples.
---

# Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network for Semi-supervised 3D Medical Image Segmentation

## Quick Facts
- arXiv ID: 2502.11456
- Source URL: https://arxiv.org/abs/2502.11456
- Authors: Yanyan Wang; Kechen Song; Yuyuan Liu; Shuai Ma; Yunhui Yan; Gustavo Carneiro
- Reference count: 20
- One-line primary result: CRLN achieves state-of-the-art semi-supervised 3D medical image segmentation with Dice scores of 91.74% (Left Atrium), 79.17% (Pancreas-CT), and 86.73% (BraTS19) under 10% labelled data protocol.

## Executive Summary
This paper addresses the challenge of semi-supervised 3D medical image segmentation by improving the quality of pseudo-labels generated in consistency-based learning. The authors propose a Cooperative Rectification Learning Network (CRLN) that leverages learned class prototypes as external priors to rectify pseudo-labels at the voxel level. The method introduces a Dynamic Interaction Module (DIM) that facilitates pairwise and cross-class interactions between prototypes and multi-resolution image features, along with a Collaborative Positive Supervision (CPS) mechanism that enhances uncertain region discrimination through unassertive positive samples. Experimental results on three public datasets demonstrate that the proposed method achieves state-of-the-art performance under the 10% labelled data protocol.

## Method Summary
The proposed Cooperative Rectification Learning Network (CRLN) improves semi-supervised 3D medical image segmentation by leveraging learned class prototypes as external priors to rectify pseudo-labels at the voxel level. The method consists of three key components: a Dynamic Interaction Module (DIM) that captures pairwise and cross-class interactions between prototypes and multi-resolution image features, a Collaborative Positive Supervision (CPS) mechanism that enhances uncertain region discrimination through unassertive positive samples, and a prototype-based rectification process that improves pseudo-label quality. The framework is trained using a combination of supervised loss on labelled data and consistency-based loss on unlabelled data, with the rectification process guided by prototype prototypes learned from labelled examples.

## Key Results
- CRLN achieves Dice scores of 91.74% on the Left Atrium dataset, 79.17% on the Pancreas-CT dataset, and 86.73% on the BraTS19 dataset under the 10% labelled data protocol.
- The method outperforms state-of-the-art consistency-based semi-supervised segmentation approaches across all three evaluated datasets.
- Significant improvements are observed in segmentation accuracy compared to baseline methods, particularly in regions with complex anatomical structures.

## Why This Works (Mechanism)
The proposed method works by leveraging learned class prototypes as external priors to rectify pseudo-labels at the voxel level, addressing the limitation of consistency-based methods that rely solely on internal consistency constraints. The Dynamic Interaction Module facilitates pairwise and cross-class interactions between prototypes and multi-resolution image features, allowing the model to capture both local and global contextual information. The Collaborative Positive Supervision mechanism enhances uncertain region discrimination by incorporating unassertive positive samples, which helps the model better distinguish between ambiguous regions and true background. This combination of prototype-based rectification and enhanced supervision enables more accurate pseudo-label generation, which in turn improves the quality of semi-supervised learning.

## Foundational Learning
- **Semi-supervised learning**: Learning from both labelled and unlabelled data; needed to reduce annotation costs in medical imaging; quick check: model should improve with limited labelled data.
- **Consistency-based regularization**: Enforcing consistency between different views of the same input; needed for robust feature learning; quick check: augmented versions should produce similar outputs.
- **Class prototypes**: Representative feature vectors for each class; needed as external priors for pseudo-label rectification; quick check: prototypes should capture semantic class characteristics.
- **Voxel-level supervision**: Per-pixel classification rather than image-level; needed for precise medical segmentation; quick check: predictions should align with anatomical boundaries.
- **Multi-resolution feature fusion**: Combining features at different scales; needed to capture both local details and global context; quick check: model should handle objects of