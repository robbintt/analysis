---
ver: rpa2
title: Semantic-Driven Topic Modeling for Analyzing Creativity in Virtual Brainstorming
arxiv_id: '2509.16835'
source_url: https://arxiv.org/abs/2509.16835
tags:
- topic
- ideas
- each
- topics
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a semantic-driven topic modeling framework
  for analyzing creativity in virtual brainstorming sessions. The framework integrates
  transformer-based embeddings (Sentence-BERT), dimensionality reduction (UMAP), clustering
  (HDBSCAN), and topic extraction with refinement to automatically discover coherent
  themes from brainstorming transcripts.
---

# Semantic-Driven Topic Modeling for Analyzing Creativity in Virtual Brainstorming

## Quick Facts
- arXiv ID: 2509.16835
- Source URL: https://arxiv.org/abs/2509.16835
- Reference count: 40
- Primary result: Sentence-BERT + UMAP + HDBSCAN pipeline achieves 0.687 CV coherence vs 0.462 for LDA

## Executive Summary
This study introduces a semantic-driven topic modeling framework for analyzing creativity in virtual brainstorming sessions. The approach uses transformer-based embeddings (Sentence-BERT) to capture semantic similarity at the sentence level, followed by dimensionality reduction (UMAP) and density-based clustering (HDBSCAN) to identify coherent themes. Evaluated on student Zoom brainstorming sessions, the framework significantly outperforms established baselines like LDA and BERTopic in topic coherence, providing interpretable insights into both convergent and divergent dimensions of group creativity.

## Method Summary
The framework processes individual ideas/sentences from brainstorming transcripts through four stages: (1) Sentence-BERT embeddings to capture semantic meaning, (2) UMAP dimensionality reduction to 2D, (3) HDBSCAN clustering with noise filtering, and (4) topic extraction via per-cluster vocabulary analysis using average cosine similarity scoring. The approach specifically handles short, conversational text and filters outliers that don't fit established patterns, enabling discovery of coherent themes that reflect the depth and diversity of ideas explored.

## Key Results
- Achieved average coherence score of 0.687 (CV), significantly outperforming LDA (0.462), ETM (0.544), and BERTopic (0.552)
- Effectively filtered noise while identifying outliers, improving topic purity
- Captured semantic similarity at sentence level, enabling discovery of coherent themes from conversational text
- Provided interpretable insights into both convergent and divergent dimensions of group creativity

## Why This Works (Mechanism)

### Mechanism 1
Transformer-based embeddings capture semantic similarity in short, conversational text more effectively than statistical co-occurrence models. By mapping sentences to a dense vector space, the model groups ideas based on contextual meaning rather than shared vocabulary, detecting related concepts even with different wording. Core assumption: Sentence-BERT's semantic geometry generalizes to student brainstorming transcripts. Break condition: Domain-specific jargon not present in SBERT pre-training corpus.

### Mechanism 2
Density-based clustering (HDBSCAN) improves topic purity by isolating noise and outliers that distance-based methods would force into invalid clusters. HDBSCAN identifies high-density regions as clusters and labels low-density points as noise (-1), preventing incoherent ideas from diluting representative topic words. Core assumption: Valid brainstorming ideas form dense clusters in reduced semantic space. Break condition: Highly divergent sessions appear uniformly sparse, causing most ideas to be classified as noise.

### Mechanism 3
Reducing dimensionality (UMAP) before clustering mitigates the "curse of dimensionality" where distance metrics lose discriminative power. UMAP projects high-dimensional SBERT vectors into lower-dimensional manifold while preserving local semantic relationships, making distance metrics meaningful for HDBSCAN. Core assumption: Essential semantic structure can be captured in lower-dimensional projection without critical information loss. Break condition: Poor UMAP parameter tuning tears distinct clusters or collapses separate themes.

## Foundational Learning

### Concept: Topic Coherence (C_v)
Why needed: Primary success metric (0.687 vs. 0.462 for LDA). C_v measures semantic similarity of high-scoring words within a topic to approximate human interpretability. Quick check: If a topic model outputs "apple, banana, fruit, car," would the coherence score increase or decrease compared to "apple, banana, fruit, pear"?

### Concept: The Curse of Dimensionality
Why needed: Paper explicitly justifies UMAP by citing this phenomenon. In high-dimensional space (SBERT outputs 768 dimensions), all points tend to become equidistant, making density estimation impossible. Quick check: Why does increasing dimensions make it harder for clustering algorithms to find "dense" regions?

### Concept: Semantic vs. Lexical Similarity
Why needed: Core innovation moves from lexical overlap to semantic meaning. "Improving the cafeteria" and "Better food options" are lexically dissimilar but semantically close. Quick check: How does Sentence-BERT handle "The bank is closed" vs. "He sat on the river bank" differently than LDA?

## Architecture Onboarding

### Component map:
Input (ideas/sentences) -> Sentence-BERT (768-dim vectors) -> UMAP (2-5 dim) -> HDBSCAN (cluster IDs + outliers) -> Custom Vectorizer (top-k words per cluster)

### Critical path:
The interaction between UMAP and HDBSCAN is the primary bottleneck. If UMAP collapses distinct semantic regions, HDBSCAN will merge distinct topics.

### Design tradeoffs:
- Noise Filtering: Excludes outliers (-1) to increase coherence scores but may discard highly novel divergent ideas
- Topic Refinement: Iteratively merges least common topics, forcing user-specified topic count that improves readability but may hide long-tail themes

### Failure signatures:
- Topic Collapse: All ideas clustered into one group (likely UMAP min_dist too high or HDBSCAN min_cluster_size too large)
- Total Fragmentation: 50+ micro-topics with 1-2 items each (UMAP n_neighbors too low)
- Incoherent Labels: Top words share no obvious semantic link (suggests word embedding misalignment)

### First 3 experiments:
1. Baseline Reproduction: Run LDA vs. BERTopic vs. proposed model on provided dataset to verify 0.687 coherence score
2. Outlier Analysis: Manually inspect sentences labeled as outliers (-1) to determine if they represent noise or high-value divergent ideas
3. UMAP Parameter Sweep: Test UMAP dimension reduction from 2D to 10D to observe impact on HDBSCAN cluster stability and coherence

## Open Questions the Paper Calls Out

### Open Question 1
How can Explainable AI (XAI) techniques be integrated to reveal which specific words or sentences drive cluster assignments and topic coherence? Current transformer-based embeddings act as "black boxes," making it difficult to transparently justify why certain ideas are grouped together. Resolution would require implementing XAI methods validated by user studies.

### Open Question 2
To what extent do multimodal signals (e.g., audio intonation, facial expressions) improve the accuracy of topic modeling in synchronous virtual meetings? Current study analyzes text transcripts only, not capturing non-verbal communication which carries significant semantic and emotional weight. Resolution requires comparative experiments showing multimodal models outperform text-only baseline.

### Open Question 3
Does high topic coherence (C_V) correlate strongly with human evaluations of actual creative output and topic usefulness? Paper relies on automated metrics without qualitative human validation. Resolution requires study correlating model's coherence scores with expert human ratings of creativity and topic relevance.

## Limitations
- Dataset not publicly available, preventing independent verification
- Key hyperparameters for UMAP and HDBSCAN unspecified, limiting exact reproduction
- Topic refinement process underspecified, making it difficult to replicate merging criteria

## Confidence
Medium - Semantic embedding mechanism well-supported but lacks direct empirical evidence; noise filtering described but not validated against alternatives; dimensionality reduction justification technically sound but not empirically tested.

## Next Checks
1. Baseline Verification: Run LDA, ETM, and BERTopic on same dataset to confirm reported coherence scores
2. Outlier Inspection: Manually review sentences labeled as outliers (-1) to determine if they represent noise or valuable divergent ideas
3. Hyperparameter Sensitivity: Conduct parameter sweep for UMAP (2D to 10D) and HDBSCAN to assess stability of coherence scores and cluster structure