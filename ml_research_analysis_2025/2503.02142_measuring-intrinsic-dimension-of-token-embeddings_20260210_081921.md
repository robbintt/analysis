---
ver: rpa2
title: Measuring Intrinsic Dimension of Token Embeddings
arxiv_id: '2503.02142'
source_url: https://arxiv.org/abs/2503.02142
tags:
- embedding
- training
- embeddings
- lora
- redundancy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper measures the Intrinsic Dimension (ID) of token embeddings
  in language models to assess redundancy compared to extrinsic dimensionality. The
  authors estimate ID for both small-scale (Word2Vec, GloVe, FastText) and large-scale
  (Pythia) models, finding embeddings typically occupy 10-30 dimensional manifolds
  versus 300 extrinsic dimensions.
---

# Measuring Intrinsic Dimension of Token Embeddings

## Quick Facts
- arXiv ID: 2503.02142
- Source URL: https://arxiv.org/abs/2503.02142
- Authors: Takuya Kataiwa; Cho Hakaze; Tetsushi Ohki
- Reference count: 5
- Primary result: Embedding embeddings typically occupy 10-30 dimensional manifolds versus 300 extrinsic dimensions, with 90-98% redundancy

## Executive Summary
This paper investigates the intrinsic dimensionality of token embeddings in language models, measuring how many dimensions are actually needed to represent the embedding space versus the nominal extrinsic dimensionality. The authors apply ID estimation techniques to various models including Word2Vec, GloVe, FastText, and Pythia models ranging from 14M to 12B parameters. They find that embeddings occupy much lower-dimensional manifolds than their nominal size suggests, with ID estimates typically between 10-30 dimensions for 300-dimensional embeddings. The study also examines how ID evolves during training and how it relates to practical applications like LoRA fine-tuning.

## Method Summary
The authors estimate intrinsic dimension using correlation dimension methods, applying this to both small-scale word embeddings (Word2Vec, GloVe, FastText) and large-scale Pythia models. They measure ID at various training stages to track evolution, and test LoRA performance with ranks set near the estimated ID. The analysis includes models from 14M to 12B parameters, examining how redundancy ratios change with scale. For LoRA experiments, they test various rank values to find optimal performance points relative to estimated ID.

## Key Results
- Token embeddings occupy 10-30 dimensional manifolds versus 300 extrinsic dimensions
- Pythia models show 90-98% redundancy, stabilizing around 98% for models above 410M parameters
- During training, ID drops rapidly in early stages then stabilizes
- LoRA performance peaks near estimated ID values, suggesting ID can guide rank selection

## Why This Works (Mechanism)
The paper leverages the mathematical framework of intrinsic dimension estimation to quantify redundancy in embedding spaces. By measuring how embedding points are distributed and correlated, the correlation dimension method reveals the actual manifold dimensionality that captures most variance in the data. This approach works because token embeddings, despite having high extrinsic dimensionality, tend to lie on lower-dimensional manifolds due to semantic and syntactic regularities in language.

## Foundational Learning

**Intrinsic Dimension Estimation**
- Why needed: Quantifies the true dimensionality of data manifolds versus nominal dimensionality
- Quick check: Compare ID estimates across different established methods (TwoNN, MLE, correlation dimension)

**Embedding Redundancy Analysis**
- Why needed: Identifies efficiency opportunities in model storage and computation
- Quick check: Verify redundancy patterns persist across different tokenization schemes

**Correlation Dimension Method**
- Why needed: Provides a robust way to estimate manifold dimensionality from point distributions
- Quick check: Validate method sensitivity to noise and sample size

**LoRA Rank Selection**
- Why needed: Connects theoretical dimensionality to practical fine-tuning efficiency
- Quick check: Test whether optimal ranks consistently align with ID estimates across diverse tasks

## Architecture Onboarding

**Component Map**
Small-scale models (Word2Vec, GloVe, FastText) -> ID estimation -> Large-scale Pythia models -> Training evolution analysis -> LoRA performance validation

**Critical Path**
ID estimation → Redundancy quantification → Training dynamics → LoRA optimization

**Design Tradeoffs**
Computational cost of ID estimation vs. potential efficiency gains from informed rank selection

**Failure Signatures**
If ID estimates vary wildly across methods, or if LoRA performance doesn't correlate with ID proximity

**First Experiments**
1. Cross-validate ID estimates using multiple methods on same datasets
2. Test LoRA performance with ranks both above and below estimated ID
3. Measure ID stability across different training data distributions

## Open Questions the Paper Calls Out
None

## Limitations
- Confidence in findings is Medium to High for empirical measurements but Medium for broader implications
- Limited validation of ID estimates across different estimation methods
- LoRA application section based on limited experiments with only 8 datasets
- Assumption that lower ID correlates with better LoRA performance may not generalize universally

## Confidence
- Empirical ID measurements: Medium to High
- Scaling patterns: Medium to High
- Training dynamics observations: Medium
- LoRA application results: Medium
- Generalization claims: Medium

## Next Checks
1. Cross-validate ID estimates using multiple established methods (TwoNN, MLE, correlation dimension) to ensure robustness of the ~10-30 dimensional manifold findings
2. Test LoRA performance across a more diverse set of tasks and model families to verify that choosing ranks near estimated ID consistently improves results
3. Examine whether ID measurements remain stable when models are evaluated on out-of-distribution data or different tokenization schemes