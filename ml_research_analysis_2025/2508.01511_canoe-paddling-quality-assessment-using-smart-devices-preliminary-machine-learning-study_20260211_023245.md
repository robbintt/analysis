---
ver: rpa2
title: 'Canoe Paddling Quality Assessment Using Smart Devices: Preliminary Machine
  Learning Study'
arxiv_id: '2508.01511'
source_url: https://arxiv.org/abs/2508.01511
tags:
- data
- stroke
- phase
- were
- paddling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored using consumer wearables to assess canoe paddling
  quality via machine learning. Motion data were collected from Apple Watches and
  smartphones worn by four participants during optimal and suboptimal paddling sessions.
---

# Canoe Paddling Quality Assessment Using Smart Devices: Preliminary Machine Learning Study

## Quick Facts
- arXiv ID: 2508.01511
- Source URL: https://arxiv.org/abs/2508.01511
- Reference count: 0
- Primary result: ExtraTrees classifier achieved F score of 0.9496 for binary stroke quality classification using motion data from Apple Watches and iPhone

## Executive Summary
This study explored using consumer wearables to assess canoe paddling quality via machine learning. Motion data were collected from Apple Watches and smartphones worn by four participants during optimal and suboptimal paddling sessions. The data were processed into stroke phases and used to train classifiers for stroke quality. The Extremely Randomized Tree model achieved the highest performance with an F score of 0.9496 under five-fold cross-validation. Wrist-mounted sensors outperformed bicep-mounted ones, and a web interface was developed to provide real-time feedback using LLM-generated insights. Despite a small sample size, the results suggest that consumer devices can effectively support paddling stroke analysis and training.

## Method Summary
The study collected motion data from four participants using Apple Watch Series 5 (worn on both wrists with HemiPhysio Data app) and iPhone 11 (in armband on bicep with Sensor Logger app at 100 Hz). Participants completed 3-minute suboptimal and 3-minute optimal paddling sessions. Data streams included acceleration, rotation, orientation, gravity vectors, quaternion (W, X, Y, Z), and magnetometer. The preprocessing pipeline aligned timestamps across devices, segmented strokes using thresholding on quaternion X values from the left watch, and segmented phases (catch, pull, recovery) using quaternion W values. Features were standardized to 40 frames per phase and summarized using mean, skewness, standard deviation, min, max, range, and percentiles, yielding 45 features per phase. An Extremely Randomized Trees classifier (100 estimators, max_depth=1) was trained with 5-fold cross-validation, achieving the best F score of 0.9496.

## Key Results
- ExtraTrees classifier achieved F score of 0.9496 for stroke quality classification
- Wrist-mounted sensors outperformed bicep-mounted sensors for this task
- Model showed consistent high performance across all three stroke phases (catch, pull, recovery)
- A web interface with LLM-generated feedback was developed for real-time coaching

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Quaternion-based signal patterns from wrist-mounted IMUs allow for the temporal segmentation of continuous paddling motion into discrete stroke phases (catch, pull, recovery).
- **Mechanism:** The X and W components of quaternion streams from the left Apple Watch exhibited consistent peaks and valleys correlating with stroke transitions. Thresholding these values isolates specific movement phases, converting raw time-series data into structured inputs for feature extraction.
- **Core assumption:** The kinematic signatures of optimal and suboptimal strokes produce distinguishable signal morphologies that are consistent across the small sample (n=4) and robust against inter-participant variance.
- **Evidence anchors:**
  - [abstract] "Motion data were processed into stroke phases..."
  - [section] Page 10-11: "...X-component of the quaternion stream from the left Apple Watch consistently exhibited the clearest pattern... achieving peak values between strokes."
  - [corpus] Weak direct evidence; corpus neighbors focus on medical stroke prediction rather than sports biomechanics segmentation.
- **Break condition:** Signal degradation due to water interference or loose strap fit alters the quaternion morphology, causing segmentation failure.

### Mechanism 2
- **Claim:** Extremely Randomized Trees (ExtraTree) effectively classify stroke quality by leveraging high-dimensional summary statistics to differentiate optimal from suboptimal form.
- **Mechanism:** Summary statistics (mean, skewness, quartiles, etc.) reduce variable-length stroke time-series into fixed-length vectors. The ExtraTree classifier creates a decision boundary by aggressively randomizing split points, which appears to handle the small dataset (66 samples) better than Gradient Boosting or SVC by reducing overfitting to specific participant idiosyncrasies.
- **Core assumption:** Summary statistics capture sufficient temporal dynamics to distinguish technique errors, assuming the "suboptimal" label accurately represents a distinct class rather than just noise.
- **Evidence anchors:**
  - [abstract] "...Extremely Randomized Tree model achieved the highest performance with an F score of 0.9496..."
  - [section] Page 16: Table 2 shows ExtraTree consistently high F-scores (0.9474–0.9600) across phases.
  - [corpus] "AI-Based Stroke Rehabilitation Domiciliary Assessment System" supports the general efficacy of sensor-based classification but is domain-shifted.
- **Break condition:** The model likely fails to generalize to unseen users with significantly different biomechanics (height/weight) not represented in the 4-participant training set.

### Mechanism 3
- **Claim:** LLMs can synthesize quantitative kinematic data into qualitative coaching feedback when prompted with raw data streams and processed metrics.
- **Mechanism:** The system passes raw sensor streams and derived metrics to the Deepseek LLM via a REST API. The LLM acts as a semantic layer, translating numerical deviations (e.g., "skewness of acceleration Z") into actionable text advice (e.g., "adjust recovery angle").
- **Core assumption:** The LLM possesses sufficient implicit knowledge of paddling biomechanics to interpret the data context correctly, or the prompt engineering constrains the output effectively.
- **Evidence anchors:**
  - [abstract] "...delivers stroke feedback via a large language model (LLM)."
  - [section] Page 15: "Deepseek is prompted with raw data streams, allowing the LLM to directly interface with comprehensive data."
  - [corpus] No direct evidence in corpus for LLMs in sports coaching feedback loops.
- **Break condition:** LLM hallucination produces technically plausible but biomechanically incorrect advice if the prompt lacks sufficient constraints or context.

## Foundational Learning
- **Concept: Quaternion Rotations vs. Euler Angles**
  - **Why needed here:** The study relies on quaternion streams (W, X, Y, Z) for segmentation because they avoid gimbal lock, which is common in the rotational axes of paddling.
  - **Quick check question:** Why would Euler angles (pitch/roll/yaw) fail to capture a complex stroke rotation compared to quaternions?
- **Concept: Threshold-based Segmentation**
  - **Why needed here:** Identifying the start/end of a stroke in continuous data is the critical first step. Understanding how to set dynamic vs. static thresholds determines the quality of the dataset.
  - **Quick check question:** If a paddler changes their stroke rate significantly, would a fixed-value threshold for segmentation still work?
- **Concept: Cross-Validation on Small Data**
  - **Why needed here:** With only 66 strokes, a simple train/test split is unreliable. 5-fold CV provides a more robust estimate of model variance.
  - **Quick check question:** Why is 5-fold cross-validation preferred over a hold-out test set when dealing with a dataset of only ~60 samples?

## Architecture Onboarding
- **Component map:** Data Sources (iPhone/Apple Watch) -> Mobile Apps (Sensor Logger/HemiPhysio) -> Preprocessing (Alignment, Segmentation, Standardization) -> Feature Engineering (Summary Stats) -> Inference (ExtraTree Model via REST API) -> Interface (Web Frontend + LLM)
- **Critical path:** The **Stroke Segmentation** and **Alignment** modules. If timestamps across the 3 devices (2 watches, 1 phone) drift or if the segmentation threshold misses the stroke peak, the feature extraction generates garbage, rendering the classifier useless.
- **Design tradeoffs:** The system trades **raw signal resolution** for **dimensionality reduction** via summary statistics (Page 13: "marginal decrease in accuracy (<5%)"), prioritizing computational efficiency for a web-based demo over raw-sequence deep learning.
- **Failure signatures:**
  - **High specificity, low sensitivity:** Model predicts "optimal" for everything (seen in some Catch phase results).
  - **Segmentation Drift:** Strokes appearing increasingly short or long in the visualization due to threshold mismatch.
  - **LLM disconnect:** Feedback text contradicts the quantitative pie charts.
- **First 3 experiments:**
  1. **Segmentation Robustness Test:** Inject synthetic noise or timing drift into the raw quaternion data to see if the thresholding logic breaks.
  2. **Device Ablation Study:** Retrain the model using *only* phone data vs. *only* watch data to quantify the performance gap cited in the paper (Page 19).
  3. **User Generalization Check:** Collect data from a 5th participant (unseen data) and run the current model to verify if the "high F-score" holds or if it was overfit to the 4 participants.

## Open Questions the Paper Calls Out
- **Generalization to diverse populations:** Can the trained models generalize effectively to a diverse population with varying biometrics and demographics without requiring individual training data? The authors note the sample size was "likely insufficient to generalize the findings to paddlers who may use the system without having provided training data" and that "demographic data... biometric and physical data was... not considered."
- **Influence of handedness:** How does paddler handedness and dominant-side paddling influence the accuracy of stroke quality classification? The paper notes that "Handedness was not considered, as all participants were asked to complete right-side paddling regardless of their dominant hand."
- **Sensor placement optimization:** Do sensor placements "closer to the paddle" provide significant performance improvements over the wrist-mounted configurations found to be superior in this study? The authors suggest future research should "employ a larger number of sensors and consider positions closer to the paddle."
- **Fatigue vs. technique:** To what extent does physiological fatigue confound the model's ability to distinguish between suboptimal technique and tiredness? The authors note a limitation that "the close succession of trials... may have led to the second trial being influenced by the paddler’s soreness or tiredness."

## Limitations
- The study only included four participants, creating high risk of overfitting and poor generalization to new users
- The quaternion segmentation thresholds are not numerically specified, making exact replication difficult
- The system's real-world robustness against variable water conditions, different paddling styles, and diverse user anthropometrics remains unproven

## Confidence
- **High Confidence:** The core finding that wrist-mounted sensors outperform bicep-mounted sensors for this task is well-supported by the presented ablation results
- **Medium Confidence:** The Extremely Randomized Trees model's superior performance (F score 0.9496) is credible within the study's controlled conditions, but generalization to real-world deployment is uncertain
- **Low Confidence:** The LLM's ability to provide meaningful coaching feedback is supported only by anecdotal description; the paper provides no systematic evaluation of feedback quality or accuracy

## Next Checks
1. **Generalization Test:** Collect data from at least 3-5 new participants with different anthropometric profiles (height, weight, arm length) and test the existing model without retraining to assess true cross-user performance
2. **Segmentation Robustness:** Apply the quaternion-based segmentation algorithm to noisy synthetic data with varying stroke rates and amplitudes to determine the algorithm's failure thresholds
3. **LLM Feedback Evaluation:** Conduct a blind study where paddling experts rate the quality and technical accuracy of LLM-generated feedback compared to expert coaching advice, measuring both correctness and actionability