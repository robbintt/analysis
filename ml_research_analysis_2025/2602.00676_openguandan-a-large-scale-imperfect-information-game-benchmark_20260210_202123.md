---
ver: rpa2
title: 'OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark'
arxiv_id: '2602.00676'
source_url: https://arxiv.org/abs/2602.00676
tags:
- player
- game
- guandan
- card
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OpenGuanDan, a novel large-scale imperfect
  information game benchmark for advancing multi-agent intelligent decision-making.
  OpenGuanDan provides an efficient simulator for GuanDan, a popular Chinese card
  game, along with comprehensive evaluations of both learning-based and rule-based
  AI agents.
---

# OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark

## Quick Facts
- arXiv ID: 2602.00676
- Source URL: https://arxiv.org/abs/2602.00676
- Reference count: 30
- Primary result: Introduces OpenGuanDan benchmark with comprehensive evaluations showing learning-based agents outperform rule-based agents but haven't achieved superhuman performance

## Executive Summary
OpenGuanDan introduces a novel large-scale imperfect information game benchmark for advancing multi-agent intelligent decision-making. The benchmark provides an efficient simulator for GuanDan, a popular Chinese card game, along with comprehensive evaluations of both learning-based and rule-based AI agents. The game presents significant challenges including imperfect information, large-scale information and action spaces, mixed cooperation-competition objectives, long-horizon decision-making, variable action spaces, and dynamic team composition.

The benchmark includes 54.5 million game data points and evaluates several AI agents, including GS2 (which combines learned strategies with real-time subgame solving), SDMC, and DanZero. Empirical results demonstrate that while learning-based agents substantially outperform rule-based agents, they have not yet achieved superhuman performance against human players. GS2 achieves the strongest performance with a 56.7% win rate against SDMC and 62% against DanZero.

## Method Summary
The OpenGuanDan benchmark provides an efficient simulator for the GuanDan card game, a complex imperfect information game that combines elements of cooperation and competition. The benchmark includes comprehensive evaluations of multiple AI agents, including both learning-based approaches (GS2, SDMC, DanZero) and rule-based methods. The evaluation framework tests agents across various game scenarios and measures performance through win rates against other agents and human players.

## Key Results
- Learning-based agents (GS2, SDMC, DanZero) substantially outperform rule-based agents in GuanDan
- GS2 achieves the strongest performance with 56.7% win rate against SDMC and 62% against DanZero
- Learning-based agents have not yet achieved superhuman performance against human players
- The benchmark successfully captures the complexity of imperfect information games with mixed objectives

## Why This Works (Mechanism)
OpenGuanDan works by providing a realistic and complex imperfect information game environment that challenges current AI capabilities. The game's structure forces agents to handle multiple simultaneous challenges: managing imperfect information, coordinating with teammates, competing against opponents, and making decisions over long time horizons. The combination of these factors creates a rich environment for testing and developing advanced multi-agent decision-making algorithms.

## Foundational Learning
- Imperfect Information Games: Why needed - to model real-world scenarios where agents have incomplete knowledge; Quick check - can the agent handle hidden information effectively?
- Multi-Agent Reinforcement Learning: Why needed - to train agents that can cooperate and compete simultaneously; Quick check - does the agent learn to balance cooperation and competition?
- Subgame Solving: Why needed - to make optimal decisions in specific game situations; Quick check - does the agent perform well in critical game moments?
- Variable Action Spaces: Why needed - to handle games where legal actions change dynamically; Quick check - can the agent adapt to changing action spaces?
- Long-Horizon Decision Making: Why needed - to handle games requiring strategic planning over extended periods; Quick check - does the agent maintain consistent performance throughout long games?

## Architecture Onboarding

Component Map:
Game Environment -> Agent Framework -> Evaluation System

Critical Path:
1. Game state representation and observation processing
2. Action selection and execution
3. Reward calculation and learning update
4. Performance evaluation against benchmarks

Design Tradeoffs:
- Computational efficiency vs. solution quality
- Model complexity vs. training data requirements
- Real-time performance vs. strategic depth
- Generalization ability vs. specialization to GuanDan

Failure Signatures:
- Poor handling of imperfect information
- Inability to coordinate with teammates
- Suboptimal decision-making in critical situations
- Failure to adapt to changing game dynamics

3 First Experiments:
1. Compare win rates of different agent types against each other
2. Test agent performance against human players
3. Evaluate agent adaptability to different game scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Learning-based agents haven't achieved superhuman performance against human players
- Benchmark's focus on GuanDan may limit generalizability to other imperfect information games
- The specific contributions of different components in hybrid approaches like GS2 are not isolated

## Confidence
- High: The benchmark's structure, game complexity, and evaluation methodology are clearly described and reproducible
- Medium: Claims about the relative performance of different agent types are well-supported, though the sample size and statistical significance are not detailed
- Low: The claim that OpenGuanDan poses unique challenges not addressed by existing benchmarks is difficult to verify without comparative analysis

## Next Checks
1. Conduct statistical significance tests on the win rates to confirm the performance differences between agent types are not due to chance
2. Perform ablation studies on GS2 to quantify the individual contributions of learned strategies versus real-time subgame solving
3. Compare the scale and complexity metrics of OpenGuanDan to other established imperfect information game benchmarks to validate its positioning as a large-scale challenge