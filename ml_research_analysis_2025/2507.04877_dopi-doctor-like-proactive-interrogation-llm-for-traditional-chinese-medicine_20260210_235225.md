---
ver: rpa2
title: 'DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine'
arxiv_id: '2507.04877'
source_url: https://arxiv.org/abs/2507.04877
tags:
- medical
- symptoms
- patient
- knowledge
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of current large language
  models in conducting effective multi-turn dialogues for Traditional Chinese Medicine
  (TCM) diagnosis. The proposed DoPI system employs a collaborative architecture with
  a guidance model and an expert model, using a knowledge graph to dynamically generate
  questions and extract critical symptom information.
---

# DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine

## Quick Facts
- arXiv ID: 2507.04877
- Source URL: https://arxiv.org/abs/2507.04877
- Reference count: 30
- Key outcome: DoPI achieves 84.68% accuracy in TCM diagnosis through proactive multi-turn dialogue interrogation

## Executive Summary
This paper addresses the limitations of current large language models in conducting effective multi-turn dialogues for Traditional Chinese Medicine (TCM) diagnosis. The proposed DoPI system employs a collaborative architecture with a guidance model and an expert model, using a knowledge graph to dynamically generate questions and extract critical symptom information. The guidance model conducts multi-turn dialogues with patients, while the expert model provides final diagnoses and treatment plans. The study constructs a multi-turn doctor-patient dialogue dataset and proposes an innovative evaluation methodology. Experimental results demonstrate that DoPI significantly enhances the model's communication ability during diagnosis while maintaining professional expertise.

## Method Summary
DoPI employs a collaborative dual-model architecture where a guidance model conducts multi-turn proactive interrogation using a symptom-disease knowledge graph, while an expert model provides final diagnoses and treatment recommendations. The guidance model fine-tuned on synthetic dialogue data parses patient input, maps symptoms to knowledge graph nodes, and asks questions based on symptom importance scores. The expert model, based on Sunsimiao, receives the confirmed symptom set and candidate diseases to generate diagnoses. A knowledge graph with weighted edges connects symptoms to diseases, enabling dynamic question generation and post-consultation weight updates. The system uses a cosine similarity threshold to determine when to stop questioning and proceed to diagnosis.

## Key Results
- DoPI achieves diagnostic accuracy of 84.68% on multi-turn TCM diagnosis tasks
- The system maintains an optimal Q&A Ratio while minimizing interrogation distance
- Significant improvement over baseline models which achieved only 14-21% accuracy
- The knowledge graph-driven questioning strategy effectively identifies critical symptoms

## Why This Works (Mechanism)
DoPI's effectiveness stems from its structured approach to information gathering that mirrors how experienced TCM doctors conduct consultations. By separating the interrogation and diagnosis functions into specialized models, the system avoids the degradation of medical expertise that occurs when fine-tuning a single model on mixed dialogue and medical data. The knowledge graph provides a principled way to prioritize which symptoms to ask about next based on their discriminative power for candidate diseases, ensuring efficient information gathering. The dual-model architecture allows the guidance model to focus purely on communication skills while the expert model maintains deep medical knowledge.

## Foundational Learning
- **Concept: Symptom-Disease Knowledge Graphs**
  - Why needed here: DoPI's core interrogation logic depends on traversing a bipartite graph connecting symptoms to diseases with weighted edges representing association strength. Understanding how nodes, edges, and weights encode diagnostic relationships is essential for interpreting the questioning algorithm.
  - Quick check question: Given a patient with symptoms A and B, how would you compute which disease to investigate first if you have edge weights for all symptom-disease pairs?

- **Concept: Multi-turn Dialogue State Management**
  - Why needed here: The guidance model maintains a Symptom Recorder that tracks confirmed, candidate, and unasked symptoms across dialogue turns. This state must persist and update correctly as the patient responds.
  - Quick check question: What happens if a patient's response confirms a symptom that was not in the original candidate set?

- **Concept: Retrieval-Augmented Generation (RAG) vs. Weight Fine-Tuning Trade-offs**
  - Why needed here: The paper argues that fine-tuning on mixed dialogue/medical data degrades expertise (Figure 2c). Understanding why RAG alone or separate fine-tuning avoids this trade-off clarifies the architectural decision.
  - Quick check question: Why might fine-tuning a model on both medical Q&A and casual dialogue data reduce its diagnostic accuracy?

## Architecture Onboarding
- **Component map:**
  Guidance Model (7B LLM) -> Knowledge Graph -> Symptom Recorder -> Expert Model (Sunsimiao-based) -> Final Diagnosis -> Treatment Plan

- **Critical path:**
  1. Patient provides initial symptom description → Guidance model parses and maps symptoms to KG nodes
  2. KG computes candidate diseases via cosine similarity; ranks unknown symptoms by importance score
  3. Guidance model asks about top-ranked symptoms → Patient responds → Symptom Recorder updates
  4. Loop repeats until cosine similarity exceeds threshold ε
  5. Confirmed symptoms + candidate disease → Expert model → Final diagnosis + treatment plan + KG update recommendations
  6. KG weights adjusted offline based on expert model feedback

- **Design tradeoffs:**
  - Dual-model vs. single-model: Separating guidance and expert models avoids data conflict during training but increases system complexity and requires coordination between models
  - KG-driven questioning vs. end-to-end learned questioning: Structured interrogation ensures medical grounding but may be less flexible than learned dialogue strategies for edge cases
  - Early stopping threshold ε: Higher threshold gathers more information but increases dialogue length; lower threshold risks premature diagnosis

- **Failure signatures:**
  - Premature diagnosis: If ε is too low or initial symptoms are highly suggestive, the system may diagnose before gathering sufficient discriminative information
  - Infinite loop: If patient responses don't confirm or deny candidate symptoms, or if KG lacks coverage for presented symptoms, the system may fail to reach the similarity threshold
  - Terminology mismatch: If the guidance model fails to align colloquial patient language with KG symptom nodes, the Symptom Recorder won't update correctly
  - Weight update drift: If expert model diagnoses contain systematic errors, KG updates may reinforce incorrect symptom-disease associations over time

- **First 3 experiments:**
  1. Threshold sensitivity analysis: Vary ε across a range (e.g., 0.6, 0.7, 0.8, 0.9) and measure diagnostic accuracy vs. average dialogue length to identify the optimal trade-off point
  2. Ablation on KG prioritization: Replace the weighted importance scoring with random symptom selection and compare diagnostic accuracy and Q&A Ratio to quantify the contribution of structured interrogation
  3. Weight update evaluation: Run the system on a held-out test set with and without dynamic KG updates enabled to measure whether the feedback mechanism improves performance over sequential consultations

## Open Questions the Paper Calls Out
- Can the integration of native Multimodal Large Language Models (MLLMs) improve the accuracy of tongue diagnosis compared to the current ResNet-based CNN approach?
- How does DoPI's diagnostic performance vary when deployed in real-world clinical settings compared to the simulated synthetic dataset?
- Can the collaborative guidance-expert architecture be effectively generalized to Western medicine diagnosis which relies heavily on objective lab/imaging data?

## Limitations
- The system relies on a synthetic dialogue dataset generated by a large language model rather than real patient-doctor interactions
- Knowledge graph construction methodology lacks transparency regarding source data quality and initial weight assignments
- The evaluation methodology may have limited external validity since it uses the same synthetic generation process for both training and testing

## Confidence
- **High Confidence:** The architectural framework of separating guidance and expert models is well-specified and technically sound
- **Medium Confidence:** The reported diagnostic accuracy of 84.68% is credible given the methodology, though dependent on synthetic data quality
- **Medium Confidence:** The three-way evaluation methodology (Diagnostic Accuracy, Q&A Ratio, and Interrogation Distance) provides a comprehensive assessment of system performance

## Next Checks
1. Validate the system on a held-out test set of real doctor-patient dialogues to assess performance on authentic clinical conversations
2. Conduct ablation studies removing the knowledge graph component to quantify its contribution to the 84.68% accuracy
3. Test the system's performance across different TCM subspecialties to evaluate generalizability beyond the training data distribution