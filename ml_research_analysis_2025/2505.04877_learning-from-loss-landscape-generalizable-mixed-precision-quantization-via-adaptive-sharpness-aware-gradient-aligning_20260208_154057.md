---
ver: rpa2
title: 'Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via
  Adaptive Sharpness-Aware Gradient Aligning'
arxiv_id: '2505.04877'
source_url: https://arxiv.org/abs/2505.04877
tags:
- loss
- quantization
- search
- datasets
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the high computational cost of mixed-precision
  quantization (MPQ) by proposing a method that first searches for quantization policies
  on small proxy datasets and then generalizes them to large-scale datasets. The core
  method, Adaptive Sharpness-Aware Gradient Aligning (ASGA), leverages loss landscape
  sharpness information to enhance quantization generalization.
---

# Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning

## Quick Facts
- arXiv ID: 2505.04877
- Source URL: https://arxiv.org/abs/2505.04877
- Reference count: 26
- Key result: Reduces MPQ search cost by using CIFAR10 (0.5% of ImageNet size) while maintaining equivalent accuracy with up to 150% speedup

## Executive Summary
This paper addresses the computational expense of mixed-precision quantization (MPQ) by introducing Adaptive Sharpness-Aware Gradient Aligning (ASGA), which searches for quantization policies on small proxy datasets and generalizes them to large-scale targets. The method leverages loss landscape sharpness information to identify flat minima that transfer well across datasets. Experiments show that using CIFAR10 for MPQ policy search achieves equivalent accuracy on ImageNet with significant speedup over state-of-the-art methods, reducing search costs while maintaining high accuracy for ResNet18, ResNet50, and MobileNet-V2.

## Method Summary
ASGA combines Sharpness-Aware Minimization with implicit gradient direction alignment and an adaptive perturbation radius. The method minimizes the surrogate gap (perturbed loss minus empirical loss) on a proxy dataset to find flat minima that generalize. It introduces an adaptive perturbation radius that adjusts based on the current surrogate gap, and resolves gradient conflicts between empirical and perturbed losses through implicit alignment. The quantization policy is searched on CIFAR10 and then applied to ImageNet, with learnable weights for bit-width selection and BOPs constraints integrated into the loss function.

## Key Results
- CIFAR10 search achieves equivalent ImageNet accuracy to direct ImageNet search with up to 150% speedup
- ResNet18, ResNet50, and MobileNet-V2 show consistent improvements across architectures
- Adaptive radius accelerates convergence compared to fixed radius approaches
- Surrogate gap minimization on proxy data effectively identifies policies that generalize to target data

## Why This Works (Mechanism)

### Mechanism 1: Surrogate Gap Minimization
The method optimizes for flat minima on proxy data by minimizing the surrogate gap $h(\theta) = L_p(\theta) - L(\theta)$. This ensures the loss landscape is as flat as possible on the proxy distribution, which correlates with flat minima on the target dataset. The core assumption is that flat minima identified on the proxy dataset scale to the target dataset regardless of distribution shift.

### Mechanism 2: Implicit Gradient Direction Alignment
Standard SAM can have conflicting gradients between empirical loss and perturbed loss. ASGA reformulates the objective to align these gradients (maximize their inner product), allowing simultaneous reduction of error and sharpness without degradation. This resolves the primary obstacle to applying SAM in MPQ scenarios.

### Mechanism 3: Adaptive Perturbation Radius
The perturbation radius $\rho$ adapts based on the current surrogate gap using $\rho = \min(\rho_{max}, \phi / \ln(h(\theta)+1))$. This dynamic adjustment captures evolving sharpness better than fixed radius, ensuring perturbation magnitude remains sensitive to local geometry and accelerating convergence.

## Foundational Learning

- **Sharpness-Aware Minimization (SAM):** SAM seeks flat minima by perturbing weights and maximizing loss locally before minimizing it. Why needed: ASGA builds directly on SAM. Quick check: Can you explain why a "flat" minimum generally generalizes better than a "sharp" one?

- **Mixed-Precision Quantization (MPQ):** MPQ assigns different bit-widths to different layers to balance model size/latency and accuracy. Why needed: This is the domain the method addresses. Quick check: Why would assigning 8-bit precision to one layer and 4-bit to another be better than uniform precision?

- **Bi-level Optimization:** The problem optimizes weights $\theta$ (inner loop) and quantization policies $Q$ (outer loop). Why needed: The framework requires understanding the nested optimization structure. Quick check: In this paper, is the quantization policy searched on the target dataset or the proxy dataset?

## Architecture Onboarding

- **Component map:** Proxy Search Loop -> Loss Aggregator -> ASGA Module -> Policy Selector -> Deployment Phase
- **Critical path:** 1) Train on Proxy Data (CIFAR10), 2) Compute standard and perturbed gradients, 3) Apply Gradient Alignment logic, 4) Update weights and learnable bit-width weights, 5) Transfer policy to target dataset for fine-tuning
- **Design tradeoffs:** Proxy vs. Target Subset - using a subset of ImageNet performs worse than using a different dataset (CIFAR10) with ASGA due to distribution shift; Efficiency vs. Accuracy - adaptive radius speeds up search while maintaining accuracy
- **Failure signatures:** High Surrogate Gap ($h(\theta)$) indicates poor generalization; Gradient Conflict suggests alignment step is faulty
- **First 3 experiments:** 1) Train ResNet18 on CIFAR10 with standard SAM vs. ASGA and plot Surrogate Gap, 2) Search policy on CIFAR10, deploy to ResNet50 on ImageNet, compare accuracy, 3) Ablation on fixed vs. adaptive $\rho$ values and plot convergence vs. accuracy

## Open Questions the Paper Calls Out

### Open Question 1
Can a quantitative metric be defined to predict the transfer efficacy of a proxy dataset based on its distributional similarity to the target dataset? The paper hypothesizes that CIFAR10's success is due to "class-level similarity" to ImageNet but provides no formal metric for selecting optimal proxy data.

### Open Question 2
Can the PAC-Bayesian generalization bound complexity term $R$ be estimated more precisely than the current simplification to $L_2$ regularization? The supplementary material explicitly states that $R$ is "hard to analyze and often simplified," indicating a theoretical gap.

### Open Question 3
Does the ASGA method generalize effectively to architectures with non-convolutional inductive biases, such as Vision Transformers (ViT)? The experimental scope is limited to CNNs, while the loss landscape geometry of Transformers is known to differ significantly.

## Limitations
- Experimental scope limited to three CNN architectures (ResNet, MobileNet, VGG) without testing on Vision Transformers
- Optimal choice of proxy dataset not explored - CIFAR10's success may be coincidental rather than fundamental
- Key hyperparameters (λ, ρₘₐₓ, φ) are underspecified, potentially affecting reproducibility

## Confidence
- **Transferability claim:** Medium confidence - theoretically grounded but limited empirical evidence across datasets
- **Mechanism validity:** Medium confidence - gradient alignment details are ambiguous and hard to verify
- **Reproducibility:** Low confidence - key hyperparameters and implementation details are underspecified

## Next Checks
1. **Cross-Dataset Transferability:** Repeat CIFAR10→ImageNet experiment with additional proxy-target pairs (CIFAR100→ImageNet, TinyImageNet→ImageNet) to test if flatness optimization generalizes across distributions
2. **Fixed vs. Adaptive Radius:** Run ablation studies comparing fixed ρ values (0.05, 0.1, 0.2) against adaptive radius across multiple epochs to quantify speedup claims and identify optimal ranges
3. **Gradient Alignment Verification:** Implement gradient alignment by explicitly monitoring the inner product ⟨∇L, ∇Lₚ⟩ during training to verify it remains positive and correlates with improved accuracy