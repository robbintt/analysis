---
ver: rpa2
title: Dynamical modeling of nonlinear latent factors in multiscale neural activity
  with real-time inference
arxiv_id: '2512.12462'
source_url: https://arxiv.org/abs/2512.12462
tags:
- mrine
- neural
- decoding
- latent
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MRINE, a real-time multimodal neural modeling
  framework that can nonlinearly fuse neural signals with different timescales (e.g.,
  spikes and LFPs) and distributions (Poisson and Gaussian) while handling missing
  samples. The key innovation is a multiscale encoder that first learns modality-specific
  dynamics to account for timescale differences and missing data, then fuses the representations
  in real-time.
---

# Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference

## Quick Facts
- arXiv ID: 2512.12462
- Source URL: https://arxiv.org/abs/2512.12462
- Reference count: 40
- Real-time multimodal neural modeling framework (MRINE) improves behavior decoding by 5-50% over single-scale models

## Executive Summary
This paper introduces MRINE, a real-time multimodal neural modeling framework that can nonlinearly fuse neural signals with different timescales (e.g., spikes and LFPs) and distributions (Poisson and Gaussian) while handling missing samples. The key innovation is a multiscale encoder that first learns modality-specific dynamics to account for timescale differences and missing data, then fuses the representations in real-time. The model also includes a dynamical backbone for recursive inference and modality-specific decoders.

Experiments show MRINE improves downstream behavior decoding (e.g., 2D velocity prediction) by 5-50% over single-scale models across two NHP datasets. It also outperforms linear (MSID) and nonlinear (mmPLRNN, MMGPV AE) multimodal baselines, especially when modalities have different timescales. Robustness to missing samples is demonstrated, and results generalize to high-dimensional visual cortex data. Ablation studies confirm the importance of the multiscale encoder design, smoothness regularization, and the training objective. MRINE is suitable for real-time applications like brain-computer interfaces where different neural modalities must be combined dynamically.

## Method Summary
MRINE addresses real-time decoding of behavioral variables from multimodal neural time-series with different timescales, distributions, and missing samples. The framework uses a multiscale encoder with modality-specific LDMs and Kalman filtering to handle timescale differences and missing data, followed by a fusion network. A multiscale LDM backbone enables recursive inference, and modality-specific decoders reconstruct each modality. The model is trained with a composite loss including k-step-ahead prediction, smoothed reconstruction, smoothness regularization, and L2 penalty, using Adam with cyclical learning rate. The framework shows improved behavior decoding performance across two NHP datasets.

## Key Results
- MRINE improves 2D velocity decoding by 5-50% over single-scale models across two NHP datasets
- Outperforms linear (MSID) and nonlinear (mmPLRNN, MMGPV AE) multimodal baselines, especially with different timescales
- Demonstrates robustness to missing samples and generalizes to high-dimensional visual cortex data
- Ablation studies confirm importance of multiscale encoder design, smoothness regularization, and training objective

## Why This Works (Mechanism)
MRINE works by first learning modality-specific dynamics to account for timescale differences and missing data through Kalman filtering, then fusing these representations in real-time. The dynamical backbone enables recursive inference, while modality-specific decoders handle different distributions (Poisson for spikes, Gaussian for LFPs). The composite training objective balances prediction accuracy, smoothness, and regularization.

## Foundational Learning
- **Kalman filtering**: Needed for real-time state estimation with noisy observations; quick check: verify posterior mean/covariance updates correctly with missing data
- **Likelihood scaling**: Required to balance Poisson and Gaussian log-likelihoods; quick check: monitor log-likelihood magnitudes during training
- **Smoothness regularization**: Ensures temporal coherence in latent factors; quick check: verify KL-divergence computation over correct dimensions

## Architecture Onboarding

Component map: Spikes/LFP -> Modality-specific MLPs -> Modality-specific LDMs -> Kalman filter -> Concatenate -> Fusion MLP -> Multiscale LDM -> Modality-specific decoders

Critical path: Encoder (Kalman filtering) -> Fusion -> Multiscale LDM backbone -> Decoders

Design tradeoffs: Real-time inference requires Kalman filtering vs. batch smoothing; likelihood scaling needed for modality balance; smoothness regularization trades off temporal smoothness vs. flexibility

Failure signatures: Dominated by one modality (likelihood scale mismatch); posterior collapse (trivial encoder/decoder); poor real-time performance (insufficient Kalman filtering)

First experiments: 1) Verify Kalman filter implementation with missing data; 2) Test likelihood scaling parameter Ï„; 3) Validate smoothness regularization implementation

## Open Questions the Paper Calls Out
None

## Limitations
- Key implementation details underspecified, particularly LDM parameter initialization and handling of initial timesteps for slower modalities
- Performance depends on specific hyperparameter choices that may not generalize
- Superiority over nonlinear baselines relies on implementation details not fully specified

## Confidence
- **High confidence**: Framework's ability to fuse multimodal neural data with different timescales and distributions
- **Medium confidence**: Real-time inference capability and robustness to missing data
- **Medium confidence**: Superiority over nonlinear baselines

## Next Checks
1. **Initialization sensitivity test**: Systematically vary LDM parameter initialization schemes and measure impact on convergence and final performance
2. **Real-time latency validation**: Measure actual inference latency on representative hardware to verify real-time constraints for BCI applications
3. **Missing data robustness analysis**: Conduct granular analysis of performance degradation with varying missing data rates and patterns