---
ver: rpa2
title: 'Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context
  Permutation'
arxiv_id: '2505.11754'
source_url: https://arxiv.org/abs/2505.11754
tags:
- noise
- documents
- scores
- mean
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper analyzes how language models perform on multi-hop question
  answering when document order is permuted. The authors examine both causal decoder-only
  models (Qwen2.5, Llama) and encoder-decoder models (Flan-T5) under different permutations:
  order of gold documents, distance between them, and completeness of context.'
---

# Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation

## Quick Facts
- **arXiv ID**: 2505.11754
- **Source URL**: https://arxiv.org/abs/2505.11754
- **Reference count**: 40
- **Primary result**: Encoder-decoder models (Flan-T5) outperform causal decoder-only models (Qwen2.5, Llama) on multi-hop QA without fine-tuning, despite being smaller

## Executive Summary
This paper investigates how language models handle multi-hop question answering when the order of supporting documents is permuted. The authors systematically examine three types of document permutations: the order of gold documents, the distance between them, and the completeness of context. They compare causal decoder-only models (Qwen2.5, Llama) with encoder-decoder models (Flan-T5) to understand how architecture differences affect performance under these permutations. The study reveals that encoder-decoder models consistently outperform causal decoder-only models without fine-tuning, while fine-tuned decoder-only models show improved performance when gold documents follow the reasoning chain order. The authors also develop a heuristic masking strategy based on attention weight analysis that improves performance across models.

## Method Summary
The authors conduct experiments on two multi-hop QA datasets (HotPotQA and 2WikiMultiHopQA) using three language models: Qwen2.5, Llama, and Flan-T5. They systematically permute document order in three ways: changing the order of gold documents, varying the distance between them, and altering context completeness. For each permutation, they measure model performance and analyze attention weights to understand how models process information. They also investigate the impact of causal masking on decoder-only models by modifying the attention mask to allow bi-directional attention. Based on their analysis of attention patterns, they develop a heuristic masking strategy that weights attention based on the distance between documents, which they validate across different model architectures.

## Key Results
- Encoder-decoder models (Flan-T5) outperform causal decoder-only models (Qwen2.5, Llama) on multi-hop QA without fine-tuning, despite being smaller
- Fine-tuned decoder-only models show improved performance when gold documents follow the reasoning chain order, and performance degrades when this order is reversed
- The proposed heuristic masking strategy, based on attention weight analysis, improves performance across different model architectures
- Higher peak attention to documents correlates with correct answers, enabling the heuristic approach

## Why This Works (Mechanism)
The mechanism underlying these results centers on how different model architectures handle document ordering and attention patterns. Encoder-decoder models like Flan-T5 can attend to all input tokens bidirectionally, allowing them to establish relationships between documents regardless of their position in the input sequence. This bi-directional attention is particularly advantageous for multi-hop reasoning, where understanding connections between distant pieces of information is crucial. In contrast, causal decoder-only models are constrained by their auto-regressive nature, which limits their ability to attend to future tokens during generation. The analysis reveals that performance degradation occurs primarily when the reasoning chain order is disrupted, suggesting that models rely on positional information to guide their reasoning process. The attention weight analysis shows that successful reasoning correlates with higher attention peaks to relevant documents, which forms the basis for the heuristic masking strategy.

## Foundational Learning

**Multi-hop QA**: Multi-step reasoning over multiple documents to answer a question - needed to understand the complexity of the task being studied; quick check: can you explain why this differs from single-hop QA?

**Document Permutation**: Systematically changing the order or arrangement of supporting documents - needed to isolate the effect of document order on model performance; quick check: what are the three types of permutations tested?

**Causal Masking**: Attention mechanism that prevents tokens from attending to future tokens - needed to understand the constraint in decoder-only models; quick check: how does this differ from bi-directional attention?

**Encoder-decoder Architecture**: Models with separate encoding and decoding components that can attend bidirectionally to input - needed to compare architectural differences; quick check: why might this be advantageous for multi-hop reasoning?

**Attention Weight Analysis**: Examining the distribution of attention scores across tokens/documents - needed to develop the heuristic masking strategy; quick check: what correlation did the authors find between attention and performance?

**Heuristic Masking**: A rule-based approach to modifying attention patterns based on observed correlations - needed to improve performance without fine-tuning; quick check: what principle guides the proposed masking strategy?

## Architecture Onboarding

**Component Map**: Input documents -> Tokenization -> Model (Encoder-decoder or Decoder-only) -> Attention mechanism -> Output generation

**Critical Path**: Document permutation -> Model processing -> Attention pattern formation -> Answer generation

**Design Tradeoffs**: Encoder-decoder models offer bi-directional attention but may be less efficient; decoder-only models are more efficient but constrained by causal masking; the choice affects multi-hop reasoning capability

**Failure Signatures**: Performance degradation when gold documents are in reverse order; lower attention peaks to relevant documents; inability to establish cross-document relationships

**First Experiments**:
1. Test the masking heuristic on additional multi-hop QA datasets (e.g., HotpotQA distractor setting)
2. Evaluate the impact of different permutation types on model calibration
3. Compare attention patterns between successful and unsuccessful reasoning paths

## Open Questions the Paper Calls Out

None

## Limitations

- The study focuses on a limited set of model architectures and datasets, which may not capture the full diversity of approaches to multi-hop QA
- The heuristic masking strategy shows promise but was only validated on a subset of models
- The analysis assumes that document order directly impacts reasoning paths, but alternative explanations are not fully explored

## Confidence

- **High Confidence**: Encoder-decoder models outperform causal decoder-only models on multi-hop QA without fine-tuning
- **Medium Confidence**: Performance degradation when gold documents are in reverse order is consistent across models
- **Low Confidence**: The proposed masking heuristic's effectiveness generalizes beyond the tested models and datasets

## Next Checks

1. Test the masking heuristic on additional multi-hop QA datasets and model architectures to verify generalizability
2. Conduct ablation studies to isolate whether performance differences stem from document order or other factors like attention mechanisms
3. Evaluate whether fine-tuning the masking strategy on validation data yields further improvements beyond the heuristic approach