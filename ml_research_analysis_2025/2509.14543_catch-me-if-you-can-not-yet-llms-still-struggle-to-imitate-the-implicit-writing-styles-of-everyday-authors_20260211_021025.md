---
ver: rpa2
title: 'Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit
  Writing Styles of Everyday Authors'
arxiv_id: '2509.14543'
source_url: https://arxiv.org/abs/2509.14543
tags:
- writing
- style
- llms
- author
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates whether large language models (LLMs) can imitate
  the implicit writing styles of everyday authors using only a few writing examples.
  The authors introduce a comprehensive evaluation framework combining authorship
  attribution, verification, style matching, and AI detection to assess style imitation
  across four domains (news, email, forums, blogs) and over 400 real-world authors.
---

# Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors

## Quick Facts
- **arXiv ID**: 2509.14543
- **Source URL**: https://arxiv.org/abs/2509.14543
- **Reference count**: 31
- **Primary result**: LLMs can partially emulate style in structured domains (news, email) but fail in informal ones (blogs, forums); outputs remain AI-detectable.

## Executive Summary
This study evaluates whether large language models (LLMs) can imitate the implicit writing styles of everyday authors using only a few writing examples. The authors introduce a comprehensive evaluation framework combining authorship attribution, verification, style matching, and AI detection to assess style imitation across four domains (news, email, forums, blogs) and over 400 real-world authors. Results show that while LLMs can partially emulate user style in structured formats like news and email, they struggle with nuanced, informal writing in blogs and forums. Generated outputs often default to a generic tone and remain detectable as AI-written. Increasing the number of demonstrations offers limited gains in stylistic alignment. These findings highlight the current limitations of in-context personalization and the need for improved techniques to achieve truly personalized, style-consistent generation.

## Method Summary
The authors evaluate LLM style imitation using four datasets: Enron (150 authors, 3,884 samples), Blog (100 authors, 25,224 samples), CCAT50 (50 authors, 2,500 samples), and Reddit (100 authors, 8,451 samples). Each dataset is split into train and test sets, with samples filtered to 100–1,500 words. For each test instance, 5 random train examples are used as demonstrations in a few-shot in-context learning setup. The study employs multiple metrics: authorship attribution (AA) and verification (AV) accuracy, Mahalanobis distance to per-author style models (using LIWC and WritePrint features), and AI detection rate via GPTZero. Models evaluated include GPT-4o, GPT-4o-mini, Gemini-2.0-Flash, Gemma-3-27B, DeepSeek-V3, and Llama-4-Maverick. AA and AV models are trained with Longformer-base-4096 and ModernBERT-base; style models use LIWC and WritePrint features. Semantic similarity (METEOR, ROUGE-L, SBERT) is used as a sanity check.

## Key Results
- LLMs partially emulate style in structured domains (news, email) but struggle with informal domains (blogs, forums).
- Generated outputs default to generic tone and remain detectable as AI-written.
- Increasing demonstrations offers limited stylistic improvement.

## Why This Works (Mechanism)
Not specified.

## Foundational Learning
- **Authorship Attribution (AA)**: Classifying text to its correct author among many candidates. Needed to measure if generated text is confused with a specific author. Quick check: Top-5 accuracy on heldout test set should be significantly above random chance.
- **Authorship Verification (AV)**: Binary classification of whether two texts are by the same author. Needed to detect subtle style divergence in generated vs. original texts. Quick check: Pairwise accuracy should drop when comparing generated to true author samples.
- **Style Modeling with LIWC/WritePrint**: Feature extraction of linguistic and stylistic cues (e.g., function word usage, syntactic patterns). Needed as a robust, interpretable baseline for style similarity. Quick check: Mahalanobis distance should be lower for true author pairs than for generated vs. author pairs.
- **AI Detection (GPTZero)**: Commercial detector estimating likelihood a text is AI-generated. Needed to quantify real-world detectability of generated outputs. Quick check: Generated texts should be classified as AI-written at high rates.
- **In-Context Learning (Few-shot)**: Providing LLM with a handful of examples in the prompt to induce stylistic behavior. Needed to simulate realistic personalization without fine-tuning. Quick check: Generated texts should reflect stylistic features of provided demonstrations.

## Architecture Onboarding

**Component Map**: Datasets (Enron/Blog/Reddit/CCAT50) -> Train AA/AV Models (Longformer, ModernBERT) -> Build Per-Author Style Models (LIWC + WritePrint) -> Generate Outputs (LLMs, 5-shot/0-shot) -> Evaluate (AA Top-5, AV, Mahalanobis, GPTZero, Semantic Similarity)

**Critical Path**: Few-shot prompt -> LLM generation -> Multi-metric evaluation (AA, AV, style distance, AI detection)

**Design Tradeoffs**: Few-shot in-context learning vs. fine-tuning (trade convenience for potentially lower style fidelity); generic LLMs vs. specialized stylization models (trade flexibility for domain expertise); manual feature-based style models vs. learned embeddings (trade interpretability for potential coverage)

**Failure Signatures**: 
- Low AA/AV accuracy on human-heldout test set → model training issues or data leakage
- Generated texts semantically divergent from summaries -> summarization step or prompt failure
- Style-model distances not separating 5-shot from 0-shot -> feature extraction or distance computation error

**Three First Experiments**:
1. Re-run AA/AV accuracy tests on the human-heldout test sets with the same hyperparameters and seeds to confirm model training integrity.
2. Validate GPTZero outputs on a small subset using the current API version and known human/AI pairs to bound detector drift.
3. Check semantic fidelity of generated outputs by re-computing METEOR/ROUGE-L/SBERT against GPT-4.1 summaries to ensure style differences are not artifacts of semantic drift.

## Open Questions the Paper Calls Out
None.

## Limitations
- Results limited to English-language datasets and four specific domains (news, email, forums, blogs).
- Use of GPTZero as primary AI detector may be subject to version/threshold changes since study run.
- Analysis focuses on few-shot in-context learning; does not address fine-tuning-based personalization or alternative demonstration counts.
- Style models rely on LIWC and WritePrint features, which may not capture all nuances of emerging informal online registers.

## Confidence

**Major Claim Confidence**:
- **High confidence**: LLMs can partially emulate style in structured domains (news, email) but fail in informal ones (blogs, forums); outputs remain AI-detectable; style matching improvements from increasing demonstrations are limited.
- **Medium confidence**: Gemini-2.0-Flash and DeepSeek-V3 are superior style imitators across domains; pairwise AV and Mahalanobis distance metrics reliably detect style divergence.
- **Low confidence**: Relative ranking of LLMs is stable across all metrics and domains; style imitation failure is purely a matter of scale, not fundamental model architecture.

## Next Checks
1. Re-run AA/AV accuracy tests on the human-heldout test sets with the same hyperparameters and seeds to confirm model training integrity.
2. Validate GPTZero outputs on a small subset using the current API version and known human/AI pairs to bound detector drift.
3. Check semantic fidelity of generated outputs by re-computing METEOR/ROUGE-L/SBERT against GPT-4.1 summaries to ensure style differences are not artifacts of semantic drift.