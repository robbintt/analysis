---
ver: rpa2
title: Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings
arxiv_id: '2601.12966'
source_url: https://arxiv.org/abs/2601.12966
tags:
- speech
- lombard
- style
- loud
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a zero-shot Lombard speech synthesis method
  that manipulates style embeddings to control prosody without requiring Lombard training
  data. The approach uses PCA to identify style embedding components correlated with
  loudness and clarity, then shifts these components to synthesize speech at desired
  Lombard levels.
---

# Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings

## Quick Facts
- **arXiv ID:** 2601.12966
- **Source URL:** https://arxiv.org/abs/2601.12966
- **Reference count:** 0
- **Primary result:** Zero-shot Lombard TTS with controllable loudness/clarity via PCA-based style embedding manipulation

## Executive Summary
This paper introduces a zero-shot Lombard speech synthesis method that manipulates style embeddings to control prosody without requiring Lombard training data. The approach uses PCA to identify style embedding components correlated with loudness and clarity, then shifts these components to synthesize speech at desired Lombard levels. The F5-TTS model is adapted with style embeddings extracted from reference audio and duration control. Evaluations show the method preserves speaker identity (SSIM ~81%), maintains naturalness (UTMOS ~3.5), and improves intelligibility under noise (relative WER reduction up to 50% at SNR=10). The system outperforms the baseline in cross-lingual settings and demonstrates that controlled style embedding manipulation enables robust, controllable Lombard TTS.

## Method Summary
The method fine-tunes F5-TTS Base by freezing early DiT blocks (for duration alignment) and adding FiLM conditioning to later blocks using 1024D style embeddings from ECAPA-TDNN. Training includes formant perturbation on masked mel-spectrograms to prevent speaker leakage. At inference, PCA is applied to style embeddings extracted from AVID (loudness) and ALBA (clarity) datasets to identify components correlated with Lombard attributes. These components are shifted by user-specified coefficients and inverse-transformed to create manipulated embeddings that condition the TTS model. Lombardness is controlled via three parameters: loudness, clarity, and speaking speed (syllable count-based duration control).

## Key Results
- SSIM scores ~81% across Lombardness levels, indicating speaker identity preservation
- UTMOS naturalness scores ~3.5 on 100-point scale
- Relative WER reduction up to 50% at SNR=10 compared to baseline
- Cross-lingual synthesis maintains intelligibility with 89.1% SSIM for German speakers prompted in English

## Why This Works (Mechanism)

### Mechanism 1: PCA-Directed Style Embedding Manipulation
Principal component analysis on style embeddings can identify and isolate Lombard-correlated dimensions, enabling zero-shot control without Lombard-specific training data. Style embeddings extracted from reference audio via ECAPA-TDNN encoder are projected into PCA space. Components correlated with loudness (PC1, PC2 from AVID corpus analysis) and clarity (PC2 from ALBA dataset analysis) are shifted by user-specified coefficients, then inverse-transformed to produce manipulated embeddings that condition speech generation.

### Mechanism 2: FiLM Conditioning for Style Injection
Feature-wise Linear Modulation (FiLM) applied to later DiT blocks enables style-conditional generation while preserving early-layer duration alignment learning. Early DiT blocks (first two) are frozen to protect learned duration alignments. Later blocks receive FiLM conditioning where outputs are scaled and shifted by parameters derived from style embeddings.

### Mechanism 3: Formant Perturbation for Speaker Leakage Prevention
Training-time augmentation via formant shifts on masked mel-spectrograms forces the model to rely on style embeddings for speaker identity, preventing direct speaker leakage from input features. During training, masked mel-spectrogram inputs receive formant perturbations that distort speaker characteristics.

## Foundational Learning

- **Lombard Effect and Acoustic Correlates**: Understanding that Lombard speech involves increased intensity, spectral tilt changes, formant expansion, and slower speaking rate is essential for interpreting why PCA components correlate with these attributes.
  - Quick check: Why does the ablation study show that removing clarity control hurts intelligibility more at moderate noise levels, while removing loudness control hurts more at high noise levels?

- **Principal Component Analysis for Latent Space Interpretation**: The method relies on PCA to discover interpretable directions in style embedding space.
  - Quick check: If PC1 and PC2 both correlate with loudness, but you only shift PC2, what happens to the resulting speech and why might this cause unintended side effects?

- **FiLM Conditioning**: Understanding how affine transformations (scale γ and shift β) conditioned on external embeddings modulate neural network activations is necessary to trace how style information propagates through the model.
  - Quick check: If FiLM parameters are derived from a linear projection of style embeddings, how many learnable parameters are introduced per conditioned DiT block given 1024D style embeddings and D-dimensional block outputs?

## Architecture Onboarding

- **Component map:**
  Reference Audio → ECAPA-TDNN Encoder → 1024D Style Embedding → PCA Projection → Component Selection → Shift → Inverse PCA → Manipulated Style Embedding → FiLM-conditioned DiT blocks → Mel-Spectrogram → Vocoder → Audio

- **Critical path:**
  1. Style embedding extraction quality (ECAPA-TDNN must capture speaker + prosody)
  2. PCA component identification (requires analysis datasets AVID/ALBA separate from training)
  3. FiLM conditioning effectiveness (later blocks must successfully integrate style)
  4. Duration control via syllable count (assumes 4 syllables/sec default for English)

- **Design tradeoffs:**
  - In-context learning vs. style embedding conditioning: Removing reference text eliminates cross-lingual accent artifacts but reduces SSIM (89.1% vs. 95.9% for English prompts)
  - Frozen early blocks: Protects duration learning but may limit fine-grained adaptation
  - Dataset-specific PCA: AVID/ALBA define loudness/clarity directions but may not generalize to other prosodic attributes or languages

- **Failure signatures:**
  - Speaker identity drift: SSIM drops below 80% → style embedding may not capture speaker sufficiently
  - Unnatural speech at extreme Lombard levels: If Very Loud sounds distorted → PCA shift coefficients may be too aggressive
  - Cross-lingual accent artifacts: If German-prompt English synthesis retains German accent → style embedding may encode language-specific patterns
  - Clarity control ineffective: If WER doesn't improve at SNR=5-10 with clarity increase → PC2 may not capture articulation in target speaker's embedding space

- **First 3 experiments:**
  1. PCA component validation: Synthesize speech shifting only PC1, only PC2, both, and neither for AVID speakers. Measure SPL and speaking rate to confirm component-attribute correlations.
  2. Speaker identity robustness: For 10 unseen speakers, synthesize Normal and Very Loud speech. Compute SSIM between Normal and Very Loud versions.
  3. Noise robustness ablation: Synthesize speech at all four Lombard levels, add noise at SNR={clean, 10, 5, 1}, measure WER with Whisper Large-v3. Compare against baseline F5-TTS and ground truth.

## Open Questions the Paper Calls Out

- **Can the framework support fine-grained, phoneme-level articulatory control beyond global loudness and clarity adjustments?**
  - Basis: The conclusion states, "Future work could explore more detailed control of articulation and prosody."
  - Unresolved: The current method applies global PCA shifts to the entire utterance. It is unclear if the embedding space manipulation can target specific phonemic units or prosodic events without distorting the global speech style.

- **How effectively can the proposed style-embedding control be integrated into real-time interactive systems with dynamic environmental feedback?**
  - Basis: The conclusion suggests future work should explore "adaptation in interactive systems."
  - Unresolved: The current system operates in a feed-forward manner (text-to-speech). It is unknown if the PCA manipulation logic can function dynamically in response to fluctuating environmental SNRs without introducing latency or instability.

- **Can the subjective naturalness gap between synthesized Lombard speech and ground truth be closed while maintaining current intelligibility gains?**
  - Basis: Table 4 shows a consistent negative preference for the TTS model in naturalness (CMOS -1.22) compared to ground truth, despite higher intelligibility scores.
  - Unresolved: While the model enhances noise robustness, the PCA shifting method may introduce subtle artifacts or "unusual" prosodic trajectories that human listeners rate as less natural than human Lombard speech.

## Limitations

- **Dataset Generality and Component Stability**: The PCA-based control relies on analyzing specific datasets (AVID for loudness, ALBA for clarity) to identify style embedding components. The method's effectiveness may degrade for speakers whose prosodic patterns differ significantly from the training corpus.
- **Cross-Lingual Generalization Gap**: The method demonstrates successful zero-shot synthesis across languages but with reduced speaker similarity (SSIM 89.1% vs 95.9% for English prompts).
- **Control Granularity and Unintended Interactions**: The method uses discrete Lombardness levels with predefined loudness, clarity, and speed coefficients. The paper does not analyze whether these attributes interact linearly or whether intermediate values produce consistent, predictable results.

## Confidence

- **High Confidence**: The core claim that PCA analysis of style embeddings can identify components correlated with loudness and clarity attributes, and that shifting these components produces corresponding acoustic changes in synthesized speech.
- **Medium Confidence**: The claim that the zero-shot approach matches or exceeds baseline performance while preserving speaker identity across Lombardness levels.
- **Low Confidence**: The generalizability of the method to speakers and languages beyond those represented in the training and analysis datasets.

## Next Checks

1. **Component Stability Analysis**: Extract style embeddings from 20 unseen speakers across different demographics and languages. Perform PCA on each speaker individually and measure the variance explained by components identified from AVID/ALBA. Calculate the correlation between these speaker-specific components and the reference loudness/clarity components.

2. **Independent Attribute Control Validation**: Synthesize speech for 5 speakers at all combinations of discrete loudness ([-1.0, 0, 1.0]) and clarity ([-1.0, 0, 1.0]) values, holding speed constant. Measure SPL, articulation rate, and intelligibility (WER under noise) for each combination.

3. **Cross-Lingual Speaker Identity Stress Test**: For 10 German speakers, synthesize speech using English, German, and French prompts at Normal Lombardness. Compute SSIM between reference German speech and each synthesized version.