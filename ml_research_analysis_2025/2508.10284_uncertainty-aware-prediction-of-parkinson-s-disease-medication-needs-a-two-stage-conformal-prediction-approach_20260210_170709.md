---
ver: rpa2
title: 'Uncertainty-Aware Prediction of Parkinson''s Disease Medication Needs: A Two-Stage
  Conformal Prediction Approach'
arxiv_id: '2508.10284'
source_url: https://arxiv.org/abs/2508.10284
tags:
- medication
- prediction
- disease
- coverage
- parkinson
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses medication management for Parkinson's Disease,
  where clinicians must balance symptom control against side effects while dealing
  with heterogeneous disease progression. The study develops a two-stage conformal
  prediction framework that first classifies patients likely to need medication adjustments,
  then predicts the magnitude of change in levodopa equivalent daily dose (LEDD).
---

# Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach

## Quick Facts
- arXiv ID: 2508.10284
- Source URL: https://arxiv.org/abs/2508.10284
- Authors: Ricardo Diaz-Rincon; Muxuan Liang; Adolfo Ramirez-Zamora; Benjamin Shickel
- Reference count: 40
- One-line primary result: Two-stage conformal prediction achieves 82.3% marginal coverage with 21.8% shorter intervals than traditional methods for PD medication forecasting

## Executive Summary
This work addresses medication management for Parkinson's Disease, where clinicians must balance symptom control against side effects while dealing with heterogeneous disease progression. The study develops a two-stage conformal prediction framework that first classifies patients likely to need medication adjustments, then predicts the magnitude of change in levodopa equivalent daily dose (LEDD). Using electronic health records from 631 inpatient admissions, the approach addresses zero-inflation challenges where many patients maintain stable medication regimens between visits.

## Method Summary
The method implements a two-stage prediction pipeline: first, an XGBoost classifier determines whether patients will require medication changes; second, a regression model predicts the magnitude of LEDD adjustments for those predicted to change. Conformal prediction (CV+, Naïve, J+aB) constructs uncertainty intervals, with the two-stage approach specifically handling the zero-inflation problem where 75% of observations show no medication change. The framework provides statistically valid coverage guarantees while producing more efficient (narrower) intervals than standard conformal methods.

## Key Results
- Achieves 82.3% marginal coverage with 21.8% shorter prediction intervals compared to traditional methods
- Provides precise short-term predictions (±3.75% LEDD at 6 months)
- Delivers appropriately wider ranges for longer-term forecasting (0.685 interval length at 4 years)
- Outperforms standard conformal methods on zero-inflated data (90.4% coverage vs 81.1% for 2-year predictions)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing zero-inflated prediction into classification-then-regression improves interval efficiency while preserving coverage guarantees.
- Mechanism: Stage 1 estimates P(Y ≠ 0 | X) via XGBoost classifier with calibrated threshold α_r; Stage 2 applies conformal prediction only to non-zero cases. Conformity scores are computed on regression residuals from samples with actual LEDD changes. The final interval combines a point-mass at zero (for predicted non-changers) with symmetric intervals around predicted magnitude (for predicted changers). The quantile correction γ = max{0, min{1, (1 − β̂ − r)/(1 − r)}} adjusts for classifier errors.
- Core assumption: Exchangeability of calibration residuals given the two-stage filtering; stable classifier calibration across folds.
- Evidence anchors:
  - [abstract] "Our two-stage approach identifies patients likely to need medication changes, then predicts required levodopa equivalent daily dose adjustments."
  - [section 3.4] "This targeted approach not only improves prediction accuracy but also ensures that uncertainty quantification focuses on clinically actionable cases where medication changes are needed."
  - [corpus] Weak direct support. Neighbors focus on PD progression and symptom tracking but not zero-inflated conformal prediction or two-stage uncertainty quantification.
- Break condition: If classifier calibration shifts significantly between training and deployment (covariate shift), coverage guarantees may degrade since the γ correction assumes stable β̂.

### Mechanism 2
- Claim: Cross-validation-based conformal prediction (CV+) maintains marginal coverage with narrower intervals than split conformal under heterogeneous PD trajectories.
- Mechanism: CV+ aggregates K=5 calibration sets via K-fold cross-validation. For each test point, the prediction interval is [inf_j(ŷ_j(x) − q̂_{j,1−α}), sup_j(ŷ_j(x) + q̂_{j,1−α})], where quantiles are computed per-fold. This leverages multiple distinct calibration sets, reducing variance in interval width compared to single split methods. The theoretical guarantee is at least 1−2α coverage under exchangeability.
- Core assumption: K-fold calibration sets are approximately exchangeable with test data; residuals are not heavily dependent on specific training subsets.
- Evidence anchors:
  - [abstract] "achieves 82.3% marginal coverage with 21.8% shorter prediction intervals compared to traditional methods"
  - [section 4.2] "Our two-stage CV+ method achieved a marginal coverage of 82.3%, exceeding nominal coverage (80%) while requiring 21.8% shorter prediction intervals than standard CV+ (0.539 to 0.421)."
  - [corpus] Weak. No corpus papers evaluate conformal prediction; neighbors use point predictions (LSTMs, neural ODEs) without coverage guarantees.
- Break condition: Under strong distribution shift (e.g., new patient populations with different PD subtypes), exchangeability fails and coverage may drop below nominal.

### Mechanism 3
- Claim: Time-horizon-dependent interval widening naturally captures compounding uncertainty in longitudinal medication forecasting.
- Mechanism: Separate models are trained for each forecast horizon (6M, 1Y, 2Y, 4Y). Conformity score distributions broaden with longer horizons due to increased trajectory variance, yielding wider intervals without manual tuning. The classifier AUC remains robust (>0.89 at 4 years), but regression RMSE and interval length increase, reflecting genuine clinical uncertainty.
- Core assumption: Training data at each horizon is representative of future patient trajectories; no systematic acceleration/deceleration of disease progression in deployment.
- Evidence anchors:
  - [abstract] "providing precise short-term predictions (±3.75% LEDD at 6 months) and appropriately wider ranges for longer-term forecasting"
  - [section 4.3, Table 2] Shows CV+ at 6M cutoff 0.95: coverage 87.3%, interval 0.075; at 4Y cutoff 0.85: coverage 100%, interval 0.685.
  - [corpus] Partial support. Neighbors like "Predicting Parkinson's Disease Progression Using Statistical and Neural Mixed Effects Models" note trajectory heterogeneity and within-subject correlations but do not quantify prediction uncertainty.
- Break condition: If disease-modifying interventions change progression dynamics between training and deployment, horizon-specific intervals will be mis-calibrated.

## Foundational Learning

- Concept: Conformal prediction (distribution-free coverage guarantees)
  - Why needed here: Enables statistically valid prediction intervals without assuming LEDD change distributions, critical for heterogeneous PD populations.
  - Quick check question: Given a calibration set of 100 residuals with 80% quantile at 0.15, what interval around a point prediction of 10 ensures 80% coverage?

- Concept: Zero-inflated regression
  - Why needed here: 75% of visits show no LEDD change; standard regression would produce biased estimates and overly wide intervals.
  - Quick check question: If 75% of Y=0 and you fit a standard regressor, what happens to predicted residuals for the non-zero 25%?

- Concept: Classification threshold calibration
  - Why needed here: The hyperparameter r trades off false positives (unnecessary predictions) vs. false negatives (missed medication changes), directly affecting coverage and interval efficiency.
  - Quick check question: If β̂ (proportion of true zeros among predicted zeros) increases, how should the quantile correction γ adjust to maintain coverage?

## Architecture Onboarding

- Component map:
  - Data layer: OMOP CDM EHR (demographics, medications, visits, clinical narratives) → LEDD computation via Tomlinson conversion factors → log-transformed percentage changes with Winsorization
  - Stage 1: XGBoost classifier (learning_rate=0.1, max_depth=7, n_estimators=700) predicts P(LEDD change | X). Outputs probability scores for thresholding
  - Stage 2: Regression model (XGBoost) trained only on non-zero LEDD changes, predicts magnitude
  - Conformal layer: CV+/J+aB/Naïve methods compute conformity scores on held-out calibration folds, apply γ correction for two-stage filtering, output prediction intervals
  - Evaluation: Coverage, interval length, calibration error across horizons and cutoffs

- Critical path:
  1. LEDD feature engineering (correct conversion factors are essential for target validity)
  2. Classifier calibration (β̂ estimation on validation set determines γ correction)
  3. Conformity score quantile selection (controls coverage vs. efficiency trade-off)
  4. Threshold r optimization (minimizes interval length subject to coverage constraint)

- Design tradeoffs:
  - CV+ vs. J+aB: CV+ provides more stable calibration (mean error +2.3%) but is computationally heavier; J+aB is efficient for ensembles but shows under-coverage (−10.5% calibration error) in this dataset
  - Higher cutoff r → narrower intervals but potentially missed patients needing medication changes
  - Longer horizons → wider intervals; at 4Y, intervals may be too wide for clinical utility despite valid coverage

- Failure signatures:
  - Coverage drops below nominal: Check for covariate shift in patient population or mis-estimated β̂
  - Intervals excessively wide: Likely high classifier false-positive rate at current threshold; consider raising cutoff
  - Calibration error highly negative: Naïve or J+aB methods on small datasets; switch to CV+
  - Zero-inflation not handled: Standard conformal methods show under-coverage (Table 7: standard CV+ at 2Y = 81.1% coverage with 0.811 interval length vs. two-stage CV+ = 90.4% coverage with 0.192 interval length)

- First 3 experiments:
  1. Reproduce Table 2 results for 6M horizon with CV+ at cutoffs [0, 0.5, 0.95]; verify coverage and interval length match reported values (target: 87.3% coverage, 0.075 interval at cutoff 0.95)
  2. Ablation: Compare two-stage vs. standard conformal on synthetic zero-inflated data (vary zero proportion 50–90%) to quantify coverage/efficiency gains from the two-stage decomposition
  3. Sensitivity analysis: Vary r ∈ [0.1, 0.9] and plot coverage vs. interval length curves; identify Pareto-optimal operating points for clinical deployment (e.g., minimum interval length at 80% coverage)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an automated optimization mechanism be developed to systematically select the classification threshold that balances interval width against marginal coverage?
- Basis in paper: [explicit] The authors state their "cutoff/threshold selection approach requires a more systematic methodology to optimally balance classification accuracy, regression performance, and interval length."
- Why unresolved: The current study utilized a specific threshold strategy that may not be robust across different datasets or time horizons without manual tuning.
- What evidence would resolve it: An algorithm that dynamically selects thresholds minimizing interval length while strictly adhering to nominal coverage guarantees across diverse cohorts.

### Open Question 2
- Question: Does the two-stage conformal framework maintain its performance characteristics (82.3% coverage, efficient interval lengths) when applied to outpatient or multi-center datasets?
- Basis in paper: [explicit] The authors list incorporating "outpatient and multi-center data" as a specific aim for future work to validate generalizability.
- Why unresolved: The model was trained and tested on a single institution's inpatient records (University of Florida Health), which may not represent broader population variances or less acute care settings.
- What evidence would resolve it: Successful replication of coverage and precision metrics on external datasets, such as the Parkinson's Progression Markers Initiative (PPMI).

### Open Question 3
- Question: Can methods addressing distribution shift, such as distributional conformal prediction, significantly narrow the overly conservative prediction intervals seen in 4-year forecasts?
- Basis in paper: [inferred] The paper notes that 4-year predictions resulted in intervals too wide for "meaningful guidance" and explicitly mentions exploring "advanced conformal methods to address distribution shifts inherent in disease progression."
- Why unresolved: The inherent uncertainty and non-stationarity of PD progression over long periods likely violate standard conformal exchangeability assumptions, leading to wide, conservative intervals.
- What evidence would resolve it: Demonstration of reduced interval widths on long-term horizons without sacrificing the statistical guarantee of coverage.

## Limitations

- Framework performance on outpatient settings remains untested, as validation was limited to inpatient admissions with 631 patients
- Clinical utility depends on threshold calibration (cutoff r), which may require frequent adjustment as patient populations shift
- The NLP pipeline for processing clinical narratives is unspecified, potentially limiting reproducibility
- Four-year forecasts show high uncertainty (0.685 interval length), questioning long-term clinical applicability
- Results are institution-specific (UF Health), requiring external validation across diverse healthcare systems

## Confidence

- High confidence: Two-stage decomposition methodology and its theoretical coverage guarantees
- Medium confidence: Empirical performance metrics (82.3% coverage, 21.8% interval reduction) within the study population
- Low confidence: Long-term forecast accuracy (4-year predictions) and generalization to non-inpatient settings

## Next Checks

1. Replicate coverage analysis across multiple institutions with different patient demographics and care settings
2. Conduct prospective clinical trial evaluating decision-making impact with clinicians using uncertainty-aware predictions vs. point estimates
3. Perform sensitivity analysis on cutoff threshold r across diverse patient subpopulations to identify robust operating points