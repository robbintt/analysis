---
ver: rpa2
title: 'Reimagining Personal Data: Unlocking the Potential of AI-Generated Images
  in Personal Data Meaning-Making'
arxiv_id: '2502.18853'
source_url: https://arxiv.org/abs/2502.18853
tags:
- data
- images
- personal
- image
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how AI-generated images can transform personal
  data into a new medium for meaning-making. Through a 21-day diary study with 16
  participants, the authors found that image-generative AI enabled four new qualities
  of data engagement: discovering emotional layers within data, (re)conceptualizing
  self through AI interpretation, crafting personal narratives, and fostering curiosity-driven
  self-tracking.'
---

# Reimagining Personal Data: Unlocking the Potential of AI-Generated Images in Personal Data Meaning-Making

## Quick Facts
- arXiv ID: 2502.18853
- Source URL: https://arxiv.org/abs/2502.18853
- Reference count: 40
- Primary result: AI-generated images enable deeper reflection on personal data through co-interpretation, defamiliarization, and serendipitous multi-perspective exploration.

## Executive Summary
This paper presents a novel approach to personal data reflection using AI-generated images. Through a 21-day diary study with 16 participants, the authors demonstrate how image-generative AI transforms personal data into an interpretive medium that enables deeper meaning-making. The system uses GPT-4 to generate image prompts from user-entered personal data, which DALL-E 3 then visualizes. Participants reported four key experience qualities: discovering emotional layers within data, reconceptualizing self through AI interpretation, crafting personal narratives, and fostering curiosity-driven self-tracking. The study reveals how AI-generated images serve as an "interpretive medium" that encourages co-interpretation between users and AI, offering new opportunities for personal informatics and mental wellbeing applications.

## Method Summary
The study employed a web-based probe that generated images from personal data using a two-stage pipeline: GPT-4o transformed user-entered data into image prompts following seven specific rules, then DALL-E 3 generated the corresponding images. Sixteen participants engaged in a 21-day diary study, entering various personal data types (quantitative: step count, screen time; qualitative: mood, habits, diary) and viewing AI-generated images. The system stored data in MongoDB and images in Amazon S3, with a web interface providing calendar/timeline views and reflection memo fields. Analysis drew from 336 diary pages and over 940 minutes of interviews to identify four key experience qualities.

## Key Results
- Participants engaged in co-interpretation of AI-generated images, viewing them as external perspectives that enriched their understanding of personal data
- The unknowable interpretation quality of AI image generation created an opaque transformation layer that heightened subjectivity and enabled deeper data understanding
- Images prompted reflection on context and emotions, transforming previously unreflective quantitative data (like step counts) into opportunities for narrative construction
- The serendipity of generative AI outputs fostered diverse types of reflection by offering multiple perspectives on the same data

## Why This Works (Mechanism)

### Mechanism 1: Co-Interpretation Through Layered Meaning
The "unknowable interpretation" quality of AI image generation creates an opaque transformation layer. Users cannot fully predict how their data becomes visual, so they must actively speculate on the AI's reasoning. This multi-layered process—data → AI interpretation → visual output → human reinterpretation—transforms passive data consumption into active meaning construction. [abstract, Findings §4.2, corpus]

### Mechanism 2: Defamiliarization Through Abstract Visual Representation
The paper's prompt rules explicitly prevent direct data depiction (no numbers, text, or obvious data-type symbols). This abstraction forces users to project personal meaning onto ambiguous visual elements—colors, moods, scenes—activating imaginative interpretation rather than literal reading. [Formative Study §3.1.2, Findings §4.1, corpus]

### Mechanism 3: Serendipity Enabling Multi-Perspective Reflection
Generative models produce non-deterministic outputs. The paper leverages this as a feature, mandating diverse styles and keywords. Users who regenerated images from the same data reported comparing outputs to identify which "best captured" their experience, deepening reflection through comparative interpretation. [Formative Study §3.1.2, Findings §4.2, corpus]

## Foundational Learning

- **Concept: Ambiguity as Design Resource**
  - Why needed here: The entire approach rests on Gaver et al.'s principle that ambiguity invites interpretation. Without understanding this, engineers may over-optimize for "accuracy" and undermine the reflective mechanism.
  - Quick check question: Can you explain why a less accurate image might produce more meaningful user reflection than a highly accurate one?

- **Concept: Co-Interpretation (Human-Machine Meaning Negotiation)**
  - Why needed here: The system is not designed to "correctly" visualize data but to create interpretive space. This inverts typical AI design goals (accuracy → interpretability).
  - Quick check question: How would you evaluate success if the system's goal is not accuracy but user engagement in meaning-making?

- **Concept: Generative AI Variability and Non-Determinism**
  - Why needed here: Prompt engineering must balance randomness (for serendipity) against coherence (for interpretability). Understanding temperature, seed control, and prompt structure is essential.
  - Quick check question: What happens to the reflective experience if you set the image generation model to its most deterministic setting?

## Architecture Onboarding

- **Component map:** User Data Input -> GPT-4 API (prompt generation) -> DALL-E 3 API (image generation) -> Storage Layer (MongoDB + S3) -> Presentation Layer (web UI)

- **Critical path:** User data input → structured prompt generation → DALL-E 3 image generation → storage and retrieval → calendar/timeline display with reflection memo

- **Design tradeoffs:** Privacy vs. interpretability (Rules 1-3 prevent direct data depiction); Serendipity vs. coherence (Rules 5-6 enforce diversity); Prompt visibility (optional access to image prompts for user choice between pure interpretation vs. understanding AI's reasoning)

- **Failure signatures:** Images "don't relate to my data at all" (abstraction too high); Images "look exactly like my data" (defamiliarization failed); Negative emotional amplification (emotional tone not regulated)

- **First 3 experiments:**
  1. Prompt rule ablation test: Generate images with/without Rule 4 (originality/unexpectedness) and compare reflection depth
  2. Serendipity calibration: Test 1 image vs. 3 images vs. user-controlled regeneration to measure reflective diary quality
  3. Emotional safety probe: Implement pre-generation emotional state check and compare emotional outcomes against control group

## Open Questions the Paper Calls Out

### Open Question 1
How do cultural backgrounds influence the interpretation and meaning-making of AI-generated images derived from personal data? The study involved participants exclusively from South Korea, leaving unknown whether the four experience qualities generalize across cultures. Comparative studies with diverse cultural backgrounds would provide broader understanding.

### Open Question 2
How does the use of AI-generated images as data representations affect long-term self-tracking behaviors and relationships with personal data? The 21-day study duration may not capture habituation effects, sustained behavioral changes, or evolving relationships with generated images as digital possessions. Longitudinal studies (6+ months) are needed.

### Open Question 3
What prompt design strategies optimize the balance between ambiguity and interpretability in AI-generated images for personal reflection? While the study identified "unknowable interpretation" and "serendipity" as valuable qualities, it did not systematically test different levels of ambiguity or compare structured versus unstructured prompt approaches.

## Limitations
- Small sample size (16 participants over 21 days) limits generalizability
- System reliability depends heavily on prompt engineering quality, which may not transfer to other contexts
- "Unknowable interpretation" mechanism assumes users have sufficient reflective capacity and motivation
- Emotional safety concerns identified (negative emotional amplification in 2 participants) require mitigation strategies

## Confidence

- **High Confidence**: The empirical findings about four specific qualities of data engagement (emotional discovery, self-reconceptualization, narrative crafting, curiosity-driven tracking) are well-supported by the diary data and interviews
- **Medium Confidence**: The theoretical framework around co-interpretation and defamiliarization mechanisms is plausible but not fully empirically validated within the study itself
- **Low Confidence**: The generalizability of the approach to broader populations and different types of personal data remains unproven

## Next Checks

1. **Prompt Rule Effectiveness Test**: Systematically vary the seven prompt rules (especially Rules 1-4 for privacy/abstraction) to empirically measure their impact on user reflection depth and emotional safety outcomes

2. **Serendipity Calibration Study**: Test different levels of AI output variability (fixed vs. multiple vs. user-controlled regeneration) to identify the optimal balance between serendipitous reflection and interpretive coherence

3. **Emotional Safety Implementation**: Develop and evaluate pre-generation emotional state checks and user-controlled tone preferences to mitigate the negative emotional amplification risks identified in the study