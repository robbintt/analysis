---
ver: rpa2
title: Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement
arxiv_id: '2601.19170'
source_url: https://arxiv.org/abs/2601.19170
tags:
- graph
- procedural
- feedback
- structural
- gateway
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces text2flow, a multi-agent framework for extracting
  procedural graphs from natural language documents. The method addresses challenges
  in capturing both structural validity and logical consistency by using iterative
  refinement with a graph builder agent, a simulation agent for structural feedback,
  and a semantic agent for logical alignment.
---

# Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement

## Quick Facts
- **arXiv ID:** 2601.19170
- **Source URL:** https://arxiv.org/abs/2601.19170
- **Reference count:** 30
- **Primary result:** Text2flow achieves F1 scores up to 0.859 for action nodes and 0.710 overall on PAGED benchmark through multi-agent iterative refinement

## Executive Summary
This paper introduces text2flow, a multi-agent framework for extracting procedural graphs from natural language documents. The method addresses challenges in capturing both structural validity and logical consistency by using iterative refinement with a graph builder agent, a simulation agent for structural feedback, and a semantic agent for logical alignment. Structural issues are detected via multi-path execution, while gateway logic is validated against the source text. The system prioritizes high-impact revisions based on error frequency and unresolved feedback, enabling interpretable corrections. Experiments on the PAGED benchmark show significant improvements over baselines, achieving F1 scores up to 0.859 for action nodes and 0.710 overall, with especially strong gains in control-flow and constraint modeling. The approach effectively balances accuracy and computational cost through a two-iteration refinement process.

## Method Summary
The text2flow framework employs a multi-agent architecture consisting of a graph builder agent, a simulation agent, and a semantic agent working in iterative refinement cycles. The graph builder agent generates initial procedural graphs from natural language documents using a graph-enhanced LLM with multi-modal fusion and adaptive thresholding. The simulation agent evaluates structural validity through multi-path execution, identifying dead ends and unreachable nodes, while the semantic agent validates gateway logic against the source text for logical consistency. The system uses a revision prioritization mechanism that focuses on high-impact nodes based on error frequency and unresolved feedback, enabling targeted corrections. The framework operates in two refinement iterations, balancing accuracy gains with computational efficiency.

## Key Results
- Achieves F1 score of 0.859 for action node extraction and 0.710 overall on PAGED benchmark
- Demonstrates significant improvements over baseline models in control-flow and constraint modeling
- Shows effective balance between accuracy and computational cost through two-iteration refinement

## Why This Works (Mechanism)
The approach works by decomposing the complex task of procedural graph extraction into specialized sub-tasks handled by different agents. The simulation agent provides structural feedback by executing multiple execution paths to identify dead ends and unreachable nodes, addressing a key limitation of purely semantic approaches. The semantic agent validates gateway logic against the source text, ensuring logical consistency of control-flow elements. The iterative refinement process with prioritized revisions allows the system to focus computational resources on the most problematic areas, improving both accuracy and efficiency compared to exhaustive approaches.

## Foundational Learning

**Multi-path execution for structural validation**
- *Why needed:* Pure semantic analysis can miss structural issues that only become apparent when tracing execution paths through the graph
- *Quick check:* Verify that the simulation agent can identify all types of structural errors (dead ends, unreachable nodes, infinite loops) in controlled test cases

**Graph-enhanced LLM with multi-modal fusion**
- *Why needed:* Procedural text requires understanding both linguistic semantics and graph structural constraints that standard LLMs struggle with
- *Quick check:* Test the model's ability to generate valid graph structures from text with varying complexity levels

**Revision prioritization based on error frequency**
- *Why needed:* Prevents wasteful computation by focusing refinement efforts on nodes that cause the most problems
- *Quick check:* Compare accuracy gains per unit of computational cost between prioritized and random revision strategies

## Architecture Onboarding

**Component map:**
Graph Builder Agent -> Simulation Agent -> Semantic Agent -> Revision Prioritizer -> Graph Builder Agent (iterative cycle)

**Critical path:**
Natural language document → Graph builder initial extraction → Structural simulation → Semantic validation → Prioritized revision → Refined graph → Final evaluation

**Design tradeoffs:**
The two-iteration approach balances accuracy gains against computational cost, sacrificing potential marginal improvements from additional iterations for practical deployment viability. The prioritization mechanism trades completeness for efficiency, potentially missing rare but critical errors in low-frequency nodes.

**Failure signatures:**
- Dead ends indicate missing return paths or incomplete gateway logic
- Unreachable nodes suggest disconnected graph components or incorrect precedence relationships
- Semantic inconsistencies point to misaligned gateway conditions or violated constraints
- Low revision impact scores may indicate either high-quality initial extraction or systematic issues requiring architectural changes

**3 first experiments:**
1. Test structural simulation on procedurally generated graphs with known dead ends and unreachable nodes
2. Evaluate semantic validation accuracy on benchmark procedural texts with annotated gateway logic
3. Compare two-iteration versus single-iteration performance across different procedure complexity levels

## Open Questions the Paper Calls Out
None

## Limitations
- Computational efficiency and resource requirements for multi-agent refinement process are not detailed, limiting practical deployment assessment
- Evaluation focuses primarily on PAGED benchmark, restricting generalizability to other procedural text domains
- Limited validation of refinement mechanism's effectiveness for very long or complex procedures

## Confidence

**High Confidence:**
- The core methodology of using multi-agent systems with structural simulation and semantic validation is technically sound and well-articulated
- The iterative refinement approach with prioritized revisions is a logical advancement in procedural graph extraction

**Medium Confidence:**
- Reported improvements over baselines on PAGED benchmark are substantial, but limited scope of evaluation and lack of cross-domain validation reduce confidence in broader applicability
- The specific choice of two refinement iterations appears empirically justified but could benefit from sensitivity analysis

**Medium Confidence:**
- The claim of interpretable corrections is supported by the methodology but would require qualitative analysis to fully validate the interpretability aspect for end-users

## Next Checks
1. Conduct computational efficiency analysis measuring inference time, memory usage, and cost per document across different procedure lengths and complexities to assess practical deployment viability
2. Perform cross-domain evaluation on diverse procedural text corpora (medical protocols, technical manuals, cooking recipes) to test generalizability beyond the PAGED benchmark
3. Implement ablation studies to quantify the individual contributions of structural simulation versus semantic validation agents and determine optimal iteration counts for different procedure types