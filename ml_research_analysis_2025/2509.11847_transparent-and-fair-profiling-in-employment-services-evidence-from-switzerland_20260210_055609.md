---
ver: rpa2
title: 'Transparent and Fair Profiling in Employment Services: Evidence from Switzerland'
arxiv_id: '2509.11847'
source_url: https://arxiv.org/abs/2509.11847
tags:
- profiling
- data
- performance
- fairness
- interpretable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper compares interpretable and black-box models for predicting
  long-term unemployment (LTU) risk using Swiss administrative data. The study evaluates
  predictive performance, interpretability, and fairness across five models: random
  forests, gradient boosting, extreme gradient boosting, logistic regression, and
  explainable boosting machines (EBM).'
---

# Transparent and Fair Profiling in Employment Services: Evidence from Switzerland

## Quick Facts
- **arXiv ID**: 2509.11847
- **Source URL**: https://arxiv.org/abs/2509.11847
- **Reference count**: 25
- **Primary result**: EBM achieves near-black-box performance (AUC ~0.76) while enabling interpretable, fair unemployment risk assessment

## Executive Summary
This study evaluates interpretable versus black-box models for predicting long-term unemployment (LTU) risk using Swiss administrative data. The research demonstrates that Explainable Boosting Machines (EBM) can match the predictive performance of state-of-the-art black-box models while providing full transparency. The paper shows that interpretability can be enhanced through feature sparsity and smoothing without significant performance loss, and that fairness constraints (equalizing false positive rates across age groups) can be implemented through post-processing while preserving model interpretability. These findings suggest that transparent, accountable alternatives to black-box models are viable for high-stakes employment services.

## Method Summary
The study trains five models (Random Forest, Gradient Boosting, XGBoost, Logistic Regression, and EBM) on Swiss administrative data to predict LTU risk. Performance is evaluated using AUC across five moving-window cross-validation folds (2014-2018 data, tested on 2019). Interpretability is enhanced through backward feature selection and smoothing of numerical feature functions. Fairness is implemented via post-processing that equalizes false positive rates across age groups (15-29, 30-44, 45-65) at the cost of reduced true positive rates.

## Key Results
- EBM achieves AUC of 0.7593, nearly matching XGB's 0.7619 while providing full interpretability
- Reducing features from 57 to 30 (EBM-30) incurs only minor AUC loss (~0.76 to ~0.75)
- Smoothing numerical feature functions removes artifacts while preserving overall risk trends
- Post-processing achieves equalized false positive rates across age groups, reducing TPR from 80% to 66%

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: EBM can approximate black-box model performance for LTU risk prediction
- **Mechanism**: EBM builds a generalized additive model where predictions are sums of non-linear feature functions, allowing global visualization while capturing non-linear relationships
- **Core assumption**: LTU risk can be modeled through additive feature effects rather than requiring complex feature interactions
- **Evidence anchors**: XGB (0.7619) and EBM (0.7593) show comparable performance; Random Forest underperforms
- **Break condition**: If LTU risk requires high-order, non-additive interactions, EBM performance would degrade

### Mechanism 2
- **Claim**: Interpretability can be enhanced through sparsity and smoothing with minimal performance loss
- **Mechanism**: Backward selection removes least important features; smoothing splines eliminate local fluctuations in numerical feature functions
- **Core assumption**: Local fluctuations represent noise rather than valid signal, and stakeholders prefer smooth, monotonic explanations
- **Evidence anchors**: EBM-30 maintains performance with 27 fewer features; smoothing preserves trends while removing artifacts
- **Break condition**: If removed features contain valid signal (e.g., policy thresholds), performance would suffer

### Mechanism 3
- **Claim**: Fairness can be achieved through post-processing without sacrificing interpretability
- **Mechanism**: Hardt et al.'s post-processing algorithm applies separate decision thresholds to different age groups to equalize false positive rates
- **Core assumption**: Equalizing FPR is worth the tradeoff of reduced overall TPR efficiency
- **Evidence anchors**: Post-processing equalizes FPR across age groups; TPR drops from 80% to 66%
- **Break condition**: If base model is poorly calibrated for subgroups, threshold adjustment cannot fix unfairness

## Foundational Learning

- **Concept: Generalized Additive Models (GAMs)**
  - **Why needed here**: EBM's mathematical foundation explains its balance of interpretability and power
  - **Quick check question**: How does a GAM differ from linear regression regarding feature-outcome relationships?

- **Concept: ROC-AUC vs. Accuracy**
  - **Why needed here**: AUC is used because accuracy is misleading with 20% positive class imbalance
  - **Quick check question**: Why might 90% accuracy be useless for rare events like LTU?

- **Concept: The Accuracy-Fairness Tradeoff**
  - **Why needed here**: Equalizing FPR reduces overall TPR from 80% to 66%, showing the Pareto frontier
  - **Quick check question**: Does equalizing FPR across groups typically increase, decrease, or maintain overall TPR?

## Architecture Onboarding

- **Component map**: 57 administrative features -> EBM (gradient boosting on binned features) -> Backward selection -> Cubic spline smoothing -> Global feature graphs + Local plots + Post-processed thresholds
- **Critical path**: Ingest 2014-2018 data -> Moving window CV training -> Backward selection pruning -> Feature smoothing -> Post-processing for fairness
- **Design tradeoffs**: ~0.2% AUC loss for full interpretability; feature reduction simplifies interface but risks signal loss; smoothing improves justification but may hide anomalies
- **Failure signatures**: Jagged curves indicate overfitting; 2019 performance drop suggests distribution shift; FPR disparity indicates bias without mitigation
- **First 3 experiments**: 1) Compare XGB vs EBM AUC on 2014-2018 data; 2) Implement backward selection and plot features vs AUC; 3) Measure FPR disparity between age groups before post-processing

## Open Questions the Paper Calls Out
None

## Limitations
- Results based on Swiss administrative data may not generalize to other contexts
- 0.76 AUC performance leaves substantial room for improvement in LTU prediction
- Fairness intervention significantly reduces TPR (80% to 66%), limiting practical utility

## Confidence
- High confidence in EBM matching black-box performance
- Medium confidence in sparsity/smoothing benefits due to limited alternative comparisons
- Medium confidence in fairness results due to fundamental utility tradeoffs

## Next Checks
1. Test model performance on 2019-2021 data to assess temporal generalization
2. Compare backward selection with L1 regularization for feature reduction
3. Conduct stakeholder evaluation with employment caseworkers on interpretability impact