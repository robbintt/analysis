---
ver: rpa2
title: 'Seemingly Simple Planning Problems are Computationally Challenging: The Countdown
  Game'
arxiv_id: '2508.02900'
source_url: https://arxiv.org/abs/2508.02900
tags:
- planning
- problem
- countdown
- size
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Countdown, a planning benchmark based on
  a game where players must form a target number from a list of input numbers using
  arithmetic operations. The authors establish Countdown as NP-complete and develop
  a novel instance generation procedure that produces more challenging problems than
  existing methods.
---

# Seemingly Simple Planning Problems are Computually Challenging: The Countdown Game

## Quick Facts
- arXiv ID: 2508.02900
- Source URL: https://arxiv.org/abs/2508.02900
- Reference count: 6
- The paper introduces Countdown as an NP-complete planning benchmark and shows that while symbolic solvers and AutoToS perform well, LLM-based methods like ToT achieve below 10% accuracy for instances larger than size 4.

## Executive Summary
This paper introduces Countdown, a planning benchmark based on a game where players must form a target number from a list of input numbers using arithmetic operations. The authors establish Countdown as NP-complete and develop a novel instance generation procedure that produces more challenging problems than existing methods. Their dataset shows a two-phase transition phenomenon as instance size grows, becoming hard around size 8 then easy again around size 20. Evaluation against symbolic planners and LLM-based methods reveals that while AutoToS (which generates symbolic solvers) performs well, popular LLM planning methods like ToT achieve below 10% accuracy for instances larger than size 4. The paper demonstrates that performance on static datasets like 24Game may be inflated due to memorization, making Countdown a more robust benchmark for planning capabilities.

## Method Summary
The Countdown game is formalized as a planning problem where given n input numbers and a target value τ, the goal is to find a sequence of n-1 arithmetic operations (+, -, *, /) that combines all input numbers to produce the target. The authors develop three instance generation methods: their own CD method (selecting least frequent reachable targets), Reasoning-Gym's RG method, and Stream-of-Search's SoS method. They prove Countdown is NP-complete via reduction from the Subtraction Addition Problem. Evaluation uses three solver types: ENHSP (numeric planner), AutoToS (LLM generates symbolic solver code once then applies it), and LLM methods (IO/CoT/ToT that reason per-instance). All methods are evaluated on datasets of 100 instances per size across sizes 4-50.

## Key Results
- CD method produces significantly harder instances than RG and SoS baselines, with fewer solutions per instance (Figure 2)
- Countdown exhibits a two-phase transition phenomenon: easy→hard at size ~8, then hard→easy at size ~20 (Figure 6)
- AutoToS achieves ~100% accuracy up to size 30 while ToT achieves below 10% accuracy for sizes >4 (Figure 7)
- Performance on 24Game (static dataset) is likely inflated by memorization, as ToT accuracy drops from 90% to 40% when tested on CD-generated instances (Figure 9)

## Why This Works (Mechanism)

### Mechanism 1: Least-Frequent Target Selection for Harder Instances
- Selecting the least frequently reachable target from multiple random solution paths produces instances with fewer solutions and greater difficulty
- Fewer solution paths → harder search problem, as search must explore more of the exponential state space
- Evidence: CD method produces significantly fewer solutions per instance than RG and SoS baselines (Figure 2)

### Mechanism 2: NP-Completeness via SAP Reduction
- Countdown is NP-complete via polynomial reduction from Subtraction Addition Problem (SAP)
- SAP instance {x₁,...,xₙ}, ω maps to Countdown instance {e^{x₁},...,e^{xₙ}}, τ = e^ω
- Lemma 3 ensures no additive operations can succeed, forcing multiplication/division which correspond to addition/subtraction of exponents
- Evidence: Full proof via SAP reduction and Lemma 3 in Complexity Analysis section

### Mechanism 3: Symbolic Code Generation (AutoToS) Outperforms Direct LLM Planning
- AutoToS elicits search components (successor function, goal test) as code from LLM in ~3-4 calls, then runs deterministic DFS
- Avoids per-instance inference costs and reasoning errors that plague methods like ToT
- Evidence: AutoToS achieves ~100% accuracy up to size 30; ToT achieves below 40% even at size 4 (Figure 7)

### Mechanism 4: Two-Phase Transition in Instance Hardness
- Countdown exhibits non-monotonic hardness: easy→hard transition around size 8, then hard→easy transition around size 20
- Both ENHSP (heuristic search) and AutoToS (DFS) show performance drop then recovery across all datasets
- Evidence: Consistent U-shaped hardness curve across all datasets and solvers (Figure 6)

## Foundational Learning

- **NP-Completeness and Polynomial Reductions**
  - Why needed: Understanding why Countdown is "hard" requires grasping reduction proofs. The SAP→Countdown mapping via exponentiation is the theoretical core.
  - Quick check: Given SAP instance {2, 3, 5}, ω=4, what is the corresponding Countdown instance?

- **State Space and Transition Systems**
  - Why needed: Countdown is formalized as Π = ⟨S, A, T, s₀, S*⟩. The exponential state space growth motivates symbolic over direct LLM approaches.
  - Quick check: For input size n=4, what is the approximate upper bound on branching factor at the root?

- **Symbolic vs. Neuro-Symbolic Planning**
  - Why needed: The performance gap between AutoToS (code generation + symbolic search) and ToT/CoT (direct neural inference) is the central empirical finding.
  - Quick check: Why does AutoToS require only ~4 LLM calls regardless of dataset size, while ToT requires hundreds?

## Architecture Onboarding

- **Component map**: Instance Generator -> PDDL Translator -> Solvers (ENHSP, AutoToS, LLM) -> Validator
- **Critical path**: 1) Generate instances using CD method for hardness, 2) Translate to PDDL for symbolic baselines, 3) Run AutoToS pipeline: prompt LLM for successor/goal code → validate on small held-out set → run DFS on full dataset, 4) For LLM baselines, restrict to sizes 4-10 due to computational cost
- **Design tradeoffs**: DFS vs. GBFS (DFS avoids heuristic computation overhead), Instance size range (4-10 captures easy/hard phases but excludes second transition at ~20), Dataset choice (CD is hardest but requires generation code; 24Game is static but likely contaminated)
- **Failure signatures**: LLM format errors (most common for IO/CoT), Unknown number used (67-95% of ToT errors), Not target number (planning failure), ENHSP timeout (sizes >30), AutoToS code generation failure (caught by validation)
- **First 3 experiments**: 1) Reproduce solution count comparison (Figure 2): Generate 100 instances each using CD, RG, SoS methods at sizes 4-7, run DFS to count solutions, verify CD produces fewest, 2) Reproduce phase transition (Figure 6): Run ENHSP and AutoToS-CD on sizes 4-25, plot accuracy to confirm U-shaped curve with transitions at ~8 and ~20, 3) Memorization test (Figure 9/Table 1): Run ToT on 24Game vs. CD[4], confirm accuracy drop (e.g., Llama: 90% → 40%) indicating data contamination

## Open Questions the Paper Calls Out

- **What explains the two-phase transition phenomenon in Countdown, where instances become hard around size 8 but easy again around size 20?**
  - The authors state: "While we cannot offer any explanation for the phenomenon, it does allow us to conclude that it is sufficient to limit our test set to sizes between 4 and 10."
  - The non-monotonic difficulty pattern was discovered empirically and persists across all three datasets tested; no theoretical analysis is provided.
  - A theoretical analysis connecting instance size to search space properties (solution density, branching structure) or formal reduction to known phase transition frameworks would resolve this.

- **Can the performance gap between static benchmarks (24Game) and dynamically generated instances be definitively attributed to memorization in LLM training data?**
  - Authors hypothesize memorization but acknowledge the gap could partially stem from different language models used; causation is not established.
  - The 24Game dataset was scraped from the internet, but controlled experiments isolating memorization effects are not conducted.
  - Controlled experiments using models with documented training corpora, systematically testing memorization via data contamination analysis would resolve this.

- **Would introducing operation costs and requiring cost-optimal solutions significantly degrade the performance of currently successful symbolic methods (AutoToS, ENHSP)?**
  - Future work section states: "introducing different costs of operations and optimizing the summed cost of a sequence makes the problem harder, and will challenge the currently well performing methods."
  - This extension is proposed but not implemented or evaluated.
  - Empirical evaluation on cost-extended Countdown variants, comparing accuracy and solve time against the current cost-agnostic formulation would resolve this.

## Limitations

- The NP-completeness proof relies on Lemma 3 (no two integer sets {x,y}, {a,b} satisfy e^{a±b} = e^x ± e^y), which is stated but not formally proven in the paper.
- The two-phase transition phenomenon at sizes 8 and 20 is empirically observed but unexplained theoretically, with no mechanistic insight into why instances become easier again at larger sizes.
- Performance comparisons may be influenced by LLM model selection and hyperparameter choices that are not fully specified (beam width, exploration depth for ToT, exact prompts for all methods).

## Confidence

- **High Confidence**: NP-completeness reduction framework, instance generation methodology (CD vs RG/SoS comparison), and the general observation that AutoToS outperforms per-instance LLM methods
- **Medium Confidence**: The specific hardness ordering (CD > RG > SoS), the two-phase transition phenomenon, and memorization effects in 24Game
- **Low Confidence**: The exact size thresholds for phase transitions (8 and 20) as universal properties, and the generalizability of the AutoToS approach to other planning domains

## Next Checks

1. Verify Lemma 3 by computational search for counterexamples across a broad range of integer values, or request formal proof from the authors
2. Test whether the two-phase transition phenomenon persists when using different input number distributions (currently unspecified) or different target ranges
3. Conduct ablation studies on AutoToS performance by varying the number of held-out instances used for code validation, and test whether the approach generalizes to other numeric planning domains beyond Countdown