---
ver: rpa2
title: A Family-Based Approach to Safety Cases for Controlled Airspaces in Small Uncrewed
  Aerial Systems
arxiv_id: '2502.02559'
source_url: https://arxiv.org/abs/2502.02559
tags:
- safety
- case
- suas
- pilot
- flight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel method, Safety Case Software Product
  Line Engineering (SafeSPLE), to extend product-family techniques to on-entry safety
  cases for small Uncrewed Aircraft Systems (sUAS) in controlled airspaces. SafeSPLE
  automates the generation of customized safety-case instances for specific sUAS flights
  by parameterizing a general safety case using a feature model representing flight
  characteristics and hazards.
---

# A Family-Based Approach to Safety Cases for Controlled Airspaces in Small Uncrewed Aerial Systems

## Quick Facts
- arXiv ID: 2502.02559
- Source URL: https://arxiv.org/abs/2502.02559
- Reference count: 40
- Primary result: Automated safety case generation for sUAS entry into controlled airspace using product-line techniques

## Executive Summary
This paper introduces Safety Case Software Product Line Engineering (SafeSPLE), a method that extends product-family techniques to on-entry safety cases for small Uncrewed Aircraft Systems (sUAS) operating in controlled airspace. The approach uses a feature model to represent flight characteristics and hazards, then automatically generates customized safety-case instances for specific sUAS flights by parameterizing a general safety case. A case study demonstrates the system can generate valid safety-case instances for specific sUAS models under varying weather conditions, checking parameters like wind speed, visibility, and battery reserves.

## Method Summary
SafeSPLE combines software product line engineering with goal structuring notation (GSN) safety cases. The method begins with hazard analysis to identify safety-relevant conditions, followed by construction of a feature model representing flight variability. A parameterized safety case is then created where feature values bind to parameters in context and evidence nodes. The instance generator evaluates evidence nodes against concrete inputs to determine if safety requirements are met, providing traceable decisions for sUAS entry into UTM-controlled airspace.

## Key Results
- Demonstrated generation of valid safety-case instances for DJI Mini 4 Pro and DEERC D20 under varying weather conditions
- Successfully implemented conservative defaults when manufacturer specifications lack explicit limits
- Provided traceable evidence for entry decisions with failure localization to specific evidence nodes

## Why This Works (Mechanism)

### Mechanism 1: Feature-to-Parameter Binding for Safety Case Instantiation
Mapping feature model variations to parameterized safety case nodes enables automated generation of flight-specific safety arguments. The feature model defines valid configurations (pilot, vehicle, weather, mission) and parameters in safety case Context and Evidence nodes are bound to feature values. Instance generator produces concrete safety case with values substituted. Core assumption: All safety-relevant variability can be captured as discrete features with enumerable values or ranges.

### Mechanism 2: Evidence Node Evaluation with Conservative Defaults
When manufacturer specifications lack explicit limits, assigning conservative default values enables the safety case to fail unsafe configurations. Missing vehicle specification (e.g., max wind speed) triggers system application of conservative default, which evidence node evaluates against current conditions to deny/recommend if exceeded. Core assumption: Conservative defaults provide adequate safety margins without being so restrictive they deny all flights.

### Mechanism 3: Traceable Evidence for Entry Decisions
Linking evidence nodes to goals via parameterized arguments enables transparent accept/deny decisions with failure localization. Safety case instance generated and each evidence node (E1-E6) evaluated against concrete inputs. If any node false, top-level goal unsatisfied with traceability to specific failure. Core assumption: Safety can be decomposed into discrete, independently verifiable evidence requirements.

## Foundational Learning

- **Software Product Line Engineering (SPLE)**: Core architectural pattern—understanding feature models, variability types (optional, alternative/XOR, OR), and cross-tree constraints is prerequisite to understanding how SafeSPLE scales safety cases.
  - Quick check: Given a feature model with an XOR group of three features, how many valid configurations exist for that group alone?

- **Goal Structuring Notation (GSN)**: Visual language for safety cases—understanding Goals (G), Strategies (S), Context (C), and Evidence (E) nodes and their hierarchy is required to read and construct parameterized safety cases.
  - Quick check: In GSN, what must be true of all child nodes for a Goal to be considered satisfied?

- **Hazard Analysis**: First step in SafeSPLE process—identifies safety-relevant conditions (wind, visibility, battery) and ensures feature model covers contributing factors and mitigations.
  - Quick check: What distinguishes a hazard (e.g., wind gusts exceed limits) from its consequence (e.g., loss of separation)?

## Architecture Onboarding

- **Component map**: Feature Model (FeatureIDE) -> Parameterized Safety Case (AdvoCATE) -> Instance Generator -> External Data Sources (Weather APIs, manufacturer spec DB, pilot registry)

- **Critical path**: 1. Hazard analysis → identify relevant features 2. Feature model construction with constraints 3. Parameterized safety case design 4. Feature-to-parameter mapping and equivalence class definition 5. Instance generation with evidence evaluation 6. Entry decision output

- **Design tradeoffs**: Closed Access (auto accept/deny) vs Open Access (safety case as pilot checklist); Conservative defaults (safer but restrictive) vs requiring complete specs (more flights but data burden); Real-time generation vs pre-computed partial instances (freshness vs latency)

- **Failure signatures**: Evidence node E4 false (wind gusts exceed vehicle limit) → deny or recommend alternative vehicle/time; Missing specification triggers default value → may fail if defaults are conservative; Feature model constraint violation → configuration invalid before safety case evaluation

- **First 3 experiments**: 1. Replicate DJI Mini 4 Pro instance with wind gusts at 6 m/s and verify all evidence nodes (E1-E6) evaluate true 2. Test boundary condition: same vehicle with wind gusts at exactly 10 m/s (max allowed) to confirm edge-case handling 3. Introduce vehicle with missing wind-speed specification and verify default (3 m/s) is applied and appropriate denial/recommendation occurs

## Open Questions the Paper Calls Out

### Open Question 1
How can "safe approximations" be formally defined for reuse when specific evidence or vehicle specifications are missing or incomplete? The case study uses ad-hoc defaults (e.g., setting max wind speed to 3 m/s for undocumented drones), but provides no generalized methodology or formal logic for deriving these safety margins.

### Open Question 2
Should the enforcement mechanism for the UTM system utilize a "Closed Access" (automated rejection) or "Open Access" (advisory) model? The paper demonstrates the ability to generate a safety case but does not evaluate the safety trade-offs or regulatory implications of automating the final entry decision versus leaving it to the pilot.

### Open Question 3
Can the generation of safety case instances be performed with sufficient speed to support real-time, on-entry decision making for a high volume of sUAS? The paper validates feasibility through a manual case study of two drones but does not measure the computational latency or throughput required for a live UTM system.

## Limitations
- Limited validation scope with only two specific vehicle instances under limited weather conditions
- Manual parameter mapping appears required, particularly for conservative default values
- Undisclosed feature model complexity makes independent verification difficult

## Confidence
- High confidence in the core SPLE-to-safety-case instantiation mechanism
- Medium confidence in conservative default strategy due to lack of empirical validation
- Medium confidence in traceability claims based on single case study

## Next Checks
1. Replicate the case study with boundary conditions (e.g., wind gusts exactly at max allowed limits) to verify edge-case handling
2. Test the system with a vehicle having missing specifications across multiple parameters to evaluate default application consistency
3. Generate multiple safety case instances varying one parameter at a time to confirm the feature-to-parameter binding correctly produces expected outcomes