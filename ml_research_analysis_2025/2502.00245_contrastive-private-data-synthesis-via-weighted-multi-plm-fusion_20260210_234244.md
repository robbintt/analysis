---
ver: rpa2
title: Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion
arxiv_id: '2502.00245'
source_url: https://arxiv.org/abs/2502.00245
tags:
- private
- samples
- data
- sample
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of generating high-quality, privacy-preserving
  synthetic datasets when only limited real data is available. It introduces WASP,
  a framework that uses weighted collaboration among multiple pre-trained language
  models (PLMs) guided by differentially private voting from real samples to improve
  data synthesis quality.
---

# Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion

## Quick Facts
- arXiv ID: 2502.00245
- Source URL: https://arxiv.org/abs/2502.00245
- Authors: Tianyuan Zou; Yang Liu; Peng Li; Yufei Xiong; Jianqing Zhang; Jingjing Liu; Xiaozhou Ye; Ye Ouyang; Ya-Qin Zhang
- Reference count: 40
- Primary result: WASP framework improves synthetic data quality under tight privacy budgets, achieving higher downstream accuracy and better distribution similarity than baselines.

## Executive Summary
This paper introduces WASP, a framework for generating high-quality, privacy-preserving synthetic datasets from limited private data. WASP employs a weighted ensemble of multiple pre-trained language models (PLMs) guided by differentially private voting from real samples. The framework uses Top-Q voting with decaying weights to estimate private data distributions more accurately, contrasts high- and low-quality synthetic samples via in-context learning prompts, and dynamically assigns importance weights to each PLM based on their contribution. Extensive experiments on 6 tasks with 9 PLMs demonstrate WASP consistently outperforms baselines like Aug-PE, Pre-Text, and FuseGen, achieving higher downstream model accuracy and better distribution similarity under tight privacy budgets, especially when private data is scarce.

## Method Summary
WASP generates synthetic data through an iterative process where multiple PLMs create samples weighted by their historical performance. Private samples vote for nearest and furthest synthetic samples using Top-Q voting with decaying weights, with Gaussian noise added for differential privacy. The voting results identify high-quality and low-quality samples, which are used as contrastive demonstrations in in-context learning prompts to guide the next generation. PLM weights are updated based on their generated samples' voting scores, creating a feedback loop that prioritizes better-performing models. The process repeats for T iterations to generate a final synthetic dataset for downstream training.

## Key Results
- WASP consistently outperforms baselines like Aug-PE, Pre-Text, and FuseGen across 6 tasks with 9 PLMs
- Achieves higher downstream BERT classifier accuracy and better FID scores under tight privacy budgets (ε=4.0, δ=10^-5)
- Dynamic PLM weighting and contrastive in-context learning contribute 2.27% and 1.56% accuracy improvements respectively on challenging tasks
- Top-Q voting with Q=8 shows diminishing returns beyond this point, indicating optimal neighborhood size for distribution estimation

## Why This Works (Mechanism)

### Mechanism 1: Top-Q Voting with Decaying Weights for Distribution Estimation
The framework extends voting from Top-1 to Top-Q with decaying weights (1, 1/2, 1/4, ...) to improve private distribution estimation when private samples are scarce. Each private sample votes for its Q nearest and Q furthest synthetic samples, extracting more ranking information while maintaining bounded sensitivity (Δ = 4) for Gaussian DP noise calibration. The relative distance ranking contains meaningful signal about distribution similarity that accumulates across multiple vote positions.

### Mechanism 2: Cross-PLM Contrastive In-Context Learning
WASP provides both high-quality (nearest) and low-quality (furthest) synthetic samples as contrastive demonstrations in prompts, reducing generation of noisy samples. The voting histograms identify these samples, which become instructions for PLMs to generate samples "further refined than good samples" while avoiding characteristics of bad samples. This approach leverages PLMs' ability to implicitly learn from contrastive examples without direct fine-tuning.

### Mechanism 3: Dynamic PLM Importance Weighting
Each PLM's weight w_k is computed as the average normalized histogram score of samples it generated. Higher weights result in larger generation quotas in subsequent iterations, creating positive feedback where better-performing PLMs contribute more. This weighting strategy improves ensemble output over equal weighting by consistently prioritizing PLMs that generate samples closer to the private distribution.

## Foundational Learning

- **Differential Privacy (Gaussian Mechanism):**
  - Why needed here: The framework relies on adding calibrated Gaussian noise to voting statistics to guarantee (ε, δ)-DP while extracting utility from private samples.
  - Quick check question: Given sensitivity Δ = 4, ε = 4.0, δ = 10^-5, and T = 5 iterations, can you derive the noise scale σ used per iteration?

- **In-Context Learning with Large Language Models:**
  - Why needed here: WASP uses PLMs as generators via prompting only (no fine-tuning). Understanding how demonstrations influence generation is critical for designing effective contrastive prompts.
  - Quick check question: What happens to generation quality if in-context examples are inconsistent with the target task distribution?

- **Embedding Space Distance Metrics (L2 Distance):**
  - Why needed here: Voting mechanism depends on computing pairwise distances between private and synthetic samples in embedding space to determine "nearest" and "furthest."
  - Quick check question: If the sentence embedding model φ fails to capture task-relevant semantic similarity, how would this manifest in WASP's outputs?

## Architecture Onboarding

- **Component map:** Private Data Holder -> Voting Module (DP) -> Sample Selector -> Prompt Constructor -> PLM Pool -> Weight Calculator -> STM Trainer
- **Critical path:** Iteration loop: Generate → Vote (DP) → Select → Weight → Prompt → Generate (repeat T times)
- **Design tradeoffs:** Higher Q improves distribution estimation but increases noise aggregation; more PLMs adds robustness but increases API cost; larger S enriches prompts but may dilute contrastive signal
- **Failure signatures:** FID increasing over iterations indicates voting selecting wrong samples; one PLM dominating weights suggests reward hacking; synthetic samples repeating prompt text indicates PLM not following instructions
- **First 3 experiments:** 1) Reproduce single-PLM Aug-PE baseline on IMDb with M = 100; 2) Add Top-Q voting (Q = 8) alone to verify FID decrease; 3) Full WASP with K = 3 PLMs to confirm dynamic weights stabilize and accuracy beats baselines

## Open Questions the Paper Calls Out
- Can WASP be effectively adapted for non-classification tasks such as text summarization or translation?
- Would a more granular, individual sample-level weighting mechanism further improve synthetic data quality compared to the current decaying Top-Q weights?
- How sensitive is WASP's performance to the specific choice of sentence embedding model used for voting and similarity calculations?
- Is the framework robust against malicious adversaries in the federated setting who manipulate their local voting histograms?

## Limitations
- The core novelty—DP-protected Top-Q voting with decaying weights—has limited external validation beyond WASP experiments
- Dynamic PLM weighting lacks comparison to simpler baselines like round-robin or random weighting
- The framework's effectiveness depends heavily on the quality of the embedding model and stability of distance rankings

## Confidence
- **High confidence:** Empirical superiority over baselines on downstream accuracy and FID metrics
- **Medium confidence:** Top-Q voting mechanism's effectiveness depends on embedding model quality
- **Low confidence:** Dynamic PLM weighting could be vulnerable to noise amplification in DP setting

## Next Checks
1. Ablation of PLM Weighting Strategy: Run WASP with static equal weights versus the proposed dynamic weighting to quantify the actual contribution of this mechanism
2. Embedding Model Sensitivity Analysis: Replace `sentence-t5-base` with alternative embedding models to assess whether WASP's gains are embedding-dependent
3. DP Noise Calibration Verification: Independently verify the Gaussian noise scale σ calculation and confirm that the sensitivity analysis correctly accounts for decaying weights in Top-Q voting across all 5 iterations