---
ver: rpa2
title: 'GFLC: Graph-based Fairness-aware Label Correction for Fair Classification'
arxiv_id: '2506.15620'
source_url: https://arxiv.org/abs/2506.15620
tags:
- noise
- label
- gflc
- fairness
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Graph-based Fairness-aware Label Correction
  (GFLC), a method that addresses label noise in fairness-sensitive datasets by integrating
  graph-based regularization with fairness constraints. GFLC constructs a k-NN graph
  from data features, applies Forman-Ricci curvature with discrete Ricci flow to optimize
  edge weights, and combines this with prediction confidence and demographic parity
  incentives.
---

# GFLC: Graph-based Fairness-aware Label Correction for Fair Classification

## Quick Facts
- arXiv ID: 2506.15620
- Source URL: https://arxiv.org/abs/2506.15620
- Reference count: 10
- One-line primary result: Achieves AUC scores of 0.874, 0.843, and 0.799 at 5%, 10%, and 20% noise rates respectively, outperforming Fair-OBNC baseline

## Executive Summary
GFLC addresses label noise in fairness-sensitive datasets by integrating graph-based regularization with fairness constraints. The method constructs a k-NN graph from data features, applies Forman-Ricci curvature with discrete Ricci flow to optimize edge weights, and combines this with prediction confidence and demographic parity incentives. Experiments on a bank account fraud dataset demonstrate GFLC achieves superior AUC scores and maintains demographic parity across varying noise levels, outperforming baseline Fair-OBNC while balancing performance and fairness in noisy, biased data scenarios.

## Method Summary
GFLC is a pre-processing method that corrects noisy labels in fairness-sensitive datasets through a three-stage process. First, it constructs a k-NN graph from data features and optimizes edge weights using Forman-Ricci curvature with discrete Ricci flow. Second, it trains a base classifier to generate prediction probabilities and calculates a combined correction score that balances prediction uncertainty (margin term), graph structural violation (Laplacian term), and fairness gain (fairness incentive). Third, it flips labels based on disparity tolerance constraints to ensure the corrected dataset satisfies demographic parity requirements, making the training data itself less biased before downstream model training.

## Key Results
- Achieves AUC scores of 0.874, 0.843, and 0.799 at 5%, 10%, and 20% noise rates respectively
- Maintains superior demographic parity ratios near 1.0 across all noise levels
- Outperforms Fair-OBNC baseline (0.813, 0.783, 0.752 AUC) at all noise rates
- Successfully balances performance and fairness in noisy, biased data scenarios

## Why This Works (Mechanism)

### Mechanism 1: Ricci Flow Optimizes Graph Structure for Noise Identification
Optimizing edge weights via discrete Ricci flow amplifies the signal for noisy labels by strengthening intra-community edges and weakening inter-community edges. The process identifies edges with positive curvature (strong local connectivity) and increases their weights, while reducing weights on edges with negative curvature (bottlenecks). This geometric refinement makes the graph Laplacian more sensitive to label disagreements that cross weak boundaries (likely noise) and less sensitive to label agreements within strong communities (likely correct).

### Mechanism 2: Combined Correction Score Prioritizes Fairness-Aware Corrections
A multi-component scoring function systematically identifies the most impactful labels to flip by balancing prediction uncertainty, graph structural violation, and fairness gain. The score combines three terms: margin term (identifies uncertain predictions), graph Laplacian term (identifies labels disagreeing with neighbors), and fairness incentive (identifies flips that improve demographic parity). This weighted combination (α=0.2, β=0.6, γ=0.2) ranks candidates for correction based on their potential to simultaneously reduce noise and improve fairness.

### Mechanism 3: Fairness-Preserving Label Flipping Logic
The final label flipping process is constrained to ensure the corrected dataset satisfies a specified disparity tolerance. The algorithm calculates minimum and maximum acceptable prevalence rates for positive labels across sensitive groups, determines the number of required flips for each group, and then flips labels of top-scoring candidates identified by the combined score. This ensures the corrected labels inherently satisfy the fairness constraint, making the training data itself less biased.

## Foundational Learning

- **Concept: Forman-Ricci Curvature on Graphs**
  - Why needed here: This is the core geometric tool GFLC uses to analyze the "shape" of the data graph. It's used to identify edges that connect different "communities" or clusters.
  - Quick check question: If an edge has negative Forman-Ricci curvature, what does that signify about its role in the graph? (Answer: It's likely a "bottleneck" or an inter-community edge).

- **Concept: The Graph Laplacian and Semi-Supervised Learning**
  - Why needed here: The paper uses the graph Laplacian as a regularizer to enforce smoothness. Understanding it is key to seeing how GFLC identifies "unusual" labels that disagree with their neighbors.
  - Quick check question: In the context of label noise, what does a high Laplacian value (L_i) for a node suggest about its label? (Answer: The node's label disagrees with most of its graph neighbors, suggesting it might be noisy).

- **Concept: Demographic Parity as a Fairness Metric**
  - Why needed here: The entire fairness incentive component of GFLC is built around optimizing for demographic parity. One must understand its definition and its limitations.
  - Quick check question: What does a demographic parity ratio of 1.0 indicate? (Answer: That the positive prediction rate is equal across all sensitive groups).

## Architecture Onboarding

- **Component map:** Input dataset -> k-NN Graph Builder -> Ricci Flow Optimizer -> Base Classifier -> Scorer -> Flip Selector -> Final Trainer
- **Critical path:** The Ricci Flow Optimizer -> Scorer -> Flip Selector chain is critical. If the graph optimization is poor, the Laplacian term in the score will be noisy, leading to suboptimal flip candidates.
- **Design tradeoffs:** 
  - Alpha, Beta, Gamma (Score Weights): The paper uses (0.2, 0.6, 0.2), heavily weighting the graph-based Laplacian term. The tradeoff is between trusting the graph structure vs. the base classifier's confidence vs. the fairness objective.
  - Ricci Iterations (ricci_iter): The paper uses 2. More iterations might over-smooth the graph or separate clusters too much. Fewer might not optimize edge weights enough.
  - Disparity Tolerance (D): A smaller D is "fairer" but may require more flips, potentially introducing more noise if the flip candidates are not ideal.
- **Failure signatures:**
  - Low AUC & Poor DP Ratio: The base classifier is too poor to generate useful margins, or the graph structure does not capture the true class clusters (making the Laplacian term misleading).
  - High AUC but Poor DP Ratio: The "fairness incentive" (γ) or the flip selector logic is failing to properly identify and flip the right candidates to achieve demographic parity.
  - Poor AUC but Good DP Ratio: The algorithm is likely flipping too many labels to satisfy the fairness constraint (D is too strict), or flipping incorrect labels, thereby corrupting the signal needed for the downstream model.
- **First 3 experiments:**
  1. Baseline Reproduction: Run GFLC on the Bank Account Fraud dataset with the same noise settings (5%, 10%, 20%) to reproduce the paper's AUC and DP ratio figures. Verify the baseline Fair-OBNC numbers are also reproduced.
  2. Ablation on Ricci Flow: Run GFLC without the Ricci flow optimization (i.e., using the initial k-NN weights for the Laplacian). Compare the AUC and DP ratio against the full GFLC. This validates the claim that Ricci flow is a critical component.
  3. Hyperparameter Sensitivity: Vary the score weights (α, β, γ) to see their effect. For example, increase γ to 0.4 and decrease β to 0.4. Does this improve the DP ratio further, and at what cost to AUC? This reveals the robustness of the scoring function.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does GFLC maintain its performance and fairness trade-offs in multi-class classification settings or domains with non-tabular data (e.g., images or text)?
- **Open Question 2:** Can the fairness incentive term be effectively reformulated to optimize for Equalized Odds or Equal Opportunity without losing the convergence stability provided by the Demographic Parity incentive?
- **Open Question 3:** How robust is the GFLC correction accuracy to the choice of k-NN graph density (k) and the weighting hyperparameters (α, β, γ)?
- **Open Question 4:** How does the computational complexity of the discrete Ricci flow update scale with dataset size compared to the baseline Fair-OBNC?

## Limitations

- Limited to binary classification and binary sensitive attributes, restricting applicability to multi-class fairness scenarios
- Lacks ablation studies to isolate contributions of individual components (Ricci flow, fairness incentive, margin term)
- Evaluation restricted to a single dataset (bank fraud), limiting generalizability across different domains and noise patterns

## Confidence

- **High Confidence:** The core mechanism of combining prediction uncertainty, graph structure violation, and fairness gain into a correction score is technically sound and well-implemented
- **Medium Confidence:** The effectiveness of discrete Ricci flow for label noise correction in fairness contexts is supported by the experimental results but lacks broader validation across datasets
- **Low Confidence:** The specific weight parameters (α=0.2, β=0.6, γ=0.2) for the correction score are not theoretically justified and may not generalize well to other problem settings

## Next Checks

1. **Ablation Study:** Implement and evaluate GFLC variants without Ricci flow optimization and without the fairness incentive term to quantify their individual contributions to performance gains
2. **Cross-Dataset Evaluation:** Test GFLC on additional fairness-sensitive datasets (e.g., COMPAS, Adult Income) with varying noise patterns and multi-class sensitive attributes to assess generalizability
3. **Weight Sensitivity Analysis:** Systematically vary the correction score weights (α, β, γ) across a grid and evaluate the trade-offs between AUC and demographic parity to identify robust parameter settings