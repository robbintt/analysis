---
ver: rpa2
title: 'From Linear Input to Hierarchical Structure: Function Words as Statistical
  Cues for Language Learning'
arxiv_id: '2601.21191'
source_url: https://arxiv.org/abs/2601.21191
tags:
- function
- words
- language
- learning
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates the role of function words in language
  learning, focusing on three key distributional properties: high lexical frequency,
  reliable structural association, and alignment with phrase boundaries. Through cross-linguistic
  corpus analysis of 186 languages and computational experiments with transformer
  models, the authors demonstrate that all three properties are robust across languages.'
---

# From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning

## Quick Facts
- arXiv ID: 2601.21191
- Source URL: https://arxiv.org/abs/2601.21191
- Authors: Xiulin Yang; Heidi Getz; Ethan Gotlieb Wilcox
- Reference count: 25
- Primary result: Function words' distributional properties (frequency, structural association, boundary alignment) robustly support language learning across 186 languages, with frequency and structural association being more influential than boundary alignment for grammatical acquisition.

## Executive Summary
This study investigates how function words—grammatical markers like determiners and prepositions—serve as statistical cues that help learners extract hierarchical structure from linear language input. Through cross-linguistic corpus analysis of 186 languages and computational experiments with transformer models, the authors demonstrate that function words are consistently more frequent, exhibit lower syntactic dependency entropy, and align more often with phrase boundaries than content words. Counterfactual language modeling and ablation experiments reveal that these properties contribute differently to learnability, with frequency and structural association being more influential than boundary alignment. The results suggest that language learners can exploit multiple complementary cues from function words to bootstrap grammatical knowledge.

## Method Summary
The study employs a two-part methodology: first, a cross-linguistic corpus analysis using Universal Dependencies treebanks from 186 languages to establish three key distributional properties of function words; second, counterfactual language modeling with GPT-2 Small trained on manipulated English Wikipedia text (89M words). The manipulations systematically alter natural language properties—removing function words, reducing their inventory, expanding it with pseudowords, randomizing dependencies, or displacing them from boundaries—to establish causal relationships between these properties and grammatical learning. Models are evaluated on BLiMP benchmark (filtered to exclude function-word-critical phenomena) and analyzed through attention probing and ablation studies to understand internal mechanisms.

## Key Results
- Function words are consistently more frequent than content words across all 186 languages analyzed
- Function words exhibit lower syntactic dependency entropy than content words, indicating more reliable structural associations
- Function words align with phrase boundaries at significantly higher rates (median 0.95) than content words (median 0.58)
- Counterfactual manipulations show that frequency and structural association properties are more critical for learnability than boundary alignment
- Attention probing reveals distinct internal mechanisms for function word representation across different learning conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High lexical frequency of function words may serve as a statistical anchor that makes grammatical cues trackable during learning.
- Mechanism: Function words occupy a small inventory of types but account for disproportionately large token counts, creating reliable statistical landmarks in the input stream.
- Core assumption: Neural learners benefit from having a small set of high-frequency items to track, as posited by the Marker Hypothesis.
- Evidence anchors:
  - [abstract]: "function words are more frequent than content words"
  - [section]: Cross-linguistic analysis across 186 languages shows function words cluster above the diagonal (small type ratio, large token ratio) while content words fall below.
  - [corpus]: Vocabulary embeddings work suggests structure emerges early in training, which may relate to frequency-driven organization.
- Break condition: The Goldilocks effect—too few function word types (FIVEFUNCTION) reduces distinctiveness; too many types (MOREFUNCTION) dilutes per-type frequency. Both degrade learning.

### Mechanism 2
- Claim: Reliable structural association between function words and syntactic contexts may support grammatical categorization and labeling.
- Mechanism: Function words exhibit lower syntactic dependency entropy than content words, meaning they connect to restricted sets of grammatical categories, making them predictable structural signals.
- Core assumption: Learners can exploit co-occurrence statistics to infer grammatical categories, consistent with Frequent Frames theory.
- Evidence anchors:
  - [abstract]: "exhibit lower entropy in their syntactic dependencies"
  - [section]: Entropy analysis (Equation 1-2) shows function-word dependency entropy is consistently lower than content-word entropy across languages.
  - [corpus]: Weak direct corpus evidence on entropy-learnability links; related work on hierarchical function learning remains theoretical.
- Break condition: RANDOMDEP condition (shuffling function word identities) destroys structural association and degrades BLiMP performance by 6.6 percentage points.

### Mechanism 3
- Claim: Alignment with phrase boundaries may provide segmentation cues that help learners identify constituent structure from linear input.
- Mechanism: Function words appear at phrase peripheries (median boundary rate 0.95 vs. 0.58 for content words), marking where constituents begin or end.
- Core assumption: Positional regularities can bootstrap constituent segmentation, consistent with the Anchoring Hypothesis.
- Evidence anchors:
  - [abstract]: "align more often with phrase boundaries"
  - [section]: Boundary analysis using UD dependency subtrees shows strong cross-linguistic alignment; WITHINBOUNDARY manipulation displaces 55% of function words.
  - [corpus]: Limited direct corpus evidence on boundary-driven learning; related work focuses on frequency rather than positional cues.
- Break condition: WITHINBOUNDARY condition shows only -1.6 percentage point drop (not statistically significant, p=0.08), suggesting this mechanism may be partially redundant with other cues.

## Foundational Learning

- Concept: **Function vs. content word distinction**
  - Why needed here: The entire experimental design depends on categorizing words as function (closed-class: DET, ADP, CCONJ, SCONJ, AUX) vs. content (open-class).
  - Quick check question: Can you explain why pronouns were excluded from the function word inventory?

- Concept: **Counterfactual language modeling**
  - Why needed here: The methodology systematically manipulates natural language properties to establish causality rather than correlation.
  - Quick check question: Why is perplexity an invalid metric for comparing models trained on different manipulations?

- Concept: **Attention probing in transformers**
  - Why needed here: Section 6 relies on probing attention heads to infer whether models have learned specialized function-word representations.
  - Quick check question: How does the function attention score (Equation 4) quantify a head's specialization for function words?

## Architecture Onboarding

- Component map:
  - Corpus: Wikipedia (89M words), manipulated via Stanza for POS/dependency parsing
  - Model: GPT-2 Small (12 layers, 12 heads), trained from scratch with condition-specific tokenizers
  - Evaluation: BLiMP minimal pairs, filtered to remove function-word-critical phenomena
  - Analysis: Attention probing + function-word ablation (masking/deletion)

- Critical path:
  1. Define function word inventory (116 English items from GUM/EWT)
  2. Apply manipulation (e.g., MOREFUNCTION expands to ~1.2k pseudowords via Wuggy)
  3. Train tokenizer on manipulated corpus
  4. Train GPT-2 for 10 epochs, 3 seeds
  5. Evaluate on filtered BLiMP
  6. Probe attention patterns; run ablation studies

- Design tradeoffs:
  - Wikipedia vs. BabyLM: Wikipedia provides longer sentences (25.3 vs. 14.8 tokens) and richer phrase structure, enabling meaningful WITHINBOUNDARY manipulation
  - Dependency vs. constituency parsing: UD used for scale (186 languages) despite imperfect constituency approximation
  - Excluding pronouns/numerals: Reduces confounds from argument structure and semantic content

- Failure signatures:
  - Perplexity comparisons across conditions are invalid (different corpus entropies)
  - BLiMP categories where function words are diagnostic must be excluded (13 subcategories removed)
  - Performance ≠ mechanism: NATURALFUNCTION and WITHINBOUNDARY show similar BLiMP scores but different attention patterns

- First 3 experiments:
  1. Replicate the cross-linguistic analysis on a subset of UD languages to verify the three properties hold for your target languages
  2. Train models on NOFUNCTION vs. NATURALFUNCTION to establish baseline learnability difference
  3. Run attention probing on a trained model to identify which heads attend to function words, then ablate those heads to confirm causal role

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do function word properties contribute equally to learnability in languages with diverse typological features, such as free word order or rich morphology?
- Basis in paper: [explicit] The authors state in the Limitations section that "testing whether the absolute magnitude of these effects varies with language-specific factors (e.g., word order, morphological richness) remains an important direction for future work."
- Why unresolved: The computational modeling experiments were restricted to English due to the need for high-quality dependency parsing and standardized benchmarks, while the cross-linguistic analysis only established the presence of properties, not their functional weight.
- What evidence would resolve it: Running the counterfactual language modeling and ablation experiments on non-English corpora with significantly different syntactic structures (e.g., agglutinative or polysynthetic languages).

### Open Question 2
- Question: Can bound grammatical morphemes serve as effective cues for syntactic learning in the same way as free function words?
- Basis in paper: [explicit] The paper notes that the focus was on word-level categories and acknowledges that "investigating whether and how such morphological markers support syntactic learning and inference would be an important extension of the present study."
- Why unresolved: The current methodology relies on identifiable free function words (e.g., determiners, adpositions) and excludes bound morphemes, which perform similar functions in many languages.
- What evidence would resolve it: Adapting the counterfactual manipulations to operate on sub-word morphological units in languages like Turkish or Finnish and observing the resulting model performance.

### Open Question 3
- Question: Does the presence of prosodic cues in speech input alter the hierarchy of importance among frequency, structural association, and boundary alignment?
- Basis in paper: [explicit] The authors identify the exclusive use of written text as a limitation, writing, "It remains to be seen whether the same patterns hold when models are trained on speech input, where prosodic information may provide additional structural cues."
- Why unresolved: Function words often carry distinct prosodic signatures (reduced stress) in spoken language, which were absent in the text-based Wikipedia training data used here.
- What evidence would resolve it: Replicating the training regimes using speech-based models or multimodal inputs where prosody is preserved alongside the text.

## Limitations

- The exclusion of pronouns from function words creates a critical boundary condition that is not empirically justified beyond avoiding semantic confounds
- The reliance on dependency parsing to approximate constituency structure for boundary analysis introduces potential noise, as these formalisms do not always align
- The causal claims depend on counterfactual manipulations that may not fully capture the complexity of natural language learning

## Confidence

- **High confidence**: The core empirical findings about distributional properties (frequency, entropy, boundary alignment) across languages are robust, as they derive from large-scale corpus analysis with clear quantitative metrics
- **Medium confidence**: The causal claims about learnability effects are supported by controlled experiments but depend on the validity of the counterfactual manipulation framework and the assumption that BLiMP accuracy reflects genuine grammatical learning
- **Low confidence**: The mechanistic interpretations of attention probing results are speculative, as probing reveals correlations in representations rather than establishing causal necessity or sufficiency

## Next Checks

1. **Boundary approximation validation**: Select 10 UD treebanks representing diverse language families and manually verify the accuracy of the dependency-to-constituency boundary mapping against gold constituency annotations, quantifying the error rate in the WITHINBOUNDARY manipulation

2. **Pronoun inclusion impact**: Repeat the core language modeling experiments with pronouns included in the function word inventory (maintaining the 116-word total count by removing an equivalent number of other function words) to test whether the exclusion materially affects the frequency-structural association trade-off

3. **Alternative probing methods**: Apply diagnostic classifiers and direct logit attribution methods alongside attention probing to cross-validate whether function words exhibit specialized representations, and whether the identified attention heads are causally necessary for the observed BLiMP performance differences