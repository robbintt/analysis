---
ver: rpa2
title: Explainable AI (XAI) for Arrhythmia detection from electrocardiograms
arxiv_id: '2508.17294'
source_url: https://arxiv.org/abs/2508.17294
tags:
- arrhythmia
- dataset
- figure
- detection
- beat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates explainable AI (XAI) methods for arrhythmia
  detection from electrocardiogram (ECG) signals using deep learning. A convolutional
  neural network was developed for arrhythmia classification using R-peak-based segmentation
  via the Pan-Tompkins algorithm on the MIT-BIH dataset.
---

# Explainable AI (XAI) for Arrhythmia detection from electrocardiograms

## Quick Facts
- arXiv ID: 2508.17294
- Source URL: https://arxiv.org/abs/2508.17294
- Reference count: 29
- CNN achieves 98.3% validation accuracy on MIT-BIH arrhythmia dataset

## Executive Summary
This study develops a convolutional neural network for arrhythmia detection from ECG signals and evaluates multiple explainable AI methods to make the model's decisions interpretable to medical professionals. The research addresses the critical challenge of understanding deep learning predictions in clinical settings by comparing different XAI techniques including saliency maps and SHAP-based approaches. Medical professionals showed preference for saliency map explanations over counterfactual visualizations, highlighting the importance of clinical intuition in XAI method selection.

## Method Summary
The research employs a CNN architecture trained on ECG signals processed through R-peak-based segmentation using the Pan-Tompkins algorithm on the MIT-BIH arrhythmia database. To address class imbalance, an additional 12-lead ECG dataset was incorporated. The study evaluates four SHAP-based XAI approaches (permutation importance, KernelSHAP, gradient-based methods, and DeepLIFT) alongside saliency maps. Medical professional feedback guides the assessment of explanation effectiveness, with preference given to methods that highlight waveform regions consistent with clinical reasoning. The model achieves high accuracy on the original dataset but shows performance degradation when combining datasets.

## Key Results
- CNN achieves 98.3% validation accuracy on MIT-BIH dataset but performance degrades on combined dataset
- Medical professionals prefer saliency map-based explanations over counterfactual visualizations
- SHAP-based methods show varying effectiveness: permutation importance and KernelSHAP produce cluttered outputs, while gradient-based methods and DeepLIFT highlight clinically relevant waveform regions
- Findings emphasize need for domain-specific XAI adaptations for medical applications

## Why This Works (Mechanism)
The CNN effectively learns spatial patterns in ECG waveforms through convolutional layers that extract hierarchical features from segmented R-peaks. The Pan-Tompkins algorithm provides consistent beat segmentation, creating uniform input for the CNN. XAI methods like saliency maps and SHAP-based approaches reveal which waveform regions contribute most to predictions by computing gradients or feature importance scores. Medical professionals' preference for saliency maps likely stems from their intuitive visual representation of decision boundaries aligned with clinical pattern recognition.

## Foundational Learning
- **R-peak segmentation via Pan-Tompkins algorithm** - needed for consistent beat extraction across variable ECG signals; quick check: verify QRS detection accuracy on MIT-BIH validation set
- **CNN feature hierarchy extraction** - needed for learning hierarchical temporal patterns in ECG waveforms; quick check: examine activation maps for early/late convolutional layer responses
- **SHAP explanation methods** - needed for attributing model decisions to specific input features; quick check: validate SHAP values against known arrhythmia markers
- **Saliency mapping techniques** - needed for visualizing gradient-based feature importance; quick check: ensure gradient computations are stable across multiple forward passes
- **Class imbalance handling** - needed for robust model training on medical datasets; quick check: monitor per-class precision/recall during training
- **Medical expert validation** - needed for clinically meaningful XAI assessment; quick check: document specific criteria used by clinicians for explanation preference

## Architecture Onboarding

**Component Map**
Raw ECG -> Pan-Tompkins R-peak detection -> Signal segmentation -> CNN feature extraction -> Classification -> XAI explanation generation

**Critical Path**
ECG signal preprocessing (Pan-Tompkins) → CNN training on segmented beats → XAI method application → Medical expert validation

**Design Tradeoffs**
CNN depth vs. interpretability: deeper networks may improve accuracy but reduce explanation clarity
Dataset size vs. model generalization: combining datasets improves coverage but introduces heterogeneity
Real-time vs. post-hoc explanations: saliency maps offer faster computation than full SHAP analyses

**Failure Signatures**
Performance degradation on combined datasets suggests sensitivity to acquisition protocol differences
Cluttered SHAP outputs indicate feature correlation issues or insufficient model interpretability
Medical professional disagreement on explanations may reveal gaps between model reasoning and clinical knowledge

**First Experiments**
1. Ablation study removing secondary dataset to isolate performance degradation causes
2. Quantitative comparison of XAI methods using region overlap with clinical annotations
3. Cross-dataset validation with independent ECG acquisition protocols

## Open Questions the Paper Calls Out
None

## Limitations
- Performance degradation when incorporating additional 12-lead ECG dataset raises concerns about model robustness to dataset heterogeneity
- Medical professional preference for XAI methods lacks quantitative validation methodology and statistical significance assessment
- SHAP method comparisons rely primarily on visual inspection rather than systematic quantitative metrics

## Confidence
- High Confidence: CNN architecture development and validation on MIT-BIH dataset (98.3% accuracy)
- Medium Confidence: XAI method comparison and preference for saliency maps requiring more rigorous validation
- Medium Confidence: Findings about waveform highlighting consistency with clinical reasoning based on qualitative expert assessment

## Next Checks
1. Conduct systematic ablation studies to identify whether performance degradation stems from specific dataset characteristics or architectural limitations in handling multimodal ECG inputs

2. Implement quantitative metrics for XAI method evaluation including region overlap with clinically annotated arrhythmia markers and computational efficiency measurements

3. Perform cross-validation using independent ECG datasets with different acquisition protocols to assess model generalization