---
ver: rpa2
title: 'VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion
  Manipulation'
arxiv_id: '2505.09577'
source_url: https://arxiv.org/abs/2505.09577
tags:
- vtla
- arxiv
- tactile
- manipulation
- insertion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents VTLA, a vision-tactile-language-action model
  designed for contact-rich robotic manipulation tasks like peg-in-hole insertion.
  The authors address the challenge of integrating visual and tactile sensing in language-conditioned
  robotic control, where traditional vision-language models struggle due to lack of
  tactile feedback and limited temporal reasoning.
---

# VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation

## Quick Facts
- arXiv ID: 2505.09577
- Source URL: https://arxiv.org/abs/2505.09577
- Reference count: 40
- Achieves over 90% success rates on unseen peg shapes with vision-tactile-language integration

## Executive Summary
This paper presents VTLA, a multi-modal model that integrates vision, tactile sensing, and language instructions for contact-rich robotic insertion tasks. The authors address the challenge of combining visual and tactile feedback in language-conditioned robotic control, where traditional vision-language models struggle due to lack of tactile sensing and limited temporal reasoning. By introducing Vision-Guided Temporally Enhanced Tokens (VGTE) and Direct Preference Optimization (DPO), VTLA achieves exceptional performance on peg-in-hole insertion tasks, with over 95% success rates in real-world experiments across various clearances and geometric configurations.

## Method Summary
VTLA uses a Qwen2-VL (7B) LLM as the backbone, augmented with specialized adapters for processing vision-tactile-action-instruction sequences. The model employs VGTE tokens that prioritize visual information by positioning visual tokens adjacent to action tokens before tokenization, improving cross-modal temporal reasoning. A ViT encoder processes 4-frame tactile sequences to create temporally-aware tactile tokens. The model uses Direct Preference Optimization to provide regression-like supervision for continuous control tasks, bridging the gap between classification-based next token prediction and continuous robotic control. The entire system is trained on a synthetic dataset of 28,000 vision-tactile-action-instruction pairs collected in simulation with domain randomization for real-world transfer.

## Key Results
- VTLA achieves over 90% success rates on unseen peg shapes, outperforming traditional imitation learning methods and multi-modal baselines
- Real-world insertion experiments demonstrate over 95% success rates across various peg-hole clearances and geometric configurations
- The model excels under challenging conditions like poor lighting, where tactile feedback becomes crucial for successful manipulation
- Ablation studies show VGTE and DPO contributions of 8% and 16% improvement in geometric clearance rate respectively

## Why This Works (Mechanism)

### Mechanism 1: Vision-Guided Temporally Enhanced Tokens (VGTE)
Positioning visual tokens adjacent to action tokens and pre-fusing temporal tactile data mitigates the LLM's limited temporal reasoning and recency bias. The architecture processes tactile image sequences through a ViT to create temporally-aware tokens, sequencing inputs as `[Tactile, Vision, Instruction]` rather than `[Vision, Tactile...]`. By placing vision closer to the action prediction output, the model prioritizes visual priors for the immediate next step, countering the tendency of LLMs to focus on the most recent tokens.

### Mechanism 2: Direct Preference Optimization (DPO) for Continuous Control
DPO provides regression-like supervision for action prediction, bridging the gap between discrete token classification and continuous robotic control. Standard Next Token Prediction uses cross-entropy loss, which treats action values as discrete classes. VTLA uses DPO to rank generated action predictions, creating a preference dataset where actions closer to ground truth are "chosen" and further ones are "rejected," allowing the model to learn the ordinal nature of continuous values.

### Mechanism 3: Cross-Modal Tactile Grounding for Contact States
Integrating tactile signals enables the policy to maintain performance when visual data is degraded or ambiguous during contact-rich phases. Visual modality handles global alignment (approaching the hole), while tactile modality detects local contact geometry (collision/slippage) that vision often misses due to occlusion or lighting. The model fuses these in the LLM latent space, allowing language-conditioned reasoning to switch reliance based on context.

## Foundational Learning

- **Concept: Next Token Prediction (NTP) vs. Regression**
  - Why needed here: VTLA frames continuous control as a language modeling problem. Standard NTP (classification) fails to capture the "closeness" of continuous action values.
  - Quick check question: Can you explain why Cross-Entropy loss treats the difference between action tokens `[0.1]` and `[0.9]` the same as `[0.1]` and `[0.2]`?

- **Concept: Recency Bias in Transformer Context Windows**
  - Why needed here: The paper's VGTE mechanism is a specific architectural fix for this general LLM property. Models pay more attention to tokens immediately preceding the prediction.
  - Quick check question: How does the input sequence order `[Tactile, Vision, Instruction] -> Action` differ from standard VLA prompts, and why does the author argue this improves insertion performance?

- **Concept: Domain Randomization for Sim2Real**
  - Why needed here: The model is trained purely in simulation but deploys on a physical UR3 robot. Understanding what parameters are randomized is critical to diagnosing real-world failures.
  - Quick check question: If a real-world peg has a significantly higher friction coefficient than the simulation's randomization range, what failure mode would you expect?

## Architecture Onboarding

- **Component map:** Wrist RGB Camera -> Vision Encoder -> Vision Tokens -> LLM; Fingertip Tactile Sensors (4-frame) -> ViT Encoder -> Tactile Tokens -> LLM; Text Instruction -> LLM; LLM -> Action String `[dx, dy, drz]`

- **Critical path:** 1) Construct 2x2 tactile grid from 4-frame history; 2) Concatenate Tokens in order: `[Tactile_Tokens] + [Vision_Tokens] + [Text_Tokens]`; 3) LLM generates action string `[dx, dy, drz]`

- **Design tradeoffs:** Uses only 28k simulation samples (low cost) vs. real-world collection; Prioritizes visual immediacy (VGTE) over chronological input; Sacrifices simplicity of pure NTP for complexity of building preference dataset (DPO)

- **Failure signatures:** Sim2Real Tactile Drift (policy acts "blind" to collisions); Recency Bias Failure (modified prompt order degrades performance); DPO Overfitting (model collapses to mean action)

- **First 3 experiments:** 1) Input Ablation: Run inference with `[Zeroed_Tactile]` vs `[Zeroed_Vision]` inputs on 0.6mm clearance task; 2) VGTE Order Swap: Reorder input tokens to standard `[Vision, Tactile, Text]` and compare success rates; 3) DPO Scaling: Train two models, one with 100 preference pairs and one with 2,400, to verify plateau effect

## Open Questions the Paper Calls Out

1. Can dedicated tactile-language alignment methods significantly outperform off-the-shelf vision encoders for representing tactile inputs in contact-rich manipulation tasks?
2. Does increasing diversity in preference data composition yield more performance gains than simply scaling preference dataset size for DPO in robotic control tasks?
3. Can advanced Sim2Real transfer methods enable the VTLA framework to handle more challenging insertion tasks beyond peg-in-hole scenarios?

## Limitations

- The model is evaluated only on peg-in-hole insertion tasks, limiting understanding of generalization to other contact-rich manipulation scenarios
- Relies exclusively on simulation data despite achieving strong real-world performance, raising questions about scalability to more complex tasks
- Uses off-the-shelf vision encoders for tactile inputs, potentially missing unique features inherent in the tactile modality

## Confidence

**High Confidence:** The VTLA architecture successfully integrates vision, tactile, and language modalities for insertion tasks; the model achieves superior performance compared to VLA and TLA baselines; real-world deployment demonstrates effective Sim2Real transfer

**Medium Confidence:** The VGTE token ordering specifically addresses transformer recency bias in insertion tasks; Direct Preference Optimization provides meaningful regression-like supervision for continuous control; tactile feedback is the primary factor enabling performance under poor lighting conditions

**Low Confidence:** The 28,000 sample dataset size is sufficient for robust generalization across all peg geometries; the preference optimization approach scales effectively to more complex manipulation tasks; the model's language understanding capabilities extend beyond the specific insertion instructions tested

## Next Checks

1. **Cross-Sensor Generalization Test:** Evaluate VTLA performance using a different tactile sensor configuration (e.g., different taxel count or spatial arrangement) to verify the model's robustness to tactile sensor hardware variations beyond the domain randomization ranges used in simulation.

2. **Multi-Stage Task Extension:** Test the model on sequential insertion tasks requiring multiple coordinated actions (e.g., pick-peg-align-insert) to assess whether the temporal reasoning capabilities extend beyond single-step predictions and whether memory limitations emerge in longer horizon tasks.

3. **Preference Dataset Ablation Study:** Systematically vary the quality and diversity of the DPO preference dataset (e.g., by filtering out similar action pairs, introducing synthetic noise, or using human preferences) to quantify the sensitivity of the final performance to preference dataset characteristics and identify potential failure modes in the preference optimization process.