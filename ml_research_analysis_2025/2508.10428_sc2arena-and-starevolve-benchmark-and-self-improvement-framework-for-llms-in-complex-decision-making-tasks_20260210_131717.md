---
ver: rpa2
title: 'SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs
  in Complex Decision-Making Tasks'
arxiv_id: '2508.10428'
source_url: https://arxiv.org/abs/2508.10428
tags:
- units
- unit
- action
- target
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SC2Arena, a comprehensive StarCraft II benchmark
  for evaluating LLM agents in complex decision-making, supporting full-length game
  contexts, all three races, complete low-level action spaces, and agent-vs-agent
  gameplay. To address text-based spatial reasoning challenges, SC2Arena optimizes
  observations using proximity-based unit ordering and worker aggregation.
---

# SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks

## Quick Facts
- arXiv ID: 2508.10428
- Source URL: https://arxiv.org/abs/2508.10428
- Reference count: 40
- Primary result: SC2Arena benchmark with StarEvolve framework achieves competitive Elo ratings (up to 1211) and high win rates (up to 95%) against StarCraft II built-in AI

## Executive Summary
This paper introduces SC2Arena, a comprehensive StarCraft II benchmark designed to evaluate LLM agents in complex decision-making tasks. The framework addresses challenges in text-based spatial reasoning through optimized observations using proximity-based unit ordering and worker aggregation. Alongside SC2Arena, the authors propose StarEvolve, a hierarchical framework that integrates strategic planning with tactical execution via a Planner-Executor-Verifier architecture. The system enables iterative self-correction and continuous improvement through fine-tuning on high-quality gameplay data. Experimental results demonstrate that StarEvolve enables smaller LLMs to perform competitively, achieving Elo ratings up to 1211 and win rates up to 95% against challenging built-in AI opponents.

## Method Summary
SC2Arena provides a full-featured benchmark supporting all three StarCraft II races, complete low-level action spaces, and agent-vs-agent gameplay with full-length game contexts. To optimize text-based spatial reasoning, the system implements proximity-based unit ordering and worker aggregation in observations. StarEvolve operates as a hierarchical framework with three core components: a Planner for high-level strategy formulation, an Executor for tactical implementation, and a Verifier for quality assessment. The framework employs iterative self-correction cycles and continuous improvement through fine-tuning on gameplay data. This architecture allows LLMs to break down complex game states into manageable sub-tasks while maintaining strategic coherence throughout gameplay.

## Key Results
- StarEvolve achieves Elo ratings up to 1211 against StarCraft II built-in AI
- Win rates reach up to 95% in competitive scenarios
- Smaller LLMs demonstrate competitive performance through the framework's hierarchical approach
- Ablation studies confirm critical importance of optimized observations, self-correction mechanisms, and strategic planning components

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental challenge of spatial reasoning in text-based environments through systematic observation optimization. Proximity-based unit ordering reduces the cognitive load on LLMs by presenting information in a spatially intuitive manner, while worker aggregation prevents information overload from large numbers of similar units. The hierarchical architecture mirrors human decision-making patterns, where high-level strategic goals guide tactical execution while continuous verification ensures quality control. Iterative self-correction allows the system to learn from mistakes and refine strategies over time, creating a feedback loop that drives continuous improvement through fine-tuning on successful gameplay patterns.

## Foundational Learning

**Spatial Reasoning Optimization**
- Why needed: Text-based environments struggle to convey spatial relationships effectively to LLMs
- Quick check: Compare unit ordering methods and their impact on decision accuracy

**Hierarchical Decision Making**
- Why needed: Complex tasks require decomposition into manageable sub-tasks while maintaining strategic coherence
- Quick check: Evaluate performance with and without hierarchical structure

**Iterative Self-Correction**
- Why needed: Enables continuous learning and strategy refinement without external intervention
- Quick check: Measure improvement rates with varying self-correction frequencies

**Action Space Management**
- Why needed: Complete low-level action spaces can overwhelm LLMs without proper abstraction
- Quick check: Assess impact of action space granularity on decision quality

## Architecture Onboarding

**Component Map**
Planner -> Executor -> Verifier -> (Feedback to Planner/Executor)

**Critical Path**
Strategy formulation (Planner) → Tactical execution (Executor) → Outcome verification (Verifier) → Self-correction → Strategy refinement

**Design Tradeoffs**
The framework balances between strategic depth and tactical precision, choosing hierarchical decomposition over monolithic decision-making. This introduces some latency in decision-making but enables better handling of complex scenarios. The observation optimization trades some raw information for improved spatial reasoning efficiency.

**Failure Signatures**
Common failures include strategic tunnel vision where the Planner becomes overly focused on specific tactics, execution drift where the Executor deviates from planned strategies, and verification paralysis where the Verifier over-analyzes decisions leading to delays.

**First Experiments**
1. Run baseline tests with unoptimized observations to quantify the impact of spatial reasoning improvements
2. Compare hierarchical vs. flat decision-making architectures on simple scenarios
3. Test self-correction frequency optimization by varying the number of correction cycles per game

## Open Questions the Paper Calls Out
None

## Limitations
- Results only validated against StarCraft II built-in AI, not human players or external competitive benchmarks
- Elo ratings achieved may not translate to broader strategic reasoning capabilities outside the specific game environment
- Limited exploration of framework scalability across different LLM sizes and architectures

## Confidence

**High Confidence**
- Technical implementation of SC2Arena's observation optimization
- Hierarchical StarEvolve framework architecture

**Medium Confidence**
- Empirical performance results against built-in AI
- Ablation study findings on component importance

**Low Confidence**
- Claims about general strategic reasoning capabilities transferable to other domains
- Long-term self-improvement potential beyond the tested environment

## Next Checks
1. Test StarEvolve against human opponents or established StarCraft II bots (like DeepMind's AlphaStar) to validate competitive performance claims
2. Evaluate the transferability of learned strategies by testing models on related RTS games or modified SC2 scenarios
3. Conduct ablation studies with different LLM sizes and architectures to better understand the framework's scalability and limitations