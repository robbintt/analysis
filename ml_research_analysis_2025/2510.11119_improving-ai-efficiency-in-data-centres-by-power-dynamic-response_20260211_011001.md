---
ver: rpa2
title: Improving AI Efficiency in Data Centres by Power Dynamic Response
arxiv_id: '2510.11119'
source_url: https://arxiv.org/abs/2510.11119
tags:
- power
- data
- centres
- energy
- would
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the power management challenge in AI data\
  \ centres, where high computational intensity and unpredictable workloads cause\
  \ power fluctuations that lead to service disruptions, oversizing of infrastructure,\
  \ and increased environmental impact. The core method introduces dynamic power response\
  \ systems\u2014both passive (capacitors, supercapacitors) and active (battery energy\
  \ storage systems)\u2014to absorb sudden power spikes and smooth out demand."
---

# Improving AI Efficiency in Data Centres by Power Dynamic Response

## Quick Facts
- **arXiv ID**: 2510.11119
- **Source URL**: https://arxiv.org/abs/2510.11119
- **Reference count**: 40
- **Primary result**: Active dynamic power response systems improve AI data center efficiency by eliminating dummy loads, increasing computational gain by 100%, and reducing CAPEX by 55%

## Executive Summary
This paper addresses the challenge of power management in AI data centers, where high computational intensity and unpredictable workloads cause power fluctuations that lead to service disruptions and infrastructure oversizing. The authors introduce dynamic power response systems—both passive (capacitors, supercapacitors) and active (battery energy storage systems)—to absorb sudden power spikes and smooth out demand. Analysis shows that over 85% of spikes last less than 100 milliseconds and contain 5-100 joules of energy, but their cumulative effect across thousands of racks is significant. Results demonstrate that active solutions eliminate the need for dummy loads, improve computational gain by 100%, reduce CAPEX by 55%, and lower management costs, while passive solutions offer limited improvements and still require dummy loads.

## Method Summary
The method introduces dynamic power response systems to manage power fluctuations in AI data centers. Active solutions use battery energy storage systems (BESS) that can track high-frequency variations while supporting large capacitance for energy storage. Passive solutions employ capacitors and supercapacitors for shorter-duration spikes. The approach involves characterizing spike distributions, sizing BESS to cover peak spike energy, validating response latency, and integrating control signals with workload schedulers. The paper analyzes real-world AI power trends and compares active versus passive solutions in terms of computational gain, CAPEX reduction, and management costs.

## Key Results
- Active solutions eliminate the need for dummy loads and improve computational gain by 100%
- Active dynamic response reduces CAPEX by 55% compared to passive solutions
- Over 85% of power spikes last less than 100 milliseconds and contain 5-100 joules of energy

## Why This Works (Mechanism)

### Mechanism 1: Active Peak Shaving via Battery Energy Storage Systems (BESS)
- Claim: Active energy storage absorbs short-duration power spikes, eliminating dummy loads and improving compute utilization.
- Mechanism: AI accelerators generate transient spikes (>85% last <100ms, 5-100J per spike). Active BESS discharges during these bursts to supplement grid power, then recharges during idle/low-draw intervals. This decouples instantaneous compute demand from grid ramp-rate limits.
- Core assumption: BESS can cycle at millisecond timescales with sufficient charge/discharge efficiency to track spike distributions.
- Evidence anchors:
  - [abstract] "over 85% of spikes last less than 100 msec and contain 5-100 J of energy... active solutions eliminate the need for dummy loads, improve computational gain by 100%"
  - [section] Page 8: "Active solutions... must be able to track extreme fluctuations (i.e., variations at high frequency) while supporting large capacitance for energy storage"
  - [corpus] Weak direct evidence; neighbor papers address power management in other domains (MPSoCs, microgrids) but not AI data center BESS specifically.
- Break condition: If spike duration distribution shifts to >500ms or energy per spike exceeds BESS discharge capacity at rack scale, the buffer saturates and dummy loads or grid upgrades become necessary again.

### Mechanism 2: Thermal Headroom Recovery by Eliminating Dummy Loads
- Claim: Removing dummy loads reduces baseline thermal load, restoring accelerator clock headroom and extending hardware lifespan.
- Mechanism: Dummy loads maintain constant grid draw during idle periods, generating excess heat that thermally derates accelerators. Active dynamic response replaces this with on-demand energy buffering, allowing thermal relaxation between compute bursts.
- Core assumption: Thermal derating is a primary constraint on realized FLOPs, not silicon limits or memory bandwidth.
- Evidence anchors:
  - [abstract] "passive solutions offer limited improvements and still require dummy loads"
  - [section] Page 4: "dummy loads deteriorate the thermal profiles of AI accelerators... reducing the compute capacity"
  - [section] Page 9: "temperature profiles within the racks and the shelves would not have the possibility to relax on the long term"
  - [corpus] No direct neighbor paper addresses thermal derating in AI accelerators.
- Break condition: If workload duty cycle approaches 100% (no idle intervals), thermal recovery windows vanish regardless of power architecture.

### Mechanism 3: CAPEX Reduction via Infrastructure Right-Sizing
- Claim: Smoothing power demand allows sizing grid connections and PDUs for average rather than peak load, reducing capital expenditure.
- Mechanism: Current practice oversizes infrastructure to handle worst-case spike aggregation across 1000-1200 racks. Dynamic response buffers local spikes, so upstream infrastructure sees averaged load with lower peak-to-mean ratio.
- Core assumption: Spike timing across racks is uncorrelated; perfect correlation would defeat statistical multiplexing benefits.
- Evidence anchors:
  - [abstract] "reduce CAPEX by 55%"
  - [section] Page 8, Table 1: Active solutions show "+55%" CAPEX reduction vs. passive/none
  - [section] Page 5: "number of racks in a classic AI data centre typically sits between 1000 and 1200... actual impact of these power fluctuations could be orders of magnitude higher"
  - [corpus] No neighbor paper quantifies CAPEX effects of power smoothing.
- Break condition: If workload correlation increases (e.g., synchronized training jobs across racks), aggregate spikes exceed buffer capacity and oversizing returns as the only mitigation.

## Foundational Learning

- Concept: **Power spike distribution and statistical multiplexing**
  - Why needed here: Understanding that 85%+ of spikes are <100ms enables right-sizing buffer energy. If you assume long-duration spikes, you over-provision; if you miss short spikes, you get shutdowns.
  - Quick check question: Given a rack with 200 H100 GPUs (700W peak each), what is the maximum instantaneous spike energy if 5% of GPUs surge simultaneously for 50ms?

- Concept: **Ramp-rate limits vs. energy capacity limits**
  - Why needed here: Grid operators constrain how fast you can change draw (MW/min), while batteries constrain total energy. These are separate bottlenecks—passive caps help with ramp-rate but have low energy; BESS addresses both.
  - Quick check question: A capacitor can discharge in 1ms but stores only 0.1J. A battery stores 1kJ but has 10ms response latency. Which handles a 50J, 80ms spike better?

- Concept: **Thermal derating and TDP headroom**
  - Why needed here: Accelerators throttle clocks when junction temperatures exceed limits. Dummy loads keep chips warmer at idle, reducing headroom for burst compute.
  - Quick check question: If an H100 GPU idles at 300W with dummy load vs. 50W without, how much additional thermal headroom (in °C-equivalent) is available at burst, assuming linear thermal resistance?

## Architecture Onboarding

- Component map:
  Grid connection → PDU → Rack-level power bus → Per-accelerator power rails
  Active path: Rack-level BESS (e.g., Li-ion or advanced chemistry) with bidirectional inverter, control logic interfacing with workload scheduler
  Passive path: Per-accelerator capacitor/supercapacitor banks (no active switching)
  Control loop: Power monitor → Spike detection → BESS discharge trigger → Recharge scheduling

- Critical path:
  1. Characterize actual spike distribution (duration, energy, frequency) from your workload telemetry
  2. Size BESS energy capacity to cover P95 spike energy × concurrent spike count
  3. Validate BESS response latency < typical spike rise time
  4. Integrate BESS control signal with job scheduler to align recharge windows with predicted idle intervals

- Design tradeoffs:
  - Active per-rack vs. per-accelerator: Active at rack level simplifies coordination but requires higher peak discharge rate; per-accelerator is granular but complex.
  - Passive vs. active: Passive has lower maintenance but cannot eliminate dummy loads; active has higher upfront cost but better ROI per Table 1.
  - Buffer size vs. grid contract: Larger buffer reduces grid peak-demand charges but increases battery CAPEX and degradation risk.

- Failure signatures:
  - Buffer saturation: Repeated spikes without recharge windows → BESS SOC → 0 → grid sees full spike amplitude → potential breaker trip
  - Control loop lag: BESS responds after spike peak → partial mitigation only → accelerator may still throttle or shutdown
  - Thermal runaway: BESS inefficiency adds heat to rack → negates thermal benefits of dummy load removal

- First 3 experiments:
  1. **Spike characterization audit**: Instrument a representative rack with sub-millisecond power monitoring across 48-72 hours of production workload. Extract spike duration histogram, energy per spike, and inter-spike intervals. Compare against paper's 85%/<100ms benchmark.
  2. **BESS sizing simulation**: Using audit data, simulate BESS with varying energy capacities (e.g., 50J, 100J, 200J per rack) and response latencies (1ms, 10ms, 50ms). Compute % of spikes fully absorbed and remaining grid variance.
  3. **Thermal baseline measurement**: Run identical workload with and without dummy loads on equivalent hardware. Measure junction temperatures, clock frequencies, and effective FLOPs. Quantify thermal derating delta to validate claimed 100% computational gain potential.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the true distribution of power spikes and energy content in AI accelerators at sub-millisecond sensing resolutions?
- Basis in paper: [explicit] The authors state that the analysis is "biased by the sensing capacity of the datasets that have been considered (which spans between 3 and 100 msec)," leading to the assumption that "shorter power spikes could occur as well."
- Why unresolved: Current datasets lack the temporal granularity to verify if significant power fluctuations exist below the 3-100 msec range, which impacts the sizing requirements for dynamic response systems.
- What evidence would resolve it: Analysis of AI workload power trends using high-frequency sensors (e.g., sub-millisecond sampling rates) to capture the full spectrum of transient spikes.

### Open Question 2
- Question: How can intelligent control systems effectively integrate hardware-aware AI models with real-time power management algorithms?
- Basis in paper: [explicit] The paper identifies an "emerging paradigm" involving control systems that "dynamically coordinate computation scheduling... in response to instantaneous power availability," but notes this requires coupling algorithmic adaptivity with infrastructure monitoring.
- Why unresolved: While the hardware (active devices) exists, the software architecture required to close the loop between varying AI workloads and instantaneous power/thermal states remains conceptual.
- What evidence would resolve it: Development and benchmarking of a scheduler that adjusts model precision or batch size based on real-time charge levels of the active dynamic response system.

### Open Question 3
- Question: Does the deployment of active dynamic response systems across thousands of racks create unforeseen stability issues or synergies for the external power grid?
- Basis in paper: [inferred] The paper notes that while individual racks show limited spikes, "the number of racks in a classic AI data centre typically sits between 1000 and 1200," implying the "cumulative effect... could be orders of magnitude higher."
- Why unresolved: The analysis focuses on per-rack or per-accelerator performance; the systemic interaction of thousands of independent active storage systems with the main grid connection is not modeled.
- What evidence would resolve it: A system-level simulation or pilot study evaluating grid harmonics and stability when thousands of active response units switch between charging and discharging modes simultaneously.

## Limitations
- Scale validation gap: No large-scale deployment data presented for 1000+ rack environments
- Battery degradation modeling: Long-term BESS cycle life under millisecond-scale charge/discharge patterns not quantified
- Correlation assumptions: 55% CAPEX reduction depends on statistical independence of spikes across racks

## Confidence
- **High confidence**: Active BESS can absorb short-duration power spikes
- **Medium confidence**: CAPEX reduction and computational gain figures
- **Low confidence**: Thermal derating elimination claims

## Next Checks
1. **Field deployment pilot**: Install active BESS in a production rack with typical AI workload for 3+ months, measuring actual spike absorption, thermal profiles, and compute utilization compared to baseline.
2. **Correlation stress test**: Model and experimentally verify how correlated workloads affect aggregate spike behavior and buffer effectiveness across multiple racks.
3. **Battery lifetime assessment**: Run accelerated aging tests on BESS units under the proposed operational profile (rapid millisecond cycling) to quantify degradation rate and impact on total cost of ownership.