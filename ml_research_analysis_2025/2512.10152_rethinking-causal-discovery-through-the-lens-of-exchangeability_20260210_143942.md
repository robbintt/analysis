---
ver: rpa2
title: Rethinking Causal Discovery Through the Lens of Exchangeability
arxiv_id: '2512.10152'
source_url: https://arxiv.org/abs/2512.10152
tags:
- causal
- dataset
- discovery
- data
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that causal discovery under the independent and
  identically distributed (i.i.d.) assumption should be reframed using exchangeability,
  a more general symmetry principle. Exchangeability allows for unobserved latent
  variables, unlike i.i.d., and the authors show that many existing i.i.d.
---

# Rethinking Causal Discovery Through the Lens of Exchangeability

## Quick Facts
- arXiv ID: 2512.10152
- Source URL: https://arxiv.org/abs/2512.10152
- Authors: Tiago Brogueira; Mário Figueiredo
- Reference count: 40
- Primary result: Reframes causal discovery from i.i.d. to exchangeability, showing this better matches real-world data structure

## Executive Summary
This paper challenges the conventional i.i.d. assumption in causal discovery by proposing exchangeability as a more appropriate statistical framework. Exchangeability, which allows for unobserved latent variables, is strictly more general than i.i.d. and better captures real-world observational data. The authors demonstrate that the widely-used Tübingen benchmark consists mainly of exchangeable examples rather than strictly i.i.d. data. They introduce a novel synthetic dataset generated purely from exchangeability principles and show it better matches the statistical structure of real-world benchmarks than existing i.i.d. synthetic datasets.

## Method Summary
The authors reframe bivariate causal discovery using exchangeability instead of i.i.d. assumptions. They create a synthetic dataset generator based on the Causal de Finetti theorem, which samples latent parameters and generates conditionally i.i.d. samples given these parameters. The generator uses 8 causal functions, 3 prior distributions, and noise injection. Dataset weights are optimized via leave-one-out cross-validation to minimize performance distance between synthetic and Tübingen data across 9 causal discovery methods. A neural network (SynthNN) is trained on this synthetic dataset to perform causal discovery on real-world benchmarks.

## Key Results
- Exchangeability allows for unobserved latent variables, unlike i.i.d.
- 81.5% of Tübingen benchmark pairs should be considered exchangeable rather than i.i.d.
- The exchangeable synthetic dataset better matches real-world benchmark structure than all other i.i.d. synthetic datasets
- SynthNN trained on exchangeable synthetic data performs similarly to other state-of-the-art i.i.d. methods on the Tübingen benchmark

## Why This Works (Mechanism)

### Mechanism 1
Reframing causal discovery from i.i.d. to exchangeability provides a more accurate statistical assumption for real-world observational data. Exchangeability is strictly more general than i.i.d. and naturally accommodates unobserved confounders that i.i.d. assumptions exclude. This reframing is motivated by the observation that real-world data often contains latent structure that i.i.d. incorrectly treats as noise.

### Mechanism 2
The Tübingen benchmark contains predominantly exchangeable (not i.i.d.) examples. Manual classification of 108 cause-effect pairs by presence of plausible latent variables shows 81.5% should be considered exchangeable. Examples like altitude→temperature (latent: longitude/latitude) or age→height (latent: genetics) violate i.i.d.'s isolation requirement but satisfy exchangeability given the latent structure.

### Mechanism 3
A synthetic dataset generated purely from exchangeability principles matches the statistical structure of real-world benchmark data better than existing i.i.d. synthetic datasets. The generator creates data via Causal de Finetti theorem: sample latent parameters, then generate conditionally i.i.d. samples given these parameters. Weight optimization minimizes performance distance between methods on synthetic vs. Tübingen data.

## Foundational Learning

- **Concept: Exchangeability vs. i.i.d.**
  - **Why needed here:** The entire paper hinges on understanding that exchangeability (joint distribution invariant to permutation) is strictly more general than i.i.d. (independent draws from identical distribution).
  - **Quick check question:** Given draws from a Polya urn (draw ball, replace it plus one more of same color), are samples i.i.d.? Are they exchangeable? (Answer: Not i.i.d., but exchangeable.)

- **Concept: Causal de Finetti Theorem**
  - **Why needed here:** The synthetic dataset generator relies on the causal extension: exchangeable pairs can be represented with causal structure and latent parameters.
  - **Quick check question:** In the causal de Finetti representation, what does conditioning on θ vs. ψ control? (Answer: θ parameterizes the cause distribution p(X|θ); ψ parameterizes the causal mechanism p(Y|X,ψ).)

- **Concept: Markov Equivalence Class (MEC)**
  - **Why needed here:** Understanding why bivariate causal discovery is fundamentally hard: X→Y and Y→X are in the same MEC, requiring additional assumptions beyond i.i.d. observations.
  - **Quick check question:** Why can't conditional independence tests distinguish X→Y from Y→X in a bivariate pair? (Answer: No conditioning set exists to create separating independencies.)

## Architecture Onboarding

- **Component map:**
  1. Tübingen analyzer: Manual classification pipeline → latent variable identification → exchangeability/i.i.d./timeseries label
  2. Synthetic generator: Prior sampler → function selector → noise injection → scaling
  3. Dataset calibrator: Weight optimizer that finds mixture weights to minimize method performance distance to Tübingen
  4. SynthNN: Image-based CNN (50×50 scatter plot → conv blocks → dense layers → sigmoid output)

- **Critical path:**
  1. Validate exchangeability prevalence in Tübingen (justifies reframing)
  2. Build synthetic generator with only exchangeability constraint (no i.i.d.)
  3. Calibrate dataset weights via leave-one-out cross-validation over 9 methods
  4. Train SynthNN on calibrated synthetic data
  5. Compare SynthNN performance on Tübingen to baselines

- **Design tradeoffs:**
  - Function diversity vs. tractability: 8 functions capture real patterns but exclude discrete/multivariate cases
  - Weight calibration method: Optimizing for similarity creates circularity, solved by leave-one-out
  - Image representation vs. direct processing: Scatter plot images outperformed PointNet-style approaches in preliminary tests

- **Failure signatures:**
  - High variance in SynthNN Tübingen performance suggests incomplete synthetic→real transfer
  - Methods with strong noise assumptions underperform on exchangeable data
  - Weight calibration may overfit to specific 9 methods

- **First 3 experiments:**
  1. Reproduce Tübingen classification: Take 10 random pairs, independently classify latent variables, compare to paper's labels
  2. Ablate generator components: Create synthetic datasets with only linear functions, only Gaussian priors, no noise injection; measure degradation in Tübingen similarity
  3. Test generalization to held-out methods: Train SynthNN on weights calibrated without a specific method, then evaluate that method's performance on synthetic vs. Tübingen

## Open Questions the Paper Calls Out
- Can the Causal de Finetti theorem and exchangeability framework be extended from bivariate to multivariate causal discovery?
- How can causal discovery algorithms be redesigned to explicitly model the latent variables implied by exchangeability?
- To what extent does high variance in SynthNN's performance stem from synthetic dataset limitations versus neural network instability?
- Can a unified framework reconcile exchangeability with sequential dependencies of time-series data?

## Limitations
- Classification of real-world data as exchangeable vs. i.i.d. relies on subjective expert judgment about plausible latent variables
- Synthetic generator covers only continuous univariate variables, missing discrete, categorical, and multivariate cases present in Tübingen
- Weight calibration optimizing for method performance similarity creates circularity concerns

## Confidence
- **High:** Exchangeability is strictly more general than i.i.d. and allows for latent variables
- **Medium:** The Tübingen benchmark contains predominantly exchangeable rather than i.i.d. examples
- **Medium:** The synthetic exchangeable dataset better matches real-world benchmark structure than i.i.d. alternatives

## Next Checks
1. Independent replication of the Tübingen latent variable classification on 10 random pairs to assess subjectivity and potential bias
2. Ablation study removing generator components (linear functions only, Gaussian priors only, no noise) to identify which aspects are critical for Tübingen similarity
3. Evaluation of held-out methods (not used in weight calibration) on synthetic vs. Tübingen data to test calibration generalizability