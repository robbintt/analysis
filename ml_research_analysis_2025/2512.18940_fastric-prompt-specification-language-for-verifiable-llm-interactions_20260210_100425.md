---
ver: rpa2
title: 'FASTRIC: Prompt Specification Language for Verifiable LLM Interactions'
arxiv_id: '2512.18940'
source_url: https://arxiv.org/abs/2512.18940
tags:
- specification
- language
- state
- fastric
- will
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FASTRIC introduces a Prompt Specification Language that makes implicit
  Finite State Machines (FSMs) explicit in natural language prompts, enabling systematic
  verification of multi-turn LLM interactions. The seven-element specification (Final
  States, Agents, States, Triggers, Roles, Initial State, Constraints) maps natural
  language to FSM components, with formality levels (L1-L4) calibrating procedural
  detail to model capacity.
---

# FASTRIC: Prompt Specification Language for Verifiable LLM Interactions

## Quick Facts
- arXiv ID: 2512.18940
- Source URL: https://arxiv.org/abs/2512.18940
- Reference count: 40
- Primary result: Introduces FASTRIC, a seven-element specification language mapping FSM components to natural language prompts, enabling verifiable multi-turn LLM interactions with model-dependent optimal formality levels.

## Executive Summary
FASTRIC introduces a systematic approach to designing verifiable multi-turn LLM interactions by making implicit Finite State Machines (FSMs) explicit in natural language prompts. The seven-element specification (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) provides a structured framework for mapping FSM components to prompt elements, with formality levels (L1-L4) calibrating procedural detail to model capacity. Testing across three model scales reveals that optimal specification formality is model-dependent, establishing "Goldilocks zones" where specifications provide sufficient structure without over-constraint. This transforms multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.

## Method Summary
FASTRIC's methodology centers on translating FSM components into natural language prompt specifications through seven defined elements. The system introduces formality levels (L1-L4) that represent increasing procedural detail, allowing calibration to different model capacities. The evaluation framework measures conformance rates across formality levels and model scales, establishing verification metrics for multi-turn interactions. The approach was tested using a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters), revealing model-specific optimal specification points.

## Key Results
- DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4 formality levels
- ChatGPT-5 (~1T) peaks at L3 (0.90) before performance collapse at L4 (0.39)
- Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36)
- Optimal specification formality is model-dependent, establishing model-specific "Goldilocks zones"

## Why This Works (Mechanism)
FASTRIC works by making implicit FSMs explicit in natural language prompts, providing structured guidance for LLM interactions. The seven-element specification creates a clear mapping between FSM components and prompt elements, enabling systematic verification of multi-turn interactions. Formality levels allow for calibration of procedural detail to match model capacity, preventing both under-constraining (leading to arbitrary behavior) and over-constraining (causing performance collapse). This systematic approach transforms what was previously heuristic prompt engineering into measurable, verifiable interaction design.

## Foundational Learning

**Finite State Machines** - Why needed: FSMs provide the theoretical foundation for modeling sequential interactions and state transitions. Quick check: Can you identify the states, transitions, and final states in a simple turn-taking conversation?

**Formality Levels** - Why needed: Different models require different levels of procedural detail to achieve optimal performance. Quick check: Can you explain why ChatGPT-5 performs worse at L4 than L3?

**Conformance Metrics** - Why needed: Measurement of adherence to specifications enables verification and optimization. Quick check: How would you measure whether an LLM follows a 3-state interaction pattern?

**Model Capacity Calibration** - Why needed: Specification effectiveness depends on matching procedural detail to model capability. Quick check: What happens when you provide too much or too little structure for a given model?

## Architecture Onboarding

**Component Map**: User -> FASTRIC Specification -> LLM -> State Transitions -> Output
**Critical Path**: Specification Design → Formality Level Selection → Model Calibration → Verification Testing
**Design Tradeoffs**: Higher formality provides more structure but risks over-constraint; lower formality allows flexibility but may lack guidance
**Failure Signatures**: Performance collapse at high formality (over-constraint), random behavior at low formality (under-constraint), high variance indicating specification instability
**3 First Experiments**: 1) Test a simple 2-state FSM across L1-L4 on one model family 2) Vary specification completeness by removing individual FASTRIC elements 3) Cross-test optimized specifications between different model architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Findings based on single interaction pattern (kindergarten tutoring FSM) limit generalizability
- Three model scales represent different architectural families, making it unclear whether differences stem from parameter count or fundamental architecture
- High variance in Phi4 performance suggests specification instability or model capacity limitations requiring further investigation
- Does not address compounding errors across multiple turns or long-horizon task completion effects

## Confidence

**High confidence**: FASTRIC specification structure is well-defined and operationalizable; FSM-to-natural-language mapping is clear and reproducible

**Medium confidence**: Model-dependent "Goldilocks zones" are identified but sample size (3 models) and single FSM pattern limit generalizability; performance collapse at L4 could reflect over-constraint or model sensitivity

**Low confidence**: Assertion that FASTRIC transforms multi-turn interaction design from "heuristic art to systematic engineering" overstates current capabilities; study demonstrates verification for one FSM type but not validated across diverse patterns or real-world applications

## Next Checks

1. Test FASTRIC specifications across diverse FSM patterns (negotiation, troubleshooting, creative collaboration) to assess generalizability beyond kindergarten tutoring

2. Conduct ablation studies varying specification element completeness to determine which FASTRIC components drive conformance differences across formality levels

3. Implement cross-model validation where specifications optimized for one model family are tested on others to quantify transferability and identify universal versus model-specific principles