---
ver: rpa2
title: 'LOCUS: Low-Dimensional Model Embeddings for Efficient Model Exploration, Comparison,
  and Selection'
arxiv_id: '2601.21082'
source_url: https://arxiv.org/abs/2601.21082
tags:
- embeddings
- embedding
- correctness
- query
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes LOCUS, a method to produce low-dimensional\
  \ vector embeddings that compactly represent a language model\u2019s capabilities\
  \ across queries. LOCUS is an attention-based approach that generates embeddings\
  \ by a deterministic forward pass over query encodings and evaluation scores via\
  \ an encoder model, enabling seamless incorporation of new models to the pool and\
  \ refinement of existing model embeddings without retraining."
---

# LOCUS: Low-Dimensional Model Embeddings for Efficient Model Exploration, Comparison, and Selection

## Quick Facts
- arXiv ID: 2601.21082
- Source URL: https://arxiv.org/abs/2601.21082
- Authors: Shivam Patel; William Cocke; Gauri Joshi
- Reference count: 40
- Primary result: 4.8× fewer query evaluation samples than baselines to produce informative and robust model embeddings

## Executive Summary
LOCUS is an attention-based method for generating low-dimensional embeddings that represent a language model's capabilities across a set of queries. Unlike previous approaches that learn embeddings via gradient descent, LOCUS uses a deterministic forward pass through an attention encoder, enabling seamless incorporation of new models and refinement of existing embeddings without retraining. The method achieves state-of-the-art routing accuracy while requiring significantly fewer query evaluations than baseline approaches.

## Method Summary
LOCUS generates model embeddings through a tokenizer that maps query encodings and evaluation scores to tokens, which are then processed by a latent bottleneck attention encoder to produce a 128-dimensional embedding. The method trains jointly with a correctness predictor that uses embeddings and query encodings to predict model performance. During inference, new models are embedded by collecting 128-256 query evaluations and passing them through a single forward pass, without any retraining. The approach is designed to be permutation-invariant to evaluation order and stable across different evaluation set variations.

## Key Results
- 4.8× fewer query evaluation samples needed compared to baseline embedding methods
- High Pearson correlation (0.845 cosine, 0.887 Euclidean) between embedding distances and correctness disagreement rates
- Nearest-neighbor models show up to 79% correctness agreement, demonstrating meaningful geometric structure
- Robustness to evaluation set variations with distances < 0.02 even at 0% overlap

## Why This Works (Mechanism)

### Mechanism 1
Permutation-invariant attention over evaluation tokens enables sample-efficient capability extraction from sparse query-score pairs. Query-score pairs are tokenized via MLP into a common token space, then processed through bidirectional attention without positional encodings, forcing the model to learn capability patterns rather than memorizing query-specific artifacts. A learned query vector attends over all output tokens to produce a single embedding. Core assumption: Model capability is a learnable function of how it distributes correctness across semantically encoded queries, not the specific query identities.

### Mechanism 2
Deterministic forward-pass embedding generation preserves geometric stability across evaluation set variations, enabling meaningful distance-based comparisons. Unlike parametric approaches that learn embeddings via gradient descent and are sensitive to initialization and optimization path, LOCUS uses a fixed encoder after training. Embeddings are a deterministic function of input evaluations, making them stable to regeneration. Core assumption: The encoder learns a general mapping from evaluation patterns to capability representations that transfers across model pools.

### Mechanism 3
Embedding distance correlates with behavioral similarity, enabling nearest-neighbor operations for fallback routing and portfolio selection. The embedding space is trained via a correctness prediction objective that forces models with similar correctness patterns across queries to have similar embeddings. This induces geometry where distance reflects behavioral divergence. Core assumption: The correctness prediction training signal is sufficient to structure the embedding space along capability-relevant dimensions.

## Foundational Learning

- **Permutation-equivariant neural architectures (Set Transformers)**: The encoder must process variable-sized evaluation sets where order is arbitrary. Understanding why positional encodings are excluded and how attention-based aggregation produces order-invariant outputs is essential. Quick check: Can you explain why learned-query attention aggregation produces permutation-invariant outputs?

- **Latent bottleneck attention**: The paper uses r=64 latent vectors to reduce O(n²) attention to O(n×r), enabling scaling to thousands of evaluations per model. Quick check: In the compression block, why does the model use latents as queries and evaluation tokens as keys/values, and what information flow does this permit?

- **Black-box LLM evaluation and LLM-as-a-judge**: LOCUS operates on query-response evaluation scores (often binary correctness), not model internals. Understanding how these scores are generated (ground truth comparison, judge models) contextualizes the input signal quality. Quick check: What are the failure modes of binary correctness as a capability signal for models that generate verbose explanations?

## Architecture Onboarding

- **Component map**: Query evaluations -> query encodings via sentence encoder -> tokenizer MLP -> 2 latent bottleneck attention blocks -> learned-query aggregation -> 128-dim embedding
- **Critical path**: Query evaluations (evaluated once offline) → query encodings via sentence encoder (all-mpnet-base-v2) → tokenizer → attention blocks → aggregation → model embedding. New model onboarding: collect ~128-256 query evaluations, single forward pass, no retraining.
- **Design tradeoffs**: Latent bottleneck (r=64) vs full attention trades O(n²) for O(n×r), limiting token-token direct communication. Embedding dimension (d=128 vs 256) shows 128/256 perform best; smaller underfits, larger increases training complexity. Sentence encoder choice: all-mpnet-base-v2 selected; ablations show comparable performance across encoders with task-specific variation.
- **Failure signatures**: Embeddings cluster randomly indicates encoder likely undertrained or evaluation set too small/low-quality. High variance in regenerated embeddings on same data indicates overfitting (should not happen with LOCUS architecture). Poor routing accuracy but good correctness prediction suggests predictor overfitting, not encoder issue. New model embeddings far from any training models indicates encoder has not generalized.
- **First 3 experiments**:
  1. Train on 16 models, embed 2 held-out models with 256 evaluations each. Verify correctness prediction accuracy is within 2% of models seen during training.
  2. For a fixed model, generate embeddings with evaluation sets of varying overlap (0%, 50%, 100%) and compute pairwise cosine distance. Expect distances < 0.02 even at 0% overlap.
  3. Compute Pearson correlation between embedding distances and correctness disagreement rates across all model pairs. Target: ρ > 0.80.

## Open Questions the Paper Calls Out

- **Multimodal extension**: Can LOCUS be extended to multimodal language models while maintaining sample efficiency and embedding stability? The authors state in Section 4: "We leave extensions to multimodal models and adaptive query evaluations for generating embeddings as future directions." Evidence would require adapting LOCUS to a multimodal model pool demonstrating comparable sample efficiency and geometric interpretability.

- **Adaptive query selection**: How can adaptive query selection be integrated into LOCUS to dynamically choose which queries to evaluate for more informative embeddings? The conclusion explicitly lists "adaptive query evaluations for generating embeddings" as a future direction. Evidence would require a modified training/inference pipeline that selects queries based on current embedding uncertainty, showing improved embedding quality with fewer evaluations.

- **Nuanced capability dimensions**: Can LOCUS embeddings capture nuanced capability dimensions beyond binary correctness, such as response quality, safety, or faithfulness? The paper exclusively uses binary correctness scores and does not explore whether the embedding space can represent richer evaluation signals. Evidence would require experiments using graded scores or multiple quality dimensions, showing that embedding distances correlate with similarity across each dimension separately.

## Limitations

- **Generalization to out-of-distribution models**: Strong performance within training pool but untested on fundamentally different model families (e.g., proprietary frontier models)
- **Evaluation data quality dependency**: Inherits limitations of underlying evaluation methodology; biased or noisy correctness judgments will be reflected in embeddings
- **Trade-off between stability and capacity**: Permutation-invariant architecture excludes positional encodings, potentially limiting ability to capture sequence-dependent patterns in evaluation data

## Confidence

- **High confidence**: Claims about deterministic embedding generation and sample efficiency (4.8× fewer evaluations than baselines) are directly supported by experimental results. Geometric meaningfulness of embedding space (correlation > 0.84 between embedding distance and correctness disagreement) is robustly demonstrated.
- **Medium confidence**: Claims about seamless incorporation of new models and refinement without retraining are theoretically sound but practical performance may vary depending on similarity to training pool.
- **Low confidence**: Applications like "model portfolio selection" and "fallback routing" based on embedding proximity are only briefly mentioned without systematic evaluation.

## Next Checks

1. **Out-of-distribution model embedding**: Test LOCUS on 10-15 models from different families (e.g., Claude, GPT series, open-weight models not in training pool) to assess generalization. Compute embedding distances to training models and verify correctness prediction accuracy remains within 5% of in-distribution performance.

2. **Evaluation set composition sensitivity**: Systematically vary composition and size of evaluation sets (64, 128, 256, 512 queries) across different benchmark subsets. Measure stability of embeddings (cosine distance between embeddings from different subsets of same size) and correctness prediction accuracy. Target: distance < 0.05 and accuracy variance < 2% across evaluation set variations.

3. **Alternative capability dimensions**: Beyond binary correctness, evaluate whether LOCUS embeddings capture other capability dimensions by testing correlation between embedding distance and: (a) pairwise zero-shot task transfer performance, (b) qualitative differences in reasoning chains, and (c) safety/jailbreak susceptibility.