---
ver: rpa2
title: Efficient Text Classification with Conformal In-Context Learning
arxiv_id: '2512.05732'
source_url: https://arxiv.org/abs/2512.05732
tags:
- cicle
- few-shot
- base
- prompting
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates Conformal In-Context Learning (CICLe), a framework
  that combines traditional classifiers with conformal prediction to guide LLM prompting
  in text classification. CICLe reduces computational cost by adaptively selecting
  candidate classes and examples, bypassing the LLM when confident.
---

# Efficient Text Classification with Conformal In-Context Learning

## Quick Facts
- arXiv ID: 2512.05732
- Source URL: https://arxiv.org/abs/2512.05732
- Authors: Ippokratis Pantelidis; Korbinian Randl; Aron Henriksson
- Reference count: 0
- Primary result: CICLe reduces LLM prompt length by up to 25.16% and shots by up to 34.45% while matching or exceeding few-shot prompting performance.

## Executive Summary
This study introduces Conformal In-Context Learning (CICLe), a framework that combines traditional classifiers with conformal prediction to guide LLM prompting in text classification. By adaptively reducing the candidate class set and bypassing the LLM when confident, CICLe achieves significant efficiency gains while maintaining competitive accuracy. Across four diverse benchmarks, CICLe consistently outperforms or matches few-shot prompting, particularly with 500+ training samples and under high class imbalance, demonstrating up to 34.45% fewer shots and 25.16% shorter prompts than baselines.

## Method Summary
CICLe uses a two-stage approach: a lightweight base classifier (Logistic Regression on TF-IDF features) first predicts class probabilities, then Conformal Prediction wraps these estimates to generate a candidate set of labels. If this set contains only one class, the system returns that label immediately. Otherwise, the LLM is prompted with examples from only the candidate classes, reducing prompt length and required shots. The framework was evaluated on four English text classification benchmarks using LLaMA-3.1-Instruct 8B/70B models with 2-shot examples per class, comparing against random, sparse (TF-IDF cosine), and dense (semantic embeddings) selection strategies.

## Key Results
- CICLe consistently outperforms or matches few-shot prompting, especially with 500+ training samples and under high class imbalance
- Achieves up to 34.45% fewer shots and 25.16% shorter prompts than baseline methods
- Enables competitive performance with 8B-parameter models versus 70B-parameter ones
- Improves over its base classifier and shows strong efficiency and robustness, particularly in imbalanced scenarios

## Why This Works (Mechanism)

### Mechanism 1: Conformal Candidate Pruning
The base classifier estimates class probabilities, which CP wraps to generate a "conformal set" of candidate labels guaranteed to include the true label with probability 1-α. This focuses the LLM on plausible classes, reducing prompt length and potentially improving accuracy.

### Mechanism 2: Shot-Efficiency via Set Reduction
By reducing the number of candidate classes from N to S, CICLe requires only S×k shots instead of N×k shots, lowering inference cost. The LLM doesn't need examples from negative classes to discriminate between remaining positive candidates.

### Mechanism 3: Adaptive Model Routing (Bypassing)
When the conformal set contains only one class (high confidence), the system returns this label immediately without invoking the LLM, optimizing resource usage by routing high-confidence instances directly to the base classifier.

## Foundational Learning

- **Concept: Conformal Prediction (CP)**
  - Why needed here: CP converts raw classifier scores into valid prediction sets with statistical guarantees (coverage). Without understanding α (significance level) and coverage, the mechanism is a black box.
  - Quick check question: If you set α=0.1, what is the guaranteed probability that the true label is inside the conformal set?

- **Concept: In-Context Learning (Few-Shot Prompting)**
  - Why needed here: This is the capability being optimized. Understanding how LLMs use demonstrations in the prompt to generalize without weight updates is essential.
  - Quick check question: How does the ordering or selection of few-shot examples typically affect LLM performance?

- **Concept: TF-IDF and Logistic Regression**
  - Why needed here: These form the "base classifier" that provides the first-pass filtering. The paper argues this simple, efficient model is sufficient for initial screening.
  - Quick check question: Why might a simple TF-IDF model outperform a BERT model on efficiency but fail on semantic ambiguity?

## Architecture Onboarding

- **Component map:** Input -> TF-IDF Vectorizer -> Logistic Regression -> Conformal Layer -> Router -> Prompt Builder -> LLM
- **Critical path:** The calibration of the Conformal Layer is the critical dependency. If the calibration set is not representative of the test distribution, the conformal sets will be invalid or inefficient.
- **Design tradeoffs:**
  - Alpha (α) Setting: Lower α increases coverage but increases set size (more LLM calls/cost). Higher α reduces set size but risks missing the true label.
  - Base Model Choice: A stronger base model yields smaller sets (higher efficiency) but increases first-stage overhead.
- **Failure signatures:**
  - "Bloated Sets": Weak base model causes |S| ≈ N, degrading to standard few-shot prompting
  - "Coverage Failure": Calibration shift causes true label exclusion, creating hard errors
- **First 3 experiments:**
  1. Vary calibration set size to measure stability of conformal set sizes and coverage guarantees
  2. Sweep α (e.g., 0.01 to 0.2) to plot trade-off between Macro-F1 and Average Set Size
  3. Replace Logistic Regression with DistilBERT to quantify impact on LLM invocation rates

## Open Questions the Paper Calls Out

1. **Alpha sensitivity:** How does varying α affect the trade-off between prediction certainty and label coverage? Fixed α=0.05 was used; sensitivity remains unexplored.

2. **Example ordering:** What is the impact of example ordering within prompts on performance? Current confidence-based ordering was not compared against alternatives.

3. **Multi-label extension:** Can CICLe be effectively extended to multi-label or hierarchical classification tasks? Only single-label flat classification was evaluated.

4. **Multilingual/generalization:** How well does CICLe generalize to multilingual and domain-specific tasks (medicine, law)? All experiments were on English datasets.

## Limitations

- All experiments conducted exclusively on English datasets, leaving open questions about multilingual and domain-specific applicability
- The TF-IDF+Logistic Regression base classifier may fail on nuanced semantic tasks where word overlap is insufficient
- The claimed shot-reduction mechanism assumes LLM can discriminate between positive candidates without negative examples, which may not hold for semantically similar classes

## Confidence

- **High confidence:** The core CICLe architecture (base classifier + conformal prediction + adaptive LLM routing) is technically valid and reported efficiency gains are plausible
- **Medium confidence:** The claim that CICLe matches or exceeds few-shot prompting performance requires careful interpretation - advantage appears strongest with larger training sets and under class imbalance
- **Medium confidence:** The claim about enabling smaller LLMs to match larger ones is reasonable but may be influenced by factors beyond class reduction

## Next Checks

1. **Calibration Set Sensitivity:** Run CICLe with varying calibration set sizes (10%, 20%, 30% of training data) and measure how conformal set efficiency and coverage stability change across datasets.

2. **Base Classifier Ablation:** Replace TF-IDF+Logistic Regression with DistilBERT and measure impact on LLM invocation rates and overall performance to quantify sensitivity to base model quality.

3. **Alpha Trade-off Analysis:** Sweep α from 0.01 to 0.2 and plot explicit trade-off curve between Macro-F1 and average conformal set size to identify optimal operating points for different dataset characteristics.