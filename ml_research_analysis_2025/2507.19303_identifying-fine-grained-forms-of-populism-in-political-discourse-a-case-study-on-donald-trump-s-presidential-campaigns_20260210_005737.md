---
ver: rpa2
title: 'Identifying Fine-grained Forms of Populism in Political Discourse: A Case
  Study on Donald Trump''s Presidential Campaigns'
arxiv_id: '2507.19303'
source_url: https://arxiv.org/abs/2507.19303
tags:
- populist
- trump
- discourse
- speeches
- populism
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores whether large language models can identify
  and classify fine-grained forms of populism in political discourse. The authors
  curate and release novel datasets to train and benchmark a range of pre-trained
  language models, both open-weight and proprietary, across multiple prompting paradigms.
---

# Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns

## Quick Facts
- arXiv ID: 2507.19303
- Source URL: https://arxiv.org/abs/2507.19303
- Reference count: 32
- Primary result: Fine-tuned RoBERTa classifier outperforms instruction-tuned LLMs for fine-grained populism classification in U.S. political discourse

## Executive Summary
This study investigates whether large language models can effectively identify and classify fine-grained forms of populism in political discourse. The authors develop novel datasets to train and benchmark both open-weight and proprietary language models across multiple prompting paradigms. Their findings reveal that fine-tuned RoBERTa classifiers significantly outperform instruction-tuned LLMs for this task, except when the LLMs are also fine-tuned. The research applies the best-performing model to analyze Donald Trump's campaign speeches, providing insights into his strategic use of populist rhetoric, and evaluates model generalizability on European political speeches.

## Method Summary
The researchers curate novel datasets for fine-grained populism classification and train a range of pre-trained language models using both fine-tuning and prompting approaches. They evaluate model performance on U.S. political discourse, then apply the best-performing model to analyze Trump's campaign speeches. To assess generalizability, they benchmark these models on European political speeches, examining cross-context transferability. The study compares traditional fine-tuned classifiers against instruction-tuned LLMs across multiple prompting paradigms.

## Key Results
- Fine-tuned RoBERTa classifier vastly outperforms all instruction-tuned LLMs for fine-grained populism classification
- The best-performing model applied to Trump's speeches reveals strategic patterns in his populist rhetoric use
- Instruction-tuned LLMs show greater robustness on out-of-domain European political speeches compared to fine-tuned models

## Why This Works (Mechanism)
The superior performance of fine-tuned RoBERTa stems from its task-specific optimization for fine-grained populism classification, allowing it to capture nuanced linguistic patterns that general-purpose instruction-tuned LLMs miss. The model's architecture, trained on political discourse data, develops specialized representations for populist rhetorical features. When applied to Trump's speeches, the fine-tuned model can identify subtle variations in populist messaging strategies across different contexts and audiences. The cross-domain robustness of instruction-tuned LLMs suggests they possess more generalizable linguistic representations that transfer better to unfamiliar political contexts.

## Foundational Learning

1. **Fine-tuning vs. Prompting Paradigms**
   - Why needed: Different approaches to adapting pre-trained models for specific classification tasks
   - Quick check: Compare task performance when models are adapted through parameter updates versus prompt engineering

2. **Fine-grained vs. Binary Populism Classification**
   - Why needed: Capturing nuanced variations in populist rhetoric beyond simple presence/absence detection
   - Quick check: Evaluate whether models can distinguish between different subtypes of populist discourse

3. **Cross-domain Transferability**
   - Why needed: Understanding how well models trained on one political context generalize to others
   - Quick check: Measure performance drop when applying U.S.-trained models to European political speeches

4. **Instruction-tuned vs. Base LLMs**
   - Why needed: Different pretraining objectives affect model behavior on specialized classification tasks
   - Quick check: Compare how instruction-tuning influences performance on fine-grained rhetorical analysis

5. **Cultural and Linguistic Context in Political Discourse**
   - Why needed: Populist rhetoric varies significantly across cultural and linguistic boundaries
   - Quick check: Assess whether model performance correlates with linguistic and cultural similarity between training and test domains

## Architecture Onboarding

**Component Map:**
Data Collection -> Dataset Curation -> Model Training (Fine-tuning + Prompting) -> Performance Evaluation -> Cross-domain Validation -> Speech Analysis Application

**Critical Path:**
The most critical sequence is Dataset Curation → Model Training → Performance Evaluation, as the quality and specificity of the training data directly determines model performance on the fine-grained classification task.

**Design Tradeoffs:**
The study balances between task-specific optimization (fine-tuning) and generalization (instruction-tuned LLMs). Fine-tuning provides superior performance on the target domain but may reduce cross-domain transferability, while instruction-tuned models sacrifice some precision for greater robustness across different political contexts.

**Failure Signatures:**
Models may fail when encountering populist rhetoric that significantly differs from training examples, particularly when rhetorical strategies vary across cultural contexts. Performance degradation is likely when analyzing speeches from political systems with different institutional structures or when populist messaging evolves beyond patterns represented in the training data.

**Three First Experiments:**
1. Test model performance on speeches containing novel populist strategies not present in training data
2. Evaluate model sensitivity to annotation variations by comparing predictions across differently labeled datasets
3. Measure performance on temporally distant speeches to assess adaptation to evolving populist discourse patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Performance evaluation limited to English-language U.S. political discourse with European politicians used only as out-of-domain test
- Human annotation process for populist rhetoric may contain subjective biases affecting model training
- No assessment of temporal shifts in populist discourse patterns that could affect model performance on future communications

## Confidence

High confidence in:
- Comparative performance ranking of models on curated U.S. dataset
- Methodological approach for fine-tuning and prompt engineering
- Application of best-performing model to analyze Trump's speeches

Medium confidence in:
- Generalizability of findings to other political contexts and languages
- Stability of performance across different time periods of political discourse
- Sensitivity of results to different annotation schemes for populist rhetoric

## Next Checks

1. Evaluate the same models on a temporally diverse dataset spanning multiple election cycles to assess whether performance degrades over time as populist rhetoric evolves.

2. Conduct a cross-linguistic validation using parallel datasets in multiple languages to determine whether the RoBERTa advantage persists outside English-language contexts.

3. Perform ablation studies on the annotation scheme by having multiple annotator groups with different political backgrounds label the same corpus, then measure how annotation variability affects model performance.