---
ver: rpa2
title: Euskarazko lehen C1 ebaluatzaile automatikoa
arxiv_id: '2503.01851'
source_url: https://arxiv.org/abs/2503.01851
tags:
- dira
- izan
- page
- testu
- sailkatzailea
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work develops an automatic C1 level classification system
  for Basque language compositions. The approach uses transformer language models
  (RoBERTa, BERT, XLM-RoBERTa, and Llama2-based Latxa) fine-tuned for binary classification
  (GAI/EZGAI) with various training strategies.
---

# Euskarazko lehen C1 ebaluatzaile automatikoa

## Quick Facts
- arXiv ID: 2503.01851
- Source URL: https://arxiv.org/abs/2503.01851
- Reference count: 0
- Develops first automatic C1 level classifier for Basque compositions using transformer models

## Executive Summary
This work presents the first automatic C1 level classification system for Basque language compositions, addressing a critical gap in Basque language assessment. The authors develop a binary classification approach using transformer language models (RoBERTa, BERT, XLM-RoBERTa, and Llama2-based Latxa) fine-tuned for distinguishing C1-level texts from lower proficiency levels. The system aims to automate the evaluation of Basque compositions at the C1 proficiency level according to the Common European Framework of Reference for Languages (CEFR).

The research demonstrates that transformer-based approaches can effectively classify Basque compositions at the C1 level, achieving test accuracies between 0.85-0.95 depending on model configuration and data split. However, the study also reveals important challenges including model calibration issues where predictions tend toward extreme probabilities, and artifact analysis suggesting models may rely on unintended features rather than genuine linguistic criteria for classification. The work establishes feasibility while highlighting areas requiring further development for reliable practical deployment.

## Method Summary
The authors developed a transformer-based binary classification system for Basque C1 level assessment using four different pre-trained models: RoBERTa, BERT, XLM-RoBERTa, and a Llama2-based model called Latxa. The models were fine-tuned on Basque composition datasets labeled for C1 proficiency, with training strategies including standard fine-tuning, Easy Data Augmentation (EDA), Self-Calibration Loss (SCL), and diluzio-p regularization. The binary classification task distinguished between GAI (C1-level texts) and EZ_GAI (non-C1 texts). Multiple data splits were used to evaluate robustness, and calibration analysis was performed to assess probability reliability. The best-performing model achieved accuracy of 0.85-0.95 depending on configuration.

## Key Results
- Transformer models achieved test accuracy of 0.85-0.95 for C1 level classification in Basque
- EDA and SCL training techniques showed limited benefit for model performance
- Diluzio-p regularization improved Latxa model performance
- Calibration analysis revealed most models assign extreme probability values
- Artifact analysis indicated models may rely on unintended features rather than linguistic criteria

## Why This Works (Mechanism)
The transformer models succeed at C1 classification by learning patterns in Basque text that correlate with C1 proficiency level. These models capture complex linguistic features through self-attention mechanisms, identifying characteristics that distinguish advanced Basque compositions from lower proficiency levels. The fine-tuning process adapts pre-trained language understanding to the specific binary classification task, allowing the models to leverage their existing linguistic knowledge while specializing in C1-level discrimination.

## Foundational Learning
1. **CEFR C1 Level Definition** - Why needed: Provides the linguistic criteria and proficiency benchmarks the models aim to identify. Quick check: Are the classification decisions aligned with established C1 descriptors?
2. **Transformer Architecture** - Why needed: Enables capture of long-range dependencies and complex linguistic patterns in Basque text. Quick check: Does the model effectively learn from context across sentence boundaries?
3. **Fine-tuning Methodology** - Why needed: Adapts pre-trained models to the specific binary classification task. Quick check: Are the learning rates and training epochs appropriately optimized?
4. **Calibration Analysis** - Why needed: Assesses whether probability outputs reflect true confidence levels. Quick check: Do extreme probability assignments indicate overconfidence or genuine certainty?
5. **Artifact Analysis** - Why needed: Identifies unintended features models may rely on rather than genuine linguistic criteria. Quick check: Are predictions based on actual C1-level characteristics or spurious correlations?
6. **Regularization Techniques** - Why needed: Prevents overfitting and improves generalization to unseen data. Quick check: Does diluzio-p regularization improve Latxa performance as intended?

## Architecture Onboarding

**Component Map:** Basque text corpus -> Tokenizer -> Transformer model (RoBERTa/BERT/XLM-R/Latxa) -> Fine-tuning -> Binary classifier (GAI/EZ_GAI) -> Output probabilities

**Critical Path:** Text input → Tokenization → Self-attention layers → Classification head → Probability output → Calibration adjustment

**Design Tradeoffs:** 
- Model selection balances performance with computational efficiency
- Binary classification simplifies the task but loses granularity of multi-level assessment
- Regularization improves generalization but may limit model capacity
- Calibration techniques improve probability reliability but add complexity

**Failure Signatures:**
- Extreme probability assignments indicate poor calibration
- Reliance on artifacts suggests models miss genuine linguistic features
- Performance degradation on external test sets indicates overfitting
- Inconsistent results across data splits suggest instability

**First Experiments:**
1. Test best model on an independent Basque composition corpus from different institutions
2. Compare model predictions with human expert judgments on identical samples
3. Analyze specific linguistic features driving correct vs. incorrect classifications

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of external validation raises concerns about generalizability to broader Basque learner populations
- Models may rely on unintended features rather than genuine C1 linguistic characteristics
- Calibration issues with extreme probability assignments limit practical decision-making utility
- Limited systematic exploration of training strategy hyperparameters across all techniques

## Confidence
| Claim | Confidence |
|-------|------------|
| Transformer-based C1 classification feasibility | High |
| Linguistic validity of classifications | Medium |
| Generalizability of training strategy conclusions | Low |

## Next Checks
1. External validation: Test the best-performing models on an independent corpus of Basque learner compositions from different institutions or time periods to assess real-world generalizability.

2. Linguistic feature analysis: Conduct a detailed error analysis comparing model predictions with human expert judgments to identify specific linguistic features the models are actually using versus intended C1 criteria.

3. Calibration refinement: Implement temperature scaling or other calibration techniques and evaluate whether probability outputs become more reliable for practical decision-making applications.