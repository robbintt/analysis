---
ver: rpa2
title: Learning with Dual-level Noisy Correspondence for Multi-modal Entity Alignment
arxiv_id: '2510.18240'
source_url: https://arxiv.org/abs/2510.18240
tags:
- entity
- correspondence
- inter-graph
- attributes
- pairs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the Dual-level Noisy Correspondence (DNC)
  problem in multi-modal entity alignment (MMEA), where both intra-entity (entity-attribute)
  and inter-graph (entity-entity and attribute-attribute) correspondences are noisy
  due to annotation errors. The proposed RULE framework estimates the reliability
  of these correspondences using a two-fold principle of uncertainty and consensus,
  then applies tailored strategies to mitigate noise during attribute fusion and inter-graph
  alignment.
---

# Learning with Dual-level Noisy Correspondence for Multi-modal Entity Alignment

## Quick Facts
- **arXiv ID**: 2510.18240
- **Source URL**: https://arxiv.org/abs/2510.18240
- **Authors**: Haobin Li; Yijie Lin; Peng Hu; Mouxing Yang; Xi Peng
- **Reference count**: 40
- **One-line primary result**: RULE framework outperforms 7 SOTA methods on 5 benchmarks, achieving 58.2% Hits@1 and 63.6% MRR under 50% noise on ICEWS-WIKI.

## Executive Summary
This paper tackles the Dual-level Noisy Correspondence (DNC) problem in Multi-modal Entity Alignment (MMEA), where both intra-entity (entity-attribute) and inter-graph (entity-entity and attribute-attribute) correspondences are noisy due to annotation errors. The proposed RULE framework estimates correspondence reliability using uncertainty and consensus principles, then applies tailored strategies to mitigate noise during attribute fusion and inter-graph alignment. It further incorporates a test-time reasoning module using large language models to uncover latent attribute-attribute connections, enhancing equivalent entity identification. Extensive experiments demonstrate significant improvements over state-of-the-art methods, showing superior robustness against noisy correspondences.

## Method Summary
RULE employs a reliability estimation module that calculates uncertainty via Dirichlet distribution evidence and consensus via similarity metrics to partition correspondences into clean, inconsistent, and uncertain sets. It then uses a Dually Robust Loss function that excludes high-uncertainty pairs and refines labels for inconsistent pairs. Attribute fusion is weighted by reliability scores, and a test-time correspondence reasoning module using large language models refines similarity scores through chain-of-thought reasoning. The framework is trained end-to-end with CLIP encoders for vision/text and GAT for structure, incorporating KL divergence regularization.

## Key Results
- RULE achieves 58.2% Hits@1 and 63.6% MRR under 50% DNC on ICEWS-WIKI, outperforming all baselines.
- On average across all datasets, RULE achieves 73.8% Hits@1, demonstrating consistent performance.
- The framework shows superior robustness, maintaining high accuracy even with increasing noise levels compared to state-of-the-art methods.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Separating clean, uncertain, and low-consensus correspondences via a dual-principle reliability metric prevents the model from overfitting to erroneous annotations.
- **Mechanism**: The framework estimates reliability $w$ by combining **Uncertainty** (inversely proportional to the Dirichlet distribution strength $Q_i$ of the evidence) and **Consensus** (similarity between the annotated match and the model's estimated match). Based on thresholds $\beta_u$ and $\beta_c$, pairs are divided into three subsets: $S_C$ (Clean), $S_I$ (low consensus), and $S_U$ (high uncertainty).
- **Core assumption**: Noisy correspondences inherently exhibit either high uncertainty (lack of supporting evidence) or low consensus (misalignment with the model's belief), allowing them to be statistically distinguished from clean pairs.
- **Evidence anchors**: [section] Section 2.2.3 describes the partitioning of pairs into $S_U$, $S_I$, and $S_C$ using uncertainty and consensus thresholds (Eq. 8). [section] Fig. 3(b) visualizes the reliability distribution, showing clean pairs concentrated at high reliability.
- **Break condition**: If the noise is adversarial such that incorrect pairs have high similarity and "evidence" in the feature space, the uncertainty metric $u_i$ may drop, causing misclassification of noisy pairs into the "Clean" set $S_C$.

### Mechanism 2
- **Claim**: Modifying the optimization objective based on reliability buckets reduces gradient corruption from noisy correspondences.
- **Mechanism**: The **Dually Robust Loss (DRL)** applies tailored strategies to the partitioned subsets. It excludes high-uncertainty pairs ($S_U$) from loss calculation entirely and replaces one-hot labels for low-consensus pairs ($S_I$) with a convex combination of the original label and the model's softmax similarity. This prevents the model from being forced to minimize distance for "incorrect" pairs.
- **Core assumption**: The evidence accumulation process (Dirichlet parameters) is sufficiently sensitive to distinguish mismatched pairs before the model overfits to them.
- **Evidence anchors**: [section] Section 2.3 details the DRL objective (Eq. 11-12) which refines labels $\hat{y}_i$ for the $S_I$ set. [abstract] States the method "prevents overfitting to noisy inter-graph correspondences during inter-graph discrepancy elimination."
- **Break condition**: If the initial feature encoder (e.g., CLIP) produces collapsed embeddings where all similarities are near 1.0, the consensus principle $c_i$ becomes uninformative, rendering the $S_I$ detection ineffective.

### Mechanism 3
- **Claim**: Explicit reasoning via Large Multimodal Models (MLLMs) captures semantic equivalences that embedding similarity misses.
- **Mechanism**: The **Test-time Correspondence Reasoning (TTR)** module prompts an MLLM (e.g., Qwen2.5-VL) to perform Chain-of-Thought (CoT) reasoning on attribute pairs (image/text) to generate a "rethinking score." This score is fused with the initial embedding similarity to rescore candidates, identifying underlying connections (e.g., "Cristiano Ronaldo" and "Portugal") that purely visual/name similarity might miss.
- **Core assumption**: The MLLM possesses sufficient world knowledge and reasoning capability to judge entity equivalence better than the trained metric learning encoder, and the CoT prompt effectively elicits this without hallucination.
- **Evidence anchors**: [section] Section 2.5 describes the TTR module using CoT (Eq. 16) to refine similarity scores. [appendix] Appendix H provides case studies of the reasoning process uncovering latent connections.
- **Break condition**: If the query entity or candidate involves concepts outside the MLLM's knowledge cutoff or involves specialized domain knowledge (e.g., rare molecular structures not in general pre-training), the MLLM may hallucinate or output random scores, degrading retrieval accuracy.

## Foundational Learning

- **Concept: Subjective Logic / Evidential Deep Learning**
  - **Why needed here**: The core uncertainty estimation (Mechanism 1) relies on modeling predictions as Dirichlet distributions rather than point estimates. You must understand that "Uncertainty" $u$ is derived from the strength of the Dirichlet parameters ($u = K/Q$), not just softmax entropy.
  - **Quick check question**: If the evidence vector $e$ is uniform, does uncertainty $u$ increase or decrease? (Answer: It increases as the total strength $Q$ concentrates probability mass on the base rate rather than specific observations).

- **Concept: Noisy Correspondence vs. Noisy Labels**
  - **Why needed here**: Standard label noise assumes independent errors in class labels. This paper addresses *correspondence* noise, where the pairing mechanism (e.g., aligning Entity A to Image B) is broken, creating "False Positive" pairs. The loss function (Eq. 11) is designed specifically for this paired-data structure.
  - **Quick check question**: In a standard Cross-Entropy loss for classification, does swapping the label of a dog to "cat" affect the loss calculation the same way as swapping the *image* of a dog to a cat in a contrastive pair? (Answer: No, contrastive losses rely on the relationship between pairs, which this paper explicitly models).

- **Concept: Chain-of-Thought (CoT) Prompting**
  - **Why needed here**: The Test-time Reasoning module (Mechanism 3) is not just an MLLM query; it uses CoT to force the model to list similarities before concluding. This is crucial for the "Rethinking Score" to be reliable.
  - **Quick check question**: Why is CoT preferred over a direct "Are these similar? Yes/No" prompt for this task? (Answer: To force the model to attend to fine-grained attributes and latent semantic connections, reducing the chance of shallow pattern matching).

## Architecture Onboarding

- **Component map**: CLIP (Vision/Text) + GAT (Structure) -> Initial Embeddings -> Reliability Estimator -> Binning logic ($S_U, S_I, S_C$) -> Dually Robust Fusion -> Dually Robust Loss -> Entity Alignment -> TTR Module
- **Critical path**: The **Reliability Estimator** is the linchpin. If the calculation of $u$ and $c$ is flawed (e.g., temperature $\tau$ in Eq. 2 is poorly tuned), the entire pipeline fails because: 1. $S_C$ (Clean set) will be contaminated, corrupting the loss. 2. $S_I$ (Inconsistent set) will be empty, preventing label correction. 3. Fusion weights $w$ will be random, degrading entity representations.
- **Design tradeoffs**:
  - **MLLM Size**: The paper uses Qwen2.5-VL-72B for best results but notes 3B/7B versions work. The tradeoff is strict latency constraints (Table 13) vs. semantic reasoning depth.
  - **Fusion Logic**: The DRF (Eq. 14) requires a greedy search (Eq. 7) to estimate consensus without labels. This adds computational overhead compared to simple concatenation but is necessary to handle the "Dual-level" noise.
- **Failure signatures**:
  - **"Uncertainty Collapse":** If $Q_i$ grows indefinitely for all pairs, $u_i$ approaches 0 for both clean and noisy pairs. Check the evidence accumulation in Eq. 2; you may need to clamp the temperature $\tau$.
  - **"MLLM Drift":** If TTR scores drop performance, the MLLM is likely confused by the prompt or the visual attributes are too abstract. Check if the CoT output is hallucinating features not present in the image.
- **First 3 experiments**:
  1. **Baseline Sanity Check**: Run the model with the Reliability Estimator disabled (treat all pairs as $S_C$) on the ICEWS-WIKI dataset to quantify the degradation caused by DNC.
  2. **Ablation of Principles**: Run two variants: (A) Only Uncertainty-based binning and (B) Only Consensus-based binning. Compare performance to verify the "Dually Robust" claim (Table 3 results should guide this).
  3. **TTR Thresholding**: Test the TTR module's efficiency vs. accuracy tradeoff. Determine the minimum similarity threshold (Eq. 28) required to trigger the expensive MLLM call without losing Hit@1 gains.

## Open Questions the Paper Calls Out
None explicitly called out in the provided content.

## Limitations
- The computational overhead of the MLLM-based TTR module makes the framework impractical for real-time or large-scale applications without optimization.
- The reliability estimation mechanism may fail if annotation errors are systematic or adversarial, rather than random.
- The framework's performance on specialized domains with rare or abstract entities may be limited by the MLLM's knowledge cutoff.

## Confidence
- **High Confidence**: The core mechanism of using Dirichlet-based uncertainty estimation for correspondence reliability is theoretically sound and aligns with evidential deep learning literature.
- **Medium Confidence**: The effectiveness of the consensus principle in detecting low-consensus noisy pairs is supported by experimental results but may be dataset-dependent.
- **Medium Confidence**: The TTR module's contribution is validated on the test datasets, but its generalizability to domains with specialized or rare entities is uncertain.

## Next Checks
1. **Adversarial Noise Test**: Generate synthetic datasets with systematic annotation errors (e.g., always aligning entities with similar but incorrect attributes) and test whether RULE's reliability estimator fails or adapts.
2. **MLLM Knowledge Cutoff Analysis**: Create test cases involving entities or attributes that emerged after the MLLM's training cutoff (e.g., recent geopolitical events) and measure the degradation in TTR performance.
3. **Cross-Domain Transfer**: Apply RULE to a completely different domain (e.g., molecular structures or legal documents) to assess whether the uncertainty-consensus framework generalizes beyond the evaluated multi-modal knowledge graphs.