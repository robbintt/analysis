---
ver: rpa2
title: 'It Takes Two: A Dual Stage Approach for Terminology-Aware Translation'
arxiv_id: '2511.07461'
source_url: https://arxiv.org/abs/2511.07461
tags:
- terminology
- translation
- target
- term
- lang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DuTerm, a dual-stage system for terminology-aware
  machine translation that combines a fine-tuned NMT model with LLM-based post-editing.
  The approach uses synthetic training data with explicit terminology tags to adapt
  the NMT, then employs an LLM to refine translations and enforce terminology constraints.
---

# It Takes Two: A Dual Stage Approach for Terminology-Aware Translation

## Quick Facts
- **arXiv ID**: 2511.07461
- **Source URL**: https://arxiv.org/abs/2511.07461
- **Reference count**: 19
- **Key outcome**: Dual-stage system combining NMT fine-tuning with LLM post-editing achieves high terminology success rates and strong BLEU scores across English→German, Spanish, and Russian.

## Executive Summary
This paper introduces DuTerm, a dual-stage system for terminology-aware machine translation that combines a fine-tuned NMT model with LLM-based post-editing. The approach uses synthetic training data with explicit terminology tags to adapt the NMT, then employs an LLM to refine translations and enforce terminology constraints. Evaluated on English→German, English→Spanish, and English→Russian using WMT 2025 shared task metrics, DuTerm achieves strong performance: strict terminology enforcement yields BLEU scores of 48.06 (DE), 58.51 (ES), and 35.80 (RU) with near-perfect terminology success rates (≥0.97). The results show that flexible, context-aware LLM post-editing produces higher-quality translations than rigid constraint enforcement, demonstrating the effectiveness of guided refinement over direct generation for terminology-sensitive translation tasks.

## Method Summary
DuTerm employs a two-stage approach: first, an NLLB-200 3.3B model is adapted via fine-tuning on synthetic parallel data generated with GPT-4o, where terminology is wrapped in `[TERM]...[/TERM]` tags. This data is filtered using COMET-QE to ensure quality. The adapted NMT model handles the base translation. Second, GPT-4o post-edits the NMT output using a prompt that includes the source text, the raw NMT output, and explicit terminology mappings. This LLM stage refines fluency and enforces constraints, treating the NMT output as context rather than generating from scratch.

## Key Results
- **High Terminology Success**: Near-perfect terminology success rates (≥0.97) across all language pairs under strict "proper" mode.
- **Strong Translation Quality**: BLEU scores of 48.06 (German), 58.51 (Spanish), and 35.80 (Russian) with LLM post-editing.
- **Flexible vs. Rigid**: LLM post-editing yields higher quality than rigid constraint enforcement, validating the guided refinement approach.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Terminology-aware fine-tuning on tagged synthetic data improves lexical constraint satisfaction in the NMT base model.
- Mechanism: The system generates synthetic parallel corpora where specific terminology is wrapped in unique boundary tags (`[TERM]...[/TERM]`). By extending the NMT model's vocabulary to include these markup tokens and fine-tuning on this data, the model learns to associate the tagged source spans with their required target equivalents, treating the tags as atomic units rather than subword fragments.
- Core assumption: The model can generalize from synthetic context to real-world terminology placement without losing overall translation fluency.
- Evidence anchors:
  - [Section 2.1] "We extend the model's vocabulary with terminology markup tokens to ensure atomic treatment of terminology annotations... preventing subword tokenization from fragmenting our special markup."
  - [Section 2.1] Describes the pipeline of generating single-term and multi-term sentence pairs with strict parsing.
- Break condition: If the synthetic data distribution drifts significantly from the evaluation domain, or if the tag frequency creates bias, the model may overfit to tag insertion at the expense of semantic fidelity.

### Mechanism 2
- Claim: LLM-based post-editing functions more effectively as a context-driven refinement stage than as a primary generator.
- Mechanism: A large language model (GPT-4o) is prompted with the source text, the raw NMT output, and explicit terminology mappings. The LLM leverages its intrinsic linguistic knowledge to resolve ambiguities and adjust morphology (critical for languages like Russian and German) while enforcing the provided constraints, rather than generating the translation from scratch.
- Core assumption: The LLM possesses sufficient multilingual capability to recognize when the NMT output requires correction versus preservation, and follows negative constraints (do not paraphrase away constraints) reliably.
- Evidence anchors:
  - [Abstract] "Our results highlight a critical trade-off, revealing that an LLM's work best for high-quality translation as context-driven mutators rather than generators."
  - [Section 4] "By starting from a reliable NMT translation, the post-editing model receives a structured, partially correct target sentence, which allows it to focus on higher-level improvements..."
  - [Corpus] Related work (TAT-R1) explores RL for terminology reasoning, but this paper relies on in-context prompting.
- Break condition: If the NMT output is too low quality or diverges too far from the source meaning, the LLM may struggle to recover the intent or may hallucinate corrections that invalidate the terminology constraints.

### Mechanism 3
- Claim: Quality filtering of synthetic data prevents the degradation of the NMT model during adaptation.
- Mechanism: The pipeline uses COMET-QE (Quality Estimation) to score generated synthetic pairs and retains only those above a conservative threshold (0.85-0.9), typically keeping 60-70% of the data. This filters out low-quality or hallucinated synthetic examples before they can corrupt the model's weights during fine-tuning.
- Core assumption: COMET-QE scores correlate strongly with the utility of the synthetic data for learning terminology constraints.
- Evidence anchors:
  - [Section 2.1] "Each pair is scored by COMETQE... keeping only high-confidence items using a conservative threshold."
- Break condition: If the quality estimation metric fails to detect subtle semantic errors in the synthetic data, the fine-tuning process may reinforce incorrect terminology usage patterns.

## Foundational Learning

- Concept: **Terminology-Constrained Decoding vs. Training-Time Integration**
  - Why needed here: The paper explicitly contrasts inference-time methods (constrained beam search) with training-time methods (tagged fine-tuning). Understanding this distinction is necessary to grasp why the authors chose a hybrid approach (training-time adaptation + inference-time post-editing) to balance fluency and strict constraint satisfaction.
  - Quick check question: Can you explain why a constrained beam search might produce grammatically awkward output compared to a model fine-tuned on tagged data?

- Concept: **Parameter-Efficient Fine-Tuning (PEFT) / Adaptation**
  - Why needed here: The method adapts a massive multilingual model (NLLB-200 3.3B) without full retraining. Understanding PEFT is required to implement the adaptation step efficiently, ensuring the model learns new tags without catastrophic forgetting of general translation capabilities.
  - Quick check question: Why might full fine-tuning of a 3.3B parameter model be disadvantageous for a task-specific adaptation compared to PEFT?

- Concept: **LLM Post-Editing vs. Zero-Shot Translation**
  - Why needed here: The architecture rejects using the LLM as a direct translator in favor of using it as a post-editor. This requires understanding the prompt engineering necessary to switch the model from "generate" mode to "refine/critique" mode.
  - Quick check question: What specific information must be included in the prompt to ensure the LLM enforces terminology constraints during post-editing?

## Architecture Onboarding

- Component map:
  1. **Data Generator:** GPT-4o (creates tagged synthetic parallel sentences).
  2. **Quality Filter:** COMET-QE model (scores and filters synthetic pairs).
  3. **Base Translator:** NLLB-200 3.3B (adapted via fine-tuning on filtered synthetic data).
  4. **Post-Editor:** GPT-4o (refines NMT output using source, draft, and term mappings).

- Critical path:
  1. Parse terminology dictionaries from development files.
  2. Generate synthetic data (single and multi-term) with `[TERM]` tags.
  3. Filter generated data with COMET-QE (threshold 0.85-0.9).
  4. Extend NLLB-200 vocabulary with markup tokens; fine-tune on filtered data.
  5. Run inference on test set using adapted NMT model.
  6. Pass NMT output + Source + Terms to GPT-4o for post-editing.
  7. Validate final output for tag integrity and terminology exact match.

- Design tradeoffs:
  - **Rigidity vs. Fluency:** Strict enforcement (proper mode) yields higher BLEU/Scores but may reduce flexibility in phrasing. The paper argues the LLM post-editor mitigates this by refining fluency *after* the constraint is placed.
  - **Cost vs. Control:** Using GPT-4o for data generation and post-editing provides high quality but introduces API dependency and latency compared to a pure NMT pipeline.
  - **Synthetic vs. Real Data:** Synthetic data allows control over term coverage but risks distributional bias.

- Failure signatures:
  - **Tag Fragmentation:** If the vocabulary extension fails, subword tokenizers split `[TERM]` tags, breaking the training signal. *Check: Verify tokenizer merges the tags into single IDs.*
  - **Prompt Drift:** If the post-editing prompt is not explicit, the LLM may paraphrase the sentence and remove the required terminology.
  - **Mode Collapse:** If synthetic data is low quality or too repetitive, the NMT may only output sentences containing tags, failing on general text.

- First 3 experiments:
  1. **Vocabulary Validation:** Before fine-tuning, verify that the tokenizer correctly maps `[TERM]` and `[/TERM]` to single, unique token IDs and that these IDs are correctly added to the model's embedding layer.
  2. **Synthetic Data Ablation:** Train two versions of the NMT adapter: one with the COMET-QE filtered data and one with raw synthetic data. Compare terminology success rates to confirm the filtering mechanism is causal to performance.
  3. **Post-Edit Isolation Test:** Take a small set of human-validated translations (without terminology constraints) and run them through the LLM post-editor with and without terminology lists. Measure if the LLM introduces errors (over-editing) when no edits are required.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive learning mechanisms that integrate terminology dynamically outperform the static prompt-based constraints used in the current DuTerm architecture?
- Basis in paper: [explicit] The Conclusion suggests "exploring adaptive learning mechanisms that integrate terminology dynamically, rather than relying on static prompts, could enhance robustness across domains and languages."
- Why unresolved: The current system relies on carefully crafted, static prompts which the authors admit may not generalize well across all domains or changing contexts.
- What evidence would resolve it: Comparative experiments where the system uses dynamic retrieval or adaptive tuning for terminology insertion compared against the static prompt baseline.

### Open Question 2
- Question: Do memory-augmented or end-to-end architectures provide better document-level consistency than the proposed sentence-level, dual-stage pipeline?
- Basis in paper: [explicit] The Conclusion states that "End-to-end or memory-augmented architectures that maintain consistency across sentences and documents hold promise for more coherent outputs," acknowledging the current limitation to sentence-level processing.
- Why unresolved: The current implementation processes text sentence-by-sentence, limiting its ability to maintain context or terminology consistency over longer documents.
- What evidence would resolve it: Evaluation of DuTerm variants equipped with document-level context windows or memory modules on a dataset specifically designed to test cross-sentence terminology consistency.

### Open Question 3
- Question: Do human evaluators validate the paper's finding that flexible, context-driven terminology handling yields higher quality translations than strict constraint enforcement?
- Basis in paper: [explicit] The Limitations section notes that while automated metrics like BLEU and COMETQE were used, they "may not fully reflect terminological precision and contextual appropriateness, suggesting the need for complementary evaluation methods that include human judgment."
- Why unresolved: The trade-off between fluency and rigid terminology enforcement is complex, and automated metrics may not capture nuances like contextual awkwardness caused by strict enforcement.
- What evidence would resolve it: A human evaluation study measuring adequacy and fluency specifically on the subsets where the "proper" (strict) mode outperformed the "random" or "noterm" modes in BLEU but potentially failed in naturalness.

### Open Question 4
- Question: Does the reliance on GPT-4o for both synthetic data generation and post-editing introduce specific biases that fail to generalize to other LLMs or NMT architectures?
- Basis in paper: [inferred] The Method section describes using GPT-4o to generate synthetic training data and then using GPT-4o again for post-editing. The Limitations section adds that evaluation was "conducted solely on GPT-4o," restricting generalizability.
- Why unresolved: Using the same model to create the training signal (synthetic data) and the final output (post-editing) creates a closed loop that might mask failure cases visible only when using different model families.
- What evidence would resolve it: Ablation studies using a different model (e.g., Llama 3 or Mistral) for either the synthetic data generation or the post-editing stage to test for performance degradation.

## Limitations

- **Synthetic Data Quality and Domain Fit**: The method relies heavily on GPT-4o-generated synthetic data with terminology tags. While COMET-QE filtering is applied, there is no guarantee that the synthetic distribution perfectly matches the test domain or that the filtering captures semantic fidelity.
- **LLM Post-Editing Consistency**: The use of GPT-4o as a post-editor introduces variability that is difficult to control. The paper assumes the LLM will reliably follow constraints and negative instructions, but LLMs can exhibit prompt sensitivity and mode collapse.
- **Evaluation Granularity**: While the paper reports strict terminology success rates, it does not provide detailed breakdowns by term frequency, morphological complexity, or error type, limiting the ability to diagnose failure sources.

## Confidence

**High Confidence**:
- The dual-stage architecture (fine-tuned NMT + LLM post-editing) is technically sound and the general mechanism for terminology enforcement via tagged synthetic data is well-established.
- The reported BLEU and terminology success rates are internally consistent with the described pipeline and evaluation setup.

**Medium Confidence**:
- The superiority of LLM post-editing over direct generation is supported by the results but lacks ablation studies isolating the contribution of each stage.
- The claim that flexible LLM refinement outperforms rigid constraint enforcement is plausible but not rigorously proven across all test cases.

**Low Confidence**:
- The exact reproducibility of results given unspecified hyperparameters (LoRA rank, training epochs, decoding settings).
- The robustness of the system to terminology outside the synthetic training distribution or to ambiguous multi-word expressions.

## Next Checks

1. **Synthetic Data Ablation Study**: Train and evaluate the NMT model with and without COMET-QE filtering on the synthetic data. Compare terminology success rates and fluency metrics to confirm that filtering is the causal factor in performance, not just dataset size or randomness.

2. **Post-Editing Isolation Test**: Take a small set of human-validated translations (without terminology constraints) and run them through the LLM post-editor with and without terminology lists. Measure if the LLM introduces errors (over-editing) when no edits are required, and quantify the frequency of terminology constraint violations.

3. **Out-of-Distribution Terminology Test**: Evaluate the system on a held-out set of terminology pairs not present in the synthetic training data. Measure terminology success rates and BLEU scores to assess the model's ability to generalize to unseen terms, and identify failure patterns (e.g., morphological errors, paraphrase drift).