---
ver: rpa2
title: 'Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks'
arxiv_id: '2507.23194'
source_url: https://arxiv.org/abs/2507.23194
tags:
- code
- kernels
- test
- geak
- triton
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GEAK, a framework for generating efficient
  Triton GPU kernels using large language models with agentic feedback mechanisms.
  GEAK employs a multi-agent system that iteratively refines code using sequential
  and parallel scaling of inference-time compute, combined with Reflexion-style debugging.
---

# Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks

## Quick Facts
- arXiv ID: 2507.23194
- Source URL: https://arxiv.org/abs/2507.23194
- Reference count: 40
- Key outcome: GEAK achieves up to 63.33% execution accuracy and 2.59x speedup on TritonBench-revised using multi-agent LLM framework with iterative refinement

## Executive Summary
This paper introduces GEAK, a framework for generating efficient Triton GPU kernels using large language models with agentic feedback mechanisms. GEAK employs a multi-agent system that iteratively refines code using sequential and parallel scaling of inference-time compute, combined with Reflexion-style debugging. The authors evaluate GEAK on two benchmark suites: a revised subset of TritonBench-G (184 kernels) and a new ROCm Triton benchmark (30 real-world kernels). Results show that GEAK significantly outperforms direct LLM prompting, achieving execution accuracy of up to 63.33% and speedups of up to 2.59x on TritonBench-revised. The authors also present an ablation study demonstrating the effectiveness of sequential and parallel scaling, as well as the importance of individual modules like knowledge injection and optimization.

## Method Summary
GEAK is a multi-agent framework that generates efficient Triton GPU kernels from task descriptions using iterative refinement. The system consists of four modules: Generator (creates initial kernel with knowledge injection and one-shot examples), Reflector (analyzes error traces and proposes fixes), Evaluator (tests functionality and performance), and Optimizer (improves execution speed). The framework uses sequential scaling (multiple refinement iterations) and parallel scaling (diverse independent runs) to improve both correctness and performance. It targets AMD GPUs (MI250, MI300X) and was tested with GPT-4.1, Gemini 2.5 Pro, and Claude 3.7 Sonnet.

## Key Results
- GEAK achieves 63.33% execution accuracy and 2.59x median speedup on TritonBench-revised (184 kernels), significantly outperforming direct LLM prompting
- Sequential scaling shows monotonic improvement: call accuracy improves from 21.2% (iter0) to 63.04% (iter19), execution accuracy from 13.04% to 44.02% on MI250
- Knowledge injection + one-shot + Optimizer configuration achieves 56.52% call accuracy vs 14.67% for direct prompting on MI250

## Why This Works (Mechanism)

### Mechanism 1: Inference-Time Compute Scaling via Sequential Refinement
Allocating additional compute during inference through iterative refinement improves both correctness and performance of generated kernels. The system runs multiple sequential iterations where each iteration receives feedback from prior attempts. Call accuracy improved from 21.2% (iter0) to 63.04% (iter19), and execution accuracy from 13.04% to 44.02% on MI250. Core assumption: LLMs can self-correct when provided with execution feedback, and errors are discoverable through test failures.

### Mechanism 2: Reflexion-Style Error Feedback with Debugging Trap Mitigation
Verbalized feedback from execution errors enables iterative debugging, but requires explicit limits to prevent infinite loops. When generated code fails functionality tests, the error trace is provided to the Reflector module for analysis. A `max_perf_debug_num` parameter prevents the "debugging trap" where the same bug persists across cycles. Core assumption: Error traces contain sufficient information for the LLM to identify root causes.

### Mechanism 3: Domain Knowledge Injection Combined with Code-Similarity Retrieval
Injecting hardware-specific optimization knowledge and retrieving similar code examples significantly improves generation quality over zero-shot prompting. Knowledge injection provides detailed hardware specifications and optimization principles. One-shot prompting retrieves similar Triton code based on code similarity (not instruction similarity), providing structural templates. Core assumption: LLMs have latent capability for kernel generation but lack domain-specific knowledge.

## Foundational Learning

- Concept: Triton DSL Memory Model
  - Why needed here: Understanding block-level programming, shared memory, and coalesced access patterns is essential for interpreting GEAK's optimization strategies
  - Quick check question: Can you explain why loading an entire block then flipping in registers is slower than direct flipped-address loading?

- Concept: Inference-Time Compute Scaling
  - Why needed here: GEAK's core innovation is trading compute for quality at inference time rather than training time
  - Quick check question: What is the difference between sequential scaling (more iterations) and parallel scaling (more independent runs), and when would each be preferred?

- Concept: Reflexion and Verbal Reinforcement
  - Why needed here: The feedback loop depends on converting execution traces into actionable insights
  - Quick check question: What types of GPU errors would be difficult to diagnose from error traces alone, potentially causing reflection to fail?

## Architecture Onboarding

- Component map: User Query → [Generator] → Draft Code → [Evaluator: Functionality Test] → Pass/Fail + Error Trace → [Reflector] → [Evaluator: Performance Test] → [Optimizer] → Refined Code (loop or output)

- Critical path:
  1. Generator produces initial kernel from query + knowledge injection + 1-shot example
  2. Evaluator runs functionality tests; failures trigger Reflector
  3. Reflector analyzes error trace, proposes fix, regenerates
  4. If functionality passes, Evaluator measures performance
  5. Optimizer proposes performance improvements based on historical results
  6. Debugging trap check: if iterations > `max_perf_debug_num`, discard and restart

- Design tradeoffs:
  - Sequential vs. parallel scaling: Sequential provides deeper refinement per kernel; parallel provides diversity and pass@k reliability
  - Knowledge injection scope: More domain knowledge improves accuracy but may overfit to specific hardware
  - Test coverage vs. evaluation speed: ROCm benchmark has thorough tests (higher confidence); TritonBench-revised has limited coverage (potential false positives)

- Failure signatures:
  - Debugging trap: Same error persists across 5+ reflection cycles (mitigated by `max_perf_debug_num`)
  - Low speedup despite correctness: Generated code is functionally correct but under-optimized
  - False positive passes: Kernels pass limited tests but fail on edge cases

- First 3 experiments:
  1. Baseline reproduction: Run direct prompting with GPT-4.1 on 10 kernels from TritonBench-revised to establish baseline accuracy (<15% expected)
  2. Sequential scaling ablation: Run GEAK with 1, 5, 10, 15 iterations on same 10 kernels. Plot accuracy vs. iterations to validate monotonic improvement claim
  3. Module ablation: Test configurations: (a) knowledge injection only, (b) knowledge + one-shot, (c) full system with Optimizer. Compare call accuracy, execution accuracy, and speedup to isolate each module's contribution

## Open Questions the Paper Calls Out

### Open Question 1
Can automated test generation (e.g., mutation-based or LLM-guided) be integrated into the evaluation loop to improve test coverage beyond the limitations of current manual benchmarks? Current benchmarks like TritonBench-revised rely on manually curated tests which may not exercise all edge cases, whereas AI-generated tests struggle to achieve high coverage themselves.

### Open Question 2
Does sequential inference-time scaling suffer from diminishing or negative returns on performance optimization (speedup) even as it improves functional correctness? While execution accuracy increases monotonically with iterations, the speedup metric fluctuates significantly, suggesting a trade-off not fully explained by the "debugging trap."

### Open Question 3
How robust is the "Knowledge Injection" module when applied to novel GPU architectures not explicitly detailed in the prompt's hardware documentation? It is unclear if the agent learns general optimization principles or simply retrieves patterns from the injected text, limiting portability to unreleased hardware.

## Limitations
- Debugging effectiveness is limited by quality of error trace interpretation - cryptic GPU errors may cause reflection to fail
- Evaluation reliability constrained by test coverage - TritonBench-revised has limited tests raising false positive concerns
- Module interactions may not be fully captured - knowledge injection might work better with certain LLM models or kernel types

## Confidence
- **High**: Sequential scaling mechanism showing monotonic improvement in accuracy with iterations is well-supported by Table 5 and cross-validated by similar iterative approaches
- **Medium**: Reflexion debugging effectiveness claim relies heavily on verbalized error traces which may not always provide sufficient information for root cause identification
- **Medium**: Domain knowledge injection and code-similarity retrieval effectiveness is demonstrated through ablation results but specific content and datasets are not fully specified

## Next Checks
1. Debugging trap analysis: Track error trace patterns across 20 iterations on 5 diverse kernels to verify whether the same errors persist despite reflection cycles
2. Cross-model generalization: Test GEAK with Gemini 2.5 Pro and Claude 3.7 Sonnet on the same kernel set to verify whether improvements are consistent across different LLM architectures
3. Test coverage validation: Run generated kernels on additional edge cases not included in the benchmark tests to measure false positive rates and verify practical reliability of evaluation framework