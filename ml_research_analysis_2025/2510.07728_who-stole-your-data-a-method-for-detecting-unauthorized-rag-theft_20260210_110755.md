---
ver: rpa2
title: Who Stole Your Data? A Method for Detecting Unauthorized RAG Theft
arxiv_id: '2510.07728'
source_url: https://arxiv.org/abs/2510.07728
tags:
- watermarking
- content
- detection
- token
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RPD, a dataset for RAG plagiarism detection
  that simulates real-world information redundancy, and proposes a dual-layered watermarking
  system combining knowledge-based and token-distribution techniques. Experiments
  show the approach achieves perfect detection accuracy (100%) across multiple LLMs
  even with factual redundancy, while baselines fail under similar conditions.
---

# Who Stole Your Data? A Method for Detecting Unauthorized RAG Theft

## Quick Facts
- arXiv ID: 2510.07728
- Source URL: https://arxiv.org/abs/2510.07728
- Authors: Peiyang Liu; Ziqiang Cui; Di Liang; Wei Ye
- Reference count: 40
- This paper introduces RPD, a dataset for RAG plagiarism detection that simulates real-world information redundancy, and proposes a dual-layered watermarking system combining knowledge-based and token-distribution techniques. Experiments show the approach achieves perfect detection accuracy (100%) across multiple LLMs even with factual redundancy, while baselines fail under similar conditions. Adversarial tests confirm the method's resilience, with accuracy dropping only to 50% for one baseline when targeted rewriting is applied, versus 100% for the proposed method. Quality assessments indicate minimal degradation in text quality (overall score ~8.57/10) while maintaining strong detection capability.

## Executive Summary
This paper addresses the challenge of detecting when an adversary steals proprietary data through RAG systems by proposing a dual-layered watermarking approach. The method combines knowledge-based watermarks (embedding semantically coherent facts) with token-distribution watermarks (manipulating vocabulary selection) to create robust detection signals. A novel interrogator-detective framework uses statistical hypothesis testing to accumulate evidence across multiple queries, achieving 100% detection accuracy even under factual redundancy conditions where baseline methods fail. The approach is validated on a newly created RPD dataset that simulates real-world information redundancy through multiple author simulations and LLMs.

## Method Summary
The proposed method implements a dual-layered watermarking system that embeds detection signals into documents at both semantic and lexical levels. The knowledge-based layer selects watermarks that maximize coherence and distinctiveness, while the token-distribution layer modifies logits to bias selection toward specific token subsets. An interrogator generates targeted queries that force retrieval of watermarked content, and a detective applies z-tests to accumulated responses to determine if the system has been compromised. The approach is tested on the RPD dataset with 12,000 entries featuring controlled redundancy, demonstrating perfect detection accuracy against multiple evasion strategies.

## Key Results
- Dual-layer watermarking achieves 100% detection accuracy across multiple LLMs even with factual redundancy
- Method maintains effectiveness against adversarial rewriting, with only 50% accuracy drop for one baseline under targeted attacks
- Minimal quality degradation observed (overall score ~8.57/10) while preserving detection capability
- Statistical hypothesis testing accumulates weak signals across queries to reach detection confidence thresholds
- RPD dataset demonstrates real-world redundancy challenges that break baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-layered watermarking (semantic + lexical) provides detection signals that survive LLM reformulation.
- Mechanism: Knowledge-based watermarks embed semantically coherent facts into documents; red-green token distribution manipulation biases token selection toward "green" tokens during regeneration. The watermark signal weakens through RAG pipeline propagation, but the interrogator's strategic queries force retrieval of watermarked content, allowing accumulated signals to exceed statistical thresholds.
- Core assumption: Adversaries cannot simultaneously filter watermarked documents AND comprehensively rewrite content without degrading utility or missing the semantic information needed to answer queries.
- Evidence anchors:
  - [abstract] "dual-layered watermarking system combining knowledge-based and token-distribution techniques"
  - [section 4.1] Knowledge-based layer selects watermarks maximizing coherence and distinctiveness (Eq. 3); token distribution layer modifies logits with bias δ toward green tokens (Eq. 5-6)
  - [corpus] Related work (RAG-WM, WARD) confirms watermarking as a viable RAG protection approach, though corpus lacks direct comparison to dual-layer methods
- Break condition: If adversaries use LLMs to detect incoherent facts and avoid suspicious documents, knowledge-based watermarks degrade (70-90% accuracy per Table 4); if adversaries rewrite completely, token distribution watermarks fail (50% accuracy per Table 4).

### Mechanism 2
- Claim: Interrogator-generated queries target unique knowledge combinations, making evasion require access to watermarked content.
- Mechanism: The interrogator crafts queries that can only be answered correctly by retrieving watermarked documents. Queries maximize the probability gap between RAG systems with vs. without watermarked data (Eq. 8). The detective applies z-tests to accumulated responses, checking if response accuracy exceeds chance thresholds.
- Core assumption: The interrogator can generate queries that require the specific combination of watermarked facts, not just generic domain knowledge available elsewhere.
- Evidence anchors:
  - [abstract] "interrogator-detective framework that employs statistical hypothesis testing on accumulated evidence"
  - [section 4.2.1] Ideal interrogation query maximizes P(A_correct|RAG with D_dual, Q) - P(A_correct|RAG without D_dual, Q)
  - [corpus] Weak corpus support—no direct citations for interrogator-based detection strategies in RAG contexts
- Break condition: If factual redundancy allows non-watermarked documents to answer queries, false positives increase (AAG and Facts methods fail at 50% accuracy under redundancy per Table 2).

### Mechanism 3
- Claim: Statistical hypothesis testing accumulates weak signals across multiple queries to reach detection confidence.
- Mechanism: Individual watermark signals weaken during RAG processing. Multiple queries aggregate evidence: S_fact measures proportion of responses containing watermarked knowledge (Eq. 9); Z_token measures standardized deviation from expected token distribution (Eq. 12). Combined decision rejects H₀ if either statistic exceeds threshold.
- Core assumption: Signal accumulation is linear or near-linear; watermark signals do not cancel out or degrade non-linearly across queries.
- Evidence anchors:
  - [section 4.2.2] "The Detective combines evidence from both watermarking layers to make a final determination" with dual-criteria decision rule (Eq. 13)
  - [section 6.2.1] Figure 3a shows S_fact stabilizing at 0.88 (above threshold τ_fact=0.86) for watermarked datasets, remaining at 0.53 (below threshold) for non-watermarked
  - [corpus] Limited corpus evidence on multi-query aggregation in RAG detection
- Break condition: If query volume is too low, signals remain below thresholds (Figure 3 shows gradual increase requiring ~20+ responses for stable detection).

## Foundational Learning

- Concept: **Watermark detection vs. robustness tradeoff**
  - Why needed here: Higher bias strength δ improves detection but degrades text quality (creativity, depth). The paper identifies δ=4.0 as optimal threshold.
  - Quick check question: If you increase δ from 4.0 to 6.0, what happens to P-SP score and overall quality? (Answer: P-SP drops from 0.973 to 0.890, quality from 8.76 to 7.82 per Figure 5)

- Concept: **Factual redundancy problem in RAG detection**
  - Why needed here: Multiple documents may contain similar facts expressed differently, making source attribution ambiguous. Methods like AAG and Facts achieve 100% accuracy without redundancy but drop to 50% with redundancy (Table 2).
  - Quick check question: Why does the Facts method produce 100% false positives under factual redundancy? (Answer: Non-watermarked documents can answer queries using similar information from other sources)

- Concept: **Red-green list watermarking mechanics**
  - Why needed here: Vocabulary partition using seeding function h determines which tokens are "green." Modified logits bias selection toward green tokens (Eq. 5). Detection counts green token frequency.
  - Quick check question: What is the expected green token proportion under H₀ (no watermark)? (Answer: ~0.5, per Eq. 12 analysis)

## Architecture Onboarding

- Component map:
  - Dataset Generation (RPD): repliqa source → fact/relation extraction → author pool simulation → multi-model article generation → 12,000 entries with controlled redundancy
  - Watermarking Pipeline: Unprotected document → Layer 1 (knowledge-based embedding via semantic similarity, Eq. 1-3) → Layer 2 (red-green token regeneration with bias δ=4.0, γ=0.25, Eq. 4-6) → Dual-watermarked document
  - Detection Pipeline: Interrogator generates targeted queries → Suspected RAG system returns responses → Detective computes S_fact and Z_token → Hypothesis test (α=0.005) → Decision

- Critical path:
  1. Watermark selection: Candidate facts must satisfy τ_sim < similarity < τ_ident (Eq. 2) to balance coherence and distinctiveness
  2. Query generation: Must maximize probability gap (Eq. 8)—poor queries fail to discriminate
  3. Signal accumulation: Insufficient query volume prevents reaching detection thresholds (Figure 3)

- Design tradeoffs:
  - Detection strength vs. text quality: δ controls this tradeoff; δ≥4.0 required for reliable detection, δ≤4.0 preserves quality (Figure 5)
  - Knowledge-based vs. token distribution: Knowledge watermarks resist rewriting but vulnerable to filtering; token watermarks resist filtering but vulnerable to rewriting (Table 4)
  - Query specificity vs. coverage: Highly specific queries better discriminate but may not be answerable if retrieval fails

- Failure signatures:
  - High false positives under factual redundancy (100% FP for AAG/Facts in Table 2) → Interrogator queries too generic
  - Accuracy drops to 50% under token distribution evasion (WARD in Table 3) → Missing knowledge-based backup layer
  - Detection fails at low query volumes (Figure 3) → Insufficient signal accumulation

- First 3 experiments:
  1. **Verify watermark survival through RAG**: Index watermarked documents in a RAG system, retrieve with standard queries, check if regenerated outputs retain detectable signals (S_fact, Z_token)
  2. **Test redundancy robustness**: Create datasets with varying fact overlap levels (0%, 25%, 50%, 75%), measure accuracy degradation for each method
  3. **Stress-test adversarial scenarios**: Apply both evasion strategies (knowledge watermark filtering, token distribution rewriting) simultaneously against dual-layer method; verify complementary protection holds

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can adaptive watermarking configurations (e.g., dynamic δ selection based on content type) improve the quality-security tradeoff for stylistically sensitive domains like creative writing?
- **Basis in paper:** [explicit] Section 6.8.5 states: "Different content types may benefit from customized δ values—more creative or stylistically sensitive content might use lower values, while technical or factual content could tolerate higher values."
- **Why unresolved:** Only fixed δ=4.0 was tested; adaptive schemes were suggested but not implemented or evaluated.
- **What evidence would resolve it:** Experiments comparing fixed vs. adaptive δ across diverse content types, measuring detection accuracy and creativity scores.

### Open Question 2
- **Question:** How does detection performance scale when the watermarked corpus grows beyond 200 documents to production-scale sizes (e.g., millions of documents)?
- **Basis in paper:** [inferred] Experiments used only 200 watermarked documents (Section 6.4); retrieval dynamics and statistical power may change at larger scales.
- **Why unresolved:** No experiments conducted on larger corpora; statistical accumulation assumptions may not hold with increased noise.
- **What evidence would resolve it:** Experiments on corpora with orders of magnitude more documents, measuring detection accuracy and query requirements.

### Open Question 3
- **Question:** Does the dual-layered approach maintain effectiveness against combined adversarial strategies that simultaneously target both watermark layers?
- **Basis in paper:** [inferred] Adversarial experiments (Section 6.5) test knowledge evasion and token distribution evasion separately; combined attacks remain unexplored.
- **Why unresolved:** Sequential integration protects against individual attacks, but adversaries may employ multi-pronged evasion.
- **What evidence would resolve it:** Experiments applying both evasion techniques simultaneously, measuring whether synergistic protection degrades.

### Open Question 4
- **Question:** Can the method generalize to non-English languages and cross-lingual RAG systems?
- **Basis in paper:** [inferred] The RPD dataset and all experiments are English-only; token distribution patterns may not transfer across languages with different vocabularies and tokenization.
- **Why unresolved:** No multilingual evaluation; knowledge-based watermarks may also face cultural context challenges.
- **What evidence would resolve it:** Experiments on multilingual corpora, testing detection accuracy across languages and mixed-language RAG systems.

## Limitations
- Dataset representativeness: The RPD dataset uses 10 writers, 5 LLMs, and 12,000 entries with controlled redundancy, but real-world data diversity far exceeds this setup.
- Query generation dependency: The interrogator's effectiveness hinges on query generation algorithms that maximize detection probability gaps, which lack empirical validation across diverse domains.
- Baseline selection: Key competitors (WARD, RAG-WM) are cited but not directly compared in main experiments, limiting performance claims.

## Confidence
- **High confidence**: The dual-layer watermarking mechanism demonstrates strong empirical performance (100% detection accuracy) in controlled experimental conditions.
- **Medium confidence**: Claims about resilience against adversarial rewriting hold under specific attack scenarios tested, but comprehensive adversarial testing is limited.
- **Low confidence**: Generalization claims to real-world deployment scenarios lack empirical support, particularly for larger document collections and diverse data sources.

## Next Checks
1. **Real-world deployment simulation**: Test the dual-layer watermarking system on a production-scale RAG system with millions of documents from diverse sources, measuring detection accuracy, false positive rates, and computational overhead under realistic query loads.
2. **Comprehensive adversarial testing**: Implement and evaluate all combinations of evasion strategies (document filtering, content rewriting, query obfuscation, system manipulation) simultaneously against the dual-layer method to identify potential attack vectors.
3. **Cross-domain transferability**: Apply the method to non-news domains (legal documents, medical records, technical manuals) and evaluate whether the interrogator can generate effective queries and the watermarking layers maintain their protective properties across different content types.