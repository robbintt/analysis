---
ver: rpa2
title: Synthesising Counterfactual Explanations via Label-Conditional Gaussian Mixture
  Variational Autoencoders
arxiv_id: '2510.04855'
source_url: https://arxiv.org/abs/2510.04855
tags:
- input
- latent
- l-gmv
- each
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LAPACE, a method for generating counterfactual
  explanations that are robust to input and model perturbations while satisfying plausibility
  and diversity. The core idea is to train a Label-conditional Gaussian Mixture Variational
  Autoencoder (L-GMVAE) that learns a structured latent space where each class is
  represented by multiple Gaussian clusters.
---

# Synthesising Counterfactual Explanations via Label-conditional Gaussian Mixture Variational Autoencoders

## Quick Facts
- arXiv ID: 2510.04855
- Source URL: https://arxiv.org/abs/2510.04855
- Reference count: 17
- Primary result: LAPACE achieves perfect robustness to input changes and strong performance across eight quantitative metrics

## Executive Summary
This paper proposes LAPACE, a method for generating counterfactual explanations that are robust to input and model perturbations while satisfying plausibility and diversity. The core idea is to train a Label-conditional Gaussian Mixture Variational Autoencoder (L-GMVAE) that learns a structured latent space where each class is represented by multiple Gaussian clusters. LAPACE then generates paths of counterfactuals by interpolating from an input's latent representation to the learned cluster centroids of the target class. This design inherently ensures robustness to input perturbations (all paths converge to the same fixed centroids) and provides diverse recourse options. The method is model-agnostic, computationally efficient, and supports actionability constraints via gradient optimization.

## Method Summary
LAPACE generates counterfactual explanations through a two-stage process. First, it trains a Label-conditional Gaussian Mixture Variational Autoencoder (L-GMVAE) on the original data and classifier predictions. The L-GMVAE learns a structured latent space where each class is represented by multiple Gaussian clusters, with cluster centroids serving as exemplars for each class. Second, given an input and target class, LAPACE performs gradient-based optimization to find a latent representation that minimizes distance to the target class cluster while respecting actionability constraints. It then generates a path of counterfactuals by interpolating between the optimized latent point and the target cluster centroid. The method ensures robustness by design - since all paths converge to fixed cluster centroids rather than being recalculated for each input, the generated counterfactuals remain stable under input perturbations and model retraining.

## Key Results
- LAPACE achieves perfect robustness to input perturbations across all datasets
- The method outperforms state-of-the-art baselines on eight quantitative metrics including validity, proximity, plausibility, diversity, and robustness
- LAPACE shows strong performance in model-change robustness, with accuracy drop of only 0.1-2.2% when tested on synthetic data after retraining
- The method successfully generates actionable and diverse counterfactuals across eight different tabular and image datasets

## Why This Works (Mechanism)
LAPACE's effectiveness stems from its use of a structured latent space where class clusters are explicitly modeled as Gaussian distributions. By learning these clusters during VAE training, the method ensures that each class has multiple representative points (centroids) that capture the underlying data distribution. The interpolation approach between an input's latent representation and target cluster centroids naturally produces diverse counterfactuals while maintaining plausibility, as the paths stay within learned data manifolds. The design inherently provides robustness because the target centroids are fixed during generation, making the output independent of small input perturbations or model retraining. This eliminates the instability common in gradient-based methods that recalculate paths for each query.

## Foundational Learning
- **Variational Autoencoders (VAEs)**: Probabilistic generative models that learn latent representations by maximizing evidence lower bound (ELBO). Why needed: Provides the foundation for learning structured latent spaces. Quick check: VAEs should learn meaningful latent representations that preserve data structure.
- **Gaussian Mixture Models (GMMs)**: Probabilistic models representing data as mixture of Gaussian distributions. Why needed: Enables modeling complex class distributions with multiple clusters per class. Quick check: GMM components should capture distinct modes in the data distribution.
- **Counterfactual Explanations**: Perturbations of input features that change model prediction while maintaining plausibility. Why needed: The core problem LAPACE addresses. Quick check: Generated examples should be valid, actionable, and meaningful.
- **Robustness to Perturbations**: Stability of generated explanations under input or model changes. Why needed: Ensures reliability of counterfactuals in real-world applications. Quick check: Small input changes should not drastically alter generated explanations.
- **Actionability Constraints**: Limitations ensuring generated counterfactuals respect real-world constraints. Why needed: Makes counterfactuals practically implementable. Quick check: Generated features should respect specified actionability requirements.

## Architecture Onboarding

Component Map: Input Data -> L-GMVAE (Encoder -> Latent Space -> GMM Clustering -> Decoder) -> Counterfactual Generation (Gradient Optimization -> Interpolation Path)

Critical Path: Data preprocessing → L-GMVAE training → Cluster centroid identification → Counterfactual generation for each query

Design Tradeoffs:
- Fixed centroids provide robustness but may limit adaptability to complex class boundaries
- Multiple clusters per class ensure diversity but increase computational complexity
- Interpolation paths ensure smooth transitions but may miss sharp decision boundaries

Failure Signatures:
- Poor VAE reconstruction quality indicates latent space misalignment with data manifold
- High reconstruction loss on test data suggests overfitting to training distribution
- Generated counterfactuals violating actionability constraints indicate optimization issues

First Experiments:
1. Test L-GMVAE reconstruction quality on held-out data to verify latent space quality
2. Verify cluster separation using silhouette scores on latent representations
3. Validate actionability constraints by checking generated features against specified limits

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can dataset-level causal constraints be effectively integrated into the L-GMVAE architecture to ensure generated counterfactuals respect causal dependencies between features?
- Basis in paper: [explicit] The conclusion identifies future work in "synthetic tabular data generation," suggesting "dataset-level causal requirements between features (beyond user-specified actionability requirements) can be incorporated, possibly through adding specialised neural network layers."
- Why unresolved: The current implementation supports user-specified actionability constraints via gradient optimization, but it does not inherently model or enforce causal relationships during the generation process.
- What evidence would resolve it: A modification of the L-GMVAE decoder or loss function that explicitly incorporates a causal graph, validated by showing that generated counterfactuals maintain causal consistency on standard causal inference benchmarks.

### Open Question 2
- Question: How can the structured latent manifold learned by L-GMVAE be utilized to derive region-based explanations for sub-groups of data rather than single point-based counterfactuals?
- Basis in paper: [explicit] The authors state in the conclusion that the "Gaussian mixture-regularised latent space... offers a powerful tool" for "region-based explanations, providing insights into the model's behaviour for entire sub-groups."
- Why unresolved: The current LAPACE algorithm focuses exclusively on generating interpolation paths for individual inputs; the methodology for aggregating these into collective, region-based recourse is undeveloped.
- What evidence would resolve it: An algorithm that maps clusters of input data to regions in the latent space and provides a summarized explanation or recourse path applicable to the entire group.

### Open Question 3
- Question: How can the L-GMVAE framework be adapted to improve performance on datasets with a high proportion of categorical features?
- Basis in paper: [explicit] The conclusion acknowledges a limitation: "our L-GMVAE is less effective on datasets with a large number of categorical features, as is reflected in utility results."
- Why unresolved: The current architecture uses standard Gaussian priors and simple one-hot encoding handling, which appears insufficient for modeling complex discrete distributions effectively.
- What evidence would resolve it: Demonstrating improved Train on Synthetic, Test on Real (TSTR) accuracy and lower reconstruction loss on heterogeneous datasets (like 'adult') compared to the reported baseline.

## Limitations
- Assumes class clusters in latent space can be well-represented by Gaussian distributions, which may not hold for complex decision boundaries
- Performance degrades on datasets with high proportion of categorical features due to inadequate handling of discrete distributions
- Reliance on VAE training quality introduces uncertainty about performance across different data types and distributions
- Assumes cluster centroids represent good counterfactual examples, which may not always align with human intuition

## Confidence

**High Confidence**: The core methodology of using L-GMVAE for structured latent space learning and centroid-based counterfactual generation is technically sound and well-explained

**Medium Confidence**: The quantitative results comparing LAPACE to baselines are reliable, though the choice of evaluation metrics and their relative importance could be debated

**Medium Confidence**: The robustness claims are supported by experiments but would benefit from more extensive real-world validation

## Next Checks

1. Test LAPACE on datasets with known multimodal class distributions to evaluate whether the Gaussian mixture assumption holds and whether the method can capture complex class structures

2. Conduct user studies to validate whether the generated counterfactuals are interpretable and meaningful to domain experts, particularly for high-stakes applications

3. Evaluate performance when the underlying model is retrained with different architectures or hyperparameters to assess true model-agnostic robustness beyond the tested scenarios