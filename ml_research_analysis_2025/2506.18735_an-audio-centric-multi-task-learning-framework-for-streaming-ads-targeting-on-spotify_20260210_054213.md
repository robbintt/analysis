---
ver: rpa2
title: An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting
  on Spotify
arxiv_id: '2506.18735'
source_url: https://arxiv.org/abs/2506.18735
tags:
- video
- audio
- task
- stream
- slots
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces CAMoE, a multi-task learning framework for\
  \ optimizing click-through rate prediction on Spotify\u2019s audio-centric, multi-modal\
  \ ad platform. CAMoE uses modality-aware task grouping, adaptive loss masking, and\
  \ deep-cross network experts to handle data imbalance and capture complex feature\
  \ interactions."
---

# An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting on Spotify

## Quick Facts
- arXiv ID: 2506.18735
- Source URL: https://arxiv.org/abs/2506.18735
- Reference count: 34
- Primary result: 14.5% CTR lift for audio ads, 1.3% for video ads in large-scale A/B test

## Executive Summary
This paper introduces CAMoE, a multi-task learning framework designed to optimize click-through rate prediction for Spotify's audio-centric, multi-modal ad platform. The system addresses the challenge of severe data imbalance between audio and video ad slots while respecting modality-specific user engagement patterns. By using modality-aware task grouping, adaptive loss masking, and deep-cross network experts, CAMoE achieves significant improvements in both offline ranking metrics and online engagement metrics. The framework demonstrates that carefully designed multi-task architectures can effectively handle the unique characteristics of audio-first advertising environments.

## Method Summary
CAMoE implements a multi-gate mixture-of-experts (MMoE) architecture with two task heads: one for audio ads and one for video ads. The model uses DCN-v2 experts to capture complex feature interactions and employs adaptive loss masking to prevent the dominant audio task from overwhelming video learning. Training involves downsampling the majority audio class, followed by per-task temperature scaling for calibration. The architecture processes shared embeddings through modality-specific gates and experts, with loss computed only for matching modalities during each training step.

## Key Results
- Offline AUC-PR improvements of 2.9-7.6% across multiple ad slots
- 14.5% CTR increase for audio ads and 1.3% for video ads in A/B test
- 4.8% reduction in eCPC for audio slots while maintaining performance
- Significant calibration improvements for minority video tasks

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Loss Masking (ALM)
- **Claim:** ALM isolates gradient updates for specific modalities, mitigating negative transfer from dominant classes.
- **Mechanism:** Masked binary cross-entropy loss computes gradients only for same-modality task heads per example, preventing high-volume audio data from biasing video task weights.
- **Core assumption:** User intent and interaction signals differ fundamentally between background audio consumption and foreground video interaction.
- **Evidence anchors:** Abstract mentions ALM prevents dominant audio task from overwhelming others; Section 5.1 defines masked loss function; corpus signals are weak for this specific technique.
- **Break condition:** If user behavior for video and audio ads becomes highly correlated, isolation might prevent beneficial cross-modal learning.

### Mechanism 2: Modality-aware Task Grouping
- **Claim:** Grouping by modality (Audio vs. Video) optimizes trade-off between data sparsity and task interference better than content-based grouping.
- **Mechanism:** Aggregates disparate slots into single task heads based on "focus state" (background vs. foreground), allowing shared representation for low-engagement contexts.
- **Core assumption:** "Focus state" is stronger predictor of CTR than specific content type.
- **Evidence anchors:** Abstract highlights struggle of traditional models; Section 6.2.2 shows content-based grouping underperforms; audio provides critical context but modality split driven by user attention.
- **Break condition:** If specific slot has sufficient unique data and diverges significantly from others, coarse grouping might fail to capture nuance.

### Mechanism 3: DCN Experts for Feature Interactions
- **Claim:** DCN experts capture explicit feature interactions more effectively than standard ReLU experts.
- **Mechanism:** Each MoE expert uses DCN-v2 blocks with cross layers to model polynomial interactions between features.
- **Core assumption:** High-order feature interactions necessary to predict clicks in sparse, multi-modal environment.
- **Evidence anchors:** Section 5.2 describes DCN-v2 integration; Table 5 shows 35% AUC-PR drop when DCN removed; no corpus evidence contradicts this.
- **Break condition:** If feature space is extremely high-dimensional without sufficient embedding compression, DCN experts may become computationally prohibitive.

## Foundational Learning

- **Concept: Multi-gate Mixture-of-Experts (MMoE)**
  - **Why needed here:** CAMoE builds directly on MMoE; understanding how multiple expert sub-networks are trained jointly and how gates route inputs is essential.
  - **Quick check question:** How does the gating mechanism differ with two task heads versus seven?

- **Concept: Model Calibration (Temperature Scaling)**
  - **Why needed here:** Accurate ranking isn't enough; probability values determine bid prices in ad auctions. CAMoE uses temperature scaling to fix miscalibration.
  - **Quick check question:** Why would a model with high AUC-PR still cause revenue loss in a second-price auction?

- **Concept: Transfer Learning in MTL**
  - **Why needed here:** 2-task setup relies on positive transfer between audio slots while ALM prevents negative transfer from video to audio.
  - **Quick check question:** Why does the paper argue that a 7-task model failed to generalize compared to the 2-task model?

## Architecture Onboarding

- **Component map:** Input -> Shared embedding -> 2 DCN-v2 Experts -> 2 Modality-specific Gates -> 2 Task Towers -> Adaptive Loss Masking -> Loss
- **Critical path:** Adaptive Loss Masking (ALM) logic - must modify training loop to selectively "turn off" loss calculation for non-matching modalities
- **Design tradeoffs:** Reject 7-task model (overfitting) and 1-task model (bias) in favor of 2-task model; do not split by content type; do not replace DCN experts with MLPs
- **Failure signatures:** High ECE on Video indicates ALM not correctly filtering audio noise; drop in "Embedded Music" performance suggests DCN structure not learning feature crosses
- **First 3 experiments:**
  1. Task Grouping Ablation: Compare 2-task (Audio/Video) vs 2-task (Music/Podcast) on same data
  2. Loss Masking Toggle: Train with and without ALM, compare ECE for minority video class
  3. Expert Architecture Swap: Swap DCN experts for standard ReLU MLPs to isolate feature interaction contribution

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can significant inference-time expert masking performance gains be realized in low-latency production environments without doubling computation time?
- **Basis in paper:** Appendix A.2.6 states naive implementation would double computation time; future work focuses on addressing serving challenges.
- **Why unresolved:** A/B test showed +122% AUC-PR for Embedded Music with masking, but current infrastructure cannot support latency cost.
- **What evidence would resolve it:** Architectural modification or conditional execution strategy achieving masking benefits while maintaining standard inference latency.

### Open Question 2
- **Question:** Can ALM be refined to improve calibration for minority video slots without degrading calibration for dominant audio slots?
- **Basis in paper:** Section 6.2.3 and Figure 5 indicate trade-off where ALM improves Stream Video calibration but worsens Stream Audio slightly.
- **Why unresolved:** Current ALM prevents audio dominance but introduces calibration penalty for high-volume audio traffic.
- **What evidence would resolve it:** Modified loss function or dynamic masking threshold reducing ECE for video slots while maintaining/improving Stream Audio ECE.

### Open Question 3
- **Question:** Can learned or dynamic task grouping outperform static "Audio vs. Video" heuristic?
- **Basis in paper:** Section 4.3 evaluates fixed configurations and concludes 2-task optimal, but grouping is manually defined.
- **Why unresolved:** Different groupings yield different results (Section 6.2.2) but paper doesn't explore automatic discovery of optimal clustering.
- **What evidence would resolve it:** Mechanism that dynamically clusters ad slots or learns soft task affinities achieving higher AUC-PR than static 2-task model.

## Limitations
- Core empirical claims rely on internal A/B test data that cannot be independently verified
- Absolute baseline AUC-PR values not reported, making practical significance difficult to assess
- DCN-v2 expert configuration remains underspecified, creating implementation uncertainty

## Confidence

- **High confidence:** Theoretical mechanism of Adaptive Loss Masking preventing negative transfer is well-established; architecture description is sufficiently detailed
- **Medium confidence:** Offline evaluation results are internally consistent and follow standard ML practices, though absolute values missing
- **Low confidence:** Online A/B test results and specific percentage improvements cannot be independently validated due to lack of public data and potential confounding factors

## Next Checks

1. **Offline ablation study replication:** Implement 2-task vs 7-task comparison to verify modality-aware grouping outperforms slot-specific grouping
2. **Calibration validation:** Test whether temperature scaling effectively reduces ECE compared to alternative calibration methods on same validation data
3. **Cross-platform generalization:** Evaluate whether ALM mechanism provides similar benefits when applied to different multi-modal advertising dataset to test robustness of modality isolation hypothesis