---
ver: rpa2
title: 'Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application
  on the DermaMNIST Dataset'
arxiv_id: '2507.12961'
source_url: https://arxiv.org/abs/2507.12961
tags:
- dataset
- skin
- dermamnist
- classification
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated convolutional neural networks for classifying
  pigmented skin lesions using the DermaMNIST dataset. Two models, ResNet-50 and EfficientNetV2L,
  were applied with transfer learning and varying layer configurations.
---

# Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset

## Quick Facts
- arXiv ID: 2507.12961
- Source URL: https://arxiv.org/abs/2507.12961
- Authors: Nerma Kadric; Amila Akagic; Medina Kapo
- Reference count: 24
- Primary result: EfficientNetV2L achieved 0.8490 accuracy on DermaMNIST-C dataset

## Executive Summary
This study evaluated convolutional neural networks for classifying pigmented skin lesions using the DermaMNIST dataset. Two models, ResNet-50 and EfficientNetV2L, were applied with transfer learning and varying layer configurations. The original DermaMNIST dataset showed overfitting and class imbalance issues, limiting classification performance. Using the improved DermaMNIST-C dataset, EfficientNetV2L achieved an accuracy of 0.8490, surpassing or matching existing state-of-the-art methods. The results demonstrate that advanced CNN architectures can significantly enhance diagnostic accuracy for dermatological image classification, though dataset quality remains a critical factor. Future work may include dataset augmentation and integration into clinical applications.

## Method Summary
The study employed transfer learning with pre-trained ImageNet weights on two CNN architectures: ResNet-50 and EfficientNetV2L. The base model weights were frozen while training only the classification head. The DermaMNIST-C dataset (224x224 resolution) was used to address the low-resolution limitations of the original DermaMNIST dataset (28x28). Various classification head configurations were tested, including simple dense layers with Batch Normalization versus complex convolutional blocks. Training utilized the Adam optimizer with learning rate 1e-4, categorical cross-entropy loss, and included EarlyStopping and ModelCheckpoint callbacks.

## Key Results
- EfficientNetV2L achieved 0.8490 accuracy on DermaMNIST-C, outperforming or matching state-of-the-art methods
- Original 28x28 DermaMNIST dataset showed overfitting issues with validation accuracy around 60%
- Simpler classification head (Flatten → BN → Dense → BN → Output) outperformed complex convolutional head configurations
- Class weighting attempt (Effv4) reduced overall accuracy from 0.8490 to 0.8247, indicating a precision-recall tradeoff

## Why This Works (Mechanism)

### Mechanism 1: Transfer Learning with Pre-trained ImageNet Weights
If standard CNN architectures are initialized with weights from ImageNet, feature extraction for dermatological images improves compared to training from scratch. The models utilize pre-learned low-level features (edges, textures) from general natural images. By freezing these base layers and training only the classification head, the model adapts high-level generic visual patterns to specific dermatoscopic features without requiring massive domain-specific training data.

### Mechanism 2: Resolution-Dependent Feature Preservation
If input image resolution is increased from 28x28 to 224x224, model performance improves significantly due to preservation of discriminative textural details. The original 28x28 downsampling destroys high-frequency data critical for distinguishing lesions. The DermaMNIST-C dataset (224x224) restores this granularity, allowing the CNN's convolutional filters to capture fine-grained spatial features required for accurate classification.

### Mechanism 3: Classification Head Regularization
If the classification head is simplified and regularized using Batch Normalization and Dropout, it prevents overfitting better than complex additional convolutional blocks on top of the base model. The study compares adding complex Conv2D blocks versus a simpler structure (Flatten → BN → Dense). The simpler structure with Batch Normalization likely stabilizes the distribution of inputs to the final dense layers, yielding the highest accuracy.

## Foundational Learning

- **Concept: Convolutional Neural Networks (CNNs)**
  - Why needed here: These are the core engines (ResNet, EfficientNet) used to extract spatial hierarchy features from the skin images
  - Quick check question: How does a convolutional layer differ from a dense (fully connected) layer in terms of handling image data?

- **Concept: Overfitting & Regularization**
  - Why needed here: The paper explicitly struggles with overfitting on the original dataset and uses Dropout/BN to mitigate it
  - Quick check question: What does it mean if training accuracy is high (99%) but validation accuracy is low (60%)?

- **Concept: Class Imbalance**
  - Why needed here: The paper notes the dataset is imbalanced (e.g., melanocytic nevi are common, dermatofibroma is rare), which biases the model unless corrected
  - Quick check question: If a dataset has 95% "Benign" and 5% "Malignant" images, what accuracy would a "dumb" classifier achieve by always guessing "Benign"?

## Architecture Onboarding

- **Component map:** Input (224x224x3 Image) → EfficientNetV2L Backbone (Frozen) → Flatten → BatchNormalization → Dense(64) → BatchNormalization → Dense(7, Softmax)

- **Critical path:**
  1. Load DermaMNIST-C (High Res)
  2. Pass through EfficientNetV2L backbone (Feature Extraction)
  3. Flatten and process through Regularized Dense Head (Classification)
  4. Optimize with Adam (lr=1e-4) and Categorical Cross-Entropy

- **Design tradeoffs:**
  - EfficientNetV2L vs. ResNet-50: EfficientNetV2L is heavier but yields better accuracy (0.7017 vs 0.6663 on low-res; superior on high-res)
  - Simple vs. Complex Head: Adding Conv2D layers atop the backbone (Effv1) performed worse (0.8271) than the simple dense head (Effv3, 0.8490), suggesting the backbone features are sufficient and extra layers induce overfitting
  - Class Weights: Applying class weights (Effv4) actually lowered accuracy (0.8247) compared to unweighted Effv3 (0.8490), indicating a tradeoff between raw accuracy and specific recall metrics

- **Failure signatures:**
  - Resolution Shock: High overfitting and poor generalization occur if using the original 28x28 dataset
  - Imbalance Bias: The confusion matrix likely shows the model favors majority classes (Melanocytic Nevi) over rare classes (Dermatofibroma)
  - Metric Conflict: Accuracy improved in Effv3, but if clinical priority is catching Melanoma (Recall), Effv4 (with class weights) might be theoretically safer despite lower raw accuracy

- **First 3 experiments:**
  1. Baseline Reconstruction: Train ResNet-50 and EfficientNetV2L on the original 28x28 DermaMNIST to reproduce the overfitting issue and verify the data quality bottleneck
  2. Ablation on Head Depth: Compare "Effv1" (added Conv2D blocks) vs. "Effv3" (Flatten→Dense) on DermaMNIST-C to validate the paper's finding that simpler heads perform better on this transfer-learning task
  3. Class Weight Sensitivity: Re-run Effv3 vs Effv4 configurations to plot the Precision-Recall tradeoff; determine if the drop in accuracy (0.8490 → 0.8247) is worth the potential gain in sensitivity for minority classes

## Open Questions the Paper Calls Out

- **Question:** Does expanding the DermaMNIST-C dataset with synthetically generated images for minority classes significantly improve classification performance metrics beyond the current 0.8490 accuracy?
  - Basis in paper: The conclusion states future work "could involve expanding dataset with generated images for each class" to further enhance results
  - Why unresolved: The authors identified class imbalance as a persistent limitation but did not implement or test image generation techniques in the current study
  - What evidence would resolve it: Experiments applying GANs or diffusion models to augment the training set, followed by a re-evaluation of the EfficientNetV2L model's accuracy and recall

- **Question:** What are the specific technical and workflow requirements for effectively integrating the trained EfficientNetV2L model into clinical medical applications?
  - Basis in paper: The text states that "future work may include... integration into clinical applications" to aid in detecting malignant and benign changes
  - Why unresolved: The current study is a technical benchmark on a dataset and does not address deployment challenges, user interface design, or real-world validation
  - What evidence would resolve it: A deployment study or prototype evaluation showing the model's latency and decision-support utility within a clinical environment

## Limitations

- The relative contribution of resolution improvement versus dataset cleaning is not explicitly isolated
- Class weighting attempt reduced overall accuracy, suggesting a precision-recall tradeoff that may have clinical implications
- The study lacks comparison with attention-based mechanisms or ensemble methods that might offer alternative approaches

## Confidence

- **High:** Transfer learning effectiveness with ImageNet pre-training
- **High:** Resolution improvement driving performance gains
- **Medium:** Head architecture simplicity benefit over complexity
- **Medium:** Class imbalance impact and mitigation tradeoff

## Next Checks

1. Perform an ablation study isolating resolution effects by training the same model on DermaMNIST-C images downsampled to 28x28 versus native 224x224 to quantify the resolution contribution independently

2. Compare the EfficientNetV2L results against attention-based architectures (e.g., ViT, ConvNeXt) on the same DermaMNIST-C dataset to establish whether the reported accuracy represents a ceiling for CNN approaches

3. Conduct a precision-recall tradeoff analysis across all experimental configurations, plotting PR curves for each class to determine if the class-weighted model (Effv4) provides better sensitivity for critical melanoma detection despite lower overall accuracy