---
ver: rpa2
title: 'When Words Can''t Capture It All: Towards Video-Based User Complaint Text
  Generation with Multimodal Video Complaint Dataset'
arxiv_id: '2509.19952'
source_url: https://arxiv.org/abs/2509.19952
tags:
- complaint
- video
- user
- text
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of expressing complaints clearly
  in text, particularly for less literate users on e-commerce platforms. The authors
  introduce a new task, Complaint Description from Videos (CoD-V), and a corresponding
  dataset, ComVID, containing 1,175 video reviews paired with detailed descriptions
  and emotion annotations.
---

# When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset

## Quick Facts
- **arXiv ID**: 2509.19952
- **Source URL**: https://arxiv.org/abs/2509.19952
- **Reference count**: 40
- **Primary result**: Introduces the Complaint Description from Videos (CoD-V) task and ComVID dataset with 1,175 video-review pairs for generating emotion-aware complaint descriptions

## Executive Summary
This paper addresses the challenge of expressing complaints clearly in text, particularly for less literate users on e-commerce platforms. The authors introduce a new task, Complaint Description from Videos (CoD-V), and a corresponding dataset, ComVID, containing 1,175 video reviews paired with detailed descriptions and emotion annotations. They propose a multimodal Retrieval-Augmented Generation (RAG) approach, integrating VideoLLaMA2-7b with a retrieval module trained on Amazon product reviews. This model incorporates the user's emotional state to generate more expressive and contextually accurate complaint descriptions. Evaluations show that the proposed method significantly outperforms several state-of-the-art models across metrics like BLEU, ROUGE, BERTScore, and the newly proposed Complaint Retention (CR) score, achieving improvements of 3–4% over fine-tuned VLMs alone.

## Method Summary
The authors propose a multimodal RAG approach for generating complaint descriptions from videos. The system integrates VideoLLaMA2-7b with a retrieval module trained on Amazon product reviews to incorporate contextual product knowledge. The approach explicitly models user emotions to generate more expressive and contextually accurate complaint descriptions. The retrieval-augmented generation framework allows the model to access relevant product information while maintaining focus on the user's specific complaint and emotional state. The model is trained on the newly introduced ComVID dataset containing 1,175 video-review pairs with detailed descriptions and emotion annotations.

## Key Results
- The proposed multimodal RAG approach significantly outperforms several state-of-the-art models across BLEU, ROUGE, BERTScore, and Complaint Retention (CR) metrics
- Emotion-aware generation achieves 3–4% improvements over fine-tuned VLMs alone
- The CoD-V task demonstrates distinctiveness from traditional video summarization and description tasks
- The ComVID dataset provides a foundation for future research in multimodal complaint generation

## Why This Works (Mechanism)
The approach works by combining visual understanding with contextual product knowledge and emotional awareness. The retrieval module provides relevant product information that helps ground the complaint in specific product features, while the emotion integration captures the user's frustration and urgency, making descriptions more authentic and actionable. The multimodal nature allows the system to interpret visual cues in videos that users might struggle to express in text, bridging the gap between visual demonstrations and written descriptions.

## Foundational Learning
- **Multimodal Video Understanding**: Understanding visual content in videos is crucial for interpreting user demonstrations of product issues
  - *Why needed*: Users often show problems visually rather than describing them textually
  - *Quick check*: Can the model identify specific defects or issues from video frames alone?

- **Retrieval-Augmented Generation**: Using external knowledge bases to enhance text generation with relevant context
  - *Why needed*: Product-specific knowledge improves the accuracy and relevance of complaint descriptions
  - *Quick check*: Does retrieved information match the video content and complaint focus?

- **Emotion-Aware Text Generation**: Incorporating emotional state into text generation to make outputs more authentic
  - *Why needed*: Complaints often convey frustration and urgency that text-only descriptions miss
  - *Quick check*: Do generated descriptions reflect appropriate emotional intensity for the complaint?

## Architecture Onboarding
**Component Map**: VideoLLaMA2-7b -> Retrieval Module -> Emotion Encoder -> Text Generator
**Critical Path**: Video input → Visual feature extraction → Retrieval query → Product knowledge retrieval → Emotion analysis → Complaint description generation
**Design Tradeoffs**: 
- Visual detail vs. generation speed (higher resolution vs. faster processing)
- Retrieval breadth vs. relevance (more products vs. more focused results)
- Emotion intensity vs. description clarity (stronger emotion vs. clearer problem statement)
**Failure Signatures**:
- Irrelevant product information in descriptions
- Misaligned emotional tone with complaint severity
- Missing key visual details from videos
- Overly generic complaint language
**3 First Experiments**:
1. Ablation test removing the retrieval module to measure knowledge contribution
2. Emotion sensitivity test with varying emotional intensities
3. Cross-domain validation using videos from different e-commerce platforms

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The dataset size of 1,175 video-review pairs may limit generalizability to broader e-commerce contexts
- Focus on e-commerce complaints may not translate to other domains with different complaint expression patterns
- Automated metrics (BLEU, ROUGE, BERTScore) may not fully capture the nuanced quality of complaint descriptions regarding emotional authenticity and practical utility

## Confidence
- **High**: The technical implementation of the multimodal RAG approach is sound, and the reported improvements over baseline models are statistically significant within the tested framework
- **Medium**: The characterization of the CoD-V task as distinct from traditional video summarization is well-supported by task design, though some overlap with existing multimodal description tasks remains
- **Medium**: The claim that emotion integration improves complaint description quality is supported by metrics, but user studies would strengthen this assertion

## Next Checks
1. Conduct user studies with customer service representatives to evaluate whether the generated complaints actually improve complaint resolution efficiency compared to text-only submissions
2. Test the model on a larger, more diverse dataset spanning multiple e-commerce platforms and product categories to assess generalizability
3. Implement ablation studies to quantify the specific contribution of the retrieval module versus the emotion-aware generation component to overall performance improvements