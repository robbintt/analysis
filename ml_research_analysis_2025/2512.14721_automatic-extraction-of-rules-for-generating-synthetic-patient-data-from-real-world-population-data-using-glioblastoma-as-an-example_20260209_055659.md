---
ver: rpa2
title: Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World
  Population Data Using Glioblastoma as an Example
arxiv_id: '2512.14721'
source_url: https://arxiv.org/abs/2512.14721
tags:
- data
- dataset
- synthea
- synthetic
- canconnect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents an automated method for generating Synthea rules
  from real-world population data to create synthetic patient data for privacy-preserving
  research. The authors developed a workflow that extracts Synthea modules from tabular
  cancer registry data in the oBDS format, using glioblastoma as an example.
---

# Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example

## Quick Facts
- arXiv ID: 2512.14721
- Source URL: https://arxiv.org/abs/2512.14721
- Reference count: 13
- Primary result: Automated Synthea module generation from oBDS cancer registry data produces synthetic glioblastoma patients with comparable statistical properties

## Executive Summary
This paper presents a workflow for automatically generating Synthea modules from real-world population data to create privacy-preserving synthetic patient data. The authors developed an oBDS parser that extracts therapy options and combinations based on relative frequencies from glioblastoma cancer registry data, creating conditional transition probabilities and time intervals between medical events. The resulting glioblastoma Synthea module contains 418 states and generates synthetic patients whose characteristics closely match the original data, though with some systematic deviations in age distribution and tumor frequencies due to distribution simplifications.

## Method Summary
The workflow processes cancer registry data in oBDS format by first enforcing k-anonymity (k=14) through filtering rare tumor localizations, then mapping relational data to the oBDS schema with fictitious exact dates. The oBDS Module Parser reads these reports, calculates transition frequencies between events (diagnosis, therapies, death), and generates a Synthea module in JSON format with Gaussian distributions for diagnosis delays, exponential distributions for survival times, and uniform distributions for inter-therapy intervals. The synthetic data generator then uses this module with default demographics to simulate patient lifecycles, producing approximately 100,000 synthetic glioblastoma patients in FHIR format.

## Key Results
- The synthetic dataset reproduced known disease courses and mostly retained statistical properties of the original cancer registry data
- Tumor occurrence frequencies showed the most pronounced deviation (2-3 percentage points) for unspecified brain tumors
- Age at diagnosis distributions were slightly shifted downward (2.5-12.5%) due to limitations in capturing skewness with Gaussian distributions
- Survival time distributions remained comparable to the original data

## Why This Works (Mechanism)

### Mechanism 1: Conditional Transition Probability Extraction from Relative Frequencies
- Claim: Converting observed treatment pathway frequencies in real-world dataset into conditional transition probabilities allows state-machine model to reproduce similar patient trajectories
- Mechanism: oBDS Parser reads all cases, chronologically orders events, identifies adjacent event pairs, calculates relative frequency of each transition and typical time intervals between them. These become distributed transitions in Synthea states with delay states encoding time intervals
- Core assumption: Observed relative frequencies accurately reflect underlying clinical decision process and can be used as direct proxies for future conditional probabilities
- Evidence anchors: "[abstract] analyzes therapy options and combinations based on relative frequencies to model treatment pathways, creating conditional transition probabilities"; Page 9, Section 2.4 steps 3,6
- Break condition: High rates of missing data or loss-to-follow-up not accounted for will bias calculated transition probabilities toward observed, potentially incomplete pathways

### Mechanism 2: Privacy via Aggregated Statistical Rules and k-anonymity
- Claim: Using only aggregated statistics derived from k-anonymized data to define generation rules prevents synthetic data from containing direct traces of any single real patient's information
- Mechanism: Workflow first enforces k-anonymity on source dataset by removing rare case groups to ensure no combination of gender × primary tumor localization × deceased is unique (k=14 achieved). Module parser consumes only derived aggregate statistics, never raw patient-level records
- Core assumption: Aggregated statistical parameters cannot be reverse-engineered to reveal individual patient identities given k-anonymity pre-processing
- Evidence anchors: Page 7, Section 2.2: "we identified rare case groups and set k-anonymity to k = 10 as requirement... we achieve k = 14 for these case groups by removing the rare tumor localizations"; Page 6, Section 2.1: "concept of Synthea ensures that conclusions from the synthetic data cannot be drawn"
- Break condition: Privacy guarantee breaks if input data not sufficiently pre-processed to meet formal privacy metric before aggregation, or if aggregation is too granular

### Mechanism 3: Probabilistic Time-to-Event Modeling with Parametric Distributions
- Claim: Simplifying complex, skewed real-world event timing into standard parametric distributions enables efficient simulation but introduces quantifiable deviations in synthetic data characteristics
- Mechanism: System maps different clinical events to Synthea delay states with specific distributions: Gaussian distributions model age at diagnosis; Uniform distributions model time between therapies; Exponential distributions model survival times. These are parameterized from source dataset's statistics
- Core assumption: Chosen parametric distributions are sufficient approximations of true underlying event-time distributions for intended use case
- Evidence anchors: Page 10, Section 2.4, Step 7: "for delays before diagnosis Gaussian distributions were used, for delays before date of death (survival times), exponential distributions were used"; "[abstract] Age at diagnosis distributions were slightly shifted downward (2.5-12.5%) due to limitations in capturing skewness with Gaussian distributions"
- Break condition: Produces inaccurate synthetic cohorts when real-world data is highly skewed or multi-modal, as simplifying parametric distribution cannot capture the shape

## Foundational Learning

- **Synthea Generic Module Framework (State Machines)**: Understanding that a module is a state machine where states represent clinical events and transitions represent rules governed by probability and time is essential for interpreting the 418-state glioblastoma module
  - Quick check question: If a Synthea module represents a disease, what two main components define how a virtual patient moves from a "Diagnosis" state to a "Treatment" state?

- **k-anonymity**: This privacy mechanism is used to prepare source data. It's critical to understand that data is pre-processed to ensure no individual is unique within a quasi-identifiable group before any rules are extracted
  - Quick check question: Why might removing a rare cancer subtype from source dataset before generating synthetic data improve the privacy of synthetic output?

- **Parametric vs. Non-parametric Distributions**: Paper's key limitations stem from this trade-off. Understanding the trade-off between simple parametric distribution and complexity of real-world distribution is key to interpreting generated data's fidelity
  - Quick check question: The paper found that using Gaussian distribution for "age at diagnosis" resulted in synthetic population that was slightly younger on average. What property of real-world age distribution could explain this discrepancy?

## Architecture Onboarding

- **Component map**: The architecture consists of three main stages: (1) Source Data & Pre-processing: Real-world oBDS cancer registry data -> k-anonymization filter -> mapping to oBDS format. (2) Rule Extraction Engine (oBDS Parser): Reads oBDS reports -> calculates transition frequencies and time interval stats -> generates Synthea module in JSON format. (3) Synthetic Data Generator (Synthea Core): Uses generated module + default demographics -> simulates patient lifecycles -> outputs synthetic FHIR/CSV data

- **Critical path**: The oBDS Parser is the core innovation. Its job is to transform structured, de-identified event logs into probabilistic state machine definition. A failure here (e.g., incorrect parsing of dates, miscalculating transition probabilities) will cascade into all generated data

- **Design tradeoffs**:
    1. **Automation vs. Clinical Fidelity**: Fully automated parser creates complex modules (418 states) but may miss nuanced clinical logic that human expert would include
    2. **Statistical Fidelity vs. Distribution Simplicity**: Using simple parametric distributions makes model easier to generate and run but introduces quantifiable error (e.g., 2.5-12.5% age shift) compared to skewed real data
    3. **Completeness vs. Complexity**: Study simplified pathways by considering only first therapy of each type. This reduces module complexity but sacrifices ability to model complex, multi-line treatment regimens

- **Failure signatures**:
    - High k-anonymity parameter leading to sparse modules: If k is set too high, too many rare but clinically important events may be filtered out, resulting in module that only captures most generic pathways
    - "Loss to follow-up" bias: Paper explicitly states that incomplete cases were not filtered, so synthetic data will reproduce this incompleteness. This is not a bug but designed feature to reflect data realities
    - Distribution mismatch: Synthetic population that is consistently younger/older or has shorter/longer survival times than expected is signature of parametric distribution choice not matching underlying data's skew

- **First 3 experiments**:
    1. **Reproduce and Validate the Parser**: Run provided open-source oBDS parser on small, manually verified subset of glioblastoma data. Inspect generated JSON module to confirm transition probabilities and delay parameters match hand-calculated expectations for few key pathways
    2. **Quantify Distribution Mismatch**: Generate two synthetic cohorts. One using paper's default parametric distributions. Another where you manually override "age at diagnosis" delay state with non-parametric distribution if Synthea allows, or by post-processing. Compare age histograms of both cohorts against source data to quantify improvement
    3. **Test Generalizability**: Attempt to apply same oBDS parsing workflow to different cancer type dataset (if available in oBDS format) to assess how much modification is needed to parser's logic for new disease domain

## Open Questions the Paper Calls Out

- **How can the automated workflow be extended to model the full complexity of multi-stage therapy sequences rather than simplifying to the first treatment per type?**
  - Basis in paper: [explicit] The authors note in Section 3.4 that they "leave a more detailed examination of the generated pathways for future work, in which also the full complexity of the therapies needs to be reflected"
  - Why unresolved: The current implementation was restricted to one surgery, one systemic therapy, and one radiotherapy per patient to ensure computational feasibility
  - What evidence would resolve it: A module generation pipeline that successfully parses repeated treatments and produces synthetic datasets where patients undergo multiple lines of the same therapy type

- **What interfaces are required to effectively integrate domain expert knowledge (e.g., biomarker implications) into the automated rule generation process?**
  - Basis in paper: [explicit] Section 4 states the method is limited to statistical properties and lacks disease-specific domain knowledge, suggesting "dedicated interfaces need to be developed so that domain experts can review the generated rules"
  - Why unresolved: The current approach relies solely on relative frequencies from tabular data and does not support input of external clinical logic or expert validation
  - What evidence would resolve it: A user interface allowing experts to modify conditional transition probabilities, resulting in synthetic data that reflects clinical causality beyond statistical correlation

- **Can the distribution models for delay states be improved to capture skewed demographic data, such as age at diagnosis?**
  - Basis in paper: [inferred] The results (Section 3.2) show that using Gaussian distributions caused downward shift in age because method "cannot capture skewness," leading to deviations of 2.5-12.5%
  - Why unresolved: The current implementation relies on Gaussian distributions for delays, which fail to accurately model non-normal distribution of patient ages found in registry data
  - What evidence would resolve it: Utilizing alternative distributions (e.g., log-normal or skewed normal) that align synthetic age distribution's skewness with original real-world dataset

## Limitations

- The methodology assumes relative frequencies of observed treatment pathways accurately represent underlying clinical decision processes, which may not hold for glioblastoma where treatment choices depend on factors like genetic markers not captured in registry data
- Use of parametric distributions (Gaussian for age, exponential for survival) introduces systematic biases - age distributions are consistently shifted younger by 2.5-12.5%, and simplified treatment modeling only considers first-line therapies
- Privacy mechanism depends on achieving sufficient k-anonymity through filtering rare tumor localizations, which may remove clinically important subgroups
- The 418-state module complexity may reduce interpretability compared to manually crafted modules

## Confidence

- **High confidence**: The core claim that automated rule extraction from tabular data can generate Synthea modules is supported by successful module generation and reasonable synthetic data characteristics. The methodology and implementation details are well-documented
- **Medium confidence**: The claim that synthetic data "closely matches" original data is partially supported but limited by systematic distribution mismatches (age shift, tumor frequency deviations of 2-3 percentage points). The privacy guarantees through k-anonymity are methodologically sound but not empirically validated
- **Low confidence**: The generalizability claim to other cancer types is speculative - the methodology hasn't been tested beyond glioblastoma, and different cancer types may have more complex treatment pathways or different data quality issues

## Next Checks

1. **Distribution Calibration Test**: Generate synthetic cohorts using alternative distributions (log-normal for age, Weibull for survival) and compare fidelity metrics against original Gaussian/exponential approach to quantify improvements in capturing skewness and multi-modality

2. **Privacy Guarantee Validation**: Conduct formal differential privacy analysis on generated synthetic data to verify that individual patient records cannot be reconstructed, particularly for rare tumor localizations that were filtered to achieve k-anonymity

3. **Cross-Cancer Generalizability**: Apply same automated parsing workflow to at least two additional cancer types (e.g., breast cancer, lung cancer) with different treatment complexity and data characteristics to assess robustness and identify necessary modifications