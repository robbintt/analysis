---
ver: rpa2
title: The Environmental Impacts of Machine Learning Training Keep Rising Evidencing
  Rebound Effect
arxiv_id: '2510.09022'
source_url: https://arxiv.org/abs/2510.09022
tags:
- training
- impacts
- cards
- energy
- environmental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether efficiency improvements can lead
  to sustainable Machine Learning (ML) model training by examining environmental impacts
  over the past decade. The authors developed a comprehensive dataset documenting
  the environmental impacts of NVIDIA workstation graphics cards from 2013 to 2025,
  then used this to estimate the environmental impacts of training notable AI systems.
---

# The Environmental Impacts of Machine Learning Training Keep Rising Evidencing Rebound Effect

## Quick Facts
- **arXiv ID**: 2510.09022
- **Source URL**: https://arxiv.org/abs/2510.09022
- **Reference count**: 40
- **Primary result**: Despite efficiency gains, ML training energy and environmental impacts have increased exponentially due to rebound effects.

## Executive Summary
This study investigates whether efficiency improvements in ML training can lead to sustainable outcomes by examining environmental impacts over the past decade. The authors developed a comprehensive dataset of NVIDIA workstation graphics cards from 2013 to 2025 and used this to estimate environmental impacts of training notable AI systems. Their analysis reveals that despite hardware and algorithmic optimizations, both energy consumption and environmental impacts associated with ML model training have increased exponentially. The study demonstrates that carbon optimization strategies fail to curb this growth, evidencing a rebound effect where efficiency gains are absorbed by creating larger models rather than reducing impacts.

## Method Summary
The authors combined two datasets: a comprehensive NVIDIA graphics card dataset (174 cards from 2013-2025) and the Epoch AI Notable Systems database. They used an attributional Life Cycle Assessment (LCA) approach through the MLCA tool to estimate environmental impacts. The methodology involved estimating GPU-hours using two methods (duration×cards or FLOP/peak compute×0.27), then allocating server production and use-phase impacts to individual training runs. Energy consumption was estimated using TDP values and PUE factors, while carbon impacts were calculated using country electricity mix data. Embodied impacts were estimated based on GPU die area, technological node, and memory specifications.

## Key Results
- Energy consumption and environmental impacts of ML model training increased exponentially from 2013-2025 despite efficiency improvements
- Carbon optimization strategies (location shifting, grid decarbonization) fail to curb impact growth
- Embodied impacts represent a significant share of total impacts, up to 100% for metallic resource depletion
- The rebound effect occurs as efficiency gains fuel creation of larger models rather than impact reduction

## Why This Works (Mechanism)

### Mechanism 1
Hardware and algorithmic efficiency gains are absorbed by the creation of larger models, producing no net reduction in environmental impact. Producer rebound effect occurs when cost reductions from efficiency (more FLOPS per Watt, smaller architectures) lower the effective price of compute, incentivizing training of significantly larger models that fully consume or exceed efficiency savings.

### Mechanism 2
Frequent hardware replacement reduces use-phase emissions but increases embodied impacts, particularly metallic resource depletion. Impact shifting occurs because newer GPUs require denser integrated circuits (larger die areas, finer technological nodes) and more memory, raising production-phase environmental costs. Shorter hardware lifespans amortize these embodied costs over fewer training runs.

### Mechanism 3
Carbon optimization via location shifting or grid decarbonization cannot keep pace with exponential growth in training energy demand. Even with aggressive (25% per year) reductions in grid carbon intensity, the compounding exponential increase in training FLOP demand dominates, leading to rising total carbon. Location shifting does not reduce embodied (production-phase) impacts.

## Foundational Learning

**Concept: Attributional Life Cycle Assessment (LCA)**
Why needed here: The paper's methodology relies on LCA to partition impacts between production (embodied) and use phases, and to compare across impact categories (GWP, ADPe).
Quick check question: Can you explain why an LCA might show different conclusions than an analysis that only considers use-phase electricity?

**Concept: Rebound Effect (Jevons Paradox)**
Why needed here: Understanding the core mechanism that efficiency gains can increase rather than decrease total resource use.
Quick check question: If GPU efficiency doubles, but model size quadruples, what happens to total training energy?

**Concept: Embodied vs. Operational Impacts**
Why needed here: The paper emphasizes that embodied impacts (hardware manufacturing) can dominate total impact, especially for metallic resource depletion.
Quick check question: For a model with training energy of 10 MWh, would embodied impacts always be smaller than use-phase impacts? Why or why not?

## Architecture Onboarding

**Component map:**
Hardware dataset (174 NVIDIA GPUs) → GPU specifications (die area, node, memory) → Production impact estimates → Training dataset (Epoch AI Notable Systems) → GPU-hours estimation (GPU-h1/h2) → MLCA tool → Server configuration (4 GPUs, 2 CPUs, 512GB RAM) → Impact allocation → Results

**Critical path:**
1. Ingest GPU specs → estimate per-card production impacts (GWP, ADPe)
2. For each model, estimate GPU-hours (prefer GPU-h1, fallback to GPU-h2)
3. Allocate server embodied impacts per training run based on server config and 3-year lifespan with 50% utilization
4. Estimate use-phase energy: GPU-hours × TDP × PUE (1.2 post-2018)
5. Convert energy to GWP using country electricity mix

**Design tradeoffs:**
- Using TDP as proxy for power consumption may overestimate; 100% utilization assumption is optimistic but claimed accurate
- 27% performance ratio in GPU-h2 is a fitted constant; may not generalize to all hardware/architectures
- PUE assumption (1.2 for hyperscale, 1.75 for 2010) aggregates heterogeneous facilities

**Failure signatures:**
- Embodied ADPe near 100% for all models → indicates production-phase metallic depletion dominates regardless of training duration
- Divergence between GPU-h1 and GPU-h2 for specific models → flags anomalies (e.g., fine-tuning vs. full training)

**First 3 experiments:**
1. Reproduce the GPU-h1 vs. GPU-h2 scatterplot and linear fit on 100+ overlapping models to verify the 27% performance ratio
2. Run a sensitivity analysis on hardware lifespan (1-5 years) to observe how amortized embodied GWP changes per training run
3. Test alternative decarbonization scenarios (10%, 25%, 50% annual grid intensity reduction) on post-2019 models to verify the paper's conclusion that carbon optimization alone cannot curb impact growth

## Open Questions the Paper Calls Out

**Open Question 1**
What are the relative contributions of model training, re-training frequency, and inference volume to the overall environmental impact of the AI sector?
Basis in paper: The authors state: "Furthermore, we need to identify the precise sources driving this growth: Is increased impact caused by more impactful model training? Is it the result of more frequent re-training? Or is it mainly caused by an increase in the number of inferences?"
Why unresolved: Access to data for model development and use phases remains scarce; this study focused only on training impacts due to data availability constraints.
What evidence would resolve it: Comprehensive datasets documenting inference volumes, re-training frequency, and development-phase compute across the AI sector.

**Open Question 2**
What is the full life-cycle environmental impact of AI hardware including water consumption, toxicity metrics, and end-of-life phases?
Basis in paper: The paper acknowledges: "Recent open quality information on toxicity and water consumption of ICT equipment and data center facilities is missing... End-of-life information is also lacking."
Why unresolved: Current LCA tools like MLCA focus on carbon footprint and metallic resource depletion; water usage, toxicity, and end-of-life data are not systematically available.
What evidence would resolve it: Expanded LCA databases with water usage, human/ecosystem toxicity, and end-of-life modeling for ICT equipment.

**Open Question 3**
Do inference impacts follow the same exponential growth trend as training impacts?
Basis in paper: The authors note: "Efforts from de Vries [15] and Desislavov et al. [16] suggest that our findings should also apply to inferences. It will however require access to user information."
Why unresolved: User-level inference data is proprietary and not publicly available; the study could not assess inference-phase impacts.
What evidence would resolve it: Public benchmarks or industry disclosures of inference workloads and their energy consumption at scale.

## Limitations
- The analysis relies on TDP as a proxy for actual power consumption, which may overestimate energy use
- Hardware configuration assumptions (4 GPUs, 2 CPUs, 512GB RAM) are simplified and may not reflect actual deployments
- Missing training duration or FLOP data excludes many models, limiting sample representativeness to approximately 26% of notable systems

## Confidence

**High Confidence**: Exponential growth in training compute and environmental impacts (2013-2025), producer rebound effect where efficiency gains fuel larger models, and the finding that embodied impacts represent significant portions of total impacts (particularly for metallic resource depletion).

**Medium Confidence**: Carbon optimization strategies (location shifting, grid decarbonization) cannot curb impact growth. This conclusion depends on specific assumptions about grid intensity floors and training demand trajectories.

**Medium Confidence**: Frequent hardware replacement represents impact shifting. This mechanism depends on assumptions about hardware lifespans and manufacturing impacts that may evolve with technology.

## Next Checks

1. **Validate the GPU-h2 correction factor**: Reproduce the linear regression analysis comparing GPU-h1 and GPU-h2 methods across all models with overlapping data to verify the 27% performance ratio and its statistical robustness. Check for systematic deviations by model type or hardware generation.

2. **Test hardware lifespan sensitivity**: Conduct a sensitivity analysis varying server hardware lifespan from 1-5 years while holding other parameters constant. Quantify how this affects the amortization of embodied impacts per training run and identify the threshold where embodied impacts dominate.

3. **Alternative decarbonization scenarios**: Implement and test additional carbon intensity reduction scenarios (5%, 15%, 35% annual improvement) beyond the 10% and 25% cases presented. Model the interaction between different decarbonization rates and training compute growth to identify potential break points where carbon impacts could plateau or decline.