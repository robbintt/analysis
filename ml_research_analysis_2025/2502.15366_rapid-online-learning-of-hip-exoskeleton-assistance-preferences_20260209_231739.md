---
ver: rpa2
title: Rapid Online Learning of Hip Exoskeleton Assistance Preferences
arxiv_id: '2502.15366'
source_url: https://arxiv.org/abs/2502.15366
tags:
- torque
- profiles
- exoskeleton
- users
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a novel online approach to rapidly learn user
  preferences for hip exoskeleton assistance by using pairwise comparisons and active
  querying, avoiding the need for pre-trained models or extensive datasets. Participants
  wore a hip exoskeleton (eWalk) and walked on a treadmill while testing randomly
  generated torque profiles.
---

# Rapid Online Learning of Hip Exoskeleton Assistance Preferences

## Quick Facts
- arXiv ID: 2502.15366
- Source URL: https://arxiv.org/abs/2502.15366
- Reference count: 40
- Users consistently selected torque profiles minimizing negative power relative to positive power through online preference learning

## Executive Summary
This study introduces a novel online approach to rapidly learn user preferences for hip exoskeleton assistance by using pairwise comparisons and active querying, avoiding the need for pre-trained models or extensive datasets. Participants wore a hip exoskeleton (eWalk) and walked on a treadmill while testing randomly generated torque profiles. After each comparison, users selected their preferred torque, and a preference-learning algorithm updated the belief distribution and learned a user-specific reward function in real time. Results from eight healthy subjects showed distinct preferred torque profiles, with choices remaining consistent when compared to perturbed versions. The method maintained individual walking patterns and joint synergies while favoring torques synchronized with users' movements, leading to reduced negative power from the device. This approach enables efficient, personalized exoskeleton control based on direct user feedback.

## Method Summary
Eight healthy subjects walked on a treadmill at 1.1 m/s wearing a hip exoskeleton. The system generated random torque profiles parameterized by six gait-cycle dependent features (peak torque 5-8 Nm, peak times, rise times 10-20 %GC). Users compared pairs of profiles in 20-second trials with 5-second rests, selecting their preference after each comparison. A preference-learning algorithm using Metropolis-Hastings updates and a soft-max human response model learned a user-specific reward function from these pairwise choices. The learning process completed 12 comparisons per subject, after which the preferred profile was validated against perturbed versions (±2.0 Nm, ±7.0 %GC).

## Key Results
- Users consistently selected torque profiles that minimized negative power relative to positive power
- The learned preferred profiles showed distinct individual preferences while maintaining normal walking patterns
- Validation showed consistent selection of the preferred profile over perturbed versions (except for rise-time variations)

## Why This Works (Mechanism)

### Mechanism 1: Bayesian Preference Learning via Pairwise Comparisons
The system rapidly identifies optimal assistance parameters by iteratively updating a belief distribution over a linear reward function, rather than optimizing directly on physiological proxies. The algorithm presents two distinct torque profiles to the user and uses a soft-max human response model to update the posterior belief via the Metropolis-Hastings algorithm, shifting probability mass toward weights that explain the user's choice.

### Mechanism 2: Implicit Minimization of Negative Power
Users naturally select torque profiles that maximize efficient energy transmission, identified by low negative-to-positive mechanical power ratios. By choosing profiles that feel "synchronized," they effectively filter out assistive torques that cause power dissipation, resulting in final profiles with high positive-to-negative power ratios.

### Mechanism 3: Parametric Gait-Cycle Synchronization
Constraining the search space to six gait-cycle dependent features allows real-time adaptability without pre-trained models. The controller maps torque profiles to specific gait phases, detecting heel-strike in real-time to apply torque at biologically relevant moments. The learning algorithm varies these six features to find user-specific synchronization points.

## Foundational Learning

- **Bayesian Inference & Posterior Updates**: Understanding how prior beliefs change to posteriors based on likelihood is required to debug why the model might be overconfident in a suboptimal profile. *Quick check*: If a user prefers Profile A over B, does the algorithm rule out Profile B entirely, or just lower its probability?

- **Mechanical Power in Rotational Systems (P = τω)**: The paper's primary validation metric is the "Power Ratio." Engineers must understand that negative power implies the exoskeleton is resisting the user's motion (dissipation), while positive power implies assistance. *Quick check*: If a user extends their hip while the exoskeleton applies a flexion torque, is the power positive or negative?

- **Human-in-the-Loop Optimization (HILO)**: This method is a specific type of HILO. Understanding the trade-off between optimization time and user fatigue explains why the authors limited comparisons to 12 and used random sampling rather than exhaustive grid search. *Quick check*: Why is asking a user to compare 100 profiles inferior to a Bayesian update strategy using 12 comparisons?

## Architecture Onboarding

- **Component map**: XSens IMUs/Encoders -> Gait Phase Detection -> Profile Generation -> Preference Learning Algo (APReL/Metropolis-Hastings) -> Reward Weight Update -> Motor Controllers
- **Critical path**: The dependency chain runs from sensor data to gait phase detection to profile generation. If phase detection fails, the "Extension Peak Time" (%GC) is applied at the wrong time, invalidating the learning loop.
- **Design tradeoffs**: 12 comparisons chosen to prevent fatigue but may limit convergence; features discretized for perceptual reliability at resolution cost; torque capped at 5-8 Nm for safety potentially limiting peak performance optimization.
- **Failure signatures**: Non-convergence (weights remain highly variable after 10+ iterations); validation failure (user selects perturbed profile over learned preferred); marching gait (user adopts unnatural gait pattern).
- **First 3 experiments**:
  1. **Familiarization Walk**: Have the user walk for 10 mins with a fixed, neutral torque profile to adapt to the exoskeleton's inertia before learning begins.
  2. **Active Query Loop**: Execute the 12 pairwise comparisons. Validate that the learning algorithm correctly updates the belief distribution after each binary selection.
  3. **Perturbation Validation**: Test the final "preferred" profile against a perturbed version (specifically varying peak times) to verify if the learned preference is robust.

## Open Questions the Paper Calls Out

- How do learned user preferences and reward functions transfer across different walking speeds? The study only tested treadmill walking at 1.1 m/s, and user preferences may vary significantly with walking velocity changes.

- What is the relationship between subjective user preferences and objective metabolic energy cost reductions? The study relied solely on subjective pairwise preferences without validating against metabolic cost, the gold standard for exoskeleton assistance effectiveness.

- Would non-linear reward function formulations capture user preferences more accurately than the assumed linear combination? The linear reward model may not capture complex interactions between torque profile features that influence user comfort.

- Would explicitly incorporating positive power optimization into the learning objective improve preference convergence or biomechanical outcomes? Users naturally selected profiles minimizing negative power, but the algorithm did not explicitly optimize for this efficiency metric.

## Limitations
- Focus on healthy young adults limits generalizability to clinical populations with different gait patterns
- 12-comparison limit may be insufficient for users with more complex preference landscapes
- Soft-max model for human choice assumes rational decision-making that may not hold under fatigue

## Confidence
- High: Feasibility of online preference learning and basic preference-power correlation
- Medium: Robustness of learned profiles given mixed perturbation validation results
- Low: Generalization claims due to limited sample diversity and lack of long-term follow-up

## Next Checks
1. Replicate the study with older adults and clinical populations (e.g., stroke survivors) to assess whether the same learning framework applies across diverse user groups.

2. Extend perturbation testing beyond rise time to include variations in peak torque and peak time. Conduct multiple validation sessions over days to test preference stability.

3. Increase the number of pairwise comparisons (e.g., 20-24) for a subset of users to determine if additional iterations improve convergence and robustness, while monitoring for fatigue effects.