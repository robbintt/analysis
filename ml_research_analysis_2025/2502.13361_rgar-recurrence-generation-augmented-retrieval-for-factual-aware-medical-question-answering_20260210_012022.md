---
ver: rpa2
title: 'RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical
  Question Answering'
arxiv_id: '2502.13361'
source_url: https://arxiv.org/abs/2502.13361
tags:
- knowledge
- retrieval
- rgar
- medical
- factual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RGAR, a retrieval-augmented generation framework
  that improves medical question answering by jointly retrieving factual knowledge
  from Electronic Health Records (EHRs) and conceptual knowledge from medical corpora.
  RGAR uses a recurrent pipeline to iteratively refine queries through dual-end retrieval
  and factual knowledge extraction, enabling interaction between both knowledge types.
---

# RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering

## Quick Facts
- arXiv ID: 2502.13361
- Source URL: https://arxiv.org/abs/2502.13361
- Reference count: 40
- Primary result: RGAR achieves state-of-the-art performance on three factual-aware medical benchmarks

## Executive Summary
RGAR introduces a novel retrieval-augmented generation framework specifically designed for medical question answering. The system uniquely combines Electronic Health Records (EHRs) and general medical corpora through a recurrent pipeline that iteratively refines queries via dual-end retrieval and factual knowledge extraction. By enabling interaction between factual knowledge from EHRs and conceptual knowledge from medical literature, RGAR addresses the challenge of answering questions that require both specific patient data and broader medical understanding.

## Method Summary
The RGAR framework employs a dual-knowledge source approach, retrieving both factual knowledge from Electronic Health Records (EHRs) and conceptual knowledge from general medical corpora. A recurrent pipeline iteratively refines queries through alternating phases of retrieval and factual knowledge extraction, allowing the model to progressively improve its understanding. The framework incorporates a dual-end retrieval mechanism where both EHR data and medical literature contribute to query enhancement, with the Llama-3.1-8B-Instruct model serving as the backbone generator.

## Key Results
- Achieves state-of-the-art performance on three factual-aware medical benchmarks
- Llama-3.1-8B-Instruct model outperforms larger GPT-3.5 with RAG enhancement
- Demonstrates effectiveness of factual knowledge extraction from EHRs, particularly in data-rich scenarios

## Why This Works (Mechanism)
RGAR's effectiveness stems from its ability to leverage complementary knowledge sources: EHRs provide patient-specific factual information while medical corpora offer broader conceptual understanding. The recurrent query refinement mechanism allows the system to iteratively improve its retrieval by incorporating newly extracted factual knowledge back into subsequent queries. This dual-end approach creates a feedback loop where factual and conceptual knowledge reinforce each other, enabling more accurate and contextually appropriate answers to medical questions.

## Foundational Learning
- **Dual-knowledge source retrieval**: Why needed - Medical questions often require both patient-specific facts and general medical knowledge; Quick check - Can the system retrieve relevant information from both EHRs and medical corpora for a given question?
- **Recurrent query refinement**: Why needed - Initial queries may be too broad or miss critical information; Quick check - Does the system improve retrieval quality over successive refinement iterations?
- **Factual knowledge extraction**: Why needed - EHRs contain unstructured data requiring extraction of relevant facts; Quick check - Can the system accurately identify and extract key facts from EHR records?
- **Iterative feedback between knowledge sources**: Why needed - Integration of factual and conceptual knowledge improves answer quality; Quick check - Does incorporating factual knowledge into conceptual retrieval improve subsequent results?

## Architecture Onboarding

**Component Map**
Query Generator -> EHR Retriever -> Fact Extractor -> Medical Corpus Retriever -> Knowledge Integrator -> Llama-3.1-8B-Instruct -> Refined Query Generator

**Critical Path**
Query generation → EHR retrieval → factual extraction → medical corpus retrieval → knowledge integration → answer generation → query refinement (repeat)

**Design Tradeoffs**
- Uses smaller Llama-3.1-8B-Instruct vs. larger GPT models for efficiency
- Balances between patient-specific (EHR) and general medical knowledge
- Iterates between retrieval and generation for quality improvement

**Failure Signatures**
- Poor factual extraction from EHRs leading to irrelevant subsequent queries
- Over-reliance on one knowledge source at the expense of the other
- Insufficient query refinement resulting in stagnant retrieval quality

**3 First Experiments**
1. Test retrieval accuracy from EHRs vs. medical corpora on a sample question
2. Evaluate factual extraction quality from sample EHR records
3. Measure performance improvement across iterative refinement cycles

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on performance metrics without detailed error analysis
- Scalability concerns when EHR access is limited or factual extraction introduces noise
- No ablation studies to isolate contributions of individual RGAR components
- Claims about effectiveness in data-rich scenarios remain speculative without testing across varying data volumes

## Confidence

**High confidence:**
- Claims about achieving state-of-the-art performance on evaluated benchmarks
- General architecture of using dual retrieval with iterative refinement

**Medium confidence:**
- Claims about Llama-3.1-8B outperforming GPT-3.5+RAG
- Claims about effectiveness of factual knowledge extraction for retrieval

## Next Checks
1. Conduct ablation studies to quantify individual contributions of EHR-based retrieval, medical corpus retrieval, and recurrent refinement mechanism
2. Perform error analysis categorizing failure modes to understand when dual retrieval strategy succeeds or fails
3. Test scalability by evaluating performance across datasets with varying amounts of EHR data