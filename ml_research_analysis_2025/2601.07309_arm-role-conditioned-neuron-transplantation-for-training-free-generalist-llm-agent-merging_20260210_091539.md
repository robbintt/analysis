---
ver: rpa2
title: 'ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist
  LLM Agent Merging'
arxiv_id: '2601.07309'
source_url: https://arxiv.org/abs/2601.07309
tags:
- backbone
- merging
- action
- neurons
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training-free model merging
  for interactive LLM agents across diverse environments. It proposes Agent-Role Merging
  (ARM), a three-step framework that first constructs merged backbones via weight-space
  merging, then selects the best backbone using role-conditioned activation overlap
  scores, and finally performs conflict-aware neuron transplantation to repair capability
  gaps.
---

# ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging

## Quick Facts
- arXiv ID: 2601.07309
- Source URL: https://arxiv.org/abs/2601.07309
- Reference count: 30
- Key outcome: Training-free merging of interactive LLM agents across six benchmarks using role-conditioned neuron transplantation

## Executive Summary
This paper introduces ARM (Agent-Role Merging), a training-free framework for merging specialized LLM agents into a generalist model. The approach addresses the challenge of preserving diverse interactive capabilities across multi-turn environments without retraining. ARM operates in three phases: constructing merged backbones via weight-space merging, selecting the best backbone using role-conditioned activation overlap scores, and repairing capability gaps through conflict-aware neuron transplantation. Evaluated on Qwen3-8B and Qwen2.5-7B expert pools, ARM achieves superior average performance and worst-suite robustness compared to training-free baselines while maintaining strong out-of-domain generalization.

## Method Summary
ARM merges benchmark-specialized LLM agents through a three-phase pipeline. First, it constructs a pool of candidate backbones by applying multiple weight-space merge operators (uniform averaging, Model Stock, task arithmetic, TIES, TIES+DARE) to the expert models. Second, it selects the best backbone using Activation-Overlap Score (AOS), which measures the Jaccard-style overlap between role-salient neuron sets of each candidate and the corresponding expert. Role-conditioned activation tracing identifies critical neurons by focusing on specific token spans (tool-calls, JSON outputs) rather than full responses. Third, for benchmarks where the selected backbone underperforms, ARM performs conflict-aware neuron transplantation, copying donor neurons from the expert while protecting neurons important for other benchmarks to avoid negative transfer. The method requires only lightweight forward-pass activation tracing and targeted neuron-level edits without retraining.

## Key Results
- ARM achieves the highest average performance and worst-suite robustness across six benchmarks compared to training-free baselines
- Role-conditioned tracing reduces cross-benchmark neuron overlap from 61% to 41% on Qwen3-8B
- AOS shows strong correlation with downstream performance (Pearson: 0.840 | Spearman: 0.986)
- Conflict-aware protection prevents regression on protected benchmarks during transplantation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Activation-Overlap Score (AOS) serves as a lightweight proxy for merged model quality, enabling backbone selection without full interactive evaluation.
- **Mechanism:** AOS computes the Jaccard-style overlap between role-salient neuron sets of a candidate backbone and the corresponding expert. Backbones that preserve more expert role-critical neurons tend to perform better downstream. The selector picks the backbone with highest mean AOS across all benchmarks.
- **Core assumption:** High activation on role-critical token spans during forward passes indicates functional importance for that benchmark's behavior; overlap in these neurons correlates with capability preservation.
- **Evidence anchors:**
  - [abstract]: "selects the best backbone using role-conditioned activation overlap scores"
  - [section 4.3, Figure 3]: "AOS correlates positively with overall performance... Pearson: 0.840 | Spearman: 0.986"
  - [corpus]: Related work "To See a World in a Spark of Neuron" similarly uses neuron-level analysis for interference disentanglement, but does not validate AOS-style selection proxies.
- **Break condition:** If AOS–performance correlation is weak or negative in new domains, or if role spans cannot be parsed deterministically, selection may fail.

### Mechanism 2
- **Claim:** Role-conditioned tracing (vs. full-response tracing) produces more benchmark-specialized neuron sets with lower cross-benchmark overlap.
- **Mechanism:** Instead of averaging activations over all response tokens, ARM restricts saliency computation to role-critical spans (tool-call positions, final-answer JSON, action schema tokens). This yields neuron sets that are more discriminative per benchmark.
- **Core assumption:** Benchmark-critical behaviors are localized to identifiable token spans within multi-turn trajectories.
- **Evidence anchors:**
  - [abstract]: "ARM uses role-conditioned activation tracing to identify critical neurons for benchmark-specific behaviors"
  - [section 4.3, Figure 4]: "Role-conditioned tracing yields substantially lower cross-benchmark overlap: from 61% to 41% on Qwen3-8B"
  - [corpus]: "Locate-then-Merge" uses neuron-level localization for multimodal LLMs, but does not isolate role-specific spans.
- **Break condition:** If tasks lack programmatically identifiable role spans, or if critical behaviors are distributed across all tokens, role-conditioning loses advantage.

### Mechanism 3
- **Claim:** Conflict-aware transplantation protects capabilities for other benchmarks, reducing negative transfer during neuron-level repair.
- **Mechanism:** When repairing benchmark \(b_i\), ARM excludes any donor neuron that overlaps with the union of role-salient neurons from all other benchmarks \(\mathcal{P}_{-b_i}\). Only non-conflicting neurons are transplanted, preserving existing capabilities.
- **Core assumption:** A neuron salient for benchmark \(b_j\) in the backbone is also functionally important for \(b_j\) after transplantation for \(b_i\); protecting it prevents regression.
- **Evidence anchors:**
  - [abstract]: "protects neurons important for other benchmarks during transplantation to avoid negative transfer"
  - [section 4.3, Figure 5]: Protected variant maintains higher performance and flatter degradation as top-\(k\) increases
  - [corpus]: "LED-Merging" addresses safety-utility conflicts in merging via location-election-disjoint strategies, conceptually similar but targeting different conflict types.
- **Break condition:** If capabilities are highly entangled (same neurons serve multiple benchmarks), protection may block too many transplant candidates, limiting repair.

## Foundational Learning

- **Concept:** Model merging (weight-space composition)
  - **Why needed here:** ARM builds on standard merge operators (averaging, TIES, task arithmetic) to construct candidate backbones before selection and refinement.
  - **Quick check question:** Can you explain why merging weights directly can cause interference between task-specific circuits?

- **Concept:** Activation-based interpretability
  - **Why needed here:** ARM relies on activation magnitudes to identify role-critical neurons; understanding what activations represent is essential.
  - **Quick check question:** Why might high activation at a token position indicate functional importance for a behavior?

- **Concept:** MLP neuron structure in transformers
  - **Why needed here:** Transplantation operates at the neuron level (row of \(W_{in}\), column of \(W_{out}\), bias entry); understanding this mapping is required for implementation.
  - **Quick check question:** For a standard MLP with gated architecture (SwiGLU), which parameters correspond to a single neuron index?

## Architecture Onboarding

- **Component map:** Calibration data → activation tracing → AOS selection → gap diagnosis → protected transplantation
- **Critical path:** Calibration data → activation tracing → AOS selection → gap diagnosis → protected transplantation. Errors in role-span parsing or activation extraction propagate downstream.
- **Design tradeoffs:**
  - Top-\(k\) fraction: Larger \(k\) captures more donor capability but increases conflict risk; paper finds 10–20% effective with protection.
  - Calibration set size: 699 tasks / 1240 trajectories used; smaller sets may yield noisy saliency estimates.
  - Merge operator pool: More candidates improve selection but increase tracing cost (~0.5 GPU-hour per backbone–benchmark pair).
- **Failure signatures:**
  - High AOS but low downstream performance → role spans may not capture true critical behaviors.
  - Post-transplant regression on protected benchmarks → protection set may be incomplete or entanglement is high.
  - Invalid structured outputs (JSON, tool calls) after merge → localized format violations cascading in multi-turn trajectories (see Appendix B case studies).
- **First 3 experiments:**
  1. **AOS validation:** On a small expert pool (2–3 benchmarks), compute AOS for multiple merge candidates and correlate with held-out performance to verify selection criterion.
  2. **Role vs. full-response ablation:** Compare neuron-set overlap and downstream performance using role-conditioned vs. full-response tracing on a single benchmark pair.
  3. **Protected vs. unprotected transplant:** Sweep top-\(k\) (5%, 10%, 20%, 30%) with and without conflict-aware protection on a weak benchmark; measure both target improvement and collateral regression.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can ARM be extended to merge experts with heterogeneous architectures or tokenizers?
- **Basis in paper:** [explicit] "ARM requires access to homologous expert checkpoints that share the same architecture and tokenizer; it does not directly apply to merging heterogeneous model families or black-box APIs."
- **Why unresolved:** The current activation-tracing and neuron-transplantation pipeline assumes parameter-level correspondence across models.
- **What evidence would resolve it:** Demonstrating successful merging across different model families with aligned neuron mapping or projection techniques.

### Open Question 2
- **Question:** How can role-critical span identification be automated for new agent environments without benchmark-specific parsers?
- **Basis in paper:** [inferred] The method relies on "deterministic, benchmark-specific parsers" to identify role spans, which limits portability to new environments without such infrastructure.
- **Why unresolved:** Current tracing requires manual specification of role spans per benchmark (tool calls, JSON outputs, action schemas).
- **What evidence would resolve it:** A generalizable method for automatic role-span detection that maintains similar AOS correlation and transplantation effectiveness.

### Open Question 3
- **Question:** Would integrating attention-layer transplantation alongside MLP neurons improve performance?
- **Basis in paper:** [inferred] ARM only transplants MLP neurons, though multi-turn reasoning may also depend on attention circuits that are perturbed during merging.
- **Why unresolved:** The paper does not ablate attention-layer interventions, leaving potential capability gaps unaddressed.
- **What evidence would resolve it:** An ablation comparing MLP-only vs. MLP+attention transplantation on the same expert pools.

## Limitations
- Role-span parsing specificity limits generalizability to domains without structured outputs
- Protection mechanism may fail when capabilities are highly entangled across neurons
- Strong reliance on AOS correlation with performance that may not transfer to different model architectures

## Confidence
- **High Confidence:** The three-phase framework structure (merge → select → transplant) is well-specified and logically coherent. The conflict-aware protection mechanism is clearly described.
- **Medium Confidence:** The role-conditioned tracing approach and AOS selection criterion are supported by ablation studies but rely on domain-specific span identification that may not transfer.
- **Low Confidence:** The generalizability of ARM to non-interactive tasks or unstructured output domains remains unproven. The paper focuses exclusively on multi-turn interactive agents.

## Next Checks
1. **Cross-domain AOS validation:** Apply ARM to a new LLM domain (e.g., code generation or summarization) where role spans must be redefined; verify whether AOS maintains predictive power for backbone selection.
2. **Entanglement stress test:** Intentionally merge benchmarks with known functional overlap (e.g., similar tool-use patterns); measure whether protection sets fail and regression occurs on supposedly protected benchmarks.
3. **Span-parsing robustness:** Systematically perturb role-span definitions (e.g., include/exclude boundary tokens); quantify impact on neuron saliency estimates and downstream performance to establish sensitivity to parsing accuracy.