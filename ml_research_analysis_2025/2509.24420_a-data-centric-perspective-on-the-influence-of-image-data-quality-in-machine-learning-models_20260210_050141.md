---
ver: rpa2
title: A Data-Centric Perspective on the Influence of Image Data Quality in Machine
  Learning Models
arxiv_id: '2509.24420'
source_url: https://arxiv.org/abs/2509.24420
tags:
- image
- images
- quality
- data
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of systematically assessing
  image dataset quality and its impact on machine learning model performance. The
  authors investigate common image quality issues and develop a pipeline integrating
  two tools, CleanVision and Fastdup, to automatically detect and filter problematic
  images.
---

# A Data-Centric Perspective on the Influence of Image Data Quality in Machine Learning Models

## Quick Facts
- arXiv ID: 2509.24420
- Source URL: https://arxiv.org/abs/2509.24420
- Reference count: 35
- Key outcome: Adaptive thresholding significantly improves defect detection F1 scores; CNNs are particularly sensitive to blur and severe downscaling.

## Executive Summary
This study addresses the challenge of systematically assessing image dataset quality and its impact on machine learning model performance. The authors investigate common image quality issues and develop a pipeline integrating two tools, CleanVision and Fastdup, to automatically detect and filter problematic images. Key enhancements include automatic threshold selection and improved algorithms for detecting low-quality and near-duplicate images. Experimental results on the CIFAKE dataset show that while CNNs are resilient to some distortions, they are particularly vulnerable to blurring and severe downscaling. The proposed automatic thresholding method significantly improves the F1 score from 0.6794 to 0.9468 under single perturbations and from 0.7447 to 0.8557 under dual perturbations. For near-duplicate detection, the deduplication strategy increases the F1 score from 0.4576 to 0.7928. These findings underscore the importance of data quality in machine learning and provide a robust, automated solution for dataset cleaning.

## Method Summary
The authors developed an automated pipeline to detect and filter image quality defects by integrating CleanVision and Fastdup tools. They enhanced these tools with automatic threshold selection algorithms (particularly Li's Minimum Cross-Entropy) to replace fixed thresholds, and improved near-duplicate detection by combining perceptual hashing with hierarchical clustering. The pipeline was evaluated on the CIFAKE dataset with a custom CNN architecture, testing sensitivity to nine defect types including blur, brightness, grayscale conversion, and duplicates. Experiments involved generating perturbed datasets with single and dual defects, then measuring detection F1 scores and model accuracy degradation.

## Key Results
- Adaptive thresholding using Li's method improved F1 score from 0.6794 to 0.9468 for single perturbations and from 0.7447 to 0.8557 for dual perturbations
- CNNs showed catastrophic accuracy loss from blurring (dropping to 54.70% with kernel size 5) and severe downscaling (32.10% accuracy at 4×4 resize)
- Near-duplicate detection improved from F1 score of 0.4576 to 0.7928 using the proposed pHash + clustering approach
- MET thresholding degraded sharply under multimodal distributions (F1 dropped from 0.9413 to 0.4530), while Li and GHT remained stable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive thresholding algorithms (particularly Li's Minimum Cross-Entropy) substantially outperform fixed thresholds for detecting image quality defects across diverse datasets.
- Mechanism: Score distributions of low-quality vs. normal images exhibit bimodal patterns; histogram-based thresholding methods (Otsu, MET, Li, GHT) automatically identify optimal separation points without manual tuning, whereas fixed thresholds fail to generalize across datasets with different contamination types and proportions.
- Core assumption: The quality scores computed by detection tools form separable distributions between defective and normal images that can be modeled statistically (Assumption: this bimodality holds across dataset domains beyond CIFAKE).
- Evidence anchors:
  - [abstract] "Our automatic thresholding method improves the F1 score from 0.6794 to 0.9468 under single perturbations and from 0.7447 to 0.8557 under dual perturbations."
  - [Section III.D] "The original thresholds in both CleanVision and Fastdup are hard-coded constants, making them unsuitable for application across different datasets."
  - [Section IV.B.1] "Li's method, in particular, achieved the highest average F1 score of 0.9468, representing a 26.7% improvement over the original method's score of 0.6794."
  - [corpus] Weak direct support; neighboring papers discuss influence functions and data selection but not thresholding mechanisms specifically.
- Break condition: If quality scores become unimodal or highly overlapping (e.g., subtle degradations), histogram-based methods will fail; MET explicitly degraded under multimodal distributions (dual perturbations).

### Mechanism 2
- Claim: CNN performance degrades non-uniformly across degradation types—blur and severe downscaling cause catastrophic accuracy loss, while brightness shifts and grayscale conversion have minor effects.
- Mechanism: Blurring erodes high-frequency information (edges, textures) that convolutional filters use to learn discriminative patterns; severe downscaling (e.g., 4×4 from 32×32) eliminates spatial detail entirely. Brightness and color channel changes preserve relative spatial relationships and edge structures, allowing learned features to transfer.
- Core assumption: The feature extraction hierarchy in CNNs depends critically on local edge and texture patterns at early layers (Assumption: this dependency generalizes to architectures beyond the tested compact CNN).
- Evidence anchors:
  - [abstract] "CNNs are particularly sensitive to blur and severe downscaling, while moderate brightness changes and grayscale conversion have smaller effects."
  - [Section IV.A] "Applying an average blur with a kernel size of just 5 caused accuracy to plummet to 54.70%. This is likely because blurring erodes high-frequency information—such as edges and textures—that convolutional filters rely on to learn discriminative patterns."
  - [Section IV.A, Table B-II] Blur kernel size 11: accuracy drops to 25.81% (average), 46.51% (Gaussian); Table B-III: 4×4 resize → 32.10% accuracy.
  - [corpus] Indirectly supported by CHIPS paper (arXiv:2511.18519) which notes data-centric factors are underexplored for adaptation.
- Break condition: If the task is primarily color-based (e.g., distinguishing red vs. blue objects), grayscale conversion may cause larger drops than observed here.

### Mechanism 3
- Claim: Near-duplicate detection improves significantly when combining pixel-level hashing (pHash) with clustering on Hamming distance, plus semantic-level similarity from feature embeddings.
- Mechanism: CleanVision's default pHash requires identical hash values to group images—too restrictive for augmented duplicates. Fastdup uses ONNX feature vectors with cosine similarity and connected-component grouping. Combining hierarchical clustering (single linkage) on pHash Hamming distances with Fastdup's semantic similarity captures both pixel-level and semantic redundancies.
- Core assumption: Near-duplicates share either visual similarity (hash proximity) or semantic similarity (embedding proximity); requiring both ensures higher precision (Assumption: this combination strategy transfers to datasets beyond CIFAKE's AI-generated images).
- Evidence anchors:
  - [abstract] "near-duplicate detection improved from 0.4576 to 0.7928."
  - [Section III.C] "Because the perceptual hash (pHash) values of two images become increasingly similar as the images themselves become more alike, we incorporated Fastdup's distance-based similarity concept and experimented with clustering methods."
  - [Section III.C] "hierarchical clustering with the linkage parameter set to single achieved the best results."
  - [corpus] CLIP deduplication study mentioned (Mayilvahanan et al.) shows duplicates affect generalization, but no direct mechanism comparison.
- Break condition: If duplicates are semantically different but visually similar (adversarial cases), or visually different but semantically identical (style transfers), the combined approach may misclassify.

## Foundational Learning

- **Laplacian Variance for Blur Detection**
  - Why needed here: Both CleanVision and Fastdup use Laplacian variance as a blur metric—understanding this helps interpret blur scores and why they work.
  - Quick check question: Given an image with sharp edges vs. a smoothed version, which will have higher Laplacian variance and why?

- **Histogram Thresholding Methods (Otsu, Li, MET)**
  - Why needed here: The paper compares seven thresholding algorithms; understanding their assumptions helps select the right one for different score distributions.
  - Quick check question: If your quality score histogram has three peaks instead of two, which thresholding method would likely fail and why?

- **Perceptual Hashing (pHash) vs. Feature Embedding Similarity**
  - Why needed here: Near-duplicate detection combines these two approaches—knowing what each captures helps debug detection failures.
  - Quick check question: Would pHash detect a near-duplicate where the subject is identical but the background color changed? Would a CLIP embedding?

## Architecture Onboarding

- **Component map:**
  Raw Image Dataset -> Quality Score Computation (CleanVision brightness, blur, grayscale, duplicates; Fastdup duplicates, outliers, brightness ranking) -> Automatic Threshold Selection (Li's method recommended) -> Near-Duplicate Clustering (pHash + Hamming distance, hierarchical clustering single, Fastdup semantic similarity) -> Flagged Images → User Review → Clean Dataset

- **Critical path:** Score computation → threshold selection → duplicate clustering. The threshold selection step is where the paper's primary contribution lies—do not skip to manual threshold tuning.

- **Design tradeoffs:**
  - **Li vs. GHT:** Li achieved highest F1 (0.9468 single, 0.8557 dual); GHT showed more stability across perturbation types. Use Li for maximum accuracy, GHT for robustness.
  - **Single vs. average linkage for duplicates:** Single linkage worked best for pHash clustering (captures chains of similar images) but may over-group; validate clusters manually initially.
  - **Detection granularity:** CleanVision's original grayscale detection missed RGB images with identical channels—apply the fix described in Section III.C if grayscale matters for your task.

- **Failure signatures:**
  - MET thresholding returns error or very low F1 when score distribution has zero variance in one class (Table I note).
  - Near-duplicate F1 <0.5 if using only CleanVision default settings—indicates overly strict hash matching.
  - Blur detection F1 near 0 with fixed thresholds on datasets with different blur characteristics than defaults.

- **First 3 experiments:**
  1. **Baseline validation:** Run CleanVision with original fixed thresholds on your dataset; record F1 for each issue type if ground truth is available, or manually inspect flagged samples.
  2. **Threshold comparison:** Apply Li, GHT, and Otsu methods to the same scores; compare which method flags images that align with your manual quality assessment.
  3. **Near-duplicate ablation:** Test three configurations on a subset with known duplicates: (a) CleanVision default, (b) Fastdup only, (c) proposed combined method; measure recall of known duplicate pairs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does the proposed automatic thresholding pipeline generalize to real-world datasets with naturally occurring, heterogeneous quality issues, as opposed to synthetic datasets with controlled perturbations?
- Basis in paper: [explicit] The authors state that "our experiments were conducted solely on a synthetic dataset" and list extending to "real-world datasets" as future work.
- Why unresolved: The study only evaluated on the CIFAKE dataset (AI-generated, 32×32 images) with artificially introduced defects. Real-world datasets contain correlated, complex, and unlabeled quality issues that may not match the bimodal score distributions assumed by the thresholding algorithms.
- What evidence would resolve it: Evaluation of the pipeline (with Li's or GHT thresholding) on diverse real-world benchmarks (e.g., WebVision, ImageNet subsets) with ground-truth quality labels, reporting F1 and downstream model performance.

### Open Question 2
- Question: How robust are the adaptive thresholding algorithms—particularly Li's Minimum Cross-Entropy Thresholding—to initialization strategies and histogram hyperparameters across varying score distributions?
- Basis in paper: [explicit] The authors note that "Li's method is sensitive to initialization (e.g., the default in scikit-image initializes at the global mean), which may affect its stability in other settings" and that they "did not perform an in-depth analysis of hyperparameter selection for the thresholding algorithms."
- Why unresolved: While Li's method achieved the highest average F1 (0.9468), its sensitivity to initialization and bin count (fixed at 256) was not systematically tested, leaving unclear whether gains are consistent across configurations.
- What evidence would resolve it: An ablation study varying initialization (global mean vs. median vs. random), histogram bin counts, and convergence criteria, reporting F1 variance across datasets and perturbation types.

### Open Question 3
- Question: How does detection performance degrade when more than two concurrent quality defects are present in the same dataset?
- Basis in paper: [explicit] The authors explicitly state: "We considered at most two concurrent perturbations."
- Why unresolved: Dual-perturbation experiments already caused MET to degrade sharply (average F1 from 0.9413 to 0.4530), but it is unknown whether top performers (Li, GHT) remain stable under three or more overlapping defect types, which are common in real-world data.
- What evidence would resolve it: Construct datasets with three to five simultaneous perturbations (e.g., blur + dark + low-information + near-duplicate) at varying contamination rates, then benchmark Li, GHT, and GMM on F1 and detection latency.

### Open Question 4
- Question: Do the observed sensitivities and resiliencies (e.g., high sensitivity to blur, resilience to brightness changes) hold across different CNN architectures, capacities, and image resolutions?
- Basis in paper: [inferred] The study uses a single compact CNN architecture on 32×32 images (CIFAKE). Appendix A specifies the exact architecture, but no experiments test other architectures or higher-resolution inputs.
- Why unresolved: The conclusions about which quality issues are most impactful may be tied to this specific model capacity and resolution. Deeper networks or higher-resolution inputs may exhibit different sensitivity profiles.
- What evidence would resolve it: Repeat the perturbation impact experiments (Tables B-I to B-VIII) with diverse architectures (ResNet, EfficientNet, Vision Transformers) and higher resolutions (e.g., 128×128, 224×224), comparing accuracy degradation curves across models.

## Limitations
- The study's conclusions are based primarily on the CIFAKE dataset with 32x32 images and a specific CNN architecture.
- The performance ceiling of the adaptive thresholding methods (especially Li's method) under multimodal score distributions remains untested, as MET explicitly degraded in dual-perturbation scenarios.
- The generalizability of the near-duplicate detection pipeline to datasets with adversarial duplicates (visually similar but semantically different) is not addressed.

## Confidence
- **High Confidence:** CNN sensitivity to blur and severe downscaling (supported by direct experimental evidence and consistent with image processing theory).
- **Medium Confidence:** Adaptive thresholding methods outperforming fixed thresholds (robust F1 improvements observed, but dependent on bimodal score distributions).
- **Low Confidence:** Combined pHash + semantic similarity approach for near-duplicates (no direct comparison to alternatives beyond CleanVision/Fastdup defaults).

## Next Checks
1. **Distribution Robustness:** Test Li's thresholding method on score distributions with three or more modes to verify its failure conditions and compare against GHT stability.
2. **Task Transfer:** Apply the quality detection pipeline to a different dataset (e.g., ImageNet or medical imaging) to validate generalizability of both the detection algorithms and the adaptive thresholding.
3. **Duplicate Semantics:** Create a test set with near-duplicates that are visually similar but semantically different (e.g., different animals with similar backgrounds) to evaluate the combined pHash + embedding approach's precision.