---
ver: rpa2
title: 'Exploring Large Language Model as an Interactive Sports Coach: Lessons from
  a Single-Subject Half Marathon Preparation'
arxiv_id: '2509.26593'
source_url: https://arxiv.org/abs/2509.26593
tags:
- uni00000013
- uni00000010
- uni00000014
- training
- uni0000001b
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored the use of a large language model (LLM) as
  an interactive virtual coach for half marathon preparation over a two-month period.
  The participant engaged with an LLM through text-based interactions, uploading training
  logs and screenshots from consumer apps, while the LLM acted as planner, explainer,
  and motivator.
---

# Exploring Large Language Model as an Interactive Sports Coach: Lessons from a Single-Subject Half Marathon Preparation

## Quick Facts
- arXiv ID: 2509.26593
- Source URL: https://arxiv.org/abs/2509.26593
- Authors: Kichang Lee
- Reference count: 25
- Primary result: LLM coaching improved half marathon pace from 7:54 to 6:30 min/km over 9 weeks

## Executive Summary
This study explored using a large language model as an interactive virtual coach for half marathon preparation. Over two months, a single participant engaged with ChatGPT through text-based interactions, uploading training logs and app screenshots while the LLM provided planning, explanation, and motivation. Performance improved significantly, with gains in pace, distance capacity, and cardiovascular efficiency metrics. The study identified key limitations including lack of real-time sensor integration, text-only feedback, user-initiated motivation support, and limited safety guardrails. These findings inform design requirements for next-generation LLM coaching systems incorporating multimodal sensing, proactive interventions, and explicit safety logic.

## Method Summary
The participant used ChatGPT (assumed GPT-4 class model) with an initial system prompt specifying demographics, half-marathon goal (<2h15m), and weekly availability (4-5 days, 30-90 min/day). Post-run data from Nike Run Club and Zepp/Amazfit Balance 2 was uploaded as structured logs or screenshots after each session. The LLM acted as planner (micro/mesocycle structuring), explainer (training rationale), and motivator. Periodization followed base building → endurance extension → pace adaptation → taper. Performance metrics included pace improvement, distance capacity, weekly mileage, efficiency index (speed/HR), and cadence trends.

## Key Results
- Pace improved from 7:54 min/km to 6:30 min/km, completing 21.1 km half marathon
- Efficiency Index and pace-HR coupling showed positive adaptation trends
- Cadence increased from 161 to 173 steps per minute
- Long-run distance extended from 2 km sustain to full half marathon completion

## Why This Works (Mechanism)

### Mechanism 1
Dialogic planning enables context-aware schedule adaptation under real-world constraints. The LLM integrates user-supplied constraints (fatigue, soreness, calendar conflicts) and restructures microcycles while preserving mesocycle intent. When disruptions occur, it proposes concrete alternatives rather than cancellations. Core assumption: Users accurately report their state and constraints; the LLM maintains sufficient context across sessions to preserve training principles.

### Mechanism 2
Explanatory rationales attached to prescriptions may increase adherence and self-efficacy. The LLM pairs prescriptive guidance with conceptual grounding, transforming opaque directives into transparent trade-offs. This reduces friction between intention and action, particularly for novice users unfamiliar with training theory. Core assumption: Users value understanding the rationale and can translate verbal explanations into embodied execution.

### Mechanism 3
User-initiated (pull-based) motivation support is structurally mismatched to adherence needs. The LLM provides encouragement only when explicitly prompted. During high-motivation phases, support is unnecessary; during low-motivation phases, users often do not initiate contact, precluding intervention exactly when needed most. Core assumption: Users will self-identify and report motivational decline; the system has no independent signal of engagement state.

## Foundational Learning

- Concept: Periodization and progressive overload
  - Why needed here: Understanding why training is phased (base → build → taper) and why load increases gradually prevents the common misconception that "training hard" means maximizing intensity daily.
  - Quick check question: If a runner increases weekly mileage by 25% in one week, what injury risk signal should trigger a load cap?

- Concept: Cardiovascular efficiency metrics (speed/HR coupling)
  - Why needed here: Interpreting the efficiency index (speed ÷ HR) and pace–HR trends enables users to recognize aerobic adaptation even when pace gains feel slow.
  - Quick check question: If pace improves but HR at that pace stays constant, what does this suggest about aerobic economy?

- Concept: Polarized intensity distribution
  - Why needed here: Grasping why ~70–80% of training should be low-intensity (Zone 2) helps users resist the urge to push every session, reducing overuse risk and improving recovery.
  - Quick check question: What proportion of weekly sessions should be easy/recovery vs. threshold/interval in a typical endurance build?

## Architecture Onboarding

- Component map: Sensing layer -> Edge inference -> State & guardrail layer -> Dialogue/feedback layer
- Critical path: 1. Ingest multimodal sensor streams with low latency (< 2s for real-time feedback candidates) 2. Fuse signals into interpretable states (e.g., "overstriding likely," "HR–pace decoupling > 5%") 3. Check guardrails before generating recommendations 4. Deliver bandwidth-aware feedback (one cue at a time, throttle during high-RPE segments)
- Design tradeoffs: Edge vs. cloud inference (edge enables real-time feedback under power constraints; cloud supports richer reasoning but adds latency), Privacy vs. personalization (federated learning preserves privacy but may limit model quality; centralizing data improves personalization at trust cost), Proactive vs. user-initiated motivation (push notifications increase intervention opportunities but risk notification fatigue)
- Failure signatures: LLM generates load increase recommendations without checking weekly cap → guardrail bypass, Real-time cue fires during high-RPE segment → cognitive overload, ignored feedback, User stops uploading logs for 5+ days → motivation asymmetry, no intervention triggered
- First 3 experiments: 1. Implement a single guardrail (weekly load increase cap at 10%) and log every instance where the LLM would have exceeded it without the constraint. 2. Add a latency measurement for HR–pace decoupling detection from wearable stream to feedback delivery; target < 3s end-to-end. 3. Deploy a lightweight check-in prompt triggered by 2+ consecutive missed sessions; measure response rate and qualitative user feedback on intrusiveness.

## Open Questions the Paper Calls Out

### Open Question 1
Can LLM-assisted coaching produce superior or equivalent outcomes compared to certified human coaches or adaptive training apps in controlled, multi-participant trials? The single-subject design with no control condition precludes causal attribution and generalization.

### Open Question 2
How can multimodal, real-time sensor integration (HR, cadence, pose, environmental data) be implemented within tight power/latency budgets to enable safe, in-session coaching adjustments? The current study used only post hoc logs and screenshots; the technical architecture for real-time multimodal fusion under wearable compute constraints remains unimplemented.

### Open Question 3
What mechanisms can effectively detect motivational risk states and deliver just-in-time interventions before training lapses occur? The current passive, pull-based interaction model cannot detect declining motivation without explicit user disclosure.

### Open Question 4
What explicit safety guardrails and progression logic should govern LLM coaching systems, and how can their effectiveness be validated? Current LLM coaching relies on implicit, conversational approximations of safety rules rather than enforceable constraints.

## Limitations
- Single-subject design provides no population-level generalizability
- Text-only interaction modality created structural gaps in real-time feedback and proactive support
- Motivation support was user-initiated rather than proactive, failing when most needed
- No real-time sensor integration or explicit safety guardrails were implemented
- Complete interaction history is unavailable, preventing exact reproduction

## Confidence
**High confidence** in descriptive findings: The study clearly documents what happened and what was tried, with logically coherent proposed mechanisms.
**Medium confidence** in proposed mechanisms: Explanatory power is supported but causation cannot be established; solutions remain speculative without empirical testing.
**Low confidence** in generalizability: Single-subject design, specific participant demographics, and particular LLM configuration prevent broad conclusions.

## Next Checks
1. Implement weekly load increase cap (10%) and log instances where the LLM would have exceeded it without the constraint
2. Measure HR-pace decoupling detection latency from wearable stream to feedback delivery, targeting <3 second end-to-end
3. Deploy scheduled check-ins triggered by 2+ consecutive missed sessions, measuring response rates and comparing adherence to pull-based baseline