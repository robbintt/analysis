---
ver: rpa2
title: An Interpretable ML-based Model for Predicting p-y Curves of Monopile Foundations
  in Sand
arxiv_id: '2501.06232'
source_url: https://arxiv.org/abs/2501.06232
tags:
- pile
- lateral
- curves
- xgboost
- piles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops an interpretable XGBoost model to predict p-y
  curves of monopile foundations in sand, addressing the challenge of accurate lateral
  pile response prediction. The model is trained on 221 p-y curves (2,554 data points)
  from 19 studies, with Bayesian optimization for hyperparameter tuning.
---

# An Interpretable ML-based Model for Predicting p-y Curves of Monopile Foundations in Sand

## Quick Facts
- arXiv ID: 2501.06232
- Source URL: https://arxiv.org/abs/2501.06232
- Authors: Biao Li; Qing-Kai Song; Wen-Gang Qi; Fu-Ping Gao
- Reference count: 11
- Primary result: Interpretable XGBoost model achieves RMSE of 1.034, SI of 0.114, and CC of 0.990 on test data for predicting p-y curves of monopile foundations in sand

## Executive Summary
This study develops an interpretable XGBoost model to predict p-y curves of monopile foundations in sand, addressing the challenge of accurate lateral pile response prediction. The model is trained on 221 p-y curves (2,554 data points) from 19 studies, with Bayesian optimization for hyperparameter tuning. Performance metrics show high accuracy: RMSE of 0.172, SI of 0.019, and CC of 0.999 on training data; RMSE of 1.034, SI of 0.114, and CC of 0.990 on test data. SHAP analysis reveals deformation as the dominant factor influencing predictions, aligning with physical mechanisms of pile-soil interaction. The model successfully generalizes to centrifuge and field test data, demonstrating strong capability for assessing offshore wind turbine monopile foundations.

## Method Summary
The study develops an interpretable XGBoost model for predicting p-y curves (soil resistance p vs. lateral deflection y at depth z) of monopile foundations in sand. The model is trained on 221 p-y curves from 19 studies, using 7 input features: critical friction angle, relative density, effective/total unit weight ratio, pile diameter, normalized rigidity, normalized depth, and normalized deflection. Bayesian optimization with Gaussian Process Regression is used to tune hyperparameters within specified ranges. SHAP analysis provides interpretability by revealing feature importance, while LOESS smoothing generates continuous p-y curves from discrete predictions. The model demonstrates strong generalization to centrifuge and field test data.

## Key Results
- XGBoost model achieves high accuracy with RMSE of 1.034, SI of 0.114, and CC of 0.990 on test data
- SHAP analysis confirms deformation (y/D) as the dominant factor influencing predictions, aligning with physical pile-soil interaction theory
- Model successfully generalizes to centrifuge and field test data, validating its practical applicability
- Captures transition from slender pile to rigid pile failure modes across different pile geometries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble tree learning captures non-linear pile-soil interaction relationships that parametric models miss.
- Mechanism: XGBoost builds K additive regression trees where each tree corrects residual errors from previous iterations, enabling approximation of complex p-y relationships without assuming functional form.
- Core assumption: The compiled dataset spans representative pile-soil interaction behaviors (flexible and rigid failure modes, varying diameters 0.24-8.0m).
- Evidence anchors:
  - [abstract] "Machine learning (ML) techniques have gained considerable attention for their effectiveness in non-linear analysis and prediction."
  - [section] "The core concept of XGBoost is based on constructing multiple trees, where each new tree is designed to correct the errors made by the previous trees, thereby progressively improving the model's performance."
  - [corpus] Related physics-informed ELM paper (arxiv 2510.00698) similarly addresses soil-pile interaction non-linearity.
- Break condition: Extrapolation beyond training distribution (e.g., pile diameters >8m, slenderness ratios outside 5-34 range) may produce unreliable predictions.

### Mechanism 2
- Claim: Bayesian optimization efficiently navigates hyperparameter space with limited evaluations.
- Mechanism: Gaussian Process Regression surrogate models the objective function, while acquisition function balances exploration (untested regions) vs exploitation (promising areas), iteratively refining toward optimal hyperparameters.
- Core assumption: The hyperparameter-response surface is sufficiently smooth for GPR approximation.
- Evidence anchors:
  - [abstract] "Bayesian optimization for hyperparameter tuning"
  - [section] "Unlike blind exploration methods such as grid search or random search, BO directs the optimization process by constructing a probabilistic model that represents the relationship between hyperparameters and the objective function."
  - [corpus] Weak/no direct corpus evidence for BO in geotechnical ML.
- Break condition: Highly multimodal objective with disconnected optima; limited evaluation budget prevents convergence.

### Mechanism 3
- Claim: SHAP values provide physically interpretable feature attribution that validates model behavior against domain theory.
- Mechanism: Shapley values compute each feature's marginal contribution across all possible feature coalitions, yielding consistent local and global importance measures.
- Core assumption: Important physical mechanisms correlate with individual feature contributions (not pure interaction effects).
- Evidence anchors:
  - [abstract] "SHAP analysis reveals deformation as the dominant factor influencing predictions, aligning with physical mechanisms of pile-soil interaction."
  - [section] "The SHAP value distributions for each variable demonstrate strong alignment with established theoretical knowledge on factors affecting the lateral response of pile foundations."
  - [corpus] Weak corpus support; no directly comparable SHAP-in-geotechnical papers in neighbors.
- Break condition: Complex feature interactions where joint contributions cannot be decomposed into individual effects.

## Foundational Learning

- **Concept: Beam on Nonlinear Winkler Foundation (BNWF) and p-y curves**
  - Why needed here: The model predicts p-y curves (soil resistance p vs. lateral deflection y at depth z), which are nonlinear springs in BNWF analysis. Without this, the output is uninterpretable.
  - Quick check question: Can you explain why p-y curves are depth-dependent and how they relate to ultimate resistance pu and initial stiffness kini?

- **Concept: Gradient Boosting and Bias-Variance Tradeoff**
  - Why needed here: XGBoost's regularization term Ω controls complexity; understanding this prevents overfitting to the 2,554 training points.
  - Quick check question: What happens to training vs. test RMSE if n_estimators increases without regularization?

- **Concept: Shapley Values and Feature Attribution**
  - Why needed here: SHAP interprets "black-box" predictions; essential for validating that model learns physically meaningful patterns, not artifacts.
  - Quick check question: If SHAP shows γ'/γ has near-zero importance, what does this imply about its role in pile-soil interaction?

## Architecture Onboarding

- **Component map:**
  Raw pile/soil parameters → Nondimensionalization (Eq. 2) → XGBoost model (Bayesian-optimized) → Point predictions p/γ'zD → LOESS smoothing → Continuous p-y curves → BNWF solver (Oasys ALP) → Force-displacement/Moment-depth outputs

- **Critical path:**
  1. Feature engineering (nondimensionalization critical for generalization across scales)
  2. Bayesian hyperparameter search (n_estimators: 600-1000, max_depth: 3-10, learning_rate: 0.01-0.3)
  3. SHAP validation against physical expectations (y/D must dominate; γ'/γ minimal)
  4. Generalization test on held-out centrifuge/field data

- **Design tradeoffs:**
  - Model complexity vs. interpretability: Deeper trees capture more interactions but reduce SHAP clarity.
  - Training/test split (70/15/15): Smaller test sets increase variance in performance estimates.
  - LOESS smoothing: Required for smooth curves but may introduce artifacts near curve endpoints.

- **Failure signatures:**
  - Training CC ≈ 1.0 but test CC < 0.9 suggests overfitting.
  - SHAP importance ranking contradicts physical theory (e.g., γ'/γ dominates over y/D) → model learned artifacts.
  - Predictions diverge from centrifuge tests for pile geometries within training range → data quality issues.

- **First 3 experiments:**
  1. **Baseline validation:** Replicate train/test split, verify reported metrics (RMSE 1.034, CC 0.990 on test). If mismatch, check data preprocessing.
  2. **Feature ablation:** Remove one feature at a time, measure performance drop. Expect y/D removal to cause largest degradation.
  3. **Out-of-distribution test:** Apply model to pile with D > 8m or Lp/D outside 5-34 range. Document prediction uncertainty; if RMSE > 2× test RMSE, flag extrapolation risk.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed model accurately predict p-y curves under long-term cyclic loading representative of operational offshore wind turbines?
- Basis in paper: [inferred] The study focuses on monotonic lateral response and static capacity. While the introduction references cyclic behavior, the model is trained and validated exclusively on static or monotonic test data.
- Why unresolved: The current training database does not contain features representing load cycle count or loading history, preventing the model from learning degradation or accumulated displacement effects.
- What evidence would resolve it: Validation of the model against centrifuge or field tests specifically measuring p-y curve evolution under cyclic loading conditions.

### Open Question 2
- Question: Does the model maintain accuracy for deep-water installations where the ratio of effective unit weight to total unit weight differs significantly from the training data?
- Basis in paper: [explicit] The authors note that the ratio of effective unit weight to total unit weight had minimal impact on predictions, potentially because "most of the data originates from centrifuge tests, where the water depth... is relatively shallow."
- Why unresolved: The model may have learned an incorrect independence from effective unit weight due to a dataset biased towards shallow water conditions, limiting its reliability for deep-water applications.
- What evidence would resolve it: Testing the model on field data from offshore sites with large water depths and varying submerged unit weight ratios to verify SHAP importance trends.

### Open Question 3
- Question: How does the model perform for extra-large diameter monopiles (D > 8m) that fall outside the range of the training database?
- Basis in paper: [inferred] The database includes pile diameters up to 8.0m. However, the industry is moving towards wider monopiles, and the paper highlights the "transition" in failure modes (flexible to rigid) which is diameter-dependent.
- Why unresolved: XGBoost and similar tree-based models can struggle with extrapolation beyond the feature bounds present in the training data, potentially leading to unreliable predictions for next-generation turbines.
- What evidence would resolve it: Comparison of model predictions against numerical simulations or field measurements for monopiles with diameters exceeding the 8.0m maximum found in the training set.

## Limitations

- Model performance may degrade for pile diameters >8m or slenderness ratios outside 5-34 range due to extrapolation beyond training bounds
- Final Bayesian-optimized hyperparameters not reported, making exact replication challenging
- Dataset composition (19 studies with unknown selection criteria) could introduce biases in representing real-world pile-soil interaction scenarios

## Confidence

- **High confidence**: Model performance metrics (RMSE 1.034, CC 0.990 on test data) and SHAP interpretation showing deformation as dominant factor
- **Medium confidence**: Generalization to centrifuge and field test data, though the study doesn't quantify uncertainty in these predictions
- **Medium confidence**: Bayesian optimization effectiveness, though limited evaluation budget may not guarantee global optimum

## Next Checks

1. **Out-of-distribution testing**: Apply the model to pile diameters >8m and slenderness ratios outside 5-34 range, measuring prediction degradation and quantifying uncertainty bounds
2. **Feature importance robustness**: Perform leave-one-feature-out experiments to verify that y/D removal causes the largest performance drop and that γ'/γ consistently shows minimal importance across multiple random seeds
3. **Data source verification**: Reconstruct the complete dataset from the 19 referenced studies to identify any systematic biases in test conditions or measurement techniques that could affect model generalization