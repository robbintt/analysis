---
ver: rpa2
title: 'DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection
  and Large Language Models'
arxiv_id: '2508.07714'
source_url: https://arxiv.org/abs/2508.07714
tags:
- door
- dataset
- detection
- floor
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a semi-automated pipeline that combines a state-of-the-art
  object detector with a large language model to construct a multi-class door detection
  dataset from architectural floor plans. The method first detects all doors as a
  unified category using Co-DETR, then employs GPT-4.1 to classify each door based
  on visual and contextual features, followed by human-in-the-loop refinement.
---

# DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models

## Quick Facts
- arXiv ID: 2508.07714
- Source URL: https://arxiv.org/abs/2508.07714
- Reference count: 40
- Multi-class door detection dataset from floor plans using semi-automated pipeline

## Executive Summary
This paper introduces DoorDet, a multi-class door detection dataset for architectural floor plans created through a semi-automated pipeline combining object detection and large language models. The method first detects all doors using Co-DETR, then employs GPT-4.1 to classify each door based on visual and contextual features, followed by human-in-the-loop refinement. The resulting dataset contains 4,991 floor plan images with 10 door categories and 49,000+ annotated instances, achieving state-of-the-art performance while reducing annotation time by 43.6% compared to manual labeling.

## Method Summary
The pipeline operates in three stages: (1) Single-class door detection using Co-DETR with ViT-L backbone trained on combined Roboflow datasets, (2) Multi-class classification via GPT-4.1 which receives expanded door crops plus full floor plan context to infer functional door types, and (3) Human-in-the-loop refinement where experts correct predictions, remove false positives, add missing detections, and adjust bounding boxes. The approach leverages Co-DETR's collaborative hybrid assignment mechanism for better convergence and small-object localization, while LLM reasoning analyzes spatial connectivity and semantic cues for functional classification.

## Key Results
- 43.6% reduction in annotation time compared to manual labeling from scratch
- State-of-the-art performance across multiple object detection models on the DoorDet dataset
- Successfully created 4,991 floor plan images with 10 door categories and 49,000+ annotated instances

## Why This Works (Mechanism)

### Mechanism 1
Collaborative hybrid assignment in detection improves convergence and small-object localization in dense floor plan regions. Co-DETR uses one-to-one matching during inference and many-to-one matching during training, sharing backbone/encoder weights. This speeds convergence and better handles tightly-clustered door symbols typical in floor plans.

### Mechanism 2
Vision-language reasoning using cropped door context plus full-floor-plan context enables functional door type inference beyond visual appearance alone. The LLM receives an expanded crop (bounding box + 200px margin) to include surrounding context and the full floor plan. It first localizes the target door within the full plan, then predicts functional type by analyzing connectivity to adjacent rooms and semantic cues.

### Mechanism 3
Human-in-the-loop refinement time savings scale with initial model difficulty; categories with higher baseline error gain more from human correction. Define task difficulty D(t)=1−Accuracymodel-only(t); performance gain Δ(t)=AccuracyHITL(t)−Accuracymodel-only(t). Human effort is targeted at correction (not from-scratch labeling), yielding larger gains for harder categories.

## Foundational Learning

- **DETR-family object detectors (DETR, Co-DETR)**
  - Why needed here: The paper builds on Co-DETR as its detection backbone; understanding one-to-one vs. many-to-one label assignment clarifies why convergence and small-object detection improve.
  - Quick check question: In Co-DETR, which matching strategy is used only during training and discarded at inference?

- **Vision-Language Models (VLMs) for multimodal reasoning**
  - Why needed here: GPT-4.1 is used to jointly process cropped images and full floor plans; understanding how VLMs fuse visual and textual context is critical to interpreting the classification mechanism.
  - Quick check question: What two visual inputs does the LLM receive for each door instance, and what is the purpose of the margin expansion?

- **Human-in-the-loop (HITL) data annotation**
  - Why needed here: HITL is the quality assurance stage that corrects model predictions; understanding its role clarifies how the paper balances automation vs. annotation cost.
  - Quick check question: What types of errors are annotators instructed to correct during HITL refinement?

## Architecture Onboarding

- **Component map:** Single-class detector (Co-DETR) -> Cropping module with margin expansion (m=200px) -> LLM classifier (GPT-4.1) -> Human-in-the-loop interface (labelImg) -> Evaluation layer (mAP/mAP@50)

- **Critical path:** Train detector on combined single-class datasets → run inference on DoorDet images → for each detection, expand crop + query LLM → collect coarse annotations → expert refinement → retrain/evaluate multi-class detectors

- **Design tradeoffs:**
  - Single-class detection first simplifies training using existing datasets but requires a second-stage classifier
  - LLM-based classification reduces manual labeling time but introduces API costs and occasional mispredictions
  - mAP@50 is used alongside mAP because bounding boxes are algorithmically generated and may not precisely align with door boundaries
  - Class imbalance is inherent (e.g., study/garage doors rare); no targeted rebalancing is implemented in this work

- **Failure signatures:**
  - LLM localization errors when multiple similar doors appear in expanded crops (mitigated by center-door instruction)
  - Low precision on rare categories (e.g., study room doors with mAP=0.598) due to extreme class imbalance
  - Domain gap if source floor plans differ stylistically from CubiCasa5K, reducing detector generalization

- **First 3 experiments:**
  1. **Reproduce single-class detector performance** — train Co-DETR on combined single-class datasets, measure mAP/mAP@50 on merged test sets, compare to reported 0.403/0.793
  2. **Ablate LLM context window size** — vary margin m (e.g., 50, 100, 200, 400) on a held-out subset to quantify impact on per-category classification accuracy
  3. **Benchmark alternative detectors** — evaluate InternImage-H, Focal-Stable-DINO, EVA on DoorDet using provided splits; analyze per-class gaps relative to Co-DETR to identify categories most sensitive to model choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can object detection performance be improved on the DoorDet dataset, specifically regarding the significant class imbalance?
- Basis in paper: [explicit] The paper states in the "Limitations and Future Work" section: "a promising direction is to explore effective methods for improving object detection performance on our dataset, particularly by leveraging techniques that address class imbalance."
- Why unresolved: The current benchmark results show a large performance gap between frequent classes (e.g., Emergency Exit) and rare classes (e.g., Study Room, Garage), which standard training does not resolve.
- What evidence would resolve it: Applying specific imbalance-mitigation strategies (e.g., re-sampling, cost-sensitive learning) and demonstrating improved mAP on minority classes without degrading performance on majority classes.

### Open Question 2
- Question: Can domain adaptation techniques effectively extend the utility of models trained on DoorDet to other architectural layout datasets?
- Basis in paper: [explicit] The authors list this as a future direction: "Another possible direction is to develop domain adaptation techniques to extend the use of our dataset to other domains."
- Why unresolved: While Figure 7 shows qualitative generalization to other datasets, the authors explicitly call for "domain adaptation techniques" to formalize this capability, implying the current cross-domain performance is not fully optimized.
- What evidence would resolve it: Benchmarking domain adaptation algorithms that use DoorDet as a source domain to improve quantitative performance on distinct target datasets like FloorPlanCAD or R2V.

### Open Question 3
- Question: How can the dataset construction pipeline be modified to generate pixel-accurate or polygon-level annotations rather than approximate bounding boxes?
- Basis in paper: [explicit] The paper lists this as a limitation: "all bounding boxes in our dataset are algorithmically generated, and therefore only approximate rather than perfectly accurate."
- Why unresolved: The current pipeline relies on object detectors (like Co-DETR) that output axis-aligned bounding boxes, which may not perfectly align with complex door boundaries.
- What evidence would resolve it: An extension of the pipeline incorporating segmentation models or polygon refinement steps that result in higher IoU scores or polygon-based annotations validated against ground truth.

## Limitations

- The LLM prompt text for door type classification is not provided, making faithful reproduction difficult
- The Roboflow datasets cited are referenced generically without clear access paths
- All bounding boxes are algorithmically generated and only approximate rather than perfectly accurate
- Performance metrics are reported on CubiCasa5K-derived data; effectiveness on other floor plan styles is unverified

## Confidence

- **High**: Co-DETR improves convergence and small-object detection (supported by direct training results and mechanism description)
- **Medium**: LLM-based classification works as described (mechanism is clear but prompt details are missing; no independent validation of LLM reasoning capability)
- **Medium**: 43.6% annotation time reduction (directly measured but depends on accurate difficulty-gain correlation which lacks corpus validation)
- **Low**: State-of-the-art performance claim (relative to unspecified baseline; no comparison to contemporary methods like YOLO variants on floor plans)

## Next Checks

1. **Prompt reproducibility test**: Implement the LLM classification with multiple prompt variants (varying margin sizes, instruction clarity) to measure classification stability and identify optimal configuration
2. **Cross-domain robustness evaluation**: Apply the trained pipeline to floor plans from different architectural sources (e.g., non-CubiCasa5K, hand-drawn plans) to assess domain adaptation limits
3. **Cost-benefit analysis**: Calculate total pipeline cost (API calls, compute hours, human refinement time) and compare to fully manual annotation for equivalent dataset size/quality