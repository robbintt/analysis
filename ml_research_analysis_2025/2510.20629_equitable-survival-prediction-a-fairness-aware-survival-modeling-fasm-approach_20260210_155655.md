---
ver: rpa2
title: 'Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach'
arxiv_id: '2510.20629'
source_url: https://arxiv.org/abs/2510.20629
tags:
- fairness
- survival
- cancer
- risk
- fasm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces Fairness-Aware Survival Modeling (FASM),
  a method designed to address algorithmic bias in survival prediction for breast
  cancer by considering both intra- and cross-group ranking fairness over time. FASM
  uses a Rashomon set approach to generate multiple near-optimal Cox proportional
  hazards models and selects the fairest one using a Model Selection Index (MSI) that
  integrates fairness metrics.
---

# Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach

## Quick Facts
- arXiv ID: 2510.20629
- Source URL: https://arxiv.org/abs/2510.20629
- Reference count: 0
- Key outcome: FASM reduces cross-group ranking disparities (ΔxCI: 0.132 vs. 0.261; iΔxAUC: 0.006 vs. 0.016) while maintaining discrimination performance (iAUC: 0.827, C-index: 0.758)

## Executive Summary
This study introduces Fairness-Aware Survival Modeling (FASM), a method designed to address algorithmic bias in survival prediction for breast cancer by considering both intra- and cross-group ranking fairness over time. FASM uses a Rashomon set approach to generate multiple near-optimal Cox proportional hazards models and selects the fairest one using a Model Selection Index (MSI) that integrates fairness metrics. Applied to SEER breast cancer data, FASM substantially reduced cross-group ranking disparities while maintaining comparable discrimination performance. Time-stratified analyses showed that FASM maintained stable fairness across a 10-year follow-up, with the greatest improvements in mid-term periods.

## Method Summary
FASM operates by first training an optimal CoxPH model on training data, then generating a Rashomon set of near-optimal models through rejection sampling with coefficient perturbation. The Model Selection Index (MSI) aggregates multiple fairness metrics (intra-group ΔCI, ΔiAUC and cross-group ΔxCI, iΔxAUC) to select the fairest model from this set. Inverse Probability of Censoring Weighting (IPCW) adjusts all fairness metrics for differential follow-up across demographic groups. The selected model is then evaluated on a held-out test set for both performance and fairness.

## Key Results
- Cross-group ranking disparities reduced by over 50% (ΔxCI: 0.132 vs. 0.261 in fairness-unaware model)
- Maintained strong discrimination performance (iAUC: 0.827, C-index: 0.758)
- Fairness improvements consistent across 10-year follow-up with greatest gains in mid-term periods (years 3-7)
- Rashomon set approach successfully identified models with equivalent performance but divergent fairness profiles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FASM achieves fairness-performance trade-offs by exploiting multiple near-optimal models with divergent fairness profiles
- Mechanism: Rejection sampling generates CoxPH models within 5% performance margin of optimal, creating Rashomon set with varying fairness properties. MSI selects fairest model.
- Core assumption: Near-optimal models can exhibit meaningfully different fairness properties
- Evidence anchors: [abstract], [Page 5-6] model generation details
- Break condition: Empty Rashomon set or all models have identical fairness profiles

### Mechanism 2
- Claim: Cross-group ranking metrics capture directional bias that intra-group metrics miss
- Mechanism: xCI measures whether high-risk individuals from one group are systematically ranked below lower-risk individuals from another group. Fair models yield symmetric xCI values.
- Core assumption: Cross-group ranking symmetry indicates algorithmic fairness
- Evidence anchors: [abstract], [Page 3] cross-group ranking problem, [Page 7-8] metric definitions
- Break condition: Insufficient comparable pairs between groups due to censoring or imbalance

### Mechanism 3
- Claim: IPCW enables unbiased fairness estimation under informative censoring
- Mechanism: Reweights observed events by inverse probability of remaining uncensored, correcting for differential follow-up across groups
- Core assumption: Censoring mechanism is predictable from observed covariates
- Evidence anchors: [Page 7], [Page 8] IPCW implementation
- Break condition: Non-ignorable censoring (depends on unobserved factors)

## Foundational Learning

- Concept: Cox Proportional Hazards Model
  - Why needed here: FASM operates on CoxPH models; understanding coefficient perturbation and hazard ratios is essential
  - Quick check question: Can you explain why CoxPH coefficients represent log-hazard ratios and how perturbing them affects relative risk rankings?

- Concept: Censoring in Survival Analysis
  - Why needed here: Right-censoring creates incomplete outcome data; FASM's fairness metrics must account for differential follow-up via IPCW
  - Quick check question: If Black patients have higher censoring rates than White patients, would naive C-index comparisons be fair? Why or why not?

- Concept: Fairness-Accuracy Trade-offs
  - Why needed here: FASM explicitly navigates this trade-off by selecting from near-optimal models
  - Quick check question: What is the difference between intra-group fairness (equal performance across groups) and cross-group fairness (consistent rankings between groups)?

## Architecture Onboarding

- Component map: Data Preprocessing -> Optimal Model Training -> Rashomon Set Generation -> Fairness Evaluation -> Model Selection -> Testing
- Critical path: Rashomon set generation → fairness metric computation → MSI-based selection. Errors in IPCW estimation propagate to all fairness metrics.
- Design tradeoffs: Tighter ε margin → smaller Rashomon set, less fairness diversity but guaranteed near-optimal performance; looser ε margin → more candidates, greater fairness potential but risk of degraded performance
- Failure signatures: Empty Rashomon set (ε too tight); MSI fails to distinguish models (all similar fairness profiles); cross-group metrics unstable (insufficient pairs); performance degradation on test set (overfit to validation)
- First 3 experiments:
  1. Baseline replication: Train standard CoxPH with/without race variable; compute all fairness metrics
  2. Rashomon set sensitivity: Generate sets at ε = {3%, 5%, 10%}; measure diversity in fairness profiles
  3. Ablation on MSI components: Compare selection when MSI includes only intra-group vs. only cross-group vs. both metrics

## Open Questions the Paper Calls Out

- Question: Can FASM be adapted to non-linear ML architectures where coefficient perturbation is not directly applicable?
- Basis: Authors note that extending FASM requires adjustments since "coefficient perturbation may not be directly applicable," suggesting random masks as an alternative
- Why unresolved: Current validation only uses CoxPH models with direct coefficient manipulation
- What evidence would resolve it: Successful implementation on neural network-based survival model demonstrating similar fairness-performance trade-offs

## Limitations

- Single-institution SEER dataset focus limits generalization to other cancer types and healthcare systems
- Rashomon set generation parameters (k scaling factors, sample sizes) not fully specified, requiring assumptions for reproduction
- Cannot disentangle biological risk from structural inequities due to lack of granular treatment data in SEER

## Confidence

- Core mechanism (Rashomon set for fairness-performance trade-offs): High
- Cross-group fairness metrics (xCI, xAUC): Medium (novel extensions with limited corpus validation)
- IPCW for fairness applications: Medium (standard in survival analysis but fairness-specific assumptions uncertain)

## Next Checks

1. Test Rashomon set sensitivity by generating models at multiple ε thresholds (3%, 5%, 10%) and quantifying fairness metric diversity across sets
2. Validate cross-group fairness metrics on a holdout cohort with different censoring patterns to assess robustness
3. Compare MSI-selected model performance when IPCW is removed versus with IPCW adjustment to isolate contribution of censoring correction