---
ver: rpa2
title: Toward Automated Cognitive Assessment in Parkinson's Disease Using Pretrained
  Language Models
arxiv_id: '2511.08806'
source_url: https://arxiv.org/abs/2511.08806
tags:
- cognitive
- categories
- language
- were
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluated NLP models for extracting narrative categories\
  \ reflecting cognitive processes from first-person narratives of individuals with\
  \ Parkinson\u2019s disease. Three model families\u2014BioClinicalBERT, fine-tuned\
  \ Meta-Llama-3-8B-Instruct, and GPT-4o mini\u2014were compared for their ability\
  \ to identify seven categories (location, time, sensory, action, thought, emotion,\
  \ social interaction) from 179 annotated narrative reports."
---

# Toward Automated Cognitive Assessment in Parkinson's Disease Using Pretrained Language Models

## Quick Facts
- arXiv ID: 2511.08806
- Source URL: https://arxiv.org/abs/2511.08806
- Reference count: 0
- Three pretrained language models (Bio_ClinicalBERT, fine-tuned Meta-Llama-3-8B-Instruct, GPT-4o mini) were evaluated for extracting cognitively relevant categories from Parkinson's disease narratives, with fine-tuned Llama-3-8B-Instruct achieving the highest F1-scores.

## Executive Summary
This study investigates the use of pretrained language models for automated extraction of cognitively relevant categories from first-person narratives of individuals with Parkinson's disease (PD). The research compares three model families—Bio_ClinicalBERT, fine-tuned Meta-Llama-3-8B-Instruct, and GPT-4o mini—across seven narrative categories representing cognitive processes. The findings demonstrate that fine-tuned Llama-3-8B-Instruct outperforms other models, particularly for abstract and context-dependent categories, suggesting potential for automated cognitive monitoring in PD.

## Method Summary
The study evaluated three pretrained language model families on 179 annotated narrative reports from individuals with Parkinson's disease. The models were tasked with identifying seven narrative categories (location, time, sensory, action, thought, emotion, social interaction) that reflect cognitive processes. Bio_ClinicalBERT served as a biomedical domain-specific baseline, while GPT-4o mini was tested under zero-shot and few-shot settings. Meta-Llama-3-8B-Instruct was fine-tuned on the annotated data. Performance was measured using micro- and macro-averaged F1-scores across all categories.

## Key Results
- Fine-tuned Llama-3-8B-Instruct achieved the highest overall performance with 0.74 micro-average and 0.59 macro-average F1-scores
- Bio_ClinicalBERT performed well for concrete categories (time, location) but poorly for abstract categories (emotion, thought)
- GPT-4o mini showed low zero-shot performance but improved with few-shot examples, highlighting sensitivity to prompt engineering

## Why This Works (Mechanism)
The superior performance of fine-tuned Llama-3-8B-Instruct stems from its ability to capture complex, overlapping narrative elements that reflect cognitive processes. The fine-tuning process enables the model to learn the nuanced relationships between linguistic patterns and cognitive categories, particularly for context-dependent concepts like thought and social interaction. The model's architecture allows it to recognize subtle semantic cues that distinguish between categories with overlapping features.

## Foundational Learning
- **Cognitive linguistics frameworks**: Why needed - Provides theoretical basis for categorizing narrative elements; Quick check - Ensure categories align with established cognitive process taxonomies
- **Fine-tuning methodology**: Why needed - Adapts general-purpose models to domain-specific cognitive assessment tasks; Quick check - Verify fine-tuning data represents diverse cognitive states
- **Zero-shot vs. few-shot learning**: Why needed - Demonstrates model adaptability without extensive retraining; Quick check - Test performance across different few-shot example sets

## Architecture Onboarding
Component map: Raw text -> Preprocessing -> Category classification -> Post-processing -> Output scores
Critical path: Input narrative → Tokenization → Contextual embedding extraction → Category probability prediction → Final classification
Design tradeoffs: Fine-tuned models offer superior performance but require labeled data and training time, while zero-shot approaches sacrifice accuracy for flexibility
Failure signatures: Poor performance on abstract categories indicates limitations in capturing nuanced cognitive processes; inconsistent few-shot results suggest sensitivity to prompt engineering
First experiments: 1) Test cross-category confusion patterns to identify ambiguous category boundaries, 2) Evaluate model performance on narratives from different PD severity levels, 3) Compare human inter-rater reliability against model consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Modest sample size (179 narratives) may limit generalizability to broader PD populations
- Domain-specific annotation scheme may introduce bias in category definitions and boundaries
- Single-center data source raises questions about model robustness across different clinical contexts

## Confidence
- **High confidence**: Comparative performance ranking of model families is consistently supported across evaluation metrics
- **Medium confidence**: Generalizability to diverse PD populations given single-center data and specific annotation scheme
- **Medium confidence**: Clinical utility claims, as technical feasibility demonstrated but longitudinal validation needed

## Next Checks
1. External validation on independent PD cohorts with diverse demographic and disease characteristics
2. Inter-rater reliability assessment between human annotators and model outputs across all seven narrative categories
3. Prospective study examining relationship between model-extracted features and longitudinal cognitive assessments in PD patients