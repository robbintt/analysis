---
ver: rpa2
title: 'ScaleTrack: Scaling and back-tracking Automated GUI Agents'
arxiv_id: '2505.00416'
source_url: https://arxiv.org/abs/2505.00416
tags:
- data
- grounding
- training
- arxiv
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'ScaleTrack addresses two limitations in automated GUI agents:
  insufficient training data for GUI grounding and lack of back-tracking in GUI planning.
  It integrates diverse grounding data sources and introduces a back-tracking training
  strategy that predicts both future actions and historical actions.'
---

# ScaleTrack: Scaling and back-tracking Automated GUI Agents

## Quick Facts
- arXiv ID: 2505.00416
- Source URL: https://arxiv.org/abs/2505.00416
- Reference count: 5
- ScaleTrack achieves 86.8% average accuracy on ScreenSpot, 86.6% step success rate on AndroidControl-Low, and 65.3% step success rate on GUI Odyssey, outperforming baselines by 1.2%-4.4% across different metrics.

## Executive Summary
ScaleTrack addresses two key limitations in automated GUI agents: insufficient training data for grounding and lack of back-tracking in planning. It integrates diverse grounding data sources (OS-Atlas, Uground, Aguvis, Aria-UI) and introduces a back-tracking training strategy that predicts both future and historical actions. Through two-stage training on Qwen2-VL-7B, ScaleTrack achieves state-of-the-art performance across multiple benchmarks, demonstrating the effectiveness of data scaling and temporal reasoning in GUI agents.

## Method Summary
ScaleTrack employs a two-stage training approach on Qwen2-VL-7B. Stage 1 focuses on grounding data from multiple sources, training the model to predict coordinates of GUI elements. Stage 2 incorporates back-tracking planning data, where the model learns to predict both next actions and historical actions based on UI state changes. The method unifies coordinate formats to relative 0-1 point format and transforms planning data to include back-tracking by predicting the immediate previous action. Training uses AdamW optimizer with cosine learning rate scheduling, batch sizes of 128 (stage 1) and 64 (stage 2), and DeepSpeed ZERO3 across 4 nodes of V100-80G GPUs.

## Key Results
- 86.8% average accuracy on ScreenSpot grounding benchmark
- 86.6% step success rate on AndroidControl-Low planning task
- 65.3% step success rate on GUI Odyssey planning task
- Outperforms baselines by 1.2%-4.4% across different metrics

## Why This Works (Mechanism)
ScaleTrack's effectiveness stems from two complementary strategies: (1) scaling up grounding data from diverse sources to improve visual understanding of GUI elements, and (2) introducing back-tracking to enable the model to reason about historical actions when predicting future steps. The back-tracking component allows the agent to understand the causal relationship between current GUI states and previous actions, enabling more robust navigation through complex interfaces.

## Foundational Learning
- **GUI grounding**: Predicting coordinates of interactive elements within screenshots - needed to locate buttons, text fields, and other UI components; quick check: verify model can accurately identify element locations on held-out screenshots
- **Planning with back-tracking**: Predicting both future and historical actions based on UI state changes - needed to understand causal relationships between actions and GUI states; quick check: validate model can correctly infer previous action from current and past GUI states
- **Two-stage training**: Separate optimization for grounding and planning capabilities - needed to specialize model capacity for different task components; quick check: confirm stage 1 improves grounding metrics before stage 2 training
- **Coordinate unification**: Converting all coordinates to relative 0-1 point format - needed for consistent input representation across diverse datasets; quick check: verify all training data uses the same coordinate format
- **Data format consistency**: Matching instruction/action formats between training and inference - needed to prevent performance degradation from format mismatches; quick check: ensure test prompts exactly match training format

## Architecture Onboarding

**Component Map:** Grounding data -> Stage 1 training -> Planning data with back-tracking -> Stage 2 training -> Evaluation

**Critical Path:** The most critical sequence is the data unification pipeline followed by the two-stage training process. Stage 1 establishes basic grounding capabilities, while stage 2 adds the temporal reasoning component through back-tracking.

**Design Tradeoffs:** The choice between point coordinates vs bounding boxes for element representation favors points for precision but may lose contextual information. The back-tracking window of k=1 (immediate previous action) balances computational efficiency with historical reasoning capability, though deeper traces might provide additional benefits.

**Failure Signatures:** Performance degradation occurs when training and testing data formats mismatch (10%+ gap), when coordinate formats are inconsistent (points vs boxes), or when back-tracking is not properly implemented in the planning stage. Model may also fail to generalize across different UI styles if training data lacks diversity.

**First Experiments:**
1. Test grounding accuracy on held-out data from each source to verify stage 1 training effectiveness
2. Validate back-tracking prediction accuracy by comparing predicted vs actual previous actions on test set
3. Evaluate end-to-end performance on a simplified version of AndroidControl with known action sequences

## Open Questions the Paper Calls Out
1. **Data scaling saturation point**: At what scale does the integration of diverse grounding data yield diminishing returns for GUI agent performance? The scaling curve suggests potential for continuous expansion, but the saturation point remains unexplored.
2. **Extended back-tracking window**: Does extending back-tracking to predict more than one historical step (k > 1) further enhance planning capabilities? The method currently predicts only the immediate prior action, leaving deeper historical traces untested.
3. **Optimal action representation**: What is the optimal unified representation for historical actions to bridge the gap between natural language instructions and functional operations? Performance sensitivity to instruction vs action formats suggests this representation remains unresolved.

## Limitations
- Critical implementation details (data unification templates, back-tracking transformation logic) remain unspecified
- Performance highly sensitive to coordinate format consistency (point vs box) and action description format (instruction vs action sequence)
- Lack of direct ablation studies to isolate back-tracking component's contribution to overall improvements
- Unspecified training epoch counts make it difficult to assess whether improvements stem from architectural innovations or increased training duration

## Confidence
- **High confidence**: Empirical observation that grounding data integration and back-tracking planning improve performance over single-stage baselines
- **Medium confidence**: Claim that back-tracking specifically drives improvements, as direct ablation studies are not provided
- **Medium confidence**: Scalability analysis showing performance improvements with increased training steps, though relationship appears asymptotic

## Next Checks
1. Implement and test the back-tracking transformation logic on a held-out subset of Aguvis data to verify the "previous n(1) action" prediction mechanism works as described
2. Conduct ablation studies comparing ScaleTrack with and without the back-tracking component using identical training protocols and datasets
3. Test coordinate format sensitivity by training identical models with point coordinates vs bounding box coordinates to measure performance impact