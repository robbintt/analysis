---
ver: rpa2
title: 'VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs'
arxiv_id: '2512.12072'
source_url: https://arxiv.org/abs/2512.12072
tags:
- diversity
- prompt
- data
- diverse
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes VOYAGER, a training-free method for generating
  diverse datasets using large language models (LLMs). The core idea is to iteratively
  explore the data manifold by maintaining a fixed-size set of representative anchor
  points and accepting new data only if it significantly increases the diversity (measured
  via determinant of similarity matrix).
---

# VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs

## Quick Facts
- arXiv ID: 2512.12072
- Source URL: https://arxiv.org/abs/2512.12072
- Authors: Avinash Amballa; Yashas Malur Saidutta; Chi-Heng Lin; Vivek Kulkarni; Srinivas Chappidi
- Reference count: 17
- Key outcome: Training-free method using LLMs to generate diverse datasets via iterative exploration and determinantal point processes

## Executive Summary
VOYAGER introduces a training-free approach for generating diverse datasets using large language models (LLMs). The method iteratively explores the data manifold by maintaining a fixed-size set of representative anchor points and accepting new data only if it significantly increases diversity, measured via the determinant of a similarity matrix. Diversity is optimized using determinantal point processes and prompt refinement through "textual gradients" to guide future explorations. The approach is scalable, works for both open and closed-weight models, and does not require model weights. Comprehensive experiments demonstrate that VOYAGER outperforms strong baselines by achieving 1.5–3x improvement in diversity metrics across multiple creative and reasoning tasks while maintaining quality and reducing LLM calls.

## Method Summary
VOYAGER employs an iterative exploration strategy to generate diverse datasets without requiring model training. The core mechanism maintains a fixed-size set of anchor points that represent the current exploration frontier. When new data is generated, it's only accepted if it significantly increases the diversity of the existing set, with diversity quantified using the determinant of a similarity matrix. The method leverages determinantal point processes to optimize diversity selection and uses "textual gradients" to refine prompts and guide future explorations toward underrepresented areas of the data manifold. This approach works with both open and closed-weight LLMs without requiring access to model weights, making it broadly applicable. The algorithm balances exploration of new data spaces with exploitation of promising areas, achieving superior diversity metrics compared to traditional sampling methods like temperature scaling or hierarchical prompting.

## Key Results
- Achieves 1.5–3x improvement in diversity metrics (e.g., Vendi score) compared to strong baselines
- Maintains dataset quality while significantly increasing diversity across multiple creative and reasoning tasks
- Reduces LLM API calls compared to traditional sampling methods while achieving better diversity outcomes
- Demonstrates effectiveness for both open and closed-weight models without requiring model weights

## Why This Works (Mechanism)

VOYAGER's effectiveness stems from its principled approach to diversity optimization through determinantal point processes and iterative exploration. The method works by maintaining a diverse set of anchor points that represent the current data manifold coverage, then systematically exploring new areas that are underrepresented. The determinant-based diversity measure provides a mathematically sound way to quantify coverage and ensure that new samples add meaningful variation rather than redundancy. The "textual gradients" mechanism allows the system to learn from previous explorations and intelligently guide future sampling toward gaps in the current coverage. This creates a self-improving loop where each iteration builds on the diversity achieved in previous steps, avoiding the local optima that plague simpler sampling strategies like temperature scaling.

## Foundational Learning

**Determinantal Point Processes (DPPs)**: Probabilistic models that favor diverse subsets - needed to mathematically formalize diversity in the anchor point selection; quick check: verify determinant calculation correctly captures diversity in practice.

**Text Embeddings and Similarity Metrics**: Vector representations that capture semantic similarity - required for computing the similarity matrix used in diversity calculations; quick check: ensure embedding space adequately captures task-relevant diversity.

**Determinant-Based Diversity Measures**: Mathematical framework using matrix determinants to quantify set diversity - provides the theoretical foundation for accepting or rejecting new samples; quick check: confirm determinant correlates with human judgments of diversity.

**Iterative Exploration Strategies**: Sequential sampling methods that build upon previous selections - enables systematic coverage of the data manifold; quick check: verify exploration doesn't get stuck in local optima.

**Prompt Refinement via Textual Gradients**: Method for adapting prompts based on exploration outcomes - guides the LLM toward generating underrepresented data types; quick check: ensure gradient-based refinements improve rather than degrade diversity.

## Architecture Onboarding

**Component Map**: LLM API -> Diversity Evaluator -> Anchor Point Manager -> Prompt Refiner -> (back to LLM API)

**Critical Path**: The core loop involves generating new samples via the LLM, evaluating their diversity contribution through determinant calculations, updating the anchor point set if diversity improves, and refining prompts based on exploration outcomes. This creates a closed feedback loop where each iteration informs the next.

**Design Tradeoffs**: The method trades computational overhead (determinant calculations, iterative processing) for superior diversity outcomes compared to simpler sampling methods. The fixed-size anchor point constraint balances memory usage against diversity coverage. The choice of similarity metric affects both diversity quality and computational cost.

**Failure Signatures**: 
- Determinant calculations becoming numerically unstable with large anchor sets
- Prompt refinements leading to mode collapse (reduced diversity)
- Exploration getting trapped in local optima of the data manifold
- Quality degradation when diversity optimization dominates generation

**First Experiments**:
1. Generate diverse creative writing samples (short stories) and measure Vendi score improvement over temperature sampling
2. Create diverse reasoning examples and evaluate downstream performance on related tasks
3. Test scalability by measuring performance and computational cost across different dataset sizes

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions in the provided content.

## Limitations

- Computational overhead may become significant for very large-scale applications due to iterative determinant calculations
- The relationship between diversity metrics and downstream task performance is not fully explored
- Effectiveness on specialized domains (medical, legal, technical) and low-resource languages is not demonstrated
- Potential sensitivity to prompt engineering quality and initial prompt selection

## Confidence

- High Confidence: Outperforms strong baselines in diversity metrics across multiple tasks
- Medium Confidence: Scalability and efficiency claims lack detailed computational overhead analysis
- Medium Confidence: Quality maintenance while increasing diversity is supported but could use more robust assessment

## Next Checks

1. Conduct detailed computational overhead analysis comparing VOYAGER's runtime and memory usage against baselines across different dataset sizes and task complexities

2. Evaluate whether diverse datasets generated by VOYAGER lead to measurable improvements in downstream task performance through fine-tuning experiments

3. Test VOYAGER's effectiveness on specialized domains (scientific literature, legal documents) and low-resource languages to assess generalizability beyond creative and reasoning tasks