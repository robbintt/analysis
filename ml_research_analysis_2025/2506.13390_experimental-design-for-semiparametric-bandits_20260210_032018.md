---
ver: rpa2
title: Experimental Design for Semiparametric Bandits
arxiv_id: '2506.13390'
source_url: https://arxiv.org/abs/2506.13390
tags:
- regret
- bandits
- bound
- design
- semiparametric
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the first experimental-design approach for
  semiparametric bandits, where each arm's reward combines a linear component with
  an unknown, potentially adversarial shift. The key idea is to develop a novel design-based
  method that leverages orthogonalized regression and a refined non-asymptotic analysis
  to achieve dimension-optimal statistical rates.
---

# Experimental Design for Semiparametric Bandits

## Quick Facts
- arXiv ID: 2506.13390
- Source URL: https://arxiv.org/abs/2506.13390
- Reference count: 40
- This paper proposes the first experimental-design approach for semiparametric bandits, where each arm's reward combines a linear component with an unknown, potentially adversarial shift.

## Executive Summary
This paper introduces the first experimental-design approach for semiparametric bandits, where rewards combine a linear component with an unknown, potentially adversarial shift. The authors develop a novel design-based method that leverages orthogonalized regression and a refined non-asymptotic analysis to achieve dimension-optimal statistical rates. They propose a phase-elimination algorithm that simultaneously achieves sharp regret bounds (eO(√dT log K)), gap-dependent logarithmic regret (eO(d log K/∆⋆)), and exploration-based guarantees including PAC and best-arm identification with matching sample complexities.

## Method Summary
The paper proposes DEO (Design of Experiment for Orthogonalized Regression), which solves the non-convex design problem efficiently by constructing difference vectors and finding a G-optimal design over them. This is combined with a phase-elimination algorithm (SBE) that uses the DEO policy to sample arms, computes an orthogonalized estimator via ridge regression on centered features, and eliminates suboptimal arms based on confidence intervals. The orthogonalized regression isolates the linear parameter from adversarial shifts by centering features, transforming the shift term into a martingale difference sequence.

## Key Results
- Achieves sharp regret bounds of eO(√dT log K) that match the minimax lower bound for finite-armed linear bandits
- Demonstrates gap-dependent logarithmic regret of eO(d log K/∆⋆) when the gap is large
- Provides exploration-based guarantees including PAC and best-arm identification with matching sample complexities
- Develops a novel analysis of orthogonalized regression that improves upon standard Cauchy-Schwarz-based approaches by removing the √d factor in estimation error

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Orthogonalized regression isolates the unknown linear parameter θ⋆ from potentially adversarial, time-varying shifts νt.
- **Mechanism:** The algorithm constructs "centered" feature vectors x̃as = xa_s - E[xa_s] and regresses rewards onto these. Because νt is assumed to be Ht-1-measurable (fixed before the action is chosen), it becomes uncorrelated with the centered feature noise. This transforms the shift term into a martingale difference sequence that vanishes in expectation, allowing standard concentration inequalities to apply without estimating νt directly.
- **Core assumption:** The adversarial shift νt is bounded and determined prior to the action selection (Ht-1-measurable).
- **Evidence anchors:** [section 2.1] "We allow the shift νt to be any Ht-1-measurable random variable... determined before the choice of arm." [section 2.2] "...regression on the centered features... E[x̃a_s νs] = 0."
- **Break condition:** If the shift νt depends on the current action (i.e., it is not Ht-1-measurable), the centering mechanism fails to decorrelate the shift from the regression error.

### Mechanism 2
- **Claim:** The DEO (Design of Experiment for Orthogonalized Regression) algorithm solves the non-convex design problem to achieve dimension-optimal estimation rates.
- **Mechanism:** The design objective for orthogonalized regression is non-convex because the covariance depends on the policy variance. DEO bypasses this by solving a standard G-optimal design on the difference vectors {xi - x1} to find a base policy, then mixes this with a point mass on x1. This ensures the resulting policy covariance Σdeo approximates the optimal covariance, bounding the maximum estimation error norm by O(√d) rather than O(d).
- **Core assumption:** The feature set spans a d-dimensional subspace.
- **Evidence anchors:** [section 3.3] "Our algorithm... finds the G-optimal design over b2, ..., bK... Then we return our final policy p = (1/2, p̃2/2, ...)." [theorem 3] "Our policy... satisfies ||xi - x1||Σdeo-1 ≤ 2√d."
- **Break condition:** If the reference arm x1 is a poor choice (e.g., not spanning the necessary subspace with differences), the design may fail to control variance in all directions.

### Mechanism 3
- **Claim:** A refined non-asymptotic analysis removes the √d factor in estimation error found in prior Cauchy-Schwarz approaches.
- **Mechanism:** Prior works bounded error |z⊤(θ̂-θ⋆)| using Cauchy-Schwarz, incurring a dimension-dependent √d factor. This paper decomposes the error into a martingale term and a bias term (Term I and Term II in the appendix). By carefully characterizing the concentration of the empirical covariance matrix relative to the true covariance (decorrelation), the authors show the error scales as O(√d log t / t) rather than O(d√log t / t).
- **Core assumption:** The number of samples t is large enough for the empirical covariance to concentrate (specifically t ≳ d log(dt/δ)).
- **Evidence anchors:** [section 4.1] "We develop a new analysis framework... removing the loose Cauchy-Schwarz arguments." [theorem 4] "...satisfies |z⊤(θ̂t - θ⋆)| ≤ C1√L log(t/δ) / t..."
- **Break condition:** If the sample complexity t is too small relative to dimension d, the concentration events fail, and the higher-order error terms dominate.

## Foundational Learning

- **Concept: Experimental (G-Optimal) Design**
  - **Why needed here:** The core contribution is extending G-optimal design to semiparametric models. You must understand how minimizing the maximum variance of parameter estimates (min max ||x||V-1) leads to sample efficiency and regret bounds.
  - **Quick check question:** Why does minimizing the maximum prediction variance help in identifying the best arm?

- **Concept: Martingale Concentration Inequalities**
  - **Why needed here:** The paper relies on the sequence of rewards being a martingale difference sequence after centering. Understanding Azuma-Hoeffding or Bernstein-type inequalities for matrix martingales is required to follow the proofs in Appendix B.
  - **Quick check question:** In orthogonalized regression, why is the term Σ x̃s νs treated as a martingale?

- **Concept: Phase-Elimination Algorithms**
  - **Why needed here:** The SBE algorithm (Algorithm 2) operates in phases, eliminating suboptimal arms based on confidence intervals. This structure is standard in linear bandits but interacts non-trivially with the semiparametric design here.
  - **Quick check question:** How does the length of a phase nℓ depend on the desired confidence level εℓ in SBE?

## Architecture Onboarding

- **Component map:**
  - DEO Module -> Sampler -> Orthogonalized Estimator -> Eliminator
  - Inputs: Feature set X; Outputs: Sampling distribution pdeo
  - Receives history {(at, rt)}; Computes centered features x̃; Returns θ̂ via Ridge Regression
  - Compares estimated rewards x⊤θ̂; Prunes action set Aℓ

- **Critical path:**
  1. Initialize active arms A1
  2. Run DEO to get distribution pℓ over Aℓ
  3. Sample arms and observe rewards for nℓ rounds
  4. Run Orthogonalized Estimator to get θ̂(ℓ)
  5. Eliminate arms with estimated rewards εℓ below the max
  6. Repeat until one arm remains

- **Design tradeoffs:**
  - Regret vs. PAC: The algorithm is tuned for regret eO(√dT log K). As noted in Section 5.3, the BAI sample complexity is not instance-optimal for fixed instances (unlike specialized pure-exploration algorithms)
  - Computation: DEO runs in O(K) (or O(d2) if solving design directly) but only needs to run O(log T) times (once per phase), unlike prior methods requiring updates every round

- **Failure signatures:**
  - Shift timing: If νt is chosen after the action at (violating Ht-1 measurability), the centering logic fails, and regret may become linear
  - Singularity: If active arms Aℓ do not span the full space, the covariance matrix Σdeo may be singular; the code must handle pseudoinverses or ensure spanning sets are maintained
  - Slow convergence: If d ≫ K, the adaptive modification in Appendix E (K-independent results) should be used to avoid suboptimal log K factors becoming dominant

- **First 3 experiments:**
  1. Synthetic Validation (sine shift): Replicate the experiment in Appendix I with νt = sin(2t). Plot √t · et (error) to verify it remains bounded, confirming the √d rate
  2. Gap-Dependent Regret: Test SBE against a baseline (e.g., BOSE) on a problem with a large gap ∆⋆. Verify that SBE regret becomes constant (flat) after identifying the best arm, while baselines continue to explore
  3. Robustness to Shift Magnitude: Increase the bound on |νt| (e.g., νt = 10 · sin(t)). Although the theory assumes |νt| ≤ 1, verify if the regret scales linearly with the magnitude of the shift (as suggested by the martingale variance terms) or if the mechanism breaks down

## Open Questions the Paper Calls Out

- **Open Question 1:** Can semiparametric bandit algorithms be developed for the fixed-budget best arm identification setting? Basis: Section 7 explicitly lists "developing methods for the fixed-budget setting" as a primary avenue for future work. Why unresolved: The current paper focuses entirely on fixed-confidence guarantees (PAC/BAI) and regret minimization. What evidence would resolve it: An algorithm with theoretical guarantees on the probability of error given a finite, fixed number of rounds T.

- **Open Question 2:** Can the Best Arm Identification (BAI) sample complexity be improved to be instance-dependent minimax optimal? Basis: Section 5.3 states that the current BAI sample complexity of eO(d log K / ∆2⋆) is "not minimax optimal when the instance is fixed." Why unresolved: The current bound is theoretically suboptimal compared to instance-dependent bounds known in linear bandits. What evidence would resolve it: An algorithm achieving sample complexities that match information-theoretic lower bounds specific to the semiparametric instance.

- **Open Question 3:** Is it possible to achieve both optimal sample complexity for pure exploration and optimal regret minimization simultaneously? Basis: Section 7 notes that refining pure exploration to achieve optimal sample complexities is a future direction, parenthetically adding "which may not simultaneously achieve optimal regret." Why unresolved: There is a potential tension between the exploration required for tight sample complexity and the exploitation/regret guarantees. What evidence would resolve it: A single algorithmic framework proven to satisfy both the optimal regret bound (eO(√dT)) and the information-theoretic limit for sample complexity.

## Limitations

- The analysis hinges critically on the adversarial shift being Ht-1-measurable, a condition not always guaranteed in practice
- The dimension-optimal rates depend on the assumption that the number of samples scales at least as d log(dt/δ), which may be prohibitive in high-dimensional regimes
- The practical adaptability of the design module (DEO) is limited by the lack of a specified G-optimal solver and dependency on problem-specific feature generation

## Confidence

- Statistical claims: High
- Practical adaptability of DEO: Medium
- Phase-elimination mechanism integration: High

## Next Checks

1. **Feature Span Robustness:** Systematically test SBE with intentionally rank-deficient active arm sets to quantify regret degradation when the span assumption fails

2. **Shift Timing Violation:** Modify the environment so that νt depends on the current action (violating Ht-1-measurability) and measure whether regret remains bounded or becomes linear

3. **High-Dimensional Scaling:** Run experiments with d ≈ K (dense feature space) and compare SBE's regret to theoretical predictions, verifying if the O(d log K) dependence is indeed necessary or can be improved