---
ver: rpa2
title: 'From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with
  Reinforcement Learning'
arxiv_id: '2512.24532'
source_url: https://arxiv.org/abs/2512.24532
tags:
- shape
- spatial
- rotation
- attention
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of multi-step spatial reasoning\
  \ in large language models (LLMs), which struggle with tasks involving shape transformations\
  \ and planning. The proposed method decomposes spatial reasoning into atomic building\
  \ blocks\u2014rotation, translation, and scaling\u2014through supervised fine-tuning,\
  \ followed by reinforcement learning to compose these primitives into multi-step\
  \ policies."
---

# From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning

## Quick Facts
- **arXiv ID**: 2512.24532
- **Source URL**: https://arxiv.org/abs/2512.24532
- **Reference count**: 25
- **Primary result**: Decomposing spatial reasoning into atomic primitives and applying two-stage training (supervised fine-tuning + reinforcement learning) improves LLM performance on multi-step spatial planning tasks.

## Executive Summary
This paper addresses the challenge of multi-step spatial reasoning in large language models by decomposing complex spatial transformations into atomic building blocks (rotation, translation, scaling) and training through a two-stage pipeline. The approach combines supervised fine-tuning on primitive operations with reinforcement learning to compose these primitives into effective multi-step policies. Evaluated in a synthetic ASCII-art environment, the method demonstrates consistent outperformance over baselines, achieving near-maximum rewards in dynamic settings and showing faster, more stable convergence during RL training.

## Method Summary
The proposed method addresses multi-step spatial reasoning by first decomposing spatial transformations into atomic primitives through supervised fine-tuning, then composing these primitives into multi-step policies via reinforcement learning. The approach uses a synthetic ASCII-art environment to train and evaluate the model. The two-stage training pipeline first teaches the model individual spatial operations (rotation, translation, scaling) and then enables it to chain these operations together to solve complex spatial planning tasks. This decomposition aims to provide better inductive biases for spatial reasoning compared to end-to-end approaches.

## Key Results
- The building block approach consistently outperforms baselines including end-to-end RL and physics-aware models, achieving near-maximum rewards in dynamic settings
- The model shows faster and more stable convergence during RL training compared to end-to-end approaches
- Attention analysis reveals meaningful changes in token focus after fine-tuning, particularly in middle layers, suggesting improved spatial understanding
- The model performs well in static settings requiring internal state tracking, though with some performance gap compared to dynamic settings

## Why This Works (Mechanism)
The method works by leveraging a decomposition strategy that breaks down complex spatial reasoning into learnable primitives, providing clearer learning signals than monolithic approaches. The two-stage training pipeline allows the model to first master individual operations before learning to compose them, creating a more stable learning trajectory. The synthetic environment provides controlled, reproducible training data that captures essential spatial reasoning challenges without the noise of real-world environments. The reinforcement learning stage enables the model to discover optimal action sequences for multi-step planning tasks.

## Foundational Learning
- **Spatial reasoning primitives**: Basic geometric operations (rotation, translation, scaling) that serve as building blocks for complex spatial transformations - needed to decompose complex tasks into learnable components; quick check: model can reliably perform individual operations before composition
- **Multi-step planning**: Sequential decision-making processes where each action affects subsequent states - needed for solving complex spatial tasks requiring temporal reasoning; quick check: model can chain primitives into coherent action sequences
- **Reinforcement learning composition**: Using RL to discover optimal ways to combine learned primitives - needed to bridge supervised fine-tuning and practical task performance; quick check: RL training improves task reward beyond supervised performance
- **Attention mechanism analysis**: Studying how fine-tuning affects token focus across transformer layers - needed to understand how spatial reasoning capabilities emerge in the model; quick check: KL divergence reveals meaningful changes in attention patterns
- **Synthetic environment design**: Creating controlled testbeds for spatial reasoning that capture essential challenges - needed for reproducible evaluation without real-world data requirements; quick check: environment supports both dynamic and static state tracking scenarios

## Architecture Onboarding

**Component Map**
ASCII-art Environment -> 1.5B Parameter LLM -> Supervised Fine-tuning (Primitives) -> Reinforcement Learning (Composition) -> Performance Evaluation

**Critical Path**
Synthetic data generation → Supervised fine-tuning on rotation/translation/scaling primitives → RL fine-tuning for multi-step planning → Performance evaluation in static/dynamic settings

**Design Tradeoffs**
- Synthetic environment vs. real-world data: Synthetic provides control and reproducibility but may miss real-world complexities
- Primitive decomposition vs. end-to-end learning: Decomposition provides clearer learning signals but may limit expressiveness
- ASCII-art representation vs. visual modalities: ASCII is simpler to process but less realistic than images

**Failure Signatures**
- Performance degradation in static settings indicates poor internal state tracking
- Convergence plateaus below optimal rewards suggest insufficient exploration or reward shaping
- Inconsistent behavior across similar tasks indicates lack of generalization from primitives

**3 First Experiments**
1. Test individual primitive operations (rotation, translation, scaling) to verify supervised fine-tuning effectiveness
2. Compare learning curves between building block approach and end-to-end RL baseline
3. Evaluate performance difference between dynamic and static environment settings to assess internal state tracking capability

## Open Questions the Paper Calls Out
### Open Question 1
- **Question**: Does the "building block" decomposition approach generalize to continuous spatial domains or other modalities like vision and robotics?
- **Basis in paper**: [explicit] The authors explicitly leave "the exploration of additional tasks and modalities to future work" in the conclusion.
- **Why unresolved**: The current evaluation is restricted to synthetic ASCII-art environments with discrete action spaces.
- **What evidence would resolve it**: Successful application of the two-stage pipeline to Visual Language Models (VLMs) or physical robot control tasks.

### Open Question 2
- **Question**: Can the model's internal state tracking be improved to close the performance gap between Dynamic and Static settings?
- **Basis in paper**: [inferred] The results show the model "loses track of earlier actions" and diverges from the optimal plan in the Static setting (Figure 3).
- **Why unresolved**: The current architecture lacks an explicit external memory mechanism, causing state drift when the environment does not provide updates.
- **What evidence would resolve it**: Architectural modifications (e.g., memory modules) that raise Static setting rewards to levels comparable with the Dynamic setting.

### Open Question 3
- **Question**: Does the concentration of learning in middle-layer attention mechanisms persist across different base model sizes and architectures?
- **Basis in paper**: [inferred] The analysis reveals middle layers (16 and 20) undergo the most adaptation, but this is observed only in the 1.5B parameter model.
- **Why unresolved**: It is unclear if this layer-wise adaptation pattern is a universal property of spatial reasoning or an artifact of the specific model size.
- **What evidence would resolve it**: Replication of the KL divergence attention analysis on larger models (e.g., 7B or 70B parameters).

## Limitations
- The synthetic ASCII-art environment may not capture the full complexity and variability of real-world spatial reasoning tasks
- The primitive decomposition into rotation, translation, and scaling may not generalize to scenarios requiring more complex geometric transformations
- The study focuses on single-object manipulation, leaving unclear how well the approach scales to multi-object spatial reasoning scenarios
- Evaluation metrics are limited to task-specific rewards within the synthetic environment without assessing cross-domain transfer

## Confidence
- **High confidence**: The claim that supervised fine-tuning on building blocks improves RL stability and convergence speed is well-supported by empirical results
- **Medium confidence**: The assertion that the approach outperforms physics-aware models and demonstrates meaningful attention changes is supported but limited by synthetic evaluation
- **Medium confidence**: Performance gains in static settings requiring internal state tracking are demonstrated, but task complexity remains modest

## Next Checks
1. Evaluate the model's performance on real-world spatial reasoning datasets (e.g., robotic manipulation planning tasks or visual reasoning benchmarks) to assess cross-domain generalization beyond the synthetic ASCII environment
2. Test the approach on multi-object spatial reasoning scenarios to determine whether the building block decomposition scales to more complex planning problems involving multiple entities and interactions
3. Conduct ablation studies varying the number and type of spatial primitives to identify whether the chosen decomposition (rotation, translation, scaling) is optimal or whether alternative primitive sets yield better performance