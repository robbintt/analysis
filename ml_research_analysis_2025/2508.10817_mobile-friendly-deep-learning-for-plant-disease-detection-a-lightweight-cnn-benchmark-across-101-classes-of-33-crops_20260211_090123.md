---
ver: rpa2
title: 'Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN
  Benchmark Across 101 Classes of 33 Crops'
arxiv_id: '2508.10817'
source_url: https://arxiv.org/abs/2508.10817
tags:
- classes
- plant
- accuracy
- disease
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a mobile-friendly deep learning solution for
  plant disease detection across 101 classes of 33 crops. The authors create a comprehensive
  dataset by merging PlantDoc, PlantVillage, and PlantWild datasets, then address
  severe class imbalance through controlled downsampling and augmentation.
---

# Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops

## Quick Facts
- arXiv ID: 2508.10817
- Source URL: https://arxiv.org/abs/2508.10817
- Reference count: 0
- Primary result: 94.7% accuracy achieved by EfficientNet-B1 on 101 disease classes

## Executive Summary
This study presents a comprehensive mobile-friendly deep learning solution for plant disease detection across 101 classes spanning 33 different crops. The authors address the challenge of mobile deployment by evaluating lightweight CNN architectures specifically designed for computational efficiency on resource-constrained devices. By creating a unified dataset through merging PlantDoc, PlantVillage, and PlantWild datasets, they establish a robust benchmark for evaluating disease detection performance across diverse agricultural scenarios.

## Method Summary
The researchers developed a comprehensive dataset by combining three major plant disease datasets: PlantDoc, PlantVillage, and PlantWild. To address severe class imbalance in the merged dataset, they implemented controlled downsampling and augmentation techniques. Several lightweight CNN architectures were evaluated including MobileNetV2, MobileNetV3 variants, and EfficientNet-B0/B1, all selected for their suitability in mobile deployment scenarios. The models were trained and tested on the unified dataset containing 101 disease classes across 33 crops, with performance measured using classification accuracy.

## Key Results
- EfficientNet-B1 achieved the highest classification accuracy of 94.7% across 101 disease classes
- MobileNetV3 variants showed competitive performance while maintaining superior computational efficiency
- The unified dataset approach enabled comprehensive evaluation across diverse crop-disease combinations

## Why This Works (Mechanism)
The success of this approach stems from the combination of lightweight CNN architectures optimized for mobile deployment and the comprehensive dataset that captures diverse disease manifestations across multiple crops. The controlled downsampling and augmentation techniques effectively addressed class imbalance, allowing the models to learn robust features across all disease classes. The EfficientNet-B1 architecture achieved the optimal balance between model complexity and accuracy, providing sufficient representational capacity for the 101-class classification task while maintaining computational efficiency suitable for mobile devices.

## Foundational Learning
- Dataset merging and preprocessing: Essential for creating comprehensive benchmarks and addressing class imbalance
- Why needed: Real-world disease detection requires models trained on diverse, representative data
- Quick check: Verify class distribution and augmentation effectiveness

- Mobile CNN architectures: Understanding MobileNet and EfficientNet design principles
- Why needed: Resource constraints on mobile devices require specialized architectures
- Quick check: Compare FLOPs and parameter counts across models

- Transfer learning for plant disease detection: Leveraging pre-trained models for agricultural applications
- Why needed: Limited labeled data and computational resources make transfer learning practical
- Quick check: Evaluate fine-tuning vs. from-scratch training performance

## Architecture Onboarding

**Component map:** Image input → CNN backbone (EfficientNet-B1) → Global pooling → Dense layers → 101-class output

**Critical path:** Input image processing through convolutional layers → Feature extraction → Classification decision

**Design tradeoffs:** The study prioritized accuracy (94.7%) over minimal computational cost, selecting EfficientNet-B1 as the optimal balance point. This choice favors performance in agricultural deployment over extreme efficiency.

**Failure signatures:** Potential domain shift between merged datasets, class imbalance despite augmentation, and reduced generalization to unseen environmental conditions.

**3 first experiments:**
1. Evaluate inference time and memory usage on target mobile devices
2. Test model performance on cross-dataset validation with independent field data
3. Assess robustness across varying lighting and disease progression stages

## Open Questions the Paper Calls Out
None

## Limitations
- The merged dataset approach may introduce domain shift and dataset bias affecting real-world generalization
- Controlled downsampling may not accurately represent true disease prevalence in agricultural settings
- No cross-dataset validation performed to assess robustness across different growing conditions or imaging environments

## Confidence
- High confidence in the architectural performance comparison methodology
- Medium confidence in the generalization capability across different agricultural environments
- Medium confidence in the practical mobile deployment feasibility without device-specific validation

## Next Checks
1. Conduct cross-dataset validation using independently collected field data to assess real-world robustness
2. Perform on-device benchmarking with actual mobile hardware to measure inference time, memory footprint, and power consumption
3. Test model performance across varying environmental conditions (different lighting, angles, disease progression stages) to evaluate practical deployment readiness