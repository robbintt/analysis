---
ver: rpa2
title: 'CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy
  Abstention'
arxiv_id: '2506.00519'
source_url: https://arxiv.org/abs/2506.00519
tags:
- feedback
- causal
- answer
- language
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of reducing hallucinations in
  multilingual large language models (LLMs) by enabling them to abstain from answering
  when knowledge gaps exist. The proposed method, CausalAbstain, uses causal inference
  to evaluate the impact of multilingual feedback on abstention decisions, helping
  LLMs determine whether to incorporate feedback and which feedback is most useful.
---

# CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention

## Quick Facts
- arXiv ID: 2506.00519
- Source URL: https://arxiv.org/abs/2506.00519
- Reference count: 21
- Primary result: Proposed method outperforms strong baselines, achieving up to 3.5% improvement in abstention accuracy for multilingual LLMs.

## Executive Summary
This paper addresses the challenge of reducing hallucinations in multilingual large language models (LLMs) by enabling them to abstain from answering when knowledge gaps exist. The proposed method, CausalAbstain, uses causal inference to evaluate the impact of multilingual feedback on abstention decisions. By decomposing the decision into Natural Direct Effect (NDE) and Total Indirect Effect (TIE) mediated by feedback, the system determines whether to incorporate feedback and which feedback is most useful. Experiments on two datasets covering encyclopedic and commonsense knowledge show significant improvements, particularly in low-resource languages.

## Method Summary
CausalAbstain employs a causal inference framework to determine whether multilingual feedback should influence an LLM's abstention decision. The method constructs a Structural Causal Model where the answer and feedback mediate the final decision. It calculates NDE (self-consistency without feedback) and TIE (impact of feedback via Jensen-Shannon Divergence) for each language, then compares their magnitudes to decide whether to use feedback. In the multilingual setting, it aggregates votes across related languages to ensure robustness against language-specific biases.

## Key Results
- Achieves up to 3.5% improvement in abstention accuracy compared to strong baselines
- Particularly effective in low-resource languages where knowledge gaps are more prevalent
- CAUSAL-MULTI (multilingual aggregation) outperforms CAUSAL-NATIVE across multiple LLM settings
- Ablation studies confirm the importance of adaptive feedback selection mechanism

## Why This Works (Mechanism)

### Mechanism 1: Causal Effect Decomposition
The decision to abstain is disentangled into the Natural Direct Effect (NDE) of the proposed answer and the Total Indirect Effect (TIE) mediated by generated feedback. The system constructs a Structural Causal Model (SCM) where Question (Q) and Answer (A) influence the final Decision (D) directly (NDE) and indirectly via Feedback (F). It calculates the causal effect of feedback by contrasting decision distributions with and without the feedback mediator using Jensen-Shannon Divergence (JSD).

### Mechanism 2: Adaptive Feedback Selection via Thresholding
The paper suggests that feedback is only useful if its causal impact (TIE) exceeds the model's inherent consistency (NDE). The system compares the magnitude of NDE and TIE: if NDE ≥ TIE, the feedback offers no new signal and the decision relies on the model's original self-consistency; if NDE < TIE, the feedback significantly shifts the decision distribution and is incorporated.

### Mechanism 3: Multilingual Aggregation for Robustness
To mitigate language-specific bias, the system aggregates "abstain" votes across multiple related languages rather than relying on a single source. In the CAUSAL-MULTI setting, feedback is generated in L related languages, TIE is calculated for each, and the final decision is a majority vote across all languages where the feedback was deemed valid.

## Foundational Learning

- **Structural Causal Models (SCMs) & Mediation Analysis**: The mathematical engine of the paper, formalizing "direct" vs. "indirect" effects to implement the NDE/TIE comparison.
  - Quick check: Can you draw the DAG for A → D and A → F → D and identify which path represents the indirect effect?

- **Jensen-Shannon Divergence (JSD)**: Used to quantify the "distance" between the decision distribution with feedback and without feedback, serving as the proxy for causal strength (TIE).
  - Quick check: Why is JSD preferred over KL-Divergence for comparing two probability distributions derived from limited sampling?

- **Self-Consistency in LLMs**: The NDE component effectively measures self-consistency, where high consistency correlates with correctness or confidence.
  - Quick check: In a binary classification setting, if an LLM outputs "True" 9 times out of 10 without feedback, how would that affect the NDE calculation?

## Architecture Onboarding

- **Component map**: Sampler -> Distribution Estimator -> Causal Calculator -> Logic Gate -> Aggregator
- **Critical path**: The Feedback Generation and Sampling loop, requiring O(N × L) LLM calls and directly determining the quality of distribution approximations
- **Design tradeoffs**: Cost vs. Accuracy (high N improves approximation but increases latency/cost), Language Selection (CAUSAL-MULTI improves robustness but doubles/triples inference cost)
- **Failure signatures**: Consistent Hallucination (high NDE, low TIE leading to wrong answers), Feedback Noise (irrelevant feedback causing system to ignore useful signals)
- **First 3 experiments**:
  1. Sanity Check (NDE only): Implement NDE calculation on a dataset where the model is known to be highly accurate to establish a baseline
  2. Feedback Injection: Manually inject incorrect feedback for a known-correct answer to verify TIE mechanism correctly identifies and discards harmful feedback
  3. Low-Resource Stress Test: Run full CAUSAL-MULTI pipeline on a low-resource language (e.g., Bengali) and compare abstention rate against ground truth accuracy

## Open Questions the Paper Calls Out

- **Open Question 1**: How can latent variables, such as intrinsic LLM biases, be formally incorporated into the CausalAbstain causal graph to refine abstention decisions?
  - Basis: "Future work could explore incorporating latent variables, such as LLM biases, to further refine the approach."
  - Why unresolved: Current SCM relies on observable variables and does not account for hidden confounders

- **Open Question 2**: Can integrating external knowledge sources and model uncertainty metrics as contextual factors improve the accuracy of causal abstention?
  - Basis: "In future work, we will explore additional contextual factors, such as model uncertainty and external knowledge sources, to further improve abstention decisions."
  - Why unresolved: Current method relies exclusively on internal feedback generation without external grounding or epistemic uncertainty signals

- **Open Question 3**: How can the computational efficiency of CausalAbstain be optimized to reduce the high inference costs associated with multiple feedback iterations?
  - Basis: The method "requires prompt LLMs multiple times, leading to higher inference costs compared to simpler prompting approaches."
  - Why unresolved: The framework necessitates N iterations across L languages, creating a computational bottleneck for real-time applications

## Limitations
- The causal decomposition relies heavily on the assumption that feedback acts as a clean mediator in the decision process
- The N=3 sampling regime may not adequately capture true decision distributions in ambiguous cases
- The framework requires 10 inference requests per query in the multilingual setting, creating significant computational costs

## Confidence
- **High Confidence**: The general utility of abstention in reducing hallucinations (supported by broader literature and Table 2 evidence)
- **Medium Confidence**: The specific mechanism of comparing NDE and TIE as a valid proxy for "feedback utility" is plausible but depends on SCM correctness and sampling quality
- **Medium Confidence**: The multilingual aggregation strategy is reasonable for reducing language-specific bias, but effectiveness depends on diversity and quality of related languages selected

## Next Checks
1. **Causal Graph Validation**: Manually inspect 10 decisions to verify feedback text is causally relevant to answer and decision, not just noise or restatement
2. **Sampling Sensitivity**: Re-run experiments with N=5 and N=10 iterations to test stability of JSD-based causal estimates and final abstention decisions
3. **Cross-Lingual Consistency**: For queries answered correctly in English, generate feedback in a low-resource language (e.g., Bengali) and verify if feedback is coherent, relevant, and leads to same decision as English feedback