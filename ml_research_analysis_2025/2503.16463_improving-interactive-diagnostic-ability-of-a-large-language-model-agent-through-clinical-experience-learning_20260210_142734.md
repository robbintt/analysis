---
ver: rpa2
title: Improving Interactive Diagnostic Ability of a Large Language Model Agent Through
  Clinical Experience Learning
arxiv_id: '2503.16463'
source_url: https://arxiv.org/abs/2503.16463
tags:
- performance
- diagnosis
- llms
- medical
- diagnostic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the performance gap in large language models
  (LLMs) for interactive medical diagnosis, where LLMs struggle with active information
  gathering and initial diagnosis formation. The core method introduces a plug-and-play
  model-enhanced (PPME) LLM agent that integrates specialized models for initial disease
  diagnosis and inquiry into the history of present illness.
---

# Improving Interactive Diagnostic Ability of a Large Language Model Agent Through Clinical Experience Learning

## Quick Facts
- arXiv ID: 2503.16463
- Source URL: https://arxiv.org/abs/2503.16463
- Reference count: 0
- This study introduces a plug-and-play model-enhanced (PPME) LLM agent that integrates specialized models for initial disease diagnosis and inquiry into the history of present illness, achieving over 30% improvement in initial diagnosis accuracy compared to baseline LLMs.

## Executive Summary
This study addresses the performance gap in large language models (LLMs) for interactive medical diagnosis, where LLMs struggle with active information gathering and initial diagnosis formation. The core method introduces a plug-and-play model-enhanced (PPME) LLM agent that integrates specialized models for initial disease diagnosis and inquiry into the history of present illness. These models are trained on over 3.5 million electronic medical records (EMRs) from Chinese and American healthcare facilities using supervised and reinforcement learning techniques. The PPME LLM achieved over 30% improvement in initial diagnosis accuracy compared to baseline LLMs. In interactive diagnostic scenarios, the final diagnostic accuracy approached levels comparable to using complete clinical data, demonstrating the potential for developing autonomous diagnostic systems.

## Method Summary
The PPME LLM agent uses a plug-and-play architecture where specialized models are trained on structured EMR data to handle the initial diagnosis phase, while the base LLM handles the differential diagnosis phase. Two FNN models are trained: a disease diagnosis model via supervised learning and an inquiry model via PPO reinforcement learning. The inquiry model learns to select optimal questions based on structured HPI vectors and patient embeddings, while the diagnosis model predicts disease probabilities. An analyzer component extracts structured state information from dialogue history to feed the plugin models.

## Key Results
- PPME LLM achieved over 30% improvement in initial diagnosis accuracy compared to baseline LLMs
- Final diagnostic accuracy in interactive scenarios approached levels comparable to using complete clinical data
- The approach successfully addressed the primary LLM deficiency in the initial diagnosis phase rather than the differential diagnosis phase

## Why This Works (Mechanism)

### Mechanism 1: Phase Decomposition and Bottleneck Isolation
- **Claim:** LLMs underperform in interactive diagnosis primarily due to inefficiencies in the initial information gathering and initial diagnosis phases, not in the subsequent differential diagnosis phase.
- **Mechanism:** The diagnostic task is split into two distinct phases: (1) history gathering with initial diagnosis formation and (2) differential diagnosis. LLMs struggle most with Phase 1 due to a lack of experiential intuition for selecting relevant history-of-present-illness (HPI) elements. Once a high-risk disease list is provided, LLMs demonstrate acceptable planning and reasoning for Phase 2. The PPME approach supplements the weak Phase 1 with specialized models trained on clinical EMR data, leaving the LLM to handle Phase 2 where its capabilities are adequate.
- **Core assumption:** The performance degradation in interactive settings stems predominantly from an inability to conduct experience-based history collection and formulate initial hypotheses, rather than from a global lack of reasoning or medical knowledge.

### Mechanism 2: Structured Clinical Experience via Simulated Patient Interactions
- **Claim:** Clinical experience required for effective history-taking and initial diagnosis can be synthesized and learned through interactions with simulated patients derived from structured EMR data, rather than requiring real doctor-patient dialogue transcripts.
- **Mechanism:** EMRs are structured into a defined HPI checklist (85 first-level, 1,177 second-level elements). This transforms open-ended history-taking into a discrete state-action space. A specialized inquiry model is trained using Reinforcement Learning (PPO) to select optimal questions based on current state and patient embeddings. A separate diagnostic model is trained via supervised learning to predict disease probabilities from the collected information. This process allows models to learn "experiential" inquiry strategies by trial and error within a controlled environment, bypassing the need for scarce expert dialogue data.

### Mechanism 3: Plug-and-Play Augmentation to Preserve Base Model Capabilities
- **Claim:** Augmenting LLMs with external, specialized plugin models for specific weak phases (like initial diagnosis) is more effective and efficient than end-to-end fine-tuning of the entire LLM.
- **Mechanism:** Instead of retraining the large LLM, PPME trains small, specialized neural networks (FNNs) for the inquiry policy and initial disease diagnosis. These models are integrated as "plugins." An "analyzer" component (prompt-based) extracts structured state information from dialogue history to feed the plugins. The plugins output the next question topic or disease probabilities, which the LLM then uses to guide its natural language generation. This avoids the computational cost of LLM RL fine-tuning and mitigates "catastrophic forgetting" or "alignment tax" often seen when fine-tuning LLMs for specific verticals.

## Foundational Learning

- **Concept: Diagnostic Phases (Initial vs. Differential)**
  - **Why needed here:** This is the core analytical framework of the paper. Understanding *why* LLMs fail in one phase but succeed in the other is essential for justifying the entire PPME architecture. The solution is built to specifically target the "initial diagnosis" bottleneck.
  - **Quick check question:** Can you explain why an LLM might fail to diagnose a patient during a free-form interview but succeed when given a list of 10 candidate diseases?

- **Concept: Reinforcement Learning (RL) in Discrete Action Spaces**
  - **Why needed here:** The inquiry model is trained using PPO, an RL algorithm, to learn a questioning policy. The problem is framed as selecting an optimal sequence of questions from a discrete set to maximize a reward (diagnostic accuracy). Understanding the basics of states, actions, rewards, and policies is needed to grasp how the "experience" is actually learned.
  - **Quick check question:** In the PPME setup, what constitutes a "state," an "action," and a "reward" for the RL-based inquiry agent?

- **Concept: Catastrophic Forgetting / Alignment Tax in LLM Fine-Tuning**
  - **Why needed here:** This is a key motivation for the plug-and-play design. The paper argues against full LLM fine-tuning because it can degrade other capabilities. This concept is crucial for understanding the architectural tradeoff made by the authors.
  - **Quick check question:** Why might making an LLM an expert at medical question-answering through fine-tuning cause its interactive diagnostic planning ability to get worse?

## Architecture Onboarding

- **Component map:**
    Base LLM (Qwen 2.5 72B-Instruct) -> Analyzer -> Inquiry Model + Disease Diagnosis Model -> Patient Response -> Base LLM

- **Critical path:**
    1. Training: EMRs -> Structured HPI -> Train Diagnosis Model (SL) and Inquiry Model (RL via simulated patient)
    2. Inference (Interactive Diagnosis):
        - LLM greets/asks initial question
        - Loop (e.g., 10 turns):
            - Patient responds
            - Analyzer processes dialogue -> updates state (s_hat_it, e_hat_it)
            - Inquiry Model selects next question topic (a_it)
            - LLM generates natural language question from topic (a_it)
        - After loop, Diagnosis Model outputs ranked disease list from final state
    3. Inference (Final Diagnosis):
        - PPME provides top-10 high-risk diseases
        - A separate LLM (e.g., DeepSeek R1) conducts interactive *differential diagnosis* dialogues to refine the final answer

- **Design tradeoffs:**
    - **Plug-and-Play vs. Fine-Tuning:** Chose plug-and-play to avoid computational cost and catastrophic forgetting, at the potential cost of less integrated, end-to-end learned behavior
    - **Structured HPI vs. Free-Text:** Chose a discrete, structured checklist for HPI to enable efficient RL training, at the cost of potentially missing nuances expressible only in natural language
    - **Specialized vs. General-Purpose:** Chose to train specialized models for a weak phase rather than trying to improve the general-purpose LLM, trading model generality for targeted performance gains

- **Failure signatures:**
    - LLM fails to follow plugin guidance: The LLM ignores or misinterprets the question topic from the Inquiry Model
    - Analyzer extraction errors: Incorrectly structuring HPI from dialogue leads to garbage state for the models
    - Hallucinations in long dialogue: Performance degrades with more questions (e.g., beyond 10 rounds) as the LLM begins to hallucinate
    - Over-reliance on incomplete EMR: Diagnosis is fundamentally limited if the admission EMR doesn't contain the needed information

- **First 3 experiments:**
    1. **Phase-Specific Performance:** Compare LLM diagnostic accuracy in four settings: (History Only - Interactive, Full Info - Interactive, Full Info - Review, Differential - Interactive). Goal: Validate that Phase 1 is the primary bottleneck
    2. **Initial Diagnosis Accuracy:** Compare Recall@K (K=1..5) of PPME against baseline LLMs (general, medical, reasoning) on a held-out test set of simulated patients after a fixed number of dialogue turns. Goal: Quantify the improvement in the targeted Phase 1 task
    3. **Cross-Analysis (Ablation):** Have the base LLM re-diagnose using the dialogue history generated by PPME. Goal: Isolate how much performance gain comes from *better information gathering* (eliciting more HPI) vs. *better diagnosis* (the SL model)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the integration of formal clinical protocols into the PPME framework improve the comprehensiveness of history-taking without sacrificing diagnostic efficiency?
- **Basis in paper:** The authors state, "Future research will need to include clinical protocols to ensure more thorough history-taking," noting that the current model misses approximately 30% of HPI elements identified by physicians.
- **Why unresolved:** The current reinforcement learning approach optimizes for diagnostic accuracy (identifying high-risk diseases) rather than the completeness of the medical record, potentially overlooking relevant clinical data that does not immediately alter the primary diagnosis.
- **What evidence would resolve it:** A comparative study measuring the "Completeness Rate" of gathered HPI elements against a ground truth for models trained with and without clinical protocol constraints.

### Open Question 2
- **Question:** Does the PPME LLM's performance in simulated environments translate to diagnostic accuracy in real-world clinical settings with actual patients?
- **Basis in paper:** The abstract concludes that "further validation studies are needed," and the discussion acknowledges the study as a "proof-of-concept" based solely on retrospective EMR data and simulated dialogues.
- **Why unresolved:** Simulated patients, generated from structured EMR data, lack the ambiguity, conversational variability, and non-compliance often found in live human interactions.
- **What evidence would resolve it:** A prospective clinical trial or "shadow mode" deployment where the PPME LLM interacts with real patients (or observes live consults) and its diagnostic suggestions are evaluated against the final physician diagnoses.

### Open Question 3
- **Question:** Can the diagnostic performance of the PPME agent be improved by incorporating physical examination findings into the interactive loop?
- **Basis in paper:** The paper notes in the limitations that "We did not incorporate physical examination information, as collecting such data via dialogue is impractical," yet acknowledges that the absence of this data may prevent the model from reaching optimal performance.
- **Why unresolved:** Physical exams are a standard component of the initial diagnostic phase (Phase 1) that the model attempts to emulate, and their absence forces the model to rely heavily on history and demographics, potentially limiting accuracy for conditions where palpation or observation is key.
- **What evidence would resolve it:** Experiments utilizing multi-modal inputs (e.g., images, audio, or structured sensor data) alongside dialogue to simulate physical findings, comparing the diagnostic lift against the text-only baseline.

## Limitations
- Study relies entirely on simulated patient interactions derived from structured EMR data, which may not capture real patient complexity
- Performance metrics evaluated on curated dataset rather than real clinical interactions
- Analysis focuses on Chinese and American datasets, potentially limiting generalizability to other healthcare systems

## Confidence
- **High Confidence:** Phase decomposition analysis showing LLMs perform better with pre-specified disease lists is well-supported by experimental results
- **Medium Confidence:** Plug-and-play augmentation outperforming fine-tuning is plausible but relies on indirect evidence
- **Low Confidence:** Structured HPI representation captures sufficient clinical nuance for effective diagnosis, and RL approach generalizes beyond training distribution

## Next Checks
1. Deploy the PPME system in a controlled clinical setting with actual patients to assess whether learned inquiry strategies and diagnosis accuracy transfer to real-world complexity
2. Test the system's performance on EMR data from healthcare systems outside China and the US, particularly those with different disease prevalence patterns and clinical documentation practices
3. Evaluate whether the system maintains diagnostic accuracy over longer dialogue sequences (beyond 10 turns) without degradation from hallucination or state tracking errors