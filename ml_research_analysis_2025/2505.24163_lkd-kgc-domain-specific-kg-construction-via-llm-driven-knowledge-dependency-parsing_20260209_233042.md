---
ver: rpa2
title: 'LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency
  Parsing'
arxiv_id: '2505.24163'
source_url: https://arxiv.org/abs/2505.24163
tags:
- knowledge
- https
- entity
- schema
- types
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LKD-KGC is a framework for unsupervised domain-specific knowledge
  graph construction that addresses limitations in existing LLM-based methods. It
  autonomously analyzes document repositories to infer knowledge dependencies, determines
  optimal processing sequences via LLM-driven prioritization, and autoregressively
  generates entity schemas by integrating hierarchical inter-document contexts.
---

# LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing

## Quick Facts
- arXiv ID: 2505.24163
- Source URL: https://arxiv.org/abs/2505.24163
- Reference count: 40
- Primary result: 10%-20% improvements in precision and recall compared to state-of-the-art baselines across three domain-specific datasets and two base LLMs

## Executive Summary
LKD-KGC presents a novel framework for unsupervised domain-specific knowledge graph construction that leverages LLM-driven knowledge dependency parsing. The system autonomously analyzes document repositories to infer knowledge dependencies, determines optimal processing sequences through LLM-driven prioritization, and generates entity schemas autoregressively by integrating hierarchical inter-document contexts. This schema guides unsupervised extraction of entities and relationships without predefined structures or external knowledge. The framework demonstrates significant performance improvements over existing methods, particularly in handling domain-specific contexts where traditional supervised approaches fall short.

## Method Summary
LKD-KGC operates through a multi-stage process that begins with autonomous analysis of document repositories to identify knowledge dependencies. The framework employs LLM-driven prioritization to determine optimal processing sequences for document analysis. It then autoregressively generates entity schemas by integrating hierarchical inter-document contexts, creating a structured foundation for knowledge extraction. The system uses this schema to guide unsupervised extraction of entities and relationships without relying on predefined structures or external knowledge bases. This approach enables the construction of high-quality domain-specific knowledge graphs while maintaining flexibility and adaptability to different domains.

## Key Results
- Achieves 10%-20% improvements in precision compared to state-of-the-art baselines
- Demonstrates 10%-20% improvements in recall across evaluated datasets
- Shows consistent performance gains across three domain-specific datasets and two base LLMs

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to autonomously discover knowledge dependencies within document repositories and leverage these insights for optimized processing. By using LLMs to prioritize document analysis sequences, LKD-KGC ensures that foundational concepts are established before dependent concepts are processed. The autoregressive schema generation captures hierarchical relationships across documents, creating a more comprehensive understanding of domain-specific knowledge structures. This approach eliminates the need for predefined schemas or external knowledge bases, making the system more adaptable to different domains while maintaining high extraction accuracy.

## Foundational Learning
- Knowledge dependency parsing - Understanding how concepts relate and depend on each other within a domain; needed to establish processing order and ensure comprehensive coverage
- Autoregressive schema generation - Sequentially building entity schemas while maintaining context; needed to create coherent domain structures without predefined templates
- Hierarchical inter-document context integration - Capturing relationships across multiple documents at different levels; needed to build comprehensive domain knowledge graphs
- LLM-driven prioritization - Using language models to determine optimal processing sequences; needed to maximize extraction efficiency and accuracy
- Unsupervised entity and relationship extraction - Extracting structured knowledge without labeled training data; needed to eliminate dependency on manual annotation efforts

## Architecture Onboarding

Component map: Document Repository -> Knowledge Dependency Parser -> LLM Prioritizer -> Schema Generator -> Entity/Relationship Extractor

Critical path: The system follows a sequential flow where document analysis feeds into dependency parsing, which informs prioritization decisions that guide schema generation, ultimately enabling accurate entity and relationship extraction.

Design tradeoffs: The framework trades computational efficiency for unsupervised operation and domain adaptability. While traditional supervised approaches may be faster, LKD-KGC eliminates the need for labeled training data and domain-specific annotations, making it more scalable across different domains.

Failure signatures: Potential failures include incorrect dependency inference leading to suboptimal processing sequences, schema generation errors that propagate through the extraction pipeline, and LLM hallucinations that introduce incorrect entities or relationships into the knowledge graph.

First experiments to run:
1. Test dependency parsing accuracy on a small, controlled document set with known relationships
2. Validate schema generation by comparing against manually created domain schemas
3. Evaluate extraction accuracy on a single document before scaling to document repositories

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited transparency regarding implementation details and evaluation methodology
- Insufficient specification of dataset characteristics, sizes, and construction methods
- No discussion of computational costs or efficiency considerations

## Confidence

| Claim | Confidence |
|-------|------------|
| 10%-20% improvements in precision and recall | Medium |
| Autonomous analysis and dependency parsing | Low |
| Effectiveness across different domains | Medium |

## Next Checks
1. Independent replication of experiments using publicly available datasets with detailed reporting of dataset characteristics, evaluation metrics, and computational requirements
2. Ablation studies to isolate the contribution of knowledge dependency parsing from other factors like prompting strategies or base LLM capabilities
3. Analysis of computational efficiency and cost-effectiveness compared to traditional supervised approaches, including runtime benchmarks and resource utilization metrics