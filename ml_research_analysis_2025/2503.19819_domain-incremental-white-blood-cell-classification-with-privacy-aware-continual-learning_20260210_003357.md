---
ver: rpa2
title: Domain-incremental White Blood Cell Classification with Privacy-aware Continual
  Learning
arxiv_id: '2503.19819'
source_url: https://arxiv.org/abs/2503.19819
tags:
- learning
- data
- performance
- classification
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of continual learning for white
  blood cell classification under domain shifts, where data distributions change across
  different hospitals and sample sources. The authors propose a privacy-aware generative
  replay-based continual learning framework that employs a non-parametric kernel density
  estimation (KDE) generator to mimic past data distributions without storing raw
  medical images.
---

# Domain-incremental White Blood Cell Classification with Privacy-aware Continual Learning

## Quick Facts
- arXiv ID: 2503.19819
- Source URL: https://arxiv.org/abs/2503.19819
- Reference count: 26
- Primary result: Privacy-aware generative replay framework outperforms conventional fine-tuning and continual learning baselines for WBC classification across domain shifts

## Executive Summary
This paper addresses the challenge of continual learning for white blood cell classification when data distributions shift across different hospitals and sample sources. The authors propose a privacy-aware framework that employs non-parametric kernel density estimation (KDE) to generate synthetic representations of past data distributions without storing raw medical images. By combining generative latent replay with Kullback-Leibler divergence-based knowledge distillation, the method effectively mitigates catastrophic forgetting while preserving patient privacy. Experiments across four datasets with varying task orderings and four backbone models demonstrate superior performance compared to conventional fine-tuning and existing continual learning approaches.

## Method Summary
The proposed framework addresses domain-incremental learning for white blood cell classification through a privacy-preserving generative replay approach. The method employs a non-parametric KDE generator that creates synthetic data representations mimicking past distributions without storing actual medical images. During training on new domains, the framework performs generative latent replay by producing synthetic samples from previously seen distributions, which are then used alongside current data. Kullback-Leibler divergence-based knowledge distillation is applied to preserve knowledge from previous tasks. The approach is evaluated across four datasets with varying task orderings and four backbone models (ResNet50, RetCCL, CTransPath, UNI), demonstrating effective mitigation of catastrophic forgetting while maintaining classification accuracy across domain shifts.

## Key Results
- Outperforms conventional fine-tuning and continual learning baselines in average accuracy across domain-incremental WBC classification tasks
- KDE-based generative replay effectively preserves model performance without storing raw medical images
- Superior incremental learning metrics demonstrate effective knowledge retention across multiple task orderings and backbone architectures

## Why This Works (Mechanism)
The framework succeeds by addressing two critical challenges simultaneously: catastrophic forgetting in continual learning and privacy preservation in medical imaging. The KDE-based generative replay creates synthetic representations that capture the statistical properties of past data distributions without storing sensitive patient information. When combined with KL-divergence knowledge distillation, the model maintains a stable representation of previously learned knowledge while adapting to new domain distributions. This dual approach allows the model to incrementally learn from new data sources without losing the ability to classify previously encountered white blood cell types accurately.

## Foundational Learning
- **Catastrophic forgetting**: Neural networks rapidly overwrite previously learned knowledge when trained on new tasks; critical to address in continual learning scenarios where data arrives sequentially
- **Domain shift**: Distribution differences between datasets from different hospitals or sample sources can degrade model performance; quick check: compare feature distributions across source and target domains
- **Generative replay**: Synthetic data generation helps maintain knowledge of past distributions; quick check: validate synthetic samples approximate original distribution statistics
- **Knowledge distillation**: Transfers knowledge from teacher to student models through probability distribution matching; quick check: monitor KL-divergence between old and new model outputs
- **Non-parametric density estimation**: KDE estimates probability distributions without assuming specific parametric forms; quick check: validate KDE bandwidth selection using cross-validation

## Architecture Onboarding

**Component Map:**
Raw Data -> Preprocessing -> Feature Extraction -> KDE Generator -> Synthetic Data Generator -> Classification Model -> Prediction Output

**Critical Path:**
KDE Generator produces synthetic samples representing past distributions -> Combined with current data during training -> KL-divergence distillation preserves old knowledge -> Classification model updates weights while maintaining performance across domains

**Design Tradeoffs:**
- Privacy preservation through KDE vs. potential information loss compared to storing raw data
- Computational overhead of generative replay vs. improved continual learning performance
- Model complexity for KDE implementation vs. scalability to larger datasets

**Failure Signatures:**
- Significant performance drop on previously learned domains indicates catastrophic forgetting
- Poor synthetic sample quality suggests inadequate KDE representation of past distributions
- High KL-divergence values indicate knowledge drift from original model

**First 3 Experiments:**
1. Baseline comparison: Evaluate model performance with and without KL-divergence distillation component
2. Ablation study: Test KDE generator performance using different bandwidth selection methods
3. Cross-dataset generalization: Evaluate model on unseen WBC datasets to assess domain generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to white blood cell classification datasets, limiting generalizability to other medical imaging domains
- Computational complexity of KDE-based generative replay for large-scale medical image distributions not characterized
- Does not compare against federated learning approaches that might address similar privacy concerns through distributed training

## Confidence
- Effectiveness of KDE-based generative replay for privacy preservation: High (supported by experimental results)
- Superiority over conventional fine-tuning and continual learning baselines: Medium (results show improvement but comparisons may be limited by benchmark scope)
- Scalability to real-world clinical deployment: Low (computational requirements and privacy guarantees under operational conditions not fully characterized)

## Next Checks
1. Conduct ablation studies removing the KL-divergence distillation component to quantify its specific contribution to catastrophic forgetting mitigation
2. Evaluate model performance on heterogeneous medical imaging tasks beyond white blood cell classification to assess generalizability
3. Test the framework under realistic data quality variations including motion artifacts, varying magnifications, and different staining protocols common in clinical practice