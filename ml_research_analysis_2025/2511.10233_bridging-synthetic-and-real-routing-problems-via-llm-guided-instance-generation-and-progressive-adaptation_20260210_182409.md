---
ver: rpa2
title: Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation
  and Progressive Adaptation
arxiv_id: '2511.10233'
source_url: https://arxiv.org/abs/2511.10233
tags:
- generator
- instances
- problems
- fine-tuning
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EvoReal bridges the generalization gap between synthetic and real-world
  routing problems by leveraging LLM-guided evolution to generate structurally realistic
  VRP instances. It combines an evolutionary module that synthesizes diverse, TSPLib-like
  distributions with a progressive fine-tuning strategy that incrementally adapts
  neural solvers from synthetic to real data.
---

# Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation

## Quick Facts
- **arXiv ID:** 2511.10233
- **Source URL:** https://arxiv.org/abs/2511.10233
- **Reference count:** 36
- **One-line primary result:** LLM-guided evolution generates structurally realistic VRP instances that improve neural solver generalization, achieving 1.05% optimality gap on TSPLib and 2.71% on CVRPLib.

## Executive Summary
This paper addresses the generalization gap in neural combinatorial optimization solvers trained on synthetic uniform data when applied to real-world routing instances. The proposed EvoReal framework uses an LLM (OpenAI o3) to evolve Python data generators that produce synthetic VRP instances mimicking the structural statistics of real benchmarks (TSPLib, CVRPLib). These evolved instances are used in a two-phase progressive fine-tuning strategy: first training on diverse synthetic data, then refining on actual benchmark instances. The approach significantly improves solver performance without modifying model architectures, achieving state-of-the-art results on standard VRP benchmarks.

## Method Summary
EvoReal employs LLM-guided evolution to generate synthetic VRP instances whose structural attributes (FFT energy, Nearest-Neighbor ratio) statistically match real benchmarks. The framework uses a population-based evolution loop where Python generator code is evolved via LLM operations (crossover, mutation, reflection). Fitness is evaluated through a low-fidelity proxy metricâ€”fine-tuning the solver for few epochs and measuring validation gap. The best generators produce data for Phase 1 progressive fine-tuning, followed by Phase 2 fine-tuning directly on real instances. This curriculum bridges the distributional gap between synthetic and real data.

## Key Results
- Achieves average optimality gaps of 1.05% on TSPLib and 2.71% on CVRPLib across various problem sizes
- Outperforms direct fine-tuning and other baselines in ablation studies
- Demonstrates effectiveness on both TSP (POMO) and CVRP (LEHD) solvers
- Shows progressive fine-tuning provides clear advantage over single-phase approaches

## Why This Works (Mechanism)

### Mechanism 1: Distributional Alignment via Structural Mimicry
The LLM evolves generators to minimize divergence between structural statistics of synthetic and real instances. By targeting FFT energy and NN-ratio distributions, the framework creates synthetic data that captures the "hardness" patterns found in real benchmarks, enabling better solver generalization.

### Mechanism 2: Low-Fidelity Proxy Evaluation
Fitness scores are derived from brief fine-tuning runs rather than full training, enabling efficient evolution search. Early performance trends are assumed to correlate with final convergence, allowing rapid selection of high-quality generators.

### Mechanism 3: Synthetic-to-Real Curriculum
The two-phase progressive fine-tuning creates a smooth training manifold. Phase 1 aligns models with diverse synthetic priors evolved to match real structure, preventing "distribution shock" when transitioning to sparse real data in Phase 2.

## Foundational Learning

- **Neural Combinatorial Optimization (NCO) & POMO**
  - Why needed: Required to evaluate generator fitness; baseline solver being adapted
  - Quick check: Explain how POMO uses augmentation to learn multiple optima, and why it might fail on non-uniform data

- **Spatial Point Pattern Analysis (FFT & NN-Ratio)**
  - Why needed: These metrics serve as loss functions for data generation; understanding their mathematical implications is crucial
  - Quick check: If a TSP instance has high FFT energy, does it imply clustered nodes or regular/repetitive structures? (Answer: Repetitive/Regular)

- **LLM-based Code Evolution**
  - Why needed: Generators are evolved via LLM operations rather than gradient descent
  - Quick check: How does the "Reflector" LLM component improve the "Generator" LLM's output? (Answer: By analyzing success/failure histories and distilling them into long-term reflection)

## Architecture Onboarding

- **Component map:** Input (TSPLib/CVRPLib Validation Set) -> LLM Engine (o3) -> Executor -> Proxy Evaluator -> Selector -> Final Trainer (2-Phase progressive fine-tuning)
- **Critical path:** The Proxy Evaluator is the bottleneck; evaluation length directly impacts evolution speed and fitness signal quality
- **Design tradeoffs:**
  - Realism vs. Diversity: Balance between mimicking real structure and generating diverse instances to prevent overfitting
  - Speed vs. Accuracy: Complex LLM improves quality but increases cost versus simpler genetic algorithms
- **Failure signatures:**
  - Code Hallucination: Invalid syntax or shape violations in generated code
  - Trivial Solutions: Degenerate instances (e.g., all nodes at origin) minimizing tour length artificially
  - Overfitting to Proxy: Generators exploiting proxy model weaknesses rather than creating truly hard instances
- **First 3 experiments:**
  1. Proxy Fidelity Test: Compare evolution results with 1 vs. 10 proxy evaluation epochs
  2. Distribution Visualization: t-SNE plot of generated vs. real instances using FFT/NN-ratio features
  3. Ablation on "Reflector": Remove long-term reflection prompt to isolate LLM reasoning value

## Open Questions the Paper Calls Out

- **Generalization to non-routing problems:** Can the framework extend to MIS and bin packing with richer structural constraints? (Basis: Paper explicitly mentions future work on MIS and bin packing)
- **Architecture-agnostic effectiveness:** Does the framework favor attention-based mechanisms over GNNs or diffusion models? (Basis: Only evaluated on POMO and LEHD attention models)
- **Eliminating Phase 2 fine-tuning:** Can generator quality improve to the point where Phase 2 is unnecessary? (Basis: Ablation shows distinct performance drop without Phase 2)

## Limitations

- Structural metric sufficiency: FFT energy and NN-ratio may not capture all complexity aspects of real routing problems
- Proxy evaluation fidelity: Brief fine-tuning may provide noisy fitness signals and risk overfitting
- LLM evolution overhead: Using sophisticated LLM (o3) is expensive and potentially less reproducible than traditional methods

## Confidence

- **High Confidence:** Progressive fine-tuning strategy shows clear performance improvements
- **Medium Confidence:** LLM-guided evolution produces structurally realistic instances, but metric sufficiency is uncertain
- **Low Confidence:** Efficiency of proxy evaluation method is asserted but not rigorously validated

## Next Checks

1. **Proxy Fidelity Validation:** Run evolution with varying proxy evaluation lengths (1, 5, 10, 20 epochs) and measure correlation between early proxy performance and final solver performance on test sets.

2. **Metric Sufficiency Test:** Extend structural analysis to include edge weight distributions and cluster validity indices, then compare solver performance with original vs. extended feature space.

3. **Cost-Benefit Analysis of LLM vs. GA:** Implement baseline using standard genetic algorithm for generator evolution and compare performance and runtime to LLM-guided approach.