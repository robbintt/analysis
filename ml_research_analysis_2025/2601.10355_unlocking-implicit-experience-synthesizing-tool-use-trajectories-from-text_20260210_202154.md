---
ver: rpa2
title: 'Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text'
arxiv_id: '2601.10355'
source_url: https://arxiv.org/abs/2601.10355
tags:
- tool
- user
- assistant
- frame
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces GEM, a novel text-based paradigm that synthesizes
  multi-turn tool-use trajectories by extracting actionable workflows from unstructured
  text corpora, bypassing the need for predefined tools. The GEM pipeline processes
  text through filtering, workflow and tool extraction, trajectory generation, and
  refinement, and further distills this process into an efficient Trajectory Synthesizer
  via supervised fine-tuning.
---

# Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text

## Quick Facts
- arXiv ID: 2601.10355
- Source URL: https://arxiv.org/abs/2601.10355
- Reference count: 40
- Primary result: Text-derived tool-use trajectories improve multi-turn agent performance by 16.5% on BFCL V3 benchmark

## Executive Summary
This paper introduces GEM, a novel text-based paradigm for synthesizing multi-turn tool-use trajectories by extracting actionable workflows from unstructured text corpora. Unlike prior methods requiring predefined tools, GEM processes text through filtering, workflow and tool extraction, trajectory generation, and refinement to produce high-quality training data for autonomous agents. The approach is further distilled into a Trajectory Synthesizer via supervised fine-tuning, achieving competitive performance while significantly reducing costs.

## Method Summary
GEM processes text corpora through a four-stage pipeline: filtering identifies procedural segments (~14% yield), workflow and tool extraction transforms them into structured trajectories, trajectory generation creates initial agent interactions, and refinement amplifies complexity and diversity. The full pipeline can be distilled into a Trajectory Synthesizer via supervised fine-tuning, which learns to generate trajectories end-to-end while matching pipeline quality at reduced computational cost.

## Key Results
- GEM-32B achieves 16.5% improvement on BFCL V3 Multi-turn benchmark
- Refinement stage raises Qwen3-32B accuracy from 32.50% to 44.88%
- Trajectory Synthesizer matches pipeline quality (28.38% vs 30.25% BFCL accuracy for 8B models) while reducing costs

## Why This Works (Mechanism)

### Mechanism 1: Latent Workflow Extraction from Unstructured Text
Text corpora contain implicit multi-step problem-solving patterns that can be systematically extracted and converted into executable tool-use trajectories. The pipeline identifies procedural content, then extracts user queries, environmental tools, and multi-step workflows, transforming them into structured trajectories. This assumes procedural text encodes agent-relevant reasoning patterns transferable to tool-calling contexts.

### Mechanism 2: Refinement-Induced Complexity Amplification
A dedicated refinement stage substantially increases trajectory difficulty and diversity, directly improving downstream agent performance. Initial trajectories are expanded with more tools, realistic responses, ambiguous user requests, and non-trivial tool-call chains. LLM-based validation filters hallucinations, ensuring quality.

### Mechanism 3: Pipeline Distillation for Scalable Generation
A supervised fine-tuned Trajectory Synthesizer can replicate the multi-stage pipeline's output quality at reduced computational cost. The full pipeline is run once to create training pairs, then a smaller model learns end-to-end text-to-trajectory mapping. The synthesizer matches pipeline quality while being more efficient.

## Foundational Learning

- **Concept:** OpenAI-style function-calling schema
  - **Why needed here:** The entire pipeline outputs tools defined in OpenAI format. Understanding JSON schema for tool definitions is non-negotiable for debugging extraction and generation stages.
  - **Quick check question:** Can you write a valid OpenAI tool schema for `get_weather(city: str, units: optional["celsius"|"fahrenheit"])` with proper type annotations?

- **Concept:** Multi-turn conversation structure (role alternation)
  - **Why needed here:** Trajectories must follow strict turn ordering: user → assistant → [tool call → tool response → assistant]* → user. The validation stage checks this explicitly.
  - **Quick check question:** In a valid trajectory, what role must immediately follow a tool response—user or assistant?

- **Concept:** Supervised fine-tuning (SFT) for instruction following
  - **Why needed here:** Both the agent training and the Trajectory Synthesizer use SFT. Understanding learning rate (5e-6), epochs (2), and the role of demonstration quality is critical.
  - **Quick check question:** Why might a higher learning rate during SFT cause catastrophic forgetting in a pre-trained model?

## Architecture Onboarding

- **Component map:** Raw Text Corpus → [Stage 1: Filter] → Multi-step Segments → [Stage 2: Workflow & Tool Extraction] → (Workflow, Tool Definitions) → [Stage 3: Trajectory Generation] → Initial Trajectory T → [Stage 4: Refinement] → Refined Trajectory T' → [Validation] → Final Trajectories → [Optional: SFT → Trajectory Synthesizer]

- **Critical path:** Stage 4 (Refinement) and Validation are the quality bottlenecks. Ablation shows removing refinement drops 32B performance by ~12 percentage points. LLM-based hallucination detection recovers ~2-3 points.

- **Design tradeoffs:** Single-pass generation vs. multi-agent simulation (GEM is faster but less realistic); pipeline complexity vs. synthesizer efficiency (pipeline is expensive, synthesizer is faster); filter threshold vs. data volume (~86% filtered, balancing quality vs. diversity).

- **Failure signatures:** Hallucinated parameters (tool calls with argument values not grounded in dialogue context); format errors (unclosed role tags, undefined functions, mismatched parameter types); low trajectory diversity (over-reliance on few tool patterns).

- **First 3 experiments:**
  1. Validate extraction quality manually: Sample 50 filtered text segments, run Stages 1-2, and manually assess workflow coherence and tool definitions.
  2. Ablate refinement on small scale: Train 8B model on unrefined vs. refined trajectories for 1K samples each; expect ~3-5 percentage point gap.
  3. Test synthesizer generalization: Train on Ultra-FineWeb, evaluate on Wikihow; >20% performance drop indicates overfitting.

## Open Questions the Paper Calls Out
None

## Limitations
- Quality of extracted workflows depends heavily on filtering classifier precision, with ~86% of text discarded
- Claims about scalability and authenticity of text-derived trajectories are under-validated beyond limited benchmarks
- No detailed cost-benefit analysis comparing pipeline vs. synthesizer computational requirements

## Confidence

- **High confidence:** Core pipeline architecture and ablation showing refinement improves performance by ~12 percentage points
- **Medium confidence:** Assumptions about procedural text encoding transferable tool-use patterns, validated only on limited benchmarks
- **Low confidence:** Claims about significant cost reduction lack detailed computational analysis

## Next Checks

1. **Manual audit of extracted workflows:** Sample 100 filtered text segments and their extracted workflows; rate each for coherence, tool relevance, and alignment with original text. Target >80% coherence.

2. **Cross-domain generalization test:** Train Trajectory Synthesizer on WikiHow, then evaluate on disjoint procedural corpus (e.g., Stack Overflow); measure performance drop, with >20% degradation indicating overfitting.

3. **Real-world API grounding test:** Deploy subset of synthesized trajectories against live APIs (e.g., weather, calendar, flight booking); measure success rate of tool calls and correctness of outputs.