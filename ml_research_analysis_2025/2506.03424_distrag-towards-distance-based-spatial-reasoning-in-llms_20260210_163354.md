---
ver: rpa2
title: 'DistRAG: Towards Distance-Based Spatial Reasoning in LLMs'
arxiv_id: '2506.03424'
source_url: https://arxiv.org/abs/2506.03424
tags:
- spatial
- questions
- reasoning
- graph
- distrag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DistRAG addresses the inability of LLMs to perform reliable spatial
  reasoning about distances between locations. The method encodes geodesic distances
  between cities and towns as an attributed graph and uses retrieval (vector similarity
  or SPARQL query generation) to provide relevant spatial context to the LLM.
---

# DistRAG: Towards Distance-Based Spatial Reasoning in LLMs

## Quick Facts
- **arXiv ID:** 2506.03424
- **Source URL:** https://arxiv.org/abs/2506.03424
- **Reference count:** 22
- **Primary result:** Achieved 90-100% reduction in MSE on distance-based spatial reasoning questions by retrieving relevant geographic triples

## Executive Summary
DistRAG addresses the fundamental limitation of large language models in performing reliable spatial reasoning about distances between locations. The method encodes geodesic distances between cities and towns as an attributed graph and uses retrieval (vector similarity or SPARQL query generation) to provide relevant spatial context to the LLM. When evaluated on distance-based spatial reasoning questions across three difficulty levels, DistRAG achieved significant improvements over the baseline LLM, particularly on easier questions where knowledge graphs were sufficiently complete.

## Method Summary
DistRAG retrieves relevant spatial knowledge triples from a graph encoding geodesic distances between cities before prompting an LLM. The system uses two retrieval variants: vector similarity search with FAISS (retrieving top-10 relevant triples) and SPARQL query generation against an RDF graph. The method was evaluated on 60 Australian location questions across three difficulty levels: Easy (direct A-B distance), Medium (find closest city to A), and Difficult (find city pair with distance similar to A-B). Both DistRAG variants significantly outperformed the baseline GPT-4 on Easy and Medium questions, with the vector similarity approach showing greater robustness to incomplete knowledge graphs.

## Key Results
- Achieved 100% reduction in Mean Squared Error compared to baseline LLM on Easy questions
- Achieved 90-100% reduction in MSE on Medium questions
- Vector similarity variant showed greater robustness to incomplete knowledge graphs than SPARQL variant, which demonstrated an "all or nothing" success pattern

## Why This Works (Mechanism)
DistRAG works by providing LLMs with explicit spatial context through retrieval rather than relying on their internal knowledge. By encoding geodesic distances as a structured graph and retrieving relevant triples based on the prompt, the method grounds the LLM's reasoning in accurate, verifiable spatial information. This approach overcomes the LLM's inherent limitations in memorizing or reasoning about precise distances between arbitrary locations.

## Foundational Learning
- **Geodesic distance computation**: Why needed - to establish accurate spatial relationships between cities; Quick check - verify distance calculations match known benchmarks
- **Graph embedding for retrieval**: Why needed - to efficiently find relevant spatial triples; Quick check - measure retrieval precision@10 on held-out queries
- **RDF serialization**: Why needed - to enable SPARQL-based retrieval; Quick check - execute sample SPARQL queries against test graph

## Architecture Onboarding

**Component map:** OSMnx data extraction -> Graph construction (cities + distances) -> Triple serialization -> Retrieval (FAISS/SPARQL) -> LLM prompting -> Evaluation

**Critical path:** Graph construction → Retrieval → LLM response. The graph must be complete enough to contain relevant triples for each question type.

**Design tradeoffs:** Vector similarity offers robustness to missing edges but may retrieve irrelevant triples; SPARQL offers precision but abstains when queries cannot be satisfied exactly.

**Failure signatures:** SPARQL variant abstains entirely on Difficult questions; vector variant performance degrades sharply with graph sparsity; both methods struggle with multi-hop reasoning.

**3 first experiments:**
1. Build knowledge graph with 10 Australian cities, test on 5 Easy questions
2. Compare FAISS vs SPARQL retrieval on 5 Medium questions with complete graph
3. Measure MSE degradation as graph edges are progressively removed

## Open Questions the Paper Calls Out
**Open Question 1:** Can retrieval-augmented approaches be extended to support reliable multi-hop spatial reasoning (e.g., the "Difficult" questions requiring two hops)? The authors state that complex questions "prove difficult even with RAG" and no method achieved consistent success on Difficult questions.

**Open Question 2:** How can DistRAG be generalized to other spatial relationships beyond geodesic distance (e.g., direction, containment, adjacency)? The conclusion states the work "can be expanded to include other spatial relationships," but the current method is designed specifically for distance attributes.

**Open Question 3:** Can SPARQL-based retrieval be made robust to query complexity without manual templating? The authors note that SPARQL "abstained from answering any of the Difficult questions" but achieved 0 MSE when provided a query template, indicating brittleness in automatic query generation.

## Limitations
- Performance highly dependent on knowledge graph completeness, with SPARQL variant showing "all or nothing" behavior
- Limited evaluation to Australian cities without testing cross-geographic generalization
- Does not address real-world routing constraints (roads, terrain, transport modes) beyond pure geodesic distances

## Confidence
- **Core technical contribution**: High - 90-100% MSE reduction is reproducible under stated conditions
- **Scalability claims**: Medium - study uses fixed, moderately sized graph without testing truly large-scale datasets
- **Practical applicability**: Low - assumes static geodesic distances, ignores real-world routing constraints and multimodal considerations

## Next Checks
1. **Knowledge Graph Completeness Stress Test**: Systematically remove edges from the spatial graph to identify the sparsity threshold where retrieval accuracy degrades, measuring abstention rates and MSE per question type.
2. **Cross-Geographic Generalization**: Replicate the experiment on a different country or continent (e.g., European cities) to test whether DistRAG's performance generalizes beyond the Australian dataset.
3. **Real-World Routing Integration**: Extend the knowledge graph to include road network distances and travel times using APIs like OpenStreetMap routing, and evaluate whether DistRAG can switch between geodesic and network-based reasoning based on query context.