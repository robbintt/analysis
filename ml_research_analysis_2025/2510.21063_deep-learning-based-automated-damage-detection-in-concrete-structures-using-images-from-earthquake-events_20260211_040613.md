---
ver: rpa2
title: Deep learning-based automated damage detection in concrete structures using
  images from earthquake events
arxiv_id: '2510.21063'
source_url: https://arxiv.org/abs/2510.21063
tags:
- damage
- structural
- deep
- learning
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a hybrid deep learning framework to automatically
  detect and classify earthquake-induced structural damage in reinforced concrete
  buildings, focusing on cracking, spalling, and exposed rebar. The approach combines
  YOLOv11 object detectors, image classifiers, and a rule-based fusion system enhanced
  with LightGBM meta-learning for improved interpretability.
---

# Deep learning-based automated damage detection in concrete structures using images from earthquake events

## Quick Facts
- arXiv ID: 2510.21063
- Source URL: https://arxiv.org/abs/2510.21063
- Reference count: 4
- Primary result: 71.04% exact accuracy, 91.92% ±1 accuracy for earthquake-induced structural damage classification

## Executive Summary
This study develops a hybrid deep learning framework that automatically detects and classifies earthquake-induced structural damage in reinforced concrete buildings. The approach combines YOLOv11 object detectors, image classifiers, and a rule-based fusion system enhanced with LightGBM meta-learning for improved interpretability. Using labeled data from the 2023 Türkiye Earthquakes and benchmark datasets, the framework achieves exact classification accuracies of 61.54% and 71.04% on separate post-earthquake datasets, with ±1 accuracies reaching 91.92%. Per-class F1 scores range from 0.128 to 0.844, showing strong performance for zero and heavy damage but lower accuracy for subtle damage levels.

## Method Summary
The framework uses a cascaded architecture with three YOLOv11 models: an inside/outside classifier, a structural component detector (beam/column/wall), and a damage type detector (crack/spalling/rebar). Detection outputs feed into Rule Fusion v2, which applies domain rules (exposed rebar triggers heavy damage) and weighted scoring for other damage levels. A meta-learning layer (LightGBM or logistic regression) optionally refines predictions by learning optimal combination weights. The system was trained on datasets from the 2023 Türkiye Earthquakes and benchmark datasets, with testing on Pohang and Mexico City earthquake damage images.

## Key Results
- Exact classification accuracy of 71.04% on Pohang dataset and 61.54% on Mexico City dataset
- ±1 tolerance accuracy reaches 91.92% on Pohang dataset
- Per-class F1 scores: Zero damage (0.844), Slight (0.384), Medium (0.128), Heavy (0.641)
- Meta-learning improves accuracy on Pohang dataset (73.72%) but underperforms on Mexico City dataset (41.96%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cascaded classifiers reduce false positives by filtering irrelevant images before damage detection.
- **Mechanism:** An initial binary classifier separates indoor/outdoor images; subsequent models identify structural components before applying damage detectors, constraining the search space and reducing background texture misclassification.
- **Core assumption:** Damage indicators are only meaningful when detected on structural components in appropriate contexts.
- **Evidence anchors:** [abstract] automated classification framework identifies inside/outside buildings and structural components; [section 2.3] images must first be classified as inside or outside before detecting structural elements.

### Mechanism 2
- **Claim:** Rule-based fusion of multiple damage detections improves interpretability and handles class imbalance better than end-to-end classification alone.
- **Mechanism:** Exposed rebar detection triggers immediate "heavy" damage classification (domain rule). When rebar is absent, a weighted scoring function aggregates counts of cracks, spalling, and rebar to assign zero/slight/medium levels via thresholds.
- **Core assumption:** The presence of exposed rebar is deterministic evidence of heavy structural damage; other damage types contribute proportionally to severity.
- **Evidence anchors:** [abstract] Steel bars are typically exposed after concrete spalling or large flexural or shear cracks; [section 2.4] Damage is immediately classified as "heavy" if exposed rebar is found.

### Mechanism 3
- **Claim:** Meta-learning (LightGBM/logistic regression) on model outputs can improve classification by learning optimal combination weights across damage detectors.
- **Mechanism:** Raw detection outputs serve as features for a meta-classifier that learns non-linear decision boundaries, outperforming hand-tuned rule thresholds for ambiguous cases.
- **Core assumption:** Systematic patterns exist in how individual model errors correlate, which a meta-learner can exploit.
- **Evidence anchors:** [section 3, Table 2] Meta-Model Decision with Logistic Regression achieved 73.72% accuracy vs. 71.04% for Rule Fusion v2 on PEI dataset.

## Foundational Learning

- **Concept: YOLO object detection architecture**
  - **Why needed here:** YOLOv11 serves as the core detector for cracks, spalling, and exposed rebar. Understanding single-shot detection, anchor boxes, and confidence scoring is essential for debugging detection failures.
  - **Quick check question:** Can you explain why YOLO predicts bounding boxes and class probabilities simultaneously, and how non-maximum suppression filters redundant detections?

- **Concept: Transfer learning and fine-tuning**
  - **Why needed here:** The study uses pre-trained YOLOv11 weights fine-tuned on domain-specific damage datasets. Knowing what layers to freeze vs. fine-tune affects convergence on small datasets.
  - **Quick check question:** When fine-tuning a pre-trained object detector for a new domain with limited data, which layers would you freeze first and why?

- **Concept: Rule-based expert systems vs. learned classifiers**
  - **Why needed here:** The hybrid framework combines neural network outputs with hand-coded engineering rules. Understanding when domain knowledge outperforms data-driven learning is critical for system design.
  - **Quick check question:** In what scenarios would a hard rule (rebar → heavy damage) be preferable to letting a neural network learn this mapping from data?

## Architecture Onboarding

- **Component map:** Input Image → Inside/Outside Classifier → Structural Component Detector → Damage Type Detector → RuleFusion v2 → Meta-Model → Damage Level

- **Critical path:** The rebar detection → heavy damage rule is the highest-impact single decision. False negatives in rebar detection directly cause underestimation of severe damage; false positives cause over-flagging for demolition.

- **Design tradeoffs:**
  - Rule Fusion v2 vs. Meta-Model: Rules are interpretable but brittle; meta-models adapt better but risk overfitting (as seen on MEI dataset)
  - Exact accuracy (61-73%) vs. ±1 accuracy (79-92%): System is reliable for gross categorization but struggles with adjacent-class distinctions
  - Single unified detector vs. specialized detectors: Current design uses multiple specialized YOLO models, increasing inference cost but improving per-task accuracy

- **Failure signatures:**
  - Low F1 on "medium" damage (0.128) with high F1 on "zero" (0.844) and "heavy" (0.641) → model struggles with subtle/intermediate visual indicators
  - Performance drop on MEI vs. PEI → generalization failure due to domain shift (lighting, structural styles, image quality)
  - "Faint or obscure visual indicators" → crack detection threshold too high or background texture confusion

- **First 3 experiments:**
  1. **Baseline ablation:** Test Rule Fusion v1 vs. v2 vs. meta-model on held-out Türkiye EQ images to isolate contribution of each enhancement
  2. **Per-class error analysis:** Visualize false negatives for "slight" and "medium" damage classes to identify whether failures stem from detection misses or classification boundaries
  3. **Domain shift robustness:** Train on combined PEI + Türkiye data, test on MEI; compare against augmentation strategies to quantify generalization gaps

## Open Questions the Paper Calls Out
None

## Limitations
- Performance degrades significantly on Mexico City dataset (41.96% accuracy), suggesting poor cross-dataset generalization
- Exact damage classification remains challenging (61-71% accuracy) despite high ±1 accuracy (91.92%)
- Key architectural details remain unspecified, including exact threshold values for rule-based fusion and specific data augmentation strategies

## Confidence

- **High confidence:** The cascaded detection architecture is technically sound and demonstrates scalability for post-disaster assessment
- **Medium confidence:** The rule-based fusion approach is interpretable but may be brittle to domain variations
- **Low confidence:** Meta-learning performance claims are dataset-dependent and the Mexico City failure suggests overfitting

## Next Checks

1. Conduct ablation study comparing Rule Fusion v1 vs v2 vs meta-model performance on held-out Türkiye earthquake images to isolate contribution of each enhancement
2. Analyze confusion matrices for slight and medium damage classes to determine whether failures stem from detection misses or classification boundary issues
3. Test generalization by training on combined Pohang + Türkiye data and evaluating on Mexico City dataset, comparing against augmentation strategies that simulate lighting and resolution variations