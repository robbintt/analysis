---
ver: rpa2
title: Data-driven tool wear prediction in milling, based on a process-integrated
  single-sensor approach
arxiv_id: '2412.19950'
source_url: https://arxiv.org/abs/2412.19950
tags:
- wear
- tool
- data
- process
- milling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates data-driven methods for tool wear prediction
  in milling, addressing the challenges of generalization and industrial applicability.
  Traditional approaches rely on multi-sensor setups and extensive data, limiting
  their transferability to new processes.
---

# Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach

## Quick Facts
- arXiv ID: 2412.19950
- Source URL: https://arxiv.org/abs/2412.19950
- Authors: Eric Hirsch; Christian Friedrich
- Reference count: 40
- Primary result: ConvNeXt model achieved 99.1% accuracy in tool wear classification using single-accelerometer data from only four milling tools

## Executive Summary
This study addresses the challenge of data-driven tool wear prediction in milling by proposing a cost-effective, single-accelerometer approach that enables effective transfer learning across different machines. The research evaluates multiple machine learning models including ConvNeXt, ConvNeXtLSTM, SVM, and decision trees on two different milling machines. The ConvNeXt model demonstrated exceptional performance with 99.1% accuracy in identifying tool wear states, while also revealing important insights about data requirements and generalization. The study found that surprisingly, models trained on smaller datasets (40% of available data) performed better on new machines compared to those trained on larger datasets, highlighting the importance of avoiding overfitting to machine-specific signatures.

## Method Summary
The approach uses a single-axis MEMS accelerometer mounted in the toolholder to capture radial acceleration during milling operations at approximately 15.38 kHz. Raw vibration signals are processed using a peak-to-peak moving window filter to isolate active milling segments, then transformed into 2D spectrograms using Short-Time Fourier Transform combined with the Welch method. Four machine learning models were evaluated: ConvNeXt (CNN-ViT hybrid), ConvNeXtLSTM (ConvNeXt with LSTM layers), Support Vector Classifier (SVC), and Decision Tree Classifier (DTreeC). Models were trained using a tool-life-cycle-based split strategy, with 3-4 complete tool life cycles for training and unseen tools for validation. The study specifically examined transfer learning capabilities by testing models trained on one machine (Chiron) on a different machine (DMU60FD).

## Key Results
- ConvNeXt achieved 99.1% accuracy in binary tool wear classification, outperforming traditional ML models (82-96% for SVM and decision trees) and sequential models
- Models trained on 40% of available data generalized better to new machines compared to models trained on 80% of data, demonstrating the importance of avoiding overfitting
- Only three tool life cycles were required for acceptable prediction accuracy, making the approach practical for industrial implementation
- Direct generalization to a new milling machine showed inconsistent performance, indicating the need for transfer learning strategies

## Why This Works (Mechanism)

### Mechanism 1
Time-frequency transformation (STFT) likely preserves discriminative wear signatures better than raw time-domain processing for image-based models. The single-axis accelerometer captures complex, non-stationary vibration data. By applying STFT combined with the Welch method, the system converts 1D time-series data into 2D "images" (time vs. frequency). This domain shift allows the ConvNeXt model to treat wear detection as a texture recognition problem, identifying energy shifts in specific frequency bands that correlate with tool degradation. The assumption is that wear-induced signal changes manifest as distinct spatial patterns in the spectrogram that are perceptible to convolutional kernels, while noise remains unstructured or is suppressed by the Welch method.

### Mechanism 2
ConvNeXt (a CNN-ViT hybrid) provides superior feature extraction for limited data regimes compared to sequential models like LSTMs. The ConvNeXt architecture utilizes a pure convolutional backbone with design choices inspired by Transformers, effectively acting as a robust feature extractor. In this study, the standalone ConvNeXt outperformed the ConvNeXtLSTM, suggesting that the STFT input already encapsulates sufficient temporal context, and adding recurrence introduces unnecessary complexity that leads to overfitting when only 3-4 tool life cycles are available. The relevant wear dynamics are captured within the short time-window of the STFT snapshot; long-term temporal dependencies across snapshots are less critical than the spatial frequency features within them.

### Mechanism 3
Limited training data (40% split) paradoxically improves generalization to unseen machines compared to full training (80%). Training on excessive data from a single machine causes the model to overfit to that machine's specific vibration signatures. When transferred to a different machine with different dynamics, the fully trained model fails. However, models trained on less data retain more general "wear" features rather than "machine-specific" features, performing slightly better on the unseen hardware. The assumption is that wear features are partially universal while healthy features are machine-specific; overfitting captures the machine more than the wear.

## Foundational Learning

- **Concept: Short-Time Fourier Transform (STFT)**
  - Why needed here: The bridge between 1D vibration sensors and 2D Deep Learning vision models. Understanding the trade-off between time and frequency resolution is critical.
  - Quick check question: If the milling speed doubles, does the STFT window size need to change to capture the same wear harmonics?

- **Concept: Overfitting in Transfer Learning**
  - Why needed here: The study explicitly shows that "more training data" on Machine A harms performance on Machine B. Understanding this inverse relationship is key to deploying TCM systems.
  - Quick check question: Why would a model with 99% accuracy on the training machine fail on a functionally identical machine at a different site?

- **Concept: Indirect Sensing (Vibration vs. Force)**
  - Why needed here: The paper uses accelerometers to proxy cutting forces. Understanding that vibration is a damped, noisy derivative of force helps in interpreting why signal processing is required.
  - Quick check question: Does an increase in vibration amplitude always indicate tool wear, or could it indicate a change in cutting parameters?

## Architecture Onboarding

- **Component map:**
  iTENDOÂ² accelerometer -> Peak-to-Peak thresholding -> STFT + Welch method (spectrogram) -> ConvNeXt backbone -> Fully Connected head (Binary Classification)

- **Critical path:**
  1. Collecting at least 3 full tool life cycles is the hard constraint for acceptable accuracy
  2. Defining "Worn" (based on 0.2mm flank wear + operator judgment) is the primary source of ground truth uncertainty
  3. Expecting a performance drop on new machines; planning for "few-shot" retraining (transfer learning) is mandatory, not optional

- **Design tradeoffs:**
  - Single Sensor vs. Multi-Sensor: Sacrificed robustness and richness of data for ease of installation and cost
  - ConvNeXt vs. LSTM: Sacrificed long-term sequence modeling for spatial feature robustness and reduced overfitting on small datasets
  - Binary vs. Regression: The system classifies state (Good/Bad) rather than predicting Remaining Useful Life (RUL), simplifying the output but reducing granular insight

- **Failure signatures:**
  - False Positives on New Machine: The model detects "wear" on a new machine because the baseline vibrations are higher/different than the training machine (Domain Shift)
  - High Frequency Blindness: If the new machine's wear signatures appear >4000Hz (where the Chiron-trained model ignores them), the model will output False Negatives

- **First 3 experiments:**
  1. Sanity Check: Train the ConvNeXt model on the STFT data using only 2 tool cycles vs. 4 tool cycles to verify the "minimum data" threshold in your specific environment
  2. Noise Robustness: Add synthetic Gaussian noise to the raw acceleration data before STFT generation to test if the Welch method effectively preserves the signal-to-noise ratio for the classifier
  3. Cross-Machine Baseline: Train on Machine A (e.g., 80% data) and test immediately on Machine B without retraining to quantify the "Domain Gap" specific to your hardware before attempting transfer learning

## Open Questions the Paper Calls Out

- What is the minimum amount of target data required to effectively apply transfer learning to a new milling machine? The conclusion states ongoing research is investigating "the amount of data required for effective transfer learning" following the finding that direct generalization to a new machine is inconsistent.

- Which of the evaluated model architectures adapts most efficiently to new machining conditions? The authors identify "determining which models adapt best" as a specific goal for their concurrent research, though ConvNeXt showed the highest accuracy on the original machine.

- How can industrial data collection and labeling be standardized to facilitate real-world deployment? The conclusion mentions efforts to "explore efficient methods for industrial data collection and labeling" as the current methodology relies on subjective manual labeling by a machine operator.

## Limitations

- The study lacks specification of exact STFT hyperparameters and ConvNeXt architecture details, making exact replication challenging
- Ground truth labeling relies on subjective operator judgment for wear classification, introducing potential uncertainty in the training data
- Significant domain gap between machines remains unresolved, with performance drops indicating substantial adaptation requirements for different manufacturing environments

## Confidence

- **High Confidence:** The core finding that ConvNeXt outperforms traditional ML models (SVM, decision trees) and sequential models (LSTM) on this specific task and dataset
- **Medium Confidence:** The minimum training data requirement (3 tool life cycles) and the observation that smaller training sets generalize better across machines, though this may be specific to the dataset characteristics
- **Low Confidence:** The exact transferability of these results to different materials, cutting conditions, or sensor placements without substantial retraining and validation

## Next Checks

1. **Hyperparameter Sensitivity:** Systematically vary STFT window size and overlap to determine their impact on classification accuracy and identify optimal parameters for your specific milling setup

2. **Cross-Environment Testing:** Evaluate the trained model on data from a third, previously unseen milling machine to quantify the true generalization capability beyond the two machines tested in the study

3. **Ground Truth Verification:** Implement independent wear measurement (optical microscopy or coordinate measuring machine) on test tools to validate the subjective wear labeling process used in the original study