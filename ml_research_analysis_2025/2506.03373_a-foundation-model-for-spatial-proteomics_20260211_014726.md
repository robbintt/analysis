---
ver: rpa2
title: A Foundation Model for Spatial Proteomics
arxiv_id: '2506.03373'
source_url: https://arxiv.org/abs/2506.03373
tags:
- kronos
- cell
- marker
- spatial
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KRONOS is a foundation model for spatial proteomics that addresses
  the challenge of analyzing high-dimensional, multi-channel fluorescence imaging
  data across diverse tissue types and platforms. It uses a self-supervised Vision
  Transformer architecture trained on 47 million single-marker patches from 175 markers,
  16 tissue types, and 8 imaging technologies, incorporating marker-specific and spatially
  contextualized embeddings.
---

# A Foundation Model for Spatial Proteomics

## Quick Facts
- arXiv ID: 2506.03373
- Source URL: https://arxiv.org/abs/2506.03373
- Reference count: 40
- Key outcome: KRONOS is a foundation model for spatial proteomics that addresses the challenge of analyzing high-dimensional, multi-channel fluorescence imaging data across diverse tissue types and platforms.

## Executive Summary
KRONOS is a self-supervised foundation model designed to analyze spatial proteomics data from multiplexed fluorescence imaging. The model addresses the challenge of analyzing high-dimensional, multi-channel imaging data across diverse tissue types and platforms by using a shared convolutional filter and marker-specific sinusoidal encoding to handle variable panel sizes and marker types. Evaluated across 11 cohorts, KRONOS outperforms existing vision models in cell phenotyping, artifact detection, region classification, and patient stratification, achieving state-of-the-art balanced accuracy and data efficiency.

## Method Summary
KRONOS uses a self-supervised Vision Transformer architecture trained on 47 million single-marker patches from 175 markers, 16 tissue types, and 8 imaging technologies. The model employs a shared convolutional kernel and marker-specific sinusoidal encoding to handle variable panel sizes, enabling segmentation-free patch-level analysis. Training uses DINO-v2 SSL with two-stage stratified sampling across 23 tissue-technology subsets to mitigate batch effects. The model outputs CLS token embeddings, marker-specific embeddings, or token embeddings for different downstream tasks, achieving state-of-the-art performance in cell phenotyping and region classification.

## Key Results
- Outperforms existing vision models in cell phenotyping, artifact detection, region classification, and patient stratification
- Achieves state-of-the-art balanced accuracy and data efficiency across 11 cohorts
- Enables segmentation-free patch-level analysis and supports scalable, cross-institutional image retrieval

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** KRONOS generalizes to unseen markers and variable panel sizes by decoupling visual feature extraction from marker identity using a shared convolutional kernel and a non-learnable sinusoidal encoding.
- **Mechanism:** Instead of learning a specific weight for every channel (like an RGB model), the model uses a single convolutional filter (`fembed`) shared across all markers. It appends a fixed sinusoidal vector (similar to positional encoding) to identify the marker type. This allows the transformer to treat marker channels as a variable-length sequence while retaining marker-specific context.
- **Core assumption:** The assumption is that protein markers in fluorescence imaging share low-level visual features (blobs, intensity gradients) that can be extracted by a shared filter, while their biological "meaning" is primarily derived from their identity embedding rather than unique visual textures.
- **Evidence anchors:**
  - [abstract] "...incorporating marker-specific and spatially contextualized embeddings."
  - [section] Page 27: "KRONOS introduces a shared convolutional filter and marker-specific encoding... enables encoding to any number, type, and order of markers."
  - [corpus] "AI-powered virtual tissues..." highlights that different panels limit knowledge transfer; KRONOS addresses this via channel-agnostic processing.
- **Break condition:** This mechanism may fail if applied to modalities where markers have visually distinct noise profiles or textures that require specialized filters (e.g., combining mass cytometry ion maps with fluorescence), or if the sinusoidal encoding fails to sufficiently disambiguate markers with high functional similarity.

### Mechanism 2
- **Claim:** The model captures microenvironment context and enables segmentation-free analysis by processing dense, overlapping patches rather than isolated single-cell crops.
- **Mechanism:** By training on 256x256 patches and evaluating on smaller 32x32 or cell-centered crops, the model is forced to learn spatial relationships and tissue architecture. The "CLS" token summarizes the patch, while token-specific features retain spatial localization, allowing the model to classify regions or retrieve patterns without needing explicit cell boundary masks.
- **Core assumption:** The assumption is that biological identity (e.g., tumor vs. stroma) is encoded in the spatial arrangement and texture of the patch, not just the intensity of a single pixel.
- **Evidence anchors:**
  - [abstract] "...enables segmentation-free patch-level analysis..."
  - [section] Page 11: "KRONOS also introduces the paradigm of segmentation-free patch-level processing... removing the dependency on cell boundaries."
  - [corpus] Weak/missing corpus signal for *patch-based* specifically, but "HEIST" (graph model) supports the general importance of spatial relationships.
- **Break condition:** This approach degrades if the patch size is too large (diluting single-cell resolution) or too small (missing context), or in regions of extreme cellular crowding where a single patch contains multiple distinct phenotypes that cannot be summarized by a single label.

### Mechanism 3
- **Claim:** KRONOS mitigates platform-specific batch effects (staining/imaging variations) through a two-stage stratified sampling strategy during pretraining.
- **Mechanism:** By partitioning the training data into 23 subsets based on tissue-technology pairs and sampling uniformly across these subsets, the model prevents overfitting to overrepresented platforms (like CellDive lymph nodes). This forces the model to learn invariant biological features rather than platform artifacts.
- **Core assumption:** The assumption is that biological structures (e.g., a B-cell) appear sufficiently similar across different fluorescence platforms for the model to align them in embedding space, provided the training distribution is manually balanced.
- **Evidence anchors:**
  - [section] Page 28: "...designed a two-stage stratified sampling strategy... exposed the model to a more balanced distribution... and mitigated bias."
  - [section] Page 23: "Mean marker expression exhibited a larger batch effect... than KRONOS."
  - [corpus] "AdvDINO" explicitly validates the difficulty of domain shift in this field, supporting the need for this mechanism.
- **Break condition:** If a new dataset introduces a technology with fundamentally different physics (e.g., Ion-based imaging vs. Fluorescence) that was not included in the stratified sampling, the model may treat the new physics as a distinct class rather than a variation.

## Foundational Learning

- **Concept: Self-Supervised Learning (SSL) / Knowledge Distillation**
  - **Why needed here:** Spatial proteomics lacks the massive labeled datasets required for supervised learning. You must understand how DINO-v2 uses a student-teacher framework to learn representations from unlabeled multiplex images.
  - **Quick check question:** Can you explain how the "teacher" network is updated (EMA) and why this prevents collapse without negative pairs?

- **Concept: Vision Transformer (ViT) Tokenization**
  - **Why needed here:** Unlike CNNs, ViTs process images as sequences of patches. Understanding how KRONOS modifies this to handle variable "channels" (markers) is critical for architecture onboarding.
  - **Quick check question:** How does KRONOS modify the standard patch embedding layer to accept an arbitrary number of input channels ($M$) instead of 3?

- **Concept: Spatial Proteomics Data Modalities**
  - **Why needed here:** Understanding the input domain (e.g., CODEX vs. MIBI, tissue folding artifacts, batch effects) is necessary to interpret the model's failure modes and the "shared filter" assumption.
  - **Quick check question:** Why does the paper explicitly exclude ion-based modalities (IMC/MIBI) from the current training scope?

## Architecture Onboarding

- **Component map:** Input Layer: Multiplex Image ($H \times W \times M$) → Tokenizer (Shared Conv2D + Sinusoidal Marker Encoding) → ViT-S/16 Encoder (12 layers, 6 heads, 384-dim) → Output Heads: CLS Token: Image-level embedding (Global features), Marker Embeddings: $M$ vectors averaged spatially (Marker-specific features), Token Embeddings: $N$ vectors concatenated (Spatial features)

- **Critical path:** The most fragile component is the **Input Tokenizer**. You must ensure the "Shared Convolutional Filter" is applied correctly across the $M$ dimension and that the sinusoidal encoding aligns with the channel indices. If the marker encoding is misaligned, the model loses all biological specificity.

- **Design tradeoffs:**
  * Shared vs. Independent Filters: Sharing weights allows handling unseen markers but assumes all markers share visual primitives (intensity blobs)
  * CLS vs. Marker Embeddings: Using the CLS token (Image-level) is faster and cheaper ($1 \times 384$ vector), but Marker Embeddings ($M \times 384$) capture significantly more detail for phenotyping (evidenced by Supp. Fig S6)
  * Token Size: 16x16 tokens are standard, but 4x4 tokens with overlap preserve more spatial detail at the cost of sequence length

- **Failure signatures:**
  * Poor Cross-Dataset Transfer: Model performs well on in-distribution test sets but fails on new cohorts (indicates batch effect mitigation failed or domain gap is too large)
  * Marker Confusion: High attention on a marker irrelevant to the predicted cell type (suggests Marker Encoding is not functioning or positional encoding is dominating)
  * Blurry Attention Maps: Attention maps focus on background/artifacts rather than cells (suggests pretraining failed to converge or patch sampling was biased)

- **First 3 experiments:**
  1. Linear Probe Validation: Extract embeddings for the cHL or DLBCL datasets, freeze KRONOS, and train a simple linear classifier to verify the extracted features are linearly separable
  2. Ablation on Marker Encoding: Run inference with "Marker Encoding" disabled (set to zeros or random). You should see a drop in balanced accuracy (reported as ~37.4% drop in Supp Fig S6), confirming the mechanism's value
  3. Embedding Visualization: Perform PCA/t-SNE on the CLS tokens of known cell types (e.g., Tumor vs. T-cells). You should observe distinct clusters forming based on cell type, not just tissue section

## Open Questions the Paper Calls Out

- **Can the KRONOS architecture be effectively adapted to support ion-based imaging modalities such as Imaging Mass Cytometry (IMC) or Multiplexed Ion Beam Imaging (MIBI)?**
  - The authors state that the training dataset "does not currently include ion-based modalities" and that these differ significantly in marker resolution and imaging outputs, potentially requiring "architectural adjustments or modality-specific adaptation strategies."
  - This remains unresolved as the current model is pretrained exclusively on fluorescence-based platforms, and it is unknown if the existing tokenization and encoding strategies transfer to the distinct signal characteristics of ion-based mass cytometry.
  - Success would be demonstrated by pretraining a KRONOS variant on IMC/MIBI datasets and benchmarking against fluorescence-based performance on phenotyping or region classification tasks.

- **How can KRONOS be extended to incorporate temporal or longitudinal data for dynamic tissue modeling?**
  - The authors explicitly identify this as a future direction: "We envision future efforts will focus on... incorporating temporal or longitudinal data to support dynamic tissue modeling."
  - This remains unresolved as the current model processes static spatial snapshots and lacks the temporal mechanisms required to model disease progression or treatment response over time.
  - Success would be demonstrated by a modified architecture that accepts time-series inputs and validation on longitudinal cohorts showing improved prediction of temporal dynamics.

- **Can the KRONOS pretrained backbone effectively facilitate multimodal integration with transcriptomics or clinical data?**
  - The Discussion notes that the backbone "can facilitate future downstream tasks such as... multimodal integration with transcriptomics or clinical data."
  - This remains unresolved as the current study evaluates KRONOS solely on image-based tasks; the alignment of its image embeddings with genomic or clinical feature spaces remains untested.
  - Success would be demonstrated by benchmarks showing that KRONOS embeddings improve performance in multimodal frameworks compared to unimodal baselines.

## Limitations

- **Data availability barrier:** The SPM-47M dataset contains 44% proprietary data that is not publicly accessible, creating a significant barrier to full reproducibility
- **Architecture generalization assumptions:** The shared convolutional filter mechanism assumes all markers share common visual primitives, but this may not hold for modalities with distinct noise profiles or imaging physics
- **Patch-based analysis limitations:** The segmentation-free approach may struggle in regions of extreme cellular crowding where a single patch contains multiple distinct phenotypes

## Confidence

- **High confidence:** The model's ability to outperform existing vision models on the tested datasets (cHL, DLBCL-1/2) and achieve state-of-the-art balanced accuracy
- **Medium confidence:** The generalization claims to unseen markers and variable panel sizes, as these are primarily demonstrated through the ablation study rather than extensive cross-modal testing
- **Low confidence:** The claim that KRONOS "enables segmentation-free patch-level analysis" for all downstream tasks, as this approach may fail in crowded regions and hasn't been tested across the full diversity of tissue types and imaging platforms

## Next Checks

1. **Cross-modal generalization test:** Evaluate KRONOS on ion-based imaging data (IMC/MIBI) that was explicitly excluded from training to assess whether the shared filter assumption holds across different imaging physics

2. **Crowded region performance analysis:** Systematically evaluate KRONOS's patch-level classification accuracy in regions with high cellular density (>10 cells per 256×256 patch) to quantify the segmentation-free approach's limitations

3. **Platform-specific bias quantification:** Compute silhouette scores across conditions on PCA projections of embeddings from each of the 8 imaging platforms to quantify the remaining batch effects after KRONOS processing, particularly for underrepresented platforms