---
ver: rpa2
title: 'T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis'
arxiv_id: '2510.27265'
source_url: https://arxiv.org/abs/2510.27265
tags:
- merging
- across
- medical
- expert
- pretrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces T3, a test-time model merging framework for
  vision-language models (VLMs) in medical imaging that dynamically balances specialist
  and generalist knowledge. The core innovation is using Jensen-Shannon divergence
  between pretrained and fine-tuned model outputs to compute per-sample interpolation
  weights, enabling adaptive fusion that preserves local precision when models agree
  and defaults to generalist robustness under distribution shift.
---

# T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis

## Quick Facts
- **arXiv ID**: 2510.27265
- **Source URL**: https://arxiv.org/abs/2510.27265
- **Reference count**: 27
- **Primary result**: T3B achieves state-of-the-art accuracy (61.36% mean across distribution shifts) and robustness (44.42 mean corruption error) in zero-shot medical imaging.

## Executive Summary
This paper introduces T3, a test-time model merging framework for vision-language models (VLMs) in medical imaging that dynamically balances specialist and generalist knowledge. The core innovation is using Jensen-Shannon divergence between pretrained and fine-tuned model outputs to compute per-sample interpolation weights, enabling adaptive fusion that preserves local precision when models agree and defaults to generalist robustness under distribution shift. A batch-wise variant (T3B) dramatically reduces inference costs while maintaining performance. Experiments across four medical modalities show T3B achieves state-of-the-art accuracy and robustness, outperforming static merging methods and dynamic baselines like DaWin.

## Method Summary
T3 merges a pretrained generalist VLM (CLIP) with a fine-tuned specialist model using JS divergence between their output distributions to compute per-sample interpolation coefficients. These coefficients determine how much weight to give each model's parameters when creating a merged model for inference. T3B extends this by averaging coefficients across batches, reducing inference overhead while preserving adaptivity. The framework requires only one forward pass per batch with precomputed weights, making it efficient for clinical deployment.

## Key Results
- T3B achieves 61.36% mean accuracy across distribution shifts, outperforming static merging and dynamic baselines
- Robustness measured at 44.42 mean corruption error (mCE), demonstrating strong performance on corrupted inputs
- Generalizes across different backbone architectures, validating broad applicability
- Batch-wise variant (T3B) maintains performance while reducing inference costs by factor of N/B

## Why This Works (Mechanism)

### Mechanism 1: Jensen-Shannon Divergence Captures Consensus vs. Disagreement
JS divergence between pretrained and fine-tuned output distributions provides a more reliable merging signal than entropy ratios alone. It is zero when models fully agree and large when both are confident but disagree on different classes. A sigmoid maps JS divergence to interpolation coefficient, biasing toward expert when disagreement is high and toward pretrained model when agreement is high.

### Mechanism 2: Batch-wise Coefficient Averaging Preserves Adaptivity at Lower Cost
Averaging per-sample interpolation coefficients within batches provides near-sample-wise performance with O(B) merges instead of O(N). This amortizes coefficient estimation while retaining input-dependent adaptation by partitioning test set into batches and computing mean coefficient per batch.

### Mechanism 3: Extrapolation Guards Against Extreme Confidence Edge Cases
A small extrapolation factor nudges weights when one model's entropy is abnormally low, preventing over/under-reliance on a single model. When predictive entropy falls below threshold, the merged weight is adjusted toward the more confident model to ensure stability.

## Foundational Learning

- **Jensen-Shannon Divergence**:
  - Why needed: Core coefficient computation; understanding I(x) vs. entropy ratio is essential
  - Quick check: If p_pt = p_ft, what is I(x)? (Answer: 0.)

- **Weight Interpolation / Model Merging**:
  - Why needed: Merged weights θ_merged = (1-λ)θ_pt + λθ_ft are the core operation
  - Quick check: What happens when λ = 0 vs. λ = 1? (Answer: Pure pretrained vs. pure expert.)

- **Vision-Language Model Logits to Probabilities**:
  - Why needed: JS divergence operates on softmax outputs p(x), not raw logits
  - Quick check: Why is softmax necessary before computing KL/JS? (Answer: Divergence requires probability distributions.)

## Architecture Onboarding

- **Component map**: Pretrained model f_pt -> JS divergence module -> Sigmoid mapper -> Extrapolation adjustment -> Parameter merger -> Final inference
- **Critical path**: Forward pass through both models → softmax → JS divergence → sigmoid + extrapolation → (batch average) → merge weights → final inference
- **Design tradeoffs**: T3 (sample-wise) offers higher precision but higher cost; T3B (batch-wise) provides near-equivalent accuracy with reduced overhead
- **Failure signatures**: Accuracy drops on specific modalities suggest expert overfitting; high λ variance within batches indicates heterogeneity; overconfident wrong predictions suggest miscalibration
- **First 3 experiments**:
  1. Sanity check: Verify I(x) ≈ 0 when p_pt = p_ft on synthetic identical outputs
  2. Ablation on coefficient type: Compare JS divergence vs. entropy ratio on Cell Microscopy modality
  3. Batch size sweep: Run T3B with batch sizes {1, 16, 32, 64, 128} on one modality

## Open Questions the Paper Calls Out

### Open Question 1
Can T3 effectively generalize to vision-language tasks beyond zero-shot classification, such as medical image segmentation, object detection, or radiology report generation? The paper states extending T3 to other task types is imperative but all experiments evaluate only zero-shot classification.

### Open Question 2
Can adaptive model merging via information-theoretic coefficients be successfully extended to large language models (LLMs) for cross-task generalization? The conclusion suggests extending T3 to LLMs is promising but T3 is currently validated only for vision-language models.

### Open Question 3
Can learned or alternative agreement metrics (beyond JS divergence) provide more robust interpolation coefficients, particularly when model outputs are sharply peaked or overconfident? Appendix notes developing alternative metrics robust to confident outputs is a direction but current JS-based coefficient relies on hand-tuned thresholds.

## Limitations
- Clinical generalization remains untested on real-world clinical datasets with heterogeneity and noise
- Framework assumes well-calibrated probability distributions from both models, which may not hold in practice
- Computational overhead of forward passing both models initially may be prohibitive for resource-constrained clinical environments

## Confidence

- **High Confidence**: Mathematical formulation of JS divergence and batch-wise efficiency improvements are well-established
- **Medium Confidence**: Claims about T3B achieving state-of-the-art accuracy are supported but acknowledge variation by modality
- **Low Confidence**: Extrapolation mechanism's generalization to other domains and performance on extremely rare pathologies are not validated

## Next Checks

1. **Clinical Dataset Validation**: Test T3B on MIMIC-CXR or CheXpert to evaluate performance in authentic clinical settings with varying image quality and patient demographics.

2. **Model Calibration Analysis**: Systematically evaluate how T3B performs when either model is deliberately miscalibrated and compare against confidence-aware merging strategies.

3. **Resource-Constrained Implementation**: Implement and benchmark a memory-efficient variant of T3B using knowledge distillation or quantization for deployment on clinical edge devices.