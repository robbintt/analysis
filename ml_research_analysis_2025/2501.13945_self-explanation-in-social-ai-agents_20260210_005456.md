---
ver: rpa2
title: Self-Explanation in Social AI Agents
arxiv_id: '2501.13945'
source_url: https://arxiv.org/abs/2501.13945
tags:
- sami
- self-explanation
- social
- questions
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a computational technique for self-explanation
  in social AI agents, specifically SAMI (Social Agent Mediated Interaction), which
  helps students in online classes form social connections. The method combines generative
  AI with knowledge-based AI by using a Task-Method-Knowledge (TMK) framework as a
  self-model and Chain of Thought reasoning with ChatGPT to generate explanations.
---

# Self-Explanation in Social AI Agents

## Quick Facts
- arXiv ID: 2501.13945
- Source URL: https://arxiv.org/abs/2501.13945
- Reference count: 28
- Presents computational technique for self-explanation in social AI agents using TMK framework and Chain of Thought reasoning

## Executive Summary
This paper introduces a computational technique for enabling self-explanation in social AI agents, specifically SAMI (Social Agent Mediated Interaction), which helps students in online classes form social connections. The approach combines generative AI with knowledge-based AI by using a Task-Method-Knowledge (TMK) framework as a self-model and Chain of Thought reasoning with ChatGPT to generate explanations. The technique aims to increase transparency and trust in social AI assistants through introspection over structured self-models.

## Method Summary
The self-explanation technique uses a TMK framework as the self-model, representing the agent's knowledge, tasks, and methods. When questions arise about SAMI's functioning, the system employs Chain of Thought reasoning with ChatGPT to generate explanations. The approach leverages both the structured knowledge in the TMK framework and the generative capabilities of large language models to provide coherent explanations of the agent's behavior and decision-making processes.

## Key Results
- 66-question evaluation showed 49/66 correct answers (37 complete)
- Precision tests indicated consistent responses across multiple queries
- Ablation study demonstrated that information from the self-model significantly improves answer quality
- Initial deployment in live online classes showed students found explanations clear and helpful

## Why This Works (Mechanism)
The approach works by combining the structured, verifiable knowledge from a TMK framework with the generative reasoning capabilities of large language models. The TMK framework provides a comprehensive self-model that captures the agent's capabilities, while the Chain of Thought reasoning helps bridge gaps between structured knowledge and natural language explanations. This combination allows for both accuracy (through the structured model) and flexibility (through generative AI) in producing explanations.

## Foundational Learning
- Task-Method-Knowledge (TMK) Framework: A knowledge-based AI framework representing agent capabilities through tasks, methods, and knowledge; needed for structured self-modeling; quick check: verify completeness of task-method-knowledge mappings
- Chain of Thought Reasoning: A prompting technique that breaks down reasoning into intermediate steps; needed for coherent explanation generation; quick check: evaluate intermediate reasoning steps for logical consistency
- Self-Model Architecture: The structured representation of an AI agent's own capabilities and decision processes; needed for introspective explanations; quick check: test self-model coverage against real-world scenarios

## Architecture Onboarding

Component Map:
User Query -> TMK Self-Model -> Chain of Thought Reasoning -> ChatGPT -> Explanation

Critical Path:
User query → TMK framework lookup → Chain of Thought generation → LLM processing → Response formulation

Design Tradeoffs:
- Structured vs. flexible knowledge representation
- Computational overhead vs. explanation quality
- Privacy considerations in self-disclosure
- Real-time vs. precomputed explanations

Failure Signatures:
- Inconsistent explanations across similar queries
- Inability to explain novel or unexpected behaviors
- Overly generic or vague responses
- Self-referential loops in explanations

First Experiments:
1. Test explanation consistency across semantically similar questions
2. Measure explanation quality with and without TMK framework access
3. Evaluate user comprehension of different explanation styles

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Small sample size (66 questions) may limit generalizability
- Single TMK framework may not capture full complexity of social AI agents
- Does not address potential biases or errors from generative AI component
- Limited evaluation of long-term impact on learning and social connections

## Confidence
- Evaluation methodology: Medium
- Generalizability of results: Low
- Technical approach: Medium

## Next Checks
1. Conduct a larger-scale evaluation with a more diverse set of questions and a broader range of social AI agents to assess the generalizability of the self-explanation technique.
2. Perform a comparative study between the TMK-based self-model and alternative self-modeling approaches to determine the optimal framework for different types of social AI agents.
3. Investigate the long-term impact of self-explanation on student learning outcomes, social connection formation, and overall satisfaction with the social AI assistant in a larger, longitudinal study.