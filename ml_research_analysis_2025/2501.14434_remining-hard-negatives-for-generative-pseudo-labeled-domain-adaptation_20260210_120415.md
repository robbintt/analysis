---
ver: rpa2
title: Remining Hard Negatives for Generative Pseudo Labeled Domain Adaptation
arxiv_id: '2501.14434'
source_url: https://arxiv.org/abs/2501.14434
tags:
- hard
- negatives
- domain
- dense
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of domain adaptation for dense
  retrievers, which struggle with robustness to domain shifts and underperform in
  zero-shot settings across diverse domains. The authors analyze the Generative Pseudo
  Labeling (GPL) approach and propose a method called R-GPL that improves domain adaptation
  by remining hard negatives during the training process.
---

# Remining Hard Negatives for Generative Pseudo Labeled Domain Adaptation

## Quick Facts
- arXiv ID: 2501.14434
- Source URL: https://arxiv.org/abs/2501.14434
- Authors: Goksenin Yuksel; David Rau; Jaap Kamps
- Reference count: 10
- Primary result: R-GPL improves domain adaptation by remining hard negatives during training, boosting performance in 13/14 BEIR and 9/12 LoTTe datasets.

## Executive Summary
This paper addresses the challenge of domain adaptation for dense retrievers using Generative Pseudo Labeling (GPL). The authors identify that pre-retrieved hard negatives become stale and less relevant as the model adapts to new domains. To solve this, they propose R-GPL, which periodically remines hard negatives using the current domain-adapted model during training. This dynamic approach ensures that the model receives more relevant and challenging training signals throughout the adaptation process. The experimental results demonstrate significant improvements in retrieval effectiveness across diverse datasets, validating the effectiveness of remining hard negatives with the domain-adapted model.

## Method Summary
The R-GPL method builds upon the Generative Pseudo Labeling framework by introducing dynamic hard negative remining. Starting with a base GPL model and pre-retrieved hard negatives, R-GPL periodically re-encodes the corpus using the current domain-adapted model and re-mines the top-50 hard negatives. This process occurs every 30,000 training steps, though the optimal frequency is analyzed. The refreshed hard negatives are then used to create new training triplets scored by a cross-encoder teacher, and training continues with MarginMSE loss. The key innovation is that the hard negatives become increasingly relevant to the adapted model's embedding space, providing stronger training signals than static pre-retrieved negatives.

## Key Results
- R-GPL achieves significant performance gains over baseline GPL, improving in 13 out of 14 BEIR datasets.
- The method shows consistent improvements across 9 out of 12 LoTTe datasets.
- Analysis confirms that remined hard negatives are more relevant to queries than pre-retrieved negatives.
- The 30,000-step remining interval provides the best balance between adaptation and stability.

## Why This Works (Mechanism)
The effectiveness of R-GPL stems from the dynamic nature of hard negative mining during domain adaptation. As the model adapts to a new domain, its embedding space shifts, making pre-retrieved hard negatives less relevant and challenging. By remining hard negatives with the current domain-adapted model, R-GPL ensures that the training signals remain appropriate for the model's current state. The remined negatives are more closely aligned with the adapted embedding space, creating stronger contrastive learning signals that drive further adaptation. This creates a positive feedback loop where better negatives lead to better adaptation, which in turn enables the retrieval of even more relevant hard negatives.

## Foundational Learning
- **MarginMSE Loss**: A margin-based loss function that encourages the model to rank relevant documents higher than irrelevant ones by a specified margin. Why needed: Provides stable training signals for contrastive learning. Quick check: Verify loss values decrease over initial training before remining.
- **Hard Negative Mining**: The process of identifying negative examples that are particularly challenging for the model to distinguish from relevant documents. Why needed: Creates stronger training signals than random negatives. Quick check: Ensure remined negatives have higher similarity scores to queries than initial negatives.
- **Cross-Encoder Teacher**: A model that scores query-document pairs by attending over both inputs jointly, providing pseudo-labels for training. Why needed: Generates high-quality training signals despite computational cost. Quick check: Validate teacher scores align with expected relevance patterns.
- **Domain Adaptation**: The process of adapting a model trained on one domain to perform well on a different but related domain. Why needed: Addresses the zero-shot performance gap across diverse domains. Quick check: Compare performance on source vs. target domains.
- **Corpus Re-encoding**: The process of generating embeddings for all documents in the corpus using the current model. Why needed: Updates the embedding space to match the adapted model. Quick check: Monitor GPU memory usage during re-encoding.
- **Synthetic Query Generation**: Creating additional training queries from documents using models like doc2query-T5. Why needed: Expands training data without requiring manual annotation. Quick check: Verify generated queries are semantically related to source documents.

## Architecture Onboarding

Component Map: Query -> Synthetic Query Generator -> Cross-Encoder Teacher -> MarginMSE Loss -> Domain-Adapted Retriever -> Corpus Encoder -> Hard Negative Miner

Critical Path: Training proceeds through synthetic query generation, triplet scoring, margin-based loss computation, and model updates. Every 30k steps, the corpus is re-encoded, hard negatives are remined, and the training data is refreshed.

Design Tradeoffs: The synchronous remining approach ensures training data quality but adds computational overhead. The frequency of remining (30k steps) balances adaptation benefits against training stability. Using pre-trained retrievers for initial negatives provides a reasonable starting point before adaptation begins.

Failure Signatures: Loss spikes immediately after remining are expected as the model encounters new hard negatives. If remining fails to improve performance, verify that the remined negatives are actually different and more relevant than initial negatives. Memory overflow during corpus re-encoding indicates the need for batch processing or alternative encoding strategies.

First Experiments:
1. Verify remining effectiveness by logging document ID overlap between hard negatives before and after the first remining event.
2. Monitor MarginMSE loss after remining to confirm it spikes then recovers within ~5k steps as expected.
3. Test remining frequency sensitivity by running ablations with k=10k, 50k, and 100k step intervals.

## Open Questions the Paper Calls Out
- Can an asynchronous hard-negative index refresh mechanism effectively reduce the training complexity of R-GPL for large corpora? The current synchronous implementation adds significant computational overhead for corpora >1M documents.
- Does the hard negative remining strategy generalize to cross-lingual, multi-lingual, or multi-modal domain adaptation settings? The distribution of embeddings may differ fundamentally in non-text or cross-lingual embedding spaces.
- Would an adaptive remining frequency schedule outperform the fixed interval strategy? It's unclear if a fixed step is robust across different convergence speeds or if the mining frequency should decay as the model stabilizes.

## Limitations
- Missing critical training hyperparameters including batch size, learning rate, optimizer type, and total training steps.
- Exact cross-encoder teacher model architecture and parameters not restated in the paper.
- Number of synthetic queries generated per document and query generation sampling parameters unspecified.

## Confidence
- **High confidence** in the core methodological contribution: remining hard negatives during training provides better training signals than static pre-retrieved negatives.
- **Medium confidence** in the empirical evaluation: reported improvements are plausible given the methodology, but exact replication requires unspecified hyperparameters.
- **Low confidence** in full reproduction: missing critical training configuration details prevent guaranteed replication of specific performance numbers.

## Next Checks
1. Verify remining effectiveness by logging document ID overlap between hard negatives before and after remining to confirm the domain-adapted model is actually retrieving different (and presumably harder) negatives.
2. Monitor training stability by tracking MarginMSE loss after each remining event to confirm it spikes initially then recovers within ~5k steps.
3. Test remining frequency sensitivity by running ablation studies with k=10k, 50k, and 100k step intervals to verify the reported optimal interval of 30k steps.