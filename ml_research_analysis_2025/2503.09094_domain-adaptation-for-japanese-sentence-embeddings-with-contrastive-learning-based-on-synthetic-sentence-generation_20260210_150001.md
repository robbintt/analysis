---
ver: rpa2
title: Domain Adaptation for Japanese Sentence Embeddings with Contrastive Learning
  based on Synthetic Sentence Generation
arxiv_id: '2503.09094'
source_url: https://arxiv.org/abs/2503.09094
tags:
- sentence
- domain
- sentences
- dataset
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of domain adaptation for Japanese
  sentence embeddings, particularly for low-resource languages where large-scale labeled
  datasets are scarce. The authors propose SDJC (Self-supervised Domain adaptation
  for Japanese sentence embeddings with Contrastive learning), which utilizes a data
  generator to create synthetic sentences with the same syntactic structure but different
  semantic meanings.
---

# Domain Adaptation for Japanese Sentence Embeddings with Contrastive Learning based on Synthetic Sentence Generation

## Quick Facts
- arXiv ID: 2503.09094
- Source URL: https://arxiv.org/abs/2503.09094
- Reference count: 40
- Method improves domain adaptation for Japanese sentence embeddings using synthetic data and contrastive learning

## Executive Summary
This paper addresses the challenge of domain adaptation for Japanese sentence embeddings in low-resource scenarios. The authors propose SDJC (Self-supervised Domain adaptation for Japanese sentence embeddings with Contrastive learning), which generates synthetic sentences with identical syntactic structure but different semantic meanings to boost contrastive learning. The method adapts a backbone model to accurately discriminate sentences within specific domains by creating hard negative examples through noun substitution using a fine-tuned T5 model. The approach is evaluated on two domain-specific tasks: clinical sentence similarity and educational information retrieval, demonstrating significant performance improvements over non-adapted models.

## Method Summary
SDJC employs a data generator to create synthetic sentences that maintain syntactic structure while altering semantic meaning through noun substitution. These generated sentences serve as hard negative examples in contrastive learning, helping the backbone model better discriminate between semantically similar sentences within a specific domain. The method uses a pre-trained T5 model to substitute nouns from anchor sentences drawn from domain-specific corpora, creating challenging negative pairs. Positive pairs are formed through random unit dropout on the anchor sentences. This contrastive learning framework adapts the backbone model to the target domain without requiring large-scale labeled datasets, making it particularly suitable for low-resource languages like Japanese.

## Key Results
- SDJC achieves Spearman's rank correlation improvement from 75.26 to 83.00 on clinical sentence similarity task
- SDJC improves MAP from 0.5666 to 0.8196 on educational information retrieval task
- Additional fine-tuning on JSNLI or Wikipedia datasets provides further performance gains

## Why This Works (Mechanism)
The method works by creating synthetic sentences that preserve syntactic structure while introducing semantic variations, effectively simulating the diversity found in real domain-specific data. By using noun substitution to generate hard negatives, the contrastive learning framework is exposed to challenging examples that force the model to learn finer-grained semantic distinctions. This process helps the backbone model develop more discriminative representations that are better suited to the target domain's linguistic characteristics. The combination of synthetic negatives and positive pairs created through dropout enables effective self-supervised adaptation without requiring extensive labeled data.

## Foundational Learning
- **Contrastive Learning**: A training paradigm that learns representations by comparing similar and dissimilar pairs; needed to adapt embeddings to domain-specific semantic distinctions; quick check: verify positive/negative pair creation logic
- **Synthetic Data Generation**: Creating artificial training examples that preserve certain properties while varying others; needed to simulate domain-specific linguistic patterns; quick check: validate syntactic preservation in generated sentences
- **Noun Substitution for Semantic Variation**: Replacing content words to create semantically different sentences; needed to generate challenging negative examples; quick check: measure semantic drift in substituted sentences
- **Sentence Embedding Adaptation**: Fine-tuning pre-trained models for specific domains; needed to improve performance on domain-specific tasks; quick check: compare adapted vs. non-adapted model performance
- **Backbone Model Fine-tuning**: Adapting the base neural architecture to new tasks; needed to leverage pre-trained knowledge while specializing for domain; quick check: monitor loss convergence during adaptation
- **Japanese NLP Specifics**: Handling language-specific features like morphological complexity; needed for effective sentence representation in Japanese; quick check: verify tokenization and morphological analysis accuracy

## Architecture Onboarding

**Component Map:** T5 Generator -> Hard Negative Creation -> Contrastive Learning Framework -> Backbone Model -> Domain-Specific Embeddings

**Critical Path:** T5 model generates noun-substituted sentences → these form hard negative pairs with original sentences → combined with positive pairs from dropout → contrastive loss updates backbone → adapted embeddings used for downstream tasks

**Design Tradeoffs:** Uses noun substitution for simplicity and efficiency versus more complex semantic transformations that might be more expensive; relies on pre-trained T5 versus training from scratch for generation; synthetic data generation versus real domain data collection (which is expensive for low-resource languages)

**Failure Signatures:** If synthetic sentences are too dissimilar, contrastive learning loses effectiveness; if T5 substitution creates unnatural or semantically incoherent sentences, downstream performance suffers; if the domain corpus is too small or unrepresentative, adaptation may not generalize

**First 3 Experiments to Run:**
1. Generate synthetic sentences from a small domain corpus and manually evaluate their syntactic validity and semantic coherence
2. Run contrastive learning with only positive pairs (no negatives) to establish baseline adaptation performance
3. Test noun substitution with varying replacement rates to find optimal balance between semantic change and syntactic preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can generating negatives via subtle synonymous substitutions improve model robustness?
- Basis in paper: [explicit] Page 27 suggests future work on "subtle synonymous substitutions" to create "even harder negative sentences."
- Why unresolved: Current negative generation via noun replacement may not provide sufficiently fine-grained semantic distinctions for contrastive learning.
- What evidence would resolve it: Performance comparison between current SDJC and a synonym-substituted variant on the JACSTS benchmark.

### Open Question 2
- Question: Do Large Language Models (LLMs) outperform T5 for generating hard negative sentences?
- Basis in paper: [explicit] Page 32 proposes exploring "utilizing an LLM" to generate higher-quality hard negatives.
- Why unresolved: It is unknown if the advanced generation capabilities of LLMs provide a better training signal than the currently used fine-tuned T5 model.
- What evidence would resolve it: Ablation studies replacing the T5 generator with an LLM and measuring the resulting backbone model's Spearman's correlation.

### Open Question 3
- Question: Can SDJC generalize to domain-specific tasks beyond clinical STS and educational IR?
- Basis in paper: [explicit] Page 32 states the intent to "evaluate SDJC on more diverse domain-specific downstream tasks."
- Why unresolved: The method has only been validated on two specific tasks within the clinical and educational domains.
- What evidence would resolve it: Evaluation results on additional low-resource Japanese domains (e.g., legal texts) to verify consistent performance improvements.

## Limitations
- Reliance on noun substitution may introduce semantic drift or unnatural sentences affecting downstream performance
- Method validated only on two specific domains (clinical and educational), limiting generalizability
- Translation-based JSTS benchmark construction may introduce noise or bias from translation artifacts

## Confidence
**High Confidence:** The core methodology of using synthetic sentences for contrastive learning and the overall experimental setup are well-documented and reproducible. The reported improvements on the two downstream tasks are statistically significant and align with expectations for domain adaptation approaches.

**Medium Confidence:** The quality and representativeness of the JSTS benchmark dataset constructed through translation, while comprehensive, may contain subtle artifacts from the translation process that could influence results. The effectiveness of the synthetic sentence generation strategy for creating meaningful hard negatives depends on the quality of noun substitution, which may vary across different domains.

## Next Checks
1. Conduct ablation studies to quantify the individual contributions of synthetic sentence generation versus random unit dropout in the contrastive learning framework.

2. Evaluate SDJC's performance across additional Japanese domains (e.g., legal, financial, or technical domains) to assess generalizability beyond the two demonstrated domains.

3. Perform human evaluation of the synthetic sentences to assess their naturalness and semantic validity, particularly focusing on cases where noun substitution might produce semantically incoherent or unnatural sentences.