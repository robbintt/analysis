---
ver: rpa2
title: Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics
  in People Living with Dementia
arxiv_id: '2502.09173'
source_url: https://arxiv.org/abs/2502.09173
tags:
- data
- state
- cognitive
- mmse
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a two-stage representation learning approach
  for analyzing movement behavior dynamics in people living with dementia. The method
  converts time-series activity data into text sequences, encodes them using a language
  model, and then applies PageRank-based dimensionality reduction to uncover low-rank
  latent states.
---

# Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia

## Quick Facts
- arXiv ID: 2502.09173
- Source URL: https://arxiv.org/abs/2502.09173
- Reference count: 36
- Primary result: 5-dimensional PageRank state features predict MMSE with MAE=3.81 and ADAS-Cog with MAE=9.73 using Ridge regression

## Executive Summary
This paper introduces a two-stage representation learning framework that converts time-series activity data from people living with dementia into interpretable, low-dimensional state vectors. The method first transforms sensor data into text sequences, encodes them using a pre-trained language model, then applies PageRank-based dimensionality reduction to uncover latent behavioral states. These states capture clinically meaningful patterns that correlate with cognitive scores. Experiments on 50 participants demonstrate that state features alone achieve strong predictive performance for MMSE and ADAS-Cog scores, outperforming baseline approaches while providing interpretable representations of complex temporal behavior data.

## Method Summary
The framework consists of two main stages: (1) converting time-series sensor data into text sequences, then encoding them using a pre-trained language model fine-tuned with triplet loss and cluster-based sampling, and (2) applying t-SNE for dimensionality reduction, K-means clustering to identify latent states, and PageRank to compress state transition dynamics into a 5-dimensional vector per participant. The method processes PIR sensor data aggregated into 20-minute intervals, creating daily text strings that represent movement patterns. These sequences are encoded into 384-dimensional embeddings, reduced to 2D via t-SNE, clustered into 5 states, and compressed using PageRank on the transition graph. The resulting state vectors are used to predict cognitive scores through Ridge regression with leave-one-out cross-validation.

## Key Results
- State features alone achieve MAE=9.73 (ADAS-Cog) and MAE=3.81 (MMSE) with Ridge regression
- State features outperform baseline location-count features and become more predictive with longer time windows (30-180 days)
- The framework provides interpretable representations where each of the 5 states captures distinct behavioral patterns correlated with clinical metrics

## Why This Works (Mechanism)

### Mechanism 1: Text-to-Embedding Transfer for Temporal Sequences
- Claim: Pre-trained language models can capture behavioral semantics when discrete temporal activity sequences are converted to text, enabling similarity-based clustering of daily movement patterns.
- Core assumption: Movement patterns expressed as text sequences exhibit distributional properties analogous to natural language, such that pre-trained linguistic knowledge transfers meaningfully.
- Evidence anchors: [abstract]: "first stage converts time-series activities into text sequences encoded by a pre-trained language model"
- Break condition: If daily activity strings lack sufficient sequential structure or vocabulary diversity, LM embeddings may collapse to uninformative representations.

### Mechanism 2: PageRank Compression of State Transition Dynamics
- Claim: A participant's movement through latent behavioral states forms a Markov-like graph whose stationary distribution (via PageRank) yields a compact, interpretable feature vector predictive of cognitive status.
- Core assumption: Behavioral dynamics are approximately stationary within the analysis window, and state transition patterns encode clinically relevant information beyond simple state frequencies.
- Evidence anchors: [abstract]: "PageRank vector captures latent state transitions, effectively compressing complex behaviour data into a succinct form"
- Break condition: If transitions are near-uniform (high entropy) or dominated by a single absorbing state, PageRank vectors provide limited discriminative power.

### Mechanism 3: Low-Rank Representation Preserves Clinical Signal
- Claim: The 5-dimensional PageRank state vector alone achieves competitive prediction of MMSE and ADAS-Cog scores, indicating that the compression preserves clinically relevant variance while discarding noise.
- Core assumption: Cognitive status manifests as stable patterns in daily behavioral routines that persist across multiple weeks/months.
- Evidence anchors: [Results, p.5, Table 1]: State features alone achieve MAE=9.73 (ADAS-Cog) and MAE=3.81 (MMSE) with Ridge regression
- Break condition: If cognitive decline manifests primarily through acute events rather than gradual behavioral shifts, or if sensor coverage is irregular, the low-rank assumption may fail.

## Foundational Learning

- Concept: **Triplet Loss with Cluster-Based Sampling**
  - Why needed here: Fine-tuning the language model requires labeled positive/negative pairs, but sensor data is unlabeled. The authors use K-means clusters on one-hot encoded daily sequences to define pseudo-labels.
  - Quick check question: Can you explain why the 30-day window was selected for positive sample selection based on silhouette scores and clinical visit patterns?

- Concept: **Stationary Distribution of Markov Chains (PageRank)**
  - Why needed here: The PageRank vector is the stationary distribution of a random walk on the state transition graph.
  - Quick check question: If a participant's transitions form a disconnected graph (some states unreachable from others), what happens to the PageRank calculation?

- Concept: **t-SNE for Visualization vs. Clustering Preprocessing**
  - Why needed here: t-SNE is used to project 384-dim embeddings to 2D for clustering and visualization.
  - Quick check question: Why might clustering in t-SNE space yield different results than clustering directly in the original 384-dim space?

## Architecture Onboarding

- Component map: Raw PIR sensor logs (second-level) → 20-minute interval aggregation → dominant location per window → text string (72 tokens/day) → Language Model Encoder (all-MiniLM-L12-v2, 384-dim output) → t-SNE projection to 2D → K-means with K=5 → Transition Matrix construction → PageRank computation → 5-dimensional state vector → Ridge regression / Random Forest for MMSE and ADAS-Cog prediction

- Critical path:
  1. Verify data quality: missing sensor periods, participant dropout, "nowhere" label frequency
  2. Fine-tune LM: monitor triplet loss convergence; check embedding separation via silhouette scores across different time windows
  3. Cluster stability: rerun K-means with multiple seeds; check if cluster assignments are stable
  4. PageRank sanity check: visualize transition graphs for extreme cases (high/low cognitive scores)

- Design tradeoffs:
  - Compression ratio vs. information loss: 7.7M → 5 is extreme; ablation shows longer windows improve prediction
  - t-SNE vs. alternatives: t-SNE emphasizes local structure; global relationships may be distorted
  - K=5 clusters: Selected via silhouette scores, but interpretability requires clinical validation
  - Ridge vs. nonlinear models: Ridge with state features alone outperforms Random Forest with combined features

- Failure signatures:
  - High-variance PageRank vectors across time windows for same participant
  - Clusters dominated by single location (e.g., all days in "lounge")—may indicate sensor malfunction
  - Prediction performance degrades when combining state + baseline features
  - LSTM baseline fails catastrophically (MAE=27.78) on the same data

- First 3 experiments:
  1. Reproduce clustering stability: Run K-means with K∈{3,4,5,6,7} on the LM embeddings (before t-SNE) and compare silhouette scores to the t-SNE-projected version.
  2. Ablate time window systematically: Replicate the ablation study with 7, 15, 30, 90, 180 day windows. Verify whether state features consistently outperform baseline as window length increases.
  3. Cross-validate PageRank hyperparameters: Test α∈{0.7, 0.85, 0.95} and different distance thresholds for transition matrix construction. Report MAE changes for cognitive score prediction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed two-stage representation framework be adapted into a generative model to synthesize realistic medical time-series data for data augmentation or alignment?
- Basis in paper: [explicit] The conclusion states, "we could explore transforming this approach into a generative model. Such a model could be used to generate sensitive and hard-to-obtain medical datasets."
- Why unresolved: The current study focuses strictly on representation learning and discriminative prediction rather than data generation.
- What evidence would resolve it: A generative model that produces synthetic movement behavior data that maintains the statistical properties and clinical correlations of the real dataset.

### Open Question 2
- Question: How does the model's predictive performance and latent state stability generalize to a larger, more diverse patient cohort compared to the 50-participant test set?
- Basis in paper: [explicit] The Clinical Challenges section notes, "Expanding the dataset to include a more diverse and representative sample of patients will also be essential for enhancing the model's reliability and applicability."
- Why unresolved: The validation was performed on a limited sample (50 participants) after excluding those with missing data.
- What evidence would resolve it: Replication of the low MAE scores in a multi-center study with significantly more participants.

### Open Question 3
- Question: Do the hypothesized semantic meanings of the five latent states (e.g., high hallway frequency indicating impairment) align with independent clinical diagnostic criteria?
- Basis in paper: [explicit] The paper states that collaborating with clinical experts allows them to "explore the semantics represented by these clusters."
- Why unresolved: The semantic interpretations are currently inferred from correlations and SHAP values rather than validated clinical labels.
- What evidence would resolve it: A clinical study where experts blindly validate the model's state classifications against qualitative behavioral assessments.

## Limitations
- Extreme compression ratio (7.7M sensor points to 5 features) raises concerns about potential information loss
- Small sample size (n=50 test participants) limits generalizability across diverse dementia populations
- Text-based representation approach lacks direct corpus validation for cross-domain transfer

## Confidence

- **High Confidence**: Methodology for converting sensor data to text sequences and PageRank-based state compression are well-specified and reproducible. Reported prediction performance metrics are methodologically sound.
- **Medium Confidence**: Assumption that language model embeddings meaningfully capture behavioral semantics when applied to discrete movement sequences. Novel approach shows empirical success but theoretical justification remains under-explored.
- **Medium Confidence**: Clinical significance of identified latent states and their correlation with cognitive scores. Statistical associations demonstrated, but practical interpretability and actionable insights require further validation.

## Next Checks

1. **Temporal Stability Analysis**: Re-run the PageRank-based state extraction across multiple non-overlapping time windows for the same participants to quantify behavioral stability. High variance in state vectors for stable participants would indicate sensitivity to noise or insufficient temporal aggregation.

2. **Cross-Dataset Generalization**: Apply the trained model to an independent dataset with similar sensor configurations but different participant demographics. Compare state feature distributions and prediction performance to assess generalizability beyond the original cohort.

3. **Clinical Interpretability Validation**: Conduct expert review sessions where clinicians map the five latent states to clinically meaningful behavioral patterns. Document agreement rates and identify which states correspond to established dementia progression markers.