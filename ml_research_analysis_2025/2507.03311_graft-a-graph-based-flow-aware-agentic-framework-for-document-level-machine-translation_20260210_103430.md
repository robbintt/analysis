---
ver: rpa2
title: 'GRAFT: A Graph-based Flow-aware Agentic Framework for Document-level Machine
  Translation'
arxiv_id: '2507.03311'
source_url: https://arxiv.org/abs/2507.03311
tags:
- translation
- discourse
- graft
- agent
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'GRAFT introduces a graph-based agentic framework for document-level
  machine translation that transforms source documents into directed acyclic graphs
  (DAGs) of discourse units. The framework employs four specialized LLM agents: Discourse
  Agent for segmentation, Edge Agent for dependency modeling, Memory Agent for context
  extraction, and Translation Agent for context-aware translation.'
---

# GRAFT: A Graph-based Flow-aware Agentic Framework for Document-level Machine Translation

## Quick Facts
- **arXiv ID:** 2507.03311
- **Source URL:** https://arxiv.org/abs/2507.03311
- **Reference count:** 40
- **Primary result:** Achieves 2.8 d-BLEU improvement on TED test sets and 2.3 d-BLEU for domain-specific translation from English to Chinese compared to strong baselines.

## Executive Summary
GRAFT introduces a graph-based agentic framework for document-level machine translation that transforms source documents into directed acyclic graphs (DAGs) of discourse units. The framework employs four specialized LLM agents: Discourse Agent for segmentation, Edge Agent for dependency modeling, Memory Agent for context extraction, and Translation Agent for context-aware translation. Experiments across eight translation directions and six domains show GRAFT achieves significant improvements in discourse coherence and consistency while maintaining competitive performance with large closed-source models.

## Method Summary
GRAFT processes documents through a pipeline of four LLM agents: (1) Discourse Agent segments documents into coherent discourse units using iterative binary decisions; (2) Edge Agent builds a DAG by identifying non-adjacent dependencies between segments; (3) Translation Agent produces translations for each node while incorporating structured memory; and (4) Memory Agent extracts structured translation memory (entity/pronoun mappings, terminology, summaries) post-translation. The framework uses few-shot prompting with Llama-3.1 and Qwen2.5 backbones, achieving document-level translation through systematic context propagation along the DAG structure.

## Key Results
- Achieves 2.8 d-BLEU improvement on TED test sets over strong baselines
- Demonstrates 2.3 d-BLEU improvement for domain-specific translation from English to Chinese
- Shows effective handling of discourse phenomena including pronoun resolution, terminology consistency, and long-range dependencies
- Maintains competitive performance with large closed-source models while providing qualitative improvements in coherence

## Why This Works (Mechanism)

### Mechanism 1: Discourse Graph Dependency Modeling
The Edge Agent identifies non-adjacent dependencies between discourse units, creating a DAG where edges indicate context dependencies needed for accurate translation. This allows non-local context to be retrieved on demand rather than relying on sliding windows. The structured graph approach achieves 2.0 d-BLEU gains over flat context methods.

### Mechanism 2: Structured Memory Propagation
The Memory Agent extracts structured translation memory (entity/pronoun mappings, terminology, summaries) post-translation and propagates it along DAG edges. This structured approach outperforms raw text context propagation, with ablation studies showing 5.7 d-BLEU gap between full memory and no memory conditions.

### Mechanism 3: Principled LLM-based Segmentation
The Discourse Agent uses LLM-based segmentation to create self-contained discourse units where intra-discourse phenomena can be resolved locally. This approach outperforms heuristic methods, achieving 11.3 d-BLEU gains over RS and 3.6 d-BLEU gains over SC baselines.

## Foundational Learning

**Concept: Directed Acyclic Graphs (DAGs)**
- **Why needed here:** Fundamental representation of document structure where translation dependencies aren't always linear
- **Quick check question:** If sentence A mentions "the report" and sentence E discusses "its conclusions," but B, C, and D are unrelated, where would the edge go in the DAG?

**Concept: Few-Shot Prompting**
- **Why needed here:** All four agents are driven by LLMs using few-shot examples rather than fine-tuning
- **Quick check question:** Why is the Edge Agent's output constrained to a single token while the Translation Agent is allowed up to 4096 tokens?

**Concept: Ablation Studies**
- **Why needed here:** Primary method for validating each architectural choice's contribution
- **Quick check question:** According to Table 7, removing which single memory component causes the largest performance drop?

## Architecture Onboarding

**Component map:** Discourse Agent ($L_{seg}$) $\rightarrow$ Segments document into nodes $\rightarrow$ Edge Agent ($L_{edge}$) $\rightarrow$ Connects nodes into DAG $\rightarrow$ Translation Agent ($L_{trans}$) $\rightarrow$ Translates node-by-node $\rightarrow$ Memory Agent ($L_{mem}$) $\rightarrow$ Extracts structured memory for successor nodes

**Critical path:** Segmentation $\rightarrow$ Graph Construction $\rightarrow$ Iterative Translate $\rightarrow$ Extract Memory loop. Latency determined by sum of LLM calls across all agents and discourse units.

**Design tradeoffs:** Accuracy vs. Latency/Cost (3x slower, 1.5x more expensive than single-shot translation); Structure vs. Noise (aggressive edge detection risks spurious context).

**Failure signatures:**
- **Drift:** Poor Memory Agent summaries degrade subsequent translations
- **Context Overload:** Too many edges may exceed LLM context window or distract translation
- **Segmentation Failure:** Poor cuts fail to resolve pronoun resolution within segments

**First 3 experiments:**
1. Validate Core Pipeline: Run GRAFT on single short document, inspect each agent's output quality
2. Ablate Memory: Compare translations with full pipeline vs. disabled memory on terminology consistency
3. Compare Context Strategies: Implement chain graph baseline and compare d-BLEU scores against full GRAFT DAG

## Open Questions the Paper Calls Out

**Open Question 1:** How does GRAFT's effectiveness scale to low-resource language pairs and specialized domains with limited training data? All experiments were on high-resource language pairs; effectiveness on low-resource languages remains unexplored.

**Open Question 2:** Can the computational overhead of GRAFT's multi-agent pipeline be reduced while maintaining translation quality? The system is 3x slower and 1.5x more expensive than single-shot translation; efficiency optimizations like caching or smaller LLMs need exploration.

**Open Question 3:** What is the optimal memory component configuration across different discourse phenomena and language pairs? Current fixed five-component structure shows varying importance across languages; optimal subset or weighting needs systematic study.

**Open Question 4:** How robust is the LLM-based discourse segmentation to different document structures and writing styles? Segmentation quality only evaluated on TED talks and structured texts; generalization to legal, technical, or non-Western document structures untested.

## Limitations
- Computational overhead makes system 3x slower and 1.5x more expensive than single-shot translation
- Results rely heavily on few-shot prompting without fine-tuning, making performance sensitive to prompt engineering
- Limited qualitative analysis beyond anecdotal comparisons with commercial systems
- No evaluation on low-resource language pairs or specialized technical domains

## Confidence

- **High Confidence:** Ablation studies demonstrating structured memory importance and comparative d-BLEU results against baselines
- **Medium Confidence:** LLM-based segmentation outperforming heuristic methods (limited external validation)
- **Medium Confidence:** DAG structure superiority over chain graphs (specific edge patterns may be prompt-sensitive)

## Next Checks

1. **Prompt Sensitivity Analysis:** Systematically vary few-shot examples in each agent's prompt to measure robustness to prompt engineering choices
2. **Cross-Domain Generalization:** Test GRAFT on additional domains (legal, technical documentation) beyond the six reported domains
3. **Commercial System Comparison:** Conduct systematic quantitative comparisons with commercial translation systems across same evaluation metrics