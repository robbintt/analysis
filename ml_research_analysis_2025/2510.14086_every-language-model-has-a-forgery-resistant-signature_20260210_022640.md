---
ver: rpa2
title: Every Language Model Has a Forgery-Resistant Signature
arxiv_id: '2510.14086'
source_url: https://arxiv.org/abs/2510.14086
tags:
- ellipse
- language
- outputs
- output
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel approach to identify the source
  of language model outputs by leveraging a geometric property: language model outputs
  lie on the surface of a high-dimensional ellipse (hyperellipsoid). The authors propose
  using this ellipse constraint as a "signature" for the model, which has unique properties
  compared to existing methods.'
---

# Every Language Model Has a Forgery-Resistant Signature

## Quick Facts
- arXiv ID: 2510.14086
- Source URL: https://arxiv.org/abs/2510.14086
- Reference count: 23
- One-line primary result: Language model outputs lie on ellipsoid surfaces in high dimensions, providing a naturally occurring, forgery-resistant signature that can verify model identity without model weights.

## Executive Summary
This paper introduces a novel approach to identify the source of language model outputs by leveraging a geometric property: language model outputs lie on the surface of a high-dimensional ellipse (hyperellipsoid). The authors propose using this ellipse constraint as a "signature" for the model, which has unique properties compared to existing methods. The signature is naturally occurring (present in all modern language models), self-contained (verifiable without model inputs or full weights), compact and redundant (detectable in each logprob output), and forgery-resistant (hard to replicate without direct access to model parameters). The authors demonstrate the effectiveness of this method by showing that outputs from various models can be correctly identified by checking their distance to the model's ellipse. They also show that while it's possible to extract the ellipse from a model's outputs, it is computationally expensive and practically infeasible for large-scale models, making the signature forgery-resistant. Finally, the authors propose using this ellipse signature as a message authentication code for language model output verification, analogous to cryptographic systems.

## Method Summary
The authors propose identifying language model outputs by checking if they lie on the model's characteristic ellipsoid in high-dimensional space. They leverage the fact that modern LMs use normalization layers that map hidden states to spheres, followed by linear transformations that produce ellipsoids in logit space. To verify an output, they apply the inverse affine transform and check if the result has unit magnitude (indicating it lies on the ellipsoid). Ellipse extraction requires collecting O(d²) samples and fitting via semidefinite programming with O(d⁶) time complexity, making forgery computationally infeasible for large models.

## Key Results
- Language model logprobs lie on high-dimensional ellipsoids due to normalization and linear projection layers
- Verification shows the true source model is orders of magnitude closer to its own ellipse than other models
- Ellipse extraction requires O(d⁶) time and O(d⁴) space, making it infeasible for production-scale models
- The method works across different model architectures and can verify outputs using only logprob vectors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language model outputs lie on a high-dimensional ellipse due to sequential normalization and linear transformation in final layers.
- Mechanism: Final normalization layer maps hidden representations onto a d-dimensional sphere by setting magnitude to constant. The subsequent linear layer (unembedding matrix) applies affine transformation (stretch, rotation, bias) to this sphere, producing a d-dimensional ellipsoid in v-dimensional logit space.
- Core assumption: Models use standard architecture with normalization followed by linear projection, encompassing virtually all modern LMs.
- Evidence anchors: [abstract] "language model outputs lie on the surface of a high-dimensional ellipse... naturally occurring, since all modern language models have these elliptical constraints"; [Section 2.1] "Normalization has the property of mapping inputs onto the surface of a d-dimensional sphere... the logits lie on the surface of a d-dimensional ellipsoid"
- Break condition: Models without final normalization layers or with significantly different output architectures may not produce ellipsoidal constraints.

### Mechanism 2
- Claim: Ellipse extraction is computationally expensive, making forgery practically infeasible for production-scale models.
- Mechanism: Recovering the ellipse requires fitting a quadric surface to O(d²) output samples. Fitting algorithm involves solving O(d²) equations with O(d²) variables, resulting in O(d⁶) time complexity and O(d⁴) space complexity. Query complexity from APIs adds O(d³ log d) cost.
- Core assumption: Attacker has only API access returning logprobs and must collect sufficient samples to uniquely define the ellipse.
- Evidence anchors: [abstract] "ellipse extraction is computationally expensive (O(d^6) time complexity) and practically infeasible for production-scale models"; [Section 3.2] "a set of O(d²) points is required in the general case to uniquely define an ellipse"; [Section 3.3] "Fitting a degree-6 polynomial to these points... recovering parameters from a typical 70 billion parameter model would take thousands of years"
- Break condition: If faster ellipsoid-specific fitting algorithms are discovered or if API access provides more information, extraction costs could decrease.

### Mechanism 3
- Claim: Verifying an output against a known ellipse cleanly identifies the generating model with high confidence.
- Mechanism: Apply inverse affine transform (using pseudoinverse of projection matrix) to logprob vector. If output came from the model, this transformation maps it back onto the unit sphere. Deviation from unit magnitude indicates distance from the ellipse.
- Core assumption: Verifier has access to ellipse parameters (projection matrix, stretch, rotation, bias) from model's final layers.
- Evidence anchors: [Section 2.2] "To measure the distance of a logprob ℓ to the ellipse, we inspect the magnitude of the ellipse's inverse affine transform applied to the logprob"; [Figure 3] Shows mean distance to ellipse is orders of magnitude smaller for true source model compared to others
- Break condition: If logprobs are modified post-generation or if numerical precision issues arise, verification may fail or produce false positives.

## Foundational Learning

- Concept: Affine transformations and ellipsoid geometry
  - Why needed here: Understanding how normalization (sphere constraint) combined with linear transformation (rotation, scaling, translation) produces an ellipsoid in high-dimensional space.
  - Quick check question: Can you explain why an affine transformation of a sphere produces an ellipsoid, and what the singular values of the transformation matrix represent?

- Concept: Normalization layers in transformers (RMSNorm, LayerNorm)
  - Why needed here: The epsilon smoothing term in normalization affects whether outputs lie exactly on the ellipsoid surface or slightly inside, impacting extraction accuracy.
  - Quick check question: How does the ε term in RMSNorm affect the output distribution, and why does this matter for ellipsoid fitting?

- Concept: Cryptographic message authentication codes (MACs)
  - Why needed here: The paper draws an analogy between ellipse signatures and symmetric-key MAC systems, where the ellipse functions as a secret key.
  - Quick check question: In a MAC system, what makes forgery infeasible, and how does this analogy apply to ellipse signatures?

## Architecture Onboarding

- Component map: Input -> [Transformer layers] -> Hidden state (d dimensions) -> [Normalization] -> Unit sphere surface (d dimensions) -> [Linear layer: W(γ⊙x̂ + β)] -> Ellipsoid in logit space (v dimensions) -> Logits -> [Softmax] -> Probabilities

- Critical path:
  1. Understand normalization constraints (sphere surface)
  2. Understand affine transformation effects (ellipsoid parameters: U, Σ, b)
  3. Understand extraction algorithm (collect samples -> down-project -> fit ellipsoid)
  4. Understand verification (inverse transform -> magnitude check)

- Design tradeoffs:
  - Extraction hardness vs. verification ease: O(d⁶) extraction vs. O(d³) verification
  - Security vs. practicality: Stronger guarantees require larger models with higher extraction costs
  - Compactness vs. robustness: Single-token verification possible but susceptible to replay attacks if outputs are reused

- Failure signatures:
  - Small models: ε smoothing causes outputs to fall inside ellipsoid, making fitting fail if algorithm is not ellipsoid-specific
  - Numerical precision: Cholesky decomposition may fail if fitted matrix is not positive definite
  - Cross-vocabulary mapping: When comparing models with different vocabularies, projection introduces approximation errors

- First 3 experiments:
  1. Reproduce ellipse extraction on a small open-weight model (e.g., pythia-70m) using semidefinite programming fitting method, measuring parameter recovery error vs. sample count.
  2. Implement the verification protocol: generate outputs from multiple models, project to shared vocabulary, and measure distance to each model's ellipse to confirm orders-of-magnitude separation.
  3. Test extraction cost scaling: measure fitting time for dimensions d=8 to d=256, extrapolate to production model sizes, and compare against API pricing to validate infeasibility claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does there exist a fast algorithm for generating new outputs on an unknown model ellipse based on samples that improves upon the current O(d⁶) time complexity?
- Basis: [explicit] The authors state, "We leave it as an open question as to whether there exists a fast algorithm for generating new outputs on an unknown model ellipse based on samples."
- Why unresolved: Current fitting algorithms (like ellipsoid-specific fitting) are computationally prohibitive, taking estimated "thousands of years" for large models.
- Evidence: An algorithm with lower time complexity (e.g., O(d³) or better) capable of generating valid logprob points on the ellipse.

### Open Question 2
- Question: Can other architectural constraints on language model outputs be identified that provide cryptographic-level security guarantees rather than just polynomial hardness?
- Basis: [explicit] The paper notes, "the hardness of forging ellipses is only polynomial, far from a cryptographic security guarantee. It is likely possible to identify other constraints... that give stronger guarantees."
- Why unresolved: The current forgery resistance relies on computational expense rather than theoretical impossibility, distinguishing it from standard cryptographic message authentication.
- Evidence: Discovery of a geometric or structural constraint that maps to a computationally hard problem with proven exponential complexity.

### Open Question 3
- Question: Are there signature methods for language models that are difficult to remove, unlike the ellipse signature which is erased by output modification?
- Basis: [explicit] The authors conclude, "Future work could explore other kinds of signatures for language models, which are hard to remove."
- Why unresolved: The ellipse signature is fragile; perturbing the model parameters or modifying outputs breaks the constraint, making the signature non-robust to post-processing.
- Evidence: A signature scheme that remains detectable even after the model outputs or parameters undergo specific classes of modification or noise.

### Open Question 4
- Question: Can language model inversion reliably serve as a defense against "stitching" attacks where an adversary pieces together authentic logprob outputs?
- Basis: [inferred] The authors suggest that inverters could detect tampering in stitched sequences by identifying low-likelihood prefixes, but they do not evaluate this.
- Why unresolved: It is unclear if the information leaked in logprobs is sufficient to distinguish a coherent generated sequence from a sequence of disjoint authentic logprob vectors.
- Evidence: An experiment demonstrating that model inversion successfully flags sequences constructed from stitched logprob outputs with high accuracy.

## Limitations

- The ellipse signature approach relies heavily on specific architectural properties of modern language models, particularly the use of normalization followed by linear projection.
- The extraction algorithm's complexity is presented as a security feature, but this assumes no more efficient ellipsoid-fitting methods exist or are discovered.
- The verification method assumes logprobs are unmodified post-generation, which may not hold in practical deployment scenarios where outputs are processed or transformed before verification.

## Confidence

**High Confidence:** The core geometric claim that language model outputs lie on ellipsoid surfaces due to normalization and linear transformation is well-established mathematically. The verification mechanism (inverse affine transform followed by magnitude check) is straightforward and should work as described.

**Medium Confidence:** The computational infeasibility claims for ellipse extraction require empirical validation. While the theoretical complexity is presented, real-world performance depends on implementation details, solver efficiency, and potential algorithmic optimizations that weren't tested.

**Low Confidence:** The security guarantees against forgery attacks need rigorous validation. The paper claims forgery resistance based on extraction hardness, but doesn't thoroughly explore potential attack vectors like approximate ellipse recovery, adversarial output generation, or exploiting epsilon smoothing variations.

## Next Checks

1. **Extraction Cost Validation:** Implement the ellipsoid fitting algorithm and measure actual runtime for dimensions ranging from d=64 to d=512 on progressively larger models. Compare measured scaling to theoretical O(d⁶) predictions and validate the infeasibility claims against real API rate limits and costs.

2. **Cross-Model Verification Robustness:** Create a comprehensive benchmark testing the verification protocol across models with different architectures (varying normalization types, projection dimensions, vocabulary sizes). Measure false positive/negative rates when comparing outputs across model families and under different epsilon smoothing regimes.

3. **Attack Surface Analysis:** Design and test potential forgery strategies including: (a) approximate ellipse recovery using fewer samples than theoretically required, (b) adversarial logprob generation to minimize distance to target ellipse, (c) exploiting epsilon smoothing variations to create outputs that fall within acceptable distance thresholds of multiple ellipses.