---
ver: rpa2
title: A Variational Approach for Mitigating Entity Bias in Relation Extraction
arxiv_id: '2506.11381'
source_url: https://arxiv.org/abs/2506.11381
tags:
- entity
- relation
- variance
- pers
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses entity bias in relation extraction, where models
  rely excessively on entities rather than contextual cues. It introduces a variational
  information bottleneck (VIB) framework that maps entities into probabilistic distributions,
  allowing the model to quantify and reduce reliance on entity-specific information
  while preserving task-relevant features.
---

# A Variational Approach for Mitigating Entity Bias in Relation Extraction

## Quick Facts
- **arXiv ID**: 2506.11381
- **Source URL**: https://arxiv.org/abs/2506.11381
- **Reference count**: 20
- **Primary result**: VIB framework achieves 70.4% ID and 66.5% OOD F1 on TACRED with LUKE-Large, outperforming baselines

## Executive Summary
This paper addresses entity bias in relation extraction where models rely excessively on entities rather than contextual cues. The authors introduce a Variational Information Bottleneck (VIB) framework that maps entities into probabilistic distributions, allowing the model to quantify and reduce reliance on entity-specific information while preserving task-relevant features. Experiments on TACRED, REFinD, and BioRED datasets show state-of-the-art performance, with LUKE-Large achieving 70.4% (ID) and 66.5% (OOD) on TACRED, outperforming existing methods like SCM. Variance analysis reveals that low variance indicates entity reliance while high variance reflects context usage, enhancing interpretability.

## Method Summary
The VIB framework applies variational inference to entity representations in relation extraction. Entity tokens pass through a single-layer perceptron (SLP) that outputs mean (μ) and variance (σ) parameters for a Gaussian distribution. The reparameterization trick enables differentiable sampling of stochastic entity embeddings. These are blended with original entity embeddings using factor β=0.5, then passed through the PLM encoder. The model is trained with a composite loss combining cross-entropy classification loss and KL divergence regularization that compresses entity-specific information. The adaptive weight α balances task performance against information compression.

## Key Results
- VIB achieves 70.4% F1 (ID) and 66.5% F1 (OOD) on TACRED with LUKE-Large, outperforming SCM (66.9% ID, 62.5% OOD)
- On REFinD, VIB reaches 78.7% F1 (ID) and 73.1% F1 (OOD), compared to Entity Masking at 77.1% ID
- BioRED results show 61.2% F1 (ID) and 56.9% F1 (OOD), with variance analysis indicating domain-specific entity reliance patterns
- Variance distribution shifts between ID and OOD samples provide interpretable diagnostics for entity-context reliance

## Why This Works (Mechanism)

### Mechanism 1: Stochastic Entity Encoding via Variational Information Bottleneck
The core mechanism maps entity embeddings to learned probabilistic distributions N(μ, σ) using a single-layer perceptron. This prevents overconfident entity-based predictions while quantifying entity reliance through variance. The reparameterization trick (z = μ + ε · σ where ε ~ N(0,1)) enables differentiable sampling. The learned σ² serves as a proxy for information retention—low variance indicates the model "knows" the entity well and may over-rely on it; high variance forces greater contextual dependence.

### Mechanism 2: Selective Information Compression via KL Divergence Regularization
The KL divergence term L_VIB = E[p(x,z,e)][KL(p(z|x,e) || r(z|e))] bounds the mutual information between input and latent representation, explicitly compressing entity-specific signals. The encoder distribution p(z|x,e) is constrained toward a standard normal prior r(z|e) = N(0,I). Minimizing this KL term forces the encoder to discard information not strictly necessary for classification. The adaptive weight α (computed as CE/VIB ratio) balances task performance against compression.

### Mechanism 3: Interpretable Variance as Entity-Context Reliance Indicator
The predicted variance σ² at inference provides built-in diagnostics: low variance correlates with entity-heavy reasoning while high variance indicates contextual reliance. The SLP learns to predict σ per entity token, and mean variance across entity tokens is computed during inference. Table 2 shows LUKE-Large concentrates 85.8% of ID samples in the 0.1–0.2 variance bin, while OOD shifts 13.2% into the lowest bin (0.0–0.1), reflecting disrupted entity utility.

## Foundational Learning

- **Concept: Variational Information Bottleneck (VIB)**
  - **Why needed here**: This is the core theoretical framework. You must understand how minimizing I(X; Z) while maximizing I(Z; Y) creates a compression-classification tradeoff.
  - **Quick check question**: Given a VIB loss L = L_CE + α · KL(p(z|x)||p(z)), what happens to representation specificity as α → ∞?

- **Concept: Reparameterization Trick**
  - **Why needed here**: Enables backpropagation through stochastic sampling. The paper uses z = μ + ε · σ with ε ~ N(0,1) to make the sampling operation differentiable.
  - **Quick check question**: Why can't we directly backprop through z ~ N(μ, σ) without reparameterization?

- **Concept: KL Divergence as Distributional Regularization**
  - **Why needed here**: The KL term forces learned distributions toward a standard normal prior. Understanding this explains why high variance = more stochasticity = less entity-specific information.
  - **Quick check question**: If KL(N(μ, σ) || N(0, 1)) = 0, what must μ and σ equal?

## Architecture Onboarding

- **Component map**: Input tokens → Entity Mask (M) generation → [Entity tokens] → SLP → (μ, σ) → Sample z ~ N(μ,σ) → Blending: x' = x·(1-M) + x·M·(1-β) + z·M·β → PLM Encoder (LUKE/RoBERTa) → [hs; ho] extraction → Classifier → Relation logits → Loss: L_CE + α·L_VIB

- **Critical path**: The SLP that predicts (μ, σ) from entity embeddings is the bottleneck. If this fails to learn meaningful variance, the entire debiasing mechanism collapses. Monitor σ distribution during training—it should show variance across entities, not uniform values.

- **Design tradeoffs**:
  - β (blending factor): Paper finds β=0.5 optimal. Higher β = more stochastic replacement but risks discarding useful entity signals.
  - α (VIB weight): Adaptive (CE/VIB ratio) prevents dominance by either term. Fixed α risks instability.
  - Backbone choice: LUKE-Large shows larger gains than RoBERTa-Large (Table 1), suggesting entity-aware pretraining amplifies VIB effectiveness.

- **Failure signatures**:
  - Variance collapse: All entities have σ² < 0.05 → model ignoring VIB signal; increase α.
  - OOD spike: Sudden F1 drop on OOD with high-variance samples → context alone insufficient; entity replacement too aggressive.
  - ID underperformance: VIB underperforms baseline → β too high, losing critical entity information.

- **First 3 experiments**:
  1. **Ablate β**: Run β ∈ {0.1, 0.3, 0.5, 0.7, 1.0} on validation set. Plot ID vs OOD F1 to find the sweet spot for your domain.
  2. **Variance diagnostics**: For a held-out set, compute mean variance per relation type. Correlate with: (a) relation frequency, (b) OOD performance gap. This validates whether variance captures entity reliance as claimed.
  3. **Backbone comparison**: If your use case involves specialized entities (biomedical, legal), test both LUKE and domain-specific PLMs. The paper's BioRED results (61.2% vs 56.9% baseline) suggest backbone matters for specialized domains.

## Open Questions the Paper Calls Out

- **Question 1**: Can the proposed Variational Information Bottleneck (VIB) framework be effectively adapted for generative Large Language Models (LLMs) or black-box settings?
  - **Basis in paper**: The Limitations section explicitly states the work focuses on PLMs and "does not easily extend to LLMs," identifying generative models like T5 as a target for future research.
  - **Why unresolved**: The current method requires white-box access to internal token embeddings and specific architectural modifications (SLPs) which may not be feasible or effective in decoder-only or black-box architectures.

- **Question 2**: How does language-specific entity bias manifest and respond to VIB mitigation in non-English contexts?
  - **Basis in paper**: The Limitations section notes the research is "conducted solely in the English language" and that "language-specific challenges and nuances could influence the performance."
  - **Why unresolved**: It is unclear if the relationship between variance (information compression) and context reliance holds universally across languages with different morphological structures or entity naming conventions.

- **Question 3**: Why does the VIB framework yield significantly greater performance gains with entity-aware backbones like LUKE compared to standard PLMs like RoBERTa?
  - **Basis in paper**: Section 5 notes that "LUKE's knowledge-based entity representations appear to amplify VIB's ability," but the precise interaction between pre-training strategies and the variational bottleneck remains observational.
  - **Why unresolved**: While the results show a larger performance delta for LUKE, the paper does not isolate if this is due to LUKE's entity-aware attention mechanism or the quality of its initial embeddings.

## Limitations

- **Implementation gaps**: Missing critical hyperparameters including exact formula for adaptive weight α and training schedule (batch size, epochs, warmup)
- **Domain generalizability**: BioRED results show smaller improvements (61.2% vs 56.9% baseline) compared to TACRED gains, suggesting VIB effectiveness varies across domains
- **Empirical validation**: Variance analysis correlation with entity reliance remains qualitative without rigorous statistical validation through ablation studies

## Confidence

**High Confidence (8/10)**:
- VIB improves both ID and OOD F1 scores compared to baselines (Entity Masking, SCM)
- The mechanism of stochastic entity encoding through VIB is technically sound
- Variance serves as a meaningful diagnostic tool for entity reliance

**Medium Confidence (6/10)**:
- The claim that VIB "quantifies entity reliance" - supported by qualitative variance analysis but lacking rigorous statistical validation
- Adaptive α weight selection is optimal - the adaptive approach is mentioned but exact implementation details are missing
- Cross-domain generalization - BioRED results show smaller improvements, suggesting domain sensitivity

**Low Confidence (4/10)**:
- The assertion that variance directly measures "context usage" - correlation exists but causation is not established
- Claims about "state-of-the-art" performance - limited comparison to recent contrastive learning approaches
- Long-term stability of variance-based interpretability - no temporal analysis of variance behavior during extended training

## Next Checks

1. **Variance-Correlation Analysis**: For each relation type in TACRED, compute the Pearson correlation between: (a) mean entity variance during inference, (b) OOD performance drop, and (c) relation frequency. This will quantify whether variance truly captures entity reliance as claimed.

2. **Ablation of Adaptive Weight Mechanism**: Implement both fixed and adaptive α versions. Compare: (a) final F1 scores, (b) variance collapse rates during training, and (c) sensitivity to initial α values. This isolates whether the adaptive mechanism is essential to VIB's success.

3. **Domain Transfer Experiment**: Train VIB on TACRED, then fine-tune on BioRED with and without VIB. Measure: (a) adaptation speed (epochs to peak performance), (b) final F1 gap between ID and OOD on BioRED, and (c) variance distribution shifts. This tests whether VIB learned entity-debiasing generalizes across domains or overfits to specific entity types.