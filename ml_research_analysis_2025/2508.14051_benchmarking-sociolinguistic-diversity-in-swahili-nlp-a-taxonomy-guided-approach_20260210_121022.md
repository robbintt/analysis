---
ver: rpa2
title: 'Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach'
arxiv_id: '2508.14051'
source_url: https://arxiv.org/abs/2508.14051
tags:
- language
- swahili
- across
- fairness
- tribal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first taxonomy-guided evaluation of Swahili
  NLP models, focusing on sociolinguistic diversity in healthcare-related psychometric
  tasks. The authors collected 2,170 free-text responses from Kenyan speakers, annotated
  with demographic metadata and sociolinguistic features including code-mixing, Sheng,
  tribal lexicons, and loanwords.
---

# Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach

## Quick Facts
- arXiv ID: 2508.14051
- Source URL: https://arxiv.org/abs/2508.14051
- Authors: Kezia Oketch; John P. Lalor; Ahmed Abbasi
- Reference count: 16
- First taxonomy-guided evaluation of Swahili NLP models for sociolinguistic diversity in healthcare-related psychometric tasks

## Executive Summary
This paper presents the first systematic evaluation of Swahili NLP models through a sociolinguistic lens, specifically focusing on healthcare-related psychometric tasks. The authors collected 2,170 free-text responses from Kenyan speakers, annotating them with demographic metadata and sociolinguistic features including code-mixing, Sheng, tribal lexicons, and loanwords. Nine models were benchmarked across four psychometric tasks, revealing that no single model consistently outperformed others and all showed significantly lower performance compared to English benchmarks. The study developed a comprehensive sociolinguistic taxonomy and found that features like Sheng and tribal terms systematically contribute to prediction errors, with intersectional fairness analysis showing that model disparities compound across demographic dimensions.

## Method Summary
The authors collected 2,170 free-text responses from Kenyan speakers for healthcare-related psychometric tasks, annotating responses with demographic metadata and sociolinguistic features including code-mixing, Sheng, tribal lexicons, and loanwords. They developed a comprehensive sociolinguistic taxonomy and benchmarked nine models (linear/logistic regression, mBERT, XLM-RoBERTa, AfriBERTa, SwahBERT, and four LLMs) across four psychometric tasks. The evaluation included intersectional fairness analysis examining how model performance varied across demographic dimensions such as tribe, gender, and education. Performance was compared against English benchmarks to establish relative effectiveness.

## Key Results
- No single model consistently outperformed others across all sociolinguistic features and tasks
- All models showed significantly lower performance compared to English benchmarks
- Sociolinguistic features like Sheng and tribal lexicons systematically contributed to prediction errors
- Model disparities compounded across demographic dimensions, revealing intersectional fairness issues

## Why This Works (Mechanism)
The study's approach works by providing a structured framework for evaluating how sociolinguistic variation affects NLP model performance. By systematically annotating data with sociolinguistic features and conducting intersectional fairness analysis, the authors reveal that performance gaps are not uniform across demographic groups but compound across multiple dimensions. The taxonomy-guided approach allows for granular analysis of which specific linguistic features contribute to errors, moving beyond aggregate performance metrics to understand the nuanced ways sociolinguistic diversity impacts model effectiveness.

## Foundational Learning
- **Sociolinguistic taxonomy development** - Why needed: Provides systematic framework for analyzing linguistic variation; Quick check: Verify taxonomy covers major sociolinguistic phenomena in target population
- **Intersectional fairness analysis** - Why needed: Reveals compound effects of multiple demographic factors on model performance; Quick check: Ensure statistical power for analyzing rare demographic intersections
- **Code-mixing detection methods** - Why needed: Critical for identifying multilingual language use patterns; Quick check: Validate detection accuracy against human annotations
- **Psychometric task adaptation** - Why needed: Ensures NLP models evaluate meaningful psychological constructs; Quick check: Confirm construct validity through expert review
- **Cross-linguistic benchmarking** - Why needed: Establishes performance baselines relative to resource-rich languages; Quick check: Use consistent evaluation metrics across languages
- **Demographic metadata collection** - Why needed: Enables analysis of fairness across population segments; Quick check: Implement privacy-preserving data collection protocols

## Architecture Onboarding
**Component Map:** Data Collection -> Taxonomy Development -> Model Benchmarking -> Fairness Analysis -> Performance Evaluation
**Critical Path:** Taxonomy Development -> Model Benchmarking -> Fairness Analysis (each stage builds on previous)
**Design Tradeoffs:** Resource efficiency (collecting smaller dataset) vs. statistical power (larger dataset for rare intersections)
**Failure Signatures:** Performance gaps attributed to linguistic features may actually reflect dataset imbalances; Model architecture limitations vs. sociolinguistic complexity
**First Experiments:** 1) Replicate benchmarking with independent dataset from different Kenyan regions; 2) Conduct ablation studies removing specific sociolinguistic features; 3) Test additional model architectures designed for code-mixed languages

## Open Questions the Paper Calls Out
- Generalizability of the sociolinguistic taxonomy beyond healthcare psychometric context
- Whether performance gaps stem from inherent linguistic features or dataset characteristics
- Impact of limited sample size (2,170 responses) on detecting subtle sociolinguistic effects

## Limitations
- Generalizability of the sociolinguistic taxonomy may be limited to the specific healthcare psychometric context studied
- Collection of only 2,170 responses may limit statistical power for detecting subtle sociolinguistic effects, particularly for rare demographic intersections
- Some model performance differences could be influenced by hyperparameter choices or training data biases not fully controlled in the experiments

## Confidence
- **High**: The existence of performance disparities across sociolinguistic features and demographic groups
- **Medium**: The systematic contribution of specific features like Sheng and tribal lexicons to prediction errors
- **Low**: The extent to which these findings generalize to other NLP tasks beyond healthcare psychometrics

## Next Checks
1. Replicate the benchmarking with an independent dataset collected from different regions of Kenya to test generalizability of the taxonomy and performance patterns
2. Conduct ablation studies removing specific sociolinguistic features to quantify their individual contributions to model errors
3. Test additional model architectures and fine-tuning strategies specifically designed for code-mixed and low-resource language scenarios to determine if performance gaps can be mitigated