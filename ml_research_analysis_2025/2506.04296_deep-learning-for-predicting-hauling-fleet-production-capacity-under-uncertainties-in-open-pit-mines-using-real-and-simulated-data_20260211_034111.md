---
ver: rpa2
title: Deep learning for predicting hauling fleet production capacity under uncertainties
  in open pit mines using real and simulated data
arxiv_id: '2506.04296'
source_url: https://arxiv.org/abs/2506.04296
tags:
- data
- operational
- mining
- these
- shift
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of short-term forecasting of
  hauling fleet capacity in open-pit mining, where uncertainties like weather fluctuations,
  mechanical breakdowns, and crew availability significantly impact operations. The
  authors propose a deep learning framework combining real-world operational data
  (high-resolution rainfall, fleet telemetry) with synthetically generated breakdown
  scenarios.
---

# Deep learning for predicting hauling fleet production capacity under uncertainties in open pit mines using real and simulated data

## Quick Facts
- arXiv ID: 2506.04296
- Source URL: https://arxiv.org/abs/2506.04296
- Authors: N Guerin; M Nakhla; A Dehoux; J L Loyer
- Reference count: 0
- One-line primary result: XGBoost (MedAE: 14.3%) and LSTM (MedAE: 15.1%) models improve short-term hauling fleet capacity forecasts by blending real telemetry with synthetic breakdown scenarios.

## Executive Summary
This study addresses the challenge of short-term forecasting of hauling fleet capacity in open-pit mining, where uncertainties like weather fluctuations, mechanical breakdowns, and crew availability significantly impact operations. The authors propose a deep learning framework combining real-world operational data (high-resolution rainfall, fleet telemetry) with synthetically generated breakdown scenarios. Two models were evaluated: XGBoost (MedAE: 14.3%) and LSTM (MedAE: 15.1%). SHAP analysis identified cumulative rainfall, historical payload trends, and breakdown frequencies as key predictors. Integrating simulated breakdowns and shift-planning features notably reduced prediction volatility. The hybrid approach provides a robust decision-support tool for proactive fleet management under dynamic uncertainties, with future work targeting further integration of maintenance indicators and human resource data.

## Method Summary
The framework blends real operational telemetry (payload, cycle times, working trucks/shovels) with synthetically generated mechanical breakdown scenarios via Monte Carlo sampling from historical residuals. Inputs include 3 years of FMS data aggregated to 10.5-hour shift windows and ERA5-Land precipitation data. Features include temporal lags (Payload_lag1, Payload_rolling_sum_4), simulated truck availability, and shift metadata. Two models were trained: XGBoost (n_estimators=1000, learning_rate=0.01, max_depth=3) and LSTM (64 units, look-back=10, dropout=0.2). Both used MinMaxScaler normalization and 80/20 chronological splits. SHAP analysis quantified feature contributions.

## Key Results
- XGBoost achieved Median Absolute Error (MedAE) of 14.3% (improved to 8.4% with scheduled trucks), RÂ² of 0.78
- LSTM achieved MedAE of 15.1% (improved to 13.5%), with smoother predictions but lagging effect on abrupt changes
- SHAP identified cumulative rainfall, historical payload trends, and breakdown frequencies as dominant predictors
- Simulated breakdown scenarios and shift-planning features reduced prediction volatility
- 33 (XGBoost) and 31 (LSTM) instances of >50% error, often coinciding with unrepresented data (missing HR/Maintenance info)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Blending real operational telemetry with synthetically generated breakdown scenarios reduces prediction volatility for short-term fleet capacity.
- **Mechanism:** The framework uses Monte Carlo-inspired simulations (MCTS) to generate stochastic noise based on historical residual distributions, creating "what-if" scenarios for equipment availability. This augments the training set to cover rare but high-impact failure events that sparse real-world logs might miss.
- **Core assumption:** The stochastic properties of historical breakdown residuals accurately reflect the probability distribution of future mechanical failures.
- **Evidence anchors:** [abstract] "blends real-world operational records... with synthetically generated mechanical-breakdown scenarios to enable the model to capture fluctuating high-impact failure events." [section] "We then inject stochastic noise sampled from the distribution of model residuals... yields a range of plausible future scenarios."
- **Break condition:** If mechanical failures are not stochastic but result from systemic, unmodeled wear-and-tear patterns (e.g., non-stationary aging), the synthetic noise injection will fail to capture the true failure dynamics.

### Mechanism 2
- **Claim:** Temporal lag features (rolling sums and previous shift values) allow the model to capture "operational inertia," where past performance heavily constrains immediate future output.
- **Mechanism:** By explicitly engineering features like `Payload_rolling_sum_4` (sum of payloads over last four shifts) and `Working_trucks_lag1`, the models can ground their predictions in the physical reality that fleet composition and efficiency do not change instantaneously but rather evolve over a sliding window.
- **Core assumption:** The selected look-back windows (e.g., 4 shifts, 6 shifts for rain) align with the actual memory of the physical system (road recovery time, crew fatigue cycles).
- **Evidence anchors:** [abstract] "historical payload trends... as dominant predictors." [section] "The three variables related to historical payload clearly dominate in terms of impact... illustrating strong operational inertia across successive shifts."
- **Break condition:** If sudden exogenous shocks (e.g., a blast event or sudden pit closure) reset operational conditions instantly, the lag features would act as noise rather than signal, inducing lagged prediction errors.

### Mechanism 3
- **Claim:** High-resolution rainfall data acts as a leading indicator for productivity loss by modeling deteriorating road conditions and cycle time delays.
- **Mechanism:** Cumulative precipitation metrics (`Precipitation_sum6`) are correlated with reduced haul-road traction and increased rolling resistance. The model learns a non-linear mapping where high rainfall correlates with increased cycle times and decreased payload capacity.
- **Core assumption:** Rainfall is the primary environmental driver of productivity loss, overriding other excluded variables like temperature or wind (which were explicitly excluded by authors).
- **Evidence anchors:** [abstract] "cumulative rainfall... identified [as] key predictors." [section] "Heavy rainfall episodes directly reduce operational efficiency by deteriorating haul road conditions... SHAP analysis revealed that rainfall was among the most significant predictors."
- **Break condition:** If the mine implements effective road drainage or dust suppression that decouples rainfall from road quality, the learned negative correlation will overestimate productivity loss.

## Foundational Learning

- **Concept:** **Gradient Boosting (XGBoost)**
  - **Why needed here:** Used to handle mixed data types (categorical crew codes + numerical sensor data) and provide interpretable feature importance via SHAP values, which is critical for operational trust.
  - **Quick check question:** Can you explain why a tree-based model might react faster to sudden payload drops than an LSTM, and what risk (overfitting) this entails?

- **Concept:** **Long Short-Term Memory (LSTM)**
  - **Why needed here:** Required to process the sequential, time-series nature of the data where the order of shifts matters. It uses gates to retain long-term dependencies (e.g., cumulative rain effects) that simple regressions might miss.
  - **Quick check question:** What is the "vanishing gradient problem" that LSTMs solve, and why is it relevant when analyzing 3 years of historical fleet data?

- **Concept:** **Shapley Additive Explanations (SHAP)**
  - **Why needed here:** Essential for moving beyond "black box" predictions. It quantifies the contribution of each feature (e.g., "How much did 50mm of rain reduce the predicted payload?"), enabling operational adjustments.
  - **Quick check question:** If the SHAP summary plot shows "Simulated Variables" with low impact, what does that imply about the quality or necessity of the simulation module?

## Architecture Onboarding

- **Component map:** Data Ingestion (FMS + ERA5-Land) -> Preprocessing (interpolation, aggregation to 10.5h shifts) -> Simulation Module (Monte Carlo noise from residuals) -> Feature Store (15+ features: lags, rolling sums, metadata) -> Model Heads (XGBoost + LSTM)

- **Critical path:** The integrity of the **Simulation Module** is the most critical dependency. If the simulated truck availability does not statistically mirror reality, the "Predicted" features poison both the XGBoost and LSTM inputs.

- **Design tradeoffs:**
  - XGBoost vs. LSTM: The paper reveals a tradeoff between **reactivity** and **stability**. XGBoost captures sudden peaks/drops better (lower MedAE 14.3%) but risks overfitting noise. LSTM is smoother (MedAE 15.1%) but suffers from "lagging effect," failing to react quickly to abrupt changes.
  - Real vs. Simulated: Relying solely on real data misses rare breakdowns; relying too much on simulation risks injecting synthetic noise that drowns out signal.

- **Failure signatures:**
  - High Error Spikes (>50%): The paper notes 33 (XGBoost) and 31 (LSTM) instances of >50% error. These often coincided with unrepresented data (missing HR/Maintenance info) rather than rain.
  - LSTM Lag: A visible delay in predictions when trends reverse sharply (e.g., end of December 2023 drop).

- **First 3 experiments:**
  1. **Baseline vs. Hybrid:** Train XGBoost on *only* empirical data vs. empirical + simulated data to quantify the specific variance reduction provided by the simulation module.
  2. **Look-back Sensitivity:** Vary the LSTM look-back window (e.g., 5 vs. 10 vs. 20 shifts) to find the optimal memory length for capturing "operational inertia" without introducing excessive lag.
  3. **Ablation of "Next Shift" Features:** Re-run the model removing `Shift_next` and `Crew_next` to verify the authors' claim that these planning features stabilize predictions and reduce large errors (>50%).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the integration of maintenance-scheduling indicators (MTBF, MTTR) significantly reduce the frequency of high-error predictions (>50%) currently attributed to unrepresented variables?
- **Basis in paper:** [explicit] The authors explicitly identify the integration of Mean Time Between Failures (MTBF) and Mean Time to Repair (MTTR) as future work to address prediction errors caused by mechanical uncertainties.
- **Why unresolved:** The current models struggle to account for sudden breakdowns, resulting in 33 instances (XGBoost) where prediction errors exceeded 50%, often without corresponding weather events.
- **What evidence would resolve it:** A reduction in the count of outlier errors and a lower Median Absolute Error (MedAE) upon retraining the models with these maintenance features.

### Open Question 2
- **Question:** To what extent does the inclusion of human resource data (operator absenteeism, crew efficiency) improve model accuracy, given that current models rely on simulated crew availability?
- **Basis in paper:** [explicit] The text notes that "simulated variables show a relatively weak impact" and explicitly lists "detailed human resource data" as a necessary future integration to enhance forecast robustness.
- **Why unresolved:** The study explicitly excluded human resources data to focus on trucks, yet noted that "crew" variables had a moderate, structured impact on predictions, suggesting the current simulations are insufficient.
- **What evidence would resolve it:** Comparative analysis showing that actual crew efficiency metrics correlate more strongly with payload variance than the current simulated variables.

### Open Question 3
- **Question:** Can the inclusion of blast event scheduling features mitigate the "lagging effect" observed in the LSTM model during periods of periodic operational disruption?
- **Basis in paper:** [explicit] The authors state future work must include "blast event scheduling" to capture periodic disruptions that slow operations.
- **Why unresolved:** The LSTM model currently exhibits a lagging effect and struggles with rapid variations, while XGBoost reacts faster; it is unclear if blast data would smooth these specific temporal discrepancies.
- **What evidence would resolve it:** Demonstrated improvement in the LSTM's ability to anticipate sudden drops in productivity aligned with scheduled blast times without the usual temporal delay.

## Limitations
- The stochastic breakdown modeling assumes mechanical failures follow the same distribution as historical residuals, which may not hold for non-stationary wear patterns
- LSTM predictions exhibit a "lagging effect" during abrupt trend reversals, failing to react quickly to sudden changes
- The study excludes temperature and wind data, assuming rainfall is the primary environmental driver despite potential contributions from other factors

## Confidence
- **High Confidence:** The utility of SHAP analysis for feature interpretability and the general effectiveness of temporal lag features in capturing operational inertia
- **Medium Confidence:** The specific mechanism of Monte Carlo-generated breakdown scenarios improving prediction stability; this requires validation on a different mine dataset
- **Low Confidence:** The claim that rainfall is the primary environmental driver of productivity loss, as other excluded factors (temperature, wind) may play significant roles

## Next Checks
1. **Ablation Study on Simulation Module:** Train the XGBoost model on *only* empirical data versus empirical + simulated data to quantify the exact variance reduction provided by the synthetic breakdown scenarios
2. **Cross-Mine Validation:** Apply the hybrid framework to a second open-pit mine with different equipment age and maintenance regimes to test the generalizability of the stochastic breakdown modeling
3. **Robustness to Weather Independence:** Simulate a scenario where the mine implements effective road drainage, and re-evaluate the model's performance to check if it over-predicts productivity loss due to rainfall