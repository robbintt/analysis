---
ver: rpa2
title: 'FinSight: Towards Real-World Financial Deep Research'
arxiv_id: '2510.16844'
source_url: https://arxiv.org/abs/2510.16844
tags:
- report
- data
- research
- financial
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FinSight, a multi-agent framework for generating
  professional financial research reports. The system uses a Code Agent with Variable
  Memory (CAVM) architecture that unifies data, tools, and agents into a programmable
  space for flexible analysis and report generation.
---

# FinSight: Towards Real-World Financial Deep Research

## Quick Facts
- arXiv ID: 2510.16844
- Source URL: https://arxiv.org/abs/2510.16844
- Authors: Jiajie Jin; Yuyao Zhang; Yimeng Xu; Hongjin Qian; Yutao Zhu; Zhicheng Dou
- Reference count: 40
- Primary result: Outperforms Gemini and OpenAI deep research baselines on financial report benchmark (8.09 vs 6.82-6.11 average score)

## Executive Summary
This paper introduces FinSight, a multi-agent framework for generating professional financial research reports that significantly outperforms existing deep research systems. The key innovation is the Code Agent with Variable Memory (CAVM) architecture, which unifies data, tools, and agents into a programmable space for flexible analysis and report generation. FinSight achieves state-of-the-art performance on a financial report benchmark through two key mechanisms: an Iterative Vision-Enhanced Mechanism that refines visualizations through VLM feedback, and a Two-Stage Writing Framework that expands concise analysis chains into comprehensive reports.

## Method Summary
FinSight uses a CAVM architecture that represents all entities (data, tools, agents) as callable variables in a unified programmable space. The system employs Deep Search and Multi-Source Collection agents to gather financial data, followed by a Data Analysis Agent that generates code-driven analysis and iteratively refines charts using VLM critique. A Two-Stage Writing Framework first creates concise Chain-of-Analysis segments, then retrieves and synthesizes them into structured reports. The system uses DeepSeek-V3 for analysis and DeepSeek-R1 for writing, with Qwen2.5-VL-72B for chart refinement and Qwen3-Embedding-0.6B for retrieval.

## Key Results
- Achieves average score of 8.09 on financial report benchmark vs 6.82-6.11 for baselines
- Outperforms Gemini Deep Research (6.85 vs 7.10) in Core Conclusion Consistency despite prioritizing comprehensive data acquisition
- Shows ablation improvements: removing iterative VLM refinement drops Presentation Quality from 8.0 to 7.5
- Maintains strong performance across both company-level (8.15) and industry-level (8.03) report generation

## Why This Works (Mechanism)

### Mechanism 1: Code Agent with Variable Memory (CAVM) Unifies Multi-Agent State
- Claim: Consolidating data, tools, and agents into a single programmable variable space enables flexible, code-driven orchestration across the research pipeline.
- Core assumption: LLMs can reliably generate correct executable code for financial operations (API calls, data transformations, chart plotting).
- Evidence: CAVM architecture enables dynamic composition without rigid handoffs, outperforming baseline agentic frameworks.

### Mechanism 2: Iterative Vision-Enhanced Mechanism Refines Charts via VLM Critique
- Claim: Multi-iteration VLM feedback loops improve chart quality from basic plots to professional-grade visualizations suitable for financial reports.
- Core assumption: VLM critique accurately identifies aesthetic and informational deficiencies, and code agents can translate critique into correct plotting code fixes.
- Evidence: Ablation shows removing iterative feedback drops Presentation Quality from 8.0 to 7.5 and Analytical Quality from 7.9 to 7.2.

### Mechanism 3: Two-Stage Writing Decomposes Analysis from Synthesis
- Claim: Separating analysis (Chain-of-Analysis generation) from writing (structured report synthesis) improves both factual accuracy and analytical depth over single-pass generation.
- Core assumption: The CoA abstraction captures sufficient context for later synthesis, and retrieval accuracy is high enough to surface relevant segments during writing.
- Evidence: Ablation shows removing two-stage writing drops Analytical Quality from 7.9 to 5.9 and Factual Accuracy from 7.0 to 6.4.

## Foundational Learning

- Concept: **Code-as-Action Agent Paradigm**
  - Why needed: FinSight's CAVM relies on LLMs generating executable code to manipulate state.
  - Quick check: Can you explain how a code-action agent differs from a tool-calling agent in terms of flexibility and failure modes?

- Concept: **Vision-Language Model (VLM) Evaluation Capabilities**
  - Why needed: The iterative mechanism depends on VLM providing actionable critique.
  - Quick check: What types of visual errors would a VLM likely catch vs. miss in a financial chart?

- Concept: **Retrieval-Augmented Generation (RAG) for Structured Content**
  - Why needed: Stage 2 retrieves CoA segments by section relevance.
  - Quick check: How would you handle a case where the correct CoA segment exists but retrieval similarity score is below threshold?

## Architecture Onboarding

- Component map: User Query → Data Collection (Deep Search + Multi-Source) → Data Analysis (Code + Iterative VLM) → CoA Generation → Outline → Section-wise Retrieval → Two-Stage Writing → Post-Processing → Final Report
- Critical path: User query → Data Collection (populate V_data) → Data Analysis → Generate CoA segments + charts (with VLM refinement) → Outline generation → Section-by-section retrieval + writing → Post-processing → Final formatted report
- Design tradeoffs:
  - Flexibility vs. Complexity: CAVM enables arbitrary code execution but increases debugging surface
  - Quality vs. Latency/Cost: Iterative VLM refinement improves charts but multiplies compute
  - Decomposition vs. Coherence: Two-stage writing improves accuracy but risks narrative fragmentation
- Failure signatures:
  - Code execution errors cascade, leaving V_data incomplete—check interpreter logs
  - VLM critique loops indefinitely or provides conflicting feedback—monitor convergence
  - Retrieval surfaces wrong CoA segments → sections reference irrelevant charts
  - Final report has hallucinated figure references—check identifier grounding
- First 3 experiments:
  1. Ablate VLM iterations: Run with 1, 2, 3 iterations on held-out set of 5 company reports
  2. Stress-test code execution: Inject malformed API responses into V_data
  3. Retrieval accuracy audit: For sample report, manually label which CoA segments should be retrieved per section

## Open Questions the Paper Calls Out

- Can FinSight achieve both high Core Conclusion Consistency and deep analytical insights simultaneously, or is the observed trade-off fundamental to the multi-source data acquisition approach?
- How does FinSight generalize to non-Chinese financial markets and multilingual report generation?
- Can human financial experts distinguish FinSight-generated reports from human-authored ones, and what qualitative gaps remain?
- Does FinSight maintain performance when scaled to larger benchmark datasets beyond 20 samples?

## Limitations

- Unknown code execution error rates in CAVM's unified variable space could lead to cascading failures
- VLM critic accuracy for chart refinement is not quantitatively validated
- Benchmark relies on proprietary data sources and may not generalize to other markets
- No human expert evaluation despite claims of "approaching human-expert quality"

## Confidence

- **High**: CAVM architecture design and Two-Stage Writing framework are well-specified and show clear ablation improvements
- **Medium**: Iterative VLM refinement mechanism is logically sound but depends on unverified VLM critique accuracy
- **Low**: Generalization claims are based on a small, curated benchmark without external validation

## Next Checks

1. Measure code execution error rates in CAVM across 50+ complex workflows to quantify reliability
2. Audit VLM critic performance by comparing its feedback to human expert ratings on chart quality
3. Replicate results on an open-source financial dataset (e.g., Yahoo Finance + SEC filings) to test generalizability