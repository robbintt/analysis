---
ver: rpa2
title: Diagnosis of Pulmonary Hypertension by Integrating Multimodal Data with a Hybrid
  Graph Convolutional and Transformer Network
arxiv_id: '2504.01025'
source_url: https://arxiv.org/abs/2504.01025
tags:
- pulmonary
- data
- hypertension
- graph
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study developed a deep learning model that combines graph\
  \ convolutional networks (GCN), convolutional neural networks (CNN), and transformers\
  \ to classify pulmonary hypertension (PH) into non-PH, pre-capillary PH, and post-capillary\
  \ PH using multimodal cardiac magnetic resonance (CMR) imaging and clinical data.\
  \ The model was trained on 186 patients and tested on 18 patients (6 per class)\
  \ across 35 random splits, achieving an overall accuracy of 73%\xB16% and AUC of\
  \ 81%\xB16%."
---

# Diagnosis of Pulmonary Hypertension by Integrating Multimodal Data with a Hybrid Graph Convolutional and Transformer Network

## Quick Facts
- arXiv ID: 2504.01025
- Source URL: https://arxiv.org/abs/2504.01025
- Reference count: 40
- Primary result: Deep learning model combining GCN, CNN, and Transformers achieves 73%±6% accuracy and 81%±6% AUC for PH classification

## Executive Summary
This study presents a hybrid deep learning model that integrates graph convolutional networks, convolutional neural networks, and transformers to classify pulmonary hypertension into non-PH, pre-capillary PH, and post-capillary PH using multimodal cardiac MRI and clinical data. The model processes both spatial anatomical features and temporal cardiac dynamics through a DC-Transformer architecture, while using a GCN to model complex interactions between clinical and imaging features. Evaluated on 186 patients with 18 held-out samples, the model demonstrates strong discriminative ability with AUC values of 86%±6% for pre-capillary PH and 83%±10% for post-capillary PH.

## Method Summary
The method employs a hybrid architecture combining DC-Transformers for spatiotemporal feature extraction from cardiac MRI sequences, GCN for multimodal feature fusion, and MLP for classification. Clinical features and imaging embeddings are mapped to 11 graph nodes, with the GCN learning higher-dimensional relationships between modalities. The DC-Transformer processes both short-axis and 4-chamber views to capture spatial and temporal cardiac dynamics, while a U-Net+LSTM calculates Relative Area Change of the pulmonary artery as a vascular elasticity biomarker.

## Key Results
- Overall accuracy of 73%±6% and AUC of 81%±6% across 35 random splits
- Strong discriminative ability with AUC values of 86%±6% for pre-capillary PH and 83%±10% for post-capillary PH
- GCN fusion improved accuracy from 70% to 73% compared to MLP-only approach
- Optimal performance achieved with 11 graph nodes, matching the number of clinical features

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating CNN with Transformers allows extraction of both spatial anatomical features and temporal cardiac dynamics
- **Mechanism:** CNN captures spatial features from individual frames, then Transformer's self-attention models long-term dependencies across the cardiac cycle
- **Core assumption:** Diagnostic criteria for PH subtypes are partially encoded in dynamic heart motion rather than just static anatomy
- **Evidence anchors:**
  - [abstract]: Model combines GCN, CNN, and Transformers to process multimodal data including short-axis sequences
  - [section]: Page 9 describes DC-Transformer extracting temporal features via self-attention
  - [corpus]: Weak support; neighbor papers focus on static images, though "Predicting Pulmonary Hypertension in Newborns" uses video data
- **Break condition:** If performance remains unchanged when input frames are shuffled temporally, Transformer is failing to capture temporal dependencies

### Mechanism 2
- **Claim:** Modeling multimodal features as a graph enables learning of higher-dimensional interactions between clinical history and imaging biomarkers
- **Mechanism:** Clinical features and imaging features mapped to 11 distinct GCN nodes, propagating information to learn complex correlations
- **Core assumption:** Relationship between clinical parameters and imaging features is better represented as graph topology than linear vector space
- **Evidence anchors:**
  - [abstract]: Mentions integrating multimodal data with hybrid GCN
  - [section]: Page 11 states GCN can express higher-dimensional relationships; Table 4 shows 11 nodes yielded optimal AUC (0.814)
  - [corpus]: General support in "Multimodal Latent Fusion of ECG Leads," but specific node-splitting technique is unique
- **Break condition:** If adjacency matrix is replaced with identity matrix and performance is maintained, graph structure is not providing utility

### Mechanism 3
- **Claim:** Relative Area Change (RAC) of pulmonary artery serves as specific proxy for vascular elasticity, providing distinct hemodynamic signal
- **Mechanism:** U-Net+LSTM segments pulmonary artery cross-section across cardiac cycle; RAC quantifies arterial stiffness, a known PH marker
- **Core assumption:** Arterial stiffness from non-invasive MRI flow sequences correlates strongly with invasive RHC pressure measurements
- **Evidence anchors:**
  - [abstract]: Mentions integrating clinical data and CMR
  - [section]: Page 7 details RAC calculation and notes PH patients exhibit reduced pulmonary artery elasticity
  - [corpus]: Not explicitly covered in neighbor abstracts, which focus more on detection than specific biomarkers like RAC
- **Break condition:** If RAC is replaced by simple mean area and accuracy drops specifically for differentiating pre-capillary vs. post-capillary PH, elasticity marker is active

## Foundational Learning

- **Concept:** Graph Construction for Non-Graph Data
  - **Why needed here:** Converts standard clinical tabular data and image embeddings into graph structure; must understand how to define nodes and edges
  - **Quick check question:** If you have 10 clinical features and 256-dimension image embedding, how would you construct the node feature matrix $H^{(0)}$?

- **Concept:** Spatiotemporal Embeddings
  - **Why needed here:** Input is 4D CMR data (3D space + time); must understand how to collapse spatial dimensions via CNN before applying temporal attention via Transformers
  - **Quick check question:** Does the Transformer in this architecture attend to pixels or to frame-level feature vectors?

- **Concept:** Imbalanced Multiclass Classification
  - **Why needed here:** Dataset is heavily imbalanced (112 pre-capillary, 32 post-capillary, 60 non-PH); must understand metrics like macro-AUC vs. accuracy
  - **Quick check question:** Why is accuracy a potentially misleading metric given the class distribution in the training set?

## Architecture Onboarding

- **Component map:** Input (CMR sequences + Clinical data + Flow sequences) -> Preprocessing (UNet++ ROI segmentation, U-Net+LSTM RAC calculation) -> Feature Extraction (DC-Transformer SAX/4CH → Spatiotemporal features) -> Fusion (GCN 11 nodes combining clinical + imaging features) -> Classifier (MLP Softmax output)

- **Critical path:** Alignment of image features to graph node count (11). Mismatching node counts causes performance degradation. Projection layer reducing image features to match clinical node dimension is bottleneck.

- **Design tradeoffs:**
  - **GCN vs. MLP Fusion:** Ablation study shows GCN improves ACC from 0.70 to 0.73. Is added complexity worth 3% gain?
  - **Node Count:** Selecting 11 nodes based on clinical feature count is heuristic. Paper tests 5 to 44 nodes; 11 is empirically best but may not generalize.

- **Failure signatures:**
  - **High Variance:** Standard deviation of AUC is ±0.06. Test set is very small (18 samples). Do not expect stable evaluation on single splits; use 35-split bootstrapping.
  - **Modality Dropout:** If clinical data is missing, GCN structure may fail if adjacency matrix relies on fixed node degrees.

- **First 3 experiments:**
  1. **Baseline Verification:** Run ablation study comparing "Full Model" vs. "No_GCN" (MLP only) to verify reported 3% accuracy lift.
  2. **Node Sensitivity:** Replicate "Influence of the Number of Graph Nodes" experiment (Table 4) to visualize performance cliff when node counts are mismatched.
  3. **Input Degradation:** Zero out RAC value in clinical input to quantify specific contribution of pulmonary artery elasticity metric to "Pre-capillary" vs. "Post-capillary" distinction.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the model maintain diagnostic accuracy when applied to external datasets from different geographical regions or scanner manufacturers?
- **Basis in paper:** [explicit] Section 5.5 states future studies should incorporate larger and more diverse datasets to overcome limitations regarding generalizability.
- **Why unresolved:** Study utilized retrospective dataset from single center using specific 3.0T Siemens scanners; unclear if model learns generalizable physiological features or site-specific artifacts.
- **What evidence would resolve it:** Prospective validation on multi-center cohort involving different scanner protocols and patient demographics.

### Open Question 2
- **Question:** How can the "black-box" nature of hybrid GCN-Transformer architecture be interpreted to provide clinicians with explainable diagnostic cues?
- **Basis in paper:** [explicit] Section 5.4 identifies "black-box" nature as limitation presenting "challenges in interpretability" and hindering clinician trust.
- **Why unresolved:** Model combines complex spatial, temporal, and graphical components; paper does not implement visualization techniques to demonstrate which features drove specific classifications.
- **What evidence would resolve it:** Integration of explainable AI methods, such as SHAP values for clinical parameters or gradient-weighted class activation mapping for CMR inputs.

### Open Question 3
- **Question:** Is observed optimal performance at 11 graph nodes a generalizable principle for multimodal fusion or artifact of specific feature dimensions?
- **Basis in paper:** [inferred] Section 5.2 notes performance peaked when node count equaled clinical feature count (11) and degraded with mismatch; authors ask if this innovation is highly adaptable.
- **Why unresolved:** Unclear if "node-clinical feature alignment" is robust architectural requirement or reflects overfitting to specific vector size of clinical inputs.
- **What evidence would resolve it:** Ablation studies on datasets with varying numbers of clinical features to see if optimal node count tracks with feature dimension.

### Open Question 4
- **Question:** Is reported AUC of 0.74 for non-PH subjects stable given small test set size and high standard deviation?
- **Basis in paper:** [inferred] Method employed test set of only 18 samples (6 per class) repeated 35 times; Section 4.1 reports AUC for non-PH as 0.745 ± 0.118.
- **Why unresolved:** Standard deviation of ~0.12 on small test set implies high variance and potential instability in model's ability to distinguish non-PH from PH subtypes; small "n" limits statistical power.
- **What evidence would resolve it:** Evaluation on held-out test set comprising at least 50-100 samples per class to reduce confidence intervals.

## Limitations
- Small test set size (18 samples, 6 per class) results in high variance estimates (±6-10%) and limits generalizability of performance metrics
- Class imbalance in training data (112 pre-capillary, 32 post-capillary, 60 non-PH) may inflate accuracy metric
- Limited clinical data using only 7 features, missing critical factors like exercise tolerance and genetic markers

## Confidence
- **High Confidence:** Model architecture integration (GCN + CNN + Transformer) is technically sound and multimodal approach is valid; RAC calculation methodology is clearly defined
- **Medium Confidence:** Relative performance improvements from architectural components (GCN fusion, node count optimization) are credible based on ablation studies, though small sample size introduces uncertainty
- **Low Confidence:** Absolute performance metrics (73% accuracy, 81% AUC) should be treated cautiously due to limited test set size and single-center nature of data

## Next Checks
1. **External Validation:** Test model on independent dataset from different institution to verify 73%±6% accuracy holds across different CMR protocols and patient populations

2. **Permutation Test:** Randomly shuffle clinical features while keeping imaging data intact to confirm GCN is learning meaningful interactions rather than exploiting spurious correlations in small dataset

3. **Temporal Robustness:** Evaluate model performance when input frames are temporally shuffled to verify Transformer is actually capturing temporal dependencies rather than learning from spatial features alone