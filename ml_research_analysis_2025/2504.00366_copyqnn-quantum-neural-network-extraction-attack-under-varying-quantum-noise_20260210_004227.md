---
ver: rpa2
title: 'CopyQNN: Quantum Neural Network Extraction Attack under Varying Quantum Noise'
arxiv_id: '2504.00366'
source_url: https://arxiv.org/abs/2504.00366
tags:
- quantum
- data
- learning
- training
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of model extraction attacks
  on Quantum Neural Networks (QNNs) deployed via QNN-as-a-Service (QNNaaS) platforms
  on noisy intermediate-scale quantum (NISQ) computers. The core method, CopyQNN,
  introduces a three-step data cleaning pipeline to filter noisy data based on variance
  across multiple query rounds, followed by a novel integration of quantum contrastive
  learning and transfer learning to train accurate substitute QNNs with limited data.
---

# CopyQNN: Quantum Neural Network Extraction Attack under Varying Quantum Noise

## Quick Facts
- arXiv ID: 2504.00366
- Source URL: https://arxiv.org/abs/2504.00366
- Reference count: 32
- Primary result: Achieves 8.73% average performance improvement over QLeak with 90× fewer queries on NISQ hardware

## Executive Summary
This paper presents CopyQNN, a novel model extraction attack framework for Quantum Neural Networks (QNNs) deployed on QNN-as-a-Service platforms. The framework addresses the challenge of varying quantum noise on NISQ devices by introducing a three-step data cleaning pipeline based on variance across multiple query rounds. CopyQNN combines quantum contrastive learning for self-supervised feature extraction with transfer learning to train accurate substitute QNNs using limited but cleaned query data. Experiments on IBM_Brisbane demonstrate significant improvements in both accuracy and query efficiency compared to state-of-the-art QLeak attack, while maintaining stealth through reduced query volume.

## Method Summary
CopyQNN operates through a three-step pipeline: (1) multi-round querying of the victim QNN over 24 hours to capture temporal noise variation, (2) variance-based data cleaning to filter out noisy samples, and (3) training a substitute QNN using quantum contrastive learning followed by transfer learning. The attack begins by querying the black-box victim QNN (4 qubits, 2 VQC layers) on randomly selected samples distributed across 5 rounds. For each sample, variance is computed across probability outputs from all rounds, and a "Remember Ratio" (RR=0.6) retains only top-variance samples. A quantum encoder (QEnc) is then pre-trained on source task data via Barlow Twins contrastive learning (100 epochs), frozen, and combined with a task-specific QClassifier (300 epochs) to create the final substitute QNN. The entire pipeline is tested on MNIST and Fashion-MNIST binary classification tasks using IBM_Brisbane NISQ hardware.

## Key Results
- 8.73% average performance improvement across all tasks compared to QLeak baseline
- 90× reduction in required queries while maintaining or improving accuracy
- Effective handling of varying quantum noise through variance-based data cleaning
- Successful extraction on both MNIST and Fashion-MNIST binary classification tasks

## Why This Works (Mechanism)

### Mechanism 1
Variance-based data filtering improves label quality by removing consistently erroneous predictions caused by quantum noise. Multi-round queries capture temporal noise variation, and low-variance samples correlate with systematic noise-induced errors. The "Remember Ratio" (RR) retains only top-variance samples, which empirical analysis shows are more likely correctly labeled.

### Mechanism 2
Quantum contrastive learning enables effective feature extraction from limited source data without requiring labels. A quantum encoder (QEnc) is trained using Barlow Twins objective on augmented unlabeled source data. The loss encourages invariance to augmentations while decorrelating embedding components.

### Mechanism 3
Freezing a pre-trained encoder and training only a lightweight classifier achieves high accuracy with minimal labeled data. After QEnc pre-training via contrastive learning, it is frozen and combined with a task-specific QClassifier. Only the classifier parameters are optimized on the cleaned query dataset.

## Foundational Learning

- **Variance as noise indicator**
  - Why needed here: The core data cleaning mechanism assumes understanding that low variance across query rounds indicates systematic noise-induced errors rather than model uncertainty
  - Quick check question: Can you explain why consistently wrong predictions would show lower variance than correct predictions under time-varying noise?

- **Contrastive learning objectives (Barlow Twins)**
  - Why needed here: The framework uses Barlow Twins loss for self-supervised pre-training; understanding the diagonal/off-diagonal terms is essential for debugging convergence
  - Quick check question: What does the first term (diagonal elements → 1) encourage versus the second term (off-diagonal elements → 0) in the cross-correlation matrix?

- **QNN architecture components (encoder, VQC, measurement)**
  - Why needed here: CopyQNN requires mapping between architecture components (QEnc vs QClassifier) and their roles in the transfer learning pipeline
  - Quick check question: Which component is frozen during target-domain training, and which parameters are updated?

## Architecture Onboarding

- **Component map**: QEnc (8 qubits, 4 VQC layers) → QClassifier (4 qubits, 4 VQC layers) → Variance Calculator → Remember Ratio Filter → Mixup Augmenter → CrossEntropy Loss

- **Critical path**:
  1. Query victim QNN over m=5 rounds distributed across 24 hours
  2. Compute variance for each sample; retain top RR=0.6 by variance
  3. Pre-train QEnc on source task via contrastive learning (100 epochs, batch 256)
  4. Freeze QEnc; train QClassifier on cleaned data (300 epochs, batch = data size)
  5. Evaluate substitute QNN accuracy on held-out test set

- **Design tradeoffs**:
  - Query rounds vs. stealth: More rounds improve variance estimates but increase detection risk
  - Remember Ratio: Lower RR improves label quality but reduces training data; optimal found at RR=0.6
  - VQC depth: Deeper QEnc (4 layers vs. QuantumLeak's 2) increases expressiveness with modest (+20%) hardware overhead

- **Failure signatures**:
  - Training loss not converging during contrastive learning → check augmentation pipeline and batch size
  - Substitute accuracy degrades with more query rounds → noise characterization may be unreliable; consider alternative variance metrics
  - Large accuracy gap between tasks → source/target domain mismatch; consider pre-training on more related source data

- **First 3 experiments**:
  1. Validate variance-noise correlation: Query victim QNN for 5 rounds on 200 samples; plot variance distribution for correct vs. incorrect predictions
  2. Ablate Remember Ratio: Sweep RR ∈ {0.1, 0.2, ..., 1.0} on a single task (e.g., m01) to identify optimal filtering threshold
  3. Contrastive pre-training sanity check: Train QEnc on source task with different augmentation strategies; monitor loss convergence and downstream classifier accuracy

## Open Questions the Paper Calls Out

### Open Question 1
Can the CopyQNN framework effectively scale to multi-class classification tasks beyond the binary classification demonstrated in the paper? The experimental methodology explicitly states, "For simplicity... we focus on a binary classification using the MNIST dataset," limiting evaluation to tasks like m01 and f23.

### Open Question 2
Is the variance-based noise characterization universally robust across different NISQ hardware architectures (e.g., ion traps vs. superconducting qubits) with distinct noise profiles? The paper relies entirely on data from the "IBM_Brisbane" superconducting device, which exhibits specific temporal noise fluctuations.

### Open Question 3
Can active defense mechanisms, such as query logging or output perturbation, effectively detect or mitigate CopyQNN despite its reduced query footprint? The paper claims that reducing queries by 90× helps maintain "attack stealth," but the evaluation focuses solely on attack success rates.

## Limitations
- The variance-based data cleaning mechanism's effectiveness critically depends on noise characteristics remaining stable across the 24-hour query window
- The Barlow Twins contrastive learning implementation lacks specification of the off-diagonal penalty weight (λ)
- The optimal Remember Ratio of 0.6 is empirically determined but may not generalize to tasks with different class distributions or noise patterns

## Confidence
- **High Confidence**: The 8.73% accuracy improvement and 90× query reduction over QLeak baseline on IBM_Brisbane (tested across 10 tasks with standard deviations reported)
- **Medium Confidence**: The variance-based filtering mechanism's noise discrimination capability (based on limited empirical correlation plots)
- **Low Confidence**: Generalization of the framework to different quantum hardware platforms and noise models not characterized by IBM_Brisbane

## Next Checks
1. **Noise Stationarity Validation**: Perform the same multi-round query experiment on IBM_Albany (different noise profile) to verify variance-based filtering generalizes across hardware platforms
2. **Temporal Noise Correlation**: Analyze variance correlation between consecutive query rounds to quantify noise stationarity assumptions and identify optimal query distribution strategy
3. **Ablation of Contrastive Learning Components**: Systematically remove Barlow Twins loss terms (diagonal vs. off-diagonal penalties) to quantify their individual contributions to downstream accuracy