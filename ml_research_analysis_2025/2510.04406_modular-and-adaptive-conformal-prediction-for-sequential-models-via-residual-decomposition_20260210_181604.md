---
ver: rpa2
title: Modular and Adaptive Conformal Prediction for Sequential Models via Residual
  Decomposition
arxiv_id: '2510.04406'
source_url: https://arxiv.org/abs/2510.04406
tags:
- coverage
- prediction
- which
- upstream
- intervals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a modular conformal prediction framework that
  decomposes prediction residuals into interpretable upstream and downstream components
  for two-stage sequential models. The method constructs prediction intervals using
  stage-specific quantiles weighted by scaling parameters selected via family-wise
  error rate control, enabling practitioners to attribute uncertainty to specific
  pipeline stages.
---

# Modular and Adaptive Conformal Prediction for Sequential Models via Residual Decomposition

## Quick Facts
- arXiv ID: 2510.04406
- Source URL: https://arxiv.org/abs/2510.04406
- Reference count: 40
- Primary result: Proposed modular conformal prediction framework achieves robust coverage for two-stage sequential models through interpretable upstream/downstream uncertainty attribution

## Executive Summary
This paper introduces a modular conformal prediction framework that decomposes prediction residuals into interpretable upstream and downstream components for two-stage sequential models. The method constructs prediction intervals using stage-specific quantiles weighted by scaling parameters selected via family-wise error rate control, enabling practitioners to attribute uncertainty to specific pipeline stages. Experiments on synthetic distribution shifts and real-world supply chain/forecasting data demonstrate that the approach maintains coverage under conditions that degrade standard conformal methods, while providing interpretable diagnostics for model improvement.

## Method Summary
The framework extends split conformal prediction to two-stage sequential models by decomposing total residuals into components attributable to upstream and downstream prediction errors. Given intermediate variable x and models μ̂₁(w) and μ̂₂(x), residuals are split into R₂ = |y - μ̂₂(x)| (downstream error) and ΔR₁ = ||y - μ̂₂(x)| - |y - μ̂₂(x̂)|| (propagation of upstream error). Prediction intervals use weighted sums of quantiles from these components, with scaling parameters selected via FWER-controlled hypothesis testing on calibration data. An adaptive extension maintains sliding windows of recent observations to update parameters based on component-wise coverage feedback, preserving long-run coverage guarantees while improving responsiveness to stage-specific distribution shifts.

## Key Results
- Maintains marginal coverage P(ytest ∈ Ĉα(wtest)) ≥ 1-α under both upstream and downstream distribution shifts
- Provides interpretable uncertainty attribution through stage-specific scaling parameters (a,b) that reflect relative contributions of upstream vs downstream errors
- Outperforms standard conformal methods when shifts affect pipeline stages asymmetrically, with degradation only under uniform shifts affecting entire pipeline
- Adaptive extension preserves long-run coverage guarantees while improving responsiveness to non-stationary data

## Why This Works (Mechanism)

### Mechanism 1
Decomposing total prediction residual R = |y - μ̂₂(μ̂₁(w))| into R₂ = |y - μ̂₂(x)| and ΔR₁ = ||y - μ̂₂(x)| - |y - μ̂₂(x̂)|| enables interpretable uncertainty attribution. The reverse triangle inequality guarantees R ≤ ΔR₁ + R₂, allowing conservative interval construction using stage-specific quantiles.

### Mechanism 2
FWER-based multiple hypothesis testing selects scaling parameters that achieve risk-controlled coverage guarantees. For candidate pairs (a,b) ∈ Λ, binomial tests against null hypothesis of α miscoverage control P(miscoverage > α) ≤ δ via Bonferroni or fixed sequence testing procedures.

### Mechanism 3
Adaptive parameter updates based on component-wise coverage feedback preserve long-run coverage while improving responsiveness. Sliding windows track recent coverage; parameters (a_t, b_t, c_t, d_t) adjust based on which residual component dominates recent errors, with step sizes η controlling adaptation rate.

## Foundational Learning

- **Split conformal prediction**: Understand quantile-based interval construction for IID data; check: For n calibration scores and target α, what quantile determines radius?
- **Two-stage sequential prediction**: Identify upstream vs downstream stages in modular pipelines; check: In sensor → feature → prediction pipeline, which stage is upstream?
- **Family-wise error rate (FWER) control**: Understand multiple testing procedures for parameter selection; check: Testing 10 hypotheses at FWER δ=0.1 via Bonferroni uses what per-hypothesis threshold?

## Architecture Onboarding

- **Component map**: Training set S_train → fit μ̂₁ on (w,x) and μ̂₂ on (x,y) → Conformal set S_conf computes {ΔR₁}, {R₂} → Calibration set S_cal tests candidates λ → Test: observe w_test only
- **Critical path**: 1) Train μ̂₁, μ̂₂ independently 2) Compute residual components on S_conf 3) Extract quantiles Q_{1-c}(ΔR₁), Q_{1-d}(R₂) 4) Test candidates on S_cal via FWER 5) Select (a,b) from Λ_val 6) Construct Ĉ(w_test) = μ̂₂(μ̂₁(w_test)) ± weighted sum
- **Design tradeoffs**: Higher c,d values increase shift sensitivity but cause more abstention; larger window k stabilizes estimates but reduces adaptivity; tolerance τ improves IID efficiency at cost of weaker guarantees
- **Failure signatures**: Λ_val = ∅ signals severe shift requiring retraining; systematic coverage gaps indicate step size issues; consistently wide intervals suggest overly conservative thresholds
- **First 3 experiments**: 1) Synthetic validation with controlled upstream/downstream shifts 2) Ablation study varying (c,d) to measure coverage-width tradeoff 3) Real-world automobile supply chain data showing scaling parameter evolution during 2020 shock

## Open Questions the Paper Calls Out

- **Multi-stage pipeline efficiency**: How to extend framework to pipelines with >2 stages without exponential growth in candidate space Λ?
- **Intermediate observability relaxation**: Can the requirement for observable intermediate x be relaxed while preserving interpretable attribution?
- **Uniform shift handling**: How to strengthen method for distribution shifts affecting all pipeline stages simultaneously?
- **Dynamic quantile selection**: Is there a principled method for selecting quantile levels (cₜ, dₜ) when desired parameters fall outside Λ_val?

## Limitations

- Requires observable intermediate variable x at calibration time, limiting applicability to black-box pipelines
- Abstention occurs when no valid parameters exist in Λ under severe distribution shifts
- Assumes temporal stationarity within adaptation windows, potentially failing under rapid non-stationarity
- Computational overhead from multiple quantile estimates and FWER testing exceeds standard conformal methods

## Confidence

- **High confidence**: Mathematical framework and IID coverage guarantees are rigorously proven
- **Medium confidence**: Adaptive extension and FWER selection work as described, though hyperparameter sensitivity remains
- **Low confidence**: Real-world experimental results lack sufficient implementation details for independent verification

## Next Checks

1. **Candidate grid ablation**: Systematically vary |Λ| grid size to identify optimal tradeoff between coverage, abstention rate, and computational cost

2. **Non-IID stress testing**: Evaluate performance under adversarial distribution shifts where upstream and downstream components shift at different rates or in opposite directions

3. **Black-box pipeline integration**: Test method on pipeline with estimated (not observed) intermediate representations to assess robustness when core assumption is violated