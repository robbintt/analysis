---
ver: rpa2
title: Learning to Calibrate for Reliable Visual Fire Detection
arxiv_id: '2502.09872'
source_url: https://arxiv.org/abs/2502.09872
tags:
- fire
- detection
- loss
- uncertainty
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of predictive uncertainty in deep
  learning-based visual fire detection, where models often exhibit overconfidence
  leading to unreliable predictions. The authors propose a novel uncertainty modeling
  method that transforms Expected Calibration Error (ECE) into a differentiable ECE
  loss function, which is combined with cross-entropy loss for training multi-class
  fire detection models.
---

# Learning to Calibrate for Reliable Visual Fire Detection

## Quick Facts
- arXiv ID: 2502.09872
- Source URL: https://arxiv.org/abs/2502.09872
- Reference count: 23
- Reduces model overconfidence in visual fire detection while maintaining classification accuracy

## Executive Summary
This paper addresses the critical issue of overconfidence in deep learning-based visual fire detection models, where high accuracy can mask unreliable predictions. The authors propose a novel method that transforms the Expected Calibration Error (ECE) metric into a differentiable loss function, enabling end-to-end calibration optimization during training. By combining this ECE loss with cross-entropy loss and applying curriculum learning to dynamically adjust the calibration pressure, the method effectively reduces model uncertainty without significant accuracy degradation on two widely used fire detection datasets.

## Method Summary
The proposed method introduces a differentiable ECE loss function by replacing the non-differentiable indicator function in standard ECE with a sigmoid approximation, enabling gradient-based calibration optimization. This ECE loss is combined with cross-entropy loss in a curriculum learning framework where the calibration pressure gradually increases during training. The approach is applied to existing fire detection architectures (DFAN and EdgeFireSmoke) and trained on two datasets: DFAN (3,803 images, 12 categories) and EdgeFireSmoke (49,452 images, 4 categories). The sigmoid approximation formula S(tan(π·p̂ᵢ − π/2)) enables smooth gradients while preserving calibration measurement properties.

## Key Results
- DFAN model: ECE reduced from 0.054 to 0.040 with less than 0.7% accuracy loss
- EdgeFireSmoke model: ECE reduced from 0.012 to 0.006 with similar accuracy preservation
- Curriculum learning approach (sₑ=0) outperforms fixed-weight calibration strategies
- Reliability diagrams show improved confidence-accuracy alignment after calibration

## Why This Works (Mechanism)

### Mechanism 1: Differentiable ECE Loss via Sigmoid Approximation
Replacing the non-differentiable indicator function in ECE with a sigmoid-based approximation enables gradient-based calibration optimization during training. The sigmoid smoothly transitions between 0 and 1 as predicted probability changes, preserving ECE's calibration logic while enabling backpropagation. This works because the sigmoid approximation sufficiently preserves the original ECE's calibration measurement properties without introducing distortion that would misguide optimization.

### Mechanism 2: Curriculum Learning for Progressive Calibration Pressure
Gradually increasing ECE loss weight during training allows the model to stabilize classification before optimizing for calibration, preventing harmful interference. The weight formula scales ECE loss from near-zero early in training toward the target weight by the final epoch. This works because classification learning benefits from being established before calibration optimization begins, and a linear weight ramp is appropriate for this domain.

### Mechanism 3: Online Calibration via Joint Loss Optimization
Simultaneously optimizing NLL and ECE losses during training produces models with aligned confidence-accuracy without requiring post-hoc recalibration. The combined loss creates competing objectives: NLL drives class separation while ECE penalizes overconfidence on errors and underconfidence on correct predictions. This works because the two objectives can reach an acceptable equilibrium without catastrophic interference, and online calibration generalizes better than post-calibration for fire detection.

## Foundational Learning

- **Expected Calibration Error (ECE)**: A metric measuring the gap between confidence and accuracy. Why needed: ECE is the core metric being optimized and the basis for the differentiable loss. Quick check: If a model outputs confidence 0.9 on 100 samples but only 70 are correctly classified, what is the calibration error for that bin?

- **Overconfidence in Deep Learning Classifiers**: Modern neural networks often produce poorly calibrated probabilities despite high accuracy. Why needed: The paper targets overconfidence as the failure mode being corrected. Quick check: Why might a fire detection model achieve 95% accuracy yet be dangerous to deploy if poorly calibrated?

- **Curriculum Learning**: Training strategy that starts with "easier" tasks before introducing "harder" ones. Why needed: The weight scheduling strategy depends on curriculum learning principles. Quick check: What would likely happen if ECE loss were applied at full weight from epoch 0 on an untrained model?

## Architecture Onboarding

- **Component map**: Image preprocessing → Backbone CNN (DFAN/EdgeFireSmoke) → Softmax probabilities → ECE binning → Sigmoid accuracy computation → NLL loss → ECE loss → Curriculum-weighted combination → Backprop

- **Critical path**: Forward pass → softmax probabilities → ECE binning across batch → sigmoid accuracy computation → loss combination (epoch-dependent) → backprop through both losses

- **Design tradeoffs**: 
  - Batch size vs. ECE stability: Larger batches improve bin statistics but increase memory
  - Number of bins (M): Training uses M=10, evaluation uses M=15; more bins = finer-grained calibration but sparser per-bin statistics
  - Target weight γₑ: Dataset-dependent (0.05 for DFAN, 5.0 for EdgeFireSmoke)
  - Start epoch sₑ: Experiments show sₑ=0 works best despite curriculum intuition

- **Failure signatures**: 
  - ECE not decreasing: γₑ may be too low for dataset
  - Accuracy drops >1%: Calibration pressure too strong; reduce γₑ or increase sₑ
  - Training instability or NaN losses: Check for extreme probability values in sigmoid/tan computations

- **First 3 experiments**:
  1. Baseline characterization: Train with NLL only, measure accuracy and ECE
  2. Loss magnitude observation: Record raw NLL and ECE values during early training
  3. Curriculum schedule ablation: Compare sₑ=0 vs. sₑ=10 on validation ECE

## Open Questions the Paper Calls Out

- **Can the trade-off between classification accuracy and decision reliability be eliminated?**: Future work will focus on "exploring methods to enhance classification accuracy while maintaining the reliability of decisions" since the current method consistently results in slight performance drops (less than 0.7% accuracy).

- **How effective is the proposed online calibration method in real-world applications?**: The authors identify "achieving better effects in real applications" as a specific goal for future work, noting that practical implementation poses "considerable challenge[s]" regarding computational resources.

- **To what extent does limited dataset availability constrain generalizability?**: The paper notes validation was limited because "Given the limited availability of multi-class datasets in fire detection, we validate the effectiveness of our method with two commonly used datasets," which may not capture all "complex environmental factors."

## Limitations

- **Model Architecture Dependency**: The method's effectiveness depends heavily on the underlying backbone architecture, with different γₑ values and sₑ settings suggesting architecture-specific tuning is critical.

- **Approximation Fidelity**: The sigmoid approximation for ECE may not perfectly preserve calibration measurement properties, with no systematic study of how approximation error affects different confidence distributions.

- **Curriculum Schedule Sensitivity**: The paper reports sₑ=0 works best, which contradicts typical curriculum learning intuition, and the sensitivity to sₑ, γₑ, and the linear ramp schedule is not fully explored.

## Confidence

- **High Confidence**: The mechanism of differentiable ECE loss enabling backpropagation for calibration (Section III-C, Equation 6) is well-specified and mathematically sound.
- **Medium Confidence**: The curriculum learning approach's effectiveness is demonstrated empirically but lacks theoretical grounding for why sₑ=0 outperforms delayed starts.
- **Medium Confidence**: The tradeoff between ECE reduction and accuracy preservation is quantified but the operational threshold for "acceptable" accuracy loss is context-dependent.

## Next Checks

1. **Approximation Error Analysis**: Systematically measure the gap between sigmoid-based soft accuracy and true discrete accuracy across different confidence distributions to quantify approximation fidelity.

2. **Architecture Transferability**: Apply the method to a third fire detection architecture (e.g., ResNet-based) with different parameter scales to test if architecture-specific γₑ tuning is necessary.

3. **Extreme Case Robustness**: Test the method on deliberately poorly calibrated models (e.g., overconfident classifiers trained on noisy labels) to verify the sigmoid approximation doesn't break down under stress conditions.