---
ver: rpa2
title: On Learning Verifiers for Chain-of-Thought Reasoning
arxiv_id: '2505.22650'
source_url: https://arxiv.org/abs/2505.22650
tags:
- veri
- reasoning
- sample
- learning
- traces
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies the problem of learning verifiers for Chain-of-Thought
  (CoT) reasoning in natural language. Given a problem statement and a step-by-step
  solution, the verifier must output YES if all reasoning steps are valid, and NO
  otherwise.
---

# On Learning Verifiers for Chain-of-Thought Reasoning

## Quick Facts
- arXiv ID: 2505.22650
- Source URL: https://arxiv.org/abs/2505.22650
- Reference count: 31
- This work studies PAC-learning of verifiers for Chain-of-Thought reasoning, establishing sample complexity bounds for both simple and trustable verification settings.

## Executive Summary
This paper formalizes the problem of learning verifiers for Chain-of-Thought (CoT) reasoning in natural language. The verifier must examine step-by-step solutions and output YES if all reasoning steps are valid, NO otherwise. The authors propose a PAC-learning framework and analyze different verification goals, establishing sample complexity bounds that depend on whether the verifier needs only to be accurate (simple verification) or also sound (trustable verification). The work bridges formal verification and learning theory, providing theoretical foundations for automated verification of natural language reasoning.

## Method Summary
The paper proposes a PAC-learning framework for CoT verifiers that examine problem-solution pairs and identify faulty reasoning steps. Two verification settings are studied: (1) Simple verification where the goal is to achieve low error rate on detecting faulty steps, and (2) Trustable verification where the verifier must be sound (never accept faulty traces) and ideally complete. For simple verifiers, ERM over a finite or VC-dimension hypothesis class achieves logarithmic sample complexity. For trustable verifiers, the paper considers two regimes: when few gold-standard proofs exist per problem (learnable with O(1/ε) samples), and when many proofs exist (requiring Ω(|H|) samples without additional structure). The intersection algorithm provides a sound verifier by taking the logical AND of all consistent hypotheses.

## Key Results
- Simple verifiers are PAC-learnable with O(log|H|/ε) samples for finite classes and O(VCDim(H)log(T)/ε) for VC-dimension classes
- Trustable verifiers can be learned when few gold-standard proofs exist with O(1/ε(log|H|+log 1/δ)) samples
- When many correct proofs exist, improper learning via intersection achieves O(|H|) sample complexity, which is optimal without additional structure
- Lower bounds show linear dependence on |H| is unavoidable in general, but intersection-closed classes achieve Õ(VCDim(H)) instead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simple verifiers can be PAC-learned from labeled reasoning traces with logarithmic sample complexity in hypothesis class size.
- Mechanism: The verifier runs on each prefix of a reasoning trace; ERM selects a consistent verifier from H. For finite classes, any consistent h achieves ε-error with O(1/ε(log|H| + log 1/δ)) samples because a bad verifier has probability ≤ (1-ε)^m of appearing consistent.
- Core assumption: The distribution D over traces is fixed and test traces come from the same distribution (realizability by h* ∈ H).
- Evidence anchors:
  - [section 3]: Theorem 3.2 proves O(1/ε(log(|H|) + log 1/δ)) sample complexity; Theorem 3.3 extends to O(1/ε(VCDim(H) log T + log 1/δ)) for VC-dimension classes.
  - [corpus]: Related work [JVB+25] shows similar logarithmic dependence for CoT generation models, supporting the tractability claim.
- Break condition: Distribution shift breaks guarantees—if a reasoner adapts based on verifier feedback, new traces fall outside D and the learned verifier provides no guarantee.

### Mechanism 2
- Claim: Trustable verifiers that are always sound (never accept faulty traces) can be learned when few gold-standard proofs exist per problem.
- Mechanism: For each training problem x, generate all gold traces g(x) as positive examples; create negative examples by single-step deviations from the tree T_g(x). ERM over this augmented dataset yields a verifier that accepts exactly g(x) for most x ∼ D.
- Core assumption: |Σ| is finite and |g(x)| ≤ k is bounded; the verifier has access to the complete gold trace tree for each training problem.
- Evidence anchors:
  - [section 4.1]: Theorem 4.3 gives O(1/ε(log|H| + log 1/δ)) sample complexity; Theorem 4.4 gives O(1/ε(VCDim(H) log(kT|Σ|) + log 1/δ)).
  - [corpus]: FormalMATH and MINIF2F-DAFNY papers demonstrate that formal verification with bounded proof structures is tractable in practice.
- Break condition: If the gold reasoner has many correct traces per problem and only random samples are available (not the full tree), this approach fails to scale.

### Mechanism 3
- Claim: When many correct proofs exist per problem, improper learning via intersection of consistent verifiers achieves O(|H|) sample complexity, which is optimal without additional structure.
- Mechanism: Algorithm 1 computes h' = ∧_{h ∈ H_S} h (intersection of all verifiers consistent with positive training traces). This guarantees zero false positives by construction. Union bound analysis shows expected error scales with |H|.
- Core assumption: Realizability (h* ∈ H) and finite H; positive examples sampled from D+ over correct traces.
- Evidence anchors:
  - [section 4.2]: Theorem 4.7 proves O(1/ηε(|H| + log 1/δ)) sample complexity; Theorems 4.8–4.9 prove Ω(|H|) lower bounds for both proper and improper learners.
  - [corpus]: Corpus papers focus on single or few proof paths (theorem proving benchmarks); limited direct evidence for many-proof regimes.
- Break condition: If H is intersection-closed, the closure algorithm achieves Õ(VCDim(H)) instead—linear dependence on |H| is avoidable with structural assumptions.

## Foundational Learning

- Concept: PAC Learning (Probably Approximately Correct)
  - Why needed here: The entire framework is built on PAC-style sample complexity bounds; understanding the ε-δ tradeoff is essential for interpreting all theorems.
  - Quick check question: Given sample complexity m = O(1/ε(log|H| + log 1/δ)), what happens to required samples if you halve ε and require 10× higher confidence?

- Concept: VC Dimension and Shattering
  - Why needed here: Theorems 3.3 and 4.4 bound sample complexity using VC dimension; the proof technique uses Sauer's lemma to bound shattering coefficients.
  - Quick check question: If a verifier class H can shatter 5 points but not 6, what is VCDim(H) and how does it affect sample complexity?

- Concept: Realizability vs. Agnostic Learning
  - Why needed here: Main results assume a perfect h* ∈ H exists; Appendix C extends to agnostic settings with O(1/ε²) dependence instead of O(1/ε).
  - Quick check question: If no verifier in H perfectly labels all traces, which sample complexity regime applies and how does the error definition change?

## Architecture Onboarding

- Component map:
  - **Simple Verifier Module**: Takes (x₀, τ) → runs h on each prefix → outputs {YES, NO, first_fault_index}
  - **Trustable Verifier Module**: Requires gold reasoner g → builds positive/negative examples from trace tree → outputs sound verifier
  - **Intersection Learner (Algorithm 1)**: Collects consistent verifiers H_S → returns h' = ∧_{h∈H_S} h
  - **Sample Complexity Calculator**: Maps (|H|, VCDim(H), ε, δ, T, k, |Σ|) → required training samples

- Critical path: Start with Simple Verifier (Section 3) → validate in-distribution performance → upgrade to Trustable Verifier (Section 4.1) if you can bound |g(x)| → use Intersection Learner (Section 4.2) for many-proof problems with intersection-closed H

- Design tradeoffs:
  - Simple vs. Trustable: Simple gives logarithmic sample complexity but no robustness to distribution shift; Trustable guarantees soundness but requires gold standard reasoner and finite Σ
  - Proper vs. Improper: Proper learners output h ∈ H but may need Ω(|H|) samples; improper learners can achieve better bounds for intersection-closed classes
  - Completeness vs. Soundness: 1-completeness requires accepting all gold traces; γ-completeness (γ < 1) relaxes this for tractability

- Failure signatures:
  - verifier accepts faulty traces → soundness violated → check if H is intersection-closed or increase sample size
  - verifier rejects most correct traces → low completeness → verify gold reasoner coverage or use γ-TVPAC with relaxed η
  - sample complexity explodes linearly with |H| → many-proof regime detected → consider if H has structure (intersection-closed, low VC dimension)

- First 3 experiments:
  1. Implement Simple Verifier on a finite H (e.g., K LLM verifiers as in Example B.4) with synthetic math problems; measure error rate vs. sample size to validate O(log K) scaling.
  2. Build Trustable Verifier using a deterministic solver (k=1, e.g., SAT solver) on constrained problems; verify zero false positives on held-out problems.
  3. Test Algorithm 1 on an intersection-closed class (e.g., graph valid-reasoning from Example B.3); compare empirical sample complexity against both O(|H|) and O(VCDim(H)) theoretical bounds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are CoT verifiers PAC-learnable when the maximum trace length T is unbounded (infinite)?
- Basis in paper: [explicit] Section 1.2 states: "The latter raises an interesting open question regarding learnability of CoT reasoners and verifiers for arbitrarily long traces."
- Why unresolved: All sample complexity bounds in the paper depend on T (logarithmically for VC-dimension classes, polynomially for trustable verification), assuming a finite bound on trace length.
- What evidence would resolve it: A sample complexity bound independent of T, or a lower bound showing T-dependence is unavoidable.

### Open Question 2
- Question: Can trustable verifiers be learned when the space of reasoning steps Σ is infinite?
- Basis in paper: [inferred] Section 4 explicitly assumes |Σ| is finite. Example B.1 shows SVPAC learning is possible with infinite Σ for a specific class, but states trustable verification results "do not apply as |Σ| is not finite."
- Why unresolved: The construction of negative examples via one-step deviations (Section 4.1) requires enumerating Σ \ Xi, which is infeasible when Σ is infinite.
- What evidence would resolve it: A learning algorithm for trustable verification that handles infinite Σ, or an impossibility result.

### Open Question 3
- Question: Beyond intersection-closed classes, what structural properties of verifier class H allow γ-TVPAC learning with sample complexity independent of |H|?
- Basis in paper: [inferred] Section 4.2 shows Ω(|H|) lower bound for general classes, but Appendix A shows intersection-closed classes achieve Õ(VCDim(H)) samples. The gap between these regimes remains unexplored.
- Why unresolved: Only intersection-closure is identified as a sufficient condition; no characterization of necessary conditions or broader sufficient conditions exists.
- What evidence would resolve it: Identification of other tractable structural families (e.g., specific types of closure, bounded branching factor) with improved sample bounds.

## Limitations
- The framework assumes a fixed distribution D over problems and traces, but in practice the distribution may shift as the reasoner adapts based on verifier feedback
- Trustable verification requires complete knowledge of the gold reasoner's trace tree for each training problem, which may be computationally infeasible for complex problems
- The analysis assumes finite |Σ| and bounded trace length T, which may not hold for general natural language reasoning

## Confidence
- **High confidence**: The PAC-learning framework and sample complexity bounds for finite and VC-dimension hypothesis classes (Theorems 3.2-3.3). The intersection algorithm analysis and lower bounds (Theorems 4.7-4.9) are also well-established learning theory results.
- **Medium confidence**: The trustable verifier analysis (Section 4.1) relies on specific assumptions about finite |Σ| and bounded |g(x)| that may not hold in general natural language reasoning. The many-proof regime analysis (Section 4.2) is theoretically sound but lacks empirical validation in the paper.
- **Low confidence**: Practical applicability to real LLM-based CoT systems, given the strong distributional assumptions and computational requirements for generating complete trace trees.

## Next Checks
1. Implement Algorithm 1 on a synthetic CoT dataset with known ground truth to empirically verify the O(|H|) sample complexity bound and test whether the intersection approach achieves better scaling than proper learning.
2. Design experiments to test robustness to distribution shift: train a verifier on traces from one distribution, then evaluate on traces from a slightly modified distribution to measure degradation in performance.
3. Benchmark the trustable verifier framework on a formal theorem proving dataset (e.g., FormalMATH) where complete trace trees can be generated, comparing soundness/completeness trade-offs against baseline verifiers.