---
ver: rpa2
title: 'FairExpand: Individual Fairness on Graphs with Partial Similarity Information'
arxiv_id: '2512.18180'
source_url: https://arxiv.org/abs/2512.18180
tags:
- fairness
- similarity
- graph
- individual
- fairexpand
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FairExpand, the first method to promote individual
  fairness in graph representation learning when only partial similarity information
  is available. Existing approaches require full pairwise similarity data, which is
  impractical for large-scale graphs.
---

# FairExpand: Individual Fairness on Graphs with Partial Similarity Information

## Quick Facts
- arXiv ID: 2512.18180
- Source URL: https://arxiv.org/abs/2512.18180
- Reference count: 40
- Primary result: First method to achieve individual fairness in graph representation learning with partial similarity information, improving balance scores by up to 84%

## Executive Summary
FairExpand introduces a novel framework for achieving individual fairness in graph representation learning when only partial similarity information is available. Unlike existing approaches that require complete pairwise similarity data across all nodes, FairExpand operates with partial similarity constraints and expands this information iteratively across the graph. The method alternates between enforcing fairness on a backbone model using available similarity data and propagating similarity information through a novel ε-Greedy PULL link predictor. Experimental results on six real-world graphs demonstrate consistent reductions in individual fairness bias while maintaining node classification performance.

## Method Summary
FairExpand addresses the challenge of individual fairness in graph representation learning when only partial similarity information exists. The framework works by iteratively alternating between two steps: (1) enforcing fairness constraints on a backbone graph representation model using the currently available similarity information, and (2) expanding the similarity knowledge by predicting new similarity pairs using a novel ε-Greedy PULL link predictor. This iterative process allows the method to gradually increase the coverage of similarity information across the graph, making individual fairness achievable even when starting with sparse similarity annotations. The approach is particularly valuable for large-scale graphs where collecting complete similarity information is impractical.

## Key Results
- Achieves up to 84% balance score in individual fairness metrics, compared to 81% for the next best method
- Consistently reduces individual fairness bias across six real-world graph datasets
- Maintains node classification performance while improving fairness metrics
- Demonstrates effective expansion of similarity knowledge to previously unannotated nodes

## Why This Works (Mechanism)
FairExpand works by leveraging the iterative nature of graph structure and similarity propagation. The ε-Greedy PULL link predictor balances exploration and exploitation when expanding similarity information, allowing the model to discover meaningful similarity relationships that weren't initially annotated. The alternating optimization framework ensures that as new similarity pairs are discovered, the fairness constraints are continuously enforced, creating a feedback loop that progressively improves both the similarity graph and the fairness of representations.

## Foundational Learning
- **Graph representation learning**: Understanding how nodes are embedded in vector space to capture structural and feature information
  - *Why needed*: Forms the basis for how FairExpand operates on graph data
  - *Quick check*: Can you explain how node embeddings capture both local and global graph structure?

- **Individual fairness**: The principle that similar individuals should receive similar treatment in algorithmic decisions
  - *Why needed*: Defines the fairness objective that FairExpand aims to achieve
  - *Quick check*: Can you articulate the difference between individual fairness and group fairness?

- **Similarity propagation**: The process of inferring similarity relationships between nodes based on graph structure and existing annotations
  - *Why needed*: Enables FairExpand to expand limited similarity information across the graph
  - *Quick check*: How does graph connectivity influence the propagation of similarity information?

## Architecture Onboarding
- **Component map**: Backbone model -> Fairness enforcement -> ε-Greedy PULL predictor -> Similarity expansion -> Backbone model (iterative loop)
- **Critical path**: Initial similarity data → Backbone model training → Fairness regularization → Similarity prediction → Updated similarity data → Repeat until convergence
- **Design tradeoffs**: The ε parameter in ε-Greedy PULL balances exploration vs exploitation in similarity discovery; higher ε explores more but may introduce noise, lower ε exploits known patterns but may miss important relationships
- **Failure signatures**: Poor initial similarity data leads to poor final results; insufficient graph structure for effective similarity propagation; inappropriate ε parameter selection causing oscillation or premature convergence
- **3 first experiments**:
  1. Run FairExpand on a small synthetic graph with known similarity structure to verify the iterative expansion process
  2. Test the ε-Greedy PULL predictor independently on a link prediction task to understand its behavior with different ε values
  3. Evaluate FairExpand with varying levels of initial similarity information (10%, 30%, 50%) to assess sensitivity to initial conditions

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes some initial similarity information exists, which may not be available in all scenarios
- Does not thoroughly address handling of noisy or biased initial similarity data
- Limited evaluation scope focused primarily on node classification tasks
- Lacks extensive ablation studies to quantify individual contributions of different components

## Confidence
- **High confidence**: Core algorithmic contribution and basic feasibility of similarity expansion
- **Medium confidence**: Empirical improvements in fairness metrics and practical utility
- **Medium confidence**: Scalability claims without comprehensive runtime analysis

## Next Checks
1. Conduct experiments with varying levels of initial similarity information (from very sparse to moderately dense) to assess robustness and identify minimum requirements for effective performance.

2. Implement and evaluate the method on additional graph tasks beyond node classification, such as link prediction and graph-level classification, to verify general applicability.

3. Perform sensitivity analysis on the ε parameter in the ε-Greedy PULL predictor to understand its impact on both fairness outcomes and similarity propagation accuracy.