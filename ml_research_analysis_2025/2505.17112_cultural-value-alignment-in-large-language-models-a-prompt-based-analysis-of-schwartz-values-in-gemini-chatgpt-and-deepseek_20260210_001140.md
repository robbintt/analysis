---
ver: rpa2
title: 'Cultural Value Alignment in Large Language Models: A Prompt-based Analysis
  of Schwartz Values in Gemini, ChatGPT, and DeepSeek'
arxiv_id: '2505.17112'
source_url: https://arxiv.org/abs/2505.17112
tags:
- value
- values
- cultural
- deepseek
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examined whether large language models (LLMs) exhibit\
  \ culturally situated value biases by comparing DeepSeek (trained on Chinese-language\
  \ data) with Western models ChatGPT and Gemini using Schwartz\u2019s value framework.\
  \ DeepSeek systematically downplayed self-enhancement values (e.g., power, achievement)\
  \ compared to both Western models, aligning with collectivist cultural tendencies."
---

# Cultural Value Alignment in Large Language Models: A Prompt-based Analysis of Schwartz Values in Gemini, ChatGPT, and DeepSeek

## Quick Facts
- arXiv ID: 2505.17112
- Source URL: https://arxiv.org/abs/2505.17112
- Reference count: 0
- DeepSeek systematically downplayed self-enhancement values compared to Western models, aligning with collectivist cultural tendencies

## Executive Summary
This study examined whether large language models exhibit culturally situated value biases by comparing DeepSeek (trained on Chinese-language data) with Western models ChatGPT and Gemini using Schwartz's value framework. The analysis revealed that DeepSeek systematically downplayed self-enhancement values (e.g., power, achievement) compared to both Western models, aligning with collectivist cultural tendencies. However, all models similarly prioritized self-transcendence values (e.g., benevolence, universalism), suggesting a general LLM tendency rather than cultural divergence. These findings indicate that LLMs reflect culturally situated biases rather than a universal ethical framework.

## Method Summary
The study employed a prompt-based methodology to analyze value expression across three LLM systems. Researchers applied Schwartz's value framework to evaluate how Gemini, ChatGPT, and DeepSeek responded to standardized prompts. The analysis focused on measuring the relative emphasis placed on different value categories, particularly comparing self-enhancement values (power, achievement) against self-transcendence values (benevolence, universalism). This approach allowed for systematic comparison of cultural value expression patterns across models trained on different linguistic and cultural datasets.

## Key Results
- DeepSeek systematically downplayed self-enhancement values compared to both Western models
- All models similarly prioritized self-transcendence values, suggesting a general LLM tendency
- DeepSeek's profile aligned with collectivist cultural tendencies while Western models emphasized individualistic values

## Why This Works (Mechanism)
The mechanism underlying these cultural value alignments likely stems from the training data composition of each model. DeepSeek's Chinese-language training corpus presumably contained cultural narratives and linguistic patterns that de-emphasize individual achievement and power in favor of collective harmony and social responsibility. Conversely, Western training data for ChatGPT and Gemini may contain more individualistic narratives emphasizing personal success and status. This training data-driven mechanism suggests that LLMs don't develop independent value systems but rather reflect and amplify cultural patterns present in their training corpora.

## Foundational Learning
The study provides foundational evidence that LLMs internalize and reproduce culturally specific value systems rather than developing neutral or universal ethical frameworks. This learning has significant implications for global deployment of LLMs, suggesting that model outputs may vary substantially based on training data origins. The consistent pattern across three distinct models indicates that value alignment is not an incidental artifact but a systematic property emerging from the interaction between training data and model architecture.

## Architecture Onboarding
While the paper doesn't explicitly discuss architectural details, the findings suggest that value expression patterns are robust across different LLM architectures (presumably transformer-based for all three models tested). The consistency of value expression patterns across models with different training methodologies and architectures indicates that cultural value alignment is a fundamental property emerging from the learning process rather than an architectural quirk. This suggests that any sufficiently large language model trained on culturally-specific data will likely exhibit similar value alignment patterns.

## Open Questions the Paper Calls Out
The paper implicitly raises questions about the ethical implications of deploying culturally-aligned models across different cultural contexts. It suggests the need for careful consideration of cultural value alignment when selecting models for global applications, particularly in contexts requiring cross-cultural communication or ethical reasoning that may conflict with the model's embedded cultural values.

## Limitations
- Analysis tested only three LLM systems and employed a single value framework, potentially missing model-specific or framework-specific effects
- Prompt-based methodology may not capture how models would express values in diverse real-world contexts or applications
- Cultural assumptions underlying interpretation of "collectivist" versus "Western" values may oversimplify complex cultural dynamics
- The study doesn't account for potential code-switching behavior in models trained on multilingual data
- Results may be influenced by language-specific nuances in value expression rather than fundamental value differences

## Confidence
- High confidence: DeepSeek's lower expression of self-enhancement values compared to Western models - this pattern was consistent and substantial across the sample
- Medium confidence: Interpretation that DeepSeek's profile aligns with "collectivist" cultural tendencies - while supported by the data, this relies on cultural assumptions that merit further validation
- Medium confidence: The claim that all models share similar prioritization of self-transcendence values - this finding is consistent but based on a limited sample of models

## Next Checks
1. Test additional LLMs trained on different cultural/linguistic datasets (e.g., Japanese, Arabic, Indian models) to determine if patterns extend beyond China-West comparison
2. Apply alternative value frameworks (e.g., Inglehart-Welzel cultural dimensions, Hofstede's cultural dimensions) to verify whether observed patterns persist across different theoretical lenses
3. Examine model behavior across diverse prompt contexts and applications (e.g., creative writing, technical assistance, ethical reasoning) to assess whether value expression remains stable across task domains
4. Investigate whether models exhibit different value expressions when prompted in different languages despite having been trained on multilingual data
5. Test whether fine-tuning on culturally diverse datasets can mitigate or alter the observed cultural value biases