---
ver: rpa2
title: Few-Shot Precise Event Spotting via Unified Multi-Entity Graph and Distillation
arxiv_id: '2511.14186'
source_url: https://arxiv.org/abs/2511.14186
tags:
- event
- player
- temporal
- graph
- sports
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of few-shot precise event spotting
  (PES) in sports videos, aiming to recognize fine-grained events at exact moments
  with limited labeled data. The authors propose UMEG-Net, a unified multi-entity
  graph network that integrates human skeletons, sport-specific object keypoints,
  and contextual landmarks into a single graph representation.
---

# Few-Shot Precise Event Spotting via Unified Multi-Entity Graph and Distillation

## Quick Facts
- arXiv ID: 2511.14186
- Source URL: https://arxiv.org/abs/2511.14186
- Authors: Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong
- Reference count: 28
- Primary result: UMEG-Net improves F1 scores by 1.3%-5.5% and edit scores by 1.3%-16.4% over existing methods in few-shot PES across five sports datasets

## Executive Summary
This paper addresses the challenge of few-shot precise event spotting (PES) in sports videos, where the goal is to recognize fine-grained events at exact moments with limited labeled data. The authors propose UMEG-Net, a unified multi-entity graph network that integrates human skeletons, sport-specific object keypoints, and contextual landmarks into a single graph representation. The model employs a spatial graph convolutional network combined with a parameter-free multi-scale temporal shift mechanism for efficient spatio-temporal feature extraction. Additionally, multimodal knowledge distillation is used to transfer knowledge from the graph-based model to an RGB-based student network, enhancing robustness. Experiments across five sports datasets demonstrate that UMEG-Net significantly outperforms existing methods in few-shot settings.

## Method Summary
The UMEG-Net architecture builds upon three key innovations: (1) a unified multi-entity graph that integrates skeletons, object keypoints, and contextual landmarks to capture comprehensive spatial relationships, (2) a parameter-free multi-scale temporal shift mechanism that efficiently extracts spatio-temporal features without additional parameters, and (3) multimodal knowledge distillation that transfers knowledge from the graph-based model to an RGB-based student network. The unified graph representation captures both human-centric and context-centric information through graph convolutional networks, while the temporal shift mechanism enables efficient temporal modeling. The distillation approach leverages the strengths of multiple modalities to improve the robustness of the RGB-based model, particularly valuable in few-shot settings where labeled data is scarce.

## Key Results
- UMEG-Net outperforms existing methods by 1.3%-5.5% in F1 score across five sports datasets
- Edit scores improve by 1.3%-16.4% compared to state-of-the-art baselines
- Multimodal distillation approach achieves an average gain of 5.8% in F1 score and 6.7% in edit score
- Performance improvements are consistent across all five tested sports: gymnastics, diving, ski jumping, bowling, and diving2

## Why This Works (Mechanism)
The unified multi-entity graph effectively captures both human-centric and context-centric information by integrating skeletons, object keypoints, and landmarks into a single representation. This comprehensive spatial modeling is particularly effective for fine-grained event spotting where precise spatial relationships matter. The parameter-free multi-scale temporal shift mechanism enables efficient temporal feature extraction without increasing model complexity, making it well-suited for few-shot scenarios where overfitting is a concern. The multimodal knowledge distillation approach leverages the complementary strengths of different modalities, with the graph-based teacher model providing structured spatial knowledge that enhances the RGB-based student model's robustness to visual variations.

## Foundational Learning
- **Few-shot learning**: Training models with limited labeled examples; needed because annotating sports videos for fine-grained events is expensive and time-consuming; quick check: verify that training sets contain only 1-5 labeled examples per class
- **Graph convolutional networks**: Neural networks that operate on graph-structured data; needed to model complex spatial relationships between entities like skeletons, objects, and landmarks; quick check: confirm that spatial relationships are preserved through graph message passing
- **Knowledge distillation**: Training a student model to mimic a teacher model's outputs; needed to transfer knowledge from the graph-based model to the RGB-based model for improved robustness; quick check: verify that teacher confidence scores are used during distillation
- **Spatio-temporal feature extraction**: Modeling both spatial and temporal dimensions in video data; needed because events in sports videos have both spatial configurations and temporal progressions; quick check: confirm temporal modeling captures event timing precisely
- **Multi-entity graph construction**: Creating graph representations from multiple entity types; needed to integrate skeletons, object keypoints, and contextual landmarks into unified representations; quick check: verify all three entity types are represented in the final graph

## Architecture Onboarding

**Component map:** Skeleton/Keypoint Detection -> Graph Construction -> Spatial GCN -> Temporal Shift -> Feature Fusion -> Classification

**Critical path:** The most critical processing path involves constructing the unified multi-entity graph from detected skeletons, object keypoints, and contextual landmarks, followed by spatial graph convolution and the parameter-free multi-scale temporal shift mechanism for spatio-temporal feature extraction.

**Design tradeoffs:** The unified graph representation trades off computational complexity for comprehensive spatial modeling, while the parameter-free temporal shift mechanism sacrifices some temporal modeling flexibility for efficiency and reduced overfitting risk in few-shot settings. The multimodal distillation approach trades teacher model complexity for improved student model robustness.

**Failure signatures:** Potential failure modes include: (1) poor performance when skeleton or keypoint detection fails due to occlusion or low resolution, (2) overfitting in few-shot scenarios despite the parameter-free temporal shift mechanism, (3) distillation failure when modality alignment between teacher and student is poor, and (4) limited generalization to sports with significantly different visual characteristics than the five tested datasets.

**First experiments to run:** 
1. Ablation study removing each modality (skeletons, object keypoints, landmarks) to quantify their individual contributions
2. Comparison of parameter-free temporal shift versus traditional temporal convolution mechanisms
3. Evaluation of distillation effectiveness by comparing teacher and student model performance

## Open Questions the Paper Calls Out
None

## Limitations
- The study relies on five sports-specific datasets (gymnastics, diving, ski jumping, bowling, and diving2), which may limit generalizability to other sports or domains with different visual characteristics
- The effectiveness of the multimodal distillation approach depends heavily on the quality of the teacher model and the alignment between skeleton, keypoint, and RGB modalities
- The parameter-free multi-scale temporal shift mechanism, though efficient, lacks detailed ablation studies to isolate its specific contribution to performance gains

## Confidence
- High confidence: The core architecture of UMEG-Net (unified multi-entity graph combining skeletons, object keypoints, and landmarks) and its superiority over baseline methods in few-shot PES
- Medium confidence: The effectiveness of the multimodal distillation approach and the specific contribution of the temporal shift mechanism
- Medium confidence: The scalability of the approach to sports beyond the five tested datasets

## Next Checks
1. Perform cross-domain validation by testing UMEG-Net on non-sports video datasets (e.g., cooking or medical procedures) to assess generalizability beyond the current sports-specific focus
2. Conduct detailed ablation studies to isolate the contribution of each modality (skeletons, object keypoints, landmarks) and the temporal shift mechanism to the overall performance
3. Evaluate the robustness of the model when skeleton and keypoint detection fails (e.g., occlusion, low resolution) to assess real-world deployment viability