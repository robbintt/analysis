---
ver: rpa2
title: 'Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?'
arxiv_id: '2602.02290'
source_url: https://arxiv.org/abs/2602.02290
tags:
- hallucination
- story
- scientific
- narrative
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces StoryScore, a composite metric for evaluating
  AI-generated scientific stories that combines semantic alignment, lexical grounding,
  structural fidelity, fluency, and hallucination control. The method addresses the
  challenge of assessing narrative quality when creative reformulation and persona
  adaptation are expected, making standard hallucination detection unreliable.
---

# Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?

## Quick Facts
- **arXiv ID**: 2602.02290
- **Source URL**: https://arxiv.org/abs/2602.02290
- **Reference count**: 27
- **Key outcome**: Introduces StoryScore, a composite metric combining semantic alignment, lexical grounding, structural fidelity, fluency, and hallucination control for evaluating AI-generated scientific narratives

## Executive Summary
This paper addresses the challenging problem of evaluating AI-generated scientific stories that require both factual grounding and creative reformulation. Traditional evaluation metrics often fail to capture the nuanced balance between scientific accuracy and narrative quality when persona adaptation or creative reformulation is expected. The authors introduce StoryScore, a composite evaluation metric that integrates multiple signals including semantic similarity (BERTScore), lexical coverage, structural fidelity, fluency, and targeted hallucination detection. Through experiments on a scientific storytelling pipeline, StoryScore successfully discriminates between pre-trained and fine-tuned models, capturing improvements in narrative quality that global semantic metrics miss.

## Method Summary
StoryScore is designed as a composite metric that addresses the dual requirements of scientific accuracy and narrative quality in AI-generated stories. The framework integrates five key components: semantic alignment (measured through BERTScore comparing generated text to reference scientific texts), lexical grounding (ensuring coverage of important scientific terminology), structural fidelity (maintaining logical flow and organization), fluency (assessing readability and coherence), and hallucination control (detecting factual inconsistencies). The hallucination detection component is particularly challenging, as it must distinguish between harmful factual errors and legitimate creative reformulation. The authors address this by comparing generated content against both source materials and persona-aligned references, though they acknowledge this remains an imperfect solution.

## Key Results
- StoryScore successfully discriminates between pre-trained and fine-tuned models, capturing narrative quality improvements missed by standard semantic metrics
- The composite metric balances factual grounding with narrative control, addressing the unique challenges of scientific storytelling evaluation
- Existing hallucination detection methods struggle to distinguish between legitimate creative reformulation and factual errors, particularly when persona adaptation is expected

## Why This Works (Mechanism)
StoryScore works by recognizing that scientific storytelling requires multiple evaluation dimensions simultaneously. Unlike single-metric approaches that might over-penalize creative reformulation or miss factual inconsistencies, StoryScore's multi-component design allows for nuanced assessment. The semantic alignment component ensures scientific accuracy, while structural fidelity and fluency capture narrative quality. The hallucination detection component attempts to filter out harmful factual errors while allowing for legitimate creative expression. By combining these signals, StoryScore provides a more complete picture of narrative quality than any single metric could achieve.

## Foundational Learning
- **Semantic alignment metrics** (BERTScore): Needed to measure content similarity between generated and reference texts while capturing semantic meaning rather than exact word matches. Quick check: Compare BERTScore with exact match metrics on paraphrased content.
- **Lexical grounding**: Ensures scientific terminology is preserved in the narrative. Needed to maintain domain-specific accuracy. Quick check: Measure vocabulary overlap between generated text and scientific domain corpus.
- **Hallucination detection**: Critical for identifying factual errors while distinguishing them from creative reformulation. Needed because traditional fact-checking fails when creative adaptation is expected. Quick check: Test hallucination detection on known factual errors versus acceptable paraphrasing.
- **Composite metric design**: Required to balance multiple evaluation objectives simultaneously. Needed because single metrics cannot capture the complexity of scientific storytelling. Quick check: Analyze individual component contributions to overall score.

## Architecture Onboarding

**Component Map:**
StoryScore -> [Semantic Alignment (BERTScore) -> Lexical Grounding -> Structural Fidelity -> Fluency -> Hallucination Detection]

**Critical Path:**
The most critical evaluation path is through semantic alignment and hallucination detection, as these directly impact the scientific validity of the generated stories. Structural fidelity and fluency ensure narrative quality, while lexical grounding maintains domain specificity.

**Design Tradeoffs:**
The primary tradeoff is between penalizing creative reformulation (which might improve narrative quality) and ensuring scientific accuracy. The authors chose to implement a composite metric that attempts to balance these competing objectives rather than using a single strict metric.

**Failure Signatures:**
- Over-penalization of creative reformulation in persona adaptation scenarios
- False positives in hallucination detection when legitimate paraphrasing occurs
- Insufficient sensitivity to narrative quality improvements when scientific accuracy is maintained

**3 First Experiments:**
1. Compare StoryScore rankings with human expert evaluations on a sample of generated scientific stories
2. Test hallucination detection performance on a benchmark dataset with labeled examples of factual errors versus acceptable reformulation
3. Evaluate component sensitivity by systematically varying individual metric weights and observing