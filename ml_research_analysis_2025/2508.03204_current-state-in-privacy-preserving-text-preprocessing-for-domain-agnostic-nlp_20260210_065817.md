---
ver: rpa2
title: Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic
  NLP
arxiv_id: '2508.03204'
source_url: https://arxiv.org/abs/2508.03204
tags:
- text
- data
- anonymization
- approaches
- pseudonymization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This report surveys domain-agnostic text anonymization techniques
  for NLP preprocessing, focusing on pseudonymization and ontology-driven approaches.
  The study highlights the challenge of protecting privacy in large language models
  trained on data containing personally identifiable information (PII), as such models
  can leak private data.
---

# Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP

## Quick Facts
- **arXiv ID:** 2508.03204
- **Source URL:** https://arxiv.org/abs/2508.03204
- **Reference count:** 5
- **Primary result:** Surveys domain-agnostic text anonymization techniques for NLP preprocessing, highlighting challenges in protecting PII in LLM training data

## Executive Summary
This survey examines current approaches to text anonymization for NLP preprocessing, focusing on pseudonymization and ontology-driven methods. The authors address the critical challenge of protecting personally identifiable information (PII) in training data for large language models, which can inadvertently leak private information. The study surveys three main pseudonymization approaches (NER-based, Seq2Seq, and LLM-based) and ontology-driven methods using knowledge graphs for PII masking. Key limitations identified include limited non-English corpora, costly annotation requirements, over-masking that reduces data utility, and lack of standardized evaluation metrics.

## Method Summary
The paper surveys three pseudonymization approaches: (1) NER-based detection using models like RoBERTa to identify entities, then replacing them with candidates from Wikidata knowledge graph; (2) Seq2Seq fine-tuning of BART on pseudonymized corpora for sequence-to-sequence anonymization; (3) LLM-based pipelines using GPT-3 for entity extraction and ChatGPT for contextual substitution. Ontology-driven approaches combine NER detection with Wikidata lookups to implement k-anonymity by replacing entities with generalizations. The survey synthesizes findings from existing literature without presenting original experimental results, focusing on the state of domain-agnostic methods.

## Key Results
- Three pseudonymization approaches (NER-based, Seq2Seq, LLM-based) show promise for domain-agnostic PII protection
- Ontology-driven methods using knowledge graphs can implement k-anonymity for privacy preservation
- Current approaches face significant limitations including limited multilingual support and costly annotation requirements
- Standard metrics (precision, recall, F-Score) are inadequate for privacy evaluation; new metrics are needed

## Why This Works (Mechanism)

### Mechanism 1: Ontology-Driven K-Anonymity
- **Claim:** Replacing PII with generalizations from a knowledge graph reduces re-identification risk while maintaining text structure
- **Mechanism:** Constructs an inverted index from knowledge graph (e.g., Wikidata); when sensitive entity detected, replaces with generalization satisfying k-anonymity
- **Core assumption:** Knowledge graph contains sufficient coverage for domain-agnostic entities, and replacement terms don't leak context
- **Evidence anchors:** [abstract] mentions ontology-driven approaches using knowledge graphs for PII masking; [section 2.2] describes using Wikidata KG and k-anonymity
- **Break condition:** Knowledge graph lacks entries for niche entities, leading to over-masking and utility loss

### Mechanism 2: Realistic Substitution (Pseudonymization)
- **Claim:** Substituting PII with realistic but fake alternatives preserves downstream NLP model utility better than generic redaction
- **Mechanism:** Replaces specific PII (e.g., "John") with realistic substitutes (e.g., "Mike") to retain linguistic properties
- **Core assumption:** Downstream tasks rely on semantic presence of entity rather than specific identity
- **Evidence anchors:** [abstract] highlights pseudonymization methods replacing PII with realistic substitutes; [section 2.1] contrasts masked vs pseudonymized text
- **Break condition:** Simple replacement logic allows frequency analysis to reverse mapping, or models overfit to specific substitutes

### Mechanism 3: LLM-Powered Sequence Replacement
- **Claim:** LLMs can generate privacy-preserving text augmentation or replacement
- **Mechanism:** Pipeline uses one model (e.g., GPT-3) to extract entities and another (e.g., ChatGPT) to generate contextually appropriate pseudonymized replacements
- **Core assumption:** LLM performing anonymization doesn't memorize and leak input PII it's supposed to mask
- **Evidence anchors:** [section 2.1] describes LLM-based pseudonymization using GPT-3 for extraction and ChatGPT for substitution
- **Break condition:** External API-based LLMs violate privacy goals when processing sensitive data

## Foundational Learning

- **Concept: PII (Personally Identifiable Information)**
  - **Why needed here:** Core objective is removal/masking of PII; understanding direct vs quasi-identifiers is required for masking logic
  - **Quick check question:** Can you identify the difference between a direct identifier and a quasi-identifier in: "Dr. Smith, a 45-year-old male from Paris, treated the patient"?

- **Concept: K-Anonymity**
  - **Why needed here:** Mathematical framework to verify anonymized dataset safety; ensures individuals cannot be distinguished from at least k-1 others
  - **Quick check question:** If dataset has 3 people named "John" in "Berlin", does it satisfy 3-anonymity for those entries?

- **Concept: Knowledge Graphs (e.g., Wikidata)**
  - **Why needed here:** Domain-agnostic approaches rely on external structured databases for replacement entities; understanding querying/traversal is critical
  - **Quick check question:** How would you query a knowledge graph to find replacement for "Microsoft" that preserves entity type "Organization"?

## Architecture Onboarding

- **Component map:** Input -> Detector (NER/LLM) -> Resolver (Wikidata/LLM-generator) -> Masker/Pseudonymizer -> Output
- **Critical path:** Accuracy of Detector (identifying spans) is bottleneck; if NER fails to flag sensitive entity, no downstream logic can save it
- **Design tradeoffs:**
  - Precision vs. Utility: Aggressive masking catches more PII but destroys utility; conservative masking preserves text but risks privacy leaks
  - Generic vs. Realistic Substitution: Generic tags ([NAME]) are safer but hurt training; realistic substitutes (Mike) help training but risk lookup errors
  - Local vs. API: Local models are slower but safer; API LLMs are easier but potentially violate data sovereignty
- **Failure signatures:**
  - Over-masking: Sentences become unreadable (e.g., "PERSON_1 went to LOC_1 and did MISC_1")
  - Context Loss: Replacing "Apple" (company) with "Apple" (fruit) due to poor entity linking
  - Re-identification: Unique quasi-identifier combinations allow identification even if names removed
- **First 3 experiments:**
  1. Baseline NER Evaluation: Run standard NER model on sample dataset to measure raw detection rate of PII entities
  2. Ontology Lookup Integration: Implement basic Wikidata lookup for detected entities to test coverage and speed
  3. Utility Stress Test: Train simple classifier on both "Masked" and "Pseudonymized" versions to quantify downstream utility loss

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can effective domain-agnostic text anonymization methods be developed for languages with tokenization schemes significantly different from English (e.g., German, Mandarin)?
- **Basis in paper:** [explicit] "However, many languages (e.g., German, Mandarin, etc.) have other tokenization schemes that significantly differ from English... Thus, more works are needed to be done in languages other than English."
- **Why unresolved:** All surveyed approaches were evaluated only on English datasets, leaving cross-linguistic generalization untested
- **What evidence would resolve it:** Evaluation of existing/new methods on non-English corpora with comparable privacy-utility trade-offs

### Open Question 2
- **Question:** How can automated "silver corpus" generation reduce annotation bottleneck for training anonymization models without sacrificing quality?
- **Basis in paper:** [explicit] "A major problem... is limited availability of annotated corpora. Annotation works for text anonymization are more costly and time-consuming than regular annotation works... Production of silver corpora with automated annotation can alleviate this problem."
- **Why unresolved:** While ontology-driven approaches have begun exploring automated corpus generation, paper notes "more works are needed," implying current methods are insufficient
- **What evidence would resolve it:** Comparative studies showing models trained on silver corpora achieve comparable performance to manually annotated ones

### Open Question 3
- **Question:** Would combining pseudonymization and ontology-driven approaches yield better privacy-utility trade-offs than either approach alone?
- **Basis in paper:** [explicit] "Also, it would be interesting to see how such multiple approaches can be combined, and is it better than the already discussed approaches."
- **Why unresolved:** Paper surveys approaches in isolation with no experimental comparison or hybrid methodology explored
- **What evidence would resolve it:** Empirical study benchmarking hybrid method against standalone approaches on standardized metrics

## Limitations
- Survey presents existing approaches without original experimental validation
- Missing implementation details for critical components (NER models, Wikidata queries, training parameters, LLM prompts)
- Evaluation framework relies on metrics acknowledged as inadequate for privacy assessment
- Limited coverage of non-English PII protection without quantitative analysis of multilingual performance gaps

## Confidence

- **High confidence:** Domain-agnostic text anonymization is a recognized challenge; knowledge graphs like Wikidata are commonly used for entity replacement
- **Medium confidence:** Pseudonymization with realistic substitutes preserves utility better than generic masking; k-anonymity provides mathematical privacy guarantees when properly implemented
- **Low confidence:** LLM-powered anonymization pipelines are practical for production use; current metrics adequately capture privacy-utility tradeoffs

## Next Checks

1. **Cross-domain generalization test:** Evaluate same NER-pseudonymization pipeline on three distinct domains (biographies, clinical notes, legal documents) using standard NER metrics and privacy leakage test

2. **Utility preservation benchmark:** Train identical downstream models (sentiment classification, named entity recognition) on both masked and pseudonymized versions of same dataset, measuring performance degradation

3. **Re-identification resistance analysis:** For small labeled dataset, attempt to re-identify individuals using combinations of quasi-identifiers after pseudonymization, comparing success rates against k-anonymity thresholds