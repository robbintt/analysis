---
ver: rpa2
title: 'CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning
  Capability of LLMs'
arxiv_id: '2508.11944'
source_url: https://arxiv.org/abs/2508.11944
tags:
- reasoning
- mechanism
- llms
- strategic
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CHBench, a novel framework to evaluate the
  strategic reasoning capability of LLMs using cognitive hierarchy models from behavioral
  economics. Unlike prior approaches relying on utility performance, which can be
  inconsistent due to opponent behavior and game structure, CHBench measures reasoning
  depth by modeling agents as performing iterative best responses at bounded cognitive
  levels.
---

# CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs

## Quick Facts
- arXiv ID: 2508.11944
- Source URL: https://arxiv.org/abs/2508.11944
- Reference count: 40
- Primary result: CHBench measures LLM strategic reasoning depth through cognitive hierarchy models, showing consistent reasoning levels across opponents

## Executive Summary
This paper introduces CHBench, a novel benchmark framework that evaluates the strategic reasoning capability of large language models using cognitive hierarchy models from behavioral economics. Unlike previous approaches that rely on utility performance (which can be inconsistent due to opponent behavior and game structure), CHBench measures reasoning depth by modeling agents as performing iterative best responses at bounded cognitive levels. The framework was tested across 15 normal-form games with six state-of-the-art LLMs, demonstrating that LLMs exhibit consistent strategic reasoning levels regardless of opponents.

The study reveals important insights about LLM architecture: the Chat Mechanism degrades reasoning ability while the Memory Mechanism enhances it. These findings make CHBench a promising tool for assessing strategic reasoning capabilities in LLMs, offering a more robust and reliable measurement approach compared to traditional utility-based evaluation methods.

## Method Summary
CHBench evaluates LLM strategic reasoning using cognitive hierarchy models, where agents are assumed to perform iterative best responses at bounded cognitive levels. The framework assesses reasoning depth by comparing an LLM's strategy to expected strategies at different cognitive hierarchy levels. Unlike utility-based approaches that can be inconsistent due to varying opponent behaviors and game structures, CHBench focuses on the reasoning process itself. The benchmark was tested across 15 normal-form games using six state-of-the-art LLMs, measuring how reasoning depth varies with different architectural components like Memory and Chat mechanisms.

## Key Results
- LLMs show consistent strategic reasoning levels regardless of opponent behavior
- Chat Mechanism degrades LLM reasoning ability
- Memory Mechanism enhances LLM reasoning performance
- CHBench provides robust measurement independent of game structure and opponents

## Why This Works (Mechanism)
The cognitive hierarchy model works by assuming agents perform iterative best responses up to a bounded cognitive level. Each level represents a deeper strategic thinking process, where level-k agents best-respond to level-(k-1) strategies. This creates a predictable pattern of behavior at each level that can be compared against LLM responses to determine their reasoning depth.

## Foundational Learning
1. Cognitive Hierarchy Theory - explains how humans make strategic decisions at different reasoning depths; needed to model bounded rationality in strategic games; quick check: can map observed strategies to specific cognitive levels
2. Iterative Best Response - describes how agents sequentially improve their strategies based on opponent behavior; needed to define cognitive hierarchy levels; quick check: each level should best-respond to previous level
3. Normal-form Games - represent simultaneous-move strategic interactions; needed as testbeds for reasoning evaluation; quick check: payoff matrix is complete and well-defined

## Architecture Onboarding
**Component Map:** Game Environment -> LLM Agent -> Strategy Selection -> Cognitive Level Assessment -> Performance Evaluation

**Critical Path:** Game selection → Strategy generation → Cognitive level mapping → Consistency verification → Mechanism effect analysis

**Design Tradeoffs:** Normal-form games vs. extensive-form games (simplicity vs. realism), single-turn vs. sequential reasoning (measurability vs. practical applicability), utility-based vs. reasoning-depth metrics (computational ease vs. psychological validity)

**Failure Signatures:** Inconsistent reasoning across similar games suggests model limitations; dependence on opponent behavior indicates non-robust evaluation; performance degradation with Chat mechanism suggests architectural constraints

**First Experiments:**
1. Test CHBench with simple 2x2 games to verify basic functionality
2. Compare reasoning depth across different LLM sizes
3. Evaluate consistency of cognitive level assessment across multiple runs

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to normal-form games, missing sequential and repeated game scenarios
- Assumes human cognitive hierarchy patterns directly apply to LLM reasoning
- Focuses on single-turn decisions without evaluating multi-stage strategic thinking
- Does not account for learning or adaptation across multiple game iterations

## Confidence
- CHBench's robustness and ability to measure reasoning depth: High
- Memory and Chat mechanisms' differential effects: Medium
- Superiority over utility-based approaches: Medium

## Next Checks
1. Test CHBench across broader game types including extensive-form and repeated games
2. Conduct ablation studies isolating Memory and Chat mechanism effects
3. Compare CHBench results with alternative strategic reasoning assessment methods