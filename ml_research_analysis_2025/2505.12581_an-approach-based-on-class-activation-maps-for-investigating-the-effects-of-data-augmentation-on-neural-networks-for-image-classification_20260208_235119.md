---
ver: rpa2
title: An approach based on class activation maps for investigating the effects of
  data augmentation on neural networks for image classification
arxiv_id: '2505.12581'
source_url: https://arxiv.org/abs/2505.12581
tags:
- augmentation
- image
- data
- figure
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a methodology to quantitatively analyze the
  impact of data augmentation on neural network models using Class Activation Maps
  (CAMs). The approach compares CAMs generated by baseline and augmented models across
  a test dataset, employing metrics such as Mean Absolute Difference, Pearson/Spearman
  Correlation, and Overlap Rate.
---

# An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification

## Quick Facts
- arXiv ID: 2505.12581
- Source URL: https://arxiv.org/abs/2505.12581
- Reference count: 36
- Primary result: Methodology using CAM comparison metrics reveals behavioral clusters among augmentation techniques while maintaining classification accuracy

## Executive Summary
This paper proposes a quantitative methodology to analyze how data augmentation techniques affect neural network attention patterns using Class Activation Maps (CAMs). The approach compares CAMs from baseline and augmented models across a test dataset using metrics like Mean Absolute Difference, Pearson/Spearman Correlation, and Overlap Rate. Experiments with EfficientNet B0 on CIFAR-10 and seven augmentation techniques reveal that augmented models show moderate CAM divergence from the baseline, with differences becoming more pronounced in high-importance regions. The methodology enables interpretable, scalable analysis of augmentation effects without manual supervision.

## Method Summary
The methodology trains a baseline EfficientNet B0 on CIFAR-10, then trains augmented variants with seven different augmentation techniques (Affine Transform, Cutmix, Color Jitter, Elastic Transform, Equalization, Gaussian Blur, Random Cropping). For each augmented model, Grad-CAM generates per-pixel importance maps from the final convolutional layer. The approach computes similarity metrics between baseline and augmented CAMs across the test set, including Mean Absolute Difference, Pearson/Spearson correlation, and Overlap Rate at different thresholds. Inter-augmentation correlation analysis identifies behavioral clusters among techniques, while Class-KLD measures divergence in classification probability distributions.

## Key Results
- Augmented models show moderate CAM divergence from baseline, with Overlap Rate decreasing from ~0.96 (Y=20) to ~0.78 (Y=5)
- Correlation analysis reveals behavioral clusters: Cutmix, Affine Transform, and Color Jitter group together, while Gaussian Blur and Elastic Transform form another cluster
- Gaussian Blur-Cutmix shows the weakest correlations (8/8 times in bottom-4), suggesting distinct behavioral profiles
- Class-KLD values mostly fall within 0-1 range, indicating classification layers can compensate for convolutional feature differences
- Performance metrics confirm consistent classification accuracy across all augmentations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Comparing CAMs between baseline and augmented models provides a scalable, quantitative proxy for measuring how data augmentation alters learned attention patterns.
- **Mechanism:** Grad-CAM generates per-pixel importance maps from the final convolutional layer. By computing similarity metrics (MAD, Pearson/Spearman correlation, Overlap Rate) between baseline and augmented CAMs across a test set, the methodology aggregates behavioral divergence without manual annotation.
- **Core assumption:** CAM differences primarily reflect changes in learned representations due to augmentation, not random training variance or architectural artifacts.
- **Evidence anchors:**
  - [abstract] "The approach compares CAMs generated by baseline and augmented models across a test dataset, employing metrics such as Mean Absolute Difference, Pearson/Spearman Correlation, and Overlap Rate."
  - [Section 5.2.2] Overlap rate decreases as threshold tightens (Y=20 to Y=5), indicating augmented models focus on different high-importance regions than baseline.
  - [corpus] Limited direct precedent; related work (Tang et al., 2020) used similar CAM comparison on MNIST with fewer metrics.

### Mechanism 2
- **Claim:** Inter-augmentation correlation of CAM metrics can reveal behavioral clusters among augmentation techniques.
- **Mechanism:** For each metric (e.g., Overlap Rate, MAD), the methodology computes correlation coefficients across augmentations over the test set. High correlation suggests augmentations induce similar attention changes; low correlation suggests distinct behavioral profiles.
- **Core assumption:** Consistent correlation patterns across multiple metrics indicate underlying similarity in how augmentations affect model attention, not metric-specific artifacts.
- **Evidence anchors:**
  - [Section 5.2.6, Table 1] Cutmix-Affine Transform and Color Jitter-Affine Transform appear in top-4 strongest correlations for 6/8 metrics; Gaussian Blur-Elastic Transform appears 7/8 times.
  - [Section 5.2.6, Table 2] Gaussian Blur-Cutmix appears in bottom-4 weakest correlations 8/8 times, suggesting distinct profiles.
  - [corpus] No corpus paper validates this clustering approach; it appears methodologically novel.

### Mechanism 3
- **Claim:** Classification layers can compensate for convolutional feature map differences, producing similar output distributions despite CAM divergence.
- **Mechanism:** Class-KLD measures divergence between class probability distributions from baseline vs. augmented models. Low Class-KLD values (mostly 0-1 range) alongside moderate CAM differences suggest later layers can map divergent convolutional features to similar classification probabilities.
- **Core assumption:** Class-KLD primarily captures decision-layer behavior, while CAM metrics capture earlier representational differences.
- **Evidence anchors:**
  - [Section 5.2.5] "Most of the values for all augmentations tend to fall within the 0 to 1 range" for Class-KLD.
  - [Section 5.2.5] High correlation in Class-KLD across augmentations suggests classification layers behave similarly despite CAM differences.

## Foundational Learning

- **Concept: Class Activation Maps (CAMs) and Grad-CAM**
  - **Why needed here:** The entire methodology depends on CAMs as the representation of model attention. Without understanding that Grad-CAM uses gradients flowing into the final convolutional layer to produce coarse localization maps, the metrics and analysis are uninterpretable.
  - **Quick check question:** Given a CNN and an input image, can you explain what a high activation value in a CAM region means for the model's classification decision?

- **Concept: Data Augmentation as Regularization**
  - **Why needed here:** The paper assumes augmentation alters learned patterns to improve robustness. Understanding that augmentation introduces variability to prevent overfitting and improve generalization is essential for interpreting why CAMs might diverge from baseline.
  - **Quick check question:** Why might random cropping cause a model to attend to different image regions compared to a baseline trained on original images?

- **Concept: Similarity Metrics for Distribution Comparison**
  - **Why needed here:** The methodology relies on interpreting MAD, Pearson/Spearman correlation, and Overlap Rate to quantify CAM differences. Each metric captures a different aspect of similarity (magnitude, linear relationship, monotonic relationship, spatial overlap).
  - **Quick check question:** If two CAMs have high Pearson correlation but low Overlap Rate (Y=5), what might this indicate about how the models differ in their attention patterns?

## Architecture Onboarding

- **Component map:** EfficientNet B0 training -> CAM generation (Grad-CAM) -> Metric computation (MAD, MSD, Pearson, Spearman, Overlap Rate, Class-KLD) -> Aggregation across seeds -> Inter-augmentation correlation analysis

- **Critical path:**
  1. Ensure deterministic training (seed control, shuffle off, controlled batch ordering as described in Appendix B)
  2. Generate CAMs consistently (same target layer, predicted class as target)
  3. Compute metrics pairwise (baseline vs. each augmented model)
  4. Aggregate across seeds before inter-augmentation analysis

- **Design tradeoffs:**
  - **Predicted class vs. ground truth as CAM target:** Predicted class reflects actual model behavior but introduces asymmetry when models disagree; ground truth ensures consistent targets but may not reflect learned patterns. Paper chose predicted class to analyze "behavioral patterns ultimately learned."
  - **Metric selection:** MAD/MSD capture magnitude; Pearson/Spearman capture relationship structure; Overlap Rate captures spatial precision. No single metric suffices.
  - **Correlation vs. absolute thresholds:** Absolute correlation values show limited variation (e.g., MAD correlations range 0.58-0.67), requiring relative comparison (frequency counting) to identify clusters.

- **Failure signatures:**
  - **High variance across seeds:** If metrics vary wildly across the 3 seeds, augmentation effects may be confounded by initialization randomness.
  - **Uniform metric distributions:** If all augmentations show identical boxplots, metrics may be insufficiently sensitive.
  - **Correlation matrices with all values near 1.0 or 0.0:** Suggests metrics are not discriminative or augmentations are functionally equivalent.

- **First 3 experiments:**
  1. **Reproduce baseline vs. single augmentation:** Train baseline EfficientNet B0 on CIFAR-10, train augmented model with Cutmix (3 seeds), generate CAMs, compute MAD and Overlap Rate (Y=10). Verify distributions match paper's Figure 28 and Figure 20.
  2. **Correlation cluster validation:** Compute full inter-augmentation correlation matrices for Overlap Rate (Y=5) and Pearson. Check if Cutmix-Affine-ColorJitter cluster and Gaussian-Elastic cluster emerge as in Tables 1-2.
  3. **Ablation on CAM target:** For one augmentation, generate CAMs using ground truth labels instead of predicted labels. Compare metric distributions to assess sensitivity to target selection.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the simultaneous application of multiple data augmentation techniques influence the behavioral clusters and CAM divergence profiles compared to individual application?
- **Basis in paper:** [explicit] The Conclusion states future work should "investigate the impact of applying multiple data augmentation techniques used in conjunction instead of individually."
- **Why unresolved:** The current experimental design isolated seven techniques to evaluate their specific impacts independently, leaving the combinatorial effects unexplored.
- **What evidence would resolve it:** Experiments combining augmentation techniques (e.g., Affine + Color Jitter) showing whether the observed correlation clusters (Cutmix-group vs. Gaussian-group) merge, shift, or disappear in the metric space.

### Open Question 2
- **Question:** To what extent do the identified "impact profiles" generalize to datasets with ground truth importance annotations?
- **Basis in paper:** [explicit] The authors suggest using "datasets that have some ground truth for important image regions, allowing the analysis of differences between CAMs and ground truth."
- **Why unresolved:** The study relied on CIFAR-10, which lacks ground truth region annotations, preventing the validation of whether augmentation improves alignment with semantic reality or merely alters internal representations.
- **What evidence would resolve it:** Application of the methodology to datasets like COCO or Pascal VOC to correlate the CAM divergence metrics against segmentation masks.

### Open Question 3
- **Question:** Can alternative similarity metrics capture fine-grained structural differences in CAMs that the current metric set failed to isolate?
- **Basis in paper:** [inferred] In Section 5.2.6, the authors admit the chosen metrics "struggled to investigate the effects of data augmentation on an individual level" and may not "fully capture some significant aspect of the differences."
- **Why unresolved:** The selected metrics (MAD, Pearson, etc.) showed high correlation across different augmentations, making it difficult to distinguish distinct behavioral profiles for individual methods.
- **What evidence would resolve it:** Identification or development of metrics sensitive to spatial texture or distribution shifts in CAMs that yield statistically distinct separation for each augmentation method.

## Limitations
- The methodology cannot distinguish whether CAM divergence reflects meaningful representation changes or decision-layer artifacts, as classification layers can compensate for convolutional differences
- The inter-augmentation correlation analysis is novel but lacks external validation, raising concerns about metric-specific artifacts driving cluster patterns
- Without ground truth importance annotations, the study cannot validate whether augmentation improves semantic alignment or merely alters internal representations

## Confidence
- **High confidence:** Baseline CAM comparison methodology (MAD, Pearson/Spearman, Overlap Rate) - well-established metrics with clear interpretation
- **Medium confidence:** Inter-augmentation correlation clustering - novel approach with some supporting evidence but no external validation
- **Low confidence:** Interpretation that CAM divergence reflects learned representation changes rather than decision-layer artifacts - correlation with task performance not established

## Next Checks
1. For each augmentation, compute correlation between CAM divergence metrics and actual classification performance differences on a held-out validation set
2. Ablate Grad-CAM target selection by generating maps using ground truth labels instead of predicted labels, then compare metric distributions
3. Train a simple classifier to distinguish baseline vs. augmented CAMs; evaluate whether classification accuracy correlates with CAM divergence metrics to validate sensitivity