---
ver: rpa2
title: 'Tell, Don''t Show: Leveraging Language Models'' Abstractive Retellings to
  Model Literary Themes'
arxiv_id: '2505.23166'
source_url: https://arxiv.org/abs/2505.23166
tags:
- topic
- topics
- passages
- passage
- race
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Retell, a method for improving topic modeling
  of literary texts by leveraging language models to perform abstractive retellings.
  Unlike conventional bag-of-words approaches that struggle with literature's "show,
  don't tell" narrative style, Retell prompts LMs to translate low-level sensory details
  into higher-level concepts and themes.
---

# Tell, Don't Show: Leveraging Language Models' Abstractive Retellings to Model Literary Themes

## Quick Facts
- **arXiv ID:** 2505.23166
- **Source URL:** https://arxiv.org/abs/2505.23166
- **Reference count:** 40
- **Primary result:** Retell improves topic modeling of literary texts by using LMs to translate narrative "showing" into abstract "telling" before LDA clustering.

## Executive Summary
This paper addresses the challenge of topic modeling for literary texts, where narrative style encodes themes through sensory details rather than explicit concepts. The authors introduce Retell, a method that prompts language models to generate abstractive retellings of passages, converting implicit themes into explicit conceptual language. By running LDA on these retellings rather than original text, Retell produces more precise and informative topics than traditional LDA or direct topic elicitation from LMs. The method shows higher precision in linking passages with shared themes and better semantic relatedness to ground truth labels, with a case study demonstrating its potential for cultural analytics in identifying racial/cultural identity themes in high school ELA books.

## Method Summary
Retell transforms literary passages into abstractive retellings using language models, then applies LDA topic modeling to these retellings. The process involves segmenting books into passages (≤250 whitespace tokens), prompting instruction-tuned LMs to describe, summarize, or paraphrase each passage, cleaning the retellings by removing short words, frequent words, rare words, and character names, and finally running Mallet LDA (k=50) on the processed retellings. Each passage receives a probability distribution across all topics, with the LM retelling step being the key innovation that translates low-level narrative details into higher-level conceptual language suitable for statistical clustering.

## Key Results
- Retell-summarize and Retell-describe outperform Retell-paraphrase (precision 0.60 vs 0.50) in linking passages with shared themes
- Retell's topics show higher semantic relatedness to ground truth labels than TopicGPT-lite's direct topic generation
- Case study successfully identified passages and themes related to racial/cultural identity in high school ELA books, aligning with expert annotations
- Two-stage processing (LM abstraction + LDA) outperforms direct LM topic generation for smaller models (2B-8B parameters)

## Why This Works (Mechanism)

### Mechanism 1
Converting narrative "showing" into expository "telling" improves topic discovery in literary texts. Literary texts encode themes through sensory details, actions, and dialogue rather than explicit concept labels. By prompting LMs to generate abstractive retellings, the method translates low-level surface forms into higher-level conceptual language. LDA then operates on transformed text where topic words appear more explicitly and consistently across documents sharing the same theme. Core assumption: LMs can reliably infer and articulate implicit themes from narrative passages.

### Mechanism 2
Two-stage processing (LM abstraction + LDA clustering) outperforms direct LM topic generation for smaller models (2B-8B parameters). Smaller LMs struggle with structured output requirements of direct topic labeling, producing overly broad or fragmented labels. Retell decouples the task: LMs handle the easier summarization task, while LDA provides consistent statistical clustering with adjustable granularity (k). Core assumption: Summarization is an easier task for smaller LMs than structured topic label generation.

### Mechanism 3
Abstractive verbs ("describe," "summarize") outperform surface-level transformations ("paraphrase") for downstream topic quality. Prompt verbs influence abstraction level in LM outputs. Verbs encouraging abstraction produce retellings where conceptual language predominates, making thematic patterns more detectable by LDA. Paraphrasing preserves more surface-level detail, reducing this benefit. Core assumption: Different prompt verbs produce materially different abstraction levels in LM outputs.

## Foundational Learning

**Concept:** Latent Dirichlet Allocation (LDA)
- Why needed here: Retell uses LDA as the clustering engine; understanding its bag-of-words assumption and topic-document distributions is essential.
- Quick check question: Can you explain why removing character names and frequent words is important before running LDA?

**Concept:** "Show, Don't Tell" narrative convention
- Why needed here: The paper's core thesis is that this literary principle breaks traditional topic modeling; understanding the problem frames the solution.
- Quick check question: Give an example of how a theme like "isolation" might be "shown" rather than "told" in a narrative passage.

**Concept:** Prompt engineering for abstraction level control
- Why needed here: The choice of verb directly affects output quality; practical implementation requires understanding this sensitivity.
- Quick check question: If a particular model's "paraphrase" outputs look like summaries, how would you diagnose and adjust?

## Architecture Onboarding

**Component map:** Passage segmentation → LM retelling (describe/summarize) → Text cleaning → LDA → Topic inference

**Critical path:** Passage segmentation → LM retelling (describe/summarize) → Text cleaning → LDA → Topic inference. The LM retelling step is the key innovation; failures cascade.

**Design tradeoffs:**
- Verb choice: summarize/describe (higher abstraction) vs. paraphrase (lower abstraction, worse performance generally)
- k selection: Retell allows easy k adjustment without re-running LM; TopicGPT-lite requires re-prompting
- Model size: Smaller models favor Retell; larger models may perform adequately with direct topic generation

**Failure signatures:**
- Topic bleeding: Single book dominating a topic (addressed by removing titles, author names, character names)
- Hallucinated context: LM introduces knowledge from pretraining data not in passage (observed in case study false positives)
- Inconsistent abstraction: Some passages get detailed summaries, others get abstract descriptions, creating uneven LDA inputs
- Overly broad topics: If LM retellings lose too much detail, LDA clusters everything under generic themes

**First 3 experiments:**
1. **Verb ablation:** Run Retell with describe, summarize, paraphrase on 100+ held-out passages; compare topic coherence metrics and human ratings of top-3 topics per passage.
2. **k sensitivity analysis:** Fix LM and verb; run LDA with k ∈ {25, 50, 100, 200}; measure precision/recall against gold labels and topic stability across runs.
3. **Cross-domain validation:** Apply Retell to a corpus where "show, don't tell" is less prevalent (e.g., news, academic papers); compare against default LDA to test whether the benefit is specific to literary narrative.

## Open Questions the Paper Calls Out

**Open Question 1:** How does Retell perform with larger, more capable language models compared to resource-efficient (2B-8B) models?
- Basis: Focus on resource-efficient models leaves open performance with larger LMs
- Why unresolved: Preliminary GPT-4o experiments suggest TopicGPT-lite improves with stronger LMs, but systematic comparison not conducted
- What evidence would resolve it: Controlled experiments comparing Retell vs. TopicGPT-lite across model scales on identical literary passages and evaluation metrics

**Open Question 2:** What factors govern LMs' content selection behavior when retelling literary passages, and how does this affect downstream topic quality?
- Basis: Observations point toward need for research characterizing LMs' content selection behavior
- Why unresolved: False negatives occurred when retellings failed to recap racially significant content; false positives sometimes included book context absent from passage
- What evidence would resolve it: Annotation studies of what content LMs retain vs. omit during retelling, correlated with topic model precision/recall on specific themes

**Open Question 3:** Can computational methods reliably identify implicit (rather than explicit) thematic references in literary texts?
- Basis: Though race can be implicitly referenced, defining scope of implicit cues is worthy of more in-depth study
- Why unresolved: Case study only annotated explicit mentions of race/culture; implicit cues excluded as too difficult to operationalize
- What evidence would resolve it: Development of validated annotation schemes for implicit thematic cues, followed by evaluation of whether Retell captures these without explicit prompting

**Open Question 4:** How do pretraining memorization effects shape LM retellings of literary passages, and how can passage-level analysis be isolated from book-level knowledge?
- Basis: Challenges around drawing consistent divide between implicit/explicit and passage-level/book-level when using LMs for literary text analysis
- Why unresolved: Some false positives arose because LMs accurately referenced character backgrounds (e.g., Iranian identity) not mentioned in passage, suggesting memorization of training data
- What evidence would resolve it: Experiments comparing retellings of passages from memorized vs. unseen books, or using models with known training corpus boundaries

## Limitations

- Retell's performance depends heavily on LM quality and consistency; hallucinations or inconsistent abstraction can degrade topic quality
- The method may introduce systematic bias when LMs accurately reference character backgrounds not mentioned in passages, confusing passage-level and book-level analysis
- Evaluation relies on human ratings and topic intruder tests, which may not fully capture whether discovered topics align with actual literary themes rather than superficial patterns

## Confidence

**High Confidence:** Literary texts encode themes through sensory details rather than explicit concepts; Retell outperforms baseline LDA on topic coherence metrics
**Medium Confidence:** Abstractive verbs outperform surface-level transformations for downstream topic quality; effect size and generalizability across LMs/genres unclear
**Low Confidence:** Retell's topics are more semantically related to ground truth labels than TopicGPT-lite's; human rating method introduces subjectivity and potential rater bias

## Next Checks

1. **Cross-corpus Validation:** Apply Retell to a non-literary corpus (e.g., news articles, academic papers) where "show, don't tell" is less prevalent. Compare Retell's performance against standard LDA to determine if the benefit is specific to literary narrative or a general property of the two-stage LM+LDA approach.

2. **Hallucination Audit:** Conduct a systematic analysis of LM retellings for hallucinated content. For a sample of passages, compare the retelling to the original text and identify instances where the LM introduces details not present in the source. Measure the frequency and impact of such hallucinations on topic coherence.

3. **Human-in-the-Loop Refinement:** Implement a lightweight human review step where annotators can flag and correct hallucinated or irrelevant content in retellings before LDA processing. Evaluate whether this refinement improves topic quality and reduces false positives in downstream applications like cultural analytics.