---
ver: rpa2
title: 'Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization'
arxiv_id: '2505.21423'
source_url: https://arxiv.org/abs/2505.21423
tags:
- loss
- sharpness
- norm
- learning
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work investigates the interaction between two forms of implicit
  regularization in deep learning: the norm-minimizing bias induced by gradient flow
  and the sharpness-minimizing bias induced by large learning rates in the Edge-of-Stability
  (EoS) regime. The authors demonstrate that learning rate acts as a hyperparameter
  balancing these biases, with different regimes emerging: a flow-aligned regime for
  small learning rates where both norm and sharpness remain stable, and an EoS regime
  for larger learning rates where norm increases and sharpness decreases hyperbolically.'
---

# Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization

## Quick Facts
- arXiv ID: 2505.21423
- Source URL: https://arxiv.org/abs/2505.21423
- Reference count: 40
- Primary result: Learning rate acts as a hyperparameter balancing norm-minimizing and sharpness-minimizing implicit biases, with good generalization occurring at intermediate rates where both biases are balanced.

## Executive Summary
This work investigates the interaction between two forms of implicit regularization in deep learning: the norm-minimizing bias induced by gradient flow and the sharpness-minimizing bias induced by large learning rates in the Edge-of-Stability (EoS) regime. The authors demonstrate that learning rate acts as a hyperparameter balancing these biases, with different regimes emerging: a flow-aligned regime for small learning rates where both norm and sharpness remain stable, and an EoS regime for larger learning rates where norm increases and sharpness decreases hyperbolically. Across diverse experimental settings, they observe that low generalization error does not align with either extreme of the learning rate spectrum and never aligns with minimal norm, with test error often following a U-shaped curve at intermediate learning rates where both biases are balanced.

## Method Summary
The authors conduct extensive experiments across various architectures (ResNets, MLPs) and datasets to study the relationship between learning rate, implicit regularization biases (norm minimization vs sharpness minimization), and generalization. They analyze the Edge-of-Stability regime where learning rates are large enough to induce oscillatory behavior but still maintain convergence. The experimental setup systematically varies learning rates to map out different regimes of behavior. A theoretical analysis of diagonal linear networks is provided to complement the empirical findings, showing that neither norm nor sharpness minimizers on the solution manifold minimize generalization error.

## Key Results
- Learning rate acts as a hyperparameter balancing norm-minimizing and sharpness-minimizing implicit biases
- EoS regime (large learning rates) exhibits hyperbolic decrease in sharpness and increase in norm
- Test error follows a U-shaped curve at intermediate learning rates where both biases are balanced
- Good generalization does not align with minimal norm solutions

## Why This Works (Mechanism)
The mechanism centers on how gradient descent with different learning rates implicitly regularizes model parameters through two competing forces: norm minimization (which favors smaller parameter magnitudes) and sharpness minimization (which favors flatter minima in loss landscape). At small learning rates, the optimization process closely follows gradient flow dynamics, leading to norm minimization. At large learning rates in the EoS regime, the optimization dynamics shift to favor flatter minima through oscillatory behavior around the loss landscape. The learning rate thus acts as a control parameter that determines which implicit bias dominates, with optimal generalization occurring when these biases are appropriately balanced.

## Foundational Learning
- Gradient flow dynamics: Understanding how optimization behaves as learning rate approaches zero is crucial for characterizing the norm-minimizing regime. Quick check: Verify that small learning rate behavior matches gradient flow predictions.
- Loss landscape geometry: Sharpness measures the sensitivity of loss to parameter perturbations, requiring understanding of Hessian-based curvature measures. Quick check: Confirm sharpness calculations using spectral norm of Hessian.
- Implicit regularization: Recognizing that optimization algorithms induce regularization beyond explicit penalty terms is fundamental to understanding why norm and sharpness behave differently across learning rates. Quick check: Compare explicit norm regularization effects with implicit norm minimization.

## Architecture Onboarding

### Component Map
Input -> Model Architecture (ResNet/MLP) -> Loss Function -> Optimizer (SGD/Adam) -> Parameter Updates -> Monitor: Norm, Sharpness, Test Error

### Critical Path
1. Model initialization
2. Training with varying learning rates
3. Monitoring norm and sharpness evolution
4. Measuring test error
5. Identifying EoS regime characteristics

### Design Tradeoffs
- Learning rate selection: Small rates favor norm minimization but may underfit; large rates enable sharpness minimization but risk instability
- Architecture choice: Deeper networks may exhibit different implicit bias interactions than shallow ones
- Dataset complexity: More complex datasets might require different learning rate balances for optimal generalization

### Failure Signatures
- Divergence at excessively large learning rates
- Premature convergence to poor minima at very small learning rates
- Inconsistent norm/sharpness trends across different random seeds
- Failure to enter EoS regime despite using theoretically large learning rates

### First Experiments
1. Train a simple MLP on MNIST with learning rates spanning 5 orders of magnitude, monitoring norm and sharpness
2. Implement the diagonal linear network theoretical model and verify analytical predictions about norm/sharpness-generalization relationships
3. Compare ResNet-18 vs ResNet-50 on CIFAR-10 to test if architecture depth affects the norm-sharpness tradeoff

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to image classification tasks, limiting generalizability to other domains
- Theoretical analysis restricted to diagonal linear networks, which may not capture deep nonlinear model complexity
- Lacks rigorous theoretical framework explaining why U-shaped test error curve emerges at intermediate learning rates

## Confidence
- Claims about EoS regime inducing norm increase and sharpness decrease: High confidence (extensive experimental support)
- Claims about good generalization requiring balancing norm and sharpness biases: Medium confidence (strong empirical evidence but limited theoretical justification)
- Claims that minimal norm solutions do not generalize well: Medium confidence (supported by experiments but mechanisms unclear)

## Next Checks
1. Extend experiments to non-image domains (NLP, tabular data) to test universality of observed phenomena
2. Develop theoretical models predicting location of U-shaped minimum in test error as function of problem characteristics and architecture properties
3. Investigate whether alternative sharpness metrics (beyond spectral norm) lead to similar observations about norm-sharpness tradeoff and generalization relationship