---
ver: rpa2
title: 'PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal
  Agents'
arxiv_id: '2602.00415'
source_url: https://arxiv.org/abs/2602.00415
tags:
- image
- memory
- polarmem
- visual
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PolarMem introduces a training-free inference-time intervention
  to mitigate hallucinations in multimodal agents by converting probabilistic visual
  perception into verifiable logical constraints. It employs ensemble semantic consistency
  verification and adaptive distributional partitioning to categorize visual concepts
  into HAS, NOT HAS, and uncertain states, explicitly encoding negative knowledge
  as orthogonal inhibitory edges in a polarized graph topology.
---

# PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents

## Quick Facts
- **arXiv ID:** 2602.00415
- **Source URL:** https://arxiv.org/abs/2602.00415
- **Reference count:** 40
- **Primary result:** Introduces training-free inference-time intervention converting visual perceptions into verifiable logical constraints with negative knowledge encoding, improving MRAG tasks (e.g., +17.5% on LLaVA-Next-Mistral-7B) and hallucination robustness across six benchmarks.

## Executive Summary
PolarMem addresses hallucinations in multimodal agents by transforming probabilistic visual perception into discrete logical constraints through non-parametric distributional partitioning and orthogonal inhibitory edges. The system employs ensemble semantic consistency verification and adaptive thresholding to categorize visual concepts into HAS, NOT HAS, and uncertain states, explicitly encoding negative knowledge as hard constraints in a polarized graph topology. Retrieval is reformulated as a lexicographical logic-dominant process, enforcing logical consistency before semantic similarity to suppress hallucinatory patterns. Evaluated across six benchmarks with eight frozen VLM backbones, PolarMem significantly improves retrieval-augmented tasks and establishes a foundation for verifiable multimodal reasoning.

## Method Summary
PolarMem converts visual perception into verifiable logical constraints through three core mechanisms: (1) Adaptive Distributional Partitioning using Otsu's method to dynamically separate confident visual concepts from noise based on ensemble confidence scores, creating HAS, NOT HAS, and uncertain categories; (2) Orthogonal Inhibitory Constraints that explicitly encode negative knowledge as "NOT HAS" edges in a polarized graph topology, distinguishing confirmed absence from implicit inferences; and (3) Lexicographical Logic-Dominant Retrieval that reformulates candidate ranking as a prerequisite relationship where logical validity must be satisfied before semantic similarity is considered. The system operates without training, using frozen VLM backbones to extract logical constraints and enforce verifiable reasoning during inference.

## Key Results
- Achieves +17.5% improvement on MRAG tasks using LLaVA-Next-Mistral-7B
- Extracts up to 141 HAS and 108 NOT HAS edges per image in complex scenarios
- Demonstrates consistent performance gains particularly for smaller and mid-size models
- Shows peak accuracy of 71.6 with F1 of 0.2450 in the "Full" configuration

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Distributional Partitioning
PolarMem mitigates hallucinations by converting continuous perceptual probabilities into discrete logical states using image-specific thresholds via Otsu's method, rather than fixed heuristics. This creates a buffer zone for ambiguous concepts by maximizing inter-class variance to find optimal separation between presence and absence clusters.

### Mechanism 2: Orthogonal Inhibitory Constraints
The system explicitly encodes negative knowledge as "NOT HAS" edges in a polarized graph, creating verifiable constraints that prevent retrieval of semantically similar but factually contradictory evidence. These inhibitory edges act as hard logical constraints distinct from low semantic similarity.

### Mechanism 3: Lexicographical Logic-Dominant Retrieval
Retrieval is reformulated as a lexicographical sort (Logic Score > Semantic Similarity) that suppresses hallucinations by strictly filtering out context violating logical constraints regardless of semantic relevance. Candidates are assigned logic scores (-1 for conflict, 0 for neutral, +1 for verified) and sorted accordingly.

## Foundational Learning

- **Otsu's Method (Thresholding):** Needed to dynamically separate confident visual concepts from noise without manual tuning. Quick check: How does maximizing inter-class variance differ from using a fixed confidence threshold (e.g., 0.5)?
- **Positive-Only Bias in Dense Retrieval:** Needed to understand why vector databases fail to encode absence of features. Quick check: Why does high cosine similarity between query and memory not guarantee factual consistency?
- **Epistemic Uncertainty vs. Aleatoric Uncertainty:** Needed to manage model ignorance by preserving ambiguous candidates rather than forcing logical labels. Quick check: What happens to the uncertainty margin δ if the model is highly confident vs. equivocal?

## Architecture Onboarding

- **Component map:** Logic Constructor -> Polarized Graph Memory -> Retriever
- **Critical path:** The Logic Construction Phase (Section 3.2) is critical as the entire system depends on quality of extracted logical constraints. Miscalibrated thresholding mechanism will compromise the graph.
- **Design tradeoffs:** Precision vs. Recall tradeoff in "Full" configuration prioritizing epistemic correctness; Model Scale effects where stronger models may suffer diminishing returns or noise introduction.
- **Failure signatures:** Unimodal confidence distributions causing degenerate partitioning; positivity bias yielding near-zero NOT HAS edges; context noise interfering with parametric reasoning in strong models.
- **First 3 experiments:** 1) Backbone Sensitivity Check: Run Logic Constructor on sample set, plot confidence histograms, verify bimodal distributions and NOT HAS edge counts; 2) Threshold Ablation: Compare fixed vs. adaptive thresholding on hallucination benchmark to measure error reduction; 3) Logic-Dominant Retrieval Stress Test: Construct adversarial queries where semantically closest result is logically incorrect, verify suppression of top-semantic result.

## Open Questions the Paper Calls Out

### Open Question 1
What architectural or training factors determine a VLM backbone's capacity to extract negative constraints (NOT HAS edges), and can this capacity be improved without fine-tuning? The paper notes significant disparity where LLaVA-Next-Mistral identifies thousands of negative constraints while LLaVA-Next-Llama3-8B extracts almost zero, but does not investigate underlying causes.

### Open Question 2
How can PolarMem adapt to prevent performance degradation in strong, large-scale models where retrieved context introduces more noise than logical value? The system drops performance on MMMU for Qwen-32B (68.4 → 66.5), suggesting imperfect retrieval can still introduce context noise that interferes with parametric reasoning.

### Open Question 3
Can the lexicographical ranking protocol be modified to recover recall lost by conservative "Full" configuration while maintaining high precision? The "Full" model achieves peak accuracy (71.6) but lower F1 (0.2450) compared to "Pos. Only" (0.2511), trading a small amount of recall for substantially higher reliability.

## Limitations
- Effectiveness critically depends on confidence score distributions being separable; flat or unimodal distributions would render partitioning ineffective
- Performance highly sensitive to underlying VLM's ability to generate negative constraints; positivity-biased models eliminate core inhibitory mechanism
- Several implementation details underspecified including exact ensemble prompt templates, κ scaling factor, and query parsing mechanism

## Confidence

- **High Confidence:** Lexicographical sorting (logic before semantics) to suppress hallucinatory retrievals is well-founded and directly supported by ablation studies
- **Medium Confidence:** General framework of converting probabilistic perceptions to discrete logical states through distributional partitioning is sound but robustness across diverse image distributions is uncertain
- **Medium Confidence:** Concept of orthogonal inhibitory edges as verifiable constraint system is novel and promising but effectiveness bottlenecked by VLM's ability to generate negative constraints
- **Low Confidence:** Specific performance gains reported are contingent on correctly implementing underspecified components and may not be reproducible without those details

## Next Checks

1. **Distribution Analysis:** For your intended VLM backbone, analyze confidence score distributions for diverse images to verify bimodal/multi-modal patterns with sufficient variance to support Otsu's method
2. **Negativity Bias Test:** Run Logic Constructor on sample set and log C_neg vs C_pos cardinality; if model consistently generates near-zero negative constraints, polarized graph will lack inhibitory edges
3. **Logic-Dominant Retrieval Stress Test:** Construct adversarial queries where semantically closest memory is logically incorrect; verify lexicographical sort successfully suppresses top-semantic result in favor of logically consistent result