---
ver: rpa2
title: Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry
arxiv_id: '2510.09740'
source_url: https://arxiv.org/abs/2510.09740
tags:
- learning
- active
- samples
- ncal-r
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'NCAL-R addresses unreliable labels in Active Learning by incorporating
  Neural Collapse geometry into sample selection. The method computes two scores:
  Class-Mean Alignment Perturbation (CMAP), which measures how candidate samples perturb
  inter-class feature geometry, and Feature Fluctuation (FF), which captures temporal
  instability of predictions across training checkpoints.'
---

# Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry

## Quick Facts
- arXiv ID: 2510.09740
- Source URL: https://arxiv.org/abs/2510.09740
- Reference count: 34
- Primary result: NCAL-R achieves higher accuracy with fewer labels and improved robustness to synthetic label noise and OOD data, with up to 3% improvement in long-tail distributions.

## Executive Summary
NCAL-R addresses unreliable labels in Active Learning by incorporating Neural Collapse geometry into sample selection. The method computes two scores: Class-Mean Alignment Perturbation (CMAP), which measures how candidate samples perturb inter-class feature geometry, and Feature Fluctuation (FF), which captures temporal instability of predictions across training checkpoints. By combining these scores, NCAL-R prioritizes samples that both preserve class separation and highlight genuine ambiguities. On ImageNet-100 and CIFAR100, NCAL-R outperforms standard AL baselines, achieving higher accuracy with fewer labels and demonstrating improved robustness to synthetic label noise and stronger generalization to out-of-distribution data.

## Method Summary
NCAL-R is a pool-based Active Learning method that leverages Neural Collapse (NC) geometry to select informative samples under label noise. The approach trains a ResNet-18 backbone to the Terminal Phase of Training (TPT) where NC phenomena emerge. It maintains running class means and computes two acquisition scores: CMAP, which quantifies how a candidate sample would perturb inter-class feature geometry if added to training, and FF, which counts prediction flips across saved checkpoints in the TPT. These scores are Z-normalized and averaged to rank candidates. The method selects 5% of the dataset per cycle (ImageNet/CIFAR-100) or 2% (CIFAR-10), queries their labels, and retrains the model.

## Key Results
- Achieves higher classification accuracy with fewer labeled samples compared to standard AL baselines
- Demonstrates improved robustness to synthetic label noise with approximately 2% better OOD classification performance
- Shows up to 3% improvement in long-tail distributions
- Effectively handles out-of-distribution data through geometry-aware sample selection

## Why This Works (Mechanism)

### Mechanism 1: Class-Mean Alignment Perturbation (CMAP)
- **Claim:** Samples that perturb inter-class geometry when hypothetically added to training data are structurally informative for acquisition.
- **Mechanism:** CMAP computes how much a candidate sample would change the mean pairwise cosine similarity between class means in feature space. Samples that push class means apart (or disrupt alignment) are prioritized. This approximates minimizing "weight correlation," which the paper links (via Jin et al. 2020) to generalization bounds.
- **Core assumption:** Neural collapse ETF-like structure correlates with good class separability and generalization; this holds when training has reached the terminal phase (TPT) where NC phenomena emerge.

### Mechanism 2: Feature Fluctuation (FF)
- **Claim:** Samples whose predictions change across training checkpoints in the terminal phase indicate persistent uncertainty valuable for acquisition.
- **Mechanism:** FF counts prediction flips across checkpoints {θ_t} from Ti to Tf (TPT window). High FF means the model is consistently unstable about the sample even when features have mostly stabilized—flagging ambiguous or genuinely uncertain regions rather than noise that the model has confidently memorized.
- **Core assumption:** Instability in the terminal phase reflects structural ambiguity, not just optimization noise; class means have mostly formed.

### Mechanism 3: Complementary Scoring via Geometry + Uncertainty
- **Claim:** Combining CMAP (structural impact) and FF (temporal uncertainty) yields samples that both improve class separation and highlight genuine boundary regions.
- **Mechanism:** Both scores are Z-normalized and averaged. CMAP pushes toward samples that reshape geometry for better separability; FF pulls toward uncertain/ambiguous samples. Together they balance exploitation (structure) and exploration (uncertainty) without relying on pseudo-labels or auxiliary networks.
- **Core assumption:** CMAP and FF are conditionally independent signals that capture orthogonal aspects of sample value; their combination is more robust than either alone.

## Foundational Learning

### Neural Collapse (NC) fundamentals
- **Why needed here:** NCAL-R's design assumes understanding of NC1–NC4 (intra-class collapse, ETF simplex structure, weight-mean alignment, nearest-mean classification) to interpret why geometry signals are meaningful.
- **Quick check question:** Given a balanced dataset and overtrained network, what geometric structure emerges among class means in the penultimate layer?

### Active Learning acquisition heuristics
- **Why needed here:** To contrast NCAL-R with standard heuristics (uncertainty, diversity) and understand failure modes they exhibit under noisy labels or distribution shift.
- **Quick check question:** Why does pure uncertainty sampling amplify annotation errors under label noise?

### Generalization bounds and weight correlation
- **Why needed here:** CMAP is motivated as a feature-space analog of weight correlation tied to a PAC-style generalization bound (Jin et al. 2020).
- **Quick check question:** How does reducing inter-class cosine similarity in feature space relate (theoretically) to generalization gap?

## Architecture Onboarding

### Component map:
Backbone feature extractor -> Class-mean tracker -> CMAP scorer -> Checkpoint buffer -> FF scorer -> Score combiner -> Acquisition loop

### Critical path:
Train to NC regime -> compute class means -> compute CMAP for all unlabeled -> compute FF across checkpoints -> combine and rank -> acquire batch -> retrain

### Design tradeoffs:
- **TPT length vs. cost:** Longer TPT improves NC signal but increases training compute; too short -> CMAP/FF unreliable
- **Checkpoint frequency:** Dense checkpoints -> better FF resolution but storage overhead; sparse -> may miss flips
- **Acquisition batch size:** Large batches may dilute geometry benefits; small batches increase cycle overhead

### Failure signatures:
- Class means collapse (low CMA baseline) -> CMAP uninformative (likely under severe imbalance or few classes)
- FF near-zero for all samples -> checkpoints too close or model overfitted to noise; check training accuracy and TPT
- CMAP and FF highly correlated -> combination may not help; inspect score distributions
- Performance degrades under extreme label noise (>40%): Assumption—NCAL-R tolerates moderate noise but has unstated limits

### First 3 experiments:
1. **Sanity check on CIFAR-10:** Replicate acquisition curve vs. Random/Coreset with clean labels; verify CMAP and FF distributions are well-separated and not degenerate.
2. **Ablation on synthetic label noise:** Inject 10–30% symmetric noise; compare NCAL-R vs. baselines. Report both accuracy and OOD AUROC to isolate robustness gains.
3. **TPT sensitivity:** Vary terminal-phase epoch range; measure correlation between NC metrics (NC1, NC2) and acquisition performance to confirm NC regime is required.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the NCAL-R framework be effectively adapted for Large Language Models (LLMs) which typically do not exhibit Neural Collapse due to short training durations?
- Basis in paper: Appendix D explicitly states that "The study of Neural Collapse in large-scale models (e.g., LLMs) remains limited" and notes it is "unclear whether NCAL-R's assumptions hold in these settings."
- Why unresolved: NCAL-R relies on the emergence of geometric regularities in the Terminal Phase of Training (TPT), but LLMs are usually trained for few epochs without reaching this collapse phase.
- What evidence would resolve it: Successful application of modified NCAL-R criteria to LLM fine-tuning tasks or proof that geometric regularities analogous to NC emerge earlier in transformer architectures.

### Open Question 2
- Question: How can the computational cost of reaching the Neural Collapse phase be mitigated to improve the efficiency of the acquisition process?
- Basis in paper: Appendix D notes that "Reaching this phase can require many epochs, depending on the dataset and architecture, which may limit efficiency."
- Why unresolved: The method's dependency on the TPT necessitates extended training cycles per active learning iteration, creating a computational bottleneck compared to standard active learning.
- What evidence would resolve it: A comparative analysis showing that NCAL-R retains performance benefits when using early-stopped models, or the introduction of a transfer-learning approach that initializes geometry faster.

## Limitations
- TPT Definition Uncertainty: The exact duration or stopping criterion for the "Terminal Phase of Training" (TPT) is not quantified, creating potential reproducibility issues.
- Hyperparameter Sensitivity: The paper does not explore sensitivity to checkpoint frequency, batch size, or the specific TPT window length, which could significantly impact CMAP and FF reliability.
- Extreme Label Noise Limits: While NCAL-R shows robustness to moderate noise, the paper does not establish clear failure thresholds for very high label corruption rates (>40%).

## Confidence
- **High:** The geometric intuition behind CMAP and its connection to Neural Collapse phenomena is well-grounded in established theory (Jin et al. 2020).
- **Medium:** The experimental results on ImageNet-100 and CIFAR100 demonstrate clear improvements, but the lack of hyperparameter sensitivity analysis reduces confidence in general robustness.
- **Low:** The assumption that FF captures structural uncertainty rather than optimization noise is plausible but not rigorously validated, particularly in the presence of severe label corruption.

## Next Checks
1. **Sanity check on CIFAR-10:** Replicate acquisition curve vs. Random/Coreset with clean labels; verify CMAP and FF distributions are well-separated and not degenerate.
2. **Ablation on synthetic label noise:** Inject 10-30% symmetric noise; compare NCAL-R vs. baselines. Report both accuracy and OOD AUROC to isolate robustness gains.
3. **TPT sensitivity:** Vary terminal-phase epoch range; measure correlation between NC metrics (NC1, NC2) and acquisition performance to confirm NC regime is required.