---
ver: rpa2
title: 'Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn
  Datasets, Not Arguments'
arxiv_id: '2505.22137'
source_url: https://arxiv.org/abs/2505.22137
tags:
- argument
- mining
- datasets
- association
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the generalizability of argument mining models
  by systematically evaluating four transformers across 17 English sentence-level
  datasets. It finds that while models perform well on benchmarks, their generalization
  to unseen datasets is limited, with macro F1 scores dropping significantly.
---

# Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments

## Quick Facts
- arXiv ID: 2505.22137
- Source URL: https://arxiv.org/abs/2505.22137
- Authors: Marc Feger; Katarina Boland; Stefan Dietze
- Reference count: 31
- Primary result: Standard transformers generalize poorly across argument mining datasets, relying on content-based shortcuts rather than structural argument patterns

## Executive Summary
This paper systematically evaluates four transformer models across 17 English sentence-level argument mining datasets to assess their generalizability. While models achieve high performance on benchmark datasets, they fail to transfer knowledge to unseen datasets, with macro F1 scores dropping significantly (97% of cross-dataset experiments fall below benchmark means). The study identifies lexical shortcuts tied to content words as a key factor undermining generalization, and demonstrates that contrastive pre-trained WRAP and joint benchmark training mitigate these issues. The results highlight fundamental challenges in argument mining and call for unified structural approaches and joint evaluation benchmarks.

## Method Summary
The study fine-tunes four transformer models (BERT, RoBERTa, DistilBERT, and WRAP) on 17 English sentence-level argument mining datasets using pairwise transfer learning (train on one dataset, test on another) and joint training (train on 16 datasets, test on held-out 17th). Datasets are split into 60/20/20 stratified folds yielding 1,700 samples each, with binary labels (argument/no-argument). Controlled manipulations remove stop words, function words, discourse markers, and punctuation to assess shortcut reliance. Performance is evaluated using macro F1 score with two-way repeated measures ANOVA and Bonferroni-corrected paired t-tests for significance.

## Key Results
- 97% of cross-dataset experiments fall below the mean benchmark result (M=0.79), with 62% scoring under 0.65 macro F1
- WRAP (M=0.61, SD=0.1) outperforms standard transformers in cross-dataset generalization, showing superior performance in 133 out of 289 experiments
- Joint training on 16 datasets raises average macro F1 to at least 0.64 for three out of four transformers, improving robustness and reducing shortcut reliance
- Post-manipulation, BERT and DistilBERT show minimal performance changes (Δ ≤ 0.02), while WRAP shows largest drop (Δ=0.05), suggesting reliance on structural cues

## Why This Works (Mechanism)

### Mechanism 1: Lexical Shortcut Learning Undermines Generalization
Standard transformers exploit dataset-specific content words as proxies for argument identification rather than learning structural argument patterns. When fine-tuned on argument mining benchmarks, models attend to nouns and content words that correlate with labels in the training domain rather than functional argument markers. This yields high in-distribution performance but fails when content vocabulary shifts across datasets. Evidence shows 97% of generalization experiments fall below benchmark results, and models show minimal performance change after stop word manipulation.

### Mechanism 2: Contrastive Pre-training Creates Argument-Generalizable Embeddings
WRAP's task-specific contrastive pre-training reduces reliance on content shortcuts by learning to distinguish inference and information patterns across diverse contexts. This forces the model to cluster structurally similar argument components while separating dissimilar ones, producing embeddings that capture functional argument properties rather than topic-specific features. WRAP demonstrates superior cross-dataset performance and shows largest performance drop after manipulation, suggesting reliance on structural cues.

### Mechanism 3: Joint Benchmark Training Reduces Shortcut Reliance
Training on multiple heterogeneous datasets simultaneously forces models to learn cross-domain argument features, reducing overfitting to any single dataset's shortcuts. When models are trained on 16 datasets and tested on a held-out 17th, the diversity of content vocabulary and annotation schemes prevents any single lexical shortcut from dominating. Joint training raises macro F1 scores by 0.03-0.08 compared to pairwise transfer.

## Foundational Learning

- **Transfer Learning (Out-of-Distribution Generalization)**
  - Why needed here: The paper's core question evaluates whether models trained on one dataset can generalize to others—this is a transfer learning problem where the target distribution differs from training
  - Quick check question: Can you explain why a model achieving 0.89 F1 on ABSTRCT might drop to 0.55 on TACO even though both are "argument mining"?

- **Shortcut Learning / Spurious Correlations**
  - Why needed here: The paper diagnoses that models exploit dataset-specific cues (content words) rather than task-relevant features (argument structure)—this is the shortcut learning problem
  - Quick check question: If you remove stop words from "Students should study because it improves grades," does the argument structure remain parseable? What does this suggest about what features models *should* rely on?

- **Contrastive Learning**
  - Why needed here: WRAP's advantage comes from contrastive pre-training that separates inference from information signals—understanding contrastive objectives is necessary to interpret why this architecture works
  - Quick check question: In a contrastive setup, what happens if negative examples are too similar to positive examples?

## Architecture Onboarding

- **Component map:**
  - 17 datasets (345k sentences) → Stratified 60/20/20 split (1,700 samples each) → Four transformers (BERT, RoBERTa, DistilBERT, WRAP) → Pairwise transfer experiments (17×17 matrix) → Joint training experiments (leave-one-out) → Controlled manipulation (stop/function word removal) → Macro F1 evaluation with statistical testing

- **Critical path:**
  1. Start with pairwise experiments (17×17 matrices) to establish baseline generalization gaps
  2. Run manipulation experiments on pairwise results to diagnose shortcut reliance
  3. Run joint training experiments to test mitigation strategies
  4. Run manipulation on joint training to confirm reduced shortcut reliance

- **Design tradeoffs:**
  - Selected 17 of 52 available datasets to ensure sentence-level binary labels and reproducibility
  - Used macro F1 to ensure minority class (argument) isn't overshadowed by majority (no-argument)
  - Aggressive manipulation removes ~50% of tokens, potentially eliminating legitimate argument signals
  - WRAP's Twitter-specific design may partially explain its advantage on TACO dataset

- **Failure signatures:**
  - High benchmark F1 (>0.80) + low cross-dataset F1 (<0.55) → shortcut overfitting
  - Minimal performance change post-manipulation (Δ < 0.02) → model relied on content, not structure
  - High performance on AEC (0.96 benchmark) + poor generalization (<0.50) → keyword-based annotation created trivial shortcuts

- **First 3 experiments:**
  1. Reproduce diagonal vs. off-diagonal gap: Train each model on UKP, test on all 16 others. Confirm 97% of off-diagonal scores fall below mean benchmark (M=0.79)
  2. Run manipulation ablation on your domain: Apply stop/function word removal to your target dataset. If Δ < 0.03, model likely shortcut-dependent
  3. Test joint training on held-out domain: Train on 16 datasets excluding your target domain. Expected improvement: +0.03 to +0.08 macro F1

## Open Questions the Paper Calls Out

- How can a GLUE-style multi-task benchmark for argument mining be constructed to capture the task's general demands while reconciling divergent argument definitions across existing datasets?
- Do decoder-based large language models exhibit stronger cross-dataset generalization in argument mining than encoder-only transformers?
- How does the presence of implicit arguments (lacking explicit structural or lexical markers) affect model generalization across datasets?
- What unified annotation guidelines could reconcile the inconsistent definitions of arguments across existing datasets to enable true cross-corpus generalization?

## Limitations

- Controlled manipulations remove ~50% of tokens, potentially eliminating legitimate argument signals alongside shortcuts
- WRAP's superior performance could partially reflect its Twitter-specific design aligning with the TACO dataset
- Selected 17 datasets represent only ~33% of available English sentence-level argument mining datasets, introducing selection bias
- Study did not separate direct from implicit arguments, which may affect interpretation of shortcut learning

## Confidence

- **High confidence**: Generalization gap exists (97% of cross-dataset results below benchmark mean) and joint training improves robustness
- **Medium confidence**: Lexical shortcut learning is the primary mechanism undermining generalization
- **Medium confidence**: WRAP's contrastive pre-training provides systematic advantage over standard transformers

## Next Checks

1. Re-run manipulation experiments with more conservative token removal (preserving discourse markers) to isolate true shortcut learning from legitimate signal loss
2. Test WRAP's performance on non-Twitter datasets (e.g., academic abstracts, legal arguments) to verify domain-general advantages
3. Evaluate joint training with varying dataset combinations to identify which dataset pairs provide the most complementary signal for reducing shortcut reliance