---
ver: rpa2
title: 'Angular Steering: Behavior Control via Rotation in Activation Space'
arxiv_id: '2510.26243'
source_url: https://arxiv.org/abs/2510.26243
tags:
- steering
- direction
- b-instruct
- angular
- activation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Angular Steering introduces a novel activation steering method
  that reformulates behavior control as a geometric rotation within a fixed 2D subspace
  of activation space. By treating steering as rotation toward or away from a target
  behavior direction, the method provides continuous, fine-grained control over behaviors
  like refusal and compliance while preserving model stability.
---

# Angular Steering: Behavior Control via Rotation in Activation Space

## Quick Facts
- **arXiv ID:** 2510.26243
- **Source URL:** https://arxiv.org/abs/2510.26243
- **Authors:** Hieu M. Vu; Tan M. Nguyen
- **Reference count:** 40
- **Primary result:** Angular Steering achieves robust behavioral control (refusal/compliance) via geometric rotation in activation space, outperforming vector addition methods while preserving general language capabilities.

## Executive Summary
Angular Steering introduces a novel activation steering method that reformulates behavior control as a geometric rotation within a fixed 2D subspace of activation space. By treating steering as rotation toward or away from a target behavior direction, the method provides continuous, fine-grained control over behaviors like refusal and compliance while preserving model stability. Experiments across multiple model families and sizes demonstrate that Angular Steering achieves robust behavioral control with minimal performance degradation on general language tasks. The approach generalizes existing vector addition and directional ablation techniques under a unified geometric framework, simplifying parameter selection. Additionally, an adaptive variant selectively applies steering based on feature alignment, further enhancing stability and coherence.

## Method Summary
Angular Steering extracts feature directions from contrastive datasets (harmful vs. harmless prompts) using difference-in-means, then constructs a fixed 2D steering plane using the target feature direction and the first principal component of candidate directions across layers. During inference, normalized activations are rotated within this plane using a rotation matrix parameterized by steering angle θ. An adaptive variant applies a binary mask based on activation alignment with the target feature, rotating only positively-aligned activations. The method operates at the activation level after normalization layers, preserving activation norms while changing angular position to control behavior.

## Key Results
- Angular Steering generalizes vector addition and ablation as special rotation cases, providing continuous control with simpler parameter selection
- Fixed 2D steering planes using PCA-based axes outperform dynamic planes (using raw activations) in stability and coherence
- Adaptive masking reduces perplexity degradation and prevents incoherent outputs on benign inputs
- Method achieves robust behavioral control across multiple model families (Llama3, Gemma2, Qwen2.5) and sizes (3B-8B parameters)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Rotation generalizes vector addition and ablation while preserving activation norms.
- **Mechanism:** Modern LLMs use RMSNorm, which maps activations to a scaled unit sphere (direction-focused). Vector addition ($h + \alpha d$) changes both direction and magnitude, often requiring sensitive coefficient tuning. Rotation changes only the angular position within a 2D plane, keeping the norm constant. This provides continuous control without the instability of magnitude scaling.
- **Core assumption:** Activation norms are less semantically important than their directions in normalized space; feature strength is encoded by angular alignment.
- **Evidence anchors:**
  - [abstract] "generalizes vector addition and orthogonalization as special rotation cases."
  - [Section 4.1] "RMSNorm... first maps the activation to a $\sqrt{d_{model}}$-scaled unit sphere... highlighting direction, not magnitude."
  - [Appendix A] Derivation showing addition and ablation are specific rotation angles ($\phi_{add}$, $\pi/2$).
- **Break condition:** If an architecture uses unnormalized activations where magnitude carries significant semantic weight, pure rotation may underperform compared to additive methods.

### Mechanism 2
- **Claim:** Steering within a fixed plane ($\text{Span}\{d_{feat}, d_{PC0}\}$) minimizes interference with unrelated features compared to the dynamic plane $\text{Span}\{h, d_{feat}\}$.
- **Mechanism:** Using the raw activation $h$ as a basis axis (prior work) introduces instance-specific noise and unrelated features into the steering calculation. Angular Steering constructs a fixed plane using the target direction and the first principal component of candidate directions across layers. This isolates the "refusal" feature evolution specifically, reducing unintended degradation of general capabilities.
- **Core assumption:** Features are nearly orthogonal (Superposition Hypothesis), so isolating the rotation to a specific 2D subspace leaves other feature directions intact.
- **Evidence anchors:**
  - [Section 4.5] "We argue against [Span{h, d_feat}]... this span might include other dominant features... Instead, we propose a fixed plane."
  - [Appendix C.2] "Steering on Span(h, d_feat) causes larger fluctuations and higher perplexity."
- **Break condition:** If the target behavior is not linearly represented or is heavily entangled (non-orthogonal) with critical syntactic features, steering in this plane will still cause coherence loss.

### Mechanism 3
- **Claim:** Adaptive masking prevents the distortion of inputs that are already misaligned with the target behavior.
- **Mechanism:** The adaptive variant computes a mask based on $\text{sign}(\text{proj}_{d_{feat}}(h))$. It only rotates activations that are positively aligned with the "harmful" direction. This prevents the method from "double correcting" or distorting benign inputs, which stabilizes perplexity and coherence.
- **Core assumption:** Contrastive datasets (harmful vs. harmless) produce activations that cluster on opposite sides of the feature direction hyperplane.
- **Evidence anchors:**
  - [Section 4.6.2] "rotate[s] only activations positively aligned with $\hat{d}_{feat}$."
  - [Section 6.2] "perplexity of Adaptive Steering is lower, more stable, and closer to no steering."
- **Break condition:** If the classification boundary for the behavior is non-linear or the projection threshold is poorly chosen, the mask may fail to steer harmful inputs or inadvertently steer harmless ones.

## Foundational Learning

- **Concept:** **RMSNorm and the Hypersphere**
  - **Why needed here:** The paper relies on the premise that RMSNorm effectively projects activations onto a sphere, making angular distance the primary metric for feature strength. Without this, rotation is just a weird way to do addition.
  - **Quick check question:** Why does the paper argue that rotation is superior to addition for models using RMSNorm? (Answer: RMSNorm removes magnitude variance, making directional rotation the natural control mechanism.)

- **Concept:** **Principal Component Analysis (PCA) of Weights/Activations**
  - **Why needed here:** The method defines the steering plane using $d_{PC0}$ (the first principal component of candidate directions). You need to understand PCA to grasp why this axis captures "inter-layer variation" better than a random axis.
  - **Quick check question:** Why does the method use the first principal component of candidate directions rather than a random vector to define the steering plane? (Answer: It captures the stable evolution of the feature across layers.)

- **Concept:** **Linear Representation Hypothesis**
  - **Why needed here:** The entire method assumes that "refusal" is a direction in space. If features were represented non-linearly or as complex manifolds, Difference-in-Means and vector rotation would fail.
  - **Quick check question:** What allows us to extract a "refusal direction" simply by subtracting the mean activation of harmless prompts from harmful prompts? (Answer: The assumption that high-level features are encoded as linear directions.)

## Architecture Onboarding

- **Component map:** Calibration Data -> Direction Solver -> Rotation Engine -> Adaptive Gate -> Intervention
- **Critical path:** The selection of the **Feature Direction ($\hat{d}_{feat}$)**. If this vector is noisy (low cosine similarity across layers) or points to a correlated but distinct feature (e.g., "anger" instead of "refusal"), the steering will be ineffective or destructive.
- **Design tradeoffs:**
  - **Fixed vs. Dynamic Plane:** The paper chooses a *Fixed Plane* (using PCA) for stability and isolation, trading off the context-specific adaptability of using the raw activation $h$ in the basis.
  - **Adaptive vs. Non-Adaptive:** *Adaptive* preserves perplexity and coherence better (essential for small models) but introduces a hard binary gate; *Non-Adaptive* is conceptually simpler but risks incoherence on benign inputs.
- **Failure signatures:**
  - **Language Switching:** The model starts refusing or complying in random languages (seen in 3B models), indicating feature interference in the steering plane.
  - **Repetition Loops:** High rotation angles (e.g., 180°+) causing the model to diverge from the training distribution manifold.
  - **High Perplexity:** A clear sign that the steering plane is interfering with general syntax features (check if you are using the dynamic Span $\{h, d\}$ instead of the fixed PCA plane).
- **First 3 experiments:**
  1. **Verify Separation:** Extract $d_{feat}$ and plot scalar projections of harmful vs. harmless prompts. Confirm distinct clusters (Fig 4/10).
  2. **Sweep Angles:** Run refusal evaluation (HarmBench) from $0^\circ$ to $350^\circ$. Plot the "steering circle" (Fig 7) to verify continuous control.
  3. **Stress Test Perplexity:** Compare perplexity of Adaptive vs. Non-Adaptive steering on Alpaca (benign) to ensure the intervention doesn't break fluency.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can principled methods for systematically identifying optimal 2D steering subspaces be developed to replace the current heuristic approach (PCA-based selection)?
  - **Basis in paper:** [explicit] The conclusion states Angular Steering "currently relies on heuristically selected steering planes, which might not always generalize optimally across diverse behaviors or architectures. Future work should focus on systematically identifying effective subspaces."
  - **Why unresolved:** The paper uses PCA on candidate directions to select the second axis, but provides no theoretical justification that this isolates the target feature optimally.
  - **What evidence would resolve it:** A comparative study showing that alternative subspace selection methods (e.g., sparse autoencoder features, contrastive learning) yield more robust steering across diverse behaviors and architectures.

- **Open Question 2:** What mechanisms cause smaller models (3B parameters) to experience greater feature interference during steering compared to larger models?
  - **Basis in paper:** [inferred] Section 6.2 notes that "smaller models like LLAMA-3.2-3B-INSTRUCT and QWEN2.5-3B-INSTRUCT often produce incoherent text across a wide arc" and hypothesizes "limited capacity in smaller models leads to feature interference, with multiple features entangled in the 2D steering subspace."
  - **Why unresolved:** The paper observes the phenomenon but does not empirically validate the feature entanglement hypothesis or identify specific interfering features.
  - **What evidence would resolve it:** Analysis using sparse autoencoders or probing classifiers to identify which non-target features are co-activated in smaller vs. larger models during steering.

- **Open Question 3:** Why do harmful completions exhibit lower perplexity than refusal responses when steering toward the "jailbroken" region?
  - **Basis in paper:** [explicit] Section 6.2 states: "harmful generations (learnt during pretraining) have lower perplexity than refusal responses (learnt during safety tuning), indicating they remain more probable. While the mechanisms behind safety alignment are still unclear, our findings offer a glimpse into this issue."
  - **Why unresolved:** The paper observes the perplexity asymmetry but does not establish whether this reflects pretraining-safety training conflicts, token distribution differences, or architectural factors.
  - **What evidence would resolve it:** Controlled experiments comparing perplexity of refusal vs. harmful tokens across models with different pretraining-safety tuning ratios, or layer-wise analysis of when the perplexity divergence emerges.

- **Open Question 4:** Why does GEMMA-2-9B-IT show significantly weaker steering effects compared to other models of similar size?
  - **Basis in paper:** [inferred] Figure 7 shows GEMMA-2-9B-IT as "an exception, displaying the weakest effect yet still following the overall trend." The paper does not investigate architectural differences that might explain this.
  - **Why unresolved:** The observation is noted but no hypothesis or analysis is provided for why this specific architecture responds differently.
  - **What evidence would resolve it:** Comparative analysis of GEMMA-2's RMSNorm implementation, attention patterns, or residual stream characteristics against other tested models to identify factors affecting steering efficacy.

## Limitations
- The method assumes linear feature representations, which may not generalize to behaviors with non-linear or distributed representations
- Adaptive steering introduces discontinuities through binary masking that could accumulate across longer generations
- The PCA-based plane selection is heuristic and may not optimally isolate target features for all behaviors or architectures

## Confidence
- **High Confidence:** The geometric framework (rotation vs. addition), the empirical superiority of fixed vs. dynamic planes, and the effectiveness of adaptive masking on stability metrics are well-supported by controlled experiments with clear baselines.
- **Medium Confidence:** Claims about generalization across model families and sizes are supported but could benefit from broader architectural diversity (e.g., transformer variants, non-decoder models).
- **Low Confidence:** Theoretical claims about why RMSNorm makes rotation "natural" are largely asserted rather than proven; the connection between the hypersphere constraint and optimal behavior control needs deeper mathematical justification.

## Next Checks
1. **Non-linear Behavior Testing:** Apply Angular Steering to behaviors known to have non-linear representations (e.g., complex reasoning chains, multi-step planning) and compare performance against linear baselines to test the limits of the linear representation hypothesis.
2. **Layer Sensitivity Analysis:** Systematically vary the steering layer positions (not just use all layers) and measure performance degradation curves to identify whether certain architectural depths are more amenable to rotation-based control.
3. **Distributional Robustness:** Evaluate steering effectiveness when the calibration data distribution shifts (e.g., domain adaptation, prompt style transfer) to test whether the learned feature directions generalize beyond the specific contrastive pairs used for calibration.