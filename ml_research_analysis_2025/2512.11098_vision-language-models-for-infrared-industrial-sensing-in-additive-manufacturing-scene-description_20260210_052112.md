---
ver: rpa2
title: Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing
  Scene Description
arxiv_id: '2512.11098'
source_url: https://arxiv.org/abs/2512.11098
tags:
- infrared
- thermal
- zero-shot
- images
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents VLM-IRIS, a zero-shot framework that adapts
  vision-language models (VLMs) to thermal infrared imagery for object presence detection
  in additive manufacturing. The framework preprocesses infrared images into RGB-compatible
  inputs and applies centroid-based prompt ensembling with CLIP ViT-B/32 to achieve
  high accuracy without model retraining.
---

# Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description

## Quick Facts
- arXiv ID: 2512.11098
- Source URL: https://arxiv.org/abs/2512.11098
- Reference count: 35
- Primary result: VLM-IRIS achieves 100% accuracy for object presence detection in thermal infrared imagery using CLIP ViT-B/32 with magma colormap preprocessing and centroid-based prompt ensembling

## Executive Summary
This paper introduces VLM-IRIS, a zero-shot framework that adapts vision-language models to thermal infrared imagery for object presence detection in additive manufacturing environments. The framework addresses the challenge of using RGB-trained vision-language models on thermal data by converting infrared images to RGB-compatible inputs through colormap preprocessing and applying centroid-based prompt ensembling strategies. Experimental results on a 3D printer testbed demonstrate that the magma colormap with centroid prompting achieves perfect accuracy under controlled room-temperature conditions, outperforming alternative preprocessing methods.

## Method Summary
VLM-IRIS converts thermal infrared images to RGB-compatible inputs using colormap preprocessing, then applies CLIP ViT-B/32 with centroid-based prompt ensembling for zero-shot object presence detection. The framework processes infrared imagery from additive manufacturing scenes without requiring model retraining, enabling label-free monitoring in low-light conditions. The approach leverages existing vision-language model capabilities while adapting them to thermal domain requirements through appropriate preprocessing and prompt design strategies.

## Key Results
- Magma colormap preprocessing with centroid prompting achieves 100% accuracy under room-temperature conditions
- Outperforms grayscale and viridis preprocessing approaches for thermal image interpretation
- Demonstrates effective zero-shot adaptation of RGB-trained VLMs to thermal infrared domains

## Why This Works (Mechanism)
The framework succeeds by bridging the domain gap between RGB-trained vision-language models and thermal infrared imagery through systematic preprocessing and prompt engineering. By converting thermal data to RGB-compatible formats using perceptually appropriate colormaps, the approach preserves thermal contrast information while making it interpretable to models trained on visible spectrum data. The centroid-based prompt ensembling strategy aggregates multiple prompts centered on different regions of interest, improving detection reliability across varying thermal distributions and object positions.

## Foundational Learning
- **Colormap preprocessing**: Converts thermal data to RGB format while preserving thermal gradients and contrast patterns. Needed to make thermal data interpretable to RGB-trained models. Quick check: Verify thermal features remain distinguishable after colormap transformation.
- **Centroid-based prompt ensembling**: Aggregates multiple prompts centered on different image regions to improve detection robustness. Needed to handle varying object positions and thermal distributions. Quick check: Compare single-prompt vs ensemble performance across test cases.
- **Zero-shot learning adaptation**: Enables VLMs to interpret new domains without retraining. Needed to avoid costly fine-tuning while maintaining model capabilities. Quick check: Validate performance consistency across different object types and thermal conditions.
- **Thermal-to-RGB conversion**: Maps infrared wavelengths to visible spectrum representations. Needed to leverage existing RGB-trained model architectures. Quick check: Ensure conversion preserves critical thermal features for detection tasks.
- **Vision-language model prompting**: Crafts text descriptions that guide model interpretation of visual inputs. Needed to provide semantic context for thermal pattern recognition. Quick check: Test prompt variations for detection accuracy and consistency.
- **Industrial thermal imaging**: Captures thermal signatures in manufacturing environments for process monitoring. Needed to enable real-time quality control and anomaly detection. Quick check: Verify thermal camera specifications match operational requirements.

## Architecture Onboarding
Component map: Infrared camera -> Colormap preprocessing -> CLIP ViT-B/32 -> Centroid prompt ensembling -> Detection output

Critical path: Thermal image capture → Colormap transformation → Vision-language model inference → Prompt aggregation → Binary presence detection

Design tradeoffs: The framework prioritizes zero-shot adaptation over fine-tuned accuracy, sacrificing potential performance gains for broader applicability and reduced computational overhead. Colormap selection balances perceptual effectiveness with computational efficiency, while prompt ensembling adds complexity but improves detection reliability.

Failure signatures: Poor thermal contrast or ambiguous thermal signatures may lead to false negatives. Inappropriate colormap selection can obscure critical thermal features. Overly broad or narrow prompts may miss objects or generate false positives. Environmental factors like ambient temperature variations can affect detection accuracy.

First experiments:
1. Test framework performance across different ambient temperature ranges to assess environmental robustness
2. Evaluate detection accuracy for multiple object types and thermal signatures beyond binary presence
3. Compare different colormap preprocessing approaches on industrial-grade thermal cameras with varying specifications

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to controlled laboratory environment with single 3D printer model
- Focuses exclusively on binary object presence detection, not more complex tasks
- 100% accuracy claim may not generalize to dynamic industrial environments with varying thermal loads

## Confidence
High: Magma colormap with centroid prompting achieves superior performance in controlled tests
Medium: Framework effectively adapts VLMs to thermal imagery, but results limited to specific conditions
Low: Claims about label-free monitoring in low-light manufacturing require broader validation

## Next Checks
1. Test framework across multiple 3D printer models and manufacturing processes under varying ambient temperature conditions and thermal loads to assess robustness
2. Evaluate performance on more complex tasks beyond binary presence detection, including object counting, thermal anomaly identification, and quality assessment metrics
3. Conduct comparative analysis between different infrared camera specifications and preprocessing approaches across industrial-grade thermal imaging equipment to establish hardware independence