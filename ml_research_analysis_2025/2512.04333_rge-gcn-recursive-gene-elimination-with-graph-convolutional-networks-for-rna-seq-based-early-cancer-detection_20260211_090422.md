---
ver: rpa2
title: 'RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for
  RNA-seq based Early Cancer Detection'
arxiv_id: '2512.04333'
source_url: https://arxiv.org/abs/2512.04333
tags:
- cancer
- gene
- graph
- genes
- rna-seq
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces RGE-GCN, a recursive gene elimination framework
  combining Graph Convolutional Networks and Integrated Gradients for biomarker discovery
  from RNA-seq data. It constructs a sample-sample graph, trains a GCN for classification,
  and uses IG to score and recursively remove the least informative genes until a
  compact set is obtained.
---

# RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection

## Quick Facts
- arXiv ID: 2512.04333
- Source URL: https://arxiv.org/abs/2512.04333
- Reference count: 40
- Primary result: RGE-GCN achieved superior accuracy and F1-scores compared to traditional differential expression methods (DESeq2, edgeR, limma-voom) for cancer detection using RNA-seq data.

## Executive Summary
RGE-GCN introduces a novel framework that combines Graph Convolutional Networks (GCN) with Integrated Gradients for recursive gene elimination in RNA-seq based cancer detection. The method constructs a sample-sample graph from expression data, trains a GCN classifier, and iteratively removes the least informative genes based on their integrated gradient scores until an optimal biomarker set is obtained. The approach demonstrates superior performance compared to traditional differential expression methods while providing interpretable gene selections that align with known cancer pathways, making it valuable for both early cancer detection and biomarker discovery.

## Method Summary
The RGE-GCN framework operates through three main phases: graph construction, GCN training with integrated gradients, and recursive gene elimination. First, it constructs a sample-sample graph where nodes represent samples and edges connect similar samples based on expression profiles. A GCN is then trained on this graph for binary cancer classification. Using integrated gradients, the framework computes importance scores for each gene, identifying those contributing least to classification. In the recursive elimination phase, the least important genes are removed iteratively, and the GCN is retrained after each elimination step. This process continues until a compact, optimal gene set is obtained that maintains high classification performance while reducing dimensionality and enhancing interpretability.

## Key Results
- RGE-GCN achieved superior accuracy and F1-scores compared to DESeq2, edgeR, and limma-voom on lung, kidney, and cervical cancer datasets
- Selected genes aligned with known cancer pathways including PI3K-AKT, MAPK, SUMOylation, and immune regulation
- The approach provides an interpretable end-to-end pipeline for early cancer detection and biomarker discovery

## Why This Works (Mechanism)
RGE-GCN leverages the graph structure to capture sample relationships and uses GCNs to learn complex interactions between genes and samples. The integrated gradients method provides principled feature importance scores that account for the entire input space, not just individual gene expression values. By recursively eliminating genes based on these scores, the method systematically removes redundancy while preserving the most informative features for cancer classification. This approach overcomes limitations of traditional differential expression methods that analyze genes in isolation without considering sample relationships or gene-gene interactions.

## Foundational Learning
1. Graph Convolutional Networks (GCNs) - Why needed: To capture complex relationships between samples and genes in the expression data; Quick check: Verify that the GCN can effectively propagate information through the sample-sample graph
2. Integrated Gradients - Why needed: To provide interpretable feature importance scores that account for the entire input space; Quick check: Confirm that integrated gradients produce stable importance scores across multiple runs
3. Recursive Gene Elimination - Why needed: To systematically reduce dimensionality while preserving classification performance; Quick check: Ensure that performance doesn't degrade significantly with each elimination step
4. Sample-sample graph construction - Why needed: To capture relationships between similar samples for better representation learning; Quick check: Validate that the graph construction method produces meaningful sample clusters
5. RNA-seq data preprocessing - Why needed: To ensure quality input for downstream analysis; Quick check: Confirm that normalization and filtering steps produce stable expression matrices
6. Pathway enrichment analysis - Why needed: To validate biological relevance of selected genes; Quick check: Verify that selected genes significantly enrich known cancer pathways

## Architecture Onboarding

**Component Map:** RNA-seq data -> Sample-sample graph construction -> GCN training -> Integrated gradients computation -> Recursive gene elimination -> Optimal biomarker set

**Critical Path:** Graph construction → GCN training → Integrated gradients → Recursive elimination

**Design Tradeoffs:** The method balances classification accuracy with feature reduction, trading computational complexity for interpretability and biomarker discovery. The recursive approach may be computationally intensive but provides systematic gene selection.

**Failure Signatures:** Poor graph construction could lead to suboptimal sample relationships; unstable integrated gradient scores could cause inconsistent gene selection; excessive recursion might eliminate important genes; poor initial GCN performance could propagate through the elimination process.

**3 First Experiments:**
1. Test GCN performance on synthetic graph data with known class labels
2. Validate integrated gradients stability across multiple random initializations
3. Evaluate recursive elimination convergence on a small gene subset before full-scale application

## Open Questions the Paper Calls Out
None

## Limitations
- The sample-sample graph construction method may be sensitive to parameter choices (k-NN neighbors, weighting schemes)
- The recursive elimination process might risk removing genes that are important in combination with others, even if individually less informative
- Biological validation relies on pathway enrichment, which doesn't definitively prove clinical utility

## Confidence

- **High confidence**: Technical implementation of GCN with integrated gradients for feature importance
- **Medium confidence**: Performance improvements over traditional differential expression methods
- **Medium confidence**: Biological relevance of selected genes based on pathway analysis

## Next Checks

1. Test RGE-GCN on multi-class cancer subtype classification tasks to assess scalability beyond binary problems
2. Perform ablation studies on graph construction parameters (k-NN selection, weighting schemes) to determine sensitivity
3. Conduct independent validation using external RNA-seq datasets and prospective clinical samples to verify generalizability