---
ver: rpa2
title: 'CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language
  Models'
arxiv_id: '2505.22869'
source_url: https://arxiv.org/abs/2505.22869
tags:
- protein
- sequence
- functional
- sequences
- gid00001
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CFP-Gen addresses the challenge of designing proteins with multiple
  functional constraints by integrating multimodal conditions including functional
  annotations, sequence motifs, and 3D structures. It introduces an Annotation-Guided
  Feature Modulation (AGFM) module that dynamically adjusts protein feature distributions
  based on composable functional annotations, and a Residue-Controlled Functional
  Encoding (RCFE) module that captures residue-wise interactions for precise control.
---

# CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models

## Quick Facts
- arXiv ID: 2505.22869
- Source URL: https://arxiv.org/abs/2505.22869
- Authors: Junbo Yin, Chao Zha, Wenjia He, Chencheng Xu, Xin Gao
- Reference count: 30
- One-line primary result: Generates multi-functional proteins with functionality comparable to natural proteins, improving ESM3's F1-score by 30% and DPLM's Amino Acid Recovery by 9%

## Executive Summary
CFP-Gen addresses the challenge of designing proteins with multiple functional constraints by integrating multimodal conditions including functional annotations, sequence motifs, and 3D structures. It introduces an Annotation-Guided Feature Modulation (AGFM) module that dynamically adjusts protein feature distributions based on composable functional annotations, and a Residue-Controlled Functional Encoding (RCFE) module that captures residue-wise interactions for precise control. The method enables high-throughput generation of novel proteins with functionality comparable to natural proteins, improving ESM3's F1-score by 30% and DPLM's Amino Acid Recovery by 9% in inverse folding tasks. It also achieves high success rates in designing multi-functional proteins, including enzymes with multiple catalytic activities.

## Method Summary
CFP-Gen builds upon DPLM-650M with a two-stage training approach. The first stage implements AGFM, which uses separate embedding layers for GO, IPR, and EC annotations, combined with MLPs to generate modulation parameters (γ, β, α) that adjust protein feature distributions. The second stage adds RCFE, which employs 16 trainable copy ESM blocks with zero-initialized linear layers to capture residue-wise interactions. The model uses a GVP-Transformer structure encoder from DPLM (frozen during training) and is trained on 103,939 proteins with 375 GO, 1,154 IPR terms, plus 139,551 enzymes with 661 EC annotations. Training uses 8 A100 GPUs for ~72 hours per stage with AdamW optimizer, 1M token batch size, and 100 sampling steps.

## Key Results
- Improves ESM3's F1-score by 30% in functional prediction tasks
- Increases DPLM's Amino Acid Recovery by 9% in inverse folding
- Successfully generates multi-functional proteins including enzymes with multiple catalytic activities

## Why This Works (Mechanism)
CFP-Gen works by decomposing the complex task of multi-functional protein design into two specialized modules. The AGFM module enables dynamic adjustment of protein feature distributions based on functional annotations, allowing the model to modulate its generation process according to different functional requirements. The RCFE module then refines these features at the residue level, capturing local interactions that are critical for maintaining both structure and function. This two-stage approach allows the model to first establish functional context through annotation-guided modulation, then precisely control residue-level details for functional implementation.

## Foundational Learning
**Diffusion Models for Proteins** - Why needed: To generate sequences that satisfy multiple functional constraints simultaneously. Quick check: Verify that noise prediction loss decreases monotonically during training.

**Functional Annotation Integration** - Why needed: To guide generation toward specific biological functions. Quick check: Test that changing annotations produces proteins with different predicted functions.

**Residue-Wise Feature Modulation** - Why needed: To capture local structural and functional interactions. Quick check: Confirm that residue-level features correlate with local structure quality scores.

**Multi-Modal Condition Handling** - Why needed: To incorporate sequence motifs and 3D backbone structures. Quick check: Validate that provided structural constraints are preserved in generated proteins.

**Two-Stage Training** - Why needed: To separately optimize functional annotation handling and residue-level control. Quick check: Compare performance when training both modules jointly versus sequentially.

## Architecture Onboarding

**Component Map:** Input conditions -> AGFM module -> RCFE module -> ESM backbone -> Output sequence

**Critical Path:** Functional annotations → AGFM embedding/MLP → γ,β,α modulation → Reshape → RCFE blocks → ESM backbone → Final sequence

**Design Tradeoffs:** Uses separate modules for functional and residue-level control (modular but requires two-stage training) versus end-to-end training (simpler but harder to control). Zero-initialized weights in RCFE ensure stability but may slow convergence.

**Failure Signatures:** Mode collapse producing repetitive n-grams; poor performance on long-tail functional categories; low structural fidelity on proteins with IDRs or very short sequences (<50 residues).

**First Experiments:**
1. Generate proteins with single functional annotations and verify function prediction accuracy
2. Test multi-annotation combinations and check for functional consistency
3. Perform inverse folding on benchmark structures and measure structural recovery metrics

## Open Questions the Paper Calls Out
**Open Question 1:** Can CFP-Gen be extended to incorporate physicochemical properties (e.g., hydrophobicity, charge, polarity) as conditional inputs to better satisfy bio-manufacturing requirements? The authors state this is essential for meeting bio-manufacturing requirements but the current implementation focuses on semantic annotations.

**Open Question 2:** How can sequence–structure co-design be effectively incorporated into the framework to enable end-to-end protein design without relying on external backbone inputs? The current model relies on off-the-shelf structure encoders to process provided backbone coordinates rather than generating structure and sequence jointly.

**Open Question 3:** Will scaling training datasets and enriching the annotation scope sufficiently generalize the model to broader functional categories and long-tail data distributions? The current dataset filters out labels with fewer than 100 sequences, potentially limiting discovery of rare or novel functions.

## Limitations
- Requires substantial computational resources (8 A100 GPUs for ~144 hours total training)
- Performance characterization on proteins with intrinsically disordered regions is incomplete
- Limited to functional categories with ≥100 training sequences, potentially missing rare functions
- Complex two-stage training procedure with underspecified hyperparameters

## Confidence
**High Confidence:** Core diffusion framework and modular architecture are well-described and follow established patterns.
**Medium Confidence:** Training procedure details and dataset preparation are sufficiently specified for reproduction.
**Low Confidence:** Exact performance characteristics on edge cases and precise computational overhead compared to baselines.

## Next Checks
1. **Module Integration Validation:** Verify that the AGFM module properly modulates feature distributions by testing with synthetic functional annotations and measuring resulting changes in protein feature embeddings.
2. **Function Prediction Consistency:** Cross-validate the generated proteins' functional annotations using multiple independent predictors (DeepGO-SE, InterProScan, CLEAN) to ensure claimed multi-functionality is reproducible.
3. **Structural Fidelity Assessment:** Perform detailed structural analysis comparing generated proteins with target backbones using multiple metrics (pTM-score, RMSD, and local quality scores) to confirm claimed structural preservation across different protein lengths and disorder content.