---
ver: rpa2
title: Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles
arxiv_id: '2511.06160'
source_url: https://arxiv.org/abs/2511.06160
tags:
- bias
- reasoning
- puzzle
- puzzles
- person
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PRIME, a novel framework using logic grid
  puzzles to evaluate implicit social biases in LLM reasoning. PRIME generates puzzle
  triplets with stereotypical, anti-stereotypical, and neutral variants, enabling
  controlled comparisons of model performance under different bias conditions.
---

# Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles

## Quick Facts
- arXiv ID: 2511.06160
- Source URL: https://arxiv.org/abs/2511.06160
- Authors: Fatima Jahara; Mark Dredze; Sharon Levy
- Reference count: 40
- Primary result: LLM reasoning performance varies systematically with social stereotypes in logic puzzles, showing consistent bias patterns across model families

## Executive Summary
This paper introduces PRIME, a novel framework using logic grid puzzles to evaluate implicit social biases in LLM reasoning. PRIME generates puzzle triplets with stereotypical, anti-stereotypical, and neutral variants, enabling controlled comparisons of model performance under different bias conditions. Across multiple model families, puzzles sizes, and mitigation strategies, the study finds that models consistently perform better on stereotype-aligned puzzles and worse on anti-stereotype ones, indicating that stereotypes function as reasoning shortcuts. Edit distance metrics reveal that bias effects are concentrated in stereotype-associated categories, with minimal spillover into neutral reasoning.

## Method Summary
PRIME creates logic grid puzzles with controlled demographic associations across stereotypical, anti-stereotypical, and neutral conditions. The framework generates 6,048 puzzles across four sizes (2×3, 2×4, 4×3, 4×4) with 504 triplets per size. Three category groups include names from US Census, bias-probing categories with gender stereotypes, and general neutral categories. Puzzles use five clue types: True/False, Neither Nor, Either Or, Unaligned Pairs, and Multi-Elimination. Models solve puzzles while edit distance metrics (ED_all, ED_BP, ED_G) measure deviations from ground truth solutions. Bias Difference (∆ = ED_S − ED_AS) with paired t-tests identifies significant bias effects. Chain-of-thought prompting and debiasing prefixes are tested as mitigation strategies.

## Key Results
- Models consistently show better performance on stereotypical puzzles compared to anti-stereotypical variants across all model families
- Bias effects are concentrated in stereotype-associated categories (ED_BP gaps) rather than spilling into neutral reasoning (ED_G)
- Chain-of-thought prompting reduces bias and improves reasoning accuracy more effectively than static debiasing prompts, though stereotypes persist

## Why This Works (Mechanism)
The PRIME framework works by isolating social biases from pure logical reasoning through controlled puzzle generation. By creating puzzle triplets with identical logical structure but different demographic associations, the framework measures how stereotypes influence reasoning pathways. The edit distance metrics capture not just accuracy but the specific nature of reasoning errors, revealing whether biases manifest as systematic substitutions in stereotype-associated categories.

## Foundational Learning
- Logic grid puzzles: Constraint satisfaction problems requiring deductive reasoning; needed for controlled bias evaluation
- Edit distance metrics: Quantify solution deviations by counting category swaps; needed to measure bias magnitude precisely
- Paired t-tests: Statistical method for comparing bias effects across puzzle variants; needed to establish significance
- Chain-of-thought prompting: Multi-step reasoning approach; needed for bias mitigation evaluation
- Latin square constraints: Ensure unique puzzle solutions; needed for valid bias measurement

## Architecture Onboarding
Component map: Puzzle Generator -> Model API -> Edit Distance Calculator -> Statistical Analyzer

Critical path: Puzzle generation → Model inference → Edit distance computation → Bias analysis

Design tradeoffs: 
- Puzzle complexity vs. bias detection sensitivity
- Number of categories vs. constraint satisfaction difficulty
- Prompt engineering vs. model-specific behavior

Failure signatures:
- Near-zero accuracy on complex puzzles with moderate edit distances
- Stereotypical associations in anti-stereotype conditions
- Inconsistent bias patterns across model families

First experiments:
1. Run 2×3 puzzle triplet through base model to verify framework functionality
2. Compare edit distance distributions between two model families
3. Test chain-of-thought prompting on single puzzle category

## Open Questions the Paper Calls Out
- Can PRIME be adapted for non-binary gender identities or demographics without standard name-based proxies?
- Do implicit bias patterns persist in spatial or numerical reasoning tasks?
- How do biases manifest in multilingual contexts or cultures with different social stereotypes?

## Limitations
- Current framework excludes non-binary identities due to name-based proxy limitations
- Evaluation focuses on linguistic and categorical reasoning, not spatial or numerical tasks
- English-only analysis limits generalizability to multilingual contexts

## Confidence
- High confidence in core finding that LLMs exhibit stereotypical reasoning shortcuts
- Medium confidence in bias measurement completeness across all demographic categories
- Medium confidence in prompting effectiveness being model-specific
- Low confidence in exact reproducibility due to unspecified hyperparameters

## Next Checks
1. Replicate the study using alternative demographic categories and stereotype mappings
2. Compare edit distance distributions between human solvers and LLMs on identical puzzle sets
3. Test the same puzzle triplets with models from different pretraining distributions