---
ver: rpa2
title: Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous
  Meme Detection
arxiv_id: '2601.07232'
source_url: https://arxiv.org/abs/2601.07232
tags:
- reasoning
- humor
- arxiv
- feedback
- florence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FLoReNce introduces a feedback-driven closed-loop reasoning system
  for multimodal humor detection, where a reasoning agent is iteratively critiqued
  by a judge, and the resulting error and semantic feedback are converted into control
  signals stored in a non-parametric knowledge base. During inference, the system
  retrieves similar past cases and uses them to modulate prompts without retraining,
  enabling adaptive reasoning.
---

# Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection

## Quick Facts
- arXiv ID: 2601.07232
- Source URL: https://arxiv.org/abs/2601.07232
- Reference count: 9
- F1-score of 0.7708 on PrideMM dataset

## Executive Summary
FLoReNce introduces a feedback-driven closed-loop reasoning system for multimodal humor detection, where a reasoning agent is iteratively critiqued by a judge, and the resulting error and semantic feedback are converted into control signals stored in a non-parametric knowledge base. During inference, the system retrieves similar past cases and uses them to modulate prompts without retraining, enabling adaptive reasoning. On the PrideMM dataset, FLoReNce achieves an F1-score of 0.7708 and 74% reasoning quality with minimal retrieval (K=1), outperforming static multimodal baselines. The approach bridges static reasoning and human-like adaptive understanding, demonstrating that feedback-regulated prompting is effective for nuanced, context-sensitive tasks like meme humor detection.

## Method Summary
FLoReNce employs a closed-loop reasoning architecture where a frozen Qwen2.5-VL-32B-Instruct agent generates predictions and rationales for multimodal memes, while a Judge module provides error signals and semantic critiques. These critiques are embedded via MiniLM and combined with PID controller states to form control vectors stored in a JSONL knowledge base alongside embedding vectors. During inference, retrieval of top-K similar experiences modulates the prompt through a prompt mapper, enabling adaptive reasoning without retraining. The system is evaluated on PrideMM, a dataset of 5,063 memes with image and OCR text, achieving strong performance with minimal retrieval (K=1).

## Key Results
- F1-score of 0.7708 on PrideMM dataset with K=1 retrieval
- 74% reasoning quality (RQ) demonstrating coherent rationales
- Closed-loop feedback with PID control outperforms static multimodal baselines

## Why This Works (Mechanism)
FLoReNce works by converting semantic feedback into adaptive control signals through a closed-loop system. The reasoning agent generates predictions and rationales, which are critiqued by a judge module that provides error signals and semantic embeddings. These signals are processed by a PID controller and stored in a non-parametric knowledge base. During inference, retrieval of similar past experiences allows the system to modulate prompts dynamically, bridging static reasoning with adaptive, human-like understanding of nuanced humor.

## Foundational Learning
- **PID Control**: Adjusts control signals based on error history (proportional, integral, derivative terms); needed to smooth and accumulate feedback across training samples. Quick check: verify K_P=1.0, K_I=0.5, K_D=0.1 produce stable u_t updates.
- **Knowledge Base Retrieval**: Stores (id, embedding, rationale, feedback) tuples for similarity-based lookup; needed to reuse past experiences without retraining. Quick check: compute cosine similarity distribution of top-K retrievals.
- **Prompt Modulation**: Maps control vectors to textual guidance for the reasoning agent; needed to adaptively steer reasoning without changing model weights. Quick check: ensure prompt mapper produces deterministic, meaningful instructions.

## Architecture Onboarding

**Component Map**: Reasoning Agent -> Judge -> PID Controller -> Knowledge Base <- Retrieval -> Prompt Mapper -> Reasoning Agent (inference)

**Critical Path**: Reasoning Agent (inference) <- Prompt Mapper <- Retrieval <- Knowledge Base <- PID Controller <- Judge <- Reasoning Agent (training)

**Design Tradeoffs**: Closed-loop learning with non-parametric KB avoids retraining but requires careful prompt modulation; frozen backbone limits adaptation but ensures stability.

**Failure Signatures**: Noisy or semantically dissimilar KB retrievals produce irrelevant control signals; inconsistent prompt mapping causes prediction instability; missing Judge feedback disables learning loop.

**First Experiments**:
1. Validate prompt mapper Ψ produces consistent guidance for identical control vectors.
2. Benchmark KB retrieval quality via semantic coherence of top-K samples.
3. Ablate PID components (disable K_I, K_D) to quantify their contribution.

## Open Questions the Paper Calls Out
- How can retrieval filtering be refined to distinguish satire critiquing power structures from mockery targeting marginalized groups? (Case study: "Christians vs. Gay People" failure where absurdity emphasis misaligned intent.)
- Does FLoReNce generalize across diverse meme datasets and cultural contexts beyond PrideMM? (Only evaluated on PrideMM; humor is context-sensitive.)
- Would enabling closed-loop feedback during inference improve performance over current open-loop design? (Framework switches to open-loop at inference; no ablation provided.)

## Limitations
- Key components (prompt mapper Ψ, projection function g) are underspecified, blocking faithful reproduction.
- PrideMM dataset availability and OCR preprocessing details are unclear.
- Judge module's extraction of 3D feedback vector from unstructured critique text is not specified.

## Confidence
- High confidence: Framework architecture and PID/KB specifications are clearly described.
- Medium confidence: Performance claims are credible but lack comparison to published multimodal humor baselines.
- Low confidence: Implementation of prompt mapper Ψ and projection function g cannot be verified.

## Next Checks
1. Implement and test a deterministic prompt mapper that converts control vectors to consistent textual guidance.
2. Validate KB retrieval returns semantically coherent neighbors by computing average cosine similarity and visualizing top-K samples.
3. Perform PID ablation by disabling K_I and K_D terms separately to measure their impact on performance.