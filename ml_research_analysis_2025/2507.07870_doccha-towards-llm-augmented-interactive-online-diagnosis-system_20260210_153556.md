---
ver: rpa2
title: 'DocCHA: Towards LLM-Augmented Interactive Online diagnosis System'
arxiv_id: '2507.07870'
source_url: https://arxiv.org/abs/2507.07870
tags:
- reasoning
- doccha
- diagnostic
- symptom
- history
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DocCHA addresses the challenge of static, brittle conversational
  health agents by introducing a modular, confidence-aware framework for adaptive
  multi-turn clinical diagnosis. It decomposes the diagnostic process into symptom
  elicitation, history acquisition, and causal graph construction, each guided by
  interpretable confidence scores to prioritize informative clarifications and refine
  reasoning.
---

# DocCHA: Towards LLM-Augmented Interactive Online diagnosis System

## Quick Facts
- arXiv ID: 2507.07870
- Source URL: https://arxiv.org/abs/2507.07870
- Reference count: 4
- Primary result: Outperforms prompting-based LLM baselines by up to 5.18% in diagnostic accuracy and 30% in symptom recall on Chinese clinical datasets

## Executive Summary
DocCHA addresses the challenge of static, brittle conversational health agents by introducing a modular, confidence-aware framework for adaptive multi-turn clinical diagnosis. It decomposes the diagnostic process into symptom elicitation, history acquisition, and causal graph construction, each guided by interpretable confidence scores to prioritize informative clarifications and refine reasoning. Evaluated on two real-world Chinese consultation datasets (IMCS21, DX), DocCHA significantly outperforms prompting-based LLM baselines (GPT-3.5, GPT-4o, LLaMA-3), achieving up to 5.18% higher diagnostic accuracy and over 30% improvement in symptom recall, while maintaining modest dialogue turn counts. This demonstrates the effectiveness of structured, confidence-guided reasoning in enabling transparent, efficient, and trustworthy LLM-powered clinical assistants in multilingual and resource-constrained settings.

## Method Summary
DocCHA is a modular framework for interactive clinical diagnosis that uses confidence-guided reasoning to adaptively elicit symptoms, acquire patient history, and construct causal explanations. The system decomposes the diagnostic process into three modules: symptom collection (prioritizing high-discriminative-power symptoms), history acquisition (scoring sufficiency across coverage, relevance, and certainty), and causal graph validation (grounding reasoning in medical knowledge bases). Each module computes confidence scores to determine when to continue questioning or proceed to diagnosis, with interpretable thresholds controlling dialogue length. The framework is evaluated against prompting-based LLM baselines on Chinese clinical datasets, showing significant improvements in accuracy, recall, and interpretability.

## Key Results
- Achieves up to 5.18% higher diagnostic accuracy compared to GPT-4o baseline
- Improves symptom recall by over 30% versus prompting-based approaches
- Maintains modest dialogue turn counts while significantly improving diagnostic quality
- Each module contributes measurable accuracy gains (2.0–2.4% for symptom module, 0.6–0.8% for history module, 1.6% for causal graph module)

## Why This Works (Mechanism)

### Mechanism 1: Discriminative Symptom Prioritization
- Claim: Targeting high-discriminative-power symptoms improves diagnostic accuracy per query.
- Mechanism: The system computes variance of conditional probabilities P(symptom|diagnosis) across top-K candidates, directing follow-up questions to symptoms that best differentiate competing hypotheses. Low-coverage or low-detail confidence scores trigger clarification.
- Core assumption: Symptom discriminability computed from LLM-estimated conditionals approximates true clinical diagnostic utility.
- Evidence anchors:
  - [abstract] "decomposes the diagnostic process into... symptom elicitation... guided by interpretable confidence scores to prioritize informative clarifications"
  - [section 3.1] DP(si) = Var P(si|dk); Csym = αCcov + (1-α)Cdet; ablation shows 2.0–2.4% accuracy drop without Module 1
  - [corpus] Limited direct corpus support for discriminative power in dialogue; related work (neighbor papers) focuses on structured datasets or test selection, not symptom variance scoring.
- Break condition: If candidate diagnosis set is wrong or symptom-conditionals are miscalibrated, discriminative power scores misguide questioning.

### Mechanism 2: Confidence-Weighted History Sufficiency
- Claim: Multi-dimensional history confidence scoring enables more efficient contextual probing.
- Mechanism: History acquisition scores coverage (category presence), relevance (semantic similarity to symptom/diagnosis context), and certainty (LLM-classified expression confidence). Low aggregate confidence triggers targeted follow-up on missing or vague categories.
- Core assumption: Weighted combination λ1Ccov + λ2Crel + λ3Ccert meaningfully reflects history sufficiency for diagnosis.
- Evidence anchors:
  - [abstract] "history acquisition... guided by interpretable confidence scores to... refine weak reasoning links"
  - [section 3.2] Chist = λ1Ccov + λ2Crel + λ3Ccert; ablation shows 0.6–0.8% accuracy loss and sharper cosine/relevance degradation without Module 2
  - [corpus] Neighbor papers on active test selection (arXiv 2510.18988) discuss sequential resource-aware reasoning, but do not validate this specific confidence decomposition.
- Break condition: If relevant history categories are unknown or semantic similarity fails on clinical text, sufficiency scoring degrades.

### Mechanism 3: External-Knowledge-Anchored Causal Graph Validation
- Claim: Validating causal graphs against medical knowledge bases reduces hallucinated reasoning chains.
- Mechanism: System constructs directed acyclic graphs linking symptoms/history to diagnoses, scores edges on coherence (BARTScore), medical plausibility (UMLS/SemMedDB alignment), and entailment (MedNLI). Low-scoring edges trigger clarification questions.
- Core assumption: UMLS/SemMedDB coverage is sufficient for common conditions; entailment classifiers generalize to clinical dialogue.
- Evidence anchors:
  - [abstract] "causal graph construction... refine weak reasoning links"
  - [section 3.3] Ccausal = µ1Ccoh + µ2Cmed + µ3Centail; Cmed = |E ∩ EUMLS|/|E|; ablation shows 1.6% accuracy drop and less interpretable conclusions without Module 3
  - [corpus] Related work (arXiv 2512.17559) emphasizes explainable conversational diagnosis, but does not provide external validation of graph-based entailment scoring.
- Break condition: If edges fall outside knowledge base scope or NLI classifier is unreliable on clinical language, validation provides false confidence.

## Foundational Learning

- Concept: **Information Sufficiency Scoring**
  - Why needed here: DocCHA's modules rely on confidence thresholds (τsym, τhist, τcausal) to decide when to stop questioning. Understanding how to design and calibrate sufficiency metrics is central to the framework.
  - Quick check question: Given a partial symptom set with 60% coverage and 40% detail completeness, how would you compute Csym with α=0.5?

- Concept: **Discriminability in Classification**
  - Why needed here: Symptom discriminative power (variance across candidate diagnoses) drives questioning priority. This connects to feature selection and information gain in sequential decision-making.
  - Quick check question: If symptom A appears in 90% of diagnosis d1 cases and 10% of d2 cases, versus symptom B appearing in 50% of both, which has higher discriminative power?

- Concept: **Knowledge Graph Alignment**
  - Why needed here: Module 3 validates causal edges against UMLS/SemMedDB. Understanding ontology structure and edge matching is necessary for extending or debugging this component.
  - Quick check question: If an LLM generates edge "cough → pneumonia" but UMLS only contains "cough PROCESS_OF lung infection," how should alignment be scored?

## Architecture Onboarding

- Component map:
  Patient input -> Symptom extraction -> Top-K diagnosis inference -> Module 1 (symptom collection) -> Module 2 (history acquisition) -> Module 3 (causal graph) -> Final diagnosis output with graph explanation

- Critical path:
  1. Patient input → symptom extraction → top-K diagnosis inference
  2. If Csym < τsym and quota remains → question generation (detail or coverage)
  3. If Chist < τhist and quota remains → history follow-up
  4. Construct causal graph → validate → if Ccausal < τcausal → weak-link clarification
  5. Final diagnosis output with graph explanation

- Design tradeoffs:
  - Quota vs. confidence: More turns improve recall but burden users; paper shows plateau after 5 turns
  - Weight sensitivity: α=0.5 balances coverage/detail; over-weighting either harms performance (Section 4.6)
  - Knowledge base scope: UMLS grounding improves plausibility but may miss rare or regional conditions
  - LLM backbone choice: GPT-4o outperforms LLaMA-3; open-source option trades accuracy for deployability

- Failure signatures:
  - Premature closure: High confidence on wrong diagnosis due to miscalibrated conditionals
  - Redundant questioning: Symptom DP scores uniform across candidates, leading to unfocused probing
  - Graph hallucination: Edges pass coherence but fail entailment or KB check, triggering excessive clarification
  - History drift: Low-certainty responses dilute relevance signal, reducing diagnostic clarity

- First 3 experiments:
  1. **Threshold sweep**: Vary τsym, τhist, τcausal on a held-out subset to calibrate stopping criteria for your target dialogue budget.
  2. **Backbone ablation**: Run DocCHA with GPT-4o vs. LLaMA-3 vs. a domain-tuned model (e.g., BioGPT) to measure accuracy/turn tradeoffs.
  3. **Knowledge base extension**: Augment UMLS/SemMedDB with a specialty ontology (e.g., dermatology) and evaluate Cmed improvement on domain-specific cases.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to Chinese-language clinical datasets, raising uncertainty about generalization to other languages or clinical domains
- Reliance on UMLS/SemMedDB assumes comprehensive coverage of common conditions, but rare or region-specific diagnoses may fall outside knowledge base
- Confidence thresholds were not optimized through systematic calibration, and their sensitivity to dialogue length and user verbosity remains unclear
- Causal graph construction still depends on LLM-generated edges that may not fully capture complex clinical reasoning chains

## Confidence
**High confidence**: The modular architecture and confidence-guided reasoning approach is sound, with clear ablation evidence showing each component contributes measurable accuracy gains (2.0–2.4% for Module 1, 0.6–0.8% for Module 2, 1.6% for Module 3). The performance improvements over baseline LLM prompting are statistically significant and substantial.

**Medium confidence**: The claim that symptom discriminative power computed via conditional variance approximates true clinical diagnostic utility is reasonable but not directly validated against expert clinician questioning patterns. The sufficiency scoring weights (α=0.5, λ1/2/3, μ1/2/3) are reported but their optimality for different clinical scenarios is not established.

**Low confidence**: The generalizability of the approach to non-Chinese clinical settings, rare diseases, or outpatient contexts with different diagnostic workflows remains untested. The robustness of the NLI-based entailment scoring for clinical dialogue is not validated on diverse medical language patterns.

## Next Checks
1. **Threshold Calibration Study**: Systematically vary τsym, τhist, and τcausal across the full range [0,1] on a held-out validation set to identify optimal stopping criteria that balance diagnostic accuracy with dialogue efficiency. Measure how different threshold combinations affect average turns per diagnosis and user satisfaction.

2. **Cross-Domain Generalization Test**: Evaluate DocCHA on English-language clinical dialogue datasets (e.g., medical forums, telehealth transcripts) or a different specialty (e.g., dermatology, pediatrics) to assess performance degradation and identify which components require adaptation for new clinical contexts.

3. **Knowledge Base Coverage Analysis**: Conduct a systematic audit of UMLS/SemMedDB coverage for the IMCS21 and DX datasets, identifying which diagnoses and symptom relationships fall outside the knowledge base. Measure the impact on Cmed scores and determine whether augmenting with specialty ontologies improves diagnostic accuracy for uncovered conditions.