---
ver: rpa2
title: 'Lost in Embeddings: Information Loss in Vision-Language Models'
arxiv_id: '2509.11986'
source_url: https://arxiv.org/abs/2509.11986
tags:
- loss
- image
- embeddings
- reconstruction
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper quantifies information loss in vision-language model
  (VLM) connectors by analyzing latent representation spaces. The authors introduce
  two complementary approaches: (1) k-nearest neighbors overlap ratio to measure geometric
  preservation before/after projection, and (2) patch-level embedding reconstruction
  to localize visual information loss.'
---

# Lost in Embeddings: Information Loss in Vision-Language Models

## Quick Facts
- arXiv ID: 2509.11986
- Source URL: https://arxiv.org/abs/2509.11986
- Reference count: 16
- Key outcome: Connectors substantially distort local geometry (40-60% k-NN divergence), with patch-level reconstruction loss predicting model failures in visually grounded QA tasks.

## Executive Summary
This paper quantifies information loss in vision-language model (VLM) connectors by analyzing latent representation spaces. The authors introduce two complementary approaches: (1) k-nearest neighbors overlap ratio to measure geometric preservation before/after projection, and (2) patch-level embedding reconstruction to localize visual information loss. Experiments across three connector-based VLMs (LLaVA, Idefics2, Qwen2.5-VL) on six datasets show that connectors substantially distort local geometry, with k-nearest neighbors diverging by 40-60% post-projection, correlating with retrieval performance degradation. Patch-level reconstruction reveals that areas of high information loss predict model failures in visually grounded question answering tasks. LLaVA and Idefics2 show reconstruction loss negatively impacts captioning and QA performance, while Qwen2.5-VL's different training approach yields more semantically meaningful representations despite geometric divergence.

## Method Summary
The paper quantifies information loss in VLM connectors through two approaches: (1) k-nearest neighbors overlap ratio (KNOR) measuring geometric preservation by computing the intersection of neighbor sets before and after projection, and (2) patch-level embedding reconstruction where a probe model attempts to invert the connector mapping to recover original vision embeddings. The method uses three VLMs—LLaVA-7B-instruct, Idefics2-8B-instruct, and Qwen2.5-VL-7B-instruct—evaluating on SEED-Bench, VizWiz Grounding VQA, VQAv2, CUB-200-2011, Flickr30k, and COCO Karpathy test. Reconstruction models are trained on COCO 2017 train set to map projected embeddings back to original patches, with loss measured as per-patch squared L2 distance. Downstream correlations examine how reconstruction loss relates to captioning CIDEr scores and VQA accuracy.

## Key Results
- k-NN overlap ratios drop 40-60% post-projection across all connectors, with Qwen2.5-VL showing severe divergence (~10%) due to continuous training approach
- High patch-level reconstruction loss correlates with wrong answers in VQA tasks, particularly for LLaVA and Idefics2
- Qwen2.5-VL achieves better retrieval performance despite geometric collapse, suggesting semantic refocusing rather than preservation
- Idefics2's Perceiver compression (576→64 tokens) shows highest information loss but acceptable downstream performance
- Reconstruction loss negatively impacts captioning and QA performance for frozen-encoder models but not for Qwen2.5-VL

## Why This Works (Mechanism)

### Mechanism 1: k-Nearest Neighbors Overlap Ratio (KNOR)
If a connector preserves the local geometry of visual embeddings, the k-nearest neighbors of an image pre-projection should significantly overlap with those post-projection. The method measures the intersection of neighbor sets N_I_ψ (pre-connector) and N_I_C (post-connector). High overlap implies structural preservation; low overlap implies "geometric collapse" or distortion where distinct features become entangled. The core assumption is that the semantic utility of visual features depends on maintaining relative distances established by the pre-trained vision encoder. Evidence shows LLaVA overlap ratios around 50-60%, while Qwen2.5-VL drops to ~10%, indicating massive restructuring. Break condition: If the vision encoder is trained continuously (unfrozen) alongside the connector, the "pre-projection" geometry is no longer the ground truth, making high divergence potentially beneficial rather than a failure mode.

### Mechanism 2: Patch-Level Embedding Reconstruction
If a connector discards visual information, a reconstruction model trained to invert the connector mapping will fail specifically at "high-loss" patches, correlating with reasoning errors. A probe model f_θ attempts to reconstruct original vision embeddings ψ(x) from projected embeddings C(ψ(x)), with squared Euclidean distance (L_patch) serving as a proxy for information density. The core assumption is that the reconstruction model has sufficient capacity to recover information if it exists; therefore, high reconstruction loss implies the information was destroyed by the connector compression, not just hard to decode. Evidence shows "areas of high information loss predict model failures in visually grounded question answering tasks." Break condition: If the connector performs a non-linear "semantic refocusing" rather than literal preservation, pixel/patch-level reconstruction error may falsely signal "loss" when it is actually "abstraction."

### Mechanism 3: Semantic Refocusing vs. Preservation
Connectors that aggressively compress or reshape geometry (low KNOR) can still perform well if the projection reorganizes features into a more semantically meaningful space for the LLM. Qwen2.5-VL uses a patch merger and continuous training, destroying original k-NN structure but improving retrieval and QA by creating a new representation space tailored to the language model. The core assumption is that the pre-trained vision encoder's geometry is not the optimal input structure for the language model, necessitating a "destructive" but useful transformation. Evidence shows Qwen2.5-VL achieves improved retrieval with post-projection embeddings despite a 90% loss of original neighbor ranking. Break condition: If the downstream task relies on fine-grained texture or exact spatial relationships rather than semantic gist, this aggressive semantic refocusing may destroy necessary signal details.

## Foundational Learning

- **Vision Encoders & Latent Space**: Models like CLIP/ViT map images to fixed vector spaces where distance implies similarity. You must understand that this paper measures what happens when you warp that space. Quick check: If two images have cosine similarity 0.9 in the vision encoder space, what does a drop to 0.5 after the connector imply about their "closeness"?

- **Probe-based Analysis (Reconstruction)**: The paper uses auxiliary models (probes) to measure information content. You need to distinguish between the VLM's performance and the probe's ability to measure it. Quick check: Why did the authors use a larger model for reconstruction than the original connector?

- **Information Bottlenecks**: Connectors often compress sequence length (e.g., Idefics2 576→64 tokens). Understanding the trade-off between efficiency and information capacity is central to the analysis. Quick check: Does the paper conclude that compression connectors are strictly worse than preserving connectors for all tasks?

## Architecture Onboarding

- **Component map**: Image → Patches → Connector Projection → LLM
- **Critical path**: The Connector is the bottleneck. The flow is: Image → Patches → Connector Projection → LLM. The paper quantifies the distortion at the arrow between "Patches" and "Connector Projection."
- **Design tradeoffs**:
  - Feature-Preserving (LLaVA): High reconstruction fidelity, but may carry redundant noise into the LLM context window
  - Feature-Compressing (Idefics2): Efficient context, but high patch-level information loss and geometric distortion
  - Semantic-Refocusing (Qwen): Destroys original geometry but creates better semantic features; requires expensive end-to-end training
- **Failure signatures**:
  - Geometric Collapse: k-NN overlap drops below ~45% (for frozen encoders), correlating with retrieval failure
  - Local Blindness: High reconstruction loss in specific image patches correlates with wrong answers in VQA
- **First 3 experiments**:
  1. Compute k-NN overlap ratio: for each image, find k nearest neighbors in both embedding spaces using L2 distance, compute intersection-over-k, average across dataset
  2. Train reconstruction model to map post-connector embeddings back to pre-connector embeddings. Validate that it learns (loss goes down)
  3. Run VQA on VizWiz. Overlay the reconstruction error heatmap onto the image. Check if the model's hallucination or error aligns with high-loss patches

## Open Questions the Paper Calls Out

### Open Question 1
Can reconstruction loss be incorporated as a regularization signal during VLM pretraining to reduce connector-induced information loss? The authors state: "the reconstruction loss at the embedding level could potentially be incorporated during model pretraining as regularization." This remains unresolved as the study only analyzes pretrained models post-hoc and does not train any models with reconstruction-based objectives.

### Open Question 2
Does the relationship between connector information loss and downstream performance generalize to cross-attention-based VLM architectures? The limitations section notes "our findings may be specific to the connector-based VLMs analyzed and may not generalize to architectures that employ cross-attention for modality fusion." This remains unresolved as the study exclusively evaluates connector-based models and excludes cross-attention models like BLIP and Llama 3.2.

### Open Question 3
Does model scale systematically affect the magnitude or nature of connector information loss? The limitations section states: "Expanding the analysis to models of different sizes could provide deeper insights into the relationship between model scale and information loss." This remains unresolved as all evaluated models fall within the narrow 7B–8B parameter range.

## Limitations
- Results are based on three specific connector designs and may not generalize to other connector types like attention-based or learned routing architectures
- The study exclusively evaluates connector-based models and does not test cross-attention architectures like BLIP or Llama 3.2
- All evaluated models fall within a narrow 7B–8B parameter range, limiting insights into scale-dependent effects

## Confidence
- **High confidence**: k-NN overlap ratio is a valid geometric distortion metric for frozen-encoder VLMs; high reconstruction loss correlates with QA failures in LLaVA/Idefics2
- **Medium confidence**: Geometric preservation is necessary but not sufficient for downstream performance; connector design choices significantly impact information retention
- **Low confidence**: The KNOR metric generalizes to models with continuous training (Qwen2.5-VL); patch-level reconstruction loss is a universal proxy for task-relevant information loss

## Next Checks
1. Test whether KNOR correlation with performance holds for tasks requiring semantic refocusing (e.g., multi-hop reasoning, scene graph generation) beyond VQA and retrieval
2. Repeat reconstruction experiments with smaller probes (closer in size to connectors) to determine if loss patterns are probe-dependent or intrinsic to connectors
3. Systematically compare information preservation across connector types (MLP, Perceiver, patch merger) while controlling for compression ratio to isolate architectural effects