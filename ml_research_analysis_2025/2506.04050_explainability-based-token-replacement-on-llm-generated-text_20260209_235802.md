---
ver: rpa2
title: Explainability-Based Token Replacement on LLM-Generated Text
arxiv_id: '2506.04050'
source_url: https://arxiv.org/abs/2506.04050
tags:
- text
- detection
- ensemble
- token
- rewriting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how XAI methods can reduce AI-generated
  text (AIGT) detectability through token replacement. The authors develop an ensemble
  classifier and use SHAP/LIME to identify influential tokens for modification via
  four strategies: synonym replacement, POS-constrained substitution, GPT-based replacement,
  and GPT-based replacement with genre context.'
---

# Explainability-Based Token Replacement on LLM-Generated Text

## Quick Facts
- arXiv ID: 2506.04050
- Source URL: https://arxiv.org/abs/2506.04050
- Reference count: 40
- Key outcome: XAI-guided token replacement significantly reduces single-model AIGT detection (F1 from 0.81→0.25), while ensemble classifier maintains robust performance across languages/domains

## Executive Summary
This paper investigates whether explainability methods can reduce AI-generated text detectability through targeted token replacement. The authors develop an ensemble classifier combining frozen transformers pre-trained on AuTexTification data with fresh models fine-tuned on domain-specific CLIN33 data. Using SHAP and LIME, they identify influential tokens for replacement via four strategies: synonym substitution, POS-constrained substitution, GPT-based replacement, and GPT-based replacement with genre context. Results show XAI-guided attacks can dramatically reduce single-model accuracy while the ensemble maintains superior robustness. Human evaluators achieved only 47% detection accuracy on rewritten texts, demonstrating the effectiveness of this approach.

## Method Summary
The authors create an ensemble classifier combining six transformers (3 frozen, 3 fresh) with a dense meta-classifier. They use SHAP and LIME to identify influential tokens in correctly classified AI texts, then replace these tokens using four strategies: HSR (Word2Vec synonyms), PSR (POS-constrained synonyms), GPT-based replacement, and GPT+Genre. The framework is evaluated on CLIN33 dataset (English/Dutch, 3 domains) against their ensemble and individual models, measuring detection metrics (F1, accuracy) and textual fidelity (BLEU, ROUGE).

## Key Results
- XAI-guided token replacement reduces single-model detection accuracy significantly (XGBoost F1 drops 56pp from 0.81 to 0.25 under LIME+HSR)
- Ensemble classifier maintains robust performance across languages and domains, with maximum 19pp drop under adversarial conditions
- Human evaluators achieved only 47% detection accuracy on rewritten AIGT texts
- More aggressive rewriting doesn't guarantee better evasion; HSR/PSR maintain high BLEU (>0.90) while achieving strong evasion

## Why This Works (Mechanism)

### Mechanism 1: XAI-Guided Token Selection Improves Evasion Efficiency
Targeting influential tokens identified by SHAP/LIME causes larger detection drops than random replacement with fewer modifications. SHAP computes Shapley values measuring each token's marginal contribution; LIME fits local linear approximations. Both identify which tokens the detector relies on most heavily. Replacing these high-importance tokens removes the detector's primary decision signals while leaving most text unchanged.

### Mechanism 2: Ensemble Diversity Provides Redundant Detection Pathways
Multi-model ensembles resist token-level attacks because different architectures rely on different features; when one component fails, others may succeed. The ensemble combines frozen models (pre-trained on diverse AuTexTification data) and fresh models (fine-tuned on domain-specific augmented CLIN33). Different architectures (BERT-base, DistilBERT, XLM-RoBERTa) have different attention patterns and inductive biases, leading to uncorrelated failure modes.

### Mechanism 3: Trade-off Between Textual Fidelity and Evasion Success
More aggressive rewriting doesn't guarantee better evasion; conservative POS-constrained replacements can achieve strong evasion while preserving more original text. HSR/PSR use Word2Vec synonyms with part-of-speech constraints, making minimal surface changes (BLEU 0.90-0.97). GPT-based methods paraphrase more extensively (BLEU 0.76-0.86). However, LLM-based rewriting may introduce new AI-detectable patterns, creating diminishing returns.

## Foundational Learning

- Concept: SHAP (SHapley Additive exPlanations)
  - Why needed here: Core mechanism for identifying which tokens drive detector predictions through game-theoretic credit assignment
  - Quick check question: Why does SHAP require computing predictions across all possible token subsets, and what does this mean computationally for 512-token texts?

- Concept: Token-level adversarial attacks
  - Why needed here: This paper's threat model—adversaries identify and modify specific tokens to evade detection
  - Quick check question: How does this XAI-based attack (requires only model predictions) differ from gradient-based white-box attacks that require internal model access?

- Concept: Ensemble learning with heterogeneous architectures
  - Why needed here: The defense relies on combining models with different inductive biases to create uncorrelated failure modes
  - Quick check question: Why might BERT, DistilBERT, and XLM-RoBERTa produce different error patterns on the same adversarial examples even when trained on similar data?

## Architecture Onboarding

- Component map:
  - Frozen branch: 3 transformers (BERT-base-multilingual, DistilBERT-multilingual, XLM-RoBERTa-base) pre-trained on AuTexTification, weights locked (~454M params)
  - Fresh branch: 3 transformers of same types, fine-tuned on augmented CLIN33, weights trainable (~454M params)
  - Meta-classifier: Concatenate 6 representations → Dense layer with L2 regularization → Sigmoid
  - XAI module: SHAP/LIME applied post-training to identify influential tokens
  - Rewriting module: 4 strategies (HSR: Word2Vec synonyms; PSR: POS-constrained synonyms; GPT: context-aware; GPT+Genre: domain-aware)

- Critical path:
  1. Pre-train frozen models on AuTexTification (33,845 English samples across tweets/legal/wiki)
  2. Freeze weights, initialize fresh models with same architectures
  3. Train full ensemble on augmented CLIN33 (9,720 samples, English + Dutch, news/reviews/Twitter)
  4. For adversarial testing: SHAP/LIME → rank tokens by importance → replace top-K → evaluate

- Design tradeoffs:
  - Frozen vs. fresh ratio: More frozen improves cross-domain generalization; more fresh improves target-domain accuracy
  - Replacement aggressiveness: HSR/PSR (BLEU >0.90) vs. GPT-based (BLEU 0.76-0.86)—higher fidelity vs. potentially better evasion
  - Ensemble size vs. cost: 908M total params, ~200ms inference, 16GB GPU memory vs. single-model ~50-100ms

- Failure signatures:
  - Single models: XGBoost F1 drops 56pp (0.81→0.25) under LIME+HSR; BERT drops 18pp
  - Ensemble: Maximum 19pp drop under LIME+HSR, demonstrating robustness
  - XLM-RoBERTa: Overpredicts AI (recall ≈1.0, precision ≈0.52), giving artificially low flip rates—don't use flip rate alone as robustness metric
  - Human evaluators: Only 47% detection accuracy on rewritten texts

- First 3 experiments:
  1. **Baseline replication**: Train individual BERT/DistilBERT/XLM-RoBERTa on CLIN33, verify performance matches Table 4 (English avg F1: 0.81, 0.84, 0.68)
  2. **Ablation study**: Remove one ensemble component at a time, measure F1 drop under adversarial conditions to quantify each model's contribution
  3. **Token count sensitivity**: Systematically vary K (tokens replaced) from 1-20% to characterize the fidelity-evasion curve and identify optimal modification levels

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the XAI-guided token replacement framework perform on text generated by newer LLMs such as Claude or Llama 3?
  - Basis: Content from newer models "may exhibit different patterns" affecting vulnerability
  - Why unresolved: Current study restricted to GPT-4, Vicuña-13B, and BLOOM-series models
  - Evidence needed: Evaluation on Claude and Llama 3 outputs

- **Open Question 2**: What is the optimal number of tokens to replace that balances maximum detection evasion with minimal semantic degradation?
  - Basis: Sensitivity analysis notes "systematic parameter sweep across different token counts was not conducted"
  - Why unresolved: Experiments relied on importance thresholds rather than systematically varying token count
  - Evidence needed: Ablation study varying replaced tokens against detection F1 and textual fidelity metrics

- **Open Question 3**: Do these token replacement strategies transfer effectively to languages with complex morphological structures?
  - Basis: Generalization to languages with different morphological structures "remains to be demonstrated"
  - Why unresolved: Evaluation limited to English and Dutch with similar structural properties
  - Evidence needed: Testing on morphologically rich languages (Finnish, Arabic) to assess cross-linguistic robustness

## Limitations

- **Unknown attack threshold parameters**: Token replacement uses "importance threshold rather than fixed count" but provides no numeric values, making exact reproduction impossible
- **GPT implementation specifics**: GPT-4o-mini with "genre context" lacks prompt templates, temperature settings, or max token parameters
- **XAI parameter sensitivity**: SHAP/LIME implementations use unspecified perturbation counts, background datasets, and kernel parameters

## Confidence

- **High confidence (⭐⭐⭐)**: Core finding that XAI-guided token replacement significantly reduces single-model detection accuracy (XGBoost F1 from 0.81→0.25) is well-supported
- **Medium confidence (⭐⭐)**: Mechanism explaining why XAI-guided attacks outperform random replacement relies on assumption about token concentration; supported by Zhou et al. but specific claim lacks direct verification
- **Low confidence (⭐)**: Trade-off claim between textual fidelity and evasion success based on limited direct evidence; "diminishing returns" pattern suggested but not systematically characterized

## Next Checks

1. **Parameter recovery**: Contact authors to obtain specific numeric values for (a) token replacement thresholds used in experiments, (b) Word2Vec hyperparameters (dimension, window size, min count), and (c) SHAP/LIME perturbation parameters

2. **Baseline ablation**: Systematically vary the number of tokens replaced (1, 5, 10, 15, 20) and measure detection accuracy and textual fidelity (BLEU/ROUGE) to characterize the full fidelity-evasion trade-off curve

3. **Cross-dataset robustness**: Evaluate the ensemble and individual models on the AuTexTification English test set (separate from pretraining data) under identical adversarial conditions to test generalization beyond CLIN33 domain