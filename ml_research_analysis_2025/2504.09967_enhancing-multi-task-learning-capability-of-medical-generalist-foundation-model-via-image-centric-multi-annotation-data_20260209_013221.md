---
ver: rpa2
title: Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model
  via Image-centric Multi-annotation Data
arxiv_id: '2504.09967'
source_url: https://arxiv.org/abs/2504.09967
tags:
- data
- medical
- imax
- training
- multi-task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces IMAX, the first image-centric multi-annotation\
  \ X-ray dataset designed to enhance multi-task learning capabilities of medical\
  \ foundation models. Unlike traditional decentralized multi-annotation data, IMAX\
  \ centralizes image-centric annotations across seven medical tasks\u2014calculation,\
  \ report generation, multi-class classification, multi-label classification, referring\
  \ expression comprehension and generation, and visual question answering\u2014ensuring\
  \ comprehensive image understanding."
---

# Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data

## Quick Facts
- **arXiv ID:** 2504.09967
- **Source URL:** https://arxiv.org/abs/2504.09967
- **Reference count:** 40
- **Primary result:** IMAX achieves 3.20%–21.05% average performance gains over decentralized multi-annotation data (DMAX).

## Executive Summary
This study introduces IMAX, the first image-centric multi-annotation X-ray dataset designed to enhance multi-task learning capabilities of medical foundation models. Unlike traditional decentralized multi-annotation data, IMAX centralizes image-centric annotations across seven medical tasks—calculation, report generation, multi-class classification, multi-label classification, referring expression comprehension and generation, and visual question answering—ensuring comprehensive image understanding. Experiments on seven open-source state-of-the-art medical MLLMs demonstrate that IMAX achieves 3.20%–21.05% average performance gains over decentralized multi-annotation data (DMAX), validating the effectiveness of image-centric data construction in fostering multi-task synergy. Analysis of Fisher information matrix eigenvalues reveals that IMAX training concentrates parameter updates along critical optimization directions, leading to significant improvements in multi-task evaluation metrics. Additionally, a three-stage DMAX-based training strategy leveraging pseudo-label generation is proposed to address practical challenges in acquiring high-quality IMAX data.

## Method Summary
The study constructs IMAX by merging seven task-specific datasets (CXP, CXR-Cardiomegaly, MIMIC-CXR-PE-Severity, CXR-LT, CheXmask, MIMIC-Ext-MIMIC-CXR-VQA) into a single image-centric format, ensuring each X-ray has annotations across multiple tasks. A unified MLLM architecture (EVA-CLIP ViT-G/14 + 2-layer MLP + LLaMA2-Chat 7B) is fine-tuned on this data using LoRA (rank 8) for 3 epochs. The DMAX baseline is created by sampling decentralized data to match IMAX task volumes. The three-stage pseudo-labeling strategy involves training on DMAX, generating synthetic IMAX annotations, and fine-tuning on the pseudo-IMAX data.

## Key Results
- IMAX achieves 3.20%–21.05% average performance gains over DMAX across seven tasks
- Fisher Information Matrix analysis shows IMAX training concentrates updates along critical optimization directions
- Three-stage pseudo-labeling strategy recovers ~16.25% relative gains from DMAX data
- Multi-task synergy improves model robustness and reduces catastrophic forgetting

## Why This Works (Mechanism)

### Mechanism 1: Optimization Direction Concentration (Fisher Information)
The image-centric structure aligns parameter updates more effectively with critical optimization directions compared to decentralized data. By presenting multiple task gradients for the same image, training increases the Dominant Eigenvalue Ratio and lowers Spectral Entropy of the Fisher Information Matrix, suggesting updates concentrate along high-information eigenvectors rather than scattering across conflicting directions.

### Mechanism 2: Semantic Grounding via Multi-Task Co-occurrence
Associating diverse task labels (e.g., bounding boxes, reports, calculations) with a single image forces the model to develop a unified internal representation. This "image-centric" structure acts as a strong regularizer, preventing the model from optimizing for one task using shortcut features that would fail other tasks on the same pixel space.

### Mechanism 3: Synthetic Data Recovery (Pseudo-Labeling)
The benefits of image-centric data can be partially recovered from DMAX using a three-stage pseudo-labeling strategy. A model trained on DMAX generates "pseudo" annotations for missing tasks, and training on this synthetic IMAX data allows the model to approximate the "concentrated optimization" dynamics of real IMAX data.

## Foundational Learning

- **Concept: Fisher Information Matrix (FIM) & Eigenvalues**
  - **Why needed here:** The paper uses FIM spectral properties to explain why the model learns better. You need to understand that high eigenvalues = important learning directions, and "concentrating" updates there is efficient.
  - **Quick check question:** If the FIM eigenvalues were uniformly distributed (flat spectrum), what would that imply about the model's gradient directions? (Answer: They are scattered/noisy, lacking clear optimization direction).

- **Concept: Multi-Task Learning (MTL) Conflicts**
  - **Why needed here:** Aggregating data naively causes conflicts (gradients pulling weights in opposite directions). This paper argues "image-centric" data resolves this by unifying the visual representation.
  - **Quick check question:** Why might adding a "report generation" task hurt "disease classification" accuracy in a standard setup? (Answer: Conflicting gradients or overfitting to text features irrelevant to the classification label).

- **Concept: Data-centric AI vs. Model-centric AI**
  - **Why needed here:** This is a "data-centric" paper. It fixes the dataset structure rather than inventing a new neural network architecture.
  - **Quick check question:** In this context, what is the difference between "scaling data" (more images) vs. "densifying data" (more annotations per image)?

## Architecture Onboarding

- **Component map:** X-ray Image → EVA-CLIP ViT-G/14 (frozen) → 2-layer MLP (trainable) → LLaMA2-Chat 7B (trainable via LoRA, rank=8)
- **Critical path:**
  1. **Data Curation (Hardest Step):** Aligning 7 distinct task datasets to a single image ID set (IMAX). Without this overlap, the mechanism fails.
  2. **Prompt Engineering:** Designing the `[calculate]`, `[caption]`, `[cls]`, `[rec]`, `[reg]` tokens to switch modes.
  3. **Joint Training:** Simultaneous batching of all 7 tasks.

- **Design tradeoffs:**
  - **IMAX (High Quality)** vs. **DMAX + Pseudo-labels (Low Cost):** IMAX requires manual alignment/collection of expensive multi-task labels. The 3-stage strategy is cheaper but yields lower absolute performance (16% gain vs 29% gain).
  - **Freezing Vision Encoder:** Speeds up training and prevents catastrophic forgetting of low-level features, but may limit adaptation to X-ray specifics.

- **Failure signatures:**
  - **Mode Collapse:** The model ignores the task prompt (e.g., generates a report when asked for a bounding box).
  - **Gradient Conflict:** Loss curves oscillate wildly without convergence.
  - **FIM Anomaly:** High Spectral Entropy ($SE$) persists throughout training, indicating the model is not finding a unified representation.

- **First 3 experiments:**
  1. **Sanity Check (DMAX vs. IMAX):** Fine-tune the unified MLLM on the DMAX subset vs. the IMAX subset. Verify the ~3-20% delta in average metrics exists.
  2. **FIM Dynamics Probe:** Calculate and plot the spectral entropy ($SE$) at 4 checkpoints (Initial, Early, Mid, Late). Confirm that IMAX training results in lower entropy than DMAX.
  3. **Pseudo-Label Ablation:** Implement the 3-stage pipeline. Generate pseudo-labels for the DMAX test set and measure the quality of these synthetic annotations against the ground truth IMAX labels to identify error propagation.

## Open Questions the Paper Calls Out

- **Can the image-centric multi-annotation framework effectively scale to 3D medical modalities such as CT and MRI?**
  - **Basis in paper:** The conclusion explicitly states future directions include "extending the concept of image-centric multi-annotation data to 3D medical modalities (e.g., CT and MRI)."
  - **Why unresolved:** The current study is restricted to 2D chest X-rays; 3D modalities introduce volumetric complexity and significantly higher dimensionality in both data and potential annotations.
  - **What evidence would resolve it:** Experiments applying the IMAX construction protocol to 3D datasets to verify if similar multi-task synergies and performance gains persist.

- **Is the observed reduction in Fisher Information Matrix (FIM) spectral entropy a causal driver of performance improvements or merely a statistical correlation?**
  - **Basis in paper:** The authors use FIM eigenvalues to hypothesize that IMAX concentrates optimization along critical directions, but note that systematically assessing this impact in MTL is "methodologically challenging."
  - **Why unresolved:** The paper establishes a link between the data structure and optimization dynamics but does not isolate the spectral properties as the definitive mechanism for the accuracy gains.
  - **What evidence would resolve it:** Ablation studies where optimization trajectories are artificially manipulated to test if enforcing lower spectral entropy directly causes better multi-task convergence.

- **How does the IMAX data construction strategy perform in more complex, heterogeneous clinical scenarios beyond the current benchmark sets?**
  - **Basis in paper:** The conclusion identifies "exploring efficient multi-task learning... in more complex mixed scenarios" as a necessary future step.
  - **Why unresolved:** The current evaluation relies on specific open-source benchmarks which may not fully represent the noise, domain shifts, and task conflicts present in real-world deployment.
  - **What evidence would resolve it:** Evaluation of IMAX-trained models on external, multi-domain test sets that combine data from diverse hospitals and imaging protocols.

## Limitations
- The Fisher Information Matrix analysis, while theoretically sound, lacks direct empirical validation specific to medical MLLMs
- The quality and noise levels in pseudo-labels are not thoroughly analyzed, which is critical for the three-stage strategy's effectiveness
- The study focuses on chest X-rays and may not generalize to more complex or heterogeneous clinical scenarios

## Confidence
- **High:** The existence of IMAX dataset, the unified architecture design, and the observed performance gains over DMAX baselines are directly verifiable
- **Medium:** The Fisher Information Matrix analysis and its interpretation as "concentrated optimization" are plausible but require domain-specific validation
- **Medium:** The three-stage pseudo-labeling strategy is methodologically sound, but its practical effectiveness depends on teacher model quality

## Next Checks
1. **FIM Spectral Dynamics Validation:** Calculate and plot FIM spectral entropy at multiple training checkpoints for both IMAX and DMAX conditions. Confirm that IMAX consistently shows lower entropy and higher dominant eigenvalue ratios throughout training.
2. **Pseudo-Label Quality Assessment:** Generate pseudo-labels for a held-out DMAX subset and measure their accuracy against ground truth IMAX labels. Analyze error patterns to determine if the strategy reinforces shortcuts or hallucinations.
3. **Task-Specific Synergy Analysis:** Design experiments that isolate individual task pairs to identify which combinations show genuine synergy versus those that conflict. This will validate the assumption that image-centric data resolves MTL conflicts.