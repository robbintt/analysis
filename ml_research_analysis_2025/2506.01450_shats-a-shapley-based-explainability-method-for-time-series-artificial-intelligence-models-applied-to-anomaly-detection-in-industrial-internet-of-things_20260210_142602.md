---
ver: rpa2
title: 'ShaTS: A Shapley-based Explainability Method for Time Series Artificial Intelligence
  Models applied to Anomaly Detection in Industrial Internet of Things'
arxiv_id: '2506.01450'
source_url: https://arxiv.org/abs/2506.01450
tags:
- shats
- data
- grouping
- time
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces ShaTS, a Shapley-based explainable AI method
  for time series models, addressing the need for accurate and actionable anomaly
  detection explanations in Industrial Internet of Things environments. Traditional
  Shapley-based methods often overlook temporal dependencies, leading to imprecise
  explanations.
---

# ShaTS: A Shapley-based Explainability Method for Time Series Artificial Intelligence Models applied to Anomaly Detection in Industrial Internet of Things

## Quick Facts
- arXiv ID: 2506.01450
- Source URL: https://arxiv.org/abs/2506.01450
- Reference count: 32
- Key outcome: ShaTS outperforms conventional SHAP in identifying critical time instants and sensors/actuators affected by anomalies while maintaining sub-second execution times.

## Executive Summary
ShaTS is a Shapley-based explainable AI method designed to provide accurate and actionable explanations for anomaly detection in Industrial Internet of Things environments. Traditional Shapley-based methods often overlook temporal dependencies, leading to imprecise explanations. ShaTS addresses this by incorporating a priori feature grouping to preserve temporal structure, offering three grouping strategies: Temporal, Feature, and Multi-Feature. Evaluated on the SWaT dataset, ShaTS demonstrates superior performance in identifying affected time instants and sensors while maintaining computational efficiency suitable for real-time deployment.

## Method Summary
ShaTS is a model-agnostic Shapley value computation method that incorporates a priori feature grouping to preserve temporal dependencies in time series data. The method processes time series data through windowing (size 10, stride configurable), applies a stacked bidirectional LSTM AD model trained with Focal Loss, and computes Shapley values using stratified sampling approximation with m = 20·|G| subsets. Three grouping strategies are implemented: Temporal (10 groups for time steps), Feature (44 groups for sensors/actuators), and Multi-Feature (6 groups for industrial processes). The background dataset contains 500 stratified samples for conditional expectation estimation.

## Key Results
- ShaTS correctly identified attacked sensors in 14/21 cases versus 6/21 for post hoc SHAP
- ShaTS identified affected processes in 19/21 cases versus 8/21 for post hoc SHAP
- ShaTS maintained sub-second execution times while KernelSHAP exceeded real-time thresholds

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A priori feature grouping produces more precise and actionable explanations than post hoc aggregation of individual feature attributions.
- **Mechanism:** ShaTS groups features before computing Shapley values by treating each group as a single "player" in the cooperative game formulation. This preserves temporal and functional relationships because the marginal contribution of a group is evaluated holistically across all coalition subsets.
- **Core assumption:** Features within a group share a coherent causal or functional relationship that should be attributed collectively.
- **Evidence anchors:** Abstract states ShaTS "incorporates an a priori feature grouping strategy that preserves temporal dependencies"; Section 4.3.2 describes three grouping strategies where each group is treated as a unit before value computation.
- **Break condition:** If grouped features have weak or conflicting contributions that should be disambiguated, a priori grouping may obscure individual feature effects.

### Mechanism 2
- **Claim:** Computing Shapley values over feature groups rather than individual features reduces computational complexity from O(2^N) to O(2^|G|), enabling real-time deployment.
- **Mechanism:** By reducing the number of "players" from N individual features to |G| groups, the number of coalition evaluations drops exponentially. ShaTS uses stratified sampling to approximate values with m = 20·|G| subsets rather than all 2^|G| coalitions.
- **Core assumption:** The sampling approximation converges sufficiently for the explainability task; small groups (|G| = 6–44 in experiments) make this tractable.
- **Evidence anchors:** Section 4.3.3 describes the exact method involving 2^|G|−1 coalitions and the approximation method using stratified sampling; Figure 9-10 show ShaTS maintaining sub-second execution times while KernelSHAP exceeds real-time thresholds.
- **Break condition:** If |G| grows large (e.g., hundreds of groups), even the approximation may exceed real-time constraints.

### Mechanism 3
- **Claim:** Different grouping strategies provide complementary, multi-scale explanatory views (when, what, where) that together enable targeted operational interventions.
- **Mechanism:** Temporal grouping isolates critical time instants; Sensor/Actuator grouping pinpoints specific devices; Process grouping localizes anomalies to industrial stages. Operators can triage at process level, then drill down.
- **Core assumption:** Domain knowledge exists to define meaningful groupings (e.g., which sensors belong to which process).
- **Evidence anchors:** Table 4 shows ShaTS correctly identified attacked sensors in 14/21 cases vs. 6/21 for post hoc SHAP; processes in 19/21 vs. 8/21; Section 5.5.1 states "ShaTS revealed a clear shift in influence as the anomalous instants diminished."
- **Break condition:** If grouping definitions are incorrect or incomplete (e.g., cross-process dependencies), explanations may mislead.

## Foundational Learning

- **Concept: Shapley Values (Cooperative Game Theory)**
  - **Why needed here:** ShaTS adapts the Shapley value—a method for fairly distributing contributions among players in a cooperative game—to attribute prediction contributions among feature groups.
  - **Quick check question:** Given three players A, B, C where the grand coalition earns 100, and A alone earns 20, B alone earns 30, C alone earns 10—what does the Efficiency axiom guarantee about their Shapley values?

- **Concept: Time-Windowed Sequential Models (LSTM/RNN)**
  - **Why needed here:** The AD model processes sliding windows of sensor data; explanations must account for how features across time steps jointly influence predictions.
  - **Quick check question:** If a 10-step window is labeled by its final instant, how might early vs. late instants differ in their contribution during attack onset vs. termination?

- **Concept: Background Dataset for Conditional Expectation**
  - **Why needed here:** Shapley methods require estimating model output when features are "missing"; this is approximated by sampling from a representative background dataset.
  - **Quick check question:** Why might a biased background dataset (e.g., all normal samples) distort anomaly explanations?

## Architecture Onboarding

- **Component map:** Raw sensor data → Windowing (10 steps, configurable stride) → AD model prediction → (on anomaly) ShaTS computation → Grouped attributions → Operator visualization/action

- **Critical path:** Raw sensor data → Windowing (10 steps, configurable stride) → AD model prediction → (on anomaly) ShaTS computation → Grouped attributions → Operator visualization/action

- **Design tradeoffs:**
  - **Exact vs. Approximate Computation:** Exact (2^|G| coalitions) is precise but slow; approximate (m = 20·|G|) is faster but introduces sampling variance
  - **Grouping Granularity:** More groups = finer attribution but higher compute; fewer groups = faster but coarser insights
  - **Background Dataset Size:** Larger K improves conditional expectation accuracy but increases memory and latency

- **Failure signatures:**
  - ShaTS returns near-zero attributions for all groups → Check background dataset representativeness; may lack anomalous samples
  - Attributions inconsistent across consecutive windows → Sampling variance too high; increase m or use exact computation
  - Memory overflow on GPU → Reduce background dataset size or use smaller window sizes; ShaTS should handle this better than KernelSHAP per experiments

- **First 3 experiments:**
  1. **Validate grouping correctness:** On synthetic data with known anomaly source, verify Temporal grouping highlights correct time instants and Sensor grouping identifies correct device
  2. **Benchmark latency vs. accuracy:** Sweep m (number of subsets) and measure (a) per-window execution time, (b) correlation between approximate and exact ShaTS values
  3. **Compare with post hoc SHAP baseline:** On a held-out attack set, measure sensor/process identification accuracy and computational resources for both methods using identical background datasets

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does ShaTS perform compared to other SHAP explainers (e.g., DeepSHAP, GradientSHAP) beyond the KernelSHAP baseline?
- **Basis in paper:** The Conclusion states, "a comparative study with other SHAP explainers could be carried out to further validate the promising potential and performance of ShaTS."
- **Why unresolved:** The experimental evaluation exclusively compared ShaTS against KernelSHAP with post hoc aggregation, leaving its relative performance against model-specific or gradient-based explainers untested.
- **What evidence would resolve it:** A benchmark comparison on the SWaT dataset measuring explanation fidelity (e.g., feature agreement) and latency between ShaTS and other SHAP variants.

### Open Question 2
- **Question:** Can ShaTS maintain its efficiency and explainability precision when applied to time-series domains other than Industrial IoT?
- **Basis in paper:** The Conclusion notes, "Future work will focus on exploring ShaTS in other use cases involving ML/DL models that process time-series data."
- **Why unresolved:** The paper validates ShaTS solely on the Secure Water Treatment (SWaT) dataset, leaving its generalizability to other time-series contexts (e.g., finance, healthcare) unproven.
- **What evidence would resolve it:** Experimental results showing ShaTS's performance on diverse public time-series anomaly detection datasets outside of industrial control systems.

### Open Question 3
- **Question:** How can the feature grouping strategy be automated for datasets lacking clear physical process mappings?
- **Basis in paper:** The Conclusion suggests "alternative grouping approaches will be investigated to align with the contextual needs of different datasets."
- **Why unresolved:** The current ShaTS implementation relies on a priori domain knowledge (defined in Section 4.3.2) to create groups; it is unclear how the method performs if such metadata is unavailable or if groups must be learned dynamically.
- **What evidence would resolve it:** An analysis of ShaTS performance using unsupervised clustering techniques to define feature groups versus the current manual definition.

### Open Question 4
- **Question:** Can advanced computation strategies further reduce the approximation error or resource consumption of the current stratified sampling method?
- **Basis in paper:** The Conclusion mentions efforts to "develop advanced Shapley value computation strategies to improve computational efficiency."
- **Why unresolved:** While ShaTS is faster than KernelSHAP, the paper relies on a specific stratified sampling approximation (Eq. 15) with a heuristic parameter m, which may not be optimal for all model complexities.
- **What evidence would resolve it:** A theoretical analysis or empirical test of different approximation algorithms (e.g., regression-based) demonstrating lower variance or faster execution times than the current method.

## Limitations
- Performance validated only on single dataset (SWaT), limiting generalizability to other time-series domains
- Relies on a priori domain knowledge for feature grouping, which may not be available for all datasets
- Sampling approximation introduces variance that may affect explanation stability across runs

## Confidence
- **High confidence:** The mechanism of a priori grouping preserving temporal structure (Mechanism 1) and the computational complexity reduction (Mechanism 2) are mathematically sound and well-supported by the equations and implementation details
- **Medium confidence:** The claim that different grouping strategies provide complementary explanatory views (Mechanism 3) is supported by Table 4 results but would benefit from additional datasets and attack scenarios
- **Medium confidence:** The real-time execution claim is demonstrated but depends on specific hardware configurations and may vary with different model architectures or background dataset sizes

## Next Checks
1. **Cross-dataset validation:** Test ShaTS on additional IIoT datasets (e.g., WADI, Secure Water Treatment variations) to verify generalization of explainability improvements and computational efficiency claims
2. **Ablation study on grouping strategies:** Systematically evaluate how incorrect or incomplete group definitions affect explanation quality, particularly testing cross-process dependencies and hybrid grouping approaches
3. **Sampling variance analysis:** Conduct a comprehensive study on the relationship between subset count m, background dataset size, and explanation stability across multiple runs to establish robust parameter guidelines