---
ver: rpa2
title: Observational Multiplicity
arxiv_id: '2507.23136'
source_url: https://arxiv.org/abs/2507.23136
tags:
- regret
- xmax
- dataset
- labels
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies how arbitrariness in probabilistic classification
  tasks arises from randomness in data observation. The authors define observational
  multiplicity as a form of predictive multiplicity that occurs when we train models
  to predict probabilities but are given observed labels (0 or 1) that represent single
  realizations of those probabilities.
---

# Observational Multiplicity
## Quick Facts
- arXiv ID: 2507.23136
- Source URL: https://arxiv.org/abs/2507.23136
- Authors: Erin George; Deanna Needell; Berk Ustun
- Reference count: 26
- Primary result: Observational multiplicity quantified through regret shows that probabilistic predictions can vary significantly when observed labels are resampled, with implications for fairness and safety in high-stakes applications

## Executive Summary
This work introduces observational multiplicity as a form of predictive multiplicity arising from randomness in data observation. When training models to predict probabilities but receiving observed labels (0 or 1) that represent single realizations of those probabilities, predictions can vary substantially. The authors formalize this uncertainty through regret - the maximum difference between current probability predictions and predictions under alternative label observations. They develop a resampling-based method to estimate regret by generating synthetic datasets with resampled labels and retraining models.

The approach is validated on semi-synthetic datasets where true regret can be computed, showing that estimated regret closely matches ground truth. Results reveal that regret is not uniformly distributed across populations, with some individuals having substantially higher regret than others. The authors demonstrate practical applications including selective abstention from high-regret predictions and active data collection to reduce uncertainty. Real-world experiments on mortgage loan data show that while most individuals have low regret, a small subset has very high regret, suggesting potential fairness concerns in deployment.

## Method Summary
The method quantifies observational multiplicity through regret, defined as the maximum difference between current probability predictions and predictions under alternative label observations. The core approach uses resampling: given a trained model and observed data, labels are resampled according to the model's predicted probabilities, creating synthetic datasets. These datasets are used to retrain models, and the variation in predictions quantifies regret. This process is repeated multiple times to obtain robust estimates. The method applies to any probabilistic classifier and can estimate regret for any prediction instance. For validation, the authors create semi-synthetic datasets by perturbing observed labels in real datasets while preserving feature distributions, allowing computation of true regret. The estimated regret is then compared against this ground truth to assess accuracy.

## Key Results
- Estimated regret closely matches true regret on semi-synthetic datasets derived from real data
- Regret is not uniformly distributed across populations - some individuals have substantially higher regret than others
- Selective abstention from high-regret predictions improves safety in high-stakes applications
- Active data collection targeting high-regret points reduces overall regret more effectively than random sampling
- Real mortgage loan data reveals a small subset of individuals with very high regret, suggesting potential fairness concerns

## Why This Works (Mechanism)
Observational multiplicity arises because observed labels represent single realizations of underlying probabilities. When we observe a 0 or 1 label, we lose information about the true probability that generated it. This creates inherent uncertainty: the same feature vector could have generated different labels under the true data distribution. Regret quantifies this uncertainty by measuring how much predictions could change if we had observed different labels. The resampling approach works because it generates alternative plausible label configurations consistent with the model's current beliefs, revealing the stability (or instability) of predictions under observation randomness.

## Foundational Learning
- **Observational multiplicity**: The phenomenon where probabilistic predictions vary due to randomness in observed labels rather than model uncertainty. Needed to understand the core problem being addressed; quick check: can you explain why two models trained on the same features but different label realizations might give different probability predictions?
- **Regret as uncertainty measure**: Regret quantifies the maximum difference between current predictions and predictions under alternative label observations. Needed to grasp the formalization of observational multiplicity; quick check: can you compute regret for a simple binary classification example?
- **Resampling-based estimation**: The method of generating synthetic datasets by resampling labels according to current model predictions and retraining. Needed to understand the practical approach; quick check: can you describe the steps to estimate regret for a new instance?
- **Semi-synthetic validation**: Creating validation datasets by perturbing observed labels while preserving feature distributions. Needed to understand how true regret is computed; quick check: can you explain why this approach provides ground truth for regret validation?
- **Selective abstention**: The practice of not making predictions for high-regret instances to improve safety. Needed to understand practical applications; quick check: can you describe scenarios where abstention would be beneficial?
- **Active data collection**: The strategy of collecting more data for high-regret instances to reduce uncertainty. Needed to understand how to mitigate observational multiplicity; quick check: can you contrast this with traditional active learning approaches?

## Architecture Onboarding
- **Component map**: Observed data and trained model -> Resample labels -> Synthetic datasets -> Retrained models -> Prediction variation -> Regret estimate
- **Critical path**: The resampling and retraining process is the core computational bottleneck; each iteration requires full model retraining
- **Design tradeoffs**: Higher number of resamples improves regret estimate accuracy but increases computational cost; simpler models train faster but may have higher inherent regret
- **Failure signatures**: Underestimated regret when resampling distribution poorly matches true label distribution; computational intractability for very large datasets or complex models
- **First experiments**: 1) Estimate regret on a simple logistic regression with synthetic binary labels to verify method correctness; 2) Compare estimated regret against true regret on semi-synthetic breast cancer dataset; 3) Test selective abstention on a small high-stakes dataset to measure safety improvement

## Open Questions the Paper Calls Out
None

## Limitations
- Estimated regret accuracy depends on the assumption that current model predictions reflect true label distributions
- Computational cost scales with number of resamples and model retraining requirements
- Real-world validation limited to mortgage dataset without ground truth verification of high-regret identification
- Method assumes access to predicted probabilities, not applicable to deterministic classifiers

## Confidence
- Estimated regret reliably identifies high-regret individuals: **Medium** - validated on semi-synthetic data but not independently verified on real-world datasets
- Observational multiplicity reveals fairness concerns: **Medium** - correlation observed but causal relationship not established
- Resampling-based estimation method is broadly applicable: **High** - theoretically sound and validated across multiple datasets and models

## Next Checks
1. Deploy the regret estimation method on a real-world dataset with known ground truth labels to verify accuracy of high-regret identification
2. Conduct an ablation study comparing different sampling strategies (e.g., number of resamples, sampling distributions) for regret estimation
3. Implement the active data collection framework in a live system to measure actual improvement in regret reduction versus random sampling