---
ver: rpa2
title: Influence branching for learning to solve mixed-integer programs online
arxiv_id: '2510.04273'
source_url: https://arxiv.org/abs/2510.04273
tags:
- series
- influence
- branching
- learning
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces influence branching, a graph-based variable
  selection heuristic for solving mixed-integer programs (MIPs) online. The method
  leverages influence graphs to identify the most influential variables to branch
  on during early iterations of the branch-and-bound algorithm.
---

# Influence branching for learning to solve mixed-integer programs online

## Quick Facts
- **arXiv ID**: 2510.04273
- **Source URL**: https://arxiv.org/abs/2510.04274
- **Reference count**: 18
- **Key outcome**: Influence branching achieves average speedups between -0.02 and -0.06 across public instance series, with convergence scores reaching at least 60%, demonstrating effective online learning for MIP variable selection.

## Executive Summary
This work introduces influence branching, a graph-based variable selection heuristic for solving mixed-integer programs online. The method constructs influence graphs from the constraint matrix to identify the most structurally influential variables for branching near the root node. Online learning via Thompson sampling optimizes the choice of influence model and branching depth across instance series. Results show performance comparable to state-of-the-art methods while providing interpretable variable selection based on problem structure.

## Method Summary
The approach combines influence branching with Thompson sampling for online hyperparameter optimization. Influence branching builds directed graphs where edge weights encode structural relationships between variables through shared constraints. At each node with depth ≤ k, the variable with maximum total influence is selected for branching. Thompson sampling maintains Gaussian priors over a small set of (model, depth) hyperparameter pairs, sampling actions and updating posteriors based on observed solving performance. The method is active only in early tree stages to avoid suboptimal late-tree decisions.

## Key Results
- Average speedups range from -0.02 to -0.06 across public instance series, comparable to state-of-the-art online methods
- Convergence scores reach at least 60% across all tested series, indicating average speedup superior to half the oracle baseline
- No consistent improvement observed on instances from the fifth batch, though insufficient samples prevent definitive conclusions about underfitting
- Best performance achieved with (g,k) pairs: (count,1), (count,5), (countdual,2), (binary,3), and (dual,3)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Influence graphs encode structural variable relationships that predict branching impact near the B&B root node.
- **Mechanism**: The constraint matrix A is transformed into a directed graph G=(V,E,W) where edge weights w_ij aggregate "local influence" through shared constraints. Variables with larger coefficients in tighter constraints receive higher influence scores. At each node (depth ≤ k), the variable with maximal total influence w_i = √(1 + c_i) Σ_j w_ij is selected for branching.
- **Core assumption**: Variables that co-occur in constraints with significant coefficients have greater mutual impact on integrality propagation; early-tree decisions compound into overall tree-size reduction.
- **Evidence anchors**:
  - [abstract]: "leverages influence graphs to identify the most influential variables to branch on during early iterations of the branch-and-bound algorithm"
  - [Section 3.1, Definition 3]: "We call influence graph the directed graph G=(V, E, W) where V={1, ..., n}... and W∈R^{n×n} satisfies the definition of direct influence"
  - [corpus]: Limited direct validation; corpus papers focus on RL-based branching (ReviBranch, PPO approaches) rather than graph-theoretic influence. Complementary but not confirmatory.
- **Break condition**: If MIP instances have sparse constraint matrices with minimal variable coupling, or if optimal branching depends on dynamic LP state rather than static structure, influence becomes a weak signal.

### Mechanism 2
- **Claim**: Limiting influence branching to early tree depth (k ≤ 6) captures most benefit while avoiding degradation from suboptimal late-tree decisions.
- **Mechanism**: Influence branching is active only for nodes with depth d ≤ k. Beyond this, SCIP's default heuristics resume. This exploits the observation that root-node and near-root decisions disproportionately affect tree size. The paper tests k ∈ {1,...,6} and selects optimal values per-series via bandits.
- **Core assumption**: Early branching decisions dominate tree-size outcomes; later decisions are better handled by mature default heuristics than by the static influence criterion.
- **Evidence anchors**:
  - [Section 3.1]: "as long as the depth of the current node d is inferior or equal to k, the maximal depth. Moreover, variables' total influence are weighted according to their associated objective function coefficient c_i. For nodes of depth d > k, influence branching is disabled"
  - [Table 2]: Individual instance results show best k varies (1–5); Table 3 shows average speedups differ by (g,k) pair, confirming depth sensitivity
  - [corpus]: "Planning in Branch-and-Bound" and "ReviBranch" papers reinforce that early-tree variable selection is critical to efficiency
- **Break condition**: If problem classes require deep-tree specialization (e.g., highly symmetric problems needing orbital branching deep in the tree), capping at k harms performance.

### Mechanism 3
- **Claim**: Thompson sampling over a small, preselected action space converges to near-optimal hyperparameters within 50 online instances.
- **Mechanism**: Each action a=(g,k) has an unknown reward distribution P_{a,s}. Thompson sampling maintains Gaussian priors N(μ̂_a, σ̂_a), draws samples, selects the action with minimum sampled value (minimizing solving time), and updates posteriors after each instance. The action space A is deliberately limited to 5 high-performing pairs to ensure tractable exploration.
- **Core assumption**: Rewards are approximately Gaussian with similar variance σ≈0.2; the instance distribution Q_s is stationary within a series; and the optimal action is within the preselected set A.
- **Evidence anchors**:
  - [Section 4.2]: "Thompson sampling algorithm draws samples from prior distributions N(μ̂_a, σ̂_a) corresponding to each action and selects the action associated with the minimum sampled value"
  - [Table 4]: Convergence scores 64–75% across series, "indicating that the average speedup achieved by the bandits algorithm is superior to half of the theoretical speedup obtained by an oracle"
  - [corpus]: Multi-armed bandit methods for MIP heuristic selection are validated in related online learning literature, though not specifically for influence branching
- **Break condition**: If the optimal (g,k) for a series is not in A, Thompson sampling converges to a suboptimal action; if Q_s shifts mid-series, priors become misaligned.

## Foundational Learning

- **Concept: Branch and Bound (B&B) Tree Structure**
  - Why needed here: Influence branching operates as a node-level heuristic within B&B. Understanding how branching partitions the feasible space and grows the search tree is essential to see why early decisions matter.
  - Quick check question: Can you explain how branching on variable x_i at a node creates two child nodes and how this affects dual bounds?

- **Concept: Multi-Armed Bandits and Thompson Sampling**
  - Why needed here: The online learning component uses Thompson sampling to select hyperparameters. Grasping the exploration-exploitation tradeoff and Bayesian posterior updates is critical for debugging convergence.
  - Quick check question: How does Thompson sampling's stochastic action selection differ from UCB's deterministic confidence-bound approach?

- **Concept: MIP Constraint Matrix Structure**
  - Why needed here: Influence graphs derive from the constraint matrix A, bounds b, and objective c. Interpreting variable-constraint incidence is necessary to understand and modify influence models.
  - Quick check question: Given a row of A with non-zeros at columns {3, 7, 12}, which local influences w^l_{ij} are non-zero?

## Architecture Onboarding

- **Component map**: MIP instance -> Normalize (A, b, c) -> Thompson sampling selects action (g,k) -> At each B&B node: if depth ≤ k, build influence graph with model g and return max-influence variable; else defer to SCIP -> After instance solved, compute performance score f_{s,i} and update Thompson posterior

- **Critical path**: 1. Receive MIP instance -> 2. Normalize (A, b, c) -> 3. Thompson sampling selects action (g,k) -> 4. At each B&B node: if depth ≤ k, build influence graph with model g and return max-influence variable; else defer to SCIP -> 5. After instance solved, compute performance score f_{s,i} and update Thompson posterior

- **Design tradeoffs**:
  - Action space size vs. convergence: Limited to 5 actions for 50-instance series; larger A would require more samples or risk non-convergence
  - Influence model complexity vs. overhead: Dual-based models require LP solutions (extra compute); count-based models are cheaper but less expressive
  - Depth k vs. robustness: Larger k extends influence branching control but amplifies risk if model is suboptimal for that series

- **Failure signatures**:
  - No speedup on easy instances: rhs series 2 (small trees) showed 0.001 average speedup; influence branching targets hard instances with large B&B trees
  - Instance-level variance: Table 2 shows speedups from -0.86 to +0.08 within one series, indicating no single (g,k) is universally optimal
  - Convergence without late-batch improvement: Table 5 shows no consistent improvement in instances 41–50 vs. earlier batches, suggesting potential hard-instance concentration or distribution shift

- **First 3 experiments**:
  1. **Influence model ablation**: Fix k=3, run each of the 7 influence models on a held-out series; rank by average speedup. Validates model sensitivity and identifies consistently strong candidates.
  2. **Depth sensitivity sweep**: Fix g=count, sweep k∈{1,2,3,4,5,6} on obj series 2; plot tree size and runtime vs. k. Identifies the depth at which influence branching becomes net harmful.
  3. **Action space expansion**: Create A' with 10–15 (g,k) pairs and test on a simulated 100-instance series (duplicating/shuffling public instances). Compare Thompson convergence rate and final performance vs. 5-action baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would increasing the action space beyond 5 preselected (g, k) pairs improve performance when more than 50 instances are available, and what sample sizes are required to maintain Thompson sampling convergence?
- Basis in paper: [explicit] Section 6 states: "in a more general framework where possibly several hundreds of instances sampled from the same distribution are solved online... larger action sets could be built while preserving Thompson sampling convergence properties."
- Why unresolved: The competition limited each series to 50 instances, constraining the action space design to ensure convergence; no experiments with larger action sets were conducted.
- What evidence would resolve it: Empirical evaluation on synthetic or real MIP series with 100–500 instances, measuring convergence speed and final speedup as action set size increases.

### Open Question 2
- Question: Is the lack of performance improvement on the fifth batch of instances due to instance difficulty distribution, algorithmic underfitting, or limitations of the online learning framework?
- Basis in paper: [explicit] Section 5 notes: "we don't observe better average performance on instances from the fifth batch. However, given the limited number of samples available, it is not sufficient to conclude that our solution is underfitting."
- Why unresolved: The paper could not isolate the cause due to small sample sizes per batch (10 instances).
- What evidence would resolve it: Controlled experiments varying instance difficulty order, or analysis with per-batch difficulty metrics and extended runs beyond 50 instances per series.

### Open Question 3
- Question: How robust is the fixed-variance assumption (σ = 0.2) in Thompson sampling across instance series with different reward variance profiles?
- Basis in paper: [inferred] Section 4.2 states Thompson sampling "make[s] the simplifying assumption that (P_a,s) are normal distributions with unknown means and fixed standard deviation σ = 0.2, the approximate value measured across public series."
- Why unresolved: Variances may differ substantially across series; misspecifying σ could bias exploration-exploitation tradeoffs.
- What evidence would resolve it: Ablation studies comparing fixed-σ vs. adaptive variance estimation across all public series, measuring convergence scores and average speedup.

## Limitations
- Action space restricted to 5 hyperparameter pairs, potentially excluding optimal configurations for certain instance classes
- Thompson sampling convergence measured relative to oracle baseline rather than absolute solving time improvements
- No consistent improvement on easier instance series where tree sizes are small
- Influence model requires LP dual solutions at each node, introducing computational overhead

## Confidence
- **High confidence**: Influence branching mechanism operates as described; Thompson sampling implementation follows standard methodology; convergence scores are accurately computed relative to oracle baseline
- **Medium confidence**: Claims about state-of-the-art performance are reasonable but context-dependent; the 5-action space limitation is acknowledged but not fully explored
- **Low confidence**: Practical runtime benefits in real-world scenarios; scalability to industrial-sized instances; robustness to distribution shifts in online settings

## Next Checks
1. **Oracle Action Space Expansion**: Test Thompson sampling with expanded action spaces (10-15 pairs) on the same instance series to determine if convergence plateaus at 5 actions or if better configurations exist
2. **Computational Overhead Measurement**: Profile the exact time spent computing influence graphs versus search tree reduction to quantify the net benefit, particularly for dual-based models requiring LP solutions
3. **Cross-Distribution Transfer**: Train influence branching on obj series 1 and evaluate on rhs series 1 without retraining to assess robustness to distribution shifts and potential for warm-starting across instance families