---
ver: rpa2
title: Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal
  Tabular Transformers
arxiv_id: '2505.00225'
source_url: https://arxiv.org/abs/2505.00225
tags:
- customer
- features
- updates
- outage
- satisfaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of predicting accurate Estimated
  Times of Restoration (ETRs) for electrical outages during natural disasters, which
  is critical for customer preparedness and satisfaction. The authors propose a Longitudinal
  Tabular Transformer (LTT) model that leverages historical outage event data along
  with sequential updates of these events to improve prediction accuracy.
---

# Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers

## Quick Facts
- arXiv ID: 2505.00225
- Source URL: https://arxiv.org/abs/2505.00225
- Reference count: 5
- Primary result: 19.08% average improvement in Customer Satisfaction Impact (CSI) metric for ETR prediction

## Executive Summary
This paper addresses the challenge of accurately predicting Estimated Times of Restoration (ETRs) for electrical outages during natural disasters. The authors propose a Longitudinal Tabular Transformer (LTT) model that leverages sequential updates of outage events alongside historical data. Evaluated on 34,000 storm-related outage events from three major utilities serving over 3 million customers, the LTT model demonstrates significant improvements in prediction accuracy while maintaining interpretability through SHAP analysis.

## Method Summary
The LTT model processes outage events as sequences of up to 20 updates, each containing 92 features including time, customer counts, crew dispatch status, and concurrent events. Categorical features are embedded and concatenated with Z-normalized continuous features, then projected to d_model=128 with time-delta positional encoding. A 6-layer transformer encoder with 16 attention heads processes the sequences, and predictions are made from the final update representation. The model is trained with an asymmetric loss function (α=5, β=2) to align with customer satisfaction patterns and optimized using Adam (lr=0.0001) with batch size 1024.

## Key Results
- LTT achieves 19.08% average improvement in Customer Satisfaction Impact (CSI) metric compared to existing methods
- Significant reduction in under-prediction rate (UPR) and over-prediction beyond 8 hours rate (OPR-8) across storm sizes
- SHAP analysis reveals predictable feature importance shifts across update revisions, with early revisions prioritizing customer counts and later revisions emphasizing crew status

## Why This Works (Mechanism)

### Mechanism 1
Sequential self-attention captures evolving outage dynamics that static single-point models miss. Each outage event is represented as a sequence of updates (up to 20), with categorical features embedded, concatenated with continuous features, projected to d_model=128, and augmented with time-delta positional encoding. The transformer's multi-head self-attention (16 heads × 6 layers) learns which prior updates most inform the current prediction. Core assumption: temporal evolution of an outage contains predictive signal beyond the most recent snapshot. Evidence: attention layers 3-6 assign higher attention to early query positions; Layer 2 shows diagonal bands indicating temporal continuity tracking.

### Mechanism 2
Asymmetric loss aligns model optimization with empirically-derived customer satisfaction patterns. A piecewise loss penalizes under-prediction at α=5×, small over-predictions (≤8 hours) at 1×, and large over-predictions (>8 hours) at β=2×, reflecting survey findings that under-prediction causes significant dissatisfaction while modest over-prediction is tolerated. Core assumption: customer satisfaction follows this asymmetric tolerance curve consistently. Evidence: LTT achieves lower UPR (0.24–0.37) and OPR-8 (0.02–0.21) across storm sizes compared to baselines.

### Mechanism 3
Feature importance shifts predictably across update revisions, and the model captures these transitions. SHAP analysis reveals early revisions prioritize "Number of Customers Under Outage" and "Priority," while later revisions emphasize crew dispatch status and rolling restoration averages. The transformer's sequence modeling allows it to weight features appropriately at each stage. Core assumption: feature relevance follows a recoverable temporal pattern that generalizes across storm types. Evidence: Figure 5 shows evolving feature importance across first five revisions for OPCO-3.

## Foundational Learning

- **Self-attention mechanism**: Understanding how transformers assign differential importance to sequence positions is essential for debugging why the model attends to early vs. late updates. Quick check: Given a 5-update sequence, can you explain why Layer 2 might show diagonal attention while Layer 5 shows dispersed attention?

- **Positional encoding for irregular time series**: Outage updates arrive at irregular intervals; time-delta encoding (∆t = current_time − first_update_time) must convey meaningful temporal relationships. Quick check: How would you modify the positional encoding if two updates arrive 5 minutes apart vs. 5 hours apart?

- **Asymmetric loss functions**: Standard MSE treats under- and over-prediction equally; understanding piecewise penalties is critical for tuning α/β and interpreting WAE/CSI metrics. Quick check: If under-prediction became less costly than over-prediction, how would you adjust the loss function?

## Architecture Onboarding

- **Component map**: Categorical features → label-encoded → embeddings → concatenated with Z-normalized continuous features → linear projection to d_model=128 → time-delta positional encoding → 6-layer transformer encoder (16 heads) → final update representation → FCN prediction head

- **Critical path**: Categorical embedding quality → positional encoding alignment → Layer 2-4 attention patterns (temporal continuity) → final update representation extraction → FCN prediction. Errors propagate if early embeddings misrepresent categorical relationships.

- **Design tradeoffs**: Sequence length 20 limits memory but may truncate long events; α=5, β=2 aggressive under-prediction penalty may increase over-prediction bias; 6 layers / 16 heads balanced capacity with no significant improvement from deeper models in pilot tests.

- **Failure signatures**: High UPR (>0.4) indicates chronic under-prediction; attention collapsing to uniform distribution suggests model not learning temporal structure; SHAP features inconsistent across revisions indicates possible data leakage or feature drift.

- **First 3 experiments**:
  1. Train LTT with standard MSE loss (α=β=1) and compare CSI/WAE to asymmetric loss version to confirm asymmetric loss drives reported improvements.
  2. Train with max_seq_len ∈ {5, 10, 20} and measure impact on RMSE and attention pattern diversity to identify diminishing returns point.
  3. Train on OPCO-1/2, evaluate on OPCO-3 without retraining to assess generalization across utility operational patterns and identify feature drift.

## Open Questions the Paper Calls Out
The paper explicitly states that the potential of the LTT model extends to addressing other longitudinal challenges across diverse domains that require sequential data modeling, underscoring a promising direction for future research and broader application.

## Limitations
- Relies on proprietary outage data from three utilities, limiting reproducibility
- Asymmetric loss parameters derived from single-source survey data (JD Power 2023) without cross-validation
- Performance on non-storm outages or different utility operational patterns remains untested

## Confidence
- High Confidence: LTT architecture implementation, training procedures, and baseline comparisons are well-documented and reproducible with proxy datasets
- Medium Confidence: 19.08% CSI improvement claim depends on proprietary data and specific utility operational patterns; results may not transfer to other contexts
- Low Confidence: Asymmetric loss parameters and customer satisfaction impact based on single-source survey data without cross-validation

## Next Checks
1. Ablation on sequence length: Train LTT with max_seq_len ∈ {5, 10, 20} to identify diminishing returns and optimize memory usage
2. Cross-OPCO transfer: Train on OPCO-1/2, evaluate on OPCO-3 without retraining to assess generalization across utility operational patterns
3. Loss function sensitivity: Train with varying α/β values (e.g., α ∈ {3,5,7}, β ∈ {1,2,3}) to test robustness of asymmetric penalty and identify optimal customer satisfaction alignment