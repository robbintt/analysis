---
ver: rpa2
title: 'From Programs to Poses: Factored Real-World Scene Generation via Learned Program
  Libraries'
arxiv_id: '2510.10292'
source_url: https://arxiv.org/abs/2510.10292
tags:
- objects
- factoredscenes
- object
- scenes
- scene
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FactoredScenes introduces a framework that generates realistic
  3D indoor scenes by decomposing the problem into hierarchical concepts of room programs
  and object poses. It learns reusable layout patterns from synthetic data, uses large
  language models to generate scene programs regularized by this learned library,
  and predicts object poses hierarchically on limited real-world data.
---

# From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries

## Quick Facts
- **arXiv ID:** 2510.10292
- **Source URL:** https://arxiv.org/abs/2510.10292
- **Reference count:** 40
- **Key outcome:** FactoredScenes achieves 38.3% FID and 80.4% KID improvements on bedrooms, and 40.1% FID and 79.5% KID improvements on living rooms vs. LayoutGPT.

## Executive Summary
FactoredScenes introduces a framework for generating realistic 3D indoor scenes by decomposing the problem into hierarchical concepts of room programs and object poses. It learns reusable layout patterns from synthetic data, uses large language models to generate scene programs regularized by this learned library, and predicts object poses hierarchically on limited real-world data. The method significantly outperforms prior works in generating ScanNet-like layouts, achieving substantial improvements in fidelity metrics and human study evaluations where generated scenes are difficult to distinguish from real ScanNet scenes.

## Method Summary
The method factorizes scene generation into a probabilistic chain: P(library) × P(program|library) × P(layout|program) × P(pose|layout,program) × P(objects|pose,program). Library learning uses a wake-sleep framework on synthetic 3D-Front data with LLMs parsing layouts and proposing abstractions. Scene programs are generated via LLMs with library constraints and few-shot ScanNet examples. A deterministic interpreter converts programs to axis-aligned layouts. An attention-based pose predictor hierarchically predicts object orientations (discretized to 36 classes) with dependency conditioning. The pipeline enables training different components on different data sources: synthetic data for library learning, commonsense knowledge for program generation, and real-world variation for pose prediction.

## Key Results
- FactoredScenes achieves 67.51 FID on bedrooms vs. 109.40 for LayoutGPT (38.3% improvement)
- Human study shows generated scenes are difficult to distinguish from real ScanNet scenes
- Learned library shows 644.1% relative improvement in function use on ScanNet vs. inference-only library, with 0.98 mIoU reconstruction accuracy

## Why This Works (Mechanism)

### Mechanism 1: Library Learning from Synthetic Data
The wake-sleep framework alternates between parsing input layouts into programs using LLMs and proposing new abstraction functions from successful reconstructions. This compresses scene structures into reusable functions like `cluster_placement`, `align`, `grid`. Core assumption: Room structure patterns in professionally designed synthetic scenes share underlying regularities with real-world layouts.

### Mechanism 2: Hierarchical Pose Prediction
Objects are classified as primary (directly initialized) or dependent (defined relative to a dependency target). The model predicts primary object poses first, then conditions dependent object predictions on their target's predicted orientation and the program function that instantiated them. Core assumption: Object orientations follow hierarchical dependencies encoded by the program.

### Mechanism 3: Factorized Decomposition
The joint distribution is factorized to enable training different components on different data sources. This allows library learning on 3D-Front, program generation via LLMs, and pose prediction on ScanNet. Core assumption: The factorization approximates the true scene distribution well enough that errors don't compound catastrophically.

## Foundational Learning

- **DreamCoder / Wake-Sleep Program Synthesis**
  - Why needed here: Core algorithm for library learning. Must understand how recognition models alternate with abstraction proposals.
  - Quick check question: Can you explain why alternating between parsing and abstraction produces more compact programs than one-shot parsing?

- **Probabilistic Factorization / Conditional Independence**
  - Why needed here: Understanding when P(A,B) ≈ P(A)P(B|A) is valid and what approximation errors this introduces.
  - Quick check question: If object poses depended on both program structure AND wall positions, where would this factorization break?

- **Attention-Based Sequence Modeling**
  - Why needed here: The pose prediction model uses multi-head self-attention over object slots with various encodings.
  - Quick check question: How would you modify the attention mechanism if you wanted to add floor-plan geometry as an additional conditioning signal?

## Architecture Onboarding

- **Component map:** Library Learner (3D-Front → learned functions) -> Program Generator (library + few-shot ScanNet → scene programs) -> Program Executor (programs → axis-aligned layouts) -> Pose Predictor (layouts + programs → oriented bounding boxes) -> Object Retriever (oriented boxes → 3D meshes)
- **Critical path:** Library learning must complete before program generation. Pose predictor must be trained before full scene output. Each stage can be debugged in isolation.
- **Design tradeoffs:** Discretizing orientations into 36 classes reduces regression complexity but limits precision. Using LLMs for both parsing and generation creates dependency on API availability and cost.
- **Failure signatures:** Invalid programs (e.g., nightstands placed at bed center) → LLM generation errors. Overlapping objects with illogical orientations → pose model failure. Poor reconstruction mIoU → library insufficient.
- **First 3 experiments:**
  1. **Library quality check:** Parse 50 ScanNet scenes with learned library vs. inference-only library; report mIoU and function diversity.
  2. **Pose prediction ablation:** Train pose model with and without dependency conditioning; verify ~11% relative improvement on dependent objects.
  3. **End-to-end spot check:** Generate 10 scenes, render top-down views, manually verify: no object overlap, chairs face tables, primary objects have natural orientation variation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can human-in-the-loop editing improve program validity and enable task-specific scene generation more effectively than purely automated LLM-based program synthesis?
- Basis in paper: Authors state: "a promising future direction is to include humans in the loop to generate new scenes programs, thus dynamically producing more task-specific data."
- Why unresolved: Current framework relies entirely on LLMs for program generation, which occasionally produces unnatural object placements.

### Open Question 2
- Question: How much would human-annotated orientation labels improve pose prediction accuracy compared to current heuristic-based ground truth extraction from ScanNet?
- Basis in paper: Authors note the pose model is "limited by the heuristics used to generate ground-truth oriented bounding boxes for ScanNet. Due to partial objects in ScanNet, extracted orientations are at times inaccurate."
- Why unresolved: ScanNet's partial object scans make automated orientation extraction error-prone, yielding illogical overlapping objects.

## Limitations
- The reliance on LLMs for both library learning and program generation introduces significant opacity and potential brittleness without disclosed prompts
- Pose prediction model architecture details (attention heads, hidden dimensions, layers) are unspecified, limiting reproducibility
- Discretization of orientations into 36 classes may restrict the model's ability to capture finer-grained pose variations present in real-world scenes

## Confidence
- **High Confidence:** The quantitative improvements on FID/KID metrics (38.3% and 40.1% improvements for bedrooms and living rooms respectively) are well-supported by the results and methodology is sound.
- **Medium Confidence:** The human study results showing generated scenes are difficult to distinguish from real ScanNet scenes, as this relies on subjective judgments and the exact protocol is not fully specified.
- **Medium Confidence:** The claim that library learning captures reusable layout patterns transferable from synthetic to real data, as this depends on the quality of the learned abstractions and the degree of structural similarity between 3D-Front and ScanNet.

## Next Checks
1. **Library Transferability Test:** Parse a held-out set of 50 ScanNet scenes with both the learned library and an inference-only library. Report reconstruction mIoU and function usage diversity. Verify that the learned library shows significantly higher mIoU (>0.95) and more diverse function usage (>644% relative improvement in function use).
2. **Pose Dependency Ablation Study:** Train two versions of the pose prediction model: one with dependency conditioning and one without. Evaluate both on a held-out set of 100 ScanNet scenes. Measure the accuracy drop for dependent objects (~11% relative degradation if dependency conditioning is effective).
3. **End-to-End Generation Quality Check:** Generate 20 scenes (10 bedrooms, 10 living rooms) using the full FactoredScenes pipeline. For each scene, compute the FID/KID score against ScanNet and perform a small-scale human study (n=10 participants) to assess visual realism. Verify that generated scenes achieve FID/KID scores comparable to Table 1 and that human accuracy is near chance (~50% accuracy).