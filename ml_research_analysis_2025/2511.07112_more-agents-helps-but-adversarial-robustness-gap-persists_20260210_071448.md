---
ver: rpa2
title: More Agents Helps but Adversarial Robustness Gap Persists
arxiv_id: '2511.07112'
source_url: https://arxiv.org/abs/2511.07112
tags:
- noise
- agent
- agents
- accuracy
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work investigates whether multi-agent collaboration improves
  adversarial robustness in large language models for mathematical reasoning. Using
  a sampling-and-voting framework (Agent Forest), it evaluates six open-source models
  (Qwen3, Llama3.1, Mistral, Gemma) across four math benchmarks (GSM8K, MATH, MMLU-Math,
  MultiArith) under various adversarial perturbations: synthetic punctuation noise
  at three intensities (10%, 30%, 50%) and human-like typos (WikiTypo, R2ATA).'
---

# More Agents Helps but Adversarial Robustness Gap Persists

## Quick Facts
- **arXiv ID**: 2511.07112
- **Source URL**: https://arxiv.org/abs/2511.07112
- **Reference count**: 0
- **Primary result**: Multi-agent collaboration improves accuracy but fails to reduce adversarial robustness gap under input perturbations

## Executive Summary
This work investigates whether multi-agent collaboration improves adversarial robustness in large language models for mathematical reasoning. Using a sampling-and-voting framework (Agent Forest), it evaluates six open-source models (Qwen3, Llama3.1, Mistral, Gemma) across four math benchmarks (GSM8K, MATH, MMLU-Math, MultiArith) under various adversarial perturbations: synthetic punctuation noise at three intensities (10%, 30%, 50%) and human-like typos (WikiTypo, R2ATA). Results show that increasing the number of agents reliably improves accuracy, with the largest gains from one to five agents and diminishing returns beyond ten. However, the adversarial robustness gap persists, as Attack Success Rate remains stable regardless of agent count. Human typos (WikiTypo) remain the dominant bottleneck, yielding the highest ASR even with 25 agents, while punctuation noise and R2ATA show similar, less severe impacts. Larger models exhibit better robustness, with Gemma3-12B achieving the highest performance under noisy conditions. The findings suggest that while collaboration enhances accuracy, inherent robustness limitations remain.

## Method Summary
The study evaluates multi-agent collaboration (Agent Forest) on mathematical reasoning tasks under adversarial perturbations. Six open-source models are tested across four math benchmarks using a sampling-and-voting framework. Each question generates exactly 25 independent samples from the same base model with fixed decoding parameters. Numeric answers are extracted via pattern matching and aggregated by majority vote. Agent groups of varying sizes (n=1,2,5,10,15,20,25) are formed from disjoint partitions of the 25 samples. Accuracy and Attack Success Rate (ASR) are computed across clean and five noise conditions: punctuation insertion at 10%/30%/50% intensity, WikiTypo (real Wikipedia typos), and R2ATA (adversarial typos). No fine-tuning is performed.

## Key Results
- Agent count reliably improves accuracy with diminishing returns beyond ten agents
- ASR remains stable regardless of agent count, indicating persistent robustness gap
- WikiTypo remains dominant bottleneck with ASR >10% even with 25 agents
- Larger models show better inherent robustness and benefit less from collaboration
- Gemma3-12B achieves highest performance under noisy conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Majority voting over multiple independent samples improves accuracy but does not proportionally reduce attack success rate.
- **Mechanism:** Sampling with different random seeds produces varied reasoning paths; aggregation by majority vote filters out stochastic errors that vary across samples. However, noise-induced failures that systematically mislead reasoning (e.g., semantic distortion from typos) affect most samples similarly, so voting cannot correct them.
- **Core assumption:** Errors are at least partially uncorrelated across samples; noise creates systematic rather than random failures.
- **Evidence anchors:**
  - [abstract] "Collaboration reliably improves accuracy as the number of agents, n, increases... However, the adversarial robustness gap persists regardless of the agent count."
  - [Section 5.1] "ASR values stay almost the same when increasing the number of agents. This indicates that under simple surface-level perturbations, the collaboration between agents is as vulnerable to noise as a single LLM."
  - [corpus] Related work on multi-agent security (arXiv:2511.10949) confirms vulnerabilities persist in multi-agent systems under adversarial prompting.
- **Break condition:** If errors become highly correlated across samples (same model, same prompt, same noise), voting yields no benefit.

### Mechanism 2
- **Claim:** Punctuation noise is more recoverable through collaboration than human-like typos because it creates superficial rather than semantic disruption.
- **Mechanism:** Punctuation insertion affects tokenization and surface patterns without altering meaning; multiple reasoning paths can converge despite this noise. Human typos (WikiTypo) introduce heterogeneous, context-dependent distortions that change how tokens are interpreted, causing more consistent reasoning failures across samples.
- **Core assumption:** Punctuation noise affects different reasoning paths inconsistently; human typos create more uniform failures.
- **Evidence anchors:**
  - [abstract] "Human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents."
  - [Section 5.3] "WikiTypo remains the dominant bottleneck. Even at n=25, ASR typically stays above 0.10, far higher than for punctuation. Human typos introduce heterogeneous and context-dependent distortions that majority voting cannot fully absorb."
  - [corpus] No direct corpus comparison; related work on adversarial perturbations (arXiv:2501.08203) examines punctuation noise but not human typos specifically.
- **Break condition:** If human typos were more uniform across instances, voting might help more.

### Mechanism 3
- **Claim:** Larger models exhibit better inherent robustness, and smaller models benefit more from collaboration.
- **Mechanism:** Larger models have more robust internal representations that resist noise-induced corruption; smaller models rely more heavily on aggregation to compensate for individual weaknesses.
- **Core assumption:** Model scale correlates with representation robustness; smaller models' errors are more independent than larger models'.
- **Evidence anchors:**
  - [Section 5.1] "Larger models (Gemma3-12B and Qwen3-14B) maintain higher absolute accuracy across conditions, while smaller (and older) models (Llama3.1 and Mistral-7B) show steeper relative gains with increasing agents."
  - [Section 6] "Within families such as Qwen and Gemma, larger models consistently achieve lower ASR values and thus demonstrate stronger inherent robustness. Their smaller counterparts show similar robustness while benefiting more from collaboration."
  - [corpus] No direct corpus evidence on scale effects for this specific noise-robustness relationship.
- **Break condition:** If smaller models' errors become highly correlated, collaboration gains diminish.

## Foundational Learning

- **Concept: Self-Consistency / Majority Voting**
  - **Why needed here:** Agent Forest relies on generating multiple responses and aggregating via majority vote; understanding why this improves accuracy but not robustness is central to interpreting results.
  - **Quick check question:** Given 25 samples where 60% are correct under clean conditions and 40% are correct under noise, what happens to accuracy vs. ASR when you aggregate?

- **Concept: Attack Success Rate (ASR) vs. Accuracy Drop**
  - **Why needed here:** The paper shows ASR remains stable while accuracy improves; these are distinct metrics measuring different failure modes.
  - **Quick check question:** If a model gets 80% accuracy on clean inputs and 60% on noisy inputs, is the ASR necessarily 20%? Why or why not?

- **Concept: Noise Taxonomy (Synthetic vs. Human-like)**
  - **Why needed here:** The paper shows different noise types have fundamentally different robustness profiles; understanding this distinction explains why collaboration helps unevenly.
  - **Quick check question:** Why might character substitution (R2ATA) be more recoverable than natural Wikipedia typos even though both affect characters?

## Architecture Onboarding

- **Component map:** Noise injection module -> Agent Forest sampler -> Answer extractor -> Voting aggregator -> Evaluation suite
- **Critical path:**
  1. Load benchmark questions (GSM8K, MATH, MMLU-Math, MultiArith)
  2. Apply noise perturbations at specified intensities
  3. Generate 25 samples per question with fixed decoding parameters
  4. Extract and normalize answers
  5. Form agent groups (n=1,2,5,10,15,20,25) from disjoint partitions
  6. Compute accuracy and ASR per group

- **Design tradeoffs:**
  - Using same base model for all agents is computationally efficient but introduces correlated errors; heterogeneous ensembles might reduce correlation
  - Rule-based answer extraction is simple but may miss edge cases; neural extractors could improve precision
  - Disjoint group partitioning enables controlled comparison but limits statistical power for larger n values (only 1 group for n=25)

- **Failure signatures:**
  - Stable ASR with increasing n indicates systematic rather than stochastic failures
  - WikiTypo ASR >10% at n=25 signals that human-like noise creates semantic disruption
  - High variance across groups for smaller n indicates sensitivity to sample composition

- **First 3 experiments:**
  1. **Reproduce baseline**: Run Agent Forest on GSM8K with n=[1,5,10,25] under clean and WikiTypo conditions; verify ASR stability and accuracy gains match paper
  2. **Noise type comparison**: Test a single model on all four noise types at matched intensity; confirm ordering WikiTypo > Punct-50 ≥ Punct-30 ≥ R2ATA ≥ Punct-10
  3. **Model scale test**: Compare Qwen3-4B vs. Qwen3-14B on MATH with n=[1,5,10]; verify larger model has lower ASR and smaller model has steeper accuracy gains from collaboration

## Open Questions the Paper Calls Out

- **Question 1:** Can advanced multi-agent collaboration strategies (e.g., debate, tool-use) reduce the adversarial robustness gap more effectively than simple sampling-and-voting?
  - **Basis in paper:** [explicit] The Conclusion lists "verifier-or tool-assisted agents" as a promising direction, and the Limitations section explicitly states the study did not compare against "debate, tool-augmented agents, verifier-guided aggregation."
  - **Why unresolved:** The paper only evaluates a "single instantiation" (sampling-and-voting) of multi-agent collaboration. While this method improves accuracy, it fails to lower the Attack Success Rate (ASR), leaving the robustness gap intact.
  - **What evidence would resolve it:** A comparative study measuring ASR on the WikiTypo benchmark between the Agent Forest baseline and debate-based or tool-augmented agent frameworks.

- **Question 2:** Does training-time data augmentation specifically targeting human typos mitigate the WikiTypo bottleneck observed during inference-time aggregation?
  - **Basis in paper:** [explicit] The Conclusion suggests "training-time augmentation targeted at human typos" as a future direction, noting that "WikiTypo remains the dominant bottleneck" even with 25 agents.
  - **Why unresolved:** The study shows that increasing agent count fails to resolve the robustness gap for human-like errors (WikiTypo), indicating that voting alone cannot handle these heterogeneous distortions.
  - **What evidence would resolve it:** Evaluation of models fine-tuned on typo-augmented datasets within the Agent Forest framework to see if the specific ASR for WikiTypo decreases relative to Clean accuracy.

- **Question 3:** Does using heterogeneous agents (different base models) break the error correlation and improve robustness better than homogeneous sampling?
  - **Basis in paper:** [inferred] The Limitations section notes that "all agents share the same base model, so errors can be correlated," suggesting this correlation might be why the robustness gap persists.
  - **Why unresolved:** The authors evaluate families of models separately (e.g., Qwen, Llama) using self-consistency. It is unclear if aggregating across different model architectures reduces the Attack Success Rate by canceling out model-specific failure modes.
  - **What evidence would resolve it:** Experiments combining different model families (e.g., one Llama, one Gemma, one Mistral agent) to determine if the ensemble achieves a lower ASR than a homogeneous group of the same size.

## Limitations
- Same base model for all agents creates correlated errors that reduce voting effectiveness
- Decoding parameters and prompts remain unspecified, limiting exact reproduction
- Noise generation methodology unclear for WikiTypo dictionary and R2ATA benchmark
- No evaluation of heterogeneous agent ensembles or advanced collaboration strategies

## Confidence

- **High confidence**: The core finding that accuracy improves with more agents while ASR remains stable; the dominance of human typos (WikiTypo) as the most challenging noise type
- **Medium confidence**: The claim that larger models show better inherent robustness; the assertion that punctuation noise is more recoverable than human-like typos through collaboration
- **Low confidence**: The precise mechanisms by which noise types differentially affect multi-agent collaboration, as these depend on undocumented implementation details

## Next Checks

1. **Reproduce baseline ASR stability**: Run Agent Forest on GSM8K with n=[1,5,10,25] under clean and WikiTypo conditions; verify that accuracy increases while ASR remains stable as reported
2. **Noise type sensitivity mapping**: Test a single model across all four noise types at matched intensity levels; confirm the relative ordering WikiTypo > Punct-50 ≥ Punct-30 ≥ R2ATA ≥ Punct-10
3. **Model scale robustness comparison**: Compare Qwen3-4B vs. Qwen3-14B on MATH with n=[1,5,10]; verify larger model shows lower ASR and smaller model shows steeper accuracy gains from collaboration