---
ver: rpa2
title: Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025
  Challenge
arxiv_id: '2509.02640'
source_url: https://arxiv.org/abs/2509.02640
tags:
- atypical
- mitotic
- stain
- classification
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of classifying atypical mitotic
  figures (AMFs) in histopathological images, which are clinically significant but
  difficult to detect due to morphological ambiguity and scanner variability. The
  authors propose adapting the pathology foundation model UNI2-h using visual prompt
  tuning (VPT) combined with stain normalization and test-time augmentation (TTA).
---

# Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge

## Quick Facts
- arXiv ID: 2509.02640
- Source URL: https://arxiv.org/abs/2509.02640
- Reference count: 12
- Primary result: Achieved 0.8837 balanced accuracy and 0.9513 ROC-AUC on MIDOG2025 Track 2 preliminary leaderboard

## Executive Summary
This paper addresses the challenge of classifying atypical mitotic figures (AMFs) in histopathological images, which are clinically significant but difficult to detect due to morphological ambiguity and scanner variability. The authors propose adapting the pathology foundation model UNI2-h using visual prompt tuning (VPT) combined with stain normalization and test-time augmentation (TTA). Their approach includes domain-adversarial learning to reduce scanner-specific biases and employs multiple stain normalization techniques (Vahadane and Macenko) during inference. The final method achieved a balanced accuracy of 0.8837 and an ROC-AUC of 0.9513 on the MIDOG2025 Track 2 preliminary leaderboard, ranking within the top 10 teams.

## Method Summary
The approach adapts UNI2-h pathology foundation model through visual prompt tuning, where learnable prompt tokens are inserted before each transformer encoder layer while the backbone remains frozen. Domain-adversarial learning via gradient reversal layer (GRL) encourages scanner-invariant features by penalizing preservation of scanner-specific information. For inference, the method applies test-time augmentation combining Vahadane and Macenko stain normalization with geometric augmentations (flips and 90° rotations), averaging predictions across all variants. The framework addresses the challenge of atypical mitosis classification under scanner domain shift in the MIDOG2025 Track 2 competition.

## Key Results
- Achieved 0.8837 balanced accuracy on MIDOG2025 Track 2 preliminary leaderboard
- Obtained 0.9513 ROC-AUC score for binary classification of normal vs. atypical mitoses
- Demonstrated sensitivity of 0.9577 and specificity of 0.8097, showing strong detection capability but asymmetric error rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Visual Prompt Tuning (VPT) enables parameter-efficient adaptation of the UNI2-h foundation model by learning task-specific steering while preserving pretrained morphological knowledge.
- Mechanism: Learnable prompt tokens are inserted before each transformer encoder layer. During training, the backbone remains frozen while prompts and the classification head update. Prompts modulate attention patterns to emphasize atypical mitotic features without overwriting the foundation model's histopathological representations.
- Core assumption: UNI2-h's pretrained representations already encode morphological primitives relevant to mitosis; only task-specific routing is needed.
- Evidence anchors:
  - [abstract]: "investigated three variants of adapting the pathology foundation model UNI2... VPT + UNI2 + Vahadane Normalizer"
  - [section]: "During training, the backbone parameters are frozen, while only the prompt tokens and the classification head are updated. This greatly reduces trainable parameters while still enabling the model to capture discriminative morphological patterns"
  - [corpus]: PRO-VPT paper on distribution-adaptive prompt tuning supports viability; "A bag of tricks for real-time Mitotic Figure detection" notes domain variability challenges that efficient adaptation addresses.
- Break condition: If target domain morphologies fall outside UNI2-h's pretraining distribution (e.g., rare staining protocols), prompts alone cannot synthesize missing features.

### Mechanism 2
- Claim: Domain-adversarial learning via Gradient Reversal Layer (GRL) encourages scanner-invariant features by penalizing preservation of scanner-specific information.
- Mechanism: A domain classifier predicts scanner identity from shared features. GRL reverses gradients during backpropagation, so the feature extractor minimizes domain classifier accuracy—learning representations that cannot distinguish scanners while still distinguishing mitosis types.
- Core assumption: Scanner identity and atypical mitosis classification are separable in feature space; scanner artifacts don't carry diagnostic signal.
- Evidence anchors:
  - [abstract]: "employ domain-adversarial learning to reduce scanner-specific biases"
  - [section]: "To explicitly encourage domain-invariant features, we attach a domain classifier to the shared feature space and train it with a Gradient Reversal Layer (GRL). Scanner labels are used to supervise this branch"
  - [corpus]: Limited direct corpus evidence on GRL for mitosis classification; neighboring papers focus on detection architectures rather than domain adaptation explicitly.
- Break condition: If scanner differences fundamentally alter mitotic appearance (not just color/staining), adversarial alignment may inadvertently remove diagnostic signal.

### Mechanism 3
- Claim: Combining multiple stain normalization methods with test-time augmentation (TTA) reduces prediction variance and improves generalization across unseen imaging conditions.
- Mechanism: Each test image is processed through Vahadane and Macenko stain normalization pipelines with geometric augmentations (flips, 90° rotations). Predictions across all variants are averaged. This ensemble smooths domain-specific artifacts while preserving classification-relevant morphology.
- Core assumption: Correct atypical mitosis classification is invariant to stain normalization choice and geometric orientation.
- Evidence anchors:
  - [abstract]: "test-time augmentation (TTA) with Vahadane and Macenko stain normalization"
  - [section]: "For each input, predictions across all augmented versions are averaged to obtain the final probability. This ensemble-like strategy reduces prediction variance and improves generalization across scanners"
  - [corpus]: "A bag of tricks for real-time Mitotic Figure detection" cites stain variations as a major challenge; MIDOG papers consistently note scanner variability.
- Break condition: Aggressive stain normalization may distort subtle chromatin patterns critical for distinguishing atypical from normal mitoses.

## Foundational Learning

- Concept: Foundation models and parameter-efficient fine-tuning
  - Why needed here: UNI2-h provides histopathology-specific representations; understanding that freezing preserves this knowledge while prompts adapt task routing is essential.
  - Quick check question: Why does freezing the backbone and only training prompts avoid catastrophic forgetting of pretrained morphological knowledge?

- Concept: Adversarial domain adaptation
  - Why needed here: GRL creates a min-max optimization where features must be discriminative for mitosis but uninformative for scanner identity.
  - Quick check question: What happens to gradient magnitude and sign when backpropagating through a gradient reversal layer, and how does this achieve domain invariance?

- Concept: Test-time augmentation for uncertainty reduction
  - Why needed here: Inference-time ensembling over stain-normalized and geometrically augmented views reduces variance without additional training.
  - Quick check question: Why would averaging predictions over multiple stain-normalized versions be more robust than choosing a single normalization method?

## Architecture Onboarding

- Component map:
  Input image → UNI2-h backbone (frozen) → Prompt tokens → Classification head → Binary output (normal/atypical)
  Input image → UNI2-h backbone → GRL → Domain classifier → Scanner identity prediction
  Inference: Input → Vahadane normalization → geometric TTA → prediction
  Inference: Input → Macenko normalization → geometric TTA → prediction
  Final: Average all predictions

- Critical path:
  1. Load UNI2-h pretrained weights and freeze all backbone parameters
  2. Initialize and register prompt tokens at each encoder block input
  3. Implement combined loss: classification cross-entropy + λ × adversarial domain loss
  4. Build inference pipeline with both stain normalizers and 4× geometric augmentations

- Design tradeoffs:
  - VPT vs. LoRA: Paper reports VPT (0.8711) outperformed LoRA (0.8305) on balanced accuracy—prompts may integrate better with ViT attention than weight factorization.
  - Sensitivity vs. specificity: Final model shows 0.9577 sensitivity but 0.8097 specificity—tuned for detecting atypical cases at cost of false positives.
  - Inference cost: Stain TTA multiplies inference time ~8× (2 normalizers × 4 geometric); acceptable for batch processing but problematic for real-time.

- Failure signatures:
  - Prompt underfitting: If prompts don't meaningfully change during training, validation accuracy stays near frozen-backbone baseline (~0.80).
  - GRL collapse: If domain loss dominates, classification accuracy drops; monitor domain accuracy staying near chance (1/num_scanners).
  - Stain normalization artifacts: Visualize normalized patches; extreme color shifts indicate reference image mismatch.

- First 3 experiments:
  1. Ablate prompt depth: Compare prompts at layer 1 only vs. all layers to measure steering localization.
  2. Single vs. dual stain normalization: Run inference with only Vahadane, only Macenko, and both to quantify ensemble benefit.
  3. GRL weight sweep: Test λ ∈ {0.1, 0.5, 1.0, 2.0} to find domain alignment strength that doesn't degrade classification.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the sensitivity-specificity trade-off be improved while maintaining the benefits of VPT and stain-normalization TTA?
- Basis in paper: [inferred] The best performing method (VPT + UNI2-h + GRL + Stain TTA) achieved high sensitivity (0.9577) but notably lower specificity (0.8097), indicating asymmetric error rates that may not be clinically optimal.
- Why unresolved: The paper does not analyze or address this imbalance; it reports aggregate metrics (balanced accuracy, ROC-AUC) without investigating whether the high false positive rate from low specificity could impact clinical utility.
- What evidence would resolve it: Experiments with class-weighted losses, threshold calibration, or cost-sensitive learning that specifically target improved specificity while preserving sensitivity gains from the proposed framework.

### Open Question 2
- Question: How computationally efficient is the proposed TTA strategy for real-world clinical deployment?
- Basis in paper: [inferred] The inference pipeline applies multiple transformations (horizontal/vertical flips, 90° rotations) and two stain normalization methods (Vahadane and Macenko) per input patch, averaging predictions across all augmented versions.
- Why unresolved: The paper provides no analysis of inference time, computational cost, or throughput limitations. For clinical workflows requiring rapid turnaround on large slide datasets, this multi-pass TTA approach may introduce unacceptable latency.
- What evidence would resolve it: Benchmarking of inference time per patch and per whole-slide image, comparison with single-pass baselines, and analysis of the accuracy-efficiency trade-off curve.

### Open Question 3
- Question: Does the domain-adversarial learning with GRL generalize to scanner types not represented during training?
- Basis in paper: [inferred] The GRL approach uses scanner labels from the training data to encourage domain-invariant features, but the preliminary test set may contain scanners with similar characteristics to training data.
- Why unresolved: True domain generalization requires evaluation on fundamentally different scanner technologies or staining protocols not seen during training. The paper's preliminary leaderboard results do not establish this broader generalization capability.
- What evidence would resolve it: Cross-dataset evaluation on external pathology datasets with scanners from different manufacturers or imaging protocols not included in MIDOG2025 training data.

### Open Question 4
- Question: How does the framework perform when mitotic figure density is extremely low or when AMFs are exceedingly rare?
- Basis in paper: [explicit] The paper acknowledges that "the scarcity of mitotic figures amplifies class imbalance" and "the subtle distinction between normal and atypical subtypes complicates reliable classification."
- Why unresolved: While these challenges are identified as motivating factors, the paper does not report stratified performance analysis across different AMF prevalence levels or tumor grades where mitotic counts vary substantially.
- What evidence would resolve it: Subgroup analysis of classification performance across cases with varying AMF frequencies, along with calibration metrics to assess prediction reliability in low-prevalence scenarios.

## Limitations
- Limited ablation studies prevent quantification of individual component contributions to final performance
- Heavy computational overhead from 8× inference time due to test-time augmentation may limit clinical deployment
- No validation on external datasets beyond MIDOG2025 to establish true domain generalization capability

## Confidence
- High Confidence: The general framework of combining prompt-based adaptation with domain-adversarial learning is technically sound and supported by established literature
- Medium Confidence: Specific implementation details and hyperparameters are not fully specified, making exact replication challenging
- Low Confidence: Claims about clinical relevance and real-world applicability are not substantiated with external validation

## Next Checks
1. **Component Ablation Study**: Implement systematic removal of VPT, GRL, and stain normalization ensemble components to quantify individual contributions to final performance. This should include running the baseline UNI2-h without any adaptation for comparison.

2. **Cross-Dataset Generalization**: Evaluate the trained model on MIDOG2022 data or other independent mitosis datasets to assess generalization beyond the specific MIDOG2025 distribution. This tests the domain-adversarial component's effectiveness in truly unseen conditions.

3. **Real-Time Performance Analysis**: Measure inference latency with and without test-time augmentation under realistic clinical workloads. Profile memory usage and determine if the 8× inference overhead creates bottlenecks in batch processing scenarios typical of pathology laboratories.