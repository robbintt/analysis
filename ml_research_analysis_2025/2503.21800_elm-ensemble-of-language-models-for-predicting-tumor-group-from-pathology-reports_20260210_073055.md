---
ver: rpa2
title: 'ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology
  Reports'
arxiv_id: '2503.21800'
source_url: https://arxiv.org/abs/2503.21800
tags:
- tumor
- pathology
- group
- reports
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ELM (Ensemble of Language Models), a novel
  approach for automating tumor group classification from pathology reports in population-based
  cancer registries. The method combines six fine-tuned small language models (SLMs)
  with a large language model (LLM) for arbitration.
---

# ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports

## Quick Facts
- arXiv ID: 2503.21800
- Source URL: https://arxiv.org/abs/2503.21800
- Authors: Lovedeep Gondara; Jonathan Simkin; Shebnum Devji; Gregory Arbour; Raymond Ng
- Reference count: 27
- Primary result: ELM achieves 0.94 average precision/recall on 2,058 pathology reports across 19 tumor groups

## Executive Summary
This paper introduces ELM (Ensemble of Language Models), a novel approach for automating tumor group classification from pathology reports in population-based cancer registries. The method combines six fine-tuned small language models (SLMs) with a large language model (LLM) for arbitration. Three SLMs analyze the top part of reports and three analyze the bottom part to maximize coverage, requiring five out of six models to agree. Disagreements are resolved by an LLM using a curated prompt. Evaluated on 2,058 pathology reports across nineteen tumor groups, ELM achieves an average precision and recall of 0.94, outperforming single-model and ensemble-without-LLM approaches.

## Method Summary
ELM processes pathology reports by partitioning each into top (first 512 tokens) and bottom (last 512 tokens) sections. Six fine-tuned SLMs (GatorTron, BCCRTron, ClinicalBERT variants) classify each section, and a 5-of-6 agreement threshold determines whether to accept the majority vote or invoke LLM arbitration. When arbitration is needed, Mistral Nemo 12B receives a curated prompt listing candidate tumor groups from the SLMs and returns a structured JSON response. The approach significantly enhances operational efficiency, saving hundreds of person-hours annually in the British Columbia Cancer Registry.

## Key Results
- ELM achieves 0.94 average precision and recall across 19 tumor groups
- Outperforms single-model (0.91) and ensemble-without-LLM (0.93) approaches
- Successfully automates a manual task saving hundreds of person-hours annually
- Maintains high performance even on difficult tumor groups through LLM arbitration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spatial partitioning of pathology reports across ensemble members improves coverage and classification accuracy.
- Mechanism: Three SLMs process the first 512 tokens (top section), and three process the last 512 tokens (bottom section). This compensates for transformer token limits and ensures anatomical descriptions appearing anywhere in the report are captured. Votes are summed per tumor group.
- Core assumption: Tumor-relevant information is distributed throughout pathology reports, not concentrated in a single section.
- Evidence anchors:
  - [abstract] "three SLMs use the top part of the pathology report and three SLMs use the bottom part. This is done to maximize report coverage."
  - [section 3.1] "During the finetuning process, the top three models use the first 512 tokens from the pathology report and the bottom three models use the last 512 tokens."
  - [corpus] Weak direct evidence; neighboring papers focus on model adaptation and multimodal approaches rather than spatial partitioning strategies.
- Break condition: If pathology reports in a new domain consistently have diagnostic information in a predictable location, spatial partitioning adds computational overhead without accuracy gains.

### Mechanism 2
- Claim: High-agreement voting thresholds reduce LLM invocation while maintaining accuracy.
- Mechanism: A 5-of-6 agreement threshold filters cases. Only reports failing consensus or belonging to hard-to-classify tumor groups proceed to LLM arbitration. This limits expensive LLM inference to genuinely uncertain cases.
- Core assumption: High ensemble agreement correlates with correct classification; disagreement signals genuine ambiguity requiring more capable language understanding.
- Evidence anchors:
  - [abstract] "ELM requires five-out-of-six agreement for a tumor group classification. Disagreements are arbitrated by an LLM."
  - [section 4.2] Table 3 shows Precision/Recall improving from 0.93/0.91 (SLM only) to 0.94/0.94 (ELM with LLM arbitration).
  - [corpus] "Cancer Type, Stage and Prognosis Assessment from Pathology Reports using LLMs" supports LLM utility for complex extraction but does not evaluate voting-based filtering.
- Break condition: If the ensemble systematically agrees on wrong classifications (high confidence errors), the threshold will filter these away from LLM correction.

### Mechanism 3
- Claim: Constraining LLM output choices to SLM-suggested tumor groups improves arbitration accuracy.
- Mechanism: The LLM receives a curated prompt listing only tumor groups suggested by SLMs plus SME-specified hard cases. The LLM must select from this constrained set and output structured JSON with reasoning. This prevents hallucination to invalid categories.
- Core assumption: The correct tumor group is among the candidates the SLMs propose; the LLM's advantage is nuanced language understanding, not expanding the candidate space.
- Evidence anchors:
  - [section 2.2] "This constraint is enforced to ensure that the LLM's response is within the most probable tumor groups."
  - [section 5] "We also tested this approach and observed that the LLM only model performs significantly worse in comparison to ELM, mainly because in that scenario the LLM has to select from nineteen tumor groups."
  - [corpus] "Small or Large? Zero-Shot or Finetuned?" explores SLM vs LLM tradeoffs but does not address constrained output spaces for arbitration.
- Break condition: If SLMs systematically miss the correct tumor group entirely, constraining LLM choices prevents recovery.

## Foundational Learning

- Concept: Transformer token limits (typically 512 for BERT-family models)
  - Why needed here: Understanding why the ensemble splits reports into top and bottom sections; not reading full documents at once.
  - Quick check question: Can you explain why a 2000-token pathology report cannot be processed by a standard BERT model in a single forward pass?

- Concept: Ensemble voting and consensus thresholds
  - Why needed here: The 5-of-6 agreement rule is the core filtering mechanism; understanding confidence vs. correctness tradeoffs.
  - Quick check question: If 4 models vote for tumor group A and 2 vote for B, what happens to this report in ELM?

- Concept: Zero-shot LLM prompting with structured output
  - Why needed here: The arbitration LLM uses carefully designed prompts without fine-tuning; understanding prompt engineering for constrained JSON output.
  - Quick check question: Why does the prompt instruct the LLM to respond only with valid JSON rather than natural language?

## Architecture Onboarding

- Component map:
  - Input layer: HL7 pathology reports → text extraction → top/bottom partitioning (512 tokens each)
  - SLM ensemble: 6 fine-tuned models (GatorTron, BCCRTron, ClinicalBERT × top/bottom variants)
  - Voting layer: Sum votes per tumor group → check threshold (≥5 agreement)
  - Arbitration layer: Mistral Nemo 12B (or smaller alternative) with curated prompt → JSON output
  - Output: Tumor group classification + optional LLM reasoning

- Critical path:
  1. Report ingestion and tokenization (top 512, bottom 512)
  2. Parallel inference across 6 SLMs
  3. Vote aggregation and threshold check
  4. If threshold met and not hard-to-classify → return majority vote
  5. If threshold failed or hard tumor group → construct prompt with candidate groups → LLM inference → parse JSON

- Design tradeoffs:
  - Larger LLM (12B) vs. smaller (3B): Mistral Nemo achieves 0.94 F1; Llama 3.2 and Qwen 2.5 drop to 0.92. Paper suggests smaller LLMs as viable when compute-constrained.
  - Voting threshold strictness: 5-of-6 balances LLM invocation rate vs. accuracy. Lower threshold = more LLM calls, higher cost; higher threshold = more unresolvable cases.
  - Hard-coded hard-to-classify list vs. dynamic detection: Paper manually specifies cervix, multiple myeloma, primary unknown, skin. Requires SME input and periodic review.

- Failure signatures:
  - High-confidence wrong ensemble: All 6 SLMs agree on incorrect tumor group → LLM never sees it → silent error.
  - LLM prompt rejection: If JSON parsing fails, system needs fallback (not specified in paper).
  - Token limit edge case: Reports shorter than 512 tokens may have redundant top/bottom views, reducing ensemble diversity benefit.
  - Label noise propagation: Training labels assigned per-patient, not per-report; paper claims resilience but rare tumors with limited data may suffer.

- First 3 experiments:
  1. Replicate single-model vs. ensemble comparison on a held-out validation set to verify 0.91 → 0.93 precision gain before deploying full pipeline.
  2. Ablate the LLM arbitration by lowering threshold to 4-of-6 and measuring F1 change; quantifies LLM contribution vs. voting strictness.
  3. Test prompt variations on a sample of discordant cases to verify constrained candidate list improves accuracy over full 19-class open selection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the ELM framework maintain its performance when applied to pathology reports from other Population-Based Cancer Registries (PBCRs) with different reporting standards or languages?
- Basis in paper: [explicit] The authors state in the Discussion: "Our future work involves validation of our proposed approach on other data sources (other PBCRs)..."
- Why unresolved: The current study validates the method only on data from the British Columbia Cancer Registry (BCCR), which may have specific formatting or linguistic characteristics not present in other regions.
- What evidence would resolve it: Evaluation of the ELM architecture on external pathology datasets from diverse geographic regions or healthcare systems without retraining the core models.

### Open Question 2
- Question: Does fine-tuning the arbitrating Large Language Model (LLM) yield higher classification accuracy than the zero-shot approach currently employed?
- Basis in paper: [explicit] The authors explicitly list as future work: "...evaluating the impact of fine-tuned LLMs instead of the zero shot approach as used in this paper."
- Why unresolved: While the zero-shot approach (Mistral Nemo) performed well, it is unknown if domain-specific fine-tuning could better capture the nuanced definitions of complex tumor groups (e.g., distinguishing lymphoma from leukemia) more effectively.
- What evidence would resolve it: A comparative study measuring precision and recall between the current zero-shot Mistral Nemo implementation and a version of the model fine-tuned on the BCCR pathology dataset.

### Open Question 3
- Question: Does the strategy of splitting reports into "top" and "bottom" 512-token segments result in the loss of critical diagnostic information located in the middle of long pathology reports?
- Basis in paper: [inferred] The methodology acknowledges that transformer models have token limits, solved by using the first and last 512 tokens. The authors imply this maximizes coverage, but do not verify if the discarded middle text contains relevant tumor group signals.
- Why unresolved: The paper does not analyze false negatives or errors specifically caused by the truncation of the report's central text.
- What evidence would resolve it: An ablation study using a long-context model (e.g., Longformer or a large-context LLM) that processes the full report text compared to the truncated segments to identify any performance gap.

### Open Question 4
- Question: Can the classification performance for "Primary Unknown" and "Skin" tumor groups be improved through architecture changes, given they showed significantly lower F1-scores even with LLM arbitration?
- Basis in paper: [inferred] The results section shows that despite LLM arbitration, "Primary Unknown" achieved an F1-score of only 0.38 and "Skin" 0.58, lagging far behind the 0.94 average.
- Why unresolved: The paper identifies these as "hard-to-classify" and shows LLM helps, but the remaining low scores suggest the current combination of SLM voting and LLM arbitration is insufficient for these specific categories.
- What evidence would resolve it: Analysis of the specific failure modes for these classes (e.g., ambiguous prompts or lack of training data) and testing alternative strategies such as specialized few-shot prompting or dedicated sub-classifiers for these groups.

## Limitations
- Data privacy constraints prevent independent verification; BCCR dataset is private
- Proprietary "BCCRTron" model weights not publicly available, requiring substitution
- Label noise from patient-level labeling across multiple reports introduces uncertainty
- Hard-coded list of difficult tumor groups requires SME domain knowledge and may not generalize

## Confidence
- High confidence: The ensemble voting mechanism and spatial partitioning strategy are well-specified and reproducible with any pathology dataset
- Medium confidence: The reported performance metrics (0.94 F1) depend on specific clinical language patterns in BCCR data and proprietary BCCRTron model weights
- Low confidence: The long-term operational impact (person-hours saved) and clinical validation through manual review are based on registry-specific workflows

## Next Checks
1. Replicate the single-model vs. ensemble comparison using a held-out validation set from TCGA or MIMIC-CXR pathology reports to verify the 0.91 → 0.93 precision gain before deploying full pipeline.

2. Perform an ablation study by lowering the voting threshold to 4-of-6 and measuring F1 change to quantify the LLM contribution versus voting strictness trade-off.

3. Test prompt variations on a sample of discordant cases to verify that constraining the LLM to SLM-suggested tumor groups improves accuracy compared to allowing open selection from all 19 classes.