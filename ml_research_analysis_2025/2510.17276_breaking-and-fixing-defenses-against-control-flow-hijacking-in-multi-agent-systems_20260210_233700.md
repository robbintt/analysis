---
ver: rpa2
title: Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent
  Systems
arxiv_id: '2510.17276'
source_url: https://arxiv.org/abs/2510.17276
tags:
- file
- agent
- agents
- user
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses control-flow hijacking attacks in multi-agent
  systems, where adversarial content manipulates orchestration mechanisms to compromise
  security and exfiltrate sensitive data. Existing defenses based on alignment checks
  are shown to be brittle and evadable through sophisticated attacks that disguise
  malicious instructions as necessary error resolutions.
---

# Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems

## Quick Facts
- arXiv ID: 2510.17276
- Source URL: https://arxiv.org/abs/2510.17276
- Authors: Rishi Jha; Harold Triedman; Justin Wagle; Vitaly Shmatikov
- Reference count: 40
- Primary result: ControlValve blocks all control-flow hijacking attacks while maintaining or improving benign task performance

## Executive Summary
This paper addresses control-flow hijacking (CFH) attacks in multi-agent systems (MAS), where adversarial content manipulates orchestration mechanisms to compromise security and exfiltrate sensitive data. Existing alignment-based defenses fail because they cannot resolve the fundamental safety/functionality conflict when checkers lack full execution context. The proposed ControlValve defense enforces control-flow integrity by generating permitted control-flow graphs and contextual rules for agent invocations before untrusted content is processed, achieving 0% attack success rate while maintaining or improving benign task performance.

## Method Summary
ControlValve is a CFI-inspired defense that generates a context-free grammar (CFG) defining permitted agent invocation sequences and edge-specific contextual rules before execution. During runtime, it checks each agent transition against the CFG and edge rules using a narrow LLM judge that only evaluates rule compliance, not action alignment. This approach blocks CFH attacks by preventing runtime reasoning-through attacks while maintaining functional task completion.

## Key Results
- ControlValve achieved 0% attack success rate across diverse CFH scenarios
- Maintained or improved benign task performance (97% coding accuracy vs 93% baseline)
- Significantly outperformed alignment-based approaches (LlamaFirewall achieved 53-77% ASR)
- Successfully blocked all evaluated CFH attack templates across coding and computer-use domains

## Why This Works (Mechanism)

### Mechanism 1
Alignment-based defenses fail against CFH because the safety/functionality conflict is fundamentally unresolvable at runtime when checkers lack full context visibility. CFH attacks present malicious actions as (1) necessary to complete the task, (2) received from a trusted agent, and (3) not unconditionally harmful. Alignment checkers must judge "related to" and "likely to further" goals with incomplete context, and attackers exploit this ambiguity. Core assumption: Alignment checkers cannot distinguish genuine errors from attack-masquerading-as-errors without full execution context. Break condition: If alignment checkers had complete visibility into all agent states and could perfectly distinguish error contexts, this attack vector would close.

### Mechanism 2
CFH succeeds by laundering adversarial instructions through trusted agents via confused-deputy vulnerabilities in delegation. Attackers embed malicious instructions in untrusted content formatted as error messages with "helpful" fix instructions. The orchestrator receives these from a trusted agent that processed the content, then re-plans to invoke unsafe agents. The original CFH attacks achieved 80-100% success rate against undefended systems. Core assumption: Orchestrators trust agents' reports and adaptively re-plan without verifying if error conditions are genuine. Break condition: If agents cryptographically signed error conditions or orchestrators required out-of-band verification of fault states, the confused-deputy channel would be disrupted.

### Mechanism 3
ControlValve blocks attacks by pre-computing control-flow constraints before ingesting untrusted content, preventing runtime reasoning-through attacks. (1) Generate a context-free grammar defining permitted agent invocation sequences based on task and available agents (done pre-execution, no attack exposure). (2) For each graph edge A→B, generate contextual rules via zero-shot LLM prompting specifying when B may be invoked given A's output. (3) At runtime, check each transition against the CFG and edge rules using a narrow LLM judge that only evaluates rule compliance, not action alignment. This achieved 0% attack success rate across all evaluated CFH scenarios. Core assumption: Attackers cannot influence CFG/rule generation because these happen before untrusted content is processed. Break condition: If the CFG is over-approximate and permits executions that should not happen, attackers could find compliant-but-malicious paths.

## Foundational Learning

- **Control-Flow Integrity (CFI)**
  - Why needed here: ControlValve is explicitly inspired by CFI from programming languages security. Understanding CFI's core insight—that restricting valid execution paths is more robust than detecting malicious intent—is essential to grasp why this defense works where alignment checks fail.
  - Quick check question: In traditional CFI, what information is used to determine the set of valid control-flow transitions, and how does this differ from "alignment checking"?

- **Confused Deputy Attack**
  - Why needed here: CFH is a confused deputy attack at the orchestration layer. The deputy (trusted agent) has legitimate authority to invoke actions, but is tricked into using that authority for the attacker's benefit. Understanding this clarifies why restricting which agents can be invoked is insufficient—the problem is contextual misuse of legitimate capabilities.
  - Quick check question: If a web surfer agent has legitimate access to fetch URLs, how does a confused deputy attack exploit this without compromising the agent itself?

- **Information Flow Control (IFC) vs. Capability Restriction**
  - Why needed here: The paper distinguishes ControlValve from IFC approaches (Dual-LLM, etc.) which require full visibility into agent internals and struggle with error recovery. ControlValve operates at the orchestration layer only, trading granularity for deployability on black-box agents.
  - Quick check question: Why would an IFC approach that completely separates trusted/untrusted data flows fail to handle genuine file-parsing errors discovered during execution?

## Architecture Onboarding

- **Component map**: User prompt → Planning Stage (CFG Generator → Lark parser compilation; Edge Rule Generator) → Execution Stage (Orchestrator intercepts transitions → CFG Check → Edge Rule Check → Permit/Re-plan/Reject)
- **Critical path**: 1. User prompt arrives → Planning Stage generates CFG and edge rules (exposed only to trusted user input) 2. During rollout, before each agent-to-agent transition, orchestrator calls ControlValve 3. ControlValve verifies trace + proposed transition against parsed CFG 4. If CFG-valid, LLM judge evaluates transition context against that edge's rules 5. If rules violated: check if replanning possible (up to 3 attempts), else reject with user-facing message
- **Design tradeoffs**:
  - **Over-approximation risk**: CFG may permit legitimate-but-overly-broad paths; paper acknowledges CFI research shows compliant-but-malicious executions are possible (open research question)
  - **Under-approximation risk**: Overly restrictive graphs block legitimate error recovery; paper evaluates benign performance (97% coding, 100% computer-use accuracy) to show acceptable tradeoff
  - **Rule judge dependency**: Edge rules are natural-language; LLM judge must correctly interpret them. The narrow scope (only rule compliance, not goal alignment) reduces error surface compared to alignment checks
- **Failure signatures**:
  - **CFG too permissive**: Attack finds a path compliant with CFG/rules but achieves adversarial objective (not observed in evaluation, but acknowledged as theoretical risk)
  - **CFG generation failure**: LLM produces unparseable grammar; paper reports up to 20% parse failures with weaker models (4o-mini), requiring retries (Table 5)
  - **Edge rules insufficient**: Generated rules don't cover attack scenario; paper limits to 3 rules/edge to avoid over-constraining, trading completeness for usability
  - **Benign task blocked**: Overly strict rules prevent legitimate error recovery; Table 7-8 show ~3-11% benign performance degradation in some coding subcategories
- **First 3 experiments**:
  1. **Reproduce alignment-check failure**: Run the CFH-Hard coding attacks (WordPress template) against LlamaFirewall with GPT-4o backing. Verify high attack success rate (Table 2: 53-77%). Analyze why alignment checkers judge malicious "notify support" instructions as aligned.
  2. **Validate CFG parseability**: Implement the CFG generation pipeline with o4-mini, GPT-4o, and GPT-4o-mini on the 16 CFH-Hard tasks. Measure parse rates and retry counts (target: match Table 5). Identify which task types cause generation failures.
  3. **Test edge rule coverage**: For the "visualize acquisitions" task (Appendix I), manually verify that generated rules would block the File Not Found and Agent Not Found attack templates. Check if rules correctly require Coder→Executor ordering and restrict Executor to running only Coder-supplied scripts.

## Open Questions the Paper Calls Out

### Open Question 1
Can attackers craft control-flow hijacking (CFH) attacks that comply with ControlValve's generated Control Flow Graph (CFG) while still achieving malicious objectives? Basis in paper: "In CFI research, there is a large body of work... on evasion attacks that compromise programs while complying with the statically computed CFG. It is an open question whether similar CFH attacks are possible in multi-agent systems." Why unresolved: ControlValve enforces structural integrity but relies on a static over-approximation of legitimate paths; it does not guarantee semantic safety if the graph is too permissive. What evidence would resolve it: A demonstration of a successful attack payload that executes a malicious action (e.g., data exfiltration) while strictly adhering to the agent transition constraints defined by the generated CFG.

### Open Question 2
Does the static generation of control-flow graphs impede the ability of multi-agent systems to adaptively recover from unforeseen environmental errors during execution? Basis in paper: "If the generated CFG is too restrictive, it may limit functionality of MAS by preventing agents from adaptively invoking new agents and tools when they encounter genuine errors and faults." Why unresolved: While the paper shows maintained benign performance on standard tasks, it acknowledges that restricting adaptive invocation is a potential failure mode requiring further investigation. What evidence would resolve it: Evaluation metrics on a dataset of tasks specifically designed to require out-of-plan agent interactions (e.g., novel error codes requiring unlisted tools) showing comparable recovery rates between defended and undefended systems.

### Open Question 3
How robust is ControlValve's rule generation when instantiated with smaller or less capable LLMs, particularly regarding the enforcement of "guarding" behaviors for high-risk agents? Basis in paper: Ablation results (Appendix B) show that while parseability is high, the "guarding" metric (forcing auditing agents to precede risky ones) drops significantly for models like 4o-mini compared to o4-mini. Why unresolved: The paper focuses on advanced models (GPT-4o, o4) but notes that deployment on weaker models may result in incomplete security policies or necessitate more retries. What evidence would resolve it: An ablation study comparing the Attack Success Rate (ASR) of ControlValve when backed by capable models (o4-mini) versus weaker models (4o-mini) to quantify the security degradation caused by imperfect rule generation.

## Limitations
- CFG over-approximation risk: The paper acknowledges that CFI-inspired defenses can permit compliant-but-malicious execution paths, though no such attacks were observed in evaluation
- Edge rule generation reliability: CFG generation with weaker models (4o-mini) showed up to 20% parse failures requiring retries
- Evaluation scope constraints: Testing was limited to 16 coding and 7 computer-use tasks against 5 CFH attack types

## Confidence
- **High Confidence**: ControlValve's fundamental mechanism (pre-computing CFG and edge rules) is sound and demonstrably blocks all evaluated CFH attacks (0% ASR). The failure of alignment-based defenses is well-supported by the paper's analysis of the safety/functionality conflict.
- **Medium Confidence**: Benign performance claims (97% coding, 100% computer-use accuracy) are based on limited task diversity. The tradeoff between attack resistance and legitimate functionality is reasonable but requires broader validation.
- **Low Confidence**: Theoretical claims about CFG over-approximation enabling compliant-but-malicious executions are acknowledged but not empirically demonstrated.

## Next Checks
1. **Cross-Domain CFG Generation Testing**: Apply the CFG generation pipeline to 50 diverse multi-agent task templates (e.g., data analysis, customer service, medical triage) and measure parse rates, retry frequencies, and rule generation quality across different model sizes and domain-specific languages.
2. **Compliance Space Mapping**: Systematically enumerate all execution paths permitted by CFGs generated for sample tasks, then identify and test for attack vectors that follow these compliant paths but achieve adversarial objectives. This validates the paper's acknowledgment of CFI's inherent over-approximation limitations.
3. **Dynamic Rule Update Evaluation**: Implement and test a mechanism for updating edge rules during execution based on observed error patterns, measuring whether this improves benign task success rates without introducing new attack surfaces.