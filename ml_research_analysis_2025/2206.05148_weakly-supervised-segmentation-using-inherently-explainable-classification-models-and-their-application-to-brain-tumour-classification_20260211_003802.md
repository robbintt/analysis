---
ver: rpa2
title: Weakly-supervised segmentation using inherently-explainable classification
  models and their application to brain tumour classification
arxiv_id: '2206.05148'
source_url: https://arxiv.org/abs/2206.05148
tags:
- segmentation
- classification
- dataset
- brain
- tumour
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for inherently explainable deep
  learning models for brain tumor classification and weakly-supervised segmentation.
  The approach uses Global Pooling (GP) to integrate localization heatmaps directly
  into classification decisions, enabling transparency without post-hoc methods.
---

# Weakly-supervised segmentation using inherently-explainable classification models and their application to brain tumour classification

## Quick Facts
- arXiv ID: 2206.05148
- Source URL: https://arxiv.org/abs/2206.05148
- Reference count: 28
- Three GP-based models (GP-UNet, GP-ShuffleUNet, GP-ReconResNet) achieve 98.7% accuracy on tumor-only images and 0.93 F1-score on multi-class classification, with median Dice 0.728 (95% CI: 0.715-0.739) for weakly-supervised segmentation

## Executive Summary
This paper introduces inherently explainable deep learning models for brain tumor classification and weakly-supervised segmentation using Global Pooling (GP). The approach integrates GP layers into three architectures (UNet, ShuffleUNet, ResNet) to generate classification heatmaps that directly drive both decisions and interpretability. Three models were evaluated on two datasets, with the best achieving 98.7% accuracy on tumor-only images and 0.93 F1-score on multi-class classification. For weakly-supervised segmentation, the framework achieved median Dice score of 0.728 (95% CI: 0.715-0.739). The GP-UNet demonstrated optimal balance between performance and efficiency, making it suitable for clinical deployment.

## Method Summary
The framework uses Global Pooling to create inherently explainable models by integrating spatial localization directly into classification decisions. Three architectures (GP-UNet, GP-ShuffleUNet, GP-ReconResNet) were trained on brain tumor MRI datasets using image-level labels only. GlobalMaxPooling aggregates 3D feature maps into class-specific neurons while preserving spatial maps for heatmap generation. At inference, bypassing GP reveals raw heatmaps showing tumor localization. Weakly-supervised segmentation is achieved by thresholding these heatmaps using multi-level Otsu thresholding with morphological post-processing. Models were trained for 300 epochs with weighted cross-entropy loss, Adam optimizer, and extensive data augmentation.

## Key Results
- GP-UNet achieved median Dice score of 0.728 (95% CI: 0.715-0.739) for weakly-supervised segmentation
- Best model achieved 98.7% accuracy on tumor-only images and 0.93 F1-score on multi-class classification
- GP-ShuffleUNet achieved highest tumor-only accuracy (98.74%) but required 13 days training time
- GP-UNet showed optimal balance with 1.90M parameters and 4-day training time while maintaining competitive performance

## Why This Works (Mechanism)

### Mechanism 1: Inherent Explainability via Global Pooling
Global Pooling creates an inherent binding between spatial localization and classification decisions, eliminating post-hoc interpretability methods. A GP layer aggregates 3D feature maps into single-pixel neurons per class via GlobalMaxPooling. The spatial feature maps preceding pooling become the "evidence" for classification—regions surviving pooling are those driving the decision. During inference, bypassing GP reveals full-resolution heatmaps showing exactly which spatial regions contributed to each class prediction.

### Mechanism 2: Weakly-Supervised Segmentation from Classification Heatmaps
Weakly-supervised segmentation emerges from classification heatmaps via thresholding, but segmentation quality is intrinsically coupled to classification precision. Raw class-specific heatmaps are suppressed (negative values → 0 via ReLU), then binarized using multi-level Otsu thresholding (selecting highest-intensity threshold). Minor post-processing refines masks. No segmentation labels are used during training—only image-level class labels.

### Mechanism 3: Architectural Trade-offs Mediate Task Performance
Architectural inductive biases mediate trade-offs between classification efficiency, segmentation fidelity, and data regime robustness. U-Net's skip connections preserve fine-grained spatial information, benefiting segmentation. ResNet's residual learning offers data efficiency in small/mixed datasets. ShuffleUNet's increased parameters risk overfitting but achieve peak tumor-only accuracy.

## Foundational Learning

- **Concept: Global Pooling (Global Max/Average Pooling)**
  - Why needed here: The GP mechanism is the architectural core enabling both classification (via aggregation) and explainability (via spatial preservation before aggregation)
  - Quick check question: If a feature map has shape [1, 64, 224, 224] and you apply GlobalMaxPooling followed by a 1×1 conv with 3 output channels, what is the output shape, and what spatial information is preserved for the heatmap?

- **Concept: Class Activation Mapping (CAM) intuition**
  - Why needed here: The paper's heatmaps are architecturally similar to CAM—they reveal which spatial regions contribute to class predictions
  - Quick check question: Why might a post-hoc method like Grad-CAM disagree with an inherent GP heatmap on the same input?

- **Concept: Weakly-Supervised Learning**
  - Why needed here: The entire segmentation capability rests on weak supervision—training with image-level labels to produce pixel-level outputs
  - Quick check question: Given only image-level labels ("tumor present" / "tumor absent"), how does the network learn to localize tumor boundaries?

## Architecture Onboarding

- **Component map:** Input MRI → Backbone (UNet/ShuffleUNet/ReconResNet) → Feature Maps → [Training: GP → 1×1 Conv → Class Logits] OR [Inference: Bypass GP → Raw Heatmap → ReLU Suppress → Otsu Threshold → Binary Mask]

- **Critical path:**
  1. Backbone modification: Insert dropout (p=0.5) before final layer; ensure output channels match class count
  2. GP integration: Wrap backbone output with GlobalMaxPooling during training
  3. Loss: Weighted CrossEntropyLoss (class imbalance handling)
  4. Inference bifurcation: Conditionally bypass GP for heatmap generation
  5. Post-processing: ReLU suppress → multi-level Otsu (3 classes, highest threshold) → morphological cleanup

- **Design tradeoffs:**
  - GP-UNet (1.9M params, ~4 days): Best balance of efficiency + segmentation (0.728 Dice). Choose when compute is limited or segmentation is primary goal.
  - GP-ShuffleUNet (26.4M params, ~13 days): Highest tumor-only accuracy (98.74%). Choose when classification precision dominates and compute is abundant.
  - GP-ReconResNet (17.3M params, ~9 days): Best for small/mixed datasets; excels on HGG subtype (0.754 Dice on majority class). Choose for data-scarce or heterogeneous orientation scenarios.

- **Failure signatures:**
  - Scattered/overly broad heatmaps: Network may have learned spurious correlations. Check via occlusion/GBP comparison.
  - Near-zero Dice on minority class: Class imbalance + weak supervision combination failing. Verify PR curves for precision drop.
  - High training loss plateau: Dropout (p=0.5) may be too aggressive for smaller datasets. Reduce to 0.2-0.3.
  - Threshold produces empty masks: Otsu offset may be too aggressive. Tune offset on validation set.

- **First 3 experiments:**
  1. Baseline sanity check: Train GP-UNet on small subset (100-200 slices) with known tumor locations. Visually inspect raw heatmaps to confirm network attends to tumor regions.
  2. Threshold calibration: Compare fixed threshold (0.5) vs. dynamic Otsu on validation set. Record Dice for both.
  3. Class imbalance stress test: Train on BraTS with and without weighted CrossEntropyLoss. Plot PR curves for minority class (LGG).

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the Global Pooling framework be extended to fully volumetric 3D architectures to recover the spatial context lost in current 2D slice-wise processing? The authors conclude that 2D operation risks "discarding volumetric context" and explicitly call for "future research into fully volumetric 3D architectures."

- **Open Question 2:** To what extent can advanced class-balancing strategies decouple segmentation fidelity from severe class imbalances observed in the BraTS dataset? The discussion notes that "segmentation fidelity remains sensitive to severe class imbalance" and lists "advanced class-balancing strategies" as a necessary direction for future research.

- **Open Question 3:** How effectively can localization priors generated by GP-models be integrated with Vision-Language Models (VLMs) to automate biologically-grounded radiological reporting? The authors identify "integrating the generated localisation priors with Vision-Language Models (VLMs)" as a "promising avenue" for future work to facilitate automated reporting.

## Limitations
- Segmentation quality is tightly coupled to classification precision, creating cascading failure when class imbalance is extreme
- Performance on minority classes (LGG) shows significant degradation (Dice 0.715-0.733 vs 0.733-0.754 for HGG)
- Architectural hyperparameter sensitivity remains unquantified - optimal GP variant depends on dataset size and composition

## Confidence
- **High confidence:** The GP mechanism's ability to generate interpretable heatmaps (proven by consistent tumor localization in Figs. 12-13, Dice scores >0.72)
- **Medium confidence:** Weakly-supervised segmentation performance (dice scores robust for HGG but degraded for LGG; segmentation quality intrinsically tied to classification precision)
- **Medium confidence:** Architectural efficiency claims (GP-UNet's parameter efficiency established, but GP-ShuffleUNet's computational cost may limit practical deployment)

## Next Checks
1. **Class imbalance stress test:** Train with progressively increasing LGG:HGG ratios (1:1, 1:2, 1:5, 1:10) and plot segmentation performance degradation curves to quantify classification-segmentation coupling strength
2. **Ablation study:** Compare GP heatmaps against post-hoc Grad-CAM on identical inputs to measure inherent explainability gains quantitatively
3. **Cross-dataset generalization:** Evaluate the best-performing GP variant on an external brain tumor dataset (e.g., MICCAI 2015) to test architectural robustness beyond the training distribution