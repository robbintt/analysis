---
ver: rpa2
title: 'QuesGenie: Intelligent Multimodal Question Generation'
arxiv_id: '2509.03535'
source_url: https://arxiv.org/abs/2509.03535
tags:
- question
- generation
- questions
- used
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents QuesGenie, a multimodal question generation
  system designed to address the challenge of generating diverse practice questions
  from various educational content formats. The system integrates multimodal input
  handling, question generation, reinforcement learning from human feedback, and an
  interactive interface.
---

# QuesGenie: Intelligent Multimodal Question Generation

## Quick Facts
- **arXiv ID**: 2509.03535
- **Source URL**: https://arxiv.org/abs/2509.03535
- **Reference count**: 0
- **Primary result**: Intelligent multimodal system generating diverse practice questions from PPT, PDF, and audio inputs

## Executive Summary
QuesGenie is an intelligent multimodal question generation system designed to automate the creation of practice questions from diverse educational content formats including PowerPoint presentations, PDFs, and audio files. The system integrates multimodal input processing, question generation, reinforcement learning from human feedback, and an interactive interface. By leveraging deep learning models such as ResNet-50 for diagram classification and fine-tuned T5 models for text-based question generation, QuesGenie addresses the challenge of creating varied question types (true/false, MCQ, fill-in-the-blanks, matching) from both textual and visual educational materials. The system represents a step toward scalable, intelligent question generation with potential for adaptive difficulty and multilingual support.

## Method Summary
The system processes multimodal educational content through a pipeline that first identifies input format and content type. For visual inputs, a ResNet-50 classifier detects diagram types, and ChartGemma generates questions from diagrams. Text-based questions are generated using fine-tuned T5 models trained on SQuAD, RACE, and BoolQ datasets. The system supports four question types: true/false, multiple-choice, fill-in-the-blanks, and matching. Reinforcement learning via Proximal Policy Optimization is employed to improve question quality, initially using DistillRoBERTa as a reward model. The interactive interface allows users to input files and generate questions across supported formats, with plans for future enhancements including adaptive difficulty and multilingual capabilities.

## Key Results
- Strong performance in question-answer pair generation (BLEU-4: 0.1230 for questions, 0.3150 for answers; ROUGE-L: 0.3957 for questions, 0.7426 for answers)
- High accuracy diagram classification (99%) using ResNet-50
- Reinforcement learning showed marginal improvements, with further gains dependent on reward model fine-tuning using user feedback

## Why This Works (Mechanism)
The system leverages specialized deep learning models for different content types: ResNet-50 for accurate diagram classification enables targeted question generation from visual content, while fine-tuned T5 models trained on educational datasets provide high-quality text-based questions. The reinforcement learning component with Proximal Policy Optimization allows iterative improvement based on feedback, though current gains are limited by the reward model's training data. The multimodal architecture processes PPT, PDF, and audio inputs through a unified pipeline, generating multiple question types to address diverse learning needs.

## Foundational Learning

**Diagram Classification (ResNet-50)**
*Why needed*: Accurately identifying diagram types is essential for generating relevant questions from visual content
*Quick check*: Validate classification accuracy across diverse diagram datasets beyond the 6 categories tested

**Text-based Question Generation (T5 models)**
*Why needed*: Generating pedagogically sound questions from educational text requires models trained on relevant datasets
*Why needed*: Question diversity (true/false, MCQ, fill-in-the-blanks, matching) addresses different learning objectives
*Quick check*: Evaluate question quality and answerability across different educational domains

**Reinforcement Learning (PPO)**
*Why needed*: Iterative improvement of question quality through feedback mechanisms
*Quick check*: Measure performance gains after reward model fine-tuning with actual user feedback

## Architecture Onboarding

**Component map**: PPT/PDF/Audio Input -> Content Type Detection -> ResNet-50 (Diagrams) / T5 Models (Text) -> Question Generation -> Reinforcement Learning (PPO) -> Interactive Interface

**Critical path**: Content type detection → appropriate model selection → question generation → RL optimization → user interface

**Design tradeoffs**: Specialized models for different content types increase accuracy but add complexity; reinforcement learning offers improvement potential but requires extensive user feedback data

**Failure signatures**: 
- Diagram misclassification leads to irrelevant questions
- Text generation errors produce unanswerable or incorrect questions
- RL component shows minimal improvement without adequate reward model training

**First experiments**:
1. Test diagram classification accuracy on expanded dataset with diverse visual content
2. Evaluate question quality across different educational domains and difficulty levels
3. Implement user feedback collection to enable reward model fine-tuning

## Open Questions the Paper Calls Out
None

## Limitations
- Small ResNet-50 classifier may not generalize to diverse diagram types beyond tested categories
- Reinforcement learning improvements are marginal and dependent on future reward model fine-tuning
- No explicit evaluation of diagram-based question quality or correctness

## Confidence
- **Medium** confidence in reported performance metrics due to absence of detailed validation procedures and user studies
- **Low** confidence in reinforcement learning results as improvements are described as marginal and dependent on future fine-tuning
- **Medium** confidence in diagram classification accuracy, though dataset diversity and real-world applicability remain unclear

## Next Checks
1. Conduct user study with educators to evaluate pedagogical quality and diversity of generated questions, especially for diagram-based queries
2. Expand and diversify diagram classification dataset to include broader range of diagram types and assess robustness
3. Implement and evaluate reward model fine-tuning using real user feedback, measuring impact on reinforcement learning-driven question quality improvements