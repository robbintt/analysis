---
ver: rpa2
title: 'FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance'
arxiv_id: '2602.02060'
source_url: https://arxiv.org/abs/2602.02060
tags:
- feature
- reliance
- spurious
- filora
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "FiLoRA introduces instruction-conditioned gating to enable explicit\
  \ control over which internal feature pathways a multimodal model relies on. It\
  \ decomposes LoRA updates into groups aligned with semantic, visual, and acoustic\
  \ computation paths, then modulates each group\u2019s contribution via natural language\
  \ instructions."
---

# FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance

## Quick Facts
- arXiv ID: 2602.02060
- Source URL: https://arxiv.org/abs/2602.02060
- Authors: Hyunsuk Chung; Caren Han; Yerin Choi; Seungyeon Ji; Jinwoo Kim; Eun-Jung Holden; Kyungreem Han
- Reference count: 40
- Key outcome: FiLoRA achieves measurable shifts in feature reliance (GMR 0.42–0.51) and higher decision stability (0.80 agreement) than baselines when spurious features are removed.

## Executive Summary
FiLoRA introduces instruction-conditioned gating to enable explicit control over which internal feature pathways a multimodal model relies on. It decomposes LoRA updates into groups aligned with semantic, visual, and acoustic computation paths, then modulates each group's contribution via natural language instructions. Across text-image and audio-visual benchmarks, FiLoRA achieves measurable shifts in reliance: under focus-core instructions, core feature groups exhibit higher reliance sensitivity than spurious ones, with Gate Modulation Range averaging 0.42–0.51 across datasets. Under spurious feature interventions, FiLoRA maintains higher decision stability and degrades more gradually than full fine-tuning, LoRA, and prompt-only baselines, demonstrating improved robustness through reliance regulation. The method generalizes across model scales and architectures without altering the task or label space.

## Method Summary
FiLoRA extends LoRA by decomposing low-rank updates into semantically aligned feature groups and applying instruction-conditioned gating. An instruction encoder maps natural language instructions to gate vectors that softly scale each group's contribution during the forward pass. During training, supervision routing is used: core labels for focus-core conditions, spurious proxy labels for spurious-emphasis conditions, with the condition never exposed to the model. This induces instruction-reliance associations while keeping the task fixed. The method intervenes at the parameter level, allowing learned reliance patterns to persist at inference.

## Key Results
- GMR averaging 0.42–0.51 across datasets demonstrates measurable shifts in gate modulation under different instructions
- RS Core/Spurious ratio shifts from 2.59 (Focus-Core) to 0.45 (Ignore-Core) show functional control over reliance patterns
- Decision stability of 0.80 agreement under spurious feature removal, higher than full FT, LoRA, and P-only baselines

## Why This Works (Mechanism)

### Mechanism 1: Instruction-to-Gate Mapping as Computation Control
- Natural language instructions can produce causal shifts in internal feature reliance through continuous gate vectors that softly scale LoRA group contributions during forward passes.
- Core assumption: Feature groups can be meaningfully decomposed and aligned with semantically interpretable computation pathways.
- Evidence anchors: Instruction-conditioned gating shown in abstract; gates independent of supervision signals per section 3.5; related work on representation disentanglement (arXiv:2508.08570).
- Break condition: If gate values saturate near 0 or 1 for all instructions, or if GMR approaches zero, instruction-conditioned control is not functioning.

### Mechanism 2: Supervision Routing Induces Reliance Patterns Without Task Redefinition
- Shifting supervision targets under different instructions teaches the model to associate instruction semantics with distinct reliance patterns while keeping task and labels fixed.
- Core assumption: Spurious proxy labels meaningfully capture reliance on restricted feature subsets with limited semantic leakage.
- Evidence anchors: Supervision routing never revealed to model per section 3.6; RS ratio shifts from 2.59 to 0.45 in Table 2; work on memorization effects under spurious correlations (arXiv:2501.00961).
- Break condition: If RS ratios remain similar across instruction conditions, or if proxy labels highly correlate with core labels.

### Mechanism 3: Parameter-Level Gating Persists Better Than Activation Steering
- Intervening at the parameter (LoRA) level, where feature reliance is established during optimization, yields more persistent and robust control than post-hoc activation steering.
- Core assumption: LoRA rank is sufficient to express semantically meaningful pathway differences; groups are not so entangled that gating one affects others unpredictably.
- Evidence anchors: Parameter-level intervention per section 3.8; FiLoRA maintains higher decision stability (0.80 agreement) than baselines per section 5.3; activation steering approaches discussed as fragile in corpus.
- Break condition: If performance degrades sharply when spurious features are suppressed at test time, or if different instructions produce similar gate activations.

## Foundational Learning

- **LoRA (Low-Rank Adaptation)**
  - Why needed here: FiLoRA extends LoRA by decomposing its low-rank updates into groups. Without understanding ΔW = BA^T and how LoRA attaches to frozen backbones, the grouped extension will be unclear.
  - Quick check question: Can you explain why LoRA keeps the base model frozen and how the low-rank update is applied during inference?

- **Feature Reliance vs. Task Performance**
  - Why needed here: FiLoRA explicitly decouples controlling reliance from maximizing accuracy. Understanding that models can achieve high accuracy via spurious shortcuts is essential to motivate this work.
  - Quick check question: Give an example where a model could score high on a benchmark by exploiting a shortcut that is not causally related to the task.

- **Gate Modulation and Differentiable Control**
  - Why needed here: The gating mechanism uses sigmoid-softened, instruction-conditioned scalars to differentiably control pathway contributions. Understanding gradient flow through gates is necessary for debugging training.
  - Quick check question: If a gate value g_g(I) is near 0.5 for all instructions, what does that imply about the instruction encoder's discriminative power?

## Architecture Onboarding

- **Component map:**
  Instruction text → instruction encoder → gate vector → scaled LoRA updates → forward pass through frozen backbone → logits → loss (with optional gate regularization)

- **Critical path:**
  The instruction text flows through the learned encoder to produce gate values, which then scale grouped LoRA updates. These gated updates are added to the frozen backbone's weights during the forward pass, affecting the model's internal computation paths.

- **Design tradeoffs:**
  - Group granularity vs. interpretability: More groups allow finer control but require clearer feature-to-group mappings and risk fragmentation
  - Gate regularization strength (λ): Too strong → gates collapse to priors; too weak → degenerate/unstable gating behavior
  - LoRA rank (r=8): Higher rank increases expressiveness but may reduce disentanglement across groups

- **Failure signatures:**
  - GMR near 0: Instructions not differentiating gate activations
  - RS identical across core/spurious groups: Gating not functionally impacting predictions
  - Sharp accuracy drop under mild spurious suppression: Model still reliant on spurious features despite training

- **First 3 experiments:**
  1. Ablate instruction encoder: Replace learned h_φ with random projections or fixed gate vectors. Measure GMR and RS drops to confirm encoder necessity.
  2. Vary group assignment: Randomly shuffle feature-to-group mappings and retrain. If controllability degrades, confirm that semantic alignment matters.
  3. Stress-test with stronger spurious correlations: Increase the correlation between spurious proxy labels and ground truth in the training set. Evaluate whether FiLoRA still maintains higher decision stability than baselines.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Reliance on small-scale or reconstructed datasets (Tiny MM-IMDb) prioritizes controllability analysis over task performance, leaving scalability to full-sized benchmarks uncertain
- Fixed, architecture-aligned grouping strategy may be insufficient to isolate features in models with highly entangled representations, especially for fine-grained spurious cues
- Lightweight instruction encoder's robustness against adversarial or ambiguous natural language commands is not evaluated, leaving linguistic variation effects unclear

## Confidence
- Controllability claims (instruction-to-gate mapping): Medium - GMR and RS shifts are reported, but causal mechanism for translating instruction semantics into persistent reliance changes is not fully validated
- Robustness claims (decision stability under spurious suppression): Medium - Stability advantage over baselines is demonstrated, but generality across different spurious correlation structures remains untested
- Scalability claims: Low - Method tested only on small-scale datasets, no evidence provided for performance on full-sized, complex benchmarks

## Next Checks
1. Ablate the instruction encoder by replacing it with random projections; if GMR and RS drop sharply, this supports the causal role of the learned encoder.
2. Shuffle feature-to-group mappings and retrain; if controllability degrades, this indicates that semantic alignment is necessary, not just any grouping.
3. Systematically increase spurious-correlation strength in training data; if FiLoRA's decision stability advantage erodes under extreme spuriousness, this would suggest limits to the method's robustness.