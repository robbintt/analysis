---
ver: rpa2
title: Understanding Task Transfer in Vision-Language Models
arxiv_id: '2511.18787'
source_url: https://arxiv.org/abs/2511.18787
tags:
- tasks
- task
- figure
- transfer
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Perfection Gap Factor (PGF), a novel
  metric to quantify how finetuning on one visual perception task transfers to zero-shot
  performance on other tasks in Vision-Language Models (VLMs). PGF measures both the
  magnitude and breadth of transfer effects by normalizing accuracy gains relative
  to the remaining gap to the ceiling performance, enabling fair comparison across
  tasks with different difficulty levels.
---

# Understanding Task Transfer in Vision-Language Models

## Quick Facts
- **arXiv ID:** 2511.18787
- **Source URL:** https://arxiv.org/abs/2511.18787
- **Reference count:** 40
- **Primary result:** Introduces PGF metric to quantify cross-task transfer in VLMs, revealing structured patterns of task transferability across scales.

## Executive Summary
This paper introduces the Perfection Gap Factor (PGF), a novel metric to quantify how finetuning on one visual perception task transfers to zero-shot performance on other tasks in Vision-Language Models (VLMs). PGF measures both the magnitude and breadth of transfer effects by normalizing accuracy gains relative to the remaining gap to the ceiling performance, enabling fair comparison across tasks with different difficulty levels. Through systematic experiments across three VLM scales (3B, 7B, 32B) and 13 perception tasks, the authors reveal structured patterns of task transferability including task cliques, personas (donor/pirate/sponge/sieve tasks), and scale-dependent effects. Key findings show that low-level and image-level tasks are highly transferable, positive transferability increases with model size, and PGF can guide data selection to improve finetuning efficiency while mitigating negative transfer. The framework generalizes to video-based tasks, demonstrating consistent transfer patterns in the temporal domain.

## Method Summary
The study finetunes Qwen-2.5-VL models (3B, 7B, 32B) on 13 perception tasks from the BLINK benchmark using LoRA (rank=8, α=16) with controlled hyperparameters. For each source task, models are finetuned then evaluated zero-shot on all 13 tasks to compute PGF values: PGF = [Acc(finetuned, target) - Acc(baseline, target)] / [ceiling - Acc(baseline, target) + ε]. The resulting PGF matrices are aggregated across 4 random seeds to identify task cliques, transfer personas, and scale-dependent patterns. Video tasks are evaluated separately to test temporal domain generalization.

## Key Results
- Low-level and image-level tasks show highest positive transferability across all model sizes
- Positive transferability increases monotonically with model scale (3B→7B→32B)
- PGF-guided data selection can reduce negative transfer and improve finetuning efficiency
- Transfer patterns generalize to video tasks with consistent task-level relationships
- Scale-dependent cliques emerge: size 3-4 in small models, size 9 in 32B models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Normalizing transfer gains by remaining performance gap enables fair cross-task comparison.
- **Mechanism:** The Perfection Gap Factor (PGF) divides accuracy change by the gap between baseline and ceiling performance. This prevents tasks near ceiling (small absolute gains = large relative impact) from being overshadowed by tasks with large absolute gains but vast remaining headroom. The metric is asymmetric: positive PGF bounded at 1, negative PGF unbounded below.
- **Core assumption:** Ceiling performance (Uj) accurately reflects attainable performance; task difficulty is meaningfully captured by baseline-to-ceiling distance.
- **Evidence anchors:**
  - [abstract] "PGF measures both the magnitude and breadth of transfer effects by normalizing accuracy gains relative to the remaining gap to the ceiling performance."
  - [Section 3, Equation 3] Formal PGF definition with ceiling normalization.
  - [corpus] Weak direct corpus support; neighbor papers focus on VLM capabilities rather than transfer metrics.
- **Break condition:** If ceiling estimates are inaccurate (e.g., human ceiling doesn't reflect model attainability), PGF comparisons become misleading. Tasks with incorrectly specified ceilings will yield spurious transfer signals.

### Mechanism 2
- **Claim:** Low-level visual perception tasks transfer broadly because they scaffold shared early visual representations.
- **Mechanism:** Low-level tasks (Relative Depth, Relative Reflectance, Visual Correspondence) operate on pixel-level features that serve as building blocks for higher-level perception. Finetuning on these tasks improves representations that other tasks implicitly depend on, creating positive transfer. Image-level tasks also transfer well due to broad feature coverage.
- **Core assumption:** VLMs process visual information hierarchically, with low-level features feeding into higher-level reasoning.
- **Evidence anchors:**
  - [Section 4.1] "Finetuning on low-level tasks has the highest average magnitude of positive task transferability across categories, for all model sizes."
  - [Figure 3, 4] Show low-level tasks have highest malleability and transferability.
  - [corpus] SocialFusion paper notes VLMs "struggle to unify and learn multiple social perception tasks simultaneously" — suggesting transfer difficulty varies by task domain.
- **Break condition:** If VLM architectures fundamentally differ from assumed hierarchical processing (e.g., late fusion with minimal shared visual features), low-level task transfer advantages would diminish.

### Mechanism 3
- **Claim:** Larger model capacity enables better feature separation, reducing negative interference and amplifying positive transfer.
- **Mechanism:** As model size increases (3B → 7B → 32B), representational capacity allows the model to maintain task-specific features without overwriting shared features. This produces "scale-dependent sharpening" where positive cliques grow (size 3-4 in small models to size 9 in 32B) and average positive transferability increases.
- **Core assumption:** Larger models have more orthogonal representations across tasks; finetuning perturbations don't catastrophically interfere.
- **Evidence anchors:**
  - [Section 4.2] "As model size increases, the average positive transferability also increases."
  - [Figure 5] Shows monotonic increase in positive transferability across 3B, 7B, 32B.
  - [Section A.14] Larger models show higher LoRA weight cosine similarity across tasks, suggesting better cross-task alignment.
  - [corpus] Mechanistic Finetuning paper notes VLAs "require finetuning to contend with varying physical factors" — size alone may not guarantee transfer without domain alignment.
- **Break condition:** Architecture differences may override scale effects; the 7B model showed anomalous negative transfer patterns, suggesting capacity alone is insufficient without proper architectural support.

## Foundational Learning

- **Concept: Transfer Learning vs. Zero-Shot Cross-Task Transfer**
  - **Why needed here:** The paper distinguishes traditional transfer learning (finetuning on both source and target) from their zero-shot cross-task transfer setting (finetuning source only, evaluate target zero-shot). Understanding this distinction is essential for interpreting PGF results.
  - **Quick check question:** If you finetune on task A then evaluate on task B without any B-specific training, what type of transfer are you measuring?

- **Concept: Performance Ceiling Normalization**
  - **Why needed here:** PGF's core innovation is normalizing by remaining gap to ceiling. Without this conceptual grounding, the metric appears arbitrary.
  - **Quick check question:** Why would a +5% accuracy gain on a 95% ceiling task be rated differently than +5% on a 60% ceiling task?

- **Concept: Task Taxonomy (Perceptual Level and Granularity)**
  - **Why needed here:** The paper organizes tasks by perceptual level (low/mid/high) and granularity (pixel/crop/image). Transfer patterns cluster by these categories.
  - **Quick check question:** Which category would "depth estimation between two points" fall into — what perceptual level and granularity?

## Architecture Onboarding

- **Component map:**
  - Baseline accuracy → Finetune on source task → Evaluate on all target tasks → Compute PGF = Δaccuracy / gap_to_ceiling for each (source, target) pair
  - PGF matrix → Threshold top 20% edges → Visualize as directed graph
  - Aggregate PGF scores → Compare to model average → Classify as Donor (high positive transfer), Pirate (high negative transfer), Sponge (high positive malleability), Sieve (high negative malleability)
  - Find maximal subsets where all pairwise transfers share the same sign (positive/negative cliques)

- **Critical path:**
  1. Establish reliable baseline and ceiling estimates per task (unstable ceilings → unreliable PGF)
  2. Finetune with controlled settings (LoRA rank=8, α=16, consistent steps across tasks)
  3. Aggregate across random seeds (paper uses 4 seeds) for statistical significance

- **Design tradeoffs:**
  - **Ceiling specification:** Human performance vs. best observed model performance. Human ceiling is task-agnostic but may be unattainable; best observed is attainable but may underestimate potential.
  - **LoRA vs. full finetuning:** Paper uses LoRA for efficiency, but this may limit transfer magnitude compared to full parameter updates.
  - **Multiple choice format:** Tasks formatted as MCQs may suppress transfer patterns visible in open-ended generation.

- **Failure signatures:**
  - High variance across seeds → unstable task relationships (check Figure A.11-A.13 std values)
  - 7B model showing anomalous negative transfer → potential architectural mismatch
  - Ceiling near baseline → PGF becomes unstable (division by near-zero gap)

- **First 3 experiments:**
  1. **Reproduce PGF matrix for one model size:** Finetune Qwen-2.5-VL-7B on 3 diverse tasks (one low-level, one mid-level, one high-level), evaluate on all 13 tasks. Compare PGF patterns to paper's Figure A.12.
  2. **Validate ceiling sensitivity:** For one target task, compute PGF using both human ceiling and best-observed-model ceiling. Quantify how rankings of source tasks change.
  3. **Test generalization to new model:** Compute PGF matrix for a different VLM family (e.g., LLaVA) on a subset of tasks. Check if low-level tasks remain strong donors.

## Open Questions the Paper Calls Out

- **Question:** How do task transfer patterns change when VLMs are evaluated on open-ended generation tasks rather than multiple-choice questions?
  - **Basis in paper:** [explicit] Section 6 states the analysis is limited to MCQs and notes that "exploring open-ended generation for visual tasks would be a promising future direction."
  - **Why unresolved:** The restricted output space of multiple-choice benchmarks may suppress failure modes or transfer patterns that would emerge in free-form generative settings.
  - **What evidence would resolve it:** Replicating the PGF framework using benchmarks that require free-form textual descriptions or dense captions (e.g., image captioning) rather than selection.

- **Question:** Do the identified task personas (donors, pirates) and cliques persist across diverse VLM architectures and training paradigms?
  - **Basis in paper:** [explicit] Section 6 explicitly lists "extending the studies to newer models" to understand generalizability and the "evolution of architectures" as a limitation.
  - **Why unresolved:** The study primarily relies on the Qwen-2.5-VL family; structural differences in other architectures could lead to different transfer behaviors.
  - **What evidence would resolve it:** Running the transfer analysis on fundamentally different VLM architectures (e.g., InternVL or proprietary models) to compare the resulting transfer graphs and persona assignments.

- **Question:** Can PGF-guided data mixtures consistently outperform direct supervision across a wide variety of target tasks?
  - **Basis in paper:** [explicit] Section 5.4 describes the data selection experiment as a "preliminary finding" and notes a "comprehensive study of PGF-guided dataset mixtures is out of scope."
  - **Why unresolved:** While Figure 8 shows promise, the authors note the experiment is limited to a few specific examples, leaving the robustness of the strategy unproven.
  - **What evidence would resolve it:** Large-scale experiments optimizing various target tasks using only PGF-selected proxy datasets compared against standard direct finetuning baselines.

## Limitations

- **Ceiling estimation uncertainty:** PGF depends critically on accurate ceiling values per task, but these are not provided and must be assumed (typically 100% based on human performance).
- **Architecture-specific findings:** Results are based on Qwen-2.5-VL family; transfer patterns may differ for other VLM architectures.
- **MCQ format constraint:** The exclusive use of multiple-choice questions may suppress transfer patterns visible in open-ended generation settings.

## Confidence

**High Confidence:** The PGF metric definition and mathematical formulation are clearly specified and internally consistent. The observed scale-dependent increase in positive transferability (3B→7B→32B) is robust across multiple tasks and seed runs.

**Medium Confidence:** The task taxonomy-based transfer patterns (low-level tasks as strong donors, image-level tasks as highly transferable) are well-supported but may be partially explained by dataset size effects rather than purely architectural reasons. The persona classifications (donor/pirate/sponge/sieve) aggregate PGF values in a reasonable but somewhat arbitrary manner.

**Low Confidence:** The video task generalization claims are based on only two video tasks, providing insufficient evidence for broader temporal domain applicability. The ceiling sensitivity analysis is mentioned but not systematically explored.

## Next Checks

1. **Ceiling Sensitivity Analysis:** Systematically compute PGF matrices using three different ceiling specifications (human performance, best-observed model performance, and 100%) for 3-4 representative tasks. Quantify how source task rankings change across specifications and identify tasks where ceiling choice most impacts transfer conclusions.

2. **Architecture-Agnostic Transfer Patterns:** Replicate the PGF analysis on a different VLM family (e.g., LLaVA or InternVL) using the same 6-8 tasks where source data is readily available. Compare whether low-level tasks maintain their donor status and whether clique structures persist across architectures.

3. **Finetuning Method Impact:** For one model size (7B recommended), compare PGF matrices from LoRA finetuning versus full finetuning on 3-4 diverse source tasks. Measure changes in both absolute transferability values and relative rankings of source tasks to assess whether LoRA systematically underestimates transfer effects.