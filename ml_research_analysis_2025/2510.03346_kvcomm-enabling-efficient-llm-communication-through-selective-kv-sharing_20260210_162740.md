---
ver: rpa2
title: 'KVComm: Enabling Efficient LLM Communication through Selective KV Sharing'
arxiv_id: '2510.03346'
source_url: https://arxiv.org/abs/2510.03346
tags:
- kvcomm
- layers
- communication
- pairs
- hidden
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses efficient inter-model communication in multi-agent
  LLM systems. Current approaches using natural language or hidden states are either
  too costly or suffer from information loss.
---

# KVComm: Enabling Efficient LLM Communication through Selective KV Sharing

## Quick Facts
- arXiv ID: 2510.03346
- Source URL: https://arxiv.org/abs/2510.03346
- Reference count: 40
- Primary result: Selective KV sharing achieves Skyline-level performance while reducing computation costs by 2.5x-6x

## Executive Summary
KVComm addresses the challenge of efficient communication between large language models in multi-agent systems by selectively sharing KV pairs instead of entire context or hidden states. The framework identifies informative layers through attention importance scores combined with a Gaussian prior, enabling models to transmit as few as 30% of layers' KV pairs while maintaining performance comparable to the upper-bound method of direct input merging. Extensive experiments across 8 datasets demonstrate that KVComm achieves 2.5x-6x computation reduction with up to 3x communication overhead reduction compared to baseline approaches.

## Method Summary
The KVComm framework operates by having the sender model prefill on context to generate KV pairs, then computing attention importance scores for each layer based on average attention weights to context tokens. A Gaussian prior biases selection toward intermediate layers, and the top-M layers by combined score are transmitted to the receiver. During receiver inference, transmitted KV pairs are concatenated with the receiver's own KV at matching layers, allowing the receiver to attend to the sender's contextual representations without overwriting its internal state. The framework uses calibration on a single sample to identify informative layers and works with same-model or same-base-model pairs.

## Key Results
- KVComm achieves comparable performance to Skyline (direct input merging) while reducing computation costs by 2.5x-6x
- Selecting as few as 30% of layers' KV pairs yields near-optimal performance across diverse datasets
- Non-contiguous layer selection outperforms contiguous chunks, enabling more efficient information transmission
- The framework reduces communication overhead by up to 3x compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
KV pairs preserve attention-routing information without corrupting the receiver model's internal state. When Ms shares KV pairs with Mr, Mr can attend to Ms's contextual representations via standard attention mechanisms. Unlike hidden state injection which overwrites or dilutes Mr's last-token state, KV concatenation lets Mr dynamically weight the imported information while avoiding "information concentration bias" where the last token's hidden state becomes critical in later layers.

### Mechanism 2
Attention importance scores identify which layers encode task-relevant contextual relations. For each layer l, attention importance is computed as the average attention weight assigned to context tokens across all heads. Layers where heads consistently attend to context tokens encode salient relational information. This is combined with a Gaussian prior that biases selection toward intermediate layers (semantic abstraction zone), under the assumption that intermediate layers capture transferable semantics.

### Mechanism 3
Non-contiguous layer selection outperforms contiguous chunks because informative layers are distributed across depth, not concentrated in a single block. Rather than transmitting layers [i, j] as a block, KVComm selects top-M layers by score regardless of adjacency. The Gaussian prior balances semantic centrality with attention evidence, allowing the framework to capture high-value information from layers that may appear at varying depths.

## Foundational Learning

- **KV Cache in Transformer Decoders**: KV pairs are the communication medium; understanding their role in attention is prerequisite. Quick check: During prefill, what information does a KV pair encode for a given token position?

- **Information Concentration Bias**: Explains why hidden-state communication fails—the last token becomes dominant, and corrupting it degrades output. Quick check: In a decoder-only model, why does the last token's hidden state disproportionately influence the next-token prediction?

- **Layer-wise Representation Hierarchy**: Hypothesis that early→surface, middle→semantic, late→task-specific representations. Quick check: What types of features would you expect in layer 5 vs. layer 28 of a 32-layer LLaMA model?

## Architecture Onboarding

- **Component map**: Ms (prefills on C) -> Calibration Module (computes attention scores) -> Transmission (sends selected KVs) -> Mr (concatenates and attends)

- **Critical path**: 
  1. Run calibration on single C/Q pair → compute attention scores → apply Gaussian prior → select M layers
  2. Ms prefills on C → extract selected KVs → transmit to Mr
  3. Mr initializes with Q → at each selected layer l∈S, prepend transmitted KVs before attention computation

- **Design tradeoffs**:
  - M (selection ratio): Lower M → less bandwidth, but risk of missing critical info
  - α (attention vs. Gaussian weight): High α trusts attention scores; low α enforces intermediate-layer bias
  - Calibration size: Paper claims 1 sample suffices, but unrepresentative calibration may generalize poorly

- **Failure signatures**:
  - Performance drops vs. Baseline: Check if models are incompatible (different base models)
  - Skyline significantly outperforms KVComm at 70%: Likely calibration mismatch; inspect attention score distribution
  - Random selection matches KVComm: Selection strategy may be misconfigured (α, μ, σ wrong for model family)

- **First 3 experiments**:
  1. Same-model pair (Llama-3.1-8B to itself) on HotpotQA with M=70% → should approach Skyline F1
  2. Ablation on α: Vary α ∈ {0.0, 0.5, 1.0} to isolate attention-only vs. Gaussian-only selection
  3. Contiguous vs. non-contiguous: Compare KVComm (M=10) against best contiguous 10-layer chunk

## Open Questions the Paper Calls Out

### Open Question 1
Can KVComm be extended to enable efficient communication between LLMs with fundamentally different architectures (e.g., a LLaMA model communicating with a Mistral or GPT-style model)? The paper limits experiments to same-model or same-base-model pairs, but practical deployment scenarios often involve heterogeneous agent populations.

### Open Question 2
How does KVComm scale to multi-agent systems with more than two agents, and what communication topologies maximize efficiency? While the introduction emphasizes multi-agent systems, all experiments involve only two-agent communication, leaving open questions about broadcasting, hierarchical aggregation, or selective peer-to-peer sharing strategies.

### Open Question 3
Why does KVComm show minimal improvement on mathematical reasoning tasks (TMATH), and can the selection strategy be adapted to task-specific information patterns? The paper attributes this to pretraining giving LLMs solid mathematical reasoning capabilities, but it remains unclear whether the issue is the selection strategy favoring semantic over procedural knowledge.

## Limitations
- The framework is restricted to same-model or same-base-model pairs, limiting practical deployment scenarios
- The selection of M=30% as a threshold lacks systematic sensitivity analysis across task complexities
- The assumption that attention weight magnitude correlates with semantic relevance may not hold for all task types

## Confidence

**High Confidence Claims**:
- KV pairs enable more effective communication than hidden states by preserving attention-routing information
- Non-contiguous layer selection outperforms contiguous chunks in information transmission efficiency
- The framework achieves 2.5x-6x computation reduction while maintaining Skyline-level performance

**Medium Confidence Claims**:
- Attention importance scores reliably identify task-relevant layers across diverse datasets
- The Gaussian prior effectively biases selection toward semantically rich intermediate layers
- Calibration on 1 sample suffices for accurate layer identification

**Low Confidence Claims**:
- Attention weight magnitude directly correlates with information value for downstream tasks
- The intermediate-layer semantic abstraction hypothesis universally applies
- The selection mechanism generalizes to heterogeneous model pairs and out-of-domain tasks

## Next Checks
1. **Calibration Sensitivity Analysis**: Systematically vary the number of calibration samples (1, 5, 10, 50) across 3 diverse datasets and measure the impact on layer selection accuracy and downstream task performance.

2. **Attention-Importance Ablation**: Compare KVComm against random layer selection and attention-score-only selection (α=1) across 5 tasks with varying reasoning complexity to directly test whether attention importance scores provide meaningful signal.

3. **Heterogeneous Model Compatibility**: Test KVComm between model pairs sharing the same base architecture but different fine-tuning objectives to identify minimum compatibility requirements and quantify performance degradation with architectural drift.