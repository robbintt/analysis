---
ver: rpa2
title: Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial
  Transferability
arxiv_id: '2505.01168'
source_url: https://arxiv.org/abs/2505.01168
tags:
- adversarial
- gradient
- heat
- ensemble
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving the transferability
  of adversarial examples in ensemble attacks. The proposed method, HEAT, integrates
  domain generalization principles into adversarial attack design.
---

# Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability

## Quick Facts
- **arXiv ID**: 2505.01168
- **Source URL**: https://arxiv.org/abs/2505.01168
- **Reference count**: 11
- **Primary result**: HEAT improves black-box adversarial transferability by integrating domain generalization principles, achieving average attack success rate improvement exceeding 28% over baseline ensemble methods.

## Executive Summary
This paper addresses the challenge of improving the transferability of adversarial examples in ensemble attacks. The proposed method, HEAT, integrates domain generalization principles into adversarial attack design. HEAT consists of two key modules: C-GRADS, which synthesizes shared gradient directions across models using SVD, and D-HARMO, which dynamically balances intra-domain coherence and inter-domain divergence to optimize gradient contributions. Experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that HEAT significantly outperforms existing methods, achieving an average attack success rate improvement exceeding 28% compared to baseline ensemble methods. The approach offers a novel perspective on enhancing adversarial transferability through domain generalization principles.

## Method Summary
HEAT combines two complementary modules to enhance adversarial transferability. C-GRADS uses Singular Value Decomposition (SVD) to extract principal gradient directions shared across multiple surrogate models, creating a consensus adversarial perturbation. D-HARMO then dynamically weights each model's contribution based on intra-domain coherence (how effective a model's perturbation is against other ensemble members) and inter-domain divergence (gradient alignment and loss sensitivity across models). The final adversarial gradient is a weighted combination of individual model gradients, optimized for both breadth (effectiveness across models) and depth (sensitivity to the consensus direction).

## Key Results
- HEAT achieves attack success rate improvements exceeding 28% compared to baseline ensemble methods
- The method shows consistent improvements across CIFAR-10, CIFAR-100, and ImageNet datasets
- HEAT demonstrates superior performance particularly when attacking models from different architecture families
- The dual weighting mechanism (intra-domain coherence and inter-domain divergence) provides significant gains over single-modality approaches

## Why This Works (Mechanism)

### Mechanism 1: SVD-based Gradient Direction Synthesis
Extracting principal directions shared across surrogate models via SVD yields perturbations that transfer better to unseen target models. The method stacks M model gradients into matrix G, decomposes via SVD (G = UΣV^T), retains top-k singular vectors capturing cumulative variance ≥ p, then synthesizes shared direction Vk = Σσi·vi. Perturbations along these consensus directions exploit vulnerabilities common across architectures. This works because models trained on similar data share sensitive input directions that generalize to unseen models.

### Mechanism 2: Intra-domain Coherence Weighting (Breadth)
Models whose gradients produce perturbations effective against multiple ensemble members deserve higher weight—they identify "broad" vulnerabilities rather than model-specific overfitting. For each model m, the method generates adversarial example x_adv^m using its gradient, then measures how well this fools OTHER models j ≠ m. Weight wintra_m ∝ Σ log(L(fj(x_adv^m))/L_self^j). Models with synergistic gradients receive higher weights, identifying generalizable vulnerabilities.

### Mechanism 3: Inter-domain Divergence Weighting (Depth)
Models with high loss sensitivity AND high gradient alignment with peers provide reliable, informative signals—quantified via low information entropy. The method computes two factors per model: (1) Loss contribution Sm = Lm(xVk_adv), (2) Alignment contribution Am from average cosine similarity with other models. After normalization with temperature τ, it computes entropy Hm = -(Šm log Šm + Ãm log Ãm), then weight winter_m = 1/Hm. Low entropy indicates high confidence, resulting in higher weight.

## Foundational Learning

- **Concept: Singular Value Decomposition (SVD) for dimensionality reduction**
  - **Why needed here**: Core to C-GRADS; extracts dominant directions from gradient matrices. You must understand how singular values rank direction importance.
  - **Quick check question**: Given gradient matrix G from 4 models, what does the first right singular vector v1 represent in terms of model sensitivities?

- **Concept: Domain Generalization theory**
  - **Why needed here**: The paper frames ensemble attacks as a domain generalization problem—each model is a "domain," and transferability = generalization to unseen domains.
  - **Quick check question**: In standard domain generalization, what makes features transfer across domains? How does this analogy map to gradient directions across models?

- **Concept: Adversarial transferability fundamentals**
  - **Why needed here**: Without understanding why perturbations transfer (shared decision boundaries, model smoothness, data manifold structure), you can't evaluate whether HEAT's design is sound.
  - **Quick check question**: Why does averaging gradients from multiple models (baseline Ens) improve transferability, and what are its limitations that HEAT addresses?

## Architecture Onboarding

- **Component map**:
  Input Image x
       │
       ├──► [C-GRADS]
       │    ├─ Compute gradients {∇L_m} for M models
       │    ├─ Stack into matrix G
       │    ├─ SVD: G = UΣV^T
       │    ├─ Select top-k by cumulative ratio p
       │    └─ Synthesize Vk = Σσ_i·v_i → xVk_adv
       │
       ├──► [D-HARMO / Intra-domain]
       │    ├─ For each m: generate x_adv^m
       │    ├─ Compute cross-model fooling effectiveness
       │    └─ Normalize → wintra weights
       │
       ├──► [D-HARMO / Inter-domain]
       │    ├─ Loss contribution Sm on xVk_adv
       │    ├─ Alignment Am via cosine similarity
       │    ├─ Entropy Hm → winter weights
       │
       └──► Combine: g = Σ (wintra_m · winter_m · ∇L_m)
            → Update: x*adv = Clip(x + α·sign(g))

- **Critical path**: C-GRADS must complete first (produces xVk_adv), which is required for inter-domain weighting. Intra-domain weights can be computed in parallel with C-GRADS.

- **Design tradeoffs**:
  - **Cumulative ratio p** (default 0.7): Higher retains more directions but includes noise; lower is cleaner but may miss transfer-critical components
  - **Temperature τ**: Controls weight distribution sharpness; requires tuning per dataset
  - **Ensemble composition**: Homogeneous (all CNNs or all ViTs) vs heterogeneous—Table 4 shows ViT ensembles transfer better to ViT targets
  - **Computation cost**: SVD on D-dimensional gradients (D = image size) can be expensive; consider gradient subsampling for large inputs

- **Failure signatures**:
  - Intra-domain weights all ≈ 1/M (uniform): Models too similar, no differentiation signal
  - Inter-domain weights collapse to single model: Temperature too low or one model dominates alignment
  - Poor transfer to ViTs from CNN-only ensemble: Architecture gap too large (see Table 4, rows 1-2)
  - ASR barely exceeds baseline Ens: Check p value (may be too low) or gradient computation issues

- **First 3 experiments**:
  1. **Ablation replication (Table 3)**: Run Ens baseline, then add components incrementally (C-GRADS alone, +Intra-domain, +Loss factor, +Alignment factor) on CIFAR-10 to verify ~31% → 40% ASR improvement trajectory
  2. **Hyperparameter sweep on p**: Test p ∈ {0.5, 0.6, 0.7, 0.8, 0.9} with fixed τ to find optimal variance retention for your target model architectures
  3. **Heterogeneous ensemble test**: Compare CNN-only (Res-18, Inc-v3), ViT-only (ViT-T, DeiT-T), and mixed ensembles on both CNN and ViT black-box targets to characterize transfer patterns

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does HEAT perform against adversarially trained models or advanced defense mechanisms?
- **Basis in paper:** [inferred] The experiments (Tables 1, 2) evaluate transferability to standard architectures (e.g., ResNet, ViT) but do not test against adversarial training or input transformation defenses.
- **Why unresolved:** Transferability to different architectures does not guarantee transferability to robust models, where gradient directions may differ significantly from standard training.
- **What evidence would resolve it:** Attack success rates against adversarially trained models (e.g., Inc-v3_ens) and defense mechanisms.

### Open Question 2
- **Question:** Does the computational cost of SVD in C-GRADS limit scalability to high-resolution inputs?
- **Basis in paper:** [inferred] C-GRADS performs Singular Value Decomposition on the gradient matrix $G \in \mathbb{R}^{M \times D}$ (Eq. 5), where $D$ is the input dimension.
- **Why unresolved:** SVD scales poorly with input size compared to gradient averaging, potentially making it impractical for high-definition inputs.
- **What evidence would resolve it:** Runtime benchmarks on high-resolution datasets (e.g., $512 \times 512$) compared to baseline methods.

### Open Question 3
- **Question:** Is the cumulative contribution ratio $p$ sensitive to the heterogeneity of the surrogate ensemble?
- **Basis in paper:** [inferred] The method fixes $p=0.7$ to select shared singular vectors (Eq. 6), ignoring potential variance differences between homogeneous (all CNNs) and heterogeneous (CNNs+ViTs) ensembles.
- **Why unresolved:** The optimal number of principal components likely depends on the gradient variance, which varies by model type.
- **What evidence would resolve it:** Ablation studies varying $p$ (e.g., 0.1–0.9) across diverse ensemble combinations.

## Limitations
- **Unknown hyperparameters**: The small constant ε and temperature τ parameters are not specified, requiring assumptions that may affect results
- **Computational complexity**: SVD on full gradient matrices can be expensive for large-scale images like ImageNet, potentially limiting practical deployment
- **Architecture dependency**: Results show strong transfer within model families but weaker cross-architecture transfer, suggesting fundamental limitations when attacking highly dissimilar models

## Confidence
- **High confidence**: The core SVD-based gradient synthesis mechanism (C-GRADS) is well-specified and theoretically grounded in domain generalization principles
- **Medium confidence**: The weighting scheme (D-HARMO) is mathematically sound but depends critically on un-specified hyperparameters that could significantly impact performance
- **Low confidence**: The claim of 28%+ improvement over baselines across all datasets is based on single values without variance reporting or significance testing

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary p ∈ {0.5, 0.6, 0.7, 0.8, 0.9} and τ ∈ {0.1, 1.0, 10.0} to quantify performance stability and identify optimal settings
2. **Cross-architecture transfer validation**: Test HEAT's performance when attacking architectures with minimal shared components (e.g., CNN ensembles attacking ViT targets) to establish boundary conditions
3. **Gradient space orthogonality test**: Measure cosine similarity between model gradients in the ensemble; if gradients are nearly orthogonal, verify that SVD still extracts meaningful shared directions rather than noise