---
ver: rpa2
title: Knowledge-based anomaly detection for identifying network-induced shape artifacts
arxiv_id: '2511.04729'
source_url: https://arxiv.org/abs/2511.04729
tags:
- synthetic
- images
- shape
- artifacts
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a knowledge-based anomaly detection method
  for identifying network-induced shape artifacts in synthetic medical images. The
  method constructs a specialized feature space by analyzing the per-image distribution
  of angle gradients along anatomical boundaries, capturing local shape variations
  while maintaining global anatomical correspondence.
---

# Knowledge-based anomaly detection for identifying network-induced shape artifacts

## Quick Facts
- arXiv ID: 2511.04729
- Source URL: https://arxiv.org/abs/2511.04729
- Reference count: 19
- One-line primary result: Novel knowledge-based anomaly detection method achieves AUC of 0.97 (CSAW-syn) and 0.91 (VMLO-syn) for identifying network-induced shape artifacts in synthetic medical images

## Executive Summary
This paper introduces a knowledge-based anomaly detection method for identifying network-induced shape artifacts in synthetic medical images. The approach constructs a specialized feature space by analyzing the per-image distribution of angle gradients along anatomical boundaries, capturing local shape variations while maintaining global anatomical correspondence. An isolation forest trained on patient data is then used to assign anomaly scores to synthetic images. The method is demonstrated on two synthetic mammography datasets, successfully concentrating artifacts in the most anomalous partition with high AUC values. A reader study involving three imaging scientists confirmed that images identified by the method as containing shape artifacts were also flagged by human readers with mean agreement rates of 66% and 68% for the most anomalous partition.

## Method Summary
The method extracts breast boundaries from images using Gaussian filtering, thresholding, and morphological operations, then removes imaging window edges and skeletonizes the mask. It tracks the boundary from the top-left point, computes angular trajectories between consecutive points, and calculates angle gradients to capture curvature changes. These gradients are binned into 64 equal bins and summarized via cumulative sums, then further reduced to a 16-dimensional vector using percentile-based binning from patient data distribution. An isolation forest (100 trees, subsample size 256) is trained on patient feature vectors and applied to synthetic images to assign anomaly scores. Images are partitioned by percentiles (P1≤1%, P2=1–10%, P3=10–100%), with lower partitions indicating higher artifact likelihood.

## Key Results
- AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn) demonstrate strong performance in detecting shape artifacts
- Mean reader agreement rates of 66% and 68% for the most anomalous partition, approximately 1.5-2 times higher than the least anomalous partition
- The method successfully detects network-induced shape artifacts without requiring prior knowledge of the anatomy or provided labels
- Shape artifacts are concentrated in the most anomalous partition (P1), validating the effectiveness of the knowledge-based feature engineering approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Binning angle gradients along anatomical boundaries into cumulative sum vectors creates size-invariant shape representations that expose local shape violations.
- Mechanism: Boundary points are ordered by tracking along anatomical curvature → angular trajectory computed between consecutive points → angular gradients capture curvature changes → gradients binned into N=64 equal bins and summarized via cumulative sum → further reduced to 16-d vector via percentile-based binning from patient data distribution.
- Core assumption: Shape artifacts manifest as anomalous angular gradient patterns (e.g., unnatural sharp angles, multiple discontinuities) that deviate from natural anatomical curvature.
- Evidence anchors:
  - [abstract] "analyzing the per-image distribution of angle gradients along anatomical boundaries, capturing local shape variations while maintaining global anatomical correspondence"
  - [Section 2.2.1] "This representation aggregates local shape variations while maintaining global correspondence between bins and anatomical regions, regardless of size differences"
  - [corpus] Weak—no corpus papers specifically address angle-gradient feature spaces for synthetic image artifact detection.
- Break condition: If artifacts occur primarily in tissue texture rather than boundary shape, or if segmentation fails to produce continuous boundaries, this mechanism degrades.

### Mechanism 2
- Claim: An isolation forest trained exclusively on patient data assigns anomaly scores to synthetic images, where fewer partitions to isolate an observation indicates higher artifact likelihood.
- Mechanism: Subsample patient feature vectors → recursively partition over random feature subsets until isolation → repeat to build forest of 100 trees → anomaly score computed from average path length across trees → apply trained forest to synthetic images.
- Core assumption: Synthetic images with network-induced shape artifacts produce feature vectors that are more "isolatable" (shorter average path lengths) than real patient anatomical shapes.
- Evidence anchors:
  - [abstract] "An isolation forest trained on patient data is then used to assign anomaly scores to synthetic images"
  - [Section 2.2.2] "The isolation forest yields an anomaly score for each observation based on the average number of partitions required to isolate it across the forest... Negative scores indicate outliers, while positive and near-zero scores correspond to inliers"
  - [corpus] Isolation forests are established for anomaly detection (Liu et al., 2008, cited 197 times), but application to synthetic medical image quality assessment is novel.
- Break condition: If patient training data contains natural anatomical outliers (surgical scars, missing nipples—observed in Figure 10), these may receive spurious anomaly scores; if synthetic artifacts approximate patient distribution too closely, sensitivity drops.

### Mechanism 3
- Claim: Knowledge-based feature engineering produces interpretable, model-agnostic artifact detection independent of generative architecture.
- Mechanism: Domain knowledge (breast curvature, single nipple expectation, smooth boundary transitions) encoded into feature bins → each bin corresponds to specific anatomical region → deviations interpretable as specific constraint violations → method applies to any synthetic image regardless of source model.
- Core assumption: Anatomical constraints are consistent within a modality and population, and violations can be systematically detected through engineered features.
- Evidence anchors:
  - [abstract] "This method can be used to detect anatomically unrealistic images irrespective of the generative model used and provides interpretability through its knowledge-based design"
  - [Section 1] "(iv) is interpretable due to its knowledge-based design"
  - [Section 3.3] "artifacts typically observed in P1 were not observed in patient data, and thus, originated from the generative process itself... the method can detect these network-induced artifacts without requiring prior knowledge of the anatomy nor any provided labels"
  - [corpus] Weak—corpus papers focus on general-purpose anomaly detection, not domain-informed feature engineering.
- Break condition: If anatomical constraints vary significantly across populations (paper notes different baseline shapes between Swedish/Vietnamese datasets—Figure 5) without adjustment, or if novel artifact types violate constraints not encoded in features.

## Foundational Learning

- Concept: **Isolation Forest algorithm**
  - Why needed here: Core detection engine; understanding how path length relates to anomaly scoring is essential for interpreting results and debugging.
  - Quick check question: If you increase subsample size from 256 to 1024, would you expect anomaly scores to become more or less stable, and why?

- Concept: **Boundary-based shape representation**
  - Why needed here: The feature space is constructed from ordered boundary points; understanding how angular gradients capture curvature is critical for adapting to new anatomies.
  - Quick check question: Why does binning cumulative sums of angle gradients provide size-invariance while preserving local shape information?

- Concept: **Unsupervised vs. supervised anomaly detection**
  - Why needed here: Method operates without artifact labels; understanding the tradeoffs helps set appropriate expectations for precision/recall.
  - Quick check question: If 5% of a synthetic dataset truly contains artifacts, and your method achieves 67% accuracy in the most anomalous partition, what is the improvement factor over random sampling? (Paper provides: ~14x)

## Architecture Onboarding

- Component map:
  1. Preprocessing: Gaussian filtering → thresholding → morphological cleaning → mask extraction
  2. Boundary extraction: Mask dilation → skeletonization → remove imaging window edges → ensure connectivity
  3. Feature construction: Boundary tracking → angular trajectory → angle gradients → bin into 64 bins → cumulative sum per bin
  4. Feature summarization: Map 64-d to 16-d using patient percentile-based bin edges
  5. Anomaly detection: Isolation forest (100 trees, subsample 256) trained on patient vectors → score synthetic images

- Critical path: Boundary extraction quality → if segmentation fails or produces discontinuous boundaries, downstream features are unreliable. Validate segmentation on a sample before proceeding.

- Design tradeoffs:
  - Bin count (N=64): Higher N captures more local artifacts; lower N emphasizes global shape. Tune based on expected artifact scale.
  - Percentile-based summarization: Using 1-99th percentiles from patient data provides robustness to outliers but may miss extreme but valid anatomical variations.
  - Forest parameters: Default 100 trees/256 subsample works; larger forests increase stability but have diminishing returns.

- Failure signatures:
  - Synthetic images with tissue artifacts but correct boundary shape → false negatives (method is shape-focused, not texture-focused)
  - Patient outliers (scars, surgical changes) flagged as anomalous → false positives in patient data; verify P1 images in synthetic data show generative artifacts, not patient-like anomalies
  - Discontinuous boundaries from poor segmentation → missing or garbage features; inspect skeletonization output

- First 3 experiments:
  1. Replicate on provided datasets: Run the open-source code (ShapeCheck on GitHub) on CSAW-syn and VMLO-syn; verify you recover similar anomaly score distributions (Figure 7) and AUC values (~0.97, ~0.91).
  2. Test segmentation robustness: Introduce synthetic background noise or intensity variations; evaluate whether adaptive thresholding maintains boundary extraction quality compared to fixed thresholding.
  3. Cross-anatomy validation: Apply the pipeline to a non-mammography dataset (e.g., lung boundaries in chest X-rays); document required modifications to boundary extraction and bin count.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the presence of network-induced shape artifacts in synthetic mammograms impact the diagnostic accuracy of downstream deep learning models?
- Basis in paper: [explicit] The authors note that "unrealistic breast shape may negatively affect downstream task performance" but explicitly state that "the clinical impact of the identified artifacts was not studied."
- Why unresolved: The current study validates the method's ability to detect artifacts via algorithmic ranking and human agreement, but it does not evaluate whether removing these artifacts improves the utility of the synthetic data for training clinical AI tools.
- What evidence would resolve it: A comparative study measuring the performance (e.g., sensitivity, specificity) of a diagnostic model trained on unfiltered synthetic data versus data cleaned using the proposed artifact detection method.

### Open Question 2
- Question: To what extent does the accuracy of the proposed method degrade when applied to synthetic images with severe background noise that impairs initial boundary segmentation?
- Basis in paper: [explicit] The authors identify a limitation regarding the reliance on segmentation: "In low-quality synthetic datasets, network-induced background artifacts may negatively impact segmentation methods. While this was not observed in our work..."
- Why unresolved: The evaluation was performed on datasets with reasonable visual quality (FID 22–43), so the method's robustness to segmentation failures in lower-quality datasets remains untested.
- What evidence would resolve it: Evaluating the anomaly detection performance on synthetic datasets with intentionally degraded image quality or added background artifacts to test the boundary extraction's limits.

### Open Question 3
- Question: Can the method be extended to spatially localize the specific origin of an artifact along the anatomical boundary, rather than just assigning a global anomaly score?
- Basis in paper: [explicit] The paper lists "further exploring the localization of detected artifacts within flagged images" as a future research direction.
- Why unresolved: The current feature space aggregates angle gradients into bins, which allows for global image ranking but obfuscates the precise location of the specific shape distortion causing the anomaly.
- What evidence would resolve it: A modified algorithm that maps high anomaly contributions back to specific pixel coordinates on the boundary, validated against human annotations of artifact locations.

## Limitations
- The method is limited to boundary-based artifacts and will not detect texture or intensity artifacts within tissue regions
- Reliance on quality segmentation means the approach may fail on datasets with poor boundary delineation or atypical anatomies (surgical scars, missing nipples)
- The domain-specific binning strategy and anatomical assumptions may not transfer directly to other body regions beyond mammography

## Confidence
- **High Confidence**: Isolation forest anomaly detection mechanism (established algorithm with clear theoretical foundation)
- **Medium Confidence**: Feature engineering approach for shape representation (novel but well-justified; requires validation on diverse anatomies)
- **Medium Confidence**: Reader study validation (limited sample size—3 readers—though results are consistent)

## Next Checks
1. **Cross-anatomy validation**: Apply the pipeline to lung boundaries in chest X-rays or cardiac contours in cardiac MRI; document required feature space adjustments and quantify performance degradation.

2. **Segmentation robustness test**: Systematically degrade synthetic image quality through varying levels of background noise and intensity inhomogeneity; measure impact on boundary extraction quality and downstream anomaly detection accuracy.

3. **Texture artifact detection capability**: Generate synthetic mammographic images with realistic tissue texture artifacts but anatomically correct boundaries; evaluate whether the current shape-focused approach produces false negatives compared to human readers.