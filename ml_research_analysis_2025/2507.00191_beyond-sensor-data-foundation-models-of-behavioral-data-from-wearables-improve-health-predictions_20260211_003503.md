---
ver: rpa2
title: 'Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve
  Health Predictions'
arxiv_id: '2507.00191'
source_url: https://arxiv.org/abs/2507.00191
tags:
- data
- health
- behavioral
- foundation
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work develops a foundation model of wearable behavioral data
  to improve health predictions. The authors train WBM on over 2.5B hours of data
  from 162K individuals, using a contrastive self-supervised loss and a Mamba-2 backbone
  with TST tokenization.
---

# Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions

## Quick Facts
- arXiv ID: 2507.00191
- Source URL: https://arxiv.org/abs/2507.00191
- Reference count: 40
- WBM foundation model trained on 2.5B hours of behavioral data from 162K individuals, improving health predictions across 57 tasks when combined with PPG sensor data.

## Executive Summary
This work develops WBM, a foundation model for wearable behavioral data that captures long-term patterns from 27 HealthKit metrics to improve health predictions. Trained on over 2.5 billion hours of data from 162,000 individuals using contrastive self-supervised learning with a Mamba-2 backbone, WBM consistently outperforms baselines across 57 health-related tasks including disease classification, medication status, sleep detection, and pregnancy prediction. The model provides complementary information to existing PPG foundation models, with their combination achieving the best performance across nearly all tasks, demonstrating the value of integrating behavioral and sensor data for health monitoring.

## Method Summary
The authors develop WBM by pre-training on 15.14 million weeks of aggregated behavioral data from 162K participants, using a contrastive InfoNCE loss with KoLeo regularization. The input consists of 27 HealthKit behavioral metrics (activity, cardiovascular, vitals, gait, body measurements) aggregated to hourly resolution and arranged into weekly 168×54 matrices with missingness indicators. A TST tokenizer projects each hour to 256 dimensions, which feeds into a bi-directional Mamba-2 encoder with 24 layers. The model is trained for 6 epochs using AdamW optimization with specific hyperparameters including token dropout at 23.3%. Downstream evaluation employs linear probing with ridge penalty across 57 health tasks, measuring performance through MAE, AUROC, and R² metrics.

## Key Results
- WBM outperforms baseline models across all 57 health prediction tasks, with particular strength in behavior-driven predictions
- Combining WBM with PPG foundation model achieves best performance across nearly all tasks, demonstrating complementary value of behavioral and sensor data
- The model shows consistent improvements in both static classifications (diseases, medications) and time-varying states (sleep, pregnancy, infection)

## Why This Works (Mechanism)
The paper does not provide explicit mechanistic analysis of why the approach works. The authors focus on demonstrating empirical performance improvements rather than explaining underlying mechanisms.

## Foundational Learning
- **Contrastive Self-Supervised Learning**: Learning representations by comparing similar and dissimilar samples without labels. Why needed: Enables training on unlabeled wearable data at massive scale. Quick check: Verify positive pairs are correctly sampled from same individuals.
- **Mamba-2 Architecture**: State Space Model designed for efficient sequence modeling. Why needed: Handles long sequences (168 hours) efficiently while capturing temporal dependencies. Quick check: Confirm model can process full weekly windows without truncation.
- **TST Tokenization**: Converts time series to tokens using linear projections per time step. Why needed: Creates fixed-size representations suitable for Mamba-2 while preserving temporal structure. Quick check: Verify tokenization preserves signal patterns across hours.
- **KoLeo Regularization**: Regularization technique that encourages consistency with PPG embeddings. Why needed: Aligns behavioral and sensor representations for complementary learning. Quick check: Monitor regularization loss during training.
- **Linear Probing**: Evaluating representations by training simple linear classifiers on frozen embeddings. Why needed: Provides fair assessment of pre-trained representations without confounding factors. Quick check: Compare linear probe performance against end-to-end fine-tuning.

## Architecture Onboarding

**Component Map**
Raw Behavioral Data → Hourly Aggregation → Weekly Matrix (168×54) → TST Tokenizer → Mamba-2 Encoder → Contrastive Loss (InfoNCE + KoLeo) → Frozen Embeddings → Linear Prober → Downstream Tasks

**Critical Path**
The critical path for performance is: Data Quality (complete weekly windows, sufficient wear time) → TST Tokenization (proper normalization, handling missingness) → Mamba-2 Backbone (bidirectional processing, parameter efficiency) → Contrastive Objective (positive pair sampling, regularization balance)

**Design Tradeoffs**
The authors chose Mamba-2 over Transformers for better efficiency with long sequences, but this limits parallelizability. Token dropout at 23.3% balances regularization with information retention. The bi-directional approach captures full temporal context but requires storing both forward and backward states. Simple global-mean imputation was surprisingly effective over more complex methods.

**Failure Signatures**
Poor performance on sparse variables (VO2max, falls) indicates contrastive loss may underweight infrequent features. If age prediction MAE exceeds 4.5, this suggests tokenization or backbone issues. Inconsistent results across behavior vs. sensor tasks may indicate insufficient KoLeo regularization or poor alignment between modalities.

**First Experiments**
1. Implement TST tokenizer and validate on sample weekly data, checking output dimensions and missingness handling
2. Train Mamba-2 encoder on synthetic time series to verify bidirectional processing and mean-pooling works correctly
3. Test contrastive loss implementation with small batch size, verifying InfoNCE computation and positive/negative pair sampling

## Open Questions the Paper Calls Out
- Can non-contrastive pre-training objectives, specifically Joint Embedding Predictive Architectures (JEPA), outperform the contrastive loss used in WBM for behavioral wearable data? The authors hypothesize JEPA might perform better but leave this exploration to future work after MAE experiments failed.
- Do complex, model-based imputation strategies improve foundation model performance over the simple global-mean imputation used in the TST tokenization? While simple imputation worked best during tuning, the authors suggest more sophisticated methods might handle missingness better.
- Does the WBM architecture generalize to behavioral data collected from non-Apple devices or differing sampling protocols? The model was trained exclusively on Apple Heart and Movement Study data, leaving cross-device transferability untested.

## Limitations
- The training data is proprietary (Apple Heart and Movement Study), preventing independent reproduction and external validation
- Bi-directional Mamba-2 implementation details are partially unspecified, with code not publicly released
- KoLeo regularization requires PPG foundation model weights that are also unavailable, preventing full reproduction of combination experiments

## Confidence
- **High Confidence**: Core technical approach (TST tokenization, bi-directional Mamba-2, contrastive pre-training) is well-specified with reproducible evaluation methodology
- **Medium Confidence**: Specific hyperparameter choices and their impact could benefit from more extensive sensitivity analysis
- **Low Confidence**: Absolute performance numbers cannot be independently verified due to proprietary dataset access restrictions

## Next Checks
1. Implement TST tokenizer and bi-directional Mamba-2 encoder, then validate on a public wearable dataset (e.g., UK Biobank) using available behavioral metrics, comparing age prediction performance against baseline models
2. Train WBM on a smaller but publicly accessible wearable dataset with similar behavioral metrics, evaluating on a subset of health prediction tasks (sleep detection, physical activity classification) to verify approach generalizes beyond proprietary data
3. Systematically vary KoLeo regularization weight λ (0.0, 0.1, 0.21, 0.5) and token dropout rate (10%, 23.3%, 40%) to quantify their impact on downstream task performance, particularly for behavior-driven vs. sensor-driven tasks