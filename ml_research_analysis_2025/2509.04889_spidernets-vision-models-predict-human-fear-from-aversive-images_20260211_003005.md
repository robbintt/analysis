---
ver: rpa2
title: 'SpiderNets: Vision Models Predict Human Fear From Aversive Images'
arxiv_id: '2509.04889'
source_url: https://arxiv.org/abs/2509.04889
tags:
- fear
- images
- vision
- human
- predict
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study demonstrates that pretrained vision models, when adapted\
  \ via transfer learning, can accurately predict group-level perceived fear for spider-related\
  \ images, even when evaluated on new individuals and new images, achieving a mean\
  \ absolute error (MAE) below 10 units on the 0\u2013100 fear scale. The best-performing\
  \ configuration (DINOv2 with full fine-tuning) reached an MAE of 9.78, and ensemble\
  \ predictions reduced error further to 9.13."
---

# SpiderNets: Vision Models Predict Human Fear From Aversive Images

## Quick Facts
- arXiv ID: 2509.04889
- Source URL: https://arxiv.org/abs/2509.04889
- Reference count: 40
- Vision models achieve MAE < 10 on 0-100 fear scale for spider images

## Executive Summary
This study demonstrates that pretrained vision models, when adapted via transfer learning, can accurately predict group-level perceived fear for spider-related images, even when evaluated on new individuals and new images, achieving a mean absolute error (MAE) below 10 units on the 0–100 fear scale. The best-performing configuration (DINOv2 with full fine-tuning) reached an MAE of 9.78, and ensemble predictions reduced error further to 9.13. Visual explanation analyses confirmed that predictions were driven by spider-specific regions in the images, and learning-curve analyses showed that transformer models are data efficient and approach performance saturation with the available dataset (~300 images). Prediction errors were larger for very low and very high fear levels and in specific image categories, suggesting targeted improvements for dataset design. These findings establish transparent, data-driven fear estimation from images, laying the groundwork for adaptive digital mental health tools.

## Method Summary
The study used 313 spider images with 13,532 ratings from 148 participants to train vision models to predict group-level fear ratings. A dual-level cross-validation scheme partitioned both images and participants into training and test sets to ensure generalization. Four pretrained vision architectures (ResNet50, ConvNeXtV2 Tiny, DeiT-S/16, DINOv2 ViT-S/14) were fine-tuned using a two-stage approach: first partial tuning of the regression head, then full fine-tuning of all layers. The regression head consisted of three fully connected layers with batch normalization and dropout. Models were trained with AdamW and MSE loss, and performance was evaluated using MAE, RMSE, and R². Ensemble predictions across multiple models further reduced error.

## Key Results
- Best single model (DINOv2 with full fine-tuning) achieved MAE = 9.78 on held-out images and participants
- Ensemble predictions reduced MAE to 9.13, improving over single models by ~6%
- Grad-CAM analyses confirmed predictions were driven by spider-specific regions, not background elements
- Transformers (DINOv2, DeiT) reached 50% of total performance improvement with only 45-59 images, while CNNs required 91-102 images

## Why This Works (Mechanism)

### Mechanism 1: Feature Transfer from General to Phobia-Specific Domains
Pretrained models map input images to a rich feature space where semantic attributes (e.g., "hairy texture," "multiple legs," "organic shapes") are already linearly separable. Fine-tuning adapts the decision boundary to map these existing features onto a continuous fear axis rather than a categorical class. The visual features eliciting fear (e.g., spider morphology) are subsets of features learned during general object recognition, rather than entirely novel, domain-specific patterns.

### Mechanism 2: Gradient-Based Attribution Grounding (Grad-CAM)
The regression model bases its scalar fear output specifically on the spatial location of the phobic object (the spider), not on confounding background elements. Gradient-weighted Class Activation Mapping (Grad-CAM) computes the gradient of the predicted fear score with respect to the final convolutional feature maps. Regions with high activation contribute positively to the output. The model is forced by the loss function (MSE) to attend to the region that varies systematically with the target label.

### Mechanism 3: Self-Supervised Data Efficiency (DINOv2)
Self-supervised vision transformers (ViTs) require fewer labeled examples to reach saturation on specialized regression tasks compared to supervised CNNs. Self-supervised pretraining (e.g., DINOv2) learns dense, spatially consistent features without labeled supervision, creating a representation space where semantic similarity is preserved. This allows the regression head to map features to fear scores with minimal gradient updates, preserving the general features while shifting the output manifold.

## Foundational Learning

- **Concept: Transfer Learning (Head vs. Full Fine-Tuning)**
  - Why needed here: The paper distinguishes between partial (head-only) and full fine-tuning. Understanding this is critical to replicating the 9.78 MAE performance.
  - Quick check question: If you only train the regression head while freezing the backbone, what is the risk regarding the "data efficiency" vs. "performance ceiling" trade-off? (Answer: You converge faster but may hit a lower accuracy ceiling than full fine-tuning).

- **Concept: Dual-Level Cross-Validation**
  - Why needed here: Standard K-fold CV leaks information if the same participants rate images in both train and test sets. This paper introduces a rigid split to ensure true generalization.
  - Quick check question: Why is splitting only by images insufficient for clinical prediction tasks? (Answer: It fails to test generalization to new *patients* with potentially different fear baselines).

- **Concept: Regression on Bounded Outputs (Clipping)**
  - Why needed here: The model predicts a 0–100 scale but uses standard MSE loss without inherent bounds.
  - Quick check question: Where does the paper apply clipping (during loss computation or post-hoc), and why does this matter for gradient stability? (Answer: Post-hoc only; raw predictions are used for loss to avoid gradient saturation).

## Architecture Onboarding

- **Component map:** Input Image (224×224) -> [ResNet50/ConvNeXtV2/DeiT/DINOv2] -> [Global Average Pooling/CLS Token] -> [Dropout -> FC(256)->ReLU->BN->Dropout -> FC(256)->ReLU->BN->Dropout -> FC(1)] -> Scalar Fear Score
- **Critical path:**
  1. Stage 1 (Partial): Freeze Backbone. Train Head with LR ~1e-3 to 1e-1.
  2. Stage 2 (Full): Unfreeze Backbone. Train All with LR ~1e-6 to 1e-4.
  3. Checkpoints: Save model at every epoch; select the checkpoint with lowest validation MSE (not the last epoch).
- **Design tradeoffs:**
  - ResNet vs. DINOv2: ResNet is faster to train (~14h vs ~21h for full tuning) and easier to visualize (Feature Visualization works well). DINOv2 achieves lower error (9.78 vs 10.05) and saturates faster but is heavier.
  - Ensembling: Reduces MAE by ~6% but requires training 10 separate outer-repetition models (inference cost x10).
- **Failure signatures:**
  - Tail Errors: The model consistently over/underestimates at extremes (< 20 or > 80 fear) due to the normal distribution of training data. Do not expect reliable predictions on "max fear" stimuli without re-balancing the dataset.
  - Context Confusion: "Civilization" backgrounds (e.g., spiders in houses) increase error compared to nature. The model struggles to disentangle context from object.
- **First 3 experiments:**
  1. Baseline Replication: Train ResNet50 (partial tuning only) on the Group A means. Verify you achieve MAE ~11.0. This validates your data pipeline.
  2. Architecture Ablation: Swap the complex 3-layer head for a single Linear layer. If MAE increases significantly (>0.5), the non-linear mapping is required to separate fear levels.
  3. Grad-CAM Sanity Check: Run inference on a "spider-free" image (e.g., a plain wall) from the internet. If the model predicts high fear (>20) or generates high-activation heatmaps on empty space, the model has learned background shortcuts (the paper suggests this is unlikely but possible).

## Open Questions the Paper Calls Out

### Open Question 1
Can vision models predict individual-level fear ratings (rather than group-level averages) with clinically useful accuracy when incorporating patient-specific covariates? Current models predict group-level means; individual variability adds noise, with MAE ~25.76 for individual ratings vs ~9.78 for group means. The paper proposes fusion with non-visual covariates but does not implement it.

### Open Question 2
Does the transfer-learning approach generalize to other specific phobias (e.g., heights, needles, snakes) with comparable accuracy? Only spider phobia was tested; different phobias may involve distinct visual features or fear-inducing cues not captured by models trained on spider images.

### Open Question 3
Can targeted data collection at the extremes of the fear distribution (very low and very high fear) substantially reduce prediction errors in those regions? The current dataset is approximately normally distributed with sparse coverage at tails; models showed larger errors at extreme fear levels due to limited training data.

## Limitations
- Dataset contains only 313 spider images, limiting generalization to other phobic stimuli
- Dual-level cross-validation reduces effective training sample size, potentially underestimating performance
- Grad-CAM analyses show spider activation but lack quantitative comparison to background-only baselines
- Ensemble approach improves performance but increases inference complexity by x10
- Focus on spider-specific fear limits applicability to other phobias without additional validation

## Confidence
- **Model Accuracy (MAE < 10)**: High confidence - Results are consistently replicated across multiple architectures and CV folds with clear statistical reporting.
- **Feature Transfer Mechanism**: Medium confidence - Supported by architecture comparisons but not directly tested with ablation studies of feature importance.
- **Grad-CAM Grounding**: Medium confidence - Visual analysis shows spider activation but lacks quantitative comparison to random or background-only baselines.
- **Data Efficiency Advantage**: High confidence - Clear learning curves demonstrate faster convergence for transformers vs CNNs with quantified x50 points.
- **Clinical Applicability**: Low confidence - The paper establishes technical feasibility but does not test actual clinical outcomes or patient-level predictions.

## Next Checks
1. Evaluate the trained DINOv2 model on a completely different set of spider images (not in SpiDa) and on non-spider fear-inducing images (snakes, heights) to assess domain transfer.
2. Systematically mask or remove specific spider features (legs, eyes, abdomen) in test images and measure degradation in prediction accuracy to establish causal feature importance.
3. Deploy the model in a small-scale clinical setting where predictions are compared against actual patient-reported fear during exposure therapy sessions, measuring both prediction accuracy and therapeutic utility.