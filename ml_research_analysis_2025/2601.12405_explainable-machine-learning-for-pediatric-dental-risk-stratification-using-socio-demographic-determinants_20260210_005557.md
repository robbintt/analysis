---
ver: rpa2
title: Explainable Machine Learning for Pediatric Dental Risk Stratification Using
  Socio-Demographic Determinants
arxiv_id: '2601.12405'
source_url: https://arxiv.org/abs/2601.12405
tags:
- risk
- health
- pediatric
- dental
- oral
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an explainable AI framework for pediatric
  dental risk stratification using socio-demographic and health data. A supervised
  machine learning model was trained with features including age, income-to-poverty
  ratio, race/ethnicity, gender, and medical history, and explainability was achieved
  using SHAP analysis.
---

# Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants

## Quick Facts
- arXiv ID: 2601.12405
- Source URL: https://arxiv.org/abs/2601.12405
- Reference count: 0
- Primary result: Explainable AI framework for pediatric dental risk stratification using socio-demographic data with AUC 0.61 and conservative calibration

## Executive Summary
This study develops an explainable AI framework for pediatric dental risk stratification using socio-demographic and health data. A supervised machine learning model was trained with features including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Explainability was achieved using SHAP analysis, with global findings showing age and income-to-poverty ratio as the strongest predictors. The model achieved modest discrimination (AUC = 0.61) and conservative calibration, systematically underestimating risk at higher predicted levels. The framework supports population screening and equitable resource allocation rather than clinical diagnosis, prioritizing transparency and ethical deployment over maximal predictive accuracy.

## Method Summary
The study employed supervised machine learning to classify pediatric dental risk using five socio-demographic features: age, income-to-poverty ratio, race/ethnicity, gender, and medical history. The model was trained and evaluated using cross-validation, with performance assessed via AUC-ROC and calibration curves. SHAP (SHapley Additive exPlanations) was implemented to provide both global and individual-level interpretability. The approach emphasizes explainability and ethical deployment over maximizing predictive accuracy, positioning the model as a screening tool for population health management rather than clinical diagnosis.

## Key Results
- Model achieved AUC = 0.61 with conservative calibration that systematically underestimates risk at higher predicted levels
- Global SHAP analysis identified age and income-to-poverty ratio as the strongest predictors of dental risk
- Lower income levels were consistently associated with higher predicted risk
- Framework prioritizes transparency and ethical deployment over maximal predictive accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SHAP decomposition makes socio-demographic risk contributions auditable at both population and individual levels.
- Mechanism: SHAP values quantify each feature's marginal contribution to a prediction by averaging across all possible feature orderings, enabling waterfall visualizations that show how baseline risk shifts toward final estimates.
- Core assumption: Feature importance reflects meaningful associations rather than causal relationships.
- Evidence anchors:
  - [abstract] "Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions."
  - [section 2.5] "Explainability was implemented using SHapley Additive exPlanations (SHAP), a game-theoretic approach that attributes model predictions to individual feature contributions."
  - [corpus] Weak direct corpus support for SHAP-specific mechanism; neighboring papers focus on risk stratification broadly rather than explainability methods.
- Break condition: If feature interactions are highly non-linear or collinear, SHAP attributions may become unstable or misleading.

### Mechanism 2
- Claim: Age and income-to-poverty ratio emerge as dominant risk predictors because they encode cumulative exposure to cariogenic environments and access-to-care constraints.
- Mechanism: Age proxies duration of exposure to dietary, behavioral, and environmental risk factors; income-to-poverty ratio proxies socioeconomic status affecting nutrition, preventive services, and healthcare access.
- Core assumption: Epidemiological associations in training data generalize to target populations with similar socio-demographic distributions.
- Evidence anchors:
  - [abstract] "Global SHAP analysis identified age and income-to-poverty ratio as the strongest predictors of dental risk."
  - [section 3.3] "Global SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted dental risk. Lower income levels were consistently associated with higher predicted risk."
  - [corpus] Demographic foundation models paper notes demographic attributes are "vital predictors in clinical risk stratification" across diseases.
- Break condition: If deployed in populations with fundamentally different socioeconomic structures or healthcare systems, feature importance may shift.

### Mechanism 3
- Claim: Conservative calibration (underestimation at higher risk) reduces false-positive escalation in screening contexts.
- Mechanism: Model produces probability estimates below observed outcome frequencies at high predicted risk levels, prioritizing harm minimization over sensitivity.
- Core assumption: In pediatric screening, overestimation cost (unnecessary anxiety, stigma, intervention) exceeds underestimation cost (missed prevention opportunity).
- Evidence anchors:
  - [abstract] "The model achieved modest discrimination (AUC = 0.61) and conservative calibration, systematically underestimating risk at higher predicted levels."
  - [section 3.2] "This conservative behavior is desirable for screening applications, as it minimizes the risk of false alarms and inappropriate clinical escalation."
  - [corpus] Corpus does not directly address calibration tradeoffs in pediatric dental contexts.
- Break condition: If public health context requires higher sensitivity (e.g., scarce interventions with high payoff), conservative calibration may underserve high-risk groups.

## Foundational Learning

- Concept: **SHAP (SHapley Additive exPlanations)**
  - Why needed here: Core interpretability method; without understanding Shapley values, global and local explanations cannot be validated or debugged.
  - Quick check question: Can you explain why a feature with high global importance might have low or negative contribution for a specific individual?

- Concept: **Calibration vs. Discrimination**
  - Why needed here: AUC (0.61) captures ranking ability; calibration captures probability reliability. The paper explicitly trades off discrimination for calibrated, conservative estimates.
  - Quick check question: If a model has AUC 0.90 but systematically overpredicts risk by 20%, what goes wrong in a resource-allocation decision?

- Concept: **Screening vs. Diagnosis Framing**
  - Why needed here: The model is explicitly NOT a diagnostic tool; misunderstanding this leads to inappropriate clinical deployment.
  - Quick check question: What operational difference exists between acting on a 0.7 screening risk score versus a positive diagnostic test?

## Architecture Onboarding

- Component map: Data layer -> Preprocessing -> Model -> Evaluation -> Explainability
- Critical path:
  1. Data ingestion and validation (ensure socio-demographic coverage)
  2. Feature engineering and encoding
  3. Model training with cross-validation
  4. Calibration assessment (reliability diagrams)
  5. SHAP computation and visualization
  6. Deployment as screening decision-support (NOT diagnostic)
- Design tradeoffs:
  - Accuracy vs. interpretability: AUC 0.61 accepted to enable transparent explanations
  - Sensitivity vs. harm minimization: Conservative calibration trades sensitivity for reduced false positives
  - Feature parsimony vs. predictive power: Only 5 features used for scalability and explainability
- Failure signatures:
  - Overconfident high-risk predictions (calibration drift)
  - SHAP attributions dominated by a single feature (potential data leakage or proxy variable)
  - Systematic bias in underrepresented demographic subgroups
  - Deployment as diagnostic tool rather than screening support
- First 3 experiments:
  1. Reproduce calibration curve on held-out subset; verify systematic underestimation at high predicted probabilities.
  2. Compute SHAP values for edge cases (highest/lowest risk individuals); confirm multi-factor contributions rather than single-feature dominance.
  3. Stratify performance by race/ethnicity and income quintile; check for differential calibration or discrimination that would signal equity concerns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent would integrating clinical dental examination findings and behavioral variables improve the model's discriminative performance (AUC) while maintaining the current level of explainability?
- Basis in paper: [explicit] The authors state that the "absence of clinical dental examination findings and behavioral variables constrains predictive performance" and suggest future studies integrate them provided explainability is preserved.
- Why unresolved: The current study relied solely on socio-demographic variables to prioritize scalability and population-level screening; clinical data was explicitly excluded.
- What evidence would resolve it: A comparative study training the model on a dataset containing both socio-demographic and clinical features, measuring changes in AUC and SHAP consistency.

### Open Question 2
- Question: Does longitudinal modeling of socio-demographic factors alter the feature importance hierarchy or improve the accuracy of temporal risk trajectories compared to the current cross-sectional approach?
- Basis in paper: [explicit] The authors note the "cross-sectional nature of the dataset precludes causal inference and limits modeling of temporal risk trajectories."
- Why unresolved: The dataset used was a "cross-sectional snapshot," preventing the analysis of how risk accumulates or changes over time.
- What evidence would resolve it: A study utilizing panel data or longitudinal cohorts to validate the model's predictions against actual future dental outcomes.

### Open Question 3
- Question: Can post-hoc calibration techniques like isotonic regression or Platt scaling correct the systematic underestimation of risk at higher probability levels without inducing overconfidence?
- Basis in paper: [explicit] The discussion asks if calibration adjustments "should be evaluated carefully to avoid introducing artificial confidence" and specifically mentions isotonic regression.
- Why unresolved: The current model demonstrates conservative calibration (underestimation), but the authors have not yet tested whether standard correction methods would inadvertently undermine ethical deployment.
- What evidence would resolve it: Re-evaluating the model with calibration metrics (Brier score, reliability diagrams) after applying isotonic regression to the output probabilities.

## Limitations
- Modest predictive performance (AUC = 0.61) limits clinical utility
- Potential generalizability constraints to populations with different socioeconomic structures
- Reliance on only five socio-demographic features limits predictive power but enables transparency

## Confidence
- Explainability mechanisms (SHAP): High
- Demographic predictor hierarchy (age and income-to-poverty ratio): Medium
- Clinical impact claims: Low

## Next Checks
1. Conduct subgroup analysis by race/ethnicity and income quintile to verify equitable performance across demographic groups.
2. Test model calibration and feature importance stability on an independent pediatric population with different socioeconomic distributions.
3. Validate that conservative calibration specifically reduces false positive rates without creating systematic bias against any demographic group.