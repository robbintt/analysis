---
ver: rpa2
title: Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings
  via Geometric Features
arxiv_id: '2508.12440'
source_url: https://arxiv.org/abs/2508.12440
tags:
- uni00000048
- uni00000044
- uni00000013
- uni00000011
- uni00000042
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a machine learning-based system for estimating
  manufacturing costs directly from 2D engineering drawings (DWG files). The approach
  extracts approximately 200 geometric and statistical features from drawings of automotive
  suspension and steering parts and trains gradient boosting models (XGBoost, CatBoost,
  LightGBM) to predict unit manufacturing costs.
---

# Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features

## Quick Facts
- arXiv ID: 2508.12440
- Source URL: https://arxiv.org/abs/2508.12440
- Reference count: 0
- Primary result: Gradient boosting models trained on ~200 geometric features from DWG files achieve MAPE <10% for 10 of 24 product groups

## Executive Summary
This paper presents a machine learning system that predicts manufacturing costs directly from 2D engineering drawings without requiring explicit process planning. The approach extracts approximately 200 geometric and statistical features from DWG files of automotive suspension and steering parts, then trains gradient boosting models (XGBoost, CatBoost, LightGBM) to estimate unit costs. The framework achieves MAPE values below 10% for 10 out of 24 product groups, with overall MAPE ranging from 3.91% to 18.51%. The system offers faster, more consistent, and interpretable cost estimation compared to traditional methods, supporting cost-aware design decisions and digital manufacturing workflows.

## Method Summary
The method converts DWG files to DXF format and parses five geometric entity types (LINE, CIRCLE, ARC, SPLINE, ELLIPSE) along with dimension measurements and material text. It computes approximately 200 statistical descriptors including counts, min/max/mean/median/mode/std/skewness/kurtosis, and 12-bin histograms for various geometric properties. The framework also calculates distributional distance metrics (Euclidean, KL divergence) between each drawing's histogram features and product-group reference distributions. Three gradient boosting regressors are trained per product group using Bayesian hyperparameter optimization via Optuna, with 5-fold cross-validation and early stopping.

## Key Results
- MAPE <10% achieved for 10 of 24 product groups
- Overall MAPE ranges from 3.91% to 18.51% across all models
- Geometric features like ellipse count, arc geometry, and dimensional extrema identified as strongest cost drivers
- XGBoost performs best with median MAPE of 10.79% on Link Stabilizer group (n=1553)

## Why This Works (Mechanism)

### Mechanism 1: Structured Geometric Feature Extraction from CAD
Parsing DXF files to extract ~200 geometric and statistical descriptors provides sufficient signal for cost prediction without explicit process planning. The approach converts DWG→DXF, parses five primitives, and computes statistical descriptors plus distributional distance metrics. This works because geometric complexity and dimensional variation correlate with manufacturing cost through implicit machining requirements.

### Mechanism 2: Gradient Boosting Captures Nonlinear Cost Relationships
Gradient-boosted decision trees model complex, nonlinear relationships between geometric features and unit cost more effectively than linear regression. Sequential ensemble of weak learners corrects residuals, naturally handles feature interactions, and includes built-in missing value handling. This approach assumes historical unit costs accurately embed both direct and indirect manufacturing expenses.

### Mechanism 3: Explainability via Feature Attribution Aligns with Domain Knowledge
SHAP and feature importance analyses reveal cost drivers that match engineering intuition, enabling actionable design feedback. Split-count importance ranks features, SHAP values quantify per-sample contribution, and single decision tree visualization exposes threshold rules. This assumes top-ranked features have causal or stable correlational relationships to manufacturing complexity.

## Foundational Learning

- Concept: DXF file format and geometric primitives
  - Why needed here: Understanding entity types and their properties is prerequisite for feature engineering
  - Quick check question: What five primitive entity types does the parser extract, and which properties are captured for ARC entities?

- Concept: Gradient boosting fundamentals
  - Why needed here: Model selection requires understanding differences in loss functions, categorical handling, and tree growth strategies
  - Quick check question: Which loss function does CatBoost use versus XGBoost in this study?

- Concept: SHAP (Shapley Additive Explanations)
  - Why needed here: Interpreting model predictions to guide cost-aware design requires understanding feature attribution
  - Quick check question: Why might ellipse_count have high SHAP importance for manufacturing cost?

## Architecture Onboarding

- Component map: Data ingestion (DWG→DXF conversion) → Geometric parser (entity extraction + dimension parsing + material text extraction) → Feature engineering (~200 descriptors + histogram bins + group-level distance metrics) → Model training (24 product-group-specific gradient boosting models with Optuna optimization) → Inference pipeline (cost prediction + SHAP attribution)

- Critical path: Scale factor computation (from rotated dimensions) → geometric entity parsing → statistical feature computation → model inference. Incorrect scaling propagates errors through all features.

- Design tradeoffs:
  - Product-group-specific models vs. unified model: 24 separate models trade training overhead for accuracy; unified model would lose group-specific patterns
  - Feature richness vs. interpretability: ~200 features require SHAP for explanation; fewer features would be more transparent but may lose signal
  - MAPE vs. MAE: MAPE chosen for business interpretability but over-weights errors on low-cost items

- Failure signatures:
  - MAPE >15%: Likely insufficient samples, inconsistent geometry within group, or noisy cost labels
  - Underestimation at high costs: Class imbalance or greater variability in expensive parts
  - High prediction variance across CV folds: Overfitting or data leakage

- First 3 experiments:
  1. Validate DXF parsing pipeline on 10–20 sample drawings: confirm all 5 entity types extracted, scale factor computed correctly, material text captured
  2. Train XGBoost on Link Stabilizer group (n=1553): target MAPE ~10.79%; verify feature importance matches reported (rotated_max, arc_angle_mean)
  3. Run SHAP analysis: confirm ellipse_count, diameter_max, rotated_median are top contributors; inspect direction of material feature effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating spatial relationships between geometric entities (e.g., adjacency, symmetry) via graph-based models improve predictive performance compared to statistical descriptors?
- Basis in paper: The Conclusion suggests that "incorporating spatial relationships... could provide richer representations" and explicitly proposes graph-based models as a future direction.
- Why unresolved: The current framework relies on "bag of features" statistical descriptors rather than the relative positioning of shapes.
- What evidence would resolve it: A comparative study benchmarking the current XGBoost model against a Graph Neural Network (GNN) on the same dataset of DWG files.

### Open Question 2
- Question: Does synthetic engineering drawing generation effectively address class imbalance and improve model robustness for product groups with limited training data?
- Basis in paper: The authors identify "expanding the dataset through synthetic drawing generation" as a specific future improvement to enhance robustness.
- Why unresolved: The dataset is imbalanced (sizes range from 34 to 1,707), and smaller groups often exhibit higher error rates or instability.
- What evidence would resolve it: Improved MAPE scores and reduced variance in cross-validation for under-represented product groups after augmenting training data with synthetic drawings.

### Open Question 3
- Question: Does the reliance on specific geometric features (e.g., ellipse count, arc statistics) limit the framework's generalizability to non-automotive domains?
- Basis in paper: The authors claim the workflow can be "readily adapted" to sectors like aerospace or shipbuilding, but the feature importance analysis is derived solely from automotive suspension parts.
- Why unresolved: It is undetermined if the identified cost drivers are universal or merely artifacts of the specific automotive dataset used.
- What evidence would resolve it: Successful application of the trained model (without architectural changes) to a distinct dataset of aerospace or civil engineering drawings.

## Limitations

- Proprietary 2D DWG files without code or data release create reproducibility barriers
- 24 product-group split may introduce overfitting risk, particularly for smaller groups with limited samples
- Geometric feature set may not capture all cost drivers (e.g., surface finish requirements, secondary operations)
- Assumes cost labels accurately reflect true manufacturing expenses across different production contexts

## Confidence

- **High Confidence**: Gradient boosting models achieving MAPE <10% for majority of groups (well-established ML literature, clear training methodology)
- **Medium Confidence**: Geometric feature extraction reliably capturing cost-relevant information (standard parsing approach but untested across diverse DWG formats)
- **Medium Confidence**: SHAP-based explainability revealing actionable design insights (SHAP is established but manufacturing cost prediction from 2D drawings lacks validation benchmarks)

## Next Checks

1. **Feature Extraction Validation**: Manually verify parsed geometric features on 10–20 sample drawings to confirm correct entity extraction, accurate scale factor computation, and proper statistical descriptor calculation.

2. **Cross-Group Transfer Testing**: Train a single unified model across all product groups and compare performance to individual group models to assess whether product-group specificity is essential or introduces overfitting.

3. **Cost Label Stability Analysis**: Conduct temporal validation by training on older cost data and testing on newer samples to measure prediction drift and assess whether model requires periodic retraining.