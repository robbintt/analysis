---
ver: rpa2
title: Softly Constrained Denoisers for Diffusion Models
arxiv_id: '2512.14980'
source_url: https://arxiv.org/abs/2512.14980
tags:
- diffusion
- constraint
- data
- denoiser
- constrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Softly Constrained Denoisers (SCD), a method
  for improving constraint satisfaction in diffusion models by embedding constraint
  knowledge directly into the denoiser architecture. Unlike previous approaches that
  add regularization terms to the loss or adjust scores at inference time, SCD uses
  a learned scaling factor to combine the base denoiser output with a constraint gradient,
  providing a soft inductive bias toward constraint-compliant samples.
---

# Softly Constrained Denoisers for Diffusion Models

## Quick Facts
- arXiv ID: 2512.14980
- Source URL: https://arxiv.org/abs/2512.14980
- Authors: Victor M. Yeom-Song; Severi Rissanen; Arno Solin; Samuel Kaski; Mingfei Sun
- Reference count: 40
- Primary result: SCD improves constraint satisfaction in diffusion models while maintaining distributional fidelity, especially under misspecification

## Executive Summary
This paper introduces Softly Constrained Denoisers (SCD), a method for improving constraint satisfaction in diffusion models by embedding constraint knowledge directly into the denoiser architecture. Unlike previous approaches that add regularization terms to the loss or adjust scores at inference time, SCD uses a learned scaling factor to combine the base denoiser output with a constraint gradient, providing a soft inductive bias toward constraint-compliant samples. The authors prove that regularization-based methods bias the model away from the true data distribution and degrade the ELBO. Experiments on toy data and PDE benchmarks (Darcy flow and Helmholtz equation) show that SCD achieves superior constraint satisfaction while maintaining distributional fidelity, especially under misspecification. SCD is also shown to be computationally efficient and robust compared to existing methods.

## Method Summary
SCD modifies the denoiser architecture to incorporate constraint gradients during training rather than at inference time. The key innovation is adding a learned scaling factor γθ that modulates the constraint correction: Dθ(xt,t) = D_orig(xt,t) + γθ(xt,t)·σ(t)²·∇D log_l_c(D_orig). This preserves the standard diffusion loss L(θ)=E[||Dθ(xt,t)-x₀||²], ensuring the denoiser remains an unbiased estimator of E[x₀|x_t]. The scaling network γθ learns when to trust or ignore the constraint gradient, providing robustness under misspecification. The method is validated on toy circle examples and PDE-constrained problems, showing superior constraint satisfaction while maintaining distributional fidelity compared to regularization-based alternatives.

## Key Results
- SCD achieves lower constraint residuals than vanilla diffusion while maintaining distributional fidelity (lower NLL) on PDE benchmarks
- Under misspecification, SCD outperforms regularization-based methods (PIDM) with much smaller distributional degradation (W1 distance 2.42±0.16 vs 33.75±3.37)
- SCD preserves ELBO guarantees by keeping the standard diffusion loss unmodified, unlike regularization approaches that bias the optimal denoiser
- The learned scaling factor γθ enables adaptive constraint influence, improving robustness to imperfect domain knowledge

## Why This Works (Mechanism)

### Mechanism 1: Guidance-Inspired Denoiser Correction
Embedding constraint gradients into the denoiser forward pass provides a soft inductive bias toward constraint-compliant samples while preserving distributional flexibility. The denoiser output is corrected by adding a learned scaling of the constraint gradient: Dθ(xt,t) = D_orig(xt,t) + γθ(xt,t)·σ(t)²·∇D log_l_c(D_orig). This structure approximates the effect of inference-time guidance but makes it a learnable component of the architecture rather than a sampling-time hack.

### Mechanism 2: Preservation of ELBO Guarantees via Unmodified Loss
By keeping the standard diffusion loss L(θ)=E[||Dθ(xt,t)-x₀||²] unchanged, SCD preserves the theoretical property that the optimal denoiser converges to E[x₀|x_t], unlike regularization-based approaches. Regularization-based methods add λ||R(Dθ)||² to the loss, which formally proves shifts the optimal denoiser away from E[x₀|x_t] to satisfy the constraint, breaking the score-denoiser connection and degrading ELBO.

### Mechanism 3: Learned Modulation of Constraint Influence
The learned scaling factor γθ(xt,t) enables the model to adaptively trust or ignore constraint gradients, providing robustness under misspecification. γθ is a small network that observes the denoiser output and time, outputting a scalar to scale the constraint correction. When the constraint aligns with data, γθ learns positive values; when misspecified, it can reduce or reverse correction.

## Foundational Learning

- **Concept: Diffusion as Denoising Score Matching**
  - Why needed here: Understanding that a denoiser Dθ(xt,t)≈E[x₀|x_t] and its connection to the score function ∇_xt log p(x_t) via Tweedie's formula is essential for grasping why modifying the loss breaks theoretical guarantees
  - Quick check question: Can you explain why the standard diffusion loss E[||Dθ-estimator connects to both the optimal denoiser and the score function?

- **Concept: Guidance as Score Adjustment**
  - Why needed here: SCD is derived from inference-time guidance formulas; understanding how guidance approximates conditional generation by adding ∇_xt log c(x₀) to the score clarifies the architectural design
  - Quick check question: Given a constraint function l_c(x₀), how would you modify the score ∇_xt log p(x_t) to bias sampling toward constraint-satisfying regions?

- **Concept: Bias-Variance Tradeoff in Constrained Generation**
  - Why needed here: The core tension SCD addresses is between constraint satisfaction (which regularization enforces at the cost of distributional bias) and distributional fidelity (which vanilla diffusion preserves but lacks constraint awareness)
  - Quick check question: If you add a regularization term λ||R(Dθ)||² to the diffusion loss, what happens to the optimal denoiser and the model's ELBO?

## Architecture Onboarding

- **Component map:**
  Base denoiser D_orig(xt,t) -> Compute constraint gradient ∇_D_orig log_l_c(D_orig) -> Scale by γθ·σ(t)² -> Add to D_orig

- **Critical path:**
  1. Forward pass: xt → D_orig(xt,t) → compute constraint gradient → scale by γθ·σ² → add to D_orig
  2. Loss computation: Compare final D_θ output to ground truth x₀ using standard MSE
  3. Backprop: Gradients flow through γθ (learning when to trust constraint) and D_orig (learning base denoising)

- **Design tradeoffs:**
  Constraint formulation: l_c(x)=exp(-||R(x)||) is a design choice; different norms or formulations change gradient behavior
  γθ capacity: Paper uses small MLP; larger capacity may overfit to spurious constraint patterns
  Noise level distribution: Paper modifies Karras loss to TruncLogNormal to improve low-noise refinement—important for PDE residuals
  No inference-time adjustments: Unlike DPS/guidance methods, SCD is training-only; constraint knowledge is baked into weights

- **Failure signatures:**
  High residual + low NLL: γθ may not be learning to apply constraint correction; check gradient flow through constraint term
  Low residual + high NLL (vs. vanilla): γθ may be over-applying constraint; reduce γθ capacity or check constraint formulation
  Instability at low noise levels: Check truncation of noise distribution; original LogNormal may cause weighting explosion

- **First 3 experiments:**
  1. **Circle toy task:** Train on unit circle points with R_circle=(√(x²+y²)-1)²; verify SCD matches vanilla W1 distance while PIDM degrades under "chop" misspecification
  2. **Ablation on γθ initialization:** Initialize γθ to output near-zero vs. random positive values; measure convergence speed and final residual/NLL tradeoff
  3. **Constraint gradient magnitude scaling:** Multiply constraint gradient by a fixed factor (0.1, 1.0, 10.0) before input to network; observe impact on training stability and final performance

## Open Questions the Paper Calls Out

- **Open Question 1:** Can robustness to misspecification be further improved by introducing learnable parameters into the constraint function l_c(x) itself?
  - Basis: The authors state in Section 6: "Even better robustness to constraint specification could be achieved by introducing learnable parameters to l_c(x) itself."

- **Open Question 2:** Can the SCD framework be extended to guarantee hard constraint satisfaction without the need for post-processing?
  - Basis: The authors note in Section 6: "Another limitation is that our model is not guaranteed to generate samples within a particular hard constraint."

- **Open Question 3:** How does the performance of SCD degrade when the constraint residual R(x) is non-differentiable or discontinuous?
  - Basis: Section 3 states, "We further assume R to be continuously differentiable," which limits the method's applicability to constraints involving inequalities or discrete variables common in scientific computing.

## Limitations
- SCD provides only soft constraint satisfaction, not guaranteed hard constraint compliance
- The method requires the constraint residual R(x) to be continuously differentiable, limiting applicability to certain constraint types
- Performance under complex misspecifications beyond tested PDE residuals and simple geometric constraints remains unproven

## Confidence

- **High**: Theoretical claims about ELBO degradation in regularization-based methods (Propositions 3.1-3.2) and the formal derivation of SCD from guidance equations
- **Medium**: Empirical performance claims on Darcy Flow and Helmholtz benchmarks, particularly the NLL comparisons and constraint satisfaction under misspecification
- **Medium**: Claims about computational efficiency relative to inference-time methods, as wall-clock comparisons are not provided
- **Low**: Generalizability claims to other scientific domains or more complex constraint structures beyond tested PDEs

## Next Checks

1. **Systematic ablation on noise distribution truncation**: Train SCD with standard LogNormal vs. TruncatedLogNormal at varying truncation levels, measuring residual/NLL tradeoff and training stability across all PDE benchmarks

2. **Cross-dataset generalization test**: Apply SCD to a new scientific domain (e.g., incompressible Navier-Stokes flow) with different constraint structure to verify robustness beyond Darcy/Helmholtz

3. **γθ capacity sensitivity analysis**: Vary the depth and width of the scaling network γθ across multiple orders of magnitude, measuring impact on constraint satisfaction, distributional fidelity, and training stability