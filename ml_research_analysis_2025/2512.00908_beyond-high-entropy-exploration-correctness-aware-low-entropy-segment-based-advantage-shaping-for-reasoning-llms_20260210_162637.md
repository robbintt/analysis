---
ver: rpa2
title: 'Beyond High-Entropy Exploration: Correctness-Aware Low-Entropy Segment-Based
  Advantage Shaping for Reasoning LLMs'
arxiv_id: '2512.00908'
source_url: https://arxiv.org/abs/2512.00908
tags:
- low-entropy
- reasoning
- less
- segments
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving reasoning stability
  in large language models trained via reinforcement learning with verifiable rewards
  (RLVR). It proposes that most reasoning trajectories consist of low-entropy segments
  encoding stable structural patterns, and that overlaps of these segments across
  correct responses strongly correlate with model accuracy.
---

# Beyond High-Entropy Exploration: Correctness-Aware Low-Entropy Segment-Based Advantage Shaping for Reasoning LLMs

## Quick Facts
- **arXiv ID:** 2512.00908
- **Source URL:** https://arxiv.org/abs/2512.00908
- **Reference count:** 37
- **Primary result:** LESS consistently improves accuracy across six mathematical reasoning benchmarks and three model backbones (1.5B, 7B math-tuned, and 7B base), with notable gains on challenging tasks like AIME and AMC.

## Executive Summary
This paper addresses the challenge of improving reasoning stability in large language models trained via reinforcement learning with verifiable rewards (RLVR). It proposes that most reasoning trajectories consist of low-entropy segments encoding stable structural patterns, and that overlaps of these segments across correct responses strongly correlate with model accuracy. Based on this insight, the authors introduce LESS, a correctness-aware reinforcement learning framework that reshapes token-level advantages by amplifying low-entropy segments unique to correct responses, suppressing those unique to incorrect responses, and neutralizing shared segments. Instantiated on GRPO, LESS consistently improves accuracy across six mathematical reasoning benchmarks and three model backbones (1.5B, 7B math-tuned, and 7B base), with notable gains on challenging tasks like AIME and AMC. It also enhances robustness by raising worst-case performance and reducing response-level variance.

## Method Summary
LESS is a correctness-aware reinforcement learning framework that reshapes token-level advantages based on low-entropy segment statistics. The method identifies contiguous low-entropy token spans (above minimum length μ) within each response, then aggregates occurrence statistics across the rollout group. Segments appearing only in correct responses are treated as productive patterns; those only in incorrect responses as unproductive; shared segments are ambiguous. For each token, the shaped advantage is: (1) unchanged for high-entropy tokens; (2) scaled by (n_r/N_r) for correct-only segments, (n_w/N_w) for incorrect-only segments; (3) set to zero for shared segments. This rescales credit assignment based on segment-level correctness statistics rather than token-level uncertainty alone. LESS is instantiated on GRPO with entropy-based segmentation using h-quantile threshold and μ=5 minimum segment length, trained on MATH dataset with batch size 512, lr 1e-6, clip range 0.2-0.28, 8 rollouts/prompt, temperature 1.0 train/0.1 eval.

## Key Results
- LESS improves accuracy across six benchmarks (MATH500, Minerva, OlympiadBench, AIME24/25, AMC23) and three model sizes
- Notable gains on challenging tasks: +6.1 to +7.8 points on worst@k robustness
- Maintains higher entropy in incorrect responses, preventing premature collapse onto incorrect patterns
- Outperforms vanilla GRPO and shows consistent improvements across different model backbones

## Why This Works (Mechanism)

### Mechanism 1
Low-entropy segments encode stable reasoning patterns whose overlap across correct responses correlates with accuracy. The method identifies contiguous low-entropy token spans (above minimum length μ) within each response, then aggregates occurrence statistics across the rollout group. Segments appearing only in correct responses are treated as productive patterns; those only in incorrect responses as unproductive; shared segments are ambiguous. Core assumption: Low-entropy segments capture reusable reasoning structure rather than trivial text (requires minimum length filtering). Evidence: Pearson r=0.94, p=1.81e-6 across six benchmarks; training dynamics show overlap and accuracy rise together. Break condition: If low-entropy overlap does not correlate with accuracy on a new domain, the shaping signal may be uninformative or counterproductive.

### Mechanism 2
Segment-level advantage shaping amplifies productive patterns, suppresses unproductive ones, and neutralizes ambiguous segments. For each token, the shaped advantage Â is: (1) unchanged for high-entropy tokens; (2) scaled by (n_r/N_r) for correct-only segments, (n_w/N_w) for incorrect-only segments; (3) set to zero for shared segments. This rescales credit assignment based on segment-level correctness statistics rather than token-level uncertainty alone. Core assumption: Segment occurrence statistics computed from a single rollout group (G=8 responses) provide sufficient signal to distinguish productive vs. unproductive patterns. Evidence: Equation 4 defines the full shaping rule; Algorithm 1 provides pseudocode. Break condition: If rollout group size is too small or response diversity is low, segment statistics may be noisy, leading to unstable shaping.

### Mechanism 3
LESS maintains higher entropy in incorrect responses, preventing premature collapse of the policy onto incorrect patterns. By zeroing advantages for shared segments and suppressing incorrect-only segments proportionally, incorrect trajectories retain higher uncertainty rather than collapsing to low-entropy errors. Core assumption: Maintaining entropy separation between correct and incorrect responses is beneficial for exploration and prevents locking in systematic errors. Evidence: Figure 3 shows LESS maintains higher entropy ratio (incorrect/correct) throughout training; GRPO collapses this separation. Break condition: If the task has multiple valid solution paths with different low-entropy signatures, zeroing shared segments may inadvertently suppress alternative correct reasoning styles.

## Foundational Learning

- **Token entropy in autoregressive LLMs:** Understanding how H_t = -Σ p(v) log p(v) measures model uncertainty per token is essential for interpreting the segmentation step. Quick check: Given a token with entropy near zero, what does that imply about the model's next-token distribution?

- **Policy gradient advantage functions:** LESS modifies the advantage A_i before policy updates; understanding how advantages encode credit assignment is prerequisite. Quick check: In REINFORCE, what happens to gradient variance if advantages are consistently miscalibrated?

- **GRPO (Group Relative Policy Optimization):** LESS is instantiated on GRPO; understanding its group-wise advantage normalization (Eq. 5) clarifies where shaping is injected. Quick check: How does GRPO's group-relative advantage differ from PPO's advantage estimation?

## Architecture Onboarding

- **Component map:** Entropy computation per token using π_old log-probs -> Per-response threshold τ_i via h-quantile of token entropies -> Segmentation into Shigh (isolated high-entropy tokens), Sfrag (short fragments < μ), Sseg (segments ≥ μ) -> Cross-group segment aggregation: build Σ of unique segments, count n_r(σ), n_w(σ) -> Advantage shaping via Eq. 4 -> Pass shaped advantages to GRPO clipped-ratio update

- **Critical path:** Accurate entropy computation → consistent segment extraction → correct cross-group counting → properly scaled advantages. Errors in step 3 (segmentation) propagate directly to credit assignment.

- **Design tradeoffs:** μ (minimum segment length): Too small (μ=3) captures noisy fragments; too large (μ=7) filters meaningful patterns. Paper finds μ=5 optimal on Qwen2.5-Math-7B. Quantile h for entropy threshold: Paper uses fixed quantile; adaptive thresholds not explored (listed as limitation). Rollout group size G: Paper uses G=8; smaller groups yield noisier statistics.

- **Failure signatures:** Training instability with high variance in shaped advantages → likely noisy segment statistics from insufficient group size. Slower early training than vanilla GRPO → expected behavior per paper; should recover by mid-training. No accuracy improvement despite implementation → check if low-entropy overlap correlates with accuracy on your dataset; if not, preconditions may not hold.

- **First 3 experiments:** 1) Reproduce correlation analysis: On your target dataset, plot low-entropy segment overlap vs. accuracy across multiple checkpoints. Confirm r > 0.8 before investing in full implementation. 2) Ablate μ: Run μ ∈ {3, 5, 7} on a held-out validation set. Expect μ=5 to show smoothest training; document divergence patterns for μ=3 (fluctuations) and μ=7 (slower convergence). 3) Worst-case robustness check: Compare worst@k (k=8,16,32) between LESS and GRPO. The paper reports +6.1 to +7.8 point improvements; if you see <2 points, investigate whether segment statistics are being computed correctly.

## Open Questions the Paper Calls Out

- **Domain generalizability:** Do the observed low-entropy patterns and LESS performance gains generalize to non-Qwen architectures like Llama? Basis: Authors state in Limitations that they only tested on Qwen2.5 family and "it is unclear whether the same entropy patterns and gains will hold more broadly." Unresolved because different model families employ varying tokenizers and pretraining corpora. Evidence needed: Replicating LESS framework on Llama-based or Mistral-based reasoning models and comparing overlap-accuracy correlation.

- **Adaptive thresholds:** Can adaptive or dynamic entropy thresholds improve segment extraction compared to the fixed quantile approach? Basis: Authors note they "do not yet study how different quantiles, adaptive thresholds, or alternative segmentation rules would affect the learned segments." Unresolved because a fixed quantile-based threshold treats all responses uniformly, potentially misclassifying segments in trajectories with unusual entropy distributions. Evidence needed: Ablation studies comparing current fixed threshold against algorithms that dynamically adjust thresholds based on per-response statistics or training progress.

- **Algorithm compatibility:** How does LESS interact with other RLVR algorithms besides GRPO? Basis: Authors describe LESS as a "generic advantage-shaping framework" and "agnostic to the underlying RLVR objective," but only instantiate and validate on GRPO. Unresolved because it's unknown if advantage shaping formula integrates seamlessly with variance reduction techniques or clipping mechanisms of algorithms like PPO or ReMax. Evidence needed: Experiments applying LESS shaping module to PPO or DAPO to verify performance stability.

## Limitations
- Correlation between low-entropy segment overlap and accuracy (r=0.94) established only on six specific benchmarks; may not generalize to domains with different reasoning structures
- Choice of μ=5 for minimum segment length empirically determined on Qwen2.5-Math-7B but not systematically explored across different model scales or domains
- Segment statistics computed from single rollout groups (G=8) may not capture diverse solution paths in problems with multiple valid approaches

## Confidence
**High confidence:** The mechanism of entropy-based token segmentation and the core LESS algorithm (Algorithm 1) are clearly specified and reproducible. The implementation details for GRPO integration and the six benchmark evaluation protocol are well-documented.

**Medium confidence:** The correlation between segment overlap and accuracy is statistically significant within the paper's experimental scope, but the external validity across different reasoning domains remains untested. The claim that maintaining entropy separation between correct and incorrect responses improves robustness is supported by Figure 3 but lacks ablation studies on the specific contribution of this mechanism.

**Low confidence:** The assertion that segment-level advantage shaping is fundamentally superior to token-level approaches lacks direct comparison with alternative shaping methods on identical model-dataset combinations. The paper's comparison to HAPO and SPINE uses different experimental setups, making definitive claims about LESS's relative advantages premature.

## Next Checks
1. **Domain transferability test:** Apply the correlation analysis (low-entropy segment overlap vs. accuracy) to a non-mathematical reasoning task (e.g., code generation or logical inference). If the correlation drops below r=0.8, the core assumption may not hold for this domain.

2. **Segment length sensitivity across scales:** Systematically vary μ∈{3,5,7} on both 1.5B and 7B models trained on the same dataset. Document whether the optimal μ scales with model capacity or remains constant, and measure the variance in shaped advantages for each setting.

3. **Alternative shaping ablation:** Implement a token-level entropy-based advantage shaping (similar to SPINE) on the same experimental setup and compare accuracy, worst-case performance, and training stability directly against LESS. This would isolate whether segment-level aggregation provides meaningful benefits over simpler approaches.