---
ver: rpa2
title: Extracting Causal Relations in Deep Knowledge Tracing
arxiv_id: '2511.03948'
source_url: https://arxiv.org/abs/2511.03948
tags:
- exercise
- knowledge
- causal
- tracing
- subsets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Extracting Causal Relations in Deep Knowledge Tracing

## Quick Facts
- arXiv ID: 2511.03948
- Source URL: https://arxiv.org/abs/2511.03948
- Reference count: 0
- Primary result: DKT achieves higher AUC on causally-structured exercise subsets vs random subsets

## Executive Summary
This paper proposes a method to extract causal prerequisite relationships between exercises from Deep Knowledge Tracing (DKT) models. By analyzing influence scores between exercises, the authors construct directed acyclic graphs (DAGs) representing causal dependencies, then demonstrate that DKT models trained on causally-structured subsets achieve significantly higher predictive accuracy than those trained on random exercise subsets of the same size.

## Method Summary
The authors train DKT models on three Assistments datasets, then extract influence scores between exercises to construct causal DAGs. They apply dataset-specific thresholds to prune these graphs, extract exercises with causal relationships, and retrain DKT models on these causal subsets. Performance is compared against 5 random subsets of equal size using AUC and z-scores. The method uses the pyKT library for DKT implementation and computes influence scores based on conditional probabilities of correct responses.

## Key Results
- DKT models achieve higher AUC on causally-structured exercise subsets compared to random subsets
- The z-score metric demonstrates statistical significance of the causal subset advantage
- Dataset-specific thresholds (2009: 0.0107, 2012: 0.0051, 2017: 0.0139) effectively prune graphs to DAGs

## Why This Works (Mechanism)
The method leverages the sequential nature of student responses to infer causal relationships. When a student correctly answers exercise i, this information influences the prediction for exercise j. By computing these influence scores across many students, the authors can identify systematic patterns where mastery of certain exercises precedes success on others, suggesting prerequisite relationships.

## Foundational Learning
- **Influence scores**: Measure how knowledge of one exercise's outcome affects prediction for another exercise
  - Why needed: Core mechanism for identifying causal relationships between exercises
  - Quick check: Verify influence scores are symmetric (J_ij = J_ji) for baseline DKT
- **DAG pruning thresholds**: Dataset-specific values that determine which edges to keep in the causal graph
  - Why needed: Prevents cycles and noise in the extracted causal structure
  - Quick check: Ensure pruned graph has no cycles and maintains meaningful structure
- **Random subset benchmarking**: 5 random exercise subsets of equal size for statistical comparison
  - Why needed: Establishes baseline to demonstrate causal structure advantage
  - Quick check: Verify random subsets have z-scores near 0 (no causal advantage)

## Architecture Onboarding

Component Map: DKT -> Influence Score Calculation -> DAG Pruning -> Causal Subset Extraction -> Retrained DKT

Critical Path: The essential sequence is training DKT on full dataset → computing influence scores → pruning to DAG → retraining on causal subset. Each step builds on the previous; failure at any point breaks the causal analysis.

Design Tradeoffs: The authors chose fixed thresholds per dataset rather than adaptive methods, prioritizing simplicity over potentially more nuanced pruning. This creates reproducibility but may miss subtle relationships.

Failure Signatures: If random subsets show similar performance to causal subsets, either the thresholds are too lenient (including non-causal edges) or the causal structure doesn't meaningfully impact prediction.

First Experiments:
1. Train baseline DKT and verify influence scores are computed correctly
2. Apply pruning thresholds and verify resulting graph is a DAG
3. Generate random subsets and confirm z-scores are near 0

## Open Questions the Paper Calls Out

Can the accuracy of the modified influence score be maintained using a practical number of probes (e.g., 5) or a convergence-based stopping criterion instead of 100 consecutive responses?

Does the superior performance of causal subsets persist when the random baseline subsets are constructed using concept-matched sampling to control for difficulty and topic distribution?

To what extent do the extracted directed edges represent true causal prerequisites versus indirect correlations when validated against a gold-standard curriculum?

## Limitations
- DKT hyperparameters and data preprocessing details are not specified, making exact reproduction difficult
- The method assumes causal relationships can be inferred from sequential data patterns, which may conflate correlation with causation
- Evaluation relies on predictive accuracy rather than structural validity of the learned causal graph

## Confidence
- **High Confidence**: General methodology for extracting causal relationships via influence scores is clearly specified
- **Medium Confidence**: Threshold values are provided but justification for specific values is unclear
- **Low Confidence**: Exact DKT implementation details needed to reproduce quantitative results

## Next Checks
1. Verify DAG property after pruning with specified thresholds; incrementally increase threshold if cycles exist
2. Test multiple DKT architectures within pyKT to understand sensitivity of causal subset performance
3. Compare random subset z-scores against published results to confirm causal subset effect robustness