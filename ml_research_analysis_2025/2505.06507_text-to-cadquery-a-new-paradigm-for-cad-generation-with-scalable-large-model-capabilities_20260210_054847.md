---
ver: rpa2
title: 'Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model
  Capabilities'
arxiv_id: '2505.06507'
source_url: https://arxiv.org/abs/2505.06507
tags:
- cadquery
- language
- arxiv
- command
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a new paradigm for CAD generation by directly\
  \ producing executable CadQuery code from natural language, bypassing intermediate\
  \ command sequences. The authors build a large-scale dataset of 170,000 text\u2013\
  CadQuery pairs by annotating the Text2CAD dataset with executable Python-based CAD\
  \ scripts."
---

# Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities

## Quick Facts
- arXiv ID: 2505.06507
- Source URL: https://arxiv.org/abs/2505.06507
- Reference count: 40
- Direct generation of executable CadQuery code from natural language descriptions

## Executive Summary
This paper presents Text-to-CadQuery, a novel approach for generating CAD models through direct translation of natural language descriptions into executable CadQuery code. The authors propose bypassing intermediate command sequences and instead producing ready-to-execute Python scripts that can be directly run in CAD environments. They construct a large-scale dataset of 170,000 text-CadQuery pairs by annotating the Text2CAD dataset, then fine-tune six pretrained models ranging from 124M to 7B parameters. The results demonstrate significant improvements over existing approaches, with the best model achieving 69.3% exact match accuracy and reducing Chamfer Distance by 48.6%.

## Method Summary
The approach involves creating a comprehensive dataset by annotating existing CAD descriptions with executable CadQuery scripts, then fine-tuning multiple pretrained language models on this data. The method directly generates Python-based CAD code rather than intermediate representations, allowing for immediate execution in CAD environments. Six models of varying sizes (124M to 7B parameters) are evaluated to demonstrate scaling benefits, with training focused on OpenSCAD primitives and basic CAD operations.

## Key Results
- Best model achieves 69.3% top-1 exact match accuracy (up from 58.8%)
- 48.6% reduction in Chamfer Distance compared to previous approaches
- Consistent scaling improvements observed across model sizes from 124M to 7B parameters

## Why This Works (Mechanism)
The direct generation of executable CadQuery code eliminates the need for intermediate representations and subsequent compilation steps, reducing error propagation and improving generation accuracy. By fine-tuning large language models on a substantial dataset of text-CadQuery pairs, the system learns to directly map natural language descriptions to functional CAD code. The CadQuery framework provides a Python-based interface to OpenSCAD, enabling the generation of executable scripts that can be immediately tested and refined in CAD environments.

## Foundational Learning
- **CadQuery framework**: Python-based CAD scripting interface built on OpenSCAD primitives - needed for generating executable CAD code from natural language
- **Chamfer Distance metric**: Measures geometric similarity between generated and target models - needed for quantitative evaluation of CAD generation quality
- **Fine-tuning large language models**: Adapting pretrained models to specific downstream tasks - needed to learn the mapping from text to CadQuery code
- **Exact match accuracy**: Percentage of perfectly matching generated code - needed for evaluating generation correctness
- **OpenSCAD primitives**: Basic geometric shapes and operations - needed as the foundation for CAD model construction

## Architecture Onboarding

Component map: Natural Language -> Text-to-CadQuery Model -> CadQuery Code -> CAD Model

Critical path: The system takes natural language descriptions as input, processes them through the fine-tuned Text-to-CadQuery model to generate executable Python code, which is then executed in a CAD environment to produce the final 3D model.

Design tradeoffs: Direct code generation versus intermediate representations - while direct generation is more efficient and reduces error propagation, it requires more complex fine-tuning and may be less interpretable than step-by-step command sequences.

Failure signatures: Generation errors manifest as syntactically incorrect Python code, semantically incorrect CAD operations, or geometric mismatches when the generated code is executed. The model may struggle with complex spatial relationships or non-standard geometric primitives.

First experiments:
1. Test the model on simple geometric primitives (cubes, cylinders, spheres) to establish baseline performance
2. Evaluate generation accuracy on increasingly complex multi-part assemblies
3. Measure execution success rate of generated code in actual CAD environments

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions for future research.

## Limitations
- Dataset construction relies heavily on human annotation, potentially introducing inconsistencies despite quality assurance measures
- Evaluation metrics focus on exact match accuracy and geometric similarity but may not fully capture functional correctness of generated CAD models
- The approach is primarily tested on OpenSCAD primitives and basic operations, limiting generalizability to complex industrial CAD scenarios

## Confidence

High: The effectiveness of direct CadQuery generation over intermediate command sequences is well-supported by quantitative improvements in both exact match and geometric accuracy metrics.

Medium: The scalability findings show consistent improvements with model size but lack analysis of asymptotic behavior or optimal parameter ranges for this specific task.

Low: The dataset's representativeness for real-world CAD applications is uncertain given its focus on relatively simple geometries and potential annotation bias.

## Next Checks

1. Conduct ablation studies removing the human annotation component to quantify its impact on model performance

2. Test model generalization on industrial CAD datasets with complex assemblies and non-primitive geometries

3. Perform user studies comparing the functional utility of generated models from different model sizes in actual CAD workflows