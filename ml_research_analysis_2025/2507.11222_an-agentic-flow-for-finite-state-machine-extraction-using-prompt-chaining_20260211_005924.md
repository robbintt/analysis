---
ver: rpa2
title: An Agentic Flow for Finite State Machine Extraction using Prompt Chaining
arxiv_id: '2507.11222'
source_url: https://arxiv.org/abs/2507.11222
tags:
- protocol
- state
- extraction
- transitions
- flowfsm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FlowFSM, an agentic framework for extracting
  Finite-State Machines (FSMs) from network protocol specifications using Large Language
  Models (LLMs) and prompt chaining. The framework addresses limitations in existing
  FSM extraction techniques such as scalability issues, incomplete coverage, and ambiguity
  in natural language specifications by systematically processing RFC documents and
  constructing structured rulebooks through chained LLM prompts.
---

# An Agentic Flow for Finite State Machine Extraction using Prompt Chaining

## Quick Facts
- arXiv ID: 2507.11222
- Source URL: https://arxiv.org/abs/2507.11222
- Reference count: 37
- FTP: 83.33% precision, 88.24% recall, 85.71% F1-score; RTSP: 81.82% precision, 85.71% recall, 83.72% F1-score

## Executive Summary
This paper presents FlowFSM, an agentic framework for extracting Finite-State Machines (FSMs) from network protocol specifications using Large Language Models (LLMs) and prompt chaining. The framework addresses limitations in existing FSM extraction techniques such as scalability issues, incomplete coverage, and ambiguity in natural language specifications by systematically processing RFC documents and constructing structured rulebooks through chained LLM prompts. FlowFSM was evaluated on FTP and RTSP protocols, achieving precision scores of 83.33% and 81.82% respectively, recall scores of 88.24% and 85.71%, and F1-scores of 85.71% and 83.72%. The results demonstrate FlowFSM's effectiveness in extracting accurate protocol state machines while minimizing hallucinated transitions, showing promising potential for cybersecurity and reverse engineering applications.

## Method Summary
FlowFSM uses a three-stage prompt-chaining approach on CrewAI to extract FSMs from RFC documents. First, RFCs are preprocessed into hierarchical JSON trees with chunked leaf nodes. Then, LLM agents sequentially extract commands, analyze state transitions, and synthesize structured rulebooks. The framework was evaluated on FTP (RFC-959) and RTSP (RFC 2326) using llama3.3-70b-versatile, deepseek-r1-distill-llama-70b, and llama3-70b-8192 models.

## Key Results
- FTP extraction: 83.33% precision, 88.24% recall, 85.71% F1-score with 18 false positives
- RTSP extraction: 81.82% precision, 85.71% recall, 83.72% F1-score with 4 false positives
- Chained approach minimizes hallucinations while maintaining high accuracy

## Why This Works (Mechanism)

### Mechanism 1: Prompt Chaining with Iterative Refinement
Decomposing FSM extraction into sequential prompts reduces hallucinations and improves accuracy compared to single-prompt approaches. Each prompt stage processes the previous output: R_{i+1} = M(P_i(R_i)). Command extraction feeds state analysis, which feeds rulebook synthesis. This creates cumulative constraint where early errors can be caught and refined in later stages.

### Mechanism 2: Hierarchical RFC Preprocessing into Chunked Context
Structured parsing of RFC documents into hierarchical trees with chunked leaf nodes improves LLM reasoning by reducing context noise and enabling targeted retrieval. RFCs are parsed into tree T = (N, E) where nodes are sections. Leaf nodes are collected as chunks. This removes headers/footers/artifacts and produces semantically coherent units for downstream prompting.

### Mechanism 3: Three-Component Rulebook Structure as Output Constraint
Enforcing a fixed three-chapter rulebook format (Purpose, Preceding Commands, Subsequent Commands) constrains LLM output space and reduces invalid transition generation. The rulebook schema forces explicit declaration of preconditions, postconditions, and valid command sequences. This structural constraint limits the degrees of freedom for hallucination while ensuring complete transition specification.

## Foundational Learning

- **Finite-State Machine Formalism**: Understanding states, transitions, inputs, and guards is prerequisite to evaluating extraction correctness. Quick check: Given FTP's USER → PASS → RETR sequence, can you identify the states, transition triggers, and which transitions would be invalid from the "Not Connected" state?

- **Prompt Chaining vs. Single-Prompt Strategies**: The core innovation is decomposing extraction into chained prompts; understanding why single prompts fail for complex tasks explains the architecture choice. Quick check: If you prompt an LLM once to "extract the complete FTP state machine from RFC-959," what failure modes would you expect compared to a three-stage approach?

- **RFC Document Structure and Protocol Specification Conventions**: The preprocessing pipeline assumes familiarity with how RFCs organize information (sections, subsections, command definitions in appendices). Quick check: In RFC-959, where would you expect to find state transition information—in the command specification sections, the state diagram appendix, or scattered throughout?

## Architecture Onboarding

- **Component map**: RFC Parser -> Command Extraction Agent -> State Transition Analyzer -> Rulebook Synthesizer -> Orchestration Layer (CrewAI)

- **Critical path**: RFC preprocessing quality → command extraction completeness → state analysis accuracy → rulebook consistency. Errors compound downstream; validation at each stage reduces propagation.

- **Design tradeoffs**: Higher recall (88.24%, 85.71%) at cost of more false positives requiring manual validation—appropriate for security applications where missing transitions is costlier than extra candidates. Computational and runtime cost noted as limitation—not suitable for real-time extraction. Protocol-agnostic design sacrifices protocol-specific optimizations for generalization.

- **Failure signatures**: Hallucinated transitions (false positives; 18 for FTP, 4 for RTSP), missed valid transitions (false negatives; 12 for FTP, 3 for RTSP), incomplete command inventory, cross-section context loss.

- **First 3 experiments**: 
  1. Baseline comparison: Run FlowFSM on a protocol with known FSM (e.g., SMTP from RFC-5321) and compare extracted rulebook against ground truth; measure TP/FP/FN to validate reported metrics.
  2. Ablation on chaining: Run single-prompt extraction vs. three-stage chaining on same RFC excerpt; quantify hallucination rate difference to validate chaining mechanism.
  3. Chunk size sensitivity: Vary leaf-node chunk aggregation (single sections vs. merged subsections) and measure impact on command coverage and transition accuracy; test chunking mechanism assumptions.

## Open Questions the Paper Calls Out
- Can FlowFSM be effectively integrated into protocol fuzzing frameworks to guide the fuzzing process and improve vulnerability discovery?
- How can multi-agent collaboration strategies be optimized to address FlowFSM's high computational and runtime costs?
- Does FlowFSM generalize effectively to diverse protocol families with complex or binary specifications beyond text-based standards?

## Limitations
- Limited evaluation to only two protocols (FTP and RTSP) may not generalize to more complex or less structured specifications
- Computational overhead and runtime costs associated with three-stage prompt chaining not quantified
- No evaluation of non-command-driven state transitions (timeout-based, error-driven, concurrent sessions)

## Confidence
- High confidence: Core mechanism of prompt chaining reducing hallucinations
- Medium confidence: Hierarchical RFC preprocessing effectiveness
- Low confidence: Generalizability across diverse protocol types

## Next Checks
1. Apply FlowFSM to a third protocol with different structural characteristics (e.g., HTTP or SMTP) and compare extraction accuracy against reported FTP/RTSP results
2. Conduct an ablation study by running three stages independently (without chaining) and quantify error propagation
3. Systematically vary leaf-node chunk granularity and measure impact on command coverage, transition accuracy, and hallucination rates