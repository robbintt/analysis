---
ver: rpa2
title: 'Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial
  Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation'
arxiv_id: '2507.14782'
source_url: https://arxiv.org/abs/2507.14782
tags:
- uncertainty
- input
- standard
- variables
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a Polynomial Chaos Expansion (PCE)-based\
  \ framework to jointly propagate input and model uncertainty in machine learning\
  \ (ML) surrogate models. The method transforms all random inputs\u2014including\
  \ a dedicated model uncertainty variable\u2014into a unified standard normal space,\
  \ enabling efficient construction of a single PCE surrogate."
---

# Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation

## Quick Facts
- arXiv ID: 2507.14782
- Source URL: https://arxiv.org/abs/2507.14782
- Reference count: 40
- Primary result: PCE-based framework that jointly propagates input and model uncertainty in ML surrogate models, achieving MCS-level accuracy with orders-of-magnitude fewer samples

## Executive Summary
This paper presents a Polynomial Chaos Expansion (PCE)-based framework for quantifying uncertainty in machine learning (ML) surrogate predictions by jointly propagating both input (aleatory) and model (epistemic) uncertainty. The method transforms all random inputs—including a dedicated model uncertainty variable—into a unified standard normal space, enabling efficient construction of a single PCE surrogate. Using Gaussian Process regression as a focus, the approach analytically computes output statistics (mean, standard deviation) and Sobol' sensitivity indices directly from PCE coefficients. Two numerical examples—a speed reducer shaft and a nonlinear heat transfer problem—demonstrate that the method accurately matches Monte Carlo Simulation (MCS) results with far fewer training points (e.g., 13 vs. 100,000), and clearly identifies the relative contributions of physical inputs and model uncertainty to overall output variability.

## Method Summary
The method transforms all random inputs (both physical variables and model uncertainty) into standard normal space using isoprobabilistic transformations, then constructs a PCE surrogate via collocation sampling. For each sample, the output is computed as Y = M(X) + U_Y·S(X), where M(X) is the GP predictive mean, S(X) is the GP predictive standard deviation, and U_Y is a standard normal variable representing model uncertainty. The PCE coefficients are obtained through least-squares regression, and output statistics and Sobol' sensitivity indices are computed analytically from these coefficients. The framework supports three sampling strategies: Latin Hypercube Sampling (LHS), Tensor-Product quadrature, and Smolyak sparse grids.

## Key Results
- Smolyak PCE achieves <1.3% error with only 13 points vs. 100,000 for MCS in the speed reducer example
- Sobol' indices clearly distinguish contributions: physical inputs dominate (63.7-92.2% combined) while model uncertainty contributes 7.8% in well-trained cases
- The sum of first-order Sobol' indices ≈ 1.0 validates the variance decomposition accuracy
- Framework correctly identifies increased model uncertainty contribution (up to 46.8%) when GP training data is reduced

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Uncertainty Injection via Auxiliary Variables
By representing model uncertainty as an explicit auxiliary random variable (U_Y), the framework can propagate it alongside physical input uncertainty within a single surrogate model. The paper employs a probability integral transform to decouple the model's epistemic uncertainty (represented by the GP standard deviation S(X)) from the aleatory uncertainty of inputs X. It maps both to a unified standard normal space (U_X and U_Y) where they are treated as independent dimensions. The output is reconstructed via Y = M(X) + U_Y S(X). Core assumption: The ML model provides well-calibrated predictive distributions. Break condition: If the ML model's uncertainty estimates are poorly calibrated, the auxiliary variable U_Y will not correctly represent true error distribution.

### Mechanism 2: Analytical Variance Decomposition via Orthonormal Basis
The use of orthonormal Hermite polynomials allows output variance and Sobol' sensitivity indices to be computed analytically from the PCE coefficients, avoiding integration errors. When the input space is standard normal, Probabilists' Hermite polynomials form an orthonormal basis. This allows total variance to be expressed simply as the sum of squares of non-constant coefficients (Σα_k²). Sobol' indices are then calculated by summing subsets of these squares corresponding to specific variables. Core assumption: The output response surface is sufficiently smooth to be approximated by a low-order polynomial expansion. Break condition: If the true response is highly discontinuous, coefficients will not capture full variance, leading to inaccurate sensitivity rankings.

### Mechanism 3: Dimension-Adaptive Sampling Efficiency
Smolyak sparse grids can achieve accuracy comparable to Monte Carlo Simulation (MCS) with orders of magnitude fewer samples by selectively sampling interaction terms. Unlike Tensor-Product grids which grow exponentially (N^D), Smolyak grids select a sparse subset of collocation points that preserves accuracy for lower-order interaction terms while truncating higher-order terms. This makes the "curse of dimensionality" manageable for the joint space of X + U_Y. Core assumption: Significant uncertainty contributions are primarily lower-order. Break condition: If the system exhibits strong high-order interactions (e.g., 5+ variable interactions), a low-level sparse grid will miss significant variance contributions.

## Foundational Learning

- **Concept: Gaussian Process (GP) Regression**
  - Why needed here: The method relies on the GP's specific output structure—the predictive mean M(X) and predictive standard deviation S(X). Understanding that S(X) is not just noise, but a spatial estimate of model confidence, is critical.
  - Quick check question: If a GP model is trained on very sparse data, how does S(X) typically change compared to a region with dense data?

- **Concept: Isoprobabilistic Transformation (Nataf/Rosenblatt)**
  - Why needed here: To use Hermite polynomials, all inputs (Uniform, Lognormal, Gumbel) must be mapped to standard normal space (U). Understanding this mapping is critical for transforming physical variables into the correct space.
  - Quick check question: Why is it necessary to transform physical variables (like a Lognormal force) into standard normal variables before applying Hermite polynomials?

- **Concept: Variance-Based Sensitivity Analysis (Sobol' Indices)**
  - Why needed here: The primary output for interpretability is the Sobol' index. Distinguishing between "First-Order" (main effect) and "Total-Order" (including interactions) is essential for diagnosing whether model uncertainty (U_Y) acts alone or interacts with physical inputs.
  - Quick check question: If the Total-Order index for U_Y is significantly higher than its First-Order index, what does this imply about the ML model's behavior?

## Architecture Onboarding

- **Component map:** Input Interface -> Standardizer -> Sampler -> Evaluator -> Solver -> Analyzer
- **Critical path:** The definition of the evaluation equation Y = M(X) + U_Y S(X). If the GP model S(X) is not called or scaled correctly by U_Y here, the entire uncertainty propagation fails.
- **Design tradeoffs:**
  - Sampling Method: Use LHS for robustness in unknown topologies; use Smolyak for speed in low-to-medium dimensions (D < 20); avoid Tensor-Product if D > 5
  - Polynomial Order (p_max): Start with p=2. Higher orders capture nonlinearity better but drastically increase the need for training data and numerical instability
- **Failure signatures:**
  - Sobol' Sum >> 1: Indicates numerical instability in coefficient calculation or ill-conditioned design matrix
  - Zero Sensitivity for U_Y: Likely a bug in the evaluation step where S(X) was omitted or U_Y was fixed to 0
  - High Error in Mean: Suggests the PCE polynomial order is too low to capture the GP mean function M(X)
- **First 3 experiments:**
  1. Validation Test: Run the framework on an analytical function with known variance (e.g., Ishigami) to verify Sobol' index calculation against theory
  2. Ablation on Training Size: Train the GP with 30, 100, and 500 points and plot the shift in U_Y sensitivity to build intuition for how data density translates to model certainty
  3. Sampling Comparison: For a fixed 5-dimensional problem, run Smolyak vs. LHS and plot Error vs. Number of Points to find the efficiency frontier for your specific problem class

## Open Questions the Paper Calls Out

- **Can advanced sampling techniques extend the computational efficiency of the proposed PCE framework to high-dimensional input spaces?**
  - The paper only validates the framework on low-dimensional examples (5 variables) using LHS, Tensor-Product, and Smolyak grids. Benchmarking with adaptive sparse grids on problems with >20 variables would resolve this.

- **How accurately does the framework estimate the full output probability distribution compared to moment estimation?**
  - The current study primarily validates mean and standard deviation accuracy, noting only that CDF/PDF estimation is possible. Comparative analysis of approximated tail probabilities against Monte Carlo simulations would resolve this.

- **How can the joint propagation of input and model uncertainty be leveraged to improve engineering design optimization?**
  - The paper establishes a method for analysis but does not demonstrate its application in a design synthesis loop. An optimization case study using PCE surrogate and sensitivity indices to minimize model uncertainty impact would resolve this.

## Limitations
- Method's accuracy fundamentally depends on ML model's ability to provide reliable uncertainty estimates; poorly calibrated GP uncertainty leads to incorrect output variance estimates
- Assumes error can be modeled as additive Gaussian noise scaled by S(X), which may not hold for all ML architectures
- While Smolyak sparse grids are efficient for low-to-medium dimensions (D < 20-30), scalability for problems with many uncertain inputs remains untested

## Confidence
- **High confidence**: Core mathematical framework (PCE construction, variance decomposition, Sobol' index calculation from coefficients) is well-established and correctly applied
- **Medium confidence**: Specific implementation details for GP model (kernel choice, hyperparameter training) and exact Smolyak sparse grid parameters are not fully specified
- **Medium confidence**: Claim that framework generalizes beyond GP to other ML models is plausible but not demonstrated; additive error model must be adapted for each model type

## Next Checks
1. **Calibration Test**: Systematically vary the training data size for the GP (e.g., 30, 100, 500 points) and verify that the U_Y Sobol' index increases as expected when the model is less certain
2. **Robustness to GP Architecture**: Replace the GP with a different ML model (e.g., Random Forest with quantile regression, or a Bayesian Neural Network) and verify that the PCE surrogate can still be constructed and that the U_Y contribution is meaningful
3. **High-Order Interaction Detection**: Construct a test problem where output variance is dominated by 4+ variable interactions and verify whether the Smolyak PCE with p=2 can capture this, or if the method fails as predicted by the dimensionality limitation