---
ver: rpa2
title: Robust Learning of Diffusion Models with Extremely Noisy Conditions
arxiv_id: '2510.10149'
source_url: https://arxiv.org/abs/2510.10149
tags:
- diffusion
- learning
- noise
- noisy
- condition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a robust learning framework to address extremely
  noisy conditions in conditional diffusion models. The core method idea involves
  learning pseudo conditions as surrogates for clean conditions and refining them
  progressively via temporal ensembling.
---

# Robust Learning of Diffusion Models with Extremely Noisy Conditions

## Quick Facts
- **arXiv ID:** 2510.10149
- **Source URL:** https://arxiv.org/abs/2510.10149
- **Reference count:** 40
- **Primary result:** Introduces a robust learning framework for conditional diffusion models under extreme noise, achieving >10% better performance than SOTA on image generation and significant improvements on visuomotor policy generation.

## Executive Summary
This paper addresses the challenge of training conditional diffusion models when input conditions are extremely noisy. The authors propose a framework that learns pseudo conditions as clean surrogates for noisy labels and refines them progressively using temporal ensembling. They introduce a Reverse-time Diffusion Condition (RDC) technique that diffuses pseudo conditions in reverse time relative to the data, enhancing the memorization effect and stabilizing training at high noise levels. The method demonstrates state-of-the-art performance across various noise levels on both class-conditional image generation (CIFAR-10/100) and visuomotor policy generation (Push-T dataset).

## Method Summary
The method combines two core mechanisms: pseudo condition refinement via temporal ensembling and reverse-time diffusion condition (RDC). Pseudo conditions are initialized as zero vectors or encoder embeddings and refined using a lightweight prediction head attached to the U-Net encoder. The pseudo conditions are updated via exponential moving average (EMA) with momentum α=0.1. RDC diffuses the pseudo conditions using modified stochastic differential equations where the condition follows a reverse-time process relative to the data. The training objective combines the standard diffusion loss with a condition prediction loss. Early stopping is applied to freeze pseudo condition updates when performance peaks, empirically determined at 25k iterations for CIFAR-10.

## Key Results
- Achieves >10% better performance than current SOTA model on all class-wise metrics for image generation across various noise levels
- Demonstrates significant improvements over baseline method on the Push-T dataset for visuomotor policy generation
- Ablation shows RDC is necessary for stability (PC alone harms performance: CW-FID 30.45 → 37.09)
- Maintains performance on 60% symmetric noise in CIFAR-100 where baselines fail

## Why This Works (Mechanism)

### Mechanism 1: Pseudo Condition Refinement via Temporal Ensembling
- **Claim:** Replacing static noisy conditions with dynamically refined "pseudo conditions" mitigates entanglement of noisy clusters during early training
- **Mechanism:** Initializes pseudo conditions as zero vector or encoder embedding, predicts target condition using lightweight head, updates via EMA: $\hat{y} = \alpha\hat{y} + (1-\alpha)\hat{y}_\phi$
- **Core assumption:** Memorization effect holds - networks fit clean patterns before noisy ones
- **Break condition:** High learning rate or low momentum causes fluctuation or overfitting to noise

### Mechanism 2: Reverse-time Diffusion Condition (RDC)
- **Claim:** Diffusing pseudo conditions in "reverse time" relative to data stabilizes score estimation at high noise levels
- **Mechanism:** At $t=T$, condition is structured pseudo-clean $\hat{y}$ rather than noise, reducing estimation error when data is pure noise
- **Core assumption:** Structured condition at high noise levels acts as condition augmentation reinforcing memorization
- **Break condition:** Mismatched diffusion schedules or SDE coefficients cause instability

## Foundational Learning

- **Concept: Classifier-Free Guidance (CFG)**
  - **Why needed here:** Framework relies on CFG to embed conditions, swapping noisy $\tilde{y}$ for pseudo condition $\hat{y}$ in score estimator
  - **Quick check question:** How does unconditional score interact with conditional score in CFG formula?

- **Concept: Memorization Effect in Noisy Labels**
  - **Why needed here:** Refinement strategy depends on phenomenon where DNNs prioritize learning clean patterns before memorizing noisy outliers
  - **Quick check question:** At what epoch/iteration does model typically transition from "learning" to "memorizing" noise?

- **Concept: Stochastic Differential Equations (SDEs)**
  - **Why needed here:** RDC requires understanding modified SDEs where drift and diffusion coefficients are inverted for reverse-time process
  - **Quick check question:** How does drift coefficient $f(\hat{y}, t)$ dictate direction of diffusion process in RDC formulation?

## Architecture Onboarding

- **Component map:** Dataset $(x, \tilde{y})$ -> Pseudo condition buffer $\hat{y}$ -> RDC sampler -> U-Net with condition $\hat{y}_t$ -> Prediction head $q_\phi$ -> EMA update of $\hat{y}$

- **Critical path:**
  1. Fetch noisy pair $(x, \tilde{y})$ and current pseudo condition $\hat{y}$
  2. Apply RDC to generate $\hat{y}_t$
  3. Forward pass U-Net with $x_t$ and $\hat{y}_t$
  4. Prediction head estimates $\hat{y}_\phi$
  5. Update stored $\hat{y}$ via EMA
  6. Early stopping: Freeze updates when validation performance peaks

- **Design tradeoffs:**
  - Stability vs. Staleness: High EMA momentum stabilizes $\hat{y}$ but slows correction of initial errors
  - Complexity: RDC adds computational overhead compared to simple embedding

- **Failure signatures:**
  - Underfitting: Vanilla model fails to disentangle clusters
  - Performance Collapse: Existing noise-robust methods fail at >60% noise
  - Overfitting: If early stopping missed, pseudo conditions decay back to noisy distribution

- **First 3 experiments:**
  1. **2-D Toy Case:** Visualize 4-class clusters; verify method separates entangled classes better than TDSM at 60-80% noise
  2. **Ablation on RDC:** Compare "Pseudo Condition only" vs. "PC + RDC" on CIFAR-10; confirm PC alone harms performance (CW-FID 30.45 → 37.09)
  3. **High-Noise CIFAR-100:** Train on 60% symmetric noise; verify method runs without collapse and achieves CW-FID < 110

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can optimal early stopping point for pseudo-condition refinement be determined theoretically rather than empirically?
- **Basis:** Section 3.1.1 states early stopping is "empirically applied," with varying iteration counts for different datasets
- **Why unresolved:** Relies on manual tuning for different noise types and datasets
- **What evidence would resolve it:** Theoretical derivation connecting noise levels or dataset characteristics to convergence rate of memorization effect

### Open Question 2
- **Question:** Does RDC theoretically improve estimation of clean conditions over standard forward diffusion?
- **Basis:** Section 3.1.2 claims RDC reduces estimation difficulty at $t=T$ but remains intuitive justification
- **Why unresolved:** Validates utility empirically through ablation but lacks theoretical bound for superiority
- **What evidence would resolve it:** Theoretical analysis comparing variance of gradient estimators between reverse-time and standard formulations

### Open Question 3
- **Question:** Is framework effective for discrete or structured conditions in text-to-image generation?
- **Basis:** Introduction identifies text generation as key area, but experiments restricted to class labels and visual observations
- **Why unresolved:** Prediction head architecture tailored for continuous embeddings or indices, potentially struggling with discrete token sequences
- **What evidence would resolve it:** Experimental results on large-scale text-conditional datasets like MS-COCO

## Limitations

- Performance gains primarily demonstrated on controlled synthetic noise settings, raising questions about real-world noise patterns
- RDC mechanism's effectiveness relies on precise synchronization between data and condition diffusion schedules
- Ablation showing PC alone harming performance suggests full method is necessary but doesn't explain why PC mechanism is insufficient without RDC

## Confidence

- **High Confidence:** 2-D toy visualization results demonstrating cluster separation improvement over TDSM at 60-80% noise levels
- **Medium Confidence:** CIFAR-10/100 performance improvements, particularly >10% gains across all class-wise metrics
- **Low Confidence:** Push-T visuomotor policy generation results, as method's effectiveness on continuous control tasks is less established

## Next Checks

1. **Prediction Head Specification:** Implement exact prediction head architecture with specified convolutional layer dimensions and kernel sizes, then reproduce CIFAR-10 ablation results to confirm PC alone indeed harms performance before RDC application

2. **RDC Numerical Stability:** Test RDC solver with varying step sizes and NFE values across different noise levels to identify minimum requirements for stable training, particularly addressing division-by-zero concerns near t=0

3. **Real-World Noise Generalization:** Apply method to dataset with naturally occurring label noise (e.g., WebVision) and compare against TDSM and other robust diffusion baselines to validate performance beyond synthetic corruption patterns