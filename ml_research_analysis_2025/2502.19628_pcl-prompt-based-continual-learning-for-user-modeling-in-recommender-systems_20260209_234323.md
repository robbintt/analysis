---
ver: rpa2
title: 'PCL: Prompt-based Continual Learning for User Modeling in Recommender Systems'
arxiv_id: '2502.19628'
source_url: https://arxiv.org/abs/2502.19628
tags:
- task
- tasks
- user
- prompts
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PCL, a prompt-based continual learning framework
  for user modeling in recommender systems. The key innovation is using position-wise
  prompts as external memory to mitigate catastrophic forgetting during sequential
  task learning, while contextual prompts capture inter-task relationships via attention
  mechanisms.
---

# PCL: Prompt-based Continual Learning for User Modeling in Recommender Systems

## Quick Facts
- arXiv ID: 2502.19628
- Source URL: https://arxiv.org/abs/2502.19628
- Reference count: 26
- Key outcome: PCL outperforms single-task and multi-task baselines across two real-world datasets, achieving the best performance in 6 out of 8 tasks.

## Executive Summary
This paper proposes PCL, a prompt-based continual learning framework for user modeling in recommender systems. The key innovation is using position-wise prompts as external memory to mitigate catastrophic forgetting during sequential task learning, while contextual prompts capture inter-task relationships via attention mechanisms. PCL demonstrates robustness to task ordering, excels with cold-start items, and generates universal user representations applicable to unseen models.

## Method Summary
PCL freezes a pretrained SASRec backbone and item embeddings, then introduces task-specific position-wise prompts fused with the last t item embeddings via element-wise addition. For each new downstream task, it uses sequential prompt initialization (copying the previous task's prompt) and adds contextual prompts generated from task descriptions via a frozen PLM and attention mechanism. The framework trains only the prompts and task adapters, preserving the frozen backbone knowledge.

## Key Results
- PCL outperforms single-task and multi-task baselines across Tenrec and MovieLens datasets
- Achieves best performance in 6 out of 8 tasks
- Demonstrates robustness to task ordering (Figure 2)
- Excels with cold-start items through frozen item embeddings
- Generates universal user representations applicable to unseen models

## Why This Works (Mechanism)

### Mechanism 1
**Claim:** Mitigating catastrophic forgetting by isolating task knowledge in external prompt memory rather than model weights.
**Mechanism:** Freezes the SASRec backbone after pretraining on next-item prediction. For each new task, introduces position-wise prompts fused with the last t item embeddings, creating task-specific "lenses" without modifying weights.
**Core assumption:** The frozen backbone captures sufficiently generic user behavior patterns that can be adapted to heterogeneous tasks solely through input-space perturbations.
**Evidence anchors:** Abstract mentions "position-wise prompts as external memory for each task, preserving knowledge and mitigating catastrophic forgetting"; Section 3.1 describes the fusion operation.
**Break condition:** Performance degrades if the backbone lacks capacity to represent new tasks, as prompts cannot modify the frozen feature space fundamentally.

### Mechanism 2
**Claim:** Enhancing task adaptation by injecting semantic inter-task relationships into the prompt space.
**Mechanism:** Generates contextual prompts by encoding task descriptions using a frozen PLM, then applying multi-head attention to learn relationships between task embeddings.
**Core assumption:** Semantic similarity of task descriptions correlates with functional transferability in the recommendation space.
**Evidence anchors:** Abstract mentions "contextual prompts to capture and leverage inter-task relationships"; Section 3.2 describes the attention mechanism.
**Break condition:** If task descriptions are ambiguous or fail to capture underlying functional logic, the attention mechanism may learn spurious correlations.

### Mechanism 3
**Claim:** Enabling knowledge transfer via sequential prompt initialization.
**Mechanism:** Initializes the current task's prompt using the optimized prompt from the previous task, creating a chain of knowledge evolution.
**Core assumption:** Adjacent tasks share some latent structure, making the previous task's prompt a better initialization point than random noise.
**Evidence anchors:** Section 3.3 states "prompts p_k are initialized as p_{k-1}, which is the optimized prompt for the previous task."
**Break condition:** In scenarios of "negative transfer," initializing with p_{k-1} could bias the model into a local minimum far from the optimal solution for the new task.

## Foundational Learning
- **Concept:** Catastrophic Forgetting
  - **Why needed here:** This is the central problem PCL solves - understanding this explains why the frozen backbone + external prompt architecture is necessary.
  - **Quick check question:** Why can't we just fine-tune the SASRec model sequentially on every new task?
- **Concept:** Prompt Tuning (Soft Prompts)
  - **Why needed here:** PCL applies this NLP technique to recommendation - these are learned continuous vectors, not discrete text instructions, inserted into the embedding layer.
  - **Quick check question:** Are the "prompts" in PCL human-readable text descriptions or learnable tensor parameters?
- **Concept:** Self-Attentive Sequential Recommendation (SASRec)
  - **Why needed here:** SASRec is the specific backbone used - understanding it uses a Transformer architecture to model user behavior sequences is necessary to comprehend where prompts are injected.
  - **Quick check question:** In the PCL architecture, are the prompts injected before or after the SASRec encoder layers?

## Architecture Onboarding
- **Component map:** Input Layer (User Behavior Sequence + Item Embeddings) -> Prompt Module (Position-wise Prompts + Contextual Prompts) -> Fusion Operation (Element-wise addition) -> Frozen SASRec Backbone -> Task Adapter (Linear/MLP)
- **Critical path:** Pretrain Backbone on T1 -> Freeze -> For Task T_k: Initialize Prompt p_k with p_{k-1} -> Fuse p_k with input sequence -> Train only p_k and Task Adapter
- **Design tradeoffs:**
  - **Plasticity vs. Stability:** Freezing the backbone maximizes stability (zero forgetting on T1 features) but sacrifices plasticity (cannot learn new fundamental item correlations)
  - **Memory vs. Capacity:** Prompts consume |T| × n × d memory - efficient compared to full model checkpoints per task but grows linearly with task count
- **Failure signatures:**
  - **Task Interference:** Misconfigured contextual prompts may shift embedding distribution outside backbone's training distribution, causing outputs to degrade into noise
  - **Cold-Start Collapse:** If backbone lacks diverse item distributions during pretraining, prompts fail to adapt to cold-start items
- **First 3 experiments:**
  1. **Sanity Check (Prompt Injection):** Run "FineAll" baseline vs. PCL on single downstream task - verify PCL achieves comparable accuracy with fewer trainable parameters
  2. **Ablation (Context vs. Position):** Isolate contextual prompt contribution by training with only position-wise prompts - check performance delta in Table 2
  3. **Robustness Test:** Shuffle task order (as in Figure 2) to ensure performance doesn't collapse when initialization chain is broken

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- **Unknown hyperparameter settings:** Critical details like embedding dimension, prompt fusion window, prompting intensity, attention head count, and learning rate schedules are unspecified
- **Dataset processing specifics:** Exact method for constructing user behavior sequences and handling cold-start items is not detailed
- **Evaluation protocol ambiguity:** The distinction between "all-ranking" and "batch-ranking" evaluation is mentioned but not defined

## Confidence
- **High Confidence:** The fundamental mechanism of using frozen backbones with external prompt memory to mitigate catastrophic forgetting is well-supported
- **Medium Confidence:** The claim that contextual prompts enhance performance by capturing inter-task relationships is supported by ablation results
- **Medium Confidence:** The assertion that PCL generates "universal user representations applicable to unseen models" is logically sound but not empirically validated

## Next Checks
1. **Ablation Study:** Replicate the "w/o PT" and "w/o PLM" ablations from Table 2 to verify position-wise and contextual prompts independently contribute to performance gains
2. **Order Sensitivity Test:** Systematically permute the task sequence order to assess robustness of the sequential prompt initialization mechanism
3. **Cold-Start Evaluation:** Design controlled experiment isolating cold-start items to empirically validate the claim that PCL "excels with cold-start items"