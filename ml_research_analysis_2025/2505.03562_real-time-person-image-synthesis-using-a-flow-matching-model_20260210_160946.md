---
ver: rpa2
title: Real-Time Person Image Synthesis Using a Flow Matching Model
arxiv_id: '2505.03562'
source_url: https://arxiv.org/abs/2505.03562
tags:
- image
- flow
- matching
- pose
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Real-Time Person Image Synthesis using a Flow
  Matching Model (RPFM), addressing the challenge of slow sampling speeds in diffusion-based
  pose-guided person image synthesis methods. The authors introduce a transformer-based
  flow matching model that operates in latent space using conditional generation,
  achieving near-real-time performance while maintaining image quality comparable
  to state-of-the-art models.
---

# Real-Time Person Image Synthesis Using a Flow Matching Model

## Quick Facts
- arXiv ID: 2505.03562
- Source URL: https://arxiv.org/abs/2505.03562
- Authors: Jiwoo Jeong; Kirok Kim; Wooju Kim; Nam-Joon Kim
- Reference count: 37
- One-line primary result: Achieves near-real-time inference (0.489s) for pose-guided person image synthesis while maintaining quality comparable to diffusion-based models.

## Executive Summary
This paper introduces Real-Time Person Image Synthesis using a Flow Matching Model (RPFM), addressing the critical bottleneck of slow sampling speeds in diffusion-based pose-guided person image synthesis. The authors propose a transformer-based flow matching model operating in latent space that achieves over twofold faster inference than state-of-the-art diffusion models while maintaining comparable image quality. By leveraging deterministic ODE-based sampling and dual conditioning mechanisms, RPFM enables practical real-time applications such as sign language video generation.

## Method Summary
RPFM operates in latent space using a DiT (Diffusion Transformer) backbone that predicts velocity fields for flow matching. The model employs input concatenation to merge noisy latents, source image latents, and target pose latents, while conditional aggregation fuses local and global features from both source and pose through self- and cross-attention. Training uses the Conditional Optimal Transport path with MSE loss between predicted and optimal transport flow. The approach achieves real-time speed through deterministic ODE sampling and efficient latent-space operation, with inference accelerated by reducing the number of function evaluations (NFE).

## Key Results
- Achieves 0.489s inference time at 512×512 resolution, over twofold faster than X-MDPT (1.121s)
- Maintains comparable image quality: FID 8.522 vs 7.162, LPIPS 0.1786 vs 0.1645, with higher SSIM 0.7742 vs 0.7522
- Medium DiT model outperforms large DiT model on FID despite typical scaling laws
- Successfully generates pose-aligned images while preserving source appearance in real-time applications

## Why This Works (Mechanism)

### Mechanism 1: Deterministic ODE-based Sampling
Flow matching achieves faster sampling than diffusion by using deterministic Ordinary Differential Equation (ODE) paths instead of Stochastic Differential Equations (SDEs). This allows a numerical ODE solver to reach the target with fewer neural network evaluations (NFE), accelerating sampling. The learned velocity field defines a direct trajectory from initial noise to target image.

### Mechanism 2: Dual Conditioning for Pose and Appearance
Combining input concatenation with multi-scale conditional aggregation effectively guides the model to preserve source appearance while adopting the target pose. Input concatenation merges latents for direct spatial alignment, while conditional aggregation fuses local and global features via transformer-based attention to provide high-level semantic guidance.

### Mechanism 3: Latent Space Operation with DiT Backbone
Operating in low-dimensional latent space with a DiT backbone is more computationally efficient than pixel-space or U-Net-based approaches. A pre-trained VAE compresses images into 32×32×4 latents, reducing computational cost per function evaluation. The authors choose DiT over U-Net based on prior work showing transformers offer faster inference.

## Foundational Learning

### Concept: Continuous Normalizing Flows (CNFs) & Flow Matching
Why needed: This is the core generative framework replacing diffusion. Understanding it is essential to grasp how the model learns a trajectory from noise to data.
Quick check: How does the training objective in Eq. 4 (flow matching) fundamentally differ from a typical denoising score-matching objective in diffusion?

### Concept: Pose-Guided Person Image Synthesis (PGPIS)
Why needed: This defines the task, its inputs (source image, target pose), and inherent challenges like occlusion handling and appearance preservation.
Quick check: Given a source image of a person facing forward and a target pose showing their back, what specific challenge must the model overcome?

### Concept: Variational Autoencoder (VAE) for Latent Representation
Why needed: The model operates entirely within the compressed latent space of a VAE to achieve real-time speed.
Quick check: What is the spatial dimensionality of the latent representation for a 256×256 input image in this architecture, and why does this lead to faster computation?

## Architecture Onboarding

### Component map
VAE Encoder -> DINOv2 Encoders -> Input Concatenation -> Conditional Aggregation -> DiT -> ODE Solver -> VAE Decoder

### Critical path
1. Encode source and pose images using VAE encoder
2. Extract global embeddings from source and pose using DINOv2
3. Concatenate current noisy latent, source latent, and pose latent
4. Aggregate four condition vectors (local/global source/pose) via self- and cross-attention
5. DiT predicts velocity field dz/dt
6. ODE solver evolves noise z0 into target latent z1
7. Decode resulting z1 to produce output image

### Design tradeoffs
- Speed vs. Quality: Managed by NFE; lower NFE = faster speed but slightly worse FID (8.522 vs. SOTA 7.162)
- Model Size vs. Performance: Medium DiT sometimes outperforms large model, suggesting potential overfitting or suboptimal hyperparameters

### Failure signatures
- Detail Loss: Blurring of clothing textures due to VAE compression
- Occlusion Artifacts: Incorrect inference of unseen body parts leading to inconsistent patterns
- Color/Pattern Drift: Minor shifts in color or pattern alignment

### First 3 experiments
1. Reproduce Inference Speed Benchmark: Run medium model with NFE=65 on A100 GPU with batch size 8 to verify 0.489s inference time against X-MDPT baseline
2. Ablation Study on Conditioning: Retrain model removing Input Concatenation and Conditional Aggregation separately to confirm their contribution to LPIPS and SSIM
3. Classifier-Free Guidance (CFG) Sweep: Generate samples using CFG scales 1.0-1.4 to observe fidelity-diversity tradeoff and validate optimal setting of 1.1

## Open Questions the Paper Calls Out

### Open Question 1
Why does the medium-sized DiT-based model achieve a superior FID score compared to the large-sized model in this flow matching framework? The authors state a more in-depth analysis is required to understand this counterintuitive result that contradicts typical scaling laws.

### Open Question 2
How does the speed-performance trade-off manifest across a broader range of Number of Function Evaluations (NFE) beyond the specific real-time target? The authors admit they did not explore the model's speed and performance trade-offs across a broader range of NFEs.

### Open Question 3
Can flow matching architectures be modified to fully preserve fine details (e.g., clothing patterns) without sacrificing their speed advantage? The authors conclude that the challenge of fully preserving the fine details of the source image persists as an unresolved issue.

## Limitations
- Detail Loss: VAE compression to 32×32×4 latents inevitably causes loss of fine textures and small patterns
- Occlusion Handling: Model struggles with extreme occlusion scenarios where source information is unavailable
- Speed-Quality Tradeoff: Achieving real-time speed requires accepting slightly worse FID scores compared to slower diffusion models

## Confidence

- **High Confidence**: Core mechanism of flow matching achieving faster sampling than diffusion through deterministic ODE paths
- **Medium Confidence**: Dual conditioning approach's effectiveness in preserving identity while adapting to new poses
- **Medium Confidence**: Speed-quality tradeoff being acceptable for real-time applications based on authors' judgment

## Next Checks

1. Verify Inference Speed: Reproduce the 0.489s inference time benchmark using medium model with NFE=65 on A100 GPU with batch size 8, comparing directly against X-MDPT

2. Confirm Conditioning Contributions: Conduct ablation experiments removing input concatenation and conditional aggregation separately to validate their impact on LPIPS and SSIM metrics

3. Analyze CFG Sweep Impact: Generate samples across CFG scales (1.0-1.4) to empirically determine optimal balance between fidelity (SSIM) and quality (FID), validating choice of 1.1 as optimal setting