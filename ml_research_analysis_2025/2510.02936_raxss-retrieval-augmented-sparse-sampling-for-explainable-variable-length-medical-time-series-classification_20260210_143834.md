---
ver: rpa2
title: 'RAxSS: Retrieval-Augmented Sparse Sampling for Explainable Variable-Length
  Medical Time Series Classification'
arxiv_id: '2510.02936'
source_url: https://arxiv.org/abs/2510.02936
tags:
- series
- time
- window
- arxiv
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RAxSS introduces retrieval-augmented sparse sampling for variable-length
  medical time series classification. By weighting window predictions using within-series
  similarity and aggregating in probability space, the method achieves convex series-level
  scores and provides explicit evidence trails for explainability.
---

# RAxSS: Retrieval-Augmented Sparse Sampling for Explainable Variable-Length Medical Time Series Classification

## Quick Facts
- arXiv ID: 2510.02936
- Source URL: https://arxiv.org/abs/2510.02936
- Reference count: 40
- Primary result: AUC 0.8046, F1 0.7275, accuracy 70.51% on multicenter iEEG for seizure onset zone localization

## Executive Summary
RAxSS introduces retrieval-augmented sparse sampling for variable-length medical time series classification. By weighting window predictions using within-series similarity and aggregating in probability space, the method achieves convex series-level scores and provides explicit evidence trails for explainability. Evaluated on a multicenter iEEG dataset for seizure onset zone localization, RAxSS attains strong performance metrics and offers practitioners both robust performance and interpretable attributions.

## Method Summary
RAxSS extends Stochastic Sparse Sampling (SSS) by incorporating within-series retrieval to weight window predictions. The method samples windows length-proportionally from variable-length recordings, computes similarity (Pearson or cosine) between each window and its top-m neighbors within the same channel, and aggregates predictions using softmax-weighted probabilities. This produces convex series-level scores with faithful explanations derived from the similarity-based weighting mechanism. The framework uses a PatchTST backbone and is evaluated on multicenter iEEG data for seizure onset zone localization.

## Key Results
- AUC: 0.8046
- F1: 0.7275
- Accuracy: 70.51%
- Outperforms or matches strong baselines on multicenter iEEG dataset
- Provides explicit evidence trails for explainability through retrieval weights

## Why This Works (Mechanism)

### Mechanism 1
Weighting window predictions by within-series similarity improves robustness to noise compared to uniform averaging. The algorithm computes support scores based on average similarity to top-m neighbors within the same recording, using softmax normalization to create aggregation weights that amplify segments with high internal consistency. This assumes informative pathological patterns exhibit higher temporal redundancy than noise.

### Mechanism 2
Aggregating predictions in probability space ensures convex series-level scores, providing a mathematically grounded basis for explainability. By averaging class probabilities rather than logits or features, the output is constrained to the probability simplex, assuming reasonably calibrated backbone probabilities.

### Mechanism 3
Deriving explanation weights from the aggregation mechanism provides faithful attributions by linking influence directly to similarity. Because the weight is strictly increasing with neighbor similarity, the ranked neighbor list serves as direct explanation for a window's contribution, assuming similarity implies relevance.

## Foundational Learning

- **Concept: Stochastic Sparse Sampling (SSS)**
  - Why needed: RAxSS is built on SSS; understand length-proportional sampling vs padding/truncating
  - Quick check: How does sampling probability change if a recording doubles in length?

- **Concept: Softmax Temperature (τ)**
  - Why needed: Controls sharpness of retrieval weights; understand τ→0 (hard selection) vs τ→∞ (uniform averaging)
  - Quick check: What happens to weight distribution if τ is set very high?

- **Concept: Convex Combination**
  - Why needed: Output is a convex combination of window probabilities; understand weights must sum to 1, output must be valid probability
  - Quick check: If weights sum to 1.1 due to bug, does output remain valid probability distribution?

## Architecture Onboarding

- **Component map:** Input: Variable-length Time Series → Windowing: Length-proportional Sampling → Backbone: PatchTST for local features → Retrieval: Compute pairwise similarity within same channel → Aggregator: Softmax weighting based on similarity → Output: Series-level Probability

- **Critical path:** Within-series retrieval step (computing similarity of current window to all other windows in same channel to find top-m) is primary computational addition compared to standard SSS

- **Design tradeoffs:**
  - Cosine vs. Pearson: Cosine optimizes for AUC, Pearson optimizes F1/Accuracy
  - Within vs. Cross-series Retrieval: Current restricts to same channel for privacy, sacrificing potential cross-patient knowledge transfer

- **Failure signatures:**
  - Uniform Weights: If α_k is flat for all windows, retrieval failed (likely τ too high or similarity constant), degrading to standard SSS
  - Dominant Noise: If repetitive artifact exists, it will have high similarity to itself, potentially dominating aggregation weights

- **First 3 experiments:**
  1. Sanity Check (Uniform vs. Weighted): Set τ→∞ to reproduce baseline SSS, verify RAxSS provides delta
  2. Neighbor Ablation (m): Vary number of neighbors to see if performance relies on local vs global consistency
  3. Similarity Metric Swap: Swap Pearson for Cosine to confirm AUC vs F1 trade-offs on your data subset

## Open Questions the Paper Calls Out

- **Cross-center retrieval expansion:** Can retrieval mechanism be expanded to cross-center or cross-subject repositories to improve evidence quality without compromising generalizability or privacy? Current implementation restricts to within-series for privacy preservation.

- **Learnable similarity parameters:** Can similarity function and temperature hyperparameters be learned directly from data rather than manually specified? Current relies on fixed choices for similarity and static temperature.

- **Explanation faithfulness validation:** How robust is explanation leaderboard when subjected to quantitative faithfulness stress tests? Current lacks comprehensive deletion/insertion tests and counterfactual probes.

## Limitations
- Similarity-based weighting assumes informative patterns exhibit higher temporal redundancy than noise, which may not hold for all medical time series
- Exact temperature parameter (τ) for softmax weighting is unspecified, limiting exact reproduction
- Framework assumes well-calibrated backbone probabilities; poor calibration could undermine theoretical guarantees

## Confidence
- **High confidence:** Mathematical framework for convex aggregation and SSS extension are well-defined and reproducible
- **Medium confidence:** Empirical performance claims supported but exact reproduction limited by unspecified hyperparameters and pending public release
- **Low confidence:** Generalizability to other datasets with different signal characteristics remains uncertain without broader validation

## Next Checks
1. Sanity Check (Uniform vs. Weighted): Set τ→∞ to reproduce baseline SSS, verify RAxSS provides delta
2. Neighbor Ablation (m): Vary number of neighbors to see if performance relies on local vs global consistency
3. Similarity Metric Swap: Swap Pearson for Cosine to confirm AUC vs F1 trade-offs on your data subset