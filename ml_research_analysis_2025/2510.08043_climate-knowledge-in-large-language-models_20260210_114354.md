---
ver: rpa2
title: Climate Knowledge in Large Language Models
arxiv_id: '2510.08043'
source_url: https://arxiv.org/abs/2510.08043
tags:
- climate
- temperature
- llms
- mean
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates the capacity of large language models (LLMs)\
  \ to recall location-specific climate normals from parametric knowledge without\
  \ external retrieval. We construct a global grid of 15,395 land points at 1\xB0\
  \ resolution and query LLMs for mean July 2-m air temperature (1991-2020) using\
  \ standardized natural language prompts."
---

# Climate Knowledge in Large Language Models

## Quick Facts
- arXiv ID: 2510.08043
- Source URL: https://arxiv.org/abs/2510.08043
- Authors: Ivan Kuznetsov; Jacopo Grassi; Dmitrii Pantiukhin; Boris Shapkin; Thomas Jung; Nikolay Koldunov
- Reference count: 40
- Primary result: LLMs encode non-trivial climate structure, capturing latitudinal and topographic patterns, with global RMSE of 3-6 °C and biases of ±1 °C

## Executive Summary
This study evaluates large language models' capacity to recall location-specific climate normals from parametric knowledge without external retrieval. Using a global 1° land grid and ERA5 reanalysis as ground truth, the research demonstrates that LLMs can encode meaningful climate structure including latitudinal and topographic patterns, though performance degrades sharply at high elevations. Geographic context significantly improves accuracy, reducing errors by 27% on average. While models capture global warming magnitude, they fail to reproduce spatial patterns of temperature change, revealing fundamental limitations in parametric climate knowledge representation.

## Method Summary
The study constructs a global grid of 15,395 land points at 1° resolution and queries LLMs for mean July 2-m air temperature (1991-2020) using standardized natural language prompts. Model responses are validated against ERA5 reanalysis data through zero-shot prompting with 10 independent queries per location. The evaluation framework computes RMSE and bias metrics, stratifies results by elevation, and tests the impact of geographic context through reverse geocoding. Temperature sampling parameter is varied between default and 0.3 to assess output consistency.

## Key Results
- LLMs encode non-trivial climate structure, capturing latitudinal and topographic patterns, with global RMSE of 3-6 °C and biases of ±1 °C
- Performance degrades sharply above 1500 m elevation (RMSE 5-13 °C vs 2-4 °C at lower elevations)
- Including geographic context (country, city, region) reduces errors by 27% on average
- Models capture global warming magnitude between 1950-1974 and 2000-2024 but fail to reproduce spatial patterns of temperature change

## Why This Works (Mechanism)

### Mechanism 1: Statistical Pattern Storage and Recall
LLMs store climate information as statistical patterns from training corpora, enabling approximate recall of climate normals without external data. During pretraining, models encounter geographic-climatic associations in text (e.g., "Sahara is hot," "Antarctica is cold") that are compressed into weight representations. Queries retrieve values by pattern-matching to stored statistical associations rather than accessing a lookup table.

### Mechanism 2: Geographic Context as Retrieval Cue Enhancement
Place names activate richer semantic associations than raw coordinates, improving recall accuracy. LLMs form stronger associations between named locations and climatic descriptors during training. Place names serve as higher-probability retrieval keys activating more relevant weight regions; coordinates lack this associative density.

### Mechanism 3: Elevation-Dependent Representation Gap
High-altitude regions suffer systematic errors due to sparse training signal and lack of explicit temperature-elevation physical relationships. Mountain climates are underrepresented in general corpora. The lapse rate relationship is rarely stated explicitly; models cannot infer physical rules they weren't trained on, leading to systematic warm biases at altitude.

## Foundational Learning

- **Concept: Parametric Knowledge vs. Retrieval-Augmented Generation**
  - Why needed here: The study evaluates closed-book performance where models rely solely on weights; understanding this distinction is critical for interpreting what the benchmark measures
  - Quick check question: Why does excluding external retrieval isolate "what the model knows" versus "what the model can find"?

- **Concept: Climate Normals and Reanalysis Data**
  - Why needed here: ERA5 reanalysis serves as ground truth for 1991-2020 climatological means; understanding its role validates the evaluation framework
  - Quick check question: What makes ERA5 appropriate as a benchmark reference, and what are its limitations?

- **Concept: Sampling Temperature Parameter**
  - Why needed here: The study tests temperature=0.3 vs. defaults; this parameter affects output determinism and may influence recall precision
  - Quick check question: How does lowering sampling temperature affect the tradeoff between consistency and exploration in model outputs?

## Architecture Onboarding

- **Component map:**
  - Grid Generator -> Reverse Geocoder -> Prompt Templates -> Query Engine -> Validation Layer -> Spatial Smoothing

- **Critical path:**
  1. Generate coordinate grid → 2. Extract ERA5 ground truth → 3. Reverse geocode for context → 4. Query LLM (10× per location) → 5. Aggregate responses (mean) → 6. Compute point-wise metrics → 7. Stratify by elevation/region

- **Design tradeoffs:**
  - Resolution: 1° balances cost and coverage; finer grids increase queries ~100×
  - Aggregation: Mean of 10 responses reduces sampling noise; median would be more outlier-robust
  - Zero-shot only: Isolates parametric knowledge but may underestimate capability with prompting techniques

- **Failure signatures:**
  - High-altitude warm bias: >5°C systematic overprediction above 2500m
  - Spatially coherent regional errors (e.g., GPT-5 cold bias in central Asia)
  - Near-zero correlation with observed temperature trends (temporal pattern failure)
  - Domain-specific fine-tuning failure: ClimateGPT 70B shows worst RMSE (10.20°C)

- **First 3 experiments:**
  1. Reproduce baseline on a 500-point subset with one model family to validate pipeline and establish personal benchmark
  2. Ablate geographic context: compare full address vs. coordinates-only vs. region-only to quantify cue contribution per elevation band
  3. Extend to January temperature or precipitation to assess generalization across seasons and variables

## Open Questions the Paper Calls Out

### Open Question 1
Does domain-specific fine-tuning on climate text improve or impair numeric climate recall, and what training interventions could enhance parametric climate knowledge? The authors note that eci-io-climategpt 70B, a specialized climate model, showed the poorest performance (RMSE 10.20 °C), suggesting that domain-specific fine-tuning on textual climate content does not necessarily improve numeric climate recall.

### Open Question 2
Do findings generalize to other climate variables (precipitation, wind, extremes) and across all months, or is temperature in July a best-case scenario? The authors note that while the demonstration focuses on July temperature, the approach extends naturally to other months and variables.

### Open Question 3
Can any prompting strategies or model architectures enable LLMs to capture spatial patterns of temperature change, or is this a fundamental limitation of parametric knowledge? The paper shows models fail to reproduce spatial patterns of temperature change, which can be explained by the fact that point-specific temperature trends are rarely discussed in accessible literature outside scientific publications.

### Open Question 4
What is the scaling relationship between model size and climate knowledge accuracy, particularly for high-altitude regions where errors are largest? The paper shows larger models within families perform better and that performance degrades sharply above 1500 m, but whether scaling alone resolves high-altitude errors remains untested.

## Limitations
- Geographic context effects are well-documented but the specific elevation-dependent failure mode lacks direct corpus validation
- The GPT-5 family identifiers and exact land-sea mask definition remain unspecified, introducing reproducibility concerns
- While the framework captures parametric knowledge effectively, it doesn't assess temporal reasoning for climate change patterns beyond simple trend magnitude

## Confidence
- Parametric Climate Knowledge Storage: Medium - Supported by systematic RMSE patterns and geographic context effects, but lacks direct evidence of how training corpora encode these associations
- Geographic Context Enhancement: Medium-High - Strong empirical evidence (27% error reduction) but untested across diverse location types and naming conventions
- Elevation-Dependent Knowledge Gaps: Medium - Well-documented systematic errors but no corpus-level validation of the underlying training data sparsity hypothesis
- Temporal Pattern Failure: Low-Medium - Single-variable analysis with limited temporal scope; could reflect prompt limitations rather than fundamental knowledge gaps

## Next Checks
1. **Prompt Engineering Ablation**: Systematically test chain-of-thought prompting, few-shot exemplars, and temperature scaling effects across the elevation gradient to establish upper bounds of parametric knowledge
2. **Corpus Analysis for Elevation Signals**: Analyze a representative climate/geography corpus to quantify explicit temperature-elevation relationships and validate the hypothesis that high-altitude regions lack sufficient training signal
3. **Multi-Variable Temporal Extension**: Evaluate models on January temperature and precipitation, then assess their ability to capture seasonal patterns and interannual variability, distinguishing between parametric knowledge gaps and temporal reasoning limitations