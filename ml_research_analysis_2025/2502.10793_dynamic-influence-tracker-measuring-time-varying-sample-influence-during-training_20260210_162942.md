---
ver: rpa2
title: 'Dynamic Influence Tracker: Measuring Time-Varying Sample Influence During
  Training'
arxiv_id: '2502.10793'
source_url: https://arxiv.org/abs/2502.10793
tags:
- influence
- training
- sample
- ztest
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Dynamic Influence Tracker (DIT), a method
  that captures time-varying sample influence during training, unlike existing methods
  that only provide static, overall measurements. DIT estimates how removing individual
  samples affects model parameters across arbitrary time windows using a query-based
  framework, projecting parameter changes onto meaningful directions to evaluate impact
  on model behaviors like loss and predictions.
---

# Dynamic Influence Tracker: Measuring Time-Varying Sample Influence During Training

## Quick Facts
- arXiv ID: 2502.10793
- Source URL: https://arxiv.org/abs/2502.10793
- Reference count: 40
- Authors: Jie Xu; Zihan Wu
- Primary result: Dynamic Influence Tracker (DIT) measures time-varying sample influence during training, achieving up to 0.99 correlation with ground truth and 98% accuracy in detecting corrupted samples

## Executive Summary
This paper introduces Dynamic Influence Tracker (DIT), a method that captures time-varying sample influence during training, unlike existing methods that only provide static, overall measurements. DIT estimates how removing individual samples affects model parameters across arbitrary time windows using a query-based framework, projecting parameter changes onto meaningful directions to evaluate impact on model behaviors like loss and predictions. The method identifies four distinct influence patterns—Early Influencers, Late Bloomers, Stable Influencers, and Highly Fluctuating Influencers—and achieves significant improvements over existing methods while avoiding assumptions about loss convexity or model convergence.

## Method Summary
DIT is a query-based framework that estimates how removing individual samples influences model parameters within arbitrary time windows during training. The method uses recursive parameter change estimation via counterfactual SGD, where parameter deviations grow multiplicatively through Hessian approximations and accumulate additively when excluded samples appear in mini-batches. Behavioral influence is projected onto interpretable directions using query vectors specific to the analysis target (loss, prediction, features). The framework scales efficiently using Hessian-vector products rather than explicit Hessian computation, making it practical for large models. DIT stores training metadata (batch indices, learning rates, parameters) in a sliding window and computes influences through backward propagation of query vectors.

## Key Results
- DIT achieves up to 0.99 Pearson correlation with ground truth LOO influence on logistic regression models
- DIT detects corrupted samples with >98% accuracy (98.25% on MNIST-DNN, 98.90% on ViT)
- Sample influences show weak correlation between early and late training stages (τ=0.18-0.34), indicating distinct learning phases
- DIT outperforms existing methods in both correlation with ground truth and corrupted sample detection across multiple architectures

## Why This Works (Mechanism)

### Mechanism 1: Recursive Parameter Change Estimation via Counterfactual SGD
DIT estimates how excluding a sample changes model parameters within arbitrary time windows [t₁, t₂] without retraining. The method derives a recursive relationship using first-order Taylor expansion of gradient differences. At each step, the parameter deviation grows multiplicatively through (I - ηₜH[t]) matrices and accumulates additively when the excluded sample appears in a mini-batch. The final estimator (Eq. 18) combines products of these matrices with summed gradient contributions. Core assumptions include bounded Hessian approximation error and Lipschitz continuous gradients. Evidence is provided through full derivation in section III-B and error bounds in appendix B.

### Mechanism 2: Query-Based Behavioral Influence Projection
Raw parameter changes don't directly reflect impact on specific model behaviors; query vectors project onto interpretable directions. DIT computes inner products ⟨q(t), Δθ₋ⱼ[t]⟩ where q(t) is chosen based on the behavioral aspect of interest. For test loss influence, q(t) = ∇θℓ(z_test; θ[t]); for prediction changes, q(t) = ∇θf(x_test; θ[t]). The difference between query projections at t₂ and t₁ captures the windowed influence (Eq. 19). Core assumption: first-order Taylor approximation accurately relates parameter changes to behavioral changes within the window.

### Mechanism 3: Efficient Backward Propagation via Hessian-Vector Products
Influence computation scales as O(T|Sₜ|p) rather than O(Tp²) or O(p³), enabling application to large models. Algorithm 2 propagates two vectors (u₁, u₂ representing q(t₁) and q(t₂)) backwards through time. At each step, it computes Hessian-vector products H[t]u via ∇θ⟨u, g(z; θ[t])⟩ in O(|Sₜ|p) operations, avoiding explicit Hessian storage or inversion. Influence accumulates via inner products with sample gradients only when the target sample appears in the batch. Core assumption: the matrices Zₜ = (I - ηₜH[t]) are approximately self-adjoint.

## Foundational Learning

- **SGD dynamics and mini-batch gradient updates**: DIT fundamentally models how removing a sample alters the SGD trajectory; understanding recursive parameter updates is prerequisite to grasping the counterfactual formulation. *Quick check: Can you explain why θ[t+1]₋ⱼ differs from θ[t+1] even when sample j is not in batch Sₜ?*

- **First-order Taylor expansion for function approximation**: The core approximation (Eq. 11, 13) relies on Taylor-expanding gradient differences; query-based projections also use Taylor expansion to relate parameter changes to behavioral changes. *Quick check: Under what conditions would a second-order term become significant in Eq. 11?*

- **Influence functions (Koh & Liang, 2017)**: Provides the baseline static influence method that DIT compares against; understanding H⁻¹∇ℓ formulation helps contrast DIT's time-varying approach. *Quick check: Why does the standard influence function require convexity and convergence assumptions that DIT avoids?*

## Architecture Onboarding

- **Component map**: Training Phase (Algorithm 1) -> Influence Computation (Algorithm 2) -> Query Module -> Checkpoint System (Appendix D)

- **Critical path**: 1) During training, store metadata {Sₜ, ηₜ, θ[t+1]} for t ∈ W 2) After training, initialize backward vectors u₁ = 0, u₂ = q(t₂) 3) Iterate backwards from t₂ to 0: if j ∈ Sₜ, accumulate ⟨u₂ - u₁, ηₜg(z_j; θ[t])/|Sₜ|⟩; update u₁, u₂ via u ← u - ηₜH[t]u 4) At t = t₁, reset u₁ = q(t₁) 5) Return accumulated Q as the influence estimate

- **Design tradeoffs**: Storage window W vs. query flexibility (larger W enables arbitrary time-window queries but increases memory); mini-batch size vs. Hessian approximation accuracy (larger batches improve H[t] estimation but slow training); learning rate vs. error bound (smaller η_max reduces exponential error growth but may slow convergence)

- **Failure signatures**: Low correlation with LOO ground truth (likely indicates Hessian approximation error is too high); high variance across runs (check random seed effects on early batch sampling); detection accuracy drops for highly fluctuating samples (expected behavior, these samples may require shorter time windows)

- **First 3 experiments**: 1) Validate on convex model with small dataset: Train logistic regression on Adult, compute DIT for 50 samples over full training, compare Pearson correlation with LOO. Target: ≥0.95 correlation 2) Time-window sensitivity analysis: For MNIST-DNN, compute influence for [0, T], [0, T/2], [T/2, T] separately. Verify weak early-late correlation 3) Corrupted sample detection: Flip 10% labels in MNIST binary (1 vs 7), use last-epoch DIT to rank samples by negative influence. Target: ≥80% detection rate

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the findings suggest several important directions for future research, including leveraging time-varying influence patterns for adaptive curriculum learning, investigating what intrinsic data characteristics determine influence patterns, and scaling the framework to billion-parameter models.

## Limitations
- The assumption that Hessian approximation errors remain bounded across all training steps (A4) may fail for highly non-convex loss landscapes
- The memory-efficient checkpoint approach requires recomputation that could introduce additional errors
- The correlation between early and late training influences being "weak" suggests distinct learning phases, but the paper doesn't explain why this occurs

## Confidence
- **High confidence**: Dynamic influence patterns exist and can be measured; DIT outperforms static methods in detection tasks
- **Medium confidence**: The specific influence pattern categories (Early Influencers, Late Bloomers, etc.) are consistently identifiable across datasets
- **Low confidence**: The exponential error growth bound (Eq. 32) remains controlled in practice for deep networks with large time windows

## Next Checks
1. Test DIT on a dataset with known temporal learning dynamics (e.g., curriculum learning setup) to verify it captures expected influence patterns
2. Systematically vary the storage window size W and measure how correlation with ground truth degrades to quantify the approximation error bounds
3. Apply DIT to a multi-task learning scenario where some samples influence task A early but task B late, validating the framework's ability to capture task-specific temporal dynamics