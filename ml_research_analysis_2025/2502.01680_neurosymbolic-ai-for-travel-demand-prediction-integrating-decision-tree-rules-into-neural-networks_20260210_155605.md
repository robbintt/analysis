---
ver: rpa2
title: 'Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules
  into Neural Networks'
arxiv_id: '2502.01680'
source_url: https://arxiv.org/abs/2502.01680
tags:
- rules
- dataset
- variance
- demand
- travel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of predicting travel demand
  between counties, which is critical for transportation planning and resource allocation.
  The proposed Neurosymbolic AI framework integrates decision tree (DT)-based symbolic
  rules with neural networks (NNs) to leverage both interpretability and predictive
  accuracy.
---

# Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks

## Quick Facts
- arXiv ID: 2502.01680
- Source URL: https://arxiv.org/abs/2502.01680
- Reference count: 28
- Key outcome: Integrating decision tree rules as binary features into neural networks improves travel demand prediction accuracy across MAE, R², and CPC metrics.

## Executive Summary
This study introduces a Neurosymbolic AI framework that combines decision tree-derived symbolic rules with neural networks to predict travel demand between counties. The approach extracts interpretable if-then rules from decision trees and incorporates them as binary features into a neural network model. Experiments show that the combined dataset consistently outperforms standalone datasets, with finer variance thresholds (e.g., 0.0001) for rule selection yielding superior performance by capturing nuanced relationships and reducing prediction errors.

## Method Summary
The method involves extracting interpretable if-then rules from decision trees of varying depths (3-15) and incorporating them as additional binary features into a neural network model. Decision tree paths are converted to if-then conditions and encoded as 0/1 indicator columns. These binary features inject structured, data-driven decision boundaries directly into the neural network's input space. The approach balances interpretability from symbolic rules with predictive accuracy from neural networks.

## Key Results
- The combined dataset (original features + rule-based features) consistently outperforms standalone datasets across multiple metrics including MAE, R², and CPC
- Rules selected at finer variance thresholds (e.g., 0.0001) show superior effectiveness in capturing nuanced relationships and reducing prediction errors
- The framework achieves lower prediction errors and better alignment with observed commuter patterns compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
Encoding decision tree rules as binary features improves neural network predictive accuracy by injecting structured, data-driven decision boundaries directly into the NN's input space. DT paths are converted to if-then conditions and encoded as 0/1 indicator columns, allowing the network to learn from both raw continuous features and pre-discovered logical partitions.

### Mechanism 2
Finer variance thresholds for rule selection yield better performance by retaining more granular, low-variance rules. Lower thresholds (e.g., 0.0001) retain more rules, including those that apply to small but meaningful subsets of data, allowing the NN to leverage nuanced patterns that would be discarded at higher thresholds.

### Mechanism 3
The combined dataset (original features + rule-based features) consistently outperforms either component alone by allowing the NN to learn interactions between raw continuous signals and discrete interpretable partitions. This hybrid approach balances the NN's non-linear capacity with the DT's explicit decision boundaries.

## Foundational Learning

- **Decision Tree Rule Extraction**: Understanding how DTs partition data into if-then paths is prerequisite to grasping the symbolic component. Rules are derived from root-to-leaf paths, each representing a conjunction of feature thresholds. Quick check: Given a DT with depth 3, how many maximum leaf nodes (and thus rules) can it produce? (Answer: Up to 2³ = 8)

- **Binary Feature Encoding**: Rules must be converted to NN-compatible inputs. Binary encoding (1 if rule fires, 0 otherwise) allows the network to treat rule activation as a learnable signal. Quick check: If a rule requires `distance ≤ 50 AND POIs > 200`, what is the binary value for a sample with distance=30 and POIs=150? (Answer: 0, because POIs ≤ 200)

- **Variance Threshold Filtering**: Not all rules are informative. Low-variance rules may not generalize, but in this paper, lower variance thresholds retain more rules and improve performance, suggesting nuanced rules matter. Quick check: A rule fires for only 0.01% of samples. Is it necessarily useless? (Answer: Not necessarily—it may capture a critical minority pattern; domain evaluation is required.)

## Architecture Onboarding

- **Component map**: Data Integration -> Preprocessing -> Decision Tree Module -> Rule Encoder -> Neural Network
- **Critical path**: Clean and merge raw datasets → Final Dataset (10 features + flow target) → Train DTs at multiple depths; extract rules → Dataset of Rules → Filter rules by variance → Dataset of Selected Rules → Concatenate original + selected rule features → Combined Dataset → Train NN; compare against baseline
- **Design tradeoffs**: Tree depth vs. interpretability; variance threshold vs. rule count; rule-only vs. combined datasets
- **Failure signatures**: No improvement over baseline (check rule encoding and variance threshold); performance degrades at high depth (validate with held-out test set); CPC low despite good R² (inspect per-origin/destination errors)
- **First 3 experiments**: 1) Baseline replication: Train NN on Final Dataset only; 2) Rule depth sweep: For DT depths 3-15, train NN on combined dataset; 3) Variance threshold ablation: At fixed depth, compare NN performance across variance thresholds

## Open Questions the Paper Calls Out

### Open Question 1
Can adaptive or dynamic variance thresholds for rule selection improve model generalization compared to the fixed thresholds (0.01, 0.001, 0.0001) utilized in this study? The current methodology relies on fixed variance thresholds, which may introduce bias or lead to the exclusion of useful rules. Experiments comparing adaptive thresholds versus fixed-threshold baseline would resolve this.

### Open Question 2
Does the Neurosymbolic framework maintain its predictive superiority when applied to diverse, real-time data streams that capture seasonal and temporal fluctuations? The current study relies on a static dataset limited to a specific timeframe, leaving the model's ability to handle dynamic, real-time changes untested. Validation on continuous, real-time mobility datasets would resolve this.

### Open Question 3
To what extent can integrating explainable neural architectures, such as attention mechanisms, recover the interpretability lost by the neural network's "black-box" nature? While decision tree rules are interpretable, the neural network component itself remains opaque. A comparative analysis quantifying explainability of standard NNs versus attention-based NNs within this architecture would resolve this.

## Limitations
- Missing detailed NN architecture specifications, including layer configurations, training hyperparameters, and validation methodology
- Geographic scope limited to Tennessee counties only, affecting generalizability to other regions or scales
- Static dataset may not fully capture temporal dynamics of travel demand

## Confidence

- DT-to-NN feature integration mechanism: High
- Variance threshold impact on performance: Low-Medium
- Generalization across geographic contexts: Low

## Next Checks

1. Replicate the rule extraction and binary encoding pipeline on a held-out validation set to verify the variance filtering effects
2. Conduct ablation studies comparing rule-based features against engineered interaction features to isolate the value of symbolic rules
3. Test the framework on a different geographic region (e.g., neighboring state) to assess scalability and robustness