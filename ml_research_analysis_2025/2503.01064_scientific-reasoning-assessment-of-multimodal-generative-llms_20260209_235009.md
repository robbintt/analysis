---
ver: rpa2
title: 'Scientific Reasoning: Assessment of Multimodal Generative LLMs'
arxiv_id: '2503.01064'
source_url: https://arxiv.org/abs/2503.01064
tags:
- reasoning
- performance
- llms
- wang
- scientific
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks multimodal LLMs on ScienceQA, evaluating
  accuracy and textual similarity for reasoning. Gemini models (especially Gemini
  1.5 Flash) achieved the highest accuracy (89.7% in setting 4) and best reasoning
  similarity when rich context was provided.
---

# Scientific Reasoning: Assessment of Multimodal Generative LLMs

## Quick Facts
- arXiv ID: 2503.01064
- Source URL: https://arxiv.org/abs/2503.01064
- Authors: Florian Dreyer; Ekaterina Kolos; Daria Matiash
- Reference count: 4
- Key outcome: Gemini models achieved highest accuracy (89.7% in setting 4) on ScienceQA, but knowledge distillation and adapter tuning of smaller models were ineffective.

## Executive Summary
This paper benchmarks multimodal large language models (LLMs) on the ScienceQA dataset to assess their reasoning capabilities. The study evaluates accuracy and textual similarity across multiple experimental settings, including varying levels of context and instruction tuning. Gemini models, particularly Gemini 1.5 Flash, demonstrate superior performance in both accuracy and reasoning quality when rich context is provided. However, knowledge distillation and adapter tuning of smaller models (Qwen2-VL-2B-Instruct, paligemma-3b-pt-224) failed to produce reliable results, with both base and fine-tuned models unable to generate valid answers in some cases. The study highlights the challenges of transferring reasoning capabilities from large models to smaller ones through distillation.

## Method Summary
The study benchmarks multimodal LLMs on ScienceQA, evaluating accuracy and textual similarity for reasoning. Experiments include testing models with and without solutions, with lecture context, and under different tuning settings. Two fine-tuning approaches—Prefix Tuning and LoRA adapter tuning—are applied to smaller models, and knowledge distillation is tested by training on Gemini-generated outputs. Performance is measured across four settings: base performance, with solutions, with lecture context, and with both solutions and lecture context. The evaluation focuses on accuracy metrics and reasoning quality via textual similarity.

## Key Results
- Gemini 1.5 Flash achieved the highest accuracy (89.7% in setting 4) on ScienceQA.
- Accuracy improved with solutions included, but lecture context sometimes hurt performance.
- Prefix Tuning and LoRA adapter tuning of smaller models failed to produce reliable results.
- Knowledge distillation from Gemini outputs consistently underperformed training on original data.

## Why This Works (Mechanism)
Multimodal LLMs excel in reasoning when provided with rich context and structured solutions, as demonstrated by Gemini models' superior performance. The inclusion of solutions enhances accuracy, while lecture context has mixed effects, potentially due to information overload or misalignment with the reasoning task. Knowledge distillation and adapter tuning failed for smaller models, likely due to the complexity of the reasoning task and the inability of smaller models to effectively learn from distilled outputs. The study suggests that the reasoning capabilities of large models like Gemini are not easily transferable to smaller models through current distillation techniques.

## Foundational Learning
- **Multimodal LLMs**: Why needed—to integrate text and visual data for complex reasoning tasks. Quick check—verify the model processes both input types correctly.
- **ScienceQA Dataset**: Why needed—provides structured multimodal reasoning challenges. Quick check—ensure dataset includes diverse question types and contexts.
- **Knowledge Distillation**: Why needed—to transfer reasoning capabilities from large to small models. Quick check—compare distilled model performance against baseline.
- **Adapter Tuning (LoRA/Prefix)**: Why needed—to efficiently fine-tune models for specific tasks. Quick check—validate fine-tuned models on held-out data.
- **Textual Similarity Metrics**: Why needed—to assess reasoning quality beyond accuracy. Quick check—ensure metrics align with human judgment.

## Architecture Onboarding
- **Component Map**: Input (text/image) -> Multimodal LLM -> Reasoning Output -> Accuracy/Textual Similarity Evaluation
- **Critical Path**: Input processing -> Context integration (solutions/lecture) -> Reasoning generation -> Output evaluation
- **Design Tradeoffs**: Larger models (Gemini) offer better reasoning but are resource-intensive; smaller models are efficient but struggle with complex tasks.
- **Failure Signatures**: Inability to generate valid answers, underperformance in distillation, and context sensitivity.
- **First Experiments**:
  1. Test baseline accuracy of models without context.
  2. Evaluate impact of solutions on accuracy.
  3. Assess performance with lecture context.

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness of knowledge distillation and adapter tuning on smaller models is uncertain.
- Mixed effects of lecture context on performance are not fully explained.
- The study does not explore alternative distillation techniques or teacher-student pairs.

## Confidence
- **High**: Gemini models excel in multimodal reasoning (89.7% accuracy).
- **Medium**: Adapter tuning and knowledge distillation fail for smaller models, but underlying causes are unclear.
- **Low**: Mixed effects of context are not well-explained.

## Next Checks
1. Conduct ablation studies to isolate the impact of different context types on reasoning accuracy.
2. Test knowledge distillation with alternative teacher-student model pairs to determine if the failure is specific to Gemini-based distillation.
3. Investigate the robustness of adapter tuning by varying hyperparameters and comparing with other fine-tuning methods on smaller models.