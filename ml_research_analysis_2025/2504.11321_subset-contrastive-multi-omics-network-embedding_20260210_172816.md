---
ver: rpa2
title: Subset-Contrastive Multi-Omics Network Embedding
arxiv_id: '2504.11321'
source_url: https://arxiv.org/abs/2504.11321
tags:
- data
- omics
- multi-omics
- learning
- scone
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Subset-Contrastive multi-Omics Network Embedding
  (SCONE), a scalable method for integrating multi-omics data using contrastive learning
  on subgraphs. The approach addresses the computational limitations of existing graph
  contrastive learning methods when applied to large single-cell datasets.
---

# Subset-Contrastive Multi-Omics Network Embedding

## Quick Facts
- arXiv ID: 2504.11321
- Source URL: https://arxiv.org/abs/2504.11321
- Authors: Pedro Henrique da Costa Avelar; Min Wu; Sophia Tsoka
- Reference count: 40
- Primary result: SCONE achieves competitive performance on single-cell and bulk multi-omics datasets using contrastive learning on subgraphs

## Executive Summary
This paper introduces SCONE (Subset-Contrastive multi-Omics Network Embedding), a method for integrating multi-omics data through contrastive learning on subgraphs. The approach addresses computational limitations of existing graph contrastive learning methods when applied to large single-cell datasets by employing a subset sampling strategy that reduces memory complexity. SCONE uses Graph Attention Networks for encoding and decoding omics layers, combining reconstruction loss with subset-based contrastive loss. Experiments demonstrate competitive performance compared to state-of-the-art methods on both single-cell (PBMC) and bulk (TCGA) multi-omics datasets.

## Method Summary
SCONE transforms similarity-based omics networks into strengths by employing a subset sampling strategy that reduces memory complexity while maintaining effective contrastive learning. The method uses Graph Attention Networks for both encoding and decoding omics layers, with a reconstruction loss combined with a subset-based contrastive loss. This approach enables scalable integration of multi-omics data while preserving the complementary information across different omics layers. The subset sampling creates positive pairs from the same sample but different omics views, while negative pairs come from different samples, enabling effective contrastive learning without requiring the entire graph to be processed simultaneously.

## Key Results
- On single-cell dataset (PBMC), SCONE achieved AMI of 0.800 and ARI of 0.698
- On TCGA datasets, SCONE achieved mean -log10(p) values up to 6.12
- Outperformed or matched baselines despite using limited data views
- Demonstrated competitive performance compared to state-of-the-art methods

## Why This Works (Mechanism)
The subset-contrastive approach works by creating positive pairs from the same biological sample but different omics views, while negative pairs come from different samples. This enables the model to learn representations that capture both the shared information across omics layers and the sample-specific characteristics. The subset sampling reduces memory requirements while maintaining the essential contrastive signal needed for effective learning. The Graph Attention Network architecture allows the model to weigh the importance of different features and interactions within each omics layer, creating rich representations that can be effectively combined through pooling operations.

## Foundational Learning
- **Graph Attention Networks**: Neural networks that weigh the importance of different nodes and edges in graph-structured data - needed for processing omics similarity networks
- **Contrastive Learning**: Training approach that learns representations by comparing similar and dissimilar pairs - enables effective multi-omics integration
- **Subset Sampling**: Strategy for processing large graphs by working with smaller subsets - reduces memory complexity while maintaining learning effectiveness
- **Multi-Omics Integration**: Combining different types of biological data (e.g., RNA, protein) - captures complementary information about biological systems
- **Clustering Metrics (AMI, ARI)**: Measures of clustering quality that account for chance agreement - used to evaluate the biological relevance of learned representations

## Architecture Onboarding

**Component Map**: Similarity Networks -> Subset Sampler -> GAT Encoder -> Pooling -> GAT Decoder -> Loss Function

**Critical Path**: The encoder processes each omics layer separately through GAT, the pooling operation combines these representations, and the decoder reconstructs the original networks while the contrastive loss ensures meaningful integration.

**Design Tradeoffs**: The subset sampling strategy trades some signal completeness for computational scalability, while the choice of GAT balances expressiveness with computational efficiency compared to full graph neural networks.

**Failure Signatures**: Poor clustering performance suggests the contrastive signal is insufficient; memory issues indicate the subset size needs adjustment; inconsistent performance across datasets may indicate the pooling operation needs refinement.

**First Experiments**:
1. Test different subset sizes to find the optimal balance between memory usage and performance
2. Compare different pooling strategies (mean, max, attention-based) to optimize multi-omics integration
3. Validate the learned representations using independent biological datasets or experimental assays

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the SCONE framework be effectively extended to accommodate the specific data availability and resolution constraints of spatially resolved transcriptomics?
- Basis in paper: The Conclusion states, "Future work may focus on... extending SCONEâ€™s framework to accommodate the specific demands of spatially resolved data."
- Why unresolved: The current study validates SCONE only on single-cell (PBMC) and bulk (TCGA) datasets; spatial data introduces unique topological constraints not addressed by the current KNN-graph implementation.
- What evidence would resolve it: Successful application of SCONE to spatial datasets (e.g., 10x Visium or MERFISH) demonstrating that the subset-contrastive approach preserves spatial coherence and improves clustering over existing spatial methods.

### Open Question 2
- Question: Does the subset sampling procedure inherently introduce stochastic noise that limits the performance of single-omics models?
- Basis in paper: The Discussion notes, "We hypothesise that the subset sampling procedure employed in our method may have introduced noise, potentially contributing to the lower average performance metrics observed in our single-omics models."
- Why unresolved: While the authors suggest multi-omics integration compensates for this noise, the specific trade-off between the scalability gained by subsetting and the potential signal degradation in single-omics views remains unquantified.
- What evidence would resolve it: Ablation studies varying the subset overlap size ($|s_1 \cap s_2|$) to measure the correlation between overlap frequency and single-omics reconstruction fidelity or clustering accuracy.

### Open Question 3
- Question: How can the integration strategy be refined to ensure consistent synergistic performance in datasets where single-omics ensembles currently outperform the joint model?
- Basis in paper: The Results section shows that in KIRC and LUAD datasets, the average of single-omics models outperformed the multi-omics model, suggesting the current pooling operation does not always achieve a synergistic interaction.
- Why unresolved: The paper does not determine why the joint latent space ($z$) fails to capture complementary information effectively in these specific cancer types compared to BLCA or STAD.
- What evidence would resolve it: The development of an adaptive weighting mechanism for the pooling operation that consistently yields a multi-omics representation superior to the best-performing single-omics component across all tested TCGA datasets.

## Limitations
- Scalability claims not empirically validated on truly large-scale datasets (>100K cells)
- Limited evaluation to clustering metrics and pathway enrichment without downstream biological validation
- Doesn't include comparison to newer transformer-based methods like scMamba

## Confidence
- High confidence in the mathematical formulation and implementation details (equations, network architecture)
- Medium confidence in the experimental results given the limited dataset sizes and evaluation metrics
- Low confidence in the scalability claims without testing on larger datasets

## Next Checks
1. Test SCONE on larger single-cell multi-omics datasets (e.g., >100K cells) to verify scalability claims and compare runtime/memory usage against baseline methods
2. Include evaluation against newer transformer-based methods like scMamba to establish competitive positioning
3. Perform biological validation using independent datasets or experimental assays to confirm that the integrated representations capture meaningful biological signals beyond statistical enrichment