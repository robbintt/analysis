---
ver: rpa2
title: Scalable Quantum Error Mitigation with Neighbor-Informed Learning
arxiv_id: '2512.12578'
source_url: https://arxiv.org/abs/2512.12578
tags:
- training
- circuits
- quantum
- circuit
- neighbor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of noise in quantum hardware, a
  major obstacle to realizing the transformative potential of quantum computing. The
  authors propose Neighbor-Informed Learning (NIL), a versatile and scalable quantum
  error mitigation (QEM) framework that unifies and strengthens existing methods like
  zero-noise extrapolation (ZNE) and probabilistic error cancellation (PEC).
---

# Scalable Quantum Error Mitigation with Neighbor-Informed Learning

## Quick Facts
- **arXiv ID:** 2512.12578
- **Source URL:** https://arxiv.org/abs/2512.12578
- **Reference count:** 40
- **Primary result:** Achieves four-order-of-magnitude MSE improvement over random Clifford training for VQE circuits at same cost

## Executive Summary
This paper addresses quantum error mitigation by proposing Neighbor-Informed Learning (NIL), a scalable framework that predicts ideal quantum circuit outputs from noisy measurements of structurally related neighbor circuits. The method unifies zero-noise extrapolation and probabilistic error cancellation through a machine learning approach using linear models trained on Clifford-converted circuits. A key innovation is the 2-design training method, which generates training data by replacing non-Clifford rotation gates with a specific subset of Clifford gates, achieving statistical equivalence to target circuits for linear models.

## Method Summary
NIL learns a linear mapping from noisy neighbor circuit outputs to ideal target circuit expectations. The framework generates neighbor circuits by inserting Pauli gates or scaling noise rates, then trains on Clifford-converted versions of the target circuit using a 2-design approach (replacing rotation gates with {0, π/2, π, 3π/2} set). Lasso regression with logarithmic sample complexity enables scalability. The method achieves training-test equivalence, proving that MSE calculated on the efficiently simulable Clifford training set equals the MSE on the non-Clifford test set.

## Key Results
- Four-order-of-magnitude MSE improvement over random Clifford training for LiH VQE circuits at same training cost
- Logarithmic scaling of training set size with number of neighbor circuits enables application to large-scale problems
- Outperforms various existing QEM techniques in extensive numerical simulations
- Validated scalability on circuits with over 100 qubits and more than 20 layers
- Pauli neighbors outperform CPTP neighbors and neural networks in benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Neighbor-Based Feature Extraction
The noisy expectation values of slightly modified neighbor circuits contain sufficient information to reconstruct the ideal output of a target circuit via a linear map. The framework executes perturbed circuits (Pauli neighbors or ZNE neighbors) and uses a learned linear function to aggregate these noisy outputs. This assumes noise correlation between target and neighbors allows linear inversion. Break condition: significant noise drift between target and neighbor executions or insufficient neighbor diversity.

### Mechanism 2: 2-Design Training for Generalization
Replacing non-Clifford rotation gates with Clifford gates from a rotational 2-design ({0, π/2, π, 3π/2}) creates training distribution that statistically mirrors target circuit distribution for linear models. This preserves second-order statistical moments, ensuring training-test equivalence where MSE on Clifford training set equals MSE on non-Clifford test set. Break condition: target circuits use arbitrary unitaries not well-approximated by Pauli rotations.

### Mechanism 3: Logarithmic Sample Complexity via Lasso
Lasso regression (linear regression with ℓ₁ penalty) enables training set size to scale logarithmically with number of neighbors. The ℓ₁ constraint enforces sparsity in linear coefficients, minimizing variance of estimator and bounding sample complexity to O(ln N / ε²). Assumes underlying relationship admits sparse linear representation. Break condition: optimal mitigation requires dense coefficients.

## Foundational Learning

- **Concept: Clifford Circuits & Stabilizer Simulation**
  - Why needed: 2-design training relies on generating classically simulable Clifford circuits that mimic target statistics
  - Quick check: Can you efficiently simulate a circuit with T-gates? (No, that's why we replace them with Clifford gates for training)

- **Concept: Unitary t-Designs**
  - Why needed: 2-design training method mimics statistical properties of random unitaries up to second order
  - Quick check: Why use a 2-design instead of a 1-design? (1-designs match first moments; 2-designs match second moments/variances, critical for MSE optimization)

- **Concept: Regularization (L1 vs L2)**
  - Why needed: Paper selects Lasso (L1) over Ridge (L2) or OLS; understanding L1 promotes sparsity is necessary to interpret the linear coefficients
  - Quick check: Does Lasso tend to produce dense or sparse coefficient vectors?

## Architecture Onboarding

- **Component map:** Target Circuit C(θ) -> Neighbor Map -> Training Generator -> Learner (Lasso) -> Inference
- **Critical path:** Constructing the neighbor map. If neighbors are too expensive to run or poorly chosen, the linear model fails to converge
- **Design tradeoffs:** Pauli neighbors outperform CPTP neighbors; linear models outperform neural networks in this framework
- **Failure signatures:** High MSE on training set indicates noise model too strong or 2-design replacement failed; divergence between training and test MSE indicates generalization error
- **First 3 experiments:**
  1. Baseline Linear Test: Implement NIL on 6-qubit VQE ansatz using weight-1 Pauli neighbors, verify MSE reduction against ZNE
  2. Training Method Ablation: Compare 2-design training vs. random Clifford training on same ansatz, plot Test MSE divergence
  3. Scalability Check: Run pipeline on 20-qubit circuit to confirm logarithmic scaling of training set size

## Open Questions the Paper Calls Out
- Can sophisticated non-linear models provide performance benefits over linear models in specific noise regimes or tasks?
- How does average-case MSE performance relate to worst-case error bounds?
- How does NIL perform under non-local or time-correlated noise models that violate local noise assumptions?

## Limitations
- Core assumption of linear combination reconstruction holds primarily for local noise models; global correlated errors may break the relationship
- Logarithmic scaling claim relies on sparsity assumption validity, which may not hold for highly entangled circuits or non-Pauli noise channels
- Lack of hardware validation creates significant gap between simulator and real quantum device noise characteristics

## Confidence
- **High confidence** in 2-design training method's statistical equivalence (proven in Appendix B)
- **Medium confidence** in logarithmic scaling claim (theoretically derived but needs more empirical validation)
- **Medium confidence** in superiority over ZNE and PEC (benchmarked on specific circuits but not comprehensively across all scenarios)

## Next Checks
1. **Noise Model Robustness Test:** Apply NIL to circuits under non-depolarizing noise (amplitude damping, coherent errors) and quantify performance degradation compared to four-order-of-magnitude improvement claim
2. **Hardware Cross-Validation:** Run NIL pipeline on IBM or Rigetti hardware using same VQE circuits to verify theoretical gains translate to real processors, examining shot noise and device-specific errors
3. **Sparsity Assumption Verification:** Analyze Lasso coefficient distribution post-training for each benchmark circuit to confirm majority of coefficients are near-zero, validating theoretical basis for logarithmic scaling