---
ver: rpa2
title: Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory
  Semantics
arxiv_id: '2509.15739'
source_url: https://arxiv.org/abs/2509.15739
tags:
- argument
- arguments
- few-shot
- llms
- one-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We evaluate whether LLMs can approximate structured reasoning from
  Computational Argumentation Theory (CAT) by ranking arguments in natural debates.
  We use Quantitative Argumentation Debate (QuAD) semantics to assign acceptability
  scores to arguments based on their attack and support relations.
---

# Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics

## Quick Facts
- arXiv ID: 2509.15739
- Source URL: https://arxiv.org/abs/2509.15739
- Reference count: 17
- One-line primary result: LLMs show moderate alignment with QuAD rankings (Spearman's ρ up to 0.46, Kendall's τ up to 0.42 on DebatePedia), but performance degrades with longer inputs or disrupted discourse flow

## Executive Summary
This paper evaluates whether large language models can approximate structured reasoning from Computational Argumentation Theory by ranking arguments in natural debates. The authors use Quantitative Argumentation Debate (QuAD) semantics to assign acceptability scores to arguments based on their attack and support relations, then prompt models to rank arguments from dialogue-formatted debates without access to the underlying argument graph. Across four LLMs and multiple instruction strategies, including Chain-of-Thought and In-Context Learning, models show moderate correlation with QuAD rankings but struggle with longer inputs and disrupted discourse flow.

## Method Summary
The study uses two NoDE benchmark datasets (12AngryMen and DebatePedia) with argument graphs converted to chronological dialogue format. QuAD semantics with uniform initial weights (0.5) computes acceptability degrees through recursive propagation of attack and support influences. Four LLMs (GPT-4o, Claude 3 Sonnet, Command R+, Llama 3 70B) are prompted using six instruction strategies: Zero-Shot Vanilla, ICL one-shot/few-shot, and CoT variants. Model rankings are evaluated against gold QuAD rankings using Spearman's ρ and Kendall's τ correlation metrics.

## Key Results
- CoT few-shot instruction consistently outperforms other techniques, achieving Spearman's ρ up to 0.46 and Kendall's τ up to 0.42 on DebatePedia
- Performance degrades significantly with longer debates and when chronological flow is disrupted via topological sorting
- LLMs rely more on natural chronological flow than underlying argument graph structure for reasoning
- Advanced prompting mitigates biases related to argument length and position

## Why This Works (Mechanism)

### Mechanism 1
- Claim: QuAD semantics provides principled ground truth by recursively propagating attack and support influences through acyclic argument graphs
- Core assumption: Acyclic graphs guarantee convergence; uniform initialization ensures neutral evaluation
- Evidence: Section 3.3 describes recursive influence propagation; section A.2 defines acceptability scores as overall persuasiveness
- Break condition: Cyclic graphs prevent guaranteed convergence

### Mechanism 2
- Claim: LLMs partially approximate QuAD rankings by leveraging discourse chronology cues rather than explicit graph reasoning
- Core assumption: Models trained on conversational data have implicit biases toward chronological coherence
- Evidence: Abstract notes performance degrades with disrupted discourse flow; section 6.1 shows topological sorting reduces LLM performance
- Break condition: Highly non-sequential debates or artificially shuffled argument orders

### Mechanism 3
- Claim: Chain-of-Thought prompting with few-shot exemplars improves ranking by reducing surface-level biases
- Core assumption: Models can reliably infer pairwise relations from text when explicitly prompted
- Evidence: Section 5 shows few-shot CoT consistently outperforms other techniques; section 6.2 demonstrates CoT addresses length and positional biases
- Break condition: Very long debates exceed context windows; poor-quality exemplars misguide inference

## Foundational Learning

- Concept: Bipolar gradual argumentation semantics
  - Why needed here: Understanding that QuAD combines both attack (negative) and support (positive) relations to produce continuous acceptability scores
  - Quick check question: If Argument A has two attackers with σ=0.8 and σ=0.3, which attacker reduces A's score more, and why?

- Concept: Topological sorting of directed acyclic graphs
  - Why needed here: The paper uses topological sorts to shuffle argument order while preserving graph structure, testing whether models rely on order vs. structure
  - Quick check question: Does topological sorting change the QuAD acceptability scores? Does it change LLM input?

- Concept: Rank correlation metrics (Spearman's ρ vs. Kendall's τ)
  - Why needed here: The paper uses both to evaluate LLM rankings—ρ captures monotonic relationships with sensitivity to rank magnitude, while τ measures pairwise directional agreement
  - Quick check question: If an LLM ranks arguments as [1,3,2,4] and QuAD ranks them [1,2,3,4], which metric would penalize the swap of adjacent items more heavily?

## Architecture Onboarding

- Component map: Graph-to-Dialogue Converter -> QuAD Scoring Engine -> LLM Prompting Module -> Rank Correlation Evaluator
- Critical path: Load NoDE dataset -> Initialize uniform weights -> Compute QuAD scores -> Convert graph to dialogue -> Prompt LLM -> Parse ranking output -> Compute correlations
- Design tradeoffs:
  - Uniform vs. learned initial weights: Uniform ensures unbiased evaluation but ignores real-world strength variations
  - Chronological vs. topological order: Chronological mimics real dialogue; topological isolates graph reasoning
  - Single vs. multi-model evaluation: Individual models show high variance; averaging provides stability
- Failure signatures:
  - Negative correlations indicate systematic inversion
  - Format violations suggest parsing issues
  - Length collapse shows context window limitations
  - Position clustering reveals bias toward argument placement
- First 3 experiments:
  1. Reproduce baseline: Run all 4 models on DebatePedia with Vanilla prompting; verify ρ≈0.11 average
  2. Ablate prompting strategy: For one model, compare all six instruction strategies; plot improvement curve
  3. Stress test with topological shuffling: Run Llama-3-70B with CoT few-shot on topological sorts; confirm performance drop

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs approximate CAT semantics on cyclic argument graphs, and which semantics best support convergence?
- Basis: Paper restricts evaluation to acyclic graphs due to QuAD convergence requirements
- Why unresolved: Cyclic debates remain untested; alternative CAT semantics not evaluated
- What evidence would resolve it: Experiments applying QuAD and alternatives to cyclic debate graphs, measuring convergence and alignment

### Open Question 2
- Question: Does providing LLMs with estimated initial argument weights improve alignment with CAT semantics?
- Basis: Study uniformly initializes all arguments at 0.5; real arguments vary in initial strength
- Why unresolved: Uniform initialization ensures neutrality but may not reflect actual argument strengths
- What evidence would resolve it: Ablation experiments comparing uniform vs. LLM-estimated initial weights

### Open Question 3
- Question: Does data contamination or memorization explain exceptional ICL performance spikes?
- Basis: Some models showed anomalous ICL improvements suggesting possible retrieval of memorized training data
- Why unresolved: Performance jumps from ~0.2 to ~0.5 ρ raise contamination concerns
- What evidence would resolve it: Contamination audits using membership inference tests and n-gram overlap analysis

### Open Question 4
- Question: Can graph-aware architectures overcome input-length sensitivity observed in this study?
- Basis: Performance degrades substantially with longer debates; even 405B models struggle
- Why unresolved: Models rely on sequential patterns rather than explicit graph reasoning
- What evidence would resolve it: Comparative experiments with graph-enhanced LLMs on long debates

## Limitations

- Evaluation restricted to acyclic graphs, limiting generalizability to real-world debates with cyclic dependencies
- Performance degradation on longer debates suggests fundamental context window limitations for complex reasoning
- Reliance on chronological discourse patterns indicates models may fail in non-dialogue contexts
- Uniform initialization assumption may not reflect actual argument strengths in natural discourse

## Confidence

- **High confidence**: QuAD semantics implementation; existence of chronological ordering bias; general improvement from Vanilla to few-shot CoT
- **Medium confidence**: Specific magnitude of performance drops; interpretation of "implicit reasoning"; claim that ICL exemplars fully compensate for biases
- **Low confidence**: Generalizability to debates with cyclic structures; assumption that uniform initialization doesn't affect rankings; claim that LLMs could handle debates with more than 50 arguments

## Next Checks

1. **Cross-dataset validation**: Test prompting strategies on a third argumentation dataset (e.g., UKP Sentential Argument Mining corpus) to verify performance patterns across different domains
2. **Ablation of chronological bias**: Create debates with randomized argument order and measure performance degradation relative to topological sorting experiments
3. **Graph structure stress test**: Introduce controlled cyclic dependencies into argument graphs and evaluate whether models can still approximate acceptability rankings