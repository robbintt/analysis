---
ver: rpa2
title: 'MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification'
arxiv_id: '2506.17140'
source_url: https://arxiv.org/abs/2506.17140
tags:
- medi
- training
- diffusion
- metadata
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MeDi, a metadata-guided diffusion model for
  histopathology image generation. MeDi conditions on both class labels and metadata
  (e.g., medical center) to synthesize high-quality images for underrepresented subpopulations,
  aiming to mitigate biases in downstream tumor classification tasks.
---

# MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification

## Quick Facts
- arXiv ID: 2506.17140
- Source URL: https://arxiv.org/abs/2506.17140
- Reference count: 30
- Primary result: MeDi reduces FID and improves balanced accuracy for tumor subtyping under subpopulation shifts

## Executive Summary
This work introduces MeDi, a metadata-guided diffusion model for histopathology image generation. MeDi conditions on both class labels and metadata (e.g., medical center) to synthesize high-quality images for underrepresented subpopulations, aiming to mitigate biases in downstream tumor classification tasks. By generating synthetic samples for missing metadata-class combinations, MeDi reduces the correlation between metadata and disease labels that often leads to shortcut learning. Experiments on the TCGA-UT dataset demonstrate that MeDi achieves lower Fréchet Inception Distance (FID) than class-only conditioning, indicating more faithful image generation. In downstream classification tasks with subpopulation shifts, MeDi improves balanced accuracy for NSCLC and uterine cancer subtyping, while matching performance for RCC. This proof-of-concept highlights the potential of metadata-aware generative models to enhance fairness and robustness in computational pathology.

## Method Summary
MeDi extends conditional diffusion models by incorporating metadata embeddings alongside class labels. The model uses a 2D UNet from the diffusers library, where class and metadata embeddings are concatenated and added to timestep embeddings. During training, paired (image, class, metadata) data generates synthetic images for all class-metadata combinations. At inference, the model synthesizes samples for missing combinations to break spurious correlations between metadata and labels. The synthetic data is then used to augment training of downstream classifiers, improving generalization to held-out subpopulations.

## Key Results
- MeDi achieves lower Fréchet Inception Distance (FID) than class-only conditioning (37.73 vs 50.65)
- Synthetic augmentation improves balanced accuracy for NSCLC (74.31→81.37) and uterine cancer subtyping (67.73→74.86)
- Performance matches class-only conditioning for RCC classification
- MeDi successfully removes spurious correlations between metadata and disease labels

## Why This Works (Mechanism)

### Mechanism 1
Conditioning diffusion on metadata improves fidelity of generated images for specific subpopulations. The model receives concatenated embeddings of class labels AND metadata (e.g., tissue source site), which are added to timestep embeddings. This forces the denoising UNet to learn domain-specific variations rather than collapsing to class-averaged modes. Core assumption: Metadata attributes (like medical center) are correlated with visually distinguishable features (staining, artifacts, scanner effects) that a class-only model would average out. Evidence: MeDi achieves lower Fréchet Inception Distance (FID) than class-only conditioning, showing MeDi captures TSS-specific staining patterns while CLS cannot.

### Mechanism 2
Targeted sampling of missing class-metadata combinations reduces spurious correlations that cause shortcut learning. At inference, MeDi generates samples for ALL combinations of class and metadata present in training (e.g., if class 1 only came from site A and class 2 from site B, MeDi generates (1,A), (1,B), (2,A), (2,B)). This breaks the correlation between metadata and label. Core assumption: Shortcut learning occurs because downstream classifiers exploit correlations between metadata (e.g., hospital) and labels when these are confounded in training data. Evidence: MeDi helps remove spurious correlations or learnable proxies between metadata and the disease label, reducing Clever Hans effects.

### Mechanism 3
Synthetic augmentation improves generalization to unseen subpopulations in low-data regimes. Adding synthetic samples (1:1 ratio with real) expands training coverage of the combinatorial class-metadata space, providing the downstream classifier with a more balanced representation that transfers better to held-out sites. Core assumption: The diffusion model generalizes to held-out metadata combinations sufficiently to provide useful training signal (not memorized artifacts). Evidence: synthetic data augmentation significantly improves performance to unseen tissue source sites in low data regimes, with MeDi improving NSCLC and Uterine balanced accuracy.

## Foundational Learning

- **Diffusion Model Conditioning**: Why needed here: MeDi extends standard class-conditional diffusion with metadata embeddings; understanding how conditioning vectors are injected into UNets is prerequisite to modifying or debugging this architecture. Quick check: Can you explain how timestep and class embeddings are combined in a standard conditional UNet?

- **Shortcut Learning / Clever Hans Effects**: Why needed here: The entire motivation rests on models exploiting spurious metadata-label correlations; without this concept, the augmentation strategy makes no sense. Quick check: Give an example where a classifier achieves high accuracy by exploiting a confound rather than the true signal.

- **Subpopulation Shift / Domain Shift**: Why needed here: The evaluation explicitly designs holdout sets based on metadata combinations; understanding distribution shift is required to interpret why balanced accuracy matters more than overall accuracy. Quick check: Why might a model with 95% overall accuracy fail catastrophically on a specific hospital's data?

## Architecture Onboarding

- **Component map**: Image patch + class label + metadata attributes -> Learnable embeddings for categorical metadata + class embedding -> z_cond = concat(z_class, z_meta_1, ..., z_meta_k) -> UNet Backbone (standard 2D UNet from diffusers library) -> Denoised image conditioned on specified class-metadata combination

- **Critical path**: Verify metadata schema and identify candidate attributes (must have visual correlates) -> Design embedding dimensions to match UNet's timestep embedding dimension -> Train with paired (image, class, metadata) data; validate FID per subpopulation -> At inference, enumerate missing class-metadata combinations and generate synthetic samples -> Train downstream classifier on real + synthetic data; evaluate on held-out subpopulations

- **Design tradeoffs**: More metadata attributes = finer control but sparser coverage per combination; the paper uses only TSS as proof-of-concept. Larger embedding dimensions capture more metadata variation but may overfit to rare sites. Uniform sampling over combinations vs. weighted by real distribution; paper uses uniform to maximize balancing effect.

- **Failure signatures**: High FID despite metadata conditioning indicates metadata may have weak visual signal; try different attributes. Downstream accuracy unchanged suggests generated samples may be too unrealistic or the held-out subpopulation is genuinely different. Training instability occurs if d_class + k·d_e ≠ d_t exactly; mismatched dimensions cause silent failures. Mode collapse on rare classes requires oversampling or separate training.

- **First 3 experiments**: 
  1. Reproduce FID comparison: Train CLS-only and MeDi models on a subset of TCGA-UT; verify MeDi achieves lower average FID (paper: 37.73 vs 50.65)
  2. Ablate metadata attributes: Train separate MeDi models with TSS-only, race-only, combined; measure which attribute drives FID improvement
  3. Test generalization with smaller holdout: Reduce holdout from 30% to 10% of class-metadata combinations; observe whether synthetic augmentation benefit diminishes as real data coverage improves

## Open Questions the Paper Calls Out

- **Can MeDi effectively mitigate bias when conditioned on demographic metadata such as race, gender, and scanner type?**: The conclusion states an intent to "explore further metadata factors (e.g., scanner type, patient age, gender, and race)." Current experiments only validate conditioning on the tissue source site (TSS), leaving fairness regarding demographic attributes untested.

- **Does the performance improvement hold when scaling to larger datasets and more general training regimes?**: Section 4.4 and the Conclusion ask to "investigate if similar results can be achieved on larger datasets and in more general settings." The study is currently a "proof-of-concept" on TCGA-UT; scalability to massive clinical pipelines is unknown.

- **Does applying classifier-free guidance improve the realism and utility of the synthetic data in this framework?**: The conclusion lists exploring "classifier-free guidance to further assess and improve both the realism and utility of synthetic histopathology data." The current implementation does not use this technique, leaving potential improvements in sample fidelity and diversity unexplored.

## Limitations

- Study relies on a single dataset (TCGA-UT) with histopathology patches rather than whole-slide images
- Downstream evaluation uses linear probe on pre-extracted embeddings rather than end-to-end training
- Metadata conditioning focuses only on tissue source site (TSS), leaving other attributes unexplored
- Synthetic data's clinical relevance and ability to capture rare pathologies remain untested

## Confidence

- **FID improvements**: Medium - demonstrated on TCGA-UT but requires replication
- **Downstream accuracy gains**: Medium - shown for specific cancer types, needs broader validation
- **Generalizability**: Low - proof-of-concept status with limited metadata scope

## Next Checks

1. Reproduce results on a different multi-site pathology dataset (e.g., CAMELYON or prostate cancer cohorts) to verify generalization beyond TCGA-UT
2. Train and evaluate end-to-end classifiers (not just linear probes) on UNI embeddings with MeDi augmentation to assess practical utility
3. Compare MeDi against alternative bias mitigation strategies (e.g., domain adversarial training, balanced sampling) on the same tasks to establish relative effectiveness