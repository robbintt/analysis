---
ver: rpa2
title: 'Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis'
arxiv_id: '2505.06271'
source_url: https://arxiv.org/abs/2505.06271
tags:
- sound
- lung
- disease
- classification
- diagnosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of improving respiratory disease
  diagnosis by integrating lung sound classification, disease diagnosis, and patient
  metadata using multitask learning (MTL). The proposed Tri-MTL framework extends
  conventional MTL by incorporating metadata classification alongside lung sound and
  disease diagnosis tasks.
---

# Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis

## Quick Facts
- arXiv ID: 2505.06271
- Source URL: https://arxiv.org/abs/2505.06271
- Reference count: 33
- Primary result: Multitask learning framework improves respiratory disease diagnosis by up to 90.16% when incorporating stethoscope metadata

## Executive Summary
This study presents Tri-MTL, a triple multitask learning framework that integrates lung sound classification, disease diagnosis, and patient metadata to improve respiratory disease diagnosis. The framework extends conventional multitask learning by incorporating metadata classification alongside lung sound and disease diagnosis tasks, using a pretrained Audio Spectrogram Transformer (AST) model. Experimental results on the ICBHI dataset demonstrate significant improvements in both lung sound classification (up to 60.21% score) and disease diagnosis (up to 90.16% score) when metadata is incorporated, particularly stethoscope information. The findings highlight the clinical potential of MTL in respiratory diagnostics, showing that shared representations and metadata integration can improve diagnostic accuracy and reduce misdiagnosis rates.

## Method Summary
The Tri-MTL framework leverages multitask learning to jointly optimize three tasks: lung sound classification, disease diagnosis, and metadata classification. Using a pretrained Audio Spectrogram Transformer (AST) model as the backbone, the framework processes respiratory audio data while simultaneously incorporating metadata such as stethoscope information. The multitask learning approach allows the model to learn shared representations across tasks, with metadata serving as additional contextual information to enhance diagnostic performance. The framework was evaluated on the ICBHI dataset, demonstrating that metadata integration, particularly stethoscope information, significantly improves both lung sound classification and disease diagnosis accuracy compared to single-task learning approaches.

## Key Results
- Lung sound classification improved by up to 60.21% when incorporating metadata
- Disease diagnosis accuracy reached up to 90.16% with metadata integration
- Stethoscope metadata showed the most significant positive impact on model performance

## Why This Works (Mechanism)
The framework's effectiveness stems from multitask learning's ability to leverage shared representations across related diagnostic tasks. By jointly optimizing lung sound classification, disease diagnosis, and metadata classification, the model learns more robust features that capture both acoustic patterns and contextual information. The Audio Spectrogram Transformer's pretrained capabilities provide a strong foundation for processing respiratory sounds, while the multitask architecture enables knowledge transfer between tasks. Metadata integration, particularly stethoscope information, provides additional clinical context that helps disambiguate similar-sounding respiratory conditions and reduces misdiagnosis rates.

## Foundational Learning
1. **Multitask Learning (MTL)**: A machine learning approach where multiple related tasks are learned simultaneously to improve overall performance. Needed because respiratory diagnosis involves multiple correlated aspects (sound patterns, disease types, patient context). Quick check: Verify that tasks share relevant features and have some level of correlation.

2. **Audio Spectrogram Transformer (AST)**: A transformer-based model pretrained on audio spectrograms that excels at capturing long-range dependencies in audio signals. Needed because respiratory sounds have complex temporal patterns that require sophisticated modeling. Quick check: Ensure the model has been pretrained on sufficient audio data before fine-tuning on respiratory sounds.

3. **Metadata Integration**: The process of incorporating auxiliary information (like stethoscope type, patient demographics) into the learning process. Needed because clinical context can significantly impact diagnostic accuracy. Quick check: Validate that metadata is relevant and properly encoded for the learning task.

4. **Respiratory Sound Classification**: The task of categorizing lung sounds into different types (crackles, wheezes, normal, etc.). Needed as a foundational component for disease diagnosis. Quick check: Establish clear labeling criteria and ensure balanced class distribution.

## Architecture Onboarding

**Component Map**: Audio Spectrogram -> AST Backbone -> Task Heads (Lung Sound, Disease Diagnosis, Metadata) -> Combined Loss Function

**Critical Path**: Raw respiratory audio → Spectrogram conversion → AST feature extraction → Task-specific heads → Multitask optimization → Diagnostic output

**Design Tradeoffs**: The framework balances between task-specific specialization and shared representation learning. While multitask learning improves overall performance, it may introduce task interference if tasks are too dissimilar. The choice of AST as backbone provides strong audio processing capabilities but requires significant computational resources.

**Failure Signatures**: 
- Performance degradation when metadata is noisy or irrelevant
- Task interference when respiratory sounds and metadata are poorly correlated
- Overfitting on the specific dataset if not properly regularized

**3 First Experiments**:
1. Compare single-task vs. multitask performance on lung sound classification baseline
2. Evaluate impact of different metadata types (stethoscope, patient demographics) individually
3. Test performance across different AST model sizes to assess computational tradeoffs

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Results are based solely on the ICBHI dataset, limiting generalizability to diverse clinical scenarios
- Performance gains from metadata integration may not translate across different recording equipment
- Practical deployment considerations (real-time processing, workflow integration) are not explored

## Confidence
- Multitask learning effectiveness: High
- AST model performance: High
- Generalizability of findings: Medium
- Clinical implementation feasibility: Medium

## Next Checks
1. Conduct cross-dataset validation using multiple respiratory sound databases to assess generalizability of the Tri-MTL framework
2. Perform ablation studies to isolate the specific contribution of each metadata type (stethoscope, patient demographics) to diagnostic performance
3. Evaluate the framework's performance in a controlled clinical setting with actual patient data to assess real-world applicability and physician feedback integration