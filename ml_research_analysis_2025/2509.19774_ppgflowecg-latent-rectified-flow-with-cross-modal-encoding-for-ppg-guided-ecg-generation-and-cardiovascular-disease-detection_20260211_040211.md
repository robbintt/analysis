---
ver: rpa2
title: 'PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided
  ECG Generation and Cardiovascular Disease Detection'
arxiv_id: '2509.19774'
source_url: https://arxiv.org/abs/2509.19774
tags:
- latent
- flow
- ppgflowecg
- rectified
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PPGFlowECG, a two-stage framework that translates
  photoplethysmography (PPG) to electrocardiogram (ECG) using latent rectified flow.
  The method aligns PPG and ECG in a shared latent space via a CardioAlign Encoder,
  then generates ECGs through latent rectified flow to ensure high fidelity and interpretability.
---

# PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided ECG Generation and Cardiovascular Disease Detection

## Quick Facts
- arXiv ID: 2509.19774
- Source URL: https://arxiv.org/abs/2509.19774
- Reference count: 10
- This paper proposes PPGFlowECG, a two-stage framework that translates photoplethysmography (PPG) to electrocardiogram (ECG) using latent rectified flow. The method aligns PPG and ECG in a shared latent space via a CardioAlign Encoder, then generates ECGs through latent rectified flow to ensure high fidelity and interpretability. This approach addresses physiological semantics misalignment and high-dimensional modeling complexity in generative models. Extensive experiments on four datasets (MCMED, MIMIC-AFib, VitalDB, and BIDMC) show state-of-the-art performance, with improved reconstruction quality (MAE 0.73, RMSE 1.14 on MCMED) and downstream cardiovascular disease detection (Macro-AUROC 0.631). Cardiologist evaluations confirm the clinical utility of synthesized ECGs for real-world screening.

## Executive Summary
This paper introduces PPGFlowECG, a novel framework for generating electrocardiogram (ECG) signals from photoplethysmography (PPG) data to enable affordable cardiovascular disease screening. The method uses a two-stage approach: first aligning PPG and ECG in a shared latent space using a CardioAlign Encoder with cross-modal constraints, then generating ECGs via latent rectified flow. The framework achieves state-of-the-art performance across multiple datasets, with quantitative metrics showing high reconstruction quality and improved downstream disease detection accuracy. Cardiologist evaluations further validate the clinical utility of the synthesized ECGs.

## Method Summary
PPGFlowECG operates in two stages. Stage 1 uses a shared CardioAlign Encoder to map PPG and ECG into a unified latent space, applying three constraints: Global Distribution Alignment (GDA) for distributional consistency, Local Instance Discrimination (LID) for subject-specific features, and Semantic Decodability Constraint (SDC) for cross-modal reconstruction. Stage 2 trains a latent rectified flow model conditioned on the PPG-aligned latent to generate ECG latents, which are then decoded. The framework leverages a Transformer-based velocity field network and solves an ODE during inference. The approach reduces the high-dimensional complexity of direct signal-to-signal translation while maintaining physiological fidelity.

## Key Results
- State-of-the-art reconstruction quality with MAE 0.73 and RMSE 1.14 on MCMED dataset
- Improved downstream cardiovascular disease detection with Macro-AUROC of 0.631
- Cardiologist evaluations confirm clinical utility of synthesized ECGs for arrhythmia screening
- Ablation studies show both alignment and flow stages are necessary for optimal performance

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Semantic Alignment via Shared Encoder
- **Claim:** A shared encoder architecture forces PPG and ECG signals into a unified latent space, reducing modality-specific noise while preserving shared physiological dynamics.
- **Mechanism:** The CardioAlign Encoder uses weight-tying ($E_{CA}$) for both modalities combined with a coarse-to-fine loss strategy: Global Distribution Alignment (GDA) aligns Gaussian posteriors, Local Instance Discrimination (LID) preserves subject-specific signatures via contrastive learning, and Semantic Decodability Constraint (SDC) ensures latents are mutually reconstructible.
- **Core assumption:** PPG and ECG, despite morphological differences, reflect a common underlying cardiovascular state that can be linearly or non-linearly mapped to a shared manifold.
- **Evidence anchors:**
  - [Page 3, Section 3.2]: "The CardioAlign Encoder mitigates this by using a shared encoder $E_{CA}(\cdot)$ for both modalities... reducing sensitivity to waveform-specific appearance."
  - [Page 6, Figure 4]: t-SNE visualizations show overlapping distributions for the shared encoder vs. distinct clusters for separate encoders.
  - [corpus]: Related works like "Translation from Wearable PPG to 12-Lead ECG" address similar translation tasks but often lack this specific tripartite alignment constraint.
- **Break condition:** If the physiological link between PPG and ECG is disrupted (e.g., significant signal corruption or probe detachment), the shared representation may collapse or hallucinate features.

### Mechanism 2: Latent Rectified Flow for Straight-Line Transport
- **Claim:** Operating rectified flow in the pre-aligned latent space, rather than raw signal space, reduces the curvature of the transport trajectory, enabling high-fidelity generation with fewer ODE steps.
- **Mechanism:** The model learns a vector field $v_\theta$ to transport Gaussian noise $z$ to the target ECG latent $y$ via a straight line. The Stage 1 alignment minimizes conditional dispersion, ensuring the path is linear and numerically stable for Euler solvers.
- **Core assumption:** The latent space is smoother and more continuous than the high-dimensional raw signal space, satisfying the straight-line assumption of rectified flow.
- **Evidence anchors:**
  - [Page 4, Section 3.4]: "Stage 1 reduces the irreducible noise floor... making the target $y$ close to the conditioning latent $c$... yielding $x^{(2)}_t \approx 0$."
  - [Page 5, Figure 5]: Performance peaks at T=5 steps and degrades slightly with more steps, indicating successful trajectory straightening.
  - [corpus]: Corpus papers like "Versatile Cardiovascular Signal Generation" use diffusion transformers, which typically require more steps; this mechanism explicitly targets step reduction.
- **Break condition:** If the latent space manifold is highly non-smooth (due to poor alignment), the straight-line assumption fails, requiring significantly more ODE steps or causing divergence.

### Mechanism 3: Multi-Granularity Constraint Coupling
- **Claim:** Combining distributional, instance-level, and functional constraints prevents the "waveform mimicker" problem where reconstruction looks correct but lacks diagnostic utility.
- **Mechanism:** $L_{GDA}$ prevents mode collapse; $L_{LID}$ prevents over-smoothing by retaining patient-specific features; $L_{SDC}$ enforces that latent codes contain sufficient information to reconstruct the *other* modality.
- **Core assumption:** Diagnostic features (e.g., arrhythmia signatures) are transferable properties of the latent code and not artifacts of a single modality's noise profile.
- **Evidence anchors:**
  - [Page 3, Eq 3-5]: Formal definitions of the three loss components.
  - [Page 6, Table 4]: Ablation study shows removing either Stage 1 (alignment) or Stage 2 (flow) degrades performance.
  - [corpus]: "Finetuning and Quantization of EEG-Based Foundational BioSignal Models" discusses cross-modal transfer, supporting the utility of shared foundations, though specific loss formulations differ.
- **Break condition:** If any single constraint dominates (e.g., $L_{SDC}$ is too high), the model may prioritize pixel-perfect reconstruction over semantic generative capacity, leading to blurry or deterministic outputs.

## Foundational Learning

- **Concept: Ordinary Differential Equations (ODEs) in Generative Models**
  - **Why needed here:** Inference in Rectified Flow relies on solving an ODE ($dx/dt = v_\theta$) to transport noise to a signal. Understanding Euler solvers and step sizes is critical for tuning the trade-off between speed and quality.
  - **Quick check question:** How does the number of ODE steps ($T$) affect the trade-off between generation speed and reconstruction error in flow matching?

- **Concept: Contrastive Learning (InfoNCE)**
  - **Why needed here:** The Local Instance Discrimination (LID) loss uses a contrastive objective to pull paired PPG/ECG embeddings together while pushing unpaired samples apart.
  - **Quick check question:** In the LID loss, what serves as the "positive" pair and what serves as the "negative" samples during batch training?

- **Concept: Variational Autoencoders (VAE) & Reparameterization**
  - **Why needed here:** The encoder outputs a distribution ($\mu, \sigma$) and samples $z$ using the reparameterization trick. This stochasticity is vital for the KL divergence calculations in $L_{GDA}$.
  - **Quick check question:** Why is the reparameterization trick ($z = \mu + \sigma \odot \epsilon$) necessary for backpropagation through the sampling process?

## Architecture Onboarding

- **Component map:**
  Input: Paired/Unpaired PPG & ECG (10-s, 128Hz) -> CardioAlign Encoder ($E_{CA}$) -> Latent Vectors ($\mu, \sigma$) -> Stage 1 Decoders ($D_{PPG}, D_{ECG}$) -> Stage 2 Transformer Velocity Field ($v_\theta$) -> ODE Solver -> Stage 2 Decoder ($D_{ECG}$)

- **Critical path:**
  1. Pre-train **CardioAlign** (Stage 1) until latent space shows overlap (verify via t-SNE) and cross-modal reconstruction loss stabilizes.
  2. Freeze Encoders/Decoders.
  3. Train **Latent Rectified Flow** (Stage 2) to learn the transport vector field conditioned on PPG latents.

- **Design tradeoffs:**
  - **Inference Steps (T):** Paper uses T=10 for evaluation but notes T=5 often works best. T=1 is too low for complex morphology; T=50 is unnecessary due to rectification.
  - **Latent Dimensionality:** Must be high enough to capture diagnostic features but low enough to ensure smooth manifold for flow.

- **Failure signatures:**
  - **High MAE + Low FID:** Model generates plausible average beats but fails on specific patient morphology (check LID strength).
  - **Mode Collapse:** Generated ECGs look identical regardless of input PPG (check GDA/Loss weights).
  - **Divergent ODE:** Loss spikes during Stage 2 (check Stage 1 alignment quality; manifold may be too jagged).

- **First 3 experiments:**
  1. **Stage 1 Sanity Check:** Visualize cross-modal reconstruction. Can $D_{ECG}(E_{CA}(PPG))$ produce a recognizable ECG waveform?
  2. **Latent Space Topology:** Plot t-SNE of PPG and ECG latents. Are they forming separate clusters (bad) or overlapping distributions (good)?
  3. **Step Ablation:** Generate samples with T $\in \{1, 5, 10, 50\}$. Plot MAE vs. T to confirm the "straight" trajectory hypothesis (error should flatten quickly).

## Open Questions the Paper Calls Out
None

## Limitations
- Clinical relevance depends heavily on alignment quality, which is sensitive to dataset heterogeneity and signal quality; generalization to out-of-distribution populations or devices remains unclear.
- Runtime efficiency claims (fewer ODE steps vs. diffusion) lack direct empirical validation with quantitative comparisons.
- Downstream CVD detection results are reported on the same datasets used for training; external validation with clinically labeled test sets is needed.

## Confidence
- **High confidence**: Cross-modal alignment via shared encoder with tripartite loss (L_GDA + L_LID + L_SDC) effectively reduces modality-specific noise while preserving shared physiological semantics, as evidenced by ablation and t-SNE visualizations.
- **Medium confidence**: Latent rectified flow achieves high-fidelity ECG synthesis with fewer ODE steps than diffusion models, but runtime efficiency claims lack direct empirical validation.
- **Low confidence**: Generated ECGs are clinically useful for real-world arrhythmia screening, as cardiologist evaluations are mentioned but not detailed or externally validated.

## Next Checks
1. **External generalization test**: Evaluate the trained model on a held-out clinical cohort from a different institution or device to assess robustness to population and hardware variation.
2. **Runtime benchmarking**: Compare inference time and MAE/RMSE of latent rectified flow (T=10) against a diffusion-based PPGâ†’ECG model under identical hardware to quantify step reduction benefits.
3. **Clinical utility verification**: Conduct a blinded study with multiple cardiologists rating generated vs. real ECGs on diagnostic clarity and arrhythmia detection accuracy to substantiate clinical claims.