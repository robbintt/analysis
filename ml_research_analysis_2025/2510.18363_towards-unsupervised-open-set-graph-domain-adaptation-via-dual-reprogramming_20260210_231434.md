---
ver: rpa2
title: Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming
arxiv_id: '2510.18363'
source_url: https://arxiv.org/abs/2510.18363
tags:
- graph
- domain
- target
- source
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of unsupervised open-set graph
  domain adaptation, where the target graph may contain classes not present in the
  source graph. The authors propose a novel framework called GraphRTA that performs
  dual reprogramming from both the graph and model perspectives.
---

# Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming

## Quick Facts
- arXiv ID: 2510.18363
- Source URL: https://arxiv.org/abs/2510.18363
- Reference count: 40
- Primary result: Novel GraphRTA framework achieves state-of-the-art performance on open-set graph domain adaptation tasks

## Executive Summary
This paper addresses the challenging problem of unsupervised open-set graph domain adaptation, where the target graph may contain classes not present in the source graph. The authors propose GraphRTA, a novel framework that performs dual reprogramming from both graph and model perspectives. The method reprograms the target graph by refining its structure and node features to better align with the source domain while differentiating known and unknown groups. It also reprograms the model by pruning domain-specific parameters based on their gradients, retaining only transferable patterns. The framework achieves significant improvements over state-of-the-art baselines on multiple public datasets.

## Method Summary
GraphRTA addresses open-set graph domain adaptation through a dual reprogramming approach. The method learns to modify the target graph's structure and features (via ΔX_t and ΔA_t) while simultaneously pruning the source model's weights (via gradient-based masking). The framework augments the classifier with an extra dimension for the unknown class, eliminating the need for manual thresholds. A three-way adversarial domain loss uses a Beta Mixture Model on entropy values to separate target-known and target-unknown nodes. The approach is trained end-to-end with alternating updates between the model and graph reprogramming modules.

## Key Results
- GraphRTA consistently outperforms or matches state-of-the-art baselines on multiple datasets
- The dual reprogramming approach shows robustness across different graph structures and domains
- GraphRTA achieves significant improvements in H-score (harmonic mean of known/unknown accuracy)
- The method demonstrates effectiveness on citation networks (DBLPv7, Citationv1, ACMv9) and WebKB datasets

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Based Model Pruning (Transferability Filtering)
- **Claim:** Pruning weights with small gradients selectively removes domain-specific parameters, reducing source bias while preserving transferable patterns.
- **Mechanism:** The framework introduces binary masks $M_l$ over GNN weights $W_l$. It calculates the gradient of the loss with respect to these masks. Weights contributing least to minimizing the loss (low gradient magnitude) are hypothesized to capture domain-specific noise rather than transferable features. These weights are pruned (set to zero), effectively "reprogramming" the pre-trained source model to ignore source-specific quirks.
- **Core assumption:** Low gradient magnitude strictly correlates with low transferability and high domain specificity.
- **Evidence anchors:**
  - [Abstract]: "...reprograms the model by pruning domain-specific parameters based on their gradients, retaining only transferable patterns."
  - [Section 3.3]: "Weights with smaller gradients typically contribute less to reducing the loss and may capture domain-specific patterns that do not help in adapting to the target domain..."
  - [Corpus]: Related work "Open Set Domain Adaptation... via Gradient-aware Separation" supports the viability of using gradient information for separation tasks.
- **Break condition:** If the source and target domains share no underlying structural features (extreme domain gap), gradient-based pruning might degrade the model's ability to learn anything useful, resulting in underfitting.

### Mechanism 2: Graph Reprogramming (Distribution Alignment via Structure/Feature Refinement)
- **Claim:** Modifying the target graph's topology and node features explicitly minimizes distribution shift and separates known/unknown classes.
- **Mechanism:** Instead of adapting the model to fit the raw target graph, the method adapts the *graph* to fit the source-aligned model. It learns a feature offset $\Delta X_t$ and a structural perturbation $\Delta A_t$ (via XOR for edge addition/removal). These parameters are optimized to make the target graph structure and features resemble the source distribution while maximizing the entropy separation between known and unknown nodes.
- **Core assumption:** The structural and feature noise in the target graph is the primary cause of the domain shift, rather than fundamental differences in the data generation process.
- **Evidence anchors:**
  - [Abstract]: "GraphRTA reprograms the target graph by refining its structure and node features to better align with the source domain..."
  - [Section 3.4]: "We modify the target graph's structure and node features to better align with the source domain, while differentiating the known and unknown groups..."
- **Break condition:** If the target graph structure is rigid and meaningful (e.g., molecular graphs), arbitrary edge perturbations could destroy semantic validity, leading to nonsense representations.

### Mechanism 3: Augmented Unknown Class (Threshold-Free Open-Set Recognition)
- **Claim:** Augmenting the classifier with a dedicated "unknown" output dimension allows the model to learn a dynamic decision boundary for novelty detection without manual thresholds.
- **Mechanism:** Standard methods use entropy thresholds to separate known/unknown classes. This method adds an extra learnable class index $|C_s|+1$. During training, source samples are encouraged to have low probability for this class, while certain target samples (identified via Beta Mixture Model on entropy) are pushed toward this class. This transforms the detection problem into a classification problem.
- **Core assumption:** The latent features of "unknown" target nodes form a cluster distinct enough to be captured by a single additional classifier dimension.
- **Evidence anchors:**
  - [Abstract]: "...classifier is augmented with an extra dimension for the unknown class, eliminating the need for manual thresholds."
  - [Section 3.3]: "This mechanism is designed to effectively distinguish between known and unknown classes through using a dynamic threshold based on the input node representation z..."
- **Break condition:** If the "unknown" class is actually a mixture of many diverse classes (multi-modal), forcing them into a single "unknown" cluster might confuse the classifier, causing known classes to leak into the unknown prediction.

## Foundational Learning

- **Concept: Message Passing (GNNs)**
  - **Why needed here:** The method relies on "reprogramming" the weights of GNN layers (Eq. 1). Without understanding how weights aggregate neighbor information ($\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}Z W$), one cannot interpret the impact of pruning $W$ or modifying $\tilde{A}$.
  - **Quick check question:** If you prune 50% of weights in a GCN layer, how does that affect the aggregation of neighbor features compared to pruning 50% of the adjacency matrix?

- **Concept: Domain Adversarial Training (DANN)**
  - **Why needed here:** The core alignment engine uses a Gradient Reversal Layer (GRL) and a domain discriminator to create domain-invariant features.
  - **Quick check question:** Why does the Gradient Reversal Layer force the feature extractor to produce domain-invariant representations?

- **Concept: Lottery Ticket Hypothesis**
  - **Why needed here:** The model reprogramming mechanism is explicitly motivated by this hypothesis (Section 3.3), assuming a sparse subnetwork exists within the source model that works for the target domain.
  - **Quick check question:** Does GraphRTA search for the subnetwork *before* or *during* the adaptation process?

## Architecture Onboarding

- **Component map:** GCN/SAGE/GAT -> Gradient-based weight masks $M_l$ -> Feature offsets $\Delta X_t$ and structure perturbations $\Delta A_t$ -> Classifier with $|C_s|+1$ dimensions -> Beta Mixture Model on entropy -> Domain discriminator with GRL

- **Critical path:**
  1. **Forward Pass:** Pass modified Target Graph ($X_t + \Delta X_t, A_t \oplus \Delta A_t$) through Pruned Model ($W \odot M$).
  2. **Separation:** Calculate entropy, run EM to estimate probability $p(tk|e_i)$ of being target-known.
  3. **Adversarial Loss:** Train Domain Discriminator to distinguish Source vs. Target-Known vs. Target-Unknown, while the feature extractor tries to confuse it.
  4. **Reprogramming Update:** Update Masks $M$ (pruning) and Graph Deltas ($\Delta X, \Delta A$) based on gradients.

- **Design tradeoffs:**
  - **Sparsity Ratio ($\rho$):** High sparsity reduces source bias but risks over-pruning transferable features (Fig 3a shows sharp drop).
  - **Structure Budget ($B$):** Large budget allows more graph modification but risks altering the target graph's semantic meaning. The paper notes performance is relatively robust to this (Fig 3b).
  - **Architecture Choice:** GCN is preferred over GAT. The paper notes GAT's attention mechanism adapts poorly and requires heavy tuning (Table 6).

- **Failure signatures:**
  - **Class Collapse:** High accuracy on "Unknown" but near-zero on "Known" (or vice versa), reflected in a low H-score.
  - **Oscillating Adversarial Loss:** The 3-class domain discriminator (Source, T-Known, T-Unknown) is unstable if the EM separation step fails to converge.
  - **Heterophily Issues:** Performance degrades significantly on heterophilous graphs if the underlying GNN cannot handle them (though GraphRTA improves over baselines, absolute scores are lower).

- **First 3 experiments:**
  1. **Sanity Check (Ablation):** Run GraphRTA without Model Reprogramming ($M=1$) and without Graph Reprogramming ($\Delta=0$) to confirm both modules contribute to the H-score (verify Table 7).
  2. **Architecture Sensitivity:** Swap the backbone from GCN to GAT on the ACMv9 -> Citationv1 task to verify the authors' claim that GAT underperforms due to tuning sensitivity.
  3. **Budget Stress Test:** Increase the structure change budget $B$ significantly beyond the default to see if performance collapses or if the model simply ignores excess capacity (verifying robustness claim in Section 4.3).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the GraphRTA framework be effectively extended to the source-free setting where the source graph is unavailable during the adaptation phase?
- **Basis in paper:** [explicit] The conclusion states the authors aim to "extend our framework to address additional challenges... such as source-free open-set graph domain adaptation."
- **Why unresolved:** The current method relies on accessing the source graph for simultaneous model reprogramming (pruning based on source gradients) and domain adversarial alignment. It is unclear if the transferable patterns can be preserved without direct access to source data or if a source-free variant would require a fundamentally different reprogramming logic.
- **What evidence would resolve it:** A modified version of GraphRTA trained in a source-free setting achieving comparable H-scores to the current state-of-the-art source-free baselines on the Citation and WebKB datasets.

### Open Question 2
- **Question:** How does the performance of the dual reprogramming mechanism change in a semi-supervised open-set setting where limited target labels are available?
- **Basis in paper:** [explicit] The conclusion lists "semi-supervised open-set graph domain adaptation" as a specific future direction for extending the framework.
- **Why unresolved:** The current model is strictly unsupervised on the target domain. It is unknown if introducing sparse target labels would improve the Beta mixture model's ability to separate known/unknown groups or if the graph reprogramming module would overfit to the limited labeled samples.
- **What evidence would resolve it:** Empirical evaluation showing the model's H-score trajectory as the percentage of labeled target nodes increases, specifically analyzing if the known-class accuracy improves without degrading unknown-class detection.

### Open Question 3
- **Question:** To what extent does integrating Large Language Model (LLM) semantic explanations improve the robustness of open-set graph domain adaptation?
- **Basis in paper:** [explicit] Appendix C discusses "Potential of LLM Integration" and concludes that "leveraging LLM-generated semantic knowledge can substantially benefit open-set scenarios... We consider this a promising direction for future research."
- **Why unresolved:** The paper only provides a preliminary pilot study (Table 10) on the ogbn-arxiv dataset using a simple concatenation of LLM explanations. It does not explore deeper architectural integrations or analyze if LLMs help distinguish semantic shift (domain shift) from semantic novelty (unknown class).
- **What evidence would resolve it:** A comprehensive study across multiple text-rich graphs comparing standard features against LLM-augmented features, specifically measuring if the Margin MMD between known and unknown classes increases in the feature space.

## Limitations

- **Hyperparameter Sensitivity**: Critical hyperparameters (sparsity ρ, structure budget B, learning rates, λ weights) are only provided as ranges without optimal values per dataset, making faithful reproduction difficult.
- **Architecture Specifications**: Exact GNN architecture details (number of layers, hidden dimensions) and domain discriminator MLP architecture are not specified, which could significantly impact performance.
- **Dataset Construction**: Specific train/val/test splits and class partitioning schemes used to create "unknown" classes are not detailed, making it unclear if reported results are directly comparable to future work.

## Confidence

- **High Confidence**: The core dual reprogramming mechanism (gradient-based model pruning and graph structure refinement) is well-specified and theoretically sound.
- **Medium Confidence**: The three-way adversarial domain loss and Beta Mixture Model separation approach appears technically sound but requires careful implementation.
- **Low Confidence**: The exact experimental setup and hyperparameter configurations that produced the reported results.

## Next Checks

1. **Ablation Study Reproduction**: Replicate the ablation experiments (Table 7) to verify that both model and graph reprogramming modules contribute to the H-score improvements.

2. **Architecture Sensitivity Test**: Swap the backbone from GCN to GAT on a single dataset (e.g., ACMv9 → Citationv1) to verify the authors' claim that GAT underperforms due to tuning sensitivity.

3. **Budget Stress Test**: Systematically vary the structure change budget B beyond default values to verify the claimed robustness to this hyperparameter.