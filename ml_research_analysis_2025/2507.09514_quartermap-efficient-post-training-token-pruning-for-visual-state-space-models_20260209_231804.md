---
ver: rpa2
title: 'QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models'
arxiv_id: '2507.09514'
source_url: https://arxiv.org/abs/2507.09514
tags:
- quartermap
- pruning
- vmamba
- accuracy
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QuarterMap is a post-training activation pruning method designed
  to improve the runtime efficiency of visual State Space Models (SSMs) like VMamba.
  It reduces spatial redundancy in activation maps by pruning spatial dimensions before
  the scanning operation and restoring them via nearest-neighbor upsampling.
---

# QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models

## Quick Facts
- **arXiv ID:** 2507.09514
- **Source URL:** https://arxiv.org/abs/2507.09514
- **Reference count:** 34
- **Primary result:** Achieves up to 11% speedup on ImageNet-1K with <0.9% accuracy drop on VMamba via post-training spatial activation pruning.

## Executive Summary
QuarterMap is a training-free method for accelerating visual State Space Models (SSMs) like VMamba by removing spatial redundancy in activation maps before the four-directional scanning operation. It applies fixed-interval pruning to reduce resolution, leverages the cross-scan mechanism to preserve context, and restores dimensions via nearest-neighbor upsampling. The method achieves significant inference speedup without retraining and is specifically designed for SSMs' unique architectural structure. QuarterMap is not applicable to CNNs or 1D-scanning SSMs due to their different spatial processing mechanisms.

## Method Summary
QuarterMap reduces computational latency by pruning spatial dimensions of activation maps before the selective scan operation in VMamba models. It applies a fixed pruning interval (m=2, n=1) to downsample resolution to 1/4, processes the reduced map through the cross-scan and selective scan mechanisms, then restores original dimensions using nearest-neighbor upsampling. The method is applied selectively to every third block (k=3), excluding the first layer, based on empirical optimization. QuarterMap is specifically effective for SSMs due to their four-directional scanning structure and avoids costly merge-unmerge operations compared to token merging methods.

## Key Results
- Achieves up to 11% inference speedup on ImageNet-1K with less than 0.9% accuracy drop on VMamba models
- Improves throughput by 1.21× on MedMamba for medical imaging tasks without accuracy loss
- Demonstrates effectiveness on both classification (ImageNet-1K) and segmentation (ADE20K) tasks

## Why This Works (Mechanism)

### Mechanism 1: Spatial Redundancy Exploitation
Reducing spatial resolution prior to the selective scan significantly lowers computational latency with minimal impact on feature integrity. The method relies on the Cross-Scan operation to aggregate information from four spatial directions, ensuring remaining tokens absorb context from pruned neighbors. This works because adjacent spatial positions in the feature map convey similar information.

### Mechanism 2: Efficient Upsampling Strategy
Nearest-neighbor upsampling provides optimal efficiency-accuracy trade-off for restoring dimensions post-scan compared to interpolation-based methods. Unlike bilinear or bicubic methods which require multiple memory accesses and multiplication operations per pixel, nearest-neighbor simply copies values, minimizing overhead. The selective scan and cross-merge operations successfully redistribute key semantic information such that simple value replication is sufficient to reconstruct the spatial map.

### Mechanism 3: Strategic Layer Application
Applying pruning to specific blocks (skipping early layers) preserves the model's ability to encode fundamental features. The network exhibits layer-wise redundancy variance; deeper semantic layers can operate on lower-resolution activations without destroying the hierarchical features built by earlier stages. Early layers are critical for low-level feature encoding, while deeper layers are more resilient to resolution drop.

## Foundational Learning

- **Concept: 2D Selective Scan (SS2D) in VMamba**
  - Why needed: QuarterMap is explicitly designed around the Cross-Scan and Cross-Merge operations of VMamba
  - Quick check: How does the Cross-Scan mechanism differ from standard 1D scanning in SSMs like ViM?

- **Concept: Token Pruning vs. Token Merging**
  - Why needed: The paper positions QuarterMap as a superior alternative to Token Merging (ToMe) for SSMs
  - Quick check: Why does ToMe incur a "merge-unmerge" overhead that QuarterMap avoids?

- **Concept: Post-Training Optimization**
  - Why needed: QuarterMap is a "training-free" method that relies on existing robustness of pre-trained weights
  - Quick check: Does QuarterMap require a dataset to calibrate the pruning mask, or can it be applied strictly to the model architecture at inference time?

## Architecture Onboarding

- **Component map:** Input activation map -> Pruning Stage (T) -> Cross-Scan -> Selective Scan -> Cross-Merge -> Upsampling Stage (U)
- **Critical path:** The Selective Scan kernel is the primary bottleneck. QuarterMap targets the input length of this specific component. The pruning (T) and upsampling (U) operations must be lightweight enough that their execution time is less than the time saved by reducing the scan length.
- **Design tradeoffs:**
  - Speed vs. Accuracy: Controlled by block interval k. Smaller k increases speed but hurts accuracy
  - Generality: QuarterMap is brittle on CNNs (breaks spatial continuity) and 1D SSMs (lacks 4-way redundancy)
- **Failure signatures:**
  - Catastrophic Accuracy Drop: Occurs if applied to the first layer or to CNN architectures
  - No Speedup: Occurs if upsampling implementation is inefficient
  - Segmentation Artifacts: Excessive pruning leads to mIoU drops > 2%
- **First 3 experiments:**
  1. Baseline Verification: Run VMamba-B checkpoint on ImageNet-1K validation to reproduce baseline throughput (590 img/s) and accuracy (83.88%)
  2. Pareto Curve Profiling: Implement QuarterMap block selection logic, sweep k ∈ {2, 3, 4} to reproduce trade-off curve, verify k=3 is optimal
  3. Overhead Analysis: Profile execution time of Pruning (T) and Upsampling (U) modules separately, verify combined overhead (~0.2ms) doesn't exceed scan savings (~0.8ms)

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the cumulative efficiency gains and accuracy impacts when combining QuarterMap with model quantization techniques?
  - Basis: The conclusion states QuarterMap is orthogonal to techniques such as quantization
  - Why unresolved: Authors validate QuarterMap as standalone method but don't provide results on interaction with compression methods
  - Evidence needed: Evaluation of VMamba models applying both QuarterMap and standard quantization

- **Open Question 2:** Can the pruning strategy be modified to remain effective for 1D-scanning State Space Models (SSMs) like ViM?
  - Basis: Table 3 and Section 3.3 show QuarterMap causes significant accuracy drop on ViM-B (80.40% → 71.00%)
  - Why unresolved: Method relies on VMamba's four-directional scan to aggregate context before pruning
  - Evidence needed: Variant of pruning mechanism tailored for unidirectional scans

- **Open Question 3:** Does a content-adaptive pruning ratio improve the trade-off compared to the fixed 1/4 resolution reduction?
  - Basis: Method enforces static pruning interval (m=2, n=1) and fixed block selection strategy (k=3)
  - Why unresolved: Spatial redundancy likely varies across different images and network layers
  - Evidence needed: Results from dynamic pruning mechanism that adjusts reduction factor based on activation entropy or variance

## Limitations

- Architecture Specificity: Effectiveness tightly coupled to VMamba's four-directional scanning structure; fails catastrophically on CNNs and 1D-scanning SSMs
- Layer-wise Sensitivity: Optimal pruning schedule (k=3, skipping first layer) empirically determined but lacks theoretical justification for generalization across model variants
- Medical Imaging Validation: Promising results but under-explored; lacks detailed analysis of failure modes in clinically sensitive contexts

## Confidence

- **High Confidence:** Core mechanism of spatial pruning before cross-scan and nearest-neighbor upsampling is well-validated; efficiency gains demonstrated across multiple datasets with proper baselines
- **Medium Confidence:** Block selection strategy (k=3, excluding first layer) is empirically optimal but lacks theoretical grounding; spatial redundancy assumption supported but not stress-tested on high-frequency tasks
- **Low Confidence:** Performance on medical imaging datasets is promising but under-explored; lacks investigation of clinically relevant metrics or analysis of when spatial redundancy assumption might fail

## Next Checks

1. **Boundary Sensitivity Test:** Apply QuarterMap to high-precision segmentation task (e.g., medical image segmentation with fine boundaries) and measure mIoU degradation when pruning is applied to early vs. late layers to validate spatial redundancy assumption for high-frequency content

2. **Architectural Transferability:** Modify QuarterMap to work with hybrid architecture combining CNN early layers with SSM deeper layers to test whether method can be adapted to benefit from spatial redundancy in CNN portion while preserving SSM efficiency gains

3. **Hardware Dependency Analysis:** Profile QuarterMap's speedup on different hardware platforms (CPU, TPU, mobile GPU) to determine whether reported 11% improvement is platform-specific or generalizes across deployment targets, validating deployment-time efficiency claim