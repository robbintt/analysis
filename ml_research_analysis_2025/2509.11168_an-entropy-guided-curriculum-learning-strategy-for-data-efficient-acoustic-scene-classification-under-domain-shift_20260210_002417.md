---
ver: rpa2
title: An Entropy-Guided Curriculum Learning Strategy for Data-Efficient Acoustic
  Scene Classification under Domain Shift
arxiv_id: '2509.11168'
source_url: https://arxiv.org/abs/2509.11168
tags:
- domain
- training
- learning
- curriculum
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of acoustic scene classification
  (ASC) under domain shift, specifically when models are trained on limited data from
  a few devices but must generalize to unseen devices. The authors propose an entropy-guided
  curriculum learning strategy to tackle this problem without modifying the model
  architecture or adding inference overhead.
---

# An Entropy-Guided Curriculum Learning Strategy for Data-Efficient Acoustic Scene Classification under Domain Shift

## Quick Facts
- arXiv ID: 2509.11168
- Source URL: https://arxiv.org/abs/2509.11168
- Authors: Peihong Zhang; Yuxuan Liu; Zhixin Li; Rui Sang; Yiqiang Cai; Yizhou Tan; Shengchen Li
- Reference count: 29
- Primary result: +1.6% to +2.5% accuracy improvement on unseen devices under 5% training data across three DCASE 2024 baselines

## Executive Summary
This paper addresses acoustic scene classification (ASC) under domain shift, specifically when models trained on limited data from a few devices must generalize to unseen devices. The authors propose an entropy-guided curriculum learning strategy that uses Shannon entropy of device posterior probabilities as a proxy for domain invariance. By prioritizing domain-invariant samples in early training stages, the method improves cross-device generalization without modifying model architecture or adding inference overhead. Experiments on DCASE 2024 Task 1 baselines show consistent performance improvements, particularly under low-resource conditions.

## Method Summary
The method employs an auxiliary device classifier to estimate domain uncertainty for each training sample via Shannon entropy. Samples with higher entropy are considered more domain-invariant and prioritized in early training. The curriculum splits samples at the median entropy into domain-invariant (Xinv) and domain-specific (Xspec) subsets. Stage 1 trains exclusively on Xinv to learn generalizable representations, while Stage 2 mixes both subsets at an 80:20 ratio to incorporate device-specific information. The approach is architecture-agnostic and integrates seamlessly into existing ASC models without inference overhead.

## Key Results
- 5% training data: Accuracy on unseen devices improves from 52.7% to 55.2% for top-ranked system
- Consistent improvements across three baseline systems (CP-Mobile, CP-MobileV2, SED-MobileVGG) at 5% and 10% data regimes
- Gains diminish with more training data (0.16%-0.38% at 100% data)
- No performance degradation on seen devices while improving generalization to unseen devices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High Shannon entropy in device posterior distributions correlates with greater domain invariance in acoustic samples.
- Mechanism: An auxiliary device classifier processes each training sample through a frozen feature extractor. When the resulting device posterior distribution exhibits high entropy, the sample confuses the classifier—suggesting it lacks strong device-specific characteristics. These samples are labeled as "domain-invariant" and prioritized early in training.
- Core assumption: Samples that confuse a device classifier are genuinely more transferable across devices, not simply ambiguous or noisy.
- Evidence anchors: [abstract] "Using entropy as a proxy for domain invariance, the curriculum begins with high-entropy samples and gradually incorporates low-entropy, domain-specific ones to facilitate the learning of generalizable representations."
- Break condition: If device classifier is undertrained or overfitted, entropy estimates become unreliable, misclassifying domain-specific samples as invariant.

### Mechanism 2
- Claim: Training on domain-invariant samples before domain-specific ones improves cross-device generalization under limited supervision.
- Mechanism: The curriculum splits samples at the median entropy into Xinv (top 50%) and Xspec (bottom 50%). Stage 1 trains exclusively on Xinv; Stage 2 mixes both subsets at an 80:20 ratio. This staged exposure allows the model to first learn transferable acoustic features before adapting to device-specific variations.
- Core assumption: Early exposure to domain-specific samples biases representation learning toward device artifacts; delaying this exposure mitigates the bias.
- Evidence anchors: [section 2.1] "early exposure to domain-specific samples may bias the internal representation space of the model, steering the learning process toward device-dependent features"
- Break condition: If the 50% split threshold does not align with actual domain invariance distribution, the curriculum may introduce domain-specific samples too early or too late.

### Mechanism 3
- Claim: Controlling sample presentation order improves generalization without architectural changes or inference overhead.
- Mechanism: The entropy calculation and curriculum construction occur entirely as a preprocessing step. During inference, only the standard scene classifier is used. The auxiliary device classifier is discarded after curriculum construction.
- Core assumption: The benefits of curriculum-ordered training persist through full model convergence and transfer to unseen devices.
- Evidence anchors: [abstract] "This strategy is architecture-agnostic, introduces no additional inference overhead, and integrates seamlessly into existing ASC models."
- Break condition: If training data distribution is highly imbalanced across devices, the median split may overrepresent dominant-device samples in one subset.

## Foundational Learning

- Concept: **Curriculum Learning**
  - Why needed here: The method builds on the principle that models learn better when presented with easier examples before harder ones. Understanding this paradigm helps explain why entropy-ordered training might outperform random shuffling.
  - Quick check question: Can you explain why training on "easy" samples first might lead to better generalization than random sampling?

- Concept: **Shannon Entropy**
  - Why needed here: Entropy quantifies uncertainty in a probability distribution. The method uses entropy of device posteriors as a scalar measure of how device-ambiguous a sample is.
  - Quick check question: Given a probability distribution [0.9, 0.05, 0.05] versus [0.33, 0.33, 0.34], which has higher entropy and why?

- Concept: **Domain Shift / Domain Generalization**
  - Why needed here: The core problem is that models trained on recordings from one set of devices fail to generalize to unseen devices due to device-specific spectral characteristics.
  - Quick check question: Why does domain shift degrade model performance, and how does it differ from standard overfitting?

## Architecture Onboarding

- Component map:
  - Feature extractor (ffeat) -> Scene classifier (fcls) -> Acoustic scene prediction
  - Feature extractor (ffeat) -> Auxiliary device classifier (fdom) -> Device posterior probabilities
  - Device posteriors -> Entropy computation module -> Sample ranking by entropy
  - Entropy ranking -> Curriculum scheduler -> Partition into Xinv/Xspec subsets

- Critical path:
  1. Train or load pretrained feature extractor ffeat
  2. Freeze ffeat; train fdom on device classification using labeled training data
  3. Compute entropy H(x) for every training sample using fdom outputs
  4. Sort samples by entropy; split at median to create Xinv and Xspec
  5. Train scene classifier: Stage 1 on Xinv only → Stage 2 on 80:20 mix until convergence

- Design tradeoffs:
  - Median vs. adaptive threshold: The paper uses a fixed 50% split for simplicity; adaptive thresholds could better handle skewed entropy distributions but add complexity
  - 80:20 mix ratio: Chosen empirically; higher Xspec ratios might introduce domain bias too quickly, lower ratios may underutilize hard samples
  - Device classifier complexity: A two-layer MLP is lightweight but may underfit device prediction; deeper classifiers could improve entropy estimates but increase preprocessing cost

- Failure signatures:
  - No improvement on unseen devices: Likely entropy estimates are corrupted (device classifier undertrained) or Xinv is contaminated with domain-specific samples
  - Performance degrades vs. baseline: Check that the same hyperparameters (optimizer, learning rate, epochs) are used; curriculum should not alter these
  - Large discrepancy between seen and unseen device gains: May indicate curriculum is helping only on source-device data, suggesting Xinv is not truly domain-invariant

- First 3 experiments:
  1. Baseline replication: Reproduce one DCASE 2024 baseline (e.g., CP-Mobile) without curriculum to establish reference accuracy on seen/unseen devices under 5% and 100% data
  2. Ablation on entropy split: Vary the split threshold (e.g., 30%, 50%, 70%) to test whether the median is optimal or whether dataset-specific tuning is needed
  3. Device classifier capacity test: Compare a 2-layer MLP vs. a deeper classifier (e.g., 4-layer) for entropy estimation; measure correlation between entropy and actual cross-device transfer performance

## Open Questions the Paper Calls Out
- How does the performance of the fixed threshold-based curriculum compare to adaptive or continuous weighting schemes? (Future work will explore adaptive or weighted curriculum scheduling schemes)
- Is the median threshold the optimal partition point for separating domain-invariant and domain-specific samples? (The paper selects the median as a "simple yet effective proxy" without ablation study)
- Does high entropy consistently correlate with semantic domain invariance, or does it risk selecting ambiguous or noisy samples? (Without analyzing the feature geometry, it's unclear if the strategy filters out device-specific artifacts)

## Limitations
- Limited independent verification that high entropy truly correlates with domain invariance beyond the auxiliary classifier's perspective
- The 50% median split is a heuristic choice without theoretical justification for optimal domain invariance separation
- No ablation studies showing entropy's correlation with actual cross-device transfer metrics

## Confidence
- Mechanism 1 (entropy correlates with invariance): Medium - supported by empirical results but lacks direct validation
- Mechanism 2 (curriculum order matters): Medium - improvements are consistent but could be partially attributed to data filtering
- Mechanism 3 (no overhead): High - clearly demonstrated as preprocessing-only with no inference modifications

## Next Checks
1. Conduct ablation studies varying the entropy threshold (30%, 50%, 70%) to determine if the median split is optimal or dataset-specific
2. Perform cross-validation where the device classifier is trained on different subsets to assess entropy estimate stability across training runs
3. Measure actual domain invariance of X_inv samples by testing their transferability to completely new device types not present in training