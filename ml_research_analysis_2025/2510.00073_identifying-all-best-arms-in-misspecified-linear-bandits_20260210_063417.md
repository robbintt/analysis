---
ver: rpa2
title: "Identifying All \u03B5-Best Arms in (Misspecified) Linear Bandits"
arxiv_id: '2510.00073'
source_url: https://arxiv.org/abs/2510.00073
tags:
- arms
- best
- bound
- algorithm
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of identifying all \u03B5-best\
  \ arms in linear bandit settings, motivated by applications like drug discovery\
  \ where identifying multiple promising candidates is valuable. The authors introduce\
  \ LinFACT, a near-optimal algorithm that efficiently identifies all arms within\
  \ \u03B5 of the best arm, overcoming limitations of conventional approaches that\
  \ focus only on the single best arm or a fixed number of top arms."
---

# Identifying All ε-Best Arms in (Misspecified) Linear Bandits

## Quick Facts
- arXiv ID: 2510.00073
- Source URL: https://arxiv.org/abs/2510.00073
- Authors: Zhekai Li; Tianyi Ma; Cheng Hua; Ruihao Zhu
- Reference count: 40
- Key outcome: Introduces LinFACT algorithm for identifying all ε-best arms in linear bandits with instance-optimal sample complexity

## Executive Summary
This paper addresses the problem of identifying all arms within ε of the best arm in linear bandit settings, motivated by applications like drug discovery where multiple promising candidates need to be discovered. The authors introduce LinFACT, a near-optimal algorithm that efficiently identifies all ε-best arms, overcoming limitations of conventional approaches that focus only on the single best arm. They establish the first information-theoretic lower bound for this problem and demonstrate that LinFACT matches this bound up to a logarithmic factor, proving its instance optimality. The algorithm employs a phase-based approach with XY-optimal sampling designs and extends to handle model misspecification and generalized linear models.

## Method Summary
The paper proposes LinFACT, a phase-based algorithm for identifying all ε-best arms in linear bandit settings. The algorithm operates in rounds, maintaining confidence sets for the parameter θ and using either G-optimal or XY-optimal sampling designs. The XY-optimal design focuses on distinguishing between arms rather than estimating individual means, proving superior to traditional G-optimal sampling. The method extends to handle model misspecification and generalized linear models by incorporating additional terms to account for approximation errors and using local linearization techniques. The algorithm achieves time complexity of O(Kd²), significantly better than competing methods, and provides both theoretical guarantees and practical performance improvements.

## Key Results
- Establishes the first information-theoretic lower bound for identifying all ε-best arms in linear bandits
- Proves LinFACT is instance-optimal, matching the lower bound up to a logarithmic factor
- Achieves O(Kd²) time complexity compared to O(K²d²) of competing methods
- Demonstrates superior performance on synthetic and real drug discovery data with higher F1 scores and lower sample complexity

## Why This Works (Mechanism)
The algorithm works by strategically focusing sampling on arms that are difficult to distinguish from the ε-best set boundary. The XY-optimal design specifically targets pairs of arms where the confidence regions overlap significantly, maximizing information gain per sample about which arms belong in the ε-optimal set. This contrasts with traditional approaches that focus on accurate mean estimation for all arms. The phase-based structure allows for adaptive refinement of confidence regions, progressively narrowing down the candidate set until all ε-best arms are identified with high confidence.

## Foundational Learning
- Linear bandit theory: Why needed - provides the mathematical foundation for analyzing multi-armed bandit problems with linear rewards; Quick check - verify understanding of confidence bounds and sample complexity
- Optimal experimental design: Why needed - enables efficient allocation of samples to maximize information gain; Quick check - understand difference between G-optimal and XY-optimal designs
- ε-best arm identification: Why needed - addresses practical need to find multiple good candidates rather than just the single best arm; Quick check - contrast with pure exploration vs. best arm identification
- Model misspecification handling: Why needed - real-world applications rarely satisfy perfect linear assumptions; Quick check - verify bounds account for approximation error terms

## Architecture Onboarding
Component map: Data collection -> Parameter estimation -> Confidence set update -> Arm elimination -> Repeat until convergence

Critical path: Sampling phase (G-optimal/XY-optimal design) -> Parameter estimation via ridge regression -> Confidence set construction -> ε-optimal set identification -> Termination check

Design tradeoffs: G-optimal sampling minimizes maximum variance but may waste samples on easily distinguishable arms; XY-optimal sampling focuses on boundary arms but requires more computation per round. The phase-based structure trades off between exploration and exploitation, allowing progressive refinement.

Failure signatures: Algorithm may fail to terminate if ε is too small relative to noise level; excessive samples may be needed if confidence parameters are set too conservatively; incorrect parameter estimation can lead to wrong arm elimination.

First experiments: 1) Verify convergence on synthetic linear bandit with known ground truth 2) Compare sample complexity against theoretical lower bound 3) Test robustness to varying levels of model misspecification

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Theoretical guarantees assume existence of non-empty ε-optimal set, which may not hold in all scenarios
- Empirical validation limited to relatively small-scale problems (up to 1000 arms), not tested in truly large-scale settings
- Extension to generalized linear models relies on stronger assumptions about link function that may not hold in practice

## Confidence
- Theoretical lower bound and algorithm optimality: High confidence
- Practical performance claims: Medium confidence (based on limited experimental scale)
- Extension to misspecified settings: Medium confidence (theoretical but limited empirical validation)

## Next Checks
1. Scale experiments to problems with 10,000+ arms to validate performance claims in realistic drug discovery settings
2. Test algorithm robustness across different types of misspecification and varying levels of noise in the linear model
3. Compare against state-of-the-art ε-best arm identification methods on real-world drug discovery datasets with ground truth active compounds