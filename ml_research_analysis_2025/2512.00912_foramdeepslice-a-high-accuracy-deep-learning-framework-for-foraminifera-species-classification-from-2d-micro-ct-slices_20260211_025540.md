---
ver: rpa2
title: 'ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species
  Classification from 2D Micro-CT Slices'
arxiv_id: '2512.00912'
source_url: https://arxiv.org/abs/2512.00912
tags:
- classification
- species
- deep
- learning
- foraminifera
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a high-accuracy deep learning framework for
  classifying 12 foraminifera species using 2D micro-CT slices. The authors curated
  a rigorous dataset of 109,617 slices from 97 specimens and employed specimen-level
  data splitting to avoid leakage.
---

# ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices

## Quick Facts
- arXiv ID: 2512.00912
- Source URL: https://arxiv.org/abs/2512.00912
- Reference count: 40
- Key outcome: 95.64% test accuracy, 99.6% top-3 accuracy, 0.998 AUC for 12 foraminifera species classification

## Executive Summary
This study introduces a high-accuracy deep learning framework for classifying 12 foraminifera species using 2D micro-CT slices. The authors curated a rigorous dataset of 109,617 slices from 97 specimens and employed specimen-level data splitting to avoid leakage. Seven CNN architectures were evaluated using transfer learning, with a PatchEnsemble of ConvNeXt-Large and EfficientNetV2-Small achieving 95.64% test accuracy, 99.6% top-3 accuracy, and 0.998 AUC. The method addresses the challenge of accurate species classification from complex 3D morphological data and includes an interactive dashboard for real-time classification and 3D slice matching using similarity metrics like SSIM and NCC. The work establishes new benchmarks for AI-assisted micropaleontological identification and offers a fully reproducible framework for fossil classification research.

## Method Summary
The framework extracts 2D slices from 3D micro-CT scans of foraminifera specimens, applies specimen-level data splitting to prevent leakage, and trains CNN models using transfer learning from ImageNet weights. The pipeline uses a two-phase training approach with geometric and color augmentations, CutMix, and Mixup regularization. The PatchEnsemble combines ConvNeXt-Large and EfficientNetV2-Small using confidence-based switching logic to improve classification of difficult species. The final model achieves 95.64% top-1 accuracy with 99.6% top-3 accuracy on a test set of 51,468 slices.

## Key Results
- Achieved 95.64% top-1 accuracy and 99.6% top-3 accuracy on 12 foraminifera species
- PatchEnsemble improved Baculogypsina F1-score from 0.389 to 0.752
- Specimen-level data splitting prevented up to 55% accuracy inflation from leakage
- Interactive dashboard provides real-time classification and 3D slice matching with SSIM/NCC/Dice metrics

## Why This Works (Mechanism)

### Mechanism 1: Transfer Learning from Natural Images to Micro-CT Slices
ImageNet-pretrained CNN features provide useful initialization for micro-CT fossil classification despite domain shift. The two-phase training approach—freezing the backbone for 10 epochs then unfreezing for full fine-tuning—allows the classifier head to adapt before modifying low-level features. Edge, texture, and shape detectors learned from natural images transfer to grayscale micro-CT slice morphologies.

### Mechanism 2: PatchEnsemble with Confidence-Based Switching
Selectively routing predictions based on model confidence improves classification of morphologically ambiguous species compared to simple majority voting. The PatchEnsemble combines ConvNeXt-Large (best overall accuracy) with EfficientNetV2-Small (stronger on difficult classes) using confidence thresholds rather than uniform aggregation.

### Mechanism 3: Specimen-Level Data Splitting to Prevent Leakage
Enforcing specimen-level train/test separation prevents over-optimistic accuracy estimates. All 2D slices derived from one 3D micro-CT specimen are assigned to a single split, ensuring the model cannot memorize specimen-specific artifacts. This approach avoids the train-test contamination common in slice-level splits, which can overestimate accuracy by up to 55%.

## Foundational Learning

- **Transfer Learning**: Understanding what transfers and what doesn't is critical for debugging poor performance. Quick check: Can you explain why freezing the backbone first, then unfreezing, might prevent catastrophic forgetting of useful pretrained features?

- **Data Leakage in Volumetric Image Classification**: Understanding this is essential for proper experimental design. Quick check: If you randomly shuffle 2D slices from 3D volumes into train/test sets, what specific information might leak?

- **Precision-Recall Tradeoffs in Multi-Class Classification**: Interpreting high precision but low recall (or vice versa) requires understanding the tradeoff. Quick check: A classifier with 99% precision but 25% recall—what does this mean operationally for a paleontologist using this tool?

## Architecture Onboarding

- **Component map**: Micro-CT volumes -> Otsu thresholding + segmentation -> 2D slice extraction (109,617 images) -> Geometric/color augmentation -> One of 7 CNN architectures -> PatchEnsemble aggregation -> Interactive dashboard (classification + 3D slice matching with SSIM/NCC/Dice)

- **Critical path**: Specimen-level split assignment (prevents leakage) -> Slice quality filtering via Otsu thresholding -> Two-phase training with cosine LR scheduling -> F1-score-guided selection of PatchEnsemble components -> Dashboard deployment with preprocessing pipeline

- **Design tradeoffs**: ConvNeXt-Large (95% accuracy, higher compute) vs. EfficientNetV2-Small (91.8% accuracy, lighter)—the ensemble captures both. Top-3 accuracy (99.6%) vs. top-1 accuracy (95.64%)—for decision-support tools, top-3 may be more operationally meaningful. Strict specimen splitting reduces apparent performance but improves real-world reliability.

- **Failure signatures**: Baculogypsina: Model is highly conservative (won't predict this class unless very confident), resulting in many false negatives. Orbitoides: Model over-predicts this class (false positives), potentially due to extraction damage creating ambiguous features.

- **First 3 experiments**:
  1. Train ResNet101V2 with specimen-level vs. slice-level splits on your own data; quantify the leakage inflation gap.
  2. Train ConvNeXt-Large and EfficientNetV2-Small independently; identify which classes each struggles with before attempting ensemble strategies.
  3. For your hardest classes, visualize slices where the model is least confident; check if failure correlates with specimen damage or intrinsic morphological variability.

## Open Questions the Paper Calls Out

- Can the framework be extended to accurately distinguish homeomorphic taxa—species from different geological ages that have evolved similar morphologies—without relying on geological context? The current model is trained only on specific listed species and lacks the geological context or stratigraphic data that human experts use to differentiate homeomorphs.

- How can the classification accuracy of specimens with extraction-induced damage (cracks, fractures, or missing fragments) be further improved beyond the current PatchEnsemble approach? While PatchEnsemble mitigates some issues, Orbitoides specimens with physical deformations still suffer from lower precision, and the current study did not focus on repairing or robustly ignoring such damage.

- What is the quantitative performance and robustness of the ForamDeepSlice model when applied to non-micro-CT imaging modalities, such as optical microscopy? The model was trained exclusively on micro-CT data; the example provided is anecdotal, and the specific preprocessing or domain adaptation required for widespread use with optical images has not been systematically evaluated.

## Limitations

- PatchEnsemble mechanism lacks complete algorithmic detail; confidence-based switching logic is described conceptually but not fully specified for reproduction
- Dataset access requires external repository download not explicitly linked in the paper text
- Class-specific failures are attributed to morphological variability and damage but require validation on independent datasets

## Confidence

- **High confidence**: Transfer learning effectiveness, specimen-level splitting benefits, overall accuracy metrics
- **Medium confidence**: PatchEnsemble mechanism effectiveness, top-3 accuracy operational value
- **Low confidence**: Specific failure mode attributions for individual species without independent validation

## Next Checks

1. Verify specimen-level vs. slice-level splitting inflation by reproducing with both methods on the same dataset and measuring accuracy differences
2. Implement and test the PatchEnsemble confidence thresholds independently to confirm the reported Baculogypsina recall improvement
3. Apply the trained model to a new, independent micro-CT foraminifera dataset to assess true generalization beyond the curated 97 specimens