---
ver: rpa2
title: 'SeSE: A Structural Information-Guided Uncertainty Quantification Framework
  for Hallucination Detection in LLMs'
arxiv_id: '2511.16275'
source_url: https://arxiv.org/abs/2511.16275
tags:
- uni00000016
- semantic
- uni00000014
- sese
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SeSE is a principled black-box uncertainty quantification framework
  that detects hallucinations in large language models by quantifying semantic structural
  uncertainty. It constructs an optimal hierarchical encoding tree to model semantic
  space structure and computes structural entropy as an uncertainty measure, generalizing
  semantic entropy.
---

# SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs

## Quick Facts
- **arXiv ID:** 2511.16275
- **Source URL:** https://arxiv.org/abs/2511.16275
- **Reference count:** 40
- **Primary result:** Outperforms state-of-the-art baselines across 24 model-dataset combinations, achieving up to 15.3% AUROC improvement.

## Executive Summary
SeSE is a black-box uncertainty quantification framework that detects hallucinations in large language models by quantifying semantic structural uncertainty. It constructs an optimal hierarchical encoding tree to model semantic space structure and computes structural entropy as an uncertainty measure, generalizing semantic entropy. The framework outperforms state-of-the-art baselines across 24 model-dataset combinations, achieving up to 15.3% AUROC improvement and providing interpretable, claim-level uncertainty estimates for long-form generation.

## Method Summary
SeSE constructs a directed semantic graph from N sampled responses using an NLI model to capture pairwise entailment relationships. A greedy algorithm optimizes a hierarchical encoding tree of height K to minimize structural entropy, which serves as the uncertainty score. For long-form generation, SeSE decomposes the greedy response into atomic claims and builds a bipartite graph between claims and responses, computing claim-level uncertainty via path entropy in the optimized tree.

## Key Results
- Achieves up to 15.3% AUROC improvement over state-of-the-art baselines
- Demonstrates superior performance across 24 model-dataset combinations
- Provides interpretable, claim-level uncertainty estimates for long-form generation
- Shows diminishing returns in performance beyond N=10 samples

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A directed, weighted semantic graph models pairwise entailment between LLM responses more expressively than undirected or cluster-based approaches.
- **Mechanism:** For each ordered pair of sampled responses, an NLI model outputs entailment, neutrality, and contradiction probabilities. These are combined into a directed edge weight, then normalized to form a stochastic transition matrix suitable for a random walk.
- **Core assumption:** The NLI model's probabilities accurately reflect semantic entailment in the context of the query.
- **Evidence anchors:**
  - [abstract]: "develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies"
  - [Section 3.1, "Semantic Graph Construction"]: Describes NLI-based weight calculation and transition matrix construction.
  - [corpus]: Related work "Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection" supports graph-based uncertainty modeling, though it does not specifically validate the directed, NLI-weighted construction.
- **Break condition:** If the NLI model exhibits systematic bias (e.g., over-entailment) or fails on domain-specific language, the transition matrix will misrepresent semantic structure, undermining downstream uncertainty estimates.

### Mechanism 2
- **Claim:** The structural entropy of an optimally constructed K-dimensional encoding tree quantifies semantic uncertainty after hierarchical compression.
- **Mechanism:** Starting from a flat tree, a greedy algorithm iteratively applies "merge" or "combine" operations on sibling nodes to minimize the tree's structural entropy. The total entropy of the resulting tree is the uncertainty score (SeSE).
- **Core assumption:** The semantic space of LLM outputs possesses a learnable hierarchical structure; minimizing structural entropy recovers the "true" abstraction.
- **Evidence anchors:**
  - [abstract]: "constructs an optimal hierarchical encoding tree to model semantic space structure and computes structural entropy as an uncertainty measure"
  - [Section 3.1, "Hierarchical Abstraction"]: Details the optimization algorithm and the definition of SeSE as the entropy of the optimal tree.
  - [corpus]: General work on structural entropy in networks exists, but direct application to LLM semantic uncertainty is novel to this paper.
- **Break condition:** If semantic relationships are fundamentally non-hierarchical or the graph is too sparse/near-complete, the optimization may converge to a trivial tree (e.g., K=1), reducing SeSE to simple semantic entropy and losing its discriminative power.

### Mechanism 3
- **Claim:** For long-form generation, claim-level uncertainty can be quantified via the structural entropy contribution along the root-to-leaf path in a claim-response bipartite graph.
- **Mechanism:** Decompose the greedy response into atomic claims. Build a bipartite graph where edges connect claims to sampled responses that entail them. Run the same encoding tree optimization on this graph. A claim's SeSE is the sum of entropy contributions for all tree nodes on the path from root to that claim's leaf.
- **Core assumption:** Claim uncertainty is captured by how "peripheral" the claim is in the entailment network, as revealed by the random-walk dynamics and hierarchical community structure.
- **Evidence anchors:**
  - [abstract]: "extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions"
  - [Section 3.2, "SeSE for Long-Form Generation"]: Describes bipartite graph construction and the definition of claim-level SeSE via path entropy.
  - [corpus]: Corpus mentions "claim-level" and "granular" uncertainty methods, but the specific structural-entropy-on-bipartite-graph approach is this paper's contribution.
- **Break condition:** If claims are not truly atomic or have strong inter-dependencies not captured by the bipartite graph's simple entailment edges, the path entropy may not accurately reflect factual hallucination risk.

## Foundational Learning

- **Concept: Structural Entropy on Graphs**
  - **Why needed here:** It is the core mathematical tool SeSE uses to quantify the "disorder" or uncertainty in the semantic graph after optimal hierarchical compression. It generalizes Shannon entropy to graph structures.
  - **Quick check question:** How does structural entropy differ from simply computing the Shannon entropy of node degrees or a stationary distribution?

- **Concept: Semantic Entropy (SE)**
  - **Why needed here:** SeSE is explicitly designed as a generalization of SE, the prior "gold standard" for black-box semantic UQ. Understanding SE's clustering-based approach clarifies what structural information SeSE adds.
  - **Quick check question:** What limitation of Semantic Entropy does SeSE aim to address by incorporating graph structure?

- **Concept: Random Walks and Stationary Distributions**
  - **Why needed here:** The directed semantic graph is transformed into a Markov chain. Its stationary distribution is used to calculate edge contributions in the structural entropy formula, anchoring the uncertainty in the graph's long-term transition dynamics.
  - **Quick check question:** In SeSE, what property must the transition matrix have for a unique stationary distribution to exist, and why is that important?

## Architecture Onboarding

- **Component Map:** Query x → [LLM] → {Greedy Response r_T0, Sampled Responses R}. R + NLI Model → [Semantic Graph Builder] → Directed Graph G. G + K → [Tree Optimizer] (Algorithm 1) → Optimal Encoding Tree T*. T* → [SeSE Calculator] → Uncertainty Score U(x). *(For long-form: r_T0 → [Claim Decomposer] → Claims C. R + C → [Bipartite Graph Builder] → G_cr. Then similar path to claim-level scores.)*

- **Critical Path:** The **Tree Optimizer** component. Its correctness and efficiency in finding the low-entropy encoding tree directly determines the quality of the uncertainty estimate. The choice of NLI model for graph construction is a close second, as it defines the input structure.

- **Design Tradeoffs:**
  - **Sampling Size (N):** Higher N improves graph connectivity and estimate stability but increases inference cost. Paper shows diminishing returns past N≈10.
  - **Tree Height (K):** Larger K can capture deeper hierarchy but risks overfitting to noise. Optimal K correlates with task difficulty.
  - **NLI Model:** Stronger NLI models (e.g., large DeBERTa) give better entailment signals but are slower. The paper uses DeBERTa-v3-large-mnli.

- **Failure Signatures:**
  - **High SeSE with Consistent Answers:** May indicate NLI model failure (e.g., treating synonyms as contradictions) or a graph construction bug.
  - **Low SeSE with Hallucinations:** Suggests the semantic space appears deceptively ordered; could happen if hallucinations are highly self-consistent or if the NLI model is over-entailing.
  - **SeSE ≈ SE (for K>1):** Implies the tree optimization is not finding a non-trivial hierarchy, potentially due to a sparse or uniform graph.

- **First 3 Experiments:**
  1. **NLI Ablation:** Replace the default NLI model with a smaller/faster or a more powerful one (e.g., a prompting-based LLM judge). Measure AUROC change and latency on a fixed dataset/LLM pair to quantify the cost-accuracy trade-off.
  2. **Sensitivity to K:** Run SeSE on a validation set while varying `K` from 1 to 5. Plot AUROC vs. K for different datasets (e.g., a simple one like TriviaQA vs. a complex one like SQuAD) to confirm the paper's finding that optimal K is task-dependent.
  3. **Long-form Case Study:** Manually inspect 10-20 examples from the long-form experiment where SeSE strongly disagrees with a baseline (e.g., DSE). Analyze the bipartite graph and resulting tree to build intuition for how structural entropy identifies uncertain claims in practice.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SeSE be effectively extended to quantify uncertainty in multi-agent LLM systems?
- Basis in paper: [explicit] The conclusion explicitly states, "Future work may explore extending SeSE to multi-agent systems."
- Why unresolved: The current framework evaluates a single LLM's semantic space. Multi-agent systems introduce consensus and debate dynamics where uncertainty might arise from inter-agent disagreement rather than just single-model entropy.
- What evidence would resolve it: A formulation of SeSE applied to a graph of communicating agents, showing that the structural entropy captures "agreement uncertainty" distinct from single-agent hallucinations.

### Open Question 2
- Question: Can the optimal encoding tree height (K) be determined automatically for a specific query without validation data?
- Basis in paper: [inferred] The ablation study (Figure 4) shows that the optimal K varies by dataset (correlating with task difficulty), suggesting a fixed K is suboptimal for general deployment.
- Why unresolved: The paper relies on grid search for K. In a real-world "off-the-shelf" setting, the model cannot know the difficulty of a user's query a priori to set the optimal tree depth.
- What evidence would resolve it: A heuristic or adaptive algorithm that estimates the optimal K based on intrinsic graph properties (e.g., density, connectivity) of the sampled responses, matching or exceeding fixed-K performance.

### Open Question 3
- Question: How can the computational overhead of SeSE be reduced, specifically regarding the dependency on multiple stochastic samples (N)?
- Basis in paper: [explicit] The conclusion lists "optimizing the computational overhead" as future work. [inferred] The method relies on sampling N responses, which is computationally expensive compared to single-pass methods.
- Why unresolved: While Figure 3 shows performance saturates as N increases, the cost of generating even 5-10 samples per query is significant for high-volume deployment.
- What evidence would resolve it: A variant of SeSE that achieves comparable AUROC performance using fewer samples (e.g., N=1-3) or by utilizing internal model states (white-box) to approximate the semantic graph structure without full sampling.

## Limitations
- **Dependency on high-quality NLI models:** Systematic biases in NLI models (like over-entailment or sensitivity to domain-specific language) could propagate through the entire framework, leading to inaccurate uncertainty estimates.
- **Assumption of hierarchical semantic structure:** The assumption that semantic relationships in LLM outputs possess a learnable hierarchical structure is not universally validated across all domains and model types.
- **Complexity of claim-level uncertainty:** The reliability of claim-level uncertainty quantification in long-form generation depends on the assumption that claims are atomic and their entailment relationships are accurately captured by simple edges, which may not hold for complex, interdependent claims.

## Confidence
- **High Confidence:** The mathematical framework of structural entropy and its relationship to semantic entropy (Theorem 1). The general methodology of using NLI-derived semantic graphs for uncertainty quantification is sound.
- **Medium Confidence:** The specific performance claims (AUROC improvements up to 15.3%) are based on the reported experiments but require independent replication. The effectiveness of the greedy tree optimization algorithm in diverse real-world scenarios is supported by results but not fully proven to be optimal or robust.
- **Low Confidence:** The universal applicability of the hierarchical structure assumption for all LLM output distributions. The reliability of claim-level uncertainty quantification in long-form generation, given the complexity of real-world claims and their interdependencies.

## Next Checks
1. **NLI Model Ablation Study:** Systematically replace the DeBERTa-v3-large-mnli model with smaller/faster models and larger/more powerful models (e.g., prompting-based LLM judges). Measure the impact on SeSE's AUROC and computational latency across multiple datasets to quantify the cost-accuracy trade-off.
2. **K-Sensitivity Analysis:** Conduct a detailed study varying the tree height parameter `K` (from 1 to 5 or higher) on a diverse set of tasks. Plot AUROC against K for datasets of varying complexity (e.g., simple QA vs. complex reasoning) to validate the paper's finding that optimal K is task-dependent and to identify potential overfitting at higher K values.
3. **Long-form Hallucination Case Study:** Manually analyze a set of 10-20 long-form generation examples where SeSE produces notably different uncertainty scores compared to a strong baseline like DSE. Focus on understanding how the structural entropy of the bipartite graph (claims-responses) identifies uncertain claims, and investigate whether the identified uncertain claims correspond to actual hallucinations.