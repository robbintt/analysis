---
ver: rpa2
title: 'Co-Producing AI: Toward an Augmented, Participatory Lifecycle'
arxiv_id: '2508.00138'
source_url: https://arxiv.org/abs/2508.00138
tags:
- lifecycle
- https
- data
- participatory
- ethics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces an augmented AI lifecycle designed to embed\
  \ participatory, equitable, and inclusive practices throughout AI development. Drawing\
  \ on design-justice principles, expansive learning theory, and four multidisciplinary\
  \ workshops, the authors propose a five-phase framework\u2014co-framing, co-design,\
  \ co-implementation, co-deployment, and co-maintenance\u2014that positions affected\
  \ communities as co-producers alongside domain experts and technologists."
---

# Co-Producing AI: Toward an Augmented, Participatory Lifecycle

## Quick Facts
- arXiv ID: 2508.00138
- Source URL: https://arxiv.org/abs/2508.00138
- Reference count: 40
- Primary result: Introduces a five-phase augmented AI lifecycle embedding participatory, equitable practices to mitigate algorithmic bias by positioning affected communities as co-producers.

## Executive Summary
This paper proposes an augmented AI lifecycle designed to embed participatory, equitable, and inclusive practices throughout AI development. Drawing on design-justice principles, expansive learning theory, and four multidisciplinary workshops, the authors introduce a five-phase framework—co-framing, co-design, co-implementation, co-deployment, and co-maintenance—that positions affected communities as co-producers alongside domain experts and technologists. The lifecycle operationalizes shared decision-making, iterative knowledge exchange, contextual privacy, and DEI commitments, distributing authority and accountability to those most impacted by AI systems. While conceptual, this structured approach addresses the absence of operational participatory processes in AI ethics.

## Method Summary
The framework was developed through inductive-deductive thematic analysis of four multidisciplinary workshops (January-May 2024, Montréal) with 20 participants (9 researchers, 6 industry, 5 civil-society), triangulated with Design Justice and Expansive Learning theories. The lifecycle emphasizes co-production through iterative knowledge exchange, with artifacts like model cards and audit trails ensuring traceability. Implementation requires multidisciplinary boundary spaces, governance charters defining decision rights, and budgets covering participant compensation including childcare and travel.

## Key Results
- Proposes a five-phase augmented lifecycle (co-framing, co-design, co-implementation, co-deployment, co-maintenance) operationalizing participatory AI development
- Framework distributes authority to affected communities through shared decision-making and veto rights
- Lifecycle includes mechanisms for iterative knowledge exchange, contextual privacy, and DEI commitments
- Provides structured response to absence of operational participatory processes in AI ethics

## Why This Works (Mechanism)
The framework works by fundamentally restructuring AI development from a linear pipeline to a learning system where affected communities are positioned as co-producers rather than passive stakeholders. By embedding participatory practices across all five phases, it creates multiple touchpoints for knowledge exchange and ensures that diverse perspectives shape both problem definition and technical implementation. The governance charter and resource allocation mechanisms address power imbalances that typically exclude marginalized voices from technology development.

## Foundational Learning

- **Concept: Participatory Design & Co-Production**
  - Why needed here: This is the core philosophy—shifting from "design for" to "design with" affected communities as experts and co-decision-makers. Without this understanding, the lifecycle's purpose is lost.
  - Quick check question: Can you explain the difference between consulting a community about a proposed AI system and partnering with them to co-produce it?

- **Concept: Expansive Learning & Activity Theory**
  - Why needed here: This theory explains how co-production works—different groups (technologists, citizens, domain experts) collectively create new knowledge and solutions that didn't exist before. It frames the project as a learning system, not just production.
  - Quick check question: In an AI project, what is an example of "expansive learning" where a conflict between a technical requirement and a community value leads to a completely new, better solution for both?

- **Concept: Arnstein's Ladder of Citizen Participation**
  - Why needed here: This diagnostic tool helps assess the quality of participation—are citizens merely informed ("therapy" rung) or do they have real shared authority ("partnership" rung)? It helps avoid "participation washing."
  - Quick check question: On which rung of Arnstein's ladder would you place a project where citizens are surveyed for opinions but developers make all final decisions?

## Architecture Onboarding

- **Component map**: The system is a five-phase lifecycle: Co-framing (Problem Definition) → Co-design (Solution Ideation) → Co-implementation (Build & Validate) → Co-deployment (Integration & Monitoring) → Co-maintenance (Sustain & Adapt)

- **Critical path**: The integrity of the entire system depends on the Co-framing phase. If problem definition is not genuinely co-created with affected communities, all subsequent phases will be built on flawed assumptions.

- **Design tradeoffs**: The primary tradeoff is thoroughness vs. resource intensity. Meaningful co-production requires significant investment in time, funding (for participant compensation, childcare, travel), and multidisciplinary coordination, increasing upfront costs but aiming to reduce long-term risks and costly redesigns.

- **Failure signatures**:
  - Tokenism: Stakeholders present but lack real decision-making power (stuck on "consultation" rung)
  - Epistemic Silos: Technical and non-technical participants cannot translate knowledge, leading to parallel monologues
  - Engagement Exhaustion: Community members drop out due to burdensome, under-compensated participation
  - Drift & Amnesia: Institutional memory of original co-framed commitments is lost as teams change

- **First 3 experiments**:
  1. Run a "Co-framing" Simulation: Stage a 2-hour mock co-framing workshop with assigned roles to observe communication breakdowns and dominant voices.
  2. Conduct an Artifact Traceability Audit: Trace a design decision back to its originating principle to determine what documentation a citizen auditor would need for trust.
  3. Map Stakeholder Incentives & Constraints: Create a chart listing potential stakeholders with their gains, losses, and participation barriers to design an inclusive engagement plan.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the societal benefits of the augmented lifecycle's governance overhead outweigh implementation costs compared to conventional AI pipelines?
- Basis in paper: [explicit] Authors state "Systematic cost–benefit analyses are also required to determine whether the additional governance overhead yields proportional societal value."
- Why unresolved: Lifecycle is conceptual; practical feasibility, cost profile, and performance implications haven't been empirically evaluated.
- What evidence would resolve it: Quantitative data on resource expenditure versus gains in fairness, privacy, and project efficiency from production settings using the framework.

### Open Question 2
- Question: How can conflicts between community veto rights and organizational accountability mechanisms be effectively resolved during operation?
- Basis in paper: [explicit] "Potential conflicts between community veto rights and organizational accountability mechanisms... were not examined in operational environments."
- Why unresolved: Workshops provided face validity but didn't test framework in real-world scenarios where legal/commercial liabilities might contradict community decisions.
- What evidence would resolve it: Case studies from longitudinal field trials analyzing how governance charters navigate disputes between citizen co-producers and institutional stakeholders.

### Open Question 3
- Question: Does the application of the augmented lifecycle quantitatively reduce algorithmic harms and improve technical metrics in production?
- Basis in paper: [inferred] Authors admit workshops "do not establish that co-production systematically reduces algorithmic harms or enhances technical metrics."
- Why unresolved: Study relies on self-reported workshop themes rather than measured outcomes from deployed systems.
- What evidence would resolve it: Comparative analysis of fairness and bias metrics between systems developed using co-production lifecycle versus standard industry pipelines.

## Limitations
- Framework remains largely conceptual with limited empirical validation beyond four workshop sessions
- Critical operational details like conflict resolution mechanisms and resource allocation models remain underspecified
- Tensions between "equity and efficiency" acknowledged but not fully resolved for resource-constrained environments

## Confidence
- **High Confidence**: Core premise that participatory co-production improves AI accountability and reduces algorithmic bias is well-supported by design justice literature and workshop findings
- **Medium Confidence**: Five-phase lifecycle structure is methodologically sound but specific implementation protocols require further field testing
- **Low Confidence**: Claims about long-term sustainability and scalability across diverse organizational contexts need empirical validation

## Next Checks
1. **Conflict Resolution Protocol Test**: Design and pilot a decision tree or arbitration framework for resolving conflicts between community veto rights and organizational accountability requirements in a controlled workshop setting.
2. **Resource Allocation Impact Study**: Conduct a comparative study measuring participant retention rates and engagement quality across projects with and without explicit budgets covering childcare, travel, and participant compensation.
3. **Cross-Organizational Pilot**: Implement the complete five-phase lifecycle in at least two different organizational contexts (e.g., healthcare and public sector) to assess transferability and identify context-specific adaptations needed.