---
ver: rpa2
title: Explaining Concept Shift with Interpretable Feature Attribution
arxiv_id: '2505.20634'
source_url: https://arxiv.org/abs/2505.20634
tags:
- features
- shift
- data
- sgshift
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying which features
  cause concept shift, where the relationship between features and labels changes
  between source and target datasets, leading to reduced model performance. The proposed
  method, SGShift, uses a sparse Generalized Additive Model (GAM) to model the difference
  between source and target distributions and performs feature selection to identify
  shifted features.
---

# Explaining Concept Shift with Interpretable Feature Attribution

## Quick Facts
- arXiv ID: 2505.20634
- Source URL: https://arxiv.org/abs/2505.20634
- Authors: Ruiqi Lyu; Alistair Turcan; Bryan Wilder
- Reference count: 6
- Primary result: SGShift identifies shifted features with AUC > 0.9 and recall > 90%, 2-3x better than baselines

## Executive Summary
This paper addresses the challenge of identifying which features cause concept shift between source and target datasets, where the relationship between features and labels changes. The proposed method, SGShift, uses a sparse Generalized Additive Model (GAM) to model the difference between source and target distributions and performs feature selection to identify shifted features. Experiments on synthetic and real healthcare datasets demonstrate that SGShift can identify shifted features with high accuracy (AUC > 0.9, recall > 90%) and significantly outperforms baseline methods.

## Method Summary
SGShift models concept shift by fitting a sparse correction term δ to source model predictions using a GAM. The method identifies shifted features as those with non-zero δ after L1 regularization. Extensions include knockoffs for false discovery rate control and an absorption term to separate model misspecification from true concept shift. The approach requires labeled target data and assumes sparsity of true concept shifts.

## Key Results
- SGShift achieves AUC > 0.9 with knockoffs, 2-3x higher recall than baselines
- SGShift-A (with absorption) improves recall over SGShift in nearly every setting (e.g., Diabetes mismatched: 0.43 → 0.50)
- SGShift-K (with knockoffs) achieves highest AUC in most settings (e.g., COVID matched: 0.99)
- Real-world evaluation on COVID-19 hospitalization data reveals features consistent with medical literature

## Why This Works (Mechanism)

### Mechanism 1
- Claim: L1-regularized GAM can identify shifted features by modeling the difference between source and target conditional distributions.
- Mechanism: The method fits a sparse correction term δ to the source model predictions using a Generalized Additive Model. Under target distribution: g(E_T[y|X]) = f(X) + φ(X)^T δ, where δ is sparse. Features with non-zero δ after L1 regularization are identified as shifted.
- Core assumption: True concept shifts are sparse (only a small subset of features cause the shift between domains).
- Evidence anchors:
  - [abstract] "SGShift models concept shift with a Generalized Additive Model (GAM) and performs subsequent feature selection to identify shifted features"
  - [Section 4.1] Defines the optimization: argmin_δ L(y_T, f̂(X_T) + φ_T^T δ) + λ||δ||_1
  - [Section 6 Results] Table 2 shows SGShift achieving AUC > 0.9 with knockoffs, 2-3x higher recall than baselines
- Break condition: If concept shift is dense (many features shift simultaneously), sparsity assumption fails and feature selection becomes unreliable.

### Mechanism 2
- Claim: Absorption term separates model misspecification from true concept shift.
- Mechanism: Introduces parameter ω that appears in both source and target domains, while δ only appears in target. The optimization solves: (ω̂, δ̂) = argmin_{ω,δ} {L_S(ω) + L_T(ω, δ) + λ_ω||ω||_1 + λ_δ||δ||_1} with hierarchical regularization λ_ω < λ_δ.
- Core assumption: Model misspecification affects both domains similarly and can be captured by a shared correction term.
- Evidence anchors:
  - [Section 4.2] "δ captures extra shifts unique to the target, while ω absorbs the main source plus target mismatch"
  - [Table 2] SGShift-A improves recall over SGShift in nearly every setting (e.g., Diabetes mismatched: 0.43 → 0.50)
- Break condition: If misspecification differs substantially between domains, absorption term cannot properly separate the effects.

### Mechanism 3
- Claim: Knockoffs with stability selection provide rigorous false discovery rate (FDR) control for shifted feature identification.
- Mechanism: Constructs synthetic features X̃ that mimic correlation structure of X but are conditionally independent of y. Features are selected when their importance statistic exceeds their knockoff copy. Derandomization aggregates over B knockoff realizations with stability threshold π.
- Core assumption: Feature distribution is known or can be accurately modeled to construct valid knockoffs.
- Evidence anchors:
  - [Section 4.3] Lemma 4.2 proves FDR control: FDR(Â(π)) ≤ q / (1 - (1-π)^B)
  - [Table 2] SGShift-K achieves highest AUC in most settings (e.g., COVID matched: 0.99)
- Break condition: If knockoff construction is invalid (unknown/mispecified feature distribution), FDR guarantees may not hold.

## Foundational Learning

- Concept: **Concept Shift vs Covariate Shift**
  - Why needed here: The method specifically targets changes in P(y|X), not changes in P(X). Confusing these leads to applying wrong diagnostic tools.
  - Quick check question: Given two datasets, if feature distributions are identical but predictions differ, what type of shift is this?

- Concept: **Generalized Additive Models (GAMs)**
  - Why needed here: SGShift models the shift as an additive correction g(E[y|X]) = f(X) + Σφ_j(X_j)δ_j, requiring understanding of link functions and additive structure.
  - Quick check question: Why might a GAM be preferred over a full neural network for interpretable shift modeling?

- Concept: **Knockoffs and FDR Control**
  - Why needed here: The paper extends standard knockoffs to the shift detection setting. Understanding Model-X knockoffs is essential for interpreting FDR guarantees.
  - Quick check question: What property must knockoff features satisfy to ensure valid FDR control?

## Architecture Onboarding

- Component map:
  ```
  Source Data (X_S, y_S) ──┐
                          ├──> Source Model f̂(X)
  Target Data (X_T, y_T) ──┘           │
                                       ▼
                          ┌───────────────────────┐
                          │   Basis Functions φ(X) │
                          └───────────────────────┘
                                       │
                                       ▼
  ┌─────────────────────────────────────────────────────────────┐
  │                    SGShift Core                             │
  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │
  │  │ SGShift      │  │ +Absorption  │  │ +Knockoffs   │       │
  │  │ (L1-GAM)     │->│ (ω, δ split) │->│ (FDR control)│       │
  │  └──────────────┘  └──────────────┘  └──────────────┘       │
  └─────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
                          Shifted Features A ⊆ X
  ```

- Critical path:
  1. Train source model f̂ on (X_S, y_S)
  2. Compute predictions f̂(X_T) on target features
  3. Construct basis functions φ(X) (default: linear)
  4. Fit sparse δ (and ω if using absorption) via L1-regularized GAM
  5. Apply knockoff selection if FDR control needed
  6. Return features with non-zero δ as shifted

- Design tradeoffs:
  - **Basis function complexity**: Linear basis is most interpretable; higher-order basis may capture non-linear shifts but increases variance
  - **Regularization strength λ_δ vs λ_ω**: Higher λ_δ (shift penalty) reduces false positives but may miss true shifts; paper uses λ_ω < λ_δ
  - **Knockoff threshold τ vs stability π**: More conservative thresholds reduce FDR but lower power
  - **Sample size requirements**: Knockoffs require sufficient target samples; absorption requires both source and target samples

- Failure signatures:
  - All features selected → λ too small or dense shift (break condition for sparsity)
  - No features selected despite performance drop → λ too large or poor basis function choice
  - High variance in selected features across runs → insufficient samples; consider stability selection
  - Contradictory signs for same feature → absorption may be failing; check model fit quality

- First 3 experiments:
  1. **Synthetic validation**: Create data with known shifted features (varying sparsity 1-10 features, varying effect sizes). Measure AUC/recall. Verify λ selection via cross-validation on target domain.
  2. **Ablation on absorption**: Compare SGShift vs SGShift-A on mismatched model settings (e.g., linear generator, tree base model). Confirm absorption recovers performance when source model is misspecified.
  3. **FDR calibration test**: Run SGShift-K under null (no true shift) across 100 trials. Verify empirical FDR matches theoretical bound at q=0.1.

## Open Questions the Paper Calls Out
None

## Limitations
- The method assumes sparsity of true concept shifts, which may not hold in domains with widespread distributional changes
- Knockoff construction requires accurate knowledge of feature distributions, which may be challenging for complex or high-dimensional features
- The absorption mechanism assumes model misspecification affects both domains similarly, which may fail when source and target domains have fundamentally different data-generating processes
- The method currently requires labeled target data, limiting applicability to unsupervised scenarios

## Confidence

- **High Confidence**: SGShift's core L1-GAM approach for identifying shifted features when concept shift is sparse and well-modeled by linear basis functions
- **Medium Confidence**: The absorption term's ability to separate model misspecification from true concept shift
- **Medium Confidence**: Knockoffs with stability selection for FDR control in the shift detection setting

## Next Checks

1. **Dense Shift Validation**: Create synthetic datasets with dense concept shifts (20-50% of features changing) to test the method's robustness when the sparsity assumption breaks down.

2. **High-Dimensional Knockoff Test**: Evaluate knockoff performance on datasets with 100+ features to assess scalability and validate FDR control in high-dimensional settings.

3. **Unsupervised Extension**: Test whether the method can detect concept shift using only unlabeled target data by leveraging source model uncertainty or prediction calibration instead of target labels.