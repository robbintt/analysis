---
ver: rpa2
title: 'EXCLAIM: An Explainable Cross-Modal Agentic System for Misinformation Detection
  with Hierarchical Retrieval'
arxiv_id: '2504.06269'
source_url: https://arxiv.org/abs/2504.06269
tags:
- detection
- exclaim
- misinformation
- retrieval
- news
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EXCLAIM, a retrieval-based framework designed
  to detect Out-of-Context (OOC) misinformation by leveraging multi-granularity information
  retrieval and a multi-agent reasoning architecture. The system constructs a self-built
  database containing both entity-level and event-level information, which is then
  used to cross-validate news content for inconsistencies.
---

# EXCLAIM: An Explainable Cross-Modal Agentic System for Misinformation Detection with Hierarchical Retrieval

## Quick Facts
- arXiv ID: 2504.06269
- Source URL: https://arxiv.org/abs/2504.06269
- Reference count: 25
- Achieves 92.7% overall accuracy in detecting Out-of-Context misinformation

## Executive Summary
EXCLAIM introduces a retrieval-based framework for detecting Out-of-Context (OOC) misinformation through multi-granularity information retrieval and multi-agent reasoning. The system constructs a self-built database containing entity-level and event-level information, which is used to cross-validate news content for inconsistencies. By leveraging hierarchical retrieval and explainable reasoning, EXCLAIM achieves state-of-the-art performance on the NewsCLIPpings dataset, with particular strength in identifying falsified content.

## Method Summary
EXCLAIM employs a retrieval-based architecture that combines entity-level and event-level information retrieval to detect OOC misinformation. The system first builds a comprehensive database containing structured information about entities and events from news articles. When processing new content, it performs multi-granularity retrieval to extract relevant facts from this database, then uses a multi-agent reasoning framework to cross-validate the retrieved information against the input content. The agents collaborate to identify inconsistencies that indicate potential misinformation, while maintaining transparency in their reasoning process to provide explainable insights.

## Key Results
- Achieves 92.7% overall accuracy on NewsCLIPpings dataset
- Outperforms state-of-the-art methods by 4.3% in accuracy
- Demonstrates 93.3% accuracy on falsified content and 92.1% on pristine content

## Why This Works (Mechanism)
The effectiveness of EXCLAIM stems from its ability to leverage hierarchical retrieval at multiple granularity levels - entity and event - to capture both specific details and broader contextual relationships. By building a comprehensive self-contained database, the system can efficiently cross-reference new content against verified information. The multi-agent reasoning architecture enables collaborative analysis, where different agents specialize in different aspects of validation while maintaining consistent communication. This structured approach allows for both accurate detection and explainable reasoning, as each step of the validation process can be traced and understood.

## Foundational Learning
- Multi-granularity retrieval: Combines entity-level and event-level information extraction to capture both specific details and contextual relationships
  - Why needed: Different types of misinformation require different levels of contextual understanding
  - Quick check: Verify that both entity and event retrieval contribute independently to detection accuracy

- Cross-modal validation: Integrates information from multiple sources and formats to establish consistency
  - Why needed: Misinformation often exploits inconsistencies across different modalities
  - Quick check: Test system's ability to detect inconsistencies between text and image-based information

- Explainable AI reasoning: Maintains transparent decision-making processes for each validation step
  - Why needed: Builds trust and enables human oversight of automated detection
  - Quick check: Verify that all detection decisions can be traced back to specific validation steps

## Architecture Onboarding

**Component Map:**
Database Builder -> Multi-Granularity Retriever -> Agent Coordinator -> Validation Agents -> Explanation Generator

**Critical Path:**
Database Builder constructs information repository -> Multi-Granularity Retriever extracts relevant facts -> Agent Coordinator manages collaboration -> Validation Agents perform cross-validation -> Explanation Generator produces interpretable results

**Design Tradeoffs:**
The system prioritizes accuracy and explainability over computational efficiency, using a comprehensive self-built database rather than relying on external APIs. This approach ensures data privacy and control but requires significant storage and maintenance overhead. The multi-agent architecture provides robust reasoning but introduces communication overhead and complexity in agent coordination.

**Failure Signatures:**
Performance degradation occurs when the self-built database lacks coverage of relevant entities or events, leading to false negatives. The system may also struggle with novel misinformation patterns that exploit gaps in the database structure. Agent coordination failures can result in inconsistent validation decisions, particularly when agents disagree on the relevance of retrieved information.

**First 3 Experiments to Run:**
1. Test retrieval accuracy with varying database completeness levels to establish minimum viable coverage
2. Measure agent collaboration efficiency under different communication protocols
3. Validate explanation quality through human evaluation of detection reasoning transparency

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on self-built database raises scalability and maintenance concerns
- Limited evaluation to Out-of-Context misinformation type only
- Performance improvements lack statistical significance analysis across different evaluation settings

## Confidence
- High confidence in technical architecture description and multi-granularity retrieval approach
- Medium confidence in claimed performance improvements due to limited comparative data
- Medium confidence in explainability claims without detailed mechanism description
- Low confidence in scalability assessment given self-built database approach

## Next Checks
1. Conduct cross-dataset validation to verify performance consistency beyond NewsCLIPpings dataset
2. Perform ablation studies to quantify contributions of entity-level versus event-level retrieval components
3. Implement stress test on self-built database by measuring accuracy degradation with decreasing coverage