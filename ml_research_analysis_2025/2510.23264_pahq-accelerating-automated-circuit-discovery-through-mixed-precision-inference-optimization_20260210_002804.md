---
ver: rpa2
title: 'PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference
  Optimization'
arxiv_id: '2510.23264'
source_url: https://arxiv.org/abs/2510.23264
tags:
- quantization
- acdc
- precision
- circuit
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PAHQ accelerates automated circuit discovery by using mixed-precision
  inference to maintain high precision only for components currently under investigation.
  It exploits the sequential nature of edge evaluation in ACDC to optimize memory
  and computation by selectively quantizing non-critical components to 8-bit while
  preserving full precision for targeted analysis.
---

# PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization

## Quick Facts
- **arXiv ID**: 2510.23264
- **Source URL**: https://arxiv.org/abs/2510.23264
- **Reference count**: 40
- **Primary result**: Achieves up to 80% runtime reduction and 30% memory savings for ACDC while maintaining 0.89-0.96 AUC-ROC scores

## Executive Summary
PAHQ accelerates automated circuit discovery (ACDC) by using mixed-precision inference to maintain high precision only for components currently under investigation. It exploits the sequential nature of edge evaluation in ACDC to optimize memory and computation by selectively quantizing non-critical components to 8-bit while preserving full precision for targeted analysis. The method introduces a three-stream CUDA scheduler to overlap low-precision computation with high-precision weight transfers, effectively masking transfer latency. Evaluations on IOI, Docstring, and Greater Than tasks show PAHQ-accelerated ACDC achieves AUC-ROC scores of 0.96-0.89, outperforming direct quantization methods while maintaining near-original ACDC performance.

## Method Summary
PAHQ accelerates ACDC by maintaining FP32 precision only for the attention head/edge currently under evaluation while quantizing all other components to FP8 (attention) or BF16 (non-attention). Direct RTN quantization fails due to numerical underflow and mantissa loss. The method uses three-stream CUDA scheduler: Sload asynchronously transfers high-precision weights, Slow computes low-precision activations for all heads, and Shigh computes the target head at high precision. This approach achieves 80% runtime reduction and 30% memory savings compared to standard ACDC.

## Key Results
- Achieves up to 80% runtime reduction compared to standard ACDC
- Reduces memory usage by approximately 30% through mixed-precision storage
- Maintains high circuit discovery accuracy with AUC-ROC scores of 0.96-0.89 on IOI, Docstring, and Greater Than tasks
- Outperforms direct quantization methods (RTN-Q) which achieve only 0.534 AUC-ROC

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Maintaining full precision only for the edge under evaluation preserves circuit discovery accuracy because ACDC's loss difference criterion depends primarily on the precision of the selected edge's activation values.
- Mechanism: The edge importance score ΔL(e) = |L(EG\{e}(z,z')) - L(EG(z))| is dominated by the numerical precision of activations flowing through edge e. Non-selected edges can operate at reduced precision since their activations are not subject to intervention during evaluation.
- Core assumption: ACDC evaluates edges sequentially, one at a time (not simultaneously).
- Evidence anchors:
  - [abstract] "PAHQ leverages a fundamental alignment between activation patching and mixed-precision quantization (MPQ): interpretability analysis through patching essentially performs targeted ablation studies."
  - [section 3.1] "This strategy ensures that the critical component under investigation maintains full numerical precision while non-critical components operate at reduced precision, thereby preserving the faithfulness of ΔL(eₜ) computation."
  - [corpus] No direct corpus validation; related work (APP, EAP-GP) focuses on pruning/attribution rather than precision allocation.
- Break condition: Methods that evaluate multiple edges simultaneously (e.g., EAP during single backward pass) would require multiple high-precision components, diminishing efficiency gains.

### Mechanism 2
- Claim: A three-stream CUDA scheduler masks CPU-to-GPU weight transfer latency by overlapping low-precision computation with high-precision weight loading.
- Mechanism: Stream Sload transfers high-precision weights from CPU to GPU asynchronously. Concurrently, Slow computes low-precision activations for all heads. When both complete, Shigh computes the target head at high precision. Total time ≈ max(Ttransfer, Tlow_comp) rather than their sum.
- Core assumption: Low-precision computation time ≥ weight transfer time (or close enough for effective masking).
- Evidence anchors:
  - [section 3.2] "The weight transfer latency Ttransfer is masked by low-precision computation time Tlow_comp because the CPU-to-GPU transfer happens in parallel with the low-precision computation."
  - [table 4] Ablation shows enabling all three streams reduces runtime from 94 minutes to 20 minutes (79% reduction on IOI task).
  - [corpus] No corpus papers address this specific scheduling technique.
- Break condition: If high-precision weight transfer time significantly exceeds low-precision computation time, latency masking degrades.

### Mechanism 3
- Claim: Direct 8-bit quantization fails for circuit discovery due to numerical underflow (truncating small activation differences to zero) and mantissa loss (small activation values overwhelmed during residual stream aggregation).
- Mechanism: FP8_E4M3 has minimum step size 2⁻⁶ and only 3 mantissa bits. When exponent difference ≥3 during floating-point addition, the smaller number's significant bits are completely lost, masking edge influence detection.
- Core assumption: The activation differences relevant for circuit edge importance fall below FP8's representable precision.
- Evidence anchors:
  - [section 2] "RTN-Q reduces activation precision when the model aggregates these values (e.g., in residual streams)... causes the activation difference introduced by the selected edge to be overwhelmed."
  - [figure 1] RTN-Q achieves AUC-ROC of 0.534 vs. 0.982 for original ACDC on IOI task.
  - [corpus] Related papers (RelP, EAP-GP) focus on gradient-based approximations rather than quantization failure modes.
- Break condition: If critical activation differences are large relative to FP8 precision, direct quantization may suffice.

## Foundational Learning

- **Activation Patching / ACDC**:
  - Why needed here: PAHQ is explicitly designed for ACDC's edge-by-edge evaluation paradigm; understanding how ΔL(e) is computed is essential to grasp why selective precision works.
  - Quick check question: Given clean and corrupted prompts, how does ACDC determine if an edge is important?

- **Floating-Point Representation (FP8_E4M3, FP32)**:
  - Why needed here: The failure of direct quantization is explained through minimum step size and mantissa bits; understanding underflow/mantissa loss is critical.
  - Quick check question: In FP8_E4M3 with 3 mantissa bits, what happens when adding 1.0 and 0.0625?

- **CUDA Streams and Asynchronous Execution**:
  - Why needed here: The three-stream scheduler relies on concurrent kernel execution and memory transfer overlap; incorrect synchronization destroys the optimization.
  - Quick check question: If two CUDA streams execute kernels on the same GPU, under what conditions can they run concurrently?

## Architecture Onboarding

- **Component map**:
  - CPU Memory -> GPU Memory (FP8 weights) -> Three-Stream Scheduler -> Mixed-Precision Assembly
  - CPU stores FP32 weights, GPU stores FP8 weights, scheduler manages precision allocation

- **Critical path**: Edge evaluation loop → Identify source head h* for edge e → Async load W_FP32(h*) via Sload → Concurrent: compute all heads in FP8 (Slow) + wait for load + compute h* in FP32 (Shigh) → Sync streams → Replace A_FP8[h*] with A_FP32[h*] → Continue forward pass

- **Design tradeoffs**:
  - Memory vs. latency: Storing all FP32 weights on GPU would eliminate transfer latency but negates memory savings (~30% reduction is a stated goal)
  - Precision granularity: Only attention heads get per-head precision control; non-attention components use uniform bf16
  - Scalability ceiling: Method accelerates ACDC but does not change O(|E|) complexity; large models remain challenging

- **Failure signatures**:
  - AUC-ROC drops to ~0.5 (random): Likely all components at FP8; precision allocation not functioning
  - Runtime similar to unaccelerated ACDC: Scheduler streams not overlapping (check synchronization points)
  - CUDA errors on precision mismatch: Matrix multiplication received mixed-precision inputs; assembly/concatenation step failed

- **First 3 experiments**:
  1. **Reproduce RTN-Q failure**: Run ACDC with full 8-bit quantization on IOI task; confirm AUC-ROC ~0.53 (baseline failure case)
  2. **Validate single-head precision preservation**: Run PAHQ-ACDC on IOI with threshold=0.001; verify AUC-ROC ≥0.94 and runtime <25 minutes on GPT-2-small
  3. **Ablate scheduler**: Disable Sload stream only, then Slow/Shigh streams only; measure runtime degradation per Table 4 (should see 49 min and 72 min respectively vs. 20 min full)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the high-precision activation signal degrade or persist as it propagates through downstream layers operating at reduced precision (e.g., FP8)?
- Basis in paper: [explicit] The authors acknowledge providing "limited theoretical analysis on how the high-precision signal avoids degradation as it propagates through downstream layers operating at lower precision."
- Why unresolved: The paper relies on empirical results to justify the mixed-precision approach but lacks a formal derivation of error bounds or signal preservation mechanics.
- What evidence would resolve it: A theoretical framework quantifying error accumulation or an ablation study tracking signal-to-noise ratios across mixed-precision layers.

### Open Question 2
- Question: Can PAHQ be effectively adapted for circuit discovery methods like Edge Attribution Patching (EAP) that evaluate multiple edges simultaneously?
- Basis in paper: [explicit] The limitations section notes that for methods like EAP, PAHQ's benefits "would be diminished" because they "would require holding all concurrently evaluated edges... at high precision."
- Why unresolved: PAHQ is optimized for the sequential, one-edge-at-a-time evaluation of ACDC, making it incompatible with the batched or simultaneous evaluation strategies of faster approximation methods.
- What evidence would resolve it: A modified precision allocation strategy that groups simultaneous edge evaluations efficiently, or benchmarks showing memory/time trade-offs when applying PAHQ to EAP.

### Open Question 3
- Question: What are the specific precision sensitivity thresholds for different transformer components (e.g., MLP layers vs. attention heads) during circuit discovery?
- Basis in paper: [explicit] The paper states the choice to use bfloat16 for non-attention components "was determined empirically... rather than being derived from a formal theoretical analysis."
- Why unresolved: The current implementation uses a generalized precision setting for non-attention parts, potentially leaving performance on the table by not tailoring precision to component-specific needs.
- What evidence would resolve it: A systematic ablation study varying precision levels per component type (Attention, MLP, LayerNorm) to isolate their impact on circuit faithfulness and memory efficiency.

## Limitations
- PAHQ accelerates ACDC but does not change O(|E|) complexity, limiting scalability to very large models
- Effectiveness diminishes for circuit discovery methods that evaluate multiple edges simultaneously
- The choice of bfloat16 for non-attention components was empirical rather than theoretically derived
- Custom CUDA kernels and synchronization primitives lack detailed implementation specifications

## Confidence

- **High confidence**: The core mechanism of selective precision allocation is well-supported by the fundamental alignment between patching and targeted ablation. The failure of direct quantization is clearly demonstrated with RTN-Q achieving only 0.534 AUC-ROC versus 0.982 for original ACDC.
- **Medium confidence**: The three-stream scheduler effectiveness is supported by ablation studies but relies on assumptions about relative timing that may vary with hardware and workload characteristics.
- **Medium confidence**: The 80% runtime reduction and 30% memory savings claims are well-supported for GPT-2 on IOI, but scalability to larger models may be limited by unchanged O(|E|) complexity.

## Next Checks

1. **Reproduce the RTN-Q failure case**: Run ACDC with full 8-bit quantization on the IOI task and verify the AUC-ROC drops to approximately 0.53, confirming the numerical underflow mechanism.

2. **Validate single-head precision preservation**: Run PAHQ-ACDC on GPT-2 with IOI task, threshold=0.001, and confirm AUC-ROC ≥0.94 and runtime <25 minutes, demonstrating the core precision allocation mechanism works.

3. **Ablate the scheduler streams**: Disable each stream individually (Sload only, then Slow/Shigh only) and measure runtime degradation compared to the full three-stream implementation, verifying the latency masking effect.