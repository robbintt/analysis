---
ver: rpa2
title: 'Research Program: Theory of Learning in Dynamical Systems'
arxiv_id: '2512.19410'
source_url: https://arxiv.org/abs/2512.19410
tags:
- dynamical
- systems
- learnability
- learning
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a research program for understanding learnability
  in dynamical systems through the lens of next-token prediction. The authors argue
  that learnability in dynamical systems should be studied as a finite-sample question
  based on the properties of the underlying dynamics rather than the statistical properties
  of the resulting sequence.
---

# Research Program: Theory of Learning in Dynamical Systems

## Quick Facts
- arXiv ID: 2512.19410
- Source URL: https://arxiv.org/abs/2512.19410
- Reference count: 29
- One-line primary result: Learnability in dynamical systems can be achieved after finite burn-in by improper methods like spectral filtering, with complexity T(ε) = Õ(1/ε) for linear systems.

## Executive Summary
This paper proposes a research program for understanding learnability in dynamical systems through next-token prediction. The authors argue that learnability should be studied as a finite-sample question based on system dynamics rather than statistical properties of sequences. They introduce dynamic learnability, showing how system structure (stability, mixing, observability, spectral properties) governs required observations for reliable prediction.

The framework differs from classical learning theory by focusing on sequential prediction in systems with hidden state and latent dynamics, rather than i.i.d. samples. The authors illustrate their approach using linear dynamical systems, demonstrating that accurate prediction can be achieved without system identification through improper methods based on spectral filtering.

## Method Summary
The paper proposes spectral filtering as an improper learning method for next-token prediction in linear dynamical systems. The approach constructs a fixed bank of data-independent filters (eigenvectors of the Hilbert matrix) that approximate the Bayes-optimal predictor through infinite convolution of past observations with exponential decay coefficients. These filters are learned via least squares on observed trajectories, bypassing the need to estimate system matrices A or C. The method achieves proper dynamic learnability with complexity T(ε) = Õ(1/ε), meaning that after observing a finite burn-in period, the expected excess risk remains bounded by ε for all future time steps.

## Key Results
- Spectral filtering achieves proper dynamic learnability without system identification by leveraging improper methods
- Sample complexity T(ε) scales as Õ(1/ε) for symmetric linear dynamical systems
- The method decomposes risk into approximation and estimation errors that both decay after finite observation
- Dynamic learnability focuses on sequential prediction in systems with hidden state rather than i.i.d. data assumptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prediction can be achieved without identifying system parameters by using improper learning methods.
- Mechanism: Spectral filtering constructs a fixed bank of data-independent filters (eigenvectors of the Hilbert matrix) that approximate the Bayes-optimal predictor, bypassing system identification. The filters are learned via least squares on observed trajectories.
- Core assumption: The underlying dynamics have bounded spectral norm (‖A‖₂ ≤ 1) and are driven by independent sub-Gaussian noise.
- Evidence anchors: [abstract], [section 2.1], neighbor paper on nonlinear dynamics
- Break condition: Unbounded spectral radius or insufficient persistent excitation leads to ill-conditioned covariance and variance that does not decay.

### Mechanism 2
- Claim: Sample complexity scales with spectral complexity, not state dimension.
- Mechanism: The Bayes-optimal predictor is a mixture of exponential kernels. Hilbert matrix eigenvalues decay exponentially, meaning only Θ(log T log(1/ε)) filters capture most predictive energy, often much smaller than true state dimension d.
- Core assumption: System exhibits spectral decay with eigenvalues bounded away from 1 in magnitude.
- Evidence anchors: [section 2.2], [section 2.1, Theorem 2.1]
- Break condition: Chaotic systems with positive Lyapunov exponents may require arbitrarily long observation horizons.

### Mechanism 3
- Claim: Uniform-in-time guarantees are achievable through bias-variance decomposition.
- Mechanism: Bias from finite filters decays exponentially with filter count; variance decays as O(m log t / t) due to least-squares concentration. After T(ε) = Õ(1/ε) samples, both terms are ≤ ε/2.
- Core assumption: Stationarity and uniform boundedness of trajectories.
- Evidence anchors: [section 2.1, proof sketch], [section 3.4, Definition 3.1]
- Break condition: Non-stationary dynamics or unbounded trajectories violate uniform guarantee premise.

## Foundational Learning

- Concept: **State-Space Models (SSM) / Linear Dynamical Systems**
  - Why needed here: The central object is the partially observed dynamical system x_{t+1} = f(x_t, w_t), y_t = h(x_t, v_t). Understanding hidden state and observation maps is prerequisite.
  - Quick check question: Can you explain why the Bayes-optimal predictor for an LDS is an infinite convolution of past observations?

- Concept: **Bias-Variance Decomposition**
  - Why needed here: The spectral filtering analysis relies on decomposing excess risk into approximation error (from finite filter bank) and estimation error (from finite samples).
  - Quick check question: For a least-squares predictor, what happens to variance as feature dimension m grows vs. as sample size t grows?

- Concept: **Classical PAC Learning vs. Online Learning**
  - Why needed here: The paper positions dynamic learnability as distinct from both PAC (i.i.d. samples) and online learning (adversarial sequences). Understanding these baselines clarifies the novelty.
  - Quick check question: Why doesn't standard PAC sample complexity apply when data are generated by a dynamical system with hidden state?

## Architecture Onboarding

- Component map: Observation sequence y₁, y₂, ..., yₜ -> Spectral Feature Extractor (Hilbert matrix eigenvectors) -> Linear Readout (least squares) -> Next-token prediction ŷ_{t+1}

- Critical path:
  1. Precompute Hilbert matrix eigenvectors (data-independent)
  2. At each timestep, compute spectral features zₜ from past observations
  3. Update least-squares weights w using (zₜ, y_{t+1}) pair
  4. Predict ŷ_{t+1} = w⊤zₜ

- Design tradeoffs:
  - Filter count m: Higher m reduces bias but increases variance (O(m/t)). Paper suggests m = Θ(log T log(1/ε)).
  - Burn-in period T(ε): Longer burn-in improves accuracy; T(ε) = Õ(1/ε) is proven for symmetric LDS.
  - Improper vs. proper learning: Improper avoids system identification but may not recover interpretable state; proper identifies parameters but has higher sample complexity.

- Failure signatures:
  - Predictions oscillate or diverge → check if system violates ‖A‖₂ ≤ 1 stability assumption
  - Variance does not decay over time → check if noise provides persistent excitation; covariance Σₜ may be singular
  - Poor prediction on held-out trajectory → possible non-stationarity or model mismatch

- First 3 experiments:
  1. **Sanity check on synthetic symmetric LDS**: Generate x_{t+1} = Axₜ + wₜ with random symmetric A (‖A‖ ≤ 0.99), observe yₜ = Cxₜ + vₜ. Verify T(ε) scales as ~1/ε and m scales as ~log(1/ε).
  2. **Ablation on filter count m**: Fix T, vary m from 1 to 50. Plot prediction MSE vs. m to validate bias-variance tradeoff; expect U-shaped curve with optimal m ≈ log T.
  3. **Stress test with near-unstable A**: Set spectral radius ρ(A) → 1. Measure if T(ε) degrades gracefully or if hidden constants explode.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the quantitative relationship between the Optimal Luenberger Program parameter (Q*) and established system properties such as spectral radii or Lyapunov exponents?
- Basis in paper: [explicit] Section 4 asks "What is the relationship between Q* and established system properties, such as spectral radii or Lyapunov exponents?"
- Why unresolved: While Q* is defined as a measure of spectral complexity, no theorem links this parameter to specific dynamical metrics.
- What evidence would resolve it: A theoretical derivation bounding Q* in terms of Lyapunov exponents or spectral properties of specific dynamical system classes.

### Open Question 2
- Question: Can we design computationally efficient (polynomial-time) learners that achieve dynamic learnability for general nonlinear dynamical systems?
- Basis in paper: [explicit] Section 4 states that designing efficient (polynomial-time) learners remains the most important open challenge for nonlinear systems.
- Why unresolved: Provably efficient methods currently exist primarily for linear systems, with few positive examples for nonlinear settings.
- What evidence would resolve it: An algorithm with provable polynomial-time complexity that achieves low predictive risk for a broad class of nonlinear dynamical systems.

### Open Question 3
- Question: How does the sample complexity T(ε) behave when the learning agent actively influences the system dynamics through a non-stationary policy (as in Reinforcement Learning)?
- Basis in paper: [explicit] Section 4 asks "How does the sample complexity T(ε) behave when the agent's policy is non-stationary, thereby actively changing the system dynamics over time?"
- Why unresolved: The paper's definitions assume a fixed policy or passive observation; open-loop inputs can transform the system arbitrarily.
- What evidence would resolve it: Bounds on dynamic learnability complexity that hold under specific active control or reinforcement learning regimes.

### Open Question 4
- Question: Is dynamic learnability robust to changes in the underlying dynamics or observation function over time (non-stationarity)?
- Basis in paper: [explicit] Section 4 asks "How robust is dynamical learnability to change in dynamics or observation? Are abrupt changes harder to handle than gradual?"
- Why unresolved: The proposed framework assumes a stationary dynamical system, whereas real-world applications often involve time-varying sources.
- What evidence would resolve it: Modified learnability definitions and bounds that account for drift or abrupt changes in transition function f or observation map h.

## Limitations

- Empirical validation gap: No experimental validation of proposed T(ε) = Õ(1/ε) scaling or effectiveness of spectral filtering on real or synthetic data
- Assumptions scope: Theoretical framework assumes linear, symmetric systems with bounded spectral radius and sub-Gaussian noise
- Hidden constants: Sample complexity bounds hide system-dependent constants that could make guarantees impractical for poorly conditioned systems

## Confidence

- **High confidence**: The theoretical framework for dynamic learnability and its distinction from classical PAC/online learning is well-founded
- **Medium confidence**: The bias-variance decomposition mechanism and specific T(ε) = Õ(1/ε) scaling are mathematically rigorous within stated assumptions
- **Low confidence**: Claims about extension to nonlinear systems and controlled systems are speculative with only conceptual connections

## Next Checks

1. **Synthetic LDS experiment validation**: Implement spectral filtering on a controlled linear system with known A and C matrices. Verify that excess risk decays to ε after T(ε) observations, and that required T(ε) scales approximately as 1/ε.

2. **Sensitivity analysis to stability margin**: Systematically vary spectral radius ρ(A) from 0.9 to 0.99999 and measure how T(ε) changes. Test whether theoretical guarantees degrade gracefully as systems approach instability.

3. **Comparison to system identification baselines**: Implement a Kalman filter-based approach that first estimates A and C, then predicts. Compare its sample complexity and prediction accuracy to spectral filtering on the same LDS instances.