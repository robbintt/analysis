---
ver: rpa2
title: 'On-device edge learning for IoT data streams: a survey'
arxiv_id: '2502.17788'
source_url: https://arxiv.org/abs/2502.17788
tags:
- data
- learning
- arxiv
- these
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey reviews continual learning methods for on-device training
  in edge computing environments, focusing on neural networks and decision trees for
  classification tasks on IoT data streams. The paper identifies key constraints including
  data architecture (batch vs.
---

# On-device edge learning for IoT data streams: a survey

## Quick Facts
- arXiv ID: 2502.17788
- Source URL: https://arxiv.org/abs/2502.17788
- Reference count: 40
- Primary result: Survey of continual learning methods for on-device training on IoT data streams under resource constraints

## Executive Summary
This survey systematically reviews continual learning approaches for training models directly on IoT edge devices, focusing on neural networks and decision trees for classification tasks. The authors identify five critical constraints: data architecture (batch vs. stream), network capacity (cloud vs. edge), catastrophic forgetting, data inefficiency, and challenges in handling IoT tabular data in open-world settings. The paper examines how to deploy neural networks at the edge while continuously learning under resource constraints, make decision trees viable for on-device training through dynamic architectures and memory-efficient growth, and assess model performance using multi-criteria evaluation metrics. The primary challenge lies in integrating these building blocks into autonomous online systems while managing stability-plasticity trade-offs, forward-backward transfer, and model convergence.

## Method Summary
The survey examines continual learning methods for on-device training in edge computing environments, focusing on neural networks and decision trees for classification tasks on IoT data streams. The paper identifies key constraints including data architecture (batch vs. stream), network capacity (cloud vs. edge), catastrophic forgetting, data inefficiency, and challenges in handling IoT tabular data in open-world settings. The authors examine how to deploy neural networks at the edge while continuously learning under resource constraints, make decision trees viable for on-device training through dynamic architectures and memory-efficient growth, and assess model performance using multi-criteria evaluation metrics. The primary challenge lies in integrating these building blocks into autonomous online systems while managing stability-plasticity trade-offs, forward-backward transfer, and model convergence.

## Key Results
- Identifies critical constraints for on-device learning: data architecture, network capacity, catastrophic forgetting, data inefficiency, and open-world challenges
- Reviews lightweight neural network approaches using pruning, quantization, and experience replay with buffer management
- Examines decision tree adaptations including Hoeffding Trees with statistical bounds and adaptive sliding windows for drift detection
- Highlights the stability-plasticity dilemma as central to maintaining performance across concept drift scenarios

## Why This Works (Mechanism)
Assumption: The survey synthesizes existing research rather than presenting original empirical findings. The mechanism underlying successful on-device learning appears to be the combination of memory-efficient algorithms (Hoeffding Trees, lightweight neural networks) with adaptive strategies (drift detection, experience replay) that balance learning new information while preserving existing knowledge. This works because it addresses the fundamental constraints of edge computing: limited memory and computational resources, while maintaining accuracy in non-stationary environments through continuous adaptation.

## Foundational Learning
- **Hoeffding Bound**: Statistical tool to decide tree splits with limited samples; needed to ensure reliable decisions in streaming; quick check: verify epsilon calculation for split confidence
- **Experience Replay**: Stores recent examples to prevent catastrophic forgetting; needed to maintain knowledge across concept drift; quick check: monitor buffer hit rate and forgetting metrics
- **ADWIN (Adaptive Windowing)**: Drift detection algorithm that adapts window size based on data distribution changes; needed for automatic concept drift handling; quick check: validate false positive/negative rates on labeled drift points
- **Prequential Evaluation**: Test-then-train protocol for streaming data; needed to evaluate model performance on data it hasn't seen yet; quick check: ensure no data leakage between test and train phases
- **TinyML Constraints**: Memory limits (100KB-1MB RAM) and computational restrictions; needed to ensure practical edge deployment; quick check: profile memory usage and inference latency on target hardware
- **Stability-Plasticity Dilemma**: Trade-off between maintaining old knowledge and learning new patterns; needed to balance catastrophic forgetting vs adaptability; quick check: measure accuracy degradation on old vs new concepts

## Architecture Onboarding
**Component Map**: IoT Stream -> Data Buffer -> Model Update (NN/DT) -> Prediction -> Drift Detection -> Model Adaptation
**Critical Path**: Data stream → instance-by-instance model update → prequential evaluation → drift detection → model adaptation
**Design Tradeoffs**: Memory vs accuracy (larger replay buffers reduce forgetting but increase resource usage), model complexity vs inference speed (deeper trees are more accurate but slower), update frequency vs stability (frequent updates adapt faster but may be unstable)
**Failure Signatures**: Accuracy plateaus indicate catastrophic forgetting or insufficient plasticity; memory overflow suggests buffer or model size constraints violated; high latency indicates computational bottlenecks
**First Experiments**: 1) Implement Hoeffding Adaptive Tree with ADWIN on Electricity dataset, 2) Deploy lightweight MLP with Experience Replay on Speech Commands benchmark, 3) Compare NN+DT hybrid approach on multi-drift synthetic dataset

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly enumerate open questions in a dedicated section. Based on the content, implicit open questions include: How to effectively combine neural networks and decision trees for edge deployment? What are the optimal buffer management strategies for experience replay under severe memory constraints? How to design unified evaluation frameworks that fairly compare different model types across diverse IoT edge platforms? What are the best practices for handling catastrophic forgetting in resource-constrained environments with concept drift?

## Limitations
- Synthesis nature means specific quantitative claims lack direct validation against primary source data
- No standardized TinyML benchmarks for comparing NN and DT performance on identical hardware and datasets
- Variable definitions of "resource constraints" across edge platforms (100KB vs 1MB RAM targets)

## Confidence
**Confidence Labels:**
- **High**: Theoretical framework for continual learning (stability-plasticity, catastrophic forgetting)
- **Medium**: Practical deployment strategies for specific edge devices and datasets
- **Medium**: Evaluation metrics standardization across different model types

## Next Checks
1. Implement and benchmark the Hoeffding Adaptive Tree with ADWIN drift detection on the Electricity dataset using River library
2. Reproduce the lightweight MLP with Experience Replay on a standard TinyML benchmark (e.g., Speech Commands) and measure prequential accuracy vs resource usage
3. Compare the combined NN+DT hybrid approach against standalone models on a multi-drift synthetic dataset (SEA concepts) with varying buffer sizes