---
ver: rpa2
title: Data Augmentation to Improve Large Language Models in Food Hazard and Product
  Detection
arxiv_id: '2502.08687'
source_url: https://arxiv.org/abs/2502.08687
tags:
- augmentation
- roberta
- available
- data
- category
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the impact of ChatGPT-4o-mini data augmentation
  on large language models (LLMs) for food hazard and product detection. The original
  dataset with 5,082 samples was augmented to 6,513 samples, focusing on underrepresented
  classes.
---

# Data Augmentation to Improve Large Language Models in Food Hazard and Product Detection

## Quick Facts
- arXiv ID: 2502.08687
- Source URL: https://arxiv.org/abs/2502.08687
- Reference count: 25
- Primary result: Data augmentation improves F1-scores by ~4 points for both RoBERTa-base and Flan-T5-base models in food hazard and product detection tasks.

## Executive Summary
This study investigates the impact of ChatGPT-4o-mini data augmentation on large language models for food hazard and product detection. The researchers fine-tuned RoBERTa-base and Flan-T5-base on a dataset augmented from 5,082 to 6,513 samples, focusing on underrepresented classes. Results demonstrate that Flan-T5-base outperforms RoBERTa-base across all metrics, with both models showing improved F1-scores of approximately 4 points when using augmented data. The study addresses class imbalance challenges in multi-class text classification for food safety applications.

## Method Summary
The researchers employed a two-pronged approach: first, they used ChatGPT-4o-mini to generate synthetic samples for underrepresented classes in the food hazard detection dataset, expanding the training set from 5,082 to 6,513 samples. Second, they fine-tuned two transformer models - RoBERTa-base (encoder-only) and Flan-T5-base (encoder-decoder) - with consistent hyperparameters including AdamW optimizer and 100 epochs. The Flan-T5 model used instruction-formatted inputs with a prefix, while RoBERTa used text-only inputs. Evaluation metrics included macro F1-score, accuracy, precision, and recall on a held-out test set of 997 samples.

## Key Results
- Flan-T5-base achieved superior performance with F1-scores of 77.40 (hazard) and 78.10 (product) using augmented data
- Data augmentation improved F1-scores by approximately 4 points for both models
- RoBERTa-base showed shorter training times due to smaller model size (125M vs 248M parameters)
- The product-category task (22 classes) performed worse than hazard-category (10 classes), consistent with the higher class imbalance in the former

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Targeted augmentation of underrepresented classes improves classification by reducing overfitting risk on minority samples.
- Mechanism: Classes with few samples (e.g., "migration" with 3 samples, "sugars and syrups" with 5) are augmented to create sufficient training signal. This expands the decision boundary coverage for rare classes, allowing the model to learn their structural patterns rather than memorizing sparse examples.
- Core assumption: The LLM-generated samples preserve semantic fidelity to the original class labels and introduce meaningful lexical variation without label noise.
- Evidence anchors: [abstract] "Results indicate that using augmented data helped improve model performance across key metrics... compared to using only the provided dataset." [section 5] "This imbalance can increase the risk of overfitting, preventing the model from learning the structures of classes with small number of samples effectively."
- Break condition: If generated samples contain systematic label errors or drift from original class semantics, performance gains may reverse; validation through human review or held-out quality checks is recommended.

### Mechanism 2
- Claim: Encoder-decoder architecture with instruction fine-tuning (Flan-T5) outperforms encoder-only architecture (RoBERTa) on complex multi-class text classification.
- Mechanism: Flan-T5's instruction fine-tuning enables better task understanding through natural language prompts. The encoder-decoder structure provides richer representation learning for sequence-to-sequence formulation, and the larger parameter count (248M vs 125M) captures more complex text patterns.
- Core assumption: The performance difference is attributable to architecture and pre-training strategy rather than hyperparameter selection.
- Evidence anchors: [section 4] "Flan-T5 achieved the highest score of 78. RoBERTa with augmentation followed with 76.83." [section 5] "FLAN-T5 has a larger model size than RoBERTa, with 248 million parameters compared to RoBERTa's 125 million."
- Break condition: If computational budget is constrained, RoBERTa with augmentation provides acceptable performance with faster training; the mechanism assumes access to GPU resources for full training.

### Mechanism 3
- Claim: Prompt-engineered augmentation focusing on semantic preservation maintains label consistency while expanding training diversity.
- Mechanism: The augmentation prompt (Figure 3) instructs ChatGPT-4o-mini to generate new samples that preserve the original hazard/product category. This creates syntactic variation while maintaining semantic class membership, effectively expanding the within-class variance the model observes during training.
- Core assumption: ChatGPT-4o-mini correctly interprets and follows the augmentation instructions without introducing systematic biases or hallucinated hazard types.
- Evidence anchors: [section 3.2] "We focused on increasing the number of samples for classes with a small sample number, such as the migration class." [section 4] "Both models saw an increase of approximately four points in F1-score."
- Break condition: If generated text diverges semantically from food safety domain conventions, model may learn spurious patterns; manual inspection of augmented samples is advised before full training runs.

## Foundational Learning

- Concept: **Class Imbalance in Multi-Class Classification**
  - Why needed here: The dataset has 22 product categories with sample counts ranging from 5 to 1,504. Understanding how imbalance affects gradient-based learning (minority classes contribute less to loss) explains why augmentation helps.
  - Quick check question: Can you explain why a model trained on imbalanced data might achieve high accuracy but low macro F1-score?

- Concept: **Encoder-Only vs Encoder-Decoder Architectures**
  - Why needed here: RoBERTa (encoder-only) and Flan-T5 (encoder-decoder) have different inductive biases. Understanding these differences informs model selection for text classification tasks.
  - Quick check question: What is the functional difference between using a model trained with masked language modeling objectives versus one trained with sequence-to-sequence objectives?

- Concept: **Instruction Fine-Tuning (FLAN methodology)**
  - Why needed here: Flan-T5's superior performance may derive from its instruction fine-tuning pre-training phase, which enables better task comprehension from natural language prompts.
  - Quick check question: How does instruction fine-tuning differ from traditional supervised fine-tuning, and why might it improve zero-shot task performance?

## Architecture Onboarding

- Component map: Original dataset (5,082 samples) + ChatGPT-4o-mini augmented samples (1,431 new) → 6,513 total training samples → Fine-tune RoBERTa-base and Flan-T5-base → Evaluate on held-out test set (997 samples)

- Critical path: Identify underrepresented classes from training distribution → Design augmentation prompt specifying target class and desired output format → Generate augmented samples via ChatGPT-4o-mini API → Merge augmented samples with original training data → Fine-tune models with consistent hyperparameters → Evaluate on unchanged test set to isolate augmentation effect

- Design tradeoffs:
  - Performance vs Training Time: Flan-T5 achieves +1-2 F1 points over RoBERTa but requires ~2x training time
  - Augmentation Cost vs Dataset Size: API costs for 1,431 augmented samples must be weighed against performance gains (~4 F1 points)
  - Prompt Complexity vs Sample Quality: More detailed prompts may improve semantic fidelity but risk constraining lexical diversity

- Failure signatures:
  - F1-score plateaus or decreases after augmentation (indicates label noise in generated samples)
  - Large gap between precision and recall (suggests class-specific overfitting)
  - Training time scaling unexpectedly with augmented dataset (may indicate tokenization issues or memory constraints)
  - Model performs well on hazard-category (10 classes) but poorly on product-category (22 classes) without corresponding data investment

- First 3 experiments:
  1. Baseline Reproduction: Train both models on original dataset only; confirm reported baseline F1-scores (RoBERTa: 73.82/71.82, Flan-T5: 74.90/77.38) to validate pipeline integrity.
  2. Augmented Subset Analysis: Augment only the 5 most underrepresented classes (e.g., migration, sugars, feed materials, food contact materials, honey) and measure incremental performance change to isolate augmentation effect.
  3. Sample Quality Audit: Manually review 50 randomly selected augmented samples per model path for semantic correctness and label consistency; document error rate before scaling to full dataset augmentation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of instructional prefixes affect the comparative performance between RoBERTa and Flan-T5 in this specific task?
- Basis in paper: [inferred] Table 1 indicates Flan-T5 used an input format of "Classify the hazard category: " + text, whereas RoBERTa used text only, introducing a confounding variable in the architectural comparison.
- Why unresolved: The authors attribute performance differences primarily to model size and architecture, failing to isolate the impact of the prompt prefix on the encoder-decoder vs. encoder-only structure.
- What evidence would resolve it: An ablation study fine-tuning both models with and without instructional prefixes on the same augmented dataset.

### Open Question 2
- Question: To what extent does synthetic data generated by ChatGPT-4o-mini introduce factual inaccuracies or label noise in classes with minimal original samples?
- Basis in paper: [inferred] The authors expanded the "migration" class from 3 to 129 samples and "food contact materials" from 7 to 136 purely via generation, without qualitative analysis of the generated content.
- Why unresolved: Evaluation relies solely on automatic metrics (F1-score) against a test set, which may mask hallucinations or semantic drift in the training data that could degrade real-world reliability.
- What evidence would resolve it: A human evaluation of the generated synthetic samples to assess semantic fidelity and factual accuracy relative to the original samples.

### Open Question 3
- Question: Is the observed improvement robust against changes in the augmentation prompting strategy?
- Basis in paper: [inferred] The study utilizes a specific prompt (Figure 3) to generate data, but does not analyze the sensitivity of the model's performance to the phrasing or structure of this prompt.
- Why unresolved: The effectiveness of LLM-based augmentation is highly prompt-dependent; the results may not generalize if the prompt fails to capture the nuances of specific hazard categories.
- What evidence would resolve it: Comparing model performance when fine-tuned on datasets generated by varying the complexity and style of the augmentation prompt.

## Limitations

- The study lacks quality assessment of ChatGPT-4o-mini generated samples, potentially introducing label noise that could degrade real-world reliability
- The architectural comparison between RoBERTa and Flan-T5 does not include ablation studies to isolate whether performance differences stem from model size, architecture, or instruction fine-tuning
- Class imbalance remains a significant challenge, particularly for the product-category task with 22 classes where some categories have fewer than 10 samples

## Confidence

- **High Confidence**: The core finding that data augmentation improves F1-scores by approximately 4 points for both models is well-supported by the reported results and aligns with established machine learning principles for handling class imbalance.
- **Medium Confidence**: The observation that Flan-T5-base outperforms RoBERTa-base is reproducible, but the attribution to instruction fine-tuning and encoder-decoder architecture versus model size differences remains uncertain without ablation studies.
- **Low Confidence**: The proposed mechanisms explaining why augmentation and architecture choices work (semantic fidelity of generated samples, encoder-decoder advantages for text classification) are plausible but lack direct empirical validation in this study or the broader corpus.

## Next Checks

1. **Sample Quality Validation**: Conduct a blind review of 100 randomly selected augmented samples by domain experts to assess semantic correctness and label consistency. Calculate the error rate and correlate with model performance degradation to establish the upper bound of augmentation benefits.

2. **Architectural Ablation Study**: Train a control model using RoBERTa-base with instruction fine-tuning capabilities (via prompt engineering) to isolate whether the performance gain comes from instruction tuning versus the encoder-decoder architecture itself. Compare against Flan-T5-base with equivalent parameter count.

3. **Alternative Augmentation Comparison**: Implement and compare three alternative augmentation strategies (synonym replacement, back-translation, and few-shot prompting with different LLM models) against the ChatGPT-4o-mini approach to determine if the reported gains are specific to this method or represent a general principle of minority class augmentation.