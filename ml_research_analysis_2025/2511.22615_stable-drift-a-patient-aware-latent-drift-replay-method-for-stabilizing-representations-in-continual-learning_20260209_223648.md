---
ver: rpa2
title: 'Stable-Drift: A Patient-Aware Latent Drift Replay Method for Stabilizing Representations
  in Continual Learning'
arxiv_id: '2511.22615'
source_url: https://arxiv.org/abs/2511.22615
tags:
- learning
- drift
- replay
- domain
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses catastrophic forgetting in continual learning
  for medical imaging, where models lose performance on previously learned tasks when
  adapting to new data from different hospitals. The proposed method, Stable-Drift,
  uses latent drift-guided replay to identify and store samples with high representational
  instability.
---

# Stable-Drift: A Patient-Aware Latent Drift Replay Method for Stabilizing Representations in Continual Learning

## Quick Facts
- **arXiv ID**: 2511.22615
- **Source URL**: https://arxiv.org/abs/2511.22615
- **Reference count**: 38
- **One-line primary result**: Stable-Drift significantly reduces catastrophic forgetting in cross-hospital COVID-19 CT classification, outperforming naive fine-tuning and random replay baselines by using patient-aware latent drift-guided replay.

## Executive Summary
Stable-Drift addresses catastrophic forgetting in continual learning for medical imaging, where models lose performance on previously learned tasks when adapting to new data from different hospitals. The method uses latent drift-guided replay to identify and store samples with high representational instability, calculated as the change in feature representations between a source-trained model and one fine-tuned on target data. Evaluated on a cross-hospital COVID-19 CT classification task, Stable-Drift significantly outperforms naive fine-tuning and random replay baselines, reducing forgetting and improving overall performance.

## Method Summary
Stable-Drift is a three-stage continual learning method for medical imaging. First, it quantifies representational instability (latent drift) by computing the cosine distance between a sample's feature representation in a source-trained model and a naively fine-tuned target model, aggregated across the final two backbone layers. Second, it builds a patient-aware replay buffer by ranking patients by average latent drift and selecting the top 30 slices from the highest-drift patients. Third, it trains a model on the target data while mixing in samples from the buffer, initializing from the source model. The method was evaluated on ResNet50 and Swin Transformer backbones for binary COVID-19 CT classification across two hospitals.

## Key Results
- Stable-Drift significantly outperformed naive fine-tuning and random replay baselines in reducing catastrophic forgetting on cross-hospital COVID-19 CT classification.
- Patient-aware buffer selection improved per-patient H1 accuracy from 82.01% to 92.45% compared to global slice selection.
- Multi-layer drift aggregation (using final two layers) improved H1 retention compared to single-layer analysis.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Samples with high latent drift between source and fine-tuned model states are at greater risk of being forgotten and are thus high-value candidates for replay.
- Mechanism: The method quantifies representational instability by calculating Multi-Layer Latent Drift (MLD)—the average cosine distance between a sample's feature representation in a source-trained model ($M_A$) and a naively fine-tuned target model ($M_B$). High MLD indicates that adaptation has corrupted the sample's representation, making it a priority for retention.
- Core assumption: The magnitude of feature-space change after naive adaptation is a reliable proxy for forgetting risk, and replaying these high-drift samples will stabilize the model's internal representation more effectively than replaying random samples.
- Evidence anchors:
  - [abstract] "...quantifies this instability via latent drift, the change in a sample’s internal feature representation after naive domain adaptation."
  - [Section 3.1.2] "A high MLD score identifies a sample as having high representational instability and thus a high risk of being forgotten."
  - [corpus] Corpus evidence supports the general use of latent replay, but direct validation of drift-as-a-selection-signal is limited to this paper's findings.
- Break condition: The correlation between MLD and forgetting risk breaks if high drift reflects beneficial adaptation rather than destructive forgetting, or if the selected layers do not capture task-critical semantic information.

### Mechanism 2
- Claim: Patient-aware buffer selection improves replay diversity and clinical relevance compared to global selection.
- Mechanism: The algorithm groups data by patient, ranks slices within each patient by MLD, and populates the buffer by taking the top S slices (e.g., 30) from the highest-drift patients first. This prevents the buffer from being dominated by slices from a few outlier cases.
- Core assumption: In medical imaging, critical diagnostic features are distributed across patients. A buffer that is diverse at the patient level is more effective for stabilizing the overall decision boundary than one that is globally dense but patient-sparse.
- Evidence anchors:
  - [abstract] "...aggregating drift scores at the patient level; our memory buffer stores the per-patient slices exhibiting the greatest multi-layer representation shift."
  - [Section 6.2.1] "...patient-aware selection boosts per-patient H1 accuracy from 82.01%... to a remarkable 92.45%... a global strategy risks creating a redundant buffer by over-sampling from a few difficult patients."
  - [corpus] No strong corpus evidence found challenging this patient-aware approach.
- Break condition: Benefits diminish if the per-patient slice quota (S) is too small to capture essential pathology or if the total buffer size (K) is too small to include a sufficiently diverse patient cohort.

### Mechanism 3
- Claim: Multi-layer drift aggregation provides a more robust signal for forgetting risk than single-layer analysis.
- Mechanism: MLD is computed by averaging cosine distances from the final two layers of the backbone ($L$ and $L-1$). This is intended to capture representational changes at multiple levels of semantic abstraction and reduce noise from any single layer.
- Core assumption: Forgetting is a hierarchical process affecting features at different network depths. A multi-layer measure is more holistic and stable than a single-layer proxy.
- Evidence anchors:
  - [abstract] "...aggregating drift scores... across multiple model layers."
  - [Section 6.2.2] "...using a multi-layer signal improves per-patient H1 retention... This suggests that forgetting is a complex process affecting features at multiple levels of semantic abstraction..."
  - [corpus] Related work on feature-space vs. classifier-level forgetting (e.g., "Asymptotic analysis of shallow and deep forgetting") provides indirect theoretical support.
- Break condition: The benefit is lost if chosen layers provide redundant information or if the distance metric (cosine) is inappropriate for the feature distributions of both layers.

## Foundational Learning
- Concept: **Catastrophic Forgetting**
  - Why needed here: This is the core failure mode the paper addresses. A new engineer must understand that sequential fine-tuning on new hospital data will, by default, cause a severe loss of diagnostic accuracy on the original hospital's data.
  - Quick check question: In Table 3, what is the approximate drop in H1 accuracy for the Swin Transformer model after Naive Fine-tuning, compared to the Source-Only model?

- Concept: **Replay-Based Continual Learning**
  - Why needed here: The proposed method is a variant of this core strategy. Understanding that mixing a small subset of past data (the buffer) with new data during training is the mechanism for stabilizing knowledge is essential.
  - Quick check question: How does the composition of the replay buffer differ between the 'Random Replay' baseline and the proposed 'Stable-Drift' method?

- Concept: **Domain Adaptation vs. Continual Learning**
  - Why needed here: The paper explicitly contrasts its setting with standard domain adaptation. A key difference is that in CL, the model does not have simultaneous access to both domains; it must learn sequentially without forgetting.
  - Quick check question: Why is a model trained with standard domain adaptation techniques likely to fail in the sequential learning scenario described in the paper?

## Architecture Onboarding
- Component map: Source Model ($M_A$) -> Naively Fine-tuned Model ($M_B$) -> Latent Drift Calculator -> Buffer Manager -> Continual Learning Trainer
- Critical path:
  1. **Phase 1 (Analysis):** Train $M_A$ on H1. Create $M_B$ by fine-tuning $M_A$ on H2. Use both to calculate MLD for all H1 training samples.
  2. **Phase 2 (Buffer Construction):** Run the patient-aware buffer selection algorithm (Alg. 1) using the calculated MLD scores.
  3. **Phase 3 (CL Training):** Initialize a fresh model from $M_A$. Train on H2 data, mixing in samples from buffer B in each mini-batch (50% probability).
- Design tradeoffs:
  - **Cosine vs. Euclidean Distance:** The paper argues for cosine distance as a proxy for semantic shift, but results (Table 6) show Euclidean distance is a strong alternative. The choice is not strictly settled.
  - **Buffer Size (K) vs. Slices per Patient (S):** A larger K improves retention but increases storage. A larger S captures more of a patient's case but reduces patient diversity for a fixed K.
  - **Multi-layer vs. Single-layer:** Using two layers adds computation but is shown to improve the robustness of the drift signal (Table 5).
- Failure signatures:
  - **No improvement over Random Replay:** Indicates MLD scores are not correlated with true forgetting risk (e.g., high drift is just noise).
  - **Good H2, Poor H1 performance:** Suggests the replay buffer content was insufficient to anchor source knowledge, or the learning rate was too aggressive.
  - **Buffer dominated by few patients:** Indicates a failure in the patient-aware logic (e.g., global selection was used instead).
- First 3 experiments:
  1. **Establish Baseline & Forgetting:** Train a backbone on H1, then fine-tune on H2 naively. Quantify the drop in H1 accuracy to confirm catastrophic forgetting.
  2. **Validate Patient-Aware Selection:** Implement the full Stable-Drift pipeline and compare its H1/H2 accuracy against a 'Random Replay' baseline and a 'Global Slice Selection' ablation. This tests the core hypothesis.
  3. **Validate Multi-Layer Drift:** Run an ablation comparing the proposed 'Multi-Layer Drift' signal against a 'Single-Layer Drift' variant. This tests the contribution of the multi-layer design.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's effectiveness is demonstrated on a single dataset (COVID-19 CT classification), limiting generalizability to other medical imaging tasks and modalities.
- The approach relies on the assumption that high latent drift correlates with forgetting risk, which, while supported by the paper's results, has not been extensively validated across diverse scenarios.
- The choice of using cosine distance over Euclidean distance, while justified in the paper, is not conclusively proven as superior in all contexts.

## Confidence
- Confidence in the core claim that patient-aware, drift-guided replay outperforms random replay is **High**, given the clear experimental comparisons and statistically significant improvements in Table 3 and Table 4.
- Confidence in the multi-layer drift aggregation mechanism's contribution is **Medium**, as the ablation study (Table 5) shows improvement, but the theoretical underpinning for why two specific layers are optimal is not deeply explored.
- Confidence in the buffer size and slice-per-patient hyperparameters is **Medium**, as these are set empirically without a systematic sensitivity analysis.

## Next Checks
1. Reproduce the main results on the proposed COVID-19 CT dataset to verify the claimed improvements over baselines.
2. Conduct an ablation study replacing the patient-aware selection with a global selection strategy on the same dataset to isolate the impact of the patient-awareness mechanism.
3. Test the method on a different medical imaging task (e.g., multi-class X-ray classification) to assess generalizability beyond the COVID-19 binary classification setting.