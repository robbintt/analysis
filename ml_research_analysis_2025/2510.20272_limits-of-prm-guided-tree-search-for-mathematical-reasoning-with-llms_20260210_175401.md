---
ver: rpa2
title: Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs
arxiv_id: '2510.20272'
source_url: https://arxiv.org/abs/2510.20272
tags:
- search
- tree
- reasoning
- beam
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PRM-guided tree search fails to outperform Best-of-N despite higher
  costs when solving mathematical reasoning problems with large language models. The
  study evaluates multiple tree search algorithms (MCTS, beam search, greedy search)
  using Qwen2.5-Math-7B-Instruct and its PRM across 23 problems.
---

# Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs

## Quick Facts
- **arXiv ID**: 2510.20272
- **Source URL**: https://arxiv.org/abs/2510.20272
- **Reference count**: 0
- **Primary result**: PRM-guided tree search fails to outperform Best-of-N selection for mathematical reasoning tasks with current PRMs

## Executive Summary
This study evaluates whether PRM-guided tree search methods (MCTS, beam search, greedy search, GBFS, Gittins-based) can improve mathematical reasoning performance compared to simple Best-of-N selection using large language models. The evaluation uses Qwen2.5-Math-7B-Instruct with its PRM across 23 mathematical reasoning problems from various benchmarks. The results show that Best-of-N with terminal PRM scores achieves the highest accuracy (72.7%), while tree search methods perform comparably but at substantially higher computational cost. The PRM poorly approximates state values, with reliability degrading significantly with reasoning depth—correlation between PRM scores and correctness drops from ~0.5 near terminal states to ~0.37 at 10 steps from termination. This credit assignment issue, combined with limited out-of-distribution generalization, explains why tree search methods underperform despite their ability to explore multiple reasoning paths.

## Method Summary
The study evaluates tree search algorithms guided by a PRM for mathematical reasoning using Qwen2.5-Math-7B-Instruct and Qwen2.5-Math-PRM-7B. The experimental setup includes 23 mathematical reasoning problems from various benchmarks. The method compares Best-of-N selection with tree search variants including MCTS, beam search, greedy search, GBFS, and Gittins-based approaches. All methods use the PRM to evaluate states and guide search decisions. The evaluation measures mean accuracy with standard errors, mean rank across problems, and token generation costs. Tree search algorithms explore reasoning paths using PRM-guided heuristics, while Best-of-N generates multiple complete solutions and selects the highest-scoring one.

## Key Results
- Best-of-N with terminal PRM scores achieves highest accuracy (72.7%) with lowest computational cost (~8M tokens)
- MCTS and beam search perform comparably to Best-of-N but generate ~10x more tokens (~89M)
- PRM correlation with correctness drops from ~0.5 near terminal states to ~0.37 at 10 steps from termination
- Tree search methods show no significant improvement over Best-of-N despite higher costs

## Why This Works (Mechanism)
Tree search methods rely on PRM evaluations at intermediate reasoning steps to guide exploration, while Best-of-N only evaluates complete solutions. When PRMs poorly estimate intermediate state values (due to credit assignment issues and OOD generalization problems), tree search cannot effectively distinguish promising from unpromising reasoning paths. This leads to inefficient exploration and no accuracy gains despite higher computational costs.

## Foundational Learning

**Reward Modeling** - Predicting solution quality from intermediate reasoning states
*Why needed*: Enables tree search to evaluate partial solutions and guide exploration
*Quick check*: PRM score correlation with correctness should be stable across reasoning depths

**Credit Assignment** - Determining which reasoning steps contributed to correct/incorrect final answers
*Why needed*: Essential for training PRMs to accurately value intermediate states
*Quick check*: PRM reliability should not degrade significantly with reasoning depth

**Tree Search Algorithms** - Methods for exploring multiple reasoning paths through branching decisions
*Why needed*: Can potentially find better solutions than greedy single-path generation
*Quick check*: Search algorithms should reduce to baseline when PRM guidance is removed

## Architecture Onboarding

**Component Map**: LLM -> Reasoning Generator -> PRM -> Search Algorithm -> Solution Selector

**Critical Path**: Problem input → LLM generation (with PRM guidance) → State evaluation → Search decision → Final answer selection

**Design Tradeoffs**: Exploration vs. exploitation in search (tree search) vs. simplicity and cost-effectiveness (Best-of-N)

**Failure Signatures**: High computational cost without accuracy improvement, PRM score instability across reasoning depths, search algorithms defaulting to greedy behavior

**First Experiments**: 1) Verify PRM correlation with correctness at different reasoning depths, 2) Compare token generation costs across methods, 3) Test search algorithm behavior with random PRM scores

## Open Questions the Paper Calls Out

**Open Question 1**: What alternative reward modeling approaches could enable tree search to outperform Best-of-N for mathematical reasoning? The paper identifies problems but doesn't propose solutions.

**Open Question 2**: Can PRM training be modified to maintain reliable value estimation across all reasoning depths? The correlation degradation from ~0.5 to ~0.37 needs addressing.

**Open Question 3**: Do these findings generalize to other LLM-PRM pairs beyond Qwen2.5-Math-7B-Instruct and its associated PRM? Only one model-PRM pair was evaluated.

**Open Question 4**: Can hybrid approaches combining tree search with online PRM adaptation overcome the identified limitations? The study used only frozen pretrained models.

## Limitations

- Single model-PRM pair evaluation limits generalizability
- Small sample size (23 problems) may not capture full problem space
- Computational constraints prevented testing larger models
- Only evaluates mathematical reasoning, not other domains

## Confidence

**Empirical Finding**: High - Clear evidence that tree search fails to outperform Best-of-N with current PRMs
**Generalizability**: Medium - Limited to one model-PRM pair and specific problem types
**Mechanism Understanding**: Medium - Correlation analysis explains failures but doesn't prove causation

## Next Checks

1. **Model Family Generalization**: Replicate with alternative LLMs (Llama-3-Math, DeepSeek-Math) and their PRMs to test if tree search failure is universal

2. **PRM Architecture Variations**: Test whether alternative PRM designs trained with different reward signals can maintain higher correlation with correctness across reasoning depths

3. **Problem Distribution Analysis**: Systematically categorize the 23 problems by reasoning depth and mathematical domain to identify if tree search failures are concentrated in specific problem types