---
ver: rpa2
title: Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented
  Recommender Systems
arxiv_id: '2505.05196'
source_url: https://arxiv.org/abs/2505.05196
tags:
- item
- items
- attacks
- retrieval
- poisoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines stealthy data poisoning in retrieval-augmented
  recommender systems by modifying only small portions of item descriptions. Three
  attack types are proposed: emotional keyword insertion, neighbor-based phrase borrowing,
  and a chained combination of both.'
---

# Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems

## Quick Facts
- arXiv ID: 2505.05196
- Source URL: https://arxiv.org/abs/2505.05196
- Reference count: 13
- Demonstrates stealthy data poisoning attacks on RAG-based recommenders via small item description edits

## Executive Summary
This paper investigates provider-side data poisoning in retrieval-augmented recommender systems by making subtle modifications to item descriptions. The attacks employ large language models to rewrite metadata with emotional keywords or neighbor-derived phrases, aiming to promote long-tail items or demote popular ones while maintaining high semantic similarity to evade detection. Experiments on MovieLens show significant rank shifts (e.g., promotion from rank 7.0 to 4.7, demotion from 5.7 to 4.4) while system-level metrics like Recall and nDCG remain relatively stable, highlighting the vulnerability of RAG-based pipelines to provider-side poisoning through metadata rewrites.

## Method Summary
The paper proposes three attack types on retrieval-augmented recommender systems: emotional keyword insertion (injecting sentiment-laden words), neighbor-based phrase borrowing (extracting phrases from top-5 embeddings-based neighbors in the opposite popularity segment), and a chained combination of both. Attacks are constrained to modify ≤10% of tokens while maintaining SBERT similarity ≥0.80. The pipeline uses Sentence Transformer retrieval (Top-N=50) followed by OpenAI LLM re-ranking (Top-K=20). Experiments use MovieLens ml-latest-small dataset with items segmented into long-tail vs short-head by popularity, targeting specific items for promotion or demotion.

## Key Results
- Emotional keyword attacks achieved promotion from rank 7.0 to 4.7 and demotion from 5.7 to 4.4
- Neighbor-based attacks showed similar rank manipulation effectiveness
- System-level metrics (Recall@20, nDCG@20) remained relatively stable despite targeted rank shifts
- Semantic similarity consistently maintained above the 0.80 threshold across all attack types

## Why This Works (Mechanism)
The attacks exploit the semantic gap between item embeddings and LLM-based re-ranking. By injecting emotionally charged language or borrowing phrases from semantically similar but popularity-opposite items, the attacks manipulate the re-ranker's scoring while maintaining high embedding similarity. The chained approach combines both effects for maximum impact. The 10% token budget constraint ensures modifications remain stealthy while still significantly altering the LLM's interpretation of item relevance.

## Foundational Learning
- **Semantic embeddings**: Vector representations capturing item meaning; needed to identify similar items for neighbor attacks; quick check: compute SBERT similarity between original and modified descriptions
- **Popularity segmentation**: Dividing items into long-tail vs short-head based on interaction counts; needed to define attack targets; quick check: verify distribution follows power law
- **LLM re-ranking**: Using generative models to refine retrieval results; needed to understand attack surface; quick check: compare rankings before/after re-ranking
- **Stealth constraints**: Semantic similarity and token edit budget limits; needed to evade detection; quick check: measure SBERT similarity and token count changes
- **Retrieval-augmented pipelines**: Combining embedding-based retrieval with LLM re-ranking; needed to understand system architecture; quick check: trace data flow through both components

## Architecture Onboarding

**Component Map**: Item descriptions -> Sentence Transformer embeddings -> Top-N retrieval -> OpenAI re-ranking -> User recommendations

**Critical Path**: Description modification → Embedding computation → Retrieval (Top-N) → Re-ranking (Top-K) → Rank shift measurement

**Design Tradeoffs**: The 10% token budget balances attack effectiveness against stealthiness; higher budgets increase rank shifts but risk detection; lower budgets maintain stealth but reduce impact.

**Failure Signatures**: Semantic similarity dropping below 0.80 threshold, rank shifts not materializing in re-ranked results, or system metrics degrading beyond acceptable thresholds.

**First 3 Experiments**:
1. Run emotional keyword insertion on a single target item and verify SBERT similarity remains ≥0.80
2. Compare rank shifts when using only retrieval vs. full retrieval+re-ranking pipeline
3. Measure rank shift effectiveness across different popularity thresholds for long-tail/short-head segmentation

## Open Questions the Paper Calls Out

**Open Question 1**: Does large-scale poisoning cause systemic collapse in global metrics (Recall, nDCG), unlike the stability observed in sparse attacks? The paper suggests this but experiments focused on specific item subsets rather than database saturation.

**Open Question 2**: Can automated textual consistency checks or provenance tracking effectively filter these attacks without blocking legitimate metadata updates? The study calls for these countermeasures but does not test specific defensive algorithms.

**Open Question 3**: Are these rewriting strategies effective on datasets with sparse textual metadata (e.g., short product titles) versus the rich descriptions found in MovieLens? The 10% token-edit budget may be infeasible for short-form metadata.

## Limitations

- Unspecified popularity threshold for long-tail vs short-head segmentation
- Unclear source/format of item descriptions (MovieLens lacks rich descriptions)
- Undisclosed LLM prompts for attack generation
- Dependency on commercial APIs (OpenAI, Sentence Transformers)

## Confidence

- **High confidence**: Core attack methodology and measurable rank manipulation results
- **Medium confidence**: Stealthiness claims supported by SBERT metrics
- **Low confidence**: Generalizability to other datasets and defensive measure effectiveness

## Next Checks

1. **Threshold sensitivity analysis**: Systematically vary popularity thresholds and measure attack effectiveness scaling
2. **Cross-model robustness**: Test attacks with different embedding and re-ranking models to assess model-specific vulnerabilities
3. **Semantic similarity trade-off**: Vary SBERT threshold (0.70, 0.80, 0.90) to quantify relationship between stealthiness and effectiveness