---
ver: rpa2
title: What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions
  to a Live Dance Performance
arxiv_id: '2508.00239'
source_url: https://arxiv.org/abs/2508.00239
tags:
- performance
- tell
- after
- visuals
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explored audience perceptions of generative AI (GenAI)
  in a live dance performance. Researchers created two versions of a 12-minute performance:
  one using GenAI for visual and sound mapping, and one using traditional digital
  tools.'
---

# What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions to a Live Dance Performance

## Quick Facts
- **arXiv ID:** 2508.00239
- **Source URL:** https://arxiv.org/abs/2508.00239
- **Reference count:** 28
- **Primary result:** Audiences attributed more artistic merit to GenAI visuals when unaware of its use; disclosure before viewing increased pattern-seeking and distraction ratings.

## Executive Summary
This study explored audience perceptions of generative AI (GenAI) in a live dance performance. Researchers created two versions of a 12-minute performance: one using GenAI for visual and sound mapping, and one using traditional digital tools. Forty participants were divided into four groups, each experiencing either version with or without prior disclosure of the technology used. Results showed that audiences attributed more artistic merit to GenAI-generated visuals when unaware of its use. Those informed beforehand were more attentive to patterns and found visuals more distracting. In contrast, audiences informed after the performance rated GenAI visuals higher in artistic value and expressed greater curiosity. The study highlights how transparency about technology influences artistic perception and calls for greater focus on explaining GenAI's presence and mechanics in creative contexts.

## Method Summary
A 2×2 between-subjects experimental design tested audience perceptions of GenAI versus traditional digital tools in a live 12-minute dance performance, with disclosure timing (before/after) as the second factor. Forty participants (39 usable) were divided into four groups (AI/Tell Before n=12, AI/Tell After n=9, Non-AI/Tell Before n=8, Non-AI/Tell After n=10). Sensor data from respiration belts and motion capture tracked dancers in real time. AI condition used ChatGPT for mapping ideation and Wekinator neural networks (3 models, 4 inputs, 1 hidden layer, 4 nodes) for classification. Non-AI condition used human-designed mappings. Participants completed Likert surveys measuring artistic merit, distraction, randomness perception, and curiosity.

## Key Results
- AI/Tell After rated visuals significantly higher in artistic merit (M=4.11) than AI/Tell Before (M=2.83), Z=-2.501, p=.012
- AI/Tell Before rated visuals as more "random" (M=3.67) than AI/Tell After (M=2.22), Z=-2.698, p=.007
- Non-AI/Tell Before showed highest pattern-seeking behavior (M=4.88) compared to other groups
- Post-hoc disclosure generated greater curiosity while preserving initial aesthetic impressions

## Why This Works (Mechanism)

### Mechanism 1: Pre-Disclosure Shifts Processing from Aesthetic to Analytical
Disclosing AI involvement before viewing triggers analytical rather than immersive aesthetic processing. Prior knowledge of GenAI presence redirects attention from experiencing art to evaluating technology. Audiences search for patterns, question causation, and assess whether outputs "make sense." This analytical stance correlates with higher "appeared random" ratings and lower artistic merit scores.

### Mechanism 2: Learned Value Magnifies Attentional Capture
Technology awareness increases visual saliency, making elements more attention-demanding. When audiences know technology is present, visual elements acquire "learned value"—they become meaningful signals rather than background. This elevates attentional priority, increasing pattern-seeking behavior and perceived distractibility.

### Mechanism 3: Post-Hoc Disclosure Preserves Aesthetic Judgment
Learning about AI involvement after viewing preserves initial aesthetic evaluation while generating curiosity. Post-hoc disclosure prevents pre-emptive skepticism. Aesthetic impressions form without "AI bias," and subsequent disclosure creates an information gap that drives curiosity rather than retroactive devaluation.

## Foundational Learning

- **Concept: Between-Subjects Experimental Design**
  - **Why needed here:** Understanding how the 2×2 design isolates causal effects without carryover.
  - **Quick check question:** Why can't the same participants experience both AI and Non-AI versions without contamination?

- **Concept: Non-Parametric Statistics (Mann-Whitney U)**
  - **Why needed here:** Likert-scale data is ordinal; the study uses Mann-Whitney tests rather than t-tests to compare groups.
  - **Quick check question:** What assumption about data distribution does Mann-Whitney avoid that t-tests require?

- **Concept: Real-Time Data Mapping for Live Performance**
  - **Why needed here:** The system transforms dancer respiration and position data into visual/audio outputs with acceptable latency.
  - **Quick check question:** What sensor inputs drive the visual petals, waves, and stars—and how are they mapped?

## Architecture Onboarding

- **Component map:**
```
Data Capture:
├── Vernier Go Direct Respiration Belt → breathing rate
├── Qualisys Track Manager (QTM) + reflective ankle markers → (x,y,z) position

Processing:
├── Non-AI version: Human-designed mappings (layered images, conditional changes)
├── AI version:
│   ├── ChatGPT → mapping ideation (prompts/responses in Appendix B.1)
│   └── Wekinator → 3 neural networks (4 inputs, 1 hidden layer, 4 nodes each)
│       └── Inputs: x/y coordinate sums from 4 ankle markers
│       └── Outputs: probabilities for 3 dance subroutines

Output:
├── Visuals → large mounted TV (petals, waves, stars per scene)
├── Audio (Scene 2) → 5×5×5 spatial grid mapped to pentatonic/minor/chromatic scales
```

- **Critical path:**
  1. Sensor data acquisition must be stable (infrared tracking, respiration belt pairing).
  2. Mapping latency must stay below perceptual threshold (target <100ms for live sync).
  3. For AI version: collect rehearsal data → train Wekinator models → validate in real time.
  4. ChatGPT prompts must be refined to produce implementable mapping suggestions.

- **Design tradeoffs:**
  - GenAI ideation (ChatGPT) vs. human design: faster exploration, less fine-grained control.
  - Pre- vs. post-disclosure: transparency vs. preserved aesthetic reception.
  - Simple neural networks (Wekinator) vs. complex models: more explainable, less powerful.

- **Failure signatures:**
  - Infrared marker occlusion → position data dropouts → visual/audio glitches.
  - Mapping latency >150ms → perceptible lag, audience reports disconnect.
  - ChatGPT outputs too generic → "appeared random" ratings increase.
  - Over-complex spatial sonification grid → audience cannot infer dancer→sound relationship.

- **First 3 experiments:**
  1. **Latency threshold test:** Present audiences with 50ms, 100ms, 200ms lags; measure detection rates and "distracting" ratings.
  2. **Mapping complexity gradient:** Compare 3×3×3 vs. 5×5×5 vs. 7×7×7 spatial grids on perceived complementarity and randomness.
  3. **Disclosure framing study:** Test neutral ("AI was used") vs. enthusiastic ("AI co-created") vs. technical ("neural networks mapped...") pre-disclosure on artistic merit ratings.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does integrating explanations of AI mechanics (as opposed to solely disclosing AI presence) influence audience perceptions of artistic merit?
- **Basis in paper:** The authors state, "It could be valuable to design a future study integrating these two approaches towards XAI: knowledge of AI's presence and knowledge of AI's mechanics."
- **Why unresolved:** This study only tested the disclosure of AI presence (before/after) and explicitly omitted technical explanations of how the AI worked.
- **What evidence would resolve it:** A follow-up study comparing conditions where audiences receive technical explanations of the algorithms versus simple disclosure of AI usage.

### Open Question 2
- **Question:** Do distinct types of AI tools (e.g., generative LLMs vs. traditional neural networks) require different explainability methodologies in artistic contexts?
- **Basis in paper:** The authors note they "utilized both GenAI... and traditional AI" and suggest "The XAI community may benefit from isolating these AI tools to test new methodologies in XAI."
- **Why unresolved:** The current study used a hybrid of ChatGPT (LLM) for visuals and Wekinator (neural networks) for sound, making it difficult to isolate the specific explainability needs for each technology.
- **What evidence would resolve it:** Research that isolates specific AI architectures (e.g., diffusion models vs. motion-sensing neural networks) to test tailored explanation strategies.

### Open Question 3
- **Question:** Does disclosing the use of AI induce a specific bias toward perceiving visual elements as "random" rather than "intentional"?
- **Basis in paper:** The results showed that participants told about the AI beforehand rated visuals as significantly more "random" than those told afterwards. The authors infer audiences search for intentionality, yet the specific link between disclosure and the "randomness" metric remains an open mechanism.
- **Why unresolved:** It is unclear if the perception of randomness is an inherent property of the AI output or a cognitive bias triggered by the "AI" label.
- **What evidence would resolve it:** A control study measuring "perceived intentionality" and "randomness" using identical outputs labeled differently (e.g., "AI-generated" vs. "Human-curated").

## Limitations
- Small sample size (n=39) with uneven group distributions limits statistical power and generalizability.
- Unclear disclosure script content may affect reproducibility of disclosure timing effects.
- Limited ecological validity: controlled theater setting may not generalize to other performance contexts or audience demographics.
- No baseline comparison with purely traditional performances to isolate GenAI-specific effects.

## Confidence

- **High confidence:** Disclosure timing effects on perceived randomness and curiosity are robust within this experimental context.
- **Medium confidence:** Mechanism that pre-disclosure shifts processing from aesthetic to analytical is plausible but needs further validation across different art forms.
- **Low confidence:** Claims about GenAI-specific perceptual differences versus traditional digital tools are weakly supported due to lack of appropriate control conditions.

## Next Checks
1. Replicate with larger, more diverse sample (n≥100) and balanced group sizes to improve statistical power.
2. Conduct follow-up interviews to understand cognitive mechanisms behind disclosure timing effects.
3. Test disclosure framing effects (neutral vs. enthusiastic vs. technical) to identify optimal transparency approaches for creative contexts.