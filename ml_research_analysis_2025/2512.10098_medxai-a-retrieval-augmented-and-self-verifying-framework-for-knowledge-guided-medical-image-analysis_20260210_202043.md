---
ver: rpa2
title: 'MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided
  Medical Image Analysis'
arxiv_id: '2512.10098'
source_url: https://arxiv.org/abs/2512.10098
tags:
- knowledge
- medxai
- clinical
- medical
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MedXAI is a neuro-symbolic framework that integrates deep learning
  models with clinician-derived expert knowledge to improve medical image analysis,
  particularly for rare-class detection and cross-domain generalization. The system
  uses a retrieval-augmented framework with LLM to extract clinical knowledge and
  generate human-understandable explanations.
---

# MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis

## Quick Facts
- arXiv ID: 2512.10098
- Source URL: https://arxiv.org/abs/2512.10098
- Reference count: 19
- Primary result: 10% improvement in rare-class F1 scores and 84% reduction in manual expert review effort

## Executive Summary
MedXAI introduces a neuro-symbolic framework that combines deep learning models with clinician-derived expert knowledge to enhance medical image analysis, particularly for rare-class detection and cross-domain generalization. The system employs a retrieval-augmented framework with LLM to extract clinical knowledge and generate human-understandable explanations. Validation on Seizure Onset Zone localization and Diabetic Retinopathy grading across ten multicenter datasets demonstrates substantial improvements over standard deep learning baselines, with 84% accuracy in cross-domain generalization and 10% improvement in rare-class F1 scores.

## Method Summary
MedXAI integrates neural and symbolic reasoning through an adaptive routing mechanism that selects from a classifier pool based on Entropy Imbalance Gain metrics. The framework uses a retrieval-augmented system with LLM to extract clinical knowledge from PubMed and generate explanations. The core algorithm (EKSAII) builds decision trees by recursively partitioning data based on classifier performance metrics, with symbolic components encoding domain-invariant clinical rules that compensate for distribution shifts. The system was validated on two clinical tasks: Seizure Onset Zone localization from fMRI and Diabetic Retinopathy grading from retinal images.

## Key Results
- 10% improvement in rare-class F1 scores compared to standard deep learning baselines
- 84% reduction in manual expert review effort required for validation
- 84% accuracy in cross-domain generalization across different imaging protocols and patient demographics

## Why This Works (Mechanism)

### Mechanism 1: Entropy Imbalance Gain (EIG) for Rare-Class Adaptive Routing
The EIG metric quantifies each classifier's contribution to rare-class separability, enabling adaptive selection of the optimal model for ambiguous or underrepresented cases. EIG computes the reduction in entropy imbalance between raw data representation and classifier output, using local density normalization to prioritize classifiers that better capture rare-class instances. This prevents rare-class samples from being overwhelmed by majority-class patterns through density-based entropy metrics.

### Mechanism 2: Neuro-Symbolic Fusion via EKSAII Algorithm
The EKSAII algorithm combines neural feature extraction with symbolic clinical rules through recursive partitioning to improve cross-domain generalization. By selecting classifiers with maximum EIG at each decision tree node and encoding domain-invariant clinical rules (like lesion counts and anatomical features), the system provides an invariant prior that compensates for neural branch degradation under distribution shift.

### Mechanism 3: Retrieval-Augmented Knowledge Extraction with LLM Explanation
RAG-connected LLMs extract clinical knowledge from PubMed and generate human-understandable explanations aligned with clinical reasoning. Medical experts encode clinical knowledge into structured representations, which are converted to fixed rules or knowledge features and fed to GPT-4 along with prediction results to synthesize explanations based on diagnostic results and clinical facts.

## Foundational Learning

- **Entropy-based class imbalance metrics**: Understanding how entropy measures class separability and how local density normalization enables fair comparison across imbalanced classes. *Quick check*: Given a binary dataset with 95% majority and 5% minority class, would standard cross-entropy loss adequately capture minority-class performance gaps?

- **Neuro-symbolic integration paradigms**: Understanding trade-offs between learned vs. encoded knowledge is essential for debugging routing failures. *Quick check*: When would a rule-based classifier outperform a neural network, and vice versa, in a medical imaging context?

- **Decision tree ensemble routing**: Understanding Gini impurity and recursive partitioning is prerequisite to modifying routing logic. *Quick check*: If Gini impurity threshold τ_g is set too low, what happens to the depth and interpretability of the resulting tree?

## Architecture Onboarding

- **Component map**: Raw image → M_d (ViT/CNN feature extraction) AND → M_k (clinical feature computation via XGBoost/rules) → EKSAII computes EIG and builds decision tree → y_final + K → LLM → Explanation output

- **Critical path**: 1) Raw image processed by M_d and M_k in parallel 2) EKSAII computes EIG scores for each classifier 3) Recursive partitioning until Gini impurity < τ_g 4) Final prediction and knowledge features fed to LLM for explanation generation

- **Design tradeoffs**: Fixed rules vs. learned knowledge features (simple conditions use rules, complex conditions use XGBoost on K); weighted vs. unweighted fusion (non-weighted achieves higher generalization); lesion-only vs. lesion+vascular features (lesion-only preferred due to domain sensitivity)

- **Failure signatures**: EIG values near zero for all classifiers (routing becomes random); large accuracy gap between M_d and M_k (imbalance in fusion quality); explanations referencing features not in K (LLM hallucination)

- **First 3 experiments**: 1) Baseline component isolation: Train M_d and M_k separately, compare per-class F1 to identify which classes benefit from symbolic vs. neural approaches 2) EIG sensitivity analysis: Vary Gini threshold τ_g and measure tree depth, inference time, and accuracy 3) Domain shift probe: Train on one site, test on another with/without M_k branch enabled to quantify symbolic contribution to cross-domain robustness

## Open Questions the Paper Calls Out
None

## Limitations
- EIG metric assumes rare-class instances have meaningful local density structure; uniform scattering degrades routing to random selection
- Clinical knowledge retrieval quality depends entirely on PubMed availability and LLM's ability to avoid hallucination
- Symbolic rules must be domain-invariant; if calibration-specific, cross-domain generalization benefits disappear

## Confidence
- **High**: Neuro-symbolic fusion improves rare-class detection (validated by 10% F1 improvement)
- **High**: Adaptive routing reduces manual review burden (84% reduction in expert effort)
- **Medium**: Cross-domain generalization claims (84% accuracy) - depends on symbolic branch's invariance to domain shift
- **Medium**: LLM explanation reliability - retrieval quality and hallucination risk not independently measured

## Next Checks
1. **EIG break condition test**: Create synthetic dataset with artificially scattered rare-class instances; verify routing performance degrades as predicted
2. **Knowledge hallucination audit**: Log all PubMed sources retrieved during inference; verify explanations reference only provided knowledge features
3. **Domain shift stress test**: Train on single site with maximum acquisition protocol variation; measure whether symbolic branch maintains performance while neural branch degrades