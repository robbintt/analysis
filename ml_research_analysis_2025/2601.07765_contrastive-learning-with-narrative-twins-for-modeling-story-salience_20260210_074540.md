---
ver: rpa2
title: Contrastive Learning with Narrative Twins for Modeling Story Salience
arxiv_id: '2601.07765'
source_url: https://arxiv.org/abs/2601.07765
tags:
- story
- narrative
- sentence
- your
- twins
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a contrastive learning framework for modeling\
  \ narrative salience using narrative twins\u2014stories with the same plot but different\
  \ surface forms. The model learns story embeddings by contrasting an original narrative\
  \ with its twin and a distractor with similar surface features but different plot."
---

# Contrastive Learning with Narrative Twins for Modeling Story Salience

## Quick Facts
- arXiv ID: 2601.07765
- Source URL: https://arxiv.org/abs/2601.07765
- Reference count: 40
- Key outcome: Contrastive learning with narrative twins outperforms masked LM baselines for salience detection, with summarization being the most reliable operation

## Executive Summary
This paper introduces a contrastive learning framework for modeling narrative salience using narrative twins—stories with identical plot but different surface forms. The model learns story embeddings by contrasting an original narrative with its twin and a distractor with similar surface features but different plot. Four narratologically motivated operations (deletion, shifting, disruption, summarization) are evaluated for inferring salience. Experiments on ROCStories and Wikipedia plot summaries show that contrastively learned embeddings outperform masked language model baselines, with summarization being the most reliable operation for identifying salient sentences.

## Method Summary
The method uses contrastive learning with InfoNCE loss to train a transformer-based encoder on triples of (anchor, twin, distractor) stories. For short narratives, BERT-base is used with dropout twins or LLM-generated narrative twins; for longer Wikipedia plots, ModernBERT-1B with windowed pooling is employed. The model is trained for 5 epochs with batch sizes of 128 (ROCStories) or 16 (Wikipedia) and a learning rate of 3e-5. Salience is evaluated via four geometric operations (deletion, shifting, disruption, summarization) using cosine similarity between sentence and story embeddings, with performance measured by Spearman rank correlation and AUC against human annotations.

## Key Results
- Contrastive learning with narrative twins achieves Spearman correlation of 0.44 on ROCStories summarization vs. 0.16 for masked LM baseline
- Summarization operation consistently outperforms other operations across both datasets
- Dropout twins perform comparably to narrative twins when no explicit twins are available
- Model performance improves monotonically with increasing model size

## Why This Works (Mechanism)

### Mechanism 1: Plot Equivalence via Surface-Level Decorrelation
Contrastive learning forces the encoder to map stories with identical plots but different surface forms (narrative twins) closer together than stories with similar surfaces but different plots (distractors). The InfoNCE loss penalizes the model if it relies on lexical overlaps to distinguish twins, requiring it to abstract away surface syntax to capture the underlying causal structure of events.

### Mechanism 2: Salience as Centrality in Embedding Space
The summarization operation identifies salient sentences by measuring the cosine similarity between a sentence embedding and the global story embedding, operationalizing Barthes's theory that cardinal functions are the best summary of a narrative. Sentences that contribute most to the core plot representation have higher vector similarity to the global embedding than peripheral details.

### Mechanism 3: Dropout as Implicit Data Augmentation
When explicit textual twins are unavailable, applying different random dropout masks to the same input text (Dropout Twins) approximates narrative twins at the representation level. Different dropout masks sample different sub-networks and token interactions, forcing these stochastic views to project to the same point in embedding space and learning to denoise input variations.

## Foundational Learning

- **InfoNCE / Contrastive Loss**: The mathematical engine driving the learning, maximizing agreement between anchor and positive while minimizing agreement with negatives. Quick check: If you use random stories as negatives instead of "hard" distractors, why might the model fail to learn fine-grained salience?
- **Pooling Strategies (Mean vs. CLS)**: The paper relies on Mean Pooling to generate story and sentence embeddings. Quick check: Why might mean pooling be superior to the [CLS] token for representing the semantics of a long narrative window?
- **Barthes's Cardinal Functions vs. Catalyses**: The theoretical definition of "salience" used in the paper. Cardinal functions (main plot points) cannot be deleted without breaking the narrative logic; catalyses (filler) can. Quick check: In the "Deletion" operation, does removing a cardinal function increase or decrease the similarity to the original story embedding?

## Architecture Onboarding

- **Component map**: Pre-trained Transformer (BERT/ModernBERT) -> Mean pooling over tokens -> Vector y -> Contrastive Loss (InfoNCE) -> Four geometric operations for salience inference
- **Critical path**: The generation of the Distractor (x⁻). If the distractor is not "hard" (shares neither surface features nor entities with the anchor), the contrastive task becomes trivial, and the model learns nothing about plot structure.
- **Design tradeoffs**: LLM Twins vs. Dropout Twins (higher data fidelity vs. free and infinite); Windowed vs. Global (computational efficiency vs. cross-window context).
- **Failure signatures**: High lexical overlap shortcut (relies on matching proper nouns); Disruption failure (performs worse than random, suggesting model struggles with "surprise").
- **First 3 experiments**: 1) Sanity Check on ROCStories using only Dropout Twins; 2) Negative Ablation comparing random in-batch negatives vs. hard LLM-generated distractors; 3) Long-Context Scaling applying "in-story negatives" on Wikipedia plots.

## Open Questions the Paper Calls Out

- **Hierarchical Salience Detection**: Can contrastive learning be extended to hierarchical salience detection (chapter-level, theme-level) beyond sentence-level? Current architecture operates only at sentence-level, requiring new datasets and multi-level training objectives for validation.

- **Distractor Generation Without LLMs**: How can effective distractors be obtained for short narratives without relying on LLM-generated supervision? No alternative distractor generation method for short narratives was identified, as LLM prompting introduces external supervision that may not be available.

- **Book-Length Narrative Scaling**: How does model performance scale to book-length narratives (hundreds to thousands of sentences) where LLM-based evaluation becomes infeasible? Current experiments limited to ~34 sentences; windowing approach may not generalize to full novels.

## Limitations

- Reliance on narrative twins as contrastive examples introduces significant data constraints, with performance gap between narrative twins (ρ=0.44) and dropout twins (ρ=0.16) suggesting dropout alone may not fully capture plot-preserving paraphrasing.
- Dynamic time warping alignment for Wikipedia twins lacks complete implementation details, potentially affecting reproducibility and making it difficult to reproduce exact results.
- Disruption operation fails to outperform random baselines, indicating fundamental limitations in the embedding space's ability to capture narrative surprise or equilibrium shifts.

## Confidence

- **High Confidence**: Contrastive learning framework with InfoNCE loss and its effectiveness in improving salience detection over masked LM baselines; experimental results showing summarization as most reliable operation.
- **Medium Confidence**: Claim that dropout twins are "statistically indistinguishable" from narrative twins based on limited ablation studies; assertion that summarization aligns with Barthes's cardinal functions relies on theoretical interpretation.
- **Low Confidence**: Failure of disruption operation to outperform random baselines may indicate fundamental limitations in embedding space's ability to capture narrative surprise rather than just weakness in specific geometric operation.

## Next Checks

1. **Twin Quality Ablation**: Systematically vary the quality of LLM-generated twins (using different prompting strategies or models) and measure the impact on salience detection performance to quantify how much contrastive learning depends on high-quality plot-preserving paraphrases.

2. **Windowed Long-Context Evaluation**: Implement the windowed approach for Wikipedia narratives and compare performance against global pooling to determine whether computational efficiency gains come at the cost of salience detection accuracy, particularly for cross-window context dependencies.

3. **Distractor Hardness Analysis**: Create a controlled set of distractors varying in plot similarity and surface feature overlap, then measure how contrastive learning performance scales with distractor difficulty to identify the optimal balance between challenging negatives and training stability.