---
ver: rpa2
title: 'Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial
  Attacks'
arxiv_id: '2503.08269'
source_url: https://arxiv.org/abs/2503.08269
tags:
- facial
- face
- adv-cpg
- adversarial
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Adv-CPG introduces facial adversarial attacks into portrait generation,
  addressing the dual challenge of enabling personalized, high-fidelity portrait customization
  while preventing malicious face recognition systems from tracking or misusing the
  generated images. It employs a two-stage framework: the first stage progressively
  protects identity by directly injecting target identity features and enhancing them
  with additional guidance, while the second stage generates fine-grained, controlled
  facial features using multi-modal prompts.'
---

# Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks

## Quick Facts
- **arXiv ID:** 2503.08269
- **Source URL:** https://arxiv.org/abs/2503.08269
- **Reference count:** 40
- **Primary result:** Achieves 28.1% and 2.86% higher attack success rate than state-of-the-art methods while maintaining natural visual quality and enabling personalization

## Executive Summary
Adv-CPG introduces facial adversarial attacks into portrait generation to address the dual challenge of enabling personalized, high-fidelity portrait customization while preventing malicious face recognition systems from tracking or misusing generated images. The framework employs a two-stage approach: the first stage progressively protects identity by injecting target identity features and enhancing them with additional guidance, while the second stage generates fine-grained, controlled facial features using multi-modal prompts. Experimental results demonstrate significant improvements over existing noise-based and unconstrained attack methods, with Adv-CPG achieving substantially higher attack success rates while maintaining natural visual quality. The framework also shows robust performance on commercial APIs with higher and more stable confidence scores compared to existing approaches.

## Method Summary
Adv-CPG operates through a two-stage framework that integrates facial adversarial attacks with personalized portrait generation. The first stage focuses on identity protection by progressively injecting target identity features and enhancing them with additional guidance mechanisms to ensure the generated portraits resist face recognition while preserving the intended identity characteristics. The second stage generates fine-grained, controlled facial features using multi-modal prompts, allowing for detailed customization of portrait attributes. This approach combines the strengths of adversarial machine learning with generative modeling to create portraits that are both personalized and resistant to unauthorized facial recognition, addressing the growing concerns around privacy and misuse of generated facial images.

## Key Results
- Achieves 28.1% higher attack success rate compared to state-of-the-art noise-based attack methods
- Demonstrates 2.86% higher attack success rate than unconstrained attack methods
- Maintains natural visual quality while enabling customization and personalization of generated portraits

## Why This Works (Mechanism)
Adv-CPG leverages the principle that adversarial perturbations can be systematically integrated into the generation process rather than applied as post-hoc modifications. By embedding identity protection directly into the portrait generation pipeline through progressive feature injection and multi-modal guidance, the framework creates a synergistic relationship between personalization and adversarial defense. The two-stage architecture allows for separation of concerns: identity protection is handled first to ensure robust resistance to face recognition, while detailed feature generation follows to maintain visual quality and customization capabilities. This integrated approach overcomes the traditional trade-off between adversarial effectiveness and visual naturalness that plagues post-hoc attack methods.

## Foundational Learning
- **Adversarial Machine Learning:** Understanding how carefully crafted perturbations can fool machine learning models is essential for implementing effective facial attacks. Quick check: Verify that perturbations remain imperceptible while maintaining attack effectiveness.
- **Generative Adversarial Networks (GANs):** The framework builds on GAN architectures for generating realistic portraits, requiring knowledge of generator-discriminator dynamics. Quick check: Ensure the generator produces high-fidelity outputs while the discriminator remains effective at distinguishing real from generated images.
- **Multi-modal Prompting:** The use of text, image, and attribute-based prompts for controlled generation requires understanding of cross-modal embeddings and conditioning mechanisms. Quick check: Validate that prompts effectively control specific facial attributes without introducing artifacts.
- **Face Recognition Systems:** Understanding the vulnerabilities and decision boundaries of commercial face recognition APIs is crucial for evaluating attack success. Quick check: Test attack transferability across multiple recognition systems to ensure robustness.
- **Progressive Feature Injection:** The technique of gradually introducing identity features requires understanding of feature space manipulation and temporal coherence. Quick check: Monitor identity preservation across the progressive stages to prevent degradation.

## Architecture Onboarding

**Component Map:** Identity Feature Extractor -> Progressive Protection Module -> Multi-modal Prompt Generator -> Fine-grained Feature Generator -> Portrait Output

**Critical Path:** The critical path flows from identity feature extraction through progressive protection to final portrait generation, with each stage building upon the previous one. The Progressive Protection Module serves as the bottleneck, as its effectiveness directly determines both attack success rate and identity preservation quality.

**Design Tradeoffs:** The framework trades computational efficiency for integration of adversarial and generative capabilities, resulting in a two-stage process that may be slower than single-stage alternatives but offers superior attack effectiveness and visual quality. The progressive approach sacrifices some generation speed for more robust identity protection, while the multi-modal prompt system increases model complexity but enables finer control over generated features.

**Failure Signatures:** Common failure modes include identity collapse when progressive protection is too aggressive, visual artifacts when multi-modal prompts conflict, and reduced attack effectiveness when identity features are insufficiently protected. The framework may also struggle with extreme pose variations or occlusions that challenge both the generation and attack components.

**First 3 Experiments:**
1. Baseline comparison with standard GAN portrait generation without adversarial components to establish the performance penalty for adding attack capabilities
2. Ablation study removing the progressive protection stage to quantify its contribution to attack success rate and identity preservation
3. Cross-API transferability test using generated portraits against a suite of commercial face recognition services not seen during training

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Attack effectiveness may vary significantly when tested against face recognition architectures not included in the evaluation set
- Computational requirements for the two-stage generation process are not quantified, raising deployment feasibility concerns
- Visual quality assessments rely on subjective human evaluation rather than standardized perceptual metrics, potentially introducing bias

## Confidence
- **High confidence** in attack effectiveness claims due to quantitative comparisons with state-of-the-art methods and validation across multiple face recognition APIs
- **Medium confidence** in personalization and customization capabilities based on controlled experimental setup, though real-world variability remains unexplored
- **Medium confidence** in "natural visual quality" assertions given reliance on human evaluation rather than standardized perceptual metrics

## Next Checks
1. Test attack transferability across diverse face recognition architectures not included in the training or evaluation set
2. Quantify and optimize computational requirements for real-time or near-real-time portrait generation
3. Conduct large-scale perceptual studies with diverse participant demographics to validate subjective quality assessments