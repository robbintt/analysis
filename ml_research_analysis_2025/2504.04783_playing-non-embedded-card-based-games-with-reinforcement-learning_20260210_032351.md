---
ver: rpa2
title: Playing Non-Embedded Card-Based Games with Reinforcement Learning
arxiv_id: '2504.04783'
source_url: https://arxiv.org/abs/2504.04783
tags:
- game
- dataset
- learning
- detection
- reinforcement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a non-embedded reinforcement learning approach
  for playing the card-based RTS game Clash Royale. The authors develop a complete
  pipeline including real-time image capture, object detection, optical character
  recognition, and decision-making on mobile devices.
---

# Playing Non-Embedded Card-Based Games with Reinforcement Learning

## Quick Facts
- arXiv ID: 2504.04783
- Source URL: https://arxiv.org/abs/2504.04783
- Reference count: 16
- Primary result: 10% win rate against built-in AI opponents in Clash Royale

## Executive Summary
This paper presents a non-embedded reinforcement learning approach for playing the card-based RTS game Clash Royale. The authors develop a complete pipeline including real-time image capture, object detection, optical character recognition, and decision-making on mobile devices. A generative dataset was created for object detection training due to the lack of existing datasets. The decision model combines spatial and temporal attention mechanisms with delayed action prediction to handle the sparse action problem. Using offline reinforcement learning with expert data, the agent achieves a 10% win rate against built-in AI opponents. The system runs in real-time on mobile devices with 120ms decision time and 240ms perception fusion time. All code and datasets are open-sourced.

## Method Summary
The approach involves capturing gameplay images from mobile devices, processing them through object detection and OCR pipelines, and feeding the extracted information into a decision-making model. The system uses offline reinforcement learning trained on expert data rather than online learning through gameplay experience. A novel generative dataset was created to train the object detection component, as no existing datasets were available for this game. The decision model incorporates spatial and temporal attention mechanisms to handle the game's complex state space, with delayed action prediction to address the sparse action problem inherent in card-based RTS games.

## Key Results
- 10% win rate against built-in AI opponents
- Real-time operation on mobile devices with 120ms decision time
- 240ms perception fusion time
- Complete pipeline including image capture, object detection, OCR, and decision-making

## Why This Works (Mechanism)
The system succeeds by combining computer vision techniques with reinforcement learning to create a non-embedded agent that can play Clash Royale without direct game engine access. The generative dataset creation enables effective object detection training despite data scarcity. The attention mechanisms help the model focus on relevant game elements while filtering noise. The delayed action prediction addresses the challenge of infrequent but critical decision points in card-based RTS gameplay.

## Foundational Learning
- **Object Detection**: Identifies game elements on screen - needed for understanding game state; quick check: detection accuracy on test set
- **Optical Character Recognition**: Reads text elements like card names and timers - needed for extracting numerical game information; quick check: OCR accuracy on captured text
- **Attention Mechanisms**: Focuses on relevant spatial and temporal features - needed to handle complex game state; quick check: attention weight distributions
- **Offline Reinforcement Learning**: Trains on expert data without environment interaction - needed due to game API restrictions; quick check: performance on validation expert trajectories
- **Delayed Action Prediction**: Handles sparse action spaces - needed for card-based RTS games; quick check: action prediction accuracy on expert data
- **Mobile Real-time Processing**: Enables on-device decision making - needed for practical deployment; quick check: latency measurements on target hardware

## Architecture Onboarding
**Component Map**: Image Capture -> Object Detection -> OCR -> State Representation -> Attention Model -> Action Prediction -> Game Controller

**Critical Path**: The perception pipeline (image capture → object detection → OCR → state representation) must complete within 240ms to meet real-time requirements. The decision model then operates within 120ms to maintain responsiveness.

**Design Tradeoffs**: Offline learning was chosen over online learning due to game API restrictions and to avoid potential violations of terms of service. The generative dataset approach was necessary due to lack of real gameplay data but may not capture full gameplay diversity. Mobile deployment constrains model size and inference speed.

**Failure Signatures**: Poor object detection accuracy leads to incorrect state representation. OCR failures result in missing or incorrect numerical information. Suboptimal attention mechanisms cause the model to focus on irrelevant features. Delayed action prediction errors result in mistimed or inappropriate card plays.

**First 3 Experiments**:
1. Measure object detection accuracy on the synthetic test set with varying levels of image distortion
2. Benchmark OCR accuracy on different font sizes and backgrounds present in gameplay
3. Evaluate attention mechanism performance on expert trajectories to verify focus on relevant game elements

## Open Questions the Paper Calls Out
None

## Limitations
- Limited win rate against AI opponents indicates suboptimal decision-making
- Offline learning approach restricts adaptive capability
- Synthetic dataset may not represent full gameplay complexity
- Sparse action prediction challenges remain unresolved

## Confidence
**High confidence**: Real-time mobile deployment feasibility, image capture and OCR pipeline functionality, dataset creation methodology

**Medium confidence**: Win rate achievement, system latency measurements, object detection accuracy

**Low confidence**: Generalization to human opponents, robustness across diverse gameplay scenarios, long-term performance stability

## Next Checks
1. Independent verification of system latency measurements on identical mobile hardware configurations
2. Extended testing against human players to assess generalization beyond built-in AI opponents
3. Evaluation of object detection performance on diverse, real-world gameplay footage beyond the synthetic dataset