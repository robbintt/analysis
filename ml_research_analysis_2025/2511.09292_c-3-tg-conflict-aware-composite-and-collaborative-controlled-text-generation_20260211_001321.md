---
ver: rpa2
title: 'C$^3$TG: Conflict-aware, Composite, and Collaborative Controlled Text Generation'
arxiv_id: '2511.09292'
source_url: https://arxiv.org/abs/2511.09292
tags:
- attribute
- text
- generation
- attributes
- control
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "C\xB3TG introduces a two-phase framework for controlled text generation\
  \ that addresses multi-attribute conflicts through collaboration between a large\
  \ language model and 17 fine-tuned BERT classifiers. The generation phase employs\
  \ weighted KL divergence to fuse attribute distributions, while the optimization\
  \ phase uses a composite energy function combining classifier scores with conflict\
  \ penalty terms to iteratively refine text."
---

# C$^3$TG: Conflict-aware, Composite, and Collaborative Controlled Text Generation

## Quick Facts
- **arXiv ID:** 2511.09292
- **Source URL:** https://arxiv.org/abs/2511.09292
- **Reference count:** 40
- **Primary result:** Achieves 90.39% attribute accuracy and 4.04 PPL on ROCStories, significantly outperforming baselines while reducing toxicity by 0.12 probability points

## Executive Summary
C$^3$TG introduces a two-phase framework for controlled text generation that addresses multi-attribute conflicts through collaboration between a large language model and 17 fine-tuned BERT classifiers. The generation phase employs weighted KL divergence to fuse attribute distributions, while the optimization phase uses a composite energy function combining classifier scores with conflict penalty terms to iteratively refine text. Experiments demonstrate C$^3$TG achieves 90.39% attribute accuracy and 4.04 PPL on ROCStories, significantly outperforming baselines while reducing toxicity by 0.12 probability points. The framework excels at resolving conflicting attributes through its energy-based optimization loop and maintains superior fluency and diversity across multiple datasets.

## Method Summary
C$^3$TG is a two-phase controlled text generation framework. First, the generation phase uses weighted KL divergence to fuse multiple attribute priors into a single token distribution through geometric mean. Second, the optimization phase iteratively refines generated text using a composite energy function that combines classifier scores with conflict penalty terms. The process involves 17 fine-tuned BERT classifiers, LoRA adapters for attribute-specific priors, and a zero-shot Feedback Agent that translates energy diagnostics into rewriting prompts. The framework achieves conflict-aware generation while preserving natural text flow and fluency.

## Key Results
- Achieves 90.39% attribute accuracy on ROCStories, outperforming baselines by 3-5 percentage points
- Maintains 4.04 perplexity on generated text, demonstrating strong fluency preservation
- Reduces toxicity by 0.12 probability points compared to state-of-the-art baselines
- Successfully resolves conflicting attributes through energy-based optimization loop

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Weighted geometric mean of attribute priors produces a valid token distribution that simultaneously reflects multiple target attributes.
- **Mechanism:** The framework minimizes weighted KL divergence between the target distribution P and n attribute-specific priors Q_i. Applying Lagrange multipliers yields P*(x) ∝ ∏Q_i(x)^(λ_i/Λ), where weights normalize influence across attributes.
- **Core assumption:** Attribute priors Q_i are not fundamentally incompatible; some overlap exists in their high-probability regions.
- **Evidence anchors:**
  - [abstract] "employs weighted KL-divergence to adjust token probabilities"
  - [PAGE 3-4] Eq. 2-3 with full derivation in Appendix A
  - [corpus] Related work (Palette, TRACE) uses similar distribution-combination strategies, suggesting this is a recognized pattern, though specific KL-weighted fusion is less established
- **Break condition:** When attributes are truly contradictory (e.g., "joy=1.0" AND "fear=1.0"), the geometric mean may collapse to near-uniform, yielding incoherent outputs.

### Mechanism 2
- **Claim:** The composite energy function drives iterative refinement toward target attribute values while preventing collateral drift in non-target dimensions.
- **Mechanism:** E(x) = Σα_i|C_Ai(x)-T_i| + Σβ_j|C_Aj(x)-C_Aj(x_prev)|. The first term pulls target attributes toward specified intensities; the second term penalizes unintended changes in stability-constrained dimensions during each rewrite.
- **Core assumption:** Classifier scores C_Ai(x) provide reliable, differentiable signals that correlate with human judgments of attribute presence.
- **Evidence anchors:**
  - [abstract] "energy function combining classifier scores and conflict penalty terms to resolve attribute conflicts"
  - [PAGE 4] Eq. 4-6 defining E_classify, Ω_overlap, and E(x)
  - [corpus] Energy-based CTG (COLD, BOLT, MacLaSa) is established; the conflict-penalty term specifically is novel and lacks external validation
- **Break condition:** If classifiers are miscalibrated or adversarially fooled, energy minimization may optimize for wrong targets. (Appendix F shows 20% label noise drops alignment only 2.6pp—suggesting partial robustness.)

### Mechanism 3
- **Claim:** A zero-shot Feedback Agent can translate energy-component signals into effective rewriting prompts, enabling closed-loop refinement without gradient updates to the base LLM.
- **Mechanism:** After each iteration, the Agent receives deviation magnitudes Δ_i and penalty values, constructs a priority queue of underperforming dimensions, and synthesizes natural-language directives (e.g., "increase joy, maintain courage"). This creates a three-stage optimization: calibrate → balance → fine-tune.
- **Core assumption:** The base LLM responds predictably to attribute-style instructions in prompts.
- **Evidence anchors:**
  - [abstract] "enabling precise control over multiple dimensions simultaneously while preserving natural text flow"
  - [PAGE 5] Figure 3 and Stage 1-3 descriptions
  - [corpus] Reflexion and agent-based refinement exist, but corpus lacks direct validation of energy-to-prompt translation
- **Break condition:** If the Agent's prompts are misinterpreted by the LLM, or if rewriting capacity is saturated (too many simultaneous constraints), convergence stalls. (Figure 7 shows energy plateaus after ~3 iterations.)

## Foundational Learning

- **KL Divergence and Geometric Mean of Distributions**
  - Why needed here: The generation phase fuses priors via weighted geometric mean; understanding why this minimizes KL divergence is essential for debugging attribute weight settings.
  - Quick check question: Given two distributions Q1(x)=[0.8,0.2] and Q2(x)=[0.3,0.7] with equal weights, what is P*(x)?

- **Energy-Based Models and Gradient-Free Optimization**
  - Why needed here: The optimization phase minimizes E(x) without backpropagation; instead relying on rejection sampling and prompt-guided rewriting.
  - Quick check question: Why does the framework require E(x_new) < E(x_prev) for acceptance rather than using gradient descent?

- **BERT Fine-Tuning for Classification**
  - Why needed here: 17 BERT classifiers provide the scoring functions C_Ai(x); their calibration directly affects energy signal quality.
  - Quick check question: If a classifier systematically over-predicts its attribute (e.g., always returns ≥0.6 for "humor"), how would this manifest in C³TG outputs?

## Architecture Onboarding

- **Component map:**
  - Base LLM (Llama2-7B) -> LoRA adapters -> Attribute-specific priors Q_i
  - 17 BERT classifiers -> Attribute scores C_Ai(x)
  - Feedback Agent (Llama2-7B) -> Rewrite prompts
  - Energy computation module -> E(x) scores
  - User context + attribute targets -> C³TG pipeline

- **Critical path:** User specifies (context, attribute targets) -> Generation Phase computes P* via weighted geometric mean -> Initial text x generated -> Optimization Phase evaluates E(x), Agent generates prompt -> LLM rewrites -> Repeat until E(x) ≤ τ (0.025) or max iterations

- **Design tradeoffs:**
  - **τ threshold:** Lower τ improves accuracy but increases iterations (Figure 6: τ=0.025 yields 87.5% acc, 2.9 avg iterations)
  - **β_j penalty scaling:** c=0.3 (derived from grid search) balances stability vs. flexibility; higher c may over-constrain
  - **Runtime:** Full 3-iteration C³TG is 1.6× slower than fastest baseline but gains ~3% accuracy, 25% toxicity reduction

- **Failure signatures:**
  - Energy fails to decrease across iterations -> Agent prompts may be ineffective; check prompt templates
  - High perplexity with good accuracy -> Over-constrained attributes; reduce target count or loosen intensities
  - Toxicity remains high -> Toxicity classifier may be underperforming; verify calibration on domain data
  - Attribute drift in non-target dimensions -> β_j coefficients may be too low; check correlation matrix

- **First 3 experiments:**
  1. **Single-attribute baseline:** Set λ for one attribute to 1.0, others to 0. Verify generation-phase fusion works correctly; compare attribute accuracy vs. prompt-only control.
  2. **Conflict stress test:** Specify opposing attributes (e.g., Joy=0.9, Sadness=0.8). Observe energy trajectory and final scores; validate that Ω_overlap prevents collapse.
  3. **Classifier calibration audit:** Run 17 classifiers on held-out labeled data; compute ECE (Expected Calibration Error). Apply temperature scaling if ECE > 5%; re-run C³TG to measure alignment recovery (per Appendix F protocol).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the computational overhead of the iterative optimization phase be reduced to match single-pass baselines?
- Basis in paper: [explicit] The authors state C³TG is 1.6x slower than the fastest baseline due to the energy-based optimization loop.
- Why unresolved: The paper optimizes the process via early stopping but accepts the latency trade-off without exploring non-iterative approximations.
- Evidence: Ablation studies comparing the full three-stage loop against a distilled, single-pass controller mimicking the energy function.

### Open Question 2
- Question: Can the framework adapt to novel control dimensions without the gradient updates required by the current adaptation strategy?
- Basis in paper: [inferred] Appendix E requires "few-step head tuning" for new attributes like "satire."
- Why unresolved: The framework relies on fine-tuned classifiers; true zero-shot generalization to unseen attributes remains untested.
- Evidence: Evaluation on a suite of unseen attributes using only frozen, off-the-shelf language models for scoring.

### Open Question 3
- Question: How robust is the conflict resolution mechanism when scaling to a significantly higher number of simultaneous constraints?
- Basis in paper: [inferred] The experiments focus on 2–4 attributes, leaving the theoretical limits of the energy function unexplored.
- Why unresolved: As constraint density increases, the energy landscape may become too complex for the Feedback Agent to navigate effectively.
- Evidence: Stress tests with 10+ concurrent attributes to measure convergence rates and conflict resolution accuracy.

## Limitations
- **Computational Overhead:** Requires fine-tuning 17 BERT classifiers and multiple LLM variants, plus iterative inference, limiting practical deployment
- **Domain Generalization:** Effectiveness on diverse domains (scientific writing, code generation, multilingual text) remains untested
- **Feedback Agent Reliance:** Zero-shot agent's prompt generation quality is critical but lacks independent validation

## Confidence
- **High Confidence:** KL-weighted geometric mean for distribution fusion (Mechanism 1) is mathematically sound and aligns with CTG literature
- **Medium Confidence:** Composite energy function's conflict resolution (Mechanism 3) is supported by results but lacks ablation studies
- **Low Confidence:** Feedback Agent's translation of energy signals to prompts is novel but not independently validated

## Next Checks
1. **Ablation of Conflict Penalty:** Remove Ω_overlap from energy function and rerun on opposing-attributes stress test to isolate conflict-resolution contribution
2. **Classifier Calibration Audit:** Independently evaluate 17 BERT classifiers on held-out data; apply temperature scaling if ECE > 5% and measure alignment recovery
3. **Generalization to New Domains:** Apply C³TG to scientific abstracts or product reviews to assess 17-attribute transferability and quantify performance drops