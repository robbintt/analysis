---
ver: rpa2
title: 'Getting Your Indices in a Row: Full-Text Search for LLM Training Data for
  Real World'
arxiv_id: '2510.09471'
source_url: https://arxiv.org/abs/2510.09471
tags:
- data
- training
- https
- arxiv
- indexing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a full-text indexing pipeline for Apertus LLM
  training data using Elasticsearch on the energy-efficient Alps HPC supercluster.
  The authors successfully indexed 8.6 trillion tokens of the 15.2 trillion token
  dataset, doubling the size of previous efforts.
---

# Getting Your Indices in a Row: Full-Text Search for LLM Training Data for Real World

## Quick Facts
- **arXiv ID:** 2510.09471
- **Source URL:** https://arxiv.org/abs/2510.09471
- **Reference count:** 40
- **Primary result:** Successfully indexed 8.6T tokens of 15.2T token dataset using Elasticsearch on ARM64 HPC, demonstrating large-scale full-text search for LLM training data safety analysis

## Executive Summary
This paper presents a full-text indexing pipeline for Apertus LLM training data using Elasticsearch deployed on the energy-efficient Alps HPC supercluster. The authors successfully indexed 8.6 trillion tokens from the 15.2 trillion token dataset, doubling the size of previous indexing efforts. They demonstrate Elasticsearch deployment on ARM64-based infrastructure and report performance metrics including indexing rates up to 10,297 documents/second for English text. The index enables fine-grained safety analysis, identifying problematic content across 11 languages. The work establishes that large-scale web-text indexing for LLM safety and security is feasible with off-the-shelf tools, requiring less than 0.1% of the compute used to train the models themselves.

## Method Summary
The authors built a full-text search pipeline using Elasticsearch 7.17.28 on ARM64 GH200 nodes of the Alps supercluster. They deployed custom OCI-compliant containers via Podman, bypassing Docker due to kernel constraints. The system disabled memory mapping to avoid vm.max_map_count limitations, trading I/O efficiency for deployment stability. Data was streamed from Parquet files using parallel_bulk indexing with configurable thread counts, chunk sizes, and queue sizes. A custom web_content_analyzer processed HTML stripping, tokenization, lowercase conversion, and ASCII folding. The index was queried using match_phrase queries with configurable slop parameters to identify safety-relevant content across 11 languages using curated word lists.

## Key Results
- Indexed 8.6 trillion tokens from 15.2 trillion token dataset using Elasticsearch on ARM64 HPC
- Achieved indexing throughput up to 10,297 documents/second for English text, 589 documents/second for multilingual data
- Index size ratios ranged from 1.1x to 2.8x relative to original data size
- Successfully identified problematic content across 11 languages for LLM safety analysis

## Why This Works (Mechanism)

### Mechanism 1: ARM64 Container Adaptation
The deployment of off-the-shelf search engines on next-generation ARM64 superclusters is feasible but requires bypassing standard Docker workflows and kernel defaults. The system replaces Docker with Podman to build OCI-compliant containers compatible with the ARM64 GH200 nodes. It explicitly disables memory mapping (mmap) to bypass the low vm.max_map_count kernel limit imposed by the HPC environment, trading I/O efficiency for successful bootstrapping. The stability gained from disabling mmap outweighs the performance loss from reduced I/O efficiency for this specific workload.

### Mechanism 2: Latency-Bounded Ingestion
Indexing throughput is fundamentally constrained by storage I/O latency and commit protocols rather than purely by CPU parallelism or batch size. Elasticsearch uses a two-phase atomic commit for document insertion. On the Alps infrastructure, the storage access latency (~50 microseconds) creates a theoretical ceiling of ~10,000 documents/second. Increasing thread count or chunk size optimizes resource utilization up to this hardware-defined limit but cannot exceed it. The storage medium (IOPStore) provides consistent low latency, and the two-phase commit is the primary serialization bottleneck.

### Mechanism 3: Linguistic Normalization Overhead
Scaling from monolingual (English) to multilingual datasets incurs a non-linear cost in indexing throughput and index size. Multilingual corpora require complex analyzers to handle diverse character sets and diacritics. This processing overhead, combined with the larger vocabulary size reducing compression efficiency, causes throughput to drop from ~10,000 docs/sec (English) to ~589 docs/sec (Multilingual European) and inflates index size ratios (1.3x to 2.8x). The performance drop is primarily driven by the complexity of the analysis chain (tokenization/normalization) rather than just data volume.

## Foundational Learning

- **Concept:** Inverted Indices & Tokenization
  - **Why needed here:** Understanding how Elasticsearch breaks text into tokens (via analyzers) is essential to diagnosing why multilingual indexing is slower and produces larger indices than English text.
  - **Quick check question:** Why would a "standard" tokenizer perform differently on English text versus a dataset containing Thai or Kabyle?

- **Concept:** HPC Job Scheduling (Slurm)
  - **Why needed here:** The authors could not use Docker Compose; they had to map orchestration to Slurm definitions. You must understand how to request resources (nodes, memory) in a batch environment.
  - **Quick check question:** How does launching a distributed search cluster via Slurm differ from launching it on a standard Kubernetes cluster?

- **Concept:** Two-Phase Commit (2PC)
  - **Why needed here:** The paper identifies 2PC as the root cause of the indexing speed limit. You need to know that ensuring data safety (durability) often requires multiple round-trips to disk, which limits speed.
  - **Quick check question:** If the system used a lazy commit strategy, how might the 10,000 docs/sec limit change, and what risk would that introduce?

## Architecture Onboarding

- **Component map:** Parquet files -> Podman containers (Elasticsearch 7.17.28) -> SLURM orchestration -> GH200 ARM64 nodes -> IOPStore storage -> Match_phrase queries

- **Critical path:**
  1. Infrastructure Setup: Build ARM64-compatible OCI image -> Configure Slurm to bypass vm.max_map_count via startup args
  2. Ingestion: Tune chunk_size and queue_size to saturate the 10k docs/sec latency limit without OOM errors
  3. Verification: Run match queries against the Chemical/Weaponized word lists to validate safety coverage

- **Design tradeoffs:**
  - Memory Mapping: Disabled to allow the process to start on HPC nodes (stability) vs. Higher system memory usage and lower I/O efficiency (performance)
  - Deduplication: Pre-computing hashes saves index space (data volume) vs. The CPU cost of hashing slows down ingestion (throughput)
  - Language Support: Comprehensive multilingual analysis (safety/quality) vs. Significantly reduced indexing speed (cost)

- **Failure signatures:**
  - vm.max_map_count error: Elasticsearch fails to bootstrap on the HPC node. Fix: Disable mmap in config.
  - Proxy connection errors: Cannot reach localhost:9200. Fix: Explicitly set no_proxy environment variables.
  - Memory Exhaustion (OOM): High thread counts + large chunks. Fix: Reduce chunk_size or queue_size per Equation (1).

- **First 3 experiments:**
  1. Latency Baseline Test: Index a 1GB English sample. Vary chunk_size to confirm if you hit the ~10k docs/sec hardware ceiling reported in the paper.
  2. Analyzer Overhead Test: Index a 1GB sample in English vs. a 1GB sample in a high-resource European language (e.g., German). Measure the difference in index size and throughput.
  3. Container Startup Test: Deploy the provided OCI image on a single allocation. Verify successful startup with memory mapping disabled to ensure the environment matches the paper's configuration.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can full-text indexing throughput be optimized for diverse multilingual corpora to match the performance of monolingual English data?
- **Basis in paper:** [inferred] The authors report a significant performance disparity, with English text indexing at 10,297 docs/s compared to only 589 docs/s for a multilingual dataset, attributed to linguistic complexity.
- **Why unresolved:** The paper identifies the bottleneck (diverse character sets, tokenization overhead) but does not propose or test specific software or hardware optimizations to close this performance gap.
- **What evidence would resolve it:** An indexing pipeline implementation that achieves comparable docs/s rates for high-resource non-English languages on similar hardware.

### Open Question 2
- **Question:** Can offline, curated full-text indices effectively support the general-purpose factual grounding of LLM generation?
- **Basis in paper:** [explicit] The conclusion suggests that the indexed data size approaches the Common Crawl, making it "particularly interesting for the general-purpose factual rooting of LLM generation based on offline search curated open web subsets."
- **Why unresolved:** The current work focuses on the feasibility of indexing and safety analysis; it does not integrate the index into a retrieval-augmented generation (RAG) pipeline to test factual accuracy.
- **What evidence would resolve it:** Benchmark results from an LLM using this static index for grounding, showing improved factual consistency compared to parametric generation or live web search.

### Open Question 3
- **Question:** What economic and legal frameworks are required to fairly compensate creators of content indexed for LLM training and retrieval?
- **Basis in paper:** [explicit] The authors state that the ability to index the open web "raises a host of ethical and economic questions, notably regarding the fair compensation of individuals who originally created and hosted the retrieved content."
- **Why unresolved:** The paper is a technical case study on infrastructure and safety; it acknowledges the ethical dilemma but does not propose solutions for governance or compensation.
- **What evidence would resolve it:** A proposed governance model or legal framework that addresses copyright and compensation in the context of large-scale training data indexing.

## Limitations

- The 10,000 docs/sec throughput ceiling is specific to the IOPStore storage system and may not generalize to different infrastructure
- The safety analysis relies on curated word lists that may not capture all problematic content patterns, particularly in underrepresented languages
- The multilingual performance degradation is attributed to analyzer complexity but the exact contribution of vocabulary size versus processing overhead remains unclear

## Confidence

- **High confidence:** The feasibility of deploying Elasticsearch on ARM64 HPC infrastructure using Podman containers is well-supported by the technical details and successful deployment described. The index-to-data size ratios (1.1-2.8x) are concrete measurements.
- **Medium confidence:** The 10,000 docs/sec hardware ceiling is theoretically sound based on storage latency arguments, but this specific limit would shift on different infrastructure. The claim about multilingual overhead being driven by analyzer complexity is reasonable but not definitively isolated from data volume effects.
- **Low confidence:** The completeness of safety analysis coverage is difficult to verify without independent assessment of the word lists across all 11 languages and evaluation of false positive/negative rates.

## Next Checks

1. Reproduce the indexing throughput measurements on a different ARM64 system with alternative storage (e.g., local SSD vs. IOPStore) to verify if the 10k docs/sec ceiling is infrastructure-dependent
2. Benchmark a whitespace-only analyzer against the full web_content_analyzer on multilingual datasets to isolate the contribution of linguistic processing to the performance gap
3. Conduct a blind safety audit using the index to find problematic content that was not in the original word lists, measuring precision and recall against human annotations