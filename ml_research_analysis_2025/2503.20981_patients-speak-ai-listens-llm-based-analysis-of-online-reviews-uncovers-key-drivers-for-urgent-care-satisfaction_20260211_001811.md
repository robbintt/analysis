---
ver: rpa2
title: 'Patients Speak, AI Listens: LLM-based Analysis of Online Reviews Uncovers
  Key Drivers for Urgent Care Satisfaction'
arxiv_id: '2503.20981'
source_url: https://arxiv.org/abs/2503.20981
tags:
- care
- sentiment
- patient
- urgent
- factors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study analyzed 152,680 Google Maps reviews of urgent care
  facilities in Florida and the DMV region using large language models to perform
  aspect-based sentiment analysis across five dimensions: interpersonal factors, technical
  quality, operational efficiency, finances, and facilities. GPT-4o mini was selected
  for its optimal balance of performance (accuracy 80%) and cost-effectiveness.'
---

# Patients Speak, AI Listens: LLM-based Analysis of Online Reviews Uncovers Key Drivers for Urgent Care Satisfaction

## Quick Facts
- arXiv ID: 2503.20981
- Source URL: https://arxiv.org/abs/2503.20981
- Reference count: 40
- Primary result: Interpersonal factors and operational efficiency are strongest independent drivers of urgent care satisfaction; technical quality, finances, and facilities show no significant effects.

## Executive Summary
This study analyzed 152,680 Google Maps reviews of urgent care facilities using large language models to perform aspect-based sentiment analysis across five dimensions. GPT-4o mini was selected for its optimal balance of performance (accuracy > 80%) and cost-effectiveness. The analysis revealed that interpersonal factors and operational efficiency were the strongest predictors of patient satisfaction, while technical quality, finances, and facilities showed no significant independent effects. Among socioeconomic factors, only population density demonstrated a modest association with ratings.

## Method Summary
The study employed large language models to classify 152,680 Google Maps reviews into five healthcare quality dimensions: interpersonal, technical, operational, financial, and facilities. GPT-4o mini was selected for its cost-effectiveness and accuracy (>80%). Hospital-level sentiment scores were aggregated and analyzed through correlation and multiple linear regression against star ratings, with socioeconomic covariates added in a second model. Classification was validated against 400 manually annotated reviews.

## Key Results
- Interpersonal factors showed the strongest correlation with ratings (0.93-0.94) and remained significant in multivariate models (β = 1.684, p < 0.001)
- Operational efficiency was the second strongest predictor (0.84-0.87 correlation; β = 1.075, p < 0.001)
- Technical quality, finances, and facilities showed no significant independent predictive power in either model
- Only population density among socioeconomic factors showed modest association with ratings (β = 0.023, p = 0.009)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLM-based aspect extraction captures multi-dimensional patient experience signals that correlate with satisfaction.
- **Mechanism:** Prompt engineering defines 5 healthcare quality dimensions with positive/negative/neutral examples; GPT-4o mini classifies each review into structured JSON outputs; scores are aggregated to hospital-level averages for correlation/regression against star ratings.
- **Core assumption:** Patient reviews contain sufficient explicit cues for each aspect that an LLM can reliably classify without domain-specific fine-tuning.
- **Evidence anchors:** [abstract] "extracting nuanced perceptions from reviews has become feasible"; [section 2.4] "ABSA facilitates a more nuanced evaluation"; [section 2.5] "All five tested LLMs demonstrate an overall accuracy of more than 80%".
- **Break condition:** If classification accuracy drops below 75% on held-out validation, or if >40% of reviews return "None" for all aspects.

### Mechanism 2
- **Claim:** Interpersonal factors and operational efficiency are the strongest independent drivers of urgent care satisfaction after adjusting for other dimensions.
- **Mechanism:** Compute Pearson correlations between each aspect's hospital-level sentiment and average star ratings; then run multiple linear regression (Model 1: 5 aspects; Model 2: +7 socioeconomic covariates) to isolate independent effects while controlling for intercorrelations.
- **Core assumption:** Hospital-level aggregation preserves the signal-to-noise ratio, and linear regression coefficients reflect causal priority rather than collinearity artifacts.
- **Evidence anchors:** [abstract] "interpersonal factors (correlation with ratings: 0.93-0.94) and operational efficiency (0.84-0.87) were the strongest predictors"; [section 3.2] "interpersonal factors emerge as the strongest predictor of hospital ratings across both models".
- **Break condition:** If VIF exceeds 10 for any predictor, or if coefficients change sign/drop significance when adding/removing covariates.

### Mechanism 3
- **Claim:** Socioeconomic factors show minimal independent association with satisfaction once service quality aspects are accounted for.
- **Mechanism:** Link each facility to Census Block Group (CBG) demographics; include as covariates in Model 2 regression.
- **Core assumption:** CBG-level demographics are an adequate proxy for the patient population's socioeconomic context.
- **Evidence anchors:** [abstract] "Among socioeconomic factors, only population density demonstrated a modest association with ratings"; [section 3.2] "only population density was significantly associated with hospital ratings".
- **Break condition:** If interaction terms (e.g., interpersonal × population density) become significant, indicating the mechanism varies by urbanization level.

## Foundational Learning

- **Aspect-Based Sentiment Analysis (ABSA)**
  - Why needed here: Urgent care satisfaction is multi-dimensional; overall sentiment conflates staff friendliness, wait times, and billing.
  - Quick check question: Given the review "Wait was short but doctor rushed and the bill was confusing," can you separate positive operational from negative interpersonal and negative financial sentiment?

- **Variance Inflation Factor (VIF) and Multicollinearity**
  - Why needed here: The 5 sentiment aspects are intercorrelated (interpersonal vs operational r=0.87-0.89), which can destabilize regression coefficients.
  - Quick check question: If two predictors have VIF > 5, how would you interpret their individual β coefficients?

- **Census Block Group (CBG) Linkage**
  - Why needed here: To test whether community-level SES affects satisfaction independent of service quality.
  - Quick check question: How would you geocode a facility's address to its CBG FIPS code for demographic attachment?

## Architecture Onboarding

- **Component map:**
  Data ingestion: Google Maps reviews → keyword filter ("urgent care") → geographic filter (DMV, FL) → text-only subset (152,680 reviews)
  → LLM classification: GPT-4o mini with structured prompt → JSON aspect-sentiment outputs (-1, 0, 1)
  → Aggregation: Review-level → hospital-level mean sentiment per aspect (534 hospitals with ≥10 reviews/aspect)
  → Statistical analysis: Correlation matrix → multiple regression (Models 1 & 2) → robustness checks (VIF, sensitivity)
  → Validation: 400 manually annotated reviews → accuracy, precision, recall, F1

- **Critical path:**
  1. Prompt engineering and manual annotation (ground truth)
  2. Model selection (GPT-4o mini: accuracy >80%, cost-optimized)
  3. Full dataset classification → aggregation
  4. Regression with VIF < 8 for all predictors
  5. Sensitivity analysis (different review thresholds, interaction terms)

- **Design tradeoffs:**
  - GPT-4o mini vs GPT-4o: ~10x cost savings for ~2-5% accuracy loss
  - 5 consolidated aspects vs 12+ fine-grained: reduces overlap but may miss sub-dimensions
  - Minimum 10 reviews/aspect: improves reliability but excludes 182 hospitals

- **Failure signatures:**
  - Severe class imbalance: 676 positive vs 18 neutral samples → poor neutral classification
  - Low mention rates: Finances appears in ~11,701 reviews vs 89,357 for interpersonal
  - Regional bias: Florida reviews consistently more positive than DMV across all aspects
  - Multicollinearity: Interpersonal VIF=7.98, approaching threshold

- **First 3 experiments:**
  1. Validate classification stability: Re-run GPT-4o mini on the 400-review set with temperature=0; compare consistency across runs.
  2. Alternative model test: Compare GPT-4o mini vs Claude Haiku on the same 400 reviews for cost/accuracy trade-off.
  3. Aspect granularity probe: Split operational efficiency into "wait time" vs "process efficiency"; test if one sub-aspect dominates the effect.

## Open Questions the Paper Calls Out

- Would fine-tuning or chain-of-thought prompting strategies improve LLM performance on aspect-based sentiment analysis for healthcare reviews beyond the accuracy achieved by GPT-4o mini with standard prompting?
- Does the finding that interpersonal factors and operational efficiency drive urgent care satisfaction generalize to other healthcare domains such as emergency departments or primary care?
- How does integrating traditional survey data with online review analysis change our understanding of urgent care satisfaction patterns?

## Limitations

- Classification accuracy of 80% leaves substantial room for misattribution, especially given severe class imbalance (676 positive vs 18 neutral samples).
- Census Block Group linkage assumes facility demographics represent the patient population, but many urgent care facilities serve transient or non-local patients.
- The five-aspect framework consolidates nuanced patient experiences; important sub-dimensions like provider empathy or diagnostic accuracy may be masked within broader categories.

## Confidence

- **High Confidence**: The strong correlation between interpersonal factors and ratings (0.93-0.94) and operational efficiency (0.84-0.87) with patient satisfaction, given the robust sample size and consistent results across models.
- **Medium Confidence**: The finding that technical quality, finances, and facilities show no independent effects, as these aspects have lower mention rates and the classification accuracy for these categories may be lower.
- **Low Confidence**: The minimal association between socioeconomic factors and satisfaction, as the CBG linkage method may not accurately capture the actual patient demographics.

## Next Checks

1. Replicate the LLM classification on a held-out 400-review validation set using the exact prompt with temperature=0 to verify classification stability and ensure consistency across runs.
2. Conduct sensitivity analysis by splitting operational efficiency into sub-aspects (wait time vs process efficiency) to determine if one sub-dimension drives the effect and test robustness of the framework.
3. Test interaction terms between interpersonal sentiment and population density to determine if the mechanism varies by urbanization level and validate the assumption that service quality effects transcend socioeconomic boundaries.