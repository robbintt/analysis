---
ver: rpa2
title: Build AI Assistants using Large Language Models and Agents to Enhance the Engineering
  Education of Biomechanics
arxiv_id: '2511.15752'
source_url: https://arxiv.org/abs/2511.15752
tags:
- ball
- mass
- solver
- hand
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of applying large language models
  (LLMs) to engineering education, specifically in biomechanics, where domain-specific
  knowledge and multi-step reasoning are required. To tackle this, the authors propose
  a dual-module framework: Retrieval-Augmented Generation (RAG) for conceptual true/false
  questions, and a Multi-Agent System (MAS) for calculation-oriented problems.'
---

# Build AI Assistants using Large Language Models and Agents to Enhance the Engineering Education of Biomechanics

## Quick Facts
- **arXiv ID**: 2511.15752
- **Source URL**: https://arxiv.org/abs/2511.15752
- **Reference count**: 40
- **Primary result**: Dual-module framework combining RAG for conceptual questions and MAS for calculations shows promise in biomechanics education

## Executive Summary
This paper addresses the challenge of applying large language models to engineering education, specifically in biomechanics where domain-specific knowledge and multi-step reasoning are essential. The authors propose a dual-module framework that combines Retrieval-Augmented Generation (RAG) for conceptual true/false questions with a Multi-Agent System (MAS) for calculation-oriented problems. The approach demonstrates how domain-specific knowledge integration and agent-based problem decomposition can enhance LLM performance in educational contexts.

## Method Summary
The proposed framework employs two complementary modules: a RAG system that improves LLM accuracy on conceptual questions by incorporating domain-specific knowledge from textbooks, and a MAS that simulates human problem-solving through Manager, Solver, and Reviewer agents. The RAG module retrieves relevant information to provide context for answering true/false questions, while the MAS breaks down complex calculations into manageable steps, generates equations, executes code, and provides explainable solutions. This dual approach addresses the limitations of LLMs in handling both conceptual understanding and computational problem-solving in biomechanics education.

## Key Results
- RAG significantly enhances LLM performance on conceptual true/false questions in biomechanics
- MAS effectively solves complex calculation problems through agent collaboration
- The dual-module framework demonstrates potential for intelligent tutoring systems in engineering education
- Domain-specific knowledge integration improves LLM accuracy and stability

## Why This Works (Mechanism)
The framework works by addressing the fundamental limitations of general-purpose LLMs in engineering education. For conceptual questions, RAG provides domain-specific context that helps LLMs make accurate judgments rather than relying on potentially incorrect general knowledge. For calculation problems, the MAS approach mimics human problem-solving by decomposing complex tasks into manageable components handled by specialized agents. This structured approach ensures that calculations are properly derived, executed, and verified, leading to more reliable and explainable solutions.

## Foundational Learning
- **Retrieval-Augmented Generation (RAG)**: Why needed - Provides domain-specific context to improve LLM accuracy; Quick check - Verify retrieval relevance scores
- **Multi-Agent Systems (MAS)**: Why needed - Simulates human problem-solving decomposition; Quick check - Validate agent task boundaries
- **Biomechanics domain knowledge**: Why needed - Essential for accurate engineering education applications; Quick check - Cross-reference with standard textbooks
- **Code generation and execution**: Why needed - Enables automated calculation solving; Quick check - Verify output correctness against known solutions
- **Explainable AI**: Why needed - Provides pedagogical value through transparent reasoning; Quick check - Review explanation clarity and completeness

## Architecture Onboarding
- **Component Map**: RAG Module -> Conceptual Question Processing; MAS Module -> Calculation Problem Processing; Manager Agent -> Problem Decomposition; Solver Agent -> Equation Generation; Reviewer Agent -> Solution Verification
- **Critical Path**: Question Input -> Domain Knowledge Retrieval (RAG) OR Problem Decomposition (MAS) -> Solution Generation -> Verification -> Output
- **Design Tradeoffs**: RAG provides stability but may limit creativity; MAS offers flexibility but increases complexity
- **Failure Signatures**: RAG failures manifest as incorrect factual answers; MAS failures appear as calculation errors or logical inconsistencies
- **First Experiments**: 1) Test RAG performance on simple conceptual questions; 2) Evaluate MAS on single-step calculations; 3) Combine modules for mixed problem types

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains primarily demonstrated on conceptual true/false questions, with limited evidence for complex multi-concept problems
- MAS approach depends heavily on code generation accuracy and may struggle with ambiguous problem statements
- Evaluation constrained to biomechanics datasets, raising questions about generalizability to other engineering disciplines

## Confidence
- **High Confidence**: Technical feasibility of combining RAG and MAS modules for different problem types
- **Medium Confidence**: Effectiveness of Manager-Solver-Reviewer agent architecture for complex calculations
- **Medium Confidence**: Improvement in LLM performance through domain-specific knowledge integration

## Next Checks
1. Test the framework's performance on interdisciplinary problems that combine conceptual and calculation elements
2. Conduct user studies with actual students and instructors to evaluate pedagogical effectiveness and usability
3. Evaluate generalization to other engineering domains beyond biomechanics to assess domain transfer capabilities