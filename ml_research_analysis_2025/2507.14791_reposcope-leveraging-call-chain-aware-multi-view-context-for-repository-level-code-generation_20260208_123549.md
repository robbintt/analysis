---
ver: rpa2
title: 'RepoScope: Leveraging Call Chain-Aware Multi-View Context for Repository-Level
  Code Generation'
arxiv_id: '2507.14791'
source_url: https://arxiv.org/abs/2507.14791
tags:
- code
- call
- generation
- context
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RepoScope addresses repository-level code generation by providing
  LLMs with multi-view context derived from call chain-aware retrieval. It constructs
  a Repository Structural Semantic Graph to capture structural semantics and employs
  a call chain prediction method to identify potential callees, enhancing context
  relevance.
---

# RepoScope: Leveraging Call Chain-Aware Multi-View Context for Repository-Level Code Generation

## Quick Facts
- arXiv ID: 2507.14791
- Source URL: https://arxiv.org/abs/2507.14791
- Reference count: 40
- Primary result: Achieves up to 36.35% relative improvement in pass@1 scores on CoderEval and DevEval benchmarks compared to state-of-the-art methods

## Executive Summary
RepoScope addresses repository-level code generation by providing LLMs with multi-view context derived from call chain-aware retrieval. It constructs a Repository Structural Semantic Graph to capture structural semantics and employs a call chain prediction method to identify potential callees, enhancing context relevance. The approach integrates four distinct context views—callers, call chains, similar functions, and similar fragments—into a structure-preserving prompt. Evaluated on CoderEval and DevEval benchmarks, RepoScope achieves up to 36.35% relative improvement in pass@1 scores compared to state-of-the-art methods, demonstrating effectiveness, efficiency, and generalizability.

## Method Summary
RepoScope is a static-analysis-only RAG system for repository-level code generation. It builds a Repository Structural Semantic Graph (RSSG) using Pytype and Tree-sitter to extract code entities and their relations, then retrieves context through four views: callers, predicted call chains, similar functions, and similar fragments. Call chain prediction uses clustering-based entity scoring with DFS traversal to identify probable callees. The retrieved context is serialized in a structure-preserving manner and integrated into prompts for a single LLM query per generation task. The system requires no training and works directly on real-world Python repositories.

## Key Results
- Achieves 36.35% relative improvement in pass@1 scores compared to state-of-the-art methods on CoderEval and DevEval benchmarks
- Call chain prediction module achieves 0.603 F1 score in identifying relevant callees
- Structure-preserving serialization demonstrates improved coherence compared to flat concatenation approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieving potential callees via structural graph traversal and repository-wide pattern matching provides more relevant context than text-based similarity alone.
- **Mechanism:** RepoScope constructs a Repository Structural Semantic Graph (RSSG). It identifies imported entities, calculates "entity scores" based on the calling patterns of similar functions (clustering), and performs Depth First Search (DFS) to predict probable call chains. This allows the system to suggest relevant internal APIs that the target function *should* call, even if their names aren't textually similar to the target's signature.
- **Core assumption:** The paper assumes that functions within the same semantic cluster exhibit similar calling behaviors, allowing the target function's dependencies to be inferred from its neighbors.
- **Evidence anchors:**
  - [abstract] "...call chain prediction method that utilizes the repository's structural semantics to identify potential callees..."
  - [section 3.3] "...we compute entity scores using the call relation set... leveraging the callees of similar functions to identify entities that are more likely to be called..."
  - [corpus] Related work "Knowledge Graph Based Repository-Level Code Generation" supports the general efficacy of using knowledge graphs for retrieval over simple text search.
- **Break condition:** If the repository is small or the target function lacks "similar counterparts" (structural isolation), the cluster-based scoring fails, and retrieval degrades to basic similarity.

### Mechanism 2
- **Claim:** Integrating four distinct context views (Callers, Call Chains, Similar Functions, Similar Fragments) exposes the LLM to the full "sociology" of the code snippet, reducing hallucinations.
- **Mechanism:** The system retrieves four specific views: (1) Callers (revealing usage context/expected inputs), (2) Predicted Call Chains (revealing implementation dependencies), (3) Similar Functions (revealing logic patterns), and (4) Similar Fragments. These are aggregated into a unified prompt.
- **Core assumption:** LLMs require both "top-down" context (how a function is used) and "bottom-up" context (what tools/APIs are available) to generate correct repository-level code.
- **Evidence anchors:**
  - [abstract] "...integrates four distinct context views... into a structure-preserving prompt."
  - [section 2.1] "The callers reveal the function's intended use... while the callees directly participate in constructing the function body..."
  - [corpus] "GRACE" and other neighbors focus on fusing contexts, but RepoScope specifically validates the "Caller + Callee" symmetry.
- **Break condition:** If the token budget is mismanaged, the "four-view" complexity leads to context truncation, potentially cutting off critical callers or callees while retaining less useful similar fragments.

### Mechanism 3
- **Claim:** Structure-preserving serialization (reconstructing hierarchy) allows the LLM to better interpret code entity relationships than flat concatenation.
- **Mechanism:** Instead of pasting code blocks sequentially, RepoScope traverses the retrieved call chains to build a structural tree (maintaining class-method hierarchies). It serializes this tree using indentation and pathing, while deduplicating overlapping nodes from different chains.
- **Core assumption:** LLMs leverage indentation and structural hierarchy to maintain "coherence" in attention mechanisms, similar to how humans parse code.
- **Evidence anchors:**
  - [abstract] "...structure-preserving serialization algorithm for prompt construction, ensuring the coherence of the context..."
  - [section 3.4] "...convert the contexts into a coherent token sequence, preserving their original hierarchical relationships..."
  - [corpus] "In Line with Context" discusses context inlining, but RepoScope explicitly focuses on *preserving structure* during this injection.
- **Break condition:** If the retrieved entities are highly disconnected (no shared classes or paths), the serialization algorithm yields a flat list, negating its benefits.

## Foundational Learning

- **Concept: Repository Structural Semantic Graph (RSSG)**
  - **Why needed here:** This is the "brain" of RepoScope. Unlike a standard AST, the RSSG is a heterogeneous graph connecting Classes, Functions, and Attributes via structural (Contains, Inherits) and semantic (Calls, Imports) edges.
  - **Quick check question:** Can you distinguish between a "Contains" edge and a "Calls" edge in a class hierarchy?

- **Concept: Static Analysis vs. Dynamic Execution**
  - **Why needed here:** RepoScope relies *solely* on static analysis (Pytype/Tree-sitter) to build the RSSG. It does not run the code. This makes it fast and training-free but blind to dynamic dispatch or reflection-based calls not visible in the type signature.
  - **Quick check question:** If a function calls an API via a dynamic string string `getattr(obj, func_name)()`, will RepoScope's RSSG capture this link? (Assumption: Likely No).

- **Concept: Context Views in RAG**
  - **Why needed here:** Understanding that "context" isn't monolithic. RepoScope argues that "Callers" provide the "Why" (interface), while "Callees" provide the "How" (implementation).
  - **Quick check question:** If you only provide the "Similar Functions" view, what specific type of information might be missing regarding the target function's inputs?

## Architecture Onboarding

- **Component map:** Indexer (Pytype/Tree-sitter -> RSSG + Segments) -> Retriever (Call Chain Predictor + Similarity Search) -> Prompt Constructor (Structure-preserving serializer + Token allocator) -> LLM

- **Critical path:** The **Call Chain Prediction** (Section 3.3) is the most sensitive module. If the "Entity Scoring" (weighting $\alpha_1, \alpha_2, \alpha_3$) is off, the DFS retrieves irrelevant chains, flooding the context window with noise.

- **Design tradeoffs:**
  - *Efficiency vs. Accuracy:* RepoScope uses a **single LLM query** and static analysis (fast/cheap) vs. Agent-based methods that use multiple queries (accurate but slow/expensive).
  - *Generalizability:* It avoids training (training-free), allowing it to work on any repo with Python support, but relies heavily on the heuristics of the clustering algorithm ($M=5$).

- **Failure signatures:**
  - **Hallucinated APIs:** If Call Chain Prediction fails (low F1 score), the LLM may invent methods that don't exist.
  - **Context Flooding:** If the serialization fails to deduplicate nodes effectively, the prompt fills up with repeated class definitions.
  - **Isolation Errors:** For small repos with few "similar functions," the clustering logic breaks, returning generic or irrelevant results.

- **First 3 experiments:**
  1. **RSSG Validation:** Construct the RSSG for a target repo. Manually inspect if "Imported Entities" correctly link to "Structural and Type Dependency" edges.
  2. **Prediction Accuracy (F1):** Isolate the Call Chain Prediction module. Run it on a dataset with known ground-truth callees. Tune the weighting coefficients ($\alpha$) to maximize F1 score.
  3. **Serialization Ablation:** Run generation tasks using "Flat" serialization vs. "Structure-Preserving" serialization. Measure the delta in pass@1 scores to verify the paper's claim on structural coherence.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can code generation systems infer specific user intentions from broader repository contexts when only vague requirements are provided?
- **Basis in paper:** [explicit] The authors explicitly state this as future work in Section 8: "Investigate how to infer specific user intentions from broader repository contexts when only vague requirements are provided."
- **Why unresolved:** Current approaches assume well-defined function signatures and docstrings; handling vague or underspecified requirements remains unaddressed in RepoScope's design.
- **What evidence would resolve it:** A systematic study showing successful generation from vague prompts by leveraging repository patterns, user history, or implicit conventions.

### Open Question 2
- **Question:** Can syntax-based or alternative code snippet segmentation strategies improve retrieval and generation quality compared to the current sliding window approach?
- **Basis in paper:** [explicit] The authors explicitly identify this in Section 8: "Explore alternative code snippet segmentation strategies (e.g., syntax-based segmentation) and study their impact."
- **Why unresolved:** RepoScope uses sliding window segmentation inherited from prior work without systematic comparison to alternatives that might better preserve semantic boundaries.
- **What evidence would resolve it:** A controlled ablation comparing sliding window against syntax-aware, AST-based, or semantic segmentation on the same benchmarks.

### Open Question 3
- **Question:** How effectively does RepoScope generalize to statically typed languages like Java and C++, where type relationships are more explicit?
- **Basis in paper:** [inferred] Section 6.2 notes that evaluation is limited to Python and states: "We are willing to conduct a more systematic study of RepoScope's performance on such languages in future work." A preliminary Java experiment showed only modest improvement (58.95% vs 57.64%).
- **Why unresolved:** Polymorphism and other language-specific features were not well-handled in preliminary experiments; systematic evaluation on multi-language benchmarks is missing.
- **What evidence would resolve it:** Comprehensive evaluation on Java/C++ benchmarks (e.g., full CoderEval Java subset) with statistical analysis showing consistent improvements.

### Open Question 4
- **Question:** How can call-chain prediction accuracy be improved when target functions lack similar counterparts or when similar functions exhibit divergent calling behaviors?
- **Basis in paper:** [inferred] Section 6.2 acknowledges: "the prediction performance may degrade if the target function lacks similar counterparts... if similar functions do not exhibit similar calling behaviors." The F1 score of 0.603, while better than baseline, indicates substantial room for improvement.
- **Why unresolved:** The heuristic assumption that similar functions share calling patterns is fundamental to the current approach but breaks down in edge cases.
- **What evidence would resolve it:** Analysis of failure cases identifying prediction accuracy vs. repository scale/function similarity, and a refined approach maintaining performance in sparse-resemblance scenarios.

## Limitations

- **Missing granularity:** The entity scoring mechanism's reliance on K-means clustering with fixed parameters (M=5) may not generalize across repository sizes and code patterns.
- **Token allocation sensitivity:** The two-stage heuristic (60% then 30%) could lead to suboptimal context distribution, potentially cutting off critical information.
- **Language restriction:** Evaluation is limited to Python, with only preliminary experiments on Java showing modest improvements, raising questions about multi-language generalization.

## Confidence

- **High confidence:** Call chain prediction mechanism and its evaluation on F1 scores; static analysis-based RSSG construction; overall architecture design
- **Medium confidence:** Structure-preserving serialization benefits; four-view context integration effectiveness; token allocation strategy
- **Low confidence:** Generalization across diverse repository types; scalability to very large codebases; robustness when similar functions are scarce

## Next Checks

1. Conduct ablation studies varying K-means parameters (M) and entity scoring weights (α1, α2, α3) to identify sensitivity to hyperparameter choices
2. Test structure-preserving serialization on repositories with highly disconnected code entities to measure performance degradation
3. Implement and measure the impact of alternative token allocation strategies beyond the proposed 60%-30% heuristic