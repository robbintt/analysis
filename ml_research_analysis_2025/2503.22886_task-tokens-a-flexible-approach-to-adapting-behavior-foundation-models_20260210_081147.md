---
ver: rpa2
title: 'Task Tokens: A Flexible Approach to Adapting Behavior Foundation Models'
arxiv_id: '2503.22886'
source_url: https://arxiv.org/abs/2503.22886
tags:
- task
- tokens
- tasks
- maskedmimic
- control
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Task Tokens, a method for adapting behavior
  foundation models (BFMs) to specific tasks while preserving their generalization
  capabilities. The core idea is to train a task-specific encoder that maps observations
  to additional input tokens for the BFM, allowing integration of task-specific optimization
  with the BFM's pre-trained behavioral priors.
---

# Task Tokens: A Flexible Approach to Adapting Behavior Foundation Models

## Quick Facts
- arXiv ID: 2503.22886
- Source URL: https://arxiv.org/abs/2503.22886
- Authors: Ron Vainshtein; Zohar Rimon; Shie Mannor; Chen Tessler
- Reference count: 11
- Key outcome: Task Tokens achieves high success rates (Reach: 94.88%, Direction: 99.26%, Steering: 88.69%, Long Jump: 99.75%, Strike: 76.61%) while maintaining human-like motion quality

## Executive Summary
This paper introduces Task Tokens, a method for adapting behavior foundation models (BFMs) to specific tasks while preserving their generalization capabilities. The core idea is to train a task-specific encoder that maps observations to additional input tokens for the BFM, allowing integration of task-specific optimization with the BFM's pre-trained behavioral priors. The method uses reinforcement learning to train the task encoder while keeping the BFM frozen, enabling parameter-efficient adaptation.

Key results show that Task Tokens achieves high success rates across multiple tasks while maintaining natural, human-like motion quality. The approach demonstrates superior sample efficiency compared to baselines, converging in approximately 50 million steps versus 300 million for PULSE. Task Tokens also shows improved robustness to out-of-distribution perturbations in friction and gravity, with success rates remaining high even under extreme conditions. Human studies confirm that Task Tokens-generated motions are consistently rated as more human-like than alternatives, particularly when compared to fine-tuned models.

## Method Summary
Task Tokens introduces a novel approach to adapting behavior foundation models by training a task-specific encoder that generates additional input tokens for the BFM. The method freezes the pre-trained BFM to preserve its generalization capabilities while using reinforcement learning to optimize the task encoder for specific objectives. The task encoder takes observations as input and produces tokens that are appended to the BFM's input sequence, allowing the model to incorporate task-specific information without modifying its weights. This design enables efficient adaptation to new tasks while maintaining the natural, human-like motion patterns learned during BFM pre-training.

## Key Results
- High task success rates: Reach (94.88%), Direction (99.26%), Steering (88.69%), Long Jump (99.75%), Strike (76.61%)
- Superior sample efficiency: converges in ~50 million steps vs 300 million for PULSE
- Robustness to physics perturbations: maintains high success rates under extreme friction and gravity variations
- Human preference: consistently rated as more human-like than alternatives, especially compared to fine-tuned models

## Why This Works (Mechanism)
The mechanism works by leveraging the pre-trained BFM's ability to generate natural, generalizable motion while allowing task-specific optimization through the learned token encoder. By freezing the BFM weights, the method prevents catastrophic forgetting of the valuable behavioral priors learned during pre-training. The task encoder acts as an adapter that translates task objectives into a format the BFM can understand, effectively bridging the gap between general behavioral priors and specific task requirements. This approach maintains the BFM's ability to produce coherent, physically plausible motions while enabling adaptation to new tasks through the learned token representation.

## Foundational Learning
- Behavior Foundation Models (BFMs): Pre-trained models that capture general human motion patterns - needed for generalization across diverse tasks, verified by strong performance across multiple benchmarks
- Token-based conditioning: Using learned tokens as additional input to control model behavior - needed for parameter-efficient adaptation, verified by maintaining BFM performance while adapting to tasks
- Reinforcement learning adaptation: Using RL to train task-specific components while freezing pre-trained models - needed to preserve learned priors while optimizing for tasks, verified by preventing catastrophic forgetting

## Architecture Onboarding

Component Map: Observation -> Task Encoder -> Task Tokens -> BFM -> Action

Critical Path: Task Encoder training with RL objective while BFM remains frozen

Design Tradeoffs:
- Freezing BFM preserves generalization but limits adaptation potential
- Token-based approach enables parameter efficiency but adds input complexity
- RL training provides task optimization but requires careful reward design

Failure Signatures:
- Task tokens fail to generate meaningful variations (encoder underfitting)
- BFM ignores task tokens (encoder tokens not integrated properly)
- Degraded motion quality (task-specific optimization conflicts with behavioral priors)

First Experiments:
1. Verify BFM produces stable outputs without task tokens
2. Test task encoder with random weights to confirm input integration
3. Validate reward shaping for each task to ensure proper optimization

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on pre-trained BFM quality, limiting performance if BFM has coverage gaps
- Freezing strategy prevents adaptation requiring significant behavioral changes
- RL-based token training may struggle with complex, high-dimensional tasks
- Evaluation limited to short-horizon tasks with predictable dynamics

## Confidence

**Task Tokens Architecture and Integration (High)**: The core mechanism of using task-specific tokens as additional input to BFMs is well-established in the literature and the implementation appears sound.

**Performance Claims (Medium)**: While the reported success rates are high, the evaluation is limited to a specific benchmark suite. The comparisons to baselines are conducted under controlled conditions that may not reflect real-world deployment scenarios.

**Human Preference Results (Medium)**: Human studies show consistent preferences, but the methodology details (number of participants, demographic diversity) are not fully specified, and subjective evaluation of "human-like" motion can vary across evaluators.

**Robustness Claims (Low-Medium)**: The perturbation experiments demonstrate resilience to certain physics variations, but the range of tested conditions is limited. The method's performance under more extreme or realistic perturbations remains uncertain.

## Next Checks

1. Cross-dataset generalization: Evaluate Task Tokens when the BFM is pre-trained on different motion datasets (e.g., large-scale human motion capture data) to assess sensitivity to BFM quality and domain mismatch.

2. Long-horizon task performance: Test the method on tasks requiring sustained control over extended time horizons (10+ seconds) with intermittent contact to validate temporal coherence and stability.

3. Real-world transfer: Implement Task Tokens on a physical robot platform to assess sim-to-real transfer capabilities, particularly focusing on how well the task-specific tokens handle unmodeled dynamics and sensor noise.