---
ver: rpa2
title: "$\u0394$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast\
  \ Cancer Risk Prediction"
arxiv_id: '2510.19003'
source_url: https://arxiv.org/abs/2510.19003
tags:
- time
- exams
- cancer
- breast
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Time-Aware \u2206t-Mamba3D addresses the challenge of modeling\
  \ irregular longitudinal medical imaging data by introducing a novel state-space\
  \ architecture that explicitly encodes true inter-visit time intervals (\u2206t)\
  \ and captures rich spatio-temporal context. The model features a continuous-time\
  \ selective scanning mechanism that modulates state transitions with actual time\
  \ gaps, complemented by a multi-scale 3D neighborhood fusion module for efficient\
  \ spatio-temporal encoding."
---

# $Δ$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast Cancer Risk Prediction

## Quick Facts
- **arXiv ID**: 2510.19003
- **Source URL**: https://arxiv.org/abs/2510.19003
- **Reference count**: 18
- **Key outcome**: Achieves 2-5 percentage point improvement in validation c-index for breast cancer risk prediction using irregular longitudinal mammogram data.

## Executive Summary
$Δ$t-Mamba3D addresses the challenge of modeling irregular longitudinal medical imaging data by introducing a novel state-space architecture that explicitly encodes true inter-visit time intervals (Δt) and captures rich spatio-temporal context. The model features a continuous-time selective scanning mechanism that modulates state transitions with actual time gaps, complemented by a multi-scale 3D neighborhood fusion module for efficient spatio-temporal encoding. In comprehensive breast cancer risk prediction benchmarks using sequential screening mammogram exams, $Δ$t-Mamba3D achieves superior performance, improving validation c-index by 2-5 percentage points and delivering higher 1-5 year AUC scores compared to established recurrent, transformer, and state-space models. The method's linear complexity enables efficient processing of long patient screening histories while maintaining robust performance across different temporal patterns and class distributions.

## Method Summary
The method processes longitudinal mammogram sequences by first extracting per-view features using a Swin-V2 backbone, then fusing the four views (L/R-CC, L/R-MLO) through summation. The core $Δ$t-Mamba3D block transforms 3D spatio-temporal features into 1D sequences, applies time-aware selective scanning where the state-space step size is modulated by actual inter-visit intervals, reshapes back to 3D, and performs multi-scale 3D neighborhood fusion using depth-wise convolutions. The model outputs risk predictions through a Risk Hazard Module that processes the fused features through global pooling and linear layers to predict 1-5 year cancer risk probabilities.

## Key Results
- **Superior performance**: 2-5 percentage point improvement in validation c-index compared to established baselines
- **Higher AUC scores**: Consistently better 1-5 year AUC scores across all benchmark datasets
- **Efficient processing**: Linear complexity enables handling up to 8 prior exams (512 tokens) efficiently vs quadratic attention transformers

## Why This Works (Mechanism)

### Mechanism 1: Time-Aware Selective Scanning
The model explicitly modulates the state-space model (SSM) step size with the true inter-visit interval (Δt) using the formula $\delta_{TA} = \delta \cdot (1 + \gamma \frac{\Delta t}{\tau_{min}})$. This enables dynamic weighing of historical context against current observations, where large Δt values drive the state transition matrix toward zero (exponential decay), effectively "forgetting" outdated history, while small Δt values preserve the hidden state, retaining short-term memory.

### Mechanism 2: Multi-Scale 3D Neighborhood Fusion
The model aggregates local voxel context across spatial and temporal dimensions via 3D convolutions to compensate for the loss of structural coherence inherent in the 1D scanning process. By reshaping the scanned sequence back into a 3D spatio-temporal grid and applying depth-wise 3D convolutions with kernels (1,3,3) and (3,3,3), the model fuses information from neighboring voxels and adjacent visits, capturing local lesion morphology that a pure sequence scan might miss.

### Mechanism 3: Linear Complexity in Longitudinal Sequences
The SSM architecture allows the model to ingest significantly longer patient histories (up to 8 exams) than quadratic-attention Transformers, improving risk estimation for complex cases. Unlike self-attention (O(L²)), the SSM recurrence maintains a fixed hidden state size, scaling linearly O(L) with sequence length, enabling efficient processing of long patient screening histories.

## Foundational Learning

- **Concept: State Space Models (SSM) & Discretization**
  - **Why needed here**: This paper is built on Mamba, an SSM. You must understand how continuous dynamics (h'(t) = Ah(t) + Bx(t)) are converted to discrete steps (h_i = Āh_{i-1}) to grasp how "time" is injected into the math.
  - **Quick check question**: If the discretization step δ increases, does the hidden state h tend to persist longer or decay faster? (See Theorem 1).

- **Concept: Irregular Time Sampling**
  - **Why needed here**: Standard RNNs/Transformers assume uniform time steps (e.g., 1 token = 1 second). Clinical data is irregular (6 months vs 2 years gap).
  - **Quick check question**: Why is simply ignoring the time gap (treating a 1-year gap the same as a 1-day gap) dangerous for medical risk prediction?

- **Concept: Multi-View Mammography**
  - **Why needed here**: The model inputs CC and MLO views.
  - **Quick check question**: The paper fuses views by "summation" (V_t = Σ F_{t,v}). What information might be lost compared to attention-based fusion?

## Architecture Onboarding

- **Component map**: Swin-V2 -> View Fusion (Summation) -> Δt-Mamba3D Block -> Head (Risk Hazard Module)
- **Critical path**: The calculation of δᵗᴬ. If the Δt values are not normalized correctly or the mixing coefficient γ is off, the "time-aware" gating will either fail to fire or dominate the content-aware step size.
- **Design tradeoffs**:
  - Depth-wise Conv vs. Standard Conv: Chosen for efficiency (less FLOPs), but limits cross-channel interaction in the fusion step.
  - Summation Fusion: Extremely cheap way to handle 4 views, but assumes spatial alignment and equal importance of all views.
- **Failure signatures**:
  - State Collapse: If Δt is massive (e.g., >10 years) and γ is high, the hidden state may zero out (complete forgetting), leading to random predictions based only on the last frame.
  - Scan Order Bias: The paper notes "Inter-Slice Δt-Mamba performs poorly because it breaks spatial coherence." If you scan across time too early (interleaved) rather than finishing a visit (intra-slice), the model fails.
- **First 3 experiments**:
  1. Verify Time-Gating: Ablate γ (set to 0). Compare C-index against the full model to confirm Δt is actually adding value (Table 3).
  2. Sanity Check Complexity: Profile memory usage with max_seq_len=8 vs. Transformer baseline to verify the linear scaling claim (Table 1).
  3. Visualize Decay: Plot the effective step size δᵗᴬ vs. input time gap Δt for a sample patient to ensure the "Time-Aware Modulation" (Eq 4) is mathematically active.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the Δt-aware modulation mechanism generalize effectively to 3D imaging modalities (e.g., MRI or CT) where spatial context and temporal changes differ significantly from 2D mammography?
  - **Basis in paper**: The conclusion states: "Future work will focus on extending the proposed method to additional medical imaging modalities and related clinical tasks."
  - **Why unresolved**: The current model is validated exclusively on 2D mammogram sequences, utilizing a specific 2D-to-token sweep and 3D neighborhood fusion designed for this data structure.
  - **What evidence would resolve it**: Benchmarks of Δt-Mamba3D on longitudinal 3D volumetric datasets (e.g., brain MRI or lung CT) demonstrating comparable improvements over baselines.

- **Open Question 2**: Does the simple summation of multi-view features (L/R CC/MLO) obscure critical inter-view dependencies, such as bilateral asymmetry, that are typically relevant for clinical diagnosis?
  - **Basis in paper**: The method aggregates the four mammogram views into a single spatial tensor V_t by "summation" (Page 4), which assumes additive information rather than relational structure.
  - **Why unresolved**: While efficient, summation is a destructive operation that may erase comparative features (e.g., contralateral differences) that a cross-attention mechanism might preserve.
  - **What evidence would resolve it**: An ablation study replacing the summation fusion with a multi-view attention block to see if asymmetry-sensitive performance metrics improve.

- **Open Question 3**: Is the linear scaling of the time-aware step size (Δt) sufficient to capture complex non-linear disease progression dynamics?
  - **Basis in paper**: The model encodes time via the linear equation δᵗᴬ_i = δ_i (1 + γ·Δt(i)/τ_min) (Page 4), assuming a direct proportional relationship between calendar time and state transition scale.
  - **Why unresolved**: Biological changes may not follow linear decay or accumulation; standard learnable temporal embeddings (as used in TimeSformer or ContiFormer) might capture non-linear dependencies better.
  - **What evidence would resolve it**: A comparison between the current linear scaling and a learnable time-embedding injection method on a dataset with highly non-uniform risk progression.

## Limitations
- **Dataset generalization**: Reliance on CSAW-CC dataset limits generalizability across populations and imaging protocols
- **Hyperparameter sensitivity**: Time-aware mechanism's effectiveness hinges on accurate Δt normalization and sensitive to τ_min and γ hyperparameters
- **Cross-channel limitations**: Depth-wise 3D convolutions may miss critical cross-channel spatial interactions for subtle lesion detection
- **View fusion assumptions**: Summation-based view fusion assumes perfect spatial alignment across views which may not hold in practice

## Confidence
- **High confidence**: Linear complexity claim (verified by GFLOPs comparison in Table 1) and empirical performance improvements (C-index gains of 2-5 percentage points)
- **Medium confidence**: The theoretical foundation of time-aware SSM discretization (Theorem 1 is stated but not empirically validated beyond performance gains)
- **Low confidence**: Claims about the multi-scale 3D fusion module's specific architectural benefits, as ablation studies only compare to single-kernel variants without exploring alternative fusion strategies

## Next Checks
1. **Time-Gating Ablation**: Train a baseline model with γ=0 (no time-awareness) and compare C-index performance to confirm Δt modulation provides measurable benefit beyond standard SSMs
2. **Memory Efficiency Verification**: Profile GPU memory usage and training time for sequences of length 512 with Δt-Mamba3D versus Transformer baseline to confirm linear scaling claims
3. **Temporal Decay Visualization**: For a sample patient cohort, plot the effective step size δᵗᴬ versus Δt gaps to verify the theoretical "forgetting" mechanism operates as described in Theorem 1