---
ver: rpa2
title: 'MDP: Multidimensional Vision Model Pruning with Latency Constraint'
arxiv_id: '2504.02168'
source_url: https://arxiv.org/abs/2504.02168
tags:
- pruning
- latency
- block
- pages
- importance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Multi-Dimensional Pruning (MDP), a novel\
  \ paradigm for structural pruning that jointly optimizes multiple pruning granularities\u2014\
  channels, heads, embeddings, blocks\u2014while strictly adhering to latency constraints.\
  \ Unlike prior methods that focus on channels or use suboptimal linear latency models,\
  \ MDP employs advanced latency modeling and reformulates pruning as a Mixed-Integer\
  \ Nonlinear Program (MINLP) to achieve optimal latency-accuracy trade-offs."
---

# MDP: Multidimensional Vision Model Pruning with Latency Constraint
## Quick Facts
- arXiv ID: 2504.02168
- Source URL: https://arxiv.org/abs/2504.02168
- Reference count: 40
- Primary result: Achieves 28% speed increase with +1.4 Top-1 accuracy improvement on ResNet50

## Executive Summary
MDP (Multi-Dimensional Pruning) introduces a novel structural pruning paradigm that simultaneously optimizes multiple pruning granularities—channels, heads, embeddings, and blocks—while strictly adhering to latency constraints. Unlike prior methods that focus on individual dimensions or use suboptimal linear latency models, MDP employs advanced latency modeling and reformulates pruning as a Mixed-Integer Nonlinear Program (MINLP) to achieve optimal latency-accuracy trade-offs. The method demonstrates significant improvements across both convolutional and transformer architectures.

## Method Summary
MDP addresses structural pruning through a multi-dimensional approach that jointly optimizes multiple pruning granularities. The method reformulates the pruning problem as a MINLP, which allows for optimal trade-offs between accuracy and latency. Unlike traditional methods that focus on single dimensions (typically channel pruning) or use linear latency models, MDP employs a sophisticated latency modeling approach that accounts for the complex interactions between different pruning dimensions. The optimization process simultaneously determines which channels, heads, embeddings, and blocks to prune while ensuring the final model meets strict latency constraints.

## Key Results
- Achieves 28% speed increase with +1.4 Top-1 accuracy improvement on ResNet50
- Delivers additional 37% acceleration with +0.7 Top-1 accuracy gain on DEIT-Base
- Demonstrates generalization across CNNs, transformers, and 3D detection tasks

## Why This Works (Mechanism)
MDP's effectiveness stems from its ability to jointly optimize multiple pruning dimensions rather than treating them independently. By formulating the problem as a MINLP, the method can capture the complex interactions between different pruning decisions and find globally optimal solutions. The advanced latency modeling accurately predicts the real-world impact of pruning decisions, allowing for precise constraint satisfaction. This holistic approach enables better utilization of model capacity while meeting strict latency requirements, resulting in superior accuracy-latency trade-offs compared to single-dimension or heuristic-based methods.

## Foundational Learning
- Mixed-Integer Nonlinear Programming (MINLP): Optimization framework combining discrete and continuous variables; needed to handle binary pruning decisions while optimizing continuous accuracy metrics; quick check: verify convexity of subproblems
- Multi-dimensional structural pruning: Simultaneous optimization across channels, heads, embeddings, and blocks; needed to capture cross-dimension interactions; quick check: measure correlation between individual and joint pruning effects
- Latency-aware pruning: Integration of hardware-specific timing constraints into the optimization; needed to ensure real-world deployment feasibility; quick check: validate latency predictions against actual hardware measurements

## Architecture Onboarding
**Component map:** Input model → Latency model → MINLP optimizer → Pruned model → Hardware verification
**Critical path:** The MINLP formulation and latency modeling are the most critical components, as they directly determine the quality of pruning decisions and ensure constraint satisfaction.
**Design tradeoffs:** Global optimization (MINLP) vs. computational overhead, accuracy vs. latency constraints, generalization across hardware vs. platform-specific optimization
**Failure signatures:** Poor accuracy retention indicates suboptimal pruning decisions; latency constraint violations suggest inaccurate latency modeling; slow convergence points to MINLP formulation issues
**First experiments:** 1) Test single-dimension pruning baselines vs. MDP on ResNet50; 2) Validate latency model accuracy on target hardware; 3) Measure scalability limits on larger transformer models

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Latency modeling generalizability remains uncertain across diverse hardware architectures beyond NVIDIA T4 GPU
- MINLP formulation may face scalability challenges when applied to extremely large models or more than four dimensions
- Effectiveness under varying batch sizes and input resolutions requires further validation

## Confidence
- **High confidence**: MDP's superior performance metrics on ResNet50 and DEIT-Base models, mathematical formulation of MINLP problem, experimental methodology for latency measurement
- **Medium confidence**: Effectiveness across different model architectures (CNNs vs transformers), practical scalability to larger models, generalizability of latency model to different hardware platforms
- **Low confidence**: Computational overhead in real-world deployment, performance on emerging model architectures, robustness under different training protocols

## Next Checks
1. Evaluate MDP's performance on additional model architectures (e.g., Swin Transformer, ConvNeXt) and different hardware platforms (CPUs, mobile NPUs, different GPU families)
2. Conduct ablation studies to quantify individual contribution of each pruning dimension and test behavior when scaling to models with more than four pruning dimensions
3. Implement real-time latency monitoring during pruning to verify accuracy of offline latency model and assess discrepancies between predicted and actual inference speeds