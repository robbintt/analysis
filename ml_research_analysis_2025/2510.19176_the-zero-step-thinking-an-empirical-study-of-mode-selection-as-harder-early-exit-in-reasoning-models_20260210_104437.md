---
ver: rpa2
title: 'The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early
  Exit in Reasoning Models'
arxiv_id: '2510.19176'
source_url: https://arxiv.org/abs/2510.19176
tags:
- reasoning
- arxiv
- think
- thinking
- mode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mode Selection as a more challenging variant
  of the Early Exit problem in reasoning models, where the goal is to determine whether
  a model should use Long-CoT (THINKING) or Short-CoT (NOTHINKING) before explicit
  reasoning begins. Through extensive experiments across four benchmarks (GSM8K, MATH-500,
  AIME25, and GPQA-D) using three model scales (1.5B, 7B, and 32B), the study reveals
  that prompt-based methods often fail due to limited classification capabilities
  when provided with minimal information.
---

# The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models

## Quick Facts
- **arXiv ID**: 2510.19176
- **Source URL**: https://arxiv.org/abs/2510.19176
- **Reference count**: 40
- **Primary result**: Mode Selection (determining THINK vs NOTHINK before reasoning) proves more challenging than Early Exit, with prompt-based methods failing on minimal information and internal states methods showing instability despite better performance.

## Executive Summary
This paper introduces Mode Selection as a harder variant of the Early Exit problem in reasoning models, where the goal is to determine whether to use Long-CoT (THINKING) or Short-CoT (NOTHINKING) before explicit reasoning begins. Through extensive experiments across four benchmarks (GSM8K, MATH-500, AIME25, and GPQA-D) using three model scales (1.5B, 7B, and 32B), the study reveals that prompt-based methods often fail due to limited classification capabilities when provided with minimal information. Internal states-based methods, which leverage model internal signals, generally perform better but still exhibit instability. The findings indicate that existing methods relying solely on model-provided information are insufficient for effectively addressing Mode Selection in scenarios with limited information, highlighting the ongoing challenges of this task.

## Method Summary
The study conducts a comprehensive empirical evaluation of mode selection methods across four mathematical reasoning benchmarks (GSM8K, MATH-500, AIME25, and GPQA-D) using three model scales (1.5B, 7B, and 32B). Two primary approaches are tested: prompt-based methods that rely on minimal information provided to the model, and internal states-based methods that leverage model internal signals. The evaluation systematically compares performance across different model sizes and benchmarks, measuring the effectiveness of each approach in determining whether to use Long-CoT (THINKING) or Short-CoT (NOTHINKING) before reasoning begins.

## Key Results
- Prompt-based methods fail on mode selection when provided with minimal information due to limited classification capabilities
- Internal states-based methods generally outperform prompt-based approaches but exhibit instability across different conditions
- Larger models show diminished mode selection effectiveness, with NOTHINKING sometimes producing longer outputs than THINKING, suggesting internalized reasoning processes

## Why This Works (Mechanism)
The mechanism behind mode selection difficulty appears to stem from the fundamental challenge of classifying whether a problem requires explicit reasoning before any reasoning has occurred. This creates a paradox where the model must predict its own reasoning needs without access to the reasoning process itself. Internal states methods capture implicit confidence signals and pattern recognition that prompt-based methods miss, but these signals are inherently unstable and model-dependent.

## Foundational Learning
- **Mode Selection**: Determining whether to use Long-CoT or Short-CoT before reasoning begins - needed to optimize computational efficiency in reasoning models
- **Early Exit**: Terminating reasoning early when sufficient confidence is reached - needed as baseline comparison for mode selection difficulty
- **Chain-of-Thought (CoT)**: Sequential reasoning steps to solve problems - needed as the underlying reasoning mechanism being optimized
- **Internal States**: Model internal signals like attention patterns and hidden states - needed for methods that outperform prompt-based approaches
- **Classification Capabilities**: Model's ability to categorize inputs based on minimal information - needed to understand prompt-based method limitations

## Architecture Onboarding
- **Component map**: Input -> Mode Classifier (prompt-based or internal states) -> Decision (THINKING/NOTHINKING) -> Reasoning Execution
- **Critical path**: Input → Classifier → Mode Decision → Output Generation
- **Design tradeoffs**: Prompt-based (simple, interpretable) vs Internal states (complex, better performance but unstable)
- **Failure signatures**: Prompt-based methods misclassify due to minimal information; internal states methods show inconsistent performance across model scales
- **3 first experiments**:
  1. Test prompt-based mode selection on a simple classification task to establish baseline capabilities
  2. Compare internal states feature importance across different model layers
  3. Evaluate mode selection performance on non-mathematical reasoning tasks

## Open Questions the Paper Calls Out
- How to develop more robust mode selection methods that generalize across different model scales and reasoning domains
- Whether additional architectural modifications could improve the stability of internal states-based methods
- How to better interpret and utilize the internal signals that contribute to successful mode selection

## Limitations
- Findings primarily based on mathematical reasoning benchmarks, limiting generalizability to other domains
- Limited exploration of prompt engineering strategies that might improve mode selection performance
- Internal states instability characterized qualitatively without quantitative detail or systematic analysis
- Interpretation of larger models' reduced effectiveness remains speculative without mechanistic analysis

## Confidence
- **High confidence**: Prompt-based methods struggle with minimal information for mode classification is well-supported by experimental results
- **Medium confidence**: Internal states-based methods are generally superior but unstable - supported but lacks quantitative characterization of instability
- **Medium confidence**: Larger models show reduced mode selection effectiveness - documented but interpretation is speculative

## Next Checks
1. Test mode selection across diverse reasoning domains (commonsense QA, code generation, multi-step planning) to assess generalizability
2. Systematically evaluate how different prompting strategies and few-shot examples affect mode selection performance
3. Conduct ablation studies on internal state features to identify which signals contribute most to successful mode selection