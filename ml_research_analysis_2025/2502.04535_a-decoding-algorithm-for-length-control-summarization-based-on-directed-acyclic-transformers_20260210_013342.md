---
ver: rpa2
title: A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic
  Transformers
arxiv_id: '2502.04535'
source_url: https://arxiv.org/abs/2502.04535
tags:
- seqmap
- length
- pages
- reranker
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SeqMAP, a new decoding algorithm for length-control
  summarization using Directed Acyclic Transformers (DAT). Unlike previous methods
  that use Connectionist Temporal Classification (CTC) models, SeqMAP aligns better
  with DAT's training objective by marginalizing possible paths and finding the most
  probable sequence satisfying length constraints.
---

# A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers

## Quick Facts
- arXiv ID: 2502.04535
- Source URL: https://arxiv.org/abs/2502.04535
- Reference count: 36
- Primary result: SeqMAP outperforms CTC-based and existing DAT approaches on Gigaword and DUC2004 datasets while maintaining faster inference than autoregressive models

## Executive Summary
This paper introduces SeqMAP, a new decoding algorithm for length-control summarization using Directed Acyclic Transformers (DAT). Unlike previous methods that use Connectionist Temporal Classification (CTC) models, SeqMAP aligns better with DAT's training objective by marginalizing possible paths and finding the most probable sequence satisfying length constraints. The approach uses beam search with dynamic programming to approximate the SeqMAP objective and includes a reranker for performance improvement. Experiments on Gigaword and DUC2004 datasets show that SeqMAP outperforms both CTC-based methods and existing DAT approaches, achieving state-of-the-art results in length-control summarization while maintaining faster inference speed than autoregressive models.

## Method Summary
SeqMAP is a decoding algorithm specifically designed for Directed Acyclic Transformers in length-control summarization tasks. The method addresses limitations in previous CTC-based approaches by better aligning with DAT's training objectives through path marginalization and constrained sequence generation. The algorithm employs beam search with dynamic programming to approximate the SeqMAP objective, allowing for efficient search over possible sequences while respecting length constraints. A reranker component is incorporated to further improve performance by selecting optimal sequences from the beam search output.

## Key Results
- SeqMAP achieves state-of-the-art performance on Gigaword and DUC2004 datasets for length-control summarization
- Outperforms both CTC-based methods and existing DAT approaches in terms of ROUGE scores
- Maintains faster inference speeds compared to autoregressive models while delivering superior summarization quality

## Why This Works (Mechanism)
SeqMAP works by better aligning the decoding process with the training objective of Directed Acyclic Transformers. While CTC-based methods treat summarization as sequence labeling with blank tokens, SeqMAP directly models the marginalization over possible paths that DAT is trained on. This alignment allows the decoding algorithm to more effectively leverage the learned representations from DAT, resulting in better sequence generation under length constraints. The beam search with dynamic programming provides an efficient approximation of the exact SeqMAP objective, making it computationally feasible for practical applications.

## Foundational Learning
- Directed Acyclic Transformers (DAT): Non-autoregressive architecture for sequence generation that allows parallel token prediction, essential for faster inference in summarization tasks
- Connectionist Temporal Classification (CTC): Sequence labeling approach originally used for speech recognition, adapted for summarization but creates misalignment with DAT training objectives
- Beam Search with Dynamic Programming: Search strategy that maintains multiple candidate sequences and uses dynamic programming to efficiently explore the search space while approximating the SeqMAP objective
- Reranking Strategies: Post-processing techniques that select optimal sequences from beam search output to improve final generation quality

## Architecture Onboarding

Component Map:
Input Document -> DAT Encoder -> SeqMAP Decoder (Beam Search + Dynamic Programming) -> Reranker -> Output Summary

Critical Path:
The critical path flows from the DAT encoder through the SeqMAP decoder. The encoder produces contextualized representations that the decoder uses to generate token sequences. The SeqMAP decoder's beam search with dynamic programming is the computational bottleneck, as it must explore multiple candidate sequences while maintaining efficiency.

Design Tradeoffs:
The paper trades off between exact inference (computationally expensive) and approximate inference (faster but potentially less accurate). Beam search with dynamic programming provides a middle ground, offering reasonable approximation quality while maintaining practical inference speeds. The inclusion of a reranker adds computational overhead but improves final output quality.

Failure Signatures:
Poor performance may manifest when the beam search cannot adequately explore the search space due to constraints, leading to suboptimal sequences. The dynamic programming approximation may also introduce errors in edge cases where the exact SeqMAP objective significantly differs from the approximation. The reranker may fail to select optimal sequences if the scoring function doesn't capture all relevant quality dimensions.

First Experiments:
1. Compare ROUGE scores of SeqMAP versus CTC-based methods on Gigaword dataset with varying beam sizes
2. Measure inference speed of SeqMAP against autoregressive baselines across different document lengths
3. Ablation study removing the reranker component to quantify its contribution to overall performance

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Beam search with dynamic programming may introduce computational overhead or approximation errors in certain scenarios
- The reranker component's effectiveness requires more detailed analysis of its contribution versus the core SeqMAP algorithm
- Evaluation focuses primarily on ROUGE scores and inference speed, potentially overlooking other important aspects of summarization quality

## Confidence

High confidence in:
- Technical formulation of SeqMAP and its theoretical alignment with DAT training objectives

Medium confidence in:
- Empirical performance claims due to limited scope of evaluation metrics and potential dataset selection bias
- Speed advantage claims, as these depend heavily on specific hardware configurations and implementation details

## Next Checks
1. Conduct ablation studies to quantify the exact contribution of the reranker component versus the core SeqMAP algorithm, including analysis of trade-offs between performance gains and computational overhead

2. Evaluate the proposed approach on additional datasets and with alternative evaluation metrics beyond ROUGE, including human evaluation studies focusing on factual accuracy, coherence, and overall summary quality

3. Perform extensive runtime analysis across different hardware configurations and batch sizes to validate the claimed inference speed advantages over autoregressive baselines under various deployment scenarios