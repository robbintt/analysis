---
ver: rpa2
title: Active Learning via Regression Beyond Realizability
arxiv_id: '2506.00316'
source_url: https://arxiv.org/abs/2506.00316
tags:
- learning
- active
- assumption
- function
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents an active learning framework for multi-class\
  \ classification that operates beyond the standard realizability assumption. The\
  \ key contribution is showing that under a new, weaker condition\u2014requiring\
  \ only that the bias of the best-in-class function is lower bounded by a nondecreasing\
  \ function of the bias of the surrogate risk minimizer\u2014one can achieve comparable\
  \ label and sample complexity to realizability-based methods while using a convex\
  \ function class."
---

# Active Learning via Regression Beyond Realizability

## Quick Facts
- arXiv ID: 2506.00316
- Source URL: https://arxiv.org/abs/2506.00316
- Reference count: 40
- Key outcome: Active learning framework achieving realizability-level rates without realizability assumption via improper learning and bias-based conditions

## Executive Summary
This paper introduces a novel active learning framework for multi-class classification that operates beyond the standard realizability assumption. The key innovation is a new condition requiring only that the bias of the best-in-class function is lower bounded by a nondecreasing function of the bias of the surrogate risk minimizer. Under this weaker assumption, the authors prove that their algorithm achieves sample and label complexities comparable to realizability-based methods while using convex function classes. The method employs an improper learning strategy, fitting models from the full class to queried data and aggregating them, allowing it to handle misspecified settings where existing algorithms fail.

## Method Summary
The algorithm operates in epochs, where in each epoch it queries labels for an actively selected set of points, fits a model from the full convex function class to minimize the surrogate risk on these points, and aggregates the resulting models to form an improper classifier. The key theoretical insight is that under their new bias condition, the excess classification risk can be bounded by the excess surrogate risk. This allows the algorithm to achieve realizability-level guarantees even when the realizability assumption fails. The approach leverages model aggregation across epochs rather than returning a single model from the function class, which is what enables the relaxation of realizability.

## Key Results
- Proves a new condition (bias lower bound) that is provably weaker than approximate realizability
- Achieves sample complexity O(dϵ^{-β+2}/(β+1)) and label complexity O(dθ^{β/(β+2)}ϵ^{-2/(β+1)}) under Tsybakov noise
- Demonstrates through examples that assumptions can be far from realizability while still achieving optimal rates
- Shows that improper learning via model aggregation enables handling of misspecified settings

## Why This Works (Mechanism)
The algorithm succeeds by relaxing the realizability assumption while maintaining comparable statistical rates through a carefully designed bias condition. By allowing improper learning (returning an aggregated model rather than a single model from the class), the algorithm can effectively leverage the full power of the convex function class without requiring that the best classifier is representable within it. The bias condition ensures that minimizing the surrogate risk leads to meaningful progress on classification risk, even when perfect classification is impossible.

## Foundational Learning
- **Surrogate risk minimization**: Why needed - to enable convex optimization instead of direct classification risk minimization; Quick check - verify that the surrogate is calibrated for the classification task
- **Model aggregation**: Why needed - to implement improper learning while maintaining statistical efficiency; Quick check - ensure aggregation preserves the bias condition
- **Disagreement coefficient**: Why needed - to characterize label complexity in active learning; Quick check - estimate from unlabeled data or use adaptive methods
- **Pseudo-dimension**: Why needed - to characterize sample complexity for function classes; Quick check - bound for the specific function class used
- **Tsybakov noise condition**: Why needed - to characterize noise level and achieve fast rates; Quick check - verify whether β is known or needs estimation
- **Bias-variance decomposition**: Why needed - to relate surrogate risk to classification risk; Quick check - ensure the bias condition is verifiable for the problem

## Architecture Onboarding

**Component map:** Active selector -> Label query oracle -> Surrogate risk minimizer -> Model aggregator -> Improper classifier

**Critical path:** The algorithm's performance critically depends on the model-fitting oracle being able to find the surrogate risk minimizer accurately, as errors in this step propagate through the aggregation process and can violate the bias condition.

**Design tradeoffs:** The improper learning approach trades computational efficiency (model aggregation overhead) for statistical robustness (handling misspecification). The algorithm assumes access to a perfect model-fitting oracle, which may be unrealistic for complex function classes.

**Failure signatures:** If the bias condition fails, the algorithm may not achieve the claimed rates. Computational failures can occur if model aggregation becomes intractable or if the surrogate risk minimizer cannot be found accurately.

**First experiments:**
1. Test on a synthetic dataset where realizability fails but the bias condition holds, comparing against realizability-based active learning
2. Vary the strength of the bias condition to empirically verify the theoretical bounds on performance degradation
3. Implement with a practical optimization method (e.g., SGD) instead of assuming a perfect oracle to assess robustness

## Open Questions the Paper Calls Out
None

## Limitations
- The bias condition, while theoretically weaker than realizability, may still be restrictive in practice and difficult to verify
- The improper learning approach could lead to computational inefficiencies in large-scale settings due to model aggregation overhead
- The algorithm assumes access to a model-fitting oracle that can find the surrogate risk minimizer, which may not be computationally tractable for complex function classes
- Dependence on pseudo-dimension d suggests potential scalability issues for high-dimensional problems
- The theoretical rates assume knowledge of parameters like the disagreement coefficient, which would need estimation in practice

## Confidence
- Theoretical framework and assumptions: High
- Sample complexity bounds: High
- Label complexity bounds: Medium (depends on accurate estimation of disagreement coefficient)
- Practical implementation: Low

## Next Checks
1. Implement a concrete version of the algorithm with a practical optimization method for finding the surrogate risk minimizer, rather than assuming a perfect oracle.
2. Test the algorithm on synthetic datasets where the realizability assumption is violated but the new bias condition holds, comparing performance against realizability-based active learning methods.
3. Analyze the computational complexity of the improper learning approach empirically, measuring the overhead of model aggregation across epochs.