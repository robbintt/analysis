---
ver: rpa2
title: 'DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses'
arxiv_id: '2601.16473'
source_url: https://arxiv.org/abs/2601.16473
tags:
- image
- demark
- watermarking
- schemes
- watermark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DEMARK, a query-free black-box attack framework
  that targets defensive image watermarking schemes for deepfakes. DEMARK exploits
  latent-space vulnerabilities in encoder-decoder watermarking models through a compressive
  sensing-based sparsification process, suppressing watermark signals while preserving
  perceptual and structural realism appropriate for deepfakes.
---

# DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses

## Quick Facts
- arXiv ID: 2601.16473
- Source URL: https://arxiv.org/abs/2601.16473
- Reference count: 40
- Key outcome: DEMARK achieves 32.9% average watermark detection accuracy across eight state-of-the-art schemes while maintaining natural visual quality through compressive sensing-based latent sparsification

## Executive Summary
DEMARK presents a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes by exploiting latent-space vulnerabilities in encoder-decoder watermarking models. The attack uses compressive sensing-based sparsification to suppress watermark signals while preserving perceptual and structural realism appropriate for deepfakes. DEMARK transforms watermarked images into sparse latent representations through a CNN-based sparse encoder, achieving significant watermark removal across eight state-of-the-art watermarking schemes without requiring access to the watermarking models or detection algorithms.

## Method Summary
DEMARK employs a compressive sensing-based approach to attack encoder-decoder watermarking schemes by enforcing sparsity in latent representations. The framework consists of a sparse encoder (T_CNN) and image reconstruction network (R_CNN) trained together using a combined loss function that includes sparsity regularization (L1 norm on latent representations) and structural-perceptual alignment (SSIM + LPIPS). This causes a dispersal effect characterized by Sparsity Change, Intensity Redistribution, and Positional Redistribution, which disrupts watermark signals while preserving essential image features. The attack operates in a query-free black-box manner, requiring only access to watermarked images rather than the watermarking models themselves.

## Key Results
- Reduces watermark detection accuracy from 100% to 32.9% average across eight state-of-the-art watermarking schemes
- Maintains natural visual quality with SSIM=0.83-0.88 and LPIPS=0.06-0.07, comparable to baseline methods
- Improves computational efficiency by 1.3×-5.7× and reduces memory usage by 2.2×-14.9× over alternative approaches
- Successfully transfers across different watermarking architectures without requiring scheme-specific knowledge

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enforcing sparsity in latent representations disrupts watermark signals through a dispersal effect while preserving essential image features.
- **Mechanism:** A CNN-based sparse encoder (T_CNN) transforms watermarked images into sparse latent representations Z using L1-regularized loss (L_SEL = ||Z||_1). This induces three measurable effects: Sparsity Change (SC) reduces the density of significant coefficients; Intensity Redistribution (IR) alters energy distribution toward uniformity; Positional Redistribution (PR) shifts non-zero element positions via Wasserstein distance. Collectively, these disperse watermark-bearing latent patterns that detectors rely on for extraction.
- **Core assumption:** Watermarks in encoder–decoder schemes depend on dense latent activation patterns; essential image semantics can survive aggressive sparsification.
- **Evidence anchors:**
  - [abstract] "DEMARK exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism"
  - [section 4.2.1] Equations (3–5) formalize SC, IR, PR; Figure 1 empirically validates dispersal across all eight watermarking schemes
  - [corpus] Weak direct corpus support—neighbor papers focus on LLM/code watermarks or detection benchmarks rather than image watermark attacks; no comparative mechanism validation available
- **Break condition:** If watermarking schemes embed signals in highly sparse latent bases (e.g., wavelet coefficients with minimal overlap), dispersal may not sufficiently degrade extraction; if image semantics require dense latent features, reconstruction quality collapses.

### Mechanism 2
- **Claim:** Coupling pixel-level structural constraints with feature-level perceptual alignment preserves visual fidelity during latent sparsification.
- **Mechanism:** A structural-perceptual loss (L_SPL = L_SSIM + L_LPIPS) co-trains with sparse encoding loss. SSIM enforces luminance/contrast/covariance consistency at the pixel level; LPIPS compares deep feature maps (e.g., AlexNet activations) across layers. The combined loss (L = α·L_SEL + β·L_SPL, with α=10, β=0.1) creates a gradient conflict: sparsity pushes latent values toward zero while reconstruction pulls perceptual features toward original distributions. This tension preferentially preserves semantically salient features while allowing watermark-carrying redundancies to collapse.
- **Core assumption:** Watermark patterns and semantic image content occupy separable regions in latent space; SSIM+LPIPS jointly capture human-perceived quality.
- **Evidence anchors:**
  - [abstract] "suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes"
  - [section 4.2.2] Equations (6–10) define L_SPL components; Table 4 shows DEMARK achieves SSIM=0.83–0.88 and LPIPS=0.06–0.07, comparable to RegenVAE
  - [corpus] No corpus papers validate the SSIM+LPIPS combination for watermark attacks specifically
- **Break condition:** If watermarks are embedded in perceptually critical features (low-frequency structural components), L_SPL may preserve them inadvertently; if α/β ratios are mis tuned, either attack fails (α too low) or image quality degrades (α too high, β too low).

### Mechanism 3
- **Claim:** Query-free black-box transfer succeeds because dispersal targets generic latent-space structure common across encoder–decoder watermarking architectures.
- **Mechanism:** DEMARK trains T_CNN and R_CNN on generic image datasets (OpenImage, COCO) without access to watermarking models or detectors. The attack transfers because: (1) post-processing schemes share encoder E(x,m) → z patterns where watermark m fuses with image features; (2) in-processing schemes embed during generation but still produce latent representations with similar density properties. Sparsification exploits this architectural commonality rather than scheme-specific parameters, enabling cross-scheme transfer without querying.
- **Core assumption:** Encoder–decoder watermarking schemes produce latent representations with exploitable redundancy patterns regardless of training specifics; detectors re-encode images into comparable latent spaces for extraction.
- **Evidence anchors:**
  - [abstract] "query-free black-box attack framework" achieving "across eight state-of-the-art watermarking schemes"
  - [section 4.1] "adversaries have access to watermarked images but lack knowledge of watermarking models (black-box) and cannot query GenAI providers' detection algorithms (query-free)"
  - [corpus] UnMarker paper also claims universal attack but requires different assumptions; no direct comparison of transfer mechanisms available
- **Break condition:** If watermarking schemes use fundamentally different latent encoding paradigms (e.g., non-encoder–decoder, frequency-domain-only), transfer degrades; if providers randomize latent structures per-image, generic sparsification patterns fail.

## Foundational Learning

- **Compressive Sensing Theory:**
  - Why needed here: DEMARK's core mechanism reformulates classical ICS (solving min ||Z||_1 s.t. y = ΦΨZ) as learnable sparse encoding; understanding sparsity, measurement matrices, and reconstruction bounds explains why dispersal works.
  - Quick check question: Given measurement y ∈ R^M and signal x ∈ R^N where M ≪ N, what constraint enables unique sparse recovery?

- **Encoder–Decoder Watermarking Architectures:**
  - Why needed here: The attack targets latent representation z = E(x, m) where watermarks fuse with image features; understanding post-processing vs. in-processing pipelines clarifies attack surface.
  - Quick check question: In a post-processing scheme, what three components (E, D, W) process the watermarked image x_m, and which holds the latent representation?

- **Image Quality Metrics (SSIM, LPIPS, PSNR, FID):**
  - Why needed here: Evaluating attack success requires distinguishing watermark suppression (BitAcc, DetectAcc) from image degradation (PSNR↑, SSIM↑, FID↓, LPIPS↓); these metrics capture different quality aspects.
  - Quick check question: Which metric measures pixel-level structural consistency vs. feature-level perceptual similarity, and why might they conflict?

## Architecture Onboarding

- **Component map:** Watermarked Image x_m -> [Sparse Encoder T_CNN] -> [Image Reconstruction R_CNN] -> Attacked Image x̃
- **Critical path:** Sparse encoding loss (Equation 2) -> dispersal effect (SC/IR/PR, Equations 3–5) -> watermark suppression. If sparsity enforcement fails (α too low or gradient vanishes), attack effectiveness drops sharply.
- **Design tradeoffs:**
  - **α (sparsity weight) vs. image quality:** Higher α -> stronger attack (Figure 4) but degraded PSNR/SSIM/FID (Table 11); α=10 empirically balances.
  - **SSIM vs. LPIPS in L_SPL:** SSIM-only smooths but color-shifts; LPIPS-only preserves texture but distorts structure (Figure 5); both required.
  - **Architecture depth:** 4 blocks chosen for efficiency (2.2×-14.9× memory reduction vs. RegenVAE/RegenDM); deeper may improve attack but increases cost.
- **Failure signatures:**
  - **Insufficient sparsity:** BitAcc > 80%, DetectAcc > 70%; SLR distribution concentrated near zero (Figure 3, α=0).
  - **Excessive sparsity:** FID > 100, visible artifacts (Table 11, α=20); watermark removal succeeds but image unusable.
  - **Loss imbalance:** If β >> α, reconstruction preserves watermarks; if α >> β, output resembles compressive sensing artifacts.
- **First 3 experiments:**
  1. **Validate dispersal effect:** Watermark 100 images using MBRS; compute SC, IR, PR before/after T_CNN (Equations 3–5, τ=0.02); confirm reduction in significant coefficient density and Wasserstein distance increase.
  2. **Sweep α parameter:** Train DEMARK with α ∈ {0, 5, 10, 15, 20} on OpenImage subset; plot BitAcc/DetectAcc vs. PSNR/SSIM/FID; verify α=10 as knee point.
  3. **Cross-scheme transfer test:** Train on images watermarked by one scheme (e.g., CIN); test attack effectiveness on unseen schemes (e.g., VINE-B, SS); measure transfer degradation vs. scheme-specific training.

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends critically on encoder-decoder watermarking schemes producing latent representations with exploitable redundancy; future architectures using different paradigms may resist the attack
- Empirical α=10 weight was chosen based on validation datasets that may not generalize to all deepfake content domains
- SSIM+LPIPS combination, while effective for standard images, may not optimally preserve quality for all deepfake generation styles

## Confidence
- **Mechanism 1 (Dispersal through sparsity):** High confidence—empirically validated through measurable SC/IR/PR effects across eight watermarking schemes with clear quantitative improvements
- **Mechanism 2 (Structural-perceptual preservation):** Medium confidence—component metrics (SSIM, LPIPS) are well-established, but the specific combination's optimality for watermark attack scenarios lacks comparative validation
- **Mechanism 3 (Query-free transfer):** Medium confidence—transfer works across eight schemes, but the exact architectural commonalities enabling this are not fully characterized; unknown if it generalizes to non-encoder watermarking

## Next Checks
1. **Transfer robustness test across watermarking paradigms:** Validate DEMARK against non-encoder watermarking schemes (e.g., frequency-domain, spread-spectrum) and architectures using different latent space definitions to quantify transfer limitations and identify architectural boundaries.

2. **Dynamic weight adaptation experiment:** Implement adaptive α tuning during attack execution based on real-time quality metrics and watermark detection feedback, testing whether context-aware weight adjustment outperforms fixed α=10 across diverse deepfake content.

3. **Perceptual quality in deepfake domain:** Evaluate DEMARK's output using deepfake-specific quality metrics (e.g., face consistency, temporal coherence for video sequences) beyond standard image metrics, as the structural-perceptual loss may not capture deepfake generation artifacts.