---
ver: rpa2
title: 'Quantum Machine Learning for Image Classification: A Hybrid Model of Residual
  Network with Quantum Support Vector Machine'
arxiv_id: '2510.23659'
source_url: https://arxiv.org/abs/2510.23659
tags:
- quantum
- learning
- classification
- feature
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a hybrid quantum-classical model combining
  ResNet-50 feature extraction with Quantum Support Vector Machines (QSVM) for potato
  disease classification. The model uses ResNet-50 to extract deep features from RGB
  images of potato diseases, followed by dimensionality reduction using PCA and classification
  using QSVM with various quantum feature maps (ZZ, Z, and Pauli-X).
---

# Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine

## Quick Facts
- **arXiv ID**: 2510.23659
- **Source URL**: https://arxiv.org/abs/2510.23659
- **Reference count**: 28
- **Primary result**: Hybrid ResNet-50 + QSVM achieves 99.23% accuracy on potato disease classification, outperforming classical SVM (56.58%) and Random Forest (97.66%)

## Executive Summary
This study presents a hybrid quantum-classical model combining ResNet-50 feature extraction with Quantum Support Vector Machines (QSVM) for potato disease classification. The model uses ResNet-50 to extract deep features from RGB images of potato diseases, followed by dimensionality reduction using PCA and classification using QSVM with various quantum feature maps (ZZ, Z, and Pauli-X). The proposed approach was evaluated on a dataset containing healthy and soft rot disease potato images using 5-fold stratified cross-validation. Results show that the Z-feature map-based QSVM achieved an accuracy of 99.23%, outperforming classical models including SVM (56.58%) and Random Forest (97.66%). The study demonstrates the potential of integrating quantum computing into image classification tasks and provides a promising solution for disease detection through hybrid quantum-classical modeling.

## Method Summary
The method employs transfer learning with pre-trained ResNet-50 to extract 2048-dimensional feature vectors from potato disease images, followed by PCA dimensionality reduction to 3-9 components and MinMax scaling to [-1, 1]. These features are then mapped to quantum states using different feature maps (Z, ZZ, Pauli-X) for quantum kernel computation. The QSVM classifier uses fidelity-based quantum kernels for final classification. The pipeline was implemented in Qiskit on Google Colab CPU, with classical baselines including SVM with RBF kernel and Random Forest for comparison.

## Key Results
- Z-feature map QSVM achieved 99.23% accuracy across all PCA configurations
- Pauli-X feature map consistently failed at 56.58% accuracy, matching poorly-tuned classical SVM
- ZZ-feature map performance degraded from 96.15% (3 components) to 66.62% (9 components)
- Classical Random Forest achieved 97.66% accuracy as the best classical baseline

## Why This Works (Mechanism)

### Mechanism 1: Transfer Learning via Pre-trained Convolutional Features
Pre-trained ResNet-50 provides effective feature representations for potato disease images despite being trained on ImageNet. The final pooling layer outputs a 2048-dimensional vector capturing structural, textural, and contextual features. These transfer because low-level visual primitives (edges, textures) generalize across domains. Disease-relevant visual features overlap sufficiently with ImageNet-learned features.

### Mechanism 2: Dimensionality Reduction for Quantum Feasibility
PCA reduction to 3-9 components enables quantum processing while preserving discriminative information. PCA projects high-dimensional features onto orthogonal axes maximizing variance. For QSVM, this reduces qubit requirements and circuit depth. MinMaxScaler normalizes to [-1, 1], ensuring compatibility with quantum rotation gates.

### Mechanism 3: Quantum Feature Map Induces Kernel Geometry
The Z-feature map outperforms ZZ and Pauli-X because it independently encodes features without entanglement, matching the data structure. The Z-feature map applies single-qubit rotations |φ(x)⟩ = R_Z(x)|0⟩, mapping each PCA component to independent rotation angles. The quantum kernel K(x,x') = |⟨φ(x)|φ(x')⟩|² measures state fidelity. Without entanglement, this approximates a classical kernel on normalized features but with quantum-induced nonlinearity.

## Foundational Learning

- **Concept: Support Vector Machines and Kernel Methods**
  - Why needed: QSVM replaces classical kernel with quantum kernel. Understanding kernel trick, margin maximization, and dual formulation is prerequisite.
  - Quick check: Given x₁ and x₂, explain how K(x₁, x₂) = ⟨φ(x₁), φ(x₂)⟩ avoids explicit computation in high-dimensional space.

- **Concept: Quantum Feature Maps and State Encoding**
  - Why needed: Core innovation maps classical data to quantum states via Z, ZZ, and Pauli-X rotations. Understanding unitary operations and fidelity is essential.
  - Quick check: Applying R_Z(θ) to |0⟩ produces what state? How does measurement collapse relate to classification?

- **Concept: Transfer Learning with CNNs**
  - Why needed: ResNet-50's frozen weights extract features without training. Understanding convolution hierarchies explains why ImageNet features transfer.
  - Quick check: Why does removing classification head from ResNet-50 produce 2048-dim vector rather than class prediction?

## Architecture Onboarding

- **Component map**: Input Image (224×224×3) → ResNet-50 (pre-trained, frozen, no top) → GlobalAveragePooling → 2048-dim vector → PCA (3/6/9 components) → MinMaxScaler → [-1, 1] → Quantum Feature Map (Z/ZZ/Pauli-X) → Quantum States → Fidelity Quantum Kernel Matrix → QSVC Classifier → Prediction (Healthy / Soft Rot)

- **Critical path**: ResNet extraction → PCA dimensionality → Feature map selection. Z-feature map with 3-9 PCA components is validated configuration.

- **Design tradeoffs**:
  | Choice | Pros | Cons |
  |--------|------|------|
  | More PCA components | More information preserved | More qubits, potential overfitting, ZZ map degrades |
  | Z-feature map | Simple, robust, highest accuracy | No entanglement, may miss feature interactions |
  | ZZ-feature map | Captures feature correlations | Performance degrades with more components (0.6662 at 9) |
  | Pauli-X | Alternative encoding | Consistently fails (0.5658) in this task |

- **Failure signatures**:
  - Accuracy ~56.5%: Pauli-X feature map used—rotation axis mismatched with data distribution
  - Accuracy drops with more PCA components (ZZ map): Over-entanglement introduces noise
  - Classical SVM at 56.58%: Likely wrong kernel or hyperparameters; RBF kernel may need tuning

- **First 3 experiments**:
  1. Reproduce Z-feature map baseline: Load ResNet-50 (ImageNet weights), extract features from potato images, apply PCA(3), MinMaxScaler, Z-feature map QSVM. Confirm ~99% accuracy via 5-fold CV.
  2. Ablate PCA components: Test PCA(2, 4, 6, 8, 10) with Z-map to find minimum viable dimensionality. Plot accuracy vs. components.
  3. Feature map sweep with controlled entanglement: Compare Z (no entanglement), ZZ (pairwise), and custom maps with varying entanglement depth.

## Open Questions the Paper Calls Out

### Open Question 1
Would alternative quantum feature maps (e.g., PauliZ) or variational quantum circuits with trainable parameters outperform the fixed Z-feature map on this classification task? Authors explicitly call for exploring alternative quantum feature maps and quantum computing strategies. Only three fixed feature maps (ZZ, Z, PauliX) were tested; no parameterized or trainable quantum circuits were explored.

### Open Question 2
Will the reported QSVM performance gains persist when deployed on actual quantum hardware, or are they artifacts of noise-free simulation? Authors state the need to assess scalability by transitioning from cloud-based simulations to actual quantum hardware. All experiments used classical simulators; NISQ devices introduce decoherence and gate errors that may degrade quantum kernel fidelity.

### Open Question 3
Why does the PauliX feature map consistently fail (56.58% accuracy across all PCA configurations), matching the poorly-tuned classical SVM baseline? The PauliX feature map yields identical accuracy to classical SVM in all configurations while Z-feature map achieves 99.23%. This suggests either implementation issues, data encoding incompatibility, or fundamental mismatch between PauliX rotations and the feature distribution.

## Limitations
- Small dataset size (495 images) raises concerns about overfitting, particularly since QSVM can memorize small training sets
- Dramatic QSVM accuracy advantage (99.23% vs 56.58% for classical SVM) may be due to implementation differences rather than genuine quantum advantage
- No hyperparameter tuning comparison between classical SVM and QSVM baselines
- Pauli-X failure mode lacks deep analysis to determine if it's true incompatibility or hyperparameter issue

## Confidence

- **High confidence**: ResNet-50 transfer learning mechanism, PCA dimensionality reduction for quantum feasibility, and the general hybrid architecture are well-established and reproducible.
- **Medium confidence**: The Z-feature map superiority claim is supported by experimental results but lacks theoretical justification for why entanglement degrades performance with more components.
- **Low confidence**: The claim of quantum advantage over classical SVM is questionable given the lack of hyperparameter comparison and small dataset size.

## Next Checks

1. **Hyperparameter parity test**: Reproduce the experiment with SVM tuned for regularization parameter C and compare against QSVM with identical preprocessing and cross-validation.
2. **Dataset size sensitivity analysis**: Systematically reduce training set size to identify the point where QSVM accuracy drops below classical SVM, testing the overfitting hypothesis.
3. **Feature map expressivity evaluation**: Measure quantum kernel matrix distances between Z, ZZ, and Pauli-X maps on the PCA-reduced data to quantify their representational differences and identify the source of Pauli-X failure.