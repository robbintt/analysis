---
ver: rpa2
title: 'MCFCN: Multi-View Clustering via a Fusion-Consensus Graph Convolutional Network'
arxiv_id: '2511.05554'
source_url: https://arxiv.org/abs/2511.05554
tags:
- clustering
- graph
- multi-view
- feature
- view
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes MCFCN, a Multi-View Clustering method via Fusion-Consensus
  Graph Convolutional Network. It addresses limitations in existing multi-view clustering
  methods that focus on consensus representation learning while neglecting the inherent
  topological structure of data, and methods based on Multi-view Graph Refinement
  (MGRC) that have issues like insufficient consideration of cross-view consistency,
  difficulty in handling hard-to-distinguish samples, and disjointed optimization
  processes.
---

# MCFCN: Multi-View Clustering via a Fusion-Consensus Graph Convolutional Network

## Quick Facts
- arXiv ID: 2511.05554
- Source URL: https://arxiv.org/abs/2511.05554
- Authors: Chenping Pei, Fadi Dornaika, Jingjun Bi
- Reference count: 40
- This paper proposes MCFCN, a Multi-View Clustering method via Fusion-Consensus Graph Convolutional Network. It addresses limitations in existing multi-view clustering methods that focus on consensus representation learning while neglecting the inherent topological structure of data, and methods based on Multi-view Graph Refinement (MGRC) that have issues like insufficient consideration of cross-view consistency, difficulty in handling hard-to-distinguish samples, and disjointed optimization processes. MCFCN learns the consensus graph of multi-view data in an end-to-end manner using a view feature fusion model and a Unified Graph Structure Adapter (UGA). It designs Similarity Matrix Alignment Loss (SMAL) and Feature Representation Alignment Loss (FRAL) to guide the optimization of view-specific graphs and preserve cross-view topological consistency. The method achieves state-of-the-art performance on eight multi-view benchmark datasets, with significant improvements in clustering accuracy compared to other methods. For example, on the BBCSport dataset, MCFCN achieved an accuracy of 0.9651 compared to 0.9632 for the second-best method.

## Executive Summary
MCFCN addresses key limitations in multi-view clustering by learning consensus graphs in an end-to-end differentiable manner, rather than relying on non-differentiable kNN preprocessing or disjointed optimization processes. The method introduces a Unified Graph Structure Adapter that enables joint optimization of graph structure and node representations, while SMAL and FRAL losses enforce cross-view topological consistency. Through extensive experiments on eight benchmark datasets, MCFCN achieves state-of-the-art clustering accuracy, demonstrating 1.5-2.5% improvements over previous methods like Multi-Graph Clustering with Graph Convolution Networks and Spectral Clustering-based Multiple Kernel Learning.

## Method Summary
MCFCN learns consensus graph structures for multi-view clustering through a unified framework that integrates feature fusion, graph learning, and consensus optimization. The method first projects and fuses features from multiple views into a shared space, then uses a Unified Graph Structure Adapter to learn a consensus adjacency matrix in a differentiable manner without kNN preprocessing. A Graph Convolutional Network extracts hierarchical representations from this consensus graph, while Similarity Matrix Alignment Loss (SMAL) and Feature Representation Alignment Loss (FRAL) ensure cross-view consistency. The final clustering is performed on concatenated multi-level GCN representations using kernel k-means in a learned feature space.

## Key Results
- Achieved 0.9651 accuracy on BBCSport dataset, outperforming second-best method (0.9632)
- Showed 1.5-2.5% improvements over state-of-the-art methods across eight benchmark datasets
- Ablation studies demonstrated that adding SMAL improved accuracy from 0.6449 to 0.8106 on 3Sources dataset, with FRAL providing additional improvement to 0.8382

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Unified Graph Structure Adapter enables end-to-end differentiable graph learning, avoiding the non-differentiable kNN bottleneck in prior MVC methods.
- **Mechanism:** Instead of using kNN to construct a static graph (non-differentiable due to sorting), UGA computes a fused similarity matrix $S_f = \sigma(F_f F_f^T)$, applies a binary mask for sparsification based on top-k values per row, then symmetrizes. The resulting adjacency matrix $A_f$ is differentiable w.r.t. feature representations, enabling joint optimization with the GCN.
- **Core assumption:** The fused features $F_f$ capture meaningful cross-view similarity; sparsification via top-k mask preserves relevant edges without breaking gradient flow through soft similarity computation.
- **Evidence anchors:**
  - [Section 3.3]: "In our method, the initial matrix is converted to a mask... The sparse similarity matrix is computed: $\dot{S}_f = S_f \odot M$"
  - [Section 3.3]: "kNN sorting algorithm being non-differentiable in deep neural network contexts. This constraint compels existing GNN-based approaches to operate in a two-stage manner."
  - [corpus]: Related work (MoEGCL, SURER) confirms graph structure learning is active in MVC but lacks consensus-driven alignment mechanisms.
- **Break condition:** If $k$ is set too small (<5), insufficient structural information is preserved; if too large (>30), noise dominates. Parameter sensitivity analysis (Figure 8) shows performance degrades at extremes.

### Mechanism 2
- **Claim:** Similarity Matrix Alignment Loss (SMAL) and Feature Representation Alignment Loss (FRAL) jointly enforce cross-view topological consistency and preserve original feature information.
- **Mechanism:** SMAL aligns the consensus similarity $HH^T$ with both view-specific similarities $F_v F_v^T$ and fused similarity $\sigma(F_f F_f^T)$. FRAL ensures transformed features retain original feature relationships by minimizing $\|X_v(X_v)^T - S_v\|^2$. This dual alignment prevents the consensus representation from drifting away from view-specific structures.
- **Core assumption:** Views represent different perspectives of the same underlying object; their graph structures should be "roughly the same" (explicit hypothesis in Section 3.3).
- **Evidence anchors:**
  - [Section 3.5.3]: "$L_{s-alignment} = \sum_{v=1}^{V}(\|HH^T - F_v(F_v)^T\|^2 + \|\sigma(F_f F_f^T) - F_v(F_v)^T\|^2)$"
  - [Section 5.2, Tables 4-6]: Ablation shows adding SMAL after UGA improves ACC from 0.6449 to 0.8106 on 3Sources; adding FRAL further improves to 0.8382.
  - [corpus]: Corpus papers on contrastive MVC (Global-Graph Guided, RAC-DMVC) similarly use alignment objectives but lack explicit similarity matrix alignment.
- **Break condition:** If $\lambda_2$ (SMAL weight) or $\lambda_3$ (FRAL weight) are too low, views diverge; if too high, the model over-constrains and cannot learn discriminative representations. Sensitivity analysis (Figure 6-7) shows stable performance in [0.1, 0.9] range.

### Mechanism 3
- **Claim:** Multi-level feature concatenation ($H_F = [H_1, H_2, H]$) captures both local neighborhood structure and global cluster information.
- **Mechanism:** The GCN produces intermediate representations $H_1$ (layer 1, 16-dim), $H_2$ (layer 2, 16-dim), and orthogonalized output $H$ (C-dim). $H_1$ encodes immediate neighborhood; $H_2$ encodes 2-hop neighborhood; $H$ encodes global cluster assignment. Concatenating all three before K-means leverages multi-scale information.
- **Core assumption:** Different GCN layers capture hierarchically abstract structural information useful for clustering.
- **Evidence anchors:**
  - [Section 3.5.6]: "By integrating $H_1$, $H_2$, and $H$, we construct the final concatenated representation $H_F$ to exploit different neighborhood information and global cluster structure knowledge."
  - [Section 3.5.6]: "each representation contains information pertaining to a specific neighborhood set."
  - [corpus]: Weak direct evidence in corpus; this is a standard GCN design pattern.
- **Break condition:** Assumption: If hidden dimensions are too small (<8), intermediate representations lose discriminative power; if too large (>64), overfitting may occur. Paper uses $h_1 = h_2 = 16$ without extensive justification.

## Foundational Learning

- **Concept: Graph Convolutional Networks (GCN)**
  - Why needed here: Core feature extractor; propagates information across learned graph structure. Understanding message passing is essential for debugging representation quality.
  - Quick check question: Can you explain why $\hat{A}_f = \hat{D}^{-1/2}(A_f + I)\hat{D}^{-1/2}$ is used instead of raw $A_f$?

- **Concept: Kernel K-means Clustering**
  - Why needed here: The deep kernel k-means loss (Eq. 16) drives cluster formation in a learned kernel space, enabling non-linear cluster boundaries.
  - Quick check question: How does the kernel trick allow k-means to detect linearly inseparable clusters?

- **Concept: Spectral Clustering and Laplacian Regularization**
  - Why needed here: $L_{spectral} = \text{trace}(H^T L_f H)$ enforces smoothness of node representations on the graph, a core inductive bias.
  - Quick check question: What property does the Laplacian matrix $L_f$ encode, and why does minimizing $\text{trace}(H^T L H)$ encourage connected nodes to have similar representations?

## Architecture Onboarding

- **Component map:**
  1. Input: Multi-view data $\{X^v\}_{v=1}^V$ with dimensions $d_v$
  2. Feature Fusion: Linear projection $U_v$ → L2 norm → Concatenate → $F_f \in \mathbb{R}^{N \times (d \times V)}$
  3. UGA: Compute $S_f = \sigma(F_f F_f^T)$ → Top-k mask → Symmetrize → $A_f$
  4. GCN: Two GCN layers (hidden=16) + Linear layer (output=C) → Orthogonalization → $H$
  5. Loss Computation: Five losses combined with weights $\beta, \lambda_1, \lambda_2, \lambda_3$
  6. Clustering: Concatenate $[H_1, H_2, H]$ → K-means → Final labels

- **Critical path:** Feature fusion quality directly affects UGA graph quality, which affects GCN propagation, which affects all downstream losses. The SMAL/FRAL losses provide the feedback signal to align views—without these, UGA produces inconsistent graphs.

- **Design tradeoffs:**
  - Hidden dimension (16): Small for efficiency, but may limit expressiveness on complex datasets
  - K=10 for sparsification: Balances graph density vs. noise; may need tuning per dataset
  - Orthogonalization of $H$: Ensures cluster indicators are well-separated but adds computational cost (Cholesky decomposition)

- **Failure signatures:**
  - ACC plateaus early (~0.3-0.4): Check if $\lambda_2$ is too low; SMAL not enforcing alignment
  - Graph becomes fully connected (no block structure): $k$ too large or features not discriminative
  - NaN loss: Check for numerical instability in kernel computation (Eq. 17-18); $\sigma^2$ may need adjustment

- **First 3 experiments:**
  1. Reproduce BBCSport results (ACC=0.9651) with default hyperparameters. This is the cleanest result with largest margin over baselines.
  2. Ablate SMAL and FRAL separately on 3Sources (smallest dataset, fastest iteration). Verify the 0.6449 → 0.8106 → 0.8382 progression.
  3. Sweep $k \in \{5, 10, 15, 20, 25\}$ on Caltech101-7 to understand graph density sensitivity on a mid-scale image dataset with 7 clusters.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited ablation on hyperparameters: K=10 for graph sparsification and hidden dimension=16 are used without systematic sensitivity analysis. The paper shows Figure 8 for k parameter, but only on one dataset.
- No comparison with self-supervised contrastive methods on incomplete/noisy views: The experiments use complete multi-view datasets, but the paper claims to address limitations of MGRC methods with "difficulty in handling hard-to-distinguish samples" without testing on corrupted or incomplete views.
- Orthogonalization computational cost: The paper uses Cholesky decomposition for feature orthogonalization (Section 3.5.6) but doesn't discuss scalability implications for large datasets.

## Confidence
- High confidence in the SMAL/FRAL alignment mechanism effectiveness (proven by ablation studies showing consistent improvements)
- Medium confidence in the Unified Graph Structure Adapter's differentiability advantage (theoretical but not extensively validated against alternatives)
- Medium confidence in multi-level feature concatenation benefits (standard GCN design pattern, but limited ablation)

## Next Checks
1. **Graph sparsification sensitivity**: Systematically test k values (5-25) across all 8 benchmark datasets to determine if the chosen k=10 is universally optimal or dataset-dependent.
2. **Incomplete view robustness**: Evaluate MCFCN performance when 10-30% of views are randomly removed per sample to validate claims about handling hard-to-distinguish samples.
3. **Scalability test**: Measure training time and clustering accuracy on a large-scale dataset (e.g., 100k+ samples) to assess the orthogonalization bottleneck and overall computational efficiency.