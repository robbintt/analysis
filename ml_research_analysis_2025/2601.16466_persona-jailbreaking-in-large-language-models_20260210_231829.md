---
ver: rpa2
title: Persona Jailbreaking in Large Language Models
arxiv_id: '2601.16466'
source_url: https://arxiv.org/abs/2601.16466
tags:
- persona
- phish
- trait
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces persona editing, a new adversarial task targeting
  Large Language Models (LLMs) in domains like mental health, tutoring, and customer
  support where consistent personality traits are critical. The authors propose PHISH,
  a black-box framework that steers an LLM's personality by embedding semantically
  loaded cues in user inputs to gradually induce reverse personas without modifying
  model parameters or accessing internal states.
---

# Persona Jailbreaking in Large Language Models

## Quick Facts
- arXiv ID: 2601.16466
- Source URL: https://arxiv.org/abs/2601.16466
- Reference count: 26
- Persona manipulation success (STIR) up to 95.58% across eight LLMs without modifying model parameters

## Executive Summary
This paper introduces persona editing, a new adversarial task targeting Large Language Models (LLMs) in domains like mental health, tutoring, and customer support where consistent personality traits are critical. The authors propose PHISH, a black-box framework that steers an LLM's personality by embedding semantically loaded cues in user inputs to gradually induce reverse personas without modifying model parameters or accessing internal states. Across three benchmarks and eight LLMs, PHISH achieves consistently higher persona manipulation success (STIR scores up to 95.58) than competitive baselines, especially in multi-turn settings. Evaluations in high-risk domains show reliable persona shifts, validated by both human and LLM-as-Judge assessments, while maintaining moderate reasoning performance. Guardrails offer only partial, brittle protection under sustained attack, highlighting the need for context-resilient persona control in LLMs.

## Method Summary
PHISH operates by embedding N QA-style pairs (100-150 demonstrations) as a single user message after persona induction system prompts. Questions are sampled from MPI-1k and aligned with psychometric constructs, with answers deterministically set to the inverse polarity of the target persona. The framework evaluates personality shifts using three personality benchmarks (BFI-44 items, MPI-120 items, ANTHR-8000 subset) and computes STIR scores measuring directional trait shifts. The method works in black-box settings without accessing model internals, making it applicable to API-only environments.

## Key Results
- PHISH achieves STIR scores up to 95.58% across eight LLMs, significantly outperforming baselines like SLIP and PFD
- Multi-turn settings amplify persona manipulation effects through cumulative inductive pressure, with STIR scores increasing as turns progress
- Guardrail defenses (CWD, ICD) show only partial protection, failing under sustained multi-turn attacks
- PHISH maintains reasoning performance with only 1-6 point accuracy drops on Math/GSM8K/CSQA benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM persona is not fixed in model weights but emerges contextually at inference, enabling manipulation through adversarial conversational history without accessing internals.
- Mechanism: Autoregressive decoding prioritizes coherence with prior context. By injecting semantically loaded QA pairs aligned with a target (inverse) persona, the model's generation progressively shifts to maintain consistency with the adversarial history.
- Core assumption: Persona expression is shaped more by context history than by fixed parametric representations.
- Evidence anchors: [abstract] "PHISH...embeds semantically loaded cues in user inputs to gradually induce reverse personas without modifying model parameters or accessing internal states"; [section 3] "We hypothesize that LLM persona is not fixed in model weights but emerges contextually at inference"; [corpus] No direct corpus evidence on adversarial persona steering mechanisms.

### Mechanism 2
- Claim: Multi-turn adversarial inputs amplify persona manipulation through cumulative inductive pressure.
- Mechanism: Each adversarial turn adds QA demonstrations consistent with the target persona, creating an implicit few-shot learning signal that strengthens trait expression in the intended direction—exploiting the same inductive mechanisms as in-context learning.
- Core assumption: LLMs treat accumulated conversational history as implicit training data for behavior adaptation.
- Evidence anchors: [abstract] "PHISH...exhibits stronger effects in multi-turn settings"; [section 5.3] "As the number of turns increases, the targeted dimension shifts more strongly in the opposite direction...This improvement suggests that PHISH exploits similar inductive mechanisms as in-context learning (ICL)"; [corpus] Corpus lacks direct evidence on multi-turn persona manipulation.

### Mechanism 3
- Claim: Targeting one Big Five trait induces collateral shifts in correlated traits due to entangled personality representations in LLMs.
- Mechanism: Pretraining data encodes personality correlations (e.g., high Agreeableness correlates with low Neuroticism). PHISH's targeted manipulation triggers these latent associations, causing non-target traits to shift in predictably correlated directions—often with amplified magnitudes compared to human populations.
- Core assumption: LLMs internalize trait correlations from training data, and these cannot be independently controlled via prompt-based manipulation.
- Evidence anchors: [abstract] "PHISH predictably shifts personas, triggers collateral changes in correlated traits"; [section 5.2] Table 2 shows O-E correlation at 0.94 (LLM) vs 0.43 (human theory), O-N at -0.96 vs -0.17; [corpus] No corpus papers address trait entanglement in LLM personality representations.

## Foundational Learning

- **Big Five (OCEAN) Personality Model**: Why needed here: PHISH operationalizes persona manipulation as steering traits on standardized OCEAN scales (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism). Understanding trait definitions and correlations is prerequisite for interpreting STIR scores and collateral effects. Quick check question: If a model's Agreeableness score drops, would you expect Neuroticism to increase or decrease based on typical trait correlations?

- **In-Context Learning (ICL) Mechanisms**: Why needed here: The paper explicitly frames PHISH as exploiting ICL-like inductive biases. Distinguishing PHISH from naive ICL (SLIP baseline fails) requires understanding how demonstration format, polarity, and trait-specificity drive implicit learning. Quick check question: Why does adding trait-relevant QA pairs with reverse-polarity answers shift persona, while adding trait adjectives alone does not?

- **Black-Box vs White-Box Adversarial Settings**: Why needed here: PHISH operates under inference-only, API-only constraints—no gradient access, no logits, no weight modification. This defines the threat model and explains methodological choices (why no gradient-based optimization). Quick check question: What information would a white-box attacker have that PHISH deliberately does not use?

## Architecture Onboarding

- **Component map**: Persona Induction -> Adversarial Injection -> Psychometric Evaluation -> STIR Computation
- **Critical path**: 1. Induce baseline persona via system prompt; 2. Inject adversarial QA with correct polarity + trait framing; 3. Run psychometric evaluation; 4. Compute STIR = (100/4|T|) × Σ max(0, d_i × (P_post,i - P_pre,i))
- **Design tradeoffs**: More demonstrations → higher STIR but consumes context window; including reasoning in QA pairs → marginal gain, omitted in main experiments due to context limits; targeting single vs. multiple traits → single-trait manipulation causes spillover but is more controllable
- **Failure signatures**: Guardrail collapse: CWD mitigates initially but fails beyond threshold; ICD delays but doesn't prevent escalation; Reasoning preservation: PHISH causes only 1-6 point accuracy drops on Math/GSM8K/CSQA—too small to serve as detection signal; Model-specific resistance: ChatHaruhi shows lower STIR due to grounding; Llama4-Maverick underperforms possibly due to weaker ICL
- **First 3 experiments**: 1. Ablation replication: Reproduce Figure 3 Settings 1-5 on a new model to confirm reverse-polarity + trait-specificity as necessary conditions; 2. Scaling curve: Plot STIR vs. number of demonstrations (10, 25, 50, 100, 150) to identify diminishing returns threshold; 3. Domain transfer: Apply PHISH to a high-risk domain (e.g., mental health scenario from Appendix D) and compare human vs. LLM-as-Judge agreement—expect r ≈ 0.87 per paper findings

## Open Questions the Paper Calls Out
- How can principled, adaptive defense mechanisms be developed to robustly prevent persona hijacking in multi-turn settings without relying on brittle prompt-level heuristics? (explicit: Conclusion states future work should focus on "designing adaptive defenses for sustained multi-turn attacks," and Section 5.6 demonstrates that current guardrails like In-Context Defense "remain brittle")
- Can white-box adversarial methods be effectively adapted for persona manipulation to exploit internal model states rather than relying solely on conversational history? (explicit: Limitations section identifies the exploration of "white-box adaptations" as a "promising direction for future work" since the current study is restricted to black-box, inference-only settings)
- Is it possible to develop persona induction techniques that disentangle the amplified inter-trait correlations observed in LLMs to allow for granular, independent control of single personality dimensions? (inferred: Section 5.2 notes that LLMs exhibit "stronger trait entanglement" than humans, creating "collateral changes" that necessitate "disentangled control")

## Limitations
- The paper lacks direct empirical evidence on the fundamental mechanism of how adversarial persona cues induce shifts—the proposed contextual emergence hypothesis remains unverified
- The MPI-1k question selection criteria and exact sampling procedure for constructing PHISH demonstrations are underspecified
- Human evaluation was limited to only 10 examples per domain, raising concerns about statistical power

## Confidence
- **High confidence**: Persona shifts are achievable through contextual manipulation without model access; Multi-turn accumulation amplifies effects via ICL-like mechanisms; Single-trait targeting causes collateral shifts in correlated traits; Guardrails provide only partial, brittle protection under sustained attack
- **Medium confidence**: LLMs encode overly coupled personality dimensions vs human populations; Reasoning preservation validates persona editing is not mere capability degradation; PFD defense effectiveness is marginal and implementation-dependent
- **Low confidence**: Exact mechanism of how QA pairs induce trait shifts at parameter level; Why Llama4-Maverick shows systematic underperformance; Optimal number of demonstrations for maximum STIR with minimal context cost

## Next Checks
1. **Mechanism validation experiment**: Conduct ablation studies varying demonstration format (QA vs. declarative statements), polarity (correct vs. neutral vs. random), and trait specificity (direct vs. indirect questions) across 3+ model families to identify necessary and sufficient conditions for STIR gains beyond baseline.
2. **Scaling and resistance study**: Systematically test PHISH across 5, 10, 25, 50, 100+ turns to map the full STIR curve, identify plateaus or resistance thresholds, and test whether different guardrail strategies (adversarial training, context window limits, persona grounding) show differential effectiveness at various attack intensities.
3. **Domain generalization and detection**: Apply PHISH to additional high-stakes domains (medical advice, legal consultation, financial planning) with expanded human evaluation (n=30+ per domain) and test whether STIR correlates with domain-specific harm potential. Simultaneously evaluate whether persona shifts can be detected through behavioral anomalies (tone drift, inconsistency patterns) rather than psychometric testing alone.