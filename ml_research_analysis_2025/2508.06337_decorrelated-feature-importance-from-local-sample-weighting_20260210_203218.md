---
ver: rpa2
title: Decorrelated feature importance from local sample weighting
arxiv_id: '2508.06337'
source_url: https://arxiv.org/abs/2508.06337
tags:
- feature
- features
- sample
- losaw
- importance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of feature importance (FI) scores
  being misleading when features are correlated in training data, often spreading
  importance across correlated features or even assigning higher importance to noise
  features than signal features. The core method, local sample weighting (losaw),
  decorrelates features during ML model training by applying sample weights that make
  target features independent of others.
---

# Decorrelated feature importance from local sample weighting

## Quick Facts
- arXiv ID: 2508.06337
- Source URL: https://arxiv.org/abs/2508.06337
- Reference count: 40
- Primary result: Local sample weighting (losaw) decorrelates features during training, achieving near-perfect separation of signal from noise features while maintaining comparable prediction accuracy

## Executive Summary
This paper addresses the problem of feature importance scores being misleading when features are correlated in training data, often spreading importance across correlated features or even assigning higher importance to noise features than signal features. The core method, local sample weighting (losaw), decorrelates features during ML model training by applying sample weights that make target features independent of others. This is integrated locally—at decision tree nodes for random forests and per mini-batch for neural networks. Losaw includes a tuning parameter (minimum effective sample size) that balances interpretability (better decorrelation) against prediction accuracy. Key results show losaw consistently improves FI scores under feature correlation, achieving near-perfect separation of signal from noise features in many cases, while maintaining comparable or slightly reduced in-distribution prediction accuracy and often improving out-of-distribution performance.

## Method Summary
The losaw method adapts inverse probability weighting from causal inference to create pseudo-populations where target features are independent of confounding features. For each feature, it computes stabilized propensity scores treating the feature as a "treatment" and remaining features as "confounders," then applies inverse propensity weights to decorrelate them. This is applied locally at decision tree nodes or per mini-batch in neural networks, using feature-specific weights rather than global decorrelation. A minimum effective sample size parameter controls the tradeoff between decorrelation quality and prediction accuracy through iterative weight clipping and redistribution.

## Key Results
- LosawRF and losawGD consistently improve feature importance scores under feature correlation, achieving near-perfect separation of signal from noise features
- In-distribution prediction accuracy is maintained at comparable or slightly reduced levels
- Out-of-distribution performance is often improved compared to baseline models
- The method effectively addresses the correlation-induced bias in standard feature importance measures

## Why This Works (Mechanism)

### Mechanism 1: Inverse Propensity Weighting Creates Pseudo-Population with Independent Features
Sample weights derived from stabilized propensity scores transform the observed data distribution into one where the target feature is independent of confounding features. By treating the target feature as a "treatment" variable and remaining features as "confounders," inverse propensity weighting creates a weighted pseudo-population where marginal association equals marginal effect.

### Mechanism 2: Local Application of Weights at Decision Points Prevents Correlation-Induced Bias
Applying losaw weights locally at tree nodes or mini-batches enables feature-specific decorrelation without requiring all features to be jointly independent. This local approach allows the ML algorithm to make feature-specific decisions based on decorrelated information at each decision point.

### Mechanism 3: Effective Sample Size Tuning Controls Interpretability-Prediction Tradeoff
The minimum relative effective sample size parameter provides a principled knob to trade decorrelation quality against sample utilization. Lower values improve feature independence and interpretability but may reduce prediction accuracy due to fewer effective samples.

## Foundational Learning

- **Inverse Probability Weighting (IPW) in Causal Inference**: Why needed - Losaw directly adapts IPW to create pseudo-populations where feature independence holds. Quick check: Given binary treatment T and confounder C, write the stabilized propensity score expression and explain why it normalizes P(T|C)/P(T).

- **Tree-Based Split Criteria (Gini/Entropy/MSE)**: Why needed - LosawRF modifies impurity calculations using weighted samples. Quick check: For regression tree node with samples {(yᵢ, xᵢ)}, write MSE impurity and compute impurity decrease for binary split at threshold t on feature p.

- **Saliency Maps for Neural Networks**: Why needed - LosawGD uses gradient-based saliency to determine which feature to decorrelate at each training step. Quick check: For neural network f(x; θ), compute saliency of input dimension p at sample x and explain what it measures.

## Architecture Onboarding

- Component map: Propensity Estimator -> Weight Constructor -> Weighted Split Selector (RF) / Weighted Mini-Batch Sampler (NN) -> FI Aggregator

- Critical path: 1) Fit propensity model for target feature, 2) Compute inverse propensity weights and clip to satisfy η constraint, 3) For each candidate feature, recompute and evaluate splits/updates, 4) Aggregate local decisions into global FI scores

- Design tradeoffs: Adjustment feature count Q (larger Q captures more confounders but increases cost), η selection (lower η improves interpretability but may reduce accuracy), global vs local decorrelation (local is feasible for many features, global is NP-hard)

- Failure signatures: High correlation + low sample size (very large weights on few samples), misspecified propensity model (residual correlation), η set too low (training instability)

- First 3 experiments: 1) Replicate Example 1.1 (MDI bias under heterogeneous correlation), 2) Sweep η to observe tradeoff curve, 3) Test propensity model sensitivity with different estimators

## Open Questions the Paper Calls Out
None

## Limitations
- Performance critically depends on propensity score model accuracy; misspecification leads to misleading importance scores
- Computational cost scales poorly with feature count and correlation structure, especially for discrete features
- η tuning parameter requires careful calibration per dataset to balance interpretability and prediction

## Confidence

- **High Confidence**: The mechanism of local sample weighting creating pseudo-populations with independent features and basic implementation are well-supported by theoretical proofs and experimental validation
- **Medium Confidence**: The interpretation-prediction tradeoff controlled by η is demonstrated empirically but relies on specific correlation structures
- **Low Confidence**: The claim that losaw consistently improves out-of-distribution performance is based on limited experimental scenarios

## Next Checks

1. **Propensity Model Robustness Test**: Evaluate losaw performance using increasingly complex propensity models (linear → RF → neural nets) on data with known non-linear confounding patterns

2. **Scalability Assessment**: Benchmark losaw on high-dimensional datasets (P > 100) to quantify practical limits of QNK² scaling behavior

3. **Distribution Shift Validation**: Systematically test losaw's OOD performance across multiple types of distribution shifts (covariate shift, concept drift, domain adaptation) beyond the single OOD experiment presented