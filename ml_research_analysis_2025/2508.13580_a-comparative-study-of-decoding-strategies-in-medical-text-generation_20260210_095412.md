---
ver: rpa2
title: A Comparative Study of Decoding Strategies in Medical Text Generation
arxiv_id: '2508.13580'
source_url: https://arxiv.org/abs/2508.13580
tags:
- decoding
- medical
- strategies
- tasks
- rouge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically evaluates 11 decoding strategies across
  5 medical tasks using both general-purpose and medical LLMs of varying sizes. Deterministic
  methods like beam search outperform stochastic ones, achieving higher scores at
  the cost of increased inference time.
---

# A Comparative Study of Decoding Strategies in Medical Text Generation

## Quick Facts
- **arXiv ID:** 2508.13580
- **Source URL:** https://arxiv.org/abs/2508.13580
- **Reference count:** 31
- **Primary result:** Deterministic decoding strategies outperform stochastic ones in medical text generation, with Beam Search achieving highest scores at increased inference cost.

## Executive Summary
This study systematically evaluates 11 decoding strategies across 5 medical tasks using both general-purpose and medical LLMs of varying sizes. Deterministic methods like beam search outperform stochastic ones, achieving higher scores at the cost of increased inference time. Larger models yield better performance but are not more robust to decoding strategy changes. Surprisingly, medical LLMs do not consistently outperform general models and are more sensitive to decoding choices. Evaluation metrics show varying agreement, with MAUVE being particularly sensitive to decoding strategy. These findings highlight the critical role of decoding strategy selection in medical applications, where it can sometimes matter as much as model choice.

## Method Summary
The study compares 11 decoding strategies (Greedy, Beam Search, Diverse BS, Contrastive Search, DoLa, Temperature, Top-p, Top-k, Min-p, Eta, Typical sampling) across 5 medical tasks using 4 LLMs ranging from 7B to 14B parameters. Datasets include 100 samples each from UFAL Medical Corpus (German-English translation), Pubmed-summarization, medalpaca/medical_meadow_medical_flashcards (QA), Healthbench (dialogue), and ROCOv2 (image captioning). Evaluation uses ROUGE, BERTScore, BLEU (for translation), MAUVE (for dialogue/QA), and inference time metrics. Statistical analysis employs Friedman test and Wilcoxon signed-rank with Holm correction. Hyperparameters were tuned within specified ranges for each strategy.

## Key Results
- Deterministic strategies (Beam Search) outperform stochastic ones, with beam search achieving highest scores while top-k and eta sampling perform worst
- Medical LLMs show higher sensitivity to decoding choices than general-purpose models, despite not consistently outperforming them
- Slower decoding methods correlate with better output quality but incur higher inference latency
- MAUVE metric shows high sensitivity to decoding strategy, disagreeing with other metrics

## Why This Works (Mechanism)

### Mechanism 1
Deterministic search strategies (specifically Beam Search) likely outperform stochastic methods in medical text generation because they optimize for global sequence probability rather than local randomness, reducing factual drift. Beam Search maintains multiple candidate sequences ("beams") and selects the one with the highest cumulative probability. In medical domains where terminology is precise, this reduces the risk of "hallucinating" low-probability but plausible-sounding tokens that often occur in stochastic sampling (e.g., top-k or Î·-sampling). Higher probability sequences correlate strongly with factual accuracy and clinical validity in the specific medical tasks tested.

### Mechanism 2
Medical-specific LLMs exhibit higher sensitivity to decoding strategies because domain-specific fine-tuning distorts probability calibration. Fine-tuning general models on narrow medical datasets sharpens the probability distribution for in-domain tokens but flattens it for out-of-distribution inputs. Stochastic methods, which rely on sampling from the "tail" of the distribution, are more affected by this miscalibration, leading to volatile performance. The performance drop is due to miscalibrated logits (probability distributions) rather than the model's architectural capacity.

### Mechanism 3
Inference latency correlates positively with output quality because complex decoding strategies (like Contrastive Search or Beam Search) require additional computation to evaluate semantic similarity or future states. Higher quality text generation requires "lookahead" or comparative evaluation of candidate tokens (e.g., contrasting layers in DoLa or comparing beams in BS). This computational overhead directly increases the time per token but reduces repetitions and incoherence. The relationship between time and quality is linear and causal within the tested strategies, not just a correlation.

## Foundational Learning

- **Autoregressive Decoding & Probability Distributions**
  - **Why needed here:** The entire paper rests on how models select the "next token" from a vocabulary distribution. Understanding the difference between picking the single most likely token (Greedy) vs. sampling from a distribution (Stochastic) is the baseline.
  - **Quick check question:** If a model assigns 60% probability to "treatment" and 40% to "diagnosis," what token does Greedy decoding select vs. Temperature sampling (T=1.0)?

- **Calibration in Fine-Tuning**
  - **Why needed here:** The paper attributes the failure of medical models to sensitivity caused by fine-tuning. You must understand that fine-tuning can make a model "overconfident" or erratic in its probability estimates.
  - **Quick check question:** Why might a model claim 99% confidence in a wrong answer after being fine-tuned on a specific medical subset?

- **N-gram vs. Embedding-based Metrics**
  - **Why needed here:** The study notes that MAUVE (distribution-based) disagrees with ROUGE (n-gram). Interpreting results requires knowing that ROUGE checks for exact word overlap while BERTScore/MAUVE check semantic meaning or distributional similarity.
  - **Quick check question:** Why would a medically accurate summary score poorly on ROUGE if it uses different synonyms than the reference text?

## Architecture Onboarding

- **Component map:** Model Backbone (LLMs) -> Decoding Head (11 strategies) -> Evaluator (ROUGE, BERTScore, MAUVE) -> Task Interface (5 medical contexts)

- **Critical path:** Task Definition (rigid vs. open) -> Strategy Selection (default Beam Search, Min-p for Summarization) -> Model Selection (General Purpose for robustness, Medical only with managed complexity)

- **Design tradeoffs:**
  - **Latency vs. Accuracy:** Beam Search offers best ROUGE scores but highest inference time
  - **Specialization vs. Robustness:** Medical LLMs may outperform on specific tasks (2/5) but are brittle to hyperparameter changes
  - **Metric Reliability:** MAUVE is sensitive and disagrees with other metrics; relying on it alone risks optimizing for wrong signal

- **Failure signatures:**
  - High Variance in Medical Models: >10% score drop when switching from Greedy to Top-p indicates miscalibration
  - Metric Disagreement: MAUVE rises but BERTScore falls suggests hallucination or mode collapse

- **First 3 experiments:**
  1. Baseline Consistency Check: Run best General model on QA task using Beam Search vs. Top-p to replicate performance gap
  2. Sensitivity Stress Test: Measure ROUGE score variance across 3 decoding strategies on Medical model to confirm high sensitivity
  3. Metric Alignment Audit: Compare ROUGE vs. BERTScore on Summarization task to verify correlation

## Open Questions the Paper Calls Out

### Open Question 1
Do the observed performance advantages of deterministic decoding strategies persist when evaluated on larger, full-scale medical datasets? The authors state, "Future work should examine whether these findings generalize to larger datasets, as our evaluation was limited in sample size." This remains unresolved because the study limited experiments to 100 samples per task due to resource constraints. Replicating the evaluation of the 11 decoding strategies on complete medical benchmarks would confirm if Beam Search remains superior.

### Open Question 2
How do repetition and frequency penalties interact with different decoding strategies to affect the quality of medical text generation? The Discussion identifies as a limitation "the lack of analysis on repetition and frequency penalties, despite their growing use in practice." While the study analyzed core decoding methods, it did not assess common hyperparameters used to mitigate repetitive outputs often associated with methods like beam search. A comparative ablation study applying repetition/frequency penalties would measure changes in ROUGE/BERTScore and output diversity.

### Open Question 3
Can a composite metric combining MAUVE with precision-oriented scores provide a more reliable evaluation for medical text generation? The authors note that "MAUVE alone may be insufficient; combining it with a precision-oriented metric could yield a more balanced evaluation, a direction future work should explore." MAUVE showed weak agreement with BERTScore and ROUGE and high sensitivity to decoding, making it unclear which metric best reflects medical accuracy versus fluency. Developing and validating a composite metric score against human clinical evaluation would determine if it correlates better with expert judgment.

## Limitations

- **Sample size constraint:** Limited to 100 samples per task due to resource constraints, potentially missing edge cases in medical terminology
- **Hardware dependency:** Evaluations conducted on single GPU hardware with fixed prompt formats, limiting generalizability to multi-GPU clusters or real-world workflows
- **Language limitation:** Exclusive focus on English-language tasks limits applicability to multilingual medical contexts

## Confidence

**High Confidence (Level 1):**
- Deterministic strategies (especially Beam Search) outperform stochastic ones in overall score metrics across all model sizes
- Larger models consistently produce better outputs regardless of decoding strategy
- Medical LLMs show higher sensitivity to decoding changes than general-purpose models

**Medium Confidence (Level 2):**
- Medical LLMs do not consistently outperform general-purpose models
- Inference time correlates positively with output quality for the tested strategies
- MAUVE metric shows high sensitivity to decoding strategy changes

**Low Confidence (Level 3):**
- The specific ranking of decoding strategies would remain identical on different hardware configurations
- These findings generalize to medical tasks beyond the five tested domains
- The calibration sensitivity observed in medical models would persist after extended fine-tuning on diverse medical corpora

## Next Checks

1. **Cross-Platform Robustness Test:** Replicate the full evaluation pipeline on different GPU architectures (e.g., H100 vs A100) and CPU-only setups to verify that decoding strategy performance rankings remain stable across hardware platforms, particularly for latency-sensitive metrics.

2. **Edge Case Stress Test:** Expand evaluation to include medical texts with rare terminology, numerical data, and mixed language content (e.g., drug names with Latin roots) to determine if stochastic methods perform better in specialized medical sub-domains where deterministic approaches might overfit to common patterns.

3. **Long-Form Generation Analysis:** Test decoding strategies on extended medical documents (1000+ tokens) rather than the short-form outputs used here to evaluate whether beam search's tendency toward repetition becomes problematic in sustained medical discourse, potentially revealing different optimal strategies for different output lengths.