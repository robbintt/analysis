---
ver: rpa2
title: 'The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons
  from Indic Languages'
arxiv_id: '2509.21294'
source_url: https://arxiv.org/abs/2509.21294
tags:
- data
- language
- evaluation
- reasoning
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Updesh, a 9.5M multilingual instruction-following
  dataset for 13 Indian languages and English, synthesized using a culturally grounded,
  bottom-up pipeline. The dataset combines reasoning data translated from high-quality
  English sources with open-domain generative data grounded in language-specific Wikipedia
  content.
---

# The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages

## Quick Facts
- arXiv ID: 2509.21294
- Source URL: https://arxiv.org/abs/2509.21294
- Reference count: 40
- Primary result: Introduces Updesh, a 9.5M multilingual instruction-following dataset for 13 Indian languages, fine-tuning models that outperform baselines across 15 tasks with largest gains in low-resource languages.

## Executive Summary
This work introduces Updesh, a 9.5M multilingual instruction-following dataset for 13 Indian languages and English, synthesized using a culturally grounded, bottom-up pipeline. The dataset combines reasoning data translated from high-quality English sources with open-domain generative data grounded in language-specific Wikipedia content. Automated quality filtering and human evaluations (10K assessments) confirm high data quality, though LLM-based evaluators show lower agreement on nuanced cultural aspects. Fine-tuned models consistently outperform baselines (BACTRIAN-X, INDICALIGN, AYA-COLLECTION) across 15 diverse multilingual tasks, with largest gains in low-resource languages. Ablation studies show that combining reasoning and generative data yields the best results, and longer training sequences (32K) improve both NLU and NLG performance. Cultural evaluation via ELO rankings confirms strong real-world utility.

## Method Summary
The paper presents a culturally grounded, bottom-up pipeline for synthesizing multilingual instruction-following data. It combines translated reasoning data from high-quality English sources with open-domain generative data using language-specific Wikipedia content. Automated quality filtering and human evaluations validate the dataset, which is then used to fine-tune models for multilingual instruction following.

## Key Results
- Fine-tuned models outperform baselines (BACTRIAN-X, INDICALIGN, AYA-COLLECTION) across 15 diverse multilingual tasks.
- Largest performance gains observed in low-resource languages.
- Combining reasoning and generative data yields best results; longer training sequences (32K) improve both NLU and NLG performance.
- Cultural evaluation via ELO rankings confirms strong real-world utility.

## Why This Works (Mechanism)
The cultural grounding approach ensures that synthetic data reflects real-world linguistic and cultural nuances of Indian languages, leading to better model performance on culturally relevant tasks. The bottom-up pipeline leverages existing high-quality data while expanding coverage through Wikipedia-based generation, creating a balanced dataset that supports both reasoning and open-domain tasks.

## Foundational Learning
- Synthetic data generation pipeline: Why needed - to create scalable, culturally relevant training data for low-resource languages. Quick check - verify quality through automated filtering and human evaluation.
- Cultural grounding techniques: Why needed - to ensure models understand context-specific language use. Quick check - validate through ELO rankings and human cultural assessments.
- Multilingual instruction tuning: Why needed - to enable models to follow instructions across multiple languages simultaneously. Quick check - benchmark against diverse task sets including NLU and NLG.

## Architecture Onboarding

Component Map:
Data Synthesis -> Quality Filtering -> Model Fine-tuning -> Evaluation

Critical Path:
The pipeline flows from data synthesis (combining translated reasoning data with Wikipedia-based generation) through quality filtering, then to model fine-tuning, and finally evaluation across multiple tasks and cultural dimensions.

Design Tradeoffs:
The authors chose to combine translated data with generative data to balance quality and coverage, accepting potential Wikipedia biases for the benefit of increased language diversity. They prioritized longer training sequences (32K) over shorter ones to improve both NLU and NLG performance, despite increased computational costs.

Failure Signatures:
- Poor cultural alignment in generated data (detected by human evaluators)
- Low agreement between human and LLM-based evaluators on cultural aspects
- Performance drops in specific low-resource languages
- Wikipedia content biases affecting model outputs

First 3 Experiments:
1. Run ablation study comparing culturally grounded vs. non-culturally grounded datasets at equivalent scale
2. Expand human evaluation coverage to include broader linguistic and cultural phenomena
3. Test model robustness on out-of-domain cultural content beyond Wikipedia

## Open Questions the Paper Calls Out
The paper notes that while human evaluations confirm high data quality, LLM-based evaluators show notably lower agreement on nuanced cultural aspects, suggesting possible model-specific biases in quality assessment. The cultural grounding is claimed to improve performance, but the study does not provide systematic comparison with purely synthetic, non-culturally grounded datasets, leaving open the question of whether gains are due to scale, language coverage, or cultural specificity.

## Limitations
- Human evaluation covers only 10K instances, which may not fully represent the diversity of 13 languages and their cultural contexts.
- Reliance on Wikipedia for generative data may introduce topical and stylistic biases, as Wikipedia's coverage and quality vary significantly across languages and cultures.
- No systematic comparison with non-culturally grounded synthetic datasets to isolate the effect of cultural specificity on performance gains.

## Confidence
- Data quality and filtering pipeline: High
- Performance gains over baselines: High
- Cultural grounding improves real-world utility: Medium (due to limited direct comparison)
- Best practice for multilingual instruction tuning (32K sequences): Medium (based on single dataset)

## Next Checks
1. Conduct ablation studies comparing culturally grounded vs. non-culturally grounded synthetic data at equivalent scale to isolate the effect of cultural specificity.
2. Expand human evaluation coverage to include a broader set of linguistic and cultural phenomena, especially low-resource languages, and compare results across different evaluator types (human, LLM, cross-lingual).
3. Test model robustness and generalization on out-of-domain or non-Wikipedia cultural content to assess the limits of cultural grounding.