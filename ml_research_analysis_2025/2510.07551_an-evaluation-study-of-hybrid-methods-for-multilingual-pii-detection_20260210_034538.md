---
ver: rpa2
title: An Evaluation Study of Hybrid Methods for Multilingual PII Detection
arxiv_id: '2510.07551'
source_url: https://arxiv.org/abs/2510.07551
tags:
- detection
- locales
- zero-shot
- across
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting personally identifiable
  information (PII) in low-resource languages where annotated data is scarce. The
  authors propose RECAP, a hybrid framework that combines deterministic regular expressions
  with context-aware large language models (LLMs) to detect over 300 PII entity types
  across 13 low-resource locales.
---

# An Evaluation Study of Hybrid Methods for Multilingual PII Detection

## Quick Facts
- arXiv ID: 2510.07551
- Source URL: https://arxiv.org/abs/2510.07551
- Reference count: 34
- Primary result: Hybrid framework RECAP combines regular expressions with LLMs to detect 300+ PII entity types across 13 low-resource locales, achieving 82% improvement over NER models and 17% over zero-shot LLMs in weighted F1-score

## Executive Summary
This paper presents RECAP, a hybrid framework for detecting personally identifiable information (PII) in low-resource languages where annotated data is scarce. The framework combines deterministic regular expressions with context-aware large language models through a three-phase refinement pipeline to resolve ambiguity and reduce false positives. RECAP successfully detects over 300 PII entity types across 13 low-resource locales, outperforming both fine-tuned NER models and zero-shot LLMs in weighted F1-score. The approach demonstrates strong scalability and adaptability for privacy compliance tasks while addressing the critical challenge of multilingual PII detection in data-scarce environments.

## Method Summary
RECAP employs a hybrid architecture that leverages both rule-based regular expressions and LLM-based context understanding to detect PII entities. The system uses a three-phase refinement pipeline: multi-label disambiguation to resolve conflicting entity predictions, span consolidation to merge overlapping or adjacent entity spans, and contextual filtering to eliminate false positives based on surrounding text context. This approach combines the precision of deterministic patterns with the flexibility of LLMs to handle ambiguous or context-dependent PII types. The framework is evaluated across 13 low-resource locales, demonstrating its effectiveness in scenarios where traditional supervised learning approaches struggle due to limited training data availability.

## Key Results
- RECAP achieves 82% improvement over fine-tuned NER models in weighted F1-score for PII detection
- RECAP achieves 17% improvement over zero-shot LLM approaches in weighted F1-score
- Successfully detects over 300 PII entity types across 13 low-resource locales

## Why This Works (Mechanism)
The hybrid approach works by combining the strengths of deterministic pattern matching with contextual understanding. Regular expressions provide high precision for well-defined PII patterns (like phone numbers, emails) while LLMs handle ambiguous cases requiring semantic understanding. The three-phase refinement pipeline systematically resolves conflicts between these different approaches, ensuring that false positives from one method are filtered out by the other. This complementary architecture addresses the fundamental trade-off between precision and recall in PII detection, particularly valuable in low-resource settings where neither pure rule-based nor pure ML approaches perform optimally.

## Foundational Learning
- **Regular Expressions**: Pattern-matching tools for identifying structured PII (phone numbers, emails, SSNs) - needed because structured PII follows predictable formats; quick check: verify regex patterns cover target entity types
- **Large Language Models**: Context-aware models that understand semantic relationships and ambiguity in text - needed because PII detection often requires understanding context beyond surface patterns; quick check: test LLM on ambiguous PII examples
- **Multi-label Disambiguation**: Technique for resolving conflicting predictions when multiple entity types overlap - needed because PII entities can share similar patterns or contexts; quick check: validate disambiguation accuracy on overlapping entity cases
- **Span Consolidation**: Process for merging adjacent or overlapping entity spans into coherent entities - needed because token-level predictions can fragment entities; quick check: measure entity fragmentation reduction
- **Contextual Filtering**: Post-processing step that uses surrounding text to validate entity predictions - needed because standalone patterns can produce false positives without context; quick check: evaluate precision improvement from contextual filtering

## Architecture Onboarding
- **Component Map**: Regular Expressions -> LLM Context Analysis -> Multi-label Disambiguation -> Span Consolidation -> Contextual Filtering -> Final Output
- **Critical Path**: Input Text -> Regular Expression Matching -> LLM Analysis -> Three-phase Refinement Pipeline (Disambiguation → Consolidation → Filtering) -> Output Entities
- **Design Tradeoffs**: The framework trades computational overhead for accuracy by adding multiple refinement stages. Regular expressions provide speed but limited coverage, while LLMs provide flexibility but require more resources. The three-phase pipeline increases processing time but significantly improves precision and recall.
- **Failure Signatures**: Performance degradation in morphologically complex languages, false negatives for novel PII patterns not covered by regex rules, computational bottlenecks in the refinement pipeline, and potential brittleness when encountering domain-specific terminology or obfuscation techniques.
- **First Experiments**: 1) Test RECAP on a held-out validation set with adversarial PII examples, 2) Measure computational overhead and latency of the three-phase refinement pipeline, 3) Evaluate performance on languages with significantly different linguistic structures than the 13 tested locales

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on 13 low-resource locales, potentially not capturing full global language diversity
- Three-phase refinement pipeline introduces computational overhead not quantified in latency or resource metrics
- Does not address robustness against common PII obfuscation techniques or adversarial examples

## Confidence
- High confidence in the hybrid architecture's effectiveness across multiple tested locales
- Medium confidence in generalizability to truly low-resource languages with minimal linguistic resources
- Medium confidence in scalability claims pending further large-scale deployment validation

## Next Checks
1. Evaluate RECAP's performance on additional low-resource languages with significantly different linguistic structures, including those with complex morphology or non-Latin scripts
2. Conduct stress testing with adversarial PII examples and common obfuscation techniques to assess robustness
3. Measure and report the computational overhead introduced by the three-phase refinement pipeline, including latency and resource utilization metrics for production deployment scenarios