---
ver: rpa2
title: 'Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama
  via Early-Layer LoRA Fine-Tuning'
arxiv_id: '2506.15415'
source_url: https://arxiv.org/abs/2506.15415
tags:
- layer
- alignment
- lexical
- pairs
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving cross-lingual lexical
  alignment for low-resource languages (LRLs) in LLMs, using Swahili as a case study.
  The authors propose Targeted Lexical Injection (TLI), a fine-tuning approach that
  leverages the observation that Lugha-Llama-8B-wura exhibits near-perfect lexical
  alignment for Swahili-English word pairs in its early internal layers (Layer 2),
  but this alignment is not fully reflected in its final output.
---

# Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning

## Quick Facts
- arXiv ID: 2506.15415
- Source URL: https://arxiv.org/abs/2506.15415
- Reference count: 5
- This paper improves cross-lingual lexical alignment for Swahili-English word pairs in Lugha-Llama-8B-wura using early-layer LoRA fine-tuning.

## Executive Summary
This paper addresses the challenge of improving cross-lingual lexical alignment for low-resource languages (LRLs) in LLMs, using Swahili as a case study. The authors propose Targeted Lexical Injection (TLI), a fine-tuning approach that leverages the observation that Lugha-Llama-8B-wura exhibits near-perfect lexical alignment for Swahili-English word pairs in its early internal layers (Layer 2), but this alignment is not fully reflected in its final output. TLI uses LoRA and a contrastive learning objective to fine-tune the model, specifically targeting embeddings from Layer 2 to better preserve and propagate this inherent cross-lingual knowledge to the output. Experiments show that TLI significantly improves output-level lexical alignment for 623 trained Swahili-English word pairs, increasing average cosine similarity from 0.3211 to 0.4113 (+28.08%, p < 1.33 x 10^-240). Remarkably, these improvements generalize to 63 unseen control word pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p < 7.17 x 10^-27), suggesting TLI enhances the model's general cross-lingual processing pathways.

## Method Summary
TLI identifies that Lugha-Llama-8B-wura has near-perfect lexical alignment for Swahili-English word pairs at Layer 2 but weak alignment at the final output layer. The method applies LoRA adapters to the query and value projection matrices, training them with a triplet margin contrastive loss applied to Layer 2 embeddings. The loss pulls translation pairs closer while pushing non-translations apart. By optimizing early-layer representations, TLI reinforces the model's inherent cross-lingual understanding and propagates it through the network to improve final output alignment. The approach uses 686 Swahili-English word pairs (623 trained, 63 control) and trains for 5 epochs with batch size 8 and AdamW optimizer.

## Key Results
- TLI increases average cosine similarity for trained Swahili-English pairs from 0.3211 to 0.4113 (+28.08%, p < 1.33 x 10^-240)
- Improvements generalize to 63 unseen control pairs, increasing similarity from 0.3143 to 0.4033 (+28.32%, p < 7.17 x 10^-27)
- Layer 2 shows near-perfect alignment (0.99998 cosine similarity) for translation pairs, while Layer 31 output shows only ~0.32 baseline

## Why This Works (Mechanism)

### Mechanism 1: Latent Alignment Propagation
The model inherently "knows" cross-lingual equivalences early in its architecture, but fails to reflect this in the final output due to propagation degradation. TLI identifies a "sweet spot" (Layer 2) where cosine similarity for translation pairs is near-perfect (~0.99998). By applying contrastive loss at this specific layer, the LoRA adapters learn to reinforce and carry this high-fidelity signal through the subsequent transformer blocks, preventing it from being diluted by language-specific processing in deeper layers.

### Mechanism 2: Geometry Correction via Early-Layer Gradients
Modifying the model's processing based on early-layer embeddings effectively reshapes the final output geometry more robustly than fine-tuning the output directly. Instead of forcing the final layer to "memorize" a mapping, gradients from the contrastive loss (applied at Layer 2) optimize the low-rank matrices (LoRA) to respect the semantic geometry inherent in the early layers. This ensures the *pathways* through the network preserve semantic equivalence.

### Mechanism 3: Generalization via Pathway Refinement
The intervention improves general cross-lingual processing pathways rather than merely memorizing trained pairs. By using LoRA to modify the query/value projections based on a contrastive objective, the model learns a general transformation function. This function preserves alignment for *any* pair that shares the structural properties found at Layer 2, not just the specific pairs seen during training.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**
  - Why needed: TLI relies on LoRA to modify the model efficiently. You must understand that LoRA adds trainable "sidecar" matrices to the frozen weights, allowing gradient updates to flow and alter the output without retraining the full model.
  - Quick check: Does the TLI method modify the frozen weights of Lugha-Llama directly, or does it train external matrices that are later merged?

- **Contrastive Learning (Triplet Loss)**
  - Why needed: The core driver of TLI is the contrastive loss. You need to understand how the loss function pulls an "anchor" (Swahili word) closer to a "positive" (English translation) while pushing it away from "negatives" (non-translations) in the embedding space.
  - Quick check: In the TLI loss function, what is the "anchor," what is the "positive," and what serves as the "negative"?

- **Layer-wise Semantics in Transformers**
  - Why needed: The paper hinges on the finding that early layers handle alignment better than final layers. You need to know that LLMs process information hierarchically—early layers often capture surface forms or basic semantics, while deeper layers mix this with context and task-specific noise.
  - Quick check: Why did the authors choose Layer 2 instead of the final layer (Layer 31) to calculate the contrastive loss?

## Architecture Onboarding

- **Component map:** Lugha-Llama-8B-wura (Frozen) -> LoRA Adapters (Rank 16) -> Contrastive Loss (Layer 2) -> Improved Alignment (Layer 31)

- **Critical path:**
  1. **Pilot Study:** Run a scan of all layers to identify the peak alignment layer (found: Layer 2)
  2. **Injection:** Inject LoRA adapters and configure training to compute loss on Layer 2 embeddings
  3. **Propagation:** Optimizer updates LoRA weights to minimize loss, effectively forcing the network to maintain Layer 2 alignment through to the end

- **Design tradeoffs:**
  - Rank 16 vs. Higher: A rank of 16 is very low (efficient), but might limit the complexity of the alignment transformation the model can learn
  - Layer 2 vs. Layer 1: Layer 2 was empirically better than Layer 1 (0.98 vs 0.99 similarity), suggesting Layer 1 is slightly too raw or Layer 2 is the optimal semantic peak
  - In-batch Negatives: Using in-batch negatives is computationally efficient but might miss "hard" negatives that would refine the boundary more effectively

- **Failure signatures:**
  - Low Generalization: If Control Set similarity stays flat while Trained Set similarity rises, the model is overfitting (memorizing) rather than learning a pathway
  - Layer Mismatch: If applying TLI to Layer 20 (deeper) results in noise or instability, it confirms the "Early-Layer" hypothesis is critical
  - Catastrophic Forgetting: If standard NLP benchmarks degrade, the LoRA updates may be interfering with general language capabilities

- **First 3 experiments:**
  1. **Replicate Pilot:** Load Lugha-Llama and plot cosine similarity for Swahili-English pairs across all 32 layers to verify the Layer 2 peak exists in your environment
  2. **Ablation Layer:** Run TLI using Layer 1 and then Layer 10 instead of Layer 2 to confirm that Layer 2 provides the optimal signal-to-noise ratio for convergence
  3. **Zero-Shot Task Check:** After merging the TLI LoRA adapter, run a simple zero-shot translation or retrieval task to see if the improved cosine similarity (0.41) translates to functional performance gains

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the improvement in lexical alignment from Targeted Lexical Injection (TLI) translate to measurable performance gains in concrete downstream NLP tasks?
- **Basis in paper:** Section 7 lists "Downstream Task Evaluation" as a future avenue, asking researchers to "Quantify the impact... on concrete downstream NLP tasks such as Swahili-English machine translation, cross-lingual question answering, and sentiment analysis."
- **Why unresolved:** The study evaluated success using cosine similarity of isolated word pairs rather than end-to-end task performance.
- **What evidence would resolve it:** Benchmarks showing performance deltas on translation (e.g., BLEU scores) or QA tasks between the base Lugha-Llama model and the TLI-finetuned version.

### Open Question 2
- **Question:** Is Layer 2 universally the optimal target for this method, or does the ideal intervention point vary across different model architectures and language pairs?
- **Basis in paper:** Section 7 asks to "Investigate whether Layer 2 is universally optimal or if the ideal target layer varies across different LLM architectures, language pairs, or specific alignment tasks."
- **Why unresolved:** The pilot study identifying Layer 2 as the peak alignment locus was restricted to the Lugha-Llama-8B-wura model and Swahili-English pairs.
- **What evidence would resolve it:** Replicating the pilot study and TLI methodology on diverse model architectures (e.g., BERT-based or other Llama variants) and languages to see if the alignment peak shifts.

### Open Question 3
- **Question:** Does optimizing for specific cross-lingual alignment inadvertently degrade the model's broader semantic understanding or generative fluency?
- **Basis in paper:** Section 5.6 notes the evaluation "focuses on isolated lexical pair similarity" and acknowledges that "impact on broader semantic understanding, syntactic processing, or generative capabilities requires further investigation."
- **Why unresolved:** The contrastive loss used for training operates on static embeddings rather than the causal language modeling objective, potentially disrupting the model's generative coherence.
- **What evidence would resolve it:** Post-training evaluation of perplexity and qualitative analysis of generated text coherence to ensure general language capabilities are maintained.

## Limitations
- The method's effectiveness is demonstrated only on Swahili-English with Lugha-Llama-8B-wura, limiting generalizability to other language pairs and models.
- The choice of Layer 2 as the optimal injection point is model-specific and may not generalize to other architectures.
- The control set's semantic diversity and tokenization characteristics are not fully detailed, which could affect generalization claims.

## Confidence

- **High Confidence:** The pilot study results showing Layer 2's near-perfect alignment and the subsequent improvement on trained word pairs are directly supported by the experiments described. The paired t-test p-values (< 1.33e-240) are extremely low, providing robust statistical evidence for the core mechanism.

- **Medium Confidence:** The generalization to unseen control word pairs is well-documented with statistical tests (p < 7.17e-27), but the semantic diversity and tokenization characteristics of the control set are not fully detailed. The conclusion that TLI improves "general cross-lingual processing pathways" is plausible but not proven to hold for all Swahili-English vocabulary or other language pairs.

- **Low Confidence:** Claims that TLI would generalize to other LRLs or that the Layer 2 optimization is universally optimal for other models are speculative. These claims are grounded in the broader literature on cross-lingual alignment but lack direct experimental validation within this paper.

## Next Checks

1. **Control Set Semantic Diversity Audit:** Manually categorize the 63 control word pairs by part-of-speech, morphological complexity, and semantic domain. Verify that the generalization improvement is consistent across these subcategories, not just driven by a subset of easy or similar words.

2. **Layer Transferability Test:** Replicate the pilot study (cosine similarity scan across layers) on a different multilingual LLM (e.g., BLOOMZ or NLLB) and apply TLI at its respective Layer 2 equivalent. Compare if the same pattern of early-layer peak and output degradation exists, and if TLI recovers alignment.

3. **Zero-Shot Task Evaluation:** Design a simple downstream task (e.g., cross-lingual information retrieval or dictionary lookup) that uses the improved embeddings. Measure if the increase in cosine similarity (0.32 → 0.41) translates into measurable gains in task accuracy or recall, providing evidence that the alignment improvements are functionally meaningful.