---
ver: rpa2
title: Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language
  Models
arxiv_id: '2508.03406'
source_url: https://arxiv.org/abs/2508.03406
tags:
- uni00000013
- uni00000052
- uni00000057
- uni00000014
- uni00000055
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MOID, a framework for diagnosing infeasible
  routing problems using multi-objective optimization and LLM-based analysis. It generates
  trade-off solutions between path cost and constraint violation, then uses an LLM
  agent to provide actionable model adjustment suggestions.
---

# Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models

## Quick Facts
- arXiv ID: 2508.03406
- Source URL: https://arxiv.org/abs/2508.03406
- Reference count: 40
- Primary result: MOID achieves significantly better HV (1.09 vs 0.83) and IGD metrics than existing LLM-based methods for diagnosing infeasible VRPs

## Executive Summary
This paper introduces MOID, a framework for diagnosing infeasible routing problems using multi-objective optimization and LLM-based analysis. The method generates trade-off solutions between path cost and constraint violation, then uses an LLM agent to provide actionable model adjustment suggestions. Experiments on 50 types of infeasible VRPs show MOID achieves significantly better HV and IGD metrics than existing LLM-based methods, offering more diverse and practical insights for restoring feasibility.

## Method Summary
MOID converts infeasible routing problems into bi-objective optimization by treating constraint violation as a soft objective. An LLM generates constraint-aware heuristics (checker and scorer programs) that guide a multi-objective solver (NSGA-II) to produce a Pareto front of trade-off solutions. For each solution, another LLM generates a solution analysis function that computes minimal constraint parameter adjustments to restore feasibility, outputting natural language suggestions. The framework uses 25-node Solomon C103 instances and evaluates performance using Hypervolume and Inverted Generational Distance metrics.

## Key Results
- MOID achieves HV of 1.09 vs 0.83 for the best existing LLM-based method
- DeepSeek-V3 outperforms ChatGPT-4o in analysis success rate
- Direct Constraint Relaxation strategy achieves higher analysis success rate than Estimating Constraint Parameters
- MOID provides more diverse diagnostic insights compared to single-objective approaches

## Why This Works (Mechanism)

### Mechanism 1
Reformulating hard constraints as soft objectives exposes trade-offs between original problem goals and feasibility restoration. The framework converts an infeasible problem into a bi-objective optimization problem: min(f_cost, f_violation). The multi-objective solver then generates a Pareto front of non-dominated solutions, each representing a different compromise between cost and violation. This transforms a binary feasible/infeasible state into a gradient of "how infeasible" options.

### Mechanism 2
LLM-generated constraint-aware heuristics enable the solver to handle arbitrary VRP variants without manually encoding constraints. An LLM agent translates natural language problem descriptions into two programs: (1) a constraint checker (boolean) and (2) a constraint scorer (numeric violation degree). These programs form the heuristic that guides solution selection in the multi-objective solver.

### Mechanism 3
Inverse-optimization-inspired analysis translates each Pareto solution into human-readable model modification suggestions. For each solution on the Pareto front, an LLM-generated "solution analysis function" computes the minimal constraint parameter adjustments that would make that solution feasible. Two strategies are offered: Direct Constraint Relaxation (DCR) computes boundary values directly; Estimating Constraint Parameters (ECP) uses a formal inverse optimization formulation.

## Foundational Learning

- **Concept:** Pareto dominance and Pareto front
  - Why needed: The core mechanism relies on generating and interpreting a set of non-dominated solutions
  - Quick check: Given two solutions (cost=100, violation=50) and (cost=80, violation=80), which dominates the other? (Answer: Neither; they are non-dominated.)

- **Concept:** Constraint violation as a scalarized objective
  - Why needed: The method requires quantifying "how infeasible" a solution is
  - Quick check: If a solution violates capacity by 10 units and time window by 5 minutes, should the total violation be 15, or should weights be applied?

- **Concept:** Inverse optimization intuition
  - Why needed: The diagnostic method is explicitly inspired by inverse optimization
  - Quick check: Given a "near-feasible" solution, what constraint adjustment would make it exactly feasible?

## Architecture Onboarding

- **Component map:** Problem description → LLM generates constraint-aware heuristic → Multi-objective solver runs → Pareto front produced → LLM generates analysis function → For each solution: analysis function computes parameter adjustments → Natural language suggestions output

- **Critical path:** Problem description → LLM generates constraint-aware heuristic → Multi-objective solver runs → Pareto front produced → LLM generates analysis function → For each solution: analysis function computes parameter adjustments → Natural language suggestions output

- **Design tradeoffs:**
  - DCR vs. ECP: DCR is simpler, more reliable, and achieves higher success rate; ECP is theoretically grounded but more complex and error-prone for LLM code generation
  - Population size vs. diversity: N=10 is used; larger populations may improve front coverage but increase runtime
  - Number of iterations: T=100 iterations balance convergence and computational cost

- **Failure signatures:**
  - Empty Pareto front: Optimization failed to find any trade-off solutions; check constraint scoring program
  - High-variance violation scores across runs: Constraint scorer may be non-deterministic or unstable
  - Analysis function syntax errors: LLM failed to generate valid code; may require prompt refinement or template hardening
  - Suggestions are nonsensical: Analysis function logic error or mismatch between scorer and analysis function assumptions

- **First 3 experiments:**
  1. Reproduce the CVRP-L result: Run MOID on the provided CVRP-L instance, verify that the Pareto front matches Figure 2(b) and that suggestions are generated correctly
  2. Ablation of diagnostic strategies: Compare DCR vs. ECP on a subset of 10 problems, measuring analysis success rate and manual inspection of suggestion quality
  3. Sensitivity to population size: Run MOID on CVRP with N=5, 10, 20; compare HV and IGD metrics to assess diversity-convergence trade-off

## Open Questions the Paper Calls Out

### Open Question 1
Can the MOID paradigm be effectively extended to diagnose infeasibility in other combinatorial optimization domains beyond routing? The current framework relies heavily on VRP-specific operators and constraint-aware heuristics designed for graph structures, which may not translate directly to other domains.

### Open Question 2
How does MOID's diagnostic performance and computational cost scale with problem size and constraint complexity? The experimental evaluation is limited to VRP instances with only 25 nodes derived from the Solomon C103 dataset.

### Open Question 3
Can the reliability of the "Estimating Constraint Parameters" (ECP) diagnostic strategy be improved to match the simpler "Direct Constraint Relaxation" (DCR)? While ECP offers a theoretical advantage via inverse optimization, LLMs struggle to implement the complex bilinear formulations required.

## Limitations

- The constraint violation scoring mechanism assumes linear aggregation of multiple constraint violations without validating whether this scoring accurately reflects real-world constraint severity tradeoffs
- The inverse optimization analysis assumes constraints are parameterized and adjustable, which may not hold for structural constraints common in routing problems
- The comparison with LLM-based methods uses baselines that are not fully specified in the main text, making independent verification difficult

## Confidence

- **High confidence:** The multi-objective optimization framework correctly generates Pareto fronts and the NSGA-II implementation appears sound
- **Medium confidence:** The LLM-generated constraint-aware heuristics work reliably for the tested VRP variants, though generalization to arbitrary constraint types remains uncertain
- **Low confidence:** The analysis module's ability to provide actionable suggestions across diverse problem structures has not been thoroughly validated

## Next Checks

1. **Cross-validation of violation scoring:** Test MOID on problems where constraint violations have known relative importance to verify the aggregation mechanism produces intuitive trade-offs
2. **Structural constraint handling:** Evaluate MOID on routing problems with structural (non-parameterizable) constraints to assess failure modes
3. **Baseline specification audit:** Obtain complete implementation details for the LLM-based baseline methods to ensure fair comparison and reproducibility