---
ver: rpa2
title: Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval
  Augmented Large Language Models
arxiv_id: '2511.13526'
source_url: https://arxiv.org/abs/2511.13526
tags:
- knowledge
- clinical
- medical
- graph
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of constructing high-quality,
  scalable medical indicator knowledge graphs from unstructured clinical guidelines,
  which traditionally require labor-intensive manual curation and rule-based extraction.
  The proposed solution integrates retrieval-augmented generation (RAG) with large
  language models (LLMs) to automate knowledge extraction, using ontology-driven schema
  design and a human-in-the-loop (HITL) validation mechanism for clinical accuracy.
---

# Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models

## Quick Facts
- arXiv ID: 2511.13526
- Source URL: https://arxiv.org/abs/2511.13526
- Reference count: 21
- 88% precision on 240 expert-reviewed triples for medical indicator extraction from clinical guidelines

## Executive Summary
This paper addresses the challenge of constructing high-quality, scalable medical indicator knowledge graphs from unstructured clinical guidelines, which traditionally require labor-intensive manual curation and rule-based extraction. The proposed solution integrates retrieval-augmented generation (RAG) with large language models (LLMs) to automate knowledge extraction, using ontology-driven schema design and a human-in-the-loop (HITL) validation mechanism for clinical accuracy. The framework performs guideline-driven data acquisition, semantic retrieval, structured extraction, knowledge fusion, and expert-guided refinement. Experimental results show 88% precision on a sample of 240 extracted triples, with the system successfully standardizing over 120 clinical indicators across eight physiological systems. The resulting knowledge graphs are interoperable with biomedical ontologies such as UMLS and SNOMED CT and can support intelligent clinical decision support systems, question-answering platforms, and biomedical research applications.

## Method Summary
The methodology employs a two-stage pipeline combining retrieval-augmented generation with ontology-guided extraction. First, dense vector retrieval identifies contextually relevant guideline segments using biomedical embeddings. Second, the LLM performs entity recognition, relation extraction, and attribute identification on retrieved text only, constraining generation to source-grounded content. The extracted triples are validated and aligned against a predefined ontology—co-developed with clinical experts—that specifies entity types, relation types, and constraints. Expert review of sampled triples creates a feedback loop for continuous refinement of prompts and extraction rules. The framework processes 38 clinical guidelines across eight physiological systems, with precision validated on 240 expert-reviewed triples.

## Key Results
- Achieved 88% precision on expert review of 240 extracted triples
- Successfully standardized over 120 clinical indicators across eight physiological systems
- Knowledge graphs interoperable with established biomedical ontologies (UMLS, SNOMED CT)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieval-augmented generation grounds LLM extraction in authoritative clinical sources, reducing hallucination and improving factual reliability.
- **Mechanism:** A two-stage hybrid pipeline where (1) dense vector retrieval identifies contextually relevant guideline segments using biomedical embeddings, then (2) the LLM performs entity recognition, relation extraction, and attribute identification on retrieved text only. This constrains generation to source-grounded content.
- **Core assumption:** Semantic similarity search correctly identifies the guideline passages containing the relevant medical indicators.
- **Evidence anchors:** [abstract]: "retrieval-augmented generation with large language models, supported by ontology-guided schema design"; [section III.C]: "vector-based retrieval grounds LLM inference in clinically relevant source text, reducing hallucination"; [corpus]: Related paper "ICA-RAG" confirms adaptive retrieval strategies matter for diagnostic accuracy.

### Mechanism 2
- **Claim:** Ontology-driven schema design enforces semantic consistency and enables cross-system interoperability of extracted knowledge.
- **Mechanism:** A predefined ontology—co-developed with clinical experts—specifies entity types (diseases, procedures, medications, indicators), relation types (diagnostic-threshold, treatment-indication), and constraints (e.g., every rehabilitation indicator must link to a procedure). Extracted triples are validated and aligned against this schema before graph insertion.
- **Core assumption:** The ontology adequately covers the entity and relation types present in target guidelines.
- **Evidence anchors:** [abstract]: "ontology-guided schema design"; [section III.B]: "The ontology serves as the structural and semantic backbone... aligned with established biomedical standards, including SNOMED CT and UMLS"; [corpus]: Weak direct corpus evidence on ontology-first extraction.

### Mechanism 3
- **Claim:** Expert-in-the-loop validation creates a feedback loop that improves both extraction quality and pipeline configuration over time.
- **Mechanism:** Clinical experts review sampled triples using a structured checklist. When errors are identified, feedback is reintegrated to refine prompt templates, adjust extraction rules, and calibrate LLM behavior for subsequent iterations—forming a continuous quality control loop.
- **Core assumption:** Expert feedback is consistent, actionable, and representative of systematic (not idiosyncratic) issues.
- **Evidence anchors:** [abstract]: "expert-in-the-loop validation"; [section III.D]: "expert feedback is reintegrated to refine prompt templates, adjust extraction rules, and improve LLM performance in subsequent cycles"; [section IV]: "expert review of 240 extracted triples and confirmed 212 to be correct... precision of 88 percent"; [corpus]: No corpus papers explicitly evaluate HITL loop efficacy for KG construction.

## Foundational Learning

- **Concept: Knowledge Graphs (entities, relations, triples)**
  - **Why needed here:** The entire output is a KG; you must understand subject-predicate-object structure, entity normalization, and schema constraints to debug extraction failures.
  - **Quick check question:** Given "Hypertension has_threshold BP < 120/80 mmHg," identify subject, predicate, object, and one potential normalization issue.

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** Core extraction mechanism depends on retrieving the right context before LLM inference; retrieval quality directly bounds extraction quality.
  - **Quick check question:** If your retriever returns irrelevant passages, what happens to extraction accuracy even with a perfect LLM?

- **Concept: Medical Ontologies (SNOMED CT, UMLS)**
  - **Why needed here:** The framework aligns extracted entities to these standards for interoperability; you need to navigate hierarchies and cross-references.
  - **Quick check question:** How would you determine if "myocardial infarction" maps to the same SNOMED CT concept as "heart attack"?

## Architecture Onboarding

- **Component map:** Data Acquisition -> Ontology Design -> Information Extraction (RAG retrieval -> LLM extraction) -> Knowledge Fusion -> Human-in-the-loop validation
- **Critical path:** Ontology quality -> Retrieval relevance -> Extraction accuracy -> Fusion consistency -> Expert validation throughput. Errors propagate forward; fixes propagate backward via feedback loop.
- **Design tradeoffs:** Automation vs. accuracy: More aggressive automation reduces expert load but increases false positives; Ontology breadth vs. specificity: Broader schemas cover more guidelines but dilute semantic precision; Retrieval chunk size: Larger chunks provide context but introduce noise; smaller chunks risk missing dependencies.
- **Failure signatures:** Low precision on specific relation types -> ontology schema likely incomplete or ambiguous; High hallucination rate -> retrieval not surfacing relevant passages; check embedding quality and chunk boundaries; Expert backlog growing -> extraction volume exceeding validation capacity.
- **First 3 experiments:**
  1. **Retrieval ablation:** Measure extraction precision with vs. without RAG (null retrieval baseline) to quantify grounding contribution.
  2. **Ontology coverage test:** Run extraction on a held-out guideline; categorize missed/incorrect triples by whether entity/relation types exist in schema.
  3. **Expert feedback loop timing:** Track precision across 3 iterations with active HITL vs. static prompts to validate the claimed continuous improvement mechanism.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework be adapted to support automated, continuous updates to medical knowledge graphs as clinical guidelines evolve?
- Basis in paper: [explicit] The Discussion states future work will focus on "automated graph updating," and the Conclusion lists "continuous knowledge updating" as an expansion goal.
- Why unresolved: The current methodology focuses on static extraction from existing guidelines without detailing a mechanism for dynamic integration of new or revised medical standards.
- What evidence would resolve it: A prototype system demonstrating real-time integration of guideline updates (e.g., version changes) without requiring a full reconstruction of the graph.

### Open Question 2
- Question: What specific calibration techniques are required to optimize LLMs for medical indicator extraction to maximize factual precision?
- Basis in paper: [explicit] The Discussion identifies "domain-specific LLM calibration" as a specific focus for future work to enhance reliability.
- Why unresolved: While the paper uses RAG to reduce hallucinations, it does not detail how the LLM itself is calibrated for the specific nuances of medical indicator extraction.
- What evidence would resolve it: Comparative benchmarks showing improved F1 scores or reduced error rates in extraction tasks using a calibrated model versus the baseline implementation.

### Open Question 3
- Question: Can the constructed knowledge graphs be effectively integrated with real-world hospital data to create personalized "health banks"?
- Basis in paper: [explicit] The Conclusion proposes building a "large-scale health visualization model" that combines clinical guidelines with real-world hospital data.
- Why unresolved: The current study validates the framework on unstructured text guidelines; integration with structured, heterogeneous hospital data systems presents technical challenges not addressed in the methodology.
- What evidence would resolve it: A successful pilot application linking extracted indicator knowledge with electronic health records (EHRs) to generate individualized health visualizations.

## Limitations
- Reported precision is based on expert review of 240 triples without specifying sampling strategy or guideline distribution across physiological systems
- Specific LLM model, embedding variants, and exact prompt templates are not disclosed, blocking precise reproduction
- Paper does not address error propagation from failed retrieval (e.g., when indicators appear in tables or figures not captured in text)

## Confidence
- **High confidence:** The mechanism of using ontology-driven schema to ensure semantic consistency and interoperability (Mechanism 2) is well-supported by explicit claims and alignment to SNOMED CT/UMLS
- **Medium confidence:** The claim that RAG grounding reduces hallucination (Mechanism 1) is plausible and consistent with related work, but lacks direct ablation evidence in the paper
- **Low confidence:** The claimed continuous improvement via human-in-the-loop feedback (Mechanism 3) is described conceptually but lacks quantitative evidence of iterative gains

## Next Checks
1. **Retrieval grounding test:** Measure extraction precision with RAG disabled (null retrieval) vs. enabled to quantify the contribution of retrieval to reducing hallucination
2. **Ontology coverage audit:** Extract from a held-out guideline and classify errors by whether the entity/relation type exists in the ontology to validate schema completeness
3. **HITL feedback efficacy:** Track precision across three iterative cycles with and without expert feedback to confirm the claimed improvement mechanism