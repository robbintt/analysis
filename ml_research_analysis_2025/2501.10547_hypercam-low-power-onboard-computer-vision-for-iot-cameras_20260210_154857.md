---
ver: rpa2
title: 'HyperCam: Low-Power Onboard Computer Vision for IoT Cameras'
arxiv_id: '2501.10547'
source_url: https://arxiv.org/abs/2501.10547
tags:
- hypercam
- image
- bundling
- hypervectors
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HyperCam introduces an energy-efficient image classification pipeline
  using hyperdimensional computing (HDC) for low-power IoT cameras. It addresses the
  challenge of deploying computer vision on resource-constrained microcontrollers
  by leveraging HDC's inherently hardware-friendly operations.
---

# HyperCam: Low-Power Onboard Computer Vision for IoT Cameras

## Quick Facts
- arXiv ID: 2501.10547
- Source URL: https://arxiv.org/abs/2501.10547
- Reference count: 40
- Primary result: Achieves 93.60%, 84.06%, 92.98%, and 72.79% accuracy on MNIST, Fashion-MNIST, face detection, and face identification tasks respectively, using only 42.91-63.00KB flash memory and 22.25KB RAM.

## Executive Summary
HyperCam introduces an energy-efficient image classification pipeline for resource-constrained IoT cameras using hyperdimensional computing (HDC). The system addresses the challenge of deploying computer vision on low-power microcontrollers by leveraging HDC's hardware-friendly binary operations. Through novel sparse bundling algorithms based on Bloom Filters and Count Sketches, HyperCam dramatically reduces encoding overhead while maintaining competitive accuracy. The implementation achieves state-of-the-art memory efficiency compared to neural networks and lightweight ML models, making it suitable for battery-powered edge devices.

## Method Summary
HyperCam uses Binary Spatter Code (BSC) hyperdimensional computing with progressive HD expression rewrites to enable efficient image classification on microcontrollers. The system implements sparse bundling using Bloom Filters and Count Sketches to reduce bundling operations by 98%, along with four optimization rewrites that factor out position and value codebooks. Training uses a modified OnlineHD algorithm with binary hypervectors, and inference computes Hamming distance between query and class hypervectors. The system was prototyped on an STM32U585AI microcontroller with a Himax HM01B0 camera.

## Key Results
- Achieves 93.60%, 84.06%, 92.98%, and 72.79% accuracy on MNIST, Fashion-MNIST, face detection, and face identification tasks
- Uses only 42.91-63.00KB flash memory and 22.25KB RAM
- Delivers inference latency of 0.08-0.27 seconds
- Outperforms SVM and xgBoost in both accuracy and memory efficiency
- Consumes 128mW power during image processing and transmission

## Why This Works (Mechanism)

### Mechanism 1
Binary hyperdimensional computing enables energy-efficient classification by replacing floating-point matrix operations with hardware-native bitwise operations. Images are encoded into 10,000-bit binary hypervectors using XOR for binding, majority vote for bundling, and circular shift for permutation. Classification uses Hamming distance comparison.

Core assumption: Binary hypervector representations preserve sufficient discriminative information while being computable with simple hardware operations.

### Mechanism 2
Sparse bundling using Bloom Filters and Count Sketches reduces bundling operations by 98% (from 19,200 to ~38 equivalent operations). The algorithm updates only 20 randomly sampled indices per element instead of all 10,000 bits.

Core assumption: Random sampling preserves enough distance relationships between pixel position sets for accurate classification.

### Mechanism 3
Four progressive HD expression rewrites reduce codebook memory by 52% and binding operations by 50%. These include on-the-fly position code generation, 2D-to-1D position coalescing, value hypervector factoring with weighted bundling, and sparse bundling application.

Core assumption: Permuting single hypervectors produces sufficiently independent codes, and weighted bundling compensates for information lost during factoring.

## Foundational Learning

- **Hyperdimensional Computing (HDC) fundamentals**: Understanding binary hypervectors, binding (XOR), bundling (majority vote), and distance metrics forms the computational substrate. Quick check: Can you explain why XOR is suitable for binding and how Hamming distance enables classification?

- **Bloom Filters and Count Sketches**: These probabilistic data structures underpin sparse bundling optimization. Quick check: What is the trade-off between Bloom Filter and Count Sketch backends in terms of speed vs. accuracy?

- **Memory-constrained embedded ML deployment**: The system must operate within 42-63KB flash and 22KB RAM, motivating all optimization decisions. Quick check: Why does eliminating pre-stored codebooks and using on-the-fly generation matter for flash memory usage?

## Architecture Onboarding

- **Component map**: Image capture → Sparse bundling per pixel value → Weighted binding with value hypervectors → Final majority vote → Hamming distance comparison → BLE transmission

- **Critical path**: Image capture → Sparse bundling per pixel value (dominant latency) → Weighted binding with value hypervectors → Final majority vote → Hamming distance comparison → BLE transmission

- **Design tradeoffs**: 
  - Count Sketch backend: Higher accuracy (93.60% MNIST) but slower encoding (0.26s) due to integer quantization
  - Bloom Filter backend: Faster encoding (0.08s) but lower accuracy (90.36% MNIST)
  - Hypervector dimensionality n=10,000: Larger n improves accuracy but increases memory and latency

- **Failure signatures**:
  - Sharp accuracy drop when sparse bundling density d < 20
  - Face identification accuracy (72.79%) significantly lower than face detection (92.98%)
  - Accuracy degradation on complex datasets with many classes or high-resolution images

- **First 3 experiments**:
  1. Implement VanillaHDC encoding on STM32U585AI to measure unoptimized memory footprint (~670KB codebook) and latency (~60 seconds for 120×160 image)
  2. Vary density parameter d from 5 to 50 on MNIST to reproduce accuracy cliff at d=20
  3. Collect small custom dataset (50-100 images per class, 3-5 classes) and compare Count Sketch vs. Bloom Filter accuracy/latency

## Open Questions the Paper Calls Out

- **Multi-modal Sensors**: How can HyperCam be extended to efficiently perform multi-modal sensor fusion, such as combining image and audio data, to enhance decision-making accuracy? The paper lists this as a future direction, noting that HD classifiers can easily fuse different data domains encoded as hypervectors.

- **Onboard Training**: How does the system perform under on-device training regimes where class hypervectors are updated in real-time with new data distributions? The paper identifies this as a key future direction, citing the ease of bundling new image hypervectors.

## Limitations

- Sparse bundling approximation may lose critical spatial relationships in complex image patterns
- Multi-class scalability issues, with face identification accuracy (72.79%) significantly lower than face detection (92.98%)
- Performance on real-world IoT camera scenarios with varying lighting, occlusion, and object diversity remains unproven

## Confidence

- **High Confidence**: Resource efficiency claims (flash/RAM usage, latency measurements) - These are hardware-measured and reproducible
- **Medium Confidence**: Sparse bundling mechanism - Accuracy degradation at d<20 is experimentally validated, but theoretical justification remains heuristic
- **Low Confidence**: Scalability to complex real-world scenarios - The paper acknowledges limitations but provides no empirical validation beyond tested benchmarks

## Next Checks

1. Evaluate HyperCam on CIFAR-10 or ImageNet subsets to assess performance degradation when scaling from 10 classes to 100+ classes
2. Port the implementation to a different microcontroller (e.g., ESP32-C3 or nRF52840) to verify cross-platform resource usage claims
3. Deploy HyperCam in a field setting with variable lighting and object distances to measure accuracy degradation and power consumption under non-ideal conditions