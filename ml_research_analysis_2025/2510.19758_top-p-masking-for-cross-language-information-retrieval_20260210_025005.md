---
ver: rpa2
title: Top-P Masking for Cross Language Information Retrieval
arxiv_id: '2510.19758'
source_url: https://arxiv.org/abs/2510.19758
tags:
- masking
- top-k
- terms
- language
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Cross Language Information Retrieval (CLIR)
  by proposing Top-P Dynamic Masking as an improvement over Top-K masking for generating
  sparse representations in multilingual embeddings. The core method involves using
  Top-P Dynamic Masking (similar to Nucleus Sampling) instead of Top-K masking during
  post-processing of BERT embeddings.
---

# Top-P Masking for Cross Language Information Retrieval

## Quick Facts
- arXiv ID: 2510.19758
- Source URL: https://arxiv.org/abs/2510.19758
- Authors: Joseph Casale; Andrew Silverschotz; Joseph DeSimone
- Reference count: 4
- Key outcome: Top-P Dynamic Masking consistently outperforms Top-K masking, achieving similar or better Mean Average Precision (mAP) with improved query throughput

## Executive Summary
This paper addresses Cross Language Information Retrieval (CLIR) by proposing Top-P Dynamic Masking as an improvement over Top-K masking for generating sparse representations in multilingual embeddings. The authors evaluate their method on the NeuCLIR dataset (75,000 Mandarin documents) using BLADE-C architecture, comparing Top-K and Top-P masking across various sparsity levels. Results show that Top-P Dynamic Masking consistently outperforms Top-K masking, achieving similar or better Mean Average Precision (mAP) with improved query throughput. The analysis reveals that Top-P selects more terms for documents but fewer for queries compared to Top-K, resulting in better overall performance.

## Method Summary
The core method involves using Top-P Dynamic Masking (similar to Nucleus Sampling) instead of Top-K masking during post-processing of BERT embeddings. While Top-K selects a fixed number of top terms, Top-P selects terms until their cumulative importance reaches proportion p, allowing a dynamic number of terms per document/query. The authors evaluate their method on the NeuCLIR dataset (75,000 Mandarin documents) using BLADE-C architecture. They compare Top-K and Top-P masking across various sparsity levels (K values from 0.5% to 2% of vocabulary, P values from 0.25 to 0.99). Results show that Top-P Dynamic Masking consistently outperforms Top-K masking, achieving similar or better Mean Average Precision (mAP) with improved query throughput.

## Key Results
- Top-P Dynamic Masking consistently outperforms Top-K masking, achieving similar or better Mean Average Precision (mAP) with improved query throughput
- At p=0.85, Top-P achieves significant improvements in query throughput compared to Top-K at similar mAP scores
- Top-P selects more terms for documents but fewer for queries compared to Top-K, resulting in better overall performance

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Sparsity Per Input
- Claim: Top-P masking enables input-dependent sparsity by selecting terms based on cumulative importance mass rather than a fixed count.
- Mechanism: Terms are sorted by importance weight, then selected until the sum reaches proportion p of total weight. This allows longer/complex documents to naturally retain more terms, while shorter queries retain fewer—without manual tuning per input type.
- Core assumption: Important terms in a document/query concentrate probability mass; distributions differ across inputs.
- Evidence anchors: [abstract] "Top-P selects terms until their cumulative importance reaches proportion p, allowing a dynamic number of terms per document/query." [section 4] Equation (1) defines Sp = min{S⊆V | Σj∈S wj ≥ p Σj∈V wj}, with masking applied outside Sp.

### Mechanism 2: Query-Document Asymmetry Exploitation
- Claim: Top-P implicitly adapts to structural differences between queries and documents, selecting more terms for documents and fewer for queries compared to Top-K at comparable throughput.
- Mechanism: Documents typically contain enough high-weight terms to hit fixed K ceilings under Top-K, while shorter queries often do not. Top-P's cumulative-threshold approach retains high-mass terms for documents but prunes low-mass terms for queries, improving efficiency without sacrificing relevance.
- Core assumption: Queries are shorter/simpler with concentrated importance; documents are longer with more diffuse but substantial mass.
- Evidence anchors: [section 6.1] "Top-P selects more terms for documents but fewer for queries compared to Top-K, resulting in better overall performance." [section 6, Figure 2] Distributions show Top-K hitting the 352-term ceiling for documents, while Top-P (p=0.98) selects more; for queries, Top-P selects fewer on average.

### Mechanism 3: Efficiency-Effectiveness Tradeoff via Thresholding
- Claim: Top-P can achieve similar or better mAP than Top-K with improved query throughput by better balancing term retention.
- Mechanism: By selecting only terms contributing to cumulative mass p, Top-P avoids retaining marginally important terms that increase index size and query latency. At p=0.85, the paper reports notable throughput gains with comparable mAP.
- Core assumption: Marginal terms (low importance weights) contribute less to relevance scoring but add computational overhead.
- Evidence anchors: [abstract] "Top-P Dynamic Masking consistently outperforms Top-K masking, achieving similar or better Mean Average Precision (mAP) with improved query throughput." [section 6.1] "The p-value of 0.85 seems to have a particularly large improvement in query throughput compared to Top-K masking at similar mAP scores."

## Foundational Learning

- Concept: Sparse Representations in Information Retrieval
  - Why needed here: The paper operates on sparse term-weight vectors derived from BERT embeddings. Understanding why sparsity matters (inverted index efficiency, storage, query speed) is prerequisite to grasping the motivation for masking strategies.
  - Quick check question: If vocabulary size |V|=50,000 and K=0.01|V|, how many non-zero terms does Top-K retain per input?

- Concept: Nucleus Sampling (Top-P Sampling)
  - Why needed here: Top-P Dynamic Masking is explicitly inspired by nucleus sampling from LLM text generation. The adaptation moves from token sampling to term selection for IR.
  - Quick check question: In nucleus sampling, if the sorted probabilities are [0.4, 0.3, 0.2, 0.1] and p=0.8, which tokens fall within the nucleus?

- Concept: Inverted Index and Query Throughput
  - Why needed here: The paper measures tradeoffs between mAP (effectiveness) and queries/second (efficiency). Fewer indexed terms per query typically yield faster lookups but may reduce recall.
  - Quick check question: How does reducing the number of terms per query in an inverted index affect query throughput vs. recall?

## Architecture Onboarding

- Component map:
  - Input: Query (English) or Document (Mandarin) → Tokenization
  - Encoder: mBERT/BLADE-C → contextual embeddings
  - SparTerm layer: Linear → GeLU → vocabulary-sized importance weights wj (RELU + log aggregation)
  - Post-processing: Top-P masking (sort → cumulative sum → threshold at p) OR Top-K masking (sort → keep top k)
  - Indexing: Anserini builds inverted index from sparse vectors
  - Retrieval: Query sparse vector → dot product scoring (MaxP) via Anserini → ranked results

- Critical path:
  1. Passage splitting (≤256 tokens)
  2. BLADE-C inference to produce importance weights
  3. Top-P masking: sort weights descending, accumulate until ≥p×total, zero out remainder
  4. Index non-zero (term, weight) pairs
  5. At search time, process query similarly and score via MaxP

- Design tradeoffs:
  - Higher p (e.g., 0.95–0.99): More terms retained → higher mAP potential, larger index, slower queries
  - Lower p (e.g., 0.50–0.75): Fewer terms → faster queries, risk of recall loss
  - Separate p for queries vs. documents: Potential optimization (per RQ2) but adds hyperparameter complexity
  - Time complexity: Both Top-K and Top-P are O(|V| log |V|); Top-P adds O(|V|) for cumulative sum

- Failure signatures:
  - Flat weight distributions → most/all terms selected (p near 1.0), defeating sparsity
  - Very low p on short queries → near-zero terms, query fails to match
  - Vocabulary/pruning mismatch (CLIR-specific) → cross-lingual terms missing from pruned mBERT vocab
  - Indexing time blowup at high p (paper reports ~43 min increase for full dataset at p=0.98 vs. Top-K k=352)

- First 3 experiments:
  1. Reproduce Top-K baseline (k=352) on 75k subset: measure mAP and queries/second to confirm reference point.
  2. Sweep Top-P (p ∈ {0.25, 0.45, 0.65, 0.85, 0.95, 0.99}) on same subset: plot mAP vs. throughput curve against Top-K.
  3. Analyze term distributions: For matched throughput (e.g., p=0.98 vs. k=352), plot histograms of terms selected per document and per query to verify asymmetric selection behavior.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the performance improvements of Top-P masking over Top-K masking remain statistically significant when evaluated on the full NeuCLIR corpus?
- Basis in paper: [explicit] The authors explicitly state in the disclaimer that results are based on a "partial subset of the dataset" and "formal statistical significance testing has not been performed."
- Why unresolved: The observed improvements in mAP and throughput were derived from only 75,000 of the 3,179,209 available documents, leaving the statistical robustness of the findings unverified.
- What evidence would resolve it: Evaluation results on the complete dataset accompanied by p-values or confidence intervals to confirm significance.

### Open Question 2
- Question: Does the optimal probability mass threshold (p) for Top-P masking generalize to languages with non-logographic writing systems?
- Basis in paper: [inferred] The experiment is restricted to the Mandarin subset of the NeuCLIR dataset, despite the authors referencing the availability of Farsi and Russian documents in the related work.
- Why unresolved: The distribution of term importance weights (which determines how many terms fall within mass p) may differ significantly between morphologically distinct languages like Mandarin and Russian.
- What evidence would resolve it: Benchmarking Top-P masking performance on the Russian and Farsi NeuCLIR subsets using the hyperparameters identified for Mandarin.

### Open Question 3
- Question: How does Top-P masking compare to FLOPS regularization in terms of the efficiency-effectiveness trade-off?
- Basis in paper: [inferred] The paper positions Top-P as an improvement over Top-K (which was a simpler alternative to FLOPS), but it does not evaluate Top-P against the FLOPS regularization baseline explicitly mentioned in the related work.
- Why unresolved: While Top-P outperforms Top-K, it is unknown if the dynamic masking approach is superior to the learned sparsity patterns induced by FLOPS regularization.
- What evidence would resolve it: A direct comparison of retrieval effectiveness and indexing speed between Top-P post-processing and FLOPS-regularized sparse representations.

## Limitations

- The paper's claims are based on a single dataset (NeuCLIR Mandarin) and specific architecture (BLADE-C), limiting generalizability
- Performance improvements are measured primarily through query throughput, with limited discussion of memory usage or indexing time tradeoffs at extreme p values
- Claims about universal superiority of Top-P over Top-K for all sparsity levels and query types are not well-supported

## Confidence

- **High Confidence**: The fundamental mechanism of Top-P masking (selecting terms until cumulative importance reaches proportion p) is clearly described and mathematically defined. The basic experimental setup using BLADE-C and NeuCLIR is reproducible given access to the model weights.
- **Medium Confidence**: The observed performance improvements (mAP gains and throughput benefits) are likely reproducible under similar conditions, though the magnitude may vary with different datasets, embedding models, or evaluation metrics.
- **Low Confidence**: Claims about the universal superiority of Top-P over Top-K for all sparsity levels and query types are not well-supported. The paper doesn't adequately address scenarios where Top-K might be preferable (e.g., very short queries, documents with flat importance distributions).

## Next Checks

1. **Cross-Dataset Validation**: Test Top-P Dynamic Masking on a different CLIR dataset (e.g., CLEF collections or other multilingual retrieval benchmarks) to assess generalizability beyond NeuCLIR Mandarin.

2. **Vocabulary Distribution Analysis**: Conduct experiments to measure the actual distribution of term importance weights across queries and documents. This would validate the assumption that documents have more diffuse but substantial mass compared to queries.

3. **Edge Case Behavior**: Systematically test Top-P at extreme p values (very low p < 0.25 and very high p > 0.98) to identify breaking points where the method fails or becomes equivalent to no masking, documenting the specific failure conditions.