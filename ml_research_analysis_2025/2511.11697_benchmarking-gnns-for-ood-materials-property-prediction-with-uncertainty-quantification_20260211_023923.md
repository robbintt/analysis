---
ver: rpa2
title: Benchmarking GNNs for OOD Materials Property Prediction with Uncertainty Quantification
arxiv_id: '2511.11697'
source_url: https://arxiv.org/abs/2511.11697
tags:
- materials
- uncertainty
- prediction
- property
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MatUQ introduces a benchmark framework for evaluating GNNs in OOD
  materials property prediction with uncertainty quantification. The framework includes
  1,375 OOD tasks from six datasets using SOAP-LOCO and five OFM-based splitting strategies,
  uncertainty-aware training combining Monte Carlo Dropout and Deep Evidential Regression,
  and novel metrics D-MAE and D-EviU.
---

# Benchmarking GNNs for OOD Materials Property Prediction with Uncertainty Quantification

## Quick Facts
- arXiv ID: 2511.11697
- Source URL: https://arxiv.org/abs/2511.11697
- Authors: Liqin Tan; Pin Chen; Menghan Liu; Xiean Wang; Jianhuan Cen; Qingsong Zou
- Reference count: 40
- Key outcome: MatUQ introduces a benchmark framework for evaluating GNNs in OOD materials property prediction with uncertainty quantification, reducing prediction errors by 70.6% on average.

## Executive Summary
This paper introduces MatUQ, a comprehensive benchmark framework for evaluating Graph Neural Networks (GNNs) on out-of-distribution (OOD) materials property prediction tasks with uncertainty quantification. The framework addresses a critical gap in materials science by providing 1,375 OOD tasks across six diverse datasets using both traditional OFM-based splitting strategies and a novel SOAP-LOCO approach that captures local atomic environments. The authors propose a unified uncertainty-aware training protocol combining Monte Carlo Dropout and Deep Evidential Regression, achieving significant error reductions. MatUQ also introduces novel metrics including D-EviU that show strong correlation with prediction errors, revealing that no single GNN model dominates across all properties.

## Method Summary
MatUQ is a benchmark framework for evaluating GNNs in OOD materials property prediction with uncertainty quantification. It includes six datasets (D1-D6) from MatBench and SuperCon3D, generating 1,375 OOD tasks using five OFM-based splitting strategies plus SOAP-LOCO clustering based on local atomic environments. The framework implements a unified training protocol combining Monte Carlo Dropout (spatial dropout rate=0.1) and Deep Evidential Regression with Normal Inverse-Gamma distribution. Models are trained with DER loss incorporating both negative log-likelihood and regularization terms. Inference uses T=50 stochastic forward passes to compute five metrics: MAE, EviU, D-MAE, D-Unc, and D-EviU. The framework evaluates 12 GNN architectures with modified output layers for uncertainty estimation.

## Key Results
- The uncertainty-aware training approach combining Monte Carlo Dropout and Deep Evidential Regression reduces prediction errors by 70.6% on average across challenging OOD scenarios.
- SOAP-LOCO data-splitting strategy creates more challenging OOD scenarios than existing OFM-based methods, generating the highest MAE for most datasets.
- The D-EviU metric shows the strongest correlation with prediction errors in most tasks, outperforming standalone uncertainty measures.
- No single GNN model dominates universally across all properties, with newer transformer-based models (CrystalFramer, SODNet) excelling on specific properties while older models like SchNet and ALIGNN remain competitive.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A unified training protocol combining Monte Carlo Dropout (MCD) and Deep Evidential Regression (DER) reduces prediction errors in OOD materials property prediction tasks.
- **Mechanism:** Dropout provides stochastic regularization during training, mitigating overfitting. DER models both epistemic and aleatoric uncertainty via a Normal Inverse-Gamma (NIG) distribution in a single forward pass. Their combination ensures robust uncertainty calibration (evidential loss) and enhanced generalization (dropout).
- **Core assumption:** The combination of these two techniques provides complementary benefits that neither provides alone, and the NIG distribution is a suitable prior for the materials property prediction tasks.
- **Evidence anchors:** [abstract] "...reducing errors by an average of 70.6% across challenging OOD scenarios." [Table 3] "MatUQ achieves an average MAE reduction of 70.61% across datasets D1-D3..."
- **Break condition:** If the regularization weight `λ` in the DER loss is not properly tuned, the model may prioritize accuracy over calibration, or vice versa. Excessively high dropout rates can also prevent the model from learning meaningful features.

### Mechanism 2
- **Claim:** The SOAP-LOCO data-splitting strategy creates more challenging and realistic OOD scenarios for evaluating GNNs than existing OFM-based methods.
- **Mechanism:** SOAP-LOCO uses Smooth Overlap of Atomic Positions (SOAP) descriptors to encode fine-grained local atomic environments, which directly affect GNN message passing. Materials are clustered based on these local descriptors using k-means. Each cluster is treated as an OOD test set, forcing the model to generalize to structurally distinct local environments absent from training.
- **Core assumption:** Local atomic environments are more critical for GNN generalization than global structural features captured by OFM.
- **Evidence anchors:** [abstract] "SOAP-LOCO... captures local atomic environments more effectively." [Table 2] "SOAP-LOCO generates the highest MAE for most datasets (D2-D6)..."
- **Break condition:** K-means clustering may produce highly unequal cluster sizes, leading to OOD tasks with too few samples for meaningful evaluation. Computing SOAP descriptors can be prohibitively expensive for very large datasets.

### Mechanism 3
- **Claim:** The D-EviU (Dropout-enhanced Evidential Uncertainty) metric provides a more robust and correlated measure of prediction error than standalone metrics.
- **Mechanism:** D-EviU integrates evidential uncertainty from DER with Monte Carlo Dropout's stochastic passes. By averaging the NIG distribution parameters over T forward passes, it quantifies both epistemic and aleatoric uncertainties, providing a more complete measure of total uncertainty.
- **Core assumption:** Combining stochastic passes with evidential parameters yields a superior estimate of total uncertainty, and averaging NIG parameters is a valid aggregation method.
- **Evidence anchors:** [abstract] "...D-EviU, which shows the strongest correlation with prediction errors in most tasks." [Table 4] "Spearman correlations... D-EviU shows the highest values for D2, D3, D4, and D6."
- **Break condition:** If the number of Monte Carlo forward passes T is too low, the variance estimate will be poor. If T is too high, inference time becomes impractical.

## Foundational Learning

- **Concept: Out-of-Distribution (OOD) Generalization**
  - **Why needed here:** The entire MatUQ benchmark evaluates GNNs not on random splits, but on data structurally distinct from training, which is the realistic scenario for discovering novel materials.
  - **Quick check question:** If a GNN trained on metal alloys achieves low error on a random 20% test split, will it necessarily perform well on a brand new ceramic material? Why or why not?

- **Concept: Uncertainty Quantification (UQ) - Epistemic vs. Aleatoric**
  - **Why needed here:** MatUQ uses DER to estimate both types. Aleatoric uncertainty is irreducible data noise; epistemic uncertainty is reducible uncertainty due to lack of knowledge, critical for assessing OOD reliability.
  - **Quick check question:** For a material in a sparse region of training space, which uncertainty type would be dominant and what does it imply?

- **Concept: Graph Neural Networks (GNNs) for Materials**
  - **Why needed here:** The paper benchmarks 12 architectures. Understanding how GNNs represent crystals as graphs (atoms as nodes, bonds as edges) is required to appreciate architectural differences.
  - **Quick check question:** How does a GNN create a representation for a crystal, and why might local atomic environments be more important for this than global descriptors?

## Architecture Onboarding

- **Component map:** 6 datasets + 5 OFM-based + 1 SOAP-LOCO splitter -> 1,375 OOD tasks -> 12 GNN models with uncertainty-aware modifications -> T=50 stochastic inference -> 5 metrics computation
- **Critical path:** 1. Select dataset and OOD splitting strategy (e.g., D2 with SOAP-LOCO) 2. Initialize GNN model and add uncertainty-aware modifications (dropout layer, DER loss head) 3. Train on designated training split 4. Run inference using both deterministic and stochastic (T=50) modes 5. Compute all five metrics and evaluate performance
- **Design tradeoffs:**
  - OFM vs. SOAP splits: OFM is computationally cheaper but may create "easier" OOD splits. SOAP-LOCO is expensive but more rigorous.
  - Metric Selection: D-EviU is more computationally intensive but better correlated with error. EviU is faster but less robust.
  - Model Complexity: Newer transformer-based models (M9-M12) show improved UQ but higher costs. Older convolutional models are faster but may have worse calibration.
- **Failure signatures:**
  - Catastrophic UQ failure: Extremely high uncertainty values (e.g., 2.7e+16 for SchNet on D6), indicating predictions are meaningless.
  - Overconfident OOD errors: Low uncertainty with high MAE, suggesting poor calibration for OOD samples.
  - Failed DER Convergence: `NaN` or diverging loss, often from inappropriate `λ` or poor data scaling.
  - SOAP Computation Crash: Out-of-memory errors for large crystal structures.
- **First 3 experiments:**
  1. Reproduce a key result: Train SchNet (M2) on the D3 dataset using SOAP-LOCO with and without uncertainty-aware training. Compare MAE reduction to the ~84% reported.
  2. Benchmark a new model: Integrate a new GNN into the framework. Evaluate on one OFM and one SOAP-LOCO split of D2 (log_gvrh), reporting D-EviU and D-MAE.
  3. Stress-test the OOD split: Train a simple linear model on the same D2/SOAP-LOCO split. Compare its performance to GNNs to isolate the splitting strategy's contribution from the model's ability to learn structural representations.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can more sophisticated uncertainty calibration techniques further improve the reliability of GNN predictions beyond the current Monte Carlo Dropout and Deep Evidential Regression (DER) protocol?
- **Basis in paper:** [explicit] The conclusion states that future work will focus on "exploring more sophisticated uncertainty calibration techniques" to address the challenges identified in the study.
- **Why unresolved:** The current benchmark establishes a baseline using DER and MCD, but does not evaluate advanced calibration layers that might better align predicted uncertainty with actual error rates.
- **What evidence would resolve it:** Experiments integrating methods like temperature scaling or conformal prediction into the MatUQ pipeline, demonstrating improved correlation or calibration metrics over D-EviU.

### Open Question 2
- **Question:** What specific architectural inductive biases are required to consistently improve performance on complex quantum mechanical properties like superconductivity, where current models show high variance?
- **Basis in paper:** [explicit] The conclusion notes that "quantum mechanical properties, such as superconductivity... are harder to predict" and that models exhibit "significant performance variations" on the SuperCon3D dataset (D6).
- **Why unresolved:** While the paper identifies that angular information (ALIGNN) helps, no single architecture reliably solves this, and some models (e.g., SchNet) fail catastrophically on superconducting transition temperatures.
- **What evidence would resolve it:** A GNN architecture specifically designed for many-body quantum effects that maintains low MAE and high uncertainty correlation on the SuperCon3D dataset compared to existing baselines.

### Open Question 3
- **Question:** Why does the proposed D-EviU metric fail to outperform the standard EviU metric on the dielectric dataset (D1), and can the metric be generalized to optical properties?
- **Basis in paper:** [inferred] Table 4 shows that while D-EviU is the dominant metric for 4 out of 6 datasets, the standard EviU yields a significantly higher Spearman correlation (0.6114 vs 0.4295) for the dielectric dataset (D1).
- **Why unresolved:** The paper does not provide a theoretical justification for why the dropout-enhanced metric degrades performance specifically for optical properties, despite claiming D-EviU's superiority in the abstract.
- **What evidence would resolve it:** An analysis of the feature distributions for dielectric materials explaining why stochastic forward passes (dropout) reduce the correlation between uncertainty estimates and prediction errors.

## Limitations

- The framework's computational cost is substantial—generating 1,375 tasks and running 50 forward passes per prediction limits practical adoption for real-time materials discovery.
- The reproducibility of the 70.6% error reduction is contingent on precise hyperparameter tuning, particularly the DER regularization weight λ and dropout rate.
- The benchmark does not evaluate scaling to multi-million sample regimes or dynamic materials discovery scenarios where data distribution shifts continuously.

## Confidence

- **High Confidence:** The observed superiority of SOAP-LOCO for creating challenging OOD splits is well-supported by systematic comparisons showing consistently higher MAE across datasets.
- **Medium Confidence:** The correlation claims for D-EviU with prediction errors are supported within the tested datasets but may not generalize to properties with fundamentally different uncertainty characteristics.
- **Low Confidence:** The claim that no single model dominates universally is based on a specific set of 12 models and 6 datasets.

## Next Checks

1. **Hyperparameter Sensitivity Analysis:** Systematically vary λ in the DER loss (e.g., λ ∈ {0.1, 1, 10}) and dropout rate (p ∈ {0.05, 0.1, 0.2}) to quantify their impact on the 70.6% error reduction claim and identify optimal settings per dataset.

2. **Generalization to New Property Families:** Apply the MatUQ framework to a dataset with a property type not represented in the current benchmark (e.g., thermal conductivity or mechanical properties) to test the universality of the SOAP-LOCO advantage and D-EviU metric correlation.

3. **Computational Cost-Benefit Analysis:** Profile the runtime for generating SOAP descriptors, training models with uncertainty quantification, and performing T=50 stochastic passes. Compare this to the accuracy gains to determine practical feasibility for real-world materials discovery pipelines.