---
ver: rpa2
title: Improving Unlearning with Model Updates Probably Aligned with Gradients
arxiv_id: '2511.02435'
source_url: https://arxiv.org/abs/2511.02435
tags:
- unlearning
- data
- machine
- update
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses machine unlearning by formulating it as a\
  \ constrained optimization problem. The authors introduce feasible updates\u2014\
  parameter update directions that help with unlearning while preserving utility\u2014\
  based on masking and statistical guarantees from batch processing."
---

# Improving Unlearning with Model Updates Probably Aligned with Gradients

## Quick Facts
- **arXiv ID**: 2511.02435
- **Source URL**: https://arxiv.org/abs/2511.02435
- **Reference count**: 40
- **Primary result**: Introduces a focus vector method that improves unlearning efficacy and efficiency by masking updates based on gradient alignment probability, reducing MIA scores and accelerating convergence.

## Executive Summary
This paper addresses the challenge of machine unlearning by formulating it as a constrained optimization problem. The authors propose a novel "focus vector" approach that identifies and updates parameters most relevant to forgetting data while preserving model utility. By leveraging statistical guarantees from batch processing and masking update directions based on gradient alignment probability, the method improves both the effectiveness and efficiency of unlearning. Experiments on CIFAR-10 and SVHN with VGG16 and ResNet18 demonstrate significant improvements over baseline methods like SalUn and NGPlus in terms of lower membership inference attack scores and faster convergence to desired unlearning accuracy.

## Method Summary
The method introduces a plug-in "Focus Vector" component for first-order unlearning techniques (SRL, NGPlus, SCRUB). It computes a focus vector based on the probability that gradients agree on sign, derived from batch gradient variance estimates obtained from Adam optimizer moments. This focus vector acts as a mask on the aggregated gradient update, prioritizing parameters that contribute most to forgetting while maintaining utility on retained data. The approach is evaluated through membership inference attacks and relative unlearning accuracy metrics across different unlearning fractions and datasets.

## Key Results
- Significantly lower membership inference attack (MIA) scores compared to SalUn and NGPlus baselines
- Faster convergence to target unlearning accuracy across all tested datasets and model architectures
- Improved efficiency with fewer epochs needed to achieve desired unlearning performance
- Maintains retain accuracy while effectively reducing influence of forget set data

## Why This Works (Mechanism)
The focus vector mechanism works by identifying parameters whose updates are most likely to align with the unlearning objective while preserving utility. By computing the probability that gradients from different batches share the same sign, the method creates a statistical guarantee about which parameters to update. The masking approach ensures that only parameters with high alignment probability receive updates, reducing noise and improving convergence. This selective updating strategy addresses the fundamental challenge of unlearning: removing influence of specific data while maintaining overall model performance.

## Foundational Learning
- **Membership Inference Attacks**: Needed to evaluate unlearning effectiveness; quick check is whether attack model can distinguish forget set from test set
- **Gradient Variance Estimation**: Critical for computing alignment probability; verify by checking variance values are reasonable
- **Batch Processing Statistics**: Used to derive focus vector; ensure batch size and gradient computation are consistent
- **Constrained Optimization**: Framework for unlearning problem formulation; confirm constraints on retain accuracy are satisfied
- **First-Order Unlearning Methods**: Base techniques being enhanced; verify baseline implementations match original papers

## Architecture Onboarding

**Component Map**
Base model training -> Focus Vector computation -> Masked gradient update -> Unlearning loop -> Evaluation (MIA, rUA)

**Critical Path**
1. Train initial model (100 epochs)
2. Implement Focus Vector logic within unlearning loop
3. Run unlearning for 10 epochs with evaluation
4. Compute MIA scores and rUA metrics

**Design Tradeoffs**
- Computational overhead of focus vector calculation vs. convergence speedup
- Batch size impact on gradient variance estimation accuracy
- Choice between different first-order unlearning base methods
- Balance between unlearning aggressiveness and retain accuracy preservation

**Failure Signatures**
- Model divergence with NGPlus (limit to 1-2 epochs or monitor RA)
- Stalling updates when gradient variance is overestimated (check focus vector density)
- MIA classifier failure to distinguish forget vs test sets (verify attack setup)
- rUA not improving despite epochs (check focus vector implementation)

**First Experiments**
1. Verify base model training achieves expected accuracy on CIFAR-10
2. Implement and test focus vector calculation on a single batch
3. Run unlearning with SRL baseline and confirm MIA scores decrease

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- NGPlus component prone to destroying model capabilities, limiting practical applicability
- MIA evaluation setup only partially specified (attack model hyperparameters need inference)
- Handling of Adam optimizer states during unlearning could impact results
- Stability constant ε for focus vector computation not explicitly valued

## Confidence
- **High**: Theoretical formulation of focus vector, overall unlearning methodology, baseline definitions
- **Medium**: Implementation details of MIA evaluation, handling of Adam states, stability constant choice
- **Low**: Exact performance parity across all datasets and model architectures (due to possible implementation variance)

## Next Checks
1. Verify MIA classifier hyperparameters and data splits match the paper's experimental protocol
2. Test unlearning with and without carrying over Adam optimizer moments to confirm impact on gradient alignment estimation
3. Perform ablation on the stability constant ε to ensure focus vector remains well-conditioned