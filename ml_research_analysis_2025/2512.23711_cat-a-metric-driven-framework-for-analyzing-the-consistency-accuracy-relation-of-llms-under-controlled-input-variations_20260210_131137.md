---
ver: rpa2
title: 'CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation
  of LLMs under Controlled Input Variations'
arxiv_id: '2512.23711'
source_url: https://arxiv.org/abs/2512.23711
tags:
- consistency
- accuracy
- llms
- which
- core
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CAT, a framework for evaluating the interplay
  between accuracy and consistency of LLMs under controlled input variations, using
  multiple-choice benchmarks. The key contribution is the CAR (Consistency-Accuracy
  Relation) curve, which visualizes how model accuracy changes as consistency requirements
  increase, formalized through the MCA (Minimum-Consistency Accuracy) metric.
---

# CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations

## Quick Facts
- arXiv ID: 2512.23711
- Source URL: https://arxiv.org/abs/2512.23711
- Reference count: 12
- Primary result: Introduces CAR curves and CORE index to reveal accuracy-consistency trade-offs that traditional metrics miss

## Executive Summary
CAT is a framework that evaluates how Large Language Models' accuracy degrades as consistency requirements increase under controlled input variations. Using multiple-choice benchmarks, the framework generates variant inputs (e.g., shuffled answer choices) and measures both accuracy and response consistency. The key contribution is the CAR (Consistency-Accuracy Relation) curve, which visualizes the relationship between accuracy and minimum consistency thresholds, formalized through the MCA (Minimum-Consistency Accuracy) metric. The CORE index combines area under the CAR curve with its deviation from an ideal perfectly consistent model, providing a nuanced evaluation that traditional accuracy metrics miss.

## Method Summary
CAT evaluates LLMs by generating M reordered variants per question, running inference on all variants, and computing response consistency (RC) for each question. The framework sweeps through consistency thresholds c ∈ [0,1] to build CAR curves showing how accuracy changes as consistency requirements tighten. Key metrics include MCA(c) (accuracy conditioned on consistency ≥ c), AUCAR (area under the CAR curve), and CORE (AUCAR × normalized DTW distance to ideal curve). The framework uses 10 variants per question, greedy decoding, and applies to 8 LLMs across 4 benchmarks (MedQA, MMLU-Redux, ARC, TruthQA) with varying shot counts for inference.

## Key Results
- CAR curves reveal behavioral patterns: low-performing models show concave curves (rapid accuracy drop), while high-performing models exhibit convex patterns (accuracy preserved longer)
- Models can exhibit negative bias, performing worse than random on low-consistency samples
- CORE and MCA(1.0) grow more gradually than traditional metrics (MCQs+, MV), offering better model differentiation and reducing early saturation
- CORE index combines AUCAR with DTW-based curve shape similarity, penalizing both low accuracy and non-ideal curve convexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Varying consistency thresholds reveals accuracy degradation patterns that single-threshold metrics miss
- Mechanism: MCA(c) computes accuracy conditioned on minimum consistency level c across input variants by sweeping c from 0.0 to 1.0
- Core assumption: Input variations are meaning-equivalent and should elicit consistent responses from robust models
- Evidence anchors: CAR curves visualize MCA variation; related work (CoRA) supports perturbation strategy
- Break condition: Semantic drift in input variants invalidates consistency penalties

### Mechanism 2
- Claim: CORE index differentiates models better than MCQA+ or MV by penalizing both low area and non-ideal curve shape
- Mechanism: CORE = AUCAR × norm-DTW measures overall performance and curve similarity to ideal horizontal line
- Core assumption: Ideal model maintains perfect accuracy at all consistency levels; deviation indicates brittleness
- Evidence anchors: norm-DTW normalizes against worst-case curve; product ensures dual constraint
- Break condition: DTW distance poorly correlates with perceived robustness

### Mechanism 3
- Claim: Consistency-aware metrics grow more gradually than traditional accuracy metrics, improving model differentiation
- Mechanism: MCQA+ and MV saturate quickly while CORE and MCA(1.0) exhibit slower, more discriminative slopes
- Core assumption: High accuracy with low consistency reflects superficial pattern matching
- Evidence anchors: CORE and MCA(1.0) show slopes of 0.059, 0.048, 0.031 on benchmarks
- Break condition: Questions require legitimately different reasoning across variants

## Foundational Learning

- Concept: Response Consistency (RC_i = correct_count / total_variants)
  - Why needed here: MCA(c) thresholds RC_i values; understanding this ratio is prerequisite to interpreting CAR curves
  - Quick check question: If a model answers 7/10 variants correctly, what is its response consistency? (Answer: 0.7)

- Concept: Dynamic Time Warping (DTW)
  - Why needed here: CORE uses DTW to measure curve shape similarity; engineers must understand DTW measures alignment distance
  - Quick check question: Why use DTW instead of simple L2 distance for comparing CAR curves? (Answer: DTW handles non-linear temporal/axis alignment better)

- Concept: Area Under Curve (AUC) Integration
  - Why needed here: AUCAR requires numerical integration; understanding discretization error matters for metric reliability
  - Quick check question: With 10 consistency thresholds, how many trapezoids are computed for AUCAR? (Answer: 9)

## Architecture Onboarding

- Component map: Input Generator → Inference Engine → Response Parser → RC Calculator → MCA Aggregator → CAR Builder → CORE Computer
- Critical path: Input Generator → Inference Engine → RC Calculator → MCA Aggregator → CAR Builder → CORE Computer. Inference dominates runtime (N questions × M variants)
- Design tradeoffs:
  - More variants (M) → finer RC granularity but higher inference cost
  - Threshold granularity (K points) → smoother CAR curves vs. computation
  - DTW vs. simpler shape metrics → DTW captures non-linear deviations but adds complexity
  - Open-ended extension → requires similarity function (BLEU, cosine, LLM-judge) with its own biases
- Failure signatures:
  - Flat CAR curve at y=0.0 → model never achieves consistency threshold
  - CAR curve starts below chance → negative bias; model worse than random on low-consistency samples
  - CORE ≈ AUCAR → DTW ≈ 1.0 (curve shape matches ideal)
  - MCA(1.0) >> MV → strict consistency surprisingly high
- First 3 experiments:
  1. Validate on synthetic random-answering models (2, 5, 10 choices) to confirm CAR curves match theoretical expectations
  2. Run CAT on 2-3 models from Table 1 on MedQA to verify concave vs. convex patterns
  3. Extend to open-ended evaluation: adapt Ψ to BLEU or cosine similarity on a small QA dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does CAT generalize to open-ended tasks when using continuous similarity scoring functions?
- Basis in paper: Section 5 outlines extension to open-ended benchmarks through adaptable scoring functions but states implementation and validation is an important next step
- Why unresolved: Only validated on multiple-choice benchmarks; open-ended extension remains theoretical
- What evidence would resolve it: Empirical results on summarization, free-form QA, or generative reasoning tasks

### Open Question 2
- Question: How do different input perturbation strategies affect CAR curves and consistency-accuracy trade-off?
- Basis in paper: Section 4.1 uses only choice reordering but mentions other perturbations in related work
- Why unresolved: Empirical validation uses only one perturbation method
- What evidence would resolve it: Comparative experiments using CAT with multiple perturbation strategies on same models

### Open Question 3
- Question: What normalization strategies or visualizations would improve CORE index interpretability?
- Basis in paper: Section 6 states improving CORE interpretability is essential and suggests normalization strategies
- Why unresolved: Current CORE formulation is challenging to interpret in practical deployment contexts
- What evidence would resolve it: User studies with practitioners or proposed alternative formulations

## Limitations
- Semantic drift: Shuffling strategy's robustness to subtle semantic shifts remains unvalidated
- DTW validation: Novel DTW-based curve comparison lacks external validation against human-annotated robustness rankings
- Unproven generalization: Open-ended extension through adaptable scoring functions is conceptually sound but untested empirically

## Confidence

- High confidence: MCA(c) metric formulation and CAR curve visualization are mathematically sound
- Medium confidence: CORE index construction via AUCAR × norm-DTW is logically coherent
- Medium confidence: Empirical results showing gradual growth of consistency-aware metrics are internally consistent

## Next Checks

1. **Semantic Drift Validation**: Test CAT on benchmarks with known semantic variation to confirm shuffled answer choices maintain meaning-equivalence
2. **DTW Alternative Comparison**: Replace DTW with simpler shape metrics to assess whether additional complexity improves model differentiation meaningfully
3. **Cross-Benchmark Consistency**: Apply CAT to at least two additional benchmarks beyond the four used to test framework generalizability