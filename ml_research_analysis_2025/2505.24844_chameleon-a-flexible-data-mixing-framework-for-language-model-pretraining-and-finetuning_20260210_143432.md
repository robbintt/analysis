---
ver: rpa2
title: 'Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining
  and Finetuning'
arxiv_id: '2505.24844'
source_url: https://arxiv.org/abs/2505.24844
tags:
- domain
- data
- chameleon
- weights
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CHAMELEON introduces a data-centric framework for language model
  pretraining and finetuning that leverages Kernel Ridge Leverage Scores (KRLS) to
  quantify domain importance directly from learned embeddings. Unlike prior methods
  that rely on costly proxy model training, CHAMELEON computes domain weights from
  the intrinsic properties of the data, enabling efficient adaptation to new domains
  without retraining.
---

# Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning
## Quick Facts
- arXiv ID: 2505.24844
- Source URL: https://arxiv.org/abs/2505.24844
- Reference count: 38
- Primary result: CHAMELEON achieves competitive perplexity and downstream task performance at fraction of computational cost of existing methods while maintaining stability across model sizes

## Executive Summary
CHAMELEON introduces a data-centric framework for language model pretraining and finetuning that leverages Kernel Ridge Leverage Scores (KRLS) to quantify domain importance directly from learned embeddings. Unlike prior methods that rely on costly proxy model training, CHAMELEON computes domain weights from the intrinsic properties of the data, enabling efficient adaptation to new domains without retraining. The method employs inverse KRLS-based weights during pretraining to promote general knowledge learning and direct KRLS-based weights during finetuning to emphasize task-specific knowledge. Experiments on SlimPajama and Pile datasets show that CHAMELEON achieves competitive perplexity and downstream task performance at a fraction of the computational cost of existing methods like DoReMi and DoGE, while maintaining stability across different model sizes and hyperparameters.

## Method Summary
CHAMELEON leverages Kernel Ridge Leverage Scores (KRLS) to quantify domain importance directly from learned embeddings, eliminating the need for costly proxy model training. The framework uses inverse KRLS-based weights during pretraining to promote general knowledge learning across diverse domains, and switches to direct KRLS-based weights during finetuning to emphasize task-specific knowledge. This approach enables efficient adaptation to new domains without requiring retraining while maintaining computational efficiency compared to existing data-mixing methods like DoReMi and DoGE.

## Key Results
- Achieves competitive perplexity scores compared to DoReMi and DoGE baselines
- Demonstrates improved downstream task performance across tested domains
- Requires significantly less computational resources than proxy model-based methods
- Maintains stability across different model sizes and hyperparameter configurations

## Why This Works (Mechanism)
CHAMELEON works by leveraging Kernel Ridge Leverage Scores (KRLS) to quantify domain importance directly from learned embeddings rather than relying on proxy model training. During pretraining, inverse KRLS-based weights promote general knowledge learning across diverse domains by preventing overfitting to any single domain. During finetuning, direct KRLS-based weights emphasize task-specific knowledge by focusing on domains most relevant to the target task. This dynamic weighting strategy allows the model to efficiently adapt to new domains without retraining while maintaining computational efficiency.

## Foundational Learning
- **Kernel Ridge Leverage Scores (KRLS)**: A measure of data point importance in kernel ridge regression that quantifies how much each data point influences the learned model. Needed to identify domain importance without proxy model training; quick check: verify KRLS values correlate with downstream task performance.
- **Data-mixing strategies**: Methods for combining multiple data sources during pretraining to improve model generalization. Needed to balance learning across diverse domains; quick check: compare perplexity across domains with different mixing ratios.
- **Domain importance quantification**: The process of determining which data domains contribute most to model performance. Needed to allocate training resources effectively; quick check: measure downstream task improvement when emphasizing high-importance domains.

## Architecture Onboarding
- **Component map**: Data domains → KRLS computation → Weight assignment (inverse for pretraining, direct for finetuning) → Model training → Performance evaluation
- **Critical path**: KRLS computation → Weight assignment → Model training → Evaluation
- **Design tradeoffs**: Computational efficiency vs. accuracy in domain importance quantification; simplicity vs. flexibility in weight assignment strategy
- **Failure signatures**: Poor performance on specific domains despite high KRLS scores; instability in weight assignment leading to training divergence
- **First experiments**: 1) Test KRLS-based weighting on synthetic datasets with known domain importance, 2) Compare pretraining performance with uniform vs. inverse KRLS weighting, 3) Evaluate finetuning performance with direct KRLS weighting on target tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical relationship between KRLS values and actual domain utility requires further empirical validation across diverse domain types
- Limited experimental scope focused primarily on SlimPajama and Pile datasets may not capture framework behavior on more heterogeneous domains
- Method's robustness to significant domain shifts and extreme domain imbalance scenarios not extensively explored

## Confidence
- **High**: Computational efficiency claims compared to proxy model-based methods are well-supported
- **Medium**: Empirical results showing competitive performance are convincing within tested conditions
- **Low**: Theoretical justification for inverse vs. direct KRLS weighting lacks comprehensive empirical validation

## Next Checks
1. Evaluate CHAMELEON's performance on specialized domains like legal, medical, and technical writing to assess generalization beyond natural language and code datasets
2. Test framework stability when pretraining data follows extreme class imbalance distributions (e.g., 99:1 domain ratio)
3. Apply CHAMELEON to different model architectures (encoder-decoder models, smaller transformer variants) to evaluate cross-architecture effectiveness