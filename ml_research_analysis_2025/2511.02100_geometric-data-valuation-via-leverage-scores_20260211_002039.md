---
ver: rpa2
title: Geometric Data Valuation via Leverage Scores
arxiv_id: '2511.02100'
source_url: https://arxiv.org/abs/2511.02100
tags:
- data
- leverage
- shapley
- learning
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces ridge leverage scores as a geometric, model-agnostic\
  \ alternative to Shapley data valuation for quantifying the importance of individual\
  \ datapoints. By leveraging statistical leverage scores\u2014which measure how much\
  \ each point extends the span of the dataset\u2014the method provides a computationally\
  \ efficient proxy for Shapley values that satisfies key axioms like symmetry, efficiency,\
  \ and (in the non-ridge case) dummy."
---

# Geometric Data Valuation via Leverage Scores

## Quick Facts
- arXiv ID: 2511.02100
- Source URL: https://arxiv.org/abs/2511.02100
- Reference count: 29
- Primary result: Ridge leverage scores provide a computationally efficient proxy for Shapley data valuation, achieving 0.846±0.006 test accuracy on MNIST active learning without gradients or quadratic computation

## Executive Summary
This paper introduces ridge leverage scores as a geometric, model-agnostic alternative to Shapley data valuation for quantifying the importance of individual datapoints. By leveraging statistical leverage scores—which measure how much each point extends the span of the dataset—the method provides a computationally efficient proxy for Shapley values that satisfies key axioms like symmetry, efficiency, and (in the non-ridge case) dummy. Extending to ridge leverage mitigates dimensional saturation and connects naturally to classical experimental design criteria. Theoretically, the paper shows that training on a leverage-sampled subset yields models within O(ε) of the full-data optimum. Empirically, in a small-scale active learning experiment on MNIST, ridge-leverage sampling outperformed standard baselines like K-center, margin, and entropy methods, achieving a final test accuracy of 0.846±0.006 without requiring gradients or quadratic computation. This work positions ridge leverage scores as a principled and tractable approach for data valuation and subset selection.

## Method Summary
The method computes ridge leverage scores on learned feature representations from a model's penultimate layer, then samples data points with probability proportional to these scores. For a dataset X with ridge parameter λ, the ridge leverage score for point i is ℓ_i^(λ) = x_i^T(X^TX + λI)^(-1)x_i, normalized to probabilities π_i^(λ) = ℓ_i^(λ)/Σ_jℓ_j^(λ). The approach avoids the computational intractability of exact Shapley values while satisfying key game-theoretic axioms under specific rank conditions. The ridge regularization prevents dimensional saturation that occurs when the dataset spans the full feature space, ensuring strictly positive marginal gains for new data. The method is validated through active learning on MNIST using a 3-layer MLP, where it outperforms baseline selectors like K-center, margin, entropy, and EGL.

## Key Results
- Ridge leverage scores satisfy symmetry, efficiency, and dummy axioms for span-based utility when rank conditions are met
- Training on a leverage-sampled subset yields models within O(ε) of the full-data optimum for ridge regression
- In MNIST active learning, ridge-leverage sampling achieved 0.846±0.006 test accuracy, outperforming K-center, margin, and entropy baselines
- The method avoids the quadratic computation of Shapley values while maintaining theoretical guarantees

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Statistical leverage scores serve as a non-linear geometric proxy for Data Shapley values, satisfying key axioms (symmetry, efficiency, dummy) under specific rank conditions.
- **Mechanism:** The method calculates the leverage score ℓ_i as the i-th diagonal entry of the projection (hat) matrix H = X(X^⊤ X)^(-1)X^⊤. This quantity measures how much a specific datapoint x_i extends the span of the dataset. By normalizing these scores (π_i = ℓ_i / Σ ℓ_j), the method assigns value based on structural influence rather than combinatorial marginal utility.
- **Core assumption:** The value of a datapoint is primarily determined by its geometric contribution to the span of the feature space (structural diversity) rather than its specific interaction with the loss landscape of a target model.
- **Evidence anchors:**
  - [abstract] "...quantify each datapoint's structural influence... by measuring how much it extends the span..."
  - [section] Theorem 1 proves that φ_U(i) := π_i satisfies symmetry, efficiency, and dummy axioms when utility is defined as the span of the subset.
  - [corpus] Neighbors like KAIROS highlight that standard Shapley is "computationally infeasible," validating the need for a proxy; however, corpus evidence specifically validating leverage scores as a replacement is currently weak or absent.
- **Break condition:** The mechanism fails to satisfy the "dummy" axiom in the ridge-regularized case (Prop 2), meaning redundant points may retain non-zero value, which is a deliberate trade-off for stability.

### Mechanism 2
- **Claim:** Ridge regularization of leverage scores prevents "dimensional saturation," ensuring points continue to receive non-zero value even after the feature space is fully spanned.
- **Mechanism:** Standard leverage scores become zero once the rank of X equals the ambient dimension d. The paper introduces ridge leverage ℓ_i^(λ) = x_i^⊤(X^⊤ X + λI)^(-1)x_i. The regularization term λI ensures that the inverse (X^⊤ X + λI)^(-1) contracts rather than becomes singular, maintaining strictly positive marginal gains for new data.
- **Core assumption:** The utility of data in deep learning behaves more like ridge regression (where variance reduction continues past full rank) than pure linear span extension.
- **Evidence anchors:**
  - [abstract] "...extending them to ridge leverage scores yields strictly positive marginal gains..."
  - [section] "Mitigating Dimensional Saturation" explains that this connects naturally to A- and D-optimal design criteria.
  - [corpus] Not explicitly covered in corpus neighbors.
- **Break condition:** If the regularization parameter λ is misspecified relative to the noise in the data, the valuation may over-value redundant points or under-value critical sparse points.

### Mechanism 3
- **Claim:** Training on a leverage-sampled subset theoretically yields a model whose parameters and risk are within O(ε) of the full-data optimum.
- **Mechanism:** The method samples indices with probability p_i ∝ ℓ_i^(λ). By using Matrix Chernoff bounds (Theorem 4), the authors prove that the sampled covariance matrix X̃^⊤ X̃ spectrally approximates the full matrix X^⊤ X. This ensures that the solution θ̂ derived from the subset is close to the full solution θ* in the A-norm.
- **Core assumption:** The theoretical bounds derived for ridge regression (a linear model) generalize effectively to the active learning experiment on non-linear architectures (MLPs).
- **Evidence anchors:**
  - [abstract] "...training on a leverage-sampled subset produces a model whose parameters and predictive risk are within O(ε) of the full-data optimum..."
  - [section] Theorem 3 details the ε-close bounds for ridge regression.
  - [corpus] Losing is for Cherishing mentions influence functions and Shapley face "prohibitive computational costs," reinforcing the efficiency motivation for this sampling approach.
- **Break condition:** Theoretical guarantees assume a linear model structure (y=Xθ_lin); significant divergence in non-linear active learning settings is possible if the embedding space does not linearize the problem effectively.

## Foundational Learning

- **Concept: Projection (Hat) Matrix H and Leverage**
  - **Why needed here:** The core valuation metric relies on the diagonal entries of H = X(X^⊤ X)^(-1)X^⊤. Without understanding that H_ii measures the "self-influence" or distance from the centroid in feature space, the proposed proxy appears arbitrary.
  - **Quick check question:** If you add a datapoint exactly equal to the mean of the dataset, does its leverage score increase or decrease relative to an outlier?

- **Concept: Shapley Axioms (Symmetry, Efficiency, Dummy)**
  - **Why needed here:** The paper justifies its geometric proxy by proving it satisfies these game-theoretic axioms (mostly). Understanding "Dummy" (zero contribution for zero utility) is critical to understanding why the authors accept its violation in the ridge case to avoid saturation.
  - **Quick check question:** Why does satisfying "Efficiency" (total value equals total utility) matter when designing a data marketplace?

- **Concept: Experimental Design (A- and D-Optimality)**
  - **Why needed here:** The paper connects ridge leverage to classical statistical design criteria. D-optimality relates to maximizing the determinant of the information matrix (volume of confidence ellipsoid), providing a statistical interpretation for the geometric scores.
  - **Quick check question:** Does maximizing D-optimality minimize the variance of the model parameters, or does it minimize the bias?

## Architecture Onboarding

- **Component map:** Raw input x -> Representation Extractor (penultimate layer) -> Feature Space X -> Score Computer (ridge leverage) -> Probabilistic Selector (sampling)
- **Critical path:** The calculation of (X^⊤ X + λI)^(-1). In high dimensions, this is the computational bottleneck. The paper suggests this avoids "quadratic computation" relative to Shapley, but exact inversion is still O(d^3) or requires iterative solvers/approximations for large d.
- **Design tradeoffs:**
  - **Proxy vs. Precision:** You trade the exact marginal utility of Shapley for the geometric approximation of Leverage.
  - **Saturation vs. Dummy Axiom:** You must choose between standard leverage (satisfies Dummy, but saturates at rank d) and ridge leverage (no saturation, but violates Dummy).
  - **Model-agnositicism:** The method requires a representation space (X). In the experiment, this was a "penultimate layer" embedding, implying a dependency on a pre-trained or concurrently trained feature extractor.
- **Failure signatures:**
  - **Saturation Collapse:** If λ is too small and rank reaches d, standard leverage scores go to zero, stalling the valuation/acquisition process.
  - **Embedding Misalignment:** If the feature extractor φ(x) is poor (e.g., random weights), geometric diversity in that space may not correlate with downstream task performance.
- **First 3 experiments:**
  1. **Baseline Verification:** Replicate the MNIST active learning loop using the penultimate layer embeddings to verify that ridge leverage outperforms "Margin" and "Entropy" baselines as claimed (0.846 accuracy).
  2. **Lambda Sensitivity:** Sweep the regularization parameter λ ([10^-4, 10^-1] × Tr(X^TX)/d) to observe the transition between dimensional saturation and stable valuation.
  3. **Linear Probe:** Test the "linear assumption" by applying the method directly to raw pixels vs. learned embeddings to quantify the performance gap introduced by the representation space.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the ε-close guarantees of Theorem 3 be extended to the noisy label setting where observations are contaminated by sub-Gaussian noise?
- **Basis in paper:** [explicit] "The same techniques underlying Theorem 3 can also be extended beyond the noiseless linear model and to derive guarantees in the setting where the labels are contaminated by sub-Gaussian noise. We leave a careful treatment of these extensions to future work."
- **Why unresolved:** The current proof assumes y = Xθ_lin (noiseless), which rarely holds in practice; extending to noisy labels requires additional concentration arguments.
- **What evidence would resolve it:** A theoretical extension proving parameter and risk bounds under sub-Gaussian noise, with empirical validation on noisy datasets.

### Open Question 2
- **Question:** How does ridge-leverage sampling compare to state-of-the-art active learning selectors like BALD, BatchBALD, LESS, or TRAK on larger-scale benchmarks?
- **Basis in paper:** [explicit] "Fully developing these scores into a selector that competes with the state-of-the-art warrants separate, dedicated study so we leave this as future work."
- **Why unresolved:** The MNIST experiment only compared to K-center, margin, entropy, EGL, and random baselines; more sophisticated methods were explicitly excluded.
- **What evidence would resolve it:** Benchmarks on CIFAR-10/100 or ImageNet comparing ridge leverage against BALD, BatchBALD, ActiveMatch, LESS, and TRAK.

### Open Question 3
- **Question:** How sensitive is ridge-leverage valuation to the choice and quality of learned embeddings from which scores are computed?
- **Basis in paper:** [inferred] The method computes leverage scores on 64-dimensional learned embeddings from the penultimate layer, but the theoretical analysis assumes fixed feature representations; embedding quality could substantially affect valuation accuracy.
- **Why unresolved:** No ablation study on embedding choice; poor embeddings could yield misleading valuations.
- **What evidence would resolve it:** Ablation experiments varying embedding dimension, layer depth, and pretraining quality, measuring correlation between leverage scores and true data value.

## Limitations
- Theoretical guarantees are proven for ridge regression but applied to non-linear active learning with MLPs, creating a significant theoretical-practical gap
- The method's effectiveness critically depends on the quality of learned feature representations, but this dependency is not systematically explored
- Experimental validation is limited to MNIST, restricting generalizability to more complex, real-world datasets
- The paper lacks ablation studies on the ridge regularization parameter λ and comparisons against more diverse baseline methods

## Confidence
- **High Confidence:** The geometric mechanism of leverage scores (Mechanism 1) is well-established in statistics and the connection to projection matrices is mathematically sound. The computational efficiency advantage over Shapley is clear.
- **Medium Confidence:** The claim that ridge leverage scores outperform standard baselines in the MNIST active learning experiment is supported by the reported results, but the narrow experimental scope and lack of hyperparameter details prevent full verification. The mechanism for preventing dimensional saturation (Mechanism 2) is theoretically sound but its practical impact is untested across diverse datasets.
- **Low Confidence:** The theoretical claim that training on a leverage-sampled subset yields a model within O(ε) of the full-data optimum (Mechanism 3) is rigorously proven for ridge regression, but the leap to claiming this holds for the non-linear MLP used in the experiment is a significant extrapolation without dedicated proof or extensive empirical validation.

## Next Checks
1. **Ablation Study on Representation Quality:** Re-run the active learning experiment on MNIST using three different feature spaces for leverage computation: (a) the current penultimate layer, (b) raw pixel values, and (c) random embeddings. This will directly test the hypothesis that the representation space is critical to the method's success and quantify the performance drop when the geometric diversity does not align with task-relevant features.
2. **Theoretical Validation for Non-Linear Models:** Design a controlled experiment on a simple, quasi-linear dataset (e.g., a low-degree polynomial regression problem with added noise). Apply the ridge leverage sampling method and compare the empirical risk of the model trained on the sampled subset to the theoretical O(ε) bound derived for ridge regression. This will provide evidence for or against the generalizability of the linear theory.
3. **Robustness Check Across Datasets and Architectures:** Extend the active learning experiment beyond MNIST to include a tabular dataset (e.g., a subset of CIFAR-10 or a UCI dataset) and a different architecture (e.g., a simple CNN). This will test the method's scalability and robustness to different data modalities and model families, moving beyond the single-task, single-architecture validation.