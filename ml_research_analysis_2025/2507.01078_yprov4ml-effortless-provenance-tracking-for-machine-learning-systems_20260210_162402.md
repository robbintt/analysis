---
ver: rpa2
title: 'yProv4ML: Effortless Provenance Tracking for Machine Learning Systems'
arxiv_id: '2507.01078'
source_url: https://arxiv.org/abs/2507.01078
tags:
- provenance
- data
- prov4ml
- learning
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: yProv4ML addresses the challenge of tracking provenance in machine
  learning workflows by providing a framework that captures execution metadata in
  PROV-JSON format with minimal code modifications. The software enables logging of
  artifacts, parameters, metrics, and system information during ML processes, facilitating
  reproducibility and hyperparameter optimization.
---

# yProv4ML: Effortless Provenance Tracking for Machine Learning Systems

## Quick Facts
- arXiv ID: 2507.01078
- Source URL: https://arxiv.org/abs/2507.01078
- Reference count: 15
- Provides framework for capturing ML execution metadata in PROV-JSON format with minimal code modifications

## Executive Summary
yProv4ML addresses the challenge of tracking provenance in machine learning workflows by providing a framework that captures execution metadata in PROV-JSON format with minimal code modifications. The software enables logging of artifacts, parameters, metrics, and system information during ML processes, facilitating reproducibility and hyperparameter optimization. It offers MLFlow-like utilities for intuitive data collection while maintaining interoperability through standard PROV-JSON serialization.

## Method Summary
The framework captures provenance through a PyTorch-based MNIST classification workflow, instrumenting training loops with `prov4ml` hooks including `start_run`, `log_param`, `log_dataset`, `log_metric`, `log_carbon_metrics`, `log_system_metrics`, `save_model_version`, and `end_run`. The method generates a valid PROV-JSON file and SVG provenance graph containing training metrics, carbon metrics, system metrics, and model versions. The implementation was validated through benchmarking experiments on over 500 GPUs and applied to tropical cyclone prediction tasks.

## Key Results
- Successfully captures execution metadata including artifacts, parameters, metrics, and system information
- Supports both single-node and distributed ML executions with automatic provenance graph generation
- Validated on over 500 GPUs with applications to tropical cyclone prediction tasks
- Maintains interoperability through W3C PROV-JSON serialization format

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Standardizing provenance capture in PROV-JSON format enables cross-tool interoperability and avoids vendor lock-in.
- Mechanism: The framework serializes all logged artifacts, parameters, and metrics into W3C PROV-JSON format rather than proprietary schemas. This allows downstream tools to consume and merge provenance graphs without format conversion.
- Core assumption: Users need to share, query, or combine provenance data across heterogeneous systems and workflows.
- Evidence anchors: [abstract] "maintaining interoperability through standard PROV-JSON serialization"; [section 2.1] "the generated graph is fully interoperable with other libraries of the yProv framework"
- Break condition: If downstream consumers do not support PROV-JSON parsing, interoperability benefits degrade to standard JSON readability only.

### Mechanism 2
- Claim: MLFlow-like API design reduces adoption friction by leveraging familiar logging patterns.
- Mechanism: yProv4ML exposes functions (`start_run`, `end_run`, `log_param`, `log_metric`, `log_artifact`) with signatures and semantics mirroring MLFlow. Users transition by substituting imports while preserving call patterns.
- Core assumption: The target user population already has experience with MLFlow or similar experiment-tracking tools.
- Evidence anchors: [abstract] "offers MLFlow-like utilities for intuitive data collection"; [section 2.2] "directives accessible through this library were designed to draw upon established tools such as MLFlow"
- Break condition: If users have no prior MLFlow exposure, the "familiarity" advantage neutralizes; learning curve reverts to standard documentation quality.

### Mechanism 3
- Claim: Automatic collection of system and energy metrics extends reproducibility beyond model artifacts to execution context.
- Mechanism: Dedicated modules integrate with `Codecarbon` and system monitors to log GPU usage, power consumption, emissions, and memory statistics alongside training metrics, without explicit user instrumentation per metric.
- Core assumption: Reproducibility and optimization require environmental context (energy, hardware load) in addition to hyperparameters and model weights.
- Evidence anchors: [section 2.1] "Energy module... contains all utility functions to save energy-related metrics, such as emissions, power consumption"; [section 4] "usefulness of yProv4ML is evident in the context of monitoring energy consumption processes"
- Break condition: If `Codecarbon` or system monitoring dependencies fail or are misconfigured, energy/system metrics may be silently incomplete or missing.

### Mechanism 4
- Claim: Distributed execution support via per-process provenance files with hierarchical aggregation enables scalable tracking.
- Mechanism: Each process logs to its own PROV-JSON file; a summary PROV collection links these into a unified hierarchical graph, preserving both granularity and global lineage.
- Core assumption: Distributed ML workloads generate provenance that must be both locally detailed and globally composable.
- Evidence anchors: [section 2.3] "each process generates its own provenance file... all PROV-JSON files can be linked together using an additional PROV collection"; [section 4] "evaluated on single-node, multi-node programs, as well as on over than 500 GPUs in parallel"
- Break condition: If the summary collection is not generated or files are misplaced, distributed lineage fragments remain disconnected.

## Foundational Learning

- **W3C PROV Data Model and PROV-JSON**
  - Why needed here: yProv4ML's output format is PROV-JSON; understanding entities, activities, and agents helps interpret generated graphs.
  - Quick check question: Can you sketch a minimal provenance triangle (Entity–Activity–Agent) for a model checkpoint?

- **MLFlow Experiment Tracking Basics**
  - Why needed here: API design mirrors MLFlow; knowing `log_param`, `log_metric`, `log_artifact` semantics accelerates adoption.
  - Quick check question: What is the difference between a parameter (logged once) and a metric (logged repeatedly)?

- **Provenance Graphs and Lineage**
  - Why needed here: The framework generates lineage graphs; reading them requires understanding nodes (artifacts, runs) and edges (derivation, usage).
  - Quick check question: If model B is fine-tuned from checkpoint A, what provenance edge type represents this relationship?

## Architecture Onboarding

- **Component map**: Main module -> Energy module -> System module -> Time module -> Graph builder
- **Critical path**:
  1. Initialize context with `prov4ml.start_run(...)` (define namespace, experiment name, save directory)
  2. Within training loop, call logging functions (`log_param`, `log_metric`, `log_system_metrics`, `log_carbon_metrics`, `save_model_version`)
  3. Finalize with `prov4ml.end_run(create_graph=True, create_svg=True)` to flush and serialize
- **Design tradeoffs**:
  - **Standard vs. convenience**: PROV-JSON ensures interoperability but may require additional tooling for visualization compared to MLFlow's built-in UI
  - **Granularity vs. overhead**: Logging every batch step increases provenance fidelity but inflates file size and I/O
  - **Distributed file handling**: Per-process files improve parallelism but require post-hoc aggregation for global lineage
- **Failure signatures**:
  - Missing PROV-JSON output: `end_run` not called or exception before flush
  - Incomplete energy metrics: `Codecarbon` not installed or lacks permissions to query hardware
  - Disconnected distributed graphs: Summary collection not generated or incorrect file paths
  - Import errors: Missing dependencies (`Codecarbon`, `Prov`, `Pytorch` as per C7)
- **First 3 experiments**:
  1. Run the MNIST example from Section 2.3 locally; verify PROV-JSON generation and open the SVG to confirm graph structure
  2. Modify the example to log a custom metric and a new artifact; confirm they appear in the provenance graph with correct context labels
  3. Simulate a minimal distributed run (two processes with different `rank` values); verify that separate PROV-JSON files are generated and can be manually linked via a summary collection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework extend its data model to support fine-grained data attribution, specifically delineating the contribution of individual training samples to the final model behavior?
- Basis in paper: [explicit] The conclusion states that future development will emphasize the "delineation of the contribution of each sample."
- Why unresolved: The current implementation logs aggregate metrics (loss, accuracy) and model versions, but lacks mechanisms to trace the influence of specific data points within the provenance graph.
- What evidence would resolve it: An extension of the library capable of mapping individual training samples to resulting model weight updates or metric shifts.

### Open Question 2
- Question: Can the accumulated provenance metadata be utilized to automatically correlate parameter variations with performance outcomes to identify optimal configurations?
- Basis in paper: [explicit] The conclusion lists "monitoring the impact of varying parameters" and "identification of the most suitable parameters in view of specific metrics" as future objectives.
- Why unresolved: While yProv4ML captures the history of experiments, it currently functions as a passive logging utility rather than an analytical tool for hyperparameter optimization.
- What evidence would resolve it: The integration of a query interface or analysis module that leverages historical PROV-JSON graphs to recommend optimal hyperparameters.

### Open Question 3
- Question: What is the computational overhead and latency introduced by real-time system and carbon metric logging on large-scale, distributed GPU clusters?
- Basis in paper: [inferred] The paper claims a "reduced memory footprint" and uses buffering (`save_after_n_logs`), but provides no quantitative data on the performance penalty imposed during the 500-GPU benchmark tests.
- Why unresolved: The trade-off between the granularity of provenance capture (e.g., per-batch system metrics) and training throughput remains unquantified.
- What evidence would resolve it: Benchmarking results comparing training job duration and resource usage with yProv4ML enabled versus a baseline run.

## Limitations
- Primary reliance on external dependencies like Codecarbon and system monitoring tools, which may fail silently in restricted execution environments
- Distributed provenance aggregation mechanism lacks empirical validation across heterogeneous hardware topologies
- Framework does not provide comprehensive error handling documentation for edge cases like network failures during distributed runs

## Confidence

- **Mechanism 1 (PROV-JSON interoperability)**: High confidence - the W3C standard is well-established and the implementation follows documented patterns
- **Mechanism 2 (MLFlow-like API)**: Medium confidence - while the design choice is sound, no usability studies confirm the claimed familiarity benefit
- **Mechanism 3 (System/Energy metrics)**: Medium confidence - depends on third-party library reliability and hardware access permissions
- **Mechanism 4 (Distributed aggregation)**: Low confidence - the mechanism is described but lacks extensive validation beyond the 500-GPU benchmark

## Next Checks

1. **API Familiarity Validation**: Conduct a controlled experiment comparing adoption time between yProv4ML and a non-MLFlow-inspired provenance tool with novice MLFlow users
2. **Distributed Lineage Robustness**: Simulate network partitions and process failures in a multi-node setup to verify the hierarchical aggregation mechanism's resilience
3. **Dependency Failure Handling**: Test the framework in a containerized environment with restricted hardware access to document failure modes and error messaging quality