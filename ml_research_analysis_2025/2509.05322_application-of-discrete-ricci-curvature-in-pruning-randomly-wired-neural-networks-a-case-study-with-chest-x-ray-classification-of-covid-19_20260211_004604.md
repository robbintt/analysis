---
ver: rpa2
title: 'Application of discrete Ricci curvature in pruning randomly wired neural networks:
  A case study with chest x-ray classification of COVID-19'
arxiv_id: '2509.05322'
source_url: https://arxiv.org/abs/2509.05322
tags:
- network
- pruning
- measures
- networks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper evaluates three edge-centric network measures\u2014\
  Forman-Ricci curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness\
  \ centrality (EBC)\u2014for pruning randomly wired neural networks (RWNNs) trained\
  \ on COVID-19 chest x-ray image classification. The study extends prior work by\
  \ comparing these measures across three random graph models (Erd\xF6s-R\xE9nyi,\
  \ Watts-Strogatz, and Barab\xE1si-Albert) and assessing whether FRC can achieve\
  \ comparable pruning performance to ORC while being computationally more efficient."
---

# Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19

## Quick Facts
- arXiv ID: 2509.05322
- Source URL: https://arxiv.org/abs/2509.05322
- Reference count: 0
- Primary result: Forman-Ricci curvature (FRC) can prune randomly wired neural networks (RWNNs) for COVID-19 chest x-ray classification with performance comparable to Ollivier-Ricci curvature (ORC) while offering computational efficiency advantages.

## Executive Summary
This paper investigates the use of discrete Ricci curvature measures—Forman-Ricci curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness centrality (EBC)—for pruning randomly wired neural networks (RWNNs) in the context of COVID-19 chest x-ray image classification. The study compares these edge-centric network measures across three random graph models (Erdös-Rényi, Watts-Strogatz, and Barabási-Albert) and evaluates their effectiveness in reducing network size while preserving classification performance. The results demonstrate that FRC-based pruning can achieve compression ratios and theoretical speedup comparable to ORC, with both outperforming EBC, while offering computational advantages due to its simpler calculation.

## Method Summary
The study employs three edge-centric network measures—Forman-Ricci curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness centrality (EBC)—to prune randomly wired neural networks (RWNNs) trained on COVID-19 chest x-ray image classification. RWNNs are constructed using three random graph models: Erdös-Rényi, Watts-Strogatz, and Barabási-Albert. Pruning is performed using a binary search approach to retain the smallest network configurations that preserve baseline accuracy, specificity, and sensitivity. The performance of each pruning method is evaluated based on compression ratios, theoretical speedup, and changes in network modularity and global efficiency. FRC is highlighted for its computational efficiency compared to ORC, though this advantage is theoretically predicted rather than empirically validated in the study.

## Key Results
- FRC and ORC generally outperformed EBC in compression ratios and theoretical speedup, with ORC achieving the highest maximum compression and FRC providing consistent average performance.
- Pruning increased network modularity but decreased global efficiency, reflecting a trade-off between modular segregation and network efficiency.
- FRC-based pruning can effectively simplify RWNNs, offering significant computational advantages while maintaining performance comparable to ORC.

## Why This Works (Mechanism)
The effectiveness of FRC and ORC in pruning RWNNs stems from their ability to identify and remove edges with low curvature values, which correspond to less structurally important connections in the network. By focusing on these edges, the pruning process reduces network complexity while preserving essential pathways for classification tasks. The increased modularity observed after pruning suggests that the remaining network structure becomes more segregated into specialized modules, which can enhance computational efficiency and potentially improve generalization. However, the decrease in global efficiency indicates a trade-off between modular organization and overall network connectivity, which may impact the network's ability to integrate information across modules.

## Foundational Learning
- **Discrete Ricci Curvature (FRC and ORC)**: Measures of edge importance in networks based on geometric properties; needed to identify structurally redundant edges for pruning; quick check: compare FRC and ORC values for edges in a simple graph.
- **Random Graph Models (Erdös-Rényi, Watts-Strogatz, Barabasi-Albert)**: Different network topologies used to construct RWNNs; needed to evaluate pruning performance across diverse network structures; quick check: visualize degree distributions for each model.
- **Network Modularity and Global Efficiency**: Metrics quantifying the trade-off between modular organization and overall connectivity; needed to assess the structural impact of pruning; quick check: compute modularity and efficiency for a pruned vs. unpruned network.

## Architecture Onboarding
- **Component Map**: RWNN (Erdös-Rényi/Watts-Strogatz/Barabasi-Albert) -> Curvature Measure (FRC/ORC/EBC) -> Binary Search Pruning -> Performance Evaluation (Accuracy/Specificity/Sensitivity/Compression/Modularity/Efficiency)
- **Critical Path**: Curvature calculation -> Edge ranking -> Binary search for optimal pruning threshold -> Performance validation
- **Design Tradeoffs**: FRC offers computational efficiency but may be less precise than ORC; higher modularity improves segregation but reduces global efficiency; random graph models provide diversity but may not reflect real-world network structures.
- **Failure Signatures**: Significant drop in accuracy/specificity/sensitivity after pruning; minimal compression achieved; increased modularity with negligible performance improvement.
- **First Experiments**: 1) Compare FRC and ORC pruning on a small RWNN; 2) Evaluate the impact of pruning on network modularity and efficiency; 3) Test pruning performance on a different dataset (e.g., MNIST).

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses exclusively on random graph models, limiting generalizability to real-world neural network topologies.
- The computational efficiency advantage of FRC over ORC is theoretically predicted but not empirically validated with runtime measurements.
- Performance is assessed only on COVID-19 chest x-ray classification, raising questions about robustness across other domains or datasets.

## Confidence
- Confidence in the claim that FRC provides "comparable performance" to ORC: Medium (ORC achieved the highest maximum compression, though FRC showed consistent average performance).
- Confidence in the efficiency claims: Medium (pending empirical runtime validation).
- Confidence in the generalization of results to other tasks or network types: Low.

## Next Checks
1. Empirically measure and compare the actual runtime of FRC-based pruning versus ORC-based pruning on the same hardware and datasets.
2. Test FRC and ORC pruning methods on diverse, structured neural network architectures (e.g., ResNet, EfficientNet) and multiple datasets beyond COVID-19 chest x-ray classification.
3. Investigate the impact of increased modularity on model generalization and robustness using cross-validation and out-of-distribution test sets.