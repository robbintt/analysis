---
ver: rpa2
title: Remote Rowhammer Attack using Adversarial Observations on Federated Learning
  Clients
arxiv_id: '2505.06335'
source_url: https://arxiv.org/abs/2505.06335
tags:
- rowhammer
- attack
- memory
- dram
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the first physical-domain-driven Rowhammer\
  \ attack on federated learning systems, where a reinforcement learning agent generates\
  \ adversarial acoustic perturbations to trigger clustered parameter updates on the\
  \ server, inducing DRAM bit-flips. The PPO-based framework achieved over 70% repeated\
  \ update rate in targeted ASR models, with cluster density as low as 0.5\u20131.6%,\
  \ successfully approaching practical Rowhammer thresholds (240K activations)."
---

# Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients

## Quick Facts
- arXiv ID: 2505.06335
- Source URL: https://arxiv.org/abs/2505.06335
- Reference count: 40
- A reinforcement learning agent generates acoustic perturbations to trigger clustered parameter updates in federated learning systems, inducing Rowhammer bit-flips without direct server access.

## Executive Summary
This paper presents the first physical-domain-driven Rowhammer attack on federated learning (FL) systems, where adversarial acoustic perturbations are used to manipulate client devices and induce DRAM bit-flips on servers. The attack exploits FL efficiency optimizations like RDMA and sparse updates to create the repetitive, localized memory access patterns required for Rowhammer. A two-stage Proximal Policy Optimization (PPO) agent learns to generate imperceptible audio that, when processed by a client's ASR model, produces clustered parameter updates that activate specific DRAM rows. The attack achieves over 70% repeated update rate with cluster density as low as 0.5-1.6%, successfully approaching practical Rowhammer thresholds of 240K activations without requiring direct server access.

## Method Summary
The attack employs a two-stage PPO agent that generates adversarial acoustic perturbations designed to induce clustered, repetitive parameter updates in FL systems. Stage 1 trains with explicit supervision on parameter update locations using observations containing both clean audio and update information, while Stage 2 generalizes using only raw waveform input with cross-attention mechanisms. The agent's reward function maximizes update stability (via Earth Mover's Distance), focuses updates on target parameter regions, and maintains stealth through imperceptibility constraints. The attack exploits FL optimizations including sparse updates (0.05-0.1%), RDMA communication, and pinned huge pages to create stable physical address mapping and sustained high-rate DRAM row activations. Evaluation uses Common Voice 17.0 English dataset across five ASR architectures, measuring Repeated Update Rate (RUR) and Cluster Density (CD) to assess attack effectiveness.

## Key Results
- Achieved over 70% Repeated Update Rate (RUR) across targeted ASR models
- Maintained cluster density as low as 0.5-1.6% while inducing repetitive updates
- Successfully approached practical Rowhammer thresholds of 240K activations
- Demonstrated attack effectiveness without requiring direct server access
- Showed two-stage PPO significantly outperforms single-stage approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A two-stage RL agent can learn to generate adversarial acoustic perturbations that induce clustered, repetitive parameter updates in FL servers.
- Mechanism: PPO agent learns correlation between waveform and parameter updates with explicit supervision (Stage 1), then generalizes policy using raw waveform with cross-attention (Stage 2). Reward function maximizes update stability, target focus, and stealth.
- Core assumption: Complex mapping from acoustic perturbation to specific sparse model updates is learnable and generalizable.
- Evidence anchors: [abstract] RL attacker learns to maximize server repetitive memory updates by manipulating client sensor observation; [Section III.D] Two-stage PPO-based agent generates adversarial waveforms inducing clustered parameter updates; [corpus] Related work focuses on digital poisoning attacks, not physical-domain methods.

### Mechanism 2
- Claim: FL efficiency optimizations can be co-opted to create high-frequency, localized memory access patterns required for Rowhammer.
- Mechanism: Sparse updates concentrate writes on tiny parameter fractions; repeated updates on same parameters create repetitive DRAM writes. RDMA and pinned memory ensure stable physical address mapping and bypass CPU caches.
- Core assumption: Targeted model parameters reside in fixed physical DRAM row during attack window.
- Evidence anchors: [abstract] Attack triggers clustered updates exploiting RDMA and sparse updates; [Section III.A] Identifies three properties from FL optimizations: stable physical address, minimal cache interference, sustained high rate of row activations; [corpus] No direct evidence supporting this specific hardware-software interaction.

### Mechanism 3
- Claim: Adversarial acoustic signal played in client environment can be transduced by microphone and manipulate model updates.
- Mechanism: Crafted acoustic perturbation played via speaker is picked up by client microphone, processed by local ASR model, causing specific gradient values during backpropagation that carry adversarial pattern as sparse updates.
- Core assumption: Perturbation remains effective after real-world transformations (D/A, A/D conversion, noise, distance).
- Evidence anchors: [abstract] RL attacker manipulates client sensor observation to maximize server repetitive memory updates; [Section II.C] Audio-based attacks persist in physical domain, maintaining effectiveness through speakers and microphones; [corpus] Corpus papers discuss adversarial attacks in FL but assume digital injection point.

## Foundational Learning

- **Federated Learning (FL) with Sparse Updates & RDMA:**
  - Why needed here: Attack targets specific memory access patterns created by large-scale FL systems using sparse updates and RDMA.
  - Quick check question: How does RDMA and pinned memory for efficiency inadvertently create a "stable physical address" for parameters, which is a prerequisite for a Rowhammer attack?

- **Reinforcement Learning (RL) Policy Learning:**
  - Why needed here: Core innovation uses RL agent (PPO) as attack generator with reward function translating to attack goals.
  - Quick check question: What are the three components of the reward function used to train the PPO agent, and how do they relate to the attack's objective?

- **Rowhammer Attack Fundamentals:**
  - Why needed here: Final impact is hardware fault requiring understanding of DRAM physics.
  - Quick check question: Why does the attack require parameter updates to be "clustered" (low Cluster Density) and "repetitive" (high Repeated Update Rate) to be successful?

## Architecture Onboarding

- **Component map:**
  PPO Agent -> Adversarial Waveform Generation -> Physical Acoustic Injection -> Client Microphone & ASR Processing -> Sparse Gradient Creation -> Server RDMA Write -> Pinned DRAM Row -> Rowhammer Bit-Flip

- **Critical path:**
  PPO Agent Generates Adversarial Waveform → Physical Acoustic Injection → Client Microphone & ASR Processing → Sparse Gradient Creation → Server RDMA Write to Pinned DRAM Row → Rowhammer Bit-Flip

- **Design tradeoffs:**
  - Two-Stage vs. Single-Stage RL: Two-stage PPO significantly outperforms single-stage; initial explicit supervision critical for learning complex audio-to-update mapping
  - Sparsity Level: Higher sparsity (0.05%) more effective for attack but may make RL agent's task more difficult
  - Perturbation Stealth: ||δ||∞ ≤ 0.1 constraint ensures audio is not obviously malicious but may limit attack effectiveness

- **Failure signatures:**
  - Low RUR / High CD: RL agent failed to learn policy producing necessary repetitive and clustered memory access pattern
  - TRR Activation: Effective Target Row Refresh intercepts and mitigates attack's activations
  - Adversarial Detection: Client-side systems flag audio as anomalous and block processing

- **First 3 experiments:**
  1. Rowhammer Threshold Characterization: Use DRAM Bender to determine activations needed to induce bit-flip under different access patterns and data patterns
  2. RL Agent Training & Evaluation: Train two-stage PPO agent and baselines; evaluate RUR and CD across ASR models and sparsity levels
  3. End-to-End Feasibility Estimation: Calculate expected row activations and compare to empirically derived threshold to determine theoretical capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can RL agent successfully learn to generate effective adversarial perturbations with highly sparse rewards (without explicit feedback about parameter update locations)?
- Basis in paper: [explicit] Section V.B states current RL framework might experience significantly reduced efficiency without explicit feedback or partial system knowledge
- Why unresolved: Current two-stage PPO relies on Stage 1 providing explicit update location feedback to bootstrap learning
- What evidence would resolve it: Demonstration of RL agent achieving comparable RUR (>65%) and cluster density (<2%) when trained without parameter update location information

### Open Question 2
- Question: Can side-channel techniques or hardware-software co-design enable precise targeting of specific DRAM rows for bit-flips in remote FL attacks?
- Basis in paper: [explicit] Section V.B identifies proposed indirect Rowhammer attack lacks precise control over specific DRAM rows affected
- Why unresolved: Current attack induces clustering but cannot guarantee which memory addresses are targeted
- What evidence would resolve it: Experimental demonstration showing consistent bit-flips at predetermined memory addresses with >80% spatial precision

### Open Question 3
- Question: How well does attack generalize across DRAM modules with different Rowhammer thresholds and TRR implementations?
- Basis in paper: [inferred] Section IV.B tested only single DRAM module (MTA18ASF2G72PZ-2G3B1) with thresholds of 115K-265K activations
- Why unresolved: Different DRAM manufacturers and generations exhibit varying vulnerability profiles
- What evidence would resolve it: Systematic evaluation across DRAM modules from multiple vendors and generations showing consistent RUR relative to each module's specific threshold

### Open Question 4
- Question: Can integrated hardware-software defense strategies mitigate this attack vector without significantly degrading FL system efficiency?
- Basis in paper: [explicit] Section V.E calls for exploring hardware-software joint-design approaches that mitigate Rowhammer risks without severely compromising computational efficiency
- Why unresolved: Paper proposes individual mitigations but does not evaluate combined effectiveness or quantify performance overhead
- What evidence would resolve it: Benchmark results from FL systems implementing combined defenses reporting both attack success rate reduction and training throughput impact

## Limitations

- The paper does not empirically demonstrate actual Rowhammer bit-flips occurring in the target FL server's DRAM, only showing the attack can induce the required memory access patterns
- Validation is limited to a single DRAM module, raising questions about generalizability across different hardware implementations and TRR mechanisms
- Environmental robustness of the acoustic attack under real-world conditions (background noise, varying distances) is not thoroughly evaluated

## Confidence

- **High Confidence:** RL agent's ability to learn policy for generating adversarial acoustic perturbations inducing clustered and repetitive parameter updates
- **Medium Confidence:** Mechanism by which FL optimizations create conditions for Rowhammer attack
- **Low Confidence:** Final claim that attack will successfully induce Rowhammer bit-flip in real FL server

## Next Checks

1. **Empirical Bit-Flip Validation:** Conduct controlled experiment where trained RL agent's perturbations are used in live FL training session with target server hardware, monitoring DRAM for actual bit-flips during and after attack using DRAM Bender platform.

2. **TRR and Mitigation Effectiveness:** Test attack against server with known DRAM mitigations like Target Row Refresh, measuring effectiveness at identifying and refreshing victim rows and quantifying impact on attack's RUR and E_Activation.

3. **Environmental Robustness Testing:** Evaluate attack effectiveness under realistic environmental conditions including background noise, varying speaker-to-microphone distances, and different acoustic environments to assess practical feasibility.