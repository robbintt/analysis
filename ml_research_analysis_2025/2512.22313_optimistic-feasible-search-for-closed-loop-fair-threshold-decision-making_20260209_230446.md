---
ver: rpa2
title: Optimistic Feasible Search for Closed-Loop Fair Threshold Decision-Making
arxiv_id: '2512.22313'
source_url: https://arxiv.org/abs/2512.22313
tags:
- reward
- feasible
- threshold
- learning
- closed-loop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies online learning of a one-dimensional threshold
  policy for closed-loop decision-making under fairness and service constraints. The
  learner observes only a scalar score and selects a threshold, with reward and constraint
  signals revealed only for the chosen threshold.
---

# Optimistic Feasible Search for Closed-Loop Fair Threshold Decision-Making

## Quick Facts
- arXiv ID: 2512.22313
- Source URL: https://arxiv.org/abs/2512.22313
- Reference count: 15
- Primary result: OFS achieves near-oracle reward with dramatically smaller cumulative constraint violation than baselines in closed-loop fair threshold decision-making

## Executive Summary
This paper studies online learning of one-dimensional threshold policies under fairness and service constraints in closed-loop decision-making environments. The learner observes only a scalar score and selects a threshold, with reward and constraint feedback available only for the chosen threshold. The authors propose Optimistic Feasible Search (OFS), a grid-based method that maintains confidence bounds for reward and constraint residuals for each candidate threshold. OFS selects thresholds that appear feasible under confidence bounds and maximizes optimistic reward, or minimizes optimistic violation if no threshold appears feasible. Across synthetic and semi-synthetic benchmarks, OFS achieves substantially higher reward with dramatically smaller cumulative constraint violation than unconstrained and primal-dual bandit baselines, while maintaining near-oracle performance.

## Method Summary
OFS operates by maintaining a grid of candidate thresholds with empirical mean estimates and confidence radii for both reward and constraint residuals. At each round, it constructs optimistic estimates by adding confidence radii to empirical means. If the feasible set (thresholds satisfying constraints under optimistic estimates) is non-empty, OFS selects the threshold maximizing optimistic reward; otherwise, it selects the threshold minimizing optimistic constraint violation. The method uses ε-greedy exploration and operates in closed-loop environments where the score distribution evolves based on previous decisions. The approach is evaluated on three benchmarks: a synthetic MVE-S environment with contraction dynamics, and semi-synthetic environments using German Credit and COMPAS datasets.

## Key Results
- OFS achieves substantially higher reward with dramatically smaller cumulative constraint violation than unconstrained and primal-dual bandit baselines
- OFS maintains near-oracle performance with steady-state reward gap to best feasible fixed threshold below 0.003 across all benchmarks
- The method successfully balances reward maximization with fairness and service rate constraints in non-stationary closed-loop environments

## Why This Works (Mechanism)
OFS works by maintaining optimistic estimates of both reward and constraint satisfaction for each candidate threshold. By adding confidence radii to empirical estimates, the method ensures that if a threshold appears feasible under optimistic estimates, it is likely truly feasible with high probability. This allows OFS to focus exploration on promising regions while avoiding constraint violations. The feasible screening approach is particularly effective in closed-loop settings where the environment evolves based on decisions, as it provides robustness to non-stationarity. The method's ability to switch between reward maximization and violation minimization based on feasibility status enables it to adapt to changing environmental conditions while maintaining constraint satisfaction.

## Foundational Learning
- **Confidence bounds for bandit feedback**: Needed to quantify uncertainty in empirical estimates when only one threshold is observed per round. Quick check: Verify confidence radii shrink appropriately with sample size using b_i(t)=√(c·log((t+1)K_θ/δ)/max(1,n_i)).
- **Closed-loop dynamics with contraction**: Required to model how score distributions evolve based on previous decisions. Quick check: Validate that μ_a(t+1)=(1-γ)μ_a(t)+γ·acc_a(θ) converges to a steady state for γ=0.1.
- **Demographic parity constraints**: Essential for measuring fairness between groups. Quick check: Confirm g_dp(θ)=∆DP(θ)-ε≤0 correctly captures the fairness requirement with tolerance ε.
- **Service rate constraints**: Needed to ensure minimum/maximum acceptance rates. Quick check: Verify acc(θ)∈[α_min, α_max] is properly enforced in both synthetic and semi-synthetic environments.
- **Optimistic planning under uncertainty**: Core algorithmic principle for balancing exploration and exploitation. Quick check: Ensure feasible set F_t is correctly computed from optimistic estimates each round.
- **Semi-synthetic data simulation**: Required to create realistic evaluation environments from real datasets. Quick check: Confirm logistic regression models are properly trained and composition shifts are simulated as described.

## Architecture Onboarding

**Component Map**
Synthetic Environment -> OFS Algorithm -> Reward/Constraint Feedback -> Score Distribution Update -> Next Round
Semi-synthetic Environment -> OFS Algorithm -> Reward/Constraint Feedback -> Mixture Weight Update -> Next Round

**Critical Path**
1. Initialize grid of thresholds with empty statistics
2. For each round: observe batch, compute empirical means and confidence radii
3. Construct optimistic estimates and feasible set
4. Select threshold based on optimistic reward or violation minimization
5. Update statistics based on observed feedback
6. Update environmental state (score distribution or mixture weights)

**Design Tradeoffs**
- Grid resolution vs computational efficiency: K_θ=50 provides balance
- Confidence radius scaling: c=1.0 with δ=0.05 offers strong guarantees
- Exploration rate: ε_exp=0.05 balances exploration with constraint satisfaction
- Batch size: n=256 provides sufficient samples per round while maintaining responsiveness

**Failure Signatures**
- Cumulative violation grows linearly: Indicates feasible region may be empty or OFS cannot find feasible thresholds
- High variance across seeds: Suggests unstable learning, possibly due to insufficient batch size or environmental non-stationarity
- Primal-dual baseline oscillates: Indicates poor tuning of step sizes or infeasible-min-violation selection rule

**First Experiments**
1. Verify feasible region exists by sweeping fixed thresholds offline across all three benchmarks
2. Implement MVE-S dynamics with γ=0.1 contraction and validate score distribution evolution over time
3. Train logistic regression models on German Credit and COMPAS datasets with one-hot encoding and standardization

## Open Questions the Paper Calls Out

**Open Question 1**
Can OFS be extended to higher-dimensional policy classes while preserving its near-oracle feasibility guarantees? The paper notes that extending optimism-based feasible screening to higher-dimensional policy classes may require structured discretization or surrogate modeling due to the curse of dimensionality.

**Open Question 2**
How does OFS perform under equalized odds constraints, where constraint estimation requires outcome labels rather than decisions alone? The authors suggest that equalized odds may require different constraint estimators and could change tradeoffs compared to demographic parity.

**Open Question 3**
What guarantees does OFS provide when the closed-loop dynamics are not contractive? The theoretical analysis relies on contraction assumptions, but real systems may exhibit oscillations or multiplicity of equilibria that could invalidate confidence-bound-based feasibility screening.

**Open Question 4**
How robust is OFS to strategic behavior by individuals who adapt their features in response to the learned threshold? Real-world feedback mechanisms can be more complex and may involve strategic behavior that breaks stationarity assumptions within each arm.

## Limitations
- Performance guarantees rely on contractive closed-loop dynamics that may not hold in all real-world systems
- Extension to higher-dimensional policy classes faces computational challenges due to grid discretization
- The method focuses on demographic parity and service constraints, with potential challenges for other fairness notions like equalized odds

## Confidence
- **Core methodology reproducibility**: High - The OFS algorithm is clearly described with well-defined components
- **Exact numerical matching**: Medium - Depends on unspecified hyperparameters and environment dynamics details
- **Soft constraint implementation**: Medium - Implementation depends on precise environmental models and parameter values

## Next Checks
1. Verify the feasible region exists offline by sweeping fixed thresholds across all benchmarks to ensure constraints are satisfiable
2. Implement the MVE-S dynamics with γ=0.1 contraction rate and validate that score distributions evolve as expected over time
3. Train logistic regression models on German Credit and COMPAS datasets with one-hot encoding and standardization, then validate that simulated composition shifts match the paper's description of the semi-synthetic environments