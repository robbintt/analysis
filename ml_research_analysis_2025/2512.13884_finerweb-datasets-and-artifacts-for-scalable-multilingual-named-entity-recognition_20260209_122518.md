---
ver: rpa2
title: 'FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition'
arxiv_id: '2512.13884'
source_url: https://arxiv.org/abs/2512.13884
tags:
- entity
- annotations
- language
- latn
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FiNERweb is a scalable pipeline for creating multilingual NER datasets
  using LLMs. It filters high-quality passages from FineWeb-2 via a regression model,
  annotates them with GPT-4o mini and Gemma3-27B, and translates labels into 91 languages
  and 25 scripts.
---

# FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition

## Quick Facts
- arXiv ID: 2512.13884
- Source URL: https://arxiv.org/abs/2512.13884
- Authors: Jonas Golde; Patrick Haller; Alan Akbik
- Reference count: 31
- FiNERweb creates 225k NER passages in 91 languages using LLM filtering and annotation

## Executive Summary
FiNERweb is a scalable pipeline for creating multilingual NER datasets using LLMs to filter high-quality passages from FineWeb-2, annotate them with GPT-4o mini and Gemma3-27B, and translate labels into 91 languages. The resulting dataset contains 225k passages with 235k distinct entity labels. Experiments show the regression model achieves >84 F1, and models trained on FiNERweb obtain comparable or improved zero-shot performance on English, Thai, and Swahili, despite using 19x less data than baselines. LLM-as-a-judge evaluation yields high scores for faithfulness (3.99/5) and completeness (4.05/5).

## Method Summary
The pipeline trains a regression model to identify NER-relevant passages from FineWeb-2 using LLM preference data, then annotates filtered passages with two LLMs (GPT-4o mini and Gemma3-27B) and merges annotations using semantic similarity thresholds. Entity labels are translated into 91 languages, and the resulting dataset is used to train student NER models. The approach addresses multilingual NER data scarcity by leveraging LLMs as annotators while maintaining quality through regression filtering and dual-annotator merging.

## Key Results
- Regression model achieves >84 F1 on binary classification of NER-relevant passages
- Student models trained on FiNERweb show comparable or improved zero-shot performance on English, Thai, and Swahili
- LLM-as-a-judge evaluation yields high faithfulness (3.99/5) and completeness (4.05/5) scores
- Performance drops by 0.02-0.09 F1 when evaluated with target language labels instead of English ones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A regression model trained on LLM preference data can filter web-scale corpora for NER-relevant passages with high precision.
- Mechanism: LLMs rate passage usefulness on a 1-4 scale; a transformer-based regressor learns to predict these scores; filtering at threshold >0.5 (score ≥3) retains high-quality passages while discarding noise like advertisements.
- Core assumption: LLM quality ratings generalize beyond the 1k samples per language used for training.
- Evidence anchors: [abstract] "our approach trains regression models to identify NER-relevant passages... regression model achieves more than 84 F1"; [section 2.2/Table 1] Binary XLM-RoBERTa model achieves 0.841 F1 on GPT-4o mini annotations; [corpus] Related work (OpenNER 1.0) similarly addresses multilingual NER data standardization.
- Break condition: If LLM annotator quality degrades significantly for low-resource languages, the preference signal becomes unreliable.

### Mechanism 2
- Claim: Dual-LLM annotation with semantic merging improves entity coverage while maintaining precision.
- Mechanism: Two LLMs annotate independently; spans with <50% overlap retain the longer span; spans with ≥50% overlap merge labels if semantic similarity >0.75 (using all-MiniLM-L6-v2). This captures complementary entity predictions.
- Core assumption: Disagreement between LLMs signals coverage gaps rather than systematic errors.
- Evidence anchors: [abstract] "annotates them with GPT-4o mini and Gemma3-27B... 235k distinct entity labels"; [section 2.4] 31.5% exact match; 63.02% of annotations retained after merging; merged dataset averages 25.4 types/sample vs 19.4 (GPT-4o only) or 21.5 (Gemma only); [corpus] No direct corpus evidence for dual-LLM merging strategies in NER.
- Break condition: If both LLMs share systematic biases (e.g., under-annotating rare entity types), merging amplifies rather than corrects errors.

### Mechanism 3
- Claim: Translating entity labels into target languages reduces downstream performance due to semantic overlap in embedding space.
- Mechanism: Classical loss functions (cross-entropy, contrastive) treat labels as mutually exclusive. Translated labels (e.g., "person"/"persona") become semantically similar in embedding space but are treated as hard negatives, degrading learning.
- Core assumption: The embedding model's semantic similarity reflects meaningful conceptual overlap.
- Evidence anchors: [abstract] "performance of current state-of-the-art models drops by 0.02 to 0.09 F1 when evaluated using target language labels instead of English ones"; [section 3.3/Figure 5] Translated labels show higher pairwise cosine similarity (distribution shifted right) compared to English labels; [corpus] Weak external validation; related work does not specifically address label translation effects.
- Break condition: If label semantics differ fundamentally across languages (polysemy, cultural specificity), embedding similarity may not capture true equivalence.

## Foundational Learning

- Concept: Teacher-student distillation for NER
  - Why needed here: FiNERweb uses LLMs as "teachers" to generate synthetic annotations for smaller student models (Binder, GLiNER). Understanding this paradigm is essential for interpreting why dataset quality matters more than quantity.
  - Quick check question: Can you explain why a smaller model trained on LLM-generated data might outperform direct LLM inference for structured extraction tasks?

- Concept: Multilingual transformer representations (XLM-RoBERTa, mDeBERTa)
  - Why needed here: The regression filter and downstream models rely on multilingual encoders. Script diversity (25 scripts, ~50% Latin) affects representation quality.
  - Quick check question: Why might a multilingual model trained on 91 languages perform worse on Thai than English even with equal data per language?

- Concept: IOB/BIO tagging schemes and span alignment
  - Why needed here: Algorithm 1 shows span matching logic; understanding token-level vs span-level annotation is critical for debugging alignment failures.
  - Quick check question: Given the substring matching approach, what happens if an LLM outputs "New York" when the text contains "New York City"?

## Architecture Onboarding

- Component map: FineWeb-2 -> [chunking 256 tokens] -> Regression Model (XLM-R) -> threshold >0.5 -> Filtered passages -> [LangID filter] -> GPT-4o mini + Gemma3-27B (parallel) -> [Span alignment] -> [Semantic merge] -> [Label translation] -> FiNERweb dataset

- Critical path: The regression model quality directly controls data efficiency. A poorly calibrated regressor either wastes annotation budget on low-quality passages or excludes valuable content.

- Design tradeoffs:
  - Binary vs multi-class regression: Binary (≥3 threshold) achieves higher F1 (0.841 vs 0.656) but loses fine-grained quality signals.
  - Single vs dual LLM annotation: Dual annotation increases coverage (+19% unique types) but doubles annotation cost.
  - English vs translated labels: English labels yield better downstream performance but reduce applicability for non-English evaluation.

- Failure signatures:
  - Low faithfulness scores (<3.5) for specific languages indicate annotator LLM limitations (e.g., Amharic, Kurdish in Figure 4).
  - High missing-annotation rate (>6%) in LLM-as-judge evaluation signals under-annotation rather than hallucination.
  - Performance drop on Thai in multilingual training (Table 4: 0.420 F1 vs 0.532 monolingual) suggests positive/negative example imbalance across scripts.

- First 3 experiments:
  1. Validate regression model calibration: Sample 100 passages per language from filtered output; manually verify NER relevance. Compare against threshold ablations (0.3, 0.5, 0.7).
  2. Single vs dual annotator ablation: Train identical student models on GPT-4o-only, Gemma-only, and merged annotations. Measure F1 delta on held-out test sets (CoNLL, MasakhaNER, ThaiNER).
  3. Label translation impact: Train models with English labels only vs translated labels; evaluate on native-language test sets to quantify the 0.02-0.09 F1 gap and identify worst-affected languages.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can training objectives be modified to prevent semantically equivalent translated labels (e.g., "person" and "persona") from being treated as hard negatives in multilingual NER models?
- **Basis in paper:** [explicit] The authors state on page 8 that "Addressing this limitation requires training objectives that explicitly account for semantic overlap... filtering near duplicate labels within a batch... or defining contrastive losses that allow multiple equivalent positives."
- **Why unresolved:** The paper demonstrates a consistent F1 drop (0.02-0.09) when using translated labels but identifies the limitation of current loss functions without implementing or testing the proposed solutions.
- **What evidence would resolve it:** A comparative study training a model (like GLiNER or Binder) on FiNERweb using a semantic-aware loss function vs. standard cross-entropy, measuring the performance gap between English and target-language label evaluation.

### Open Question 2
- **Question:** Can the regression model's binary classification performance (>84 F1) be maintained when scaling the pipeline to low-resource languages not well-supported by the underlying LLMs?
- **Basis in paper:** [explicit] The Limitations section (page 9) notes that the work is constrained by "the multilingual capacity of the underlying LLMs" and that extending beyond 91 languages "would require additional annotation resources and quality control."
- **Why unresolved:** The current experiments are restricted to languages supported by XLM-RoBERTa and the annotator LLMs; the efficacy of the regression filter on languages with "limited digital presence" remains untested.
- **What evidence would resolve it:** Evaluation of the regression model's precision and recall on a held-out set of passages from languages outside the XLM-R pretraining set.

### Open Question 3
- **Question:** Does training student models on confidence-based partitions of FiNERweb improve performance on rare entity types found in the dataset's long-tail distribution?
- **Basis in paper:** [inferred] Page 9 notes that confidence scores follow a "long-tail distribution" and that the authors release confidence-based subsets to enable "further study of positive–unlabeled learning."
- **Why unresolved:** The authors analyze the confidence distribution and create the artifacts, but the downstream experiments do not explicitly test whether filtering low-confidence examples improves the student model's ability to learn rare or ambiguous entity types.
- **What evidence would resolve it:** Ablation results showing downstream NER performance (specifically for infrequent labels like "scientific concept") when training strictly on the >0.97 confidence subset versus the full merged dataset.

### Open Question 4
- **Question:** Is the performance drop in Thai during joint training caused by the Binder architecture's handling of non-segmented scripts or by data imbalance in the multilingual batch?
- **Basis in paper:** [inferred] Page 6 reports that performance on Thai decreases when trained jointly with English and Swahili, which the authors "attribute... to Binder not requiring word-segmented inputs," leading to differing positive/negative ratios.
- **Why unresolved:** The paper identifies the correlation between the architecture and the Thai script but does not isolate whether the issue is intrinsic to the script type or a consequence of batching strategy.
- **What evidence would resolve it:** An experiment comparing Binder's performance on Thai using word-segmented inputs versus character-level inputs, or a joint training run with language-balanced batching.

## Limitations

- The pipeline is constrained by the multilingual capacity of underlying LLMs and cannot easily extend beyond 91 languages without additional annotation resources
- Translating entity labels introduces semantic overlap that degrades downstream performance by 0.02-0.09 F1 due to current loss function limitations
- Performance on Thai decreases during joint training with English and Swahili, suggesting script-specific challenges with the Binder architecture

## Confidence

**High confidence**: The core pipeline architecture (regression filtering → dual LLM annotation → semantic merging) is well-specified and reproducible. The reported F1 scores for regression (0.841) and downstream zero-shot transfer results are supported by clear methodology.

**Medium confidence**: Claims about data efficiency (19x less data than baselines) depend on comparing against specific OpenNER configurations. The LLM-as-judge evaluation methodology introduces potential bias that limits confidence in the faithfulness/completeness scores.

**Low confidence**: The generalizability of results across all 91 languages is uncertain given the evaluation focuses on English, Thai, and Swahili. The semantic similarity threshold (0.75) for merging annotations was chosen without ablation studies.

## Next Checks

1. **Regression model robustness test**: Sample 500 filtered passages across 10 diverse languages (low-resource to high-resource). Have human annotators rate NER relevance and compare against model predictions. Measure precision/recall to validate the 84 F1 claim holds across language tiers.

2. **Annotation pipeline bias audit**: Run the full annotation pipeline on a fixed 100-passage English sample using both GPT-4o mini and an alternative LLM (e.g., Claude-3). Compare annotation consistency, entity type coverage, and faithfulness scores. This isolates LLM-specific biases from pipeline effects.

3. **Label translation impact study**: Train student models on English labels, translated labels, and a mixed approach. Evaluate on native-language test sets for Thai, Swahili, and two additional languages (e.g., Hindi, Korean). Quantify the performance gap and identify whether specific entity types (e.g., PERSON, ORGANIZATION) show larger degradation.