---
ver: rpa2
title: Unsupervised Prompting for Graph Neural Networks
arxiv_id: '2505.16903'
source_url: https://arxiv.org/abs/2505.16903
tags:
- prompting
- graph
- distribution
- data
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Unsupervised Graph Prompting Problem (UGPP),
  a new setup for evaluating GNN prompting methods without updating base model parameters
  or using labeled data. The authors propose UGP ROMPT, a framework leveraging consistency
  regularization and pseudo-labeling to train a prompting function.
---

# Unsupervised Prompting for Graph Neural Networks

## Quick Facts
- arXiv ID: 2505.16903
- Source URL: https://arxiv.org/abs/2505.16903
- Reference count: 40
- Primary result: Unsupervised prompting method UGPROMPT outperforms supervised methods on GNN adaptation across distribution shifts without labeled data.

## Executive Summary
This paper introduces Unsupervised Graph Prompting Problem (UGPP), a new setup for evaluating GNN prompting methods without updating base model parameters or using labeled data. The authors propose UGPROMPT, a framework leveraging consistency regularization and pseudo-labeling to train a prompting function. Two regularization techniques address class imbalance and prevent out-of-distribution outputs. Extensive experiments across graph and node classification tasks demonstrate UGPROMPT outperforms state-of-the-art supervised prompting methods in most cases, despite having no access to labeled data. The method shows consistent improvements over base models across various distribution shifts including edge homophily, graph density, and clustering coefficient. Ablation studies confirm the effectiveness of regularization terms and augmentation strategies. The framework's versatility is validated by integrating alternative prompting functions.

## Method Summary
UGPROMPT is a fully unsupervised prompting framework that adapts a frozen pre-trained GNN to target data using only unlabeled samples. The method creates weak and strong augmentations of target graphs, uses confident pseudo-labels from the weak view to train the prompting function on the strong view, and incorporates consistency regularization, diversity regularization to counter class imbalance, and adversarial domain alignment. The prompting function is optimized without updating the base GNN parameters, making it applicable to any pre-trained model.

## Key Results
- UGPROMPT outperforms state-of-the-art supervised prompting methods on most graph and node classification tasks
- The method achieves consistent improvements over base models across distribution shifts including edge homophily, graph density, and clustering coefficient
- Regularization techniques significantly contribute to performance, with diversity loss preventing class imbalance issues and adversarial loss improving domain alignment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Consistency regularization via pseudo-labeling enables the prompting function to adapt a frozen GNN to a target domain without labeled data.
- **Mechanism:** The method creates two augmented views of an unlabeled target graph: a "weak" view (`Gw`) and a "strong" view (`Gs`). The frozen GNN generates a pseudo-label for the weak view if its prediction confidence exceeds a threshold (`τ`). The prompting function (`f`) is trained on the strong view (`Gs`) to produce a prediction that matches this high-confidence pseudo-label. This process transfers the frozen GNN's knowledge to the prompting function, allowing it to learn data transformations that align target samples with the model's pre-trained distribution.
- **Core assumption:** The pre-trained GNN's highly confident predictions on weakly augmented target data are correct and reflect a conditional distribution (`P(Y|X)`) that is invariant to the covariate shift between source and target domains.
- **Break condition:** The mechanism fails if the pre-trained GNN is systematically over-confident on the target data due to extreme distribution shift, leading to consistently incorrect pseudo-labels and optimizing the prompt toward a trivial or incorrect solution.

### Mechanism 2
- **Claim:** Diversity regularization prevents the prompting function from collapsing all predictions to the majority class under dataset imbalance.
- **Mechanism:** By maximizing the entropy of the *expected* prediction distribution over a batch (`Ldiv`), the loss function forces the prompting function to generate prompts that lead to a more uniform distribution of class predictions across the dataset, counteracting a bias toward the majority class.
- **Core assumption:** The target dataset has a non-trivial class distribution, and simply minimizing consistency loss without this term leads to a trivial solution where the model maximizes confidence by assigning all samples to the most common class.
- **Break condition:** If the target dataset's classes are genuinely highly imbalanced, forcing the model's predictions to be more uniform could lower accuracy by forcing confident, correct predictions into uncertain ones.

### Mechanism 3
- **Claim:** Adversarial domain adaptation constrains the prompting function to generate graphs that remain within the feature manifold of the original data.
- **Mechanism:** An adversarial discriminator is trained to distinguish between the latent representations of original (weakly-augmented) graphs and prompted graphs. The prompting function is trained to fool this discriminator (`Ladv`), thereby forcing it to produce prompts whose representations are indistinguishable from the original target data's distribution.
- **Core assumption:** The latent space of the frozen GNN encoder captures the semantic manifold of the data, and aligning the prompted representations with the original data's latent distribution prevents the generation of out-of-distribution (OOD) or semantically meaningless features.
- **Break condition:** If the latent space is not well-structured or if the discriminator overpowers the prompt function, the prompt may be forced to generate features that are statistically similar to the original data but semantically useless for classification.

## Foundational Learning

- **Concept:** Graph Neural Networks (GNNs) & Message Passing
  - **Why needed here:** The method is a wrapper around a frozen GNN. Understanding that a GNN's final representation is built by aggregating neighbor information is crucial because a feature-level prompt (adding a vector to node features) propagates through the network and affects the graph-level embedding.
  - **Quick check question:** If a prompt adds a vector to only one node's features, can it affect the representation of other nodes? (Yes, via message passing).

- **Concept:** Consistency Regularization
  - **Why needed here:** This is the core learning signal. The method trains on the assumption that the model's prediction should be invariant to different augmentations of the same input.
  - **Quick check question:** Why are weak and strong augmentations used? (Weak provides stable pseudo-labels; strong provides a difficult target for the prompting function to learn from).

- **Concept:** Distribution Shift (Covariate Shift)
  - **Why needed here:** The paper's problem setting (UGPP) is explicitly defined by covariate shift (`P_s(X) != P_t(X)`). The method's goal is to close this gap without changing the model's parameters.
  - **Quick check question:** What assumption is made about the label distribution `P(Y|X)`? (It is assumed to be invariant: `P_s(Y|X) = P_t(Y|X)`).

## Architecture Onboarding

- **Component map:** Input Graph -> Prompting Function `f` -> GNN Encoder `g` -> GNN Projection Head `h` -> Prediction. The architecture consists of a frozen base GNN (`φ`), a trainable prompting function (`f`), and an adversarial discriminator (`d`). Input graphs are processed by an augmentation module to create weak (`Gw`) and strong (`Gs`) views. `f` transforms `Gs` into a prompted graph (`Gp`). The GNN encoder (`g`) processes both `Gw` and `Gp`. The discriminator (`d`) tries to distinguish between their latent representations.

- **Critical path:** The inference path is: Input Graph -> **Prompting Function `f`** -> **GNN Encoder `g`** -> **GNN Projection Head `h`** -> Prediction. All training components (augmentation, discriminator) are removed.

- **Design tradeoffs:**
  - **Prompting Function:** A feature-additive prompt (Eq. 1) is chosen to align with feature-masking augmentation. Structural prompting is less effective (Appendix A.4.6).
  - **Augmentation Strength (`ps`):** A higher `ps` (stronger masking) improves robustness to shift but can hurt performance on continuous features (Table 3).

- **Failure signatures:**
  - **Mode Collapse:** The model predicts the same class for all graphs. Check if the diversity loss weight (`λ1`) is too low (Section 4.2).
  - **No Improvement over Base:** The prompt fails to adapt. This can occur if the base GNN is over-confident on the target data, causing the pseudo-label threshold (`τ`) to accept noisy labels.

- **First 3 experiments:**
  1.  **Baseline Test:** Evaluate the frozen GNN (`BaseModel`) on your target dataset without prompting to establish a performance floor.
  2.  **Ablation Study:** Run `UGPrompt` with only consistency loss (`Lc`) and then add diversity (`Ldiv`) and domain (`Ladv`) losses separately to replicate the results in Figure 2 and confirm each component's contribution.
  3.  **Hyperparameter Scan:** Test different values for the strong augmentation probability (`ps`) and confidence threshold (`τ`) to find the optimal settings for your specific dataset, as the paper shows sensitivity to these parameters (Table 3).

## Open Questions the Paper Calls Out

- **Question:** How does UGPROMPT perform when integrated with prompting functions that modify graph structure rather than solely node features?
- **Basis in paper:** [explicit] The authors state in Appendix A.4.6 that "none of the existing GNN prompting functions can be categorized solely as structural prompting," and they explicitly "leave experimenting with such prompting method for future works."
- **Why unresolved:** The current framework aligns specifically with feature-based prompting functions to match the feature-masking augmentation strategy.
- **What evidence would resolve it:** Experiments applying UGPROMPT to structural prompting baselines (e.g., edge addition/removal prompts) on standard benchmarks.

## Limitations

- The method relies on the base GNN producing sufficiently confident and correct pseudo-labels on weakly-augmented target data, which may fail under extreme distribution shifts or when the source model is poorly aligned with the target domain.
- The framework assumes invariant conditional label distributions across domains, which may not hold in practice.
- Hyperparameter sensitivity (especially τ and ps) is not fully characterized across datasets, and the choice of augmentation type (feature masking) may not generalize well to all graph types.

## Confidence

- **High confidence:** Core methodology and experimental design are sound; ablation studies support the effectiveness of regularization terms.
- **Medium confidence:** Performance gains are consistently reported but depend on tuning sensitive hyperparameters; adversarial alignment improves robustness but its exact contribution is unclear.
- **Low confidence:** Claims about domain-agnostic improvements rely on synthetic splits that may not reflect realistic shifts; full reproducibility is hindered by missing implementation details.

## Next Checks

1. **Hyperparameter robustness scan:** Systematically vary τ, ps, and λ weights across multiple target datasets to quantify sensitivity and find stable defaults.
2. **Cross-domain generalization test:** Apply the same prompting function trained on one target domain to a different target domain to evaluate true transfer capability beyond the assumed covariate shift.
3. **Adversarial component ablation:** Run experiments with and without the discriminator while controlling for prompting function capacity to isolate the effect of domain alignment regularization.