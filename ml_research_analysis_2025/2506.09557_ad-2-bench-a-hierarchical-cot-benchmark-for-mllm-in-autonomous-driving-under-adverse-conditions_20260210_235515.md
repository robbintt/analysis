---
ver: rpa2
title: 'AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under
  Adverse Conditions'
arxiv_id: '2506.09557'
source_url: https://arxiv.org/abs/2506.09557
tags:
- reasoning
- driving
- should
- autonomous
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AD2-Bench, the first benchmark designed to
  evaluate Chain-of-Thought (CoT) reasoning for Multimodal Large Language Models (MLLMs)
  in autonomous driving under adverse conditions. AD2-Bench addresses the lack of
  rigorous evaluation for MLLMs in challenging driving scenarios by providing over
  5,400 manually annotated CoT instances with explicit ground truth for each intermediate
  reasoning step.
---

# AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under Adverse Conditions

## Quick Facts
- arXiv ID: 2506.09557
- Source URL: https://arxiv.org/abs/2506.09557
- Authors: Zhaoyang Wei; Chenhui Qiang; Bowen Jiang; Xumeng Han; Xuehui Yu; Zhenjun Han
- Reference count: 40
- Over 5,400 manually annotated CoT instances with explicit ground truth for each intermediate reasoning step

## Executive Summary
This paper introduces AD2-Bench, the first benchmark designed to evaluate Chain-of-Thought (CoT) reasoning for Multimodal Large Language Models (MLLMs) in autonomous driving under adverse conditions. The benchmark addresses the lack of rigorous evaluation for MLLMs in challenging driving scenarios by providing diverse real-world images covering adverse weather and complex scenes, along with novel multi-level visual prompts to mitigate perceptual limitations. AD2-Bench features a multi-dimensional evaluation metric assessing semantic similarity, reasoning coherence, and decision consistency, revealing that even state-of-the-art MLLMs achieve below 60% accuracy on this challenging benchmark.

## Method Summary
AD2-Bench introduces a comprehensive benchmark for evaluating MLLM reasoning capabilities in autonomous driving under adverse conditions. The methodology centers on creating over 5,400 manually annotated Chain-of-Thought reasoning instances with explicit ground truth for each intermediate step. The benchmark employs diverse real-world images capturing adverse weather conditions and complex driving scenes, supplemented by novel multi-level visual prompts designed to address perceptual limitations. A multi-dimensional evaluation metric was developed to assess three key aspects: semantic similarity between generated and reference reasoning, coherence of the reasoning chain, and consistency of final driving decisions. This systematic approach enables rigorous evaluation of MLLM reasoning quality beyond simple accuracy metrics.

## Key Results
- Current SOTA MLLMs achieve below 60% accuracy on AD2-Bench
- Manual annotation provides explicit ground truth for each reasoning step
- Multi-dimensional evaluation metric reveals gaps in semantic similarity, reasoning coherence, and decision consistency

## Why This Works (Mechanism)
The benchmark works by systematically addressing the complexity gap between standard driving datasets and real-world autonomous driving challenges. By incorporating adverse conditions and requiring explicit Chain-of-Thought reasoning with ground truth annotations for each step, AD2-Bench forces models to demonstrate interpretable reasoning rather than relying on superficial pattern matching. The multi-level visual prompts help mitigate perceptual limitations that commonly plague MLLMs in challenging visual conditions, while the multi-dimensional evaluation captures nuanced aspects of reasoning quality beyond binary correctness judgments.

## Foundational Learning

**Chain-of-Thought Reasoning**: A prompting technique that encourages models to generate intermediate reasoning steps before reaching final conclusions. Needed because autonomous driving requires transparent decision-making processes that can be audited and validated. Quick check: Verify that intermediate reasoning steps logically connect to final driving decisions.

**Multimodal Large Language Models**: AI systems that process both visual and textual inputs to generate responses. Essential for autonomous driving where visual scene understanding must be combined with language-based reasoning and decision-making. Quick check: Confirm the model can process image inputs and generate coherent driving-related responses.

**Adverse Weather Conditions**: Environmental factors like rain, fog, snow, and low-light that degrade visual perception. Critical to test because autonomous vehicles must operate reliably across all weather conditions, not just ideal scenarios. Quick check: Test model performance degradation as image quality systematically decreases.

**Semantic Similarity Metrics**: Quantitative measures of meaning equivalence between generated and reference text. Important for evaluating whether different phrasings of reasoning steps represent equivalent logical content. Quick check: Validate that synonymous reasoning paths receive similar scores.

## Architecture Onboarding

**Component Map**: Image Input -> Multi-Level Visual Prompt Processing -> CoT Reasoning Generation -> Multi-Dimensional Evaluation -> Performance Assessment

**Critical Path**: Visual input processing through multi-level prompts → intermediate reasoning step generation → final decision output → evaluation against ground truth

**Design Tradeoffs**: Manual annotation provides high-quality ground truth but limits dataset size; multi-dimensional evaluation captures nuanced performance but increases computational complexity; multi-level prompts improve robustness but add processing overhead.

**Failure Signatures**: Models may fail by producing semantically different but logically equivalent reasoning paths (false negatives in evaluation); perceptual limitations in adverse conditions may cause cascading reasoning errors; decision consistency may break down despite coherent intermediate reasoning.

**First 3 Experiments**: 1) Baseline evaluation of SOTA MLLMs without multi-level prompts, 2) Ablation study comparing performance with and without explicit CoT requirements, 3) Cross-condition analysis examining model performance across different types of adverse weather

## Open Questions the Paper Calls Out

None

## Limitations

The benchmark's reliance on manually annotated ground truth for each reasoning step, while valuable for interpretability, may not fully capture the diverse valid reasoning paths an autonomous system might take. The dataset size of 5,400 instances, though substantial, may limit statistical robustness for fine-grained analysis of model performance across specific adverse conditions. The multi-dimensional evaluation metric design, while comprehensive, introduces complexity in interpretation and may not fully account for semantically equivalent but syntactically different reasoning paths.

## Confidence

**High Confidence**: The claim that current SOTA MLLMs achieve below 60% accuracy is supported by experimental results presented in the paper. The multi-dimensional evaluation metric design and its three components (semantic similarity, reasoning coherence, decision consistency) are clearly defined and methodologically sound.

**Medium Confidence**: The assertion that AD2-Bench is the "first benchmark" for this specific task, while likely accurate given the detailed differentiation from existing work, requires broader literature review to definitively establish precedence.

**Medium Confidence**: The effectiveness of multi-level visual prompts in mitigating perceptual limitations is demonstrated empirically but could benefit from more extensive ablation studies to isolate the contribution of each prompt level.

## Next Checks

1. Conduct cross-dataset validation by testing AD2-Bench-trained models on established autonomous driving datasets to assess generalizability
2. Perform inter-annotator agreement studies on a subset of reasoning steps to quantify annotation consistency and establish reliability metrics
3. Implement stress testing with systematically degraded image quality across different adverse conditions to better characterize model failure modes and robustness boundaries