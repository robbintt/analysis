---
ver: rpa2
title: Designing User-Centric Metrics for Evaluation of Counterfactual Explanations
arxiv_id: '2507.15162'
source_url: https://arxiv.org/abs/2507.15162
tags:
- user
- feature
- proximity
- cfes
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the gap between existing counterfactual explanation
  (CFE) evaluation metrics and user preferences by conducting two user studies to
  validate personalized weighted proximity as a more user-aligned metric. The first
  pilot study with 20 MTurk participants revealed that standard proximity and sparsity-based
  CFEs matched user preferences in only 63.81% and 69.51% of cases, respectively.
---

# Designing User-Centric Metrics for Evaluation of Counterfactual Explanations

## Quick Facts
- arXiv ID: 2507.15162
- Source URL: https://arxiv.org/abs/2507.15162
- Authors: Firdaus Ahmed Choudhury; Ethan Leicht; Jude Ethan Bislig; Hangzhi Guo; Amulya Yadav
- Reference count: 19
- One-line primary result: AWP model predicts user-preferred CFEs with 84.37% accuracy, outperforming uniform proximity baselines

## Executive Summary
This paper addresses the gap between existing counterfactual explanation (CFE) evaluation metrics and user preferences by conducting two user studies to validate personalized weighted proximity as a more user-aligned metric. The first pilot study with 20 MTurk participants revealed that standard proximity and sparsity-based CFEs matched user preferences in only 63.81% and 69.51% of cases, respectively. The second, more detailed two-day study with 41 participants facing realistic credit scenarios tested three hypotheses about user preferences. Results showed strong support for personalized weighted proximity (80.2% preference) and feature-specific acceptability thresholds, but limited evidence for rounding preferences. Based on these findings, the authors propose the Acceptability & Weighted Proximity (AWP) model, which predicts user-preferred CFEs with 84.37% accuracy. This work provides the first human-centered validation of personalized cost models in CFE generation, highlighting the need for adaptive, user-centered evaluation metrics.

## Method Summary
The authors conducted two user studies to validate personalized weighted proximity for CFE evaluation. Study 1 (pilot) used 20 MTurk participants to compare user preferences against proximity, sparsity, and mixed metrics. Study 2 involved 41 participants in a two-session protocol: Session 1 elicited personalized feature weights via pairwise comparisons using the Bradley-Terry model, while Session 2 tested acceptability thresholds and CFE preferences in credit scenarios. The authors generated synthetic credit data with 5 features, trained a decision tree classifier, and produced CFEs using Floyd-Warshall shortest-path algorithm. The AWP model implements a two-stage process: Stage 1 filters CFEs exceeding user acceptability thresholds, and Stage 2 selects the CFE with lowest weighted proximity among survivors.

## Key Results
- Personalized weighted proximity achieved 80.2% alignment with user preferences in pairwise CFE comparisons
- AWP model predicted user-preferred CFEs with 84.37% accuracy, significantly outperforming uniform proximity (63.81%)
- Users employed feature-specific acceptability thresholds as initial filters, with 84.4% choosing minimum weighted proximity among acceptable CFEs
- Limited support for rounding preferences (Hypothesis 3), suggesting users prioritize exact cost-minimizing modifications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Personalized feature weights improve CFE preference prediction over uniform proximity.
- Mechanism: Pairwise comparisons elicit user-specific cost perceptions; Bradley-Terry models infer per-feature weights βi; weights convert to w_i = -β_i for weighted L1 proximity. Users select CFEs minimizing their personal weighted cost.
- Core assumption: Users have stable, feature-specific effort perceptions that generalize across scenarios.
- Evidence anchors:
  - [abstract] "propose the AWP model... predicts user-preferred CFEs with 84.37% accuracy"
  - [section: User Study Results] "participants selected recourses optimized on their personalized feature weights 80.2% of the time"
  - [corpus] UGCE (arXiv:2505.21330) supports user-guided adaptation but does not validate personalization empirically.
- Break condition: If user preferences are inconsistent across scenarios or contexts, learned weights overfit to elicitation task.

### Mechanism 2
- Claim: Users employ hard feature-specific acceptability thresholds as initial filters.
- Mechanism: For each feature i, user has threshold α_i; any CFE requiring change beyond α_i is rejected regardless of weighted proximity. Thresholds are feature-local, not global cost trade-offs.
- Core assumption: Thresholds are relatively stable within a decision session and can be explicitly probed or self-reported.
- Evidence anchors:
  - [section: User Study Results] "participants had a limit for every feature beyond which they either pivoted to the alternative recourse or outright rejected both"
  - [section: AWP Model] "Stage 1 – Feasibility Filtering... If a recourse is found to be 'unacceptable' by the user, it is rejected and filtered out"
  - [corpus] No direct corpus validation; related work on feasibility constraints (Mahajan et al., cited in paper) is simulation-based.
- Break condition: If thresholds are context-dependent or dynamically shift during deliberation, single-value thresholds misrepresent user behavior.

### Mechanism 3
- Claim: The two-stage AWP model (filter-then-compare) approximates user CFE selection.
- Mechanism: Stage 1 applies acceptability thresholds to prune infeasible CFEs; Stage 2 selects minimum weighted proximity among survivors. Sequential gating prevents high-cost features from dominating weighted sum.
- Core assumption: Users process CFEs sequentially (feasibility then optimization), not holistically.
- Evidence anchors:
  - [section: AWP Model] "In 84.4% of these cases, participants chose the recourse with the lower personalized weighted proximity"
  - [section: Pilot Study] Observation 5: "Users are willing to consider a recourse as acceptable as long as its suggested feature modifications remain below some threshold"
  - [corpus] No corpus papers implement or validate AWP directly; mechanism is novel to this work.
- Break condition: If users make trade-offs across features holistically (e.g., accepting large change in one feature to avoid small change in another), the sequential model underfits.

## Foundational Learning

- Concept: **Counterfactual Explanations (CFEs)**
  - Why needed here: The entire framework optimizes CFEs for user preference; understanding validity, proximity, and sparsity is prerequisite.
  - Quick check question: Given a loan applicant x with income $40K, credit score 650, predict whether a CFE requiring +$10K income or +50 credit score has lower L1 proximity (assuming equal ranges).

- Concept: **Bradley-Terry Model**
  - Why needed here: Core mechanism for learning personalized feature weights from pairwise preference data.
  - Quick check question: If a user prefers CFE A over B in 7 of 10 comparisons, what does the Bradley-Terry model infer about the latent strength parameter for features differing between A and B?

- Concept: **L1 Distance and Normalized Proximity**
  - Why needed here: Weighted proximity is the evaluation metric; understanding normalization by feature range is essential for implementation.
  - Quick check question: For features income (range $10K-$500K) and credit score (range 300-850), why is normalization necessary before summing absolute differences?

## Architecture Onboarding

- Component map:
  1. Synthetic data generator → 5-feature loan profiles (income, credit score, loan amount, employment type, education level)
  2. Decision tree classifier → Rule-based loan approval model (glass-box for controlled CFE generation)
  3. CFE generator → Floyd-Warshall shortest path between reject/accept leaves; outputs top-K candidate CFEs
  4. Bradley-Terry weight learner → Fits per-user feature weights from pairwise comparison data
  5. AWP predictor → Two-stage filter (threshold) then rank (weighted proximity)

- Critical path:
  User elicitation (pairwise comparisons) → weight learning → threshold probing → AWP prediction → CFE ranking. Without personalized weights, AWP defaults to unweighted proximity, reducing accuracy.

- Design tradeoffs:
  - Glass-box decision tree vs. black-box: Tree enables controlled CFE generation but limits ecological validity.
  - Synthetic vs. real data: Synthetic enables controlled feature trade-offs but may miss real-world correlations.
  - Threshold probing is interactive (Session 2) vs. assumed pre-specified; production systems may need explicit user input.

- Failure signatures:
  - Low weighted match accuracy (<60%): Indicates weights do not reflect user preferences; may need more elicitation pairs or reweighting.
  - High reject rate on all CFEs: Thresholds too restrictive; may need to relax α_i or generate more diverse CFEs.
  - AWP accuracy near random (50%): Sequential model may not match user decision process; consider holistic scoring alternatives.

- First 3 experiments:
  1. Replicate pilot with global weights on synthetic dataset; confirm proximity match rate ~63% as baseline.
  2. Implement Bradley-Terry weight learning from simulated pairwise data; verify weight recovery against ground truth.
  3. Deploy two-session protocol (n=10) with threshold probing; measure AWP accuracy on held-out CFE scenarios.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the AWP model generalize to independent datasets, or does it overfit the specific behavioral patterns observed in the derivation study?
- Basis in paper: [explicit] The authors note the 84.37% accuracy result may partially reflect overfitting to observed patterns and that "a more rigorous, prospective validation on independent data will be necessary."
- Why unresolved: The current evaluation used retrospective analysis on the same data used to derive the model parameters.
- What evidence would resolve it: A prospective study where AWP predicts user preferences in a new, separate cohort of participants.

### Open Question 2
- Question: Can the AWP framework maintain high predictive accuracy when applied to high-dimensional, noisy real-world datasets and complex black-box models?
- Basis in paper: [explicit] The authors acknowledge reliance on a "well-behaved" synthetic dataset and a glass-box decision tree, stating future efforts should extend to "messier, real-world datasets and state-of-the-art models."
- Why unresolved: The controlled experimental setting may not capture the noise and complexity of actual financial or medical decision-making systems.
- What evidence would resolve it: User studies conducted using actual credit data (e.g., FICO) and deep learning models.

### Open Question 3
- Question: Do user preferences for CFEs in the credit domain transfer to high-stakes domains like healthcare or criminal justice?
- Basis in paper: [explicit] The study limits itself to "recourses for credit rejection scenarios," noting that "preferences may differ across different decision-making tasks."
- Why unresolved: Users might weigh feature modification costs differently when personal health or legal freedom is at stake compared to financial loans.
- What evidence would resolve it: Replicating the AWP validation study in non-financial contexts.

## Limitations
- Controlled synthetic data may not capture real-world correlations and distributions
- Glass-box decision tree reduces ecological validity compared to black-box models
- User acceptability thresholds and preferences may not remain stable over time

## Confidence
- **High confidence**: The superiority of personalized weighted proximity over uniform proximity (84.37% vs 63.81% accuracy) is well-supported by within-study comparisons.
- **Medium confidence**: The two-stage AWP model's predictive validity holds for the synthetic, controlled scenarios tested, but generalizability to real-world deployments is uncertain.
- **Low confidence**: The limited support for rounding preferences (Hypothesis 3) may reflect task design or sample size rather than a true absence of user preference for rounded values.

## Next Checks
1. **External validation**: Apply AWP to CFEs generated from a real-world, black-box credit model (e.g., FICO or bank underwriting data) and compare prediction accuracy to the synthetic setup.
2. **Temporal stability**: Re-test a subset of users after 2-4 weeks to measure consistency of personalized weights and acceptability thresholds.
3. **User comprehension audit**: Conduct think-aloud sessions during CFE evaluation to verify users understand feature trade-offs and are not influenced by presentation artifacts.