---
ver: rpa2
title: 'XISM: an eXploratory and Interactive Graph Tool to Visualize and Evaluate
  Semantic Map Models'
arxiv_id: '2507.04070'
source_url: https://arxiv.org/abs/2507.04070
tags:
- semantic
- graph
- xism
- edges
- forms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces XISM, an interactive tool for constructing
  and visualizing semantic map models that balances automated data-driven graph generation
  with expert refinement capabilities. The system generates candidate semantic maps
  from user-uploaded data using a top-down algorithm and allows iterative edge editing
  with real-time metric feedback.
---

# XISM: an eXploratory and Interactive Graph Tool to Visualize and Evaluate Semantic Map Models

## Quick Facts
- arXiv ID: 2507.04070
- Source URL: https://arxiv.org/abs/2507.04070
- Reference count: 40
- High accuracy (0.963-0.975) and coverage (1.0) on typological datasets after edge merging

## Executive Summary
XISM is an interactive tool that enables linguists to construct and visualize semantic map models from form-function data. The system combines automated graph generation with human-in-the-loop refinement, addressing the tradeoff between computational scalability and expert knowledge in semantic map construction. Using a top-down approach with Kruskal's algorithm, XISM generates candidate graphs from user-uploaded data and allows iterative edge editing with real-time metric feedback. The tool has been validated on three typological datasets with high accuracy and positive user feedback.

## Method Summary
XISM constructs semantic maps through a three-stage process: (1) building a fully-connected weighted graph where edge weights represent co-occurrence frequencies between functions, (2) extracting maximum spanning trees using Kruskal's algorithm and ranking them by Div_D diversity metric, and (3) merging the top K=6,000 candidates iteratively to achieve 100% coverage. The system then enables expert refinement through interactive edge editing while providing real-time feedback on graph metrics. This human-in-the-loop approach balances automated efficiency with linguistic expertise.

## Key Results
- High accuracy across datasets: SUP (0.963), EAT (0.975), DIT (0.963) after edge merging
- Perfect coverage (1.0) achieved for all datasets through the merge algorithm
- User study ratings: utility 3.4/5, efficiency 3.6/5, usability 3.8/5 from 10 participants
- Computational efficiency demonstrated with K=6,000 approximation avoiding full spanning tree enumeration

## Why This Works (Mechanism)
The system works by leveraging the top-down approach to generate multiple candidate semantic maps from the same data, then using the Div_D metric to identify the most diverse and representative graphs. The iterative merge algorithm connects disconnected components by adding edges that maximize functional gain while maintaining graph connectivity. The human-in-the-loop interface allows experts to refine the automated output, ensuring that the final semantic map reflects both statistical patterns and linguistic knowledge.

## Foundational Learning
- **Form-function tables**: Binary matrices representing which linguistic forms express which functions across languages; needed for graph edge-weight calculation
- **Maximum spanning trees**: Subgraphs that connect all nodes with maximum total edge weight; used to identify optimal function relationships
- **Div_D diversity metric**: Measures functional diversity within a semantic map; lower values indicate more focused semantic domains
- **Edge merging algorithms**: Iterative procedures to combine multiple graphs into a single connected structure; essential for achieving 100% coverage
- **Human-in-the-loop systems**: Interactive frameworks where expert input guides automated processes; critical for balancing efficiency with expertise
- **Real-time metric feedback**: Immediate updates of graph quality measures during editing; enables informed decision-making

## Architecture Onboarding
**Component Map**: Data Input -> Graph Construction -> Candidate Generation -> Merge Algorithm -> Interactive Interface -> Expert Refinement
**Critical Path**: User uploads binary form-function table → System generates candidate graphs → Merge algorithm produces initial map → User edits edges → Real-time metrics update → Final semantic map export
**Design Tradeoffs**: Computational efficiency (K=6,000 approximation) vs. exhaustive search; automated generation vs. expert control; real-time feedback vs. processing overhead
**Failure Signatures**: Low coverage (<1.0) indicates disconnected components requiring edge addition; zero productivity for large function spaces reflects combinatorial complexity; slow response times suggest metric calculation bottlenecks
**First Experiments**: 1) Test edge-weight calculation on sample form-function table, 2) Verify spanning tree extraction using small synthetic graph, 3) Validate merge algorithm connectivity on disconnected components

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Small user study sample size (10 participants) limits generalizability of usability findings
- Gold-standard semantic maps for validation are not publicly available, preventing independent accuracy verification
- Computational complexity grows exponentially with number of functions, limiting scalability to very large typological domains

## Confidence
- High confidence in offline graph construction methodology and its computational validity
- Medium confidence in user study results due to small sample size and potential selection bias
- Low confidence in generalizability across typological domains without additional dataset testing

## Next Checks
1. Verify edge-weight calculation by reconstructing the fully-connected graph from binary form-function table using co-occurrence counting
2. Replicate coverage and accuracy metrics on SUP dataset using publicly available versions of WALS/APiCS data
3. Test merge algorithm scalability by applying to synthetic datasets with varying numbers of functions to confirm exponential growth in spanning trees