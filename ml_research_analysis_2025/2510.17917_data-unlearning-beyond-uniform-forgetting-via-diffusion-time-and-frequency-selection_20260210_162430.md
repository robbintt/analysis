---
ver: rpa2
title: Data Unlearning Beyond Uniform Forgetting via Diffusion Time and Frequency
  Selection
arxiv_id: '2510.17917'
source_url: https://arxiv.org/abs/2510.17917
tags:
- unlearning
- diffusion
- data
- time
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data unlearning in diffusion
  models, where the goal is to remove the influence of specific training samples without
  requiring full retraining. The authors observe that existing methods attempt to
  unlearn samples at all diffusion time steps equally, leading to poor-quality generation
  and incomplete forgetting.
---

# Data Unlearning Beyond Uniform Forgetting via Diffusion Time and Frequency Selection

## Quick Facts
- **arXiv ID**: 2510.17917
- **Source URL**: https://arxiv.org/abs/2510.17917
- **Reference count**: 27
- **Key outcome**: Time-frequency selective unlearning improves quality of unlearned samples by up to 31.90% in aesthetic scores while achieving effective forgetting

## Executive Summary
This paper addresses the challenge of data unlearning in diffusion models, where the goal is to remove the influence of specific training samples without requiring full retraining. The authors observe that existing methods attempt to unlearn samples at all diffusion time steps equally, leading to poor-quality generation and incomplete forgetting. They argue that forgetting occurs disproportionately across time and frequency domains, depending on the model and scenarios. To address this, they propose a novel time-frequency selective unlearning approach that focuses on specific time-frequency ranges during training. The method is compatible with existing unlearning objectives and effective in various experimental setups. The authors also introduce a normalized version of SSCD to better evaluate both deletion and quality of unlearned data samples.

## Method Summary
The authors propose a time-frequency selective unlearning approach for diffusion models that applies selective forgetting during training. The method consists of two main components: time selection and frequency selection. Time selection uses a Gaussian window P(t) applied to specific time intervals during the diffusion process, while frequency selection employs a low-pass filter F(·) in the Fourier domain. These components can be combined with existing unlearning objectives like GA, SISS, DPO, and KTO. The approach focuses the unlearning effort on time-frequency regions where forgetting is most effective, preserving generation quality in other regions. A key innovation is the introduction of SSCD_norm, a normalized version of the similarity score change detection metric that accounts for image quality when evaluating unlearning success.

## Key Results
- Time-frequency selective unlearning achieves up to 31.90% improvement in aesthetic scores compared to baseline methods on CelebA-HQ
- The method successfully unlearns specific samples while maintaining generation quality on retain sets, with improved FID-10K scores
- Optimal unlearning time steps differ significantly between unconditional image generation (CelebA-HQ: [250, 750]) and text-to-image models (Stable Diffusion: [750, 1000])
- The proposed SSCD_norm metric provides more reliable evaluation by accounting for image quality differences

## Why This Works (Mechanism)
The method works by recognizing that different diffusion time steps and frequency components contribute unequally to forgetting specific samples. By selectively applying unlearning objectives to time-frequency regions where forgetting is most effective, the model can remove unwanted influences while preserving generation quality in other regions. The frequency selection component is particularly important because high-frequency information often carries fine details and textures that are crucial for maintaining visual quality during unlearning.

## Foundational Learning

**Diffusion Models**: Generative models that learn to reverse a noising process by predicting noise at different time steps. *Why needed*: Understanding the time-dependent nature of diffusion models is crucial for selective unlearning. *Quick check*: Can you explain how DDIM sampling differs from ancestral sampling in diffusion models?

**SSCD (Similarity Score Change Detection)**: Metric measuring the change in similarity between generated samples before and after unlearning. *Why needed*: Standard evaluation metric for data unlearning effectiveness. *Quick check*: Can you calculate SSCD between two generated images using CLIP embeddings?

**Time-Frequency Analysis**: Decomposition of signals into time and frequency components. *Why needed*: Enables selective forgetting by identifying which components carry information about target samples. *Quick check*: Can you explain why low-pass filtering might help preserve image quality during unlearning?

## Architecture Onboarding

**Component map**: Pretrained Diffusion Model -> Time Selection P(t) -> Frequency Filter F(·) -> Unlearning Objective -> Updated Model

**Critical path**: Input image -> Noising process -> Selected time steps -> Gradient update with P(t) and F(·) -> Denoising -> Evaluation

**Design tradeoffs**: The method balances between effective forgetting (requiring strong unlearning) and quality preservation (requiring minimal perturbation). The time-frequency selection mechanism allows for this balance by concentrating unlearning efforts where they are most effective.

**Failure signatures**: 
- Quality collapse (blurry/noisy outputs) indicates wrong time window selection or missing frequency filtering
- Incomplete forgetting (high SSCD) suggests time window excludes critical steps or insufficient unlearning intensity
- FID degradation on retain set indicates over-aggressive unlearning affecting general generation quality

**First experiments**:
1. Implement time selection with P(t) using k=0 on CelebA-HQ with window [250, 750] and evaluate SSCD improvement
2. Add frequency selection with r_t=0.15 to the time-selected model and measure aesthetic score changes
3. Compare unlearning success rate between selective and uniform forgetting approaches using the same computational budget

## Open Questions the Paper Calls Out

**Open Question 1**: How can adaptive strategies be developed to dynamically identify the optimal time steps and frequency components for unlearning without manual tuning? The current implementation requires manually selecting time windows and cutoff frequencies based on empirical observation, which may not generalize across all datasets or model architectures.

**Open Question 2**: What underlying mechanisms cause the optimal unlearning time steps to differ between unconditional image generation and text-to-image models? The authors note that middle steps are optimal for CelebA-HQ, but later steps are required for Stable Diffusion, and they offer hypotheses regarding sampling procedures but do not establish a definitive cause.

**Open Question 3**: Does the proposed SSCD_norm metric correlate more reliably with human perception of unlearning quality than standard SSCD? While theoretically motivated to fix flaws in raw SSCD, the new metric's alignment with human judgment regarding successful unlearning remains empirically unverified.

## Limitations
- Method effectiveness depends on identifying optimal time-frequency ranges through heuristic tuning or preliminary gradient norm analysis
- The normalized SSCD metric introduces an additional hyperparameter ρ that needs careful calibration
- Evaluation focuses on high-level aesthetic scores and FID metrics without detailed perceptual studies of unlearned content quality
- Method's generalization to non-diffusion architectures or multi-concept unlearning scenarios remains unexplored

## Confidence

**High confidence** in the core observation that forgetting is time-frequency dependent
**Medium confidence** in the proposed selection mechanism's effectiveness across diverse scenarios
**Medium confidence** in the normalized SSCD metric's reliability for evaluation

## Next Checks

1. Verify time-frequency selection robustness by testing multiple k and r_t configurations beyond the paper's chosen values
2. Conduct ablation studies isolating time selection vs frequency selection effects on forgetting and quality
3. Test the method's performance on models with different training objectives (e.g., score-matching vs likelihood-based) to assess generalizability