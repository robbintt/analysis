---
ver: rpa2
title: 'RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design'
arxiv_id: '2512.03762'
source_url: https://arxiv.org/abs/2512.03762
tags:
- heuristics
- heuristic
- roco
- matrix
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RoCo introduces a multi-agent role-based system for automatic heuristic
  design, coordinating explorer, exploiter, critic, and integrator agents to collaboratively
  generate high-quality heuristics. This approach extends population-based evolutionary
  methods by integrating structured agent collaboration and memory-guided mutations.
---

# RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design

## Quick Facts
- arXiv ID: 2512.03762
- Source URL: https://arxiv.org/abs/2512.03762
- Reference count: 40
- Key outcome: RoCo framework outperforms baselines across five COPs, showing superior convergence and stability in black-box settings

## Executive Summary
RoCo introduces a multi-agent role-based system for automatic heuristic design in combinatorial optimization. The framework coordinates four specialized LLM agents—explorer, exploiter, critic, and integrator—to collaboratively generate and refine heuristics through structured population-based evolution. By leveraging LLMs for mutation and crossover operations guided by memory-driven prompts, RoCo extends traditional evolutionary algorithms with more intelligent search behavior. Experimental results demonstrate consistent performance improvements over state-of-the-art baselines across diverse problem settings.

## Method Summary
RoCo employs a population-based evolutionary framework enhanced by LLM-driven collaboration. Four agents work in tandem: explorer generates diverse mutations, exploiter refines promising candidates, critic evaluates solutions using white-box or black-box feedback, and integrator synthesizes improvements. The system maintains a population of heuristics that evolve through iterative cycles of generation, evaluation, and refinement. Memory mechanisms guide mutations toward unexplored regions, while structured prompts ensure each agent performs its specialized role effectively. The approach operates in both white-box (full information) and black-box (limited feedback) settings, with heuristics encoded as executable code rather than parameter vectors.

## Key Results
- RoCo consistently outperforms ReEvo and HSEvo baselines across five combinatorial optimization problems
- Demonstrates faster convergence and improved stability in black-box settings compared to existing methods
- Shows strong generalization across problem scales and maintains effectiveness when integrated with local search frameworks

## Why This Works (Mechanism)
The multi-agent collaboration architecture enables more sophisticated search behavior than traditional evolutionary approaches. By separating exploration, exploitation, evaluation, and integration into specialized roles, the system can simultaneously pursue diverse strategies while maintaining focus on promising regions. The LLM's ability to generate and reason about code allows for complex heuristic mutations that would be difficult to achieve through traditional genetic operators. Memory-guided mutations prevent premature convergence by systematically exploring underrepresented regions of the search space.

## Foundational Learning
- **Population-based evolutionary algorithms**: Iterative improvement through selection, mutation, and crossover operations on a population of candidate solutions
- **LLM-powered code generation**: Using large language models to create executable heuristics and optimization strategies
- **Multi-agent collaboration**: Coordinating multiple specialized agents with distinct roles to achieve collective intelligence
- **Memory-guided search**: Maintaining and utilizing historical information to direct exploration toward unexplored regions
- **White-box vs black-box optimization**: Differentiating between full problem information access versus limited feedback scenarios
- **Combinatorial optimization problem structure**: Understanding TSP, CVRP, MKP, and other discrete optimization challenges

## Architecture Onboarding

**Component map**: Explorer -> Critic -> Exploiter -> Integrator -> Population Memory -> Explorer

**Critical path**: Solution generation → Evaluation → Selection → Mutation/Crossover → Population update → Memory integration

**Design tradeoffs**: 
- Specialized agents provide focused capabilities but increase coordination complexity
- Code-based representation enables complex heuristics but requires careful LLM prompting
- Memory mechanisms improve exploration but add storage and computation overhead
- Multi-agent approach enhances search but increases inference costs

**Failure signatures**:
- Poor coordination between agents leading to redundant or conflicting operations
- LLM-generated code that fails to compile or execute correctly
- Premature convergence due to insufficient exploration or memory limitations
- Evaluation bottlenecks when critic agent cannot effectively assess solutions

**First 3 experiments to run**:
1. Single-agent baseline (remove collaboration) to quantify multi-agent benefits
2. Memory ablation study to measure exploration impact
3. Problem size scaling test to assess computational complexity growth

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the RoCo framework be successfully extended to continuous or mixed-integer optimization domains?
- Basis in paper: [explicit] The Conclusion explicitly lists applying RoCo to problems "beyond combinatorial optimization (e.g., continuous, mixed-integer)" as a future direction.
- Why unresolved: The current study evaluates RoCo exclusively on discrete COPs (TSP, CVRP, MKP, etc.), and the role-based prompts (explorer/exploiter) are designed for heuristic code generation rather than continuous parameter tuning.
- What evidence would resolve it: Demonstration of RoCo evolving competitive optimization strategies for continuous benchmark functions or mixed-integer programming tasks.

### Open Question 2
- Question: Does RoCo maintain its performance advantages when applied to dynamic, real-world logistics and scheduling problems?
- Basis in paper: [explicit] The authors state that exploring RoCo's potential in real-world applications like logistics and scheduling "remains an exciting avenue for practical impact."
- Why unresolved: Experiments rely on static, synthetic benchmark datasets (e.g., uniformly sampled nodes), which lack the noise, constraints, and dynamism of physical-world industrial environments.
- What evidence would resolve it: Evaluation of generated heuristics on dynamic VRP variants or industrial scheduling instances with real-world constraints.

### Open Question 3
- Question: How sensitive is the multi-agent collaboration architecture to the reasoning capabilities of the underlying LLM?
- Basis in paper: [inferred] The experiments utilize only GPT-4o-mini, leaving the system's dependency on high-capability models untested.
- Why unresolved: The critic and integrator agents require sophisticated reasoning to synthesize feedback and code; it is unclear if smaller or open-source models would fail to coordinate effectively, negating the framework's benefits.
- What evidence would resolve it: Ablation studies substituting the backbone LLM with smaller or open-source alternatives (e.g., Llama 3) to measure the performance gap.

## Limitations
- Limited testing on large-scale problems may not reflect real-world computational constraints
- Heavy dependency on LLM capabilities introduces potential brittleness and inference costs
- Framework's generalization to non-combinatorial optimization domains remains unproven
- Evaluation methodology may not fully capture robustness across diverse problem types

## Confidence
- **High confidence**: The effectiveness of RoCo in improving convergence speed and stability in black-box settings, as demonstrated through controlled experiments
- **Medium confidence**: The superiority of RoCo over ReEvo and HSEvo baselines, given the specific problem instances tested
- **Low confidence**: The scalability and real-world applicability of RoCo, due to limited testing on large-scale or highly complex problems

## Next Checks
1. Evaluate RoCo on larger-scale combinatorial optimization problems to assess scalability and performance degradation
2. Test the framework's robustness across diverse problem domains beyond the five COPs studied, including real-world applications
3. Conduct ablation studies to quantify the individual contributions of each role (explorer, exploiter, critic, integrator) to the overall performance