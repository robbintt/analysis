---
ver: rpa2
title: Contextual Augmentation for Entity Linking using Large Language Models
arxiv_id: '2510.18888'
source_url: https://arxiv.org/abs/2510.18888
tags:
- entity
- linking
- disambiguation
- entities
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents an entity linking approach using large language\
  \ models for contextual augmentation. The method integrates named entity recognition\
  \ and disambiguation into a unified framework with a fine-tuned T5 model, then leverages\
  \ LLaMA3 to expand ambiguous entity mentions into their likely Wikipedia titles\
  \ (e.g., \"Angelina\" \u2192 \"Angelina Jolie\")."
---

# Contextual Augmentation for Entity Linking using Large Language Models

## Quick Facts
- arXiv ID: 2510.18888
- Source URL: https://arxiv.org/abs/2510.18888
- Reference count: 11
- Key outcome: 70B LLaMA3 provides the most stable and accurate entity mention expansions, achieving state-of-the-art performance on most out-of-domain datasets

## Executive Summary
This paper presents an entity linking approach that integrates named entity recognition and disambiguation into a unified T5 framework, then enhances it with large language model (LLaMA3) contextual augmentation. The method expands ambiguous entity mentions into their likely Wikipedia titles based on surrounding context, improving disambiguation accuracy for terse or ambiguous spans. Experiments demonstrate significant performance gains on out-of-domain datasets, with the 70B parameter LLaMA3 model providing the most stable and accurate expansions compared to smaller models.

## Method Summary
The approach combines a fine-tuned T5 model (for joint NER and entity disambiguation) with LLaMA3 contextual augmentation. The T5 model is trained on KILT data with inputs suffixed with `target_ner` or `target_el` to learn both tasks simultaneously. For augmentation, LLaMA3-70B expands detected entity mentions (e.g., "Angelina" → "Angelina Jolie") based on context. A dictionary mapping Wikipedia titles to URIs filters model outputs to prevent hallucinations. The pipeline follows: T5 performs NER → LLaMA3 expands detected spans → T5 performs ED on augmented text → dictionary filter validates predictions.

## Key Results
- State-of-the-art performance on most out-of-domain datasets using LLaMA3-70B augmentation
- Significant improvements over traditional two-step methods for ambiguous or short-text mentions
- 70B parameter LLaMA3 provides most stable and accurate expansions compared to smaller models
- Dictionary-based filtering successfully mitigates hallucination risks while maintaining precision

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Contextual augmentation via large language models (LLMs) improves entity disambiguation accuracy for ambiguous or short-text mentions.
- **Mechanism:** The approach uses LLaMA3-70B to expand terse entity mentions (e.g., "Angelina") into full Wikipedia titles (e.g., "Angelina Jolie") based on surrounding context. This "contextual enrichment" replaces ambiguous spans with more unique identifiers before the final linking step, effectively simplifying the retrieval task for the underlying entity linking model.
- **Core assumption:** The LLM possesses sufficient parametric knowledge to resolve the ambiguity correctly given the local context, and the expansion mapping is deterministic enough to avoid introducing noise.
- **Evidence anchors:**
  - [abstract] "approach leverages large language models to enrich the context of entity mentions, yielding better performance in entity disambiguation."
  - [section 3.2.2] "This is achieved by prompting the LlaMA3 model to generate these extended forms... replacing ambiguous mentions with their more specific counterparts."
  - [corpus] Related work "Harnessing Deep LLM Participation for Robust Entity Linking" supports the general efficacy of LLMs in EL pipelines.
- **Break condition:** If the input context is too sparse or ambiguous for the LLM to form a confident inference, it may produce hallucinated or incorrect expansions (e.g., expanding "Apple" to a company when the context implies fruit), degrading performance.

### Mechanism 2
- **Claim:** Jointly fine-tuning a single Transformer model for both Named Entity Recognition (NER) and Entity Disambiguation (ED) creates shared representations that enhance robustness.
- **Mechanism:** Instead of training separate models for span detection (NER) and linking (ED), the authors fine-tune a T5 model on a combined dataset where samples are suffixed with `target_ner` or `target_el`. This forces the model to learn syntactic span detection and semantic linking simultaneously, reducing error propagation typical of pipeline architectures.
- **Core assumption:** The model capacity of T5-base is sufficient to handle the dual objective without catastrophic forgetting or task interference.
- **Evidence anchors:**
  - [abstract] "integrates named entity recognition and disambiguation into a unified framework."
  - [section 3.2.4] "This integration enhances the robustness and accuracy of our approach... leading to improved performance."
  - [corpus] Corpus signals for "End-to-end neural entity linking" (Kolitsas et al.) validate the general shift toward unified architectures.
- **Break condition:** If training data distribution for NER and ED is heavily imbalanced, the model may optimize for one task at the expense of the other.

### Mechanism 3
- **Claim:** Dictionary-based filtering constrains generative model outputs, mitigating the risk of hallucinations during entity disambiguation.
- **Mechanism:** To prevent the T5 or LLaMA models from generating plausible but non-existent entity titles, the system maps output strings against a fixed dictionary of valid Wikipedia titles/URIs. Predictions that do not match the dictionary are discarded.
- **Core assumption:** The target Knowledge Graph (Wikipedia) is static enough that a precomputed dictionary covers the vast majority of valid entities, or "out-of-wiki" entities are acceptable losses.
- **Evidence anchors:**
  - [section 3.3] "To avoid this, we generated a dictionary that maps all Wikipedia titles to their URIs. By applying this dictionary, we can omit all annotations, where no exact match in the dictionary exists."
  - [abstract] Implies a unified framework but section 3.3 explicitly details the error correction mechanism.
  - [corpus] Corpus evidence for explicit dictionary constraint mechanisms is weak in the provided neighbor summaries.
- **Break condition:** If the system encounters a valid new entity not in the static dictionary, it will force a "miss" rather than a correct link, limiting adaptability to evolving knowledge.

## Foundational Learning

- **Concept:** **Autoregressive Entity Linking (GENRE/Seq2Seq)**
  - **Why needed here:** The paper utilizes a T5 model (text-to-text) rather than a bi-encoder/retriever approach. Understanding that EL is framed as a sequence generation task (generating the entity name token-by-token) is crucial for interpreting the model architecture.
  - **Quick check question:** Does the model retrieve a candidate from an index or generate the entity name as a text string?

- **Concept:** **Zero-shot Prompting Strategies**
  - **Why needed here:** The contextual augmentation relies on prompting LLaMA3 without fine-tuning it on the specific EL task. Understanding prompt engineering (instruction + context) is necessary to replicate the augmentation module.
  - **Quick check question:** How does the prompt structure separate the instruction from the raw text data to ensure the LLM outputs the desired format?

- **Concept:** **Micro-F1 (InKB) Evaluation**
  - **Why needed here:** The results use "InKB micro F1," which explicitly excludes "out-of-wiki" entities. To interpret the performance drops or gains correctly, one must understand that the metric only rewards linking to pre-existing Knowledge Graph entries.
  - **Quick check question:** If the model correctly identifies a real-world entity that is missing from the Knowledge Graph, does this metric count it as a success or failure?

## Architecture Onboarding

- **Component map:** Input text → T5 (NER) → LLaMA3 expansion → T5 (ED) → Dictionary filter → Output links
- **Critical path:** The interaction between the T5 model and the Augmentation Module. In the "Traditional Setup" (which performed best), T5 performs NER → LLaMA3 expands the detected spans → T5 performs ED on the *expanded* text.
- **Design tradeoffs:**
  - **Accuracy vs. Cost:** Using LLaMA3-70B for augmentation improves SOTA on out-of-domain data but introduces significant inference latency and GPU memory overhead compared to standard NER.
  - **Static vs. Dynamic KG:** The dictionary constraint (Mechanism 3) ensures precision but prevents the model from linking new entities added to Wikipedia after the dictionary dump.
- **Failure signatures:**
  - **Hallucination Loop:** LLaMA3 expands a span to a non-existent entity (e.g., "Angelina Jolie's Sister" when none exists), and the Dictionary Filter drops it, resulting in a null link.
  - **Error Propagation:** If the initial NER step misses a span, the Augmentation step never sees it, and the entity is lost entirely.
  - **Format Drift:** Smaller LLMs (e.g., 8B parameters) output JSON inconsistently, breaking the regex parser that extracts expansions.
- **First 3 experiments:**
  1. **Baseline Validation:** Run the fine-tuned T5 (NER+ED) on AIDA-test-B without augmentation to establish a baseline F1 score vs. the paper's reported 67.4.
  2. **Augmentation Ablation:** Enable LLaMA3-70B augmentation on the KORE50 dataset (high ambiguity) to verify the jump in F1 score (paper claims ~50.0 → ~70.6).
  3. **Hallucination Stress Test:** Feed synthetic text with ambiguous entities not in the training set and check if the dictionary filter successfully rejects invalid LLaMA generations without crashing the pipeline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLM-based disambiguation strategies perform in predicting rare entities compared to common ones?
- Basis in paper: [explicit] The conclusion states that future work will focus on analyzing the performance of these strategies on rare entities, which requires creating new benchmark datasets.
- Why unresolved: Current benchmarks are outdated and do not sufficiently address the challenge of predicting rare or "long-tail" entities.
- What evidence would resolve it: Evaluation results on a newly created benchmark dataset specifically designed to test rare entity prediction.

### Open Question 2
- Question: To what extent does the inclusion of benchmark datasets in LLM pre-training corpora affect the validity of Entity Linking evaluations?
- Basis in paper: [explicit] The limitations section notes it is currently unclear to what degree existing benchmarks have been included in the training data of modern LLMs.
- Why unresolved: Lack of transparency in LLM training data makes it difficult to distinguish between model generalization and memorization.
- What evidence would resolve it: A data contamination analysis or evaluation on temporally held-out datasets guaranteed to be absent from LLM training sets.

### Open Question 3
- Question: Can this text-based augmentation approach generalize to knowledge graphs like Wikidata where graph structure is necessary for disambiguation?
- Basis in paper: [inferred] The limitations section highlights that the method relies on Wikipedia titles, whereas other graphs (e.g., Wikidata) require graph-based context to distinguish entities with identical labels (e.g., Berlin city vs. state).
- Why unresolved: The current model architecture relies solely on text-based features and does not integrate the graph topology required for non-Wikipedia KGs.
- What evidence would resolve it: Experimental results applying the approach to a Wikidata linking task or augmenting the model with graph embeddings.

## Limitations

- Heavy reliance on LLaMA3-70B introduces significant computational overhead that limits practical deployment
- Dictionary-based filtering creates a rigid system unable to link entities missing from the Wikipedia snapshot
- Fine-tuning procedure lacks critical hyperparameters (learning rate, batch size, optimizer), making exact replication difficult

## Confidence

- **High Confidence:** The unified T5 framework for NER+ED integration is technically sound and well-documented. The dictionary filtering mechanism for hallucination prevention is straightforward and verifiable.
- **Medium Confidence:** The LLaMA3-70B contextual augmentation provides SOTA performance on out-of-domain datasets. The performance improvements are substantial but may depend heavily on the quality of the augmentation prompts and the specific characteristics of each test dataset.
- **Low Confidence:** The exact replication of results is uncertain due to missing hyperparameters and the opaque nature of the LLaMA3-70B model's internal reasoning. The generalization claims across diverse datasets need independent verification.

## Next Checks

1. **Baseline Establishment:** Run the fine-tuned T5 (NER+ED) on AIDA-test-B without augmentation to establish a baseline F1 score versus the paper's reported 67.4, isolating the contribution of the unified architecture from the augmentation module.

2. **Hallucination Stress Test:** Create synthetic test cases with ambiguous entities not in the training data and verify that the dictionary filter successfully rejects invalid LLaMA3 expansions without causing pipeline failures, measuring both precision and recall.

3. **Cost-Benefit Analysis:** Measure inference latency and GPU memory usage of the full pipeline (T5 + LLaMA3-70B augmentation) on a representative dataset, comparing against the computational cost to performance gain ratio of baseline methods to assess practical deployment viability.