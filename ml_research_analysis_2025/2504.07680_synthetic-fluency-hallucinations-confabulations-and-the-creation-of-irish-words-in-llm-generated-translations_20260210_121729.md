---
ver: rpa2
title: 'Synthetic Fluency: Hallucinations, Confabulations, and the Creation of Irish
  Words in LLM-Generated Translations'
arxiv_id: '2504.07680'
source_url: https://arxiv.org/abs/2504.07680
tags:
- irish
- hallucinations
- translation
- rules
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates hallucinations in LLM-generated Irish translations,
  focusing on novel word creation. We analyzed hallucinations in verb and noun categories,
  identifying six distinct patterns for nouns.
---

# Synthetic Fluency: Hallucinations, Confabulations, and the Creation of Irish Words in LLM-Generated Translations

## Quick Facts
- arXiv ID: 2504.07680
- Source URL: https://arxiv.org/abs/2504.07680
- Authors: Sheila Castilho; Zoe Fitzsimmons; Claire Holton; Aoife Mc Donagh
- Reference count: 27
- Key outcome: GPT-4.0 Mini generates significantly more Irish word hallucinations (2.14 per 1,000 tokens) than GPT-4.0 (0.86 per 1,000 tokens), with Mini showing lower morphological rule adherence (40% vs 71%).

## Executive Summary
This study investigates hallucinations in LLM-generated Irish translations, focusing on novel word creation. We analyzed hallucinations in verb and noun categories, identifying six distinct patterns for nouns. Our findings show that both GPT-4.0 and GPT-4.0 Mini generate similar types of hallucinations, but the Mini model does so at significantly higher frequency (2.14 vs 0.86 hallucinations per 1,000 tokens). We found that GPT-4.0 adheres to Irish morphological rules more consistently (71%) than the Mini model (40%). Many confabulations resemble patterns made by Irish learners, raising questions about potential influence on language evolution. The study highlights the need for further research on LLM impacts on morphologically rich, low-resource languages.

## Method Summary
The study analyzed English-to-Irish translations generated by GPT-4.0 and GPT-4.0 Mini using three domain-specific texts from the DELA corpus (scientific, medical, technical content). Researchers submitted full texts via ChatGPT web interface with a simple translation prompt, manually identified hallucinated words through dictionary lookup, classified them into six noun patterns (Compounds, Lazy Gaelicisation, Good Confabulations, Code-switching, Prefix, Suffix) and verb patterns, then evaluated morphological correctness against Irish grammar rules.

## Key Results
- GPT-4.0 Mini generates 2.14 hallucinations per 1,000 tokens compared to GPT-4.0's 0.86 per 1,000 tokens
- GPT-4.0 adheres to Irish morphological rules in 71% of hallucinated words versus 40% for GPT-4.0 Mini
- Hallucinations primarily occur in domain-specific technical texts, not general news content
- Six distinct noun hallucination patterns identified, with confabulations showing morphological patterns similar to Irish learner errors

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Domain-specific terminology in low-resource languages triggers higher hallucination rates due to lexical gaps in training data.
- **Mechanism:** When LLMs encounter unfamiliar technical terms (scientific, medical), they lack established Irish equivalents in their training distribution. The model's generative process fills these gaps by constructing plausible-looking words using available morphological patterns, rather than admitting uncertainty or falling back to English.
- **Core assumption:** The correlation between technical domain content and hallucination frequency reflects insufficient training coverage rather than architectural limitations.
- **Evidence anchors:**
  - [abstract] "We classify these hallucinations within verb and noun categories, identifying six distinct patterns among the latter."
  - [section 3.1] "general texts (such as general news from the WMT corpora) did not produce any of these hallucinations. However, domain-specific texts, particularly those in scientific and medical fields containing a higher frequency of unfamiliar terms, showed noticeable examples of these hallucinations."
  - [corpus] Weak direct corpus evidence—neighbor papers address hallucination detection broadly but not domain-specific triggers in low-resource languages.
- **Break condition:** If hallucinations occurred at similar rates across domains regardless of lexical familiarity, domain-specific gaps would not be the causal driver.

### Mechanism 2
- **Claim:** Smaller model capacity reduces morphological rule adherence during word invention.
- **Mechanism:** GPT-4.0 Mini's reduced parameter count limits its ability to maintain consistent application of Irish morphological constraints (lenition rules, vowel harmony, declension patterns) during generation. The larger GPT-4.0 model better internalizes and applies these complex rules even when inventing non-existent words.
- **Core assumption:** The performance gap between models reflects capacity differences rather than different training data or architectural choices.
- **Evidence anchors:**
  - [abstract] "GPT-4.0 adheres to Irish morphological rules more consistently (71%) than the Mini model (40%)."
  - [section 4] "the Mini model shows a greater number of invented hallucinated words in comparison with GPT4, showing a rate of 2.14 hallucinations of this type, against 0.86 hallucinations for the latter."
  - [corpus] No direct corpus evidence on model size vs. morphological consistency—this represents a gap in prior work.
- **Break condition:** If both models showed similar morphological adherence rates despite size differences, capacity would not be the causal factor.

### Mechanism 3
- **Claim:** Confabulations emerge from internalized word-formation patterns rather than random errors.
- **Mechanism:** Models learn morphological processes (compounding, affixation, phonetic adaptation) from training data. When lacking lexical items, they apply these productive patterns to generate "confabulations"—morphologically plausible inventions. This mirrors human learner strategies like code-switching and phonetic borrowing.
- **Core assumption:** The similarity between LLM confabulations and learner errors reflects analogous pattern-based generation rather than coincidence.
- **Evidence anchors:**
  - [abstract] "Many confabulations resemble patterns made by Irish learners, raising questions about potential influence on language evolution."
  - [section 4.2.2] "These phonetic adaptations have been found among Irish speakers, particularly in informal or spontaneous speech, and sometimes in writing."
  - [corpus] Limited corpus support—related work on confabulation exists (Sui et al., 2024 cited in paper) but not specifically for morphological pattern transfer in low-resource languages.
- **Break condition:** If confabulations showed no systematic morphological patterns and appeared genuinely random, pattern-based generation would not explain the phenomenon.

## Foundational Learning

- **Concept:** Irish morphological system (declensions, conjugations, initial mutations)
  - **Why needed here:** Understanding whether hallucinations follow rules requires knowing those rules—e.g., broad/slender vowel harmony, lenition triggers, plural formation patterns across 5 declensions.
  - **Quick check question:** Can you identify why "gaothchumhachtaí" follows Irish morphology while "gaoithchumachta" does not?

- **Concept:** Hallucination taxonomy (factuality vs. faithfulness; hallucination vs. confabulation)
  - **Why needed here:** The paper distinguishes general hallucinations from confabulations—internally coherent inventions. This classification determines whether outputs are random errors or systematic pattern applications.
  - **Quick check question:** Why is "nascáil" (phonetic adaptation of "nacelle") classified as confabulation rather than simple error?

- **Concept:** Low-resource language challenges in neural MT/LLMs
  - **Why needed here:** Irish is both morphologically rich and under-represented in training data. These compound factors explain why models struggle differently than for high-resource languages.
  - **Quick check question:** Why would a model produce more hallucinations for technical Irish text than for general news, even if both were in the training corpus?

## Architecture Onboarding

- **Component map:** Input layer (domain-specific English source text) -> Translation prompt (simple instruction) -> Generation layer (token-by-token Irish output) -> Detection layer (manual dictionary lookup) -> Classification layer (six-category taxonomy) -> Evaluation layer (morphological rule adherence checking)

- **Critical path:**
  1. Select domain-specific test sets (scientific/medical content triggers hallucinations)
  2. Generate translations with minimal prompting (avoid guiding morphology)
  3. Identify hallucinated words via dictionary cross-reference
  4. Classify by pattern type
  5. Evaluate morphological correctness against Irish grammar rules

- **Design tradeoffs:**
  - Simple prompts vs. morphological guidance: Simple prompts reveal natural model behavior but produce more errors
  - Model size vs. evaluation cost: Larger models hallucinate less but require more compute to test
  - Manual vs. automated detection: Manual analysis catches subtle morphological violations; automation misses rule-breaking patterns

- **Failure signatures:**
  - **High hallucination rate in general text:** Indicates broader training gaps beyond domain-specific issues
  - **Random morphological patterns:** Suggests models haven't internalized rules (breaks Mechanism 3)
  - **Similar rates across model sizes:** Contradicts capacity-based explanation (breaks Mechanism 2)
  - **Refusal to translate:** Observed with Co-Pilot and Gemini—different failure mode requiring verbose output handling

- **First 3 experiments:**
  1. **Domain comparison:** Translate identical content in general vs. technical domains; measure hallucination frequency difference to validate domain-specific triggering (Mechanism 1)
  2. **Model scale ablation:** Test multiple model sizes (GPT-4.0, Mini, intermediate if available) on same technical text; plot morphological adherence rate vs. parameter count to validate capacity effects (Mechanism 2)
  3. **Pattern transfer test:** Provide models with Irish morphology rules in context; measure whether explicit rule access reduces morphologically incorrect hallucinations, testing whether the barrier is knowledge access or application capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Irish speakers perceive and react to LLM-generated confabulations and hallucinations?
- Basis in paper: [explicit] The authors state: "future work should look into how speakers perceive and react to these hallucinations and confabulations."
- Why unresolved: The study only performed linguistic classification of outputs without conducting user studies or perception experiments.
- What evidence would resolve it: Surveys, interviews, or acceptability judgment tasks with native speakers, learners, and new speakers of Irish.

### Open Question 2
- Question: Could LLM-generated confabulations, if encountered frequently, influence Irish language evolution?
- Basis in paper: [explicit] The authors ask: "Could these errors, if encountered frequently in machine-generated content, influence the way Irish is written or even spoken over time?"
- Why unresolved: The paper provides no longitudinal data or real-world usage tracking to assess actual influence on language change.
- What evidence would resolve it: Longitudinal corpus analysis tracking adoption of confabulated terms in Irish media and online content.

### Open Question 3
- Question: Do confabulation patterns generalize to other morphologically rich, low-resource languages?
- Basis in paper: [explicit] The authors note "similar concerns arise in other morphologically rich, low-resource languages, such as Scottish Gaelic, and Welsh."
- Why unresolved: Only Irish was examined; no comparative cross-linguistic data exists.
- What evidence would resolve it: Replication studies applying the same classification framework to Scottish Gaelic, Welsh, and similar languages.

### Open Question 4
- Question: Do LLM confabulations help fill lexical gaps in technical domains or undermine existing vocabulary?
- Basis in paper: [explicit] The authors ask whether forms "could help fill lexical gaps in technical domains where Irish terminology is scarce" or "risk further undermining existing Irish vocabulary."
- Why unresolved: The study documents confabulations in technical domains but does not assess their functional impact or compare against official terminology databases.
- What evidence would resolve it: Comparison of confabulated terms against official terminology databases; studies of real-world translation workflow adoption.

## Limitations

- Manual hallucination detection and classification relies on linguistic expertise and specific dictionary resources, introducing potential variability
- Speculation about LLM confabulations influencing language evolution lacks empirical support and remains highly speculative
- Model behavior may vary across different ChatGPT versions or access dates, affecting reproducibility

## Confidence

- **High confidence:** GPT-4.0 Mini generates hallucinations at significantly higher frequency than GPT-4.0 (2.14 vs 0.86 per 1,000 tokens)
- **Medium confidence:** Classification of six hallucination patterns and morphological adherence rates (71% for GPT-4.0 vs 40% for Mini) based on systematic analysis
- **Low confidence:** Speculation about LLM confabulations influencing language evolution without empirical evidence

## Next Checks

1. **Annotation consistency test:** Have two additional linguistic experts independently classify a subset of hallucinated words from the dataset and calculate inter-annotator agreement to assess the reliability of the classification system.

2. **Model version stability:** Repeat the translation task using GPT-4.0 and GPT-4.0 Mini at different time points (e.g., one month apart) to determine if hallucination patterns and rates are consistent across model updates.

3. **Domain generalization:** Test the same domain-specific texts with a morphologically rich but higher-resource language (e.g., Icelandic or Finnish) to determine whether the domain-specific hallucination trigger is specific to low-resource languages or reflects a broader pattern.