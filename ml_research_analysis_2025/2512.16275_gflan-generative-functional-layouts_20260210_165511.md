---
ver: rpa2
title: 'GFLAN: Generative Functional Layouts'
arxiv_id: '2512.16275'
source_url: https://arxiv.org/abs/2512.16275
tags:
- room
- gflan
- layout
- each
- floor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces GFLAN, a two-stage generative model for
  floor plan synthesis that explicitly separates topological planning (room centroid
  allocation) from geometric realization (room boundary regression on a hybrid room-boundary
  graph). The method operates from minimal inputs: an exterior envelope, a front-door
  location, and a functional program (room counts).'
---

# GFLAN: Generative Functional Layouts

## Quick Facts
- arXiv ID: 2512.16275
- Source URL: https://arxiv.org/abs/2512.16275
- Reference count: 36
- Primary result: Two-stage generative model for floor plan synthesis with 95% connectivity, 4 adjacency violations, and 1.03 shortest-path sanity ratio on RPLAN dataset

## Executive Summary
GFLAN introduces a two-stage generative model that separates topological planning (room centroid allocation) from geometric realization (axis-aligned room boundary regression) for floor plan synthesis. The method takes minimal inputs—an exterior envelope, front-door location, and functional program—and produces connected, constraint-compliant residential layouts. Evaluated on the RPLAN dataset, GFLAN achieves superior connectivity (95% vs 79-93% for baselines), fewer adjacency violations (4 vs 53-65), and improved circulation efficiency (shortest-path sanity ratio of 1.03 vs 1.15-1.18), with 1.71x faster inference than WallPlan and 10.2% less memory usage.

## Method Summary
GFLAN operates in two stages: Stage A uses a dual-encoder CNN architecture to sequentially place room centroids within the envelope, while Stage B employs a graph neural network to predict axis-aligned room rectangles conditioned on these centroids. The dual-encoder design separates invariant spatial context (envelope, entrance, program) from evolving layout state, improving sequential conditioning stability. Stage B constructs a heterogeneous k-NN graph connecting each room to nearby rooms and boundary vertices, then uses TransformerConv layers to jointly regress room boundaries while enforcing connectivity and adjacency constraints. This factorization prevents irrecoverable errors by committing to connectivity intent before geometric realization.

## Key Results
- Connectivity ratio: 95% (vs 79-93% for baselines)
- Adjacency violations: 4 (vs 53-65 for baselines)
- Shortest-path sanity ratio: 1.03 (vs 1.15-1.18 for baselines)
- Inference speed: 1.71x faster than WallPlan with 10.2% less memory usage

## Why This Works (Mechanism)

### Mechanism 1: Topology-First Factorization Reduces Irrecoverable Errors
Separating room-centroid placement from boundary regression prevents connectivity errors that are costly or impossible to fix later. By committing to a discrete connectivity scaffold before any geometry is drawn, Stage A ensures that Stage B's rectangle instantiation has a valid topological foundation. This explicit centroid-to-rectangle pipeline yields higher connectivity (95% vs. 79–93%) compared to monolithic pixel-to-pixel generation.

### Mechanism 2: Dual-Encoder Separation Stabilizes Sequential Conditioning
The dual-encoder architecture prevents the network from "forgetting" program constraints during sequential room placement. The global encoder processes invariant inputs once, while the step encoder handles evolving context, with fused features decoded into per-type heatmaps. This separation produces more coherent layouts with better circulation and room-size balance compared to single-encoder alternatives.

### Mechanism 3: k-NN Hybrid Graph Propagates Adjacency Constraints
The sparse heterogeneous graph connecting each room to nearby rooms and boundary nodes enables effective GNN-based regression that respects containment and adjacency. Each room node links to its 5 nearest boundary vertices and 2 nearest other room nodes, allowing TransformerConv layers to propagate positional and type information across edges. This structure captures the essential adjacency relationships for residential layouts while maintaining computational efficiency.

## Foundational Learning

- **Graph Neural Networks (TransformerConv variant)**: Essential for understanding how attention-based message passing jointly regresses room boundaries in Stage B. Quick check: Given a room node with 7 neighbors (5 boundary + 2 room), how do attention weights determine which neighbor's features most influence its predicted rectangle?

- **Heatmap Regression with Blob Detection**: Critical for Stage A's per-type probability maps and inference via Laplacian-of-Gaussian peak extraction. Quick check: What happens to output diversity if temperature τ is decreased from 0.7 toward 0 during sampling from the suppressed heatmap?

- **Sequential Autoregressive Conditioning**: Fundamental to understanding the room placement dependency chain and debugging mode collapse or missing rooms. Quick check: Why does the suppression mask subtract filled discs at already-placed centroids before extracting the next peak?

## Architecture Onboarding

- **Component map:**
  - Input → Global encoder (DeepLabV3-ResNet101) → Frozen after Phase 1
  - Loop: step encoder (DeepLabV3-ResNet101) + type-specific decoder → LoG peak extraction → centroid added
  - Graph construction: centroids + envelope vertices → heterogeneous graph
  - Stage B GNN (7-layer TransformerConv) → 4D rectangle corners per room
  - Post-processing: boundary clipping, overlap resolution, output

- **Critical path:**
  Input → Global encoder → Sequential: step encoder + decoder → peak extraction → centroid addition → End loop → Graph construction → GNN regression → Clip to envelope → Output

- **Design tradeoffs:**
  - Rectangular-only rooms limit expressiveness for curved or non-orthogonal boundaries
  - Frozen encoders in Phase 2 improve stability but reduce adaptability to out-of-distribution programs
  - Stochastic sampling enables diverse outputs but requires post-hoc filtering for architectural validity

- **Failure signatures:**
  - Trapped room: Connectivity ratio <1.0; centroid isolated from entrance path
  - Sliver geometry: Aspect ratio >3:1; insufficient boundary edges in graph
  - Floating balcony: Not snapped to envelope edge; boundary-attachment check fails

- **First 3 experiments:**
  1. Reproduce Stage A centroid prediction on ResPlan subset, validate heatmap MSE and peak-extraction accuracy within 5px of ground-truth centroids
  2. Ablate dual-encoder vs. single-encoder, compare connectivity ratio and bedroom-size balance metrics (expect degradation per Figure 8)
  3. Stress-test graph robustness with uniform noise U(−ε, ε) for ε∈{0,3,5} pixels into centroids before Stage B, measure stability of final rectangle areas and connectivity

## Open Questions the Paper Calls Out

- **Multi-story extension**: How to extend the two-stage decomposition to multi-story buildings with vertical circulation constraints and inter-floor alignment requirements? The current 2D planar assumption doesn't model 3D constraints and floor-to-floor dependencies.

- **Non-orthogonal geometry**: Can the axis-aligned rectangle assumption be relaxed to support non-orthogonal or curved room boundaries while preserving factorization benefits? Stage B's direct corner regression cannot express arbitrary polygonal rooms.

- **Regulatory constraints**: How to integrate explicit structural, HVAC, and building-code requirements into the generative process? Current constraints are limited to connectivity, adjacency, and envelope containment.

- **Dataset bias**: How robust is GFLAN to architectural styles, building typologies, or geographic regions underrepresented in training data? The model's priors may yield suboptimal layouts for unseen spatial patterns.

## Limitations
- Rectangular-only rooms cannot represent curved or non-orthogonal boundaries
- Single-story, single-envelope setting limits applicability to multi-story buildings
- No explicit structural/HVAC constraints in current formulation

## Confidence
- **High confidence**: Connectivity improvements (95% vs 79-93%), adjacency violations (4 vs 53-65), and inference speed (1.71× faster than WallPlan) are directly measurable from ablation studies
- **Medium confidence**: Dual-encoder impact on circulation quality (shortest-path sanity ratio 1.03 vs 1.15-1.18) supported by internal ablation but lacks external validation
- **Low confidence**: Architectural usability claims (bedroom size balance, circulation efficiency) depend on subjective metrics difficult to quantify without full dataset access

## Next Checks
1. Replicate Stage A connectivity gains: Train dual-encoder centroid predictor on RPLAN, measure connectivity ratio and adjacency violations against baselines
2. Ablate k-NN graph parameters: Systematically vary k_room and k_boundary to determine sensitivity of rectangle quality and overlap frequency
3. Test out-of-distribution generalization: Generate layouts for programs with 6+ bedrooms or irregular envelopes, measure connectivity, overlap, and circulation sanity ratios