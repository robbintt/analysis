---
ver: rpa2
title: Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and
  Meta-Features
arxiv_id: '2511.00126'
source_url: https://arxiv.org/abs/2511.00126
tags:
- expert
- gate
- gating
- oracle
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the unreliability of deep trajectory predictors\
  \ in complex, long-tail driving scenarios by proposing a dynamic multi-expert gating\
  \ framework. The core method involves adaptively selecting the most reliable trajectory\
  \ predictor\u2014among a physics-informed LSTM, a Transformer, and a fine-tuned\
  \ GameFormer\u2014on a per-sample basis."
---

# Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features

## Quick Facts
- arXiv ID: 2511.00126
- Source URL: https://arxiv.org/abs/2511.00126
- Reference count: 22
- Primary result: LLM-enhanced tri-expert gate achieves 2.567 m FDE on nuPlan-mini, 9.5% reduction over GameFormer baseline

## Executive Summary
This paper addresses the unreliability of deep trajectory predictors in complex, long-tail driving scenarios by proposing a dynamic multi-expert gating framework. The core method involves adaptively selecting the most reliable trajectory predictor—among a physics-informed LSTM, a Transformer, and a fine-tuned GameFormer—on a per-sample basis. This is achieved through a pairwise ranking formulation over internal model signals (meta-features) such as stability and uncertainty, directly optimizing decision quality without requiring post-hoc calibration. An LLM supervisor provides semantic overrides for low-confidence cases. Evaluated on the nuPlan-mini dataset (1,287 samples), the LLM-enhanced tri-expert gate achieves a Final Displacement Error (FDE) of 2.567 m, representing a 9.5% reduction over GameFormer (2.835 m), and realizes 57.8% of the oracle performance bound. In open-loop simulations, after trajectory horizon alignment, the same configuration reduces FDE on left-turn scenarios by approximately 10%, demonstrating consistent improvements across both offline validation and open-loop evaluation.

## Method Summary
The method dynamically selects among three trajectory prediction experts—LSTM-KF (physics), Transformer (long-tail), and GameFormer (interaction)—using a pairwise ranking gate trained on 36-dimensional meta-features. These features capture uncertainty (MC-dropout variance), stability (input perturbation sensitivity), and physics violations for each expert. The gate is a 3-layer MLP optimized with RankNet loss to order experts by predicted FDE. When the gate's confidence falls below 0.4, a lightweight LLM (Qwen3-4B) analyzes scene semantics to recommend the expert. The system is trained on nuPlan-mini with a 60/20/20 split, using Adam optimizer (lr=5×10⁻⁴, batch=128, 30 epochs with early stopping).

## Key Results
- LLM-enhanced tri-expert gate achieves 2.567 m FDE on nuPlan-mini (9.5% reduction over GameFormer baseline of 2.835 m)
- Oracle Realization Rate reaches 57.8%, demonstrating 57.8% of theoretical oracle performance
- Meta-feature-based gate outperforms geometric-only features (49.6% vs 2.1% ORR)
- LLM semantic overrides trigger on 34% of scenes and improve left-turn scenario FDE by ~10%

## Why This Works (Mechanism)

### Mechanism 1: Meta-Feature Informed Competence Assessment
- Claim: Internal model diagnostics (uncertainty, stability) are stronger predictors of per-sample reliability than external scene geometry alone.
- Mechanism: The gate computes a 36-dimensional vector of "meta-features"—including MC-dropout variance, input stability under perturbation, and physics violation rates—for every expert. These signals serve as proxies for model competence, allowing the gate to select the expert that "knows what it doesn't know."
- Core assumption: A model's internal variance or physics compliance correlates inversely with its prediction error on a specific sample.
- Evidence anchors: Ablation studies (Table 2) show geometric-only features achieve 2.1% ORR versus 49.6% with meta-features.

### Mechanism 2: Pairwise Ranking Objective
- Claim: Optimizing for relative ordering of experts is more robust than regressing absolute errors or classifying discrete winners.
- Mechanism: The gate uses a pairwise ranking loss (RankNet) to learn a scoring function where the argmax identifies the best expert. This bypasses the heavy-tailed distribution of regression targets and calibration brittleness of classification.
- Core assumption: Determining "Expert A is better than Expert B" is learnable from input meta-features, even if the magnitude of improvement is noisy.
- Evidence anchors: "Hybrid Gating Mechanism" section notes regression failed with negative R²; Ranking improved ORR over Classification (49.6% vs 41.8%).

### Mechanism 3: Hybrid Neuro-Symbolic Fallback
- Claim: LLM supervisor can recover performance in cases where numerical confidence is low by applying semantic reasoning to high-risk scenarios.
- Mechanism: If the ranking gate's softmax score falls below 0.4, a lightweight LLM (Qwen3-4B) analyzes a scene synopsis to recommend an expert based on high-level intent (e.g., identifying a "cut-in").
- Core assumption: High-risk scenarios possess semantic cues (like "starting left turn") that are legible in text but lost in numerical meta-features.
- Evidence anchors: "LLM Supervisor for Semantic Overrides" states it triggers on 34% of scenes and lifts ORR from 49.6% to 57.8%.

## Foundational Learning

- **Concept: Uncertainty Quantification (MC Dropout)**
  - Why needed here: The "Model Uncertainty" meta-feature relies on calculating variance across stochastic forward passes with dropout enabled.
  - Quick check question: How do you enforce dropout during inference in your framework (e.g., `model.train()` mode or custom forward pass)?

- **Concept: Learning to Rank (Pairwise Loss)**
  - Why needed here: The core loss function minimizes ranking errors between pairs of experts rather than predicting error magnitude directly.
  - Quick check question: How does the pairwise ranking loss handle cases where two experts have very similar FDEs (a tie)?

- **Concept: Physics-based Kinematics**
  - Why needed here: The "Physics Violation Rate" meta-feature requires checking trajectories against dynamic constraints (max acceleration/curvature); the LSTM-KF expert enforces these.
  - Quick check question: How do you penalize a predicted trajectory that exceeds a maximum lateral acceleration of 8 m/s²?

## Architecture Onboarding

- **Component map**: Experts (LSTM-KF, Transformer, GameFormer) -> Meta-feature Extractor (36-dim vector) -> Ranking Gate (3-layer MLP) -> LLM Supervisor (Qwen3-4B)
- **Critical path**: Extracting stable meta-features. The paper notes the LSTM expert produced near-zero variance, creating blind spots. Ensuring non-zero variance for all experts is critical for the gate to function.
- **Design tradeoffs**: 
  - Latency vs. Safety: LLM adds latency but covers long-tail scenarios (improving left-turn scenarios by ~10%)
  - Compute vs. Performance: MC-Dropout requires 8 passes per expert (expensive) to get uncertainty
- **Failure signatures**:
  - "Stuck on SOTA": Gate defaults to GameFormer 100% of the time if meta-features are uninformative or poorly normalized
  - "Late LLM": Supervisor triggers too late due to prompt processing delay, missing safety-critical window
- **First 3 experiments**:
  1. **Expert Baseline**: Evaluate LSTM, Transformer, and GameFormer individually on nuPlan-mini to establish "Oracle Gap"
  2. **Feature Ablation**: Train gate using only geometric features to confirm failure (ORR < 5%), validating need for meta-features
  3. **Mechanism Validation**: Train Ranking-Gate with meta-features on 60/20/20 split and verify ORR exceeds 40% before adding LLM

## Open Questions the Paper Calls Out

- **Question**: Do meta-feature correlations and LLM triggers generalize to full nuPlan benchmark and external datasets like Waymo?
  - Basis in paper: [explicit] "Validating the meta-feature correlations and LLM triggers on the full nuPlan benchmark... and across other datasets such as Waymo... remains future work."
  - Why unresolved: Study restricted to 1,287-sample nuPlan-mini subset
  - What evidence would resolve it: Consistent ORR and FDE improvements on complete nuPlan and Waymo Open Motion datasets

- **Question**: Can LLM supervisor be distilled into lightweight surrogate to maintain semantic reasoning while meeting real-time latency constraints?
  - Basis in paper: [explicit] Authors state "real-time deployment is challenging" and "A deployable system will need to distil the LLM's reasoning into a lightweight surrogate"
  - Why unresolved: Current LLM supervisor incurs high latency (second-scale), impractical for online autonomous driving cycles
  - What evidence would resolve it: Distilled model replicating LLM's override decisions with sub-100ms inference latency and comparable accuracy

- **Question**: Does expanding expert pool to include diffusion-based or raster-based predictors significantly raise theoretical oracle ceiling?
  - Basis in paper: [explicit] "Broader expert diversity—including diffusion-based (Jiang et al. 2023) or raster-based predictors—is the most direct lever for raising the theoretical ceiling"
  - Why unresolved: Current oracle bounded by specific three experts used, where non-SOTA experts are significantly weaker
  - What evidence would resolve it: Higher theoretical Oracle FDE bound and increased gate performance (ORR) when heterogeneous architectures are added

## Limitations

- Critical architectural parameters for LSTM-KF and Scene-conditioned Transformer experts are omitted, making faithful reproduction challenging
- LLM supervisor's semantic triggers rely on qualitative descriptions rather than concrete implementation details
- Limited contextual support in corpus for core innovation of pairwise ranking for expert selection

## Confidence

- **High Confidence**: Empirical results on nuPlan-mini (2.567 m FDE, 57.8% ORR) are well-supported by described methodology and represent clear improvement over baselines
- **Medium Confidence**: Ranking objective's superiority over regression and classification is demonstrated through ablation, but negative R² failure mode suggests sensitivity to data distribution
- **Low Confidence**: Generalization of results to other datasets or driving contexts is unknown; performance on highly dynamic scenarios beyond nuPlan-mini's scope is speculative

## Next Checks

1. **Expert Architecture Completion**: Implement missing LSTM-KF and Scene-conditioned Transformer baselines with specified parameters to verify reported oracle gap and validate selection problem's magnitude

2. **Meta-Feature Distribution Analysis**: Measure variance and correlation structure of 36 meta-features across all experts to confirm discriminative signal (checking for near-zero variance cases like noted LSTM expert)

3. **Cross-Dataset Generalization**: Evaluate trained gate on independent trajectory prediction dataset (e.g., Argoverse) to assess whether meta-feature ranking generalizes beyond nuPlan-mini's distribution