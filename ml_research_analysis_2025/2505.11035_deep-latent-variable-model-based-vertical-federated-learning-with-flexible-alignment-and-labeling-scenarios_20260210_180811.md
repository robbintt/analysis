---
ver: rpa2
title: Deep Latent Variable Model based Vertical Federated Learning with Flexible
  Alignment and Labeling Scenarios
arxiv_id: '2505.11035'
source_url: https://arxiv.org/abs/2505.11035
tags:
- data
- xobs
- learning
- mcar
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FALSE-VFL, a vertical federated learning
  framework designed to handle feature-partitioned data with arbitrary alignment and
  labeling scenarios. By reinterpreting alignment gaps as missing data problems, the
  authors develop a unified approach that supports both training and inference under
  MCAR, MAR, and MNAR mechanisms.
---

# Deep Latent Variable Model based Vertical Federated Learning with Flexible Alignment and Labeling Scenarios

## Quick Facts
- arXiv ID: 2505.11035
- Source URL: https://arxiv.org/abs/2505.11035
- Reference count: 40
- Primary result: Achieves 9.6 percentage points average accuracy improvement over baselines in 160 of 168 VFL configurations with arbitrary alignment and labeling.

## Executive Summary
This paper introduces FALSE-VFL, a vertical federated learning framework that addresses the challenge of training models on feature-partitioned data with arbitrary alignment and labeling scenarios. By reinterpreting alignment gaps as missing data problems, the authors develop a unified approach supporting Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR) mechanisms. The framework employs a deep latent variable model with a two-stage optimization strategy: pretraining via marginal likelihood maximization followed by conditional likelihood maximization. Experiments across 168 configurations on four datasets demonstrate that FALSE-VFL outperforms all baselines in 160 cases, achieving an average accuracy improvement of 9.6 percentage points.

## Method Summary
FALSE-VFL treats alignment gaps in vertical federated learning as missing data problems solvable via generative modeling. The framework uses a Deep Latent Variable Model (DLVM) where local parties encode their features into a shared latent space, and a global model performs prediction. The method employs a two-stage optimization: Stage 1 maximizes marginal likelihood on all data to learn robust feature representations, while Stage 2 maximizes conditional likelihood on labeled data by freezing the generative parameters. This approach leverages unlabeled and unaligned data while maintaining privacy through federated aggregation of local posterior parameters.

## Key Results
- FALSE-VFL outperforms all baselines in 160 out of 168 experimental configurations
- Achieves an average accuracy improvement of 9.6 percentage points
- Demonstrates robustness to higher missing rates, often improving accuracy when alignment gaps increase
- Shows consistent performance gains across MCAR, MAR, and MNAR scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Alignment gaps in feature-partitioned data can be treated as a missing data problem solvable via generative modeling.
- **Mechanism:** The framework models complete data distribution using a Deep Latent Variable Model, aggregating partial observations from different parties into a shared latent space. By maximizing marginal likelihood of observed features, the model learns to infer posterior distribution of latent variables even when specific party features are missing.
- **Core assumption:** Observed data from each party is generated from shared latent structure, and missingness mechanism allows for valid posterior inference.
- **Evidence anchors:** Abstract states "reinterprets alignment gaps... as missing data problems"; Section 3.1 provides unified framework for incomplete data.

### Mechanism 2
- **Claim:** Two-stage optimization prevents implicit modeling bias where generative model focuses solely on feature reconstruction at expense of label prediction.
- **Mechanism:** Stage 1 maximizes marginal likelihood to learn robust feature representations using all data. Stage 2 freezes generative parameters and optimizes only conditional likelihood, forcing model to use learned representation for prediction without being distracted by reconstruction error.
- **Core assumption:** Features learned during marginal likelihood maximization contain sufficient signal for downstream supervised task.
- **Evidence anchors:** Section 4.1 explains freezing parameters makes objective equivalent to maximizing conditional likelihood, avoiding implicit modeling bias.

### Mechanism 3
- **Claim:** Precision-based aggregation of local posteriors allows global model to dynamically adjust confidence based on number of participating parties.
- **Mechanism:** Each party outputs local Gaussian parameters. Global latent variable is approximated by aggregating these, with variance aggregated via precision. Missing parties contribute zero precision (infinite variance), effectively removing influence without breaking computation.
- **Core assumption:** Posterior approximation is well-represented by Gaussian, and local encoders produce meaningful uncertainty estimates.
- **Evidence anchors:** Section 3.3.1 shows aggregation of inverse covariance matrices; Appendix B.2 explains precision-based variance aggregation.

## Foundational Learning

- **Concept: Missing Data Mechanisms (MCAR, MAR, MNAR)**
  - **Why needed here:** Framework explicitly optimizes for scenarios where data is MCAR, MAR, or MNAR. Understanding these assumptions is required to select between FALSE-VFL-I and FALSE-VFL-II.
  - **Quick check question:** Does probability of party dropping out depend on data held by other parties? (If yes, approaches MNAR).

- **Concept: Variational Inference (VI) and ELBO**
  - **Why needed here:** Model relies on maximizing lower bound rather than exact likelihoods. Loss functions are derived from VI principles to approximate intractable posterior.
  - **Quick check question:** Why must we use lower bound (ELBO) instead of directly computing likelihood in Deep Latent Variable Model?

- **Concept: Importance Weighted Autoencoders (IWAE)**
  - **Why needed here:** Paper uses importance samples to estimate lower bound, which is core technique of IWAE. Explains why model draws samples and averages them.
  - **Quick check question:** How does increasing number of importance samples affect tightness of bound?

## Architecture Onboarding

- **Component map:** Local Encoders ($\gamma^k_c$) -> Local Decoders ($\theta^k_c$) -> Precision Aggregation -> Global Encoder ($\gamma_s$) -> Global Decoder ($\theta_s$) -> Discriminator ($\phi$) -> Label Output
- **Critical path:**
  1. Data Ingest: Each party receives raw features $x_k$
  2. Local Encode: Compute local mean $\mu_k$ and precision $\Sigma_k^{-1}$
  3. Aggregate: Fuse into global $h$ using precision-based aggregation
  4. Hierarchical Sample: Draw $z$ from $q(z|h)$
  5. Likelihood Estimation: Pretraining computes reconstruction error; Training passes frozen $h$ to Discriminator for classification loss
- **Design tradeoffs:**
  - FALSE-VFL-I vs. II: VFL-I ignores mask distribution (simpler), VFL-II adds Missing Indicator network to model mask probabilities (more complex)
  - Generative Depth: $L=2$ layers used; deeper hierarchies might capture more complex data structures but increase training instability
- **Failure signatures:**
  - Posterior Collapse: Latent variable $z$ becomes uninformative if KL divergence collapses to zero
  - Alignment Brittleness: Stage 1 fails to converge on unaligned data, Stage 2 accuracy will be random
  - Communication Bottleneck: Transmitting $\mu$ and $\Sigma$ for every sample could clog bandwidth
- **First 3 experiments:**
  1. Sanity Check: Run Vanilla VFL vs. FALSE-VFL on MCAR 0 (fully aligned). Verify FALSE-VFL doesn't underperform significantly.
  2. Ablation on Missingness: Train on MCAR 2 vs. MCAR 5. Verify accuracy degrades gracefully or "robustness" holds as claimed.
  3. Stage Ablation: Train without pretraining (skip Stage 1). Compare accuracy to full two-stage pipeline to quantify value of marginal likelihood optimization.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can framework be extended to model inter-party dependencies in MNAR mechanisms without compromising privacy? Basis: Authors note current mask model assumes missingness depends only on own features, failing to capture dependencies across different parties.
- **Open Question 2:** Can FALSE-VFL be integrated with formal privacy guarantees like Differential Privacy without negating accuracy improvements? Basis: Broader Impact section acknowledges potential information leakage risks, yet proposed method lacks formal privacy mechanisms.
- **Open Question 3:** Can FALSE-VFL be effectively combined with privacy-preserving record linkage techniques to address "potentially alignable" data alongside "inherently unalignable" data? Basis: Introduction distinguishes between these record types, stating method focuses solely on latter.

## Limitations
- Experiments rely on synthetic data partitions and missingness patterns rather than real-world feature-partitioned datasets
- Does not extensively explore alternative architectures or hyperparameter sensitivity
- Precision-based aggregation assumes local encoders produce meaningful uncertainty estimates, which may not hold in heterogeneous data

## Confidence
- **High:** Precision-based aggregation method is well-grounded in probabilistic modeling principles
- **Medium:** Two-stage optimization mechanism is theoretically justified but limited real-world validation
- **Low:** Robustness claims across missingness rates depend heavily on synthetic generation of alignment gaps

## Next Checks
1. **Real-world Dataset Validation:** Apply FALSE-VFL to publicly available feature-partitioned dataset (e.g., healthcare or finance) to assess performance outside synthetic scenarios
2. **Ablation on Missingness Mechanisms:** Systematically vary degree of MAR vs. MNAR to quantify necessity and impact of Missing Indicator network in FALSE-VFL-II
3. **Communication Overhead Analysis:** Measure bandwidth and latency impact of transmitting precision-weighted statistics during aggregation, especially for high-dimensional features