---
ver: rpa2
title: 'MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems'
arxiv_id: '2503.03686'
source_url: https://arxiv.org/abs/2503.03686
tags:
- mas-gpt
- multi-agent
- code
- answer
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MAS-GPT is a large language model designed to generate executable
  multi-agent systems (MAS) for user queries within a single inference. The approach
  reframes MAS construction as a generative language task, representing MAS as executable
  Python code and training on a consistency-oriented dataset of query-MAS pairs.
---

# MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems

## Quick Facts
- arXiv ID: 2503.03686
- Source URL: https://arxiv.org/abs/2503.03686
- Authors: Rui Ye; Shuo Tang; Rui Ge; Yaxin Du; Zhenfei Yin; Siheng Chen; Jing Shao
- Reference count: 40
- Primary result: MAS-GPT generates executable multi-agent systems in a single inference, achieving up to 3.89% improvement over strong baselines across 9 benchmarks.

## Executive Summary
MAS-GPT reframes the construction of multi-agent systems (MAS) as a generative language task, representing MAS as executable Python code and training on a consistency-oriented dataset of query-MAS pairs. This approach significantly simplifies building MAS, reduces inference costs, and enhances adaptability compared to manually crafted or multi-inference baselines. Extensive experiments on 9 benchmarks and 5 LLMs demonstrate MAS-GPT's consistent superiority, with average improvements of up to 3.89% over strong baselines. It also generalizes to unseen queries and can augment reasoning capabilities of advanced LLMs like o1-preview.

## Method Summary
MAS-GPT is a large language model trained via supervised fine-tuning on synthetic data to generate executable Python code representing multi-agent systems. The method unifies MAS representation as code, uses a consistency-oriented data construction pipeline, and enables one-shot generation at inference time. The system takes user queries as input and outputs a `forward(query)` function containing agent definitions, function calls for LLM invocations, and string concatenations for interactions. Training uses Qwen2.5-Coder-32B-Instruct fine-tuned on ~11k samples derived from various benchmarks, with hardware requirements of 16 A100s and hyperparameters including batch size 32, 3 epochs, and learning rate 1e-5.

## Key Results
- MAS-GPT achieves average improvements of up to 3.89% over strong baselines across 9 benchmarks
- The approach reduces inference costs by eliminating iterative search methods
- The system generalizes to unseen queries and augments reasoning capabilities of advanced LLMs like o1-preview

## Why This Works (Mechanism)

### Mechanism 1: Executable Code as a Unified Representation
Representing the multi-agent system topology and logic as an executable Python function constrains the output space to valid, runnable structures. The model generates a `forward(query)` function where variables define agents, function calls define LLM invocations, and string concatenations define interactions. This reduces the ambiguity inherent in natural language descriptions of agent relationships. The base LLM (e.g., Qwen2.5-Coder) must possess sufficient code-generation capabilities to maintain syntax and logical validity in this specific format.

### Mechanism 2: Consistency-Oriented Data Construction
Performance improves when training data enforces structural consistency for similar queries (Inter-consistency) and semantic alignment between the query and agent definitions (Intra-consistency). The pipeline clusters similar queries and assigns them the same high-performing base MAS architecture (Inter-consistency), then uses an LLM to refine agent prompts to match the specific query context (Intra-consistency), adding a reasoning trace to bridge the query and the code.

### Mechanism 3: Inference-Time Efficiency via One-Shot Generation
Offloading the architecture search to a training phase allows for a single forward pass at inference time, replacing iterative search methods. By training MAS-GPT on a dataset of (Query, Ideal MAS Code) pairs, the model learns to approximate the result of an expensive search process (like evolutionary algorithms) instantly. The system essentially "memorizes" design patterns for specific query types.

## Foundational Learning

- **Concept: Supervised Fine-Tuning (SFT) on Synthetic Data**
  - Why needed here: MAS-GPT is not a pre-trained reasoning engine; it is a specialized model trained via SFT on synthetic (LLM-generated) query-MAS pairs. Understanding how synthetic data quality affects overfitting is crucial.
  - Quick check question: How does the "Inter-consistency" step prevent the model from learning contradictory mappings for similar queries?

- **Concept: Code Generation & Execution**
  - Why needed here: The output of the system is not text, but Python code that must be executed. One must understand the risks of running LLM-generated code (sandboxing, syntax errors).
  - Quick check question: In the MAS representation, how are inter-agent interactions encoded within the `forward` function?

- **Concept: Multi-Agent Topologies (e.g., Chain, Debate, Tree)**
  - Why needed here: The model selects from topologies like "Debate" or "Self-Refine." You need to recognize these structures to debug why MAS-GPT chose a specific one for a given query.
  - Quick check question: If a query requires divergent thinking, which topology (e.g., Debate vs. Linear Refine) would likely be selected by the consistency-oriented pipeline?

## Architecture Onboarding

- **Component map:**
  1. Data Pipeline (Offline): Query/MAS Pools -> Evaluation (Ground Truth) -> Inter-consistency Clustering -> Intra-consistency Refinement -> SFT Dataset
  2. Model (MAS-GPT): Qwen2.5-Coder-32B-Instruct (fine-tuned)
  3. Runtime: Input Query -> MAS-GPT -> Generated Python Code -> Executor -> Final Answer

- **Critical path:** The Intra-consistency-oriented pair refinement step links the abstract query to concrete code. If the reasoning trace generated here is flawed, the model learns spurious correlations.

- **Design tradeoffs:**
  - Fixed vs. Dynamic MAS: The model generates a fixed MAS code snippet per query. It does not dynamically adjust the topology during the execution of that snippet.
  - Data Scale vs. Quality: The paper notes ~11k samples. The tradeoff is strict quality filtering (consistency) vs. raw data volume.

- **Failure signatures:**
  - Non-executable Output: Generated code has syntax errors
  - Structural Hallucination: The model generates a generic "chain" structure for a complex problem requiring parallel debate

- **First 3 experiments:**
  1. Zero-Shot Baseline: Run the base Qwen-Coder model on a query to generate MAS code without fine-tuning to verify the necessity of the training pipeline
  2. Ablation on Consistency: Remove the Inter-consistency clustering (random selection) and verify the drop in accuracy on the MATH benchmark
  3. Cross-Model Generalization: Use MAS-GPT to generate code, but execute the code using a smaller/cheaper LLM to test if the architecture is robust to the underlying agent intelligence

## Open Questions the Paper Calls Out

### Open Question 1
Does the performance of MAS-GPT continue to scale effectively with orders of magnitude more training data, or is it constrained by the limited diversity of the 40 base MAS designs used to initialize the dataset? While more data improves the model, it is unclear if the finite variety of the foundational MAS templates caps the architectural novelty the model can learn, potentially leading to plateauing performance on novel tasks.

### Open Question 2
Is the "optimal" MAS generated by MAS-GPT biased toward the specific reasoning patterns and failure modes of the Llama-3-70B model used for evaluation during data construction? The training dataset encodes the logic of what makes a "correct" answer based on a specific 70B model; architectures that fix errors for Llama-3 might be redundant or suboptimal for more robust models like GPT-4o or reasoning models like o1.

### Open Question 3
Does the "forward function" code representation limit the ability to express dynamic or recursive agent interactions compared to graph-based approaches? While executable code is flexible, the implied linear or nested structure of a `forward` function may struggle to represent the dynamic topologies available in graph-based systems like GPTSwarm.

## Limitations
- The reported improvements are based on 9 specific benchmarks, which may not represent real-world complexity or out-of-distribution queries
- The approach relies heavily on synthetic data construction, raising questions about whether the consistency-oriented pipeline captures the true diversity of MAS design requirements
- The base MAS pool of 40+ templates, while extensive, may still constrain the system's ability to generate truly novel architectures for unprecedented query types

## Confidence

- **High Confidence:** The mechanism of representing MAS as executable Python code is well-supported by the code-generation capabilities of modern LLMs like Qwen2.5-Coder. The empirical results showing improved inference efficiency are directly measurable.
- **Medium Confidence:** The consistency-oriented data construction pipeline shows promise through ablation studies, but the clustering methodology and its impact on generalization remain somewhat opaque.
- **Low Confidence:** The claim of significant generalization to unseen queries is the weakest. While the paper shows improvements on held-out test sets, the fundamental question of whether the model can truly generate effective MAS architectures for queries requiring completely novel topologies remains unanswered.

## Next Checks

1. **Out-of-Distribution Topology Generation:** Test MAS-GPT on queries requiring topologies not present in the base pool (e.g., hierarchical debate structures or cyclic feedback loops) to assess hallucination rates and structural validity.

2. **Cross-Domain Robustness:** Evaluate performance on real-world MAS benchmarks from robotics, logistics, or scientific discovery domains where the query semantics and required agent interactions differ substantially from academic test sets.

3. **Dynamic Adaptation Assessment:** Modify the evaluation to allow the generated MAS code to dynamically adjust its topology during execution (not just at generation time), comparing performance against the fixed architecture approach to quantify the tradeoff.