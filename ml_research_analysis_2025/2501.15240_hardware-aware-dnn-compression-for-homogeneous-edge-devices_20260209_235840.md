---
ver: rpa2
title: Hardware-Aware DNN Compression for Homogeneous Edge Devices
arxiv_id: '2501.15240'
source_url: https://arxiv.org/abs/2501.15240
tags:
- devices
- hdap
- evaluation
- edge
- homogeneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HDAP addresses the challenge of hardware-aware DNN compression
  across homogeneous edge device clusters, where prior methods assume identical performance
  that does not hold in practice due to manufacturing variances and environmental
  factors. The method clusters devices by performance similarity using DBSCAN and
  employs surrogate models for latency prediction, reducing evaluation overhead from
  thousands of devices to a few representative clusters.
---

# Hardware-Aware DNN Compression for Homogeneous Edge Devices

## Quick Facts
- **arXiv ID:** 2501.15240
- **Source URL:** https://arxiv.org/abs/2501.15240
- **Reference count:** 32
- **Primary result:** HDAP achieves 2.86× and 1.67× latency speedups on ResNet50 and MobileNetV1 while maintaining competitive accuracy across device clusters

## Executive Summary
HDAP addresses hardware-aware DNN compression for homogeneous edge device clusters, where prior methods incorrectly assume identical performance across devices. The method clusters devices by performance similarity using DBSCAN and employs surrogate models for latency prediction, reducing evaluation overhead from thousands of devices to a few representative clusters. HDAP uses a derivative-free evolutionary algorithm (NCS) to iteratively prune and fine-tune DNN models while maintaining accuracy constraints. Experiments on ImageNet demonstrate HDAP achieves significant latency speedups while maintaining competitive accuracy, with consistent performance across device clusters.

## Method Summary
HDAP first benchmarks a reference model on all devices to measure baseline latencies, then clusters devices using DBSCAN based on these latencies. For each cluster, it trains a surrogate model (GBRT) to predict latency from pruning vectors. An evolutionary algorithm (NCS) searches for optimal pruning configurations using surrogate evaluations, penalized by accuracy constraints. The best candidates are fine-tuned for 90 epochs. This approach enables efficient deployment across large homogeneous device populations while accounting for manufacturing variances and environmental factors.

## Key Results
- Achieves 2.86× latency speedup on ResNet50 and 1.67× on MobileNetV1 compared to unpruned models
- Maintains competitive accuracy (within 1-2% of baseline) while meeting strict latency constraints
- Surrogate evaluation provides up to 2.65×10^7 speedup over hardware evaluation
- Consistent performance improvements across all device clusters

## Why This Works (Mechanism)

### Mechanism 1
Partitioning homogeneous devices into performance clusters using benchmark latencies likely preserves performance variance information while reducing evaluation scope, assuming variance stems from stable factors (manufacturing, thermal throttling) rather than random noise. HDAP uses DBSCAN on benchmark inference latencies, grouping devices that behave similarly to allow evaluation on one representative device per cluster rather than every device. Core assumption: Device performance variance is consistent and clusterable. Break condition: If device performance varies unpredictably per inference rather than per device characteristic.

### Mechanism 2
Surrogate models (Gradient Boosted Regression Trees) trained on pruning ratios can approximate hardware latency, enabling gradient-free optimization loops that would otherwise be intractable due to hardware measurement overhead. Instead of deploying a model to measure latency, HDAP trains a regression model mapping pruning vectors to latency, decoupling the optimization loop from physical hardware constraints. Core assumption: Latency is a smooth, learnable function of the pruning vector for a specific device cluster. Break condition: If hardware exhibits highly non-linear latency jumps not captured in training samples.

### Mechanism 3
A derivative-free evolutionary algorithm (NCS) can navigate the constrained optimization space (latency vs. accuracy) effectively without relying on differentiable hardware metrics. The algorithm generates pruning vectors, evaluates them via the surrogate, and penalizes vectors that violate the accuracy constraint, iteratively refining the model. Core assumption: The search space contains discoverable structures yielding latency reductions without catastrophic accuracy loss. Break condition: If the accuracy constraint is too high or target latency is physically impossible.

## Foundational Learning

**Concept: Structured Pruning (Filter/Channel Pruning)**
Why needed: HDAP optimizes the "pruning vector" (ratios per layer). You must understand that removing entire filters (structured) differs from removing individual weights (unstructured) because it directly impacts hardware latency (dense computation vs. sparse).
Quick check: Does removing 50% of weights via unstructured pruning guarantee a 2x speedup on a standard GPU? (Answer: No, unless hardware supports sparse acceleration).

**Concept: Density-Based Clustering (DBSCAN)**
Why needed: The paper assumes devices form natural groups. Unlike K-Means, DBSCAN doesn't require specifying the number of clusters beforehand, crucial since you don't know how many "slow" or "fast" device groups exist.
Quick check: How does DBSCAN handle a device with completely erratic performance compared to the fleet? (Answer: It typically labels it as noise/an outlier).

**Concept: Surrogate Modeling / Proxy Metrics**
Why needed: Measuring latency on real hardware is slow. Understanding that FLOPs are a bad proxy for real latency (due to memory bandwidth, caching, etc.) explains why HDAP builds a data-driven surrogate instead of just minimizing FLOPs.
Quick check: Why is FLOPs often a misleading metric for edge devices? (Answer: It ignores memory access costs and parallelism limits).

## Architecture Onboarding

**Component map:** Benchmark Runner -> Cluster Engine -> Data Generator -> Surrogate Trainer -> Search Controller (NCS) -> Fine-tuner

**Critical path:** The interaction between the Data Generator and Search Controller. If the surrogate is not trained on a representative distribution of pruning ratios, the Search Controller will exploit errors in the surrogate model leading to models that are slow in reality.

**Design tradeoffs:**
- Surrogate Accuracy vs. Overhead: Collecting more data samples improves the surrogate but increases initialization time
- Cluster Granularity: Too few clusters mask device variance; too many clusters increase the number of surrogates to train and maintain

**Failure signatures:**
- Sim-to-Real Gap: Optimizer selects a model predicted to be fast, but it runs slowly on target hardware
- Accuracy Collapse: Penalty weight in fitness function is too low, resulting in an aggressively pruned, useless model
- Cluster Instability: DBSCAN classifies most devices as noise, preventing surrogate training

**First 3 experiments:**
1. **Variance Validation:** Run the same model 100 times on 10 "identical" devices. Plot the distribution. If standard deviation is < 5%, HDAP is likely overkill (use standard compression). If variance is high, proceed.
2. **Surrogate Sanity Check:** Train the surrogate on 80% of collected latency data, test on 20%. If Mean Absolute Percentage Error (MAPE) > 10%, the surrogate features are insufficient; consider adding architectural features.
3. **Ablation on Cluster Count:** Compare HDAP performance using K=1 (Unified), K=4 (Clustered), and K=N (Per-device). Verify that K=4 captures the majority of the latency reduction benefit without N-times overhead.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions. However, the following limitations and uncertainties exist:

## Limitations

**Dataset generalization:** HDAP is validated primarily on ImageNet classification with limited testing on CIFAR-10 and Pascal VOC. Effectiveness for other DNN architectures (Transformers, recurrent networks) or different deployment scenarios remains untested.

**Hardware-specific behavior:** The method assumes latency-variance stems from stable factors, but thermal throttling patterns, concurrent workloads, or power delivery differences could create time-varying performance that clusters cannot capture.

**Surrogate model limitations:** While the GBRT surrogate achieves significant speedups, only aggregate metrics are reported. The variance in surrogate predictions across clusters and distribution of prediction errors are not provided.

## Confidence

**High confidence:** The core insight that homogeneous devices exhibit performance variance requiring per-device optimization is well-supported by device clustering literature and basic manufacturing principles.

**Medium confidence:** The DBSCAN clustering approach effectively groups devices by performance is supported by experimental results showing consistent latency improvements across clusters.

**Medium confidence:** The surrogate modeling approach significantly reduces evaluation overhead while maintaining reasonable prediction accuracy, though detailed error analysis is missing.

**Low confidence:** The evolutionary search consistently finds optimal pruning configurations across all tested scenarios without getting trapped in local optima or failing under strict constraints.

## Next Checks

1. **Cluster stability validation:** Run the benchmark latency measurement 5 times on the same device fleet over different days. Calculate cluster membership stability using Adjusted Rand Index. If cluster assignments change frequently, HDAP's core assumption of stable device performance clusters is violated.

2. **Surrogate error distribution analysis:** Generate 1000 pruning vectors, measure actual latency on representative devices per cluster, and compare with surrogate predictions. Plot prediction error histograms and calculate MAPE per cluster. If any cluster shows MAPE > 15% or has systematic bias, the surrogate is unreliable for that device population.

3. **Cross-architecture generalization test:** Apply HDAP to a non-classification task (e.g., object detection with YOLOv5 or a Transformer-based model). Measure whether the same clustering and surrogate approach maintains effectiveness. If performance degrades significantly, the method's applicability is more limited than claimed.