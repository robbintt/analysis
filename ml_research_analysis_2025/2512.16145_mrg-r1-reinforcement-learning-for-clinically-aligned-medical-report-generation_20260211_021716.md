---
ver: rpa2
title: 'MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation'
arxiv_id: '2512.16145'
source_url: https://arxiv.org/abs/2512.16145
tags:
- report
- reward
- clinical
- medical
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating clinically accurate
  radiology reports from medical images. Existing methods rely on token-level training
  objectives that focus on fluency and linguistic style but fail to ensure clinical
  correctness, often resulting in reports that look plausible but contain factual
  errors or missing key findings.
---

# MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation

## Quick Facts
- arXiv ID: 2512.16145
- Source URL: https://arxiv.org/abs/2512.16145
- Reference count: 40
- Primary result: Achieves state-of-the-art clinical efficacy (CE-F1: 51.88 IU X-Ray, 40.39 MIMIC-CXR) using reinforcement learning with clinically aligned rewards

## Executive Summary
This paper addresses the challenge of generating clinically accurate radiology reports from medical images. Existing methods rely on token-level training objectives that focus on fluency and linguistic style but fail to ensure clinical correctness, often resulting in reports that look plausible but contain factual errors or missing key findings. To address this, the authors propose a semantic-driven reinforcement learning (SRL) method for medical report generation (MRG-R1) that optimizes a clinically grounded, report-level reward instead of token-level likelihood. The approach uses a large vision-language model (Med-LVLM) fine-tuned with Group Relative Policy Optimization (GRPO) to maximize a margin-based CheXbert cosine similarity (MCCS) reward, which measures the clinical alignment between generated and reference reports. Additionally, a lightweight format reward encourages structured "reasoning → report" outputs for improved interpretability. The method is evaluated on IU X-Ray and MIMIC-CXR datasets using clinical efficacy (CE) metrics. MRG-R1 achieves state-of-the-art performance with CE-F1 scores of 51.88 on IU X-Ray and 40.39 on MIMIC-CXR, significantly outperforming conventional MLE baselines and other semantic supervision methods. Ablation studies confirm that the clinical reward (MCCS) and format constraint are key to these improvements. These results demonstrate that optimizing report-level clinical rewards meaningfully improves factual accuracy and clinical correctness in medical report generation.

## Method Summary
The proposed method uses reinforcement learning to optimize clinically aligned medical report generation. The approach employs a vision-language model (VLM) as the base generator, which is fine-tuned using Group Relative Policy Optimization (GRPO) to maximize a margin-based CheXbert cosine similarity (MCCS) reward. This reward measures the clinical alignment between generated and reference reports using a large vision-language model (Med-LVLM) fine-tuned with CheXbert embeddings. The training objective combines the MCCS reward with a lightweight format reward that encourages structured "reasoning → report" outputs. The method is evaluated on two chest X-ray datasets (IU X-Ray and MIMIC-CXR) using clinical efficacy metrics that assess the model's ability to correctly identify clinical findings in generated reports.

## Key Results
- Achieves state-of-the-art clinical efficacy with CE-F1 scores of 51.88 on IU X-Ray and 40.39 on MIMIC-CXR
- Significantly outperforms conventional maximum likelihood estimation (MLE) baselines and other semantic supervision methods
- Ablation studies confirm that both the clinical reward (MCCS) and format constraint are critical for performance improvements

## Why This Works (Mechanism)
The paper demonstrates that optimizing token-level likelihood in medical report generation leads to fluent but clinically inaccurate reports. By shifting to a report-level reward that directly measures clinical alignment using MCCS, the model learns to generate reports that are factually correct rather than just linguistically plausible. The GRPO algorithm enables efficient reinforcement learning by using group-relative comparisons rather than requiring separate value networks. The format reward further improves interpretability by encouraging structured reasoning before report generation.

## Foundational Learning

**Reinforcement Learning for Text Generation**
- Why needed: Standard MLE training doesn't optimize for clinical correctness, only linguistic fluency
- Quick check: Verify the model can generate multiple valid reports for the same image with different reward weights

**Vision-Language Models in Medical Domain**
- Why needed: Medical images require specialized visual understanding beyond general-purpose models
- Quick check: Confirm the VLM can correctly identify basic anatomical structures in chest X-rays

**Clinical Alignment Metrics**
- Why needed: Traditional NLP metrics don't capture medical accuracy or clinical relevance
- Quick check: Validate that MCCS scores correlate with clinician assessments of report quality

## Architecture Onboarding

**Component Map**
VLM Generator -> GRPO Optimizer -> MCCS Reward (Med-LVLM + CheXbert) + Format Reward -> Clinical Alignment

**Critical Path**
1. Input medical image processed by VLM
2. VLM generates candidate report
3. Med-LVLM encodes both generated and reference reports
4. CheXbert embeddings compare clinical content
5. MCCS reward calculated based on cosine similarity margin
6. Format reward adds structural constraint
7. GRPO updates model parameters

**Design Tradeoffs**
- Uses frozen fine-tuned LVLM for reward (computational efficiency vs. potential reward model bias)
- Margin-based MCCS reward (encourages clinical improvement vs. potential overfitting to ontology)
- Format reward encourages interpretability vs. stylistic constraint not clinically necessary

**Failure Signatures**
- Reports that are clinically aligned but lack important findings outside CheXbert ontology
- Generation failures when input images contain rare or atypical presentations
- Over-reliance on structured format may limit natural report variations

**3 First Experiments**
1. Compare generated reports against reference reports using standard clinical efficacy metrics
2. Evaluate model performance on clinical finding detection tasks
3. Conduct ablation study removing MCCS reward vs. removing format reward

## Open Questions the Paper Calls Out
None

## Limitations
- Clinical reward metric relies on CheXbert ontology, potentially missing clinically important findings outside predefined set
- Computationally expensive frozen fine-tuned LVLM required as reward model
- Format reward is stylistic constraint rather than clinically validated necessity

## Confidence

**High Confidence**: The empirical performance improvements on IU X-Ray and MIMIC-CXR datasets are well-documented with statistically significant results. The methodology for training with GRPO and the use of MCCS as a reward are clearly described and reproducible.

**Medium Confidence**: The clinical relevance of improvements measured by CE metrics is reasonable but limited by the underlying CheXbert ontology. The format reward's contribution to clinical correctness is plausible but not directly validated through clinician assessment.

**Low Confidence**: The generalizability of results to clinical practice and other imaging modalities is uncertain. The long-term stability of RL-trained models and their behavior with out-of-distribution cases has not been established.

## Next Checks

1. Conduct clinician review studies to validate that the generated reports are not only syntactically correct but clinically useful and complete, including findings outside the CheXbert ontology.

2. Test the model on external datasets with different imaging modalities (CT, MRI) and clinical domains to assess generalizability beyond chest X-rays.

3. Evaluate model performance and clinical alignment on challenging cases with rare findings or atypical presentations to assess robustness and safety in edge cases.