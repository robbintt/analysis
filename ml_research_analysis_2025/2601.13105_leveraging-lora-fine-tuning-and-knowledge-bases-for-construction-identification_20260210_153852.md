---
ver: rpa2
title: Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification
arxiv_id: '2601.13105'
source_url: https://arxiv.org/abs/2601.13105
tags:
- construction
- constructions
- grammar
- language
- ditransitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addressed the challenge of automatically identifying
  English ditransitive constructions by integrating LoRA-based fine-tuning of a large
  language model with a Retrieval-Augmented Generation (RAG) framework. Using annotated
  data from the British National Corpus, the fine-tuned Qwen3-8B model achieved an
  accuracy of 0.936 and F1 score of 0.874, significantly outperforming both a native
  Qwen3-MAX model and a theory-only RAG system.
---

# Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification

## Quick Facts
- arXiv ID: 2601.13105
- Source URL: https://arxiv.org/abs/2601.13105
- Reference count: 2
- Key outcome: LoRA fine-tuning of Qwen3-8B on BNC data achieved 0.936 accuracy and 0.874 F1 for ditransitive construction identification, outperforming both native LLM and theory-only RAG baselines.

## Executive Summary
This study addresses the challenge of automatically identifying English ditransitive constructions by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework. Using annotated data from the British National Corpus, the fine-tuned Qwen3-8B model achieved an accuracy of 0.936 and F1 score of 0.874, significantly outperforming both a native Qwen3-MAX model and a theory-only RAG system. Error analysis revealed that fine-tuning enabled the model to shift from surface-form pattern matching to semantically grounded understanding. The results demonstrate the effectiveness of combining theoretical knowledge with instance-based learning for construction identification and provide a practical, low-cost computational pathway for implementing constructionist theories.

## Method Summary
The approach combined LoRA-based fine-tuning with RAG to identify ditransitive constructions. Researchers first defined construction grammar criteria for ditransitives (S-V-IO-DO form with "CAUSE-RECEIVE" semantics), then annotated 5,000 sentences from the British National Corpus. A Qwen3-8B base model was fine-tuned using LoRA adapters on this dataset, with hyperparameters optimized via grid search. The fine-tuned model was evaluated against native LLM and theory-only RAG baselines on held-out test data, measuring accuracy, precision, recall, and F1 scores.

## Key Results
- Fine-tuned Qwen3-8B achieved 0.936 accuracy and 0.874 F1 score on ditransitive construction identification
- Outperformed native Qwen3-MAX model and theory-only RAG system across all metrics
- Error analysis showed fine-tuning shifted model behavior from surface pattern matching to semantically grounded understanding
- Demonstrated practical feasibility of using LoRA for construction identification tasks

## Why This Works (Mechanism)
The success stems from LoRA's parameter-efficient fine-tuning that calibrates the base LLM to the specific semantic constraints of ditransitive constructions. By training on annotated BNC data with clear form-meaning criteria, the model learns to associate the S-V-IO-DO surface pattern with the underlying "CAUSE-RECEIVE" semantic frame. The RAG component provides theoretical knowledge as context, but the fine-tuned model demonstrates superior performance by internalizing both syntactic and semantic requirements. This combination allows the model to correctly reject semantically invalid instances that fit the surface pattern but violate construction semantics.

## Foundational Learning
- **Concept: Construction Grammar (CxG)**
  - Why needed here: The entire paper is framed within this theory. To understand the task, you must know that CxG posits language consists of learned "form-meaning pairings" (constructions), where the meaning of a sentence (like "He baked her a cake") is not solely from the verb but also from the construction itself ("CAUSE-RECEIVE").
  - Quick check question: According to CxG, does the verb "bake" inherently contain the meaning of transfer, or is this meaning supplied by the ditransitive construction?

- **Concept: The Ditransitive Construction**
  - Why needed here: This is the target of identification. You must grasp its central sense ("X causes Y to receive Z") and its form (S-V-IO-DO) to understand what the model is being trained to recognize and the semantic constraints it must learn.
  - Quick check question: Why, according to the paper, might "She whispered him the news" be considered an incorrect use of the ditransitive construction, despite fitting the S-V-IO-DO pattern?

- **Concept: LoRA (Low-Rank Adaptation)**
  - Why needed here: This is the core technique used for model adaptation. Understanding it as a "parameter-efficient" method that updates a tiny fraction of the model's weights is key to appreciating the low-cost, practical contribution of the work.
  - Quick check question: Instead of updating all parameters, what does LoRA fine-tuning modify, and why is this advantageous for specialized tasks?

## Architecture Onboarding
- **Component map:**
  Base LLM (Qwen3-8B) -> LoRA Adapter -> Training Corpus (BNC) -> Annotation Scheme (1/0 binary) -> Fine-tuned Model

- **Critical path:**
  1. Define Criteria: Establish the theoretical definition of the ditransitive construction to create annotation guidelines
  2. Curate & Annotate Data: Extract candidate sentences from the BNC and have human annotators label them (1 = construction, 0 = not construction)
  3. Fine-Tune: Apply LoRA to fine-tune the Qwen3-8B model on the curated dataset. This calibrates the model to the task-specific semantic constraints
  4. Evaluate: Test the fine-tuned model against baselines (native LLM, RAG) on a held-out set to measure accuracy, precision, recall, and F1 score

- **Design tradeoffs:**
  - Low-Cost vs. Black Box: The LoRA approach is computationally cheap and effective, but the learned linguistic knowledge remains opaque and distributed in the model's parameters, making it hard to interpret
  - BNC Data Only: Using a single, clean corpus ensures quality but limits the model's generalization to other genres of English (e.g., social media, American English)
  - Binary Classification: The simple 1/0 output simplifies the task but may not capture the nuanced "degrees" of membership in a prototypical category

- **Failure signatures:**
  - Form-Meaning Dissociation: The model correctly identifies the S-V-IO-DO form but fails to reject semantically invalid instances (e.g., idioms like "give someone a call")
  - Overgeneralization: The model is so tuned to the construction's pattern that it mislabels transitive sentences (missing an object) as ditransitive
  - Syntactic Hierarchy Misjudgment: The model identifies a ditransitive structure nested in a subordinate clause as the main clause construction

- **First 3 experiments:**
  1. Baseline Benchmarking: Evaluate the performance of the native Qwen3-MAX model (no fine-tuning) and a pure theory-based RAG system on a sample test set. This establishes the difficulty of the task for generic models
  2. Hyperparameter Search: Perform a grid search to find optimal LoRA settings (rank, alpha, learning rate, epochs) by monitoring validation set accuracy
  3. Ablation Study: Train models on different subsets of data (e.g., theory-only annotations, form-only annotations) to isolate the contribution of semantic grounding vs. surface pattern matching

## Open Questions the Paper Calls Out
None

## Limitations
- The model's ability to generalize beyond the British National Corpus remains untested, potentially limiting real-world deployment
- The binary classification approach may oversimplify the graded nature of construction membership
- The fine-tuned model operates as a black box, preventing direct inspection of how construction knowledge is encoded

## Confidence
- High confidence in: (1) The core finding that LoRA fine-tuning significantly improves ditransitive construction identification compared to baseline approaches, (2) The demonstration that fine-tuning shifts the model from pattern matching to semantically grounded understanding, (3) The practical feasibility of using LoRA for construction identification tasks
- Medium confidence in: (1) The model's ability to generalize to other English varieties and domains, (2) The completeness of the error analysis in characterizing model limitations, (3) The relative contribution of semantic vs. syntactic features to model performance

## Next Checks
1. **Cross-Domain Validation**: Evaluate the fine-tuned model on construction identification tasks using corpora from different English varieties (American English, spoken English, social media text) and genres (academic writing, news articles) to assess generalization capabilities
2. **Error Type Taxonomy**: Conduct a systematic error analysis that categorizes misclassifications by type (form errors, semantic errors, idiomatic expressions, nested constructions) and develops targeted strategies to address each category
3. **Interpretability Analysis**: Apply probing techniques to identify which model components encode construction-specific knowledge, and test whether the learned representations align with theoretical predictions about constructional semantics and syntax