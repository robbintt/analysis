---
ver: rpa2
title: 'ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent
  Motion Forecasting'
arxiv_id: '2509.09210'
source_url: https://arxiv.org/abs/2509.09210
tags:
- prediction
- agents
- future
- graph
- joint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ProgD, a joint multi-agent motion prediction
  method that explicitly models the evolution of future interactions through dynamic
  heterogeneous graphs. Unlike existing methods that focus on modeling observed interactions
  or use static graphs for future scenarios, ProgD captures the dynamic and complex
  nature of social interactions among agents and their environment.
---

# ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting

## Quick Facts
- arXiv ID: 2509.09210
- Source URL: https://arxiv.org/abs/2509.09210
- Authors: Xing Gao; Zherui Huang; Weiyao Lin; Xiao Sun
- Reference count: 11
- Ranks 1st on INTERACTION and Argoverse 2 multi-agent prediction benchmarks

## Executive Summary
ProgD is a joint multi-agent motion forecasting method that explicitly models the evolution of future interactions through dynamic heterogeneous graphs. Unlike existing methods that focus on modeling observed interactions or use static graphs for future scenarios, ProgD captures the dynamic and complex nature of social interactions among agents and their environment. The method employs a progressive construction approach, where the structure of the dynamic graph at each future timestep is built based on previously predicted agent states. This enables accurate and consistent joint trajectory prediction for an arbitrary number of agents. The proposed ProgD achieves state-of-the-art performance on the INTERACTION multi-agent prediction benchmark, ranking 1st, and the Argoverse 2 multi-world forecasting benchmark.

## Method Summary
ProgD uses a multi-stage approach to predict future trajectories for multiple agents simultaneously. The method takes historical states (positions, velocities, yaw) and HD maps as input, then employs an encoder-decoder architecture. The encoder uses agent transformers and a road graph convolutional network to process the input, while the decoder progressively constructs dynamic heterogeneous graphs for each future timestep. At each step, the model predicts agent states based on the current graph structure, then updates the graph using these predictions to inform the next step. This process is repeated for the entire prediction horizon, with multi-scale decoding employed to reduce error accumulation.

## Key Results
- Achieves state-of-the-art performance on INTERACTION benchmark, reducing minJFDE from 0.9218 to 0.8620
- Decreases minJMR from 0.1728 to 0.1538 on the INTERACTION benchmark
- Reduces ranking metric average brier minimum final displacement error from 2.23 to 1.98 on Argoverse 2 benchmark

## Why This Works (Mechanism)
ProgD's effectiveness stems from its explicit modeling of dynamic future interactions through heterogeneous graphs. By constructing the graph structure based on previously predicted agent states, the method can capture how relationships between agents and their environment evolve over time. This is particularly important in complex traffic scenarios where interactions are not static but change as agents move. The progressive construction allows the model to make short-term predictions first, then use these as the basis for longer-term forecasts, creating a coherent trajectory that respects both agent dynamics and road constraints.

## Foundational Learning
- **Dynamic Heterogeneous Graphs**: Why needed: To model the evolving relationships between agents and their environment as scenarios unfold. Quick check: Verify that edges are correctly added/removed between consecutive timesteps based on predicted positions.
- **Multi-scale Decoding**: Why needed: To reduce error accumulation in progressive predictions. Quick check: Compare performance with and without multi-scale approach.
- **Scenario-centric Coordinates**: Why needed: To normalize inputs across different scenes and improve model generalization. Quick check: Ensure all positions are correctly transformed relative to ego or centroid agent.

## Architecture Onboarding

Component Map:
Historical States -> Agent Transformer -> Temporal Features -> Progressive Decoder -> Dynamic Graphs -> Trajectory Predictions

Critical Path:
Encoder (Agent Transformer + Road GCN + FusionGCN) -> Temporal Module -> Progressive Decoder (Coarse Pass -> Fine Pass) -> Multi-scale Headers

Design Tradeoffs:
- Fixed snapshot interval (τ=1s) balances accuracy and computational complexity
- Fully connected agent-agent graph ensures all interactions are considered
- Distance-based agent-lane edges reduce graph complexity while maintaining relevant environmental context

Failure Signatures:
- High collision rate in predictions suggests dynamic graph edges are not updating correctly
- Inconsistent trajectories with road network indicate issues in the FusionGCN or environmental modeling
- Poor long-term predictions point to insufficient error correction in the multi-scale decoding

First Experiments:
1. Visualize dynamic graph edge updates between consecutive timesteps to verify correct construction
2. Implement ablation comparing static versus dynamic graphs using the same progressive decoding framework
3. Test robustness by varying the snapshot interval τ and measuring performance impact

## Open Questions the Paper Calls Out
- How can joint multi-agent predictions be effectively integrated with downstream motion planning modules for autonomous vehicles?
- Can the time interval τ for dynamic graph snapshots be made adaptive or learnable to optimize the trade-off between temporal resolution and model complexity?
- To what extent does the progressive construction mechanism suffer from error accumulation when scaling to prediction horizons significantly longer than the tested 3 to 6 seconds?

## Limitations
- Specific architectural details of the FusionGCN module and Road GCN pooling/unpooling mechanisms are underspecified
- Learning rate schedule and weight decay parameters for the Adam optimizer are not detailed
- No ablation studies isolating the contribution of dynamic graph construction versus progressive decoding approach

## Confidence

**High Confidence:**
- Overall framework design (progressive multi-scale decoding with dynamic heterogeneous graphs) is clearly articulated and logically sound
- Evaluation metrics (minJFDE, minJMR, B-minJFDE) are standard in the field

**Medium Confidence:**
- Reported benchmark results appear valid given the described methodology
- Exact reproducibility requires assumptions about unspecified hyperparameters

**Low Confidence:**
- Specific architectural choices for the GCN components and their impact on performance are difficult to assess without additional implementation details

## Next Checks
1. Verify the dynamic graph construction by visualizing edge updates between consecutive timesteps in a sample scene, confirming that agent-lane edges are correctly added/removed based on the 15m distance threshold
2. Implement an ablation comparing static versus dynamic graphs using the same progressive decoding framework to quantify the contribution of the dynamic graph mechanism
3. Test the robustness of the progressive decoding by measuring performance degradation when varying the snapshot interval τ (e.g., 0.5s, 2s) to determine the optimal temporal granularity for different traffic densities