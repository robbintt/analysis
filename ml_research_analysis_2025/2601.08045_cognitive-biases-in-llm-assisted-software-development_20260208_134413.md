---
ver: rpa2
title: Cognitive Biases in LLM-Assisted Software Development
arxiv_id: '2601.08045'
source_url: https://arxiv.org/abs/2601.08045
tags:
- biases
- bias
- cognitive
- actions
- developers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first comprehensive study of cognitive
  biases in LLM-assisted software development. Through observational studies with
  14 developers and surveys with 22 additional developers, the authors found that
  48.8% of total programmer actions are biased, with developer-LLM interactions accounting
  for 56.4% of these biased actions.
---

# Cognitive Biases in LLM-Assisted Software Development

## Quick Facts
- arXiv ID: 2601.08045
- Source URL: https://arxiv.org/abs/2601.08045
- Reference count: 40
- 48.8% of programmer actions show cognitive bias, with 56.4% of biased actions occurring during LLM interactions

## Executive Summary
This paper presents the first comprehensive study of cognitive biases in LLM-assisted software development. Through observational studies with 14 developers and surveys with 22 additional developers, the authors found that LLM interactions significantly increase both the likelihood of biased actions and reversal rates compared to traditional programming workflows. They identified 90 cognitive biases specific to developer-LLM interactions, grouped into 15 validated bias categories. The study reveals that Fixation biases cause the most reversed actions (43.4% of cases), while Instant Gratification and Suggester Preference are the most frequent biases in LLM-related actions.

## Method Summary
The study used a mixed-methods approach with 14 developers (7 students, 7 professionals) coding for 60 minutes with think-aloud protocol, followed by retrospective interviews. Actions were classified into 9 categories and annotated for bias presence using a taxonomy of 90 biases across 15 categories validated by a cognitive psychologist. Chi-square tests with Bonferroni correction examined associations between LLM usage, bias presence, and reversal actions. An additional 22 developers participated in scenario-based surveys for triangulation and mitigation strategy collection.

## Key Results
- 48.8% of total programmer actions were biased, with developer-LLM interactions accounting for 56.4% of these biased actions
- LLM use strongly correlates with bias presence (χ²(1, N=2013)=30.72, p=2.97×10⁻⁸)
- Fixation biases led to the largest number of reversed actions (43.4% of cases)

## Why This Works (Mechanism)

### Mechanism 1
The shift from solution-generation to solution-evaluation creates new cognitive load patterns. Developers must evaluate AI-generated suggestions rapidly, which reduces deliberation time and increases susceptibility to biases like instant gratification (accepting code because it runs initially) and suggester preference (trusting LLM authority without verification).

### Mechanism 2
When LLM provides an initial solution, developers treat it as an anchor point. Even when errors occur, they modify the same approach rather than considering alternatives. This manifests as "anchoring bias" and "sunk cost fallacy"—continuing down a suboptimal path because of prior investment.

### Mechanism 3
Task delegation attitude correlates with bias type—developers delegating complex tasks show more optimism/pessimism biases; those delegating simple tasks show more self-preference and fixation. Type A developers (high-cognitive-load tasks) exhibit optimism bias about LLM capabilities, while Type B developers (low-cognitive-load tasks) exhibit self-preference and fixation on their initial approach.

## Foundational Learning

- **Cognitive biases in decision-making**: Systematic thinking deviations affect judgment. Why needed: The entire paper assumes familiarity with how systematic thinking deviations affect judgment. Quick check: Can you explain why cognitive biases are called "systematic" rather than random errors?

- **Chi-square tests with Bonferroni correction**: Statistical tests for correlation significance with multiple comparison adjustment. Why needed: The paper's statistical claims about bias-reversal associations depend on understanding when correlations are significant versus spurious. Quick check: Why does the Bonferroni correction make it harder to find "significant" results?

- **Reversal actions as bias impact metrics**: Actions developers later undo, discard, or redo as measurable proxy for suboptimal decisions. Why needed: The paper operationalizes "negative outcomes" as actions developers later undo/discard/redo. Quick check: What are limitations of using reversal actions as the sole indicator of bias impact?

## Architecture Onboarding

- **Component map**: Observation layer -> Action classification layer -> Bias taxonomy layer -> Survey validation layer
- **Critical path**: 1) Code actions from video transcripts -> 2) Classify as LLM-related or not -> 3) Label each action for bias category membership -> 4) Identify reversal actions -> 5) Run chi-square tests
- **Design tradeoffs**: Sample size vs. depth (14 participants provides rich data but limits generalizability); Reversal as proxy (captures only lower-bound of bias impact); Think-aloud protocol (may alter natural behavior)
- **Failure signatures**: High reversal rate (>30%) combined with low self-reported bias awareness indicates poor calibration; If fixation bias dominates but developer reports "Instant Gratification" as primary concern, perception-reality gap exists
- **First 3 experiments**: 1) Replicate with larger sample (n=50+) to validate whether 56.4% LLM-bias association holds across experience levels and programming languages; 2) Test intervention: require developers to list two alternative approaches before adopting LLM suggestion—measure fixation bias reduction; 3) Longitudinal study: track whether bias frequency decreases with LLM experience or if patterns persist

## Open Questions the Paper Calls Out

- **New cognitive blind spots**: Do LLMs create new cognitive blind spots or diminish developers' critical evaluation skills through over-reliance on generated suggestions? The study established a correlation but cannot isolate whether LLMs actively diminish existing skills or simply expose developers to novel bias vectors.

- **Task complexity correlation**: How does the complexity of a development task correlate with the frequency and specific types of cognitive biases in developer-LLM interactions? The observational study size limited statistical power to validate preliminary findings about higher cognitive load leading to higher bias susceptibility.

- **Effective debiasing strategies**: Which specific debiasing strategies are most effective at mitigating high-frequency biases like Instant Gratification and Fixation in LLM-assisted coding? While the paper identified harmful biases and cataloged potential mitigation strategies, it did not empirically test their efficacy.

## Limitations

- Small sample size (14 observational participants) limits generalizability across different programming domains, experience levels, and cultural contexts
- Using reversal actions as the primary measure of bias impact captures only lower-bound estimates—persistent bugs, technical debt, and delayed discovery remain unmeasured
- The 90 biases across 15 categories may not capture all relevant biases in LLM-assisted programming or may overfit to this specific sample

## Confidence

- **High confidence**: The statistical finding that LLM-related actions show significantly higher bias frequency (56.4% of biased actions) and that fixation biases lead to the most reversals (43.4% of cases)
- **Medium confidence**: The claim that task delegation attitude correlates with specific bias types (Type A vs Type B developers)
- **Medium confidence**: The 15 bias categories and 90 individual biases identified

## Next Checks

1. Replicate the study with N=50+ developers across different programming languages, domains, and experience levels to validate whether the 56.4% LLM-bias association holds
2. Implement a controlled experiment where one group must list two alternative approaches before adopting any LLM suggestion, while a control group proceeds normally, to measure fixation bias reduction
3. Conduct a 6-month longitudinal study tracking the same developers as they gain experience with LLMs to test whether bias frequency decreases over time or remains stable