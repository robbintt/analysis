---
ver: rpa2
title: Testing for Causal Fairness
arxiv_id: '2502.12874'
source_url: https://arxiv.org/abs/2502.12874
tags:
- fairness
- n-te
- testing
- sensitive
- cf-clot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a distribution-based Potential Outcomes Framework
  (POF) to transform fairness analysis into Distributional Closeness Testing (DCT)
  by intervening on sensitive attributes. The authors define counterfactual closeness
  fairness where factual and counterfactual potential outcome distributions are sufficiently
  close, measured by Norm-Adaptive Maximum Mean Discrepancy Treatment Effect (N-TE).
---

# Testing for Causal Fairness

## Quick Facts
- arXiv ID: 2502.12874
- Source URL: https://arxiv.org/abs/2502.12874
- Authors: Jiarun Fu; LiZhong Ding; Pengqi Li; Qiuning Wei; Yurong Cheng; Xu Chen
- Reference count: 35
- Key outcome: Introduces distribution-based POF framework transforming fairness analysis into DCT, with CF-CLOT method validated across real-world datasets

## Executive Summary
This paper presents a novel approach to causal fairness testing by reformulating the problem as Distributional Closeness Testing (DCT). The authors introduce a Potential Outcomes Framework (POF) where fairness is measured by the closeness between factual and counterfactual outcome distributions, quantified using Norm-Adaptive Maximum Mean Discrepancy Treatment Effect (N-TE). The proposed Counterfactual Fairness-Closeness Testing (CF-CLOT) method provides theoretical guarantees for testing consistency while demonstrating effectiveness across various real-world datasets. The framework handles high-dimensional data and offers adjustable sensitivity through the closeness parameter ε.

## Method Summary
The paper introduces a distribution-based Potential Outcomes Framework that transforms fairness analysis into Distributional Closeness Testing by intervening on sensitive attributes. The framework defines counterfactual closeness fairness where factual and counterfactual potential outcome distributions are sufficiently close, measured by N-TE. CF-CLOT uses empirical N-TE estimation with rigorous theoretical analysis establishing testing consistency. The method successfully handles high-dimensional data and achieves comparable performance to state-of-the-art structural causal model methods.

## Key Results
- CF-CLOT effectively identifies unfair sensitive attributes across various real-world datasets
- The method demonstrates sensitivity through adjustable closeness parameter ε with "Strong," "Neutral," and "Weak" levels
- Achieves comparable performance to state-of-the-art SCM-based methods while handling high-dimensional data
- Validated effectiveness through experiments showing consistent fairness detection capabilities

## Why This Works (Mechanism)
The approach works by reframing causal fairness as a statistical testing problem rather than requiring explicit causal graph construction. By measuring distribution closeness between factual and counterfactual outcomes using kernel-based MMD, the method captures complex non-linear relationships without requiring structural causal knowledge. The N-TE normalization adapts to different feature spaces and sample sizes, providing a robust metric for fairness assessment that can be tuned through the ε parameter.

## Foundational Learning
**Distributional Closeness Testing (DCT)**: A statistical framework for comparing probability distributions without parametric assumptions - needed to avoid distributional assumptions about outcome variables, quick check: verify characteristic kernel properties hold
**Reproducing Kernel Hilbert Space (RKHS)**: Function space where kernel methods operate, enabling non-linear feature mapping - needed for non-parametric distribution comparison, quick check: confirm kernel is characteristic
**Norm-Adaptive Maximum Mean Discrepancy (N-MMD)**: Normalized version of MMD that adapts to different feature space norms - needed for scale-invariant fairness measurement, quick check: verify normalization factor computation
**Potential Outcomes Framework (POF)**: Counterfactual reasoning framework for causal inference - needed to define factual/counterfactual distributions, quick check: confirm consistency with Rubin causal model
**Counterfactual Fairness**: Fairness notion where predictions are independent of sensitive attributes given non-descendants - needed to define fairness criterion, quick check: verify Markov property assumptions

## Architecture Onboarding
**Component Map**: Sensitive attribute → Intervention mechanism → Outcome generation → Distribution estimation → N-TE calculation → Fairness decision
**Critical Path**: Intervention on sensitive attributes → Generate counterfactual outcomes → Estimate factual/counterfactual distributions → Compute N-TE statistic → Compare against ε threshold
**Design Tradeoffs**: Distribution-based approach avoids explicit causal graph construction but may lose structural information compared to SCM methods; kernel choice affects N-TE stability but offers flexibility for high-dimensional data
**Failure Signatures**: High variance in N-TE estimates indicating insufficient sample size; failure to reject fairness null when true discrimination exists (low power); overfitting to specific kernel choices
**First Experiments**: 1) Synthetic data with known discrimination to validate detection power, 2) Ablation study on different characteristic kernels, 3) Scalability test with increasing dimensionality and sample size

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can the closeness parameter $\epsilon$ be determined theoretically or adaptively for specific domains rather than relying on manual tuning?
- Basis in paper: Section 4.2 establishes "Strong," "Neutral," and "Weak" sensitivity levels with example values (0, 0.1, 0.3), but leaves the exact selection of $\epsilon$ to the user.
- Why unresolved: The paper provides heuristics for $\epsilon$ but no formal mechanism to derive the parameter based on the statistical properties of the data or legal fairness standards.
- What evidence would resolve it: A derived theoretical bound or an automated algorithm that sets $\epsilon$ based on dataset characteristics to minimize Type I/II errors in fairness detection.

### Open Question 2
- Question: Can the distribution-based approach be improved to consistently outperform or match Structural Causal Model (SCM) methods when causal graphs are available?
- Basis in paper: Section 6 states that CF-CLOT was "slightly inferior" to the SCM-based method IFair and notes the method "paves the way for further exploration."
- Why unresolved: The paper validates the method's viability but does not address the performance gap compared to models that utilize explicit causal structural knowledge.
- What evidence would resolve it: Theoretical analysis identifying the information loss in distribution-based embeddings compared to causal graphs, or a hybrid model that closes the performance gap.

### Open Question 3
- Question: How sensitive is the N-TE statistic to the selection of the characteristic kernel $\kappa$ in high-dimensional spaces?
- Basis in paper: Definitions 2 and 4 rely on the Reproducing Kernel Hilbert Space (RKHS) and Lemma 1 requires a characteristic kernel, yet the experiments do not ablate the impact of different kernel functions.
- Why unresolved: While the method handles high-dimensional data, the dependence of the N-TE's normalized value on the kernel choice could affect the calibration of the fairness threshold $\epsilon$.
- What evidence would resolve it: Experimental results comparing the stability of N-TE and testing power across standard characteristic kernels (e.g., Gaussian, Laplacian) on the RAF-DB or Credit Risk datasets.

## Limitations
- Theoretical guarantees assume complete conditional distributions and perfect counterfactual generation, which may not hold in practice
- N-TE estimation through empirical means introduces approximation errors that could affect testing consistency in high-dimensional settings
- Computational complexity of kernel-based MMD calculations may limit scalability for very large datasets
- Performance gap remains compared to structural causal model methods when explicit causal knowledge is available

## Confidence
- **High Confidence**: The theoretical framework connecting causal fairness to distribution closeness testing is sound and well-established
- **Medium Confidence**: Empirical validation shows promising results, but performance comparisons are limited to a specific set of datasets
- **Low Confidence**: The practical implications of adjusting the closeness parameter ε for real-world fairness interventions require further investigation

## Next Checks
1. Conduct extensive scalability tests with datasets containing >100,000 samples to evaluate computational feasibility and runtime performance
2. Implement robustness analysis by introducing various types of data perturbations and noise to assess sensitivity of the N-TE estimates
3. Compare CF-CLOT performance against additional fairness testing methods beyond structural causal models, including post-processing fairness approaches