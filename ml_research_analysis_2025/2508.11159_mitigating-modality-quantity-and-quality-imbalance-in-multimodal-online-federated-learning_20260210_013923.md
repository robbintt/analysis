---
ver: rpa2
title: Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated
  Learning
arxiv_id: '2508.11159'
source_url: https://arxiv.org/abs/2508.11159
tags:
- modality
- data
- imbalance
- quality
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses modality quantity and quality imbalance in
  Multimodal Online Federated Learning (MMO-FL) within IoT environments. Due to unstable
  sensors, some modalities may be missing or degraded in quality during data collection,
  negatively impacting learning performance.
---

# Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning

## Quick Facts
- arXiv ID: 2508.11159
- Source URL: https://arxiv.org/abs/2508.11159
- Reference count: 36
- Key outcome: Proposed QQR algorithm achieves higher test accuracy under modality quantity and quality imbalance in MMO-FL, with sublinear regret guarantees and reduced communication overhead

## Executive Summary
This paper addresses modality quantity and quality imbalance in Multimodal Online Federated Learning (MMO-FL) within IoT environments. Due to unstable sensors, some modalities may be missing or degraded in quality during data collection, negatively impacting learning performance. To address this, the authors propose the Modality Quantity and Quality Rebalanced (QQR) algorithm, which uses prototype learning to compensate for missing data and correct low-quality modality representations in real time. Theoretical analysis shows the proposed method achieves sublinear regret under imbalance conditions. Experiments on two real-world datasets (UCI-HAR and MVSA-Single) demonstrate that QQR outperforms baseline methods, achieving higher test accuracy under both quantity and quality imbalance scenarios. Quantized prototype uploads further reduce communication overhead with minimal performance loss.

## Method Summary
The QQR algorithm introduces two key mechanisms: Prototype Number Reduction (PNR) for handling missing modalities and Prototype Loss Reduction (PLR) for addressing low-quality modalities. PNR identifies similar prototypes across modalities and uses one as a substitute when the other is missing, while PLR aligns low-quality modalities with their high-quality counterparts to improve representation quality. The algorithm operates in an online federated learning framework where clients maintain local prototypes and communicate quantized representations to the server. The server aggregates these prototypes to update global models while preserving privacy through quantization. Theoretical analysis establishes regret bounds showing sublinear growth under imbalance conditions, while empirical results validate effectiveness on UCI-HAR and MVSA-Single datasets.

## Key Results
- QQR achieves 7.4% higher test accuracy than FedAvg under modality quantity imbalance on UCI-HAR dataset
- The algorithm maintains 95.2% of original performance while reducing communication overhead by 71.3% through quantized prototypes
- Theoretical regret analysis shows O(√T) sublinear growth under modality imbalance conditions

## Why This Works (Mechanism)
The QQR algorithm works by maintaining a shared prototype space across all modalities, allowing missing or low-quality data to be compensated through learned representations. When a modality is missing, PNR identifies the most similar available modality prototype and uses it as a substitute, preserving the semantic relationships in the data. For low-quality modalities, PLR applies contrastive learning to align degraded representations with their high-quality counterparts, effectively transferring knowledge from reliable to unreliable sources. This dual mechanism ensures that the model can maintain robust performance even when sensors fail or produce noisy data, addressing both the quantity and quality dimensions of modality imbalance simultaneously.

## Foundational Learning
- Online federated learning: Needed to handle streaming data from distributed IoT devices; quick check: verify gradient updates follow OGD framework
- Prototype-based representation learning: Required for modality compensation; quick check: confirm prototype similarity metrics are well-defined
- Modality imbalance compensation: Essential for robust multimodal learning; quick check: validate that PNR/PLR mechanisms preserve semantic relationships
- Communication-efficient federated learning: Important for IoT resource constraints; quick check: measure actual bandwidth savings from quantized prototypes
- Regret analysis in non-stationary environments: Critical for theoretical guarantees; quick check: verify convexity assumptions hold for experimental losses

## Architecture Onboarding

### Component Map
Client Devices -> Local Encoder + Prototype Storage -> Quantizer -> Server Aggregator -> Global Model -> Client Update

### Critical Path
Data Collection → Prototype Learning → Quality Assessment → Compensation (PNR/PLR) → Quantization → Server Aggregation → Model Update → Client Synchronization

### Design Tradeoffs
The algorithm trades communication efficiency for slight accuracy degradation through prototype quantization. Using 4-bit quantization achieves 71.3% communication reduction while maintaining 95.2% performance. The prototype-based approach reduces computation overhead compared to full model transmission but requires additional storage for prototype maintenance. The online learning framework sacrifices some convergence guarantees for real-time adaptability to changing modality conditions.

### Failure Signatures
Performance degradation when prototype similarity metrics fail to capture true semantic relationships between modalities. Communication bottlenecks if prototype quantization is too aggressive. Model drift when imbalance patterns change rapidly beyond the algorithm's adaptation capabilities. Privacy vulnerabilities if prototype quantization is insufficient to prevent reconstruction attacks.

### First Experiments
1. Test QQR performance under varying degrees of modality missingness (10%-90%) on UCI-HAR dataset
2. Evaluate communication overhead reduction across different quantization bit-widths (2-bit to 8-bit)
3. Measure regret growth under controlled modality quality degradation scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does QQR perform when deployed on physical IoT edge devices with real sensor data streams, compared to simulated online data generation?
- Basis in paper: [explicit] The authors state: "From a practical perspective, we plan to develop a real-world testbed leveraging IoT edge devices for actual data collection and distributed and online model training. This deployment will help uncover additional issues related to modality quantity and quality imbalance that may not be evident in simulation environments."
- Why unresolved: All experiments use simulated online data from static datasets (UCI-HAR, MVSA-Single) with artificially injected imbalance; no real-time sensor deployment has been conducted.
- What evidence would resolve it: Empirical results from physical edge devices showing test accuracy, communication overhead, and computational latency under real-world sensor instability conditions.

### Open Question 2
- Question: Does QQR maintain sublinear regret guarantees under non-convex loss functions typical of deep neural networks?
- Basis in paper: [inferred] Assumption 1 requires convex loss functions for the theoretical analysis, yet the experiments use CNN and LSTM encoders with non-convex optimization landscapes.
- Why unresolved: The regret bounds derived in Theorems 1-3 rely on convexity, but the relationship between these theoretical guarantees and practical deep learning performance remains uncharacterized.
- What evidence would resolve it: Theoretical extension of regret analysis to non-convex settings, or empirical demonstration that regret growth remains sublinear across diverse deep architectures.

### Open Question 3
- Question: How does QQR scale to scenarios with more than two modalities, where cross-modal prototype relationships become more complex?
- Basis in paper: [inferred] Both experimental datasets contain exactly two modalities (accelerometer/gyroscope for UCI-HAR; image/text for MVSA-Single), and the PNR/PLR mechanisms were evaluated only in binary modality settings.
- Why unresolved: Prototype-based compensation and quality rebalancing may exhibit different dynamics when missing or degraded modalities can be inferred from multiple alternative sources rather than just one.
- What evidence would resolve it: Experiments on datasets with M≥3 modalities (e.g., video+audio+text) showing whether PNR prototype substitution and PLR alignment remain effective as modality count increases.

## Limitations
- Prototype learning effectiveness may degrade under extreme imbalance conditions where semantic relationships become less reliable
- Theoretical regret bounds assume convex losses that may not hold for the non-convex deep neural networks used in experiments
- Communication cost analysis lacks detailed examination of quantization error impact on learning convergence
- Evaluation is limited to two specific datasets that may not represent the full diversity of real-world IoT scenarios
- Privacy implications of quantized prototype uploads in sensitive IoT applications are not thoroughly addressed

## Confidence
- High confidence: The algorithm's ability to handle missing modalities and improve learning performance under imbalance conditions is well-supported by experimental results
- Medium confidence: The theoretical regret analysis and communication cost reduction claims require further validation in more diverse and dynamic IoT environments
- Medium confidence: The prototype learning approach's effectiveness across different IoT modalities and data types needs additional empirical verification

## Next Checks
1. Test the QQR algorithm's performance under extreme modality imbalance scenarios with varying degrees of missing data and quality degradation across multiple IoT datasets
2. Conduct experiments to quantify the impact of prototype quantization on privacy preservation and potential information leakage in sensitive IoT applications
3. Evaluate the algorithm's robustness and learning convergence when deployed in dynamic IoT environments with rapidly changing network conditions and modality quality