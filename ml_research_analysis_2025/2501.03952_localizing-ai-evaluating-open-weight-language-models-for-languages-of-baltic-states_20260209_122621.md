---
ver: rpa2
title: 'Localizing AI: Evaluating Open-Weight Language Models for Languages of Baltic
  States'
arxiv_id: '2501.03952'
source_url: https://arxiv.org/abs/2501.03952
tags:
- gemma
- wang
- llama
- llms
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates how well open-weight language models support
  Baltic languages (Lithuanian, Latvian, Estonian) by testing popular models like
  Llama 3, Gemma 2, Phi 3, and NeMo on machine translation, multiple-choice question
  answering, and free-form text generation. The study finds that while Gemma 2 models
  achieve performance close to top commercial models like GPT-4o, most open-weight
  models still struggle with these languages.
---

# Localizing AI: Evaluating Open-Weight Language Models for Languages of Baltic States

## Quick Facts
- arXiv ID: 2501.03952
- Source URL: https://arxiv.org/abs/2501.03952
- Authors: Jurgita Kapočiūtė-Dzikienė; Toms Bergmanis; Mārcis Pinnis
- Reference count: 7
- Key outcome: Open-weight LLMs (Llama 3, Gemma 2, Phi 3, NeMo) show strong translation scores but suffer 1-in-20-word lexical hallucinations on Baltic languages; Gemma 2 approaches GPT-4o performance, while quantization and fine-tuning critically affect low-resource language output quality.

## Executive Summary
This study evaluates popular open-weight language models on Lithuanian, Latvian, and Estonian across machine translation, multiple-choice question answering, and free-form text generation. While models like Gemma 2 achieve near state-of-the-art translation performance, they still exhibit lexical hallucinations with invented words in at least 1 in 20 words. Quantization disproportionately harms Baltic languages, and specialized fine-tuning (e.g., Lt-Llama 2) is essential for high-quality outputs, reducing hallucination rates to near zero. The findings highlight the need for better Baltic language data and targeted model development.

## Method Summary
The evaluation uses zero-shot inference on open-weight models (Llama 3/3.1/3.2, Gemma 2, Phi 3, NeMo) via Ollama, testing three tasks: machine translation (FLORES-200), multiple-choice QA (Belebele), and free-form text generation (human-evaluated for errors). Models are tested at 4-bit, 8-bit, and 16-bit precision. Translation quality is scored with COMET; QA with accuracy; text generation is assessed via human annotation of grammatical errors, invented words, and syntactic errors per 100 words. Lt-Llama 2 is included as a fine-tuned baseline for Lithuanian.

## Key Results
- Gemma 2 27B achieves COMET scores within 0.15-0.25 of GPT-4o on Baltic language translation.
- All open-weight multilingual models exhibit lexical hallucinations with errors in at least 1 in 20 words.
- Quantization (4-bit) disproportionately degrades Baltic language performance: Llama 3.1 70B loses 0.06-0.12 accuracy for Lithuanian, Latvian, and Estonian versus 0.01-0.02 for English and Czech.
- Lt-Llama 2, fine-tuned for Lithuanian, achieves near-zero hallucination rates (<1%) compared to 5%+ for general multilingual models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model performance on lesser-spoken languages scales with training data representation, not linguistic complexity.
- Mechanism: The relative strength of Czech results compared to Baltic languages suggests disparities correlate with training corpus volume per language. Models encode statistical patterns from exposure; languages with fewer tokens receive weaker internal representations, yielding lower fluency and accuracy.
- Core assumption: Architectural capacity is not the bottleneck; data scarcity is.
- Evidence anchors:
  - [abstract] "Most surprisingly, however, we find that these models, while showing close to state-of-the-art translation performance, are still prone to lexical hallucinations with errors in at least 1 in 20 words for all open-weight multilingual LLMs."
  - [section 3] "Comparatively good results for Czech suggest that these disparities are related to the amount of data each LLM has seen for each language during training, rather than factors such as the structural complexity of the language."
  - [corpus] Related work on multilingual LLM evaluation confirms performance gaps for low-resource languages are widespread but does not establish causality.
- Break condition: If a model with similar parameter count but different training distribution achieves parity on Baltic languages, the data-volume hypothesis weakens.

### Mechanism 2
- Claim: Quantization degrades low-resource language performance more than high-resource language performance.
- Mechanism: Low-resource language representations likely occupy fewer dimensions and are more sparsely encoded. Aggressive quantization (4-bit) compresses already-fragile embeddings, causing disproportionate accuracy loss for languages with less training signal.
- Core assumption: Quantization error distributes non-uniformly across language-specific subspaces.
- Evidence anchors:
  - [abstract] "The evaluation reveals that quantization affects smaller language performance more."
  - [section 3] "Less spoken languages like Lithuanian, Latvian, and Estonian are affected more than English and Czech... For example, the Llama 3.1 70B model loses 0.06, 0.12, and 0.08 accuracy for Lithuanian, Latvian, and Estonian, respectively, but only 0.01 and 0.02 for English and Czech."
  - [corpus] Weak direct evidence; neighboring papers do not quantify quantization effects on low-resource languages explicitly.
- Break condition: If fine-tuning on modest Baltic-language data before quantization restores performance parity, the fragility may be remediable rather than structural.

### Mechanism 3
- Claim: Specialized language fine-tuning dramatically reduces lexical hallucinations even with smaller base models.
- Mechanism: Task-specific fine-tuning (e.g., Lt-Llama 2) reweights model parameters toward target-language patterns, suppressing spurious token predictions that cause invented words and grammatical errors.
- Core assumption: Hallucinations arise from under-specified language priors rather than inherent model capacity limits.
- Evidence anchors:
  - [abstract] "Specialized fine-tuning (e.g., Lt-Llama 2) is necessary for high-quality outputs in Baltic languages."
  - [section 3, Table 4] "Lt-Llama 2 models, specifically fine-tuned for Lithuanian, are the exception, with an error rate of just 0.98% and no invented words."
  - [corpus] Cross-lingual fine-tuning studies suggest similar gains, but causal attribution remains inferred.
- Break condition: If general multilingual models match Lt-Llama 2 performance via in-context learning with retrieved Baltic examples, fine-tuning necessity may be task-specific rather than absolute.

## Foundational Learning

- Concept: **Lexical hallucination in LLMs**
  - Why needed here: The paper documents "invented words not existing in the language" as a distinct failure mode separate from grammatical errors.
  - Quick check question: Can you distinguish between a mistranslation (wrong word), a grammatical error (wrong inflection), and a lexical hallucination (nonexistent word)?

- Concept: **Quantization (4-bit vs. 8-bit vs. 16-bit)**
  - Why needed here: The paper evaluates precision tradeoffs and finds Baltic languages are more sensitive to quantization than high-resource languages.
  - Quick check question: If a model loses 0.10 accuracy on Lithuanian but only 0.02 on English when moving from 16-bit to 4-bit, what does this imply about the language representations?

- Concept: **Zero-shot evaluation**
  - Why needed here: All experiments use zero-shot inference; understanding this setup is critical for interpreting the results as measures of latent multilingual capability.
  - Quick check question: Why might zero-shot performance understate what fine-tuning could achieve?

## Architecture Onboarding

- Component map:
  Ollama platform -> Model selection (Llama 3/3.1/3.2, Gemma 2, Phi 3, NeMo, Lt-Llama 2) -> Task-specific prompts -> Zero-shot inference -> Output evaluation (COMET, accuracy, human error annotation)

- Critical path:
  1. Select model and quantization level
  2. Run zero-shot inference on target task (MT/MCQA/generation)
  3. Score outputs using task-appropriate metrics
  4. For generation: deploy human annotators to count grammatical errors, invented words, and syntactic failures

- Design tradeoffs:
  - **Model size vs. deployment cost**: 70B models require enterprise GPUs; 9B Gemma 2 at 4-bit offers strong performance on consumer hardware.
  - **Quantization vs. low-resource accuracy**: 4-bit cuts memory but disproportionately harms Baltic-language performance, especially for Llama models.
  - **General multilingual vs. language-specific fine-tuning**: Lt-Llama 2 achieves near-zero hallucination rates but requires additional training investment.

- Failure signatures:
  - High translation COMET scores but elevated hallucination rates (1 in 20 words) indicate fluent-sounding but unreliable outputs.
  - Phi 3 models fail to follow JSON output format instructions in non-English tasks.
  - Llama 3.1 generates 3–4 invented words per 100 tokens in Lithuanian/Latvian.

- First 3 experiments:
  1. **Baseline comparison**: Evaluate Gemma 2 9B vs. Llama 3.1 8B on FLORES-200 English-to-Lithuanian at 4-bit; expect COMET gap of ~0.20+.
  2. **Quantization sensitivity test**: Run Llama 3.1 8B at 4-bit, 8-bit, and 16-bit on Belebele Lithuanian; quantify accuracy delta per precision level.
  3. **Hallucination audit**: Generate 10 free-form Lithuanian responses with Gemma 2 27B; manually count grammatical errors and invented words to verify the ~1 in 20 word error rate claimed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would fine-grained error analysis using MQM (Multidimensional Quality Metrics) and ESA (Error Span Annotation) frameworks reveal specific error patterns in Baltic language generation that current COMET scores mask?
- Basis in paper: [explicit] The authors state: "future work could benefit from more fine-grained error analysis using frameworks like MQM (Multidimensional Quality Metrics) and ESA (Error Span Annotation). These approaches allow detailed classification of errors-such as those related to accuracy, fluency, and terminology."
- Why unresolved: The current evaluation uses only COMET scores for MT, which provide holistic quality measures but do not categorize specific error types that could guide targeted improvements.
- What evidence would resolve it: MQM/ESA annotation of model outputs revealing error type distributions (accuracy, fluency, terminology) and their relative impact on usability for Baltic languages.

### Open Question 2
- Question: What data and training factors cause Gemma 2 models to exhibit quantization robustness while Llama models show significant performance degradation for lower-resource languages?
- Basis in paper: [inferred] The paper documents that Gemma 2 shows "statistically insignificant drop" under 4-bit quantization while Llama 3.1 8B loses 0.074 COMET points for MT and 0.100 accuracy for MCQA. The paper does not investigate architectural or training-data causes.
- Why unresolved: The paper reports the differential impact but does not analyze whether this stems from training data composition, architectural choices, or other factors.
- What evidence would resolve it: Ablation studies comparing model architectures and training corpora, specifically examining multilingual data ratios and their interaction with quantization methods.

### Open Question 3
- Question: Can high-quality language-specific fine-tuning data alone reduce lexical hallucination rates to near-zero for Baltic languages, or are architectural modifications also required?
- Basis in paper: [explicit] The authors conclude with: "highlighting the need for 1) high-quality language data for languages of the Baltic states and 2) research on language-specialized LLMs" while noting Lt-Llama 2 achieves 0.98% error rate versus 4.08% for the best open-weight multilingual model.
- Why unresolved: While Lt-Llama 2 demonstrates near-perfect output, it remains unclear whether this success transfers to other Baltic languages (Latvian, Estonian) or requires language-specific fine-tuning data that may not exist.
- What evidence would resolve it: Fine-tuning experiments on Latvian and Estonian using comparable data volumes, measuring error rates and hallucination frequency against multilingual baselines.

## Limitations

- The evaluation uses a small sample size (10 questions, 3 annotators) for text generation error rates, introducing high variance in the extrapolated 1-in-20-word hallucination rate.
- Quantization comparisons are limited to 4-bit vs 16-bit, lacking intermediate precision analysis to identify optimal tradeoffs.
- The study cannot definitively attribute performance gaps to training data volume due to opacity in model training corpora.

## Confidence

**High Confidence Claims**:
- Gemma 2 27B achieves COMET scores within 0.15-0.25 of GPT-4o on Baltic language translation
- Llama models show consistent degradation of 0.06-0.12 accuracy points for Baltic languages versus English/Czech under 4-bit quantization
- Lt-Llama 2 demonstrates near-zero lexical hallucination rates (<1%) compared to 5%+ for general multilingual models

**Medium Confidence Claims**:
- Performance disparities between Baltic and high-resource languages primarily reflect training data volume differences
- 4-bit quantization disproportionately impacts low-resource language performance due to sparse representation encoding
- Specialized fine-tuning effectively reduces hallucinations but requires substantial language-specific investment

**Low Confidence Claims**:
- The exact relationship between tokenization quality and Baltic language performance
- Generalizability of the 1-in-20-word hallucination rate across different domains and generation tasks
- Whether quantization effects are structural or remediable through pre-fine-tuning

## Next Checks

**Check 1: Quantization Trade-off Analysis** - Systematically evaluate Llama 3.1 8B and Gemma 2 9B across 4-bit, 8-bit, and 16-bit precisions on all three Baltic languages for both MT (COMET) and MCQA (accuracy). Plot performance curves to identify inflection points where quantization noise overwhelms language representation benefits, particularly for low-resource languages.

**Check 2: Hallucination Rate Validation** - Generate 100 free-form responses per model (Gemma 2 9B, Llama 3.1 8B, Lt-Llama 2) using the 10 evaluation questions, then recruit 10 annotators to independently rate invented words and grammatical errors. Compare inter-annotator agreement and verify whether the extrapolated 1-in-20-word rate holds under larger samples.

**Check 3: Training Data Impact Isolation** - Using available model cards and public training data statistics, construct a regression model predicting Baltic language performance from per-language token counts. Test whether Czech's superior performance relative to Baltic languages correlates with its training representation, controlling for linguistic family and morphological complexity.