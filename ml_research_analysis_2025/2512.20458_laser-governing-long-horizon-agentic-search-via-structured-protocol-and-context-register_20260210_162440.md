---
ver: rpa2
title: 'Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context
  Register'
arxiv_id: '2512.20458'
source_url: https://arxiv.org/abs/2512.20458
tags:
- reasoning
- search
- context
- laser
- agentic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Laser introduces a structured symbolic protocol and compact context
  register to stabilize long-horizon agentic search. The protocol organizes agent
  actions into planning, task-solving, and retrospection subspaces, each with explicit
  semantics and deterministic formats, enabling interpretable, traceable reasoning
  and reliable parsing.
---

# Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register

## Quick Facts
- arXiv ID: 2512.20458
- Source URL: https://arxiv.org/abs/2512.20458
- Authors: Shuting Wang; Qiaolin Xia; Vich Wang; Herberttli; Bobsimons; Zhicheng Dou
- Reference count: 7
- Primary result: Structured symbolic protocol and compact context register improve long-horizon agentic search robustness and scalability

## Executive Summary
Laser introduces a structured symbolic protocol and compact context register to stabilize long-horizon agentic search. The protocol organizes agent actions into planning, task-solving, and retrospection subspaces, each with explicit semantics and deterministic formats, enabling interpretable, traceable reasoning and reliable parsing. The context register stores only essential states, avoiding uncontrolled context expansion and noise accumulation. Evaluated on Qwen2.5/3-series models across multi-hop QA benchmarks, Laser consistently outperforms existing baselines under both prompting and fine-tuning settings, demonstrating improved robustness and scalability for complex, long-horizon queries.

## Method Summary
Laser employs a structured symbolic protocol with three action subspaces (planning, task-solving, retrospection) and a compact context register to manage state in long-horizon agentic search. The protocol uses JSON-formatted actions with explicit semantics for reliable parsing, while the register stores essential states (refined intent, planning history, current plan state) to avoid context pollution. The method follows a two-stage loop: holistic planning to construct task DAGs, then proactive solving with iterative action execution. Training uses rejection sampling fine-tuning (RFT) on filtered trajectories from stronger teachers, with deterministic register updates ensuring efficient token reuse.

## Key Results
- Laser achieves higher accuracy and robustness than ReAct and NL-based baselines on multi-hop QA benchmarks
- Context register enables consistent high token cache ratios and slower context growth over reasoning turns
- Retrospection actions (particularly replanning) are triggered more frequently on complex queries, improving solution quality

## Why This Works (Mechanism)

### Mechanism 1: Tripartite Action Space Decomposition
Partitioning agent behaviors into planning, task-solving, and retrospection subspaces with deterministic formats enables reliable parsing and reduces reasoning drift. Each action is a JSON object with explicit semantics (e.g., `<problem_framing>`, `<task_answer>`, `<revisit_task>`). The symbolic protocol constrains the action space to A = A_plan ∪ A_sol ∪ A_ret, allowing deterministic code-based parsing rather than fragile generative extraction.

### Mechanism 2: Context Register as State Surrogate
A slot-based register storing only essential states (refined intent, planning history, current plan state) mitigates context pollution and enables longer reasoning horizons. Register R_t = {I, P_his, P_cur} replaces raw interaction logs with structured state. Updates are purely deterministic (no LLM inference): R_t = U(R_{t-1}, a_t).

### Mechanism 3: Explicit Retrospection for Error Correction
Dedicated replanning and revisit-task actions enable systematic error recovery, with replanning triggered more frequently when initial task decomposition is flawed. Retrospection space provides `<revisit_task>` for task-level correction and `<replanning>` for plan-level reconstruction.

## Foundational Learning

- Concept: **Directed Acyclic Graph (DAG) for Task Decomposition**
  - Why needed here: Problem framing constructs a DAG where nodes are sub-tasks and edges encode dependencies. Understanding DAG traversal is essential for comprehending execution order.
  - Quick check question: Can you explain why a DAG (vs. a tree or linear sequence) is appropriate for multi-hop QA with potentially shared sub-task dependencies?

- Concept: **Context Window and Attention Dilution**
  - Why needed here: The paper's central problem is context pollution—critical information being obscured by noise in long reasoning traces.
  - Quick check question: What happens to an LLM's attention distribution when the context window is filled with redundant natural-language reasoning traces?

- Concept: **Rejection Sampling Fine-Tuning (RFT)**
  - Why needed here: Laser's optimized version uses RFT to train student models on filtered trajectories from stronger teachers.
  - Quick check question: Why does RFT require both (1) correct final answers AND (2) valid structured output schemas for training sample inclusion?

## Architecture Onboarding

- Component map:
  - Action Spaces: Planning (intent_refinement, problem_framing) → Task-solving (tool_call, doc_extraction, task_answer, final_answer) → Retrospection (revisit_task, replanning)
  - Context Register: Three slots—Refined Intent (I), Planning History (P_his: archived DAGs), Current Plan State (P_cur: active DAG, retry records V_his, tool logs L_tool)
  - Action Parser: Deterministic Python code parsing JSON action outputs

- Critical path:
  1. User query → Intent refinement (I = M_θ(p_h, q))
  2. Problem framing → DAG construction (G = M_θ(p_h, q, I))
  3. Register initialization (R_0 = C(I, G))
  4. Iterative solving loop: a_t = M_θ(p_s, R_{t-1}, q) → R_t = U(R_{t-1}, a_t)
  5. Final answer generation when all tasks solved

- Design tradeoffs:
  - **Structured vs. flexible**: Deterministic formats enable reliable parsing but constrain natural exploration
  - **Compression vs. fidelity**: Register abstracts state but may lose nuanced context
  - **Retrospection overhead**: Correction mechanisms add complexity but improve robustness on complex queries

- Failure signatures:
  - Action parsing errors (model generates malformed JSON)
  - Infinite replanning loops (model cannot escape flawed DAG)
  - Context register corruption (essential state not properly updated)
  - Premature final answers (tasks marked solved without sufficient evidence)

- First 3 experiments:
  1. **Baseline comparison**: Run Laser vs. ReAct on Bamboogle (2-hop questions) with identical retrieval settings; measure ACC and context length at turn 20
  2. **Ablation sweep**: Disable each retrospection action sequentially; quantify performance drop on BrowseComp-ZH
  3. **Context growth analysis**: Plot input token length over reasoning turns for Laser vs. NL-based baselines; compute average cache ratio to verify prefix reuse efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does Laser maintain its effectiveness when applied to non-Qwen model architectures?
- Basis in paper: [explicit] The authors restrict evaluation to Qwen2.5-7B and Qwen3-8B/32B models.
- Why unresolved: It is unclear if the symbolic protocol relies on specific instruction-following tendencies unique to the Qwen series.
- What evidence would resolve it: Benchmark results on Llama-3 or Mistral models using the same prompting protocol.

### Open Question 2
- Question: Can the action space be generalized to agentic tasks beyond multi-hop QA?
- Basis in paper: [explicit] The conclusion suggests Laser provides a foundation for "future reasoning-centric agents."
- Why unresolved: The current actions (e.g., "doc_extraction") are search-specific; utility in coding or mathematical reasoning is unknown.
- What evidence would resolve it: Application of the protocol to non-search benchmarks like HumanEval or MATH.

### Open Question 3
- Question: Does the rigid structure introduce latency overhead that offsets context efficiency?
- Basis in paper: [inferred] The paper highlights token reduction (Fig 5) but does not analyze wall-clock time or inference cost.
- Why unresolved: Generating strict JSON and managing the multi-stage loop might be slower than free-text reasoning.
- What evidence would resolve it: Latency measurements (seconds per query) comparing Laser against ReAct baselines.

## Limitations

- The deterministic parsing of JSON actions assumes near-perfect instruction-following without error-handling mechanisms
- Register-based state abstraction may not capture nuanced context in highly interdependent tasks
- Retrospection effectiveness relies on the model's ability to self-diagnose reasoning failures without empirical validation

## Confidence

- **High Confidence**: Structured protocol design and action space decomposition
- **Medium Confidence**: Context register effectiveness and token cache ratios
- **Low Confidence**: Retrospection mechanisms and error recovery claims

## Next Checks

1. **Error Handling Robustness**: Implement and test a comprehensive error recovery pipeline for malformed JSON actions and register corruption scenarios.
2. **State Compression Validation**: Conduct ablation studies varying register abstraction levels to quantify information loss vs. context efficiency tradeoffs.
3. **Retrospection Trigger Analysis**: Log and analyze all retrospection events with human-labeled reasoning quality scores to validate self-correction effectiveness.