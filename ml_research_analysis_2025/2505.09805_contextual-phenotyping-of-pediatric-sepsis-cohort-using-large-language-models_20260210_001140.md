---
ver: rpa2
title: Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models
arxiv_id: '2505.09805'
source_url: https://arxiv.org/abs/2505.09805
tags:
- clustering
- cluster
- p-value
- data
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that large language models (LLMs) can effectively
  cluster pediatric sepsis patients into clinically meaningful subgroups by converting
  mixed numerical and categorical EHR data into text embeddings. Using a dataset of
  2,686 pediatric records from Uganda, the authors compared LLM-based embeddings (Llama
  3.1 8B, DeepSeek-R1-Distill-Llama-8B, and Stella-En-400M-V5) against classical methods
  (UMAP and FAMD with K-Medoids).
---

# Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models

## Quick Facts
- arXiv ID: 2505.09805
- Source URL: https://arxiv.org/abs/2505.09805
- Reference count: 40
- Primary result: LLM-based embeddings (especially Stella-En-400M-V5) outperform classical methods for clustering pediatric sepsis patients into clinically meaningful subgroups.

## Executive Summary
This study evaluates the use of large language models (LLMs) for phenotyping pediatric sepsis patients by clustering mixed numerical and categorical EHR data into clinically meaningful subgroups. Using a synthetic dataset based on Ugandan pediatric sepsis records, the authors compare LLM-generated embeddings (Llama 3.1 8B, DeepSeek-R1-Distill-Llama-8B, Stella-En-400M-V5) against classical methods (UMAP and FAMD with K-Medoids). The Stella-En-400M-V5 model achieved the highest silhouette score of 0.86, while LLM-based approaches consistently outperformed classical methods, especially at higher cluster counts. The LLM-generated clusters revealed distinct patient subgroups characterized by differences in nutritional status, clinical severity, and socioeconomic factors, with Cluster 1 showing the highest mortality rate and poorest outcomes.

## Method Summary
The authors developed a pipeline to cluster pediatric sepsis patients by first serializing each patient record (28 numerical + 119 categorical features) into text format, then generating embeddings using three LLM architectures: Llama 3.1 8B, DeepSeek-R1-Distill-Llama-8B, and Stella-En-400M-V5. These embeddings were created both with and without a clustering objective appended to the input text. The resulting embeddings were clustered using K-means for k=2-9 clusters, with performance evaluated using silhouette scores. For comparison, classical methods (UMAP and FAMD dimensionality reduction followed by K-Medoids clustering) were applied to the same dataset. The synthetic dataset was generated from an original Ugandan cohort using the CART method via the synthpop R package.

## Key Results
- Stella-En-400M-V5 achieved the highest silhouette score of 0.86, outperforming all other methods.
- LLM-based embeddings consistently outperformed classical methods (UMAP/FAMD + K-Medoids) across all cluster counts.
- LLM-generated clusters revealed clinically distinct subgroups with significant differences in nutritional status, clinical severity, and mortality rates.
- Cluster 1 (identified by LLMs) showed the highest mortality rate (7.4%) and poorest outcomes compared to other clusters.

## Why This Works (Mechanism)
LLMs can effectively process mixed numerical and categorical EHR data by converting it into semantically rich text embeddings that capture complex relationships between clinical features. The clustering objective prompt guides the model to prioritize features indicative of critical conditions, enhancing the clinical relevance of the resulting clusters. By treating the entire patient record as a unified text input, LLMs can identify subtle patterns and correlations that traditional statistical methods might miss, particularly in high-dimensional mixed-type data common in EHRs.

## Foundational Learning
- **EHR serialization for LLMs**: Converting structured medical records into text format is essential for leveraging LLM embeddings; quick check: verify that all features are preserved in serialized format without information loss.
- **Embedding dimensionality selection**: 4096-dim for large models vs 1024-dim for sentence transformers affects clustering granularity; quick check: test clustering performance across different embedding dimensions.
- **Mixed data dimensionality reduction**: UMAP and FAMD handle numerical and categorical features differently; quick check: validate that categorical features maintain their discrete nature through reduction.
- **Quantization for efficiency**: 4-bit quantization via unsloth reduces memory requirements for 8B models; quick check: monitor GPU memory usage during inference.
- **Clustering evaluation metrics**: Silhouette score measures cluster separation and cohesion; quick check: verify silhouette scores are calculated correctly using scikit-learn.
- **Clinical validation of clusters**: Statistical tests (Kruskal-Wallis, chi-square) with Bonferroni correction validate cluster distinctiveness; quick check: ensure p-values are appropriately adjusted for multiple comparisons.

## Architecture Onboarding

**Component map:**
EHR records -> Text serialization -> LLM embedding generation -> K-means clustering -> Silhouette evaluation -> Clinical validation

**Critical path:**
Text serialization → LLM embedding → K-means clustering → Silhouette score calculation

**Design tradeoffs:**
- **Model size vs efficiency**: 8B models provide rich embeddings but require quantization (4-bit) and LoRA adapters for practical deployment
- **Embedding dimensionality**: Higher dimensions (4096) capture more nuance but increase computational cost vs 1024-dim embeddings
- **Serialization format**: Different text templates may affect semantic preservation in embeddings
- **Clustering method**: K-means chosen for speed vs alternatives like hierarchical clustering

**Failure signatures:**
- Low silhouette scores across all methods suggest fundamental data quality issues or inappropriate clustering parameters
- Memory errors during embedding generation indicate insufficient GPU resources or improper quantization setup
- Inconsistent cluster membership across runs suggests poor embedding stability or need for deterministic settings
- Statistical tests showing no cluster differences indicate either over-clustering or lack of meaningful variation in the data

**Exactly 3 first experiments:**
1. Test alternative text serialization templates (JSON-like vs. plain key:value) and measure embedding stability and clustering performance
2. Compare K-means clustering results using embeddings with and without the clustering objective prompt appended
3. Run baseline UMAP+FAMD+K-Medoids pipeline with different hyperparameter settings (n_neighbors, min_dist, number of components) to establish performance floor

## Open Questions the Paper Calls Out
**Open Question 1:** Can LLM-based phenotyping pipelines be optimized for computational efficiency to enable real-time use in resource-limited clinical settings? The authors note that "further work is needed to optimize model efficiency" and that "high computational requirements" may limit adoption, despite using quantization and mini-batch processing.

**Open Question 2:** How can the "black-box" nature of LLM-derived clusters be interpreted to ensure clinical transparency and trust? The study validated clusters statistically but did not integrate explainable AI methods to help clinicians understand why specific patients were grouped together, identifying this as a barrier to clinical acceptance.

**Open Question 3:** Do the phenotypes identified in synthetic data persist and retain the same clinical associations when applied to real-world patient data? Since the analysis used a synthetic dataset generated via CART methods, there's uncertainty about whether the high performance metrics (e.g., silhouette score of 0.86) would translate to the original prospective cohort data with its real-world noise and complexity.

## Limitations
- The study relies on synthetic data generated via CART from an original Uganda cohort, introducing uncertainty about real-world generalizability
- The exact serialization template for mixed-type EHR records into text is unspecified, which critically affects embedding quality
- The computational cost of fine-tuning 8B models via LoRA, even with quantization, remains substantial for resource-limited settings
- The interpretability of LLM-generated clusters is limited, as the models act as black boxes without clear feature attribution for clinical decision-making

## Confidence

**High confidence:** LLMs can outperform classical methods (UMAP/FAMD+K-Medoids) for clustering mixed-type EHR data into phenotypically distinct subgroups.

**Medium confidence:** Stella-En-400M-V5 specifically achieved the highest silhouette score (0.86) and revealed clinically meaningful mortality patterns.

**Low confidence:** The synthetic dataset accurately represents real pediatric sepsis heterogeneity in resource-limited settings.

## Next Checks
1. Validate the serialization template by testing alternative formats (JSON-like vs. plain key:value concatenation) and measuring embedding stability across formats.
2. Replicate clustering on real-world pediatric sepsis EHR data from Uganda to assess external validity and clinical utility of discovered subgroups.
3. Conduct ablation studies comparing LLM embeddings with and without the clustering objective prompt to quantify the objective's impact on phenotyping quality.