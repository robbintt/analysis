---
ver: rpa2
title: The Sample Complexity of Online Strategic Decision Making with Information
  Asymmetry and Knowledge Transportability
arxiv_id: '2506.09940'
source_url: https://arxiv.org/abs/2506.09940
tags:
- learning
- function
- strategic
- knowledge
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses online strategic decision making under information
  asymmetry and knowledge transportability, motivated by multi-agent systems where
  agents act strategically based on private information. The authors propose a model-based
  algorithm that leverages nonparametric instrumental variables (NPIV) to handle confounding
  from unobserved agent types while enabling knowledge transfer between source and
  target populations.
---

# The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability

## Quick Facts
- arXiv ID: 2506.09940
- Source URL: https://arxiv.org/abs/2506.09940
- Reference count: 40
- Primary result: Achieves ε-optimal policy with sample complexity Õ(1/ε²) under information asymmetry and knowledge transfer

## Executive Summary
This paper addresses online strategic decision making when agents have private information that confounds the principal's observations. The authors propose a model-based algorithm using nonparametric instrumental variables (NPIV) to handle confounding from unobserved agent types while enabling knowledge transfer between source and target populations. The method constructs confidence sets for rewards and transitions using minimax estimation and applies optimistic planning under the target distribution. The algorithm achieves an ε-optimal policy with sample complexity Õ(1/ε²), which is tight up to logarithmic factors.

## Method Summary
The algorithm leverages principal's state-action pairs as instrumental variables to bypass confounding from agents' private information. It uses minimax estimation with discriminator function classes to handle the intractability of conditional moment constraints in online settings. The method constructs high-probability confidence sets using source data while applying optimistic planning with respect to the target population distribution. The approach separates estimation (using source distribution Ps) from exploration (using target distribution Pt) and achieves tight sample complexity bounds that depend on problem-specific parameters like ill-posedness and knowledge transfer difficulty.

## Key Results
- Achieves ε-optimal policy with sample complexity Õ(1/ε²), tight up to logarithmic factors
- Successfully handles confounding from unobserved agent types using NPIV
- Enables sample-efficient knowledge transfer between source and target populations
- Identifies conditions for causal identification under non-i.i.d. data
- Characterizes impact of distributional shift through multiplicative transfer term

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The algorithm recovers system dynamics despite unobserved confounding by treating principal's state-action pairs as instrumental variables.
- **Mechanism:** Principal's actions (sh, ah) influence agent feedback (eh) but are conditionally independent of endogenous noise (ξh) from private type (th). By satisfying conditional moment equation E[r_h - R*(s_h, a_h, e_h) | s_h, a_h] = 0, the method isolates causal effect of feedback on reward/transition, filtering spurious correlation with private type.
- **Core assumption:** Principal's state-action pairs are valid instruments (relevant and exogenous), and noise ξh is zero-mean conditioned on these instruments.
- **Break condition:** If principal's actions become correlated with agent's private type (e.g., agent can anticipate action and pre-emptively bias noise), exclusion restriction fails and instrument is invalid.

### Mechanism 2
- **Claim:** The algorithm estimates underlying model using minimax formulation to handle intractability of conditional moment constraints in online setting.
- **Mechanism:** Standard least-squares regression on conditional expectation E[Y|X] is intractable due to nested expectation. Method transforms this into saddle-point problem using discriminator function class F. Minimizes empirical risk over model class while maximizing over discriminators to enforce moment condition, utilizing Fenchel-Rockafellar duality.
- **Core assumption:** Discriminator function class F is sufficiently expressive (realizable) to capture projection of error terms onto instrumental variable space.
- **Break condition:** If discriminator class F is too small (under-realizable), moment conditions cannot be adequately enforced, leading to biased estimates.

### Mechanism 3
- **Claim:** The algorithm achieves sample-efficient knowledge transfer by constructing confidence sets using source data and performing optimistic planning with respect to target population distribution.
- **Mechanism:** Algorithm separates estimation from planning. Estimates model parameters using data sampled from source distribution Ps but aggregates model (computes expectations) using target distribution Pt. Selects policy that maximizes value under most optimistic plausible model within high-probability confidence set.
- **Core assumption:** "Knowledge transfer multiplicative term" (Cf), representing density ratio between target and source distributions, is finite. This implies source distribution provides sufficient coverage of target distribution.
- **Break condition:** If source distribution has very low density where target distribution is high (large distributional shift), term Cf explodes, causing sample complexity bounds to become vacuous.

## Foundational Learning

- **Concept: Nonparametric Instrumental Variables (NPIV)**
  - **Why needed here:** Essential to understand how paper resolves "chicken-and-egg" problem of learning when input data (agent feedback) is corrupted by very thing trying to infer (agent type).
  - **Quick check question:** Can you explain why standard regression fails when input variable is correlated with error term, and how instrument variable breaks this correlation?

- **Concept: Martingale Concentration (Freedman's Inequality)**
  - **Why needed here:** Unlike offline RL with i.i.d. datasets, this online setting generates data sequentially where current action depends on history. Standard concentration bounds (like Hoeffding's) do not apply.
  - **Quick check question:** How does Freedman's inequality differ from Hoeffding's inequality in its treatment of variance and dependence?

- **Concept: Distributional Eluder Dimension**
  - **Why needed here:** Measures complexity of function class (how many "independent" directions of exploration exist). Determines linear term in sample complexity, scaling with problem difficulty rather than just state space size.
  - **Quick check question:** Why is Eluder dimension preferred over standard complexity measures like VC-dimension when analyzing exploration-exploitation trade-off in RL?

## Architecture Onboarding

- **Component map:** Interaction Module -> NPIV Estimator -> Confidence Set Constructor -> Transfer Aggregator -> Optimistic Planner
- **Critical path:**
  1. Collect non-i.i.d. samples from Ps
  2. Update confidence sets Ck using NPIV risk estimates
  3. Aggregate models using Pt
  4. Compute optimistic policy for next round
- **Design tradeoffs:**
  - Source vs. Target Distribution: System must know target distribution Pt (or density ratio) prior to learning. If Pt is unknown, transfer mechanism stalls.
  - Discriminator Capacity: Increasing size/complexity of discriminator class F reduces estimation bias but increases logarithmic term in sample complexity (log |F|).
- **Failure signatures:**
  - Exploding Confidence Intervals: If ill-posedness measure τh is high (weak instruments), confidence sets remain large, preventing convergence to ε-optimal policy.
  - Covariate Shift Failure: If algorithm explores regions irrelevant to target distribution (low Cf overlap), regret bounds degrade.
- **First 3 experiments:**
  1. Linear MDP Validation: Implement algorithm on synthetic linear MDP with known confounders. Verify sample complexity scales as Õ(d/ε²) and matches lower bounds, ensuring NPIV implementation is correct.
  2. Stress Test for Transfer: Create "hard" transfer scenario where source and target distributions have minimal overlap (high Cf). Demonstrate performance drop compared to "soft" transfer scenario.
  3. Instrument Strength Analysis: Vary correlation between agent's private type and feedback to artificially adjust "ill-posedness" τh. Measure resulting increase in sample complexity to validate theoretical linear dependence on τh.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the NPIV-based approach for handling confounding be extended to partially observable Markov decision processes (POMDPs)?
- **Basis in paper:** The authors state: "Is it possible to solve reinforcement learning problems with confounding issues under partially observable Markov decision processes (POMDPs)?"
- **Why unresolved:** Current algorithm assumes full state observability. POMDPs introduce additional latent structure beyond agent private types, potentially complicating causal identification.
- **What evidence would resolve it:** Algorithm with provable sample complexity guarantees for POMDPs with strategic agents, or formal impossibility result.

### Open Question 2
- **Question:** Does the NPIV method remain valid and sample-efficient when combined with value bridge functions for confounded POMDPs?
- **Basis in paper:** The authors ask: "Is the NPIV method still valid with value bridge functions?"
- **Why unresolved:** Value bridge functions (from Shi et al., 2021; Uehara et al., 2022a) are different approach to handling confounding; their compatibility with NPIV techniques is unknown.
- **What evidence would resolve it:** Theoretical analysis establishing whether NPIV and bridge function approaches can be unified, with sample complexity bounds.

### Open Question 3
- **Question:** What are the lower bounds on sample complexity with respect to problem-dependent parameters like ill-posedness measure τh and distributional Eluder dimension?
- **Basis in paper:** Remark 5.6 states: "The dependence of lower bounds on problem-dependent parameters is of independent interest, and we leave it as a future research avenue."
- **Why unresolved:** Paper provides upper bounds matching 1/ε² rate but does not establish whether dependence on τh, Cf_h, and dV,h is tight.
- **What evidence would resolve it:** Lower bound constructions showing necessity of these parameters, or improved upper bounds with different dependencies.

### Open Question 4
- **Question:** Can the algorithm be modified to handle settings where target distribution Pt and/or feedback manipulation distribution F are unknown to the principal?
- **Basis in paper:** Section 6 acknowledges this as limitation: "it requires the target distribution Pt and the feedback manipulation distribution F to be known to the principal."
- **Why unresolved:** Current algorithm requires these as inputs for knowledge transfer; estimating them from limited target population samples may affect sample complexity.
- **What evidence would resolve it:** Algorithm that learns Pt and/or F online while maintaining sample efficiency, with analysis of additional cost.

## Limitations

- Algorithm requires explicit knowledge of target distribution Pt (or density ratio), which may be unavailable in many real-world deployment scenarios.
- Discriminator function class F must satisfy realizability assumptions for convergence, but paper does not provide guidance on how to verify or achieve this in practice.
- Theoretical bounds depend on problem-dependent quantities (ill-posedness τh, transfer term Cf_h) that are not computable from data alone, limiting diagnostic capabilities during implementation.

## Confidence

- **High confidence:** NPIV identification mechanism and separation of estimation from planning are well-supported by theoretical analysis and follow established causal inference principles.
- **Medium confidence:** Sample complexity bounds are tight up to logarithmic factors, but practical impact of ill-posedness and distributional shift depends heavily on problem structure not captured in theoretical analysis.
- **Low confidence:** Minimax optimization procedure for general function classes lacks implementation details, and paper's experimental validation is limited to linear MDPs.

## Next Checks

1. **Instrument Validity Test:** Implement stress test where principal's actions become partially correlated with agent private types. Measure breakdown point where exclusion restriction fails and NPIV estimation degrades.

2. **Transfer Robustness Evaluation:** Create synthetic scenarios with varying degrees of source-target distributional overlap. Quantify relationship between density ratio Cf and actual sample complexity observed in practice.

3. **Discriminator Class Sensitivity:** Systematically vary capacity of discriminator function class F and measure trade-off between estimation bias and variance in learned policies.