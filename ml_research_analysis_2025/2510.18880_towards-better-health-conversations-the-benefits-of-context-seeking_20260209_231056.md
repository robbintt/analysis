---
ver: rpa2
title: 'Towards Better Health Conversations: The Benefits of Context-seeking'
arxiv_id: '2510.18880'
source_url: https://arxiv.org/abs/2510.18880
tags:
- questions
- health
- user
- information
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors explore how people engage with large language models\
  \ for health information seeking, particularly the role of context-seeking. Through\
  \ four mixed-methods studies with 163 participants, they show that proactive context-seeking\
  \ by LLMs\u2014asking clarifying questions before providing answers\u2014is valued\
  \ by users and improves the perceived helpfulness, relevance, and tailoring of responses."
---

# Towards Better Health Conversations: The Benefits of Context-seeking

## Quick Facts
- arXiv ID: 2510.18880
- Source URL: https://arxiv.org/abs/2510.18880
- Reference count: 40
- Primary result: Context-seeking by LLMs improves perceived helpfulness and relevance of health information

## Executive Summary
This paper investigates how large language models can improve health information seeking through context-seeking dialogue. The authors conducted four mixed-methods studies with 163 participants to examine whether LLMs that proactively ask clarifying questions before providing answers are more effective than those that don't. Their Wayfinding AI system demonstrates that context-seeking significantly improves user perceptions of helpfulness, relevance, and tailoring of health information responses. The research highlights the importance of conversational design in health AI systems and provides actionable design patterns for future implementations.

## Method Summary
The authors conducted four mixed-methods studies using the Wayfinding AI system. Participants were recruited through Prolific and engaged in simulated health information seeking scenarios. The studies employed randomized, blinded comparisons between the context-seeking Wayfinding AI and baseline AI systems. Multiple experimental conditions tested different aspects of context-seeking behavior, including timing, question types, and response patterns. Data collection included both quantitative ratings of helpfulness and qualitative feedback through interviews and open-ended responses.

## Key Results
- Participants rated the Wayfinding AI as significantly more helpful and relevant than baseline AI systems
- Context-seeking improved perceived tailoring of responses to individual needs
- Users valued conversational approaches that established context before providing health information
- Design patterns emerged for effective context-seeking in health AI conversations

## Why This Works (Mechanism)
Context-seeking works because it mirrors effective human-to-human health communication patterns. By establishing shared understanding before providing information, the AI can better match responses to user needs and reduce the likelihood of irrelevant or overwhelming information. This approach addresses the challenge that health information seeking often involves complex, context-dependent queries where users may not know exactly what information they need.

## Foundational Learning
- **Health Information Complexity**: Health queries often involve multiple contextual factors (why needed, user background, specific concerns) - needed to understand why simple Q&A fails in health contexts, quick check: can users articulate all relevant context upfront?
- **Conversational AI Design**: Context-seeking requires balancing question depth with user burden - needed to avoid overwhelming users while gathering sufficient information, quick check: does context-seeking increase completion rates?
- **User Trust in AI Health Systems**: Users need to feel understood before trusting health information - needed to explain why context-seeking improves perceived helpfulness, quick check: does context-seeking correlate with trust scores?

## Architecture Onboarding
- **Component Map**: User Input -> Context Extraction -> Clarifying Questions -> Information Retrieval -> Response Generation -> User Feedback
- **Critical Path**: The sequence from user query through context-seeking to tailored response generation represents the core value proposition
- **Design Tradeoffs**: More context-seeking questions improve tailoring but may increase cognitive load and reduce engagement
- **Failure Signatures**: Over-questioning leads to user drop-off; insufficient context leads to irrelevant responses
- **3 First Experiments**: 1) Test different numbers of clarifying questions on completion rates, 2) Measure accuracy of context extraction algorithms, 3) Compare open-ended vs structured context questions

## Open Questions the Paper Calls Out
None

## Limitations
- Sample size of 163 participants may limit generalizability
- Prolific recruitment may introduce demographic selection bias
- Studies focused on lay users without extensive health knowledge
- Limited testing with users having chronic conditions or medical professionals

## Confidence
- High confidence: Users prefer conversational AI that engages in context-seeking dialogue
- Medium confidence: Specific quantitative improvements in helpfulness and relevance scores
- Medium confidence: Generalizability of design recommendations across different health AI implementations

## Next Checks
1. Conduct longitudinal studies with larger, more diverse samples to assess persistence of context-seeking benefits
2. Test Wayfinding AI approach with actual health outcomes rather than just perceived helpfulness
3. Implement A/B testing with real-world health information seekers in naturalistic settings