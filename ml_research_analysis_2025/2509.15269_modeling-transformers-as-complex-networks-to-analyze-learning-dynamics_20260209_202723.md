---
ver: rpa2
title: Modeling Transformers as complex networks to analyze learning dynamics
arxiv_id: '2509.15269'
source_url: https://arxiv.org/abs/2509.15269
tags:
- network
- components
- training
- graph
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using Complex Network Theory to analyze the
  learning dynamics of Large Language Models by modeling the Transformer architecture
  as a directed, weighted graph where nodes represent computational components (attention
  heads and MLPs) and edges represent causal influence between them. The author constructs
  these component-level graphs across 143 training checkpoints of a Pythia-14M model
  on an induction task using an intervention-based ablation technique to measure causal
  influence.
---

# Modeling Transformers as complex networks to analyze learning dynamics

## Quick Facts
- arXiv ID: 2509.15269
- Source URL: https://arxiv.org/abs/2509.15269
- Reference count: 3
- Primary result: Transformer learning dynamics can be characterized as the evolution of a component-level causal influence graph

## Executive Summary
This paper proposes using Complex Network Theory to analyze the learning dynamics of Large Language Models by modeling the Transformer architecture as a directed, weighted graph where nodes represent computational components (attention heads and MLPs) and edges represent causal influence between them. The author constructs these component-level graphs across 143 training checkpoints of a Pythia-14M model on an induction task using an intervention-based ablation technique to measure causal influence. Analysis of graph-theoretic metrics reveals the network structure evolves through distinct phases: initial exploration with rapid growth in nodes and edges, consolidation with pruning of less effective components, and refinement with discovery of more efficient circuits. The study identifies a stable hierarchy of information spreader components (early MLPs and embeddings) and dynamic sets of information gatherer and gatekeeper components whose roles reconfigure at key learning junctures. The work demonstrates that a component-level network perspective offers a powerful macroscopic lens for visualizing and understanding the self-organizing principles that drive the formation of functional circuits in LLMs.

## Method Summary
The methodology constructs a directed, weighted graph G=(V,E) where nodes represent computational components (attention heads, MLPs) across 6 layers of a Pythia-14M Transformer. For each training checkpoint, the author measures causal influence between component pairs using an intervention-based ablation technique: a clean forward pass records outputs, then an ablated pass zeros each component's output while recording the downstream effects on other components. Edge weights are computed as 1 minus the cosine similarity between clean and ablated outputs, with edges existing when similarity drops below threshold τ. Graph-theoretic metrics including degree, betweenness centrality, and closeness centrality are computed and tracked across 143 checkpoints to analyze learning dynamics on an induction task.

## Key Results
- Network topology evolves through three correlated phases matching learning progress: exploration → consolidation → refinement
- A stable hierarchy of information spreader components (early MLPs and embeddings) emerges alongside dynamic sets of information gatherer and gatekeeper components
- Component roles reconfigure at key learning junctures (~10k and ~80k training steps), correlating with performance improvements
- The component-level network perspective reveals self-organizing principles driving functional circuit formation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer learning dynamics can be characterized as the evolution of a component-level causal influence graph
- Mechanism: Construct a directed, weighted graph G=(V,E) where nodes are computational components (attention heads, MLPs). For each pair (Ci, Cj), perform two forward passes: (1) clean run recording O_clean_j, (2) ablated run zeroing Ci's output recording O_ablated_j. Edge weight wij = 1 - cosine_similarity(O_clean_j, O_ablated_j). Edges exist when similarity drops below threshold τ.
- Core assumption: Zero-ablation accurately captures functional dependence; cosine similarity meaningfully quantifies output perturbation.
- Evidence anchors:
  - [abstract] "edges represent causal influence, measured via an intervention-based ablation technique"
  - [section 4.1] Details the two-pass methodology with Equation 3: wij = 1 - S(O_clean_j, O_ablated_j)
  - [corpus] Weak direct support; La Malfa et al. (2024) used similar neuron-strength metrics but for CNNs/RNNs, not component-level Transformer graphs.
- Break condition: If ablation causes distributed compensation (other components adjust), single-component intervention may underestimate true influence.

### Mechanism 2
- Claim: Network topology evolves through three correlated phases matching learning progress: exploration → consolidation → refinement.
- Mechanism: Early training (0-20k steps) shows explosive growth in |V| and |E| as model establishes pathways. Consolidation phase prunes less effective components (|V|, |E| decrease). Refinement phase (~60k-80k steps) shows further pruning coinciding with renewed performance gains, indicating efficient circuit discovery.
- Core assumption: Node/edge count changes reflect meaningful computational restructuring, not noise.
- Evidence anchors:
  - [abstract] "network's structure evolves through distinct phases of exploration, consolidation, and refinement"
  - [section 6] Figure 1a,b shows the phase transitions with correct token logit overlaid; notes "initial 'burst' directly correlates with the steep increase in the correct token logit"
  - [corpus] No direct corpus validation of three-phase dynamics in Transformers.
- Break condition: If different tasks induce different phase timing or structure, the three-phase pattern may be task-specific rather than universal.

### Mechanism 3
- Claim: Components differentiate into stable "spreader" hubs (high out-degree) versus dynamic "gatherer" and "gatekeeper" roles (high in-degree/betweenness) that reconfigure at learning junctures.
- Mechanism: Out-degree analysis shows embeddings (emb) and early MLPs (mlp_0) consistently broadcast information. In-degree and betweenness centrality show dynamic reallocation—components like attn.z.2.3, mlp_2, mlp_5 gain/lose prominence at ~10k and ~80k step marks, correlating with learning phase transitions.
- Core assumption: Degree/centrality metrics from CNT capture functional computational roles in neural networks.
- Evidence anchors:
  - [abstract] "stable hierarchy of information spreader components and a dynamic set of information gatherer and gatekeeper components, whose roles reconfigure at key learning junctures"
  - [section 6] Figures 3, 4, 6 show heatmaps of high-centrality components over training; notes "stable core of information gatekeepers" with "dynamic rewiring"
  - [corpus] Scabini and Bruno (2023) showed neuronal centrality correlates with performance in FCNs, supporting role-based analysis.
- Break condition: If threshold τ significantly changes which components appear central, role assignments may be artifacts of graph construction rather than true functional properties.

## Foundational Learning

- Concept: **Residual Stream Communication**
  - Why needed here: All component-to-component influence flows through the residual stream; understanding this highway is essential for interpreting edge semantics.
  - Quick check question: Can you explain why attention head outputs are added (not concatenated) to the residual stream?

- Concept: **Intervention-Based Causal Attribution**
  - Why needed here: The core methodology uses ablation to measure influence; requires understanding what zeroing a component's output means versus other ablation types.
  - Quick check question: What is the difference between zero-ablation and mean-ablation, and when might each be appropriate?

- Concept: **Complex Network Metrics (Degree, Betweenness, Closeness)**
  - Why needed here: The paper's conclusions rely on interpreting these metrics as functional roles (spreader, gatherer, gatekeeper).
  - Quick check question: What does high betweenness centrality indicate about a node's role in information flow?

## Architecture Onboarding

- Component map: emb -> attn_0,1,2,3 -> mlp_0 -> attn_1,1,2,3 -> mlp_1 -> ... -> attn_5,1,2,3 -> mlp_5

- Critical path:
  1. Load checkpoint → 2. Run clean forward pass → 3. For each component pair (Ci, Cj), run ablated pass → 4. Compute cosine similarity → 5. Apply threshold τ → 6. Build graph → 7. Compute CNT metrics → 8. Track evolution across checkpoints.

- Design tradeoffs:
  - **Threshold τ**: Lower τ → sparser graph (only strong edges); higher τ → denser graph (more noise). Paper uses τ=0.7 as "sweet spot" for visualization.
  - **Zero-ablation vs alternatives**: Zero-ablation may overestimate importance for components with non-zero mean activation; mean-ablation or resampling alternatives not explored.
  - **Single input vs dataset**: Using one induction sentence provides specificity but limits generalizability.

- Failure signatures:
  - **Component saturation**: Excessively high subgraph centrality (per Scabini and Bruno 2023) correlates with poor performance.
  - **Static role assignment**: If gatherer/gatekeeper roles don't reconfigure, model may be stuck in suboptimal circuit configuration.
  - **No phase transitions**: Absence of growth/pruning phases may indicate learning failure or task incompatibility.

- First 3 experiments:
  1. **Threshold sensitivity analysis**: Reconstruct graphs at τ ∈ {0.3, 0.5, 0.7, 0.9} and verify that identified phases and role assignments are qualitatively consistent.
  2. **Cross-task comparison**: Apply the same pipeline to a different task (e.g., factual recall) on the same checkpoints to test whether spreader/gatherer roles are task-specific or universal.
  3. **Ablation method comparison**: Compare zero-ablation edges vs mean-ablation edges for a subset of checkpoints to quantify sensitivity to intervention choice.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do different tasks (e.g., factual recall, translation) induce the formation of structurally distinct component networks?
- Basis in paper: [explicit] The author states, "It remains an open question whether different tasks... would induce the formation of structurally distinct networks."
- Why unresolved: The study was restricted to analyzing a single canonical induction task.
- What evidence would resolve it: A comparative analysis of graph-theoretic metrics derived from the same model performing distinct tasks.

### Open Question 2
- Question: How robust are the identified network structures when calculated over a diverse dataset rather than a single input?
- Basis in paper: [explicit] The paper notes the graph was constructed using a single sentence and "the graph structure is likely dependent on the input tokens."
- Why unresolved: Causal influence was measured on one specific text, potentially capturing idiosyncratic activation patterns rather than general circuitry.
- What evidence would resolve it: Constructing graphs using averaged influence scores across a representative corpus of input data.

### Open Question 3
- Question: How does the choice of ablation technique (e.g., zero-ablation vs. resampling) alter the derived causal influence and network topology?
- Basis in paper: [explicit] The author acknowledges that "zero-ablation is one of several possible intervention strategies" and others "could yield different insights."
- Why unresolved: Different ablation methods may result in varying noise levels or different causal attributions for the same components.
- What evidence would resolve it: A comparison of graph structures generated using mean-ablation, resampling, and zero-ablation on the same checkpoints.

## Limitations
- **Component Output Definition**: The paper does not specify whether the "output" O_j used for cosine similarity includes the full residual stream after a component's operation or only the component's contribution vector.
- **Single-component Ablation**: The methodology applies single-component ablation but doesn't explore whether multi-component ablations reveal different influence patterns.
- **Threshold Sensitivity**: The claim of a "sweet spot" at τ=0.7 is qualitative rather than rigorously justified through systematic analysis.

## Confidence
- **High Confidence**: The general framework of modeling Transformer components as a graph with intervention-based edge weights is methodologically sound. The identification of phase transitions through network metrics is supported by visualizations.
- **Medium Confidence**: The interpretation of degree/centrality metrics as functional roles (spreader, gatherer, gatekeeper) requires assuming that Complex Network Theory metrics directly map to computational roles in neural networks.
- **Low Confidence**: The universality of the three-phase learning dynamics across different tasks or model architectures is asserted but not tested.

## Next Checks
1. **Cross-task Role Stability**: Apply the component-level graph methodology to Pythia checkpoints trained on a different task (e.g., factual recall or language modeling on a different corpus). Compare whether the same components consistently emerge as spreaders/gatherers across tasks, or if roles are task-specific.

2. **Multi-component Ablation Sensitivity**: For a subset of checkpoints, implement joint ablations of 2-3 components simultaneously and compare the resulting edge weight distributions against single-component ablations. This tests whether the current edge weights capture the full influence structure.

3. **Temporal Phase Robustness**: Systematically vary the threshold τ across the full range (0.1-1.0) and document how the timing and characteristics of the three identified phases change. This validates whether phase transitions are robust features or threshold-dependent artifacts.