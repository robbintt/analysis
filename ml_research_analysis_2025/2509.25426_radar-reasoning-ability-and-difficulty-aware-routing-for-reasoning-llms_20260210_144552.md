---
ver: rpa2
title: 'RADAR: Reasoning-Ability and Difficulty-Aware Routing for Reasoning LLMs'
arxiv_id: '2509.25426'
source_url: https://arxiv.org/abs/2509.25426
tags:
- reasoning
- performance
- routing
- queries
- cost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of choosing the optimal reasoning
  language model (RLM) configuration for different queries, balancing performance
  and cost across model size and reasoning budget. RADAR introduces a lightweight,
  interpretable, and scalable routing framework that leverages item response theory
  (IRT) to estimate query difficulties and model-budget abilities, then routes queries
  to sufficiently capable configurations.
---

# RADAR: Reasoning-Ability and Difficulty-Aware Routing for Reasoning LLMs

## Quick Facts
- arXiv ID: 2509.25426
- Source URL: https://arxiv.org/abs/2509.25426
- Authors: Nigel Fernandez; Branislav Kveton; Ryan A. Rossi; Andrew S. Lan; Zichao Wang
- Reference count: 40
- Key outcome: Achieves 90% of OpenAI o4-mini performance at 1.31% of its cost on reasoning benchmarks

## Executive Summary
This paper addresses the challenge of selecting optimal reasoning language model (RLM) configurations for different queries, balancing performance and cost across model size and reasoning budget. The authors introduce RADAR, a lightweight, interpretable, and scalable routing framework that uses item response theory (IRT) to estimate query difficulties and model-budget abilities. By formulating routing as a multi-objective optimization problem with scalarization, RADAR efficiently routes queries to sufficiently capable configurations while optimizing the performance-cost tradeoff. Extensive experiments demonstrate that RADAR significantly outperforms state-of-the-art routing methods on 8 challenging reasoning benchmarks.

## Method Summary
RADAR employs item response theory to estimate query difficulties and model-budget abilities, then routes queries based on these estimates through a multi-objective optimization framework. The routing problem is formulated as balancing performance against cost using scalarization techniques to handle the tradeoff. The framework is designed to be lightweight, interpretable, and scalable, enabling efficient routing decisions while maintaining transparency in how queries are assigned to different RLM configurations.

## Key Results
- RADAR achieves 90% of OpenAI o4-mini performance with high reasoning effort
- RADAR operates at only 1.31% of OpenAI o4-mini's cost on reasoning benchmarks
- RADAR significantly outperforms state-of-the-art routing methods across 8 challenging benchmarks

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to accurately estimate query difficulties using IRT and match them with appropriately capable RLM configurations. By treating routing as a multi-objective optimization problem, RADAR can systematically balance the tradeoff between performance and cost. The IRT-based approach provides interpretable estimates of both query characteristics and model capabilities, enabling principled routing decisions that outperform heuristic or learning-based alternatives.

## Foundational Learning
- Item Response Theory (IRT): A psychometric framework for modeling the relationship between latent traits and response patterns; needed for estimating query difficulties and model abilities from performance data
- Multi-objective optimization: Optimization involving multiple conflicting objectives; needed to balance performance-cost tradeoffs in routing decisions
- Scalarization techniques: Methods for converting multi-objective problems into single-objective ones; needed to find optimal tradeoff points between performance and cost
- Reasoning benchmarks: Standardized datasets for evaluating reasoning capabilities; needed to validate routing effectiveness across diverse problem types
- Performance-cost tradeoff: The fundamental tension between computational expense and output quality; needed to optimize resource allocation across RLM configurations

## Architecture Onboarding
- Component map: Query -> IRT Difficulty Estimator -> Model-Budget Ability Estimator -> Multi-Objective Optimizer -> RLM Configuration Selector
- Critical path: Query evaluation → Difficulty estimation → Ability matching → Configuration selection → Response generation
- Design tradeoffs: IRT-based interpretability vs. potential complexity of implementation; accuracy vs. computational overhead in difficulty estimation; routing flexibility vs. configuration management overhead
- Failure signatures: Poor routing decisions when difficulty estimates are inaccurate; suboptimal configurations selected due to imperfect ability modeling; cost overruns from conservative routing
- First experiments: 1) Test IRT parameter estimation accuracy on held-out queries, 2) Validate multi-objective optimization convergence across different scalarization weights, 3) Measure routing accuracy when integrating new RLM configurations

## Open Questions the Paper Calls Out
None

## Limitations
- Routing effectiveness depends on availability of well-curated evaluation datasets for accurate difficulty parameter estimation
- Performance-cost tradeoff optimization assumes linear scalarization which may not capture complex preference structures
- Benchmark-based results may not fully represent real-world query distributions

## Confidence
- Performance Claims (Medium-High): Well-supported by extensive benchmark experiments across 8 datasets with strong empirical evidence
- Generalization Claims (Medium): Good out-of-distribution performance demonstrated but evaluations are relatively limited in scope
- Interpretability Claims (High): IRT-based framework provides theoretically grounded and transparent routing decisions

## Next Checks
1. Conduct ablation studies to quantify contributions of IRT-based difficulty estimation versus other routing components, and test alternative scalarization methods
2. Evaluate RADAR on diverse real-world query distributions beyond curated reasoning benchmarks, including long-tail and adversarial queries
3. Test framework scalability and routing accuracy when integrating RLM configurations with significantly different capabilities or reasoning approaches