---
ver: rpa2
title: 'FedRE: Robust and Effective Federated Learning with Privacy Preference'
arxiv_id: '2505.04889'
source_url: https://arxiv.org/abs/2505.04889
tags:
- privacy
- learning
- data
- federated
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FedRE, a novel federated learning framework
  designed to protect privacy-sensitive information (PSI) while maintaining model
  effectiveness. The key innovation lies in its layer-wise local differential privacy
  mechanism that allocates privacy budgets based on the sensitivity of gradients to
  PSI, rather than applying uniform protection across all data.
---

# FedRE: Robust and Effective Federated Learning with Privacy Preference

## Quick Facts
- arXiv ID: 2505.04889
- Source URL: https://arxiv.org/abs/2505.04889
- Authors: Tianzhe Xiao; Yichen Li; Yu Zhou; Yining Qi; Yi Liu; Wei Wang; Haozhao Wang; Yi Wang; Ruixuan Li
- Reference count: 40
- One-line primary result: Layer-wise local differential privacy mechanism achieves 0.601 IoU on T-SROIE and 0.524 IoU on DocTamper while defending gradient inversion attacks

## Executive Summary
FedRE introduces a novel federated learning framework that protects privacy-sensitive information (PSI) through layer-wise local differential privacy, allocating privacy budgets based on gradient sensitivity rather than uniform protection. The framework computes PSI scores using Jacobian matrices to quantify gradient sensitivity to specific data regions, then perturbs gradients accordingly while employing a novel aggregation mechanism that prioritizes less sensitive updates. Experimental results demonstrate that FedRE achieves competitive performance with IoU scores of 0.601 and 0.524 respectively, outperforming state-of-the-art methods while maintaining strong defense metrics under strict privacy budgets.

## Method Summary
FedRE is a federated learning framework designed to protect PSI regions in document images during collaborative training. The method computes layer-wise PSI scores via Jacobian matrices of gradients with respect to input data in sensitive regions, allocates privacy budgets inversely proportional to sensitivity scores, and adds calibrated Gaussian noise to gradients. The server-side PDA-PAM aggregation mechanism uses a public dataset to evaluate incoming client updates and assigns higher weights to less sensitive gradients, improving model utility while maintaining privacy guarantees.

## Key Results
- Achieves IoU scores of 0.601 on T-SROIE and 0.524 on DocTamper datasets
- Outperforms state-of-the-art methods in both utility (IoU) and defense metrics
- Demonstrates strong performance under strict privacy budgets (ε=10) with MSE improvements of 0.383 and 0.438
- Shows particular strength in defense metrics while maintaining model utility through targeted perturbation

## Why This Works (Mechanism)

### Mechanism 1: Jacobian-Based Sensitivity Quantification
FedRE computes PSI scores for each layer by calculating the Jacobian matrix of the gradient with respect to input data in PSI regions, quantifying how much gradients reveal about sensitive information. This identifies high-risk layers where information leakage is most likely, allowing targeted protection. The mechanism assumes gradient derivative magnitude correlates directly with information encoding in gradients.

### Mechanism 2: Inverse-Proportional Layer-wise Budget Allocation
Instead of uniform privacy budgets, FedRE assigns specific budgets to each layer inversely proportional to its PSI Score. Layers with high sensitivity receive stricter protection through smaller budgets, while less sensitive layers retain more precision. This concentrated approach preserves model utility while effectively obfuscating sensitive information, assuming layer gradients have heterogeneous sensitivity to PSI.

### Mechanism 3: Perturbation Distribution Aware Aggregation (PDA-PAM)
The server uses a public dataset to evaluate PSI scores of incoming client updates, assigning higher aggregation weights to updates with lower sensitivity scores. This prioritizes "cleaner" gradients with less distortion, mitigating performance degradation from aggressive local noise injection. The mechanism assumes the public dataset approximates the sensitivity distribution of private data.

## Foundational Learning

- **Gradient Inversion Attacks (Deep Leakage from Gradients)**: The defense mechanism counters attacks that reconstruct training data from shared gradients. Understanding this threat model explains the need for PSI scores and noise injection.
  - *Quick check*: How does comparing differences between generated pseudo-data and real gradients allow attackers to recover original images?

- **Local Differential Privacy (LDP) & Gaussian Mechanism**: FedRE implements LDP through clipping and Gaussian noise addition. Understanding the relationship between privacy budget (ε), clipping threshold (C), and noise scale (σ) is crucial for interpreting experimental results.
  - *Quick check*: Does a smaller privacy budget ε require larger or smaller noise variance to ensure indistinguishability?

- **Jacobian Matrix in Deep Learning**: The core innovation uses the Jacobian (derivative of gradient w.r.t input) to measure sensitivity. This second-order derivative calculation quantifies how input changes affect gradient outputs.
  - *Quick check*: In this context, does a high Frobenius norm of the Jacobian imply the layer is learning robust features or leaking sensitive information?

## Architecture Onboarding

- **Component map**: Client Side: Input (local data with PSI annotations) -> Process (local training, compute Jacobian/PSI Score, calculate layer-wise budget, clip & perturb gradients) -> Output (perturbed gradients). Server Side: Input (perturbed gradients + Public Dataset) -> Process (compute sensitivity, calculate aggregation weights, aggregate model) -> Output (updated Global Model).

- **Critical path**: Jacobian computation on the client side, which involves second-order derivative calculations (gradient of gradient) with O(FD) complexity, making it computationally expensive and distinct from standard backpropagation.

- **Design tradeoffs**: Utility vs. Defense (lower ε improves defense but lowers accuracy), Efficiency vs. Precision (sampling 10 data points reduces overhead), Clipping Threshold (too small destroys information, too large reduces regularization benefit).

- **Failure signatures**: IoU Collapse (model fails to learn if C_l is too low), Ineffective Defense (gradient inversion attack succeeds if noise multiplier is miscalculated).

- **First 3 experiments**: (1) Sanity Check (No Noise vs. Noise) to verify gradient perturbation preserves utility better than pixel-level perturbation, (2) Ablation on Aggregation (PDA-PAM) to quantify benefits of server-side weighting, (3) Hyperparameter Sensitivity sweep on clipping threshold C to find regularization sweet spot.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can computational efficiency of PSI score calculation be significantly improved by leveraging the sparsity of the Jacobian matrix? The paper states PSI computational efficiency can be enhanced using optimization methods like utilizing Jacobian sparsity, but this remains untested for large-scale scenarios.

- **Open Question 2**: How can sampling strategies for PSI scores be optimized to maintain accuracy in scenarios with high data heterogeneity? The paper highlights the need to explore sampling computation optimization, especially in non-IID data environments where simple sampling averages may not capture statistical variance.

- **Open Question 3**: Is the PDA-PAM aggregation mechanism robust when the server lacks access to a representative public dataset? The mechanism assumes server has public dataset to compute weights, but the paper doesn't validate performance when public data distribution mismatches client data.

## Limitations

- Computational overhead of Jacobian-based PSI score computation remains a practical bottleneck with O(FD) complexity, though sampling mitigation is suggested but not thoroughly validated.
- PDA-PAM aggregation effectiveness critically depends on public dataset quality and distribution match, which introduces variability not fully explored across different scenarios.
- Practical feasibility of Jacobian computation overhead mitigation (sampling 10 points) is asserted but lacks empirical validation across different model architectures and dataset sizes.

## Confidence

- **High Confidence**: Layer-wise budget allocation inversely proportional to PSI scores is well-supported by mathematical formulation and ablation studies showing C_l sensitivity.
- **Medium Confidence**: PDA-PAM aggregation benefits are shown through comparative results, but public dataset dependency introduces variability not thoroughly analyzed.
- **Low Confidence**: Jacobian computation overhead mitigation strategy (sampling 10 points) is asserted but not empirically validated across different contexts.

## Next Checks

1. **Overhead Validation**: Measure actual runtime overhead of full vs. sampled PSI score computation across different model depths and input dimensions to verify claimed efficiency gains.
2. **Public Dataset Sensitivity**: Systematically vary public dataset distribution (in-domain vs. out-of-domain) and measure PDA-PAM effectiveness degradation to establish robustness requirements.
3. **Generalization Test**: Apply FedRE to non-document datasets (e.g., medical imaging with sensitive regions) to assess whether Jacobian sensitivity approach generalizes beyond T-SROIE/DocTamper domain.