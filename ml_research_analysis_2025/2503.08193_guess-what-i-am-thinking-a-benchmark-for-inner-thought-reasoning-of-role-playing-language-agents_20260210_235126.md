---
ver: rpa2
title: 'Guess What I am Thinking: A Benchmark for Inner Thought Reasoning of Role-Playing
  Language Agents'
arxiv_id: '2503.08193'
source_url: https://arxiv.org/abs/2503.08193
tags:
- character
- thought
- thoughts
- characters
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ROLETHINK, a benchmark for evaluating inner
  thought reasoning in role-playing language agents (RPLAs). The benchmark includes
  a Gold Set, which compares generated thoughts with original character monologues,
  and a Silver Set, which uses expert-synthesized character analyses as references.
---

# Guess What I am Thinking: A Benchmark for Inner Thought Reasoning of Role-Playing Language Agents

## Quick Facts
- arXiv ID: 2503.08193
- Source URL: https://arxiv.org/abs/2503.08193
- Reference count: 40
- Key outcome: Introduces ROLETHINK benchmark and MIRROR method for evaluating and generating inner thoughts in role-playing language agents

## Executive Summary
This paper introduces ROLETHINK, a benchmark for evaluating inner thought reasoning in role-playing language agents (RPLAs). The benchmark includes a Gold Set, which compares generated thoughts with original character monologues, and a Silver Set, which uses expert-synthesized character analyses as references. The authors propose MIRROR, a chain-of-thought approach that retrieves memories, predicts character reactions, and synthesizes motivations to generate character inner thoughts. Experiments with various LLMs show that MIRROR consistently outperforms existing methods, achieving higher scores on ROLETHINK. The study demonstrates that enabling RPLAs to generate inner thoughts improves performance across downstream tasks such as decision-making and motivation analysis. The results highlight the importance of structured reasoning in RPLAs and provide insights into character psychological complexity.

## Method Summary
The authors develop ROLETHINK as a comprehensive benchmark for evaluating inner thought reasoning in role-playing language agents. The benchmark consists of two sets: a Gold Set with original character monologues from literary works and a Silver Set with expert-synthesized character analyses. They propose MIRROR, a chain-of-thought approach that leverages memory retrieval, reaction prediction, and motivation synthesis to generate character inner thoughts. The method is evaluated across multiple LLMs and compared against existing approaches using both automatic metrics and human evaluation. The study also demonstrates the impact of inner thought generation on downstream tasks including decision-making and motivation analysis.

## Key Results
- MIRROR approach consistently outperforms existing methods on ROLETHINK benchmark
- Generating inner thoughts improves downstream task performance in decision-making and motivation analysis
- LLMs with inner thought generation capabilities show better understanding of character psychology
- The benchmark reveals significant differences in how various LLMs handle character inner thought reasoning

## Why This Works (Mechanism)
The success of MIRROR stems from its structured approach to inner thought generation, which mimics human cognitive processes by first retrieving relevant memories, then predicting character reactions, and finally synthesizing motivations. This chain-of-thought methodology allows the model to build a coherent internal representation of character psychology before generating thoughts, rather than attempting to produce thoughts directly from context. The dual-reference benchmark design (Gold and Silver sets) provides both objective and expert-validated measures of quality, capturing different aspects of inner thought reasoning. The improvement in downstream tasks suggests that inner thoughts serve as a form of cognitive scaffolding that enhances the agent's overall reasoning capabilities.

## Foundational Learning

**Role-Playing Language Agents (RPLAs)**: AI systems that simulate characters in interactive narratives or dialogues. Needed because they form the target application domain for inner thought generation. Quick check: Can the agent maintain consistent character voice across multiple interactions?

**Chain-of-Thought Reasoning**: A prompting strategy where models generate intermediate reasoning steps before producing final answers. Needed because it provides the structured approach for generating coherent inner thoughts. Quick check: Does the intermediate reasoning improve task performance compared to direct generation?

**Character Psychology Modeling**: The representation and reasoning about fictional characters' mental states, motivations, and behaviors. Needed because inner thoughts are fundamentally about character psychology. Quick check: Can the model distinguish between different character types and their psychological profiles?

**Benchmark Construction**: The systematic creation of evaluation datasets with reference standards. Needed because reliable evaluation is crucial for measuring progress in inner thought generation. Quick check: Do multiple annotators agree on the quality of reference texts?

## Architecture Onboarding

**Component Map**: Literary Context -> Memory Retrieval -> Reaction Prediction -> Motivation Synthesis -> Inner Thought Generation -> Downstream Task Performance

**Critical Path**: The MIRROR approach follows a sequential pipeline where each stage builds upon the previous one: memory retrieval informs reaction prediction, which in turn shapes motivation synthesis, ultimately producing inner thoughts that enhance downstream performance.

**Design Tradeoffs**: The authors balance between using original literary texts (Gold Set) for objective evaluation and expert-synthesized analyses (Silver Set) for nuanced psychological assessment. This dual approach captures both surface-level similarity and deeper psychological plausibility, though it requires significant annotation effort.

**Failure Signatures**: Poor performance occurs when memory retrieval fails to identify relevant context, when reaction prediction is inconsistent with character personality, or when motivation synthesis produces implausible character drives. Models may also struggle with complex multi-character dynamics or non-literary role-playing scenarios.

**First Experiments**:
1. Evaluate MIRROR against baseline direct generation methods on both Gold and Silver sets
2. Test the impact of inner thought generation on decision-making accuracy in role-playing scenarios
3. Compare performance across different LLMs to identify model-specific strengths and weaknesses

## Open Questions the Paper Calls Out
None

## Limitations
- The validation of expert-synthesized character analyses (Silver Set) lacks independent verification of quality and representativeness
- The evaluation focuses primarily on comparison with existing methods rather than establishing absolute quality benchmarks
- The scalability of MIRROR to handle complex multi-character scenarios or non-literary role-playing contexts is not explored

## Confidence
- Effectiveness of ROLETHINK benchmark: Medium (lacks independent validation of Silver Set)
- Claim that inner thoughts improve downstream performance: High (demonstrated through controlled experiments)
- Contribution to understanding character psychological complexity: Medium (focuses on surface similarity rather than deep psychological plausibility)

## Next Checks
1. Conduct a blind evaluation with multiple literary experts to assess the quality and representativeness of the Silver Set character analyses, including inter-rater reliability metrics.

2. Perform ablation studies to determine which components of the MIRROR approach contribute most significantly to performance improvements, and test its scalability with increasingly complex narrative scenarios involving multiple characters.

3. Evaluate the generated inner thoughts using metrics beyond text similarity, such as psychological plausibility scores from domain experts and narrative coherence assessments with target audience feedback.