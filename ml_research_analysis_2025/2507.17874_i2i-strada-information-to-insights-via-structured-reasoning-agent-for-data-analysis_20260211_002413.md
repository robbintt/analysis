---
ver: rpa2
title: I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data
  Analysis
arxiv_id: '2507.17874'
source_url: https://arxiv.org/abs/2507.17874
tags:
- data
- reasoning
- agent
- query
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces I2I-STRADA, an agentic architecture designed\
  \ to formalize structured reasoning in data analysis. Unlike prior systems that\
  \ focus on query translation or visualization, I2I-STRADA models the cognitive workflow\
  \ of analysis\u2014interpreting vague goals, grounding them in context, constructing\
  \ abstract plans, and adapting execution iteratively."
---

# I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis

## Quick Facts
- arXiv ID: 2507.17874
- Source URL: https://arxiv.org/abs/2507.17874
- Authors: SaiBarath Sundar; Pranav Satheesan; Udayaadithya Avadhanam
- Reference count: 31
- Primary result: 80.56% accuracy on easy tasks, 28.04% on hard tasks in DABstep; 90.27% on DABench

## Executive Summary
I2I-STRADA introduces an agentic architecture that formalizes structured reasoning for data analysis tasks. Unlike prior systems focused on query translation or visualization, it models the cognitive workflow of analysis through goal interpretation, contextual grounding, abstract planning, and iterative execution. The system achieves state-of-the-art performance on DABstep and DABench benchmarks, demonstrating robust reasoning capabilities across diverse domains while addressing limitations in prior agents through explicit structured planning and procedural knowledge integration.

## Method Summary
I2I-STRADA employs a modular pipeline using Claude 3.5 Sonnet to process user queries, raw data, SOPs, and instructions. The system extracts intent and constraints through goal construction, grounds analysis using metadata and SOPs via contextual reasoning, generates high-level plans through workflow scaffolding, and iteratively executes Python code in a sandbox with dynamic state management. The architecture includes six components: goal construction, contextual reasoner, workflow scaffolding, adaptive planner/executor, context-aware tool creation, and dynamic state handler. Evaluation uses DABstep (financial/operational tasks with SOPs) and DABench (data science tasks across domains) benchmarks.

## Key Results
- Achieves 80.56% accuracy on easy tasks and 28.04% on hard tasks in DABstep benchmark
- Reaches 90.27% accuracy on DABench using Accuracy by Question metric
- Outperforms state-of-the-art baselines through structured reasoning approach
- Demonstrates robustness across diverse analytical domains

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Planning with Progressive Abstraction
The system decomposes planning into global scaffolding followed by adaptive execution, improving accuracy by aligning high-level strategy with dynamic data interaction. The Workflow Scaffolding module generates a high-level plan $P = \{t_1, t_2, ..., t_n\}$ without data interaction, then the Adaptive Planner iteratively derives and executes fine-grained actions, observing results and updating context. This allows adjustment based on actual intermediate outcomes while maintaining strategic coherence.

### Mechanism 2: Contextual Grounding via Metadata and SOPs
The Contextual Reasoner module bridges initial goal construction with planning by updating beliefs using metadata ($M$) and SOPs ($S$). This grounded belief ensures generated plans respect column names, data types, and procedural rules from the outset, reducing errors from misinterpreted constraints and aligning execution with domain-specific requirements.

### Mechanism 3: Dynamic Tool Creation and State Management
Context-aware tool creation generates Python code snippets on-the-fly using metadata and instructions, while the Dynamic State Handler maintains execution context across iterations. This enables handling heterogeneous data sources and complex multi-step calculations by carrying variable definitions and debugging information from one iteration to the next.

## Foundational Learning

- **Context-Window Management and "Lost-in-the-Middle"**: Why needed: The architecture relies on LLM receiving and prioritizing long context including metadata, SOPs, and execution history. Quick check: Can you explain why simply stuffing all available metadata into the prompt might not work and how the architecture tries to mitigate it?

- **Graph-Based vs. Linear Task Planning**: Why needed: Understanding trade-offs between DFS, graph-based planning, and I2I-STRADA's hybrid approach. Quick check: What are the primary limitations of a Depth-First Search (DFS) planning approach in complex, multi-step data analysis?

- **Iterative Code Execution and Sandboxing**: Why needed: Core of agent's action is writing and executing Python code in sandbox. Quick check: Why is a sandboxed execution environment necessary for an agentic system that generates and runs its own code?

## Architecture Onboarding

- **Component Map**: Input: User Query ($Q$), Raw Data Sources ($D$), SOPs ($S$), Instructions ($I$) -> Offline: Metadata Preparation -> Core Loop: Goal Construction -> Contextual Reasoner -> Workflow Scaffolding -> Adaptive Planning & Execution Loop -> Output: Communication Handler

- **Critical Path**: The sequence from Goal Construction -> Contextual Grounding -> Workflow Scaffolding is critical. If the initial goal is misunderstood or not properly grounded in available data and rules, the entire downstream plan will be flawed.

- **Design Tradeoffs**: Global Plan vs. Flexibility (rigid plan ensures coherence but may struggle with unforeseen data complexities); Complexity vs. Interpretability (more sub-tasks increase complexity but aim for structured reasoning).

- **Failure Signatures**: SOP Misinterpretation (agent fails to correctly apply rule from SOP); Scaffold-Execution Mismatch (adaptive executor gets stuck due to poorly defined scaffolded task); Context Loss (agent "forgets" early step information as context grows).

- **First 3 Experiments**: 
  1. Ablate Contextual Grounding: Run agent without Contextual Reasoner module on DABstep to measure performance delta.
  2. Vary Planner Rigidity: Experiment with allowing Adaptive Planner to request re-scaffold for unexpected results.
  3. Stress-Test State Management: Give agent task requiring >10 iterative steps to observe Dynamic State Handler performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can agents be improved to consistently apply procedural rules (e.g., SOPs) for edge cases like explicit null/None values versus empty lists?
- Basis: Authors state: "The agent seems inconsistent when applying SOP rule related to handling of 'Null' values... when a field is explicitly 'null'/'None', it fails to apply this rule."
- Why unresolved: Inconsistency appears tied to LLM attention mechanisms focusing on single SOP examples.
- What evidence would resolve it: Systematic ablation across null-handling variants with modified SOP phrasing or attention-guiding mechanisms.

### Open Question 2
- Question: Can structured procedural knowledge (SOPs) be leveraged to stabilize hyperparameter selection in machine learning tasks?
- Basis: "When applying machine learning algorithms, the choice of hyperparameters often results in different results. This could be corrected by providing an appropriate procedure document."
- Why unresolved: Paper proposes SOPs as solution but does not implement or evaluate this.
- What evidence would resolve it: Experiments comparing ML task accuracy with and without hyperparameter-specific procedural guidance.

### Open Question 3
- Question: To what extent does I2I-STRADA's structured workflow generalize across different base LLMs?
- Basis: All experiments use Claude 3.5 Sonnet exclusively; no ablation across model families reported.
- Why unresolved: Modular architecture may interact differently with models having varying reasoning capabilities.
- What evidence would resolve it: Benchmark evaluations using identical prompts/workflow across GPT-4o, Gemini, and open-source models.

### Open Question 4
- Question: What architectural improvements could close the large performance gap between easy (80.56%) and hard (28.04%) tasks on DABstep?
- Basis: Dramatic accuracy drop suggests structural limitations in handling increased complexity, multi-step dependencies, or deeper reasoning chains.
- Why unresolved: Paper does not analyze failure modes on hard tasks or propose targeted enhancements.
- What evidence would resolve it: Fine-grained error analysis on hard tasks identifying whether failures stem from planning, execution, or context management.

## Limitations
- Performance on hard tasks (28.04% accuracy) reveals substantial gaps in handling complex analytical challenges
- Reliance on structured SOPs and metadata may limit ability to handle novel scenarios without guidance
- Two-stage planning creates rigid separation between planning and execution that could struggle with unpredictable data patterns

## Confidence
- **High Confidence**: Architectural design and modular approach are well-documented and technically sound; reported performance improvements over baselines are specific and reproducible
- **Medium Confidence**: Mechanism claims (two-stage planning benefits, contextual grounding importance) are supported by internal logic and comparisons but need more ablation studies and real-world validation
- **Low Confidence**: Generalizability claims to diverse domains beyond evaluated benchmarks require further empirical validation

## Next Checks
1. Conduct ablation study on contextual grounding by removing the Contextual Reasoner module and re-running experiments on DABstep
2. Deploy I2I-STRADA on a small set of real-world data analysis tasks from actual business domains to assess performance beyond synthetic benchmarks
3. Perform detailed error analysis of the 28.04% success rate on hard DABstep tasks to identify failure sources in planning, execution, or reasoning capabilities