---
ver: rpa2
title: ReReLRP -- Remembering and Recognizing Tasks with LRP
arxiv_id: '2502.10789'
source_url: https://arxiv.org/abs/2502.10789
tags:
- accuracy
- rerelrp
- learning
- average
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ReReLRP, a replay-free continual learning method
  that leverages Layerwise Relevance Propagation (LRP) to mitigate catastrophic forgetting.
  The core idea is to freeze neurons with high relevance scores after each task, preserving
  task-specific knowledge while allowing the rest of the network to adapt.
---

# ReReLRP -- Remembering and Recognizing Tasks with LRP

## Quick Facts
- **arXiv ID:** 2502.10789
- **Source URL:** https://arxiv.org/abs/2502.10789
- **Reference count:** 40
- **Primary result:** ReReLRP achieves competitive accuracy to replay-based methods while significantly reducing catastrophic forgetting through neuron freezing guided by LRP relevance scores.

## Executive Summary
ReReLRP is a replay-free continual learning method that addresses catastrophic forgetting by combining neuron freezing with task recognition using Layerwise Relevance Propagation (LRP). The method identifies and freezes neurons critical for previous tasks based on their LRP relevance scores, while allowing remaining neurons to adapt to new tasks. Additionally, it constructs task-specific relevance signatures from frozen neurons to enable explainable task recognition without storing raw data. Experiments show ReReLRP achieves competitive performance to state-of-the-art replay-based methods while offering privacy benefits and reduced memory footprint.

## Method Summary
ReReLRP operates by first training a neural network on each task sequentially. After training, LRP is used to compute relevance scores for all neurons, which are then normalized per layer. The method prunes neurons with the lowest relevance scores iteratively until a predefined accuracy threshold is met on validation data. The remaining high-relevance neurons are frozen by preventing weight updates during subsequent task training. For task recognition, relevance datasets are built using representative samples selected via herding, and feature selection is applied based on mean relevance thresholds. A classifier chain trained on these relevance signatures enables task inference during testing.

## Key Results
- Achieves competitive task-agnostic accuracy (~40%) compared to replay-based methods (iCaRL ~23%) on CIFAR-10 with 5 tasks
- Significantly reduces catastrophic forgetting compared to LWF/LWM/EWC baselines (forgetting ~19% vs ~87-91%)
- Maintains strong performance on real-world medical image datasets (BloodMNIST, PathMNIST) while offering privacy advantages
- Demonstrates memory efficiency by storing compressed relevance features instead of raw images

## Why This Works (Mechanism)

### Mechanism 1: Relevance-based Neuron Freezing
Freezing neurons with high LRP relevance scores preserves task-specific knowledge while allowing unfrozen neurons to adapt to new tasks. After each task, LRP decomposes predictions backward through layers to assign relevance scores. Neurons with smallest average relevance are pruned until accuracy threshold τ is met, and remaining neurons are frozen to prevent weight updates.

### Mechanism 2: Task-Specific Relevance Signatures for Task Recognition
LRP relevance patterns across frozen neurons serve as discriminative fingerprints for identifying which task a sample belongs to. For each task, relevance datasets are constructed by computing LRP scores on representative samples, and a classifier chain is trained on these signatures to estimate task probabilities.

### Mechanism 3: Selective Plasticity with Privacy-Preserving Storage
Storing only relevance values instead of raw images enables task recognition with reduced privacy risk and competitive memory footprint. Relevance datasets store compressed feature representations (e.g., 40 relevance values per exemplar vs. 3×32×32 pixels), enabling larger numbers of representative samples while maintaining comparable memory usage.

## Foundational Learning

**Catastrophic Forgetting**
- Why needed: The entire method addresses this fundamental DNN limitation where learning new information degrades previously acquired knowledge
- Quick check: Can you explain why gradient descent on new task data overwrites weights critical for old tasks?

**Layerwise Relevance Propagation (LRP)**
- Why needed: Core technical tool for identifying important neurons and building task signatures. Requires understanding conservation property: f(x) = Σi Ri
- Quick check: Given a 2-layer network with activations a_i and weights w_ij, can you manually compute one step of relevance propagation using the LRP-ε rule?

**Class-Incremental Learning**
- Why needed: Paper operates in this setting where tasks are class subsets, requiring task-agnostic inference at test time
- Quick check: How does class-incremental learning differ from task-incremental (where task identity is known at inference)?

## Architecture Onboarding

**Component map:**
Base Model (fθ, h) → LRP Module (Rθ) → Freezing Mask (Fi per task)
                          ↓
              Relevance Dataset (DRi) → Feature Selection
                          ↓
              Classifier Chain → Task Inference

**Critical path:**
1. Train base model on Task Ti
2. Compute LRP relevance for all neurons using validation samples
3. Prune low-relevance neurons iteratively until Acc(M|Fi, Ti) ≥ τ
4. Freeze remaining neurons (add to Fi)
5. Build relevance dataset DRi via herding selection (m samples)
6. Select features via mean relevance threshold (ϵ)
7. Train task classifier on relevance signatures
8. Repeat for subsequent tasks; at inference, classifier chain identifies task

**Design tradeoffs:**
- τ (accuracy threshold): Higher τ → more neurons frozen → better retention but faster saturation
- Number of features: More features → better accuracy, but linear storage increase
- Number of exemplars: Diminishing returns beyond threshold due to redundancy
- Network capacity vs. task complexity: High-capacity networks with fewer tasks show competitive accuracy; saturation occurs when task count exceeds capacity

**Failure signatures:**
- Network saturation: When >80-90% neurons frozen, new task accuracy collapses
- Under-capacity deployment: Smaller architectures (LeNet) saturate mid-sequence on complex tasks
- Over-aggressive pruning: If τ is set too high without capacity margin, essential neurons may be pruned

**First 3 experiments:**
1. CIFAR-10 baseline reproduction: Train VGG-11 on 5 tasks (2 classes each), validate forgetting drops to ~19% vs. ~87-91% for LWF/LWM/EWC
2. Accuracy threshold (τ) ablation: On CIFAR-10, test τ ∈ {1, 5, 15} to measure trade-off between forgetting reduction and final average accuracy
3. Network capacity boundary test: Run FashionMNIST with varying architectures (LeNet vs. VGG-11 vs. ResNet-18) to identify saturation point where frozen percentage exceeds ~70%

## Open Questions the Paper Calls Out

**Open Question 1:** How can dynamic network capacity expansion be integrated into ReReLRP to prevent network saturation during long-term learning scenarios?
- Basis: Authors propose integration of dynamic network capacity management as future direction
- Why unresolved: Current method operates on fixed-capacity networks; experiments show performance degradation when tasks exceed capacity
- Evidence needed: Modified framework with dynamic neuron/layer addition maintaining stable accuracy across task sequences exceeding initial capacity

**Open Question 2:** Can advanced feature selection techniques reduce the storage overhead of relevance datasets while maintaining high inter-task classification performance?
- Basis: Outlook section lists investigating advanced feature selection techniques as promising direction
- Why unresolved: Current implementation uses mean relevance selection as resource-efficient alternative to theoretically superior mutual information approach
- Evidence needed: Comparative analysis demonstrating new technique lowering memory footprint without significant accuracy drop

**Open Question 3:** Does ReReLRP provide a scalable and storage-efficient solution for scenarios with large image sizes relative to network capacity?
- Basis: Authors suggest applying method to scenarios with large image sizes relative to network capacity
- Why unresolved: Effectiveness on high-resolution inputs where feature maps are large relative to network's representational power remains unverified
- Evidence needed: Successful application on high-resolution datasets demonstrating efficient relevance signature storage and avoidance of saturation

## Limitations

- Network capacity constraints limit scalability on high-complexity tasks where saturation occurs mid-sequence
- LRP implementation sensitivity due to unspecified hyperparameters that directly impact neuron freezing decisions
- Privacy claims lack empirical validation through quantified privacy leakage measurements

## Confidence

**High confidence:**
- Catastrophic forgetting reduction on moderate-complexity datasets
- Task recognition capability using LRP signatures
- Memory efficiency advantage over replay methods

**Medium confidence:**
- Performance on medical imaging datasets (limited sample size)
- Scalability claims for high-capacity networks (only VGG-11/ResNet-18 tested)
- Privacy benefits (claimed but not empirically validated)

**Low confidence:**
- Long-sequence performance beyond 5-10 tasks
- Performance on highly overlapping task semantics
- Real-world deployment scenarios with varying data distributions

## Next Checks

1. **Capacity scaling experiment:** Test ReReLRP on progressively larger architectures (VGG-16, ResNet-50) and task sequences (10+ tasks) to identify saturation thresholds and provide capacity guidelines

2. **Privacy leakage quantification:** Conduct membership inference attacks on relevance datasets to measure actual privacy risk, comparing against raw data storage to validate claimed privacy benefits

3. **Cross-dataset generalization:** Evaluate ReReLRP on dataset with high task overlap (e.g., CIFAR-100 with semantic groupings) to test limits of task discrimination when relevance patterns become similar across tasks