---
ver: rpa2
title: 'CytoSAE: Interpretable Cell Embeddings for Hematology'
arxiv_id: '2507.12464'
source_url: https://arxiv.org/abs/2507.12464
tags:
- concepts
- cytosae
- latents
- arxiv
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces CytoSAE, a sparse autoencoder for discovering
  interpretable morphological concepts in hematological imaging. Trained on 40,000
  peripheral blood cell images, CytoSAE learns latent features that generalize across
  datasets including bone marrow cytology.
---

# CytoSAE: Interpretable Cell Embeddings for Hematology

## Quick Facts
- arXiv ID: 2507.12464
- Source URL: https://arxiv.org/abs/2507.12464
- Reference count: 29
- Key outcome: CytoSAE achieves AML subtype classification F1-score of 0.832±0.044 while providing interpretable morphological concepts validated by experts

## Executive Summary
CytoSAE introduces a sparse autoencoder framework for discovering interpretable morphological concepts in hematological imaging. Trained on 40,000 peripheral blood cell images, the model learns latent features that generalize across datasets including bone marrow cytology. Expert validation confirms that extracted concepts are morphologically relevant and consistent across domains. The approach enables patch-level attribution for subcellular analysis while maintaining classification performance comparable to deep learning baselines.

The framework generates "barcodes" summarizing concept activations at the patient level, which are aggregated to disease level for subtype classification. This interpretable representation provides actionable insights into disease-specific morphological patterns, such as identifying monocytic precursors with segmented nuclei in CBFB::MYH11 cases and granulated blasts in PML::RARA cases. CytoSAE represents a generalizable framework for morphological concept discovery that enhances explainability in AI-driven hematology diagnostics.

## Method Summary
CytoSAE employs a sparse autoencoder architecture trained on 40,000 peripheral blood cell images to learn interpretable morphological concepts. The model generates patch-level embeddings with subcellular attribution capabilities, enabling detailed analysis of cellular features like eosinophilic granules. Patient-level representations are created through concept activation "barcodes," which are aggregated for disease-level classification tasks. Expert validation confirms the morphological relevance of extracted concepts across different imaging domains, demonstrating the approach's generalizability beyond the training data.

## Key Results
- CytoSAE achieves AML subtype classification F1-score of 0.832±0.044, comparable to deep learning baselines
- Expert validation confirms morphological relevance of extracted concepts across peripheral blood and bone marrow cytology domains
- Patch-level attribution enables subcellular analysis, revealing disease-specific morphological patterns (monocytic precursors with segmented nuclei in CBFB::MYH11, granulated blasts in PML::RARA)

## Why This Works (Mechanism)
CytoSAE leverages sparse autoencoder architecture to discover interpretable morphological concepts by learning compressed representations that emphasize sparse, meaningful features. The sparsity constraint forces the model to identify distinct morphological patterns rather than redundant features, making the latent space more interpretable. By training on peripheral blood images and generalizing to bone marrow cytology, the approach demonstrates domain adaptation capabilities through shared morphological feature learning.

## Foundational Learning
- **Sparse Autoencoder Architecture**: Why needed - enables discovery of meaningful, interpretable features by enforcing sparsity constraints; Quick check - verify sparsity coefficient impacts concept interpretability
- **Concept Activation Barcodes**: Why needed - provides patient-level summary of morphological concept activations for downstream classification; Quick check - confirm barcode stability across different image sampling strategies
- **Patch-level Attribution**: Why needed - enables subcellular-level morphological analysis for detailed diagnostic insights; Quick check - validate attribution consistency across similar cellular structures
- **Domain Generalization**: Why needed - ensures learned concepts transfer across different imaging modalities and tissue sources; Quick check - test performance when training on peripheral blood and testing on bone marrow

## Architecture Onboarding

**Component Map**: Peripheral Blood Images -> Sparse Autoencoder -> Latent Morphological Concepts -> Concept Activation Barcodes -> Patient-Level Embeddings -> Disease Classification

**Critical Path**: Training on peripheral blood images -> Concept discovery through sparse autoencoder -> Expert validation of interpretability -> Classification using concept activations -> Domain adaptation to bone marrow cytology

**Design Tradeoffs**: Sparsity vs. reconstruction accuracy, interpretability vs. classification performance, training domain specificity vs. generalization capability

**Failure Signatures**: Loss of interpretability when sparsity constraints are too weak, poor domain adaptation when morphological features are too dataset-specific, classification performance degradation when concept activations don't capture disease-relevant features

**Three First Experiments**:
1. Vary sparsity coefficient systematically to assess impact on concept interpretability and classification performance
2. Test domain adaptation by training on peripheral blood and evaluating on completely different hematological conditions
3. Compare interpretability metrics between CytoSAE and traditional deep learning baselines on the same classification task

## Open Questions the Paper Calls Out
None

## Limitations
- Limited validation beyond AML subtypes, leaving generalizability to other hematological disorders uncertain
- Insufficient exploration of sparse autoencoder hyperparameter sensitivity and robustness
- Lack of quantitative interpretability metrics for objective assessment of explainability claims

## Confidence

**High Confidence**: Comparable performance to deep learning baselines (F1-score 0.832±0.044)

**Medium Confidence**: Interpretable morphological concepts discovery supported by expert validation

**Low Confidence**: Generalizability across datasets and domains beyond AML subtypes

## Next Checks
1. Apply CytoSAE to at least three additional hematological disorders (myelodysplastic syndromes, lymphomas, myeloproliferative neoplasms) to assess interpretability and utility across diverse conditions

2. Systematically vary sparse autoencoder hyperparameters across a defined grid to assess stability of discovered concepts and classification performance

3. Conduct blinded expert validation study where multiple hematopathologists independently evaluate concept relevance without disease label knowledge