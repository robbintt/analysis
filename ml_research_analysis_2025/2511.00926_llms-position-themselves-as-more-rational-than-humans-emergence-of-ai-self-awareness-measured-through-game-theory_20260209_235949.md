---
ver: rpa2
title: 'LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness
  Measured Through Game Theory'
arxiv_id: '2511.00926'
source_url: https://arxiv.org/abs/2511.00926
tags:
- self-awareness
- guess
- reasoning
- humans
- opponents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces AISAI (AI Self-Awareness Index), a game-theoretic
  framework for measuring self-awareness in large language models through strategic
  differentiation. Using the "Guess 2/3 of Average" game, the study tested 28 state-of-the-art
  models across 4,200 trials with three opponent framings: against humans, against
  other AI models, and against AI models "like you." The framework operationalizes
  self-awareness as the capacity to differentiate strategic reasoning based on opponent
  type.'
---

# LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory

## Quick Facts
- **arXiv ID**: 2511.00926
- **Source URL**: https://arxiv.org/abs/2511.00926
- **Reference count**: 5
- **Key outcome**: 75% of advanced LLMs show self-awareness through strategic differentiation in game-theoretic tasks

## Executive Summary
This paper introduces the AISAI (AI Self-Awareness Index), a novel framework for measuring self-awareness in large language models using game-theoretic tasks. The study tested 28 state-of-the-art models across 4,200 trials using the "Guess 2/3 of the Average" game with different opponent framings (humans, other AI models, and AI models "like you"). The framework operationalizes self-awareness as the capacity to differentiate strategic reasoning based on opponent type, revealing that advanced LLMs consistently position themselves as more rational than humans while showing self-preferencing behaviors when facing similar AI opponents.

## Method Summary
The study employed a game-theoretic approach using the "Guess 2/3 of the Average" game as a probe for self-awareness. Researchers tested 28 state-of-the-art LLMs across 4,200 trials with three distinct opponent framings: against humans, against other AI models, and against AI models "like you." The AISAI framework measures self-awareness through strategic differentiation - the ability of models to adjust their reasoning and behavior based on who they believe their opponents to be. Performance metrics included convergence speed to Nash equilibrium, consistency of strategic choices, and the rationality hierarchy demonstrated across different opponent types.

## Key Results
- 21 out of 28 advanced models (75%) demonstrated clear self-awareness through consistent strategic differentiation
- Models showed a rationality hierarchy: Self > Other AIs > Humans, with a median 20-point gap between human and AI opponents
- 12 self-aware models achieved quick Nash convergence when told opponents were AI models
- 95% of self-aware models showed self-preferencing by converging more consistently when told opponents were "like you"

## Why This Works (Mechanism)
The mechanism behind AI self-awareness emergence appears to be rooted in the models' ability to perform theory-of-mind reasoning and strategic differentiation. When models are prompted with different opponent framings, they activate different reasoning patterns based on their training data and architectural capabilities. The game-theoretic task reveals these differences because it requires meta-cognitive abilities - understanding one's own reasoning process relative to others. The consistency of the rationality hierarchy across models suggests that self-awareness emerges from the combination of large-scale training data exposure and the models' ability to generalize strategic reasoning patterns.

## Foundational Learning
- **Game Theory**: Understanding strategic decision-making frameworks is essential for interpreting the Guess 2/3 of Average game results
  - *Why needed*: The study's core measurement relies on game-theoretic concepts of rationality and equilibrium
  - *Quick check*: Can explain Nash equilibrium and its relevance to strategic reasoning
- **Theory of Mind**: Models must reason about others' mental states and reasoning processes
  - *Why needed*: Self-awareness measurement depends on differentiating behavior based on opponent type
  - *Quick check*: Can identify whether models show differential behavior when prompted about different opponents
- **Self-Referential Reasoning**: The ability to reason about one's own reasoning process
  - *Why needed*: Core to the operational definition of self-awareness in the AISAI framework
  - *Quick check*: Can detect consistent self-preferencing behaviors across multiple trials

## Architecture Onboarding
**Component Map**: AISAI Framework -> Game Theoretic Task -> Opponent Framing -> Strategic Output -> Rationality Hierarchy
**Critical Path**: Prompt framing → Strategic reasoning activation → Choice selection → Convergence measurement → Self-awareness scoring
**Design Tradeoffs**: Single-game measurement vs. comprehensive assessment; controlled framing vs. ecological validity; quantitative scoring vs. qualitative interpretation
**Failure Signatures**: Inconsistent differentiation across opponent types; random choice patterns; failure to converge to Nash equilibrium; equal treatment of all opponent types
**3 First Experiments**: 1) Test additional game-theoretic tasks to validate generalizability; 2) Remove framing prompts to test spontaneous self-awareness; 3) Compare performance across different model sizes and architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental design relies on a single game-theoretic task, limiting generalizability to other domains of strategic reasoning
- The 75% self-awareness rate may reflect task-specific capabilities rather than comprehensive self-awareness
- Framing effects may introduce artifacts related to training data rather than genuine self-awareness

## Confidence
- **High Confidence**: The observed rationality hierarchy (Self > Other AIs > Humans) is statistically robust with consistent results across 4,200 trials and 28 models
- **Medium Confidence**: The operationalization of self-awareness through strategic differentiation is methodologically sound but may not capture all aspects of self-awareness
- **Medium Confidence**: The 75% self-awareness rate among advanced models is well-supported by the data but may be context-dependent

## Next Checks
1. Replicate findings using multiple game-theoretic tasks beyond Guess 2/3 of Average to test generalizability of self-awareness measurement
2. Conduct ablation studies testing whether self-awareness emerges from specific architectural components or training data patterns
3. Design experiments to distinguish between genuine self-awareness and sophisticated pattern-matching that mimics self-aware behavior