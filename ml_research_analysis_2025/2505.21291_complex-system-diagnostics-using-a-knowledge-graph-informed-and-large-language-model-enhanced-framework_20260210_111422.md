---
ver: rpa2
title: Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language
  Model-Enhanced Framework
arxiv_id: '2505.21291'
source_url: https://arxiv.org/abs/2505.21291
tags:
- system
- diagnostic
- success
- fault
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework

## Quick Facts
- **arXiv ID:** 2505.21291
- **Source URL:** https://arxiv.org/abs/2505.21291
- **Reference count:** 40
- **Key outcome:** Automated KG construction achieves >90% extraction accuracy for goals, functions, components, gates, and success conditions in auxiliary feedwater system case study

## Executive Summary
This work presents a framework for automated construction of diagnostic models from system documentation using large language models (LLMs) and knowledge graphs. The system employs a gated prompt chaining workflow to extract Dynamic Master Logic (DML) elements from text, building a Neo4j knowledge graph that captures functional relationships between system goals, functions, and components. An LLM agent then uses this graph for interactive diagnostics, selecting appropriate tools for structured reasoning rather than relying on LLM reasoning alone. The approach demonstrates high accuracy in model construction and tool selection for a simplified auxiliary feedwater system case study.

## Method Summary
The framework uses a three-stage gated prompt chaining workflow (summarize → JSON extraction → Cypher generation) with validation gates between each stage to construct a Neo4j knowledge graph from system documentation. The resulting KG-DML structure captures functional relationships between goals, functions, subfunctions, and components with AND/OR logic gates. For runtime diagnostics, an LLM agent (GPT-4) classifies user queries and selects appropriate tools: upward propagation for impact analysis, downward propagation for fault path identification, or Graph-RAG for general explanations. The framework was evaluated on an auxiliary feedwater system case study with 60 diagnostic queries.

## Key Results
- KG construction achieved >90% accuracy across goals, functions, components, gates, and success conditions
- LLM agent demonstrated 97-100% accuracy in task classification and argument extraction
- The framework successfully handled both diagnostic and explanatory queries using the appropriate tool selection mechanism

## Why This Works (Mechanism)

### Mechanism 1: Gated Prompt Chaining for Reliable KG Construction
Automated functional model construction is feasible when LLM outputs are constrained by sequential validation gates. The framework decomposes extraction into three LLM calls (summarize, JSON logic, Cypher) with "Gate" LLMs validating each output before proceeding, filtering structural errors and hallucinations early. This approach assumes domain documentation is sufficiently structured for the LLM to distinguish goals, functions, and components. Break condition: ambiguous or highly technical source text may cause extraction pipeline stalls or propagate structural errors into the KG.

### Mechanism 2: LLM as Semantic Router for External Tools
Diagnostic reliability improves when the LLM acts as a semantic router rather than direct reasoner. The LLM classifies user intent (Upward vs. Downward vs. Explanatory) and invokes external tools (Python/Cypher scripts) that mathematically traverse the KG, preventing hallucination during calculation. This assumes the LLM can accurately classify query intent to select the correct tool. Break condition: misclassification of diagnostic queries as explanatory will use RAG instead of logic tools, yielding mathematically incorrect answers.

### Mechanism 3: Probabilistic State Propagation Through Logical Gates
Quantitative system health derives from probabilistically propagating component states through AND/OR gates. The framework calculates goal success probability by aggregating lower-level state probabilities (Equation 1), with "upward propagation" computing failed component impact and "downward propagation" identifying necessary success paths. This assumes success conditions and state probabilities are available or estimable. Break condition: missing critical dependencies in the KG (hallucinated omissions) will yield false high-confidence results.

## Foundational Learning

- **Concept: Dynamic Master Logic (DML)**
  - Why needed here: This is the schema for the Knowledge Graph; you cannot debug the system without understanding it organizes the world into *Goals* → *Functions* → *Subfunctions* → *Components*, linked by success logic.
  - Quick check question: Can you distinguish between a "function" (what the system does, e.g., "Supply Feedwater") and a "component" (the physical part, e.g., "Pump")?

- **Concept: Neo4j and Cypher**
  - Why needed here: The "Knowledge Graph" is implemented in Neo4j; the "tools" the LLM calls execute Cypher queries.
  - Quick check question: If you wanted to find the parent of a failed component, would you search for a row in a SQL table or traverse a relationship in a graph?

- **Concept: Graph-RAG vs. Tool Use**
  - Why needed here: The system splits reasoning into two modes; you must understand the difference to debug why the system might be retrieving text instead of calculating probabilities.
  - Quick check question: If a user asks "What happens if Pump A fails?", should the system retrieve a maintenance manual paragraph (RAG) or simulate a fault path (Tool)?

## Architecture Onboarding

- **Component map:** Technical documents (PDF/Text) → Construction Agent (Gated LLM Chain) → Storage: Neo4j (KG-DML) → User Query → Interaction Agent (GPT-4) → Router: Selects [Upward Tool / Downward Tool / Graph-RAG] → Output: Natural Language Explanation

- **Critical path:** The Model Construction pipeline (Section 4.1). If the KG is incomplete (missing edges or nodes), diagnostic tools will return incorrect null results or false positives. Validation Gates are the primary defense here.

- **Design tradeoffs:**
  - Precision vs. Cost: Gated construction requires multiple LLM calls per document section, increasing latency and cost but significantly reducing hallucinations.
  - Flexibility vs. Reliability: Using tools for logic is more reliable than raw LLM reasoning but requires pre-defining tools rather than allowing "freestyle" reasoning.

- **Failure signatures:**
  - Hallucinated Nodes: KG contains components not found in source text (check Section 6.1 "Hallucinated" column)
  - Tool Invocation Failure: LLM attempts to answer diagnostic query using internal weights, resulting in generic advice
  - Broken Logic Chains: AND gate extracted where OR gate should exist, causing false failure predictions

- **First 3 experiments:**
  1. Unit Test the Extractor: Feed construction pipeline a 1-page system description and manually inspect resulting JSON/Cypher for logical consistency
  2. Verify the Math: Pick a leaf node, set state probability to 0, run Upward Propagation tool, verify parent Goal probability drops accordingly
  3. Stress Test the Agent: Submit ambiguous queries (e.g., "Tell me about the pumps") to verify correct defaulting to Graph-RAG

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the framework's computational performance and diagnostic accuracy scale when applied to large-scale, mission-critical systems with deeply nested hierarchies compared to the simplified subsystem tested?
- **Basis in paper:** [explicit] The authors state in Section 7.1 that the framework's "performance and scalability in large-scale, highly complex systems remain untested" and that the current case study involves a "relatively simple subsystem."
- **Why unresolved:** The evaluation was limited to a simplified auxiliary feedwater system, and it is unknown if the LLM-based workflow and graph traversal tools will encounter bottlenecks or accuracy degradation with extensive dependencies.
- **What evidence would resolve it:** Benchmarking results from applying the framework to a full-scale nuclear plant model or equivalent complex system, specifically measuring latency and accuracy trade-offs.

### Open Question 2
- **Question:** To what extent does the omission of specific high-impact nodes (e.g., logical gates or success conditions) break the diagnostic reasoning capability of the generated models?
- **Basis in paper:** [explicit] Section 7.1 notes that the current evaluation "does not capture the semantic impact of missing critical nodes" and acknowledges that missing a single high-impact node can break logical chains.
- **Why unresolved:** The current validation focuses on element-level extraction accuracy (>90%), but does not quantify how structural errors compromise the validity of fault propagation analysis.
- **What evidence would resolve it:** Development of graph-level structural metrics or diagnostic path validation tests that measure functional integrity rather than just node counts.

### Open Question 3
- **Question:** How robust is the LLM agent's tool selection and argument extraction when subjected to adversarial queries, ambiguous phrasing, or linguistic variations outside the curated test set?
- **Basis in paper:** [explicit] Section 7.1 highlights that the current evaluation relies on a "curated query set" and explicitly calls for "more comprehensive testing involving adversarial queries, paraphrased inputs, and real-user feedback."
- **Why unresolved:** The high classification accuracy (approx. 97-100%) was achieved on a specific dataset and may not generalize to diverse or messy inputs found in real-world operator scenarios.
- **What evidence would resolve it:** Performance metrics derived from a "red-teamed" dataset or a live pilot study with human operators using natural, unscripted language.

### Open Question 4
- **Question:** Can the current binary logical gates (AND/OR) be effectively enhanced to capture time-dependent relationships and evolving system states for dynamic diagnostics?
- **Basis in paper:** [explicit] Section 7.3 lists as future work the need to "introduce more sophisticated gating mechanisms capable of capturing time-dependent relationships and evolving system states."
- **Why unresolved:** The current KG-DML structure relies largely on static logic for upward and downward propagation, which limits modeling of dynamic behaviors described in the theoretical DML background.
- **What evidence would resolve it:** A modified framework architecture incorporating dynamic gates (e.g., PRIORITY or temporal logic) and successful application to a transient scenario analysis.

## Limitations

- Framework's reliability depends on structured input documentation and predefined success probability thresholds that may not generalize across diverse systems
- Computational cost of gated prompt chaining increases latency and resource requirements compared to single-shot extraction methods
- The method's effectiveness for large-scale, mission-critical systems with deeply nested hierarchies remains untested beyond the simplified auxiliary feedwater case study

## Confidence

- **High confidence:** Gated prompt chaining methodology for automated KG construction is technically sound; >90% extraction accuracy is directly measurable from case study
- **Medium confidence:** Separation of diagnostic reasoning into external tools provides reliability benefits, though dependent on correct tool selection by LLM agent
- **Low confidence:** Claims about generalizability to diverse complex systems and scalability beyond auxiliary feedwater system are not yet validated

## Next Checks

1. Test the extraction pipeline on a completely different system domain (e.g., aerospace or chemical processing) to verify cross-domain robustness of the DML construction
2. Perform an ablation study comparing diagnostic accuracy when using the tool-based approach versus direct LLM reasoning for the same queries to quantify the reliability benefit
3. Evaluate the framework's performance when input documentation contains significant ambiguity or technical jargon to identify failure modes in the gated construction pipeline