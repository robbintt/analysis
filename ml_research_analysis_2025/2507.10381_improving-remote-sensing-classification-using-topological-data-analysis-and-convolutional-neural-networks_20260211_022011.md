---
ver: rpa2
title: Improving Remote Sensing Classification using Topological Data Analysis and
  Convolutional Neural Networks
arxiv_id: '2507.10381'
source_url: https://arxiv.org/abs/2507.10381
tags:
- features
- data
- topological
- eurosat
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method to improve remote sensing classification
  by integrating topological data analysis (TDA) features with convolutional neural
  networks (CNNs). The author addresses the limitation of CNNs being biased towards
  high-frequency texture-based features by incorporating TDA, which captures global
  geometric features.
---

# Improving Remote Sensing Classification using Topological Data Analysis and Convolutional Neural Networks

## Quick Facts
- **arXiv ID:** 2507.10381
- **Source URL:** https://arxiv.org/abs/2507.10381
- **Reference count:** 40
- **Primary result:** Achieves 99.33% accuracy on EuroSAT dataset, surpassing larger architectures, by integrating TDA features with CNNs.

## Executive Summary
This paper addresses the texture bias of CNNs in remote sensing by integrating topological data analysis (TDA) features. The method captures global geometric features through persistent homology on filtrations based on image gradients and local entropy, complementing the local texture-based features learned by CNNs. By fusing these distinct feature sets via concatenation, the approach achieves state-of-the-art accuracy on the EuroSAT dataset and improves performance on RESISC45. The findings demonstrate that TDA can be effectively combined with deep learning models to enhance classification accuracy in remote sensing applications.

## Method Summary
The method employs a dual-branch fusion architecture combining a CNN (ResNet18 or ResNet12) with a TDA feature pipeline. Images are downsampled to 32x32 for TDA processing, where multiple filtrations (grayscale, binary, gradient, entropy) generate persistence diagrams. These diagrams are vectorized into descriptors (Betti curves, heat kernel, amplitudes) and encoded through a 4-layer MLP. The TDA features are concatenated with CNN features and passed through a classification head. Training uses Adam optimizer with ReduceLROnPlateau scheduling for 50 epochs.

## Key Results
- Achieves 99.33% accuracy on EuroSAT dataset, a new state-of-the-art for single models.
- Improves RESISC45 accuracy by 1.82% over ResNet18 baseline (82.23% vs 80.41%).
- Demonstrates faster convergence and reduced overfitting when TDA features are incorporated.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Topological features provide global geometric signals that complement the local texture bias of CNNs.
- **Mechanism:** CNNs primarily encode high-frequency local features (texture). TDA extracts global shape and connectivity information via persistent homology on cubical complexes. Concatenating these distinct feature sets allows the classifier to access both local texture and global structure.
- **Core assumption:** The target classes are distinguishable not just by texture but by global geometric layout (e.g., the distribution of crop fields vs. forests).
- **Evidence anchors:**
  - [abstract] "CNNs have been shown to be biased towards texture based local features... TDA... captures global geometric features."
  - [section] "TDA is specially suited to handle global features that can provide the low-frequency features that CNNs often miss."
  - [corpus] "Hybrid Topological and Deep Feature Fusion..." supports the general efficacy of TDA-DL fusion in imaging.
- **Break Condition:** If the dataset relies exclusively on fine-grained local details (e.g., subtle object parts) with no distinct global structure, TDA features may become noise.

### Mechanism 2
- **Claim:** Multi-filtration strategies capture geometric information from intensity gradients and complexity, not just raw pixel values.
- **Mechanism:** By applying filtrations based on image gradients (boundaries) and local entropy (complexity), the pipeline computes persistence diagrams that highlight structural edges and heterogeneity. This serves as a "shape signature" for different land-use types.
- **Core assumption:** Discriminative information is encoded in the "layout of boundaries" and "local randomness" of pixel intensities.
- **Evidence anchors:**
  - [abstract] "...uses multiple topological descriptors and filtrations based on image gradients and local entropy."
  - [section] "Images of locations such as highways... will typically have strong boundaries... These global, boundary-based properties can be captured effectively using image gradients."
  - [corpus] Corpus evidence is weak for specific "gradient/entropy" filtrations in remote sensing; most neighbors use standard intensity filtrations.
- **Break Condition:** If images are downsampled too aggressively (to 32x32), the gradient and entropy signals may be lost or distorted, degrading feature quality.

### Mechanism 3
- **Claim:** TDA features improve generalization and convergence speed by providing robust, deterministic signals.
- **Mechanism:** TDA features are deterministic and robust to noise. When fused with learned CNN features, they stabilize the optimization landscape, allowing the model to converge faster and reducing the gap between training and validation accuracy.
- **Core assumption:** The topological signatures are consistent across train and test splits (distribution shift is minimal regarding global geometry).
- **Evidence anchors:**
  - [section] "Not only does the training accuracy improve, but the model's overfitting also decreases (smaller training vs test accuracy gaps...)."
  - [section] "For EuroSAT, training both ResNets have faster convergence using topological features than without."
  - [corpus] Corpus evidence for convergence speed specifically is weak/absent.
- **Break Condition:** When TDA features are weakly discriminative for a specific dataset (low TDA-only MLP accuracy), they fail to regularize the model and may introduce noise.

## Foundational Learning

- **Concept:** Persistent Homology & Cubical Complexes
  - **Why needed here:** This is the core mathematical engine used to convert a static image (grid of pixels) into a topological signature (birth/death of features) that can be vectorized.
  - **Quick check question:** Can you explain why we track the "birth" and "death" of a hole in an image as we threshold it?

- **Concept:** Image Filtrations
  - **Why needed here:** The paper doesn't just look at the image; it transforms it via gradients and entropy. Understanding how a filtration turns an image into a sequence of complexes is vital for debugging the feature pipeline.
  - **Quick check question:** How does a "radial filtration" differ from a "grayscale filtration" in terms of the geometric features it emphasizes?

- **Concept:** Texture Bias in CNNs
  - **Why needed here:** The entire motivation for adding TDA is the cited limitation of CNNs (ResNet) prioritizing local texture over global shape. Understanding this bias explains why the fusion is necessary.
  - **Quick check question:** Why might a standard ResNet confuse "Annual Crop" and "Permanent Crop" if it relies heavily on texture?

## Architecture Onboarding

- **Component map:** Input Image (224x224) -> ResNet18 -> Feature Vector; Input Image (32x32) -> TDA Pipeline (Gradients, Entropy, Grayscale, Binary) -> Persistence Diagrams -> Vectorized Descriptors -> 4-layer MLP -> TDA Vector; ResNet Vector + TDA Vector -> Concatenation -> 2-layer MLP Head -> Logits

- **Critical path:** The synchronization of feature dimensions during concatenation and ensuring the TDA MLP effectively compresses the high-dimensional topological descriptors before fusion.

- **Design tradeoffs:**
  - **Computational cost vs. Granularity:** TDA is computationally expensive; the authors downsample images to 32x32 to make it feasible, losing fine-grained topological details.
  - **Model size vs. Feature complexity:** A small ResNet12 + TDA is cheaper than a ResNet50, but the TDA pipeline adds significant inference latency.

- **Failure signatures:**
  - **Accuracy Degradation:** If TDA features are uninformative (as seen in RESISC45 with ResNet12), the model performs *worse* than the baseline (76.70% vs 81.41%), suggesting the features act as noise.
  - **Stagnation:** If the TDA-only MLP achieves low accuracy (e.g., <40%), do not expect the fused model to significantly outperform the CNN baseline.

- **First 3 experiments:**
  1. **Baseline Probe:** Train the TDA-MLP branch *alone* (no CNN) on the target dataset. If accuracy is low (<50%), TDA features may not be suitable for the data without redesign.
  2. **Ablation on Filtrations:** Train the fused model using only Grayscale filtration vs. All Filtrations to verify that the computationally expensive gradient/entropy steps are adding signal, not noise.
  3. **Resolution Sensitivity:** Test TDA extraction at 32x32 vs. 64x64 (if resources allow) to quantify the information loss from downsampling.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can deeply integrated architectures (e.g., TDA-Net) provide stronger feature fusion than the simple concatenation method used in this study?
- **Basis in paper:** [explicit] The author states in Section 8 that "exploring more deeply integrated architectures... may offer stronger feature fusion than simple concatenation."
- **Why unresolved:** The current implementation relies on a straightforward concatenation of ResNet and MLP-processed TDA features, which may not fully exploit the interactions between topological and texture data.
- **What evidence would resolve it:** A comparative study showing that cross-attention mechanisms or intermediate layer fusion yield statistically significant accuracy improvements over the concatenation baseline on EuroSAT.

### Open Question 2
- **Question:** Does the significant image downsampling (to 32x32) required for computational feasibility limit the effectiveness of TDA on object-centric datasets?
- **Basis in paper:** [explicit] The author notes in Section 8 that "We also downsampled our images greatly... This loses a lot of granularity in our TDA features. This likely made TDA features on RESISC45 far less effective."
- **Why unresolved:** The trade-off between computational cost and feature granularity was not tested; the lower performance on RESISC45 might be an artifact of the low resolution rather than a lack of topological structure.
- **What evidence would resolve it:** Experiments demonstrating that applying the TDA pipeline to full-resolution images significantly closes the performance gap between ResNet-only and TDA-fused models on the RESISC45 dataset.

### Open Question 3
- **Question:** Can approximation techniques mitigate the high inference time cost of computing TDA features without sacrificing the accuracy gains?
- **Basis in paper:** [explicit] Section 8 highlights that "computing TDA features is very computationally intensive" and suggests "direction in approximation techniques that could speed up feature processing pipelines."
- **Why unresolved:** While the method improves accuracy, the computational overhead of generating persistence diagrams and filtrations makes the approach heavy during inference compared to standard CNNs.
- **What evidence would resolve it:** The development of a quantized or approximated TDA extraction method that maintains the reported 1.44% accuracy gain on EuroSAT while reducing inference latency to near-baseline levels.

## Limitations
- **Dataset Dependency:** The significant performance gap between EuroSAT (1.82% gain) and RESISC45 (5.92% gap) suggests TDA effectiveness is dataset-specific and not universally applicable.
- **Computational Overhead:** The TDA pipeline adds substantial computational cost, with no reported inference times or FLOPs for practical deployment assessment.
- **Ablation Gaps:** The paper does not isolate the contribution of individual filtration types (gradient, entropy, grayscale) to verify their necessity beyond computational cost.

## Confidence
- **High:** The ResNet18 + TDA architecture achieves 99.33% accuracy on EuroSAT and shows faster convergence with reduced overfitting compared to ResNet18 alone.
- **Medium:** The claim that TDA captures "global geometric features" complementing CNN "texture bias" is supported by the EuroSAT results but lacks ablation studies isolating the contribution of each filtration type.
- **Low:** The assertion that TDA features universally improve generalization is weakened by the RESISC45 results, where ResNet12 + TDA performs worse (76.70%) than ResNet12 alone (81.41%).

## Next Checks
1. **Ablation on Filtration Types:** Train the fused model using only Grayscale filtration vs. All Filtrations to verify that the computationally expensive gradient/entropy steps are adding signal, not noise.
2. **Distribution Shift Analysis:** Quantify the consistency of TDA signatures across train and test splits using persistence diagram similarity metrics (e.g., bottleneck distance) to validate the assumption of minimal geometric distribution shift.
3. **Cross-Dataset Transferability:** Evaluate the EuroSAT-trained TDA feature extractor on RESISC45 (and vice versa) to test whether the topological features learned are transferable or dataset-specific.