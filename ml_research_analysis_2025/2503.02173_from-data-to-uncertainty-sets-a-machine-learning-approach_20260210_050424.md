---
ver: rpa2
title: 'From Data to Uncertainty Sets: a Machine Learning Approach'
arxiv_id: '2503.02173'
source_url: https://arxiv.org/abs/2503.02173
tags:
- loss
- uncertainty
- probability
- ellipsoidal
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes using loss functions from machine learning models
  to construct uncertainty sets for robust optimization problems. The core idea is
  that the loss function naturally quantifies the uncertainty around predictions,
  allowing for more informed robust optimization.
---

# From Data to Uncertainty Sets: a Machine Learning Approach

## Quick Facts
- arXiv ID: 2503.02173
- Source URL: https://arxiv.org/abs/2503.02173
- Authors: Dimitris Bertsimas; Benjamin Boucher
- Reference count: 40
- Key outcome: Machine learning loss functions used to construct uncertainty sets for robust optimization, achieving up to 10x smaller radii than classical methods

## Executive Summary
This paper establishes a novel connection between machine learning loss functions and uncertainty set construction in robust optimization. The authors demonstrate that loss functions naturally quantify uncertainty around predictions, providing a principled way to construct uncertainty sets that are informed by data and covariates. By generalizing the classical ellipsoidal uncertainty set to the context of covariate-driven robust optimization, the framework allows for more precise uncertainty quantification while maintaining theoretical guarantees on constraint violation probabilities.

The proposed approach is validated through computational experiments on synthetic data across three problem types: newsvendor, portfolio optimization, and shortest path problems. Results show significant improvements in both objective values and regret compared to classical methods, with uncertainty sets requiring radii up to one order of magnitude smaller. The framework bridges the gap between data-driven prediction and robust decision-making, offering a unified approach to handle uncertainty in optimization problems.

## Method Summary
The paper introduces a framework that leverages machine learning loss functions to construct uncertainty sets for robust optimization problems. The core insight is that loss functions naturally capture the uncertainty in predictions, which can be translated into uncertainty sets that reflect both the inherent uncertainty in the problem and the influence of covariates. The authors show that this approach generalizes the classical ellipsoidal uncertainty set by incorporating covariate information, leading to more precise uncertainty quantification.

The method involves first training a machine learning model to capture the relationship between covariates and outcomes, then using the loss function from this model to define the uncertainty set. The uncertainty set is constructed such that it contains the true outcomes with high probability, ensuring that the robust optimization problem remains feasible while accounting for uncertainty. Theoretical guarantees are provided to ensure that the probability of constraint violation is bounded, and computational experiments demonstrate the practical benefits of the approach.

## Key Results
- Uncertainty sets with radii up to 10x smaller than classical methods while maintaining theoretical guarantees
- Improved objective values and regret across newsvendor, portfolio optimization, and shortest path problems
- Generalization of classical ellipsoidal uncertainty sets to covariate-driven robust optimization
- Theoretical guarantees on probability of constraint violation

## Why This Works (Mechanism)
The mechanism relies on the observation that loss functions in machine learning naturally quantify prediction uncertainty. When a model is trained to minimize a loss function, the magnitude of the loss for a given prediction directly reflects the model's uncertainty about that prediction. By using this loss function to define an uncertainty set, the robust optimization problem can account for both the inherent uncertainty in the problem and the influence of covariates. This approach generalizes classical uncertainty sets by incorporating covariate information, leading to more precise uncertainty quantification.

## Foundational Learning
- **Robust Optimization**: Why needed - Provides a framework for making decisions under uncertainty while ensuring feasibility; Quick check - Can the problem be formulated as minimizing the worst-case objective over an uncertainty set?
- **Uncertainty Sets**: Why needed - Define the range of possible outcomes that must be considered in robust optimization; Quick check - Does the set contain the true outcomes with high probability?
- **Machine Learning Loss Functions**: Why needed - Quantify the uncertainty in predictions based on the data; Quick check - Is the loss function convex and differentiable?
- **Covariate-Driven Robust Optimization**: Why needed - Incorporates external information (covariates) into uncertainty quantification; Quick check - Are the covariates predictive of the uncertainty in the outcomes?
- **Theoretical Guarantees**: Why needed - Ensure that the probability of constraint violation is bounded; Quick check - Does the framework provide probabilistic guarantees on constraint satisfaction?

## Architecture Onboarding

**Component Map:**
ML Model -> Loss Function -> Uncertainty Set -> Robust Optimization Problem

**Critical Path:**
1. Train ML model on data to capture covariate-outcome relationships
2. Use loss function from ML model to construct uncertainty set
3. Formulate robust optimization problem with constructed uncertainty set
4. Solve robust optimization problem to obtain robust decisions

**Design Tradeoffs:**
- Precision vs. tractability: More precise uncertainty sets may lead to computationally intractable optimization problems
- Data requirements: The quality of the uncertainty set depends on the availability and quality of data
- Model choice: The choice of ML model and loss function affects the shape and size of the uncertainty set

**Failure Signatures:**
- Poor performance if the ML model is misspecified or the data is not representative
- Computational intractability if the uncertainty set is too complex
- Over-conservative solutions if the uncertainty set is too large

**First 3 Experiments:**
1. Implement the framework on a simple newsvendor problem with synthetic data to verify theoretical guarantees
2. Compare the performance of different loss functions (e.g., squared loss vs. absolute loss) on a portfolio optimization problem
3. Test the scalability of the approach on a high-dimensional shortest path problem with many covariates

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical framework primarily focuses on linear loss functions, with limited exploration of non-linear losses
- Computational experiments limited to synthetic data and three specific problem types
- No addressing of potential computational challenges for large-scale problems with high-dimensional covariate spaces

## Confidence
- High confidence in theoretical connection between loss functions and uncertainty sets
- Medium confidence in practical performance improvements due to limited experimental scope
- Low confidence in generalizability to complex, real-world optimization problems

## Next Checks
1. Implement and test the proposed method on real-world datasets from domains such as supply chain management or energy systems to assess practical applicability
2. Conduct sensitivity analysis on the choice of loss functions, particularly for non-linear losses, to understand the impact on uncertainty set quality and optimization performance
3. Develop and benchmark scalable algorithms for constructing uncertainty sets in high-dimensional spaces to address potential computational bottlenecks in large-scale applications