---
ver: rpa2
title: Learning Accurate, Efficient, and Interpretable MLPs on Multiplex Graphs via
  Node-wise Multi-View Ensemble Distillation
arxiv_id: '2502.05864'
source_url: https://arxiv.org/abs/2502.05864
tags:
- mgfnn
- mlps
- multiplex
- mgnns
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of combining the accuracy of
  multiplex graph neural networks (MGNNs) with the efficiency of multilayer perceptrons
  (MLPs) for latency-sensitive applications. The authors propose MGFNN and MGFNN+,
  which use knowledge distillation to transfer knowledge from MGNNs to MLPs.
---

# Learning Accurate, Efficient, and Interpretable MLPs on Multiplex Graphs via Node-wise Multi-View Ensemble Distillation

## Quick Facts
- arXiv ID: 2502.05864
- Source URL: https://arxiv.org/abs/2502.05864
- Authors: Yunhui Liu; Zhen Tao; Xiang Zhao; Jianhua Zhao; Tao Zheng; Tieke He
- Reference count: 31
- Primary result: MGFNN+ achieves ~10% accuracy improvement over vanilla MLPs and 35.40×-89.14× inference speedup vs MGNNs

## Executive Summary
This paper addresses the challenge of combining the accuracy of multiplex graph neural networks (MGNNs) with the efficiency of multilayer perceptrons (MLPs) for latency-sensitive applications. The authors propose MGFNN and MGFNN+, which use knowledge distillation to transfer knowledge from MGNNs to MLPs. MGFNN directly uses soft labels from MGNNs as targets, while MGFNN+ introduces a node-wise multi-view ensemble distillation strategy. This strategy employs a low-rank approximation-based reparameterization to learn node-wise coefficients, enabling adaptive knowledge ensemble from each view-specific GNN. The experiments show that MGFNNs achieve average accuracy improvements of about 10% over vanilla MLPs and perform comparably or even better to teacher MGNNs. In terms of efficiency, MGFNNs achieve a 35.40×-89.14× speedup in inference over MGNNs. Additionally, MGFNN+ can learn different ensemble coefficients to distill multiplex semantic knowledge for different nodes interpretably.

## Method Summary
The method trains student MLPs using soft labels from teacher MGNNs via knowledge distillation. MGFNN+ extends this with node-wise multi-view ensemble distillation, learning per-node coefficients to combine predictions from view-specific GNNs. These coefficients are computed through low-rank reparameterization (C=ST) to reduce parameters while maintaining expressiveness. The student MLP is trained only with KL divergence loss weighted by these coefficients, achieving high accuracy while being orders of magnitude faster than MGNNs at inference since it only needs node features.

## Key Results
- MGFNNs achieve average accuracy improvements of about 10% over vanilla MLPs
- MGFNNs perform comparably or even better than teacher MGNNs
- MGFNNs achieve 35.40×-89.14× speedup in inference over MGNNs
- MGFNN+ learns interpretable node-wise ensemble coefficients, showing different nodes benefit differently from each graph view

## Why This Works (Mechanism)

### Mechanism 1: Soft Label Distillation from Teacher MGNNs
- Claim: MLPs can approximate MGNN performance when trained with soft labels containing structural knowledge
- Mechanism: The teacher MGNN encodes graph structure into probability distributions (soft labels) via message passing. The student MLP learns to map node features directly to these distributions, effectively "memorizing" structural patterns without needing graph access at inference
- Core assumption: Node features and structural roles are correlated in real-world tasks
- Evidence anchors: [abstract] "MGFNN directly trains student MLPs with node features as input and soft labels from teacher MGNNs as targets"; [section 4.1] Equation (2): L = λL_CE + (1-λ)L_KL; [corpus] Related work confirms GNN-to-MLP distillation is established for homogeneous graphs

### Mechanism 2: Node-wise Multi-View Ensemble Distillation
- Claim: Using view-specific GNN outputs separately, weighted per-node, captures more semantic knowledge than using only the final integrated MGNN output
- Mechanism: Each view-specific GNN captures distinct structural semantics. Instead of distilling only the final integrated prediction z_v, MGFNN+ distills from each view-specific prediction z_i^v with node-adaptive coefficients c_i^v, preserving fine-grained multiplex semantics
- Core assumption: Different nodes benefit differently from each graph view based on their local structural patterns
- Evidence anchors: [abstract] "MGFNN+ introduces a node-wise multi-view ensemble distillation strategy using low-rank approximation to learn node-specific ensemble coefficients"; [section 4.2, Figure 2] Oracle experiment shows ideal ensemble outperforms MGNN

### Mechanism 3: Low-Rank Reparameterization for Scalable Coefficient Learning
- Claim: Decomposing the node-wise coefficient matrix C = ST reduces parameters from O(n(r+1)) to O((r+1)m + hm) while enabling gradient flow across nodes
- Mechanism: Matrix C is factorized into S (node-dependent, computed from hidden representations via tanh(HW)) and T (node-agnostic base weight-assigners). This allows coefficients to generalize via shared bases rather than learning independent parameters per node
- Core assumption: Node-wise ensemble patterns can be expressed as combinations of a small number of base weight-assigners
- Evidence anchors: [section 4.2] "C = ST... This means that each row of T parameterizes a globally shared view-wise weight-assigner"; [section 4.2] "reduces the parameter complexity of C from O(n × (r+1)) to O((r+1) × m + h × m)"

## Foundational Learning

- Concept: **Knowledge Distillation (Teacher-Student Paradigm)**
  - Why needed here: The entire MGFNN framework relies on transferring knowledge from MGNN teachers to MLP students via soft labels and KL divergence
  - Quick check question: Can you explain why soft labels (probability distributions) contain more information than hard labels (one-hot vectors)?

- Concept: **Multiplex Graph Structure (Multiple Views/Edge Types)**
  - Why needed here: Understanding that the same nodes can have different relationships across views (e.g., Paper-Author-Paper vs. Paper-Subject-Paper) is essential for grasping why view-specific processing matters
  - Quick check question: Given a multiplex graph with 3 edge types, how would a 2-layer MGNN's computational cost compare to a single-view GNN?

- Concept: **Message Passing in GNNs**
  - Why needed here: The efficiency problem stems from neighborhood aggregation requiring feature fetches proportional to node degree and network depth
  - Quick check question: Why does inference time grow exponentially with GNN layers (as shown in Figure 1)?

## Architecture Onboarding

- Component map:
  - **Teacher MGNN**: Pre-trained, frozen. Contains view-specific GNNs (e.g., RSAGE per view) + integration layer
  - **View-specific soft labels**: z_i^v for each view i and node v, plus integrated z_v
  - **Student MLP**: Input = node features X; Output = predictions ŷ_v
  - **Coefficient module**: H (hidden) → S = tanh(HW) → C = ST (node-wise ensemble weights)
  - **Loss**: L = λ·CE(ŷ, y) + (1-λ)·Σ_c_i^v·KL(ŷ, z_i) - γ·H(c)

- Critical path:
  1. Train teacher MGNN to convergence on multiplex graph
  2. Generate soft labels from all view-specific GNNs + integrated output
  3. Initialize student MLP; train with distillation loss (Equation 6)
  4. At inference: MLP takes node features only (no graph access)

- Design tradeoffs:
  - **m (low-rank dimension)**: Search in {1, 2, 3} per paper. Larger m = more expressive but more parameters
  - **λ (hard/soft label weight)**: Paper sets λ=0, finding non-zero values unhelpful (consistent with GLNN)
  - **γ (entropy regularization)**: Prevents coefficient collapse to single view; search in {0.1, 0.01, 0.001}
  - **Teacher architecture**: Works with RSAGE, RGCN, RGAT, HAN (Figure 4)

- Failure signatures:
  - **Inductive setting degradation**: On ArXiv/MAG, production accuracy drops 2-4% below teacher (Table 3), attributed to distribution shift between train/test nodes
  - **Feature noise sensitivity**: Figure 6(a) shows MLP-based methods degrade faster than MGNNs as noise increases
  - **Coefficient collapse**: Without entropy regularization (γ), coefficients may over-emphasize one view (c_i^v > 0.999)

- First 3 experiments:
  1. **Sanity check**: Train vanilla MLP vs. MGFNN (no ensemble) on a small dataset (ACM). Expect ~10-20% accuracy gap favoring MGFNN
  2. **Teacher ablation**: Compare distillation from RSAGE vs. RGCN vs. HAN teachers. Verify MGFNN+ consistently outperforms MGFNN regardless of teacher
  3. **Coefficient visualization**: Extract learned C matrix for sample nodes; verify different nodes have different view importance patterns (replicate Figure 3)

## Open Questions the Paper Calls Out
None

## Limitations
- Low-rank coefficient factorization's robustness to dataset size is unclear - the m ∈ {1, 2, 3} search space may be too narrow for larger graphs
- The paper doesn't report validation metrics during hyperparameter tuning, raising concerns about potential overfitting to test sets
- The inductive setting degradation (2-4% accuracy drop) suggests fundamental limitations when train/test node distributions differ

## Confidence
- **High confidence**: MLP-to-MGNN distillation mechanism (well-established in related work, moderate FMR=0.396)
- **Medium confidence**: Node-wise multi-view ensemble benefits (novel contribution with Oracle experiment support but no corpus validation)
- **Low confidence**: Low-rank coefficient factorization's generalizability (no corpus evidence, theoretical justification only)

## Next Checks
1. **Coefficient diversity audit**: Compute the average entropy of learned coefficients across nodes. Values near 0 indicate collapse to single views, while values near log(r+1) suggest healthy multi-view ensemble
2. **Oracle upper bound validation**: Implement the Oracle ensemble (using ground truth labels to compute optimal coefficients) on a small dataset to verify the paper's claim that it outperforms MGNN by ~10%
3. **Inductive robustness test**: Evaluate MGFNN+ on a synthetic dataset where node features are permuted between train and test sets. If accuracy drops >15%, this confirms the paper's hypothesis that feature-structure correlation is essential