---
ver: rpa2
title: 'Infinite-Instruct: Synthesizing Scaling Code instruction Data with Bidirectional
  Synthesis and Static Verification'
arxiv_id: '2505.23177'
source_url: https://arxiv.org/abs/2505.23177
tags:
- code
- task
- problem
- data
- output
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Infinite-Instruct is an automated framework for synthesizing high-quality
  instruction data for code generation tasks. It addresses the problem of limited
  diversity and poor logic in traditional code instruction data synthesis methods
  by introducing a bidirectional approach: "Reverse Construction" transforms code
  snippets into diverse programming problems, while "Backfeeding Construction" uses
  knowledge graphs to reconstruct problems with stronger internal logic.'
---

# Infinite-Instruct: Synthesizing Scaling Code instruction Data with Bidirectional Synthesis and Static Verification

## Quick Facts
- arXiv ID: 2505.23177
- Source URL: https://arxiv.org/abs/2505.23177
- Reference count: 40
- Key outcome: On mainstream code generation benchmarks, models fine-tuned with Infinite-Instruct data achieve average performance improvements of 21.70% on 7B-parameter models and 36.95% on 32B-parameter models.

## Executive Summary
Infinite-Instruct introduces a bidirectional framework for synthesizing high-quality instruction data for code generation tasks. It addresses the limitations of traditional unidirectional synthesis methods by combining "Reverse Construction" (transforming code snippets into diverse programming problems) with "Backfeeding Construction" (using knowledge graphs to reconstruct problems with stronger internal logic). The framework employs static code analysis to filter invalid samples and GPT-4o quality assessment to ensure data quality, achieving significant performance improvements on mainstream code generation benchmarks while using less than one-tenth of the instruction fine-tuning data.

## Method Summary
The framework synthesizes instruction data through a bidirectional approach using GPT-4o for both prompt synthesis and response generation. It starts with seed code from Magicoder-OSS-Instruct-75K, applies reverse construction to extract problems, and uses backfeeding construction with knowledge graphs to generate additional problems. A 7-dimensional quality assessment filters prompts (threshold ≥6), and static syntax analysis removes invalid code responses. The final dataset is used to fine-tune Qwen2.5-Coder-Base models with specific hyperparameters (LR 2e-5, 3 epochs, batch size 512, cosine annealing, prompt loss mask 0.0, response loss mask 1.0).

## Key Results
- Models fine-tuned with Infinite-Instruct data achieve 21.70% average performance improvement on 7B-parameter models and 36.95% on 32B-parameter models
- Using less than one-tenth of the instruction fine-tuning data achieves performance comparable to Qwen-2.5-Coder-Instruct
- Filtered 90K datasets outperform unfiltered 100K datasets (e.g., 19.30% vs 8.75% improvement on 7B for Backfeed)
- Static-filtered datasets consistently outperform unfiltered versions after quality assessment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Bidirectional synthesis (code→problem and keywords→problem) produces more diverse and logically structured instruction data than unidirectional evolution methods.
- **Mechanism**: Reverse Construction extracts diverse problem formulations from real code snippets, ensuring solvability. Backfeeding Construction extracts task/instruction/knowledge-point keywords, structures them via knowledge graph triples, and reconstructs problems with explicit semantic relationships—addressing the "poor logic" limitation of prior methods.
- **Core assumption**: Real-world code contains implicit problem structures that can be reliably extracted and recombined; keyword relationships map meaningfully to problem difficulty.
- **Evidence anchors**:
  - [abstract]: "Reverse Construction transforms code snippets into diverse programming problems... Backfeeding Construction uses knowledge graphs to reconstruct problems with stronger internal logic"
  - [Section 3.1-3.2]: Reverse synthesis yields ~30K problems; Backfeeding yields ~20K with complexity mean 6.83 vs. OSS-Instruct mean 3.17
  - [corpus]: Neighbor paper "Scaling Code-Assisted Chain-of-Thoughts" confirms code-assisted synthesis improves reasoning, supporting the code→problem direction.
- **Break condition**: If seed code lacks functional diversity or extracted keywords have weak semantic cohesion, reconstructed problems may become incoherent or artificially difficult.

### Mechanism 2
- **Claim**: Seven-dimensional quality assessment filters low-quality prompts before costly response generation.
- **Mechanism**: GPT-4o evaluates each synthesized prompt on specificity, domain knowledge, complexity, problem-solving, creativity, technical accuracy, and practical application (3 assessments averaged, threshold ≥6). This upstream filtering prevents wasting compute on invalid or trivial prompts.
- **Core assumption**: GPT-4o's quality judgments align with downstream training utility; the seven dimensions capture the relevant quality factors for code instruction.
- **Evidence anchors**:
  - [Section 3.3]: "We filter out data with scores less than 6 points... filter out 10K 'reverse' data and 10K 'backfeed' data"
  - [Table 4-5]: Filtered 90K datasets outperform unfiltered 100K datasets (e.g., 19.30% vs 8.75% improvement on 7B for Backfeed)
  - [corpus]: Limited direct corroboration; quality filtering mechanisms are underexplored in neighbor papers.
- **Break condition**: If evaluation model has systematic biases (e.g., favoring verbose prompts), filtering may inadvertently reduce diversity.

### Mechanism 3
- **Claim**: Static syntax analysis removes syntactically invalid code responses, ensuring only compilable examples enter training.
- **Mechanism**: Language-specific linters (PyLint, ESLint, Checkstyle, Clang-Tidy, SQLFluff) detect error-level issues. Invalid prompt-response pairs are discarded entirely rather than repaired, enforcing strict quality bounds.
- **Core assumption**: Syntactic validity correlates with training utility; discarding is better than auto-fixing to avoid introducing synthetic artifacts.
- **Evidence anchors**:
  - [Section 3.4]: "~10,000 out of 100,000 generated responses contained syntax issues"
  - [Table 4]: Static-filtered datasets consistently outperform unfiltered versions
  - [corpus]: Qwen2.5-Coder (cited in paper) uses AST parsing for similar filtering—corroborates the approach.
- **Break condition**: Static analysis cannot detect logical errors or algorithmic bugs; filtered data may still contain semantically incorrect solutions.

## Foundational Learning

- **Concept: Knowledge Graph Construction (Triples: Entity-Relation-Entity)**
  - Why needed here: Backfeeding Construction relies on extracting task/instruction/knowledge-point entities, building relationship triples, and deriving semantically coherent keyword combinations.
  - Quick check question: Given nodes `[user authentication] (task)`, `[password hashing] (instruction)`, `[bcrypt] (knowledge point)`, what triple represents their relationship?

- **Concept: Static Analysis vs. Dynamic Analysis**
  - Why needed here: The framework uses static linters to filter code without execution. Understanding what static analysis can/cannot catch is critical for interpreting quality guarantees.
  - Quick check question: Will PyLint catch a function that returns the wrong value for edge-case inputs? Why or why not?

- **Concept: Instruction Tuning Loss Masking**
  - Why needed here: The paper sets prompt loss mask=0.0 and response loss mask=1.0. Understanding why prevents implementation errors in SFT pipelines.
  - Quick check question: What happens to model behavior if you accidentally set both prompt and response loss masks to 1.0?

## Architecture Onboarding

- **Component map**: Seed Code Repository (Magicoder-OSS-Instruct-75K) → Reverse Construction → Problems → Quality Assessment → Filtered Prompts → Response Generation → Static Analysis → Final Dataset → SFT Training (Qwen2.5-Coder-Base)

- **Critical path**: Reverse/Backfeeding synthesis → Quality filtering → Response generation → Static analysis filtering. Static analysis is the final gate; errors here directly reduce dataset size.

- **Design tradeoffs**:
  - Filtering aggressiveness: Stricter static rules → higher quality but smaller dataset (100K→90K in paper)
  - Complexity target: Backfeed (mean 6.83) vs. Reverse (mean 5.85)—choose based on model capacity and training stage
  - Repair vs. discard: Paper chooses discard; repair could recover data but risks introducing artifacts

- **Failure signatures**:
  - High discard rate (>20%) suggests response generator quality issues
  - Low complexity variance suggests keyword combinations lack diversity
  - Benchmark performance plateau suggests filtered dataset lacks coverage

- **First 3 experiments**:
  1. **Ablation on filtering threshold**: Train with quality score thresholds [4, 5, 6, 7] on a small model (1B-3B) to validate 6-point cutoff before full training runs.
  2. **Reverse vs. Backfeed mixing ratio**: Test 100% Reverse, 100% Backfeed, 50/50, 70/30 on complexity benchmarks to confirm paper's implicit 50/50 split.
  3. **Static analysis strictness levels**: Compare "error-only" filtering vs. "error+info" filtering to quantify the quality-vs-quantity tradeoff on held-out validation sets.

## Open Questions the Paper Calls Out
None

## Limitations
- The bidirectional synthesis approach relies heavily on seed code quality and semantic coherence of extracted keyword triples, which may not generalize across different programming domains or language families.
- Static analysis filtering cannot detect logical or algorithmic flaws, potentially leaving semantically incorrect solutions in the training data.
- The 7-dimensional quality assessment using GPT-4o introduces significant dependency on a proprietary model whose evaluation criteria may not perfectly align with downstream training utility.

## Confidence
- **High confidence**: The static analysis filtering mechanism and its documented impact on performance (20% reduction to achieve measurable improvements) are well-supported by empirical results and corroborated by the use of similar approaches in Qwen2.5-Coder.
- **Medium confidence**: The bidirectional synthesis methodology shows clear improvements over unidirectional approaches, but the complexity calibration between Reverse (mean 5.85) and Backfeed (mean 6.83) construction remains somewhat arbitrary and may require domain-specific tuning.
- **Medium confidence**: The 7-dimensional quality assessment effectively filters low-quality prompts, but the reliance on GPT-4o evaluation introduces uncertainty about whether these judgments translate optimally to downstream model performance across diverse code generation scenarios.

## Next Checks
1. **Ablation study on quality assessment thresholds**: Systematically test quality score cutoffs at 4, 5, 6, and 7 points on a small 1B-3B model to empirically validate the optimal filtering threshold and quantify the quality-vs-quantity tradeoff.

2. **Cross-domain generalization test**: Apply the framework to a non-Python language (e.g., C++ or Rust) with different static analysis tools to verify whether the bidirectional synthesis approach and complexity calibration transfer effectively across programming ecosystems.

3. **Semantic correctness evaluation**: Implement a dynamic analysis phase using test harnesses to measure the logical correctness of filtered code samples, distinguishing between syntax-valid but semantically incorrect solutions that static analysis cannot detect.