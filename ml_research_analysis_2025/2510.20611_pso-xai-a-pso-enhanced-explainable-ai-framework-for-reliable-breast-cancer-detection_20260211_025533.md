---
ver: rpa2
title: 'PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer
  Detection'
arxiv_id: '2510.20611'
source_url: https://arxiv.org/abs/2510.20611
tags:
- feature
- cancer
- selection
- accuracy
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a PSO-enhanced explainable AI framework for
  breast cancer detection, addressing limitations in traditional diagnostic methods.
  The framework integrates Particle Swarm Optimization (PSO) for feature selection
  with 29 machine learning models, employing explainable AI techniques and rigorous
  cross-validation.
---

# PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection

## Quick Facts
- **arXiv ID**: 2510.20611
- **Source URL**: https://arxiv.org/abs/2510.20611
- **Reference count**: 40
- **Primary result**: PSO-enhanced framework achieves 99.1% accuracy, precision, and F1-score for breast cancer detection

## Executive Summary
This study proposes a PSO-enhanced explainable AI framework for breast cancer detection, addressing limitations in traditional diagnostic methods. The framework integrates Particle Swarm Optimization (PSO) for feature selection with 29 machine learning models, employing explainable AI techniques and rigorous cross-validation. PSO reduces dimensionality while optimizing accuracy and interpretability, achieving 99.1% accuracy, precision, and F1-score. The approach demonstrates statistically significant improvements over baseline models and provides transparent, clinically relevant explanations using SHAP. Key features like concave points and tumor area are identified as critical predictors. This framework offers a robust, generalizable solution for reliable, interpretable breast cancer diagnosis, enhancing clinical decision-making and patient outcomes.

## Method Summary
The framework preprocesses the Wisconsin Diagnostic Breast Cancer dataset through outlier detection, winsorization, and normalization, then applies PSO-based feature selection to identify optimal feature subsets (3-12 features) that balance accuracy and interpretability. PSO encodes feature subsets as continuous vectors, with particles updating positions based on velocity, cognitive, and social components. The fitness function balances classification accuracy (α=0.8) and interpretability (β=0.2), evaluated using 29 machine learning models. Top performers include MLP, Linear SVC, KNN, and LightGBM, validated through 10-fold stratified cross-validation and SHAP analysis for feature importance interpretation.

## Key Results
- Achieved 99.1% accuracy, precision, and F1-score across all evaluation metrics
- PSO-selected features (typically 12) significantly outperformed baseline models with p<0.05 statistical significance
- SHAP analysis identified concave points and tumor area as most critical predictors, aligning with clinical knowledge
- Framework demonstrates robustness through cross-validation and provides transparent, interpretable explanations for clinical decision-making

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: PSO-based feature selection improves classifier performance by discovering optimal feature subsets that balance discriminative power with model interpretability.
- **Mechanism**: Particles encode candidate feature subsets as continuous vectors in [0,1]^d space, with threshold θ=0.3 determining binary selection. The population-based search simultaneously explores C(30,k) combinations across iterations, discovering feature interactions that single-trajectory methods miss. Each particle's fitness is evaluated by training an ML classifier on the selected subset, creating a feedback loop that rewards predictive accuracy while penalizing complexity.
- **Core assumption**: The optimal feature subset lies in a tractable region of the 2^30 search space that PSO can converge to within 25 iterations with 20 particles.
- **Evidence anchors**:
  - [abstract]: "PSO reduces dimensionality while optimizing accuracy and interpretability, achieving 99.1% accuracy"
  - [section III.C]: "PSO-selected features exhibit higher mutual information I(S*;y) > I(S_random;y), mathematically justifying performance improvements"
  - [corpus]: Neighbor papers use XAI for breast cancer but lack systematic feature optimization comparison
- **Break condition**: If baseline models already achieve >98% accuracy on full features, PSO improvements may be marginal. Dataset-specific optimization may not transfer to external cohorts.

### Mechanism 2
- **Claim**: The multi-objective fitness function creates a Pareto-optimal trade-off between classification accuracy and clinical interpretability requirements.
- **Mechanism**: Fitness_i = 1 - (α·Accuracy_i + β·Interpretability_i) with α=0.8, β=0.2. The interpretability component (1 - |S_i|/|F|) penalizes large feature subsets. Constraint enforcement (3 ≤ |S_i| ≤ 12) ensures clinically actionable models. This transforms the combinatorial optimization into a guided search where particles balance two competing objectives.
- **Core assumption**: Medical diagnosis applications tolerate slight accuracy decreases in exchange for simpler, more interpretable models.
- **Evidence anchors**:
  - [section III.C.1]: "α=0.8 emphasizes accuracy and β=0.2 promotes interpretability... prioritizing classification performance while maintaining model simplicity"
  - [section III.C.4]: "3 and 12 features determined based on medical domain expertise and computational efficiency"
  - [corpus]: Weak explicit evidence for this specific weighting scheme in related work
- **Break condition**: If α/β weights don't reflect actual clinical priorities, the optimal subset may sacrifice too much accuracy or remain too complex.

### Mechanism 3
- **Claim**: SHAP-based explainability validates that PSO-selected features align with clinically known breast cancer predictors, enabling physician trust.
- **Mechanism**: SHAP (SHapley Additive exPlanations) computes feature contributions by measuring marginal contributions across all possible feature coalitions. For the MLP classifier, SHAP values quantify how each feature pushes predictions toward malignant or benign. Features with wide SHAP value distributions (high variance) indicate strong, context-dependent effects on model decisions.
- **Core assumption**: Clinically interpretable features should show both high SHAP importance and alignment with established oncological knowledge.
- **Evidence anchors**:
  - [abstract]: "Key features like concave points and tumor area are identified as critical predictors"
  - [section IV.F]: "concave points (worst) is the most crucial feature, with SHAP values ranging from approximately -0.1 to +0.3"
  - [corpus]: Neighbor paper "Bridging Accuracy and Interpretability" similarly uses XAI for breast cancer detection validation
- **Break condition**: If SHAP identifies features without clinical rationale, the explainability may not translate to physician adoption.

## Foundational Learning

- **Concept**: Particle Swarm Optimization fundamentals
  - **Why needed here**: Understanding velocity/position updates, inertia weight decay, and cognitive/social coefficients is essential before modifying the feature selection algorithm.
  - **Quick check question**: What happens to exploration vs. exploitation when inertia weight decreases from 0.9 to 0.4 over iterations?

- **Concept**: Feature selection vs. feature extraction
  - **Why needed here**: PSO performs feature selection (subset selection) not extraction (dimensionality reduction via transformation). This preserves original feature meanings for clinical interpretation.
  - **Quick check question**: Why would PCA-selected components be harder for clinicians to interpret than PSO-selected original features?

- **Concept**: Shapley values from cooperative game theory
  - **Why needed here**: SHAP builds on Shapley values to fairly distribute "prediction credit" among features. Understanding the coalition-based approach clarifies why SHAP is model-agnostic.
  - **Quick check question**: If features A and B are perfectly correlated, what would you expect their SHAP values to look like?

## Architecture Onboarding

- **Component map**:
  Raw dataset (569 × 32) → Preprocessing → PSO Feature Selector → Model Training → Validation → Output

- **Critical path**: PSO fitness evaluation (line 15-18 in Algorithm 1) is the bottleneck—each particle trains a full ML model per iteration. With 20 particles × 25 iterations × 29 classifiers = 14,500 model trainings. Start with fewer classifiers during development.

- **Design tradeoffs**:
  - Population size (20) vs. iteration count (25): More particles improve diversity but increase compute. Authors chose smaller population with moderate iterations.
  - Feature subset constraints (3-12): Too few features may underfit; too many reduce interpretability gain.
  - Fitness weights (α=0.8, β=0.2): Heavy accuracy emphasis may miss clinically simpler models.

- **Failure signatures**:
  - **No improvement over baseline**: Check if dataset is already well-separated; PSO gains diminish when baseline >98%.
  - **Inconsistent feature selection across runs**: PSO may converge to different local optima—fix random seeds for reproducibility.
  - **High variance in cross-validation**: Selected features may be dataset-specific; reduce feature count or increase regularization.
  - **SHAP values near zero for all features**: Model may not be learning—check data leakage or scaling issues.

- **First 3 experiments**:
  1. **Reproduce single-classifier PSO**: Run Algorithm 1 with only Logistic Regression. Verify feature subset reduces from 30 to ~12 while maintaining baseline accuracy. Compare selected features against Table IV.
  2. **Ablate fitness function components**: Test α=1.0, β=0 (accuracy only) vs. α=0.5, β=0.5. Measure trade-off between final accuracy and feature count to validate the 0.8/0.2 weighting.
  3. **Cross-dataset validation**: Apply the PSO-selected 12-feature subset to an independent breast cancer dataset (e.g., Coimbra dataset mentioned in related work). If accuracy drops significantly, the selection is dataset-specific—flag for external validation requirement.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the proposed PSO-enhanced framework maintain high interpretability and accuracy when applied to multi-modal datasets combining genomic data and medical imaging?
- **Basis in paper**: [explicit] The conclusion states that future work will focus on "extending the framework to multi-modal datasets, such as genomic and imaging data."
- **Why unresolved**: The current study validated the framework exclusively on the Wisconsin Diagnostic Breast Cancer (WDBC) dataset, which consists of numerical features derived from fine needle aspirates, rather than raw images or complex genomic sequences.
- **What evidence would resolve it**: Demonstration of the framework's performance and SHAP-based explainability on datasets containing paired histopathology images and genomic markers.

### Open Question 2
- **Question**: How does the framework perform in real-world clinical deployment regarding scalability and integration with hospital systems?
- **Basis in paper**: [explicit] The authors explicitly identify the need for "validating the approach in real-world clinical environments to assess its scalability, robustness, and trustworthiness for deployment in healthcare systems."
- **Why unresolved**: The reported 99.1% accuracy is derived from a controlled benchmark environment using cross-validation on a static dataset, which does not account for the noise, variability, and integration challenges of live clinical workflows.
- **What evidence would resolve it**: Results from prospective clinical trials or pilot programs measuring system latency, user acceptance by radiologists, and performance on live patient data streams.

### Open Question 3
- **Question**: Does the PSO-selected feature subset generalize effectively to independent, external cohorts outside the WDBC benchmark?
- **Basis in paper**: [inferred] While the authors claim the framework is "generalizable," the Related Works section critiques existing literature for relying on benchmark datasets "without sufficient external validation across independent cohorts," a limitation present in this study which uses only WDBC.
- **Why unresolved**: It is unclear if the specific 12 features selected by PSO (e.g., `concave points worst`) are universally optimal for breast cancer detection or if they are overfitted to the specific population characteristics of the WDBC dataset.
- **What evidence would resolve it**: Testing the pre-trained PSO-optimized models on external datasets (e.g., the Coimbra dataset) without retraining the feature selection process to verify consistent performance.

## Limitations
- PSO optimization is inherently local rather than global, potentially missing optimal feature subsets in the 2^30 search space
- WDBC dataset contains only 569 samples with limited clinical diversity, raising questions about external validity
- PSO constraints (3-12 features) are based on domain expertise but may not generalize to other medical imaging modalities

## Confidence
- **High confidence** (80-90%): The PSO mechanism itself and its integration with ML models. The algorithm structure and parameter ranges are clearly specified.
- **Medium confidence** (60-70%): The 99.1% performance metrics. While the cross-validation approach is sound, the small dataset size means results may vary significantly with different seeds or data splits.
- **Low confidence** (40-50%): Clinical interpretability claims. SHAP visualization provides explanations, but the alignment with actual clinical decision-making processes requires physician validation.

## Next Checks
1. **Cross-dataset generalization test**: Apply the PSO-selected 12-feature subset to an independent breast cancer dataset (e.g., Coimbra dataset). If accuracy drops >5%, flag for external validation requirement before clinical deployment.

2. **SHAP-clinical alignment validation**: Have 3-5 oncologists review SHAP-identified top features (concave points, area) against their clinical experience. Document agreement/disagreement rates to quantify explainability utility.

3. **Robustness to initialization**: Run PSO 10 times with different random seeds on the same data. Measure feature subset stability (Jaccard similarity) and performance variance. If Jaccard <0.7, consider ensemble PSO approaches.