---
ver: rpa2
title: 'SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem'
arxiv_id: '2505.21887'
source_url: https://arxiv.org/abs/2505.21887
tags:
- single
- depot
- routing
- time
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SVRPBench introduces the first open benchmark suite for stochastic
  vehicle routing under realistic urban uncertainty. It models time-dependent congestion,
  log-normal delays, probabilistic accidents, and heterogeneous time windows grounded
  in empirical logistics data, spanning 500+ instances up to 1000 customers.
---

# SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem

## Quick Facts
- arXiv ID: 2505.21887
- Source URL: https://arxiv.org/abs/2505.21887
- Reference count: 40
- Open benchmark suite for stochastic vehicle routing under realistic urban uncertainty, modeling time-dependent congestion, log-normal delays, probabilistic accidents, and heterogeneous time windows.

## Executive Summary
SVRPBench introduces the first open benchmark suite for stochastic vehicle routing under realistic urban uncertainty. It models time-dependent congestion, log-normal delays, probabilistic accidents, and heterogeneous time windows grounded in empirical logistics data, spanning 500+ instances up to 1000 customers. Evaluation shows classical solvers (OR-Tools, NN+2opt) remain highly feasible (>97%) and robust, while RL methods (POMO, Attention) suffer >20% cost degradation under distributional shift and struggle with multi-depot generalization. Multi-depot setups consistently improve cost and feasibility across all solver types. The dataset and evaluation suite are publicly released on Hugging Face and GitHub to enable reproducible research and community-driven advancements in robust routing algorithms.

## Method Summary
SVRPBench provides 500+ instances (10–1000 customers) on Hugging Face, including single/multi-depot and vehicle configurations. The benchmark models stochastic vehicle routing with time-dependent congestion, log-normal delays, probabilistic accidents, and time windows. Evaluation metrics include Total Cost (TC), Feasibility Rate (FR), and Constraint Violation Rate (CVR). Baselines include OR-Tools, NN+2opt, ACO, and Tabu Search, while RL methods POMO and Attention are trained via the RL4CO framework. Stochastic parameters are explicitly defined, and travel time matrices are generated using equations modeling urban uncertainty.

## Key Results
- Classical solvers (OR-Tools, NN+2opt) maintain >97% feasibility under stochastic conditions.
- RL methods (POMO, Attention) suffer >20% cost degradation under distributional shift.
- Multi-depot setups consistently improve cost and feasibility across all solver types.

## Why This Works (Mechanism)
SVRPBench addresses the gap in realistic stochastic routing benchmarks by incorporating empirically grounded urban uncertainty models, including time-dependent congestion, log-normal delays, and probabilistic accidents. The benchmark's strength lies in its comprehensive evaluation framework, which measures not only cost but also feasibility and robustness across multiple solver types. The inclusion of heterogeneous time windows and multi-depot configurations provides a realistic testbed for evaluating algorithm performance under complex constraints.

## Foundational Learning
- **Stochastic Vehicle Routing Problem (SVRP):** Routing with probabilistic travel times and delays; needed to model real-world uncertainty in logistics.
- **Time-Dependent Congestion:** Travel times vary by time of day; critical for urban routing realism.
- **Log-normal Delay Modeling:** Captures skewed delay distributions; more realistic than Gaussian assumptions.
- **Feasibility vs. Cost Trade-off:** Balancing optimal routes with constraint satisfaction; essential for practical deployment.
- **Distributional Shift:** Performance drop when test data differs from training data; key challenge for RL methods.
- **Multi-depot Routing:** Multiple depots improve flexibility and cost; important for large-scale logistics.

## Architecture Onboarding

**Component Map:**
Data Generation -> Instance Storage (Hugging Face) -> Solver Evaluation -> Metric Aggregation

**Critical Path:**
Generate stochastic instances → Evaluate solvers (classical/RL) → Compute TC, FR, CVR → Analyze robustness

**Design Tradeoffs:**
- Realistic uncertainty modeling vs. computational tractability
- Single vs. multi-depot configurations for scalability
- Classical heuristics vs. RL for generalization under distributional shift

**Failure Signatures:**
- RL methods: >20% cost degradation, lower feasibility under distributional shift
- Metaheuristics: Feasibility crashes on TWVRP (~38%)
- Classical solvers: High feasibility (>97%) but potentially suboptimal cost

**First Experiments:**
1. Run OR-Tools on 100-customer TWVRP instances; verify feasibility >97%.
2. Evaluate POMO on multi-depot instances; measure cost degradation vs. single-depot.
3. Compare ACO vs. Tabu Search on CVRP vs. TWVRP; document feasibility gap.

## Open Questions the Paper Calls Out

**Open Question 1:** How do current solvers perform when transitioning from Euclidean distances to road-constrained instances derived from OpenStreetMap or GIS data?
- Basis: Authors state future extensions will incorporate road-constrained instances from OpenStreetMap or GIS data.
- Why unresolved: Current instances use Euclidean distances and clustered city layouts, not actual road network topologies.
- Evidence needed: Benchmarking existing solvers on proposed road-network instances to evaluate feasibility and runtime degradation.

**Open Question 2:** How can routing algorithms be evaluated for real-time adaptability in dynamic, multi-day settings with rolling horizons?
- Basis: Current evaluation lacks dynamic and multi-day settings with online updates and rolling horizons.
- Why unresolved: Benchmark focuses on a priori optimization, ignoring online corrective actions.
- Evidence needed: Development of a new evaluation suite supporting re-optimization events triggered by dynamic changes.

**Open Question 3:** Can stochastic benchmarks better capture network-level dynamics, such as cascading congestion or bottlenecks, rather than isolated probabilistic delays?
- Basis: Current models rely on Gaussian and log-normal distributions, unable to capture network-level dynamics like bottlenecks or cascading congestion.
- Why unresolved: Independent edge-based stochastic models fail to simulate delay propagation through the network.
- Evidence needed: Integrating dependency structures where delays on specific edges correlate with delays on adjacent or downstream edges.

## Limitations
- Fidelity of synthesized data to actual urban traffic patterns remains unverified without independent validation on real-world datasets.
- Exact random seeds for instance generation are not specified, affecting reproducibility.
- Performance comparisons may be influenced by unspecified implementation details, particularly for OR-Tools and LKH3.

## Confidence

**High Confidence:** Classical solvers maintain >97% feasibility under stochastic conditions.
**Medium Confidence:** RL methods suffer >20% cost degradation under distributional shift.
**Medium Confidence:** Multi-depot setups consistently improve performance.

## Next Checks

1. **Instance Generation Reproducibility:** Verify instance generation using published parameters on Hugging Face; check if results match reported metrics across different random seeds.
2. **Solver Configuration Verification:** Test OR-Tools and LKH3 with specified time limits against benchmark instances; confirm feasibility rates and cost metrics.
3. **Distribution Shift Impact:** Systematically evaluate RL methods (POMO, Attention) on progressively shifted distributions from training data; quantify generalization bounds beyond reported >20% degradation.