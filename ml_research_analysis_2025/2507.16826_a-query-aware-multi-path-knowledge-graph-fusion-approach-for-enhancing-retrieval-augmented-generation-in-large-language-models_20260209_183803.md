---
ver: rpa2
title: A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented
  Generation in Large Language Models
arxiv_id: '2507.16826'
source_url: https://arxiv.org/abs/2507.16826
tags:
- query
- subgraph
- arxiv
- semantic
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QMKGF is a Retrieval-Augmented Generation approach that improves
  LLM response quality by integrating multi-path knowledge graph fusion. It extracts
  entities and relations from queries using LLMs, constructs knowledge graphs, and
  builds subgraphs through one-hop, multi-hop, and importance-based relations.
---

# A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented Generation in Large Language Models

## Quick Facts
- arXiv ID: 2507.16826
- Source URL: https://arxiv.org/abs/2507.16826
- Reference count: 40
- Primary result: Achieves 64.98% ROUGE-1 score on HotpotQA, surpassing BGE-Rerank by 9.72 percentage points

## Executive Summary
QMKGF is a Retrieval-Augmented Generation approach that improves LLM response quality by integrating multi-path knowledge graph fusion. It extracts entities and relations from queries using LLMs, constructs knowledge graphs, and builds subgraphs through one-hop, multi-hop, and importance-based relations. A query-aware attention reward model scores subgraph triples by semantic relevance, enabling effective fusion and query expansion. Evaluated on SQuAD, IIRC, Culture, HotpotQA, and MuSiQue, QMKGF demonstrates significant improvements in retrieval accuracy and generated content quality.

## Method Summary
The approach constructs a knowledge graph from document corpora using LLMs, then extracts entities from user queries and maps them to KG nodes. It builds three types of subgraphs (one-hop, multi-hop, and PageRank-based) around each mapped entity. A query-aware attention reward model scores these subgraphs based on semantic relevance to the query, selects the highest-scoring subgraph, and fuses it with semantically similar triples from other subgraphs. The fused subgraph's entities, relations, and triples are then used to expand the original query for enhanced retrieval and generation.

## Key Results
- Achieves 64.98% ROUGE-1 score on HotpotQA benchmark
- Outperforms BGE-Rerank by 9.72 percentage points
- Demonstrates improved semantic relevance and reduced noise in generated responses
- Shows effectiveness across multiple datasets including SQuAD, IIRC, Culture, and MuSiQue

## Why This Works (Mechanism)

### Mechanism 1: Multi-Path Subgraph Construction for Diverse Semantic Capture
The approach improves retrieval relevance by constructing three distinct types of subgraphs (one-hop, multi-hop, and importance-based) around entities identified in the query, thereby capturing diverse semantic evidence. This multi-path strategy surfaces relevant information that a single retrieval path might miss.

### Mechanism 2: Query-Aware Attention Reward Model for Noise Reduction
A dedicated reward model, trained with a query-aware attention mechanism, can effectively score and filter subgraph triples based on their semantic relevance to the specific query, reducing noise before fusion. This forces the model to prioritize triples and subgraphs whose semantic content aligns with the query's intent.

### Mechanism 3: Subgraph Fusion and Query Expansion for Holistic Context
Fusing high-scoring triples from multiple subgraphs and using the resulting structure to expand the query leads to more comprehensive and semantically rich retrieval, which in turn improves generation quality. This composite approach provides context that a single path cannot provide.

## Foundational Learning

- **Concept: Knowledge Graph (KG)**
  - Why needed here: The entire QMKGF framework is built on top of a Knowledge Graph. Without understanding what a KG is, the core data structure and retrieval logic are unintelligible.
  - Quick check question: If you have a set of documents about "Apple Inc." and "apples" (the fruit), what might be some nodes and edges in a Knowledge Graph constructed from them, and how would you distinguish the two concepts?

- **Concept: Query Expansion**
  - Why needed here: QMKGF's final retrieval step is not based on the original query alone, but on an "expanded" query enriched with entities, relations, and triples from the fused KG subgraph.
  - Quick check question: Given a user query "When was the CEO of Apple born?", what are some entities and relations from a KG that could be added to this query to form an expanded query?

- **Concept: Attention Mechanism in Transformers**
  - Why needed here: The Query-Aware Reward Model uses a specific attention mechanism where the query (Q) attends to the subgraph representation (K, V).
  - Quick check question: In a simple attention calculation, what is the purpose of the "Key" vector, and how is it used in relation to the "Query" vector?

## Architecture Onboarding

- **Component map:** Offline KG Construction -> Entity Mapping -> Multi-Path Subgraph Construction -> Subgraph Fusion -> Query Expansion & Retrieval
- **Critical path:** Entity extraction and mapping accuracy → Quality of the multi-path subgraphs → Effectiveness of the Reward Model in scoring and filtering → Effectiveness of query expansion in improving retrieval recall without adding noise
- **Design tradeoffs:** KG Complexity vs. Cost (LLM-based extraction is rich but costly), Multi-path Breadth vs. Noise (three-path strategy maximizes information but increases candidates for noise), RM Training Effort (substantial one-time effort vs. using off-the-shelf reranker)
- **Failure signatures:** Retrieval returns irrelevant documents (poor entity mapping, poorly trained RM, threshold τ too low), Generated answers factually incorrect (final LLM synthesis issue or query expansion introduces misleading information), System very slow (KG construction bottleneck)
- **First 3 experiments:**
  1. Entity Mapping Ablation: Evaluate accuracy of initial entity extraction and mapping step by manually checking if entities extracted from sample queries are correctly mapped to relevant KG nodes
  2. Reward Model Evaluation: Test trained Reward Model in isolation by feeding it subgraphs of known relevance and measuring classification accuracy or ranking correlation
  3. End-to-End Baseline Comparison: Run full QMKGF pipeline on benchmark dataset and compare ROUGE/BLEU scores against paper's reported baselines to confirm functional implementation

## Open Questions the Paper Calls Out

- How can the QMKGF framework be adapted to construct and utilize domain-specific knowledge graphs tailored to specialized data characteristics? (Future work will explore construction of more domain-specific knowledge graphs)
- How can causal relationship modeling and event chain mechanisms be integrated into the subgraph fusion process to enhance reasoning capabilities? (Integration of causal relationship modeling and event chain is outlined as future research direction)
- What is the computational latency overhead of the multi-path subgraph construction and Reward Model inference compared to standard RAG methods in real-time applications? (Paper does not analyze scalability or retrieval latency on full corpora)

## Limitations
- KG Quality Dependency: The pipeline relies heavily on accurate entity extraction and mapping from initial LLM processing
- Training Data for Reward Model: Method for generating training data (LLM scoring rubric, number of examples) is not specified
- Computational Overhead: Multi-path subgraph construction and RM scoring add significant latency compared to standard RAG

## Confidence

- **High**: Multi-path subgraph construction mechanism and theoretical basis for capturing diverse semantic evidence
- **High**: Query-aware attention mechanism design for the reward model
- **Medium**: Effectiveness of subgraph fusion and query expansion in improving downstream RAG performance
- **Low**: Reproducibility of exact implementation details for KG construction, RM training data generation, and threshold optimization

## Next Checks

1. **Entity Mapping Accuracy Test**: Manually validate entity extraction and KG mapping accuracy on a sample of 50 queries from a target dataset to quantify the error rate in the critical first step
2. **Reward Model Ablation**: Implement a simplified baseline that skips the RM and uses only one-hop subgraphs. Compare performance to full multi-path fusion to isolate the RM's contribution
3. **Threshold Sensitivity Analysis**: Run full pipeline across range of fusion thresholds τ on validation set and plot performance curves to identify optimal values and stability