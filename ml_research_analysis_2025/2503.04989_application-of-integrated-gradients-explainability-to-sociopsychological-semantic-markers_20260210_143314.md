---
ver: rpa2
title: Application of integrated gradients explainability to sociopsychological semantic
  markers
arxiv_id: '2503.04989'
source_url: https://arxiv.org/abs/2503.04989
tags:
- agency
- baseline
- text
- which
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of explaining how sociopsychological
  semantic markers, beyond sentiment, are classified at the word level in text. The
  authors use the integrated gradients (IG) method to reveal which words contribute
  most to classification decisions in a pre-trained agency classifier (BERTAgent).
---

# Application of integrated gradients explainability to sociopsychological semantic markers

## Quick Facts
- **arXiv ID**: 2503.04989
- **Source URL**: https://arxiv.org/abs/2503.04989
- **Reference count**: 40
- **Primary result**: Integrated gradients reliably explains sociopsychological semantic markers in text at the word level, with zero baseline and 300 integration steps optimal.

## Executive Summary
This paper investigates how to explain the classification of sociopsychological semantic markers—beyond simple sentiment—at the word level in text. Using the integrated gradients (IG) method, the authors systematically evaluate how different IG parameters affect the identification of salient words in a pre-trained agency classifier. They compare IG against alternative explanation methods (DeepLIFT, GradientSHAP) and demonstrate that IG with zero baseline and 300 integration steps provides the most faithful and interpretable explanations. By intentionally overfitting models on limited data, the authors showcase how IG can reveal gender, emotion, and objectification cues in textual data, offering actionable insights for dictionary building and theory development in sociopsychological research.

## Method Summary
The authors use the integrated gradients method to explain word-level contributions to sociopsychological text classification. They systematically test IG parameters—baseline choice and number of integration steps—and compare IG to DeepLIFT and GradientSHAP in terms of faithfulness metrics (comprehensiveness, sufficiency) and approximation error. Models are intentionally overfitted to small datasets to highlight salient words for each class, enabling the identification of sociopsychological cues such as gender, emotion, and objectification.

## Key Results
- IG with zero baseline and 300 integration steps yields the most faithful and interpretable explanations.
- IG outperforms or matches DeepLIFT and GradientSHAP on faithfulness metrics and approximation error.
- Salient words identified via IG align with known sociopsychological markers (gender, emotion, objectification) in textual data.
- Overfitting models on limited data reveals class-specific cues useful for dictionary building.

## Why This Works (Mechanism)
Integrated gradients attribute classification decisions to individual words by integrating gradients along a path from a baseline (e.g., zero) to the input. This approach provides a principled, theoretically grounded way to quantify word importance, making it well-suited for uncovering sociopsychological markers that are not captured by sentiment alone.

## Foundational Learning
- **Integrated Gradients**: A gradient-based attribution method that integrates gradients along a path from baseline to input. *Why needed*: Provides theoretically grounded word-level importance scores. *Quick check*: Does increasing integration steps improve explanation fidelity?
- **Baseline Selection**: Choice of reference input (e.g., zero, random) affects IG attributions. *Why needed*: Baseline defines what "absence" means for each feature. *Quick check*: Compare attributions across different baselines.
- **Faithfulness Metrics**: Measures like comprehensiveness and sufficiency assess explanation quality. *Why needed*: Quantify how well explanations reflect true model behavior. *Quick check*: Do faithfulness scores correlate with human interpretability?
- **Overfitting for Interpretability**: Intentionally overfitting on small data to expose salient patterns. *Why needed*: Forces models to rely on few, highly informative words. *Quick check*: Do salient words generalize across datasets?

## Architecture Onboarding
- **Component Map**: Text input → BERTAgent model → IG attribution → Salient words
- **Critical Path**: Model prediction → IG integration (baseline + steps) → Attribution → Analysis
- **Design Tradeoffs**: More integration steps improve fidelity but increase computation; zero baseline is interpretable but may miss subtle cues.
- **Failure Signatures**: Low faithfulness scores; attributions inconsistent across baselines; salient words unrelated to sociopsychological theory.
- **3 First Experiments**: (1) Vary IG integration steps and measure faithfulness; (2) Compare baselines (zero vs. random) for IG; (3) Test IG on a different sociopsychological dimension (e.g., communion).

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to a single model (BERTAgent) and one sociopsychological dimension (agency).
- Faithfulness metrics do not assess robustness to adversarial inputs or semantic drift.
- Overfitting scenario uses artificially constrained data, not reflecting realistic deployment.
- Results may not generalize to other models, tasks, or semantic markers.

## Confidence
- Core methodological contribution: **Medium** (careful experimental design, limited external validity)
- Broader applicability: **Low** (narrow experimental scope, lack of external validation)

## Next Checks
1. Test IG explainability across multiple sociopsychological dimensions (e.g., communion, emotion, objectification) and models (e.g., RoBERTa, GPT variants).
2. Evaluate robustness of IG explanations under data perturbations, adversarial examples, and domain shifts.
3. Benchmark IG against post-hoc human interpretability studies to assess alignment with expert or crowdworker judgments.