---
ver: rpa2
title: 'The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition
  Trials of Standard Multiple-Choice Benchmarks'
arxiv_id: '2509.09705'
source_url: https://arxiv.org/abs/2509.09705
tags:
- consistency
- questions
- accuracy
- answers
- sure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper defines answer consistency for LLMs as oracle-level
  correctness and evaluates it using repeated multiple-choice trials. It proposes
  RWS|S/T metrics and consistency plots for visualization.
---

# The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks

## Quick Facts
- arXiv ID: 2509.09705
- Source URL: https://arxiv.org/abs/2509.09705
- Reference count: 5
- Key outcome: Small LLMs (2B-8B) show 50-80% consistency at low temperatures, while medium models (50B-80B) show >95% consistency on repeated multiple-choice trials.

## Executive Summary
This paper defines answer consistency for LLMs using a novel "oracle-based" framework and evaluates it through repeated multiple-choice trials. The authors propose RWS|S/T metrics (Right When Sure ratio and Sure/Total percentage) and consistency plots for visualization. Experiments with 26 small and medium models on MMLU-Redux and MedQA benchmarks reveal that small models achieve 50-80% consistency at low temperatures, with accuracy among consistent answers correlating reasonably well with overall accuracy. Medium models display >95% consistency. The study finds that increasing temperature improves accuracy among consistent answers for general knowledge tasks but not for medical ones, suggesting a precision-coverage tradeoff modulated by temperature.

## Method Summary
The paper evaluates LLM answer consistency by running 10 repetitions per question using top-K sampling with temperatures of 0.3, 0.7, and 1.0. Each model answers questions from MMLU-Redux (4-choice) and MedQA (5-choice) benchmarks. The first-line letter response is parsed from each output, and questions are classified as SURE (≥9 identical answers out of 10) or UNSURE. RWS (accuracy among SURE questions) and S/T (percentage of SURE questions) metrics are computed and visualized through consistency plots. The study uses max_new_tokens=3 for efficiency and applies a specific prompt template requesting the answer letter on the first line.

## Key Results
- Small models (2B-8B) achieve 50-80% S/T consistency at low temperatures (t=0.3), while medium models (50B-80B) achieve >95% consistency
- RWS at low temperatures correlates with overall accuracy (70% for MMLU-Redux, 91% for MedQA at t=0.3)
- Increasing temperature improves RWS for general knowledge tasks but not for medical ones
- Accuracy among consistent answers at t=0.3 correlates with overall accuracy, suggesting RWS can proxy model accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model scale determines baseline consistency capacity, with medium models exhibiting substantially higher answer consistency than small models.
- Mechanism: Larger parameter count appears to stabilize the token probability distribution during softmax sampling, making internal representations more robust to sampling noise.
- Core assumption: The relationship is causal (scale → consistency) rather than confounded by training data quality or architecture differences.
- Evidence anchors: Medium models achieve 94-99% S/T rates versus 50-80% for small models at equivalent temperatures.

### Mechanism 2
- Claim: Temperature modulates a precision-coverage tradeoff: lower temperatures yield higher consistency while higher temperatures can improve accuracy among consistent answers for general knowledge tasks.
- Mechanism: Temperature controls the entropy of token selection. Lower temperatures sharpen the distribution toward the most probable token, reducing variance across repetitions.
- Core assumption: The observed RWS improvement at higher temperatures reflects better calibration rather than random noise cancellation.
- Evidence anchors: RWS improves at t=1.0 for MMLU-Redux but not for MedQA.

### Mechanism 3
- Claim: RWS at low temperatures serves as a proxy signal for overall model accuracy, enabling consistency-based filtering without requiring ground-truth labels.
- Mechanism: Questions answered consistently across repetitions indicate the model has high internal confidence, which correlates with correctness.
- Core assumption: High internal confidence correlates with correctness, which may not hold for systematically miscalibrated models.
- Evidence anchors: 70% correlation between RWS and average accuracy at t=0.3 for MMLU-Redux, and 91% correlation for MedQA.

## Foundational Learning

- Concept: **Oracle-based consistency definition (c-answer consistency)**
  - Why needed here: The paper defines consistency as equivalence to an oracle guessing at rate c, determining how SURE/UNSURE is classified.
  - Quick check question: For a 4-choice benchmark with 10 repetitions, what minimum success guessing rate (MSGR) is required to achieve 9 identical answers?

- Concept: **RWS | S/T representation**
  - Why needed here: The paper's core metric pair separates correctness conditional on consistency (RWS) from consistency coverage (S/T).
  - Quick check question: If a model has RWS=0.80 and S/T=60%, what proportion of total questions are answered correctly AND consistently?

- Concept: **Top-K sampling with temperature**
  - Why needed here: The paper uses top-K sampling decoding across all experiments. Temperature interacts with the top-K truncation to control diversity.
  - Quick check question: How does temperature=0.3 differ from temperature=1.0 in terms of token probability sharpening?

## Architecture Onboarding

- Component map: Repetition engine -> Answer parser -> Consistency classifier -> RWS|S/T calculator -> Consistency plot generator
- Critical path: Select benchmark → Set temperature → Execute 10 repetitions per question → Parse first-line letter → Classify SURE/UNSURE → Compute RWS|S/T
- Design tradeoffs:
  - max_new_tokens=3 vs 256: Paper reduced to 3 for efficiency; longer outputs may yield different first-letter patterns
  - 10 repetitions vs fewer: 10 enables 0.99-consistency detection with 9/10 threshold; fewer repetitions reduce confidence in SURE classification
  - Single A100 vs multi-GPU: Medium models accessed via API may introduce infrastructure variance
- Failure signatures:
  - RWS << average accuracy: Model is confidently wrong (systematic miscalibration)
  - S/T < 20% at t=0.3: Model has unstable representations (potential training issue)
  - RWS-accuracy correlation near zero at t=0.3: Consistency filtering provides no information gain
- First 3 experiments:
  1. Reproduce small model baseline: Run Llama-3-8B-instruct on MMLU-Redux at t=0.3 with 10 repetitions; verify S/T ~79%, RWS ~0.73
  2. Temperature sweep on new benchmark: Test whether RWS increases with temperature holds for GSM8K or only general knowledge
  3. Domain-specific calibration check: Compare MedQA finetuned vs. base models; verify that finetuned models show higher S/T at equivalent accuracy

## Open Questions the Paper Calls Out

- Question: To what extent does "rogue memorization" from benchmark contamination artificially inflate the observed consistency scores of LLMs?
  - Basis in paper: Section 7 states the authors "did not consider benchmark contamination through memorization" and are "working out reliable ways to filter contaminated questions out."
  - Why unresolved: The reported metrics for medium-sized models may be biased by training data overlap, but the magnitude of this effect is currently unknown.
  - What evidence would resolve it: A re-evaluation of the RWS|S/T metrics after applying a robust contamination detection filter to remove memorized questions.

- Question: Can answer consistency be accurately predicted or assured during a single inference pass without relying on repetitive API calls?
  - Basis in paper: Section 3.2 describes the current repetition method as "inefficient," and Section 7 explicitly calls for "alternative methods... which are not based on repetitive API calls."
  - Why unresolved: Requiring 10 repetitions is computationally expensive and impractical for real-world applications, yet no single-pass alternative has been proposed.
  - What evidence would resolve it: The development of a runtime heuristic or internal confidence score that correlates strongly with the consistency determined by the 10-trial method.

- Question: Do the consistency metrics and temperature trade-offs found in multiple-choice benchmarks hold true for open-ended generation tasks?
  - Basis in paper: Section 7 notes the intention to "go beyond simple repetition" and apply methods "to contexts beyond multiple-choice benchmarks."
  - Why unresolved: The current definition of consistency relies on discrete choices; open-ended answers require semantic equivalence checks which introduce new noise.
  - What evidence would resolve it: An extension of the RWS|S/T metrics to generative tasks using semantic similarity thresholds.

## Limitations

- The scale-consistency relationship assumes parameter count drives the effect, but experiments mix different architectures, training datasets, and finetuning strategies without ablation studies.
- The consistency definition (0.99-c-answer consistency requiring 9/10 identical answers) represents an arbitrary threshold that may not optimally capture model reliability.
- The correlation between RWS and overall accuracy (70% for MMLU-Redux at t=0.3) suggests substantial unexplained variance, limiting the reliability of RWS as a proxy for model accuracy.

## Confidence

- **High confidence**: Scale differences between small and medium models produce measurable consistency gaps (50-80% vs >95% S/T at t=0.3)
- **Medium confidence**: Temperature modulates the precision-coverage tradeoff, with low temperatures maximizing consistency and higher temperatures potentially improving accuracy among consistent answers for general knowledge
- **Low confidence**: RWS at low temperatures serves as a reliable proxy for overall accuracy due to significant unexplained variance in the correlation

## Next Checks

1. **Domain generalization test**: Evaluate whether the temperature-RWS relationship observed for MMLU-Redux extends to GSM8K (math reasoning) or fails entirely for reasoning-heavy benchmarks.

2. **Scale-ablated comparison**: Compare models with similar parameter counts but different training data quality (e.g., Llama-3-8B vs. DeepSeek-Coder-6.7B) to isolate whether parameter count or training data drives the consistency differences.

3. **Consistency threshold sensitivity**: Systematically vary the 9/10 threshold for 0.99-consistency (e.g., 8/10, 7/10) to determine if the observed relationships hold across different definitions of answer consistency.