---
ver: rpa2
title: Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error
  Correction and Spatially-Aware Prompting
arxiv_id: '2506.11124'
source_url: https://arxiv.org/abs/2506.11124
tags:
- code
- functions
- scenario
- mining
- gemini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of runtime errors and spatial\
  \ relationship misinterpretation in LLM-generated code for scenario mining in autonomous\
  \ driving datasets. The proposed solution introduces a fault-tolerant iterative\
  \ code generation mechanism that refines code by re-prompting the LLM with error\
  \ feedback, and specialized prompt engineering to improve the LLM\u2019s understanding\
  \ of spatial-relationship functions."
---

# Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error Correction and Spatially-Aware Prompting

## Quick Facts
- arXiv ID: 2506.11124
- Source URL: https://arxiv.org/abs/2506.11124
- Reference count: 14
- Best configuration: 52.37 HOTA-Temporal on Argoverse2 test set using Gemini 2.5 Pro

## Executive Summary
This paper tackles runtime errors and spatial relationship misinterpretation in LLM-generated code for scenario mining in autonomous driving datasets. The authors introduce two enhancements to the RefAV framework: a fault-tolerant iterative code generation mechanism that refines code using error feedback, and specialized prompt engineering to improve LLM understanding of spatial-relationship functions. Experiments on Argoverse 2 with three different LLMs show consistent improvements across multiple metrics, with the best configuration achieving a HOTA-Temporal score of 52.37 on the test set.

## Method Summary
The authors enhance the RefAV framework with two key mechanisms: (1) Fault-Tolerant Iterative Code Generation (FT-ICG) that re-prompts the LLM with runtime error feedback up to K=5 iterations, and (2) Explicit Prompt Spatial Function Relationship (EP-SRF) instructions that clarify spatial function parameter semantics. The system generates Python code from natural language queries using atomic spatial/temporal functions, executes the code against Argoverse 2's pre-computed 3D tracks, and returns identified scenario timestamps and relevant object tracks.

## Key Results
- FT-ICG improves execution success rates and scenario mining coverage through iterative error correction
- EP-SRF reduces object-role confusion in spatial relationship functions
- Best configuration achieves 52.37 HOTA-Temporal score on test set using Gemini 2.5 Pro
- Consistent improvements across all three tested LLMs (Qwen2.5-VL-7B, Gemini 2.5 Flash, Gemini 2.5 Pro)

## Why This Works (Mechanism)

### Mechanism 1
Iterative re-prompting with error feedback improves code generation success rates and scenario mining coverage. The system captures runtime exceptions, feeds error messages back to the LLM with failed code, and re-prompts up to K=5 iterations until successful execution. This mirrors human debugging cycles. Break condition: manual code editing required if errors persist beyond K iterations.

### Mechanism 2
Explicit disambiguation of spatial function parameter semantics reduces object-role confusion. The prompt is augmented with clarifying instructions defining "track candidates" vs. "related candidates" for functions like `has_objects_in_relative_direction()` and `facing_toward()`. This serves as contextual disambiguation. Break condition: parameter misassignment may persist for novel function combinations not covered by provided definitions.

### Mechanism 3
Composing atomic spatial/temporal function calls via LLM-generated code enables flexible scenario mining. The RefAV framework provides pre-defined atomic functions, and the LLM translates natural language into executable Python scripts that chain these functions, offering flexibility beyond rigid query languages. Break condition: queries requiring causal or temporal reasoning beyond available atomic functions may generate incorrect scripts.

## Foundational Learning

- **HOTA-Temporal metric**: Primary evaluation metric measuring detection, association, and localization for scenario-relevant objects during active scenario frames. Understanding it is essential to interpret improvements. Quick check: Can you explain why HOTA jointly captures detection and association, unlike metrics that evaluate them separately?

- **LLM code generation with API constraints**: The system relies on LLMs generating valid Python that calls specific domain functions with correct parameters. Understanding prompt-code translation is critical. Quick check: What are two common failure modes when prompting an LLM to call an unfamiliar API function?

- **Argoverse 2 multi-modal data structure**: Scenario mining operates on RGB, LiDAR, HD maps, and 3D track annotations for 26 object categories. Knowing what's available informs query design. Quick check: Which data modalities in Argoverse 2 are used for track-level scenario mining vs. frame-level classification?

## Architecture Onboarding

- **Component map**: Input Layer (NLQuery + atomic function descriptions) → LLM Code Generator → Iterative Error Handler → Spatial Prompt Augmenter → Execution Engine → Output (scenario timestamps and track IDs)

- **Critical path**: Query → LLM with EP-SRF instructions → Generate code → Execute code → If error: append error message to prompt → Re-generate (loop up to K times) → Successful execution → Return scenario timestamps and track IDs

- **Design tradeoffs**: Higher K increases robustness but adds latency and API costs; more detailed EP-SRF instructions improve semantic accuracy but risk over-constraining the LLM; stronger LLMs improve scores but increase cost and reduce local deployability

- **Failure signatures**: Persistent runtime errors after K iterations requiring manual intervention; semantically incorrect but executable code with wrong objects/frames retrieved; parameter role reversal in spatial functions producing inverted scenarios

- **First 3 experiments**: 1) Baseline measurement with each LLM without enhancements (HOTA-Temporal ~33-43); 2) FT-ICG ablation only (observed gains: +1.4-2.2 HOTA-T); 3) Full system (FT-ICG + EP-SRF) validation on Argoverse 2 validation set and test server submission

## Open Questions the Paper Calls Out

- **Open Question 1**: How can dynamic prompt adaptation strategies improve scenario mining accuracy compared to the current static error feedback mechanism? The current FT-ICG uses a static template to feed error messages back to the LLM, which may not optimally address specific error types. Evidence would come from experiments demonstrating that context-aware prompt adjustments yield higher HOTA-Temporal scores or require fewer iterations.

- **Open Question 2**: To what extent does tighter integration of visual multimodal cues reduce semantic errors in spatial relationship identification? The current EP-SRF method relies on text-based instructions to define spatial semantics, potentially missing visual grounding. Evidence would come from ablation studies showing that incorporating visual features into the prompting mechanism significantly lowers parameter assignment errors.

- **Open Question 3**: Can the system achieve full autonomy by resolving persistent errors without the current manual intervention fallback? Section 3.1 notes that manual code editing is required when iteration count exceeds K. Evidence would come from successful mining where the "exceeds K" rate drops to zero without declining scenario retrieval metrics.

## Limitations

- The paper relies heavily on the RefAV framework without providing direct access to its codebase or detailed function specifications, creating dependency risks for faithful reproduction
- Manual code correction fallback for persistent errors introduces potential human bias, though the paper does not quantify how often this occurs
- The study focuses on three LLMs but does not systematically compare against other code generation approaches or domain-specific planners

## Confidence

- **High confidence**: Iterative error correction improves execution success rates and HOTA-Temporal scores (directly supported by quantitative results)
- **Medium confidence**: Spatial function parameter disambiguation meaningfully reduces semantic errors (logically sound but lacks isolated ablation studies)
- **Low confidence**: The compositional atomic function approach is superior to alternatives for complex scenario queries (claims flexibility but provides no comparative evaluation)

## Next Checks

1. Replicate the FT-ICG mechanism independently with a different LLM (e.g., GPT-4o) on the same query set to verify that error feedback consistently improves success rates across model families

2. Conduct an ablation study: measure HOTA-Temporal when enabling only EP-SRF (without FT-ICG) and vice versa, to isolate each mechanism's contribution

3. Analyze error logs from the K=5 iteration loop to quantify how often manual correction is required and whether certain error types persist across all models, indicating fundamental limitations in the approach