---
ver: rpa2
title: 'SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor
  Arrays for Earthquake Source Inversion'
arxiv_id: '2601.06320'
source_url: https://arxiv.org/abs/2601.06320
tags:
- kagan
- sourcenet
- learning
- data
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SourceNet, a Transformer-based framework
  for earthquake source inversion using variable-geometry sensor arrays. The key innovation
  is Physics-Structured Domain Randomization (PSDR), which bridges the Sim-to-Real
  gap by randomizing physical simulation parameters (velocity models, noise, scattering)
  rather than visual appearance, forcing the model to learn invariant physical operations.
---

# SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion

## Quick Facts
- **arXiv ID:** 2601.06320
- **Source URL:** https://arxiv.org/abs/2601.06320
- **Reference count:** 40
- **Key outcome:** State-of-the-art earthquake source inversion with mean Kagan angle of 23.9° and median of 19.7° on real-world Southern California seismic data.

## Executive Summary
SourceNet is a Transformer-based framework for earthquake source inversion using variable-geometry sensor arrays. The key innovation is Physics-Structured Domain Randomization (PSDR), which bridges the Sim-to-Real gap by randomizing physical simulation parameters (velocity models, noise, scattering) rather than visual appearance. This forces the model to learn invariant physical operations. SourceNet achieves state-of-the-art performance, effectively matching the uncertainty floor of manual catalogs, and demonstrates exceptional data efficiency by requiring only ~2,500 real events after pre-training on 100,000 synthetic events.

## Method Summary
SourceNet uses a two-stage transfer learning approach. First, it pre-trains on 100,000 synthetic events using Physics-Structured Domain Randomization (PSDR), which randomizes physical simulation parameters including 17 velocity models, stochastic time/amplitude shifts, real ambient noise superposition, and Bernoulli station dropout. The model architecture consists of a 3-tower station encoder (P-wave 1D-CNN, S-wave 1D-CNN, Scalar MLP) that processes multi-modal per-station inputs, followed by a Set Transformer with self-attention to capture relational station dependencies, and attention pooling to aggregate to event-level representations. The second stage fine-tunes all layers on ~2,500 real Southern California events using Focal L1 Loss with weighted sampling for moment tensor balance.

## Key Results
- Achieves state-of-the-art performance with mean Kagan angle of 23.9° and median of 19.7° on real-world Southern California seismic data
- Demonstrates exceptional data efficiency, requiring only ~2,500 real events after pre-training on 100,000 synthetic events
- Ablation studies show that removing either the scalar metadata tower or self-attention significantly degrades performance, confirming the necessity of multi-modal fusion and relational reasoning for wave physics

## Why This Works (Mechanism)

### Mechanism 1: Physics-Structured Domain Randomization (PSDR)
Randomizing physical simulation parameters forces the model to learn domain-invariant features by preventing memorization of specific simulation artifacts. The model must learn robust, invariant operators mapping waveforms to source parameters through causal intervention on nuisance variables. Break condition: if real-world data contains physics completely outside the convex hull of randomized simulation parameters.

### Mechanism 2: Self-Attention as Relational Reasoning
Self-attention captures pairwise station dependencies required to resolve radiation patterns, which is geometrically ambiguous for single stations. Every station can query every other station to construct a global radiation pattern context that resolves local ambiguities. Break condition: if the sensor array is so sparse that no relational context exists, or if noise is so high that relative phases are unrecoverable.

### Mechanism 3: Multi-Modal Fusion for Disentanglement
Explicit geometric metadata (Scalar Tower) is required to disentangle source energy from path attenuation. Waveform amplitudes are scale-ambiguous, and the Scalar Tower injects explicit distance and azimuth data, allowing the model to normalize learned waveform features and recover absolute magnitude. Break condition: if sensor location data is corrupted or velocity model errors cause distance estimates to be wildly inaccurate.

## Foundational Learning

- **Concept: Permutation Invariance (Set Input)**
  - Why needed: Seismic networks are ad-hoc; the number of sensors and their order vary per event. Standard CNNs/RNNs fail here. The model treats input as a set {x₁, ..., xₙ}, not a sequence or grid.
  - Quick check: If you shuffle the input sensors in a batch, does the model output change? (It should not).

- **Concept: Amortized Inference**
  - Why needed: Unlike classical solvers that run optimization per event, this model learns a global inverse operator during training for instant inference. Understanding this explains the heavy pre-training cost vs. instant inference speed.
  - Quick check: Does the model run an optimization loop during inference on a new earthquake, or a single forward pass?

- **Concept: Moment Tensor / Focal Mechanism**
  - Why needed: This is the output space y ∈ ℝ⁶ representing the 3D geometry of fault slip (visualized as "beachballs"), not just a location or time.
  - Quick check: If the model predicts a Kagan angle of 0°, what does that mean physically? (Perfect alignment with ground truth orientation).

## Architecture Onboarding

- **Component map:** P-Wave 1D-CNN + S-Wave 1D-CNN + Scalar MLP → Concat → Set Transformer → Attention Pooling → Dual Heads (MT: 5-d, Mag: 1-d)
- **Critical path:** The Scalar Tower → Station Encoder fusion. The model relies on concatenation of waveform features and distance/azimuth features to determine magnitude.
- **Design tradeoffs:** Attention vs. Pooling trades O(N²) complexity for modeling relational physics. Synthetic Pre-training requires generating 100k events, which is computationally expensive upfront but saves orders of magnitude in real-label requirements later.
- **Failure signatures:** High Magnitude Variance likely indicates Scalar Tower failure (check distance normalization). High Kagan Angle likely indicates Self-Attention failure (e.g., masking issue) or insufficient training on diverse focal mechanisms.
- **First 3 experiments:**
  1. Sanity Check (Synthetic): Train on only 100 synthetic events. The model should overfit (Loss ≈ 0, Kagan ≈ 0°). If not, the architecture is broken.
  2. Ablation (Scalar): Zero out the Scalar Tower inputs on the test set. Confirm Magnitude MAE jumps from ~0.07 to ~0.18 as per Table 1.
  3. Manifold Alignment (PSDR): Train one model with PSDR and one without. Visualize t-SNE of latent space. The non-PSDR model should show disjoint clusters for Synthetic vs. Real data.

## Open Questions the Paper Calls Out
1. Can the SourceNet architecture be extended to model the full spatiotemporal evolution of fault slip (dynamic rupture) rather than static point-source parameters?
2. How does the framework performance degrade when applied to out-of-distribution (OOD) events, such as complex multi-fault ruptures, which are absent from the synthetic training support?
3. Can the emergent attention policy, which identifies information bottlenecks, be formalized into an active learning framework to optimize physical sensor placement?

## Limitations
- The exact physical parameterization of the 17 velocity models from CRUST1.0 and ambient noise library remains underspecified, limiting reproducibility
- Model's generalization to entirely different tectonic regimes (e.g., subduction zones) is untested
- Performance claims hinge on partially opaque components whose fidelity cannot be fully verified

## Confidence
- **High Confidence:** Core mechanism of PSDR (randomizing physical simulation parameters) is well-supported by ablation studies and manifold alignment results
- **Medium Confidence:** Claim that SourceNet "autonomously discovers optimal sensor placement" is demonstrated but could benefit from more explicit analysis
- **Medium Confidence:** Assertion that SourceNet's Kagan angle (23.9°) "effectively matches the uncertainty floor of manual catalogs" is supported but requires external validation

## Next Checks
1. Physics Coverage Test: Systematically vary the velocity models in PSDR and measure degradation in real-world performance to quantify the critical assumption that simulation support covers real-world physics
2. Noise Realism Audit: Compare the ambient noise library's spectral characteristics to real Southern California noise recordings to validate that noise superposition doesn't introduce exploitable artifacts
3. Tectonic Transfer Test: Evaluate SourceNet on a held-out dataset from a different tectonic setting (e.g., Pacific Northwest) without retraining to test claimed domain invariance beyond Southern California