---
ver: rpa2
title: 'Stochastic Gradient Descent in Non-Convex Problems: Asymptotic Convergence
  with Relaxed Step-Size via Stopping Time Methods'
arxiv_id: '2504.12601'
source_url: https://arxiv.org/abs/2504.12601
tags:
- convergence
- have
- assumption
- lemma
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes the asymptotic convergence of Stochastic\
  \ Gradient Descent (SGD) under relaxed step-size conditions using a stopping-time\
  \ method. While previous analyses required step-sizes satisfying the Robbins-Monro\
  \ conditions (\u2211\u221Et=1 \u03B5t = \u221E and \u2211\u221Et=1 \u03B5\xB2t <\
  \ \u221E), this work proves convergence for step-sizes satisfying \u2211\u221Et=1\
  \ \u03B5t = \u221E and \u2211\u221Et=1 \u03B5\u1D56t < \u221E for some p 2, enabling\
  \ step-sizes like \u03B5t = 1/t^q with q \u2208 (1/p, 1/2] that were previously\
  \ unsupported."
---

# Stochastic Gradient Descent in Non-Convex Problems: Asymptotic Convergence with Relaxed Step-Size via Stopping Time Methods

## Quick Facts
- arXiv ID: 2504.12601
- Source URL: https://arxiv.org/abs/2504.12601
- Reference count: 40
- This paper establishes the asymptotic convergence of Stochastic Gradient Descent (SGD) under relaxed step-size conditions using a stopping-time method.

## Executive Summary
This paper proves the asymptotic convergence of Stochastic Gradient Descent (SGD) for non-convex optimization problems under significantly relaxed step-size conditions compared to classical results. Using a stopping-time method, the authors show that SGD converges to critical points even when step-sizes satisfy $\sum_{t=1}^{\infty} \varepsilon_t = \infty$ and $\sum_{t=1}^{\infty} \varepsilon_t^p < \infty$ for some $p > 2$, which allows for step-sizes like $\varepsilon_t = 1/t^q$ with $q \in (1/p, 1/2]$ that were previously unsupported. The analysis eliminates the global Lipschitz continuity assumption on the loss function and relaxes boundedness requirements on higher-order moments of stochastic gradients, replacing global conditions with local ones.

## Method Summary
The paper analyzes standard SGD with iterates $\theta_{t+1} = \theta_t - \varepsilon_t \cdot g_t$, where $g_t$ is an unbiased stochastic gradient. The key innovation is using a stopping-time method to establish convergence under relaxed step-size conditions. The authors prove both almost sure convergence of iterates to critical points and $L^2$ convergence of gradients to zero. The theoretical framework requires Assumptions 3.1-3.4 on the loss function and stochastic gradients, including coercivity, boundedness near critical points, and weak growth conditions on gradient moments.

## Key Results
- Proves asymptotic convergence of SGD under relaxed step-size conditions $\sum \varepsilon_t = \infty$ and $\sum \varepsilon_t^p < \infty$ for $p > 2$
- Eliminates global Lipschitz continuity assumption on the loss function
- Replaces global boundedness conditions on stochastic gradients with local conditions
- Establishes both almost sure convergence to critical points and $L^2$ convergence of gradient norms to zero

## Why This Works (Mechanism)
The stopping-time method provides a novel approach to handle the relaxed step-size conditions by carefully controlling the martingale terms that arise in the analysis. By introducing local boundedness conditions near critical points and relaxing the moment conditions on stochastic gradients, the authors create a more flexible framework that still guarantees convergence. The key insight is that these local conditions are sufficient to ensure stability and convergence without requiring the stricter global assumptions of previous analyses.

## Foundational Learning
- **Robbins-Monro conditions**: Why needed: Classical requirement for SGD convergence; quick check: Verify $\sum \varepsilon_t = \infty$ and $\sum \varepsilon_t^2 < \infty$
- **Stopping-time methods**: Why needed: Handle relaxed step-size conditions; quick check: Identify appropriate stopping times in the martingale analysis
- **Coercivity**: Why needed: Ensures iterates don't diverge to infinity; quick check: Verify $\lim_{\|\theta\| \to \infty} f(\theta) = \infty$
- **Weak growth condition**: Why needed: Controls gradient moments; quick check: Verify $E[\|g_t\|^2 | F_{t-1}] \leq G(\|\nabla f(\theta_t)\|^2 + 1)$

## Architecture Onboarding
- **Component map**: SGD update -> Stopping-time analysis -> Local boundedness conditions -> Convergence proof
- **Critical path**: Step-size selection $\rightarrow$ Verification of summability conditions $\rightarrow$ Application of stopping-time method $\rightarrow$ Convergence proof
- **Design tradeoffs**: Relaxed step-sizes enable larger learning rates but require stronger local conditions on the function
- **Failure signatures**: Divergence occurs if coercivity fails or if local boundedness near critical points is violated
- **First experiments**:
  1. Verify step-size summability for $\varepsilon_t = 1/t^q$ with different $q$ values
  2. Test convergence on a simple non-convex function satisfying all assumptions
  3. Compare convergence rates under relaxed vs. Robbins-Monro step-size conditions

## Open Questions the Paper Calls Out
### Open Question 1
Can the stopping-time method be extended to analyze adaptive gradient methods like ADAM and SGDM? The paper suggests this could be possible but notes that adaptive methods introduce complex dependencies that the current analysis doesn't cover.

### Open Question 2
What are the non-asymptotic convergence rates for SGD under the relaxed step-size conditions? The paper establishes asymptotic results but doesn't derive finite-time bounds.

### Open Question 3
Can the "Boundedness Near Critical Points" assumption be removed or replaced by a milder geometric condition? The current proof relies on this assumption, but its theoretical necessity remains unverified.

## Limitations
- No empirical validation or numerical examples provided
- Key constants (G, M₀, M₁, D_η, L, p) are unspecified and problem-dependent
- Direct reproduction requires substantial additional work to define valid experimental setup

## Confidence
- Asymptotic convergence under relaxed step-size conditions: High confidence
- Elimination of global Lipschitz continuity assumption: High confidence
- Almost sure convergence to critical points: High confidence
- Practical performance or empirical validation: Low confidence

## Next Checks
1. **Step-size summability verification**: For $\varepsilon_t = 1/t^q$, compute numerical partial sums of $\sum \varepsilon_t$ and $\sum \varepsilon_t^p$ to verify they satisfy relaxed conditions but violate Robbins-Monro conditions
2. **Assumption verification on test function**: Select $f(\theta) = \theta^4 - 2\theta^2$ and numerically verify Assumptions 3.1-3.4 regarding Lipschitz gradients, coercivity, and boundedness near critical points
3. **Gradient growth condition check**: Empirically estimate $E[\|g_t\|^2 | F_{t-1}] \leq G(\|\nabla f(\theta_t)\|^2 + 1)$ by sampling stochastic gradients at various iterates