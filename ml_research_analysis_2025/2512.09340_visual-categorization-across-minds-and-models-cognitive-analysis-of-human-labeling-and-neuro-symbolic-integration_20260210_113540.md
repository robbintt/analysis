---
ver: rpa2
title: 'Visual Categorization Across Minds and Models: Cognitive Analysis of Human
  Labeling and Neuro-Symbolic Integration'
arxiv_id: '2512.09340'
source_url: https://arxiv.org/abs/2512.09340
tags:
- cognitive
- visual
- human
- confidence
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how humans and AI systems interpret ambiguous
  visual stimuli by comparing human labeling performance with that of a ResNet-18
  model on low-resolution CIFAR-10 images. Participants demonstrated perfect classification
  accuracy with high confidence ratings (mean 4.75/5), using shape-based and analogical
  reasoning strategies.
---

# Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration

## Quick Facts
- **arXiv ID**: 2512.09340
- **Source URL**: https://arxiv.org/abs/2512.09340
- **Reference count**: 40
- **Primary result**: Humans achieved perfect classification accuracy on ambiguous CIFAR-10 images using shape-based reasoning, while ResNet-18 achieved ~70.7% accuracy with texture-focused attention

## Executive Summary
This study compares human and AI visual categorization performance on ambiguous low-resolution CIFAR-10 images, revealing fundamental differences in how biological and artificial systems process visual information. Humans demonstrated perfect classification accuracy using shape-based and analogical reasoning strategies, while the ResNet-18 model achieved ~70.7% accuracy with Grad-CAM visualizations showing texture-focused attention patterns. The research highlights that humans employ metacognitive monitoring and satisficing heuristics (bounded rationality), whereas AI systems optimize for statistical texture features. These findings support Marr's tri-level hypothesis and motivate future neuro-symbolic architectures that integrate symbolic reasoning with connectionist representations to achieve more interpretable and cognitively aligned AI systems.

## Method Summary
The study compares human labeling performance with a ResNet-18 model on 10 selected low-resolution CIFAR-10 test images (2 per class: airplane, automobile, bird, cat, deer). Twelve human participants classified each image while reporting confidence ratings (1-5) and describing their reasoning strategies. The ResNet-18 model was modified for CIFAR-10 (3x3 first conv layer, no initial max pooling) and trained for 5 epochs using Adam optimizer with cross-entropy loss. Grad-CAM visualizations were generated to analyze AI attention patterns, and human responses were analyzed for classification accuracy, confidence calibration, and strategy usage.

## Key Results
- Humans achieved perfect classification accuracy on ambiguous images using shape-based and analogical reasoning
- ResNet-18 model achieved approximately 70.7% test accuracy with texture-focused attention patterns
- Human confidence inversely correlated with cognitive load, demonstrating metacognitive monitoring absent in AI
- AI misclassifications showed high confidence when texture features matched learned patterns, regardless of semantic validity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Humans outperform pure connectionist models on ambiguous, low-resolution stimuli by utilizing shape-based heuristics and analogical reasoning rather than localized texture statistics.
- **Mechanism:** Human visual processing applies a "satisficing" strategy (bounded rationality), mapping degraded inputs to global prototypes via semantic memory. In contrast, the ResNet-18 model optimizes for statistical regularities in pixel data, resulting in a bias toward texture features which can mislead classification when global shapes are obscured.
- **Core assumption:** Human accuracy on this specific dataset is driven by top-down semantic priors rather than bottom-up feature accumulation.
- **Evidence anchors:** Participants demonstrated perfect classification accuracy using shape-based strategies; AI exhibited feature-based attention focused on textures. Notes that AI attention is localized and sensitive to texture, lacking higher-level shape context, leading to misclassifications.
- **Break condition:** If images are presented without any recognizable shape prototype or context (pure noise), human heuristic advantages may disappear, reducing performance to random guessing.

### Mechanism 2
- **Claim:** Human confidence calibrates with perceived cognitive load (metacognitive monitoring), whereas AI confidence (softmax probability) correlates only with feature clarity.
- **Mechanism:** Humans employ "metacognitive monitoring" where decision certainty decreases as internal conflict or processing effort increases. The ResNet-18 model generates confidence via softmax activation, which spikes simply when specific texture features are present, regardless of semantic validity.
- **Core assumption:** The self-reported cognitive load (1-5) accurately reflects the internal computational cost of the decision process.
- **Evidence anchors:** Human behavior interpreted through cognitive principles reveals layered and heuristic decision strategies under uncertainty. Describes an inverse correlation between confidence and cognitive load in humans, exemplifying metacognitive monitoring not present in the AI.
- **Break condition:** If the model is heavily calibrated or temperature scaling is applied to the softmax outputs, the correlation between AI confidence and feature clarity might be altered.

### Mechanism 3
- **Claim:** Integrating symbolic reasoning modules with connectionist perception (Neuro-symbolic AI) is proposed to mitigate the "texture-bias" failures observed in pure deep learning models.
- **Mechanism:** By attaching a symbolic reasoning layer (e.g., rule-checks for "wings" or "wheels") on top of feature extraction, the system can validate Grad-CAM activations against structural constraints. This forces the architecture to satisfy both statistical pattern matching and semantic structure.
- **Core assumption:** The divergence in human vs. AI performance is primarily due to the lack of symbolic representation in AI, not merely insufficient training data or model scale.
- **Evidence anchors:** Findings motivate future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Proposes a hybrid model combining Grad-CAM activations with symbolic reasoning modules for fallback logic checks.
- **Break condition:** If the symbolic rules are too rigid or the neural-symbolic interface lacks robust grounding, the system may suffer from "symbol grounding" failures where symbolic rules do not correctly map to visual features.

## Foundational Learning

- **Concept: Grad-CAM (Gradient-weighted Class Activation Mapping)**
  - **Why needed here:** Used to visualize where the AI "looks" to reveal the mechanism of its errors (texture vs. shape).
  - **Quick check question:** If a Grad-CAM heatmap highlights the background grass instead of the foreground object, what does this imply about the model's learned features?

- **Concept: Bounded Rationality (Simon)**
  - **Why needed here:** Explains why humans achieve high accuracy with low computational effort by "satisficing" rather than optimizing.
  - **Quick check question:** How does the "satisficing" heuristic explain human success on 32x32 images where a brute-force pixel-analysis approach might struggle?

- **Concept: Marr's Tri-Level Hypothesis**
  - **Why needed here:** Provides the structural framework (Computational, Algorithmic, Implementational) to compare the human brain and the AI model systematically.
  - **Quick check question:** At which of Marr's levels does the paper identify the primary divergence between human (symbolic/analogical) and AI (connectionist) processing?

## Architecture Onboarding

- **Component map:** Data Ingestion -> ResNet Feature Extraction -> Softmax Classification -> (If Low Confidence/Ambiguous) -> Symbolic Fallback Check -> Final Label

- **Critical path:** The model processes 32x32 CIFAR-10 images through modified ResNet-18, generates predictions with softmax probabilities, and when encountering ambiguous cases, could apply symbolic reasoning rules to validate or override the neural output.

- **Design tradeoffs:**
  - **Texture vs. Shape:** The standard ResNet trades shape-robustness for texture-accuracy.
  - **Speed vs. Interpretability:** A pure neural path is fast but "black box"; adding symbolic checks increases latency and complexity but improves cognitive alignment.

- **Failure signatures:**
  - **High-Confidence Hallucination:** Model predicts "Airplane" with ~0.37 confidence on a "Deer" image because diagonal texture lines resemble airplane wings.
  - **Diffused Attention:** Grad-CAM shows scattered "blob" attention rather than object-centric contours, indicating a lack of semantic understanding.

- **First 3 experiments:**
  1. **Reproduce Texture Bias:** Train the provided ResNet-18 config on CIFAR-10 and use Grad-CAM to verify if the model attends to texture boundaries rather than object outlines on misclassified samples.
  2. **Confidence Calibration Check:** Compare model softmax scores vs. human confidence ratings on the 10 specific test images to quantify the "calibration gap" (e.g., Does 0.5 AI confidence map to human 3/5 or 5/5?).
  3. **Prototype Symbolic Override:** Implement a simple rule-based script that overrides the "Deer" misclassification (predicted as Airplane) by checking for the absence of "sky-blue" contextual pixels or presence of "brown/green" texture, observing if accuracy improves.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can Grad-CAM-derived neural activations be effectively integrated with symbolic reasoning modules to create fallback logic checks (e.g., validating "wings" for airplane predictions) that prevent texture-driven misclassifications?
- **Basis in paper:** The authors state they will "design and evaluate a hybrid neuro-symbolic model that integrates structured symbolic reasoning rules with neural attention mechanisms," combining Grad-CAM activations with