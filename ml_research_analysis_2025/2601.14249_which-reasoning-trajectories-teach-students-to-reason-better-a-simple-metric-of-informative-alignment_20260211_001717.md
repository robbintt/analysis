---
ver: rpa2
title: Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric
  of Informative Alignment
arxiv_id: '2601.14249'
source_url: https://arxiv.org/abs/2601.14249
tags:
- reasoning
- student
- trajectories
- teacher
- metric
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of selecting effective reasoning\
  \ trajectories for knowledge distillation from teacher to student language models.\
  \ The authors propose Rank-Surprisal Ratio (RSR), a metric that jointly captures\
  \ informativeness and alignment by measuring the ratio of a trajectory\u2019s average\
  \ token-wise rank to its average negative log-likelihood under the student model."
---

# Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment

## Quick Facts
- arXiv ID: 2601.14249
- Source URL: https://arxiv.org/abs/2601.14249
- Reference count: 40
- Primary result: Rank-Surprisal Ratio (RSR) achieves 0.86 average Spearman correlation with post-training reasoning performance, outperforming existing metrics.

## Executive Summary
This paper addresses the challenge of selecting effective reasoning trajectories for knowledge distillation from teacher to student language models. The authors propose Rank-Surprisal Ratio (RSR), a metric that jointly captures informativeness and alignment by measuring the ratio of a trajectory's average token-wise rank to its average negative log-likelihood under the student model. Across five student models and reasoning trajectories from 11 diverse teachers, RSR consistently outperforms existing metrics and demonstrates strong predictive power for post-training reasoning performance.

## Method Summary
The Rank-Surprisal Ratio (RSR) metric is computed through a single forward pass of the student model on teacher-generated reasoning trajectories. For each token position, the method calculates surprisal (-log probability of target token) and rank (position of target token in sorted probability distribution, clipped at 100). The final RSR score is the sum of clipped ranks divided by the sum of surprisals. The method uses a surprisal-weighted formulation to emphasize informative tokens. Dataset-level RSR aggregates trajectory-level scores using surprisal weights.

## Key Results
- RSR achieves 0.86 average Spearman correlation with post-training reasoning performance across five student models
- RSR outperforms existing metrics (0.49 for Avg-Surprisal, 0.59 for Avg-Rank, 0.47 for GRAD)
- Practical applications show RSR effectively identifies suitable trajectories for distillation, with selection experiments demonstrating improved student performance

## Why This Works (Mechanism)

### Mechanism 1: Informativeness Captured Through Surprisal
Trajectories with higher surprisal (lower probability) under the student model provide stronger learning signals during distillation. Surprisal measures absolute unfamiliarity—how much the trajectory deviates from the student's dominant generation patterns. When tokens receive low probability, they represent patterns the student has not yet mastered, creating gradient pressure during SFT that pushes the model toward new capabilities rather than reinforcing existing behavior.

### Mechanism 2: Alignment Captured Through Token Rank
Tokens with high rank (top positions in the vocabulary ordering) indicate relative familiarity even when absolute probability is low. Rank measures position relative to alternatives. A token at rank 5 with probability 0.01 is "relatively familiar"—the student considers it a plausible continuation despite low absolute score. This distinguishes "stretch but achievable" patterns from "completely alien" ones.

### Mechanism 3: Joint Optimization Through Rank-Surprisal Ratio
The ratio RSR = (sum of ranks) / (sum of surprisals) identifies trajectories that are simultaneously informative and aligned. The ratio formulation creates a Pareto-like trade-off surface. Low RSR requires both numerator (alignment) and denominator (informativeness) to be balanced. Only the "zone of proximal development"—low rank with high surprisal—minimizes the ratio.

## Foundational Learning

- **Knowledge Distillation in LLMs**: Understanding why "stronger teacher ≠ better student" is the motivating puzzle. Quick check: Can you explain why training a 3B model on DeepSeek-R1 (671B) outputs might underperform training on QwQ-32B outputs?

- **Token-Level Probability Distributions**: RSR requires computing both probability (for surprisal) and rank from the student's softmax output over vocabulary at each position. Quick check: Given logits [2.0, 1.0, 0.5, 0.1] for four tokens with target token index 2, what is the surprisal and rank?

- **Zone of Proximal Development (Vygotsky)**: The paper explicitly draws this analogy—effective learning occurs when material is neither too easy (already mastered) nor too hard (beyond current capability). Quick check: How does the "low probability + high rank" combination map to Vygotsky's zone concept?

## Architecture Onboarding

- **Component map**: Student Model (frozen) → Forward pass on teacher trajectory → Logits per token position → Surprisal = -log p(t|c) and Rank = count(p > p_target) + 1 → Clip ranks at r_max=100 → RSR = Σ(rank) / Σ(surprisal) → Lower RSR → Better trajectory

- **Critical path**: Load student model weights (base model, not instruction-tuned) → For each candidate trajectory, run single forward pass with teacher tokens as input → At each position, extract target token probability and compute rank via top-k selection → Aggregate across trajectory using surprisal-weighted formulation → For dataset-level RSR, aggregate using Eq. 9 (weighted by trajectory-level surprisal)

- **Design tradeoffs**: Rank clipping threshold (r_max=100) reduces noise from extremely unfamiliar tokens; simple average vs. surprisal-weighted improves correlation from 0.39 to 0.86; token-level vs. trajectory-level aggregation—trajectory-level is required for stability

- **Failure signatures**: All RSR values similar (check rank computation); negative correlation with performance (may indicate student model mismatch); numerical overflow (ensure log-probabilities are stable)

- **First 3 experiments**: Sanity check—compute RSR for trajectories from same model family vs. distant family; correlation validation—compute RSR for 3-5 teachers, train student on each, measure post-training accuracy; selection experiment—from pool of 33 trajectories per problem, select lowest-RSR trajectory for each problem and compare to random selection

## Open Questions the Paper Calls Out

**Open Question 1**: Does RSR arise from deeper mathematical or theoretical principles, and can a formal framework explain its effectiveness? The metric was derived empirically through simulation studies without formal theoretical justification for why the rank-to-surprisal ratio captures optimal learning conditions.

**Open Question 2**: Can RSR effectively guide trajectory rewriting or synthesis rather than just selecting from a fixed candidate pool? The current work only validates RSR for selection among pre-generated trajectories; the metric's utility as an optimization target for generating new trajectories remains unexplored.

**Open Question 3**: How well does RSR generalize to domains beyond mathematical reasoning, such as code generation or multi-modal reasoning? All experiments focused on mathematical reasoning due to resource constraints; the metric's effectiveness for code, logic puzzles, or other reasoning tasks is unknown.

**Open Question 4**: How does RSR interact with distillation methods beyond supervised fine-tuning, such as reinforcement learning or on-policy approaches? The paper evaluates only SFT-based distillation, yet the compatibility of RSR with RL-based methods remains untested.

## Limitations
- Domain Generalization Uncertainty: RSR demonstrates strong performance specifically for mathematical reasoning tasks but has not been validated on other domains like code generation or scientific reasoning
- Student Model Dependency: Metric's effectiveness depends on using the correct target student model for scoring, creating a chicken-and-egg problem
- Trajectory Length Effects: Paper clips ranks at 100 but doesn't systematically study how trajectory length affects RSR reliability

## Confidence

- **High Confidence**: RSR outperforms existing metrics (Avg-Surprisal, Avg-Rank, GRAD) on mathematical reasoning trajectory selection, achieving 0.86 vs. 0.49-0.59 average Spearman correlation
- **Medium Confidence**: The mechanism explanation (informativeness + alignment trade-off captured by ratio) is plausible but relies on intuitive reasoning rather than formal proof
- **Low Confidence**: Claims about RSR's general applicability beyond mathematical reasoning remain untested

## Next Checks
1. **Cross-Domain Validation**: Apply RSR to trajectory selection for code generation tasks (e.g., HumanEval, MBPP) and compare against surprisal-only and rank-only baselines
2. **Student Model Robustness Study**: Systematically test how RSR correlation degrades when using mismatched student models for scoring
3. **Trajectory Length Sensitivity Analysis**: Generate teacher trajectories at varying lengths and measure how RSR correlation with performance changes