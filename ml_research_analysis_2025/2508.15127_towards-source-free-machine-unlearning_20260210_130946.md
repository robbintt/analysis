---
ver: rpa2
title: Towards Source-Free Machine Unlearning
arxiv_id: '2508.15127'
source_url: https://arxiv.org/abs/2508.15127
tags:
- data
- unlearning
- unlearned
- performance
- remaining
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of machine unlearning in source-free
  settings, where the original training data is unavailable during the forgetting
  process. The authors propose a novel method that estimates the Hessian of the remaining
  training data using only the model parameters and the data to be forgotten.
---

# Towards Source-Free Machine Unlearning

## Quick Facts
- arXiv ID: 2508.15127
- Source URL: https://arxiv.org/abs/2508.15127
- Reference count: 40
- Primary result: Novel method achieves source-free unlearning with accuracy gaps within 1-3% of retrained models

## Executive Summary
This paper addresses the challenge of machine unlearning when the original training data is unavailable, presenting a method that can remove specific data points from a trained model using only the forget set. The approach estimates the Hessian of the remaining training data through a Semi-Definite Program, enabling zero-shot unlearning while providing theoretical guarantees. The method is validated across multiple datasets and architectures, demonstrating that it can achieve performance close to models retrained on the remaining data while maintaining robust protection against membership inference attacks.

## Method Summary
The proposed method tackles source-free unlearning by estimating the Hessian of the remaining training data without direct access to it. Given a trained model and the data to be forgotten, the approach samples random perturbations around the trained weights, computes loss differences on the forget data at these perturbed points, and formulates an SDP to estimate the retain Hessian. This estimated Hessian is then used in a Newton update step to unlearn the forget data. The method extends to neural networks through a linearization approach (mixed-linear unlearning) that approximates the network's behavior around its trained weights using the Neural Tangent Kernel theory.

## Key Results
- Achieves accuracy within 1-3% of retrained models across test, remaining, and forget data sets
- Maintains MIA scores close to 50%, indicating successful unlearning protection
- Demonstrates theoretical guarantees on unlearning performance through bounded gradient norms
- Successfully extends to mixed-linear neural networks (ResNet-18 with linearized last layers)

## Why This Works (Mechanism)

### Mechanism 1: Retain Hessian Estimation via Forget Data Approximation
The method approximates the Hessian of remaining data using only the trained model parameters and forget data. By leveraging the Lipschitz continuity of the loss function, the difference between loss of retain and forget data at small perturbations is bounded. This allows the retain Hessian to be estimated by solving an SDP that minimizes an objective function based on forget data loss differences.

Core assumption: Loss differences for retain and forget data at perturbed points are small and bounded (Assumption: $|\delta L_r(w_i) - \delta L_f(w_i)| \le \epsilon$).

### Mechanism 2: Bounded-Error Unlearning Update
Using the estimated Hessian, a Newton update step is applied to provably move the model parameters toward those of a model retrained on the retain set. Theoretical bounds show that as the Hessian estimation error decreases, the unlearning performance improves, with the gradient norm of the unlearned model on remaining data being bounded.

Core assumption: The loss function is convex, Lipschitz, and the model was trained to convergence.

### Mechanism 3: Extension to Neural Networks via Linearization
The method extends to deep neural networks by linearizing the network's behavior around its trained weights using the Neural Tangent Kernel approach. This transforms the non-convex problem into a convex optimization task, allowing the Hessian-based unlearning update to be applied to the linearized last few layers of a network like ResNet-18.

Core assumption: The network's behavior during unlearning can be well-approximated by its linearization around trained weights.

## Foundational Learning

### Concept: Hessian Matrix
Why needed here: The Hessian matrix of second derivatives is central to the method, as the core innovation is estimating this matrix for the "retain" data without having access to that data.
Quick check question: In a convex loss landscape, what does the Hessian tell you about the curvature of the loss function, and how is that curvature used in a second-order optimization method like a Newton step?

### Concept: Semi-Definite Program (SDP)
Why needed here: The Hessian estimation is formulated as an optimization problem constrained by the condition that the Hessian must be positive semi-definite (a property of convex loss functions).
Quick check question: What is a Semi-Definite Program, and what kind of constraint does a "positive semi-definite" constraint place on the solution matrix?

### Concept: Convexity and Lipschitz Continuity
Why needed here: The entire theoretical framework and guarantees are built on the assumption that the loss function is convex and Lipschitz continuous.
Quick check question: Why is the assumption of a convex loss function critical for a machine unlearning method that relies on a Hessian-based update?

## Architecture Onboarding

### Component map:
Trained Linear Model -> Forget Data ($D_f$) -> Perturbation Sampler -> Loss & Gradient Calculator -> SDP Optimizer -> Newton Update Engine -> Unlearned Model

### Critical path:
1. Receive forget data $D_f$
2. Sample perturbations $\delta w$ 
3. Compute loss differences $\delta L_f$ and gradient $\nabla_f$ using $D_f$
4. Formulate and solve the SDP to estimate $\hat{H}_r$
5. Compute the unlearning update using $\hat{H}_r$ and $\nabla_f$
6. Return the unlearned model $w_{uf}$

### Design tradeoffs:
- **Perturbation count ($m$)**: More perturbations improve the Hessian estimate but increase computational cost
- **Forget data size**: Larger forget set gives more reliable approximation but larger update magnitude, potentially degrading performance
- **Regularization ($\lambda$)**: Higher regularization tightens theoretical bounds and improves unlearning performance, but may hurt original model accuracy

### Failure signatures:
- **High Performance Gap**: Large accuracy difference on remaining data vs. retrained baseline suggests poor Hessian estimation; try increasing perturbations or reducing forget set size
- **High MIA Score**: Score significantly above 50% indicates incomplete unlearning; verify gradient computation and model convergence
- **Degraded Test Accuracy**: Overall performance collapse suggests update was too large or convexity assumption violated

### First 3 experiments:
1. **Baseline Sanity Check**: On CIFAR-10 with linear classifier, set forget data to 5%. Compare accuracy and MIA score against paper's "Unlearned(-)" and "Retrained" models to confirm minimal performance gap.
2. **Ablation on Perturbations**: Vary perturbation count ($m=250, 500, 1000$) and plot resulting test accuracy vs. $m$ to replicate Table 2 trends.
3. **Ablation on Forget Set Size**: Vary forget data percentage (5%, 10%, 15%) and observe widening performance gap as $n_f$ increases.

## Open Questions the Paper Calls Out
- **Open Question 1**: Can Hessian approximation techniques (diagonalization, Hessian-vector products) be integrated to enable computationally feasible source-free unlearning for large-scale deep models?
- **Open Question 2**: How does the approximation assumption hold in highly non-convex loss landscapes beyond the mixed-linear setting?
- **Open Question 3**: Can the theoretical upper bound on gradient norm be tightened to maintain performance when the ratio of forget data to retain data is high?

## Limitations
- Computational cost of SDP optimization becomes prohibitive for large-scale deep networks
- Performance degrades as the percentage of forget data increases relative to remaining data
- The linearization approximation for DNNs may not generalize well to deeper or more complex architectures

## Confidence
- **High**: Theoretical guarantees for convex linear models, SDP-based Hessian estimation method
- **Medium**: MIA score performance indicating successful unlearning, accuracy gap relative to retrained models
- **Low**: Robustness of mixed-linear extension to arbitrary DNNs, precise conditions for acceptable approximation error

## Next Checks
1. Test method robustness when forget set is drawn from underrepresented classes to measure distribution shift effects
2. Evaluate on deeper CNN architectures (e.g., ResNet-50) or transformer models to test linearization limits
3. Validate method using alternative convex loss functions (e.g., logistic loss) beyond the quadratic loss used in experiments