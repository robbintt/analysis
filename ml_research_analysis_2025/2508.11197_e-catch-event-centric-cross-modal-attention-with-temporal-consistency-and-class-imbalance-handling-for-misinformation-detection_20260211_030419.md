---
ver: rpa2
title: 'E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and
  Class-Imbalance Handling for Misinformation Detection'
arxiv_id: '2508.11197'
source_url: https://arxiv.org/abs/2508.11197
tags:
- temporal
- misinformation
- detection
- e-catch
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: E-CaTCH is a multimodal misinformation detection framework designed
  to address challenges posed by cross-modal inconsistencies, temporal evolution,
  and class imbalance. It clusters posts into pseudo-events based on textual and temporal
  similarity, then applies intra-modal self-attention and bidirectional cross-modal
  attention with a soft gating mechanism to fuse text and image features.
---

# E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection

## Quick Facts
- **arXiv ID:** 2508.11197
- **Source URL:** https://arxiv.org/abs/2508.11197
- **Reference count:** 40
- **Primary result:** E-CaTCH achieves state-of-the-art results (95.5% accuracy) on Fakeddit, India Elections (89.8%), and COVID-19 MISINFOGRAPH (89.5%) benchmarks.

## Executive Summary
E-CaTCH is a multimodal misinformation detection framework that clusters posts into pseudo-events based on textual and temporal similarity, then fuses text and image features via bidirectional cross-modal attention with a soft gating mechanism. The model captures narrative evolution using overlapping temporal windows and a trend-aware LSTM with momentum and semantic shift signals. Classification is performed at the event level with adaptive class weighting and temporal consistency regularization to handle class imbalance and prevent erratic predictions. E-CaTCH demonstrates strong cross-dataset generalization and supports interpretability through its modular design.

## Method Summary
E-CaTCH clusters posts into pseudo-events using BERT embeddings and hierarchical clustering, then processes each event through a multimodal attention pipeline. Text features from BERT and image features from ResNet-152 are refined via intra-modal self-attention, then aligned using bidirectional cross-modal attention with a learned soft gating mechanism. Temporal trends are modeled using overlapping windows and a trend-aware LSTM that incorporates semantic shift and momentum signals. The model classifies events using a composite loss function that includes adaptive weighted cross-entropy, temporal consistency regularization, and ℓ2 regularization to handle class imbalance and smooth narrative evolution.

## Key Results
- Achieves 95.5% accuracy on Fakeddit, 89.8% on India Elections, and 89.5% on COVID-19 MISINFOGRAPH benchmarks
- Outperforms existing methods across all three datasets in accuracy, precision, recall, and F1-score metrics
- Demonstrates strong cross-dataset generalization capabilities
- Shows robust performance under various challenging conditions including class imbalance and temporal evolution

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Bidirectional cross-modal attention with soft gating improves detection by resolving conflicts between text and image modalities.
- **Mechanism:** The model extracts features using BERT and ResNet, applies intra-modal self-attention, and then aligns them via cross-attention (Text→Image and Image→Text). A learned gating vector $g_i$ dynamically weights these two directional streams, allowing the model to suppress noisy or misleading modalities per instance.
- **Core assumption:** Misinformation often contains inconsistency between modalities, and one modality is typically more reliable than the other for a given post.
- **Evidence anchors:**
  - [section 3.2] Defines the soft gating equation $P_i = \sigma(g_i) \odot C^{T \to I}_i + (1-\sigma(g_i)) \odot C^{I \to T}_i$.
  - [abstract] Mentions resolving "inconsistencies between modalities" via "soft gating mechanism."
- **Break condition:** If text and image are semantically consistent in both real and fake news, the gating signal may lack discriminative gradients.

### Mechanism 2
- **Claim:** Modeling narrative evolution via overlapping temporal windows and momentum signals captures the "drift" of misinformation events better than static analysis.
- **Mechanism:** Posts are clustered into pseudo-events. Within each, the model creates overlapping time windows and computes semantic shift $\Delta_t$ and momentum $M_t$. These are fed into a trend-aware LSTM to encode narrative trajectory.
- **Core assumption:** Misinformation narratives exhibit distinct temporal dynamics compared to legitimate content.
- **Evidence anchors:**
  - [section 3.3] Details the construction of $\Delta_t$ and $M_t$ and the LSTM input $\bar{L}_t = [L_t; \Delta_t; M_t]$.
  - [abstract] Highlights "overlapping windows" and "trend-aware LSTM."
- **Break condition:** If clustering fails to group related posts or temporal density is too sparse, the "trend" becomes noise.

### Mechanism 3
- **Claim:** A composite loss function enforces stable learning under class imbalance and prevents erratic predictions over time.
- **Mechanism:** The total loss combines adaptive weighted cross-entropy, ℓ2 regularization, and Temporal Consistency Loss ($L_{TC}$). $L_{TC}$ penalizes large Euclidean distances between adjacent LSTM hidden states.
- **Core assumption:** Valid narrative evolution is smooth; abrupt changes in latent space likely indicate noise.
- **Evidence anchors:**
  - [section 3.4] Defines $L_{TC} = \sum \|T_t - T_{t-1}\|_2 \cdot \text{sim}(T_t, T_{t-1})$.
  - [abstract] References "temporal consistency regularization."
- **Break condition:** If real-world events genuinely shift abruptly, this regularization may over-smooth the representation.

## Foundational Learning

- **Concept: Multi-Head Attention (MHA)**
  - **Why needed here:** The framework relies on MHA for both intra-modal refinement and cross-modal alignment. Understanding Query/Key/Value interactions is required to debug the fusion logic.
  - **Quick check question:** Can you explain why the paper uses $H^{text}$ as Query and $H^{img}$ as Key/Value in the Text→Image attention stream?

- **Concept: LSTM Sequence Modeling**
  - **Why needed here:** The core of the temporal encoder is an LSTM. You must understand hidden state propagation to interpret how "momentum" features influence the final event classification.
  - **Quick check question:** Why might an LSTM be preferred over a standard Transformer for the relatively short, windowed sequences in this specific architecture?

- **Concept: Class Imbalance Strategies**
  - **Why needed here:** The paper explicitly tackles skewed data via adaptive weights.
  - **Quick check question:** How does the adaptive weight $w_c = \bar{n} / (n_c + \epsilon)$ change the gradient contribution of a rare "fake" sample compared to a standard loss?

## Architecture Onboarding

- **Component map:** Encoders (BERT + ResNet) → Intra-modal Self-Attn → Bi-directional Cross-Attn → Soft Gating (Fusion) → Temporal Windowing → Semantic Shift/Momentum → LSTM → Linear Classifier with Composite Loss
- **Critical path:** The Soft Gating output ($P_i$) is the critical junction. If this fused embedding is poor, the subsequent temporal aggregation ($L_t$) will average out noise rather than signal.
- **Design tradeoffs:**
  - No Normalization Layers: The paper omits LayerNorm/BatchNorm, arguing the shallow design and LSTM gating make it unnecessary. This reduces complexity but may require careful learning rate tuning.
  - Pseudo-Events vs. Explicit: Clusters are derived via textual similarity, not ground-truth events. This is scalable but risks mixing unrelated topics.
- **Failure signatures:**
  - Gating Collapse: $\sigma(g_i)$ saturates to 0.5 or 1.0 for all inputs, meaning the model ignores one modality entirely.
  - Temporal Smoothing: The Temporal Consistency Loss dominates, pushing all hidden states $T_t$ to a constant vector, resulting in high accuracy on the majority class but zero recall on the minority class.
- **First 3 experiments:**
  1. Sanity Check - Modality Ablation: Run inference using only text features to establish a performance floor.
  2. Window Sensitivity: Vary the overlap percentage (20% vs. 50%) to see if the "narrative drift" signal is robust.
  3. Loss Decomposition: Train three separate models: one with only Weighted CE, one with CE+Consistency, and the Full Model to quantify the exact contribution of the temporal consistency regularizer.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can extending E-CaTCH to process audio and video modalities improve the detection of sophisticated misinformation like deepfakes?
- **Basis in paper:** [explicit] Section 6 states that expanding the framework to incorporate modalities such as audio and video could facilitate more comprehensive fusion for emerging forms like deepfakes.
- **Why unresolved:** The current architecture relies strictly on static image and text encoders (ResNet-152 and BERT-base), lacking the temporal and auditory feature extractors necessary for video analysis.
- **What evidence would resolve it:** Experimental results on video-based misinformation benchmarks demonstrating performance improvements over the current static image-based model.

### Open Question 2
- **Question:** Does integrating structured knowledge graphs enhance the model's interpretability and accuracy in domain-specific contexts?
- **Basis in paper:** [explicit] Section 6 suggests that linking textual claims to verified knowledge graphs would allow automated cross-verification, particularly benefiting authoritative domains like healthcare.
- **Why unresolved:** E-CaTCH currently operates as a data-driven deep learning model without explicit access to external truth databases or structured facts to ground its reasoning.
- **What evidence would resolve it:** Ablation studies on datasets like COVID-19 MISINFOGRAPH showing increased accuracy and explainability when knowledge graph embeddings are injected into the fusion mechanism.

### Open Question 3
- **Question:** Can continual or online learning strategies be integrated to adapt to breaking news without full model retraining?
- **Basis in paper:** [explicit] Section 6 identifies the need for advanced domain adaptation and incremental learning to handle rapidly emerging topics and sudden outbreaks in real-time.
- **Why unresolved:** The framework currently processes posts in batched, overlapping temporal windows and requires re-training to adapt to significant distributional shifts or new narrative patterns.
- **What evidence would resolve it:** Evaluation of model drift and adaptation speed on a streaming data feed, comparing the performance of an incremental update rule against the static baseline.

### Open Question 4
- **Question:** How does incorporating social-contextual information, such as user profiles and propagation networks, compare to the current content-based approach?
- **Basis in paper:** [explicit] Section 6 notes that social-contextual information remains an important area for future exploration, specifically suggesting Graph Neural Networks for modeling diffusion patterns.
- **Why unresolved:** The current methodology treats posts primarily as content items within temporal clusters, ignoring the social topology and user-level attributes that often signal coordinated misinformation campaigns.
- **What evidence would resolve it:** Comparative experiments on datasets with rich social metadata evaluating if adding graph-based social features to the event encoder improves recall for organized disinformation.

## Limitations
- Key hyperparameters (feature dimension, attention heads, LSTM size, learning rate, batch size, window length) are not specified, making exact reproduction challenging
- The clustering procedure for pseudo-events is underspecified (linkage method, distance threshold)
- No per-class performance metrics or confusion matrices are provided, limiting assessment of minority class detection
- The soft gating mechanism's learned weights are not analyzed to verify dynamic weighting across different post types

## Confidence

- **High confidence:** The overall framework architecture (BERT + ResNet → attention → soft gating → temporal LSTM → classification) is clearly specified and internally consistent
- **Medium confidence:** The reported benchmark results are specific and verifiable against stated datasets, but lack of per-class metrics reduces confidence in practical utility
- **Low confidence:** The claim that soft gating "resolves conflicts between text and image modalities" lacks empirical validation through analysis of gating weights

## Next Checks

1. **Gating Mechanism Analysis:** Extract and analyze the learned gating weights σ(g_i) across different post types to verify dynamic modality weighting and check for gating collapse.
2. **Temporal Consistency Regularization Impact:** Train separate models with varying λ_TC values (0.0, 0.1, 1.0, 10.0) and analyze impact on minority class recall; plot hidden state trajectories to verify smooth transitions.
3. **Cross-Dataset Generalization Stress Test:** Evaluate the model trained on one dataset using a held-out test set from another dataset to quantify cross-dataset generalization claims and report per-class metrics.