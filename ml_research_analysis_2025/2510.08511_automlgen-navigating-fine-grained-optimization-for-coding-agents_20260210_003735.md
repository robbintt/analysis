---
ver: rpa2
title: 'AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents'
arxiv_id: '2510.08511'
source_url: https://arxiv.org/abs/2510.08511
tags:
- automlgen
- tasks
- performance
- search
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AutoMLGen is a coding agent that combines a curated ML knowledge
  base with Monte Carlo Graph Search (MCGS) to autonomously generate and optimize
  end-to-end ML pipelines. It addresses the limitations of LLMs in specialized ML
  domains and the knowledge isolation in tree-based search by enabling cross-branch
  trajectory reuse and multi-branch fusion.
---

# AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents

## Quick Facts
- arXiv ID: 2510.08511
- Source URL: https://arxiv.org/abs/2510.08511
- Reference count: 37
- Primary result: Achieves 36.4% average medal rate and 18.7% gold medal rate on MLE-Bench under 12-hour budget

## Executive Summary
AutoMLGen addresses the challenge of autonomously generating and optimizing end-to-end machine learning pipelines by combining a curated ML knowledge base with Monte Carlo Graph Search (MCGS). The system overcomes limitations of both large language models in specialized ML domains and the knowledge isolation inherent in traditional tree-based search approaches. By enabling cross-branch trajectory reuse and multi-branch fusion, AutoMLGen effectively navigates the complex search space of ML pipeline construction. The architecture demonstrates state-of-the-art performance on the MLE-Bench benchmark, setting a new standard for autonomous ML engineering agents.

## Method Summary
AutoMLGen integrates a comprehensive ML knowledge base containing over 600 entities with an enhanced Monte Carlo Graph Search algorithm. The MCGS extends traditional MCTS by introducing graph edges that enable trajectory sharing across different branches, addressing the exploration limitations of standard tree search. The system employs fine-grained operators that improve execution stability and allows for dynamic decision-making throughout the pipeline construction process. A multi-branch fusion mechanism combines promising partial solutions from different search paths, while cross-branch trajectory reuse prevents redundant exploration and accelerates convergence to optimal solutions.

## Key Results
- Achieves 36.4% average medal rate on MLE-Bench benchmark
- Obtains 18.7% gold medal rate under 12-hour time budget
- Outperforms all baseline approaches, establishing new state-of-the-art performance

## Why This Works (Mechanism)
AutoMLGen succeeds by addressing two fundamental challenges in autonomous ML pipeline generation: the knowledge gap in general-purpose LLMs and the exploration limitations of traditional search algorithms. The curated ML knowledge base provides domain-specific expertise that general models lack, while MCGS with cross-branch trajectory reuse and multi-branch fusion enables more efficient exploration of the solution space. Fine-grained operators ensure stable execution by breaking down complex operations into manageable steps. The combination of these elements creates a system that can navigate the intricate trade-offs involved in ML pipeline optimization while maintaining robustness and adaptability.

## Foundational Learning

**Monte Carlo Graph Search (MCGS)**
- Why needed: Extends MCTS to enable cross-branch trajectory reuse and better exploration of complex ML pipeline spaces
- Quick check: Verify that graph edges are properly established between promising nodes across different branches

**Cross-branch trajectory reuse**
- Why needed: Prevents redundant exploration and accelerates convergence by sharing successful paths between search branches
- Quick check: Confirm that trajectory sharing metrics show reduced redundancy compared to standard MCTS

**Multi-branch fusion**
- Why needed: Combines promising partial solutions from different search paths to construct superior complete pipelines
- Quick check: Measure whether fusion operations consistently produce better results than individual branches

**Fine-grained operators**
- Why needed: Break down complex ML operations into stable, executable steps to improve overall system reliability
- Quick check: Track failure rates of individual operator executions versus monolithic operations

## Architecture Onboarding

**Component Map**
Knowledge Base (600+ entities) -> MCGS Planner -> Execution Engine -> Pipeline Repository -> Evaluation Module -> Feedback Loop to MCGS

**Critical Path**
1. Knowledge Base retrieval for initial pipeline components
2. MCGS search with cross-branch trajectory reuse
3. Multi-branch fusion of promising solutions
4. Execution and evaluation of generated pipelines
5. Feedback incorporation for subsequent iterations

**Design Tradeoffs**
- Static curated knowledge base vs. dynamic learning: Chosen for reliability over adaptability
- Graph-based search vs. pure tree search: Added complexity for improved exploration efficiency
- Fine-grained operators vs. coarse-grained actions: Reduced execution failures at cost of increased planning steps

**Failure Signatures**
- Knowledge base coverage gaps leading to suboptimal initial pipelines
- MCGS convergence to local optima without proper trajectory sharing
- Execution engine failures due to operator incompatibility
- Evaluation module misclassification affecting feedback quality

**First Experiments**
1. Run MCGS with and without cross-branch trajectory reuse on simple ML tasks to measure exploration efficiency
2. Test multi-branch fusion on partial pipelines from different search branches to verify improvement metrics
3. Execute fine-grained operators versus coarse-grained alternatives on identical tasks to quantify stability gains

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on curated knowledge base raises scalability and maintenance concerns
- 12-hour time budget may limit applicability to time-sensitive real-world scenarios
- Evaluation focused on MLE-Bench benchmark, requiring validation on broader ML engineering tasks

## Confidence

**High Confidence Claims:**
- MCGS significantly improves exploration and robustness compared to MCTS
- AutoMLGen achieves 36.4% average medal rate and 18.7% gold medal rate on MLE-Bench

**Medium Confidence Claims:**
- Cross-branch trajectory reuse and multi-branch fusion address knowledge isolation in tree-based search
- Fine-grained operators improve execution stability

## Next Checks
1. Conduct ablation studies isolating the contributions of cross-branch trajectory reuse, multi-branch fusion, and fine-grained operators to determine their individual impact on performance.
2. Test AutoMLGen's performance on extended time budgets (24-48 hours) to evaluate whether gold medal rates improve with additional search time.
3. Evaluate the system on a subset of MLE-Bench tasks using a dynamic knowledge base that updates during search to assess adaptability versus the static curated approach.