---
ver: rpa2
title: Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based
  Completion under Noisy and Incomplete Data
arxiv_id: '2505.09733'
source_url: https://arxiv.org/abs/2505.09733
tags:
- data
- federated
- noise
- learning
- noisy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a robust federated learning methodology designed
  to address common data quality challenges such as label noise, missing classes,
  and class imbalance in decentralized client datasets. The proposed approach introduces
  a three-stage pipeline: local noise cleaning using confidence-weighted filtering,
  federated training of conditional GANs for synthetic data generation, and data completion
  followed by robust federated classifier training.'
---

# Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data

## Quick Facts
- **arXiv ID:** 2505.09733
- **Source URL:** https://arxiv.org/abs/2505.09733
- **Reference count:** 40
- **Primary result:** Three-stage pipeline achieves up to 0.98 macro-F1 on MNIST/Fashion-MNIST under label noise and missing classes

## Executive Summary
This paper presents a three-stage federated learning pipeline designed to address label noise, missing classes, and class imbalance in decentralized client datasets. The approach combines local confidence-weighted noise filtering, federated training of conditional GANs for synthetic data generation, and robust classifier training using FedProx regularization. Experiments demonstrate that noise cleaning alone significantly improves performance, with additional GAN-based completion providing further gains on complex datasets.

## Method Summary
The methodology employs a three-stage pipeline: (1) local noise cleaning using stratified K-fold cross-validation to compute confidence scores based on entropy, prediction margin, and clustering consistency, followed by adaptive thresholding to remove low-confidence samples; (2) federated training of conditional GANs using FedAvg to generate synthetic samples for missing classes; and (3) robust federated classifier training using either FedAvg or FedProx with synthetic data augmentation. The system is evaluated on MNIST and Fashion-MNIST across various noise levels and missing class scenarios.

## Key Results
- CleanAvg and CleanProx models consistently outperform baselines, achieving up to 0.98 macro-F1 under ideal conditions
- Noise cleaning stage alone provides substantial performance gains across all tested scenarios
- GAN-based data completion improves F1 scores on Fashion-MNIST but shows limited benefit on simpler MNIST dataset
- FedProx regularization helps stabilize training on heterogeneous, non-IID data distributions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Local noise filtering based on multi-metric confidence scores improves downstream federated model accuracy by removing erroneous labels before aggregation
- **Mechanism:** Each client trains a lightweight CNN using Stratified K-Fold cross-validation. For every sample, the system calculates an aggregated confidence score $C_{agg}$ derived from prediction entropy, prediction margin, and clustering consistency (Silhouette score). Samples falling below an adaptive threshold $T$ (based on the mean, median, and 75th percentile of local scores) are discarded from the local training set
- **Core assumption:** Label noise correlates with low prediction confidence and low clustering consistency (i.e., noisy samples are outliers in the feature/label joint space), and local models are sufficiently accurate to detect these outliers
- **Evidence anchors:** [abstract] "systematically enhances data integrity through adaptive noise cleaning"; [section] Section III.B, Equation (2): "threshold is computed as the average of the mean, median, and 75th percentile"; [corpus] "Robust Federated Learning against Noisy Clients via Masked Optimization" aligns with the need to handle complex label noise
- **Break condition:** If noise is adversarial and specifically crafted to produce high-confidence errors, the entropy/margin filters may fail to detect it

### Mechanism 2
- **Claim:** Federated training of conditional GANs (cGANs) enables data completion for missing classes without violating privacy, mitigating weight divergence caused by non-IID data
- **Mechanism:** Clients collaboratively train a generator $G$ and discriminator $D$ using Federated Averaging (FedAvg). Once converged, clients with missing classes sample latent vectors $z$ and conditional labels $y$ to generate synthetic images $\hat{x} = G(z, y)$. These images are normalized and added to the local dataset to balance the class distribution before the final classifier training
- **Core assumption:** The generator learns a generalized distribution where synthetic samples for a missing class lie on the same manifold as real data from other clients, improving rather than confusing the classifier
- **Evidence anchors:** [abstract] "collaborative conditional GAN-based synthetic data generation... improves data quality"; [section] Section V.C: "models incorporating conditional GAN based augmentation... achieved significantly higher F1 scores"; [corpus] Weak direct evidence in provided neighbors for the specific "completion" mechanism
- **Break condition:** If the global generator suffers mode collapse or produces low-fidelity artifacts for specific classes, injecting this data introduces label noise (correct label, wrong features), degrading the classifier

### Mechanism 3
- **Claim:** FedProx regularization stabilizes the global model convergence when training on the cleaned and synthetically augmented datasets
- **Mechanism:** The final classifier training utilizes FedProx, which adds a proximal term $L_{prox} = \sum_j \|w_j - w_j^{(global)}\|^2$ to the local loss function. This penalizes excessive deviation of local weights from the global model during updates, accommodating the heterogeneity (Non-IID nature) that remains even after data completion
- **Core assumption:** The direction of the global model is beneficial enough that local updates should be tethered to it, preventing catastrophic forgetting of classes abundant in other clients
- **Evidence anchors:** [abstract] "robust federated model training... ensuring practicality for resource constrained edge devices"; [section] Section III.D, Equation (7): "Total loss: $L = L_{CE} + \frac{\mu}{2} L_{prox}$"; [corpus] "FedGSCA" and related works implicitly rely on robust aggregation
- **Break condition:** If specific clients have highly unique features (strongly non-IID) that are actually valid but suppressed by the proximal term, the regularization may prevent the global model from learning these distinct features

## Foundational Learning

- **Concept: Stratified K-Fold Cross-Validation**
  - **Why needed here:** This is the engine of the noise cleaning stage. It ensures that every single data point in a client's dataset gets a "confidence score" from a model that was *not* trained on that specific point, preventing overfitting bias in the noise detection
  - **Quick check question:** If a client has a severely imbalanced dataset, how does stratification in K-Fold ensure the noise estimator remains reliable for minority classes?

- **Concept: Conditional GANs (cGANs)**
  - **Why needed here:** Standard GANs generate random samples; cGANs allow the generation of samples *for a specific class*. This is a prerequisite for the "Data Completion" stage, allowing clients to fill specific gaps (e.g., "generate more 'class 5' samples") rather than just random data
  - **Quick check question:** In a federated setting, if the generator generates an image for class $c$, but that image looks like class $k$ to a human, how does this "semantic drift" impact the final classifier?

- **Concept: Non-IID Data (Non-Independent and Identically Distributed)**
  - **Why needed here:** The entire paper is a response to the Non-IID problem (missing classes and local bias). Understanding that local data distributions $P_i(X,Y)$ differ from the global distribution $P(X,Y)$ is necessary to understand why weight divergence occurs and why synthetic data completion is proposed as a solution
  - **Quick check question:** Does balancing the local dataset via synthetic data fully transform the Non-IID problem into an IID one for the client, or does the distribution of *real* features remain Non-IID?

## Architecture Onboarding

- **Component map:** Client-Side Cleaner (Stratified K-Fold CNN + Confidence Scorer + Thresholding Filter) -> Federated cGAN Module (Local Generator/Discriminator trainers + FedAvg Aggregator) -> Synthetic Augmenter (Missing class detection + GAN generation + Dataset merging) -> Robust Classifier (Local CNN trainer + FedProx Aggregator)

- **Critical path:** The **Noise Cleaning (Stage 1)** is the most high-impact component. The results (Table II) show "CleanAvg" and "CleanProx" significantly outperform baselines even without GANs. If the cleaning threshold is wrong, the system fails immediately by either deleting good data or keeping poison

- **Design tradeoffs:**
  - **Compute vs. Quality:** The 3-stage pipeline (Clean -> GAN -> Train) is computationally expensive for edge devices. The paper suggests "CleanProx" (Stage 1 + Stage 3, skipping GANs) as a highly effective, lower-compute alternative for simpler datasets like MNIST
  - **Privacy vs. Utility:** Sharing GAN weights allows for high-fidelity data synthesis but theoretically increases the attack surface for model inversion compared to standard classifier weight sharing

- **Failure signatures:**
  - **Over-pruning:** If the adaptive threshold $T$ is too aggressive, clients may discard 50%+ of their data, causing underfitting
  - **GAN Hallucination:** If the federated GAN fails to converge (common with Non-IID data), the synthetic "completion" data will act as noise, causing the final classifier accuracy to drop below the "Noisy" baseline

- **First 3 experiments:**
  1. **Isolate Cleaning:** Run `CleanAvg` vs. `FedAvg (Noisy)` on MNIST with 30% label noise to validate the signal-to-noise ratio of the confidence scoring mechanism
  2. **Stress Test Missing Classes:** Run `GenCleanProx` with 5 missing classes per client to verify if the cGAN actually generates usable features for unseen classes or just noise
  3. **Ablation on Threshold:** Vary the threshold calculation (e.g., use Median only vs. Mean+Median+P75) to see how sensitive the retention rate is to the definition of "confidence"

## Open Questions the Paper Calls Out
- **Question:** Does the proposed three-stage pipeline maintain robustness and computational feasibility when applied to complex, real-world federated datasets and larger client populations?
- **Question:** Can model compression techniques effectively reduce the computational burden of the GAN training stage for highly resource-constrained edge devices?
- **Question:** What is the quantitative impact of the proposed noise cleaning and synthetic data completion on the convergence speed (number of communication rounds) of the global model?

## Limitations
- Results are limited to MNIST and Fashion-MNIST datasets, raising questions about generalizability to more complex data
- Several critical hyperparameters remain unspecified (K-fold value, K-means cluster count, GAN training epochs, early stopping criteria)
- The federated GAN training assumes successful convergence across heterogeneous clients, which may not hold in practice
- Adaptive threshold mechanism for noise filtering could be overly aggressive, potentially discarding valid samples

## Confidence
- **High confidence:** The noise cleaning mechanism (Stage 1) is well-specified and demonstrably improves performance across multiple noise levels and missing class scenarios
- **Medium confidence:** The federated GAN training approach is theoretically sound but relies on assumptions about convergence stability and sample quality that aren't fully validated
- **Low confidence:** The specific hyperparameter choices (threshold calculation, learning rates, batch sizes) that determine practical performance remain unspecified

## Next Checks
1. **Ablation study on threshold sensitivity:** Test how varying the noise filtering threshold (mean only vs. mean+median+P75) affects per-class retention rates and overall accuracy
2. **GAN convergence validation:** Monitor generator/discriminator loss curves during federated training to verify stability and measure synthetic sample quality using classifier confidence scores
3. **Cross-dataset generalization:** Evaluate the complete pipeline on CIFAR-10 or a medical imaging dataset to assess performance beyond MNIST/Fashion-MNIST