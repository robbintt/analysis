---
ver: rpa2
title: Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets
  for Abusive Language Detection Using Traditional and Deep Learning Models
arxiv_id: '2504.21026'
source_url: https://arxiv.org/abs/2504.21026
tags:
- language
- learning
- code-mixed
- abusive
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces novel, manually annotated datasets for abusive
  language detection in code-mixed Nepali-English and Telugu-English text. The authors
  collected 5,000 Nepali-English and 2,000 Telugu-English comments from social media,
  categorized as abusive or non-abusive.
---

# Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models

## Quick Facts
- arXiv ID: 2504.21026
- Source URL: https://arxiv.org/abs/2504.21026
- Authors: Manish Pandey; Nageshwar Prasad Yadav; Mokshada Adduru; Sawan Rai
- Reference count: 29
- This paper introduces novel, manually annotated datasets for abusive language detection in code-mixed Nepali-English and Telugu-English text, achieving 78.3% accuracy for Nepali-English and 80.5% for Telugu-English using large language models.

## Executive Summary
This paper addresses the challenge of detecting abusive language in code-mixed social media text by introducing two manually annotated datasets: 5,000 Nepali-English and 2,000 Telugu-English comments. The authors evaluate multiple machine learning approaches including traditional classifiers, deep learning models, and large language models using 10-fold cross-validation and statistical significance testing. Results demonstrate that transformer-based LLMs significantly outperform other models, achieving 78.3% accuracy for Nepali-English and 80.5% for Telugu-English. The study provides valuable benchmarks and insights for abusive language detection in low-resource code-mixed settings while highlighting the challenges of linguistic blending and cultural context.

## Method Summary
The authors collected social media comments from Twitter, YouTube, and Instagram, then manually annotated them as abusive or non-abusive. Text preprocessing included NFKC Unicode normalization, lowercase conversion, punctuation and emoji removal, tokenization, and stopword filtering. All models used 768-dimensional mBERT embeddings as input features. Traditional classifiers (Logistic Regression, SVM, Random Forest), deep learning models (Neural Network, CNN, LSTM), and transformer-based LLMs were evaluated using 10-fold cross-validation with paired t-tests for statistical significance. The best-performing configurations were Nepali-English with learning rate 1e-5 for 4 epochs (78.3% accuracy) and Telugu-English with learning rate 3e-5 for 3 epochs (80.5% accuracy).

## Key Results
- Transformer-based LLMs achieved 78.3% accuracy for Nepali-English and 80.5% for Telugu-English, significantly outperforming traditional ML models
- Learning rate optimization was critical, with 1e-5 yielding best results for Nepali and 3e-5 for Telugu; higher rates caused catastrophic degradation
- The Telugu dataset showed CMI=0 peaks, indicating Romanized Telugu words were misclassified as English, underestimating true code-mixing levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based LLMs achieve superior performance through contextual cross-lingual understanding
- Mechanism: Pre-trained multilingual representations capture semantic relationships across language boundaries, enabling recognition of abusive patterns even when lexical markers are split between native and English words
- Core assumption: Pre-training corpus contains sufficient multilingual signal for effective transfer to low-resource code-mixed combinations
- Evidence anchors:
  - "Results showed that LLMs significantly outperformed other models, achieving 78.3% accuracy for Nepali-English and 80.5% for Telugu-English"
  - "Analysis showed critical dependencies among learning rates, training length, and model performance, with the best configuration (1e-5 learning rate, 4 epochs) achieving 78.3% accuracy"
  - Related work confirms transformer-based approaches are emerging as standard for Telugu code-mixed tasks

### Mechanism 2
- Claim: mBERT embeddings provide unified semantic representations enabling traditional classifiers to process code-mixed text
- Mechanism: All models consume 768-dimensional mBERT embeddings rather than raw text, allowing non-transformer architectures to benefit from cross-lingual pre-training without architectural modification
- Core assumption: Embedding quality is consistent across both high-frequency English tokens and lower-frequency Romanized native tokens
- Evidence anchors:
  - "The text is then tokenized using the mBERT tokenizer, which breaks the text into subword units and produces 768-dimensional embeddings for each token"
  - All traditional and deep learning models explicitly use "768-dimensional mBERT embeddings" as input features

### Mechanism 3
- Claim: Learning rate selection is the dominant factor in LLM fine-tuning success for low-resource code-mixed datasets
- Mechanism: Smaller learning rates (1e-5 to 3e-5) enable stable gradient updates that preserve pre-trained multilingual knowledge while adapting to task-specific patterns; higher rates (5e-5) cause catastrophic interference
- Core assumption: Optimal learning rate is dataset-specific and not transferable across language pairs
- Evidence anchors:
  - Nepali dataset: "higher rates showed extreme degradation: 3e-5 demonstrated volatility... whereas 5e-5 catastrophically failed (53.9% for all epochs)"
  - Telugu dataset: "higher learning rate models (5e-5) always performed poorly (57.75% accuracy for all epochs)"

## Foundational Learning

- Concept: Code-Mixing Index (CMI)
  - Why needed here: Quantifies linguistic complexity of code-mixed datasets; CMI scores revealed Telugu-English comments appeared monolingual due to Romanization identification failures
  - Quick check question: If CMI=0 for a dataset known to contain mixed languages, what preprocessing failure does this indicate?

- Concept: Transliteration/Romanization Variance
  - Why needed here: Romanized Telugu and Nepali lack standard spelling conventions; same words appear with multiple spellings (e.g., "chepparu," "cheparu," "cheppaaru"), creating vocabulary explosion and tokenization challenges
  - Quick check question: How would you normalize "kasto," "kastho," and "casto" to a single canonical form without access to native script?

- Concept: Statistical Significance Testing with Paired t-Tests
  - Why needed here: Determines whether observed performance differences between models are meaningful or due to random variation; paper uses p<0.05 threshold across 10-fold cross-validation
  - Quick check question: If Model A beats Model B by 2% accuracy but p=0.25, what conclusion should you draw?

## Architecture Onboarding

- Component map:
  Data Collection -> Manual Annotation -> Text Preprocessing (Unicode normalization, punctuation removal, emoji conversion) -> mBERT Tokenization -> 768-dim Embedding Generation -> Model Training (LR/SVM/RF/NN/CNN/LSTM/LLM) -> 10-Fold Cross-Validation -> Paired t-Test Statistical Analysis

- Critical path:
  Embedding generation quality directly limits all downstream classifier performance; if mBERT fails on Romanized tokens, even optimal hyperparameters cannot recover accuracy
  Hyperparameter tuning (especially learning rate for LLMs) is the second critical path—24.4% accuracy gap observed between best and worst configurations

- Design tradeoffs:
  Dataset size vs. annotation quality: Telugu dataset (2,000 samples) showed class imbalance (60:40) while Nepali (5,000 samples) was more balanced (53:47), potentially affecting model generalization
  Model complexity vs. low-resource constraints: Deeper architectures (e.g., 512-256 hidden layers) improved performance but risk overfitting on limited data
  Bidirectional vs. unidirectional LSTM: Bidirectional helped on Nepali but underperformed on Telugu, suggesting language-specific optimal architectures

- Failure signatures:
  CMI=0 peak in Telugu dataset: Romanized Telugu words misclassified as English, underrepresenting true code-mixing levels
  Learning rate 5e-5 with LLMs: Consistent ~53-58% accuracy across all epochs indicates optimization divergence rather than underfitting
  Random Forest with bootstrap enabled: Reduced minority class recall, suggesting bootstrap sampling amplifies class imbalance effects

- First 3 experiments:
  1. Establish baseline with mBERT embeddings + Logistic Regression using class_weight='balanced' and C=0.01 (72.3% F1 on Nepali per paper)
  2. Fine-tune LLM with learning rate sweep [1e-5, 3e-5, 5e-5] across 2-4 epochs; expect optimal at 1e-5 for Nepali and 3e-5 for Telugu
  3. Implement paired t-test validation across 10 folds to confirm statistical significance before concluding model A > model B

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specialized transliteration normalization techniques affect the performance of abusive language detection models in Romanized code-mixed text?
- Basis in paper: [explicit] The Conclusion states that "inconsistent Romanization" remains a challenge and suggests future work should focus on "the integration of more refined preprocessing techniques"
- Why unresolved: Current study utilized standard preprocessing (lowercasing, emoji removal), which does not normalize spelling variations inherent in user-generated Romanized text
- Evidence to resolve: A comparative study measuring model accuracy on raw versus transliteration-normalized datasets would determine if normalizing spelling variations reduces noise and improves classification

### Open Question 2
- Question: To what extent does the implementation of culturally sensitive annotation guidelines reduce subjectivity and improve inter-annotator agreement?
- Basis in paper: [explicit] The Conclusion identifies the "subjective nature of abuse annotation" as a persistent issue and explicitly lists "culturally sensitive annotation guidelines" as an avenue for future improvement
- Why unresolved: Paper notes that defining "abusive" is inherently subjective, potentially leading to annotation bias where annotators interpret content differently based on cultural understanding
- Evidence to resolve: Re-annotating a subset of data using newly defined culturally sensitive guidelines and measuring Inter-Annotator Agreement (IAA) score against original annotation effort would provide evidence

### Open Question 3
- Question: Can improved Language Identification (LID) models correct the underestimation of code-mixing levels in Romanized Telugu text?
- Basis in paper: [inferred] Section 4.1 notes that CMI for Telugu dataset was likely skewed because "Telugu words written in the Roman script are not being identified as Telugu"
- Why unresolved: Current analysis likely misclassified Romanized Telugu tokens as English or "universal," falsely inflating count of monolingual comments (CMI = 0) and obscuring true linguistic complexity
- Evidence to resolve: Applying a robust Romanized LID tool to re-tag tokens and recalculating CMI distribution would reveal true level of mixing and potentially explain model behaviors

## Limitations

- The paper lacks detailed LLM architecture specifications, making exact reproduction challenging despite demonstrating superior performance
- CMI analysis revealed significant data quality issues where Romanized Telugu words were misclassified as English, suggesting preprocessing gaps that could affect model generalization
- Dataset sizes (2,000 Telugu-English, 5,000 Nepali-English) represent relatively small samples for low-resource settings, with Telugu dataset exhibiting class imbalance (60:40) that may influence performance metrics

## Confidence

- **High confidence**: Transformer-based LLMs outperform traditional ML and deep learning models on code-mixed abusive language detection (78.3% vs 73.1% Nepali-English accuracy; 80.5% vs 77.8% Telugu-English accuracy)
- **Medium confidence**: mBERT embeddings enable effective cross-lingual representation learning for code-mixed text
- **Medium confidence**: Learning rate optimization is critical for low-resource code-mixed fine-tuning
- **Low confidence**: The claimed superior performance is entirely attributable to the proposed methodology rather than dataset-specific characteristics or annotation artifacts

## Next Checks

1. Reproduce the learning rate sensitivity analysis by fine-tuning the LLM with lr ∈ {1e-5, 3e-5, 5e-5} across 2-4 epochs on both datasets, confirming the catastrophic degradation at 5e-5 and optimal performance at 1e-5 (Nepali) and 3e-5 (Telugu) as reported

2. Conduct ablation studies on preprocessing components by systematically removing NFKC normalization, Unicode filtering, and stopword removal to quantify their individual contributions to model performance and identify potential CMI calculation failures

3. Validate mBERT embedding quality by analyzing token-level representations for Romanized Nepali and Telugu words versus English words, measuring whether subword tokenization preserves semantic integrity for native language tokens in code-mixed contexts