---
ver: rpa2
title: Time Series Similarity Score Functions to Monitor and Interact with the Training
  and Denoising Process of a Time Series Diffusion Model applied to a Human Activity
  Recognition Dataset based on IMUs
arxiv_id: '2505.14739'
source_url: https://arxiv.org/abs/2505.14739
tags:
- similarity
- training
- sequences
- time
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study addresses the challenge of objectively monitoring and\
  \ optimizing the training and denoising processes of Denoising Diffusion Probabilistic\
  \ Models (DDPMs) for time series data. The authors propose using similarity score\
  \ functions\u2014specifically, the adapted Class-Optimized Global Alignment Kernel\
  \ (C-Opt GAK) and Cosine similarity\u2014to assess the quality of synthetic sequences\
  \ generated by the IMUDiffusion model."
---

# Time Series Similarity Score Functions to Monitor and Interact with the Training and Denoising Process of a Time Series Diffusion Model applied to a Human Activity Recognition Dataset based on IMUs

## Quick Facts
- **arXiv ID:** 2505.14739
- **Source URL:** https://arxiv.org/abs/2505.14739
- **Reference count:** 15
- **Primary result:** Early stopping based on PSD-based similarity metrics reduces DDPM training epochs by up to 28.70% and denoising steps without degrading downstream classification performance.

## Executive Summary
This paper addresses the challenge of objectively monitoring and optimizing the training and denoising processes of Denoising Diffusion Probabilistic Models (DDPMs) for time series data. The authors propose using similarity score functions—specifically, the adapted Class-Optimized Global Alignment Kernel (C-Opt GAK) and Cosine similarity—to assess the quality of synthetic sequences generated by the IMUDiffusion model. These metrics are applied to the power spectral densities (PSDs) of time series data to capture key signal characteristics independent of temporal dependencies. By integrating these similarity metrics as early stopping criteria, the authors significantly reduce the number of training epochs (by up to 28.70%) and denoising steps without compromising the quality of the generated sequences. The effectiveness of the approach is validated through classification tasks on a human activity recognition dataset, where synthetic sequences improve the macro F1-scores for most participants compared to baseline models. This method offers a resource-efficient and objective way to optimize DDPM training and denoising, with potential applications across various time series domains.

## Method Summary
The study uses IMUDiffusion, a DDPM architecture for multivariate IMU time series, with linear noise schedulers and per-sensor diffusion rates. Training involves sliding window segmentation (160 timesteps, 40 overlap) and STFT preprocessing (window 22, overlap 20, Hanning). Power spectral densities are computed via Welch's method. Two similarity metrics are employed: C-Opt GAK (optimizing σ to maximize intra-class similarity) and Cosine similarity on PSDs. Early stopping monitors synthetic-real sequence similarity every 50 epochs (training) and every 30 denoising steps. A CNN classifier (3 conv + 3 FC layers) trained via leave-one-subject-out cross-validation evaluates generated sequence quality through macro F1-score improvements.

## Key Results
- C-Opt GAK and Cosine similarity metrics successfully monitor DDPM training quality via PSD comparison
- Early stopping reduces training epochs by 19.51-28.70% and denoising steps while maintaining or improving classification performance
- Synthetic sequence augmentation improves macro F1-scores for most participants compared to baseline models
- The method provides an objective, resource-efficient approach to DDPM optimization for time series data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Comparing synthetic and real time series via Power Spectral Densities (PSDs) rather than raw signals provides a more robust quality metric for DDPM training, as it captures activity-relevant frequency characteristics independent of temporal alignment.
- **Mechanism:** Welch's method decomposes signals into windowed subsequences, computes periodograms, and averages them to estimate PSD. This transformation removes temporal dependencies, allowing similarity comparison focused on spectral signatures that define human activities (e.g., cyclic patterns in walking/running).
- **Core assumption:** The key information distinguishing activities is encoded in frequency domain characteristics rather than precise temporal dynamics.
- **Evidence anchors:**
  - [abstract] "These metrics are applied to the power spectral densities (PSDs) of time series data to capture key signal characteristics independent of temporal dependencies."
  - [Section 2.2.1] Equations 1-3 define Welch's PSD estimation; text states: "Using this approach removes the temporal dependency in the course of the sequence."
  - [corpus] Limited direct validation; related work TSGDiff addresses temporal dependencies but doesn't compare PSD vs. time-domain evaluation.
- **Break condition:** If activities are primarily distinguished by temporal dynamics (e.g., transition patterns, phase relationships) rather than frequency content, PSD-based metrics may fail to capture quality degradation.

### Mechanism 2
- **Claim:** The Class-Optimized Global Alignment Kernel (C-Opt GAK) provides dataset-adaptive similarity scoring by optimizing the scaling parameter σ to match expected intra-class similarity distributions.
- **Mechanism:** GAK computes a normalized kernel over alignment paths between sequences, with σ controlling sensitivity to small variations. C-Opt GAK selects σ by maximizing average GAK between training/validation pairs while constraining standard deviation to [0.09, 0.12], ensuring consistent similarity scores within classes.
- **Core assumption:** Training and validation sequences from the same class should exhibit high, low-variance similarity when σ is properly calibrated.
- **Evidence anchors:**
  - [abstract] "The adapted Class-Optimized Global Alignment Kernel (C-Opt GAK)..."
  - [Section 2.3.1] Equations 4-7 define GAK and C-Opt optimization; Figure 2 visualizes σ selection per class.
  - [corpus] No direct comparison in related literature; DS-Diffusion and TSGDiff use different evaluation approaches.
- **Break condition:** If inter-class and intra-class similarity distributions overlap significantly, or if activities lack cyclic structure, the σ optimization criterion may not select meaningful values.

### Mechanism 3
- **Claim:** Early stopping based on similarity score convergence reduces training epochs (19-29%) and denoising steps without degrading downstream classification performance.
- **Mechanism:** During training, synthetic batches are periodically generated and compared to real sequences. For C-Opt GAK, training stops when ≥25% of scores fall within the calibrated range. For Cosine, training stops at local maxima with 100-epoch confirmation buffer. Denoising similarly stops when similarity peaks.
- **Core assumption:** Peak similarity between synthetic and real sequences corresponds to optimal generative quality for the target classification task.
- **Evidence anchors:**
  - [abstract] "...reduce the number of training epochs (by up to 28.70%) and denoising steps without compromising the quality..."
  - [Section 3.1/Table 2] Cosine (Time) achieved 28.70% reduction; C-Opt GAK achieved 19.51% reduction.
  - [Section 3.3] "With the remaining sets we achieved higher test scores for those two participants" when using early stopping.
  - [corpus] CDNet uses contrastive diffusion but doesn't address training efficiency; no corpus papers validate early stopping via similarity metrics.
- **Break condition:** If similarity peaks before the model has learned full data distribution complexity, early stopping may underfit; conversely, if similarity metrics plateau while quality continues improving, the approach misses optimal checkpoints.

## Foundational Learning

- **Power Spectral Density (PSD) via Welch's Method:**
  - Why needed here: The entire similarity framework operates on PSDs rather than raw time series. Understanding windowing, periodograms, and averaging is essential to interpret why this removes temporal dependencies.
  - Quick check question: Given a 160-timestep signal sampled at 50Hz, what frequency resolution would you expect from Welch's method with window size 22?

- **Global Alignment Kernel (GAK):**
  - Why needed here: C-Opt GAK is the novel contribution. GAK extends dynamic time warping concepts to kernel methods, providing normalized similarity scores for variable-length sequences.
  - Quick check question: How does the scaling factor σ affect the sensitivity of GAK to small sequence differences?

- **Denoising Diffusion Probabilistic Models (DDPMs):**
  - Why needed here: The paper monitors DDPM training/denoising. Understanding the forward noising process, reverse denoising, and why loss functions don't directly measure output quality is foundational.
  - Quick check question: Why does minimizing MSE between predicted and actual noise not guarantee high-quality synthetic samples?

## Architecture Onboarding

- **Component map:**
  Input pipeline: IMU signals (50Hz, 6 axes) → Sliding windows (160 steps, 40 overlap) → STFT (window 22, overlap 20) → Frequency domain → PSD via Welch → C-Opt GAK/Cosine similarity → Early stopping trigger → IMUDiffusion (U-Net) → Linear scheduler with per-sensor rates → Denoising monitoring → Synthetic sequences → CNN classifier (3 Conv + 3 FC) → Macro F1 evaluation

- **Critical path:**
  1. Calibrate C-Opt GAK σ per class using train/validation pairs (Equation 7)
  2. Train DDPM with periodic similarity monitoring
  3. Generate synthetic sequences with monitored denoising
  4. Augment training set and evaluate via classification macro F1

- **Design tradeoffs:**
  - C-Opt GAK vs. Cosine: GAK requires σ calibration per dataset/class but provides wider score range (0.007→0.917 vs. 0.4→0.6 for Cosine PSD); Cosine is simpler but less discriminative
  - Time domain vs. PSD: PSD removes temporal alignment issues but may miss timing-sensitive features
  - Early stopping threshold: Conservative (wait for 2 confirmation steps) reduces false positives but may miss earlier optima

- **Failure signatures:**
  - Sigma values outside expected range (paper reports 0.1-1.0): suggests class structure doesn't match assumptions
  - Similarity scores volatile across epochs: indicates unstable training or inappropriate metric
  - Classification F1 decreases with synthetic augmentation: generated samples may introduce noise or mode collapse
  - Cosine similarity high for Gaussian noise (observed 0.4 in paper): metric may not distinguish signal from noise in PSD space

- **First 3 experiments:**
  1. Replicate C-Opt GAK σ calibration on held-out participant to verify generalization across subjects
  2. Compare PSD-based vs. time-domain early stopping on a non-cyclic activity (e.g., Jump Up) to test temporal-dependency assumption
  3. Ablate similarity-guided denoising by generating at fixed step counts (500, 1000, 2000, 3000) and plot similarity vs. F1 to verify correlation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the subjective standard deviation range [0.09, 0.12] for sigma calculation in C-Opt GAK impact the optimization of scaling factors for datasets with acyclic movements?
- **Basis in paper:** [explicit] The authors state the range was defined by subjective analysis and suggest analyzing different ranges and datasets, "especially for datasets with acyclic movements."
- **Why unresolved:** The current heuristic relies on assumptions valid for the specific cyclic IMU dataset used, limiting generalizability to non-cyclic data.
- **What evidence would resolve it:** Comparative results showing C-Opt GAK performance using various sigma ranges on a dataset containing non-cyclic, non-periodic time series data.

### Open Question 2
- **Question:** To what extent does the early stopping of the denoising process, which retains high-frequency noise, negatively impact the quality of synthetic signals for non-cyclic activities or different sensor types?
- **Basis in paper:** [explicit] The authors note that stopping early leads to noise and "might affect different time series signals... differently," recommending tests on different sensors and activities.
- **Why unresolved:** The current study only validates this trade-off on cyclic human activity data (IMUs), leaving the effect on other signal types unknown.
- **What evidence would resolve it:** Evaluation of classifier performance using early-stopped synthetic data generated for acyclic activities or distinct sensor modalities (e.g., physiological signals).

### Open Question 3
- **Question:** Can an automated selection process effectively identify the most suitable synthetic sequences to minimize data volume while maximizing classifier performance?
- **Basis in paper:** [explicit] The authors suggest integrating "a selection process to identify the most suitable sequences... and reduce the required amount of synthetic sequences to a minimum."
- **Why unresolved:** The current method adds all generated sequences that meet the similarity threshold, potentially including redundant or suboptimal samples.
- **What evidence would resolve it:** A comparative study showing that a filtered subset of synthetic sequences achieves equivalent or superior F1-scores compared to the full synthetic set.

## Limitations

- The study evaluates similarity metrics and early stopping only on one human activity recognition dataset, limiting generalizability to other time series domains.
- PSD-based similarity removes temporal dependencies by design, potentially excluding important timing features for activities that rely on temporal dynamics.
- Early stopping criteria lack ablation studies demonstrating that similarity peaks truly correspond to optimal generative quality versus arbitrary convergence points.

## Confidence

- **High Confidence:** The mechanism by which Welch's PSD removes temporal dependencies and enables frequency-domain comparison is well-established and mathematically sound.
- **Medium Confidence:** The effectiveness of C-Opt GAK for dataset-adaptive similarity scoring is supported by the paper's results but lacks independent validation and comparison to simpler alternatives.
- **Medium Confidence:** Early stopping based on similarity scores achieves the claimed epoch reductions, but the downstream classification improvements are participant-specific rather than consistent across all subjects.

## Next Checks

1. **Generalization Test:** Apply the C-Opt GAK calibration and early stopping approach to a non-cyclic time series domain (e.g., ECG anomaly detection or financial forecasting) to verify the method's broader applicability beyond human activity recognition.

2. **Temporal vs. Spectral Feature Importance:** Conduct an ablation study comparing PSD-based similarity metrics against time-domain similarity measures on activities known to depend on temporal dynamics (e.g., Jump Up), measuring classification performance to quantify what features are being captured or lost.

3. **Early Stopping Optimality Verification:** Generate synthetic sequences at multiple fixed denoising step counts (e.g., 500, 1000, 2000, 3000) and plot similarity scores against downstream classification F1-scores to empirically verify that similarity peaks correspond to optimal generative quality.