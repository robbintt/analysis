---
ver: rpa2
title: Learning Interpretable Differentiable Logic Networks for Tabular Regression
arxiv_id: '2505.23615'
source_url: https://arxiv.org/abs/2505.23615
tags:
- e-03
- regression
- logic
- training
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends Differentiable Logic Networks (DLNs) from classification
  to regression by introducing a SumLayer that enables continuous output predictions
  through weighted summation of binary rule activations. The key innovation is replacing
  the classification DLN's discrete class voting mechanism with a single-output neuron
  that produces real-valued predictions via learned continuous coefficients.
---

# Learning Interpretable Differentiable Logic Networks for Tabular Regression

## Quick Facts
- arXiv ID: 2505.23615
- Source URL: https://arxiv.org/abs/2505.23615
- Reference count: 40
- This paper extends Differentiable Logic Networks from classification to regression through a SumLayer that enables continuous output predictions

## Executive Summary
This paper introduces a novel extension of Differentiable Logic Networks (DLNs) to tabular regression tasks. The key innovation is the SumLayer, which replaces the classification DLN's discrete class voting mechanism with a single-output neuron that produces real-valued predictions through weighted summation of binary rule activations. The unified end-to-end training procedure simultaneously optimizes neuron functions, connections, and rule weights using temperature-annealed softmax operations. Experiments on 15 tabular regression datasets demonstrate that regression DLNs achieve predictive accuracy comparable to state-of-the-art black-box models while preserving DLN's core advantages of interpretability through human-readable logical rules and computational efficiency.

## Method Summary
The method extends DLNs from classification to regression by introducing a SumLayer that computes a weighted sum of binary rule activations. The architecture consists of three layers: ThresholdLayer (binarizes continuous features with learnable thresholds), one or more LogicLayers (apply 16 candidate Boolean functions with learned connections), and SumLayer (weighted sum with continuous coefficients). All operations use temperature-annealed softmax/sigmoid for differentiability, with Straight-Through Estimators for gradient flow. The model is trained end-to-end with hyperparameters optimized via Optuna across 128 trials per dataset. Post-training, rules are simplified symbolically using SymPy for interpretability.

## Key Results
- Regression DLNs achieve R² scores comparable to random forest and neural networks across 15 tabular datasets
- Inference operations are 5.8× lower than random forest and 86× lower than MLPs, maintaining computational efficiency
- Temperature scheduling and unified training phases are critical, with ablation showing 1.7% R² drop when disabled
- The model produces interpretable rules like "Insurance = Bias + 13.3K·(smoker==1) - 2.98K·(age>22 AND NOT children_2==1)"

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Discrete Boolean logic can be learned via gradient descent by relaxing hard operations into differentiable approximations
- Mechanism: Real-valued logic maps binary operations to [0,1] interval (e.g., real-valued AND(a,b) = a·b). Training uses softmax over learnable logits for function selection; inference uses arg-max
- Core assumption: Continuous relaxations provide meaningful gradient signals that converge to useful discrete circuits
- Evidence anchors: [section 3.1.2] real-valued AND implementation, [abstract] differentiable relaxation approach, [corpus] LGN generalization

### Mechanism 2
- Claim: Weighted sum of binary rule activations can approximate continuous regression targets while remaining interpretable
- Mechanism: SumLayer computes y = Σ Sigmoid(sⱼ/τ) · cⱼ · xⱼ where xⱼ are binary rule outputs and cⱼ are learned coefficients
- Core assumption: Regression target can be decomposed into linear combination of interpretable binary conditions
- Evidence anchors: [section 3.1.3] SumLayer design, [figure 7-9] concrete insurance prediction examples, [corpus] novel SumLayer mechanism

### Mechanism 3
- Claim: Temperature-annealed softmax/sigmoid operations improve convergence by gradually sharpening soft distributions into discrete choices
- Mechanism: Temperature τ starts high (soft distributions) and decays exponentially by factor γ until τmin, transitioning from exploration to exploitation
- Core assumption: Gradual sharpening avoids premature commitment to poor discrete configurations
- Evidence anchors: [section 4.5 ablation] 1.7% R² drop without scheduling, [table 6] tuning essential, [corpus] LGN work confirms annealing importance

## Foundational Learning

- **Real-valued (fuzzy) logic**:
  - Why needed here: Core mechanism for making Boolean operations differentiable. You must understand how AND, OR, XOR generalize from {0,1}²→{0,1} to [0,1]²→[0,1}
  - Quick check question: What is real-valued OR(a,b) for a=0.3, b=0.7? (Answer: min(1, a+b) = 1.0 for probabilistic OR)

- **Temperature annealing in softmax**:
  - Why needed here: Controls hardness of discrete choices during training. High τ → uniform distributions; low τ → near-one-hot
  - Quick check question: Given logits [2, 1, 0] and τ=2, what is the softmax probability for first element? (Answer: e¹/(e¹+e⁰·⁵+e⁰) ≈ 0.58)

- **Straight-Through Estimators (STE)**:
  - Why needed here: Forward pass uses discrete outputs (for training-inference alignment); backward pass uses continuous gradients (for learning)
  - Quick check question: If forward pass outputs 0 or 1 via Heaviside, how does gradient flow? (Answer: STE bypasses step function; gradient passes through unchanged to pre-activation)

## Architecture Onboarding

- **Component map**:
  1. ThresholdLayer: Converts continuous features to 6-10 binary thresholds via learnable bias/slope
  2. LogicLayer(s): Each neuron applies one of 16 Boolean functions to exactly 2 inputs; learns both function and connections
  3. SumLayer: Single output neuron; computes weighted sum of binary rule activations with continuous coefficients

- **Critical path**:
  1. Preprocess: min-max scale features to [0,1]; one-hot encode categoricals; standardize targets
  2. Initialize ThresholdLayer biases from decision-tree bin edges; slopes = 2
  3. Initialize all logits uniformly; set temperature τ high (1.0-2.0)
  4. Forward pass uses SoftLogic and soft connections; compute MSE loss
  5. Backward pass via STE where needed; update all parameters jointly
  6. After each epoch: τ ← max(τ × γ, τmin)
  7. Post-training: discretize to arg-max functions/connections; simplify rules symbolically with SymPy

- **Design tradeoffs**:
  - More thresholds per feature → finer resolution but more parameters and slower training
  - Deeper/wider LogicLayers → more expressive rules but harder optimization and less interpretability
  - Larger subspace for function/connection search → more flexibility but slower convergence (8 candidates is sweet spot)

- **Failure signatures**:
  - R² near 0, predictions constant: temperature collapsed too fast; check τ schedule
  - Training loss stalls high: search space too constrained; increase subspace size or network width
  - Inference accuracy much worse than training: discretization gap; verify STE applied correctly
  - Rules implausibly complex: model over-parameterized; reduce LogicLayer size

- **First 3 experiments**:
  1. **Sanity check on synthetic data**: Generate y = 2·(x₁>0.5) + 3·(x₂<0.3) - 1·(x₁>0.5 AND x₃>0.7) + noise; verify DLN recovers similar coefficients and rules
  2. **Temperature ablation**: On Energy dataset, run τ ∈ {0.5, 1.0, 2.0} with γ ∈ {0.95, 0.99}; plot final R² vs. τ schedule
  3. **Baseline comparison on 3 datasets**: Compare DLN vs. Random Forest vs. MLP on Yacht (small, nonlinear), Bike (medium, mixed), Housing (large); measure R², inference ops, extract 3 example rules from each DLN

## Open Questions the Paper Calls Out
None

## Limitations
- Computational cost of hyperparameter optimization requires 128 Optuna trials per model per dataset, making training expensive despite efficient inference
- Ablation studies provide strong evidence for temperature scheduling but do not exhaustively explore alternative architectural designs or loss functions
- Symbolic simplification via SymPy is presented as post-hoc interpretability but computational overhead and effectiveness on larger models is not quantified

## Confidence
- **High confidence**: Core mechanisms (real-valued logic, temperature annealing, SumLayer design) are well-specified and ablation-validated
- **Medium confidence**: Comparative performance claims, as they depend on specific HPO configurations and seed randomness
- **Medium confidence**: Interpretability claims, as rule quality assessment is qualitative and dataset-dependent

## Next Checks
1. **Architecture scaling study**: Systematically vary LogicLayer widths and depths across datasets to map performance-interpretability tradeoff curve
2. **Loss function ablation**: Compare MSE vs. MAE vs. Huber loss impact on DLN performance and rule quality
3. **Inference latency benchmarking**: Measure actual wall-clock inference time on CPU vs. random forest and MLP across dataset sizes