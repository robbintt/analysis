---
ver: rpa2
title: Characterizing the Investigative Methods of Fictional Detectives with Large
  Language Models
arxiv_id: '2505.07601'
source_url: https://arxiv.org/abs/2505.07601
tags:
- investigative
- detective
- traits
- detectives
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an AI-driven approach for systematically characterizing
  the investigative methods of fictional detectives using a multi-large language model
  (LLM) workflow. The method extracts, synthesizes, and validates distinctive investigative
  traits across seven iconic detectives through description generation, trait extraction,
  semantic grouping, consistency analysis, and reverse identification.
---

# Characterizing the Investigative Methods of Fictional Detectives with Large Language Models

## Quick Facts
- arXiv ID: 2505.07601
- Source URL: https://arxiv.org/abs/2505.07601
- Reference count: 40
- Primary result: 91.43% accuracy in identifying detectives from synthesized trait profiles

## Executive Summary
This paper introduces a systematic, AI-driven framework for extracting and validating the distinctive investigative methods of fictional detectives. Using a multi-LLM workflow, the authors process seven iconic detectives through five phases: description generation, trait extraction, semantic grouping, consistency filtering, and reverse identification validation. The method achieves high accuracy (91.43%) in correctly identifying detectives based solely on their synthesized investigative traits, demonstrating its effectiveness in capturing unique character methodologies across different LLM providers.

## Method Summary
The study employs a five-phase multi-LLM workflow to characterize detective investigative methods. First, all 15 selected LLMs generate descriptive narratives about each detective's methods. Second, GPT-4o extracts key investigative traits from these descriptions. Third, the same model semantically groups related traits. Fourth, traits supported by fewer than three models (20% threshold) are filtered out. Finally, the reverse identification phase validates the synthesized profiles by having all 15 models match each profile to its correct detective, achieving 91.43% accuracy overall.

## Key Results
- Overall reverse identification accuracy of 91.43% across 15 LLMs
- Perfect identification scores (100%) achieved for three detectives
- High inter-model agreement with consistency threshold filtering
- Successful distinction between similar detectives (e.g., Holmes vs. Dupin)

## Why This Works (Mechanism)
The method works by leveraging the collective knowledge of multiple LLMs to synthesize and validate detective traits through consensus building. By requiring traits to be supported by at least three models (20% threshold), the approach filters out idiosyncratic or hallucinated characteristics. The reverse identification phase serves as empirical validation, demonstrating that the synthesized trait profiles are distinctive enough to uniquely identify each detective.

## Foundational Learning
- **Multi-LLM consensus building**: Using multiple models reduces individual model biases and hallucinations; quick check: compare trait consistency rates across different model combinations
- **Reverse identification validation**: Empirical verification that synthesized profiles capture unique characteristics; quick check: measure identification accuracy degradation when traits are randomly shuffled
- **Semantic grouping of traits**: Clustering related investigative methods into coherent categories; quick check: assess inter-annotator agreement on grouped trait categories
- **Consistency threshold filtering**: Removing unreliable traits that lack cross-model support; quick check: vary threshold percentages and measure impact on accuracy
- **Character profile synthesis**: Combining extracted traits into comprehensive behavioral descriptions; quick check: compare profile completeness across different extraction methods
- **Investigative method characterization**: Focusing on procedural and cognitive approaches rather than superficial traits; quick check: validate that profiles capture method rather than appearance

## Architecture Onboarding
- **Component map**: Description Generation -> Trait Extraction -> Semantic Grouping -> Consistency Filtering -> Reverse Identification
- **Critical path**: The trait extraction and semantic grouping phases using GPT-4o are most critical, as accuracy drops significantly when using other models for these steps
- **Design tradeoffs**: High accuracy vs. model dependency (heavily relies on GPT-4o for key phases) and lack of cross-validation
- **Failure signatures**: Dupin frequently misclassified as Holmes (7/15 models); smaller models struggle with nuanced differentiation
- **Three first experiments**: 1) Run Phase 1 description generation with all 15 LLMs; 2) Execute trait extraction using GPT-4o; 3) Validate reverse identification accuracy with all models

## Open Questions the Paper Calls Out
1. **Interactive storytelling integration**: How do synthesized trait profiles improve character behavior consistency in AI-driven narrative generation systems?
2. **Cross-genre generalization**: Can the workflow effectively characterize other narrative roles (criminals, victims) or literary genres beyond detective fiction?
3. **Performance with obscure characters**: How does method accuracy degrade for characters with limited cultural prominence or scarce LLM training data?
4. **Source text fidelity**: Does the workflow reflect original literary canon or conflate traits from adaptations and secondary analysis?

## Limitations
- Critical implementation details (rule-based post-processing logic) are omitted
- Heavy dependence on GPT-4o for trait extraction and grouping phases
- Detective selection limited to Western detective fiction traditions
- Validation relies on single reverse identification phase without cross-validation

## Confidence
- **High Confidence**: Multi-LLM framework architecture and reverse identification results
- **Medium Confidence**: Trait synthesis process captures distinctive methods, though quality depends on GPT-4o
- **Low Confidence**: Claims about model-agnostic performance given stark differences between GPT-4o and other models

## Next Checks
1. **Rule specification audit**: Reconstruct exact parsing logic for trait bullet points and validate impact on accuracy
2. **Cross-model validation**: Repeat extraction/grouping phases using each of 15 models individually to quantify GPT-4o's contribution
3. **Sensitivity threshold analysis**: Systematically vary consistency threshold (10%, 15%, 25%, 30%) and measure impacts on trait distinctiveness and accuracy