---
ver: rpa2
title: Best Group Identification in Multi-Objective Bandits
arxiv_id: '2505.17869'
source_url: https://arxiv.org/abs/2505.17869
tags:
- group
- algorithm
- each
- groups
- arms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the best group identification (BGI) problem
  in multi-objective multi-armed bandits, where the objective is to identify optimal
  groups of arms based on their efficiency vectors with high probability while minimizing
  sample complexity. The authors propose two key formulations: group Pareto set identification
  (GPSI) and linear best group identification (LBGI).'
---

# Best Group Identification in Multi-Objective Bandits

## Quick Facts
- **arXiv ID**: 2505.17869
- **Source URL**: https://arxiv.org/abs/2505.17869
- **Reference count**: 40
- **Primary result**: Introduces two formulations (GPSI and LBGI) for identifying optimal groups in multi-objective bandits, with provable PAC guarantees and near-optimal sample complexity

## Executive Summary
This paper addresses the best group identification (BGI) problem in multi-objective multi-armed bandits, where the goal is to identify optimal groups of arms based on their efficiency vectors with high probability while minimizing sample complexity. The authors propose two formulations: Group Pareto Set Identification (GPSI) to find Pareto optimal groups, and Linear Best Group Identification (LBGI) to find the group maximizing a weighted efficiency vector. They develop two elimination-based algorithms—Triple Elimination (TE) for GPSI and Equal Effect Confidence Bound (EECB) for LBGI—with provable (ε,δ)-PAC guarantees and near-optimal sample complexity for certain problem instances.

## Method Summary
The paper introduces two key algorithms for best group identification in multi-objective bandits. For GPSI, the Triple Elimination algorithm maintains three nested active sets (groups, dimensions, arms) and performs progressive elimination to identify Pareto optimal groups with (ε,δ)-PAC guarantees. For LBGI, the EECB algorithm selects dimensions by maximum weighted uncertainty (w_d·β) to achieve near-equal effective confidence across dimensions, with δ-correctness and near-optimal sample complexity for non-optimal groups. Both algorithms are elimination-based and extend single-objective techniques to the multi-objective setting.

## Key Results
- TE algorithm achieves (ε,δ)-PAC guarantees with sample complexity scaling as O(log(NKD/δ)/Δ²_i,j) for instance-dependent gaps
- EECB algorithm is δ-correct with near-optimal sample complexity for non-optimal groups, using dimension selection based on w_d·β(n_d(r),δ)
- Numerical experiments show TE significantly outperforms naive baselines across varying numbers of groups and arms per group
- EECB demonstrates strong empirical performance compared to baseline that ignores reward weights during sampling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Maintaining three nested active sets (groups, dimensions, arms) with progressive elimination reduces sample complexity by avoiding uniform exploration.
- Mechanism: The Triple Elimination algorithm maintains an active set of groups G, active dimensions Di for each group, and active arms Ai,d for each dimension. At each round, it eliminates: (1) groups that are dominated with high confidence, (2) dimensions where dominance relationships are resolved, and (3) arms that cannot be best in their dimension. This cascading elimination prevents wasteful sampling on arms/dimensions that cannot affect the final answer.
- Core assumption: Sub-Gaussian reward distributions with known parameter; arm means bounded in [0,1].
- Evidence anchors:
  - [Section 3.2]: "Our algorithm generalizes this approach by simultaneously maintaining (i) an active set of groups, (ii) an active set of dimensions for each active group, and (iii) an active set of arms for each active dimension within each active group."
  - [Theorem 3.3]: Upper bound on sample complexity scales with 1/̃Δ²_i,j where ̃Δ_i,j = max(Δ_i,j, Δ_i, ε), showing instance-dependent efficiency.
  - [corpus]: Related work on elimination-based algorithms (EDMMM06, ACOD16, KKS13) validates the elimination paradigm in single-objective settings; this extends it to multi-objective groups.
- Break condition: If confidence bounds β(r,δ) are too loose, elimination stalls; if too tight, correctness guarantees may fail.

### Mechanism 2
- Claim: Dimension resolution allows early termination of sampling in dimensions where dominance relationships are determined, reducing unnecessary exploration.
- Mechanism: For each active group Gi, the algorithm tracks "resolved" dimensions where |Ĵ^d_j(r) - Ĵ^d_i(r)| ≥ 4β(r,δ) + ε for all other active groups. Once resolved, the algorithm adheres to the current estimate and stops sampling that dimension. This exploits the fact that not all dimensions are equally informative for distinguishing Pareto optimality.
- Core assumption: The gap structure is such that some dimensions become resolved earlier than others.
- Evidence anchors:
  - [Definition 3.2]: Formal definition of dimension resolution condition.
  - [Remark 3.4]: "In the proof of Theorem 3.3 in Appendix 3, we demonstrate that the same sample complexity upper bound holds even without performing the dimension elimination phase. This suggests that in most instances where dimension elimination occurs, the algorithm can achieve better performance than this theoretical upper bound."
  - [corpus]: No directly comparable mechanism found in corpus; this appears novel to the multi-objective group setting.
- Break condition: If dimensions have nearly identical values across groups (small gaps), resolution may require many samples, negating benefits.

### Mechanism 3
- Claim: For LBGI, selecting dimensions by maximum weighted uncertainty (w_d·β) achieves near-equal effective confidence across dimensions, leading to near-optimal sample complexity for non-optimal groups.
- Mechanism: EECB maintains per-dimension sampling counts n_d(r). At each round, it selects d(r) = argmax_d w_d·β(n_d(r),δ) and samples all active arms in that dimension. Since β decreases with samples, this equalizes w_d·β across dimensions over time. Group elimination occurs when weighted sum gaps exceed total weighted confidence bounds.
- Core assumption: Known weight vector w; unique best group exists.
- Evidence anchors:
  - [Section 4.1]: "By selecting dimensions in this manner... this results in nearly equal values w_d·β(n_d(r),δ) for different dimensions d in the long run."
  - [Remark 4.3]: Shows that effective gap per arm is Δ_i,j/D or larger; in some cases algorithm is near-optimal for all non-optimal groups.
  - [corpus]: [Optimal Multi-Objective Best Arm Identification with Fixed Confidence] addresses multi-objective BAI but assumes independent reward dimensions; this work does not require independence.
- Break condition: If weight vector is poorly specified or if multiple groups have nearly equal weighted rewards, sample complexity degrades gracefully but stopping may be delayed.

## Foundational Learning

- Concept: **Pareto Dominance and Efficiency Frontiers**
  - Why needed here: The GPSI problem identifies groups whose efficiency vectors are Pareto optimal—no other group strictly dominates them in all dimensions. Understanding dominance (u ⪯ v means u_d ≤ v_d ∀d with strict inequality for some d) is essential for interpreting algorithm outputs.
  - Quick check question: Given efficiency vectors R_1 = (0.8, 0.3) and R_2 = (0.6, 0.5), which groups are Pareto optimal if these are the only two groups?

- Concept: **Fixed-Confidence Pure Exploration vs. Regret Minimization**
  - Why needed here: This paper addresses pure exploration—identifying optimal groups with probability ≥ 1-δ using minimum samples. This differs from regret minimization (cumulative reward maximization). The (ε,δ)-PAC guarantee means: P[τ < ∞ and (G*_0 ⊆ î_τ ⊆ G*_ε)] ≥ 1-δ.
  - Quick check question: If δ=0.01 and ε=0.1, what does the PAC guarantee promise about the algorithm's output?

- Concept: **Sub-Gaussian Concentration and Confidence Bounds**
  - Why needed here: Both algorithms rely on confidence bounds β(r,δ) = √(2·log(4NKDr²/δ)/r) derived from sub-Gaussian tail bounds. All elimination decisions depend on whether estimated gaps exceed 2β or 4β+ε thresholds.
  - Quick check question: Why does the algorithm use log(4NKDr²/δ) instead of log(1/δ) in the confidence bound?

## Architecture Onboarding

- Component map:
  - Input Layer: Group structure (N groups × K arms), reward dimensionality D, weight vector w (for LBGI), confidence δ, tolerance ε (for GPSI)
  - Estimation Layer: Empirical means tensor μ̂(r), empirical efficiency vectors R̂_i(r), per-dimension sample counts n_d(r)
  - Confidence Module: β(r,δ) computation for all active elements
  - Elimination Engine: Three-phase elimination (groups → dimensions → arms) for GPSI; two-phase (groups → arms) for LBGI
  - Selection Module: Round-robin for GPSI; max w_d·β selection for LBGI
  - Termination Condition: Empty active group set (GPSI) or single remaining group (LBGI)

- Critical path:
  1. Initialize all groups/dimensions/arms as active
  2. Sample active arms according to selection rule
  3. Update estimates and confidence bounds
  4. Apply elimination rules in order (groups first, then dimensions, then arms)
  5. Check termination; if not done, return to step 2

- Design tradeoffs:
  - **TE vs. EECB**: TE handles general Pareto sets but may over-explore; EECB exploits known weights for efficiency but only outputs single best group
  - **Dimension elimination**: Reduces samples empirically (Figure 1 shows TE outperforms AGE/GE) but adds implementation complexity
  - **Conservative β(r,δ)**: Ensures correctness but may slow convergence; authors note smaller values work empirically

- Failure signatures:
  - **Non-termination**: Check if gaps are below ε or if confidence bound is too conservative
  - **Incorrect output with high frequency**: Likely bug in domination check or elimination threshold; verify β(r,δ) formula includes all log factors
  - **Excessive samples on easy instances**: Dimension elimination may not be triggering; check resolution condition implementation

- First 3 experiments:
  1. **Reproduce Figure 1a**: Set D=3, K=6, vary N from 6-20, set 30% of groups as Pareto optimal, compare TE vs. AGE vs. GE vs. UniS. Verify TE achieves lowest sample complexity and correctness rate > 99%.
  2. **Weight sensitivity for LBGI**: Use N=5, K=5, D=3 with weight vectors w_1=(0.1,0.1,1), w_5=(1,2,3) etc. Compare EECB vs. TEL baseline. Verify EECB adapts to weights (different stopping times) while TEL ignores them.
  3. **Gap scaling test**: Generate instances with controlled Δ_min values. Verify sample complexity scales as O(1/Δ²) and algorithm terminates correctly even for small gaps (with log factor increases).

## Open Questions the Paper Calls Out

- Can algorithms be developed for LBGI when the weight vector w is only partially known or subject to uncertainty?
- Can asymptotically optimal algorithms (like Track-and-Stop) be developed for GPSI, achieving tight matching with lower bounds across all instances?
- What are optimal sample complexity bounds for the optimal group Gi* in LBGI?
- How can the BGI framework be extended to the fixed-budget setting with probability of error guarantees?

## Limitations

- Theoretical guarantees depend on known problem parameters (δ, ε, weight vector w) and sub-Gaussian assumption with bounded means
- GPSI algorithm's sample complexity bound includes logarithmic factors and depends on instance-dependent gaps that may not always yield practical improvements
- LBGI near-optimal guarantee applies only to non-optimal groups, not the optimal one
- Paper does not address sensitivity to parameter misspecification or reward distribution deviations

## Confidence

- **High confidence**: Core mechanism of progressive elimination (groups → dimensions → arms) is well-founded, with proofs for (ε,δ)-PAC guarantees and δ-correctness in Appendices B and C. Empirical performance gains over baselines are demonstrated across multiple experimental conditions.
- **Medium confidence**: Theoretical sample complexity bounds for TE are near-optimal only for specific problem instances where elimination phases effectively reduce exploration. The dimension resolution mechanism's empirical benefit (Figure 1) is shown but theoretical guarantees don't explicitly quantify the improvement.
- **Medium confidence**: EECB's near-optimal sample complexity for non-optimal groups is established, but the algorithm's performance on the optimal group and sensitivity to weight vector specification require further validation.

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary ε and δ in GPSI experiments to verify how algorithm performance degrades with parameter misspecification. Measure sample complexity and error rates across a grid of parameter values.

2. **Robustness to Distributional Assumptions**: Test algorithms with reward distributions that violate strict sub-Gaussianity (e.g., heavy-tailed distributions) while maintaining bounded means. Compare empirical error rates against theoretical δ guarantees.

3. **Scalability with Problem Size**: Extend experiments to larger problem instances (N, K > 50) to validate whether sample complexity scaling matches theoretical predictions and whether computational overhead becomes prohibitive.