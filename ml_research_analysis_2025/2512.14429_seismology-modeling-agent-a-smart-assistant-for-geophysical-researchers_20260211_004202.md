---
ver: rpa2
title: 'Seismology modeling agent: A smart assistant for geophysical researchers'
arxiv_id: '2512.14429'
source_url: https://arxiv.org/abs/2512.14429
tags:
- agent
- simulation
- specfem
- seismic
- material
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first Model Context Protocol (MCP) server
  suite for SPECFEM seismic modeling software, enabling natural language control through
  AI agents. The framework decomposes the complex simulation workflow into discrete
  tools, supporting both fully automated execution and interactive human-in-the-loop
  operation.
---

# Seismology modeling agent: A smart assistant for geophysical researchers

## Quick Facts
- arXiv ID: 2512.14429
- Source URL: https://arxiv.org/abs/2512.14429
- Reference count: 5
- First MCP server suite enabling natural language control of SPECFEM seismic modeling software

## Executive Summary
This paper introduces the first Model Context Protocol (MCP) server suite for SPECFEM seismic modeling software, enabling natural language control through AI agents. The framework decomposes the complex simulation workflow into discrete tools, supporting both fully automated execution and interactive human-in-the-loop operation. Validated across five case studies from teaching-level experiments to global 3D simulations, the system successfully lowers entry barriers, enhances reproducibility, and demonstrates compatibility with multiple state-of-the-art LLMs. The approach represents a paradigm shift from file-driven to intent-driven workflows in computational geophysics.

## Method Summary
The framework consists of three async MCP servers (one per SPECFEM variant) exposing tools via JSON-RPC 2.0. Tools generate configuration files via Jinja2 templates and wrap Fortran executables (xmeshfem*, xspecfem*). Integration with VS Code cline plugin serves as the agent frontend. The agent performs intent recognition, tool discovery, planning, and execution, supporting both automated and human-in-the-loop operation. SPECFEM core code remains unmodified, with the MCP servers interacting identically to traditional command-line users.

## Key Results
- Successfully executes seismic simulations from natural language prompts across 2D, 3D Cartesian, and 3D Globe SPECFEM variants
- Demonstrates compatibility with multiple LLM models (Claude, Gemini) through standardized MCP interface
- Validates framework across five cases from teaching experiments to global 3D simulations
- Maintains numerical fidelity consistent with standard SPECFEM baselines while enabling intent-driven conversational interactions

## Why This Works (Mechanism)

### Mechanism 1
Decomposing a monolithic simulation workflow into discrete, standardized tools enables LLM agents to reliably orchestrate complex scientific software. The MCP server exposes granular tools (e.g., `generate_par_file`, `run_mesher`, `run_solver`) with JSON schemas. The LLM agent discovers capabilities via `list_tools`, plans a sequence, and invokes tools via `call_tool` with structured arguments. Each tool wraps file generation (using Jinja2 templates) or subprocess execution of SPECFEM binaries. Core assumption: The underlying software's operations can be faithfully represented as stateless, schema-constrained function calls without hidden dependencies.

### Mechanism 2
Natural language intent can be translated into valid simulation configurations when the agent has access to both tool schemas and interactive human feedback. The agent receives a high-level prompt, performs intent recognition, queries MCP tools for capabilities, plans a multi-step sequence, and executes. Users can intervene at any point to adjust parameters or inspect intermediate results, enabling error correction before committing to expensive computation. Core assumption: The LLM possesses sufficient domain knowledge (or can acquire it via context) to map scientific intent to physically valid parameter combinations.

### Mechanism 3
Wrapping legacy scientific software with a thin service layer preserves numerical fidelity while enabling modern AI interfaces. The MCP servers do not modify SPECFEM core code. They interact with SPECFEM identically to a human user—preparing input files in `DATA/`, invoking binaries in `bin/`, and reading outputs from `OUTPUT_FILES/`. This ensures results match baseline manual execution. Core assumption: The legacy software's input/output behavior is deterministic and fully specified by its configuration files and command-line interface.

## Foundational Learning

- **Model Context Protocol (MCP)**: Communication substrate between LLM agents and SPECFEM tools. Why needed: MCP is the communication substrate between LLM agents and SPECFEM tools. Without understanding its client-server model, JSON-RPC semantics, and tool/resource/prompt primitives, you cannot debug agent-tool interactions. Quick check: Can you explain how an MCP client discovers available tools and what information each tool's JSON schema provides?

- **SPECFEM workflow stages**: The agent's tool sequence mirrors SPECFEM's pipeline: meshing → database generation → solver execution → post-processing. Why needed: The agent's tool sequence mirrors SPECFEM's pipeline: meshing → database generation → solver execution → post-processing. Misordering or skipping steps will cause silent failures. Quick check: What are the three core executables invoked in a typical SPECFEM3D Cartesian forward simulation, and what does each do?

- **Spectral-element method (SEM) basics**: The paper's case studies involve configuring material properties, sources, and boundary conditions in physically meaningful ways. Why needed: The paper's case studies involve configuring material properties, sources, and boundary conditions in physically meaningful ways. Understanding SEM helps validate that agent-generated parameters are scientifically plausible. Quick check: Why does SEM use Gauss-Lobatto-Legendre points, and what advantage does this provide for mass matrix structure?

## Architecture Onboarding

- **Component map**: User Environment -> MCP Server Suite -> SPECFEM Core -> Data Flow: User prompt → Agent planning → MCP tool calls → File generation / subprocess execution → Output files → Agent synthesis → Natural language response
- **Critical path**: 1) Configure MCP server connection in Cline (point to specfem-mcp repository) 2) Verify SPECFEM binaries are compiled and accessible in `bin/` 3) Test a minimal 2D forward simulation via natural language prompt 4) Inspect generated `Par_file`, `SOURCES`, `STATIONS` for correctness 5) Confirm solver output matches expected seismogram format
- **Design tradeoffs**: Automation vs. control: Fully automated mode reduces tedium but may mask configuration errors; human-in-the-loop preserves scientific judgment at the cost of speed. Tool granularity: Finer-grained tools (separate source/station/mesh tools) offer flexibility but increase planning complexity for the agent. Template-based file generation: Jinja2 templates ensure syntactic validity but may not cover all edge cases in SPECFEM's extensive parameter space.
- **Failure signatures**: Agent produces syntactically invalid configuration files → Check Jinja2 template coverage for requested parameters. Solver crashes with MPI errors → Verify mesh decomposition matches available processes/GPUs. Agent hallucinates non-existent tools → Confirm MCP server is running and `list_tools` returns expected catalog. Output seismograms are empty or all-zero → Check source-receiver geometry and time window configuration.
- **First 3 experiments**: 1) Minimal 2D homogeneous medium: Prompt the agent to create a simple 2D elastic model with one source and one receiver. Verify the complete workflow executes and produces a non-zero seismogram. 2) Interactive parameter refinement: Start a simulation, then interrupt to modify the source frequency or receiver positions. Confirm the agent correctly updates only the changed files without re-running unnecessary steps. 3) External mesh integration: Provide a pre-computed mesh file (as in Case 3) and verify the agent correctly parses material IDs and completes the remaining workflow without regenerating the mesh.

## Open Questions the Paper Calls Out

### Open Question 1
Can the MCP-based agent framework be extended from forward simulation to full seismic inversion workflows, including gradient computation and model updates? Basis: The conclusion states "Future research will focus on... achieving a deep integration of the agent with seismic inversion workflows." Why unresolved: The current implementation only addresses forward simulation; adjoint-based inversion requires additional tools for gradient computation, line search, and iterative model updates that were not implemented. What evidence would resolve it: A case study demonstrating agent-driven full-waveform inversion with automatic gradient computation and convergence to a target model.

### Open Question 2
What are the failure rates and specific error categories that require human intervention in the current agentic workflow? Basis: The paper demonstrates successful case studies but provides no quantitative analysis of failure modes, success rates across many runs, or systematic categorization of where human-in-the-loop intervention was necessary. Why unresolved: Only successful executions are reported; no systematic evaluation of robustness or error recovery capabilities was conducted. What evidence would resolve it: A benchmark study with statistical analysis of success/failure rates across diverse simulation scenarios and a taxonomy of common failure modes.

### Open Question 3
How can the agent's error correction and experience summarization capabilities be enhanced to achieve robust autonomous operation without human intervention? Basis: The conclusion explicitly identifies the need for "enhancing the agent's abilities for error correction, exploratory learning, and experience summarization so that it can robustly handle unexpected simulation challenges." Why unresolved: Current implementation relies on multi-turn dialogue with users for error diagnosis and correction; the agent lacks persistent memory of past failures and recovery strategies. What evidence would resolve it: Demonstration of autonomous recovery from common SPECFEM configuration errors without user intervention, measured by reduced human interaction frequency.

## Limitations
- Lacks independent replication of core claims; validation relies on internal consistency rather than comparison with published benchmarks
- Scalability to production-scale simulations remains unproven, with largest case using only a single A800 GPU
- Framework assumes SPECFEM's deterministic behavior, which may not hold across different compiler versions or hardware architectures

## Confidence
- **High confidence**: MCP server architecture correctly exposes SPECFEM tools and enables basic natural language control for simple 2D cases
- **Medium confidence**: Framework successfully handles moderately complex 3D cases with external meshes and heterogeneous materials
- **Low confidence**: Claims about dramatically lowering entry barriers for non-expert users and achieving full reproducibility across diverse computational environments

## Next Checks
1. **Independent Benchmark Validation**: Reproduce Case 3 (China crustal model) and compare generated surface wave dispersion curves against reference data from Zhu et al. (2012) to verify quantitative accuracy
2. **Cross-LLM Robustness Test**: Execute same complex 3D simulation workflow using multiple different LLM backends (Claude, Gemini, GPT-4) with identical prompts to assess consistency across models
3. **Resource Scaling Experiment**: Scale up Case 5's global simulation to multiple GPUs/nodes while monitoring memory usage, solver convergence, and output fidelity to document performance bottlenecks