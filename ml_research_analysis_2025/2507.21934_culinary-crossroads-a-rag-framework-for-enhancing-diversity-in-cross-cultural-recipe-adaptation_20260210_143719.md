---
ver: rpa2
title: 'Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural
  Recipe Adaptation'
arxiv_id: '2507.21934'
source_url: https://arxiv.org/abs/2507.21934
tags:
- diversity
- recipe
- recipes
- diverse
- cultural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating diverse, culturally
  appropriate recipe adaptations across cuisines. It finds that standard retrieval-augmented
  generation (RAG) models often fail to produce diverse outputs even when provided
  with varied contextual inputs.
---

# Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation

## Quick Facts
- arXiv ID: 2507.21934
- Source URL: https://arxiv.org/abs/2507.21934
- Reference count: 13
- Primary result: CARRIAGE achieves Pareto efficiency in balancing diversity and quality for cross-cultural recipe adaptation

## Executive Summary
This paper addresses the challenge of generating diverse, culturally appropriate recipe adaptations across cuisines. Standard RAG models often fail to produce diverse outputs even with varied contextual inputs. The authors propose CARRIAGE, a novel RAG framework that enhances diversity at multiple stages: diversity-aware retrieval, dynamic context organization, and contrastive context injection. Experiments on a Spanish-language recipe dataset show CARRIAGE outperforms both closed-book LLMs and standard RAG approaches, improving model's utilization of diverse contexts by over 40%.

## Method Summary
CARRIAGE is a multi-stage RAG framework that enhances diversity through: (1) Query rewriting using LLaMA3.1 to generate culturally-adapted titles, (2) Diversity-aware MMR re-ranking with λ=0.6 that incorporates historical outputs to avoid repetition, (3) Dynamic context organization via sliding window (w=1) to force attention to different context segments, and (4) Contrastive context injection that provides previously generated outputs as "negative examples" to discourage repetition. The framework is evaluated on cross-cultural recipe adaptation from Latin American to Spanish cuisine using the RecetasDeLaAbuel@ dataset.

## Key Results
- CARRIAGE achieves Pareto efficiency in balancing diversity and quality, outperforming both closed-book LLMs and standard RAG approaches
- CARRIAGE improves the model's utilization of diverse contexts by over 40% compared to vanilla RAG
- Increases average context usage count from ~1.8 to 2.67 across five generations

## Why This Works (Mechanism)

### Mechanism 1: Diversity-Aware Re-ranking with Historical Constraints
Extending MMR to consider both retrieved candidates and previously generated outputs improves contextual diversity. The re-ranking score balances relevance against maximal similarity to already-selected documents and historical outputs, preventing retrieval of documents similar to what the model has already produced.

### Mechanism 2: Dynamic Context Organization via Sliding Window
Subsetting retrieved context through a sliding window across sequential generations forces the LLM to attend to different contextual slices. Given k retrieved recipes, only a window of size w is presented per generation, sidestepping the LLM's tendency to over-rely on the same context segments.

### Mechanism 3: Contrastive Context Injection
Explicitly providing previously generated outputs as "negative examples" in the prompt guides the LLM away from repeating similar adaptations. Retrieved historical outputs are injected into the prompt with instructions to avoid similar recommendations, providing explicit diversity signals.

## Foundational Learning

- **Concept: Pareto Efficiency in Multi-Objective Generation** - Why needed: The paper frames diversity and quality as competing objectives; understanding trade-off frontiers is essential for interpreting results. Quick check: Can you explain why increasing source preservation tends to reduce both diversity and cultural appropriateness?

- **Concept: Lost-in-the-Middle Phenomenon in LLMs** - Why needed: The paper cites Liu et al. (2023) showing LLMs over-focus on certain context segments; this motivates the sliding-window mechanism. Quick check: If an LLM receives 10 retrieved recipes in context, which positions are most likely to influence the output?

- **Concept: Per-Input vs. Across-Input Diversity** - Why needed: The paper distinguishes diversity within multiple outputs for one input from diversity across different inputs; metrics and goals differ substantially. Quick check: For a recipe adaptation system serving a single user requesting variants, which diversity paradigm matters more?

## Architecture Onboarding

- Component map: Query Rewriting → Diversity-aware Re-ranking (MMR with history) → Dynamic Context Organization (sliding window) → LLM Generation with Contrastive Context Injection → Output collection (updates history for next iteration)

- Critical path: 1. Query rewriting (regenerate title, culturally-adapted title) → retrieves broader candidate pool; 2. MMR re-ranking with λ=0.6 → selects diverse, relevant documents; 3. Sliding window (w=1) subsets context per generation; 4. Contrastive history injection in prompt → discourages repetition; 5. Generate at temperature=0.7 → collect output, append to history

- Design tradeoffs: λ (re-ranking): Higher = more relevant but less diverse retrieval; Window size w: Smaller = more context variation but risk of missing key information; Temperature: Higher = more lexical diversity but potential quality degradation; History length: More history = stronger contrastive signal but longer prompts

- Failure signatures: Low semantic diversity despite diverse retrieval → check if sliding window is active (w < k); High cultural appropriateness but low source preservation → reduce temperature or increase λ; Repetitive outputs across generations → verify contrastive context is being injected correctly; Retrieved documents irrelevant to source → check query rewriting quality

- First 3 experiments: 1. Replicate the context utilization probe: Generate 5 outputs per input with vanilla RAG vs. CARRIAGE, track which retrieved document is most similar to each output. Expect ~40% improvement in unique context usage; 2. Ablate one component at a time (remove contrastive injection, then sliding window, then MMR re-ranking) to isolate each mechanism's contribution to diversity metrics; 3. Sweep λ ∈ {0.2, 0.4, 0.6, 0.8} and temperature ∈ {0.1, 0.4, 0.7, 1.0} to map the Pareto frontier for your specific dataset

## Open Questions the Paper Calls Out

- How can cross-cultural adaptation frameworks be modified to improve global across-input ingredient diversity, rather than just per-input diversity? The paper demonstrates that while CARRIAGE improves per-input diversity, all evaluated methods reduced global ingredient diversity by increasing reliance on high-frequency ingredients.

- Does the CARRIAGE framework's performance in cultural appropriateness and diversity align with human judgments, particularly regarding culinary validity? The study relied solely on automatic metrics due to resource constraints; the nuanced subjective nature of "cultural appropriateness" may not be fully captured by a BERT-based classifier.

- Does the CARRIAGE framework maintain its Pareto efficiency when applied to cross-lingual adaptation tasks or non-Spanish culinary traditions? Results are restricted to Spanish-speaking countries; the method's reliance on specific re-ranking and contrastive injection is untested in cross-lingual scenarios or distant culinary traditions.

## Limitations

- Retrieval-Generation Quality Gap: The paper doesn't directly measure whether retrieved documents contain useful adaptation examples, only that they're diverse
- Language and Cultural Generalization: Results are demonstrated only on Spanish-language recipes within Latin American/Spanish culinary contexts
- Computational Overhead: The paper doesn't report inference time or cost differences between CARRIAGE and standard RAG

## Confidence

- **High Confidence**: The empirical results showing CARRIAGE achieving Pareto efficiency in diversity-quality trade-offs (Figure 3) and the 40% improvement in context utilization (Table 2)
- **Medium Confidence**: The proposed mechanisms' theoretical effectiveness, though specific hyperparameters appear tuned for this dataset without systematic sensitivity analysis
- **Low Confidence**: The generalizability of the CultureScore metric and its ability to capture nuanced cultural appropriateness across diverse culinary traditions

## Next Checks

1. **Cross-Dataset Validation**: Implement CARRIAGE on a different recipe dataset (e.g., English-language recipes from Recipe1M+ or Yummly) to test whether diversity gains and Pareto efficiency patterns replicate across culinary cultures and languages.

2. **Retrieval Quality Audit**: For a random sample of 50 CARRIAGE generations, manually evaluate whether the top-3 retrieved documents contain actually useful cultural adaptation examples, not just diverse ones.

3. **Ablation at Scale**: Systematically vary λ ∈ {0.2, 0.4, 0.6, 0.8} and window size w ∈ {1, 2, 3, k} across the full test set, measuring the full Pareto frontier rather than the single configuration reported.