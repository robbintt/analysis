---
ver: rpa2
title: Is Your Conditional Diffusion Model Actually Denoising?
arxiv_id: '2512.18736'
source_url: https://arxiv.org/abs/2512.18736
tags:
- schedule
- deviation
- diffusion
- imcf
- ddpm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Schedule Deviation, a novel metric for measuring
  how much conditional diffusion models deviate from their idealized denoising behavior.
  The authors find that such models routinely deviate from the idealized "model-consistent
  diffusion flow," even with large model capacity or training data.
---

# Is Your Conditional Diffusion Model Actually Denoising?

## Quick Facts
- arXiv ID: 2512.18736
- Source URL: https://arxiv.org/abs/2512.18736
- Reference count: 40
- Primary result: Conditional diffusion models deviate from ideal denoising behavior, exhibiting "self-guidance" bias toward smoothness.

## Executive Summary
This paper introduces Schedule Deviation (SD), a novel metric measuring how much conditional diffusion models deviate from their idealized denoising behavior. The authors find that such models routinely deviate from the idealized "model-consistent diffusion flow," even with large model capacity or training data. This deviation is strongly correlated with differences between popular sampling algorithms like DDPM and DDIM. The authors attribute this phenomenon to an inductive bias towards smoothness with respect to the conditioning variable, leading to "self-guidance" where the model interpolates flows from nearby conditioning values.

## Method Summary
The authors propose Schedule Deviation as a metric to measure how much conditional diffusion models deviate from their idealized denoising behavior. The method involves training conditional U-Net denoisers on MNIST/Fashion-MNIST with 2D t-SNE embeddings as conditioning variables, then computing SD via Algorithm 1. This algorithm samples x₀ from the model using DDPM, adds noise to obtain x_s, estimates ε_IMCF using kernel density estimation with N=128 samples, and estimates the divergence ∇·(ε_s - ε_IMCF) using random diagonal approximation. The training uses AdamW optimizer with cosine decay, 300K iterations, and a log-linear noise schedule.

## Key Results
- Conditional diffusion models routinely deviate from idealized "model-consistent diffusion flow"
- Schedule Deviation strongly correlates with differences between DDPM and DDIM sampling algorithms (ρ > 0.99)
- This deviation is attributed to an inductive bias toward smoothness with respect to the conditioning variable
- The phenomenon of "self-guidance" occurs where models interpolate flows from nearby conditioning values

## Why This Works (Mechanism)
The mechanism behind Schedule Deviation stems from an inductive bias toward smoothness in conditional diffusion models. When conditioning on variables, the model tends to produce smoother transitions in the denoising process rather than following the theoretically optimal path. This leads to "self-guidance" where the model effectively interpolates between flows from nearby conditioning values, creating a deviation from the ideal model-consistent diffusion flow.

## Foundational Learning
- Conditional generation: Why needed - Enables context-aware sample synthesis; Quick check - Verify conditioning variable affects output distribution
- Diffusion sampling algorithms (DDPM/DDIM): Why needed - Different mathematical principles lead to different sampling behaviors; Quick check - Compare sample quality between algorithms
- Kernel density estimation: Why needed - Used for estimating divergence in SD computation; Quick check - Validate KDE bandwidth selection on toy data

## Architecture Onboarding

**Component Map**
U-Net -> Conditional embeddings -> Noise schedule -> SD computation

**Critical Path**
1. U-Net denoiser training with conditional embeddings
2. Sample generation using DDPM
3. Noise addition and divergence estimation
4. Schedule Deviation calculation

**Design Tradeoffs**
- Model capacity vs. generalization: Larger models may overfit to training distribution
- Sampling timestep resolution: More timesteps increase computation but may capture finer details
- Kernel density estimation parameters: Tradeoff between bias and variance in divergence estimation

**Failure Signatures**
- High variance in SD computation at low noise levels indicates unstable kernel density gradient estimates
- Memory/time issues with full Jacobian computation suggest using random diagonal approximation
- Poor correlation between SD and sampler divergence may indicate implementation errors

**3 First Experiments**
1. Train U-Net on MNIST with t-SNE conditioning and verify basic denoising capability
2. Compute SD on a single sample to validate Algorithm 1 implementation
3. Compare SD values across different noise schedules to test sensitivity

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical characterization of "self-guidance" as an inductive bias toward smoothness remains speculative
- Limited validation beyond image-based conditional tasks (MNIST, Fashion-MNIST, maze paths)
- Claims about generalizability to other conditional domains lack empirical support

## Confidence
- High confidence: SD metric computation, experimental methodology, correlation results between SD and sampler divergence
- Medium confidence: Theoretical explanation of self-guidance mechanism, claims about inductive bias toward smoothness
- Medium confidence: Generalizability to other conditional domains beyond tested image/maze tasks

## Next Checks
1. **Architectural ablation study**: Test SD across different U-Net configurations (varying channel counts, attention mechanisms) to isolate architectural contributions to self-guidance.
2. **Regularization impact**: Systematically vary smoothness-inducing regularizers (e.g., total variation, spectral normalization) to establish causal links with SD magnitude.
3. **Cross-domain validation**: Apply SD analysis to conditional generation tasks outside vision (e.g., language, audio) to test the universality of the self-guidance phenomenon.