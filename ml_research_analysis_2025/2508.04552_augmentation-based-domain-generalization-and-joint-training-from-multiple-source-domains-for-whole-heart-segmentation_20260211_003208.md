---
ver: rpa2
title: Augmentation-based Domain Generalization and Joint Training from Multiple Source
  Domains for Whole Heart Segmentation
arxiv_id: '2508.04552'
source_url: https://arxiv.org/abs/2508.04552
tags:
- data
- training
- domain
- image
- joint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of whole heart segmentation
  (WHS) from medical images under domain shift conditions, where training and test
  data may come from different imaging modalities (CT/MR) or different medical centers.
  The authors propose a method that combines (1) balanced joint training from multiple
  source domains and (2) strong intensity and spatial augmentation techniques.
---

# Augmentation-based Domain Generalization and Joint Training from Multiple Source Domains for Whole Heart Segmentation

## Quick Facts
- arXiv ID: 2508.04552
- Source URL: https://arxiv.org/abs/2508.04552
- Reference count: 33
- Primary result: State-of-the-art whole heart segmentation on CARE2024 Challenge WHS++ dataset (MR: 89.30% DSC, CT: 93.33% DSC)

## Executive Summary
This paper addresses whole heart segmentation under domain shift conditions by proposing a method that combines balanced joint training from CT and MR modalities with strong augmentation techniques. The approach trains a single model on both modalities in equal proportions to conflate feature representations, while RandConv-based augmentation diversifies training data to bridge the domain gap to unseen test domains. The method achieves state-of-the-art performance on the CARE2024 WHS++ dataset, demonstrating robust generalization to unseen centers and modalities.

## Method Summary
The method employs a 3D U-Net trained on CT and MR data from multiple sources using balanced joint training (one CT and one MR scan per batch). Spatial and intensity augmentation simulate anatomical and scanner variations, while RandConv - a randomly initialized convolutional network - removes domain-specific features while preserving shape information. The model is trained with Generalized Dice Loss, temporal ensembling, and evaluated through 5-fold ensemble averaging with post-processing to retain only the largest connected component per label.

## Key Results
- Achieved state-of-the-art MR segmentation with 89.30% DSC and 1.2411 mm ASSD
- CT segmentation performance of 93.33% DSC and 0.8388 mm ASSD, close to best CT-only models
- Ablation studies show 15-25% DSC improvements for cross-domain performance when using RandConv augmentation
- Balanced joint training enables single model to handle both modalities, though slight CT performance degradation observed (93.77% → 93.00% DSC)

## Why This Works (Mechanism)

### Mechanism 1
Balanced joint training from multiple source domains conflates feature representations, enabling a single model to perform well across CT and MR modalities. By sampling one CT and one MR scan per training batch and optimizing a combined loss with equal weighting, the shared weights must learn modality-agnostic anatomical features rather than modality-specific intensity patterns. The equal weighting prevents either domain from dominating gradient updates.

### Mechanism 2
Strong spatial and intensity augmentation diversifies observed feature representations, improving robustness to domain shift toward unseen test domains. Spatial augmentation simulates anatomical variations while intensity augmentation simulates scanner and protocol differences. This forces the network to rely on structural rather than texture features.

### Mechanism 3
RandConv-based augmentation removes domain-specific features while preserving shape information, bridging the gap to unseen domains. A randomly initialized shallow convolutional network transforms the input image, which is then blended with the original. Random weights are re-initialized per image, creating diverse synthetic domains that share only structural information.

## Foundational Learning

- **Concept**: Domain shift vs. domain generalization
  - **Why needed here**: The core problem is performance degradation when test data distributions differ from training data. Distinguishing Domain Adaptation (target domain known at training time) from Domain Generalization (target domain unknown) clarifies method goals.
  - **Quick check**: Can you explain why a model trained on CT might fail on MR, even for the same anatomical structures?

- **Concept**: U-Net architecture with skip connections
  - **Why needed here**: The base architecture is a 5-level U-Net with contracting/expanding paths and skip connections. Understanding how multi-scale features are combined is essential for debugging segmentation failures.
  - **Quick check**: What role do skip connections play in preserving spatial information during downsampling?

- **Concept**: Dice Similarity Coefficient (DSC) and surface distance metrics
  - **Why needed here**: Evaluation uses DSC (region overlap), Hausdorff Distance (worst-case boundary error), and ASSD (average boundary error). Each captures different failure modes.
  - **Quick check**: Why might a segmentation achieve high DSC but poor Hausdorff Distance?

## Architecture Onboarding

- **Component map**: Input pipeline → U-Net → Output → Post-processing. Input pipeline includes modality-specific normalization (CT: divide by 2048, clip [-1,1]; MR: percentile normalize), spatial augmentation (translation ±20 vox, rotation ±0.35 rad, scale [0.8,1.2], elastic deformation), intensity augmentation (shift ±0.2, scale [0.8,1.2] CT/[0.6,1.4] MR), and RandConv blending. Network is 5-level U-Net with 64 filters/level, LeakyReLU α=0.1, dropout 0.1, skip connections. Output is 7-class segmentation. Training uses Adam lr=5e-5, batch=2 (1 CT + 1 MR), Generalized Dice Loss, temporal ensembling. Inference averages 5-fold ensemble predictions and applies post-processing.

- **Critical path**: Data normalization differs by modality—incorrect normalization will cascade failures. RandConv blending factor α sampled uniformly [0,1] per image—controls augmentation strength. Balanced batch construction—each iteration must include one CT and one MR sample. Frobenius norm re-normalization after RandConv—prevents gradient explosion.

- **Design tradeoffs**: Joint training vs. modality-specific models: Joint enables cross-domain inference but slight CT performance reduction (93.77% → 93.00%). RandConv strength: Higher α increases domain diversity but risks shape corruption. Ensemble size: 5 models improve MR DSC (88.92% → 89.30%) but increase inference time (~11s/subject). Resolution: Training at 128³ reduces memory but may miss fine structures; test at 192³ recovers detail.

- **Failure signatures**: CT→MR failure: DSC ~60% or below typically indicates missing RandConv or intensity augmentation. MR→CT failure: DSC ~13% (near-random) indicates model trained on MR-only without augmentation. Disconnected components: Indicates missing post-processing step. Gradient explosion: Check RandConv normalization—Frobenius norm should be applied.

- **First 3 experiments**: Ablation on joint training: Train CT-only, MR-only, and joint models without RandConv. Compare in-domain vs. out-of-domain DSC. Expect large cross-domain gaps for single-modality models. Ablation on RandConv: Train joint model with and without RandConv. Measure MR→CT and CT→MR generalization. Expect 15-25% DSC improvement for cross-domain. Sensitivity to α: Vary RandConv blending factor α (fix at 0.3, 0.5, 0.7 vs. uniform sampling). Monitor both in-domain and cross-domain DSC to find stability range.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Training duration/epoch count unspecified, affecting reproducibility and temporal ensembling effectiveness
- Performance degradation on CT when including MR data suggests potential negative transfer in some scenarios
- Assumes CT and MR share sufficient anatomical structure for joint feature learning, which may not hold for all cardiac pathologies

## Confidence

**High confidence**: Augmentation-based generalization mechanisms (spatial/intensity augmentation) - well-supported by ablation results showing 15-25% DSC improvements for cross-domain performance

**Medium confidence**: Balanced joint training efficacy - supported by strong cross-domain results but lacks direct comparison to modality-specific models with separate test-time adaptation

**Medium confidence**: RandConv preserving shape while removing domain-specific features - theoretically sound but performance impact depends on α sampling strategy not fully characterized

## Next Checks

1. **Ablation study on training duration**: Train models for varying epoch counts (50, 100, 150) to determine convergence behavior and optimal stopping point, particularly for temporal ensembling effectiveness

2. **Cross-center generalization analysis**: Evaluate model performance when training on centers A+B and testing on center C, versus training on C+D+E+F and testing on A, to quantify generalization across acquisition protocols within modalities

3. **Negative transfer investigation**: Train separate CT-only and MR-only models with identical augmentation, then compare their cross-domain performance against the joint model to quantify the cost of modality inclusion on primary domain performance