---
ver: rpa2
title: 'Delta Activations: A Representation for Finetuned Large Language Models'
arxiv_id: '2509.04442'
source_url: https://arxiv.org/abs/2509.04442
tags:
- delta
- activations
- arxiv
- task
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Delta Activations, a method to represent
  finetuned language models as vector embeddings by measuring shifts in their internal
  activations relative to a base model. The approach addresses the challenge of navigating
  and understanding the growing ecosystem of post-trained models, which often lack
  standardized metadata and documentation.
---

# Delta Activations: A Representation for Finetuned Large Language Models

## Quick Facts
- arXiv ID: 2509.04442
- Source URL: https://arxiv.org/abs/2509.04442
- Reference count: 40
- Primary result: Delta Activations achieves 0.61 average silhouette score for clustering finetuned LLMs, outperforming parameter-based and output embedding baselines.

## Executive Summary
This paper introduces Delta Activations, a method to represent finetuned language models as vector embeddings by measuring shifts in their internal activations relative to a base model. The approach addresses the challenge of navigating and understanding the growing ecosystem of post-trained models, which often lack standardized metadata and documentation. By passing a small, generic set of prompts through both base and finetuned models and computing the difference in their hidden states, Delta Activations provides a compact behavioral indicator that reflects how models process information differently after finetuning.

The method is evaluated across multiple model pools derived from LLaMA-3.1-8B, Gemma-2-9B, and Qwen-2.5-7B, finetuned on five distinct domains. Delta Activations consistently achieves strong clustering performance with an average silhouette score of 0.61, significantly outperforming baselines including flattened weights and output sentence embeddings. The method demonstrates desirable properties such as stability across different training settings, an additive property when finetuning datasets are mixed, and the ability to embed tasks via few-shot finetuning. Additionally, Delta Activations generalizes to a family of delta-based representations (Delta-X) that can handle cross-architecture comparisons when using model-agnostic features. These results establish Delta Activations as an effective tool for organizing and discovering finetuned models, potentially facilitating more efficient reuse of publicly available models.

## Method Summary
Delta Activations represents finetuned LLMs as vector embeddings by computing the difference between their hidden states and those of a base model on a small set of generic prompts. The method uses LoRA finetuning with specific hyperparameters (rank 8, alpha 16, learning rate 1e-4, 3 epochs) on base models (LLaMA-3.1-8B, Gemma-2-9B, Qwen-2.5-7B) finetuned on five domains. Hidden states are extracted from the last token at the final layer for both base and finetuned models, and the difference vectors are averaged across a 5-prompt probe set to create the model representation. K-Means clustering is then applied to these delta vectors to organize models by their finetuning domain, with performance measured using silhouette scores.

## Key Results
- Delta Activations achieves an average silhouette score of 0.61 for domain clustering, significantly outperforming flattened weights and sentence embeddings.
- The method demonstrates stability across different training settings and exhibits an additive property when finetuning datasets are mixed.
- Delta Activations generalizes to cross-architecture comparisons through model-agnostic features, enabling broader applicability.

## Why This Works (Mechanism)

### Mechanism 1
Finetuning induces consistent, geometric shifts in the activation space that are detectable even on out-of-distribution (generic) inputs. By computing $\Delta_f(x) = h_f(x) - h_{base}(x)$, the method isolates the "specialization vector" added by finetuning from the base model's generic knowledge. Averaging over a probe set denoises this signal, leaving a fingerprint of the model's behavioral edit. Core assumption: Generic instruction templates activate a sufficiently broad set of model circuits such that the finetuned model's specialization "bleeds" into these activations, even without domain-specific prompts. Break condition: If a finetuned model uses aggressive regularization that suppresses activation shifts on out-of-domain data, the delta signal may vanish.

### Mechanism 2
The final token's activation at deep layers serves as a sufficient summary statistic for the model's processing state. Decoder-only LLMs use the final token position to predict the next token, meaning this vector must theoretically contain the compressed context required for generation. The delta of this vector captures how the *intent* of that generation has changed. Core assumption: The "meaning" of the finetuning update is globally distributed or at least summarized in the final residual stream, rather than being localized to specific attention heads or early layers. Break condition: If finetuning primarily alters early-layer token embeddings without affecting the final logits, this specific extraction point might miss the signal.

### Mechanism 3
The activation shifts induced by finetuning exhibit an additive property similar to task vectors. If finetuning on dataset $D_1$ moves the model by vector $v_1$ and $D_2$ by $v_2$, finetuning on $D_1 \cup D_2$ moves it approximately to $v_1 + v_2$. This linearity allows the embedding space to reflect mixed capabilities. Core assumption: The finetuning dynamics operate in a locally linear region of the loss landscape, minimizing interference between distinct domain knowledge. Break condition: If severe catastrophic forgetting or interference occurs during multi-domain training, the resulting vector will deviate from the arithmetic sum of the individual domain vectors.

## Foundational Learning

- **Concept:** **Residual Stream & Hidden States**
  - **Why needed here:** Delta Activations relies on extracting the specific vector from the final layer's residual stream. Understanding that this stream accumulates information from previous layers is crucial.
  - **Quick check question:** Does the "hidden state" refer to the input embedding or the output of the final Transformer block?

- **Concept:** **Supervised Finetuning (SFT) vs. Representation Learning**
  - **Why needed here:** The paper contrasts "flattened weights" (parameter-based) with "Delta Activations" (behavior/activation-based). You must understand that SFT changes weights, but the *effect* is measured in activations.
  - **Quick check question:** If two models have identical weights but different architectures, can Delta Activations compare them? (Hint: See Section 3.3 "Cross-architecture" and "Delta Meaning").

- **Concept:** **Silhouette Score**
  - **Why needed here:** This is the primary metric used to validate that the embeddings form meaningful clusters.
  - **Quick check question:** Does a high silhouette score indicate that clusters are dense and well-separated, or just that the data is high-dimensional?

## Architecture Onboarding

- **Component map:** Probe Dataset -> Inference Engine -> Extractor -> Delta Computer -> Aggregator
- **Critical path:** The extraction of the `last_token` hidden state. Errors in padding or truncation that shift the position of the last meaningful token will break the alignment between base and finetuned models, resulting in noisy deltas.
- **Design tradeoffs:**
  - Probe Set Size: Paper uses $N=5$. Increasing $N$ adds compute cost but provides diminishing returns (Table 5a).
  - Layer Depth: The paper notes 2/3 depth is theoretically optimal, but the final layer is simpler to implement and nearly as effective.
  - Precision: Computing deltas requires high precision (e.g., float32) to detect subtle shifts; quantized inference may destroy the signal.
- **Failure signatures:**
  - Collapse: Delta vector is near-zero (model is effectively the base model or probe is ignored).
  - Random Clustering: Silhouette score $\approx 0$ or negative (extraction logic is misaligned or finetuning failed).
  - Domination: One cluster absorbs others (Probe set is inadvertently biased toward a specific domain).
- **First 3 experiments:**
  1. **Sanity Check:** Compute Delta Activations for the base model against itself. The resulting vector should be effectively zero.
  2. **Hyperparameter Robustness:** Finetune a model on a domain (e.g., Math) with 3 different learning rates. Verify they cluster together (Section 3.2 / Table 7).
  3. **Additivity Test:** Finetune two separate models (Math, Code) and one combined model (Math+Code). Check if $v_{combined} \approx v_{math} + v_{code}$.

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: Does the clustering quality and additive property of Delta Activations scale effectively to model pools containing thousands of diverse models?
- Basis in paper: [explicit] The authors explicitly ask "how our method might perform on model pools substantially larger than those considered," noting that such pools currently exist mostly in proprietary settings.
- Why unresolved: The evaluation is limited to small pools (15 models) per backbone (LLaMA, Gemma, Qwen); behavior in massive, uncurated ecosystems is unknown.
- What evidence would resolve it: Successful maintenance of high silhouette scores and retrieval rates when applied to a comprehensive, large-scale repository such as the full Hugging Face Hub.

**Open Question 2**
- Question: Can the method be adapted to work effectively for proprietary "black-box" models where internal hidden states are inaccessible?
- Basis in paper: [explicit] The limitations section states that "Delta Activations require access to internal hidden states, which is not feasible to be evaluated on proprietary models."
- Why unresolved: The core mechanism relies on extracting $h_f(x)$, which is unavailable via standard APIs, restricting the method to open-weight architectures.
- What evidence would resolve it: A demonstration that the model-agnostic "Delta Meaning" variant achieves clustering performance comparable to the primary Delta Activations method on open models.

**Open Question 3**
- Question: How can Delta Activations be utilized to mitigate model interference during merging, given that high similarity can degrade performance?
- Basis in paper: [inferred] The model selection experiment revealed that selecting the 20 most similar models resulted in worse performance than random selection, a phenomenon attributed to "model interference."
- Why unresolved: Simple nearest-neighbor retrieval based on the embeddings is counter-productive for merging; the geometry of interference in the embedding space is unmapped.
- What evidence would resolve it: A merging algorithm that successfully uses Delta vector magnitudes or angles to select a maximally dispersed (orthogonal) set of models for ensembling.

## Limitations

- **Scope limitation:** The method's effectiveness relies on the finetuning inducing detectable activation shifts. For tasks that primarily affect early layers or require minimal weight changes, the delta signal may be weak or absent.
- **Probe set sensitivity:** While the paper shows robustness to probe set size, it doesn't explore whether certain domains require domain-specific probe templates to capture finetuning effects.
- **Cross-architecture claims:** The paper mentions that Delta-X can handle cross-architecture comparisons using model-agnostic features, but the evaluation is limited.

## Confidence

**High confidence (Strong experimental support):**
- Delta Activations consistently outperforms flattened weights and sentence embeddings for clustering finetuned models
- The method is stable across different training settings and exhibits the additive property
- Last token at the final layer is an effective extraction point

**Medium confidence (Supported but with caveats):**
- Cross-architecture applicability through Delta-X (Section 3.3 mentions but doesn't fully validate)
- Generic prompts capture sufficient signal for diverse domains (ablated but not exhaustively tested)
- The method generalizes to embedding tasks via few-shot finetuning (mentioned as a future direction)

**Low confidence (Limited evidence or theoretical):**
- Delta Activations as a tool for discovering models in the wild (Section 4 is prospective)
- The claim that finetuning "rarely rewrites" base knowledge (Section 3.4 is brief)

## Next Checks

1. **Robustness to probe prompt design:** Systematically vary the probe prompts from generic to domain-specific and measure the impact on clustering performance.

2. **Large-scale model pool evaluation:** Test Delta Activations on a significantly larger pool (>100 models) to assess scalability and whether performance degrades with increased model diversity.

3. **Cross-architecture additive property:** Finetune the same domain on two different architectures (e.g., LLaMA and Gemma) and verify whether their delta vectors can be meaningfully compared or combined.