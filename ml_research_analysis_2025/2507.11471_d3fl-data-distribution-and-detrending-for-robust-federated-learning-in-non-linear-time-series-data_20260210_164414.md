---
ver: rpa2
title: 'D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear
  Time-series Data'
arxiv_id: '2507.11471'
source_url: https://arxiv.org/abs/2507.11471
tags:
- data
- forecasting
- gen-extreme
- detrending
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of non-linear time-series data
  distributions on Federated Learning (FL) performance for forecasting. Using synthetic
  and real-world datasets (energy usage from Ausgrid), it trains LSTM-based models
  with and without detrending under centralized and FL settings.
---

# D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data

## Quick Facts
- **arXiv ID:** 2507.11471
- **Source URL:** https://arxiv.org/abs/2507.11471
- **Reference count:** 40
- **Primary result:** Detrending techniques significantly improve FL forecasting accuracy on non-linear time-series data, with differencing being most effective.

## Executive Summary
This paper investigates how non-linear time-series data distributions affect Federated Learning (FL) performance for forecasting. Using synthetic and real-world energy usage datasets, the authors train LSTM-based models with various detrending techniques under both centralized and FL settings. The study finds that FL significantly underperforms centralized learning, especially with log-normal data distributions, but appropriate detrending—particularly differencing and moving average—can substantially reduce forecasting errors across different distributions. The research highlights the critical need for tailored preprocessing in FL to handle non-linear trends and improve model accuracy.

## Method Summary
The study trains LSTM models for univariate time-series forecasting in both centralized and federated settings. Synthetic datasets are generated using gen-extreme and log-normal distributions with 10,000 data points per client, while real-world data comes from Ausgrid energy usage. Five detrending techniques are evaluated: differencing, moving average, mean subtraction, linear model, and quadratic model. The FL setup uses FedAvg aggregation with 10 clients, 100 global rounds, and 1 local epoch per round. Models use 24-hour look-back to predict 2-hour horizons, with performance measured using MSE, RMSE, and MAE.

## Key Results
- Centralized learning consistently outperforms FL, with MSE increasing by over 200% in federated settings
- Differencing proves most effective for reducing forecasting error in FL, particularly for gen-extreme distributions (MSE 0.00554)
- Log-normal distributions degrade FL performance more than gen-extreme due to higher variance across clients
- Moving average detrending shows best results for real-world mixed distribution data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If non-stationary trends are removed via differencing, the Federated Learning (FL) model converges with lower error on non-linear data.
- **Mechanism:** Differencing transforms non-stationary time-series into stationary data by subtracting the previous time step, reducing variance and extreme value drift that destabilizes gradient updates during local training.
- **Core assumption:** The underlying trends are the primary source of distribution shift causing model divergence, rather than inherent noise or seasonality.
- **Evidence anchors:** [Section VI-A2] Differencing yields MSE of 0.00554 for clients with gen-extreme distributions; [Section II-C] defines the differencing equation.

### Mechanism 2
- **Claim:** Log-normal data distributions degrade FL performance more than generalized extreme value (gen-extreme) distributions due to higher variance.
- **Mechanism:** Log-normal distributions are right-skewed with long tails, causing high variance across clients that leads to larger gradient explosions or shifts during FL aggregation.
- **Core assumption:** The increase in MSE is driven by the statistical variance of the distribution rather than the volume of data points.
- **Evidence anchors:** [Section VI-A1] Average MSE rose from 0.00844 (gen-extreme) to 0.03115 (mixed) due to extreme values; [Abstract] notes FL performs worse with non-linear data distributions.

### Mechanism 3
- **Claim:** Centralized learning outperforms FL on non-linear time-series because it can model global trends that are lost when data is siloed.
- **Mechanism:** A centralized LSTM sees the full distribution and trend trajectory across all clients simultaneously, while FL's averaged model becomes a compromise that fails to capture sharp non-linear curves of individual clients.
- **Core assumption:** The non-linear trends are not locally learnable within a single client's epoch window before overfitting occurs.
- **Evidence anchors:** [Section VI-A1] Centralized models consistently outperformed FL counterparts; [Section I] notes FL is less effective with non-IID data.

## Foundational Learning

- **Concept: Stationarity vs. Non-Stationarity**
  - **Why needed here:** The paper's core intervention (detrending) attempts to force non-stationary data into a stationary state to help the model.
  - **Quick check question:** If a dataset has a consistent upward curve (trend), is it stationary?

- **Concept: FedAvg (Federated Averaging)**
  - **Why needed here:** Understanding that FedAvg simply averages weights explains why high-variance log-normal clients destabilize the global model.
  - **Quick check question:** In FedAvg, does the server see the raw data of the clients to calculate the average?

- **Concept: Time-Series Detrending Methods**
  - **Why needed here:** The paper evaluates 5 methods (Differencing, Moving Average, Mean Subtraction, Linear, Quadratic) with different mathematical properties.
  - **Quick check question:** Which detrending method would you use to remove a curve that looks like a parabola ($y=x^2$)?

## Architecture Onboarding

- **Component map:** Data Inject -> Local Train -> Aggregate -> Validate
- **Critical path:**
  1. **Data Inject:** Generate/Load data → Apply Detrending (e.g., Differencing)
  2. **Local Train:** Client trains LSTM on 24h look-back, 2h forecast (1 local epoch)
  3. **Aggregate:** Server receives weights → FedAvg → Dispatches new global model
  4. **Validate:** Evaluate on 10% hold-out set using MSE/MAE/RMSE

- **Design tradeoffs:**
  - **Detrending vs. Raw:** Detrending reduces MSE but requires reversible transformations if final output must be in original scale
  - **Synthetic vs. Real:** Synthetic data allows isolation of distribution effects while real data validates robustness

- **Failure signatures:**
  - **Log-Normal Spike:** High MSE (0.015+) specifically in Exp 2/3 suggests model failing to handle long tail
  - **Divergence:** If FL loss oscillates wildly while Centralized loss stabilizes, detrending method is failing

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Run Exp 1 (Gen-extreme, No detrending) in both Centralized and FL modes to verify environment matches paper
  2. **Detrending Intervention:** Apply Differencing to Log-normal dataset (Exp 5) and check if FL MSE drops toward 0.013 range
  3. **Real-world Stress Test:** Take Ausgrid "Mixed" dataset (Exp 9, Moving Average) and verify FL achieves RMSE below 0.11

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can time-series data characteristics be leveraged to develop data-driven client selection strategies and offloading approaches?
- **Basis in paper:** [explicit] Authors state in conclusion: "For future work, we plan to investigate the characteristics of time-series data to develop data-driven client selection strategies and offloading approaches."
- **Why unresolved:** Current study uses fixed client set and focuses on preprocessing/impact analysis rather than optimizing client selection based on data distribution.
- **What evidence would resolve it:** A framework that dynamically selects clients based on local trend metrics and demonstrates faster convergence than random selection.

### Open Question 2
- **Question:** Can an adaptive mechanism be designed to automatically select the optimal detrending technique based on a client's specific local data distribution?
- **Basis in paper:** [inferred] Authors conclude that "the choice of technique should be based on the underlying characteristics of the data" because differencing worked best for synthetic data while quadratic detrending worked best for real-world gen-extreme data.
- **Why unresolved:** Paper evaluates techniques individually but does not propose algorithmic selection without manual tuning.
- **What evidence would resolve it:** A/B comparison showing meta-detrending model outperforms any single static detrending method in heterogeneous FL environment.

### Open Question 3
- **Question:** Can personalized or advanced aggregation strategies bridge the performance gap between Federated Learning and centralized learning for non-linear time-series data?
- **Basis in paper:** [inferred] Paper consistently reports FL performs worse than centralized approaches (MSE increasing by over 200%) using only standard FedAvg aggregator.
- **Why unresolved:** Study isolates detrending as primary variable and does not explore whether modifying aggregation logic could mitigate accuracy loss.
- **What evidence would resolve it:** Experiments demonstrating personalized FL approach reduces MSE to be statistically insignificant from centralized baseline.

## Limitations
- The study does not specify critical hyperparameters including batch size, learning rate, and optimizer choice
- Synthetic data generation uses vague descriptions of sine functions and offsets without exact mathematical formulations
- Research focuses exclusively on univariate forecasting with LSTM models, limiting generalizability

## Confidence
- **High:** Detrending improves centralized model performance; Differencing is effective for gen-extreme distributions
- **Medium:** Log-normal distributions create greater FL challenges than gen-extreme; Differencing most effective for FL
- **Low:** Generalizability to other time-series models and multivariate forecasting

## Next Checks
1. Replicate synthetic experiments with explicit parameter specifications (sine frequency, offset values) to verify distribution separation effects
2. Test additional detrending methods including wavelet-based approaches and compare against differencing performance
3. Evaluate FL robustness under varying client counts (5, 20, 50) to assess scalability beyond 10-client baseline