---
ver: rpa2
title: On the Complexity of Global Necessary Reasons to Explain Classification
arxiv_id: '2501.06766'
source_url: https://arxiv.org/abs/2501.06766
tags:
- global
- necessary
- reason
- classi
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the computational complexity of determining
  minimal global necessary reasons to explain the behavior of classifiers. The authors
  focus on three families of classifiers: binary decision diagrams (BDDs), perceptrons,
  and multilayer perceptrons (MLPs).'
---

# On the Complexity of Global Necessary Reasons to Explain Classification

## Quick Facts
- arXiv ID: 2501.06766
- Source URL: https://arxiv.org/abs/2501.06766
- Reference count: 7
- Primary result: Deciding minimal global necessary reasons is in L for perceptrons, NL-complete for BDDs, and DP-complete for MLPs

## Executive Summary
This paper investigates the computational complexity of determining minimal global necessary reasons to explain classifier behavior. The authors analyze three classifier families - perceptrons, binary decision diagrams (BDDs), and multilayer perceptrons (MLPs) - using a logic-based language to express conditions that must be satisfied for classification. They establish complexity bounds ranging from logspace for perceptrons to DP-complete for MLPs, providing a complete characterization of when explanations can be efficiently computed.

## Method Summary
The paper presents a generic decision procedure (Algorithm 1) that determines whether a condition is a minimal global necessary reason by checking if any entailed literal is itself a global necessary reason. This procedure is instantiated differently for each classifier family: a logspace subroutine for perceptrons, a nondeterministic logspace algorithm for BDDs, and a SAT-based approach for MLPs. The complexity analysis leverages reductions to established problems (2CNF unsatisfiability for L, path existence for NL, SAT for DP) and carefully characterizes the relationship between logical entailment and classifier behavior.

## Key Results
- Deciding minimal global necessary reasons is in L for perceptrons, NL-complete for BDDs, and DP-complete for MLPs
- Cardinality-minimality and subset-minimality criteria coincide for the studied classifier families
- For MLPs, a SAT-based approach is necessary due to DP-hardness of the decision problem

## Why This Works (Mechanism)

### Mechanism 1: Literal-Based Minimality Characterization
The key insight is that a global necessary reason φ is minimal if and only if no literal ℓ (with φ ⊭ ℓ) is itself a global necessary reason. Algorithm 1 checks O(n²) literals, using logspace entailment checking via 2CNF reduction and classifier-specific subroutines. This mechanism works because the logical language L[n] (conjunctions of (in)equalities) enables tractable entailment checking while maintaining expressiveness.

### Mechanism 2: BDD Path-Literal Duality
For BDDs, a condition φ is not a global necessary reason iff there exists a path π to a c-sink and literal ℓ such that φ_π ⊭ ℓ and φ ⊧ ℓ. Algorithm 2 uses nondeterministic traversal to guess paths and literals, checking conditions dynamically. This works because BDDs have a uniform structure (rooted DAG with two outgoing edges per node) that enables logspace traversal.

### Mechanism 3: MLP Complexity via SAT Reduction
Deciding minimal global necessary reasons for MLPs is DP-complete because arbitrary global necessary reasons are co-NP-complete (reduce from UNSAT), and minimality adds an NP check. The reduction encodes 3CNF formulas into MLPs computing (γ ∨ g) ∧ (δ ∨ d), with minimality requiring γ satisfiable and δ unsatisfiable (Sat-Unsat, DP-hard).

## Foundational Learning

- **Concept: Complexity classes L, NL, co-NP, DP**
  - Why needed: Main results are phrased in these classes; understanding their relationships (L ⊆ NL ⊆ NP, co-NP ⊆ DP) is essential to interpret tractability landscape.
  - Quick check: Why is NL closed under complement but NP is not believed to be?

- **Concept: Binary Decision Diagrams (BDDs)**
  - Why needed: BDDs are one of three classifier families studied; their graph-based structure enables logspace path traversal.
  - Quick check: What property of BDDs ensures each instance follows exactly one path from root to sink?

- **Concept: 2CNF and Implication Graphs**
  - Why needed: Entailment checking in L[n] reduces to 2CNF unsatisfiability; undirected implication graph allows logspace reachability.
  - Quick check: Why does symmetry of implications make reachability easier to decide?

## Architecture Onboarding

- **Component map:** Logical language L[n] (conjunctions of (in)equalities) -> Minimality oracle (classifier-specific subroutine) -> Literal enumerator (iterates over O(n²) literals) -> Greedy builder (conjoins necessary literals)
- **Critical path:** For MLPs, the co-NP oracle dominates; each iteration may call a SAT solver. For BDDs/perceptrons, entire process is in logspace/NL.
- **Design tradeoffs:** Expressiveness vs. complexity: Adding disjunctions would make explanations more expressive but computationally intractable. Minimality criteria: Cardinality and subset minimality coincide for L[n], simplifying implementation.
- **Failure signatures:** For MLPs: If SAT solver times out, no explanation is returned; problem is DP-hard. For BDDs: If graph is not a DAG or not uniform, NL algorithm may not terminate correctly.
- **First 3 experiments:**
  1. Implement literal-based minimality test for perceptrons; verify logspace behavior on synthetic data.
  2. Implement BDD path-literal nondeterministic algorithm; test against uniform RDAG reachability benchmarks.
  3. Integrate SAT solver for MLP explanations; measure overhead and correctness on encoded Sat-Unsat instances.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the computational complexity of deciding and computing minimal global sufficient reasons for the families of classifiers studied (BDDs, perceptrons, MLPs)?
- Basis in paper: [explicit] The authors state: "Another avenue for future work is to carry out complexity analyses for other important notions proposed in the literature where a systematic study is still lacking, such as for global sufficient reasons, which are the logical dual of global necessary reasons."
- Why unresolved: Global sufficient reasons (φ such that x|=φ → M(x)=c) are the logical dual of global necessary reasons, but their complexity may differ substantially; the techniques developed for necessary reasons may not directly transfer.
- What evidence would resolve it: A complete complexity classification matching Table 4.1's structure for global sufficient reasons, including upper and lower bounds for each classifier family.

### Open Question 2
- Question: How does extending the language L[n] to allow disjunctions or richer logical constructs affect the complexity of computing minimal global necessary reasons?
- Basis in paper: [explicit] The authors state their study "might be extended along different dimensions, such as by considering other (more expressive) languages to express conditions" and note that allowing disjunctions would increase expressiveness but come at computational cost.
- Why unresolved: The paper deliberately restricted the language to conjunctions of (in)equalities for interpretability; the complexity trade-offs of richer languages remain unexplored.
- What evidence would resolve it: Complexity analysis for decision problems over extended languages, showing whether hardness increases and by how much.

### Open Question 3
- Question: What is the practical performance of SAT-based approaches for computing minimal global necessary reasons for MLPs on real-world classifiers?
- Basis in paper: [explicit] The authors state: "A natural next step is the development of algorithms to compute (minimal) global necessary reasons (along with their experimental evaluation)."
- Why unresolved: The paper provides theoretical foundations and proves a SAT-based approach is "somewhat mandatory" for MLPs, but no implementation or empirical evaluation is provided.
- What evidence would resolve it: Implementation of the proposed algorithms and benchmarking on trained MLPs from practical applications, measuring runtime and explanation quality.

## Limitations

- Limited empirical validation: The paper establishes theoretical complexity bounds but provides no experimental evaluation of the algorithms on real-world classifiers.
- External dependency dependencies: The DP-hardness proof for MLPs relies on external results from Barceló et al. (2020) without reproducing the exact weight construction.
- Weak corpus support: The related work search returned no papers addressing the specific complexity questions posed here, suggesting this is a novel theoretical contribution.

## Confidence

- **High confidence:** The theoretical framework linking logical minimality to complexity classes (L, NL, co-NP, DP) is internally consistent and well-grounded in established complexity theory.
- **Medium confidence:** The BDD-specific algorithm and complexity analysis are detailed and appear correct, though the lack of external validation makes absolute certainty difficult.
- **Low confidence:** The perceptron complexity claim (L) and the exact implementation of the generic instance generation mechanism are stated but not fully detailed in the text.

## Next Checks

1. Implement and verify Algorithm 1 on synthetic perceptron and BDD examples, measuring actual runtime against theoretical complexity bounds.

2. Reconstruct the MLP reduction from Barceló et al. (2020) Lemma 13 to verify the DP-hardness claim independently.

3. Implement Algorithm 2 with explicit cycle detection and verify correctness on small uniform BDDs against brute-force enumeration.