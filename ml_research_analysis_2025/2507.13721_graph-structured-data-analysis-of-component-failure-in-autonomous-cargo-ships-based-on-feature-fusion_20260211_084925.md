---
ver: rpa2
title: Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships
  Based on Feature Fusion
arxiv_id: '2507.13721'
source_url: https://arxiv.org/abs/2507.13721
tags:
- failure
- feature
- system
- data
- mode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study constructs a graph-structured dataset for component
  failure analysis in autonomous cargo ships (ACS), addressing challenges of cascading
  failures and uncertain emergency decision-making. It employs an improved cuckoo
  search algorithm (HN-CSA) for efficient literature retrieval, achieving F1-scores
  of 0.60 and a Pareto hypervolume of 0.153, surpassing existing methods by 3.4-7.1%.
---

# Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion

## Quick Facts
- **arXiv ID**: 2507.13721
- **Source URL**: https://arxiv.org/abs/2507.13721
- **Reference count**: 0
- **Primary result**: Graph-structured dataset with 12 systems, 1,262 failure modes, and 6,150 propagation paths; GATE-GNN achieves 0.735 accuracy

## Executive Summary
This study constructs a graph-structured dataset for component failure analysis in autonomous cargo ships, addressing cascading failures and uncertain emergency decision-making. The dataset integrates 12 systems, 1,262 failure modes, and 6,150 propagation paths using hybrid feature fusion from Word2Vec, BERT, and Sentence-BERT. An improved cuckoo search algorithm (HN-CSA) achieves F1-scores of 0.60 and a Pareto hypervolume of 0.153, outperforming existing methods by 3.4-7.1%. Validation shows GATE-GNN achieves classification accuracy of 0.735, with the Shore-based Meteorological Service System reaching F1-score of 0.93.

## Method Summary
The methodology combines literature retrieval via an improved cuckoo search algorithm (HN-CSA) with hybrid feature fusion from three embedding models (Word2Vec, BERT-KPCA, Sentence-BERT) and graph topology construction. The dataset represents failures as nodes with edges constructed through expert-evaluated propagation paths using AHP-TOPSIS-ASIM. Classification is performed using GATE-GNN on the graph-structured data, with validation across 12 autonomous cargo ship systems.

## Key Results
- HN-CSA achieves F1-scores of 0.60 and Pareto hypervolume of 0.153, outperforming existing methods by 3.4-7.1%
- GATE-GNN classification accuracy reaches 0.735 on the constructed dataset
- Shore-based Meteorological Service System achieves F1-score of 0.93, while Positioning System and Intelligent Cargo Hold show poor performance (F1=0.19 and 0.34)
- Hybrid feature fusion creates distinct clusters with average silhouette coefficient of 0.62

## Why This Works (Mechanism)

### Mechanism 1: Hidden Nest Strategy for Search Space Coverage
The "hidden nest" strategy prevents premature convergence by temporarily masking optimal solutions during iterations, forcing exploration of broader keyword combinations. This improves Pareto hypervolume by 4.1% over standard CSA by avoiding local optima in semantic search.

### Mechanism 2: Semantic Alignment via Task-Specific Encoding
Different embedding models are assigned to text granularities: Word2Vec for short component labels, BERT-KPCA for medium failure modes, and Sentence-BERT for long emergency measures. This preserves semantic nuance better than a single encoder by preventing dilution of short labels or truncation of long documents.

### Mechanism 3: Topological Regularization of Failure Propagation
Representing failures as a graph topology enables the model to learn cascading fault dependencies rather than treating failures as independent. The 6,150 edges constructed via expert evaluation provide structural priors that allow GATE-GNN to propagate label information from high-data to low-data systems.

## Foundational Learning

- **Graph Representation Learning (GNNs)**: Needed to understand how message passing aggregates neighbor features for cascading failure analysis. Quick check: Removing 6,150 propagation edges would likely decrease GATE-GNN performance by eliminating structural priors.
- **Word Embeddings vs. Sentence Embeddings**: Required to understand why hybrid fusion is necessary. Quick check: Word2Vec would fail to capture "Emergency Decision-Making Measure" nuance due to loss of word order and long-range context.
- **Meta-heuristic Optimization (Cuckoo Search)**: Needed to understand HN-CSA's literature retrieval approach. Quick check: "Hidden nest" solves the problem of getting stuck in local optima during keyword search.

## Architecture Onboarding

- **Component map**: Raw text -> HN-CSA Crawler -> Hybrid Vector Builder (Word2Vec→Components; BERT-KPCA→Modes; S-BERT→Measures) -> Graph Topology Builder -> GATE-GNN
- **Critical path**: Feature Fusion stage. Misconfiguration of weights or KPCA dimensionality reduction causes silhouette coefficient drops, preventing GNN from separating classes.
- **Design tradeoffs**: HN-CSA achieves high recall (0.64) but lower precision (0.59), creating a comprehensive but noisy dataset. AHP-TOPSIS-ASIM edge construction is accurate but labor-intensive and expert-dependent.
- **Failure signatures**: Low F1-scores (0.19-0.34) for Positioning and Intelligent Cargo Hold systems indicate data sparsity or isolation. Silhouette coefficient below 0.5 suggests KPCA compression creates overlapping feature space.
- **First 3 experiments**: 1) Ablate "hidden nest" strategy to verify 4.1% hypervolume improvement. 2) Vary KPCA retained variance (90% vs 95%) to test 121-dimension optimality. 3) Train GATE-GNN with edges removed to quantify cascading topology contribution.

## Open Questions the Paper Calls Out

1. How can few-shot learning or transfer learning be effectively integrated to improve the representation of failure modes in systems with sparse data samples?
2. To what extent does incorporating real-time sensor data into the feature extraction pipeline enhance the dataset's robustness compared to the current text-based approach?
3. What architectural modifications are required to resolve the semantic overlap and feature confounding observed in systems like the Positioning System?

## Limitations
- Domain-specific bias may limit generalization to non-maritime autonomous systems
- HN-CSA performance improvement lacks comparison to more recent meta-heuristics
- Hybrid feature fusion requires significant computational overhead that may not scale to real-time applications
- Expert-dependent edge construction introduces potential subjectivity in propagation topology

## Confidence
- **High**: GATE-GNN classification accuracy (0.735) and Shore-based Meteorological Service F1-score (0.93)
- **Medium**: HN-CSA literature retrieval performance metrics (Recall=0.64, Precision=0.59)
- **Low**: Generalization of dataset to non-maritime autonomous systems

## Next Checks
1. Conduct ablation studies removing the "hidden nest" strategy to quantify its specific contribution to the 4.1% hypervolume improvement
2. Test GATE-GNN performance on randomly edge-removed graphs to isolate the contribution of the cascading failure topology
3. Validate the dataset's transferability by applying the same methodology to a different autonomous system domain (e.g., autonomous vehicles) and comparing failure propagation patterns