---
ver: rpa2
title: Split Conformal Prediction in the Function Space with Neural Operators
arxiv_id: '2509.04623'
source_url: https://arxiv.org/abs/2509.04623
tags:
- prediction
- coverage
- conformal
- function
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work extends split conformal prediction to function spaces
  for uncertainty quantification in neural operators. The core method discretizes
  the output function space using a quadrature-weighted norm, applies standard split
  conformal prediction in this finite-dimensional space, and lifts the resulting coverage
  guarantee to the continuous function space via a bilipschitz discretization assumption.
---

# Split Conformal Prediction in the Function Space with Neural Operators

## Quick Facts
- arXiv ID: 2509.04623
- Source URL: https://arxiv.org/abs/2509.04623
- Authors: David Millard; Lars Lindemann; Ali Baheri
- Reference count: 17
- Primary result: Extends split conformal prediction to function spaces for neural operators using quadrature-weighted discretization and bilipschitz assumptions

## Executive Summary
This work introduces a method for uncertainty quantification in neural operators operating on function spaces by extending split conformal prediction to infinite-dimensional outputs. The approach discretizes continuous function outputs using quadrature-weighted norms, applies standard split conformal prediction in this finite-dimensional space, and lifts the coverage guarantee to the continuous function space via a bilipschitz discretization assumption. The method decomposes conformal radius into discretization, calibration, and misspecification components, enabling a regression-based correction for resolution shifts. Empirical results demonstrate calibrated coverage with less variation under resolution shifts and improved coverage in super-resolution tasks compared to baseline approaches.

## Method Summary
The method discretizes continuous function outputs using quadrature-weighted L2 norms, where each grid cell receives volume-based weights. Split conformal prediction is applied in this weighted discrete space, and coverage guarantees are lifted to the continuous function space via a bilipschitz discretization assumption. The conformal radius is decomposed into discretization error, calibration error, and misspecification error. For super-resolution tasks, a log-linear regression on conformal radius across resolutions enables calibration transfer without retraining. The approach also introduces diagnostic metrics for autoregressive forecasting, including conformal ensemble score and internal agreement.

## Key Results
- Maintains calibrated coverage with 5.1% vs 8.6% coefficient of variation under resolution shifts using weighted norms
- Improves super-resolution coverage from 19.9% to 74.9% in Poisson case and 87.8% to 90.9% in Darcy case
- Demonstrates functional coverage around 90% in benchmark problems while baseline MC dropout methods show undercoverage

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quadrature-weighted L2 norm discretizes function-space outputs while preserving asymptotic equivalence to continuous L2 norm
- Mechanism: Each grid cell receives weight w_j = ∏Δx^(k)_jk (cell volume). The weighted norm ‖h‖²_w,2 = Σw_j·h(x_j)² is a Riemann sum for ∫u²dx, converging to continuous L2 norm as mesh refines
- Core assumption: Target functions lie in Sobolev space H^s(Ω) with s > d/2 (smoothness sufficient for convergence)
- Evidence anchors: Theorem 4 proves lim_{d→∞} ‖f‖²_w,2,d = ‖f‖²_{L2(Ω)}; corpus lacks direct evidence for function-space extensions
- Break condition: Non-smooth or discontinuous functions violate Sobolev assumption, breaking convergence guarantees

### Mechanism 2
- Claim: Bilipschitz discretization assumption enables lifting finite-sample coverage from discrete to continuous function space
- Mechanism: If c₁‖u−v‖_Y ≤ ‖P_d(u)−P_d(v)‖_{w,2,d} ≤ c₂‖u−v‖_Y, then discrete nonconformity score bounds continuous score: s_i ≤ τ_α implies ‖û−u‖_Y ≤ τ_α/c₁
- Core assumption: Assumption 1 (Bilipschitz Discretization) holds with constants c₁, c₂ close to 1 for smooth functions on fine grids
- Evidence anchors: Theorem 1 states functional coverage guarantee via bilipschitz inequality; full proof derives functional coverage from discrete guarantee
- Break condition: Coarse discretizations or irregular grids where c₁ ≪ 1 produce overly conservative prediction sets

### Mechanism 3
- Claim: Log-linear regression on conformal radius across resolutions enables calibration transfer for super-resolution without retraining
- Mechanism: Empirically observed log τ(R_i) ≈ s·R_i + b beyond training resolution. Fitted regression τ(R) = exp(s·R + b) extrapolates to higher resolutions
- Core assumption: Conformal radius varies log-linearly with resolution in target regime (FNO-specific empirical pattern)
- Evidence anchors: Equation (7): τ(R) = exp(s·R + b); Table 5 shows coverage improvements after adjustment
- Break condition: Large resolution jumps or model architectures without log-linear behavior may produce unreliable extrapolation

## Foundational Learning

- Concept: Split Conformal Prediction
  - Why needed here: Core framework providing finite-sample, distribution-free coverage guarantees; this work extends it to function spaces
  - Quick check question: Given calibration scores s_1,...,s_n and miscoverage level α=0.1, what quantile defines threshold τ_α? (Answer: ⌈(1−α)(n+1)⌉-th ordered score)

- Concept: Neural Operators (FNO, DeepONet)
  - Why needed here: Learn mappings between infinite-dimensional function spaces; outputs require function-space uncertainty quantification
  - Quick check question: How does a neural operator differ from a standard neural network? (Answer: Learns operator G: X→Y between function spaces, not pointwise mappings)

- Concept: Weighted Norms and Quadrature
  - Why needed here: Bridges discrete evaluations and continuous function norms via Riemann sum approximation
  - Quick check question: Why use cell-area weights w_j rather than uniform weights? (Answer: Uniform weights ignore grid geometry; weighted norm converges to continuous L2 integral)

## Architecture Onboarding

- Component map: Input functions → Discretization operator P_d → Neural operator G_θ → Nonconformity scorer → Calibration routine → Prediction set constructor → Output functional ball Γ_α(f)

- Critical path: Train G_θ → Discretize calibration pairs → Compute nonconformity scores → Extract τ_α → Apply to test functions

- Design tradeoffs:
  - Weighted vs. unweighted norm: Weighted reduces variation under grid geometry shifts (5.1% vs. 8.6% CoV) but requires cell-area computation
  - MC sampling vs. quantile bounds: MC provides pointwise intervals but computationally expensive; quantile bounds efficient but rely on pinball loss quality
  - Resolution transport: Enables super-resolution without recalibration but loses formal guarantee (heuristic only)

- Failure signatures:
  - Coverage drops sharply under large resolution mismatch (Poisson falls to 19.9% without adjustment)
  - Autoregressive forecasting: IA drops from 98% to 10.7% over 8 steps, signaling distribution drift
  - Non-smooth solutions violate Sobolev assumption, breaking bilipschitz property

- First 3 experiments:
  1. Reproduce Darcy 1D MC-Dropout calibration: Train FNO with dropout, compute τ_α on calibration set, verify functional coverage ≈ 90% at α=0.1
  2. Grid geometry ablation: Generate Poisson 2D data on uniform/center-clustered/boundary-clustered grids; compare weighted vs. unweighted norm variation in τ_α values
  3. Super-resolution transport: Calibrate at resolution d=256, fit log-linear regression on τ values at d∈{320,384,448}, evaluate coverage at d=512 with and without adjustment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the bilipschitz constant \(c_1\) be explicitly bounded or estimated for specific discretization schemes beyond the asymptotic regime where \(c_1 \to 1\)?
- Basis in paper: Theorem 1 requires Assumption 1 (bilipschitz discretization), but paper notes only that "for sufficiently fine discretizations, the distortion constant \(c_1 \to 1\)" without providing finite-resolution bounds
- Why unresolved: Proof relies on asymptotic convergence; practical finite-grid applications must assume \(c_1 \approx 1\) without quantifying approximation error
- What evidence would resolve it: Deriving explicit bounds on \(c_1\) as function of grid resolution and function regularity, validated empirically across resolutions

### Open Question 2
- Question: Can log-linear extrapolation heuristic for super-resolution conformal radius adjustment be replaced with method that preserves formal coverage guarantees?
- Basis in paper: "Although no formal coverage guarantee exists for extrapolated value \(\tau_\alpha\), we find that it yields substantial improvements in coverage accuracy" (Section 4)
- Why unresolved: Decomposition in Equation 6 is motivated theoretically but regression-based correction is purely empirical
- What evidence would resolve it: Deriving finite-sample coverage bounds for resolution transfer under assumptions on decay rate of \(\varepsilon_{disc}(d)\) and \(\varepsilon_{misspec}(d)\)

### Open Question 3
- Question: How can conformal prediction be extended to autoregressive neural operator forecasting while maintaining valid coverage under distributional drift?
- Basis in paper: "Because each forecasted state depends on previous predictions, sequence is no longer exchangeable. This violates core assumption of split conformal prediction" (Time-Series Forecasting section)
- Why unresolved: Paper treats coverage degradation as diagnostic signal rather than correcting for it; existing adaptive conformal methods not integrated
- What evidence would resolve it: Incorporating drift-aware corrections and empirically demonstrating maintained coverage over extended forecast horizons

### Open Question 4
- Question: Why does resolution adjustment heuristic fail to recover target coverage in Poisson case (74.9% vs. 90%) but succeeds in Darcy (90.9%)?
- Basis in paper: Table 5 shows adjusted Poisson super-resolution coverage remains substantially below target; paper states heuristic "fails to capture full complexity of underlying error behavior"
- Why unresolved: Paper observes phenomenon but does not analyze whether failure stems from model misspecification, discretization, or their interaction
- What evidence would resolve it: Ablation studies isolating each error component, or theoretical analysis of how solution regularity affects \(\tau_\alpha(d)\) scaling

## Limitations
- Bilipschitz discretization assumption critical but not rigorously verified across diverse function classes and grid geometries
- Log-linear resolution-transport heuristic shows empirical promise but lacks theoretical grounding and may fail for large resolution jumps
- Autoregressive forecasting coverage degrades due to distributional drift from exchangeability violation

## Confidence
- High: Core split conformal prediction framework and weighted discretization mechanism (supported by established theory and empirical validation)
- Medium: Bilipschitz assumption validity across general function spaces (theoretically sound but practically unverified)
- Medium: Resolution-transport log-linear regression (empirically effective but theoretically heuristic)

## Next Checks
1. **Bilipschitz Sensitivity Analysis**: Systematically evaluate coverage guarantees across function classes (smooth, piecewise smooth, discontinuous) and grid types (uniform, clustered, adaptive) to quantify breakdown conditions
2. **Resolution Transport Robustness**: Test log-linear extrapolation limits by applying resolution transport to larger resolution gaps (e.g., 2x, 4x) and alternative architectures (DeepONet vs. FNO) to identify failure modes
3. **Autoregressive Distribution Drift**: Extend autoregressive experiments beyond 8 steps and analyze internal agreement trajectories to determine when distribution drift invalidates conformal assumptions