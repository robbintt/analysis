---
ver: rpa2
title: 'FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation
  via Federated Learning'
arxiv_id: '2505.05155'
source_url: https://arxiv.org/abs/2505.05155
tags:
- data
- trajectory
- fedtdp
- training
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedTDP, a privacy-preserving framework for
  trajectory data preparation in federated environments. It addresses the limitations
  of existing methods that either compromise privacy or lack generalizability across
  diverse tasks.
---

# FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning

## Quick Facts
- **arXiv ID:** 2505.05155
- **Source URL:** https://arxiv.org/abs/2505.05155
- **Reference count:** 40
- **Primary result:** FedTDP outperforms 13 baselines by 4.84% to 45.22% on 6 datasets across 10 trajectory data preparation tasks while preserving privacy.

## Executive Summary
This paper introduces FedTDP, a federated learning framework for trajectory data preparation that addresses the privacy and generalizability limitations of existing methods. The framework leverages Large Language Models (LLMs) with a privacy-preserving autoencoder to securely transmit trajectory data, and a trajectory knowledge enhancer to adapt LLMs for spatio-temporal data. Federated parallel optimization improves training efficiency by reducing data transmission and enabling parallel model training. Experiments demonstrate significant performance improvements over state-of-the-art baselines while maintaining privacy guarantees.

## Method Summary
FedTDP implements a three-module architecture: (1) Trajectory Privacy AutoEncoder (TPA) that converts raw trajectory points into 32-dimensional embeddings using a 3-layer MLP with GELU activation, (2) Trajectory Knowledge Enhancer (TKE) that adapts LLMs for spatio-temporal data through bidirectional knowledge distillation between server-side LLM and client-side SLM, and (3) Federated Parallel Optimization (FPO) that reduces communication overhead through LoRA sparse-tuning and alternating optimization. The framework is evaluated on 6 datasets across 10 trajectory data preparation tasks using a multi-task training approach with combined loss functions.

## Key Results
- FedTDP achieves 4.84% to 45.22% better performance than 13 baseline methods across 10 trajectory tasks
- Framework maintains privacy through decentralized secret-sharing aggregation preventing trajectory reconstruction
- Strong generalization demonstrated on both seen and unseen datasets with consistent improvements
- Communication efficiency improved through LoRA sparse-tuning and alternating optimization strategies

## Why This Works (Mechanism)

### Mechanism 1: Privacy Preservation through Secret Sharing
- **Claim:** The framework preserves data privacy by preventing trajectory reconstruction during model aggregation, even if embeddings are intercepted.
- **Mechanism:** Trajectory Privacy AutoEncoder (TPA) converts raw trajectory points into embeddings, and a decentralized secret-sharing method masks parameter blocks with pairwise secret keys ($sk_{i,j}$) during Federated Learning aggregation.
- **Core assumption:** Attackers cannot access raw local data or pre-shared secret keys stored on client devices.
- **Evidence anchors:** Section 4.1 describes the decentralized aggregation approach and acknowledges limitations of embedding-only privacy.
- **Break condition:** Privacy fails if secret keys are compromised or embedding dimension is too high for reconstruction prevention.

### Mechanism 2: Generalizability through Bidirectional Knowledge Distillation
- **Claim:** The system achieves generalizability across 10 distinct Trajectory Data Preparation (TDP) tasks by distilling knowledge between server-side LLM and client-side SLM.
- **Mechanism:** Trajectory Knowledge Enhancer (TKE) uses bidirectional knowledge learning with inverse KL divergence aligning SLM output with LLM's high-frequency output, and forward KL divergence aligning LLM knowledge with SLM's raw data perspective.
- **Core assumption:** LLMs possess latent reasoning capabilities applicable to spatio-temporal trajectories if properly prompted and distilled.
- **Evidence anchors:** Section 4.2 details the bidirectional knowledge learning approach and its alignment with LLM multi-task learning capabilities.
- **Break condition:** Mechanism fails if SLM capacity is too small to absorb LLM knowledge or prompt engineering fails to bridge natural language and spatio-temporal logic gaps.

### Mechanism 3: Training Efficiency through Federated Parallel Optimization
- **Claim:** The framework improves training efficiency by reducing communication overhead through selective parameter updates and split learning.
- **Mechanism:** FPO uses LoRA sparse-tuning selecting top $m$ layers with highest parameter change rates for training, and alternating optimization freezing data transmissions periodically for local training without continuous synchronization.
- **Core assumption:** Layers with higher parameter change rates contribute disproportionately to model convergence.
- **Evidence anchors:** Section 4.3 describes LoRA sparse-tuning and FPO's decomposition of federated training.
- **Break condition:** Efficiency gains diminish if convergence requires updating dense layers or frozen data distribution shifts significantly.

## Foundational Learning

- **Concept: Split Learning**
  - **Why needed here:** The architecture splits the model between client (SLM/TPA) and server (LLM), requiring understanding of partitioned forward/backward passes and smashed data management.
  - **Quick check question:** Can you explain who holds the decoder weights versus the LLM weights in this framework?

- **Concept: Parameter-Efficient Fine-Tuning (PEFT) / LoRA**
  - **Why needed here:** The paper relies on LoRA to make training feasible through sparse-tuning modifications.
  - **Quick check question:** How does LoRA reduce the number of trainable parameters without changing the pre-trained model weights?

- **Concept: Secret Sharing (Shamir's or Pairwise)**
  - **Why needed here:** Section 4.1 uses pairwise secret keys to mask parameter blocks before aggregation.
  - **Quick check question:** In this context, why is secret sharing preferred over Differential Privacy (DP) for protecting TPA parameters?

## Architecture Onboarding

- **Component map:** Raw Data -> TPA Encoder -> Embeddings -> Server LLM -> Decoded Results -> Client SLM -> Results
- **Critical path:**
  1. Local TDP: Raw Data -> SLM -> Result (No server interaction)
  2. Cross-Client TDP: Raw Data -> TPA Encoder -> Embeddings -> Server LLM -> Decoded Results
  3. Training Update: Calculate Loss -> Select Top-$m$ LoRA Layers -> Mask Parameters (Secret Sharing) -> Aggregate -> Broadcast
- **Design tradeoffs:**
  - *Accuracy vs. Privacy:* TPA embeddings preserve spatio-temporal correlation but may lose fine-grained detail compared to raw coordinates
  - *Efficiency vs. Convergence:* "Freezing" data in FPO reduces communication but may slow convergence if frozen state becomes stale
  - *SLM Size:* Smaller SLM reduces client load but limits capacity for local reasoning distilled from LLM
- **Failure signatures:**
  - TPA Collapse: Reconstruction loss ($L_1$) remains high; trajectory decoding produces garbage coordinates
  - Secret Sharing Deadlock: Clients cannot agree on keys or aggregate parameters correctly (sum of masks â‰  0)
  - Catastrophic Forgetting: LLM loses general spatio-temporal knowledge while fine-tuning on specific TDP tasks
- **First 3 experiments:**
  1. TPA Reconstruction Test: Verify autoencoder can encode and decode trajectories with minimal error on held-out set
  2. LoRA Sparsity Sweep: Run ablation on training layers ratio $m$ (10% vs 25% vs 50%) to find efficiency/performance sweet spot
  3. Cross-Client Communication Profile: Measure bandwidth usage with FPO enabled vs disabled to validate efficiency claims

## Open Questions the Paper Calls Out
- The paper states plans to extend FedTDP for more trajectory analysis tasks beyond data preparation in future work.

## Limitations
- Insufficient detail on hyperparameter configurations (learning rates, batch sizes, training rounds, LoRA hyperparameters) makes exact reproduction challenging
- Geographic partitioning logic across clients vaguely described without specifying exact method
- Implementation details for task-specific prompts, road network integration, and weather data are incomplete
- Framework tested on only 6 datasets, which may not capture all failure modes across diverse trajectory domains

## Confidence

- **Privacy Preservation Claims:** High Confidence - Secret-sharing mechanism well-described with clear mathematical formulation and theoretical soundness
- **Performance Improvement Claims:** Medium Confidence - Improvements well-supported by experiments but lack hyperparameter tuning details and ablation studies
- **Generalizability Claims:** Medium Confidence - Strong performance on seen/unseen datasets demonstrated but sample size may not capture all edge cases

## Next Checks

1. **Secret-Sharing Implementation Validation:** Implement pairwise secret-sharing aggregation and verify masked parameter blocks correctly sum to raw aggregation result across different client numbers and parameter block sizes.

2. **Ablation Study on Core Components:** Conduct systematic ablation tests removing each component (TPA, TKE, FPO) individually to quantify independent contributions to performance and reveal synergistic vs additive effects.

3. **Stress Testing on Edge Cases:** Test framework on trajectories with extreme characteristics (high velocity, irregular sampling, long gaps) to identify failure modes not captured in standard datasets and monitor for catastrophic forgetting in sequential multi-task training.