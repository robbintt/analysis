---
ver: rpa2
title: 'SEMU: Singular Value Decomposition for Efficient Machine Unlearning'
arxiv_id: '2502.07587'
source_url: https://arxiv.org/abs/2502.07587
tags:
- unlearning
- semu
- data
- dataset
- forgetting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses machine unlearning (MU) in deep neural networks,
  which aims to remove the influence of specific data points while preserving model
  performance. Existing MU methods are computationally expensive and often require
  the original training dataset.
---

# SEMU: Singular Value Decomposition for Efficient Machine Unlearning

## Quick Facts
- arXiv ID: 2502.07587
- Source URL: https://arxiv.org/abs/2502.07587
- Reference count: 40
- Achieves competitive performance vs state-of-the-art MU methods while modifying <1% of model parameters and eliminating need for remaining dataset.

## Executive Summary
SEMU introduces a parameter-efficient approach to machine unlearning by leveraging SVD to identify and modify only the critical weight subspaces responsible for knowledge to be forgotten. The method projects gradients perpendicular to existing weights before applying truncated SVD, selecting rank based on explained variance threshold. This enables targeted forgetting while preserving retained knowledge and achieving competitive accuracy with minimal parameter changes. SEMU successfully extends to both discriminative (classification) and generative (diffusion) models.

## Method Summary
SEMU computes gradients over the forget dataset using a forgetting loss, then projects these gradients perpendicular to existing weights before applying truncated SVD. The rank is selected via an explained variance threshold γ, and only a low-rank correction matrix R is fine-tuned. The method modifies each layer as A ← A + U_r R_r V_r^T, where R_r is initialized to zero. SEMU can operate without the remaining dataset, though performance improves with even small subsets.

## Key Results
- Alters less than 1% of model weights while maintaining high accuracy on remaining and test sets
- Achieves competitive unlearning accuracy (UA) compared to state-of-the-art methods
- Successfully removes unwanted concepts from generated images in diffusion models
- Works effectively without requiring access to the remaining dataset

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Guided SVD Subspace Identification
- SVD decomposition of forgetting gradients isolates minimal weight subspace for targeted unlearning
- Orthogonal projection matrices from truncated SVD define low-dimensional critical subspace
- Assumes largest gradient directions correspond to weights most responsible for knowledge to forget

### Mechanism 2: Orthogonal Gradient Projection for Weight Preservation
- Projects gradients perpendicular to existing weights to prevent interference with retained knowledge
- Updates occur in directions orthogonal to current representations
- Assumes knowledge to retain is encoded in directions parallel to current weights

### Mechanism 3: Low-Rank Trainable Adapter for Minimal Modification
- Adds trainable low-rank matrix R to each layer for achieving unlearning
- Only R (initialized to zero) is updated during fine-tuning
- Assumes critical subspace identified by SVD is sufficient for unlearning

## Foundational Learning

- **Truncated Singular Value Decomposition**
  - Why needed: Core mechanism for identifying critical weight subspace
  - Quick check: Given a 1000×1000 weight matrix with rapidly decaying singular values, what rank approximation would capture 95% of variance if σ₁²/(Σσᵢ²) = 0.6 and σ₂²/(Σσᵢ²) = 0.25?

- **Explained Variance in PCA/SVD Context**
  - Why needed: Hyperparameter γ controls rank selection via cumulative explained variance
  - Quick check: If γ = 0.90 and singular values are [10, 5, 3, 1, 0.5, ...], what is the minimum rank r that satisfies the threshold?

- **Gradient Ascent/Random Labeling for Unlearning**
  - Why needed: Base unlearning objectives constrained by SVD mechanism
  - Quick check: Why does gradient ascent on forget loss cause forgetting, and what is risk of applying to all weights vs. subset?

## Architecture Onboarding

- **Component map**: Forget Dataset → Forward Pass → Forgetting Loss → Gradient Computation → Perpendicular Projection → SVD → Rank Selection → Low-Rank Correction → Fine-tuning

- **Critical path**:
  1. Accumulate gradients over all forget batches
  2. Apply perpendicular projection before SVD
  3. Select rank via explained variance threshold
  4. Initialize R to zero
  5. Fine-tune using classification or generation loss

- **Design tradeoffs**:
  - Higher γ retains more directions but modifies more parameters
  - SEMU works without remaining dataset but performance improves with even small subsets
  - Cross-attention layers in diffusion models use γ = 1.0 to preserve concept-association capacity

- **Failure signatures**:
  - Low UA with high RA: γ too low, insufficient directions for forgetting
  - High UA with degraded RA/TA: orthogonal projection failing, check gradient preprocessing
  - Training instability: rank varies wildly, normalize singular values or cap minimum rank
  - Generation artifacts: cross-attention layers over-truncated, set γ = 1.0 for these layers

- **First 3 experiments**:
  1. Baseline validation on CIFAR-10 class-wise forgetting with γ = 0.90
  2. Ablation on γ sensitivity with grid search 60-95% on random 10% forgetting
  3. Remaining dataset dependency test with no D_r, 5% D_r, and full D_r on CIFAR-100

## Open Questions the Paper Calls Out

- **Generalization to LLMs and VLMs**: Can SEMU be effectively generalized to large language models and vision-language models given architectural differences and scale compared to CNNs and diffusion models tested? (Future research needed)

- **Constraining updates in task-crucial directions**: How can SEMU be modified to constrain weight updates in directions crucial to downstream tasks without relying on the remaining dataset? (Current method lacks mechanism to preserve task-important features without D_r)

- **Preserving sample quality in generative models**: How can degradation of sample quality in generative models be mitigated when operating in strict remaining dataset-free scenarios? (FID scores may degrade when α and β are set to zero)

## Limitations

- Lacks complete implementation details for critical hyperparameters including learning rates, epochs, and relabeling strategy
- Computational cost analysis focuses on parameter count rather than wall-clock time
- Effectiveness on generative models demonstrated only on limited datasets without specialized generative unlearning comparisons
- Cross-attention layer treatment in diffusion models requires manual γ = 1.0 setting without principled justification

## Confidence

- **High Confidence**: SVD mechanism for identifying critical weight subspaces is well-founded with convergent evidence from related methods; parameter modification claims verified in tables
- **Medium Confidence**: Orthogonal projection mechanism shows theoretical soundness but lacks ablation studies; performance claims need validation on more diverse datasets
- **Low Confidence**: Generative model results lack statistical significance reporting; claims about cross-architecture applicability need more extensive validation

## Next Checks

1. Reproduce CIFAR-10 random 10% forgetting experiment with γ ∈ {0.60, 0.75, 0.90, 0.95} to verify TParams < 1% and UA > 95% performance curve
2. Remove perpendicular projection step and rerun CIFAR-100 50% forgetting to quantify RA degradation
3. Apply SEMU to remove simple concept (e.g., color red) from pretrained GAN on CIFAR-10, measuring FID changes and visual quality