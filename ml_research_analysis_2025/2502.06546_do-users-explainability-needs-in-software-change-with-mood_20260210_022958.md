---
ver: rpa2
title: Do Users' Explainability Needs in Software Change with Mood?
arxiv_id: '2502.06546'
source_url: https://arxiv.org/abs/2502.06546
tags:
- needs
- explanation
- mood
- user
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the relationship between user mood, demographic
  factors, and explanation needs in software systems. Analyzing data from 66 participants,
  the research found limited correlations between these factors and explanation needs.
---

# Do Users' Explainability Needs in Software Change with Mood?

## Quick Facts
- arXiv ID: 2502.06546
- Source URL: https://arxiv.org/abs/2502.06546
- Reference count: 40
- Primary result: Limited correlations between mood/demographic factors and explanation needs; only emotional reactivity and age predict UI explanation needs.

## Executive Summary
This study investigated whether user mood and demographic factors predict explanation needs in software systems. Analyzing survey data from 66 participants, researchers found that only emotional reactivity and age significantly predicted the need for UI explanations. No significant relationships were found between general mood (sentiment) and any explanation needs category, nor between gender and explanation needs. The findings suggest that explanation needs are highly subjective and not reliably predictable based on mood or demographic data alone.

## Method Summary
The study used an online survey with 83 participants, filtered to 66 with complete mood and reactivity responses. Participants completed mood scales (sentiment and reactivity) using 7-point Likert items, provided demographic information, and described their explanation needs which were categorized into five types: Interaction, System behavior, Domain knowledge, Privacy/security, and User interface. Statistical analysis included Pearson correlation for continuous variables and Mann-Whitney U tests for gender, with Bonferroni correction applied to control for multiple hypothesis testing.

## Key Results
- Emotional reactivity positively correlated with the need for UI explanations (r = 0.33, p = 0.007)
- Age negatively correlated with UI explanation needs (r = -0.25, p = 0.044)
- No significant correlations found between general sentiment and any category of explanation needs
- No significant correlations found between gender and any category of explanation needs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Emotional reactivity, not general sentiment, correlates with specific explanation needs (UI).
- Mechanism: Reactivity measures intensity of mood fluctuations (a personality/trait-like dimension). Higher reactivity may lead to greater uncertainty or cognitive friction when facing UI changes, triggering a higher expressed need for UI explanations.
- Core assumption: Users with higher emotional reactivity experience stronger responses to interface ambiguity or change, increasing their desire for explicit guidance.
- Evidence anchors:
  - [abstract] "Emotional reactivity positively correlated with the need for UI explanations"
  - [Section 4.3] "Reactivity and the need for user interface explanations showed a positive correlation at r = 0.33, p = 0.007"
  - [Section 5.1] "Reactivity and the need for explanations related to user interfaces (r = 0.33, p = 0.007)... general sentiment did not show significant correlations"
  - [corpus] Weak/direct support; related works emphasize personalizing explanations by user traits but do not directly confirm reactivity–UI links.
- Break condition: If reactivity is not measured (or proxies are invalid), the correlation may not replicate; if UI complexity is uniform and low, reactivity effects may disappear.

### Mechanism 2
- Claim: Age negatively correlates with UI explanation needs (younger users report higher UI explanation needs).
- Mechanism: Older users may have more stable mental models or lower expectations for UI novelty/intuitiveness, whereas younger users face a broader variety of interfaces and may expect higher design standards, increasing their expressed need for UI guidance.
- Core assumption: Age-related differences in exposure to diverse interfaces and expectations drive this correlation, not inherent ability.
- Evidence anchors:
  - [abstract] "age negatively correlated with UI explanation needs"
  - [Section 4.3] "older participants demonstrated fewer needs for user interface explanations (r = −0.25, p = 0.044)"
  - [Section 5.2] "Younger participants... may have higher expectations regarding intuitive design"
  - [corpus] Indirectly relevant: [44384] and [40763] highlight user-specific needs but do not directly address age.
- Break condition: If software UI is highly standardized or if older adults have high digital literacy, the age effect may attenuate; sample biases (tech-savvy older users) could reduce observed correlation.

### Mechanism 3
- Claim: General sentiment (enduring mood) does not significantly predict explanation needs.
- Mechanism: Stable mood disposition may be too diffuse to impact context-sensitive explanation demands; situational emotional intensity (reactivity) matters more in specific categories like UI.
- Core assumption: Explanation needs are context-dependent and influenced by transient emotional intensity rather than global mood.
- Evidence anchors:
  - [abstract] "No significant correlations were found between general mood (sentiment) and any category of explanation needs"
  - [Section 5.2] "Sentiment did not correlate with any category of explanation needs... situational emotional fluctuations may influence immediate explanation demands"
  - [corpus] [47600] aligns on context-aware explanations, but does not explicitly test sentiment vs explanation needs.
- Break condition: If sentiment is assessed with higher granularity or with affect scales (e.g., PANAS) over shorter time windows, previously undetected links may emerge.

## Foundational Learning

### Concept: Sentiment vs Reactivity
- Why needed here: The paper distinguishes stable mood (sentiment) from intensity of fluctuation (reactivity); only reactivity correlated with UI explanation needs.
- Quick check question: Which mood dimension showed a significant correlation with UI explanation needs?

### Concept: Explanation Needs Taxonomy
- Why needed here: The study uses five categories (Interaction, System behavior, Domain knowledge, Privacy/security, User interface) to segment needs.
- Quick check question: Which explanation need category showed significant correlations with both reactivity and age?

### Concept: Bonferroni Correction
- Why needed here: Multiple hypothesis testing increases false positive risk; Bonferroni correction was applied to control Type I error.
- Quick check question: Why might applying Bonferroni correction lead to missing true relationships in small samples?

## Architecture Onboarding

### Component map
Data collection -> Survey administration -> Mood and demographic data collection -> Explanation needs categorization -> Statistical analysis -> Correlation results

### Critical path
1. Instrument design (mood scale, demographic, open-ended needs)
2. Data cleaning (complete mood responses only; N=66)
3. Categorization of explanation needs (Interaction, Behavior, Domain, Security, Interface)
4. Correlation/Mann–Whitney U analysis with α=0.05 and Bonferroni-adjusted sub-hypotheses
5. Interpretation (significant r = 0.33 and r = -0.25 only for UI)

### Design tradeoffs
- Sample size (N=66) limits power and generalizability; broad hypothesis set (28 null hypotheses) with strict correction increases Type II risk
- Using self-reported mood (Likert) vs clinical measures trades granularity for practicality
- Focus on age/gender excludes other factors (education, technical competence)

### Failure signatures
- Many non-significant results despite theoretical expectations (26/28 null hypotheses not rejected)
- Weak effect sizes (r around 0.25–0.33) and borderline p-values

### First 3 experiments
1. Replication with larger, more diverse sample (N>200) and balanced age/gender to verify UI-reactivity and UI-age links
2. Add multi-dimensional mood measures (e.g., PANAS) and additional demographics (education, domain expertise) to explore other predictors
3. A/B test UI explanation placements on high-reactivity vs low-reactivity users to observe behavioral outcomes (e.g., task completion, subjective satisfaction)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do psychological traits (e.g., openness, conscientiousness) or cognitive styles offer better predictive power for explanation needs than mood or demographics?
- Basis in paper: [explicit] The authors suggest in the Future Work section that expanding personal data to include variables such as "psychological traits and personality characteristics" could help identify underlying factors more influential than mood.
- Why unresolved: The current study was restricted to mood (sentiment/reactivity) and basic demographics, finding limited correlations; it did not assess broader personality inventories.
- What evidence would resolve it: A follow-up study utilizing standard psychological models (e.g., Big Five) to correlate specific traits with the frequency and types of explanation needs.

### Open Question 2
- Question: Are explanation needs culturally dependent, or do specific preferences for explanation types remain consistent across diverse cultural contexts?
- Basis in paper: [explicit] The abstract and Future Work section explicitly call for research to explore "cross-cultural factors" to determine if preferences are culturally specific or universal.
- Why unresolved: The participant pool was sourced via the authors' networks in Germany, limiting the ability to generalize findings across different cultural backgrounds.
- What evidence would resolve it: Replicating the survey methodology with participants from various geographic and cultural regions to perform a comparative analysis of explanation needs.

### Open Question 3
- Question: Can multivariate regression analysis reveal complex relationships between user traits and explanation needs that were undetected by pairwise correlation analysis?
- Basis in paper: [explicit] The authors note in Section 5.3 and 5.4 that correlation analysis is limited to pairwise comparisons and suggest regression analysis as a future method to consider multiple variables simultaneously.
- Why unresolved: The current study relied on Pearson correlation and Mann-Whitney-U tests, which are insufficient for detecting complex interdependencies among multiple variables.
- What evidence would resolve it: A statistical analysis of the existing (or expanded) dataset using regression models to test for interactions between age, mood, and reactivity.

### Open Question 4
- Question: How do software practitioners in industrial settings evaluate the trade-offs between inferring user profiles and actively gathering user-specific explainability requirements?
- Basis in paper: [explicit] The Conclusion states an intent to "validate our findings in industrial settings, by conducting workshops and focus groups with software practitioners."
- Why unresolved: The current paper is a survey-based study focusing on the user perspective; it provides recommendations for industry but lacks empirical data on how developers implement these strategies.
- What evidence would resolve it: Qualitative data from industry workshops or case studies analyzing the cost-benefit of active requirement gathering versus persona-based heuristics.

## Limitations
- Small, homogeneous sample (N=66) limits generalizability of findings
- Modest effect sizes (r=0.33, r=-0.25) may not replicate in larger populations
- Self-reported mood measures and lack of behavioral outcome data are additional constraints

## Confidence
- Correlation between emotional reactivity and UI explanation needs: **Medium**
- Correlation between age and UI explanation needs: **Medium**
- No significant link between general sentiment and any explanation needs: **Medium**

## Next Checks
1. Replicate the study with a larger, demographically diverse sample (N>200) to confirm the reactivity and age effects on UI explanation needs
2. Incorporate additional user traits (e.g., education, technical expertise) and multi-dimensional mood measures (e.g., PANAS) to explore other predictors
3. Conduct an A/B test varying UI explanation placements for high- vs. low-reactivity users to measure behavioral and subjective impacts