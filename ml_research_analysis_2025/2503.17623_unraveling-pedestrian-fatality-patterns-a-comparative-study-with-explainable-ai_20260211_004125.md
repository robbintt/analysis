---
ver: rpa2
title: 'Unraveling Pedestrian Fatality Patterns: A Comparative Study with Explainable
  AI'
arxiv_id: '2503.17623'
source_url: https://arxiv.org/abs/2503.17623
tags:
- pedestrian
- fatalities
- safety
- data
- states
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study uses explainable AI to identify key factors contributing
  to pedestrian fatalities across U.S. states with high and low crash rates (2018-2022).
---

# Unraveling Pedestrian Fatality Patterns: A Comparative Study with Explainable AI

## Quick Facts
- **arXiv ID:** 2503.17623
- **Source URL:** https://arxiv.org/abs/2503.17623
- **Reference count:** 40
- **Primary Result:** XGBoost model achieved 98% balanced accuracy, 90% accuracy, 92% precision, 90% recall, and 91% F1-score in predicting pedestrian fatality contributing factors.

## Executive Summary
This study applies explainable AI techniques to identify key factors contributing to pedestrian fatalities across U.S. states with varying crash rates. Using FARS data from 2018-2022, the research employs machine learning models including Decision Trees, Gradient Boosting Trees, Random Forests, and XGBoost to predict contributing factors. The XGBoost model outperformed alternatives, achieving a balanced accuracy of 98% and demonstrating that age, alcohol and drug use, location, and environmental conditions are significant predictors. The study's use of SHAP (SHapley Additive exPlanations) values provides actionable insights into why specific crashes resulted in fatalities, enabling targeted safety interventions.

## Method Summary
The study utilized FARS (Fatality Analysis Reporting System) data from 2018-2022, filtering for 14 key variables including weather, lighting, age, alcohol and drug use, and location. To address class imbalance between fatal and non-fatal crashes, SMOTENC (Synthetic Minority Over-sampling Technique for Nominal and Continuous features) was applied. The research compared four machine learning models - Decision Tree, Gradient Boosting Trees, Random Forest, and XGBoost - using 80/20 train/test splits with 5-fold cross-validation for hyperparameter tuning. XGBoost with hyperparameters (learning_rate=0.3, max_depth=20, n_estimators=100) emerged as the best performer. SHAP values were computed to interpret model predictions and identify feature importance.

## Key Results
- XGBoost achieved 98% balanced accuracy, significantly outperforming other models in predicting pedestrian crash severity.
- Age emerged as the most impactful predictor, with mid-block locations and poor visibility conditions increasing risk for older adults and substance-impaired individuals.
- SHAP analysis revealed that alcohol and drug use remain strong predictors of fatal outcomes across all age groups.
- The model successfully identified actionable safety factors that can guide targeted interventions like improved lighting and enhanced pedestrian infrastructure.

## Why This Works (Mechanism)

### Mechanism 1: SMOTENC for Class Imbalance
- **Claim:** Synthetic sampling improves detection of minority class outcomes (non-fatal crashes).
- **Mechanism:** SMOTENC generates synthetic examples of non-fatal crashes rather than duplicating existing ones, preventing model bias toward the majority class.
- **Core assumption:** Feature space between fatal and non-fatal crashes is continuous and interpolatable.
- **Evidence anchors:** Abstract mentions SMOTE usage; section 4.2 shows performance improvement from 65.22% misclassification to balanced results.
- **Break condition:** Synthetic data creating unrealistic hybrids that overlap with majority class, reducing generalizability.

### Mechanism 2: XGBoost Gradient Boosting
- **Claim:** Ensemble boosting captures non-linear interactions between environmental and behavioral features better than single trees.
- **Mechanism:** XGBoost sequentially builds trees correcting previous errors, combining "weak learners" with regularization to model complex interactions.
- **Core assumption:** Contributing factors are non-linear and interactive, requiring more than simple additive models.
- **Evidence anchors:** Abstract shows XGBoost outperforming others with 98% balanced accuracy; section 3.2.1 describes regularized objective function.
- **Break condition:** If relationships are actually linear or data is extremely sparse, leading to overfitting.

### Mechanism 3: SHAP for Interpretability
- **Claim:** Post-hoc feature attribution converts "black box" predictions into actionable policy insights.
- **Mechanism:** SHAP calculates each feature's contribution to predictions by comparing model output with and without that feature across all possible coalitions.
- **Core assumption:** Feature importance rankings reflect causal reality rather than just training data correlations.
- **Evidence anchors:** Abstract mentions SHAP values enhance interpretability; section 5.3 shows Age as most impactful predictor.
- **Break condition:** Highly correlated features causing SHAP to distribute importance randomly between them.

## Foundational Learning

- **Concept:** **SMOTENC (Synthetic Minority Over-sampling Technique for Nominal and Continuous)**
  - **Why needed here:** FARS dataset is heavily imbalanced (far more fatal than non-fatal records), requiring synthetic sampling to prevent model bias.
  - **Quick check question:** If you oversample the minority class by simply duplicating rows, how does that affect the decision boundary compared to generating synthetic points?

- **Concept:** **Gradient Boosting vs. Random Forest**
  - **Why needed here:** Understanding that Boosting sequentially corrects errors while Random Forest averages parallel trees explains XGBoost's superior performance.
  - **Quick check question:** Does Gradient Boosting build trees independently (parallel) or dependently (sequential)?

- **Concept:** **SHAP (Shapley Values)**
  - **Why needed here:** The paper's core contribution is "Explainable AI," requiring understanding of local interpretability that aggregates to global importance.
  - **Quick check question:** In a SHAP summary plot, does a red dot indicate a high feature value or a high impact on the prediction?

## Architecture Onboarding

- **Component map:** FARS Dataset (2018-2022) → Filter 14 variables → Handle missing values → SMOTENC (Balance classes) → Train/Test Split → XGBoost (Primary) vs. RF/DT (Baselines) → TreeSHAP (Feature Attributions) → Confusion Matrix + SHAP Beeswarm Plots

- **Critical path:** SMOTENC balancing and XGBoost hyperparameter tuning (`max_depth` and `learning_rate`) are critical. Misconfigured SMOTE generates nonsense rows; excessive depth causes overfitting.

- **Design tradeoffs:**
  - **Interpretability vs. Complexity:** Complex ensemble (XGBoost) requires heavy SHAP computation overhead for interpretability.
  - **Accuracy vs. Recall:** Study prioritizes balanced accuracy (98%) over raw accuracy to correctly identify minority "Non-Fatal" class.

- **Failure signatures:**
  - **High Accuracy, Low Recall:** Model ignoring minority class → Check SMOTE application.
  - **SHAP Inconsistency:** Values change with small data perturbations → Model is unstable or overfitted.
  - **Perfect Training, Poor Test:** Standard overfitting → Reduce `max_depth` or increase regularization (`lambda`).

- **First 3 experiments:**
  1. **Baseline Verification:** Train Decision Tree on raw (imbalanced) data to establish majority class bias baseline (~65% miss rate on negatives).
  2. **Ablation on Sampling:** Train XGBoost on raw vs. SMOTENC data; compare Recall scores to quantify balancing utility.
  3. **Feature Sensitivity:** Remove top SHAP-ranked feature (e.g., "Age" or "Alcohol") and retrain to measure performance degradation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does incorporating socioeconomic status (SES) and related demographic variables alter predictive performance and feature importance rankings?
- **Basis:** Authors state future studies should explore variables like socioeconomic status, noting current study used only 14 specific variables.
- **Why unresolved:** FARS data focuses on crash, vehicle, and environmental factors without broader social determinants.
- **What evidence would resolve it:** Comparative analysis adding SES variables (income levels, education) to observe changes in SHAP rankings and model accuracy.

### Open Question 2
- **Question:** Does expanding geographical scope to include intermediate-rate states and integrating GIS reveal distinct location-specific factors not visible in current top/bottom comparison?
- **Basis:** Conclusion suggests expanding beyond Top and Bottom states and integrating GIS analysis for comprehensive understanding.
- **Why unresolved:** Study only compares five highest and five lowest fatality states, omitting majority of country and relying on coarse location data.
- **What evidence would resolve it:** GIS mapping on national level identifying high-risk zones in "middle-tier" states and comparing feature attributions to current outliers.

### Open Question 3
- **Question:** How do temporal variations in population distribution and road network infrastructure affect stability of identified fatality patterns over time?
- **Basis:** Authors recommend time-stability analyses accounting for temporal variations in population distribution, road networks, and travel behavior.
- **Why unresolved:** Analysis treats factors as static predictors without explicitly modeling how changes in infrastructure or demographics influence fatality rates.
- **What evidence would resolve it:** Longitudinal analysis segmenting data by year to track how feature importance shifts relative to population changes.

### Open Question 4
- **Question:** Can inclusion of additional features better balance dataset to improve model's capability to predict non-fatal crashes?
- **Basis:** Paper notes need for efforts to balance dataset by incorporating additional relevant features to improve prediction of non-fatal crashes.
- **Why unresolved:** Dataset heavily imbalanced (16,352 fatal vs. ~800 non-fatal observations), and while SMOTE used, underlying data sparsity limits prediction utility.
- **What evidence would resolve it:** Experiments augmenting FARS data with non-fatal crash datasets to validate if synthetic oversampling or feature addition yields better generalization.

## Limitations

- **Target Class Definition Ambiguity:** Non-Fatal cases extracted from FARS (fatal crash database) with methodology not explicitly detailed, creating uncertainty about class representativeness.
- **Synthetic Data Generation Parameters:** Specific SMOTENC `k_neighbors` parameter value not reported, critical for synthetic sample quality.
- **Hyperparameter Documentation Errors:** Table 4 lists SVM parameters (Kernel: Linear, Gamma: 1) under XGBoost, raising questions about implementation accuracy.

## Confidence

- **High Confidence:** XGBoost model performance metrics (balanced accuracy, precision, recall, F1-score) - standard, reproducible ML metrics.
- **Medium Confidence:** Feature importance rankings from SHAP - methodology sound but correlations may not equal causation.
- **Low Confidence:** Non-fatal class definition and SMOTENC parameter selection - critical methodological choices lack sufficient documentation.

## Next Checks

1. **Verify Non-Fatal Class Definition:** Reconstruct exact logic used to extract non-fatal cases from FARS data to ensure it represents genuine non-fatal pedestrian crashes.

2. **SMOTENC Parameter Sensitivity:** Systematically vary `k_neighbors` parameter (e.g., 3, 5, 7) and measure impact on model recall and balanced accuracy to determine optimal configuration.

3. **Geographic Generalization Test:** Apply trained XGBoost model to FARS data from states not included in original study (e.g., states with mid-range fatality rates) to assess how well model generalizes beyond specific high/low fatality states.