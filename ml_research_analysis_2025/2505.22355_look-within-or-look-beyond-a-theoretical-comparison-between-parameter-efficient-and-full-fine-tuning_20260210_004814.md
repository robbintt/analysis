---
ver: rpa2
title: Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient
  and Full Fine-Tuning
arxiv_id: '2505.22355'
source_url: https://arxiv.org/abs/2505.22355
tags:
- peft
- fine-tuning
- performance
- language
- lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper compares Parameter-Efficient Fine-Tuning (PEFT) methods
  with Full Fine-Tuning (FFT) in terms of representational capacity and robustness,
  grounded in optimization theory. It proves that PEFT is a strict subset of FFT,
  meaning its limited parameter space inherently constrains its representational ability
  and makes it more susceptible to perturbations.
---

# Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning

## Quick Facts
- arXiv ID: 2505.22355
- Source URL: https://arxiv.org/abs/2505.22355
- Reference count: 40
- The paper proves PEFT is a strict subset of FFT, constraining representational capacity and robustness.

## Executive Summary
This paper provides a rigorous theoretical comparison between Parameter-Efficient Fine-Tuning (PEFT) and Full Fine-Tuning (FFT) methods for adapting large language models. It proves that PEFT methods, which optimize a low-dimensional parameter subspace, are mathematically constrained to be a strict subset of FFT, resulting in lower representational capacity and reduced robustness to input perturbations. Through theoretical bounds and extensive experiments across 15 diverse datasets and 11 adversarial test sets, the paper demonstrates that while PEFT is more resource-efficient, FFT consistently outperforms PEFT on complex tasks and exhibits greater resilience to adversarial attacks.

## Method Summary
The paper establishes a theoretical framework comparing PEFT and FFT by analyzing their optimization spaces and representational capacity. It proves that PEFT methods define a low-dimensional sub-manifold within the full parameter space of FFT through a non-surjective mapping function. The authors derive upper bounds for PEFT's representational capacity and prove that FFT benefits more from additional training data. Theoretical analysis of Hessian matrices demonstrates PEFT's reduced robustness to perturbations. These theoretical findings are validated through experiments on diverse NLP tasks including classification, generation, reasoning, and instruction fine-tuning, alongside adversarial robustness evaluations.

## Key Results
- PEFT is mathematically proven to be a strict subset of FFT, limiting its maximum representational ability.
- FFT achieves significantly greater marginal benefits from additional training data compared to PEFT.
- PEFT exhibits lower robustness to input perturbations and adversarial attacks than FFT.
- On complex tasks like GSM8k reasoning, FFT outperforms PEFT by 7.7% accuracy.
- On adversarial datasets like AdvGLUE, FFT shows 3.2% higher accuracy than PEFT.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PEFT is a strict subset of FFT.
- Mechanism: The optimization space of PEFT is defined as a low-dimensional sub-manifold (measure-zero) within the full high-dimensional parameter space of FFT ($R^d$). The mapping function $g: R^k \to R^d$ is non-surjective, meaning PEFT cannot reach all parameter configurations accessible to FFT. This limited parameter space directly constrains the model's maximum representational ability, as formalized by an upper bound dependent on the fine-tuning parameter count and network depth.
- Core assumption: The mapping function $g$ is non-surjective, which holds true for standard PEFT methods like LoRA (low-rank) or BitFit (sparse), where $k \ll d$.
- Evidence anchors:
  - [abstract] "We theoretically demonstrate that PEFT is a strict subset of FFT."
  - [section 3, Theorem 1] "f(x; θ0; Φ) = f(x; θΦ) ⇒ f(x; θ0; Φ) ⊂ F full. That is to say, ∀Φ ∈ Rk, ∃θΦ ∈ Rd such that f(x; θ0; Φ) = f(x; θΦ) ⊂ F full"
  - [corpus] Implicitly supported by the field's definition of PEFT. No direct corpus paper contradicts this theoretical relationship.
- Break condition: If the PEFT method uses a surjective mapping (e.g., a full-rank reparameterization that can span $R^d$), it would no longer be a strict subset and this bound would not apply.

### Mechanism 2
- Claim: PEFT has a lower capacity to benefit from additional training data compared to FFT.
- Mechanism: The expected risk decomposition shows that the improvement from an additional sample is proportional to the parameter dimension ($O(d/N^{-3/2})$ for FFT vs. $O(k/N^{-3/2})$ for PEFT). Because PEFT operates in a restricted subspace ($k \ll d$), its risk reduction from new data is significantly smaller (by a factor of roughly $k/d$). Once the low-dimensional PEFT subspace is saturated with learned features, it has no remaining capacity to accommodate new information.
- Core assumption: The empirical optimality achievement error ($L_N(\hat{\theta}_N) - L^*_H$) is near zero, meaning the model has trained sufficiently.
- Evidence anchors:
  - [abstract] "FFT's marginal benefit from additional data... is significantly greater than PEFT's."
  - [section 3, Theorem 5] "for each additional sample, the risk reduction achieved by PEFT is k/d times that of FFT, which is significantly smaller."
  - [corpus] The paper "GraLoRA" [arXiv:2505.20355] notes LoRA suffers from overfitting when its "bottleneck is widened," which aligns with the idea of a saturated subspace.
- Break condition: If the fine-tuning task requires very little new knowledge, PEFT may reach its saturation point with minimal data, after which extra data provides diminishing returns.

### Mechanism 3
- Claim: PEFT is less robust to input perturbations and adversarial attacks than FFT.
- Mechanism: Theoretical analysis using Hessian matrices shows that PEFT's loss fluctuation under perturbation ($\Delta L_{peft}$) is greater than FFT's ($\Delta L_{full}$). This is because PEFT can only counteract the perturbation component within its low-dimensional subspace ($\epsilon_{\parallel}$) and is helpless against the orthogonal component ($\epsilon_{\perp}$). FFT, with its full-rank Hessian, can mitigate perturbations in any direction.
- Core assumption: The perturbation $\epsilon$ has components both within and orthogonal to the PEFT subspace.
- Evidence anchors:
  - [abstract] "...making it more susceptible to perturbations."
  - [section 3, Theorem 4] "$\Delta L_{peft} - \Delta L_{full} > 0$"
  - [corpus] The paper "Artificial Entanglement in the Fine-Tuning of Large Language Models" [arXiv:2601.06788] explores robustness from a quantum-inspired perspective, indicating it's an active area of research. No corpus paper directly contradicts the claim.
- Break condition: If the perturbation is entirely within the PEFT subspace, its impact could theoretically be mitigated, potentially matching FFT.

## Foundational Learning

- Concept: **Low-Rank Adaptation (LoRA)**
  - Why needed here: It is the most prominent example of the reparametrization-based PEFT methods analyzed. Understanding its mechanism (freezing base weights and learning low-rank matrices) is crucial to grasping how PEFT becomes a strict subset of FFT.
  - Quick check question: How does LoRA's low-rank constraint limit the possible weight updates compared to full fine-tuning?

- Concept: **Empirical Risk Minimization (ERM) and Rademacher Complexity**
  - Why needed here: These are the theoretical tools used in Theorem 5 to derive the generalization error and prove FFT has a higher marginal benefit from data. Grasping the decomposition of expected risk is key to understanding the paper's core proof.
  - Quick check question: How does the complexity of the hypothesis space, as measured by Rademacher complexity, influence the generalization error?

- Concept: **Adversarial Robustness and the Sharpness-Flatness Theory**
  - Why needed here: This provides the theoretical lens for analyzing why PEFT is less robust. The sharpness of the loss landscape and the Hessian analysis directly explain the vulnerability to perturbations.
  - Quick check question: How might a "sharper" incremental weight distribution make a model more sensitive to small input perturbations?

## Architecture Onboarding

- Component map:
  1. **FFT (Full Fine-Tuning):** The full model parameter space $\Theta \in R^d$. The optimizer updates any parameter in any direction.
  2. **PEFT (e.g., LoRA, BitFit):** A constrained parameter space represented by a low-dimensional manifold $\Phi \in R^k \subset \Theta$. The optimizer updates only these parameters, which are then mapped to the full space via a non-surjective function $g(\Phi)$.
  3. **Comparison Framework:** A theoretical layer proving the subset relationship and deriving bounds. An experimental layer validating performance and robustness across 15+ datasets.

- Critical path:
  1. **Theoretical Foundation:** Establish the non-surjective mapping $g$ (Theorem 1).
  2. **Derive Bounds:** Prove the capacity upper bound (Theorem 2) and data scaling limit (Theorem 5).
  3. **Analyze Robustness:** Apply Hessian-based perturbation analysis (Theorem 4).
  4. **Empirical Validation:** Run experiments on diverse tasks (classification, generation, reasoning) and adversarial datasets (AdvGLUE, Adversarial SQuAD).

- Design tradeoffs:
  - **Resource Efficiency vs. Representational Capacity:** PEFT saves compute but has a lower performance ceiling, especially on complex tasks or with large data volumes.
  - **Fast Adaptation vs. Robustness:** PEFT adapts quickly on small data, but resulting models are more brittle to input perturbations.

- Failure signatures:
  - **Performance Plateau:** As training data increases, PEFT performance stagnates while FFT continues to improve significantly.
  - **Adversarial Collapse:** A PEFT model that performs well on clean data fails catastrophically on adversarial datasets, while FFT degrades more gracefully.
  - **Limited Knowledge Acquisition:** On tasks requiring complex new knowledge (e.g., GSM8k), PEFT fails to close the gap with FFT.

- First 3 experiments:
  1. **Data Scaling Comparison:** Fine-tune a base model (e.g., LLaMA2-7B) on a reasoning task (e.g., GSM8k) using both FFT and a PEFT method (LoRA). Vary the training set size (e.g., from 100 to 50,000 samples) and plot performance. Hypothesis: FFT's performance curve will have a steeper positive slope as data increases.
  2. **Robustness Evaluation:** Take models fine-tuned on a standard dataset (e.g., GLUE) and evaluate them on a corresponding adversarial dataset (e.g., AdvGLUE). Compare the performance drop. Hypothesis: The PEFT model will show a larger performance degradation.
  3. **Parameter Sensitivity Analysis:** Analyze the distribution of the incremental weights ($\Delta W$) for a PEFT model (e.g., LoRA) and an FFT model after fine-tuning on the same task. Compute the standard deviation. Hypothesis: The PEFT distribution will be steeper and more sharply peaked, as shown in Figure 1.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can hybrid Parameter-Efficient Fine-Tuning (PEFT) approaches effectively bridge the performance and robustness gap compared to Full Fine-Tuning (FFT)?
- Basis in paper: [explicit] The authors explicitly state in the limitations (Appendix E) that they "focus solely on a single PEFT method and do not extend our investigation to hybrid PEFT approaches."
- Why unresolved: The paper establishes that single PEFT methods are strict subsets of FFT with limited capacity. It remains unclear if combining methods (e.g., LoRA + Prefix) can approximate the full parameter space sufficiently to recover the marginal benefits of data and parameters observed in FFT.
- What evidence would resolve it: Experiments evaluating hybrid PEFT configurations on the complex tasks and adversarial benchmarks detailed in the paper, specifically measuring if they break the theoretical upper bounds derived for single PEFT methods.

### Open Question 2
- Question: How can "task complexity" be formally defined to predict the crossover point where PEFT becomes strictly inferior to FFT?
- Basis in paper: [explicit] Appendix E notes, "We do not provide a strict definition of task complexity, we empirically observe that tasks such as reasoning are generally more complex."
- Why unresolved: While the paper proves PEFT has an upper bound on capacity, the link between specific task attributes and the required representational capacity is currently empirical. Without a formal definition, it is difficult to predict a priori which fine-tuning method is appropriate for a novel task.
- What evidence would resolve it: A theoretical framework connecting task complexity metrics to the PEFT capacity upper bound (Theorem 2), validated by predicting the performance cliffs on datasets beyond those used in the study.

### Open Question 3
- Question: Is PEFT more or less vulnerable to training-phase attacks (e.g., gradient-based poisoning) compared to FFT?
- Basis in paper: [explicit] The authors state their robustness evaluation "is limited to the model's reasoning performance, without accounting for training-phase attack methods such as gradient-based attacks" (Appendix E).
- Why unresolved: While PEFT is proven to be more sensitive to inference-time perturbations due to steeper loss landscapes, its restricted parameter subspace might theoretically offer a form of regularization against data poisoning or gradient manipulation during training.
- What evidence would resolve it: Comparative experiments applying gradient-based poisoning or backdoor attacks during the fine-tuning process to measure the relative susceptibility of PEFT versus FFT.

## Limitations

- The theoretical bounds may not generalize to all PEFT variants, especially those with different reparameterization strategies.
- The robustness analysis focuses on inference-time perturbations but does not explore training-phase attacks like gradient-based poisoning.
- The paper primarily validates claims on specific PEFT methods (primarily LoRA) and a limited set of base models, potentially limiting generalizability.

## Confidence

- **High confidence**: The core subset relationship between PEFT and FFT and the derived mathematical bounds are proven theorems with provided proofs.
- **Medium confidence**: The empirical validation of these bounds across diverse tasks is sound but could be affected by confounding variables in the 15+ datasets.
- **Medium confidence**: The Hessian-based robustness analysis is theoretically sound, but the practical quantification of vulnerability gaps requires further investigation.

## Next Checks

1. **Generalization Across PEFT Methods:** Validate the core theoretical claims on a broader set of PEFT methods (e.g., BitFit, PrefixTuning, P-Tuning) to ensure the bounds are not method-specific.
2. **Controlled Perturbation Analysis:** Design a synthetic adversarial attack with a known perturbation distribution to quantify the exact contribution of the $\epsilon_{\perp}$ component to PEFT's vulnerability.
3. **Cross-Model Validation:** Repeat the experiments on a wider range of base models (e.g., OPT, BLOOM) to confirm that the performance and robustness trends are not model-dependent.