---
ver: rpa2
title: 'Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century
  Spanish'
arxiv_id: '2503.22585'
source_url: https://arxiv.org/abs/2503.22585
tags:
- irony
- dataset
- classification
- historical
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish

## Quick Facts
- arXiv ID: 2503.22585
- Source URL: https://arxiv.org/abs/2503.22585
- Authors: Kevin Cohen; Laura Manrique-Gómez; Rubén Manrique
- Reference count: 26
- Key outcome: BERT-based contextual embeddings with human-verified semi-automated annotation achieved 0.71 binary F1 for irony detection in 19th-century Spanish

## Executive Summary
This study tackles the challenge of detecting irony in 19th-century Latin American Spanish newspaper texts using modern language models. The researchers found that while large language models struggle with historical irony detection due to cultural bias and lack of contextual knowledge, a hybrid approach combining BERT-based contextual embeddings with semi-automated annotation and human verification significantly improves performance. The work addresses the critical problem of class imbalance in irony detection, where ironic texts comprise only 10.68% of the dataset, and demonstrates that domain-specific fine-tuning on historical language can overcome the limitations of contemporary model training.

## Method Summary
The methodology combines BERT-based contextual embeddings with semi-automated annotation. The team used a Spanish BERT encoder (dccuchile/bert-base-spanish-wwm-cased) with a feed-forward neural network classifier (768 → 50 → output_dim) to capture contextual relationships in 19th-century Spanish. GPT-4o was employed to generate initial labels with justifications, which human experts then verified and corrected, effectively addressing class imbalance by increasing ironic examples from 10.68% to 22.40%. The approach was tested on the LatamXIX Dataset (2,734 human-annotated entries, expanded to 3,750 through augmentation), achieving binary F1 of 0.71 for irony detection.

## Key Results
- Semi-automated annotation with human verification improved irony class recall from 0.34 to 0.70
- BERT-based pipeline achieved 0.71 binary F1 for irony detection on augmented dataset
- Text enhancement via emotional expansion showed limited impact due to cultural bias in modern LLMs
- GPT-4o struggled with historical irony detection (0.39 multi-class accuracy) due to lack of historical context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semi-automated annotation with human verification improves irony detection recall by addressing class imbalance.
- Mechanism: GPT-4o generates initial labels with justifications; human experts verify and correct, reducing annotation cost while maintaining quality. This increases training examples for the underrepresented "IRONY" class (from 10.68% to 22.40%).
- Core assumption: GPT-4o's false positives on irony are more acceptable than false negatives for augmentation purposes, since humans filter errors.
- Evidence anchors:
  - [abstract] "semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations"
  - [section 5.3, Table 9] Binary F1 for IRONY improved from 0.48 (baseline) to 0.71 (augmented); recall improved from 0.34 to 0.70
  - [corpus] CAF-I (arXiv:2506.08430) similarly uses multi-agent LLM collaboration for irony detection, suggesting human-LLM collaboration is an emerging pattern
- Break condition: If GPT-4o systematically misses certain irony types (e.g., cultural-specific), human verification cannot recover examples never proposed.

### Mechanism 2
- Claim: BERT-based contextual embeddings capture historical Spanish linguistic patterns better than prompt-based GPT-4o classification.
- Mechanism: BERT encoder produces 768-dimensional contextual vectors that capture syntactic and semantic relationships; these are fed to a feed-forward classifier fine-tuned on domain data.
- Core assumption: The pre-training distribution of Spanish BERT models sufficiently overlaps with 19th-century Spanish for transfer learning to be effective.
- Evidence anchors:
  - [section 4.3] Architecture uses "BERT encoder with a feedforward neural network head" with 768-dim input, 768x50 hidden layer, ReLU activation
  - [section 5.1, Table 4] BERT pipeline achieved 0.66 accuracy vs. GPT-4o prompt's 0.39 for multi-class
  - [corpus] Weak direct corpus support for historical language transfer specifically; related work focuses on contemporary irony detection
- Break condition: If semantic drift between 19th-century and modern Spanish is too large, embeddings may misrepresent historical meanings.

### Mechanism 3
- Claim: Text enhancement via emotional expansion shows limited impact on historical irony detection.
- Mechanism: GPT-4o expands original texts to emphasize emotional content while preserving meaning; enhanced text is then classified. The approach fails because emotional intensity alone does not capture historical-cultural irony signals.
- Core assumption: GPT-4o's modern training data biases it toward contemporary irony patterns (e.g., excessive praise as sarcasm), mismatching 19th-century norms.
- Evidence anchors:
  - [abstract] "dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis"
  - [section 6] "GPT-4o struggled to identify irony... primarily due to a lack of historical context" and shows "cultural bias embedded in commercial models"
  - [corpus] Lin et al. (2024, cited in paper) found emotion-centric enhancement effective for modern benchmarks—but this did not transfer to historical texts
- Break condition: Enhancement strategies may work when cultural context matches the model's training distribution.

## Foundational Learning

- Concept: **Transfer learning for historical language**
  - Why needed here: 19th-century Spanish differs lexically and culturally from modern Spanish; models need domain adaptation.
  - Quick check question: Can you explain why a model trained on contemporary text might misclassify "poetic praise" in 1890s newspapers as ironic?

- Concept: **Class imbalance in classification**
  - Why needed here: Irony was only 10.68% of the original dataset; models default to majority classes.
  - Quick check question: If accuracy is 91% but the minority class has 0.34 recall, is the model useful for detecting that class?

- Concept: **Human-in-the-loop annotation**
  - Why needed here: LLMs hallucinate and misapply modern cultural norms; expert verification corrects systematic biases.
  - Quick check question: What verification step would you add if GPT-4o labeled 73.6% of texts as ironic but experts found only 53.1%?

## Architecture Onboarding

- Component map:
  Raw historical Spanish text → BERT Encoder (dccuchile/bert-base-spanish-wwm-cased) → 768-dim contextual embeddings → Feed-Forward Classifier (768→50→output_dim) → Classification output

- Critical path:
  1. Start with PRIMARY dataset (2,734 human-annotated entries)
  2. Fine-tune BERT encoder + classifier
  3. Use GPT-4o + tailored prompt to propose labels for new data
  4. Human experts verify GPT-4o labels → AUGMENTED dataset (3,750 entries)
  5. Retrain on augmented data

- Design tradeoffs:
  - Binary vs. multi-class: Binary achieves higher accuracy (~0.88) but loses sentiment granularity; multi-class retains sentiment but lowers IRONY F1 (~0.68)
  - Enhancement vs. augmentation: Enhancement is automated but ineffective; augmentation requires human effort but improves recall significantly
  - Model selection: beto-cased-finetuned-xix-latam is domain-specific but cased/uncased Spanish BERT models performed comparably

- Failure signatures:
  - Low IRONY recall (0.09-0.34) with high NOT IRONY accuracy → class imbalance not addressed
  - GPT-4o labels 0% as POSITIVE → model cannot detect historical positive sentiment expressions
  - 1.7% "unreadable" entries → OCR quality issues cause hallucinations

- First 3 experiments:
  1. Replicate baseline: Train BERT-based pipeline on PRIMARY dataset; verify IRONY F1 ≈ 0.48 (binary)
  2. Test augmentation: Apply semi-automated annotation to add 1,000 entries; retrain; target IRONY F1 ≥ 0.65
  3. Ablate enhancement: Train on ENHANCED dataset; confirm no significant improvement over baseline (validates paper's finding)

## Open Questions the Paper Calls Out

- **Question:** Can open-source or smaller language models achieve comparable performance to GPT-4o in the semi-automated annotation of historical texts while reducing cost and latency?
  - **Basis in paper:** [explicit] The authors identify in the Limitations section that the "reliance on GPT-4o... is costly and restricts scalability," explicitly calling for future research to explore "alternative models" that are more accessible.
  - **Why unresolved:** The study exclusively utilized GPT-4o for the dataset enhancement and augmentation phases, leaving the efficacy and cost-benefit analysis of other models (e.g., Llama, Mistral) for this specific historical annotation task untested.
  - **What evidence would resolve it:** A comparative study evaluating the annotation quality, speed, and operational cost of open-source models against the GPT-4o baseline using the same historical dataset and prompts.

- **Question:** Does Retrieval-Augmented Generation (RAG) or explicit integration of external historical knowledge improve the efficacy of text enhancement strategies for irony detection?
  - **Basis in paper:** [inferred] The authors note that dataset enhancements showed "limited impact" and that GPT-4o struggled due to "cultural bias" and a lack of specific historical context (e.g., the Porfiriato example). This implies the model's parametric knowledge is insufficient for historical nuance.
  - **Why unresolved:** The enhancement strategy relied on the model's internal weights to generate emotional context without providing external historical data, resulting in hallucinations or misinterpretations of historical political critiques.
  - **What evidence would resolve it:** An experiment where the enhancement pipeline is augmented with a retrieval mechanism accessing 19th-century historical records, comparing the resulting irony detection F1 scores against the non-enhanced baseline.

- **Question:** To what extent can agent-based workflows automate the "human verification" step currently required to distinguish historical irony from poetic language or political critique?
  - **Basis in paper:** [explicit] The paper concludes that future research should focus on "developing increasingly automated architectures, including agent-based workflows that systematically incorporate historical context," moving beyond the current semi-automated approach.
  - **Why unresolved:** The current methodology relies heavily on human experts to correct GPT-4o's tendency to misclassify "political opinions" and "poetic language" as irony, a bottleneck the authors wish to reduce.
  - **What evidence would resolve it:** A proposal and evaluation of a multi-agent system where one agent retrieves historical context and another critiques the classification before final labeling, measuring the reduction in human intervention rate.

## Limitations

- **Training configuration gaps**: Critical hyperparameters (learning rate, batch size, optimizer settings, random seeds, and early stopping patience) were not specified, preventing exact replication of reported results.
- **Cultural context transfer limitations**: Modern LLMs struggle with historical language nuances and cultural contexts, revealing fundamental limitations in parametric knowledge for 19th-century Spanish.
- **Generalizability constraints**: The methodology was validated only on Latin American Spanish texts from the 19th century, limiting transferability to other historical languages or time periods.

## Confidence

**High Confidence**:
- BERT-based contextual embeddings with fine-tuning outperform prompt-based GPT-4o classification for irony detection in historical Spanish
- Semi-automated annotation with human verification significantly improves IRONY class recall (0.34 → 0.70) and F1 (0.48 → 0.71) by addressing class imbalance
- Text enhancement via emotional expansion shows limited impact on historical irony detection due to cultural bias in modern LLMs

**Medium Confidence**:
- The specific dccuchile/bert-base-spanish-wwm-cased model performs best among tested Spanish BERT variants
- 1,500 epochs with early stopping provides sufficient training capacity
- The 22.4% IRONY class proportion in the augmented dataset represents optimal balance for training

**Low Confidence**:
- Exact hyperparameter values and training procedures that led to the reported results
- Generalization of findings to other historical languages or time periods
- Long-term stability and reproducibility of the semi-automated annotation pipeline

## Next Checks

1. **Hyperparameter sensitivity analysis**: Replicate the BERT-based pipeline with systematic variation of learning rate (1e-5, 2e-5, 3e-5), batch size (8, 16, 32), and early stopping patience (3, 5, 10 epochs) to determine optimal configurations and quantify performance variance.

2. **Cross-validation of semi-automated annotation**: Apply the GPT-4o + human verification pipeline to a new subset of 500 unlabeled texts from the same corpus. Compare inter-annotator agreement rates and class distribution shifts to validate reproducibility of the augmentation approach.

3. **Domain adaptation comparison**: Train the same BERT-based pipeline on the augmented dataset but evaluate on a held-out contemporary Spanish irony dataset. Measure performance degradation to quantify the specific challenge of historical language adaptation versus general irony detection.