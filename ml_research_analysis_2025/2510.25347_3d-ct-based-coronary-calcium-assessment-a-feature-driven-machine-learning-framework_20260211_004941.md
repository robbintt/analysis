---
ver: rpa2
title: '3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning
  Framework'
arxiv_id: '2510.25347'
source_url: https://arxiv.org/abs/2510.25347
tags:
- features
- coronary
- non-contrast
- calcium
- artery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops and evaluates radiomics-based and deep learning
  approaches for classifying coronary artery calcium (CAC) scores using non-contrast
  CCTA scans. The primary focus is categorizing patients into zero versus non-zero
  calcium score groups.
---

# 3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework

## Quick Facts
- arXiv ID: 2510.25347
- Source URL: https://arxiv.org/abs/2510.25347
- Authors: Ayman Abaid; Gianpiero Guidone; Sara Alsubai; Foziyah Alquahtani; Talha Iqbal; Ruth Sharif; Hesham Elzomor; Emiliano Bianchini; Naeif Almagal; Michael G. Madden; Faisal Sharif; Ihsan Ullah
- Reference count: 27
- One-line primary result: Radiomics-based models achieve 84% accuracy for binary CAC classification using pseudo-labels, outperforming foundation models (63-74%)

## Executive Summary
This study develops a radiomics-based pipeline for classifying coronary artery calcium (CAC) scores using non-contrast CCTA scans, achieving 84% accuracy in distinguishing zero from non-zero calcium scores. The framework leverages TotalSegmentator for pseudo-labeling coronary artery regions, eliminating the need for expert segmentations while extracting 36 radiomics features from 112 initial descriptors. When compared to foundation models (CT-FM and RadImageNet), the radiomics approach demonstrates significantly superior performance, highlighting the continued relevance of handcrafted features for specialized medical imaging tasks with limited annotations.

## Method Summary
The study uses 182 CCTA scans (94 zero-score, 88 non-zero) to train and evaluate a binary CAC classification framework. TotalSegmentator automatically segments coronary arteries to create pseudo-segmentation masks, which are then processed by PyRadiomics to extract 112 features including shape, first-order statistics, and texture matrices (GLCM, GLRLM, GLSZM, NGTDM). Correlation filtering reduces these to 36 features, which are classified using tree-based ensembles (Random Forest, XGBoost, LightGBM) with 5-fold cross-validation. For comparison, frozen foundation models (CT-FM with 512 embeddings, RadImageNet with slice-wise averaging) are also evaluated using the same classifiers.

## Key Results
- Radiomics-based Random Forest achieves 84% accuracy, 95% sensitivity, and 72% specificity for zero vs. non-zero CAC classification
- Foundation models (CT-FM, RadImageNet) significantly underperform with 63-74% accuracy compared to radiomics
- Five-fold cross-validation with hyperparameter grid search confirms Random Forest as the best-performing classifier
- No statistically significant performance difference between models trained on mixed contrast/non-contrast data versus non-contrast only

## Why This Works (Mechanism)

### Mechanism 1: Pseudo-labeling via TotalSegmentator for ROI Definition
Automated segmentation using TotalSegmentator can replace expert-defined segmentations for coronary artery region-of-interest extraction in calcium scoring tasks. TotalSegmentator generates anatomically-relevant pseudo-segmentations of coronary artery regions that serve as masks for radiomics feature extraction, filtering background noise while preserving calcification-bearing tissue. This enables feature extraction without manual annotation overhead.

Core assumption: The coronary artery regions identified by TotalSegmentator sufficiently overlap with clinically-relevant calcium-bearing regions, even though TotalSegmentator was not trained specifically for calcium detection.

Evidence anchors:
- [abstract]: "propose a radiomics-based pipeline that leverages pseudo-labeling to generate training labels, thereby eliminating the need for expert-defined segmentations"
- [section 3.1]: "This tool automatically segments major anatomical structures from full-body CT scans, including the left and right coronary arteries, without requiring human-annotated training data... enables us to focus on anatomically relevant areas while avoiding noisy background information"
- [corpus]: Neighboring paper 12003 ("Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation") supports anatomical segmentation as an active research direction, though pseudo-labeling specifically lacks direct corpus validation

Break condition: If TotalSegmentator's coronary segmentations have low spatial overlap with actual calcium deposits (e.g., severe calcification distorts anatomy), pseudo-labeling will fail to capture discriminative features.

### Mechanism 2: Radiomics Feature Discrimination Superiority
Hand-crafted radiomics features capture texture and intensity patterns more discriminative for calcium scoring than learned deep learning embeddings from foundation models. Radiomics features explicitly quantify calcification-relevant properties—intensity distributions, tissue heterogeneity via texture matrices (GLCM, GLRLM, GLSZM), and edge characteristics—that directly encode the physical signatures of calcium deposits in non-contrast CT.

Core assumption: Calcium deposits produce distinctive texture and intensity patterns better captured by explicit quantitative descriptors than implicit representations learned by general-purpose foundation models trained on diverse CT tasks.

Evidence anchors:
- [abstract]: "Results show that radiomics-based models significantly outperform CNN-derived embeddings from foundation models (achieving 84% accuracy and p<0.05)"
- [section 4.2]: "Paired t-tests revealed statistically significant differences in both the combined contrast and non-contrast dataset (accuracy: p=0.033; F1-score: p=0.017)"
- [section 5]: "Radiomics features capture well-defined quantitative descriptors of image texture and intensity, contributing to their strong performance, reproducibility, and interpretability"
- [corpus]: No direct corpus comparison exists for radiomics vs. foundation models in CAC scoring; this represents a novel contribution requiring external validation

Break condition: If calcium appearance varies significantly across scanner manufacturers, reconstruction kernels, or patient populations in ways not captured by standard radiomics features, performance will degrade on out-of-distribution data.

### Mechanism 3: Tree-Based Ensemble Learning on Limited Data
Tree-based ensemble classifiers (Random Forest, XGBoost, LightGBM) effectively learn decision boundaries for binary calcium classification from high-dimensional radiomics features with small training samples (n=182). Ensemble tree methods handle feature correlations and non-linear relationships through iterative feature splitting and weak learner aggregation, providing robustness against overfitting on small datasets while maintaining interpretability via feature importance rankings.

Core assumption: The zero vs. non-zero calcium decision boundary is approximable by piecewise-linear splits in the 36-dimensional radiomics feature space, and 182 patients provide sufficient diversity for generalization.

Evidence anchors:
- [section 4.2]: "Random Forest achieving the highest accuracy of 84%, sensitivity of 95%, and specificity of 72%. XGBoost and LightGBM also performed well with accuracies of 81% and 78%, respectively"
- [section 3.2]: "Five-fold cross-validation was employed to determine the optimal hyperparameters... Model performance was comprehensively evaluated using multiple metrics"
- [corpus]: Limited corpus evidence for classifier comparison in CAC scoring specifically

Break condition: If test-time data distribution differs substantially from training (different scanner protocols, demographic shifts), tree-based models will fail to generalize without retraining.

## Foundational Learning

- **Concept: Radiomics texture feature families (GLCM, GLRLM, GLSZM, NGTDM)**
  - Why needed here: Understanding what each texture matrix quantifies (spatial co-occurrence, run lengths, zone sizes) is essential for debugging feature quality, interpreting model decisions, and designing feature selection strategies.
  - Quick check question: Can you explain what a Gray-Level Co-occurrence Matrix (GLCM) captures and why heterogeneous calcified plaques might produce distinctive GLCM patterns compared to uniform soft tissue?

- **Concept: Weakly supervised learning via pseudo-labels**
  - Why needed here: The pipeline depends on TotalSegmentator outputs as proxy ground truth; recognizing failure modes of weak supervision helps assess reliability and identify when manual annotation becomes necessary.
  - Quick check question: What systematic errors might arise if pseudo-segmentations consistently miss distal coronary segments where early calcification occurs?

- **Concept: Foundation model domain transfer in medical imaging**
  - Why needed here: The study demonstrates that CT-FM and RadImageNet embeddings underperform radiomics (63-74% vs. 84% accuracy); understanding transfer failure modes informs whether to invest in fine-tuning or abandon foundation model approaches.
  - Quick check question: Why might a foundation model pretrained on 146,000 CT scans (CT-FM) fail to transfer to coronary calcium detection despite pretraining scale?

## Architecture Onboarding

- **Component map**:
  DICOM Scans → NIfTI Conversion → TotalSegmentator → Coronary ROI Masks → PyRadiomics (112 features → Correlation Filter → 36 features) → Random Forest/XGBoost/LightGBM (5-fold CV) → Binary Output: CAC=0 vs CAC>0

  Alternative (DL Path):
  NIfTI → CT-FM (512 embeddings) OR RadImageNet (slice-wise average) → Classifiers

- **Critical path**: TotalSegmentator pseudo-segmentation → PyRadiomics extraction → Correlation-based feature reduction → Random Forest classifier. Segmentation errors propagate directly to all downstream features.

- **Design tradeoffs**:
  - Radiomics vs. DL embeddings: Radiomics provides interpretability and 84% accuracy with 36 explicit features; DL embeddings underperform (63-74%) but promise scalability if fine-tuned.
  - Binary vs. multi-class: Current zero/non-zero classification enables 182-patient training; multi-class Agatston stratification (0/1-10/11-100/101-400/>400) would require substantially more data.
  - Mixed vs. non-contrast-only training: Table 2 shows minimal difference (84% either way), suggesting contrast-specific features add limited value for non-contrast inference.

- **Failure signatures**:
  - Sensitivity <70%: Pseudo-segmentations missing coronary regions containing calcium; investigate ROI dilation or alternative segmenters.
  - Specificity <60%: Non-calcium high-intensity structures (stents, implants) captured in ROI; add intensity thresholding post-processing.
  - CT-FM/RadImageNet accuracy <65%: Domain gap between pretraining data and clinical CCTA; requires supervised fine-tuning or domain adaptation.
  - Volumes excluded (n=181 vs n=188): TotalSegmentator failed to detect coronary arteries; monitor exclusion rate as quality signal.

- **First 3 experiments**:
  1. **Pseudo-segmentation validation**: Manually annotate coronary ROIs on 20 randomly selected scans; compute Dice coefficient between expert annotations and TotalSegmentator outputs. If Dice < 0.6, evaluate ROI dilation or alternative segmentation tools.
  2. **Feature family ablation**: Train separate Random Forest models on each feature category (shape-only, first-order-only, GLCM-only, etc.) to identify which texture families drive classification. Report per-family feature importance.
  3. **Foundation model fine-tuning probe**: Implement supervised fine-tuning of CT-FM's final layers on the 182-patient training set with 5-fold cross-validation. Compare against frozen-encoder baseline to quantify potential gains from domain adaptation.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the integration of clinical report text via multimodal fusion techniques improve classification accuracy?
  - Basis in paper: [explicit] The authors state, "we plan to incorporate clinical report text using multimodal fusion techniques" for future work.
  - Why unresolved: The current study relied exclusively on imaging features, ignoring potentially complementary textual data.
  - What evidence would resolve it: Experiments comparing the performance of image-only models against fused text-image architectures.

- **Open Question 2**: Is the proposed framework effective for multi-class calcium scoring rather than just binary classification?
  - Basis in paper: [explicit] The authors explicitly aim to "explore multi-class calcium scoring (e.g., 0, 1–10, 11–100, etc.)" in future studies.
  - Why unresolved: Clinical risk stratification requires granular scoring, but this study only evaluated zero versus non-zero groups.
  - What evidence would resolve it: Validation of the pipeline on datasets with labeled Agatston score ranges showing high per-class accuracy.

- **Open Question 3**: Can fine-tuning foundation models (CT-FM, RadImageNet) close the performance gap with radiomics-based approaches?
  - Basis in paper: [inferred] The authors note that deep features "could benefit from fine-tuning" after observing they significantly underperformed compared to radiomics.
  - Why unresolved: This study used frozen pre-trained weights, potentially limiting the models' task-specific sensitivity for CAC detection.
  - What evidence would resolve it: Comparative analysis of frozen versus fine-tuned foundation models on the same CAC classification task.

## Limitations
- Absence of expert-annotated calcium segmentations for validation, relying entirely on TotalSegmentator pseudo-labels
- 182-patient dataset provides limited generalizability testing across scanner manufacturers and protocols
- Foundation model comparisons lack ablation studies explaining architectural vs. fine-tuning limitations

## Confidence
- **High confidence**: Radiomics pipeline outperforms foundation models on the internal dataset (84% vs 63-74% accuracy)
- **Medium confidence**: Pseudo-labeling via TotalSegmentator provides sufficient ROI quality for calcium detection (no expert validation)
- **Low confidence**: Results generalize to external datasets with different acquisition parameters or patient demographics

## Next Checks
1. Expert validation study: Manually annotate coronary calcium regions in 50 randomly selected scans and compute Dice overlap with TotalSegmentator outputs
2. Cross-scanner validation: Test the 84% accuracy pipeline on an external dataset from different scanner manufacturers and reconstruction kernels
3. Multi-class extension: Evaluate whether the pipeline maintains performance when classifying four Agatston score categories (0/1-10/11-100/101-400/>400) instead of binary zero/non-zero classification