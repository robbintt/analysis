---
ver: rpa2
title: 'FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive
  Learning and Neural Radiance Fields'
arxiv_id: '2505.19863'
source_url: https://arxiv.org/abs/2505.19863
tags:
- fruit
- instance
- field
- neural
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FruitNeRF++, a generalized multi-fruit counting
  method that combines contrastive learning with neural radiance fields. The approach
  addresses the limitation of previous fruit counting methods that required fruit-specific
  adaptations by encoding instance-level information into a neural instance field
  using contrastive learning.
---

# FruitNeRF++

## Quick Facts
- arXiv ID: 2505.19863
- Source URL: https://arxiv.org/abs/2505.19863
- Reference count: 40
- Primary result: Generalized multi-fruit counting method achieving F1-scores of 0.925 (GT masks), 0.832 (Grounded-SAM masks), 0.765 (real-world)

## Executive Summary
FruitNeRF++ presents a shape-agnostic multi-fruit counting framework that overcomes the fruit-specific limitations of previous approaches by encoding instance identity into neural fields via contrastive learning. The method uses vision foundation models to extract semantic and instance masks, trains a neural radiance field with density, semantic, and instance components, then clusters the resulting point cloud to count fruits. Unlike prior work requiring fruit-specific templates or shape priors, FruitNeRF++ generalizes across six fruit types (apples, plums, lemons, pears, peaches, mangoes) without retraining.

## Method Summary
The framework extracts semantic and instance masks using Grounded-SAM and Detic foundation models, then trains a cascaded neural radiance field. First, density and RGB fields optimize appearance; next, a semantic field adds fruit/background classification; finally, an instance field is trained with a contrastive InfoNCE loss using positive pairs from the same fruit masks and negative pairs from different fruits. The instance field outputs D-dimensional embeddings that encode fruit identity. After training, volumetric sampling produces a point cloud with instance features, which is partitioned and clustered using a multi-modal HDBSCAN with custom distance combining Euclidean and cosine metrics.

## Key Results
- Achieves F1-score of 0.925 on synthetic data with ground truth masks
- Maintains F1-score of 0.832 using only Grounded-SAM-generated masks
- Generalizes across six fruit types without fruit-specific retraining
- Outperforms previous FruitNeRF approach on same datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Encoding instance identity into a neural field via contrastive learning enables shape-agnostic fruit separation without templates.
- **Mechanism:** The instance field maps 3D coordinates to D-dimensional embeddings. During training, pixels from the same 2D instance mask form positive pairs (attracted), while pixels from different instances form negative pairs (repelled). The contrastive loss (adapted InfoNCE) optimizes a "fruit-prototype" feature per instance, making embeddings cluster by fruit identity in feature space.
- **Core assumption:** 2D instance masks from foundation models provide sufficient multi-view overlap to resolve 3D instance identity, despite view-inconsistency.
- **Evidence anchors:**
  - [abstract] "The masks are used to encode the identity of each fruit as instance embeddings into a neural instance field."
  - [Section IV-C.2] Equation 7 defines the contrastive loss using fruit-prototype features F_a as positive pairs.
  - [corpus] Related work (Contrastive Lift, Panoptic Lifting) shows contrastive objectives can lift 2D masks to 3D, though corpus does not validate fruit-specific performance.
- **Break condition:** If instance masks are highly inconsistent across views (e.g., occluded fruit split into two masks repeatedly), embeddings fragment and clustering overcounts.

### Mechanism 2
- **Claim:** Combining spatial (Euclidean) and feature (cosine) distances in clustering improves instance separation for closely-spaced fruits.
- **Mechanism:** The custom distance metric d_kl = λ_c·d_cosine + λ_e·d_euclidean (Eq. 9) lets HDBSCAN separate fruits that are spatially proximal but featurally distinct. The weighting (λ_e=5, λ_c=1 in practice) prioritizes spatial separation while using features to disambiguate clusters.
- **Core assumption:** Instance embeddings from the neural field are discriminative enough to separate adjacent fruits when spatial cues alone are insufficient.
- **Evidence anchors:**
  - [Section IV-E.2] Defines the multi-modal clustering metric and parameter sweep results.
  - [Figure 5, right] Shows F1-score drops when either spatial or feature component is removed (λ_e=0 or λ_e=∞).
  - [corpus] No direct corpus validation for this specific metric; neighboring papers use different clustering approaches.
- **Break condition:** If feature embeddings are noisy (from inaccurate camera poses), the cosine component contaminates clustering, reducing accuracy.

### Mechanism 3
- **Claim:** Cascaded training (density → semantics → instance with freezing) prevents catastrophic forgetting and stabilizes learning.
- **Mechanism:** Training proceeds in stages: (1) optimize density and RGB fields, (2) add semantic field, (3) freeze all and train instance field only. This prevents the instance-focused pixel sampler from degrading geometry.
- **Core assumption:** Density and semantics must converge before instance learning; instance training signal is too sparse/narrow to maintain overall scene quality.
- **Evidence anchors:**
  - [Section IV-C.4] "The training of the semantic and instance fields is unstable if the representation of density in the neural field is poor."
  - [Section IV-C.4] Describes freezing to avoid "catastrophic forgetting" from instance pixel sampler.
  - [corpus] No corpus comparison; this is a design choice specific to this architecture.
- **Break condition:** If density field is undertrained before freezing, instance embeddings will be geometrically incoherent.

## Foundational Learning

- **Concept: Neural Radiance Fields (NeRF)**
  - Why needed here: FruitNeRF++ extends NeRF with semantic and instance fields; understanding volumetric rendering (Eq. 1-3) is prerequisite.
  - Quick check question: Can you explain how accumulated transmittance T̂ determines pixel color along a ray?

- **Concept: Contrastive Learning (InfoNCE loss)**
  - Why needed here: The instance field is trained via a modified InfoNCE loss (Eq. 6-7) using positive/negative pairs from masks.
  - Quick check question: Given a batch of feature vectors and their instance labels, how would you construct positive and negative pairs?

- **Concept: Instance vs. Semantic Segmentation**
  - Why needed here: The pipeline uses Grounded-SAM/Detic to extract instance masks (per-fruit identity) not just semantics (fruit vs. background).
  - Quick check question: What is the difference between a semantic mask labeling "apple pixels" and an instance mask labeling "this specific apple"?

## Architecture Onboarding

- **Component map:** Unstructured RGB images + COLMAP poses → Grounded-SAM/Detic masks → Cascaded NeRF training (density→semantic→instance) → Volumetric sampling → k-Means partitioning → Multi-modal HDBSCAN clustering → Fruit counts

- **Critical path:** Instance field quality depends on: (1) accurate masks, (2) converged density, (3) proper temperature τ and embedding size D. Weakness in any stage degrades counting.

- **Design tradeoffs:**
  - Larger D (embedding dim) improves separation but increases memory; D=32 found sufficient (Fig. 5).
  - Lower τ emphasizes hard negatives but risks overfitting; τ=0.2–0.3 optimal range.
  - Grounded-SAM masks (IoU 0.56 avg) are noisier than GT but avoid per-fruit training.

- **Failure signatures:**
  - Overcounting: Occluded fruits split into multiple masks → fragmented embeddings
  - Undercounting: High λ_e merges spatially-close fruits
  - Noisy poses (FUJI dataset): Embeddings "contaminate" neighbors, F1 drops to 0.765

- **First 3 experiments:**
  1. **Sanity check:** Train on synthetic apple tree with GT masks; verify F1 ~0.996 (Tab. II baseline).
  2. **Ablation:** Sweep τ (0.1–0.5) and D (4–64) on single fruit type; plot F1 to find optimal region (reproduce Fig. 5).
  3. **Mask quality test:** Compare Grounded-SAM vs. Detic masks on same synthetic scene; quantify IoU vs. counting F1 correlation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the method be extended to handle fruits that grow in dense clusters (e.g., bananas, berries, dates) where individual instance segmentation fails?
- Basis in paper: [explicit] The authors state in Section VI: "challenges arise for fruits that grow in clusters, such as bananas, berries, or dates. Further research is needed to efficiently estimate cluster sizes and predict accurate cluster counts."
- Why unresolved: The current instance segmentation approach assumes fruits are spatially separable, but clustered fruits share boundaries and occlusions that prevent mask-level instance distinction.
- What evidence would resolve it: Evaluation on clustered fruit datasets showing F1-scores comparable to the current performance on separated fruits (e.g., ≥0.83).

### Open Question 2
- Question: Can the training time be reduced to near real-time by leveraging faster scene representations like Gaussian Splatting or incremental SLAM-based approaches?
- Basis in paper: [explicit] The authors note: "Training on larger scenes...takes about 8 hours...making it unsuitable for real-time use" and suggest "Using time-series images and incrementally building up the scene with SLAM [50], Gaussian Splatting [51] or PAgNeRF [7] could help achieve real-time performance."
- Why unresolved: The instance field training alone accounts for over half of the 8-hour training time, and NeRF's volumetric rendering is inherently slow compared to explicit representations.
- What evidence would resolve it: A modified architecture achieving comparable counting accuracy (F1 ≥0.76 on real data) with training under 30 minutes on equivalent hardware.

### Open Question 3
- Question: How can the framework resolve cases where occlusion causes a single fruit to be incorrectly segmented as two instances?
- Basis in paper: [explicit] The authors identify in Section IV-B and VI: "when a fruit is partially occluded by an obstacle, such as a leaf or branch, it may be detected as two separate instances. This leads to the feature space of a fruit being partially separated."
- Why unresolved: The contrastive learning objective reinforces the 2D mask inconsistencies, pulling apart embeddings that should belong to the same fruit.
- What evidence would resolve it: A post-processing or training modification that reduces over-segmentation errors on partially occluded fruits, measurable via instance recall improvement.

## Limitations
- Mask quality significantly impacts performance: Grounded-SAM masks (IoU ~0.56) create a 10% F1 gap vs. ground truth
- Real-world performance lags synthetic benchmarks, suggesting domain transfer challenges
- Method relies heavily on foundation model quality for segmentation, creating generalization dependencies

## Confidence

- **High confidence**: The contrastive learning mechanism for encoding instance identity into neural fields is well-supported by the synthetic evaluation results and ablation studies. The cascaded training approach to prevent catastrophic forgetting is clearly demonstrated.
- **Medium confidence**: The generalization capability across six fruit types is shown, but limited to a single synthetic dataset. Real-world performance suggests the method may struggle with pose noise and varying fruit appearances.
- **Low confidence**: Claims about extensibility beyond fruit counting lack validation; the method hasn't been tested on other object categories or counting scenarios.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate on an independent real-world fruit dataset with ground truth counts to verify the method transfers beyond the FUJI dataset.
2. **Robustness to pose noise**: Systematically degrade camera pose quality in synthetic data to quantify the impact on instance field accuracy and identify failure thresholds.
3. **Foundation model ablation**: Compare Grounded-SAM vs. Detic vs. other segmentation models on the same scenes to isolate the impact of mask quality on counting accuracy.