---
ver: rpa2
title: Training-Free Consistency Pipeline for Fashion Repose
arxiv_id: '2501.13692'
source_url: https://arxiv.org/abs/2501.13692
tags:
- image
- garment
- pipeline
- logo
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FASHION REPOSE, a training-free pipeline
  for non-rigid pose normalization of long-sleeve garments. The method uses pretrained
  models in a zero-shot fashion to edit garment poses from relaxed arm positions to
  a standardized 45-degree arm-torso angle while preserving garment identity, texture,
  and brand attributes.
---

# Training-Free Consistency Pipeline for Fashion Repose

## Quick Facts
- arXiv ID: 2501.13692
- Source URL: https://arxiv.org/abs/2501.13692
- Reference count: 40
- Primary result: Training-free pipeline for non-rigid pose normalization of long-sleeve garments using pretrained models

## Executive Summary
This paper introduces FASHION REPOSE, a training-free pipeline for non-rigid pose normalization of long-sleeve garments. The method uses pretrained models in a zero-shot fashion to edit garment poses from relaxed arm positions to a standardized 45-degree arm-torso angle while preserving garment identity, texture, and brand attributes. The pipeline integrates several stages including long-sleeve detection, coarse generation, conditioned unsampling, source-target shape matching, garment parts composition, upsampling, and logo restoration. Experiments on DressCode and VITON-HD datasets show that the method achieves better identity preservation than state-of-the-art baselines.

## Method Summary
The method operates through an 8-stage pipeline: (1) Long-sleeve detection using VGG16, Florence2, and LLaMa3; (2) Preprocessing with dual resolution outputs; (3) Coarse generation using RealisticVision v5.1 with ControlNet OpenPose and IP-Adapter Plus conditioning; (4) Conditioned unsampling with gradient-mask latent blending and noise injection/removal; (5) Source-target shape matching with silhouette scaling; (6) Garment parts composition using geometric boundary detection; (7) 4× upsampling with Ultrasharp; and (8) Logo detection/suppression/injection using Florence2 and SAM2. The approach operates entirely in a zero-shot manner without requiring fine-tuning on fashion datasets.

## Key Results
- LPIPS scores of 0.3147 (DressCode) and 0.3396 (VITON-HD), outperforming ControlNet (0.3858 and 0.3909)
- Parts composition improves LPIPS from 0.2189 to 0.1966 on DressCode dataset
- Logo subset shows improved SSIM (0.8304) vs full VITON-HD (0.7817)
- Superior identity preservation compared to inversion-based methods

## Why This Works (Mechanism)

### Mechanism 1: Conditioned Unsampling for Pose Transformation
- Claim: Conditioned unsampling enables pose transformation while preserving garment identity by navigating latent space along a semantic direction.
- Mechanism: Gradient-mask blending creates initial latent code from both source and target poses. Noise is then injected up to a specific timestep (unsampling) and removed (sampling) while being guided by positive embeddings (Florence2 garment description) and negative embeddings (artifact suppression). ControlNet OpenPose enforces target pose geometry; ControlNet Canny preserves edge structure.
- Core assumption: The diffusion latent space contains traversable directions that correspond to sleeve pose changes without disrupting texture/identity.
- Evidence anchors: Section 3.6 describes the unsampling process; abstract lists "conditioned unsampling" as key pipeline stage; weak direct evidence from PMMD mentions pose-guided diffusion but not unsampling specifically.
- Break condition: Complex textures or patterns may not transfer coherently through latent traversal, leading to reconstruction artifacts.

### Mechanism 2: Pixel-Space Composition for Identity Recovery
- Claim: Pixel-space composition of original torso with edited sleeves recovers identity fidelity lost during diffusion-based generation.
- Mechanism: After shape-matching aligns source and target silhouettes, a geometric algorithm identifies torso-sleeve boundaries using horizontal line intersections at 55% and 65% of image height. The original still-life torso is masked and composited with the normalized-pose sleeves, followed by light conditioned unsampling to soften hard edges and color realignment.
- Core assumption: Torso region remains relatively unchanged between poses, so original pixels are more faithful than generated ones.
- Evidence anchors: Section 3.8 describes the composition process; ablation shows parts composition improves LPIPS from 0.2189→0.1966 (DressCode); no direct corpus evidence for this specific composition strategy.
- Break condition: Incorrect mask computation creates white gaps or artifacts; highly complex torso patterns may not blend seamlessly.

### Mechanism 3: Logo Detection-Suppression-Injection for Brand Preservation
- Claim: Logo detection-suppression-injection preserves brand identity that would otherwise be distorted by diffusion edits.
- Mechanism: Florence2 detects logo bounding boxes → SAM2 generates precise segmentation masks → inpainting fills logo area with texture-matched content (positive prompt: "uniform color, solid color") → edited garment is composited with extracted logo using the saved mask.
- Core assumption: Logos are spatially localized and can be cleanly segmented; surrounding texture is homogeneous enough for convincing inpainting.
- Evidence anchors: Section 3.10 describes logo restoration; logo subset shows improved SSIM (0.8304) vs full VITON-HD (0.7817); no corpus papers address logo preservation in pose editing.
- Break condition: Neck regions may be misdetected as logos (Fig. 10); logos on highly textured areas produce inpainting artifacts.

## Foundational Learning

- Concept: **Latent Diffusion Models (Stable Diffusion architecture)**
  - Why needed here: The pipeline operates in latent space for unsampling/sampling; understanding VAE encoder/decoder and U-Net denoising is essential for debugging.
  - Quick check question: Can you explain why editing in latent space is more efficient than pixel space?

- Concept: **ControlNet Conditioning (OpenPose, Canny)**
  - Why needed here: These provide the structural and pose constraints that guide generation; misconfigured conditioning causes pose drift or loss of garment shape.
  - Quick check question: How does ControlNet differ from text conditioning in its influence on the denoising process?

- Concept: **Segmentation Models (SAM2, Florence2)**
  - Why needed here: Both sleeve/torso separation and logo isolation depend on accurate segmentation masks; poor detection propagates through composition.
  - Quick check question: What is the difference between bounding box detection and instance segmentation?

## Architecture Onboarding

- Component map: Long-sleeve detection → Preprocessing (512px + 1024px) + Logo detection + Logo suppression → Coarse generation → Conditioned unsampling → Source-target shape matching → Parts composition → Upsampling → Logo injection
- Critical path: Coarse generation → Conditioned unsampling → Parts composition. These three stages directly determine pose accuracy and identity preservation; upstream detection failures block the pipeline.
- Design tradeoffs:
  - Training-free vs. fine-tuned: Zero-shot flexibility but may underperform on highly complex patterns (acknowledged limitation)
  - Parts composition vs. end-to-end diffusion: Recovers identity but introduces hard-edge artifacts requiring additional unsampling pass
  - Logo suppression before generation vs. post-hoc correction: Prevents logo distortion but depends on accurate detection (neck false positives in Fig. 10)
- Failure signatures:
  - Duplicated sleeves with mismatched texture → complex garment patterns exceed model capability (Fig. 10 left)
  - White gaps at torso-sleeve boundary → mask misalignment in parts composition
  - Logo injected in wrong position → neck misdetected as logo (Fig. 10 right)
  - Color shifts → insufficient color realignment after composition
- First 3 experiments:
  1. Run single garment through pipeline with each stage logged (save intermediate outputs at coarse generation, post-unsampling, post-composition) to establish baseline timing and quality per stage.
  2. Ablate parts composition: compare output with and without this stage on 10 garments to quantify LPIPS/SSIM delta (expect ~0.02-0.03 LPIPS improvement per Table 2).
  3. Test logo workflow on garments with known logo positions: verify Florence2 detection accuracy and SAM2 mask quality before full pipeline integration.

## Open Questions the Paper Calls Out

- Can the pipeline be enhanced to accurately reconstruct intricate garments with complex patterns or highly detailed textures?
  - Basis: Section 5 states the model "struggles to accurately reconstruct" garments containing "complex patterns or textures"
  - Why unresolved: Current diffusion-based generation stages may lose high-frequency details during latent space manipulation
  - What evidence would resolve it: Improved LPIPS scores and qualitative fidelity on high-complexity texture patterns dataset

- How can the parts-composition algorithm be refined to prevent artifacts or white gaps when the segmentation mask misaligns with the sleeves?
  - Basis: Section 5 notes that "artifacts or white gaps may appear" if the mask misaligns, and Figure 10 shows "wrong duplicated sleeves" resulting from mask computation errors
  - Why unresolved: Algorithm 1 relies on geometric heuristics (fixed pixel lines and intersection points) that may fail on irregular garment shapes
  - What evidence would resolve it: A modified algorithm that eliminates hard edges in the ablation study without requiring manual correction

- Can the methodology generalize to arbitrary target poses beyond the standardized 45-degree arm-torso angle?
  - Basis: Section 3.1 defines the "Target Pose" strictly as a "standardized 45-degree arm-torso angle"
  - Why unresolved: Unclear if shape matching and composition logic relies on this specific geometry or can handle diverse kinematic changes
  - What evidence would resolve it: Successful qualitative generation of varied poses (e.g., T-pose, dynamic action poses) using the same zero-shot pipeline

## Limitations

- Struggles to accurately reconstruct garments containing complex patterns or textures, with limited characterization of quantitative impact
- Parts-composition algorithm may produce artifacts or white gaps when segmentation mask misaligns with sleeves
- Logo detection accuracy is affected by false positives, particularly detecting neck regions as logos

## Confidence

- **High**: Identity preservation claims supported by LPIPS/SSIM metrics; core pipeline architecture implementation
- **Medium**: Mechanism explanations for conditioned unsampling and parts composition; logo restoration effectiveness
- **Low**: Generalizability to highly complex garment patterns; long-term stability of diffusion-based pose transformations

## Next Checks

1. Test conditioned unsampling on garments with complex patterns (stripes, paisley, etc.) and measure LPIPS degradation compared to simple textures
2. Validate parts composition algorithm on asymmetric or loose-fitting garments where torso shape changes significantly between poses
3. Evaluate logo detection accuracy across diverse garment types, particularly for logos near necklines or on patterned backgrounds