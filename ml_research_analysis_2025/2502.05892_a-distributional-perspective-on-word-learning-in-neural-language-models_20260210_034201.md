---
ver: rpa2
title: A Distributional Perspective on Word Learning in Neural Language Models
arxiv_id: '2502.05892'
source_url: https://arxiv.org/abs/2502.05892
tags:
- word
- learning
- language
- signatures
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a distributional approach to measure word
  learning in neural language models (LMs) by defining lexical knowledge through properties
  of learned word distributions. The authors propose multiple distributional signatures
  that capture knowledge of both appropriate and inappropriate contexts for target
  words, including intrinsic (LM-internal) and reference-based (comparing to a larger
  pretrained LM) metrics.
---

# A Distributional Perspective on Word Learning in Neural Language Models

## Quick Facts
- **arXiv ID**: 2502.05892
- **Source URL**: https://arxiv.org/abs/2502.05892
- **Reference count**: 37
- **Primary result**: Proposed distributional signatures for measuring word learning in LMs fail to correlate with human age-of-acquisition patterns, suggesting current models learn primarily through frequency rather than human-like developmental trajectories.

## Executive Summary
This paper introduces a distributional approach to measure word learning in neural language models by tracking surprisal trajectories across both positive (where words occur) and negative (where they don't) contexts. The authors propose nine signature types that capture knowledge of appropriate and inappropriate contexts for target words, including intrinsic metrics based solely on the LM and reference-based metrics comparing to a larger pretrained model. They train small GPT-2 models from scratch on three datasets varying in developmental plausibility and size, then track these signatures across training. While different signatures capture complementary information, most show learning trajectories that fail to correlate with human word learning patterns. The metrics are also highly correlated with simple lexical frequency features, suggesting they primarily capture frequency effects rather than more nuanced aspects of word knowledge.

## Method Summary
The authors train GPT-2 small (12 layers, 12 heads) from scratch on three datasets of varying size and developmental plausibility: Unified (~600M words), BabyLM (100M words), and CHILDES (29M tokens). They compute nine distributional signatures tracking surprisal patterns for 305 target words across training checkpoints. Signatures include positive contexts (σ+), negative contexts (σ−), and their combinations, both intrinsic to the model and comparing to a reference Llama-3.1-8B model. Age of Acquisition is extracted using a Cauchy convergence criterion (ε=0.07) rather than arbitrary thresholding. The study evaluates correlation with human AoA data from Wordbank and compares learning patterns to child development.

## Key Results
- Different distributional signatures capture complementary information about word learning, with intrinsic and reference signatures showing distinct patterns
- Most signatures fail to correlate with human age-of-acquisition data (maximum r=0.31), suggesting current LM training yields learning patterns poorly aligned with human development
- LM age-of-acquisition is heavily predicted by log frequency (R²=0.61 for σ+ on Unified), while children's AoA is better predicted by concreteness (R²=0.26)
- LMs acquire abstract words faster while children acquire concrete words faster, showing opposite concreteness effects

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Word learning in LMs can be characterized by tracking surprisal trajectories across both positive and negative contexts.
- **Mechanism**: The model assigns decreasing surprisal to words in appropriate contexts and increasing surprisal in inappropriate contexts during training, capturing both "where a word can go" and "where it cannot go."
- **Core assumption**: Distributional knowledge requires knowing both appropriate AND inappropriate contexts, not just positive contexts.
- **Evidence anchors**:
  - [abstract]: "capturing knowledge of both where the target word can and cannot occur as well as gradient preferences about the word's appropriateness"
  - [section 3]: "even in expectation, there is one salient manner in which Chang and Bergen's (2022) distributional signature misses potentially valuable distributional information about the target word: it fails to account for the LM's distributional knowledge about w in negative contexts"
  - [corpus]: Related work confirms surprisal-based metrics can mask learning difficulties in subword models ("Subword models struggle with word learning, but surprisal hides it")
- **Break condition**: When trajectories are non-monotonic (σ̂+, σ̂I±, σ̂I+, σ̂I− show inconsistent shapes), threshold-based AoA extraction fails; requires Cauchy convergence approach instead.

### Mechanism 2
- **Claim**: Comparing a target LM's probability distribution to a larger reference LM provides a more grounded measure of lexical knowledge than absolute surprisal values.
- **Mechanism**: Reference signatures compute weighted Manhattan distances between log-probabilities from target model q and reference model r (Llama-3.1-8B), capturing how closely the small model approximates a "ground truth" distribution.
- **Core assumption**: A large pre-trained LM approximates ground truth better than the small target model, and distance from this reference correlates with lexical knowledge quality.
- **Evidence anchors**:
  - [section 3]: "reference signatures that compare the learned distribution to a non-trivial ground truth, which we approximate using a large pretrained LM"
  - [section 6.2]: "the reference signatures are mostly monotonically decreasing, indicating that the probability of the word of interest under the LM becomes closer to the ground truth after more iterations"
  - [corpus]: Limited corpus support for reference model comparison as a cognitive modeling tool
- **Break condition**: If the reference model has systematic biases, all comparisons inherit those errors; correlation with human AoA remains weak (r < 0.31) regardless of reference model quality.

### Mechanism 3
- **Claim**: Age of Acquisition can be extracted from learning trajectories using a Cauchy convergence criterion rather than arbitrary thresholding.
- **Mechanism**: AoA = argmin_t(max_{s,s'∈{t,...,T}} |σ(w,s) − σ(w,s')| < ε). A word is "acquired" when its signature stabilizes within tolerance ε of all subsequent values.
- **Core assumption**: Learning has occurred when the signature stops changing significantly, not when it crosses an arbitrary percentage of initial-to-final range.
- **Evidence anchors**:
  - [section 4]: "thresholding in this way is only suitable when σ̂ exhibits (roughly) monotonic change over time. While this is true of some signatures we consider, we find empirically that σ̂+, σ̂I±, σ̂I+, and σ̂I− are exceptions"
  - [appendix D]: Formal definition of Cauchy-based AoA with tolerance parameter ε
  - [corpus]: No corpus evidence for this specific AoA extraction method in cognitive modeling
- **Break condition**: When ε is too small (< 0.07), many words fail to converge; when too large, acquisition is claimed prematurely.

## Foundational Learning

- **Concept: Prefix probability and surprisal**
  - Why needed here: The entire framework builds on computing p⃗(w|c), the probability of a word following a context, and its negative log (surprisal). Without understanding that surprisal = −log p, the signature formulas are opaque.
  - Quick check question: If an LM assigns probability 0.125 to "cat" after context "The furry", what is the surprisal? (Answer: 3 bits)

- **Concept: Monte Carlo estimation of expectations**
  - Why needed here: All signature estimators (σ̂+, σ̂−, etc.) are Monte Carlo approximations, sampling contexts to estimate expectations over infinite context spaces.
  - Quick check question: Why does the paper sample exactly 100 positive and 100 negative contexts per word rather than computing over all possible contexts?

- **Concept: Cross-entropy and language model training**
  - Why needed here: The paper trains LMs via cross-entropy minimization. Understanding that σ+ at initialization approximates the loss restricted to a single word class helps interpret trajectories.
  - Quick check question: How is cross-entropy related to the σ+ signature when positive contexts are sampled from the training distribution?

## Architecture Onboarding

- **Component map**: Datasets (Unified/BabyLM/CHILDES) -> GPT-2 tokenizer -> training batches -> GPT-2 small model -> checkpoints (50/200/500 step intervals) -> signature computation (100 pos/neg contexts) -> 9 signature types per word -> Cauchy convergence (ε=0.07) -> correlation with Wordbank AoA

- **Critical path**:
  1. Checkpoint saving must be frequent early (learning happens fast initially)
  2. Context sampling must be fixed across all models for fair comparison
  3. Signature computation requires forward passes through both target model AND reference model (Llama-3.1-8B)
  4. Convergence check requires all checkpoints loaded; non-converging words excluded from analysis

- **Design tradeoffs**:
  - Dataset size vs. developmental plausibility: CHILDES is most plausible but has worst convergence rates
  - ε threshold: 0.07 balances convergence rate vs. precision; <0.05 causes >50% non-convergence on CHILDES
  - Reference model choice: Larger models may better approximate ground truth but introduce computational overhead

- **Failure signatures**:
  1. **Non-convergence**: Intrinsic signatures (σI±, σI+, σI−) fail to converge for 20-50% of words on smaller datasets
  2. **Weak human correlation**: Across ALL signatures, maximum correlation with children's AoA is r=0.31; many show negative correlations
  3. **Frequency dominance**: LM AoA heavily predicted by log frequency (R²=0.61 for σ+ on Unified); children's AoA better predicted by concreteness (R²=0.26)
  4. **Opposite concreteness effect**: LMs acquire abstract words faster; children acquire concrete words faster

- **First 3 experiments**:
  1. **Signature correlation matrix**: Train GPT-2 on Unified dataset, compute all 9 signatures for 305 words, verify that most signature pairs show weak or negative correlations (confirming complementary information capture).
  2. **Convergence sensitivity**: Vary ε from 0.01 to 0.15 across all three datasets, plot convergence rates per signature to validate that 0.07 is a reasonable operating point.
  3. **Feature regression replication**: Predict LM AoA from log frequency, concreteness, character count, MLU, and lexical category; compare R² patterns to child AoA regressions to confirm that frequency dominates for LMs but concreteness dominates for children.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Which specific distributional evaluations or combinations thereof should researchers prioritize when studying word learning in language models?
- Basis in paper: [explicit] The authors state, "the question remains: which of these evaluations should be the focus of researchers interested in studying word learning in LMs?"
- Why unresolved: The paper demonstrates that different signatures capture complementary information, yet none perfectly correlate with human data, leaving the optimal metric undefined.
- What evidence would resolve it: A comparative study identifying a specific signature or weighted ensemble that robustly predicts human learning milestones across multiple languages and model architectures.

### Open Question 2
- Question: Are the observed learning trajectories and the lack of correlation with human data robust across different pre-training settings and model architectures?
- Basis in paper: [explicit] "Future work should examine whether different pre-training settings yield qualitatively different results, i.e., whether our findings are robust across various setups."
- Why unresolved: The study restricted its experiments to GPT-2 models trained on specific datasets (CHILDES, BabyLM, Unified), leaving the generalizability of the findings unconfirmed.
- What evidence would resolve it: Replicating the distributional signature analysis on diverse architectures (e.g., LSTMs, larger Transformers) and data regimes to verify if trajectories remain consistent.

### Open Question 3
- Question: Can training procedures be modified to induce more human-like learning trajectories in language models?
- Basis in paper: [explicit] "We call for future work to evaluate and improve the human-likeness of LMs’ learning trajectories using the distributional signatures we propose."
- Why unresolved: The paper concludes that current models fail to align with human trajectories, citing the lack of grounding and interaction as potential missing factors.
- What evidence would resolve it: Tracking trajectories of models trained with multimodal grounding or communicative feedback to determine if their age-of-acquisition curves align more closely with those of children.

## Limitations

- **Frequency dominance**: All distributional signatures correlate strongly with lexical frequency rather than human-like developmental factors, suggesting current metrics primarily capture statistical regularities
- **Weak human alignment**: Maximum correlation with child age-of-acquisition data is only r=0.31, indicating poor alignment between LM learning trajectories and human development
- **Convergence reliability**: Cauchy-based AoA extraction yields non-convergence rates of 20-50% on smaller datasets, raising questions about method reliability

## Confidence

- **High confidence**: The framework's technical implementation (signature computation, convergence criteria, training setup) is sound and reproducible. The finding that all signatures correlate strongly with frequency rather than human-like factors (concreteness, MLU) is robust across datasets and seeds.
- **Medium confidence**: The claim that LM learning patterns poorly align with human development is supported by correlation data, though alternative explanations (different learning mechanisms, suboptimal metrics) cannot be ruled out. The Cauchy convergence method for AoA extraction is theoretically justified but practically problematic with high non-convergence rates.
- **Low confidence**: The reference signature approach as a measure of lexical knowledge quality is weakly supported, with limited corpus evidence for its effectiveness as a cognitive modeling tool.

## Next Checks

1. **Test signature robustness**: Recompute all signatures using double the context samples (200 positive/negative) and compare AoA correlations with the original 100-sample results to determine if sampling variability explains weak human correlations.

2. **Alternative reference models**: Replace Llama-3.1-8B with smaller, similarly-sized models (e.g., GPT-2 small trained on same corpus) and test whether reference signatures still show the same convergence patterns and human correlation deficits.

3. **Frequency-matched analysis**: Select subsets of words matched on frequency but varying in concreteness, then compare AoA trajectories across signatures to determine if frequency truly dominates or if subtle frequency-independent patterns exist that the current analysis misses.