---
ver: rpa2
title: Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary
  Generalization
arxiv_id: '2509.04745'
source_url: https://arxiv.org/abs/2509.04745
tags:
- sign
- phonological
- learning
- signs
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generalizing sign language
  models to unseen signs by leveraging phonological inductive biases. The proposed
  VQ-ASL framework combines Parameter Disentanglement, an architectural bias that
  factors the latent space by phonological parameters, with Phonological Semi-Supervision,
  a regularization technique that aligns learned codes with expert linguistic labels.
---

# Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization

## Quick Facts
- arXiv ID: 2509.04745
- Source URL: https://arxiv.org/abs/2509.04745
- Reference count: 10
- VQ-ASL achieves test MSE of 0.041 for OOV sign reconstruction and improves isolated sign recognition MRR to 0.452

## Executive Summary
This paper addresses the challenge of generalizing sign language models to unseen signs by leveraging phonological inductive biases. The proposed VQ-ASL framework combines Parameter Disentanglement, an architectural bias that factors the latent space by phonological parameters, with Phonological Semi-Supervision, a regularization technique that aligns learned codes with expert linguistic labels. Evaluated on the Sem-Lex benchmark, VQ-ASL achieves a test MSE of 0.041 for OOV sign reconstruction and improves isolated sign recognition MRR to 0.452, outperforming both baseline and ablation variants. The results demonstrate that explicit, linguistically-motivated biases enable more effective discrete representations for both generative and discriminative sign language tasks.

## Method Summary
The VQ-ASL framework improves sign language representation learning through two key interventions. Parameter Disentanglement (PD) partitions the latent space into phonologically-motivated streams (right hand, left hand, right movement, left movement, non-manual markers, and body) with dedicated encoders, decoders, and codebooks, plus shared codebooks for symmetric articulators. Phonological Semi-Supervision (PSS) uses a subset of codebook entries pre-assigned to ASL-LEX 2.0 phonological features, with training that forces quantization to select the ground-truth code with specified probability. The model operates on MediaPipe keypoint sequences from isolated signs, using transformer encoders and decoders with vector quantization to create discrete representations that improve both reconstruction quality and out-of-vocabulary generalization.

## Key Results
- VQ-ASL achieves test MSE of 0.041 for OOV sign reconstruction, outperforming baseline (0.058) by 21%
- Isolated sign recognition MRR improves to 0.452 with full VQ-ASL, up from baseline 0.381
- Individual interventions show complementary benefits: PD alone improves reconstruction (0.046 MSE) but slightly hurts recognition (0.372 MRR), while PSS alone improves recognition (0.435 MRR) with minimal reconstruction gain (0.055 MSE)

## Why This Works (Mechanism)

### Mechanism 1: Parameter Disentanglement (PD)
- Claim: Partitioning the latent space into phonologically-motivated streams improves compositional generalization to unseen sign combinations.
- Mechanism: The model replaces a monolithic encoder-decoder with parallel streams (X^RH, X^LH, X^MOVR, X^MOVL, X^NMM, X^BODY), each with dedicated codebooks. Shared codebooks for symmetric articulators (left/right hand) enforce linguistic symmetry constraints. This prevents the model from encoding spurious correlations between independent phonological parameters.
- Core assumption: Signs can be decomposed into independent articulatory components that recombine productively; the Prosodic Model's factorization (Brentari, 1998) correctly identifies these components.
- Evidence anchors:
  - [Section 5.1] VQ-ASL-PD reduces test MSE to 0.046 from baseline 0.058 (21% improvement in OOV reconstruction).
  - [Section 3.2.1] Input keypoints are filtered for each stream with minimal overlap; each stream has its own encoder, decoder, and codebook.
  - [Corpus] Related work on articulator-based disentanglement (Tasyurek et al., 2025) shows similar architectural approaches for continuous latents, though not for VQ or OOV generalization.
- Break condition: PD alone slightly degrades ISR performance (MRR .372 vs baseline .381), suggesting architectural separation is insufficient for semantic alignment without supervisory signal.

### Mechanism 2: Phonological Semi-Supervision (PSS)
- Claim: Weak supervision from expert phonological labels aligns discrete codes with linguistically-contrastive features, improving discriminative quality.
- Mechanism: A subset of codebook entries is pre-assigned to ASL-LEX 2.0 features (e.g., handshape, location). During training, with specified probability, quantization is forced to select the code corresponding to the ground-truth label. The commitment loss then trains the encoder to produce outputs that map to semantically meaningful codes.
- Core assumption: ASL-LEX 2.0 features are both (a) valid phonological primitives and (b) generalizable to OOV signs.
- Evidence anchors:
  - [Section 5.2] VQ-ASL-PSS achieves OOV ISR MRR of .435 vs baseline .381 (14% improvement).
  - [Section 5.2] PFR probe confirms high phonological alignment for supervised models (.565 OOV MRR for VQ-ASL-PSS).
  - [Corpus] No direct corpus evidence on semi-supervised phonological alignment in VQ-VAEs for sign language; this appears novel.
- Break condition: PSS provides minimal reconstruction gain alone (test MSE 0.055 vs baseline 0.058), indicating semantic alignment doesn't automatically improve generative fidelity.

### Mechanism 3: Stratified Inductive Bias Interaction
- Claim: Architectural (PD) and semantic (PSS) biases provide complementary benefits; their combination yields both best reconstruction and best recognition.
- Mechanism: PD creates a productive latent space for novel combinations; PSS ensures those combinations map to linguistically meaningful distinctions. Together they address Locatello et al.'s impossibility theorem by providing both model-level (architecture) and data-level (labels) inductive biases.
- Core assumption: The two biases do not conflict in how they structure the latent space.
- Evidence anchors:
  - [Section 5] Full VQ-ASL achieves best test MSE (0.041) and best OOV ISR MRR (.452).
  - [Section 6.1] Results empirically support Locatello et al.—structural bias alone insufficient for semantic meaning; semantic bias required for discriminative tasks.
  - [Corpus] Weak related evidence; "Disentangle and Regularize" (Tasyurek et al., 2025) addresses articulator disentanglement but with different regularization and continuous latents.
- Break condition: Trade-off between reconstruction fidelity and discriminability persists in individual interventions; only combination resolves it.

## Foundational Learning

- Concept: Vector Quantization (VQ-VAE)
  - Why needed here: Core architecture; maps continuous encoder outputs to discrete codebook entries via nearest-neighbor lookup, creating token-like representations. Straight-through estimator enables gradient flow through non-differentiable quantization.
  - Quick check question: Can you explain why argmin is non-differentiable and how the straight-through estimator solves this?

- Concept: Disentangled Representation Learning
  - Why needed here: The paper directly addresses Locatello et al.'s impossibility result—unsupervised disentanglement requires inductive biases. Understanding β-VAE and the theoretical limits helps contextualize why explicit biases are necessary.
  - Quick check question: Why can't an unsupervised model distinguish between a disentangled representation and an entangled transformation that produces the same data distribution?

- Concept: Sign Language Phonology (Prosodic Model)
  - Why needed here: The interventions are derived from Brentari's hierarchical model (articulators, place of articulation, prosodic features). Knowing the phonological parameters (handshape, location, movement, NMM) is essential for understanding the stream partitioning.
  - Quick check question: What are the five phonological parameters in sign language, and why might movement require continuous rather than discrete representation?

## Architecture Onboarding

- Component map:
  Input (MediaPipe keypoints) -> Stream partitioning (PD only) -> Stream-specific encoding -> Vector quantization (forced code selection if PSS + label available) -> Codebook lookup -> Stream-specific decoding -> Reconstruction loss

- Critical path:
  1. Pose extraction → stream partitioning (PD only)
  2. Stream-specific encoding → quantization (forced code selection if PSS + label available)
  3. Codebook lookup → decoding → reconstruction loss
  4. Commitment loss trains encoder; codebook loss updates code vectors

- Design tradeoffs:
  - PD improves reconstruction but harms recognition alone; requires PSS for semantic structure
  - PSS improves recognition but minimal reconstruction gain alone
  - Shared vs. separate codebooks: Shared enforces symmetry but may limit expressivity for asymmetric signs
  - Codebook size: Must be large enough to represent unlabeled features (palm orientation, complex paths) but not so large that codebook collapse occurs

- Failure signatures:
  - Codebook collapse: "Dead codes" never selected → re-initialize dead codes to encoder output averages
  - Poor OOV generalization: Model memorizes train-set correlations → check if PFR probe shows low alignment on test set
  - Asymmetric reconstruction errors: If X^(LH) MSE >> X^(RH), check shared codebook constraint

- First 3 experiments:
  1. Reproduce baseline vs. VQ-ASL-PD vs. VQ-ASL-PSS vs. Full ablation on Sem-Lex OOV split; verify MSE and MRR match Table 2 and Table 3.
  2. Ablate shared codebook constraint (separate C^(LH) and C^(RH)) to measure impact of symmetry enforcement on one-handed vs. two-handed signs.
  3. Vary PSS supervision probability (currently unspecified in paper) to characterize trade-off between phonological alignment and reconstruction flexibility.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the VQ-ASL framework effectively tokenize continuous, conversational signing containing co-articulation and prosodic markers?
- Basis in paper: [explicit] Section 6.3 states the scope is restricted to isolated signs and does not address the challenges of co-articulation.
- Why unresolved: Isolated datasets lack the fluid transitions and grammatical non-manual markers found in natural discourse.
- What evidence would resolve it: Evaluation of the tokenizer on continuous sign language recognition (CSLR) benchmarks to measure performance on fluid sentences.

### Open Question 2
- Question: Does the improved reconstruction MSE of VQ-ASL correlate with higher perceptual naturalness for human signers?
- Basis in paper: [explicit] Section 6.3 notes that automated metrics like MSE are imperfect proxies for human perception of motion quality.
- Why unresolved: Mathematical fidelity to pose keypoints does not guarantee that generated motions are free from uncanny artifacts or jitter.
- What evidence would resolve it: A human evaluation study where native ASL signers rate the naturalness and semantic accuracy of reconstructed clips.

### Open Question 3
- Question: Can residual vector quantization be used to explicitly model the hierarchical dependencies between phonological features?
- Basis in paper: [explicit] Appendix C proposes the "Hierarchical Hypothesis" to model relationships between high-level features (e.g., handshape) and sub-features (e.g., flexion).
- Why unresolved: The current architecture uses a flat VQ structure, which does not explicitly capture the part-whole relationships defined in Brentari's Prosodic Model.
- What evidence would resolve it: Implementation of a residual codebook that successfully refines a coarse "handshape" code with a specific "flexion" correction code.

### Open Question 4
- Question: Are specific phonological parameters (e.g., movement path) better represented as continuous variables rather than discrete codes?
- Basis in paper: [explicit] Appendix C proposes the "Gradient Hypothesis" to determine which aspects of signing are more continuous in nature.
- Why unresolved: The current model enforces discrete representations for all channels, potentially losing fine-grained trajectory information necessary for smooth movement.
- What evidence would resolve it: Ablation studies selectively disabling quantization for movement channels to compare reconstruction fidelity and motion smoothness.

## Limitations
- The paper assumes ASL-LEX 2.0 labels are valid phonological primitives for OOV signs, but no validation is provided that these labels transfer to unseen sign combinations.
- Shared codebooks for left/right hands may constrain representation of asymmetric signs, yet no ablation study isolates the impact of this architectural choice on sign recognition accuracy for one-handed vs. two-handed signs.
- The supervision probability for PSS is not specified, making it unclear how much labeled data is required for the alignment benefit and whether this scales to other sign languages with different phonological inventories.

## Confidence
- High confidence: The architectural implementation of Parameter Disentanglement and its impact on reconstruction quality (21% MSE improvement). The mechanism is clearly described and empirically supported.
- Medium confidence: The Phonological Semi-Supervision mechanism and its alignment benefits. While PFR probe results support the claim, the lack of baseline for phonological alignment and unspecified supervision probability introduces uncertainty.
- Low confidence: The assumption that compositional generalization works for novel sign combinations through code concatenation. No qualitative analysis shows whether reconstructed OOV signs are linguistically plausible or merely statistically plausible.

## Next Checks
1. Conduct a human perceptual study where signers rate the plausibility of VQ-ASL-generated OOV signs compared to baseline reconstructions, directly testing whether compositional generalization produces recognizable signs.
2. Perform an ablation on the shared codebook constraint (C^(LH) ≠ C^(RH)) and measure performance differences across one-handed and two-handed signs in both reconstruction and recognition tasks.
3. Vary the PSS supervision probability from 0% to 100% and characterize the trade-off curve between phonological alignment (PFR probe scores) and reconstruction flexibility (MSE on OOV test set).