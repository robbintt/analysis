---
ver: rpa2
title: 'LegalGuardian: A Privacy-Preserving Framework for Secure Integration of Large
  Language Models in Legal Practice'
arxiv_id: '2501.10915'
source_url: https://arxiv.org/abs/2501.10915
tags:
- legal
- entities
- data
- client
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LegalGuardian is a privacy-preserving framework that protects client
  confidentiality when using large language models (LLMs) in legal practice. It uses
  named entity recognition and local LLMs to mask and unmask sensitive personally
  identifiable information (PII) in legal prompts before external LLM interactions.
---

# LegalGuardian: A Privacy-Preserving Framework for Secure Integration of Large Language Models in Legal Practice

## Quick Facts
- arXiv ID: 2501.10915
- Source URL: https://arxiv.org/abs/2501.10915
- Reference count: 32
- Key outcome: 93% F1-score with GLiNER and 97% with Qwen2.5-14B for PII detection while maintaining high semantic similarity in masked LLM outputs

## Executive Summary
LegalGuardian is a privacy-preserving framework that protects client confidentiality when using large language models (LLMs) in legal practice. It employs named entity recognition (NER) techniques and local LLMs to detect, mask, and unmask sensitive personally identifiable information (PII) in legal prompts before external LLM interactions. Tested with synthetic immigration law prompts, the framework achieves high PII detection accuracy (93% F1-score with GLiNER and 97% with Qwen2.5-14B) while maintaining semantic similarity between masked and original outputs. This enables legal professionals to leverage LLM capabilities without compromising confidentiality or output quality.

## Method Summary
The framework implements a mask-process-unmask pipeline using synthetic immigration law prompts generated with Faker and Qwen2.5-14B. PII detection employs two parallel approaches: GLiNER Multi PII-v1 (a BERT-based NER model) and Qwen2.5-14B (one-shot prompting for JSON-structured entity extraction). Detected entities are replaced with sequential placeholders (e.g., [PERSON 1], [ADDRESS 1]) while maintaining a bidirectional entity dictionary. Masked prompts are sent to external LLMs, then outputs are restored using the dictionary. Evaluation measures include entity-level precision/recall/F1-scores and semantic similarity metrics (cosine similarity, Jaro-Winkler, Levenshtein distance) between masked and original outputs.

## Key Results
- PII detection achieved 93% F1-score with GLiNER and 97% with Qwen2.5-14B
- Semantic similarity between masked and original outputs exceeded 0.97 cosine similarity
- GLiNER demonstrated 100% precision but 88% recall, while Qwen2.5-14B achieved 94% recall
- Entity replacement maintained coherence across diverse legal task types (summarization, translation, legal analysis, drafting)

## Why This Works (Mechanism)

### Mechanism 1
Named Entity Recognition (NER) models and local LLMs can detect legal-specific PII with high accuracy before external transmission. The framework applies GLiNER (BERT-based NER fine-tuned for PII) and Qwen2.5-14B (one-shot prompting) to identify entities such as person names, case numbers, addresses, tax IDs, and nationalities. Each detected entity is logged with its text, label, and position.

### Mechanism 2
Structured placeholder replacement preserves document coherence and enables accurate reconstruction after external LLM processing. Detected PII entities are replaced with unique, sequential placeholders combining entity type and index (e.g., [PERSON 1], [ADDRESS 1]). An entity dictionary maintains bidirectional mappings between originals and placeholders.

### Mechanism 3
A mask-process-unmask pipeline maintains semantic fidelity of LLM outputs while eliminating PII exposure during external interactions. The process follows: (1) Original prompt → PII detection → masked prompt; (2) Masked prompt sent to external LLM; (3) LLM output → dictionary-based unmasking → restored output. Semantic similarity between restored and baseline outputs validates utility preservation.

## Foundational Learning

- **Named Entity Recognition (NER) with Custom Entity Types**
  - Why needed here: LegalGuardian requires detecting domain-specific PII categories beyond standard NER (e.g., "case_number," "tax_id," "law_office"). Traditional NER models often limit users to predefined categories.
  - Quick check question: Given a prompt containing "Case A-2024-78932 filed by Maria Santos of 123 Oak Street," can you identify which tokens map to "case_number," "person," and "address" entity types?

- **One-Shot Prompting for LLM-based Entity Extraction**
  - Why needed here: The framework uses Qwen2.5-14B with a single example to extract structured PII. Understanding prompt design for consistent JSON output is critical for reliable entity detection.
  - Quick check question: What elements in Listing 1 ensure the LLM outputs valid JSON rather than explanatory text? How would missing the "Dont provide any explanations" instruction affect downstream parsing?

- **Semantic Similarity Metrics for Utility Evaluation**
  - Why needed here: The framework must prove that masking doesn't degrade output quality. Understanding cosine similarity (embedding-based), Jaro-Winkler, and Levenshtein distance helps interpret the privacy-utility tradeoff.
  - Quick check question: If cosine similarity is 0.98 but Jaro-Winkler is 0.83, what does this suggest about the nature of changes between masked and original outputs?

## Architecture Onboarding

- **Component map:** Synthetic Data Generator -> PII Masking Layer -> Secure Prompting Layer -> Evaluation Layer
- **Critical path:** Input prompt → PII detection (GLiNER or Qwen) → Entity dictionary creation → Placeholder replacement → External LLM call → Output post-processing → Dictionary-based unmasking → Final output
- **Design tradeoffs:**
  - GLiNER vs. Qwen2.5-14B for detection: GLiNER offers 100% precision (fewer false positives) but 88% recall; Qwen offers 94% recall but may over-detect. Paper recommends hybrid approach.
  - Local vs. external LLMs: Framework assumes local detection + external inference. Running both locally eliminates privacy risk but requires more compute.
  - Placeholder design: Sequential labeling ([PERSON 1], [PERSON 2]) preserves entity relationships but increases token count. Single-type placeholders ([PERSON]) simplify but lose cross-reference fidelity.
- **Failure signatures:**
  - Undetected PII leakage: Recall gaps (GLiNER at 65% for "location") mean sensitive data reaches external LLMs. Monitor by comparing detected entity count against expected baseline.
  - Unmasking failures: If external LLM generates outputs referencing entities not in original dictionary (e.g., "the applicant's spouse"), restoration produces incoherent text.
  - Semantic drift: Low cosine similarity (<0.90) between masked and baseline outputs indicates masking degraded LLM reasoning quality.
- **First 3 experiments:**
  1. Baseline PII detection benchmark: Run GLiNER and Qwen2.5-14B on 50 synthetic prompts with manually labeled ground truth. Compute precision, recall, F1 per entity type. Identify weakest categories.
  2. End-to-end pipeline validation: Select 10 prompts → mask → send to external LLM (e.g., GPT-4) → unmask → compute semantic similarity against baseline (unmasked) outputs. Flag any unmasking failures.
  3. Edge case PII testing: Generate prompts with entity types outside the 10-category taxonomy (e.g., medical records, biometric identifiers). Measure false negative rate to determine taxonomy expansion needs.

## Open Questions the Paper Calls Out
- How does LegalGuardian perform when applied to legal domains beyond immigration law, such as corporate litigation or criminal defense, which may feature different terminologies and PII structures?
- Is the rule-based unmasking process robust against external LLMs that paraphrase content or omit the specific masked placeholders (e.g., `[PERSON 1]`) in their generated outputs?
- Does the implementation of LegalGuardian introduce latency or workflow friction that would hinder its adoption by practicing legal professionals?

## Limitations
- GLiNER's recall performance (65-72% for "location" and "person" categories) represents a significant privacy risk, as undetected PII may still leak to external LLMs.
- The framework assumes external LLM outputs can be reliably reconstructed using only the original entity dictionary, which may fail if the LLM generates new entity references or complex relational inferences.
- Evaluation used simulated external LLM interactions (Qwen2.5-14B locally) rather than actual cloud-based LLM APIs, potentially missing real-world privacy and performance variations.

## Confidence
- **High Confidence**: The masking/unmasking mechanism using placeholder replacement and entity dictionaries works as described for the tested synthetic dataset.
- **Medium Confidence**: The framework's ability to maintain semantic similarity between masked and unmasked outputs across diverse legal tasks and real external LLM APIs.
- **Low Confidence**: The framework's robustness against PII types outside the defined 10-category taxonomy and its performance with real-world legal prompts containing complex entity relationships.

## Next Checks
1. **Ground Truth PII Detection Benchmark**: Manually annotate 50 real immigration law prompts with PII labels, then compare GLiNER and Qwen2.5-14B detection performance against ground truth. Focus on recall for "location," "person," and custom categories like "case_number."
2. **End-to-End External LLM Testing**: Implement the complete pipeline using an actual external LLM API (e.g., GPT-4) with 10 real-world legal prompts. Measure both PII leakage (manual inspection) and semantic similarity between masked/unmasked outputs.
3. **Taxonomy Coverage Assessment**: Create a diverse test set of legal prompts containing PII types beyond the current taxonomy (e.g., medical records, financial accounts, biometric data). Measure false negative rates to identify taxonomy gaps requiring expansion.