---
ver: rpa2
title: Deep Learning-Based Cross-Anatomy CT Synthesis Using Adapted nnResU-Net with
  Anatomical Feature Prioritized Loss
arxiv_id: '2509.22394'
source_url: https://arxiv.org/abs/2509.22394
tags:
- nnu-net
- nnresu-net
- loss
- task
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces a robust patch-based 3D nnU-Net adaptation
  for cross-modality CT synthesis from MRI and CBCT, using the SynthRAD2025 dataset
  across head/neck, thorax, and abdomen regions. Two configurations are explored:
  standard U-Net and residual U-Net (nnResU-Net).'
---

# Deep Learning-Based Cross-Anatomy CT Synthesis Using Adapted nnResU-Net with Anatomical Feature Prioritized Loss

## Quick Facts
- arXiv ID: 2509.22394
- Source URL: https://arxiv.org/abs/2509.22394
- Reference count: 12
- Primary result: nnResU-Net with AFP loss improves anatomical segmentation metrics while maintaining intensity fidelity in cross-modality CT synthesis

## Executive Summary
This work introduces a robust patch-based 3D nnU-Net adaptation for cross-modality CT synthesis from MRI and CBCT, using the SynthRAD2025 dataset across head/neck, thorax, and abdomen regions. Two configurations are explored: standard U-Net and residual U-Net (nnResU-Net). The Anatomical Feature-Prioritized (AFP) loss is introduced, which leverages multi-layer features from a compact TotalSegmentator-trained network to improve preservation of clinically relevant structures. Inputs are normalized per-case (z-score for MRI, clipped+dataset-level z-score for CBCT/CT). Training uses 3D patches, 1000-1500 epochs with SGD, and AFP fine-tuning for 500 epochs. Inference aggregates overlapping patches with step size 0.3. Residual networks with AFP achieve sharper reconstructions and better segmentation-based metrics (Dice, HD95), especially for bone and lesion structures, while L1-only variants perform better on intensity-based metrics (MAE, PSNR, MS-SSIM). The approach provides a stable solution for medical image synthesis by combining nnU-Net automation, residual learning, and anatomically guided feature losses.

## Method Summary
The method uses a patch-based 3D nnU-Net adaptation for cross-modality CT synthesis from MRI/CBCT. Two network configurations are tested: standard U-Net and residual U-Net (nnResU-Net). The AFP loss leverages features from a compact TotalSegmentator network to prioritize anatomical fidelity. Inputs undergo case-wise normalization (z-score for MRI, clipped+dataset-level z-score for CBCT/CT). Training employs 3D patches with 1000-1500 epochs using SGD, followed by 500 epochs of AFP fine-tuning. Inference uses overlapping patches aggregated by mean averaging with step size 0.3.

## Key Results
- Residual U-Net (nnResU-Net) with AFP loss achieves Dice scores of 0.7496-0.7649 in Task 1 (vs. 0.7244-0.7555 for L1-only)
- HD95 values improve to 6.896-7.084 with AFP vs. 7.629-9.172 for L1-only variants
- L1-only models outperform AFP on intensity metrics (MAE, PSNR, MS-SSIM)
- Bone and lesion structures show sharper reconstruction with residual networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Residual connections improve gradient flow and focus learning on local modifications rather than full image reconstruction.
- Mechanism: The nnResU-Net learns the residual (difference) between input (MR/CBCT) and target (CT) instead of the full mapping. Since cross-modality pairs share high structural similarity, residual learning allows the network to concentrate computational capacity on modality-specific transformations (e.g., intensity mapping, bone enhancement) rather than relearning shared anatomical structures.
- Core assumption: Source and target modalities have substantial structural correspondence; the transformation is primarily local/intensity-based rather than geometric.
- Evidence anchors:
  - [abstract] "both network configurations were applied across all regions, allowing consistent model design while capturing local adaptations through residual learning"
  - [Page 3] "In this residual approach, the network learns only the difference between input and target images rather than the full mapping. This is particularly advantageous for medical image translation, where source and target share high structural similarity"
  - [corpus] Limited direct corpus support; neighboring papers focus on segmentation rather than synthesis
- Break condition: If input-output misalignment exceeds local correction capacity (e.g., significant deformable registration errors), residual learning may fail to correct global structural discrepancies.

### Mechanism 2
- Claim: AFP loss improves anatomical fidelity (segmentation metrics) at the cost of slight degradation in pixel-wise intensity metrics.
- Mechanism: AFP computes L1 distance between multi-layer feature maps extracted from a pre-trained compact segmentation network (TS_Compact7_3x1x1, derived from TotalSegmentator). By aligning features that encode anatomical structures rather than raw intensities, the loss biases reconstruction toward preserving clinically relevant structures (bones, organs) over pixel-perfect intensity matching. The feature extractor acts as a learned anatomical prior.
- Core assumption: The feature extractor's internal representations correlate with clinically relevant anatomical structures; TotalSegmentator labels generalize to the target domain.
- Evidence anchors:
  - [Page 4-5] "AFP loss computes an L1 distance between feature maps extracted from a pre-trained TotalSegmentator model applied to both predicted and ground truth CT volumes"
  - [Page 8, Table 4] AFP models show higher Dice (0.7496–0.7649 vs. 0.7244–0.7555) and lower HD95 (6.896–7.084 vs. 7.629–9.172) than L1-only variants in Task 1
  - [corpus] Neighbor papers use anatomical priors for segmentation (PCC tumor study), suggesting cross-domain validity of anatomy-aware losses
- Break condition: If the feature extractor was trained on a substantially different anatomical distribution, feature alignment may optimize for irrelevant structures.

### Mechanism 3
- Claim: Two-stage training (L1 pretraining → L1+AFP fine-tuning) stabilizes synthesis by decoupling intensity learning from anatomical refinement.
- Mechanism: L1 loss first establishes a coarse intensity mapping, providing stable initialization. AFP fine-tuning then refines anatomical boundaries. This curriculum avoids the instability of jointly optimizing conflicting objectives from scratch. The λL1 = 5.0 weighting maintains intensity fidelity during AFP refinement.
- Core assumption: L1 pretraining converges to a reasonable baseline; AFP fine-tuning does not catastrophically override learned intensities.
- Evidence anchors:
  - [Page 4] "AFP fine-tuning performed for 500 epochs using a combined L1+AFP objective"
  - [Page 6] "For AFP fine-tuning, the pretrained L1 loss models were further trained for 500 epochs with the combined L1+AFP objective and an updated learning rate of 0.001"
  - [corpus] No direct corpus evidence; curriculum/fine-tuning strategies common but not explicitly discussed in neighbors
- Break condition: If AFP weight is too high or fine-tuning too long, anatomical features may dominate at the expense of intensity calibration (observed as checkerboard artifacts in the paper).

## Foundational Learning

- **Concept: Residual learning in U-Nets**
  - Why needed here: Understanding why nnResU-Net adds skip connections at the block level (not just encoder-decoder) and how this differs from standard U-Net skip connections.
  - Quick check question: Can you explain why learning `output = input + residual` is easier than learning `output = f(input)` when input and target are structurally similar?

- **Concept: Perceptual/feature-based losses**
  - Why needed here: AFP is a variant of perceptual loss using a medical segmentation network as the feature extractor. Understanding why matching VGG/segmentation features differs from matching pixel intensities.
  - Quick check question: Why would minimizing L1 on feature maps improve Dice scores while slightly hurting MAE?

- **Concept: Patch-based 3D inference with overlap aggregation**
  - Why needed here: The paper uses overlapping patches (step size 0.3) aggregated by mean averaging. This affects boundary artifacts and GPU memory management.
  - Quick check question: What happens to reconstruction quality if step size increases from 0.3 to 0.7?

## Architecture Onboarding

- **Component map:**
  Input (MR/CBCT) → Normalization (z-score) → Patch Extraction
           ↓
  nnResU-Net Encoder (residual blocks) → Bottleneck
           ↓
  nnResU-Net Decoder (residual blocks + trilinear interp)
           ↓
  Patch Aggregation (mean, step=0.3) → Denormalization → sCT Output
           ↓
  [Training only] AFP Loss ← TS_Compact7_3x1x1 Feature Extractor

- **Critical path:** The residual block design (conv → instancenorm → leakyReLU → conv + skip) and AFP feature extractor compatibility are the highest-leverage components. Errors in residual connections or feature extractor input preprocessing will propagate globally.

- **Design tradeoffs:**
  - L1 vs. AFP: L1 optimizes intensity metrics (MAE/PSNR); AFP optimizes anatomical metrics (Dice/HD95). Choose based on clinical priority.
  - Standard vs. Residual U-Net: Residual improves gradient flow (~57M params vs. ~30M) but increases training time by ~43% (165s vs. 115s per epoch).
  - Step size: 0.3 reduces boundary artifacts but increases inference compute ~3× vs. 0.5.

- **Failure signatures:**
  - Checkerboard/staircase artifacts in AFP models → mitigated by replacing transposed convolutions with conv + trilinear interpolation.
  - Blurred bone structures in L1-only models → add AFP fine-tuning.
  - Misaligned structures → check registration preprocessing; manually remove severe cases.

- **First 3 experiments:**
  1. **Baseline verification:** Train nnU-Net with L1 loss only on HN dataset for 1000 epochs. Verify MAE, PSNR, and MS-SSIM match reported ranges (~63–64 MAE, ~29.7–29.8 PSNR).
  2. **AFP ablation:** Fine-tune baseline with L1+AFP (λL1=5.0) for 500 epochs. Confirm Dice improvement and MAE degradation. Visualize bone structure sharpness.
  3. **Residual comparison:** Train nnResU-Net with L1 from scratch on same data. Compare training stability (loss curves) and final metrics against standard U-Net baseline.

## Open Questions the Paper Calls Out
- Future work will focus on further artifact suppression, potentially by adapting the decoder architecture in nnResU-Net and exploring hybrid configurations such as residual encoders combined with standard U-Net decoders.

## Limitations
- Manual removal of misaligned cases (21-40 volumes per region) introduces potential selection bias
- Limited ablation studies for curriculum training strategy and residual block design choices
- Exact nnU-Net hyperparameter configuration and AFP loss implementation details remain unspecified

## Confidence
- **High**: Residual U-Net improves gradient flow and stability compared to standard U-Net (supported by architectural theory and training time evidence).
- **Medium**: AFP loss improves anatomical fidelity (Dice, HD95) at the cost of intensity metrics (MAE, PSNR) - well-supported by table data but limited ablation on feature layer selection.
- **Low**: Two-stage training (L1 pretraining + AFP fine-tuning) is necessary for stable optimization - reasonable but not rigorously tested against joint training from scratch.

## Next Checks
1. **Curriculum ablation**: Train a single model from scratch with combined L1+AFP loss (no pretraining) to test whether the two-stage approach is truly necessary.
2. **Feature extractor ablation**: Replace TS_Compact7_3x1x1 with a randomly initialized network to determine whether AFP benefits come from anatomical features or simply deeper feature matching.
3. **Residual block ablation**: Replace residual blocks with standard conv-norm-relu blocks in nnResU-Net to quantify the contribution of residual connections beyond the standard U-Net skip connections.