---
ver: rpa2
title: 'ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning
  LiDAR Sensors without Calibration Metadata'
arxiv_id: '2510.20708'
source_url: https://arxiv.org/abs/2510.20708
tags:
- point
- range
- sensor
- alice-lri
- lidar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ALICE-LRI addresses the problem of irreversible information loss
  in LiDAR range image generation caused by geometric inconsistencies in real-world
  sensors. The core method automatically infers sensor-specific intrinsic parameters
  (vertical/horizontal angles, offsets, resolutions) directly from calibrated point
  clouds without requiring manufacturer metadata.
---

# ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata

## Quick Facts
- arXiv ID: 2510.20708
- Source URL: https://arxiv.org/abs/2510.20708
- Reference count: 40
- One-line primary result: ALICE-LRI achieves perfect lossless projection with zero points lost by automatically inferring sensor-specific intrinsic parameters from calibrated point clouds

## Executive Summary
ALICE-LRI addresses the fundamental problem of irreversible information loss in LiDAR range image generation caused by geometric inconsistencies in real-world sensors. Traditional methods assume ideal sensor parameters, but manufacturing tolerances and calibration errors create mismatches that lead to lost or duplicated points during projection. ALICE-LRI automatically reverse-engineers the intrinsic geometry by inferring critical parameters including laser beam configuration, angular distributions, and per-beam calibration corrections directly from calibrated point clouds without requiring manufacturer metadata.

The method works by first estimating vertical parameters (laser angles and offsets) using a Hough Transform combined with Weighted Least Squares fitting and conflict resolution, then determining horizontal resolution through exhaustive search. This two-stage inference enables lossless forward projection to range images and perfect inverse reconstruction back to 3D point clouds. Comprehensive evaluation demonstrates zero point loss across all tested datasets, sub-millimeter geometric accuracy within sensor precision limits, and real-time performance suitable for practical applications including compression.

## Method Summary
ALICE-LRI is a two-stage algorithm that infers sensor-specific intrinsic parameters (vertical/horizontal angles, offsets, resolutions) directly from calibrated point clouds without requiring calibration metadata. The method first estimates vertical parameters using Hough Transform voting combined with Weighted Least Squares fitting and conflict resolution to identify individual laser scanlines. It then performs an exhaustive search over horizontal resolution candidates to minimize projection errors. These inferred parameters enable perfect bijective mapping between 3D points and 2D range image pixels, achieving zero point loss during projection and exact 3D reconstruction.

## Key Results
- Perfect lossless projection with zero point loss across all tested KITTI and DurLAR point clouds
- Sub-millimeter Chamfer distances (0.000-0.044mm) well within sensor precision limits
- Real-time performance with 25ms combined projection and reconstruction time
- Eliminates need for calibration metadata while maintaining geometric accuracy

## Why This Works (Mechanism)

### Mechanism 1: Inverse Intrinsic Parameter Inference
If sensor-specific intrinsic parameters are recovered from calibrated point clouds, projection mismatches caused by real-world manufacturing tolerances are eliminated. The algorithm isolates individual laser scanlines by identifying clusters in parameter space using Hough Transform, then fits a linearized model via Weighted Least Squares to estimate vertical angles and offsets per beam. Core assumption: geometric deviations are small relative to measured range and point density is sufficient to separate scanlines statistically.

### Mechanism 2: Residual Angular Correction
Estimated intrinsic parameters enable computation and subtraction of angular residuals, forcing observed angles to align with ideal discrete angular grids. This guarantees unique pixel indices for every point, enabling bijective mapping. Core assumption: coordinate quantization error can be estimated from data minimum spacing to define valid scanline membership regions.

### Mechanism 3: Conflict Resolution via Uncertainty Backtracking
Iterative consensus algorithm validates scanline candidates against global uncertainty scores, rejecting spurious detections from noise in favor of globally consistent solutions. The algorithm backtracks when rejecting scanlines, reintroducing previously discarded candidates that conflicted with rejected ones. Core assumption: valid scanlines have lower statistical uncertainty than artifacts from noise or quantization.

## Foundational Learning

- **Concept: Spherical Projection & Range Image**
  - Why needed: Method converts Cartesian points to spherical coordinates for 2D mapping
  - Quick check: Given point (0, 1, 0) meters, what are approximate azimuth and elevation angles, and where maps on 360° range image?

- **Concept: Weighted Least Squares (WLS)**
  - Why needed: Algorithm fits scanline parameters with heteroscedastic noise
  - Quick check: Why would ordinary least squares fail when points have varying coordinate uncertainty?

- **Concept: Hough Transform**
  - Why needed: Initialization step for finding scanlines through parameter space voting
  - Quick check: In Hough Transform for line detection, what do accumulator axes represent and how does a point create a pattern?

## Architecture Onboarding

- **Component map:** Input Point Cloud → Vertical Estimation (Hough Transform → WLS Fitter → Conflict Resolver) → Horizontal Estimation (Exhaustive Search → Loss Minimization) → Projection/Reconstruction Engine → Output Range Image + Intrinsics

- **Critical path:** Vertical Estimation Module is the bottleneck; accuracy depends on correctly identifying beam count and vertical parameters before horizontal estimation

- **Design tradeoffs:**
  - Accuracy vs Compute: Exhaustive horizontal resolution search is accurate but costlier than fixed-resolution methods
  - Robustness vs Complexity: Backtracking conflict resolution adds complexity but essential for sparse data
  - Assumption: Method assumes stable vertical offsets per device, doesn't model time-varying thermal drift

- **Failure signatures:**
  - High Sampling Error (>0%): Indicates parameter estimation failed or sensor model assumption violated
  - Fragmented Range Image: Horizontal gaps suggest incorrect angular resolution or azimuthal offset estimation
  - Scanline Count Mismatch: Reported beams ≠ sensor spec indicates Hough voting thresholds need adjustment

- **First 3 experiments:**
  1. Visual Validation Loop: Project KITTI frame to range image, unproject back to 3D, verify SE=0 by comparing clouds
  2. Parameter Sensitivity Test: Add Gaussian noise to input, plot degradation of estimated vertical angle accuracy vs noise magnitude
  3. Resolution Boundary Test: Synthetically reduce horizontal resolution, determine minimum points-per-scanline for >99% vertical estimator accuracy

## Open Questions the Paper Calls Out

- Can ALICE-LRI estimate intrinsic parameters and extrinsic motion corrections simultaneously for ego-motion corrected datasets?
- What quantitative improvements does lossless range image generation provide for downstream perception tasks like semantic segmentation and object detection?
- Can inferred parameters enable sensor-aware point cloud upsampling that generates physically consistent new points?
- What performance gains can be achieved through GPU acceleration and multi-threading of parallel projection operations?

## Limitations
- Assumes small geometric offsets and relies on linear approximation that may fail for sensors with extreme manufacturing defects
- Performance depends on sufficient point density per scanline (requires 64+ points per beam for DurLAR)
- Exhaustive horizontal resolution search has higher computational cost than fixed-resolution methods
- Does not account for time-varying thermal drift or motion distortion during single-scan acquisition

## Confidence
- **High Confidence:** Perfect lossless projection with zero point loss on KITTI and DurLAR datasets; sub-millimeter Chamfer distances within sensor precision limits
- **Medium Confidence:** Real-time performance claims (25ms combined) as exact implementation details may vary
- **Medium Confidence:** Conflict resolution mechanism effectiveness due to limited ablation studies (only two variants tested)

## Next Checks
1. Cross-Dataset Generalization: Test ALICE-LRI on Velodyne VLP-16 and Ouster OS1 datasets to verify performance across different beam counts and resolutions

2. Degradation Analysis: Systematically reduce point density per scanline (from 64+ to 32, 16, 8) and measure when vertical parameter estimation accuracy falls below 95%

3. Robustness to Manufacturing Defects: Introduce synthetic geometric distortions (10-50% of beam spacing) into perfect point clouds and measure when linear approximation breaks down