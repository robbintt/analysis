---
ver: rpa2
title: Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug
  Interactions
arxiv_id: '2511.06662'
source_url: https://arxiv.org/abs/2511.06662
tags:
- drugs
- precision
- fusion
- student
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of predicting drug-drug interactions
  (DDIs), particularly for unseen drugs where knowledge graphs (KGs) fail and electronic
  health records (EHRs) are noisy. The authors introduce a novel dual-pathway fusion
  framework that conditions KG relation scoring on patient-level EHR context and distills
  that reasoning into an EHR-only model for zero-shot inference.
---

# Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions

## Quick Facts
- **arXiv ID**: 2511.06662
- **Source URL**: https://arxiv.org/abs/2511.06662
- **Reference count**: 36
- **Primary result**: Dual-pathway fusion of EHRs and KGs improves precision and mechanism-specific reasoning for unseen drug-drug interaction prediction

## Executive Summary
This paper introduces a dual-pathway fusion framework to predict drug-drug interactions (DDIs) for both known and unseen drugs. Traditional knowledge graphs (KGs) fail for drugs not in the graph, while EHRs alone are noisy. The proposed approach uses a KG-based "Teacher" model conditioned on patient-level EHR context, and a distilled "Student" model that operates solely on EHR embeddings for zero-shot inference. Both models share a pharmacologic mechanism ontology, enabling interpretable, clinically consistent alerts. The framework is trained on multi-institution EHRs paired with DrugBank DDIs, and validated across institutions with precision gains and reduced false alerts.

## Method Summary
The method fuses two sources: a curated DrugBank KG for known drugs and multi-institution EHRs for real-world usage patterns. A fusion "Teacher" learns mechanism-specific relations for drugs represented in both sources, while a distilled "Student" generalizes to new or rarely used drugs without KG access at inference. Both models operate under a shared ontology of pharmacologic mechanisms to produce interpretable, auditable alerts. The framework uses cross-entropy loss to protect rare-mechanism recall, and is validated on multi-institution test data with precision, F1, and mechanism-specific analyses.

## Key Results
- Maintains precision across multi-institution test data, producing mechanism-specific, clinically consistent predictions
- Reduces false alerts (higher precision) at comparable overall detection performance (F1)
- Misses fewer true interactions compared to prior methods
- Case studies show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG

## Why This Works (Mechanism)
The dual-pathway design addresses the "known drug" vs "unknown drug" gap: KGs provide structured, interpretable relations but lack coverage for new compounds; EHRs offer real-world co-prescription patterns but are noisy and incomplete. By conditioning KG relation scoring on patient-level EHR context, the Teacher leverages both sources, while the Student distills this reasoning for zero-shot inference. The shared pharmacologic mechanism ontology ensures both models produce interpretable, clinically relevant alerts, and the distillation process preserves rare-mechanism recall by using cross-entropy loss.

## Foundational Learning
- **Knowledge Graph (KG) relation scoring**: Predicts interaction likelihoods using KG structure and EHR context. Needed to capture mechanism-specific DDIs for known drugs. Quick check: Validate Teacher's precision on KG-represented drugs.
- **EHR-derived drug embeddings**: Encodes co-prescription patterns from patient records. Needed to generalize to unseen drugs. Quick check: Evaluate Student's zero-shot performance.
- **Mechanism-specific ontology**: Maps DDIs to pharmacologically interpretable mechanisms. Needed for clinical interpretability. Quick check: Verify mechanism consistency in case studies.
- **Model distillation**: Transfers Teacher's reasoning to Student for zero-shot inference. Needed to maintain accuracy without KG at inference. Quick check: Compare Student vs Teacher on hold-out drugs.
- **Cross-entropy loss with rare-mechanism protection**: Preserves recall for infrequent but clinically important interactions. Needed to avoid missing true DDIs. Quick check: Analyze per-mechanism recall.
- **Multi-institution validation**: Tests generalization across hospitals. Needed for real-world applicability. Quick check: Compare precision/recall across institutions.

## Architecture Onboarding

**Component Map**: EHR records → Patient-level context → Teacher (KG + EHR) → Mechanism-specific relations; Teacher → Student (EHR-only) → Zero-shot DDI predictions

**Critical Path**: EHR data → Patient embeddings → Teacher conditioning → KG relation scoring → Distillation to Student → Zero-shot predictions

**Design Tradeoffs**: Teacher gains interpretability and mechanism-specificity at the cost of KG coverage; Student gains generalization but loses explicit KG reasoning. Distillation balances both.

**Failure Signatures**: KG coverage gaps → missed interactions in Teacher; noisy EHR patterns → false positives in Student; mechanism ontology mismatches → uninterpretable alerts.

**First 3 Experiments**:
1. Ablation: Teacher vs Student performance on KG-represented vs unseen drugs
2. Mechanism analysis: Per-mechanism recall and precision across models
3. Temporal validation: Student performance on future/past EHR data

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can uncertainty calibration and abstention mechanisms be integrated into the dual-pathway framework to improve reliability for high-stakes clinical deployment?
- **Basis in paper**: "Looking ahead, we aim to calibrate uncertainty and add abstention mechanisms to improve reliability"
- **Why unresolved**: The current system produces mechanism-specific alerts without confidence bounds or the ability to defer on uncertain predictions, which limits safety in bedside use.
- **What evidence would resolve it**: A study showing that adding calibrated uncertainty scores and an abstention option (e.g., routing low-confidence predictions to non-interruptive queues) improves clinician trust and reduces harmful missed interactions without increasing alert fatigue.

### Open Question 2
- **Question**: How does the distilled student model's performance decay or improve over time as drug usage patterns and co-prescription behaviors shift in EHR data?
- **Basis in paper**: "conduct external and temporal validation"; EHR embeddings are derived from temporal patient data, but no longitudinal analysis of model drift is reported.
- **Why unresolved**: The student relies on EHR-derived drug embeddings that reflect historical co-prescription patterns; changes in prescribing guidelines, new drug approvals, or seasonal variations may degrade zero-shot predictions.
- **What evidence would resolve it**: Temporal hold-out experiments where the student model is trained on earlier years and evaluated on later years, with metrics on precision/recall drift and comparison to periodic retraining schedules.

### Open Question 3
- **Question**: Can lightweight model editing techniques efficiently update the fusion teacher's KG embeddings when new drugs or relations are added, without full retraining?
- **Basis in paper**: "refresh KG structure and enable lightweight model editing over time"
- **Why unresolved**: The current pipeline requires retraining when DrugBank or similar KGs are updated; in production, frequent retraining may be computationally expensive and delay alert currency.
- **What evidence would resolve it**: Experiments applying model editing methods (e.g., hypernetwork-based updates, knowledge editing) to add new drug nodes or relations, measuring accuracy on edited entries versus retrained baselines and computational cost.

### Open Question 4
- **Question**: What is the optimal distillation temperature (τ) and loss weighting (α) for transferring mechanism-specific reasoning from the fusion teacher to the EHR-only student?
- **Basis in paper**: "optimize hyperparameters like distillation temperature (τ) through more ablation studies"; the paper fixes τ=1 and α=0.5 without systematic tuning.
- **Why unresolved**: Different temperatures may better preserve rare-mechanism recall (which BCE was chosen to protect) or improve student generalization; the current choice may be suboptimal.
- **What evidence would resolve it**: A grid search or Bayesian optimization over τ and α, evaluating student precision, F1, and per-mechanism recall on node hold-out splits, with analysis of how temperature affects rare versus common mechanism transfer.

## Limitations
- Performance gains primarily demonstrated on multi-institution EHR data; specific institutions and populations not fully characterized, limiting real-world applicability.
- KG coverage and accuracy for rare or novel drugs not quantified, introducing uncertainty in zero-shot predictions for truly unseen compounds.
- Distillation assumes stable EHR patterns; shifts in prescribing behavior or drug availability could degrade Student performance without retraining.

## Confidence
- **Precision and mechanism-specific prediction gains**: Medium confidence; limited external validation.
- **Zero-shot identification of clinically recognized mechanisms**: Low confidence; absence of blinded clinical expert review.
- **Generalizability across institutions and populations**: Medium confidence; need for broader external validation.

## Next Checks
1. Perform external validation on independent, diverse EHR datasets to assess robustness and generalizability.
2. Conduct blinded clinical expert review of mechanism-specific predictions to verify clinical consistency and validity.
3. Quantify and report the impact of KG coverage gaps on zero-shot prediction accuracy for rare and novel drugs.