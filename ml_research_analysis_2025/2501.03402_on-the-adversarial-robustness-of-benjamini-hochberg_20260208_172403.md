---
ver: rpa2
title: On the Adversarial Robustness of Benjamini Hochberg
arxiv_id: '2501.03402'
source_url: https://arxiv.org/abs/2501.03402
tags:
- p-values
- then
- adversarial
- which
- alternative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the adversarial robustness of the Benjamini-Hochberg
  (BH) multiple testing procedure for controlling false discovery rate (FDR). The
  authors present algorithms (INCREASE-c and MOVE-1) that strategically perturb p-values
  to significantly break BH's FDR control, even with minimal budget (e.g., c=1 or
  c=5).
---

# On the Adversarial Robustness of Benjamini Hochberg

## Quick Facts
- arXiv ID: 2501.03402
- Source URL: https://arxiv.org/abs/2501.03402
- Reference count: 40
- Primary result: BH procedure can be broken via strategic p-value perturbations with minimal budget

## Executive Summary
This paper demonstrates that the Benjamini-Hochberg (BH) procedure for controlling false discovery rate (FDR) is highly vulnerable to adversarial manipulation. The authors present algorithms that strategically perturb p-values to significantly break FDR control, even with minimal perturbation budgets. Through theoretical analysis and computational experiments on both synthetic and real data (credit card fraud detection), they show that BH is particularly vulnerable when alternative hypotheses are not strongly separated from null hypotheses. The results suggest caution is needed when using BH in safety/security-critical applications where adversarial corruption is possible.

## Method Summary
The paper presents two algorithms (INCREASE-c and MOVE-1) that strategically perturb p-values to break BH's FDR control. INCREASE-c identifies the current rejection threshold and moves null p-values from the non-rejection zone to artificially inflate the stopping time. The method uses a combinatorial "balls into bins" framework that transforms the continuous testing problem into a discrete counting process, allowing precise analysis of the procedure's robustness. Experiments use N=1000 p-values (900 null, 100 alternatives) with varying signal strength μ₁ ∈ {0,1,2}, and test the algorithms on synthetic data, credit card fraud detection, and PRDS conformal p-values.

## Key Results
- Small perturbations (c=1 or c=5) can significantly increase FDR beyond the controlled level
- BH is most vulnerable when alternative distributions are close to null distributions (low signal strength)
- The INCREASE-c algorithm can force FDP to approach 1 when the natural rejection count is near zero
- Real-world credit card fraud data shows similar vulnerability patterns to synthetic experiments

## Why This Works (Mechanism)

### Mechanism 1: Balls into Bins Combinatorial Reframing
The paper reinterprets BH as a "balls into bins" stopping time problem, partitioning [0,1] into N ordered bins where the rejection threshold is the largest index i where cumulative count equals i. This transforms continuous testing into discrete counting, allowing precise combinatorial analysis of robustness under PRDS assumptions.

### Mechanism 2: Strategic Injection via INCREASE-c
An adversary can break FDR control by moving null p-values from the non-rejection zone into specific rejection bins to artificially inflate the stopping time. The algorithm calculates a target threshold and forces the BH procedure to reject the injected nulls, increasing FDP.

### Mechanism 3: Exploiting Low Sub-Uniformity
BH is most vulnerable when alternatives are statistically close to nulls (small effect size). The attack exploits this by forcing rejection expansion from 0 to c, capturing almost exclusively adversarially injected nulls when signal is weak, resulting in FDP ≈ 1.

## Foundational Learning

- **Concept: False Discovery Rate (FDR) & Proportion (FDP)**: Understanding the difference between the random variable (FDP) and its expectation (FDR) is essential for grasping the attack's objective of maximizing FDP.
  - Quick check: If a procedure rejects 10 hypotheses and 9 are actually null, what is the FDP? (Answer: 0.9)

- **Concept: Step-Up Multiple Testing Procedures**: BH is a "step-up" procedure that dynamically determines the rejection region based on sorted p-values, making it sensitive to boundary perturbations.
  - Quick check: In a step-up procedure, does a larger rejection count R_p generally imply a larger p-value threshold? (Answer: Yes)

- **Concept: Stopping Times & Martingales**: The BH threshold is re-framed as a stopping time of a martingale sequence, allowing theoretical guarantees through the Optional Stopping Theorem.
  - Quick check: Why is the "stopping time" concept useful here? (Answer: It allows predicting the expected value of the threshold under perturbations using martingale properties)

## Architecture Onboarding

### Component Map
Input p-values → Bins (discrete partitioning) → BH Engine (cumulative counting) → Adversary (INCREASE-c/MOVE-1) → Perturbed p-values

### Critical Path
1. Bin Loading: Calculate B^N_j for all bins
2. Stopping Time Calculation: Find initial k̃ where B^N_{1:k̃} = k̃
3. Target Identification: Compute post-perturbation k̃⁺_c
4. Perturbation Execution: Shift c null p-values to target bin

### Design Tradeoffs
INCREASE-c is simple but sub-optimal (only increases rejection count), while MOVE-1 is optimal for c=1 but requires full reverse pass. Omniscient adversary provides theoretical bounds but oblivious versions exist with larger budget requirements.

### Failure Signatures
- High Signal (μ₁ large): Attack requires large c to achieve significant FDP
- Empty Non-Rejection Zone: If B⁰_{N+1} < c, algorithm fails to execute
- Strong Alternatives: Natural rejection region already saturated with true alternatives

### First 3 Experiments
1. Verify "Balls into Bins" mapping: Implement binning logic and compare analytical vs. simulation probabilities
2. INCREASE-c Sensitivity Analysis: Test varying μ₁ and c values to confirm "Low Sub-Uniformity" vulnerability
3. MOVE-1 vs. INCREASE-1 Benchmark: Compare FDP and perturbation magnitude for both algorithms

## Open Questions the Paper Calls Out

### Open Question 1
Do other step-up multiple testing procedures exhibit similar vulnerabilities to adversarial p-value perturbations as the Benjamini-Hochberg procedure? The conclusion states BH is one member of a family of step-up procedures that can be similarly prone, but the analysis was specific to BH.

### Open Question 2
How does the INCREASE-c algorithm perform when implemented by an oblivious adversary who lacks knowledge of the null/alternative hypothesis partition? Section 1.4 notes the omission of explicit analysis for this scenario despite mentioning the algorithm can be modified.

### Open Question 3
Can the Benjamini-Hochberg procedure be modified or combined with robust estimation techniques to maintain FDR control under the c-Perturbation threat model? The paper demonstrates the attack surface but doesn't propose defensive mechanisms.

## Limitations
- The omniscient adversary assumption significantly overestimates practical vulnerability as real-world adversaries lack perfect knowledge of null/alternative labels
- Theoretical bounds rely heavily on PRDS assumption which may not hold for dependent p-values common in practice
- Discrete binning approximation introduces potential errors that could affect precise quantitative predictions

## Confidence

- **High Confidence**: BH is vulnerable to strategic p-value perturbations under idealized conditions (well-supported by theory and evidence)
- **Medium Confidence**: Specific quantitative predictions for FDP increases are moderately reliable for synthetic data with independent p-values
- **Low Confidence**: Practical implications for safety-critical systems remain uncertain due to unaddressed knowledge requirements

## Next Checks

1. **Dependence Analysis**: Evaluate BH vulnerability under realistic dependence structures (block correlations, time series) that violate PRDS assumptions

2. **Practical Attack Feasibility**: Design simulation where adversary must infer null/alternative labels from partial observations to quantify knowledge limitations

3. **Alternative Procedures**: Test whether proposed adversarial algorithms can compromise other FDR-controlling procedures (Storey's q-value, adaptive BH) to determine if vulnerability is specific to BH or inherent to FDR control