---
ver: rpa2
title: The Cost of Shuffling in Private Gradient Based Optimization
arxiv_id: '2502.03652'
source_url: https://arxiv.org/abs/2502.03652
tags:
- private
- gradient
- priv
- privacy
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the privacy-accuracy trade-offs of private\
  \ shuffled gradient methods (DP-ShuffleG) for convex empirical risk minimization.\
  \ The authors provide the first empirical excess risk bound showing that DP-ShuffleG\
  \ has worse performance compared to DP-SGD, with an excess risk of O(1/n^{2/3}(d/\u03F5\
  )^{4/3}) versus the lower bound of \u03A9(\u221Ad/n\u03F5) for DP-SGD."
---

# The Cost of Shuffling in Private Gradient Based Optimization

## Quick Facts
- **arXiv ID:** 2502.03652
- **Source URL:** https://arxiv.org/abs/2502.03652
- **Reference count:** 40
- **Primary result:** DP-ShuffleG has worse privacy-accuracy trade-offs than DP-SGD (excess risk O(1/n^{2/3}(d/ϵ)^{4/3}) vs lower bound Ω(√d/nϵ)), but Interleaved-ShuffleG improves performance by leveraging public data.

## Executive Summary
This paper studies the privacy-accuracy trade-offs of private shuffled gradient methods (DP-ShuffleG) for convex empirical risk minimization. The authors prove that DP-ShuffleG suffers from worse convergence rates than DP-SGD due to the privacy amplification by iteration (PABI) mechanism, which provides insufficient privacy benefits compared to Poisson subsampling. To address this limitation, they propose Interleaved-ShuffleG, which interleaves private and public samples within each epoch. The method achieves better empirical excess risk by effectively using PABI and reducing dissimilarity between surrogate and true objectives. Experiments on diverse datasets demonstrate Interleaved-ShuffleG's superior performance compared to several baselines including DP-ShuffleG.

## Method Summary
The paper analyzes generalized shuffled gradient descent for differentially private convex ERM. The core algorithm processes data in epochs using random permutations, adding Gaussian noise to gradients computed on private samples while processing public samples without noise. The key innovation is Interleaved-ShuffleG, which processes all private samples first within an epoch, followed by all public samples. This ordering maximizes privacy amplification by iteration since the differing private sample is processed early and followed by many public steps. The method applies regularization only once per epoch via a proximal operator to maintain theoretical convergence properties. Privacy accounting uses Renyi differential privacy with PABI bounds, while convergence analysis tracks excess risk with terms for optimization error, noise injection, and dissimilarity between public and private objectives.

## Key Results
- DP-ShuffleG has excess risk O(1/n^{2/3}(d/ϵ)^{4/3}) versus DP-SGD's lower bound Ω(√d/nϵ)
- Interleaved-ShuffleG improves upon DP-ShuffleG by a factor of 1/(n+1-n_d) due to better PABI utilization
- Experiments on MNIST-69, CIFAR-10, Crime, COMPAS, and CreditCard datasets validate theoretical findings
- The method outperforms block-wise public-private training approaches (Priv-Pub-ShuffleG, Pub-Priv-ShuffleG)

## Why This Works (Mechanism)

### Mechanism 1: Privacy Amplification by Iteration in Shuffling
DP-ShuffleG leverages privacy amplification by iteration (PABI) by releasing only the final model iterate after an epoch. Under this mechanism, the privacy cost of processing a sample at step j decays with the number of subsequent steps (n-j+1) due to the contractive nature of gradient descent. This allows bounding the Renyi Divergence by approximately 1/(n-j+1). However, unlike Poisson subsampling, this amplification is insufficient to match the optimal O(√d/nϵ) rate of DP-SGD, resulting in the derived O(n^{-2/3}) rate. The core assumption is that the loss function is convex and smooth, and the learning rate η ≤ 1/L ensures gradient steps are contractive.

### Mechanism 2: Interleaving for Enhanced Privacy Amplification
Interleaved-ShuffleG interleaves public samples after private samples within an epoch to reduce noise requirements more effectively than block-wise training. By processing private samples first (steps 1 to n_d), the differing private sample is followed by n-n_d public steps, maximizing the privacy amplification distance. This reduces the noise variance requirement by a factor of 1/(n-n_d+1) compared to methods with separate private and public blocks. The core assumption is that the public dataset P is related to the private dataset D, such that optimizing over P improves the objective on D with bounded dissimilarity.

### Mechanism 3: Epoch-Wise Regularization for Convergence
Applying regularization only once per epoch, rather than at every step, is critical for theoretical convergence in shuffled methods. Shuffled gradient methods approximate the full gradient over the entire dataset before taking a true step towards the optimum. Applying regularization/projection after every gradient step destroys this approximation property, preventing convergence to the true optimum of the regularized objective. By accumulating gradients and applying the proximal operator only at the end of the epoch, the algorithm maintains the theoretical properties required for convergence. The core assumption is that the regularization function ψ is convex (e.g., ℓ₂ norm).

## Foundational Learning

- **Concept: Differential Privacy (DP-SGD vs. DP-ShuffleG)** - Why needed: The paper's core contribution is analyzing the trade-off between these two. Standard DP-SGD uses Poisson subsampling for amplification, while ShuffleG uses random permutation with PABI. Quick check: Does random reshuffling provide the same privacy amplification as Poisson subsampling? (Answer: No, it relies on different mechanisms).

- **Concept: Excess Risk and Convergence Rates** - Why needed: The paper compares utility via excess risk bounds (e.g., O(n^{-2/3}) vs O(n^{-1})). Understanding these rates helps judge the severity of shuffling's cost. Quick check: If Algorithm A has excess risk O(n^{-2/3}) and Algorithm B has O(n^{-1}), which is better for large n?

- **Concept: Last-Iterate vs. Average-Iterate Convergence** - Why needed: PABI relies on hiding intermediate steps and releasing only the final step, forcing analysis to focus on last-iterate convergence. Many standard analyses use averaging, which is incompatible with this privacy definition. Quick check: Why does analyzing the average of iterates create problems for privacy in this context?

## Architecture Onboarding

- **Component map:** Input datasets (D, P) -> Permutation generation -> Inner loop (Private samples with noise → Public samples without noise) -> Gradient updates -> Epoch end (Proximal regularization) -> Output final model

- **Critical path:** The most sensitive parts are noise injection and regularization timing. Noise must be calibrated correctly using PABI accounting, and regularization must be deferred to the epoch end. The "Private-First" ordering is the key architectural feature of Interleaved-ShuffleG.

- **Design tradeoffs:**
  - Private ratio (p): Increasing p improves optimization on the target objective but increases noise requirements. Decreasing p reduces noise but increases dissimilarity error if public data isn't perfect.
  - Regularization timing: Standard frameworks apply weight decay every step, but this must be disabled to apply only at the epoch end to match the paper's theory.

- **Failure signatures:**
  - Divergence: If regularization is applied every step, the model may not converge or may violate PABI assumptions.
  - Privacy underestimation: If PABI accounting is used but intermediate checkpoints are saved, the privacy guarantee is invalid.
  - Public data mismatch: If P differs drastically from D, the dissimilarity term grows and performance may degrade below the private-only baseline.

- **First 3 experiments:**
  1. Sanity check: Implement proximal step at epoch end vs every step on logistic regression to verify convergence behavior.
  2. Ablation on interleaving: Compare Interleaved-ShuffleG against Priv-Pub-ShuffleG on MNIST-69 to validate PABI amplification claims.
  3. Noise sensitivity: Measure empirical excess risk while varying ε to see if the O(n^{-2/3}ϵ^{-4/3}) trend holds experimentally for DP-ShuffleG.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the non-vanishing error terms caused by noise injection be eliminated when using non-differentiable regularizers, specifically ℓ₁ regularization or projection operators? The authors state this additional nB term cannot be eliminated under these conditions, but leave it as an open question whether this can be resolved.

- **Open Question 2:** Can the privacy loss bound for Random Reshuffling (RR) be significantly tightened to scale with 1/n without imposing additional assumptions? The appendix remarks that deriving a significantly smaller privacy loss bound in the RR setting is unlikely without additional assumptions.

- **Open Question 3:** Do the established privacy-convergence trade-offs for DP-ShuffleG extend to non-convex optimization landscapes common in deep learning? The paper limits its theoretical analysis to convex ERM but notes practical implementations are often used for deep learning where convexity assumptions do not hold.

## Limitations

- The PABI analysis assumes full gradient descent without mini-batching, which may not hold in practical implementations.
- The dissimilarity term C^n_part is theoretically bounded but may be difficult to estimate in practice, potentially affecting the claimed improvements of Interleaved-ShuffleG.
- Experiments validate claims but are limited to specific datasets and tasks, with generalization to other domains remaining uncertain.

## Confidence

- **High Confidence:** The mechanism of PABI and its role in DP-ShuffleG's convergence rate (Mechanism 1).
- **Medium Confidence:** The superiority of Interleaved-ShuffleG over block-wise approaches (Mechanism 2), supported by experiments but with some theoretical gaps.
- **Medium Confidence:** The necessity of applying regularization only once per epoch (Mechanism 3), with strong theoretical reasoning but potential implementation complexity.

## Next Checks

1. Implement the full Renyi DP accountant with PABI for DP-ShuffleG and verify the theoretical noise scaling against empirical privacy leakage measurements.

2. Systematically vary the quality of public data (increasing dissimilarity) to empirically measure when Interleaved-ShuffleG degrades below the private-only baseline.

3. Extend the theoretical analysis to mini-batch settings and validate whether the O(n^{-2/3}) rate persists or degrades under practical implementation constraints.