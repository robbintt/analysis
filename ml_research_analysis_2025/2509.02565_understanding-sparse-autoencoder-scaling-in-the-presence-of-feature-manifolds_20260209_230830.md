---
ver: rpa2
title: Understanding sparse autoencoder scaling in the presence of feature manifolds
arxiv_id: '2509.02565'
source_url: https://arxiv.org/abs/2509.02565
tags:
- feature
- scaling
- latents
- saes
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies how sparse autoencoders (SAEs) scale when neural
  activations contain multi-dimensional features (feature manifolds). The authors
  adapt a capacity-allocation model from neural scaling theory to understand SAE scaling
  behavior.
---

# Understanding sparse autoencoder scaling in the presence of feature manifolds

## Quick Facts
- arXiv ID: 2509.02565
- Source URL: https://arxiv.org/abs/2509.02565
- Reference count: 40
- Primary result: SAEs can optimally allocate latents to tiling common feature manifolds rather than discovering rarer features when per-feature loss decay rate β is less than feature frequency decay rate α, potentially causing sublinear feature discovery scaling

## Executive Summary
This paper investigates how sparse autoencoders (SAEs) scale when neural activations contain multi-dimensional features (feature manifolds). The authors adapt a capacity-allocation model from neural scaling theory to understand SAE scaling behavior. Their analysis reveals a critical threshold: when the rate at which loss decreases on common feature manifolds (β) is less than the rate at which feature frequencies decay (α), SAEs can optimally allocate most latents to tiling these common manifolds rather than discovering rarer features. This leads to pathological scaling where the number of discovered features grows sublinearly with SAE width. Through experiments on synthetic manifolds, they find that SAEs can indeed reduce loss by tiling certain manifold geometries, though they do not necessarily do this in more realistic settings with radial variation.

## Method Summary
The authors model SAE optimization as a latent allocation problem across features with power-law frequency distributions. Under assumptions of feature-specific latents, orthogonal feature subspaces, and decoder respect for subspaces, the total expected loss decomposes as a sum over features. They analyze two scaling regimes based on the relationship between α (feature frequency decay) and β (per-feature loss decay): when α < β, loss scales as N^{-α} with constant feature discovery rate; when β < α, loss scales as N^{-β} with sublinear feature discovery. Synthetic experiments on hyperspheres and spherical shells with ReLU and JumpReLU SAEs demonstrate that manifold geometry determines whether pathological tiling occurs.

## Key Results
- Theoretical framework identifies two scaling regimes based on α vs. β relationship
- When β < α, SAEs allocate latents to common manifolds at expense of feature discovery
- Synthetic experiments show SAEs can tile hyperspheres but not spherical shells with radial variation
- Real feature manifold geometries and frequency distributions remain unknown

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAE optimization reduces to a latent allocation problem across features
- Mechanism: Under assumptions of feature-specific latents, orthogonal feature subspaces, and decoder respect for subspaces, the total expected loss decomposes as E_x[L(x)] = Σ_i p_i L_i(n_i), where p_i is feature frequency and n_i is latents allocated to feature i
- Core assumption: Features live in orthogonal subspaces; each latent fires only when its associated feature is active
- Evidence anchors:
  - [Section 2.2]: "We assume that SAEs learn solutions where each latent j is specific to a particular feature i"
  - [Appendix B.1]: Full derivation showing loss decomposition under orthogonality assumptions
  - [corpus]: Weak direct evidence—related SAE work (Transcoders Beat SAEs, SAIF) does not challenge this decomposition but also does not validate orthogonality in practice
- Break condition: Feature absorption, non-orthogonal features, or superposition violate assumptions; real SAEs may not satisfy the decomposition

### Mechanism 2
- Claim: Manifold geometry determines whether SAEs tile or discover new features
- Mechanism: Per-feature loss curves L_i(n_i) depend on manifold geometry. For hollow hyperspheres, loss decays gradually (β ≈ 0.05 for dim 6-8), allowing many latents to reduce loss. For manifolds with radial variation, loss plateaus after ~2d_i latents (forming a signed basis), preventing pathological tiling
- Core assumption: The per-feature loss follows an approximate power law L(n) ∝ n^{-β} within the scaling regime
- Evidence anchors:
  - [Section 3, Figure 3]: ReLU SAEs on hyperspheres show gradual L(n) scaling; spherical shells plateau quickly
  - [Section A.1]: "when there is variation in the radial direction...manifolds tend to saturate very quickly"
  - [corpus]: Engels et al. (referenced as [22]) observed radial variation in real features—supports benign regime hypothesis
- Break condition: If real feature manifolds have different geometries (e.g., "ripples" through many dimensions), scaling behavior may differ from toy experiments

### Mechanism 3
- Claim: Two scaling regimes exist based on the relationship between α (feature frequency decay) and β (per-feature loss decay)
- Mechanism: When α < β, loss scales as N^{-α} and D(N)/N → constant (benign). When β < α, loss scales as N^{-β} and D(N) ∝ N^{(1+β)/(1+α)}, so D(N)/N → 0 (pathological)—latents accumulate on common manifolds at the expense of feature discovery
- Core assumption: Feature frequencies follow p_i ∝ i^{-(1+α)}; per-feature losses follow L_i(n) ∝ n^{-β}
- Evidence anchors:
  - [Section 2.5, Figure 2 left]: Mathematical derivation of both regimes following Brill (2024)
  - [Section 2.6, Figure 2 right]: Numerical simulation shows single power-law feature absorbing majority of latents when β < α
  - [corpus]: No direct empirical validation in related work; the regime question remains open
- Break condition: Real feature distributions may not follow clean power laws; heterogeneous L_i(n_i) curves complicate the binary regime classification

## Foundational Learning

- Concept: **Sparse Autoencoders (SAEs)**
  - Why needed here: The entire paper models SAE scaling behavior; understanding the encoder-decoder architecture, sparsity penalties (L1/L0), and reconstruction loss is prerequisite
  - Quick check question: Can you explain why an SAE with L1 penalty might prefer many sparsely-firing latents over fewer densely-firing ones for the same reconstruction quality?

- Concept: **Power Law Distributions**
  - Why needed here: Both feature frequencies (α) and per-feature loss curves (β) are modeled as power laws; the α vs. β comparison determines scaling regime
  - Quick check question: If p_i ∝ i^{-1.5}, what fraction of total probability mass is in the first 10 features vs. the next 100?

- Concept: **Manifold Learning/Geometry**
  - Why needed here: Feature manifolds are multi-dimensional features; their geometry (hollow sphere vs. shell with radial variation) determines whether tiling occurs
  - Quick check question: Why would a hollow sphere allow more latents to reduce loss than a thick shell?

## Architecture Onboarding

- Component map:
  - Data model: Activations x = Σ_i S_i f_i where S_i is subspace matrix, f_i is sparse feature activation
  - SAE encoder: f̂ = σ(W_e x + b_e) with ReLU or JumpReLU nonlinearity
  - SAE decoder: x̂ = W_d f̂ + b_d
  - Loss: L = ||x - x̂||² + λ||f̂||₁ (or other sparsity penalty)
  - Allocation problem: Choose n_i for each feature i subject to Σn_i = N to minimize Σp_i L_i(n_i)

- Critical path:
  1. Identify feature manifold geometries in real data (currently unknown)
  2. Measure per-feature loss curves L_i(n_i) to estimate β
  3. Measure feature frequency distribution to estimate α
  4. Compare α vs. β to determine if pathological scaling is occurring

- Design tradeoffs:
  - Higher L1 penalty λ → more sparsity but potentially more tiling behavior
  - More latents N → lower loss but D(N)/N may decrease if β < α
  - ReLU vs. JumpReLU: Both show similar tiling behavior on synthetic manifolds (Figure 3 vs. Figure 6)

- Failure signatures:
  - Many latents with high cosine similarity (>0.97) to nearest neighbor suggests potential tiling
  - Feature discovery count D(N) growing sublinearly with N indicates pathological regime
  - Loss scaling as N^{-β} rather than N^{-α} suggests manifold-dominated scaling

- First 3 experiments:
  1. **Synthetic manifold validation**: Train SAEs on controlled manifolds (circles, spheres, shells) with known geometry; measure L(n) curves to confirm β depends on radial variation presence
  2. **Real SAE geometry analysis**: Compute decoder latent nearest-neighbor cosine similarity distributions for existing SAEs (Gemma Scope, etc.); identify if meaningful fractions have very high similarity (>0.97) beyond dead latent artifacts
  3. **Feature discovery scaling measurement**: For SAEs of varying widths (16k, 32k, 65k, etc.), measure how D(N) (number of features discovered) scales with N; check if D(N)/N is decreasing or constant

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are SAEs trained on real neural network activations in the pathological scaling regime where β < α, causing sublinear feature discovery as latent count increases?
- Basis in paper: [explicit] "Unfortunately, we do not resolve the question of whether SAEs are in this pathological scaling regime in practice."
- Why unresolved: The authors lack knowledge of both the true feature frequency distribution (determining α) and real feature manifold geometries (determining β)
- What evidence would resolve it: Empirical measurement of α from true feature frequencies and β from per-feature loss curves on real neural networks, or demonstration that D(N)/N approaches a constant vs. zero as N scales

### Open Question 2
- Question: What is the true value of α (the feature frequency decay exponent) for features in real LLM and vision model activations?
- Basis in paper: [explicit] "Our uncertainty is due to our knowing neither the distribution over true feature frequencies (determining α)..."
- Why unresolved: Measured SAE latent activation frequencies may not reflect true feature frequencies due to feature absorption, compositional features, and manifold tiling distorting the relationship
- What evidence would resolve it: Independent characterization of ground-truth feature frequencies in neural activations, or methods to correct SAE latent frequency measurements for known distortions

### Open Question 3
- Question: Do real feature manifolds in neural networks have geometries that allow SAEs to tile them with many latents (slow β decay) or do they saturate quickly like manifolds with radial variation?
- Basis in paper: [explicit] "If this geometry is realistic [manifolds with radial variation], then manifolds may not pose an issue to SAE scaling in practice."
- Why unresolved: Experiments show different geometries yield vastly different β values, but the actual geometry of real feature manifolds in neural networks is unknown
- What evidence would resolve it: Characterization of real feature manifold geometries in trained networks, or empirical measurement of β from SAE scaling on isolated real features

### Open Question 4
- Question: What fraction of high cosine-similarity latent pairs in real SAEs represent genuine manifold tiling versus training artifacts or feature duplication?
- Basis in paper: [inferred] The authors find latents with high neighbor cosine similarity but note "the extent remains unclear" and that some may be dead latents or duplicates from L1 training
- Why unresolved: The high cosine similarity could indicate manifold tiling, but could also result from training dynamics, dead latents, or lack of duplication penalty in L1 loss
- What evidence would resolve it: Analysis of whether high-similarity latent pairs both fire on similar inputs and reconstruct points along a coherent manifold, versus having different activation patterns

## Limitations
- The paper cannot determine whether pathological scaling (β < α) exists in real SAE applications due to unknown feature manifold geometries and frequency distributions
- Strong assumptions about orthogonality, feature-specific latents, and power-law distributions may not hold in practice
- No empirical evidence from real neural network activations showing the predicted scaling behavior

## Confidence
**High confidence**: The theoretical framework for capacity allocation under the stated assumptions is mathematically sound (Section 2.2-2.5). The derivation that loss decomposes into Σ p_i L_i(n_i) under orthogonality assumptions is rigorous.

**Medium confidence**: The synthetic experiments demonstrating that SAEs can reduce loss by tiling certain manifold geometries (hyperspheres) are well-executed and reproducible. The observation that hollow spheres allow more latents to reduce loss than shells with radial variation is clearly demonstrated.

**Low confidence**: The claim that pathological scaling regimes exist in practice remains speculative. While the theory predicts such regimes when β < α, there is no empirical evidence from real neural network activations showing this behavior. The paper raises this as an open question rather than a demonstrated finding.

## Next Checks
1. **Measure feature geometry in real SAEs**: Analyze existing SAE solutions (e.g., from Gemma Scope, Transcoders) to estimate per-feature loss curves L_i(n_i) and determine β empirically. This requires training SAEs with varying widths and measuring how loss scales with latents per feature.

2. **Analyze feature frequency distributions**: Estimate α from real neural activations by measuring how feature frequencies decay. This involves identifying features (through clustering or other methods) and measuring their empirical frequency distribution to see if it follows a power law.

3. **Test for pathological scaling signatures**: Examine real SAEs for signatures of the pathological regime, such as decoder latent cosine similarity distributions showing many latents with very high similarity (>0.97) beyond dead latent artifacts, and feature discovery count D(N) growing sublinearly with SAE width N.