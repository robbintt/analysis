---
ver: rpa2
title: 'TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South
  African Languages'
arxiv_id: '2512.02799'
source_url: https://arxiv.org/abs/2512.02799
tags:
- sentiment
- languages
- lexicon
- multilingual
- african
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces TriLex, a three-stage retrieval-augmented
  framework for sentiment lexicon expansion in low-resource African languages. The
  method combines corpus-based extraction, cross-lingual mapping, and RAG-driven refinement
  to build multilingual sentiment lexicons.
---

# TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages

## Quick Facts
- **arXiv ID:** 2512.02799
- **Source URL:** https://arxiv.org/abs/2512.02799
- **Reference count:** 40
- **Primary result:** TriLex framework builds sentiment lexicons for low-resource African languages; AfroXLMR achieves F1-scores above 80% on isiXhosa and isiZulu sentiment tasks.

## Executive Summary
TriLex is a three-stage framework designed to expand sentiment lexicons for low-resource African languages, specifically targeting isiXhosa and isiZulu. The method combines corpus-based extraction, cross-lingual mapping, and RAG-driven refinement to build multilingual sentiment lexicons. Using the expanded lexicon, AfroXLMR and AfriBERTa models are evaluated on isiXhosa and isiZulu sentiment tasks. The framework demonstrates strong performance improvements over prior benchmarks and shows potential for scalable multilingual sentiment analysis in under-resourced African languages.

## Method Summary
The TriLex framework employs a three-stage retrieval-augmented approach for sentiment lexicon expansion. First, corpus-based extraction identifies candidate sentiment-bearing terms from monolingual data. Second, cross-lingual mapping aligns these terms with English seed words using translation resources. Third, RAG-driven refinement filters and validates expanded entries using context-aware retrieval. The expanded lexicon is then used to fine-tune AfroXLMR and AfriBERTa models for sentiment classification in isiXhosa and isiZulu, with ensemble methods further improving precision and robustness.

## Key Results
- AfroXLMR achieves F1-scores above 80% on isiXhosa and isiZulu sentiment classification
- AfriBERTa reaches around 64% F1 despite lacking pre-training on these languages
- Ensemble learning improves precision and robustness compared to individual models

## Why This Works (Mechanism)
The framework leverages multiple complementary approaches to overcome data scarcity in low-resource languages. Corpus-based extraction captures language-specific sentiment expressions, while cross-lingual mapping transfers knowledge from high-resource languages. RAG refinement ensures semantic coherence of expanded entries. The combination of lexicon expansion with pre-trained multilingual models (AfroXLMR, AfriBERTa) provides both linguistic specificity and generalization capabilities.

## Foundational Learning

**Cross-lingual sentiment mapping**: Why needed - transfers sentiment knowledge from high-resource to low-resource languages. Quick check - verify alignment accuracy between source and target language sentiment terms.

**RAG-driven refinement**: Why needed - ensures semantic coherence of expanded lexicon entries. Quick check - measure precision of retrieved context matches for validation.

**Ensemble learning for sentiment classification**: Why needed - combines model strengths to improve overall performance. Quick check - evaluate precision gains from ensemble vs individual models.

## Architecture Onboarding

**Component map**: Corpus extraction -> Cross-lingual mapping -> RAG refinement -> Lexicon expansion -> Model fine-tuning (AfroXLMR/AfriBERTa) -> Ensemble classification

**Critical path**: Lexicon expansion (TriLex stages 1-3) -> Model fine-tuning -> Ensemble classification

**Design tradeoffs**: English seed word dependency vs cultural specificity; computational cost of RAG refinement vs lexicon quality; model size vs performance in resource-constrained settings

**Failure signatures**: Lexicon entries misaligned with cultural context; RAG refinement introduces semantic drift; ensemble methods degrade performance due to conflicting predictions

**3 first experiments**: 1) Validate expanded lexicon entries against native speaker judgments. 2) Compare performance across different ensemble configurations. 3) Test framework on out-of-domain text types.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Validation dataset limited to 1,000 manually labeled tweets per language
- Binary sentiment classification only; fine-grained sentiment categories not explored
- Cross-lingual mapping may introduce bias from English cultural perspectives

## Confidence
- **High** for lexicon expansion methodology and AfroXLMR performance
- **Medium** for AfriBERTa performance given lack of pre-training on target languages
- **Medium** for ensemble approach improvements without ablation studies

## Next Checks
1. Test expanded lexicon on out-of-domain datasets to assess robustness beyond social media text
2. Conduct qualitative linguistic validation of expanded sentiment entries in isiZulu and isiXhosa
3. Evaluate framework performance on multi-class sentiment classification tasks