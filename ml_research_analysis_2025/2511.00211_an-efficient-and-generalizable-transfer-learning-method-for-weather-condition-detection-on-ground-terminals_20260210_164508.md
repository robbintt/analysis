---
ver: rpa2
title: An Efficient and Generalizable Transfer Learning Method for Weather Condition
  Detection on Ground Terminals
arxiv_id: '2511.00211'
source_url: https://arxiv.org/abs/2511.00211
tags:
- satellite
- conditions
- images
- weather
- faster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a transfer learning method for detecting
  weather-related conditions on satellite ground terminals. The approach uses YOLACT
  for background removal and segmentation, combined with a ResNet50-based classifier,
  to detect snow, wet, and normal conditions on satellite antennas.
---

# An Efficient and Generalizable Transfer Learning Method for Weather Condition Detection on Ground Terminals

## Quick Facts
- arXiv ID: 2511.00211
- Source URL: https://arxiv.org/abs/2511.00211
- Authors: Wenxuan Zhang; Peng Hu
- Reference count: 19
- This paper introduces a transfer learning method for detecting weather-related conditions on satellite ground terminals, achieving 88.33% accuracy with only 180 training images.

## Executive Summary
This paper presents a transfer learning approach for detecting snow, wet, and normal conditions on satellite ground terminal antennas. The method combines YOLACT-based background removal and segmentation with a ResNet50 classifier, achieving state-of-the-art accuracy while requiring minimal training data. Evaluated against YOLOv7, YOOLv9, R-YOLO, and Faster R-CNN, the approach demonstrates strong generalizability to real-world scenarios, making it suitable for reliable satellite Internet deployment in diverse weather conditions.

## Method Summary
The approach uses a two-stage pipeline: first, YOLACT is fine-tuned on antenna images to generate binary masks that isolate satellite dishes from backgrounds. These masks are then used to remove backgrounds, creating simplified images for classification. The second stage uses a ResNet50 backbone with two fully connected layers (128 units + dropout) for weather condition classification. The model employs partial freezing of pre-trained weights to preserve generic weather features while adapting to antenna-specific patterns. Training requires only 180 images and achieves results in 50 epochs.

## Key Results
- Achieves 88.33% accuracy in multi-class classification with only 180 training images
- Outperforms YOLOv7, YOOLv9, R-YOLO, and Faster R-CNN on satellite antenna weather detection
- Successfully generalizes to real-world scenarios with 45 unaugmented test images
- Requires significantly less training data than competitor models while maintaining higher accuracy

## Why This Works (Mechanism)

### Mechanism 1
Background removal via segmentation reduces domain discrepancy between source weather datasets and target antenna classification. YOLACT generates binary masks to isolate satellite dishes, transforming target domain $D_T$ into simplified domain $D_{ST}$ that excludes background noise. This reduces Maximum Mean Discrepancy (MMD) between pre-trained weather features and target classification task.

### Mechanism 2
Partial freezing of pre-trained weights preserves generic weather features while allowing task-specific adaptation with minimal data. Lower ResNet50 layers (frozen at $\alpha = 0$) retain features from source domain weather classification; only final layers are fine-tuned with reduced learning rate $\alpha'$. This prevents catastrophic forgetting while adapting to antenna-specific patterns.

### Mechanism 3
Decoupled two-stage pipeline (segmentation → classification) enables independent optimization and more efficient learning than unified detection frameworks. YOLACT and ResNet50+FC are trained separately with distinct loss functions. This decomposition allows segmentation to focus on shape localization while classification specializes on surface condition features.

## Foundational Learning

- **Concept: Transfer Learning / Domain Adaptation**
  - **Why needed here:** Core technique enabling the system to leverage pre-trained weather knowledge with only 180 labeled antenna images.
  - **Quick check question:** Can you explain why MMD (Maximum Mean Discrepancy) matters for measuring domain shift between source and target datasets?

- **Concept: Instance Segmentation (YOLACT)**
  - **Why needed here:** Provides pixel-level dish isolation; distinct from bounding-box detection used in YOLO variants.
  - **Quick check question:** What is the difference between semantic segmentation and instance segmentation, and why does YOLACT use mask coefficients?

- **Concept: ResNet Residual Connections**
  - **Why needed here:** Enables training of 50-layer network by addressing vanishing gradients; foundation of the feature extractor.
  - **Quick check question:** Why do skip connections allow deeper networks to train without degradation?

## Architecture Onboarding

- **Component map:** Input Image (300×300) -> YOLACT (fine-tuned on antenna images) -> Binary Mask → Mask Remover -> Isolated Dish Image -> ResNet50 (partial freeze: layers 1-n-1 frozen) -> FC Layer (128 units) → Dropout -> FC Layer (N classes: snow/wet/normal) -> Softmax Classification

- **Critical path:** YOLACT fine-tuning quality → mask precision → classification accuracy. If segmentation fails on novel antenna designs, the entire pipeline degrades.

- **Design tradeoffs:**
  - **Computational cost:** 186 GFLOPs (highest among compared models) vs. accuracy gains. YOLACT contributes 118.6 GFLOPs alone.
  - **Memory:** 16.3 GB training memory; can reduce batch size for inference on weaker GPUs.
  - **Data efficiency:** 180 images sufficient; trade-off is architectural complexity vs. simpler models requiring more data.

- **Failure signatures:**
  - Low accuracy on unseen antenna geometries (paper acknowledges this limitation in Section IV-J)
  - Overfitting if background removal is incomplete
  - Confusion between "wet" and "normal" classes under similar lighting

- **First 3 experiments:**
  1. **Baseline sanity check:** Run YOLACT segmentation on 10-20 validation images; manually verify mask quality covers full dish surface. If masks are incomplete, classification will train on corrupted features.
  2. **Ablation on freezing depth:** Compare full freezing (all but last layer) vs. partial unfreezing (last 2-3 layers) with 40-image subset to validate the paper's freezing strategy for your specific antenna types.
  3. **Domain shift test:** Train on augmented data (dish + synthetic backgrounds per Section III), test on unaugmented real images. Measure accuracy gap; if >5%, augmentation may not match deployment conditions.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the computational complexity (186 GFLOPs) be significantly reduced by replacing YOLACT with a simpler segmentation tool without degrading the classification accuracy of weather conditions? (Basis: Section IV.I suggests this as future work)

- **Open Question 2:** How does the model perform when deployed on ground terminals with "uniquely designed" antenna geometries that differ significantly from the training data? (Basis: Section IV.J acknowledges potential performance degradation on novel antenna designs)

- **Open Question 3:** Can this transfer learning method be effectively adapted for telescopes in optical ground stations given the different visual characteristics compared to RF antennas? (Basis: Section IV.J proposes this as a future application possibility)

## Limitations
- Performance on antenna geometries not represented in training data remains untested beyond brief acknowledgment
- Exact hyperparameters for YOLACT fine-tuning and ResNet50+FC training are unspecified, affecting reproducibility
- Decoupled architecture may suffer from error propagation if segmentation fails on novel antenna designs

## Confidence
- **High Confidence:** The segmentation-based background removal mechanism and its role in reducing domain discrepancy
- **Medium Confidence:** The partial freezing strategy (specific layer selection lacks comprehensive ablation testing)
- **Medium Confidence:** The decoupled two-stage pipeline efficiency (error propagation analysis not explicitly conducted)

## Next Checks
1. **Segmentation Quality Verification:** Run YOLACT on 10-20 validation images from your antenna dataset and manually verify that masks completely cover the dish surface without gaps or artifacts.
2. **Freezing Strategy Ablation:** Compare full freezing (all but last layer) versus partial unfreezing (last 2-3 layers) using a small 40-image subset to determine optimal freezing depth for your specific antenna types.
3. **Real-World Domain Shift Test:** Train on augmented data as specified, then evaluate on unaugmented real-world images from your deployment environment to measure accuracy degradation and identify augmentation gaps.