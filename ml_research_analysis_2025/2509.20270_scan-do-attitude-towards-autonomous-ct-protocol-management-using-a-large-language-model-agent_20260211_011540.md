---
ver: rpa2
title: 'Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large
  Language Model Agent'
arxiv_id: '2509.20270'
source_url: https://arxiv.org/abs/2509.20270
tags:
- protocol
- agent
- entity
- scan
- request
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces an LLM-based agent framework to automate CT
  scan protocol management, addressing the time-intensive and expertise-demanding
  task of configuring acquisition, reconstruction, and postprocessing parameters.
  The agent leverages in-context learning, instruction-following, and structured tool-calling
  to interpret natural language or structured requests and modify XML-based protocol
  definition files.
---

# Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent

## Quick Facts
- arXiv ID: 2509.20270
- Source URL: https://arxiv.org/abs/2509.20270
- Reference count: 9
- The paper introduces an LLM-based agent framework to automate CT scan protocol management, demonstrating up to 89% syntax correctness and 67% plan accuracy

## Executive Summary
This paper presents an LLM-based agent framework for automating CT scan protocol management, addressing the time-intensive and expertise-demanding task of configuring acquisition, reconstruction, and postprocessing parameters. The agent leverages in-context learning, instruction-following, and structured tool-calling to interpret natural language or structured requests and modify XML-based protocol definition files. Evaluation across multiple LLMs demonstrates the agent's ability to retrieve protocol elements, generate device-compatible definitions, and implement user requests with high syntax correctness rates and plan accuracy.

## Method Summary
The approach implements an LLM agent that decomposes user requests into manageable sub-requests (Adding, Modification, Deleting, Others) using a Router component with few-shot examples. It employs a Memory module storing static entity descriptions and simplified protocol tree structures, while a Planner retrieves relevant context before generating action proposals. The system executes modifications through specialized downstream agents and validates syntax through a human-in-the-loop approach. The framework was evaluated using GPT-4o, GPT-4o-mini, and Gemma3:27B models on Siemens Healthineers XML protocol files without fine-tuning.

## Key Results
- GPT-4o achieved 83% syntax correctness rate (SCR) and 67% plan accuracy on protocol modifications
- GPT-4o-mini showed 62% SCR and 39% plan accuracy
- Gemma3:27B demonstrated 43% SCR but strong performance on Deleting tasks (50% plan accuracy)
- Memory-augmented reasoning improved entity retrieval precision/recall to approximately 0.8

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Request decomposition and routing enables handling of compound protocol modification tasks
- Mechanism: The Router component uses LLM domain knowledge with few-shot examples to classify sub-requests into Adding, Modification, Deleting, or Others categories, then dispatches to specialized downstream agents
- Core assumption: Complex clinical requests can be meaningfully decomposed into discrete, categorizable operations without losing intent
- Evidence anchors: [abstract] "agent combines in-context-learning, instruction-following, and structured toolcalling abilities to identify relevant protocol elements and apply accurate modifications"; [section 2.2] "The Router component addresses this by decomposing user requests into manageable sub-requests and directing them to appropriate downstream agents"

### Mechanism 2
- Claim: Template-based entity insertion preserves hierarchical and semantic consistency
- Mechanism: For Adding requests, the agent retrieves contextually relevant existing entities as templates, refines them based on user intent, and inserts at appropriate protocol tree locations rather than generating from scratch
- Core assumption: Existing protocol entities encode valid structural patterns that can be safely adapted
- Evidence anchors: [section 2.2] "the agent leverages existing and contextually relevant entities as templates, refines them optionally based on the user intent, and inserts them into appropriate locations in the protocol tree to preserve semantic and hierarchical consistency"

### Mechanism 3
- Claim: Memory-augmented reasoning improves entity retrieval accuracy
- Mechanism: Explicit memory module stores static entity descriptions (functional descriptions based on key configuration values) and simplified protocol tree structure, enabling the planner to retrieve relevant context before proposing actions
- Core assumption: Concise functional descriptions of entity types are sufficient for the LLM to match user intent to protocol elements
- Evidence anchors: [section 2.2] "we introduce an explicit memory module that stores static and protocol-specific prior knowledge"

## Foundational Learning

- Concept: XML hierarchical structure (tree nodes, parent-child relationships, entity attributes)
  - Why needed here: CT protocol definition files are hierarchical XML documents where Range entities define acquisition phases and Recon entities specify reconstructions; structural modifications must preserve tree validity
  - Quick check question: Can you identify what happens to a parent node if its sole child is deleted?

- Concept: In-context learning with few-shot prompting
  - Why needed here: The Router uses few-shot examples in prompts to classify request types; all deployed LLMs operate without task-specific fine-tuning
  - Quick check question: How would adding a new request type category require changes to the Router's prompt design?

- Concept: Tool-calling / function-calling in LLM agents
  - Why needed here: The agent dynamically invokes a comprehensive tool set including entity retrieval, attribute management, and validation through structured tool-calling interfaces
  - Quick check question: What is the difference between an action specification and a human-readable plan in the planner's output?

## Architecture Onboarding

- Component map: Router → downstream agents (Modification/Adding/Deleting handlers) → Memory module → entity descriptions + simplified protocol tree → Planner → retrieves context → generates actions + plan → Downstream agents → execute entity/essential modifications → Human-in-the-loop → validates proposals before execution

- Critical path: User request → Router (decompose + classify) → Planner (retrieve entities/essentials via memory) → generate proposal → human verification → downstream agent executes XML modification → syntax validation

- Design tradeoffs:
  - GPT-4o: highest SCR (83%) and plan accuracy (52% general) but API dependency and cost
  - Local deployment (Gemma3:27B): data privacy and cost efficiency but lower SCR (43%) with selective strengths in Deleting tasks (50% plan accuracy vs 25% for GPT-4o)
  - Template-based insertion vs generation-from-scratch: safety vs flexibility

- Failure signatures:
  - Router misclassification → wrong downstream agent dispatch
  - Structural errors: adding entity under wrong parent, deleting sole child without parent
  - Semantic errors: using unsupported values or ignoring attribute inter-dependencies (no device API)

- First 3 experiments:
  1. Reproduce SCR baseline: Run Modification requests (highest GPT-4o performance at 89%) on the adult thorax protocol and verify XML compilability with the protocol browser
  2. Test memory ablation: Remove entity descriptions from memory module and measure entity-level retrieval precision/recall degradation (compare against Fig. 4 baseline where GPT-4o achieves ~0.8 precision)
  3. Edge case probe: Submit deletion request for an entity that is the sole child of its parent; verify whether downstream agent correctly removes both child and parent (as specified in section 2.2) or creates dangling structure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can semantically meaningful device APIs be integrated to resolve attribute inter-dependencies and value constraints that currently cause semantic errors?
- Basis in paper: [explicit] The authors state future research must focus on "expanding the agent’s access to relevant knowledge sources, in particular semantically meaningful device APIs" to address the current "insufficient understanding of attribute inter-dependencies"
- Why unresolved: The current implementation relies on context provided via prompts, which is insufficient for the agent to reason about dynamic parameter ranges and complex naming conventions
- What evidence would resolve it: Demonstration of significantly reduced semantic errors when the agent queries a structured API that explicitly enforces parameter logic and valid value ranges

### Open Question 2
- Question: Can evaluation methodologies be refined to eliminate the bias introduced by using LLMs to generate pseudo-requests for ground truth comparison?
- Basis in paper: [explicit] The authors note that generating complementary pseudo-requests using LLMs "potentially introduces bias due to inconsistent model performance" and call for developing "more robust evaluation methodologies"
- Why unresolved: The "Plan Faithfulness" metric relies on LLM-generated pseudo-tasks and embedding similarity, which may favor specific model outputs rather than measuring true alignment with user intent
- What evidence would resolve it: Validation of the metric against a human-annotated ground truth set, or the development of a deterministic evaluation framework that does not rely on generative models

### Open Question 3
- Question: To what extent can the current hierarchical parsing strategy generalize to protocol definition files from different scanner manufacturers without architecture changes?
- Basis in paper: [inferred] The authors acknowledge the "lack of a unified device API" and that "different scanner models have different capabilities," yet the evaluation is restricted to a single vendor's specific XML structure
- Why unresolved: It is unclear if the agent's "Router" and "Planner" definitions are overfitted to the specific entity types (e.g., TopogramRange, SpiralRange) found in the evaluated Siemens Healthineers protocols
- What evidence would resolve it: Successful application of the agent to a multi-vendor dataset, maintaining comparable Syntax Correctness Rates and Plan Accuracy scores across different XML schemas

## Limitations

- Absence of device-specific knowledge bases restricts the agent to producing syntactically valid but semantically uncertain protocols
- Evaluation focuses on XML syntax correctness and plan accuracy rather than actual clinical appropriateness of modifications
- Test protocol is relatively simple (adult thorax CT), and performance on more complex protocols with numerous interdependent entities remains unvalidated

## Confidence

- High confidence in technical feasibility of LLM agent framework for XML protocol manipulation and syntax validation (supported by SCR metrics up to 89%)
- Medium confidence in agent's ability to correctly interpret and execute user requests based on plan accuracy results (up to 67% overall)
- Low confidence in clinical validity and safety of generated protocols due to lack of device-specific knowledge integration and semantic validation

## Next Checks

1. **Device interoperability test**: Evaluate the agent's performance across multiple scanner manufacturers' protocol formats (Siemens, GE, Philips) to assess generalizability beyond the single-vendor XML schema used in the study

2. **Complex protocol stress test**: Apply the agent to a high-complexity protocol (e.g., cardiac CT with multiple phases, contrast protocols, and reconstruction chains) to identify performance degradation in handling numerous interdependent entities and attributes

3. **Clinical expert validation**: Conduct a blind comparison where radiologists review original vs. agent-modified protocols for clinical appropriateness, measuring false positive rates in parameter changes that appear syntactically valid but are clinically inappropriate