---
ver: rpa2
title: 'The study of short texts in digital politics: Document aggregation for topic
  modeling'
arxiv_id: '2503.05065'
source_url: https://arxiv.org/abs/2503.05065
tags:
- topic
- topics
- document
- state
- season
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how document length affects topic modeling
  interpretability, focusing on aggregating short documents like tweets and Wikipedia
  pages. Using one million tweets from U.S.
---

# The study of short texts in digital politics: Document aggregation for topic modeling

## Quick Facts
- arXiv ID: 2503.05065
- Source URL: https://arxiv.org/abs/2503.05065
- Reference count: 40
- Primary result: Aggregating short political texts significantly improves topic model interpretability and predictive accuracy for identifying legislators' states

## Executive Summary
This study examines how document length affects topic modeling outcomes in political text analysis. Using one million tweets from U.S. state legislators and Wikipedia pages, researchers compare topic models built on individual documents versus aggregated documents (by legislator or birthplace). They find that aggregation substantially increases state-related topics and improves model performance in predicting legislators' states. For example, legislator-level aggregation yielded 43 state-related topics compared to 24 for individual tweets, with predictive accuracy rising from 59% to 86%. The study demonstrates that aggregation is a critical preprocessing choice for political text analysis, particularly when studying state-level politics.

## Method Summary
The researchers collected approximately one million tweets from U.S. state legislators between 2019-2020 and Wikipedia pages about these legislators. They compared topic models built on three document types: individual tweets, Wikipedia pages, and aggregated tweets by legislator. Two modeling approaches were used: structural topic models (STMs) and BERTopic. The aggregation strategy grouped tweets by legislator, which proved more effective than grouping by birthplace. Model performance was evaluated using predictive accuracy for identifying legislators' states, with ground truth labels from the Wikipedia data. The study employed structural topic models and BERTopic to analyze the text data.

## Key Results
- Aggregated documents yield substantially more state-related topics (43 topics) compared to individual tweets (24 topics)
- Predictive accuracy for identifying legislators' states improves dramatically with aggregation, rising from 59% to 86%
- Aggregation benefits are driven by document length rather than other factors, confirmed through robustness checks
- Results hold across both structural topic models and BERTopic approaches

## Why This Works (Mechanism)
Aggregation combines multiple short texts into longer documents, providing richer contextual information that enables topic models to identify coherent themes more effectively. Short texts like tweets contain limited vocabulary and context, making it difficult for models to distinguish between genuinely distinct topics versus artifacts of sparse data. When multiple texts from the same source are combined, the resulting document contains more diverse vocabulary and clearer thematic patterns, allowing topic models to better differentiate between substantive topics and noise.

## Foundational Learning
- **Topic modeling fundamentals**: Understanding how LDA and related models identify latent topics from word co-occurrence patterns is essential for interpreting aggregation effects
- **Document length effects**: Recognizing that shorter documents provide less context and vocabulary diversity explains why aggregation improves model performance
- **Evaluation metrics**: Predictive accuracy and topic interpretability measures are crucial for assessing model quality and comparing different preprocessing approaches
- **Political text characteristics**: Familiarity with how state legislators communicate differently across platforms helps contextualize why state-related topics emerge more clearly with aggregation

## Architecture Onboarding
**Component Map**: Raw text data -> Preprocessing (cleaning, tokenization) -> Document aggregation (optional) -> Topic modeling (STM/BERTopic) -> Evaluation (predictive accuracy, interpretability)

**Critical Path**: Document collection → Aggregation strategy → Topic modeling → State prediction accuracy assessment

**Design Tradeoffs**: Aggregation improves topic coherence but may obscure temporal dynamics; individual documents preserve time-sensitive information but reduce topic clarity

**Failure Signatures**: Poor topic coherence with individual documents suggests aggregation is needed; over-aggregation may mask important temporal or individual variation

**3 First Experiments**:
1. Test aggregation on different political roles (federal legislators, mayors) to assess generalizability
2. Compare models using time-sliced versus aggregated documents to evaluate temporal information loss
3. Apply aggregation to non-political short text corpora to determine if benefits extend beyond political domains

## Open Questions the Paper Calls Out
None

## Limitations
- Findings are limited to U.S. state legislators and may not generalize to other political actors or geographic contexts
- Aggregation may obscure temporal patterns in political communication that could be important for certain research questions
- The study does not assess whether aggregation affects discovery of non-geographic topics or creates new trade-offs in thematic coverage

## Confidence
- **High confidence**: Document aggregation improves predictive accuracy for state identification and increases state-related topics in topic models
- **Medium confidence**: Aggregation benefits are driven by document length rather than other factors, though robustness checks support this conclusion
- **Medium confidence**: Findings generalize to other political text corpora, pending further validation

## Next Checks
1. Test aggregation effects on political texts from different countries, roles (e.g., federal legislators, mayors), and platforms to assess generalizability
2. Examine whether aggregation obscures temporal patterns in political discourse by comparing models built on time-sliced versus aggregated documents
3. Investigate whether aggregation affects the discovery of non-geographic topics to understand potential trade-offs in thematic coverage