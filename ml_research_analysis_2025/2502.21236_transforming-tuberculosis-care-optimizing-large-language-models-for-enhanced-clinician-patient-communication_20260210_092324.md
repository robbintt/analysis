---
ver: rpa2
title: 'Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced
  Clinician-Patient Communication'
arxiv_id: '2502.21236'
source_url: https://arxiv.org/abs/2502.21236
tags:
- prompt
- treatment
- questions
- responses
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored using large language models (LLMs) to enhance
  communication between tuberculosis (TB) patients and treatment supporters in Argentina.
  The researchers developed and evaluated six GPT-based conversational models using
  various prompt engineering techniques, including zero-shot, few-shot, retrieval-augmented
  generation (RAG), and a multi-agent classification pipeline.
---

# Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication

## Quick Facts
- arXiv ID: 2502.21236
- Source URL: https://arxiv.org/abs/2502.21236
- Reference count: 26
- Primary result: A GPT-3.5 model combining RAG with few-shot examples and a two-step classification pipeline achieved moderate to high scores across empathy, medical accuracy, and linguistic appropriateness in Spanish TB patient communication.

## Executive Summary
This study developed and evaluated six GPT-3.5-based conversational models for tuberculosis patient communication in Argentina, focusing on optimizing both medical accuracy and empathetic engagement. The researchers tested various prompt engineering approaches including zero-shot, few-shot, retrieval-augmented generation (RAG), and a multi-agent classification pipeline. Results showed that the best-performing model combined RAG with few-shot examples and a two-step classification system that separated emotional from informational queries, achieving the highest scores across all evaluation categories while maintaining appropriate cultural communication norms.

## Method Summary
The researchers built six GPT-3.5 models using different prompt engineering techniques: zero-shot English/Spanish, few-shot examples, RAG with FAISS retrieval from TB guidelines, and combinations with a two-step classification pipeline that routes emotional queries to an empathy agent and informational queries to a RAG agent. They evaluated models on 10 representative questions using clinical expert ratings across empathy (0-2 scale), medical accuracy (1-5 scale), and linguistic appropriateness (Low/Moderate/High), while also testing privacy-preserving techniques using differential privacy with epsilon values from 0.01 to 1000 on sanitized few-shot examples.

## Key Results
- The RAG + Few-Shot + Classification pipeline (Model 5) achieved highest overall scores across all categories
- Medical accuracy scores ranged from 2.6 (Zero-shot English) to 4.2 (RAG + Few-Shot model)
- Privacy-preserving text sanitization at higher epsilon values (less noise) maintained better linguistic performance while protecting patient data
- Challenges included maintaining conversational continuity, avoiding overgeneralization, and ensuring consistent pronoun usage

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining RAG with few-shot examples improves medical accuracy over either technique alone in domain-specific healthcare dialogue.
- Mechanism: RAG retrieves contextually relevant medical documents (TB guidelines, medication info), while few-shot examples provide conversational patterns that model appropriate response structure, empathy, and local dialect. The combination grounds factual claims in authoritative sources while maintaining natural dialogue flow.
- Core assumption: The retrieval corpus contains accurate, non-conflicting information that maps cleanly to user queries.
- Evidence anchors:
  - [abstract] "Results showed that the best-performing model combined RAG with few-shot examples and a two-step classification pipeline, achieving moderate to high scores across all categories."
  - [section: Results] Model 4 (RAG + Few-Shot) scored 4.0 medical accuracy vs. Model 2 (Few-Shot only) at 4.4, but the full pipeline (Model 5) recovered to 4.2.
  - [corpus] Weak direct support—neighbor papers focus on medical imaging and chronic care frameworks, not RAG+few-shot combinations for dialogue.
- Break condition: RAG retrieval returns conflicting documents (e.g., incorrect passage about liver toxicity when asked about analgesics), or retrieval corpus lacks coverage for specific symptom combinations.

### Mechanism 2
- Claim: A two-step classification pipeline separating emotional from informational queries enables specialized agent responses.
- Mechanism: First LLM agent classifies user intent (emotional vs. informational). Emotional queries route to an empathy-optimized agent; informational queries route to a fact-focused RAG agent. This modularity allows independent optimization of each response type.
- Core assumption: Queries can be cleanly bifurcated, and patients don't seek both emotional support and medical information simultaneously.
- Evidence anchors:
  - [section: Methods] "Queries classified as empathy-seeking are directed to an empathy-optimized agent, while information-heavy queries are routed to a fact-focused RAG agent."
  - [section: Results] Model 5 (RAG + Few-Shot + Classification) achieved highest empathy scores (0.50, 0.75, 0.00) across categories.
  - [corpus] No direct corpus support for multi-agent classification in healthcare dialogue.
- Break condition: Queries contain both emotional distress and medical information needs (e.g., "I'm terrified—I've been vomiting for days, when will this stop?"), leading to misclassification or incomplete responses.

### Mechanism 3
- Claim: Local Differential Privacy (LDP) text sanitization protects patient data in few-shot examples with controllable utility-privacy tradeoffs via epsilon (ε).
- Mechanism: Before inclusion in prompts, patient messages are sanitized using the UMLDP algorithm, which replaces words with semantically similar alternatives based on embedding distance. Lower ε = more noise = better privacy but degraded linguistic quality; higher ε = less noise = better utility.
- Core assumption: Word-level perturbation preserves enough semantic meaning for few-shot learning to remain effective.
- Evidence anchors:
  - [section: Privacy and Data Security] "To protect patient privacy, removing Personally Identifiable Information (PII) from these examples is important before including them in the prompt."
  - [section: Results/Privacy] At ε=1000, linguistic accuracy was "High" with "Vos" pronoun usage; at ε=0.01, accuracy remained "Moderate" but with less appropriate pronoun usage ("tú").
  - [corpus] Weak—no neighbor papers directly evaluate LDP for healthcare LLMs.
- Break condition: At low ε values, perturbation produces semantically incoherent text (e.g., "[unused489]" tokens appearing), rendering examples useless for few-shot learning.

## Foundational Learning

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: The paper relies on RAG to ground medical responses in authoritative TB guidelines rather than relying solely on model parametric knowledge.
  - Quick check question: Can you explain why RAG alone underperformed (3.2 accuracy) compared to few-shot (4.4) in this study?

- Concept: Local Differential Privacy (LDP) and epsilon (ε)
  - Why needed here: The privacy experiments use ε to control the privacy-utility tradeoff in text sanitization for few-shot examples.
  - Quick check question: If you observe "[unused489]" tokens in sanitized text, what does this indicate about the ε value used?

- Concept: Voseo (Argentinian Spanish pronoun system)
  - Why needed here: The paper explicitly evaluates models on correct usage of "vos" vs. "tú" vs. "usted," which affects patient trust and cultural appropriateness.
  - Quick check question: Why might a model that uses "tú" instead of "vos" feel less natural to an Argentinian patient?

## Architecture Onboarding

- Component map: User Query → Classification Agent → [Emotional Agent OR RAG Agent] → Response → Few-shot examples (sanitized w/ LDP) → TB Guidelines DB (CDC, WHO, Mayo Clinic, PAHO/WHO)
- Critical path: The classification step determines response quality—if emotional queries route to the RAG agent, responses may feel clinically cold; if informational queries route to the emotional agent, medical accuracy degrades.
- Design tradeoffs:
  - Privacy vs. linguistic accuracy: Higher ε improves dialect authenticity but reduces privacy guarantees.
  - RAG coverage vs. precision: Larger document corpora increase recall but introduce conflicting information.
  - Pipeline complexity vs. debugging: Multi-agent systems are harder to debug but allow targeted improvements.
- Failure signatures:
  - Repetitive "consult your doctor" responses indicate insufficient RAG specificity.
  - Gender bias (defaulting to "médico" instead of "médico/a") indicates training data artifacts.
  - Pronoun switching mid-conversation ("vos" → "tú") indicates weak cultural grounding.
  - Query misclassification when emotional distress accompanies factual questions.
- First 3 experiments:
  1. Baseline classification accuracy: Manually label 50 patient queries as emotional/informational; compare model classification against human labels to quantify routing errors.
  2. RAG retrieval quality audit: For 20 medical questions, inspect retrieved document chunks—identify cases where irrelevant or conflicting passages were retrieved.
  3. Epsilon sensitivity sweep: Run the privacy pipeline at ε ∈ {0.1, 1, 10, 100} with fixed evaluation questions; plot linguistic accuracy vs. ε to identify the viable operating range before text becomes incoherent.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a multi-agent framework effectively decouple the optimization of empathetic engagement from medical factuality to improve performance in both domains simultaneously?
- Basis in paper: [explicit] The Discussion states that developing a more robust "multi-agent framework that can allow to separately improve each agent for a specific task" is a valuable future direction.
- Why unresolved: Current models struggled to balance objectives, occasionally providing generic reassurance for medical queries or failing to show empathy when delivering factual information.
- What evidence would resolve it: Comparative evaluation showing a multi-agent system achieving higher independent scores in both empathy and medical accuracy than the current RAG + Few-Shot model.

### Open Question 2
- Question: Do Membership Inference Attacks (MIA) reveal privacy vulnerabilities in the differentially private text sanitization process that are not predicted by epsilon (ϵ) values alone?
- Basis in paper: [explicit] The Limitations section notes the reliance on epsilon values "instead of performing a membership inference attack (MIA)," identifying this as a continued "valuable research direction."
- Why unresolved: The relationship between privacy noise and utility is inconsistent; for instance, medical accuracy dropped unexpectedly at ϵ 0.10 but improved at lower privacy levels, suggesting the privacy guarantees are not fully verified.
- What evidence would resolve it: Results from MIA tests on the sanitized dataset correlating attack success rates with specific epsilon values to validate the actual privacy preservation.

### Open Question 3
- Question: To what extent can knowledge graphs mitigate the hallucination of conflicting medical advice caused by the current RAG pipeline's retrieval of overlapping documents?
- Basis in paper: [explicit] Future Work suggests "LLM’s knowledge can be extended via knowledge graphs" to capture precise relations, addressing the issue where RAG retrieved "excessive incomplete data" leading to "incorrect or conflicting conclusions."
- Why unresolved: The current RAG implementation occasionally retrieves contradictory guidelines (e.g., regarding drug toxicity), causing the model to generate incorrect medical warnings.
- What evidence would resolve it: A study demonstrating that a knowledge graph-augmented model yields a statistically significant reduction in medical inaccuracies compared to the standard vector-similarity RAG baseline.

## Limitations

- The privacy experiments relied on epsilon values rather than performing membership inference attacks (MIA) to validate actual privacy preservation
- The RAG implementation occasionally retrieved conflicting or incomplete medical information, leading to incorrect advice
- Pronoun consistency (vos/tú/usted) and gender bias (defaulting to masculine forms) remained challenging, affecting cultural appropriateness

## Confidence

High confidence in the experimental methodology and results, as the study provides detailed evaluation protocols and clear performance metrics. Medium confidence in the privacy analysis due to reliance on epsilon values rather than MIA testing. Low confidence in the generalizability of results beyond Argentinian Spanish TB patients due to cultural and linguistic specificity.

## Next Checks

1. Validate RAG retrieval precision by manually inspecting top-5 retrieved chunks for 20 medical queries to identify false positives and conflicting passages
2. Test epsilon sensitivity by running the privacy pipeline at ε ∈ {0.1, 1, 10, 100} and measuring linguistic coherence degradation before prompting
3. Evaluate pronoun consistency by analyzing 50 generated responses for vos/tú/usted switching and verb agreement errors