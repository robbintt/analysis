---
ver: rpa2
title: Causal Retrieval with Semantic Consideration
arxiv_id: '2504.04700'
source_url: https://arxiv.org/abs/2504.04700
tags:
- causal
- retrieval
- semantic
- cawai
- effect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of retrieving causal relationships
  in information retrieval systems, where existing methods primarily focus on semantic
  similarity and fail to capture deeper relational structures such as causality. The
  proposed method, CAWAI, introduces a novel dense retriever trained with dual objectives:
  semantic and causal relations.'
---

# Causal Retrieval with Semantic Consideration

## Quick Facts
- arXiv ID: 2504.04700
- Source URL: https://arxiv.org/abs/2504.04700
- Reference count: 7
- Dense retriever CAWAI significantly outperforms DPR, GTR, and BM25 on causal retrieval tasks, especially in large-scale settings

## Executive Summary
This paper addresses the problem of retrieving causal relationships in information retrieval systems, where existing methods primarily focus on semantic similarity and fail to capture deeper relational structures such as causality. The proposed method, CAWAI, introduces a novel dense retriever trained with dual objectives: semantic and causal relations. CAWAI employs three encoders—Cause Encoder, Effect Encoder, and Semantic Encoder—to learn cause-to-effect and effect-to-cause mappings while preserving semantic consistency. Experiments show that CAWAI significantly outperforms baselines like BM25, DPR, and GTR on causal retrieval tasks, especially under large-scale retrieval settings, and demonstrates strong zero-shot generalization across scientific domain QA tasks.

## Method Summary
CAWAI introduces a three-encoder architecture for causal retrieval: Cause Encoder, Effect Encoder, and Semantic Encoder. The model is trained with dual objectives—semantic alignment and causal directionality—using in-batch negative sampling. The Semantic Encoder provides frozen reference embeddings that regularize the learning of the Cause and Effect encoders, which are trained to map cause-to-effect and effect-to-cause relationships respectively. The total loss combines causal contrastive losses and semantic preservation losses weighted by a hyperparameter β (typically 0.1-1.0). The model is trained on datasets like e-CARE and BCOPA-CE, which provide cause-effect pairs, and evaluated on causal retrieval tasks with retrieval pools from Wikipedia.

## Key Results
- CAWAI achieves significantly higher Hit@1 and MRR@10 scores than DPR, GTR, and BM25 on e-CARE causal retrieval tasks
- On large-scale retrieval (wikiXXL with 20M sentences), CAWAI-GTR achieves 14.6% Hit@1 versus 12.9% for baseline GTR on Task 2
- CAWAI demonstrates strong zero-shot generalization, performing comparably to DPR on general QA tasks while excelling at causal reasoning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Asymmetric encoder specialization enables bidirectional causal mapping that standard dense retrievers cannot capture.
- **Mechanism:** The Cause Encoder learns to map cause text → semantic embedding of the corresponding effect (e′₁ → e′′₂), while the Effect Encoder learns the reverse mapping (e′₂ → e′′₁). This forces each encoder to internalize directional causal structure rather than symmetric semantic similarity.
- **Core assumption:** Causal relationships have learnable directional patterns that differ from semantic similarity patterns.
- **Evidence anchors:**
  - [section 3.2] "Cause Encoder is trained to map an input cause event e1 (text) to its corresponding effect event e′′₂ (vector), thereby learning the cause-to-effect relationship."
  - [section 6] t-SNE visualization shows CAWAI maps cause-effect pairs closely while DPR embeddings "remain separated without shared semantics."
  - [corpus] Related work CausalRAG and CDF-RAG similarly find that semantic-similarity-based retrieval fails to distinguish true causal structure.

### Mechanism 2
- **Claim:** Frozen semantic encoder acts as a regularization anchor, preventing representation drift while learning causal structure.
- **Mechanism:** The Semantic Encoder (weights frozen) provides stable reference embeddings (e′′₁, e′′₂). The semantic loss (loss_sem) forces the Cause/Effect encoder outputs to remain close to these anchors, creating dual constraints: encode causal directionality while preserving semantic identity.
- **Core assumption:** Preserving semantic proximity provides useful signal for retrieval, especially when keyword-based retrieval sometimes succeeds.
- **Evidence anchors:**
  - [section 3.2] "Semantic Encoder, whose weights are frozen during training... This alignment preserves contextual nuances and maintains semantic consistency."
  - [table 6] Ablation shows semantic loss (β=0.1) improves Hit@1 from 32.4% to 37.2% on e-CARE Task 1; β>1 yields diminishing returns.
  - [corpus] No direct corpus evidence for frozen-encoder regularization in causal retrieval; this appears novel.

### Mechanism 3
- **Claim:** In-batch negative sampling with cross-encoder contrasting forces discriminative causal representations.
- **Mechanism:** For each cause e1^(i), all effect embeddings e2^(j) where j≠i serve as negatives. The Cause Encoder must score the true effect higher than all distractors. Critically, negatives come from the Semantic Encoder outputs (e′′₂), creating a contrasting signal between learned causal representations and fixed semantic representations.
- **Core assumption:** Within a batch, randomly paired cause-effect instances are likely non-causal—reasonable for diverse training data.
- **Evidence anchors:**
  - [section 3.2] "In Cause Encoder, for a given cause event e1(i)... we define a set of negative effects N(e2(j)) that are sampled from {e2(j)|j≠i}"
  - [table 2] CAWAI-GTR improves over baseline GTR on wikiXXL (20M corpus): 14.6% vs 12.9% Hit@1 on Task 2.
  - [corpus] Triple-Encoders (Erker et al., 2024) uses similar multi-encoder approach but for contextualized embeddings, not causal directionality.

## Foundational Learning

- **Concept: Dense Retrieval with Bi-encoders (e.g., DPR, GTR)**
  - **Why needed here:** CAWAI extends standard dense retrieval by adding specialized encoders. Without understanding how DPR maps queries and documents to a shared embedding space via contrastive learning, the multi-encoder design will be confusing.
  - **Quick check question:** Can you explain why in-batch negative sampling creates a stronger training signal than using a single fixed negative?

- **Concept: Causal Directionality in Text**
  - **Why needed here:** The paper assumes cause→effect and effect→cause are distinct relational patterns. Understanding that "X caused Y" differs from "Y was caused by X" semantically and logically is essential for grasping why two separate encoders are needed.
  - **Quick check question:** Given "The factory exploded" as a query, would you expect a semantic retriever to return "Workers were injured" or "Another factory also exploded"? Why might the latter be semantically closer but causally wrong?

- **Concept: Representation Regularization via Auxiliary Loss**
  - **Why needed here:** The semantic loss is an auxiliary objective that constrains the learned embeddings. Understanding multi-task or multi-objective training helps explain why β tuning matters.
  - **Quick check question:** What happens if you train a model with two objectives but weight one 10x higher than the other?

## Architecture Onboarding

- **Component map:**
  - Cause Encoder (trainable) -> Effect Encoder (trainable) -> Semantic Encoder (frozen)
  - Loss Computation Module combines lossc, losse, losssem,c, losssem,e with β weighting
  - Retrieval Index uses Effect Encoder to index corpus; Cause Encoder encodes query

- **Critical path:**
  1. Data preparation: Create (cause, effect) pairs from e-CARE, BCOPA-CE, Causal QA datasets
  2. Initialize Cause/Effect encoders from same pre-trained weights (BERT-base, GTR-base, or LLaMA-1B)
  3. Freeze Semantic Encoder weights
  4. Training loop: Forward pass through all three encoders → compute 4 loss terms → backprop through Cause/Effect encoders only
  5. Checkpoint selection: Validate on held-out pairs; select highest accuracy

- **Design tradeoffs:**
  - **Three encoders vs. single encoder:** Higher memory and compute, but enables directional specialization
  - **Frozen semantic encoder vs. trainable:** Freezing reduces overfitting risk and provides stable anchors; limits adaptability to domain-specific semantics
  - **β tuning:** β=0.1 to 1.0 recommended; higher values prioritize semantic preservation at potential cost to causal discrimination

- **Failure signatures:**
  - **Semantic collapse:** Cause and effect embeddings become nearly identical; model retrieves semantically similar but causally unrelated passages. Check: cosine(e′₁, e′′₁) vs. cosine(e′₁, e′′₂)
  - **Over-regularization:** With β too high, Hit@1 on causal retrieval drops close to baseline DPR/GTR
  - **Poor generalization to large corpora:** Performance degrades sharply from e-CARE-only to wikiXL/wikiXXL; indicates overfitting to small retrieval pool

- **First 3 experiments:**
  1. **Reproduce ablation (Table 6):** Train CAWAI-DPR with β ∈ {0, 0.1, 1, 2, 5} on e-CARE; verify that β=0.1–1 yields optimal Hit@1 on wikiXL. This validates the semantic loss contribution.
  2. **Directional swap test:** Swap Cause/Effect encoders at inference (use Effect Encoder for queries, Cause Encoder for corpus). Expect performance drop if encoders have truly specialized.
  3. **Out-of-domain generalization:** Train on e-CARE only, test on scientific QA (SciFact, SciQ) without further training. Compare to GTR baseline to verify zero-shot generalization claims.

## Open Questions the Paper Calls Out

- **Question:** Does integrating CAWAI into a full Retrieval-Augmented Generation (RAG) pipeline significantly reduce hallucinations compared to standard semantic retrievers?
- **Basis in paper:** [explicit] The introduction cites that "40–50% of hallucinations originate from failures in the document retrieval step" in legal domains. However, the experiments focus exclusively on retrieval metrics (Hit@k, MRR) rather than measuring the downstream impact on LLM generation quality.
- **Why unresolved:** The paper evaluates the retriever in isolation and does not measure the end-to-end fidelity of answers generated by an LLM using CAWAI-retrieved context.
- **What evidence would resolve it:** An end-to-end experiment measuring hallucination rates in generated answers for causal queries when using CAWAI versus baselines like DPR.

- **Question:** Can CAWAI maintain its superior performance when applied to the legal domain, which was a primary motivation for the work?
- **Basis in paper:** [explicit] The introduction emphasizes the need for accuracy in "knowledge-intensive domains such as biomedical and legal fields," but Section 5.3 (Science Domain QA Tasks) only validates zero-shot generalization on scientific datasets (NFCorpus, SciDocs, etc.), omitting legal benchmarks.
- **Why unresolved:** The model’s effectiveness is demonstrated for scientific and general domains, but the specific legal use case posited in the motivation remains unverified.
- **What evidence would resolve it:** Evaluation results on legal-specific causal reasoning or retrieval datasets (e.g., case law consequence retrieval).

- **Question:** Can the CAWAI architecture be adapted to outperform standard baselines on general QA tasks rather than achieving only comparable performance?
- **Basis in paper:** [explicit] Section 5.4 notes that while CAWAI excels at causal tasks, it achieves performance "comparable to DPR but without a clear advantage" on general QA datasets like Natural Questions and SQuAD.
- **Why unresolved:** The current dual-objective training appears to specialize the model for causal structures, potentially at the expense of general semantic matching efficiency.
- **What evidence would resolve it:** Modifications to the loss function or architecture that allow CAWAI to statistically significantly outperform baselines on general QA benchmarks while retaining causal strengths.

## Limitations

- Performance degrades on larger retrieval pools (wikiXXL with 20M sentences), suggesting scalability concerns
- Narrow optimal β range (0.1-1.0) indicates delicate balance requirements in the dual-objective training
- Frozen Semantic Encoder may limit adaptation to domain-specific causal patterns in specialized scientific domains

## Confidence

- CAWAI's causal retrieval superiority over baselines: **High** (supported by consistent improvements across multiple datasets and metrics)
- Dual-objective training mechanism effectiveness: **Medium** (ablation studies confirm semantic loss contribution, but optimal β range is narrow)
- Zero-shot generalization capability: **Medium** (performance drops on larger retrieval pools suggest potential overfitting to training data characteristics)

## Next Checks

1. **Encoder specialization validation**: Swap Cause and Effect encoders at inference and measure performance degradation. If CAWAI truly learns directional causal patterns, swapping should cause significant performance drops.
2. **Cross-dataset generalization**: Train exclusively on e-CARE, then evaluate on scientific QA tasks (SciFact, SciQ) without fine-tuning. Compare performance drop against DPR baseline to quantify zero-shot generalization.
3. **Negative sampling sensitivity**: Vary batch composition to test robustness to different negative sampling strategies. Test with batch sizes of 16, 32, and 128 to assess whether performance degradation on large retrieval pools stems from inadequate negative sampling.