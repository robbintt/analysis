---
ver: rpa2
title: 'Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms'
arxiv_id: '2505.21792'
source_url: https://arxiv.org/abs/2505.21792
tags:
- learning
- multimodal
- data
- federated
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a taxonomy of multimodal federated learning
  (MFL) through the lens of three FL paradigms: horizontal FL (HFL), vertical FL (VFL),
  and hybrid FL. The key insight is that multimodal data introduces distinct challenges
  in each paradigm - HFL faces modality heterogeneity across clients, VFL encounters
  increased privacy risks from cross-party embedding transmission, and hybrid FL struggles
  with computational and communication efficiency due to complex data partitioning.'
---

# Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms

## Quick Facts
- **arXiv ID:** 2505.21792
- **Source URL:** https://arxiv.org/abs/2505.21792
- **Reference count:** 40
- **Primary result:** Proposes taxonomy of MFL through HFL, VFL, and hybrid FL paradigms, identifying distinct challenges and future directions

## Executive Summary
This paper provides a comprehensive survey of multimodal federated learning (MFL) through the lens of three federated learning paradigms: horizontal FL (HFL), vertical FL (VFL), and hybrid FL. The key insight is that multimodal data introduces distinct challenges in each paradigm - HFL faces modality heterogeneity across clients, VFL encounters increased privacy risks from cross-party embedding transmission, and hybrid FL struggles with computational and communication efficiency due to complex data partitioning. The paper systematically reviews representative works in each category, identifying key challenges and proposing future research directions including lightweight model design, privacy-preserving mechanisms, unsupervised learning, and personalized MFL.

## Method Summary
The paper conducts a comprehensive literature review across the three FL paradigms, analyzing how multimodal data characteristics affect each paradigm's assumptions and mechanisms. The authors systematically categorize existing works based on data partitioning schemes and identify common challenges and solutions within each category. The survey draws connections between centralized multimodal learning techniques and their federated counterparts, highlighting gaps and opportunities for future research.

## Key Results
- Multimodal HFL faces modality heterogeneity that disrupts feature alignment and model aggregation
- Multimodal VFL increases privacy risks through cross-party transmission of rich semantic embeddings
- Hybrid FL suffers from efficiency bottlenecks due to complex coordination requirements
- Current MFL research focuses heavily on supervised learning, leaving unsupervised approaches largely unexplored
- Lightweight model design, privacy-preserving mechanisms, and personalization are identified as key future directions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** In Multimodal HFL, modality heterogeneity disrupts standard aggregation because clients possess non-overlapping feature subspaces.
- **Mechanism:** Different clients own different subsets of modalities (e.g., Client A has Image+Text, Client B has Text only). Standard FedAvg assumes a shared feature space. When clients train local models on divergent modality subsets, their weight updates correspond to incompatible sub-models. Aggregating these updates via weighted averaging introduces noise and conflicting gradients, degrading the global model's convergence.
- **Core assumption:** Standard aggregation algorithms (like FedAvg) fail to handle partial model structures effectively, and local model architectures are not perfectly disentangled or masked to account for missing modalities.
- **Evidence anchors:**
  - [abstract]: Mentions that in HFL, "modality heterogeneity... disrupts feature alignment and model aggregation."
  - [section 3.4]: States that "Clients with non-overlapping modalities may learn incompatible representations, and directly aggregating their updates can introduce noise... which degrades global model performance."
  - [corpus]: MMiC and ClusMFL specifically target "Modality Incompleteness," supporting the assertion that this is a primary failure mode in distributed multimodal systems.
- **Break condition:** This mechanism fails if local models are architecturally constrained to share a universal latent space regardless of input modalities, or if distinct aggregation rules (e.g., modality-specific weighted averaging) are successfully applied.

### Mechanism 2
- **Claim:** In Vertical FL (VFL), privacy leakage is amplified because cross-party transmission of intermediate embeddings carries rich semantic information susceptible to reconstruction.
- **Mechanism:** VFL requires clients to send embeddings to a server for fusion. Unlike gradients in unimodal FL, multimodal embeddings are dense, high-information representations. Adversaries can exploit these transmitted vectors using gradient inversion or feature inference attacks (e.g., Generative Regression Networks) to approximate the raw input data of other parties.
- **Core assumption:** Raw modalities cannot be shared and standard encryption or secure aggregation may be insufficient if the semantic content of the embeddings themselves leaks sensitive attributes.
- **Evidence anchors:**
  - [abstract]: Highlights that in VFL, "cross-party transmission of embeddings increases privacy risks such as representation-based inference and gradient reconstruction attacks."
  - [section 4.3]: Details specific attacks like the "Reverse Multiplication Attack (RMA)" and "CAFE," noting that "multimodal embeddings often carry rich semantic information that... may unintentionally reveal sensitive attributes."
  - [corpus]: Corpus evidence regarding specific VFL attacks is weak or generic; the primary evidence is internal to the survey's cited methodologies (e.g., CAFE, WMI).
- **Break condition:** This mechanism is mitigated if differential privacy is effectively applied to embeddings, or if the architecture uses split learning where the cut layer minimizes reconstructable information.

### Mechanism 3
- **Claim:** Efficiency bottlenecks in Hybrid FL arise from the coordination complexity of simultaneously aligning sample spaces (HFL) and feature spaces (VFL).
- **Mechanism:** Hybrid FL involves "silos" that must coordinate internally while also synchronizing with a global server. The mechanism of failure is dual-layer communication overhead: (1) high-frequency embedding exchange for intra-silo fusion and (2) periodic model aggregation for inter-silo updates. This load overwhelms resource-constrained edge devices, creating stragglers.
- **Core assumption:** The system operates on devices with limited bandwidth and computation, and modality encoders (e.g., Vision Transformers) are too heavy for edge-only processing without offloading.
- **Evidence anchors:**
  - [abstract]: Identifies that in hybrid FL, "partitioning both sample and feature spaces introduces efficiency bottlenecks due to complex coordination."
  - [section 5.3]: Explains that "The dual-axis training structure simultaneously involves VFL... and HFL," creating "substantial system complexity in terms of computational cost and communication coordination."
  - [corpus]: The corpus mentions "Cloud-Edge-Terminal Collaborative Intelligence," which aligns with the structural complexity, though specific hybrid bottleneck evidence is largely internal to the survey.
- **Break condition:** This mechanism is less relevant if asynchronous communication protocols are robust or if edge devices have sufficient computing power to handle local fusion without significant latency.

## Foundational Learning

- **Concept:** Data Partitioning Schemes (HFL vs. VFL)
  - **Why needed here:** The entire taxonomy of the paper rests on distinguishing how data is split. Without understanding that HFL splits *samples* (rows) and VFL splits *features* (columns), the distinct challenges of modality heterogeneity vs. privacy leakage cannot be correctly diagnosed.
  - **Quick check question:** If two hospitals have different patients but record the same types of data (MRI + Genomics), is this HFL or VFL? (Answer: HFL).

- **Concept:** Multimodal Fusion Strategies (Early vs. Late)
  - **Why needed here:** The survey discusses "modality heterogeneity" in HFL. Understanding *when* fusion happens is critical to diagnosing the problemâ€”if fusion is early (input-level), missing modalities break the pipeline; if late (decision-level), aggregation becomes complex.
  - **Quick check question:** Does the system combine raw pixels and audio waves before training (Early), or does it combine the output probabilities of two separate networks (Late)?

- **Concept:** Gradient Inversion / Model Inversion Attacks
  - **Why needed here:** This is the core risk mechanism in VFL identified by the paper. One must understand that gradients/embeddings are not abstract math but contain "shadows" of the training data to grasp why VFL privacy is a unique challenge.
  - **Quick check question:** Can an attacker reconstruct a training image solely by analyzing the gradients sent to the server? (Answer: Yes, in many cases).

## Architecture Onboarding

- **Component map:**
  - Clients/Parties -> Local Encoders -> Communication Links -> Aggregation Server
  - (Hospital A holds Images) -> (CNN encoder) -> (embedding vectors) -> (Server fuses embeddings)
  - (Bank B holds Transaction Logs) -> (BERT encoder) -> (embedding vectors) -> (Server fuses embeddings)

- **Critical path:**
  1. **Partition Diagnosis:** Determine if your use case is HFL (different users, same data types), VFL (same users, different data types), or Hybrid.
  2. **Modality Check:** Identify if all clients have all modalities. If not (HFL), implement modality-agnostic encoders or partial aggregation logic immediately.
  3. **Privacy Assessment:** If VFL, audit the embedding exchange layer. Apply compression or noise (DP) before transmission.

- **Design tradeoffs:**
  - **Modality Completeness vs. Convergence:** Enforcing strict modality completeness improves model quality (HFL) but excludes clients with limited hardware, reducing data volume.
  - **Embedding Richness vs. Privacy:** Sending high-dimensional, unprocessed embeddings improves fusion performance (VFL) but drastically increases the success rate of reconstruction attacks.
  - **Coordination Frequency vs. Efficiency:** Frequent synchronization in Hybrid FL improves accuracy but exacerbates the "straggler" problem on edge networks.

- **Failure signatures:**
  - **HFL Stagnation:** Training loss plateaus early; analysis shows client gradients are cancelling each other out due to modality misalignment.
  - **VFL Data Leak:** Audit reveals that an attacker querying the VFL server can recover recognizable facial features or text segments from the gradient updates.
  - **Hybrid Straggling:** System time-out errors increase linearly with the number of silos; the bottleneck is identified as the intra-silo embedding exchange bandwidth.

- **First 3 experiments:**
  1. **HFL Heterogeneity Stress Test:** Run a standard FedAvg baseline on a multimodal dataset (e.g., VQA). Then, artificially mask/erase 50% of modalities for random clients to observe the performance drop and verify the "modality heterogeneity" challenge.
  2. **VFL Leakage Simulation:** Implement a basic VFL setup. Attempt a Gradient Inversion attack on the server side to verify if raw features (e.g., image outlines) are recoverable from the embeddings.
  3. **Hybrid Latency Profile:** Set up a Hybrid FL simulation (e.g., using FedMultimodal or a custom split). Measure communication latency as the number of silos and modalities increase to confirm the efficiency bottleneck.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can scalable, general-purpose unsupervised MFL frameworks be designed to handle partially or entirely unlabeled multimodal data across heterogeneous clients?
- **Basis in paper:** [explicit] The authors state that "real-world applications frequently involve partially or entirely unlabeled multimodal data" and that only "a few pioneering works have explored unsupervised MFL setups." They explicitly call for "scalable, general-purpose unsupervised MFL frameworks inspired by centralized self-supervised strategies."
- **Why unresolved:** Current MFL frameworks predominantly assume supervised learning. Extending contrastive learning and self-supervised methods to federated settings with modality heterogeneity and missing modalities remains largely unexplored.
- **What evidence would resolve it:** A framework demonstrating competitive performance on benchmark datasets (e.g., Kinetics-400, IEMOCAP) using only unlabeled data, with analysis of convergence under varying modality availability across clients.

### Open Question 2
- **Question:** How can federated prompt aggregation, visual-prompt alignment, and adapter sharing be effectively implemented for multimodal large language models in MFL settings?
- **Basis in paper:** [explicit] The authors identify "Knowledge Transfer and Prompt-based Learning" as a "compelling yet underexplored direction," specifically noting that "prompt learning in federated multimodal contexts, including federated prompt aggregation, visual-prompt alignment, and adapter sharing" warrants future investigation.
- **Why unresolved:** While prompt tuning offers communication-efficient personalization, aggregating prompts across clients with heterogeneous modality distributions and aligning visual-textual prompts without sharing raw data presents fundamental challenges not addressed by current methods.
- **What evidence would resolve it:** Empirical evaluation showing reduced communication costs and improved personalization compared to full model fine-tuning, with theoretical guarantees on prompt alignment across modality-specific distributions.

### Open Question 3
- **Question:** What cross-modal attribution methods can provide interpretable explanations for MFL systems where internal representations are distributed across clients?
- **Basis in paper:** [explicit] The authors state that "Current techniques such as Grad-CAM provide interpretability for image-text models but are insufficient for other modality combinations like sensor-audio or video-language." They call for "cross-modal attribution methods, per-modality influence analysis, and interpretable client-side logging tools."
- **Why unresolved:** In federated settings, visibility into client data and model updates is limited by design. Extending attribution methods to work without centralized access to all modalities or intermediate activations remains an open problem.
- **What evidence would resolve it:** Attribution methods that can identify modality-specific contributions to predictions while respecting privacy constraints, validated through user studies on trust and debugging utility in sensitive domains like healthcare.

## Limitations
- Limited quantitative evidence for the severity of identified challenges, particularly for VFL privacy risks and Hybrid FL efficiency bottlenecks
- Most supporting evidence comes from the survey's own cited works rather than external validation
- Analysis is primarily conceptual rather than empirically measured

## Confidence
- **High Confidence:** The paradigm-aware taxonomy structure itself and the identification of modality heterogeneity as a core HFL challenge
- **Medium Confidence:** The VFL privacy leakage mechanism, based on theoretical plausibility and cited attack methods
- **Medium Confidence:** The Hybrid FL efficiency bottleneck claim, which follows logically from architectural complexity but lacks concrete performance benchmarks

## Next Checks
1. **HFL Modality Heterogeneity Quantification:** Conduct controlled experiments measuring FedAvg performance degradation on multimodal datasets when clients have incomplete modality coverage (e.g., 0%, 50%, 100% modality completeness).
2. **VFL Embedding Privacy Attack Success Rate:** Implement and measure the success rate of gradient/feature inversion attacks on multimodal embeddings in a VFL setup, comparing different embedding compression/noise-adding defenses.
3. **Hybrid FL Scalability Benchmark:** Profile communication and computation costs in a hybrid FL system as the number of silos and modalities increases, identifying the exact bottleneck points and measuring the effectiveness of asynchronous coordination protocols.