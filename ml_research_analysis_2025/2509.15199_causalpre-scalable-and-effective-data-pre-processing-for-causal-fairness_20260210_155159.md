---
ver: rpa2
title: 'CausalPre: Scalable and Effective Data Pre-processing for Causal Fairness'
arxiv_id: '2509.15199'
source_url: https://arxiv.org/abs/2509.15199
tags:
- fairness
- data
- attributes
- causal
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CausalPre introduces a scalable causality-guided data pre-processing
  framework that guarantees justifiable fairness without relying on predefined causal
  models. It reformulates the extraction of causally fair relationships as a distribution
  estimation problem, using a tailored low-dimensional marginal factorization to approximate
  the joint distribution and a heuristic algorithm for scalable clique selection.
---

# CausalPre: Scalable and Effective Data Pre-processing for Causal Fairness

## Quick Facts
- arXiv ID: 2509.15199
- Source URL: https://arxiv.org/abs/2509.15199
- Authors: Ying Zheng; Yangfan Jiang; Kian-Lee Tan
- Reference count: 40
- Primary result: Reduces discrimination by over 50% while maintaining more than 99% of original utility on large-scale data

## Executive Summary
CausalPre introduces a scalable causality-guided data pre-processing framework that guarantees justifiable fairness without relying on predefined causal models. It reformulates the extraction of causally fair relationships as a distribution estimation problem, using a tailored low-dimensional marginal factorization to approximate the joint distribution and a heuristic algorithm for scalable clique selection. Extensive experiments on real-world and synthetic datasets demonstrate that CausalPre consistently outperforms state-of-the-art baselines in achieving high causal fairness while preserving data utility, even on large-scale data.

## Method Summary
CausalPre achieves justifiable fairness by modifying only the conditional distribution of the label attribute while preserving all non-label attribute relationships. The method constructs a "fair distribution" where the label Y depends only on admissible (A) and additional (W) attributes by blocking sensitive (S) and inadmissible (I) paths through edge pruning in the implied causal structure. To handle high-dimensional data, it approximates the joint distribution using low-dimensional marginal factorization with carefully selected overlapping cliques, decomposing the distribution into manageable components while maintaining computational tractability through a two-phase heuristic algorithm.

## Key Results
- Reduces discrimination by over 50% compared to original datasets
- Maintains more than 99% of original utility across multiple classifiers
- Scales to 60 million records with 70 attributes while baselines exhaust memory at 20 attributes

## Why This Works (Mechanism)

### Mechanism 1: Distribution-Level Intervention for Justifiable Fairness
Justifiable fairness is achieved by modifying only the conditional distribution of the label attribute, preserving all non-label attribute relationships. Given attribute set V = S ∪ I ∪ A ∪ W ∪ {Y}, CausalPre constructs a "fair distribution" P_G′ where the label Y depends only on admissible (A) and additional (W) attributes—sensitive (S) and inadmissible (I) paths are blocked. This is done via edge pruning in the implied causal structure rather than explicit DAG construction. The core assumption is that the original data distribution is Markov compatible with and faithful to some underlying causal graph.

### Mechanism 2: Low-Dimensional Marginal Factorization
High-dimensional joint distribution can be accurately approximated via low-dimensional marginal factorization using carefully selected cliques. The joint distribution P[V \ {Y}] is decomposed into overlapping cliques {C₁, ..., Cᵣ} with separators {F₁,₂, ..., Fᵣ₋₁,ᵣ}. Each clique captures strongly related attributes (high mutual information), and the factorization P[C₁]·∏P[Cᵢ \ Fᵢ₋₁,ᵢ | Fᵢ₋₁,ᵢ] approximates the full joint while remaining computationally tractable. The core assumption is that pairwise mutual information approximates multivariate mutual information sufficiently for clique quality.

### Mechanism 3: Two-Phase Heuristic Clique Selection
A two-phase heuristic (clique initialization + extension) efficiently produces high-quality overlapping cliques satisfying structural constraints. Phase 1 partitions attributes into r disjoint cliques by iteratively assigning nodes to cliques based on highest affinity (Δ score). Phase 2 extends cliques to overlap by merging separators (top-m attributes by Δₘ score) in a tree-like manner, enforcing acyclicity. The core assumption is that greedy selection based on pairwise MI produces near-optimal cliques for the objective in Equation 12.

## Foundational Learning

- **Concept: do-operator and interventions**
  - Why needed here: Justifiable fairness is defined via interventional distributions P[O|do(S=s), do(K=κ)]; understanding causal effects vs. correlations is essential.
  - Quick check question: Given DAG X→Y→Z, what is the difference between P[Z|X=x] and P[Z|do(X=x)]?

- **Concept: Conditional independence and d-separation**
  - Why needed here: The paper assumes conditional independence constraints (S⊥⊥Y | A∪W) are sufficient for fairness; d-separation provides the graphical criterion.
  - Quick check question: In a chain X→Y→Z, does X⊥⊥Z | Y hold? What if the path is X←Y→Z?

- **Concept: Mutual information and entropy**
  - Why needed here: Clique selection relies on MI to quantify attribute relationships; KL divergence measures distributional distortion.
  - Quick check question: If H(X)=2, H(Y)=2, H(X,Y)=3, what is I(X;Y)?

## Architecture Onboarding

- **Component map:** MI Computation → Clique Initialization → Clique Extension → Label Clique → Sequential Sampling
- **Critical path:** MI Computation → Clique Initialization → Clique Extension → Label Clique → Sequential Sampling. The clique construction (steps 2-4) determines the quality of both fairness and utility.
- **Design tradeoffs:**
  - k+m (max clique size): Larger → better approximation, higher memory; smaller → faster, more information loss
  - m (separator size): Larger → better overlap coverage, reduced flexibility in clique extension
  - α (in CausalPre+): Controls fairness-utility trade-off; α=1 enforces strict fairness, α<1 relaxes constraints
- **Failure signatures:**
  - Invalid results (utility lower than "Dropped" or discrimination higher than "Original"): Section V-B notes Cap-MS/Cap-MF often produce invalid results due to over-aggressive CI enforcement
  - Memory exhaustion: Baseline Cap-MF fails at ~20 attributes (Figure 9); CausalPre handles 70+ attributes
  - High KL divergence: Indicates excessive distribution distortion; Figure 6 shows CausalPre achieves lowest distortion among valid methods
- **First 3 experiments:**
  1. End-to-end validation on Adult dataset: Compare AUC and ROD across LR, RF, MLP classifiers. Expected: CausalPre achieves >99% utility retention and >50% discrimination reduction.
  2. Parameter sweep on clique size (k+m): Vary from 7 to 11 on Adult with MLP. Monitor AUC and ROD. Expected: mild utility degradation (<3%) at smaller sizes with slightly improved fairness.
  3. Scalability benchmark: Generate synthetic datasets with 10-70 attributes and 60M records. Measure runtime and memory. Expected: linear growth for CausalPre; exponential for baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we design fine-grained mechanisms to balance fairness and utility when sensitive attributes are strongly correlated with the label, beyond the linear interpolation used in CausalPre+?
- Basis in paper: Section V.B states that for datasets like Adult and Census-KDD, where sensitive attributes are strongly tied to the label, tuning the interpolation parameter $\alpha$ has a less significant effect.
- Why unresolved: The current mechanism (CausalPre+) relies on a simple linear interpolation between the original and fair distributions ($P_G$ and $P_{G'}$), which fails to effectively disentangle utility from fairness in high-correlation regimes.
- What evidence would resolve it: A new pre-processing technique or parameterization that maintains high utility while strictly enforcing fairness on datasets where $S$ and $Y$ exhibit strong statistical dependence.

### Open Question 2
- Question: What are the theoretical guarantees regarding the optimality gap or approximation error of the heuristic clique selection algorithm compared to the exact optimal solution?
- Basis in paper: Theorem 2 proves that the constrained clique selection problem is NP-hard. The paper empirically validates the heuristic's performance but does not provide theoretical bounds on how closely its selected cliques approximate the global optimum.
- Why unresolved: While the heuristic is shown to be efficient and effective empirically, the theoretical extent to which it captures the "best" set of marginals (compared to the NP-hard optimal) remains unquantified.
- What evidence would resolve it: A formal analysis providing approximation ratios or error bounds for the heuristic relative to the objective function.

### Open Question 3
- Question: How does the approximation of multivariate mutual information using pairwise summation affect performance on data with complex, high-order dependencies?
- Basis in paper: Section IV-C notes that computing exact multivariate MI for clustering is computationally infeasible ($O(2^d)$). The authors adopt an approximation that sums pairwise MI values.
- Why unresolved: The framework relies on this approximation to guide marginal selection. If the data contains significant high-order dependencies with weak pairwise signals, the clique selection might fail to group dependent attributes.
- What evidence would resolve it: An experimental evaluation on synthetic datasets designed to have high multivariate MI but low pairwise MI (e.g., XOR-type relationships).

## Limitations
- Performance depends heavily on correct identification of admissible attributes and proper parameter tuning
- Scalability claims rely on specific hardware configurations not detailed in the paper
- The two-phase heuristic may produce suboptimal cliques compared to global optimization
- Causal assumptions (faithfulness, Markov compatibility) may not hold in real-world datasets with unobserved confounders

## Confidence
- Justifiable Fairness Guarantee (Mechanism 1): High - Supported by formal proof and clear causal framework
- Clique-Based Distribution Approximation (Mechanism 2): Medium - Novel approach with empirical validation but limited theoretical bounds
- Scalability Claims (Mechanism 3): High - Demonstrated through extensive experiments across multiple dataset scales
- MI Computation for Mixed Attributes: Medium - Formula provided but encoding/discretization unspecified
- Sampling Methodology: Low - Sequential sampling lacks algorithmic details
- Causal Assumptions: Medium - Relies on standard but potentially violated assumptions

## Next Checks
1. **Sensitivity Analysis:** Test CausalPre's performance across different parameter settings (k, m, α) on a single dataset to establish robustness boundaries
2. **Causal Structure Validation:** Verify that the identified admissible attributes truly block sensitive paths in known causal structures (e.g., synthetic datasets with ground truth DAGs)
3. **Distribution Reconstruction:** Measure reconstruction error when sampling from generated data vs. original data to quantify information preservation limits