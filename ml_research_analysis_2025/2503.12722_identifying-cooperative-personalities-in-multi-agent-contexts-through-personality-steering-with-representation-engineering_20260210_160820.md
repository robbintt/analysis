---
ver: rpa2
title: Identifying Cooperative Personalities in Multi-agent Contexts through Personality
  Steering with Representation Engineering
arxiv_id: '2503.12722'
source_url: https://arxiv.org/abs/2503.12722
tags:
- player
- personality
- traits
- llms
- cooperation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how personality traits influence the cooperative\
  \ behavior of large language models (LLMs) in multi-agent contexts, specifically\
  \ within Iterated Prisoner\u2019s Dilemma scenarios. Using representation engineering,\
  \ the authors steer LLMs to express varying levels of the Big Five personality traits\
  \ and measure their impact on cooperation."
---

# Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering

## Quick Facts
- **arXiv ID**: 2503.12722
- **Source URL**: https://arxiv.org/abs/2503.12722
- **Reference count**: 7
- **Primary result**: Personality steering via representation engineering effectively promotes cooperation in LLMs, but introduces trade-offs between trust and vulnerability.

## Executive Summary
This paper investigates how personality traits influence the cooperative behavior of large language models (LLMs) in multi-agent contexts, specifically within Iterated Prisoner's Dilemma scenarios. Using representation engineering, the authors steer LLMs to express varying levels of the Big Five personality traits and measure their impact on cooperation. They find that higher Agreeableness and Conscientiousness significantly increase cooperation rates but also increase susceptibility to exploitation. In communication-based variants, these traits reduce lying rates regardless of opponent behavior. When both agents are steered toward Agreeableness and Conscientiousness, they achieve better collective outcomes but at a personal cost. Overall, the results demonstrate that personality-based steering is effective for promoting cooperation in LLMs, but introduces trade-offs between trust and vulnerability.

## Method Summary
The authors employ representation engineering to steer LLMs toward specific personality traits by manipulating their latent representations. They extract personality steering vectors using contrastive prompts for each of the Big Five traits (Agreeableness, Conscientiousness, Neuroticism, Openness, Extraversion). These vectors are then applied to model representations during inference with a steering factor of 3.5. The study tests this approach across three LLM variants (GPT-3.5-turbo, Llama-2-7b, Mistral-7b) in Iterated Prisoner's Dilemma games with and without communication. Cooperation rates, exploitation susceptibility, and collective outcomes are measured across different personality configurations and opponent behaviors.

## Key Results
- Higher Agreeableness and Conscientiousness significantly increase cooperation rates in IPD scenarios
- Agreeableness and Conscientiousness increase vulnerability to exploitation when faced with defectors
- Personality-steering reduces lying rates in communication-based IPD variants regardless of opponent behavior
- When both agents are steered toward Agreeableness and Conscientiousness, collective outcomes improve but at personal cost

## Why This Works (Mechanism)
The mechanism relies on representation engineering to manipulate the latent space of LLMs, where personality traits are encoded. By amplifying specific trait vectors, the model's behavioral outputs shift toward corresponding personality expressions. This steering affects decision-making processes in game-theoretic contexts, where Agreeableness promotes cooperative choices and Conscientiousness enhances rule-following and long-term thinking. The communication reduction in lying occurs because these traits bias the model toward truthfulness and consideration of others' perspectives.

## Foundational Learning
- **Representation Engineering**: A technique for manipulating LLM behavior by modifying latent representations; needed to steer personality traits without fine-tuning; quick check: verify steering vectors can be extracted and applied across different model architectures
- **Iterated Prisoner's Dilemma**: A repeated game scenario testing cooperation vs. defection; provides framework for measuring personality effects on strategic decision-making; quick check: ensure payoff matrix and iteration count are clearly defined
- **Big Five Personality Traits**: Five-factor model of personality (Agreeableness, Conscientiousness, Neuroticism, Openness, Extraversion); provides psychological framework for steering targets; quick check: confirm trait definitions align with established psychological literature
- **Contrastive Prompting**: Method for extracting steering vectors by contrasting trait expressions; enables targeted manipulation of personality dimensions; quick check: validate that contrastive pairs produce distinct and interpretable vectors
- **Personality-State Transfer**: The application of personality steering to influence model behavior; bridges psychological theory and LLM control; quick check: measure behavioral changes against baseline personality-free responses
- **Cooperation-Exploitation Trade-off**: The balance between cooperative behavior and vulnerability to defection; central to understanding personality-driven strategy selection; quick check: analyze exploitation rates against cooperation gains across different steering intensities

## Architecture Onboarding

**Component Map:**
Mistral-Nemo-Instruct-2407 (12B) -> Representation Extractor -> Contrastive Prompting -> Personality Steering Vectors -> IPD Game Engine -> Outcome Metrics

**Critical Path:**
Model inference → Representation extraction → Vector application (factor 3.5) → Game decision → Outcome measurement

**Design Tradeoffs:**
- Fixed steering factor (3.5) vs. adaptive intensity
- Binary communication vs. natural language
- Single model architecture vs. cross-model validation
- Pure IPD vs. complex multi-agent games

**Failure Signatures:**
- No behavioral change despite steering
- Unintended behavioral artifacts
- Inconsistent cooperation rates across trials
- Overfitting to specific opponent strategies

**Three First Experiments:**
1. Vary steering factor intensity (1.0 to 5.0) to identify optimal balance between cooperation and exploitation resistance
2. Test personality steering transfer across different LLM architectures (Llama, GPT, Gemma) to assess generalizability
3. Implement adaptive steering that reduces Agreeableness when exploitation is detected over time

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does personality steering effectiveness generalize across different LLM architectures, scale, and training paradigms?
- Basis in paper: [explicit] The authors state that "its effectiveness across different LLMs architectures and tasks remains an open avenue for research" in the Limitations section.
- Why unresolved: All experiments used only Mistral-Nemo-Instruct-2407 (12B parameters). The representation vectors were extracted using contrastive prompts on this specific model, and it is unclear whether similar steering effects would emerge in models with different architectures, sizes, or training objectives.
- What evidence would resolve it: Replicating the IPD experiments across diverse model families (e.g., Llama, GPT, Gemma) with varying parameter counts, comparing how steering vectors transfer or require re-extraction for each architecture.

### Open Question 2
- Question: How does personality-based steering perform in more complex multi-agent games with diverse payoff structures and incentive mechanisms?
- Basis in paper: [explicit] The authors acknowledge that "real-world multi-agent interactions involve more complex incentives, which future work can explore by incorporating diverse game-theoretic frameworks."
- Why unresolved: The study only examined Iterated Prisoner's Dilemma with a single payoff matrix. Real-world coordination problems involve asymmetric payoffs, multi-player settings, sequential games, and partial observability that may produce different personality-behavior mappings.
- What evidence would resolve it: Testing personality-steered agents in games like Public Goods, Ultimatum, Trust games, or mixed-motive n-player scenarios to assess whether Agreeableness and Conscientiousness retain their cooperative effects.

### Open Question 3
- Question: Can personality steering be calibrated to promote cooperation while mitigating susceptibility to exploitation?
- Basis in paper: [inferred] The paper identifies a core trade-off—higher Agreeableness and Conscientiousness improve cooperation but increase exploitability—but does not propose or test methods to balance these outcomes.
- Why unresolved: The steering factor (3.5) was fixed to maximize effect, without exploring intermediate intensities or conditional steering that adapts based on opponent behavior over time.
- What evidence would resolve it: Experiments varying steering intensity factor, implementing adaptive steering that reduces Agreeableness when exploitation is detected, or combining traits (e.g., Agreeableness + elevated Neuroticism) to preserve cooperation with enhanced vigilance.

### Open Question 4
- Question: Does richer natural language communication alter the relationship between personality traits, honesty, and cooperative outcomes?
- Basis in paper: [inferred] Communication was limited to the words "cooperate" or "defect." The authors found reduced lying rates with Agreeableness/Conscientiousness, but this constrained protocol may not reflect how traits influence deception in realistic dialogue.
- Why unresolved: With only binary communication, agents could not justify decisions, negotiate, or mislead through complex language. Personality effects on strategic deception may differ when agents can produce open-ended messages.
- What evidence would resolve it: Running IPD variants with unconstrained natural language communication, analyzing whether Agreeableness/Conscientiousness continue to reduce sophisticated deception or whether new strategic behaviors emerge.

## Limitations
- Limited to Iterated Prisoner's Dilemma scenarios, restricting generalizability to other cooperative contexts
- Single LLM model family used without cross-model validation of steering effectiveness
- Binary communication protocol may not reflect realistic personality-behavior relationships
- Fixed steering intensity without exploring adaptive or conditional personality manipulation

## Confidence
- **High Confidence**: The finding that Agreeableness and Conscientiousness positively correlate with cooperation rates in IPD scenarios
- **Medium Confidence**: The claim that personality steering increases vulnerability to exploitation
- **Low Confidence**: The assertion that collective outcomes improve when both agents are steered toward Agreeableness and Conscientiousness

## Next Checks
1. Replicate the experiments across diverse multi-agent game scenarios (e.g., Stag Hunt, Trust Games) to test whether personality steering effects generalize beyond IPD contexts.
2. Implement cross-validation using multiple personality assessment methods (not just representation engineering) to verify that observed behavioral changes genuinely reflect the intended personality traits rather than artifacts of the steering mechanism.
3. Conduct ablation studies to isolate the specific neural representations most critical for personality-driven cooperation, distinguishing between genuine trait expression and confounding factors in the steering process.