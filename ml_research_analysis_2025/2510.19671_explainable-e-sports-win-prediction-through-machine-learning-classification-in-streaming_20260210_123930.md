---
ver: rpa2
title: Explainable e-sports win prediction through Machine Learning classification
  in streaming
arxiv_id: '2510.19671'
source_url: https://arxiv.org/abs/2510.19671
tags:
- data
- prediction
- features
- game
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the challenge of real-time win prediction
  in e-sports, particularly in Counter-Strike: Global Offensive, by proposing a streaming-based
  machine learning solution with integrated explainability. The method leverages sliding
  windows to dynamically engineer features from historical player data, combined with
  real-time in-game metrics, enabling adaptive learning as the game evolves.'
---

# Explainable e-sports win prediction through Machine Learning classification in streaming

## Quick Facts
- **arXiv ID:** 2510.19671
- **Source URL:** https://arxiv.org/abs/2510.19671
- **Reference count:** 40
- **Primary result:** Adaptive Random Forest achieves over 90% accuracy for real-time CS:GO win prediction with integrated explainability

## Executive Summary
This work addresses the challenge of real-time win prediction in e-sports, particularly in Counter-Strike: Global Offensive, by proposing a streaming-based machine learning solution with integrated explainability. The method leverages sliding windows to dynamically engineer features from historical player data, combined with real-time in-game metrics, enabling adaptive learning as the game evolves. Multiple classification models—including Gaussian Naive Bayes, Hoeffding Adaptive Tree, and Adaptive Random Forest—are evaluated using prequential learning and nested cross-validation, with the latter achieving over 90% accuracy. An explainability module provides natural language descriptions and visual dashboards to enhance transparency and trust in predictions. The system minimizes training data requirements (half the game) and supports integration into ranking and recommender systems. Results surpass existing literature, demonstrating robust performance and scalability for real-time e-sports analytics.

## Method Summary
The method processes streaming e-sports data by first aggregating player statistics across teams, then applying four sliding windows (sized to average, 25th, 50th, and 75th percentiles of player game distributions) to compute historical feature statistics. These 240 pre-game features, combined with real-time in-game metrics, are filtered through variance thresholding and fed into stream classifiers evaluated via prequential (predict-then-train) learning. The Adaptive Random Forest model, using 50 estimators and incremental updates, achieves the highest performance (>90% accuracy). An explainability module traverses decision paths to generate natural language explanations and interactive dashboards, enhancing transparency without requiring post-hoc interpretation methods.

## Key Results
- Adaptive Random Forest classifier achieves 92.51% accuracy in full-feature scenario
- System requires only ~50% of game data for training while maintaining >90% accuracy
- Explainability module provides natural language descriptions and visual dashboards for transparent predictions
- Sliding window approach with 4 temporal scales captures player performance evolution effectively

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-scale sliding windows capture player performance evolution at different temporal granularities, enabling the model to adapt as games progress.
- **Mechanism:** Four sliding windows sized to the average, 25th, 50th, and 75th percentiles of the player game distribution compute statistical summaries (mean, quartiles, std, FFT magnitude) from historical features. This produces 240 pre-game features from player skills that reflect both recent form and longer-term trends.
- **Core assumption:** Player performance patterns that correlate with win probability are captured by aggregate statistics over varying historical depths, and these patterns persist within a match.
- **Evidence anchors:**
  - [abstract]: "The method leverages sliding windows to dynamically engineer features from historical player data, combined with real-time in-game metrics, enabling adaptive learning as the game evolves."
  - [Section 3.2.1]: "four sliding windows will be applied, each with the samples equivalent to the values mentioned above (i.e., average, 25th, 50th, and 75th percentiles). For each of the four sliding windows and each feature...some values will be calculated: average, 25th, 50th, and 75th percentiles, the standard deviation (std), and the maximum modulus of the Fast Fourier Transform (fft)."
  - [corpus]: TSKAN paper (FMR 0.517) demonstrates interpretable ML over time series using windowed approaches, supporting the general viability of temporal feature engineering.
- **Break condition:** When game updates fundamentally alter mechanics or when individual player behavior becomes highly erratic, historical window statistics may degrade predictive signal.

### Mechanism 2
- **Claim:** Prequential (predict-then-train) evaluation combined with tree-based stream classifiers enables accurate real-time prediction while requiring only ~50% of game data for training.
- **Mechanism:** Each incoming sample is classified before the model is updated with that sample's ground truth. The Adaptive Random Forest (ARFC) maintains an ensemble of incrementally-updated trees with drift detection, achieving 92.51% accuracy in the full-feature scenario.
- **Core assumption:** The feature-to-win-probability relationship remains sufficiently stable within a game for incremental learning to converge faster than batch retraining.
- **Evidence anchors:**
  - [abstract]: "Multiple classification models—including Gaussian Naive Bayes, Hoeffding Adaptive Tree, and Adaptive Random Forest—are evaluated using prequential learning and nested cross-validation, with the latter achieving over 90% accuracy."
  - [Section 4.4]: "In this regard, the biggest difference are between the gnb baseline and arfc (i.e., 18.34%, 16.98%, 17.37%, 18.33% in accuracy, precision, recall and f-measure, respectively)...the arfc classifier exhibits the best performance (i.e., all metrics are above 90%)."
  - [corpus]: No direct corpus evidence for prequential learning in e-sports; corpus primarily covers batch win prediction methods.
- **Break condition:** Rapid mid-game strategy shifts (concept drift) that invalidate learned patterns faster than the ensemble can adapt.

### Mechanism 3
- **Claim:** Decision path traversal through tree-based models provides transparent, actionable explanations via feature frequency counting and natural language generation.
- **Mechanism:** The explainability module traverses decision paths through each estimator, counting feature occurrences to rank importance. Top features are presented in natural language with confidence scores and visualized on a dashboard showing player positions and accumulated stats.
- **Core assumption:** Feature frequency in decision paths correlates with actual predictive importance, and users interpret these rankings correctly without inferring causation.
- **Evidence anchors:**
  - [abstract]: "An explainability module provides natural language descriptions and visual dashboards to enhance transparency and trust in predictions."
  - [Section 3.4]: "To gather the relevant data to be included in the natural language descriptions, the decision path (greater than and lower than branches) is traversed to extract the track and the feature occurrence number (i.e., frequency of the features)."
  - [Table 1]: Contrasts prior work (feature importance only) with this system's "Feature importance and path, Natural language description, Visual dashboard."
  - [corpus]: MAIT (FMR 0.554) and XAI for Financial Statements (FMR 0.602) support the viability of integrated explainability modules in ML frameworks.
- **Break condition:** Users conflate feature frequency with causal mechanism; explanations become misleading if decision paths are unstable across estimators.

## Foundational Learning

- **Concept: Stream Learning (Incremental/Online Learning)**
  - **Why needed here:** E-sports matches produce sequential data where predictions must be made in real-time and models must adapt without retraining from scratch. Batch learning is infeasible for live prediction.
  - **Quick check question:** Why can't a batch-trained model simply be deployed for real-time e-sports prediction without modification?

- **Concept: Prequential Evaluation (Interleaved Test-Then-Train)**
  - **Why needed here:** Matches the operational constraint that predictions precede ground-truth availability. Each sample tests the model's current state before it learns from that sample.
  - **Quick check question:** In prequential evaluation, does the model see the label before or after making a prediction on each sample?

- **Concept: Intrinsic Interpretability (Tree-Based Models)**
  - **Why needed here:** Post-hoc explanation methods (e.g., SHAP, LIME) add complexity and may be less faithful. Hoeffding Trees and Random Forests expose decision paths directly, enabling transparent explanation extraction.
  - **Quick check question:** Why might an intrinsically interpretable model be preferred over a black-box model with post-hoc explanations for a trust-critical application?

## Architecture Onboarding

- **Component map:**
  Raw player skills (subset P) + match results (subset R) → team aggregation → sliding window statistics → variance filtering → ARFC prediction → decision path extraction → explanation dashboard

- **Critical path:** Raw player skills (subset P) + match results (subset R) → team aggregation → sliding window statistics → variance filtering → ARFC prediction → decision path extraction → explanation dashboard

- **Design tradeoffs:**
  - ARFC achieves 92.51% accuracy but is ~40× slower than GNB (200.58s vs. 5.33s); acceptable for 22.5 samples/sec throughput
  - Cold start requires ~10% of stream before stable feature windows are established
  - Variance threshold at 10th percentile balances dimensionality reduction vs. information loss
  - Data decimation (1-in-10 samples) improves training efficiency at potential accuracy cost

- **Failure signatures:**
  - Accuracy drops >5% in nested cross-validation vs. standard prequential → possible overfitting to stream order
  - Explanation feature rankings unstable across estimators → model may not have converged
  - Cold start window too small → insufficient historical context for reliable window statistics

- **First 3 experiments:**
  1. Replicate Scenario A (in-game only) vs. Scenario B (in-game + pre-game) comparison; expect ~18% accuracy improvement from adding sliding-window features
  2. Vary cold start chunk size (5%, 10%, 20% of stream) and measure convergence time to >85% accuracy
  3. Validate explanation quality: compare decision-path feature frequencies against held-out permutation importance; assess user trust with/without natural language descriptions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does the inclusion of real-time physiological data (e.g., heart rate variability) enhance the accuracy of streaming win prediction beyond historical skill-based features?
- Basis in paper: [explicit] The authors state they plan to "analyze how new features influence winning prediction (e.g., physiological features of players)."
- Why unresolved: The current study relies exclusively on historical match data and in-game metrics (e.g., kills, economy); it does not yet integrate or test biological signals from players.
- What evidence would resolve it: Experimental results comparing model performance (Accuracy, F-measure) with and without the integration of physiological data streams from live players.

### Open Question 2
- Question: How does the integration of a "human-in-the-loop" feedback mechanism on the explainability dashboard influence user trust and the practical utility of the system?
- Basis in paper: [explicit] The conclusion notes the intent to "analyze user feedback, notably regarding the explainability dashboard," and the paper includes a UI element for user assessment (Fig. 7).
- Why unresolved: While the dashboard and feedback interface are designed, the paper does not present findings from actual user interaction or deployment studies to validate the module's effectiveness.
- What evidence would resolve it: User studies or deployment logs quantifying user satisfaction (e.g., Likert scale analysis) and behavioral changes resulting from the provided explanations.

### Open Question 3
- Question: Can unsupervised classification or reinforcement learning approaches outperform the current supervised Adaptive Random Forest in a streaming e-sports environment?
- Basis in paper: [explicit] The authors list "unsupervised classification" and "reinforcement learning" as future perspectives to be taken into account.
- Why unresolved: The current evaluation is limited to supervised models (Gaussian Naive Bayes, Hoeffding Tree, Random Forest), excluding other learning paradigms.
- What evidence would resolve it: A comparative benchmark where these alternative paradigms are trained on the same data stream and evaluated using the prequential evaluation method described in the paper.

## Limitations

- Sliding window approach assumes player performance patterns remain stable within matches, which may not hold during dramatic strategy shifts
- Explainability module relies on feature frequency in decision paths that may not capture true causal mechanisms
- Stream learning assumes sequential independence and stationarity within games, limiting applicability when rapid concept drift occurs

## Confidence

- **High confidence:** ARFC achieves 92.51% accuracy in prequential evaluation with half-game training data
- **Medium confidence:** Sliding windows effectively capture temporal performance evolution across different timescales
- **Low confidence:** Natural language explanations reliably convey causal understanding to users

## Next Checks

1. **Temporal stability test:** Measure accuracy degradation when inserting synthetic concept drift (random feature value shifts) into the stream at different game progression points.

2. **Explanation faithfulness audit:** Compare feature importance rankings from decision paths against permutation importance on held-out data to quantify explanation reliability.

3. **Cold start robustness evaluation:** Test system performance when historical data is sparse (new players/teams) and quantify the minimum training data percentage needed for acceptable accuracy (>85%).