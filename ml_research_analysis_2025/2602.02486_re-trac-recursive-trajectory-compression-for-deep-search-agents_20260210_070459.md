---
ver: rpa2
title: 'RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents'
arxiv_id: '2602.02486'
source_url: https://arxiv.org/abs/2602.02486
tags:
- re-trac
- search
- state
- answer
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RE-TRAC addresses the limitations of ReAct-style linear reasoning
  workflows in deep research agents, where strict sequential execution hinders revisiting
  earlier states, branching into alternative search directions, and maintaining global
  awareness under long contexts. This often leads to local optima, redundant exploration,
  and inefficient search.
---

# RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents

## Quick Facts
- **arXiv ID:** 2602.02486
- **Source URL:** https://arxiv.org/abs/2602.02486
- **Authors:** Jialiang Zhu; Gongrui Zhang; Xiaolong Ma; Lin Xu; Miaosen Zhang; Ruiqi Yang; Song Wang; Kai Qiu; Zhirong Wu; Qi Dai; Ruichun Ma; Bei Liu; Yifan Yang; Chong Luo; Zhengyuan Yang; Linjie Li; Lijuan Wang; Weizhu Chen; Xin Geng; Baining Guo
- **Reference count:** 40
- **Primary result:** RE-TRAC improves deep research agent accuracy by 15-20% over ReAct baseline on BrowseComp benchmark

## Executive Summary
RE-TRAC addresses the limitations of ReAct-style linear reasoning workflows in deep research agents, where strict sequential execution hinders revisiting earlier states, branching into alternative search directions, and maintaining global awareness under long contexts. This often leads to local optima, redundant exploration, and inefficient search. RE-TRAC introduces a recursive trajectory compression framework that generates structured state representations after each trajectory, summarizing evidence, uncertainties, failures, and future plans. Subsequent trajectories are conditioned on this state representation, enabling iterative reflection and globally informed planning. Empirical results show that RE-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, RE-TRAC-aware supervised fine-tuning achieves state-of-the-art performance at comparable scales. Notably, RE-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.

## Method Summary
RE-TRAC implements a recursive framework where each search trajectory generates a structured state representation summarizing evidence, uncertainties, failures, and future plans. The method compresses trajectory history into five facets (Answer, Evidence, Conclusions, Sources, Uncertainties) after each round, then conditions subsequent rollouts on this compressed state rather than raw history. For smaller models, RE-TRAC-aware supervised fine-tuning trains agents on GLM-4.7-generated RE-TRAC trajectories. The system uses a continuation prompt that injects the state representation and exploration directives into each new round's context. Training employs Qwen3-4B-Instruct and Tongyi-DeepResearch-30B-A3B models with SFT on 104k QA pairs from an entity-tree method, using a learning rate of 2e-5, batch size of 512, and maximum length of 65536.

## Key Results
- RE-TRAC outperforms ReAct by 15-20% accuracy on BrowseComp benchmark with frontier LLMs
- Smaller models (4B) achieve state-of-the-art performance through RE-TRAC-aware supervised fine-tuning
- Monotonic reduction in tool calls and token usage across rounds indicates progressively targeted exploration
- Efficiency gains show ~50% resource consumption compared to baselines while maintaining or improving accuracy

## Why This Works (Mechanism)

### Mechanism 1: Cross-Trajectory State Compression
- **Claim:** Structured state representations enable knowledge transfer across sequential rollouts without context bloat.
- **Mechanism:** After each trajectory τ_t, the system distills findings into a fixed-format state S_t covering: current answer, verified evidence, analytical conclusions, source inventory, and unexplored branches. The next rollout receives S_t as context rather than raw trajectory history, filtering low-level trace details while preserving actionable knowledge.
- **Core assumption:** Models can reliably extract and compress key information from long trajectories into structured summaries without critical information loss.
- **Evidence anchors:**
  - [abstract] "generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans"
  - [Section 4.1] "St ← Compress(τ_t, S_{t-1}; C)" with three complementary facets
  - [corpus] ReSum (arXiv:2509.13313) independently validates summarization for long-horizon search
- **Break condition:** If summarization quality degrades (smaller models struggle), the 4B model shows 30% vs 38.5% when using GLM-4.7 as summarizer—suggesting compression quality gates effectiveness.

### Mechanism 2: Explicit Branch Preservation
- **Claim:** Forcing enumeration of unexplored branches prevents premature convergence in long-horizon tasks.
- **Mechanism:** The state representation explicitly tracks "Uncertainties, Limitations, Gaps" including candidate branches, failed attempts, and uncompleted proposals. Unlike independent rollouts that may re-sample identical paths, RE-TRAC carries forward missed branches as actionable directives for subsequent rounds.
- **Core assumption:** The failure analysis in Table 1 (83–93% of failed trajectories contain incomplete branches) generalizes across task distributions.
- **Evidence anchors:**
  - [Section 3] "the ratio of this case can be up to 93%" for incomplete branch exploration
  - [Figure 4] Visual comparison showing ReAct forgetting branches vs RE-TRAC preserving them
  - [corpus] Weak direct corpus evidence—no neighbor papers specifically address branch preservation in agentic search
- **Break condition:** If tasks require minimal branching or have single clear paths, overhead may not justify gains.

### Mechanism 3: Progressive Search Convergence
- **Claim:** Recursive conditioning yields monotonically targeted exploration, reducing redundant tool calls.
- **Mechanism:** Each round inherits verified facts, preventing re-querying identical sources. The "Evidence Base & Source Verification" facet marks claims as verified/partial/unverified. Empirically, token usage and tool calls decrease across rounds as search space narrows.
- **Core assumption:** Front-loaded exploration cost amortizes over rounds; early redundancy is acceptable if later rounds are efficient.
- **Evidence anchors:**
  - [abstract] "monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration"
  - [Figure 5] RE-TRAC achieves better accuracy with ~50% resource consumption vs baselines
  - [corpus] AutoContext (arXiv:2510.02369) notes redundant interactions from lack of instance-level context
- **Break condition:** If early rounds pursue wrong directions aggressively, compression may lock in misleading priors—mitigated by continuation prompt instructing models to critique summaries.

## Foundational Learning

- **Concept: ReAct paradigm (interleaved reasoning + acting)**
  - Why needed here: RE-TRAC explicitly identifies ReAct's linear structure as the root cause of incomplete exploration; understanding the baseline reveals why recursive compression helps.
  - Quick check question: In ReAct, what happens to early planning decisions when trajectory length exceeds 100K tokens?

- **Concept: Pass@k vs Pass@1 evaluation metrics**
  - Why needed here: The paper's motivation hinges on the gap between single-attempt and multi-attempt performance, proving exploration—not reasoning—is the bottleneck.
  - Quick check question: If Pass@8 is 80% and Pass@1 is 56%, what does this suggest about where improvements should focus?

- **Concept: Supervised fine-tuning on agentic trajectories**
  - Why needed here: Small models require SFT on RE-TRAC-structured data to internalize the compression-aware reasoning pattern; naive application underperforms (Table 4 shows 4B goes from 2.7% to 30% post-SFT).
  - Quick check question: Why can't a base 4B model simply be prompted with RE-TRAC instructions at inference time?

## Architecture Onboarding

- **Component map:** Query input → Initial ReAct rollout → Trajectory compressor → Structured state S_t → State accumulator → Continuation prompter → Next round rollout → Repeat for N rounds
- **Critical path:** Quality of state representations (compressor output). Table 6 shows 4B model gains 8.5 points when using stronger summarizer, indicating this is the bottleneck.
- **Design tradeoffs:**
  - Base vs Full compression spec: Base (5 facets) for small/SFT models; Full (+3 audit facets) for frontier LLMs—more detail but higher token overhead
  - Free-use prompt (Table 5): Without explicit instruction to critique prior summaries, models may over-rely and get stuck in "logic loops"
  - Round budget: Default 8 rounds balances coverage vs cost; diminishing returns visible in per-round accuracy gains (Tables 9–13)
- **Failure signatures:**
  - Early saturation: Accuracy plateaus by round 3–4 (common in MV@8 baselines)—suggests exploration not branching effectively
  - Summary hallucination: Model inherits incorrect conclusions from prior state; detect by cross-checking "Facts & Evidence" against source URLs
  - Over-pruning: Excessive compression discards critical context; manifests as repeated searches for already-visited URLs
- **First 3 experiments:**
  1. **Baseline comparison:** Run RE-TRAC vs MV@8 vs Best@8 on BrowseComp300 subset with identical token budget; verify 15–20% gain is reproducible
  2. **Ablate continuation prompt:** Remove "Critical Evaluation" and "Expand search space" directives from Figure 11; quantify drop in per-round gains (expecting pattern like Table 5 "w/o free-use")
  3. **Summarizer swap:** For a 4B agent, use GLM-4.7 as external compressor; confirm ~8-point lift per Table 6 to isolate compression quality as variable

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can reinforcement learning (RL) be integrated into the RE-TRAC framework to optimize the generation of structured state representations?
- **Basis in paper:** [explicit] The conclusion states: "Future work will explore integrating Re-TRAC with reinforcement learning to further optimize the experience generation process..."
- **Why unresolved:** The current framework relies on supervised fine-tuning (SFT) or inference-time prompting for state compression; it does not use RL to dynamically maximize the utility of the compressed state.
- **What evidence would resolve it:** An implementation of RE-TRAC using RL for compression, demonstrating superior performance or convergence speed compared to the SFT/prompting baselines.

### Open Question 2
- **Question:** How can the trajectory summarization capabilities of smaller models be improved to reduce reliance on stronger teacher models?
- **Basis in paper:** [explicit] The ablation on summarizer quality (Table 6) shows the 4B model performs significantly better when using GLM-4.7 as a summarizer. The authors state: "In terms of how to train a search agent with better summarization ability, We leave this to future study."
- **Why unresolved:** The 4B model's search abilities are currently constrained by its weaker ability to summarize its own trajectory into a useful state representation compared to a frontier model.
- **What evidence would resolve it:** A training methodology that enables a 4B model to generate state representations of comparable utility to those generated by GLM-4.7, achieving similar accuracy when summarizing itself.

### Open Question 3
- **Question:** Can the recursive compression framework generalize effectively to agentic tasks beyond deep research, such as coding or robotics?
- **Basis in paper:** [explicit] The conclusion proposes exploring "scalability across even more diverse agentic tasks."
- **Why unresolved:** The specific state representation facets (Evidence Base, Source Verification) and the BrowseComp/GAIA benchmarks are tailored specifically for information retrieval and web navigation.
- **What evidence would resolve it:** Successful application of RE-TRAC to benchmarks like SWE-bench (coding) or embodied AI tasks, necessitating modifications to the state compression schema to handle code states or spatial memory.

### Open Question 4
- **Question:** What is the optimal mechanism for answer selection across recursive rounds to close the gap between RT@N and Accuracy Prefix (AP@N)?
- **Basis in paper:** [inferred] The appendix defines Accuracy Prefix (AP@N) as an upper bound, noting it "helps quantify how much room remains for improvement in answer selection strategies." The current method simply takes the final round's answer (RT@N).
- **Why unresolved:** The model often finds the correct answer in an intermediate round but fails to select it as the final output, a limitation acknowledged by the performance gap between RT@N and AP@N.
- **What evidence would resolve it:** A verification or selection module integrated into RE-TRAC that identifies and extracts the correct answer from any intermediate round, matching the AP@N performance.

## Limitations
- Effectiveness is gated by summarization quality - smaller models show 30% vs 38.5% performance gap when using weaker vs stronger summarizers
- Claims about monotonic resource reduction lack rigorous statistical validation across all datasets
- Framework appears tailored for information retrieval tasks and may not generalize to domains like coding or robotics without significant modifications

## Confidence
- **High confidence:** The mechanism of explicit branch preservation preventing premature convergence is well-supported by the 83-93% incomplete branch statistics and Figure 4's visual comparison
- **Medium confidence:** The 15-20% accuracy improvement over ReAct on BrowseComp is demonstrated but limited to specific task distributions and model scales
- **Medium confidence:** Progressive search convergence claims are partially supported by Figure 5's efficiency metrics but lack rigorous statistical validation across all evaluation settings

## Next Checks
1. **Statistical significance testing:** Apply paired t-tests or bootstrap confidence intervals to the 15-20% accuracy improvements across BrowseComp folds to verify claims aren't driven by outlier splits
2. **Generalization stress test:** Evaluate RE-TRAC on tasks requiring minimal branching (single-path reasoning) to confirm the overhead claims are valid and that the approach doesn't harm simpler scenarios
3. **Compression quality ablation:** Systematically vary the summarizer strength (using multiple compression quality tiers) on identical agent trajectories to quantify the exact relationship between state representation fidelity and downstream task performance