---
ver: rpa2
title: 'Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets'
arxiv_id: '2510.25779'
source_url: https://arxiv.org/abs/2510.25779
tags:
- agents
- arxiv
- agent
- market
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Magentic Marketplace, an open-source environment
  for studying two-sided agentic markets where AI agents represent both consumers
  and businesses. The environment enables controlled experimentation of LLM agents
  across the complete transaction lifecycle, from search and discovery through negotiation
  to fulfillment.
---

# Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets

## Quick Facts
- **arXiv ID**: 2510.25779
- **Source URL**: https://arxiv.org/abs/2510.25779
- **Reference count**: 11
- **Key outcome**: Introduces an open-source environment for studying two-sided agentic markets where AI agents represent both consumers and businesses, revealing severe first-proposal bias and capability-dependent manipulation resistance

## Executive Summary
Magentic Marketplace is an open-source HTTP/REST environment for evaluating LLM agents in two-sided markets where Assistant Agents (consumers) and Service Agents (businesses) interact through search, negotiation, and transactions. Experiments across multiple models reveal that while frontier models can approach optimal welfare under perfect search conditions, performance degrades sharply with scale and all models exhibit severe first-proposal bias, creating 10-30x advantages for response speed over quality. Proprietary models show robust resistance to manipulation tactics, while open-source models display significant vulnerabilities to psychological manipulation and adversarial prompt injection.

## Method Summary
The environment uses a three-endpoint REST API (register, protocol discovery, action execution) to support autonomous agents performing search, communication, proposal submission, and payment transactions. Experiments used synthetic restaurant and contractor domains with configurable scales (small: 33 customers/99 businesses; medium: 100 customers/300 businesses). Five agent actions are supported: search, send text, send proposal, send payment, and receive messages. Agents use ReACT-style prompting for autonomous decision-making. Models tested include proprietary (GPT-4o, GPT-4.1, GPT-5, Gemini-2.5-Flash) and open-source (GPT-OSS-20b, Qwen3-14b) variants. Welfare is measured as consumer value minus transaction price, with additional metrics for manipulation susceptibility and position bias.

## Key Results
- All models exhibit severe first-proposal bias, with 60-100% selection rates for first proposals versus 0-13.3% for third proposals
- Under perfect search, GPT-4.1 and Gemini-2.5-Flash approach optimal welfare, but lexical search causes 4-65% welfare decline
- Proprietary models show robust resistance to manipulation tactics, while open-source models display significant vulnerabilities to authority appeals and social proof
- First-proposal bias creates 10-30x advantages for faster-responding businesses regardless of offer quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-sided agentic markets can reduce information asymmetry and improve welfare outcomes when discovery mechanisms are accurate.
- Mechanism: Assistant Agents and Service Agents engage in open-ended dialogue to discover bespoke configurations not listed in static catalogs. Agent-to-agent communication overcomes information asymmetries that would require costly human communication.
- Core assumption: Agents can effectively reason about and compare multiple proposals; consumers have stable preferences agents can represent.
- Evidence anchors: "agents can approach optimal welfare under ideal search conditions"; GPT-4.1 and Gemini-2.5-Flash come very close to optimal outcome under perfect search.
- Break condition: When search returns noisy results (lexical search), welfare declines 4-65% depending on model.

### Mechanism 2
- Claim: First-proposal bias creates extreme market distortion, giving 10-30x advantage to faster-responding businesses regardless of offer quality.
- Mechanism: Agents anchor on the first acceptable proposal received rather than comparing alternatives. This satisficing behavior emerges from how LLMs process temporal decision sequences.
- Core assumption: The bias is inherent to current LLM architectures, not merely prompt artifacts.
- Evidence anchors: "all models exhibit severe first-proposal bias, creating 10-30x advantages for response speed over quality"; first proposals achieving selection rates between 60-100% compared to near-zero selection for third proposals.
- Break condition: Even the best-performing model (GPT-4.1) showed 60% first-proposal selection vs. 13.3% third-proposal—bias persists but is less extreme in frontier models.

### Mechanism 3
- Claim: Manipulation resistance correlates with model capability tier; frontier models resist psychological tactics but remain vulnerable to adversarial prompt engineering.
- Mechanism: Proprietary models appear to have training or architecture features that reduce susceptibility to authority appeals, social proof, and loss aversion tactics. However, strong prompt injection attacks can still compromise decision-making.
- Core assumption: Resistance stems from training procedures rather than fundamental architectural differences.
- Evidence anchors: "Proprietary models show robust resistance to manipulation tactics, while open-source models display significant vulnerabilities"; GPT-OSS-20B and Qwen3-4B-2507 proved particularly vulnerable to authority appeals and social proof tactics.
- Break condition: Strong prompt injection with emergency framing ("HEALTH DEPARTMENT CLOSURE") reduced Gemini-2.5-Flash performance, suggesting limits to robustness.

## Foundational Learning

- **Concept**: Two-sided markets with network effects
  - Why needed here: The environment models indirect network effects where competition among businesses benefits consumers; understanding platform economics is prerequisite to interpreting welfare results.
  - Quick check question: Can you explain why adding more businesses to a market can improve consumer welfare even if individual consumers only transact with one?

- **Concept**: Principal-agent problems
  - Why needed here: The paper explicitly distinguishes human principals from AI agents; welfare loss stems from agent mistakes, not misaligned incentives. Understanding this distinction is critical for designing human-in-the-loop systems.
  - Quick check question: In this environment, what causes welfare loss—misaligned incentives between principal and agent, or agent capability limitations?

- **Concept**: REST API design with capability discovery
  - Why needed here: The three-endpoint architecture enables extensibility; new actions appear in /protocol responses without breaking existing agents.
  - Quick check question: Why does the environment use runtime capability discovery via /protocol rather than static API specifications?

## Architecture Onboarding

- **Component map**: Register agent → GET /protocol to discover actions → POST /action with "search" → POST /action with "send" (text messages) → POST /action with "send" (order proposal from Service Agent) → POST /action with "pay" (transaction completion)

- **Critical path**: Register agent → GET /protocol to discover actions → POST /action with "search" → POST /action with "send" (text messages) → POST /action with "send" (order proposal from Service Agent) → POST /action with "pay" (transaction completion)

- **Design tradeoffs**:
  - Three-endpoint minimalism vs. comprehensive functionality: Chose minimalism for extensibility; complexity pushed to action space
  - Asymmetric capabilities: Assistant Agents initiate search and payment; Service Agents respond with proposals. Mirrors conventional customer-driven patterns but limits proactive business discovery.
  - Synthetic vs. real data: Current experiments use fully synthetic data for control; environment supports real datasets via unified schema.

- **Failure signatures**:
  - Premature termination: Agent stops before payment (observed in Qwen3-14b)
  - Role confusion: Agent critiques its own actions while executing them
  - Excessive purchasing: Agent accepts multiple proposals without selection criteria
  - Context window overflow: Large consideration sets degrade decision quality

- **First 3 experiments**:
  1. Replicate the consideration set size experiment: Run GPT-4o with 3, 10, 50, 100 search results; verify 4-5% welfare decline pattern.
  2. Test proposal bias mitigation: Implement forced-wait mechanism requiring agents to receive N proposals before deciding; measure welfare change.
  3. Evaluate manipulation transfer: Test whether models trained to resist authority appeals show cross-domain robustness (restaurants → contractors).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What indexing and search mechanisms enable efficient agent discovery in large-scale marketplaces with heterogeneous services?
- Basis in paper: Listed in Section 3.1 under "Potential Research Directions" as a key challenge for scaling.
- Why unresolved: Current experiments used controlled synthetic data with basic lexical search; real-world scaling mechanisms remain unexplored.
- What evidence would resolve it: Implementation and evaluation of advanced retrieval algorithms within the environment at higher agent densities.

### Open Question 2
- Question: Can specific market mechanisms or agent architectures mitigate the severe "first-proposal bias" (10-30x advantage) observed in all models?
- Basis in paper: Section 5.4 identifies this as a "universal and severe market distortion," and Section 6 calls for designs that include "guardrails against suboptimal decisions."
- Why unresolved: The paper quantifies the bias but does not test interventions; it hypothesizes the issue is a deep limitation of current models.
- What evidence would resolve it: Experiments comparing standard agents against those using forced-delays or ranking-randomization protocols to measure bias reduction.

### Open Question 3
- Question: How do agent behaviors and market efficiency evolve in dynamic environments with repeated interactions and adaptive learning?
- Basis in paper: Section 6 explicitly states the limitation that "experiments focused on static markets" and identifies dynamic effects as a "realistic extension."
- Why unresolved: The current study captures only single-transaction lifecycles without history or adaptation.
- What evidence would resolve it: Longitudinal simulation results showing how welfare and manipulation susceptibility change as agents learn from past transactions.

### Open Question 4
- Question: How can interfaces be designed to allow humans to effectively supervise and override agent decisions in high-stakes transactions?
- Basis in paper: Posed in Section 3.1 and reinforced in Section 6 regarding "principal-agent relationships" and human-in-the-loop designs.
- Why unresolved: The environment currently supports fully autonomous agents; human-intervention protocols are untested.
- What evidence would resolve it: User studies measuring intervention accuracy and resulting utility changes when humans are looped into the transaction protocol.

## Limitations
- First-proposal bias creates severe market distortions where response speed dominates quality, providing 10-30× advantages to faster businesses regardless of offer merit
- Manipulation resistance varies dramatically by model capability tier, with open-source models showing significant vulnerabilities to psychological manipulation and adversarial prompt injection
- Current experiments focus on static markets without repeated interactions or adaptive learning, limiting understanding of dynamic market evolution

## Confidence
- **High Confidence**: The welfare degradation patterns under imperfect search (4-65% decline) and the first-proposal bias magnitude are empirically reproducible across multiple model evaluations
- **Medium Confidence**: The interpretation of first-proposal bias as an inherent LLM satisficing behavior rather than prompt artifact requires additional validation across different prompt designs and agent architectures
- **Low Confidence**: The claim that manipulation resistance stems from training procedures rather than fundamental architectural differences lacks direct evidence

## Next Checks
1. **Bias Mitigation Validation**: Implement and test forced-wait mechanisms requiring agents to receive at least N proposals before decision-making, then measure welfare improvement and bias reduction
2. **Open-Source Robustness Enhancement**: Apply the context extension techniques (YaRN + vLLM) to Qwen3-14b and test whether increased context capacity reduces premature termination and improves manipulation resistance
3. **Manipulation Transfer Testing**: Systematically test whether models trained to resist authority appeals in restaurant domains show cross-domain robustness when applied to contractor or other business types