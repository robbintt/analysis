---
ver: rpa2
title: 'RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs'
arxiv_id: '2510.13901'
source_url: https://arxiv.org/abs/2510.13901
tags:
- raid
- refusal
- decoding
- attack
- jailbreak
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses jailbreak attacks on large language models
  (LLMs), where adversarial suffixes are crafted to bypass safety mechanisms and elicit
  harmful content. The authors propose RAID (Refusal-Aware and Integrated Decoding),
  a framework that optimizes continuous embeddings with three key components: (i)
  gradient-based embedding relaxation, (ii) a refusal-aware triplet regularizer that
  steers activations away from refusal directions in embedding space, and (iii) a
  coherence-preserving objective based on Maximum Mean Discrepancy (MMD).'
---

# RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs

## Quick Facts
- arXiv ID: 2510.13901
- Source URL: https://arxiv.org/abs/2510.13901
- Reference count: 34
- Key outcome: RAID achieves up to 92.35% attack success rate on Llama-2-7B with fewer queries and lower computational cost than state-of-the-art baselines

## Executive Summary
This paper addresses jailbreak attacks on large language models (LLMs), where adversarial suffixes are crafted to bypass safety mechanisms and elicit harmful content. The authors propose RAID (Refusal-Aware and Integrated Decoding), a framework that optimizes continuous embeddings with three key components: (i) gradient-based embedding relaxation, (ii) a refusal-aware triplet regularizer that steers activations away from refusal directions in embedding space, and (iii) a coherence-preserving objective based on Maximum Mean Discrepancy (MMD). After optimization, a critic-guided decoding procedure maps embeddings back to tokens by balancing embedding affinity with language model likelihood. Experiments on multiple open-source LLMs show that RAID achieves higher attack success rates with fewer queries and lower computational cost compared to state-of-the-art baselines.

## Method Summary
RAID constructs adversarial suffixes by optimizing continuous embeddings in the target model's hidden space. The method uses gradient-based optimization to update suffix embeddings while incorporating three regularizers: an adversarial objective targeting affirmative responses, a refusal-aware triplet loss that steers activations away from refusal directions, and an MMD-based coherence term that maintains semantic plausibility. After optimization, a critic-guided beam search decodes the continuous embeddings back to discrete tokens by jointly scoring candidates based on embedding affinity and language model likelihood. The approach is evaluated on AdvBench across multiple 7B parameter models including Llama-2-7B, Mistral-7B, Guanaco-7B, and Vicuna-7B.

## Key Results
- RAID achieves up to 92.35% attack success rate on Llama-2-7B, outperforming baselines like GCG (89.23%)
- Computational cost reduced to 8.7s per attack versus 15.3s for PEZ baseline
- Maintains effectiveness under system prompt constraints with 78.9% ASR
- Reduces perplexity by 15.4% compared to GCG while preserving attack success

## Why This Works (Mechanism)

### Mechanism 1: Refusal-Aware Triplet Regularization
RAID assumes refusal behavior is geometrically localized in activation space and can be represented by a linear direction. The triplet loss contrasts current suffix activations against refusal regions while maintaining similarity to refusal-ablated versions. This steers embeddings away from dense refusal clusters while preserving adversarial strength. The approach relies on the assumption that safety alignment manifests as directional differences in hidden representations.

### Mechanism 2: MMD-Based Coherence Regularization
The MMD loss constrains optimized embeddings to match the distribution of benign reference embeddings, discouraging clustering and maintaining fluency. By penalizing divergence from benign text statistics, this prevents the optimized suffixes from becoming too adversarial to decode coherently. The coherence term serves as a regularizer that keeps outputs on the manifold of natural language while preserving attack effectiveness.

### Mechanism 3: Critic-Guided Decoding
RAID uses joint scoring that balances embedding affinity with language model likelihood during token decoding. This approach shortlists candidates by similarity before computing LM coherence, reducing computational complexity while maintaining effectiveness. The decoding procedure produces suffixes that are both adversarially effective and natural in form, addressing the typical trade-off between attack strength and fluency.

## Foundational Learning

- **Representation-Level Refusal Directions**: Understanding how safety alignment manifests geometrically in hidden space is essential for interpreting the triplet regularizer. Quick check: Can you explain why ablating a direction computed as the difference between harmful and harmless activation means might suppress refusals?

- **Continuous Embedding Relaxation with Gradient Optimization**: RAID lifts discrete suffixes to continuous space for differentiable optimization, enabling gradient-based updates but requiring mapping back to tokens. Quick check: What is the trade-off between optimizing in continuous embedding space versus discrete token search?

- **Distribution Matching via MMD**: The coherence loss uses MMD to regularize suffix embeddings, leveraging kernel-based two-sample tests to preserve fluency. Quick check: Why might MMD be preferred over perplexity as a fluency constraint during embedding optimization?

## Architecture Onboarding

- **Component map**: Input prompt → Embedding relaxation (frozen instruction + learnable suffix) → Optimization loop (L_RAID = L_aff + λ_refusal·L_refusal + λ_MMD·L_MMD) → Refusal geometry estimation (d = μ − ν, r from refusal responses) → Decoding (critic-guided beam search)

- **Critical path**: 1) Estimate refusal direction d and refusal mean r before optimization, 2) Run optimization for T iterations with suffix sampling to update r, 3) Decode final suffix using critic-guided beam search with tuned λ

- **Design tradeoffs**: Refusal regularizer weight affects avoidance of refusal regions vs. over-constraining; MMD weight balances coherence vs. adversarial effectiveness; decoding balance λ trades affinity vs. LM likelihood; reference set choice impacts fidelity vs. speed

- **Failure signatures**: Optimization collapse (narrow clustering), refusal persistence (high refusal rate), incoherent suffixes (nonsensical tokens), high perplexity detection

- **First 3 experiments**: 1) Ablation of refusal regularizer on Llama-2-7B to quantify geometric contribution, 2) Layer sensitivity study varying refusal direction estimation layer, 3) Decoding λ sweep to identify optimal ASR-perplexity operating point

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on linear separability assumption for refusal directions may not generalize across architectures
- MMD coherence term uses vocabulary embeddings without comparison to layer activations
- Critic-guided decoding balance parameter λ not systematically swept to identify optimal operating point
- Attack evaluation binary Match() predicate without disclosure of human verification

## Confidence

**High Confidence:**
- RAID achieves state-of-the-art ASR across multiple models (92.35% on Llama-2-7B vs 89.23% for GCG)
- RAID reduces computational cost compared to baseline methods (8.7s vs 15.3s for PEZ)
- The triplet refusal regularizer effectively steers embeddings away from refusal regions (ASR improvement of 3.12%)

**Medium Confidence:**
- MMD coherence regularization improves fluency without sacrificing attack success (perplexity reduction of 15.4% vs GCG)
- Critic-guided decoding balances adversarial strength and natural language generation
- RAID maintains effectiveness under system prompt constraints (78.9% vs 65.2% for baselines)

**Low Confidence:**
- The refusal direction estimation method generalizes across model architectures
- Vocabulary embeddings serve as adequate reference distribution for MMD
- The margin hyperparameter m=0.5 is optimal for all model types

## Next Checks

1. **Refusal Geometry Validation**: Conduct ablation studies varying the refusal direction estimation layer and comparing against random directions to quantify how critical the geometric assumption is to RAID's effectiveness.

2. **MMD Reference Distribution Comparison**: Replace vocabulary embedding reference with layer-specific activations from benign suffixes and retrain RAID to determine whether the current MMD implementation is optimal.

3. **Decoding Balance Parameter Sweep**: Systematically vary λ ∈ [0.1, 0.3, 0.5, 0.7, 0.9] in critic-guided decoding and plot the complete ASR vs perplexity Pareto frontier to reveal optimal trade-offs.