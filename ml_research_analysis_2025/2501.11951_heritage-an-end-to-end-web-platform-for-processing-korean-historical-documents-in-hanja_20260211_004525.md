---
ver: rpa2
title: 'HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents
  in Hanja'
arxiv_id: '2501.11951'
source_url: https://arxiv.org/abs/2501.11951
tags:
- hanja
- korean
- documents
- historical
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "HERITAGE is a web-based platform for processing Korean historical\
  \ documents written in Hanja, an ancient Korean script derived from Chinese characters.\
  \ The platform provides three AI-assisted tasks\u2014punctuation restoration, named\
  \ entity recognition, and machine translation\u2014to accelerate expert annotation\
  \ workflows."
---

# HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja

## Quick Facts
- arXiv ID: 2501.11951
- Source URL: https://arxiv.org/abs/2501.11951
- Reference count: 9
- HERITAGE is a web-based platform for processing Korean historical documents written in Hanja, providing AI-assisted punctuation restoration, named entity recognition, and machine translation to accelerate expert annotation workflows.

## Executive Summary
HERITAGE is a web-based platform for processing Korean historical documents written in Hanja, an ancient Korean script derived from Chinese characters. The platform provides three AI-assisted tasks—punctuation restoration, named entity recognition, and machine translation—to accelerate expert annotation workflows. Built with a microservice architecture, it uses BERT-based models for sequence labeling and quantized LLMs for translation, achieving F1 scores of 88.61 (punctuation), 97.53 (named entities), and BLEU scores of 48.97 (Korean) and 33.15 (English) for translation. The system also features an interactive glossary offering character-level Korean pronunciations and English definitions. Designed for both Hanja experts and the general public, HERITAGE lowers barriers to accessing Korea's vast historical archives by providing accessible English translations and streamlined annotation tools. The platform is open-source and aims to significantly boost translation efficiency for unexplored Korean historical documents.

## Method Summary
HERITAGE employs a microservice architecture with three core AI components: punctuation restoration and named entity recognition using fine-tuned SikuRoBERTa models for sequence labeling, and machine translation using quantized Qwen2-7B models deployed via vLLM. The system processes Hanja text through a sequential pipeline where punctuation restoration segments text, NER identifies proper nouns, and translation produces Korean and English outputs. The platform features a React/Remix frontend with PocketBase authentication, providing interactive glossary lookup and a four-panel interface for comparing original text with model outputs. Training data includes the Annals of the Joseon Dynasty (AJD) and Korean Literary Collections (KLC), with evaluation on Documents of Royal Secretariat (DRS) and Diaries of Royal Rituals in Joseon (DRRI).

## Key Results
- Punctuation restoration achieves F1 score of 88.61 on royal records and 87.76 on literary works
- Named entity recognition achieves F1 scores of 97.53 on royal records and 83.55 on literary works (limited to Person, Location, and Misc. entity types)
- Machine translation achieves BLEU scores of 48.97 for Korean and 33.15 for English translations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential task decomposition (punctuation → NER → translation) aligned with expert annotation workflows improves output quality by providing structured intermediate representations.
- Mechanism: Each task produces annotations that inform subsequent stages: punctuation restoration segments continuous text into logical units; NER identifies proper nouns for disambiguation; machine translation leverages both to produce more accurate outputs.
- Core assumption: The expert workflow (collation → punctuation → vocabulary analysis → translation) represents an optimal processing order that models can replicate.
- Evidence anchors:
  - [abstract] "providing model predictions of three critical tasks in historical document understanding via Hanja language models: punctuation restoration, named entity recognition, and machine translation"
  - [section 3] "These components mirror and support the traditional expert workflow of punctuation, text collation, vocabulary analysis, and translation"
  - [corpus] Limited direct corpus evidence on sequential pipeline efficacy for ancient languages; related work (Sandhan et al. for Sanskrit) uses similar multi-task integration but without comparative pipeline analysis.
- Break condition: If punctuation errors cascade through NER and translation, degrading final output below baseline single-stage approaches.

### Mechanism 2
- Claim: Transfer learning from Classical Chinese pre-trained models (SikuRoBERTa) to Hanja is effective due to shared character vocabulary and structural similarities, despite centuries of divergent evolution.
- Mechanism: SikuRoBERTa's pre-training on Classical Chinese provides character-level representations that transfer to Hanja; fine-tuning on Hanja corpora (AJD, KLC) adapts these representations to Korean-specific grammatical markers and vocabulary.
- Core assumption: The overlap between Classical Chinese and Hanja character distributions is sufficient to provide useful initial representations before fine-tuning.
- Evidence anchors:
  - [section 3.3] "We employ SikuRoBERTa (Wang et al., 2022) and fine-tune it as a sequence labeling task" with resulting F1 scores of 88.61 (punctuation) and 97.53 (NER) on royal records
  - [section 4.1] References Song et al. (2024) investigating "transferability between Hanja and Classical Chinese"
  - [corpus] HanjaBridge paper addresses related transfer questions but focuses on modern Korean LLMs augmented with Hanja, not historical document processing.
- Break condition: If Hanja-specific vocabulary and grammatical markers (not present in Classical Chinese) occur frequently enough to require Hanja-native pre-training.

### Mechanism 3
- Claim: AWQ quantization of translation models enables practical deployment (single GPU) while maintaining acceptable translation quality.
- Mechanism: Activation-aware weight quantization reduces model precision from FP16 to INT4, decreasing VRAM requirements from ~14GB to ~6GB for a 7B parameter model; vLLM's PagedAttention further optimizes memory for batched inference.
- Core assumption: Quantization-induced accuracy degradation remains within acceptable bounds for expert-assisted workflows where outputs are revised.
- Evidence anchors:
  - [section 3.1] "a dedicated vLLM instance optimized for efficient machine translation using quantized LLM models" with minimum 11GB VRAM requirement
  - [section 3.3] "we employ vLLM with AWQ quantization" achieving BLEU of 48.97 (Korean) and 33.15 (English)
  - [corpus] No corpus evidence directly comparing quantized vs. full-precision translation for ancient languages; assumption remains untested in this domain.
- Break condition: If quantization causes semantic drift in domain-specific vocabulary (official titles, place names) critical for historical accuracy.

## Foundational Learning

- Concept: **Sequence labeling with token classification (BERT-style)**
  - Why needed here: Punctuation restoration and NER both formulate as per-token classification; understanding IOB2 tagging and context windows is essential for debugging model outputs.
  - Quick check question: Given input "王幸温阳" and labels O, O, B-LOC, I-LOC, what spans are identified?

- Concept: **LLM quantization fundamentals (AWQ/PagedAttention)**
  - Why needed here: The MT component relies on quantized inference; understanding trade-offs between precision, memory, and latency is necessary for deployment decisions.
  - Quick check question: Why does AWQ use activation-aware calibration rather than uniform weight quantization?

- Concept: **Hanja linguistic properties vs. Classical Chinese**
  - Why needed here: Evaluating whether transfer learning and translation quality issues stem from model architecture or linguistic divergence requires distinguishing Hanja-specific features.
  - Quick check question: What are two grammatical or vocabulary differences between Hanja and Classical Chinese mentioned in the paper?

## Architecture Onboarding

- Component map:
  - Frontend: React + Remix web application (containerized)
  - Backend-PR/NER: FastAPI server with SikuRoBERTa-SFT models
  - Backend-MT: vLLM API server with Qwen2-7B-SFT (AWQ quantized)
  - Database: PocketBase for authentication/session management
  - Orchestration: Docker containers with HTTPS routing

- Critical path:
  1. User inputs Hanja text via web interface
  2. PR/NER request → FastAPI → SikuRoBERTa inference (~1s)
  3. MT request → vLLM → Qwen2 inference with streaming (~10s for typical document)
  4. Results rendered in four-panel interface with interactive glossary lookup

- Design tradeoffs:
  - Separate FastAPI and vLLM servers: Enables independent scaling but increases operational complexity
  - 512-token context window: Limits document chunk size but enables broader hardware compatibility
  - Ruby-style glossary annotations: Improves readability but requires character-level parsing overhead

- Failure signatures:
  - MT timeout on inputs >512 tokens: Context window truncation without warning
  - NER missing "Organization" entities: Insufficient training data explicitly noted in paper
  - Glossary lookup failures: CC-CEDICT coverage gaps for Hanja-specific characters

- First 3 experiments:
  1. **Latency profiling**: Measure end-to-end latency for PR→NER→MT pipeline vs. MT-only to quantify sequential overhead.
  2. **Transfer learning ablation**: Compare SikuRoBERTa fine-tuned on Hanja vs. Hanja-native pre-training (if data permits) on held-out DRS documents.
  3. **Quantization quality gap**: Translate AJD test set with FP16 and AWQ-INT4 models; compute BLEU delta and manually inspect semantic drift in named entities.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the NER model be extended to include Organization entities with acceptable performance, given that this entity type was omitted due to insufficient training data?
- Basis in paper: [explicit] Footnote 11 states "The Organization entity type is omitted due to insufficient training data."
- Why unresolved: The current NER model only recognizes three entity types (Person, Location, Misc.), limiting its utility for identifying institutional references common in administrative historical documents.
- What evidence would resolve it: Training results with expanded Organization-labeled data showing F1 scores comparable to existing entity types (>83 on literary works, >97 on royal records).

### Open Question 2
- Question: What causes the substantial performance gap between royal records and literary works in NER (97.53 vs 83.55 F1), and can domain adaptation techniques narrow this gap?
- Basis in paper: [inferred] Table results show consistently lower performance on KLC (literary works) across tasks, with NER showing the largest discrepancy of ~14 F1 points.
- Why unresolved: The paper does not analyze whether the gap stems from linguistic variation, annotation inconsistency, or data scarcity in literary corpora.
- What evidence would resolve it: Ablation studies isolating domain shift effects, or improved KLC performance through domain-adaptive pretraining or multi-task learning.

### Open Question 3
- Question: To what extent does HERITAGE actually improve annotation efficiency in real-world expert workflows compared to manual annotation?
- Basis in paper: [explicit] The paper claims the platform "would boost the translation efficiency" and help process documents that "would otherwise take decades," but provides no quantitative user study or time-saved measurements.
- Why unresolved: System-level metrics (processing time, throughput) are reported, but human-in-the-loop productivity gains remain unquantified.
- What evidence would resolve it: A controlled study measuring expert annotation time with and without AI assistance on identical documents.

### Open Question 4
- Question: How can Hanja-to-English translation quality be improved to approach Hanja-to-Korean performance levels (BLEU 33.15 vs 48.97)?
- Basis in paper: [inferred] English translation scores are notably lower than Korean translation, with a ~16 BLEU point gap, suggesting English presents additional challenges.
- Why unresolved: The paper does not investigate whether this gap stems from training data imbalance, linguistic distance, or cultural localization issues.
- What evidence would resolve it: Error analysis of English outputs, or experiments with parallel Hanja-English data augmentation and culturally-aware translation approaches.

## Limitations

- The platform's performance metrics are based on limited domain-specific corpora (AJD and KLC), raising questions about generalizability to other Hanja text types or broader historical periods.
- The 512-token context window may truncate important historical document structures that often exceed this limit, potentially missing context crucial for accurate interpretation.
- The absence of "Organization" entities in the NER task due to training data limitations represents a significant gap in entity coverage, particularly for documents involving bureaucratic or institutional references.

## Confidence

- **High Confidence**: The platform successfully integrates three AI-assisted tasks (punctuation restoration, NER, machine translation) into a functional web interface with reported performance metrics on benchmark datasets. The microservice architecture is technically sound and the reported F1 scores (88.61 for PR, 97.53 for NER) and BLEU scores (48.97 Korean, 33.15 English) are internally consistent with the described model configurations.

- **Medium Confidence**: The effectiveness of sequential task decomposition (PR→NER→MT) aligned with expert annotation workflows is theoretically justified but lacks comparative validation against alternative processing orders or parallel architectures. The transfer learning approach from Classical Chinese to Hanja is supported by related work but not directly validated through ablation studies.

- **Low Confidence**: The claim that quantization-induced accuracy degradation remains within acceptable bounds for expert-assisted workflows is asserted without empirical measurement of semantic drift in domain-specific vocabulary. The assertion that the platform "significantly boosts translation efficiency" for unexplored historical documents lacks quantitative comparison with existing manual or semi-automated approaches.

## Next Checks

1. **Sequential Pipeline Efficacy Analysis**: Conduct controlled experiments comparing the PR→NER→MT sequential pipeline against MT-only and parallel processing approaches on held-out DRS documents, measuring end-to-end translation quality (BLEU, semantic accuracy) and identifying whether punctuation errors cascade through subsequent stages.

2. **Quantization Quality Impact Assessment**: Systematically evaluate the semantic accuracy of AWQ-quantized vs. full-precision translation models on AJD test sets, focusing specifically on named entities, official titles, and place names critical for historical document interpretation. Compute BLEU delta and conduct expert annotation of semantic drift in translation outputs.

3. **Transfer Learning Ablation Study**: Compare the performance of SikuRoBERTa fine-tuned on Hanja against a hypothetical Hanja-native pre-trained model (if training data permits) or a controlled ablation where pre-training is limited to Hanja data only, measuring the impact on PR and NER F1 scores and identifying the contribution of Classical Chinese transfer to final performance.