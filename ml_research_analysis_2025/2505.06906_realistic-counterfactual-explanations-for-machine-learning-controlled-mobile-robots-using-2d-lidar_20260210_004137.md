---
ver: rpa2
title: Realistic Counterfactual Explanations for Machine Learning-Controlled Mobile
  Robots using 2D LiDAR
arxiv_id: '2505.06906'
source_url: https://arxiv.org/abs/2505.06906
tags:
- lidar
- cfes
- data
- counterfactual
- turtlebot3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for generating realistic counterfactual
  explanations (CFEs) for machine learning-controlled mobile robots using 2D LiDAR
  data. The method addresses the challenge of generating interpretable and realistic
  CFEs by parameterizing the LiDAR space with geometric shapes and using a genetic
  algorithm to optimize their placement.
---

# Realistic Counterfactual Explanations for Machine Learning-Controlled Mobile Robots using 2D LiDAR

## Quick Facts
- **arXiv ID**: 2505.06906
- **Source URL**: https://arxiv.org/abs/2505.06906
- **Reference count**: 22
- **Primary result**: A model-agnostic method for generating spatially realistic counterfactual explanations for ML-controlled robots with 2D LiDAR using geometric parameterization and genetic algorithms

## Executive Summary
This paper introduces a method for generating realistic counterfactual explanations (CFEs) for machine learning-controlled mobile robots using 2D LiDAR data. The method addresses the challenge of generating interpretable and realistic CFEs by parameterizing the LiDAR space with geometric shapes and using a genetic algorithm to optimize their placement. The approach generates CFEs in the form of synthetic LiDAR data that resembles a base LiDAR state but is modified to produce a pre-defined ML model control output. The method is demonstrated on a TurtleBot3 controlled using deep reinforcement learning (DRL) in both real-world and simulated scenarios.

## Method Summary
The method parameterizes LiDAR space with simple geometric shapes (circles and rectangles) whose parameters are optimized by a genetic algorithm. These geometric configurations are transformed into LiDAR data via raycasting. The algorithm encodes obstacles using six genes per obstacle (type, position, orientation, size), then transforms these into LiDAR readings via raycasting. Two combination methods are proposed: "min distance" takes the element-wise minimum between baseline and generated readings, while "gen priority" replaces baseline readings within a threshold Dmax. The fitness function combines hinge loss (target output bounds) and proximity loss (similarity to base state) with configurable weights.

## Key Results
- The method generates logical and realistic CFEs that help interpret the DRL agent's decision-making
- Outperforms existing techniques like DiCE in interpretability and similarity to real data when applied to 2D LiDAR data
- Successfully demonstrates CFEs that can be physically validated in real-world robot experiments
- Provides actionable counterfactuals that explain single-step policy decisions in navigation tasks

## Why This Works (Mechanism)

### Mechanism 1: Geometric Parameterization Preserves Spatial Coherence
Parameterizing LiDAR space with geometric shapes rather than directly manipulating individual sensor readings produces spatially coherent counterfactuals by encoding obstacles with six genes (type, position, orientation, size) and transforming them via raycasting.

### Mechanism 2: Genetic Algorithm Navigates Non-Differentiable Raycasting Pipeline
GA-based optimization enables counterfactual search through the non-differentiable raycasting operation and complex ML model landscape using tournament selection, single-point crossover, and 20% mutation rate.

### Mechanism 3: Dual Combination Methods Trade Actionability for Flexibility
Two combination methods (min distance, gen priority) provide different affordances: min distance yields actionable CFEs representing obstacle placement while gen priority allows larger deviations for exploration.

## Foundational Learning

- **Counterfactual Explanations (CFEs)**: Core conceptual framework; CFEs answer "what if" questions by showing minimal input changes that produce different model outputs. Quick check: Given a robot moving forward, what input change would cause it to reverse?
- **LiDAR Sensor Model and Spatial Correlation**: LiDAR returns distance readings at regular angular intervals; consecutive readings often sample the same physical object. Quick check: Why does independently perturbing each LiDAR reading produce unrealistic sensor data?
- **Genetic Algorithm Fundamentals**: GA is the optimization backbone. Quick check: What happens to solution quality if mutation rate is too low? Too high?

## Architecture Onboarding

- **Component map**: Gene space encoder -> GA optimizer (PyGAD) -> Raycaster (Shapely) -> Combiner -> ML model evaluator -> Fitness calculator
- **Critical path**: 1. Define target output bounds B, 2. Select combination method, 3. Set loss weights λy and λp, 4. Run GA until convergence, 5. Decode chromosome → geometric obstacles → combined LiDAR → validate
- **Design tradeoffs**: More obstacles (on): higher expressiveness but slower convergence; Higher λp: more realistic CFEs but may fail to find solutions; Min distance vs gen priority: actionability vs search flexibility
- **Failure signatures**: Noisy CFEs (check geometric parameterization), GA fails to converge (verify fitness function), CFE validates in sim but not reality (sim-to-real gap), Generated obstacles overlap LiDAR origin (dmin constraint not enforced)
- **First 3 experiments**: 1. Replicate DiCE comparison (Figure 4), 2. Validate CFE actionability (Case 1 replication), 3. Policy preference probe (Case 3 replication)

## Open Questions the Paper Calls Out
1. Can this method be effectively extended to 3D LiDAR data while maintaining realistic spatial structure and computational tractability?
2. How can counterfactual explanation methods be adapted to explain sequential decision-making in control tasks rather than single-step actions?
3. Would alternative optimization methods within DiCE produce more realistic LiDAR CFEs if properly adapted for multi-output regression?

## Limitations
- Single-step explanations cannot capture temporal dependencies in sequential decision-making policies
- Effectiveness depends on LiDAR spatial correlations being preserved through geometric parameterization
- Method's generalizability to different robot platforms and sensor configurations remains unproven

## Confidence
- **High Confidence**: Geometric parameterization preserves spatial coherence and produces realistic CFEs compared to pixel-level perturbation methods
- **Medium Confidence**: The GA effectively finds CFEs that satisfy both output constraints and proximity requirements across diverse scenarios
- **Low Confidence**: The method's generalizability to different robot platforms, sensor configurations, and ML model architectures beyond SAC+DRL

## Next Checks
1. **Sim-to-Real Transfer Validation**: Generate CFEs in simulation for at least three distinct scenarios, physically place the corresponding obstacles in the real robot environment, and verify that predicted behavior changes actually occur.
2. **Hyperparameter Sensitivity Analysis**: Systematically vary λy, λp, mutation rate, and population size across five scenarios to identify robust parameter ranges and quantify solution quality trade-offs.
3. **Temporal Policy Evaluation**: Extend the method to generate CFE sequences (e.g., using Monte Carlo tree search or recurrent evaluation) to test whether multi-step counterfactuals better explain complex navigation behaviors than single-step CFEs.