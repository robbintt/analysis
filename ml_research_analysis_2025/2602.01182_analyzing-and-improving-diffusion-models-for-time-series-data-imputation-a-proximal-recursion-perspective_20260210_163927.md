---
ver: rpa2
title: 'Analyzing and Improving Diffusion Models for Time-Series Data Imputation:
  A Proximal Recursion Perspective'
arxiv_id: '2602.01182'
source_url: https://arxiv.org/abs/2602.01182
tags:
- ximp
- xobs
- imputation
- logp
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces SPIRIT, a diffusion model-based approach
  for time-series data imputation that addresses two key limitations of existing methods:
  non-stationarity and objective inconsistency. The authors analyze diffusion models
  through a proximal recursion lens, identifying that the implicit Wasserstein distance
  regularization and dissipative structure hinder performance in non-stationary settings.'
---

# Analyzing and Improving Diffusion Models for Time-Series Data Imputation: A Proximal Recursion Perspective

## Quick Facts
- **arXiv ID:** 2602.01182
- **Source URL:** https://arxiv.org/abs/2602.01182
- **Reference count:** 40
- **Primary result:** SPIRIT outperforms state-of-the-art imputation methods on multiple real-world datasets across various missing ratios

## Executive Summary
This paper addresses critical limitations in diffusion model-based time-series imputation by analyzing the problem through a proximal recursion lens. The authors identify two key issues: non-stationarity handling and objective inconsistency. Standard diffusion models implicitly regularize using squared 2-Wasserstein distance, which enforces strict mass conservation and creates outlier-sensitive imputations. Additionally, the dissipative structure inherent in standard stochastic differential equations (SDEs) disperses imputed values, reducing accuracy. The paper introduces SPIRIT, which employs a novel Semi-Proximal Transport (SPT) discrepancy that relaxes mass-preserving constraints using entropy-induced Bregman divergence, and removes dissipative terms while adding gradient norm regularization. Experiments demonstrate significant improvements over state-of-the-art methods in MAE and MSE metrics across multiple datasets.

## Method Summary
The approach operates in two stages: Score Learning and Recursive Imputation. First, a 3-layer MLP with adaptive layer normalization (hidden dimension 256) is trained using Denoising Score Matching to approximate the gradient of the data distribution. Second, the recursive imputation loop iteratively updates imputed values using proximal operators that optimize the SPT-functional directly. The SPT framework transforms standard optimal transport by replacing the hard mass-preserving constraint with a soft penalty using entropy-induced Bregman divergence, making it more robust to outliers and non-stationary dynamics. The dissipative structure is removed from the functional objective and replaced with gradient norm regularization to improve pointwise accuracy. The method uses alternating optimization between score network updates and imputation updates.

## Key Results
- SPIRIT consistently outperforms state-of-the-art imputation methods on ETT, Exchange, Illness, and Traffic datasets
- The Semi-Proximal Transport (SPT) component significantly improves robustness to non-stationarity and outliers
- Removing dissipative structure while adding gradient norm regularization improves imputation accuracy
- Ablation studies confirm the importance of both SPT and dissipative term removal
- Performance peaks at approximately 256 hidden dimensions, with degradation observed at larger model sizes

## Why This Works (Mechanism)

### Mechanism 1: SPT Improves Robustness to Non-stationarity
Standard diffusion models use squared 2-Wasserstein distance ($W_2^2$) which enforces strict mass conservation. In non-stationary data with transient outliers, this forces the model to transport mass to these outliers (bad couplings). SPT relaxes the hard constraint $\pi_y = \nu$ to a soft penalty using entropy-induced Bregman divergence, allowing selective matching that ignores costly matches to outliers rather than distorting the entire trajectory.

### Mechanism 2: Removing Dissipative Structure Improves Accuracy
Standard SDEs include dissipative regularizers (drift $-x_\tau$ and diffusion $dW_\tau$) that inject entropy and promote sample diversity. While beneficial for generation, this disperses imputed values, raising MSE/MAE. By explicitly removing this term and adding gradient norm regularization $\|\nabla \log p\|^2$, the model shifts from finding a diverse distribution to finding a specific point with "saddle point" property, accelerating convergence to the ground truth.

### Mechanism 3: Proximal Recursion Unifies Score Learning and Imputation
Instead of viewing diffusion purely as reverse-time SDE simulation, the paper frames the update step as a proximal operator solving $\inf_{q'} \text{Objective} + \frac{1}{2\eta} \text{Discrepancy}(q', q)$. This allows derivation of particle dynamics that optimize the SPT-functional directly rather than just simulating a stochastic path, creating a unified framework for both score learning and imputation.

## Foundational Learning

- **Concept: Proximal Operators and Proximal Recursion**
  - **Why needed here:** Required to understand why SPT replaces Wasserstein distance by viewing diffusion inference as an iterative optimization problem rather than denoising chain.
  - **Quick check question:** What mathematical term enforces that the solution $y$ remains in the neighborhood of $x$ in $\text{prox}_g(x)$? (Answer: The squared Euclidean norm term $\frac{1}{2\epsilon}\|y-x\|^2$).

- **Concept: Wasserstein Distance vs. Optimal Transport (OT)**
  - **Why needed here:** Critical for understanding the core critique - standard Wasserstein distance enforces "mass conservation" which is problematic when data has "transient outliers" (noise).
  - **Quick check question:** In the context of this paper, why does standard Wasserstein distance cause "outlier-sensitive imputations"? (Answer: It forces all mass, including outlier mass, to be transported/matched).

- **Concept: Denoising Score Matching (DSM)**
  - **Why needed here:** The "Score Learning" stage relies on training a network $s_\theta$ to approximate the score function ($\nabla \log p$) without knowing the ground truth score explicitly.
  - **Quick check question:** In DSM, what is the network trained to estimate? (Answer: The gradient of the log-density of the noisy data $\nabla \log q_\sigma(\tilde{x}|x)$).

## Architecture Onboarding

- **Component map:** Data patches -> Score Network (3-layer MLP) -> SPT Solver -> Imputed values
- **Critical path:**
  1. **Initialization:** Start with observed data $X_{obs}$
  2. **Score Learning:** Train $s_\theta$ using DSM objective to approximate marginal score
  3. **Recursive Imputation:**
     - Compute descent directions $T_x$ and $T_w$
     - Update log-weights using ApplyGrad and normalize via Softmax
     - Update locations $x_{imp}$ using weighted gradients
     - Mask update to ensure observed values remain fixed

- **Design tradeoffs:**
  - **Fidelity vs. Diversity:** Removing dissipative term prioritizes accurate point estimate (low MAE/MSE) but sacrifices ability to generate multiple diverse plausible samples
  - **Model Capacity:** Performance degrades with hidden dimension beyond 256, suggesting preference for smaller models

- **Failure signatures:**
  - **High MSE on Stationary Data:** SPT complexity may overfit or perform worse than simpler baselines
  - **Divergence:** Step size $\eta$ > 0.01 causes instability
  - **Overfitting:** Too deep score network causes training loss decrease but imputation accuracy degradation

- **First 3 experiments:**
  1. **Toy Outlier Verification:** Replicate Figure 1 on synthetic data comparing standard OT transport plans (coupling to outliers) vs SPIRIT's SPT plan (selective matching)
  2. **Step Size Sensitivity:** Run ablation on ETT-h1 dataset varying $\eta \in \{0.001, 0.002, 0.005, 0.01\}$ to verify "U-shape" performance curve
  3. **Ablation on Dissipative Term:** Train versions with and without dissipative regularizer, compare MAE/MSE to validate objective consistency claim

## Open Questions the Paper Calls Out

- **Open Question 1:** How can SPIRIT be extended to handle Missing Not At Random (MNAR) mechanisms where missingness depends on unobserved values? The current formulation relies on MCAR assumption for theoretical derivation and does not model the missingness mechanism itself.

- **Open Question 2:** Can SPIRIT be adapted to provide reliable uncertainty quantification without sacrificing pointwise imputation accuracy? Removing dissipative component to improve accuracy reduces sample diversity, diminishing reliability of uncertainty estimates.

- **Open Question 3:** Can alternative score-learning objectives replace DSM to reduce computational overhead from input-gradient backpropagation? The current implementation requires backpropagating through the network to input layer, increasing computational cost as data scales.

## Limitations

- The theoretical claims about non-stationarity handling rely on specific assumptions about entropic potential and Bregman divergence
- Experimental validation is strong but ablation studies focus on proposed components rather than comprehensive comparisons against all relevant baselines
- The choice of 256 hidden dimensions appears somewhat arbitrary, with limited exploration of optimal architecture space
- The method prioritizes deterministic recovery over uncertainty quantification, limiting its applicability for probabilistic forecasting

## Confidence

- **High Confidence:** Experimental results showing SPIRIT's superior performance on MAE/MSE metrics across all tested datasets and missing ratios
- **Medium Confidence:** Theoretical derivation of SPT discrepancy and its relationship to standard Wasserstein distance, relying on specific mathematical assumptions
- **Medium Confidence:** Claim that removing dissipative structure improves imputation accuracy, supported by ablation studies but represents departure from standard diffusion model practice

## Next Checks

1. **Sensitivity Analysis:** Perform extensive grid search on step size Î· and hidden dimension H to map full performance landscape and verify claimed "U-shape" curve

2. **Stationary vs Non-stationary:** Test SPIRIT on purely stationary synthetic data to verify whether SPT complexity is justified or if simpler methods perform comparably

3. **Uncertainty Quantification:** Implement variant retaining dissipative structure to generate multiple samples, then compare both point estimates and uncertainty measures against SPIRIT's single estimate