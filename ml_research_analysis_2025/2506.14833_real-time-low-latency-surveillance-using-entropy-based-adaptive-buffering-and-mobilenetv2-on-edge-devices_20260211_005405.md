---
ver: rpa2
title: Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering
  and MobileNetV2 on Edge Devices
arxiv_id: '2506.14833'
source_url: https://arxiv.org/abs/2506.14833
tags:
- system
- surveillance
- video
- detection
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a real-time surveillance system for resource-constrained
  edge devices using an entropy-based adaptive frame buffering algorithm integrated
  with MobileNetV2. This approach optimizes frame processing by prioritizing frames
  with high informational content, reducing computational load and improving responsiveness.
---

# Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices

## Quick Facts
- arXiv ID: 2506.14833
- Source URL: https://arxiv.org/abs/2506.14833
- Reference count: 17
- Key outcome: Sub-50ms end-to-end inference latency and over 92% detection accuracy on embedded platforms

## Executive Summary
This paper introduces a real-time surveillance system optimized for resource-constrained edge devices. The approach combines an entropy-based adaptive frame buffering algorithm with MobileNetV2 to prioritize frames with high informational content while maintaining detection accuracy. The system achieves sub-50ms latency and over 92% accuracy on platforms like Raspberry Pi 4 and NVIDIA Jetson Nano, outperforming comparable lightweight models in both speed and energy efficiency. Privacy is preserved through local processing without facial recognition, aligning with GDPR principles.

## Method Summary
The system uses MobileNetV2 with ImageNet pretrained weights, trained on a custom 5-class dataset (person, vehicle, fire, weapon, intruder) with focal loss for class imbalance and quantization-aware training. An entropy-based adaptive buffering algorithm computes Shannon entropy H(F) and temporal delta ΔH(Ft, Ft-1) to prioritize frames via P(Ft) = α·H(Ft) + β·ΔH(Ft, Ft-1). Low-priority frames are discarded before inference. Deployment uses TensorRT FP16 on Jetson Nano and ONNX Runtime on Raspberry Pi 4 with batch size 1.

## Key Results
- Sub-50ms end-to-end inference latency with over 92% detection accuracy on embedded platforms
- 18.2% improvement in throughput through entropy-based frame prioritization
- Lower power consumption than Tiny-YOLOv3 and EfficientDet-Lite across tested platforms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entropy-based frame prioritization reduces computational redundancy while preserving detection-relevant content.
- Mechanism: Shannon entropy H(F) computed from grayscale histogram captures spatial complexity; temporal delta ΔH(Ft, Ft-1) captures scene change rate. Priority score P(Ft) = αH(Ft) + βΔH(Ft, Ft-1) ranks frames; low-scoring frames are discarded before inference.
- Core assumption: Frames with low entropy and low temporal change contain redundant information irrelevant to detection tasks.
- Evidence anchors:
  - [abstract] "entropy-based adaptive frame buffering algorithm...optimizes frame processing by prioritizing frames with high informational content"
  - [section 4.3] Formal equation for P(Ft) with α and β hyperparameters; mutex locks for concurrency safety
  - [corpus] Weak direct corpus support for this specific entropy formulation; neighboring papers focus on cloud-edge collaboration and LLM acceleration, not entropy-based frame filtering
- Break condition: Scenes with rapid, uniform motion (e.g., crowds, rain) may generate persistently high entropy scores, potentially overwhelming the buffer without proportional detection value.

### Mechanism 2
- Claim: MobileNetV2's inverted residual structure enables sub-50ms inference on resource-constrained devices when combined with quantization-aware training.
- Mechanism: Depthwise separable convolutions reduce FLOPs; inverted residuals (1×1 expansion → 3×3 depthwise → 1×1 projection) maintain representational capacity at low cost. QAT pre-trains the model for INT8/FP16 precision, reducing latency at deployment.
- Core assumption: The detection task does not require fine-grained spatial features that would be lost in the bottleneck compression.
- Evidence anchors:
  - [abstract] "sub-50ms end-to-end inference latency and over 92% detection accuracy on embedded platforms"
  - [section 4.2] "MobileNetV2...initialized with pretrained weights from ImageNet...focal loss...mixup data augmentations"
  - [section 5, Table 1] Jetson Nano: 38.7ms latency, 92.5% accuracy; Raspberry Pi 4: 47.3ms latency, 90.1% accuracy
  - [corpus] Lokhande and Ganorkar [13] (cited in paper) validated SSD-MobileNetV2 achieving <10ms inference on similar hardware
- Break condition: Highly occluded or small objects may fall below the effective resolution after 320×240 downsampling.

### Mechanism 3
- Claim: Platform-specific inference engines (TensorRT FP16, ONNX Runtime) provide measurable latency gains over generic frameworks.
- Mechanism: TensorRT applies graph optimization and FP16 kernels on Jetson; ONNX Runtime enables cross-platform deployment with optimized operators. Both reduce memory bandwidth and kernel launch overhead.
- Core assumption: The target hardware supports the required instruction sets (e.g., NVIDIA GPU tensor cores, ARM NEON).
- Evidence anchors:
  - [section 4.4] "Jetson Nano...inference was sped up by using NVIDIA's TensorRT in FP16...Raspberry Pi 4, ONNX Runtime was used"
  - [section 5] Power consumption: Jetson Nano 9.5W vs. Tiny-YOLOv3 11.0W; Raspberry Pi 4 7.2W vs. EfficientDet-Lite 8.3W
  - [corpus] EdgeMLBalancer [arxiv:2502.06493] discusses dynamic model switching but does not directly validate TensorRT vs. ONNX tradeoffs
- Break condition: Models with custom operators not supported by TensorRT/ONNX may fall back to unoptimized paths, negating latency gains.

## Foundational Learning

- Concept: Shannon entropy for image analysis
  - Why needed here: Understanding how H(F) = -Σ pi log pi quantifies pixel intensity distribution enables tuning α and β thresholds effectively.
  - Quick check question: Given a grayscale image with 50% black and 50% white pixels, is its entropy higher or lower than a uniform gray image?

- Concept: Depthwise separable convolutions
  - Why needed here: MobileNetV2's efficiency depends on understanding how standard convolutions are factored into depthwise + pointwise operations, reducing parameters by ~8-9×.
  - Quick check question: If a 3×3 convolution has C input and C output channels, how many multiplications does depthwise separable convolution save compared to standard convolution?

- Concept: Quantization-aware training (QAT)
  - Why needed here: QAT simulates quantization during training to minimize accuracy loss at inference; understanding this explains why FP16/INT8 deployment maintains 92%+ accuracy.
  - Quick check question: What is the difference between post-training quantization and quantization-aware training in terms of when quantization error is introduced?

## Architecture Onboarding

- Component map:
  1. Video capture -> frame acquisition (live stream input)
  2. Entropy calculator -> H(F) and ΔH(Ft, Ft-1) computation
  3. Priority scorer -> P(Ft) = αH(Ft) + βΔH(Ft, Ft-1)
  4. Adaptive buffer -> mutex-protected circular buffer with threshold filtering
  5. MobileNetV2 inference -> object detection (person, vehicle, fire, weapon, intruder)
  6. Output handler -> detection results with bounding boxes

- Critical path: Entropy calculation -> priority scoring -> buffer admission decision -> inference. If any step exceeds ~30ms, end-to-end latency breaks the 50ms target.

- Design tradeoffs:
  - α vs. β tuning: Higher α prioritizes complex scenes; higher β prioritizes motion/change. Default values not specified in paper—empirical tuning required.
  - Buffer size: Small buffers reduce staleness but risk dropping frames during burst activity.
  - Resolution (320×240): Faster inference but limits detection range for small objects.

- Failure signatures:
  - Throughput drops >18% -> entropy module disabled or threshold too aggressive (all frames rejected)
  - Latency variance >1.2ms -> buffer race conditions; check mutex implementation
  - Accuracy <88% on validation -> class imbalance not addressed; verify focal loss and mixup are active

- First 3 experiments:
  1. Baseline latency measurement: Run MobileNetV2 inference without entropy buffering on target hardware; establish reference FPS and power consumption.
  2. Entropy threshold sweep: Vary the priority threshold across 5 values (e.g., 10th-50th percentile of training set entropy distribution); measure throughput vs. accuracy tradeoff.
  3. Ablation validation: Disable entropy module (process all frames); confirm the reported 18.2% throughput reduction is reproducible on your hardware.

## Open Questions the Paper Calls Out

- How can federated anomaly detection be integrated into the entropy-based surveillance system to enhance privacy and scalability across distributed deployments?
  - Basis in paper: [explicit] The conclusion states: "Future work includes establishing federated anomaly detection for privacy and scalability options"
  - Why unresolved: The current system operates on isolated edge devices; federated learning would require new protocols for model aggregation without sharing raw video data.
  - What evidence would resolve it: Implementation of a federated learning framework across multiple edge nodes with metrics on detection accuracy, communication overhead, and privacy guarantees.

- How can the system be extended to handle multi-camera inputs for spatial reasoning across larger surveillance areas?
  - Basis in paper: [explicit] The conclusion identifies "devising an extended system to handle multi-camera inputs for a larger surveillance area and spatial reasoning" as future work.
  - Why unresolved: The current single-camera architecture cannot correlate events across overlapping or non-overlapping camera views.
  - What evidence would resolve it: A multi-camera deployment demonstrating cross-camera object tracking accuracy, synchronized frame buffering, and resource allocation efficiency.

- How would an edge-cloud architecture support distributed processing while maintaining the sub-50ms latency constraint?
  - Basis in paper: [explicit] The conclusion mentions "orchestrating the related edge-cloud architecture to support distributed processing" as a future direction.
  - Why unresolved: Network latency introduced by edge-cloud communication risks violating the sub-50ms end-to-end inference latency achieved in edge-only deployment.
  - What evidence would resolve it: A hybrid edge-cloud prototype measuring latency breakdown, offloading decision policies, and conditions under which sub-50ms targets remain achievable.

- Can the entropy threshold hyperparameters (α and β) be adaptively tuned in real-time rather than empirically fixed?
  - Basis in paper: [inferred] The paper states α and β are "empirically tuned hyperparameters," and experiments with "varying entropy threshold parameters" showed improved stability, suggesting fixed values may not generalize.
  - Why unresolved: Static hyperparameters may not adapt to varying scene dynamics, lighting changes, or environmental conditions across deployments.
  - What evidence would resolve it: An adaptive threshold mechanism demonstrating equivalent or superior throughput and latency stability across diverse environments without manual retuning.

## Limitations

- Entropy-based buffering algorithm lacks explicit hyperparameter values (α, β, rejection threshold), requiring empirical tuning that may yield different results across hardware and scene types.
- Dataset construction method is underspecified - while COCO and Open Images are mentioned as sources, the exact process for generating the custom 5-class dataset is unclear.
- Power measurements rely on hardware-specific frameworks (TensorRT/ONNX Runtime) whose optimization levels may vary with software versions and driver configurations.

## Confidence

- High confidence: Sub-50ms latency and >92% accuracy claims are supported by specific hardware benchmarks and measurable end-to-end testing
- Medium confidence: The 18.2% throughput improvement from ablation studies is well-documented, though dependent on entropy threshold tuning
- Medium confidence: Privacy claims based on local processing without facial recognition are technically accurate but require operational validation

## Next Checks

1. Replicate the ablation study on identical hardware to verify the 18.2% throughput improvement from the entropy buffering algorithm
2. Measure per-class detection accuracy for rare events (fire, weapon) to validate the focal loss implementation handles class imbalance effectively
3. Profile end-to-end latency with different entropy threshold settings to establish optimal performance-accuracy tradeoffs across varied scene complexities