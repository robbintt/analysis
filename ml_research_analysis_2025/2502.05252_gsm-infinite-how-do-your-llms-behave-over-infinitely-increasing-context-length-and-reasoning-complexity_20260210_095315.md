---
ver: rpa2
title: 'GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length
  and Reasoning Complexity?'
arxiv_id: '2502.05252'
source_url: https://arxiv.org/abs/2502.05252
tags:
- number
- problems
- reasoning
- context
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces GSM-\u221E, a scalable benchmark for evaluating\
  \ long-context large language models (LLMs) on reasoning tasks with controllable\
  \ complexity and context length. The key idea is to represent math problems as computational\
  \ graphs with varying topology, allowing generation of infinitely many problems\
  \ with adjustable reasoning difficulty and noise levels."
---

# GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?

## Quick Facts
- arXiv ID: 2502.05252
- Source URL: https://arxiv.org/abs/2502.05252
- Authors: Yang Zhou; Hongyi Liu; Zhuoming Chen; Yuandong Tian; Beidi Chen
- Reference count: 25
- One-line primary result: Introduces GSM-∞, a benchmark for evaluating LLMs on infinitely scalable reasoning tasks with controllable complexity and context length, revealing consistent sigmoid decay in performance.

## Executive Summary
This paper presents GSM-∞, a scalable benchmark for evaluating long-context large language models (LLMs) on reasoning tasks with controllable complexity and context length. The key innovation is representing math problems as computational graphs with varying topology, enabling generation of infinitely many problems with adjustable reasoning difficulty and noise levels. The benchmark supports problems with explicit operations, implicit operations, and three-entity variables to induce multiplication/division. Evaluations across 17 LLMs show consistent sigmoid decay in performance as problem complexity increases, with reasoning-optimized models significantly outperforming general-purpose ones.

## Method Summary
GSM-∞ generates arithmetic problems by representing them as directed acyclic computational graphs where nodes are variables and edges are operations (+, -, ×, ÷). Problem difficulty is quantified by topological sort length to the query node. The benchmark supports three subtasks: Symbolic (explicit operations), Medium (2-entity variables with implicit +/-), and Hard (3-entity variables with implicit ×/÷). Noise is injected via "Spider Topology" - extending the core graph with distractor nodes connected to core nodes while maintaining semantic similarity. The generator produces problems with operation counts ranging from 2 to 130+, mapped to natural language using interchangeable templates.

## Key Results
- Consistent sigmoid decay in reasoning performance across 17 LLMs as problem complexity increases (R² > 0.98)
- Reasoning-optimized models (Qwen2.5-32B-Instruct, DeepSeek-Coder-V2) outperform general-purpose models on GSM-∞
- Long-context degradation observed: performance decreases as context length increases from 0 to 32K+ tokens
- Repeated sampling yields linear accuracy gains at exponentially higher computational cost

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Controlling problem complexity via computational graph topology creates fine-grained difficulty scaling
- Mechanism: Problems are represented as DAGs where nodes are variables and edges are operations. Difficulty is quantified by topological sort length to the query node, representing minimum reasoning steps required. Graphs with increasing operation counts scale difficulty continuously.
- Core assumption: Graph depth correlates with human-perceived reasoning difficulty and LLM solution capability
- Evidence anchors: Computational graph generator employs abstract parameters to generate implicit operations; topological sort list ensures shortest solution path as complexity measure

### Mechanism 2
- Claim: Noise injected as semantically connected "spider topology" graph extensions defeats retrieval-based filtering
- Mechanism: Instead of unrelated filler text, noise extends core graphs with distractor nodes and edges pointing outward from core nodes. Maintains semantic relatedness while ensuring noise doesn't contribute to solution path.
- Core assumption: Retrieval systems rely on semantic similarity; semantically proximate but causally irrelevant noise bypasses retrieval filters
- Evidence anchors: Spider topology design ensures majority of added edges connect core nodes and noise nodes; RAG retriever cannot distinguish essential chunks from noise chunks

### Mechanism 3
- Claim: Sigmoid decay in LLM performance reveals fundamental scaling limit in reasoning capability
- Mechanism: Accuracy as function of operation count follows sigmoid curve: near-perfect at low ops, gradual decline, sharp drop, then floor near zero. Consistent across models (R² > 0.98).
- Core assumption: Sigmoid form reflects fundamental property of transformer-based reasoning, not benchmark artifact
- Evidence anchors: Most models exhibit sigmoid-like performance decay with R² > 0.98

## Foundational Learning

- **Computational Graphs as Reasoning Abstraction**
  - Why needed here: Entire benchmark maps arithmetic problems to DAGs where nodes are variables and edges are operations
  - Quick check question: Given a graph with nodes A, B, C and edges A→B (+), B→C (×), if query is C and A=3, B=5, what is solution path and result?

- **Topological Sorting and Operation Count**
  - Why needed here: Operation count (graph depth in topological order) is primary difficulty metric enabling fine-grained control
  - Quick check question: In graph with nodes {V1, V2, V3, V4, V5} and edges V1→V2, V2→V3, V3→V4, V4→V5, what is operation count if V5 is query?

- **Implicit Operations in Natural Language**
  - Why needed here: Benchmark generates implicit operations hidden in semantic hierarchies (e.g., "total money" implies sum)
  - Quick check question: In "Mary earns $20 in morning and $25 in afternoon. How much total?" - is addition explicit or implicit, which node represents total?

## Architecture Onboarding

- Component map: Graph Generator -> Noise Injector -> Template Mapper -> Difficulty Filter -> LLM Input -> Accuracy Calculation -> Sigmoid Curve Fitting -> AUC Scoring

- Critical path: Graph Generator generates DAGs with configurable depth → Noise Injector extends core graphs with spider-topology noise → Template Mapper converts graphs to natural language → Difficulty Filter selects graphs by operation count → LLM processes input → Accuracy calculated per operation count → Sigmoid curve fitted → AUC scored

- Design tradeoffs:
  - Diversity vs. Control: Three templates limit natural language diversity but ensure LLM-readability and avoid real-world knowledge contamination
  - Complexity vs. Context Length: Higher operation counts require longer contexts; difficulty axes are coupled
  - Synthetic vs. Realistic: Synthetic problems enable infinite scaling and precise control but may not fully capture human-authored reasoning nuances

- Failure signatures:
  - Quadratic/Higher-order Equations: Reverse-mode problems can generate multiple solutions; discarded if detected
  - RAG-Exploitable Noise: Semantically distant noise allows retriever filtering; spider topology prevents this
  - Output Token Limits: Long CoT for simple symbolic problems can saturate API limits (4K tokens), causing artificial decay

- First 3 experiments:
  1. Zero-noise baseline: Run model on Symbolic, Medium, Hard subtasks (ops 2-50). Plot accuracy vs. ops, fit sigmoid, confirm R² > 0.98
  2. Noise ablation: At fixed op count (e.g., 10), compare performance across GSM-∞ (spider), LLM-generated filler, and random noise. Verify RAG drops only for GSM-∞ noise
  3. Repeated sampling scaling: For small model, run best-of-N sampling (N ∈ {1, 2, 4, ..., 256}) on fixed Hard problems. Plot AUC vs. log(N); confirm linear relationship (exponential compute for linear gain)

## Open Questions the Paper Calls Out

- Can LLM training methodologies or architectures be modified to eliminate performance asymmetry between "forward-thinking" (constructive) and "reverse-thinking" (implicit subtraction/division) tasks?
- Is it possible to develop inference-time scaling strategies that yield super-linear performance gains, breaking the trade-off where exponential compute increases result in only linear accuracy improvements?
- Does the observed sigmoid decay in reasoning performance persist when benchmark is expanded to include non-arithmetic or higher-order mathematical operators (e.g., exponents, roots, trigonometry)?

## Limitations
- Synthetic nature of problems may not fully capture diversity of human-authored reasoning tasks
- "Spider Topology" noise injection may not represent all forms of distracting information encountered in practice
- Performance patterns may reflect current transformer architectures rather than universal reasoning limitations

## Confidence
- High Confidence: Benchmark generation pipeline and evaluation methodology are well-specified and reproducible
- Medium Confidence: Claim that sigmoid decay represents "fundamental scaling limit" requires more validation across diverse problem types
- Low Confidence: Extrapolations about infinite context length behavior and universality of performance scaling patterns remain speculative

## Next Checks
1. Cross-Domain Generalization Test: Generate GSM-∞ problems using different template domains (e.g., scientific, historical, financial) and evaluate whether sigmoid decay patterns and model rankings remain consistent across domains.

2. Architecture Ablation Study: Test GSM-∞ across diverse model architectures including recurrent models, state-space models, and hybrid architectures to determine whether sigmoid decay is specific to transformers or represents more general reasoning constraint.

3. Human Performance Benchmark: Conduct controlled human evaluations on GSM-∞ problems across difficulty levels to establish baseline human performance curves and validate whether synthetic problems capture cognitively meaningful reasoning challenges.