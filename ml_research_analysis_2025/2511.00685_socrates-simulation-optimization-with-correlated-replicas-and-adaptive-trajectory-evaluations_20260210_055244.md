---
ver: rpa2
title: 'SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory
  Evaluations'
arxiv_id: '2511.00685'
source_url: https://arxiv.org/abs/2511.00685
tags:
- optimization
- system
- learning
- algorithms
- schedule
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SOCRATES, a two-stage LLM-driven framework
  for simulation optimization that constructs digital replicas of complex stochastic
  systems and uses them to meta-optimize optimization algorithms. The method first
  builds Operational AI Replicas (OARs) through LLM-guided causal skeleton discovery
  and EM-type learning, then employs LLMs to iteratively evaluate and revise simulation
  optimization schedules using trajectory-based metrics.
---

# SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations

## Quick Facts
- arXiv ID: 2511.00685
- Source URL: https://arxiv.org/abs/2511.00685
- Authors: Haoting Zhang; Haoxian Chen; Donglin Zhan; Hanyang Zhao; Henry Lam; Wenpin Tang; David Yao; Zeyu Zheng
- Reference count: 40
- Primary result: LLM-driven framework constructs digital replicas and composes hybrid SO schedules, achieving 6.0% cost reduction (26.52±0.85) vs. best standalone method.

## Executive Summary
This paper introduces SOCRATES, a two-stage LLM-driven framework for simulation optimization that constructs digital replicas of complex stochastic systems and uses them to meta-optimize optimization algorithms. The method first builds Operational AI Replicas (OARs) through LLM-guided causal skeleton discovery and EM-type learning, then employs LLMs to iteratively evaluate and revise simulation optimization schedules using trajectory-based metrics. Experiments on a multi-SKU warehouse base-stock optimization problem demonstrate that SOCRATES outperforms standalone optimization algorithms, with the best hybrid schedule (BO-EI(50)→GA(50)) achieving a 6.0% cost reduction (26.52±0.85) compared to the best single method (28.20±1.22). The framework shows improved performance and robustness by leveraging trajectory analysis to compose complementary algorithms across optimization phases.

## Method Summary
SOCRATES operates in two stages: first, it constructs Operational AI Replicas (OARs) by using an LLM to perform causal discovery from textual system descriptions, generating a structural DAG skeleton that guides EM-type learning from historical I/O data; second, it employs an LLM as a meta-optimizer that analyzes optimization trajectory metrics to iteratively revise and compose hybrid algorithm schedules. The framework uses an ensemble of OARs weighted by Dirichlet mixtures, evaluates candidate schedules on this ensemble, and accepts revisions based on validation performance gaps. The approach aims to transfer trajectory signals from replicas to real systems, enabling phase-aware algorithm switching that outperforms standalone methods.

## Key Results
- Best hybrid schedule (BO-EI(50)→GA(50)) achieved mean cost 26.52±0.85, a 6.0% reduction versus best single method (28.20±1.22).
- SOCRATES demonstrated improved robustness with lower variance across random seeds compared to standalone baselines.
- Trajectory-aware meta-optimization successfully identified complementary algorithm strengths, switching from BO to GA after initial exploration phase.

## Why This Works (Mechanism)

### Mechanism 1: LLM-Guided Causal Skeleton Discovery Reduces Hypothesis Space
BFS-based causal discovery from text reduces LLM queries from O(|V|²) to O(|V|) while producing a DAG that constrains model learning. LLM identifies exogenous variables, then iteratively expands children with cycle-checking. The resulting DAG G = (V, E) becomes the structural template for subsequent EM learning, pruning invalid parameterizations.

### Mechanism 2: EM-Type Learning with Latent Consistency Enables Data Efficiency
Alternating E-step (latent inference) and M-step (mechanism update) with consistency regularization enables learning from limited I/O data. E-step balances end-to-end objective fit against per-node mechanism consistency via λ-weighted loss. M-step refits local mechanisms fⱼ while maintaining global alignment via γ term.

### Mechanism 3: Trajectory-Aware Meta-Optimization Complements Algorithm Strengths
Exposing full optimization trajectories (not just final metrics) to LLMs enables phase-aware algorithm switching that outperforms standalone methods. LLM receives trajectory metrics (final improvement, AUC, monotonicity, stability) and revision history. It proposes schedules π = ((aⱼ, Tⱼ)) that allocate budget across algorithms.

## Foundational Learning

- **Concept: Directed Acyclic Graphs (DAGs) and Causal Structure**
  - Why needed: Understanding how variables relate causally is essential for interpreting the LLM-inferred skeleton and why it constrains learning.
  - Quick check: Given variables X₁ → Z → Y, why must learning f_Y depend on Z but not directly on X₁?

- **Concept: Expectation-Maximization (EM) Algorithm**
  - Why needed: The OAR learning uses E-step/M-step alternation; understanding latent variable inference is critical for debugging convergence.
  - Quick check: In the E-step, why might inferred latents drift without the mechanism consistency term?

- **Concept: Simulation Optimization Paradigms (Ranking-and-Selection, Bayesian Optimization, Meta-Heuristics)**
  - Why needed: SOCRATES composes these baselines; knowing when each excels helps interpret LLM scheduling decisions.
  - Quick check: Why might BO excel early (sample-efficient refinement) while GA helps after exploration stalls?

## Architecture Onboarding

- **Component map:** Text input → LLM causal discovery (BFS) → DAG skeleton → EM learning → Ensemble of OARs → Baseline SO library → Execute on OAR ensemble → Collect trajectories → LLM revision loop → Final schedule → Deploy schedule → Monitor real trajectory → (Optional) Adapt if deviation detected

- **Critical path:** Causal skeleton quality → determines EM learning feasibility → OAR fidelity → determines whether trajectory signals transfer to real system → LLM revision effectiveness → determines schedule quality

- **Design tradeoffs:** Skeleton detail vs. data (richer text may improve skeleton but data scarcity still limits learning); Ensemble size (K) vs. cost (larger K improves resilience but increases meta-optimization compute); Revision iterations vs. overfitting (more revisions improve on training OARs but may overfit; validation split detects this)

- **Failure signatures:** Skeleton has cycles or missing edges (check LLM expansion logs for rejected insertions); EM diverges or latents explode (λ may be too small; increase mechanism consistency weight); Schedule overfits OAR but fails on real system (check train-validation gap; enable online adaptation); LLM proposes invalid schedules (add constraint validation layer before execution)

- **First 3 experiments:** 1) Skeleton validation: On known system, compare LLM-inferred DAG to ground truth; measure precision/recall of edges. 2) Ablate EM components: Train OARs with/without mechanism consistency (λ=0 vs. λ>0); compare MSE on held-out data under N=50, 100, 200 samples. 3) Schedule vs. standalone: On multi-SKU warehouse problem, run SOCRATES schedule against best standalone baseline across 5 seeds; verify 6% improvement replicates and measure variance reduction.

## Open Questions the Paper Calls Out
None

## Limitations
- LLM-driven causal discovery from text lacks direct empirical validation and depends heavily on textual quality and LLM capabilities.
- The multi-SKU warehouse experiment uses only 5 random seeds, limiting statistical power and generalizability claims.
- Implementation details for LLM prompts, model specifications, and neural architecture remain underspecified.

## Confidence
- **High Confidence**: EM-type learning mechanism for OAR construction with E-step/M-step alternation and mechanism consistency regularization.
- **Medium Confidence**: Overall two-stage framework architecture and hypothesis that trajectory-aware meta-optimization can identify complementary algorithm strengths.
- **Low Confidence**: Effectiveness of LLM-driven causal discovery from textual descriptions as the most novel and least validated component.

## Next Checks
1. **Causal Skeleton Validation**: On a simple, well-understood system (e.g., M/M/1 queue) where the true causal structure is known, compare the LLM-inferred DAG against ground truth. Measure edge precision/recall and test robustness to textual variations in the system description.

2. **EM Component Ablation Study**: Train OARs with varying λ values (0, 0.1, 0.5, 1.0) and data regimes (N=50, 100, 200 samples). Compare validation MSE and convergence behavior to quantify the importance of mechanism consistency in low-data regimes.

3. **Schedule Transfer Validation**: Beyond replicating the 6% cost reduction on the multi-SKU warehouse problem, test schedule robustness by: (a) running on 3 additional warehouse configurations; (b) comparing against 10+ random schedule baselines; (c) measuring variance reduction across seeds. This addresses both statistical significance and generalizability concerns.