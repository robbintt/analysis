---
ver: rpa2
title: Voice Adaptation for Swiss German
arxiv_id: '2505.22054'
source_url: https://arxiv.org/abs/2505.22054
tags:
- stt4sg
- german
- speech
- dialect
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of developing voice adaptation
  technology for Swiss German dialects, which are underrepresented in existing speech
  synthesis systems. The authors create a large pseudo-labeled dataset (SRG-corpus)
  by automatically transcribing and dialect-tagging approximately 5,000 hours of Swiss
  podcast speech, then fine-tune the XTTSv2 model on this data.
---

# Voice Adaptation for Swiss German

## Quick Facts
- arXiv ID: 2505.22054
- Source URL: https://arxiv.org/abs/2505.22054
- Reference count: 0
- Developed high-quality voice adaptation system for Swiss German dialects using 5,000 hours of weakly labeled podcast data

## Executive Summary
This paper addresses the challenge of developing voice adaptation technology for Swiss German dialects, which are underrepresented in existing speech synthesis systems. The authors create a large pseudo-labeled dataset (SRG-corpus) by automatically transcribing and dialect-tagging approximately 5,000 hours of Swiss podcast speech, then fine-tune the XTTSv2 model on this data. Their approach achieves strong results in both automated and human evaluations: automated metrics show WER as low as 0.107 and BLEU scores up to 0.898 for German content, while human evaluations report CMOS scores up to -0.28 (near human quality) and SMOS scores of 3.8 (very similar voices). The study demonstrates that high-quality voice adaptation for Swiss German dialects is feasible using weakly labeled data and large-scale fine-tuning.

## Method Summary
The authors developed a voice adaptation system for Swiss German dialects by creating a large pseudo-labeled dataset through automatic transcription and dialect-tagging of Swiss podcast speech. They fine-tuned the XTTSv2 model on this 5,000-hour dataset (SRG-corpus) to create speaker-adapted models. The approach leverages weakly supervised learning where transcripts are automatically generated rather than manually annotated. The system was evaluated using automated metrics (WER, BLEU) and human assessments (CMOS for audio quality, SMOS for voice similarity) to validate performance across different dialect and language conditions.

## Key Results
- Automated metrics achieved WER as low as 0.107 and BLEU scores up to 0.898 for German content
- Human evaluations reported CMOS scores up to -0.28 (near human quality) and SMOS scores of 3.8 (very similar voices)
- The approach successfully demonstrated high-quality voice adaptation for Swiss German dialects using weakly labeled data

## Why This Works (Mechanism)
The success stems from leveraging a large volume of Swiss German podcast data that captures natural dialectal variation, combined with the powerful generalization capabilities of the XTTSv2 model architecture. The automatic transcription and dialect-tagging process enables scaling to thousands of hours of data that would be prohibitively expensive to annotate manually. Fine-tuning on this domain-specific data allows the model to learn dialect-specific pronunciation patterns and speaker characteristics that are crucial for natural-sounding synthesis in Swiss German.

## Foundational Learning
- Automatic speech recognition (ASR) systems: why needed - to generate transcripts for the large corpus; quick check - evaluate ASR accuracy on Swiss German dialects
- Speaker diarization: why needed - to separate different speakers in podcast recordings; quick check - verify speaker separation accuracy
- Dialect classification: why needed - to identify Swiss German content within mixed-language podcasts; quick check - test dialect detection precision
- Text-to-speech synthesis: why needed - core technology for voice adaptation; quick check - baseline TTS quality on standard German
- Pseudo-labeling: why needed - enables scaling to large datasets without manual annotation; quick check - measure quality degradation from automatic vs manual labels

## Architecture Onboarding
Component map: XTTSv2 model <- SRG-corpus (5,000h podcast data with ASR transcripts) <- Automatic transcription and dialect-tagging pipeline

Critical path: Podcast data collection → ASR transcription → Dialect tagging → Fine-tuning XTTSv2 → Evaluation

Design tradeoffs: Large weakly labeled dataset vs. smaller professionally annotated data; automatic dialect detection vs. manual speaker annotation

Failure signatures: Poor ASR quality leading to incorrect pronunciations; dialect misclassification reducing adaptation effectiveness; overfitting to podcast-specific acoustic conditions

3 first experiments:
1. Fine-tune XTTSv2 on a small manually transcribed Swiss German dataset for baseline comparison
2. Test speaker adaptation with varying amounts of target speaker data (5h, 10h, 50h)
3. Evaluate cross-dialect generalization by testing adaptation from one Swiss German dialect to another

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies heavily on automated metrics that may not fully capture perceptual quality for dialectal content
- Human evaluation sample sizes are not specified, limiting confidence in perceptual results
- Pseudo-labeling approach quality is not analyzed, with no error analysis of weak labels provided

## Confidence
- Technical approach and methodology: High
- Automated evaluation results: Medium (reliance on pseudo-labels introduces uncertainty)
- Human evaluation results: Medium (small sample sizes not reported)
- Real-world applicability to diverse Swiss German speakers: Low (limited evaluation scope)

## Next Checks
1. Conduct error analysis on pseudo-labeled training data to quantify label quality and identify systematic biases
2. Expand human evaluations to include cross-dialect speaker adaptation tests with larger sample sizes
3. Compare performance against a baseline fine-tuned on professionally transcribed Swiss German speech (if available) to isolate the impact of weak labels