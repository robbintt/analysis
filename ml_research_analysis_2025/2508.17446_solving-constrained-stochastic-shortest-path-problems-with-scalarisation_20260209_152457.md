---
ver: rpa2
title: Solving Constrained Stochastic Shortest Path Problems with Scalarisation
arxiv_id: '2508.17446'
source_url: https://arxiv.org/abs/2508.17446
tags:
- optimal
- carl
- policy
- policies
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CARL, a novel algorithm for solving Constrained
  Stochastic Shortest Path Problems (CSSPs) optimally by using scalarisation to transform
  the problem into a series of unconstrained Stochastic Shortest Path Problems (SSPs).
  CARL searches for an optimal scalarisation using techniques similar to the subgradient
  method, solves each induced SSP with heuristic search, and then combines the resulting
  policies to produce an optimal policy for the original CSSP.
---

# Solving Constrained Stochastic Shortest Path Problems with Scalarisation

## Quick Facts
- arXiv ID: 2508.17446
- Source URL: https://arxiv.org/abs/2508.17446
- Reference count: 38
- Key outcome: CARL solves 50% more CSSP instances than state-of-the-art and offers 10x average speedup on solvable problems

## Executive Summary
This paper introduces CARL, a novel algorithm for optimally solving Constrained Stochastic Shortest Path Problems (CSSPs). CARL uses scalarisation to transform the constrained problem into a series of unconstrained Stochastic Shortest Path Problems (SSPs), then searches for the optimal scalarisation using techniques similar to the subgradient method. The approach solves each induced SSP with heuristic search and combines the resulting policies to produce an optimal solution for the original CSSP. CARL represents the first primal-space heuristic search method for optimal CSSP solutions, demonstrating significant performance improvements over existing dual-space Linear Programming approaches.

## Method Summary
CARL solves CSSPs by transforming them into unconstrained SSPs through scalarisation. The algorithm iterates through scalarisation vectors λ, solving each induced SSP S(λ) using a modified CG-iLAO* heuristic search with vector value functions. CARL employs warm-starting between iterations to accelerate convergence and requires "strong ε-consistency" to capture all deterministic policy constituents for the final stochastic mixture. The optimal policy is extracted by solving a linear system over the support of the final value function. The method uses coordinate search for optimization with subgradient fallback and integrates with CPLEX for policy extraction.

## Key Results
- Solves 50% more benchmark problems than state-of-the-art i2-dual algorithm
- Achieves average 10x speedup on problems all algorithms can solve
- Demonstrates superior performance across five benchmark domains: Search and Rescue, Elevators, Exploding Blocks World, PARC Printer, and Triangle Tireworld

## Why This Works (Mechanism)

### Mechanism 1: Constraint Relaxation via Scalarised Objective
CARL transforms CSSPs into unconstrained SSPs by projecting the vector cost onto a scalar cost using scalarisation parameter λ. This enables the use of efficient primal-space heuristic search instead of slower dual-space Linear Programming approaches. The method relies on strong duality, where the optimal CSSP policy is a convex combination of deterministic policies optimal for the scalarised SSP S(λ*). The transformation creates a concave maximisation problem over λ where subproblems are standard SSPs solvable by algorithms like CG-iLAO*.

### Mechanism 2: Warm-Started Vector Value Functions
CARL maintains a vector value function V tracking all cost types rather than a scalar one. When λ changes slightly between iterations, the previous V serves as a warm start, significantly reducing computation time. The modified CG-iLAO* algorithm tracks value changes (Γ set) to correct any inadmissibility introduced by the warm start, focusing search only on affected states. This approach assumes the optimal policy for S(λ_new) is structurally similar to S(λ_old).

### Mechanism 3: Strong ε-Consistency for Stochastic Policies
To extract a single optimal stochastic policy from the primal solution, CARL requires "strong ε-consistency" where the Bellman residual must be small for all greedy actions in a state, not just one. This stricter condition ensures the final value function V*_∀ encodes every deterministic policy required to form the optimal stochastic mixture via the final linear system (SOL 1). This is necessary because the optimal CSSP policy is stochastic and requires mixing deterministic policies that appear tied at the scalarised optimum λ*.

## Foundational Learning

- **Concept**: Stochastic Shortest Path (SSP) & Bellman Equations
  - **Why needed here**: CARL decomposes the complex constrained problem into standard SSPs. Understanding cost-to-go and Bellman backups is essential for grasping the subproblem solver (CG-iLAO*) and the role of value function V.
  - **Quick check question**: How does an improper policy differ from a proper one in the context of SSP convergence?

- **Concept**: Lagrangian Duality (specifically Scalarisation)
  - **Why needed here**: The core innovation treats constraints as linear penalty terms (λ) in the objective. Understanding that λ represents the "exchange rate" between primary cost and secondary constraint violation is crucial for debugging the outer optimisation loop.
  - **Quick check question**: If a secondary constraint is satisfied with slack, what does complementary slackness imply about the corresponding λ_i? (Answer: It should be 0).

- **Concept**: Heuristic Search (specifically AO*/iLAO* variants)
  - **Why needed here**: The paper assumes familiarity with concepts like "fringes," "envelopes," and "admissibility." CARL modifies these specific search mechanics to work with vector costs and warm starts.
  - **Quick check question**: Why must a heuristic be admissible (lower bound) to guarantee an optimal solution in heuristic search?

## Architecture Onboarding

- **Component map**: Outer Loop (find-λ*) -> Inner Loop (solve-S(λ)) -> State (vector value function V) -> Policy Extractor (SOL 1 Solver)
- **Critical path**:
  1. Initialise V and λ=0
  2. **Repeat (Outer)**: Call **Inner Loop** (CG-iLAO* with vector backups) to solve S(λ)
  3. **Update**: Calculate subgradient based on constraint violations from V; update λ
  4. **Finalise**: Once λ converges, run "Strong Consistency" check to find all tied actions
  5. **Solve**: Run LP/SOL 1 to find mixing weights for the stochastic policy

- **Design tradeoffs**:
  - **Coordinate Search vs. Subgradient**: Coordinate search is faster (exploits piecewise linear structure) but incomplete; requires fallback to Subgradient if it stalls
  - **Vector vs. Scalar V**: Vector V allows efficient warm starts and multi-cost evaluation but complicates Bellman backup logic (requires dot products and tie-breaking)

- **Failure signatures**:
  - **Infinite Loop in Outer Loop**: Coordinate search gets stuck at a non-optimal kink; ensure fallback to subgradient is triggered
  - **Infeasible Final Policy**: The "Strong ε-consistency" threshold was too tight/loose, missing necessary actions for the stochastic mix
  - **Slow Convergence**: Warm start failing (values becoming inadmissible), forcing full re-search every iteration

- **First 3 experiments**:
  1. **Baseline Verification**: Run CARL on a deterministic CSSP where the optimal policy is deterministic; verify λ convergence matches manual calculation
  2. **Ablation on Warm Start**: Compare runtime of CARL with warm-start enabled vs. disabled on the "Search and Rescue" domain to quantify speedup
  3. **Stochastic Policy Validation**: Construct a problem where the only feasible solution requires a 50/50 mix of two policies; verify `extract-opt-policy` finds non-zero weights for both

## Open Questions the Paper Calls Out

### Open Question 1
Can a more robust optimization procedure be developed to find the optimal scalarisation λ* that guarantees optimality and scales efficiently with many secondary-cost constraints? The authors note that coordinate search "can not guarantee an optimal solution and it may not scale well with many secondary-cost constraints." This remains unresolved because coordinate search is incomplete for non-smooth problems, requiring slow fallback to subgradient methods.

### Open Question 2
What specific structural features of a CSSP instance determine its amenability to CARL's search procedure? While experiments suggest sparse optimal scalarisation (λ*) correlates with efficiency, this trend is not guaranteed and depends on complex search space structures. A theoretical characterization or empirical profile linking problem features to the number of S(λ) subproblems would resolve this.

### Open Question 3
Can an admissible heuristic be constructed for the scalarised subproblems S(λ) that accounts for secondary-cost constraints? CARL struggles on PARC instances with tight constraints because its heuristic fails to take secondary-cost constraints into account. An admissible heuristic that incorporates constraint information while maintaining admissibility would significantly improve performance on tightly constrained problems.

## Limitations

- The coordinate search optimization procedure cannot guarantee an optimal solution and may not scale well with many secondary-cost constraints
- The paper lacks specific implementation details for handling vector value functions and the "strong ε-consistency" check, which could impact the correctness of the final stochastic policy extraction
- No direct corpus validation exists for the scalarisation mechanism in CSSPs, though strong duality provides theoretical grounding

## Confidence

- **High Confidence**: The overall algorithm architecture and its relationship to Lagrangian duality is well-specified and theoretically grounded
- **Medium Confidence**: The experimental results (50% more coverage, 10x speedup) are reported but require verification against provided benchmarks to confirm reproducibility
- **Low Confidence**: The specific implementation details for handling vector value functions and "strong ε-consistency" check are not fully specified, which could impact the correctness of the final stochastic policy extraction

## Next Checks

1. **Replicate the Exploding Blocks World experiment**: Run CARL on instance id=6 (N=8, c=0.3) and verify it achieves 30/30 coverage with competitive runtime, while baselines fail

2. **Ablation study on warm-start**: Implement CARL with and without the warm-start feature on the Search and Rescue domain to quantify the claimed 10x speedup

3. **Stochastic policy verification**: Construct a synthetic CSSP instance where the optimal solution is a 50/50 mix of two deterministic policies and verify CARL's `extract-opt-policy` correctly identifies both with non-zero weights