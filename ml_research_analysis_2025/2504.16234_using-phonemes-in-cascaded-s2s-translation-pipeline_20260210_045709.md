---
ver: rpa2
title: Using Phonemes in cascaded S2S translation pipeline
arxiv_id: '2504.16234'
source_url: https://arxiv.org/abs/2504.16234
tags:
- translation
- phoneme
- phonemic
- text
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study investigates using phonemic representations instead
  of text in a multilingual speech-to-speech translation pipeline, aiming to address
  challenges with under-resourced languages that lack standardized written forms.
  Two models were trained from scratch using the WMT17 dataset: one using standard
  text and the other using phonemic representations.'
---

# Using Phonemes in cascaded S2S translation pipeline

## Quick Facts
- arXiv ID: 2504.16234
- Source URL: https://arxiv.org/abs/2504.16234
- Authors: Rene Pilz; Johannes Schneider
- Reference count: 3
- Primary result: Phonemic representations achieve BLEU scores comparable to text-based representations (38 vs 39) on English-German translation

## Executive Summary
This study investigates using phonemic representations instead of text in a multilingual speech-to-speech translation pipeline, particularly for under-resourced languages lacking standardized written forms. The authors trained two models from scratch using the WMT17 dataset: one using standard text and another using phonemic representations converted via espeak-ng. Both models were evaluated using BLEU scores after manual conversion of phonemic outputs back to standard German. The phoneme-based model achieved a BLEU score of 38, comparable to the reference model's score of 39, demonstrating that phonemic representations can maintain translation quality while offering advantages for low-resource languages and potentially reducing computational complexity in TTS-integrated systems.

## Method Summary
The study used the Eole seq2seq model (an OpenNMT derivative) trained on the WMT17 English-German dataset. Both source (English) and target (German) text were converted to International Phonetic Alphabet (IPA) phonemes using espeak-ng. Two models were trained: a reference model on standard text and a phoneme model on phoneme-converted data, both using the default WMT17 recipe configuration. Training was performed from scratch on an Nvidia 3090 GPU for approximately 24 hours. Evaluation used newstest2016, with the phoneme model's outputs manually converted back to standard German text before computing BLEU scores, while the reference model was evaluated directly.

## Key Results
- Phoneme-based model achieved BLEU score of 38 on English-German translation
- Reference text-based model achieved BLEU score of 39
- Both models showed similar error patterns, including issues with ambiguous verbs and name translations
- Phonemic approach offers potential benefits for under-resourced languages and TTS-integrated systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Phonemic representations can achieve comparable translation quality to text-based representations in seq2seq models
- Mechanism: The espeak-ng framework converts text to IPA phonemes, and the seq2seq model learns to map source phonemes to target phonemes directly, bypassing orthographic representations
- Core assumption: The phonemic representation preserves sufficient semantic and syntactic information for the translation task
- Evidence anchors:
  - [abstract]: "phonemic approach provides comparable quality"
  - [section 5]: BLEU scores of 39 (reference) vs 38 (phoneme model) on English-German translation
- Break condition: If phonemic representations fail to capture word boundaries or morphological information critical for syntax

### Mechanism 2
- Claim: Phoneme-based pipelines reduce computational steps in TTS-integrated systems
- Mechanism: Modern TTS models internally convert text to phonemes before speech synthesis. Using phonemes natively eliminates this conversion step
- Core assumption: The downstream TTS system can accept phoneme input directly without re-conversion
- Evidence anchors:
  - [section 1]: "recent progress in Text-to-Speech (TTS) models has shown a preference for phoneme-based embeddings"
  - [section 6]: "working directly with phonemes eliminates the necessity of translating standard text into phonemic representations"
- Break condition: If phoneme format incompatibility requires intermediate conversion anyway

### Mechanism 3
- Claim: Phonemic representations may benefit under-resourced languages lacking standardized orthography
- Mechanism: Generating phonemic transcriptions from audio requires less linguistic infrastructure than creating standardized writing systems and text corpora
- Core assumption: Phonemization tools exist for the target language
- Evidence anchors:
  - [abstract]: "better suitability for low-resource languages"
  - [section 1]: Cites Jiang et al. (2011) and Do et al. (2022) on phonetic representations for under-resourced source languages
- Break condition: If the language has highly variable pronunciation or lacks phonemization tooling

## Foundational Learning

- Concept: **International Phonetic Alphabet (IPA) and Phonemization**
  - Why needed here: Understanding how espeak-ng converts text to phoneme strings is essential for data preprocessing and debugging
  - Quick check question: Can you explain why "Registration" becomes "ɹˌɛdʒɪstɹˈeɪʃən" and what each symbol represents?

- Concept: **Sequence-to-Sequence (Seq2Seq) Translation Architecture**
  - Why needed here: The Eole model uses encoder-decoder structure; understanding attention and tokenization is critical for modifications
  - Quick check question: How does a seq2seq model handle variable-length input and output sequences?

- Concept: **BLEU Score Evaluation**
  - Why needed here: The study relies on BLEU for quality comparison; understanding its limitations informs result interpretation
  - Quick check question: Why might a BLEU score of 30+ be considered "understandable" but not semantically perfect?

## Architecture Onboarding

- Component map: Text -> espeak-ng (IPA phonemes) -> Eole Seq2Seq model -> Phoneme output -> Manual conversion to text -> BLEU evaluation

- Critical path:
  1. Phonemize both source (English) and target (German) sides of parallel corpus
  2. Train Eole model using the WMT17 recipe on phoneme-tokenized data
  3. Generate translations, manually back-convert phonemes to text, compute BLEU

- Design tradeoffs:
  - Vocabulary size: Phoneme vocabularies are smaller but require Unicode support
  - Evaluation complexity: BLEU requires manual conversion back to text (study used only 100 sentences)
  - Semantic loss: Both models struggled with ambiguous verbs and name translations—limitation is in base model, not representation

- Failure signatures:
  - Names not localized (e.g., "Miller" stays "Miller" instead of "Müller")
  - Ambiguous verbs default to common meaning ("receives" → "erhält" rather than "meets")
  - Short sentences with limited context produce more errors
  - Tense shifting: phoneme model showed preference for present tense over conditional

- First 3 experiments:
  1. Reproduce baseline: Train reference and phoneme models on WMT17 English-German, verify BLEU 39 vs 38
  2. Language pair extension: Test on a low-resource language pair (e.g., using IPA-CHILDES resources) to validate under-resourced language claims
  3. TTS integration: Connect phoneme output directly to a phoneme-based TTS (VITS/FastSpeech 2) and measure end-to-end latency reduction

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions.

## Limitations
- Results validated only on single high-resource language pair (English-German) rather than truly under-resourced languages
- Manual phoneme-to-text conversion for evaluation creates scalability bottleneck and potential human error
- Computational complexity reduction claims lack direct benchmarking data
- No empirical validation of benefits for languages without standardized written forms

## Confidence
- High confidence: Phonemic representations can achieve BLEU scores comparable to text-based representations on English-German WMT17 dataset
- Medium confidence: Phonemic representations reduce computational steps in TTS-integrated pipelines (theoretical but unverified with benchmarks)
- Medium confidence: Phonemic representations benefit under-resourced languages lacking standardized orthography (plausible but untested)

## Next Checks
1. **Empirical low-resource validation**: Test the phonemic approach on a truly under-resourced language pair using IPA-CHILDES resources to verify claims about benefits for languages without standardized written forms
2. **End-to-end latency measurement**: Connect phoneme output directly to a phoneme-based TTS system (VITS/FastSpeech 2) and measure actual latency reduction compared to text-based pipeline
3. **Cross-linguistic generalization**: Evaluate the approach across multiple language pairs with varying phonological complexity to assess whether the BLEU parity holds beyond English-German