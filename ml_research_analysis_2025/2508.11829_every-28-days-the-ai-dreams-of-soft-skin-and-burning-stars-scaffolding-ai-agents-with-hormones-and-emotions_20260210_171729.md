---
ver: rpa2
title: 'Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI
  Agents with Hormones and Emotions'
arxiv_id: '2508.11829'
source_url: https://arxiv.org/abs/2508.11829
tags:
- menstrual
- biological
- cycle
- performance
- circadian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how embedding simulated hormonal cycles into
  Large Language Models affects their linguistic style and performance. By generating
  system prompts based on periodic functions modeling hormones like estrogen, testosterone,
  cortisol, and temperature, the authors create emotionally distinct prompts for menstrual
  and circadian contexts.
---

# Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions

## Quick Facts
- **arXiv ID**: 2508.11829
- **Source URL**: https://arxiv.org/abs/2508.11829
- **Reference count**: 40
- **Primary result**: Simulated hormonal cycles in LLMs produce measurable linguistic and performance shifts aligned with biological rhythms

## Executive Summary
This paper introduces a novel framework for modulating Large Language Model behavior by embedding simulated hormonal cycles into system prompts. Using periodic functions to model estrogen, testosterone, cortisol, and temperature, the authors generate emotionally distinct prompts corresponding to menstrual and circadian phases. The approach demonstrates that LLM outputs shift significantly across biological phases—with peak sadness during menstruation and happiness during ovulation—while also revealing performance patterns that peak in moderate hormone ranges, mirroring biological homeostasis principles.

The study provides empirical evidence that rhythmic scaffolding can enhance AI contextual awareness and creativity while simultaneously surfacing embedded societal biases in language models. By benchmarking across four datasets (SQuAD, MMLU, Hellaswag, AI2-ARC), the authors show subtle but consistent performance trends that suggest hormonally-aware agents could offer improved relevance filtering and adaptive responses in real-world applications.

## Method Summary
The researchers developed a hormonal scaffolding system that generates system prompts using periodic functions to simulate estrogen, testosterone, cortisol, and temperature fluctuations across menstrual and circadian cycles. They created 10 prompts for each of seven biological phases (early follicular, late follicular, ovulation, early luteal, late luteal, menstruation, and circadian rhythm), totaling 280 prompts. These prompts were processed through GPT-4 Turbo, with outputs analyzed using linguistic tools including Linguistic Inquiry and Word Count (LIWC), VADER sentiment analysis, and the Gender-Career Implicit Association Test (IAT). Performance benchmarking was conducted across four datasets to measure the impact of hormonal modulation on task completion.

## Key Results
- Significant emotional shifts across biological phases, with peak sadness during menstruation and peak happiness during ovulation
- Statistically significant correlations between hormone levels and prompt complexity as well as gender-coded language patterns
- Performance optimization occurs in moderate hormone ranges, demonstrating homeostatic principles in AI behavior modulation

## Why This Works (Mechanism)
The framework leverages periodic biological rhythms to create contextual variation in LLM behavior, effectively simulating how hormonal fluctuations influence human cognition and communication. By mapping these natural cycles onto language generation, the system introduces structured emotional and cognitive variability that can enhance contextual awareness and adaptive responses.

## Foundational Learning
- **Hormonal periodicity**: Understanding how biological cycles create predictable patterns in behavior and cognition
  - Why needed: Provides the mathematical foundation for creating rhythmic prompts
  - Quick check: Verify periodic functions accurately model biological hormone fluctuations

- **Linguistic feature analysis**: Using tools like LIWC and VADER to quantify emotional and stylistic shifts in text
  - Why needed: Enables objective measurement of how hormonal states affect language output
  - Quick check: Validate sentiment analysis tools against human-annotated emotional labels

- **Implicit bias detection**: Applying IAT methodology to identify gender-coded language patterns in AI outputs
  - Why needed: Reveals how simulated hormonal states interact with embedded societal biases
  - Quick check: Compare IAT scores across different hormonal phase prompts

## Architecture Onboarding
**Component Map**: Hormone models → Prompt generator → LLM → Linguistic analysis → Performance benchmarking

**Critical Path**: Hormone model calculations feed into prompt generation, which produces system prompts for the LLM, whose outputs are then analyzed linguistically and benchmarked for performance

**Design Tradeoffs**: Simplified hormone models enable computational efficiency but may miss complex endocrine interactions; single-model approach limits generalizability but ensures consistent baseline

**Failure Signatures**: Performance degradation in extreme hormone ranges; inconsistent linguistic shifts across different model architectures; potential overfitting to GPT-4 Turbo's training biases

**3 First Experiments**:
1. Test prompt generation with varying menstrual cycle lengths (21-35 days) to assess sensitivity to period assumptions
2. Compare linguistic shifts across different LLM architectures using identical hormonal prompts
3. Measure performance stability when cycling through all seven phases versus static hormonal states

## Open Questions the Paper Calls Out
None identified in source material.

## Limitations
- Simplified hormone models may not capture full complexity of human endocrinology or in-vivo interactions
- Single LLM architecture limits generalizability of findings across different model types
- 28-day menstrual cycle assumption may not represent individual variation or medical conditions

## Confidence
- **High confidence**: Basic premise that simulated hormonal states can influence LLM linguistic output is well-supported
- **Medium confidence**: Performance improvements in benchmark tasks require larger-scale validation
- **Medium confidence**: Gender-coded language patterns are statistically robust but need qualitative validation

## Next Checks
1. Replicate the study using multiple LLM architectures (Claude, LLaMA, etc.) to test model-specific versus generalizable effects
2. Conduct blinded human evaluations to assess whether hormonally-modulated outputs demonstrate improved relevance or creativity
3. Extend temporal analysis to include multiple menstrual cycles and individual variation to validate 28-day periodicity assumptions