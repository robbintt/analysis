---
ver: rpa2
title: What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization
arxiv_id: '2502.02903'
source_url: https://arxiv.org/abs/2502.02903
tags:
- names
- text
- similarity
- person
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates name bias in text-embedding models, where
  embeddings are disproportionately influenced by names in text rather than semantic
  content. This can lead to erroneous similarity assessments in downstream tasks.
---

# What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization

## Quick Facts
- arXiv ID: 2502.02903
- Source URL: https://arxiv.org/abs/2502.02903
- Reference count: 40
- Authors: Sahil Manchanda; Pannaga Shivaswamy
- One-line primary result: Simple inference-time anonymization of names in text significantly reduces name bias in embeddings, improving semantic similarity task performance.

## Executive Summary
Text-embedding models can exhibit significant bias toward names in text, causing embeddings to cluster based on shared names rather than semantic content. This name bias leads to erroneous similarity assessments in downstream tasks. The authors propose a simple inference-time anonymization technique that removes named entities from text while preserving core meaning. Extensive experiments across 14 text-embedding models demonstrate that anonymized text embeddings achieve significantly better performance on semantic similarity tasks, with AUC-ROC scores improving from near-random (0.07-0.71) to excellent (0.92-1.00). The method is training-free, easy to implement, and effective across diverse embedding architectures.

## Method Summary
The method involves using an LLM (e.g., Gemini, Claude 3.5 Sonnet) or a Named Entity Recognition (NER) tool to identify and completely remove specified named entities (persons, locations, organizations) from text before generating embeddings. The anonymization pipeline processes input text through entity identification, entity removal (deletion preferred over replacement), and then generates embeddings using any off-the-shelf text-embedding model. The approach is evaluated through three tasks: a bias benchmark measuring cosine similarity across text perturbations, a binary semantic similarity task (STS) using AUC-ROC, and a graded similarity task measuring correlation with human judgments.

## Key Results
- Anonymization significantly reduces name bias, with average cosine similarity dropping from 0.77 to 0.68-0.89 across models when only names are perturbed
- AUC-ROC scores improve from 0.07-0.71 (near-random or worse) to 0.92-1.00 on semantic similarity tasks after anonymization
- Spearman and Pearson correlations with human judgments improve from 0.03-0.19 to 0.47-0.67 on graded similarity tasks
- The approach works across 14 different text-embedding models without requiring any model retraining or fine-tuning

## Why This Works (Mechanism)

### Mechanism 1: Name-Induced Embedding Drift
Text-embedding models trained on internet-scale data encode social and cultural associations with names, causing these named entities to disproportionately influence embedding geometry relative to semantic content. Names function as high-magnitude feature vectors that pull embedding similarity toward name-based associations rather than thematic content. When two texts share names, their embeddings cluster together regardless of semantic divergence; when names differ, embeddings separate despite semantic similarity. This operates through learned co-occurrence patterns where names carry implicit information that the model over-weights during representation learning.

### Mechanism 2: Semantic Content Preservation Under Entity Removal
Removing named entities via anonymization preserves sufficient semantic structure for embedding models to capture thematic similarity while eliminating the name-bias signal. Anonymization removes the high-variance name feature while leaving action verbs, relationships, and thematic content intact. The embedding model, forced to operate on the remaining tokens, attends to semantic structure that was previously overshadowed. This is a signal-to-noise improvement: names were noise for thematic similarity tasks.

### Mechanism 3: Inference-Time Intervention Independence
The anonymization-based debiasing operates orthogonally to model architecture because it modifies the input distribution rather than model weights. By intervening at inference time on raw text (pre-embedding stage), the approach bypasses the need to modify learned representations. All tested embedding models process the same anonymized input, shifting all models toward name-invariant behavior simultaneously. This is an input-space rather than representation-space intervention.

## Foundational Learning

- **Concept: Cosine Similarity in Embedding Space**
  - **Why needed here:** The paper's entire evaluation framework rests on measuring whether embedding vectors for semantically similar texts are closer (higher cosine similarity) than embedding vectors for semantically dissimilar texts.
  - **Quick check question:** Given two embedding vectors with cosine similarity 0.75, what does this indicate about their semantic relationship? If you swap only the names in the source texts and similarity drops to 0.65, what inference can you draw?

- **Concept: Named Entity Recognition (NER) and LLM-based Extraction**
  - **Why needed here:** The anonymization approach requires reliable identification of person names, locations, and organizations.
  - **Quick check question:** If your NER system misses 15% of person names, what downstream effect would you expect on the anonymization approach's effectiveness as measured by AUC-ROC?

- **Concept: AUC-ROC for Binary Classification Tasks**
  - **Why needed here:** Task 1 evaluation uses AUC-ROC to measure whether the embedding model can distinguish positive pairs (semantically similar, different names) from negative pairs (semantically dissimilar, same names).
  - **Quick check question:** If a model achieves AUC-ROC of 0.10 on Task 1 (original text), what does this imply about how name bias is affecting its ranking behavior? What AUC would you expect after anonymization if the mechanism works?

## Architecture Onboarding

- **Component map:** Input text -> Entity identifier (LLM-based or NER tool) -> Entity removal module (deletion or placeholder replacement) -> Anonymized text -> Text-embedding model -> Embedding vectors -> Similarity computation

- **Critical path:** The entity identification step is the bottleneck. If names are missed (false negatives) or non-names are removed (false positives), anonymization quality degrades. The paper notes LLMs were more accurate than NER tools in initial experiments, but this increases latency and cost at inference time.

- **Design tradeoffs:**
  - **Deletion vs. replacement:** Deletion marginally outperforms replacement because replacement tokens introduce new embedding artifacts. However, deletion can create grammatical awkwardness.
  - **LLM vs. NER for entity extraction:** LLMs are more accurate but add 100-500ms latency per text and incur API costs. NER tools are faster and free but may miss culturally diverse names.
  - **Entity scope:** Removing only person names vs. also removing locations/organizations trades semantic preservation against bias mitigation.

- **Failure signatures:**
  - **Low improvement after anonymization:** Check entity extraction qualityâ€”are names being correctly identified and removed?
  - **AUC-ROC still below 0.5:** Possible that anonymization is incomplete or downstream task design is flawed.
  - **Performance degradation on name-relevant tasks:** If your use case requires entity-specific retrieval, anonymization will break this.

- **First 3 experiments:**
  1. **Reproduce Table 1 on your domain-specific texts:** Create 5-10 triplets (query, positive with different names, negative with same names) from your corpus. Compute cosine similarities with your embedding model before and after anonymization.
  2. **Benchmark entity extraction quality:** Run 100 diverse texts from your domain through your chosen anonymization pipeline. Manually annotate precision and recall for name detection.
  3. **End-to-end AUC test on Task 1-style evaluation:** Construct a binary semantic similarity dataset. Measure AUC-ROC with and without anonymization.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can text-embedding models be trained to prioritize semantics over names intrinsically?
- **Basis:** The conclusion explicitly asks, "how to train text-embedding models such that the embeddings capture the semantics more than the names in the text?"
- **Why unresolved:** The current study proposes an inference-time, training-free solution rather than addressing the model's internal learning mechanisms.
- **What evidence would resolve it:** A training methodology (e.g., data augmentation or contrastive loss modification) that achieves high semantic similarity scores on the proposed benchmarks without external anonymization.

### Open Question 2
- **Question:** Does name bias persist in multilingual text-embedding models or non-English contexts?
- **Basis:** The Limitations section states the work "does not cover other languages" or "name bias issues arising in multi language texts."
- **Why unresolved:** The benchmarking and mitigation experiments were restricted to English datasets.
- **What evidence would resolve it:** Application of the perturbation methodology to non-English corpora, measuring if cosine similarity drops similarly when names are swapped.

### Open Question 3
- **Question:** How does the choice of anonymization tool (LLM vs. NER) impact the robustness of the bias mitigation?
- **Basis:** The methodology notes LLMs were used over NER tools because they were "more accurate" in initial tests, implying NER is a viable but unquantified alternative.
- **Why unresolved:** The paper does not quantify the performance gap or failure cases between using an LLM versus a standard NER system for the anonymization step.
- **What evidence would resolve it:** A comparison of AUC-ROC scores on the Semantic Similarity Task using both LLM-based and rule-based NER anonymization.

## Limitations
- The approach may not generalize to tasks where named entities are semantically essential (e.g., entity retrieval)
- The evaluation relies on synthetic perturbation experiments rather than real-world downstream failures caused by name bias
- The LLM-based anonymization approach introduces inference-time latency and cost, and its performance across diverse cultural name variations remains unexplored

## Confidence
- **High Confidence:** The core finding that anonymization improves semantic similarity AUC-ROC scores (from ~0.2 to >0.9) across multiple models. This is directly measurable and well-supported by the experimental results.
- **Medium Confidence:** The mechanism explanation that names function as high-magnitude features disproportionately influencing embeddings. While the experiments support this, the exact training dynamics and feature attribution remain implicit.
- **Low Confidence:** The claim that anonymization preserves "core meaning" without degradation. The paper provides minimal evidence that semantic preservation holds across diverse text types and embedding models beyond the specific tasks tested.

## Next Checks
1. **Cross-Domain Generalization Test:** Apply the anonymization pipeline to 100 texts from a different domain (e.g., news articles or medical literature) and measure AUC-ROC on Task 1-style evaluations to verify the approach transfers beyond movie/book summaries.

2. **Entity-Relevant Task Failure Mode:** Design a controlled experiment where Task 1 queries require entity-based matching (e.g., "Find documents about Barack Obama" vs. "Find documents about Joe Biden"). Measure whether anonymization degrades performance on this entity-centric task while improving semantic similarity tasks.

3. **Cultural Name Coverage Analysis:** Create a test set with 500 names from diverse cultural backgrounds (including uncommon and compound names) and measure anonymization precision/recall. This would validate whether the approach handles global name diversity or exhibits bias in its own entity extraction step.