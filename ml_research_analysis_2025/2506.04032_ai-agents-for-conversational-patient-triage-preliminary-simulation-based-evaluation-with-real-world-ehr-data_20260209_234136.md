---
ver: rpa2
title: 'AI Agents for Conversational Patient Triage: Preliminary Simulation-Based
  Evaluation with Real-World EHR Data'
arxiv_id: '2506.04032'
source_url: https://arxiv.org/abs/2506.04032
tags:
- patient
- simulator
- clinical
- data
- triage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a Patient Simulator that generates synthetic
  test subjects for evaluating AI-driven conversational patient triage systems, using
  real-world EHR data to create realistic patient vignettes. These vignettes are transformed
  into dynamic, multi-turn conversations with an AI triage agent, which follows a
  multi-agent architecture to collect symptoms, retrieve relevant EHR data, reason
  through differential diagnoses, and generate care recommendations.
---

# AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data

## Quick Facts
- arXiv ID: 2506.04032
- Source URL: https://arxiv.org/abs/2506.04032
- Reference count: 27
- Primary result: Patient Simulator achieves 97.7% consistency with vignettes; AI triage proposes correct diagnosis in top 3 for 95.4% of cases

## Executive Summary
This paper introduces a Patient Simulator that generates synthetic test subjects for evaluating AI-driven conversational patient triage systems using real-world EHR data. The simulator transforms clinical encounters into structured vignettes, then creates dynamic, multi-turn conversations with an AI triage agent following a modular multi-agent architecture. Expert clinicians evaluated 519 simulated encounters, finding the Patient Simulator consistent with vignettes in 97.7% of cases and the AI triage system's diagnostic accuracy exceeds 95% for top-3 differential diagnoses. This framework offers a scalable, safe, and interpretable method to train and test AI triage agents using realistic clinical data.

## Method Summary
The method transforms real EHR encounters into structured vignettes using GPT-4o-mini for classification, then implements a Patient Simulator to role-play patients based on these vignettes with layperson language constraints. An 8-agent AI Triage system collects symptoms through RAG-based EHR retrieval, generates case summaries, performs differential diagnosis with step-by-step reasoning, and produces care recommendations. A guideline verifier safety layer cross-references urgency assessments against clinical guidelines. The system was evaluated through 519 simulated encounters with expert clinician scoring across 14 dimensions measuring consistency, diagnostic accuracy, and clinical appropriateness.

## Key Results
- Patient Simulator maintains consistency with source vignettes in 97.7% of cases
- Case summaries achieve 99% relevance to conversation content
- AI triage agent's questions are precise and non-redundant in 81.7% of cases
- Most likely diagnosis appears in top three differential diagnoses for 95.4% of cases

## Why This Works (Mechanism)

### Mechanism 1: EHR-Anchored Patient Simulation
Transforming real EHR encounters into structured vignettes enables privacy-preserving, scalable patient simulation that maintains clinical realism. Clinical encounters → GPT-4o-mini classification → structured vignettes containing chief complaint, HPI, medical history → Patient Simulator prompt constrains responses to vignette content + common-sense inferences + layperson language constraints → multi-turn conversation with triage agent. Core assumption: Vignette-to-simulation fidelity depends on LLM's ability to maintain internal consistency without "leaking" information a real patient wouldn't volunteer unprompted.

### Mechanism 2: Modular Multi-Agent Triage Pipeline
Decomposing triage into specialized sequential agents (SymptomCollector → HealthDataPlanner → HealthDataRetriever → Summary → Differential Diagnosis → Next Steps) improves traceability and error localization compared to monolithic LLM deployments. Each agent receives specific inputs and produces structured outputs; controller orchestrates handoffs. SymptomCollector uses RAG to digest EHR context. Differential Diagnosis agent performs internal step-by-step reasoning explaining how each question narrows diagnoses. This modularity allows clinician evaluators to assess each stage independently.

### Mechanism 3: Guideline Verifier as Safety Override
Post-hoc RAG-based verification against clinical guidelines provides an interpretable safety layer that can override LLM-derived urgency assessments. AI Triage produces top-5 differential diagnoses → GPT-4o retrieves relevant guidelines using semantic matching → o3-mini with RAG cross-references guideline-based urgency against original assessment → defaults to most severe recommendation if conflict exists. Core assumption: Clinical guidelines are comprehensive enough to cover the differential diagnoses the system generates.

## Foundational Learning

- **Multi-Agent LLM Orchestration**: Why needed here: The system uses 8 agents with defined inputs/outputs; understanding controller patterns, handoff protocols, and error propagation is essential. Quick check: Can you trace what happens if SymptomCollector receives incomplete EHR data—does HealthDataPlanner compensate or fail?

- **Retrieval Augmented Generation (RAG) for Clinical Data**: Why needed here: SymptomCollector uses RAG for EHR digestion; Guideline Verifier uses RAG for clinical guideline retrieval. Different retrieval strategies apply to each. Quick check: What's the difference between keyword-based retrieval and the "conceptually similar conditions" retrieval used by the Guideline Verifier?

- **Clinical Workflow Modeling (History-Taking, Differential Diagnosis, Triage)**: Why needed here: The agent architecture mirrors physician reasoning. Without understanding SOCRATES-based symptom collection or differential diagnosis narrowing, you cannot evaluate whether agents follow sound clinical logic. Quick check: Why does the Differential Diagnosis agent need "internal step-by-step reasoning" rather than direct output?

## Architecture Onboarding

- **Component map**: Patient Simulator (LLM + vignette prompt) ←→ SymptomCollector (RAG for EHR context) → HealthDataPlanner → HealthDataRetriever → EHR DB → Summary Agent → Differential Diagnosis Agent → Next Steps Agent → Guideline Verifier (RAG) → Triage Output (urgency, care recommendations)

- **Critical path**: SymptomCollector → Summary → Differential Diagnosis → Next Steps. If Summary receives incomplete conversation history, downstream DDX and triage decisions will be unreliable. This is where 99.2% relevance matters most.

- **Design tradeoffs**: Multi-agent modularity vs. latency (each handoff adds inference time but enables per-agent debugging); Guideline Verifier coverage vs. override frequency (GV only runs if guidelines exist; rare conditions bypass this safety layer); Vignette-based simulation vs. open-ended generation (vignettes constrain realism but may not capture edge-case patient presentations).

- **Failure signatures**: Low Q4 scores (patient inconsistency): Simulator prompt not constraining responses to vignette; Low Q6 scores (incomplete summary): Context handoff failure between SymptomCollector and Summary; Disagreement on urgency between clinicians and system (Q10-Q11): DDX agent missing key differentiating symptoms or Guideline Verifier retrieving irrelevant guidelines.

- **First 3 experiments**: 1) Ablate Guideline Verifier: Run 100 encounters with GV disabled; compare urgency agreement rates to full system to quantify GV's contribution to safety. 2) Vignette perturbation test: Introduce controlled inconsistencies into 20 vignettes; measure whether clinicians detect simulator inconsistencies (validates Q4 as reliable metric). 3) Single-agent baseline: Replace multi-agent pipeline with a single LLM given same inputs; compare DDX accuracy and interpretability scores to isolate modularity benefit.

## Open Questions the Paper Calls Out

### Open Question 1
How can the Patient Simulator and AI Triage architecture be extended to handle follow-up encounters where prior patient-provider relationships and established medical histories would enable more streamlined triage? Basis: Authors state "for returning patients, one might desire a more streamlined triaging process given the already established patient history, which is beyond the scope of our study." Unresolved because current framework exclusively uses Initial Encounter cases and the multi-agent workflow assumes minimal prior context.

### Open Question 2
What is the failure mode distribution and safety profile when patients provide vague, incomplete, or contradictory symptom descriptions during conversational triage? Basis: Authors acknowledge "the information exchange is entirely conversational, there may be gaps in content, particularly when patients provide vague or incomplete descriptions of their symptoms," and note this is only "partially offset" by EHR retrieval. Unresolved because evaluation questionnaire does not systematically probe how AI Triage handles ambiguity, evasiveness, or patient confusion.

### Open Question 3
How robust is the multi-agent architecture to error propagation when upstream agents (e.g., SymptomCollector or HealthDataPlanner) produce incomplete or incorrect outputs? Basis: Paper emphasizes modularity for "error localization," but evaluation only assesses final outputs. Unresolved because 14-question evaluation rubric focuses on end-state clinical appropriateness, not whether downstream agents can detect or compensate for earlier errors.

## Limitations
- Guideline verifier safety layer is limited by guideline availability—rare conditions may bypass this protection
- Exclusion of psychological symptoms represents a significant clinical gap
- Evaluation relies on expert clinician scoring that may introduce subjective bias

## Confidence

| Claim | Confidence |
|-------|------------|
| Patient Simulator consistency with vignettes (97.7%) | High |
| AI triage diagnostic accuracy (>95% for top-3) | Medium |
| Multi-agent architecture provides interpretability benefits | High |
| Guideline verifier improves safety | Medium |

## Next Checks
1. Replicate the 97.7% consistency rate by running a small validation set of 50 vignettes through the Patient Simulator and having clinicians rate consistency
2. Test guideline verifier coverage by identifying conditions in the EHR dataset lacking clinical guidelines and measuring what percentage of encounters bypass the safety layer
3. Evaluate inter-rater reliability by having multiple clinicians independently score the same 20 simulated encounters and calculating agreement rates on key dimensions like diagnostic accuracy and clinical appropriateness