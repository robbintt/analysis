---
ver: rpa2
title: 'TimeFound: A Foundation Model for Time Series Forecasting'
arxiv_id: '2503.04118'
source_url: https://arxiv.org/abs/2503.04118
tags:
- forecasting
- series
- time
- patch
- foundation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TimeFound, a transformer-based foundation
  model for zero-shot time series forecasting. The key innovation is a multi-resolution
  patching strategy that tokenizes time series data at multiple scales, enabling the
  model to handle diverse temporal patterns from various domains.
---

# TimeFound: A Foundation Model for Time Series Forecasting

## Quick Facts
- **arXiv ID:** 2503.04118
- **Source URL:** https://arxiv.org/abs/2503.04118
- **Reference count:** 12
- **Primary result:** Multi-resolution transformer achieves superior zero-shot time series forecasting performance across 24 unseen datasets

## Executive Summary
This paper introduces TimeFound, a transformer-based foundation model for zero-shot time series forecasting that addresses the limitations of point-based autoregressive generation. The key innovation is a multi-resolution patching strategy that tokenizes time series data at multiple scales (patch sizes 16 and 32), enabling the model to capture diverse temporal patterns simultaneously. TimeFound employs an encoder-decoder architecture trained on a large corpus of real and synthetic time series data using next-patch prediction with MSE and quantile loss objectives. Extensive experiments demonstrate that TimeFound achieves superior or competitive zero-shot forecasting performance compared to state-of-the-art foundation models, with the best geometric mean MASE across all datasets, while excelling particularly in long-horizon forecasting tasks.

## Method Summary
TimeFound is a transformer-based foundation model for zero-shot time series forecasting that uses multi-resolution patching to handle diverse temporal patterns. The model processes input time series by dividing them into patches at multiple resolutions (16 and 32), projecting each resolution independently via MLPs, upsampling coarser resolutions to match the finest resolution length, and summing the embeddings element-wise. An encoder-decoder T5 architecture with relative position embeddings processes these fused embeddings, predicting future patches (size 32) rather than individual points. The model is pre-trained on a large corpus of real-world and synthetic time series data using next-patch prediction with MSE and quantile loss objectives. Training uses AdamW with batch size 1024 for 200K steps, and evaluation metrics include MASE and sMAPE computed as geometric means across 24 unseen datasets.

## Key Results
- Achieves superior zero-shot forecasting performance with best geometric mean MASE across 24 unseen datasets
- Outperforms state-of-the-art foundation models in long-horizon forecasting tasks
- Demonstrates effectiveness of patch-based modeling in reducing error accumulation compared to point-based generation
- Shows strong cross-domain generalization from pre-training on mixed real and synthetic data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-resolution patching allows a single model to capture temporal dependencies at different frequencies simultaneously.
- **Mechanism:** The input series is divided into patches using multiple sizes (e.g., $P_1=16, P_2=32$). Each resolution is projected independently via dedicated MLPs. Coarser resolutions (fewer patches) are upsampled via replication to match the sequence length of the finest resolution, and the resulting embeddings are summed element-wise to form a unified input representation.
- **Core assumption:** Summing upsampled coarse embeddings with fine-grained embeddings preserves high-frequency details while retaining macro-context without introducing excessive sequence length overhead.
- **Evidence anchors:**
  - [abstract] "employs a multi-resolution patching strategy to capture complex temporal patterns at multiple scales"
  - [section 4.1] "summing the corresponding patches across all groups... ensures that information from multiple resolutions is effectively aggregated"
  - [corpus] Weak direct evidence; neighbors like *Shapelets-Enriched Selective Forecasting* discuss multi-domain robustness but not specifically the multi-resolution fusion summation.
- **Break condition:** If the input context length is shorter than the largest patch size ($P_K$), the mechanism fails to generate a valid patch sequence for that resolution.

### Mechanism 2
- **Claim:** Patch-based auto-regressive forecasting reduces error accumulation compared to point-based generation.
- **Mechanism:** The model predicts the next block of points (a patch) in a single forward pass rather than predicting one point at a time. By outputting a patch (size $P_o=32$) per step, the number of auto-regressive steps required for a fixed horizon is reduced by a factor of $P_o$.
- **Core assumption:** The semantic meaning of a "patch" is learnable and generalizes better than point-wise noise, providing a stable context for subsequent generation steps.
- **Evidence anchors:**
  - [section 5.2.2] "point-based modeling... leads to significant error accumulation in long-horizon forecasting... patch-based modeling and prediction are crucial"
  - [section 4.5] "perform an auto-regressive forecasting in a patch-by-patch manner"
  - [corpus] *KAIROS* and *YingLong* papers support non-autoregressive or structured generation for efficiency, aligning with the inefficiency of point-wise AR models.
- **Break condition:** If the forecast horizon $H$ is not a multiple of the output patch size $P_o$, the model generates wasted predictions that must be discarded, potentially introducing boundary artifacts in rolling forecasts.

### Mechanism 3
- **Claim:** Training on a mixture of real and synthetic data (via TSMixup and Gaussian Processes) enforces invariance to domain-specific scale and distribution shifts.
- **Mechanism:** The model uses standard scaling (mean/std) for normalization but is exposed to synthetic variations created by interpolating between real time series. This forces the Transformer to learn structural patterns (trends, seasonality) rather than memorizing dataset-specific magnitudes.
- **Core assumption:** The diversity of synthetic augmentations covers the distribution of "unseen" datasets well enough to enable zero-shot transfer.
- **Evidence anchors:**
  - [abstract] "pre-train our model... on a large time-series corpus comprising both real-world and synthetic datasets"
  - [section 5.1] "applied two data augmentation strategies... TSMixup... Gaussian processes"
  - [corpus] *How Foundational are Foundation Models...* challenges this, suggesting inherent data diversity may limit generalization, acting as a counter-weight to this assumption.
- **Break condition:** If the target domain exhibits complex non-stationary behaviors (e.g., sudden regime shifts) not present in the Gaussian Process or Mixup priors, zero-shot performance may degrade.

## Foundational Learning

- **Concept: Encoder-Decoder Attention Masking**
  - **Why needed here:** TimeFound relies on a T5-style architecture where the Encoder sees the full history (bidirectional attention) while the Decoder must predict the future causally (masked attention).
  - **Quick check question:** Can you distinguish between the patch-level mask used for padding in the encoder versus the causal mask used in the decoder?

- **Concept: Residual MLP Projectors**
  - **Why needed here:** The input and output modules map raw time-series patches to the Transformer's latent space. The paper explicitly uses 2-layer MLPs with residual connections here to stabilize gradient flow across different patch resolutions.
  - **Quick check question:** Why is a residual connection necessary in the patch projector when the Transformer backbone already has residuals?

- **Concept: Quantile Loss for Probabilistic Forecasting**
  - **Why needed here:** The model optimizes MSE (point forecast) and Quantile Loss (probabilistic intervals) simultaneously. Understanding the pinball loss function is required to interpret the training dynamics.
  - **Quick check question:** If the model predicts quantiles [0.1, 0.5, 0.9], how does the loss penalize over-prediction versus under-prediction at the 0.9 quantile?

## Architecture Onboarding

- **Component map:** Normalization -> Multi-Resolution Patching (Sizes 16, 32) -> K Independent MLP Projectors -> Upsampling & Sum Fusion -> T5 Encoder/Decoder -> MLP Head -> Point Forecast + Quantile Forecasts

- **Critical path:** The **fusion step** (summing upsampled patch embeddings) is the unique architectural dependency. If the upsampling logic misaligns indices (e.g., off-by-one errors in `ceil(j * N_k / N_1)`), the multi-scale signal is corrupted before entering the Transformer.

- **Design tradeoffs:**
  - **Output Patch Size (32 vs 16):** The paper selects an output patch size of 32, double the smallest input patch. This speeds up long-horizon inference but reduces the granularity of intermediate "feedback" during autoregressive generation.
  - **Channel Independence:** The model processes multivariate data channel-by-channel (univariate modeling). This simplifies the architecture but may miss cross-dimensional correlations present in datasets like ETT.

- **Failure signatures:**
  - **Inference Drift:** If the input context is not normalized strictly using the statistics of the *input window only* (as per pre-training), the model outputs will be scaled incorrectly.
  - **Attention Leakage:** If the point-level mask is not correctly aggregated into a patch-level mask (Section 4.2), the attention mechanism may attend to padding tokens, degrading forecast accuracy.

- **First 3 experiments:**
  1. **Resolution Ablation:** Run zero-shot inference using only $P_1$ (single resolution) vs. the full multi-resolution setup to isolate the performance gain on datasets with mixed frequencies (e.g., M1/M3).
  2. **Long-Horizon Stability:** Compare rolling validation errors on ETTh1 for Horizon=96 vs. Horizon=720 to verify the claim that patch-based prediction resists error accumulation better than Chronos.
  3. **Synthetic Data Necessity:** Pre-train a smaller model using only real data (no TSMixup/GP) and evaluate on the "Covid Deaths" or "Hospital" datasets to test generalization to unseen domains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is simple summation the most effective method for fusing patch embeddings from different resolutions, or would attention-based or learnable weighted mechanisms improve performance?
- Basis in paper: [inferred] Section 4.1 (Eq. 3) specifies that the model fuses embeddings from multiple patch resolutions ($Z^k$) by simply summing the upsampled vectors ($z_j = \sum \tilde{z}^k_j$).
- Why unresolved: The authors provide no ablation study comparing this naive summation against other fusion techniques (e.g., concatenation, cross-attention, or gating), leaving the optimality of this specific aggregation method unverified.
- What evidence would resolve it: An ablation study comparing the performance of summation fusion against learned fusion strategies across the 24 unseen datasets.

### Open Question 2
- Question: How sensitive is the model's zero-shot performance to the specific selection of input patch sizes $\{16, 32\}$ and output patch size $32$?
- Basis in paper: [inferred] Table 1 fixes the patch sizes to $\{16, 32\}$ (input) and $32$ (output) for both Base and Large models.
- Why unresolved: The paper asserts that multi-resolution patching captures diverse temporal patterns, but it does not demonstrate if these specific hyperparameters are optimal for all frequencies (e.g., yearly vs. 5-minute intervals) or if other configurations yield better geometric mean MASE.
- What evidence would resolve it: A hyperparameter sensitivity analysis sweeping different patch size combinations (e.g., $\{8, 16\}$ or $\{32, 64\}$) on the benchmark datasets.

### Open Question 3
- Question: Does the channel-independent univariate approach limit the model's ability to capture cross-variate dependencies essential for multivariate forecasting tasks?
- Basis in paper: [explicit] Section 3 states: "In this work, we focus on univariate forecasting... For multivariate time series data, the univariate model can still be applied by performing channel-independent forecasting."
- Why unresolved: While channel independence simplifies scaling, it ignores correlations between variables in multivariate time series, which are often critical for state-of-the-art accuracy in domains like electricity or traffic.
- What evidence would resolve it: Comparative benchmarks against multivariate-native foundation models (e.g., Moirai) on datasets where cross-variate correlation is high, specifically measuring the performance gap.

## Limitations
- Channel-by-channel processing for multivariate series may miss cross-dimensional temporal dependencies
- Synthetic data augmentation assumes GP and TSMixup cover real-world distribution shifts, which may not hold for complex non-stationary behaviors
- Multi-resolution patching is sensitive to proper alignment during upsampling and fusion, with implementation errors potentially degrading performance

## Confidence
- **High confidence:** The core architecture design (multi-resolution patching, T5 backbone, patch-based forecasting) is well-specified and technically sound
- **Medium confidence:** The zero-shot performance claims are supported by extensive experiments, though the specific contribution of synthetic data augmentation versus real data pre-training is not isolated
- **Low confidence:** The long-term generalization to truly unseen domains with complex non-stationary behaviors remains untested beyond the current benchmark suite

## Next Checks
1. **Synthetic Data Necessity Test:** Pre-train a TimeFound variant using only real data (no TSMixup/GP augmentation) and evaluate zero-shot performance on the "Covid Deaths" and "Hospital" datasets to quantify the contribution of synthetic data to cross-domain generalization.

2. **Rolling Forecast Boundary Analysis:** Implement rolling forecasting on datasets with horizons not divisible by 32 (e.g., Horizon=96 with output patch size 32) and analyze prediction quality at boundary points versus interior points to identify potential artifacts from patch-based generation.

3. **Cross-Channel Dependency Validation:** Modify the model to process multivariate series using a shared attention mechanism across channels (rather than channel-by-channel processing) and compare performance on ETT datasets to assess the cost of the current architectural simplification.