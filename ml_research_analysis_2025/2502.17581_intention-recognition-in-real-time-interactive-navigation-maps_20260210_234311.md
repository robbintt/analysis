---
ver: rpa2
title: Intention Recognition in Real-Time Interactive Navigation Maps
arxiv_id: '2502.17581'
source_url: https://arxiv.org/abs/2502.17581
tags:
- recognition
- maps
- location
- interactive
- navigation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IntentRec4Maps, a system for real-time intention
  recognition in interactive navigation maps using the Google Maps Platform. The core
  approach adapts Mirroring, comparing ideal routes to observation routes using the
  Haversine formula for geographic distance computation.
---

# Intention Recognition in Real-Time Interactive Navigation Maps

## Quick Facts
- **arXiv ID**: 2502.17581
- **Source URL**: https://arxiv.org/abs/2502.17581
- **Reference count**: 21
- **One-line primary result**: IntentRec4Maps achieves perfect intention recognition (TPR 1.00, F1 1.00) using Google Maps API, significantly outperforming Mapbox and ChatGPT-4 baselines

## Executive Summary
This paper introduces IntentRec4Maps, a system for real-time intention recognition in interactive navigation maps using the Google Maps Platform. The core approach adapts Mirroring, comparing ideal routes to observation routes using the Haversine formula for geographic distance computation. The system encodes recognition problems in JSON format and employs probabilistic inference to rank possible destinations. Experiments using 100 real-world navigation problems show strong performance: the baseline using Google Maps achieved TPR of 1.00 and F1 of 1.00 for most observation counts, while Mapbox performed moderately well (TPR 0.78, F1 0.29 for 10 observations). The LLM-based approach (ChatGPT4) yielded the poorest results (TPR 0.35, F1 0.04 for 10 observations), demonstrating that general-purpose LLMs are less reliable than specialized routing systems for this task.

## Method Summary
IntentRec4Maps implements a real-time intention recognition system that predicts user destinations from partial GPS observation sequences. The method encodes navigation problems in JSON format with initial location, possible intentions, and observation sequences. For each candidate destination, the system generates an "ideal route" using a path-planning API and compares it to an "observation route" that passes through the user's actual GPS points. Route similarity is computed using the Haversine formula to measure geographic distance between corresponding points. A probabilistic inference framework ranks destinations by computing posterior probabilities, with performance evaluated using TPR, FPR, and F1-score metrics across varying observation counts.

## Key Results
- Google Maps baseline achieved perfect recognition (TPR 1.00, F1 1.00) for most observation counts
- Mapbox showed moderate performance (TPR 0.78, F1 0.29 for 10 observations)
- ChatGPT-4 LLM approach performed poorly (TPR 0.35, F1 0.04 for 10 observations)
- Recognition accuracy improved with more observations, reaching perfect scores with 5+ observations for Google Maps

## Why This Works (Mechanism)

### Mechanism 1: Mirroring via Route Comparison
- **Claim:** Comparing an observed route against an "ideal" optimal route allows for the probabilistic ranking of user intentions.
- **Mechanism:** The system generates a hypothetical "ideal route" from the start location to every candidate destination using a Path-Planner. It then generates an "observation route" that complies with the user's actual GPS coordinates. It calculates a compliance score (ε) based on the deviation between these two paths.
- **Core assumption:** Users behave rationally and follow optimal or near-optimal paths provided by standard navigation algorithms.
- **Evidence anchors:**
  - [Abstract]: "...core approach adapts Mirroring, comparing ideal routes to observation routes..."
  - [Section 2.3]: "...for every possible intended location in I, we compare its ideal route π with its observation route π_Obs and compute a score..."
  - [corpus]: Weak direct support; neighbor papers discuss trajectory prediction and intention tracking but do not validate the specific "Mirroring" algorithm in navigation contexts.
- **Break condition:** The user behaves irrationally, takes detours not reflected in the map data, or acts adversarially to obscure their destination.

### Mechanism 2: Geographic Similarity via Haversine Distance
- **Claim:** Accurate intention recognition in real-world maps requires spherical distance computation rather than Euclidean approximation to correctly penalize route deviations.
- **Mechanism:** The system uses the Haversine formula to compute the geographic distance between points on the ideal route and the observation route. This distance feeds the compliance score ε, ensuring that physical separation on the Earth's sphere is accurately measured.
- **Core assumption:** The curvature of the Earth is significant enough in the problem domain that Euclidean distance would introduce error in the similarity scoring.
- **Evidence anchors:**
  - [Abstract]: "...using the Haversine formula for geographic distance computation."
  - [Section 2.3]: "...ensuring a geographically accurate assessment of spatial separation of the points... in the Earth's sphere space."
  - [corpus]: No specific evidence in the provided corpus regarding the necessity of Haversine over other metrics; validation rests solely on the paper's implementation.
- **Break condition:** The coordinates are noisy or spurious to the degree that the spherical distance calculation becomes unreliable or misleading for the threshold settings.

### Mechanism 3: Specialized Routing vs. Generalist LLMs
- **Claim:** Specialized routing APIs (Google Maps) provide significantly more reliable path hypotheses for intention recognition than general-purpose Large Language Models (LLMs).
- **Mechanism:** The recognition process depends on the path-planner's ability to generate realistic routes. The paper demonstrates that while Google Maps achieves perfect recognition (TPR 1.00) and Mapbox is moderate (TPR 0.78), ChatGPT-4 fails (TPR 0.35) because it cannot consistently generate valid, coherent spatial routes.
- **Core assumption:** The accuracy of the intention recognition is upper-bounded by the realism and precision of the underlying path-planning engine.
- **Evidence anchors:**
  - [Abstract]: "...LLM-based approach (ChatGPT4) yielded the poorest results (TPR 0.35...), demonstrating that general-purpose LLMs are less reliable..."
  - [Section 3]: "It is noteworthy that the results for the recognition process using an LLM (ChatGPT4) are the worst... since LLMs are not explicitly designed for extracting the routes."
  - [corpus]: Consistent with neighbor "On the Planning Abilities of Large Language Models" (Valmeekam et al., cited in paper text), which investigates LLM planning limitations.
- **Break condition:** The specialized API suffers from outages, rate limits, or lacks map data for the specific region, forcing a fallback to inferior planners.

## Foundational Learning

- **Concept**: **Goal Recognition as Planning (GRP)**
  - **Why needed here**: The core logic relies on inverting the planning problem—using the plans (routes) that *would* be generated to infer the goal being pursued.
  - **Quick check question**: How does the system utilize the set of possible intentions I to compute the probability of the observations Obs?

- **Concept**: **Probabilistic Inference (Bayesian Update)**
  - **Why needed here**: The system does not output a single deterministic answer but a probability distribution (P(loc | Obs)) that updates as new GPS observations arrive.
  - **Quick check question**: In the formula P(loc | Obs) = η · P(loc) · P(Obs | loc), what does the term P(Obs | loc) represent in the context of a navigation route?

- **Concept**: **Haversine Formula**
  - **Why needed here**: Engineers must understand why standard distance formulas fail here; this formula accounts for the earth's curvature when calculating the distance between latitude/longitude pairs.
  - **Quick check question**: Why is the Haversine formula used instead of Euclidean distance when comparing the similarity of two GPS coordinates?

## Architecture Onboarding

- **Component map**: Input Interface -> Path-Planner Module -> Recognition Engine -> Probabilistic Ranker
- **Critical path**: The generation of the **Observation Route** (π_Obs) is the bottleneck. It requires querying the path-planner to find a route that passes through the observed points *before* reaching the goal. If the planner fails to find a route connecting these specific waypoints, recognition for that intention fails.
- **Design tradeoffs**:
  - **Google Maps vs. Mapbox**: Google Maps offers higher accuracy (Baseline TPR 1.00) but may introduce API cost and latency. Mapbox offers a lower-cost alternative but reduces recognition accuracy (TPR 0.78) due to route divergence.
  - **LLM Integration**: Using an LLM offers flexibility but current evidence suggests it is architecturally unsuitable for precise spatial path-planning (F1 0.04).
- **Failure signatures**:
  - **Cross-Platform Divergence**: If the user is navigating with Google Maps but the system uses Mapbox for recognition, performance drops.
  - **Sparse Observations**: With only 1 observation, the system struggles to differentiate between distinct goals (Google Maps TPR drops to 0.90, Mapbox to 0.20).
  - **Irrational Behavior**: The "Mirroring" logic assumes optimal behavior; unexpected detours or "scenic routes" will lower the probability score of the correct destination.
- **First 3 experiments**:
  1. **Baseline Verification**: Run the 100-problem dataset using the Google Maps planner exclusively to verify the "perfect" recognition (TPR 1.00) claimed in the paper.
  2. **Observation Ablation**: Test the system with varying observation counts (1, 3, 5, 10) to measure how quickly the probability ranking converges to the correct destination.
  3. **Planner Comparison**: Replicate the "User on Google vs. Recognizer on Mapbox" scenario to quantify the performance degradation caused by differing route optimization algorithms.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can intention recognition systems effectively handle irrational or adversarial user behavior that deliberately deviates from optimal routes?
- **Basis in paper**: [explicit] Authors state in the conclusions: "we aim to extend INTENT REC4MAPS and implement other recognition features and functionalities, such as dealing with irrational and possibly adversarial behaviour."
- **Why unresolved**: The current Mirroring approach fundamentally assumes users follow near-optimal routes, comparing ideal routes to observation routes. Adversarial behavior would violate this core assumption.
- **What evidence would resolve it**: Development of robust recognition algorithms that maintain accuracy when users intentionally take deceptive paths, evaluated on adversarial navigation scenarios.

### Open Question 2
- **Question**: Can LLMs be made reliable for spatial reasoning tasks like route planning through improved prompting, fine-tuning, or chain-of-thought approaches?
- **Basis in paper**: [inferred] LLM (ChatGPT4) performed poorest (TPR 0.35, F1 0.04), but authors only tested one prompting approach. The gap between symbolic planners and LLMs suggests potential for improvement.
- **Why unresolved**: Only a basic prompting approach was tested. The paper did not explore whether the LLM's poor performance is fundamental or due to suboptimal usage.
- **What evidence would resolve it**: Systematic experiments with varied prompting strategies (e.g., chain-of-thought, few-shot examples, structured output formats) or domain-adapted LLMs, showing significantly improved TPR and F1 scores.

### Open Question 3
- **Question**: How does recognition accuracy scale with the geographic distance between initial location and intended destinations?
- **Basis in paper**: [explicit] Authors state: "we aim to assess the recognition accuracy of INTENTREC4MAPS when dealing with long-distance intended location points."
- **Why unresolved**: The current dataset uses London-based locations of unspecified distance range. Long-distance routes may have more route alternatives, observations spread across longer paths, and different noise characteristics.
- **What evidence would resolve it**: Evaluation on problems grouped by distance categories (e.g., <5km, 5-50km, >100km), showing whether accuracy remains stable or degrades with distance.

## Limitations

- The system assumes rational user behavior following optimal routes, which may not hold in real-world scenarios with traffic, personal preferences, or detours
- Performance is tightly coupled to the underlying path-planning API's quality, with significant accuracy gaps between different providers
- Perfect performance metrics (TPR 1.00, F1 1.00) seem unusually high and may indicate overfitting to the specific 100-problem dataset

## Confidence

- **High confidence**: The architectural design of using specialized routing APIs over LLMs for spatial reasoning is well-supported by experimental results and consistent with literature on LLM planning limitations
- **Medium confidence**: The Haversine formula provides accurate geographic distance computation, though the paper doesn't provide empirical comparison with alternative distance metrics
- **Low confidence**: The claimed "perfect" recognition performance with Google Maps requires independent verification, as such results are rare in real-world intention recognition tasks

## Next Checks

1. **Cross-platform stress test**: Run the recognition system with Google Maps as path-planner but simulate user behavior using Mapbox routes (and vice versa) to quantify the performance penalty from planner divergence
2. **Edge case analysis**: Test the system with intentionally irrational user behavior (detours, backtracking, non-optimal routes) to measure how quickly the "Mirroring" approach breaks down
3. **Dataset generalization**: Apply the recognition system to a different, independently collected navigation dataset to verify that the perfect performance metrics are not artifacts of the specific 100-problem collection