---
ver: rpa2
title: Extractive Fact Decomposition for Interpretable Natural Language Inference
  in one Forward Pass
arxiv_id: '2509.18901'
source_url: https://arxiv.org/abs/2509.18901
tags:
- spans
- fact
- atomic
- span
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of making natural language inference
  (NLI) interpretable and robust by proposing a method to distill atomic fact decomposition
  into encoder-only architectures, eliminating the need for resource-intensive generative
  models at inference time. The authors introduce JEDI, a joint encoder-only model
  that performs extractive atomic fact decomposition and logical inference in a single
  forward pass.
---

# Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass

## Quick Facts
- arXiv ID: 2509.18901
- Source URL: https://arxiv.org/abs/2509.18901
- Reference count: 26
- This paper demonstrates that extractive atomic fact decomposition achieves competitive accuracy and significantly improved robustness compared to models using only extractive rationale supervision.

## Executive Summary
This paper addresses the challenge of making natural language inference (NLI) interpretable and robust by proposing a method to distill atomic fact decomposition into encoder-only architectures, eliminating the need for resource-intensive generative models at inference time. The authors introduce JEDI, a joint encoder-only model that performs extractive atomic fact decomposition and logical inference in a single forward pass. To train this model, they create SYRP, a large synthetic corpus of rationales across multiple NLI benchmarks. Experiments show that JEDI achieves competitive accuracy in-distribution and significantly improves robustness out-of-distribution and in adversarial settings over models using only extractive rationale supervision.

## Method Summary
The authors propose JEDI (Joint Extractive Decompositional Inference), an encoder-only architecture that jointly performs premise decomposition into atomic facts and atom-level classification. The model uses DeBERTa as its backbone with additional heads for global classification, span extraction, and span-wise NLI. Training leverages a synthetic corpus (SYRP) created by prompting LLMs to highlight salient spans given gold labels. The approach uses adaptive thresholding loss to handle class imbalance and employs rule-based logical aggregation for final predictions.

## Key Results
- JEDI achieves competitive accuracy on in-distribution ANLI benchmarks
- Significantly improved robustness on out-of-distribution datasets (ConTRoL, RTE, WNLI)
- Substantial gains on HANS adversarial benchmark compared to baseline models
- Outperforms pipeline models and JEDIsent (sentence-level variant) on both accuracy and interpretability metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured reasoning over decomposed semantic units improves out-of-distribution robustness compared to end-to-end classification.
- **Mechanism:** Atomic fact decomposition isolates semantically coherent sub-facts, requiring the model to verify each against the hypothesis individually rather than learning shallow correlations from the full premise. This constraint forces granular alignment rather than pattern matching.
- **Core assumption:** Robustness gains arise from the decomposition structure itself (span-level reasoning), not specifically from generative abstraction.
- **Evidence anchors:**
  - [abstract] "Experimental results demonstrate that JEDI achieves competitive accuracy in distribution and significantly improves robustness out of distribution and in adversarial settings over models based solely on extractive rationale supervision."
  - [section 3] "...observed robustness improvements may not inherently depend on abstraction via generation, but rather on the structured reasoning over clearly defined semantic units..."
  - [corpus] Related work (Atomic-SNLI, NLI under the Microscope) supports decomposition for fine-grained inference, though direct evidence for extractive vs. generative equivalence is limited.
- **Break condition:** If decomposition quality is poor (e.g., spans don't capture atomic facts, or hallucinated spans are included), the reasoning becomes unreliable and robustness gains may disappear.

### Mechanism 2
- **Claim:** Synthetic rationales from LLMs can effectively supervise extractive models when the teacher is provided gold labels and only tasked with highlighting.
- **Mechanism:** By giving the annotator LLM the correct label upfront, the task shifts from full NLI reasoning to span identification, reducing error propagation. The model learns to mimic the extraction behavior without needing to match the teacher's full reasoning capacity.
- **Core assumption:** The annotation model can reliably identify salient spans given the correct label, even if it cannot solve NLI at state-of-the-art levels.
- **Evidence anchors:**
  - [abstract] "...we create SYRP, a large synthetic corpus of rationales across multiple NLI benchmarks."
  - [section 4.1] "...IoU of 69%, indicating substantial agreement... We found only 2 out of 30 explanations to be of low quality..."
  - [corpus] No direct corpus evidence on synthetic rationale quality thresholds; this remains a domain-specific assumption.
- **Break condition:** If synthetic annotations contain systematic biases or hallucinations not caught by quality checks, model predictions will inherit these errors.

### Mechanism 3
- **Claim:** Joint training of extraction and inference in a single forward pass reduces error propagation compared to pipeline approaches.
- **Mechanism:** The encoder learns shared representations for both span detection and NLI classification simultaneously. Span-level predictions directly contribute to the final label through explicit logical rules, creating end-to-end differentiable feedback.
- **Core assumption:** Span extraction and logical inference are sufficiently related to benefit from shared representations.
- **Evidence anchors:**
  - [abstract] "...joint encoder-only model that performs extractive atomic fact decomposition and logical inference in a single forward pass."
  - [section 5] "...encoder-only model architecture which performs premise decomposition and atom-level interpretable classification while requiring only a single forward pass..."
  - [corpus] Joint architectures in relation extraction (Eberts & Ulges 2021) show similar benefits, but direct NLI-specific evidence is limited.
- **Break condition:** If extraction and inference objectives conflict significantly, joint training may underperform pipelined alternatives with dedicated components.

## Foundational Learning

- **Concept: Span-level representations**
  - **Why needed here:** JEDI encodes premise spans as embeddings (concatenating start/end token vectors) and classifies each independently. Understanding how token embeddings aggregate into span representations is essential.
  - **Quick check question:** Can you explain how the model represents a span (i, j) for classification?

- **Concept: Logical aggregation rules**
  - **Why needed here:** Final predictions emerge from rule-based aggregation over span-level classifications (contradiction if any span contradicts, etc.), not from a learned classifier.
  - **Quick check question:** If three spans are classified as [neutral, entailment, neutral], what is the final prediction assuming the global classifier predicts entailment?

- **Concept: Adaptive thresholding loss**
  - **Why needed here:** Class imbalance (most spans are neutral) is handled via adaptive thresholding from relation extraction, not standard cross-entropy.
  - **Quick check question:** Why might standard cross-entropy struggle with a dataset where 90% of spans are labeled neutral?

## Architecture Onboarding

- **Component map:**
  1. Encoder (DeBERTa): Processes concatenated [CLS] + premise + [SEP] + hypothesis
  2. Global classifier: Group bilinear layer on CLS/SEP embeddings for initial triage
  3. Span detector: Binary classifiers for start positions and span validity
  4. Span classifier: Group bilinear layer on CLS + span embeddings
  5. Logical aggregator: Rule-based combination of span predictions

- **Critical path:**
  Premise/hypothesis → Encoder → Global classification (if neutral, stop) → Span extraction → Span-wise NLI → Logical aggregation → Final label + evidence spans

- **Design tradeoffs:**
  - Sentence-level vs. span-level: Sentences (JEDIsent) yield higher accuracy but coarser interpretability
  - Extraction vs. generation: Avoids LLM inference cost and hallucination risk, but loses paraphrasing flexibility
  - Global classifier gating: Saves computation but requires learning when to stop early

- **Failure signatures:**
  - Low HANS accuracy → model may have learned shallow heuristics rather than genuine reasoning
  - Missing spans on long premises → extraction module may struggle with coverage
  - Inconsistent span-level vs. global predictions → aggregation rules may need tuning

- **First 3 experiments:**
  1. Reproduce SYRP annotation quality: Sample 100 ANLI examples, generate synthetic rationales, measure IoU against manual annotations
  2. Ablate global classifier: Compare full JEDI vs. JEDI_no_global on ANLI and HANS to verify contribution
  3. Cross-dataset transfer: Train on ANLI, evaluate on ConTRoL/RTE without fine-tuning to assess generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Direct comparison with generative models using identical decomposition quality metrics is absent, leaving open whether generation adds value beyond the decomposition structure itself
- Synthetic rationale generation quality thresholds and their impact on downstream performance lack detailed characterization
- The global classifier gating mechanism may prematurely classify complex cases requiring span-level reasoning as neutral

## Confidence

**High Confidence:** The empirical results demonstrating improved HANS performance and out-of-distribution robustness are well-supported by the experimental design and results presentation.

**Medium Confidence:** The mechanism claiming extractive decomposition equals generative abstraction for robustness gains relies on indirect evidence without direct comparison of models using identical decomposition quality.

**Low Confidence:** The synthetic rationale generation quality thresholds and their impact on downstream performance lack detailed characterization and minimum quality requirements.

## Next Checks

1. **Decomposition Quality Equivalence Test:** Generate synthetic rationales using both extractive and generative approaches on identical examples, then measure decomposition quality metrics (IoU, semantic coherence) to determine if they produce comparable atomic facts for the same premises.

2. **Annotation Noise Sensitivity Analysis:** Systematically degrade synthetic rationale quality in controlled increments and measure the resulting impact on model accuracy and robustness to identify minimum annotation quality thresholds for reliable supervision.

3. **Reasoning Complexity Impact Study:** Stratify the test set by reasoning complexity (simple lexical overlap vs. multi-hop reasoning) and measure how JEDI's performance advantage varies across these categories to identify limitations in the decomposition approach.