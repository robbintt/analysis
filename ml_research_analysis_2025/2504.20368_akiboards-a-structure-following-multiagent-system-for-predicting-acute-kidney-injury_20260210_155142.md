---
ver: rpa2
title: 'AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney
  Injury'
arxiv_id: '2504.20368'
source_url: https://arxiv.org/abs/2504.20368
tags:
- agent
- round
- sf-ft
- reasoning
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: STRUC-MAS automates learning global structures for multiagent systems
  to improve diagnostic reasoning in complex medical settings. This study demonstrates
  its application to acute kidney injury (AKI) prediction using a prosocial multiagent
  system (AKIBoards) that leverages learned global structures as prior beliefs.
---

# AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury

## Quick Facts
- arXiv ID: 2504.20368
- Source URL: https://arxiv.org/abs/2504.20368
- Reference count: 0
- Primary result: Structure-following multiagent system (SF-FT) achieves AP=0.195 vs. baseline SF-FT AP=0.141 for AKI prediction

## Executive Summary
AKIBoards introduces a structure-following multiagent system (STRUC-MAS) that automates learning global structures from tabular clinical data to improve diagnostic reasoning in complex medical settings. The system leverages SHAP-based rank learning to extract feature importance and directionality from validation data, producing an explicit structure template that serves as prior beliefs for agents. When applied to acute kidney injury prediction, incorporating global structure enabled agents to outperform baseline models, with balanced precision-weighted-recall-weighted voting achieving superior performance. The framework demonstrates that learning and leveraging global structures in MAS is necessary for competitive classification and diagnostic reasoning performance in healthcare applications.

## Method Summary
The method employs SHAP-based rank learning (RAUS) to automatically extract global structures from tabular clinical data, creating a structure template that serves as prior beliefs for fine-tuned LLMs. Three agents (Llama 3.1 8B, Phi4 14B, Qwen 2.5 32B) operate in "smart rounds" where they produce independent diagnoses in Round 0, then view and potentially revise diagnoses based on peer outputs in subsequent rounds. The system uses a prosocial layer with PScore calculation to gate execution, and aggregates results using balanced precision-weighted-recall-weighted voting. Structure templates are injected into agent prompts to ground reasoning in population-level patterns rather than relying solely on parametric knowledge.

## Key Results
- Structure-following-fine-tuned AP=0.195 vs. baseline non-structure-following-fine-tuned AP=0.141 for AKI prediction
- Balanced precision-weighted-recall-weighted voting achieved best performance over precision-weighted, recall-weighted, or majority vote
- Agents with higher recall initially reported lower confidence on true positive and false negative cases, but confidence increased after explicit interactions
- Agent with lowest recall decreased confidence after interactions, suggesting new belief formation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating learned global structure as prior beliefs improves multi-agent diagnostic performance over unstructured approaches
- Mechanism: SHAP-based rank learning extracts feature importance and directionality from validation data, producing explicit structure template injected into agent prompts
- Core assumption: Validation set distribution approximates test distribution; SHAP rankings capture clinically meaningful relationships
- Evidence anchors: SF-FT Agent 1 recall increased from 0.01 to 0.62 after explicit interactions; Agent 1 decreased confidence on TP/FN cases post-interaction
- Break condition: If feature distributions shift between validation and deployment, learned structure may mislead agents

### Mechanism 2
- Claim: Explicit inter-agent interaction drives belief updates that improve individual agent recall through knowledge distillation
- Mechanism: Agents produce independent diagnoses in Round 0, then view and revise based on peers' outputs in Round 1+, with higher-recall agents reinforcing confidence and lower-recall agents reducing confidence on misdiagnosed cases
- Core assumption: Agents can meaningfully interpret and incorporate peer reasoning; at least one agent has sufficiently high recall to serve as teacher signal
- Evidence anchors: SF-FT Agent 1 recall increased from 0.01 to 0.62 after explicit interactions; Agents 2-3 increased confidence post-interaction
- Break condition: If all agents have uniformly poor recall, interaction may reinforce errors rather than correct them

### Mechanism 3
- Claim: Balanced precision-weighted-recall-weighted voting outperforms simpler aggregation for imbalanced clinical outcomes
- Mechanism: BPRV averages precision-weighted and recall-weighted votes, balancing false positive control against sensitivity for conditions with low prevalence but high consequence
- Core assumption: Voting weights meaningfully reflect agent reliability; agent performance on validation approximates test behavior
- Evidence anchors: BPRV recall improved from 0.37 (Round 0) to 0.62 (Round 1) for SF-FT; BPRV used for reported AP gains
- Break condition: If agent calibration degrades, weighted voting may amplify errors

## Foundational Learning

- **Concept: SHAP (SHapley Additive exPlanations)**
  - Why needed here: Core method for learning global structure from tabular clinical data; converts black-box model outputs into interpretable feature rankings with directionality
  - Quick check question: Can you explain why SHAP values for eGFR bin 1 being negative indicates higher AKI risk in the learned structure?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Semi-structure-following path uses RAG to retrieve similar training cases, enabling comparison-based reasoning beyond static structure template
  - Quick check question: How does RAG complement vs. compete with structure-following in this architecture?

- **Concept: Knowledge Distillation in Multi-Agent Systems**
  - Why needed here: Explains how weaker agents improve via exposure to stronger agents' outputs during explicit interaction rounds
  - Quick check question: What conditions must hold for inter-agent distillation to improve rather than degrade team performance?

## Architecture Onboarding

- **Component map:** Data Layer -> Structure Learning Module -> Prosocial Layer -> Agent Pool -> Smart Rounds Orchestrator -> Aggregation -> Logging
- **Critical path:** Serialize patient data into note format → Apply structure template as prior in agent prompt → Run Round 0 (independent agent diagnoses) → If early stopping threshold not met, run Round 1+ with peer output sharing → Aggregate via BPRV → Log MAR-ABT outputs
- **Design tradeoffs:** SF-FT vs. SF-FT-RAG (RAG adds retrieval overhead but may help edge cases); Number of agents (3 used, more increases robustness but also latency); Early stopping threshold (set at 0.040)
- **Failure signatures:** Agent 1 pattern (high confidence on false negatives in Round 0); Flat AP across rounds (structure not utilized); PScore below threshold (prosocial layer blocking execution)
- **First 3 experiments:** Reproduce structure learning (verify top-10 feature ranking matches Table 1); Ablate structure template (compare AP delta to validate mechanism 1); Single-round vs. two-round comparison (measure recall and confidence changes to validate belief update dynamics)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can STRUC-MAS maintain performance when applied to clinical domains with complex, overlapping pathologies (e.g., oncology or cardiology)?
- Basis in paper: Authors state board configurations "may be suitable for other clinical specialties... such as where overlap of organs/systems makes it difficult to assume or know underlying structures"
- Why unresolved: Current study validated framework exclusively on AKI prediction using MIMIC-III dataset
- What evidence would resolve it: Empirical validation of AKIBoards framework on datasets from specialties like cardiology or rheumatology, comparing performance against current baselines

### Open Question 2
- Question: How does implementing multiple stakeholder boards with dynamic resource allocation affect diagnostic accuracy and efficiency?
- Basis in paper: Conclusion explicitly lists "implementing multiple boards (i.e., multi-stakeholders) and dynamic resource allocation" as future work
- Why unresolved: Current implementation limited to single board configuration with static resource allocation
- What evidence would resolve it: Comparative study measuring Average Precision and documentation burden in systems utilizing multiple boards versus single board

### Open Question 3
- Question: Is observed knowledge distillation from high-performing agents to low-performing agents robust across different foundation model combinations?
- Basis in paper: Paper notes Agent 1 (weak) improved via interactions with stronger agents, but study used specific set of three LLMs
- Why unresolved: Unclear if this "smart rounds" improvement is generalizable emergent behavior or dependent on specific LLMs chosen
- What evidence would resolve it: Ablation studies substituting different foundation models to verify if knowledge distillation effect persists regardless of underlying model architectures

## Limitations
- SHAP-based global structure relies heavily on validation set distribution matching test conditions; distributional shifts could degrade structure utility
- Prosocial layer (PScore threshold) may prevent execution in some clinical scenarios, though exact failure rates are not quantified
- Interaction dynamics depend on having at least one competent anchor agent; system performance could degrade significantly if all agents have poor recall

## Confidence
- **High Confidence:** Structural learning mechanism (SHAP rank learning) and its integration into agent prompts is well-documented and reproducible
- **Medium Confidence:** Belief update dynamics during agent interactions show consistent patterns but require further validation across diverse clinical conditions
- **Low Confidence:** BPRV aggregation method's superiority over simpler voting schemes lacks direct comparative validation in medical MAS literature

## Next Checks
1. **Distributional Robustness Test:** Evaluate structure-following performance across multiple validation/test splits to assess sensitivity to data distribution shifts
2. **Anchor Agent Dependency Analysis:** Systematically measure team performance with varying numbers of competent vs. incompetent agents to quantify interaction benefits
3. **Voting Scheme Comparison:** Directly compare BPRV against simple majority voting and weighted voting across multiple clinical prediction tasks to validate aggregation method claims