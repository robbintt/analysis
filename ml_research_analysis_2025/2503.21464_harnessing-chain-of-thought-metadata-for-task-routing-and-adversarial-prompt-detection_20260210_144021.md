---
ver: rpa2
title: Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt
  Detection
arxiv_id: '2503.21464'
source_url: https://arxiv.org/abs/2503.21464
tags:
- number
- prompts
- prompt
- routing
- hard
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel metric called Number of Thoughts (NofT)
  to assess task complexity and improve efficiency in large language model (LLM) deployments.
  The NofT metric quantifies the number of intermediate reasoning steps in Chain-of-Thought
  (CoT) prompting, enabling better prompt routing, adversarial prompt detection, and
  resource optimization.
---

# Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection

## Quick Facts
- arXiv ID: 2503.21464
- Source URL: https://arxiv.org/abs/2503.21464
- Reference count: 37
- This work introduces a novel metric called Number of Thoughts (NofT) to assess task complexity and improve efficiency in large language model (LLM) deployments.

## Executive Summary
This paper introduces Number of Thoughts (NofT), a metric that quantifies intermediate reasoning steps in Chain-of-Thought (CoT) prompting to improve LLM task routing, adversarial prompt detection, and resource optimization. The NofT metric is derived by parsing CoT outputs using a distilled Deepseek model and sentence analysis techniques, enabling classification of task complexity and detection of potential security threats. A Random Forest classifier trained on NofT predictions achieves 80% accuracy in difficulty classification and 95% accuracy in adversarial prompt detection. The routing framework assigns prompts to appropriately sized models (1.5B, 7B, or 14B parameters) based on NofT thresholds, resulting in a 2.4% reduction in latency while maintaining comparable accuracy.

## Method Summary
The NofT metric is derived by generating CoT outputs using a distilled DeepSeek-R1 model (1.5B) with explicit step numbering, then parsing thought counts through a two-stage process: checking for explicit numbering and falling back to transitional keyword detection (first, next, finally). A Random Forest classifier trained on TF-IDF representations predicts NofT for unseen prompts. The framework routes prompts to appropriately sized models based on NofT thresholds optimized via Tree-structured Parzen Estimator (TPE), balancing latency, accuracy, and power consumption. Adversarial prompts are detected by identifying NofT deviations from predicted complexity expectations.

## Key Results
- RF classifier achieves 80% accuracy in task difficulty classification (Easy/Medium/Hard)
- Adversarial prompt detection reaches 95% accuracy with 90% precision using 0.90 probability threshold
- Three-model routing (1.5B/7B/14B) achieves 14.96% latency improvement while maintaining ROUGE-L accuracy

## Why This Works (Mechanism)

### Mechanism 1: NofT Quantifies Task Complexity via CoT Structure
The number of reasoning steps in Chain-of-Thought outputs correlates with task difficulty, enabling pre-generation complexity estimation. A distilled DeepSeek-R1 model (1.5B) generates CoT responses with explicit step numbering. A two-stage parser extracts thought counts: (1) check for explicit numbering, (2) fallback to transitional keyword detection (first, next, finally). A Random Forest classifier trained on TF-IDF representations predicts NofT for unseen prompts. Complex tasks require more discrete reasoning steps than simple ones, and models consistently decompose tasks proportionally to their intrinsic difficulty.

### Mechanism 2: NofT Deviations Signal Adversarial Intent
Prompts with anomalous NofT values relative to predicted complexity indicate potential injection attacks. Compare predicted NofT against learned difficulty expectations. Significant deviations trigger adversarial classification. A Random Forest classifier with calibrated probability threshold (0.90) labels prompts as adversarial. Adversarial prompts induce atypical reasoning patterns—either truncated (attempting direct manipulation) or bloated (obfuscating malicious intent)—that differ measurably from benign prompts of similar surface complexity.

### Mechanism 3: Threshold-Based Routing Optimizes Latency-Accuracy Tradeoffs
NofT thresholds enable intelligent routing to appropriately-sized models, reducing latency while maintaining accuracy. Tree-structured Parzen Estimator (TPE) optimizes threshold values (T1, T2) by maximizing a score function combining ROUGE-L accuracy, latency, and power consumption. Prompts below T1 route to 1.5B model, between T1-T2 to 7B, above T2 to 14B. Smaller quantized models adequately handle low-complexity tasks, and the marginal accuracy gain from larger models doesn't justify their latency cost for simple prompts.

## Foundational Learning

- **Chain-of-Thought (CoT) Prompting**: Why needed here: NofT fundamentally depends on models generating explicit intermediate reasoning steps. Understanding how CoT is elicited (prompting vs. fine-tuning) and how step granularity varies across models is essential for interpreting NofT reliability. Quick check: Given a prompt "Calculate 15% tip on $47," would you expect a higher or lower NofT from a model prompted with "Think step by step" versus one fine-tuned for concise responses?

- **Random Forest Classification with Imbalanced Data**: Why needed here: The paper uses RF classifiers with SMOTE oversampling and isotonic calibration. Understanding why sparse TF-IDF features work better than dense embeddings here—and how class imbalance affects precision/recall tradeoffs—is critical for reproducing results. Quick check: If adversarial prompts represent only 10% of your dataset, which metric (precision or recall) would you prioritize for a security-focused classifier, and how would SMOTE help?

- **Threshold Optimization via Tree-structured Parzen Estimator (TPE)**: Why needed here: Routing thresholds aren't manually set but learned via TPE balancing multiple objectives. Understanding how TPE differs from grid search and why it suits this multi-objective problem is key for extending the routing framework. Quick check: If TPE finds threshold T1=5 but you notice high variance in routing decisions near this boundary, what modification to the optimization objective might stabilize routing?

## Architecture Onboarding

- **Component map**: Input Prompt → [TF-IDF Vectorizer] → [RF Classifier (NofT Prediction)] → Predicted NofT → [T1 Check] [T2 Check] [Adversarial Check] → Route to 1.5B Route to 7B Route to 14B [Alert/Block]

- **Critical path**: 
  1. NofT Derivation Pipeline: Prompt → DeepSeek-R1-Distill-Qwen-1.5B → CoT output → Sentence parser → Thought count label
  2. RF Training: TF-IDF vectors + NofT labels → Train RF with MSE loss → Calibrate with isotonic regression
  3. Inference Flow: New prompt → TF-IDF → RF predicts NofT → Threshold comparison → Model routing + adversarial flag

- **Design tradeoffs**:
  - Parser robustness vs. model dependency: Explicit step numbering is reliable but model-specific. Keyword fallback is model-agnostic but brittle (TinyR1 failure case)
  - Threshold sensitivity: High thresholds (Config 1: 35) maximize latency gains but skip mid-tier models entirely. Lower thresholds (Config 2: 4.8, 20.3) distribute load but show weaker gains
  - Adversarial precision vs. recall: 0.90 threshold yields 90% precision but only 60% recall on adversarial class (Table 9). Security contexts may prefer higher recall

- **Failure signatures**:
  - Parsing failures: Models outputting unstructured prose without clear transitions → NofT undercounting
  - Medium difficulty confusion: RF achieves 64% precision on medium prompts (Table 7) vs. 98% on easy—expect routing jitter near T1/T2
  - Domain shift: RF trained on MathInstruct may not generalize to non-mathematical domains without retraining
  - Power measurement noise: NVML-based power sampling showed zero variance in results (Tables 10-11)—verify monitoring setup

- **First 3 experiments**:
  1. Validate NofT extraction on your target model: Run the parser on 50 diverse prompts from your production data. Manually verify thought counts match parser output. Flag prompts where bundling or unusual formatting causes undercounting
  2. Calibrate routing thresholds for your model set: The paper's thresholds (4.8, 20.3) were tuned for quantized DeepSeek variants. Run TPE optimization with your actual model latency/accuracy profiles to find domain-specific thresholds
  3. Test adversarial detection on known attack patterns: Inject 20 prompt injection attempts (e.g., "Ignore previous instructions...") into a sample of 100 benign prompts. Measure precision/recall at different probability thresholds to find your security/UX balance point

## Open Questions the Paper Calls Out

### Open Question 1
Can the NofT metric be adapted to generalize across LLM architectures that produce aggregated or non-sequential reasoning outputs? The current methodology relies on detecting transitional keywords (e.g., "first," "next") that are absent in models utilizing dense reasoning representations. A modified parsing strategy that successfully extracts thought counts from models like TinyR1 or Llama without relying on explicit step-numbering would resolve this.

### Open Question 2
Is it possible to define NofT thresholds that reliably distinguish "medium" complexity prompts from "easy" and "hard" categories? The RF classifier often misclassifies medium prompts as hard, and the routing optimization showed limitations in clearly differentiating medium difficulty levels. A classifier achieving significantly higher F1-scores for the "medium" class or a routing configuration that utilizes a three-model tier effectively without bypassing the medium-sized model would resolve this.

### Open Question 3
Does using a larger model to generate ground-truth thought counts improve the accuracy of complexity estimation? The authors hypothesize that a larger model might over-generalize while missing nuances captured by smaller annotator models. An ablation study comparing the quality of ground-truth labels generated by 1.5B, 7B, and 14B parameter models against human expert annotations would resolve this.

## Limitations
- NofT metric reliability depends heavily on consistent Chain-of-Thought formatting across models
- Difficulty classification boundaries are fuzzy, with RF classifier showing weak performance on medium (64%) and hard (35%) prompts
- Adversarial detection trade-offs result in only 60% recall despite 95% accuracy with conservative 0.90 precision threshold

## Confidence
- **High Confidence**: NofT metric can be reliably extracted from models that consistently format CoT outputs with explicit step numbering or clear transitional keywords
- **Medium Confidence**: Threshold-based routing achieves measurable latency improvements without significant accuracy degradation for mathematical reasoning tasks
- **Medium Confidence**: NofT deviations correlate with adversarial intent in mathematical reasoning contexts with conservative probability thresholds
- **Low Confidence**: Framework generalizes effectively to non-mathematical domains and models with varying CoT formatting conventions

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate the RF classifier and routing framework on a non-mathematical dataset (e.g., legal reasoning, creative writing) to assess whether NofT maintains predictive power across reasoning types. Compare performance degradation against baseline routing.

2. **Robustness Against CoT Obfuscation**: Design prompts that deliberately obscure reasoning steps (e.g., embedded narratives, metaphorical reasoning) and measure parser accuracy and subsequent routing/adversarial detection failures. This tests the framework's vulnerability to adversarial prompt design.

3. **Multi-Model Calibration Study**: Test routing thresholds across a broader range of model families (not just DeepSeek quantized variants) to determine if TPE-optimized thresholds are model-specific or transferable. Include models with different parametric capacities and architectural designs.