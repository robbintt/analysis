---
ver: rpa2
title: Model Compression Engine for Wearable Devices Skin Cancer Diagnosis
arxiv_id: '2507.17125'
source_url: https://arxiv.org/abs/2507.17125
tags:
- skin
- cancer
- performance
- precision
- diagnostic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of skin cancer detection in
  resource-limited settings by developing an AI-driven diagnostic tool optimized for
  embedded systems. The core method involves transfer learning using the MobileNetV2
  architecture, followed by model compression and optimization with the TensorRT framework
  for deployment on the NVIDIA Jetson Orin Nano.
---

# Model Compression Engine for Wearable Devices Skin Cancer Diagnosis

## Quick Facts
- arXiv ID: 2507.17125
- Source URL: https://arxiv.org/abs/2507.17125
- Reference count: 15
- One-line primary result: Achieved 87.18% F1-Score with 93.18% precision and 81.91% recall on binary skin cancer classification using TensorRT-optimized MobileNetV2 on Jetson Orin Nano

## Executive Summary
This study addresses the challenge of skin cancer detection in resource-limited settings by developing an AI-driven diagnostic tool optimized for embedded systems. The core method involves transfer learning using the MobileNetV2 architecture, followed by model compression and optimization with the TensorRT framework for deployment on the NVIDIA Jetson Orin Nano. The optimized model achieved an F1-Score of 87.18%, with precision of 93.18% and recall of 81.91%, demonstrating strong diagnostic performance. Post-compression results showed significant improvements: model size reductions up to 0.41×, inference speed enhancements, throughput gains, and power consumption reductions of up to 0.93× in INT8 precision. These outcomes validate the feasibility of deploying high-performing, energy-efficient diagnostic tools on resource-constrained edge devices, enabling accessible healthcare solutions in underserved regions.

## Method Summary
The method employs transfer learning with MobileNetV2, pre-trained on ImageNet, which is fine-tuned on the Skin Lesions Classification Dataset (SLCD) for binary classification of skin lesions into "Skin Cancer" and "Other" categories. The original 14-class dataset is collapsed into two classes to address class imbalance, and 5-fold cross-validation is used to ensure robust performance estimation. The model is then optimized using the TensorRT framework, converting it into FP32, FP16, and INT8 precision variants for deployment on the NVIDIA Jetson Orin Nano. The optimization process includes layer fusion, precision quantization, and calibration to balance model size, inference speed, and power consumption.

## Key Results
- Achieved 87.18% F1-Score with 93.18% precision and 81.91% recall on binary skin cancer classification
- Model size reduced by up to 0.41× post-compression, with significant improvements in inference speed and throughput
- Power consumption decreased by up to 0.93× in INT8 precision, demonstrating energy efficiency
- FP16 and INT8 quantization showed mixed performance, with FP16 underperforming due to hardware optimization constraints on Jetson Orin Nano

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Transfer learning from MobileNetV2 enables effective skin lesion classification with limited domain-specific training data.
- **Mechanism:** Pre-trained convolutional features from ImageNet transfer to dermatological imaging because low-level visual representations (edges, textures, color gradients) are shared across domains. The final classification layer and last four layers are fine-tuned on the Skin Lesions Classification Dataset (SLCD), adapting high-level features while preserving learned representations.
- **Core assumption:** Dermoscopic/clinical skin lesion images share sufficient low-level visual structure with ImageNet images for feature transfer to be effective.
- **Evidence anchors:**
  - [abstract] "Using transfer learning with the MobileNetV2 architecture, the model was adapted for binary classification of skin lesions into 'Skin Cancer' and 'Other.'"
  - [section] "The final classification layer was retrained for 50 epochs using the Skin Lesions Classification Dataset (SLCD), followed by the fine-tuning of the last four layers."
  - [corpus] MedGrad E-CLIP (arXiv:2501.06887) addresses interpretability in skin lesion diagnosis but does not validate transfer learning efficacy directly.
- **Break condition:** Transfer learning benefits diminish if pre-training domain is too dissimilar or if target dataset distribution shift is extreme.

### Mechanism 2
- **Claim:** TensorRT optimization reduces model size, inference latency, and power consumption through layer fusion and precision quantization.
- **Mechanism:** TensorRT performs graph optimization (layer fusion, kernel auto-tuning, constant folding) and precision calibration. FP16 and INT8 quantization reduce memory bandwidth and computational intensity. Mixed-precision retains FP32 for input/output layers while using lower precision in hidden layers. Cast operations handle precision transitions between layers.
- **Core assumption:** Quantization-induced accuracy loss is negligible for this binary classification task after calibration.
- **Evidence anchors:**
  - [abstract] "Post-compression results showed reductions in model size of up to 0.41, along with improvements in inference speed and throughput, and a decrease in energy consumption of up to 0.93 in INT8 precision."
  - [section] Table III shows operation distribution changes including "Cast operations added for precision conversion" for FP16/INT8 models.
  - [corpus] Corpus does not provide external validation of TensorRT's quantization behavior on medical imaging tasks.
- **Break condition:** INT8/FP16 gains may not materialize if hardware lacks native low-precision support or if calibration dataset is unrepresentative.

### Mechanism 3
- **Claim:** Binary classification (cancer vs. other) with 5-fold cross-validation mitigates class imbalance and improves generalization.
- **Mechanism:** Original 14-class dataset (highly imbalanced: melanocytic nevi = 12,875; squamous cell carcinoma = 628) is collapsed into two classes. Cross-validation systematically rotates validation folds, reducing overfitting risk and providing robust performance estimates. The 90-10 train-validation split ensures consistent evaluation.
- **Core assumption:** Collapsing 14 classes into binary preserves clinically meaningful distinctions without introducing label noise.
- **Evidence anchors:**
  - [section] "To mitigate the challenges posed by class imbalance, 5-fold cross-validation was employed."
  - [section] "The dataset, which originally consisted of images from 14 distinct skin lesion types, was condensed into two categories."
  - [corpus] iToBoS dataset paper (arXiv:2501.18270) uses different dataset structure; no direct comparison available.
- **Break condition:** Binary simplification may obscure sub-type information clinically relevant for treatment decisions.

## Foundational Learning

- **Concept: Transfer Learning**
  - **Why needed here:** Understanding how pre-trained weights transfer and what layers to fine-tune is essential for adapting the pipeline to new lesion types or hardware.
  - **Quick check question:** If you were adapting this model to detect a different cancer type, which layers would you freeze vs. fine-tune, and why?

- **Concept: Quantization (FP32 → FP16/INT8)**
  - **Why needed here:** The paper relies on TensorRT's quantization for deployment gains; understanding precision tradeoffs is critical for debugging performance regressions.
  - **Quick check question:** What calibration strategy would you use to minimize accuracy loss when quantizing from FP32 to INT8 for a medical classifier?

- **Concept: Class Imbalance Handling**
  - **Why needed here:** The dataset has 8,473 skin cancer vs. 25,821 "other" samples; understanding how cross-validation and metrics (F1 vs. accuracy) interact with imbalance prevents misinterpretation.
  - **Quick check question:** Why is F1-Score reported instead of accuracy when evaluating this imbalanced dataset?

## Architecture Onboarding

- **Component map:**
  Input: Skin lesion images (resized to MobileNetV2 input dimensions) -> Backbone: MobileNetV2 (pre-trained on ImageNet, fine-tuned on SLCD) -> Classification head: Binary output ("Skin Cancer" vs. "Other") -> Optimization layer: TensorRT engine (FP32/FP16/INT8 variants) -> Deployment target: NVIDIA Jetson Orin Nano (8GB RAM)

- **Critical path:**
  1. Dataset preprocessing -> collapse 14 classes to binary
  2. Transfer learning training -> 50 epochs, fine-tune last 4 layers
  3. Export model to ONNX/TensorRT format
  4. Build TensorRT engine with target precision
  5. Profile inference time, throughput, power on Jetson

- **Design tradeoffs:**
  - FP32: Highest accuracy retention, largest model, moderate efficiency
  - FP16: Smaller model (0.41×), but paper notes underperformance on Jetson Nano due to hardware optimization limits
  - INT8: Best power reduction (0.93×), but lowest inference speed in this study due to RAM-constrained calibration
  - Binary vs. multi-class: Simpler task, higher reliability, but loses diagnostic granularity

- **Failure signatures:**
  - FP16/INT8 slower than FP32: Indicates calibration failure or hardware mismatch (observed in paper due to 8GB RAM limit)
  - High precision, low recall: Model too conservative; may need threshold adjustment or class weighting
  - Inference OOM on Jetson: Model not fully optimized; verify TensorRT engine build and batch size

- **First 3 experiments:**
  1. Replicate baseline MobileNetV2 training on SLCD with 5-fold cross-validation; log precision, recall, F1, ROC-AUC per fold.
  2. Build TensorRT engines for FP32, FP16, INT8; measure model size, inference time (ms/image), throughput (images/sec), and power draw (W) on Jetson Orin Nano.
  3. Conduct calibration sensitivity test: vary INT8 calibration dataset size (100, 500, 1000 images) and measure impact on F1-Score and inference speed.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does knowledge distillation compare to the current TensorRT quantization methods in balancing model compression ratios against diagnostic accuracy for skin cancer?
  - **Basis in paper:** [explicit] The conclusion explicitly states that future work will focus on "introducing new compression techniques, such as knowledge distillation."
  - **Why unresolved:** The current study evaluated only the TensorRT framework; the efficacy of knowledge distillation in this specific application remains untested.
  - **What evidence would resolve it:** A comparative benchmark showing model size and F1-scores for a distilled model versus the FP16/INT8 quantized models presented.

- **Open Question 2:** Is it feasible to deploy the binary classification model on microcontroller platforms like the Arduino Nano while retaining diagnostic utility?
  - **Basis in paper:** [explicit] The authors identify "expanding the use case to other platforms, such as the Arduino Nano" as a specific goal for future research.
  - **Why unresolved:** The current implementation relies on the NVIDIA Jetson Orin Nano (GPU-accelerated), and it is unclear if the model can function within the severe memory and compute constraints of a standard microcontroller.
  - **What evidence would resolve it:** Successful deployment of the model on an Arduino Nano with measurable inference latency and reported accuracy metrics.

- **Open Question 3:** Can the inference speed and throughput bottlenecks observed in INT8 and FP16 modes be mitigated through software optimization to surpass the baseline FP32 performance?
  - **Basis in paper:** [inferred] The results section notes that FP16 and INT8 models exhibited lower inference performance than FP32 due to "constrained calibration" and hardware limitations (8GB RAM).
  - **Why unresolved:** The paper identifies the hardware limitation but does not investigate if software-level adjustments (e.g., dynamic batch sizing or layer fusion tweaks) could overcome the calibration issues on the specific hardware.
  - **What evidence would resolve it:** A demonstration of optimized INT8/FP16 models achieving higher throughput than the FP32 baseline on the same Jetson Orin Nano hardware.

## Limitations

- **Hardware-specific results:** The performance gains from TensorRT optimization are validated only on NVIDIA Jetson Orin Nano with 8GB RAM. The noted underperformance of FP16 precision on this hardware suggests results may not generalize to other embedded platforms.
- **Calibration methodology gaps:** The INT8 quantization calibration process lacks detailed specification, including calibration dataset size, distribution, and quality metrics, which are critical for reproducibility.
- **Dataset provenance ambiguity:** While the Skin Lesions Classification Dataset is referenced, details about preprocessing, augmentation, and exact class consolidation rules remain unspecified.

## Confidence

- **High confidence:** Transfer learning mechanism using MobileNetV2 and its effectiveness for binary skin lesion classification (supported by multiple external studies on transfer learning in medical imaging).
- **Medium confidence:** TensorRT optimization benefits (model size reduction and power efficiency) are hardware-specific and may vary across deployment targets.
- **Low confidence:** Claims about binary classification preserving clinical utility are weakly supported, as collapsing 14 classes into two may obscure clinically relevant distinctions.

## Next Checks

1. **Hardware generalization test:** Benchmark the TensorRT-optimized model on at least two additional edge devices (e.g., Raspberry Pi, Google Coral) to assess portability of performance gains.
2. **Calibration sensitivity analysis:** Systematically vary INT8 calibration dataset size and composition, measuring F1-Score and inference latency to identify optimal calibration parameters.
3. **Multi-class ablation study:** Compare binary vs. 14-class classification performance to quantify information loss and validate clinical relevance of the binary simplification.