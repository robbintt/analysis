---
ver: rpa2
title: Integrating External Tools with Large Language Models to Improve Accuracy
arxiv_id: '2507.08034'
source_url: https://arxiv.org/abs/2507.08034
tags:
- tools
- language
- external
- llms
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Athena, a framework that integrates external\
  \ tools with large language models (LLMs) to enhance accuracy in educational settings.\
  \ The core idea is to enable LLMs to access external APIs\u2014such as calculators,\
  \ calendars, and search engines\u2014so they can handle tasks requiring up-to-date\
  \ data or computational reasoning."
---

# Integrating External Tools with Large Language Models to Improve Accuracy

## Quick Facts
- **arXiv ID:** 2507.08034
- **Source URL:** https://arxiv.org/abs/2507.08034
- **Reference count:** 22
- **Key result:** Athena achieves 83% math accuracy and 88% science accuracy on MMLU, outperforming LLaMA-Large (67%, 79%) and GPT-4o (53%, 77%).

## Executive Summary
This paper introduces Athena, a framework that integrates external tools with large language models to enhance accuracy in educational settings. The core idea is to enable LLMs to access external APIs—such as calculators, calendars, and search engines—so they can handle tasks requiring up-to-date data or computational reasoning. The framework dynamically identifies when a query needs external tools, extracts relevant parameters, and integrates the results back into the model's response. Evaluation using the MMLU dataset shows that Athena achieves 83% accuracy in mathematical reasoning and 88% in scientific reasoning, outperforming state-of-the-art models like LLaMA-Large (67% and 79%) and GPT-4o (53% and 77%). These results demonstrate that tool integration significantly improves LLM performance, especially for computation-heavy or knowledge-intensive tasks. The work highlights the value of augmenting LLMs with external tools rather than relying solely on model scaling.

## Method Summary
Athena is implemented using LangChain as middleware, hosting multiple LLMs behind a unified API. The framework integrates five external tools (Wolfram Alpha, Google SERPer, ArXiv, OpenWeatherMap, Google Calendar) registered via Pydantic schemas that specify functionality, descriptions, and parameter types. When a user query is submitted, the LLM analyzes intent via keyword matching and query complexity to determine if external tools are needed. If so, the HandleRequiredAction service extracts parameters using NLU techniques, executes the API call, and the UpdateMessage service resubmits the enriched query until the LLM can generate a complete answer. The system was evaluated on MMLU math and science subsets using accuracy on multiple-choice questions as the metric.

## Key Results
- Athena achieves 83% accuracy on mathematical reasoning questions, outperforming LLaMA-Large (67%) and GPT-4o (53%).
- On scientific reasoning, Athena reaches 88% accuracy compared to LLaMA-Large (79%) and GPT-4o (77%).
- The framework successfully handles computation-heavy queries requiring step-by-step reasoning beyond standalone LLM capabilities.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Schema-based tool registration enables LLMs to dynamically select appropriate external tools for computation-heavy queries.
- Mechanism: Tools are registered with structured schemas (name, description, argument types) that act as "blueprints" the LLM references to match tools to queries via keyword matching, intent recognition, and query complexity analysis. The RunMonitoring service parses user input and triggers tool identification when query intent aligns with registered tool capabilities.
- Core assumption: The LLM can accurately interpret tool schemas and correctly assess when its internal capabilities are insufficient for a given query type.
- Evidence anchors:
  - [abstract] "The framework dynamically identifies when a query needs external tools, extracts relevant parameters, and integrates the results back into the model's response."
  - [Section 2.1] "The decision-making process regarding when to use these tools starts with the LLM analysing the user's input... determined by keyword matching, intent recognition, or query complexity."
  - [corpus] ToolDreamer (arXiv:2510.19791) addresses tool retrieval for large toolsets, suggesting schema-based selection faces scalability limits.
- Break condition: If tool descriptions are ambiguous or query intent is unclear, tool selection may fail or trigger inappropriate tools.

### Mechanism 2
- Claim: Parameter extraction and structured API formatting enable accurate execution of external computations.
- Mechanism: The HandleRequiredAction service uses NLU techniques to map query data points to tool parameter schemas, transforms natural language inputs into API-compatible formats (e.g., city names to location codes), executes the API call, and converts raw output into conversational responses.
- Core assumption: The query contains all required parameters in extractable form, and the API returns structured, interpretable results.
- Evidence anchors:
  - [Section 2.1] "This extraction process uses natural language understanding techniques to identify and map the required data points from the query to the parameters defined in the tool's schema."
  - [Section 3.4] "The framework demonstrated strong capacity to handle diverse mathematical challenges... requiring step-by-step computational reasoning beyond what standalone LLMs could provide."
  - [corpus] Corpus evidence is weak for this specific parameter extraction mechanism; related papers focus on tool selection rather than extraction details.
- Break condition: Incomplete or ambiguous parameters in user queries lead to API call failures or incorrect results.

### Mechanism 3
- Claim: Iterative tool assessment enables multi-step reasoning for complex queries.
- Mechanism: The UpdateMessage service resubmits enriched queries to the LLM, which continuously assesses whether additional tool invocations are needed until the query is fully addressed. This loop handles problems requiring sequential computations or multiple data sources.
- Core assumption: The LLM can correctly determine when sufficient information has been gathered and avoid unnecessary additional tool calls.
- Evidence anchors:
  - [Section 2.1] "This entire process is iterative; the LLM continuously assesses whether additional information from external tools is needed to fully address the user's query."
  - [Section 3.4] "Athena's success was particularly evident in questions requiring numerical calculations combined with theoretical knowledge."
  - [corpus] Toward Effective Tool-Integrated Reasoning (arXiv:2509.23285) notes TIR models can display "insufficient or excessive tool usage," indicating iterative control is non-trivial.
- Break condition: Over-iteration wastes resources; under-iteration produces incomplete answers.

## Foundational Learning

- Concept: **API schema design (Pydantic/JSON schemas)**
  - Why needed here: Tools are registered via schemas that specify functionality, descriptions, and parameter types. Without understanding schema definition, you cannot add new tools or debug tool selection failures.
  - Quick check question: Can you write a Pydantic schema for a tool that takes a date range and returns calendar events?

- Concept: **LangChain tool abstraction patterns**
  - Why needed here: The implementation uses LangChain as middleware to abstract tool integration complexity. Understanding how LangChain handles tool binding, execution, and response integration is essential for extending the framework.
  - Quick check question: What is the difference between LangChain's `@tool` decorator and manually defining a StructuredTool?

- Concept: **LLM tool-calling behavior and tool token overhead**
  - Why needed here: Tool schemas consume context window tokens; large tool registries may exceed limits. The paper uses ~5 tools, but scaling requires understanding token budgets and retrieval strategies.
  - Quick check question: If each tool schema consumes ~200 tokens and your context window is 8K, what is your practical upper bound on registered tools?

## Architecture Onboarding

- Component map: ExternalServiceIntegrator -> MessageSubmission -> RunMonitoring -> HandleRequiredAction -> External API -> UpdateMessage -> LLM response
- Critical path: User query → MessageSubmission → LLM analysis (RunMonitoring detects tool need) → HandleRequiredAction extracts params → External API call → Result formatting → UpdateMessage resubmits enriched context → LLM generates final response
- Design tradeoffs:
  - **LangChain abstraction vs. custom orchestration**: LangChain reduces implementation complexity but limits fine-grained control over tool selection logic
  - **Iterative vs. single-pass tool calls**: Iteration handles complex queries but increases latency and API costs
  - **Schema verbosity vs. LLM comprehension**: Detailed schemas improve tool selection accuracy but consume more context tokens
- Failure signatures:
  - Tool not triggered when needed → Check schema descriptions for keyword coverage; verify RunMonitoring detection logic
  - API call fails with malformed parameters → Inspect parameter extraction logs; validate schema-to-API format transformation
  - Infinite iteration loop → Review LLM stopping conditions; add max-iteration guardrails
  - Context window overflow → Reduce registered tools; implement tool retrieval instead of full registration
- First 3 experiments:
  1. Reproduce the MMLU math/science evaluation with a single baseline LLM (e.g., GPT-3.5) and Athena configuration to validate the 16-9 percentage point improvement claims on a small subset (20 questions each).
  2. Ablate individual tools (remove Wolfram Alpha only, remove SERPer only) to isolate which tools contribute most to math vs. science accuracy gains.
  3. Stress-test the iterative loop: construct queries requiring 3+ sequential tool calls and measure whether the framework correctly terminates vs. over-iterates.

## Open Questions the Paper Calls Out
- How can the accuracy and robustness of the automatic tool selection mechanism be improved to handle ambiguous or multi-intent queries?
- What is the marginal contribution of each integrated tool (Wolfram Alpha, SERPer, ArXiv, etc.) to the overall performance improvement?
- How does Athena compare against LLMs with native tool-use capabilities (e.g., GPT-4 with function calling) rather than standalone baseline models?

## Limitations
- The exact LLM backing Athena is not specified, only that it runs on the Unify platform with multiple models available.
- The evaluation scope is limited to MMLU math and science subsets, with no validation across diverse domains or handling of ambiguous queries.
- The schema-based tool selection mechanism faces scalability concerns with large tool registries, though this wasn't tested.

## Confidence
- **High confidence** in the 16-9 percentage point accuracy improvements over LLaMA-Large and GPT-4o on MMLU math/science subsets, as the evaluation protocol is clearly specified and reproducible.
- **Medium confidence** in the mechanism explanations, particularly parameter extraction and iterative tool assessment, as these are described but lack detailed empirical validation or error analysis.
- **Low confidence** in scalability claims—the framework's performance with large tool registries, under context window constraints, or with complex multi-hop reasoning remains unproven.

## Next Checks
1. Reproduce MMLU evaluation with a baseline LLM (e.g., GPT-3.5) and Athena configuration to validate the 16-9 percentage point improvement claims on a small subset (20 questions each), controlling for model-specific effects.
2. Ablate individual tools to isolate contributions—remove Wolfram Alpha only, remove SERPer only—to determine which tools drive math vs. science accuracy gains and whether the framework suffers from over-instrumentation.
3. Stress-test iterative tool calls by constructing queries requiring 3+ sequential tool invocations and measuring whether the framework correctly terminates versus over-iterating, including latency and API cost analysis.