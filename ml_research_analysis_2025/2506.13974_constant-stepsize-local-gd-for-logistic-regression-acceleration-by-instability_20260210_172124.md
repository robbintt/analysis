---
ver: rpa2
title: 'Constant Stepsize Local GD for Logistic Regression: Acceleration by Instability'
arxiv_id: '2506.13974'
source_url: https://arxiv.org/abs/2506.13974
tags:
- local
- lemma
- logistic
- regression
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper analyzes Local Gradient Descent (Local GD) for logistic\
  \ regression with separable, heterogeneous data, addressing the open question of\
  \ whether large step sizes (\u03B7 \u226B 1/K) can accelerate convergence. Unlike\
  \ prior worst-case analyses requiring \u03B7 \u2264 O(1/K) for monotonic decrease,\
  \ the authors prove convergence for any \u03B7 0 and K \u2265 1, identifying an\
  \ initial unstable phase followed by a stable phase with monotonic decrease."
---

# Constant Stepsize Local GD for Logistic Regression: Acceleration by Instability

## Quick Facts
- arXiv ID: 2506.13974
- Source URL: https://arxiv.org/abs/2506.13974
- Reference count: 40
- Large step sizes (η ≫ 1/K) can accelerate Local GD convergence for logistic regression

## Executive Summary
This paper challenges the conventional wisdom that small step sizes are necessary for Local Gradient Descent (Local GD) convergence in federated learning. The authors prove that Local GD with constant stepsize η > 0 and K local steps converges for any K ≥ 1, contrary to prior worst-case analyses requiring η ≤ O(1/K). The key insight is that instability in early iterations is beneficial, enabling faster convergence through an initial unstable phase followed by a stable phase with monotonic decrease. For logistic regression with separable, heterogeneous data, the optimal scaling ηK = Θ(γ³R/M) achieves an improved convergence rate of O(M/(γ⁵R²)), demonstrating that large stepsizes can accelerate federated learning beyond what centralized gradient descent achieves.

## Method Summary
The paper analyzes Local GD for binary logistic regression with separable, heterogeneous data across M clients. Each client maintains a local model and performs K gradient steps with constant stepsize η before averaging with other clients' models. The objective is the average logistic loss across all clients, where each client's loss is the average negative log-likelihood of their local data. The authors prove convergence for any η > 0 and K ≥ 1 by tracking individual data point contributions through local updates, relating Local GD's trajectory to centralized GD. The key theoretical result shows that choosing ηK proportional to γ³R/M (where γ is the margin parameter and R is the number of rounds) yields the improved convergence rate, effectively leveraging the instability phase to accelerate overall convergence.

## Key Results
- Proves convergence for Local GD with any η > 0 and K ≥ 1, challenging prior worst-case analysis requiring η ≤ O(1/K)
- Identifies beneficial instability phase in early iterations that accelerates convergence
- Shows optimal scaling ηK = Θ(γ³R/M) achieves O(M/(γ⁵R²)) rate, improving upon O(1/R) bounds for general convex objectives
- Experiments confirm larger η and K accelerate convergence despite initial instability

## Why This Works (Mechanism)
The paper's mechanism centers on exploiting instability in early iterations. Unlike previous analyses that required monotonic decrease and small stepsizes, this work shows that an initial unstable phase is not only tolerable but beneficial. The algorithm first undergoes an unstable phase where the loss may increase, but this allows the iterates to move more aggressively toward the solution. Once the iterates enter the stable phase, they exhibit monotonic decrease. The key insight is that the unstable phase enables faster progress overall, and the analysis tracks individual data point contributions to rigorously prove this behavior. The optimal stepsize scaling ηK = Θ(γ³R/M) balances the need for aggressive early progress with eventual stability.

## Foundational Learning
- **Logistic regression with separable data**: Binary classification where data can be perfectly separated by a linear classifier; needed because margin parameters enable sharper convergence analysis.
- **Local GD algorithm**: Each client performs K local gradient steps before synchronization; needed to understand the interplay between local computation and communication.
- **Heterogeneous data assumption**: Clients have different data distributions; needed because real federated learning involves non-IID data across clients.
- **Margin parameter γ**: Minimum distance from data points to decision boundary; needed for deriving improved convergence rates specific to separable data.
- **Instability analysis**: Tracking behavior when loss may increase temporarily; needed to prove convergence despite non-monotonic early behavior.
- **Individual data point tracking**: Analyzing contribution of each data point through iterations; needed to relate Local GD trajectory to centralized GD.

## Architecture Onboarding
- **Component map**: Synthetic/MNIST data generation -> Local GD implementation -> Training loop with varying η/K -> Loss tracking and visualization
- **Critical path**: Data preparation → Model initialization → Local GD iterations → Loss computation → Convergence analysis
- **Design tradeoffs**: Large η enables faster initial progress but risks divergence; local steps K reduce communication but may slow convergence if too large
- **Failure signatures**: Divergence with large η (expected behavior); non-monotonic loss spikes in early rounds (normal during unstable phase)
- **First experiments**:
  1. Run Local GD with η=64, K=1 on MNIST to observe divergence behavior
  2. Run with η=16, K=4 on MNIST to observe accelerated convergence after initial instability
  3. Run with η=4, K=16 on MNIST to verify optimal ηK scaling

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis relies on strong assumptions about data separability and heterogeneity that may not hold in practical settings
- Convergence guarantees are specific to logistic regression and may not extend to other convex or non-convex objectives
- Relationship between step size η and local steps K is characterized only for certain ranges, leaving open questions about optimal hyperparameter selection

## Confidence
- High confidence: Empirical validation showing accelerated convergence with larger η and K on synthetic and MNIST datasets
- Medium confidence: Theoretical convergence bounds for ηK = Θ(γ³R/M) yielding O(M/(γ⁵R²)) rate
- Low confidence: Claims about matching or exceeding GD's performance remain unproven

## Next Checks
1. Test convergence behavior on more diverse datasets beyond MNIST to assess generalizability of ηK scaling rules
2. Compare Local GD performance against other federated learning algorithms (e.g., FedAvg, FedProx) to quantify practical advantages
3. Extend theoretical analysis to non-separable or non-heterogeneous data settings to identify limitations of current convergence guarantees