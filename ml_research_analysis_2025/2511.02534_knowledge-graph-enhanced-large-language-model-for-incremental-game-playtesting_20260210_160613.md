---
ver: rpa2
title: Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting
arxiv_id: '2511.02534'
source_url: https://arxiv.org/abs/2511.02534
tags:
- game
- testing
- update
- knowledge
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces KLPEG, a knowledge graph-enhanced LLM framework
  designed to address the challenge of efficient testing for incremental game updates.
  The core method constructs and maintains a knowledge graph to model game elements,
  dependencies, and causal relationships, enabling knowledge reuse across versions.
---

# Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting

## Quick Facts
- arXiv ID: 2511.02534
- Source URL: https://arxiv.org/abs/2511.02534
- Reference count: 22
- Primary result: KLPEG achieves 100% coverage of update-related elements and perfect bug detection ratio while requiring far fewer test steps than traditional RL-based methods.

## Executive Summary
This paper introduces KLPEG, a knowledge graph-enhanced large language model framework designed to address the challenge of efficient testing for incremental game updates. The core innovation constructs and maintains a knowledge graph to model game elements, dependencies, and causal relationships, enabling knowledge reuse across versions. LLMs parse natural language update logs to identify impacted game elements through multi-hop reasoning on the KG, and then generate targeted test cases. Evaluated in Overcooked and Minecraft environments, KLPEG demonstrates significant improvements in coverage, efficiency, and bug detection compared to traditional RL-based playtesting methods.

## Method Summary
KLPEG operates through a four-stage pipeline: (1) A curiosity-driven PPO agent explores the game environment to collect action-state trajectories from game execution logs; (2) Knowledge triples are extracted from these logs using LLM, script-based, and rule-based extractors to construct a knowledge graph with nodes representing game elements and edges representing dependencies and causal relationships; (3) Natural language update logs are parsed by an LLM, synchronized to the knowledge graph, and bounded multi-hop traversal (K hops) is performed to infer the scope of impacted elements; (4) Test cases are generated via LLM using KG-guided prompts, focusing on elements within the inferred impact scope. The framework is evaluated on Overcooked and Minecraft environments with rewards configured for key component collection and task completion.

## Key Results
- Achieved 100% coverage of update-related elements compared to baselines (50-63%)
- Generated test cases with 90% interaction focus on relevant elements versus 50-63% for baselines
- Perfect bug detection ratio (1.00) with significantly fewer test steps (6-10 vs. 21-96) and faster completion times than traditional RL-based methods

## Why This Works (Mechanism)
The knowledge graph serves as a persistent memory structure that captures the game's evolving state space and dependencies. When updates occur, the KG enables efficient reasoning about which elements are affected through multi-hop traversal, rather than requiring full game exploration. The LLM acts as both a semantic parser (converting natural language updates into KG updates) and a test case generator (producing targeted action sequences based on KG-guided prompts). This combination allows the system to focus testing resources on the most relevant game regions while maintaining awareness of broader game structure.

## Foundational Learning

**Knowledge Graph Construction**: Representing game state as a graph of elements and relationships. Why needed: Provides persistent memory and enables efficient reasoning about dependencies. Quick check: Can you manually trace a multi-hop path from one game element to another?

**Multi-hop Reasoning**: Bounded traversal of the KG to infer impact scope. Why needed: Determines which game regions need testing after an update. Quick check: Given a small KG, can you identify all elements within K hops of an updated node?

**LLM as Semantic Parser**: Converting natural language updates into structured KG updates. Why needed: Bridges human-readable changelists to machine-actionable knowledge. Quick check: Can you write a prompt that extracts triples from a simple update log?

**Curiosity-driven Exploration**: RL agent exploration strategy for KG construction. Why needed: Ensures comprehensive coverage of game mechanics for initial KG building. Quick check: Can you explain how curiosity bonuses differ from standard reward shaping?

## Architecture Onboarding

**Component Map**: Game Execution Logs -> Curiosity-driven PPO Agent -> Action-State Trajectories -> KG Extractors -> Knowledge Graph -> Natural Language Update Logs -> LLM Parser -> KG Updater -> Impact Inference (Multi-hop Traversal) -> Test Case Generator (LLM) -> Test Execution

**Critical Path**: Update Log Parsing -> KG Update -> Impact Scope Inference -> Test Case Generation -> Test Execution

**Design Tradeoffs**: KG construction overhead vs. testing efficiency gains; LLM prompt complexity vs. reasoning accuracy; multi-hop threshold K vs. computational cost.

**Failure Signatures**: Incomplete KG coverage leading to missed impact inference; ambiguous update logs causing incorrect impact scope; synthetic bug injection methodology limitations.

**First Experiments**:
1. Implement KG extractors and validate triple extraction rates on sample game logs
2. Test multi-hop traversal accuracy on a manually constructed KG with known dependencies
3. Evaluate LLM prompt effectiveness for converting natural language updates into KG updates

## Open Questions the Paper Calls Out

**Scalability to Large Games**: Can graph partitioning, hierarchical representations, or graph databases enable KLPEG to scale efficiently to large open-world RPGs or MMORPGs with significantly more nodes and relations? Current experiments only cover Overcooked and Minecraft; scalability to much larger games remains untested.

**Expanded KG Modeling Scope**: How can the KG modeling scope be expanded to capture UI logic, implicit gameplay rules, and environment-triggered events for more comprehensive testing? Current KG schema focuses on core mechanics and cannot represent non-symbolic or event-driven game aspects.

**Indirect Regression Bug Detection**: What sampling strategies or integration methods could enable KLPEG to detect indirect regression bugs in legacy game regions outside the immediate update scope? The current design prioritizes update-specific regions; systematic detection of cross-region regressions has not been implemented.

## Limitations

- Evaluation relies heavily on synthetic bug injection and controlled update scenarios in simplified game environments
- Knowledge graph construction assumes perfect extraction from game logs with no analysis of extraction error rates
- Multi-hop reasoning effectiveness is bounded by assumed K-hop threshold, which may not scale to games with deeper dependency chains

## Confidence

**High Confidence**: Claims about computational efficiency (test steps and time comparisons) are directly supported by measured results in controlled experiments.

**Medium Confidence**: Element coverage and interaction focus metrics are convincing within the tested environments but may not generalize to more complex games or real-world update scenarios.

**Low Confidence**: The perfect bug detection ratio (1.00) achieved through synthetic bug injection may not reflect real-world performance, as the methodology for bug injection is not fully specified.

## Next Checks

1. Implement error analysis on the knowledge graph extraction pipeline to quantify false positives/negatives in triple extraction from game logs
2. Test the framework on a more complex game environment with longer dependency chains to evaluate multi-hop reasoning scalability
3. Conduct ablation studies removing the knowledge graph component to isolate its specific contribution to test generation performance