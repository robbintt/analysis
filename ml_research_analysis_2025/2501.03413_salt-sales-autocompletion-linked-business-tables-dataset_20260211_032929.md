---
ver: rpa2
title: 'SALT: Sales Autocompletion Linked Business Tables Dataset'
arxiv_id: '2501.03413'
source_url: https://arxiv.org/abs/2501.03413
tags:
- data
- categorical
- sales
- salesdocument
- salesdocumentitem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SALT, a novel dataset for table representation
  learning derived from real-world enterprise sales data. SALT contains four interconnected
  relational tables with millions of rows sourced from an ERP system, capturing the
  complexity of linked business tables prevalent in enterprise environments.
---

# SALT: Sales Autocompletion Linked Business Tables Dataset

## Quick Facts
- arXiv ID: 2501.03413
- Source URL: https://arxiv.org/abs/2501.03413
- Reference count: 40
- Primary result: Novel enterprise dataset with 4 linked tables and 21 input variables for 8 target prediction tasks, achieving MRR up to 0.99 with tree-based models

## Executive Summary
This paper introduces SALT, a novel dataset for table representation learning derived from real-world enterprise sales data. SALT contains four interconnected relational tables with millions of rows sourced from an ERP system, capturing the complexity of linked business tables prevalent in enterprise environments. The dataset includes 21 input variables and 8 target variables for predicting missing fields in sales orders, with tasks ranging from multiclass classification to handling high cardinality and class imbalance issues. Experiments with baseline models show that most tabular models can effectively manage the prediction tasks, with CARTE achieving the best performance with a mean reciprocal rank of 0.99 for most targets. The authors plan to enhance the dataset's complexity by including additional tables and scenarios in future work.

## Method Summary
The dataset is constructed from four linked ERP tables (SalesDocument, SalesDocumentItem, Customer, Address) containing 500,908 sales documents, 2,319,944 items, 139,611 customers, and 1,788,887 addresses. Data spans January 2018 to December 2020 and is temporally split into training (pre-February 2020), validation (February-July 2020), and test (post-July 2020) sets. The tables are flattened through SQL joins to create one row per sales order item, with 21 input variables and 8 target variables for prediction. Preprocessing involves filling missing categorical values with a constant and numerical values with the mean, with date/time features removed after splitting. Eight classification targets are evaluated using Mean Reciprocal Rank (MRR), with baselines including random/majority predictions, tree-based models (XGBoost, LightGBM, CatBoost), deep learning approaches (CARTE, AutoGluon), and GraphSAGE for multi-table native processing.

## Key Results
- CARTE achieves best average MRR of 0.79 across all targets
- Plant and SalesOffice targets achieve near-ceiling performance (MRR ≈ 0.99) due to business process regularity
- High cardinality targets like SalesGroup show lower performance (MRR ≈ 0.46) due to class imbalance
- Tree-based models outperform neural approaches on this tabular dataset

## Why This Works (Mechanism)

### Mechanism 1: Relational Context Encoding via Foreign Key Joins
Linking multiple tables through foreign keys provides predictive signal that single-table approaches cannot capture. The dataset joins four tables (SalesDocument → SalesDocumentItem → Customer → Address) such that each prediction row incorporates header-level sales order context, item-level details, and customer master data simultaneously. This denormalization exposes cross-entity patterns—for example, a customer's country may correlate with specific Incoterms or ShippingConditions.

### Mechanism 2: Business Process Regularity Enables High Predictability for Certain Targets
Some target variables are highly predictable (MRR ~0.99) because enterprise sales processes follow constrained business rules. Targets like Plant and SalesOffice achieve near-ceiling performance because they are often deterministically assigned based on organizational structure, product-location mappings, or distribution chain configurations.

### Mechanism 3: Tree-Based Ensemble Models Capture Categorical Interactions Without Extensive Preprocessing
Gradient-boosted decision trees (especially CARTE, XGBoost, AutoGluon) outperform neural baselines on this task because they handle high-cardinality categoricals and missing values natively. The dataset contains categorical features with high cardinality (Product: 187,562 unique values) and moderate missingness. Tree ensembles split on categorical values directly, while neural approaches require embedding layers or extensive encoding.

## Foundational Learning

- **Foreign Key Relationships and Denormalization**: Why needed here: The dataset is explicitly constructed by joining four normalized tables; understanding how SalesDocument → SalesDocumentItem → Customer → Address link is essential for feature engineering. Quick check: Can you explain why Address.Region has 80.11% missing values after the join, and which table's sparsity causes this?

- **Class Imbalance and Long-Tail Distributions**: Why needed here: Two sales offices cover 99% of orders; models may achieve high accuracy by predicting the majority class while failing on the long tail (39 other offices). Quick check: Why does the Majority Class Baseline achieve 0.99 MRR on SalesOffice but only 0.05 on SalesGroup?

- **Mean Reciprocal Rank (MRR) for Multiclass Classification**: Why needed here: The paper reports MRR rather than accuracy or F1; this metric evaluates whether the correct class appears near the top of a ranked list, which is appropriate for autocompletion scenarios. Quick check: If a model ranks the correct SalesGroup as its 5th prediction out of 589 classes, what contribution does this make to MRR?

## Architecture Onboarding

- **Component map**: SalesDocument → SalesDocumentItem → Customer → Address → Flattened table → Prediction models
- **Critical path**: Load four tables → Apply filters → Execute 10-way join → Fill missing values → Temporal split → Train baselines
- **Design tradeoffs**: Flattened vs. multi-table modeling (flattened for most baselines; GraphSAGE underperforms), Temporal vs. random split (temporal tests future generalization but may suffer from data drift)
- **Failure signatures**: SalesGroup prediction failure due to high cardinality (589 classes), Region features limited by 80.11% missingness, data drift affecting category definitions
- **First 3 experiments**: 1) Reproduce Majority Class Baseline to confirm class imbalance, 2) Train XGBoost to verify Plant MRR ≈ 0.99, 3) Ablate address features to measure their contribution

## Open Questions the Paper Calls Out

- **Cross-domain generalization**: How does inclusion of data from multiple companies and broader scenarios affect model generalization and robustness? The current dataset is from a single enterprise source; future work plans to expand to multi-company data.

- **High cardinality prediction**: What modeling strategies are required to effectively predict targets like SalesGroup with 589 classes where current baselines perform poorly? The paper identifies this as a challenge but does not propose solutions.

- **Temporal data drift impact**: How does the temporal evolution of input categorizations impact model stability when using temporal validation splits? The authors note this may particularly impact analyses involving temporal splits but do not quantify the effect.

## Limitations
- Extreme class imbalance may inflate performance metrics while masking poor generalization on long-tail classes
- Incomplete preprocessing details (exact constant for categorical imputation, random seeds) limit reproducibility
- High missingness in Region fields (80.11%) limits utility of geographic features
- Data drift between training and test periods may affect target predictability

## Confidence
- **High confidence**: Dataset construction methodology, temporal split procedure, finding that tree-based models outperform neural approaches, observation that certain targets achieve near-ceiling performance
- **Medium confidence**: Relative ranking of baseline model performance, claim that SALT is first dataset focused on sales order autocompletion in enterprise settings
- **Low confidence**: Extent to which results generalize to other domains or different temporal periods, impact of data drift on target predictability, exact flattened table structure across database systems

## Next Checks
1. Verify class distribution and baseline performance by reproducing Majority Class Baseline results to confirm extreme class imbalance
2. Test robustness to temporal drift by training on pre-2019 data only and testing on 2020 data
3. Analyze missingness impact by training models with and without address features to measure their contribution given 80.11% missingness in Region fields