---
ver: rpa2
title: 'MammoRGB: Dual-View Mammogram Synthesis Using Denoising Diffusion Probabilistic
  Models'
arxiv_id: '2511.22759'
source_url: https://arxiv.org/abs/2511.22759
tags:
- mammograms
- synthetic
- real
- images
- channel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents MammoRGB, a denoising diffusion probabilistic
  model (DDPM) for synthesizing dual-view mammograms (craniocaudal and mediolateral
  oblique views). The model encodes both views in a three-channel RGB representation,
  where the red channel represents the CC view, the green channel the MLO view, and
  the blue channel encodes additional information via sum, absolute difference, or
  zero encoding.
---

# MammoRGB: Dual-View Mammogram Synthesis Using Denoising Diffusion Probabilistic Models

## Quick Facts
- arXiv ID: 2511.22759
- Source URL: https://arxiv.org/abs/2511.22759
- Reference count: 0
- One-line primary result: MammoRGB generates anatomically consistent dual-view mammograms with distribution similarity comparable to real data.

## Executive Summary
This study presents MammoRGB, a denoising diffusion probabilistic model (DDPM) for synthesizing anatomically consistent dual-view mammograms. The model encodes craniocaudal (CC) and mediolateral oblique (MLO) views into a three-channel RGB representation, with the blue channel encoding additional cross-view information. Trained on 11,020 screening mammograms, the model generates synthetic pairs evaluated for breast mask overlap and distributional similarity against 2,500 real images. Results show synthetic images achieve IoU and DSC distributions comparable to real data, with low Earth Mover's Distance and Kolmogorov-Smirnov test values. The approach demonstrates the feasibility of generating paired mammograms for potential medical imaging augmentation.

## Method Summary
MammoRGB is a DDPM fine-tuned from `google/ddpm-celebahq-256` to generate dual-view mammograms. The model encodes paired CC and MLO mammograms into a three-channel RGB image (red=CC, green=MLO, blue=combination of views). Training used 11,020 screening mammograms (BI-RADS 2 only, no implants) with preprocessing including normalization, mirroring left views, and histogram matching to RSNA 2023 Challenge reference CDF. The model was fine-tuned for 100 epochs with batch size 16 and learning rate 1e-5. Evaluation compared breast mask overlap (IoU, DSC) and distribution similarity (EMD, KS tests) between 500 synthetic pairs per variant and 2,500 real pairs.

## Key Results
- Synthetic images achieved IoU and DSC distributions comparable to real data with median IoU ≈ 0.84
- Models using sum or absolute difference encodings in the blue channel outperformed zero-channel encoding
- Distributional similarity metrics showed low EMD (0.020) and KS (0.077) values between real and synthetic pairs
- Cross-view consistency was maintained with 6-8% artifact rate consistent with training data limitations

## Why This Works (Mechanism)
The DDPM framework iteratively denoises Gaussian noise into realistic mammograms by learning the reverse of a forward noising process. The three-channel RGB encoding captures anatomical relationships between CC and MLO views, with the blue channel providing auxiliary cross-view information that improves consistency. The U-Net architecture predicts and removes noise at each timestep, while the histogram-matching preprocessing ensures consistent intensity distributions across the dataset. The combination of structural encoding and iterative denoising enables generation of anatomically coherent dual-view pairs.

## Foundational Learning
- Concept: Denoising Diffusion Probabilistic Models (DDPM)
  - Why needed here: Core generative engine that iteratively denoises Gaussian noise into realistic mammograms
  - Quick check question: Can you explain, in one sentence, how a DDPM generates an image starting from random noise?

- Concept: Intersection over Union (IoU) and Dice Similarity Coefficient (DSC)
  - Why needed here: Quantitative metrics for assessing anatomical consistency between generated CC and MLO breast masks
  - Quick check question: Given two binary masks, how would you compute their IoU?

- Concept: Earth Mover's Distance (EMD) and Kolmogorov-Smirnov (KS) Test
  - Why needed here: Statistical measures comparing distributions of IoU/DSC metrics between real and synthetic mammograms
  - Quick check question: What does a low EMD value indicate about two distributions?

## Architecture Onboarding
- Component map: Input encoding (CC/MLO preprocessing → RGB encoding) → DDPM fine-tuning (U-Net noise prediction) → Synthetic image generation (iterative denoising) → View extraction (red/green channels) → Metric computation (IoU/DSC, EMD, KS)

- Critical path: Input encoding → Model fine-tuning → Synthetic image generation → View extraction → Metric computation

- Design tradeoffs:
  - Third-channel encoding: Sum/difference provides auxiliary cross-view information but may introduce artifacts; zero-channel is simpler but performs worse
  - Learning rate: Lower LR (1e-5) yields more stable training but may require more epochs; higher LR (1e-4) is faster but less stable
  - Image resolution: Training at 256×256 reduces computational cost but may limit fine-detail capture compared to higher resolutions

- Failure signatures:
  - Cross-view artifacts: Visible inconsistencies between generated CC and MLO views (e.g., mismatched breast size or shape)
  - Mode collapse: Limited diversity in generated samples, indicating overfitting or insufficient training data variety
  - Training divergence: Loss fails to decrease, often due to inappropriate learning rate or data preprocessing issues

- First 3 experiments:
  1. Reproduce the third-channel comparison: Train three models (sum, absolute difference, zero) and compare their IoU/DSC distributions against a holdout set of real mammograms
  2. Learning rate sweep: Fine-tune the model with LRs of 1e-4, 5e-5, and 1e-5, tracking training stability and qualitative image quality over epochs
  3. Artifact analysis: Visually inspect a random sample of generated images for cross-view artifacts and correlate findings with training data preprocessing steps to identify potential sources

## Open Questions the Paper Calls Out
- Future work includes testing synthetic images in deep learning classification/detection tasks to assess data augmentation utility
- The study will explore stable diffusion pipelines for conditional generation to improve anatomical fidelity and reduce artifacts
- Alternative preprocessing strategies could reduce or eliminate preprocessing-related artifacts present in both training and synthetic mammograms
- Assessment of anatomical consistency was limited to masking-based methods without exploring other internal anatomical metrics

## Limitations
- Private dataset restricts independent validation and requires substitute datasets for reproduction
- Evaluation focused on structural consistency (breast masks) rather than lesion realism or internal anatomical correspondence
- Artifacts present in synthetic images trace to training data preprocessing rather than model hallucinations
- No assessment of clinical utility or performance in downstream AI tasks

## Confidence
- Anatomical consistency claims: High (robust quantitative and qualitative evidence)
- Cross-view alignment via RGB encoding: Medium (no lesion-level detail assessment)
- Distribution similarity to real data: High (multiple metrics support comparability)
- Clinical utility: Low (not evaluated; only structural realism demonstrated)

## Next Checks
1. Cross-view artifact analysis: Inspect 100 random synthetic pairs for anatomical mismatches (e.g., breast size, position) and correlate with encoding variant performance
2. Distribution comparison validation: Apply EMD and KS tests to IoU/DSC metrics between real and synthetic mammograms to confirm distributional similarity
3. Preprocessing impact test: Vary histogram-matching parameters or remove left-view mirroring to assess effects on cross-view consistency and artifact generation