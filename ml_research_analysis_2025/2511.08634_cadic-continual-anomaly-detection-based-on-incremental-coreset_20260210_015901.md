---
ver: rpa2
title: 'CADIC: Continual Anomaly Detection Based on Incremental Coreset'
arxiv_id: '2511.08634'
source_url: https://arxiv.org/abs/2511.08634
tags:
- anomaly
- tasks
- detection
- learning
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CADIC, a novel continual anomaly detection
  method that incrementally updates a shared memory bank with embeddings from sequential
  tasks. Unlike prior approaches that require class-specific memory banks, CADIC employs
  a unified coreset updated via a nearest-neighbor-based replacement mechanism, enabling
  efficient, flexible knowledge acquisition without catastrophic forgetting.
---

# CADIC: Continual Anomaly Detection Based on Incremental Coreset
## Quick Facts
- arXiv ID: 2511.08634
- Source URL: https://arxiv.org/abs/2511.08634
- Authors: Gen Yang; Zhipeng Deng; Junfeng Man
- Reference count: 40
- Primary result: State-of-the-art continual anomaly detection with 0.972 AUROC on MVTec AD

## Executive Summary
CADIC introduces a continual anomaly detection framework that uses an incremental coreset approach to maintain a unified memory bank across sequential tasks. Unlike prior methods requiring separate memory banks per class, CADIC employs a nearest-neighbor-based replacement mechanism to efficiently update a shared coreset. The method demonstrates strong performance on standard benchmarks and achieves 100% accuracy on a real-world electronic paper dataset, showing promise for industrial deployment.

## Method Summary
CADIC builds on continual learning principles to address anomaly detection in streaming data scenarios. The core innovation is an incremental coreset that maintains a representative subset of embeddings across all observed tasks. When processing new tasks, the method evaluates each new embedding against the existing coreset and selectively replaces entries using a nearest-neighbor criterion. This approach avoids catastrophic forgetting while maintaining computational efficiency compared to storing all historical data. The unified memory structure allows flexible knowledge acquisition without requiring task-specific memory banks.

## Key Results
- Achieves 0.972 average image-level AUROC on MVTec AD dataset
- Achieves 0.891 average image-level AUROC on VisA dataset
- Attains 100% accuracy on real-world electronic paper dataset

## Why This Works (Mechanism)
CADIC's effectiveness stems from maintaining a representative memory of previously seen normal patterns while efficiently incorporating new information. The nearest-neighbor-based replacement ensures that the coreset remains diverse and relevant across all tasks. By avoiding task-specific memory banks, the method reduces redundancy and improves generalization. The incremental nature allows the system to adapt to concept drift without requiring complete retraining, making it suitable for real-world deployment where data distributions evolve over time.

## Foundational Learning
- **Continual Learning**: Why needed - prevents catastrophic forgetting when learning sequential tasks; Quick check - model maintains performance on earlier tasks after training on new ones
- **Anomaly Detection**: Why needed - identifies deviations from normal patterns in industrial settings; Quick check - detection accuracy on known anomalies vs. normal samples
- **Coreset Selection**: Why needed - maintains representative subset without storing all data; Quick check - diversity and coverage of selected embeddings
- **Nearest Neighbor Search**: Why needed - efficient similarity comparison for replacement decisions; Quick check - computational time scales reasonably with coreset size
- **Euclidean Distance Calculation**: Why needed - measures similarity between embeddings for coreset updates; Quick check - distance distributions remain stable across tasks

## Architecture Onboarding
- **Component Map**: Input Embeddings -> Coreset Manager -> Memory Bank -> Anomaly Detector -> Output
- **Critical Path**: New embeddings are processed through similarity comparison with coreset, followed by selective replacement decisions, then used for anomaly scoring
- **Design Tradeoffs**: Fixed coreset size vs. dynamic allocation; computational efficiency vs. representation quality; unified memory vs. task-specific separation
- **Failure Signatures**: Degraded performance on early tasks indicates catastrophic forgetting; poor detection rates suggest insufficient coreset diversity; high computational costs indicate scaling issues
- **First Experiments**: 1) Test AUROC on MVTec AD with varying coreset sizes, 2) Measure forgetting on sequential tasks, 3) Evaluate computational time per image update

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What specific efficient updating strategies can mitigate the high computational cost of iterative Euclidean distance calculations in large-scale memory banks?
- Basis in paper: [explicit] The Conclusion states, "The overall computation costs is high for large-scale memory banks. Therefore, we will investigate more efficient updating strategies to accelerate the memory bank updating processes."
- Why unresolved: The current greedy replacement mechanism requires frequent matrix operations (Eq. 7) that scale poorly as the coreset size increases to 20,000 or more.
- What evidence would resolve it: A modified algorithm (e.g., using approximate nearest neighbors) that maintains comparable AUROC scores while significantly reducing training time per image compared to the current implementation.

### Open Question 2
- Question: Can the fixed coreset size constraint be replaced with a dynamic allocation mechanism to better accommodate varying task complexities?
- Basis in paper: [inferred] The ablation study (Table VII) highlights a trade-off between fixed sizes, and the analysis notes that categories like "hazelnut" require significantly more features (1,839) than "grid" (21).
- Why unresolved: The current method imposes a static memory budget (e.g., 10,000), which may under-allocate memory for complex structural tasks while over-allocating for simple texture tasks.
- What evidence would resolve it: A variable-sized coreset approach that adapts storage capacity based on intra-class variance, achieving higher average detection metrics without increasing the total average memory footprint.

### Open Question 3
- Question: How does CADIC perform under non-alphabetical or adversarial task orderings compared to the standard sequential benchmarks?
- Basis in paper: [inferred] The experiments utilize a fixed alphabetical task order (Section IV), whereas the Introduction emphasizes real-world scenarios involving dynamic data distributions and concept drift.
- Why unresolved: Continual learning methods are often sensitive to the order of task acquisition; the current results may not reflect stability in "worst-case" or random sequences typical in industrial deployment.
- What evidence would resolve it: Evaluation of the Forgetting Measure (FM) and AUROC across multiple randomized task permutations on the MVTec AD and VisA datasets.

## Limitations
- High computational costs for large-scale memory banks due to iterative distance calculations
- Fixed coreset size may not optimally accommodate varying task complexities
- Limited evaluation of performance under non-standard task orderings
- Results primarily validated on two specific datasets without broader domain testing

## Confidence
- **High Confidence**: The unified coreset approach for continual anomaly detection is theoretically sound and builds on established continual learning principles
- **Medium Confidence**: Performance metrics are promising but require validation on more diverse datasets and real-world scenarios
- **Low Confidence**: Claims about scalability and practical deployment readiness need further substantiation through computational analysis and industrial testing

## Next Checks
1. **Dataset Generalization Testing**: Evaluate CADIC on diverse datasets beyond MVTec AD and VisA, including different domains and anomaly types
2. **Real-world Deployment Validation**: Implement CADIC in actual industrial settings to assess practical performance, integration requirements, and operational constraints
3. **Computational Efficiency Analysis**: Measure memory usage, processing time, and scalability as coreset size and task complexity increase to verify deployment feasibility