---
ver: rpa2
title: 'RAG-KG-IL: A Multi-Agent Hybrid Framework for Reducing Hallucinations and
  Enhancing LLM Reasoning through RAG and Incremental Knowledge Graph Learning Integration'
arxiv_id: '2503.13514'
source_url: https://arxiv.org/abs/2503.13514
tags:
- knowledge
- reasoning
- graph
- data
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of hallucination and reasoning
  limitations in large language models (LLMs) by introducing RAG-KG-IL, a multi-agent
  hybrid framework that integrates Retrieval-Augmented Generation (RAG), Knowledge
  Graphs (KGs), and incremental learning. The framework uses a multi-agent architecture
  to continuously update knowledge, integrate structured domain knowledge, and improve
  explainability.
---

# RAG-KG-IL: A Multi-Agent Hybrid Framework for Reducing Hallucinations and Enhancing LLM Reasoning through RAG and Incremental Knowledge Graph Learning Integration

## Quick Facts
- arXiv ID: 2503.13514
- Source URL: https://arxiv.org/abs/2503.13514
- Reference count: 40
- Primary result: 73% reduction in hallucination rate compared to GPT-4o on health queries

## Executive Summary
RAG-KG-IL is a multi-agent hybrid framework that addresses hallucination and reasoning limitations in large language models by integrating Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and incremental learning. The system continuously updates its knowledge base through entity extraction and KG updates while fusing retrieved text with structured graph data to ensure responses are grounded in verifiable information. Evaluated on health-related queries, the framework achieves a 73% lower hallucination rate than GPT-4o while improving answer completeness and demonstrating effective knowledge growth across 20 sequential questions.

## Method Summary
The framework uses a multi-agent architecture built on LangChain and Haystack to process queries through specialized components: a Data Selection Agent identifies relevant sources, a KG Agent extracts entities and updates the knowledge graph incrementally using RDFLib, and an Answer Generation Agent fuses retrieved text with sub-graph data before generation. Each query triggers entity extraction, KG updates, and RDF-based reasoning, with the system evaluated on 20 health questions covering 10 interconnected diseases. The evaluation measures hallucination rates (invalidated statements), completeness (missed facts), and KG growth metrics, using a truth-checking agent verified by human review.

## Key Results
- 73% reduction in hallucination counts (35 vs 129) compared to GPT-4o on identical health queries
- KG grows from 57 terms/114 triples to 226 terms/420 triples across 20 questions
- Improved reasoning accuracy with expanding causal relationships for diseases like Pneumonia

## Why This Works (Mechanism)

### Mechanism 1
Fusing structured KG triples with retrieved text before generation reduces hallucination by providing explicit entity-relationship constraints. The system concatenates retrieved text with sub-KG data, vectorizes it, and passes it to the answer generator, where KG triples serve as a consistency check.

### Mechanism 2
Specialized agents improve retrieval precision and reasoning traceability compared to monolithic RAG. The decomposition into Data Selection, KG, and Answer Generation agents with focused prompts and tools yields better results than single-agent processing.

### Mechanism 3
Incremental KG growth enables reasoning improvement without model retraining. Each query triggers entity extraction and KG updates, allowing knowledge to accumulate across queries and enrich future reasoning without computational overhead of full retraining.

## Foundational Learning

- **Knowledge Graph Triple Structure (Subject-Predicate-Object)**
  - Why needed here: All KG operations assume understanding of RDF-style triples. Without this, the fusion and reasoning mechanisms are opaque.
  - Quick check question: Given "Pneumonia - causes - Chest Pain," what are the subject, predicate, and object?

- **Retrieval-Augmented Generation (RAG) Pipeline**
  - Why needed here: The framework builds on RAG; understanding retrieval, reranking, and grounding is essential before adding KG integration.
  - Quick check question: How does RAG differ from standard LLM generation in handling out-of-training-distribution queries?

- **Incremental vs. Batch Learning Trade-offs**
  - Why needed here: The paper claims computational savings from incremental updates; understanding catastrophic forgetting and knowledge retention is critical.
  - Quick check question: Why might incremental updates to a KG be preferable to fine-tuning an LLM on new documents?

## Architecture Onboarding

- **Component map:** Application Interface -> Data Selection Agent -> API Retrieval -> KG Agent (extraction + update) -> Fusion with existing KG -> Answer Generation Agent -> Reasoning Graph -> Interface Output

- **Critical path:** Query flows through Data Selection Agent for source identification, KG Agent for entity extraction and updates, then Answer Generation Agent for data fusion and answer synthesis. Latency is dominated by LLM API calls.

- **Design tradeoffs:**
  - Lightweight KG (no fixed ontology) vs Schema-enforced KG: Uses flexible LightKG/LightRAG approach, risks inconsistent schema
  - Multi-agent decomposition vs Monolithic pipeline: Improves specialization but adds orchestration complexity
  - Human-in-the-loop vs Fully automated: Ensures quality but limits scalability

- **Failure signatures:**
  - High hallucination despite KG → Check retrieval relevance
  - Empty reasoning graph → KG extraction prompt may fail on domain-specific terminology
  - Stagnant KG growth → Entity extraction may be too conservative
  - Response latency spikes → LLM API rate limits

- **First 3 experiments:**
  1. Baseline comparison: Run same 20 health queries on (a) raw GPT-4o, (b) RAG-only, (c) RAG-KG-IL. Measure hallucination count and completeness.
  2. KG growth audit: After each query, log triple count, unique relation types, and sample extracted edges.
  3. Ablation on agent roles: Disable KG Agent (use only RAG) on subset of queries; measure reasoning graph quality and answer accuracy.

## Open Questions the Paper Calls Out

- **Scalability to large KGs:** How does the framework maintain reasoning accuracy and latency when scaled to large-scale knowledge graphs beyond the 420 triples tested? (Basis: Evaluation limited to small graph size, future work needed)
- **Multi-modal integration:** Can the framework be extended to integrate multi-modal data sources, such as medical imaging, without increasing hallucination rates? (Basis: Identified as primary future research avenue)
- **Automated evaluation:** Can a fully automated evaluation agent be developed to reliably assess answer completeness and accuracy without inconsistencies? (Basis: Initial automated scoring failed, requiring human verification)

## Limitations

- Framework effectiveness depends heavily on quality of underlying KG and retrieval mechanisms
- Multi-agent architecture adds orchestration complexity with potential cascading failures
- Lacks automatic error correction for incorrect relationships in incremental KG updates

## Confidence

- **High Confidence:** 73% hallucination reduction vs GPT-4o directly supported by experimental results
- **Medium Confidence:** Multi-agent contribution to reasoning traceability plausible but not conclusively isolated
- **Low Confidence:** Scalability of human-in-the-loop interface for production environments questionable

## Next Checks

1. Replicate hallucination reduction: Run the same 20 health queries against raw GPT-4o, RAG-only, and RAG-KG-IL implementations. Measure hallucination counts and completeness to verify the 73% reduction claim.

2. Audit KG growth quality: After each query, log the number of new triples added, their relation types, and sample the extracted edges. Verify that growth patterns match Figure 3 and identify any anomalous or nonsensical relationships.

3. Ablation study on agent roles: Disable the KG Agent component on a subset of queries while keeping the RAG pipeline intact. Compare reasoning graph quality and answer accuracy to isolate the specific contribution of incremental KG learning versus standard RAG retrieval.