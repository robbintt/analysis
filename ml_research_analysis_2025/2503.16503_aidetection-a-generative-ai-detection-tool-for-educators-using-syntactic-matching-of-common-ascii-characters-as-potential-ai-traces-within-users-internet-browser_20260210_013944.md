---
ver: rpa2
title: 'AIDetection: A Generative AI Detection Tool for Educators Using Syntactic
  Matching of Common ASCII Characters As Potential ''AI Traces'' Within Users'' Internet
  Browser'
arxiv_id: '2503.16503'
source_url: https://arxiv.org/abs/2503.16503
tags:
- text
- chatgpt
- aidetection
- detection
- ascii
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "AIDetection is a JavaScript-based web tool that detects potential\
  \ AI-generated content in student essays by identifying inconsistent character encodings\u2014\
  specifically, mixed use of ASCII and Unicode quotation marks. It scans uploaded\
  \ documents for syntactic artifacts and AI tool acknowledgments, providing color-coded\
  \ visual summaries and downloadable Excel/CSV reports."
---

# AIDetection: A Generative AI Detection Tool for Educators Using Syntactic Matching of Common ASCII Characters As Potential 'AI Traces' Within Users' Internet Browser

## Quick Facts
- arXiv ID: 2503.16503
- Source URL: https://arxiv.org/abs/2503.16503
- Reference count: 0
- A JavaScript-based web tool detecting AI-generated content by identifying mixed ASCII and Unicode quotation marks

## Executive Summary
AIDetection is a browser-based tool that helps educators identify potential AI-generated content in student essays by detecting inconsistent character encodings, specifically mixed use of ASCII and Unicode quotation marks. The tool also scans for AI tool acknowledgments and provides color-coded visual summaries with downloadable Excel/CSV reports. Running entirely client-side without server uploads, it offers a privacy-compliant alternative to opaque AI detection systems. Validated in an undergraduate course, it successfully flagged students using AI without acknowledgment, though it cannot provide definitive proof of AI use and may yield false positives.

## Method Summary
AIDetection uses heuristic regex-based detection to identify potential AI-generated content by counting ASCII quotation marks (U+0022, U+0027) versus Unicode curly quotes (U+201C/U+201D, U+2018/U+2019) in uploaded PDF and Word documents. The tool applies case-insensitive regex patterns to detect mentions of ChatGPT, Claude, Grammarly, Gemini, Llama/Meta, Copilot, and similar tools. All processing runs locally in the browser using PDF.js for PDFs, Mammoth.js for Word docs, and ExcelJS for reports, ensuring privacy compliance without data uploads. Results are color-coded: Green for clean or acknowledged content, Red for traces without acknowledgment, Gray for ambiguous/all-ASCII documents.

## Key Results
- Successfully flagged students using AI without acknowledgment in undergraduate course validation
- Provides transparent, privacy-compliant detection without server uploads or data privacy concerns
- Offers color-coded visual summaries and downloadable Excel/CSV reports for educators
- Cannot provide definitive proof of AI use and may yield false positives in certain cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mixed ASCII and Unicode quotation marks within a document serve as syntactic traces indicating potential AI-generated content.
- Mechanism: LLMs are predominantly trained on ASCII-formatted text (8-bit) for compatibility and tokenization efficiency. When users copy-paste AI output into text processors like MS Word or Google Docs (which use UTF-8/UTF-16), ASCII "straight quotes" remain alongside Unicode "curly quotes," creating detectable inconsistency.
- Core assumption: Students do not manually standardize quotation marks after pasting AI-generated content.
- Evidence anchors:
  - [abstract]: "identifying inconsistent character encodings—specifically, mixed use of ASCII and Unicode quotation marks"
  - [Page 2]: "Large Language Models (LLMs), by contrast, are usually trained on ASCII-formatted text because of greater compatability and smaller size (8 bit)... ASCII characters, particularly quotation marks, frequently appear in LLM outputs"
  - [corpus]: No direct corpus validation of encoding-based detection; neighbor papers focus on ML-based or semantic detection approaches
- Break condition: Students use ASCII-only text editors; text copied from non-AI ASCII sources (e.g., Wikipedia); students manually replace quotation marks; pre-ChatGPT documents.

### Mechanism 2
- Claim: Regular expression string matching for AI tool names identifies whether students have acknowledged AI use.
- Mechanism: The tool applies case-insensitive regex patterns to detect mentions of ChatGPT, Claude, Gemini, Llama/Meta, Microsoft Copilot, Grammarly AI, and similar tools, cross-referencing these with detected AI traces.
- Core assumption: Students who acknowledge AI use will explicitly name the tools they used in the document.
- Evidence anchors:
  - [abstract]: "scans uploaded documents for syntactic artifacts and AI tool acknowledgments"
  - [Page 4]: "Detecting direct mentions of AI models and tools within the text"
  - [corpus]: Weak corpus evidence; neighbor paper "Beyond Detection" addresses AI assessment design but does not validate acknowledgment-detection heuristics
- Break condition: Essays discussing AI as a topic (false positives for acknowledgment); students acknowledging AI generically without naming specific tools; partial name matches.

### Mechanism 3
- Claim: Client-side JavaScript execution enables privacy-compliant detection without data leaving the user's browser.
- Mechanism: All file parsing (PDF.js, Mammoth.js) and analysis run locally in the browser; no server uploads occur. Libraries are delivered via CDN (Cloudflare, jsDelivr).
- Core assumption: Educators have sufficient local computing resources; browsers remain stable during processing.
- Evidence anchors:
  - [abstract]: "running entirely in the user's browser without server uploads"
  - [Page 2-3]: "Since JS is executed within the user's own browser and no data is uploaded or processed on a web server, AIDetection complies with GDPR, FRAPA, and other data privacy regulations"
  - [corpus]: No corpus comparison available for privacy-preserving detection architectures
- Break condition: Processing large batches (>1000 documents) may crash browsers; performance depends on client hardware.

## Foundational Learning

- **Concept: Character Encoding (ASCII vs. UTF-8/Unicode)**
  - Why needed here: The entire detection heuristic rests on distinguishing ASCII "straight quotes" from Unicode "curly quotes." Without understanding encoding, the mechanism appears arbitrary.
  - Quick check question: In UTF-8, how many bytes does a curly quote ("") require versus a straight ASCII quote (")?

- **Concept: Regular Expressions for Pattern Matching**
  - Why needed here: AI tool acknowledgment detection uses regex to find tool names with case insensitivity and whitespace variations.
  - Quick check question: Write a case-insensitive regex that matches "ChatGPT" with optional whitespace (e.g., "Chat gpt").

- **Concept: Client-Side JavaScript Architecture**
  - Why needed here: The privacy claim and scalability constraints depend on understanding browser-based execution models.
  - Quick check question: What happens to processing if the user closes the browser tab mid-analysis?

## Architecture Onboarding

- **Component map:**
  File Processing Module -> Text Extraction Module -> Detection Engine -> Results Visualization -> Export Module

- **Critical path:** Upload files → Filter by date/extension → Extract raw text → Count ASCII vs. non-ASCII quotation marks → Scan for AI tool mentions → Generate color-coded result → Export report

- **Design tradeoffs:**
  - Heuristic simplicity vs. detection accuracy (cannot provide definitive proof)
  - Client-side privacy vs. scalability (browser crashes with large batches)
  - Transparent logic vs. code obfuscation (obfuscated on live site to prevent reverse engineering)

- **Failure signatures:**
  - All-ASCII documents (returns black/gray—"ambiguous" due to no comparison baseline)
  - Very short texts (insufficient character diversity for detection)
  - Essays about AI topics (false positive acknowledgment detection)
  - Pre-ChatGPT documents (filtered out by date check)

- **First 3 experiments:**
  1. Generate test documents with known AI-written passages; verify quote encoding inconsistency is flagged correctly.
  2. Create mixed documents (human + AI sections) with manual quote standardization; test false negative rate.
  3. Batch-upload 100+ files of varying sizes to identify browser memory thresholds and crash points.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the false positive and false negative rates of AIDetection when tested against a large, labeled corpus of human-written and AI-generated essays?
- Basis in paper: [explicit] "It was validated in an undergraduate writing course" but the author notes "it cannot provide definitive proof of AI use and may yield false positives in certain cases."
- Why unresolved: The validation was limited to one course without systematic measurement of accuracy metrics.
- What evidence would resolve it: A controlled study with known ground truth labels and statistical reporting of sensitivity, specificity, PPV, and NPV.

### Open Question 2
- Question: Will future LLMs continue outputting ASCII-style quotation marks, or will they adapt to produce typographically consistent Unicode characters?
- Basis in paper: [inferred] The detection method relies on the assumption that AI outputs ASCII characters due to training data and tokenization efficiency.
- Why unresolved: AI model behavior may change as training practices and tokenizers evolve.
- What evidence would resolve it: Longitudinal testing of quotation mark outputs across major LLM versions (GPT-3.5 through GPT-5, Claude iterations, etc.).

### Open Question 3
- Question: Can detection accuracy be improved by incorporating additional syntactic artifacts beyond quotation marks and apostrophes?
- Basis in paper: [inferred] The tool currently analyzes only quotation marks and apostrophes, but other characters may also exhibit encoding inconsistencies.
- Why unresolved: No investigation of other potential character-level artifacts is reported.
- What evidence would resolve it: Systematic analysis of other punctuation, whitespace, or formatting characters in AI vs. human text.

### Open Question 4
- Question: What proportion of flagged documents represent true AI use versus alternative explanations such as Wikipedia copying or ASCII-only text editors?
- Basis in paper: [explicit] "ASCII characters could originate from other copied sources like Wikipedia or uncommon document editors that do not support Unicode."
- Why unresolved: The paper does not quantify the sources of false positives.
- What evidence would resolve it: Follow-up investigation with students whose work was flagged to determine actual text sources.

## Limitations
- Detection reliability: Provides heuristic indicators rather than definitive proof; false positives can occur from ASCII-only editors, Wikipedia copying, or manual quote standardization
- Scope constraints: Limited to English-language documents in ASCII-compatible encodings; cannot detect pre-ChatGPT content or complex formatting
- Performance limitations: Client-side processing may fail with large batches (>1000 files) due to browser memory constraints

## Confidence
- High Confidence: Core mechanism of detecting mixed ASCII/Unicode quotation marks is technically sound and well-explained; privacy-preserving client-side architecture is clearly specified and GDPR-compliant
- Medium Confidence: Heuristic approach for AI tool acknowledgment detection using regex patterns is reasonable but lacks comprehensive validation; effectiveness depends on student acknowledgment patterns
- Low Confidence: Overall detection accuracy and false positive/negative rates are not empirically validated; tool's performance in real-world educational settings remains unproven beyond single undergraduate course

## Next Checks
1. **Encoding Consistency Validation**: Generate controlled test documents with known AI-written passages and verify that quote encoding inconsistency is correctly flagged. Create mixed human+AI documents with manual quote standardization to measure false negative rates.

2. **Acknowledgment Detection Testing**: Create diverse document sets including essays about AI topics, documents with partial AI tool name mentions, and documents with generic AI acknowledgments. Measure false positive rates in non-AI contexts.

3. **Scalability and Performance Assessment**: Batch-upload 100+ files of varying sizes (small, medium, large) to identify browser memory thresholds and crash points. Test processing time and memory usage across different client hardware configurations.