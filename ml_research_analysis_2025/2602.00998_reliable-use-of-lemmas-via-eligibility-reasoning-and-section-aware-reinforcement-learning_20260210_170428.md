---
ver: rpa2
title: Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement
  Learning
arxiv_id: '2602.00998'
source_url: https://arxiv.org/abs/2602.00998
tags:
- lemma
- perturbation
- statement
- reasoning
- mathematical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of lemma misapplication in large
  language models, where models often use conclusions without validating assumptions.
  The authors formalize lemma-judging as a structured prediction task requiring explicit
  precondition and conclusion-utility checks before using a lemma.
---

# Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning

## Quick Facts
- **arXiv ID:** 2602.00998
- **Source URL:** https://arxiv.org/abs/2602.00998
- **Reference count:** 20
- **Primary result:** A two-section, section-aware RL method improves lemma-judging robustness on perturbed test sets by up to 23+ points vs baselines.

## Executive Summary
This paper addresses the problem of lemma misapplication in large language models, where models often use conclusions without validating assumptions. The authors formalize lemma-judging as a structured prediction task requiring explicit precondition and conclusion-utility checks before using a lemma. They propose RULES, which trains with section-aware reinforcement learning that assigns penalties to the specific sections responsible for errors rather than the entire rollout. The method uses a two-section output format and leverages both natural language and formal proof corpora for training, with perturbations to test robustness. Results show consistent in-domain gains over vanilla models and single-label RL baselines, with larger improvements on applicability-breaking perturbations (up to 23+ points). On end-to-end tasks, performance is broadly on par or slightly better than baselines. Ablations confirm that both the two-section outputs and section-aware RL are necessary for robustness.

## Method Summary
RULES trains a model to judge lemma applicability by decomposing the task into two sequential sections: (1) precondition check with rationale and binary label, (2) conclusion-utility check with rationale and binary label. The final usefulness decision is the logical AND of these two labels. Training uses GRPO with section-aware loss masking: if the final label is wrong but one section's intermediate label is correct, only the tokens in the incorrect section receive a gradient update. This isolates the learning signal to the faulty reasoning step. The method incorporates perturbation data where preconditions are broken by minimal edits, providing hard negatives for the precondition check. Results show improved robustness on out-of-domain perturbation tests while maintaining in-domain accuracy.

## Key Results
- RULES achieves 23+ point improvements over vanilla GRPO on applicability-breaking perturbations.
- Consistent in-domain accuracy gains over single-label RL baselines across four test sets.
- Ablation shows staged two-section output and section-aware masking are both necessary for robustness.
- End-to-end task performance is broadly on par with or slightly better than baselines.

## Why This Works (Mechanism)

### Mechanism 1: Section-Aware Loss Masking for Precise Credit Assignment
- Claim: Assigning penalties only to the specific section responsible for an error improves the model's ability to learn the "check-before-use" discipline compared to penalizing the entire rollout.
- Mechanism: RULES uses a two-section output format (precondition check, conclusion-utility check). If the final aggregated label is wrong but one section's intermediate label is correct, the gradient update (loss mask) is applied *only* to tokens in the incorrect section. This isolates the learning signal to the part of the reasoning chain that failed, preventing gradient noise from correct sections.
- Core assumption: The model can learn distinct reasoning skills for precondition checking and conclusion-utility assessment, and that errors in these skills are localized to their respective output sections.
- Evidence anchors:
  - [abstract] "...trains with reinforcement learning plus section-aware loss masking to assign penalty to the section responsible for errors."
  - [section 3.2] "By this, we are penalizing the incorrect sections only and supervising models in more fine-grained signals on certain wrong tokens..."
  - [corpus] Weak direct corpus evidence for this specific loss masking technique in lemma judging. Related work in process-level supervision exists (e.g., LEMMA, Pan et al., 2025), but this specific two-section gating application is a novel contribution of this paper.
- Break condition: The assumption breaks if reasoning for the two checks is not well-localized, for example, if the model generates the conclusion-check rationale based on tokens generated in the precondition-check section, making a clean mask ineffective.

### Mechanism 2: Staged, Structured Prediction Decomposition
- Claim: Forcing a model to explicitly generate and separate a precondition check from a conclusion-utility check encourages a "gating" behavior that reduces spurious lemma application based on surface similarity.
- Mechanism: The two-section prompt structure forces the model to externalize its reasoning for each step. The final decision is a deterministic function ($l_{use} = l_{pre} \land l_{con}$) of these intermediate checks. This creates an explicit reasoning bottleneck: if the precondition check yields `False`, the lemma is gated regardless of the conclusion's utility. This structure fights the tendency to jump to a conclusion based on surface features.
- Core assumption: The model has the base capability to perform the individual checks (precondition verification, utility assessment) and that forcing this structure doesn't overly constrain its ability to reason about complex lemmas.
- Evidence anchors:
  - [abstract] "...formalize lemma-judging as a structured prediction task... from which a usefulness decision is derived."
  - [section 3.1] "The final usefulness decision is a deterministic aggregation of the precondition and conclusion checks..."
  - [section 5.2] Ablation shows "two-section-onetime" (both judgements at the end) has weaker robustness than the sequential two-section protocol, confirming the *staged* structure matters.
  - [corpus] The concept of structured reasoning or process supervision is related to other works like "LEMMA" (learning from errors), but the specific two-stage check-before-use structure is a unique formalization here.
- Break condition: This mechanism fails if the model lacks the base knowledge to reliably perform the first step (precondition check), in which case the gating will be noisy or incorrect.

### Mechanism 3: Perturbation-Based Training for Robustness
- Claim: Training on carefully constructed examples where a lemma's preconditions are broken by minimal statement edits forces the model to learn genuine applicability rules rather than relying on surface-level patterns.
- Mechanism: The authors create a "perturbation suite" by taking valid statement-lemma pairs and minimally editing the statement to falsify a lemma's precondition. Training on these negatives provides a strong signal for the precondition check (`l_pre = 0`), creating a dataset of "hard negatives" that specifically target the failure mode of lemma misapplication.
- Core assumption: The perturbed statements are mathematically coherent and the preconditions are genuinely broken in a way that cannot be trivially circumvented. The paper notes they use an o3 model and human validation to ensure this quality.
- Evidence anchors:
  - [abstract] "...robustness is assessed with a held-out perturbation suite..."
  - [section 4.2] "...we also add some perturbation data in training by making a lemma inapplicable while keeping the statement minimally changed..."
  - [section 5.2] Ablation shows removing this perturbation data "collapses robustness on the out-of-domain suite," confirming its necessity.
  - [corpus] This connects to broader work on adversarial/perturbation-based training for robustness (e.g., MATH-Perturb), but the application here is specifically targeted at falsifying preconditions for lemma use.
- Break condition: The assumption holds only if the perturbation data is high quality. If perturbations introduce nonsensical statements or do not genuinely break applicability, the model will learn a distorted precondition-checking signal.

## Foundational Learning

- **Reinforcement Learning with Verifiable Rewards (RLVR) / GRPO**
  - Why needed here: RULES uses GRPO (Group Relative Policy Optimization) as its base RL algorithm. Understanding the basics of policy gradients and how rewards are computed from verifiable outcomes is essential to grasp how the section-aware masking modifies the base training loop.
  - Quick check question: How does a policy gradient update differ from standard supervised fine-tuning (SFT)?

- **Chain-of-Thought (CoT) & Structured Reasoning**
  - Why needed here: The method relies on a specific, structured chain-of-thought output (two sequential checks). Understanding how to prompt for and enforce structured outputs is a prerequisite for implementing the data format and parsing logic.
  - Quick check question: What are the benefits and risks of enforcing a rigid structure on a model's reasoning output?

- **Loss Masking in Sequence Modeling**
  - Why needed here: The core novelty is a section-aware loss mask. One must understand how loss is computed over a sequence of tokens and how masking allows for selective gradient updates to appreciate the precision of this technique.
  - Quick check question: If you have a prompt `[P]`, a correct response `[R1]`, and an incorrect response `[R2]`, how would you construct a loss mask to train only on `[R2]`?

## Architecture Onboarding

- **Component map:**
  - Data Curation Pipeline -> Two-Section Prompting Schema -> Rule-Based Reward Function -> Section-Aware RL Trainer (GRPO-based)

- **Critical path:**
  1.  **Data Prep:** Acquire statement-lemma pairs. For a subset, generate high-quality perturbations that break preconditions and obtain gold `l_pre=0` labels.
  2.  **Prompting:** Format all training data using the two-section schema (Appendix A).
  3.  **Training Loop:**
      - For each batch, generate rollouts with the two-section format.
      - Parse rollouts to get predicted `l_pre`, `l_con`.
      - Compare against gold labels (final label for all data, intermediate labels for perturbation data).
      - Identify incorrect sections.
      - Create the `m_j` mask for each rollout.
      - Perform GRPO update step with the masked gradient calculation.

- **Design tradeoffs:**
  - **Structured vs. Free-form Output:** The rigid two-section structure enables precise credit assignment but could constrain the model's reasoning style. The paper argues the tradeoff favors robustness.
  - **Labeling Cost:** Obtaining gold labels for *both* sections for all data is expensive. The design choice is to use them only for the perturbation data (where `l_pre` is reliably `0`) and rely on the final label for other data, making the system practical.
  - **Performance vs. Rigor:** The paper notes a tradeoff on some end-to-end benchmarks. Strict precondition gating can reduce "lucky" answers, potentially lowering scores on tasks where looser reasoning might succeed.

- **Failure signatures:**
  - **Parsing Failures:** High rate of -2 format penalties indicates the model is struggling to follow the two-section schema. Check prompt clarity or model capability.
  - **Collapse of Precondition Gating:** If performance on the perturbation test set drops to baseline levels, the section-aware masking may not be activating correctly, or the perturbation training data is not being used effectively.
  - **Low Mask Activation:** If the section-aware loss mask is almost never activated (i.e., model is mostly wrong on the final label but not in a localized way), it may indicate that the model is not learning to separate the two reasoning steps.

- **First 3 experiments:**
  1.  **Baseline Comparison:** Train a model with vanilla GRPO (single final label) on the same data. Compare against RULES on the in-domain and, crucially, the out-of-domain perturbation test sets to validate the robustness claim.
  2.  **Ablation on Output Structure:** Train a "two-section-onetime" variant as described in the ablation study. This tests whether the *staged* output structure is critical, or if just having the information is enough. The paper shows staged is key.
  3.  **Ablation on Perturbation Data:** Train RULES *without* the perturbation data. This validates whether the perturbation data (which provides the gold intermediate labels for masking) is the source of the robustness gain, as the paper's ablation suggests.

## Open Questions the Paper Calls Out

- **Can RULES's section-aware credit assignment mechanism transfer effectively to multilingual mathematical reasoning or formal proof assistants like Lean and Coq?**
  - Basis in paper: [explicit] "the extension to multilingual settings or other formal proof assistants (e.g., Lean, Coq) remains a direction for future work."
  - Why unresolved: Experiments only covered English-language natural language and Isabelle formal proofs; the structured output schema may not directly transfer to different formal systems with distinct syntax.
  - What evidence would resolve it: Evaluation of RULES-trained models on Lean/Coq premise selection benchmarks or multilingual math datasets, showing whether section-aware masking retains benefits across formalisms.

- **How can conclusion-utility supervision be incorporated at scale without introducing strategy-dependent noise?**
  - Basis in paper: [explicit] "In the perturbation data, only the precondition label is available while the conclusion-utility label is omitted to avoid strategy dependence. This asymmetric supervision can introduce bias and limit learning of usefulness beyond eligibility."
  - Why unresolved: Conclusion utility is inherently tied to proof strategy, making scalable annotation difficult; the paper deliberately omits it, leaving models potentially under-trained on actual helpfulness assessment.
  - What evidence would resolve it: A method for generating strategy-agnostic conclusion-utility labels, or an ablation showing whether adding noisy conclusion labels improves or degrades perturbation robustness.

## Limitations

- The core assumption of clean error localization between sections may not hold for all lemma-judging tasks.
- The perturbation data quality and generation mechanism are critical but not fully detailed.
- Strict precondition gating may reduce performance on end-to-end tasks where looser reasoning could lead to correct answers.

## Confidence

- **High Confidence:** The formal definition of lemma-judging as a structured prediction task with a two-section output is well-defined and the experimental results showing in-domain improvements are robust.
- **Medium Confidence:** The claim that section-aware masking specifically drives the robustness gains on perturbation tests is supported by ablations, but the exact contribution of each component (structure vs. masking vs. perturbation data) is not fully disentangled.
- **Low Confidence:** The generalization of these robustness gains to entirely different lemma-judging datasets or mathematical domains not seen in the perturbation suite.

## Next Checks

1. **Cross-Domain Perturbation Test:** Apply the perturbation generation process to a new lemma-judging dataset (e.g., one not in the training corpora) and evaluate if RULES maintains its robustness advantage over baselines.
2. **Intermediate Label Ablation:** Train a variant where gold intermediate labels (`l_pre`, `l_con`) are provided for *all* training data (not just perturbations) and compare robustness to the original RULES to isolate the impact of having these labels.
3. **Qualitative Error Analysis:** Perform a detailed analysis of model outputs on perturbation test cases where RULES fails, to identify if errors are truly localized to one section or if the two-section assumption breaks down in complex cases.