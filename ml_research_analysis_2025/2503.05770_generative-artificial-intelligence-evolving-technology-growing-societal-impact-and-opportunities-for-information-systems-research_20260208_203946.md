---
ver: rpa2
title: 'Generative Artificial Intelligence: Evolving Technology, Growing Societal
  Impact, and Opportunities for Information Systems Research'
arxiv_id: '2503.05770'
source_url: https://arxiv.org/abs/2503.05770
tags:
- systems
- genai
- information
- research
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a sociotechnical framework for understanding
  generative AI (GenAI), emphasizing its transformative potential through strong emergence,
  generative novelty, and systemic inputs/outputs. It identifies key research opportunities
  for information systems scholars in productivity enhancement, human-AI collaboration,
  dark-side issues (biases, misinformation), and system design.
---

# Generative Artificial Intelligence: Evolving Technology, Growing Societal Impact, and Opportunities for Information Systems Research

## Quick Facts
- arXiv ID: 2503.05770
- Source URL: https://arxiv.org/abs/2503.05770
- Reference count: 18
- One-line primary result: Proposes a sociotechnical framework for GenAI with three core properties and four research themes for IS scholars.

## Executive Summary
This paper presents a sociotechnical framework for understanding generative AI (GenAI) as a transformative technology characterized by strong emergence, generative novelty, and systemic inputs/outputs. The framework distinguishes GenAI from traditional AI by emphasizing its ability to produce self-contained conceptual systems rather than mere decisions or data snippets. The authors identify four key research themes for Information Systems scholars: disruption and impact, human-machine collaboration, dark-side issues (biases, misinformation), and system design. The paper calls for interdisciplinary research to address ethical, governance, and environmental challenges while leveraging GenAI's capabilities for innovation.

## Method Summary
The paper employs conceptual analysis and synthesis, drawing on systems theory, sociotechnical perspectives, and the evolution of AI from symbolic to connectionist approaches. The authors develop a framework by applying theoretical foundations to GenAI, identifying three core properties (strong emergence, generative novelty, systemic I/O) and using this lens to categorize research opportunities across four themes. The method is primarily theoretical, with no empirical datasets or code provided, focusing instead on creating a structured research agenda for IS scholars.

## Key Results
- GenAI exhibits strong emergence where outputs cannot be directly derived from component properties
- GenAI produces self-contained conceptual systems rather than decisions requiring human interpretation
- The framework identifies four research themes: disruption/impact, human-AI collaboration, dark-side issues, and system design

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GenAI exhibits strong emergence where outputs cannot be directly derived from component properties.
- Mechanism: Neural network components interact at massive scale, producing emergent properties like human-sounding outputs that vanish if components are decoupled.
- Core assumption: Complexity at sufficient scale creates qualitatively different system behavior.
- Evidence anchors: The paper contrasts hereditary properties (derivable from parts) with emergent properties (system-level only), noting that human-sounding outputs vanish when components are decoupled.

### Mechanism 2
- Claim: GenAI produces outputs through a predictive, probabilistic approach based on connectionist pattern matching rather than symbolic reasoning.
- Mechanism: LLMs use transformer architecture with self-attention mechanisms to process text, creating weighted connections among tokens through billions of iterations, generating outputs probabilistically.
- Core assumption: Statistical co-occurrence patterns at sufficient scale approximate meaningful language generation.
- Evidence anchors: The paper notes that ChatGPT is a predictive approach based on deep neural networks, making responses probabilistic and necessarily error-prone.

### Mechanism 3
- Claim: GenAI's systemic inputs/outputs enable it to function as a generative sociotechnical system producing self-contained conceptual systems.
- Mechanism: Unlike traditional ML that produces decision boundaries requiring interpretation, GenAI generates standalone outputs (essays, code, images) that are directly usable conceptual systems.
- Core assumption: Self-contained outputs reduce integration friction and expand use cases.
- Evidence anchors: The paper states that GenAI can accept and generate component systems as well as systems in their own right, producing standalone conceptual systems.

## Foundational Learning

- Concept: **Emergent vs. Hereditary Properties (Systems Theory)**
  - Why needed here: The paper's core theoretical contribution distinguishes GenAI's emergent properties from traditional AI's hereditary properties; misunderstanding this conflates component-level analysis with system-level behavior.
  - Quick check question: Can you explain why "transparency" in a neural network is an emergent rather than hereditary property?

- Concept: **Connectionism vs. Symbolism Paradigm**
  - Why needed here: The paper positions GenAI as the culmination of AI's shift from symbolic (rule-based) to connectionist (neural network) approaches; this frames why GenAI behaves differently from expert systems.
  - Quick check question: What fundamental limitation of symbolic AI did connectionism overcome for natural language tasks?

- Concept: **Sociotechnical Systems Perspective**
  - Why needed here: The proposed framework requires analyzing GenAI within organizational and social contexts, not as isolated technology; this determines research design choices.
  - Quick check question: Why does the paper argue IS researchers should study GenAI as "a component of broader sociotechnical systems" rather than focusing on technical properties?

## Architecture Onboarding

- Component map: **Core LLM** (transformer architecture with self-attention) -> **Supporting models** (GAN, attention models, reward models, RLHF) -> **Training data** (big data repositories) -> **Interface layer** (prompt engineering)

- Critical path: Pre-training on large text corpora (self-supervised learning) -> Fine-tuning with RLHF for human preference alignment -> Inference via probabilistic token prediction with temperature parameter -> Output as self-contained conceptual system

- Design tradeoffs:
  - Generic capability vs. accuracy: Single model serving all domains trades specialization for breadth
  - Predictive generation vs. factual reliability: Probabilistic outputs enable creativity but introduce hallucination risk
  - Transparency vs. performance: Billions of parameters improve output quality but reduce explainability

- Failure signatures:
  - Hallucination: Confident generation of non-factual information
  - Bias amplification: Training data biases reflected in outputs (political, cultural, moral)
  - Context misunderstanding: Failure to grasp semantic meaning despite fluent output
  - Energy/resource constraints: Training GPT-3 required ~936 MWh

- First 3 experiments:
  1. **Emergence boundary test**: Decompose a transformer model and attempt to reproduce specific emergent behaviors with isolated components; document where properties disappear.
  2. **Self-contained output validation**: Generate diverse GenAI outputs (code, essays, images) and measure the percentage requiring human modification before practical use.
  3. **Probabilistic consistency check**: Run identical prompts multiple times with temperature > 0; analyze variance in factual accuracy and coherence to quantify the "generative novelty" vs. "hallucination" tradeoff.

## Open Questions the Paper Calls Out

- Question: How can researchers effectively model business tasks and processes that involve both human and machine agents?
  - Basis in paper: [explicit] The authors explicitly ask in Table 4: "How do researchers model business tasks and processes that involve both human and machine agents?"
  - Why unresolved: Traditional process modeling assumes human-centric logic or rigid automation. GenAI introduces "generative novelty" and "strong emergence," making the behavior of AI agents less predictable and requiring new theoretical principles for design and configuration.

- Question: What specific organizational capabilities are required to match the accelerated pace of information systems adaptation and evolution driven by GenAI?
  - Basis in paper: [explicit] Section 4.1 explicitly states: "This raises the question of what organizational capabilities are needed to match the expected increase in information systems adaptation and evolution."
  - Why unresolved: GenAI empowers "empowered users" to develop solutions autonomously, potentially outpacing traditional centralized IT governance and risk management structures.

- Question: What governance structures must be implemented to manage the internal and external risks associated with GenAI?
  - Basis in paper: [explicit] Table 4 lists: "What governance needs to be put into place?" and asks how to manage internal and external risks given the potential for "dark-side" outcomes.
  - Why unresolved: The opacity of LLMs ("transparency" issues) and their ability to generate systemic, self-contained outputs (e.g., deepfakes, malicious code) create liability and ethical risks that existing IT policies do not cover.

## Limitations
- The theoretical framework relies heavily on conceptual arguments about emergence without empirical validation
- The distinction between strong emergence and other forms of emergence remains philosophical rather than operational
- The framework's applicability across different GenAI modalities is asserted but not demonstrated

## Confidence
- **High confidence**: Claims about GenAI's basic capabilities (text generation, image creation, code generation) and general deployment patterns
- **Medium confidence**: Framework's identification of key research themes (productivity, collaboration, dark-side issues, design) and the sociotechnical perspective
- **Low confidence**: Specific claims about strong emergence mechanisms and the precise boundaries between hereditary and emergent properties in complex AI systems

## Next Checks
1. **Emergence boundary test**: Decompose a transformer model and attempt to reproduce specific emergent behaviors with isolated components; document where properties disappear.
2. **Self-contained output validation**: Generate diverse GenAI outputs (code, essays, images) and measure the percentage requiring human modification before practical use.
3. **Probabilistic consistency check**: Run identical prompts multiple times with temperature > 0; analyze variance in factual accuracy and coherence to quantify the "generative novelty" vs. "hallucination" tradeoff.