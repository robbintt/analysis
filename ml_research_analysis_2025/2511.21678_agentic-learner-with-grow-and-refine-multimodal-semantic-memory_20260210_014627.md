---
ver: rpa2
title: Agentic Learner with Grow-and-Refine Multimodal Semantic Memory
arxiv_id: '2511.21678'
source_url: https://arxiv.org/abs/2511.21678
tags:
- memory
- visual
- reasoning
- logical
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes ViLoMem, a dual-stream memory framework that
  separately encodes visual distraction patterns and logical reasoning errors to address
  the limitation of existing memory-augmented agents that store only trajectory-based
  memories without preserving multimodal reasoning. The system employs specialized
  retrieval strategies: image-similarity search followed by question-aware attention
  maps for visual memories, and problem analysis with text-embedding similarity for
  logical memories.'
---

# Agentic Learner with Grow-and-Refine Multimodal Semantic Memory

## Quick Facts
- arXiv ID: 2511.21678
- Source URL: https://arxiv.org/abs/2511.21678
- Reference count: 40
- Key outcome: ViLoMem dual-stream memory improves multimodal reasoning accuracy across six benchmarks via separate visual and logical error correction

## Executive Summary
This paper introduces ViLoMem, a dual-stream memory framework that separately encodes visual distraction patterns and logical reasoning errors to enhance multimodal reasoning in large language models. The system employs specialized retrieval strategies: image-similarity search followed by question-aware attention maps for visual memories, and problem analysis with text-embedding similarity for logical memories. Through extensive experiments on six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy across different model scales, achieving notable gains on mathematical reasoning tasks while avoiding catastrophic forgetting through its grow-and-refine memory consolidation principle.

## Method Summary
ViLoMem implements a dual-stream memory system that maintains separate banks for visual distraction patterns and logical reasoning errors. The framework generates memories by analyzing model failures: visual errors produce (guideline, source_image) pairs, while logical errors generate text-only reasoning schemas. Retrieval employs a two-stage process for visual memories (image embedding → text reranking) and problem-analysis-based retrieval for logical memories. The grow-and-refine principle filters similar error patterns before storing, merging memories above a similarity threshold to prevent fragmentation while preserving actionable specificity. The system incrementally accumulates knowledge through this selective consolidation mechanism.

## Key Results
- ViLoMem achieves +6.48 pass@1 improvement on MathVision benchmark using GPT-4.1
- The framework delivers +4.38 gain on MMMU benchmark using Qwen3-VL-8B
- Ablation studies confirm both memory streams are essential, with visual errors dominating generation (59-93%) but both streams contributing comparably during retrieval

## Why This Works (Mechanism)

### Mechanism 1: Dual-Stream Error Decomposition
Separating visual distraction errors from logical hallucination errors enables more effective error correction than single-modality memory. The system maintains two distinct memory banks—visual memory stores (guideline, source_image) pairs for perceptual traps; logical memory stores text-only reasoning schemas. An MLLM analyzer attributes errors to the appropriate stream, and merge/create operations consolidate similar patterns while preserving distinct representational structures. Core assumption: Visual and logical errors have different causal origins and require modality-specific intervention strategies.

### Mechanism 2: Two-Stage Visual Memory Retrieval with Question-Aware Attention
Image-similarity alone is insufficient; combining visual similarity with semantic filtering and attention-guided spatial cues improves retrieval relevance. Stage 1 retrieves top-k candidates via multimodal image embeddings. Stage 2 reranks using text similarity between enriched queries (question + problem analysis) and stored visual guidelines. Retrieved memories then generate attention heatmaps highlighting historically error-prone regions in the query image. Core assumption: Visual errors are context-dependent; the same image region may be task-relevant or distracting depending on the question.

### Mechanism 3: Grow-and-Refine Memory Consolidation
Filtering similar error patterns and selectively merging/appending memories avoids both catastrophic forgetting and detail erosion from iterative rewriting. Before storing a new guideline, the system computes text-embedding similarity against existing memories. If max similarity exceeds threshold τ, the new guideline merges with the closest match; otherwise, it creates a new entry. This preserves stable generalizable strategies while incrementally accumulating knowledge. Core assumption: Semantically similar errors share underlying patterns that can be abstracted into unified schemas without losing actionable specificity.

## Foundational Learning

- **Semantic Memory vs. Episodic Memory**: Why needed here: ViLoMem is explicitly inspired by human semantic memory—modality-specific "spokes" (visual/logic) integrated through a central hub. Understanding this distinction clarifies why the system stores abstracted schemas rather than raw interaction traces. Quick check question: Can you explain why storing "triangles require base×height/2" differs from storing "on problem #47, I mistakenly added the side lengths"?

- **Multimodal Embedding Spaces**: Why needed here: Retrieval depends on both ϕ_M (image embeddings) and ϕ_T (text embeddings). Without understanding how these spaces align and diverge, the two-stage filtering logic will seem arbitrary. Quick check question: Why might two images with similar visual embeddings have unrelated semantic relevance to a given question?

- **Error Attribution in Chain-of-Thought**: Why needed here: The framework's viability hinges on correctly classifying whether an error stems from visual misinterpretation or logical fallacy. Misattribution cascades into noisy memory updates. Quick check question: Given a wrong answer where the model misread "12" as "6" in a diagram, is this a visual or logical error? What if it then applied the wrong formula?

## Architecture Onboarding

- **Component map**: Memory Banks (Logic Memory, Visual Memory) → Analyzers (LLM for logical, MLLM for visual) → Retrivers (Two-stage visual, Problem-analysis logical) → Solver (MLLM with retrieved memories + attention) → Verifier (LLM-as-judge) → Memory Update (similarity check → merge/create)

- **Critical path**: Problem (I, q) enters → parallel retrieval from both banks → retrieved memories (R_L, R_V) + attention maps → solver generates candidate answer → verifier compares against ground truth → on error: analyzers attribute to visual/logical stream → merge or create memory entry

- **Design tradeoffs**: Separate vs. unified memory enables modality-specific retrieval but requires coordination logic; merge threshold (τ) balances specificity vs. generalization; attention map integration helps perception tasks but adds overhead and may degrade on fine-grained geometry

- **Failure signatures**: Textual bias (solver ignores visual cues → visual memory underpopulated); low-quality visual descriptions (verifier cannot identify clear visual errors → mixed memory updates); cross-domain interference (mismatched benchmark memories → conflicting retrieval results)

- **First 3 experiments**: (1) Ablate one stream at a time on held-out benchmark to quantify marginal contribution; (2) Vary merge threshold τ (0.7, 0.8, 0.9) and measure memory bank size vs. accuracy; (3) Cross-model transfer: populate memory using GPT-4.1 and evaluate Qwen3-VL-8B benefits

## Open Questions the Paper Calls Out

- **Decoupling dual memory streams**: How can the dual memory streams be better decoupled to handle cases where solvers exhibit strong textual bias or struggle with complex diagram perception? The paper suggests designing more specialized mechanisms to enhance decoupling, as current approaches struggle when solvers over-rely on linguistic reasoning or produce low-quality visual descriptions.

- **Attention visualization for geometry**: What attention visualization methods could faithfully preserve fine-grained geometric structures and chart details for mathematical reasoning tasks? Current methods struggle with geometric structures and impose higher interpretation demands, causing performance plateau on mathematics-centric datasets.

- **Cross-domain memory sharing conditions**: Under what precise conditions does cross-domain memory sharing benefit versus interfere with multimodal reasoning performance? The paper reveals substantial heterogeneity—MathVision and RealWorldQA benefit from cross-domain memories due to spatial reasoning requirements, while tasks with large domain gaps exhibit conflicts in memory utilization.

## Limitations

- Memory consolidation granularity is underspecified, making it unclear how aggressively patterns are generalized versus preserved
- Attention map fidelity may not capture sub-pixel precision needed for vertex-level geometry reasoning
- Cross-domain contamination can degrade retrieval relevance when memories from different benchmark distributions are mixed

## Confidence

- **High confidence**: Dual-stream error separation improves performance over single-stream baselines (consistent ablation results across 6 benchmarks)
- **Medium confidence**: Two-stage visual retrieval with question-aware attention provides consistent gains (gains plateau on MathVision due to visualization limits)
- **Medium confidence**: Grow-and-refine consolidation avoids catastrophic forgetting (lack of long-term forgetting metrics makes verification difficult)

## Next Checks

1. Ablate individual memory streams on held-out benchmarks to quantify marginal contributions; expect asymmetric degradation patterns based on task type
2. Cross-model transfer test: populate memory using GPT-4.1 and evaluate whether Qwen3-VL-8B shows disproportionate gains, validating knowledge distillation effectiveness
3. Merge threshold sweep: systematically vary τ (0.7→0.9) and measure memory bank size vs. accuracy to identify optimal balance between consolidation and specificity