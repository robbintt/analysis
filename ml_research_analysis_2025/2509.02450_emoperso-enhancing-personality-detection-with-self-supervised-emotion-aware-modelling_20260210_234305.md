---
ver: rpa2
title: 'EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware
  Modelling'
arxiv_id: '2509.02450'
source_url: https://arxiv.org/abs/2509.02450
tags:
- personality
- emotion
- reasoning
- emoperso
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EmoPerso is a self-supervised framework for personality detection
  that leverages emotion-aware modelling. It uses LLM-based generative mechanisms
  for data augmentation and representation learning, extracts pseudo-labeled emotion
  features, and jointly optimizes them with personality prediction via multi-task
  learning.
---

# EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling

## Quick Facts
- arXiv ID: 2509.02450
- Source URL: https://arxiv.org/abs/2509.02450
- Reference count: 40
- Primary result: Achieves Macro-F1 of 81.07% on Kaggle and 68.60% on Pandora datasets

## Executive Summary
EmoPerso introduces a self-supervised framework that enhances personality detection by jointly modeling personality traits and emotional expressions. The approach leverages large language models for data augmentation and representation learning, extracting pseudo-labeled emotion features that are jointly optimized with personality prediction via multi-task learning. A cross-attention module captures fine-grained interactions between personality traits and inferred emotional representations. Experiments demonstrate EmoPerso outperforms state-of-the-art models on two benchmark datasets, with the framework showing particular effectiveness when emotion-aware modeling is integrated.

## Method Summary
EmoPerso employs a frozen DeepSeek-V3 backbone with LLM-based style-conditioned paraphrasing and contextual completion for data augmentation. The model uses a shared encoder to extract personality and emotion representations, which are jointly optimized through separate MLP heads. A cross-attention module modulates personality representations using emotion-guided attention weights. The framework incorporates a self-taught reasoning strategy that generates multiple reasoning chains and selects the optimal one using Information Gain and Mutual Information scoring. The training procedure uses weighted loss functions combining personality and emotion predictions with consistency regularization.

## Key Results
- EmoPerso achieves Macro-F1 of 81.07% on Kaggle dataset, outperforming previous state-of-the-art models
- The framework achieves 68.60% Macro-F1 on Pandora dataset, demonstrating effectiveness across different data sources
- Ablation studies show emotion-aware modeling and reasoning chain selection each contribute significant performance gains

## Why This Works (Mechanism)

### Mechanism 1: Pseudo-Labeled Emotion Auxiliary Task
The framework introduces emotion detection as an auxiliary task using pseudo-labels inferred from text, regularizing the personality model to learn richer latent representations. This multi-task learning setup shares a bottom-level encoder between personality and emotion tasks, assuming they share underlying linguistic features like lexical choice and punctuation.

### Mechanism 2: Emotion-Conditioned Attention Modulation
A cross-attention module uses personality vectors to query text tokens, with emotion-conditioned weighting re-weighting attended tokens based on emotion embeddings. This modulation amplifies psychologically salient features guided by emotional context, helping the model focus on diagnostically relevant tokens for personality prediction.

### Mechanism 3: Information-Theoretic Reasoning Chain Selection
The model generates multiple reasoning chains and filters them using Information Gain and Mutual Information metrics rather than using all chains indiscriminately. This selection mechanism reduces noise compared to standard Chain-of-Thought prompting by choosing chains that maximize information gain relative to personality-emotion pairs.

## Foundational Learning

### Concept: Multi-Task Learning (MTL) with Shared Encoders
**Why needed here:** Understanding how gradients from emotion auxiliary tasks backpropagate to update shared encoders is critical to grasping why the model learns richer representations than personality labels alone would allow.

**Quick check question:** If the emotion loss has much larger magnitude than the personality loss, what happens to the shared representation?

### Concept: Cross-Attention vs. Self-Attention
**Why needed here:** The model uses cross-attention where personality vectors query text tokens, differing from standard self-attention where tokens attend to tokens.

**Quick check question:** In the cross-attention module, what serves as the Query and what serves as the Keys/Values?

### Concept: Self-Taught Reasoner (STaR)
**Why needed here:** Understanding that STaR involves generating rationales and fine-tuning on correctly solved chains, with EmoPerso modifying this through external IG/MI filtering.

**Quick check question:** How does EmoPerso modify standard STaR to ensure only high-quality chains influence predictions?

## Architecture Onboarding

### Component map:
Frozen DeepSeek-V3 LLM -> Augmentation Module -> Shared Encoder -> MTL Heads -> Interaction Module -> Reasoning Module

### Critical path:
The Augmentation -> MTL -> Interaction flow is vital. The model relies on augmentation to handle noisy social media text and the MTL module to produce valid emotion embeddings. If emotion embeddings are generic, the subsequent emotion-conditioned modulation fails to highlight specific personality cues.

### Design tradeoffs:
- Frozen Backbone: Uses frozen LLM to save resources and leverage pre-trained knowledge, but limits adaptation to dataset nuances
- Pseudo-Labels vs. Gold Labels: Self-supervised pseudo-labels enable training without external annotations but risk propagating errors compared to human-annotated emotion data

### Failure signatures:
- Semantic Drift: Weak KL Divergence regularization may cause paraphrasing augmentation to diverge from original intent
- Uniform Reasoning: Removing IG/MI filtering may result in selecting generic reasoning chains lacking diagnostic value

### First 3 experiments:
1. Ablate emotion: Run model with w/o Emotions to verify magnitude of performance drop and confirm emotion aids personality detection
2. Cross-Attention Replacement: Replace Cross-Attention with simple concatenation to test if specific attention mechanism is necessary
3. Reasoning Validation: Compare w/o Reasoning Chains vs. Replace STaR with CoT Templates vs. Full EmoPerso to isolate value added by information-theoretic filtering

## Open Questions the Paper Calls Out
- How effectively does EmoPerso transfer to multilingual contexts where cultural nuances alter emotion-personality correlations
- Whether LLM-based synthetic augmentation limits generalization to real-world distributions not captured by generative models
- The performance degradation when replacing self-supervised emotion pseudo-labels with gold-standard human annotations

## Limitations
- Relies on pseudo-labeled emotion features rather than human-annotated emotion data, potentially introducing noise
- Uses frozen LLM weights, limiting adaptation to dataset-specific nuances and reducing generalizability
- Performance gains depend heavily on quality of emotion pseudo-labeling heuristics, which are inferred rather than validated

## Confidence
- **High confidence**: MTL framework's ability to extract shared representations (well-established mechanism)
- **Medium confidence**: Overall effectiveness on Kaggle/Pandora datasets (based on specific preprocessing and pseudo-labeling choices)
- **Low confidence**: Emotion modulation specifically improves beyond simple feature concatenation (~3.2% ablation drop)

## Next Checks
1. Verify emotion pseudo-labeling quality by manually annotating 100 samples and comparing to heuristic outputs
2. Test model on held-out dataset with gold emotion annotations to isolate pseudo-label noise effects
3. Measure variance across 5 random seeds to assess statistical significance of reported gains