---
ver: rpa2
title: IoT-based Android Malware Detection Using Graph Neural Network With Adversarial
  Defense
arxiv_id: '2512.20004'
source_url: https://arxiv.org/abs/2512.20004
tags:
- graph
- malware
- android
- detector
- application
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Graph Neural Network (GNN)-based method for
  Android malware detection that uses API graph embeddings combined with permission
  and intent features. The approach achieves high accuracy (98.33% on CICMaldroid
  and 98.68% on Drebin datasets) but is vulnerable to adversarial attacks that add
  fake relationships to evade detection.
---

# IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense

## Quick Facts
- arXiv ID: 2512.20004
- Source URL: https://arxiv.org/abs/2512.20004
- Reference count: 40
- Achieves 98.33% accuracy on CICMaldroid and 98.68% on Drebin datasets using GNN-based Android malware detection with adversarial defense.

## Executive Summary
This paper introduces a Graph Neural Network (GNN)-based method for Android malware detection that leverages API call graph embeddings combined with permission and intent features. The approach demonstrates high detection accuracy on both CICMaldroid and Drebin datasets but is vulnerable to adversarial attacks that add fake relationships to evade detection. To address this, the authors propose VGAE-MalGAN, a GAN-based attack algorithm that generates adversarial malware API graphs while preserving original semantics. Experimental results show that VGAE-MalGAN can significantly reduce detection rates, but retraining the model with adversarial samples improves robustness and helps mitigate such attacks.

## Method Summary
The proposed method involves decompiling APKs using Apktool to extract smali code and manifest files. APIs are extracted with code block IDs, and the top 7000 APIs are selected using Linear Regression feature importance. Local API graphs are built per app based on co-occurrence in code blocks, and a global graph is constructed from the training set. Five centrality features are computed for each node, and a GNN (GCN or GraphSAGE) is trained to generate 32-dimensional embeddings. Permission and intent features are extracted from the manifest and concatenated with the graph embeddings. The final representation is fed into ML classifiers (NB, DT, RF, SVM, 1D-CNN) for malware detection. The VGAE-MalGAN attack is implemented using a modified VGAE generator and GraphSAGE substitute detector to generate adversarial graphs, which are then used to retrain the model for improved robustness.

## Key Results
- Achieves 98.33% accuracy on CICMaldroid dataset and 98.68% on Drebin dataset for Android malware detection.
- VGAE-MalGAN attack can significantly reduce detection rates, demonstrating vulnerability to adversarial manipulation.
- Retraining the model with adversarial samples improves robustness and mitigates the impact of VGAE-MalGAN attacks.

## Why This Works (Mechanism)
The method works by leveraging the structural information in API call graphs, which capture the behavioral patterns of Android applications. By combining these graph embeddings with permission and intent features, the model can effectively distinguish between benign and malicious apps. The VGAE-MalGAN attack exploits the vulnerability of the GNN by injecting fake relationships into the API graphs, causing the model to misclassify malicious apps as benign. Retraining with adversarial samples helps the model learn to recognize and resist such attacks.

## Foundational Learning
- **API call graph embeddings**: Represent the structural relationships between APIs in Android apps, capturing their behavioral patterns. *Why needed*: To encode the app's functionality into a form that can be processed by GNNs. *Quick check*: Verify that the API graph captures meaningful co-occurrence patterns in the code.
- **Graph Neural Networks (GNNs)**: Neural networks designed to operate on graph-structured data, enabling the learning of node representations that incorporate neighborhood information. *Why needed*: To process the API call graphs and extract relevant features for malware detection. *Quick check*: Ensure that the GNN can effectively propagate information through the graph.
- **Adversarial attacks on GNNs**: Techniques that manipulate the input graph to fool the GNN into making incorrect predictions. *Why needed*: To evaluate the robustness of the malware detection system against potential evasion attempts. *Quick check*: Test the model's vulnerability to simple edge/node additions in the API graph.
- **Generative Adversarial Networks (GANs)**: A framework for training generative models by pitting them against discriminative models in a two-player game. *Why needed*: To generate realistic adversarial examples that can effectively evade the malware detection system. *Quick check*: Verify that the generated adversarial graphs preserve the semantic meaning of the original graphs.
- **Graph centrality features**: Measures of the importance or influence of nodes in a graph, such as degree, betweenness, and closeness centrality. *Why needed*: To provide additional information about the structure of the API call graphs that can aid in malware detection. *Quick check*: Confirm that the centrality features capture relevant structural properties of the graphs.

## Architecture Onboarding

**Component Map**
Decompiled APKs -> API extraction -> API graph construction -> Centrality feature computation -> GNN embedding generation -> Concatenation with permissions/intents -> ML classifier -> Malware detection

**Critical Path**
The critical path for malware detection involves extracting APIs from decompiled APKs, constructing API graphs, computing centrality features, generating GNN embeddings, concatenating with permission and intent features, and feeding the final representation into an ML classifier.

**Design Tradeoffs**
- Using a GNN allows for the incorporation of structural information from API call graphs but may be computationally expensive and vulnerable to adversarial attacks.
- Combining graph embeddings with permission and intent features provides a richer representation but increases the dimensionality of the input.
- Retraining with adversarial samples improves robustness but requires additional computational resources and may lead to overfitting.

**Failure Signatures**
- Low detection accuracy on either the CICMaldroid or Drebin dataset, indicating issues with the feature extraction or model training process.
- High vulnerability to adversarial attacks, suggesting that the model is not sufficiently robust to graph-based manipulations.
- Overfitting to the training data, resulting in poor generalization to unseen samples.

**First Experiments**
1. Verify the API extraction and graph construction process by visualizing the API call graphs for a sample of benign and malicious apps.
2. Evaluate the effectiveness of the centrality features by training a simple ML classifier (e.g., Random Forest) on the concatenated graph embeddings and centrality features, and comparing its performance to a classifier trained on graph embeddings alone.
3. Test the vulnerability of the GNN to simple adversarial attacks (e.g., random edge additions) by measuring the change in detection accuracy before and after the attack.

## Open Questions the Paper Calls Out
- How can different feature types or alternative graph embedding generation methods be integrated to create representations that are inherently resistant to adversarial attacks?
- Does the robustness gained from adversarial retraining against VGAE-MalGAN generalize to other attack vectors, such as graph rewiring or node deletion?
- How does the size and complexity of the training dataset influence the vulnerability of the GNN classifier to adversarial manipulation?

## Limitations
- The exact implementation details of the VGAE-MalGAN attack, including training epochs, batch sizes, and convergence criteria, are not fully specified.
- The selection criteria for benign samples used to create adversarial examples are not clearly defined.
- The paper does not provide quantitative results comparing detection rates before and after retraining with adversarial samples, limiting the assessment of the defense's effectiveness.

## Confidence
- High confidence in the overall methodology and evaluation results for the GNN-based malware detection system.
- Medium confidence in the VGAE-MalGAN implementation and adversarial attack effectiveness due to the lack of specific training details and benign sample selection criteria.
- Low confidence in the robustness improvements after retraining with adversarial samples, as the paper does not provide quantitative results comparing detection rates before and after retraining.

## Next Checks
1. Verify the VGAE-MalGAN implementation by reproducing the attack success rates (recall reduction) on a held-out test set and comparing against the paper's reported values.
2. Conduct an ablation study to assess the impact of different benign sample selection strategies on the quality and effectiveness of the generated adversarial examples.
3. Evaluate the robustness of the GNN model after retraining with adversarial samples by testing against a diverse set of adversarial attacks (e.g., random edge additions, node feature perturbations) and comparing the detection rates to the baseline model.