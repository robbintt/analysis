---
ver: rpa2
title: Emerging categories in scientific explanations
arxiv_id: '2505.17832'
source_url: https://arxiv.org/abs/2505.17832
tags:
- explanations
- categories
- dataset
- which
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study addresses the lack of large-scale datasets of human-like,
  human-generated explanations in scientific literature. The authors extracted 340
  explanatory sentences from biotechnology and biophysics literature, then performed
  inductive classification to derive six explanation types: causation, mechanistic
  causation, contrastive, correlation, functional, and pragmatic approach.'
---

# Emerging categories in scientific explanations

## Quick Facts
- arXiv ID: 2505.17832
- Source URL: https://arxiv.org/abs/2505.17832
- Authors: Giacomo Magnifico; Eduard Barbu
- Reference count: 25
- Primary result: Achieved Krippendorff's alpha of 0.667 for inter-annotator agreement after consolidating six explanation categories into three based on causal strength

## Executive Summary
This study addresses the lack of large-scale datasets of human-like, human-generated explanations in scientific literature. The authors extracted 340 explanatory sentences from biotechnology and biophysics literature, then performed inductive classification to derive six explanation types: causation, mechanistic causation, contrastive, correlation, functional, and pragmatic approach. To evaluate annotator consensus, they conducted a classification study on Prolific with 120 annotators rating 272 high-quality sentences. Initial Krippendorff's alpha showed poor agreement between closely related categories, but improved to 0.667 after grouping into strong relation (causation, mechanistic causation), weak relation (correlation, functional, pragmatic), and multipath relation (contrastive) categories.

## Method Summary
The authors extracted 340 explanatory sentences from PubMed PMC Open Access subset in biotechnology and biophysics domains. They performed inductive classification to derive six explanation types, then conducted crowdsourced annotation with 120 Prolific annotators rating 272 high-quality sentences. Initial Krippendorff's alpha showed poor agreement between closely related categories, but improved to 0.667 after grouping into three categories based on causal strength: strong relation (causation, mechanistic causation), weak relation (correlation, functional, pragmatic), and multipath relation (contrastive).

## Key Results
- Initial Krippendorff's alpha showed poor agreement (approximately 0.067) between closely related categories
- After consolidating six categories into three based on causal strength, agreement improved to 0.667
- 120 annotators participated, with approximately 10 valid annotations per sentence
- Dataset is publicly available at the provided GitHub repository

## Why This Works (Mechanism)

### Mechanism 1: Inductive Category Emergence
- Claim: Categories derived from data rather than imposed a priori capture natural explanation structures in scientific text.
- Mechanism: Sentence extraction → pattern analysis → category emergence → validation through annotator consensus. The authors avoided pre-set criteria to explore intrinsic connections between categories and the dataset's subject.
- Core assumption: Scientific explanations possess identifiable structures that emerge organically from domain-specific text.
- Evidence anchors:
  - [abstract]: "providing a multi-class notation derived inductively from the data"
  - [section]: "categorization process was entirely driven by the dataset, in a deductive classification originating from the text and not a superimposition of pre-existing categories upon the dataset"
  - [corpus]: Weak corpus evidence—related papers like the GPT-4o/DeepSeek categorization study use predefined relationship categories rather than inductive discovery.
- Break condition: When domain-specific jargon or highly specialized explanations obscure pattern recognition during category formation.

### Mechanism 2: Causal Strength Clustering Reduces Annotation Ambiguity
- Claim: Grouping fine-grained categories by causal strength (strong/weak/multipath) improves inter-annotator agreement.
- Mechanism: Six categories showed confusion between causation/mechanistic causation and correlation/functional/pragmatic → authors identified "causal strength" as unifying dimension → consolidated to three super-categories → alpha improved from ~0.067 to 0.667.
- Core assumption: Humans more reliably distinguish causal strength levels than subtle semantic distinctions between explanation types.
- Evidence anchors:
  - [abstract]: "improved to 0.667 after grouping into strong relation (causation, mechanistic causation), weak relation (correlation, functional, pragmatic), and multipath relation (contrastive) categories"
  - [section]: "significant disagreement between categories of similar causal strength was observed (causation/mechanistic causation, correlation/functional/pragmatic approach)"
  - [corpus]: WISCA paper similarly addresses consensus-building for interpretability, suggesting broader relevance of agreement-harmonization approaches.
- Break condition: When explanations blur causal strength boundaries (e.g., mechanistic accounts with correlational hedging language like "may contribute to").

### Mechanism 3: Explicit Explanandum Constraint Filters Trailing Explanations
- Claim: Requiring an explicit explanandum (the thing being explained) improves annotation consistency by grounding each explanation.
- Mechanism: Filter sentences where explanandum is named (e.g., "the sky is blue because...") vs. implicit ("this happens because...") → reduces multi-sentence dependencies → clearer annotator task.
- Core assumption: Single-sentence explanations with named targets are more consistently interpretable than distributed explanations.
- Evidence anchors:
  - [abstract]: Not explicitly mentioned.
  - [section]: "only include explanations that presented an explicit explanandum, e.g. 'the sky is blue because of light refraction through the atmosphere' rather than 'this happens due to light refraction through the atmosphere', in order to avoid explanations trailing through multiple sentences"
  - [corpus]: No direct corpus evidence for this specific constraint.
- Break condition: When complex scientific phenomena require multi-sentence exposition to adequately explain.

## Foundational Learning

- Concept: **Explanans/Explanandum Structure**
  - Why needed here: Core theoretical framework; the dataset explicitly filters for explanations with identifiable explanans-explanandum relationships.
  - Quick check question: In "Gene expression increased due to promoter activation," which part is the explanandum?

- Concept: **Krippendorff's Alpha**
  - Why needed here: Primary metric for annotator agreement; 0.667 threshold represents acceptable consensus for this dataset.
  - Quick check question: Why might Krippendorff's alpha be preferred over simple percent agreement for multi-category annotation tasks?

- Concept: **Inductive vs. Deductive Classification**
  - Why needed here: The study's methodology hinges on bottom-up category discovery; understanding this distinction clarifies why categories emerged as they did.
  - Quick check question: What risks arise when pre-existing theoretical categories are imposed on data before exploration?

## Architecture Onboarding

- Component map:
  Data Source -> Sentence Extraction -> Inductive Classification -> Crowdsourced Annotation -> Agreement Analysis -> Category Consolidation

- Critical path:
  1. Domain selection (scientific literature to control for truth/relevance confounds)
  2. Sentence extraction with explicit explanandum filter
  3. Inductive category discovery from extracted sentences
  4. Crowdsourced annotation with redundancy (10+ annotators/sentence)
  5. Agreement analysis → category consolidation based on observed confusion patterns

- Design tradeoffs:
  - Granularity vs. reliability: 6-class schema captures nuance but yields poor agreement; 3-class schema trades detail for consensus
  - Single-sentence vs. context: Explicit explanandum constraint excludes richer multi-sentence explanations
  - Domain specificity vs. generalizability: Biotech/biophysics focus controls complexity but may limit transfer to other fields

- Failure signatures:
  - Krippendorff's alpha substantially below 0.6 indicates category confusion or poor annotation guidelines
  - Systematic confusion between adjacent categories (e.g., causation vs. mechanistic causation) suggests semantic overlap
  - High per-sentence variance in annotations signals ambiguous examples

- First 3 experiments:
  1. Cross-domain validation: Apply the 3-class schema to explanations from physics or chemistry literature; measure whether agreement holds.
  2. Classifier baseline: Train a simple text classifier (e.g., TF-IDF + logistic regression) on the 3-class labels; establish performance benchmark.
  3. Boundary analysis: Manually review sentences with highest annotator disagreement to identify failure modes and refine category definitions.

## Open Questions the Paper Calls Out
None

## Limitations
- The dataset's focus on biotechnology and biophysics literature severely limits generalizability to other scientific fields or everyday explanations
- The explicit explanandum filter excludes potentially richer multi-sentence explanations that may be essential for capturing complex scientific reasoning
- While Krippendorff's alpha of 0.667 represents the minimum for "good" agreement, this value is only marginally above the threshold and may not reflect robust consensus

## Confidence
- **High**: The inductive methodology is sound and well-documented; the dataset is publicly available with clear annotation guidelines
- **Medium**: The category consolidation approach is reasonable but represents a compromise between granularity and reliability; the domain-specific focus limits broader applicability
- **Low**: Claims about the dataset representing "human-like" explanations require further validation, as the constrained sentence structure may not capture the full range of human explanatory behavior

## Next Checks
1. **Cross-domain replicability**: Apply the three-class schema to scientific explanations from physics, chemistry, or social science literature to test whether the strong/weak/multipath categorization holds across domains and whether agreement levels remain stable (target Krippendorff's alpha > 0.7).
2. **Classifier performance benchmark**: Train and evaluate machine learning models (both traditional and transformer-based) on the three-class dataset to establish baseline performance and identify which explanation types are most reliably classified by automated systems.
3. **Expert vs. crowd comparison**: Re-annotate a subset of the dataset with domain experts in biotechnology/biophysics and compare agreement patterns with the crowdsourced annotations to determine whether the observed confusion reflects genuine semantic ambiguity or annotation skill limitations.