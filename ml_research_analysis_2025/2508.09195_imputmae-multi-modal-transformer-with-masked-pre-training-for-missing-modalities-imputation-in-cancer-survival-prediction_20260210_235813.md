---
ver: rpa2
title: 'impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities
  Imputation in Cancer Survival Prediction'
arxiv_id: '2508.09195'
source_url: https://arxiv.org/abs/2508.09195
tags:
- multimodal
- modalities
- data
- survival
- missing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces impuTMAE, a multimodal transformer-based
  approach that addresses missing data in cancer survival prediction by combining
  masked multimodal pretraining with modality-specific encoders and a unified decoder.
  The model simultaneously reconstructs masked patches from RNA-seq, DNA methylation,
  whole-slide images, and MRI data, enabling effective imputation of missing modalities
  without requiring all modalities during training.
---

# impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction

## Quick Facts
- arXiv ID: 2508.09195
- Source URL: https://arxiv.org/abs/2508.09195
- Reference count: 23
- This paper introduces impuTMAE, a multimodal transformer-based approach that addresses missing data in cancer survival prediction by combining masked multimodal pretraining with modality-specific encoders and a unified decoder.

## Executive Summary
This paper introduces impuTMAE, a multimodal transformer-based approach that addresses missing data in cancer survival prediction by combining masked multimodal pretraining with modality-specific encoders and a unified decoder. The model simultaneously reconstructs masked patches from RNA-seq, DNA methylation, whole-slide images, and MRI data, enabling effective imputation of missing modalities without requiring all modalities during training. When evaluated on glioma survival prediction using TCGA and BraTS datasets, impuTMAE achieves state-of-the-art performance with C-index scores up to 0.840 and CS-scores up to 0.870, outperforming previous methods that either do not handle missing data or lack multimodal pretraining. The approach demonstrates robustness across modality subsets and provides a scalable solution for integrating heterogeneous medical data in survival analysis.

## Method Summary
imputMAE employs a two-stage MAE-style framework. During pre-training, modality-specific encoders transform raw inputs (RNA-seq, DNAm, WSI, MRI) into fixed-size latent embeddings, which are concatenated and fed to a unified multimodal decoder that reconstructs masked patches from all available modalities. Missing modalities are treated as fully masked with MASK_TOKEN embeddings. The model is trained with 50% random patch masking per modality using MSE reconstruction loss on masked patches only. For fine-tuning, the pretrained encoders are partially frozen (MRI/WSI fully frozen, 5/6 layers of RNA/DNAm frozen), and a fusion multi-head self-attention block plus linear risk head are added for survival prediction using NLL loss over 20 time intervals.

## Key Results
- impuTMAE achieves C-index up to 0.840 and CS-score up to 0.870 on glioma survival prediction
- Outperforms previous methods by up to 0.047 in CS-score when all modalities are available
- Maintains strong performance (C-index 0.831, CS-score 0.853) when at least RNA-seq is available

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Context Imputation via Joint Reconstruction
- **Claim:** The model generates plausible representations for missing modalities by leveraging statistical correlations learned from available modalities.
- **Mechanism:** During pre-training, the system masks 50% of patches across available modalities while treating entirely missing modalities as 100% masked. The unified decoder is forced to reconstruct all masked patches simultaneously, forcing the encoder to learn inter-modal dependencies so the decoder can reconstruct Target Modality A given only inputs from Modality B.
- **Core assumption:** The latent relationships between modalities are consistent and learnable, allowing the model to hallucinate missing data that is functionally useful for survival prediction even if pixel-level accuracy is approximate.
- **Evidence anchors:** "learns inter- and intra-modal interactions while simultaneously imputing missing modalities by reconstructing masked patches"; "we leverage all available multimodal data... by treating missing modalities as entirely masked... [replaced] with embeddings filled with MASK_TOKEN."
- **Break condition:** If modalities are statistically independent, reconstruction collapses to noise, and imputed data degrades downstream survival prediction accuracy.

### Mechanism 2: Modality-Specific Feature Isolation Before Fusion
- **Claim:** Specialized encoders prevent the "modality gap" problem where high-dimensional imaging data dominates lower-dimensional tabular data.
- **Mechanism:** The architecture employs distinct encoders (e.g., 3D Conv for MRI vs. 1D Conv for RNA) that project inputs into a fixed latent dimension before concatenation, ensuring that the unique statistical structure of omics data is preserved rather than washed out by the spatial complexity of whole-slide images.
- **Core assumption:** There exists an optimal shared latent dimension d where semantic information from heterogeneous sources is comparable.
- **Evidence anchors:** "Each data modality is handled by a dedicated encoder network... transforms the raw input into a latent feature embedding of fixed size (denoted as d)"; "Multimodal Decoder... fed to a multimodal decoder that reconstructs the original inputs... [via] dedicated projection heads."
- **Break condition:** If the latent dimension d is too small, omics data suffers information bottleneck; if too large, imaging data overfits noise.

### Mechanism 3: Pre-training Induced Robustness to Sparsity
- **Claim:** Masked pre-training acts as a regularizer that improves survival prediction fine-tuning, even when data is incomplete.
- **Mechanism:** By training the model to reconstruct randomly masked patches (MSE loss) before training on the survival task (NLL loss), the encoder learns robust feature representations that generalize from limited samples. Ablation shows removing pre-training drops the CS-score from 0.870 to 0.853.
- **Core assumption:** The features required to reconstruct a masked patch (low-level semantics) overlap significantly with features required to predict survival risk (high-level semantics).
- **Evidence anchors:** Table 3 shows "imputMAE +pretraining" (0.870 CS-score) outperforms "imputMAE" without it (0.853 CS-score); "The reconstruction loss... is computed only on the masked patches... [enabling] robust representations that are resilient to missing data."
- **Break condition:** If the reconstruction task is too easy (low masking ratio) or irrelevant to survival, the transfer learning benefits diminish.

## Foundational Learning

- **Concept: Masked Autoencoders (MAE)**
  - **Why needed here:** This is the core engine of impuTMAE. You must understand how masking patches and forcing reconstruction acts as a self-supervised signal that requires no human labels.
  - **Quick check question:** If you mask 90% of an image instead of 50%, does the model learn faster or slower? (Answer: Likely slower/harder; the paper uses 50% to balance difficulty).

- **Concept: Transformer Positional Embeddings (1D vs 3D)**
  - **Why needed here:** The model processes non-standard inputs. RNA is a 1D sequence, while MRI is a 3D volume. Standard Transformers expect 1D tokens. You need to grasp how the model adds "positional info" so the Transformer knows which gene or voxel comes next.
  - **Quick check question:** Why does the MRI encoder need 3D positional embeddings or patching logic distinct from the RNA encoder?

- **Concept: Survival Analysis Loss (NLL vs. MSE)**
  - **Why needed here:** The objective changes between stages. Stage 1 uses MSE to reconstruct pixels/values. Stage 2 uses NLL to predict death risk over time. You cannot use MSE for survival prediction because it doesn't handle "censored" data (patients who didn't die during the study).
  - **Quick check question:** Why can't we just use Cross-Entropy loss for survival prediction? (Hint: Survival data involves time-to-event, not just binary class).

## Architecture Onboarding

- **Component map:**
  1. **Inputs:** RNA-seq, DNAm (1D vectors), WSI (2D patches), MRI (3D volumes), Clinical data
  2. **Encoders (Modality-Specific):**
     - RNA/DNAm: 1D Conv + 6 Transformer layers
     - MRI: 3D Conv + 4 Transformer layers
     - WSI: 2D Conv + 4 Transformer layers
  3. **Fusion/Neck:** Concatenation of latent embeddings [z_RNA, z_DNA, ...]
  4. **Decoder (Pre-train only):** 3 Transformer layers + Modality-specific projection heads (Linear/Transposed Conv)
  5. **Head (Fine-tune only):** Fusion Multi-head Attention + Risk Projection Layer (Linear)

- **Critical path:**
  1. **Data Prep:** Ensure RNA/DNAm are log-transformed and normalized per subject; MRI must be tumor-cropped (64x64x64)
  2. **Pre-training:** Run the Encoder-Decoder loop on TCGA/BraTS data with 50% masking. Save encoder weights
  3. **Imputation (Inference/Finetune):** If a patient lacks MRI, pass available modalities through Encoder -> Decoder to generate synthetic MRI features (or use encoder outputs directly if the model is robust)
  4. **Fine-tuning:** Freeze encoders (fully or partially), attach Fusion Attention + Risk Head, train using NLL loss

- **Design tradeoffs:**
  - **Unified vs. Separate Decoders:** impuTMAE uses one unified decoder for all modalities. This is more parameter-efficient than methods like DRIM (which uses separate decoders) but risks "interference" where reconstruction of one modality degrades another
  - **Freezing Strategy:** The paper freezes WSI/MRI encoders fully but keeps 1/6 layers of RNA/DNAm unfrozen. This assumes imaging features are more generic/transferable, while omics features may need slight adjustment for the specific cohort

- **Failure signatures:**
  - **Collapse to Mean:** Reconstructed modalities look like blurry averages (MSE loss plateau)
  - **Dominance:** Fusion attention ignores clinical/omics data (likely due to scale mismatch with imaging tensors)
  - **Overfitting:** High performance on training subsets, 0.0 C-index on test (common with small medical datasets; mitigate via strict cross-validation)

- **First 3 experiments:**
  1. **Unimodal Baseline:** Train and test the model using only RNA data (highest importance modality) to establish a performance floor (Target C-index > 0.82)
  2. **Ablation on Pre-training:** Compare fine-tuning from scratch vs. fine-tuning from the pre-trained checkpoint to verify the utility of the MAE stage (Expect ~0.02 CS-score drop without pre-training)
  3. **Missing Modality Stress Test:** Systematically remove one modality (e.g., Drop MRI) during testing to verify the imputation mechanism maintains stability (C-index should drop, but not crash)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does impuTMAE generalize to cancer types beyond glioma, particularly those with different multimodal data availability patterns?
- **Basis in paper:** [explicit] The authors evaluate exclusively on glioma using TCGA-GBM/LGG and BraTS datasets, stating their method achieves "state-of-the-art performance in glioma patient survival prediction" without demonstrating applicability to other cancers.
- **Why unresolved:** The paper provides no experiments or discussion of transferability to other tumor types with potentially different modality importance rankings or missing data patterns.
- **What evidence would resolve it:** Evaluation on at least one additional cancer type (e.g., breast, lung) from TCGA with comparable multimodal data, showing C-index and CS-score performance relative to baselines.

### Open Question 2
- **Question:** What is the quality of the imputed modalities themselves, independent of downstream survival prediction performance?
- **Basis in paper:** [inferred] The paper evaluates survival prediction accuracy but does not assess reconstruction fidelity of imputed modalities. The MSE loss during pretraining is computed on masked patches, but no quantitative metrics report how closely imputed RNA-seq, DNAm, MRI, or WSI match ground truth distributions.
- **Why unresolved:** High survival prediction performance could be achieved even with inaccurate imputations if the model learns to rely primarily on available modalities. Clinical utility of imputed data for other downstream tasks remains unknown.
- **What evidence would resolve it:** Report modality-specific reconstruction metrics (e.g., correlation between imputed and actual gene expression values, structural similarity for images) on held-out samples with artificially masked modalities.

### Open Question 3
- **Question:** How does performance scale with the number and combination of missing modalities during inference?
- **Basis in paper:** [inferred] The paper evaluates two conditions (all modalities available; at least RNA present) but does not systematically analyze performance degradation as specific modalities are removed individually or in combination.
- **Why unresolved:** Understanding which modality absences are most detrimental would inform clinical deployment decisions and data collection priorities.
- **What evidence would resolve it:** Ablation study reporting C-index and CS-score for all 16 possible modality availability combinations (2^4 modalities), with analysis of which missing patterns cause largest performance drops.

### Open Question 4
- **Question:** Is the 50% masking ratio optimal, and how sensitive is pretraining quality to this hyperparameter?
- **Basis in paper:** [inferred] The authors state "50% of the patches from each of the four modalities were masked" without justification or ablation comparing alternative ratios (e.g., 25%, 75%).
- **Why unresolved:** The masking ratio directly affects the difficulty of the pretraining task and may influence learned representations' robustness to missing data.
- **What evidence would resolve it:** Ablation experiments varying masking ratio from 25-90%, reporting both reconstruction loss during pretraining and downstream survival prediction metrics after fine-tuning.

## Limitations
- The study only validates on glioma datasets, limiting generalizability claims to other cancer types
- Key architectural hyperparameters (transformer layer configurations, latent dimension d) are not explicitly specified
- Performance metrics rely on synthetic missingness experiments rather than real-world incomplete data scenarios

## Confidence
- **High Confidence**: The core MAE-based imputation mechanism and the two-stage training procedure (pre-training + fine-tuning) are clearly described and well-supported by ablation results
- **Medium Confidence**: Performance metrics (C-index up to 0.840, CS-score up to 0.870) are convincing within the glioma context, but external validation on non-glioma cancers is absent
- **Low Confidence**: Claims about robustness to missing modalities are primarily based on synthetic missingness experiments rather than real-world incomplete data scenarios

## Next Checks
1. **External Dataset Validation**: Test impuTMAE on a non-glioma cancer dataset (e.g., breast or lung cancer) with multimodal data to assess generalizability beyond the reported TCGA/BraTS glioma cohorts
2. **Real-World Missingness Simulation**: Instead of random masking, simulate realistic clinical scenarios where certain modalities are systematically unavailable (e.g., MRI only for patients with advanced disease) to evaluate practical imputation utility
3. **Hyperparameter Sensitivity Analysis**: Systematically vary the latent dimension d and transformer layer configurations to determine robustness to architectural choices not explicitly specified in the manuscript