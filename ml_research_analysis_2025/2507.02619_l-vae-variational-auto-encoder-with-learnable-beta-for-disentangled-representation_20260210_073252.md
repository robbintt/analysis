---
ver: rpa2
title: 'L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation'
arxiv_id: '2507.02619'
source_url: https://arxiv.org/abs/2507.02619
tags:
- loss
- l-vae
- disentanglement
- learning
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Learnable VAE (L-VAE), which learns the\
  \ hyperparameter \u03B2 of \u03B2-VAE automatically during training. The proposed\
  \ method dynamically adjusts the weights of the reconstruction loss and KL divergence\
  \ terms in the loss function using a multi-task learning approach."
---

# L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation

## Quick Facts
- arXiv ID: 2507.02619
- Source URL: https://arxiv.org/abs/2507.02619
- Reference count: 40
- Primary result: L-VAE learns β hyperparameter automatically, achieving state-of-the-art disentanglement without manual tuning

## Executive Summary
This paper introduces Learnable VAE (L-VAE), which automatically learns the hyperparameter β of β-VAE during training. The method dynamically adjusts the weights of reconstruction loss and KL divergence terms using a multi-task learning approach based on learned uncertainties. Experimental results demonstrate that L-VAE consistently outperforms or matches state-of-the-art disentanglement methods across multiple datasets without requiring extensive hyperparameter search.

## Method Summary
L-VAE extends the standard VAE framework by introducing learnable parameters σ₀ and σ₁ that weight the reconstruction loss and KL divergence terms respectively. The total loss is formulated as L = (1/σ₀²)L_R + (1/σ₁²)D_KL + Σσ²ᵢ, where the inverse variance weighting (1/σ²) acts as adaptive task importance and the regularization term Σσ²ᵢ prevents weight collapse. Both σ parameters are optimized alongside network weights using gradient descent, allowing the reconstruction-KL tradeoff to evolve dynamically during training.

## Key Results
- L-VAE achieves disentanglement performance matching or exceeding state-of-the-art methods on dSprites, MPI3D, Falcor3D, and Isaac3D
- Learned β values reveal that β < 1 can sometimes yield better disentanglement, challenging conventional assumptions
- Qualitative experiments on CelebA demonstrate successful disentangling of facial attributes
- The learned weights converge to stable values after approximately 50K iterations

## Why This Works (Mechanism)

### Mechanism 1: Multi-Task Loss Weighting via Learnable Uncertainties
Treating reconstruction and KL divergence as separate tasks with learned weights automatically balances their competing objectives. The loss function L = (1/σ₀²)L_R + (1/σ₁²)D_KL + Σσ²ᵢ learns σ parameters alongside network weights. The inverse variance weighting (1/σ²) acts as adaptive task importance, while the regularization term Σσ²ᵢ prevents either weight from collapsing to zero or exploding. Core assumption: The homoscedastic uncertainty formulation from Kendall et al. [19] transfers from multi-task vision to VAE loss balancing.

### Mechanism 2: Dynamic Weight Evolution During Training
Allowing β-equivalent weights to change during training captures different optimal tradeoffs at different training stages. σ parameters are optimized via gradient descent with the network, enabling the reconstruction-KL balance to shift as the model learns. Early training may favor reconstruction; later stages can emphasize disentanglement as latent structure emerges. Core assumption: The optimal reconstruction-disentanglement tradeoff is non-stationary across training.

### Mechanism 3: Dataset-Dependent Optimal β Discovery
The learned β-equivalent (σ²₀/σ²₁) reveals that optimal β varies across datasets and can be < 1. By learning rather than specifying β, L-VAE discovers that MPI3D and Isaac3D benefit from β < 1 (reconstruction weighted higher), while dSprites and Falcor3D prefer β > 1. This contradicts the common assumption that β > 1 always improves disentanglement. Core assumption: No universal β value works across all datasets; the optimal tradeoff is data-dependent.

## Foundational Learning

- **Concept: Evidence Lower Bound (ELBO) in VAEs**
  - Why needed here: L-VAE modifies the ELBO formulation; understanding the reconstruction term (likelihood) and KL divergence (prior matching) is prerequisite
  - Quick check question: Can you explain why maximizing ELBO approximates maximum likelihood training?

- **Concept: β-VAE and the Disentanglement-Reconstruction Tradeoff**
  - Why needed here: L-VAE directly addresses β-VAE's limitations; you must understand how increasing β improves disentanglement at reconstruction's expense
  - Quick check question: What happens to reconstruction quality as β increases from 1 to 10 in β-VAE?

- **Concept: Gradient-Based Hyperparameter Optimization**
  - Why needed here: The σ parameters are hyperparameters learned via gradient descent; understanding how this differs from manual tuning is essential
  - Quick check question: Why can σ be optimized via backpropagation but traditional hyperparameters like learning rate typically cannot?

## Architecture Onboarding

- **Component map:**
  Input → Encoder → [μ, log σ²] → Sample z → Decoder → Reconstruction
                    ↓
  Loss = (1/σ₀²)·MSE + (1/σ₁²)·KL(z||prior) + σ₀² + σ₁²
                    ↑
              Learnable σ₀, σ₁ (initialized to 1, added to optimizer)

- **Critical path:**
  1. Initialize σ₀ = σ₁ = 1.0 (both added to Adam optimizer)
  2. Forward pass computes reconstruction loss and KL divergence separately
  3. Weight each term by inverse variance (1/σ²)
  4. Add regularization Σσ²ᵢ to total loss
  5. Backpropagate through network weights AND σ parameters

- **Design tradeoffs:**
  - Latent dimension selection: Paper sets L = number of ground truth factors (5-9 depending on dataset). Assumption: you know or can estimate factor count. Alternative: over-specify and allow unused dimensions
  - σ initialization: Paper uses σᵢ = 1 (equivalent to β = 1). Assumption: neutral starting point. Risk: if optimal β is far from 1, convergence may be slow
  - Regularization strength: Paper uses Σσ²ᵢ. This is soft constraint; no hard bounds on σ values. Could add explicit clipping if weights diverge

- **Failure signatures:**
  - σ collapse to zero: Regularization too weak; loss becomes undefined (division by zero). Monitor σ values during training
  - σ explosion: One loss term dominates entirely; reconstruction or disentanglement fails completely
  - No disentanglement improvement: σ₁ stays near 1, model behaves like vanilla VAE. Check if KL term is being computed correctly
  - High reconstruction loss with good disentanglement: May indicate σ₀ is being suppressed; verify regularization balance

- **First 3 experiments:**
  1. Baseline comparison: Train vanilla VAE, β-VAE (β=2,4), and L-VAE on dSprites. Compare reconstruction loss and β-VAE disentanglement metric. Expect L-VAE to match or beat β-VAE without manual β search
  2. Learned β analysis: After training L-VAE, compute β̂ = σ²₀/σ²₁. Train a separate β-VAE with this fixed β. Compare to verify dynamic weighting provides benefit (should see L-VAE outperform fixed-β ablation per Table 3)
  3. σ trajectory monitoring: Log σ₀, σ₁, and β̂ every 1000 iterations. Verify they converge (around 50K iterations per Figure 3) rather than oscillating or diverging. If diverging, reduce learning rate for σ parameters specifically

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does relying on the β-VAE metric for validation model selection bias the reported performance comparisons?
- Basis in paper: [explicit] Section 6.5 states that selecting hyperparameters based on a specific measure brings "strong bias toward the selected measure," making the definition of "optimal" ambiguous
- Why unresolved: The authors selected the best models based on β-VAE scores, which may artificially inflate L-VAE's performance on that specific metric compared to others (e.g., MIG or SAP)
- What evidence would resolve it: A comparison using an aggregation of disentanglement metrics or a downstream task performance metric for model selection rather than a single disentanglement score

### Open Question 2
- Question: Can L-VAE quantitatively disentangle complex factors in natural images without sacrificing reconstruction fidelity?
- Basis in paper: [inferred] Section 8 presents results on CelebA (natural images) only qualitatively via latent traversals, while quantitative results (Section 7.2) are restricted to synthetic datasets
- Why unresolved: The trade-off dynamics on natural images with correlated attributes (like facial features) may differ significantly from the synthetic datasets used for quantitative benchmarking
- What evidence would resolve it: Reporting quantitative disentanglement metrics and reconstruction losses on complex datasets like CelebA or FFHQ

### Open Question 3
- Question: Under what data generation conditions does an optimal learned β fall below 1?
- Basis in paper: [explicit] Section 7.1 notes that finding β̂ < 1 (e.g., in Isaac3D) is "counter-intuitive" and contradicts the prevailing assumption that β > 1 is required for disentanglement
- Why unresolved: The paper identifies the phenomenon empirically but does not offer a theoretical explanation for why weighting reconstruction higher than KL divergence aids disentanglement in specific datasets
- What evidence would resolve it: A theoretical analysis linking data properties (e.g., factor correlation or noise levels) to the optimal weighting of reconstruction vs. KL terms

## Limitations
- The transferability of homoscedastic uncertainty weighting from multi-task vision to VAE loss balancing remains theoretically underexplored
- The finding that β < 1 can improve disentanglement may be dataset-specific and requires more extensive validation on naturalistic datasets
- The ablation study doesn't fully isolate whether the multi-task learning formulation or simply having an extra degree of freedom drives the improvement

## Confidence

- **High Confidence:** The core mechanism of learning σ parameters alongside network weights is straightforward and well-implemented. The experimental results showing L-VAE consistently matches or outperforms baseline methods are robust across multiple datasets and metrics
- **Medium Confidence:** The claim that β < 1 can improve disentanglement is supported by learned β values but requires more extensive validation across diverse datasets. The interpretation of what drives this phenomenon (dataset structure vs. general principle) remains speculative
- **Medium Confidence:** The ablation study showing dynamic weighting outperforms fixed β is compelling but doesn't fully isolate whether the multi-task learning formulation or simply having an extra degree of freedom drives the improvement

## Next Checks
1. Cross-dataset Generalization Test: Train L-VAE on CelebA or 3D Shapes (more naturalistic than synthetic datasets) and compare learned β to ground truth factor structure. This would test whether β < 1 finding extends beyond structured datasets
2. Ablation of Regularization Term: Remove the Σσ²ᵢ regularization and observe whether σ parameters still converge to meaningful values. This would isolate whether the regularization is essential for stable weight learning or if the optimization dynamics alone suffice
3. Per-dimension Weighting Extension: Modify L-VAE to learn separate σ parameters for each latent dimension's KL term, then compare to the global weighting approach. This would test whether the single global β-equivalent is sufficient for complex datasets with heterogeneous factor relationships