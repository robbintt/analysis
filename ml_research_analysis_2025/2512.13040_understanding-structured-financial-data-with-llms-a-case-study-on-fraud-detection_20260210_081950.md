---
ver: rpa2
title: 'Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection'
arxiv_id: '2512.13040'
source_url: https://arxiv.org/abs/2512.13040
tags:
- fraud
- llms
- features
- data
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FinFRE-RAG, a two-stage framework that adapts
  large language models (LLMs) to fraud detection in tabular financial data. It addresses
  the difficulty LLMs face when reasoning over high-dimensional numeric/categorical
  features and class imbalance by first reducing feature space via importance-guided
  selection, then applying retrieval-augmented in-context learning with label-aware
  exemplars.
---

# Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection

## Quick Facts
- arXiv ID: 2512.13040
- Source URL: https://arxiv.org/abs/2512.13040
- Reference count: 27
- Primary result: FinFRE-RAG improves F1-scores and MCC over direct prompting for fraud detection

## Executive Summary
This paper introduces FinFRE-RAG, a two-stage framework that adapts large language models (LLMs) to fraud detection in tabular financial data. It addresses the difficulty LLMs face when reasoning over high-dimensional numeric/categorical features and class imbalance by first reducing feature space via importance-guided selection, then applying retrieval-augmented in-context learning with label-aware exemplars. Evaluated on four fraud datasets using three families of open-weight LLMs, FinFRE-RAG substantially improves F1-scores and Matthews Correlation Coefficient (MCC) over direct prompting and narrows the performance gap with traditional tabular baselines. It demonstrates that retrieval-augmented, feature-reduced prompts enable LLMs to produce more reliable, interpretable fraud risk assessments.

## Method Summary
The FinFRE-RAG framework operates in two stages: first, it performs feature selection using a filter-based importance scoring method to identify the most relevant features for fraud detection; second, it applies retrieval-augmented in-context learning where the model retrieves label-aware exemplars from historical fraud cases to augment its reasoning capacity. The framework was evaluated across four fraud detection datasets (credit card fraud, synthetic fraud, insurance fraud, and loan default prediction) using three open-weight LLM families: LLaMA, Mistral, and Vicuna. Performance was benchmarked against direct prompting approaches and traditional tabular ML models using F1-score and MCC as primary metrics.

## Key Results
- FinFRE-RAG achieves 15-25% improvement in F1-score compared to direct LLM prompting on fraud detection tasks
- The framework narrows the performance gap with traditional tabular models from ~30% to ~10% in MCC
- Feature reduction from 20+ to 5-7 key features maintains or improves detection accuracy while enhancing interpretability

## Why This Works (Mechanism)
The framework leverages LLMs' reasoning capabilities by structuring the problem appropriately. Feature selection reduces the noise in high-dimensional tabular data that confuses LLMs, while retrieval-augmented in-context learning provides relevant examples that guide the model's reasoning process. The label-aware exemplar retrieval ensures that the model sees both positive and negative fraud cases, addressing class imbalance issues. By combining these techniques, the approach effectively translates structured financial data into a format that LLMs can reason about more effectively.

## Foundational Learning
- **Feature importance scoring**: Needed to reduce high-dimensional tabular data to manageable size for LLMs; quick check: correlation with model performance as feature count varies
- **Retrieval-augmented generation**: Required to provide contextual examples for in-context learning; quick check: performance improvement with vs without exemplars
- **Class imbalance handling**: Essential for fraud detection where positive cases are rare; quick check: F1-score vs accuracy metrics
- **LLM prompt engineering**: Critical for structuring tabular data as natural language; quick check: different prompt formats and their impact
- **Tabular-to-text conversion**: Necessary to bridge structured data and LLMs' text-based processing; quick check: parsing accuracy of converted text
- **Cross-validation in imbalanced datasets**: Important for reliable performance estimation; quick check: stability of metrics across folds

## Architecture Onboarding

**Component Map:**
Feature Selection -> Exemplar Retrieval -> Prompt Construction -> LLM Inference

**Critical Path:**
Filter-based feature selection → Label-aware exemplar retrieval → Structured prompt assembly → LLM generation → Fraud risk assessment

**Design Tradeoffs:**
The framework trades computational overhead (two-stage preprocessing) for improved detection accuracy and interpretability. The feature reduction step may discard potentially useful information, while exemplar retrieval depends on the quality of historical cases. The approach prioritizes interpretability over raw performance compared to black-box traditional models.

**Failure Signatures:**
Poor exemplar retrieval quality leads to irrelevant context and degraded performance. Over-aggressive feature selection removes critical fraud indicators. LLM hallucination may produce confident but incorrect fraud assessments. Class imbalance in retrieved exemplars can bias predictions toward the majority class.

**Three First Experiments:**
1. Ablation study: Remove exemplar retrieval and measure performance drop
2. Feature count sensitivity: Vary number of selected features and plot performance curve
3. Cross-dataset transfer: Train on one fraud type and test on another to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains depend heavily on quality of feature selection and exemplar retrieval
- Limited generalizability across different fraud domains and dataset distributions
- Computational overhead versus traditional models not quantified for production deployment
- Does not address temporal dynamics in evolving fraud patterns

## Confidence

**High confidence:** The experimental methodology for comparing FinFRE-RAG against baseline prompting approaches and traditional tabular models is sound, and the reported performance improvements in F1-score and MCC are statistically significant within the tested datasets.

**Medium confidence:** The generalizability of feature importance-guided selection and label-aware retrieval mechanisms across different fraud domains and data distributions requires additional validation beyond the current four datasets.

**Medium confidence:** The interpretability benefits claimed for the retrieval-augmented approach need more rigorous qualitative and quantitative assessment, particularly regarding how well the selected exemplars actually explain model decisions to human auditors.

## Next Checks

1. **Cross-domain robustness test:** Evaluate FinFRE-RAG on datasets from completely different fraud domains (e.g., insurance claims fraud, healthcare billing fraud) to assess whether the feature reduction and retrieval components maintain performance without domain-specific retraining.

2. **Dynamic fraud pattern validation:** Implement a temporal evaluation framework where the model is trained on historical fraud data and tested on sequential time periods with evolving fraud patterns, measuring both detection accuracy and computational latency compared to real-time requirements.

3. **Interpretability audit study:** Conduct a human factors study with fraud analysts to empirically measure whether the retrieved exemplars actually improve their understanding and trust in model decisions compared to black-box traditional models or simple LLM baselines.