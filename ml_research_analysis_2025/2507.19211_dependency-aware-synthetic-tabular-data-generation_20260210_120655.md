---
ver: rpa2
title: Dependency-aware synthetic tabular data generation
arxiv_id: '2507.19211'
source_url: https://arxiv.org/abs/2507.19211
tags:
- data
- hfgf
- synthetic
- features
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The authors address the challenge of preserving inter-attribute
  dependencies, specifically functional dependencies (FDs) and logical dependencies
  (LDs), in synthetic tabular data generation. While existing generative models often
  fail to maintain these structured relationships, the proposed Hierarchical Feature
  Generation Framework (HFGF) introduces a two-step method: generating independent
  features using standard generative models and reconstructing dependent features
  based on predefined FD and LD rules.'
---

# Dependency-aware synthetic tabular data generation

## Quick Facts
- **arXiv ID:** 2507.19211
- **Source URL:** https://arxiv.org/abs/2507.19211
- **Reference count:** 40
- **Primary result:** Hierarchical Feature Generation Framework (HFGF) improves preservation of functional and logical dependencies in synthetic tabular data while maintaining distributional fidelity.

## Executive Summary
Existing generative models for tabular data often fail to preserve inter-attribute dependencies, particularly functional dependencies (FDs) and logical dependencies (LDs). The Hierarchical Feature Generation Framework (HFGF) addresses this by separating features into independent and dependent sets, generating independent features with standard models, and reconstructing dependent features using predefined dependency rules. Evaluated across four benchmark datasets and six generative models, HFGF significantly improves dependency preservation—for example, increasing FD preservation from 0% to 75% in one case—while maintaining distributional fidelity in low-dimensional space.

## Method Summary
The method involves identifying independent features (IFs) and dependent features (DFs) using either a configuration dictionary or the FDTool. Standard generative models (CTGAN, TVAE, etc.) are trained only on IFs, reducing the complexity of the learning task. Dependent features are then reconstructed deterministically or probabilistically based on predefined FD and LD rules. The final synthetic dataset combines the generated IFs with reconstructed DFs, preserving both the structural dependencies and the marginal distributions of the original data.

## Key Results
- HFGF improved FD preservation across all four benchmark datasets, with increases from 0% to 75% in one case.
- All LDs were preserved when using HFGF, whereas baseline models failed to maintain any LDs.
- Distributional fidelity in 2D PCA space improved, with synthetic data distributions closely resembling real data (p-values > 0.05).
- The framework consistently outperformed baseline models across multiple generative models (CTGAN, TVAE, GReaT, etc.).

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reducing generative model scope to independent features only improves dependency preservation.
- Mechanism: By separating features into independent (IFs) and dependent (DFs), the generative model learns a simpler, lower-dimensional distribution. DFs are reconstructed deterministically via explicit mapping rules rather than inferred, eliminating contradictions that would violate FDs/LDs.
- Core assumption: Dependencies are known a priori (or extractable via FDTool/Q-function) and the independent feature set is non-empty and uncorrelated.
- Evidence anchors:
  - [abstract] "The framework first generates independent features using any standard generative model, and then reconstructs dependent features based on predefined FD and LD rules."
  - [section 3] "Rather than modeling all features, we restrict the generative process to only the independent features... the number of independent features is small and these features are uncorrelated."
  - [corpus] Related work (e.g., "Not All Features Deserve Attention") identifies sparse feature-level dependencies in tabular data, supporting the premise that not all features require joint modeling.
- Break condition: If all features are mutually dependent (no clear IFs), the framework cannot reconstruct structure.

### Mechanism 2
- Claim: Deterministic reconstruction enforces exact FD preservation.
- Mechanism: DFs are generated by applying mapping rules from the config dictionary to synthetic IFs. Since FDs are deterministic (one-to-one, many-to-one), this guarantees that if the IF distribution is captured, FDs are preserved by construction.
- Core assumption: Mapping rules are correctly specified and the generative model produces all required categorical classes in IFs.
- Evidence anchors:
  - [section 3] "Dependent features are reconstructed by applying the mapping rules specified in the configuration dictionary... The reconstruction process is applied recursively to all dependent features, preserving the defined FDs and LDs."
  - [section 4] "Incorporating HFGF with generative models improves both FDs and LDs in synthetic tabular data."
  - [corpus] Weak direct corpus evidence on deterministic reconstruction; related work focuses on learned dependencies rather than rule-based enforcement.
- Break condition: If the generative model fails to produce certain categorical classes in IFs, any DFs relying on them will miss dependency mappings.

### Mechanism 3
- Claim: Hierarchical generation improves distributional fidelity in low-dimensional space.
- Mechanism: By constraining the generative model to IFs, the learned distribution is closer to the true marginal distribution of independent features. Combined with deterministic DFs, the joint distribution aligns better with real data in PCA space.
- Core assumption: IFs are representative of the dataset's core variability; DFs add structure without distorting the global distribution.
- Evidence anchors:
  - [section 5, Figure 3] "The two-dimensional PCA projections of synthetic data generated with HFGF more closely resemble the real data distribution... p-values above 0.05 indicate statistical similarity."
  - [abstract] "HFGF can significantly enhance the structural fidelity and downstream utility of synthetic tabular data."
  - [corpus] Related work on evaluating synthetic data (e.g., "What's Wrong with Your Synthetic Tabular Data?") notes conflicting quality metrics; HFGF explicitly targets structural fidelity.
- Break condition: If IFs are poorly chosen or imbalanced, distributional fidelity gains may not translate to downstream utility.

## Foundational Learning

- Concept: Functional Dependencies (FDs)
  - Why needed here: Understanding deterministic relationships (one-to-one, many-to-one) is essential to identify which features can be reconstructed rather than generated.
  - Quick check question: Given feature A determines feature B uniquely, can you identify which is independent?

- Concept: Logical Dependencies (LDs)
  - Why needed here: Rule-based constraints (one-to-many with probabilities) require probabilistic reconstruction, not deterministic mapping.
  - Quick check question: If feature A constrains but does not uniquely determine feature B, how would you sample B?

- Concept: Generative Model Limitations for Tabular Data
  - Why needed here: Models like CTGAN, TVAE, and GReaT optimize for distributional similarity, not structural integrity; understanding this gap motivates the need for HFGF.
  - Quick check question: Why might a generative model violate an FD even if it captures marginal distributions well?

## Architecture Onboarding

- Component map:
  1. Config dictionary (defines features, types, ranges, dependencies, mappings)
  2. Benchmark data generator (Algorithm 1)
  3. Independent feature generator (any standard generative model)
  4. Dependent feature reconstructor (applies mapping rules)
  5. Evaluator (FDTool for FDs, Q-function for LDs, PCA + Peacock test for distribution)

- Critical path: Config definition → IF identification → generative model training on IFs → DF reconstruction via mappings → concatenation → evaluation.

- Design tradeoffs:
  - Assumes dependencies are known or extractable; not suitable for fully mutual dependencies.
  - Only handles categorical-to-categorical dependencies; numerical-categorical interactions require discretization.
  - Reduces generative model complexity but introduces manual specification overhead.

- Failure signatures:
  - FD preservation drops if IFs are imbalanced or missing classes.
  - LD preservation fails if mapping probabilities are misspecified.
  - Framework inapplicable if no independent features exist.

- First 3 experiments:
  1. Replicate Case 1 (100 rows, 7 features, 4 FDs, 64 LDs) with CTGAN; verify FD/LD preservation without HFGF, then add HFGF and confirm improvement.
  2. Test with increased dataset size (Case 2, 1000 rows); observe whether larger data improves baseline generative model FD/LD preservation without HFGF.
  3. Introduce feature imbalance (Case 4); confirm that HFGF maintains FD/LD preservation where baseline models degrade.

## Open Questions the Paper Calls Out
None

## Limitations
- The framework assumes dependencies are known or can be extracted a priori; no mechanism is provided for dependency discovery from real data.
- Numerical-categorical dependencies are not supported without discretization, limiting applicability to datasets with mixed-type dependencies.
- The method's effectiveness depends on the independence of IFs; in datasets with fully mutual dependencies, the framework cannot be applied.

## Confidence
- **High:** The core mechanism of separating IFs from DFs and deterministic reconstruction for FD preservation is well-supported by the paper's empirical results.
- **Medium:** The improvement in distributional fidelity (PCA alignment) is supported by results but could be more thoroughly validated with additional statistical tests.
- **Low:** The claim that HFGF "can significantly enhance downstream utility" is not directly validated with downstream task performance metrics.

## Next Checks
1. Validate dependency preservation on a real-world dataset (e.g., Adult Census) where FDs/LDs can be extracted and compared against synthetic data generated with and without HFGF.
2. Test the framework's robustness to imbalanced IFs by intentionally undersampling certain categories and measuring FD/LD preservation degradation.
3. Evaluate downstream task performance (e.g., classification accuracy) on synthetic data generated with HFGF versus baseline models to confirm utility improvements.