---
ver: rpa2
title: 'GANGR: GAN-Assisted Scalable and Efficient Global Routing Parallelization'
arxiv_id: '2511.17665'
source_url: https://arxiv.org/abs/2511.17665
tags:
- nets
- routing
- batches
- batch
- batching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces GANGR, a deep learning-assisted batching framework
  for global routing in electronic design automation. The key innovation is using
  Wasserstein generative adversarial networks (WGANs) to replace traditional heuristic-based
  batching methods, enabling more effective parallelization by generating fewer, higher-quality
  batches in less time.
---

# GANGR: GAN-Assisted Scalable and Efficient Global Routing Parallelization

## Quick Facts
- arXiv ID: 2511.17665
- Source URL: https://arxiv.org/abs/2511.17665
- Authors: Hadi Khodaei Jooshin; Inna Partin-Vaisband
- Reference count: 13
- Primary result: Up to 40% runtime reduction compared to InstantGR with only 0.002% degradation in routing quality

## Executive Summary
GANGR introduces a deep learning-assisted batching framework for global routing in electronic design automation. The key innovation uses Wasserstein generative adversarial networks (WGANs) to replace traditional heuristic-based batching methods, enabling more effective parallelization by generating fewer, higher-quality batches in less time. Experiments on ISPD'24 benchmarks demonstrate significant scalability improvements while maintaining competitive wirelength, via count, and congestion metrics.

## Method Summary
GANGR replaces heuristic-based net batching in global routing with WGAN-based batching to generate fewer, higher-quality batches for parallel processing. The method uses pin coordinate features (16-dimensional vectors) as input to a WGAN generator that produces soft clustering probability distributions over batch assignments. During inference, nets are assigned to batches via argmax of predicted probabilities. The framework includes adaptive evaluation for conflict detection using layer-aware 3D overlap detection and greedy reallocation of conflicting nets. Training data comes from 177k NVDLA nets routed with modified InstantGR.

## Key Results
- 40% runtime reduction compared to state-of-the-art InstantGR framework
- Only 0.002% degradation in routing quality (weighted score)
- Generates 68 batches vs 383 in InstantGR for benchmark #12 (82% fewer)
- Maintains competitive wirelength, via count, and congestion metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: WGAN-based batching replaces heuristic methods to generate fewer, higher-quality batches by learning spatial interference patterns.
- Mechanism: WGAN generator produces soft clustering probability distributions over batch assignments, trained with composite loss (segment overlap, pin overlap, center distance). Nets assigned via argmax(P) during inference.
- Core assumption: Pin coordinate features provide sufficient signal to predict non-overlapping batch membership without explicit routing segment information.
- Break condition: Complex topologies where pin positions poorly predict segment conflicts increase reallocation burden.

### Mechanism 2
- Claim: Layer-aware 3D overlap detection increases parallelism by flagging conflicts only within same metal layer.
- Mechanism: Compares horizontal/vertical segments only within matching metal layers using thread-local 3D visibility arrays for constant-time conflict checks.
- Core assumption: Nets with overlapping segments on different metal layers can be safely routed in parallel.
- Break condition: Routing resource congestion at layer transition points may still cause failures downstream.

### Mechanism 3
- Claim: Adaptive memory management with dense/sparse representations and greedy reallocation maintains scalability.
- Mechanism: Dense 3D arrays used when memory permits; switches to sparse hash sets for large designs. Greedy reallocation assigns conflicting nets to existing batches or creates new ones.
- Core assumption: Greedy reallocation produces near-optimal batch assignments without global optimization.
- Break condition: High net density where most nets conflict may create many small batches, reducing parallelism gains.

### Mechanism 4
- Claim: Custom loss function with domain-specific constraints enforces spatial separation during WGAN training.
- Mechanism: `L_final` combines segment overlap loss, center penalty loss, and pin overlap loss during adversarial training with 5:1 critic-to-generator updates.
- Core assumption: Hand-crafted loss weights generalize across different benchmark characteristics.
- Break condition: Mis-calibrated loss weights for new benchmark distributions may converge to poor local minima.

## Foundational Learning

- Concept: **Global routing and batching in EDA**
  - Why needed here: Understanding net batching as a parallelization strategy for routing is essential to grasp the motivation for replacing heuristics with WGANs.
  - Quick check question: Can you explain why grouping non-overlapping nets into batches enables parallel routing?

- Concept: **Wasserstein GANs with gradient penalty (WGAN-GP)**
  - Why needed here: GANGR uses WGAN-GP architecture; understanding generator/critic dynamics and Wasserstein distance is essential for debugging training instability.
  - Quick check question: Why does WGAN-GP use gradient penalty instead of weight clipping, and how does the critic loss differ from standard GAN discriminators?

- Concept: **VLSI metal layers and routing resources**
  - Why needed here: Layer-aware overlap detection relies on understanding that different metal layers provide independent routing resources.
  - Quick check question: In a 6-layer metal stack, why can two nets overlap horizontally on layers 2 and 4 without resource conflict?

## Architecture Onboarding

- Component map:
Input Nets → [Feature Extraction: 16-dim vectors] → [WGAN Generator: batch probabilities] → [Argmax Assignment: initial batches] → [Adaptive Evaluation: 3D conflict detection] → [Conflicting Nets → Greedy Reallocation] → [Batch Consolidation → Output Batches]

- Critical path: WGAN inference latency (GPU) → CPU-GPU memory transfers → conflict detection (parallel, thread-local) → sequential greedy reallocation. The greedy reallocation stage is the only non-parallelized bottleneck.

- Design tradeoffs:
  - **Fewer batches vs. conflict rate**: Lower WGAN batch number speeds runtime but may increase conflicts requiring reallocation.
  - **Feature richness vs. inference speed**: Using only pin coordinates reduces accuracy but speeds preprocessing and inference.
  - **Dense vs. sparse storage**: Dense arrays are faster but memory-intensive; sparse hashes scale but add latency per lookup.

- Failure signatures:
  - High conflict rate after WGAN batching (>15–20% reallocation) suggests model underfitting or feature insufficiency.
  - GPU OOM during inference → chunk size too large; reduce `MAX_CHUNK_SIZE`.
  - Many small batches post-consolidation → greedy reallocation failing to find fits; may need to increase `MAX_BATCH_SIZE` or retrain with adjusted loss weights.

- First 3 experiments:
  1. **Reproduction baseline**: Run GANGR on ISPD'24 benchmarks #0–2 with reported settings (n=30, 8 threads); verify ~40% runtime reduction and <0.01% score degradation vs. InstantGR.
  2. **Ablation on WGAN batch number**: Sweep n ∈ {20, 30, 40, 50, 60} on benchmark #4; plot score vs. runtime to confirm n=30 Pareto optimality.
  3. **Feature enrichment test**: Add bounding box dimensions and segment perimeters to feature vectors; measure impact on initial batching accuracy and total conflicts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does expanding the feature vector beyond pin coordinates to include bounding boxes and segment perimeters significantly improve batching accuracy enough to justify the increased preprocessing and inference latency?
- Basis in paper: [explicit] Page 4 notes that only pin coordinates are used to reduce input size and latency, which lowers accuracy, but states "additional spatial characteristics can be included... to improve the accuracy... at runtime cost."
- Why unresolved: The authors prioritized runtime reduction via a minimal feature set and did not quantify the quality trade-offs or overhead associated with richer spatial features.
- What evidence would resolve it: Ablation studies comparing routing quality (overflow, wirelength) and runtime using the 16-coordinate pin input versus an expanded feature set including IoU and segment overlap.

### Open Question 2
- Question: Can a dynamic, benchmark-specific WGAN batch number selection mechanism improve the routing score without negating the runtime benefits observed with a fixed batch count?
- Basis in paper: [explicit] Page 6 states that "assigning benchmark-specific values could further optimize results, this option is not considered here for fair comparison."
- Why unresolved: The paper utilizes a fixed hyperparameter (n=30) across all benchmarks to ensure consistency, leaving the potential gains from adaptive configuration unexplored.
- What evidence would resolve it: Experiments using a heuristic or learning-based method to predict the optimal batch number for each specific circuit, measuring the resulting score and runtime.

### Open Question 3
- Question: How does the model's performance vary when trained on a more diverse dataset or the target design itself compared to training solely on the NVDLA benchmark?
- Basis in paper: [inferred] Page 4 specifies the training dataset is constructed exclusively from "177k nets from the NVLDA benchmark," yet the model is applied to vastly different architectures (e.g., MemPool, TeraPool) in the ISPD'24 benchmarks.
- Why unresolved: While the results show generalization, the paper does not analyze if training on a heterogeneous mix of circuit topologies would improve the ~90% initial batching accuracy or reduce the need for the greedy reallocation stage.
- What evidence would resolve it: Comparative evaluation of model convergence and batching conflict rates when trained on a multi-domain dataset versus the single-domain NVDLA dataset.

## Limitations

- **Major uncertainty in WGAN generalizability**: Training data generated using modified InstantGR may create domain-specific biases that don't transfer to other benchmark sets.
- **Unspecified loss function weights**: Critical weights (w_seg, w_ctr, w_pin) are not provided, significantly impacting model performance if not properly tuned.
- **Layer resource assumption**: Layer-aware overlap detection assumes sufficient metal layer resources, which may not hold in extremely congested designs.

## Confidence

- **High confidence**: Runtime reduction claims (40% vs. InstantGR) are well-supported by Table II comparisons across multiple benchmarks with minimal score degradation (0.002%).
- **Medium confidence**: WGAN architecture details are partially specified; while the general framework is clear, specific layer dimensions and training hyperparameters remain unknown.
- **Medium confidence**: Layer-aware conflict detection's effectiveness is theoretically sound but not empirically validated against alternative conflict detection methods in the paper's experiments.

## Next Checks

1. **Cross-benchmark validation**: Test GANGR on non-ISPD benchmarks (e.g., industry designs) to assess whether the WGAN model generalizes beyond the training distribution from modified InstantGR routing data.

2. **Loss function sensitivity analysis**: Systematically vary the segment overlap, center penalty, and pin overlap loss weights to determine their impact on batching quality and identify optimal configurations.

3. **Conflict detection comparison**: Implement and compare the layer-aware method against both bounding box and InstantGR's layer-agnostic approaches on benchmark #6 to quantify false positive/negative rates in conflict detection.