---
ver: rpa2
title: 'SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling'
arxiv_id: '2512.05343'
source_url: https://arxiv.org/abs/2512.05343
tags:
- control
- generation
- conditioning
- spatial
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SpaceControl, a training-free test-time method
  for explicit spatial control of 3D generative modeling. The method enables users
  to control the geometry of generated 3D assets by providing geometric inputs ranging
  from coarse primitives to detailed meshes.
---

# SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling

## Quick Facts
- arXiv ID: 2512.05343
- Source URL: https://arxiv.org/abs/2512.05343
- Authors: Elisabetta Fedele; Francis Engelmann; Ian Huang; Or Litany; Marc Pollefeys; Leonidas Guibas
- Reference count: 15
- Primary result: Training-free test-time spatial control for 3D generative modeling with superior geometric faithfulness

## Executive Summary
SpaceControl introduces a training-free method for explicit spatial control of 3D generative models. The approach enables users to control generated 3D asset geometry by providing geometric inputs ranging from coarse primitives to detailed meshes. By encoding user-specified geometry into the latent space of pretrained generative models like Trellis and using it as explicit guidance, SpaceControl achieves superior geometric faithfulness while maintaining high visual quality. The method introduces a controllable parameter that allows users to trade off between geometric fidelity and output realism.

## Method Summary
SpaceControl works by voxelizing user-provided geometry to 64³ binary occupancy grids, encoding these through the pretrained Trellis encoder E to obtain latent representations, then partially noising these latents to an intermediate timestep t₀ using the forward diffusion equation. The noised latents are then denoised with the original Structure Flow Model from t₀ to 0, guided by text conditioning. A time-step parameter τ₀ controls the trade-off between fidelity to the input geometry and output realism. The method operates in two stages: structure generation (binary occupancy grid) and appearance generation (textures and materials), with geometry control applied only to the first stage.

## Key Results
- Outperforms training-based (Spice-E, SPICE-E-T) and guidance-based (Coin3D) baselines in geometric faithfulness
- Achieves significantly better Chamfer Distance to spatial control (14.0 vs 39.1 for SPICE-E-T on Toys4K)
- Maintains comparable realism metrics (FID) while providing explicit geometric control
- Demonstrated through extensive quantitative evaluation, user studies, and an interactive user interface

## Why This Works (Mechanism)

### Mechanism 1
Injecting geometry through latent noising enables training-free spatial control. The method encodes user-specified geometry into the pretrained encoder's latent space, then "noises up" this latent to an intermediate timestep t₀ using the forward diffusion equation z_t₀ = t₀·z₁ + (1-t₀)·z_c,₀, before denoising with the original Structure Flow Model. This bypasses early denoising steps where structure is determined, preserving geometric priors from the control signal.

### Mechanism 2
A time-step parameter (τ₀) provides continuous interpolation between fidelity and realism. The rescaled timestep t(τ) = λt(τ)/(1 + (λ-1)t(τ)) maps user parameter τ₀ to the diffusion schedule. Lower τ₀ places z_t₀ closer to pure noise, invoking more denoising steps that favor the model's learned prior (higher realism, lower fidelity). Higher τ₀ preserves more of the control latent structure (higher fidelity, potentially lower realism).

### Mechanism 3
Disentangled structure-appearance generation isolates geometry control from texture control. The first stage (Structure FM) generates a binary occupancy grid conditioned on geometry + text. The second stage (Appearance FM) operates only on active voxels from the first stage, using separate latent features and conditioning (text or image). Geometry intervention is applied only to the first stage; appearance generation proceeds normally.

## Foundational Learning

- **Concept: Rectified Flow / Diffusion Models**
  - Why needed here: SpaceControl manipulates the forward/backward diffusion schedule; understanding how noising and denoising shape latent trajectories is essential to reason about τ₀.
  - Quick check question: Given z_t = (1-t)z₀ + tε, what happens to z₀ information as t → 1?

- **Concept: Variational Autoencoders / Latent Spaces**
  - Why needed here: The method relies on encoder E mapping geometry to a latent that aligns with the flow model's manifold.
  - Quick check question: If encoder E had never been trained jointly with the flow model, would latent injection still work? Why or why not?

- **Concept: 3D Representations (Voxels, Meshes, Gaussians)**
  - Why needed here: Inputs are voxelized; outputs can be decoded to multiple formats. Understanding voxel resolution and occupancy grids is needed to interpret CD metrics and failure modes.
  - Quick check question: What geometric information is lost when converting a detailed mesh to a 64³ binary occupancy grid?

## Architecture Onboarding

- **Component map**: Input geometry → voxelizer → encoder E → z_c,₀ → noising (t₀) → Structure FM (DiT-based rectified flow) → denoised z₀ → decoder D → occupancy grid x₀ → Appearance FM (point-wise latent features) → decoder D_O → {GS, RF, Mesh}

- **Critical path**: Voxelization fidelity (resolution 64³) sets upper bound on geometric detail that can be preserved. Encoder E must produce latents within the flow model's support; out-of-distribution geometry may fail. τ₀ selection determines whether the output skews realistic or faithful—manual tuning per use case is currently required.

- **Design tradeoffs**: Higher voxel resolution improves fidelity but increases memory and may exceed encoder training distribution. Uniform τ₀ across the entire object (current limitation) prevents part-aware control; future extension suggested by authors. Training-free approach preserves generalization but precludes learning new geometry-conditioned priors.

- **Failure signatures**: Artifacts in thin or topologically complex regions (e.g., chair legs, antennas) when τ₀ is too high. Texture-geometry mismatch when structure output yields unusual active voxel patterns. Poor generalization on object classes far from Trellis training distribution.

- **First 3 experiments**:
  1. Replicate the Toys4K primitive-conditioned experiment (Table 1): set τ₀ = 6, measure CD and FID vs. baselines to validate implementation.
  2. Ablate τ₀: sweep τ₀ ∈ {0, 2, 4, 6, 8} on a held-out category and plot CD vs. FID to verify tradeoff curve shape matches Figure 3.
  3. Encoder sanity check: replace E with a randomly initialized encoder and confirm that CD degrades significantly, isolating the importance of pretrained alignment.

## Open Questions the Paper Calls Out

- **Can the adherence parameter τ₀ be automated** to select the optimal realism-faithfulness trade-off without per-instance manual tuning? The paper identifies manual selection as a limitation preventing fully autonomous pipelines.

- **Can the control mechanism be extended to support spatially-varying adherence levels** for part-aware generation? The authors propose future work on part-aware control to allow specific regions to deviate freely.

- **How robust is the latent injection technique when the geometric control conflicts semantically with the text prompt?** The interaction between geometry injection and text conditioning under high semantic contradiction is unexplored.

## Limitations
- Single global τ₀ parameter prevents part-aware control, limiting the ability to control different regions of an object independently.
- Method inherits distribution limitations of pretrained Trellis model, failing on objects with unusual topologies.
- Relies on encoder E producing latents within flow model's training distribution; out-of-distribution geometry may produce artifacts.

## Confidence

- **High Confidence**: The tradeoff mechanism (τ₀ ↔ fidelity/ realism) is well-supported by quantitative results and ablation studies.
- **Medium Confidence**: The claim of superior geometric faithfulness is supported by quantitative metrics but relies on Trellis's inherent quality.
- **Low Confidence**: The assumption that E's latents will always align with the flow model's manifold for arbitrary user inputs is weakly supported.

## Next Checks

1. **Out-of-Distribution Stress Test**: Apply SpaceControl to topologically complex or unusual geometries (e.g., thin meshes, meshes with holes) and measure CD/FID degradation compared to standard shapes.

2. **Part-Aware Control Ablation**: Modify the method to apply different τ₀ values to different voxel regions (e.g., using semantic segmentation) and measure whether localized control improves over uniform τ₀.

3. **Encoder Sensitivity Analysis**: Replace the pretrained Trellis encoder E with a randomly initialized encoder and confirm that CD degrades significantly, isolating the importance of pretrained alignment.