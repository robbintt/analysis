---
ver: rpa2
title: Leveraging AI multimodal geospatial foundation models for improved near-real-time
  flood mapping at a global scale
arxiv_id: '2512.02055'
source_url: https://arxiv.org/abs/2512.02055
tags:
- flood
- data
- https
- floodsnet
- mapping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluates the performance of TerraMind, a geospatial
  foundation model, for global flood mapping by fine-tuning it with the multimodal
  FloodsNet dataset containing Sentinel-1 and Sentinel-2 imagery from 85 global flood
  events. Four configurations were tested: base vs.'
---

# Leveraging AI multimodal geospatial foundation models for improved near-real-time flood mapping at a global scale

## Quick Facts
- arXiv ID: 2512.02055
- Source URL: https://arxiv.org/abs/2512.02055
- Reference count: 13
- Primary result: TerraMind GFM fine-tuned on FloodsNet achieves high recall in global flood mapping with multimodal Sentinel-1/Sentinel-2 data

## Executive Summary
This study evaluates TerraMind, a geospatial foundation model, for global flood mapping by fine-tuning it with the multimodal FloodsNet dataset containing Sentinel-1 and Sentinel-2 imagery from 85 global flood events. Four configurations were tested: base vs. large model sizes, with frozen vs. unfrozen backbones. The base unfrozen configuration achieved the best balance of accuracy, precision, and recall at lower computational cost, while the large unfrozen configuration achieved the highest recall. Models trained on FloodsNet outperformed those trained on the Sen1Floods11 dataset in recall. A U-Net baseline achieved higher recall than all GFM configurations but with slightly lower accuracy and precision. These findings demonstrate the promise of multimodal geospatial foundation models for near-real-time flood mapping, highlighting their potential for operationalizing Earth observation data in climate adaptation and disaster resilience.

## Method Summary
The study fine-tuned TerraMind, a geospatial foundation model, using the multimodal FloodsNet dataset containing Sentinel-1 and Sentinel-2 imagery from 85 global flood events. Four configurations were tested: base vs. large model sizes, with frozen vs. unfrozen backbones. The fine-tuning process leveraged contrastive learning to optimize the model for flood detection across diverse geographical regions and flood types. Performance was evaluated against a U-Net baseline and compared with models trained on the Sen1Floods11 dataset. The analysis focused on accuracy, precision, recall, and computational efficiency to determine the optimal configuration for near-real-time flood mapping applications.

## Key Results
- Base unfrozen GFM configuration achieved optimal balance of accuracy, precision, and recall at lower computational cost
- Large unfrozen configuration achieved highest recall but with increased computational requirements
- FloodsNet-trained models outperformed Sen1Floods11-trained models in recall
- U-Net baseline achieved higher recall than all GFM configurations but with slightly lower accuracy and precision

## Why This Works (Mechanism)
The multimodal approach leverages complementary information from both Sentinel-1 (radar) and Sentinel-2 (optical) sensors, capturing flood characteristics across different environmental conditions and times of day. The foundation model architecture, pre-trained on extensive geospatial data, provides a strong starting point that can be efficiently adapted to flood detection through fine-tuning. The contrastive learning framework enables the model to learn robust flood-water boundaries and distinguish between various land cover types under different illumination and weather conditions.

## Foundational Learning
- **Geospatial foundation models**: Pre-trained models on Earth observation data that can be fine-tuned for specific tasks - needed for leveraging large-scale Earth observation datasets; quick check: verify model was pre-trained on diverse EO data
- **Multimodal learning**: Integration of data from multiple sensor types (radar and optical) - needed to handle varying environmental conditions; quick check: confirm both Sentinel-1 and Sentinel-2 data are processed
- **Contrastive learning**: Training approach that learns by comparing similar and dissimilar examples - needed for robust feature learning; quick check: verify contrastive loss is used in training
- **Fine-tuning vs. training from scratch**: Adapting pre-trained models versus training new models - needed for computational efficiency; quick check: confirm training time comparisons
- **Model backbone freezing**: Whether to update lower layers during fine-tuning - needed for controlling computational cost; quick check: verify parameter update counts
- **Flood detection metrics**: Accuracy, precision, and recall evaluation - needed for assessing real-world performance; quick check: confirm confusion matrix calculations

## Architecture Onboarding

Component map: Sentinel-1/Sentinel-2 data -> Preprocessing pipeline -> TerraMind GFM -> Fine-tuning layer -> Classification output

Critical path: Data ingestion and preprocessing -> Model fine-tuning -> Inference and evaluation

Design tradeoffs: Larger models provide better recall but require more computational resources; frozen backbones reduce training time but may limit performance; multimodal inputs increase complexity but improve robustness across conditions

Failure signatures: Poor performance on specific flood types (coastal vs. riverine); degradation in areas with complex land cover; reduced accuracy during sensor limitations (cloud cover for optical sensors)

Three first experiments:
1. Test model performance on a held-out flood event from a different geographical region
2. Evaluate computational requirements for near-real-time processing at different resolutions
3. Compare model performance when using only Sentinel-1 vs. only Sentinel-2 data

## Open Questions the Paper Calls Out
None

## Limitations
- Limited diversity of flood events in training dataset may affect generalizability to unseen flood types
- Performance comparison with U-Net baseline doesn't account for potential domain-specific optimizations
- Computational requirements and practical deployment challenges for near-real-time operational use not explicitly addressed

## Confidence
- High confidence: Comparative performance of different GFM configurations and their trade-offs
- Medium confidence: Superiority of FloodsNet-trained models over Sen1Floods11-trained models
- Medium confidence: Overall promise of multimodal geospatial foundation models pending further validation

## Next Checks
1. Test model performance on a larger, more geographically diverse set of flood events, including different flood types and climate zones
2. Conduct cost-benefit analysis comparing GFM approach with optimized traditional methods for operational deployment
3. Evaluate model performance in near-real-time operational scenarios accounting for data availability and processing time