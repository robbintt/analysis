---
ver: rpa2
title: 'Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving
  Alignment-Critical Circuits'
arxiv_id: '2511.07482'
source_url: https://arxiv.org/abs/2511.07482
tags:
- pruning
- aapp
- refusal
- probe
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of preserving alignment-critical
  safety circuits during dynamic structured pruning of large language models (LLMs),
  where standard pruning methods can degrade safety behaviors like refusal of harmful
  instructions. The authors introduce Alignment-Aware Probe Pruning (AAPP), which
  builds on probe pruning by adding a risk-aware gate that detects adversarial inputs
  and preserves alignment-critical channels based on historical activation patterns
  from benign and harmful prompts.
---

# Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits

## Quick Facts
- arXiv ID: 2511.07482
- Source URL: https://arxiv.org/abs/2511.07482
- Reference count: 8
- This paper addresses the problem of preserving alignment-critical safety circuits during dynamic structured pruning of large language models (LLMs), where standard pruning methods can degrade safety behaviors like refusal of harmful instructions.

## Executive Summary
This paper addresses the problem of preserving alignment-critical safety circuits during dynamic structured pruning of large language models (LLMs), where standard pruning methods can degrade safety behaviors like refusal of harmful instructions. The authors introduce Alignment-Aware Probe Pruning (AAPP), which builds on probe pruning by adding a risk-aware gate that detects adversarial inputs and preserves alignment-critical channels based on historical activation patterns from benign and harmful prompts. Experiments on Llama-2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by up to 50% at matched compute compared to baseline probe pruning, while maintaining lower toxicity and higher classification accuracy. AAPP achieves a better alignment-efficiency trade-off, preserving safety behaviors closer to unpruned models while reducing inference cost.

## Method Summary
AAPP operates through a five-stage pipeline: (1) probe generation from layer-normalized hidden states using residual-importance token selection; (2) probe run several layers ahead; (3) KL gate compares probing states vs historical benign/harmful distributions; (4) if KL_harm - KL_safe ≥ τ_margin, preserve top k_align channels by harmful-history scores; (5) full inference with binary masks applied to o_proj/down_proj channels. The method uses PPsp importance scoring blended with historical general-purpose activation scores, prunes only attention o_proj and MLP down_proj input channels, and excludes first 6 and last 3 layers from pruning.

## Key Results
- AAPP improves refusal rates by up to 50% at matched compute compared to baseline probe pruning
- Maintains lower toxicity and higher classification accuracy than baseline methods
- Achieves better alignment-efficiency trade-off, preserving safety behaviors closer to unpruned models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A risk-aware KL divergence gate can detect adversarial inputs by comparing live probing states to historical activation distributions from benign and harmful prompts.
- **Mechanism:** The method computes two KL divergence values: KL_harm (probing states vs harmful historical) and KL_safe (probing states vs benign historical). When KL_harm − KL_safe ≥ τ_margin, the gate "fires," indicating the input is closer to harmful patterns in activation space. This triggers preservation of alignment-critical channels rather than standard pruning.
- **Core assumption:** Activation patterns of harmful prompts form a distinguishable distribution from benign prompts in the channel energy space, and this separation is preserved during the probe pass.
- **Evidence anchors:**
  - [Methods]: "If KL_harm − KL_safe ≥ τ_margin, we preserve the top k_align channels by hist_jail as we wish to protect channels most active under harmful prompts"
  - [Figure 2]: Shows the KL Gate component comparing probing states to historical safe/harmful states
  - [corpus]: Related work on attribution-guided pruning (arXiv:2506.13727) supports using activation patterns for circuit identification, but does not specifically validate KL-based adversarial detection
- **Break condition:** If harmful and benign prompts produce overlapping activation distributions, or if adversarial inputs don't trigger the harmful pattern, the gate will fail to fire and alignment-critical circuits may be pruned.

### Mechanism 2
- **Claim:** Reserving a fixed fraction of channels (k_align = ⌊align_frac · C⌋) for safety-prioritized selection preserves refusal circuitry when adversarial inputs are detected.
- **Mechanism:** When the KL gate fires, the top k_align channels are selected by hist_jail (historical harmful activation scores) rather than by PPsp importance scores. These channels are "most active under harmful prompts because they include refusal circuitry." The remaining (1−r)C − k_align channels are then filled by descending importance score.
- **Core assumption:** Channels with high activation under harmful prompts causally contribute to refusal behavior; preserving them preserves the refusal circuit.
- **Evidence anchors:**
  - [Methods]: "We keep k=⌈(1−r)C⌉ channels, reserving k_align = ⌊align_frac · C⌋ channels for safety"
  - [Results]: Figure 1 shows AAPP achieving 50% higher refusal rates than PP at r=0.3 on Llama-2-7B
  - [corpus]: Wei et al. [2024] (cited in paper) found removing as little as 3% of parameters can compromise safety, supporting channel-level brittleness
- **Break condition:** If refusal circuits are distributed across many low-activation channels, or if high-activation harmful channels serve other purposes (e.g., harmful content generation), this selection may not preserve the intended circuit.

### Mechanism 3
- **Claim:** Blending live probe scores with historical general-purpose activation scores maintains linguistic functionality while enabling adaptive pruning.
- **Mechanism:** The PPsp importance metric combines |W_final|² with the ℓ2 norm of channel activations. Live scores are blended with stored activation scores from general prompts (C4 dataset), ensuring that channels critical for general language modeling are not accidentally pruned even when focusing on alignment.
- **Core assumption:** General linguistic capability is captured by activation patterns on diverse text corpora, and blending these with task-specific scores balances safety and capability.
- **Evidence anchors:**
  - [Methods]: "For each target with C input channels, we create 3 tensors: general, benign, and harmful using sets of prompts: (1) general prompts to maintain linguistic functionality from C4 dataset"
  - [Table 1]: AAPP maintains higher classification accuracy (0.741 vs 0.624 on Llama-2-7B at r=0.3) compared to PP
  - [corpus]: Corpus papers focus on circuit discovery and pruning for compression but do not validate the blending mechanism specifically
- **Break condition:** If general and alignment-critical circuits substantially overlap, blending may dilute the protection signal; if they are disjoint, the method may still prune capability-critical channels under high prune ratios.

## Foundational Learning

- **Structured vs. Unstructured Pruning:**
  - Why needed here: AAPP operates on input channels (groups of weights), not individual weights. Understanding this distinction is critical for implementing the mask generation and materialization steps.
  - Quick check question: Can you explain why structured pruning yields direct compute savings while unstructured pruning often requires sparse matrix libraries?

- **KL Divergence as Distribution Distance:**
  - Why needed here: The KL gate uses KL divergence to measure how close probing states are to historical harmful vs. benign distributions. Understanding its asymmetry and sensitivity to low-probability regions is essential for tuning τ_margin.
  - Quick check question: If p and q are identical distributions, what is KL(p||q)? What happens when q has near-zero values where p is non-zero?

- **Causal Circuits in LLMs:**
  - Why needed here: The paper assumes specific channels constitute "alignment-critical circuits" for refusal. Understanding circuit analysis helps evaluate whether channel selection actually preserves the causal mechanism.
  - Quick check question: What is the difference between correlation (channels active during refusal) and causation (channels necessary for refusal)?

## Architecture Onboarding

- **Component map:** Probe Generator -> Probe run -> KL Gate -> Channel Selector -> Pruned Inference Engine
- **Critical path:** Probe generation → Probe run (layers ahead) → KL comparison against historical states → Gate decision → Mask generation → Full inference. The KL gate decision is the key branching point; latency overhead from probing must be amortized across the batch.
- **Design tradeoffs:**
  - **align_frac (0.3 default):** Higher values reserve more channels for safety but reduce compute savings. Tuning depends on safety-criticality vs. efficiency requirements.
  - **τ_margin:** Controls gate sensitivity. Too low → false positives, unnecessary compute overhead; too high → false negatives, missed adversarial inputs.
  - **refresh_window (20):** How often historical states are updated. Longer windows reduce overhead but may miss distribution shift.
  - **Layer exclusion (first 6, last 3):** These layers are never pruned, assumed critical for tokenization and output generation.
- **Failure signatures:**
  - **False negative (gate doesn't fire on adversarial input):** Refusal rate drops toward PP baseline; may produce toxic outputs. Check if τ_margin is too high or if adversarial prompts differ from historical harmful prompts.
  - **False positive (gate fires on benign input):** Unnecessary compute overhead, potential over-refusal of legitimate requests. Check if benign historical states are representative.
  - **Linguistic degradation at high prune ratios:** Toxicity scores paradoxically decrease due to incoherent outputs (not true safety). Monitor fluency metrics alongside toxicity.
- **First 3 experiments:**
  1. **Reproduce refusal rate comparison at r=0.3:** Run AAPP and PP on WildJailbreak subset, verify the 50% refusal rate improvement on Llama-2-7B-chat. This validates the core claim and your implementation.
  2. **Ablate align_frac:** Sweep align_frac ∈ {0.1, 0.2, 0.3, 0.4, 0.5} at fixed r=0.3. Plot refusal rate vs. compute to find the Pareto frontier and understand sensitivity.
  3. **Test gate sensitivity:** Vary τ_margin and plot false positive/negative rates using labeled benign/harmful prompts from the held-out WildJailbreak set. This calibrates the detection threshold for your deployment context.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does AAPP maintain its alignment-preserving benefits when scaled to frontier-scale models (70B+ parameters)?
- Basis in paper: [explicit] "Limitations of our study include evaluation at mid-scale model sizes... Future work will extend AAPP to larger models"
- Why unresolved: All experiments were conducted on models between 7B-14B parameters; larger models may have different circuit structures or alignment mechanisms.
- What evidence would resolve it: Evaluation of AAPP on models such as Llama-2-70B or Llama-3-70B, measuring refusal rates and toxicity at comparable compute budgets.

### Open Question 2
- Question: Can the risk-aware gating mechanism generalize to probe pruning frameworks in other contexts beyond safety alignment?
- Basis in paper: [explicit] Future work will "investigate whether similar additions can be made to build upon probe pruning in other contexts"
- Why unresolved: The paper only demonstrates the gating approach for alignment preservation; other constraint-satisfying applications remain unexplored.
- What evidence would resolve it: Demonstrating that similar history-informed gating improves preservation of other targeted behaviors (e.g., reasoning capabilities, domain knowledge) during pruning.

### Open Question 3
- Question: Are the observed reductions in toxicity scores at high pruning ratios genuine safety improvements or artifacts of linguistic degradation?
- Basis in paper: [inferred] "Although toxicity scores decrease at high pruning ratios, this may reflect linguistic degradation rather than improved safety. Pruning can suppress expressive activations, yielding flatter, less coherent text that is rated as less toxic."
- Why unresolved: The paper does not include human evaluation or coherence metrics to disentangle these competing explanations.
- What evidence would resolve it: Human evaluation of response coherence alongside toxicity, or analysis using fluency-controlled toxicity benchmarks.

## Limitations

- **Threshold Sensitivity:** The KL divergence gate's τ_margin threshold is not specified, creating uncertainty about false positive/negative rates.
- **Circuit Identification Validity:** The method assumes channels active during harmful behavior constitute refusal circuits but doesn't verify causal relationships through ablation studies.
- **Dataset Representativeness:** Historical states built from WildJailbreak prompts may not capture novel attack patterns or prompt engineering strategies.

## Confidence

**High Confidence:** The method's core framework of combining probe pruning with alignment-aware channel preservation is technically sound. The KL divergence comparison for adversarial detection follows established distributional analysis principles, and the experimental results demonstrate measurable improvements in refusal rates.

**Medium Confidence:** The claim that AAPP achieves "better alignment-efficiency trade-off" is supported by comparative results, but the experiments don't explore the full Pareto frontier across different prune ratios and align_frac values.

**Low Confidence:** The specific mechanism by which preserved channels actually implement refusal behavior is not empirically validated. The paper assumes high-activation harmful channels contain refusal circuitry but doesn't demonstrate this through ablation studies or circuit analysis.

## Next Checks

1. **Ablation of Circuit Causality:** Run targeted channel ablation experiments where you systematically disable top k_align channels identified by hist_jail on harmful prompts. Measure whether refusal behavior actually degrades proportionally, establishing causal relationships rather than mere correlation.

2. **Gate Calibration on Novel Adversaries:** Create a held-out set of adversarial prompts designed to evade the KL gate (e.g., benign-sounding requests that elicit harmful responses). Measure false negative rates and tune τ_margin to minimize these while controlling false positives on legitimate benign prompts.

3. **Cross-Dataset Distribution Shift:** Test the method on models fine-tuned on different safety datasets (e.g., Anthropic's HH-RLHF or OpenAI's alignment datasets). Evaluate whether the historical state distributions from WildJailbreak generalize or whether model-specific safety circuits require dataset-specific tuning.