---
ver: rpa2
title: 'LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs'
arxiv_id: '2505.18517'
source_url: https://arxiv.org/abs/2505.18517
tags:
- prompt
- arxiv
- audio
- tasks
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces LiSTEN, a framework for adapting LLMs to speech
  and audio tasks using dynamic prompt selection with learnable key-value pairs. The
  approach enables the model to balance general and task-specific knowledge while
  avoiding overfitting in multitask settings.
---

# LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs

## Quick Facts
- arXiv ID: 2505.18517
- Source URL: https://arxiv.org/abs/2505.18517
- Reference count: 0
- This work introduces LiSTEN, a framework for adapting LLMs to speech and audio tasks using dynamic prompt selection with learnable key-value pairs.

## Executive Summary
LiSTEN introduces a dynamic prompt selection framework that adapts text-based LLMs to multitask audio-language processing. The approach uses learnable key-value pairs where each input instance dynamically retrieves relevant prompts based on task-specific similarity, avoiding the limitations of fixed adapters like LoRA. This enables better task balance, improved interpretability through prompt diversity analysis, and maintains performance with fewer trainable parameters through a single-stage training process.

## Method Summary
LiSTEN uses a prompt pool of learnable key-value pairs where each input's mean-pooled audio+text representation serves as a query to retrieve relevant prompts. During training, top-k most similar keys are selected and their corresponding values are prepended to the LLM input. The framework employs an auxiliary loss that encourages selected keys to be close to their query representations, improving selection quality. Training is single-stage across all tasks with stochastic prompt length sampling, allowing flexible inference. Only the Q-Former and prompt pool are trainable, while the backbone LLM and audio encoders remain frozen.

## Key Results
- Dynamic prompt selection achieves 0.6462 ER accuracy vs. 0.5542 for LoRA
- Similarity-based DPS outperforms LoRA on 6/8 tracked metrics
- Performance maintained even with prompt length reduced to 10 tokens (vs. 160)
- Improved interpretability through analysis of prompt diversity and overlap across tasks

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Prompt Selection via Learnable Key-Value Pairs
LiSTEN's dynamic prompt selection uses a prompt pool storing P learnable key-value pairs. For each input, a query vector q (mean-pooled audio+text tokens) computes cosine similarity against all keys, selecting top-k matching values as soft prompts. This allows different instances to activate different prompts based on task and data characteristics, rather than sharing fixed adapters across all tasks. The core assumption is that mean-pooled representations capture sufficient task-discriminative information for relevant prompt selection.

### Mechanism 2: Auxiliary Key Loss Structures the Prompt Pool Geometry
An auxiliary loss L_key is added to next-token prediction: L = L_next-token + α·L_key. For similarity-based selection, L_key = Σ||q - k_i|| for selected keys. This gradients keys toward regions of query space associated with their selection, creating a structured embedding space where similar tasks share nearby keys. The assumption is that joint optimization of next-token prediction and key proximity does not create conflicting gradients that degrade LLM performance.

### Mechanism 3: Stochastic Prompt Length Enables Inference Efficiency
During training, prompt length k is randomly sampled from U(1, P) per batch, forcing the model to learn robust representations that work across prompt lengths. At inference, k can be reduced (e.g., 10 instead of 160) for efficiency. The model learns to prioritize the most important prompt tokens early in selection, creating a coarse-to-fine representation. This enables deployment with fewer tokens at inference with minimal performance loss.

## Foundational Learning

- **Parameter-Efficient Fine-Tuning (PEFT)**: LiSTEN is explicitly positioned against LoRA and soft prompting. Understanding PEFT tradeoffs (trainable params vs. performance vs. forgetting) is prerequisite to evaluating DPS advantages. Quick check: Can you explain why LoRA might cause "loss of text-based commonsense knowledge" in audio LLMs?

- **Cross-Modal Alignment via Q-Former**: LiSTEN inherits Q-Former architecture from BLIP-2/SALMONN for aligning variable-length audio to fixed-dimension LLM tokens. The query vector q depends on this alignment quality. Quick check: How does window-level Q-Former processing differ from full-sequence processing, and what efficiency/expressiveness tradeoff does it introduce?

- **Prompt Pool / Prompt Tuning**: The prompt pool {(k_i, v_i)} is the core learnable component. Understanding soft prompts as continuous vectors in embedding space (not discrete tokens) is essential. Quick check: Why might a prompt pool with 400 tokens (~3.3M params) achieve comparable performance to LoRA with similar param count, but with better interpretability?

## Architecture Onboarding

- **Component map**:
Audio Input → Whisper encoder → BEATs encoder → Concatenate → Q-Former windows → Concat with text instruction tokens → Mean pooling → query vector q → Cosine similarity vs. prompt pool keys → Top-k selection → k prompt values → Prepend values to input tokens → LLaMA 8B LLM → output response

- **Critical path**: Audio encoding quality (Whisper/BEATs) → Q-Former alignment → query q quality → query q → key similarity computation → prompt selection relevance → selected prompt values → LLM conditioning → task performance

- **Design tradeoffs**:
  - **Prompt pool size (P)**: Larger P increases capacity but requires more data to train. Paper uses P=400; notes "prompt pool can be significantly reduced without substantial performance loss."
  - **Prompt length (k)**: Larger k provides more task-specific capacity but increases inference cost. Stochastic training enables flexible k at inference.
  - **Selection strategy**: Similarity-based outperforms attention-based and residual-based on 6/8 metrics. Attention-based enables soft weighting but showed unstable results (ER drops to 0.4350 with stochastic).
  - **Auxiliary loss weight (α)**: Must balance key learning vs. next-token prediction. Paper does not specify value used.

- **Failure signatures**:
  - **Query collapse**: If all queries q become similar, same prompts selected for all tasks → performance resembles fixed soft prompting.
  - **Key collapse**: If auxiliary loss too strong, all keys converge to mean query → no diversity in prompt selection.
  - **Attention selection instability**: Attention-based stochastic showed CER=0.9004 (much worse than similarity-based 0.6736), suggesting numerical instability or poor gradient flow.

- **First 3 experiments**:
  1. **Ablate prompt pool size**: Train with P∈{50, 100, 200, 400} on same data, report performance vs. trainable params. This validates the claim that "prompt pool can be significantly reduced."
  2. **Visualize query-key similarity matrix**: Compute q for all validation samples, visualize similarity to all keys. Check whether different tasks cluster in distinct key regions (supporting Figure 2's interpretability claim).
  3. **Zero-shot task generalization test**: Train on ASR+ER+SV+SQA only. Evaluate on held-out tasks (En2Zh, ACAP) without further training. Check whether DPS selects prompts similar to related trained tasks.

## Open Questions the Paper Calls Out

- **Can the LiSTEN framework generalize to entirely new, unseen audio tasks without requiring updates to the prompt pool or model weights?**: The conclusion explicitly identifies "exploring its scalability to new tasks" as a primary direction for future work, while Section 4.2 hypothesizes that the prompt pool could help generalize to unseen tasks. This remains unproven as current experiments only evaluate performance on the specific multitask dataset the model was trained on.

- **Are there prompt selection strategies that can outperform the current best-performing similarity-based approach?**: The authors state in the conclusion that "further optimizing prompt selection strategies" is a goal for future work. The paper compares similarity, attention, and residual-based selection, finding similarity-based selection superior, but does not explore potential hybrids or alternative retrieval mechanisms.

- **What is the precise relationship between prompt pool size and performance as the number of concurrent tasks increases?**: The authors note that the prompt pool size (400 tokens) was chosen to match LoRA parameters for fair comparison, yet they observed it "can be significantly reduced without substantial performance loss." It is unclear if a reduced pool size remains sufficient when scaling from 6 tasks to dozens, or if capacity bottlenecks will emerge that degrade the dynamic selection capability.

## Limitations

- The paper's claims rely on untested assumptions about the learned prompt pool geometry and task-discriminative properties of mean-pooled query vectors. While similarity-based DPS outperforms LoRA on 6/8 metrics, the analysis does not establish whether performance gains stem from better task adaptation or simply increased model capacity.

- The stochastic prompt length mechanism's claimed efficiency benefits require further validation. The paper shows only that k=10 outperforms LoRA, but does not test whether this holds across all tasks or identify the minimum k that maintains performance.

- The auxiliary key loss, while shown to improve performance, could create adversarial gradients that harm LLM capabilities if α is not carefully tuned - a parameter regime the paper does not explore.

## Confidence

- **High confidence**: The superiority of similarity-based DPS over LoRA/soft prompting on multitask audio tasks is well-supported by the reported metrics (ER 0.6462 vs 0.5542; CER 0.6736 vs 0.8453). The single-stage training advantage and parameter efficiency claims are directly verifiable from the architecture.

- **Medium confidence**: The interpretability claims about prompt diversity and task overlap depend heavily on the quality of the mean-pooled query representations. While Figure 2 suggests distinct clustering patterns, the paper does not provide quantitative measures of task separability in the query space or establish that these patterns generalize beyond the studied tasks.

- **Low confidence**: The stochastic prompt length mechanism's claimed efficiency benefits require further validation. The paper shows only that k=10 outperforms LoRA, but does not test whether this holds across all tasks or identify the minimum k that maintains performance.

## Next Checks

1. **Query space discriminability analysis**: Compute and visualize the pairwise cosine similarity matrix between all validation samples' query vectors q, colored by task label. Quantify task separability using silhouette scores or nearest-neighbor accuracy. This directly tests whether mean pooling preserves task-discriminative information.

2. **Prompt length sensitivity sweep**: Systematically evaluate DPS performance across k ∈ {2, 4, 8, 16, 32, 64, 128} for each task. Plot task performance vs. k to identify where diminishing returns begin and whether complex tasks (SQA) require longer prompts than simple tasks (ASR).

3. **Cross-task prompt transferability**: Hold out one task (e.g., En2Zh) during training, then evaluate zero-shot performance. Analyze whether prompts selected for similar tasks (e.g., ASR for speech sounds) transfer effectively, or whether DPS requires task-specific prompt pools for each new task.