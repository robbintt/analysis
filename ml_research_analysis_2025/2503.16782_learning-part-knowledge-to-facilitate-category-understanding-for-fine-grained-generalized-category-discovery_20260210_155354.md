---
ver: rpa2
title: Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained
  Generalized Category Discovery
arxiv_id: '2503.16782'
source_url: https://arxiv.org/abs/2503.16782
tags:
- part
- fine-grained
- learning
- datasets
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PartGCD, a novel approach for fine-grained
  Generalized Category Discovery (GCD) that leverages part knowledge to overcome limitations
  of global feature-based methods. The key innovation is incorporating part-level
  information through Adaptive Part Decomposition, which automatically extracts class-specific
  semantic parts using Gaussian Mixture Models, and Part Discrepancy Regularization,
  which enforces clear semantic separation among part features.
---

# Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained Generalized Category Discovery

## Quick Facts
- arXiv ID: 2503.16782
- Source URL: https://arxiv.org/abs/2503.16782
- Authors: Enguang Wang; Zhimao Peng; Zhengyuan Xie; Haori Lu; Fei Yang; Xialei Liu
- Reference count: 40
- Primary result: PartGCD achieves state-of-the-art performance on fine-grained GCD benchmarks by leveraging part-level information

## Executive Summary
This paper addresses Generalized Category Discovery (GCD) in fine-grained settings where distinguishing subtle inter-class differences is critical. The proposed PartGCD method overcomes limitations of global feature-based approaches by incorporating part knowledge without requiring part annotations. The method automatically extracts class-specific semantic parts and enforces clear semantic separation among them through a novel three-branch architecture. PartGCD demonstrates significant improvements on fine-grained datasets while maintaining competitive performance on generic benchmarks.

## Method Summary
PartGCD introduces a novel framework for fine-grained GCD that leverages part-level information to overcome the limitations of global feature-based methods. The approach consists of three key components: Adaptive Part Decomposition (APD) that automatically extracts semantic parts using Gaussian Mixture Models, Part Discrepancy Regularization (PDR) that enforces clear semantic separation among part features, and a three-branch architecture that jointly learns global, known, and novel class representations. The method achieves state-of-the-art performance on multiple fine-grained benchmarks while being more efficient than previous approaches, requiring only 200 training epochs compared to 1000 for competing methods.

## Key Results
- Achieves state-of-the-art performance on fine-grained benchmarks (CUB, Stanford Cars, FGVC-Aircraft, Herbarium19)
- Shows significant improvements on ultra-fine-grained datasets (SoyAgeing series)
- Maintains competitiveness on generic datasets (CIFAR-10/100, ImageNet-100)
- Demonstrates better efficiency with 200 epochs vs 1000 epochs for competing approaches

## Why This Works (Mechanism)
PartGCD addresses the fundamental challenge in fine-grained GCD where subtle inter-class differences are often overshadowed by dominant inter-category distinctions in global features. By decomposing images into semantic parts and learning representations at this finer granularity, the method can capture discriminative features that distinguish similar classes. The Adaptive Part Decomposition automatically discovers class-specific parts without annotations, while Part Discrepancy Regularization ensures these parts provide complementary information. This part-level focus is particularly effective for fine-grained tasks where global features may be insufficient to capture subtle differences between visually similar classes.

## Foundational Learning

**Generalized Category Discovery**: Understanding both labeled and unlabeled data across known and novel classes simultaneously. Needed because real-world scenarios often involve discovering new categories while leveraging existing knowledge. Quick check: Can the model handle mixed supervision effectively?

**Fine-Grained Classification**: Distinguishing between visually similar classes with subtle differences. Needed because standard GCD methods struggle when inter-class differences are minimal. Quick check: Does the method improve performance on datasets with high visual similarity?

**Semantic Part Decomposition**: Extracting meaningful sub-regions of objects without manual annotations. Needed because part-level features are more discriminative for fine-grained tasks. Quick check: Are the discovered parts semantically meaningful and consistent across instances?

**Gaussian Mixture Models**: Unsupervised clustering technique for discovering part regions. Needed because it provides a principled way to identify coherent semantic regions. Quick check: Does the GMM effectively capture meaningful parts without supervision?

**Discrepancy Regularization**: Enforcing diversity among learned representations. Needed because it prevents redundancy and ensures parts capture different aspects of the object. Quick check: Do part features show clear semantic separation?

## Architecture Onboarding

**Component Map**: Input Images -> Adaptive Part Decomposition -> Part Features + Global Features -> Three-Branch Network -> Known Class Predictions + Novel Class Predictions

**Critical Path**: Image input flows through feature extraction, part decomposition, and three parallel branches (global, known class, novel class) that jointly optimize for both classification tasks.

**Design Tradeoffs**: The three-branch architecture increases parameter count but provides specialized learning for different tasks. Part decomposition adds computational overhead but enables more discriminative representations. The method trades some efficiency for significantly improved fine-grained performance.

**Failure Signatures**: Poor performance when semantic parts are not consistent across classes, when background clutter overwhelms part features, or when the GMM fails to discover meaningful parts. The method may also struggle with classes that lack clear semantic part structure.

**First 3 Experiments**: 1) Ablation study removing Adaptive Part Decomposition to show its impact on performance, 2) Evaluation on generic vs fine-grained datasets to demonstrate specialization, 3) Comparison of different part numbers from GMM to optimize granularity.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions beyond those addressed by the proposed method.

## Limitations

- The method assumes semantic parts are consistent across classes, which may not hold for datasets with significant intra-class variation
- Performance evaluation is limited to image classification datasets without exploration of other data modalities
- Computational overhead of the part decomposition module is not fully analyzed, particularly for high-resolution images
- The explicit focus on fine-grained scenarios means advantages may diminish on categories without subtle inter-class differences

## Confidence

- High Confidence: Improved performance on fine-grained benchmarks with multiple metrics and thorough ablation studies
- Medium Confidence: State-of-the-art claims are conditional on specific benchmark settings and comparison methods
- Medium Confidence: Efficiency claims are supported by epoch counts but lack comprehensive wall-clock time and memory usage analysis

## Next Checks

1. Evaluate PartGCD on a broader range of fine-grained datasets including medical imaging and satellite imagery to assess cross-domain generalization

2. Systematically vary the number of parts extracted by GMM and analyze impact on performance to validate optimal part granularity

3. Test the method on datasets with significant background clutter, occlusion, or varying image quality to evaluate real-world robustness