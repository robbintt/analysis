---
ver: rpa2
title: 'AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection
  Training'
arxiv_id: '2507.00049'
source_url: https://arxiv.org/abs/2507.00049
tags:
- pruning
- data
- samples
- dataset
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces AdaDeDup, an adaptive hybrid data pruning
  framework that addresses the challenge of efficiently training large-scale object
  detection models by reducing dataset redundancy while preserving informative samples.
  AdaDeDup combines density-based pruning with model-informed feedback at a cluster-specific
  level.
---

# AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection Training

## Quick Facts
- arXiv ID: 2507.00049
- Source URL: https://arxiv.org/abs/2507.00049
- Authors: Feiyang Kang; Nadine Chang; Maying Shen; Marc T. Law; Rafid Mahmood; Ruoxi Jia; Jose M. Alvarez
- Reference count: 40
- Primary result: AdaDeDup achieves near-original performance while pruning up to 20% of data on tested datasets and models

## Executive Summary
AdaDeDup introduces an adaptive hybrid data pruning framework designed to improve the efficiency of large-scale object detection training. The method combines density-based pruning with model-informed feedback at a cluster-specific level, allowing for more aggressive pruning in redundant clusters while preserving critical data in informative ones. By leveraging semantic features from a vision-language model for clustering and then applying a proxy model to evaluate pruning impact within each cluster, AdaDeDup achieves significant dataset reduction with minimal performance degradation.

## Method Summary
The AdaDeDup framework operates through a multi-stage process. First, data is clustered using semantic features extracted from a vision-language model, grouping samples with similar visual characteristics. An initial density-based pruning step removes samples based on local density metrics within each cluster. Then, a proxy model evaluates the impact of this pruning by comparing losses between kept and pruned samples within each cluster. This evaluation informs adaptive pruning decisions, allowing the framework to prune more aggressively in clusters with redundant samples while preserving informative ones. The approach is validated across multiple datasets (Waymo, COCO, nuScenes) and model architectures (BEVFormer, Faster R-CNN).

## Key Results
- Achieves near-original performance while pruning up to 20% of data
- Outperforms baselines like Random Downsampling and VLM-SSE by significant margins
- Reduces performance degradation by over 54% compared to random sampling on Waymo dataset

## Why This Works (Mechanism)
AdaDeDup works by recognizing that not all data samples contribute equally to model training. The density-based pruning removes clearly redundant samples, while the model-informed feedback ensures that pruning decisions are validated against actual model performance impact. The cluster-specific adaptation allows the system to recognize that some clusters contain more informative samples than others, adjusting pruning aggressiveness accordingly. This hybrid approach combines the efficiency of automated pruning with the intelligence of model-based validation.

## Foundational Learning

**Vision-Language Models**: Models that bridge visual and textual representations, used here for semantic clustering of detection data. Needed for creating meaningful groupings of similar samples. Quick check: Verify the VLM can capture relevant semantic similarities for object detection tasks.

**Density-Based Pruning**: A method that removes samples based on local density metrics, identifying outliers or redundant points. Needed for initial dataset reduction without model training. Quick check: Confirm density metrics align with visual redundancy in detection data.

**Proxy Model Evaluation**: Using a smaller or faster model to estimate the impact of dataset changes on full model performance. Needed to validate pruning decisions without full training overhead. Quick check: Ensure proxy model predictions correlate well with full model performance.

**Cluster-Adaptive Pruning**: Adjusting pruning strategies based on cluster characteristics rather than applying uniform pruning across all data. Needed because different data regions have varying levels of redundancy and information content. Quick check: Verify clusters represent meaningful semantic groupings.

## Architecture Onboarding

**Component Map**: Data samples -> VLM feature extraction -> Clustering -> Density-based pruning -> Proxy model evaluation -> Cluster-specific adaptive pruning -> Final dataset

**Critical Path**: The most time-consuming steps are the VLM feature extraction and proxy model evaluation, as these require significant computation. The clustering and density-based pruning are relatively faster operations.

**Design Tradeoffs**: The framework trades initial computational overhead (VLM extraction, proxy evaluation) for long-term training efficiency. More aggressive pruning saves more training time but risks performance degradation. The cluster-specific approach adds complexity but enables more intelligent pruning decisions.

**Failure Signatures**: If pruning too aggressively, performance degradation will occur disproportionately in certain object categories. If proxy model evaluation is inaccurate, pruning decisions may remove informative samples. Poor clustering will lead to inappropriate pruning within clusters.

**First Experiments**: 
1. Test on a single dataset/model combination to validate basic functionality
2. Compare performance against random pruning baseline on same dataset
3. Conduct ablation study removing proxy model evaluation to measure its contribution

## Open Questions the Paper Calls Out

The paper identifies several areas requiring further investigation. The generalizability of the approach to other detection tasks and model types remains unclear, as experiments focus on specific architectures and datasets. The framework's sensitivity to different clustering approaches and feature extractors hasn't been thoroughly explored. Additionally, the computational overhead of the adaptive pruning process relative to training time savings requires more detailed analysis.

## Limitations

- Results may not generalize beyond the three tested datasets (Waymo, COCO, nuScenes) and two model architectures
- Analysis of which specific data characteristics determine redundancy versus informativeness remains qualitative
- Real-world deployment considerations like inference speed and memory usage are not addressed

## Confidence

**High Confidence**: AdaDeDup achieves near-original performance while pruning up to 20% of data on tested datasets and models

**Medium Confidence**: The hybrid approach combining density-based pruning with model-informed feedback outperforms pure density-based or random pruning methods

**Low Confidence**: The cluster-specific adaptive mechanism provides consistent benefits across different detection architectures and dataset types

## Next Checks

1. Test AdaDeDup's effectiveness on additional detection architectures (e.g., Transformer-based detectors) and more diverse dataset types (e.g., medical imaging, satellite imagery)

2. Conduct ablation studies isolating the contribution of the model-informed feedback component versus the initial density-based pruning

3. Evaluate the computational overhead of the adaptive pruning process relative to the training time savings from reduced dataset size