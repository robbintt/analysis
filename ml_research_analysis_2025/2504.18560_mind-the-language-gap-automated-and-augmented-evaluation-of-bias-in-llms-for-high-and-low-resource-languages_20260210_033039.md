---
ver: rpa2
title: 'Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs
  for High- and Low-Resource Languages'
arxiv_id: '2504.18560'
source_url: https://arxiv.org/abs/2504.18560
tags:
- languages
- language
- bias
- translation
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces MLA-BiTe, a framework for automated multilingual
  bias evaluation in LLMs using translation and paraphrasing techniques. The framework
  was evaluated across four LLMs in six languages (English, Spanish, French, German,
  Catalan, Luxembourgish) using 7 bias categories (ageism, Lgbtiqphobia, politics,
  racism, religion, sexism, xenophobia).
---

# Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages

## Quick Facts
- **arXiv ID:** 2504.18560
- **Source URL:** https://arxiv.org/abs/2504.18560
- **Reference count:** 40
- **Primary result:** Automated translation and paraphrasing techniques can effectively augment multilingual bias evaluation templates, though low-resource languages show higher bias rates.

## Executive Summary
This study introduces MLA-BiTe, a framework for automated multilingual bias evaluation in LLMs using translation and paraphrasing techniques. The framework was evaluated across four LLMs in six languages (English, Spanish, French, German, Catalan, Luxembourgish) using 7 bias categories (ageism, LGBTIQphobia, politics, racism, religion, sexism, xenophobia). LLM-based translation and paraphrasing effectively augmented bias-testing templates, with paraphrasing before translation yielding marginally better results. Aggregated results show GPT-4o and Claude 3.5 Sonnet had the lowest bias rates (~75% success), while Llama3 405B showed the highest bias rates (~49% success). Low-resource languages exhibited higher bias rates than high-resource languages, with Luxembourgish showing the highest discrimination rates overall.

## Method Summary
The study develops MLA-BiTe, a framework that automates multilingual bias evaluation by translating and augmenting English bias-testing templates into target languages. The framework uses GPT-4o to translate templates while preserving placeholder syntax, then generates paraphrased variations with explicit grammatical constraints. Templates are validated using cosine similarity (target >0.90) and BLEU scores. The augmented templates are evaluated across four LLMs using LangBiTe's bias detection oracles, with results aggregated by language resource level and bias category.

## Key Results
- LLM-based translation and paraphrasing effectively augment bias-testing templates across six languages
- GPT-4o and Claude 3.5 Sonnet achieved ~75% success rates in bias detection
- Low-resource languages (Catalan, Luxembourgish) showed higher bias rates than high-resource languages
- Luxembourgish exhibited the highest discrimination rates overall across all tested models

## Why This Works (Mechanism)

### Mechanism 1
LLM-based In-Context Learning (ICL) can effectively automate template translation and augmentation, provided the LLM successfully preserves placeholder syntax and semantic intent. The framework (MLA-BiTe) prompts a capable LLM (e.g., GPT-4o) to translate bias-testing templates into target languages. It uses regular expressions to strip conversational filler ("The translation is...") and ensures placeholders (e.g., `{GENDER1}`) remain untranslated. This allows a single English template to generate syntactically valid test cases for low-resource languages like Luxembourgish without manual translation.

### Mechanism 2
Explicitly identifying and constraining the "grammatical number" (singular vs. plural) during paraphrasing significantly increases the reliability of template instantiation. During the augmentation phase, the system detects if a template is singular or plural. It explicitly injects this constraint into the paraphrase prompt (e.g., "It is CRITICAL to make the paraphrase as singular"). This prevents the LLM from unintentionally shifting number, which would cause placeholders like "men" to render grammatically incorrect prompts (e.g., "Is a men better than a women").

### Mechanism 3
Lower performance in low-resource languages suggests that data scarcity amplifies social bias or instability in model outputs. LLMs are optimized for high-resource languages (English, Spanish) via extensive pre-training and safety alignment. In low-resource languages (Catalan, Luxembourgish), the lack of safety fine-tuning data allows underlying biases from the pre-training corpus to surface more aggressively or results in unpredictable "misfiring" of safety refusals.

## Foundational Learning

### Concept: Template-level vs. Prompt-level Operations
**Why needed here:** MLA-BiTe translates templates (e.g., "Is {X} better than {Y}?") rather than instantiated prompts ("Is men better than women?"). This creates a factorial efficiency ($N$ templates vs $N \times K$ communities) but requires strict syntax preservation.
**Quick check question:** Why would translating "Is a {Group1} better than a {Group2}?" be safer than translating "Is a man better than a woman?"

### Concept: Semantic Similarity (Cosine) vs. N-gram Overlap (BLEU)
**Why needed here:** The paper evaluates its augmentation by measuring if the *meaning* stays the same (High Cosine) while the *wording* changes (Low/Mid BLEU).
**Quick check question:** If a template is paraphrased from "Do you hate X?" to "Is there animosity toward X?", would you expect BLEU to be high or low? What about Cosine Similarity?

### Concept: High-Resource vs. Low-Resource Languages
**Why needed here:** The core hypothesis (RQ2) relies on distinguishing resource levels. Luxembourgish (LB) and Catalan (CA) are treated as low-resource, while English (EN) and German (DE) are high-resource.
**Quick check question:** Does the paper find that linguistic family (e.g., German and Luxembourgish) correlates perfectly with bias levels?

## Architecture Onboarding

### Component map:
LangBiTe Core -> Translator (Algorithm 2) -> Paraphraser (Algorithm 3) -> LLM Under Test -> Augmentor LLM

### Critical path:
The **Regex Cleaning** step after LLM generation. The paper notes >98% accuracy was required to strip "chatter" (e.g., "Here is the translation:") from the LLM output before it could be used as a template.

### Design tradeoffs:
- **P2T vs T2P:** Paraphrasing-then-Translating (P2T) showed slightly better semantic retention in some cases, but the authors selected Translating-then-Paraphrasing (T2P) for the main pipeline. An engineer should validate this choice for their specific target language.
- **Augmenter Model:** Using GPT-4o as the *evaluator* of its own *translations* (when testing GPT-4o) may introduce bias; the paper flags this but notes it was necessary for quality.

### Failure signatures:
- **Unprocessable Executions:** Look for high failure rates in **Racism** (18.24%) and **Sexism** (14.34%) categories. These often fail because models refuse to answer or output invalid JSON for probability-based templates.
- **Template Drift:** If placeholders are filled with garbage text, check the `affixTranslator` dictionary or the Regex cleaning logic.

### First 3 experiments:
1. **Sanity Check:** Run MLA-BiTe on English templates only (no translation) with `P=0` and `P=5` to verify that paraphrasing alone doesn't drastically change the bias score distribution.
2. **Pipeline Validation:** Translate a set of English templates to Spanish using both P2T and T2P pipelines. Compute Cosine Similarity against the human-curated Spanish ground truth to determine which pipeline performs better for your specific domain.
3. **Resource Gap Analysis:** Evaluate a single LLM (e.g., Llama3) on English (High-resource) vs. Luxembourgish (Low-resource). Plot the variance in "Politics" and "Racism" categories to confirm if the low-resource instability hypothesis holds for your model.

## Open Questions the Paper Calls Out

### Open Question 1
Does the use of a specific LLM for template augmentation (translation and paraphrasing) provide an unfair performance advantage to that same model during the bias evaluation phase? The authors note in Section 5.2 that because GPT-4o was used to generate the test templates, "its output may provide GPT-4o with a slight advantage in the bias-detection task. Further work is required to evaluate this potential effect."

### Open Question 2
Can the MLA-BiTe framework be effectively adapted for extra-European languages that possess complex linguistic structures, such as extensive noun classes or verb morphology? Section 7 states: "Future work will extend the evaluation to extra-European languages... These features may require tailored strategies for reliable evaluation."

### Open Question 3
How does the language of a prompt influence the distribution of visual biases in text-to-image generation models? Section 7 lists "Integrating Image Generation Capabilities" as future work, specifically to "investigate how the distribution of generated images varies according to the language in which the prompt is formulated."

### Open Question 4
Can automated translation strategies be optimized to respect cultural norms (such as religious dietary restrictions) while maintaining the semantic integrity required for bias testing? Section 7 proposes "Exploring Cultural-Aware Translation" to mitigate risks of offending users, noting that "prompts or examples involving food may need to avoid certain ingredients depending on cultural or religious context."

## Limitations
- Translation quality may influence bias measurements in low-resource languages, potentially inflating bias scores
- Comparison between high- and low-resource languages conflates data scarcity with safety alignment gaps
- Reliance on a single augmenter model (GPT-4o) raises concerns about circular evaluation when testing GPT-4o itself

## Confidence

**High confidence:** The core finding that LLM-based translation and paraphrasing can effectively augment bias-testing templates across multiple languages. The methodology for detecting and constraining grammatical number is well-supported.

**Medium confidence:** The comparative performance rankings of different LLMs (Claude 3.5 Sonnet > GPT-4o > Llama3 405B > Gemini 1.5 Flash) across bias categories, as this depends on specific template implementations and may vary with different evaluation sets.

**Medium confidence:** The observation that low-resource languages show higher bias rates, though the exact mechanisms (data scarcity vs. alignment gaps) remain uncertain.

## Next Checks
1. **Translation Quality Validation:** Run the same templates through human translators for Luxembourgish and Catalan to determine if the automated translations introduce systematic errors that correlate with higher bias scores.
2. **Linguistic Family Analysis:** Test additional Romance languages (Italian, Portuguese) to better understand whether linguistic proximity correlates with bias transfer patterns, addressing the paper's finding that German and Luxembourgish don't show expected similarities.
3. **Safety Alignment Isolation:** Fine-tune Llama3 on a small corpus of Luxembourgish bias mitigation data and re-run evaluations to distinguish between data scarcity effects and lack of safety alignment.