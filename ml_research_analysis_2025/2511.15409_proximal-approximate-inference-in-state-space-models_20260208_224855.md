---
ver: rpa2
title: Proximal Approximate Inference in State-Space Models
arxiv_id: '2511.15409'
source_url: https://arxiv.org/abs/2511.15409
tags:
- variational
- forward
- posterior
- gaussian
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a unified framework for approximate Bayesian
  inference in nonlinear, non-Gaussian state-space models using entropic proximal
  variational optimization. The authors formulate inference as a sequence of trust-region
  updates over probability densities, yielding forward-backward algorithms whose structure
  depends on the factorization of the variational posterior.
---

# Proximal Approximate Inference in State-Space Models

## Quick Facts
- arXiv ID: 2511.15409
- Source URL: https://arxiv.org/abs/2511.15409
- Authors: Hany Abdulsamad; Ángel F. García-Fernández; Simo Särkkä
- Reference count: 40
- Primary result: A unified framework for approximate Bayesian inference in nonlinear, non-Gaussian state-space models using entropic proximal variational optimization

## Executive Summary
This paper introduces a unified framework for approximate Bayesian inference in nonlinear, non-Gaussian state-space models using entropic proximal variational optimization. The authors formulate inference as a sequence of trust-region updates over probability densities, yielding forward-backward algorithms whose structure depends on the factorization of the variational posterior. By focusing on Gauss-Markov approximations, they derive recursive schemes with favorable computational complexity. The method generalizes classical smoothers to nonlinear and non-Gaussian settings, with practical implementations using generalized statistical linear regression and Fourier-Hermite moment matching.

## Method Summary
The framework treats Bayesian inference as an optimization problem that maximizes the evidence lower bound (ELBO) subject to a KL-divergence trust-region constraint. The key insight is that this formulation naturally leads to iterative updates where each step computes a new variational posterior that is "close" to the previous one, controlled by a damping parameter β. The authors develop three specific algorithms based on different posterior factorizations: Forward Proximal Variational Smoothing (FPVS), Reverse Proximal Variational Smoothing (RPVS), and Hybrid Proximal Variational Smoothing (HPVS). These algorithms use local quadratic approximations of the model log-densities via Generalized Statistical Linear Regression (GSLR) or Fourier-Hermite moment matching to enable closed-form Gaussian updates.

## Key Results
- Derives three proximal variational smoothing algorithms (FPVS, RPVS, HPVS) with favorable O(T) computational complexity
- Shows convergence to exact Kalman/RTS solutions in linear-Gaussian cases when β→0
- Demonstrates improved stability compared to non-proximal methods through trust-region regularization
- Provides practical implementations using GSLR and Fourier-Hermite approximations for non-linear/non-Gaussian models

## Why This Works (Mechanism)

### Mechanism 1: Entropic Proximal Regularization
Adding a KL-divergence constraint between successive posterior iterates stabilizes inference and enforces a trust region. The optimization solves for a new variational posterior $q^{[i+1]}$ that maximizes the ELBO while keeping $D_{KL}(q^{[i+1]}||q^{[i]}) \le \varepsilon$. This "dampens" the update, preventing the optimizer from taking large, unstable steps in probability density space, especially when relying on local approximations. The optimal posterior $q^{*}$ lies within a "proximity" of the current iterate $q^{[i]}$, which is reasonable if local model linearizations/quadratizations are accurate in this region.

### Mechanism 2: Gauss-Markov Posterior Factorization
Structuring the variational posterior with a Markov property enables efficient, recursive, scalable algorithms. By assuming the posterior factors as a Markov chain (forward or reverse), the high-dimensional joint optimization decomposes into a sequence of local, tractable updates. This mirrors the SSM's temporal structure, allowing forward-backward message passing with $O(T)$ complexity. The true smoothing posterior $p(x_{0:T}|y_{1:T})$ can be adequately approximated by a Markovian Gaussian distribution, though this neglects potential long-range dependencies in the true posterior.

### Mechanism 3: Local Statistical Function Approximation
Quadratic approximations of log-densities, built around the current posterior belief, enable closed-form Gaussian updates. The core recursion computes "potential functions" $V_k(x_k)$. To make them tractable, log-densities of dynamics $\log f_k$ and measurements $\log h_k$ are approximated by a quadratic function (second-order Taylor-like expansion) around the mean of the current marginal posterior. This turns the integration step for normalizers into a tractable Gaussian integral, preserving the Gaussian form. The log-densities are well-approximated by a quadratic function within the high-probability region of $q_k^{[i]}(x_k)$, equivalent to assuming the system is "locally linear-Gaussian."

## Foundational Learning

- **Variational Inference (VI) & ELBO**: This framework is built on finding a tractable distribution $q$ that maximizes the ELBO. Understanding optimization over distributions is the starting point. *Quick check*: If an update increases KL-divergence from the prior $p(x)$ but massively increases the expected log-likelihood, will the ELBO go up or down?

- **Kalman Filtering and RTS Smoothing**: The paper's algorithms are generalizations of these classical linear-Gaussian methods. The recursions for potentials are analogous to forward filter and backward smoother passes. *Quick check*: In a standard RTS smoother, does the backward pass use the original system dynamics or the *filtered* covariances to compute the smoothed gain?

- **Duality & Lagrangian Multipliers**: The central "damping" parameter $\beta$ is derived from a Lagrangian multiplier $\alpha$ for the KL-divergence constraint. The adaptive step size is found by solving a dual optimization problem. *Quick check*: If the KL constraint is binding ($D_{KL} = \varepsilon$), is the Lagrangian multiplier $\alpha$ zero or non-zero?

## Architecture Onboarding

- **Component map**: Model Definition -> Statistical Expansions (GSLR/Fourier-Hermite) -> Recursive Core (Algo 1,4,9) -> Dual Optimizer (Algo 3,6) -> Main Loop (Algo 7,8,10)

- **Critical path**: Initialize Gaussian posterior $q^{[0]}$ (e.g., via extended Kalman smoother). Iterate: compute marginals, compute quadratic coefficients for model log-densities, run dual optimizer to find optimal $\beta$, run core recursive update to get $q^{[i+1]}$, check for convergence.

- **Design tradeoffs**:
  - *Posterior Factorization*: Forward-Markov (FPVS) simpler for forecasting, Reverse-Markov (RPVS) generalizes RTS smoother for general smoothing, Hybrid (HPVS) more accurate but higher cost
  - *Approximation Method*: GSLR faster and simpler, assumes additive noise; Fourier-Hermite more accurate for highly non-linear models, handles some non-additive noise

- **Failure signatures**: Covariance collapse/numerical instability if precision matrices become non-positive definite; damping failure if bisection search fails to find valid β; non-convergence if marginals oscillate due to poor local approximations

- **First 3 experiments**:
  1. Linear-Gaussian sanity check: Implement on linear-Gaussian model, verify single-iteration convergence to exact Kalman/RTS solution
  2. Univariate non-linear benchmark: Test on univariate growth model, compare smoothed mean RMSE against extended/unscented RTS and analyze effect of proximal damping (β)
  3. Damping sensitivity: On multi-modal problem, fix β at different values (0, 0.5, 0.9), analyze impact on convergence speed and stability compared to adaptive β

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the increased fidelity of Fourier-Hermite moment matching provide a significant accuracy advantage over GSLR that justifies its higher computational complexity in high-dimensional state-space models?
- Basis: Section 5.2.2 notes Fourier-Hermite captures second-order information neglected by GSLR, while Section 6.2 admits improvements come at "increased algorithmic complexity"
- Why unresolved: The paper derives both methods but does not provide comparative empirical analysis or complexity scaling for high-dimensional systems
- What evidence would resolve it: Benchmark comparison of estimation error versus runtime on systems with varying state dimensions d

### Open Question 2
- Question: Under what conditions does HPVS yield superior estimation accuracy compared to FPVS or RPVS?
- Basis: Section 6.1 suggests hybrid scheme offers structural independence and parallelization but "increases the overall computational cost" without quantifying accuracy trade-off
- Why unresolved: Authors derive hybrid fusion rules but don't analyze if combining forward and reverse potentials yields statistically significant improvements
- What evidence would resolve it: Theoretical analysis or simulations showing HPVS convergence to lower variational free energy than FPVS/RPVS for specific model classes

### Open Question 3
- Question: Is the bisection method for damping parameter robust against non-convexity in the dual objective?
- Basis: Section 5.5 states off-the-shelf solvers struggle with feasibility issues due to implicit convexity assumptions, leading to bisection method adoption
- Why unresolved: While bisection handles root-finding for KL constraint, paper doesn't prove updates avoid local optima or ensure stability when quadratic approximations break down
- What evidence would resolve it: Convergence proofs for bisection in non-convex settings or stress-testing on chaotic systems

## Limitations
- The KL trust-region constraint assumes local quadratic approximations remain accurate within the neighborhood, which may fail for highly non-linear or multi-modal systems
- Assuming the posterior factors as a Markov chain neglects long-range dependencies, limiting accuracy in problems with strong non-Markovian structure
- The quadratic fit of log-densities depends critically on the region being "locally linear-Gaussian," a core modeling assumption rather than a universal property

## Confidence

- **High**: The entropic proximal framework is mathematically sound; the KL trust-region mechanism is a well-established principle in optimization
- **Medium**: The empirical validation is limited to a small set of synthetic examples; claims about robustness and scalability require testing on real-world, high-dimensional problems
- **Medium**: The generalization to non-Gaussian dynamics via GSLR/Fourier-Hermite is principled, but implementation details significantly impact performance

## Next Checks
1. **Convergence and Stability Analysis**: Systematically vary the trust-region radius ε and initial damping β across multiple problem types, quantify effects on convergence speed, stability (covariance positive-definiteness), and final ELBO
2. **Non-Markovian Stress Test**: Construct synthetic SSM where true smoothing posterior has strong long-range dependencies, compare proposed Gauss-Markov approximation against particle smoother baseline
3. **Scalability Benchmark**: Implement full algorithm and benchmark wall-clock time and memory usage against state-of-the-art particle and variational smoothers on high-dimensional (>100 state dimension) non-linear problem