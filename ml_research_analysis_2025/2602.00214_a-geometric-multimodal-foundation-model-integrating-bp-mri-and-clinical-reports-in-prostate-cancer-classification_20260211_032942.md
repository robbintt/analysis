---
ver: rpa2
title: A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports
  in Prostate Cancer Classification
arxiv_id: '2602.00214'
source_url: https://arxiv.org/abs/2602.00214
tags:
- clinical
- multimodal
- geometric
- classification
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of prostate cancer classification
  using bi-parametric MRI and clinical reports, overcoming limitations of existing
  methods that rely solely on imaging or suffer from data scarcity. The proposed MFM-Geom
  integrates a geometric multimodal foundation model that learns representations from
  both imaging and clinical variables through a novel symmetric positive definite
  (SPD) descriptor and Riemannian deep learning.
---

# A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification

## Quick Facts
- arXiv ID: 2602.00214
- Source URL: https://arxiv.org/abs/2602.00214
- Reference count: 0
- Primary result: MFM-Geom achieves 90.67 AUC-PR using only 10% training data

## Executive Summary
This work addresses prostate cancer classification using bi-parametric MRI (bp-MRI) and clinical reports through a novel geometric multimodal foundation model (MFM-Geom). The method overcomes limitations of existing approaches that rely solely on imaging or suffer from data scarcity by integrating pretrained BiomedCLIP encoders with a symmetric positive definite (SPD) descriptor and Riemannian deep learning. Experiments demonstrate that MFM-Geom significantly outperforms baseline approaches, achieving robust performance with limited data and maintaining effectiveness on external datasets.

## Method Summary
The method integrates BiomedCLIP's pretrained ViT and PubMedBERT encoders to process bp-MRI volumes and clinical reports, respectively. A geometric classification head processes the multimodal representations through an SPD descriptor (covariance matrix) computed from concatenated embeddings, followed by Riemannian processing using SPDnet layers (BiMap, ReEig, LogEig) to classify prostate cancer (NC vs {IM,HM}, NC vs IM, NC vs HM). The model is trained with combined binary cross-entropy and InfoNCE contrastive loss, demonstrating data-efficient transfer learning from 15M biomedical image-text pairs.

## Key Results
- MFM-Geom achieves 90.67 AUC-PR using only 10% of training data
- Outperforms baseline approaches by 4.3-4.7 points (AUC-PR) on limited data
- Maintains robust performance (90.6 AUC-PR) on external validation dataset
- Geometric head with SPD processing provides consistent improvement over Euclidean alternatives

## Why This Works (Mechanism)

### Mechanism 1: SPD Descriptor Captures Cross-Modal Correlation Structure
Representing multimodal embeddings as an SPD covariance matrix preserves pairwise correlation information between imaging patches and clinical tokens that standard class-token aggregation discards. Given embeddings matrix M ∈ R^(N×d), the SPD descriptor S₀ = (1/d²)MM^T computes similarity between every embedding pair, creating a unified geometric representation. The SPD constraint ensures the matrix lies on a Riemannian manifold with well-defined metric properties. Core assumption: Discriminative information for csPCa classification resides in the correlation structure between modalities, not just in individual modality representations.

### Mechanism 2: Foundation Model Pretraining Enables Data-Efficient Transfer
BiomedCLIP's pretrained encoders, trained on 15M PubMed image-text pairs, provide domain-specific representations that transfer more efficiently than generic ImageNet pretraining for prostate MRI classification. The pretrained ViT and PubMedBERT encoders already encode biomedical visual patterns and clinical terminology. Fine-tuning with contrastive loss (InfoNCE) aligns modality-specific embeddings while preserving transferable features. Core assumption: The PubMed pretraining corpus contains imaging patterns and clinical language relevant to prostate cancer diagnosis.

### Mechanism 3: Riemannian Geometry Preserves SPD Manifold Structure During Learning
Processing SPD matrices with geometry-aware operations (BiMap, ReEig, LogEig) preserves discriminative manifold properties that Euclidean MLPs would distort. SPDnet's BiMap layer (W·S·W^T) projects along the SPD cone; ReEig enforces positive definiteness via eigenvalue thresholding; LogEig maps to the tangent space (Euclidean domain) for classification. This respects the curved geometry of the SPD manifold. Core assumption: The SPD manifold's intrinsic geometry contains meaningful structure that Euclidean operations would corrupt.

## Foundational Learning

- **Symmetric Positive Definite (SPD) Matrices**
  - Why needed here: Understanding why covariance-style representations require special mathematical treatment—SPD matrices form a curved manifold where standard Euclidean operations (like matrix addition) leave the manifold.
  - Quick check question: Given a covariance matrix S, why can't we directly apply a standard MLP layer?

- **Vision Transformer (ViT) Patch Embeddings vs. Class Token**
  - Why needed here: The method explicitly uses patch embeddings (not just CLS tokens) to construct the SPD descriptor. Understanding what information each representation captures is essential.
  - Quick check question: What information does the CLS token aggregate versus what remains in patch embeddings?

- **Contrastive Learning (InfoNCE Loss)**
  - Why needed here: The fine-tuning strategy aligns imaging and text embeddings using contrastive objectives inherited from BiomedCLIP's pretraining paradigm.
  - Quick check question: What does InfoNCE loss optimize, and how does it create a shared embedding space across modalities?

## Architecture Onboarding

- **Component map:**
  bp-MRI volumes + clinical reports → BiomedCLIP ViT-B/16 with 3D adapter + PubMedBERT → patch/text embeddings → SPD descriptor S₀ → SPDnet (2× BiRe blocks) → LogEig → MLP → classification logits

- **Critical path:**
  1. Preprocessing: Standardize MRI to 384×384×24, extract VoIs around lesion centroids
  2. Forward pass: 3D patches → ViT encoders → patch/text embeddings → SPD matrix → SPDnet → classification
  3. Loss computation: BCE on classification output + InfoNCE on aligned CLS embeddings

- **Design tradeoffs:**
  - Geometric head vs. standard MLP: +6.7% AUC-PR improvement but ~2× inference time (14.3ms vs. 7.6ms per sample)
  - Multimodal vs. imaging-only: +1.7% AUC-PR over unimodal geometric model, but requires clinical variables at inference
  - BiomedCLIP vs. ImageNet pretraining: +5.8 AUC-PR points on external validation, but locked into domain-specific encoder

- **Failure signatures:**
  - Missing clinical variables: Multimodal model cannot operate; fallback to imaging-only configuration required
  - Degenerate SPD matrices: If eigenvalues approach ε threshold, ReEig layer may over-regularize, losing discriminative information
  - Misaligned modalities: If contrastive loss plateaus without convergence, imaging-text pairs may lack semantic correspondence

- **First 3 experiments:**
  1. Ablate geometric head: Compare MFM-Geom vs. MFM with standard MLP classification head on patch embeddings (validates SPD contribution)
  2. Modality dropout analysis: Train with single MRI sequences (T2W-only, ADC-only) to quantify per-sequence contribution and identify minimum viable input configuration
  3. SPD eigenvalue monitoring: Track eigenvalue distribution across training epochs to detect near-degeneracy and validate ReEig threshold (ε) selection

## Open Questions the Paper Calls Out
- Can the learned multimodal geometric latent space effectively stratify different levels of malignancy (specific ISUP grades) rather than performing binary classification?
- Does the proposed multimodal fusion strategy maintain its performance robustness when validated on external cohorts that include paired clinical variables?
- How does the model's performance vary when processing unstructured, free-text clinical reports compared to the structured "fill-in-the-blank" templates used in the study?

## Limitations
- Limited external validation scope: Single institution's data represented, confidence in generalization remains medium
- SPD descriptor dimensionality constraints: Rank-deficient matrices may occur with small lesion VoIs or limited clinical variables
- Clinical workflow integration unknowns: Computational overhead and clinical variable dependencies may limit real-world deployment

## Confidence
- **High confidence**: Foundation model pretraining enables data-efficient transfer (supported by quantitative ablation and external validation comparisons)
- **Medium confidence**: SPD descriptor captures cross-modal correlation structure (mechanism is sound, but lacks ablation studies isolating SPD contribution from geometric processing)
- **Medium confidence**: Riemannian geometry preserves SPD manifold structure (theoretically justified, but no direct comparison to Euclidean alternatives on this specific task)

## Next Checks
1. Ablate SPD vs. Euclidean classification: Replace SPDnet with a standard MLP on the same concatenated embeddings to isolate whether the SPD descriptor structure or the Riemannian processing drives performance gains
2. Cross-institutional multi-site validation: Evaluate MFM-Geom on at least two additional independent prostate cancer datasets from different institutions to establish robustness across imaging protocols, scanner manufacturers, and patient populations
3. Rank-deficiency stress test: Systematically reduce input VoI size and clinical variable count to identify the minimum viable configuration and determine at what point the SPD descriptor becomes rank-deficient or performance degrades significantly