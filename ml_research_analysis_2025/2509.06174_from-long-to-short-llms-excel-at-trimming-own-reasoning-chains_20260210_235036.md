---
ver: rpa2
title: 'From Long to Short: LLMs Excel at Trimming Own Reasoning Chains'
arxiv_id: '2509.06174'
source_url: https://arxiv.org/abs/2509.06174
tags:
- reasoning
- arxiv
- length
- answer
- edit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of overthinking in large reasoning
  models (LRMs), where they generate excessively long and convoluted reasoning chains,
  especially for simple problems. The authors propose EDIT (Efficient Dynamic Inference
  Trimming), a test-time scaling method that guides LRMs to identify the shortest
  correct reasoning paths by employing constraint-guided generation and jointly tracking
  length and answer distributions under varying constraints.
---

# From Long to Short: LLMs Excel at Trimming Own Reasoning Chains

## Quick Facts
- arXiv ID: 2509.06174
- Source URL: https://arxiv.org/abs/2509.06174
- Reference count: 40
- Primary result: EDIT reduces reasoning length by 20% while maintaining accuracy within 2% across diverse models and datasets

## Executive Summary
This paper addresses the problem of overthinking in large reasoning models (LRMs), where they generate excessively long and convoluted reasoning chains, especially for simple problems. The authors propose EDIT (Efficient Dynamic Inference Trimming), a test-time scaling method that guides LRMs to identify the shortest correct reasoning paths by employing constraint-guided generation and jointly tracking length and answer distributions under varying constraints. The core idea is to use a dual-goal search algorithm that dynamically adjusts the constraint strength based on the variation trends of solution lengths and answer confidence. EDIT significantly enhances reasoning efficiency, producing compact yet informative outputs that improve readability and user experience. Experimental results on diverse models and datasets show that EDIT substantially reduces reasoning length while maintaining or even improving accuracy, with the largest performance gap being below 2% with 20% fewer tokens produced in the reasoning paths.

## Method Summary
The EDIT method employs constraint-guided generation to guide LRMs toward identifying the shortest correct reasoning paths. It uses a dual-goal search algorithm that dynamically adjusts constraint strength based on the variation trends of solution lengths and answer confidence. The approach tracks both length and answer distributions under varying constraints, allowing the model to explore different reasoning paths while maintaining accuracy. The method operates during test-time inference, making it a lightweight addition to existing LRM pipelines without requiring model retraining.

## Key Results
- EDIT reduces reasoning length by 20% compared to baseline approaches
- Accuracy maintained within 2% of baseline performance across diverse datasets
- Method works across multiple model architectures and reasoning domains
- Demonstrates improved reasoning efficiency while producing more readable outputs

## Why This Works (Mechanism)
EDIT works by recognizing that LRMs often generate redundant or unnecessarily detailed reasoning chains, particularly for simpler problems. The constraint-guided generation approach allows the model to explore multiple reasoning paths with varying levels of detail, while the dual-goal search algorithm identifies the optimal balance between path length and answer confidence. By dynamically adjusting constraints based on observed performance trends, EDIT effectively prunes unnecessary reasoning steps without sacrificing correctness. This approach leverages the model's own capabilities to evaluate the quality of different reasoning paths, making it self-improving and adaptive to different problem types.

## Foundational Learning

**Constraint-guided generation**: Why needed - To control reasoning path length without manual intervention. Quick check - Verify that constraints can be adjusted dynamically based on performance metrics.

**Dual-goal search algorithms**: Why needed - To balance between finding correct answers and minimizing reasoning length. Quick check - Ensure the algorithm can track both length and accuracy metrics simultaneously.

**Test-time scaling**: Why needed - To improve inference efficiency without model retraining. Quick check - Confirm that the method adds minimal computational overhead during inference.

**Answer distribution tracking**: Why needed - To understand how constraint changes affect final answer quality. Quick check - Validate that distribution changes correlate with actual performance improvements.

## Architecture Onboarding

**Component map**: Input problem -> Constraint module -> Reasoning chain generator -> Length tracker -> Answer evaluator -> Constraint adjuster -> Output

**Critical path**: Problem input → Constraint application → Reasoning generation → Length evaluation → Answer verification → Constraint adjustment (loop) → Final output

**Design tradeoffs**: 
- Tighter constraints reduce length but risk accuracy drops
- Looser constraints maintain accuracy but increase token usage
- Dynamic adjustment balances these competing objectives
- Tradeoff between computational overhead and efficiency gains

**Failure signatures**: 
- Excessive constraint tightening leading to incorrect answers
- Inadequate constraint adjustment causing minimal length reduction
- Performance degradation on particularly complex problems
- Overfitting to specific problem types or distributions

**First experiments**:
1. Test on simple arithmetic problems with varying constraint strengths
2. Evaluate across different model sizes to assess scalability
3. Measure performance on problems known to cause overthinking in baseline models

## Open Questions the Paper Calls Out

The study does not explicitly call out open questions, but several implications remain unexplored. The generalizability to other reasoning tasks or domains remains uncertain. The method's performance with smaller models or in resource-constrained environments has not been thoroughly evaluated. Additionally, potential biases introduced by the constraint-guided generation approach could affect the diversity of reasoning paths explored.

## Limitations

- Claims about maintaining or improving accuracy are based on specific datasets and model configurations
- Generalizability to other reasoning tasks or domains remains uncertain
- Performance with smaller models or in resource-constrained environments not thoroughly evaluated
- Potential biases introduced by constraint-guided generation not addressed

## Confidence

High: The core methodology of EDIT and its ability to reduce reasoning length while maintaining accuracy are well-supported by experimental results.
Medium: The claim that the method improves readability and user experience is supported by the reduction in token count but lacks direct user studies.
Low: The generalizability of the method to other reasoning tasks or domains is not fully established due to limited testing across diverse problem types.

## Next Checks

1. Conduct extensive testing across a broader range of reasoning tasks, including those outside the original study's scope, to assess generalizability.
2. Perform user studies to directly measure the impact of reduced reasoning chains on readability and user experience.
3. Investigate the method's performance with smaller models and in resource-constrained environments to evaluate its applicability in diverse settings.