---
ver: rpa2
title: Subject-Adaptive Sparse Linear Models for Interpretable Personalized Health
  Prediction from Multimodal Lifelog Data
arxiv_id: '2510.02835'
source_url: https://arxiv.org/abs/2510.02835
tags:
- sleep
- sasl
- data
- feature
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study tackles the challenge of interpretable, personalized
  health prediction from multimodal lifelog data, addressing the trade-off between
  predictive accuracy and model transparency. The proposed Subject-Adaptive Sparse
  Linear (SASL) framework combines ordinary least squares regression with subject-specific
  interactions, enabling both global pattern detection and personalized adjustments.
---

# Subject-Adaptive Sparse Linear Models for Interpretable Personalized Health Prediction from Multimodal Lifelog Data

## Quick Facts
- **arXiv ID:** 2510.02835
- **Source URL:** https://arxiv.org/abs/2510.02835
- **Reference count:** 32
- **Primary result:** SASL achieves Macro-F1 of 0.6387 on CH-2025 dataset, ranking 4th among 1,032 competitors while maintaining interpretable, sparse models.

## Executive Summary
This study addresses the challenge of interpretable, personalized health prediction from multimodal lifelog data, specifically targeting the trade-off between predictive accuracy and model transparency. The proposed Subject-Adaptive Sparse Linear (SASL) framework combines ordinary least squares regression with subject-specific interactions, enabling both global pattern detection and personalized adjustments. A nested F-test backward feature elimination ensures statistical parsimony, while a regression-then-thresholding strategy optimizes ordinal predictions using macro-F1 scores. For particularly difficult outcomes, SASL selectively integrates compact LightGBM outputs through confidence-based gating. Evaluated on the CH-2025 dataset (450 daily records from ten subjects), SASL achieved a macro-F1 of 0.6387, placing fourth among 1,032 competitors, while maintaining interpretability through sparse, action-oriented models.

## Method Summary
SASL uses OLS regression with subject-ID interaction terms to create a design matrix equivalent to separate models per subject. An iterative backward elimination via nested F-tests prunes predictors with p-values exceeding α. Continuous predictions from OLS are then thresholded to maximize macro-F1 using chronological 2-fold CV. For challenging targets, SASL optionally gates in LightGBM predictions when confidence exceeds 0.97. The S2 pipeline uses 172 temporal features and k-means archetypes for minute-level sleep efficiency prediction.

## Key Results
- SASL achieved macro-F1 of 0.6387 on CH-2025 dataset
- Ranked 4th among 1,032 competitors
- Selective LightGBM integration improved macro-F1 by +0.0076
- Maintained interpretability through sparse models (most features had zero coefficients)

## Why This Works (Mechanism)

### Mechanism 1: Subject-Specific Interaction Terms with Statistical Sparsification
Modeling subject-specific deviations through interaction terms, then pruning non-significant features via nested F-tests, enables personalization without overfitting. One-hot encoded subject IDs are interacted with all features, creating a design matrix equivalent to separate models per subject. An iterative backward elimination computes F-statistics comparing full vs. reduced models; the predictor with the largest p-value exceeding α is removed until no term violates the criterion.

### Mechanism 2: Regression-then-Thresholding for Ordinal Macro-F1 Optimization
Predicting continuous latent scores via OLS, then optimizing discretization thresholds for macro-F1, aligns predictions with ordinal evaluation metrics better than direct classification. OLS predicts continuous ẑ; thresholds τ are tuned by searching for stable plateau regions where both chronological folds maintain high macro-F1 simultaneously.

### Mechanism 3: Confidence-Based Gating for Selective Black-Box Integration
Selectively adopting LightGBM predictions only at very high confidence corrects linear model blind spots while preserving overall interpretability. When SASL and LightGBM disagree, adopt LightGBM's prediction only if max class probability ≥ 0.97. This limits black-box influence to high-certainty cases, leaving most predictions transparent.

## Foundational Learning

- **Nested F-test for Feature Selection:** Core sparsification mechanism; understanding how F-tests compare reduced vs. full models is essential for interpreting the elimination trace. Quick check: Given SSE_reduced, SSE_full, N=450, and p=50, can you compute the F-statistic and determine whether a feature with p-value = 0.12 should be removed at α = 0.05?

- **Interaction Terms in Linear Regression:** Subject adaptation is implemented entirely via ID × feature interactions; interpreting coefficients requires understanding how interactions modify base effects. Quick check: If β_screen = −0.3 globally and β_screen×id01 = +0.2, what is the effective screen coefficient for subject id01?

- **Macro-F1 vs. Accuracy for Ordinal/Imbalanced Targets:** Threshold optimization explicitly targets macro-F1; understanding why requires knowing macro-F1 equally weights all classes regardless of frequency. Quick check: Why would a model achieving 85% accuracy on a 5-class ordinal problem with 70% of samples in one class potentially have poor macro-F1?

## Architecture Onboarding

- **Component map:** Preprocessing (standardize, one-hot subject IDs, generate interactions) → Full interaction model → F-test elimination (with seed tuning) → Fit final OLS → Threshold search → Confidence gating
- **Critical path:** Feature engineering → Full interaction model → F-test elimination (with seed tuning) → Fit final OLS → Threshold search → Confidence gating
- **Design tradeoffs:** Parsimony vs. personalization (aggressive elimination may remove genuine signals); Interpretability vs. accuracy (LightGBM gating improves macro-F1 but introduces black-box dependency); Global vs. local (subject interactions capture deviations but assume linear heterogeneity)
- **Failure signatures:** Over-pruning (model collapses to underfitted global baseline); Temporal leakage (random shuffling in validation inflates performance); Threshold instability (if τ doesn't plateau across folds, predictions become seed-sensitive); S2 underperformance (sleep efficiency requires dedicated pipeline)
- **First 3 experiments:** Baseline comparison (SASL vs. full interaction model vs. simple global OLS on held-out test); Ablation on gating (disable confidence gating and measure macro-F1 drop); Threshold sensitivity analysis (vary τ around reported values and confirm plateau robustness)

## Open Questions the Paper Calls Out

- **Open Question 1:** How does model performance and interpretability change when SASL is applied to the original continuous ground-truth labels rather than the discretized ordinal categories used in the competition? The study was constrained by the competition dataset, which converted continuous health states into coarse ordinal bins.

- **Open Question 2:** Can the SASL framework incorporate sequential dependencies or detailed temporal dynamics without sacrificing the sparsity and computational efficiency of the current daily-summary approach? The current approach relies on daily summary statistics, which flatten intra-day variations that might be critical for prediction.

- **Open Question 3:** Does the subject-adaptive interaction mechanism scale effectively to populations with thousands of users, or does the design matrix become too sparse/inflated to maintain statistical robustness? The method was validated on a very small cohort, but the use of one-hot encoded ID interaction terms may face dimensionality and sparsity challenges in large-scale deployments.

## Limitations

- The nested F-test backward elimination relies heavily on the choice of significance threshold α, which is not specified in the paper
- The confidence-based gating mechanism's threshold (0.97) appears arbitrary and lacks sensitivity analysis
- The S2 pipeline's 172 temporal features and k-means archetypes are highly specialized, raising questions about generalizability

## Confidence

- **High Confidence:** The linear interaction framework and F-test elimination methodology are well-established statistical techniques
- **Medium Confidence:** The regression-then-thresholding approach for macro-F1 optimization is novel and well-motivated, but the plateau identification method lacks rigorous definition
- **Low Confidence:** The S2-specific pipeline (172 features, k-means archetypes) appears overfitted to this particular target

## Next Checks

1. **Parameter Sensitivity Analysis:** Systematically vary α in the F-test elimination and confidence gating threshold; document performance impact and identify stable operating regions
2. **Ablation Study on S2 Pipeline:** Remove the specialized temporal features and k-means archetypes; test whether standard SASL features achieve comparable S2 performance
3. **Generalization Test:** Apply the framework to an external multimodal health dataset; verify that the interaction-based personalization and thresholding strategy transfer beyond CH-2025