---
ver: rpa2
title: 'Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic
  Reasoning'
arxiv_id: '2511.02194'
source_url: https://arxiv.org/abs/2511.02194
tags:
- choice
- utility
- symbolic
- travel
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ATHENA, a two-stage framework for personalized
  decision modeling that integrates symbolic utility discovery and LLM-driven semantic
  adaptation. In the first stage, group-level symbolic utility functions are discovered
  via LLM-augmented symbolic regression; in the second, individual-level semantic
  templates are optimized using textual gradients.
---

# Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning

## Quick Facts
- arXiv ID: 2511.02194
- Source URL: https://arxiv.org/abs/2511.02194
- Authors: Yibo Zhao; Yang Zhao; Hongru Du; Hao Frank Yang
- Reference count: 40
- Key outcome: ATHENA achieves 6.5%+ F1 score improvements over baselines in personalized decision modeling tasks

## Executive Summary
This paper introduces ATHENA, a two-stage framework for personalized decision modeling that integrates symbolic utility discovery and LLM-driven semantic adaptation. The framework first discovers group-level symbolic utility functions via LLM-augmented symbolic regression, then optimizes individual-level semantic templates using textual gradients. Evaluated on Swissmetro travel mode choice and COVID-19 vaccine uptake tasks, ATHENA consistently outperforms classical utility models, ML classifiers, and LLM baselines. The framework produces interpretable symbolic utilities while improving calibration on semantically similar choices.

## Method Summary
ATHENA operates through a two-stage pipeline. First, it discovers group-level symbolic utility functions by combining classical symbolic regression with LLM augmentation to extract and formalize utility structures from behavioral data. Second, it performs individual-level semantic adaptation by optimizing textualized utility templates through gradient-based methods on semantic representations. This allows the framework to maintain interpretability while achieving personalization. The approach bridges traditional utility theory with modern LLMs, enabling both symbolic reasoning and semantic flexibility in decision modeling.

## Key Results
- ATHENA achieves at least 6.5% higher F1 scores compared to classical utility models, ML classifiers, and LLM baselines
- Ablation studies show that removing either the symbolic discovery stage or semantic adaptation stage reduces performance by at least 18%
- The framework produces interpretable symbolic utilities while maintaining strong calibration on semantically similar choices

## Why This Works (Mechanism)
ATHENA leverages LLMs to bridge the gap between symbolic utility discovery and semantic personalization. By first discovering interpretable utility functions at the group level, it establishes a solid theoretical foundation. The textualization of these utilities enables semantic adaptation at the individual level, where textual gradients can optimize the representation for personal preferences. This two-stage approach combines the interpretability of symbolic methods with the flexibility of semantic learning, allowing the model to capture both common decision structures and individual variations.

## Foundational Learning
- **Symbolic Regression**: A technique that discovers mathematical expressions from data; needed for interpretable utility discovery, quick check: verify discovered functions match known utility forms
- **Textual Gradients**: Gradient-based optimization on textual representations; needed for semantic adaptation, quick check: ensure gradients lead to meaningful utility modifications
- **Utility Theory**: Economic framework for modeling preferences; needed for interpretable decision modeling, quick check: validate utility functions satisfy rationality axioms
- **LLM Semantic Embeddings**: Vector representations of text meaning; needed for capturing semantic relationships in utilities, quick check: test embedding quality on utility-related text

## Architecture Onboarding

**Component Map**: Symbolic Regression -> Textualization -> Semantic Adaptation -> Utility Optimization

**Critical Path**: The framework's core path flows from group-level symbolic utility discovery through textual representation to individual-level semantic optimization. This path is essential for maintaining both interpretability and personalization.

**Design Tradeoffs**: The approach trades computational efficiency for interpretability and personalization. While classical ML models may be faster, ATHENA provides symbolic, interpretable utilities that can be adapted to individuals. The two-stage design adds complexity but enables the combination of symbolic reasoning with semantic flexibility.

**Failure Signatures**: Performance degradation may occur if: symbolic discovery fails to capture true utility structure, textualization loses semantic information, or semantic adaptation overfits to individual noise. The ablation studies show that either stage alone significantly reduces performance.

**3 First Experiments**:
1. Run ATHENA on a simple synthetic dataset with known utility structure to verify correct symbolic discovery
2. Test the textualization stage by comparing embeddings of original and modified utilities for semantic similarity
3. Perform ablation by running with only the symbolic discovery stage to measure baseline performance

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation limited to two specific behavioral datasets (Swissmetro travel mode choice and COVID-19 vaccine uptake) with modest sample sizes
- Symbolic regression performance depends heavily on LLM prompt engineering quality and may vary with model versions
- Computational overhead of the two-stage process compared to simpler models is not quantified
- Interpretability claims lack independent validation from domain experts

## Confidence
**High Confidence**: Core methodology is clearly articulated and comparative performance against established baselines is robust across both datasets. Ablation study results provide strong evidence for framework design.

**Medium Confidence**: Interpretability claims and semantic adaptation effectiveness are supported by methodology but lack independent expert validation. Generalizability to other domains and larger datasets is suggested but not empirically demonstrated.

**Low Confidence**: Computational efficiency and scalability for real-world deployment are not addressed. Sensitivity to specific LLM choices and prompt engineering is acknowledged but not systematically explored.

## Next Checks
1. Test ATHENA on additional decision-making datasets from different domains (e.g., consumer choice, financial decisions) to assess generalizability beyond the two current behavioral datasets.

2. Conduct a blinded expert review where domain specialists evaluate the interpretability and utility of the discovered symbolic functions, comparing ATHENA outputs to ground-truth utility structures.

3. Perform systematic ablation studies varying the underlying LLM model (different sizes, architectures) and prompt engineering strategies to quantify the sensitivity of ATHENA's performance to these implementation choices.