---
ver: rpa2
title: Neural Risk-sensitive Satisficing in Contextual Bandits
arxiv_id: '2501.08612'
source_url: https://arxiv.org/abs/2501.08612
tags:
- action
- reglinrs
- neuralrs
- each
- reliability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Neural Risk-sensitive Satisficing (NeuralRS),
  an algorithm that extends RegLinRS by incorporating neural networks for contextual
  bandit problems. NeuralRS addresses limitations in RegLinRS where linear approximation
  restricts handling non-linear relationships between features and expected rewards.
---

# Neural Risk-sensitive Satisficing in Contextual Bandits

## Quick Facts
- arXiv ID: 2501.08612
- Source URL: https://arxiv.org/abs/2501.08612
- Authors: Shogo Ito; Tatsuji Takahashi; Yu Kono
- Reference count: 10
- Primary result: NeuralRS with kNN reliability estimation achieved lower regret than NeuralUCB and NeuralTS on both artificial and real-world datasets

## Executive Summary
This paper proposes NeuralRS, an algorithm extending RegLinRS to handle non-linear relationships between features and expected rewards in contextual bandit problems. The method uses neural networks as function approximators while maintaining the satisficing framework for switching between exploration and exploitation based on target achievement status. NeuralRS demonstrates lower regret compared to benchmark algorithms, with kNN-based reliability estimation showing the best performance.

## Method Summary
NeuralRS extends RegLinRS by replacing linear function approximation with a neural network backbone (2 FC layers, 128 hidden units, ReLU activations) to estimate expected rewards per action. The algorithm computes a value function I_i = ρ_i(f_i(x_t) - ℵ) where ρ_i is a reliability estimate and ℵ is an aspiration level. Reliability is estimated in the neural network's latent space using either k-means centroids or kNN lookup. The algorithm trains online via MSE loss with batch size 1024 and Adam optimizer (lr=1e-3). Action selection uses argmax over computed values, switching between optimistic exploration (when expected reward < ℵ) and pessimistic exploitation (when expected reward ≥ ℵ) based on trial ratios.

## Key Results
- NeuralRS with kNN reliability achieved lower cumulative regret than NeuralUCB and NeuralTS on both artificial and Statlog-Shuttle datasets
- k-means reliability estimation offered computational efficiency advantages over kNN while maintaining competitive performance
- The satisficing framework with aspiration level ℵ=0.65 effectively balanced exploration and exploitation
- NeuralRS adapted more flexibly to complex environments compared to linear approaches

## Why This Works (Mechanism)

### Mechanism 1: Satisficing-Driven Exploration-Exploitation Switching
The algorithm switches between exploration and exploitation based on target achievement status using the value function I^NeuralRS_i = ρ_i(f_i(x_t) - ℵ). When expected reward f_i < aspiration level ℵ, actions with low reliability receive optimistic value boosts promoting exploration. When f_i ≥ ℵ, high-reliability actions are preferred promoting exploitation. The trial ratio ρ_i acts as a confidence weight—under-explored actions get exploration incentives. Core assumption: environment has achievable target reward level and agents can estimate whether they are "on track" relative to this target.

### Mechanism 2: Neural Network Function Approximation for Non-linear Reward Surfaces
Neural networks enable reward estimation in environments where feature-reward relationships are non-linear, extending beyond RegLinRS's linear assumptions. A feedforward network with ReLU activations maps feature vectors to expected rewards per action, trained online via MSE loss. The penultimate layer's latent representation z_t is reused for reliability estimation. Core assumption: true reward function is smooth enough to be approximated by shallow neural network; online gradient descent converges sufficiently within bandit's decision horizon.

### Mechanism 3: Latent-Space Reliability Estimation via k-means/kNN
Estimating reliability (trial ratio) in neural network's latent space provides more accurate confidence weights than raw feature space or simple count-based methods. Multiple centroids per action are maintained in the penultimate layer's representation space, with kNN using nearest neighbors from episodic memory instead of centroids. Core assumption: learned latent representation clusters meaningfully by action-reward similarity; distances in this space correlate with decision uncertainty.

## Foundational Learning

- **Contextual Bandit Problem**: At each timestep, agent receives feature vector, selects action, and observes only reward for that action (not counterfactual rewards). Needed because this is the core formalism NeuralRS operates within.
  - Quick check: Can you explain why contextual bandits differ from both multi-armed bandits (no context) and full reinforcement learning (delayed rewards)?

- **Exploration-Exploitation Trade-off and Regret**: The satisficing framework is a solution to this trade-off; regret is the evaluation metric. Needed to understand why NeuralRS's approach differs from optimization-based methods.
  - Quick check: Why might minimizing regret be different from maximizing cumulative reward in practice?

- **Aspiration Level (Satisficing)**: The ℵ parameter defines what "good enough" means and is central to NeuralRS's switching mechanism. Needed because this parameter determines when the algorithm switches between exploration and exploitation.
  - Quick check: How would you set ℵ if you knew the maximum achievable reward was 1.0 and you wanted to reach 80% of optimal?

## Architecture Onboarding

- **Component map**: Input features -> Neural network (2 FC layers, 128 ReLU, K outputs) -> Latent representation z_t -> Reliability estimation (k-means or kNN) -> Value computation I_i = ρ_i(f_i - ℵ) -> Action selection (argmax)

- **Critical path**: 
  1. Receive feature x_t → forward pass through NN → get f_i for all actions
  2. Compute latent representation z_t from penultimate layer
  3. Update reliability ρ_i using k-means centroids or kNN lookup
  4. Compute value I_i = ρ_i × (f_i - ℵ), select argmax action
  5. Observe reward r_t, store transition, update NN via MSE gradient step

- **Design tradeoffs**:
  - kNN vs. k-means reliability: kNN gives lower regret but requires O(memory_size) lookups; k-means is O(M) per action and better for large-scale/real-time systems
  - Aspiration level ℵ: Higher ℵ → more exploration, potentially lower regret but slower convergence; lower ℵ → faster exploitation but risk of suboptimal convergence
  - Network depth: Paper uses 2 layers for simplicity; deeper networks may capture more complex reward functions but increase training variance and computational cost

- **Failure signatures**:
  - Regret plateaus early but remains high → ℵ likely too low (premature exploitation)
  - Regret continues growing linearly → ℵ too high or neural network underfitting
  - k-means reliability unstable → centroids poorly initialized; try more centroids or kNN fallback
  - Cross-entropy reliability performs poorly → early-stage NN outputs are unreliable; consider warm-start period

- **First 3 experiments**:
  1. Sanity check on linear data: Replicate artificial dataset experiment to verify NeuralRS achieves comparable regret to RegLinRS and lower than NeuralUCB/NeuralTS
  2. Ablation on reliability methods: On Statlog-Shuttle dataset, compare kNN, k-means, cross-entropy, and trial-ratio reliability
  3. Aspiration level sensitivity: Sweep ℵ ∈ {0.5, 0.6, 0.65, 0.7, 0.8} on both datasets to identify regret-minimizing setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does k-means-based reliability estimation outperform kNN-based estimation in terms of regret and computational efficiency on large-scale, noisy, and complex datasets?
- Basis in paper: Authors state future work will include evaluating k-means-based reliability estimation on large, noisy, and complex datasets to confirm its practicality.
- Why unresolved: Current experiments limited to datasets of 10,000 steps; kNN performed best but authors hypothesize k-means offers computational advantages and robustness to noise that would make it superior in larger, real-world settings.
- What evidence would resolve it: Empirical results from experiments on high-dimensional datasets with significantly larger sample sizes (>100k steps) and injected noise, comparing wall-clock time and cumulative regret of k-means against kNN.

### Open Question 2
- Question: How sensitive is the performance of NeuralRS to the selection of the aspiration level (ℵ), and does this require domain-specific tuning?
- Basis in paper: ℵ is defined as a fixed hyperparameter (set to 0.65 in experiments) crucial for switching between exploration and exploitation, but paper does not analyze how deviations impact regret.
- Why unresolved: Satisficing mechanism depends entirely on achieving target ℵ; if ℵ is set too high or low relative to true reward distribution, algorithm might fail to switch strategies correctly.
- What evidence would resolve it: Ablation study showing change in cumulative regret as aspiration level ℵ is varied across different environments with different reward scales.

### Open Question 3
- Question: Can Cross-Entropy (XE) based reliability estimation become a viable alternative if stabilized during early phases of training?
- Basis in paper: Authors note XE-based reliability performed worst, likely because "NN outputs... can be unstable in earlier time steps," suggesting failure might be due to implementation timing rather than method itself.
- Why unresolved: Paper dismisses XE based on initial results, but it remains unclear if low performance is inherent flaw or symptom of cold-start problem.
- What evidence would resolve it: Experiments utilizing warm-up period or pre-training for neural network before enabling XE-based reliability updates.

## Limitations

- The satisficing framework assumes a well-calibrated aspiration level with no adaptive mechanism provided for setting or updating ℵ based on observed performance
- The neural network's capacity (128 hidden units) may be insufficient for highly non-linear reward surfaces, potentially limiting generalization to more complex environments
- k-means reliability method's performance is sensitive to centroid initialization and decay rate; poor initialization can lead to unreliable early estimates

## Confidence

- **High confidence** in satisficing mechanism for switching between exploration and exploitation based on target achievement status
- **Medium confidence** in neural network function approximation's ability to capture non-linear reward surfaces, given shallow architecture and online training constraints
- **Medium confidence** in k-means reliability estimation's effectiveness, though kNN shows superior empirical performance

## Next Checks

1. **Ablation on Network Depth**: Test NeuralRS with 1, 3, and 4 hidden layers on artificial dataset to assess whether increased capacity improves regret beyond 2-layer baseline

2. **Aspiration Level Robustness**: Perform grid search over ℵ ∈ {0.4, 0.5, 0.6, 0.7, 0.8} on both datasets to identify optimal setting and measure performance sensitivity to misspecification

3. **Latent Space Structure Analysis**: Visualize penultimate layer's representation space for k-means reliability (e.g., via t-SNE) on held-out validation set to verify action clusters are meaningful and distances correlate with decision uncertainty