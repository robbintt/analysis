---
ver: rpa2
title: 'ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification
  Models'
arxiv_id: '2510.20084'
source_url: https://arxiv.org/abs/2510.20084
tags:
- perturbed
- auroc
- proportion
- time
- shapex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SHAPEX introduces a novel post-hoc explanation framework for time
  series classification that addresses the limitation of existing methods by focusing
  on shapelet-driven segment-level attribution rather than individual timesteps. The
  core idea involves learning a compact set of shapelets using the Shapelet Describe-and-Detect
  (SDD) framework, which segments time series into meaningful units aligned with these
  shapelets, and then applying Shapley value analysis to assess their contribution
  to classification outcomes.
---

# ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models

## Quick Facts
- arXiv ID: 2510.20084
- Source URL: https://arxiv.org/abs/2510.20084
- Reference count: 40
- Primary result: Achieves 58.12% average AUPRC improvement on synthetic datasets compared to existing methods

## Executive Summary
ShapeX introduces a novel post-hoc explanation framework for time series classification that addresses the limitation of existing methods by focusing on shapelet-driven segment-level attribution rather than individual timesteps. The core idea involves learning a compact set of shapelets using the Shapelet Describe-and-Detect (SDD) framework, which segments time series into meaningful units aligned with these shapelets, and then applying Shapley value analysis to assess their contribution to classification outcomes. Experiments demonstrate that ShapeX consistently outperforms existing methods, achieving an average AUPRC improvement of 58.12% on synthetic datasets and showing superior robustness across 114 real-world datasets from the UCR archive. The framework also provides theoretical justification for interpreting its attributions as causal rather than merely correlational, enhancing trustworthiness in high-stakes applications like healthcare and finance.

## Method Summary
ShapeX is a two-phase framework that first trains a Shapelet Describe-and-Detect (SDD) module to learn N shapelets of length L from the training data, then uses these shapelets to segment time series during inference. The SDD framework uses a descriptor-detector layer with 1D convolution to compute activation maps, followed by softmax normalization and peak detection to identify shapelet-aligned segments. At inference, ShapeX applies a Shapelet-Driven Segment-Level (SDSL) perturbation that uses linear interpolation to mask identified segments, then computes Shapley values using a temporally-relational subset strategy. The framework is evaluated on synthetic datasets (MCC-E, MCC-H, MTC-E, MTC-H), ECG data, and 114 datasets from the UCR archive using black-box classifiers including Transformer, LSTM, CNN, and MultiRocket.

## Key Results
- Achieves 58.12% average AUPRC improvement on synthetic datasets compared to existing methods
- Shows superior robustness across 114 real-world datasets from the UCR archive
- Provides theoretical justification for causal interpretation of attributions through Shapley value analysis
- Linear interpolation perturbation ("w/o LIN" ablation) significantly improves performance by avoiding boundary artifacts

## Why This Works (Mechanism)

### Mechanism 1: Shapelet-Atomicity in Segmentation
- **Claim:** If time series are segmented based on learned morphological patterns (shapelets) rather than fixed intervals, the resulting saliency maps are more likely to preserve the integrity of class-discriminative features.
- **Mechanism:** The Shapelet Describe-and-Detect (SDD) framework learns a compact set of shapelets. During inference, the time series is segmented specifically where activation maps exceed a threshold for these shapelets. This ensures that perturbations applied to a "segment" affect a semantically whole unit rather than arbitrary time slices.
- **Core assumption:** Classification decisions are driven by specific subsequence shapes (shapelets) rather than individual timestep values.
- **Evidence anchors:** [abstract] "segments time series into shapelet-aligned segments... overlooked the fundamental prior that classification outcomes are predominantly driven by key shapelets."

### Mechanism 2: Linear Interpolation for Counterfactuals
- **Claim:** If perturbations use linear interpolation between segment boundaries rather than zero-filling (mean-substitution), the resulting "removed" segments create fewer artifacts in the frequency domain, leading to more faithful attribution.
- **Mechanism:** The Shapelet-Driven Segment-Level (SDSL) perturbation creates a synthetic baseline that smoothly bridges the start and end of the masked segment. This mimics the "removal" of the pattern without introducing abrupt discontinuities that might trigger a model's sensitivity to noise rather than the absence of the feature.
- **Core assumption:** The black-box model's behavior is sensitive to input distribution shifts caused by abrupt masking artifacts.
- **Evidence anchors:** [page 6] "introduces abrupt changes at boundaries... preventing the value function... from fully eliminating the influence."

### Mechanism 3: Shapley Value as Approximate Causal Intervention
- **Claim:** Under specific assumptions (SUTVA, Ignorability), computing Shapley values over shapelet-segments approximates the model-level Conditional Average Treatment Effect (CATE), distinguishing causal drivers from correlation.
- **Mechanism:** By framing the retention vs. masking of a segment as an intervention, the marginal contribution calculated by Shapley values represents the expected change in model output given that intervention. This moves the explanation from "what is present" to "what causes the prediction."
- **Core assumption:** Segments are independent interventions (SUTVA) and the assignment of masks is independent of potential outcomes (Ignorability).
- **Evidence anchors:** [page 7] "ShapeX produces explanations which reveal causal relationships instead of just correlations."

## Foundational Learning

- **Concept:** **Shapley Values (Game Theory)**
  - **Why needed here:** This is the mathematical engine for calculating attribution. You must understand "marginal contribution" and "coalitions" to interpret why specific segments receive high saliency scores.
  - **Quick check question:** If adding a segment to a coalition changes the prediction from 0.4 to 0.9, what is its marginal contribution?

- **Concept:** **Shapelets**
  - **Why needed here:** Unlike raw pixels or timesteps, shapelets are "short, class-discriminative subsequences." Understanding this distinction is critical to grasping why timestep-level methods fail and why ShapeX works.
  - **Quick check question:** In an ECG signal, is the QRS complex a shapelet or a timestep?

- **Concept:** **Post-Hoc vs. In-Hoc Explainability**
  - **Why needed here:** ShapeX is post-hoc (explains a pre-trained black box). You need to distinguish this from models that are interpretable by design to understand the constraints of not modifying the classifier.
  - **Quick check question:** Does ShapeX require access to the training data of the black-box model or the weights of the black-box model?

## Architecture Onboarding

- **Component map:** SDD Framework (Training) -> Descriptor-Detector Layer -> Shapelet Encoder -> SDSL Module (Inference) -> Shapley Attribution
- **Critical path:** The Descriptor-Detector Layer. If the activation map is noisy, the peak detection will misalign the segments, causing the entire Shapley calculation to evaluate the wrong subsequence.
- **Design tradeoffs:**
  - **Granularity vs. Cost:** Increasing the number of shapelets (N) captures more latent features (higher Recall) but increases Shapley computation cost.
  - **Pre-training overhead:** Unlike gradient-based methods (e.g., Integrated Gradients), ShapeX requires a separate training phase for the SDD module, trading speed for semantic alignment.
- **Failure signatures:**
  - **Segment Drift:** If the matching loss (L_match) is too low, the detector extracts subsequences that don't morphologically resemble the shapelet prototype.
  - **Distribution Shift Artifacts:** If linear perturbation is disabled (ablation "w/o LIN"), performance drops, indicating the model is reacting to masking artifacts rather than feature absence.
- **First 3 experiments:**
  1. **Sanity Check (Motif Dataset):** Run ShapeX on synthetic "MCC-E" data to verify it correctly highlights the inserted motifs with 100% overlap.
  2. **Ablation on Perturbation Type:** Compare "w/o LIN" (zero-masking) vs. Full ShapeX on the ECG dataset to visualize boundary artifacts in the saliency map.
  3. **Occlusion Robustness:** Run occlusion experiments on the UCR archive to confirm that removing high-saliency segments causes a steeper drop in classifier accuracy than removing random segments.

## Open Questions the Paper Calls Out

- **Can automated mechanisms be developed to determine the optimal number and length of shapelets without requiring manual, dataset-specific tuning?**
  - **Basis in paper:** [explicit] The Conclusion states that the framework relies on "user-defined hyperparameters" and that "Future work could address these limitations through automated hyperparameter selection."
  - **Why unresolved:** The current implementation requires manual calibration to balance granularity and diversity, limiting its "plug-and-play usability" on unseen domains.
  - **What evidence would resolve it:** A version of the SDD framework that dynamically adjusts shapelet parameters based on input data statistics while maintaining AUPRC performance.

- **How can the framework be generalized to effectively explain models processing multivariate and irregular time series?**
  - **Basis in paper:** [explicit] The Conclusion identifies the need for "generalized formulations for multivariate and irregular time series," noting the current method focuses on the univariate setting (D=1).
  - **Why unresolved:** The current mathematical formulation and perturbation strategy rely on fixed-length, univariate assumptions.
  - **What evidence would resolve it:** Successful extension of ShapeX to multivariate datasets where shapelets capture cross-channel dependencies, validated against multivariate benchmarks.

- **Can a joint-training or lightweight strategy be devised to reduce the computational overhead of the separate SDD training phase?**
  - **Basis in paper:** [explicit] The Conclusion acknowledges that the separate training phase "sacrifices some efficiency" and suggests "lightweight or joint-training strategies" as future work.
  - **Why unresolved:** Unlike purely gradient-based methods, ShapeX requires a distinct pre-training stage to learn representative shapelets, increasing computational cost.
  - **What evidence would resolve it:** Demonstrating an integrated training pipeline that achieves comparable fidelity to the current two-stage approach with reduced wall-clock time.

## Limitations
- ShapeX's segmentation quality depends entirely on the SDD framework's ability to correctly identify shapelets, which is not fully validated across diverse real-world datasets
- The theoretical causal interpretation (Proposition 1) assumes SUTVA and Ignorability conditions that may not hold in practice, particularly when segments are temporally correlated
- The paper reports strong performance on 114 UCR datasets but doesn't characterize failure modes when shapelets are ambiguous or when time series contain multiple overlapping patterns

## Confidence
- **High Confidence:** The ablation study showing performance drops when removing linear interpolation ("w/o LIN") and matching loss ("w/o M") is well-documented with quantitative evidence
- **Medium Confidence:** The 58.12% AUPRC improvement on synthetic datasets is compelling, but synthetic data with inserted motifs may not generalize to complex real-world patterns where shapelet identification is ambiguous
- **Low Confidence:** The causal interpretation claim lacks empirical validationâ€”no experiments demonstrate that high-saliency segments actually cause prediction changes versus merely correlating with them

## Next Checks
1. **Cross-dataset robustness:** Test ShapeX on time series datasets with known shapelet ambiguity (e.g., ECG with multiple arrhythmia types) and quantify how often the SDD framework fails to identify coherent segments
2. **Causal intervention experiment:** For datasets with ground-truth feature importance, perform targeted occlusion of high-saliency segments and measure if classifier accuracy drops more than random occlusions, validating the causal interpretation
3. **Segment fragmentation analysis:** On real-world datasets, measure the average segment length produced by SDD versus the average motif length, quantifying how often the segmentation splits coherent patterns versus preserving them