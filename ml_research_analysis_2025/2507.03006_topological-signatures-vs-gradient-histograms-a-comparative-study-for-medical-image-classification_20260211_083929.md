---
ver: rpa2
title: 'Topological Signatures vs. Gradient Histograms: A Comparative Study for Medical
  Image Classification'
arxiv_id: '2507.03006'
source_url: https://arxiv.org/abs/2507.03006
tags:
- features
- image
- topological
- classification
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study presents the first comparative analysis of two handcrafted\
  \ feature extraction methods\u2014Histogram of Oriented Gradients (HOG) and Topological\
  \ Data Analysis (TDA) via persistent homology\u2014for medical image classification\
  \ using retinal fundus images. HOG captures local texture and edge information,\
  \ while TDA extracts global topological signatures from pixel intensity structures."
---

# Topological Signatures vs. Gradient Histients: A Comparative Study for Medical Image Classification

## Quick Facts
- arXiv ID: 2507.03006
- Source URL: https://arxiv.org/abs/2507.03006
- Reference count: 38
- Primary result: HOG and TDA features achieve 94% accuracy on diabetic retinopathy classification

## Executive Summary
This study presents the first comparative analysis of Histogram of Oriented Gradients (HOG) and Topological Data Analysis (TDA) via persistent homology for medical image classification using retinal fundus images. Both handcrafted feature extraction methods were evaluated independently using seven classical machine learning models on the APTOS dataset for binary (normal vs diabetic retinopathy) and five-class (DR severity grading) classification tasks. XGBoost achieved the best performance with 94.29% accuracy using HOG and 94.18% using TDA in binary classification, and 74.41% (HOG) and 74.69% (TDA) in five-class classification. The results demonstrate that both methods offer competitive performance while encoding different structural aspects of images, providing complementary insights for medical image analysis.

## Method Summary
The study compares two handcrafted feature extraction methods for medical image classification. Histogram of Oriented Gradients (HOG) captures local texture and edge information through gradient orientation histograms, while Topological Data Analysis (TDA) extracts global topological signatures from pixel intensity structures using persistent homology. Both feature sets were computed independently from retinal fundus images and evaluated using seven classical machine learning models. The binary classification task distinguished normal from diabetic retinopathy images, while the five-class task performed severity grading of diabetic retinopathy. XGBoost was identified as the optimal classifier for both feature types across both tasks.

## Key Results
- Binary classification: XGBoost achieved 94.29% accuracy with HOG and 94.18% with TDA features
- Five-class classification: XGBoost achieved 74.41% accuracy with HOG and 74.69% with TDA features
- Both methods demonstrated competitive performance with different structural encoding approaches

## Why This Works (Mechanism)
The study demonstrates that both local gradient-based features (HOG) and global topological features (TDA) can effectively capture discriminative patterns in medical images. HOG excels at encoding local texture and edge information that is crucial for identifying pathological structures, while TDA captures the global topological relationships and connectivity patterns within the image intensity distributions. The complementary nature of these feature types allows them to encode different aspects of the same image, potentially providing robust representations for medical diagnosis tasks.

## Foundational Learning
- **Histogram of Oriented Gradients (HOG)**: Captures local gradient orientations and edge structures - needed for encoding texture and boundary information; quick check: visualize gradient histograms on sample images
- **Persistent Homology**: Extracts topological features by tracking connected components across different scales - needed for capturing global structural patterns; quick check: verify Betti number computations
- **XGBoost Algorithm**: Gradient boosting framework that builds sequential decision trees - needed for handling high-dimensional feature vectors effectively; quick check: examine feature importance scores
- **Diabetic Retinopathy Classification**: Medical task requiring discrimination between normal and pathological retinal images - needed for real-world clinical validation; quick check: review ground truth labeling accuracy
- **Handcrafted vs Deep Features**: Traditional feature engineering vs learned representations - needed to understand when classical methods remain competitive; quick check: compare computational requirements
- **Medical Image Analysis Pipeline**: End-to-end processing from raw images to classification - needed for deployment considerations; quick check: measure inference latency

## Architecture Onboarding

**Component Map**: Raw Image -> Preprocessing -> Feature Extraction (HOG/TDA) -> Machine Learning Model (XGBoost) -> Classification Output

**Critical Path**: The feature extraction stage represents the critical path, as both HOG and TDA are computationally intensive operations that directly impact downstream model performance. The choice between HOG and TDA affects both computational requirements and the type of information captured.

**Design Tradeoffs**: HOG offers faster computation and better interpretability for local structures but may miss global topological patterns. TDA captures global structural information but requires more computational resources and complex parameter tuning. Both methods trade computational efficiency for interpretability compared to deep learning approaches.

**Failure Signatures**: Poor performance may indicate inadequate preprocessing, incorrect parameter settings for feature extraction, or class imbalance issues. Both methods are sensitive to image quality and resolution, with TDA particularly affected by noise in intensity distributions.

**First Experiments**:
1. Test feature extraction on a small subset of images to verify computational feasibility and parameter sensitivity
2. Evaluate individual feature importance using XGBoost's built-in analysis tools
3. Perform cross-validation with different machine learning models to identify optimal classifier selection

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Single-dataset evaluation limits generalizability across different imaging protocols and populations
- No computational efficiency analysis or runtime comparisons between methods
- Lack of quantitative validation for interpretability claims regarding model complexity and parameter counts

## Confidence
- **High**: Binary classification results (94% accuracy) demonstrate robust performance
- **Medium**: Five-class grading task (74% accuracy) shows moderate performance with potential for improvement

## Next Checks
1. Cross-dataset validation using MESSIDOR or EyePACS to verify robustness across different imaging platforms
2. Computational complexity analysis comparing feature extraction times, model training durations, and memory requirements
3. Ablation studies testing feature fusion approaches to quantify complementarity and potential performance gains