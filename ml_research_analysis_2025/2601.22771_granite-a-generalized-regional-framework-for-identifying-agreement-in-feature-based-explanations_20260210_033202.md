---
ver: rpa2
title: 'GRANITE: A Generalized Regional Framework for Identifying Agreement in Feature-Based
  Explanations'
arxiv_id: '2601.22771'
source_url: https://arxiv.org/abs/2601.22771
tags:
- feature
- explanations
- regional
- pure
- disagreement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GRANITE is a generalized regional framework that addresses disagreement
  in feature-based explanations by partitioning the feature space into regions where
  interaction and distribution influences are minimized. The method unifies existing
  regional approaches and extends them to feature groups, providing consistent and
  interpretable explanations for black-box models.
---

# GRANITE: A Generalized Regional Framework for Identifying Agreement in Feature-Based Explanations

## Quick Facts
- arXiv ID: 2601.22771
- Source URL: https://arxiv.org/abs/2601.22771
- Reference count: 40
- Primary result: GRANITE partitions feature space to minimize disagreement between explanation methods by reducing interaction and distribution influences

## Executive Summary
GRANITE addresses the problem of disagreement between different feature-based explanation methods for black-box models. The framework partitions the feature space into regions where the model's behavior becomes more consistent across explanation approaches. By minimizing the disagreement between methods like ICE vs PDP (interaction effects) and CFI vs PFI (distribution influences), GRANITE produces more interpretable and reliable explanations that reveal how model behavior varies across different subpopulations.

## Method Summary
GRANITE uses recursive partitioning to create regions where feature-based explanations align. The method pre-computes evaluation matrices R^S for all feature subsets S, then builds a decision tree that splits on features and thresholds to minimize regional disagreement between explanation methods. The algorithm handles both interaction-based disagreement (pure vs full effects) and distribution-based disagreement (marginal vs conditional masking). The framework is extensible to feature groups and allows simultaneous optimization of multiple disagreement sources.

## Key Results
- On Bikesharing dataset, reduced ICE vs PDP interaction disagreement from 100% to 4% in specific regions
- Reduced CFI vs PFI distribution disagreement from 100% to 3% at maximum depth
- Maximum depth of 3 provided optimal trade-off between disagreement reduction and interpretability
- Framework unifies existing regional approaches while extending them to feature groups

## Why This Works (Mechanism)

### Mechanism 1: Interaction-based Disagreement Decomposition
The framework decomposes disagreement between explanation methods into interaction terms using functional ANOVA. If features interact, pure effects (accounting only for direct feature influence) differ from full effects (including interactions). By Theorem 1, the disagreement φ₁ - φ₂ equals a weighted sum of interaction terms Δ(S), meaning the framework explicitly captures higher-order interactions as the source of disagreement.

### Mechanism 2: Distribution Influence Minimization via Partitioning
When features are correlated, marginal masking (ignoring correlations) and conditional masking (respecting them) produce different explanations. GRANITE minimizes this by partitioning the space into regions where features become effectively independent. Theorem 3 shows that disagreement is driven by the density ratio between marginal and conditional distributions, which the framework reduces through regionalization.

### Mechanism 3: Recursive Partitioning for Localized Additivity
The greedy splitting algorithm treats explanation disagreement as a loss function. It iteratively finds splits that maximize disagreement reduction, isolating subsets where the model behaves more simply (closer to additive). This requires fewer splits than global approximation and can capture heterogeneous effects like different behavior on weekends vs weekdays.

## Foundational Learning

- **Concept: Functional ANOVA (fANOVA)**
  - Why needed: GRANITE relies on decomposing functions into main and interaction effects to understand why pure and full effects differ
  - Quick check: Can you explain why f_{ij}(x_i, x_j) represents a pure interaction that cannot be predicted from f_i(x_i) and f_j(x_j) alone?

- **Concept: Marginal vs. Conditional Expectation (Masking)**
  - Why needed: These are primary sources of disagreement identified by the paper
  - Quick check: If X₁ is always twice X₂, why would Marginal masking potentially evaluate the model on impossible points like (X₁=10, X₂=0)?

- **Concept: Recursive Partitioning (Decision Trees)**
  - Why needed: This is the engine of the GRANITE framework
  - Quick check: In a standard regression tree, we split to minimize variance. What quantity does GRANITE minimize when splitting a node?

## Architecture Onboarding

- **Component map:** Input (model F, dataset X) -> Pre-compute R^S matrices -> Recursive partitioning engine -> Output (decision tree with regional explanations)
- **Critical path:** Computation of R^S matrices (O(dN²) complexity). This step becomes the bottleneck for large N, suggesting sub-sampling as a mitigation strategy.
- **Design tradeoffs:** Depth vs interpretability (deeper trees reduce disagreement but create more regions), Marginal vs conditional masking (computational complexity trade-off), Memory vs speed (pre-computation enables fast splitting but requires significant storage).
- **Failure signatures:** High memory usage during R^S computation, stagnant disagreement indicating excessive regularization or independence, over-partitioning suggesting axis-aligned splits cannot capture smooth interaction structures.
- **First 3 experiments:**
  1. Replicate Toy Example with synthetic data containing known interactions and dependencies
  2. Run scalability test on Bikesharing dataset with varying N to validate O(dN²) complexity
  3. Perform hyperparameter sensitivity analysis measuring disagreement reduction vs max_depth

## Open Questions the Paper Calls Out

### Open Question 1
Can GRANITE simultaneously minimize interaction and distributional influences without excessive partitioning? The current framework optimizes one disagreement source at a time, but simultaneous minimization requires multi-objective optimization that may need significantly more regions.

### Open Question 2
How can feature groups be selected in a principled manner to reduce region complexity? While feature groups increase expressiveness, the framework currently relies on user-defined groups rather than automated detection of highly interacting feature subsets.

### Open Question 3
Can uncertainty quantification optimize subsample sizes to balance memory usage and estimate reliability? The current fixed sub-sampling approach may sacrifice accuracy, suggesting adaptive sampling based on variance of regional explanation estimates could be beneficial.

## Limitations

- Axis-aligned partitioning may struggle with non-linear, smooth, or diagonal dependency patterns that cannot be effectively isolated by binary splits
- O(dN²) memory complexity creates scalability barriers for larger datasets, requiring sub-sampling that may reduce representativeness
- Conditional masking implementation details are underspecified, particularly regarding conditional distribution estimation within regions
- Limited empirical validation across diverse datasets and lack of comparison with alternative regionalization methods

## Confidence

- **High confidence** in theoretical framework linking explanation disagreement to interaction effects and distribution influences
- **Medium confidence** in practical effectiveness based on experimental results showing meaningful disagreement reduction
- **Low confidence** in computational scalability claims without extensive validation across diverse dataset sizes and dimensionalities

## Next Checks

1. **Synthetic Interaction Validation**: Generate data with known non-axis-aligned interaction patterns and evaluate GRANITE's effectiveness compared to axis-aligned alternatives

2. **Scalability Benchmark**: Systematically evaluate runtime and memory usage across varying N (100 to 10,000) and d (5 to 50) to measure actual O(dN²) scaling behavior

3. **Conditional Masking Implementation**: Implement and compare multiple conditional masking strategies (k-NN, kernel density estimation, tree-based) to assess their impact on disagreement reduction and computational efficiency