---
ver: rpa2
title: Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model
arxiv_id: '2502.08612'
source_url: https://arxiv.org/abs/2502.08612
tags:
- cardiac
- arrest
- prediction
- feature
- hour
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses in-hospital cardiac arrest (IHCA) prediction
  using only single-channel finger photoplethysmography (PPG) signals. The authors
  propose a two-stage model called Feature Extractor-Aggregator Network (FEAN) that
  leverages pre-trained PPG foundation models (up to 1 billion parameters) for feature
  extraction, followed by sequential classification models for aggregation.
---

# Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model

## Quick Facts
- arXiv ID: 2502.08612
- Source URL: https://arxiv.org/abs/2502.08612
- Reference count: 40
- This paper proposes FEAN, a two-stage model leveraging pre-trained PPG foundation models for continuous cardiac arrest prediction using only single-channel finger photoplethysmography signals.

## Executive Summary
This paper introduces a novel approach for predicting in-hospital cardiac arrest (IHCA) using only single-channel finger photoplethysmography (PPG) signals. The authors develop the Feature Extractor-Aggregator Network (FEAN), which leverages pre-trained PPG foundation models (up to 1 billion parameters) for feature extraction, followed by sequential classification models for aggregation. Two FEAN variants are proposed: a 1-hour model using the latest hour of data and a full-history model using up to 24 hours of patient history. The best model achieves an average AUROC of 0.79 over the 24-hour prediction window before cardiac arrest, with peak performance of 0.82 one hour before the event. The study demonstrates that PPG foundation model representations can effectively predict cardiac arrest using only continuous waveform data, without requiring multimodal inputs.

## Method Summary
The study proposes a two-stage FEAN framework for cardiac arrest prediction. In the first stage, a pre-trained PPG foundation model (PPG-GPT) serves as a frozen feature extractor, converting raw PPG signals into latent representations. In the second stage, a sequential classification model (LSTM or Transformer) aggregates these features to predict cardiac arrest probability. Two variants are developed: a 1-hour model using the latest hour of data and a full-history model using up to 24 hours of patient history. The models are trained on a large dataset of 17,278 patients from UCSF ICU, with 390 cardiac arrest cases. The authors compare different foundation model sizes (19M to 1B parameters) and sequential classification approaches.

## Key Results
- FEAN achieves an average AUROC of 0.79 over the 24-hour prediction window before cardiac arrest
- Peak performance of 0.82 AUROC is achieved one hour before the event
- The 1-hour FEAN model outperforms full-history models in early prediction (<4 hours before arrest)
- Pre-trained PPG foundation models show strong performance without fine-tuning in some cases

## Why This Works (Mechanism)
The paper leverages the hierarchical representation learning capabilities of pre-trained PPG foundation models to capture subtle physiological patterns in continuous waveform data. The PPG-GPT models learn rich representations from large-scale unlabeled PPG data, which can then be transferred to the downstream task of cardiac arrest prediction. By using sequential classification models, FEAN can effectively aggregate temporal features and capture the progression of physiological deterioration leading to cardiac arrest.

## Foundational Learning
- PPG foundation models (PPG-GPT): Pre-trained models that learn general representations from unlabeled PPG data, needed for transferring knowledge to clinical prediction tasks; quick check: model architecture and pre-training objectives
- Feature extraction-aggregation framework: Two-stage approach separating representation learning from temporal aggregation, needed to leverage pre-trained models effectively; quick check: compatibility between feature extractor and aggregator
- Sequential classification: Using models like LSTM and Transformer to process temporal sequences, needed for capturing physiological trends; quick check: model architecture and attention mechanisms
- Multi-task pre-training: Training on multiple related tasks (e.g., anomaly detection, R-peak detection) before fine-tuning, needed for robust representation learning; quick check: pre-training task definitions
- Foundation model adaptation: Strategies for using large pre-trained models in resource-constrained settings, needed for practical deployment; quick check: fine-tuning vs. feature extraction trade-offs

## Architecture Onboarding

### Component Map
PPG Signal -> Pre-trained PPG-GPT (frozen) -> Latent Features -> Sequential Classifier (LSTM/Transformer) -> Cardiac Arrest Prediction

### Critical Path
The critical path for deployment involves capturing PPG signals from bedside monitors, extracting features using the pre-trained PPG-GPT model, and aggregating these features with the sequential classifier to generate real-time predictions.

### Design Tradeoffs
- Frozen vs. fine-tuned feature extractor: Using frozen models saves computational resources but may limit performance; fine-tuning improves performance but requires more resources
- Model size vs. efficiency: Larger models (1B parameters) show better performance but are more computationally expensive than smaller models (19M parameters)
- History length vs. prediction window: Full-history models use more context but may miss early warning signals compared to 1-hour models
- LSTM vs. Transformer for aggregation: LSTMs are more efficient but Transformers may capture longer-range dependencies better

### Failure Signatures
- Poor generalization to other institutions due to differences in bedside capture devices and patient demographics
- Computational bottlenecks during real-time inference with large foundation models
- Sensitivity to signal quality and artifacts in PPG waveforms
- Overfitting to specific patterns in the training dataset that may not generalize

### 3 First Experiments
1. Test FEAN on external datasets (e.g., MIMIC-IV) to evaluate generalization
2. Compare performance with other foundation models like PaPaGei
3. Implement memory-efficient fine-tuning for the full-history variant

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does the FEAN framework generalize to other clinical institutions with different bedside capture devices and patient demographics?
- Basis in paper: The authors state in the conclusion: "Finally, we can conduct cross-institutional testing [46] to test generalization to other bedside capture devices and patient demographics."
- Why unresolved: The study utilized a single dataset (UCSF ICU), limiting the validation of the model's robustness across different hardware and patient populations.
- What evidence would resolve it: Performance evaluation on external datasets, such as MIMIC-IV, to assess the model's generalizability.

### Open Question 2
- Question: How does the PPG-GPT foundation model compare to other pre-trained models, such as PaPaGei, for cardiac arrest prediction?
- Basis in paper: The authors suggest: "Another direction would be to compare performance with other foundation models like PaPaGei [5]."
- Why unresolved: This study focused exclusively on the PPG-GPT family (19M to 1B parameters) without benchmarking against other available foundation models.
- What evidence would resolve it: A comparative analysis benchmarking the FEAN model using PaPaGei embeddings versus PPG-GPT embeddings on the same task.

### Open Question 3
- Question: Does fine-tuning the foundation model improve performance in the full-history (FH) variant compared to the frozen feature extractor?
- Basis in paper: The paper notes that results for the full-history model were reported with a frozen feature extractor "Due to the computational challenges (GPU memory) of processing 24-hour-long signals and fine-tuning."
- Why unresolved: While fine-tuning improved the 1-hour model, resource constraints prevented the authors from determining if this benefit extends to the 24-hour history model.
- What evidence would resolve it: Experiments utilizing memory-optimized training techniques to successfully fine-tune the FH model and compare its performance against the frozen baseline.

## Limitations
- Performance metrics are based on a single dataset (MIMIC-II) and may not generalize well to other hospital settings
- The clinical utility depends heavily on the precision-recall trade-off, which is not thoroughly discussed
- Absence of direct comparisons with leading methods like Wav2Arrest 2.0 limits the strength of performance claims
- Computational efficiency of the 1-billion-parameter model for real-time deployment is not adequately addressed

## Confidence

| Claim | Confidence |
|-------|------------|
| PPG foundation models can effectively predict cardiac arrest using only continuous waveform data | High |
| FEAN performance is competitive with multimodal approaches | Medium |
| The 1-billion-parameter model is practical for real-time deployment | Low |

## Next Checks
1. External validation on independent ICU datasets to assess generalizability across different hospital systems and patient demographics
2. Prospective clinical study to evaluate the model's performance in real-time monitoring scenarios and its impact on intervention outcomes
3. Comprehensive computational analysis comparing the inference time and resource requirements of the proposed model against existing clinical monitoring systems to determine practical deployment feasibility