---
ver: rpa2
title: Retrieval-Augmented Generation of Ontologies from Relational Databases
arxiv_id: '2506.01232'
source_url: https://arxiv.org/abs/2506.01232
tags:
- ontology
- ontologies
- database
- table
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces RIGOR, a Retrieval-Augmented Generation\
  \ pipeline that transforms relational database schemas into rich OWL ontologies\
  \ with minimal manual effort. The method combines three sources via RAG\u2014the\
  \ database schema and its documentation, a repository of domain ontologies, and\
  \ a growing core ontology\u2014to prompt a generative LLM for producing successive,\
  \ provenance-tagged delta ontology fragments."
---

# Retrieval-Augmented Generation of Ontologies from Relational Databases

## Quick Facts
- **arXiv ID**: 2506.01232
- **Source URL**: https://arxiv.org/abs/2506.01232
- **Reference count**: 40
- **Key outcome**: Introduces RIGOR, a RAG pipeline transforming relational schemas into OWL ontologies with high quality metrics and reduced manual effort.

## Executive Summary
This paper presents RIGOR, a retrieval-augmented generation pipeline that automatically converts relational database schemas into rich OWL ontologies. The system leverages three knowledge sources—database documentation, domain ontologies, and a core ontology—to guide a generative LLM in producing ontology fragments table-by-table, following foreign key constraints. Each fragment is refined by a judge-LLM before merging into the core ontology. Experiments on medical databases demonstrate substantial improvements in ontology quality metrics while significantly reducing manual effort.

## Method Summary
RIGOR implements a retrieval-augmented generation pipeline that transforms relational database schemas into OWL ontologies through an iterative process. The method combines three knowledge sources via RAG: the target database schema and its documentation, a repository of domain ontologies, and a growing core ontology. A generative LLM produces ontology fragments based on these sources, with each fragment tagged for provenance. A judge-LLM refines these delta fragments before they are merged into the core ontology. The process iterates table-by-table following foreign key constraints until complete coverage is achieved.

## Key Results
- RIGOR produces ontologies scoring highly on accuracy, completeness, conciseness, adaptability, clarity, and consistency metrics
- The method substantially reduces manual effort compared to traditional ontology engineering approaches
- Experiments on real-world medical databases demonstrate the effectiveness of the retrieval-augmented generation approach

## Why This Works (Mechanism)
RIGOR works by combining multiple knowledge sources to guide ontology generation, ensuring contextual relevance and consistency. The three-source RAG approach provides comprehensive coverage: the database schema offers structural information, domain ontologies provide semantic context, and the core ontology maintains consistency across iterations. The judge-LLM acts as a quality control mechanism, filtering and refining generated fragments before integration. The table-by-table iteration following foreign key constraints ensures systematic coverage while maintaining relational integrity throughout the ontology construction process.

## Foundational Learning
- **Retrieval-Augmented Generation (RAG)**: Combines information retrieval with text generation to produce contextually relevant outputs. Needed to ground LLM outputs in specific database schemas and domain knowledge. Quick check: Verify retrieval components can access and process relevant documents from all three knowledge sources.
- **OWL Ontology Construction**: Web Ontology Language provides formal representation of knowledge with classes, properties, and individuals. Needed to create machine-readable semantic models from relational data. Quick check: Confirm generated fragments adhere to OWL syntax and semantic constraints.
- **Foreign Key Constraint Navigation**: Database relationships guide the iteration order through tables. Needed to maintain referential integrity and logical consistency in the resulting ontology. Quick check: Validate that the iteration order respects all foreign key dependencies.
- **Provenance Tracking**: Each ontology fragment includes source attribution. Needed for debugging, validation, and understanding decision provenance. Quick check: Ensure all generated fragments contain proper provenance metadata.
- **Iterative Refinement**: Judge-LLM evaluates and improves generated fragments before integration. Needed to maintain quality and prevent error accumulation. Quick check: Test judge-LLM accuracy on sample delta fragments.

## Architecture Onboarding

**Component Map**: Database Schema -> RAG Retriever -> LLM Generator -> Judge-LLM -> Core Ontology -> Merge Process

**Critical Path**: The end-to-end pipeline follows: Schema documentation retrieval → Delta fragment generation → Judge refinement → Core ontology merging → Iteration to next table

**Design Tradeoffs**: The table-by-table approach trades completeness speed for accuracy control, while the three-source RAG provides comprehensive context at the cost of increased complexity. The judge-LLM adds quality assurance but introduces additional computational overhead and potential bottlenecks.

**Failure Signatures**: Schema parsing errors will propagate through the pipeline, judge-LLM failures will allow low-quality fragments into the core ontology, and foreign key constraint misinterpretation will break the iteration order and potentially miss tables.

**First Experiments**: 1) Validate RAG retrieval accuracy on a single table's documentation, 2) Test LLM generation quality with controlled prompts on simple schemas, 3) Evaluate judge-LLM refinement effectiveness on sample delta fragments.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on synthetic or moderately sized medical databases, limiting generalizability to enterprise-scale schemas
- Manual gold-standard annotations by small team raise concerns about bias and edge case coverage
- Iterative approach may accumulate errors, especially if early decisions constrain later ontology fragments
- Dependency on prompt quality and LLM behavior introduces variability across different model versions

## Confidence

**High Confidence**: The core retrieval-augmented generation pipeline design is technically sound and well-documented, with clear descriptions of the three-source RAG approach and iterative refinement process. Experimental results demonstrate measurable improvements in ontology quality metrics on the tested datasets.

**Medium Confidence**: Claims about substantial reduction in manual effort are supported by the experimental design but would benefit from broader testing across different database sizes and domains. The generalizability of quality metric improvements to larger, more complex schemas remains uncertain.

**Medium Confidence**: The judge-LLM's ability to reliably filter and refine delta fragments is promising but depends heavily on prompt engineering and model selection, which may vary in effectiveness across different contexts.

## Next Checks
1. **Scale Validation**: Test RIGOR on large-scale enterprise databases (100+ tables) to evaluate performance degradation, accuracy retention, and computational resource requirements.
2. **Domain Generalization**: Apply the pipeline to non-medical domains (e.g., financial, manufacturing, logistics) to assess whether the quality improvements and effort reductions transfer beyond healthcare contexts.
3. **Long-term Stability**: Conduct multi-iteration experiments tracking error propagation and consistency maintenance across 50+ table sequences to quantify the risk of cumulative degradation in complex schema mappings.