---
ver: rpa2
title: Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs)
  for Automated Telecom Network Troubleshooting
arxiv_id: '2511.00651'
source_url: https://arxiv.org/abs/2511.00651
tags:
- troubleshooting
- network
- arxiv
- solution
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a Multi-Agent System (MAS) leveraging Large
  Language Models (LLMs) for orchestrating specialized agents and a fine-tuned Small
  Language Model (SLM) for generating domain-specific solution plans to automate telecom
  network troubleshooting. The SLM was fine-tuned on proprietary telecom documents
  using supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with Transformers
  Reinforcement Learning (TRL), achieving up to 6x faster troubleshooting and 10%
  higher accuracy compared to manual processes.
---

# Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting

## Quick Facts
- arXiv ID: 2511.00651
- Source URL: https://arxiv.org/abs/2511.00651
- Reference count: 22
- Key outcome: 6x faster troubleshooting and 10% higher accuracy versus manual processes

## Executive Summary
This study presents a Multi-Agent System (MAS) that leverages Large Language Models (LLMs) to orchestrate specialized agents and a fine-tuned Small Language Model (SLM) for generating domain-specific troubleshooting plans in telecom networks. The SLM is fine-tuned on proprietary telecom documentation using supervised and reinforcement learning techniques. The approach addresses the challenge of automating troubleshooting in heterogeneous telecom environments where existing models struggle to generalize and suffer from high costs and privacy concerns.

The system demonstrates up to 6x faster resolution times and 10% higher accuracy compared to manual processes, with the fine-tuned SLM showing superior performance over base models and comparable solution quality to GPT-4o-mini for Input Power Failure alarms. The architecture enables scalable, privacy-preserving automation while maintaining accuracy in complex network troubleshooting scenarios.

## Method Summary
The study introduces a multi-agent system architecture where LLMs orchestrate specialized agents, and a fine-tuned SLM generates domain-specific troubleshooting plans. The SLM undergoes supervised fine-tuning on proprietary telecom documents followed by reinforcement fine-tuning using Transformers Reinforcement Learning (TRL). The system employs a RAG-based document retriever for context retrieval and implements custom reward functions (completeness, relevancy, groundedness) adapted for telecom troubleshooting scenarios. The methodology includes human-in-the-loop validation for plan execution and evaluates performance across specific fault types including Input Power Failure and PDU session degradation.

## Key Results
- Fine-tuned SLM achieved up to 6x faster troubleshooting compared to manual processes
- 10% higher accuracy versus traditional manual troubleshooting approaches
- Superior performance over base models with improved reward stability and comparable solution quality to GPT-4o-mini for Input Power Failure alarms

## Why This Works (Mechanism)
The approach combines the reasoning capabilities of LLMs for agent orchestration with the efficiency and specialization of fine-tuned SLMs for domain-specific plan generation. The multi-agent system allows for distributed problem-solving while the fine-tuned SLM leverages domain knowledge from proprietary telecom documents. Reinforcement learning with custom reward functions ensures the generated plans are both accurate and actionable, while the RAG-based retrieval system provides relevant context for decision-making.

## Foundational Learning
- Multi-Agent Systems (MAS): Distributed AI architecture where multiple agents collaborate to solve complex problems
  - Why needed: Enables specialized handling of different troubleshooting aspects while maintaining coordination
  - Quick check: Verify agent specialization and communication protocols

- Small Language Models (SLMs): Compact language models optimized for specific domains
  - Why needed: Balance between performance and efficiency while preserving privacy
  - Quick check: Evaluate model size vs. performance tradeoffs

- Reinforcement Fine-Tuning (RFT): Training method using reward-based feedback to improve model outputs
  - Why needed: Align model behavior with operational success metrics
  - Quick check: Monitor reward function stability and correlation with actual outcomes

- RAGAS-based Evaluation: Retrieval-Augmented Generation Assessment Score methodology
  - Why needed: Robust evaluation of generated troubleshooting plans
  - Quick check: Validate custom reward functions against human expert assessments

- Human-in-the-Loop (HITL): Incorporating human validation in automated workflows
  - Why needed: Ensure plan safety and correctness before execution
  - Quick check: Track validation acceptance rates and failure modes

## Architecture Onboarding

**Component Map:**
LLM Orchestrator -> Specialized Agents -> SLM Plan Generator -> RAG Retriever -> HITL Validator -> Executor

**Critical Path:**
LLM receives alert → Agents analyze context → SLM generates plan → RAG retrieves documentation → HITL validation → Execution

**Design Tradeoffs:**
- Model size vs. inference speed (8B SLM vs. larger models)
- Automation level vs. human oversight requirements
- Generalization capability vs. domain specificity

**Failure Signatures:**
- Low RAG retrieval relevance scores
- SLM plan generation timeouts
- High HITL rejection rates
- Reward function instability during RFT

**First 3 Experiments:**
1. Validate RAG retrieval accuracy on held-out telecom documentation
2. Test SLM plan generation quality across different fault categories
3. Measure HITL validation time and acceptance rates for generated plans

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does the fine-tuned SLM generalize to alarm types beyond Input Power Failure and PDU session degradation across heterogeneous network deployments?
- Basis in paper: [inferred] The experiments section evaluates only two specific fault scenarios, while the introduction emphasizes that existing models "struggle to generalize across heterogeneous deployments" and the related work notes distribution shifts across deployments remain a challenge.
- Why unresolved: No evaluation is provided for other common telecom alarm types (e.g., handover failures, interference, hardware degradation) or across different vendor equipment with varying telemetry formats and documentation styles.
- What evidence would resolve it: Evaluation across a broader taxonomy of alarm types with performance metrics disaggregated by fault category, vendor, and network configuration.

### Open Question 2
- Question: What is the Human-in-the-Loop rejection rate for generated troubleshooting plans, and what failure modes prompt human intervention?
- Basis in paper: [inferred] The methodology states the executor incorporates HITL feedback "for validating the generated executable plans" before execution, but the paper reports no rejection rates, revision frequency, or failure mode analysis for the validation step.
- Why unresolved: The efficiency claims (6× faster, 10% accuracy improvement) do not quantify human validation overhead or how often plans require correction before approval.
- What evidence would resolve it: Reporting of HITL acceptance rates, time spent on human validation, taxonomy of rejection reasons, and end-to-end latency including human review.

### Open Question 3
- Question: How robust are the custom RAGAS-based reward functions against reward hacking, and do they correlate with actual troubleshooting effectiveness in production?
- Basis in paper: [explicit] The paper states "effective use of SLMs requires... robust evaluation criteria to ensure accuracy and reliability" and introduces custom reward functions (completeness, relevancy, groundedness) adapted for telecom, but does not validate their correlation with operational outcomes.
- Why unresolved: Optimizing reward scores may produce well-formatted responses that fail to resolve actual faults; the paper reports reward improvements but not whether they translate to higher first-time-fix rates.
- What evidence would resolve it: Correlation analysis between RFT reward scores and downstream operational metrics such as first-time-fix rate, mean time to resolution, or SME-rated solution quality on held-out fault scenarios.

### Open Question 4
- Question: What is the quantitative performance gap between the fine-tuned 8B SLM and GPT-4o-mini on standardized solution quality metrics?
- Basis in paper: [inferred] Figure 7 provides a qualitative comparison showing "comparable quality" between the fine-tuned model and GPT-4o-mini for Input Power Failure, but no quantitative metrics (e.g., exact match, step coverage, hallucination rate) are reported.
- Why unresolved: Without quantitative benchmarking, it is unclear whether the SLM achieves parity, approaches within an acceptable margin, or sacrifices quality in ways not visible in a single example.
- What evidence would resolve it: Side-by-side evaluation on a held-out test set using metrics such as step-level accuracy, counter/command recall, and SME-rated actionability scores.

## Limitations
- Evaluation focuses on a single fault type (Input Power Failure), limiting generalizability across diverse telecom scenarios
- 10% accuracy improvement requires validation across broader range of network issues and failure modes
- Proprietary training data raises questions about reproducibility and potential data bias

## Confidence
- **High Confidence**: The architectural design of the MAS and SLM integration is technically sound and follows established patterns in AI-driven network management
- **Medium Confidence**: The reported performance improvements (speed and accuracy) are based on the presented evaluation but require broader validation
- **Low Confidence**: Generalizability of results to other telecom fault types and long-term model stability in production environments

## Next Checks
1. Conduct comprehensive testing across multiple fault types and network topologies to assess generalizability and robustness
2. Implement a longitudinal study to evaluate model performance, drift, and adaptation over extended periods in a live network environment
3. Perform an independent replication study using publicly available telecom datasets to verify reproducibility and mitigate potential data bias