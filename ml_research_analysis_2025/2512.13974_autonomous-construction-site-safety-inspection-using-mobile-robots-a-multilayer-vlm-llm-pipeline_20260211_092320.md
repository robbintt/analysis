---
ver: rpa2
title: 'Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer
  VLM-LLM Pipeline'
arxiv_id: '2512.13974'
source_url: https://arxiv.org/abs/2512.13974
tags:
- safety
- construction
- framework
- robot
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multi-layer framework for autonomous construction-site
  safety inspection using mobile robots. The system combines SLAM-based navigation
  with a Vision-Language Model (VLM) and Large Language Model (LLM) pipeline to detect
  safety violations and generate traceable safety reports.
---

# Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline

## Quick Facts
- arXiv ID: 2512.13974
- Source URL: https://arxiv.org/abs/2512.13974
- Reference count: 0
- Zero-shot mobile robot pipeline achieves up to 92.2% recall for construction safety violations using open-source VLMs and LLMs.

## Executive Summary
This paper presents a multi-layer framework for autonomous construction-site safety inspection using mobile robots. The system combines SLAM-based navigation with a Vision-Language Model (VLM) and Large Language Model (LLM) pipeline to detect safety violations and generate traceable safety reports. In lab-based experiments across three scenarios simulating common construction hazards, the framework achieved high recall (up to 92.2%) and competitive precision compared to GPT-4o, while maintaining transparency through intermediate artifacts at each layer. The approach addresses the challenge of dynamic, data-scarce construction environments by leveraging zero-shot, open-source models and regulatory grounding. Key contributions include a generalizable, auditable inspection pipeline and a proof-of-concept implementation demonstrating practical feasibility for real-world deployment.

## Method Summary
The system employs a four-layer pipeline combining robotics navigation with AI-based safety assessment. The robot uses RTAB-Map SLAM and Nav2 with Dijkstra planning for autonomous waypoint navigation. The AI module extracts 1 FPS RGB frames, which pass through four sequential layers: B1) Gemma-3 12B VLM generates scene descriptions; B2) RAG with Llama-3.3 retrieves relevant OSHA regulations; B3) Gemma-3 12B VLM performs safety assessment using a 5-level severity scale; B4) DeepSeek-R1 generates comprehensive safety reports. The entire pipeline operates zero-shot using open-source models via Ollama on a workstation with 2x RTX 3090 GPUs. The system was evaluated across three lab scenarios (A: unobstructed work, B: minor hazards, C: major hazards) with 442 frames total.

## Key Results
- Achieved up to 92.2% recall for detecting safety violations across three lab scenarios
- Outperformed GPT-4o in precision while maintaining competitive recall rates
- Successfully generated traceable safety reports with intermediate artifacts at each pipeline layer
- Demonstrated robustness across varying hazard complexity levels (scenarios A, B, C)

## Why This Works (Mechanism)
The pipeline's effectiveness stems from decomposing complex safety inspection into specialized, traceable layers. The SLAM-based navigation ensures reliable coverage of inspection areas, while the zero-shot VLM-LLM architecture eliminates data scarcity issues typical in construction domains. The RAG component grounds assessments in actual OSHA regulations rather than learned patterns, ensuring compliance-focused evaluations. The five-layer structure creates accountability through intermediate outputs that can be audited, addressing the "black box" concern common in AI safety systems.

## Foundational Learning
- **RTAB-Map SLAM**: Real-time appearance-based mapping for robot localization in dynamic environments - needed for autonomous navigation without GPS; quick check: verify loop closure detection in multi-room scenarios
- **VLM Scene Description**: Vision-language models that generate textual descriptions from images - needed to translate visual data into analyzable text; quick check: validate object recognition accuracy against ground truth
- **RAG with OSHA Regulations**: Retrieval-augmented generation using regulatory knowledge bases - needed to ensure assessments are grounded in actual safety standards; quick check: confirm relevant regulation retrieval for each hazard type
- **Five-level Severity Assessment**: Structured classification from negligible to catastrophic - needed to prioritize violations by risk level; quick check: verify consistent severity assignment across similar violations
- **Zero-shot Inference**: Model operation without task-specific training - needed to overcome data scarcity in specialized construction scenarios; quick check: test model generalization to unseen hazard types

## Architecture Onboarding
**Component Map**: Robot sensors (LiDAR + camera) -> SLAM/Navigation -> Frame extraction -> B1 VLM -> B2 RAG -> B3 VLM -> B4 LLM -> Safety Report

**Critical Path**: Frame extraction (1 FPS) → B1 scene description → B2 regulation retrieval → B3 safety assessment → B4 report generation

**Design Tradeoffs**: Zero-shot approach avoids costly training data collection but limits adaptation to site-specific hazards; open-source models ensure transparency but may underperform proprietary alternatives; traceable intermediate outputs enhance auditability but increase processing latency

**Failure Signatures**: Object hallucination (VLM misidentifies objects leading to false positives), spatial reasoning errors (struggles with relative positioning critical for ladder stability), context misinterpretation (fails to recognize complex multi-hazard scenarios)

**First Experiments**: 1) Deploy pipeline on sample construction video and verify each layer's output matches expected format; 2) Test RAG retrieval with known OSHA violations to confirm regulatory grounding; 3) Validate severity assessment consistency across identical hazards in different contexts

## Open Questions the Paper Calls Out
None

## Limitations
- Lab-based evaluation limits generalizability to real construction environments with variable weather, lighting, and terrain conditions
- 442-frame dataset represents a narrow sample of construction hazards, potentially missing edge cases
- Zero-shot approach lacks site-specific adaptation that would likely be necessary for production deployment

## Confidence
- Technical Claims: Medium - pipeline architecture is sound but missing complete implementation details (prompts, RAG configuration, severity scale definitions)
- Reproducibility: Medium - code available but critical parameters unspecified
- Performance Claims: Medium - lab results credible but real-world validation needed

## Next Checks
1. Deploy the system in a real outdoor construction site with varying weather conditions, lighting, and terrain to assess robustness beyond controlled lab environments
2. Conduct a longitudinal study tracking the system's performance across multiple days/weeks to evaluate consistency and identify any model drift or environmental adaptation needs
3. Perform a formal human-AI comparison study where trained safety inspectors review the same video footage and their assessments are compared against the system's outputs to establish practical reliability thresholds