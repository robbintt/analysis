---
ver: rpa2
title: Efficient Clustering in Stochastic Bandits
arxiv_id: '2601.09162'
source_url: https://arxiv.org/abs/2601.09162
tags:
- lemma
- hence
- algorithm
- clustering
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the Bandit Clustering (BC) problem, where the
  goal is to cluster a collection of data sequences (arms) into groups by sequentially
  sampling arms adaptively, ensuring a fixed error probability at the stopping time.
  Unlike existing work that assumes Gaussian-distributed arms, the authors study a
  broader class of vector-parametric distributions satisfying mild regularity conditions.
---

# Efficient Clustering in Stochastic Bandits

## Quick Facts
- arXiv ID: 2601.09162
- Source URL: https://arxiv.org/abs/2601.09162
- Reference count: 40
- One-line primary result: An Efficient Bandit Clustering algorithm (EBC) achieves asymptotic optimality while drastically reducing per-iteration computation compared to existing methods.

## Executive Summary
This paper studies the Bandit Clustering (BC) problem, where the goal is to cluster a collection of data sequences (arms) into groups by sequentially sampling arms adaptively, ensuring a fixed error probability at the stopping time. Unlike existing work that assumes Gaussian-distributed arms, the authors study a broader class of vector-parametric distributions satisfying mild regularity conditions. They propose an Efficient Bandit Clustering algorithm (EBC) that, instead of solving a full optimization problem at each step, takes a single gradient step toward the optimal value, making it computationally efficient while remaining asymptotically optimal. A heuristic variant, EBC-H, further simplifies the sampling rule. Simulations on synthetic and real-world datasets show EBC and EBC-H outperform existing approaches in both sample complexity and runtime. EBC achieves the same asymptotic slope as the theoretical lower bound, proving its asymptotic optimality.

## Method Summary
The paper addresses the Bandit Clustering problem by proposing the EBC algorithm. EBC uses forced exploration (sampling arms below a √(t/M) threshold), gradient tracking to estimate optimal sampling proportions, and a Generalized Likelihood Ratio Test (GLRT) stopping rule with a threshold incorporating Fisher information, parameter space volume, and local KL geometry. The algorithm maintains per-arm maximum likelihood estimates (MLEs) and applies single-linkage clustering (SLINK) to these estimates at stopping time. EBC-H is a heuristic variant that simplifies the sampling rule by reusing the GLRT computation.

## Key Results
- EBC and EBC-H outperform existing approaches in both sample complexity and runtime on synthetic and real-world datasets.
- EBC achieves the same asymptotic slope as the theoretical lower bound, proving its asymptotic optimality.
- The algorithm works for a broader class of vector-parametric distributions beyond Gaussians, satisfying mild regularity conditions.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing full optimization with single-step gradient descent toward optimal arm-pull proportions preserves asymptotic optimality while drastically reducing per-iteration computation.
- Mechanism: At each time t, EBC computes the gradient g_t = ∇_w ψ(w, θ̂(t)) at the current proportion estimate w(t-1), where ψ is the inner infimum from the lower bound. Using Danskin's theorem, this gradient equals the KL-divergence vector [D_KL^(m)(θ̂_m, λ*_m)] where λ* is the minimizer of the inf problem (not sup-inf). A gradient step w'(t) = w(t-1) + η·g_t followed by simplex projection yields w(t), and the algorithm tracks the averaged estimate w̄(t) = (1/t)∑w(s). This converges to some w* ∈ S*(θ) because ψ is concave and continuous.
- Core assumption: The KL-divergence is uniformly continuous (Assumption 5), and the parameter space Θ is compact, ensuring gradient bounds and convergence.
- Evidence anchors:
  - [abstract] "instead of solving the full optimization problem, takes a single step toward the optimal value at each time step, making it computationally efficient while remaining asymptotically optimal"
  - [Section IV] "We compute the gradient of the inner infimum function ψ(·,·)... From Danskin's theorem [18], the above gradient can be computed as g_t = [D_KL^(1)(θ̂_1, λ*_1), ..., D_KL^(M)(θ̂_M, λ*_M)]"
  - [corpus] Weak direct evidence; neighbor papers focus on regret minimization and best arm identification, not clustering with fixed-confidence stopping.
- Break condition: If ψ(·,θ) were not concave or the gradient were unbounded, the sequence {w(t)} might diverge or converge to a non-optimal point.

### Mechanism 2
- Claim: Forced exploration at O(√t) samples per arm ensures parameter estimates converge r-quickly, which is necessary for the gradient to point toward the true optimum.
- Mechanism: The sampling rule checks if min_m N_m(t) < √(t/M); if so, it pulls the least-sampled arm (Lines 4-5). This guarantees N_m(t) ≥ ⌊√(t/M)⌋, and Lemma 2 proves that this forces θ̂_m(t) → θ_m in the r-quick sense (for r=2), meaning E[(T_ϵ^m)²] < ∞ where T_ϵ^m is the last time the estimate was ϵ-far from truth.
- Core assumption: Assumption 2 (E[∥∇ log P(X|θ)∥³] < ∞) and Assumption 4 (λ_min(-∇² log P) ≥ σ² > 0) ensure MLE r-quick convergence via the martingale argument in Appendix C.
- Evidence anchors:
  - [Section IV] "Forced exploration ensures that each arm is sampled at least on the order of √t (Lines 4 and 5 in Algorithm 1)"
  - [Lemma 2] "For any ϵ₁ > 0, there exist a stochastic time N_S^ϵ₁ satisfying E[N_S^ϵ₁] < ∞, such that for all t > N_S^ϵ₁, ∥θ̂_m(t) - θ_m∥ < ϵ₁"
  - [corpus] No direct analogs found; forced exploration is specific to this fixed-confidence clustering setting.
- Break condition: If forced exploration were weakened to O(log t), parameter estimates might still converge almost surely but not r-quickly, potentially breaking the finite expected stopping time guarantee.

### Mechanism 3
- Claim: The Generalized Likelihood Ratio Test (GLRT) stopping rule with a threshold incorporating Fisher information, parameter space volume, and local KL geometry bounds the error probability at δ.
- Mechanism: Z(t) = t·ψ(N(t)/t, θ̂(t)) is the log-GLRT statistic. The threshold β(δ,t) includes: (1) (d/2)∑log(N_m·I(θ̂_m)) from the martingale bound on parameter uncertainty; (2) log(1/δ) from Ville's inequality; (3) correction terms W_ϵ^m(t) and max-KL terms to handle finite-sample deviations from asymptotic approximations. Lemma 11 constructs a non-negative martingale M_m(t) that upper-bounds the per-arm KL divergence.
- Core assumption: Assumptions 1, 3, 4 ensure the Fisher information I(θ) is bounded and the log-likelihood is sufficiently smooth for the martingale construction.
- Evidence anchors:
  - [Section IV] "The choice of this threshold is to ensure that the EBC is a δ-PC... To prove that EBC is δ-PC (Theorem 2), we first derive a martingale-based upper bound on the KL divergence"
  - [Theorem 2] "EBC satisfies P_θ^EBC[τ_δ(EBC) < ∞] = 1 and P_θ^EBC[C(θ̂(τ_δ(EBC))) ≁ C(θ)] ≤ δ"
  - [corpus] No corpus papers address fixed-confidence clustering; they focus on regret bounds.
- Break condition: If the threshold omitted the local KL geometry correction (∑ max{D_KL(θ̂, θ̂±ϵe_i)}), small parameter errors could cause the GLRT to trigger prematurely on wrong clusterings.

## Foundational Learning

- **Stochastic Multi-Armed Bandits (Fixed-Confidence Pure Exploration)**
  - Why needed here: EBC is fundamentally a bandit algorithm where the goal is pure exploration (identify correct clustering) rather than regret minimization. Understanding the exploration-exploitation distinction and fixed-confidence vs. fixed-budget settings is prerequisite.
  - Quick check question: Given M arms with unknown Bernoulli means, what is the expected sample complexity of a δ-PC algorithm to identify the best arm as δ → 0?

- **KL Divergence and Fisher Information**
  - Why needed here: The lower bound (Theorem 1) and the gradient computation both use KL divergence. The stopping threshold depends on Fisher information. These are not implementation details—they define the geometry of the problem.
  - Quick check question: For a d-dimensional Gaussian N(μ, I), what is D_KL(P_μ₁, P_μ₂) and I(μ)?

- **Single Linkage Clustering (SLINK)**
  - Why needed here: The clustering structure C(θ) is defined via SLINK applied to parameter vectors. The algorithm's output is C(θ̂(τ_δ)), and the alternative space Alt(θ) consists of all λ where SLINK on λ yields different clusters than SLINK on θ.
  - Quick check question: Given points at distances d(1,2)=1, d(2,3)=2, d(1,3)=5, what clustering does SLINK produce for K=2?

## Architecture Onboarding

- **Component map**:
  - Sampling Module: Forced exploration (pull argmin N_m if below √(t/M)) + Gradient tracking (compute g_t via inf-problem, take step η·g_t, project to simplex, track average w̄(t), pull argmin(N_m/t - w̄_m(t)))
  - Estimation Module: Per-arm MLE θ̂_m(t) = argmax_ρ∈Θ ∑_{s:A_s=m} log P(X_s|ρ), projected to compact Θ
  - Stopping Module: Compute Z(t) = t·ψ(N(t)/t, θ̂(t)) by solving inf over Alt(θ̂(t)); compare to β(δ,t)
  - Declaration Module: On stopping, output ĉ = C(θ̂(t)) via SLINK

- **Critical path**: The inf-problem (computing λ* and thus the gradient g_t and statistic Z(t)) is the per-iteration bottleneck. EBC reduces this from sup-inf to just inf, but the inf still requires optimization over Alt(θ̂(t)), which is non-convex for K > 2.

- **Design tradeoffs**:
  - **ε parameter**: Controls the local KL geometry correction in β(δ,t). Smaller ε tightens the threshold (better sample complexity) but increases numerical sensitivity. Theorem 3 shows asymptotic slope approaches 1/ψ(w*,θ) as ε → 0.
  - **Compact space |Θ|**: Larger Θ increases the log|Θ| term in β(δ,t), worsening sample complexity. Table I shows shrinking Θ from [-500,500]² to [-5,5]² improves slope from ~25 to ~20.
  - **Step size η**: Must be O(1/√B(t)) for convergence; too large causes oscillation, too small slows convergence.
  - **EBC vs. EBC-H**: EBC-H replaces gradient tracking with argmax_m D_KL(θ̂_m, λ*_m) (Eq. 2), reusing Z(t) computation. No theoretical guarantee but outperforms EBC empirically (Table II).

- **Failure signatures**:
  - Non-termination (τ_δ = ∞): Likely caused by bug in Alt(θ) construction or threshold underflow. Check that Z(t) is monotonic increasing on average and β(δ,t) grows as O(log t).
  - Wrong clustering at stopping: The threshold β(δ,t) may be too loose for non-Gaussian distributions violating assumptions. Verify Assumptions 1-5 hold.
  - Runtime blowup: The inf-problem over Alt(θ̂(t)) may not converge quickly. Use warm-start from previous iteration's λ*.

- **First 3 experiments**:
  1. **Synthetic Gaussian validation**: Implement EBC on the 6-arm, 3-cluster example from Fig. 1. Plot expected stopping time vs. log(1/δ) and verify slope matches theoretical T*(θ) = 20. Compare runtime per sample against ATBOC (Table II baseline: ~21ms for M=4).
  2. **ε sensitivity**: On the same setup, sweep ε ∈ {0.001, 0.01, 0.1, 0.5} and plot sample complexity slope and empirical error rate. Identify the practical ε that maintains δ-PC without excessive samples.
  3. **Non-Gaussian stress test**: Use exponential-distributed arms (Synthetic Dataset 2) with parameters [1, 1.1, 9, 9.1, 20, 20.1]. Verify EBC slope ≈ 98 (matching lower bound). This tests the vector-parametric distribution generality claimed in the abstract.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the EBC-H heuristic algorithm satisfy the same asymptotic optimality guarantees as the theoretically proven EBC algorithm?
- Basis in paper: [explicit] "Sample complexity guarantee of EBC-H is not analyzed in this work."
- Why unresolved: While empirical results suggest EBC-H matches the theoretical lower bound, there is currently no formal derivation proving its optimality.
- What evidence would resolve it: A rigorous proof demonstrating that EBC-H achieves the asymptotic lower bound $T^*(\theta)$ for the BC problem.

### Open Question 2
- Question: Can the Bandit Clustering framework be extended to problems where the number of clusters $K$ is unknown a priori?
- Basis in paper: [explicit] The problem setup states: "We assume that the number of clusters K is known."
- Why unresolved: The current algorithm requires $K$ as a fixed input for the stopping rule and SLINK algorithm.
- What evidence would resolve it: A modification of the EBC algorithm that adaptively estimates the number of clusters while maintaining $\delta$-PC guarantees.

### Open Question 3
- Question: Is the EBC algorithm robust to violations of the strict regularity conditions, such as when distributions are heavy-tailed or non-parametric?
- Basis in paper: [inferred] The theoretical analysis relies on five specific assumptions, including log-likelihood differentiability and bounded Fisher information.
- Why unresolved: The paper does not analyze performance if these specific conditions on the vector-parametric distributions are not met.
- What evidence would resolve it: An analysis of EBC's performance or the derivation of a modified algorithm that remains asymptotically optimal under relaxed assumptions.

## Limitations

- **Assumption sensitivity**: The theoretical guarantees rely on five specific assumptions (differentiability, bounded moments, Fisher information, etc.) that may not hold for all practical distributions.
- **Computational complexity**: The inf-problem over Alt(θ̂(t)) is non-convex and potentially exponential in M for large problems, though the paper doesn't provide a complexity analysis.
- **Unknown hyperparameters**: Key implementation details like step size schedule, threshold computation method, and projection algorithm are only referenced externally without specification.

## Confidence

- **High Confidence**: The asymptotic optimality claim (Theorem 3) and the fixed-confidence guarantee (Theorem 2) are rigorously proven within the stated assumptions. The mechanism of using gradient descent instead of full optimization is mathematically sound.
- **Medium Confidence**: The practical implementation details (step sizes, threshold computation, Alt(θ) enumeration) are sufficient for reproducing results on small-scale synthetic problems (M≤20) but may not scale. The EBC-H heuristic lacks theoretical guarantees but shows empirical gains.
- **Low Confidence**: The generality claim for "vector-parametric distributions" is limited by the regularity assumptions (e.g., existence of Fisher information, bounded moments). The paper doesn't validate EBC on heavy-tailed or discrete distributions.

## Next Checks

1. **Convergence Verification**: On Synthetic Dataset 1, plot w(t) convergence and θ̂_m(t) → θ_m paths over time to confirm r-quick convergence and gradient tracking work as claimed.
2. **Scalability Test**: Implement Alt(θ) enumeration for M=10 arms, K=3 clusters. Measure runtime of ψ(w, θ) computation vs. t to quantify the computational bottleneck and verify it remains tractable.
3. **Robustness Check**: Apply EBC to a heavy-tailed distribution (e.g., Cauchy-distributed arms with clustered locations). Check if the algorithm still stops finitely and produces correct clustering, or if Assumptions 1-5 are violated in practice.