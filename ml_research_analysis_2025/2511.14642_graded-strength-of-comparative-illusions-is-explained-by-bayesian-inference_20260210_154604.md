---
ver: rpa2
title: Graded strength of comparative illusions is explained by Bayesian inference
arxiv_id: '2511.14642'
source_url: https://arxiv.org/abs/2511.14642
tags:
- have
- acceptability
- more
- sentence
- posterior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study bridges a gap in understanding comparative illusions
  by developing a quantitative model of the noisy-channel posterior probability of
  plausible interpretations. The authors integrate human behavioral data from a sentence
  correction task with statistical language models (GPT-2 Small and OPT) to approximate
  the posterior distribution of intended meanings given an anomalous comparative illusion
  sentence.
---

# Graded strength of comparative illusions is explained by Bayesian inference

## Quick Facts
- arXiv ID: 2511.14642
- Source URL: https://arxiv.org/abs/2511.14642
- Reference count: 29
- Key outcome: Noisy-channel Bayesian inference with mean linking function explains graded illusion strength in comparative illusions

## Executive Summary
This study bridges a gap in understanding comparative illusions by developing a quantitative model of the noisy-channel posterior probability of plausible interpretations. The authors integrate human behavioral data from a sentence correction task with statistical language models (GPT-2 Small and OPT) to approximate the posterior distribution of intended meanings given an anomalous comparative illusion sentence. They test whether this approximation predicts graded illusion strength as measured by acceptability judgments in a large-scale experiment (n=500). The model explains significant variance in acceptability over strong controls, with the mean posterior probability of multiple plausible interpretations outperforming alternatives.

## Method Summary
The authors combined acceptability ratings from 494 participants with sentence corrections from 199 participants to approximate Bayesian inference over noisy channels. They used GPT-2 Small and OPT language models to estimate prior probabilities of intended sentences, and Damerau-Levenshtein edit distance to approximate likelihood of corruption. Posterior probabilities were computed for each plausible correction, then aggregated using either mean or max linking functions. These were used as predictors in Bayesian ordinal regression models predicting acceptability ratings, controlling for SLOR, trial order, and baseline control acceptability.

## Key Results
- The mean posterior probability across multiple plausible interpretations significantly outperformed the max posterior in predicting acceptability judgments
- The model explains substantial variance in acceptability over strong control variables
- Noisy-channel theory successfully accounts for graded (rather than binary) illusion strength

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Comparative illusion strength is conditionally explained by a comprehender's implicit Bayesian inference over a noisy communication channel.
- Mechanism: Upon perceiving an anomalous sentence (e.g., "More students have been to Russia than I have"), the comprehender computes a posterior probability distribution over plausible intended meanings (s_i). This posterior is proportional to the product of (1) the prior probability of the intended meaning p(s_i) and (2) the likelihood p(s_p|s_i) that the intended meaning could have been corrupted into the perceived anomalous sentence.
- Core assumption: The human language comprehension system operates as an approximately rational Bayesian agent, integrating prior knowledge with uncertain input.
- Evidence anchors:
  - [abstract] "The authors integrate human behavioral data... to approximate the posterior distribution of intended meanings given an anomalous comparative illusion sentence."
  - [section: 1 Introduction] "noisy channel theories predict that illusions will occur when the posterior probability p(s_i|s_p) of an intended sentence s_i given a perceived (illusory) sentence s_p is high."
- Break condition: If future work demonstrates that illusion strength can be fully predicted by heuristic or non-probabilistic processing without recourse to Bayesian integration, this mechanism would be undermined.

### Mechanism 2
- Claim: Acceptability judgments for illusion sentences are better predicted by the mean posterior probability across multiple plausible interpretations than by the maximum posterior of any single interpretation.
- Mechanism: Instead of committing to the single most likely interpretation (a "max" linking function), the comprehension system appears to aggregate evidence from a set of plausible corrections. This "mean" linking function better aligns with behavioral acceptability ratings.
- Core assumption: The cognitive process rendering an acceptability judgment maintains or integrates uncertainty over multiple candidate interpretations rather than collapsing onto a single winner prematurely.
- Evidence anchors:
  - [abstract] "...with the mean posterior probability of multiple plausible interpretations outperforming alternatives."
  - [section: 6.5 Results] "...mean numerically outperformed max, and when mean is present in the model, the coefficient for max becomes negative, suggesting that noisy-channel effects are best captured by the linking function (f_mean) that aggregates over multiple alternatives."
- Break condition: If subsequent experiments using tasks forcing single-interpretation commitment show the "mean" link vanishes, it would suggest the effect is task-dependent, not a core property of the illusion mechanism.

### Mechanism 3
- Claim: The likelihood term of the Bayesian model, p(s_p|s_i), can be approximated using behavioral edit distance data from a sentence correction task.
- Mechanism: The probability of a corruption (noise) transforming an intended meaning (s_i) into the perceived illusion (s_p) is modeled as inversely related to the edit distance between them. Human corrections from Experiment 2 provide an empirical sample of plausible s_i, and their Damerau-Levenshtein distance to s_p serves as the likelihood proxy.
- Core assumption: The cognitive representation of "noise" or "corruption" in language production/perception is monotonically related to simple string edit operations.
- Evidence anchors:
  - [section: 6.1 Linking the posterior...] "we let the approximate likelihood p̂(s_p|s_i) be proportional to the exponentiated negative Damerau-Levenshtein edit distance (DLD)."
  - [section: 5.4 Results] "The average edit distance in each illusion condition reflects its acceptability difference from the acceptable control in Experiment 1. This result is predicted by noisy-channel theory."
- Break condition: A more cognitively-plausible noise model (e.g., one sensitive to phonological, semantic, or syntactic similarity) that yields substantially better predictive power would replace this simple approximation.

## Foundational Learning

- Concept: **Bayesian Inference & Noisy-Channel Models**
  - Why needed here: This is the core computational theory the entire paper tests. Understanding how posterior probabilities are derived from priors and likelihoods is non-negotiable.
  - Quick check question: Given a perceived sentence "The cat the dog chased ran," and a high prior for "The cat chased the dog," what would a noisy-channel account predict about its perceived acceptability? (Answer: High, if the likelihood of the intended sentence being corrupted into the perceived one is also high.)

- Concept: **Statistical Language Models (e.g., GPT-2, OPT) for Probability Estimation**
  - Why needed here: The paper uses these models to operationalize the unobservable prior p(s_i) and evidence p(s_p). You must understand their role as approximators, not ground truth.
  - Quick check question: Why might a language model's sentence probability not perfectly match a human's prior judgment of that sentence's plausibility? (Answer: Training data biases, lack of world knowledge, different objectives.)

- Concept: **Linking Hypotheses in Cognitive Modeling**
  - Why needed here: The choice between `f_max` and `f_mean` is a linking hypothesis connecting the computational-level posterior to the behavioral measurement (acceptability). This concept is key to interpreting the model comparison.
  - Quick check question: What cognitive process might be represented by a "mean" linking function versus a "max" linking function? (Answer: "Mean" suggests parallel evaluation/aggregation of alternatives; "Max" suggests a winner-take-all selection.)

## Architecture Onboarding

- Component map:
  1. Behavioral Data Pipeline: Experiment 1 (acceptability judgments) -> DV. Experiment 2 (correction task) -> Sample of s_i + edit distances (DLD).
  2. Language Model (LM) Probability Engine: (GPT-2 Small, OPT) -> Computes p(s_i) and p(s_p) for all stimuli and corrections.
  3. Posterior Calculator: Integrates LM-derived priors (p(s_i)) with DLD-derived likelihoods (p(s_p|s_i)) per Equation 8 to produce p̂(s_i|s_p) for each s_i.
  4. Linking Function Aggregator: Computes `f_max` and `f_mean` per stimulus from the set of p̂(s_i|s_p).
  5. Bayesian Regression Model: Predicts acceptability ratings using linking functions (`f_max`, `f_mean`) and control variables (SLOR, order, baseline) in a multilevel ordinal model.

- Critical path: The most sensitive part is the **Posterior Calculator**. Errors in approximating p(s_i) (via LM) or p(s_p|s_i) (via DLD) will propagate directly into the linking functions and the final model comparison. The assumption that `β=1` in the likelihood exponentiation is a key, unvalidated parameter.

- Design tradeoffs:
  - **LM Choice**: Trading between computational cost and potential psychometric fit. GPT-2 Small is cheaper but may be less accurate than OPT-1.3B.
  - **Noise Model Simplicity**: DLD is tractable and monotonic but cognitively impoverished. A more complex noise model might be more accurate but is undefined and hard to estimate.
  - **Correction Task**: Open-ended correction provides a rich sample of s_i but requires qualitative coding and may introduce participant biases.

- Failure signatures:
  - The `f_mean` link shows no predictive advantage over `f_max` in new data.
  - The model's predictions are extremely sensitive to the choice of language model.
  - A control variable (e.g., SLOR) entirely subsumes the variance explained by the posterior metrics.
  - The model fails to generalize to a different type of linguistic illusion.

- First 3 experiments:
  1. **Sensitivity Analysis on β**: Re-run the core model varying the β parameter in the likelihood approximation (e^{-β·DLD}). Does the superiority of `f_mean` hold for a range of plausible β values?
  2. **Ablation of Correction Sample**: Systematically reduce the set of s_i per stimulus (e.g., use only the top N most common corrections). At what sample size does `f_mean`'s advantage degrade? This tests the importance of multiple interpretations.
  3. **Cross-Illusion Validation**: Apply the same pipeline to a different illusion type (e.g., depth-charge illusion) using existing datasets. Does the `f_mean` link generalize, suggesting a domain-general mechanism?

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the noisy-channel posterior model with the mean linking function generalize to other linguistic illusion types (e.g., depth-charge illusion, negative polarity illusion)?
- Basis in paper: [explicit] "An immediate future step that completes the noisy-channel theory of language illusions is to investigate whether this mathematical modeling of posterior probabilities of alternatives and the mean linking function can generalize to other illusion types, such as the depth-charge illusion... and the negative polarity illusion..."
- Why unresolved: The current study only tested comparative illusions; generalization to other illusion types remains untested.
- What evidence would resolve it: Apply the same modeling approach to other illusion types and test whether the mean linking function predicts acceptability ratings similarly.

### Open Question 2
- Question: Why does the mean posterior linking function outperform the max linking function in predicting acceptability?
- Basis in paper: [explicit] "A remaining puzzle is that acceptability was better predicted by the mean linking function compared to max... The details of this mental process, and its relationship to comprehension more generally, remain to be understood."
- Why unresolved: Noisy-channel theory does not currently make predictions about how multiple candidate interpretations influence acceptability measures.
- What evidence would resolve it: Experiments comparing tasks requiring single interpretations versus tasks allowing multiple interpretations, potentially combined with more sophisticated noise models.

### Open Question 3
- Question: How do noisy-channel inferences unfold incrementally during real-time sentence processing?
- Basis in paper: [explicit] "Given that we have focused on offline judgment data, another open question concerns how these putative noisy-channel inferences unfold incrementally in time."
- Why unresolved: This study used offline acceptability judgments rather than online measures like reading times or eye movements.
- What evidence would resolve it: Online processing experiments (e.g., eye-tracking, self-paced reading) combined with incremental noisy-channel models applied word-by-word.

### Open Question 4
- Question: Can a more sophisticated noise model that captures global context and syntactic structure improve model fit?
- Basis in paper: [explicit] "Existing implementations of the noise model... are thus limited in capturing how global context and syntactic structure affect the channel distortions. Future work is needed to close this gap..."
- Why unresolved: The current noise model uses simple edit distance and does not distinguish between different types of edits based on acoustic, articulatory, or semantic similarity.
- What evidence would resolve it: Develop and test noise models incorporating linguistic constraints (phonological, syntactic, semantic) and compare predictive performance against behavioral data.

## Limitations
- The study relies on approximations (language model likelihoods, edit distance) rather than direct measurement of Bayesian components
- ~17% of corrections were implausible but handling in posterior calculations isn't fully specified
- The linking hypothesis (f_mean vs f_max) remains a computational-level claim without direct cognitive evidence

## Confidence
- **High confidence**: The noisy-channel framework successfully explains graded illusion strength as a continuous phenomenon rather than an all-or-nothing effect; the mean linking function outperforms maximum across multiple model comparisons.
- **Medium confidence**: The Bayesian inference mechanism is the best current explanation for the data, but the approximations used (LM priors, edit-distance likelihoods) leave room for alternative implementations.
- **Medium confidence**: The finding that multiple interpretations matter (f_mean > f_max) suggests a cognitively plausible uncertainty representation, though this could be task-dependent.

## Next Checks
1. **Sensitivity analysis on β parameter**: Systematically vary the β parameter in the likelihood approximation (e^{-β·DLD}) from 0.5 to 2.0 to determine if f_mean's advantage holds across a range of plausible noise models.
2. **Ablation study on correction sample size**: Systematically reduce the number of s_i per stimulus (e.g., use only top 1, 3, 5 corrections) to test when f_mean's advantage degrades, establishing the minimum number of interpretations needed.
3. **Cross-linguistic validation**: Apply the same pipeline to comparative illusions in a typologically different language (e.g., Mandarin or Arabic) to test whether the Bayesian mechanism generalizes beyond English.