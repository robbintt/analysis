---
ver: rpa2
title: 'FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for
  Equity Research Report Generation'
arxiv_id: '2511.07322'
source_url: https://arxiv.org/abs/2511.07322
tags:
- agent
- financial
- company
- news
- cash
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FinRpt, the first open-source benchmark for
  Equity Research Report (ERR) generation, addressing data scarcity and evaluation
  metric gaps. It proposes a Dataset Construction Pipeline that automatically generates
  a high-quality ERR dataset by integrating 7 financial data types and 800 stocks,
  resulting in 6,825 reports.
---

# FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation

## Quick Facts
- arXiv ID: 2511.07322
- Source URL: https://arxiv.org/abs/2511.07322
- Authors: Song Jin; Shuqi Li; Shukun Zhang; Rui Yan
- Reference count: 40
- Primary result: Introduces FinRpt, the first open-source benchmark for Equity Research Report generation with 6,825 reports across 800 stocks

## Executive Summary
This paper addresses the critical challenge of generating high-quality Equity Research Reports (ERRs) by introducing FinRpt, a comprehensive benchmark system. The authors tackle the fundamental problems of data scarcity and evaluation metric gaps in ERR generation by creating a large-scale dataset and evaluation framework. The work presents a multi-agent framework called FinRpt-Gen, specifically designed to generate professional-grade equity research reports by leveraging financial data and specialized agent interactions.

## Method Summary
The paper introduces a Dataset Construction Pipeline that automatically generates a high-quality ERR dataset by integrating 7 financial data types and 800 stocks, resulting in 6,825 reports. A comprehensive evaluation system with 11 metrics is developed, assessing report quality from text similarity, prediction accuracy, and financial professionalism perspectives. The FinRpt-Gen framework comprises nine specialized agents working collaboratively to generate equity research reports. The system is trained using Supervised Fine-Tuning and Reinforcement Learning on the constructed dataset, with experiments showing superior performance compared to strong baselines.

## Key Results
- FinRpt-Gen outperforms strong baselines, achieving 55% accuracy and 49.06 ROUGE-L score
- Human evaluation confirms generated ERRs closely match expert-written reports
- Framework excels in financial numeric precision, news analysis, and company insights
- The dataset construction pipeline successfully generates 6,825 high-quality reports from 7 financial data types across 800 stocks

## Why This Works (Mechanism)
The success of FinRpt stems from its systematic approach to addressing the fundamental challenges in equity research report generation. By integrating multiple financial data sources and creating specialized agents, the framework can capture the complex, multi-faceted nature of professional equity analysis. The combination of automated data collection, comprehensive evaluation metrics, and agent-based generation creates a robust system that can produce reports with high professional quality and accuracy.

## Foundational Learning
- Financial data integration (why needed: ERRs require diverse financial inputs; quick check: verify 7 data types are correctly processed)
- Multi-agent collaboration (why needed: complex reports need specialized expertise; quick check: validate agent communication flows)
- Evaluation metric design (why needed: quality assessment requires multiple perspectives; quick check: test metric consistency across report types)
- Reinforcement learning for financial generation (why needed: optimize report quality based on feedback; quick check: monitor reward convergence)
- Domain-specific fine-tuning (why needed: financial terminology requires specialized understanding; quick check: validate terminology accuracy)
- Automated report construction (why needed: scale dataset creation efficiently; quick check: verify report consistency and completeness)

## Architecture Onboarding

Component Map: Data Sources -> Data Processing Pipeline -> Agent Framework -> Report Generation -> Evaluation System

Critical Path: Financial Data Collection → Data Preprocessing → Agent Interaction → Report Generation → Quality Assessment

Design Tradeoffs: The framework prioritizes report quality and accuracy over generation speed, using multiple specialized agents rather than a single monolithic model. This increases complexity but enables more nuanced and professional reports.

Failure Signatures: Poor data quality from sources leads to inaccurate reports; agent communication breakdowns cause inconsistent analysis; insufficient training data results in generic or incorrect recommendations.

First Experiments:
1. Test single-agent generation to establish baseline performance
2. Validate individual agent accuracy on their specific tasks
3. Measure inter-agent communication effectiveness in controlled scenarios

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- The benchmark's focus on Chinese stocks limits generalizability to other markets and languages
- Heavy reliance on Webull platform's data quality and availability could affect replication
- The multi-agent framework's complexity introduces multiple potential points of failure
- Limited dataset size (6,825 reports) may not capture full complexity of equity research

## Confidence
High for dataset construction methodology and multi-agent framework design; Medium for evaluation system effectiveness and benchmark utility; Low for generalizability to other markets and languages.

## Next Checks
1. Cross-market validation: Test the framework on equity research reports from different stock markets (e.g., US, European) to assess generalizability
2. External data source validation: Construct a parallel dataset using alternative financial data sources to verify robustness against data source variations
3. Long-term performance monitoring: Track the framework's performance over time with new data to evaluate stability and adaptability to changing market conditions