---
ver: rpa2
title: Data-Driven Qubit Characterization and Optimal Control using Deep Learning
arxiv_id: '2601.18704'
source_url: https://arxiv.org/abs/2601.18704
tags:
- control
- pulse
- gate
- pulses
- qubit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a data-driven method for optimizing quantum
  control pulses using recurrent neural networks (RNNs). The approach addresses the
  challenge of incomplete system models in quantum gate optimization by training an
  RNN to predict qubit dynamics from experimental measurements of random control pulses.
---

# Data-Driven Qubit Characterization and Optimal Control using Deep Learning

## Quick Facts
- **arXiv ID:** 2601.18704
- **Source URL:** https://arxiv.org/abs/2601.18704
- **Reference count:** 0
- **Primary result:** RNN surrogate models trained on random probe pulses achieve 1.11% average infidelity in optimized single-qubit gates

## Executive Summary
This paper proposes a data-driven approach for optimizing quantum control pulses using recurrent neural networks (RNNs). The method trains an RNN to predict qubit dynamics from experimental measurements of random control pulses, creating a differentiable surrogate model for gradient-based pulse optimization. This approach addresses the challenge of incomplete system models in quantum gate optimization by learning directly from experimental data rather than relying on detailed physical models. The method was validated through simulations on an ST₀ qubit, achieving average infidelities of 1.11% across optimized gate sets.

## Method Summary
The method trains an RNN surrogate model on random probe pulse responses to predict qubit measurement outcomes, then uses the differentiable model for gradient-based control pulse optimization of single-qubit gates (Xπ/2, Yπ/2). Random control pulses with detuning ϵ are sampled and applied to the device, with measurement outcomes p|0⟩(λ) collected via Monte Carlo simulation. The RNN (LSTM-based with Conv1D layers, 83,562 parameters) is trained on 2M samples with pulse lengths 10-50ns, then used to optimize 12ns pulses for the target gates using Gate Set Calibration (GSC) sequences. The optimization minimizes L_GSC syndrome loss with L2 penalty on predicted variance, selecting the top 10/256 gate sets by lowest L_GSC.

## Key Results
- RNN surrogate model achieved >95% accuracy within 0.05 error margin on held-out test pulses
- Optimized gate sets achieved average infidelities of 1.11% across Xπ/2 and Yπ/2 gates
- Performance comparable to optimization using full system knowledge
- Method successfully handles non-linearities and transfer function distortions without explicit modeling

## Why This Works (Mechanism)

### Mechanism 1
**Claim:** A Recurrent Neural Network (RNN) can approximate qubit dynamics, including non-linearities and transfer function distortions, using only control-measurement pairs.
**Mechanism:** The RNN acts as a universal function approximator. By processing sequences of control voltages (λ), it encodes the temporal dependencies of the Hamiltonian evolution and the hardware's transfer function into its hidden states, mapping them to measurement probabilities p|0⟩.
**Core assumption:** The experimental system's response to control pulses is sufficiently deterministic and Markovian-like within the time steps to be learnable by an LSTM structure.
**Evidence anchors:** [abstract]: "training a recurrent neural network (RNN) to predict qubit dynamics from experimental measurements." [section]: "RNNs... well-suited for modeling dynamic systems due to their ability to learn temporal dependencies."

### Mechanism 2
**Claim:** Gate Set Calibration (GSC) loss provides a self-consistent, differentiable objective for optimization without requiring full quantum state tomography.
**Mechanism:** GSC sequences amplify coherent gate errors into a measurable "error syndrome." By minimizing the squared deviation of these syndromes (L_GSC), the optimizer corrects systematic Pauli errors. Because this loss is derived from simple measurement statistics, it is compatible with the RNN's output format.
**Core assumption:** State Preparation and Measurement (SPAM) errors are small enough or sufficiently decoupled that minimizing the syndrome primarily corrects gate errors rather than amplifying SPAM biases.
**Evidence anchors:** [section]: "GSC mitigates these issues by identifying and correcting systematic errors... proxy for the coherent gate infidelities."

### Mechanism 3
**Claim:** Surrogate-based gradient descent transfers effectively from simulation to the physical device (or high-fidelity simulation).
**Mechanism:** The RNN surrogate allows for efficient backpropagation to compute gradients of the GSC loss with respect to pulse parameters. This bypasses the need for costly finite-difference approximations on the physical hardware ("quantum-classical" feedback loop).
**Core assumption:** The "sim-to-real" gap is closed by training the surrogate purely on experimental data, meaning the gradients calculated on the surrogate point "downhill" on the actual device.
**Evidence anchors:** [abstract]: "achieved average infidelities of 1.11%... comparable performance to optimization using full system knowledge."

## Foundational Learning

**Surrogate Modeling / System Identification**
- **Why needed here:** You cannot perform gradient-based optimization on a black-box physical system efficiently without a differentiable model. The RNN serves as a "digital twin" learned from data.
- **Quick check question:** If I feed the RNN a random pulse sequence, can it predict the final measurement probability more accurately than a simple linear model?

**Transfer Functions & Bandwidth Limitations**
- **Why needed here:** In quantum hardware, the electrical signal sent is rarely the signal that arrives at the qubit due to filtering and distortion. The paper explicitly models this by learning the distortion implicitly rather than using a fixed analytical kernel.
- **Quick check question:** Does the model account for the "ringing" or transient voltages that occur immediately after a sharp voltage change in the pulse?

**Gate Set Calibration (GSC)**
- **Why needed here:** Standard fidelity metrics (like process fidelity) are hard to measure. GSC provides a scalar "loss" that is fast to measure and correlates with fidelity, making it suitable as a loss function for the neural network.
- **Quick check question:** Is the optimization metric a direct physical measurement (like population), or is it a derived quantity that requires running a specific sequence of gates?

## Architecture Onboarding

**Component map:**
Random pulse generator → Device simulator → Measurement outcomes → RNN training → Optimized pulse generator → GSC sequence evaluation → SGD optimization → Best gate set selection

**Critical path:**
1. **Data Quality:** Sampling the device with "weak prior assumptions" (random pulses) that still cover the relevant voltage range (to avoid the RNN extrapolating poorly).
2. **Training Convergence:** The RNN must achieve high accuracy (A0.05 > 95%) on held-out test pulses; otherwise, gradient directions will be noisy.
3. **Selection:** Running 256 optimization seeds in parallel and selecting the top 10 based on lowest L_GSC to ensure robustness against local minima.

**Design tradeoffs:**
- **Physics-informed vs. Pure Data-driven:** The paper chooses not to enforce CPTP (Completely Positive Trace Preserving) constraints, opting for a generic RNN. This trades physical guarantee for approximation flexibility.
- **Random vs. Structured Probing:** Random pulses are cheap and scalable, but might miss specific corner cases (e.g., specific resonant transitions) that a structured grid might capture.

**Failure signatures:**
- **Distribution Shift:** The optimizer creates pulses that look very different from the training pulses (e.g., very high amplitude or sharp spikes), causing the RNN to output non-physical probabilities (clipped to [0,1]) or erroneous gradients.
- **GSC Local Minima:** Optimization converges to a pulse set with low L_GSC but high actual infidelity (false positive).
- **Noise Overfitting:** The RNN fits the statistical noise of the probe measurements rather than the underlying deterministic dynamics.

**First 3 experiments:**
1. **Sanity Check (General Model):** Train the RNN on the "general" simulation (Gaussian noise, ideal exchange). Verify if the optimization can find a simple X-gate with infidelity < 2%.
2. **Robustness Test (Specific Model):** Train on the "specific" simulation (measured transfer function kernels). Check if the network prediction error increases for longer pulse sequences (generalization test).
3. **Ablation on Probing:** Reduce the size of the training dataset (e.g., from 2M to 100k samples) to determine the minimum data density required for the optimizer to converge.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance generalizability beyond training distribution is uncertain; optimized pulses deviating from random probe pulses may produce unreliable gradients
- GSC loss assumes linear error model that may break down for initial gate infidelities exceeding ~20%
- Method performance on multi-qubit systems or complex pulse shapes remains unexplored
- Computational cost of generating 2M probe samples may be prohibitive for some experimental setups

## Confidence

**High Confidence:** The RNN can learn and predict qubit dynamics from control-measurement data pairs, achieving good prediction accuracy (>95% within 0.05 error margin).

**Medium Confidence:** The surrogate-based optimization achieves infidelities comparable to full-model optimization (1.11% average), though validation is limited to simulated ST₀ qubits.

**Medium Confidence:** GSC loss provides a useful, differentiable proxy for gate infidelity that enables efficient optimization without full state tomography.

**Low Confidence:** Claims about the method's robustness to experimental noise and hardware drift are not directly tested beyond simulation.

## Next Checks
1. **Distribution Shift Test:** Generate optimized pulses that systematically deviate from the training distribution (e.g., higher amplitude, sharper transitions) and measure the RNN's prediction accuracy degradation.
2. **Cross-Device Transfer:** Train the surrogate model on one simulated device (with specific transfer function and noise characteristics) and attempt optimization on a different simulated device to test model robustness.
3. **Noise Sensitivity Analysis:** Vary the levels of quasi-static and 1/f noise in the training data and measure the resulting impact on final gate infidelity to establish the method's noise tolerance limits.