---
ver: rpa2
title: Coreset selection based on Intra-class diversity
arxiv_id: '2509.21380'
source_url: https://arxiv.org/abs/2509.21380
tags:
- dataset
- coreset
- training
- learning
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces an intelligent sampling methodology based
  on intraclass diversity for coreset selection in deep learning-based biomedical
  image classification. The proposed approach extracts intraclass diversity to form
  per-class clusters using K-Medoids clustering and then intelligently samples these
  clusters to create a representative subset of the original dataset.
---

# Coreset selection based on Intra-class diversity

## Quick Facts
- **arXiv ID**: 2509.21380
- **Source URL**: https://arxiv.org/abs/2509.21380
- **Reference count**: 10
- **Primary result**: Intelligent sampling based on intra-class diversity achieves comparable accuracy to full dataset training using only 25% of data

## Executive Summary
This study introduces an intelligent sampling methodology for coreset selection in deep learning-based biomedical image classification. The proposed approach extracts intraclass diversity to form per-class clusters using K-Medoids clustering, then intelligently samples these clusters to create a representative subset of the original dataset. Evaluated on the Peripheral Blood Cell (PBC) dataset using both custom CNN and pretrained ResNet-101-v2 models, the method consistently outperforms random sampling across multiple performance metrics while reducing computational costs.

## Method Summary
The proposed Intelligent Sampling (IS) method works by first extracting features from blood cell images using a frozen VGG16 model pretrained on ImageNet. These high-dimensional features are then reduced via PCA (retaining 95% variance) to improve clustering quality and efficiency. K-Medoids clustering is applied within each class to identify distinct sub-populations based on intra-class diversity. Finally, the method uniformly samples from each identified cluster to create a representative coreset, ensuring that rare morphologies and diverse cell types are included rather than allowing dominant modes to dominate the sample selection.

## Key Results
- Models trained on intelligently selected coreset (25% of dataset) achieved comparable performance to models trained on complete dataset (accuracy ~81-82%)
- Intelligent Sampling consistently outperformed Random Sampling across multiple performance metrics
- The method effectively reduced computational costs while maintaining high classification accuracy and robustness
- Custom 14-layer CNN and pretrained ResNet-101-v2 models both benefited from the intelligent sampling approach

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The proposed Intelligent Sampling (IS) method mitigates the under-representation of diverse subgroups within a class better than Random Sampling (RS).
- **Mechanism**: The method applies K-Medoids clustering within each class to identify distinct sub-populations (intra-class diversity). By sampling uniformly from each identified cluster rather than the class aggregate, it prevents over-sampling dominant modes and ensures rare morphologies are included in the coreset.
- **Core assumption**: Visual diversity in the feature space corresponds to semantic diversity relevant to the classification task.
- **Evidence anchors**:
  - [abstract]: "proposes a method to extract intraclass diversity, forming per-class clusters that are utilized for the final sampling."
  - [section 4.3]: "K-Medoids chooses actual data points as centers... making it more robust to noise and outliers."
  - [corpus]: *SubZeroCore* supports the efficacy of training-free coreset selection, aligning with the use of fixed features here.
- **Break condition**: If the data within a class is a continuous manifold with no distinct clusters, or if the feature extractor fails to separate semantic variations, clustering will impose artificial boundaries that may not aid generalization.

### Mechanism 2
- **Claim**: Using a fixed pre-trained feature extractor (VGG16) allows for efficient coreset selection without the computational cost of training on the target dataset first.
- **Mechanism**: The pipeline freezes the weights of a VGG16 model pre-trained on ImageNet. It passes the blood cell images through this network to extract features from the last pooling layer. These features serve as the basis for similarity calculations in the clustering step, decoupling the selection process from the specific training of the target classifier.
- **Core assumption**: Features learned on natural images (ImageNet) transfer sufficiently to capture the structural nuances of biomedical images (blood cells).
- **Evidence anchors**:
  - [section 4.1]: "features from the last pooling layer are extracted to obtain a compact representation... VGG16 [SZ15]."
  - [abstract]: "intelligent, lightweight mechanism... effectively reduces computational costs."
  - [corpus]: *Non-Uniform Class-Wise Coreset Selection* highlights the importance of class-wise data efficiency, supporting the move away from gradient-based (training-dependent) selection.
- **Break condition**: If the domain shift between ImageNet and microscopic blood cells is too large, the extracted features may be semantically meaningless, causing the clustering to group images based on irrelevant low-level statistics (e.g., background color) rather than cell type.

### Mechanism 3
- **Claim**: Dimensionality reduction via PCA improves clustering quality and computational efficiency by denoising the feature space.
- **Mechanism**: High-dimensional embeddings from VGG16 often contain redundant information. By retaining 95% of the variance via PCA, the method projects data into a lower-dimensional subspace. This emphasizes the primary axes of variation, allowing K-Medoids to identify more robust clusters and reducing the $O(N^2)$ complexity burden of the clustering step.
- **Core assumption**: The most significant variance in the data corresponds to meaningful biological differences between cell samples, while lower-variance components constitute noise.
- **Evidence anchors**:
  - [section 4.2]: "PCA projects the embeddings onto a new basis... ensuring minimal loss of information... value of k is chosen... typically retaining 95%."
  - [abstract]: "method effectively reduces computational costs while maintaining high classification accuracy."
  - [corpus]: Evidence is weak in the provided corpus regarding specific PCA benefits for coreset selection; this inference relies on the paper's internal justification in Section 4.2.
- **Break condition**: If critical discriminative features for rare classes exist in low-variance dimensions, PCA will discard them, making it impossible for the subsequent clustering step to identify those rare samples.

## Foundational Learning

- **Concept: K-Medoids vs. K-Means Clustering**
  - **Why needed here**: The paper explicitly chooses K-Medoids over K-Means. You must understand that K-Means minimizes squared error (sensitive to outliers) and uses virtual centroids, while K-Medoids minimizes pairwise dissimilarity and uses actual data points as centers (robust to outliers).
  - **Quick check question**: If you have a noisy dataset with extreme outliers, which method is likely to create a more stable central representative for a cluster?

- **Concept: Transfer Learning & Feature Hierarchies**
  - **Why needed here**: The method relies on VGG16 features. You need to grasp that early layers capture generic edges/textures (transferable) while later layers capture dataset-specific objects (less transferable). The paper uses the "last pooling layer" as a balance.
  - **Quick check question**: Why would extracting features from the final classification layer of VGG16 be a poor choice for clustering diverse blood cell images?

- **Concept: The Bias-Variance Trade-off in Sampling**
  - **Why needed here**: The paper argues Random Sampling (RS) leads to underfitting (high bias) in custom CNNs or overfitting (high variance) in ResNet due to poor data representation. Intelligent Sampling aims to reduce variance (by covering all modes) without increasing bias significantly.
  - **Quick check question**: Why does reducing the dataset size via random sampling often hurt generalization more than reducing it via stratified diversity sampling?

## Architecture Onboarding

- **Component map**: Raw Blood Cell Images (PBC Dataset) -> Pre-trained VGG16 (Frozen) -> $N \times d$ Embeddings -> PCA -> $N \times k$ Reduced Embeddings -> K-Medoids (Per Class) -> Cluster Assignments -> Uniform Sampler (Per Cluster) -> Coreset Indices -> Custom CNN or ResNet-101-v2

- **Critical path**: The **Silhouette Score** calculation in the K-Medoids phase is critical. If the optimal cluster count ($K$) is misidentified, the sampling will either fragment cohesive groups or merge distinct subtypes, breaking the "intra-class diversity" preservation.

- **Design tradeoffs**:
  - **VGG16 vs. ResNet for selection**: The paper uses VGG16 for selection but ResNet for classification training. VGG16 is computationally cheaper for simple feature extraction but may offer less semantic richness than modern backbones (e.g., ResNet-50 features), trading off selection quality for setup speed.
  - **Cluster Count ($K$)**: Higher $K$ captures more diversity but risks overfitting to noise and increasing selection time.

- **Failure signatures**:
  - **Homogeneity Collapse**: If clustering returns a single cluster ($K=1$) for a diverse class, the mechanism degrades to random sampling.
  - **Over-segmentation**: If $K$ is too high, the coreset may consist of too many outlier/noise samples, degrading model accuracy by training on "garbage" data.
  - **RS Outperformance**: If Random Sampling beats Intelligent Sampling, it suggests the feature space (VGG16) does not align with the classification task's semantic needs.

- **First 3 experiments**:
  1. **Baseline Validation**: Train the custom 14-layer CNN on the full dataset vs. a 25% Random Sample to reproduce the accuracy drop described in the paper.
  2. **Feature Ablation**: Compare VGG16 features vs. ResNet features for the clustering step to see if a stronger backbone improves the "purity" of the clusters.
  3. **Sensitivity Analysis**: Vary the coreset percentage (e.g., 10%, 25%, 50%) with the IS method to map the point of diminishing returns where IS matches full-dataset performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of cluster count and silhouette scoring thresholds affect the performance of the proposed Intelligent Sampling (IS) technique?
- Basis in paper: [explicit] The authors state that future work will "determine the impact of various parameters, including silhouette scoring and cluster count, on different metrics."
- Why unresolved: The current study evaluates the method's overall efficacy but does not isolate the sensitivity of the results to these specific hyperparameters.
- What evidence would resolve it: Results from systematic ablation studies demonstrating how variations in cluster counts influence accuracy, precision, and recall.

### Open Question 2
- Question: Can the proposed coreset selection method maintain performance when applied to diverse biomedical imaging domains such as dermatology or histopathology?
- Basis in paper: [explicit] The authors acknowledge the study is "based on a single biomedical imaging dataset, PBC" and propose testing on "dermatology or histopathology scans."
- Why unresolved: The method's utility is currently demonstrated only on peripheral blood cell images, limiting claims of universal applicability in medical imaging.
- What evidence would resolve it: Comparable classification results on dermatology and histopathology datasets using the coreset versus the full dataset.

### Open Question 3
- Question: Is the intraclass diversity-based coreset selection method effective for non-medical image classification tasks?
- Basis in paper: [explicit] The authors state, "Furthermore, we will expand the idea of IS-based coreset selection for other non-medical classification studies."
- Why unresolved: The validation is currently confined to the biomedical domain, leaving the method's robustness in general computer vision contexts unproven.
- What evidence would resolve it: Performance metrics derived from applying the sampling technique to standard non-medical image classification benchmarks.

## Limitations

- **Feature representation bottleneck**: The method relies on VGG16 features for clustering, which may not capture domain-specific characteristics of blood cell morphology as effectively as features learned from the target dataset.
- **Cluster validity assumption**: The approach assumes that K-Medoids will reliably identify meaningful subgroups within each class, which may not hold when classes are continuous manifolds or when feature space doesn't align with task-relevant distinctions.
- **Computational scaling**: While PCA reduces dimensionality, the K-Medoids clustering step still has $O(N^2)$ complexity, making the method challenging to scale to very large datasets.

## Confidence

- **High confidence**: The core mechanism of using intra-class diversity via K-Medoids clustering is well-established and the experimental setup is clearly described.
- **Medium confidence**: The specific performance improvements (81-82% accuracy on 25% data matching full-dataset performance) are credible but may not generalize to other biomedical imaging domains.
- **Low confidence**: Claims about computational cost reduction relative to alternative coreset methods are not quantified in detail.

## Next Checks

1. **Feature space validation**: Compare clustering results using VGG16 features versus ResNet features to quantify the impact of feature representation quality on selection effectiveness.

2. **Dataset generalizability test**: Apply the method to a different biomedical imaging dataset (e.g., histopathology images) to assess whether the performance gains transfer across domains.

3. **Computational complexity analysis**: Measure and compare the actual wall-clock time for IS versus RS across different dataset sizes to provide concrete evidence for the claimed efficiency gains.