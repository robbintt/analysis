---
ver: rpa2
title: Characterizing Linguistic Shifts in Croatian News via Diachronic Word Embeddings
arxiv_id: '2506.13569'
source_url: https://arxiv.org/abs/2506.13569
tags:
- word
- words
- shift
- embeddings
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates diachronic word embeddings on Croatian news
  spanning 25 years, revealing linguistic shifts tied to major societal changes. Using
  skip-gram embeddings trained on five-year periods, it detects semantic drift in
  terms linked to COVID-19, EU accession, and technology.
---

# Characterizing Linguistic Shifts in Croatian News via Diachronic Word Embeddings

## Quick Facts
- **arXiv ID:** 2506.13569
- **Source URL:** https://arxiv.org/abs/2506.13569
- **Reference count:** 18
- **Primary result:** Semantic drift in Croatian news embeddings reveals linguistic shifts tied to societal events (COVID-19, EU, tech), with increased positivity in later periods contrasting documented mental health declines.

## Executive Summary
This work investigates diachronic word embeddings on Croatian news spanning 25 years (2000–2024), revealing linguistic shifts tied to major societal changes. Using skip-gram embeddings trained on five-year periods, it detects semantic drift in terms linked to COVID-19, EU accession, and technology. The embeddings, evaluated for quality via word similarity and synonym discrimination, show moderate correlation with human judgments and improve over time. Notably, sentiment analysis using these embeddings indicates a trend toward increased positivity in recent periods, contrasting with documented declines in mental health. The findings demonstrate that linguistic shifts can be effectively captured even in shorter timeframes and that embedding-based sentiment can diverge from broader societal trends.

## Method Summary
The method trains skip-gram embeddings (Gensim Word2Vec) separately for each five-year period of the TakeLab Retriever corpus (9.5M articles, 3.7B words), using consistent hyperparameters (300-dim, window=4, negative=5). After preprocessing with spaCy POS tagging and MOLEX lemmatization, embeddings are recursively aligned via orthogonal Procrustes alignment starting from the most recent period. Semantic shifts are quantified using cumulative shift scores (Dc) based on halved cosine distances between adjacent period vectors. Embedding quality is evaluated intrinsically using CroSemRel450 (word similarity) and CroSYN (synonym discrimination), and extrinsically via sentiment transfer experiments using logistic regression classifiers trained on STONE and 24sata datasets.

## Key Results
- Embedding quality (Spearman correlation on CroSemRel450) improves from 0.48 in 2000–2004 to 0.56 in 2020–2024 as corpus size increases.
- Top-shifting words show coherent semantic transitions: "varijanta" (Dc=0.53) shifts from general meaning to COVID-19 variants, "maska" (Dc=0.66) from clothing to pandemic protection.
- Sentiment analysis reveals a statistically significant increase in positivity in later periods (2015–2024), contrasting with documented societal mental health declines.
- CroSYN synonym discrimination improves across periods (contrastive spread increases from 0.27 to 0.39), indicating better embedding discrimination.

## Why This Works (Mechanism)

### Mechanism 1
Skip-gram embeddings trained on distinct time slices capture semantic drift through changes in co-occurrence patterns. Words appearing in similar contexts receive similar vector representations; as real-world usage contexts shift (e.g., "mask" from clothing to pandemic protection), the learned vectors move accordingly, which is quantifiable via cosine distance between adjacent periods. Core assumption: Each time slice contains sufficient context diversity to learn meaningful representations, and semantic change is reflected in distributional shifts rather than just frequency changes. Evidence anchors: [abstract] "Using skip-gram embeddings trained on five-year periods, it detects semantic drift in terms linked to COVID-19, EU accession, and technology." [section 3.1] "We use the skip-gram with negative sampling (SGNS) method from Word2Vec (Mikolov et al., 2013) to train our word embeddings." Break condition: Insufficient corpus size per period leads to sparse contexts and noisy embeddings; very frequent polysemous words may show spurious drift.

### Mechanism 2
Procrustes alignment enables cross-period comparison by mapping independently-trained embedding spaces into a shared coordinate system. An orthogonal transformation matrix is learned to minimize the Frobenius norm between aligned embedding matrices. The paper uses recursive alignment starting from the most recent period (2020–2024) backward, anchoring all earlier spaces to the latest. Core assumption: A shared vocabulary with stable core meanings exists across periods, and the overlap is sufficient to learn a reliable orthogonal mapping. Evidence anchors: [section 3.3] "For this analysis, we use Procrustes alignment (Schönemann, 1966) to align word embeddings across periods. We begin by recursively aligning pairs of embeddings, starting from the most recent, fifth period (2020–2024), and then moving toward the earlier ones." [table 3] The alignment is used to compute cumulative shift scores (Dc) for words like "varijanta" (Dc=0.53) and "maska" (Dc=0.66), showing coherent semantic transitions. Break condition: High vocabulary turnover or too few shared anchor words degrades alignment; orthogonal constraint may be too restrictive if embedding spaces have diverged significantly.

### Mechanism 3
The cumulative shift score (Dc), based on halved cosine distance between adjacent period vectors, quantifies meaningful semantic change over time. Dc = Σ(1 - cos(vi, vi+1))/2 sums pairwise distances across four adjacent transitions, capturing both gradual drift and sudden shifts. High Dc values indicate words whose contextual neighborhood changed substantially. Core assumption: Real semantic change produces measurable vector distance that accumulates, while random noise averages out; nouns are more prone to measurable shift than verbs or adjectives. Evidence anchors: [section 3.3] "We measure the shift of each word using the cumulative shift score, based on the halved cosine distance (cos) over neighboring periods." [section 4.2] "We provide a summary of words exhibiting most prominent shifts in Table 3. We show that neighboring words of top-shifting words inside a topic can pinpoint the period when words acquire new meanings." Break condition: Polysemous words with stable multiple senses may show drift without real meaning change; very rare words have unreliable vectors regardless of semantic stability.

## Foundational Learning

- **Concept: Skip-gram with Negative Sampling (SGNS)**
  - Why needed here: This is the core architecture for learning static word embeddings from co-occurrence statistics. Without understanding how context windows and negative sampling work, you cannot diagnose embedding quality issues or tune hyperparameters meaningfully.
  - Quick check question: Why does negative sampling improve computational efficiency over the full softmax in skip-gram training?

- **Concept: Orthogonal Procrustes Alignment**
  - Why needed here: Embeddings trained on different corpora exist in different vector spaces. Procrustes alignment is the standard method to place them in a shared coordinate system for diachronic comparison.
  - Quick check question: Why is an orthogonal transformation preferred over an unconstrained linear transformation when aligning word embedding spaces?

- **Concept: Intrinsic vs. Extrinsic Embedding Evaluation**
  - Why needed here: The paper uses both intrinsic (word similarity, synonym discrimination) and extrinsic (sentiment classification transfer) evaluation. Understanding this distinction is critical for interpreting claims about embedding quality and practical utility.
  - Quick check question: Why might embeddings that perform well on intrinsic similarity tasks fail to improve downstream task performance?

## Architecture Onboarding

- **Component map:** Corpus acquisition (9.5M articles) → Preprocessing (sentence/token/lemma/POS) → Temporal segmentation (5 periods) → Per-period SGNS training → Intrinsic quality validation (CroSemRel450, CroSYN) → Procrustes alignment → Shift analysis (Dc scores, neighbor inspection) → Sentiment transfer experiments (STONE, 24sata datasets)

- **Critical path:** Corpus acquisition (9.5M articles) → Preprocessing (sentence/token/lemma/POS) → Temporal segmentation (5 periods) → Per-period SGNS training → Intrinsic quality validation (CroSemRel450, CroSYN) → Procrustes alignment → Shift analysis (Dc scores, neighbor inspection) → Sentiment transfer experiments (classifier embedding substitution)

- **Design tradeoffs:**
  - **5-year windows:** Authors report 2-year periods were "too fine-grained" (sparse data), while longer windows would obscure rapid events like COVID-19. Five years balances data volume and temporal resolution.
  - **Static (SGNS) vs. contextual embeddings:** Static embeddings enable direct vector comparison and alignment; contextual models (e.g., BERTić used only for sentiment labeling) would complicate diachronic analysis but may capture polysemy better.
  - **Recursive alignment from latest period:** Later periods have more data (Table 1: Period 5 has 1.75B words vs. 53M in Period 1), producing more stable embedding spaces as alignment targets.

- **Failure signatures:**
  - **Low intrinsic correlation:** Spearman ρ < 0.5 on CroSemRel450 suggests insufficient context diversity or preprocessing errors.
  - **Noisy shift scores:** High Dc for common function words indicates alignment failure rather than real semantic change.
  - **Incoherent neighbor evolution:** If nearest neighbors change randomly (not thematically), the signal is likely data sparsity rather than meaningful shift.
  - **Sentiment transfer inconsistency:** Non-monotonic or contradictory shifts across datasets suggest classifier instability rather than embedding-driven effects.

- **First 3 experiments:**
  1. **Validate embedding quality per period:** Train SGNS on each slice, evaluate on CroSemRel450 (Spearman correlation) and CroSYN (contrastive spread). Confirm quality improves with corpus size as reported.
  2. **Reproduce topical shift analysis:** Curate word lists for COVID-19, EU, and technology topics; compute Dc scores; inspect top-5 nearest noun neighbors per period to verify coherent semantic transitions (e.g., "inteligencija" from cognitive to AI contexts).
  3. **Sentiment transfer sanity check:** Train linear classifiers on period-specific embeddings for STONE/24sata, substitute aligned embeddings from other periods, and measure average sentiment shift. Verify that later-period embeddings produce more positive predictions as claimed.

## Open Questions the Paper Calls Out

- **Question:** What specific phenomena (e.g., media polarization, satire, or compensatory positivity) drive the observed divergence between increased embedding-based sentiment positivity and documented declines in societal mental health?
  - **Basis in paper:** [explicit] The discussion section states that the increase in positivity could be attributed to several factors like "increased polarization" or "satirical or comedic articles," and explicitly notes that "this phenomenon... warrants further study."
  - **Why unresolved:** The current methodology identifies the trend and proposes hypotheses but does not isolate the causal mechanism or specific content types responsible for the shift.
  - **What evidence would resolve it:** A fine-grained analysis correlating sentiment scores with article genres or a comparative study linking lexical changes to external metrics of media tone versus societal well-being.

- **Question:** Do semantic shift findings derived from Skip-gram with Negative Sampling (SGNS) generalize to contextualized embedding models for morphologically rich languages like Croatian?
  - **Basis in paper:** [explicit] The authors explicitly list as a limitation that they "only explore a single distributed word embedding method in SGNS, the results of which need not generalize to other methods."
  - **Why unresolved:** Static embeddings conflate polysemy into a single vector, whereas contextualized models separate senses; it remains untested if the drift observed in static vectors holds when analyzing specific contextual usages.
  - **What evidence would resolve it:** Replicating the alignment and shift detection experiments using contextualized models (e.g., BERTić) to verify if similar cumulative shift scores are observed for the target topics.

- **Question:** How does the significant imbalance in corpus volume across periods (53M words vs. 1.7B words) bias the measurement of semantic change?
  - **Basis in paper:** [inferred] While the paper notes that embedding quality improves with data quantity, the Limitations section concedes that the "distribution of article count per period varies significantly... [which] could bias the results."
  - **Why unresolved:** It is unclear if the detected shifts in later periods are genuine semantic changes or artifacts of the vastly higher resolution provided by the larger datasets.
  - **What evidence would resolve it:** Controlling for corpus size by downsampling the larger periods to match the smallest period and re-evaluating the stability of the linguistic shifts.

## Limitations
- Analysis limited to Croatian, where lemmatization quality directly impacts embedding coherence.
- Five-year temporal resolution may miss rapid semantic changes within periods.
- Sentiment transfer experiments rely on a single linear classifier and two datasets, limiting generalizability.

## Confidence
- **High:** Intrinsic embedding quality improvements (Spearman correlation increases from 0.48 to 0.56).
- **Medium:** Semantic shift quantification via cumulative shift scores, given strong correlation with curated topical evidence.
- **Low:** Sentiment analysis conclusions, as they contradict documented societal trends and depend on dataset-specific classifier behavior.

## Next Checks
1. **Corpus Bias Analysis:** Quantify coverage bias across the 33 news outlets and examine how outlet-specific framing affects semantic shift patterns.
2. **Cross-Lingual Validation:** Compare Croatian shift patterns with parallel diachronic studies in morphologically similar languages to assess language-specific vs. universal phenomena.
3. **Alternative Alignment Methods:** Implement non-orthogonal alignment (e.g., full linear Procrustes) to test whether the orthogonal constraint limits capture of extreme semantic divergence.