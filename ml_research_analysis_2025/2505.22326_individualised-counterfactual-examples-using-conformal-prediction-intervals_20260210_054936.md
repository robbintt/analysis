---
ver: rpa2
title: Individualised Counterfactual Examples Using Conformal Prediction Intervals
arxiv_id: '2505.22326'
source_url: https://arxiv.org/abs/2505.22326
tags:
- prediction
- counterfactual
- data
- conformal
- individual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for generating individualised
  counterfactual examples using conformal prediction intervals. The core idea is to
  model an individual's limited knowledge of a black-box classifier and generate counterfactuals
  that maximally reduce their prediction uncertainty.
---

# Individualised Counterfactual Examples Using Conformal Prediction Intervals

## Quick Facts
- arXiv ID: 2505.22326
- Source URL: https://arxiv.org/abs/2505.22326
- Reference count: 11
- Generates individualised counterfactuals that reduce prediction uncertainty based on user's limited knowledge

## Executive Summary
This paper introduces a novel method for generating individualised counterfactual examples using conformal prediction intervals. The approach models an individual's limited knowledge of a black-box classifier and generates counterfactuals that maximally reduce their prediction uncertainty. By combining proximity to the original instance with the width of conformal prediction intervals, the method produces examples that are both actionable and informative. Experiments on synthetic and real-world datasets demonstrate that these "conformal prediction interval counterfactuals" (CPICFs) can improve classification performance when used for data augmentation, particularly when training data is limited.

## Method Summary
The method combines conformal prediction intervals with counterfactual generation to create individualized explanations. It trains a regression model on the individual's limited dataset T(k) to predict class probabilities, then computes conformal prediction intervals using locally weighted conformal prediction (LWCP) or conditional quantile regression (CQR). The counterfactual generation problem is formulated as an optimization that minimizes a loss function balancing inverse interval width (information gain) and Gower distance from the original instance. A genetic algorithm solves this constrained optimization to find counterfactuals that flip the classifier's prediction while maximizing uncertainty reduction for the individual.

## Key Results
- CPICFs generated with appropriate λ tuning (1-100) lead to better average precision and F1 scores compared to unconstrained counterfactuals
- The method shows particular effectiveness when training dataset is small (Tabformer subset of 1K samples)
- Intermediate λ values balance proximity and uncertainty objectives, producing counterfactuals that improve both classification performance and individual knowledge
- Conformal prediction intervals effectively identify regions where additional information would be most valuable to an individual

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactuals generated in regions of high prediction uncertainty provide more information to an individual about the underlying classifier than those in low-uncertainty regions.
- Mechanism: The individual's knowledge is modeled as a classifier trained on a limited subset T(k) of training data. Conformal prediction intervals computed from this limited knowledge are wider where the individual has less information. By generating counterfactuals at points with wide intervals (high uncertainty), a single new labeled example can reduce prediction variance more than one placed in already-certain regions.
- Core assumption: The individual has access to model probabilities/scores for their subset T(k), not just labels.
- Evidence anchors:
  - [abstract] "Regions of feature space where the prediction interval is wide correspond to areas where the confidence in decision making is low, and an additional counterfactual example might be more informative to an individual."
  - [section 3.1] "We model the individual's knowledge of the classifier in the same way as we would model the original classifier hθ trained on T, but now trained on T(k)."
  - [corpus] Related work (Altmeyer et al. 2024, Lei & Candès 2021) uses conformal prediction for counterfactuals but assumes global models rather than individualized uncertainty.

### Mechanism 2
- Claim: Using regression on class probabilities with locally weighted conformal prediction (LWCP) provides finer-grained uncertainty estimates than binary conformal classification sets.
- Mechanism: Binary conformal prediction produces only three possible set types ({0}, {1}, {0,1}), offering coarse uncertainty quantification. By training a regression model to predict class probabilities and applying LWCP with locally weighted residuals R_i = |Y_i - μ̂(X_i)|/ρ̂(X_i), the method obtains continuous prediction interval widths that vary smoothly across feature space, enabling more targeted counterfactual placement.
- Core assumption: The regression model for probabilities is well-calibrated; the dispersion estimator ρ̂ captures local variability accurately.
- Evidence anchors:
  - [section 3.2] "For binary 0−1 classification these prediction sets provide a coarse quantification of uncertainty, as the only possible prediction sets are {0}, {0,1}, {1}. To provide a fine grained determination of uncertainty we use the probabilities pθ as determined by a classification model to create a regression model."
  - [section 4.1, Figure 3] Shows LWCP and CQR produce finer-grained uncertainty maps than binary conformal set size.
  - [corpus] Corpus shows limited direct comparison; related CCI methods (arXiv 2509.04112) also use conformal inference for counterfactuals but focus on treatment effect estimation.

### Mechanism 3
- Claim: Balancing proximity and uncertainty in the counterfactual loss (via λ parameter) produces examples that are both actionable and informative.
- Mechanism: The optimization objective argmin(L_info + λL_dist) trades off inverse interval width (information gain) against Gower distance from the original instance. Small λ prioritizes high-uncertainty regions; large λ produces nearby but potentially less informative counterfactuals. The paper finds intermediate λ values (1–100 depending on α) yield best knowledge improvement.
- Core assumption: There exists a λ regime where both objectives are meaningfully satisfied; the genetic optimizer finds good solutions within evaluation budget.
- Evidence anchors:
  - [section 3.4, Equation 6] Defines the combined loss function with λ tuning parameter.
  - [section 4.1.1, Figure 6] Shows λ = 1 and λ = 100 improve prediction probabilities (negative Δ), while λ = 0 (uncertainty only) or λ = 10⁵ (distance only) do not.
  - [corpus] DiCE (Mothilal et al. 2020) uses similar multi-objective formulation but with diversity rather than uncertainty.

## Foundational Learning

- Concept: **Conformal Prediction**
  - Why needed here: Core to quantifying individual uncertainty; provides distribution-free coverage guarantees for prediction intervals under exchangeability.
  - Quick check question: Given calibration scores S₁ ≤ S₂ ≤ ... ≤ Sₙ, what quantile defines a (1-α) prediction set for a new observation?

- Concept: **Counterfactual Explanations**
  - Why needed here: The target output; must understand that counterfactuals are input perturbations that flip model predictions, and that many valid counterfactuals typically exist per query.
  - Quick check question: Why might proximity alone be insufficient for selecting among multiple valid counterfactuals?

- Concept: **Gower Distance for Mixed Data**
  - Why needed here: Real-world tabular data (like Tabformer) contains both continuous and categorical features; standard L₁/L₂ distances don't handle categorical variables appropriately.
  - Quick check question: How does Gower distance normalize contributions from continuous vs. categorical features?

## Architecture Onboarding

- Component map:
  - Classification Model (h_θ) -> Individual's Model (p_{θ_k}) -> Dispersion Model (ρ̂) -> Conformal Interval Computation -> Counterfactual Optimizer

- Critical path:
  1. Extract p_θ(X_i) for all calibration points using the black-box classifier.
  2. Train individual's regression model p_{θ_k} on T(k) with targets = p_θ(X_i).
  3. Train dispersion model ρ̂ on residuals |Y_i - p_{θ_k}(X_i)|.
  4. Compute conformal intervals C_α(X) = [μ̂(X) - ρ̂(X)d_α, μ̂(X) + ρ̂(X)d_α].
  5. For query X, run genetic optimization to find X' minimizing L_info(X') + λL_dist(X, X') subject to h_θ(X) ≠ h_θ(X').

- Design tradeoffs:
  - LWCP vs. CQR: LWCP produces symmetric intervals (may be suboptimal near probability boundaries); CQR handles asymmetry but risks quantile crossing.
  - Calibration set size: Larger calibration sets improve interval reliability but reduce training data.
  - Genetic optimizer budget: 50 evaluations × 20 population is relatively low; may miss global optimum for complex feature spaces.

- Failure signatures:
  - All counterfactuals cluster in one region: Indicates single dominant uncertainty well; may need diversity constraints.
  - Negative interval widths (CQR): Quantile crossing; requires concurrent quantile training or fallback to LWCP.
  - No improvement after augmentation: λ mismatch with α; recalibrate using local evaluation framework (Equation 9).
  - Sparse feature changes: Method may modify many features (Table 2 shows 10+ changes); consider adding sparsity penalty.

- First 3 experiments:
  1. Reproduce hypercube visualization: Train on 60% of 30K samples, visualize LWCP interval widths across 2D feature space, confirm wider intervals near decision boundary and in sparse regions (compare to Figure 3).
  2. Ablate T(k) size: For fixed query points, vary individual dataset size (50, 100, 500 samples) and measure correlation between interval width reduction and classification improvement after counterfactual addition.
  3. Lambda sweep on held-out data: For Tabformer subset, grid search λ ∈ {0, 1, 10, 100, 1000, 10000} with α ∈ {0.1, 0.2}, evaluate average precision on temporal test split; verify intermediate λ regime outperforms extremes (Figure 7 pattern).

## Open Questions the Paper Calls Out
None

## Limitations
- The method assumes individuals have access to model probabilities/scores for their subset T(k), which may not hold in practice
- Empirical validation focuses on classification performance rather than actual user comprehension or trust metrics
- Genetic optimizer budget (50 evaluations × 20 population) may be insufficient for high-dimensional or highly constrained feature spaces

## Confidence
- **High confidence**: Mathematical formulation of conformal prediction intervals and their use for uncertainty quantification
- **Medium confidence**: Individual knowledge modeling approach and its practical applicability
- **Low confidence**: Claim that CPICFs improve human trust and transparency without direct user studies

## Next Checks
1. **User study on counterfactual comprehensibility**: Conduct controlled experiment where users with varying ML knowledge are shown both standard proximity-based counterfactuals and CPICFs, then tested on their ability to predict model behavior on new instances. Measure both accuracy and subjective confidence ratings.

2. **Sensitivity analysis to T(k) data quality**: Systematically vary quality and representativeness of individual training subsets T(k) by introducing label noise, class imbalance, and feature correlations. Evaluate how these perturbations affect interval width reliability and counterfactual informativeness.

3. **Cross-domain generalization test**: Apply CPICF method to non-tabular data (e.g., image or text classification) where uncertainty quantification is less straightforward. Compare performance against established counterfactual methods like DiCE or CEM in terms of both prediction improvement and feature modification sparsity.