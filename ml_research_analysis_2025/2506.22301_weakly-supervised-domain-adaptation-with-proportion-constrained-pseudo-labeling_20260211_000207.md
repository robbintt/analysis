---
ver: rpa2
title: Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling
arxiv_id: '2506.22301'
source_url: https://arxiv.org/abs/2506.22301
tags:
- domain
- target
- adaptation
- class
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses domain shift in medical imaging, where models
  trained on source domain data underperform when applied to target domains due to
  differing data distributions across institutions. Most domain adaptation methods
  struggle when class proportions differ between domains.
---

# Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling

## Quick Facts
- arXiv ID: 2506.22301
- Source URL: https://arxiv.org/abs/2506.22301
- Reference count: 33
- Key outcome: Proposed method achieves higher macro-F1 scores than semi-supervised domain adaptation techniques on endoscopic datasets using proportion-constrained pseudo-labeling

## Executive Summary
This paper addresses domain shift in medical imaging by proposing a weakly-supervised domain adaptation method that leverages known class proportions from target domains. The approach uses proportion-constrained pseudo-labeling to assign pseudo-labels to unlabeled target data, enabling effective adaptation without requiring extensive annotations. The method is particularly relevant for medical imaging scenarios where class proportions are commonly available but annotations are scarce.

## Method Summary
The proposed method addresses domain adaptation challenges by utilizing known class proportions from target domains to guide pseudo-label assignment. When source and target domains have different class distributions, traditional domain adaptation methods struggle. This approach constrains the pseudo-label assignment process to match the known target domain proportions, effectively creating a bridge between domains. The method works by generating pseudo-labels for target data while ensuring the resulting class distribution matches the known target proportions, thus avoiding the pitfalls of proportion mismatch between domains.

## Key Results
- Outperformed semi-supervised domain adaptation techniques on LIMUC and Private endoscopic datasets
- Achieved higher macro-F1 scores even with only 5% labeled target data
- Demonstrated robustness to noisy proportion labels in realistic scenarios

## Why This Works (Mechanism)
The method works by incorporating prior knowledge about target domain class distributions directly into the pseudo-label assignment process. By constraining the pseudo-label generation to match known proportions, the approach creates a more accurate representation of the target domain distribution. This constraint helps the model learn domain-invariant features that respect the actual class balance in the target domain, leading to better generalization. The proportion constraint acts as a regularizer that prevents the model from being misled by class imbalance when assigning pseudo-labels.

## Foundational Learning
- **Domain Adaptation**: Transferring knowledge from source to target domain; needed to handle distribution shifts in medical imaging across institutions; quick check: source and target data distributions differ
- **Pseudo-labeling**: Assigning labels to unlabeled data based on model predictions; needed to leverage abundant unlabeled target data; quick check: model confidence exceeds threshold
- **Class Proportion Information**: Prior knowledge of class distribution in target domain; needed to constrain pseudo-label assignment; quick check: available for target domain
- **Weak Supervision**: Learning with limited labeled data; needed to reduce annotation burden in medical imaging; quick check: few labeled samples available

## Architecture Onboarding

**Component Map**
Proportion-Constrained Pseudo-Labeling -> Domain Adaptation Module -> Classification Model

**Critical Path**
1. Extract features from target data using source-pretrained model
2. Apply proportion-constrained pseudo-labeling to unlabeled target data
3. Train adapted model using both labeled and pseudo-labeled data
4. Fine-tune with limited labeled target data

**Design Tradeoffs**
- Using proportion constraints vs. pure confidence-based pseudo-labeling
- Weak supervision (5% labels) vs. semi-supervised (more labels)
- Simple constraint enforcement vs. complex optimization

**Failure Signatures**
- Poor performance when proportion estimates are highly inaccurate
- Degraded results when source and target domain distributions are too dissimilar
- Limited effectiveness when class proportions are uniform across domains

**First Experiments**
1. Compare macro-F1 scores with and without proportion constraints on LIMUC dataset
2. Test robustness by varying noise levels in proportion labels
3. Evaluate performance degradation as labeled target data percentage decreases

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation limited to two endoscopic datasets, with one not publicly available
- Method effectiveness depends on availability of accurate class proportion information
- Limited comparison to diverse domain adaptation approaches beyond semi-supervised methods

## Confidence
- Method's viability and technical soundness: High confidence
- Performance superiority within experimental scope: High confidence
- Generalizability across medical imaging domains: Medium confidence

## Next Checks
1. Replicate experiments on additional publicly available medical imaging datasets from multiple hospitals or imaging modalities
2. Compare performance against a broader range of domain adaptation methods including fully unsupervised approaches
3. Conduct sensitivity analysis across different levels and patterns of proportion label noise to characterize performance bounds