---
ver: rpa2
title: 'Efficient extraction of medication information from clinical notes: an evaluation
  in two languages'
arxiv_id: '2502.03257'
source_url: https://arxiv.org/abs/2502.03257
tags:
- clinical
- drug
- extraction
- french
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a new transformer-based architecture for extracting
  medication information from clinical narratives. The method improves upon existing
  approaches by simultaneously classifying all relationships, significantly reducing
  computational cost while maintaining state-of-the-art accuracy.
---

# Efficient extraction of medication information from clinical notes: an evaluation in two languages

## Quick Facts
- arXiv ID: 2502.03257
- Source URL: https://arxiv.org/abs/2502.03257
- Reference count: 40
- Primary result: Transformer-based architecture achieves 0.82 F1 (French) and 0.96 F1 (English) for relation extraction while reducing training time by 10x

## Executive Summary
This study introduces a transformer-based architecture for extracting medication information from clinical narratives that improves computational efficiency while maintaining state-of-the-art accuracy. The method classifies all relationships simultaneously in a single forward pass, reducing training time by a factor of 10 compared to baseline approaches. Evaluated on both French and English clinical corpora, the approach achieves strong F1 scores for relation extraction (0.82 and 0.96) and demonstrates portability across languages by simply swapping the underlying transformer model.

## Method Summary
The architecture uses a transformer-based model (CamemBERT-BIO for French; ClinicalBERT/BioBERT for English) that classifies all relations simultaneously rather than processing entity pairs individually. It concatenates transformer token embeddings with learned label embeddings, processes all token pairs through shared dense and classification layers, and applies masked cross-entropy loss restricted to labeled token pairs. A sliding window approach (200-300 characters) manages computational complexity for long documents, with segments containing fewer than 2 entities excluded from training.

## Key Results
- Relation extraction F1 scores: 0.82 (French) and 0.96 (English)
- End-to-end performance: 0.69 F1 (French) and 0.82 F1 (English)
- Training time reduced by factor of 10 compared to baseline methods
- Frame-based annotation improved F1 by 1.4 points (0.821 vs 0.807)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simultaneous classification of all relations in a single forward pass reduces computational cost by 10–23x while maintaining competitive accuracy.
- Mechanism: The architecture concatenates token embeddings with dedicated entity label embeddings, then processes all token pairs through a shared dense + classification layer. This replaces the baseline approach of feeding each entity pair through the full transformer independently.
- Core assumption: Relation dependencies can be captured through self-attention over token representations without requiring per-pair transformer encodings.
- Evidence anchors:
  - [abstract] "significantly reducing computational cost while maintaining state-of-the-art accuracy... reducing training time by a factor of 10"
  - [section] "Our model depicted Figure 3 is designed to classify all relationships simultaneously... These token-pair representations are then processed through one dense layer followed by a classification layer"
  - [corpus] Related work on BERT-based relation extraction (Yang et al. 2021) confirms per-pair processing is standard; corpus signals do not contradict efficiency claims.
- Break condition: If documents contain many entities (>50) with long-range dependencies exceeding the sliding window, recall degrades due to missed cross-window relations.

### Mechanism 2
- Claim: Frame-based annotation captures complex temporal dependencies in medication regimens more precisely than flat drug-attribute links.
- Mechanism: A "frame" groups a drug with its specific attributes (dosage, frequency, route, duration) as a coherent unit. Multi-frame prescriptions—where the same drug has different attributes across time periods—are represented through multiple frames rather than ambiguous links.
- Core assumption: Relations among attributes within a frame provide useful signal; the model can leverage intra-frame relationships to improve extraction.
- Evidence anchors:
  - [abstract] Not explicitly mentioned; framing is a methodological contribution.
  - [section] "The integration of frame information led to an improvement in both precision and the global F1 score (0.821 vs. 0.807)... augmenting annotated data by adding relations between drug attributes could facilitate the extraction of multi-frame information"
  - [corpus] Corpus does not provide external validation of frame-based schemas; this appears novel to the paper.
- Break condition: When multi-frame prescriptions are rare (<5% in test set), the framing benefit is underutilized and performance gains are marginal.

### Mechanism 3
- Claim: Masked cross-entropy loss restricted to labeled token pairs enables efficient optimization for RE without sparse label noise.
- Mechanism: The loss function applies only to token pairs associated with entity labels, ignoring all other token combinations. This focuses gradient updates on relation-relevant pairs.
- Core assumption: Relations only occur between labeled entities; unlabeled token pairs provide no direct supervision signal for RE.
- Evidence anchors:
  - [abstract] Not explicitly described; operational detail in architecture.
  - [section] "During training, we optimize computation by applying a mask to the loss function, restricting its application to labeled token pairs, i.e. token associated with an entity label. The loss function employed is cross-entropy."
  - [corpus] Standard practice in relation extraction; corpus signals consistent but not confirmatory.
- Break condition: If the NER component misses entities in end-to-end mode, the masking will prevent the RE layer from learning relations involving those missed entities.

## Foundational Learning

- Concept: **Transformer-based Relation Extraction (pair-wise vs. joint)**
  - Why needed here: Understanding that baseline approaches process entity pairs individually through transformers (expensive) vs. this architecture's joint classification is essential to grasp the efficiency gain.
  - Quick check question: Given a sentence with 5 entities, how many forward passes does a pair-wise transformer classifier require? (Answer: up to 10 pairs; this architecture: 1 pass.)

- Concept: **Frame semantics in clinical NLP**
  - Why needed here: The paper's annotation schema departs from flat drug-attribute relations; understanding frames as coherent units clarifies how multi-frame prescriptions are represented.
  - Quick check question: If "aspirin 100mg daily from Jan–Mar, then 200mg twice daily from Apr–Jun" appears in a note, how many frames would represent this? (Answer: 2 frames—one per regimen period.)

- Concept: **Sliding window truncation for long documents**
  - Why needed here: The architecture uses a character-based sliding window (200–300 chars) to bound input length; this trade-off affects recall for long-range dependencies.
  - Quick check question: A modifier (e.g., a date) applies to multiple drugs across a 500-character span with window size 300. What happens? (Answer: Some relations may be missed if entities fall in different windows.)

## Architecture Onboarding

- Component map:
  Tokenizer + Pretrained Transformer (CamemBERT-BIO for French; ClinicalBERT/BioBERT for English) → contextual token embeddings
  Entity Label Embedding Layer → learnable embeddings for NER tag types
  Concatenation Layer → unified token representation (contextual + label)
  Multi-head Self-Attention → captures dependencies across tokens
  Token-pair Representation → concatenate token embeddings + relative position embeddings
  Dense + Classification Layer → multiclass relation prediction
  Masked Cross-Entropy Loss → applied only to labeled entity pairs

- Critical path:
  1. Input text + NER labels → tokenizer
  2. Transformer produces contextual embeddings
  3. Label embeddings concatenated to token embeddings
  4. Self-attention refines token representations
  5. Token pairs formed with relative position encoding
  6. Dense layer → relation classification
  7. Loss computed only on labeled pairs

- Design tradeoffs:
  - **Precision vs. Recall**: The proposed architecture shows higher precision but lower recall compared to pair-wise baselines (0.834 vs. 0.786 precision; 0.782 vs. 0.834 recall on French corpus).
  - **Window size**: Larger windows (300 vs. 200 chars) improve recall (+3 pts) at cost of longer sequences.
  - **Frame augmentation**: Adds annotation complexity but improves F1 (+1.4 pts); requires multi-frame-aware annotation guidelines.
  - **Language portability**: Changing languages requires only swapping the pretrained transformer; schema differences (e.g., Dosage/Strength merged in French vs. separate in n2c2) complicate direct comparison.

- Failure signatures:
  - **Low recall on modifiers spanning multiple drugs**: Dates or contexts applying to several drugs may fall outside window boundaries.
  - **Rare relation types underperform**: Classes with <15 examples (e.g., Contraindicated, Discontinue) show near-zero F1.
  - **End-to-end bottleneck**: NER errors propagate; overall end-to-end F1 (0.69 French, 0.82 English) is substantially lower than RE-only (0.82, 0.96).

- First 3 experiments:
  1. **Baseline replication on n2c2**: Train the proposed architecture on the English n2c2 training set with ClinicalBERT; compare RE-only F1 and training time against the reported baseline (Yang et al. 2021). Expect ~0.95 F1 with ~20× speedup.
  2. **Ablation on label embeddings**: Remove the entity label embedding layer and train with contextual embeddings only. Measure impact on precision/recall to confirm the auxiliary signal's contribution.
  3. **Window size sweep on French corpus**: Train with window sizes of 200, 300, 400, and 500 characters. Plot recall vs. training time to identify the knee point where longer windows yield diminishing returns.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the model better capture long-range dependencies for modifiers that apply to multiple drugs beyond the constraints of the sliding window?
  - Basis in paper: [inferred] The authors note that lower recall was "primarily attributed to the handling of modifiers that apply to multiple drugs" which "often extends beyond the boundaries of the sliding window," and suggest future research could explore this.
  - Why unresolved: The current implementation uses a fixed-size sliding window (e.g., 200 or 300 characters) for computational efficiency, which truncates the context necessary to link shared attributes to multiple distinct drug entities.
  - What evidence would resolve it: An architectural modification (e.g., hierarchical attention or sparse attention mechanisms) that demonstrates significantly improved recall on multi-drug modifier relationships compared to the current sliding window baseline.

- **Open Question 2**: To what extent does the frame-based representation improve performance on datasets with a high prevalence of complex, multi-frame prescriptions?
  - Basis in paper: [explicit] The authors state that "The limited presence of multi-frame prescriptions (less than 5%) in the test set, make it difficult to fully evaluate the impact of such representation."
  - Why unresolved: The study used a corpus primarily consisting of rheumatoid arthritis notes, which lacked sufficient examples of complex regimens (e.g., oncology) to validate the full utility of the proposed "frame" annotation schema.
  - What evidence would resolve it: Evaluation of the model on a larger corpus specifically curated to include a higher frequency of multi-frame scenarios, such as chemotherapy treatment notes.

- **Open Question 3**: What reconstruction algorithms are required to accurately assemble extracted medication information into coherent longitudinal patient timelines?
  - Basis in paper: [explicit] The Conclusion states that "Applying this algorithm to longitudinal data could enable the extraction of detailed medication timelines... However, the development of reconstruction algorithms is still required."
  - Why unresolved: The current study successfully extracts entities and relations from individual documents, but it does not address the subsequent challenge of linking these extractions across a patient's history to resolve temporal conflicts or gaps.
  - What evidence would resolve it: The development and validation of a post-processing pipeline that integrates extracted entities from multiple clinical notes into a unified therapeutic timeline, benchmarked against manual clinical review.

## Limitations

- **Language portability gap**: Direct F1 comparisons are confounded by corpus schema differences (French merges Dosage/Strength; English keeps separate).
- **Window-based recall ceiling**: 300-character sliding window creates hard recall ceiling for long-range dependencies.
- **Frame annotation complexity**: Frame-based schema shows modest improvement but requires substantial annotation effort and domain expertise.

## Confidence

- **High Confidence**: The simultaneous classification mechanism's computational efficiency claims (10-23x reduction in training time) are well-supported by the architectural description and comparison to standard pair-wise processing.
- **Medium Confidence**: The F1 score improvements (0.82-0.96) are reported for specific test sets with specific evaluation protocols, but exact reproduction requires assumptions about preprocessing.
- **Low Confidence**: The frame-based annotation's contribution to performance (+1.4 F1 points) is demonstrated on one corpus but lacks external validation and quantification of annotation burden.

## Next Checks

1. **Ablation Study on Label Embeddings**: Remove the entity label embedding layer and retrain on the n2c2 corpus. Compare precision/recall to confirm whether the auxiliary label signal provides measurable benefit beyond standard contextual embeddings.

2. **Window Size Sensitivity Analysis**: Systematically vary window sizes (200, 300, 400, 500 characters) on the French corpus. Plot recall vs. training time to quantify the efficiency-recall tradeoff and identify optimal window size for different clinical note lengths.

3. **Error Analysis by Relation Type**: Categorize RE errors by relation type frequency. Focus on rare relations (<15 examples) like Contraindicated/Discontinue to determine if the architecture's efficiency gains come at the cost of performance on clinically important but infrequent relationships.