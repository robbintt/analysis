---
ver: rpa2
title: High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent
  on Least Squares
arxiv_id: '2510.16687'
source_url: https://arxiv.org/abs/2510.16687
tags:
- noisy
- privacy
- hsgd
- risk
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops a continuous-time diffusion approximation for
  noisy stochastic gradient descent (SGD) to analyze both statistical risk and privacy
  loss in high-dimensional settings. The key innovation is the noisy Homogenized SGD
  (HSGD) process, which matches the statistical risk behavior of noisy SGD and enables
  precise characterization of its privacy dynamics.
---

# High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares

## Quick Facts
- **arXiv ID**: 2510.16687
- **Source URL**: https://arxiv.org/abs/2510.16687
- **Reference count**: 40
- **One-line result**: Develops diffusion approximation for noisy SGD that provides exact risk trajectories and closed-form privacy loss without gradient clipping

## Executive Summary
This paper develops a continuous-time diffusion approximation for noisy stochastic gradient descent (SGD) to analyze both statistical risk and privacy loss in high-dimensional settings. The key innovation is the noisy Homogenized SGD (HSGD) process, which matches the statistical risk behavior of noisy SGD and enables precise characterization of its privacy dynamics. For statistical risk, the paper shows that population risk concentrates around a deterministic trajectory governed by Volterra integral equations, providing the first exact characterization of this evolution rather than bounds. For privacy, it derives closed-form expressions for Rényi differential privacy loss under three release strategies (last iterate, multiple iterates, and average) by analyzing the exact law of the HSGD process.

## Method Summary
The paper develops a continuous-time diffusion approximation for noisy SGD on least squares regression. It scales discrete SGD iterations to continuous time via η_k = γ(k/d)/d and t = k/d, yielding an SDE with drift from the regularized population risk gradient and diffusion from sampling stochasticity and DP noise. This noisy HSGD process matches the statistical risk behavior of noisy SGD in high dimensions. The approach avoids explicit gradient sensitivity bounds or clipping by quantifying privacy loss through the distributional law of the process. The theory applies in high-dimensional regimes where sample size and dimension are comparable, making it relevant for modern overparameterized models.

## Key Results
- Noisy HSGD matches the statistical risk behavior of noisy SGD in high-dimensional regimes, with risk concentration around deterministic Volterra trajectories
- Closed-form expressions for Rényi differential privacy loss under three release strategies derived by analyzing the exact law of neighboring HSGD processes
- Avoids explicit gradient sensitivity bounds or clipping by quantifying privacy loss through the distributional law of the process
- Theory applies in high-dimensional regimes where sample size and dimension are comparable, relevant for modern overparameterized models

## Why This Works (Mechanism)

### Mechanism 1: High-Dimensional Risk Equivalence via Diffusion Scaling
- Claim: Noisy SGD and its continuous-time surrogate (noisy HSGD) have indistinguishable quadratic risk trajectories in high dimensions.
- Mechanism: Discrete SGD iterations are rescaled to continuous time via η_k = γ(k/d)/d and t = k/d. This yields an SDE with drift from the regularized population risk gradient and diffusion from both sampling stochasticity and DP noise. The quadratic risk discrepancy between the discrete and continuous processes vanishes as d → ∞.
- Core assumption: High-dimensional regime where n and d are comparable; spectral norm of Σ bounded independent of d; sub-Gaussian noise with ∥w∥ψ2 ≤ d^{c*} where c* < 1/24.
- Evidence anchors: [abstract] "noisy Homogenized SGD (HSGD) process, which matches the statistical risk behavior of noisy SGD"; [section 3, Theorem 3.1] Explicit bound: sup |q(x_k) - q(X_{k/d})| ≤ ∥q∥_{C²} e^{c₀n/(8d)} (d^{-1/2+9c*} + σ terms), vanishing as d → ∞

### Mechanism 2: Risk Concentration to Deterministic Volterra Trajectory
- Claim: Population risk concentrates around a deterministic curve characterized exactly by Volterra integral equations—not just bounded.
- Mechanism: The expected risk E[q(X_t)] decomposes into: (i) gradient flow contribution, (ii) sampling noise accumulated through martingale terms, (iii) injected DP noise. Each component is captured by kernel integrals G(t,s;M) and G'(t,s;M) in the Volterra equations. Concentration follows from controlling martingale fluctuations via Bernstein/Freedman inequalities.
- Core assumption: Same high-dimensional regime; bounded learning rate schedule γ(·); stopping time construction to control norm growth.
- Evidence anchors: [abstract] "population risk concentrates around a deterministic trajectory governed by Volterra integral equations, providing the first exact characterization"; [section 4.1, Theorem 4.1] Concentration bound: sup|q(X_t) - E[q(X_t)]| ≤ d^{-1/2+2c*} with probability ≥ 1 - c₂d^{-c₁}

### Mechanism 3: Privacy Quantification via Gaussian Process Law
- Claim: Rényi DP loss can be computed exactly without gradient clipping or explicit sensitivity bounds by analyzing the distributional law of neighboring HSGD processes.
- Mechanism: For datasets differing at a single point used in iteration ℓ (continuous time s = ℓ/d), the pre-update state X_{s⁻} is Gaussian. The differentiating update induces affine transformations C₁, C₂ with different shifts c₁, c₂, yielding post-update Gaussians with tractable mean/covariance. The state transition matrix Φ(t,s) = exp(-A(Γ(t)-Γ(s))) propagates this perturbation. Rényi divergence between the resulting Gaussians is computed in closed form.
- Core assumption: Conjecture 3.1 (Distributional Equivalence)—that finite-dimensional distributions of noisy SGD and HSGD converge as d → ∞.
- Evidence anchors: [abstract] "derives closed-form expressions for Rényi differential privacy loss under three release strategies... by analyzing the exact law of the HSGD process"; [section 4.2, Theorem 4.3] Equation (14) gives exact Rényi divergence formula

## Foundational Learning

- Concept: **Rényi Differential Privacy (RDP)**
  - Why needed here: The paper uses RDP (not (ε,δ)-DP) because it provides tighter composition for multiple iterations and admits closed-form Gaussian-to-Gaussian divergence formulas.
  - Quick check question: Given two Gaussians N(μ₁,Σ₁) and N(μ₂,Σ₂), can you write down the α-Rényi divergence formula?

- Concept: **Itô Stochastic Differential Equations**
  - Why needed here: The noisy HSGD is defined as an SDE dX_t = -γ(t)∇R(X_t)dt + γ(t)√(1/d)(2P(X_t)Σ + σ²I)dB_t. Understanding drift vs. diffusion terms is essential.
  - Quick check question: What does the quadratic variation [M]_t tell you about martingale concentration in this SDE?

- Concept: **Martingale Concentration (Bernstein/Freedman inequalities)**
  - Why needed here: The proofs decompose risk into predictable parts plus martingale increments, then apply stopping times and concentration to show fluctuations vanish in high dimensions.
  - Quick check question: Why introduce a stopping time τ := inf{k : ∥v_k∥ > d^α} in the analysis?

## Architecture Onboarding

- Component map: Discrete Noisy SGD -> Time Scaling Layer -> Noisy HSGD SDE -> Gradient Flow Baseline -> Volterra Risk Engine -> Neighboring Process Constructor -> Rényi Divergence Calculator

- Critical path: Start with Theorem 3.1 (risk equivalence) → Theorem 4.1 (concentration) → Theorem 4.2 (Volterra characterization) → Section 4.2 (privacy analysis). The conjecture in Section 3 bridges theory to practice.

- Design tradeoffs:
  - One-pass vs. multi-pass: One-pass enables exact analysis; multi-pass complicates privacy via record reuse
  - Clipping vs. distributional approach: Clipping bounds sensitivity but biases gradients; this approach avoids clipping by quantifying privacy through process law, but requires Gaussian dynamics
  - Release strategy: Last iterate has simpler analysis; averaged release may improve utility but requires computing cross-covariances

- Failure signatures:
  - Risk concentration degrades if c* (noise scale exponent) is not ≪ 1/24
  - Privacy guarantees rely on unproven distributional equivalence (Conjecture 3.1)
  - Non-quadratic losses: closed-form Volterra representation unavailable; may need smoothing or stationary-state analysis

- First 3 experiments:
  1. **Validate diffusion approximation**: Run noisy SGD with d=1000, n=1500; plot Mahalanobis QQ plot of final iterate vs. theoretical HSGD Gaussian law
  2. **Verify Volterra risk trajectory**: Compute P_t from Equation (6) numerically; compare against empirical risk curves across noise scales σ ∈ {1.0, 1.25, 1.5}
  3. **Benchmark privacy-utility tradeoff**: For fixed σ=1.5, compare HSGD-based Rényi loss against clipping-based bounds from prior work; plot both risk and privacy trajectories

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the finite-dimensional distributional equivalence between noisy SGD and noisy HSGD provably hold as dimension d → ∞?
  - Basis: Conjecture 3.1 states the finite-dimensional distributions converge, but this remains unproven despite empirical support.

- **Open Question 2**: Can the privacy-utility analysis be extended to multi-pass SGD with rigorous privacy guarantees under repeated data reuse?
  - Basis: Multi-pass training is "more straightforward on the risk side but subtler for privacy analysis" due to correlated differentiation events across epochs.

- **Open Question 3**: Do analogous diffusion approximations and closed-form privacy expressions exist for smooth (strongly) convex losses beyond least squares?
  - Basis: Smooth and strongly convex losses "should admit similar diffusion approximations, though the same closed-form Volterra representation may no longer be available."

- **Open Question 4**: Can the gap between the privacy loss of noisy SGD and its HSGD approximation be rigorously quantified?
  - Basis: A natural next step is to "theoretically quantify the gap between the privacy loss of SGD and that of HSGD, e.g., by proving that the laws of two processes are close."

## Limitations

- The distributional equivalence conjecture (Conjecture 3.1) remains unproven despite being critical for the exact privacy analysis.
- The theory is specifically tailored to least squares regression and may not extend directly to non-quadratic losses.
- The one-pass assumption simplifies privacy analysis but limits applicability to settings where data can be accessed only once.

## Confidence

- **High Confidence**: The risk concentration around deterministic Volterra trajectories (Theorems 4.1-4.2) and the validity of the diffusion approximation for quadratic risk (Theorem 3.1)
- **Medium Confidence**: The exact privacy loss formulas (Theorems 4.3-4.5) given the distributional equivalence assumption
- **Low Confidence**: The distributional equivalence conjecture itself due to limited empirical validation

## Next Checks

1. **Test distributional equivalence under stress conditions**: Run experiments with c* values approaching 1/24 and with n ≫ d to identify where the diffusion approximation breaks down.

2. **Validate privacy bounds on real data**: Apply the closed-form privacy analysis to a real-world dataset and compare the Rényi DP bounds against clipping-based methods.

3. **Explore non-quadratic extensions**: Test the Volterra-based risk analysis on logistic regression or other smooth convex losses to measure how quickly the Gaussian approximation degrades.