---
ver: rpa2
title: Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling
arxiv_id: '2511.20257'
source_url: https://arxiv.org/abs/2511.20257
tags:
- local
- transport
- physics-guided
- forecast
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes a physics-guided, interpretable-by-design
  framework for air pollution forecasting that achieves superior performance and clear
  spatiotemporal attributions. The model decouples pollutant concentration evolution
  into two transparent, additive modules: (1) a station-wise attention encoder for
  local dynamics, providing temporal-feature interpretability, and (2) a physics-guided
  transport kernel with wind-conditioned, directed weights for advection, yielding
  spatial interpretability.'
---

# Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling

## Quick Facts
- arXiv ID: 2511.20257
- Source URL: https://arxiv.org/abs/2511.20257
- Reference count: 23
- Primary result: Outperforms state-of-the-art baselines with 9.3% MAE and 14.0% MSE reduction

## Executive Summary
This study proposes a physics-guided, interpretable-by-design framework for air pollution forecasting that achieves superior performance and clear spatiotemporal attributions. The model decouples pollutant concentration evolution into two transparent, additive modules: (1) a station-wise attention encoder for local dynamics, providing temporal-feature interpretability, and (2) a physics-guided transport kernel with wind-conditioned, directed weights for advection, yielding spatial interpretability. Evaluated on a comprehensive Stockholm dataset, the model consistently outperforms state-of-the-art baselines (e.g., Airformer, AirPhyNet, Crossformer, iTransformer, and Transformer) across 24-, 48-, and 72-hour horizons, reducing MAE by 9.3% and MSE by 14.0% on average. Case studies confirm that spatial attributions align with observed wind patterns, demonstrating both predictive accuracy and physically meaningful interpretability. This framework offers a reliable, transparent foundation for operational air-quality management.

## Method Summary
The framework decomposes spatiotemporal pollutant behavior into two additive modules: a station-wise interpretable attention encoder for local temporal dynamics and a physics-guided transport kernel for advection-driven spatial interactions. The model uses learnable queries in attention to enable temporal-feature attribution, while wind-conditioned adjacency scores with upwind masking ensure physically meaningful spatial aggregation. A gated fusion combines local and transported representations for final forecasting. The approach is validated on Stockholm PM10 data across 24-, 48-, and 72-hour horizons, consistently outperforming state-of-the-art baselines.

## Key Results
- Achieves 9.3% MAE reduction and 14.0% MSE reduction over state-of-the-art baselines
- Demonstrates physically consistent spatial attributions that align with wind patterns
- Provides interpretable temporal-feature attributions through learnable attention queries
- Validates effectiveness across 24-, 48-, and 72-hour forecasting horizons

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoupling pollutant evolution into advection and local-dynamics modules improves both accuracy and interpretability.
- **Mechanism:** The model enforces an additive decomposition where each forecast is the sum of (a) wind-driven transport from upwind stations and (b) site-specific temporal responses learned via attention. This aligns with the advection–diffusion–reaction formulation where non-local transport dominates inter-station interactions.
- **Core assumption:** Urban PM10 transport between monitoring sites is primarily governed by advection along the wind field, while emissions, chemistry, and mixing operate locally.
- **Evidence anchors:** Abstract mentions "decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules"; Section III.B, Eq. 3 provides explicit decomposition; Spatiotemporal Causal Decoupling Model for Air Quality Forecasting validates decoupling as an emerging strategy.

### Mechanism 2
- **Claim:** Physics-guided, wind-conditioned adjacency enforces physically meaningful spatial attribution.
- **Mechanism:** A dynamic adjacency score combines wind alignment, speed, and distance decay. An upwind mask zeroes out non-upwind contributions before softmax normalization, ensuring transport only originates from meteorologically valid sources.
- **Core assumption:** Advection is directional; pollutants travel downwind, and the binary upwind condition correctly identifies source–target relationships.
- **Evidence anchors:** Section IV.C, Eq. 10–13 detail wind alignment score, physics-guided adjacency, and upwind masking; Section V.D, Fig. 4 shows spatial attributions shift correctly when wind changes; no directly comparable physics-guided adjacency validation in neighbors.

### Mechanism 3
- **Claim:** Learnable queries in station-wise attention provide interpretable temporal-feature attribution.
- **Mechanism:** Unlike standard self-attention, queries are learned positional encodings representing forecast targets. The resulting attention maps directly attribute each future patch to historical lag and covariate tokens, shared across all stations for generalization.
- **Core assumption:** A shared attention mechanism can capture universal local temporal dynamics across heterogeneous monitoring sites.
- **Evidence anchors:** Section IV.B, Eq. 6–9 show query construction and attention computation; Section V.D, Fig. 4b confirms attention identifies past PM10, pressure, and precipitation as most influential; X2-attention mechanism is referenced but lacks independent validation.

## Foundational Learning

- **Advection–diffusion–reaction PDE (Eq. 2)**
  - **Why needed here:** The model's decoupling strategy is derived from physical scale separation in this governing equation.
  - **Quick check question:** Can you explain why advection is separated from diffusion and reaction terms in this context?

- **Attention mechanism with learnable queries**
  - **Why needed here:** Interpretable attribution relies on understanding how queries, keys, and values interact beyond standard self-attention.
  - **Quick check question:** How do learnable queries differ from data-derived queries in standard transformers?

- **Softmax normalization over masked adjacency**
  - **Why needed here:** Spatial aggregation uses masked softmax to convert physics-guided scores into valid mixing weights.
  - **Quick check question:** What happens to the gradient if all upwind mask entries for a target station are zero?

## Architecture Onboarding

- **Component map:** Input tokenization -> station-wise attention encoder -> physics-guided transport kernel -> gated fusion -> forecast patches

- **Critical path:** Input tokenization → attention context G → spatial aggregation C_nb → gated fusion → forecast patches. The physics-guided module refines local representations; both paths must remain consistent.

- **Design tradeoffs:**
  - Patch length (P=12h): Longer patches reduce sequence length but may obscure fine-grained patterns
  - Learnable residual adjacency U: Adds flexibility but risks learning spurious correlations if physics prior is weak
  - Shared attention weights: Improves generalization but may underfit heterogeneous sites

- **Failure signatures:**
  - All-zero upwind masks for a station → transport module contributes nothing; check wind data coverage
  - Attention weights uniform across lags → query initialization may need adjustment or longer training
  - Spatial attributions contradict wind direction → ε margin may be misconfigured or wind data noisy

- **First 3 experiments:**
  1. **Ablation on transport module:** Run with U=0 and with full physics-guided adjacency; compare MAE/MSE and inspect spatial attributions for physical consistency
  2. **Patch length sensitivity:** Test P ∈ {6, 12, 24} hours; evaluate tradeoff between forecast granularity and attribution clarity
  3. **Station heterogeneity analysis:** Separate roadside vs. background stations; examine if shared attention weights produce systematically different temporal attributions

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the "local dynamics" module effectively capture non-local chemical reactions necessary for forecasting secondary pollutants like Ozone (O3)?
- **Basis in paper:** The governing equation explicitly includes a reaction term R(c, χ), but the model treats it as a station-wise "local" process. The framework was validated solely on PM10, which behaves primarily as a transport-driven inert tracer, unlike photochemical pollutants.
- **Why unresolved:** It is uncertain if the station-wise attention mechanism can model the non-local, non-linear chemical coupling that occurs between pollutants in the atmosphere, or if this requires an explicit spatial reaction term in the architecture.
- **What evidence would resolve it:** Evaluation of the model on datasets containing chemically reactive species (e.g., O3, NO2) to determine if the local decoder can learn these interactions without explicit physics constraints.

### Open Question 2
- **Question:** Does the computation of dense spatial weights Wsp limit the model's scalability to large-scale, dense sensor networks?
- **Basis in paper:** The spatial aggregation computes a dynamic weight matrix Wsp_m ∈ ℝ^(S×S) for every forecast step, yet the experimental validation was restricted to a small network of only 9 stations.
- **Why unresolved:** The quadratic complexity O(S²) of the transport kernel may introduce computational bottlenecks and over-smoothing issues when applied to city-wide networks with hundreds or thousands of sensors.
- **What evidence would resolve it:** Complexity analysis and latency benchmarks on datasets with significantly larger station counts (S > 100) compared to efficient sparse GNN baselines.

### Open Question 3
- **Question:** Can the simplified distance-decay transport kernel generalize to urban environments with complex topographies or street canyons?
- **Basis in paper:** The physics-guided kernel relies on a rectified alignment score and a squared distance penalty, which assumes relatively unobstructed wind flow.
- **Why unresolved:** While effective in Stockholm, this formulation may fail to capture the turbulent advection and channeling effects present in high-density urban street canyons or complex terrains where wind fields deviate significantly from Euclidean distance assumptions.
- **What evidence would resolve it:** Testing the model in cities with complex geometries (e.g., Hong Kong or Seoul) and analyzing the learned residual adjacency U to see if it compensates for the simplified physics by learning static barriers.

## Limitations
- Model generalizability across cities with different urban geometries and meteorological regimes remains uncertain
- Several critical hyperparameters are unspecified, potentially affecting reproducibility and performance
- Physics prior strength validation is incomplete, with unclear balance between physical constraints and model flexibility

## Confidence
- **High confidence** in predictive performance claims: Supported by extensive baseline comparisons across three forecast horizons
- **Medium confidence** in interpretability claims: Validation relies primarily on qualitative case studies rather than systematic quantitative metrics
- **Medium confidence** in generalizability: Limited evaluation to one city and specific pollutant suggests caution when extrapolating

## Next Checks
1. **Cross-city transferability test:** Apply the pre-trained Stockholm model to another city's air quality network without retraining. Measure performance degradation and compare spatial attribution consistency with local wind patterns.

2. **Physics constraint ablation study:** Systematically vary the strength of physics guidance by interpolating between pure physics-based adjacency (U=0) and learned-only adjacency (ε→∞, no masking). Quantify the tradeoff between physical interpretability and predictive accuracy.

3. **Heterogeneous station sensitivity analysis:** Train separate models for homogeneous station groups (roadside vs. background sites) and compare interpretability metrics. Measure whether shared attention weights produce systematically different temporal attributions across station types.