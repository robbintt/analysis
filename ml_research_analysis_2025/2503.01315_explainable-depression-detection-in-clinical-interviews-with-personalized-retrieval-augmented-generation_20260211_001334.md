---
ver: rpa2
title: Explainable Depression Detection in Clinical Interviews with Personalized Retrieval-Augmented
  Generation
arxiv_id: '2503.01315'
source_url: https://arxiv.org/abs/2503.01315
tags:
- depression
- query
- participant
- detection
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RED, a retrieval-augmented generation framework
  for explainable depression detection in clinical interviews. RED retrieves evidence
  from interview transcripts and uses personalized queries and social intelligence
  enhancement to improve interpretability.
---

# Explainable Depression Detection in Clinical Interviews with Personalized Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2503.01315
- Source URL: https://arxiv.org/abs/2503.01315
- Authors: Linhai Zhang; Ziyang Gao; Deyu Zhou; Yulan He
- Reference count: 40
- Primary result: Macro F1 score of 90.00% on DAIC-WoZ dataset

## Executive Summary
This paper introduces RED, a retrieval-augmented generation framework for explainable depression detection in clinical interviews. The system addresses hallucination in LLM-based explanations by retrieving evidence from interview transcripts before generating predictions. RED combines personalized query generation, adaptive evidence retrieval, and social intelligence knowledge enhancement to achieve superior interpretability and performance compared to neural network and LLM baselines.

## Method Summary
RED is a retrieval-augmented generation framework that detects depression from clinical interview transcripts while providing explainable evidence. The system first infers user profiles from transcripts, then generates personalized queries for each of the 8 PHQ-8 depression aspects. It retrieves relevant evidence chunks from the interview using dense embeddings, iteratively checking sufficiency with an LLM judge module. The framework extracts event triplets from dialogue, retrieves relevant psychological knowledge from COKE knowledge base, and performs final assessment using an LLM. The approach avoids hallucination by grounding predictions in retrieved evidence rather than post-hoc generation.

## Key Results
- Achieves macro F1 score of 90.00% on DAIC-WoZ dataset
- Outperforms neural network and LLM baselines in both performance and interpretability
- Personalized query generation and social intelligence enhancement provide measurable improvements
- Effective threshold calibration from PHQ-8 score 10 to 8 with knowledge augmentation

## Why This Works (Mechanism)

### Mechanism 1: Retrieval-Grounded Explanation Prevents Hallucination
RED retrieves actual transcript segments as evidence before prediction, using these verbatim snippets as the factual basis for both prediction and explanation. This approach ensures the system uses reliable, relevant snippets, avoiding irrelevant content and improving precision. The retrieved snippets serve as explanations, reducing hallucination compared to post-hoc LLM generation.

### Mechanism 2: Personalized Query Generation Improves Retrieval Relevance
The system uses an LLM to infer user profiles from dialogue, then generates personalized PHQ-8-aligned questions. This tailoring is effective because depression manifests differently across backgrounds. Using a single query for all participants may lead to suboptimal results, while personalized queries retrieve more relevant evidence.

### Mechanism 3: Social Intelligence Knowledge Augmentation Compensates for LLM Gaps
RED extracts event triplets (subject, predicate, object) from dialogue, encodes them into Gaussian embeddings, and retrieves relevant cognitive chains from COKE knowledge base. This compensates for LLMs' documented weaknesses in social reasoning and psychological understanding, enhancing judgment particularly in predicting the depressed class.

## Foundational Learning

- **Retrieval-Augmented Generation (RAG)**: Core architecture pattern for understanding when retrieval helps (grounding, window extension) vs. when it's overhead. Quick check: Can you explain why RAG reduces hallucination compared to direct LLM prompting?

- **PHQ-8 Questionnaire Structure**: System retrieves evidence per-aspect; understanding the 8 symptom domains is essential for debugging retrieval quality. Quick check: What score threshold distinguishes depression from control in PHQ-8?

- **Event Extraction & Representation**: Social intelligence enhancement depends on extracting (subject, predicate, object) triplets and encoding them for similarity search. Quick check: How does event-centric retrieval differ from direct text similarity search?

## Architecture Onboarding

- **Component map**: Input: Clinical interview transcript → Profile Inference (LLM) → Personal Query Generator (LLM) → Evidence Retriever (dense embeddings, L2 distance) → adaptive loop with Judge module → Event Extractor (LLM) → Event Encoder (MORE-CL, Gaussian embeddings) → Knowledge Retriever (COKE KB) → Final Assessment (LLM) → Output: Depression label + PHQ-8 scores + retrieved evidence

- **Critical path**: Transcript → Profile → Personal Query → Evidence Retrieval (iterative with Judge) → Event Extraction → Knowledge Retrieval → Final Assessment. If any upstream component fails (bad profile, missed evidence), downstream quality degrades.

- **Design tradeoffs**: Dense vs. sparse retrieval (authors chose dense for semantic matching); Fixed vs. adaptive retrieval (adaptive adds compute but handles variable transcript depth); Single modality (text) sacrifices audio/video signals for privacy and simplicity.

- **Failure signatures**: Low recall on "depressed" class with high "control" accuracy → check if retrieval is finding symptom-related evidence or missing key utterances; Evidence extraction precision drops → LLM may be hallucinating events; Disagreement between predicted and actual PHQ-8 subscores → check if certain aspects (e.g., appetite, movement) are underrepresented in transcripts.

- **First 3 experiments**: 1) Ablate personal query generation: Compare RED vs. Naive RAG to isolate personalization benefit (Table 2 shows ~2-4 point F1 gain); 2) Ablate social intelligence enhancement: Compare with/without COKE retrieval to measure knowledge augmentation contribution; 3) Error analysis on near-threshold cases (PHQ-8 ≈ 10): Examine where RED succeeds vs. fails on ambiguous diagnoses.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can RED's retrieval-based explainable detection framework be effectively extended to multimodal settings by integrating audio and video evidence alongside text transcripts? The limitations section states future work should explore the potential for explainable depression detection using multimodal data, integrating other modalities to improve the system's performance and robustness.

- **Open Question 2**: How can the framework's threshold calibration (from PHQ-8 score 10 to 8 with social intelligence enhancement) be systematically determined rather than manually adjusted? The paper notes that calibration brings significant improvement by adjusting the threshold from 10 to 8, but provides no principled methodology for determining optimal thresholds across different populations or interview contexts.

- **Open Question 3**: How does RED's performance and explanation quality generalize to non-clinical settings such as early depression detection from social media posts? The limitations section states the proposed method may not be easily transferred to other important settings, such as detecting early signs of depression from social media posts, due to significant differences in data structure, task format, and judgment criteria.

- **Open Question 4**: How robust is RED's personalized query generation to biases in LLM-inferred user profiles, particularly regarding demographic factors such as age, gender, or ethnicity? The ethical impact section states we must carefully monitor the model's outputs to ensure fairness and continuous efforts should be made to detect and mitigate any bias in the system.

## Limitations
- Results are based solely on the DAIC-WoZ dataset with 189 participants, limiting generalizability to diverse clinical populations
- The adaptive retrieval mechanism depends on subjective LLM-based judgment of "sufficiency" without clear operational definitions
- Reliance on COKE knowledge base introduces uncertainty about generalization to real-world clinical settings where patient contexts may differ

## Confidence

- **High Confidence**: Retrieval-grounded explanation mechanism effectively reduces hallucination compared to post-hoc LLM generation
- **Medium Confidence**: Personalized query generation provides meaningful improvement over generic queries in depression detection
- **Medium Confidence**: The overall architecture demonstrates superior performance compared to neural network and LLM baselines on DAIC-WoZ

## Next Checks
1. Cross-Dataset Validation: Test RED on independent depression detection datasets (e.g., AViD-Corpus, DAIC-PTSD) to verify performance consistency across different clinical interview protocols and patient populations.

2. Knowledge Base Dependency Analysis: Systematically evaluate RED's performance with and without COKE knowledge retrieval across varying transcript complexities to quantify the true contribution of social intelligence enhancement.

3. Error Pattern Investigation: Conduct detailed error analysis on near-threshold cases (PHQ-8 scores 8-12) and false negatives to identify systematic failure modes in the retrieval and assessment pipeline.