---
ver: rpa2
title: 'From Reasoning to Generalization: Knowledge-Augmented LLMs for ARC Benchmark'
arxiv_id: '2505.17482'
source_url: https://arxiv.org/abs/2505.17482
tags:
- image
- kaar
- input
- output
- priors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates reasoning-oriented large language models (LLMs)
  on the Abstraction and Reasoning Corpus (ARC) benchmark, which tests abstract reasoning
  and generalization using minimal training examples. We formulate ARC as program
  synthesis and propose nine solvers that differ in generation strategies, modalities,
  and solution representations.
---

# From Reasoning to Generalization: Knowledge-Augmented LLMs for ARC Benchmark

## Quick Facts
- arXiv ID: 2505.17482
- Source URL: https://arxiv.org/abs/2505.17482
- Authors: Chao Lei; Nir Lipovetzky; Krista A. Ehinger; Yanchuan Chang
- Reference count: 40
- Primary result: KAAR achieves ~5% absolute gains and up to 64.52% relative improvement over RSPC baseline

## Executive Summary
This study evaluates reasoning-oriented large language models (LLMs) on the Abstraction and Reasoning Corpus (ARC) benchmark, which tests abstract reasoning and generalization using minimal training examples. We formulate ARC as program synthesis and propose nine solvers that differ in generation strategies, modalities, and solution representations. Experimental results show that repeated-sampling planning-aided code generation (RSPC) achieves the highest test accuracy across most LLMs. To further improve performance, we introduce Knowledge Augmentation for Abstract Reasoning (KAAR), which encodes core knowledge priors within a hierarchical ontology and progressively augments LLMs at each level, applying RSPC after each augmentation stage. KAAR maintains strong generalization and consistently outperforms non-augmented RSPC across all evaluated LLMs, achieving around 5% absolute gains and up to 64.52% relative improvement. Despite these gains, ARC remains challenging for current reasoning-oriented LLMs.

## Method Summary
The paper formulates ARC as a program synthesis task where LLMs generate Python code to map input 2D grids to output grids. The core approach involves two main components: RSPC (Repeated-Sampling Planning-aided Code generation) as the baseline solver, and KAAR (Knowledge Augmentation for Abstract Reasoning) as the enhancement. RSPC generates a text-based solution plan from the problem description, then uses that plan to guide Python code generation, validating solutions on training instances. KAAR progressively augments LLMs with core knowledge priors organized in a three-level hierarchy (objectness, geometry/topology/numbers/counting, goal-directedness), invoking RSPC after each stage. The system iterates through different image abstractions (from simple to complex) and applies staged knowledge injection to prevent context interference.

## Key Results
- KAAR consistently outperforms RSPC baseline across all evaluated LLMs
- KAAR achieves approximately 5% absolute gains in test accuracy
- Up to 64.52% relative improvement over non-augmented RSPC
- RSPC (repeated-sampling planning-aided code generation) achieves highest test accuracy across most LLMs
- Both RSPC and KAAR performance degrades significantly on images larger than 20x20 pixels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical, staged knowledge augmentation improves abstract reasoning by reducing context interference
- Mechanism: KAAR organizes core knowledge priors into a three-level dependency hierarchy and progressively augments the LLM with priors at each level, invoking the RSPC solver backbone after each stage rather than presenting all priors simultaneously
- Core assumption: LLMs struggle to reason effectively when overwhelmed with all relevant knowledge priors at once; they perform better when reasoning is scaffolded incrementally
- Evidence anchors: [abstract] "This stage-wise reasoning reduces interference from irrelevant priors and improves LLM performance"; [section 4] "This progressive augmentation enables LLMs to gradually expand their reasoning capabilities and facilitates stage-wise reasoning"

### Mechanism 2
- Claim: Program synthesis via planning-aided code generation yields better generalization on ARC than direct code or plan generation
- Mechanism: The Repeated-Sampling Planning-aided Code generation (RSPC) solver first generates a text-based solution plan from the problem description and then uses that plan to guide the generation of Python code
- Core assumption: Decomposing program synthesis into planning and then coding encourages the model to identify a generalizable rule before implementing it
- Evidence anchors: [abstract] "Experimental results show that repeated-sampling planning-aided code generation (RSPC) achieves the highest test accuracy across most LLMs"; [Table 1] RSPC shows highest accuracy for GPT-o3-mini, Gemini-2.0, and DeepSeek-R1-70B

### Mechanism 3
- Claim: Abstracting images into object-centric representations enables more effective reasoning for certain task categories
- Mechanism: KAAR uses predefined abstraction methods to convert images into structured representation of objects with attributes and relations, directing LLM's attention to salient features and reducing noise from irrelevant pixels
- Core assumption: ARC tasks are fundamentally object-oriented, and LLMs' native "objectness" reasoning is insufficient or unreliable on raw pixel grids
- Evidence anchors: [Figure 7] "KAAR consistently outperforms RSPC on problems with average image sizes below 400, benefiting from object-centric representations"; [corpus] "ARC Is a Vision Problem!" argues for vision-centric approach

## Foundational Learning

- **Concept: Abstraction and Reasoning Corpus (ARC)**
  - **Why needed here:** ARC is the central benchmark. Understanding its design—novel tasks, few training examples, and grounding in core human cognitive priors—is essential to grasp why this paper's approach is structured the way it is
  - **Quick check question:** Can you explain why ARC is considered a test of generalization rather than a pattern-matching benchmark?

- **Concept: Program Synthesis**
  - **Why needed here:** The paper formulates ARC as a program synthesis task. Instead of outputting an image, the model generates a Python program that produces the output image from the input. All proposed solvers are variants of this core idea
  - **Quick check question:** What is the fundamental goal of the program generated by the LLM in this framework?

- **Concept: Core Knowledge Priors**
  - **Why needed here:** The KAAR method is explicitly built around augmenting LLMs with these priors (objectness, geometry, etc.). Understanding their definition and their role as the assumed basis for solving ARC tasks is critical
  - **Quick check question:** What are the four primary categories of core knowledge priors described in the paper?

## Architecture Onboarding

- **Component map:** Raw 2D matrices → Abstraction Module → Hierarchical Augmentation (Objectness → Geometry/Topology/Numbers → Goal-directedness) → RSPC Solver Backbone → Final Python program

- **Critical path:** The correct sequence is crucial. You cannot apply goal-directedness priors before objectness priors because the former depend on the components identified by the latter. The path is strictly: Abstraction -> Objectness Augmentation -> Solver -> (if fail) Geometric/Topological/Number Augmentation -> Solver -> (if fail) Goal-directedness Augmentation -> Solver

- **Design tradeoffs:**
  - Staged vs. All-at-once Augmentation: The paper's ablation study shows that augmenting all priors at once lowers accuracy. The tradeoff is increased API calls and latency for better performance
  - Token Cost: KAAR significantly increases token usage. The paper notes augmentation tokens can be ~60% of the solver backbone's usage on GPT-o3-mini
  - Abstraction Complexity: Starting with simple abstractions is faster but may fail. Iterating to more complex ones increases the chance of finding a solution but also computational cost

- **Failure signatures:**
  - Overfitting to Training Instances: A solution passes all training pairs but fails on the test pair
  - Incorrect Abstraction Selection: If KAAR selects a simpler abstraction that solves the training set but is incorrect for the general rule, it will fail on the test set and not try the correct, more complex one
  - Failure on Large Images: Both RSPC and KAAR performance degrades significantly on images larger than 20x20 pixels due to attention challenges and component complexity

- **First 3 experiments:**
  1. Reproduce RSPC Baseline: Implement the RSPC solver on a subset of the ARC public evaluation set to establish a baseline accuracy using the same LLMs
  2. Ablation on Staged Augmentation: Run KAAR and a modified KAAR* (which applies all priors at once) and compare their accuracies to confirm the benefit of the hierarchical, staged approach
  3. Analyze Abstraction Selection: Manually inspect a sample of failed cases to identify if "incorrect abstraction selection" is a primary cause

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What underlying architectural or algorithmic differences cause reasoning-oriented LLMs to vary significantly in generalization capabilities when applied to different ARC solvers?
- Basis in paper: [explicit] The authors note in the Discussion (Section 6) that "LLMs differ in their generalization across ARC solvers" and state that "investigating the underlying causes... presenting a promising direction for future work"
- Why unresolved: The study evaluates performance empirically but does not conduct mechanistic analysis to explain why specific models like GPT-o3-mini generalize better than DeepSeek-R1-70B across planning-aided vs. standalone generation strategies
- What evidence would resolve it: A comparative analysis of internal attention mechanisms or reasoning traces that correlates specific model features with the ability to avoid overfitting to training instances

### Open Question 2
- Question: Can LLMs be trained or prompted to infer the correct visual abstraction (e.g., 4-connected vs. 8-connected) directly from few-shot examples without relying on exhaustive search?
- Basis in paper: [inferred] In the Limitations (Section A.12), the authors note that current models rely on iteration because "accurate abstraction inference often requires validation through viable solutions, thereby shifting the challenge back to solution generation"
- Why unresolved: KAAR currently iterates through abstractions from simplest to most complex (brute-force) because prompting LLMs to select abstractions directly from raw matrices remains "unsatisfactory"
- What evidence would resolve it: A model capable of predicting the correct abstraction taxonomy with high accuracy prior to code generation, reducing the need for sequential execution

### Open Question 3
- Question: Can fine-tuning or reinforcement learning enforce adherence to core knowledge priors more effectively than the prompting-based augmentation used in KAAR?
- Basis in paper: [explicit] The authors state in the Limitations (Section A.12) that KAAR "lacks mechanisms to enforce LLM adherence to these priors during reasoning" and suggest future work could explore these training methods
- Why unresolved: The current system relies on structured prompting, which cannot guarantee the model utilizes the provided ontological constraints during its internal reasoning process
- What evidence would resolve it: Experiments demonstrating that a fine-tuned model generates solutions that strictly obey the hierarchical ontology with lower token overhead than the prompting approach

## Limitations
- The paper's claims about hierarchical knowledge augmentation improving generalization are moderately well-supported by ablation comparisons but the underlying mechanism remains largely theoretical
- The program synthesis approach via planning-aided code generation shows strong empirical results, but the claim that this decomposition inherently enforces better generalization lacks controlled comparisons with alternative strategies
- The object-centric abstraction mechanism is supported by performance differences on image size categories, but causation is not established
- KAAR significantly increases token usage, with augmentation tokens comprising up to 60% of the solver backbone's usage on some models
- Both RSPC and KAAR performance degrades significantly on images larger than 20x20 pixels

## Confidence

- **High confidence**: KAAR outperforms RSPC baseline across all tested LLMs (5% absolute gains, up to 64.52% relative improvement)
- **Medium confidence**: Staged hierarchical augmentation is superior to simultaneous augmentation (supported by ablation but mechanism explanation is theoretical)
- **Medium confidence**: Planning-aided code generation enables better generalization than direct code generation (supported by accuracy but lacks comparative program synthesis studies)
- **Low confidence**: Object-centric abstraction directly improves LLM object reasoning capability (performance correlation exists but causation not established)

## Next Checks

1. **Isolation experiment**: Run KAAR with staged augmentation but inject random/irrelevant priors at each stage to test whether performance degrades, confirming that the staged approach specifically reduces interference from irrelevant knowledge

2. **Alternative synthesis comparison**: Implement a direct code generation baseline without the planning step and compare generalization performance on identical tasks to test whether the planning decomposition is the key differentiator

3. **Component analysis**: For failed cases where KAAR selected a simpler abstraction that solved training but failed test instances, manually verify whether the more complex abstraction would have succeeded, quantifying the false positive rate of early abstraction selection