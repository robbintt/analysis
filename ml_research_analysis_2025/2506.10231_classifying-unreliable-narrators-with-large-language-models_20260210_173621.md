---
ver: rpa2
title: Classifying Unreliable Narrators with Large Language Models
arxiv_id: '2506.10231'
source_url: https://arxiv.org/abs/2506.10231
tags:
- narrator
- unreliable
- unreliability
- narrators
- narrative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the task of automatically classifying unreliable\
  \ narrators in first-person narratives. The authors propose using definitions from\
  \ narratology to identify three forms of unreliability: intra-narrational (verbal\
  \ tics), inter-narrational (contradictions from other characters or changes over\
  \ time), and inter-textual (fitting unreliable character tropes like madman or p\xED\
  caro)."
---

# Classifying Unreliable Narrators with Large Language Models

## Quick Facts
- arXiv ID: 2506.10231
- Source URL: https://arxiv.org/abs/2506.10231
- Authors: Anneliese Brei; Katharine Henry; Abhisheik Sharma; Shashank Srivastava; Snigdha Chaturvedi
- Reference count: 33
- Primary result: Introduces automated classification of unreliable narrators using LLM approaches with modest performance across intra-narrational, inter-narrational, and inter-textual reliability types

## Executive Summary
This paper presents the novel task of automatically identifying unreliable narrators in first-person narratives using large language models. The authors define three forms of unreliability based on narratology theory: intra-narrational (verbal tics), inter-narrational (contradictions from other characters or temporal inconsistencies), and inter-textual (fitting unreliable character tropes like madman or pícaro). They create TUN A, an expert-annotated dataset of 817 narratives from diverse sources including fiction, blog posts, subreddit posts, and hotel reviews. Through experiments with zero-shot, few-shot, fine-tuning, and curriculum learning approaches, the paper demonstrates that classifying unreliable narrators remains challenging for current LLMs, with performance varying significantly across reliability types and text domains.

## Method Summary
The authors construct TUN A, a dataset of 817 first-person narratives annotated by English literature experts to identify three types of unreliability: intra-narrational (verbal tics), inter-narrational (contradictions from other characters or changes over time), and inter-textual (fitting unreliable character tropes). They employ large language models using multiple experimental paradigms including zero-shot prompting, few-shot learning, fine-tuning on the annotated dataset, and curriculum learning approaches that train on easier tasks before progressing to harder ones. The evaluation spans four text domains: fiction, blog posts, subreddit posts, and hotel reviews, with particular attention to cross-domain generalization where models trained on fictional narratives are tested on real-world text.

## Key Results
- Classifying unreliable narrators is challenging for LLMs, with modest performance across all experimental setups
- Intra-narrational tasks (identifying verbal tics) are easier than inter-textual tasks (recognizing character tropes)
- Models trained on fictional narratives show better generalization when tested on real-world text domains
- Performance varies significantly across the three reliability types, with inter-textual classification being most difficult

## Why This Works (Mechanism)
The approach leverages narratology theory to operationalize abstract concepts of narrator unreliability into concrete classification tasks. By decomposing unreliability into three distinct types (intra-narrational, inter-narrational, and inter-textual), the methodology provides multiple angles for LLM analysis. The use of expert-annotated datasets ensures high-quality training data, while the diverse text domains (fiction, blogs, social media, reviews) create opportunities for cross-domain learning. Curriculum learning strategies that progress from easier to harder tasks may help models build foundational understanding before tackling complex reliability judgments.

## Foundational Learning
- Narratology theory fundamentals: Understanding the theoretical framework for identifying unreliable narrators is essential for interpreting the classification tasks and evaluation criteria. Quick check: Can you define the three types of unreliability and provide examples from literature?
- First-person narrative structures: Recognizing how first-person perspective differs from other narrative modes helps explain why the study focuses exclusively on this narrative type. Quick check: What are the key characteristics that distinguish first-person from third-person narration?
- Textual inconsistency detection: The ability to identify contradictions within and across texts is crucial for inter-narrational reliability classification. Quick check: How would you programmatically detect temporal inconsistencies in a narrative?

## Architecture Onboarding
**Component Map:** TUN A dataset -> LLM model (various architectures) -> Reliability classification (intra, inter, inter-textual) -> Performance evaluation across domains
**Critical Path:** Expert annotation → Dataset creation → Model training/testing → Cross-domain evaluation → Performance analysis
**Design Tradeoffs:** The choice to focus on first-person narratives simplifies the problem space but limits generalizability; using diverse text domains improves real-world applicability but introduces genre-specific challenges; expert annotation ensures quality but creates scalability constraints
**Failure Signatures:** Poor performance on inter-textual tasks suggests models struggle with abstract character trope recognition; cross-domain generalization issues indicate overfitting to genre-specific patterns; modest overall scores reveal fundamental challenges in capturing nuanced reliability cues
**First Experiments:** 1) Test zero-shot classification on a held-out subset of TUN A to establish baseline performance, 2) Fine-tune a pre-trained LLM on the full TUN A dataset and evaluate on each reliability type separately, 3) Train on fictional narratives and test exclusively on real-world text to measure cross-domain generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size (817 narratives) may not capture full diversity of unreliable narrator types and narrative styles
- Annotation process relies on subjective judgments about narrator reliability that may lack consistency across genres
- Exclusive focus on first-person narratives limits generalizability to other narrative perspectives
- Does not address cultural or linguistic variations in how unreliability manifests across different writing traditions

## Confidence
- Claim: LLM-based classification of unreliable narrators is "challenging" - **High** confidence based on modest performance metrics
- Claim: Intra-narrational tasks are easier than inter-textual ones - **Medium** confidence, experimental design could be more balanced
- Claim: Better cross-domain generalization (fiction → real-world text) - **Low** confidence due to limited testing across diverse domains

## Next Checks
1. Expand the dataset to include more diverse narrative genres and cultural contexts while maintaining expert annotation quality
2. Conduct inter-annotator agreement studies to quantify the subjectivity inherent in identifying unreliable narrators
3. Test model performance on narratives where the reliability status is ambiguous or debated in literary scholarship to assess real-world applicability