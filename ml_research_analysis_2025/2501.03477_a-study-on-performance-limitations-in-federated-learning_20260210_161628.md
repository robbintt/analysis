---
ver: rpa2
title: A study on performance limitations in Federated Learning
arxiv_id: '2501.03477'
source_url: https://arxiv.org/abs/2501.03477
tags:
- learning
- federated
- client
- data
- devices
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study characterizes performance limitations in Federated Learning
  (FL), focusing on communication overhead and data Non-IID-ness. Communication overhead
  is addressed through lossy compression of model broadcasts and gradient aggregations
  using quantization, reducing cumulative bits from 17 GB to 5 GB with only a 0.3%
  accuracy drop (93% to 92.7%).
---

# A study on performance limitations in Federated Learning

## Quick Facts
- arXiv ID: 2501.03477
- Source URL: https://arxiv.org/abs/2501.03477
- Authors: Karthik Mohan
- Reference count: 0
- Primary result: Compression reduces communication from 17 GB to 5 GB with 0.3% accuracy loss; label Non-IID (single class per client) reduces accuracy from 80% to 73%

## Executive Summary
This study characterizes performance limitations in Federated Learning (FL), focusing on communication overhead and data Non-IID-ness. Communication overhead is addressed through lossy compression of model broadcasts and gradient aggregations using quantization, reducing cumulative bits from 17 GB to 5 GB with only a 0.3% accuracy drop (93% to 92.7%). Non-IID-ness is characterized by creating label-non-IID datasets where each client has only one class, resulting in reduced model performance (80% to 73% accuracy). The study demonstrates that compression techniques can significantly reduce communication costs with minimal accuracy loss, while Non-IID-ness substantially impacts model performance, suggesting limited data exchange as a potential mitigation strategy.

## Method Summary
The study uses TensorFlow Federated (TFF) to simulate cross-device FL on EMNIST digits with 3383 users. Two main experiments were conducted: (1) compression using 8-bit quantization on model variables exceeding 10,000 elements during broadcast and aggregation, and (2) label Non-IID characterization by partitioning data so each client holds only one class. FedAvg was used with 10 clients per round, 1 local epoch for compression experiments, and 5 local epochs for Non-IID experiments. Accuracy and cumulative bits transmitted were measured as key metrics.

## Key Results
- 8-bit quantization reduces cumulative communication from 17 GB to 5 GB with only 0.3% accuracy drop (93% to 92.7%)
- Label Non-IID (single class per client) reduces accuracy from 80% to 73% compared to IID settings
- FedAvg's synchronous aggregation protocol shows sensitivity to client sampling randomness, creating noise in training curves

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lossy compression via quantization can reduce communication overhead in FL with minimal accuracy degradation.
- Mechanism: Uniform 8-bit quantization (256 buckets) is applied to model variables exceeding 10,000 elements during both broadcast (server→client) and aggregation (client→server), reducing floating-point precision while preserving directional information in gradient updates.
- Core assumption: The information loss from reduced precision does not catastrophically corrupt the optimization trajectory; gradient direction remains approximately preserved.
- Evidence anchors:
  - [abstract]: "reducing cumulative bits from 17 GB to 5 GB with only a 0.3% accuracy drop (93% to 92.7%)"
  - [section 6.2]: "cumulative broadcasted bits...and cumulative aggregated bits...are greatly reduced from 17 GB before compression to 5 GB after compression"
  - [corpus]: Limited direct corpus validation; neighboring papers discuss compression principles but do not replicate this specific 8-bit quantization result.
- Break condition: If model weights have high dynamic range or critical low-magnitude components, quantization may cause convergence failure; this study tested only EMNIST with CNN architecture.

### Mechanism 2
- Claim: Label-distribution skew (label Non-IID) degrades global model performance compared to IID settings.
- Mechanism: When clients each hold only a single class, local SGD updates optimize for disparate objectives; FedAvg's weighted averaging produces a global model that must reconcile conflicting gradient directions, leading to slower convergence and suboptimal minima.
- Core assumption: The degradation stems primarily from objective misalignment rather than insufficient local data quantity per client.
- Evidence anchors:
  - [abstract]: "Non-IID-ness is characterized by creating label-non-IID datasets where each client has only one class, resulting in reduced model performance (80% to 73% accuracy)"
  - [section 6.3]: "it is evident that the label non IID-ness causes poor model performance...accuracy of IID model is 80% while the accuracy of the non IID model is 73%"
  - [corpus]: FBFL paper (arxiv:2502.08577) confirms "data across devices are non-independently and idententially distributed" as a significant challenge, though with different mitigation approaches.
- Break condition: This represents an extreme Non-IID case (single-class clients); degradation magnitude may differ under milder skew or with personalized FL architectures.

### Mechanism 3
- Claim: FedAvg's synchronous aggregation protocol is sensitive to client sampling randomness and stragglers.
- Mechanism: Random client subset selection per round introduces stochasticity in aggregated gradients; coupled with stateless clients that may drop between rounds, this creates noise in training curves even under controlled simulation.
- Core assumption: Client sampling noise averages out over sufficient rounds; the paper does not formally prove convergence bounds.
- Evidence anchors:
  - [section 3.4]: "The communication protocol is synchronous. Stragglers - the devices in which the local training is much slower could be dropped."
  - [section 6.2]: "The noise in the accuracy curves is because a random subset of clients is chosen...client participating in one round may not participate in the next round"
  - [corpus]: FedAT paper reference [11] in bibliography proposes asynchronous tiers as alternative; corpus neighbors mention "temporal correlations" and "active user selection" as related concerns.
- Break condition: Under high client dropout rates or systematic bias in which clients participate, convergence may stall or produce biased models.

## Foundational Learning

- Concept: **Federated Averaging (FedAvg) algorithm**
  - Why needed here: This is the baseline orchestration protocol; understanding its 5-step cycle (selection→broadcast→computation→aggregation→update) is prerequisite to diagnosing where bottlenecks occur.
  - Quick check question: Can you explain why FedAvg performs local SGD epochs before aggregation rather than sending raw gradients after each batch?

- Concept: **IID vs. Non-IID data distributions**
  - Why needed here: The paper's Non-IID experiments assume familiarity with why IID is a standard ML assumption and how label skew violates it.
  - Quick check question: If Client A has only digit "0" images and Client B has only digit "1" images, why might averaging their model weights produce a worse classifier than if both had mixed data?

- Concept: **Quantization for neural network compression**
  - Why needed here: The compression experiment applies uniform quantization; understanding floating-point→integer mapping is needed to interpret tradeoffs.
  - Quick check question: Why does the paper quantize only variables with >10,000 elements rather than all parameters?

## Architecture Onboarding

- Component map:
  Central Server -> Model initialization (Keras→tff.learning.from_keras_model) -> Broadcast process (optional: encoded_broadcast_from_model) -> Aggregation process (optional: encoded_mean_from_model) -> IterativeProcess (initialize + next computations)
  Simulated Clients (via TFF simulation datasets) -> Local data partition (EMNIST per-user split) -> Local training (client_optimizer_fn, e.g., SGD) -> Update transmission (compressed or raw)
  Evaluation -> Federated: tff.learning.build_federated_evaluation -> Centralized: tf.keras.models.Model.evaluate

- Critical path:
  1. Define Keras model architecture
  2. Wrap as `tff.learning.Model` with sample batch spec
  3. Build FedAvg process via `tff.learning.build_federated_averaging_process`
  4. Call `initialize()` to get server state
  5. Loop: call `next(state, client_data)` for N rounds
  6. Evaluate using federated or centralized evaluator

- Design tradeoffs:
  - **Compression level vs. accuracy**: Higher quantization (fewer bits) saves bandwidth but risks convergence; this paper found 8-bit acceptable for EMNIST/CNN.
  - **Clients per round vs. convergence speed**: More clients = smoother gradients but higher per-round communication; paper used 10 clients/round.
  - **Local epochs vs. communication rounds**: More local epochs reduce communication frequency but may increase client drift (exacerbated under Non-IID).
  - **Model complexity vs. simulation speed**: Paper used simple MLP for Non-IID experiments to iterate faster; CNN for compression to get realistic bit counts.

- Failure signatures:
  - **Loss plateau or divergence under Non-IID**: Check label distribution across clients; consider data sharing or personalized layers.
  - **No accuracy improvement across rounds**: Verify client optimizer learning rate; check if clients have sufficient local data.
  - **Memory errors in TFF simulation**: Reduce batch size or clients per round; TFF loads all client data in memory by default.
  - **Compression causes NaN loss**: Quantization bounds may be too aggressive; inspect variable histograms before/after encoding.

- First 3 experiments:
  1. **Baseline FedAvg replication**: Train CNN on EMNIST with 10 clients/round for 50 rounds; log accuracy and cumulative bits to establish reference (target: ~93% accuracy as per paper).
  2. **Compression ablation**: Apply 8-bit quantization; vary quantization levels (4-bit, 8-bit, 16-bit) and measure accuracy/bit-saved frontier; confirm 17GB→5GB reduction is reproducible.
  3. **Non-IID severity sweep**: Generate label-skew datasets with 1, 2, 5, and 10 classes-per-client; plot accuracy vs. skew severity to characterize degradation curve beyond the single extreme (73%) data point.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the specific 8-bit quantization compression technique validated on EMNIST be effectively applied to Natural Language Processing (NLP) tasks without causing significant degradation in model convergence or accuracy?
- Basis: [explicit] The paper states in Section 8 (Future Work) that it needs to be "investigated if the same quantization technique will work for natural language processing tasks."
- Why unresolved: The study restricted its experimentation to computer vision tasks (handwritten digit classification) and did not test the compression efficacy on the sparse or high-dimensional data structures typical of NLP.
- What evidence would resolve it: Empirical results from federated training on NLP datasets (e.g., text classification or next-word prediction) comparing baseline accuracy against models using 8-bit quantization for broadcast and aggregation.

### Open Question 2
- Question: Does allowing limited data exchange across clients effectively mitigate the extreme label Non-IID-ness (single label per client) that causes the 7% accuracy drop observed in this study?
- Basis: [inferred] Section 6.3 concludes that oversampling techniques likely will not work for the extreme label skew tested and suggests "limited data exchange" as a potential solution, though this was not implemented.
- Why unresolved: The paper characterizes the performance limitation but stops short of validating the proposed mitigation strategy for the specific single-label data distribution.
- What evidence would resolve it: A comparative study measuring the convergence rate and final accuracy of models trained with restricted data sharing versus the baseline FedAvg on the same label-skewed dataset.

### Open Question 3
- Question: How do communication bottlenecks and data Non-IID-ness affect model performance in a fully decentralized peer-to-peer learning environment compared to the centrally orchestrated setting?
- Basis: [explicit] Section 8 identifies the need to extend this project to a "peer-to-peer machine learning setting," noting that decentralized orchestration adds complexity to these issues.
- Why unresolved: The experiments were conducted exclusively using cross-device horizontal federated learning with a central server; decentralized architectures handle aggregation and synchronization differently.
- What evidence would resolve it: Simulations of peer-to-peer federated algorithms (e.g., gossip protocols) under similar compression and Non-IID constraints to benchmark against the centralized Federated Averaging results.

## Limitations

- Extreme Non-IID assumption (single class per client) may not generalize to realistic skew distributions
- Limited hyperparameter transparency (optimizer configs, CNN layer specs) prevents exact reproduction
- No formal convergence analysis provided for compressed training under Non-IID conditions

## Confidence

- **High confidence**: Communication overhead reduction via quantization (backed by concrete bit counts and accuracy drop)
- **Medium confidence**: Non-IID performance degradation (validated on extreme case but limited to single architecture)
- **Low confidence**: Generalization of results to other datasets/models without further validation

## Next Checks

1. Replicate experiments with intermediate Non-IID skew levels (2-5 classes per client) to map degradation curve
2. Test compression performance across different model architectures (ResNet, Transformer) and datasets (CIFAR-10, Shakespeare)
3. Conduct ablation studies varying quantization bits (4-bit vs 8-bit vs 16-bit) to establish precise accuracy/bit tradeoff frontier