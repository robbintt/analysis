---
ver: rpa2
title: Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models
arxiv_id: '2508.10339'
source_url: https://arxiv.org/abs/2508.10339
tags:
- selection
- instruction
- visual
- skill
- skills
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how different vision-language instruction selection
  strategies affect downstream benchmark performance. The key finding is that benchmarks
  fall into two categories: those benefiting more from concept-aligned training (visual
  content similarity) and those benefiting more from skill-aligned training (reasoning
  ability similarity).'
---

# Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models

## Quick Facts
- **arXiv ID:** 2508.10339
- **Source URL:** https://arxiv.org/abs/2508.10339
- **Reference count:** 8
- **Key outcome:** Targeted instruction selection based on concept vs. skill alignment improves VLM benchmark performance, with +0.9% average gain over baselines.

## Executive Summary
This paper challenges the assumption that uniform instruction selection is optimal for multi-modal model training. Instead, it proposes that benchmarks fall into two categories: those benefiting more from concept-aligned training (visual content similarity) and those benefiting more from skill-aligned training (reasoning ability similarity). By classifying benchmarks and selecting training data accordingly, the authors demonstrate consistent improvements across 12+ vision-language benchmarks, with particular gains on skill-focused tasks. The work provides both a practical method for targeted selection and a simple cross-ranking heuristic to predict optimal strategy without running multiple fine-tuning experiments.

## Method Summary
The authors propose a targeted instruction selection framework that classifies benchmarks as concept- or skill-dominant, then selects training data matching that type. They extract concept embeddings using CLIP for visual content similarity and skill embeddings by prompting GPT-4o for reasoning descriptions followed by MiniLM-L6-v2 encoding. Using FAISS, they retrieve nearest neighbors in either embedding space and train separate models on each selection. A cross-ranking heuristic (measuring where top skill neighbors appear in concept rankings and vice versa) predicts benchmark alignment without training. Experiments use LLaVA-1.5 (665k examples) and ALLaVA-4V (1.2M examples) instruction pools with 5-10% sampling budgets.

## Key Results
- Targeted selection achieves +0.9% average improvement over best untargeted baselines across all benchmarks
- Skill-focused benchmarks show +1.5% improvement with skill-targeted selection
- Cross-ranking heuristic successfully predicts optimal selection strategy in most cases
- Concept-targeted selection benefits VQAv2, GQA, and similar benchmarks
- Skill-targeted selection benefits SQA-I, LLaVA-Bench, and reasoning-heavy tasks

## Why This Works (Mechanism)

### Mechanism 1: Concept-Skill Decomposition Enables Targeted Alignment
The paper decomposes vision-language tasks into concept (visual content) and skill (reasoning operations) components, enabling targeted training data selection. By retrieving training examples nearest to benchmark samples in either concept-space or skill-space, models receive inductive biases matched to the task's dominant demand. This mirrors the formal view of compositionality in VQA where skills and concepts are explicitly modeled. The approach assumes skill descriptions generated by GPT-4o meaningfully cluster by reasoning type, which is supported by qualitative analysis.

### Mechanism 2: Mutual Ranking Heuristic Predicts Benchmark Alignment Without Training
A lightweight cross-ranking analysis predicts whether a benchmark is concept- or skill-dominant by measuring rank asymmetry. For each benchmark, the paper computes where top skill neighbors appear in the concept ranking (Rc|s) and vice versa (Rs|c). Asymmetric patterns indicate dominance: low Rc|s + high Rs|c suggests skill-dominance, while high Rc|s + low Rs|c suggests concept-dominance. This eliminates the need to run multiple fine-tuning experiments, though the causal mechanism behind the correlation remains observational.

### Mechanism 3: Targeted Selection Outperforms Untargeted Baselines Under Data Budget Constraints
When training data is limited (5-10% of available data), targeted selection yields higher performance than untargeted methods like random selection, Coincide, or PreSel. Untargeted baselines optimize for global criteria like diversity or average transferability, while targeted selection explicitly aligns training examples with the benchmark's dominant axis, reducing irrelevant data and focusing model capacity on the most relevant inductive biases.

## Foundational Learning

### Concept: Vision-Language Instruction Tuning
- **Why needed here:** The method operates on instruction tuning datasets, where understanding what instruction tuning does—aligning multimodal models to follow task-specific prompts—is essential to grasp why selection matters.
- **Quick check question:** Can you explain why instruction tuning is necessary after pretraining a vision-language model, and what types of capabilities it typically improves?

### Concept: Nearest-Neighbor Retrieval in Embedding Spaces
- **Why needed here:** The selection pipeline uses FAISS-based nearest-neighbor search in both concept and skill embedding spaces, making understanding how embedding similarity translates to semantic relatedness crucial.
- **Quick check question:** Given two embedding spaces (concept and skill), how would you interpret a case where the same instruction has high similarity to a benchmark sample in one space but low similarity in the other?

### Concept: Skill–Concept Compositionality in VQA
- **Why needed here:** The paper builds on prior work that decomposes VQA into skills and concepts, which is central to the method's design and to interpreting results.
- **Quick check question:** For a VQA question like "How many red cars are in the image?", what is the skill component and what is the concept component?

## Architecture Onboarding

### Component Map
1. Benchmark Ingestion -> Concept Encoder (CLIP) -> Concept Embeddings
2. Benchmark Ingestion -> Skill Extraction Pipeline (GPT-4o + MiniLM-L6-v2) -> Skill Embeddings
3. Instruction Pool Embeddings -> FAISS Index -> Nearest-Neighbor Retrieval
4. Cross-Rank Computation -> Alignment Prediction -> Targeted Selection
5. Selected Data -> LLaVA-1.5 Training (LoRA) -> Fine-tuned Model

### Critical Path
1. Implement skill extraction pipeline (LLM prompting + sentence encoding) - this is the most fragile component
2. Precompute and index all instruction pool embeddings (concept + skill) using FAISS
3. Implement cross-rank computation for alignment prediction; validate against Figure 1 scatter plot pattern

### Design Tradeoffs
- **LLM for Skill Extraction vs. Human Annotation:** LLM-based extraction is scalable but may introduce noise; the paper does not compare against human-annotated skills
- **Single-Targeted vs. Hybrid Selection:** Hybrid strategies (sum, max, split) did not consistently outperform single-targeted selection; the paper recommends predicting and committing to one alignment type
- **Data Budget vs. Alignment Signal:** At very low budgets (5%), alignment matters more; as budget increases, the gap between targeted and untargeted methods may narrow

### Failure Signatures
- **Skill Embedding Collapse:** If skill descriptions are generic (e.g., "visual understanding" for all questions), skill embeddings will not discriminate reasoning types
- **Cross-Rank Asymmetry Absent:** If Rc|s and Rs|c are similar across benchmarks, the prediction heuristic fails
- **Performance Parity with Random Baseline:** If targeted selection does not outperform random, check embedding quality and retrieval correctness

### First 3 Experiments
1. **Reproduction Check:** Implement concept- and skill-based retrieval on VQAv2 vs. SQA-I with 5% LLaVA-1.5 data; verify VQAv2 benefits more from concept-aligned selection and SQA-I from skill-aligned selection
2. **Ablation on Skill Extraction:** Replace GPT-4o with Llama-3-8B for skill description generation; compare downstream performance to quantify sensitivity to LLM quality
3. **Scaling the Data Budget:** Test targeted vs. untargeted selection at 25% and 50% data budgets to characterize when alignment effects saturate

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can benchmark alignment preferences be inferred without supervision to enable dynamic, zero-shot selection for unseen tasks?
- **Basis in paper:** The authors state they aim to develop automatic methods to infer benchmark alignment preferences without supervision
- **Why unresolved:** The current cross-ranking heuristic requires analyzing the target benchmark's data distribution, which is unavailable in true zero-shot deployment scenarios
- **Evidence would resolve it:** A method that accurately predicts the optimal alignment strategy for a new task using only task metadata or a few-shot prompt, without accessing the full evaluation set

### Open Question 2
- **Question:** How can fine-grained selection criteria be designed to successfully capture interaction effects between concept and skill attributes?
- **Basis in paper:** The authors plan to explore more fine-grained selection criteria that consider interaction effects between concept and skill attributes
- **Why unresolved:** The paper found that naive hybrid strategies failed to outperform single-targeted approaches, indicating the interaction is non-additive and complex
- **Evidence would resolve it:** A selection algorithm that dynamically weighs concept and skill similarity per sample and demonstrates superior performance on benchmarks with mixed requirements

### Open Question 3
- **Question:** How does targeted instruction selection impact multi-task generalization and interference effects when tuning a model jointly for multiple tasks?
- **Basis in paper:** The paper notes it treats each benchmark in isolation and does not account for multi-task generalization or interference effects
- **Why unresolved:** It is unclear if aggregating "optimal" subsets for different benchmarks creates a conflicting signal that degrades overall average performance
- **Evidence would resolve it:** Experiments comparing the performance of a model trained on a union of targeted subsets against a model trained on a global diversity-maximizing set across diverse benchmarks

### Open Question 4
- **Question:** Does the effectiveness of concept- versus skill-targeted selection transfer across different model architectures, sizes, and pretraining regimes?
- **Basis in paper:** The authors note the effectiveness may vary with model size and pretraining quality
- **Why unresolved:** Experiments are restricted to LLaVA-1.5 (7B) framework; larger models may saturate on "skill" gains, while different visual encoders might alter the concept/skill dichotomy
- **Evidence would resolve it:** Reproducing the selection experiments on varying model scales (13B, 70B) and different base architectures (Fuyu, Qwen-VL) to verify consistency of improvements

## Limitations
- The skill extraction pipeline relies on GPT-4o, which may introduce variability and noise that is difficult to control
- The cross-ranking heuristic shows correlation but lacks a clear causal mechanism explaining why rank asymmetry reliably predicts benchmark alignment
- Experiments are limited to LLaVA-1.5 (7B) scale; scaling to larger models or different architectures may alter the relative effectiveness of targeted vs. untargeted selection

## Confidence
- **High Confidence:** The core empirical finding that concept-aligned and skill-aligned training benefit different types of benchmarks is well-supported by experimental results across 12 benchmarks
- **Medium Confidence:** The cross-ranking heuristic for predicting benchmark alignment is validated through correlation analysis but lacks formal theoretical grounding or robustness testing
- **Medium Confidence:** The claim that targeted selection outperforms untargeted baselines under data budget constraints is supported, but the limited budget range (5-10%) and single model architecture constrain generalizability

## Next Checks
1. **Ablation Study on Skill Extraction Quality:** Replace GPT-4o with smaller, open-source LLMs (e.g., Llama-3-8B) for skill description generation and measure the impact on downstream performance to quantify sensitivity to LLM quality

2. **Cross-Rank Correlation Robustness:** Systematically vary the k-nearest neighbors parameter and embedding dimensions to test whether the cross-rank correlation remains stable across different retrieval granularities and embedding qualities

3. **Scaling Behavior Analysis:** Extend experiments to higher data budgets (25%, 50%) and larger model scales (13B, 30B) to characterize when alignment effects saturate and whether targeted selection remains advantageous