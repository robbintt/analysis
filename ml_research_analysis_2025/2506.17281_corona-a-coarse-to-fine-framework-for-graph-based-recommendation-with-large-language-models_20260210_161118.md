---
ver: rpa2
title: 'CORONA: A Coarse-to-Fine Framework for Graph-based Recommendation with Large
  Language Models'
arxiv_id: '2506.17281'
source_url: https://arxiv.org/abs/2506.17281
tags:
- user
- recommendation
- retrieval
- llms
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CORONA, a novel framework for graph-based
  recommendation that leverages large language models (LLMs) for coarse-to-fine retrieval.
  CORONA addresses the limitation of existing methods that only use LLMs for re-ranking
  or data augmentation, failing to utilize their capabilities during candidate filtering.
---

# CORONA: A Coarse-to-Fine Framework for Graph-based Recommendation with Large Language Models

## Quick Facts
- arXiv ID: 2506.17281
- Source URL: https://arxiv.org/abs/2506.17281
- Authors: Junze Chen; Xinjie Yang; Cheng Yang; Junfei Bao; Zeyuan Guo; Yawen Li; Chuan Shi
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on graph-based recommendation, with 18.6% relative improvement in recall and 18.4% in NDCG on average

## Executive Summary
This paper introduces CORONA, a novel framework that leverages large language models (LLMs) for coarse-to-fine retrieval in graph-based recommendation. Unlike existing methods that only use LLMs for re-ranking or data augmentation, CORONA integrates LLMs into the candidate filtering process through progressive subgraph narrowing. The framework performs three-stage retrieval: preference reasoning from user profiles, intent reasoning from purchase history, and final recommendation via graph neural networks. Experiments on three datasets demonstrate significant performance improvements over state-of-the-art methods.

## Method Summary
CORONA addresses the limitation of existing graph-based recommendation methods by integrating LLMs into the candidate filtering process. The framework operates on bipartite user-item interaction graphs and employs a three-stage retrieval pipeline: (1) LLM performs preference reasoning from user profiles to generate query embeddings for retrieving top-k similar users and their connected items; (2) LLM performs intent reasoning using the retrieved subgraph summary combined with user history to refine the candidate set; (3) a graph neural network operates on the final subgraph to produce recommendations. The method uses distance-aware user retrieval with attention bias toward closer neighbors and shows effectiveness in cold-start scenarios.

## Key Results
- Achieves state-of-the-art performance with 18.6% relative improvement in recall@20 and 18.4% in NDCG@20 on average
- Demonstrates effectiveness in cold-start scenarios, with 26.1% and 29.4% relative improvements in recall@20 and NDCG@20 respectively
- Shows optimal performance with k≈3000 candidates and temperature τ≈0.2-0.4 for LLM reasoning

## Why This Works (Mechanism)

### Mechanism 1: LLM-Guided Progressive Subgraph Narrowing
- Claim: Using LLMs to generate query embeddings that progressively narrow the interaction graph improves retrieval precision by filtering irrelevant candidates early.
- Mechanism: The framework extracts smaller subgraphs at each stage: (1) LLM performs preference reasoning from user profile → query embedding retrieves top-k similar users and their connected items; (2) LLM performs intent reasoning from history + previous subgraph summary → refines to smaller user set; (3) GNN operates only on final subgraph rather than full graph.
- Core assumption: LLMs' reasoning about user preferences/intent can be meaningfully captured in text embeddings that correlate with relevant users/items in the interaction graph.
- Evidence anchors: [abstract] "CORONA to progressively narrow down the range of candidate items on interaction graphs with the help of LLMs"; [section 3.2] "We conduct three stages of retrieval from different granularities"; [corpus] Related work on coarse-to-fine retrieval validates hierarchical candidate selection.

### Mechanism 2: Preference-Intent Dual Reasoning Decomposition
- Claim: Separating long-term preference reasoning (from profiles) from short-term intent reasoning (from history) allows complementary signals to guide retrieval.
- Mechanism: Stage 1 uses static profile attributes for broad preference inference. Stage 2 combines the retrieved candidate summary with recent interaction history for context-specific intent.
- Core assumption: User profiles encode stable preferences while interaction histories encode dynamic intent, and both can be verbalized by LLMs.
- Evidence anchors: [section 3.3.1] "LLM should infer that the user might prefer French-language movies in the item set"; [section 3.4] "Intent Reasoning: Please infer the user's watching intent based on user history and candidate information".
- Break condition: If user profiles are sparse/missing, or if interaction history is too short, the LLM lacks sufficient context for meaningful reasoning.

### Mechanism 3: Distance-Aware User Retrieval with Attention Bias
- Claim: Encoding graph distance from target user into user embeddings improves retrieval by prioritizing similar users (1-hop, 2-hop neighbors) over distant ones.
- Mechanism: Distance encodings are concatenated with user features before computing similarity to query. Users beyond 2 hops receive uniform encoding, reducing their attention weight.
- Core assumption: Collaborative filtering signal degrades with graph distance; closer neighbors are more relevant for retrieval.
- Evidence anchors: [section 3.3.2] "very few users in Ztrain pay attention to items interacted by users beyond two-hop neighbors"; [section 3.3.2] Equation (1) shows distance-conditioned user embeddings.
- Break condition: If the dataset has long-range collaborative signals, distance encoding may exclude relevant candidates.

## Foundational Learning

- Concept: **Bipartite User-Item Interaction Graphs**
  - Why needed here: The entire CORONA framework operates on a bipartite graph where edges represent purchases. Understanding how GNNs propagate messages across this structure is essential.
  - Quick check question: Given a target user, can you manually trace their 2-hop neighbors (users who share items with their 1-hop neighbors)?

- Concept: **Query Embedding Retrieval (Dense Retrieval)**
  - Why needed here: LLM outputs are converted to embeddings and compared against user features via cosine similarity. This is the core retrieval mechanism.
  - Quick check question: Given an LLM-generated preference text "prefers action movies from the 1990s" and two user feature vectors, which would have higher cosine similarity?

- Concept: **Bayesian Personalized Ranking (BPR) Loss**
  - Why needed here: The GNN component is trained with BPR loss, which optimizes ranking of positive items over negative samples.
  - Quick check question: If user u interacted with item v but not v', what does BPR loss penalize: score(u,v) > score(u,v') or the reverse?

## Architecture Onboarding

- Component map:
User Profile → LLM (Preference Reasoning) → Query Embedding E_Q1
                                           ↓
                         Subgraph Retriever (cosine similarity with distance encoding)
                                           ↓
                        Preference Subgraph (U'_1, V'_1) → Summary Generator
                                           ↓
User History + Summary → LLM (Intent Reasoning) → Query Embedding E_Q2
                                           ↓
                         Subgraph Retriever (refined from U'_1)
                                           ↓
                        Intent Subgraph (U'_2, V'_2) → GNN Message Passing
                                           ↓
                        Final Scores: H_u · M_v for items in V'_2

- Critical path:
  1. LLM inference quality directly determines subgraph relevance (Stage 1 & 2)
  2. Distance encoding dimension affects neighbor differentiation (Section 4.5.3 shows dim=2 optimal)
  3. Subgraph size k controls precision-efficiency tradeoff (k~3000 optimal per Section 4.5.1)

- Design tradeoffs:
  - **LLM choice vs. cost**: GPT-4o-mini yields better reasoning but costs ~$0.01/user; Vicuna-7B is free but 15.87% lower performance (Figure 3)
  - **Subgraph size**: Larger k captures more candidates but dilutes precision; smaller k is efficient but may miss relevant items
  - **Temperature τ**: Higher values increase reasoning diversity but reduce consistency (Section 4.5.2 shows τ≈0.2-0.4 optimal)

- Failure signatures:
  1. **Empty or sparse subgraphs**: LLM reasoning doesn't match any users → retrieval returns empty set. Check query embedding distribution vs. user embedding distribution.
  2. **Cold-start degradation**: Items with ≤2 interactions should still appear in recommendations. If not, the subgraph retriever may be filtering them out at Stage 1.
  3. **Intent reasoning ignores history**: If "w/o Intent Reasoning" variant performs similarly to full model, the LLM isn't effectively using history context.

- First 3 experiments:
  1. **Ablate Stage 1**: Run CORONA with only Intent Retrieval + GNN (skip Preference Retrieval). Compare Recall@20 against full model. Expected: 10-15% drop per Table 4.
  2. **Vary k on held-out users**: Test k ∈ {1000, 2000, 3000, 4000} on a random 20% user subset. Plot Recall@20 vs. inference time. Verify the ~3000 peak holds.
  3. **Distance encoding sanity check**: Replace learned distance encodings with zero vectors. Expect performance drop if graph structure truly matters. If no drop, the retrieval is only using feature similarity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework be effectively extended to larger-scale industrial scenarios by incorporating more stages of retrieval?
- Basis in paper: [explicit] The conclusion explicitly proposes future work to "extend our framework to larger-scale industrial scenarios with more stages of retrieval."
- Why unresolved: The current evaluation is limited to three academic datasets with a fixed three-stage process, leaving the scalability and efficacy of deeper retrieval pipelines untested.
- What evidence would resolve it: Performance metrics and efficiency analysis on billion-scale industrial graphs using a pipeline with four or more retrieval stages.

### Open Question 2
- Question: To what extent can fine-tuning open-source LLMs improve preference and intent reasoning accuracy compared to proprietary models?
- Basis in paper: [explicit] The conclusion highlights the possibility to "finetune an open-source LLM for more accurate preference or intent reasoning."
- Why unresolved: While the paper tests Vicuna-7B (off-the-shelf), it performs worse than GPT-4o-mini; the potential gains from specializing an open-source model for this specific reasoning task remain unquantified.
- What evidence would resolve it: A comparative study measuring CORONA's performance when using a specialized fine-tuned LLM versus general-purpose models like GPT-4o-mini.

### Open Question 3
- Question: How robust is the candidate filtering process against errors or hallucinations in the LLM's natural language reasoning?
- Basis in paper: [inferred] The framework relies on LLM-generated text for query embeddings, but the paper does not analyze how semantic errors or noise in the reasoning output affect the subgraph retrieval quality.
- Why unresolved: The ablation study removes reasoning entirely but does not test the system's resilience to confident but incorrect reasoning (hallucinations) provided by the LLM.
- What evidence would resolve it: Experiments measuring performance degradation when the LLM is prompted with adversarial constraints or when synthetic noise is injected into the reasoning responses.

## Limitations
- The framework requires user profiles to be available, which may limit applicability in truly cold-start scenarios where no profile information exists
- The optimal k value and temperature settings are dataset-dependent and require tuning, which may not transfer well to different domains
- Distance encoding is only validated on datasets with sparse long-range edges (3% beyond 2 hops), limiting generalizability to datasets with different graph structures

## Confidence
- **High** (Mechanism 1, 2, 3): Supported by ablation studies, Figure 2/3, and detailed experimental analysis
- **Medium** (Dual reasoning decomposition): Limited direct corpus evidence; relies on intuitive decomposition
- **Medium** (Distance-aware retrieval): Only validated on datasets with sparse long-range edges

## Next Checks
1. Run ablation of Stage 1 (Preference Retrieval only) on a held-out user subset; expect 10-15% Recall@20 drop if preference reasoning is critical
2. Test k ∈ {1000, 2000, 3000, 4000} on a random 20% user subset; plot Recall@20 vs. inference time to verify the ~3000 peak
3. Replace learned distance encodings with zeros; expect performance drop if graph structure matters; no drop indicates retrieval ignores distance