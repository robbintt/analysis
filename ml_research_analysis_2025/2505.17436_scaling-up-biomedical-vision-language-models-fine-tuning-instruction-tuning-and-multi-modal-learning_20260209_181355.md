---
ver: rpa2
title: 'Scaling Up Biomedical Vision-Language Models: Fine-Tuning, Instruction Tuning,
  and Multi-Modal Learning'
arxiv_id: '2505.17436'
source_url: https://arxiv.org/abs/2505.17436
tags:
- text
- image
- biomedical
- language
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed two larger-scale biomedical vision-language
  models (BiomedGPT-Large and BiomedGPT-XLarge) by scaling up model parameters and
  incorporating long-form text data from PubMed literature. The scaled models were
  fine-tuned on 23 benchmark datasets across six biomedical tasks and instruction-tuned
  using a large multimodal instruction dataset.
---

# Scaling Up Biomedical Vision-Language Models: Fine-Tuning, Instruction Tuning, and Multi-Modal Learning

## Quick Facts
- **arXiv ID**: 2505.17436
- **Source URL**: https://arxiv.org/abs/2505.17436
- **Reference count**: 0
- **Primary result**: Scaled biomedical vision-language models (BiomedGPT-Large/XLarge) achieved state-of-the-art performance on 15 of 23 benchmark datasets and improved long-text handling by 4.6-11.4% in summarization tasks.

## Executive Summary
This study developed larger-scale biomedical vision-language models by scaling from 182M to 930M parameters and incorporating long-form PubMed literature. The scaled models were fine-tuned on 23 benchmark datasets across six biomedical tasks and instruction-tuned using a large multimodal instruction dataset (BioMed-VITAL). The new models outperformed the previous BiomedGPT-Base model on 17 of 23 datasets, with the largest model (BiomedGPT-XLarge) achieving state-of-the-art performance on 15 of 23 datasets. Instruction tuning significantly enhanced zero-shot learning abilities and alignment accuracy across multiple tasks, with accuracy increases of 12.5-45.3% compared to previous state-of-the-art models.

## Method Summary
The researchers developed BiomedGPT-Large (472M) and BiomedGPT-XLarge (930M) by continuing pretraining from OFA models on expanded biomedical data including PubMed abstracts and long-form literature. They used a unified encoder-decoder transformer architecture with a shared vocabulary for text, images (via VQ-GAN), and object bounding boxes. Models were first fine-tuned on 23 benchmark datasets across six biomedical tasks, then instruction-tuned on BioMed-VITAL (210K samples) for zero-shot capabilities. Training used PyTorch 1.8.1 and fairseq 1.0.0 on 8×A100 80GB GPUs with max input length of 512 tokens and 196 image patches.

## Key Results
- BiomedGPT-XLarge outperformed Base and Large models on 17 of 23 datasets
- Achieved state-of-the-art performance on 15 of 23 datasets
- Scaled models demonstrated 4.6-11.4% improvement in text summarization and understanding tasks
- Instruction tuning enhanced zero-shot learning with accuracy increases of 12.5-45.3% compared to previous state-of-the-art models

## Why This Works (Mechanism)

### Mechanism 1: Unified Tokenization and Shared Representation
A unified vocabulary and shared transformer structure allow the model to handle multi-modal inputs and outputs efficiently. By representing images (via VQ-GAN and ResNet), text (via BPE tokens), and object bounding boxes as tokens from a single finite vocabulary (59,457 tokens total), and processing them through a shared encoder-decoder transformer, the model learns joint representations. This allows a single architecture to perform diverse tasks (image classification, VQA, text summarization) without task-specific model heads, using a sequence-to-sequence objective.

### Mechanism 2: Scale-Dependent Representation Capacity
Increasing model parameters and training data improves the model's ability to capture complex patterns and long-range dependencies in biomedical text and imagery. Larger models (more layers, higher hidden dimensions) have greater capacity to store and generalize from vast datasets. Scaling from 182M (Base) to 930M (XLarge) parameters, combined with a 50% increase in training text (including long-form PubMed literature), allows the model to form richer semantic representations. This directly translates to better performance on tasks requiring synthesis of long text (summarization) and nuanced visual understanding.

### Mechanism 3: Instruction Tuning for Alignment and Zero-Shot Generalization
Supervised fine-tuning on a dataset of instruction-following samples significantly enhances a model's ability to perform novel tasks zero-shot and follow complex prompts accurately. Instruction tuning shapes the model's behavior by teaching it to map from diverse natural language instructions (prompts) to desired outputs. By training on a large dataset like BioMed-VITAL (210K samples), the model learns the format of following instructions, aligning the model's generation with human intent and allowing it to generalize to unseen tasks.

## Foundational Learning

- **Concept: Encoder-Decoder Transformer Architecture**
  - **Why needed here**: BiomedGPT uses this architecture to handle both understanding (encoder) and generation (decoder) across modalities. This is fundamental to how it processes an image (via encoder) and generates a radiology report (via decoder).
  - **Quick check question**: Can you explain why an encoder-decoder architecture is more suitable for generation tasks (like report summarization) than an encoder-only architecture (like BERT)?

- **Concept: Sequence-to-Sequence (Seq2Seq) Learning**
  - **Why needed here**: The model frames all tasks—whether classifying an image or summarizing text—as seq2seq problems. Understanding this abstraction is key to seeing how one model can handle many different tasks with a unified training objective.
  - **Quick check question**: How would you format a multi-choice medical question (MedMCQA) as a seq2seq problem for the model to solve?

- **Concept: Zero-Shot Learning & Alignment**
  - **Why needed here**: A major goal is deploying a model that can handle novel clinical tasks without new training data. Instruction tuning is the technique used to achieve this alignment. Understanding what "alignment" means in this context is crucial for evaluating the model's real-world applicability.
  - **Quick check question**: What is the difference between a model fine-tuned for a specific task (e.g., pneumonia detection) and an instruction-tuned model performing the same task in a zero-shot manner?

## Architecture Onboarding

- **Component map**: Images (ResNet-50 + VQ-GAN) + Text (BPE) -> Unified Vocabulary (59,457 tokens) -> Shared Encoder-Decoder Transformer -> Generated Tokens -> Decoded Output

- **Critical path**: The Unified Vocabulary is the linchpin. The entire model hinges on the successful discretization of images into tokens that can be processed alongside text tokens by the same transformer. If this step fails (e.g., poor image reconstruction), downstream tasks suffer.

- **Design tradeoffs**:
  - Continual Pre-training vs. From Scratch: The paper shows continual training from the general-domain OFA model is more efficient (half the epochs) and performs better. However, it may inherit biases or limitations from the original model.
  - Unified Model vs. Specialist Ensembles: A single BiomedGPT model is more efficient and easier to deploy than an ensemble of specialized models, but may not reach the peak performance of a specialist on a single task.

- **Failure signatures**:
  - Modality Bias: The model ignores image input and answers VQA questions using only textual priors.
  - Hallucination in Generation: The model generates fluent but factually incorrect medical statements.
  - Performance Saturation: Adding more data or parameters yields diminishing returns, as seen with BiomedGPT-Large sometimes underperforming Base on certain datasets.

- **First 3 experiments**:
  1. Reproduce a Single Task Fine-Tuning: Pick one dataset (e.g., PathMNIST) and fine-tune the pre-trained BiomedGPT-Base model. Verify the setup by matching the paper's reported accuracy.
  2. Ablate Input Modality: On a VQA task (e.g., SLAKE), run inference with the image input replaced by a blank or noise tensor. Compare performance to quantify the model's reliance on visual vs. textual information.
  3. Test Zero-Shot Transfer: Use the instruction-tuned Instruct-BiomedGPT model on a new, held-out biomedical instruction prompt not present in the training set. Qualitatively assess the alignment and correctness of its response.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the clinical utility of BiomedGPT outputs compare to human expert standards when evaluated beyond automated surface-level metrics?
- **Basis in paper**: The authors state they "mainly used automated machine evaluation scores... which may not reflect the real-world evaluation of humans."
- **Why unresolved**: The study relied on metrics like ROUGE-L and Accuracy rather than clinical fact-checking or expert preference.
- **What evidence would resolve it**: A human-subject evaluation study where clinicians blindly rate BiomedGPT summaries against human-written ones for factual accuracy and clinical relevance.

### Open Question 2
- **Question**: Can the current BiomedGPT architecture be effectively extended to process temporal data modalities such as medical video and time-series EHR data?
- **Basis in paper**: The authors conclude that "Future studies should explore additional data modalities such as video and time-series data."
- **Why unresolved**: The current model processes static images (via ResNet/VQ-GAN) and text, lacking architectural components for temporal feature extraction.
- **What evidence would resolve it**: Successful integration of temporal encoders into the unified vocabulary, followed by benchmarking on video-based medical datasets.

### Open Question 3
- **Question**: Does balancing the instruction-tuning dataset to reduce the dominance of radiology images improve performance stability for underrepresented modalities like gross pathology?
- **Basis in paper**: The authors note the instruction data "is not evenly distributed across modalities, with a higher proportion of radiology images compared to gross pathology."
- **Why unresolved**: The study did not ablate the effect of modality imbalance in the instruction-tuning phase, leaving the specific performance penalty for pathology unknown.
- **What evidence would resolve it**: A comparative analysis of models trained on the current imbalanced dataset versus a curated, modality-balanced version of BioMed-VITAL.

## Limitations

- **Data Quality Concerns**: The instruction-tuning dataset (BioMed-VITAL) was generated using GPT-4, raising potential concerns about hallucinations or systematic biases being incorporated into the model's behavior.
- **Task Distribution Bias**: The evaluation focuses heavily on classification and text understanding tasks, with fewer complex generation tasks, potentially overestimating real-world applicability.
- **Scale Diminishing Returns**: BiomedGPT-Large sometimes underperforms the Base model on certain datasets, suggesting that simply adding parameters without architectural innovations yields inconsistent benefits.

## Confidence

**High Confidence Claims** (Supported by direct experimental evidence):
- BiomedGPT-XLarge achieves SOTA performance on 15/23 datasets
- Scaling improves performance on long-text tasks (4.6-11.4% gains in summarization)
- Instruction tuning improves zero-shot performance (12.5-45.3% accuracy gains)
- Fine-tuning on long-text data enables better handling of extended contexts

**Medium Confidence Claims** (Reasonable but less directly tested):
- Unified tokenization enables effective cross-modal reasoning
- Instruction tuning provides better alignment than task-specific fine-tuning
- The models will generalize to novel clinical tasks beyond evaluated benchmarks

**Low Confidence Claims** (Speculative or minimally tested):
- The instruction-tuning dataset quality claims relative to alternatives
- That the observed scaling benefits will continue with further parameter increases
- That the models avoid the "blind faith in text" problem common to VLMs

## Next Checks

1. **Safety and Bias Audit**: Systematically evaluate the instruction-tuned models on adversarial prompts, clinically dangerous scenarios, and diverse demographic groups to identify potential harm vectors before clinical deployment consideration.

2. **Cross-Domain Transfer Validation**: Test the models on entirely new biomedical domains (e.g., rare disease imaging, novel molecular structures) not represented in the training or fine-tuning datasets to verify genuine capability generalization versus benchmark memorization.

3. **Clinical Expert Evaluation**: Conduct blinded comparisons between model outputs and clinician decisions on a representative sample of complex cases to establish real-world clinical utility and identify scenarios where model confidence exceeds competence.