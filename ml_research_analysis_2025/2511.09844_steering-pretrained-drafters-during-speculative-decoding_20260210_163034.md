---
ver: rpa2
title: Steering Pretrained Drafters during Speculative Decoding
arxiv_id: '2511.09844'
source_url: https://arxiv.org/abs/2511.09844
tags:
- drafter
- steering
- decoding
- pretrained
- speculative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses the challenge of improving token acceptance\
  \ rates in speculative decoding when using pretrained drafters, especially in scenarios\
  \ where verification latency dominates or the input is out of distribution. The\
  \ authors introduce a lightweight dynamic alignment mechanism called SD\xB2, which\
  \ generates a steering vector from the verifier\u2019s hidden states and injects\
  \ it into the pretrained drafter via bias terms in MLP layers."
---

# Steering Pretrained Drafters during Speculative Decoding

## Quick Facts
- arXiv ID: 2511.09844
- Source URL: https://arxiv.org/abs/2511.09844
- Reference count: 13
- Primary result: SD² boosts accepted tokens by up to 35% under standard sampling and 22% under greedy sampling while maintaining negligible computational overhead

## Executive Summary
This work addresses the challenge of improving token acceptance rates in speculative decoding when using pretrained drafters, especially in scenarios where verification latency dominates or the input is out of distribution. The authors introduce a lightweight dynamic alignment mechanism called SD², which generates a steering vector from the verifier's hidden states and injects it into the pretrained drafter via bias terms in MLP layers. This allows the drafter to be guided at inference time without requiring extensive retraining or distillation. Experiments show that SD² boosts the number of accepted tokens by up to 35% under standard sampling and 22% under greedy sampling, while maintaining negligible computational overhead. It also consistently outperforms distillation-based approaches in block efficiency and throughput across multiple model pairs and tasks.

## Method Summary
SD² extracts hidden states from the verifier's layers 3, L/2, and L-2 at the position of first rejected token, concatenates them, and projects through a linear layer to form a steering vector. This vector is injected as a bias into the drafter's MLP up-projections via SwiGLU layers. The method fine-tunes the drafter and steering weights jointly using KL divergence loss with random offsets during training. This dynamic alignment enables the pretrained drafter to generate tokens more likely to be accepted by the verifier, improving speculative decoding efficiency without the need for distillation.

## Key Results
- SD² improves token acceptance rates by up to 35% under standard sampling and 22% under greedy sampling
- Achieves 61% throughput improvement on Vicuna 1.3 + Llama 3.2 pair, outperforming distillation-based approaches
- Maintains negligible computational overhead compared to transformer inference latency

## Why This Works (Mechanism)

### Mechanism 1: Hidden-State-to-Steering Extraction
- **Claim:** Verifier hidden states encode predictive information about future tokens that can be extracted to guide the drafter.
- **Mechanism:** The verifier's intermediate representations at layers 3, L/2, and L-2 are concatenated and linearly projected to form a steering vector g_t = W_hml[h_t, m_t, l_t]^T. This vector captures multi-scale predictive signals.
- **Core assumption:** Auto-regressive models implicitly encode information about tokens beyond the immediate next token (Assumption: cited as Samragh et al. 2025, not independently validated in this paper).
- **Evidence anchors:**
  - [abstract] "steering vector computed from the verifier's hidden states and injected into the pretrained drafter"
  - [section 3.1] "Similar to EAGLE-3 we use a linear layer, which is applied on the concatenation of h_t, m_t, l_t"
  - [corpus] No direct corpus validation; mechanism is novel to this paper
- **Break condition:** If verifier hidden states do not contain sufficient predictive information about future tokens, steering vector will provide no useful signal; performance degrades to pretrained drafter baseline.

### Mechanism 2: MLP Bias Injection via SwiGLU Modification
- **Claim:** Injecting steering vectors as biases into MLP up-projections provides precise control over drafter behavior with minimal latency overhead.
- **Mechanism:** The standard SwiGLU computation a(l)_(t+i) → W_d(W_u·a(l)_(t+i) ⊙ σ(W_g·a(l)_(t+i))) is modified to a(l)_(t+i), g_t → W_d((W_u·a(l)_(t+i) + W_s·g_t) ⊙ σ(W_g·a(l)_(t+i))). The term W_s·g_t is computed once per drafting phase and added across all layers.
- **Core assumption:** Conditioning MLP computations on steering vectors allows meaningful adjustment of token probability distributions without architectural redesign.
- **Evidence anchors:**
  - [abstract] "injected into the pretrained drafter via bias terms in MLP layers"
  - [section 3.2] "This ensures that the added overhead is negligible compared to the latency of the transformer"
  - [corpus] Corpus contains no comparable MLP bias injection methods for speculative decoding
- **Break condition:** If W_s·g_t creates incoherent representations (e.g., producing nonsensical tokens as in Table 2), steering degrades output quality; safety-critical applications require fallback to unsteered mode.

### Mechanism 3: Offset-Based Training Alignment
- **Claim:** Training with random offsets δ ∈ [1, k] forces the steering mechanism to encode information useful across all drafting positions.
- **Mechanism:** During training, compute π_D(x_t | x_(1:t-1), g_(t-δ)) with uniformly sampled δ. This exposes the steering mechanism to gradients at all positions within the draft block, encouraging generalization.
- **Core assumption:** Position-agnostic steering requires diverse positional training signals; joint fine-tuning of drafter weights improves alignment beyond steering alone.
- **Evidence anchors:**
  - [section 3.3] "we utilize a uniformly random offset δ ∈ [1, k]... This ensures that the steering mechanism uniformly receives gradients for all drafting positions"
  - [section 4.1, Figure 6] Ablation shows frozen drafter achieves +100% acceptance over baseline, but unfrozen drafter yields consistently better results
  - [corpus] No corpus papers validate offset-based training for speculative decoding
- **Break condition:** If training data is narrow or low-quality, both steering mechanism and drafter overfit (observed in HumanEval/GSM8K where distilled drafter underperforms pretrained).

## Foundational Learning

- **Concept: Speculative Decoding (Draft-Verify Paradigm)**
  - **Why needed here:** SD² modifies this foundational paradigm by adding steering vector computation during verification and conditioning during drafting.
  - **Quick check question:** Can you explain why verification latency (not just drafting speed) determines whether block efficiency or drafting throughput matters more?

- **Concept: Activation Steering / Representation Engineering**
  - **Why needed here:** SD² applies dynamic activation steering to speculative decoding, assuming verifier states encode steerable directions.
  - **Quick check question:** What is the linear representation hypothesis, and why does it motivate adding biases to activations rather than modifying weights?

- **Concept: SwiGLU Architecture**
  - **Why needed here:** The steering injection point (between up-projection and gating) is architecture-specific; understanding SwiGLU is required for correct implementation.
  - **Quick check question:** Where does SD² inject the steering bias, and why must this happen before the gating operation?

## Architecture Onboarding

- **Component map:**
  - Verifier (frozen) -> Extract hidden states (layers 3, L/2, L-2) -> Steering Vector Projector (linear W_hml + LayerNorm) -> Bias Generator (linear W_s) -> Drafter (fine-tuned) -> MLP layers with bias injection

- **Critical path:**
  1. Verifier forward pass → reject token at position t
  2. Extract h_t, m_t, l_t → compute g_t = LayerNorm(W_hml·[h_t, m_t, l_t])
  3. Compute W_s·g_t once per draft phase
  4. Drafter generates tokens with MLP bias injection at each layer
  5. Verifier validates draft; repeat

- **Design tradeoffs:**
  - **Steering mechanism expressiveness vs. latency:** Adding 2-layer MLP for bias computation (ablated variant) increases control but adds overhead; paper chooses single linear projection.
  - **Drafter fine-tuning vs. modularity:** Unfreezing drafter improves results (Figure 6) but requires retraining; frozen drafter preserves plug-and-play modularity.
  - **Training data breadth vs. domain specialization:** UltraChat training generalizes poorly to HumanEval/GSM8K (Table 1); domain-specific steering requires domain-specific training.

- **Failure signatures:**
  - **Incoherent output:** Table 2 shows SD² can produce non-English tokens ([?]) when steering interferes incorrectly; indicates W_s initialization or steering magnitude issues.
  - **No improvement over pretrained:** Observed on GSM8K/HumanEval for Qwen and Llama pairs (Table 1); indicates drafter-verifier already well-aligned or training data mismatch.
  - **Overhead dominates:** If W_s·g_t computation adds latency exceeding acceptance gains, throughput decreases (not observed in paper but possible on very fast hardware).

- **First 3 experiments:**
  1. **Reproduce Vicuna 1.3 + Llama 160M baseline:** This pair shows largest gains (61% throughput improvement); train SD² on UltraChat, evaluate block efficiency τ and speedup α.
  2. **Ablate steering mechanism variants:** Compare (a) bias after MLP, (b) bias in MLP before gating (SD²), (c) 2-layer MLP bias generator; measure τ and latency per draft step.
  3. **Test out-of-distribution generalization:** Train on UltraChat, evaluate on HumanEval and GSM8K; compare SD² vs. distilled vs. pretrained to verify robustness claim.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can SD² be effectively extended to complex speculative decoding paradigms like dynamic tree verification?
  - **Basis in paper:** [explicit] The authors state, "extending SD² to more complex speculative decoding paradigms, such as dynamic tree verification, remains an open problem."
  - **Why unresolved:** The current method is validated on chain drafting strategies; it is unclear how the steering mechanism interacts with the branching logic and parallel verification structures of tree-based methods.
  - **What evidence would resolve it:** Empirical results showing block efficiency and throughput when SD² is integrated into a tree-based speculative decoding system.

- **Open Question 2:** Does training a drafter explicitly for dynamic steering from scratch outperform retrofitting existing pretrained models?
  - **Basis in paper:** [explicit] The paper notes, "we do not explore the training of new drafters explicitly designed for dynamic steering, which we leave as an open direction for future work."
  - **Why unresolved:** The current approach fine-tunes existing drafters; a model architected specifically to accept steering vectors might utilize the verifier's hidden states more efficiently or with higher alignment.
  - **What evidence would resolve it:** A comparative study between a drafter trained from scratch with the SD² objective versus the current fine-tuning approach.

- **Open Question 3:** Does the proposed steering mechanism generalize to architectures using gated activations other than SwiGLU?
  - **Basis in paper:** [explicit] The authors list this as a limitation: "While our steering mechanism should generalize to other gated activations, this remains to be validated in future work."
  - **Why unresolved:** All models tested (Llama, Qwen, Vicuna) utilize SwiGLU; the mathematical interaction between the injected bias and alternative gating functions (e.g., GeGLU) is currently unproven.
  - **What evidence would resolve it:** Successful application and maintenance of acceptance rates when applying SD² to transformer models utilizing non-SwiGLU gated activation layers.

## Limitations

- Variable performance across model pairs, with minimal gains on some configurations
- Potential safety concerns with steering producing nonsensical tokens when mechanism interferes incorrectly
- Limited generalization to out-of-distribution tasks like code and math

## Confidence

**High Confidence Claims:**
- SD² can improve token acceptance rates compared to pretrained drafters when training data matches the target distribution
- The computational overhead of steering vector computation is negligible compared to transformer inference latency
- Joint fine-tuning of drafter weights improves steering effectiveness compared to frozen-drafter baselines

**Medium Confidence Claims:**
- SD² consistently outperforms distillation-based approaches across all tested scenarios (evidence shows distillation fails on certain model pairs)
- SD² generalizes to out-of-distribution tasks (limited evidence; HumanEval/GSM8K results mixed)
- SD² provides a general solution for integrating pretrained drafters into speculative decoding (contradicted by variable performance)

**Low Confidence Claims:**
- Verifier hidden states at layers 3, L/2, and L-2 are optimal for steering (no ablation study)
- The linear steering mechanism is sufficient for capturing complex predictive relationships (no comparison to more expressive alternatives)
- SD² is broadly applicable across different model architectures and domains (strong performance on chat data but weak on code/math)

## Next Checks

1. **Layer Ablation Study:** Systematically test steering from individual layers (only layer 3, only L/2, only L-2) and different combinations to determine whether the three-layer approach is optimal or merely sufficient. Compare against using all layers or different layer selections.

2. **Safety and Robustness Testing:** Conduct adversarial evaluation where steering vectors are perturbed or corrupted to test model robustness. Implement safety mechanisms that fall back to unsteered generation when steering produces low-confidence or out-of-distribution outputs.

3. **Cross-Domain Training Transfer:** Train SD² on UltraChat, then evaluate transfer to code (HumanEval), math (GSM8K), and multilingual tasks. Measure performance degradation and identify whether domain-specific fine-tuning is necessary for each application area.