---
ver: rpa2
title: 'Beyond Internal Data: Constructing Complete Datasets for Fairness Testing'
arxiv_id: '2507.18561'
source_url: https://arxiv.org/abs/2507.18561
tags:
- data
- synthetic
- datasets
- fairness
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of evaluating classifier fairness
  when complete datasets including protected attributes are inaccessible. The authors
  propose a method to construct synthetic datasets by leveraging separate overlapping
  datasets and learning their joint distribution, enabling fairness testing without
  requiring sensitive demographic data.
---

# Beyond Internal Data: Constructing Complete Datasets for Fairness Testing

## Quick Facts
- arXiv ID: 2507.18561
- Source URL: https://arxiv.org/abs/2507.18561
- Authors: Varsha Ramineni; Hossein A. Rahmani; Emine Yilmaz; David Barber
- Reference count: 40
- One-line primary result: Synthetic test data from overlapping datasets enables accurate fairness testing when protected attributes are unavailable, with fidelity metrics above 0.966 and fairness metric differences as low as 0.000-0.015.

## Executive Summary
This work addresses the challenge of evaluating classifier fairness when complete datasets including protected attributes are inaccessible. The authors propose a method to construct synthetic datasets by leveraging separate overlapping datasets and learning their joint distribution, enabling fairness testing without requiring sensitive demographic data. They evaluate their approach using three real-world datasets (Adult, COMPAS, German Credit) and compare synthetic test data generated through various joint distribution estimation methods against real data.

## Method Summary
The method leverages two separate datasets with at least one overlapping variable to construct complete synthetic test data. Using structural independence assumptions (Independence Given Overlap, Marginal Preservation, or Latent Naïve Bayes), the joint distribution p(x₁, x₂, x₃, x₄) is estimated from marginal observations. Synthetic samples are then drawn from this estimated joint distribution, including protected attributes absent from the internal data. The approach is validated by comparing fairness metrics computed on synthetic data against those from real test data, showing high fidelity and accurate fairness metric estimation.

## Key Results
- Synthetic datasets show high fidelity to real data with 1-TVD values above 0.966 and low KL divergence (0.001-0.002) for protected attribute-outcome relationships
- Fairness metrics (AOD, DI, EOD) computed on synthetic data closely match those from real data, with absolute differences as low as 0.000-0.015
- Proposed methods outperform baseline approaches including CTGAN, despite CTGAN having access to complete data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic test data generated from separate overlapping datasets can accurately reconstruct the joint distribution needed for fairness metric computation.
- Mechanism: Two datasets with at least one overlapping variable are combined using structural independence assumptions to estimate the full joint distribution. This enables sampling complete synthetic records that include protected attributes absent from internal data.
- Core assumption: Marginal consistency—all marginal distributions originate from a common underlying joint distribution.
- Evidence anchors: [abstract] states the approach uses "separate overlapping datasets" to construct complete synthetic data; [section 3.1] describes using "marginal data observations and a structural independence assumption" for joint distribution estimation.

### Mechanism 2
- Claim: Simple structural assumptions suffice for high-fidelity reconstruction when overlap variables capture meaningful correlations.
- Mechanism: Three methods impose different conditional independence structures. "Independence Given Overlap" assumes x₄ ⊥ (x₁,x₂) | x₃; "Marginal Preservation" directly uses empirical marginals; "Latent Naïve Bayes" introduces a latent variable Z with conditional independence given Z.
- Core assumption: The overlapping variable carries sufficient information about the dependency structure between protected attributes and model features.
- Evidence anchors: [section 5.1] shows synthetic datasets demonstrate high fidelity with average 1-TVD values of 0.991, 0.978, and 0.966 for Adult, COMPAS, and German respectively.

### Mechanism 3
- Claim: Fairness metrics computed on synthetic data closely approximate real-data metrics because the joint distribution p(Protected Attribute, Outcome) is accurately preserved.
- Mechanism: KL divergence D_KL(p_synth(A,Y) || p_real(A,Y)) is minimized during generation, ensuring the key joint distribution for group disparity calculations matches ground truth.
- Core assumption: Fairness metrics depend primarily on the joint distribution of (A, Y, Ŷ), not on fine-grained higher-order dependencies.
- Evidence anchors: [section 5.3] reports "absolute differences of 0.000 in bootstrap means for AOD and DI values for race" on the COMPAS dataset.

## Foundational Learning

- Concept: Joint Distribution Estimation from Marginals
  - Why needed here: The core technical challenge is reconstructing p(all variables) when only p(subset₁) and p(subset₂) are observed.
  - Quick check question: Given p(X, Y) and p(Y, Z), can you write down the "Independence Given Overlap" factorization for p(X, Y, Z)?

- Concept: Fairness Metrics (EOD, DI, AOD)
  - Why needed here: These are the target quantities being estimated; understanding their dependence on joint distributions is essential.
  - Quick check question: Which metric requires knowing P(Ŷ=+ | Y=+, A) versus just P(Ŷ=+ | A)?

- Concept: Total Variation Distance and KL Divergence
  - Why needed here: These measure how close synthetic distributions are to real distributions; low values validate the approach.
  - Quick check question: If 1-TVD = 0.99, what is the maximum difference in probability mass on any single outcome?

## Architecture Onboarding

- Component map:
  - Data Separator: Splits complete ground-truth data into "internal" (model features + outcome) and "external" (protected attributes + overlap variable)
  - Joint Distribution Estimator: Three variants that learn p(X₁, X₂, X₃, X₄) from separated marginals
  - Synthetic Sampler: Draws N samples from estimated joint distribution to create synthetic test set
  - Fairness Metric Computer: Calculates EOD, DI, AOD on both synthetic and real test data for comparison
  - Fidelity Evaluator: Computes 1-TVD, Contingency Similarity, KL divergence to validate synthetic data quality

- Critical path:
  1. Identify overlapping variable(s) between internal and external datasets
  2. Fit joint distribution using chosen estimation method
  3. Sample synthetic test data with all attributes
  4. Query black-box classifier on synthetic data
  5. Compute fairness metrics and compare to any available real benchmark

- Design tradeoffs:
  - More overlap variables → better reconstruction but harder data procurement
  - Latent Naïve Bayes → captures more complex dependencies but requires EM training and hyperparameter K
  - Marginal Preservation → simplest implementation but assumes one marginal is fully reliable
  - Sample size → larger synthetic datasets reduce metric variance but increase computational cost

- Failure signatures:
  - KL divergence > 0.1 for p(A, Y) indicates poor reconstruction of protected-attribute-outcome relationship
  - Large discrepancy (>0.05) between fairness metrics on synthetic vs. real data signals fundamental distribution mismatch
  - Discriminator Measure > 0.75 suggests synthetic data is easily distinguishable from real data

- First 3 experiments:
  1. Replicate Adult dataset experiment with "relationship" as overlap variable using Independence Given Overlap method; verify 1-TVD > 0.99 and KL divergence < 0.005
  2. Test sensitivity: vary the overlap variable choice and measure impact on fairness metric accuracy
  3. Stress test: artificially reduce external dataset size to 10% and observe degradation in KL divergence and fairness metric fidelity

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the approach perform when applied to actual disparate real-world data sources rather than simulated separated datasets?
- **Basis in paper:** The authors state in the Conclusion that "future research could explore incorporating real public data and more complex data scenarios to validate the results obtained."
- **Why unresolved:** The experiments rely on simulating data scarcity by splitting complete datasets into internal and external subsets, ensuring the existence of a ground truth joint distribution that may not exist in truly separate real-world data.
- **What evidence would resolve it:** Empirical validation using a proprietary internal dataset and a truly distinct public dataset where the underlying joint distribution is not guaranteed to be consistent.

### Open Question 2
- **Question:** Can the constraints of marginal distributions be used to define reliable bounds for fairness metrics rather than point estimates?
- **Basis in paper:** The Conclusion suggests future work could "explore all feasible joint distributions that meet the constraints of the available marginal distributions, and thus work towards defining bounds within which the true fairness metrics are likely to fall."
- **Why unresolved:** The current method relies on structural assumptions to estimate a single joint distribution, which does not capture the uncertainty or the range of possible fairness values compatible with the marginals.
- **What evidence would resolve it:** A methodological framework that maps the space of valid joint distributions to a bounded interval for metrics like Disparate Impact, verified against real data.

### Open Question 3
- **Question:** How can the joint estimation methods be scaled to handle multiple overlapping datasets with complex dependency structures?
- **Basis in paper:** The authors note in Section 3.1.4 that real-world datasets may involve multiple overlaps, and while Latent Naïve Bayes offers an extension, "alternative approaches such as using Junction Trees... is left for future research."
- **Why unresolved:** The proposed methods and experiments are restricted to combining two datasets with a single overlapping variable, simplifying the graphical model structure required.
- **What evidence would resolve it:** An implementation using Junction Trees or similar graphical models to successfully integrate three or more datasets with multiple overlapping variables while maintaining fidelity.

## Limitations
- Structural assumptions required for joint distribution estimation may not hold in practice
- Performance depends heavily on careful variable selection and availability of meaningful overlapping variables
- Comparison against CTGAN uses default hyperparameters which may not represent CTGAN's full potential

## Confidence
- Core claim validation: High (strong empirical results across three datasets)
- General applicability: Medium (depends on structural assumptions and variable availability)
- Methodological robustness: Medium (unclear hyperparameter sensitivity and distribution drift handling)

## Next Checks
1. **Overlap Variable Sensitivity**: Systematically test different overlapping variables on the same dataset and measure impact on KL divergence and fairness metric accuracy
2. **Distribution Drift Assessment**: Introduce controlled shifts between internal and external marginal distributions and quantify degradation in synthetic data fidelity
3. **Sample Size Scaling**: Vary the size of the external dataset (10% to 100%) and measure how KL divergence and fairness metric differences scale