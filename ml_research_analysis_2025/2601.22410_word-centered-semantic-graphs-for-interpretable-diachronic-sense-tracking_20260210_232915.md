---
ver: rpa2
title: Word-Centered Semantic Graphs for Interpretable Diachronic Sense Tracking
arxiv_id: '2601.22410'
source_url: https://arxiv.org/abs/2601.22410
tags:
- semantic
- sense
- word
- time
- year
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of tracking semantic shift in
  diachronic corpora, particularly for polysemous words. It introduces a graph-based
  framework that constructs word-centered semantic networks by integrating distributional
  similarity from static Skip-gram embeddings with lexical substitutability from fine-tuned
  masked language models.
---

# Word-Centered Semantic Graphs for Interpretable Diachronic Sense Tracking

## Quick Facts
- **arXiv ID:** 2601.22410
- **Source URL:** https://arxiv.org/abs/2601.22410
- **Reference count:** 18
- **Primary result:** Graph-based framework for tracking polysemous word sense evolution using combined static and contextual embeddings

## Executive Summary
This paper introduces a graph-based framework for tracking semantic shift in diachronic corpora, particularly for polysemous words. The method constructs word-centered semantic networks by integrating distributional similarity from static Skip-gram embeddings with lexical substitutability from fine-tuned masked language models. Applied to New York Times Magazine articles (1980-2017), it reveals distinct semantic trajectories: event-driven sense replacement (trump), semantic stability with cluster over-segmentation (god), and gradual association shifts tied to digital communication (post).

## Method Summary
The method constructs a graph for each target word in each time slice by combining distributional neighbors from time-sliced Word2Vec SGNS models with substitution neighbors from fine-tuned RoBERTa models. The target word node is removed to create a peripheral graph, and connected components are extracted as sense communities. Sense evolution is tracked by aligning clusters across time using node overlap and estimating sense distributions via normalized cluster sizes.

## Key Results
- Successfully identified event-driven sense replacement for "trump" (card game â†’ political figure)
- Revealed semantic stability for "god" with cluster over-segmentation artifacts
- Tracked gradual semantic shift for "post" from communication to digital context
- Demonstrated interpretability through visualizable semantic networks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating global distributional similarity with local lexical substitutability creates a more robust semantic neighborhood than either signal alone.
- **Mechanism:** Static Skip-gram embeddings capture broad topical associations while fine-tuned Masked Language Model (RoBERTa) predictions capture context-specific substitutes. The union of these neighbor sets forms the first layer of the graph, grounding the representation in both stable similarity and dynamic usage.
- **Core assumption:** Distributional neighbors and substitution neighbors provide complementary, non-redundant evidence for a word's meaning.
- **Evidence anchors:** Section 3.1 describes the two complementary types of semantic relations used.

### Mechanism 2
- **Claim:** Peripheral connectivity clustering isolates distinct senses by removing the "semantic hub" effect of the target word.
- **Mechanism:** By deleting the target node from the constructed graph, only neighbors with direct semantic edges remain connected. The resulting connected components function as distinct sense clusters.
- **Core assumption:** Words sharing a specific sense will share direct edges between themselves, whereas words from different senses will only be connected through the central target word.
- **Evidence anchors:** Section 3.2 explains the peripheral graph construction and clustering approach.

### Mechanism 3
- **Claim:** Normalized cluster mass serves as a proxy for sense frequency, allowing for the tracking of dominance shifts without discrete sense inventories.
- **Mechanism:** By calculating the size of each connected component relative to the total graph size, the method infers the probability of a sense being used. Tracking this relative mass over time reveals if a sense is expanding, contracting, or being replaced.
- **Core assumption:** The size of the induced graph neighborhood correlates linearly with the actual usage frequency of that sense in the corpus.
- **Evidence anchors:** Section 3.4 describes estimating usage distribution based on cluster sizes.

## Foundational Learning

- **Concept:** Skip-gram vs. Contextual Embeddings (RoBERTa)
  - **Why needed here:** Understanding that Skip-gram yields one static vector per word (blending senses) while RoBERTa yields dynamic vectors based on context (separating senses) is crucial for why both are extracted.
  - **Quick check question:** Does the static embedding for "bank" distinguish between river and finance in this architecture, or does the graph structure handle that separation?

- **Concept:** Graph Connected Components
  - **Why needed here:** This is the core clustering logic - the method uses topological connectivity in a graph after node removal, not vector clustering.
  - **Quick check question:** If you remove node $w$ and the remaining graph is fully connected (one component), what does that imply about the polysemy of $w$?

- **Concept:** Jaccard Similarity / Node Overlap
  - **Why needed here:** This is the alignment mechanism - to track a sense from 1990 to 2000, the system calculates the overlap of nodes in the clusters.
  - **Quick check question:** Why is aligning clusters via node overlap more robust here than aligning vector spaces (e.g., Procrustes alignment)?

## Architecture Onboarding

- **Component map:** Embedding Trainers -> Graph Constructor -> Sense Extractor -> Tracker
- **Critical path:** The Substitution Neighbor Extraction. This requires running inference with a fine-tuned MLM on the specific corpus slice. If the masking or fine-tuning is flawed, the graph edges will not reflect true substitutability.
- **Design tradeoffs:**
  - Alignment Window: Aligning to previous period detects transient spikes but causes fragmentation; aligning to all history is stable but may miss new senses.
  - Graph Depth (L): Depth L=2 is used; deeper graphs capture indirect associations but risk diluting specific sense signals.
- **Failure signatures:**
  - Over-segmentation: Many small clusters for monosemous words indicates graph connectivity is too sparse.
  - Residual Dominance: Most nodes in "Residual" cluster indicates overlap threshold is too high or vocabulary shift is too rapid.
- **First 3 experiments:**
  1. Sense Separation Validation: Run pipeline on "trump" and "god" to verify expected splitting vs. stability patterns.
  2. Alignment Sensitivity: Implement both "previous period" and "all history" alignment for fast-changing word; compare cluster counts and residual sizes.
  3. Neighbor Ablation: Construct graphs using only distributional vs. only substitution neighbors; observe sense cluster degradation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the proposed graph-based framework perform on established semantic change detection benchmarks compared to state-of-the-art embedding or contextual methods?
- **Basis in paper:** [explicit] The authors explicitly state in the Limitations section: "We did not evaluate our method on benchmarks corpora yet."
- **Why unresolved:** The paper focuses on a qualitative application study for interpretability rather than competitive detection performance.
- **What evidence would resolve it:** Quantitative evaluation on standard benchmarks (e.g., SemEval-2020 Task 1) showing performance metrics against baseline models.

### Open Question 2
- **Question:** To what extent do variations in graph construction hyperparameters (neighbor set sizes $k_i, k_c$ and depth $L$) alter the detected sense communities and their temporal stability?
- **Basis in paper:** [explicit] The Limitations section notes that the graphs depend on fixed hyperparameters and that "Different settings may change the number of clusters, the degree of fragmentation, and the apparent stability of senses."
- **Why unresolved:** The study utilizes a fixed configuration without conducting sensitivity analysis or ablation studies on these structural parameters.
- **What evidence would resolve it:** A systematic ablation study measuring cluster consistency and sense tracking metrics across varying hyperparameter settings.

### Open Question 3
- **Question:** Can the method distinguish between persistent semantic change and transient shifts driven by specific event coverage in diverse or multi-source corpora?
- **Basis in paper:** [explicit] The authors note a "Corpus and domain bias" limitation, acknowledging that "Some observed changes are transient and event-driven, reflecting shifts in coverage rather than persistent changes in general language."
- **Why unresolved:** The analysis relies solely on a single-source corpus (New York Times Magazine) which introduces editorial biases that may conflate usage shifts with topic shifts.
- **What evidence would resolve it:** Application of the framework to a multi-genre, multi-source diachronic corpus where ephemeral event-driven changes can be cross-validated or filtered out.

## Limitations

- The method's reliance on static Skip-gram embeddings may cause the graph to link semantically distant concepts through shared distributional neighbors.
- Peripheral connectivity clustering may fail for metaphorical or domain-specific extensions where senses share significant vocabulary.
- The claim that "normalized cluster mass" is a proxy for "sense frequency" conflates graph topology with underlying language usage.

## Confidence

- **High Confidence:** Core graph construction methodology is well-defined and reproducible; qualitative examples are internally consistent.
- **Medium Confidence:** Peripheral clustering is reasonable but untested on complex polysemy; alignment strategy trade-off is clearly explained but optimal choice not established.
- **Low Confidence:** Claim that cluster mass is direct proxy for sense frequency is not empirically validated; robustness to noisy substitution signals is not demonstrated.

## Next Checks

1. **Substitution Signal Robustness:** For a word known to have shifted (e.g., "tweet"), compare graph and cluster structure using only distributional vs. only substitution neighbors; measure drop in F1 score for sense separation.

2. **Frequency Proxy Validation:** For a set of target words, compute correlation between normalized cluster mass for a specific sense and its actual relative frequency in the corpus (measured by counting occurrences).

3. **Peripheral Clustering Edge Case:** Select a word with known metaphorical extension (e.g., "head" in anatomical vs. leadership contexts); construct peripheral graph and manually verify if senses form disconnected components.