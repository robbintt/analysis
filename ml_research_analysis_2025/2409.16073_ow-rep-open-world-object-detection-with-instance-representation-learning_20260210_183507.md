---
ver: rpa2
title: 'OW-Rep: Open World Object Detection with Instance Representation Learning'
arxiv_id: '2409.16073'
source_url: https://arxiv.org/abs/2409.16073
tags:
- unknown
- objects
- object
- known
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method for open-world object detection that
  simultaneously detects unknown objects and learns semantically rich instance embeddings.
  It addresses the challenge of capturing fine-grained semantic relationships between
  detected objects, which is essential for applications like open-world tracking and
  novel class discovery.
---

# OW-Rep: Open World Object Detection with Instance Representation Learning

## Quick Facts
- arXiv ID: 2409.16073
- Source URL: https://arxiv.org/abs/2409.16073
- Authors: Sunoh Lee; Minsik Jeon; Jihong Min; Junwon Seo
- Reference count: 40
- Primary result: Achieves state-of-the-art open-world object detection with Unknown Recall of 30.56 and Recall@1 of 11.69 on OWOD split

## Executive Summary
This paper introduces OW-Rep, a method for open-world object detection that simultaneously detects unknown objects and learns semantically rich instance embeddings. The approach leverages Vision Foundation Models (VFMs) through two modules: the Unknown Box Refine Module uses SAM to accurately localize unknown objects, while the Embedding Transfer Module distills instance-wise semantic similarities from DINOv2 features to the detector's embeddings. This enables the detector to learn a semantically meaningful and generalizable instance feature space. Experimental results show significant improvements in unknown object detection and instance embedding quality compared to existing methods, while also enhancing performance in downstream tasks like open-world tracking.

## Method Summary
OW-Rep extends the deformable DETR-based PROB detector with two VFM-based modules for open-world object detection. The Unknown Box Refine Module selects top-k unknown proposals by objectness score, uses them as SAM prompts to generate instance masks, and derives refined bounding boxes. The Embedding Transfer Module distills instance-wise semantic similarities from DINOv2 features to the detector's embeddings using a relaxed contrastive loss. Both modules are trained jointly with the base detector, with VFMs frozen during training. The method achieves faster inference than VFM-based approaches while maintaining superior embedding quality.

## Key Results
- Unknown Recall of 30.56 on OWOD split, significantly outperforming existing methods
- Recall@1 of 11.69 for instance embedding quality, demonstrating semantically meaningful feature space
- Enhanced performance in open-world tracking with A-Accuracy of 70.65 and OWTA of 60.49
- Inference speed of 47.2ms, faster than VFM-based methods (80.9ms) while maintaining quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Refining unknown object boxes with SAM masks improves localization accuracy for subsequent feature learning
- Core assumption: SAM's segmentation generalizes to objects outside the detector's known classes, and initial detector proposals are close enough for SAM to refine successfully
- Evidence: Abstract mentions SAM accurately localizes unknown objects; section 3.3 describes the IoU filtering approach
- Break condition: If initial unknown proposals have very low quality (IoU < κ consistently), the refinement pipeline receives insufficient valid supervision

### Mechanism 2
- Claim: Distilling pairwise semantic similarities from DINOv2 via relaxed contrastive loss yields more semantically meaningful embeddings than binary contrastive learning
- Core assumption: DINOv2's self-supervised features capture transferable semantic relationships for both known-unknown and unknown-unknown objects
- Evidence: Abstract mentions relaxed contrastive loss; section 3.4 explains the adjustment of pushing/pulling strength based on semantic similarity
- Break condition: If DINOv2 features lack discriminative power for domain-specific objects, transferred similarities may be noisy

### Mechanism 3
- Claim: Joint training of box refinement and embedding transfer improves embedding quality by providing cleaner proposal regions for feature extraction
- Core assumption: Improved box localization directly improves feature pooling quality, which cascades to better embedding learning
- Evidence: Section 3.4 shows combined modules yield highest Recall@1 (11.69) vs. ETM alone (7.25)
- Break condition: If SAM refinement consistently produces boxes diverging from true object boundaries, feature pooling remains noisy

## Foundational Learning

- **Deformable DETR and Query-based Detection**
  - Why needed: PROB uses deformable DETR with learnable query embeddings; understanding how queries encode object proposals is essential
  - Quick check: Can you explain how Hungarian matching associates queries with ground truth objects, and what happens to unmatched queries?

- **Contrastive Learning Fundamentals**
  - Why needed: The relaxed contrastive loss modifies standard contrastive learning by replacing binary labels with continuous similarity weights
  - Quick check: In standard contrastive learning, how are positive and negative pairs defined, and what does the margin parameter control?

- **Knowledge Distillation Paradigms**
  - Why needed: ETM distills relational knowledge (pairwise similarities) rather than direct feature matching
  - Quick check: What is the difference between feature-based distillation (L1 matching) and relation-based distillation (similarity transfer)?

## Architecture Onboarding

- **Component map:** Backbone (ResNet-50 FPN) -> PROB (Deformable DETR) -> Unknown Box Refine Module (SAM) -> Embedding Transfer Module (DINOv2) -> Combined loss

- **Critical path:**
  1. PROB generates proposals with query embeddings
  2. URM refines top-k unknown boxes (warmup: applied after epoch 35)
  3. ETM pools DINOv2 features from refined boxes and known boxes (warmup: applied after epoch 14)
  4. Combined loss backpropagates; SAM and DINOv2 remain frozen
  5. At inference: only PROB + MLP head for instance embeddings (VFM modules discarded)

- **Design tradeoffs:**
  - DINOv2 chosen over SAM for ETM (Recall@1 11.69 vs. 10.38) due to superior semantic features
  - IoU threshold κ=0.5 balances filtering false positives vs. retaining sufficient supervision
  - Warmup scheduling prevents early instability from noisy proposals
  - Inference efficiency: Distillation enables VFM-quality embeddings without runtime VFM overhead (47.2ms vs. 80.9ms)

- **Failure signatures:**
  - Catastrophic drop in Known mAP: κ threshold too aggressive or α/β weights too high
  - Flat Recall@1 despite training: DINOv2 features not aligned to domain
  - Unknown Recall stagnation: SAM generating empty/mask-only outputs
  - Training instability after warmup: Learning rate too high for new loss terms

- **First 3 experiments:**
  1. Train PROB, PROB+URM, PROB+ETM, PROB+both on Task 1 of OWOD split; verify Recall@1 increases with ETM, Unknown Recall with URM
  2. Sweep κ ∈ {0.4, 0.5, 0.6} and k ∈ {5, 10, 15} on validation set; monitor tradeoff between metrics
  3. Extract instance embeddings, compute t-SNE projection on held-out classes; compare cluster separation against PROB baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can online learning techniques be effectively integrated to refine the feature space during inference in open-world environments?
- Basis: The conclusion states future work will explore online learning techniques to refine the feature space during inference
- Why unresolved: Current method operates in task-based offline training setting where modules are discarded at inference
- What evidence would resolve it: A framework demonstrating real-time updates without catastrophic forgetting

### Open Question 2
- Question: Can the trade-off between capturing fine-grained semantic relationships and maintaining strict separation between known and unknown classes be optimized?
- Basis: Appendix D.4 shows proposed method increases confusion metrics (Wilderness Impact and Absolute Open-Set Error)
- Why unresolved: Relaxed contrastive loss pulls semantically similar instances together regardless of known/unknown status
- What evidence would resolve it: Experiments minimizing Wilderness Impact and A-OSE while retaining high Recall@1

### Open Question 3
- Question: To what extent does performance depend on the scale and specific architecture of underlying Vision Foundation Models?
- Basis: Method relies on specific heavy models (ViT-H SAM and ViT-L DINOv2) for supervision
- Why unresolved: Superior performance attributed to "rich and generalizable knowledge" of VFMs, but untested with smaller models
- What evidence would resolve it: Ablation studies using smaller VFM variants to determine minimum teacher capacity

## Limitations
- Heavy reliance on Vision Foundation Models assumes SAM's segmentation generalizes to unknown objects and DINOv2 features are transferable across domains
- Additional computational overhead during training despite achieving faster inference through distillation
- Limited evaluation to MS-COCO/Pascal VOC datasets raises questions about generalizability to other domains

## Confidence
- **High Confidence:** Modular design of URM and ETM, and their individual contributions to improving unknown object detection and embedding quality
- **Medium Confidence:** Synergistic effect of combining URM and ETM, as the paper demonstrates improved performance but doesn't fully isolate the interaction mechanism
- **Medium Confidence:** Generalizability of the approach to datasets beyond MS-COCO/Pascal VOC, as experiments are limited to the OWOD split

## Next Checks
1. **Domain Transferability Test:** Evaluate OW-Rep on medical imaging or satellite imagery to assess VFM generalization limits
2. **VFM Ablation Study:** Replace SAM with weaker segmentation model and DINOv2 with smaller model to quantify their impact
3. **Failure Mode Analysis:** Systematically test on objects that challenge SAM (transparent, occluded, unusual shapes) and DINOv2 (fine-grained distinctions) to identify failure patterns