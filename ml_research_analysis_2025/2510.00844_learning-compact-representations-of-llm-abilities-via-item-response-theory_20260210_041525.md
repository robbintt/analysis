---
ver: rpa2
title: Learning Compact Representations of LLM Abilities via Item Response Theory
arxiv_id: '2510.00844'
source_url: https://arxiv.org/abs/2510.00844
tags:
- query
- irtnet
- routing
- benchmark
- abilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IrtNet, a novel framework for learning compact
  representations of large language model (LLM) abilities using Item Response Theory
  (IRT). IrtNet models the probability of an LLM correctly answering a query as a
  function of the model's latent ability vector, query discrimination vector, and
  query difficulty scalar.
---

# Learning Compact Representations of LLM Abilities via Item Response Theory
## Quick Facts
- arXiv ID: 2510.00844
- Source URL: https://arxiv.org/abs/2510.00844
- Reference count: 7
- Primary result: Novel IRT-based framework for learning compact LLM ability representations

## Executive Summary
This paper introduces IrtNet, a novel framework that leverages Item Response Theory (IRT) to learn compact representations of large language model abilities. The framework models the probability of an LLM correctly answering a query as a function of the model's latent ability vector, query discrimination vector, and query difficulty scalar. By employing a Mixture-of-Experts (MoE) network, IrtNet jointly learns these parameters from model-query performance data, enabling more efficient model routing and benchmark prediction.

The approach demonstrates state-of-the-art performance across multiple evaluation tasks. IrtNet achieves 67.4% accuracy in model routing across 10 benchmarks, significantly outperforming existing methods. Notably, the framework shows remarkable data efficiency, achieving 69.9% accuracy in benchmark prediction using less than 4% of the training data compared to previous state-of-the-art methods. The learned parameters are also interpretable, with difficulty parameters showing strong correlation with true benchmark scores and model embeddings forming meaningful clusters based on model families and specializations.

## Method Summary
IrtNet applies Item Response Theory to model the probability of an LLM correctly answering a query based on three key parameters: the model's latent ability vector, the query's discrimination vector, and the query's difficulty scalar. The framework employs a Mixture-of-Experts (MoE) network architecture to jointly learn these parameters from historical model-query performance data. This IRT-based approach transforms the complex, high-dimensional problem of LLM ability assessment into a more tractable, lower-dimensional representation space, enabling efficient model routing and benchmark prediction while maintaining interpretability of the learned parameters.

## Key Results
- Achieves 67.4% accuracy in model routing across 10 benchmarks, outperforming existing methods
- Demonstrates data efficiency with 69.9% accuracy using <4% of training data for benchmark prediction
- Difficulty parameters show strong correlation (Pearson correlation of -0.9721) with true benchmark scores

## Why This Works (Mechanism)
IrtNet works by applying Item Response Theory's probabilistic framework to LLM ability modeling, which captures the interaction between model abilities and task difficulties through a principled statistical approach. The IRT framework decomposes the probability of correct responses into model-specific ability parameters and task-specific difficulty parameters, allowing for more nuanced and interpretable representations than traditional embedding approaches. By jointly learning these parameters through an MoE architecture, the system can efficiently route models to appropriate tasks and predict benchmark performance with minimal data, while the learned parameters provide meaningful insights into both model capabilities and task characteristics.

## Foundational Learning
- **Item Response Theory (IRT)**: A statistical framework for modeling the probability of correct responses based on latent ability and item difficulty parameters. Needed to transform complex LLM ability assessment into tractable probabilistic modeling. Quick check: Verify that the IRT model assumptions (local independence, unidimensionality) approximately hold for the LLM-task interactions.

- **Mixture-of-Experts (MoE) Architecture**: A neural network design where multiple expert networks are combined with a gating mechanism to selectively activate relevant experts. Needed to enable efficient learning of multiple parameter types (abilities, discriminations, difficulties) simultaneously. Quick check: Confirm that the gating mechanism appropriately balances expert utilization across different model families.

- **Latent Ability Representation**: Low-dimensional vectors that capture the underlying capabilities of LLMs across different task dimensions. Needed to create compact, interpretable representations that generalize across benchmarks. Quick check: Validate that the learned ability vectors form coherent clusters corresponding to model families and specializations.

## Architecture Onboarding
**Component Map**: Input data (model-query performance) -> MoE network (ability vector, discrimination vector, difficulty scalar) -> IRT probability function -> Output (correctness probability)

**Critical Path**: Performance data → MoE parameter learning → IRT probability calculation → Model routing/benchmark prediction decisions

**Design Tradeoffs**: The IRT-based approach trades some modeling flexibility for interpretability and data efficiency, while the MoE architecture balances computational efficiency with expressive power. The framework prioritizes learning compact representations over capturing every nuance of model-task interactions.

**Failure Signatures**: Poor performance may manifest as inability to generalize to unseen benchmarks, inconsistent parameter interpretations across different model families, or suboptimal routing decisions for edge-case queries that don't match training distribution.

**First Experiments**:
1. Test model routing accuracy on held-out benchmarks to verify generalization
2. Perform ablation study comparing IRT-based modeling with alternative representation learning approaches
3. Evaluate parameter interpretability by correlating learned difficulty scores with external benchmark metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements show only 11 percentage point absolute gain over competing methods, which may be insufficient for critical applications
- Data efficiency comparisons conflate architectural differences with IRT-based modeling benefits
- Interpretability claims lack external validation beyond the studied benchmark suite
- Generalizability to broader task distributions beyond the curated 10 benchmarks remains unproven

## Confidence
- **High Confidence**: The mathematical framework is sound and experimental methodology is rigorously executed
- **Medium Confidence**: Interpretability claims are supported by evidence but lack external validation
- **Low Confidence**: Generalizability to real-world scenarios and unseen tasks remains unproven

## Next Checks
1. Evaluate IrtNet's performance on a held-out set of benchmarks not used during training to assess true generalization capabilities
2. Conduct ablation studies to isolate the contribution of IRT-based modeling versus the MoE architecture to the observed performance improvements
3. Test the practical utility of learned parameters by using them for downstream tasks such as dynamic prompting or few-shot learning, beyond the routing and prediction tasks studied here