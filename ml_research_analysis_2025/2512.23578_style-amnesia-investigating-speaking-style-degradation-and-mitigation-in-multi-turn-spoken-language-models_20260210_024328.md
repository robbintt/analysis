---
ver: rpa2
title: 'Style Amnesia: Investigating Speaking Style Degradation and Mitigation in
  Multi-Turn Spoken Language Models'
arxiv_id: '2512.23578'
source_url: https://arxiv.org/abs/2512.23578
tags:
- style
- slms
- mini
- gpt-4o
- speaking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Spoken language models (SLMs) struggle to maintain user-specified
  speaking styles like emotion, accent, volume, or speed across multi-turn dialogues,
  a phenomenon termed "style amnesia." The authors evaluate five SLMs (three proprietary,
  two open-source) by instructing them to follow a specific style from the start of
  a conversation and measuring their adherence across turns using automatic judges.
  Results show that while models follow the style well in the first turn, performance
  degrades significantly in subsequent turns, with degradation rates ranging from
  0.7% to 65.3% depending on the style and model.
---

# Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models

## Quick Facts
- arXiv ID: 2512.23578
- Source URL: https://arxiv.org/abs/2512.23578
- Reference count: 35
- Primary result: SLMs show significant degradation in maintaining speaking styles across multi-turn dialogues, with degradation rates from 0.7% to 65.3% depending on style and model

## Executive Summary
Spoken language models (SLMs) struggle to maintain user-specified speaking styles like emotion, accent, volume, or speed across multi-turn dialogues, a phenomenon termed "style amnesia." The authors evaluate five SLMs (three proprietary, two open-source) by instructing them to follow a specific style from the start of a conversation and measuring their adherence across turns using automatic judges. Results show that while models follow the style well in the first turn, performance degrades significantly in subsequent turns, with degradation rates ranging from 0.7% to 65.3% depending on the style and model. The degradation is not due to forgetting the instruction—models recall the style well when explicitly asked—but rather to failing to express it consistently. Placing style instructions in system messages instead of user messages worsens performance, contradicting their intended higher priority. A recall mechanism, where models restate the style before each response, partially mitigates but does not fully resolve style amnesia. This highlights a fundamental gap between style retention and expressive control in current SLMs.

## Method Summary
The authors evaluate five SLMs (GPT-4o, GPT-4o mini, Gemini Live, Step-Audio 2 mini, Qwen2.5-Omni) across 10 speaking styles using 100 conversation openers from the SODA dataset. A user simulator (ASR → GPT-5 mini → TTS cascade) interacts with each SLM for 4 turns, with style instructions placed in the first user message. Style adherence is measured per turn using automatic judges (Emotion2vec-Large for emotion, Voxlect for accent, LUFS/PyLoudnorm for volume, Parakeet TDT v2 for speed). The primary metrics are first-turn IF rate (IF₁) and degradation rate D measuring average decline from turn 1 to turn 4. A recall mechanism is tested by prompting models to restate the style before each response. Prompt position experiments compare style instructions in user vs. system messages.

## Key Results
- Style amnesia is widespread: All SLMs show significant degradation in style adherence from turn 1 to turn 4, with degradation rates ranging from 0.7% to 65.3%
- Degradation not due to forgetting: Models can recall style instructions well when explicitly asked, but fail to express them consistently
- Prompt position matters: Placing style instructions in user messages yields significantly better adherence than system messages, contradicting standard LLM behavior
- Recall mechanism helps: Explicitly asking models to restate the style before each response partially mitigates degradation (e.g., +35.0 percentage points for sadness in GPT-4o mini)

## Why This Works (Mechanism)

### Mechanism 1: Recall-Based Style Reinforcement
- Claim: Explicitly prompting SLMs to restate the style instruction before generating each response partially mitigates style amnesia by bridging the gap between retention and expression.
- Mechanism: The recall process forces the model to actively retrieve and verbalize the style constraint before speech generation, making the style specification more salient in the immediate generation context rather than relying on it being buried in conversation history.
- Core assumption: The degradation stems from attention/context dilution rather than permanent memory loss—models retain the instruction but fail to prioritize it during generation.
- Evidence anchors: [abstract] "explicitly asking the model to recall the style instruction can partially mitigate style amnesia"; [Section 6.2, Table 3] GPT-4o mini achieves ~25% average degradation reduction with recall process; improvement of +35.0 percentage points for sadness style.
- Break condition: If recall rates are already low (e.g., Step-Audio 2 mini at 55-89%), the recall process provides minimal benefit since the model cannot reliably retrieve the instruction to begin with.

### Mechanism 2: Prompt Position Sensitivity
- Claim: Placing style instructions in user messages yields significantly better style adherence than system messages, contradicting the intended priority hierarchy.
- Mechanism: SLMs may process system messages through a different pathway that doesn't properly integrate paralinguistic style specifications with the speech generation module, while user messages are more directly coupled to the generation context.
- Core assumption: The speech generation component in current SLMs may not uniformly access all prompt sources, or system prompts may be processed in ways that strip paralinguistic specifications.
- Evidence anchors: [abstract] "SLMs struggle to follow the required style when the instruction is placed in system messages rather than user messages, which contradicts the intended function of system messages"; [Section 5.1, Figure 5] GPT-4o mini shows ~80% drop for Indian accent when in system vs. user messages; ~50% drop for sadness.
- Break condition: This mechanism fails for styles that the model cannot reliably produce even in the first turn regardless of prompt position (e.g., Qwen2.5-Omni with Indian accent at 0% IF rate).

### Mechanism 3: Default Style Regression Under Context Accumulation
- Claim: As conversation turns accumulate, SLMs regress toward their default speaking styles (typically happy/neutral emotion and North American accent) even when instructed otherwise.
- Mechanism: Training data distribution biases emerge more strongly as the immediate instruction context becomes diluted across turns—models revert to statistically probable outputs when style signals weaken.
- Core assumption: Style amnesia is fundamentally a context-attention problem where the model's prior/learned distribution overtakes the specified constraint as the instruction becomes more distant.
- Evidence anchors: [Section 4.2] "nearly all SLMs perform better when generating happiness, neutral tone, and North American English than other style attributes... we hypothesize that this discrepancy arises because these attributes correspond to the default speaking styles"; [Section D.2, Table 4] Default style analysis shows Step-Audio 2 mini produces 93.7% happiness, 76.7% North American accent even in neutral conditions.
- Break condition: If a model has strong first-turn control (high IF₁) and low degradation for a specific style, the default regression mechanism is weaker—e.g., Gemini Live with Indian accent shows 0% degradation.

## Foundational Learning

- Concept: **Paralinguistic features in speech**
  - Why needed here: Understanding that speaking style encompasses non-semantic attributes (emotion, accent, volume, speed) that are generated differently from text content is essential for diagnosing why text-based prompt strategies may fail for speech.
  - Quick check question: Can you explain why volume and speed can be measured with signal-level metrics (LUFS, WPM) while emotion and accent require learned classifier models?

- Concept: **Multi-turn context accumulation and attention dilution**
  - Why needed here: Style amnesia emerges specifically in multi-turn settings—understanding how context grows and how attention mechanisms may deprioritize early instructions is critical for mitigation strategies.
  - Quick check question: Why would an instruction at turn 1 have less influence on generation at turn 4 than at turn 1, even if the model can still recall it when explicitly asked?

- Concept: **System vs. user prompt hierarchy in instruction-following**
  - Why needed here: The counter-intuitive finding that system messages perform worse requires understanding the intended role of each prompt type and how SLMs may diverge from text-only LLMs in processing them.
  - Quick check question: What is the intended function of system messages vs. user messages in LLMs, and why might an SLM process them differently for style specifications?

## Architecture Onboarding

- Component map: User Simulator (cascade: ASR → GPT-5 mini → TTS) → Evaluated SLM → Style Judge (emotion/accent/volume/speed specific) → Evaluation Metrics

- Critical path:
  1. Style instruction placed in first user turn (or system message for position experiments)
  2. Multi-turn interaction via user simulator (4 assistant turns)
  3. Per-turn style evaluation using IF rate metric
  4. Degradation rate computed as average drop from IF₁ across turns 2-4

- Design tradeoffs:
  - **End-to-end SLMs vs. cascade baseline**: E2E models show style amnesia; cascade with per-turn TTS style instruction provides upper bound (~3% degradation) but loses the benefits of integrated speech understanding
  - **Automatic vs. human evaluation**: Automatic judges validated with human study (MCC 0.511-0.811) enable scale but may miss nuance; human validation required for new style types
  - **Recall process latency**: Adding recall query before each response increases latency but partially mitigates degradation; trade-off depends on application sensitivity to style consistency vs. response speed

- Failure signatures:
  - First-turn IF₁ < 50%: Model fundamentally cannot produce the style; not a style amnesia issue
  - High recall rate (>95%) + high degradation (>20%): Classic style amnesia—memory intact, expression failing
  - Low recall rate (<75%): Memory degradation, not just expression gap; recall process will be less effective
  - System message IF₁ significantly below user message IF₁: Prompt position issue specific to model architecture

- First 3 experiments:
  1. **Baseline style amnesia measurement**: Run 4-turn conversations for each target style with instruction in first user turn; compute IF₁ and degradation rate D across all evaluated models to establish the scope of the problem.
  2. **Recall process ablation**: Implement recall query ("What speaking style should you use?") before each response generation; compare degradation rates with and without recall to quantify mitigation effectiveness per model and style.
  3. **Prompt position comparison**: Duplicate key experiments with style instruction in system message vs. first user message; measure first-turn IF₁ to identify models where system prompt integration is broken for paralinguistic specifications.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can current SLMs maintain consistency when instructed to perform composite or dynamically updating speaking styles (e.g., "speak fast and sadly")?
- Basis in paper: [explicit] The authors state they did not compose multiple style types because models struggle with single styles, explicitly leaving this extension for future work (Section 3.2.4, Limitations).
- Why unresolved: Current benchmarks focus on single attributes, and preliminary experiments show models struggle with complex instructions.
- What evidence would resolve it: Evaluating SLMs on a new benchmark of composite style instructions using multi-dimensional judges.

### Open Question 2
- Question: How does style amnesia impact role-playing scenarios where consistent persona maintenance is critical?
- Basis in paper: [explicit] The authors identify role-playing as an important consistency scenario but exclude it due to the lack of reliable automatic judges for assessing speech role-playing behaviors (Limitations).
- Why unresolved: No reliable automated metrics currently exist to quantify persona consistency in speech.
- What evidence would resolve it: Development and application of a role-playing specific evaluation protocol to the tested models.

### Open Question 3
- Question: Why do system messages result in worse style adherence than user messages, contradicting standard LLM behaviors?
- Basis in paper: [inferred] The authors find that placing instructions in system messages worsens performance (Section 5.1) and suggest this contradicts the intended function of system prompts.
- Why unresolved: The mechanism causing SLMs to deprioritize system-level style instructions remains unidentified.
- What evidence would resolve it: An ablation study analyzing attention weights on system vs. user tokens during speech generation.

## Limitations

- Proprietary model variability: Results depend on three proprietary models with opaque architectures, limiting generalizability
- Judge reliability constraints: Automatic style judges may miss nuanced expressions despite validation with human evaluation
- Recall process scalability: The mitigation strategy adds latency and effectiveness varies significantly by model

## Confidence

- High confidence: Style amnesia exists as a measurable phenomenon across multiple SLMs and style types
- Medium confidence: The recall process effectively mitigates style amnesia for some models and styles
- Low confidence: The exact mechanisms of style amnesia and generalizability of mitigation strategies

## Next Checks

1. **Human evaluation validation**: Conduct human evaluation for all 10 styles on a subset of model outputs to verify that automatic judge metrics accurately capture style adherence and to identify systematic judge biases.

2. **Cross-model replication**: Test the style amnesia phenomenon and recall mitigation on additional SLMs (both proprietary and open-source) to establish whether results generalize beyond the five models evaluated.

3. **Architectural probing**: Analyze the internal representations of style instructions in different prompt positions (user vs. system messages) using interpretability techniques to understand why system messages perform worse for paralinguistic specifications.