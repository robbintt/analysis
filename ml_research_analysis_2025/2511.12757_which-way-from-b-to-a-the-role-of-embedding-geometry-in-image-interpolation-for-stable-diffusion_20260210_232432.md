---
ver: rpa2
title: 'Which Way from B to A: The role of embedding geometry in image interpolation
  for Stable Diffusion'
arxiv_id: '2511.12757'
source_url: https://arxiv.org/abs/2511.12757
tags:
- image
- diffusion
- space
- embedding
- interpolation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of optimal transport for image
  interpolation in Stable Diffusion by leveraging a permutation-invariance property
  of cross-attention layers. Viewing CLIP embeddings as point clouds rather than matrices
  allows for optimal transport-based interpolation, which produces shorter, smoother
  paths through embedding space.
---

# Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion

## Quick Facts
- arXiv ID: 2511.12757
- Source URL: https://arxiv.org/abs/2511.12757
- Reference count: 4
- Primary result: Optimal transport interpolation in CLIP embedding space produces smoother, shorter paths with lower PPL scores than linear or random couplings

## Executive Summary
This paper investigates optimal transport for image interpolation in Stable Diffusion by leveraging a permutation-invariance property of cross-attention layers. By treating CLIP embeddings as point clouds rather than matrices, optimal transport-based interpolation produces shorter, smoother paths through embedding space. The method was tested on 10,000 prompt pairs with varying similarity levels, comparing optimal transport (OT) interpolation against linear and random coupling methods. Results show that OT interpolation consistently yields lower perceptual path length (PPL) scores, indicating smoother image transitions, with the improvement most significant for semantically similar prompts.

## Method Summary
The method encodes two prompts via CLIP into 77×768 embedding matrices, then solves an optimal transport problem to find the permutation σ* minimizing Σ||e0[i] - e1[σ*(i)]||². For each interpolation step t ∈ {0.1, 0.2, ..., 0.9}, the method computes μt by linear interpolation between paired tokens, converts μt back to matrix form, and generates images via Stable Diffusion 1.5 with fixed seed. The approach compares OT coupling against linear (CLIP) coupling and random coupling, measuring smoothness via PPL computed with LPIPS between consecutive images. The paper uses 10,000 prompt pairs from Crisscrossed Captions dataset, stratified across similarity bins from 0 to 5.

## Key Results
- OT interpolation yields consistently lower PPL scores than linear or random couplings across all similarity groups (p < 0.0001)
- The improvement is most significant for more similar prompts (similarity ≥ 2.5), where suboptimal couplings produce hallucinated images
- OT produces the shortest Wasserstein paths through embedding space, resulting in more geometrically faithful interpolation
- Statistical tests show highly significant differences in both PPL and coupling costs between OT and other methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating CLIP embeddings as point clouds rather than matrices preserves semantic structure during interpolation.
- Mechanism: Cross-attention in Stable Diffusion's U-Net computes attention via softmax(QK^T/√D)V, which is invariant to permutation of K and V rows. This means the 77 token embeddings have no inherent ordering—the model attends to their values, not positions.
- Core assumption: The permutation invariance property fully holds and no other architectural components depend on token order.
- Evidence anchors:
  - [abstract] "It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of CLIP embedding matrices."
  - [section 2.2] "Cross-attention is invariant under permutation of the rows of K and V, and hence also of X′"
  - [corpus] Weak/no direct corpus support for this specific property in SD 1.5

### Mechanism 2
- Claim: Optimal transport coupling produces geodesically shortest interpolation paths in Wasserstein space, yielding smoother image transitions.
- Mechanism: OT finds the permutation σ* that minimizes Σ||xi - yσ(i)||² (Equation 2). Linear interpolation uses the "CLIP coupling" (row-order pairing), which is generally suboptimal. The geodesic μt = ((1-t)id + tT)#μ0 (Equation 3) traces the shortest path.
- Core assumption: Shorter Wasserstein paths correspond to perceptually smoother image trajectories.
- Evidence anchors:
  - [abstract] "By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings"
  - [section 3] "the OT-inspired way to interpolate two N-point clouds μ0, μ1 is to pair off points using the optimal transport coupling"
  - [corpus] "What's Inside Your Diffusion Model?" discusses Riemannian geometry in diffusion manifolds but doesn't directly address OT for interpolation

### Mechanism 3
- Claim: Suboptimal couplings cause relatively worse interpolations for semantically similar prompts because the relative cost penalty is larger.
- Mechanism: When embeddings are close in Wasserstein distance, any suboptimal pairing represents a larger proportional deviation from the geodesic. This manifests as hallucinated objects in interpolated images.
- Core assumption: PPL (measured via LPIPS) adequately captures perceptual path smoothness and contextual coherence.
- Evidence anchors:
  - [abstract] "The improvement is most significant for more similar prompts, where suboptimal couplings produce hallucinated images"
  - [section 5] "the improvement is more substantial for more similar prompts...suboptimal couplings are relatively more costly when embeddings are close"
  - [corpus] No direct corpus support for this specific effect

## Foundational Learning

- Concept: Cross-attention mechanism and permutation invariance
  - Why needed here: Understanding why token order doesn't matter is the foundation for the entire point-cloud reformulation.
  - Quick check question: Given Q=XW_Q and K=X′W_K, if you swap rows 3 and 5 of X′, does the attention output change?

- Concept: Wasserstein distance and optimal transport
  - Why needed here: The core method relies on computing OT couplings between point clouds as an alternative to linear interpolation.
  - Quick check question: For two point clouds {{0,0}, {1,1}} and {{1,0}, {0,1}}, what pairing minimizes total squared distance?

- Concept: Perceptual Path Length (PPL) and LPIPS
  - Why needed here: PPL is the primary metric for evaluating interpolation smoothness; understanding what it measures is critical.
  - Quick check question: Why might pixel-wise MSE be a poor metric for measuring perceptual smoothness of image transitions?

## Architecture Onboarding

- Component map:
  - CLIP encoder: text → 77×768 embedding matrix (padded token embeddings)
  - Cross-attention blocks: latent × embedding → attended features (permutation-invariant on embedding rows)
  - U-Net denoiser: noisy latent + conditioning → denoised latent
  - VAE decoder: latent → image
  - OT solver: computes optimal pairing σ* between two embedding point clouds

- Critical path:
  1. Encode both prompts via CLIP → e0, e1 (77×768 matrices)
  2. Solve OT: find σ* minimizing Σ||e0[i] - e1[σ*(i)]||²
  3. For each t ∈ {0.1, 0.2, ..., 0.9}: compute μt by linear interpolation between paired tokens
  4. Convert μt back to matrix form, generate image via SD with fixed seed
  5. Compute PPL: average LPIPS between consecutive images

- Design tradeoffs:
  - Fixed latent seed vs. latent interpolation: Paper fixes seed to isolate embedding effects; real applications may need both
  - Discrete OT (permutations) vs. continuous OT: Paper uses discrete since CLIP produces exactly 77 tokens
  - LPIPS vs. other perceptual metrics: Paper notes LPIPS doesn't explicitly penalize contextual shifts

- Failure signatures:
  - Hallucinated objects in middle frames indicate suboptimal coupling (CLIP or random)
  - High variance in PPL across prompt pairs suggests embedding space irregularities
  - Non-significant differences between OT and baselines would indicate permutation invariance doesn't hold or OT doesn't capture geometry

- First 3 experiments:
  1. Reproduce the PPL comparison on a small subset (100 pairs) across 3 similarity bins to validate the OT vs. CLIP vs. random ranking.
  2. Visualize coupling matrices: plot which tokens in prompt A map to which tokens in prompt B for OT vs. CLIP coupling to build intuition.
  3. Stress test with identical prompts (similarity=5): verify all methods converge and PPL approaches minimum, confirming the metric behaves as expected.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the point-cloud/optimal transport framing generalize to transformer-based denoising architectures like Stable Diffusion 3.5, which use shared multi-modal token spaces rather than cross-attention?
- Basis in paper: [explicit] "While architectural innovations in the latest models present barriers to direct extension of the proposed approach, the point cloud perspective may still better preserve underlying geometry... Therefore, an important future direction would be extending and evaluating the point cloud framing for shared, multi-modal token spaces and transformer-based denoising architectures."
- Why unresolved: SD 3.5 uses substantially different architecture (transformer-based denoising) that may not have the same permutation-invariance property used in SD 1.5's cross-attention layers.
- What evidence would resolve it: Testing OT interpolation on SD 3.5 or similar transformer-based models and comparing PPL scores against baseline methods.

### Open Question 2
- Question: Can metrics be developed that explicitly capture contextual and content shifts between interpolated images, beyond LPIPS-based perceptual similarity?
- Basis in paper: [explicit] "The path length surrogate considered in this work leverages a standard image similarity score, LPIPS, but that score does not explicitly capture or penalize for contextual and content shifts between image pairs."
- Why unresolved: Current PPL metric treats all perceptual differences equally but doesn't distinguish between desirable thematic transitions and undesirable content hallucinations.
- What evidence would resolve it: A new metric that correlates better with human judgments of thematic coherence and flags hallucinated content in interpolation sequences.

### Open Question 3
- Question: Does the CLIP embedding space have formal convexity properties with respect to Wasserstein distance that explain why OT interpolation preserves semantic class membership better than linear interpolation?
- Basis in paper: [inferred] The paper observes "embedding space has a 'convexity' property with respect to Wasserstein distance that it does not have when the embedding matrices are handled as matrix objects," but this is stated as an empirical observation without formal proof.
- Why unresolved: The convexity property is hypothesized from experimental results but not mathematically characterized or proven.
- What evidence would resolve it: Formal mathematical analysis of Wasserstein geodesic properties in CLIP embedding space, or larger-scale empirical validation across diverse prompt classes.

### Open Question 4
- Question: What are the precise conditions under which prompt interpolation produces thematically consistent images versus hallucinated intermediate content?
- Basis in paper: [explicit] "Deeper exploration of the optimal path between prompt embeddings could uncover properties and conditions under which prompt interpolation results in thematically consistent and smooth images."
- Why unresolved: The paper shows OT reduces hallucinations but doesn't characterize when/why hallucinations occur even with optimal transport.
- What evidence would resolve it: Systematic study identifying prompt pair characteristics (semantic distance, shared attributes, etc.) that predict interpolation quality.

## Limitations
- Permutation invariance scope: The assumption may not generalize to newer architectures (SD 3.0/3.5 with transformer-based U-Nets) or other diffusion models
- Metric alignment: PPL via LPIPS may not fully capture semantic coherence or contextual shifts, potentially overestimating OT's perceptual advantages
- Embedding space geometry: Assumes Wasserstein geodesics correspond to perceptually meaningful paths, which may not hold if embedding space has non-trivial curvature

## Confidence

**High Confidence**: The permutation invariance property of cross-attention layers (Mechanism 1) - this follows directly from the softmax(QK^T/√D)V formulation and is mathematically provable. The computational advantage of OT over linear interpolation in terms of Wasserstein distance (Mechanism 2) is also high confidence, as it's a direct consequence of optimal transport theory.

**Medium Confidence**: The perceptual superiority of OT interpolation (main claim) - supported by statistical significance (p < 0.0001) across 10,000 prompt pairs, but dependent on whether PPL/LPIPS adequately captures human perception of interpolation quality. The mechanism explaining why OT helps more for similar prompts (Mechanism 3) has medium confidence due to limited corpus support.

**Low Confidence**: Generalization to architectures beyond SD 1.5, and whether the observed effects persist with different CLIP models or text encoders.

## Next Checks

1. **Architectural Generalization Test**: Validate the permutation invariance property and OT interpolation advantage on Stable Diffusion 3.0/3.5, which use transformer-based U-Nets rather than cross-attention with CLIP embeddings. This would test whether the core mechanism holds across architecture generations.

2. **Metric Complementarity Analysis**: Compare OT vs. CLIP coupling results using multiple perceptual metrics beyond LPIPS (e.g., CLIP similarity scores, human perceptual studies, or semantic segmentation consistency). This would validate whether PPL improvements correspond to meaningful semantic coherence.

3. **Embedding Space Structure Validation**: Analyze the curvature and topology of CLIP embedding space by measuring whether OT geodesics consistently align with semantically meaningful paths. This could involve clustering analysis or measuring whether OT pairings respect semantic categories across diverse prompt pairs.