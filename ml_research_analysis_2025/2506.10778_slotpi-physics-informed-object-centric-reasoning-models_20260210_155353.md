---
ver: rpa2
title: 'SlotPi: Physics-informed Object-centric Reasoning Models'
arxiv_id: '2506.10778'
source_url: https://arxiv.org/abs/2506.10778
tags:
- dataset
- learning
- physical
- object-centric
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SlotPi, a physics-informed object-centric
  reasoning model that integrates Hamiltonian-based physical constraints with spatiotemporal
  reasoning to improve dynamic prediction and physical understanding. The model uses
  slot-based object representations and combines a physical module (derived from Hamiltonian
  equations) with a spatiotemporal reasoning module to accurately simulate object
  dynamics and fluid behavior.
---

# SlotPi: Physics-informed Object-centric Reasoning Models

## Quick Facts
- **arXiv ID:** 2506.10778
- **Source URL:** https://arxiv.org/abs/2506.10778
- **Reference count:** 40
- **Primary result:** Physics-informed object-centric model integrating Hamiltonian dynamics with spatiotemporal reasoning achieves state-of-the-art prediction and VQA performance across rigid objects, fluids, and fluid-object interactions.

## Executive Summary
SlotPi introduces a physics-informed object-centric reasoning model that combines Hamiltonian-based physical constraints with spatiotemporal reasoning for dynamic prediction and physical understanding. The model uses slot-based object representations and integrates a physical module (derived from Hamiltonian equations) with a spatiotemporal reasoning module to accurately simulate object dynamics and fluid behavior. Evaluations on benchmark datasets demonstrate strong performance improvements over state-of-the-art baselines, with ablation studies confirming the effectiveness of the physics-informed module and the importance of balanced integration between physical and spatiotemporal reasoning.

## Method Summary
SlotPi is a two-stage framework: first, scenes are decomposed into slots using upstream object-centric models (SAVi, STATM-SAVi, or patch-based encoders for fluids); second, the SlotPi model processes these slots to predict future states. The core architecture consists of a physics module based on Hamiltonian mechanics that computes generalized coordinates, momentum, and total energy via attention mechanisms, and a spatiotemporal reasoning module that captures non-conservative dynamics through cross- and self-attention. The final prediction is a weighted combination of physics-based and data-driven predictions. The model is trained with slot prediction and image reconstruction losses, with hyperparameters including Adam optimizer, batch size 64, and λ=1 weighting between modules.

## Key Results
- Achieves 66.12% FG-ARI on CLEVRER (1.56% improvement over SlotFormer)
- Reaches 50.32% FG-mIoU on OBJ3D (0.75% improvement over SlotFormer)
- Demonstrates strong fluid dynamics prediction with RMSE 0.2816 on NS dataset

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SlotPi’s physics module provides inductive bias toward energy-conserving dynamics.
- **Mechanism:** The physical module is structured to mirror Hamiltonian mechanics. It uses attention-based computations to derive generalized coordinates (Q_t), generalized momentum (P_t), and total system energy (H_t). State updates follow Euler integration of Hamilton’s equations: dQ/dt = ∂H/∂P, dP/dt = -∂H/∂Q. This injects a physical prior that energy should be tracked and updated coherently across time.
- **Core assumption:** Slot representations from upstream object-centric encoders contain sufficient state information (position, velocity-like features) for the Hamiltonian formulation to approximate physical dynamics.
- **Evidence anchors:**
  - [abstract] "integrates a physical module based on Hamiltonian principles with a spatio-temporal prediction module"
  - [section 3.1] Equations (1)-(4) detail the Hamiltonian-based computation of P_t, Q_t, H_t, and state updates via Euler method.
  - [corpus] Corpus shows related physics-informed approaches (PINP, PIORF) but no direct evidence validating Hamiltonian mechanisms in object-centric contexts; corpus evidence is weak.
- **Break condition:** If slots do not encode physically meaningful states (e.g., missing velocity information), the Hamiltonian formulation cannot properly compute derivatives, and the physics module degrades to arbitrary function approximation.

### Mechanism 2
- **Claim:** The spatiotemporal reasoning module captures non-conservative dynamics and residual interactions not covered by the Hamiltonian prior.
- **Mechanism:** While the Hamiltonian formulation assumes conservative systems (no friction, no external driving forces), real-world dynamics involve dissipation and external influences. The spatiotemporal module uses cross-attention (temporal reasoning across historical slots) and self-attention (spatial interactions among slots at the same timestep) to learn these residuals. The final prediction is a weighted sum: Ŝ_{t+1} = λ·Q̂_{t+1} + ŚT_{t+1}, where λ balances physics-based and data-driven contributions.
- **Core assumption:** The weighted sum can effectively combine conservative (physics module) and non-conservative (spatiotemporal module) contributions without destructive interference.
- **Evidence anchors:**
  - [abstract] "combines a physical module... with a spatiotemporal reasoning module to accurately simulate object dynamics and fluid behavior"
  - [section 3.2] "Hamiltonian physics module alone cannot fully capture the motion of objects... integrated a spatiotemporal reasoning module"
  - [section 4.4, Table 7] Ablation shows λ=1 (equal weighting) performs best; learnable λ increases during training but stays ≤1.
  - [corpus] Related work (AnyNav, Causal-PIK) addresses physics-ML integration for non-conservative systems but no direct validation of SlotPi’s specific combination strategy.
- **Break condition:** If the two modules produce conflicting updates (e.g., physics predicts acceleration left, spatiotemporal predicts acceleration right), the weighted sum may average to incorrect dynamics rather than resolve the conflict.

### Mechanism 3
- **Claim:** Slot-based decomposition enables unified handling of heterogeneous systems (rigid bodies, fluids, fluid-object interactions).
- **Mechanism:** SlotPi relies on upstream object-centric models (SAVi, STATM-SAVi) to decompose scenes into N slots, each representing an entity. This abstraction allows the same physics and spatiotemporal modules to operate on rigid objects (CLEVRER, OBJ3D), fluid elements (NS dataset, 1024 slots), or mixed systems (real-world fluid-object interactions). The architecture adapts by changing slot count and dimension per dataset, not the core reasoning modules.
- **Core assumption:** Slots provide a sufficiently disentangled representation that individual entity dynamics can be reasoned independently before being aggregated for global prediction.
- **Evidence anchors:**
  - [abstract] "uses slot-based object representations and combines a physical module... with a spatiotemporal reasoning module"
  - [section 4.2] For fluid dataset, "slot dimensions to 512 and set the number of slots to 1024 in SlotPi to accommodate the encoded tokens"
  - [section 4.3, Figure 5] Real-world dataset shows consistent slot-to-object binding over time; features of each object decomposed into separate slots without confusion.
  - [corpus] Dyn-O paper similarly uses object-centric representations for world models, supporting slot-based decomposition as a viable approach, but does not validate SlotPi’s specific unified modeling claim.
- **Break condition:** If the upstream slot extractor fails (e.g., merges multiple objects into one slot, or splits one object across slots), the reasoning modules propagate this error, leading to incorrect dynamics predictions.

## Foundational Learning

- **Concept: Hamiltonian Mechanics / Energy-Based Dynamics**
  - **Why needed here:** The physics module is explicitly built on Hamilton’s equations. Without understanding that Hamiltonian systems define dynamics via energy gradients (∂H/∂q, ∂H/∂p), one cannot interpret why the architecture computes H_t and uses its derivatives for state updates, or why this enforces conservative dynamics.
  - **Quick check question:** Can you explain why a Hamiltonian formulation cannot naturally model friction, and how this relates to SlotPi needing a separate spatiotemporal module?

- **Concept: Object-Centric Learning / Slot Attention**
  - **Why needed here:** SlotPi is a downstream model that consumes slots from upstream encoders. Understanding how slot attention binds pixels/features to discrete entity representations (slots) is essential for debugging decomposition failures, setting slot counts, and interpreting slot semantics.
  - **Quick check question:** If you observe that two visually distinct objects are consistently assigned to the same slot, is this a SlotPi issue or an upstream encoder issue?

- **Concept: Attention Mechanisms for Relational Reasoning**
  - **Why needed here:** Both the physics module (cross-attention for P_t, self-attention for Q_t and H_t) and spatiotemporal module (cross-attention for temporal, self-attention for spatial) rely on attention to compute interactions. Understanding how attention computes pairwise or sequence relationships is critical for modifying or debugging these components.
  - **Quick check question:** Why might the authors choose cross-attention (across time) for computing momentum P_t, but self-attention (within a timestep) for computing coordinates Q_t? (Hint: consider what information each quantity requires.)

## Architecture Onboarding

- **Component map:** Input frames → upstream encoder → slots → physics module (Q_t, P_t, H_t, Euler update) || spatiotemporal module (attention over time/space) → fusion → predicted slots → downstream decoder (if reconstructing images) or direct use for VQA

- **Critical path:** Input frames → upstream encoder → slots → physics module (Q_t, P_t, H_t, Euler update) || spatiotemporal module (attention over time/space) → fusion → predicted slots → downstream decoder (if reconstructing images) or direct use for VQA

- **Design tradeoffs:**
  - **Physics vs. data-driven balance (λ):** Ablation shows λ=1 works best on CLEVRER; setting λ too low (0.1) or making it learnable (converges to ~0.9) slightly hurts performance. Default is equal weighting, but optimal balance may vary by domain.
  - **Attention vs. MLP for Hamiltonian embedding (Table S4):** Attention (1 block) outperforms MLP (7–9 layers) with fewer parameters. Attention is default for computing P, Q, H.
  - **Slot count/dimension per domain:** Rigid objects (CLEVRER): 7 slots, 128D. Fluids: 1024 slots, 512D (patch-level representation). Real-world: 6 slots, 192D (ResNet encoder). No universal setting; must adapt per dataset.

- **Failure signatures:**
  - **Physics module ignored:** If λ→0 during training (learnable setting) or ablation removes physics module, performance degrades to STATM/SlotFormer baselines; expect increased FG-ARI errors and physics-inconsistent predictions (e.g., objects stopping abruptly).
  - **Slot decomposition failure:** If upstream encoder fails to separate objects (e.g., merged slots in real-world dataset), expect poor FG-mIoU/ARI and visual artifacts (object deformation, disappearance). Check STATM-SAVi decomposition quality first.
  - **Insufficient burn-in frames (Figure 7):** For slow dynamics (real-world fluid-object interactions), 6 burn-in + 10 rollout frames cause model to predict objects as stationary. Use 10 burn-in + 15 rollout for such datasets.
  - **Overfitting in spatiotemporal module (Table S3):** On OBJ3D, N>2 attention blocks cause overfitting; optimal is N=2. If PSNR/SSIM degrade with more blocks, reduce N.

- **First 3 experiments:**
  1. **Reproduce CLEVRER baseline with λ ablation:** Train SlotPi on CLEVRER with STATM-SAVi slots (7 slots, 128D). Compare λ∈{0, 0.1, 1, learnable}. Verify that λ=1 achieves reported FG-ARI ~66%, FG-mIoU ~50%, and that λ=0 (physics removed) degrades to ~64–65% FG-ARI. This validates the physics module’s contribution.
  2. **Validate slot decomposition quality on real-world dataset:** Use provided real-world dataset with STATM-SAVi (ResNet encoder, 6 slots, 192D). Visualize slot masks over time (as in Figure 5) to confirm each object is consistently bound to one slot. If slots mix or drop objects, debug upstream encoder before proceeding to prediction tasks.
  3. **Test cross-domain slot scaling on fluid dataset:** Train SlotPi on NS fluid dataset with patch encoder (1024 slots, 512D). Compare against U-Net and FNO baselines using RMSE/MAE/HCT metrics. Verify that SlotPi achieves RMSE <0.3 (reported 0.2816) and qualitatively matches ground-truth flow fields (as in Figure 3). This confirms the architecture handles non-object-centric, high-slot-count domains.

## Open Questions the Paper Calls Out
None

## Limitations
- Slot semantics ambiguity: The physics module assumes slots encode physically meaningful states, but no ablation shows performance when slots are randomized or permuted, leaving uncertainty about whether the Hamiltonian module truly learns physical dynamics or merely fits slot trajectories.
- Energy conservation vs. non-conservative dynamics: The paper claims the spatiotemporal module compensates for the Hamiltonian module’s inability to model friction and external forces, but provides no quantitative analysis of each module’s contribution to energy conservation or dissipation.
- Cross-domain generalization: While SlotPi is tested on rigid objects, fluids, and fluid-object interactions, all datasets are synthetic or controlled. No evaluation on real-world noisy videos tests robustness to occlusion, lighting changes, or camera motion.

## Confidence
- **Physics module improves FG-ARI by 1.56% over SlotFormer:** High (directly measured via ablation, consistent across runs)
- **SlotPi generalizes across rigid objects, fluids, and fluid-object interactions:** Medium (evaluated on synthetic/real datasets but not noisy real-world conditions)
- **Hamiltonian formulation enables energy-aware reasoning:** Low (mechanism plausible but not empirically validated; slot semantics unverified)

## Next Checks
1. **Ablation with randomized slots:** Shuffle slot assignments in CLEVRER/OBJ3D and retrain SlotPi. If FG-ARI drops to baseline levels, this confirms slots must encode physical states; if performance remains high, the physics module may be fitting slot trajectories without true physical reasoning.
2. **Energy conservation analysis:** Compute total system energy (H_t) over time for each dataset. For conservative systems (e.g., OBJ3D), energy should remain constant; for non-conservative (e.g., real-world friction), energy should decrease monotonically. Quantify deviation to assess whether the physics module enforces realistic energy dynamics.
3. **Robustness to occlusion/noise:** Evaluate SlotPi on a subset of CLEVRER with artificial occlusion (e.g., Gaussian blur or object masking). Measure FG-mIoU degradation vs. SlotFormer. If SlotPi’s physics prior improves robustness (smaller drop), this validates the inductive bias; if not, the spatiotemporal module may be over-reliant on pixel-level cues.