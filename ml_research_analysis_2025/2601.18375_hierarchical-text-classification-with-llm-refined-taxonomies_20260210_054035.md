---
ver: rpa2
title: Hierarchical Text Classification with LLM-Refined Taxonomies
arxiv_id: '2601.18375'
source_url: https://arxiv.org/abs/2601.18375
tags:
- taxonomy
- taxonomies
- association
- classification
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents TAXMORPH, a framework that uses large language
  models (LLMs) to refine hierarchical taxonomies for text classification. TAXMORPH
  transforms existing taxonomies through renaming, merging, splitting, and reordering
  nodes to better align with the semantic structure captured by language models.
---

# Hierarchical Text Classification with LLM-Refined Taxonomies

## Quick Facts
- arXiv ID: 2601.18375
- Source URL: https://arxiv.org/abs/2601.18375
- Authors: Jonas Golde; Nicolaas Jedema; Ravi Krishnan; Phong Le
- Reference count: 30
- Primary result: LLM-refined taxonomies improve F1 scores by up to +2.9 percentage points in hierarchical text classification

## Executive Summary
This paper introduces TAXMORPH, a framework that uses large language models to refine hierarchical taxonomies for text classification. The method transforms existing taxonomies through renaming, merging, splitting, and reordering nodes to better align with the semantic structure captured by language models. TAXMORPH improves hierarchical text classification performance across three benchmarks, achieving up to +2.9 percentage points in F1 score. The analysis reveals that while human-curated taxonomies produce more separable clusters in embedding space, LLM-refined taxonomies better reflect the model's actual confusion patterns during classification.

## Method Summary
TAXMORPH is a two-stage framework for refining hierarchical taxonomies. In Stage 1, an LLM (Claude Haiku/Sonnet-3/Sonnet-3.5) transforms the full taxonomy to a JSON mapping of original paths to new paths. In Stage 2, post-processing with normalized Levenshtein distance matching aligns generated paths with true paths. The framework uses a Bi-encoder DistilBERT classifier with dot-product similarity and sigmoid activation, trained with binary cross-entropy loss and AdamW optimizer (lr=2e-5). Two label representation strategies are evaluated: Single Node (leaf only) and Full Path. The method improves hierarchical text classification performance while revealing a trade-off between classification accuracy and structural alignment with model representations.

## Key Results
- TAXMORPH improves hierarchical text classification F1 scores by 1.1-2.9 percentage points across three benchmarks
- LLM-refined taxonomies show better alignment with model confusion patterns than human-curated taxonomies
- Single Node label representation outperforms Full Path strategy in all experiments
- Claude Sonnet-3.5 produces zero invalid paths while Haiku generates approximately 21 invalid paths in WOS experiments

## Why This Works (Mechanism)
TAXMORPH works by aligning taxonomy structure with how language models actually process and classify text. The LLM identifies problematic taxonomic relationships that cause confusion during classification and restructures them to better match the model's internal representations. This alignment reduces classification errors by reorganizing labels according to the model's learned semantic boundaries rather than human intuition. The framework leverages the LLM's understanding of semantic similarity to create taxonomies that minimize confusion between similar classes, effectively bridging the gap between human-designed hierarchical structures and machine learning model behavior.

## Foundational Learning

**Hierarchical Text Classification**: Classifying documents into multi-level category trees where each node represents a label. Needed because many real-world categorization tasks require hierarchical structure. Quick check: Verify dataset has depth > 1 and labels form tree structure.

**Taxonomy Probing Metric (TPM)**: Measures structural alignment between taxonomy and model representations using probing tasks. Needed to quantify how well taxonomy structure matches model behavior. Quick check: Compute TPM before/after refinement to measure alignment changes.

**Bi-encoder Architecture**: Separate encoders for text and labels, with similarity computed via dot product. Needed for efficient classification of many classes. Quick check: Ensure label embeddings are precomputed and stored.

**Normalized Levenshtein Distance**: String similarity metric used to match generated paths to original paths. Needed to handle LLM output variations and typos. Quick check: Verify threshold captures valid matches while filtering invalid ones.

## Architecture Onboarding

**Component Map**: LLM Prompt -> JSON Taxonomy Mapping -> Levenshtein Matching -> DistilBERT Training -> F1 Evaluation

**Critical Path**: Taxonomy refinement (LLM + post-processing) directly impacts classification performance through better label representation alignment

**Design Tradeoffs**: Single Node labels vs Full Path labels (performance vs completeness), LLM model choice (accuracy vs invalid path generation), threshold selection (precision vs recall of path matching)

**Failure Signatures**: Invalid paths from LLM (>20% in WOS with Haiku), training instability with Linear Layer/BERT baselines, Full Path labels underperforming Single Node

**First Experiments**:
1. Run LLM refinement on WOS with Claude Haiku, count invalid paths
2. Train DistilBERT with Single Node labels on original taxonomy, establish baseline F1
3. Apply Levenshtein post-processing and retrain, measure F1 improvement

## Open Questions the Paper Calls Out

**Open Question 1**: Do LLM-refined taxonomies retain semantic validity and domain-specific consistency compared to human-curated structures? The authors explicitly state the work does not address questions related to semantic validity, potential biases, or alignment with domain-specific expectations and notes the absence of human evaluation.

**Open Question 2**: Does the performance gain from LLM-refined taxonomies generalize to generative or graph-based model architectures? The limitations section notes that results are restricted to encoder-based transformer models and other classes of models are not considered.

**Open Question 3**: Can a taxonomy refinement strategy optimize simultaneously for high classification performance and high structural alignment (TPM)? The conclusion identifies a trade-off between expressiveness and geometric alignment, noting that human taxonomies have better TPM while LLM taxonomies have better F1.

## Limitations

- LLM outputs show variability, with Claude Haiku producing approximately 21 invalid paths in WOS experiments while Sonnet-3.5 generated none
- The normalized Levenshtein distance threshold for path matching is not precisely specified, introducing potential reproducibility concerns
- Performance improvements (1.1-2.9 F1 points) are modest and may not justify added complexity in all applications
- Results are restricted to encoder-based transformer models, with unknown generalizability to generative or graph-based architectures

## Confidence

**High Confidence**: The core finding that LLM-refined taxonomies improve classification F1 scores (1.1-2.9 points) is well-supported by experimental results across multiple datasets and models.

**Medium Confidence**: The claim about better alignment with model confusion patterns is supported by TPM analysis but requires more detailed investigation of the structural differences.

**Low Confidence**: The assertion that taxonomies should be evaluated by structural alignment with model representations is a theoretical proposition not yet validated across diverse model architectures.

## Next Checks

1. Conduct ablation studies varying the normalized Levenshtein distance threshold to quantify its impact on path matching accuracy and downstream classification performance.

2. Test TAXMORPH with additional LLM models (GPT-4, LLaMA) to assess whether improvements generalize beyond Claude or depend on specific model capabilities.

3. Evaluate whether the improved alignment with model confusion patterns translates to better zero-shot or few-shot generalization when taxonomies are refined for different model families.