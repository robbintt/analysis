---
ver: rpa2
title: 'Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis'
arxiv_id: '2512.18699'
source_url: https://arxiv.org/abs/2512.18699
tags:
- speech
- dialect
- synthesis
- e-vector
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of synthesizing emotionally
  expressive dialectal speech by proposing a two-stage method called Hierarchical
  Expressive Vector (HE-Vector). The method constructs task vectors to independently
  model dialectal and emotional styles, then hierarchically integrates them without
  requiring jointly labeled data.
---

# Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis

## Quick Facts
- arXiv ID: 2512.18699
- Source URL: https://arxiv.org/abs/2512.18699
- Reference count: 0
- Key outcome: HE-Vector achieves superior dialect synthesis and promising zero-shot emotionally expressive dialectal speech synthesis without requiring jointly labeled data.

## Executive Summary
This paper addresses the challenge of synthesizing emotionally expressive dialectal speech by proposing a two-stage method called Hierarchical Expressive Vector (HE-Vector). The method constructs task vectors to independently model dialectal and emotional styles, then hierarchically integrates them without requiring jointly labeled data. Experimental results demonstrate that HE-Vector achieves superior performance in dialect synthesis and promising results in synthesizing emotionally expressive dialectal speech in zero-shot settings, with objective evaluations showing comparable word error rates and speaker similarity to ground truth.

## Method Summary
The proposed two-stage approach first constructs E-Vectors by fine-tuning F5-TTS separately on dialect and emotion data, then computing task vectors as the difference between fine-tuned and pretrained weights. These vectors are scaled by an enhancement coefficient. The second stage hierarchically merges dialect and emotion E-Vectors by applying dialect LoRA to early DiT layers (text embedding + first half) and emotion LoRA to later DiT layers (second half), enabling controllable multi-style synthesis without jointly labeled data.

## Key Results
- HE-Vector outperforms baselines in dialect synthesis with higher MOS scores
- Hierarchical merging strategy achieves better cross-style controllability than fully merged approaches
- Zero-shot emotionally expressive dialectal synthesis shows comparable WER and speaker similarity to ground truth

## Why This Works (Mechanism)

### Mechanism 1: Task Vector Arithmetic Captures Style-Specific Directions
Fine-tuning F5-TTS on dialect or emotion data → compute τ = θ_finetuned − θ_pretrained → scale by α to form E-Vector → add back to pretrained weights at inference. Core assumption: Style-specific adaptation directions are approximately linear in parameter space and can be amplified without catastrophic interference.

### Mechanism 2: Hierarchical Layer Assignment Reduces Cross-Style Interference
Assign Dialect LoRA E-Vector to text embedding layer + early DiT blocks (phonetic/pronunciation); apply Emotion LoRA E-Vector to later DiT blocks (prosody/rhythm/intonation). Core assumption: Early vs. late DiT layers specialize in phonetic vs. prosodic features respectively; styles can be disentangled by layer.

### Mechanism 3: LoRA Enables Efficient Multi-Style Coexistence
Insert LoRA blocks into modules with largest parameter variations during full fine-tuning; at inference, scale LoRA outputs by enhancement coefficient α. Core assumption: Style-relevant updates are low-rank; scaling does not degrade perceptual quality.

## Foundational Learning

- **Task Vectors (Model Arithmetic)**: Why needed here: The entire E-Vector framework builds on computing and scaling task-specific parameter offsets. Quick check: Can you explain why subtracting pretrained weights from fine-tuned weights might capture task-specific behavior?
- **Diffusion Transformer (DiT) with Flow Matching**: Why needed here: F5-TTS backbone is a DiT-based flow-matching model; understanding layer functions is critical for hierarchical assignment. Quick check: What types of features might early vs. late transformer layers capture in a speech generation model?
- **LoRA (Low-Rank Adaptation)**: Why needed here: Practical implementation uses LoRA for parameter-efficient multi-style storage. Quick check: Why might low-rank factorization be sufficient for style adaptation but insufficient for full model capacity?

## Architecture Onboarding

- **Component map**: F5-TTS (flow-matching DiT) -> E-Vector construction (fine-tune → compute τ → scale by α) -> LoRA E-Vector (insert (A, B) pairs into high-variation modules; scale at inference) -> Hierarchical merger (dialect → early layers; emotion → late layers)
- **Critical path**: 1. Moderate fine-tuning on style-specific data 2. Compute task vector τ = θ_finetuned − θ_pretrained 3. Determine enhancement coefficient α via validation 4. For multi-style: assign each LoRA E-Vector to designated layers 5. At inference: apply scaled E-Vectors to pretrained backbone
- **Design tradeoffs**: Full E-Vector vs. LoRA E-Vector: Full achieves higher MOS but requires more storage; Fully merged vs. hierarchical: Hierarchical achieves better cross-style control with less interference; Enhancement coefficient α: Higher α increases style intensity but may degrade naturalness
- **Failure signatures**: CosyVoice + E-Vector shows degraded quality due to interference with LLM text encoder coordination; Over-fine-tuning (FT-last) shows inconsistent dialect performance; Fully merged strategy shows reduced controllability vs. hierarchical
- **First 3 experiments**: 1. Validate E-Vector construction on single-style synthesis: Fine-tune F5-TTS on one dialect, compute τ, sweep α ∈ [1.0, 4.0], measure MOS and WER. 2. Ablate hierarchical vs. fully merged strategy: Train separate dialect and emotion E-Vectors, compare hierarchical layer assignment against full parameter merger. 3. Test LoRA rank sensitivity: Train LoRA E-Vectors with r ∈ {4, 8, 16, 32}, compare against full E-Vector baseline.

## Open Questions the Paper Calls Out

- **How can E-Vectors be adapted for TTS architectures that utilize decoupled text encoders and acoustic models?** The authors note that applying the method to CosyVoice resulted in degraded synthesis quality because the vector enhancement interfered with the coordination between its LLM-based text encoder and the flow-matching acoustic model.

- **Can non-linear parameter construction strategies improve the performance of E-Vectors compared to the current linear scaling approach?** The authors state that their analysis reveals parameter variations during fine-tuning are "not strictly linear," which identifies a limitation in the current linear E-Vector construction method.

- **What alternative layer-wise merging strategies can yield performance gains where simple coefficient adjustments have failed?** The authors mention that assigning different coefficients to DiT layers brought no significant gain, but conclude that developing more effective strategies for constructing and merging E-Vectors remains an important direction for future work.

## Limitations

- Reliance on an in-house Chinese dialect corpus that is not publicly available, preventing direct reproduction and independent validation
- Unspecified exact layer boundaries for hierarchical assignment (early vs. late DiT blocks) and LoRA module placement
- Claim that task vector arithmetic captures style information in a linear, scalable manner remains an assumption without rigorous ablation studies across different model architectures

## Confidence

- **High Confidence**: The core task vector construction method (fine-tuning → subtracting → scaling) is well-established in model editing literature and has been validated for single-style synthesis
- **Medium Confidence**: The hierarchical merging strategy shows improved controllability over fully merged approaches, but the optimal layer assignment for different dialect-emotion combinations requires further validation
- **Low Confidence**: The zero-shot performance claims rely on in-house data and limited external baselines; generalization to other datasets or languages is unverified

## Next Checks

1. **Cross-Corpus Generalization**: Apply the HE-Vector method to a publicly available multi-dialect corpus (e.g., Common Voice) and measure whether the task vector arithmetic and hierarchical merging still yield performance gains.

2. **Ablation of Layer Assignment**: Systematically vary the layer boundaries for dialect and emotion E-Vector application across the DiT blocks, and measure the impact on cross-style controllability and interference.

3. **Scaling Coefficient Robustness**: Sweep the enhancement coefficient α across a wider range (e.g., [1.0, 5.0]) for both full and LoRA E-Vectors, and analyze the trade-off between style intensity and naturalness across different dialect-emotion combinations.