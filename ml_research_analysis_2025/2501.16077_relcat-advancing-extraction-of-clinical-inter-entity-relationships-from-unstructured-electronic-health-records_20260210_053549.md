---
ver: rpa2
title: 'RelCAT: Advancing Extraction of Clinical Inter-Entity Relationships from Unstructured
  Electronic Health Records'
arxiv_id: '2501.16077'
source_url: https://arxiv.org/abs/2501.16077
tags:
- recall
- bert
- performance
- f1-score
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces RelCAT (Relation Concept Annotation Toolkit),
  a comprehensive NLP toolkit for extracting and classifying inter-entity relationships
  in clinical narratives. Building on the CogStack MedCAT framework, RelCAT employs
  state-of-the-art transformer models including BERT and Llama to identify relationships
  between SNOMED CT entities extracted from unstructured clinical text.
---

# RelCAT: Advancing Extraction of Clinical Inter-Entity Relationships from Unstructured Electronic Health Records

## Quick Facts
- arXiv ID: 2501.16077
- Source URL: https://arxiv.org/abs/2501.16077
- Authors: Shubham Agarwal; Vlad Dinu; Thomas Searle; Mart Ratas; Anthony Shek; Dan F. Stein; James Teo; Richard Dobson
- Reference count: 22
- Primary result: RelCAT achieves macro F1-score of 0.977 on n2c2 dataset, surpassing previous state-of-the-art results.

## Executive Summary
RelCAT (Relation Concept Annotation Toolkit) is a comprehensive NLP toolkit for extracting and classifying inter-entity relationships in clinical narratives. Building on the CogStack MedCAT framework, it employs state-of-the-art transformer models including BERT and Llama to identify relationships between SNOMED CT entities extracted from unstructured clinical text. The toolkit implements multiple entity representation methods and incorporates strategies to address class imbalance in medical datasets, including class weighting and stratified batching. A novel annotation tool built within MedCATTrainer enables dataset creation and annotation, while also supporting automatic relation generation using ontology dictionaries.

## Method Summary
RelCAT leverages MedCAT for NER+L to identify and standardize medical concepts, then uses transformer models (BERT, Llama) for relation classification. The method marks entity positions with special tokens or indices, applies context windows around entities, and uses fully connected layers for classification. Class imbalance is addressed through weighted loss functions and stratified batching. The system is trained on gold-standard datasets like n2c2 and evaluated on real-world NHS clinical datasets, achieving state-of-the-art performance across multiple relation types.

## Key Results
- Achieves macro F1-score of 0.977 on gold-standard n2c2 dataset, surpassing previous state-of-the-art of 0.9610
- Strong performance on minority classes: ADE-Drug F1 0.866, Duration-Drug F1 0.933
- BERT models achieve F1-scores â‰¥0.93 on real-world NHS clinical datasets
- Llama models also perform competitively, particularly when layers are unfrozen

## Why This Works (Mechanism)

### Mechanism 1: Entity Marking with Special Tokens and Context Windows
Marking entity start/end positions with special tokens and focusing attention on a localized context window around entities allows transformer models to learn relationships between clinically relevant terms even when separated by intervening text. RelCAT inserts special tokens `[s1], [e1], [s2], [e2]` to explicitly mark entity boundaries or stores token indices. It then applies a context selection window focusing on tokens near these marked entities before passing embeddings through fully connected layers. This creates a targeted signal for the classification head to learn inter-entity patterns. The relationship between two clinical entities is primarily determined by the local context surrounding them, not the entire document.

### Mechanism 2: Layer Unfreezing for Domain Adaptation
Unfreezing transformer layers during fine-tuning allows the model to adapt pre-trained linguistic knowledge to the specific statistical distribution and vocabulary of clinical text, improving relation classification performance. RelCAT fine-tunes pre-trained models (BERT, Llama). Experiments show that unfreezing layers ("all layers unfrozen" or "last layer unfrozen") generally leads to better performance than freezing all layers, especially for complex or minority classes. This allows gradient updates to reshape internal feature representations for the clinical domain. The pre-trained models provide a strong starting point, but domain-specific adaptation through unfreezing is crucial for optimal performance.

## Foundational Learning
The paper demonstrates that using transformer models pre-trained on large text corpora (BERT, Llama) provides a strong foundation for clinical relation extraction. The pre-training on general text gives these models rich linguistic knowledge that can be adapted to clinical domains. The ability to fine-tune these models on specific clinical datasets allows them to learn the particular vocabulary and context patterns relevant to medical text. The success of RelCAT suggests that pre-trained transformers are effective for clinical NLP tasks when combined with appropriate fine-tuning strategies.

## Architecture Onboarding
RelCAT is built on the MedCAT framework, which provides NER+L capabilities. The architecture extends MedCAT by adding transformer-based relation classification. The system accepts clinical text as input, uses MedCAT to identify and standardize entities, then applies transformer models to classify relationships between these entities. The architecture supports multiple entity representation methods (special tokens, token indices) and allows for context window selection around entities. The design is modular, allowing different transformer models (BERT, Llama) to be plugged in. The system also includes a custom annotation tool within MedCATTrainer for dataset creation and annotation.

## Open Questions the Paper Calls Out
The paper identifies several open questions and areas for future work. One key question is how to improve performance on minority classes, particularly for complex relation types like Adverse Drug Event-Drug. Another question is how to handle the large number of rare relation types that may appear in real-world clinical data but are not well-represented in training datasets. The paper also suggests exploring alternative entity representation methods and context selection strategies. Additionally, the authors note that evaluating on larger, more diverse real-world datasets would be valuable for assessing the system's generalizability.

## Limitations
The primary limitation is that the system's performance on real-world NHS datasets, while strong, does not reach the same level as on the gold-standard n2c2 dataset. This suggests potential challenges in generalizing from curated datasets to actual clinical practice. The performance on minority classes, while improved, still shows room for enhancement, particularly for complex relations like ADE-Drug. The system's reliance on pre-existing entity annotations from MedCAT means its performance is partially dependent on the quality of the underlying NER+L system. Additionally, the evaluation focuses primarily on English clinical text, limiting insights into multilingual capabilities.

## Confidence
The reported performance metrics are based on established benchmarks (n2c2) and are compared against previous state-of-the-art results, suggesting reasonable confidence in the quantitative findings. The use of standard evaluation metrics (F1-score, precision, recall) and the comparison across multiple datasets (gold-standard and real-world) strengthens confidence in the results. However, the evaluation is limited to specific relation types and datasets, and real-world clinical deployment may present additional challenges not captured in the evaluation.

## Next Checks
Future evaluation should include testing on additional clinical datasets to assess generalizability across different healthcare systems and document types. Investigation into the system's performance on emerging or evolving clinical terminology would be valuable. Further work on improving minority class performance, particularly for complex relations, is needed. The system should be tested in actual clinical deployment scenarios to identify practical limitations. Exploring the system's performance with multilingual clinical text would extend its applicability. Additionally, examining the computational requirements and efficiency of the system for large-scale deployment would be important for practical implementation.