---
ver: rpa2
title: 'Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step
  High-Quality Generation'
arxiv_id: '2505.13377'
source_url: https://arxiv.org/abs/2505.13377
tags:
- diffusion
- ambient
- data
- distillation
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Restoration Score Distillation (RSD), a two-phase
  framework for learning high-fidelity generative models directly from corrupted data
  without access to clean samples. RSD first pretrains a teacher diffusion model on
  corrupted observations using corruption-aware objectives (e.g., Ambient Tweedie,
  Ambient Diffusion, Fourier-space variants), then distills it into a one-step generator.
---

# Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step High-Quality Generation

## Quick Facts
- arXiv ID: 2505.13377
- Source URL: https://arxiv.org/abs/2505.13377
- Reference count: 40
- Learns high-fidelity generative models directly from corrupted data without clean samples via a two-phase framework

## Executive Summary
This paper introduces Restoration Score Distillation (RSD), a framework for learning clean generative models directly from corrupted observations. RSD operates in two phases: first pretraining a diffusion teacher model on corrupted data using corruption-aware objectives, then distilling it into a one-step generator via score distillation. The method handles diverse corruption types including blurring, inpainting, and super-resolution, and consistently outperforms both its teacher and recent baselines across natural and scientific datasets, achieving FID scores as low as 4.44 while providing 25× faster inference.

## Method Summary
RSD is a two-phase framework that learns clean generative models from corrupted data without access to clean samples. Phase I pretrains a diffusion teacher using corruption-aware objectives (Ambient Tweedie, Ambient Diffusion, Fourier-space variants) to model p(A(x)) or p(x|y) where y = A(x) + σε. Phase II distills the teacher into a one-step generator using SiD-style Fisher divergence, where the generator produces samples whose corrupted versions match teacher scores. The framework is compatible with advanced diffusion techniques and uses Proximal FID for model selection when clean data is unavailable.

## Key Results
- Consistently surpasses teacher model across diverse restoration tasks on both natural (CelebA-HQ) and scientific (multi-coil MRI) datasets
- Achieves FID scores as low as 4.44 in random inpainting and 12.99 in super-resolution
- Provides 25× faster inference compared to multi-step diffusion models
- Extends denoising score distillation beyond pure noise to general corruption operators like blurring, inpainting, and super-resolution

## Why This Works (Mechanism)

### Mechanism 1: Eigenspace Recovery Through Fisher Divergence Minimization
The distillation process minimizes Fisher divergence between teacher and student score distributions, which in a linear low-rank regime recovers the eigenspace of clean data covariance. This acts as implicit regularization, aligning the generator's covariance structure with the true data distribution. The theoretical guarantee shows global minimizers recover eigenvectors of clean data covariance (up to perturbations in the kernel of A), though this relies on strong linear assumptions that may not hold for deep networks.

### Mechanism 2: Corruption-Aware Pretraining Provides Unbiased Score Estimation
Ambient Tweedie and Ambient Diffusion objectives account for known corruption operators and noise levels, learning to model p(A(x)) or p(x|y) without introducing systematic bias from the corruption. These objectives prevent the model from simply copying observed pixels and force inference of missing structure, yielding a teacher that encodes useful structure about the clean distribution despite being trained on corrupted data.

### Mechanism 3: Distillation Amplifies Signal-to-Artifact Ratio
The one-step distilled generator outperforms its multi-step teacher by filtering out corruption-induced artifacts during knowledge transfer. The generator learns to produce samples that are "easy" for the teacher to explain under corruption, effectively pushing the generator toward the clean data manifold. This requires the teacher to encode useful structure about the clean distribution and the optimization landscape to be navigable.

## Foundational Learning

- **Score-based generative models (diffusion models)**: Understanding forward/reverse processes, Tweedie's formula, and score matching is essential since RSD builds on diffusion pretrained on corrupted data. Quick check: Given xt = x + σtε, what does the denoising autoencoder fϕ(xt, t) approximate?

- **Fisher divergence**: SiD-style distillation uses Fisher divergence between teacher and student score distributions as the training objective. Quick check: Write the Fisher divergence D_F(p, q) between two distributions in terms of their score functions ∇log p and ∇log q.

- **Linear inverse problems and corruption operators**: RSD handles y = A(x) + σε where A may be blur, mask, downsample, or Fourier mask. Understanding operator properties (rank, null space) informs task selection. Quick check: For A = downsampling by 2×, what is ker(A) and how does it affect recoverability?

## Architecture Onboarding

- **Component map**: 
  1. Pretraining module (choose objective per corruption type) → 2. EDM-style U-Net denoiser fϕ(·, t) → 3. Distillation module (Generator Gθ, fake diffusion model fψ) → 4. Corruption re-application A(·) + σε → 5. SiD-style Fisher divergence loss with α=1.2

- **Critical path**: 
  1. Identify corruption type → select pretraining objective (Tab. 1) 
  2. Pretrain fϕ for 100M image iterations on corrupted dataset {y(i)}
  3. Initialize Gθ, fψ ← fϕ
  4. Distill for 50-100M iterations: sample z → xg = Gθ(z) → corrupt → update fψ → update Gθ via Eq. 11
  5. Use Proximal FID (Sec. 5.3) for model selection when clean data unavailable

- **Design tradeoffs**: 
  - Standard vs. corruption-aware pretraining: Standard is simpler but may not remove noise bias; Ambient Tweedie adds complexity but handles noise
  - Distillation length: Longer improves quality but risks divergence; monitor FID curves
  - α in Eq. 11: Paper uses 1.2 (from SiD); tuning may help for new domains

- **Failure signatures**: 
  - Teacher FID very high (>250) and not improving → pretraining failed; check corruption alignment
  - Distillation FID diverges after initial drop → reduce learning rate or enable early stopping
  - Generated samples look like corrupted data → corruption not re-applied in distillation loop

- **First 3 experiments**: 
  1. Sanity check on synthetic data: Generate low-rank Gaussian data x ∈ R^64, corrupt with A = random 32×64 matrix, σ = 0.1. Pretrain with Standard Diffusion, distill, verify eigenspace recovery by comparing top eigenvectors of generated covariance to ground truth.
  2. Random inpainting on CelebA-HQ 64×64: Download Ambient Diffusion checkpoint, distill using RSD, compare FID to teacher at p = 0.6, 0.8, 0.9.
  3. Ablation on pretraining objective: For Gaussian deblurring with σ = 0.2, compare Standard Diffusion vs. Ambient Tweedie pretraining followed by same distillation; report FID gap.

## Open Questions the Paper Calls Out

- **Conditional sampling for inverse problems**: While RSD learns a clean data distribution from corrupted observations, it doesn't inherently support conditional sampling based on a specific observation. Extending the framework into a conditional solver for inverse problems is a promising future direction.

- **Unknown corruption operators**: In practical scenarios where only corrupted datasets are available, the true corruption operator is often unknown. The method currently assumes access to corruption propagation, not explicit formulas, which may limit applicability in real-world scientific data.

- **EM-Diffusion exception**: Table 2 shows EM-Diffusion outperforms RSD specifically in Gaussian deblurring with σ = 0.2 noise (FID 51.33 vs 76.98), despite EM-Diffusion using only 50 clean samples. Understanding this exception could reveal important limitations.

- **Theoretical extension to nonlinear settings**: Theorem 1 analysis considers the rank-r = 1 case for simplicity, and Assumption 1 requires a low-rank linear model that may not hold for complex natural images. Real data distributions are high-rank and generated through nonlinear processes.

## Limitations
- Theoretical claims rely on strong simplifying assumptions (linear low-rank data, perfect score estimation, low-rank linear generators) that may not hold in practical deep learning settings
- Framework performance depends critically on the quality of the corruption operator specification and the ability to train effective teacher models on corrupted data
- The method's effectiveness is uncertain for severely nonlinear corruption processes or when the corruption operator is unknown

## Confidence
- **High confidence**: Empirical improvements over teacher models across multiple tasks (CelebA-HQ and MRI datasets), with substantial FID gains and 25× inference speedup
- **Medium confidence**: The theoretical eigenspace recovery claim, which relies on idealized linear assumptions
- **Medium confidence**: The mechanism by which distillation amplifies signal-to-artifact ratio, as this depends on teacher model quality and the optimization landscape

## Next Checks
1. **Synthetic data validation**: Generate low-rank Gaussian data corrupted with known linear operators, apply RSD, and verify eigenspace recovery by comparing top eigenvectors of generated vs. ground truth covariance matrices.

2. **Teacher quality threshold**: Systematically evaluate RSD performance as a function of teacher model FID (e.g., using pretrained teachers with FID ranging from 50-300) to identify the minimum viable teacher quality for successful distillation.

3. **Corruption operator robustness**: Test RSD on increasingly nonlinear corruption operators (e.g., learned or adversarial corruptions) to assess the framework's robustness when the corruption process deviates from the assumed linear structure.