---
ver: rpa2
title: Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems
arxiv_id: '2512.05580'
source_url: https://arxiv.org/abs/2512.05580
tags:
- reasoning
- prompting
- bengali
- problems
- shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first systematic evaluation of Tree-of-Thought
  (ToT) reasoning for Bengali mathematical word problems using the SOMADHAN dataset.
  The study compares standard prompting, Chain-of-Thought (CoT), and ToT strategies
  across multiple large language models (LLMs) including GPT-OSS and LLaMA variants.
---

# Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems

## Quick Facts
- arXiv ID: 2512.05580
- Source URL: https://arxiv.org/abs/2512.05580
- Authors: Aurprita Mahmood; Sabrin alam; Neloy kumer Sagor; Md. Abdul Hadi; Md. Sehab Al Islam; Minhajul Islam
- Reference count: 17
- Primary result: Tree-of-Thought (ToT) prompting achieves 88% accuracy on Bengali math word problems, outperforming Chain-of-Thought by up to 5 percentage points

## Executive Summary
This paper presents the first systematic evaluation of Tree-of-Thought (ToT) reasoning for Bengali mathematical word problems using the SOMADHAN dataset. The study compares standard prompting, Chain-of-Thought (CoT), and ToT strategies across multiple large language models (LLMs) including GPT-OSS and LLaMA variants. Results show that ToT improves reasoning accuracy over CoT by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. The improvements are particularly notable in medium-to-large-scale models, while smaller models show less benefit from ToT.

## Method Summary
The study evaluates three prompting strategies (standard, CoT, and ToT) on Bengali math word problems from the SOMADHAN dataset using multiple LLMs. Models were tested via the Groq API with fixed temperature (1.0) and max tokens (1024). CoT experiments varied shot counts (1/2/5/7-shot), while ToT used zero-shot prompting with explicit multi-path instructions. Accuracy was determined through manual human validation of final numeric answers on a 100-problem subset.

## Key Results
- ToT achieved 88% accuracy with GPT-OSS-120B, outperforming CoT by up to 5 percentage points
- ToT is particularly effective in medium-to-large-scale models (≥17B parameters) but shows limited advantage for smaller models
- LLaMA-3.1-8B demonstrated unstable behavior with ToT (31% accuracy) versus 7-shot CoT (73% accuracy)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree-of-Thought (ToT) prompting improves accuracy over Chain-of-Thought (CoT) by enabling parallel exploration of multiple reasoning paths with explicit selection.
- Mechanism: The model generates multiple candidate solution branches (Path 1, Path 2, Path 3), evaluates intermediate steps, and selects the most consistent final answer. This contrasts with CoT's single linear trajectory where errors compound irrecoverably.
- Core assumption: The model possesses sufficient reasoning capacity to simultaneously maintain and evaluate multiple solution paths without degrading coherence.
- Evidence anchors:
  - [abstract] "ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B"
  - [section V] "ToT outperformed CoT by up to five percentage points, with GPT-OSS-120B reaching its peak accuracy of 88%"
  - [corpus] Weak direct corpus support; neighbor papers focus on CoT for Bengali MWPs, not ToT comparisons
- Break condition: Small models (<10B parameters) lack capacity for multi-path reasoning—LLaMA-3.1-8B collapsed to 31% under ToT versus 73% with 7-shot CoT.

### Mechanism 2
- Claim: ToT reduces error propagation by allowing backtracking and branch selection.
- Mechanism: When an intermediate step appears inconsistent, the model can abandon that branch and proceed with alternatives rather than committing to a flawed linear chain.
- Core assumption: The model can self-assess reasoning quality at intermediate steps without external verification.
- Evidence anchors:
  - [abstract] "CoT follows a single linear reasoning trajectory, and an early error within this chain often propagates throughout the solution process"
  - [section I] "ToT provides a more flexible and globally consistent reasoning framework than conventional linear approaches"
  - [corpus] Long (2023) showed ToT with backtracking significantly outperformed CoT on Sudoku puzzles—external validation of backtracking benefits
- Break condition: Without external validators, self-assessment may fail; models may select incorrect branches with high confidence.

### Mechanism 3
- Claim: ToT benefits scale with model size; medium-to-large models (≥17B parameters) show consistent gains while small models show instability or degradation.
- Mechanism: Larger parameter counts provide the representational capacity to maintain multiple coherent reasoning threads simultaneously.
- Core assumption: Reasoning capacity correlates positively with parameter scale for structured multi-path exploration.
- Evidence anchors:
  - [abstract] "ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones"
  - [Table I] LLaMA-3.1-8B: 31% (ToT) vs 73% (7-shot CoT); LLaMA-4-Maverick-17B: 88% (ToT) vs 83% (CoT peak)
  - [corpus] ToTRL paper notes prolonged CoT reasoning presents limitations including verbose outputs—suggests capacity constraints affect structured reasoning broadly
- Break condition: Small models should use CoT with few-shot examples rather than ToT; resource-constrained deployments may find CoT more efficient.

## Foundational Learning

- Concept: **Chain-of-Thought (CoT) Prompting**
  - Why needed here: CoT serves as the baseline against which ToT improvements are measured; understanding linear reasoning limitations contextualizes ToT benefits.
  - Quick check question: Can you explain why CoT's linear structure causes error propagation in multi-step problems?

- Concept: **Few-Shot vs Zero-Shot Prompting**
  - Why needed here: The paper varies shot counts (1/2/5/7-shot for CoT) to find optimal configurations; performance peaked at 5-shot for most models.
  - Quick check question: What happens to CoT accuracy when you increase from 5-shot to 7-shot examples?

- Concept: **Low-Resource Language Challenges in NLP**
  - Why needed here: Bengali lacks extensive training data relative to English; structured reasoning methods may compensate for limited language-specific training.
  - Quick check question: Why might a reasoning strategy that works on GSM8K (English) need separate validation for Bengali MWPs?

## Architecture Onboarding

- Component map: Bengali MWP text from SOMADHAN dataset -> Prompting strategy (Standard/CoT/ToT) -> LLM (GPT-OSS/LLaMA) -> Manual answer validation

- Critical path:
  1. Load Bengali MWP from dataset
  2. Apply prompting strategy with appropriate few-shot examples (for CoT)
  3. Model generates response (temperature=1.0, max_tokens=1024)
  4. Extract final numeric answer
  5. Compare against ground truth; manual validation

- Design tradeoffs:
  - **Scope vs depth**: 100-problem subset limits statistical power but enables multi-model comparison within token budgets
  - **ToT vs CoT for small models**: ToT degrades performance below ~10B parameters; use CoT for efficiency
  - **Shot count**: 5-shot CoT provides best cost-performance ratio; 7-shot shows diminishing returns

- Failure signatures:
  - **Small model ToT collapse**: LLaMA-3.1-8B dropping to 31% indicates capacity exceeded
  - **CoT instability at certain shot counts**: 5-shot CoT at 41% for LLaMA-3.1-8B vs 73% at 7-shot suggests sensitivity to example selection
  - **Temperature sensitivity**: Fixed at 1.0; higher values may increase path diversity but reduce consistency

- First 3 experiments:
  1. **Baseline verification**: Replicate standard prompting (zero-shot) on 100-problem subset to confirm 78% baseline for GPT-OSS-20B.
  2. **CoT calibration**: Test 1/2/5/7-shot CoT on a single model to identify optimal shot count before expanding to other architectures.
  3. **Scale boundary test**: Identify the minimum parameter count where ToT consistently outperforms CoT by testing models across 8B-70B range.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the performance advantages of ToT over CoT persist when evaluated on the full SOMADHAN dataset (8,792 samples) and state-of-the-art proprietary models?
- Basis in paper: [explicit] The Limitations section states the study was restricted to 100 samples and open-access models, while Future Work explicitly calls for extending experiments to the complete dataset and incorporating proprietary models.
- Why unresolved: Current conclusions are based on a curated subset of 100 problems due to computational constraints, limiting the generalizability of the 5% improvement metric.
- What evidence would resolve it: Benchmark results comparing ToT and CoT across the full dataset using closed-source models (e.g., GPT-4, Claude 3).

### Open Question 2
- Question: Can hybrid reasoning frameworks, such as validator-augmented ToT or Graph-of-Thought (GoT), further improve accuracy for Bengali MWPs compared to standalone ToT?
- Basis in paper: [explicit] The Conclusion and Future Work section suggests investigating hybrid frameworks like validator-augmented ToT, Graph-of-Thought, or multi-agent systems as a next step.
- Why unresolved: The current study isolated ToT as a specific intervention; it did not combine ToT with external verification modules or graph-based aggregation.
- What evidence would resolve it: Comparative experiments on Bengali MWPs using GoT or multi-agent ToT setups showing superior accuracy over the reported 88% baseline.

### Open Question 3
- Question: What is the minimum parameter scale or architectural requirement for models to effectively utilize Tree-of-Thought reasoning without performance degradation?
- Basis in paper: [inferred] The Results and Limitations sections note that smaller models like LLaMA-3.1-8B showed "highly unstable behavior," with accuracy collapsing to 31% under ToT.
- Why unresolved: The paper demonstrates that small models fail but does not determine if this is due to context window limitations, instruction-tuning data, or fundamental reasoning capacity.
- What evidence would resolve it: An ablation study varying model sizes (e.g., 7B vs. 13B vs. 30B) to identify the inflection point where ToT becomes beneficial rather than detrimental.

## Limitations

- The study was limited to 100 problems from the 8,792-problem SOMADHAN dataset, constraining statistical power
- Manual validation introduces potential subjectivity in borderline cases
- The study focused exclusively on zero-shot ToT without exploring few-shot examples for multi-path reasoning
- Temperature was fixed at 1.0 across all experiments without testing different values

## Confidence

- **High confidence**: ToT's superiority over standard prompting (78% → 88% for GPT-OSS-120B), and ToT's degradation for models below 10B parameters (LLaMA-8B at 31% ToT vs 73% CoT)
- **Medium confidence**: The claim that ToT reduces error propagation through backtracking, as this relies on implicit rather than explicit path selection mechanisms
- **Medium confidence**: The 5-shot optimal configuration for CoT, given the small sample size and potential sensitivity to example selection

## Next Checks

1. **Scale up evaluation set**: Test the full SOMADHAN dataset (8,792 problems) using GPT-OSS-120B with ToT prompting to establish confidence intervals and detect edge cases where structured reasoning fails

2. **Cross-linguistic validation**: Apply identical ToT methodology to English GSM8K problems to determine whether observed benefits transfer across language pairs or represent Bengali-specific phenomena

3. **External validation integration**: Modify ToT prompting to include explicit intermediate step verification (either through self-consistency or external calculators) to test whether automated validation improves branch selection quality beyond the current implicit self-assessment approach