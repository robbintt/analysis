---
ver: rpa2
title: 'SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual
  Instruction Tuning'
arxiv_id: '2505.02486'
source_url: https://arxiv.org/abs/2505.02486
tags:
- forgetting
- answer
- question
- task
- superficial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in Multimodal Continual
  Instruction Tuning (MCIT), categorizing it into superficial forgetting (response
  format deviation) and essential forgetting (actual knowledge loss). To mitigate
  these issues, the authors propose the SEFE method, which introduces the Answer Style
  Diversification (ASD) paradigm to prevent superficial forgetting by diversifying
  response formats during training, and RegLoRA to minimize essential forgetting by
  stabilizing critical parameters through regularization.
---

# SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning

## Quick Facts
- arXiv ID: 2505.02486
- Source URL: https://arxiv.org/abs/2505.02486
- Authors: Jinpeng Chen; Runmin Cong; Yuzhi Zhao; Hongzheng Yang; Guangneng Hu; Horace Ho Shing Ip; Sam Kwong
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on CoIN benchmark with MFN 58.57% and MAA 63.04%, significantly reducing both superficial and essential forgetting in multimodal continual instruction tuning.

## Executive Summary
This paper addresses catastrophic forgetting in Multimodal Continual Instruction Tuning (MCIT) by distinguishing between superficial forgetting (response format deviation) and essential forgetting (actual knowledge loss). The authors propose the SEFE method, which combines Answer Style Diversification (ASD) to prevent superficial forgetting by diversifying response formats during training, and RegLoRA to minimize essential forgetting by stabilizing critical parameters through regularization. Experimental results on the CoIN benchmark demonstrate that SEFE achieves state-of-the-art performance, significantly reducing forgetting across both categories and improving overall model accuracy.

## Method Summary
SEFE addresses catastrophic forgetting in MCIT through two complementary mechanisms. First, Answer Style Diversification (ASD) transforms 20% of each task's training data into four alternative formats (yes/no, MCQ, short answer, brief/detailed explanation) to prevent superficial forgetting caused by style shifts. Second, RegLoRA applies selective regularization to the top 2% of elements in LoRA weight update matrices across all prior tasks, identified by absolute value magnitude, to stabilize critical parameters where prior knowledge is primarily stored. The method is evaluated on the CoIN benchmark using LLaVA-1.5 with Vicuna-7B LLM, achieving 58.57% MFN and 63.04% MAA.

## Key Results
- SEFE achieves MFN 58.57% and MAA 63.04% on CoIN benchmark, significantly outperforming baseline LoRA
- ASD alone improves baseline MFN from 41.59% to 47.88% by reducing format-consistency errors
- RegLoRA further improves performance to 58.57% MFN by stabilizing critical weight update elements
- The top 1% of elements in ∆W matrices have average absolute values 580× greater than bottom 1%, justifying selective regularization

## Why This Works (Mechanism)

### Mechanism 1: Answer Style Diversification (ASD) Reduces Response Format Bias
Converting single-format task data into multi-format datasets prevents the model from developing biased response styles that cause superficial forgetting. ASD transforms X% of each task's training data equally into four alternative formats (yes/no, MCQ, short answer, brief/detailed explanation), ensuring the model encounters all five question types per task. This breaks the sequential style bias where later tasks' formats override earlier ones.

### Mechanism 2: RegLoRA Regularizes High-Magnitude Weight Update Elements
Selective regularization of the top M% elements in LoRA weight update matrices (∆W = B × A) preserves prior knowledge while maintaining learning capacity. After completing task i, compute ∆W_i = B_i × A_i, identify top 2% elements by absolute value, create binary mask R_i. During subsequent training, add L_reg = λ × Σ|∆W_j ⊗ R_i| to encourage near-zero updates at critical positions identified from all prior tasks.

### Mechanism 3: Sequential Treatment of Superficial Then Essential Forgetting
Addressing superficial forgetting via ASD is prerequisite to accurately measuring and addressing essential forgetting via RegLoRA. ASD ensures format-consistent outputs, revealing true knowledge state. RegLoRA then protects this knowledge by constraining updates to critical parameter positions across sequential tasks.

## Foundational Learning

- **Concept: Catastrophic Forgetting in Neural Networks**
  - Why needed: SEFE is fundamentally a solution to catastrophic forgetting in sequential multimodal task learning.
  - Quick check: After fine-tuning a model on Task B, why might Task A performance drop even though Task A weights still exist?

- **Concept: LoRA (Low-Rank Adaptation)**
  - Why needed: RegLoRA extends LoRA; understanding ∆W = B × A decomposition is essential for mask generation.
  - Quick check: Given pretrained weight W ∈ R^(k×d), how does LoRA represent updates using matrices A ∈ R^(r×d) and B ∈ R^(k×r) where r ≪ min(d,k)?

- **Concept: Regularization-based Continual Learning**
  - Why needed: RegLoRA is a regularization approach; understanding the stability-plasticity trade-off is critical.
  - Quick check: Why might regularizing all parameters equally harm new task acquisition?

## Architecture Onboarding

- **Component map:** Input: (Image, Instruction) → Vision Encoder [frozen] → LLM Backbone + LoRA adapters (W + B×A per layer) → Training Loop

- **Critical path:**
  1. ASD data prep (once per dataset): Use InternVL2-26B or equivalent MLLM to transform 20% of samples across 4 formats
  2. Per-task training: Initialize new LoRA, load accumulated masks R₁...Rᵢ₋₁, train with L_total = L_lm + L_reg
  3. Mask generation: Post-training, compute ∆W = B × A, extract top 2% positions, append to mask collection

- **Design tradeoffs:**
  - X (transformation %): 10% minimal viable, 20% optimal. Higher X trades MFT for long-term retention.
  - M (regularized %): 2% optimal. M < 1% under-protects; M > 5% over-constrains plasticity.
  - Regularization target: ∆W outperforms A, B, or A&B individually because ∆W directly encodes knowledge changes.

- **Failure signatures:**
  - Format errors persist on old tasks: ASD not applied or X < 10%
  - New task accuracy drops 10%+ vs baseline: M > 5% or λ too aggressive
  - Old task knowledge degrades despite RegLoRA: M < 1% or mask accumulation failing
  - GPU OOM during mask computation: Reduce LoRA rank r or compute masks on CPU post-training

- **First 3 experiments:**
  1. ASD isolation test: Train baseline LoRA on CoIN tasks 1-4, measure format-consistency rate. Add ASD (X=20), verify format error reduction >50%.
  2. RegLoRA isolation test: On CoIN-ASD, compare LoRA vs. RegLoRA (M=2, λ=2.5×10³) on backward transfer (BWT metric).
  3. M sensitivity analysis: Sweep M ∈ {0.5, 1, 2, 5} on 3-task sequence; plot MFN vs. MFT to identify optimal stability-plasticity point for your model scale.

## Open Questions the Paper Calls Out

### Open Question 1
How does the accumulation of regularization masks in RegLoRA affect model plasticity in significantly longer task sequences where mask overlap becomes frequent? The paper notes that overlapping masks increase regularization weight, but only evaluates performance on an 8-task benchmark (CoIN). It is unclear if the "increased resistance to further updates" caused by mask accumulation will eventually prevent the model from learning new tasks effectively in lifelong learning scenarios.

### Open Question 2
Is the Answer Style Diversification (ASD) paradigm's reliance on five standardized question formats sufficient for complex, specialized multimodal domains? The authors state that "certain cases may require minor adjustments" to the five identified types to fit various MCIT applications. The framework assumes these five types cover the majority of scenarios, but specialized domains like medical imaging or chart-to-code generation may require structurally different response formats.

### Open Question 3
How does the choice of LoRA rank (r) influence the granularity and effectiveness of RegLoRA's top-M% element selection strategy? The implementation fixes the rank at 128, but the identification of "key elements" depends on the dimensions of the weight update matrix ∆W. Regularizing a fixed percentage (top 2%) may have different semantic implications when the underlying matrix is much smaller (e.g., rank 8) or larger.

## Limitations

- Limited ablation of ASD threshold (X): The paper selects X=20% based on Table 3, but the sensitivity analysis is relatively narrow and may not generalize across model scales or task complexities.
- Mask accumulation complexity: RegLoRA's effectiveness depends on proper mask accumulation across tasks, but computational overhead and memory requirements as task count scales are not detailed.
- Orthogonality assumption: The sequential treatment of superficial then essential forgetting assumes these are independent problems, which may be suboptimal if both forgetting modes share underlying causes.

## Confidence

- **High confidence:** The distinction between superficial and essential forgetting is well-motivated and empirically observable. The format-consistency improvements from ASD are substantial and clearly demonstrated. The claim that RegLoRA's selective regularization works better than full-parameter regularization is strongly supported by magnitude distribution evidence.
- **Medium confidence:** The optimal hyperparameters (X=20%, M=2%, λ=2.5×10³) are claimed based on ablation studies but could be task- or model-specific with limited evidence for generalizability.
- **Low confidence:** The claim that ASD is prerequisite to accurate essential forgetting measurement is theoretical rather than empirically validated.

## Next Checks

1. **Hyperparameter robustness test:** Sweep X from 5% to 50% on CoIN with varying task complexities to establish the relationship between transformation percentage and model scale.
2. **Orthogonality validation:** Train a variant applying RegLoRA directly to baseline LoRA without ASD preprocessing. Compare essential forgetting rates to determine if superficial forgetting must be eliminated first.
3. **Scale-up experiment:** Apply SEFE to 16 sequential tasks (double CoIN) and measure memory/compute overhead from mask accumulation. Track whether MFN and MAA improvements persist at scale.