---
ver: rpa2
title: Do LLMs Signal When They're Right? Evidence from Neuron Agreement
arxiv_id: '2510.26277'
source_url: https://arxiv.org/abs/2510.26277
tags:
- neuron
- neurons
- early
- token
- activated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models signal correctness
  through their internal neuron activations. The authors find that correct responses
  activate significantly fewer unique neurons than incorrect ones, and that correct
  responses exhibit stronger cross-sample neuron agreement.
---

# Do LLMs Signal When They're Right? Evidence from Neuron Agreement

## Quick Facts
- arXiv ID: 2510.26277
- Source URL: https://arxiv.org/abs/2510.26277
- Reference count: 26
- Primary result: Neuron activation sparsity and cross-sample agreement predict response correctness without ground truth

## Executive Summary
This paper demonstrates that large language models signal correctness through their internal neuron activations. Correct responses activate substantially fewer unique neurons than incorrect ones, and exhibit stronger cross-sample neuron agreement. The authors propose Neuron Agreement Decoding (NAD), an unsupervised method that selects high-quality responses by measuring neuron activation sparsity and cross-sample agreement without requiring comparable textual outputs. NAD enables early correctness prediction within the first 32 tokens and achieves substantial efficiency gains, reducing token usage by up to 99% with minimal loss in generation quality.

## Method Summary
NAD selects responses via activation sparsity (MinAct) or cross-sample agreement (kNN/Medoid/DBSCAN on Jaccard similarity). The method generates n=64 parallel samples, computes per-neuron contributions using SwiGLU feed-forward network activations, aggregates over 32-token chunks, and selects responses based on either minimal activation counts or maximal cross-sample agreement. The approach works without ground truth labels and enables early stopping after the first chunk, achieving significant computational savings while maintaining or improving accuracy compared to majority voting.

## Key Results
- Correct responses activate significantly fewer unique neurons than incorrect ones across math, science, and coding tasks
- Neuron activation patterns from correct responses show stronger cross-sample agreement than incorrect responses
- NAD achieves up to 99% token reduction with minimal accuracy loss while outperforming majority voting and random sampling

## Why This Works (Mechanism)

### Mechanism 1: Activation Sparsity Signal
Correct responses activate fewer unique neurons because correct reasoning follows more direct computational paths while incorrect responses engage in excessive exploration. This signal is strongest on math and science tasks but weakens on open-ended code generation where multiple valid implementations require broader knowledge activation.

### Mechanism 2: Cross-Sample Neuron Agreement
Correct reasoning converges on similar internal representations across samples, while incorrect reasoning follows divergent paths producing inconsistent activation patterns. This consensus signal correlates with answer correctness but may break down on tasks with multiple equally valid reasoning approaches.

### Mechanism 3: Early Internal Signal Extraction
Response correctness can be predicted from neuron activations within the first 32 tokens because early tokens establish reasoning trajectory patterns. Additional tokens may introduce noise that dilutes the predictive signal rather than strengthening it, though this assumes reasoning quality determinants emerge early.

## Foundational Learning

- **SwiGLU Feed-Forward Networks**: Neuron activation contribution formula is designed specifically for SwiGLU-based FFNs; other architectures require modified formulations. Quick check: Can you compute neuron i's contribution to token y_j using the SwiGLU formula with hidden input x and gate projection W_g?

- **Jaccard Index for Set Similarity**: NAD uses Jaccard similarity to quantify agreement between activation sets, underlying all consensus-based selection methods. Quick check: If set A has 200 neurons and set B has 150 neurons with 100 overlapping, what is J(A,B)?

- **Chunk-Based Activation Aggregation**: Activations are aggregated over B-sized chunks rather than per-token to capture localized reasoning patterns while reducing noise. Quick check: Why might per-token activation analysis produce noisier signals than chunk-level aggregation?

## Architecture Onboarding

- **Component map**: Input Prompt → Parallel Sampling (n=64 responses) → Forward Pass → Per-Neuron Contributions → Chunk Aggregation (B=32 tokens) → Threshold Function (top-k=500) → Activated Neuron Set per Response → Selection Strategy (kNN/Medoid/DBSCAN/MinAct) → Selected Response → Complete Generation

- **Critical path**: The threshold function determines which neurons qualify as "activated." Incorrect thresholding cascades into degraded selection quality.

- **Design tradeoffs**: Storage vs. Selection Quality (kNN/Medoid/DBSCAN require storing full activation sets; MinAct uses only neuron counts); Early stopping position (B=32 balances savings vs. signal reliability); Selection method choice (kNN most consistent; MinAct fails on code generation).

- **Failure signatures**: Accuracy no better than Avg@64 → verify threshold implementation; check if model uses SwiGLU. MinAct underperforms on code tasks → expected per Figure 6; switch to kNN for open-ended generation. Minimal token savings → confirm early stopping is triggered at chunk boundary.

- **First 3 experiments**: 1) Validate sparsity signal: On 100 AIME samples, plot neuron counts for correct vs. incorrect responses to confirm distribution separation. 2) Calibrate early stopping position: Test B ∈ {32, 64, 128} on validation set to find optimal tradeoff. 3) Compare selection strategies: Run all four methods on held-out benchmark to determine best performer for target task type.

## Open Questions the Paper Calls Out

1. Which selector method (kNN, Medoid, DBSCAN, MinAct) is optimal under different sampling patterns, model architectures, and task domains? The paper reports varied performance across selectors but provides no principled framework for choosing among them.

2. Why does minimizing neuron activations improve accuracy on math/science tasks but not consistently on code generation tasks? The authors hypothesize code requires broader knowledge activation, but this remains untested.

3. Can space-efficient representations of neuron activations achieve comparable selection quality while reducing storage overhead? While bitset encodings are mentioned, no systematic comparison of compression techniques has been conducted.

## Limitations

- Method depends on SwiGLU architecture and may not generalize to other FFN designs
- Signal reverses on open-ended tasks where multiple valid approaches require broader knowledge activation
- Computational overhead remains substantial despite token savings due to storage requirements for activation sets

## Confidence

**High Confidence**: Correct responses activate fewer neurons than incorrect ones (confirmed across all benchmarks); Cross-sample neuron agreement is higher for correct responses (confirmed in t-SNE visualization); NAD outperforms random sampling consistently.

**Medium Confidence**: NAD achieves 99% token reduction with minimal accuracy loss (validated on Qwen3 models only); Early stopping at B=32 provides optimal tradeoff (tested on limited benchmark subset); DBSCAN clustering effectively identifies high-quality response groups (described but not extensively validated).

**Low Confidence**: Method generalizes to other model architectures beyond SwiGLU-based models; Performance scales to larger models without degradation; Method works for highly subjective or creative tasks where correctness is ambiguous.

## Next Checks

1. Apply NAD to a non-SwiGLU model (e.g., LLaMA with GeLU activations) to verify the neuron contribution formula generalizes or requires modification.

2. Systematically test NAD on tasks with varying correctness ambiguity (creative writing, multiple solution math problems, open-ended design questions) to quantify where sparsity/agreement signals break down.

3. Conduct ablation studies varying the top-k threshold (100, 300, 500, 1000) across different model scales and task types to determine if task-specific threshold calibration is necessary.