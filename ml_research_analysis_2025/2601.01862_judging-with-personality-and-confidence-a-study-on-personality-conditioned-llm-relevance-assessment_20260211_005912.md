---
ver: rpa2
title: 'Judging with Personality and Confidence: A Study on Personality-Conditioned
  LLM Relevance Assessment'
arxiv_id: '2601.01862'
source_url: https://arxiv.org/abs/2601.01862
tags:
- personality
- confidence
- relevance
- high
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how simulating personality traits in large
  language models (LLMs) influences automated relevance assessment in information
  retrieval. By infusing LLMs with Big Five personality traits, the research examines
  both alignment with human judgments and confidence calibration.
---

# Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment

## Quick Facts
- arXiv ID: 2601.01862
- Source URL: https://arxiv.org/abs/2601.01862
- Reference count: 40
- Primary result: Personality infusion in LLMs improves relevance assessment alignment with human judgments while addressing overconfidence issues

## Executive Summary
This study investigates how simulating personality traits in large language models influences automated relevance assessment in information retrieval. By infusing LLMs with Big Five personality traits, the research examines both alignment with human judgments and confidence calibration. Experiments across five LLMs and three datasets reveal that Low Agreeableness consistently improves human alignment, while Low Conscientiousness and High Neuroticism effectively suppress overconfidence, enhancing overall calibration.

The research introduces a random forest classifier that integrates personality-conditioned scores and confidence values as features, outperforming single-personality baselines even with limited training data. This approach leverages personality-derived confidence as a complementary signal, advancing reliable, human-aligned LLM-based evaluation systems.

## Method Summary
The study employs five LLMs (GPT-3.5, GPT-4, Llama-2, Llama-3, and Claude-3) to assess document relevance across three datasets: MS MARCO, TREC Robust, and TREC-COVID. Each LLM is prompted to simulate Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) by role-playing a person with that trait. The researchers evaluate both alignment with human judgments and confidence calibration. A random forest classifier is then trained using personality-conditioned scores and confidence values as features to combine multiple personality perspectives effectively.

## Key Results
- Low Agreeableness consistently improves human alignment across all models and datasets
- Low Conscientiousness and High Neuroticism effectively suppress overconfidence while maintaining accuracy
- Random forest classifier with multi-personality features outperforms single-personality baselines, especially with limited training data

## Why This Works (Mechanism)
Personality infusion works by conditioning LLM behavior through role-play prompts that simulate specific personality traits. This conditioning influences both the relevance assessment process and the confidence calibration. Different personality traits affect these two dimensions differently: Agreeableness primarily impacts alignment with human judgments, while Conscientiousness and Neuroticism more strongly influence confidence calibration. The mechanism appears to work through altering the LLM's risk tolerance and decision-making patterns during assessment.

## Foundational Learning
- **Big Five Personality Traits**: The five-factor model (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) provides a standardized framework for personality simulation. Why needed: Offers a well-established psychological foundation for systematic personality infusion. Quick check: Ensure proper mapping of personality traits to their psychological definitions.
- **Confidence Calibration**: The alignment between predicted confidence scores and actual accuracy. Why needed: Critical for reliable automated evaluation systems. Quick check: Compare confidence intervals with actual error rates.
- **Random Forest Classification**: An ensemble learning method that combines multiple decision trees. Why needed: Effectively integrates multiple personality perspectives while handling limited training data. Quick check: Evaluate feature importance and cross-validation performance.
- **Role-play Prompting**: A technique where LLMs are instructed to simulate specific personas or traits. Why needed: Enables systematic personality infusion without model fine-tuning. Quick check: Test prompt variations for consistency.

## Architecture Onboarding

Component Map: LLM -> Personality Infusion -> Relevance Assessment -> Confidence Calibration -> Random Forest Classifier

Critical Path: The core workflow involves personality-conditioned LLMs performing relevance assessments, with their scores and confidence values serving as features for the random forest classifier. The critical path emphasizes the integration of multiple personality perspectives to produce final evaluation scores.

Design Tradeoffs: The study prioritizes generalization across models and datasets over optimization for specific scenarios. This approach sacrifices some potential performance gains from model-specific tuning but ensures broader applicability. The choice of random forest over neural networks balances performance with interpretability and data efficiency.

Failure Signatures: Poor performance may manifest as systematic biases in certain personality trait assessments, overconfidence in specific domains, or classifier overfitting when training data is insufficient. Monitoring confidence intervals against actual accuracy helps identify calibration failures.

First Experiments:
1. Baseline assessment without personality infusion to establish performance benchmarks
2. Single-trait personality simulations to identify individual trait effects
3. Multi-trait combinations to test optimal personality profiles for specific domains

## Open Questions the Paper Calls Out
The study acknowledges several open questions, particularly regarding the optimal combination of personality traits for different evaluation contexts and the generalizability of findings across diverse retrieval tasks beyond the current datasets.

## Limitations
- The study focuses exclusively on the Big Five personality traits, potentially overlooking other personality frameworks or individual differences
- Evaluation relies on three specific datasets (MS MARCO, TREC Robust, and TREC-COVID), which may not capture full diversity of information retrieval scenarios
- The mechanisms by which personality infusion affects confidence calibration remain unclear and warrant further investigation

## Confidence

| Major Claim Cluster | Confidence Assessment |
|---------------------|-----------------------|
| Personality infusion improves human alignment | High |
| Personality traits effectively control overconfidence | Medium |
| Multi-personality feature integration outperforms single-personality baselines | High |

## Next Checks

1. Cross-domain validation: Test personality-conditioned LLMs on diverse retrieval tasks beyond the current datasets, including specialized domains like legal or medical information retrieval.

2. Longitudinal stability assessment: Evaluate the consistency of personality-conditioned judgments over extended periods and multiple assessment rounds to ensure reliability.

3. Personality framework expansion: Investigate the impact of alternative personality models (e.g., HEXACO, Dark Triad) and trait combinations to identify optimal configurations for different evaluation contexts.