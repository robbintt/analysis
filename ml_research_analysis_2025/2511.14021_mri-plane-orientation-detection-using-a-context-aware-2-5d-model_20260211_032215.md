---
ver: rpa2
title: MRI Plane Orientation Detection using a Context-Aware 2.5D Model
arxiv_id: '2511.14021'
source_url: https://arxiv.org/abs/2511.14021
tags:
- plane
- metadata
- detection
- accuracy
- tumor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of automatically identifying
  MRI slice orientations (axial, coronal, sagittal) when metadata is missing, a common
  issue that complicates medical image analysis and reduces diagnostic accuracy. The
  proposed solution is a 2.5D context-aware model that leverages multi-slice information
  from MRI volumes to overcome the ambiguity of isolated 2D slices.
---

# MRI Plane Orientation Detection using a Context-Aware 2.5D Model

## Quick Facts
- arXiv ID: 2511.14021
- Source URL: https://arxiv.org/abs/2511.14021
- Reference count: 0
- Primary result: 2.5D random-sampling model achieves 99.49% accuracy, reducing errors by 60% compared to 2D baseline

## Executive Summary
This study addresses the challenge of automatically identifying MRI slice orientations (axial, coronal, sagittal) when metadata is missing, a common issue that complicates medical image analysis and reduces diagnostic accuracy. The proposed solution is a 2.5D context-aware model that leverages multi-slice information from MRI volumes to overcome the ambiguity of isolated 2D slices. The model employs a random sampling strategy of three slices ([i, j, k]) from the same volume and plane, which learns robust, identity-level features and acts as an effective regularizer. Trained on a mixed dataset of brain MRI scans, the 2.5D random-sampling model achieved 99.49% accuracy, reducing errors by 60% compared to a 2D reference model. The generated metadata was validated in a brain tumor detection task, where a gated strategy selectively applied metadata based on classifier uncertainty, improving accuracy from 97.0% to 98.0% and reducing misdiagnoses by 33.3%. The system was deployed as an open-source web application for practical use.

## Method Summary
The method uses a 2.5D CNN architecture where three random slices from the same MRI volume and plane are stacked as a 3-channel input to an AlexNet backbone. The model is trained on a mixed dataset of BRISC (tumor patients) and IXI (healthy adults) T1-weighted MRI scans. A gated metadata fusion strategy based on predictive entropy selectively applies generated plane orientation information to downstream tasks. The system includes preprocessing with 3D morphological opening, sparse sampling, and intensity/coverage thresholding. The model is deployed as a web application that accepts MRI slices and returns plane orientation metadata.

## Key Results
- 2.5D random-sampling model achieves 99.49% accuracy on mixed BRISC+IXI test data
- Reduces classification errors by 60% compared to 2D reference model (98.74% accuracy)
- Gated metadata strategy improves tumor detection accuracy from 97.0% to 98.0%
- Reduces misdiagnoses by 33.3% in downstream classification task
- Deployed as open-source web application at https://mri-metadata.herokuapp.com/

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-slice random sampling ([i, j, k]) improves plane classification accuracy by providing anatomical context that resolves single-slice ambiguity.
- Mechanism: Three randomly selected slices from the same volume and plane are stacked as 3-channel input (Ch1, Ch2, Ch3). This forces the model to learn identity-level features common across slices rather than overfitting to slice-specific visual patterns. The random sampling acts as a regularizer.
- Core assumption: Slices from the same plane share consistent orientation features regardless of position in the volume.
- Evidence anchors: [abstract] "employs a random sampling strategy of three slices ([i, j, k]) from the same volume and plane, which learns robust, identity-level features and acts as an effective regularizer"

### Mechanism 2
- Claim: Mixed-domain training (healthy + pathological scans) reduces domain shift and improves generalization across heterogeneous MRI datasets.
- Mechanism: Combining BRISC (tumor patients) and IXI (healthy adults) creates a unified training distribution. The model learns plane features that are invariant to pathology presence, preventing overfitting to a single domain.
- Core assumption: Plane orientation features are fundamentally similar across healthy and pathological brains.
- Evidence anchors: [abstract] "Trained on a mixed dataset of brain MRI scans"

### Mechanism 3
- Claim: Gated metadata fusion based on predictive uncertainty selectively leverages generated metadata while avoiding harm from incorrect predictions.
- Mechanism: Two models run in parallel—Image-Only and Metadata-Enhanced. Predictive entropy (uncertainty score) determines which prediction to use. If uncertainty exceeds threshold (0.2020), the system defaults to Image-Only, avoiding incorrect metadata contamination.
- Core assumption: Uncertainty correlates with prediction reliability; high-uncertainty predictions are more likely wrong.
- Evidence anchors: [abstract] "a gated strategy selectively applied metadata based on classifier uncertainty, improving accuracy from 97.0% to 98.0% and reducing misdiagnoses by 33.3%"

## Foundational Learning

- Concept: **2.5D CNN Architecture**
  - Why needed here: The paper uses "2.5D" to mean 3-channel input where each channel is a separate slice (not RGB color). This differs from true 3D CNNs that process volumetric data with 3D convolutions.
  - Quick check question: If you stack three 2D slices as [Ch1, Ch2, Ch3], does a standard 2D CNN treat this as a single RGB-like image with 3 channels, or as a 3D volume?

- Concept: **Predictive Entropy for Uncertainty**
  - Why needed here: The gated strategy relies on Shannon entropy (H = -Σ p·log(p)) to quantify prediction confidence. Higher entropy = more uncertainty = use Image-Only model.
  - Quick check question: For a 3-class classifier (axial, coronal, sagittal), what entropy value indicates maximum uncertainty?

- Concept: **Domain Shift in Medical Imaging**
  - Why needed here: Models trained on one scanner type or patient population often fail on others. The paper explicitly addresses this by mixing datasets.
  - Quick check question: Why would a model trained only on healthy brains (IXI) fail on tumor scans (BRISC), and vice versa?

## Architecture Onboarding

- Component map:
```
Input → Preprocessing Pipeline → 2.5D Sampler → AlexNet (ImageNet pretrained) → Plane Classifier (3 classes)
         │                        │
         ├─ 3D morphological      ├─ 2D: [i, i, i] (reference)
         │   opening              ├─ Sequential: [i-1, i, i+1]
         ├─ Sparse sampling       └─ Random: [i, j, k] ← SELECTED
         ├─ Intensity/coverage
         │   thresholding
         └─ Square padding
```

- Critical path:
  1. Data cleaning (morphological opening, sparse sampling, filtering)
  2. Slice selection strategy (random sampling from same volume/plane)
  3. Pretrained AlexNet with ImageNet normalization
  4. Mixed BRISC+IXI training with balanced class sampling

- Design tradeoffs:
  - AlexNet (larger kernels, global features) vs ResNet-18 (deeper, fine details): Paper chose AlexNet (97.73% vs 95.28% on BRISC test)
  - Sequential vs Random 2.5D: Random slightly better on IXI (99.99% vs 99.98%), chosen for regularization benefit
  - Gated vs Always-on metadata: Gated achieves 98.0% vs 97.7% for always-on

- Failure signatures:
  - Near-skull slices lacking brain context → both 2D and 2.5D may fail
  - Large asymmetric tumors → can cause sagittal/coronal confusion
  - Incorrect metadata propagation → always-on strategy harms downstream tasks
  - Domain mismatch → IXI-only model achieves only 57.54% on BRISC

- First 3 experiments:
  1. Replicate the 2D baseline: Train AlexNet on single-slice [i, i, i] input with BRISC+IXI mixed data. Target: ~98.74% accuracy. This establishes the reference point.
  2. Ablate context strategy: Compare random [i, j, k] vs sequential [i-1, i, i+1] sampling on a held-out domain (e.g., train IXI-only, test BRISC). Target: sequential should outperform random when training data has ordered slices (73.0% vs 63.5% per Table 2).
  3. Validate gated threshold: On tumor detection task, sweep uncertainty thresholds (0.0 to 1.0) on validation set to find optimal gating point. Verify the 0.2020 threshold reproduces the 98.0% test accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the 2.5D context-aware framework be effectively adapted to classify other types of MRI metadata, such as distinguishing between T1 and T2-weighted scans?
- Basis in paper: [explicit] The conclusion states, "Future work will expand this contextual framework to other metadata, such as T1 vs T2-weighted scans."
- Why unresolved: The current study restricted its scope to anatomical plane orientation (axial, coronal, sagittal) using strictly T1-weighted images.
- What evidence would resolve it: Training the model on multi-contrast datasets and reporting accuracy on weighting classification tasks.

### Open Question 2
- Question: Why does the sequential context strategy significantly outperform random sampling in the cross-domain ablation study, despite random sampling being superior or equivalent in the main pre-trained experiments?
- Basis in paper: [inferred] In Table 2 (training from scratch), sequential sampling achieves 73.0% vs. random's 63.5%, whereas in Table 1 (pre-trained), random sampling slightly outperforms sequential on the IXI test set.
- Why unresolved: The paper notes the discrepancy but does not isolate whether pre-training or the mixed-domain training set neutralizes the advantages of local anatomical flow found in the ablation.
- What evidence would resolve it: A comparative analysis of context strategies specifically isolating the variables of pre-training weights and domain heterogeneity.

### Open Question 3
- Question: Is the optimal uncertainty threshold (0.2020) for the gated metadata strategy robust across different datasets, or is it sensitive to the specific validation set used?
- Basis in paper: [inferred] The threshold was determined by maximizing accuracy on the validation set (Fig. 3), but the paper does not validate this specific gating parameter on external institutional data.
- Why unresolved: A fixed threshold derived from one dataset distribution may not generalize, potentially leading to suboptimal gating decisions (e.g., accepting bad metadata) in deployment.
- What evidence would resolve it: Evaluating the gated model on an external test set using the 0.2020 threshold without re-tuning to observe if performance gains persist.

## Limitations
- Inference strategy for 2.5D random model is underspecified (how to aggregate multiple random predictions per slice)
- Gated metadata threshold (0.2020) lacks detailed derivation or sensitivity analysis
- One error in coronal classification attributed to tumor-induced asymmetry suggests edge case vulnerability
- Model performance on MRI modalities beyond T1-weighted (T2, FLAIR) not evaluated

## Confidence
- **High confidence**: 2.5D random sampling architecture and mixed-domain training benefits (supported by ablation studies in Tables 1-2)
- **Medium confidence**: Gated metadata strategy effectiveness (threshold appears tuned to specific validation set)
- **Low confidence**: Generalization to unseen pathologies and MRI protocols (no external validation beyond BRISC/IXI)

## Next Checks
1. **Threshold robustness**: Perform threshold sensitivity analysis on tumor detection task by sweeping uncertainty values (0.0 to 1.0) and plotting accuracy vs. threshold
2. **Cross-domain generalization**: Train on BRISC+IXI and test on an external MRI dataset (e.g., ADNI) to measure real-world domain shift effects
3. **Model architecture ablation**: Compare AlexNet vs ResNet-50 performance on same task to verify AlexNet choice wasn't coincidental to specific dataset characteristics