---
ver: rpa2
title: 'CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain'
arxiv_id: '2509.19925'
source_url: https://arxiv.org/abs/2509.19925
tags:
- con-qa
- entities
- privacy
- framework
- sensitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CON-QA is a hybrid privacy-preserving QA framework for enterprise
  contract analysis that combines local and cloud LLMs to protect sensitive contractual
  information during question answering. It uses a session-based one-to-many anonymization
  scheme for PII and a deterministic many-to-one reverse mapping for answer recovery,
  ensuring strong privacy without sacrificing semantic fidelity.
---

# CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain

## Quick Facts
- arXiv ID: 2509.19925
- Source URL: https://arxiv.org/abs/2509.19925
- Reference count: 4
- Primary result: 98.80% entity restoration accuracy with strong privacy guarantees

## Executive Summary
CON-QA is a hybrid privacy-preserving QA framework for enterprise contract analysis that combines local and cloud LLMs to protect sensitive contractual information during question answering. It uses a session-based one-to-many anonymization scheme for PII and a deterministic many-to-one reverse mapping for answer recovery, ensuring strong privacy without sacrificing semantic fidelity. Evaluated on CUAD-QA, a newly curated dataset of 85k QA pairs, CON-QA achieves 98.80% private entity restoration accuracy, 97.78% response relevancy, and 91.66% expert-assessed answer correctness, demonstrating robust privacy protection and high answer quality in real-world legal document scenarios.

## Method Summary
CON-QA employs a hybrid architecture where sensitive contract data is processed locally before being sent to cloud LLMs for question answering. The system first uses a local LLM (Qwen-2.5-14B) for query decomposition and metadata extraction, then retrieves relevant document chunks from a local vector database. A local privacy layer with GLiNER performs NER to detect sensitive entities, which are then anonymized using a session-based one-to-many surrogate mapping scheme. The anonymized query and chunks are sent to GPT-4o-mini for answering, and the cloud response is restored using deterministic many-to-one reverse mapping to recover original entities.

## Key Results
- 98.80% private entity restoration accuracy on CUAD-QA dataset
- 97.78% response relevancy score for cloud-generated answers
- 91.66% expert-assessed answer correctness, though with noted degradation for summarization queries

## Why This Works (Mechanism)

### Mechanism 1: Session-Scoped One-to-Many Surrogate Mapping
This mechanism mitigates cross-session inference attacks by generating multiple semantically similar candidates for each sensitive entity and randomly sampling one per session. The mapping is discarded after each session, preventing the cloud provider from linking entities across sessions. Core assumption: the adversarial cloud model cannot link diverse surrogates to a single original entity without the mapping key.

### Mechanism 2: Semantic Filtering via Local RAG
A local LLM performs query decomposition and retrieves only relevant document chunks from a local vector database, reducing the data surface area sent to the cloud. This lowers privacy risk while maintaining answer relevancy. Core assumption: the local retrieval model has sufficient accuracy to identify all relevant clauses.

### Mechanism 3: Deterministic Many-to-One Restoration
The system creates a temporary reverse map during anonymization, allowing exact string matching when restoring entities from cloud responses. This deterministic approach achieves higher restoration accuracy than learned generative decoding. Core assumption: the cloud LLM reproduces surrogate entities exactly in its output without modification.

## Foundational Learning

- **Named Entity Recognition (NER) & GLiNER**: The entire privacy pipeline depends on detecting 100% of sensitive entities. Quick check: Can you distinguish between a "Person" entity and a "Title" entity in a legal signature block?

- **Semantic Fidelity in Text Generation**: Replacements must fit the context so the cloud LLM understands legal relationships correctly. Quick check: If you replace "The plaintiff" with "The banana," how does the LLM's legal reasoning change?

- **Hybrid Cloud/Local Architecture**: Understand latency and privacy trade-offs. Local processing adds network hops but secures raw data. Quick check: Which component fails if the local GPU runs out of memory during "One-to-Many" generation?

## Architecture Onboarding

- **Component map**: Input (Query + Contract) -> Local Inference (Qwen-2.5-14B) -> Local Retrieval (Vector DB) -> Local Privacy Layer (GLiNER + Qwen) -> Cloud Interface (GPT-4o-mini) -> Restoration Layer -> Output (Final Answer)

- **Critical path**: The Surrogate Generation Loop - extracting entities, prompting local LLM for K replacements, and performing string substitution before user response

- **Design tradeoffs**: Surrogate Cardinality (K) vs. local inference time; Local Model Size vs. GPU VRAM requirements

- **Failure signatures**: "The Stubborn Entity" (legal term treated as proper noun), "The Hallucinated Surrogate" (cloud LLM introduces new name), "Context Drift" (anonymized chunks lose semantic connection)

- **First 3 experiments**: 1) NER Recall Audit - run GLiNER against 50 manually labeled contract pages, target >99% recall; 2) Surrogate Stress Test - verify distinct candidates with measurable edit distance; 3) Cloud Fidelity Test - verify exact surrogate string reproduction in cloud output

## Open Questions the Paper Calls Out

- **Contextual Enrichment vs. Ground Truth**: How to fairly assess "contextually enriched" summarization responses that diverge from concise reference answers? Current metrics penalize detailed summaries despite potential legal utility.

- **NER Coverage Validation**: What failure modes exist in GLiNER for context-specific legal entities, and how can the pipeline detect the 0.89% of missed sensitive entities? Current framework lacks fallback mechanisms for undetected entities.

- **Semantic Similarity Impact**: Does the semantic similarity of generated surrogates impact the cloud LLM's ability to perform multi-hop reasoning compared to abstract placeholders? Unclear if semantic properties aid or hinder reasoning logic.

## Limitations

- Privacy claims rely on session-based mapping but don't address insider threats or timing attacks
- 98.80% restoration accuracy assumes perfect surrogate generation without quantifying LLM hallucination impact
- Deterministic restoration requires exact string matching, which may fail if cloud LLM performs text normalization

## Confidence

- **High Confidence (9/10)**: Experimental results on CUAD-QA dataset are well-documented and reproducible
- **Medium Confidence (6/10)**: Privacy guarantees depend on semantic diversity of surrogates, which wasn't quantitatively validated
- **Low Confidence (4/10)**: System behavior under adversarial conditions wasn't tested; GLiNER accuracy assumed without independent validation

## Next Checks

1. **Semantic Diversity Audit**: Measure pairwise edit distance and semantic similarity of K surrogates to verify meaningful privacy through diversity

2. **Adversarial Cloud Simulation**: Test whether a simulated adversarial cloud LLM can link anonymized entities across sessions through linguistic patterns or contextual cues

3. **NER Coverage Validation**: Conduct independent recall analysis of GLiNER on CUAD-QA dataset, particularly for legal-specific entity types