---
ver: rpa2
title: Untangling the Influence of Typology, Data and Model Architecture on Ranking
  Transfer Languages for Cross-Lingual POS Tagging
arxiv_id: '2503.19979'
source_url: https://arxiv.org/abs/2503.19979
tags:
- features
- language
- transfer
- languages
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper examines how linguistic typology, dataset features, and
  model architecture affect transfer language selection for cross-lingual POS tagging.
  The authors train gradient-boosted decision tree rankers using features from URIEL
  and Grambank typological databases, plus dataset-dependent metrics like word overlap
  and type-token ratio.
---

# Untangling the Influence of Typology, Data and Model Architecture on Ranking Transfer Languages for Cross-Lingual POS Tagging

## Quick Facts
- arXiv ID: 2503.19979
- Source URL: https://arxiv.org/abs/2503.19979
- Reference count: 13
- Primary result: Combined typological and dataset-dependent features yield best transfer language rankings for POS tagging

## Executive Summary
This paper investigates how linguistic typology, dataset characteristics, and model architecture influence transfer language selection for cross-lingual POS tagging. The authors develop gradient-boosted decision tree rankers using features from URIEL and Grambank typological databases, along with dataset-dependent metrics like word overlap and type-token ratio. They compare biLSTM and MLM (XLM-R/M-BERT) zero-shot transfer scenarios across multiple datasets. The study demonstrates that combining fine-grained typological and dataset-dependent features achieves optimal performance, with genetic distance, word overlap, and type-token ratio being the most important predictors across architectures. Notably, M-BERT shows the most stable performance across different feature configurations.

## Method Summary
The authors employ gradient-boosted decision tree rankers to predict optimal transfer languages for cross-lingual POS tagging. They extract features from two typological databases (URIEL and Grambank) and compute dataset-dependent metrics including word overlap and type-token ratio. The study evaluates both biLSTM and MLM architectures (XLM-R and M-BERT) in zero-shot transfer scenarios across multiple datasets. Model performance is assessed using NCDG@5 metrics, and feature importance is analyzed to identify the most predictive features for transfer language selection.

## Key Results
- Combined fine-grained typological and dataset-dependent features yield best performance (NCDG@5 up to 0.827 for XLM-R)
- Genetic distance, word overlap, and type-token ratio are consistently most important across architectures
- M-BERT exhibits the most stable performance across feature configurations
- Strong performance achievable using either feature group alone

## Why This Works (Mechanism)
The effectiveness of the proposed approach stems from capturing both structural linguistic relationships (through typological features) and practical dataset characteristics (through overlap and diversity metrics). Genetic distance reflects deep linguistic relatedness that often correlates with transfer difficulty, while word overlap and type-token ratio capture surface-level similarity and dataset complexity that directly impact model learning. The combination provides complementary signals that improve transfer language ranking accuracy beyond what either feature type achieves alone.

## Foundational Learning
- Typological feature extraction from linguistic databases: Why needed - to capture structural linguistic relationships between languages; Quick check - verify feature completeness and granularity alignment across sources
- Zero-shot cross-lingual transfer: Why needed - to evaluate model performance without target language fine-tuning; Quick check - confirm no target language data used during training
- Gradient-boosted decision tree rankers: Why needed - to learn complex feature interactions for transfer language selection; Quick check - validate ranker calibration and feature importance stability
- NCDG@5 evaluation metric: Why needed - to measure ranking quality for top transfer language candidates; Quick check - ensure proper normalization and relevance scoring
- MLM architecture comparison: Why needed - to assess impact of pre-trained language models on transfer; Quick check - verify consistent tokenization and vocabulary handling

## Architecture Onboarding

Component Map:
URIEL/Grambank databases -> Feature extraction -> Dataset metrics computation -> Feature combination -> GBDT ranker -> Transfer language ranking

Critical Path:
Feature extraction and combination -> GBDT training -> Transfer language prediction -> Model evaluation

Design Tradeoffs:
- Fine-grained vs coarse-grained typological features: Higher granularity provides more discriminative power but increases complexity
- Combined vs individual feature sets: Combined features improve performance but require more sophisticated modeling
- Zero-shot vs few-shot transfer: Zero-shot is more challenging but more practical for low-resource scenarios

Failure Signatures:
- Poor NCDG@5 scores indicating ineffective transfer language selection
- Unstable feature importance rankings suggesting model sensitivity
- Large performance gaps between M-BERT and XLM-R indicating architectural mismatches

First Experiments:
1. Baseline ranking using only genetic distance features
2. Ablation study removing word overlap features
3. Comparison of different layer combinations within M-BERT

## Open Questions the Paper Calls Out
None

## Limitations
- Typological feature selection lacks theoretical grounding, relying on empirical performance
- Architectural capacity differences (12 vs 24 layers) may confound stability comparisons
- Zero-shot transfer focus limits generalizability to practical few-shot scenarios
- Task-specific evaluation (POS tagging) may not generalize to other downstream tasks

## Confidence
- High: Importance of genetic distance, word overlap, and type-token ratio features
- Medium: Superiority of combined feature sets
- Medium: M-BERT stability claims
- Low: Generalizability beyond POS tagging

## Next Checks
1. Evaluate typological feature selection based on linguistic theory rather than empirical performance
2. Test transfer language rankers on diverse downstream tasks (dependency parsing, NER)
3. Conduct ablation studies comparing different layer combinations within M-BERT and XLM-R