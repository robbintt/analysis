---
ver: rpa2
title: 'The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global
  Statistics'
arxiv_id: '2602.01186'
source_url: https://arxiv.org/abs/2602.01186
tags:
- heads
- gh-ofl
- client
- accuracy
- fisher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Classical federated learning relies on multi-round communication
  between clients and server, leading to high latency and privacy risks. The authors
  propose the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated learning
  methods that avoid multi-round communication.
---

# The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics

## Quick Facts
- arXiv ID: 2602.01186
- Source URL: https://arxiv.org/abs/2602.01186
- Reference count: 40
- One-shot federated learning methods using per-class sufficient statistics, achieving state-of-the-art robustness and accuracy with orders-of-magnitude less communication than multi-round FL

## Executive Summary
Classical federated learning relies on multi-round communication between clients and server, leading to high latency and privacy risks. The authors propose the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated learning methods that avoid multi-round communication. Clients transmit only per-class sufficient statistics (counts and first/second-order moments), optionally compressed via a public random projection, without uploading raw data or model parameters. The server constructs closed-form Gaussian heads (NB-diag, LDA, QDA) directly from these statistics, and trains lightweight heads (FisherMix, Proto-Hyper) on synthetic samples drawn in a Fisher subspace, all strictly data-free. Extensive experiments on CIFAR-10, CIFAR-100, CIFAR-100-C, and SVHN show that GH-OFL methods achieve state-of-the-art robustness and accuracy under strong non-IID conditions, surpassing traditional multi-round FL methods (FedAvg, FedProx) and one-shot baselines, while using orders of magnitude less communication and remaining fully data-free.

## Method Summary
The GH-OFL family enables one-shot federated learning by having clients upload only per-class sufficient statistics—counts, first-order moments, and second-order moments—rather than raw data or model parameters. These statistics are optionally compressed using a public random projection to further reduce communication. The server reconstructs closed-form Gaussian heads (Naive Bayes, LDA, QDA) from the statistics and trains lightweight heads (FisherMix, Proto-Hyper) on synthetic samples generated in a Fisher subspace. This approach is strictly data-free, avoiding privacy leakage from raw data and model parameter exchanges. The method is designed to work under strong non-IID data distributions, achieving high accuracy and robustness without the latency and privacy risks of multi-round FL.

## Key Results
- GH-OFL methods achieve state-of-the-art accuracy and robustness on CIFAR-10, CIFAR-100, and SVHN under strong non-IID conditions
- Orders-of-magnitude reduction in communication compared to multi-round FL baselines (FedAvg, FedProx)
- Superior performance to one-shot baselines while remaining fully data-free and avoiding raw data uploads

## Why This Works (Mechanism)
The GH-OFL family leverages the fact that per-class sufficient statistics (counts and moments) capture all information needed to reconstruct class-conditional distributions. By fitting closed-form Gaussian heads (NB-diag, LDA, QDA) directly from these statistics, the server bypasses the need for iterative model updates and raw data access. Synthetic samples drawn in the Fisher subspace enable training of lightweight heads without exposing real client data. The optional random projection further compresses transmitted statistics, reducing communication overhead. This design allows for one-shot global model construction with minimal privacy risk and high robustness, even under severe data heterogeneity.

## Foundational Learning
- **Sufficient statistics**: Why needed—summarize client data for global model construction without raw data; Quick check—verify that per-class counts and moments fully capture class-conditional distributions.
- **Fisher discriminant analysis**: Why needed—project data into a discriminative subspace for synthetic sample generation; Quick check—confirm eigenvalues/eigenvectors are correctly computed and used.
- **Gaussian discriminant analysis**: Why needed—assume class-conditional Gaussians to fit closed-form heads; Quick check—validate assumptions hold approximately on real data.
- **Random projection**: Why needed—compress statistics to reduce communication; Quick check—measure impact on downstream accuracy vs. compression ratio.
- **One-shot federated learning**: Why needed—avoid iterative communication rounds for efficiency and privacy; Quick check—compare accuracy and communication cost against multi-round FL.
- **Non-IID robustness**: Why needed—ensure performance under heterogeneous client data; Quick check—evaluate on strongly non-IID splits and corrupted datasets.

## Architecture Onboarding

**Component Map**: Clients (sufficient stats) -> Server (Gaussian heads + Fisher subspace) -> Synthetic samples -> Lightweight heads

**Critical Path**: 1. Clients compute and upload per-class sufficient statistics; 2. Server reconstructs Gaussian heads and Fisher subspace; 3. Server generates synthetic samples; 4. Server trains lightweight heads on synthetic data

**Design Tradeoffs**: Transmitting sufficient statistics instead of raw data greatly reduces communication and privacy risk, but relies on strong distributional assumptions; random projection offers further compression but may degrade accuracy; closed-form heads are efficient but may not capture complex class boundaries

**Failure Signatures**: Degraded accuracy if sufficient statistics are inaccurate or if class-conditional Gaussian assumptions are violated; privacy leakage if statistics are not properly anonymized or if reconstruction attacks succeed; scalability issues if high-dimensional eigenvalue problems become computationally prohibitive

**First Experiments**: 1. Verify sufficient statistics accurately reconstruct class-conditional distributions on a small dataset; 2. Test privacy leakage via membership inference on transmitted statistics; 3. Benchmark communication cost and accuracy under varying non-IID splits

## Open Questions the Paper Calls Out
None

## Limitations
- Privacy guarantees of sufficient statistics under differential privacy or membership inference attacks are not quantified
- Closed-form Gaussian head construction relies on strong distributional assumptions that may not hold in highly heterogeneous or adversarial data regimes
- Scalability of eigenvalue decomposition for high-dimensional feature spaces is not analyzed

## Confidence
- High confidence in communication efficiency claims: orders-of-magnitude reduction demonstrated and per-client transmission explicitly bounded
- High confidence in accuracy/robustness results: consistent outperformance on standard benchmarks with strong non-IID conditions
- Medium confidence in distributional assumptions: theoretical soundness, but practical validity depends on real-world feature statistics matching assumed class-conditional Gaussians

## Next Checks
1. Perform membership inference or reconstruction attacks on transmitted sufficient statistics to quantify privacy leakage under realistic threat models
2. Test GH-OFL methods on heterogeneous data domains (e.g., medical imaging, text) where class-conditional Gaussian assumptions may be violated and assess sensitivity to distributional mismatch
3. Benchmark scalability by measuring wall-clock time and memory usage for eigenvalue decomposition as feature dimensionality and number of classes increase, and compare against approximate solvers or dimensionality reduction baselines