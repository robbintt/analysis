---
ver: rpa2
title: 'ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes'
arxiv_id: '2504.20411'
source_url: https://arxiv.org/abs/2504.20411
tags:
- event
- diffusion
- noise
- events
- asynchronous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modeling temporal point processes
  using diffusion models with asynchronous noise schedules. The key idea is to apply
  different noise scales to different events in a sequence, enabling faster generation
  of earlier events to provide stronger conditioning for forecasting later ones.
---

# ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes

## Quick Facts
- arXiv ID: 2504.20411
- Source URL: https://arxiv.org/abs/2504.20411
- Authors: Amartya Mukherjee, Ruizhi Deng, He Zhao, Yuzhen Mao, Leonid Sigal, Frederick Tung
- Reference count: 40
- One-line primary result: State-of-the-art TPP forecasting with 17% RMSE improvement on Retweet dataset using asynchronous diffusion models

## Executive Summary
This paper introduces ADiff4TPP, a diffusion model framework for temporal point processes that uses asynchronous noise schedules to improve forecasting accuracy. The key innovation is applying different noise scales to different events in a sequence, with earlier events denoised faster than later ones to provide stronger conditioning. The method combines a β-VAE to map mixed-type events (time and category) to a continuous latent space, then applies diffusion models with asynchronous noise schedules to model the joint distribution. Results show significant improvements over existing methods, particularly for long-horizon prediction tasks.

## Method Summary
ADiff4TPP operates in two stages: first training a β-VAE to map heterogeneous events (continuous time and discrete category) to a continuous latent space, then applying a diffusion model with asynchronous noise scheduling to model the joint distribution in this latent space. The asynchronous noise schedule allows earlier events to be generated faster than later ones, providing stronger conditioning for forecasting. The framework uses a modified Diffusion Transformer with masked self-attention and solves a conditional ODE during inference. The method handles variable-length observation and prediction windows by adjusting the ODE solution path and using masking to maintain temporal causality.

## Key Results
- Achieves 17% improvement in RMSE on Retweet dataset for next event prediction
- Shows 24.5% average improvement over existing methods in long-horizon prediction tasks
- Demonstrates superior performance in Optimal Transport Distance metrics across multiple benchmark datasets
- Ablation studies confirm importance of masked attention and asynchronous noise scheduling

## Why This Works (Mechanism)

### Mechanism 1: Asynchronous Noise Scheduling for Sequential Conditional Generation
The method applies different noise scales to different events in a sequence, with earlier events denoised faster than later ones. This is implemented through a matrix-valued noise schedule A(s) where diagonal elements define event-specific diffusion speeds. Earlier events have their diffusion paths start and end later in flow time s, making them "less diffused" at any intermediate point. During reverse generation, this results in earlier events being fully denoised first, providing stable context for generating later, still-noisy events. This works because sequential events in TPPs exhibit causal dependencies where reducing uncertainty in earlier events reduces uncertainty in later ones.

### Mechanism 2: Latent Space Diffusion for Mixed-Type Event Data
The method first trains a β-VAE to map heterogeneous events (continuous time and discrete category) to a continuous latent space. The VAE's reconstruction loss combines MSE for continuous time and cross-entropy for discrete category. The diffusion process then operates entirely on these latent vectors, avoiding the difficulty of designing a diffusion process over heterogeneous data. This works because the β-VAE can learn a faithful and sufficiently regularized continuous representation that preserves information from both continuous and discrete components.

### Mechanism 3: Flexible Forecasting via Conditional ODE and Masking
The framework handles variable-length observation and prediction windows by solving a single conditional ODE over a partial time interval. The vector field for observed events is set to analytically reconstruct known latents, while for prediction events it's learned via neural network. Masked self-attention ensures prediction for event i can only attend to preceding events, respecting temporal causality. This works because the learned vector field generalizes well to the conditional generation task defined by the modified ODE solution path.

## Foundational Learning

**Flow Matching & Rectified Flow**: The paper's diffusion model is built on the flow matching framework rather than traditional DDPM. Understanding ODE-based generative modeling is essential. Quick check: How does training a flow model (regressing a vector field) differ from training a traditional diffusion model (predicting noise)?

**Variational Autoencoders (VAEs) and β-VAE**: This is the core of the "latent diffusion" part, mapping mixed data to a continuous space. Understanding the trade-off between reconstruction accuracy and KL regularization is critical. Quick check: What is the role of the β hyperparameter in a β-VAE?

**Temporal Point Processes (TPPs)**: This is the core problem domain. Understanding how events are represented (time, type) and the forecasting tasks is essential. Quick check: How does this paper's approach differ from traditional intensity-based TPP models?

## Architecture Onboarding

**Component map**: β-VAE Encoder -> Asynchronous DiT -> ODE Solver -> β-VAE Decoder

**Critical path**: 1) Train/freeze β-VAE (ensure good reconstruction) 2) Encode training data to latent sequences 3) Train Asynchronous DiT using CFM objective with noise schedule A(s) 4) At inference: run conditional ODE solver from s_end to s_start 5) Decode generated latents with β-VAE Decoder

**Design tradeoffs**: Latent dimension (d_latent): Paper tested 16 and 32; affects information capacity vs. diffusion model complexity. Noise schedule: Asynchronous vs. disjoint (autoregressive) vs. synchronous (standard). Masking: Causal attention shown critical in ablation.

**Failure signatures**: Poor VAE reconstruction: Check VAE MSE/accuracy before training diffusion. Mode collapse in diffusion: Generating only frequent event types. ODE solver divergence: NaNs or drift off data manifold. No benefit from asynchrony: If synchronous schedule performs comparably.

**First 3 experiments**: 1) VAE Sanity Check: Train β-VAE with d_latent ∈ {8,16,32} and β_max ∈ {0.1,0.01,0.001}. Plot reconstruction loss vs. KL divergence. 2) Schedule Comparison: Train DiT models on same dataset with (a) asynchronous A(s) and (b) synchronous A(s)=(1-s)I. Compare next-event RMSE/Error Rate. 3) Masking Ablation: Train unmasked version with full self-attention. Compare against masked version to quantify impact of causal design.

## Open Questions the Paper Calls Out

**Open Question 1**: How does the inference latency of ADiff4TPP compare quantitatively to autoregressive baselines? The authors claim the method "significantly reduces evaluation time" but experiments only report RMSE and OTD without wall-clock time benchmarks.

**Open Question 2**: Can the asynchronous noise schedule A(s) be optimized dynamically rather than pre-defined? Section 3.2 defines a specific piecewise linear schedule and Section 4 states A(s) is "decided prior to training," leaving the potential of a learnable schedule unexplored.

**Open Question 3**: Does the frozen VAE training regime limit performance compared to end-to-end optimization? Section 3.1 states "The encoder and decoder weights are frozen after training," isolating the diffusion model from the representation learner.

## Limitations

- The quality of the β-VAE's latent space representation is not rigorously evaluated beyond reconstruction metrics
- Theoretical justification for why asynchronous noise scheduling improves conditional generation remains heuristic
- Computational efficiency compared to existing TPP methods is not addressed, which could limit real-time applications
- Claims about flexible forecasting lack rigorous ablation studies across diverse forecasting scenarios

## Confidence

**High Confidence**: The core framework combining β-VAE with diffusion models for TPPs is technically sound and the latent diffusion approach is well-established in related work.

**Medium Confidence**: The asynchronous noise scheduling mechanism shows strong empirical results (17% RMSE improvement on Retweet, 24.5% average improvement in long-horizon tasks) but the underlying theoretical guarantees are not proven.

**Low Confidence**: The paper's claims about flexible forecasting handling variable-length windows are plausible but lack rigorous ablation studies across diverse forecasting scenarios.

## Next Checks

1. **VAE Representation Quality**: Evaluate the β-VAE's latent space using downstream metrics beyond reconstruction loss, such as latent interpolation smoothness and information preservation tests.

2. **Noise Schedule Ablation**: Conduct controlled experiments comparing asynchronous, synchronous, and disjoint noise schedules on the same datasets with identical DiT architectures to isolate the effect of scheduling.

3. **Computational Efficiency Analysis**: Measure inference time and memory usage of the ODE-based generation compared to traditional TPP intensity models and autoregressive baselines across different sequence lengths.