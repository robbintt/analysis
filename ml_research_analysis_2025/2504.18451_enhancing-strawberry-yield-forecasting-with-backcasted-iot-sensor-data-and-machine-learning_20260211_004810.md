---
ver: rpa2
title: Enhancing Strawberry Yield Forecasting with Backcasted IoT Sensor Data and
  Machine Learning
arxiv_id: '2504.18451'
source_url: https://arxiv.org/abs/2504.18451
tags:
- uni00000013
- uni00000011
- uni00000010
- uni00000014
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addressed the challenge of limited historical sensor
  data for AI-based strawberry yield forecasting by deploying IoT sensors in polytunnels
  over two growing seasons. To bridge the gap of missing data for two additional seasons,
  the authors proposed a backcasting approach that generated synthetic sensor observations
  using historical weather data from a nearby weather station combined with existing
  polytunnel data.
---

# Enhancing Strawberry Yield Forecasting with Backcasted IoT Sensor Data and Machine Learning

## Quick Facts
- **arXiv ID:** 2504.18451
- **Source URL:** https://arxiv.org/abs/2504.18451
- **Reference count:** 40
- **Primary result:** Backcasting approach improved strawberry yield forecasting accuracy by 13.93-41.9% using synthetic sensor data for missing seasons

## Executive Summary
This study addresses the challenge of limited historical sensor data for AI-based strawberry yield forecasting by deploying IoT sensors in polytunnels over two growing seasons. To bridge the gap of missing data for two additional seasons, the authors propose a backcasting approach that generates synthetic sensor observations using historical weather data from a nearby weather station combined with existing polytunnel data. They evaluate this approach by developing yield forecasting models using both real and synthetic data. The results demonstrate that incorporating synthetic data improves yield forecasting accuracy, with models using the combined dataset outperforming those trained only on historical yield, weather records, and real sensor data.

## Method Summary
The study employs a two-stage process: first, backcasting generates synthetic historical IoT sensor data for 2021-2022 using weather data; second, yield forecasting predicts weekly strawberry yield. The backcasting stage uses ensemble models (RF, GBDT, XGBoost) trained on 2023-2024 data to predict past sensor values from future weather data, which is then applied to 2021-2022 weather data to create synthetic sensor observations. The forecasting stage aggregates data to weekly intervals and uses a sliding window of 3 weeks of environmental features to predict yield for week 3, comparing models trained on real-only versus real-plus-synthetic data.

## Key Results
- Backcasting method achieved RMSE values between 2.459-11.866 for different sensor features
- Enhanced dataset with synthetic data led to performance improvements of 13.93% to 41.9% in yield forecasting compared to real data only
- Models using combined dataset (real + synthetic) outperformed those trained only on historical yield, weather records, and real sensor data

## Why This Works (Mechanism)

### Mechanism 1: Proxy-based Synthetic Data Generation (Backcasting)
The system generates valid historical sensor data if external weather observations serve as effective proxies for internal polytunnel conditions. By inverting the standard forecasting timeline and training regressors to predict past sensor values using future meteorological data, the authors reconstruct missing historical internal states. This relies on the physical relationship between external weather and internal polytunnel microclimate being relatively stationary across years.

### Mechanism 2: Volume-Enabled Feature Utility
Synthetic data augmentation improves yield forecasting because it provides the sample volume necessary to learn complex interactions between environmental features and yield. Standard yield-only models suffer from high variance, and adding rich sensor features to a small dataset creates the "curse of dimensionality." By boosting the dataset from ~166 to ~246 samples using synthetic data, the models gain sufficient statistical power to leverage informative features rather than overfitting to noise.

### Mechanism 3: Microclimate Specificity
Models utilizing synthetic sensor data outperform those using regional weather data because the sensor features capture the specific controlled environment of the polytunnel. Regional weather is a coarse approximation of the growing environment, while backcasted sensor data reflects the specific conditions of the tunnels including heating and shelter. The yield model uses these precise inputs to learn the true biological response.

## Foundational Learning

- **Concept: Backcasting (vs Forecasting)** - Why needed here: This is the core novelty. You must distinguish between predicting the future (forecasting yield) and reconstructing the past (backcasting sensors). Quick check question: If you have weather data for 2021 but need sensor data for 2021, do you train the model on 2023 data to predict 2021 inputs?
- **Concept: Feature Correlation Analysis (Pearson)** - Why needed here: The entire backcasting strategy rests on the assumption that External Weather drives Internal Sensors. You need to verify this correlation before building the pipeline. Quick check question: If the correlation between External Temperature and Internal Temperature is 0.2 (weak), can you reliably backcast Internal Temperature?
- **Concept: Ensemble Learning (Random Forest / GBDT)** - Why needed here: These are the specific engines used for both backcasting and forecasting. Understanding their ability to handle tabular data and non-linear relationships is key. Quick check question: Why might GBDT perform better than RF on the "Backcasting" task for specific features?

## Architecture Onboarding

- **Component map:** Met Office Weather Data -> Polytunnel Sensor Data -> Backcasting Models (RF/GBDT/XGBoost) -> Synthetic Sensor Data -> Combined Dataset -> Yield Forecasting Models (RF/GBDT/XGBoost) -> Yield Predictions
- **Critical path:** Verify Correlation -> Train Backcasting Models -> Generate Synthetic Data -> Combine with Real Data -> Train Yield Forecaster -> Evaluate against "Real Only" baseline
- **Design tradeoffs:** The paper uses standard ensembles rather than Deep Learning to trade potential sequence modeling power for robustness on small tabular datasets. Authors removed low-impact features in final forecasting stage to reduce complexity, trading data richness for generalization.
- **Failure signatures:** High Backcast RMSE (>15%) indicates synthetic data is likely noise and will degrade the yield model. Negative transfer occurs if "Real+Syn" performs worse than "Real Only", suggesting distribution shift.
- **First 3 experiments:** 1) Calculate Pearson correlation between external weather station and internal sensors - if r < 0.5, do not proceed with backcasting. 2) Train on hold-out set of real sensor data (hide 2024, train on 2023, predict 2024 sensors using 2024 weather) to validate backcaster. 3) Train yield model on three sets: Yield Only, Real Sensors + Yield, Real + Synthetic + Yield, and compare RMSEs to confirm volume helps.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed backcasting framework be effectively transferred to different geographical growing locations and distinct crop varieties? The authors acknowledge using data from a single farm and state future work should explore transferability across multiple growing locations and other crop varieties. This remains unresolved as the study validates only on strawberries in Scotland.

### Open Question 2
Can advanced synthetic data generation techniques improve capture of extreme weather conditions compared to the current regression-based backcasting approach? The Conclusion notes further exploration should be made into techniques that can capture extreme weather conditions and their effects on yield. The current method may smooth out or fail to extrapolate to extreme values not well-represented in training data.

### Open Question 3
What is the optimal balance between feature richness (integrating Met Office and sensor data) and training data volume for maximizing yield forecasting accuracy? The Discussion suggests an optimal balance between feature richness and data volume that the current dataset approaches but does not fully achieve. It's unclear if performance degradation was due to specific Met Office features adding noise or insufficient dataset size to support higher dimensionality.

## Limitations
- The backcasting approach's effectiveness depends critically on the assumption of stable polytunnel management across seasons
- Synthetic data generation quality is directly tied to backcasting models' performance - errors propagate to yield forecasting stage
- The study is limited to strawberries in a specific facility, leaving generalizability to different crops unproven

## Confidence
- **High Confidence:** The empirical improvement from synthetic data augmentation (13.93-41.9% RMSE reduction) is well-supported by ablation studies
- **Medium Confidence:** The correlation analysis supporting backcasting mechanism is sound, though specific correlation coefficients for critical feature pairs are not explicitly reported
- **Low Confidence:** The generalizability of this approach to different crops or polytunnel management systems remains unproven

## Next Checks
1. **Correlation Validation:** Before implementing backcasting, explicitly calculate and report Pearson correlation coefficients between all external weather features and internal sensor readings to verify the fundamental assumption
2. **Temporal Stability Test:** Train backcasting models on 2023 data to predict 2024 sensor values using 2024 weather data. Compare RMSE against Table 2 to validate model performance on held-out real data
3. **Distribution Shift Analysis:** Perform statistical tests (e.g., KS test) comparing distributions of backcasted vs. real sensor data to quantify potential bias introduced by the synthetic generation process