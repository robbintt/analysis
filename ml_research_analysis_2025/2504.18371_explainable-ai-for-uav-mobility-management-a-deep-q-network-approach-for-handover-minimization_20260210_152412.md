---
ver: rpa2
title: 'Explainable AI for UAV Mobility Management: A Deep Q-Network Approach for
  Handover Minimization'
arxiv_id: '2504.18371'
source_url: https://arxiv.org/abs/2504.18371
tags:
- handover
- data
- buffer
- feature
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of frequent handovers in cellular-connected
  UAV systems due to their 3D mobility and fragmented BS coverage. It proposes an
  explainable AI framework combining Deep Q-Networks (DQN) for handover optimization
  with Shapley Additive Explanations (SHAP) for interpretability.
---

# Explainable AI for UAV Mobility Management: A Deep Q-Network Approach for Handover Minimization

## Quick Facts
- arXiv ID: 2504.18371
- Source URL: https://arxiv.org/abs/2504.18371
- Reference count: 20
- This paper proposes a DQN-based explainable AI framework that reduces UAV handover rates by over 80% while providing interpretable explanations via SHAP.

## Executive Summary
This paper addresses frequent handovers in cellular-connected UAVs caused by 3D mobility and fragmented BS coverage. The authors propose an explainable AI framework combining Deep Q-Networks (DQN) for handover optimization with Shapley Additive Explanations (SHAP) for interpretability. By integrating buffer status, RSRP, and RSRQ metrics, the DQN learns to make intelligent handover decisions that significantly reduce unnecessary transitions while maintaining service continuity. The framework is evaluated using real-world LTE data from UAV flights, demonstrating substantial performance improvements over conventional methods.

## Method Summary
The method employs a Deep Q-Network that learns handover policies by observing UAV states (position, buffer size, serving BS, signal metrics) and selecting actions (target BS association). Training uses experience replay and a target network for stability, with rewards balancing buffer reduction, handover penalties, and signal quality maintenance. SHAP analysis provides feature attribution explanations, revealing buffer status and position as dominant decision factors. The framework uses a template-based language module to generate natural language explanations while avoiding hallucinations.

## Key Results
- DQN-based approach reduces handovers by over 80% compared to conventional methods
- SHAP analysis reveals buffer queue size and UAV position as most influential factors in handover decisions
- Method maintains low ping-pong rates (~14%) while preventing buffer overflow incidents
- Integration of buffer status with signal metrics enables intelligent handover decisions

## Why This Works (Mechanism)

### Mechanism 1
Integrating buffer queue status with signal quality metrics enables adaptive handover decisions that reduce unnecessary handovers while maintaining service continuity. The DQN state space includes buffer queue size alongside traditional signal metrics, allowing the policy to postpone handovers when buffers are empty and prioritize transitions when buffers are full. Core assumption: UAVs with empty buffers can tolerate delayed handovers without service degradation. Evidence: Buffer queue size emerges as the most influential feature in SHAP analysis. Break condition: If packet arrival patterns deviate significantly from Poisson assumptions.

### Mechanism 2
Target network stabilization with experience replay enables converged Q-learning in non-stationary UAV mobility environments. Two neural networks (main and target) provide stable bootstrap targets, while experience replay breaks temporal correlations through random sampling. Core assumption: Environment dynamics are sufficiently stationary for replay buffer samples to remain relevant during training. Evidence: Standard DQN architecture with target network updates every M iterations. Break condition: If UAV flight trajectories shift dramatically between training and deployment.

### Mechanism 3
DeepSHAP quantifies feature contributions to handover decisions, revealing buffer status and position as dominant factors over signal quality metrics. Shapley values compute marginal contribution of each feature across all subsets, providing both local and global feature importance rankings. Core assumption: SHAP approximations sufficiently capture feature interactions in the neural network. Evidence: Buffer queue size remains the most dominant feature in SHAP analysis. Break condition: If model architecture changes significantly, DeepSHAP calibration requires re-computation.

## Foundational Learning

- **Deep Q-Network (DQN) fundamentals**: Core algorithm for learning handover policies without explicit environment models; understanding Q-function approximation is essential for debugging convergence issues. Quick check: Why does a target network prevent divergence compared to using a single network for both prediction and bootstrap targets?

- **Shapley Values and Game-Theoretic Attribution**: Provides theoretical foundation for understanding why SHAP fairly attributes feature contributions; necessary for validating explanation quality. Quick check: Why must Shapley values average over all possible feature orderings rather than using a single permutation?

- **3GPP Air-to-Ground Channel Model (TR 36.777)**: Required to understand LoS/NLoS probability and path loss that govern UAV signal dynamics. Quick check: At what altitude does the model assume P_LOS = 1, and how does this differ from terrestrial user assumptions?

## Architecture Onboarding

- **Component map**: Environment -> State Encoder -> Q-Network -> Action -> Reward -> Replay Buffer -> Loss -> Gradient Update (periodic target sync)
- **Critical path**: Training: Environment → State → Q-Network → Action → Reward → Replay Buffer → Loss → Gradient Update (periodic target sync); Inference: State → Q-Network → argmax(Q) → BS association decision; Explanation: State + Q-values → DeepSHAP → ψ values → Template → Natural language output
- **Design tradeoffs**: Reward weights (ω₁-ω₄) balance handover reduction vs signal quality; ε-decay rate affects exploration vs exploitation; SHAP background sample size impacts attribution accuracy vs compute cost
- **Failure signatures**: Ping-pong rate >14% indicates exploration issues; buffer overflow indicates reward weight imbalance; SHAP explanations contradicting intuition suggest data distribution mismatch
- **First 3 experiments**: 1) Baseline comparison: DQN vs CHM vs SA-MRO on identical trajectories; 2) Feature ablation: Train DQN variants with single features removed; 3) Sim-to-real gap analysis: Compare SHAP distributions between simulated and real data

## Open Questions the Paper Calls Out

**Open Question 1**: Can the explainable DQN framework be effectively scaled to multi-agent reinforcement learning (MARL) for coordinated UAV handovers without losing interpretability? Basis: Future work section mentions extending to MARL. Unresolved because scaling introduces non-stationarity and complex credit assignment that may obscure current SHAP-based explanations. Evidence needed: Demonstration of MARL training convergence where SHAP successfully disentangles individual agent contributions.

**Open Question 2**: How can the divergence in feature importance—specifically regarding signal quality metrics—between simulated training and real-world evaluation be minimized? Basis: Results section notes RSRP/RSRQ importance differs from simulated data. Unresolved because standard 3GPP channel models don't fully capture real-world propagation dynamics. Evidence needed: Comparative study showing domain-adapted channel models yield SHAP distributions matching real-world data.

**Open Question 3**: To what extent do natural language explanations generated by Language Models (LMs) enhance operator trust and decision validation speed compared to standard SHAP visualizations? Basis: Paper proposes LM-based text explanations but evaluation focuses on quantitative SHAP values. Unresolved because efficacy of generated text in bridging AI-human gap remains qualitative. Evidence needed: Human-subject study measuring accuracy and time-to-insight using LM explanations versus raw plots.

## Limitations

- Neural network architecture specifications are incomplete, making exact reproduction challenging
- Critical hyperparameters are not specified, potentially affecting performance sensitivity
- Real-world LTE dataset is not publicly available, preventing independent validation
- Method's performance on 5G NR networks with different channel characteristics remains untested

## Confidence

- **High Confidence (7/10)**: Core mechanism of using buffer status as state feature is well-supported by SHAP analysis and theoretical reasoning
- **Medium Confidence (5/10)**: Explainability claims through DeepSHAP are technically sound but practical utility depends on template quality
- **Low Confidence (3/10)**: Sim-to-real gap analysis is limited by dataset unavailability, preventing independent verification of real-world performance claims

## Next Checks

1. **Reproduce core results**: Implement DQN with assumed hyperparameters and validate 80%+ handover reduction on simulated dataset using 3GPP DA2G model

2. **SHAP attribution stability**: Generate SHAP explanations across multiple training runs and different UAV flight patterns to verify consistent buffer_queue_size dominance

3. **Baseline sensitivity analysis**: Systematically vary reward weights ω₁-ω₄ and measure impact on handover count, ping-pong rate, and buffer overflow incidents