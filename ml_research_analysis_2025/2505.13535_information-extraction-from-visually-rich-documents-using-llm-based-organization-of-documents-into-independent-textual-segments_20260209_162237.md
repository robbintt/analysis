---
ver: rpa2
title: Information Extraction from Visually Rich Documents using LLM-based Organization
  of Documents into Independent Textual Segments
arxiv_id: '2505.13535'
source_url: https://arxiv.org/abs/2505.13535
tags:
- document
- block
- blockie
- text
- blocks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces BLOCKIE, a novel LLM-based approach for information
  extraction from visually rich documents (VRDs). BLOCKIE organizes documents into
  localized, reusable semantic textual segments called "semantic blocks" and processes
  them independently using LLM-driven reasoning.
---

# Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments

## Quick Facts
- arXiv ID: 2505.13535
- Source URL: https://arxiv.org/abs/2505.13535
- Reference count: 36
- Outperforms state-of-the-art on CORD, FUNSD, SROIE by 1-3% F1 scores

## Executive Summary
BLOCKIE introduces a novel LLM-based approach for information extraction from visually rich documents by organizing them into localized, reusable semantic textual segments called "semantic blocks." The method processes these blocks independently using LLM-driven reasoning, enabling format-agnostic extraction and value-absent inference. Experiments demonstrate 1-3% F1 improvements over state-of-the-art methods on public benchmarks while maintaining strong performance even with smaller LLMs.

## Method Summary
BLOCKIE is a 3-stage LLM pipeline that first segments documents into self-contained semantic blocks where all entity linkages are internal, then parses each block independently using retrieved similar examples, and finally combines the partial parses into a complete schema output. The method uses OCR text and bounding boxes as input, with block creation and parsing guided by few-shot examples and chain-of-thought reasoning. Training involves converting ground truth into semantic blocks with reasoning traces, and the system achieves strong format generalization by matching semantically similar blocks across document types rather than requiring format-matched training data.

## Key Results
- Achieves 1-3% F1 improvements over state-of-the-art on CORD, FUNSD, and SROIE benchmarks
- Demonstrates 97.06% F1 on SROIE total-amount extraction when trained on CORD (vs. 33.43% for LayoutLMV3)
- Maintains strong performance with smaller LLMs (7B-32B), suggesting improvements stem from methodology rather than raw model size
- Successfully performs value-absent inference, correctly extracting information not explicitly present in 90% of test cases

## Why This Works (Mechanism)

### Mechanism 1: Semantic Block Decomposition Enables Format-Agnostic Reasoning
Decomposing documents into self-contained semantic blocks allows LLMs to reason over generalizable units rather than format-specific layouts. A semantic block is defined as a segment where all attribute-value and hierarchical linkages are internal, enabling correct interpretation in isolation. This works because documents naturally organize information in human-readable blocks where related entities co-locate spatially and semantically.

### Mechanism 2: Localized Few-Shot Learning via Block-Level Similarity Matching
Matching test blocks to similar blocks in training data improves generalization to unseen formats. During block parsing, the system retrieves few-shot examples using cosine similarity of OCR text embeddings at the block level. Since semantically similar blocks (e.g., contact information) appear across heterogeneous document formats, this bypasses the need for format-matched training samples.

### Mechanism 3: Sequential Reasoning Enables Value-Absent Inference
Chain-of-thought reasoning over semantic blocks allows extraction of information not explicitly present in the document. The training data labeling step generates step-by-step reasoning traces that prime the LLM to perform multi-step inference during testing, such as counting line items by aggregating hierarchical sub-items.

## Foundational Learning

- **Semantic Segmentation vs. Layout Segmentation**: BLOCKIE's core innovation is segmenting by semantic completeness rather than visual/layout boundaries. Understanding this distinction is prerequisite to implementing block creation. Quick check: Given text "TOTAL ITEMS 1" where "TOTAL" and "ITEMS" are adjacent but "1" is spatially distant, which segments form semantic atoms vs. a semantic block?

- **In-Context Learning with Retrieval-Augmented Few-Shot**: The system relies on dynamically retrieved similar blocks as few-shot examples. Understanding how embedding similarity interacts with LLM in-context learning is critical for debugging retrieval quality. Quick check: If block-level cosine similarity retrieves examples from a different document domain (e.g., legal fax examples for retail receipts), would you expect performance to improve or degrade compared to format-matched retrieval?

- **Hierarchical Entity Schemas**: The document schema defines hierarchical entities (e.g., menu→menu_item→sub_item). Block creation must preserve these hierarchies internally. Quick check: A document has line items with sub-items. If a block contains a sub-item but not its parent line item, does it satisfy the semantic block definition?

## Architecture Onboarding

- **Component map**: Train Dataset Labeling -> Block Creator -> Block Parser -> Block Combiner
- **Critical path**: Schema definition → Training data labeling → Block creation on test document → Per-block parsing → Final combination
- **Design tradeoffs**: Sequential LLM calls increase latency but enable modular debugging; block-level retrieval improves format generalization but requires block-level indexing; text-only input limits visual cue utilization
- **Failure signatures**: Block creation errors cascade (70% recoverable); smaller LLMs struggle with block creation (74.91% vs 86.73% F1); cross-block dependencies severed if linkage crosses boundaries
- **First 3 experiments**: 1) Block quality ablation: Run with ground-truth blocks to isolate block-creation errors; 2) Format generalization test: Train on CORD, test on SROIE to replicate cross-dataset results; 3) LLM size scaling: Test with Qwen 2.5 (7B-72B) to identify performance thresholds

## Open Questions the Paper Calls Out

1. **Incorporating Visual Features**: Future work could focus on incorporating image-based features such as font size, bold/italics, etc., into semantic block creation even in text-only LLMs. The current implementation relies primarily on OCR text and bounding boxes, potentially missing visual cues that define semantic boundaries.

2. **Robust Block Creation**: Future research should focus on robust block creation as missed linkages can be hard to recover. The pipeline is sequential; if the block creator misses a linked semantic atom, the block parser cannot recover that information, degrading final accuracy.

3. **Sequential Architecture Optimization**: The computational architecture currently requires sequential LLM calls for block creation, processing, and combining which increases latency. While the method improves accuracy, the multi-stage sequential nature may hinder real-time application suitability compared to single-pass models.

## Limitations
- Sequential LLM architecture increases latency compared to single-pass models
- Block creation quality strongly impacts final performance, with smaller LLMs struggling to create high-quality blocks
- Value-absent inference capability demonstrated on limited sample size (20 cases) without systematic failure analysis

## Confidence
- **High Confidence**: Core methodology of semantic block decomposition and 3-stage pipeline architecture are well-specified and reproducible
- **Medium Confidence**: Format generalization claims rely on single cross-dataset experiment (CORD→SROIE for total amount extraction)
- **Low Confidence**: Value-absent inference capability demonstrated on small sample (18/20 success rate) with limited variety in reasoning types

## Next Checks
1. **Embedding Model Sensitivity**: Systematically test different embedding models (e.g., SBERT, CLIP, BERT) for block-level retrieval to determine impact on both block quality and final extraction performance.

2. **Schema Complexity Scaling**: Evaluate BLOCKIE on progressively more complex schemas (shallow 2-3 level hierarchies vs. deep 5+ level hierarchies) to identify the point where block-based reasoning degrades due to severed cross-block dependencies.

3. **Cross-Format Entity Generalization**: Beyond the single total-amount experiment, test BLOCKIE's ability to extract multiple entity types (e.g., date, address, itemized lines) when trained on one document domain and tested on another (e.g., train on invoices, test on forms).