---
ver: rpa2
title: 'SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper'
arxiv_id: '2601.19194'
source_url: https://arxiv.org/abs/2601.19194
tags:
- speaker
- speech
- dicow
- target
- diarization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces SE-DiCoW (Self-Enrolled Diarization-Conditioned
  Whisper), a target-speaker ASR system that addresses ambiguity in overlapped speech
  regions in the original Diarization-Conditioned Whisper (DiCoW) approach. SE-DiCoW
  automatically selects a segment containing the target speaker's speech from a recording
  and uses it as fixed conditioning via cross-attention at each encoder layer.
---

# SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper

## Quick Facts
- arXiv ID: 2601.19194
- Source URL: https://arxiv.org/abs/2601.19194
- Reference count: 0
- Primary result: Reduces macro-averaged tcpWER by 52.4% relative to original DiCoW on EMMA MT-ASR with oracle diarization

## Executive Summary
SE-DiCoW introduces a target-speaker ASR system that improves upon the original Diarization-Conditioned Whisper (DiCoW) approach by addressing ambiguity in overlapped speech regions. The system automatically selects a segment containing the target speaker's speech from a recording and uses it as fixed conditioning via cross-attention at each encoder layer. Through additional architectural improvements including an FDDT layer, data augmentation, and corrected training data segmentation, SE-DiCoW achieves state-of-the-art performance on AMI SDM and Libri2Mix datasets.

## Method Summary
SE-DiCoW builds on the Diarization-Conditioned Whisper framework by implementing automatic speaker enrollment through self-segmentation. The system extracts a speaker-specific segment from the recording and applies it as fixed conditioning across all encoder layers using cross-attention mechanisms. Key architectural enhancements include inserting an additional FDDT layer before positional embeddings, implementing data augmentation strategies, and correcting training data segmentation errors. These modifications collectively address the original DiCoW limitation of handling overlapped speech regions by providing clearer speaker conditioning throughout the encoding process.

## Key Results
- Achieves 52.4% relative reduction in macro-averaged tcpWER compared to original DiCoW with oracle diarization
- Demonstrates state-of-the-art performance on AMI SDM and Libri2Mix benchmark datasets
- Successfully addresses ambiguity in overlapped speech regions through self-enrollment mechanism

## Why This Works (Mechanism)
SE-DiCoW works by providing unambiguous speaker conditioning throughout the encoding process. By selecting a segment containing only the target speaker's speech and using it as fixed cross-attention conditioning at each encoder layer, the system maintains clear speaker identity even in overlapping speech scenarios. The additional FDDT layer enhances temporal feature extraction before positional embedding, while data augmentation improves robustness to varying acoustic conditions. The corrected training segmentation ensures the model learns from properly aligned speaker segments, contributing to improved generalization.

## Foundational Learning

**Cross-attention conditioning**: Allows the model to attend to speaker-specific features at every encoder layer, maintaining speaker identity throughout processing. Quick check: Verify attention weights consistently focus on speaker-relevant features across layers.

**FDDT (Frequency Domain Dilated Transformer)**: Processes temporal features in frequency domain with dilated convolutions, capturing long-range dependencies. Quick check: Compare temporal resolution before and after FDDT layer.

**Self-enrollment segmentation**: Automatically extracts speaker-specific segments from recordings for conditioning. Quick check: Validate segment purity by measuring non-target speaker content percentage.

## Architecture Onboarding

Component map: Audio input -> FDDT layer -> Positional embeddings -> Encoder layers (with cross-attention to speaker segment) -> Decoder

Critical path: Speaker segment selection -> Cross-attention conditioning at each encoder layer -> ASR decoding

Design tradeoffs: Fixed cross-attention conditioning provides clear speaker identity but may reduce flexibility for speaker changes; automatic enrollment reduces manual annotation burden but depends on segment quality.

Failure signatures: Performance degradation when enrollment segment contains overlapping speech; reduced accuracy with speaker characteristic changes across recording.

First experiments: 1) Test cross-attention effectiveness by comparing with and without speaker conditioning; 2) Evaluate FDDT layer impact through ablation; 3) Measure enrollment segment quality correlation with final accuracy.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions in the provided content.

## Limitations

- Performance relies on oracle diarization in benchmark evaluation, limiting real-world applicability
- Insufficient exploration of failure modes when enrollment segments contain mixed speech
- Individual contributions of architectural improvements not quantitatively isolated through ablation studies

## Confidence

High in technical approach description and benchmark results; Medium in claimed relative improvements and ablation analysis; Low in real-world deployment considerations and failure mode analysis.

## Next Checks

1. Test SE-DiCoW performance with automatic (non-oracle) diarization on the EMMA MT-ASR benchmark to assess practical deployment viability
2. Conduct controlled experiments isolating the impact of each proposed improvement (FDDT layer, data augmentation, segmentation correction) on overall performance
3. Evaluate system robustness by testing with intentionally corrupted enrollment segments containing overlapping speech or non-target speaker content