---
ver: rpa2
title: 'NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation'
arxiv_id: '2512.05106'
source_url: https://arxiv.org/abs/2512.05106
tags:
- diffusion
- noise
- image
- phase
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of structure-aligned generation
  in diffusion models, where maintaining spatial consistency during image-to-image
  translation is critical. Standard diffusion corrupts phase components, destroying
  spatial structure and forcing models to reconstruct geometry from scratch.
---

# NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation

## Quick Facts
- **arXiv ID:** 2512.05106
- **Source URL:** https://arxiv.org/abs/2512.05106
- **Reference count:** 40
- **Primary result:** Phase-Preserving Diffusion (ϕ-PD) improves CARLA-to-Waymo planner performance by 49% by preserving spatial structure during simulation enhancement.

## Executive Summary
NeuralRemaster introduces Phase-Preserving Diffusion (ϕ-PD), a model-agnostic reformulation of the diffusion process that maintains spatial alignment during image-to-image translation by preserving input phase while randomizing magnitude in the frequency domain. Unlike standard diffusion that corrupts phase components and forces models to reconstruct geometry from scratch, ϕ-PD replaces Gaussian noise with structured noise that locks spatial structure via phase preservation. The method requires no architectural changes or additional parameters, works with any diffusion model (DDPM or flow matching), and adds no inference-time overhead. Evaluated across photorealistic re-rendering, stylized generation, and simulation enhancement for driving planners, ϕ-PD consistently maintains geometry alignment while producing high-quality outputs.

## Method Summary
The core innovation is replacing Gaussian noise in the diffusion forward process with structured noise that preserves the input image's phase component. Given an input image I with Fourier transform F_I = A_I · e^{jφ_I}, ϕ-PD constructs noise ε̂ = F^{-1}{A_ε · e^{jφ_I}} where A_ε is random magnitude sampled from Gaussian or Rayleigh distributions. This ensures that throughout the diffusion process, the spatial structure encoded in phase remains intact while magnitude randomization provides creative flexibility. The method extends to Frequency-Selective Structured (FSS) noise with a single cutoff parameter r that controls structural rigidity via frequency masking. Training uses standard diffusion objectives with this structured noise substitution, making it compatible with any existing diffusion architecture without architectural modifications.

## Key Results
- Improves CARLA-to-Waymo planner performance by 49%, significantly narrowing the sim-to-real gap
- Maintains depth SSIM above 0.95 across all UnrealCV test images while improving photorealism
- Achieves continuous control over structure-creativity tradeoff via single frequency-cutoff parameter
- Works with multiple architectures (SD 1.5, FLUX-dev, Wan 2.2-14B) without architectural changes

## Why This Works (Mechanism)

### Mechanism 1: Phase-Preserving Noise Replaces Gaussian Noise
Replacing Gaussian noise with structured noise that preserves input phase maintains spatial alignment throughout diffusion sampling. The mechanism constructs noise by combining random magnitude with fixed input phase in frequency domain, leveraging the established principle that phase encodes spatial structure more strongly than magnitude for natural images.

### Mechanism 2: Frequency-Selective Structured (FSS) Noise Enables Continuous Control
A single cutoff parameter r provides interpretable control over structure-to-creativity tradeoff by applying frequency masks that preserve low-frequency phase (global structure) while randomizing high-frequency phase (fine detail flexibility).

### Mechanism 3: Model-Agnostic Training Objective Compatibility
ϕ-PD integrates with any DDPM or flow-matching model by substituting noise in the forward process while keeping loss functions unchanged, allowing direct application to pre-trained models without architectural modifications.

## Foundational Learning

- **Fourier Transform: Magnitude vs Phase**
  - Why needed here: Understanding why phase encodes spatial structure is prerequisite to grasping ϕ-PD's core insight.
  - Quick check question: Given two images A and B, if you combine phase from A with magnitude from B in frequency domain, which image's structure does the reconstruction resemble?

- **Diffusion Forward/Reverse Process**
  - Why needed here: ϕ-PD modifies the forward corruption process; you must understand how noise schedules and denoising interact.
  - Quick check question: In a DDPM, what does the network learn to predict at each timestep?

- **Flow Matching / Rectified Flows**
  - Why needed here: Paper implements ϕ-PD on flow-matching models (FLUX, Wan); linear interpolation differs from DDPM's noise schedule.
  - Quick check question: In rectified flow, how is intermediate sample x_t constructed from data and noise?

## Architecture Onboarding

- **Component map**: Input image → FFT → Extract φ_I (phase), discard A_I → Sample random magnitude A_ε → Construct F_ε̂ = A_ε · e^{jφ_I} → IFFT → ε̂ (structured noise) → Forward diffusion uses ε̂ instead of Gaussian ε → Standard denoising network (unchanged)

- **Critical path**: Structured noise construction (Eq. 5-6, 9-10). Errors here (wrong phase extraction, incorrect mask application) propagate to all downstream steps.

- **Design tradeoffs**:
  - Higher cutoff r → stronger structural alignment, less appearance flexibility
  - Training r_0 (minimum cutoff) → models trained with higher r_0 perform better at high inference r; lower r_0 better for low-quality inputs requiring larger changes
  - Full finetuning vs LoRA → Paper shows LoRA sufficient for large models (Wan 2.2-14B, FLUX-dev)

- **Failure signatures**:
  - Geometric drift/distortion → Phase not properly preserved; check FFT/IFFT implementation
  - Over-rigid outputs, no style transfer → Cutoff r too high
  - Structure loss comparable to SDEdit → Cutoff r too low or noise magnitude sampling incorrect
  - Color/statistics artifacts → Magnitude A_ε distribution mismatch; verify Rayleigh vs Gaussian-derived sampling

- **First 3 experiments**:
  1. **Unit test structured noise**: For a synthetic image (e.g., checkerboard), construct ϕ-PD noise, verify IFFT(FFT(ε̂)) matches and phase equals input phase exactly.
  2. **Ablate cutoff r**: On UnrealCV subset, sweep r ∈ {1, 6, 10, 20, 30} with fixed r_0=4, plot Appearance Score vs Depth SSIM tradeoff curve.
  3. **Cross-model sanity check**: Apply ϕ-PD LoRA finetuning to SD 1.5 on a small dataset (1K images, 5K steps), verify structure preservation improves over SDEdit baseline on 100 held-out images using depth SSIM.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is Phase-Preserving Diffusion effective for general image restoration tasks such as deblurring, relighting, and super-resolution?
- **Basis in paper:** The Future Work section explicitly lists extending ϕ-PD to these tasks.
- **Why unresolved:** The current experiments focus on stylization and sim-to-real translation (image-to-image), whereas restoration requires recovering lost information rather than preserving the phase of a complete input.
- **What evidence would resolve it:** Quantitative benchmarks (e.g., PSNR, LPIPS) on standard restoration datasets like GoPro (deblurring) or SIDD (denoising) comparing ϕ-PD against specialized restoration baselines.

### Open Question 2
- **Question:** Can ϕ-PD be successfully integrated with architectural adapters like ControlNet to provide compound control?
- **Basis in paper:** The authors state ϕ-PD is orthogonal to existing conditioning methods and suggest their integration as a direction for future work.
- **Why unresolved:** It is unclear if the strict phase constraint from ϕ-PD conflicts with the spatial control signals injected by adapter branches, potentially limiting flexibility.
- **What evidence would resolve it:** Evaluation of a model combining ϕ-PD and ControlNet, measuring if structural fidelity improves without suppressing the adapter's conditioning capability.

### Open Question 3
- **Question:** Can the method be adapted to handle non-RGB geometric modalities like depth maps or normals directly?
- **Basis in paper:** The Limitations section notes ϕ-PD assumes image-like inputs and requires a lightweight prior to represent modalities like depth.
- **Why unresolved:** Depth maps possess different frequency statistics and structural definitions than natural images; it is unknown if simple phase preservation suffices for geometric validity.
- **What evidence would resolve it:** Successful application of ϕ-PD to depth-to-depth translation or depth-aware video generation without converting to an RGB representation first.

### Open Question 4
- **Question:** Is the finetuning step (LoRA or full) strictly necessary for structure alignment, or can pre-trained models function in a strictly zero-shot manner using only structured noise?
- **Basis in paper:** While the paper claims "model-agnostic" compatibility, all experimental results rely on models that underwent finetuning, leaving the efficacy of the noise substitution alone unproven.
- **Why unresolved:** If finetuning is mandatory, the method's "no additional parameters" advantage is offset by the need for dataset-specific training, unlike training-free guidance methods.
- **What evidence would resolve it:** A comparison of structural alignment metrics (e.g., Depth SSIM) between a vanilla pre-trained model and a finetuned model, both using ϕ-PD noise injection.

## Limitations
- Phase-dominance assumption may not hold for synthetic or highly stylized inputs where magnitude carries equal or greater structural information
- Training hyperparameters (LoRA rank, learning rate, optimizer settings) are unspecified for the largest models, making exact replication challenging
- Structural evaluation relies on depth estimation which may not capture all forms of geometric misalignment, particularly in texture-rich or ambiguous regions

## Confidence

- **High confidence**: Model-agnostic integration works as claimed (no architectural changes needed; standard loss functions remain valid)
- **Medium confidence**: Phase-preserving noise maintains spatial alignment in practical applications (validated empirically across multiple datasets but theoretical foundation untested)
- **Medium confidence**: Frequency cutoff r provides interpretable control over structure-creativity tradeoff (empirical tradeoff curves observed but underlying mechanism not proven)

## Next Checks

1. Test ϕ-PD on stylized input distributions (e.g., artistic renderings, cartoons) where magnitude might encode structure, measuring whether phase-locking degrades creative flexibility.
2. Implement ablation studies on LoRA hyperparameters (rank, learning rate) for FLUX-dev and Wan2.2-14B to determine sensitivity and optimal configurations.
3. Validate depth estimation robustness by comparing structural alignment metrics using multiple depth estimators (MiDaS variants, DPT) on the same ϕ-PD outputs to quantify metric sensitivity.