---
ver: rpa2
title: On The Variability of Concept Activation Vectors
arxiv_id: '2509.24058'
source_url: https://arxiv.org/abs/2509.24058
tags:
- random
- number
- examples
- variance
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the variability of Concept Activation Vectors
  (CAVs) in the TCAV method, focusing on how the number of random examples affects
  their stability. The authors provide a theoretical analysis showing that the variance
  of CAVs decreases as 1/N, where N is the number of random examples, under certain
  assumptions.
---

# On The Variability of Concept Activation Vectors

## Quick Facts
- arXiv ID: 2509.24058
- Source URL: https://arxiv.org/abs/2509.24058
- Reference count: 40
- Primary result: CAV variance decreases as 1/N with random sample count; TCAV variance remains constant due to borderline points

## Executive Summary
This paper investigates the variability of Concept Activation Vectors (CAVs) in the TCAV method, focusing on how the number of random examples affects their stability. The authors provide a theoretical analysis showing that CAV variance decreases as 1/N under the "surrounded mean" assumption, while TCAV score variance remains approximately constant due to borderline evaluation points. The paper recommends using multiple runs with modest sample sizes for stable TCAV scores and larger per-run sample sizes for stable CAV directions. Experiments on image, tabular, and text data confirm the theoretical findings.

## Method Summary
The study analyzes CAV variability through theoretical analysis of penalized logistic regression in the infinitely imbalanced regime (fixed concept samples, growing random samples). The authors prove that √N(β_N - β_0) converges to a multivariate normal distribution, implying Cov(β_N) ∝ 1/N. They also analyze TCAV score variance, showing it remains constant due to sensitivity of borderline samples. The methodology involves training CAVs using logistic regression with L2 penalty, computing sensitivity scores for evaluation samples, and aggregating to TCAV scores. The study validates findings across three data modalities: ImageNet images, UCI Adult tabular data, and IMDB text data.

## Key Results
- CAV variance decreases as 1/N with number of random examples under "surrounded mean" assumption
- TCAV score variance remains approximately constant (Θ(1)) despite CAV stabilization, due to borderline samples
- Multi-run averaging reduces TCAV variance as 1/s where s is number of independent runs

## Why This Works (Mechanism)

### Mechanism 1: CAV Variance Decays as O(1/N)
- **Claim:** The variance of Concept Activation Vectors decreases inversely with the number of random examples used in training.
- **Mechanism:** The CAV is the coefficient vector β_N from L2-penalized logistic regression. In the "infinitely imbalanced" regime (fixed concept samples, N→∞ random samples), √N(β_N - β_0) converges in distribution to a multivariate normal N(0, Σ), implying Cov(β_N) ∝ 1/N.
- **Core assumption:** Assumption 1 (Surrounded Mean) — the distribution F_0 of random samples has the concept mean x̄ "surrounded" in every direction, and the limit Hessian H_0 exists and is invertible.
- **Evidence anchors:**
  - [abstract] "variance of CAVs decreases as 1/N, where N is the number of random examples"
  - [section 4.2] Theorem 1 and Corollary 4.2 provide the formal proof; experimental validation in Figure 2 across image, tabular, and text datasets.
  - [corpus] Related work (FastCAV, Post-Hoc Concept Disentanglement) addresses computational efficiency and entanglement but does not formally derive variance scaling; this paper is the first O(1/N) theoretical result for CAVs.
- **Break condition:** When the "surrounded mean" assumption fails (e.g., random samples lie in a narrow subspace around x̄), or when the Hessian is near-singular (highly collinear features), the O(1/N) guarantee may not hold.

### Mechanism 2: TCAV Score Variance Persists at Θ(1)
- **Claim:** Even as CAV variance vanishes with larger N, the TCAV score variance remains approximately constant.
- **Mechanism:** TCAV is the proportion of class samples with positive sensitivity S(x, β_N). For "borderline" samples near the decision boundary (sensitivity ≈ 0), small CAV perturbations flip the sign, contributing O(1) variance. Non-borderline samples contribute negligibly as CAV stabilizes.
- **Core assumption:** There exists a subset of evaluation samples whose latent embeddings lie on or near the decision boundary, making their classification highly sensitive to CAV perturbations.
- **Evidence anchors:**
  - [section 4.4] "the variance of the TCAV scores is approximately independent of the number N of random embedding vectors used"; experimental confirmation in Figure 4.
  - [corpus] No corpus papers directly address TCAV variance persistence; this is a novel finding in this work.
- **Break condition:** When all evaluation samples are far from the decision boundary (no borderline points), TCAV variance may decrease; conversely, if many samples are borderline, variance remains high regardless of N.

### Mechanism 3: Multi-run Averaging Reduces TCAV Variance as O(1/s)
- **Claim:** Averaging TCAV scores over s independent runs reduces variance proportionally to 1/s.
- **Mechanism:** Each run uses a disjoint random sample set, producing independent CAVs β^(j)_N and TCAV scores T_j. The sample mean of s independent scores has variance σ²/s, where σ² = Var(T_j) = O(1).
- **Core assumption:** The s runs use disjoint random samples and produce approximately independent TCAV scores.
- **Evidence anchors:**
  - [section 4.5] Conjecture 1 and Figure 5 validate empirically; variance decreases as s increases for fixed total samples R.
  - [corpus] No corpus papers analyze multi-run variance reduction for TCAV; this is a practical contribution.
- **Break condition:** If runs share samples or CAVs become correlated (e.g., due to strong regularization or small random pools), independence breaks and O(1/s) decay may not hold.

## Foundational Learning

- **Concept: Asymptotic Normality in M-Estimation**
  - Why needed here: Theoretical guarantees for CAV variance rely on proving √N-scaling normality of penalized logistic regression estimators.
  - Quick check question: Given an M-estimator θ_N minimizing empirical risk, what conditions ensure √N(θ_N - θ_0) → N(0, Σ)?

- **Concept: Logistic Regression in Infinitely Imbalanced Regimes**
  - Why needed here: CAV training fixes concept samples (n) while growing random samples (N→∞), creating asymmetric class sizes.
  - Quick check question: In logistic regression with one class fixed and the other growing, why does the intercept scale as α_N ~ log(A_0/N)?

- **Concept: TCAV (Testing with Concept Activation Vectors)**
  - Why needed here: The paper's target is understanding TCAV variance; TCAV aggregates per-sample sensitivities into a class-level score.
  - Quick check question: How is sensitivity S_C,k,ℓ(x) defined, and how does TCAV aggregate sensitivities across a class?

## Architecture Onboarding

- **Component map:**
  - Model split: f = g_ℓ ∘ h_ℓ, where h_ℓ: X → R^d (embeddings) and g_ℓ,k: R^d → R (class logits)
  - CAV computation: Binary classifier (logistic regression / hinge loss / difference of means) separates concept embeddings {h_ℓ(x_i)} from random embeddings {h_ℓ(z_j)}; normal vector β_N = v_C^ℓ
  - Sensitivity: S_C,k,ℓ(x) = ∇g_ℓ,k(h_ℓ(x)) · v_C^ℓ
  - TCAV score: Proportion of class k samples with S(x) > 0; tested for significance via two-tailed t-test

- **Critical path:**
  1. Collect concept samples (fixed n) and sample random references (variable N)
  2. Extract latent embeddings at layer ℓ
  3. Train binary classifier → obtain CAV β_N
  4. Compute sensitivities for all evaluation samples in target class
  5. Aggregate to TCAV score; optionally repeat across s runs and average

- **Design tradeoffs:**
  - Larger N per run → more stable CAV directions (good for bias mitigation, steering), but TCAV variance does not decrease
  - More runs s (smaller N per run) → reduced TCAV variance O(1/s), but higher compute overhead (~1.5× per doubling of s in Captum)
  - Classifier choice: Logistic regression (amenable to theory), hinge loss (default in TCAV libraries), difference of means (simpler, also O(1/N) variance)

- **Failure signatures:**
  - High CAV variance: CAVs change drastically across runs; check if N is too small or random pool lacks diversity
  - High TCAV variance despite large N: Likely due to borderline samples; increase runs s rather than N
  - CAV directions unstable across layers: Known layer inconsistency (Nicolson et al., 2025); not addressed here

- **First 3 experiments:**
  1. **Variance vs. N curve:** For one concept and layer, repeat CAV training r=10 times at each N ∈ {10, 50, 100, 200, 300}. Plot trace of covariance matrix; fit a/N + b and confirm ~1/N scaling.
  2. **TCAV variance vs. N:** Fix class and concept; compute TCAV scores over r runs for each N. Plot variance; confirm it plateaus (does not decrease with N).
  3. **Multi-run averaging:** Fix total budget R=2000 random samples. Split into s ∈ {1, 2, 4, 8, 16} subsets (N=R/s). For each s, run r=10 repetitions of the s-run averaging procedure; plot variance of averaged TCAV vs. s to validate O(1/s).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the choice of optimization algorithm (e.g., SGD vs. L-BFGS) and its convergence interact with the statistical stability of CAVs?
- **Basis in paper:** [explicit] The Conclusion states: "since our analysis assumed perfect optimization, an important goal for future work is to investigate the role of the optimizer... examine the interaction between its convergence properties and the statistical stability."
- **Why unresolved:** The theoretical proofs in the paper assume the penalized logistic estimator is the unique maximizer, effectively ignoring the noise introduced by iterative optimization algorithms used in practice.
- **What evidence would resolve it:** A theoretical analysis or empirical benchmark quantifying the variance contribution of the optimizer compared to the sampling variance of the random examples.

### Open Question 2
- **Question:** How can the trade-off between compute time and stability be quantified for specific library implementations like Captum?
- **Basis in paper:** [explicit] The Conclusion notes: "the nature of the trade-off between compute time and stability is highly implementation-dependent... we therefore propose investigating this trade-off in more detail to provide implementation-specific advice."
- **Why unresolved:** The paper establishes general $O(N)$ rates, but practical implementation overheads (e.g., data loading, model inference) vary across libraries, making general resource allocation rules difficult to standardize.
- **What evidence would resolve it:** A comparative study measuring wall-clock time versus variance reduction for specific software implementations to derive optimal sample sizing for each.

### Open Question 3
- **Question:** Can the constant variance of TCAV scores caused by "borderline points" be mitigated by filtering evaluation samples?
- **Basis in paper:** [inferred] Section 4.4 identifies "borderline points" (evaluation samples near the decision boundary) as the cause for TCAV variance remaining constant ($O(1)$) rather than decreasing with sample size.
- **Why unresolved:** The theoretical analysis suggests that increasing random samples does not reduce TCAV variance because these borderline points remain sensitive to small perturbations regardless of CAV accuracy.
- **What evidence would resolve it:** An algorithm that identifies and excludes borderline points from the TCAV calculation, successfully demonstrating a reduction in score variance as sample size increases.

### Open Question 4
- **Question:** Does the asymptotic $O(1/N)$ variance decay apply to non-linear concept boundary methods?
- **Basis in paper:** [inferred] The theoretical analysis is restricted to linear classifiers (Logistic Regression, SVM, Difference of Means), while the Related Work mentions non-linear extensions like Concept Activation Regions (CAR).
- **Why unresolved:** Non-linear boundaries introduce additional complexity and parameters in the estimator's covariance structure that may not follow the same decay rate as linear normal vectors.
- **What evidence would resolve it:** Experimental validation or theoretical derivation of variance rates for kernel-based or deep concept encoders to see if the $O(1/N)$ law holds.

## Limitations
- The "surrounded mean" assumption may not hold in all practical settings, particularly when random samples occupy a narrow subspace around the concept mean
- The persistence of TCAV variance at Θ(1) depends critically on the existence of borderline evaluation points, which may vary significantly across datasets and concepts
- The theoretical analysis assumes perfect optimization, ignoring potential variance contributions from iterative optimization algorithms

## Confidence
- **High confidence**: CAV variance decaying as 1/N (supported by both theory and extensive experimental validation across three data modalities)
- **Medium confidence**: TCAV variance remaining constant with increasing N (theoretically sound but requires the borderline sample assumption)
- **Medium confidence**: Multi-run averaging reducing TCAV variance as 1/s (empirical validation shown, but theoretical proof remains conjectural)

## Next Checks
1. Test the surrounded mean assumption across diverse random sample distributions (uniform, Gaussian, clustered) to identify when the O(1/N) guarantee breaks.
2. Analyze the proportion of borderline samples in different datasets and concepts to quantify their contribution to persistent TCAV variance.
3. Evaluate whether different classifier choices (hinge loss, difference of means) exhibit the same variance scaling properties as logistic regression.