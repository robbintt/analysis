---
ver: rpa2
title: 'The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic
  Systems'
arxiv_id: '2512.05449'
source_url: https://arxiv.org/abs/2512.05449
tags:
- scheming
- action
- more
- course
- long-term
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces akrasia (weakness of will) as a lens for\
  \ analyzing inconsistency and goal drift in agentic AI systems. It proposes the\
  \ Akrasia Benchmark, a structured prompting framework that tests when a model\u2019\
  s local response contradicts its prior commitments under conditions like distraction,\
  \ paraphrasing, and temptation."
---

# The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems

## Quick Facts
- arXiv ID: 2512.05449
- Source URL: https://arxiv.org/abs/2512.05449
- Reference count: 31
- Models exhibit high immediate and temporal consistency, but reduced consistency under temptation, particularly with negation and decoy questions.

## Executive Summary
This paper introduces akrasia (weakness of will) as a philosophical lens for analyzing inconsistency and goal drift in agentic AI systems. The authors propose the Akrasia Benchmark, a structured prompting framework that tests whether a model’s local response contradicts its prior commitments under conditions like distraction, paraphrasing, and temptation. Across multiple models (including Llama, Qwen, GPT-4o-mini) and decoding strategies, the benchmark reveals that while models generally maintain high immediate and temporal consistency, they show reduced consistency under temptation—especially with negation and decoy questions. Larger models exhibit better resistance to social proof, but trends are mixed for other temptations. The findings suggest that apparent “scheming” may arise from micro-level epistemic lapses rather than hidden intent, offering a bridge between philosophy and AI safety research.

## Method Summary
The Akrasia Benchmark is a structured prompting framework that evaluates AI models’ consistency under conditions designed to elicit akrasia-like behavior. It tests three types of consistency: immediate (consistency between prompt and immediate response), temporal (consistency across repeated exposures), and temptation (resistance to prompts that attempt to contradict prior commitments). The benchmark uses multi-turn prompts with various decoding strategies (temperature, top-k) and includes conditions like distraction, paraphrasing, and social proof. The study evaluates multiple models including Llama, Qwen, and GPT-4o-mini, measuring how often responses contradict stated commitments under different temptation conditions.

## Key Results
- Models show high immediate and temporal consistency across all tested conditions
- Temptation resistance is significantly lower, particularly for negation and decoy questions
- Larger models demonstrate better resistance to social proof temptations
- Consistency trends are mixed for other temptation types, suggesting model-dependent vulnerabilities

## Why This Works (Mechanism)
The Akrasia Benchmark works by creating controlled conditions where models must maintain consistency despite various forms of interference. By structuring prompts to include distractions, paraphrasing, and temptations, the framework reveals whether apparent goal drift stems from epistemic lapses (akrasia) rather than intentional scheming. The benchmark’s strength lies in its ability to isolate specific failure modes and measure them quantitatively across different models and decoding strategies.

## Foundational Learning
- Akrasia (weakness of will): The philosophical concept of acting against one’s better judgment; needed to frame AI inconsistencies as lapses rather than intent; quick check: can the model maintain commitment under temptation?
- Prompt engineering: Structured prompting techniques to test consistency; needed to create controlled test conditions; quick check: do prompts reliably elicit target behaviors?
- Temporal consistency: Maintaining the same response across repeated exposures; needed to assess model reliability over time; quick check: does the model contradict itself in repeated trials?
- Temptation resistance: Ability to maintain commitments despite attempts to contradict them; needed to identify genuine goal drift; quick check: how does the model respond to negation or social proof?

## Architecture Onboarding
- Component map: Prompt structure -> Model response -> Consistency evaluation -> Temptation condition
- Critical path: Structured prompt → Model generation → Consistency check → Temptation evaluation
- Design tradeoffs: Structured prompts provide control but may not reflect naturalistic interactions; single-turn prompts are efficient but may miss multi-step reasoning effects
- Failure signatures: High immediate consistency but low temptation resistance suggests epistemic lapses; inconsistent responses across repetitions indicate temporal instability
- First experiments: 1) Test benchmark across additional frontier models, 2) Evaluate multi-turn scenarios, 3) Conduct ablation studies on decoding strategies

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark relies on structured prompts that may not reflect real-world deployment conditions
- Attribution of inconsistencies to akrasia rather than intent is interpretive and not empirically validated
- Sample size of tested models and decoding strategies is modest
- Single-turn prompts may understate persistence of goal drift
- Focus on English-language prompts limits applicability to multilingual systems

## Confidence
- Benchmark design and methodology: High
- Observed consistency trends: Medium
- Philosophical interpretation (akrasia vs scheming): Medium
- Generalization to broader AI systems: Low

## Next Checks
1. Test the Akrasia Benchmark across additional frontier models and non-English languages to assess robustness
2. Incorporate multi-turn, interactive scenarios to evaluate consistency under sustained agentic engagement
3. Conduct ablation studies isolating the effect of decoding strategy (e.g., top-k, temperature) on temptation resistance