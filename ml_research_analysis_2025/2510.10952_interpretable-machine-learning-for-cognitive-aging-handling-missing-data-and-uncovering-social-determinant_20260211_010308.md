---
ver: rpa2
title: 'Interpretable Machine Learning for Cognitive Aging: Handling Missing Data
  and Uncovering Social Determinant'
arxiv_id: '2510.10952'
source_url: https://arxiv.org/abs/2510.10952
tags:
- cognitive
- health
- features
- data
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops an interpretable machine learning framework
  to predict cognitive performance from social determinants of health using the Mex-Cog
  cohort. It employs SVD-based imputation to handle missing data and XGBoost for prediction,
  achieving an RMSE of 36.65 via 10-fold cross-validation.
---

# Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant

## Quick Facts
- **arXiv ID:** 2510.10952
- **Source URL:** https://arxiv.org/abs/2510.10952
- **Reference count:** 0
- **Primary result:** XGBoost with SVD imputation achieves RMSE of 36.65 on Mex-Cog cognitive aging prediction task.

## Executive Summary
This study develops an interpretable machine learning framework to predict cognitive performance from social determinants of health using the Mex-Cog cohort. It employs SVD-based imputation to handle missing data and XGBoost for prediction, achieving an RMSE of 36.65 via 10-fold cross-validation. SHAP analysis identifies key predictors including education, age, sleep quality, social engagement, and flooring material, which serves as a proxy for socioeconomic and environmental inequities. The framework outperforms existing methods and demonstrates robustness, interpretability, and adaptability across age groups, highlighting the value of SDOH modeling in early Alzheimer's disease detection.

## Method Summary
The framework uses iterative hard-thresholded SVD for missing data imputation, separating continuous and categorical variables. After preprocessing (one-hot encoding categoricals, z-score normalization), XGBoost is selected for its superior performance on heterogeneous, imputed tabular data. SHAP values provide post-hoc interpretability, identifying flooring material as a key SDOH proxy. The approach is validated through 10-fold cross-validation and age-stratified analysis.

## Key Results
- SVD-based imputation with XGBoost achieves RMSE of 36.65 ± 1.47
- SHAP identifies flooring material, education, age, sleep quality, and social engagement as top predictors
- Flooring material shows Cramér's V ≥ 0.5 association with urban residence (0.76) and insurance coverage (0.75)
- Framework outperforms Random Forest and Decision Tree alternatives
- Age-stratified analysis reveals varying feature importance across age groups

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SVD-based matrix completion recovers missing SDOH values by exploiting latent correlations across demographic, socioeconomic, and health features.
- Mechanism: Iterative hard-thresholded SVD decomposes the incomplete data matrix, retains singular values above cross-validated threshold λ*, reconstructs, and updates missing entries until convergence. Continuous and categorical variables are processed separately to respect their distinct structures.
- Core assumption: The data matrix has low-rank structure—features share underlying latent factors (e.g., SES clusters) that allow reconstruction from partial observations.
- Evidence anchors:
  - [abstract] "This approach leverages latent feature correlations to recover missing values while balancing reliability and scalability."
  - [section 3.1] "This approach exploits latent correlations among features to recover incomplete values and provides a balance between statistical robustness and computational efficiency."
  - [corpus] Limited direct corpus evidence on SVD imputation for SDOH; neighboring papers focus on SDOH extraction (LLM-based) rather than imputation methods.
- Break condition: If the true data matrix is high-rank (weak inter-feature correlations) or missingness is non-random in ways unrelated to observed features, low-rank assumption fails and imputation quality degrades.

### Mechanism 2
- Claim: XGBoost outperforms alternative models on heterogeneous, imputed SDOH tabular data due to built-in regularization, sparsity handling, and non-linear interaction capture.
- Mechanism: Gradient-boosted decision trees sequentially fit residuals, with L1/L2 penalties controlling complexity, shrinkage reducing overfitting, and automatic sparsity-aware split directions handling imputed uncertainty.
- Core assumption: Cognitive scores have non-linear, interactive relationships with SDOH features; tree ensembles generalize better than deep networks on moderate sample sizes (~3000 records) with mixed feature types.
- Evidence anchors:
  - [abstract] "After evaluating multiple methods, XGBoost was chosen for its superior predictive performance."
  - [section 3.2] "Gradient-boosted decision trees have been shown to perform exceptionally well on tabular data, especially when variables are heterogeneous and nonlinearly related to the outcomes."
  - [corpus] Related ADRD/SDOH prediction paper exists but uses different ML approaches; limited direct algorithmic comparison available.
- Break condition: If feature-outcome relationships are predominantly linear, or if dataset scales to millions of records with complex text/image inputs, simpler linear models or deep architectures may become competitive.

### Mechanism 3
- Claim: SHAP-based post-hoc analysis identifies flooring material and other SDOH features as key predictors, with flooring serving as a compact proxy for structural socioeconomic and environmental inequities.
- Mechanism: SHAP computes each feature's marginal contribution across all possible feature coalitions, aggregating to global importance rankings and enabling age-stratified interpretation.
- Core assumption: High SHAP importance reflects meaningful associations; flooring material correlates with SES, healthcare access, and environmental exposure through latent structural factors.
- Evidence anchors:
  - [abstract] "SHAP analysis identifies key predictors including education, age, sleep quality, social engagement, and flooring material, which serves as a proxy for socioeconomic and environmental inequities."
  - [section 5.2] "The combined findings indicate that flooring material is a concise indicator for underlying factors like poverty, healthcare access, living conditions, and SES... Cramér's V results show strong associations (V ≥ 0.5) between flooring material and urban residence (0.76), insurance coverage (0.75), household income."
  - [corpus] Neighboring papers address SDOH extraction/prediction but not SHAP interpretability mechanisms specifically.
- Break condition: If features are highly collinear (e.g., flooring and income), SHAP distributes importance unstably; associations are correlational, not causal—policy claims require additional validation.

## Foundational Learning

- Concept: Low-Rank Matrix Completion via SVD
  - Why needed here: Understanding how missing SDOH survey data is recovered without simple mean/mode imputation that would distort feature distributions.
  - Quick check question: If you increase the hard threshold λ*, what happens to the rank of the reconstructed matrix and the risk of overfitting to noise?

- Concept: Gradient Boosting with Regularization
  - Why needed here: XGBoost is selected over neural networks; understanding why boosting handles imputation noise and heterogeneous features better is critical for architectural decisions.
  - Quick check question: How does column subsampling in XGBoost specifically help when some features contain imputed values with higher uncertainty?

- Concept: SHAP Values for Feature Attribution
  - Why needed here: The paper's interpretability claims rest on SHAP; understanding its properties is essential for validating that flooring material's importance is not an artifact.
  - Quick check question: If two features are perfectly correlated (e.g., flooring quality and household income), how would SHAP distribute importance between them, and what does this imply for interpretation?

## Architecture Onboarding

- Component map:
  1. Preprocessing (separate continuous/categorical, one-hot encode, z-score normalize)
  2. SVD Imputation (iterative hard-thresholded SVD, cross-validated λ*)
  3. Feature Engineering (add time-interval, retain age_12)
  4. XGBoost Regressor (10-fold CV, RMSE evaluation)
  5. SHAP Interpretation (global importance, age-stratified analysis)

- Critical path: Data preprocessing → SVD imputation quality → XGBoost training → SHAP interpretation. Paper shows SVD imputation provides larger gains for models without native missing-value handling (Random Forest, Decision Tree) than for XGBoost (which has sparsity-aware splits).

- Design tradeoffs:
  - SVD imputation vs. median/mode: SVD adds ~O(n³) computational cost but preserves latent structure; simpler imputation works nearly as well for XGBoost.
  - XGBoost vs. deep learning: XGBoost chosen for interpretability + tabular performance on moderate N; deep learning may scale better for larger, more complex data.
  - Cross-validated λ vs. fixed threshold: Data-driven but computationally expensive; fixed heuristics faster but may under/over-smooth.

- Failure signatures:
  - High RMSE variance across folds (e.g., <49 age group: 44.5 ± 11.03) → data heterogeneity or weak feature-outcome signal in subgroup.
  - Imputation non-convergence → threshold λ too aggressive or data rank too high; relax tolerance or increase max iterations.
  - SHAP importance dominated by single feature → check for data leakage or extreme collinearity.

- First 3 experiments:
  1. **Baseline replication**: Implement median/mode imputation + XGBoost; verify RMSE near 36.65 to confirm environment correctness.
  2. **Ablate imputation method**: Compare SVD vs. median/mode across all tested algorithms (as in Figure 2); quantify imputation contribution per model type.
  3. **Age-stratified SHAP replication**: Train separate models or filter SHAP values for one age cohort (e.g., 60–69); verify whether top features match Table 2 rankings.

## Open Questions the Paper Calls Out
None

## Limitations
- SVD imputation assumes low-rank data structure; if latent correlations among SDOH features are weak, imputation quality may degrade, affecting downstream predictions.
- SHAP interpretability relies on correlation-based associations; identified predictors (e.g., flooring material) may be proxies rather than causal drivers of cognitive outcomes.
- Performance gains from SVD imputation are most pronounced for models without native missing-value handling; XGBoost's built-in sparsity support reduces imputation impact.

## Confidence
- **High confidence**: XGBoost achieves RMSE of 36.65 via 10-fold CV; SVD imputation methodology is clearly described and reproducible.
- **Medium confidence**: SHAP-identified features reflect meaningful associations, though causality requires further validation; flooring material's role as SES proxy is supported by Cramér's V statistics but not experimentally confirmed.
- **Low confidence**: Claims about SDOH interpretability across all age groups lack individual age-stratified model comparisons; no ablation study isolating SVD vs. median imputation impact.

## Next Checks
1. Conduct ablation study comparing SVD imputation to median/mode imputation across all tested models to quantify imputation contribution.
2. Train and evaluate separate XGBoost models for each age group to validate SHAP interpretability claims and identify cohort-specific feature importance shifts.
3. Perform causality validation using quasi-experimental designs or instrumental variables to test whether identified SDOH features directly influence cognitive outcomes versus serving as proxies.