---
ver: rpa2
title: 'From BERT to Qwen: Hate Detection across architectures'
arxiv_id: '2507.10468'
source_url: https://arxiv.org/abs/2507.10468
tags:
- hate
- gemma
- speech
- bert
- qwen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks encoder-only (DistilBERT, Twitter-RoBERTa)
  and lightweight decoder-only (Qwen-1.5, Gemma-3) transformer models for hate-speech
  detection on a balanced, real-world corpus of 100k English sentences. Models were
  evaluated under zero-shot, few-shot, and fine-tuned regimes using identical train/validation
  splits.
---

# From BERT to Qwen: Hate Detection across architectures

## Quick Facts
- **arXiv ID**: 2507.10468
- **Source URL**: https://arxiv.org/abs/2507.10468
- **Reference count**: 18
- **Key outcome**: Fine-tuned Qwen-1.5 achieved highest accuracy and F1 scores, slightly surpassing encoder baselines in hate-speech detection

## Executive Summary
This study benchmarks encoder-only (DistilBERT, Twitter-RoBERTa) and lightweight decoder-only (Qwen-1.5, Gemma-3) transformer models for hate-speech detection. Models were evaluated under zero-shot, few-shot, and fine-tuned regimes using identical train/validation splits on a balanced, real-world corpus of 100k English sentences. The results show that compact decoder-only LLMs can match or exceed encoder-only transformers when given task-specific fine-tuning, and that minimal in-context examples substantially improve zero-shot performance.

## Method Summary
The study evaluates transformer models for hate-speech detection using a balanced, real-world corpus of 100k English sentences. Four models were tested: DistilBERT and Twitter-RoBERTa (encoder-only) and Qwen-1.5 and Gemma-3 (lightweight decoder-only). All models underwent evaluation under three regimes: zero-shot, few-shot prompting, and fine-tuning. The fine-tuning approach used identical train/validation splits across all models to ensure fair comparison. Few-shot prompting specifically boosted Gemma-3 performance by over 0.15-0.20 F1 score improvement.

## Key Results
- Fine-tuned Qwen-1.5 achieved the highest overall accuracy and F1 scores
- Few-shot prompting improved Gemma-3 performance by over 0.15-0.20 F1
- Encoder-only models (DistilBERT, RoBERTa) exceeded 0.80 F1 on each class

## Why This Works (Mechanism)
Decoder-only architectures like Qwen-1.5 and Gemma-3 leverage in-context learning capabilities that allow them to adapt to specific tasks through prompt engineering, even without parameter updates. The lightweight design of these models maintains sufficient capacity for complex semantic understanding while being computationally efficient. Fine-tuning these architectures on hate-speech detection tasks enables them to develop specialized attention patterns for identifying harmful content, while their autoregressive nature allows for better handling of sequential dependencies in text.

## Foundational Learning
- **Transformer Architecture**: Why needed - Provides the foundation for both encoder and decoder models; Quick check - Understand attention mechanisms and positional encoding
- **Fine-tuning vs Zero-shot**: Why needed - Different training approaches yield different performance characteristics; Quick check - Know when to use each approach
- **In-context Learning**: Why needed - Critical for few-shot performance improvements; Quick check - Understand how examples in prompts affect model behavior
- **Hate Speech Classification**: Why needed - Domain-specific knowledge for proper evaluation; Quick check - Understand class imbalance and evaluation metrics
- **Model Efficiency**: Why needed - Lightweight models must balance performance and computational cost; Quick check - Know typical parameter counts and inference times

## Architecture Onboarding

**Component Map**: Data -> Preprocessing -> Model Architecture -> Training/Fine-tuning -> Evaluation -> Performance Metrics

**Critical Path**: Data preparation and preprocessing → Model selection and configuration → Training/fine-tuning → Evaluation on held-out test set → Performance analysis

**Design Tradeoffs**: Encoder-only models offer stable performance with less sensitivity to prompt formatting but lack in-context learning capabilities. Decoder-only models provide flexibility through few-shot learning but may require more careful prompt engineering and can be more computationally intensive during inference.

**Failure Signatures**: Overfitting to training data (poor generalization), sensitivity to prompt formatting in few-shot settings, class imbalance issues leading to biased predictions, and reduced performance on out-of-domain hate speech examples.

**First Experiments**:
1. Replicate baseline performance on the original dataset with identical splits
2. Test few-shot performance with varying numbers of examples (1, 3, 5, 10)
3. Evaluate cross-dataset generalization by testing on an external hate speech corpus

## Open Questions the Paper Calls Out
None

## Limitations
- Single-dataset scope limits generalizability to other hate speech contexts
- Absence of cross-domain robustness testing for different platform-specific language patterns
- Limited evaluation to English language only, excluding multilingual hate speech scenarios

## Confidence
- **Model and Architecture Uncertainty**: Medium - Only one lightweight decoder variant per architecture type tested
- **Dataset and Generalization Constraints**: Medium - Single corpus limits external validity
- **Prompt Engineering Impact**: Medium - No sensitivity analysis to prompt variations

## Next Checks
1. Test the same models on at least two additional hate speech detection datasets from different platforms (e.g., Gab, Reddit) to assess cross-domain robustness.
2. Evaluate performance across multilingual hate speech datasets to determine if decoder-only advantages persist beyond English.
3. Conduct systematic ablation studies on few-shot prompt formats and example counts to establish the reliability and reproducibility of in-context learning improvements.