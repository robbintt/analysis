---
ver: rpa2
title: Stackelberg Game Based Performance Optimization in Digital Twin Assisted Federated
  Learning over NOMA Networks
arxiv_id: '2501.01584'
source_url: https://arxiv.org/abs/2501.01584
tags:
- client
- clients
- server
- problem
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of straggler clients and malicious
  attacks in federated learning (FL) systems by leveraging digital twin (DT) technology
  and non-orthogonal multiple access (NOMA) networks. The authors propose a reputation-based
  client selection scheme that considers accuracy contribution, model staleness, and
  positive interactions to mitigate poisoning attacks.
---

# Stackelberg Game Based Performance Optimization in Digital Twin Assisted Federated Learning over NOMA Networks

## Quick Facts
- arXiv ID: 2501.01584
- Source URL: https://arxiv.org/abs/2501.01584
- Reference count: 40
- The paper proposes a reputation-based client selection scheme with DT assistance and Stackelberg game optimization to improve FL performance over NOMA networks.

## Executive Summary
This paper addresses the twin challenges of straggler clients and malicious poisoning attacks in federated learning by integrating digital twin technology with NOMA networks. The authors propose a reputation-based client selection scheme that evaluates clients using accuracy contribution, model staleness, and positive interaction detection to mitigate poisoning risks. A Stackelberg game framework is formulated where clients (leader) optimize their resource allocation to minimize energy consumption, while the server (follower) allocates frequency coefficients to minimize latency. The equilibrium solution is obtained through backward induction and the Dinkelbach algorithm, with simulations demonstrating superior performance over benchmark methods even under poisoning attacks and DT deviations.

## Method Summary
The method combines reputation-based client selection with DT-assisted training and Stackelberg game optimization. Clients are selected based on a composite reputation score incorporating accuracy contribution (via Weibull model), model staleness (rounds since last selection), and positive interactions (RONI-based detection). Each selected client maps a portion of its data to a DT model at the server while training locally on the remainder. A Stackelberg game is formulated with clients as leader optimizing mapping ratio, CPU frequency, and transmit power to minimize energy, and the server as follower optimizing frequency coefficients to minimize latency. The equilibrium is found via backward induction: first solving the follower's frequency allocation problem (Theorem 1), then decomposing the leader's problem into subproblems solved using Dinkelbach algorithm for power optimization.

## Key Results
- The reputation-based selection scheme effectively mitigates poisoning attacks, maintaining higher accuracy than benchmarks even with 30-50% malicious clients.
- DT-assisted training reduces straggler impact, with graceful accuracy degradation as DT deviation increases.
- The Stackelberg equilibrium solution achieves the lowest total cost (latency + weighted energy) compared to random selection, OMA, and schemes without DT assistance.
- Total cost decreases with higher bandwidth and lower maximum latency constraints, with diminishing returns observed at higher values.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reputation-based client selection mitigates poisoning attacks while balancing client heterogeneity
- Mechanism: The scheme evaluates clients using three weighted factors before aggregation: (1) Accuracy Contribution (AC) via a Weibull model relating data quantity to accuracy gains; (2) Model Staleness (MS), tracking rounds since last selection; (3) Positive Interactions (PI), using RONI-based detection to count beneficial vs. harmful updates. Clients are ranked by composite reputation score $Z_n = \xi_1 AC_n + \xi_2 MS_n + \xi_3 PI_n$, and top-N are selected.
- Core assumption: Malicious clients exhibit detectable patterns in model update quality that differ from honest clients' contributions; the RONI threshold correctly separates PI from NI.
- Evidence anchors:
  - [abstract] "A reputationbased client selection scheme is proposed, which accounts for client heterogeneity in multiple aspects and effectively mitigates the risks of poisoning attacks in FL systems."
  - [Section III] Defines AC via Weibull model (Eq. 12), MS via age-of-update (Eq. 13-14), PI via RONI detection (Eq. 15), combined in Eq. 16.
  - [corpus] Related work "Incentive-Compatible Federated Learning with Stackelberg Game Modeling" addresses incentive mechanisms in FL but does not focus on poisoning mitigation via multi-criteria reputation.
- Break condition: If attackers can craft model updates that pass RONI detection while still degrading global accuracy, PI scores become unreliable; if data quantity correlates poorly with accuracy contribution for specific datasets, AC weights misrank clients.

### Mechanism 2
- Claim: Digital Twin (DT) mapping reduces straggler impact by offloading partial training to the server
- Mechanism: Each client $n$ maps a portion $v_n \in [0, v_n^{max}]$ of its insensitive data to a DT model $\text{DT}_n = \{w_n, \hat{D}_n\}$ at the server. The server trains on $\hat{D}_n = v_n D_n + \epsilon$ (where $\epsilon$ captures DT deviation) while the client trains locally on $(1-v_n)D_n$. The global model aggregates both contributions (Eq. 3), allowing resource-constrained clients to contribute via DT assistance.
- Core assumption: Insensitive data mapped to DT is sufficiently representative of client data distribution; DT deviation $\epsilon$ remains bounded and does not catastrophically distort gradients.
- Evidence anchors:
  - [abstract] "By effectively imitating the distributed resources, digital twin (DT) shows great potential in alleviating this issue [straggler problem]."
  - [Section II-A] Eq. 3 shows aggregation combining local and DT-trained parameters; convergence argument follows gradient descent property with factor $\Gamma = 1 + \epsilon N/D$.
  - [corpus] "Energy-Efficient Federated Learning and Migration in Digital Twin Edge Networks" explores DT-enabled FL but emphasizes migration and long-term maintenance, not poisoning-resilient selection.
- Break condition: If DT deviation $\epsilon$ grows large (e.g., non-stationary client data distributions), convergence guarantee weakens; if $v_n^{max}$ is too small due to privacy constraints, DT offloading provides minimal straggler relief.

### Mechanism 3
- Claim: Stackelberg game formulation jointly optimizes client energy and server latency through equilibrium solutions
- Mechanism: Clients (leader) first choose mapping ratio $v_n$, CPU frequency $f_n$, and transmit power $p_n$ to minimize energy $E = \sum_n (\kappa c_n (1-v_n) D_n f_n^2 + p_n t_n^{com})$. The server (follower) observes these and allocates frequency coefficients $\alpha_n$ (with $\sum \alpha_n \leq 1$) to minimize latency $T = \max\{t_n^{cmp} + t_n^{com}, t_n^S\}$. Equilibrium is found via backward induction: solve follower (Theorem 1 gives $\alpha_n^*$ in closed form), then leader via decomposition and Dinkelbach algorithm for power.
- Core assumption: Clients can predict server's best response; NOMA decoding order follows channel gain ranking ($|h_1|^2 \geq |h_2|^2 \geq ...$); SIC at server is error-free.
- Evidence anchors:
  - [abstract] "We then formulate a Stackelberg game by considering clients and the server as the leader and the follower, respectively... The Stackelberg equilibrium is achieved to obtain the optimal solutions."
  - [Section V] Theorem 1 derives follower strategy; leader problem decomposed into three subproblems (v, f, p); Algorithm 1 uses Dinkelbach for power optimization.
  - [corpus] Corpus evidence for Stackelberg in FL is present but does not directly validate NOMA-specific equilibrium derivations; "Incentive-Compatible Federated Learning with Stackelberg Game Modeling" uses Stackelberg for incentives, not latency-energy tradeoffs.
- Break condition: If clients cannot accurately predict server response (e.g., dynamic $\alpha$ constraints), equilibrium solutions become suboptimal; if NOMA SIC fails or decoding order changes mid-round, rate equations (Eq. 9) become invalid.

## Foundational Learning

### Concept: Federated Learning (FL) basicsâ€”local training, gradient/weight aggregation, synchronous vs. asynchronous updates
- Why needed here: The entire system builds on FL; understanding local loss (Eq. 1), SGD update (Eq. 2), and aggregation (Eq. 3) is prerequisite.
- Quick check question: Given $N$ clients with datasets $D_n$, write the global aggregation formula if all clients participate equally.

### Concept: Non-Orthogonal Multiple Access (NOMA) and Successive Interference Cancellation (SIC)
- Why needed here: NOMA enables simultaneous uplink transmission; understanding superposition coding (Eq. 8) and achievable rate (Eq. 9) is essential for latency/energy analysis.
- Quick check question: In uplink NOMA with 3 clients where $|h_1|^2 > |h_2|^2 > |h_3|^2$, which client's signal is decoded first and which experiences the most interference?

### Concept: Stackelberg Game fundamentals (leader-follower, backward induction, equilibrium)
- Why needed here: The optimization problem is formulated as a Stackelberg game; grasping leader/follower roles and equilibrium conditions (Eq. 21) is necessary.
- Quick check question: In a Stackelberg game, does the leader or follower move first, and whose best response is solved first in analysis?

## Architecture Onboarding

### Component map:
- **Edge Server** -> **Global Aggregation** -> **Frequency Coefficient Allocation** -> **DT Network**
- **Clients** -> **Local Training** -> **NOMA Transmission** -> **Reputation Evaluation**
- **DT Network** -> **DT Model Training** -> **Global Aggregation**

### Critical path:
1. Server broadcasts global model $w_{t-1}$.
2. Reputation module computes $Z_n$ for all clients; top-$N$ selected.
3. Selected clients compute optimal $v_n^*, f_n^*, p_n^*$ (leader strategy).
4. Clients train locally on $(1-v_n)D_n$; DT network trains on $\hat{D}_n$ in parallel.
5. Clients transmit local parameters via NOMA uplink.
6. Server performs SIC, aggregates local + DT parameters into $w_t$.
7. Server computes optimal $\alpha_n^*$ (follower strategy) for next round DT allocation.
8. Repeat until convergence.

### Design tradeoffs:
- **DT mapping ratio $v_n$**: Higher $v_n$ reduces client compute load but increases dependency on DT accuracy and deviation $\epsilon$.
- **Reputation weights ($\xi_1, \xi_2, \xi_3$)**: Emphasizing PI improves robustness but may exclude clients with stale but honest data; emphasizing MS improves fairness but risks including low-accuracy contributors.
- **Number of selected clients $N$**: Larger $N$ improves data diversity but increases NOMA interference and total latency.
- **Channel bandwidth $B$**: More bandwidth reduces transmission time but is resource-costly; diminishing returns observed in Fig. 9(c).

### Failure signatures:
- **Poisoning attack detection failure**: Sudden global accuracy drop with high-PI clients; check if RONI threshold is too permissive.
- **Straggler persistence**: Certain clients consistently miss deadline $T^{max}$; check if $v_n^{max}$ is too low or $f_n^{min}$ insufficient.
- **DT deviation explosion**: Global model diverges despite convergence conditions; inspect $\epsilon$ growth or non-stationary data distribution.
- **NOMA SIC failure**: Unexpectedly low rates $R_n$; verify channel gain ordering assumption and interference cancellation.

### First 3 experiments:
1. **Baseline reputation ablation**: Run FL with 30% poisoners; compare proposed scheme (AC+MS+PI) vs. benchmark (AC+MS only) on MNIST/CIFAR-10 IID. Measure accuracy over rounds; expect proposed to maintain higher accuracy (Fig. 5).
2. **DT deviation sensitivity**: Fix all parameters; vary $\epsilon \in \{0.2, 0.4, 0.6\}$; plot accuracy convergence on CIFAR-10. Expect graceful degradation but noticeable drop at high $\epsilon$ (Fig. 6).
3. **Total cost vs. model size**: Measure total cost (latency + weighted energy) across $d_n \in [1, 5]$ Mbit for proposed, random, OMA, and W/O DT schemes. Expect proposed to achieve lowest cost, with gap widening as $d_n$ increases (Fig. 9(a)).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does joint optimization of the NOMA decoding order impact the Stackelberg equilibrium compared to the fixed channel gain-based order assumption?
- Basis in paper: [explicit] The paper states "the design of decoding order is complicated and beyond the scope of this research," assuming the order aligns strictly with descending channel gains.
- Why unresolved: The fixed decoding order simplifies the interference analysis but may yield suboptimal latency and energy outcomes compared to a dynamic ordering strategy.
- What evidence would resolve it: A convergence analysis and simulation comparing the proposed fixed-order scheme against a joint optimization algorithm that dynamically adjusts the decoding order.

### Open Question 2
- Question: Can the reputation-based client selection scheme maintain robustness when using more advanced attack detection algorithms instead of the classical RONI method?
- Basis in paper: [explicit] The authors note "the design of attack detection algorithm is beyond the scope of this paper," relying instead on the Reject on Negative Influence (RONI) scheme.
- Why unresolved: RONI may fail to detect sophisticated or stealthy poisoning attacks, potentially skewing the "Positive Interactions" metric and degrading model accuracy.
- What evidence would resolve it: Simulations evaluating the FL accuracy and convergence rate under adaptive adversarial attacks using RONI versus deep learning-based detection methods.

### Open Question 3
- Question: What is the optimal number of selected clients ($N$) that balances NOMA spectral efficiency against the computational latency of Successive Interference Cancellation (SIC) at the server?
- Basis in paper: [inferred] The paper notes that "due to the complexity of SIC in NOMA, the appropriate number of selected clients $N$ should be carefully considered," yet fixed $N=5$ for simulations.
- Why unresolved: While increasing $N$ improves data diversity, the processing time for SIC increases, potentially negating the latency minimization goals of the server (follower).
- What evidence would resolve it: An analytical model quantifying the trade-off between the number of superimposed signals and the server's processing time budget.

## Limitations
- The NOMA decoding order assumption may not hold in realistic fading scenarios without explicit power control mechanisms.
- The DT deviation parameter $\epsilon$ is assumed bounded but not empirically validated across real non-IID data distributions.
- The reputation mechanism relies on RONI detection, which may fail against sophisticated poisoning attacks.

## Confidence
- Reputation-based client selection: **High** - Three-factor weighting scheme is explicitly defined and simulation results demonstrate effectiveness against poisoning attacks.
- DT mapping for straggler mitigation: **Medium** - Theoretical convergence proof exists but real-world DT deviation bounds are unverified.
- Stackelberg equilibrium solution: **Medium** - Mathematical derivation is sound but practical observability assumptions may limit real-world applicability.

## Next Checks
1. **Robustness testing:** Implement the same attack scenarios with more sophisticated poisoning methods (e.g., model replacement attacks) to evaluate whether the reputation mechanism remains effective.
2. **DT deviation validation:** Measure actual DT deviation $\epsilon$ when mapping from non-IID client datasets and verify if convergence guarantees hold under realistic data drift conditions.
3. **NOMA channel validation:** Simulate Rayleigh fading channels with imperfect channel state information to test whether the assumed decoding order and rate equations remain valid.