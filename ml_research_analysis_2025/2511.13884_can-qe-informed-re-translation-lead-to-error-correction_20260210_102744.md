---
ver: rpa2
title: Can QE-informed (Re)Translation lead to Error Correction?
arxiv_id: '2511.13884'
source_url: https://arxiv.org/abs/2511.13884
tags:
- translation
- quality
- comet
- original
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper investigates whether QE-informed retranslation can improve
  machine translation quality by reducing errors. Two approaches are proposed: (1)
  selecting the best translation from multiple LLM candidates using QE scores, and
  (2) prompting an LLM to replace error segments identified by QE.'
---

# Can QE-informed (Re)Translation lead to Error Correction?

## Quick Facts
- arXiv ID: 2511.13884
- Source URL: https://arxiv.org/abs/2511.13884
- Reference count: 9
- Primary result: QE-based selection among diverse LLM translations improved COMET score by 0.0201, winning WMT 2025 task

## Executive Summary
This paper explores whether Quality Estimation (QE) can improve machine translation quality through retranslation. The authors propose two approaches: selecting the best translation from multiple LLM candidates using QE scores, and prompting an LLM to replace error segments identified by QE. The first approach achieved a Delta COMET score of 0.0201, outperforming the second approach (-0.0108) and winning the WMT 2025 task. Results show that QE-based selection among diverse LLM translations can improve quality, especially for low-resource languages, while targeted error replacement via masking was less effective due to model limitations and prompt engineering issues.

## Method Summary
The study investigates QE-informed retranslation through two distinct approaches. The first approach generates multiple candidate translations from an LLM, then uses QE scores to select the highest-quality output. The second approach identifies error segments through QE and prompts an LLM to replace only those problematic portions. The experiments were conducted on low-resource language pairs, with performance measured using COMET scores. The methodology leverages the complementary strengths of QE for error detection and LLM capabilities for translation generation.

## Key Results
- QE-based selection approach achieved Delta COMET score of 0.0201
- Error replacement approach performed worse with Delta COMET score of -0.0108
- Selection approach won WMT 2025 task for low-resource language pairs
- QE-informed selection is more effective than targeted error replacement

## Why This Works (Mechanism)
The QE-informed selection approach works by leveraging diversity among multiple LLM-generated translations. When an LLM produces several candidate translations for the same source text, these candidates often exhibit different strengths and weaknesses. QE models can identify which candidate has the fewest errors or highest overall quality without requiring reference translations. This is particularly effective for low-resource languages where reference data is scarce, and QE models trained on higher-resource languages can still provide useful quality signals. The selection mechanism essentially amplifies the probability of choosing a translation that benefits from the LLM's best performance on that particular input.

## Foundational Learning
- **Quality Estimation (QE)**: Automated assessment of translation quality without reference translations; needed for identifying translation errors without human intervention; quick check: validate QE model accuracy on held-out data
- **Delta COMET scoring**: Metric measuring improvement over baseline translations; needed to quantify quality gains from QE-informed approaches; quick check: compare against human evaluation for correlation
- **LLM candidate generation**: Producing multiple translation variants from a single source; needed to create diversity for QE-based selection; quick check: measure lexical and semantic diversity across candidates
- **Error masking and replacement**: Identifying and substituting problematic translation segments; needed for targeted correction approach; quick check: evaluate whether replacements maintain coherence with surrounding text

## Architecture Onboarding

**Component Map**
LLM (multiple candidates) -> QE model -> Selection/Replacement module -> Final translation

**Critical Path**
Source text → LLM generation (multiple outputs) → QE scoring → Best candidate selection → Final output

**Design Tradeoffs**
The selection approach trades computational cost (generating multiple candidates) for quality improvement, while the replacement approach attempts efficiency but suffers from coherence issues when modifying only segments.

**Failure Signatures**
The error replacement approach fails when QE-identified segments are context-dependent, when LLM replacements introduce new errors, or when prompt engineering cannot maintain translation coherence during segment substitution.

**3 First Experiments**
1. Generate 5 LLM candidates per source and compare QE score variance to assess diversity quality
2. Test QE model performance on low-resource languages to establish baseline accuracy
3. Evaluate whether increasing candidate count beyond 5 improves selection quality gains

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several emerge from the experimental results. Why did the error replacement approach perform worse than selection despite being more targeted? What is the optimal number of candidates to generate for balancing quality gains against computational cost? How well does the QE-informed selection approach generalize to higher-resource language pairs and different domains? What specific types of translation errors are most effectively corrected through selection versus replacement?

## Limitations
- Limited to COMET scores without human evaluation to validate quality improvements
- Modest Delta COMET improvement of 0.0201 may not yield perceptible practical gains
- Error replacement approach's poor performance not thoroughly investigated for root causes
- WMT 2025 task win may not generalize across different language pairs and domains
- Computational overhead of generating multiple candidates for each source text
- Potential bias in QE models when applied to low-resource language pairs

## Confidence

**High Confidence**: Comparative results between selection and replacement approaches are reliable given controlled experimental setup and consistent metric reporting.

**Medium Confidence**: QE-based selection among diverse LLM translations improves quality, but needs validation across more language pairs and domains.

**Low Confidence**: Practical significance of observed improvements and generalizability of WMT 2025 results to broader MT applications remain uncertain.

## Next Checks

1. Conduct human evaluation studies across multiple language pairs to verify whether automatic metric improvements correlate with actual quality gains perceived by human translators.

2. Systematically analyze which specific error types identified by QE are most effectively corrected through the selection approach versus which types remain problematic, particularly for low-resource languages.

3. Test the QE-informed selection methodology on additional domains beyond the WMT corpus to assess robustness and identify potential limitations in domain transfer.