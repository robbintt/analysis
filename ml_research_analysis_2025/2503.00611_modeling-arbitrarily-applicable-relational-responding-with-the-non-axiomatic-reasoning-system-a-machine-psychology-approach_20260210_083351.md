---
ver: rpa2
title: 'Modeling Arbitrarily Applicable Relational Responding with the Non-Axiomatic
  Reasoning System: A Machine Psychology Approach'
arxiv_id: '2503.00611'
source_url: https://arxiv.org/abs/2503.00611
tags:
- relational
- nars
- sample
- relations
- same
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a theoretical demonstration of modeling Arbitrarily\
  \ Applicable Relational Responding (AARR) within the Non-Axiomatic Reasoning System\
  \ (NARS). By integrating Relational Frame Theory (RFT) with NARS's adaptive reasoning\
  \ mechanisms, the study shows how key properties of AARR\u2014mutual entailment,\
  \ combinatorial entailment, and transformation of stimulus functions\u2014can emerge\
  \ from NARS's inference rules and memory structures."
---

# Modeling Arbitrarily Applicable Relational Responding with the Non-Axiomatic Reasoning System: A Machine Psychology Approach

## Quick Facts
- **arXiv ID:** 2503.00611
- **Source URL:** https://arxiv.org/abs/2503.00611
- **Reference count:** 24
- **Primary result:** This paper presents a theoretical demonstration of modeling Arbitrarily Applicable Relational Responding (AARR) within the Non-Axiomatic Reasoning System (NARS), showing how key properties of AARR can emerge from NARS's inference rules and memory structures.

## Executive Summary
This paper presents a theoretical demonstration of modeling Arbitrarily Applicable Relational Responding (AARR) within the Non-Axiomatic Reasoning System (NARS). By integrating Relational Frame Theory (RFT) with NARS's adaptive reasoning mechanisms, the study shows how key properties of AARR—mutual entailment, combinatorial entailment, and transformation of stimulus functions—can emerge from NARS's inference rules and memory structures. Two theoretical experiments are presented: one modeling stimulus equivalence and transfer of function, and another modeling complex relational networks involving opposition frames. In both cases, NARS logically derives untrained relations and context-sensitive transformations of stimulus significance, mirroring established human cognitive phenomena. The results suggest that AARR, long considered uniquely human, can be conceptually captured by suitably designed AI systems, highlighting the value of integrating behavioral science insights into artificial general intelligence research.

## Method Summary
The study integrates Relational Frame Theory (RFT) with the Non-Axiomatic Reasoning System (NARS) through conceptual modeling rather than empirical implementation. Two theoretical experiments were constructed: Experiment 1 models stimulus equivalence and transfer of function using the "acquired relations" mechanism, while Experiment 2 models complex relational networks involving opposition frames. The research employs Narsese representations to encode relational structures and uses NARS's inference rules (mutual entailment, combinatorial entailment) to derive untrained relations. The methodology relies on symbolic representations and conceptual analysis rather than live system implementation, with experimental setups described but not executed in the OpenNARS for Applications (ONA) system.

## Key Results
- NARS successfully models stimulus equivalence and transfer of function through the "acquired relations" mechanism
- The system derives context-sensitive mutual entailment consistent with SAME and OPPOSITE relational frames
- Key properties of AARR—mutual entailment, combinatorial entailment, and transformation of stimulus functions—emerge from NARS's inference rules and memory structures

## Why This Works (Mechanism)

### Mechanism 1: Acquisition of Relations from Sensorimotor Contingencies
The system theoretically transforms procedural associations (action-outcome links) into declarative relational terms, allowing symbolic reasoning to emerge from embodied interaction. When NARS executes a successful operation based on a sensory contingency, a novel "acquired relation" is derived. Specifically, a contingency like `<(sample * X1) ... =/> G>` triggers the creation of a relational term `<(X1 * Y1) --> (property * property)>`. This term then serves as a premise for higher-order logical inference (mutual/combinatorial entailment). The paper assumes that relational terms can be validly represented as "products" of inheritance statements and that extracting these relations only during active execution prevents memory overflow. If the system executes operations via random babbling without structured feedback, the specific relational terms required for entailment will not form or will lack the confidence to drive inference.

### Mechanism 2: Functional Equivalence via Variable Substitution
The system generalizes specific sensorimotor experiences into abstract rules using variable substitution, enabling the transfer of stimulus functions (e.g., "clap" response) to novel stimuli within an equivalence class. NARS uses variable introduction to abstract specific contingency rules. For example, if `<(sample * B1) ... =/> G>` and `<(sample * C1) ... =/> G>` both hold, and a relation `<(B1 * C1) --> (equivalence)>` exists, the system can substitute terms. If C1 is presented, the system recognizes the abstract applicability of the B1 rule to the C1 context via the derived equivalence link. The inference engine can successfully unify variables across distinct temporal statements and relational statements to bridge the gap between "perception" and "action." If the "confidence" values of the derived relations decay too quickly or fail to exceed the threshold for rule formation, the system will treat novel stimuli as unrelated, failing the function transfer test.

### Mechanism 3: Contextual Control of Relational Networks
The architecture models complex frames (like "Opposite") by treating context cues (e.g., the word "OPPOSITE") as explicit terms in the relational structure, modifying how functions transform. Rather than hard-coding logic, the context is part of the Narsese statement. For opposition, the system learns distinct combinatorial rules (e.g., `OPPOSITE + OPPOSITE = SAME`). When a context cue is active, it primes specific inference chains that reverse the valence of a transferred function (e.g., "Good" becomes "Bad"). The system has undergone sufficient pre-training to have established the abstract implication rules for specific frames. If the context cue (e.g., `rel * OPPOSITE`) is not perceived or fails to activate the relevant abstract implication rules due to low priority, the system defaults to simple equivalence or fails to respond.

## Foundational Learning

- **Concept: Non-Axiomatic Logic (NAL) Truth Values**
  - **Why needed here:** Unlike standard logic, NARS uses (frequency, confidence) pairs. Understanding this is required to interpret why the system might derive a relation but fail to act on it if the evidence is weak.
  - **Quick check question:** Can you explain why a derived relation with frequency 1.0 but confidence 0.01 might not trigger a motor action?

- **Concept: Narsese Term Syntax (Product & Image)**
  - **Why needed here:** The "Acquired Relations" mechanism relies heavily on specific term structures like `<(A * B) --> (loc * loc)>`. Understanding how NARS parses these products is essential for debugging the relational extraction process.
  - **Quick check question:** How does the system represent the relation "Red is at the Left" using a product term?

- **Concept: Derived Relational Responding (RFT)**
  - **Why needed here:** The paper validates the system not on correctness, but on *derived* outcomes (e.g., symmetry). One must distinguish between a trained association (A->B) and a derived one (B->A) to evaluate the success of the experiment.
  - **Quick check question:** If the system is trained A->B and B->C, and then selects C given A, is this derived or trained?

## Architecture Onboarding

- **Component map:** Input (Perception: Location/Color/OCR) -> Event Buffers -> Concept Memory (Nodes for stimuli + "Acquired Relations" mechanism) -> NAL Engine (Syllogistic/Temporal rules + Variable Introduction) -> Motor Executive (select, clap, wave)

- **Critical path:**
  1. **Pretraining (Phase 1):** This is non-negotiable. The system must derive abstract rules (symmetry, transitivity) from basic examples before attempting the complex networks.
  2. **Network Training:** Execute matching-to-sample tasks to populate memory with specific conditional relations.
  3. **Function Attachment:** Pair specific stimuli with specific motor outputs (e.g., B1 -> Clap).
  4. **Derivation:** Allow the inference engine idle time to process "backward" inferences (if A=B and B acts, how does A act?).

- **Design tradeoffs:** The paper restricts "acquired relations" to moments of active motor execution to avoid a combinatorial explosion of terms. The paper currently presents "theoretical experiments" (conceptual proofs) rather than live robotic implementations, simplifying sensorimotor noise handling.

- **Failure signatures:**
  - **Cascading Silence:** If Phase 1 pretraining is insufficient, no abstract rules exist. Phase 2 training will result in isolated memories with no connectivity, leading to zero response in the testing phase.
  - **Wrong Frame Application:** If confidence decay is misconfigured, the system might apply an "Equivalence" rule to an "Opposite" context.

- **First 3 experiments:**
  1. **The "Acquired Relation" Unit Test:** Input a single successful matching event `(Sample=X1, Left=Y1) -> G`. Verify that the system explicitly creates the term `<(X1 * Y1) --> relation>` in memory.
  2. **Symmetry Verification:** Train X1 -> Y1. Present Y1 as sample and check if X1 is preferred over a distractor without explicit training.
  3. **Function Transfer (The "Clap" Test):** Train Network A-B-C. Train B -> Clap. Present C. Log output to verify "Clap" is executed.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the extended NARS framework effectively model complex relational frames beyond equivalence and opposition, such as comparative, hierarchical, and deictic relations?
- **Basis in paper:** Section 7.3 states an immediate direction is "expanding the relational frames modeled in NARS beyond equivalence and opposition, including comparative, hierarchical, and deictic relations."
- **Why unresolved:** The current study only theoretically demonstrates coordination (equivalence) and opposition frames; the logic for perspective-taking (deictic) or valuing (comparative) requires different entailment structures not yet tested.
- **What evidence would resolve it:** Successful theoretical or empirical derivation of untrained relations in NARS using Narsese representations for comparative (e.g., "more than") and deictic (e.g., "I-You") frames.

### Open Question 2
- **Question:** Does the "acquired relations" mechanism function as intended when implemented in the actual OpenNARS for Applications (ONA) system, rather than just as a conceptual analysis?
- **Basis in paper:** Section 5.1 explicitly states that "experimental setups were not implemented in the existing OpenNARS for Applications (ONA) system" but were "conceptual analyses employing symbolic representations."
- **Why unresolved:** The theoretical derivations assume ideal logical consistency, but NARS operates under the Assumption of Insufficient Knowledge and Resources (AIKR), meaning resource constraints in an actual implementation could prevent the derivation of stable relations.
- **What evidence would resolve it:** A demonstration where the ONA architecture, updated with the acquired relations mechanism, successfully completes the stimulus equivalence and opposition tasks in a real-time execution environment.

### Open Question 3
- **Question:** Can NARS integrate raw sensory data to "ground" these symbolic relations in a physical environment without relying on pre-processed symbolic inputs like OCR?
- **Basis in paper:** Section 7.3 identifies "integrating perceptual inputs with symbolic reasoning" as a crucial step, noting the need for NARS to "generate and reason about relations directly from sensory data in dynamic environments."
- **Why unresolved:** The experiments rely on abstract inputs (e.g., `<(sample * X1) --> (loc * ocr)>`), assuming a location sensor and OCR detector handle the perception, effectively bypassing the sensorimotor grounding problem.
- **What evidence would resolve it:** An experiment where the system forms equivalence classes based directly on visual feature vectors or sensorimotor contingencies rather than human-defined text labels.

## Limitations
- The theoretical nature of the experiments represents a significant limitation, as the paper demonstrates conceptual feasibility rather than empirical validation through actual system implementation.
- The acquired relations mechanism depends on precise confidence thresholds that could prevent functional transfer if misconfigured.
- The contextual control mechanism assumes pre-existing abstract rules for frames like "Opposite," but does not address how these rules themselves are acquired from sensorimotor experience.

## Confidence
- **High Confidence:** The integration of RFT properties with NARS's existing inference framework is conceptually coherent, and the basic mechanisms of relational extraction and variable substitution are well-grounded in NARS theory.
- **Medium Confidence:** The functional transfer mechanism through variable substitution is theoretically plausible but untested in implementation.
- **Low Confidence:** The scalability of the acquired relations mechanism to complex, real-world environments remains unproven.

## Next Checks
1. **Implementation Verification Test:** Build and run the acquired relations mechanism with a simple two-stimulus matching task, logging memory contents to verify that relational terms like `<(X1 * Y1) --> relation>` are correctly created and stored after successful execution.
2. **Function Transfer Empirical Test:** Implement the equivalence network (A-B-C) with function attachment (B -> Clap), then present stimulus C to empirically verify that the system executes the Clap action without explicit training on the C -> Clap relation.
3. **Context Frame Robustness Test:** Create a mixed context environment where SAME and OPPOSITE frames compete, presenting stimuli that could be interpreted under both frames to test whether the system correctly applies context cues to select appropriate inference rules.