---
ver: rpa2
title: 'Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems'
arxiv_id: '2512.13771'
source_url: https://arxiv.org/abs/2512.13771
tags:
- semantic
- context
- responses
- embedding
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Semantic Grounding Index (SGI), a geometric
  measure for detecting when retrieval-augmented generation (RAG) systems fail to
  engage with retrieved context, resulting in hallucination. SGI is defined as the
  ratio of angular distances from the response to the question versus the context
  on the unit hypersphere.
---

# Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems

## Quick Facts
- **arXiv ID:** 2512.13771
- **Source URL:** https://arxiv.org/abs/2512.13771
- **Reference count:** 4
- **Primary result:** SGI achieves large effect sizes (d=0.92-1.28) on HaluEval by detecting when responses stay angularly proximate to questions rather than departing toward retrieved context

## Executive Summary
This paper introduces the Semantic Grounding Index (SGI), a geometric measure for detecting when retrieval-augmented generation (RAG) systems fail to engage with retrieved context, resulting in hallucination. SGI is defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere. The key finding is "semantic laziness": hallucinated responses remain angularly proximate to questions rather than departing toward contexts. On the HaluEval benchmark (n=5,000), SGI achieves large effect sizes (Cohen's d from 0.92 to 1.28) across five embedding models with cross-model correlation r=0.85. The discriminative power increases with question-context angular separation, confirming theoretical predictions from the spherical triangle inequality (AUC improves from 0.72 to 0.83). SGI excels on long responses (d=2.05) and short questions (d=1.22), with calibration quality ECE=0.10, though it fails to detect factual inaccuracies in TruthfulQA (AUC=0.478), confirming it measures topical engagement rather than factual accuracy.

## Method Summary
SGI is computed as θ(r,q)/θ(r,c) where θ denotes angular distance on the unit hypersphere. The method requires L2-normalized embeddings using sentence-transformers, computing arccos of clipped dot products with ε=10^-8 added to the denominator. The approach was tested on HaluEval QA dataset (n=5,000 stratified samples) using five embedding models: all-mpnet-base-v2, all-MiniLM-L6-v2, bge-base-en-v1.5, e5-base-v2, and gte-base. Cross-model correlation was r=0.85, with MiniLM showing highest effect size (d=1.28). The method assumes retrieved context is relevant and measures topical engagement rather than factual accuracy.

## Key Results
- Large effect sizes on HaluEval: d=0.92-1.28 across five embedding models with cross-model correlation r=0.85
- Discriminative power increases with question-context angular separation: d=0.61→0.90→1.27 (low→medium→high terciles), AUC=0.72→0.83
- Excellent performance on long responses (d=2.05) and short questions (d=1.22), calibration ECE=0.10
- Fails on TruthfulQA (AUC=0.478), confirming SGI measures topical engagement not factual accuracy

## Why This Works (Mechanism)

### Mechanism 1: Semantic Laziness Pattern
Hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. When autoregressive models fail to integrate retrieved context, they default to "safe" completions within the question's semantic neighborhood rather than actively avoiding context. The effect is 3-4x stronger for question proximity (d=1.39-1.62) than context distance (d=0.38-0.45).

### Mechanism 2: Triangle Inequality Amplification
SGI discriminative power increases predictably with question-context angular separation θ(q,c). The spherical triangle inequality mathematically constrains SGI values near 1 when θ(q,c) is small; larger separation relaxes bounds, permitting greater separation between grounded and ungrounded responses. Effect size rises monotonically from d=0.61 (low θ(q,c)) to d=1.27 (high θ(q,c)).

### Mechanism 3: Topical Engagement Boundary
SGI measures whether responses engage with context topics, NOT whether responses are factually accurate. Angular distance on the hypersphere measures semantic topic similarity; true and false statements about the same topic occupy nearby geometric regions. This explains why SGI fails on TruthfulQA (AUC=0.478) - it cannot distinguish true from false statements about identical topics.

## Foundational Learning

- **Angular distance on unit hypersphere (S^{d-1})**: SGI is defined intrinsically on this manifold; cosine similarity does NOT satisfy triangle inequality, making angular distance (arccos of dot product) the correct metric. *Quick check:* Given two L2-normalized embeddings with dot product 0.5, what is their angular distance?

- **Spherical triangle inequality**: Provides theoretical bounds on SGI values and predicts when discrimination will be effective. *Quick check:* If θ(q,c)=0.5 radians, what approximate bounds does this place on SGI?

- **Contrastive learning objectives (alignment + uniformity)**: Explains why sentence embeddings are structured on the hypersphere in ways that make angular analysis meaningful. *Quick check:* Why do contrastive objectives produce embeddings where angular distance is semantically meaningful?

## Architecture Onboarding

- **Component map**: Embedding encoder -> L2 normalization -> Angular distance computation -> SGI ratio calculation
- **Critical path**: 1) Measure θ(q,c) first—this predicts expected discriminative power; 2) Encode question, context, response as separate strings without instruction prefixes; 3) L2 normalize all embeddings before distance computation; 4) Clip dot products to [-1, 1] before arccos to prevent domain violations
- **Design tradeoffs**: Embedding model choice (cross-model correlation r=0.85 suggests any validated model works); Threshold calibration (ECE=0.10 enables probability estimation but optimal thresholds are domain-specific); Response length sensitivity (long responses d=2.05 provide 2x signal of short responses d=0.95)
- **Failure signatures**: AUC hovering near 0.5 (likely high topic overlap between questions and contexts); High variance in SGI scores (check for very short responses or multi-clause questions); Valid responses flagged as hallucinations (verify retrieval quality—SGI assumes relevant context)
- **First 3 experiments**: 1) Characterize your domain: Compute θ(q,c) distribution on 500-1000 samples; if median < 0.9 radians, expect reduced effect sizes; 2) Calibrate thresholds on labeled data: Use min-max normalization to convert SGI to probabilities; validate ECE on held-out set; 3) Compare with NLI baseline: SGI detects disengagement; NLI detects contradiction. Measure correlation between signals—if low (orthogonal), combine for improved coverage

## Open Questions the Paper Calls Out

### Open Question 1
Does SGI correlate with internal model uncertainty measures such as attention entropy, hidden state variance, or logit dispersion? The semantic laziness hypothesis is proposed as reflecting "a default mode of autoregressive generation under uncertainty," but no causal link to internal model states was established. Correlation analysis between SGI scores and attention entropy/hidden state variance across layers on held-out RAG samples would resolve this.

### Open Question 2
Do production hallucinations in deployed RAG systems exhibit the same geometric signatures as adversarially-generated HaluEval hallucinations? HaluEval uses synthetic, deliberately fabricated answers; real-world model failures may follow different patterns. SGI evaluation on organically occurring hallucinations from production RAG logs with human-verified grounding labels would resolve this.

### Open Question 3
How does SGI perform when retrieved context is irrelevant or marginally relevant to the question? The theoretical framework assumes c provides a meaningful geometric anchor; retrieval failures may invalidate this assumption. Controlled experiments varying context relevance (e.g., BM25 score terciles) and measuring SGI discriminative power degradation would resolve this.

### Open Question 4
Can SGI be combined with NLI-based detection methods to improve overall hallucination detection performance? SGI detects semantic disengagement; NLI detects logical contradiction. The signals are orthogonal but complementarity is claimed but not empirically validated. Joint evaluation of SGI + SummaC/HALT-RAG ensembles on HaluEval, measuring AUC gains over individual methods would resolve this.

## Limitations
- SGI's discriminative power is constrained by geometric bounds that become trivial when question and context are semantically similar (low θ(q,c))
- SGI measures topical engagement rather than factual accuracy, failing to detect false but topically coherent responses (AUC=0.478 on TruthfulQA)
- The assumption that semantic laziness manifests uniformly across all RAG failure modes hasn't been validated across different types of hallucinations

## Confidence

- **High confidence**: The empirical effect sizes (d=0.92-1.28 on HaluEval) and cross-model correlation (r=0.85) are robust findings that should generalize to any RAG system using validated sentence embeddings
- **Medium confidence**: The geometric bounds from spherical trigonometry apply to the unit hypersphere, but real embedding spaces may deviate from perfect uniformity due to training artifacts
- **Low confidence**: The assumption that semantic laziness manifests uniformly across all RAG failure modes, as the paper focuses on generation failures but doesn't characterize retrieval failures or hybrid failure modes

## Next Checks

1. **Domain Transfer Validation**: Apply SGI to your specific RAG use case and compute the θ(q,c) distribution. If median angular separation < 0.9 radians, expect reduced effect sizes per the theoretical bound. This validates whether your domain's question-context similarity permits effective discrimination.

2. **Calibration Quality Assessment**: Implement min-max normalization to convert SGI to probability estimates, then compute Expected Calibration Error (ECE) on held-out data. The paper reports ECE=0.10, but this may vary significantly with domain and threshold choice. Poor calibration suggests the SGI distribution doesn't follow the assumed pattern in your data.

3. **Orthogonal Signal Detection**: Measure correlation between SGI scores and natural language inference (NLI) scores for the same samples. If correlation is low (orthogonal signals), combine both methods—SGI detects disengagement while NLI detects contradiction. This validates whether SGI captures unique failure modes not detectable by existing methods.