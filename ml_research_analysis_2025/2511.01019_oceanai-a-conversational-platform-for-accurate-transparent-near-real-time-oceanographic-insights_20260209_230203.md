---
ver: rpa2
title: 'OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time
  Oceanographic Insights'
arxiv_id: '2511.01019'
source_url: https://arxiv.org/abs/2511.01019
tags:
- data
- noaa
- level
- oceanai
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OceanAI addresses the problem of AI "hallucinations" in scientific
  domains by integrating large language models with real-time, parameterized access
  to authoritative NOAA oceanographic data. The system uses function calling to retrieve,
  process, and visualize structured datasets like sea level trends and SST, ensuring
  outputs are grounded, transparent, and reproducible.
---

# OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights

## Quick Facts
- arXiv ID: 2511.01019
- Source URL: https://arxiv.org/abs/2511.01019
- Reference count: 22
- Combines LLMs with NOAA oceanographic data through function calling for accurate, transparent insights

## Executive Summary
OceanAI addresses the problem of AI "hallucinations" in scientific domains by integrating large language models with real-time, parameterized access to authoritative NOAA oceanographic data. The system uses function calling to retrieve, process, and visualize structured datasets like sea level trends and SST, ensuring outputs are grounded, transparent, and reproducible. In blind comparisons, OceanAI consistently provided NOAA-sourced values with full metadata, while other models either declined to answer or gave unsupported results. This approach bridges the usability gap between conversational AI and expert-level data portals, enabling interdisciplinary access to ocean science with both transparency and technical rigor.

## Method Summary
OceanAI integrates large language models with NOAA oceanographic data through a function-calling architecture that retrieves, processes, and visualizes structured datasets in near-real-time. The system uses parameterized API calls to access NOAA's authoritative data sources, including sea level trends and sea surface temperature measurements. When users pose queries, the LLM determines when to invoke specific NOAA data functions, which return structured responses that the model incorporates into its answers. The architecture includes visualization components that generate charts and maps directly from retrieved data, maintaining full metadata attribution to the original NOAA sources. This approach ensures that all outputs are traceable to authoritative datasets while maintaining the conversational interface of modern LLMs.

## Key Results
- OceanAI provided NOAA-sourced values with full metadata in blind comparisons, while other models declined or gave unsupported results
- System successfully handles parameterized queries for sea level trends and SST with near-real-time data retrieval
- Maintains transparency through complete source attribution and reproducible methodology

## Why This Works (Mechanism)
The system works by using function calling to bridge the gap between conversational AI and authoritative scientific data sources. When a user poses a query, the LLM evaluates whether it needs to retrieve specific oceanographic data. If so, it calls pre-defined functions that interface with NOAA's APIs, passing parameters like location, time range, and data type. The NOAA functions return structured data that the LLM incorporates into its response, ensuring all claims are grounded in actual measurements. This approach prevents hallucinations by limiting the model to answering only what the data supports, while the visualization components provide immediate graphical context. The transparency is maintained through explicit source attribution and metadata preservation throughout the entire query-response chain.

## Foundational Learning

**Function Calling in LLMs**
Why needed: Enables LLMs to retrieve structured data from external APIs rather than relying solely on training knowledge
Quick check: Can the model correctly identify when to call NOAA functions vs. when to answer from its knowledge base?

**NOAA Oceanographic Data APIs**
Why needed: Provides authoritative, real-time data that grounds LLM responses in scientific accuracy
Quick check: Are the NOAA API endpoints properly parameterized and returning valid JSON structures?

**Metadata Attribution**
Why needed: Ensures reproducibility and scientific rigor by tracking data provenance
Quick check: Does every visualization and data point include complete source attribution?

**Near-Real-Time Data Processing**
Why needed: Maintains relevance by incorporating the most current oceanographic measurements
Quick check: Is the data latency between NOAA collection and OceanAI display within acceptable bounds?

**Data Visualization Integration**
Why needed: Transforms raw numerical data into interpretable scientific visualizations
Quick check: Do generated charts and maps accurately represent the underlying NOAA data?

## Architecture Onboarding

**Component Map**
User Query -> LLM Router -> NOAA Data Functions -> Data Processing -> Visualization Engine -> Response with Attribution

**Critical Path**
The critical execution path runs from user query through the LLM router, which determines if NOAA data functions need to be called. These functions retrieve and process data, which flows to the visualization engine before being incorporated into the final response. The path must maintain metadata attribution throughout to ensure transparency.

**Design Tradeoffs**
Synchronous function calling provides better accuracy and transparency but may face scalability challenges. The system prioritizes scientific rigor over conversational fluency, which may result in more structured responses. The choice to integrate directly with NOAA APIs ensures data authority but requires robust error handling for API downtime or rate limiting.

**Failure Signatures**
- LLM router fails to identify data needs: Responses lack necessary scientific context
- NOAA API timeouts: System should provide cached data with appropriate freshness warnings
- Visualization engine errors: Fall back to tabular data presentation with source attribution
- Metadata loss: Any missing source attribution indicates system integrity failure

**3 First Experiments**
1. Test with simple NOAA data queries (e.g., current SST at specific location) to verify function calling
2. Verify metadata attribution appears correctly in all response components
3. Test error handling by simulating NOAA API downtime

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on narrow test cases (sea level, SST) without broader oceanographic scope
- Comparison limited to single blind scenario without multi-model benchmarking
- Synchronous function calling may face scalability challenges under high query volumes
- Unproven ability to handle ambiguous or contradictory NOAA data sources

## Confidence

**High confidence:** The core technical contribution of integrating LLMs with parameterized NOAA data access through function calling is well-demonstrated and technically sound.

**Medium confidence:** The claim of improved transparency and reproducibility is supported by the source attribution mechanism, but requires broader testing across diverse query types and user expertise levels.

**Medium confidence:** The usability benefits for interdisciplinary researchers are plausible based on the design, but lack direct user study validation beyond the technical demonstration.

## Next Checks

1. Conduct systematic evaluation across all major NOAA oceanographic datasets (e.g., salinity, currents, dissolved oxygen) to assess generalizability beyond sea level and SST

2. Implement load testing with concurrent queries to evaluate performance scalability and response time consistency

3. Perform user studies with interdisciplinary researchers to quantify usability improvements and identify edge cases where the system may struggle