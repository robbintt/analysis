---
ver: rpa2
title: Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective
  Reasoning Distillation
arxiv_id: '2505.20014'
source_url: https://arxiv.org/abs/2505.20014
tags:
- mental
- detection
- rationales
- rationale
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether the quality of rationales impacts
  the performance of smaller language models (SLMs) in mental health detection. It
  addresses the problem of inconsistent rationale quality in reasoning distillation
  from large language models (LLMs) to SLMs, particularly in the context of mental
  health applications where clinical relevance is critical.
---

# Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective Reasoning Distillation

## Quick Facts
- arXiv ID: 2505.20014
- Source URL: https://arxiv.org/abs/2505.20014
- Reference count: 40
- Selective distillation of high-quality, clinically-relevant rationales significantly improves mental disorder detection accuracy and rationale quality in smaller language models

## Executive Summary
This paper addresses the challenge of inconsistent rationale quality when distilling reasoning ability from large language models (LLMs) to smaller, deployable models in mental health applications. The authors propose a selective distillation framework that evaluates and filters rationales based on domain relevance before training student models. By using an LLM-based evaluator to score rationales against DSM-5 diagnostic criteria, the framework identifies high-quality reasoning chains for knowledge transfer. Experimental results demonstrate that this quality-focused approach significantly outperforms standard distillation methods in both detection accuracy and rationale generation quality, highlighting the importance of rationale quality for effective learning transfer in clinical domains.

## Method Summary
The framework generates multiple candidate rationales per input using high-temperature sampling from teacher LLMs, then employs a GPT-4o evaluator prompted with DSM-5 criteria to score each rationale on a 10-point scale across three factors: Domain Knowledge, Symptom Recognition, and Symptom Relevancy. The highest-scoring rationale is selected for training smaller student models via LoRA fine-tuning. The method uses temperature=1.0 for generation, produces L=10 candidates per post, and applies standard LoRA hyperparameters (r=16, α=32, lr=2e-4, 1 epoch) with inference settings of top_p=0.95, max_len=300, temperature=0.0.

## Key Results
- Selective distillation improves accuracy by 5-10 percentage points across all teacher-student combinations (e.g., GPT-4o→Mistral: 86.57→91.02 accuracy)
- LLM-based evaluator correlates with human "Professionality" ratings at ρ=0.565 (p<.001), outperforming traditional metrics like BERTScore (0.248) and BLEU (0.257)
- Selection of best rationales outperforms random selection by 10-20+ accuracy points in ablation studies
- Framework generalizes across multiple teacher models (GPT-3.5, GPT-4o, Llama-3-70B) and student models (Llama-2-7B, Llama-3.1-8B, Mistral-7B)

## Why This Works (Mechanism)

### Mechanism 1: Quality-Based Selection Filtering
Filtering rationales based on domain relevance before distillation improves student model performance in both detection accuracy and rationale quality. The teacher generates multiple candidate rationales per input (L=10 candidates at temperature=1.0). An LLM-based evaluator scores each rationale against DSM-5 diagnostic criteria. Only the highest-scoring rationale is used for student fine-tuning. This reduces exposure to noisy or superficial reasoning chains that could degrade learning.

### Mechanism 2: DSM-5-Aligned Evaluation as Proxy for Human Clinical Reasoning
An LLM-based evaluator prompted with DSM-5 criteria produces quality assessments that align with expert human evaluation. GPT-4o is prompted with explicit DSM-5 symptom criteria and a 10-point rubric (Severely Inadequate to Exemplary). The evaluator assesses three factors: Domain Knowledge integration, Symptom Recognition accuracy, and Symptom Relevancy alignment.

### Mechanism 3: Multi-Rationale Generation Creates Quality Variance for Selection
Generating multiple rationales per input creates sufficient quality variance to enable effective selection. High temperature (1.0) sampling produces diverse reasoning paths. Some rationales will coincidentally align better with clinical criteria even with identical prompts. Selection exploits this variance.

## Foundational Learning

- **Concept: Knowledge Distillation (Teacher-Student Framework)**
  - Why needed here: The entire framework transfers reasoning ability from large proprietary models to smaller deployable models. Understanding distillation loss functions and fine-tuning dynamics is prerequisite.
  - Quick check question: Can you explain why standard fine-tuning on teacher outputs might propagate teacher errors?

- **Concept: Chain-of-Thought (CoT) Prompting**
  - Why needed here: Rationales are generated via CoT prompting strategies (Std-CoT, Step-by-Step, Emotion-enhanced). Understanding how prompt design affects reasoning quality is essential.
  - Quick check question: What makes a CoT prompt domain-appropriate vs. generic?

- **Concept: Clinical Diagnostic Criteria (DSM-5, PHQ-9)**
  - Why needed here: Evaluation explicitly uses DSM-5 criteria as the ground truth for rationale quality. Without understanding symptom-based diagnosis, the "Professionality" metric is opaque.
  - Quick check question: Can you identify which DSM-5 symptoms the "R1" rationale in Figure 1 references?

## Architecture Onboarding

- **Component map:** Teacher LLMs -> Rationale Pool Generator (T=1.0, L=10) -> Quality Evaluator (GPT-4o, DSM-5 rubric) -> Selection Filter (argmax) -> Student Trainer (LoRA) -> Inference Engine (top_p=0.95, max_len=300, T=0.0)

- **Critical path:** Teacher generation → Evaluation scoring → Selection → Student fine-tuning. Breaks in evaluation validity or selection pool quality propagate directly to student performance.

- **Design tradeoffs:**
  - Pool size (L): Larger pools increase selection opportunity but multiply API costs (L=10 used)
  - Evaluator model choice: GPT-4o provides stronger alignment but higher cost than smaller evaluators
  - Temperature setting: Higher T increases variance but may produce more incoherent candidates
  - Single vs. multi-rationale training: Paper uses single best rationale; Assumption: ensemble approaches could provide robustness but were not tested

- **Failure signatures:**
  - Selection shows no improvement over standard distillation → evaluator scoring may not capture transferable quality features
  - High evaluator-human correlation but low downstream gains → quality dimension measured may not be learning-relevant
  - Performance degrades on non-depression tasks → selection criteria overfit to specific symptoms

- **First 3 experiments:**
  1. Reproduce baseline comparison: Train Llama-2-7B with standard distillation vs. selective distillation using GPT-3.5 teacher on Reddit_depression. Verify accuracy gain is within reported range (~5-10 points).
  2. Ablate pool size: Test L∈{1,3,5,10,20} to characterize cost-benefit curve of candidate generation.
  3. Evaluator calibration check: Sample 50 rationales, correlate GPT-4o evaluator scores with human expert ratings on Consistency, Reliability, Professionality. Target ρ>0.5 for Professionality as reported.

## Open Questions the Paper Calls Out

### Open Question 1
Can the computational overhead of the selective distillation framework be reduced using lightweight evaluation metrics without compromising student model performance? The authors acknowledge the "significant computational costs due to the necessity of repeated rationale generation and LLM-based quality evaluation" and suggest future work should explore "computationally less expensive evaluation metrics."

### Open Question 2
To what extent do selectively distilled rationales improve the diagnostic efficiency and accuracy of mental health professionals in real-world clinical workflows? The paper states, "Future research could investigate more deeply the human-AI interaction regarding how these rationales can assist mental health professionals... by conducting user studies with clinicians."

### Open Question 3
Does the selective distillation framework effectively generalize to mental health domains with more complex or ambiguous diagnostic criteria, such as schizophrenia or bipolar disorder? The authors note, "While this study primarily focuses on mental disorder detection, specifically for major depressive disorder... future research should investigate the feasibility... of applying this framework to different domains."

## Limitations
- Computational overhead from 10× more LLM API calls than standard distillation creates significant cost and scalability constraints
- Moderate correlation (ρ=0.565) between evaluator scores and human judgment leaves ~69% of variance unexplained
- All experiments focus exclusively on Major Depressive Disorder detection from Reddit posts, limiting generalization claims

## Confidence

- **High confidence:** The core finding that selective distillation outperforms standard distillation on this dataset (multiple consistent experimental results across teacher-student pairs)
- **Medium confidence:** The correlation between evaluator scores and human judgment (statistically significant but moderate effect size)
- **Medium confidence:** The mechanism that quality variance from multi-sample generation enables selection (supported by ablation studies but limited exploration of pool size optimization)

## Next Checks

1. **Evaluator calibration validation:** Collect human expert ratings (from at least two licensed mental health professionals) on a stratified sample of 100 rationales from the best/worst selection groups to verify evaluator alignment with clinical judgment.

2. **Cross-disorder generalization test:** Apply the selective distillation framework to detect another mental health condition (e.g., anxiety or bipolar disorder) using the same Reddit dataset or similar social media corpus to assess domain transfer.

3. **Selection threshold optimization:** Instead of always selecting the top-scoring rationale, experiment with selecting top-k rationales (k>1) or using a score threshold to investigate whether multiple rationales could provide more robust learning signals than single best selection.