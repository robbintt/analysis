---
ver: rpa2
title: 'Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion
  Models'
arxiv_id: '2505.08833'
source_url: https://arxiv.org/abs/2505.08833
tags:
- urban
- land
- satellite
- residential
- design
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study adapts Stable Diffusion with ControlNet to generate
  high-fidelity satellite imagery for urban planning by conditioning on land use descriptions
  and infrastructure constraints. It spatially aligns OpenStreetMap data with satellite
  imagery to address data scarcity, enabling large-scale training across three U.S.
---

# Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models

## Quick Facts
- arXiv ID: 2505.08833
- Source URL: https://arxiv.org/abs/2505.08833
- Reference count: 29
- This study adapts Stable Diffusion with ControlNet to generate high-fidelity satellite imagery for urban planning by conditioning on land use descriptions and infrastructure constraints.

## Executive Summary
This study adapts Stable Diffusion with ControlNet to generate high-fidelity satellite imagery for urban planning by conditioning on land use descriptions and infrastructure constraints. It spatially aligns OpenStreetMap data with satellite imagery to address data scarcity, enabling large-scale training across three U.S. cities. The model generates diverse, realistic urban landscapes and captures city-specific styles, while supporting varied prompting styles. Quantitative evaluations using FID (58.94) and KID (0.03514) show strong fidelity, and user studies indicate generated images are preferred over real ones and closely match design constraints. The work provides a benchmark for controlled urban imagery generation and demonstrates generative AI's potential to enhance planning workflows and public engagement.

## Method Summary
The study employs a diffusion model approach, specifically adapting Stable Diffusion with ControlNet architecture to generate satellite imagery conditioned on urban planning constraints. The key innovation is the spatial alignment between OpenStreetMap (OSM) vector data and satellite imagery, which enables the model to learn the relationship between infrastructure layouts and their visual representation. The model is trained on datasets from three U.S. cities, using land use descriptions and infrastructure constraints as conditioning inputs. ControlNet provides precise spatial control by conditioning the diffusion process on edge maps derived from OSM data, ensuring generated imagery accurately reflects the specified urban layouts.

## Key Results
- FID score of 58.94 and KID of 0.03514 demonstrate strong fidelity in generated satellite imagery
- User studies show generated images are preferred over real satellite imagery and closely match design constraints
- Model captures city-specific styles and generates diverse, realistic urban landscapes across different U.S. cities

## Why This Works (Mechanism)
The approach works by leveraging diffusion models' ability to generate realistic imagery while ControlNet provides precise spatial conditioning through OpenStreetMap-derived edge maps. The spatial alignment between vector infrastructure data and raster satellite imagery enables the model to learn the mapping between urban layouts and their visual representations. By conditioning on both land use descriptions and infrastructure constraints, the model can generate imagery that accurately reflects specified planning parameters. The use of diffusion models allows for the generation of diverse outputs while maintaining realism, and the ControlNet architecture ensures spatial consistency with the provided constraints.

## Foundational Learning
- **Diffusion Models**: Generate images by iteratively denoising random noise, why needed for high-quality image synthesis, quick check: understand forward and reverse diffusion processes
- **ControlNet Architecture**: Provides spatial conditioning to diffusion models using edge maps, why needed for precise layout control, quick check: understand how control signals guide generation
- **OpenStreetMap Integration**: Vector infrastructure data aligned with raster imagery, why needed for training data creation, quick check: verify spatial alignment quality and accuracy
- **FID and KID Metrics**: Quantitative measures of image generation quality, why needed for objective evaluation, quick check: understand what these metrics capture and their limitations
- **User Preference Studies**: Qualitative assessment of generated imagery, why needed for real-world applicability, quick check: examine study design and potential biases
- **Conditional Image Generation**: Generating images based on specific inputs, why needed for controlled urban planning applications, quick check: understand conditioning mechanisms and their effects

## Architecture Onboarding

Component Map: OSM Data -> ControlNet Edge Detection -> Stable Diffusion + ControlNet -> Generated Satellite Imagery

Critical Path: The critical path involves extracting edge maps from OSM data, feeding these through ControlNet as conditioning information to Stable Diffusion, and generating the final satellite imagery. This path ensures spatial alignment between specified infrastructure and generated visual output.

Design Tradeoffs: The approach trades computational complexity (ControlNet adds parameters and processing) for precise spatial control. Using OSM data provides abundant training data but requires careful spatial alignment. The diffusion model approach enables high-quality generation but requires significant computational resources for training and inference.

Failure Signatures: Common failure modes include misalignment between OSM data and satellite imagery leading to spatial artifacts, over-smoothing of fine urban details, generation of unrealistic building textures or patterns, and failure to capture subtle city-specific characteristics when training data is limited.

First Experiments:
1. Test spatial alignment accuracy between OSM data and satellite imagery using a small sample
2. Generate single building blocks with known OSM layouts to verify ControlNet conditioning works
3. Compare FID scores on held-out test data to establish baseline performance

## Open Questions the Paper Calls Out
None

## Limitations
- Limited generalizability beyond three U.S. cities to diverse urban forms globally
- Potential biases in user preference studies and sample size limitations
- Uncertainties about the robustness of spatial alignment methodology and error propagation

## Confidence
- High Confidence: Technical implementation of ControlNet with Stable Diffusion, methodology for spatial alignment with OSM data, basic feasibility across three U.S. cities
- Medium Confidence: Quantitative evaluation metrics showing strong fidelity, user preference results, claim about matching design constraints
- Low Confidence: Generalizability to non-U.S. cities, robustness of spatial alignment, capturing city-specific styles without comprehensive validation

## Next Checks
1. Conduct cross-city validation by testing the model on satellite imagery from cities with significantly different urban planning patterns (e.g., European historic cities, Asian megacities, and informal settlements in developing countries) to assess generalizability beyond the three U.S. cities used in training.

2. Implement a controlled user study with larger, demographically diverse samples comparing generated imagery against both real satellite imagery and alternative generation approaches, including detailed analysis of what specific aspects drive user preferences.

3. Perform rigorous validation of the spatial alignment between OpenStreetMap data and satellite imagery by quantifying alignment errors, testing the model's robustness to alignment inaccuracies, and evaluating whether misalignment affects the quality of generated outputs.