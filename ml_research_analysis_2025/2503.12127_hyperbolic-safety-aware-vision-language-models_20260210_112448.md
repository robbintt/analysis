---
ver: rpa2
title: Hyperbolic Safety-Aware Vision-Language Models
arxiv_id: '2503.12127'
source_url: https://arxiv.org/abs/2503.12127
tags:
- safe
- unsafe
- content
- hyperbolic
- hysac
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of retrieving unsafe content
  from vision-language models like CLIP. The authors propose a novel approach, HySAC
  (Hyperbolic Safety-Aware CLIP), which leverages the hierarchical properties of hyperbolic
  space to encode safe and unsafe content as an entailment hierarchy.
---

# Hyperbolic Safety-Aware Vision-Language Models

## Quick Facts
- arXiv ID: 2503.12127
- Source URL: https://arxiv.org/abs/2503.12127
- Authors: Tobia Poppi; Tejaswi Kasarla; Pascal Mettes; Lorenzo Baraldi; Rita Cucchiara
- Reference count: 40
- One-line primary result: HySAC achieves 30.5% R@1 on T⋆-to-I∪I⋆ retrieval while Safe-CLIP drops to 1.4%

## Executive Summary
This paper addresses the challenge of retrieving unsafe content from vision-language models like CLIP by proposing a novel approach, HySAC (Hyperbolic Safety-Aware CLIP). Instead of unlearning unsafe concepts, HySAC models them as specific cases of safe counterparts in a hyperbolic entailment hierarchy, placing safe content closer to the origin and unsafe content farther away. The model employs entailment loss functions to enforce these hierarchical and asymmetrical relations, enabling it to serve as both a multimodal unsafe classifier and a flexible content retriever.

## Method Summary
HySAC fine-tunes CLIP ViT-L/14 using LoRA in Lorentzian hyperbolic space to learn a safety-aware hierarchy where safe content (closer to origin) entails unsafe content (farther from origin). The method combines hyperbolic safety contrastive loss for multimodal alignment with hyperbolic safety entailment loss for enforcing the hierarchy. At inference, geodesic traversal enables controlled retrieval of safe or unsafe content while maintaining semantic relevance. Training uses the ViSU dataset with quadruplets of safe/unsafe image-text pairs, optimized via AdamW with mixed precision.

## Key Results
- HySAC achieves 30.5% R@1 on T⋆-to-I∪I⋆ retrieval (unsafe text to safe+unsafe images), compared to 4.1% for Safe-CLIP
- HySAC maintains 81.4% R@1 on T⋆-to-I⋆ retrieval (unsafe-to-unsafe), demonstrating bidirectional traversal capability
- Ablation study shows entailment loss is critical, dropping T⋆-to-I∪I⋆ R@1 from 30.5% to 1.4% when removed

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Encoding safe and unsafe content in hyperbolic space as an entailment hierarchy enables the model to distinguish between them while preserving semantic relationships.
- **Mechanism:** HySAC projects CLIP embeddings onto a Lorentz hyperboloid and enforces a four-level hierarchy: safe text (closest to origin) ≪ safe image ≪ unsafe text ≪ unsafe image (farthest from origin). The exponential map transforms Euclidean encoder outputs to hyperbolic space, while entailment cone losses enforce that unsafe embeddings lie within the cones defined by their safe counterparts.
- **Core assumption:** The paper assumes that unsafe content can be meaningfully modeled as specific cases (entailments) of general safe concepts—a semantic relationship that hyperbolic geometry's hierarchical properties can capture more naturally than Euclidean space.
- **Evidence anchors:** [abstract] "encode safe and unsafe content as an entailment hierarchy, where both are placed in different regions of hyperbolic space"; [Page 4, Section 4.1] Equation 7 defines the full hierarchy; [Page 7, Figure 2] Distribution plots show four distinct peaks for safe text, safe image, unsafe text, and unsafe image based on distance from root.

### Mechanism 2
- **Claim:** Combined contrastive and entailment losses in hyperbolic space create both multimodal alignment and safety-aware hierarchical structure.
- **Mechanism:** The training objective combines (1) hyperbolic safety contrastive loss (L_hSC) using negative Lorentzian distance for image-text alignment across safe/unsafe pairs and cross-safety modalities, and (2) hyperbolic safety entailment loss (L_hSE) using entailment cones to enforce that images lie within their corresponding text cones and that unsafe text lies within safe image cones.
- **Core assumption:** Assumes that the Lorentz model's numerical stability advantages over Poincaré ball are sufficient for training, and that the temperature τ and cone aperture parameters can be tuned to balance retrieval quality against safety separation.
- **Evidence anchors:** [Page 4, Section 4.2] Equations 8-14 define the complete loss formulation with contrastive and entailment components; [Page 7, Table 3] Ablation study shows removing entailment loss (w/o Ent) drops T⋆-to-I∪I⋆ R@1 from 30.5% to 4.1%, and removing safety entailment (w/o S-Ent) drops it to 1.4%.

### Mechanism 3
- **Claim:** Geodesic traversal from query embeddings toward or away from the hyperboloid origin enables controlled retrieval of safe or unsafe content while maintaining semantic relevance.
- **Mechanism:** At inference, HySAC computes the mean distance μX from the origin for each content type (safe text/image, unsafe text/image) and defines boundaries τX. To redirect an unsafe query toward safe content, the embedding is moved along the Euclidean direction vector vdir = q - r toward the root r until it reaches the safe boundary τT or τI.
- **Core assumption:** Assumes that semantic relevance is preserved along the geodesic path—that moving toward the origin generalizes the concept rather than replacing it with unrelated safe content.
- **Evidence anchors:** [Page 5, Section 4.3] Equations 16-17 define boundary τX = μX + tanh((μX - α)/κ) + 1 and traversal target q* = r + τX · vdir/||vdir||; [Page 8, Figure 3] Qualitative traversal visualization shows an unsafe image query retrieving increasingly safe but semantically related captions as it moves toward the root.

## Foundational Learning

- **Concept: Hyperbolic geometry and the Lorentz model**
  - **Why needed here:** HySAC operates entirely in hyperbolic space, using the Lorentz model (two-sheeted hyperboloid in Minkowski spacetime). You need to understand why negative curvature enables hierarchical representation with lower distortion than Euclidean space, and how the Lorentz model addresses numerical stability issues compared to Poincaré ball.
  - **Quick check question:** Can you explain why the Lorentzian distance dL(p,q) = √(1/κ)·cosh⁻¹(-κ⟨p,q⟩L) produces different embedding distributions than Euclidean cosine similarity, and what the time-axis p₀ represents?

- **Concept: Entailment cones and partial order embeddings**
  - **Why needed here:** The core innovation builds on Ganea et al.'s entailment cones—geometric regions in hyperbolic space where if q entails p, then p must lie within cone Sq defined by q's half-aperture. Understanding this lets you see why "safe entails unsafe" creates a navigable hierarchy.
  - **Quick check question:** Given an embedding q with half-aperture ω(q) = sin⁻¹(2K·κ·||q̄||), can you sketch why embeddings farther from the origin have wider cones, and how this enforces that unsafe content (farther) is "contained by" safe content (closer)?

- **Concept: CLIP vision-language alignment**
  - **Why needed here:** HySAC inherits CLIP's dual-encoder architecture (ViT-L/14 visual encoder + text transformer) and contrastive pre-training. You need to understand how CLIP aligns image and text embeddings via InfoNCE loss to see what HySAC modifies (the embedding space geometry and loss structure).
  - **Quick check question:** If CLIP aligns [image embedding, text embedding] pairs in Euclidean space via cosine similarity, what changes when HySAC projects these to hyperbolic space and replaces cosine with negative Lorentzian distance?

## Architecture Onboarding

- **Component map:** Visual encoder (ViT-L/14) -> Text encoder (Transformer) -> Exponential map (exp_κ^0) -> Hyperbolic similarity layer -> Entailment cone module -> Traversal controller

- **Critical path:**
  1. Initialize from CLIP ViT-L/14 pre-trained weights
  2. Set hyperbolic parameters: curvature c=1.0 (clamped [0.1, 10.0]), αimg=αtxt=1/√512, τ=0.07
  3. Load ViSU dataset with quadruplets (safe image/text, unsafe image/text pairs)
  4. Forward pass: encode → exponential map to hyperboloid → compute L_hSC (4 contrastive terms) + L_hSE (3 entailment terms)
  5. Backprop with AdamW (lr=8×10⁻⁴, weight decay=0.2), mixed precision (FP32 for hyperbolic ops)
  6. Train 20 epochs, batch size 256 (32 per GPU × 8 A100s)

- **Design tradeoffs:**
  - **Hyperbolic vs. Euclidean:** Table 9 ablation shows Euclidean version with entailment cones achieves 2.1% R@1 on T⋆-to-I∪I⋆ vs. HySAC's 30.5%—hyperbolic geometry is essential
  - **LoRA full fine-tuning vs. frozen encoders:** LoRA allows adapting both encoders while constraining updates; full fine-tuning risks catastrophic forgetting of CLIP's general knowledge
  - **Awareness vs. unlearning:** HySAC retains ability to retrieve unsafe content (81.4% R@1 on T⋆-to-I⋆) while Safe-CLIP drops to 58.0%; this trades safety-by-default for user control and transparency
  - **η parameter (cone aperture):** Table 10 shows η<1 (narrower cones) degrades safe retrieval; η>1 improves safe retrieval but heavily degrades safety performance; η=1 is the balance point

- **Failure signatures:**
  - **Numerical instability:** If curvature c is not clamped properly, exponential map can produce NaN/Inf; symptoms include exploding gradients or zero embeddings
  - **Collapsed hierarchy:** If entailment loss weight is too low, all embeddings cluster at similar distances from origin (check via distance distribution plots); safety-awareness degrades to random
  - **Over-constrained cones:** If η is too small, entailment cones become too narrow to satisfy; training loss plateaus high, retrieval R@1 drops on all tasks
  - **Semantic drift during traversal:** If traversal step size is too large or boundary τX is miscalibrated, retrieved content becomes irrelevant; check by visualizing retrieval results at intermediate interpolation points

- **First 3 experiments:**
  1. **Reproduce safe-to-unsafe hierarchy visualization:** Embed all ViSU test samples and plot distance distributions from root (replicate Figure 2); verify four distinct peaks for T, I, T⋆, I⋆ appear—this confirms the core geometric structure is learned
  2. **Ablate entailment loss components:** Train with (a) contrastive only, (b) contrastive + modality entailment (no safety entailment), (c) full HySAC; compare T⋆-to-I∪I⋆ R@1 to verify the 30.5% → 4.1% → 1.4% degradation pattern from Table 3
  3. **Test traversal on held-out NSFW category:** Take NudeNet images as unsafe queries, traverse toward safe region, and manually assess whether top-1 retrieved captions transition from explicit to safe while maintaining topic relevance; this validates the qualitative claim in Figure 3

## Open Questions the Paper Calls Out
- **Integrating with generative frameworks:** The paper suggests adapting U-Net architecture for Stable Diffusion to process hyperbolic embeddings, but this requires non-trivial architectural modifications for controlled generation.
- **Strengthening safety guarantees:** The model doesn't provide guarantees for redirecting inappropriate content in diverse scenarios, requiring expanded training data for robustness.
- **Generalizing safety thresholds:** The empirical threshold τ relies on ViSU's mean distances, suggesting recalibration may be needed when data distribution changes.

## Limitations
- **Dataset dependency:** Claims rely heavily on ViSU dataset generated via LLM rather than human-annotated unsafe content, raising generalization concerns.
- **Lack of paired evaluation:** No formal evaluation with paired unsafe-safe content alternatives to validate traversal mechanism's semantic preservation.
- **Cross-dataset validation:** No validation on established safety benchmarks to verify hierarchy holds beyond ViSU's specific generation process.

## Confidence
- **Core mechanism (hyperbolic entailment hierarchy):** High - strong ablation evidence shows 30.5% → 4.1% → 1.4% R@1 degradation when removing components
- **Safety effectiveness:** Medium - results depend on specific ViSU generation process, no cross-dataset validation provided
- **Traversal mechanism:** Low - lack of rigorous paired-content evaluation, relies on qualitative visualizations

## Next Checks
1. **Cross-dataset generalization test:** Evaluate HySAC on established safety benchmarks (e.g., DrawBench safety prompts, RealToxicityPrompts with visual components) to verify hierarchy holds beyond ViSU's LLM-generated content.

2. **Fine-grained safety boundary analysis:** Systematically vary the entailment cone threshold η and measure the precision-recall tradeoff on the T⋆-to-I⋆ task to identify optimal operating points for different safety requirements.

3. **Real-world deployment simulation:** Create a test protocol where HySAC processes user-uploaded images with ambiguous safety (e.g., medical imagery, artistic nudity) and measure both safety classification accuracy and retrieval relevance compared to human annotators.