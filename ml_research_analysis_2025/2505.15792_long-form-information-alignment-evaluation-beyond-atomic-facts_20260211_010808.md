---
ver: rpa2
title: Long-Form Information Alignment Evaluation Beyond Atomic Facts
arxiv_id: '2505.15792'
source_url: https://arxiv.org/abs/2505.15792
tags:
- text
- evaluation
- linguistics
- target
- evaluators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MontageLie, a benchmark designed to evaluate
  information alignment evaluators' ability to detect deceptive narratives composed
  of reordered truthful statements. Current fine-grained methods like FactScore verify
  individual facts but fail to detect manipulation in fact ordering.
---

# Long-Form Information Alignment Evaluation Beyond Atomic Facts

## Quick Facts
- arXiv ID: 2505.15792
- Source URL: https://arxiv.org/abs/2505.15792
- Authors: Danna Zheng; Mirella Lapata; Jeff Z. Pan
- Reference count: 40
- Primary result: DoveScore achieves 65.25% AUC-ROC on MontageLie, outperforming existing fine-grained methods by over 8%

## Executive Summary
Current fine-grained information alignment evaluators verify individual facts but fail to detect deceptive narratives composed of reordered truthful statements. This paper introduces MontageLie, a benchmark designed to evaluate alignment evaluators' ability to detect "montage-style lies" where accurate facts are shuffled to create false causality. Existing evaluators, both coarse-grained and fine-grained, achieve AUC-ROC scores below 65% on this task. The paper proposes DoveScore, a novel framework that jointly verifies factual accuracy and event-order consistency by modeling inter-fact relationships, achieving 65.25% AUC-ROC on MontageLie.

## Method Summary
DoveScore is a three-component LLM-based framework that decomposes text into event and descriptive facts, verifies each fact against the source, and compares the chronological ordering of verified event facts. The framework uses gpt-4o-mini-2024-07-18 with temperature=0 for all components. The final score is a weighted combination of factual accuracy and ordering consistency, with weights determined by the relative frequency of event versus descriptive facts in the target text.

## Key Results
- DoveScore achieves 65.25% AUC-ROC on MontageLie, outperforming FactScore by 8% (57.36% to 65.25%)
- Performance varies significantly across difficulty levels: easy (87.50%), medium (71.86%), hard (56.40%), extreme (43.20%)
- All existing evaluators, including GPT-4o-mini and FactScore, achieve AUC-ROC below 65% on MontageLie
- Component ablation shows SEO (Event Order Score) is the most critical component for discrimination

## Why This Works (Mechanism)

### Mechanism 1: Inter-Fact Dependency Modeling
Existing fine-grained evaluators fail on montage-style lies because they verify facts independently, ignoring how relationships between facts convey meaning. DoveScore distinguishes between descriptive facts (time-independent attributes) and event facts (temporally ordered actions), then explicitly models the ordering relationships among event facts rather than treating all facts as isolated units. This works because event sequences, not just atomic factuality, carry semantic meaning; readers infer causality from presentation order.

### Mechanism 2: Dual-Sequence Event Ordering Verification
The framework compares the chronological ordering of event facts in source vs. target by producing two ordered sequences and computing Event Order Score (SEO) via normalized inversion count: SEO = 1 - ShuffleD. High SEO indicates preserved ordering; low SEO signals potential montage manipulation. This works because the LLM-based sorter can reliably infer chronology from narrative text, detecting when accurate facts are presented in a sequence that creates false causality.

### Mechanism 3: Frequency-Weighted Score Aggregation
The framework weights event-based and descriptive scores by their relative frequency to provide robustness across texts with varying event densities. The final DoveScore = α · SE · SEO + (1 − α) · SD, where α = |FE| / (|FE| + |FD|). This works because the relative proportion of event to descriptive facts in the target text is a reasonable proxy for which dimension matters more for alignment.

## Foundational Learning

**Concept: Inversion Count and Kendall's Tau**
Why needed: The ShuffleD metric is based on counting inversions in a permutation; understanding this helps interpret SEO scores and difficulty levels.
Quick check: Given original sequence [A, B, C, D] and permuted [D, B, A, C], what is the inversion count?

**Concept: Atomic Fact Decomposition**
Why needed: DoveScore builds on prior work decomposing text into atomic facts; understanding the granularity distinction (sentence vs. atomic vs. event/descriptive) is critical.
Quick check: How does "Dr. Lin submitted her resignation" differ atomically from "Dr. Lin, a tenured professor, submitted her resignation yesterday"?

**Concept: AUC-ROC for Binary Classification**
Why needed: All results are reported in AUC-ROC; understanding what 65% means vs. random (50%) vs. perfect (100%) is essential for interpreting claims.
Quick check: If an evaluator assigns identical scores to all inputs, what AUC-ROC would result?

## Architecture Onboarding

**Component map:**
Target Text + Source Text -> [Decomposer] -> Event Facts (FE) + Descriptive Facts (FD) -> [Fact Checker] -> Verified Correct: F_E^c, F_D^c -> [Sorter] -> Sorted(F_E^c, s), Sorted(F_E^c, t) -> SEO = 1 - ShuffleD(source_order, target_order) -> [Aggregator] -> α = |FE|/(|FE|+|FD|) -> DoveScore = α·SE·SEO + (1-α)·SD

**Critical path:** The Sorter is identified as "a critical and currently underexplored component." Fact Checker accuracy bounds both SE and SEO (since SEO only applies to verified-correct events).

**Design tradeoffs:**
- Global sorting vs. pairwise comparison: The paper chooses global list sorting to reduce O(n²) pairwise comparisons, trading some accuracy for efficiency
- LLM backbone choice: Using GPT-4o-mini provides reasonable performance; smaller models may struggle with the sorter's temporal reasoning
- Incremental lie generation during benchmark construction was necessary because "giving the full F to the LLM often leads to failure in preserving the order"

**Failure signatures:**
- All facts verified correct but low DoveScore → likely ordering manipulation (check SEO)
- High SE but SD ≈ 0 → descriptive facts unsupported; check fact checker's handling of attributes
- SEO near 1.0 but overall score low → individual facts failing verification; check fact checker
- Uniformly high scores on deceptive texts → sorter failing; examine its chronology inference

**First 3 experiments:**
1. **Ablation on components:** Run DoveScore with SE only, SD only, SEO only, and combinations to measure each component's marginal contribution on MontageLie
2. **Sorter backbone comparison:** Test the sorter with different LLM backbones (e.g., Qwen-3-32B, Llama-3.3-70B) to identify minimum viable model size for reliable chronology inference
3. **Cross-domain generalization:** Evaluate DoveScore on existing alignment benchmarks (TRUE, LLM-AggreFact) to verify it does not regress on conventional hallucination detection while gaining on montage-style lies

## Open Questions the Paper Calls Out

**Open Question 1:** How does the trade-off between computational efficiency and ranking accuracy shift when using pairwise comparison-based sorting strategies versus the global list prediction method currently employed in DoveScore? The authors state the trade-off between efficiency and ranking accuracy remains an open research question.

**Open Question 2:** How robust is the DoveScore framework when instantiated with open-source or smaller language models compared to the GPT-4o-mini backbone used in the study? The authors note future work is needed to assess robustness under varying resource constraints.

**Open Question 3:** Does the performance of evaluators on MontageLie generalize to human-curated deceptive narratives, or is it influenced by distributional artifacts inherent in LLM-generated data? The authors acknowledge the benchmark is entirely LLM-generated and may introduce stylistic patterns not reflecting real-world misinformation.

**Open Question 4:** What specific reasoning mechanisms are required to elevate the detection of narrative manipulation beyond the ~65% AUC-ROC ceiling observed in current state-of-the-art models? The paper demonstrates that modeling inter-fact relationships helps, but the relatively low absolute score suggests current models lack deeper causal reasoning.

## Limitations
- The framework may not detect all montage-style manipulations (e.g., removing connecting sentences, interleaving unrelated event chains)
- All components rely on gpt-4o-mini, raising questions about scalability and consistency across different LLM backends
- The 8% improvement may not generalize beyond MontageLie's specific construction to conventional alignment tasks

## Confidence

**High:** The core problem of montage-style lies is well-defined and the benchmark construction methodology is reproducible.

**Medium:** The DoveScore architecture is sound, but component-level performance and interaction effects require validation.

**Low:** The claimed superiority over existing methods may not generalize beyond MontageLie's specific construction.

## Next Checks

1. **Component ablation study:** Run DoveScore with individual components disabled (SE-only, SD-only, SEO-only) on MontageLie to quantify each component's marginal contribution and identify potential redundancy.

2. **Cross-domain evaluation:** Test DoveScore on established alignment benchmarks (TRUE, LLM-AggreFact) to verify it doesn't regress on conventional hallucination detection while maintaining montage-lie detection capability.

3. **Sorter robustness test:** Systematically evaluate the Sorter component on texts with known temporal ambiguities, parallel timelines, and non-linear narratives to measure false positive/negative rates and identify failure patterns.