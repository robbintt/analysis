---
ver: rpa2
title: 'UniECG: Understanding and Generating ECG in One Unified Model'
arxiv_id: '2509.18588'
source_url: https://arxiv.org/abs/2509.18588
tags:
- uniecg
- generation
- understanding
- evidence-based
- unified
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents UniECG, the first unified model capable of
  both interpreting ECG signals/images and generating ECG signals from text. The model
  addresses the limitation of existing ECG models that typically specialize in either
  understanding or generation but not both.
---

# UniECG: Understanding and Generating ECG in One Unified Model

## Quick Facts
- arXiv ID: 2509.18588
- Source URL: https://arxiv.org/abs/2509.18588
- Reference count: 0
- Primary result: First unified model for both ECG interpretation and generation, achieving substantial improvements in understanding tasks over PULSE baseline

## Executive Summary
This paper presents UniECG, the first unified model capable of both interpreting ECG signals/images and generating ECG signals from text. The model addresses the limitation of existing ECG models that typically specialize in either understanding or generation but not both. UniECG employs a two-stage training approach: first fine-tuning for evidence-based ECG interpretation (ECG-to-Text), then injecting generation capabilities (Text-to-ECG) through latent space alignment with DiffuSETS. During inference, the model autonomously determines whether to interpret or generate ECG based on user input. Experiments demonstrate that UniECG achieves substantial improvements in ECG understanding tasks compared to PULSE, with feature grounding improving from 41.63 to 69.44, evidence-based reasoning from 38.53 to 61.76, and overall average from 39.95 to 63.98.

## Method Summary
UniECG employs a two-stage training approach to achieve unified ECG understanding and generation. In Stage 1, the model learns evidence-based interpretation by fine-tuning an LLM on ECG-to-Text tasks using signal and image encoders that project modality-specific embeddings into the LLM's input space. In Stage 2, generation capabilities are injected by adding special [ECG] tokens to the LLM vocabulary and training their embeddings through alignment with DiffuSETS' frozen text encoder using a lightweight mapper network. The model autonomously determines whether to interpret or generate ECG during inference based on user input.

## Key Results
- Achieved feature grounding improvement from 41.63 to 69.44 compared to PULSE baseline
- Evidence-based reasoning improved from 38.53 to 61.76
- Overall average score increased from 39.95 to 63.98
- First model to enable signal-level ECG generation while maintaining strong interpretive capabilities

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Joint multimodal alignment of ECG signals, images, and text enables evidence-based diagnostic reasoning.
- **Mechanism:** Signal and visual encoders extract modality-specific embeddings which are projected into the LLM's input space via learned linear mappings. The LLM is then full-parameter fine-tuned on image-signal-text triplets, optimizing negative log-likelihood of target diagnostic sequences. This forces the model to ground textual explanations in actual waveform features.
- **Core assumption:** Evidence-based interpretation requires simultaneous access to both signal-level temporal patterns and visual ECG representations.
- **Evidence anchors:**
  - [abstract]: "model first learns evidence-based interpretation skills (ECG-to-Text)"
  - [Section 2.1]: "we jointly optimize Wts, Wtsi, and the LLM parameters θ on image–signal–text triplets by minimizing the negative log-likelihood"
  - [corpus]: GEM paper confirms multimodal synergy between time series and visual representations improves grounded understanding
- **Break condition:** If signal and image encoders produce conflicting embeddings or if the projection matrices fail to align modalities, diagnostic accuracy degrades.

### Mechanism 2
- **Claim:** Special [ECG] tokens with frozen LLM backbone enable generation capability injection without catastrophic forgetting.
- **Mechanism:** The LLM vocabulary is extended with n special tokens ([ECG_1]...[ECG_n]). During stage 2 training, the entire LLM is frozen and only gradients for these new token embeddings are updated. This constrains generation learning to a narrow subspace while preserving understanding capabilities.
- **Core assumption:** The frozen LLM's language understanding is sufficient to map textual conditions to semantically meaningful [ECG] token representations.
- **Evidence anchors:**
  - [abstract]: "injecting generation capabilities (Text-to-ECG) through latent space alignment"
  - [Section 2.2]: "we freeze the entire LLM and only update the gradients of the newly added tokens in the input embedding matrix"
  - [corpus]: Weak direct evidence—no corpus papers specifically validate frozen-backbone token injection for medical signal generation
- **Break condition:** If the frozen LLM lacks sufficient expressiveness in its hidden states, [ECG] tokens cannot capture fine-grained clinical conditions.

### Mechanism 3
- **Claim:** Lightweight mapper alignment with pretrained DiffuSETS enables signal-level generation without paired ECG-text training data.
- **Mechanism:** An encoder-decoder Transformer mapper takes [ECG] token hidden states as input and produces embeddings aligned to DiffuSETS' frozen text encoder via MSE loss. This projects LLM outputs into DiffuSETS' semantic space, leveraging its pretrained generation capability.
- **Core assumption:** DiffuSETS' text encoder captures semantically meaningful embeddings that can be matched by transformed [ECG] token representations.
- **Evidence anchors:**
  - [Section 2.2]: "the key idea is to project the [ECG] tokens into a semantically meaningful region of DiffuSETS' input space"
  - [Section 2.2]: "this process does not require any ECG data, but relies solely on text-based training"
  - [corpus]: DiffuSETS paper establishes text-conditioned 12-lead ECG generation capability
- **Break condition:** If mapper capacity is insufficient or MSE alignment fails to capture semantic equivalence, generated ECGs will not match textual conditions.

## Foundational Learning

- **Concept: Multimodal Representation Alignment**
  - Why needed here: UniECG requires projecting signal and image embeddings into a shared LLM space—misalignment causes ungrounded diagnoses.
  - Quick check question: Can you explain why separate projection matrices (W_ts, W_tsi) are needed rather than a single shared projection?

- **Concept: Catastrophic Forgetting Mitigation via Parameter Freezing**
  - Why needed here: Stage 2 must add generation without destroying stage 1 understanding—freezing prevents knowledge overwrite.
  - Quick check question: What would happen if all LLM parameters were updated during stage 2 training?

- **Concept: Latent Space Transfer via Mapper Networks**
  - Why needed here: The mapper bridges LLM [ECG] tokens to DiffuSETS' input space—understanding this enables debugging generation failures.
  - Quick check question: Why use MSE loss between mapper output and DiffuSETS text encoder rather than end-to-end training?

## Architecture Onboarding

- **Component map:**
  - Input: ECG signal → ϕ_s (signal encoder) → W_ts projection
  - Input: ECG image → ϕ_v (visual encoder) → W_tsi projection
  - Core: LLM with extended vocabulary containing M_ECG ([ECG_1]...[ECG_n] embeddings)
  - Generation path: LLM [ECG] hidden states → f_ω (mapper) → DiffuSETS decoder → ECG signal
  - Training: Stage 1 updates all LLM params; Stage 2 freezes LLM, updates M_ECG and mapper

- **Critical path:** Stage 1 alignment quality → [ECG] token expressiveness → mapper alignment accuracy → DiffuSETS generation fidelity

- **Design tradeoffs:**
  - Full fine-tuning (Stage 1) vs. frozen backbone (Stage 2): Maximizes understanding but risks forgetting
  - Text-only generation training: Avoids paired data requirements but limits signal-level supervision
  - n token embeddings vs. single token: Increases expressiveness but adds mapper complexity

- **Failure signatures:**
  - Understanding degradation after Stage 2 → Check if LLM parameters were accidentally unfrozen
  - Generated ECGs mismatch text conditions → Debug mapper alignment loss convergence
  - Model always generates instead of interpreting → Verify [ECG] token emission logic in inference

- **First 3 experiments:**
  1. Reproduce Stage 1 understanding metrics on ECG-Grounding validation set before proceeding to Stage 2
  2. Ablate mapper capacity (number of Transformer layers) and measure generation fidelity vs. alignment loss
  3. Test inference routing: provide mixed understanding/generation prompts and verify correct task selection

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions.

## Limitations
- Critical architectural components (base LLM, encoder architectures, hyperparameters) are not specified, making faithful reproduction impossible
- Evaluation relies entirely on LLM-based metrics rather than clinical validation, raising concerns about practical utility
- Reported "slight degradation" in understanding after Stage 2 training suggests fundamental tension between maintaining interpretation capabilities while adding generation functionality

## Confidence

**High Confidence Claims:**
- The two-stage training approach is technically sound and follows established LLM fine-tuning practices
- The problem statement (unified ECG understanding and generation) is well-defined and addresses a genuine gap in current ECG models
- The quantitative improvements over PULSE on the stated metrics are accurately reported given the evaluation methodology

**Medium Confidence Claims:**
- The mechanism by which multimodal alignment enables evidence-based reasoning (Mechanism 1) is plausible but not directly validated
- The claim that text-only generation training is sufficient for clinically meaningful ECG generation (Mechanism 3) is theoretically reasonable but lacks clinical validation

**Low Confidence Claims:**
- The clinical relevance of the reported metric improvements for actual patient care
- The assertion that UniECG's generation capabilities are superior to existing specialized ECG generators without direct comparison on clinically relevant generation tasks

## Next Checks
1. **Clinical Validation Study:** Conduct a blind review by cardiologists comparing UniECG's interpretations and generated ECGs against gold-standard clinical assessments, measuring diagnostic accuracy and clinical utility rather than LLM-based metrics alone.

2. **Ablation of Generation vs Understanding Trade-off:** Systematically vary the learning rate and regularization during Stage 2 to quantify the relationship between generation quality and understanding retention, identifying the optimal balance point.

3. **Direct Generation Capability Comparison:** Benchmark UniECG's text-to-ECG generation against DiffuSETS and other specialized ECG generators on clinically relevant generation tasks (e.g., generating ECGs for specific arrhythmias, conditions) using both quantitative metrics and clinician assessment.