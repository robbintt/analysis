---
ver: rpa2
title: An Explainable Disease Surveillance System for Early Prediction of Multiple
  Chronic Diseases
arxiv_id: '2501.15969'
source_url: https://arxiv.org/abs/2501.15969
tags:
- chronic
- disease
- diseases
- risk
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an explainable disease surveillance system
  that predicts the risk of multiple chronic diseases using routinely available electronic
  health record (EHR) data. The system uses Random Forest models to forecast disease
  risk 3, 6, and 12 months before potential diagnosis, without requiring lab test
  results.
---

# An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases

## Quick Facts
- arXiv ID: 2501.15969
- Source URL: https://arxiv.org/abs/2501.15969
- Reference count: 23
- System predicts chronic disease risk using routine EHR data without lab tests, achieving F1 scores above 75% and AUROC exceeding 80%

## Executive Summary
This paper introduces an explainable disease surveillance system designed to predict multiple chronic diseases using routinely available electronic health record (EHR) data. The system leverages Random Forest models to forecast disease risk 3, 6, and 12 months before potential diagnosis, eliminating the need for lab test results. Trained on integrated U.S. practice data from CureMD's EMR/EHR system, the models demonstrate strong performance across various time horizons and diseases. A key innovation is the rule-engineering framework that translates complex model predictions into understandable clinical explanations, enhancing interpretability for healthcare providers.

## Method Summary
The system employs Random Forest models trained on routinely available EHR data to predict chronic disease risk across multiple time windows (3, 6, and 12 months). The models were developed using data from multiple U.S. practices integrated with CureMD's EMR/EHR system. A novel rule-engineering framework simplifies the Random Forest predictions into interpretable clinical explanations. The entire system was packaged into a practical API that runs efficiently on standard CPUs, facilitating integration with existing EMR systems for real-world clinical deployment.

## Key Results
- F1 scores above 75% for most diseases across different prediction time windows
- AUROC values exceeding 80% across disease predictions
- System runs efficiently on standard CPUs without requiring specialized hardware
- Rule-engineering framework successfully converts complex Random Forest predictions into understandable clinical explanations

## Why This Works (Mechanism)
The system works by leveraging Random Forest's ability to capture complex non-linear relationships in EHR data while maintaining interpretability through the rule-engineering framework. By using routinely available data (excluding lab results), the models can be deployed more broadly across healthcare settings. The multi-time-window approach allows for progressive risk assessment, enabling earlier interventions. The rule-engineering component translates the ensemble model's decision-making process into actionable clinical insights that healthcare providers can understand and trust.

## Foundational Learning
- Random Forest ensemble learning - Why needed: Handles non-linear relationships and provides feature importance; Quick check: Verify model diversity and appropriate hyperparameter tuning
- Explainable AI techniques - Why needed: Converts black-box predictions into clinical explanations; Quick check: Validate rule simplicity and clinical relevance
- EHR data preprocessing - Why needed: Ensures data quality and temporal consistency; Quick check: Confirm handling of missing values and temporal alignment
- Multi-class/multi-label prediction - Why needed: Simultaneously predicts multiple chronic conditions; Quick check: Verify appropriate loss function and evaluation metrics
- API deployment architecture - Why needed: Enables integration with existing EMR systems; Quick check: Test API response times and error handling

## Architecture Onboarding
- Component map: Data Ingestion -> Feature Engineering -> Random Forest Models -> Rule-Engineering Layer -> API Endpoint
- Critical path: Raw EHR data flows through preprocessing to feature extraction, model prediction, rule generation, and API delivery
- Design tradeoffs: Balanced model complexity with interpretability; prioritized routine data availability over comprehensive lab results; optimized for CPU efficiency over GPU acceleration
- Failure signatures: Poor performance with missing demographic data; degraded accuracy with highly imbalanced disease prevalence; increased latency with very large patient populations
- First experiments: 1) Test model performance with different time window configurations, 2) Validate rule explanations against clinical expert review, 3) Benchmark API response times under varying load conditions

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to retrospective EHR data from CureMD EMR system, raising generalizability concerns
- Performance metrics achieved in single healthcare system context require external validation
- Clinical utility of simplified explanations not independently validated by healthcare professionals

## Confidence
- High confidence: Technical implementation of Random Forest models and API integration follows standard machine learning practices
- Medium confidence: Reported performance metrics likely accurate for the specific dataset but generalizability remains uncertain
- Medium confidence: Explainability features are methodologically sound but practical clinical value needs independent assessment

## Next Checks
1. Conduct external validation on EHR data from multiple independent healthcare systems and different geographic regions to assess generalizability
2. Perform prospective clinical studies to evaluate whether the system's predictions and explanations actually improve patient outcomes when integrated into clinical workflows
3. Test the system's performance on underrepresented demographic groups to ensure equitable predictions across diverse populations