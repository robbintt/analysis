---
ver: rpa2
title: 'Evaluating LLMs for Historical Document OCR: A Methodological Framework for
  Digital Humanities'
arxiv_id: '2510.06743'
source_url: https://arxiv.org/abs/2510.06743
tags:
- historical
- russian
- page
- llms
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of evaluating large language
  models for historical document OCR, where traditional metrics fail to capture temporal
  biases and period-specific errors. The authors develop a methodological framework
  that includes contamination-aware dataset creation, novel metrics for historical
  character preservation and archaic insertion detection, and systematic analysis
  of prompt engineering and processing modes.
---

# Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities

## Quick Facts
- arXiv ID: 2510.06743
- Source URL: https://arxiv.org/abs/2510.06743
- Authors: Maria Levchenko
- Reference count: 5
- Primary result: Gemini and Qwen models outperform traditional OCR systems on 18th-century Russian Civil font texts, but all exhibit "over-historicization" by inserting anachronistic archaic characters.

## Executive Summary
This study develops a methodological framework for evaluating large language models on historical document OCR, addressing the failure of traditional metrics to capture temporal biases and period-specific errors. The framework includes contamination-aware dataset creation, novel metrics for historical character preservation and archaic insertion detection, and systematic analysis of prompt engineering and processing modes. Using 1,029 pages of 18th-century Russian Civil font texts, the research evaluates 12 multimodal LLMs and finds that Gemini and Qwen models achieve the lowest character error rates, while all models exhibit systematic insertion of pre-Petrine characters. Post-OCR correction with LLMs consistently degrades performance rather than improving it.

## Method Summary
The study evaluates 12 multimodal LLMs on 1,029 pages of 18th-century Russian Civil font texts using three recognition modes (single-line, full-page, sliding-window 3-line). Models are tested with baseline English prompts, context-enhanced English prompts, and context-enhanced Russian prompts. Evaluation uses standard metrics (CER, WER) plus novel metrics (Historical Character Preservation Rate for period-accurate characters, Archaic Insertion Rate for pre-Petrine characters) and stability testing over 7 days. The dataset is stratified by decade, text density, decorative elements, and subject matter, with ground truth established through TrOCR fine-tuning plus 100% manual correction.

## Key Results
- Gemini-2.5-Pro achieves 3.36% CER in full-page mode vs 9.35% in single-line mode
- All models exhibit "over-historicization," systematically inserting archaic characters from incorrect historical periods
- Post-OCR correction with LLMs consistently degrades performance rather than improving it
- Gemini-2.5-Pro shows lowest stability (CV=0.037) across 7-day testing

## Why This Works (Mechanism)

### Mechanism 1: Contextual Resolution via Full-Page Processing
- Claim: Full-page processing mode yields lower error rates than single-line or sliding-window approaches for most LLMs on historical documents.
- Mechanism: Holistic page view provides contextual information that resolves visual ambiguities; surrounding characters help disambiguate visually similar glyphs that are common in historical typography.
- Core assumption: Models can effectively attend to and integrate information across page-level context without attention dilution.
- Evidence anchors:
  - [section 5]: Table 2 shows Gemini-2.5-Pro achieving 3.36% CER in full-page mode vs 9.35% in single-line mode; similar patterns across most models.
  - [section 2]: References Humphries et al. (2024) and Kim et al. (2025) finding LLMs outperform specialized OCR through holistic page processing.
  - [corpus]: Limited direct corpus support for mechanism; related papers (Benchmarking VLMs on Chinese Ancient Documents) suggest context-aware processing helps historical documents but don't isolate the causal mechanism.
- Break condition: Complex layouts with decorative elements or very high line counts may reduce effectiveness due to attention dilution (Claude-3.5 shows r=0.55 correlation between line count and error).

### Mechanism 2: Over-Historicization via Training Data Conflation
- Claim: LLMs systematically insert archaic characters from incorrect historical periods (pre-Petrine Slavonic in 18th-century Civil font texts) rather than modernizing.
- Mechanism: Models trained on heterogeneous historical Russian without explicit period tags treat distinctive archaic forms as generic "historical text" signals; rare or visually unusual characters become associated with "old document" regardless of actual period accuracy.
- Core assumption: Training corpora contain mixed historical periods (Church Slavonic, pre-reform, post-1918) without temporal metadata that would enable period discrimination.
- Evidence anchors:
  - [abstract]: Models "exhibit 'over-historicization,' systematically inserting archaic characters from incorrect historical periods."
  - [section 6]: "LLMs, lacking explicit period awareness, generalize from a noisy mixture of training data: rare or visually distinctive archaic forms become signals for 'historical text' regardless of actual period accuracy."
  - [corpus]: No direct corpus evidence for this mechanism; related work doesn't address temporal bias specifically.
- Break condition: Explicit period tagging in training data or prompts; constrained decoding to period-appropriate character sets.

### Mechanism 3: Post-OCR Correction Degradation via Editor-Generator Mismatch
- Claim: Providing OCR text to LLMs for post-correction consistently degrades accuracy rather than improving it.
- Mechanism: Chat-tuned models prioritize fluent regeneration over minimal edits; when given image + text, models re-decode from image (using text as weak context) rather than correcting; text-only correction removes visual grounding entirely, increasing hallucination.
- Core assumption: Models lack constrained decoding mechanisms that would enforce minimal edit operations.
- Evidence anchors:
  - [abstract]: "Post-OCR correction with LLMs consistently degrades performance rather than improving it."
  - [section 6]: "Models rarely apply constrained edits; instead they re-decode from the image, using the text as weak context. Text-only correction (without source images) consistently degrades performance."
  - [corpus]: Mixed evidence—PreP-OCR paper suggests post-correction can help with specialized semantic-aware pipelines, but Thomas et al. (2024) notes unpredictable generative outputs remain a challenge.
- Break condition: Constrained decoding architectures that enforce minimal edits; specialized correction models rather than general-purpose chat-tuned LLMs.

## Foundational Learning

- Concept: **Character Error Rate (CER) vs Word Error Rate (WER)**
  - Why needed here: Standard OCR metrics but insufficient alone—they don't capture period-specific errors like archaic character insertion or temporal conflation.
  - Quick check question: Two OCR outputs have identical 5% CER on an 18th-century Russian text. One preserves all 'ѣ' characters but confuses 'т/ш'; the other loses half the 'ѣ' but handles other characters well. Which is better for diplomatic transcription?

- Concept: **Training Data Contamination Risk**
  - Why needed here: LLMs may have seen evaluation texts during pretraining, making benchmark results unreliable; requires contamination-aware dataset protocols.
  - Quick check question: Why might n-gram overlap detection fail to identify contamination for historical documents that exist in modernized orthography online?

- Concept: **Historical Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR)**
  - Why needed here: Novel metrics designed to capture LLM-specific behaviors standard metrics miss—preservation of period-accurate characters vs insertion of anachronistic ones.
  - Quick check question: A model achieves 98% HCPR but 15% AIR. What does this pattern indicate about its training data or internal representations?

## Architecture Onboarding

- Component map:
  Document images (150ppi+ required) -> Processing mode selection (single-line, sliding-window, full-page) -> Prompt engineering (language, context enhancement) -> Model selection (Gemini-2.5-Pro, Qwen-2.5-VL preferred) -> Evaluation layer (CER/WER + HCPR + AIR + stability testing)

- Critical path:
  1. Dataset preparation with contamination control (sources never digitized/published online; kept offline during known pretraining windows)
  2. Stratified sampling across document features (publication period, text density, decorative elements, subject)
  3. Processing mode selection based on layout complexity assessment
  4. Prompt construction in document language with explicit period character list
  5. Direct OCR (no post-correction pipeline)
  6. Multi-metric evaluation with stability testing

- Design tradeoffs:
  - Full-page vs single-line: Full-page provides context (lower error) but risks hallucination on complex layouts; single-line preferred for models highly sensitive to line count (Claude-3.5)
  - Prompt complexity: Context-enhanced Russian prompts help some models (Claude-3.7, Gemini-2.5-Flash show statistically significant CER reductions) but others unaffected (GPT-4.1)
  - Model stability vs availability: Gemini-2.5-Pro highest stability (CV=0.037) and accuracy; API-only access limits reproducibility

- Failure signatures:
  - **Over-historicization**: Insertion of pre-Petrine characters (ѧ, ѡ, ꙋ, ѿ) in 18th-century texts; GPT-4o shows this in 59% of files
  - **ї→i substitution**: Most common error across all models; legitimate period character replaced with modern form
  - **Visual confusion pairs**: т→ш, т→п due to Civil font glyph similarity (see Figure 4)
  - **Hard sign handling**: 'ъ' commonly omitted (Claude), replaced with 'ь' (Gemini), or incorrectly capitalized (Claude-3.5/3.7)
  - **Post-correction degradation**: Accuracy drops when text-only correction applied; models introduce errors not present in original OCR

- First 3 experiments:
  1. **Baseline establishment on pilot sample**: Process 20-page stratified sample through full-page mode with simple Russian prompt; measure CER, WER, HCPR, AIR across Gemini-2.5-Pro, Qwen-2.5-VL, Claude-3.7; establish expected performance ranges for your document collection.
  2. **Processing mode ablation**: Run same documents through single-line, sliding-window, and full-page modes; correlate error rates with line count and layout complexity to identify crossover points where context benefits diminish.
  3. **Over-historicization audit**: Create character-frequency comparison of model outputs vs ground truth; specifically count pre-Petrine character insertions (ѧ, ѡ, ꙋ) and map to linguistic contexts (reflexive verb endings, prepositions) to quantify systematic bias patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the field resolve the trade-off between transparency, reproducibility, and long-term benchmark validity when releasing historical ground-truth datasets?
- Basis in paper: [explicit] The conclusion states, "The trade-off between transparency, reproducibility, and long-term benchmark validity remains an open question for the community."
- Why unresolved: Releasing ground-truth datasets risks their incorporation into future model training corpora, permanently compromising their utility for evaluating "unseen" data.
- What evidence would resolve it: The development of secure, non-public benchmarking consortia or "contamination-proof" evaluation protocols that function even when test data is public.

### Open Question 2
- Question: Can "over-historicization" be effectively mitigated through constrained decoding or specific prompt engineering strategies?
- Basis in paper: [inferred] The paper identifies "over-historicization" (insertion of anachronistic characters) as a systematic bias but only characterizes the error rather than testing a solution.
- Why unresolved: The authors attribute the issue to a "noisy mixture of training data" but do not test if explicit negative constraints (e.g., "do not use pre-Petrine characters") or character whitelisting reduce the error rate.
- What evidence would resolve it: Experiments comparing standard decoding against character-restricted vocabularies or prompts explicitly forbidding specific archaic glyphs.

### Open Question 3
- Question: To what extent do different output formatting constraints (e.g., Markdown vs. JSON vs. raw text) impact the recognition accuracy of multimodal LLMs?
- Basis in paper: [explicit] The limitations section notes that "Alternative output formats... may yield different recognition results and could be further investigated in future work."
- Why unresolved: The study relied primarily on structured (JSON) outputs or programmatic extraction, leaving the interaction between output schema complexity and transcription fidelity unexplored.
- What evidence would resolve it: A comparative study running the same models and documents across different output format conditions to measure the variance in CER/WER.

## Limitations
- Corpus restricted to single language (Russian) and narrow historical window (18th century) using one font type (Civil font)
- Contamination-aware dataset protocols rely on assumptions about pretraining timelines and digitization status
- Over-historicization may represent model-specific bias rather than universal LLM characteristic
- Systematic degradation of post-OCR correction may reflect specific chat-tuned models tested rather than inherent limitations

## Confidence

**High Confidence**:
- Gemini-2.5-Pro and Qwen-2.5-VL outperform traditional OCR systems on 18th-century Russian documents
- Full-page processing mode consistently yields lower error rates than single-line mode for most LLMs
- Post-OCR correction with chat-tuned LLMs degrades performance rather than improving it
- Stability testing shows Gemini-2.5-Pro has lowest variability (CV=0.037) across 7-day testing

**Medium Confidence**:
- "Over-historicization" represents a systematic bias across evaluated models
- Context-enhanced Russian prompts provide statistically significant CER reductions for some models
- Character preservation rates and archaic insertion rates effectively capture period-specific OCR behaviors

**Low Confidence**:
- Contamination-aware dataset protocols completely eliminate pretraining contamination risk
- Over-historicization behavior is universal across all historical document types and languages
- Post-OCR correction cannot be improved through architectural modifications

## Next Checks
1. **Cross-linguistic validation**: Apply the framework to documents from different historical periods and languages (e.g., 16th-century German Fraktur, 19th-century French texts) to assess whether over-historicization and other LLM-specific behaviors persist across linguistic and typographic boundaries.

2. **Architectural intervention testing**: Evaluate whether constrained decoding models, specialized correction architectures, or fine-tuned historical OCR models can overcome the documented degradation in post-OCR correction performance.

3. **Temporal bias quantification**: Conduct systematic analysis of training data composition across the evaluated models to establish whether observed over-historicization correlates with specific historical period distributions in pretraining corpora.