---
ver: rpa2
title: Learning to Defer in Non-Stationary Time Series via Switching State-Space Models
arxiv_id: '2601.22538'
source_url: https://arxiv.org/abs/2601.22538
tags:
- expert
- experts
- time
- learning
- predictive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for learning to defer expert selection
  in non-stationary time series with partial feedback and time-varying expert availability.
  The key innovation is a factorized switching linear dynamical system (SLDS) that
  models expert residuals via a shared global factor and expert-specific idiosyncratic
  states, enabling cross-expert information transfer under censoring.
---

# Learning to Defer in Non-Stationary Time Series via Switching State-Space Models

## Quick Facts
- arXiv ID: 2601.22538
- Source URL: https://arxiv.org/abs/2601.22538
- Reference count: 40
- Primary result: Factorized switching linear dynamical system with shared global factor outperforms contextual bandit baselines in non-stationary time series with partial feedback

## Executive Summary
This paper addresses the challenge of learning to defer expert selection in non-stationary time series with partial feedback and time-varying expert availability. The authors propose a factorized switching linear dynamical system (SLDS) that models expert residuals through a shared global factor and expert-specific idiosyncratic states, enabling cross-expert information transfer under censoring. The method supports dynamic expert entry and pruning, and uses an IDS-inspired routing rule that balances predicted cost against information gain about latent regimes and the shared factor. Experiments on synthetic data and real-world datasets demonstrate improved adaptation to non-stationarity compared to contextual bandit baselines.

## Method Summary
The method models expert residuals using a factorized switching linear-Gaussian state-space model with M discrete regimes, a shared global factor g_t (dimension d_g), and per-expert idiosyncratic states u_t,k (dimension d_α). The discrete regime z_t evolves with context-dependent transition probabilities conditioned on observed context x_t. Expert residuals are generated through a shared loading matrix B_k applied to g_t plus idiosyncratic components. The router uses an IDS-inspired rule that minimizes the squared information ratio between predicted cost gaps and information gain about latent states. The system employs IMM-style filtering with factorized marginals for tractable inference, and supports dynamic expert registry management with initialization and pruning.

## Key Results
- Factorized SLDS with shared global factor outperforms contextual bandit baselines on synthetic and real-world datasets
- Ablation study shows shared factor provides 5-8% cost reduction (13.58 vs 14.68) compared to model without shared component
- Method demonstrates effective adaptation to regime switches and utilization of partial feedback
- Dynamic expert management enables handling of time-varying expert availability

## Why This Works (Mechanism)

### Mechanism 1: Cross-expert information transfer via shared global factor
The shared global factor enables cross-expert information transfer under partial feedback by coupling expert residuals through expert-specific loading matrices B_k. When expert I_t is queried, the observed residual e_t updates g_t via Kalman update, which immediately shifts predictive distributions for all unqueried experts k ≠ I_t through their B_k loadings.

### Mechanism 2: Context-dependent regime transitions for proactive adaptation
Context-dependent regime transitions enable proactive adaptation to non-stationarity before observing residuals. The discrete regime z_t evolves with transition probabilities conditioned on observed context x_t, allowing the router to update regime beliefs using x_t and shift preference toward experts with low predicted cost under the anticipated regime.

### Mechanism 3: IDS-inspired routing for exploration-exploitation tradeoff
IDS-inspired routing trades off immediate cost against information gain about latent states, preventing over-exploitation under partial feedback. The routing rule minimizes ∆_t(k)² / IG_t(k), where ∆_t(k) is the predicted cost gap and IG_t(k) measures mutual information between the joint latent state and the hypothetical residual.

## Foundational Learning

- **Kalman filtering and state-space models**: The core inference maintains Gaussian posteriors over continuous latent states (g_t, u_t,k) conditioned on regime. Kalman updates provide tractable one-step prediction and filtering under linear-Gaussian emissions.
  - Quick check: Can you derive the Kalman gain K_t = Σ_{t|t-1}·H^T·(H·Σ_{t|t-1}·H^T + R)^{-1} for state s_t with observation H·s_t + noise?

- **Bandit feedback (partial observability)**: At each round, only the queried expert's residual is observed; costs for unqueried experts remain hidden. This creates an exploration-exploitation dilemma that motivates the IDS routing rule.
  - Quick check: In a K-armed bandit with partial feedback, why can't we directly evaluate the myopic Bayes selector (Eq. 9)?

- **Interacting Multiple Model (IMM) filtering for switching systems**: The discrete regime z_t requires maintaining a mixture of Gaussians. IMM provides efficient approximate inference by moment-matching after mixing regime-conditioned predictions.
  - Quick check: How does IMM avoid exponential growth in mixture components while tracking a switching linear system?

## Architecture Onboarding

- **Component map**: Input: (x_t, E_t) → Context encoder → Π_θ(x_t) [regime transitions] → z_t [discrete regime] → g_t [shared global factor] + u_t,k [per-expert idiosyncratic state] → Emission: e_t,k ~ N(Φ(x_t)^T·α_t,k, R_{m,k}) where α_t,k = B_k·g_t + u_t,k → Router: Compute C^{pred}_{t,k} and IG_t(k) for k ∈ E_t → IDS rule → Select I_t → Update: Observe e_t = e_{t,I_t} → Kalman update on (g_t, u_{t,I_t}) → Regime posterior w_t

- **Critical path**:
  1. IMM predictive step: Mix regime-conditioned priors from t–1 using Π_θ(x_t), propagate (g_{t-1}, u_{t-1,k}) through dynamics
  2. Predictive cost and information gain: For each available expert, compute mixture-of-Gaussians predictive residual, expected cost, and IG_t(k)
  3. IDS routing: Minimize information ratio; ties go to lower cost
  4. Queried Kalman update: Update joint state s_t = (g_t, u_{t,I_t}), project to factorized marginals, update regime weights
  5. Registry management: Add new experts with initialization prior, prune stale experts

- **Design tradeoffs**:
  - Factorized vs. joint filtering: Projecting to factorized marginals discards cross-covariance Σ^{(m)}_{gu,t|t}, enabling O(|K_t|) memory but losing some correlation information
  - Shared factor dimension d_g: Higher d_g captures more cross-expert structure but risks overfitting; experiments use d_g ∈ {1,2}
  - Staleness horizon Δ_max: Larger values retain experts longer (better for re-entry) but increase memory

- **Failure signatures**:
  - Shared factor collapse: If B_k → 0 for all k, g_t becomes unobservable; ablation shows ~5–8% cost increase
  - Regime non-identifiability: If emission parameters R_{m,k} are too large or identical across regimes, regime posterior flattens and routing becomes near-uniform
  - Exploration stall: If IG_t(k) floors to ϵ_IG frequently, check if Σ^{(m)}_{g,t|t-1} has collapsed

- **First 3 experiments**:
  1. Sanity check on synthetic data: Replicate regime-switching correlation experiment with M=2, d_g=1, d_α=1. Verify selection frequencies track regime switches and shared-factor ablation degrades
  2. Ablation on information gain components: Disable mode-identification term vs shared-factor refinement term. Measure adaptation speed after regime switches
  3. Expert re-entry test: On Melbourne data, artificially remove expert for t ∈ [a,b] and verify pruning removes state at t = a+Δ_max, re-initialization at t=b produces calibrated predictions within ~50 steps via shared-factor coupling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can formal regret guarantees be derived for the IDS-inspired routing rule in the non-stationary time-series setting?
- Basis in paper: The authors state that "this objective is computed under our model-based filtering approximation and is used as a pragmatic exploration criterion rather than as an optimality guarantee" (Section 4.2.3).
- Why unresolved: Standard IDS regret bounds assume stationary bandits, while this setting involves latent regime switching and partial feedback with cross-expert coupling, complicating traditional analyses.
- What evidence would resolve it: A regret bound showing sublinear cumulative cost relative to an oracle or myopic Bayes selector, possibly under assumptions on regime transition rates or expert coupling strength.

### Open Question 2
- Question: What is the quantitative impact of the factorized filtering approximation on long-term routing performance?
- Basis in paper: Section 4.2.2 acknowledges that "This projection discards posterior cross-covariances" between the shared factor and expert-specific states, and Appendix D.3 explains the discarded cross-covariance is generally non-zero.
- Why unresolved: The paper empirically validates the full model against baselines but does not isolate the performance degradation specifically attributable to factorization versus the exact (but intractable) joint posterior.
- What evidence would resolve it: Controlled experiments comparing factorized versus exact filtering on small expert pools where the exact joint posterior remains computable, measuring cumulative cost differences.

### Open Question 3
- Question: How robust is L2D-SLDS to violations of the linear-Gaussian assumptions in real-world expert residual dynamics?
- Basis in paper: The generative model assumes linear-Gaussian emission and dynamics conditioned on the regime. Real expert predictions may exhibit heavy-tailed errors or nonlinear dependence on the shared factor.
- Why unresolved: Experiments use AR/ARIMA experts with approximately Gaussian noise, which aligns with model assumptions; no experiments test model misspecification.
- What evidence would resolve it: Experiments with experts exhibiting nonlinear residual dependence or heavy-tailed noise (e.g., LLM predictions with outlier errors), comparing L2D-SLDS against nonparametric or neural alternatives.

## Limitations
- Factorized filtering approximation discards cross-covariance between shared factor and expert-specific states, potentially accumulating bias in highly correlated systems
- Context-dependent transition model assumes expert cost functions are sufficiently correlated across regimes to justify cross-expert learning
- Relative contribution of mode-identification vs shared-factor refinement in information gain remains unclear without comparative ablation

## Confidence
- **High confidence**: Basic SLDS architecture and IMM filtering implementation are well-established. Factorized state-space formulation and Kalman updates are mathematically sound.
- **Medium confidence**: Shared factor mechanism's benefits are empirically demonstrated but theoretically justified only through Proposition 2. IDS routing extension to switching systems follows established framework but specific decomposition requires more grounding.
- **Low confidence**: Context-dependent transition parameterization (low-rank attention with bottleneck d_attn) is novel and its impact on routing performance is not fully characterized. Registry management heuristics (Δ_max, initialization priors) are empirically chosen without systematic sensitivity analysis.

## Next Checks
1. Run experiments disabling each component of IG_t(k) separately (mode-identification vs shared-factor refinement) to quantify their relative contributions to routing performance.
2. Systematically vary the correlation structure between expert residuals in synthetic experiments to identify the threshold below which the shared factor provides no benefit.
3. Implement the exact joint filter (without factorization) for small-scale problems to measure the bias introduced by discarding Σ^{(m)}_{gu,t|t} in highly correlated regimes.