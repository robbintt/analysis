---
ver: rpa2
title: Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers
arxiv_id: '2510.25372'
source_url: https://arxiv.org/abs/2510.25372
tags:
- prompts
- class
- data
- prompt
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a federated learning framework for vision transformers
  that achieves personalization using only global prompts. It introduces class-specific
  prompts that are adaptively combined into a per-sample Class-Contextualized Mixed
  Prompt (CCMP) using class priors and global class prototypes.
---

# Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers

## Quick Facts
- **arXiv ID**: 2510.25372
- **Source URL**: https://arxiv.org/abs/2510.25372
- **Reference count**: 40
- **Primary result**: Achieves mean accuracy up to 95.46% and worst accuracy up to 84.74% on pathological label splits using global prompts only

## Executive Summary
This paper introduces PEP-FedPT, a federated learning framework for vision transformers that achieves personalization without storing client-specific trainable parameters. The key innovation is the Class-Contextualized Mixed Prompt (CCMP), which generates per-sample prompts by adaptively combining class-specific prompts using weights derived from global class prototypes and client class priors. By leveraging intermediate CLS token representations and prototype-based aggregation, the framework enables each client to create personalized prompts dynamically while sharing only global parameters. Experiments on CIFAR-100, TinyImageNet, DomainNet, and iNaturalist demonstrate consistent improvements over state-of-the-art baselines, particularly in worst-case accuracy on pathological label distributions.

## Method Summary
PEP-FedPT extends visual prompt tuning to federated settings by introducing shared prompts, class-specific prompts, and a CCMP mechanism that generates personalized prompts per sample without client-specific storage. The framework uses global class prototypes computed from intermediate CLS tokens, aggregated across clients with momentum updates, and combines them with client-specific class priors to create soft weights for prompt mixing. The model architecture places one shared prompt at the input layer and CCMP at middle ViT layers (5-7), where CLS tokens show optimal class discrimination. Training follows standard federated averaging with periodic prototype aggregation, achieving personalization through dynamic prompt generation rather than storing client-specific parameters.

## Key Results
- Achieves mean accuracy up to 95.46% on CIFAR-100 pathological split
- Worst accuracy reaches 84.74% (vs 75.67% for pFedPG baseline)
- Maintains strong performance under Dirichlet non-IID splits (β=0.3)
- Demonstrates robust generalization to heldout clients in split evaluation
- DP noise experiments show only 1-2% accuracy drop with ϵ=0.2

## Why This Works (Mechanism)

### Mechanism 1: Class-Contextualized Mixed Prompt (CCMP) Enables Zero-Storage Personalization
For each input x, compute soft weights s_c by taking similarity between the input's CLS token at layer l-1 and global class prototypes μ_c, scaled by client k's class prior δ^k_c. The CCMP is then m = Σ_c s_c · p_c where p_c are class-specific prompts. This creates client-specific prompts purely from global information and local statistics.

**Core assumption**: CLS tokens at intermediate layers carry sufficient class-discriminative information; class priors accurately reflect local data distributions.

**Evidence anchors**:
- [abstract] "CCMP adaptively combines class-specific prompts using weights derived from global class prototypes and client class priors."
- [section 4.2] Eq. 13-15 formalize the weight computation; Figure 2 shows Top-5 accuracy of 70-90% using prototype similarity alone at layers 6-10.
- [corpus] FedDPG and CAPT explore class-aware prompt tuning in FL, but neither uses prototype-guided mixing.

**Break condition**: If CLS token prototypes fail to discriminate classes (e.g., collapse to uniform representations), mixing weights become meaningless and personalization degrades to noise.

### Mechanism 2: Layer-Separated Prompts Optimize Generalization-Personalization Tradeoff
Placing shared prompts at early layers and CCMP at middle layers (5-7) captures both domain-invariant low-level features and class-specific semantic context. Early ViT layers produce uniformly distributed representations across classes, making them suitable for shared prompts that generalize. Middle layers (5-7) show structured class separation in CLS tokens, enabling effective CCMP contextualization.

**Core assumption**: Pretrained ViT layer representations follow the assumed distribution pattern (uniform early → structured middle).

**Evidence anchors**:
- [section 4.1] "The representations in the initial layer of pre-trained ViT are uniformly distributed on the manifold."
- [section A.4.6, Table 12] CCMP at layers 1-3 achieves 90.05% vs. 95.46% at layers 5-7 vs. 93.55% at layers 8-10 on CIFAR-100 pathological split.
- [corpus] Weak evidence—related works don't analyze layer-wise prompt placement systematically.

**Break condition**: If the pretrained backbone's layer semantics differ significantly, optimal CCMP placement may shift.

### Mechanism 3: Prototype Aggregation with Momentum Stabilizes Global Class Statistics
Federated averaging of CLS token prototypes with momentum updates (Eq. 11-12) produces robust global class representations across heterogeneous clients. Clients compute local prototypes μ^k_c by averaging CLS tokens per class. Server aggregates periodically and applies momentum update μ_c ← ρ·μ_c^(r-1) + (1-ρ)·μ̂_c. This smooths noise from heterogeneous data distributions.

**Core assumption**: Class prototypes remain meaningful across domain shifts; periodic updates provide sufficient freshness.

**Evidence anchors**:
- [section 4.2] Eq. 10-12 define prototype computation and aggregation; Sec A.3.2 specifies R and ρ hyperparameters.
- [section A.4.1] Differential privacy noise (ϵ=0.2) on prototypes causes only 1-2% accuracy drop, suggesting prototype robustness.
- [corpus] Prototype-based FL methods exist (referenced in Sec 2.1), but CLS-token prototype aggregation for prompt tuning is novel.

**Break condition**: If class priors are severely skewed (e.g., missing classes at clients), prototypes for absent classes remain stale or zero.

## Foundational Learning

- **Concept: Visual Prompt Tuning (VPT)**
  - **Why needed here**: PEP-FedPT builds on VPT—prompts are trainable tokens prepended to ViT input sequences. Without this, the shared/class prompt architecture won't make sense.
  - **Quick check question**: Can you explain how prompts are inserted into a ViT forward pass and which parameters are frozen vs. trainable?

- **Concept: Federated Averaging (FedAvg)**
  - **Why needed here**: PEP-FedPT uses standard FedAvg for prompt aggregation. Understanding how local updates combine into global models is essential for debugging convergence.
  - **Quick check question**: Given n clients with local parameters θ_k, how does FedAvg compute the global θ^{t+1}?

- **Concept: CLS Token Semantics in ViTs**
  - **Why needed here**: The entire prototype mechanism depends on CLS tokens encoding class-relevant information at intermediate layers. Misunderstanding this leads to wrong design choices.
  - **Quick check question**: What does the CLS token represent in a Vision Transformer, and how does its semantic content evolve across layers?

## Architecture Onboarding

- **Component map**:
  - Shared Prompts (P^S) at layer 0 input → CCMP at layers 5,6,7 → Classification Head (H) → Output
  - Class-Specific Prompts (P^C) available for mixing in CCMP → Frozen ViT Backbone → CLS tokens for prototype computation

- **Critical path**:
  1. Warm-start: Server samples S_0 clients to compute initial prototypes
  2. Broadcast: Server sends P^S, P^C, H, and μ to sampled clients S_t
  3. Local Training: Each client computes CCMP per sample, trains for E epochs
  4. Upload: Clients send updated P^S, P^C, H and local prototypes back
  5. Aggregation: Server applies FedAvg to prompts/heads; momentum update to prototypes
  6. Repeat for T rounds

- **Design tradeoffs**:
  - CCMP layers (l): Earlier (1-3) = less class info in CLS tokens; later (8-10) = prompts too shallow to learn representations. Default: 5, 6, 7.
  - Number of shared prompts (|S|): Table 10 shows 1→5→10 prompts yield only marginal gains (~1-2%). Default: 1.
  - Update period (R): Larger R = less communication overhead but staler prototypes.
  - Temperature (τ): Lower = sharper softmax; too low causes gradient issues. Default: 0.05.
  - Momentum (ρ): Higher = more stability but slower adaptation to new data.

- **Failure signatures**:
  - Prototype collapse: All μ_c converge to similar vectors → CCMP weights uniform → no personalization. Diagnose by checking intra-class vs. inter-class prototype distances.
  - Class prior mismatch: If local priors δ^k_c don't reflect test distribution, heldout accuracy drops sharply. Compare participating vs. heldout accuracy.
  - CCMP placement error: Accuracy at layers 1-3 significantly lower than 5-7 → CLS tokens lack discriminative info. Verify via Figure 2-style analysis.
  - Privacy leakage: Prototypes are aggregated statistics, not raw data, but class-level info can still leak. Monitor with DP noise experiments.

- **First 3 experiments**:
  1. **Prototype quality audit**: For each CCMP layer, compute Top-5 accuracy using prototype nearest-neighbor classification. If accuracy <50% at layer 5, reconsider placement or prototype computation.
  2. **Class prior ablation**: Run PEP-FedPT with uniform priors (δ^k_c = 1/|C|) vs. true priors. Expect 10%+ drop on pathological splits if priors matter.
  3. **Heldout generalization test**: Train with 90% clients, test on 10% unseen. Compare PEP-FedPT vs. pFedPG. If heldout accuracy <80% of participating accuracy, prototype generalization is failing.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can PEP-FedPT be adapted for semi-supervised or unsupervised federated learning where labeled data is scarce or unavailable for estimating class priors and centroids?
- **Basis in paper**: [explicit] The authors state that the reliance on empirical estimation of class priors and centroids requires labeled data, making adaptation to unsupervised settings "non-trivial" and a direction for future research.
- **Why unresolved**: The current CCMP generation mechanism fundamentally relies on supervised signals (class labels) to aggregate cls-token prototypes and compute priors.
- **What evidence would resolve it**: A modified framework using pseudo-labels or unsupervised clustering to estimate prototypes, evaluated on datasets with limited labels.

### Open Question 2
- **Question**: Can the framework provide formal differential privacy guarantees for the transmitted prototypes without nullifying the accuracy gains of the CCMP mechanism?
- **Basis in paper**: [inferred] The paper acknowledges that without formal protection, strict privacy guarantees are challenging, and while DP noise was tested empirically, a theoretical bound was not established.
- **Why unresolved**: The trade-off between the noise required for formal (ϵ, δ)-differential privacy and the precision needed for meaningful prompt mixing remains uncharacterized.
- **What evidence would resolve it**: A theoretical analysis proving convergence and utility bounds under specific privacy budgets.

### Open Question 3
- **Question**: How robust is the prototype aggregation mechanism in "cold-start" scenarios where specific classes are entirely absent from the participating client subset during specific rounds?
- **Basis in paper**: [inferred] The method handles missing data by setting prototypes to zero, which may lead to dead prompts if certain classes are not observed by the participating clients during the update period.
- **Why unresolved**: The paper evaluates heterogeneity but assumes the collective client pool covers all classes; it does not address the stability of the global prototype update when D_c = 0 for extended periods.
- **What evidence would resolve it**: Convergence analysis and performance metrics on data splits where subsets of classes are withheld from the federated network for multiple rounds.

## Limitations
- Prototype quality depends on CLS tokens encoding class-discriminative information, but this assumption lacks external validation
- Layer-wise prompt placement optimization is based on limited comparisons (layers 1-3, 5-7, 8-10) with modest performance differences
- Warm-start phase may introduce initialization bias in pathological splits where some classes have only one or two clients initially

## Confidence
- **High confidence**: The empirical results showing PEP-FedPT outperforming baselines on pathological and Dirichlet splits, particularly the worst-case accuracy improvements (up to 84.74% vs 75.67% for pFedPG), are well-supported by experimental tables and appear reproducible given the detailed hyperparameter specifications.
- **Medium confidence**: The claim that CCMP achieves personalization without storing client-specific parameters is mechanistically sound based on the prototype-similarity weight computation, but depends critically on unstated assumptions about CLS token behavior and class prior stability that lack external validation.
- **Low confidence**: The assertion that layer 5-7 is optimal for CCMP placement rests primarily on Table 12 comparisons, but the performance differences between layer ranges are relatively modest (95.46% vs 93.55%), suggesting the mechanism may be more robust to placement than claimed.

## Next Checks
1. **Prototype quality validation**: Replicate the Figure 2 analysis for all CCMP layers on CIFAR-100 pathological split, measuring Top-5 accuracy of prototype-based nearest-neighbor classification. If accuracy at layer 5 falls below 60%, the CCMP mechanism's foundation is compromised.

2. **Class prior ablation study**: Run PEP-FedPT with uniform class priors (δ^k_c = 1/|C|) versus true local priors on pathological splits. If accuracy drops more than 10%, class prior accuracy is critical; if drop is minimal, the mechanism may be more robust than designed.

3. **Heldout generalization test**: Train PEP-FedPT on 90% of clients, test on heldout 10% unseen clients. Compare heldout accuracy to participating client accuracy. If heldout accuracy is less than 80% of participating accuracy, prototype generalization is failing despite the paper's claims.