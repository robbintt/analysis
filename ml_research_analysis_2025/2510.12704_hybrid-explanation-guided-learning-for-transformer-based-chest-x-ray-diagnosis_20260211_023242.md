---
ver: rpa2
title: Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis
arxiv_id: '2510.12704'
source_url: https://arxiv.org/abs/2510.12704
tags:
- attention
- learning
- h-egl
- alignment
- self-supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the issue of spurious correlations in transformer-based
  medical imaging models, which can lead to biases and limited generalization. To
  mitigate this, the authors propose a Hybrid Explanation-Guided Learning (H-EGL)
  framework that combines self-supervised and human-guided attention alignment.
---

# Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis

## Quick Facts
- arXiv ID: 2510.12704
- Source URL: https://arxiv.org/abs/2510.12704
- Authors: Shelley Zixin Shu; Haozhe Luo; Alexander Poellinger; Mauricio Reyes
- Reference count: 20
- Primary result: H-EGL achieves 89.3% AUC, 69.4% F1, and 58.3% MCC on chest X-ray classification while improving attention alignment and robustness.

## Executive Summary
Transformer-based models for medical imaging often learn spurious correlations, reducing generalization. This paper proposes Hybrid Explanation-Guided Learning (H-EGL), which combines human-guided and self-supervised attention alignment to mitigate these issues. H-EGL uses a hybrid loss function that enforces both expert annotation alignment and class-distinctive attention map separation. Evaluated on chest X-ray classification, H-EGL outperforms state-of-the-art EGL methods in both accuracy and attention map quality.

## Method Summary
H-EGL integrates a Vision Transformer (ViT) encoder with a frozen Med-KEBERT text encoder and a Transformer Query Network decoder. The model processes chest X-ray images and disease labels to generate class-specific attention maps. The hybrid loss function combines three components: classification loss (L_CE), human-AI alignment loss (L_HA) using penalized Dice loss against expert bounding boxes, and discriminative attention learning loss (L_DAL) that minimizes cosine similarity between class attention maps. The model is trained with AdamW optimizer (lr=1e-5, batch=32) for 1000 epochs with early stopping, evaluated on the ChestXDet dataset.

## Key Results
- Achieved 89.3% AUC, 69.4% F1, and 58.3% MCC on chest X-ray classification
- Outperformed state-of-the-art EGL methods in both classification accuracy and generalization capability
- Produced attention maps better aligned with human expertise while maintaining high accuracy
- Demonstrated robustness under Gaussian noise perturbations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enforcing separability between class-specific attention maps reduces spurious feature reliance.
- **Mechanism:** DAL minimizes cosine similarity between attention maps of different classes, forcing the model to learn class-specific anatomical features rather than shared shortcuts.
- **Core assumption:** Distinct pathologies manifest in spatially distinct feature distributions, and high similarity between class maps indicates shortcut learning.
- **Evidence anchors:** [section 2] Equation 3 defines L_DAL as minimization of pairwise cosine similarity; [section 4] Table 1 shows H-EGL outperforming baselines.
- **Break condition:** If pathologies frequently co-occur in the same spatial regions, strict similarity minimization may conflict with clinical reality.

### Mechanism 2
- **Claim:** Hybrid supervision balances the rigidity of human annotations with the flexibility of self-supervision.
- **Mechanism:** L_HA anchors the model to known pathology while L_DAL allows exploration of discriminative features outside annotated regions, preventing overfitting to potentially incomplete annotations.
- **Core assumption:** Expert annotations may be incomplete or sparse, and the model can find valid discriminative signals in unlabeled regions.
- **Evidence anchors:** [section 5] Notes that fully supervised methods can be rigid; [section 4] Table 1 shows hybrid approach outperforms both pure human and pure self-supervised baselines.
- **Break condition:** If expert annotations are noisy or incorrect, L_HA will enforce false constraints conflicting with L_DAL.

### Mechanism 3
- **Claim:** Attention alignment improves robustness to input perturbations.
- **Mechanism:** Forcing predictions to ground in specific pathological regions reduces sensitivity to global image noise or artifacts by creating tighter focus less susceptible to distribution shift.
- **Core assumption:** True pathological features are more robust to noise than spurious correlations the model would otherwise learn.
- **Evidence anchors:** [section 4] Figure 2 shows H-EGL remains superior under Gaussian noise; [section 5] Notes strong robustness under noisy test conditions.
- **Break condition:** If noise specifically occludes the pathological regions the model fixates on, performance may drop more sharply than in less constrained models.

## Foundational Learning

- **Concept:** Vision Transformer (ViT) Attention Mechanics
  - **Why needed here:** The paper relies on extracting and manipulating attention maps directly from the transformer decoder.
  - **Quick check question:** Can you explain how the decoder's cross-attention weights are reshaped to form the 2D attention map A_i for a specific class?

- **Concept:** Multi-label Classification Loss Composition
  - **Why needed here:** The H-EGL objective function is a weighted sum (L_CE + αL_HA + βL_DAL). Understanding how these gradients interact is critical for tuning.
  - **Quick check question:** If you set β too high, what might happen to classification accuracy if classes share significant visual overlap?

- **Concept:** Cosine Similarity in Feature Space
  - **Why needed here:** This is the core metric for the self-supervised DAL loss.
  - **Quick check question:** In the context of Equation 4, does minimizing cosine similarity force attention maps to be spatially disjoint or just linearly independent?

## Architecture Onboarding

- **Component map:** Image → ViT-B Encoder → Transformer Query Network Decoder → Classification Head + Attention Map Generator
- **Critical path:**
  1. Input Image + Class Labels
  2. Forward pass through ViT and Text Encoder
  3. Decoder generates class-specific Attention Maps (A)
  4. Compute L_CE (Prediction vs. Truth)
  5. Compute L_HA (Attention A vs. Bounding Box M)
  6. Compute L_DAL (Similarity between A_i and A_j for all pairs)
  7. Weighted sum of losses → Backprop

- **Design tradeoffs:**
  - **Computational Cost:** DAL calculates pairwise similarity for all classes (C(C-1)/2 pairs). Scaling to >20 classes may require approximation or sampling strategies.
  - **Annotation Reliance:** Framework relies on "weak" supervision (bounding boxes/masks) for L_HA. Without localization data, limited to α=0 (DAL-only) configuration.

- **Failure signatures:**
  - **Attention Collapse:** Maps become uniform/grey (model ignores losses)
  - **Over-regularization:** Maps become extremely sparse (single pixel) to satisfy L_HA or orthogonalize too aggressively for L_DAL
  - **Shortcut Retention:** If α and β are too low, model achieves high accuracy but A highlights image corners or text tags

- **First 3 experiments:**
  1. **Baseline Verification:** Run base KAD model (no EGL) to confirm presence of spurious attention
  2. **Ablation Study:** Run H-EGL with α=0 (DAL only) and β=0 (Human only) to verify hybrid approach yields higher AUC/robustness than sum of parts
  3. **Noise Robustness Test:** Evaluate trained model on validation set with added Gaussian noise (σ=0.05) to verify improved robustness over standard training

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can dynamic mechanisms be developed to automatically optimize the relative weighting between self-supervision and human alignment during training?
- **Basis in paper:** [Explicit] The Discussion section states: "Inspired by policy learning strategies, future work will explore dynamic mechanisms to optimize the degree of self-supervision and human alignment during training..."
- **Why unresolved:** Current H-EGL uses static hyperparameters (α and β set to 1.0) to balance losses. Unknown if adaptive weighting could yield better convergence or robustness.
- **What evidence would resolve it:** Ablation study showing adaptive weighting strategy (based on training epochs or validation performance) results in statistically significant improvements in AUC or generalization gap compared to static baseline.

### Open Question 2
- **Question:** Does the H-EGL framework maintain its superior performance and annotation efficiency when applied to larger, multi-institutional datasets or different medical imaging modalities?
- **Basis in paper:** [Explicit] The Conclusion explicitly notes: "Future work will extend to larger datasets and explore dynamic alignment strategies to further enhance interpretability and generalization in clinical tasks."
- **Why unresolved:** Study validated on ChestXDet (3,578 patients). Performance on larger, more heterogeneous datasets (e.g., MIMIC-CXR) or non-radiological modalities remains untested.
- **What evidence would resolve it:** Successful replication of H-EGL results (specifically reduction in generalization gap) on MIMIC-CXR or non-X-ray imaging data (CT or MRI).

### Open Question 3
- **Question:** Is the proposed Discriminative Attention Learning (DAL) effective when applied to non-transformer architectures, such as Convolutional Neural Networks (CNNs)?
- **Basis in paper:** [Inferred] The Methodology section claims "H-EGL is architecture-agnostic and flexible," but implementation and experiments rely exclusively on Vision Transformer (ViT).
- **Why unresolved:** While loss functions are theoretically generic, DAL was designed to exploit specific attention mechanism of ViTs. Unclear if "class-distinctive attention" constraint translates effectively to CNN feature maps or Grad-CAM outputs.
- **What evidence would resolve it:** Comparative evaluation of H-EGL applied to standard CNN backbones (ResNet, DenseNet) to verify if self-supervised DAL component still provides performance gains over standard baselines.

## Limitations

- Evaluation relies on single dataset (ChestXDet) with limited size (3,543 images); generalizability to other modalities and larger datasets untested
- Choice of α and β weights (both set to 1.0) appears arbitrary without sensitivity analysis
- Computational overhead of DAL scales quadratically with number of classes, potentially limiting practical deployment

## Confidence

- **High Confidence:** Core architectural design combining human and self-supervised attention guidance is technically sound and mathematical formulation of DAL is clearly defined
- **Medium Confidence:** Reported performance improvements (89.3% AUC, 69.4% F1) are promising but require independent replication given single-dataset evaluation
- **Medium Confidence:** Qualitative improvements in attention map alignment with expert annotations are compelling but subjective without quantitative localization metrics

## Next Checks

1. **Ablation Study:** Systematically vary α and β (0.0, 0.1, 0.5, 1.0, 2.0) to determine optimal weighting and test sensitivity to hyperparameter choices
2. **Cross-Dataset Evaluation:** Evaluate H-EGL on independent chest X-ray dataset (CheXpert or MIMIC-CXR) to assess generalization beyond ChestXDet
3. **Scalability Test:** Measure computational overhead and performance as class count increases (10→20→50 pathologies) to validate DAL's practical scalability