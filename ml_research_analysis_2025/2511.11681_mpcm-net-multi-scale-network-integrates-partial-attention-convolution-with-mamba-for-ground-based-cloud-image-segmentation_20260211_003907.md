---
ver: rpa2
title: 'MPCM-Net: Multi-scale network integrates partial attention convolution with
  Mamba for ground-based cloud image segmentation'
arxiv_id: '2511.11681'
source_url: https://arxiv.org/abs/2511.11681
tags:
- cloud
- segmentation
- feature
- attention
- multi-scale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes MPCM-Net, a multi-scale network for ground-based
  cloud image segmentation that integrates partial attention convolutions with Mamba
  architectures. The method addresses key limitations in existing approaches, including
  inadequate handling of multi-scale context, lack of inter-channel feature interoperability,
  and inefficient decoder designs that fail to establish global interdependencies
  among hierarchical local features.
---

# MPCM-Net: Multi-scale network integrates partial attention convolution with Mamba for ground-based cloud image segmentation

## Quick Facts
- arXiv ID: 2511.11681
- Source URL: https://arxiv.org/abs/2511.11681
- Reference count: 40
- Primary result: Proposes MPCM-Net for ground-based cloud image segmentation with 90.6% precision, 91.1% recall, and 64.8% MIoU

## Executive Summary
This paper introduces MPCM-Net, a multi-scale network that integrates partial attention convolutions with Mamba architectures for ground-based cloud image segmentation. The method addresses key limitations in existing approaches, including inadequate handling of multi-scale context, lack of inter-channel feature interoperability, and inefficient decoder designs that fail to establish global interdependencies among hierarchical local features. The authors propose a novel encoder-decoder architecture that combines partial attention mechanisms with linear-complexity state space models to achieve superior segmentation performance while maintaining computational efficiency. Extensive experiments on a newly introduced CSRC dataset demonstrate significant improvements over state-of-the-art methods.

## Method Summary
The proposed MPCM-Net architecture consists of an encoder (MPAC) and decoder (MMD) connected through a multi-scale feature fusion mechanism. The encoder employs Partial Multi-scale Attention Convolution (MPAC) blocks that split feature channels, processing one subset with standard convolutions and another with partial attention mechanisms (ParCM for coordinate attention and ParSM for spatial attention). The final encoder stage uses a Multi-scale Partial Attention (MPA) block with Softmax-like Linear Attention (SLA) to extract discriminative features. The decoder employs a Multi-scale Mamba Decoder (MMD) with Multi-scale Mamba Blocks (M2B) that use 2D-Selective Scan Mechanisms (SSHD) to maintain linear complexity while enabling deep feature aggregation across spatial and scale dimensions. The model is trained on the newly introduced CSRC dataset using a compound loss function combining focal and dice losses.

## Key Results
- Achieves 90.6% precision, 91.1% recall, and 64.8% MIoU on the CSRC dataset
- Outperforms state-of-the-art methods including U-Net and DeepLabv3+ by 18-24% in MIoU
- Maintains efficient inference speed with 24.6ms inference time while achieving superior accuracy
- Ablation studies confirm the effectiveness of each proposed component (MPAC, MMD, SLA)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Processing only a portion of feature channels with attention mechanisms while applying standard convolutions to the rest reduces computational redundancy while preserving the global context required for multi-scale cloud segmentation.
- **Mechanism:** The encoder splits input channels using a ratio R=1/4. The smaller subset (X_{C×R}) undergoes standard 3×3 convolution for local aggregation, while the larger subset (X_{C×(1-R)}) is processed by Coordinate Attention (ParCM) or Spatial Attention (ParSM). This reduces FLOPs by limiting expensive attention operations to a channel subset.
- **Core assumption:** Assumes that cloud spatial-channel dependencies can be effectively captured by processing a reduced channel subset, and that the remaining channels contain redundant information resolvable via standard convolution.
- **Evidence anchors:** [abstract] "...extract discriminative features with reduced computational complexity." [section III.C.1] "The subset of X_{C×R} undergoes a 3×3 convolution... Concurrently, the complementary X_{C×(1-R)} leverages channel attention mechanisms..." [corpus] "Partial Convolution Meets Visual Attention" (arXiv:2503.03148) supports the efficacy of partial convolution in reducing memory access frequency.
- **Break condition:** If critical feature correlations exist strictly across the channels separated by the split, the partial mechanism might sever necessary dependencies, degrading accuracy.

### Mechanism 2
- **Claim:** Introducing a Softmax-like Linear Attention (SLA) potentially restores the amplitude sensitivity lost in standard linear attention, improving feature discriminability for the final encoder stage without quadratic complexity.
- **Mechanism:** Standard linear attention removes the softmax, losing the ability to distinguish query magnitudes. SLA adds a learnable scaling factor (α) and offset (β) to the linear attention score (Eq. 12). This allows high-magnitude queries to contribute more significantly, mimicking the "winner-takes-all" dynamic of softmax attention while maintaining O(N) complexity.
- **Core assumption:** Assumes that the performance gap between linear and softmax attention is primarily due to the inability to propagate query amplitude information.
- **Evidence anchors:** [section III.C.3] "SLA preserves the amplitude propagation capability characteristic of softmax attention... achieving dual advantages in performance and complexity." [section IV.E Table VII] Shows SLA outperforming standard Self-Attention (SA) in MIoU (64.8% vs 64.3%) while reducing inference time.
- **Break condition:** If the learned parameters α and β fail to generalize to out-of-distribution feature magnitudes, the attention distribution may become unstable or flat.

### Mechanism 3
- **Claim:** Employing a 2D selective scan (Mamba) in the decoder appears to mitigate contextual loss during upsampling by establishing global dependencies with linear complexity, rather than the quadratic complexity of self-attention.
- **Mechanism:** The Multi-scale Mamba Block (M2B) uses a Spatial-Semantic Hybrid Domain (SSHD). It partitions channels; one branch processes features via 2D-SSM (scanning in 4 directions to capture global context), and the other uses Hybrid Attention (channel + spatial). This hybrid approach aggregates long-range dependencies necessary for reconstructing blurred cloud boundaries.
- **Core assumption:** Assumes that the compressed state representation of Mamba is sufficient to retain critical semantic details that are typically lost in standard CNN decoders.
- **Evidence anchors:** [abstract] "...M2B is employed to mitigate contextual loss through a SSHD that maintains linear complexity..." [section IV.E Table VIII] Ablation shows removing MMD drops MIoU from 64.8% to 61.6%. [corpus] "ECMNet" (arXiv:2506.08629) provides corroborating evidence that CNN-Mamba hybrids effectively handle global context in segmentation.
- **Break condition:** If the local feature details lost during the encoder's downsampling are too fine-grained, the Mamba state compression might fail to recover them, leading to boundary artifacts.

## Foundational Learning

- **Concept: State Space Models (SSMs) / Mamba**
  - **Why needed here:** The decoder relies on Mamba (2D-SSM) to replace self-attention for global context aggregation. You must understand how SSMs compress sequential history into a state to see why they offer linear complexity.
  - **Quick check question:** How does the "selective scan" mechanism in Mamba differ from the global matrix multiplication in Transformers regarding memory consumption?

- **Concept: Linear vs. Softmax Attention**
  - **Why needed here:** The ParAM module uses a custom linear attention variant (SLA). Understanding the trade-offs (speed vs. magnitude sensitivity) is crucial to grasping why the custom α, β parameters were added.
  - **Quick check question:** Why does standard linear attention fail to differentiate between a high-confidence query and a low-confidence query?

- **Concept: Partial Convolution / Channel Splitting**
  - **Why needed here:** The encoder (MPAC) is built on splitting channels to reduce FLOPs. Understanding how information flows through separate (Conv vs. Attention) branches is key to debugging feature extraction.
  - **Quick check question:** In the ParCM module, which branch is responsible for capturing the positional information of cloud clusters?

## Architecture Onboarding

- **Component map:**
  - Raw Image -> MPAC (MPC blocks with ParCM/ParSM) -> MPA (ParAM + ParSM) -> MMD (M2B with SSHD) -> Final 1×1 Conv for segmentation mask

- **Critical path:**
  1. Channel Split: Verify the 1/4 split ratio is correctly applied in both MPAC and SSHD
  2. The Scan: Ensure the 2D-SSM in the decoder performs the 4-direction scan correctly; a faulty scan direction will destroy global context
  3. Fusion: The concatenation of Conv-processed and Attention-processed channel subsets must be seamless

- **Design tradeoffs:**
  - Accuracy vs. Speed: The paper claims a balance (Table IV). The tradeoff is using Mamba/Linear Attention instead of heavy Self-Attention, accepting a potential (but mitigated) drop in theoretical representational capacity for faster inference
  - Complexity vs. Granularity: The CSRC dataset introduces "complex-scale" and "radiative" labels. The model trades off a simpler binary task for a more complex 4-class segmentation to support PV forecasting

- **Failure signatures:**
  - "Ghosting" artifacts: Mentioned in the paper (Problem Description); indicates failure to capture temporal/semantic consistency in boundaries
  - Boundary blur: If the M2B (SSHD) is removed or undertrained, cloud boundaries near the sun (radiation source) will bleed into the background
  - Misclassification of scale: If MPAC is removed (Ablation Row 1, Table VIII), variable-scale clouds are often missed

- **First 3 experiments:**
  1. Sanity Check - Overfit: Train on a tiny subset of CSRC (e.g., 10 images) to ensure the MPAC/M2B pipeline can memorize the data (loss converges to near zero)
  2. Ablation - Mamba: Run the model with and without the M2B (SSHD) block on the validation set. Compare MIoU specifically for the "Sun" and "Boundary" regions to verify context recovery
  3. Attention Analysis: Visualize Grad-CAM for the ParAM block to confirm that SLA is actually focusing on cloud structures and not background noise, comparing it against standard Self-Attention

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can MPCM-Net be effectively adapted to directly improve ultra-short-term photovoltaic (PV) power forecasting accuracy?
- **Basis:** [explicit] The Conclusion states: "Future work will focus on extending MPCM-Net to ultra-short-term PV power forecasting tasks, further enhancing its practical utility..."
- **Why unresolved:** The current study validates performance only on the segmentation task (mIoU, Precision) using the CSRC dataset, without implementing the downstream forecasting pipeline.
- **Evidence:** Quantitative forecasting metrics (e.g., RMSE, MAE) derived from a system using MPCM-Net segmentation maps as input compared to systems using other segmentation methods.

### Open Question 2
- **Question:** Does the explicit segmentation of the "Sun" class (radiative source) correlate more strongly with ground-truth irradiance measurements than standard binary cloud/sky segmentation?
- **Basis:** [inferred] The paper introduces the CSRC dataset with a specific "Sun" class to address "radiative properties," but validates the method only via pixel-wise segmentation accuracy rather than physical irradiance prediction.
- **Why unresolved:** While the segmentation of the sun region is visually accurate, the paper does not quantitatively demonstrate that this fine-grained class enhances the estimation of solar irradiance for PV applications.
- **Evidence:** A correlation analysis comparing the area/intensity of the segmented "Sun" class against pyranometer data.

### Open Question 3
- **Question:** How does MPCM-Net perform on established public datasets (e.g., SWIMSEG, TLCDD) that lack the specific radiative and color attributes found in CSRC?
- **Basis:** [inferred] The experimental section (IV.D) evaluates performance exclusively on the newly proposed CSRC dataset, leaving cross-dataset generalization unverified.
- **Why unresolved:** Architectural components like the SSHD are optimized for the specific challenges of CSRC; performance on standard binary datasets remains unknown.
- **Evidence:** Benchmarking results (Precision, Recall) of MPCM-Net on the SWIMSEG or TLCDD datasets compared to existing SOTA methods.

## Limitations
- The 1/4 channel split ratio in partial attention mechanisms lacks theoretical justification for optimal performance across diverse cloud image distributions
- The CSRC dataset's train/val/test split ratios and total image count are unspecified, making reproducibility challenging
- SLA attention's learned parameters (α, β) are initialized without clear calibration, potentially limiting generalization to images with varying feature magnitude distributions

## Confidence
- **High Confidence:** The computational complexity reduction claims (linear vs quadratic) and the overall architecture design are well-founded based on established SSM and partial convolution literature
- **Medium Confidence:** The ablation results showing MPCM-Net's superiority over baselines are convincing, but the specific hyperparameter choices (split ratio, SLA parameters) may not generalize optimally
- **Low Confidence:** The claim that SLA attention "restores amplitude sensitivity" requires further empirical validation across diverse datasets, as the mechanism's behavior with out-of-distribution feature magnitudes remains untested

## Next Checks
1. **Channel Split Sensitivity Analysis:** Systematically vary the channel split ratio (1/4, 1/3, 1/2) and measure the impact on both computational efficiency and segmentation accuracy to identify optimal partitioning
2. **SLA Generalization Test:** Evaluate SLA attention on a held-out dataset with deliberately varied feature magnitude distributions to verify the learned α, β parameters maintain stable attention distributions
3. **Cross-Dataset Transferability:** Test MPCM-Net's performance on established cloud segmentation datasets (SWIMSEG, TLCDD) without retraining to assess architectural generalizability beyond the CSRC dataset