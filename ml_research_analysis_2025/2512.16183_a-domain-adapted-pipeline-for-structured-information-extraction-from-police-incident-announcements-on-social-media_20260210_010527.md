---
ver: rpa2
title: A Domain-Adapted Pipeline for Structured Information Extraction from Police
  Incident Announcements on Social Media
arxiv_id: '2512.16183'
source_url: https://arxiv.org/abs/2512.16183
tags:
- extraction
- information
- police
- data
- structured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a domain-adapted pipeline for structured information
  extraction from police incident announcements on social media. The pipeline combined
  task-specific prompt engineering with LoRA-based fine-tuning of the Qwen2.5-7B model
  to extract 15 key fields from Chinese Weibo police briefings.
---

# A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media

## Quick Facts
- arXiv ID: 2512.16183
- Source URL: https://arxiv.org/abs/2512.16183
- Reference count: 0
- Developed LoRA-based pipeline achieving 95%+ accuracy on structured extraction from Chinese Weibo police briefings

## Executive Summary
This study presents a domain-adapted pipeline for extracting structured information from Chinese police incident announcements on Weibo. The approach combines task-specific prompt engineering with LoRA-based fine-tuning of the Qwen2.5-7B model to extract 15 key fields including location, event characteristics, and impact assessments. Trained on a manually annotated dataset of 4,933 instances, the pipeline achieved 98.36% accuracy for mortality detection and 95.31% exact match rate for fatality counts, demonstrating that parameter-efficient fine-tuning with carefully engineered prompts can enable mid-sized models to match or exceed the performance of larger models in specialized structured extraction tasks.

## Method Summary
The pipeline uses a dual-prompt structure (system and user prompts) to guide structured JSON output generation, combined with LoRA fine-tuning on a manually annotated dataset of 4,933 Weibo police announcements. The Qwen2.5-7B-Base model was fine-tuned using LLaMA-Factory with LoRA adapters, training for 60 epochs with a learning rate of 2×10⁻⁴ and dynamic scheduling. The approach achieved high performance on objective fields while showing limitations on subjective assessments like social impact evaluation.

## Key Results
- Mortality detection accuracy: 98.36%
- Fatality count exact match rate: 95.31%
- Province-level location extraction accuracy: 95.54%
- Case type classification Jaccard similarity: 82.55%
- Social impact assessment accuracy: 71.15% (vs 90.27% for larger models)

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Adaptation for Domain-Specific Adaptation
- Claim: LoRA fine-tuning enables mid-sized LLMs to achieve domain-specific structured extraction performance competitive with larger models.
- Mechanism: LoRA decomposes weight updates ΔW into two low-rank matrices B and A (where rank r << dimensions of original weight matrix W₀), keeping base parameters frozen while training only the adapter matrices.
- Core assumption: The domain adaptation can be captured in a low-dimensional subspace.
- Evidence anchors: [abstract] "LoRA-based fine-tuning significantly improved performance over both the base and instruction-tuned models"; [section 3.1] "Qwen2.5-7B-LoRA achieved 93.76 in BLEU-4, compared with 24.97 for the base model".
- Break condition: Performance degrades on tasks requiring qualitatively different reasoning patterns not represented in training data.

### Mechanism 2: Structured Prompt Engineering for Output Format Enforcement
- Claim: Task-specific prompts with explicit JSON schemas constrain model outputs to analyzable structured formats.
- Mechanism: System prompts establish role definitions and output rules; user prompts provide extraction instructions with field specifications and examples.
- Core assumption: Models can learn format adherence from in-context instructions during fine-tuning.
- Evidence anchors: [abstract] "pipeline combined task-specific prompt engineering with LoRA-based fine-tuning"; [section 2.1.4] "These robustly designed prompts provide a reliable foundation for the subsequent fine-tuning".
- Break condition: Base models without fine-tuning "often failed to comply with the required JSON schema, producing incomplete or inconsistent fields".

### Mechanism 3: High-Quality Manual Annotation for Domain Grounding
- Claim: Curated, domain-specific annotated data enables models to capture specialized terminology and extraction patterns.
- Mechanism: Dual-annotation process with inter-annotator agreement (Kappa=94%) and expert adjudication produces reliable ground truth.
- Core assumption: Annotation quality transfers to model learning.
- Evidence anchors: [section 2.1.3] "Kappa consistency coefficient was calculated to be 94%—a result indicating excellent inter-annotator agreement"; [section 4.1] LoRA models "trained on carefully curated, domain-specific annotations".
- Break condition: Tasks requiring professional legal judgment show limits of annotation-based learning.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**
  - Why needed here: Core fine-tuning method enabling 7B parameter model training on consumer hardware
  - Quick check question: Can you explain why initializing matrix B to zeros ensures training starts from the pre-trained state?

- **Structured Information Extraction Evaluation Metrics**
  - Why needed here: Different field types require different metrics (EMR for numerical/exact matches, F1 for Boolean, Cosine similarity for text, Jaccard for sets)
  - Quick check question: Why would BLEU/ROUGE alone be insufficient for evaluating structured extraction quality?

- **Prompt Engineering Roles (System vs. User Prompts)**
  - Why needed here: Understanding the separation enables effective training data construction
  - Quick check question: What is the functional difference between a system prompt and a user prompt in dialogue-style training data?

## Architecture Onboarding

- **Component map:** Raw Weibo posts → OCR + Cleaning → Manual Annotation → Prompt Synthesis → LoRA Fine-tuning → Evaluation → 15-field JSON schema

- **Critical path:** Data annotation quality → Prompt format consistency → LoRA rank/learning rate selection → Cross-validation splits

- **Design tradeoffs:**
  - LoRA rank vs. expressiveness
  - Dataset size (4,933) vs. coverage of edge cases
  - Strict JSON enforcement vs. flexibility for ambiguous inputs

- **Failure signatures:**
  - Schema non-compliance in base/instruction models
  - Location hallucination at sub-prefectural levels
  - Subjective task degradation (social impact: 71.15%)
  - Numerical extraction errors on multi-step calculations

- **First 3 experiments:**
  1. Replicate baseline comparison: Run base Qwen2.5-7B vs. LoRA-finetuned on 100 held-out samples; verify schema compliance rate difference.
  2. Ablate prompt components: Test extraction accuracy with system prompt only vs. full prompt structure to isolate formatting contribution.
  3. Cross-validate field difficulty: Rank 15 extraction fields by accuracy; identify which field types underperform and may need schema redesign.

## Open Questions the Paper Calls Out

- **Can reinforcement learning or AI agent integration enhance the robustness of fine-tuned compact models for complex, multi-domain structured extraction tasks?**
  - Basis: Authors suggest future work integrating reinforcement learning or AI agents with fine-tuning to enhance model robustness.
  - Why unresolved: Current study focused solely on LoRA fine-tuning without exploring hybrid approaches.
  - What evidence would resolve it: Comparative experiments showing whether RL-enhanced or agent-augmented fine-tuned models achieve higher accuracy on subjective judgment tasks.

- **To what extent do fine-tuned compact models generalize beyond their training domain to other types of police or legal documents?**
  - Basis: Authors acknowledge generalization capabilities were not thoroughly validated.
  - Why unresolved: Dataset limited to Chinese Weibo police briefings from 2019-2020.
  - What evidence would resolve it: Cross-domain evaluation testing the fine-tuned model on police announcements from other countries or official police reports.

- **How do fine-tuned smaller models compare to large models in discriminative performance across specific case type categories?**
  - Basis: Authors note only overall accuracy was assessed without in-depth analysis of predictive performance across case categories.
  - Why unresolved: Category-specific performance, error patterns, and potential biases remain unexplored.
  - What evidence would resolve it: Per-category precision, recall, and F1 scores across all 11 case types with confusion matrix analysis.

## Limitations

- Dataset domain specificity: The 4,933 Weibo police briefings may not generalize beyond 2019-2020 Chinese police communications.
- LoRA hyperparameter sensitivity: Unspecified rank and alpha parameters impact reproducibility.
- Performance gap on subjective tasks: Social impact evaluation accuracy (71.15%) lags significantly behind objective fields.

## Confidence

- **High Confidence (95%+):** LoRA-based fine-tuning mechanism and observed improvements over base models are well-established patterns.
- **Medium Confidence (70-95%):** Specific performance metrics are internally validated but lack external benchmarks; mid-sized model performance vs. larger models is task-dependent.
- **Low Confidence (30-70%):** Generalizability of the 15-field schema to other domains or languages is untested.

## Next Checks

1. **Schema Robustness Test:** Systematically vary the JSON schema requirements and measure how extraction accuracy degrades to quantify sensitivity to schema design.

2. **Cross-Domain Transfer Evaluation:** Apply the fine-tuned model to a different structured extraction task (e.g., medical incident reports) without additional fine-tuning to assess domain adaptation limits.

3. **Ablation of Prompt Components:** Conduct controlled experiments removing system prompt elements to isolate the contribution of each component to schema compliance and extraction accuracy.