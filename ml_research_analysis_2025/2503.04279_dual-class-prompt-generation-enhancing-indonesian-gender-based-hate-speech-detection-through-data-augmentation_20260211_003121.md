---
ver: rpa2
title: 'Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate Speech
  Detection through Data Augmentation'
arxiv_id: '2503.04279'
source_url: https://arxiv.org/abs/2503.04279
tags:
- speech
- hate
- data
- augmentation
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of detecting gender-based hate
  speech in Indonesian social media, which is hindered by limited labeled datasets
  and class imbalance issues. The authors compare three data augmentation techniques:
  backtranslation, single-class prompt generation, and their proposed dual-class prompt
  generation approach that uses examples from both hate speech and non-hate speech
  classes.'
---

# Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate Speech Detection through Data Augmentation

## Quick Facts
- arXiv ID: 2503.04279
- Source URL: https://arxiv.org/abs/2503.04279
- Reference count: 40
- Primary result: Dual-class prompt generation achieved 88.5% accuracy and 88.1% F1-score on Indonesian gender-based hate speech detection

## Executive Summary
This paper addresses the challenge of detecting gender-based hate speech in Indonesian social media, which is hindered by limited labeled datasets and class imbalance issues. The authors compare three data augmentation techniques: backtranslation, single-class prompt generation, and their proposed dual-class prompt generation approach that uses examples from both hate speech and non-hate speech classes. Experiments show all augmentation methods improve classification performance, with dual-class prompt generation achieving the best results (88.5% accuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis reveals that dual-class prompt generation produces the most novel content while T-SNE visualizations confirm these samples occupy distinct feature space regions while maintaining class characteristics.

## Method Summary
The study uses an Indonesian Twitter dataset with severe class imbalance (306 hate speech vs 12,863 non-hate samples). A balanced subset (306 each) is created, and 306 additional minority samples are generated using three augmentation approaches: backtranslation (Indonesian→English→Indonesian), single-class prompt generation (hate speech examples only), and dual-class prompt generation (5 examples from each class via GPT-3.5-turbo with temperature=0.25, top_p=0.4). Preprocessing removes special characters, normalizes numbers to "[NUM]", and usernames to "[USERNAME]". TF-IDF vectorization is applied, followed by training Logistic Regression, Naive Bayes, Random Forest, and XGBoost classifiers with 5-fold cross-validation. Evaluation uses accuracy, F1-score, semantic similarity via IndoBERTweet embeddings, and T-SNE visualization.

## Key Results
- Dual-class prompt generation achieved the highest performance (88.5% accuracy, 88.1% F1-score) among all augmentation methods
- All augmentation techniques improved F1-scores compared to the baseline, with dual-class showing the largest gains
- Generated samples from dual-class prompting had the lowest semantic similarity to originals (0.8684), indicating greater diversity
- T-SNE visualizations confirmed that dual-class generated samples occupy distinct feature space regions while maintaining class characteristics

## Why This Works (Mechanism)

### Mechanism 1
Incorporating examples from both classes in prompts yields more diverse yet class-appropriate synthetic samples than single-class prompting. The dual-class prompt provides implicit contrastive signals—showing the LLM what the target class looks like and what it is not—enabling the model to identify distinguishing linguistic patterns rather than replicating surface patterns from positive examples alone.

### Mechanism 2
Low-temperature, low-top_p generation with class-balanced prompts preserves semantic relevance while reducing hallucinated or off-target content. Temperature=0.25 and top_p=0.4 constrain the sampling distribution, prioritizing high-probability tokens conditioned on the prompt, which reduces exploration of unlikely, potentially off-class content while still allowing lexical variation.

### Mechanism 3
Augmented samples that occupy distinct feature space regions improve classifier generalization by filling under-represented areas of the minority class distribution. Novel samples with low semantic overlap expand coverage of the feature space, as visualized via T-SNE, potentially helping classifiers generalize better to unseen instances.

## Foundational Learning

- Concept: **Few-shot prompting with class contrast**
  - Why needed here: The dual-class method relies on constructing prompts that implicitly define a classification boundary via demonstration
  - Quick check question: Given 5 positive and 5 negative examples, can you write a single prompt that guides generation toward the positive class without explicitly stating the class label?

- Concept: **Semantic similarity as a diversity proxy**
  - Why needed here: The paper uses cosine similarity on IndoBERTweet embeddings to quantify novelty
  - Quick check question: If two sentences have a cosine similarity of 0.95 on contextual embeddings, are they more or less diverse than a pair at 0.75? What might 0.75 vs 0.95 imply about lexical vs semantic overlap?

- Concept: **Class imbalance and F1 vs accuracy divergence**
  - Why needed here: The original dataset shows accuracy (0.798) far exceeding F1 (0.590), indicating majority-class bias
  - Quick check question: On a binary task with 90% majority class, a dummy classifier predicting only the majority achieves 90% accuracy. What F1 does it achieve for the minority class?

## Architecture Onboarding

- Component map: Original imbalanced dataset (306 minority, 12,863 majority) -> balanced subset (306 each) -> augmented datasets (backtranslation, single-class, dual-class; +306 minority each) -> TF-IDF vectorization -> classifiers (LR, NB, RF, XGBoost) -> evaluation (accuracy, F1, similarity, T-SNE)

- Critical path: 1) Construct balanced baseline (306 minority + 306 majority) 2) Generate 306 additional minority samples per augmentation method 3) Train classifiers on each augmented dataset 4) Evaluate via cross-validation; compute similarity and T-SNE for generated samples

- Design tradeoffs:
  - **Low temperature vs diversity**: temp=0.25 reduces hallucination but may limit lexical variety; increasing temp risks semantic drift
  - **Prompt length vs cost**: 10 examples (dual-class) doubles prompt tokens vs single-class; increases API cost and latency
  - **TF-IDF vs contextual embeddings**: TF-IDF chosen for classifier comparison with prior work; IndoBERTweet used only for analysis, not classification

- Failure signatures:
  - **Semantic drift**: Generated samples with similarity <0.75 may indicate off-topic or misclassified content; validate manually
  - **Class leakage**: If majority-class examples in dual-class prompt are mislabeled or ambiguous, the LLM may generate content that blurs boundaries
  - **Overfitting to synthetic data**: If augmented samples cluster tightly (low within-class variance), classifiers may overfit to synthetic patterns not present in real data

- First 3 experiments:
  1. **Ablation on prompt composition**: Vary the ratio of positive to negative examples (e.g., 3:7, 5:5, 7:3) and measure impact on F1 and similarity scores
  2. **Temperature sweep**: Test temp ∈ {0.1, 0.25, 0.5, 0.7} with fixed dual-class prompt; plot diversity (similarity) vs classifier performance
  3. **Cross-dataset validation**: Train on augmented Indonesian data; evaluate on a held-out Indonesian hate speech dataset or a related language (e.g., Malay) to assess generalization

## Open Questions the Paper Calls Out
- Does combining backtranslation with prompt-based generation yield complementary performance benefits? (The study evaluated methods in isolation)
- Is the dual-class prompt generation approach effective for other languages and hate speech categories? (Experiments were limited to Indonesian gender-based hate speech)
- How does dual-class augmentation impact deep learning classifiers compared to the TF-IDF models used in this study? (The methodology restricted classification to TF-IDF with traditional models)

## Limitations
- The exact prompt template used for dual-class generation is not provided, making it difficult to reproduce the specific formulation that yielded reported improvements
- The study focuses exclusively on Indonesian gender-based hate speech, limiting generalizability to other languages, domains, or types of hate speech
- While demonstrating superior performance, the paper does not conduct ablation studies to isolate which component (contrastive examples, controlled generation parameters, or class balance) contributes most to the observed gains

## Confidence

- **High confidence**: The experimental results showing dual-class prompt generation outperforms baseline augmentation methods on the tested Indonesian dataset
- **Medium confidence**: The proposed mechanisms explaining why dual-class prompting works (contrastive signals, controlled decoding, feature space expansion) are plausible but would benefit from additional ablation studies
- **Medium confidence**: The semantic similarity analysis and T-SNE visualizations provide reasonable evidence that dual-class generation produces more diverse samples

## Next Checks
1. **Ablation on prompt composition**: Systematically vary the ratio of positive to negative examples in the dual-class prompt (e.g., 3:7, 5:5, 7:3) while holding other parameters constant to isolate the effect of contrastive demonstration on generation quality and classification performance

2. **Temperature sensitivity analysis**: Conduct a comprehensive sweep of generation temperature parameters (e.g., 0.1, 0.25, 0.5, 0.7) with fixed dual-class prompts to quantify the tradeoff between diversity (semantic similarity) and semantic drift

3. **Cross-dataset generalization test**: Evaluate models trained on augmented Indonesian data on an independent Indonesian hate speech dataset or a related language (e.g., Malay) to assess whether the observed performance gains generalize beyond the original training distribution