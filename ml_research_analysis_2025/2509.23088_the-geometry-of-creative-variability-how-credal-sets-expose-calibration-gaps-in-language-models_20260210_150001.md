---
ver: rpa2
title: 'The Geometry of Creative Variability: How Credal Sets Expose Calibration Gaps
  in Language Models'
arxiv_id: '2509.23088'
source_url: https://arxiv.org/abs/2509.23088
tags:
- uncertainty
- calibration
- human
- credal
- diversity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of uncertainty quantification\
  \ in creative language generation, where no single ground truth exists. The authors\
  \ introduce a geometric framework using credal sets\u2014convex hulls of probability\
  \ distributions\u2014to measure and decompose uncertainty in neural text generation,\
  \ calibrated against human creative variation."
---

# The Geometry of Creative Variability: How Credal Sets Expose Calibration Gaps in Language Models

## Quick Facts
- **arXiv ID**: 2509.23088
- **Source URL**: https://arxiv.org/abs/2509.23088
- **Authors**: Esteban Garces Arias; Julian Rodemann; Christian Heumann
- **Reference count**: 7
- **Primary result**: Geometric credal set analysis reveals substantial calibration gaps between LLM creative generation and human variation, with best overlap 0.434.

## Executive Summary
This paper introduces a geometric framework using credal sets—convex hulls of probability distributions—to measure and decompose uncertainty in creative language generation. The authors analyze 500 creative writing prompts with 10 unique human continuations each, evaluating four language models across five decoding strategies to generate 100,000 stories. Their credal set analysis reveals that current models capture only a fraction of human creative variation, with the best model-human calibration reaching only 0.434. The work demonstrates that uncertainty decomposition shows decoding strategy choice contributes 39.4-72.0% of total epistemic uncertainty, while model scale shows weak correlation with calibration quality.

## Method Summary
The authors construct credal sets by computing diversity vectors across semantic, lexical, and syntactic dimensions for each prompt's story set, then building convex hulls across all prompts. They measure calibration using overlap coefficients between human and model credal sets, and decompose uncertainty into epistemic (decoding strategy-dependent) and aleatoric (inherent task ambiguity) components via variance analysis. The study evaluates GPT2-XL, Gemma-2B, Mistral-7B-Instruct, and Llama-3.1-8B-Instruct with temperature, top-k, top-p, and typical decoding strategies, generating 10 samples per configuration.

## Key Results
- The best model-human calibration achieved 0.434 (Gemma-2B with temperature 0.7)
- Decoding strategy choice contributes 39.4-72.0% of total epistemic uncertainty
- Model scale shows weak correlation with calibration quality
- No significant difference exists between base and instruction-tuned models in calibration quality

## Why This Works (Mechanism)

### Mechanism 1
Representing uncertainty as credal sets (convex hulls of diversity distributions) enables geometric comparison between human and model variation patterns. For each prompt, compute diversity vectors across semantic, lexical, and syntactic dimensions. The convex hull of these vectors across prompts forms a credal set—a geometric region capturing the range of plausible variation. Overlap between human and model credal sets quantifies calibration. Core assumption: Creative variation is distributional and prompt-dependent; convex hulls adequately capture uncertainty structure.

### Mechanism 2
Uncertainty can be decomposed into epistemic (decoding strategy-dependent) and aleatoric (inherent task ambiguity) components via variance analysis across strategies. For each model, compute between-strategy variance (centroid differences across decoding strategies) as epistemic uncertainty, and within-strategy variance (prompt-level variation within a strategy) as aleatoric uncertainty. The epistemic ratio quantifies sensitivity to configuration choices. Core assumption: Decoding strategy variation approximates model uncertainty; within-strategy variation approximates irreducible task uncertainty.

### Mechanism 3
Calibration quality depends more on credal set position and shape than absolute volume; instruction-tuned models produce larger but not better-aligned credal sets. Overlap coefficient measures calibration via nearest-neighbor distances between credal set vertices, not volume ratios. Larger credal sets (instruction-tuned models: 3.87 vs base: 1.10) can overlap less with human sets if positioned incorrectly. Core assumption: Human creative variation provides a valid calibration target; overlap coefficient captures alignment meaningfully.

## Foundational Learning

- **Credal Sets**: Why needed here: Core mathematical object for representing uncertainty as a set of distributions rather than a point estimate. Quick check question: Can you explain why a convex hull of probability distributions captures more information than a single distribution for creative tasks?

- **Epistemic vs Aleatoric Uncertainty**: Why needed here: Distinguishes reducible model uncertainty from irreducible task ambiguity; informs where to focus improvement efforts. Quick check question: If epistemic ratio is 72%, what does this imply about the value of tuning decoding strategies?

- **Diversity Metrics (Semantic, Lexical, Syntactic)**: Why needed here: Define the axes of the diversity space in which credal sets are constructed. Quick check question: Why might semantic diversity (0.645 mean) be higher than lexical (0.328) for creative writing?

## Architecture Onboarding

- **Component map**: Input layer (500 prompts with 10 human continuations each) -> Diversity computation (semantic, lexical, syntactic) -> Credal set construction (PCA + Quickhull) -> Calibration module (overlap coefficient, Wasserstein distance) -> Uncertainty decomposition (between-strategy variance, within-strategy variance)

- **Critical path**: 1. Prompt selection (uniqueness verification, length filtering, quality scoring) 2. Model inference (4 models × 5 strategies × 10 samples = 200 configurations per prompt) 3. Diversity vector computation per prompt 4. Credal set construction across all prompts 5. Overlap and decomposition analysis

- **Design tradeoffs**: Volume vs calibration: Larger credal sets (instruction-tuned) do not guarantee better alignment. Computational cost vs sample size: 10 samples per configuration; larger samples may reveal finer patterns. Convex hull vs non-convex: Current approach may miss multimodal distributions within credal sets

- **Failure signatures**: Calibration score <0.3: Model credal set largely disjoint from human set. Epistemic ratio >70%: Model highly sensitive to decoding strategy (e.g., Gemma-2B at 72%). Overlap coefficient <0.05: Model and human occupy fundamentally different regions of diversity space

- **First 3 experiments**:
  1. **Baseline calibration**: Run Gemma-2B with temperature 0.7 on 50 held-out prompts; compute overlap coefficient and Wasserstein distance; verify calibration ≈0.43.
  2. **Ablation on decoding strategies**: For Mistral-7B-Instruct, compare top-k (k=40) vs temperature (1.2) vs nucleus (p=0.9); measure which strategy yields highest mean calibration and lowest epistemic ratio.
  3. **Sensitivity to sample size**: For a single prompt, generate 100 samples (vs 10) for Gemma-2B temperature 0.7; assess whether credal set shape stabilizes or reveals multimodal structure missed by smaller samples.

## Open Questions the Paper Calls Out

- **Question 1**: Does geometric calibration in diversity space correlate with human perceptions of creative quality, or can a model be well-calibrated yet produce low-quality text? Basis: Authors state calibration "does not necessarily indicate qualitative alignment" and list validating relationship between metrics and perceived creative quality as essential future work.

- **Question 2**: Does the credal set calibration framework generalize to other open-ended NLG tasks beyond creative storytelling? Basis: Authors note findings are specific to storytelling and suggest "task-specific calibration analyses" are needed for other NLG areas with different communicative objectives.

- **Question 3**: To what extent does the mismatch between model decoding (prioritizing high-probability tokens) and human writing (utilizing surprising, low-probability tokens) limit the maximum achievable calibration? Basis: Limitations section notes standard decoding strategies "prioritize high-probability tokens, whereas humans often select surprising, low-probability tokens for creative effect."

## Limitations

- The geometric approach using credal sets is computationally intensive and may not scale efficiently to larger model collections.
- The assumption that convex hulls adequately capture the complex, potentially multimodal uncertainty structure in creative tasks remains an open question.
- The overlap coefficient metric may not fully capture practical calibration quality—a model could achieve moderate overlap while still producing undesirable outputs.

## Confidence

- **High**: The geometric framework using credal sets is well-defined and computationally implementable; the methodology for constructing and comparing credal sets is sound.
- **Medium**: The decomposition of uncertainty into epistemic and aleatoric components via variance analysis is theoretically justified but may not capture all sources of uncertainty.
- **Medium**: The claim that no significant difference exists between base and instruction-tuned models in calibration quality is supported by the data but may be dataset-dependent.

## Next Checks

1. **Cross-dataset validation**: Test the calibration framework on a different creative writing dataset (e.g., OpenWebText or a different genre from WritingPrompts) to assess whether the observed calibration gaps are dataset-specific or generalizable.

2. **Alternative uncertainty decomposition**: Implement an entropy-based uncertainty decomposition (similar to Ling et al., 2024) as a complementary approach to validate the variance-based epistemic-aleatoric decomposition.

3. **Modal analysis of credal sets**: Generate 100 samples per configuration (instead of 10) for a subset of prompts to investigate whether credal sets exhibit multimodal structure that convex hulls may miss, potentially explaining some calibration gaps.