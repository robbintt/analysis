---
ver: rpa2
title: 'Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus'
arxiv_id: '2509.19033'
source_url: https://arxiv.org/abs/2509.19033
tags:
- clic-it
- corpus
- community
- research
- authors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The CLiC-it Corpus compiles 10 years of Italian CL and NLP conference\
  \ papers, providing structured metadata and full-text content to track community\
  \ trends. The corpus covers 693 papers from 2014\u20132024, including author affiliations,\
  \ gender, and institutional collaboration networks."
---

# Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus

## Quick Facts
- arXiv ID: 2509.19033
- Source URL: https://arxiv.org/abs/2509.19033
- Reference count: 2
- Primary result: 10-year diachronic corpus of Italian CL/NLP conference papers with metadata, collaboration networks, and topic modeling showing community evolution

## Executive Summary
The CLiC-it Corpus compiles 10 years of Italian computational linguistics and NLP conference papers (2014-2024), providing structured metadata and full-text content to track community trends. The corpus covers 693 papers with author affiliations, gender, and institutional collaboration networks. Analysis reveals growing participation, with a 51.78% average of first-time authors per edition and increasing international engagement (Netherlands most represented). The collaboration network shows a large connected component of 241 nodes, with key hubs including University of Torino and Fondazione Bruno Kessler. Topic modeling identified 15 research themes, with lexical/semantic resources, sentiment analysis, and language models most prominent. Diachronic trends show shifts from foundational linguistic resources toward neural models and socially relevant applications. The corpus is openly available for further research and longitudinal monitoring.

## Method Summary
The corpus construction involved parsing heterogeneous document formats (PDF, LaTeX, Word) using format-specific tools including TexSoup for LaTeX and NotebookLM for PDFs. Entity normalization standardized affiliations and author names, while EasyNMT machine translation standardized Italian papers into English. The dataset was analyzed using weighted directed graphs to identify institutional hubs through centrality measures, and BERTopic topic modeling to detect thematic shifts over time. The analysis pipeline processed 693 papers, extracting metadata and content for diachronic analysis of community structure and research trends.

## Key Results
- Corpus contains 693 papers from CLiC-it conferences spanning 2014-2024
- Collaboration network reveals 241-node giant component with University of Torino and Fondazione Bruno Kessler as key hubs
- Topic modeling identified 15 research themes, with lexical/semantic resources, sentiment analysis, and language models most prominent
- Diachronic analysis shows shift from foundational linguistic resources toward neural models and socially relevant applications

## Why This Works (Mechanism)

### Mechanism 1: Unified Diachronic Corpus Construction
The authors implement a multi-stage pipeline involving format-specific parsers (TexSoup for LaTeX, NotebookLM for PDFs), entity normalization for affiliations, and machine translation (EasyNMT) to standardize Italian papers into English. This creates a queryable diachronic corpus that preserves semantic content during translation and extraction, with Abstract/Introduction/Conclusion sections serving as proxies for full-text topic modeling.

### Mechanism 2: Weighted Centrality for Institutional Influence
The system models institutions as nodes and collaborations as weighted edges, calculating Degree (activity), Closeness (reachability), and Betweenness (bridging) centrality. This aggregate rank identifies key players that structurally bind the community, assuming co-authorship implies meaningful knowledge transfer and institutional alignment.

### Mechanism 3: Soft Clustering for Thematic Evolution
Transformer-based embeddings combined with density-based clustering detect fine-grained thematic shifts over time. Using BERTopic with BERT embeddings, UMAP dimensionality reduction, and HDBSCAN clustering allows for outlier detection and reassignment, facilitating clean diachronic comparison of research topics.

## Foundational Learning

- **Graph Centrality Measures**
  - Why needed: To interpret why specific institutions are identified as "hubs" and what that implies about the flow of ideas
  - Quick check: If a node has high Betweenness centrality but low Degree centrality, what role does it play in the network?

- **BERTopic / c-TF-IDF**
  - Why needed: To understand how the paper extracts 15 distinct topics from raw text without predefined labels
  - Quick check: Why does BERTopic use class-based TF-IDF (c-TF-IDF) rather than standard TF-IDF?

- **Entity Resolution (Normalisation)**
  - Why needed: The paper relies on merging variants (e.g., "Univ. of Pisa" vs "Università di Pisa") to build the collaboration graph
  - Quick check: What happens to the "Connected Component" size if entity resolution is too aggressive (false positives)?

## Architecture Onboarding

- Component map: PDF/LaTeX/Word inputs -> TexSoup/NotebookLM parsers -> Manual/Heuristic standardization of names/affiliations -> EasyNMT Translation -> Weighted Graph Constructor -> Centrality Calculators (Degree/Closeness/Betweenness) || BERTopic Pipeline (Embeddings -> UMAP -> HDBSCAN)
- Critical path: **Affiliation Normalization**. Raw extraction yields "Università di Torino" and "University of Turin" as distinct nodes. Without accurate merging here, the graph density (0.017) would drop further, and the "Giant Component" (241 nodes) would fragment, invalidating the centrality analysis.
- Design tradeoffs:
  - **Content Scope**: Using only Abstract/Intro/Conclusion vs Full Text. *Tradeoff*: Faster processing and reduced noise vs potential loss of technical detail and methodology specificities
  - **Clustering**: HDBSCAN outlier reassignment vs strict clustering. *Tradeoff*: Ensures 100% paper coverage for trend analysis vs potentially forcing papers into ill-fitting topics
- Failure signatures:
  - **Topic Fragmentation**: "Language Models" splits into "LLMs" and "Transformers" due to embedding variance
  - **Graph Silos**: A sudden drop in the "Giant Component" size indicates a failure in affiliation matching
  - **Translation Drift**: Technical terms in Italian mistranslated, leading to ambiguous topic clusters
- First 3 experiments:
  1. **Sensitivity Analysis**: Re-run the topic model with min_cluster_size = 5 vs 10 to see if the 15 topics are stable or a parameter artifact
  2. **Translation Validation**: Spot-check 10 Italian papers to verify that technical terminology in the "Conclusion" section was preserved accurately by EasyNMT
  3. **Edge Weight Stress Test**: Remove the top 3 hubs (Torino, FBK, CNR-ILC) from the graph to measure the resilience of the collaboration network

## Open Questions the Paper Calls Out

### Open Question 1
Does the machine translation of Italian papers into English introduce semantic artifacts that affect the accuracy of topic modeling compared to native English texts? The authors used EasyNMT to translate 47 Italian papers to ensure "linguistic uniformity" before clustering, but did not evaluate if this step altered the semantic features used by BERTopic. This remains unresolved as the paper assumes translation creates uniformity without verifying that the embedding space of translated texts aligns perfectly with native English texts.

### Open Question 2
Does the use of PDF extraction for the 2014, 2018, 2019, and 2023 editions result in lower data quality or topic clustering noise compared to editions parsed from LaTeX source files? The authors note that source files were unavailable for these years, necessitating the use of NotebookLM and manual correction, which introduces a methodological variance from the automated LaTeX parsing used for other years. This remains unresolved as the paper does not quantify potential errors in the PDF-extracted text that might skew the topic distributions.

### Open Question 3
Will the emergence of "Baby LLMs" specifically revitalize the declining "Learner Corpora and Language Acquisition" research cluster in future editions? The authors hypothesize that "interest in Language Acquisition could be revitalized by the rise of Baby LLMs that target developmental linguistics and incremental learning." This remains unresolved as it is a predictive statement about future trajectory that cannot be confirmed by the historical data analyzed.

## Limitations

- Translation pipeline may introduce semantic drift for technical terms, though spot-checking showed acceptable preservation
- Network analysis assumes co-authorship implies meaningful collaboration, potentially overestimating institutional influence
- Topic modeling stability is uncertain due to sensitivity to clustering parameters

## Confidence

- Corpus construction and metadata extraction: **High**
- Institutional centrality analysis: **Medium** (depends on affiliation normalization quality)
- Diachronic topic modeling: **Medium** (sensitive to clustering parameters)
- Gender representation analysis: **Low** (manual gender assignment introduces bias)

## Next Checks

1. Re-run topic modeling with UMAP n_neighbors=15 and HDBSCAN min_cluster_size=10 to test cluster stability
2. Validate 50 randomly selected paper translations for technical term accuracy
3. Perform ablation study removing the top 3 institutions to assess network resilience