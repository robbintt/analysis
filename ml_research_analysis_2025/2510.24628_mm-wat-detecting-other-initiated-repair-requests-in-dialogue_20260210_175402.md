---
ver: rpa2
title: '"Mm, Wat?" Detecting Other-initiated Repair Requests in Dialogue'
arxiv_id: '2510.24628'
source_url: https://arxiv.org/abs/2510.24628
tags:
- repair
- features
- initiation
- prosodic
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multimodal model to detect Other-Initiated
  Repair (OIR) requests in spoken dialogue, integrating linguistic and prosodic features
  grounded in Conversation Analysis. The model combines pretrained text (RobBERT)
  and audio (Whisper) embeddings with handcrafted features and uses multihead attention
  for fusion.
---

# "Mm, Wat?" Detecting Other-initiated Repair Requests in Dialogue
## Quick Facts
- arXiv ID: 2510.24628
- Source URL: https://arxiv.org/abs/2510.24628
- Reference count: 21
- Primary result: Multimodal model achieves 94.6% F1-score for detecting other-initiated repair requests in Dutch dialogue

## Executive Summary
This paper introduces a multimodal approach to detecting Other-Initiated Repair (OIR) requests in spoken dialogue by combining linguistic and prosodic features based on Conversation Analysis theory. The model integrates pretrained text embeddings (RobBERT), audio embeddings (Whisper), and handcrafted features using multihead attention for fusion. Results demonstrate that the multimodal approach significantly outperforms unimodal baselines, achieving 94.6% F1-score. The model effectively handles repair initiation detection and provides interpretable insights through SHAP analysis, revealing the importance of pauses, intensity, and grammatical structures in identifying repair requests.

## Method Summary
The proposed model combines pretrained text embeddings (RobBERT) and audio embeddings (Whisper) with handcrafted features representing linguistic and prosodic characteristics of repair initiations. Linguistic features include POS patterns and coreference structures, while prosodic features capture pitch, intensity, pauses, and transitions. Multihead attention mechanisms fuse these diverse feature streams, and the model incorporates dialogue micro context to improve detection accuracy. The approach is grounded in Conversation Analysis theory, which provides the theoretical foundation for understanding how speakers signal problems in communication.

## Key Results
- Multimodal model achieves 94.6% F1-score, significantly outperforming unimodal baselines
- SHAP analysis identifies pauses, intensity, and grammatical structures as top predictors of repair requests
- Strong synergy demonstrated between linguistic and prosodic cues in repair detection
- Incorporating dialogue micro context further improves detection accuracy

## Why This Works (Mechanism)
The model's effectiveness stems from its comprehensive integration of multiple information channels that humans naturally use when signaling communication problems. Linguistic features capture the grammatical and semantic patterns specific to repair initiations, while prosodic features encode the acoustic cues (pitch, intensity, pauses) that speakers use to mark uncertainty or requests for clarification. The multihead attention mechanism allows the model to learn complex interactions between these modalities, while the grounding in Conversation Analysis ensures the features are theoretically motivated rather than purely data-driven.

## Foundational Learning
- **Conversation Analysis**: Framework for understanding how people manage communication breakdowns in natural dialogue. Needed to identify which features are theoretically relevant for repair detection. Quick check: Can the model identify repair initiations that follow classic CA patterns (open-class vs. restricted-class repairs)?
- **Multimodal Fusion**: Techniques for combining heterogeneous feature streams (text, audio, handcrafted). Needed to leverage complementary information from different modalities. Quick check: Does the model maintain performance when one modality is degraded or missing?
- **SHAP Analysis**: Method for interpreting model predictions by quantifying feature contributions. Needed to understand which features drive repair detection and validate theoretical assumptions. Quick check: Do the most important features align with Conversation Analysis predictions?
- **Other-Initiated Repair**: Specific type of conversational move where one participant signals a problem with what another just said. Needed as the target phenomenon for detection. Quick check: Can the model distinguish OIR from other types of clarification requests?
- **Prosodic Features**: Acoustic characteristics like pitch, intensity, and timing that convey pragmatic meaning. Needed to capture non-verbal cues in repair initiations. Quick check: Does the model leverage pitch and intensity changes that correlate with repair functions?
- **Coreference Resolution**: NLP task of identifying when different expressions refer to the same entity. Needed to capture linguistic patterns in repair initiations. Quick check: Do coreference features improve detection of specific repair types?

## Architecture Onboarding
Component Map: Input audio/text -> Whisper/RobBERT embeddings -> Handcrafted features -> Multihead attention fusion -> Classification
Critical Path: Audio/text input → Embedding extraction → Feature engineering → Attention-based fusion → Binary classification
Design Tradeoffs: The model trades pure end-to-end learning for interpretability by incorporating handcrafted features grounded in Conversation Analysis, accepting the engineering overhead for better theoretical alignment and feature transparency
Failure Signatures: Model may struggle with repair initiations that deviate from learned patterns, cross-linguistic variations, or contexts where repair cues are subtle or culturally specific
First Experiments:
1. Test model performance on Dutch dialogues with varying repair types (open-class vs. restricted-class)
2. Evaluate contribution of individual feature groups through ablation studies
3. Assess model robustness by introducing noise in audio or text inputs

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Generalizability constrained by reliance on Dutch dialogue data, raising questions about cross-linguistic performance
- Handcrafted feature engineering approach may not capture all relevant repair initiation cues and could be biased toward specific conversational patterns
- Model brittleness in novel or ambiguous repair contexts not addressed, lacking systematic ablation studies beyond SHAP analysis
- Evaluation metrics focus on F1-score without deeper analysis of false positive/negative patterns across different repair types

## Confidence
High: The multimodal fusion approach (text + audio + handcrafted features) outperforms unimodal baselines and achieves strong performance (94.6% F1) on the Dutch dialogue dataset. The SHAP analysis findings about pauses, intensity, and grammatical structures being key predictors are well-supported.

Medium: The claim about "strong synergy between linguistic and prosodic cues" is supported by the ablation results but could benefit from more detailed interaction analysis. The assertion that incorporating dialogue micro context "further improves detection" is plausible but the magnitude of improvement is not quantified in the summary.

Low: The model's effectiveness in "handling repair initiation detection" across diverse real-world scenarios is not validated beyond the controlled dataset, and the paper lacks explicit discussion of edge cases or failure modes.

## Next Checks
1. Test model performance on multilingual datasets or translated Dutch dialogues to assess cross-linguistic generalizability
2. Conduct systematic ablation studies removing specific feature subsets to quantify individual contributions more precisely
3. Perform error analysis categorizing false positives/negatives by repair type, speaker role, and conversational context to identify systematic weaknesses