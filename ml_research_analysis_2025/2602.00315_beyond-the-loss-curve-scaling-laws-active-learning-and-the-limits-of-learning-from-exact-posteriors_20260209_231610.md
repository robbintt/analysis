---
ver: rpa2
title: 'Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning
  from Exact Posteriors'
arxiv_id: '2602.00315'
source_url: https://arxiv.org/abs/2602.00315
tags:
- oracle
- epistemic
- arxiv
- error
- shift
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We introduce a framework that uses class-conditional normalizing\
  \ flows as oracles to compute exact posteriors p(y|x) on realistic images (AFHQ,\
  \ ImageNet), enabling direct decomposition of prediction error into aleatoric and\
  \ epistemic components and controlled experiments impossible on standard benchmarks.\
  \ We find that epistemic uncertainty follows a clean power law in dataset size (KL\u221D\
  N^\u2212\u03B1), continuing to shrink even when total loss plateaus, with ResNet\
  \ achieving 6\xD7 reduction and ViT less than 1.2\xD7 without pretraining."
---

# Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors

## Quick Facts
- arXiv ID: 2602.00315
- Source URL: https://arxiv.org/abs/2602.00315
- Reference count: 39
- Primary result: Epistemic uncertainty follows clean power laws (KL∝N^−α) that continue shrinking even after loss plateaus

## Executive Summary
This work introduces a framework using class-conditional normalizing flows as oracles to compute exact posteriors p(y|x) on realistic images, enabling direct decomposition of prediction error into aleatoric and epistemic components. The framework reveals that standard metrics hide ongoing learning, mask architectural differences, and cannot diagnose the nature of distribution shift. Key findings include power-law scaling of epistemic uncertainty with dataset size, significant accuracy gains from exact soft labels, and the superiority of exact epistemic uncertainty for active learning.

## Method Summary
The framework trains class-conditional normalizing flows at 256×256 resolution on AFHQ and ImageNet datasets to serve as exact posterior oracles. These flows compute p(y|x) directly, allowing decomposition of prediction error into aleatoric and epistemic components. The framework enables controlled experiments impossible on standard benchmarks, including testing with exact soft labels, analyzing distribution shift effects, and implementing active learning with exact epistemic uncertainty. The approach reveals that epistemic uncertainty follows clean power laws (KL∝N^−α) that continue to shrink even when total loss plateaus, with ResNet achieving 6× reduction and ViT less than 1.2× without pretraining.

## Key Results
- Epistemic uncertainty follows clean power law scaling (KL∝N^−α), continuing to shrink even when total loss plateaus
- Training with exact soft labels outperforms hard labels by up to 1% accuracy and achieves near-perfect calibration (ECE=0.018)
- Class imbalance barely affects accuracy at KL values where Gaussian noise causes 20-point drops, showing shift type matters more than magnitude
- Active learning with exact epistemic uncertainty requires 47.8% fewer labeled samples than entropy-based methods to reach equivalent performance

## Why This Works (Mechanism)
The framework's power comes from computing exact posteriors p(y|x) rather than relying on model-based approximations. By using normalizing flows as oracles, the method bypasses the circular dependency where uncertainty estimation requires training multiple models that themselves have uncertain outputs. This enables clean decomposition of error into aleatoric uncertainty (irreducible noise in the data) and epistemic uncertainty (reducible uncertainty from limited data). The exact soft labels derived from p(y|x) provide richer supervision signals than hard labels, allowing models to learn the inherent ambiguity in classification boundaries. The ability to measure epistemic uncertainty directly reveals that models continue learning even after loss plateaus, as they reduce uncertainty about ambiguous samples rather than just improving on clear-cut cases.

## Foundational Learning
- Normalizing flows: Required to understand how exact posteriors are computed from the flow model. Quick check: Verify the flow architecture can generate realistic samples from the training distribution.
- Epistemic vs aleatoric uncertainty: Needed to interpret the decomposition of prediction error. Quick check: Confirm that epistemic uncertainty decreases with more data while aleatoric uncertainty remains constant.
- Power law scaling: Essential for understanding the relationship between dataset size and uncertainty reduction. Quick check: Plot KL divergence against dataset size on log-log scale to verify linear relationship.
- Soft label calibration: Important for understanding why exact posterials improve accuracy. Quick check: Measure ECE before and after training with exact soft labels.

## Architecture Onboarding

**Component Map**
Normalizing Flow Model -> Exact Posterior Computation -> Uncertainty Decomposition -> Model Training -> Performance Evaluation

**Critical Path**
1. Train class-conditional normalizing flow on training data
2. Use flow to compute exact posteriors p(y|x) for all samples
3. Decompose loss into aleatoric and epistemic components
4. Train classifier with exact soft labels
5. Evaluate scaling laws and distribution shift effects

**Design Tradeoffs**
- Flow resolution (256×256) vs. computational cost and representational capacity
- Exact posterior computation vs. approximation error from flow model limitations
- Soft label training vs. standard hard label approaches
- Single flow model vs. ensemble methods for uncertainty estimation

**Failure Signatures**
- If flow model fails to capture true data distribution, exact posteriors will be incorrect
- Poor flow training leads to unreliable uncertainty estimates and decomposition
- Computational bottleneck in flow training limits scalability to larger datasets

**First 3 Experiments to Run**
1. Verify flow model generates realistic samples from training distribution
2. Test exact posterior computation on held-out validation set
3. Compare accuracy of model trained with exact soft labels vs. hard labels

## Open Questions the Paper Calls Out
- How do scaling laws change when moving beyond 256×256 resolution to full-resolution images?
- Can the exact posterior framework be extended to more complex distribution shifts beyond class imbalance and Gaussian noise?
- What architectural modifications could better exploit the information in exact soft labels?
- How does the epistemic uncertainty reduction mechanism differ between architectures like ResNet and ViT?
- Can the framework be adapted for active learning scenarios with streaming data or non-stationary distributions?

## Limitations
- Framework relies on class-conditional normalizing flows trained at 256×256 resolution, potentially missing higher-resolution behaviors
- Exact posterior computation assumes perfect flow model capture of true data distribution without quantifying approximation errors
- Architectural comparisons (ResNet vs. ViT) may be confounded by uncontrolled factors like optimization hyperparameters
- Limited to image classification tasks, with unclear generalization to other domains
- Computational cost of training high-quality normalizing flows limits scalability to very large datasets

## Confidence

**High Confidence Claims:**
- Epistemic uncertainty power laws (KL∝N^−α) are directly measurable from experiments
- Accuracy improvements from exact soft labels (up to 1%) and calibration gains (ECE=0.018) are straightforward statistical claims

**Medium Confidence Claims:**
- Distribution shift analysis comparing class imbalance to Gaussian noise depends on flow model's ability to capture shift types
- Active learning results (47.8% fewer samples) depend on specific acquisition function implementation

**Low Confidence Claims:**
- Architectural comparison between ResNet (6× reduction) and ViT (<1.2×) may be confounded by factors not controlled for in experiments

## Next Checks
1. Replicate epistemic uncertainty scaling experiments across multiple flow architectures to assess sensitivity to posterior approximation method
2. Conduct distribution shift experiments with controlled synthetic shifts while measuring both accuracy and epistemic uncertainty
3. Test active learning framework with alternative acquisition functions on the same exact posterior oracle
4. Verify that flow model generates realistic samples from the training distribution
5. Compare accuracy improvements from exact soft labels against other label smoothing techniques