---
ver: rpa2
title: Evaluating LLM Story Generation through Large-scale Network Analysis of Social
  Structures
arxiv_id: '2510.18932'
source_url: https://arxiv.org/abs/2510.18932
tags:
- networks
- stories
- gemini
- average
- story
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel, scalable methodology for evaluating
  LLM story generation by analyzing underlying social structures as signed character
  networks. Using over 1,200 stories from four leading LLMs and human writers, the
  study reveals that LLM-generated stories consistently exhibit higher density, clustering,
  and positive relationship bias compared to human-written narratives.
---

# Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures
## Quick Facts
- arXiv ID: 2510.18932
- Source URL: https://arxiv.org/abs/2510.18932
- Authors: Hiroshi Nonaka; K. E. Perry
- Reference count: 40
- Primary result: LLM-generated stories show higher network density, clustering, and positive relationship bias compared to human narratives

## Executive Summary
This paper introduces a novel methodology for evaluating LLM story generation by analyzing underlying social structures as signed character networks. Using over 1,200 stories from four leading LLMs and human writers, the study reveals that LLM-generated stories consistently exhibit higher density, clustering, and positive relationship bias compared to human-written narratives. Network analysis shows LLMs focus on tightly-knit, positive interactions among protagonists while being less conflict-driven. These findings align with prior human-annotated evaluations, validating the effectiveness of this automated network-based approach for assessing creative storytelling limitations and tendencies in LLMs.

## Method Summary
The study extracts signed character networks from stories by detecting co-occurrences within narrative units (1% of total sentences) and classifying unit sentiment via RoBERTa classifier. Characters appearing together form edges weighted by aggregated sentiment scores. Networks are filtered for minimum size (10 nodes) and density (0.1), then split into positive and negative subgraphs for comparative analysis. The methodology compares density, clustering, assortativity, and edge weights across four LLMs and human-written stories, using statistical tests and Wasserstein distance to quantify distributional differences.

## Key Results
- LLM positive networks show significantly higher density (0.315-0.395) and clustering (0.531-0.589) than human networks (clustering 0.259)
- Human stories have negative mean edge weights (-0.061) while all LLM models show positive mean weights (0.235-0.659)
- LLM negative networks show lower clustering (0.072-0.212) than human negative networks (0.395), indicating less structural integration of conflict

## Why This Works (Mechanism)
### Mechanism 1
Co-occurrence-based network extraction captures social structure signatures that differentiate LLM from human narratives at scale. Characters appearing together within narrative units form edges, aggregating thousands of micro-interactions into tractable graph metrics that surface structural biases invisible to token-level evaluation.

### Mechanism 2
Sentiment-aggregated edge signing isolates positivity bias in LLM social dynamics. Each narrative unit receives a sentiment label via RoBERTa classifier. Edge polarity equals argmax of sigmoid-aggregated logits across all co-occurrence units, revealing LLMs' tendency toward positive relationships.

### Mechanism 3
Subgraph decomposition (positive vs. negative networks) reveals LLMs' asymmetric conflict avoidance. Splitting each network into positive-edge and negative-edge subgraphs shows LLM positive networks have higher density and clustering than negative networks, while humans show the opposite pattern.

## Foundational Learning
- **Concept: Signed graphs** - Why needed: Core representation for relationship polarity enabling structural balance theory analysis. Quick check: Given three characters where A-B and B-C are positive edges but A-C is negative, is this structurally balanced?
- **Concept: Clustering coefficient** - Why needed: Quantifies "small-world-ness" showing how tightly a node's neighbors connect. Quick check: If a node has 5 neighbors with 8 edges between those neighbors, what's its local clustering coefficient?
- **Concept: Wasserstein distance** - Why needed: Measures distributional shift between score populations. Quick check: Two distributions with identical means but different variances—will Wasserstein distance be zero?

## Architecture Onboarding
- **Component map**: Story corpus → NER + vertex contraction → co-occurrence detection within narrative units → sentiment classification per unit → edge aggregation → signed graph construction → metric computation → distributional comparison
- **Critical path**: NER accuracy → determines which characters enter graph; narrative unit sizing → controls edge granularity; sentiment classifier reliability → directly affects edge signing
- **Design tradeoffs**: Binary {-1, 1} edges vs. continuous weights (paper chooses binary for simplicity); co-occurrence vs. conversation networks (paper uses co-occurrence for simplicity); fixed vs. adaptive unit size (1% threshold scales with story length)
- **Failure signatures**: Empty or near-empty negative subgraphs → LLM story may lack conflict; human/LLM distributions overlapping in density but diverging in edge weight → structural similarity but tonal difference
- **First 3 experiments**: 1) Replicate pipeline on new story corpus from different genre to test generalization of positivity bias finding. 2) Ablate sentiment classifier: replace RoBERTa with alternative to measure sensitivity of edge-weight conclusions. 3) Introduce neutral edge class: expand {-1, 1} to {-1, 0, 1} to capture ambiguous relationships.

## Open Questions the Paper Calls Out
- Do the observed structural biases (high density, positivity) in LLM networks persist in genres outside of science fiction?
- How does the choice of edge definition (e.g., co-occurrence vs. conversation) impact the structural comparison between human and LLM networks?
- Does the lack of coreference resolution artificially inflate the density metrics of LLM-generated networks?
- How do the social structures of LLM narratives evolve temporally compared to human narratives?

## Limitations
- Genre bias: All stories analyzed are sci-fi, potentially limiting generalizability of positivity bias findings
- Sentiment classifier dependency: Results heavily rely on RoBERTa model performance with no ablation study provided
- Network construction assumptions: Co-occurrence within narrative units may not capture all meaningful social interactions
- Limited conflict representation: Human stories showing negative mean edge weight suggests cultural differences in sci-fi writing

## Confidence
- **High confidence**: LLM positivity bias (edge weights 0.235-0.659 vs humans at -0.061), clustering differences (LLM positive networks 0.531-0.589 vs human 0.259), and density patterns
- **Medium confidence**: Wasserstein distance comparisons showing LLM-to-LLM similarity (0.123-0.188) vs LLM-to-human divergence (0.327-0.410)
- **Low confidence**: Assortativity findings (LLMs: -0.004 to 0.122; humans: 0.039) due to high variance in human data (std=0.260)

## Next Checks
1. Replicate the entire pipeline on a non-sci-fi corpus (romance, mystery, or literary fiction) to test whether positivity bias generalizes beyond the current genre
2. Implement an ablation study comparing the RoBERTa sentiment classifier against alternative models or domain-specific fine-tunes to quantify sensitivity of edge-weight conclusions
3. Expand the binary edge system to include neutral relationships {-1, 0, 1} and measure distributional shifts to determine if ambiguous interactions were previously misclassified