---
ver: rpa2
title: 'Your Spending Needs Attention: Modeling Financial Habits with Transformers'
arxiv_id: '2507.23267'
source_url: https://arxiv.org/abs/2507.23267
tags:
- data
- features
- transaction
- embeddings
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes nuFormer, a transformer-based representation
  learning approach for modeling financial transaction data. The key idea is to formulate
  transactions as sequences of special tokens and natural language descriptions, enabling
  the use of standard transformer architectures with self-supervised next-token prediction.
---

# Your Spending Needs Attention: Modeling Financial Habits with Transformers

## Quick Facts
- arXiv ID: 2507.23267
- Source URL: https://arxiv.org/abs/2507.23267
- Reference count: 40
- Primary result: +1.25% relative AUC improvement over baseline models using transformer-based financial transaction embeddings

## Executive Summary
This paper introduces nuFormer, a transformer-based approach for learning user representations from financial transaction data. The key innovation is representing transactions as sequences of special tokens (for numerical features) and natural language descriptions, enabling standard transformer architectures to process raw transaction data without manual feature engineering. The method extends to joint fusion, integrating these embeddings with existing tabular features through an end-to-end trainable neural network. Experiments on large-scale recommendation tasks at Nubank demonstrate a 1.25% relative improvement in AUC over baseline models, achieved solely through enhanced representation learning. The system was successfully deployed in production, reducing long-term user churn by 4.4% relative to the baseline.

## Method Summary
The approach tokenizes transactions by converting numerical features (amount, date) into discrete special tokens and using BPE tokenization for natural language descriptions. A causal transformer (GPT-like) is pre-trained using next-token prediction on user transaction sequences. User embeddings are extracted from the final token representation. For joint fusion, these embeddings are combined with tabular features processed through a DCNv2 model with Periodic Linear Recurrence (PLR) embeddings. The entire system is fine-tuned end-to-end using LoRA adapters to prevent catastrophic forgetting. The architecture was validated on a recommendation task predicting user engagement with financial products, using 6 months of transaction history to predict product activation after a 6-month delay.

## Key Results
- 1.25% relative improvement in Test AUC compared to baseline models
- 4.4% relative reduction in long-term user churn in production deployment
- 330M parameter model outperforms 24M parameter variant on the same task
- Joint fusion architecture achieves better performance than late fusion approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representing transactions as mixed special-token + natural language sequences enables transformers to learn behavioral patterns from raw financial data without manual feature engineering.
- Mechanism: Numerical features (amount, date) are quantized into discrete special tokens; text descriptions are tokenized via BPE. The concatenation forms a token sequence that standard language modeling objectives can process. This preserves semantic richness (via descriptions) while controlling context length (via special tokens).
- Core assumption: Transaction descriptions contain predictive signal that categorical/numerical features alone miss, and seasonal spending patterns require modeling long-range dependencies better captured by transformers than RNNs.
- Evidence anchors:
  - [abstract]: "The key idea is to formulate transactions as sequences of special tokens and natural language descriptions, enabling the use of standard transformer architectures with self-supervised next-token prediction."
  - [section 3.1]: "We represent numerical and categorical features using special tokens... The special token set is crafted from the specific attributes we want to model."
  - [corpus]: Weak direct evidence; corpus papers focus on other financial modeling approaches (GNNs, RL, fraud detection) rather than tokenization strategies for transformers.
- Break condition: If transaction descriptions are noisy, sparse, or non-predictive for your task, the natural language component may add noise without benefit. If context windows are severely constrained, even special-token compression may be insufficient.

### Mechanism 2
- Claim: Self-supervised next-token prediction on user transaction sequences produces general-purpose user embeddings transferable across downstream tasks.
- Mechanism: A causal (GPT-like) transformer is trained to predict the next token in a user's transaction history. The final token embedding (before padding) serves as the user representation because it attends to all prior context. LoRA fine-tuning prevents catastrophic forgetting while adapting to specific tasks.
- Core assumption: Future transaction patterns encode user behavioral signatures that correlate with downstream outcomes (e.g., product engagement, churn risk).
- Evidence anchors:
  - [abstract]: "This approach learns rich user embeddings directly from raw transaction data, eliminating the need for manual feature engineering."
  - [section 3.1]: "We pre-train causal transformers on our tokenized user representation using the standard next token prediction (NTP) task."
  - [section 3.2]: "In preliminary experiments, we found that finetuning the entire transformer often leads to overfitting and catastrophic forgetting. Hence, we use LoRA."
  - [corpus]: MesaNet (arxiv 2506.05233) discusses sequence modeling alternatives to transformers but doesn't address financial transaction SSL.
- Break condition: If user behavior is highly non-stationary or externally driven (e.g., macroeconomic shocks), historical sequences may not predict future patterns. Very short transaction histories may not provide sufficient signal.

### Mechanism 3
- Claim: Joint fusion—end-to-end training of transformer embeddings with tabular features via a DNN—outperforms late fusion by learning interactions between sequential and static signals.
- Mechanism: Tabular features are processed through DCNv2 with Periodic Linear Recurrence (PLR) numerical embeddings. The cross-layer output is projected to a low-dimensional embedding, concatenated with the transformer user embedding, and passed through an MLP classifier. Regularization (weight decay, dropout, embedding normalization) prevents overfitting.
- Core assumption: There exist cross-feature interactions between transaction-derived embeddings and hand-crafted tabular features that late fusion (training separately) cannot capture.
- Evidence anchors:
  - [abstract]: "The method is extended to joint fusion, integrating user embeddings with existing tabular features through an end-to-end trainable deep neural network."
  - [section 3.3]: "We hypothesize that finetuning jointly with blending will allow the transformer to better capture interactions between the tabular features and embedded transaction data."
  - [section 4.4, Table 4]: Joint fusion achieves +1.25% relative AUC improvement vs. +0.97% for late fusion.
  - [corpus]: No direct corroboration; corpus lacks papers on embedding-tabular fusion architectures.
- Break condition: If tabular features are already near-saturating performance, joint fusion adds complexity without gain. If DNN tabular models underperform GBTs significantly on your data (common per section 3.3), joint fusion may lag late fusion with GBTs.

## Foundational Learning

- Concept: **Causal vs. bidirectional attention**
  - Why needed here: The paper uses causal (GPT-like) transformers for transaction sequences, where prediction depends only on past context. Understanding the difference clarifies why this suits transaction modeling (predicting future from past) vs. bidirectional models like BERT4Rec.
  - Quick check question: Given a transaction sequence `[t1, t2, t3, t4]`, which tokens can `t3` attend to in a causal transformer? In a bidirectional transformer?

- Concept: **Self-supervised learning (SSL) objectives**
  - Why needed here: The core innovation is applying next-token prediction (a standard SSL objective) to transaction sequences. Understanding SSL clarifies why massive unlabeled transaction data can produce useful representations without task-specific labels.
  - Quick check question: What pseudo-label does next-token prediction construct from raw transaction sequences?

- Concept: **Feature fusion strategies (early/late/joint)**
  - Why needed here: The paper explicitly compares fusion approaches. Joint fusion is the key architectural contribution, and understanding why it outperforms alternatives is critical for implementation decisions.
  - Quick check question: In late fusion, are the transformer weights updated during the final classifier training? In joint fusion?

## Architecture Onboarding

- Component map:
  1. Tokenizer: Maps transactions → special tokens (amount buckets, date features) + BPE-tokenized descriptions
  2. Pre-trained transformer: Causal decoder-only, produces user embeddings via final token representation
  3. Fine-tuning adapter: LoRA layers added to transformer for task adaptation
  4. Tabular encoder: DCNv2 with PLR numerical embeddings + categorical embedding tables
  5. Fusion head: Concatenates transformer embedding + tabular embedding → MLP classifier
  6. Training infrastructure: FlashAttention + NoPE for long contexts; distributed training on A100/H100 GPUs

- Critical path:
  1. Define tokenization vocabulary (special tokens for your features + BPE for text)
  2. Pre-train transformer on historical transaction sequences (20M+ users in paper)
  3. Build DCNv2 tabular encoder with PLR embeddings; validate parity vs. GBT baseline
  4. Implement joint fusion training with regularization (L2, dropout, embedding normalization)
  5. Fine-tune end-to-end on labeled downstream task

- Design tradeoffs:
  - **Context length vs. compute**: Longer contexts improve performance (Figure 6) but increase attention cost quadratically; FlashAttention mitigates but doesn't eliminate this.
  - **Model size vs. data scale**: 330M model outperforms 24M (Table 3), but requires more training data to avoid underfitting (Figure 7).
  - **DNN vs. GBT for tabular**: DNN enables joint fusion but may underperform GBT; PLR embeddings + regularization are often needed for parity (Table 1).
  - **Data source selection**: Adding sources can hurt performance if they push useful transactions out of the context window (Table 2: BC < B).

- Failure signatures:
  - Overfitting during fine-tuning: Mitigate with LoRA (not full fine-tuning), weight decay, dropout.
  - DNN tabular model underperforming GBT: Add PLR numerical embeddings; check regularization.
  - Performance degrading with more data sources: Audit information density; high-frequency low-signal sources may displace valuable transactions.
  - Embedding instability in fusion: Normalize transformer embeddings before concatenation.

- First 3 experiments:
  1. **Tokenization ablation**: Compare special-token-only vs. text-only vs. hybrid on a held-out transaction reconstruction task. Verify that hybrid captures both structured patterns and description semantics.
  2. **Tabular parity test**: Train DCNv2 with PLR embeddings on your tabular features alone. Compare vs. LightGBM baseline; iterate until within 0.1% AUC before attempting joint fusion.
  3. **Fusion strategy comparison**: On a 5M-row subset, compare (a) early fusion (frozen embeddings + GBT), (b) late fusion (fine-tuned embeddings + GBT), (c) joint fusion (end-to-end DNN). Expect joint fusion to win if tabular-embedding interactions matter.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the rigorous scaling laws (e.g., power laws) governing the performance of transformer-based transaction embedding models relative to model size and data volume?
- **Basis in paper:** [explicit] The authors state in Section 4.3.2 and the Conclusion: "In future work, we plan to derive scaling laws for these transaction based user embedding models."
- **Why unresolved:** While the paper demonstrates that increasing parameters (24M to 330M) and data improves performance, it does not formalize the mathematical relationship or predict diminishing returns.
- **What evidence would resolve it:** A comprehensive empirical study plotting validation loss and downstream AUC against varying orders of magnitude for parameter count, training duration, and dataset size.

### Open Question 2
- **Question:** Can the nuFormer embeddings transfer effectively to diverse downstream financial tasks beyond the recommendation domain tested in this study?
- **Basis in paper:** [explicit] The Conclusion explicitly lists as future work the goal to "show that they are powerful foundation models by applying them to a diverse collection of problems."
- **Why unresolved:** The empirical validation in the paper is restricted to a single recommendation task (product activation/churn prediction) involving a 6-month delay label.
- **What evidence would resolve it:** Benchmarking the pre-trained embeddings on distinct tasks such as credit risk scoring, fraud detection, or income estimation to verify generalization capabilities.

### Open Question 3
- **Question:** How can tokenization or context management be optimized to prevent the observed performance degradation when merging heterogeneous financial data sources?
- **Basis in paper:** [inferred] Section 4.3.1 notes that adding data sources can decrease AUC (e.g., $ABC < AB$) because "additional transactions caus[e] increased contention in the already limited context window."
- **Why unresolved:** The current static tokenization approach forces high-frequency/low-value data (source B) to displace low-frequency/high-value data (source A), hurting the model.
- **What evidence would resolve it:** Experiments utilizing dynamic context allocation or source-aware compression techniques that yield monotonically non-decreasing performance as data sources are added.

## Limitations
- Single-institution evaluation limits external validity of performance claims
- Critical hyperparameters (amount quantization boundaries, PLR periods) not fully specified
- Effectiveness for new users with sparse transaction history untested
- Implementation complexity requires careful hyperparameter tuning

## Confidence
**High confidence** in the core architectural claims:
- Representing transactions as token sequences enables standard transformer architectures
- Causal next-token prediction produces useful user embeddings
- Joint fusion with PLR embeddings can match or exceed GBT baselines

**Medium confidence** in performance claims:
- The +1.25% AUC improvement is statistically significant within the paper's experimental framework
- The 4.4% churn reduction represents a production outcome but lacks statistical significance testing

**Low confidence** in cross-domain generalization:
- No experiments on datasets outside Nubank
- No ablation of transaction types to understand which patterns drive predictive power

## Next Checks
1. **Tokenizer ablation study**: Systematically vary the amount quantization scheme (bin count, boundary selection) and measure impact on downstream task performance to clarify whether specific tokenization choices are critical.

2. **Temporal generalization test**: Train on transactions from period T1 and evaluate on T2 with shifted economic conditions to reveal whether learned embeddings capture robust behavioral patterns or merely memorize temporal correlations.

3. **User segment analysis**: Stratify performance by user tenure, transaction frequency, and product usage to identify whether the method's benefits concentrate among high-activity users or extend to the broader population where it might have the greatest business impact.