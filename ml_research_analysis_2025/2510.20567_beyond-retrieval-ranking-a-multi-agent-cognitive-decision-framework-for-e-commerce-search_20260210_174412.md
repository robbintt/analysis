---
ver: rpa2
title: 'Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce
  Search'
arxiv_id: '2510.20567'
source_url: https://arxiv.org/abs/2510.20567
tags:
- user
- search
- macdf
- decision
- e-commerce
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a Multi-Agent Cognitive Decision Framework (MACDF)
  to address the limitations of traditional e-commerce search systems, which often
  fail to meet complex user needs due to their reliance on query-item matching. MACDF
  replaces the conventional retrieval-ranking paradigm with a collaborative ensemble
  of specialized agents that simulate professional shopping consultants, aiming to
  reduce user decision costs and provide proactive decision support.
---

# Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search

## Quick Facts
- arXiv ID: 2510.20567
- Source URL: https://arxiv.org/abs/2510.20567
- Reference count: 40
- Primary result: Multi-agent framework improves e-commerce search conversion by 6.5% through cognitive decision support

## Executive Summary
This paper proposes MACDF (Multi-Agent Cognitive Decision Framework) to address the limitations of traditional e-commerce search systems that rely on keyword matching and fail to meet complex user needs. MACDF replaces the conventional retrieval-ranking paradigm with a collaborative ensemble of specialized agents that simulate professional shopping consultants, aiming to reduce user decision costs and provide proactive decision support. The framework includes agents for intent clarification, task planning, product and web search, and decision synthesis, achieving significant improvements in recommendation accuracy and user satisfaction, especially for complex queries.

## Method Summary
MACDF is a multi-agent system that transforms e-commerce search from a retrieval task into a cognitive decision process. The framework consists of six specialized agents: Leader (orchestrator), Guider (intent clarification), Planner (task decomposition via DAGs), ProductSearch (vector + keyword hybrid retrieval), WebSearch (real-time web information), and Decider (multi-criteria synthesis using AHP and Pareto Optimality). The system uses Deepseek-V3 for reasoning agents and Qwen3-8B for execution agents, trained with distillation from Deepseek-R1. Offline evaluation uses the proprietary ECCD-Bench dataset, while online A/B testing on JD.com demonstrates significant improvements in business metrics including 6.5% increase in user conversion rate and 7.7% reduction in query reformulation count.

## Key Results
- Online A/B testing shows 6.5% increase in user conversion rate and 3.9% increase in click-through rate
- 7.7% reduction in query reformulation count demonstrates improved search satisfaction
- 15-second average response time versus 0.8-second baseline represents significant latency trade-off
- Offline evaluation on ECCD-Bench shows superior performance on complex query categories including negation and multi-constraint queries

## Why This Works (Mechanism)

### Mechanism 1: Task Decomposition via Directed Acyclic Graphs (DAG)
If complex user intents are decomposed into structured dependency graphs rather than linear keyword matches, the system can parallelize information retrieval and cover implicit constraints more effectively. The Planner Agent translates user intent into a DAG where vertices are atomic tasks and edges are dependencies, allowing parallel execution of independent searches. This assumes the LLM-based Planner can accurately map natural language intent to a logically ordered task graph without introducing cycles.

### Mechanism 2: Interactive Intent Convergence via Guider Agent
Reducing the "semantic gap" requires an interactive clarification loop that minimizes interaction rounds while maximizing intent confidence. The Guider Agent employs Q-learning with a reward function balancing Intent Gain against Interaction Rounds to select optimal clarification questions. This assumes users will engage in multi-turn interaction if it reduces overall decision cost.

### Mechanism 3: Multi-Source Synthesis and Decision Theory
Shifting from "retrieval" to "decision support" is achieved by aggregating heterogeneous signals within a multi-criteria decision matrix. The Decider Agent applies AHP and Pareto Optimality to weigh functional performance, economic cost, and risk reliability. This assumes LLMs can effectively simulate expert decision-making logic via prompt engineering to balance conflicting constraints.

## Foundational Learning

- **Directed Acyclic Graphs (DAG) in Task Planning**: Essential for understanding how the Planner Agent decomposes complex searches into parallel sub-tasks and manages execution order. Quick check: Can you explain why a DAG is superior to a linear chain for executing parallel web and product searches?

- **Simon's Three-Stage Decision-Making Model**: The framework explicitly cites this model (Intelligence, Design, Choice) to structure the agent workflow. Understanding this helps map the "Guider" to Intelligence and "Decider" to Choice. Quick check: Which specific agent in MACDF corresponds to the "Design" phase (generating alternatives/task graphs)?

- **Q-Learning in Dialogue Management**: The Guider Agent uses Q-learning to optimize clarification questions. You need to understand the balance between "Intent Gain" (value) and "Interaction Rounds" (cost). Quick check: In the Guider's reward function, what happens to the agent's behavior if the weight β for "Interaction Rounds" is increased?

## Architecture Onboarding

- **Component map**: Query Input -> Leader (Intent Analysis) -> [If ambiguous] Guider (Clarification) -> Planner (DAG Generation) -> ProductSearch + WebSearch (Parallel Execution) -> Memory Update -> Decider (Synthesis) -> Output

- **Critical path**: The system follows a sequential flow with parallel execution opportunities at the search stage. The Leader Agent handles intent reasoning and dispatches Guider/Planner, while the Decider Agent synthesizes final recommendations using multi-criteria evaluation.

- **Design tradeoffs**: MACDF achieves higher conversion (+6.5%) but increases latency significantly (15s vs 0.8s baseline). The system trades speed for cognitive decision support. The autonomous re-planning capability improves results but makes behavior less deterministic for debugging.

- **Failure signatures**: High drop-off rate from users exiting before results return, looping behavior from continuous reflection-triggered re-planning, and context dilution from irrelevant web search results causing inaccurate advice synthesis.

- **First 3 experiments**: 1) Latency Profiling to measure DAG execution path vs baseline, 2) Intent Accuracy Test on ECCD-Bench "Negation Intent" and "Multi-Constraint" categories, 3) Ablation on Reflection to measure impact on ARC and User Satisfaction.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can MACDF reduce its average latency (currently 15s) to match traditional systems (0.8s) without significant degradation in decision quality? The paper lists improving computational efficiency as a primary future direction due to the 18.75× longer processing time.

- **Open Question 2**: What is the long-term impact of cognitive decision support on user retention and lifetime value compared to short-term gains in conversion rates? The evaluation relies primarily on short-term metrics from a two-week online experiment.

- **Open Question 3**: Which specific agents or collaborative strategies within MACDF are most critical for observed performance improvements? The paper admits that "further systematic ablation studies are required to determine which collaborative combination is the most critical."

## Limitations

- The framework relies on proprietary datasets (ECCD-Bench) and internal APIs (JD.com Product Search, ZhiPu Web Search) that are not publicly accessible, making complete reproduction challenging.

- The 15-second average response time represents a substantial trade-off against traditional systems (0.8 seconds), which could limit practical deployment despite performance gains.

- The paper doesn't address failure cases where multi-agent coordination becomes a bottleneck or where the reflection mechanism triggers infinite re-planning loops.

## Confidence

- **High Confidence**: Online A/B testing results showing UCTR (+3.9%), UCVR (+6.5%), and ARC (-7.7%) reduction are well-documented with clear methodology and statistically significant sample sizes.

- **Medium Confidence**: Offline evaluation on ECCD-Bench demonstrates improved performance on complex query categories, but the dataset's proprietary nature prevents independent verification.

- **Low Confidence**: Specific implementation details of the Leader Agent's reflection mechanism and exact prompt templates are not fully specified, making it difficult to assess whether the described behavior can be faithfully reproduced.

## Next Checks

1. **Latency Impact Assessment**: Conduct a controlled experiment measuring user engagement metrics at different response time thresholds (5s, 10s, 15s) to determine if the 15-second latency is justified by performance gains, or if streaming outputs could maintain user satisfaction while reducing perceived wait time.

2. **Ablation Study on Agent Components**: Systematically disable or replace individual agents (particularly the Planner's DAG generation and the Guider's Q-learning clarification) to quantify their individual contributions to overall performance metrics.

3. **Cross-Domain Transferability Test**: Implement a simplified version of MACDF using publicly available e-commerce datasets (like Amazon product data) to assess whether core mechanisms (DAG planning, intent clarification, multi-source synthesis) generalize beyond the JD.com platform.