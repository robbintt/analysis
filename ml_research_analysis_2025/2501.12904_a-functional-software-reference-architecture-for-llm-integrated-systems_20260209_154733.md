---
ver: rpa2
title: A Functional Software Reference Architecture for LLM-Integrated Systems
arxiv_id: '2501.12904'
source_url: https://arxiv.org/abs/2501.12904
tags:
- systems
- architecture
- integration
- software
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a preliminary functional reference architecture
  for LLM-integrated systems to address the lack of systematic design guidance. The
  authors identify key architectural concerns through literature review and expert
  experience, then propose a four-layer RA with cross-layer components for monitoring
  and guardrails.
---

# A Functional Software Reference Architecture for LLM-Integrated Systems
## Quick Facts
- arXiv ID: 2501.12904
- Source URL: https://arxiv.org/abs/2501.12904
- Authors: Alessio Bucaioni; Martin Weyssow; Junda He; Yunbo Lyu; David Lo
- Reference count: 27
- Primary result: Presents a 4-layer functional reference architecture for LLM-integrated systems, validated against three open-source systems

## Executive Summary
This paper addresses the lack of systematic design guidance for LLM-integrated systems by proposing a functional reference architecture (RA). Through literature review and expert experience, the authors identify key architectural concerns and develop a four-layer RA with cross-layer components for monitoring and guardrails. The architecture is validated by mapping three open-source LLM systems (MaxKB, Continue, InternVL) to the proposed components, demonstrating coverage of concerns like modularity, scalability, security, and interoperability. This work provides foundational framework for designing and evaluating LLM-integrated systems, though further validation across diverse domains is needed.

## Method Summary
The authors conducted a literature review and leveraged expert experience to identify architectural concerns for LLM-integrated systems. They then proposed a four-layer functional reference architecture consisting of Presentation, Application logic, LLM integration, and Data management layers, along with cross-layer components for monitoring and guardrails. The RA was evaluated through qualitative validation by mapping three open-source LLM systems (MaxKB, Continue, InternVL) to the defined architectural components using code analysis and traceability. The validation involved identifying where RA components like Orchestrator, Pre-processing, and Guardrails exist within the target systems' codebases.

## Key Results
- The four-layer RA effectively addresses identified concerns including modularity, scalability, security, and interoperability
- All three validation systems (MaxKB, Continue, InternVL) successfully mapped to the RA components as described in Table III
- The architecture provides comprehensive coverage with cross-layer components for monitoring and guardrails
- The RA structure enables systematic evaluation of LLM-integrated system designs

## Why This Works (Mechanism)
The reference architecture works by providing a structured, four-layer framework that separates concerns while maintaining integration points between layers. The functional approach focuses on what components do rather than how they're implemented, making it adaptable across different LLM system types. The inclusion of cross-layer monitoring and guardrail components addresses critical operational concerns that span multiple layers. By mapping existing systems to this structure, the authors demonstrate that the RA captures the essential architectural patterns found in real LLM-integrated implementations.

## Foundational Learning
- **Four-layer structure (Presentation, Application logic, LLM integration, Data management)**: Why needed: Separates concerns while maintaining integration; Quick check: Can you identify which layer handles user interaction vs. model interaction?
- **Cross-layer components (Monitoring, Guardrails)**: Why needed: Operational concerns span multiple layers; Quick check: Are monitoring and safety mechanisms implemented consistently across all system layers?
- **Component boundary definitions**: Why needed: Clear boundaries prevent architectural ambiguity; Quick check: Can you distinguish between Middleware and Pre-processing responsibilities?
- **Validation through traceability mapping**: Why needed: Ensures theoretical architecture aligns with practical implementations; Quick check: Can you map each RA component to actual code locations in target systems?
- **Functional vs. implementation view**: Why needed: Enables technology-agnostic design guidance; Quick check: Does the RA describe what components do rather than specific implementation technologies?

## Architecture Onboarding
**Component Map**: Presentation -> Application Logic -> LLM Integration -> Data Management (with Monitoring and Guardrail sidecars connecting across layers)

**Critical Path**: User request flows from Presentation through Application Logic (orchestration), to LLM Integration (pre-processing/tokenization), to LLM service, then back through Application Logic to Data Management (caching/vectoring), and finally to the user via Presentation

**Design Tradeoffs**: Functional view provides technology-agnostic guidance but may obscure implementation-specific performance characteristics; Cross-layer components add safety but increase architectural complexity

**Failure Signatures**: Missing guardrails indicate potential safety gaps; Ambiguous component boundaries suggest unclear separation of concerns; Incomplete layer coverage reveals architectural incompleteness

**3 First Experiments**:
1. Clone MaxKB repository and locate the Orchestrator component in the workflow engine
2. Identify LangChain usage in Continue to verify the Pre-processing component mapping
3. Confirm LoRA adapter usage in InternVL as the Task-specific adapter component

## Open Questions the Paper Calls Out
**Open Question 1**: Does the proposed reference architecture generalize to real-world LLM-integrated systems across diverse domains beyond the three open-source systems tested (computer vision, text processing, coding)?
- Basis: "However, further evaluation across real-world systems spanning diverse domains is essential to ensure broader coverage and uncover any overlooked challenges."
- Why unresolved: Validation was limited to three open-source systems in specific domains
- What evidence would resolve it: Successful mapping to real-world LLM systems in healthcare, finance, autonomous systems, and enterprise applications

**Open Question 2**: What additional architectural concerns exist for LLM-integrated systems that are not captured in the current reference architecture?
- Basis: "Additionally, there may be architectural concerns not yet considered, which is a natural aspect of the early-stage development of such frameworks."
- Why unresolved: Literature review yielded only three primary studies, and field is rapidly evolving
- What evidence would resolve it: Findings from ongoing systematic literature review including grey literature, or identification through expert surveys

**Open Question 3**: What dedicated architectural views (e.g., technical, compliance, fairness) should extend the functional reference architecture?
- Basis: "We also aim to extend this RA by incorporating dedicated architectural views, as suggested by the ISO/IEC/IEEE 42010 standard"
- Why unresolved: Current RA focuses on functional view; additional views following ISO/IEC/IEEE 42010 not yet developed
- What evidence would resolve it: Definition of additional views addressing stakeholder concerns not covered by functional view, validated through expert evaluation

**Open Question 4**: How do practitioners assess the practical applicability and utility of the reference architecture?
- Basis: "As part of future work, we also plan to conduct focus group validations and expert surveys"
- Why unresolved: Current validation performed by authors through mapping; external expert validation not conducted
- What evidence would resolve it: Qualitative feedback from focus groups and survey responses from software architects and practitioners

## Limitations
- Validation relies entirely on qualitative traceability mapping without quantitative performance metrics
- Selection of validation targets may introduce sampling bias, representing limited application domains
- Functional black-box approach limits insights into implementation-specific trade-offs and performance characteristics
- Component boundary definitions (e.g., Middleware vs. Pre-processing) may require subjective interpretation

## Confidence
- **High Confidence**: Identification of core architectural concerns (modularity, scalability, security, interoperability) through literature review and expert experience
- **Medium Confidence**: Four-layer reference architecture structure and component definitions provide reasonable mapping coverage for validation targets
- **Low Confidence**: Generalizability of reference architecture to diverse LLM-integrated system domains remains unproven

## Next Checks
1. **Expand Validation Scope**: Apply RA mapping methodology to at least five additional LLM-integrated systems spanning different domains (healthcare, finance, education)
2. **Implement and Benchmark**: Select one validation target system and implement RA components, measuring implementation overhead and performance compared to original
3. **Expert Review**: Conduct structured interviews with at least three LLM systems architects to evaluate practical utility and completeness of RA components