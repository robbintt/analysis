---
ver: rpa2
title: 'From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach
  and Dataset for Psychiatric Comorbidity'
arxiv_id: '2510.25232'
source_url: https://arxiv.org/abs/2510.25232
tags:
- patient
- sub-state
- doctor
- diagnostic
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces PsyCoTalk, the first large-scale dataset
  for psychiatric comorbidity diagnosis, containing 3,000 multi-turn dialogues between
  simulated doctor and patient agents. The dataset is constructed using a two-stage
  pipeline: first generating 502 structured electronic medical records (EMRs) from
  social media posts of users with self-reported psychiatric disorders, then employing
  a multi-agent framework with a hierarchical diagnostic state machine and context
  tree to generate dialogues.'
---

# From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity

## Quick Facts
- **arXiv ID:** 2510.25232
- **Source URL:** https://arxiv.org/abs/2510.25232
- **Reference count:** 39
- **Primary result:** Introduces PsyCoTalk, the first large-scale dataset for psychiatric comorbidity diagnosis with 3,000 multi-turn dialogues validated by licensed psychiatrists.

## Executive Summary
This paper presents PsyCoTalk, the first large-scale dataset for psychiatric comorbidity diagnosis containing 3,000 multi-turn dialogues between simulated doctor and patient agents. The dataset is constructed using a two-stage pipeline: first generating 502 structured electronic medical records (EMRs) from social media posts of users with self-reported psychiatric disorders, then employing a multi-agent framework with a hierarchical diagnostic state machine and context tree to generate dialogues. The dialogues are validated by licensed psychiatrists and show high structural and linguistic fidelity compared to real-world clinical transcripts. The dataset enables the development and evaluation of models for multi-disorder psychiatric screening, achieving 0.31 subset accuracy in diagnosis.

## Method Summary
The method employs a two-stage pipeline: Stage 1 constructs 502 EMRs from social media posts using symptom and life-event classifiers, then generates fictitious experiences to increase diversity. Stage 2 uses a multi-agent framework (doctor, patient, and tool agents) with a Hierarchical Diagnostic State Machine (HDSM) and Diagnostic Context Tree to generate dialogues. The HDSM translates SCID-5-RV protocols into discrete states with binary transitions, while the DSD-KG prevents symptom hallucinations. The system generates approximately 5,000 dialogues and filters them to 3,000 that match predefined comorbidity labels.

## Key Results
- PsyCoTalk achieves 0.31 subset accuracy in psychiatric comorbidity diagnosis, outperforming the 0.22 baseline from zero-shot LLMs
- Human evaluations show high realism scores (3.87/5.0) with significant improvement over baseline models (p<0.01)
- Structural and linguistic metrics demonstrate strong alignment with real-world clinical transcripts
- The dataset exhibits high diversity with normalized entropy scores of 0.89 and Jaccard similarity of 0.35

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical Diagnostic State Machine (HDSM) enables clinically-grounded, iterative diagnostic reasoning rather than random topic selection.
- Mechanism: The HDSM translates SCID-5-RV interview protocols into a three-level hierarchy (High-Level States, Intermediate-Level States, Basic-Level States) with explicit transition rules based on binary symptom responses. Sub-state groups aggregate related questions, and thresholds determine diagnostic transitions, emulating real psychiatric evaluation flow.
- Core assumption: SCID-5-RV protocols map cleanly onto discrete states with binary transitions, which may oversimplify nuanced clinical judgment.
- Evidence anchors:
  - [abstract] "Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards."
  - [Section 4.1] "In contrast to MDD-5k, which selected topics in random order, HDSM enables the agent to both ask questions and refine the diagnosis iteratively, reflecting real clinical reasoning."
  - [corpus] Related work (MDD-5k, MoodAngels) uses similar neuro-symbolic controllers, suggesting this is an evolving design pattern, but comparative effectiveness across frameworks remains under-evaluated.
- Break condition: If symptom presentations require non-binary or probabilistic state transitions, the current threshold-based design may produce premature or incorrect diagnostic paths.

### Mechanism 2
- Claim: Disease-Symptom Description Knowledge Graph (DSD-KG) prevents patient agents from hallucinating symptom agreements not grounded in their EMR.
- Mechanism: The patient agent consults the DSD-KG before responding. If a queried symptom is absent from the EMR or contradicts the provisional diagnosis, the agent responds "no," filtering spurious affirmations.
- Core assumption: The DSD-KG comprehensively captures valid symptom-disorder relationships per DSM-5, and EMR entries are sufficiently complete.
- Evidence anchors:
  - [Section 4.2] "Initial experiments revealed a bias towards affirming all symptoms, even those not documented in the EMR. To mitigate this, we developed a Disease–Symptom Description Knowledge Graph (DSD-KG) derived from SCID-5-RV guidelines."
  - [corpus] Corpus lacks direct comparisons of hallucination rates with/without DSD-KG; this mechanism is plausible but effect size is not quantified externally.
- Break condition: If EMRs omit symptoms present in real patients, or if DSD-KG coverage is incomplete for atypical presentations, the patient agent may incorrectly deny clinically relevant symptoms.

### Mechanism 3
- Claim: Modular EMR generation from social media posts preserves clinical realism while enabling scalable dialogue diversity.
- Mechanism: Posts are classified into EMR sections (Chief Complaint, Medical History, etc.) using symptom/life-event classifiers and keyword-based extraction, then synthesized via LLM. Each EMR yields multiple fictitious experiences, allowing 50+ unique dialogues per record while maintaining symptom consistency.
- Core assumption: Social media self-reports are sufficiently accurate and detailed to ground clinically valid EMRs; LLM generation does not introduce systematic distortions.
- Evidence anchors:
  - [Section 3.1] "We adopted a modular approach to EMR generation, which outperformed a single-step aggregation method in terms of information recall, classification accuracy, and reasoning coherence."
  - [Section 3.2] Psychiatrists confirmed EMR realism; Figure 3 shows alignment with real-world distributions, though age skews younger (20–24 vs. 30–34).
  - [corpus] MedSynth uses similar dialogue-note pair synthesis but in general medicine; cross-domain validation is limited.
- Break condition: If social media posts contain misdiagnoses or exaggerated symptom claims, synthetic EMRs may propagate inaccuracies without clinical correction.

## Foundational Learning

- Concept: **Finite State Machines for Dialogue Control**
  - Why needed here: The HDSM governs diagnostic flow across 130+ states; understanding state transitions, terminal states, and threshold-based branching is essential to debug or extend the system.
  - Quick check question: Given a patient responding "present" to 4 of 5 symptoms in a sub-state group with threshold=5, which branch should the HDSM take?

- Concept: **SCID-5-RV / DSM-5 Diagnostic Criteria**
  - Why needed here: All states, questions, and transitions derive from SCID-5-RV; familiarity prevents inadvertent clinical logic errors when modifying the pipeline.
  - Quick check question: What is the minimum duration criterion for a Major Depressive Episode, and which HDSM node enforces it?

- Concept: **Multi-Agent Orchestration with Tool Agents**
  - Why needed here: The Tool Agent mediates between symbolic state machines and LLM-based agents; understanding prompt generation, response classification, and termination conditions is critical for system reliability.
  - Quick check question: What triggers the "Experience Inquiry" branch in the Diagnostic Context Tree, and which agent decides this?

## Architecture Onboarding

- Component map: PsySym posts → Symptom/Life-Event Classifiers → Modular EMR sections (GPT-4o-mini) → 502 structured EMRs → Fictitious Experience Generator → D_his, D_fic dictionaries → Patient Agent (Qwen2.5-72B) + Doctor Agent (Qwen2.5-72B) + Tool Agent → HDSM state transitions + DCT context management → 3,000 dialogues

- Critical path:
  1. EMR quality → Symptom classifier accuracy directly affects downstream dialogue validity
  2. DSD-KG lookup → Patient response correctness; failures here cascade into incorrect diagnostic trajectories
  3. HDSM threshold logic → Terminal diagnosis assignment; misconfigured thresholds yield invalid labels
  4. Tool Agent response classification (ResponseClassifier) → State transitions depend on correct present/absent labeling

- Design tradeoffs:
  - Binary vs. 4-point symptom scale: Paper collapses SCID-5-RV's 4-point scale to binary for tractability, potentially losing clinical nuance
  - Fixed thresholds (e.g., ≥5 for MDD): May not generalize across disorder combinations or cultural contexts
  - Chinese-only release: Ensures annotation quality but limits multilingual applicability
  - EMR reuse (502 EMRs → 3,000 dialogues): Increases diversity via fictitious experiences but risks overfitting if downstream models memorize EMR-specific patterns

- Failure signatures:
  - Patient agent affirms all symptoms → DSD-KG lookup failing or prompt not enforcing constraint
  - Dialogue terminates prematurely → HDSM terminal state reached before DCT traversal complete, or IsDialEnd logic error
  - Diagnosis mismatch with EMR label → Sub-state machine ordering or threshold misconfiguration; check symptom-informed vs. random ordering
  - Repetitive doctor utterances → Profile cues not injected, or few-shot examples exhausted

- First 3 experiments:
  1. **Ablate DSD-KG:** Run dialogue generation with DSD-KG disabled; measure hallucination rate (symptom affirmations not in EMR) and compare against baseline. Confirm paper's claim that DSD-KG reduces spurious agreements.
  2. **Threshold sensitivity analysis:** Vary MDD threshold (e.g., 4, 5, 6) on held-out EMRs; measure subset accuracy and F1 per disorder. Identify if current thresholds are optimal or overfit to dataset construction.
  3. **Cross-validate with real clinical transcripts:** Use the 1,731 real-world dialogues mentioned in Appendix A.2.2 to compute diversity metrics (normalized entropy, hapax proportion, semantic diversity) and compare against PsyCoTalk; verify generalization beyond synthetic data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does training diagnostic models on the synthetic PsyCoTalk dataset yield better performance on real-world clinical interactions compared to models trained solely on smaller, authentic clinical corpora?
- Basis in paper: [inferred] The paper validates the realism of the synthetic dialogues via human evaluation and structural metrics, but it does not provide empirical evidence regarding the efficacy of transferring models trained on this synthetic data to real clinical deployments.
- Why unresolved: The domain gap between LLM-generated simulations and actual patient behavior (despite high structural fidelity) remains a critical unknown in the "sim-to-real" transfer for psychiatric AI.
- What evidence would resolve it: A comparative study measuring the diagnostic accuracy of models fine-tuned on PsyCoTalk versus real transcripts when tested on a held-out set of real-world doctor-patient interactions.

### Open Question 2
- Question: To what extent does the demographic bias in the source data (specifically the age skew towards 20–24 years) limit the diagnostic generalizability of models trained on PsyCoTalk for older populations?
- Basis in paper: [inferred] Section 3.2 and Figure 3 acknowledge that the synthetic EMRs show an age peak at 20–24, whereas real-world records peak at 30–34, a discrepancy attributed to the younger user base of the source social media platform (Reddit/PsySym).
- Why unresolved: While the symptom distribution matches clinical expectations, the specific linguistic and symptom expression patterns of the underrepresented older demographic may not be adequately captured.
- What evidence would resolve it: Stratified diagnostic accuracy results showing model performance across different age brackets, specifically testing for performance degradation in the 30+ age groups.

### Open Question 3
- Question: Can the Hierarchical Diagnostic State Machine (HDSM) framework be effectively extended to rarer psychiatric conditions while maintaining clinical validity and manageable state complexity?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that the work "limits coverage of rarer conditions" but suggest the "pipeline is extensible and can be scaled to broader disorder coverage... in future work."
- Why unresolved: Adding more disorders increases the state space combinatorially, which may introduce conflicts in the diagnostic logic or make the dialogue flow incoherent.
- What evidence would resolve it: Successful generation and psychiatric validation of dialogues involving disorders outside the current four (MDD, AD, BD, ADHD), such as Schizophrenia or Eating Disorders, using the existing architecture.

## Limitations
- The dataset's clinical realism depends on the accuracy of social media self-reports, which may contain misdiagnoses or symptom exaggerations.
- The binary symptom scale simplification from SCID-5-RV's 4-point scale could miss clinically relevant nuances.
- Cross-cultural generalizability is untested, as the dataset uses Chinese language and DSM-5 criteria predominantly validated in Western contexts.

## Confidence

- **High confidence:** The two-stage pipeline architecture (EMR generation → dialogue simulation) is technically sound and reproducible given the detailed implementation specifications. The human evaluation methodology and statistical comparisons are robust.
- **Medium confidence:** Claims about clinical realism and diagnostic accuracy are supported by psychiatrist validation and subset accuracy metrics, but lack independent replication on real-world clinical data beyond the 1,731 transcripts mentioned in Appendix A.2.2.
- **Low confidence:** The dataset's ability to capture atypical symptom presentations or cultural variations in psychiatric expression remains uncertain, as the construction methodology assumes standard DSM-5 presentations.

## Next Checks

1. Conduct an ablation study disabling the DSD-KG to measure hallucination rates (symptom affirmations not present in EMRs) and compare against the baseline claims of reduced spurious agreements.
2. Perform threshold sensitivity analysis by varying diagnostic criteria (e.g., MDD threshold from 4 to 6 symptoms) and measuring impacts on subset accuracy and disorder-specific F1 scores to identify potential overfitting.
3. Cross-validate dialogue diversity and realism metrics against the 1,731 real-world clinical transcripts using normalized entropy, hapax proportion, and semantic diversity measures to assess generalization beyond synthetic data.