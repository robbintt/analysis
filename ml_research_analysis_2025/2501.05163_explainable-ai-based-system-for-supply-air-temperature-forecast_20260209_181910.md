---
ver: rpa2
title: Explainable AI based System for Supply Air Temperature Forecast
arxiv_id: '2501.05163'
source_url: https://arxiv.org/abs/2501.05163
tags:
- feature
- values
- shapley
- asat
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the need for explainability in AI-driven supply
  air temperature (ASAT) forecasting for HVAC control systems. It employs SHapley
  Additive exPlanations (SHAP), a Shapley values-based XAI method, to interpret a
  linear regression model with Huber loss that forecasts ASAT.
---

# Explainable AI based System for Supply Air Temperature Forecast

## Quick Facts
- arXiv ID: 2501.05163
- Source URL: https://arxiv.org/abs/2501.05163
- Reference count: 21
- Primary result: SHAP-based XAI reveals that historical ASAT and average room temperature are more predictive than ambient temperature for short-horizon ASAT forecasts.

## Executive Summary
This paper proposes an explainable AI system for forecasting supply air temperature (ASAT) in HVAC control systems using SHapley Additive exPlanations (SHAP). The approach employs a linear regression model with Huber loss and generates contrastive explanations—slices—for each forecasted ASAT value. By analyzing feature contributions through semantic and physical interpretations, the study highlights the importance of historical ASAT data and average room temperature while noting the lower impact of ambient temperature. The SHAP method provides global model interpretability, ensuring all features contribute to predictions and supporting field experts in understanding and validating ASAT forecasts.

## Method Summary
The method uses linear regression with Huber loss to forecast ASAT, leveraging a 2D dynamic array constructed from a sliding window approach with lag-37 (representing operational hours 08:00-17:00 at 15-minute resolution) spanning two previous days. Feature engineering combines historical ASAT values from day-1 and day-2, ambient temperature, and average room temperature. SHAP (KernelSHAP or LinearSHAP) generates per-timestamp feature contributions visualized as waterfall plots. The approach provides contrastive explanations that fairly distribute prediction contributions across all features, creating additive, globally consistent explanations through Shapley values from cooperative game theory.

## Key Results
- SHAP analysis shows historical ASAT values and average room temperature are the most important features for forecasting, while ambient temperature has lower impact
- The linear model with Huber loss provides interpretable baseline forecasts with reported max error of 2.1°C at 14:45 on October 10, 2024
- Waterfall plots generated by SHAP provide semantic explanations for each forecasted ASAT value, enabling objective justifications for control curve changes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SHAP provides contrastive explanations that fairly distribute prediction contributions across all features
- Mechanism: Shapley values from cooperative game theory compute each feature's average marginal contribution across all possible feature coalitions. The efficiency property ensures that the sum of all Shapley values equals the difference between the actual prediction and the average prediction: $\sum_{i=1}^{M} \phi_i = \hat{f}(x) - E_X(\hat{f}(X))$. This creates additive, globally consistent explanations.
- Core assumption: The background dataset used for sampling unobserved features is representative of the true data distribution
- Evidence anchors: Abstract states SHAP "allows to reveal the reasoning and highlight the contribution of each feature"; section II-B cites axioms of efficiency, symmetry, dummy, and additivity; corpus shows weak direct support for HVAC-specific SHAP applications

### Mechanism 2
- Claim: Historical ASAT values from previous days are more predictive than ambient temperature for short-horizon forecasts
- Mechanism: The sliding window approach constructs a 2D dynamic array using lag-37 features from two prior days. This captures autocorrelation in the supply air temperature signal, which encodes building thermal mass effects, occupancy patterns, and control system dynamics
- Core assumption: The system's thermal behavior exhibits sufficient day-to-day periodicity that historical values remain informative
- Evidence anchors: Section IV identifies relevant features at beginning and end of feature vector; notes lower effect of ambient temperature; corpus supports that indoor temperature forecasting benefits from historical sensor data

### Mechanism 3
- Claim: Linear models with Huber loss provide interpretable baselines that can be post-hoc explained without surrogate model approximation error
- Mechanism: Linear regression with Huber loss is robust to outliers (quadratic loss near zero, linear loss beyond threshold). SHAP explanations for linear models have closed-form solutions: $\phi_i(\hat{f}) = \beta_i x_i - E(\beta_i X_i)$. This avoids variance from Monte-Carlo sampling required for complex models
- Core assumption: The relationship between features and ASAT is approximately linear or the linear model is sufficient for control purposes
- Evidence anchors: Abstract states focus on linear regression with Huber loss; section II-A provides the formula for feature contribution; corpus shows neighbor papers don't directly compare linear vs. deep learning for HVAC forecasting

## Foundational Learning

- Concept: Shapley Values and Coalition Games
  - Why needed here: The paper assumes readers understand how cooperative game theory translates to feature attribution—the "fairness" of Shapley values comes from averaging contributions across all possible player (feature) coalitions
  - Quick check question: If you have 3 features, how many coalitions must be evaluated for exact Shapley values? (Answer: $2^3 = 8$)

- Concept: Sliding Window Time Series Transformation
  - Why needed here: The paper's feature engineering converts univariate time series into supervised learning inputs using lag features; understanding this is essential to interpret the 2D dynamic array structure
  - Quick check question: Given a lag of 5 and a time series [10, 12, 14, 16, 18, 20], what are the input features and target for the first training sample? (Answer: Input = [10, 12, 14, 16, 18], Target = 20)

- Concept: Huber Loss
  - Why needed here: The paper specifies Huber loss without detailed explanation; understanding its quadratic-near-zero / linear-beyond-threshold behavior explains why it's chosen for noisy HVAC sensor data
  - Quick check question: Why might Huber loss outperform MSE for temperature sensor data with occasional spikes? (Answer: Linear penalty for large errors reduces sensitivity to outliers)

## Architecture Onboarding

- Component map: Sensor Data (AT, RT-avg, ASAT history) → Feature Engineering (2D Dynamic Array, lag-37 sliding window) → Linear Regression Model (Huber loss) → ASAT Forecast (37 values per operational day) → SHAP Explainer (Kernel or Linear SHAP) → Waterfall Plots + Semantic Mapping (feature → timestamp explanation) → Expert Review / Control Curve Adjustment

- Critical path: 1. Data ingestion and alignment (ensure 15-minute resolution, handle missing values) 2. 2D dynamic array construction (verify lag-37 indexing matches paper's time-step representation) 3. SHAP value computation (use `shap.LinearExplainer` for efficiency) 4. Semantic explanation mapping (f37 → "16:45 minus 2-DAYS" format in Table I)

- Design tradeoffs: Linear model + SHAP: Fast, exact explanations, but may underfit complex HVAC dynamics vs. LSTM/transformer alternatives; 2-day history window: Captures day-to-day patterns but increases feature dimensionality (74+ features with ambient/room temp); Waterfall plots: Human-readable for single timestamps, but 37 plots per day may overwhelm operators—consider summary views

- Failure signatures: Shapley values with unexpectedly high variance: Check background dataset size; too few samples increase estimation noise; Ambient temperature features showing near-zero importance: Verify sensor calibration; may indicate data quality issues rather than true irrelevance; Large forecast error at specific times (e.g., 14:45): Check occupancy anomalies or HVAC setpoint changes not captured in features

- First 3 experiments: 1. Replicate the feature vector construction with your building's ASAT data; verify that the first two SHAP-max features correspond to prior-day timestamps as shown in Figure 7; 2. Compare Linear SHAP vs. Kernel SHAP on the same model; quantify speed difference and check if Shapley values match (they should for linear models); 3. Introduce a synthetic perturbation (e.g., artificially increase ambient temperature by 5°C) and observe whether SHAP explanations correctly identify ambient temperature as a driver—if not, the model may have learned spurious correlations

## Open Questions the Paper Calls Out

- Question: How stable are the identified feature contributions—specifically the low impact of ambient temperature—when the forecasting model is applied across different seasons or extreme weather events?
  - Basis: The numerical results analyze only a single working day (October 10, 2024), leaving the generalizability of the feature importance rankings across diverse operational conditions untested
  - Why unresolved: The study validates the method on a narrow dataset without demonstrating robustness across varying environmental inputs that would likely alter physical dynamics
  - What evidence would resolve it: Feature importance rankings derived from SHAP analysis applied to a dataset covering multiple seasons and extreme weather scenarios

- Question: Can the SHAP-based explanation framework maintain its interpretability and semantic clarity when applied to non-linear deep learning forecasting models (e.g., LSTMs) for ASAT control?
  - Basis: The authors restrict the implementation to linear regression to ensure transparency, despite acknowledging that deep learning models are prevalent in the field
  - Why unresolved: The trade-off between the potential performance gains of complex models and the transparency of the proposed explanation system for non-linear decision boundaries remains unexplored
  - What evidence would resolve it: A comparative study of SHAP explanations for both linear and LSTM models on the same ASAT forecasting task to evaluate interpretability

- Question: To what extent does the "contrastive explanation" interface improve the decision-making accuracy or speed of field experts compared to traditional numerical logs?
  - Basis: The paper claims the method supports field experts and improves trust, but includes no user study, qualitative feedback, or quantitative measurement of human-in-the-loop performance
  - Why unresolved: The benefit of "semantic" explanations over raw model outputs is assumed based on theoretical transparency rather than empirical validation with human operators
  - What evidence would resolve it: A controlled user study measuring operator reaction times and fault diagnosis accuracy when using the SHAP-based interface versus standard tools

## Limitations

- The paper's explainability claims depend heavily on the assumption that linear models capture the dominant dynamics of ASAT behavior; if non-linear effects are significant, SHAP explanations may describe an incomplete model
- Ambient temperature's low feature importance is stated but not rigorously tested—it could reflect true irrelevance or data quality issues
- The 2-day historical window assumes stationarity in building usage, which may not hold during atypical operational periods

## Confidence

- High confidence: SHAP's theoretical foundation and ability to provide additive, globally consistent explanations; the use of historical ASAT data as a strong predictor is well-supported by time-series autocorrelation in HVAC systems
- Medium confidence: The relative importance of ambient vs. historical ASAT and room temperature is plausible but could benefit from additional experiments (e.g., ablation studies or synthetic perturbations)
- Low confidence: Generalizability of the approach to buildings with different thermal profiles or occupancy patterns; robustness of explanations to changes in operational regime

## Next Checks

1. Perform an ablation study: Remove ambient temperature features and retrain; compare forecast accuracy and SHAP explanations to confirm or refute its claimed low importance
2. Test model robustness: Introduce synthetic changes to ambient temperature and occupancy schedules; verify that SHAP explanations correctly attribute changes to the appropriate features
3. Compare against a non-linear baseline: Train an LSTM or transformer model on the same data; evaluate whether SHAP-based explanations remain stable and if forecast accuracy improves significantly