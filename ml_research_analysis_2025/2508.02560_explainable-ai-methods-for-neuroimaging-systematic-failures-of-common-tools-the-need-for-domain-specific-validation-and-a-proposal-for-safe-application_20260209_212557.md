---
ver: rpa2
title: 'Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools,
  the Need for Domain-Specific Validation, and a Proposal for Safe Application'
arxiv_id: '2508.02560'
source_url: https://arxiv.org/abs/2508.02560
tags:
- brain
- methods
- neuroimaging
- explanations
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents the first large-scale systematic comparison
  of XAI methods for neuroimaging, using ~45,000 structural brain MRIs. The authors
  developed a novel XAI validation framework that establishes verifiable ground truth
  by constructing prediction tasks with known signal sources, ranging from localized
  anatomical features to subject-specific clinical lesions, without artificially altering
  input images.
---

# Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools, the Need for Domain-Specific Validation, and a Proposal for Safe Application

## Quick Facts
- arXiv ID: 2508.02560
- Source URL: https://arxiv.org/abs/2508.02560
- Reference count: 40
- Key outcome: This study presents the first large-scale systematic comparison of XAI methods for neuroimaging, using ~45,000 structural brain MRIs. The authors developed a novel XAI validation framework that establishes verifiable ground truth by constructing prediction tasks with known signal sources, ranging from localized anatomical features to subject-specific clinical lesions, without artificially altering input images.

## Executive Summary
This study systematically evaluates three widely-used XAI methods (SmoothGrad, GradCAM, and LRP) for neuroimaging applications using ~45,000 structural brain MRIs. The authors develop a novel validation framework that establishes verifiable ground truth by constructing prediction tasks with known signal sources, ranging from localized anatomical features to subject-specific clinical lesions, without artificially altering input images. The analysis reveals systematic failures in two of the most widely used XAI methods in neuroimaging: GradCAM consistently failed to localize predictive features, while Layer-wise Relevance Propagation generated extensive artifactual explanations incompatible with neuroimaging data characteristics. In contrast, the simpler gradient-based method SmoothGrad, which makes fewer assumptions about data structure, proved consistently accurate across all tested scenarios.

## Method Summary
The study uses UK Biobank structural MRI data (T1w and T2 FLAIR, N≈45,760) preprocessed with bias correction, brain extraction, and linear registration to MNI152 space. The authors construct "corrected Imaging-Derived Phenotypes" (cIDPs) by removing global correlations from standard IDPs via PCA regression, creating prediction targets with known localized signal sources. A 3D ResNet-50 is trained to predict these targets, with performance validated by masking the target region and confirming prediction accuracy collapses (R²≈0). XAI methods (SmoothGrad, LRP with various rulesets, GradCAM with various layers) are then applied to these trained models and evaluated using Relevance Mass Accuracy (RMA) against the known ground truth masks. The study also validates methods on subject-specific lesion detection tasks.

## Key Results
- SmoothGrad consistently achieved RMA values above 80% for all tested scenarios, demonstrating reliable localization of predictive features.
- GradCAM failed to localize predictive features, with RMA values below 50% for most tasks and high "Miss" rates on small regions.
- LRP generated extensive artifactual explanations, with high false positive rates highlighting ventricles and brainstem regions unrelated to the target anatomy.
- The performance ranking of methods was inverted compared to natural image domains, with the simplest method proving most robust.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Domain mismatch causes XAI methods optimized for natural images to fail on volumetric neuroimaging data.
- **Mechanism:** Methods like GradCAM and LRP were tuned or validated on 2D natural images containing sharp edges and compositional hierarchies. Neuroimaging data features strong spatial correlations, diffuse features, and low-contrast boundaries. When applied to brain MRI, LRP's edge-biased rules latch onto high-contrast transitions (e.g., ventricles) rather than predictive tissue, and GradCAM's reliance on final layer activations misses non-hierarchical predictive features.
- **Core assumption:** The standard implementations and rule sets used in the study are representative of common off-the-shelf usage and inherently encode natural image priors.
- **Evidence anchors:**
  - [abstract] "failures stem from a domain mismatch, where methods optimized for natural images require substantial adaptation for neuroimaging data."
  - [section] "GradCAM... relying heavily on final convolutional layer activations... may falter when relevant information... is represented differently." and "LRP... appears prone to latching onto high contrast transitions... generating artifacts unrelated to true feature importance."
  - [corpus] Neighbor papers discuss the general need for XAI validation (e.g., EvalxNLP) and medical imaging overview, but corpus evidence is weak regarding the specific *mechanism* of LRP edge-bias failure on smooth volumetric data.
- **Break condition:** If neuroimaging-specific LRP rule sets are developed that suppress relevance propagation at high-contrast CSF-tissue boundaries, or if architectures explicitly learn compositional hierarchies for brain structures.

### Mechanism 2
- **Claim:** Conceptual simplicity in XAI methods (specifically SmoothGrad) improves robustness during domain shifts.
- **Mechanism:** SmoothGrad reduces noise by averaging gradients over multiple noisy versions of the input. Unlike LRP or GradCAM, it does not rely on heuristics about feature hierarchies or specific layer activations. Because it makes fewer assumptions about the data structure, it generalizes better from natural images to the continuous, smooth gradients of brain MRI.
- **Core assumption:** Averaging gradients from small perturbations approximates the true local importance manifold without introducing structural artifacts.
- **Evidence anchors:**
  - [abstract] "simpler, gradient-based method SmoothGrad, which makes fewer assumptions about data structure, proved consistently accurate."
  - [section] "The success of this relatively simple method suggests that approaches making fewer assumptions about data structure... may be inherently more robust to domain shifts."
  - [corpus] Weak support; corpus papers focus on LLM or finance XAI, not specifically on the robustness of gradient smoothing in 3D imaging.
- **Break condition:** If the noise level used for smoothing is insufficient to overcome 3D volumetric noise, or if the model relies on extremely sparse, non-local features where gradient averaging dilutes the signal.

### Mechanism 3
- **Claim:** Constructing prediction targets with isolated signal sources enables objective XAI validation without artificial image modification.
- **Mechanism:** The authors generate "corrected Imaging-Derived Phenotypes" (cIDPs) by removing global correlations (via PCA) from standard IDPs. This ensures a target (e.g., hippocampus volume) depends causally only on the local region, not global proxies like brain size. Since the model is forced to learn from the specific region, the ground truth for the XAI explanation is verifiably restricted to that region's mask.
- **Core assumption:** The PCA-based regression removes enough global variance to sever the predictive link between the target region and remote brain areas, forcing the model to use local anatomy.
- **Evidence anchors:**
  - [abstract] "establishing verifiable ground truth by constructing prediction tasks with known signal sources... without artificially altering input images."
  - [section] Methods: "when the target anatomical region was computationally removed... the model's ability to predict the cIDP collapsed (R² ≈ 0)."
  - [corpus] No direct corpus support for this specific cIDP validation methodology.
- **Break condition:** If the "correction" removes global signal but leaves residual correlations with other specific regions, or if the model relies on "suppressor variables" in other regions to contextualize the local signal.

## Foundational Learning

### Concept: 3D Convolutional Neural Networks (3D CNNs) vs. 2D
- **Why needed here:** The failure of GradCAM is partly attributed to the difference between 2D natural images and 3D volumetric MRI data (spatial correlations, lack of sharp edges). Understanding this distinction is critical to grasping the "domain mismatch."
- **Quick check question:** Why might a 2D XAI method that detects "edges" fail when applied to a 3D volume where tissue boundaries are smooth gradients rather than sharp pixel transitions?

### Concept: Gradient-based Attribution
- **Why needed here:** SmoothGrad, the "winning" method in this study, relies on gradients. Understanding that gradients represent the rate of change of the output with respect to input pixels is necessary to understand why "averaging" them reduces noise.
- **Quick check question:** If a model's prediction changes very little when a specific voxel is altered, what does that imply about the gradient magnitude at that voxel?

### Concept: Ground Truth in Validation
- **Why needed here:** The paper critiques "plausibility" checks (does it look right?) and introduces cIDPs as a mechanism for "ground truth." Learners must understand the difference between verifying an explanation looks plausible vs. verifying it points to the mathematically necessary location.
- **Quick check question:** If a model predicts "brain age" (a complex, distributed biomarker), why is it harder to establish ground truth for the explanation than for predicting "lesion load" (a localized pathology)?

## Architecture Onboarding
- **Component map:** UK Biobank MRIs → cIDP Generation (PCA-based) → 3D ResNet-50 → XAI Methods (SmoothGrad, LRP, GradCAM) → Relevance Mass Accuracy (RMA)
- **Critical path:** The **cIDP generation** is the system's lynchpin. Without correcting the IDPs to remove global correlations, the model learns shortcuts, making the ground truth mask invalid for evaluation.
- **Design tradeoffs:** The study identifies a tradeoff between **complexity** and **robustness**. Complex methods (LRP/GradCAM) perform well on natural images but fail here. Simple methods (SmoothGrad) are noisier on natural images but robust to the domain shift in neuroimaging.
- **Failure signatures:**
  - **GradCAM:** Diffuse, coarse heatmaps; High "Miss" rate on small regions (Low True Positive Rate).
  - **LRP:** Distinct high-intensity artifacts in ventricles or brain stem (high contrast regions) unrelated to the target; High False Positive Rate.
- **First 3 experiments:**
  1. **Masking Validation (Stage 1):** Train a model on a cIDP target. Achieve high performance. Then, train a second model on the same data but with the target region (e.g., caudate) masked to zero. Verify that performance drops to R² ≈ 0 to confirm the signal is localized.
  2. **XAI Artifacts (Stage 1 vs Natural):** Run LRP on a neuroimaging model and observe heatmaps. Compare against the LRP results on a standard 2D ImageNet model (Fig 4). Confirm the "inverse performance ranking" (LRP good on ImageNet, bad on MRI).
  3. **Threshold Sensitivity:** Generate SmoothGrad maps for a lesion prediction task. Apply different percentile thresholds (80th, 90th, 99th) to observe how post-processing affects the Relevance Mass Accuracy (RMA) and visual clarity.

## Open Questions the Paper Calls Out
- Can LRP be successfully adapted for neuroimaging through domain-specific rule sets, or is its core methodology fundamentally mismatched to this data modality? The authors state their findings "do not indicate fundamental flaws in the LRP framework itself" but rather "highlight the need for domain-specific adaptation," suggesting a path forward via "neuroimaging-specific rule configurations." The paper only characterizes the failure of off-the-shelf rules and does not perform systematic ablation studies or parameter optimization required to design, test, and validate new rule sets tailored for brain MRI statistics.
- Do the documented failures of GradCAM and LRP generalize to transformer-based architectures, which are becoming prominent in neuroimaging? The authors explicitly list this as a limitation, stating "resource constraints limited our analysis... A comprehensive evaluation across a wider range of architectures (e.g., Transformers) was beyond the current scope." The paper's conclusions are based on CNNs, leaving a critical methodological gap as Vision Transformers use self-attention mechanisms where explanations based on convolutional feature hierarchies may not apply.
- How should researchers interpret XAI results in real-world clinical datasets where models are known to exploit spurious correlations, such as scanner artifacts or site effects? The authors note that "even perfectly validated AI explanations do not necessarily reflect the underlying biological processes" and that models can exploit spurious correlations, leading to explanations that "accurately reflect what the model learned while misrepresenting the biological relationships of interest." The validation framework is designed to eliminate confounds for methodological ground truth but does not test the scenario where a faithful XAI method highlights a spurious but predictive feature.

## Limitations
- The specific PCA component selection criteria for cIDP generation, while described as "visually optimized," lacks fully detailed procedural guidelines and the exact threshold for "sufficient" correction is not standardized.
- The study focuses on structural MRI (T1/T2) and may not generalize to functional or diffusion imaging modalities where domain mismatch mechanisms may differ.
- While systematic failures are demonstrated, the study does not explore whether hyperparameter tuning or architectural modifications could rescue GradCAM or LRP performance for neuroimaging applications.

## Confidence
- **High confidence:** The systematic failures of GradCAM and LRP in neuroimaging contexts are well-demonstrated with objective ground truth validation. The conceptual simplicity-robustness relationship for SmoothGrad is supported by consistent empirical results.
- **Medium confidence:** The specific mechanism explaining why LRP produces artifactual explanations (edge-bias in smooth volumetric data) is plausible but requires further investigation. The generalizability of findings to other XAI methods not tested remains uncertain.
- **Low confidence:** Claims about the specific number of PCA components needed for cIDP generation are difficult to verify without the companion manuscript's detailed tables.

## Next Checks
1. **Transferability Test:** Apply the same XAI methods to functional MRI data to determine if the domain mismatch mechanisms hold for temporal-spatial data with different statistical properties.
2. **Architectural Modification Test:** Implement neuroimaging-specific adaptations of GradCAM (e.g., multi-scale attention mechanisms) to assess whether domain-specific tuning can recover performance.
3. **Cross-Resolution Test:** Evaluate XAI methods across different image resolutions (e.g., 1mm vs 2mm isotropic) to determine whether the failures are resolution-dependent or inherent to the data structure.