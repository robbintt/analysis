---
ver: rpa2
title: '"Don''t Do That!": Guiding Embodied Systems through Large Language Model-based
  Constraint Generation'
arxiv_id: '2506.04500'
source_url: https://arxiv.org/abs/2506.04500
tags:
- stpr
- path
- constraints
- constraint
- point
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents STPR, a neuro-symbolic navigation framework
  that uses LLMs to translate natural language constraints into executable Python
  functions for robotic path planning. The key idea is to leverage LLMs' coding capabilities
  to generate constraint functions, which are then integrated into point cloud representations
  for classical search algorithms like A and RRT.
---

# "Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation

## Quick Facts
- arXiv ID: 2506.04500
- Source URL: https://arxiv.org/abs/2506.04500
- Reference count: 40
- One-line primary result: STPR achieves 100% constraint compliance in robotic navigation by using LLMs to generate executable constraint functions, outperforming naive LLM planners with 0-10% success rates.

## Executive Summary
STPR introduces a neuro-symbolic framework that translates natural language constraints into executable Python functions for robotic path planning. The key insight is leveraging LLMs' coding capabilities rather than their reasoning abilities, generating constraint functions that are then integrated into point cloud representations for classical search algorithms like A* and RRT*. Experiments in Gazebo demonstrate STPR achieves perfect constraint compliance across four challenging scenarios while maintaining fast runtimes between 12-18 seconds, significantly outperforming naive LLM-based planners.

## Method Summary
STPR operates through a three-stage pipeline: (1) LLM prompt engineering generates Python boolean functions from natural language constraints using a structured template, (2) rejection sampling converts these functions into point clouds representing forbidden regions, and (3) classical planners (A* or RRT*) navigate around these virtual obstacles. The framework maintains theoretical guarantees by preserving the properties of the underlying search algorithms while shifting the complexity from navigation reasoning to code generation. The approach uses smaller, code-specific LLMs that demonstrate faster performance and lower hallucination risk compared to general-purpose models.

## Key Results
- STPR achieves 100% constraint compliance across four Gazebo test scenarios versus 0-10% for naive LLM planners
- Runtime remains practical at 12-18 seconds per planning query
- Smaller code-specific LLMs (Granite-34B) perform comparably to larger models while offering faster inference
- Success rates are robust across diverse constraint types including camera FOV avoidance, hole detection, and heat dissipation zones

## Why This Works (Mechanism)

### Mechanism 1: Code as an Intermediate Representation for Constraints
Translating natural language constraints into executable Python functions reduces ambiguity and hallucination compared to direct end-to-end LLM planning. LLMs possess stronger syntactic and structural reasoning capabilities for code than for free-form spatial navigation text. By enforcing a fixed function signature and providing a structured prompt, STPR forces the LLM to map abstract instructions into precise mathematical logic inside a Python function. The core assumption is that the LLM's pre-training on code allows it to translate semantic concepts into geometric/mathematical logic more reliably than it can reason about a specific environment's topology directly.

### Mechanism 2: Spatial Pruning via Rejection Sampling
Converting constraint functions into point clouds via rejection sampling allows classical planners to treat abstract rules as physical obstacles. The generated Python function acts as a boolean oracle. STPR samples points in the environment, tests them against the oracle, and retains only those satisfying the constraint. These points are stored in a K-d tree, and the path planner treats these points as "imaginary obstacles," pruning any trajectory that ventures too close. The core assumption is that the density of the sampled point cloud is sufficient to approximate the continuous forbidden region defined by the code.

### Mechanism 3: Preservation of Theoretical Guarantees via Planner Agnosticism
Decoupling constraint definition from path execution preserves the theoretical properties (completeness, optimality) of the underlying classical planner. The LLM does not generate the path; it only modifies the topology of the traversable space. Because A* and RRT* operate on this modified space without internal modification, they retain their inherent guarantees. A* remains complete and optimal; RRT* remains probabilistically complete. The core assumption is that the constraint generation step is treated as a static preprocessing step, and the environment does not change dynamically in a way that invalidates the sampled point cloud during planning.

## Foundational Learning

- **Concept: A* and RRT* Search Algorithms**
  - Why needed here: These are the "engines" of STPR. Understanding their trade-offs is critical: A* guarantees optimality on a grid but scales poorly with dimension; RRT* is asymptotically optimal in continuous space but relies on sampling density.
  - Quick check question: If STPR uses A* on an 8-connected grid, does it guarantee the globally shortest path in the continuous 3D space?

- **Concept: Rejection Sampling**
  - Why needed here: This is the bridge from Code to Geometry. You must understand how sampling efficiency drops as the constrained volume decreases relative to the total space.
  - Quick check question: If a forbidden region is a tiny sphere in a large room, why might simple rejection sampling be inefficient, and how does STPR attempt to mitigate this?

- **Concept: K-d Trees**
  - Why needed here: Used for efficient nearest-neighbor queries during collision checking. Understanding the O(log N) lookup cost is key to analyzing STPR's runtime scaling with point density K.
  - Quick check question: Why does the runtime for collision checking increase logarithmically with the number of sampled points K?

## Architecture Onboarding

- **Component map:** Prompt Engineer -> LLM Inference -> Code Executor -> Sampler -> Planner Interface
- **Critical path:** The Constraint Block in the prompt -> LLM logic generation -> Sampling density (K). If the LLM logic is flawed or K is too low, the architecture fails.
- **Design tradeoffs:**
  - LLM Size: Smaller code-specific models (Granite-34B) work well and are faster/cheaper than GPT-4 or Llama-405B
  - Point Density (K): Higher K improves collision accuracy but increases memory and lookup time (O(log K))
  - Planner Choice: A* is better for strict optimality in 2D; RRT* is better for continuous 3D spaces with complex geometry
- **Failure signatures:**
  - "No Path Found" (False Negative): Often caused by an LLM generating an overly conservative constraint or high point density blocking narrow passages
  - Invalid Path (False Positive): Caused by low sampling density (K=100 in the paper's ablation) creating gaps in the "virtual wall"
  - Syntax Error: LLM omits imports (e.g., import math); paper notes this was an issue with some smaller models requiring prompt tuning
- **First 3 experiments:**
  1. Run the same "Fireplace" prompt 10 times with a small code-model to check for syntactic consistency and logical correctness
  2. Implement the sampler and planner. Vary K (100, 1000, 10000) and measure the rate of constraint violations in a simple 2D "don't cross this line" scenario
  3. Connect the LLM output directly to a Python exec() call (safely) to verify the pipeline from "Text -> Code -> Point Cloud -> Path" works end-to-end before optimizing latency

## Open Questions the Paper Calls Out
None

## Limitations
- The approach assumes static environments where constraints don't change dynamically during planning
- Rejection sampling efficiency decreases significantly when forbidden regions are small relative to the environment volume
- The framework relies on prompt engineering quality and may not generalize to more complex or ambiguous constraint descriptions
- No theoretical guarantees about sampling completeness for irregularly shaped forbidden regions

## Confidence
- **High confidence:** The architectural separation of concerns (LLM for constraint generation, classical planner for pathfinding) is sound and preserves theoretical guarantees of the underlying search algorithms
- **Medium confidence:** The empirical results showing 100% constraint compliance across four scenarios are convincing within the tested environment, though the small sample size limits statistical robustness
- **Low confidence:** The claim that STPR "circumvents potential hallucinations" is overstatedâ€”the approach merely shifts hallucination risk from navigation reasoning to code generation

## Next Checks
1. Stress test with adversarial prompts: Systematically vary constraint descriptions to quantify the sensitivity of generated constraint functions to linguistic variations
2. Sampling completeness analysis: Measure the relationship between forbidden region volume, point density K, and false negative rate in controlled synthetic environments
3. Cross-scenario generalization: Test STPR on a benchmark suite with diverse constraint types beyond the current four static scenarios to evaluate real-world applicability