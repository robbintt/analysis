---
ver: rpa2
title: '600k-ks-ocr: a large-scale synthetic dataset for optical character recognition
  in kashmiri script'
arxiv_id: '2601.01088'
source_url: https://arxiv.org/abs/2601.01088
tags:
- dataset
- kashmiri
- text
- recognition
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the 600K-KS-OCR dataset, a large-scale synthetic
  corpus of approximately 602,000 word-level segmented images for training and evaluating
  optical character recognition (OCR) systems targeting the Kashmiri script. The dataset
  addresses the critical resource gap for Kashmiri, an endangered Dardic language
  spoken by approximately seven million people that uses a modified Perso-Arabic writing
  system.
---

# 600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script

## Quick Facts
- arXiv ID: 2601.01088
- Source URL: https://arxiv.org/abs/2601.01088
- Reference count: 9
- Primary result: Introduces a 602k synthetic Kashmiri word image dataset with multi-format labels

## Executive Summary
This paper presents 600K-KS-OCR, a large-scale synthetic dataset for Kashmiri script OCR addressing the critical resource gap for this endangered Dardic language. The dataset contains approximately 602,000 word-level segmented images rendered at 256×64 pixels using three traditional Kashmiri typefaces. Each image includes ground-truth transcriptions in multiple formats compatible with popular OCR frameworks. The dataset is partitioned across ten archives totaling ~10.6 GB and released under CC-BY-4.0 license for research use.

## Method Summary
The dataset generation employs synthetic rendering of Kashmiri text using three traditional typefaces (Afan Koshur Naksh, Nastaleeq, Nakash) at 256×64 pixels. The process incorporates comprehensive data augmentation including rotation, perspective distortion, various blur types, noise injection, brightness/contrast adjustments, and background textures simulating aged paper and ink bleed effects. The dataset is partitioned into ten archives for distribution and provides labels in CSV, JSONL, and plain text formats compatible with CRNN, TrOCR, and general ML pipelines. GPU acceleration enables efficient generation across multiple cores.

## Key Results
- Dataset contains ~602,000 word images at 256×64 pixels resolution
- Includes 3 traditional Kashmiri typefaces with 60% augmented / 40% clean split
- Multi-format labels (CSV, JSONL, TXT) compatible with CRNN and TrOCR frameworks
- Covers diverse background textures and realistic document degradation effects

## Why This Works (Mechanism)
The dataset addresses the critical resource scarcity for Kashmiri OCR by providing large-scale synthetic training data with realistic document characteristics. The combination of traditional typefaces, comprehensive augmentation simulating real-world degradation, and diverse backgrounds enables robust model training. The multi-format label support ensures compatibility with established OCR frameworks, while the partitioning facilitates distributed processing and experimentation.

## Foundational Learning
- **Kashmiri script characteristics**: Modified Perso-Arabic right-to-left writing system requiring specific rendering and text processing pipelines; needed for correct text layout and OCR model design
- **Data augmentation for OCR**: Techniques like rotation, blur, noise, and perspective distortion that simulate real-world document degradation; needed to improve model robustness beyond clean synthetic data
- **OCR framework compatibility**: Understanding CRNN and TrOCR label formats (CTC vs encoder-decoder) for proper model training and evaluation; needed to effectively utilize provided dataset labels

## Architecture Onboarding
- **Component map**: Text corpus → Rendering engine → Augmentation pipeline → Image storage → Label generation → Dataset distribution
- **Critical path**: Synthetic text rendering → Augmentation application → Image saving → Label format generation → Archive creation
- **Design tradeoffs**: Synthetic vs real data quality, augmentation intensity vs domain gap, multi-format labels vs storage overhead
- **Failure signatures**: Incorrect RTL rendering, poor augmentation parameter choices leading to unrealistic images, label-text misalignment
- **First experiments**: 1) Verify text rendering correctness in labels, 2) Train simple baseline OCR model, 3) Analyze vocabulary coverage and distribution

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- No baseline model performance metrics provided to validate dataset utility
- Source text corpus and vocabulary coverage remain unspecified
- Exact augmentation parameter values not detailed beyond high-level categories

## Confidence
- Medium confidence in dataset completeness and scale claims
- Low confidence in dataset quality and utility without baseline results
- Medium confidence in reproducibility of generation process

## Next Checks
1. Train and evaluate a standard CRNN model on the dataset, reporting CER/WER on held-out test splits to establish baseline performance
2. Evaluate synthetic-to-real domain transfer by testing on real Kashmiri documents or conducting augmentation ablation studies
3. Analyze vocabulary frequency distribution and attempt to identify source text corpus to assess linguistic representativeness