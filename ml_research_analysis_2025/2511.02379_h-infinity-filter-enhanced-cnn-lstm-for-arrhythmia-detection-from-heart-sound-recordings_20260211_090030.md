---
ver: rpa2
title: H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart Sound
  Recordings
arxiv_id: '2511.02379'
source_url: https://arxiv.org/abs/2511.02379
tags:
- heart
- proposed
- audio
- lstm
- filter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of arrhythmia detection from heart
  sound recordings using deep learning, focusing on small, noisy, and imbalanced datasets
  typical in biomedical applications. The authors propose a CNN-H-Infinity-LSTM architecture
  that incorporates a trainable H-Infinity filter in place of the standard LSTM forget
  gate, improving robustness and generalization.
---

# H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart Sound Recordings

## Quick Facts
- arXiv ID: 2511.02379
- Source URL: https://arxiv.org/abs/2511.02379
- Reference count: 24
- Primary result: 99.42% test accuracy and 98.85% F1-score on PhysioNet CinC 2016 arrhythmia detection

## Executive Summary
This paper addresses arrhythmia detection from heart sound recordings using a CNN-H-Infinity-LSTM architecture that incorporates a trainable H-Infinity filter in place of the standard LSTM forget gate. The model is designed to handle small, noisy, and imbalanced biomedical datasets by improving robustness through worst-case error minimization and addressing class imbalance with adaptive thresholding and weighted loss functions. The approach achieves state-of-the-art performance on the PhysioNet CinC Challenge 2016 dataset, outperforming existing benchmarks with 99.42% accuracy and 98.85% F1-score.

## Method Summary
The method involves preprocessing heart sound recordings through wavelet decomposition, low-pass filtering, and segmentation into 5-second clips, followed by conversion to Mel spectrograms. A CNN-H∞-LSTM architecture extracts spatial features through convolutional layers and temporal dependencies through H∞-LSTM cells, where the forget gate is replaced by a learned parameter λh from the H-Infinity filter. Training uses two phases: first fine-tuning a standard CNN-LSTM, then transferring CNN weights and training only the H∞-LSTM layers. The model employs Penalty Weighted Loss with α=0.87 to handle class imbalance and Stochastic Adaptive Probe Thresholding to optimize the decision threshold every 10 epochs.

## Key Results
- Achieved 99.42% test accuracy and 98.85% F1-score on PhysioNet CinC 2016 dataset
- Outperformed baseline CNN-LSTM (96.19% F1) and other existing models
- Demonstrated superior performance compared to raw audio approaches (68-78% accuracy with Wav2Vec2, HuBERT, DistilHuBERT)
- Successfully addressed class imbalance with 87:13 normal-to-abnormal ratio through adaptive thresholding and weighted loss

## Why This Works (Mechanism)

### Mechanism 1
- Claim: H∞-LSTM cell improves noise robustness by learning a data-driven forgetting coefficient rather than computing forget gates from potentially noisy inputs
- Mechanism: A trainable parameter K_filter is passed through sigmoid to produce λh = σ(K_filter), which directly controls the balance between retaining previous cell state ct-1 and incorporating new candidate information. Unlike standard LSTMs where ft = σ(Wf·xt + Uf·ht-1 + bf) depends on noisy current inputs, λh is learned globally from training data. This is claimed to reduce susceptibility to noise-induced forgetting errors.
- Core assumption: Heart sound recordings contain non-Gaussian or unknown noise distributions where worst-case error minimization (H∞ principle) outperforms standard gradient-based forget gate learning
- Evidence anchors:
  - [abstract]: "trainable parameters inspired by the H-Infinity filter from control theory, enhancing robustness and generalization"
  - [section II.C]: "The H∞ filter excels in minimizing the worst-case estimation error and is particularly useful when underlying noise is non-Gaussian or of unknown nature"
  - [corpus]: Weak direct evidence—no corpus papers use H∞ filters; related work focuses on transformers and CNN variants
- Break condition: If noise is approximately Gaussian or if the dataset is sufficiently large that standard LSTM forget gates can learn noise patterns, the H∞ modification may provide marginal benefit over standard LSTM

### Mechanism 2
- Claim: Mel spectrogram representation enables CNN-based spatial feature extraction that raw audio waveforms cannot efficiently capture
- Mechanism: Raw audio is converted to time-frequency representations (N_mels frequency bands × T time steps), compressing high-dimensional spectral information into perceptually relevant bands. CNNs then extract hierarchical spatial patterns (S1-S2 heart sounds, murmurs) from these 2D representations. This bypasses the difficulty of learning both temporal and spectral structure simultaneously from 1D waveforms.
- Core assumption: Arrhythmic patterns manifest as distinctive spatial structures in time-frequency space that 2D convolutions can capture better than 1D temporal convolutions on raw audio
- Evidence anchors:
  - [section II.B]: "Initial experiments conducted on audio-specific models taking the raw audio files as input did not perform well... attributed to the failure of audio models to recognise the spatial features"
  - [section IV.A]: Wav2Vec2, HuBERT, DistilHuBERT achieved 68-78% accuracy on raw audio vs. 99.42% with Mel spectrograms
  - [corpus]: QuPCG and Scattering Transformer papers also use time-frequency representations for PCG classification
- Break condition: If arrhythmic signatures are purely temporal (timing irregularities without spectral changes), spectrogram-based approaches may lose critical temporal resolution

### Mechanism 3
- Claim: Penalty Weighted Loss (PWL) combined with SAPT addresses class imbalance by adaptively penalizing minority class misclassifications and optimizing the decision threshold
- Mechanism: PWL multiplies BCE loss by R_penalty(δ) = 1 + α·FNI(δ) + (1-α)·FPI(δ), where α = 0.87 approximates the 87:13 class imbalance ratio. This amplifies gradients when false negatives (missed arrhythmias) occur. SAPT independently searches threshold space every γ=10 epochs to maximize F1-score, breaking the default τ=0.5 assumption that biases toward majority class.
- Core assumption: Fixed decision thresholds and unweighted losses systematically underperform on imbalanced medical data where false negatives are clinically critical
- Evidence anchors:
  - [section II.D]: "α ∈ (0,1) balances the emphasis between false negatives and false positives... α = 0.87, which is roughly equal to the class imbalance ratio"
  - [section IV, Table III]: CNN-H∞-LSTM with SAPT achieves 98.85% F1 vs. 96.19% F1 for CNN-LSTM with SAPT (same training, different architecture)
  - [corpus]: Scaling to Multimodal paper addresses class imbalance via synthetic/augmented signals—an alternative approach
- Break condition: If the validation set is not representative of test distribution, SAPT may overfit to an incorrect threshold; PWL assumes α correctly reflects true class costs

## Foundational Learning

- Concept: **H∞ Filter Theory (Robust Control)**
  - Why needed here: Understanding why worst-case error minimization differs from standard MSE-based learning; explains why λh is positionally-independent rather than input-dependent
  - Quick check question: If noise statistics were known to be Gaussian, would H∞ filtering still be theoretically preferred over Kalman filtering?

- Concept: **LSTM Gate Mechanics (Input, Forget, Output)**
  - Why needed here: The H∞ modification replaces only the forget gate; you must understand standard LSTM equations to see what changes and what stays the same
  - Quick check question: In a standard LSTM, if ft ≈ 0 for several timesteps, what happens to the cell state ct?

- Concept: **Class Imbalance Metrics (F1 vs. Accuracy)**
  - Why needed here: The paper optimizes F1-score via SAPT; accuracy alone is misleading when 87% of samples are normal
  - Quick check question: On a dataset with 90% negative samples, what accuracy would a naive "always predict negative" classifier achieve?

## Architecture Onboarding

- Component map:
  Input (N_mels, T, 1) Mel spectrogram → Conv Block 1 (3×3 conv, BN, 3×3 conv, BN, 2×2 MaxPool) → Conv Block 2 (same) → Reshape → H∞-LSTM layers → Dense → Sigmoid output

- Critical path:
  1. Pre-processing: DWT (db4) → IIR Butterworth (500Hz cutoff) → 5-second segmentation
  2. Feature extraction: Mel spectrogram conversion
  3. Spatial features: CNN backbone (transfer learning from pre-trained CNN-LSTM)
  4. Temporal memory: H∞-LSTM with fixed λh per training run
  5. Classification: Threshold τ* from SAPT applied to sigmoid output

- Design tradeoffs:
  - λh is a global scalar, not timestep-dependent: simpler optimization but less expressive than standard forget gate; may limit adaptivity to variable-length dependencies
  - Fine-tuning strategy freezes CNN weights: leverages pre-learned spatial features but may not fully adapt H∞-LSTM to task-specific representations
  - SAPT searches thresholds discretely: may miss optimal continuous values; γ=10 balances reactivity vs. stability

- Failure signatures:
  - Validation F1 oscillates wildly: SAPT γ too low (overreacting to noise); increase γ
  - Model achieves high accuracy but low sensitivity: threshold τ too high or PWL α too low; verify α matches class imbalance
  - H∞-LSTM underperforms standard LSTM: dataset may be large/clean enough that H∞ assumptions don't hold; test on noisier subsets
  - Training loss plateaus early: K_filter may be stuck in saturated sigmoid region; check initialization

- First 3 experiments:
  1. **Ablation study**: Train identical architecture with standard LSTM forget gate vs. H∞-LSTM on the same data splits; isolate the contribution of λh mechanism
  2. **Noise sensitivity test**: Inject controlled Gaussian vs. non-Gaussian noise into test set; verify H∞-LSTM degrades more gracefully than baseline
  3. **Threshold sweep**: Replace SAPT with fixed thresholds {0.3, 0.4, 0.5, 0.6, 0.7}; quantify how much performance gain SAPT provides vs. manual tuning

## Open Questions the Paper Calls Out

- **Open Question 1**: Does integrating the H-infinity filter mechanism into advanced architectures, such as Vision Transformers or Attention-based models, yield comparable improvements in robustness?
  - Basis in paper: [explicit] The conclusion states future work includes "integrating the H∞ filter to more advanced architectures."
  - Why unresolved: The current study validates the filter exclusively within a CNN-LSTM framework, leaving its efficacy in non-recurrent or transformer-based architectures untested
  - What evidence would resolve it: Benchmarking an H∞-enhanced Transformer model against a standard Transformer on the same noisy physiological datasets

- **Open Question 2**: Can centroid-based thresholding and the AutoBalance optimizer provide superior convergence stability and minority class recall compared to the proposed SAPT and Penalty Weighted Loss?
  - Basis in paper: [explicit] The authors identify evaluating "centroid-based thresholding" and the "AutoBalance optimizer" as specific scope for future improvements
  - Why unresolved: The current experimental results rely entirely on the Stochastic Adaptive Probe Thresholding (SAPT) and custom loss functions; the suggested alternatives remain hypothetical for this application
  - What evidence would resolve it: Comparative ablation studies substituting SAPT and PWL with the suggested methods while keeping the base architecture constant

- **Open Question 3**: How effectively does the proposed model generalize to external clinical datasets with different acoustic characteristics or noise profiles not represented in the PhysioNet CinC 2016 challenge?
  - Basis in paper: [inferred] The paper claims the method improves generalization for "real-world scenarios," but the experimental evaluation is restricted to a single dataset (PhysioNet CinC 2016)
  - Why unresolved: High performance on a single benchmark does not guarantee robustness against the device-specific artifacts or varying signal-to-noise ratios found in other hospitals or recording setups
  - What evidence would resolve it: Cross-database validation where the model trained on CinC 2016 is tested on a distinct heart sound database (e.g., independent clinical trial data)

## Limitations

- The paper lacks comparative experiments isolating the H∞-LSTM mechanism's contribution to the 99.42% accuracy
- Architectural details for the CNN backbone and exact Mel spectrogram parameters are unspecified, making faithful reproduction challenging
- Claims about H∞-LSTM superiority for non-Gaussian noise remain largely theoretical without empirical noise robustness testing

## Confidence

- High confidence: Mel spectrogram effectiveness over raw audio, PWL + SAPT handling of class imbalance, overall framework validity
- Medium confidence: H∞-LSTM noise robustness claims, architectural choices and hyperparameters
- Low confidence: Claims about H∞-LSTM superiority without direct ablation comparisons, generalization to datasets beyond PhysioNet

## Next Checks

1. **Ablation study**: Train identical architectures with standard LSTM vs. H∞-LSTM on same data splits to isolate architectural contribution
2. **Noise sensitivity test**: Inject controlled Gaussian and non-Gaussian noise into test set to empirically verify H∞-LSTM's claimed robustness advantage
3. **Reproducibility audit**: Implement the method from scratch using only specifications in the paper, then compare results to published metrics to identify missing implementation details