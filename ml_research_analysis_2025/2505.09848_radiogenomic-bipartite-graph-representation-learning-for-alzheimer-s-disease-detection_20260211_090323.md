---
ver: rpa2
title: Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease
  Detection
arxiv_id: '2505.09848'
source_url: https://arxiv.org/abs/2505.09848
tags:
- alzheimer
- disease
- graph
- genes
- imaging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a bipartite graph representation learning
  framework that integrates structural MRI images and gene expression data to detect
  Alzheimer's disease. The approach constructs a heterogeneous bipartite graph with
  gene and image nodes, where dynamic edge weights are learned during training using
  a graph neural network.
---

# Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection

## Quick Facts
- arXiv ID: 2505.09848
- Source URL: https://arxiv.org/abs/2505.09848
- Reference count: 29
- Primary result: Novel bipartite graph framework achieves 92% accuracy, 93% F1, 100% recall, 87.5% precision for AD vs CN classification

## Executive Summary
This study introduces a bipartite graph representation learning framework that integrates structural MRI images and gene expression data to detect Alzheimer's disease. The approach constructs a heterogeneous bipartite graph with gene and image nodes, where dynamic edge weights are learned during training using a graph neural network. The model achieves superior performance compared to existing methods, with classification accuracy of 92%, F1 score of 93%, recall of 100%, and precision of 87.5% for distinguishing AD from CN cases. The method also identifies the relative importance of specific genes (APOE, PSEN1, PSEN2) in classification. Ablation studies confirm that dynamic edge weight learning improves accuracy by 17% over static approaches. The framework demonstrates the value of integrating imaging and genomic data for disease detection and could be extended to other conditions.

## Method Summary
The framework integrates 3D structural MRI and gene expression data through a bipartite graph representation learning approach. It first extracts 512-dimensional latent features from MRI using a 3D denoising autoencoder. Gene expression data for three Alzheimer's driver genes (APOE, PSEN1, PSEN2) is normalized and used to construct a heterogeneous bipartite graph with both gene and image nodes. A graph neural network with dynamic edge weight learning computes node embeddings, where edge weights are learned through a learnable prior α that is transformed and activated. The final classification aggregates gene and image embeddings through a prediction block. The model is trained end-to-end with MSE loss, and dynamic edge weights are updated during training, distinguishing it from static approaches.

## Key Results
- Achieves 92% classification accuracy, 93% F1-score, 100% recall, and 87.5% precision for AD vs CN classification
- Dynamic edge weight learning improves accuracy by 17% compared to static approaches (ablative study)
- Identifies APOE, PSEN1, and PSEN2 as key genes contributing to AD classification
- Outperforms existing methods including SVM, CNN, and GraphSAGE on ADNI dataset

## Why This Works (Mechanism)
None

## Foundational Learning
- **3D Denoising Autoencoder**: Extracts robust latent representations from MRI data by reconstructing noisy inputs, reducing dimensionality from 3D volumes to 512 features
- **Bipartite Graph Construction**: Creates heterogeneous connections between gene and image nodes to model radiogenomic relationships, enabling joint feature learning
- **Dynamic Edge Weight Learning**: Learns edge importance during training through a learnable prior α, allowing the model to adaptively weigh gene-image relationships
- **Graph Neural Network Aggregation**: Combines node features through message passing to create unified representations for classification
- **Min-max Normalization**: Scales gene expression values to [0,1] range for stable training and fair comparison across genes

## Architecture Onboarding
- **Component Map**: 3D Denoising Autoencoder -> Latent Feature Extraction -> Bipartite Graph Construction -> Dynamic Edge Weight Learning -> GNN Aggregation -> Classification
- **Critical Path**: MRI → Autoencoder → Latent Features → Graph Nodes → Edge Weights → GNN → Classification
- **Design Tradeoffs**: Small dataset (n=52) necessitates lightweight models and regularization; dynamic edges add complexity but improve performance
- **Failure Signatures**: Overfitting on small dataset, high variance due to random initialization, class imbalance affecting recall metrics
- **First Experiments**:
  1. Train 3D denoising autoencoder on ADNI MRI data with Gaussian noise addition
  2. Construct bipartite graph with gene expression and image latent features
  3. Implement and train GNN with dynamic edge weight learning mechanism

## Open Questions the Paper Calls Out
- Can the bipartite graph framework be effectively generalized to detect other complex diseases using radiogenomic data?
- How does the model's performance scale when expanding from three pre-selected driver genes to a genome-wide set of features?
- Are the high classification metrics (e.g., 100% recall) reproducible on larger, independent cohorts?

## Limitations
- Very small sample size (n=52) raises concerns about statistical robustness and generalizability
- Key architectural details for both the autoencoder and GNN prediction block are missing from the main text
- Dynamic edge weight mechanism may be overfitting-prone given the small dataset
- No cross-validation reported, only a single 80-20 split, making performance estimates potentially optimistic

## Confidence
- High confidence in the novel methodology (bipartite graph with dynamic edge weights)
- Medium confidence in reported classification metrics (due to small sample size and single split)
- Low confidence in precise architectural details required for exact reproduction

## Next Checks
1. Ablation study replication: Re-run the experiment with and without dynamic edge weight learning on multiple random seeds to verify the claimed 17% improvement
2. Dataset scaling validation: Test the framework on larger ADNI cohorts (if available) to assess performance stability and generalizability
3. Statistical robustness check: Implement k-fold cross-validation to obtain confidence intervals for the reported metrics rather than relying on a single train-test split