---
ver: rpa2
title: 'Restoring Exploration after Post-Training: Latent Exploration Decoding for
  Large Reasoning Models'
arxiv_id: '2602.01698'
source_url: https://arxiv.org/abs/2602.01698
tags:
- exploration
- decoding
- arxiv
- pass
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies an exploration collapse in RL-post-trained
  large reasoning models (LRMs), where the final-layer posterior becomes overly confident,
  making temperature-based sampling ineffective. The authors propose Latent Exploration
  Decoding (LED), which leverages intermediate-layer posteriors with higher entropy,
  aggregates them via cumulative sum, and selects the depth with maximal entropy for
  exploration.
---

# Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models

## Quick Facts
- arXiv ID: 2602.01698
- Source URL: https://arxiv.org/abs/2602.01698
- Reference count: 26
- Key outcome: LED improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple benchmarks and models without additional training or parameters.

## Executive Summary
This paper identifies a critical limitation in RL post-trained Large Reasoning Models (LRMs): exploration collapse. After GRPO-style training, these models' final-layer posteriors become overly confident, making temperature-based sampling ineffective. The authors propose Latent Exploration Decoding (LED), which leverages intermediate-layer posteriors with higher entropy, aggregates them via cumulative sum, and selects the depth with maximal entropy for exploration. LED successfully reactivates exploration capabilities without additional training or parameters, improving both accuracy and solution diversity.

## Method Summary
LED addresses exploration collapse in post-trained LRMs by exploiting the entropy reservoir in intermediate layers. The method caches hidden states from the final `d` layers, decodes latent posteriors through the LM-Head, and filters them to final-layer top-k candidates. It then computes cumulative-sum aggregated posteriors, selects the depth with maximum entropy, and uses a confidence-based criterion (final-layer top-1 probability) to decide between exploration (sampling from the entropy-selected latent posterior) and exploitation (sampling from the final-layer posterior). This approach requires no additional training or parameters while improving both pass@1 and pass@16 accuracy.

## Key Results
- LED improves pass@1 accuracy by 0.61 percentage points and pass@16 accuracy by 1.03 percentage points across multiple benchmarks
- The method works across different model sizes (4B, 7B) and training approaches (Qwen2.5-RLV, DeepSeek-R1-Distill)
- LED reactivates exploration at high temperatures where standard sampling fails for post-trained models
- The approach requires no additional training or parameters, only modifying the decoding procedure

## Why This Works (Mechanism)

### Mechanism 1
RL post-training with GRPO-style objectives concentrates probability mass on a small number of dominant hypotheses, causing entropy collapse in final-layer posteriors while intermediate layers retain higher uncertainty. GRPO's group-relative optimization rewards correct rollouts relative to incorrect ones, implicitly sharpening the policy at high-variance "branching tokens" through asymmetric credit assignment. Intermediate layers, not directly optimized by the RL objective, preserve higher entropy, forming a "latent entropy reservoir."

### Mechanism 2
Aggregating intermediate-layer posteriors via final-to-latent cumulative sum and selecting the depth with maximal entropy produces a posterior that better supports exploration than the final layer alone. Cumulative sum aggregation progressively blends higher-entropy latent posteriors with the final-layer posterior, and selecting the depth with maximum entropy adaptively identifies the "richest exploration signal" across depth without hand-tuned weights.

### Mechanism 3
A confidence-based criterion (top-1 probability from the final layer) adaptively routes between an exploration branch (sampling from the entropy-selected latent posterior) and an exploitation branch (sampling from the final-layer posterior). High final-layer confidence indicates a trivial or committed prediction, triggering exploitation, while low confidence activates exploration. This dynamic avoids noise injection for predictable tokens while enabling exploration where reasoning paths diverge.

## Foundational Learning

- **Entropy in probability distributions**
  - Why needed here: The entire diagnosis and solution revolve around comparing entropy (uncertainty) across layers and using it as a selection criterion.
  - Quick check question: Given two probability distributions [0.9, 0.1] and [0.5, 0.5], which has higher entropy? Why does higher entropy imply more exploration potential?

- **Reinforcement Learning (RL) post-training & GRPO**
  - Why needed here: To understand the root cause—how GRPO's group-relative correctness reward leads to entropy collapse in final-layer posteriors.
  - Quick check question: How does optimizing for pass@1 accuracy (a single correct sample) implicitly reduce the model's incentive to maintain a diverse set of plausible reasoning paths?

- **Early exit and hidden states in Transformers**
  - Why needed here: LED relies on the ability to decode intermediate hidden states (h₁ to hₗ₋₁) through the LM-Head, a technique known as "early exit," made possible by residual connections.
  - Quick check question: Why can the hidden state from an intermediate layer be fed directly into the final LM-Head to produce a valid probability distribution over the vocabulary?

## Architecture Onboarding

- **Component map:** Input context and current token -> Standard LLM forward (cache h_{L-d+1} to h_L) -> LM-Head applied to each cached h_l -> Top-k filtering from final layer -> Cumulative aggregation and entropy selection -> Confidence check (top-1 probability) -> Exploration/exploitation branch selection -> Output token

- **Critical path:** Correctly capturing and caching intermediate hidden states -> Accurately computing and filtering latent posteriors to final-layer top-k candidates -> Efficiently computing cumulative sum and entropy over small k and depth d

- **Design tradeoffs:**
  - Depth d: Larger d accesses more entropy but risks noise from early, "immature" layers and increases overhead. Default uses d=8 for safety and efficiency.
  - LayerNorm on latents: Applying it boosts exploration (higher pass@16) but can hurt exploitation (lower pass@1) due to instability. Default omits it.
  - Top-k vs. top-p: Using fixed small top-k (e.g., 8) instead of top-p simplifies implementation and is computationally cheaper with minimal performance difference.

- **Failure signatures:**
  - Endless looping/context limit reached: Caused by removing top-k filtering, allowing sampling of very low-probability tokens
  - Sharp pass@1 drop without pass@16 gain: Likely from over-aggressive exploration (e.g., removing exploitation branch)
  - No performance gain: May occur if intermediate layers don't exhibit higher entropy than final layer

- **First 3 experiments:**
  1. Entropy profile validation: Plot normalized entropy vs. layer index for your target model to confirm the "entropy reservoir" exists
  2. LED vs. CoT baseline comparison: Implement core LED logic with d=8, k=8 and compare pass@1/pass@16 on GSM8K subset
  3. Ablation of exploitation branch: Force exploration on every token to observe expected pass@1 drop and quantify the trade-off

## Open Questions the Paper Calls Out

### Open Question 1
Can the relationship between sparse RL rewards and token-level entropy collapse be mathematically formalized beyond the provided mechanistic intuition? The paper offers qualitative reasoning about "asymmetric credit assignment" but lacks a rigorous mathematical derivation linking GRPO objectives to specific entropy decay rates.

### Open Question 2
Why does LED fail to improve pass@16 accuracy on the QwQ-32B model despite its success on other LRMs? The authors hypothesize that QwQ-32B may not be "heavily post-trained" or possesses a different entropy-layer tendency, but these remain untested conjectures.

### Open Question 3
How can the trade-off between improved exploration (pass@16) and degraded exploitation (pass@1) caused by applying LayerNorm to latent states be mitigated? The paper identifies the dilemma but resolves it by defaulting to the configuration that prioritizes pass@1, leaving the optimization of this trade-off for future work.

## Limitations
- The approach's effectiveness depends on the existence of an entropy reservoir in intermediate layers, which may not be universal across all model architectures
- The theoretical justification for why cumulative sum aggregation is optimal remains underdeveloped
- The confidence-based switching mechanism relies on top-1 probability as a proxy for exploration necessity, which may not capture all relevant factors

## Confidence

**High Confidence:** Experimental results demonstrating LED's effectiveness (0.61 pass@1 and 1.03 pass@16 improvements) are well-supported with multiple benchmarks and model sizes. Ablation studies providing evidence for the exploitation branch and importance of top-k filtering are robust.

**Medium Confidence:** Diagnosis of entropy collapse as the root cause of exploration failure is well-supported by literature and empirical observations, but specific mechanisms by which GRPO causes this collapse (particularly asymmetric credit assignment) are inferred rather than directly measured.

**Low Confidence:** Theoretical justification for why cumulative sum aggregation and maximum entropy selection is optimal remains underdeveloped. The paper shows this works empirically but doesn't provide strong theoretical grounding for why this aggregation method should be preferred over alternatives.

## Next Checks

1. **Cross-architecture entropy profile validation:** For models not mentioned in the paper (e.g., Llama-3-70B-Instruct or Claude-3 models), measure and compare entropy profiles across layers to determine whether the "entropy reservoir" phenomenon exists universally.

2. **Alternative aggregation mechanism comparison:** Implement and compare LED's cumulative