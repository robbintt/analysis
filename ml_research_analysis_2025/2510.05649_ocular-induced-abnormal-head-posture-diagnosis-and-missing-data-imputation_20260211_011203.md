---
ver: rpa2
title: 'Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation'
arxiv_id: '2510.05649'
source_url: https://arxiv.org/abs/2510.05649
tags:
- clinical
- data
- head
- imputation
- ocular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a multi-level attention fusion framework\
  \ (AHP-CADNet) for diagnosing ocular-induced abnormal head posture by integrating\
  \ eye and head landmarks with clinical features, alongside a curriculum learning-based\
  \ imputation framework to handle missing data in clinical records. The frameworks\
  \ are evaluated on the PoseGaze-AHP dataset, achieving high diagnostic accuracy\
  \ (96.9%\u201399.0%) and low regression errors (MAE 0.103\u20130.199, R\xB2 0.93)."
---

# Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation

## Quick Facts
- arXiv ID: 2510.05649
- Source URL: https://arxiv.org/abs/2510.05649
- Reference count: 0
- This paper introduces a multi-level attention fusion framework (AHP-CADNet) for diagnosing ocular-induced abnormal head posture by integrating eye and head landmarks with clinical features, alongside a curriculum learning-based imputation framework to handle missing data in clinical records.

## Executive Summary
This work presents two complementary deep learning frameworks for ocular-induced abnormal head posture (AHP) diagnosis. AHP-CADNet employs a three-level attention fusion architecture that integrates eye/head landmarks and clinical features, achieving 96.9–99.0% diagnostic accuracy. The curriculum-based imputation framework progressively learns to reconstruct missing clinical variables from unstructured notes, reaching 93.46–99.78% accuracy. Both frameworks address critical challenges in clinical data incompleteness and diagnostic automation.

## Method Summary
The study proposes AHP-CADNet, a multi-level attention fusion network that hierarchically combines intra-modal feature learning, cross-modal attention with gated relevance, and global context fusion. The imputation framework uses domain-specific BERT models with curriculum learning, progressively increasing masking rates from 10% to 100% over four phases while modeling clinical target dependencies through attention propagation. Both methods are evaluated on the PoseGaze-AHP dataset using 70/15/15 splits for diagnosis and 60/20/20 splits for imputation.

## Key Results
- AHP-CADNet achieves 96.9%–99.0% diagnostic accuracy across five classification tasks
- Regression tasks show MAE 0.103–0.199 with R² > 0.93
- Imputation framework reaches 93.46%–99.78% accuracy with statistically significant gains (p < 0.001) from clinical dependency modeling
- Multi-level attention outperforms early fusion (90.8% → 96.9%) and late fusion (7.83% → 96.9%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-level attention fusion (intra-modal → cross-modal → global) captures hierarchical feature relationships that single-level fusion cannot.
- **Mechanism:** Level 1 learns modality-specific internal dependencies (e.g., correlations among eye landmarks). Level 2 applies cross-modal attention with gated relevance scores to weight inter-modal contributions. Level 3 fuses all streams with learned modality weights. This hierarchical structure preserves fine-grained patterns before integration.
- **Core assumption:** Ocular misalignment and compensatory head posture have both modality-internal structure and cross-modal dependencies that must be modeled sequentially.
- **Evidence anchors:**
  - [abstract] "AHP-CADNet is a multi-level attention fusion framework for automated diagnosis that integrates ocular landmarks, head pose features, and structured clinical attributes"
  - [Page 13-17] Section 3.1.2 details the three-level architecture with gated relevance mechanism (Eq. 5)
  - [Page 25-27] Table 5 shows AHP-CADNet outperforms early fusion (90.8% → 96.9% diagnosis accuracy) and late fusion (7.83% → 96.9%)

### Mechanism 2
- **Claim:** Curriculum learning with progressive masking (10% → 100%) enables models to generalize from partial to fully missing inputs.
- **Mechanism:** Training starts with mostly complete inputs (Phase 1: 10-30% masking) to learn clinical patterns. Masking increases progressively (Phases 2-4), forcing the model to infer from sparse context. The final 25 epochs enforce full masking to guarantee deployment readiness.
- **Core assumption:** Missingness patterns in clinical data follow learnable structure that can be progressively acquired.
- **Evidence anchors:**
  - [abstract] "a curriculum learning–based imputation framework is designed to mitigate missing data by progressively leveraging structured variables and unstructured clinical notes"
  - [Page 19-21] Table 3 and Section 3.2.3.2 describe the four-phase curriculum schedule
  - [Page 33] Figure 10 shows validation accuracy improves from ~0.20 to ~0.95 as mask rate increases from 0.2 to 1.0

### Mechanism 3
- **Claim:** Modeling clinical target dependencies via attention-based hierarchical propagation improves imputation accuracy.
- **Mechanism:** Each target embedding is enhanced by attended information from its clinical dependencies (Eq. 12). The diagnosis label serves as a fully-observed anchor that informs downstream targets (AHP type, direction, degree). Cross-target attention weights (Eq. 11) capture relationship strength.
- **Core assumption:** Clinical targets have hierarchical dependencies that can be expressed as directed attention flows.
- **Evidence anchors:**
  - [abstract] "clinical dependency modeling yielding significant improvements (p < 0.001)"
  - [Page 22-23] Table 4 defines the dependency structure (Diagnose → AHP Type/Direction/Eye/...; Eye → EyeMisalignment → PD)
  - [Page 36] Figure 14 shows statistically significant gains (p < 0.001) for all targets, with AHPDirection (+0.040) and EyeMisalignment (+0.037) benefiting most

## Foundational Learning

- **Concept: Multi-head self-attention**
  - Why needed here: Both AHP-CADNet and imputation framework use attention as the core fusion operation. Understanding Q/K/V projections, attention weights, and multi-head decomposition is essential.
  - Quick check question: Can you explain why scaling dot-product attention by √d stabilizes gradients?

- **Concept: Curriculum learning**
  - Why needed here: The imputation framework's performance hinges on progressive difficulty scheduling. Understanding when and why curriculum helps is critical for tuning mask rates.
  - Quick check question: Why might curriculum learning fail if the difficulty measure doesn't align with the model's actual learning trajectory?

- **Concept: Transfer learning with domain-specific BERT**
  - Why needed here: The imputation framework uses PubMedBERT, BioBERT, and SciBERT as backbone encoders. Understanding how pretraining domain affects downstream performance informs backbone selection.
  - Quick check question: Would PubMedBERT be expected to outperform BioBERT on ophthalmology text? Why or why not?

## Architecture Onboarding

- **Component map:**
  - MediaPipe landmark extractor → Intra-modal attention blocks (eye: 32-dim, head/clinical: 16-dim) → Cross-modal gated attention (clinical→eye, clinical→head, eye→head) → Global context attention with modality weighting → Task-specific MLP heads (5 classification, 2 regression)
  - Clinical notes (augmented via NLTK) → PubMedBERT encoder → Shared feature extractor → Target-specific embeddings → Cross-target dependency attention → Classification/regression heads
  - PoseGaze-AHP dataset (496 cases → 2,296 augmented notes) → 70/15/15 split for diagnosis, 60/20/20 for imputation

- **Critical path:**
  1. Landmark extraction quality directly limits diagnosis accuracy (eye landmark errors propagate through all attention levels)
  2. Clinical note quality (via Claude Sonnet generation) determines imputation ceiling
  3. Curriculum schedule must reach Phase 4 with 25-epoch minimum to ensure deployment readiness
  4. Dependency graph correctness affects all downstream target predictions

- **Design tradeoffs:**
  - Multi-level attention vs. early/late fusion: 6-10% accuracy gain but 2-3x computation
  - PubMedBERT vs. BioBERT/SciBERT: PubMedBERT most stable across tasks (Table 6), but BioBERT slightly better on eye misalignment (98.69% vs. 97.17%)
  - Data augmentation (4x expansion): Mitigates small dataset (496 cases) but risks introducing artifacts if synonym substitution changes clinical meaning

- **Failure signatures:**
  - Diagnosis F1 drops sharply (e.g., from 92.3% to 34.3%) if intra-modal attention removed → indicates modality-internal patterns are critical
  - Regression MAE spikes (e.g., PD from 0.199 to 0.635) with early fusion → indicates cross-modal dependencies not captured
  - Imputation accuracy degrades at high masking rates without curriculum → indicates model overfitting to observed patterns

- **First 3 experiments:**
  1. **Ablation on attention levels:** Run AHP-CADNet with only Level 1, only Level 1+2, and full 3-level architecture. Measure accuracy drop per task to validate hierarchical contribution.
  2. **Curriculum schedule sensitivity:** Compare 4-phase curriculum vs. linear masking increase vs. fixed 50% masking. Track validation accuracy at each mask rate to identify optimal pacing.
  3. **Dependency graph validation:** Randomly permute target dependencies in Eq. 12 and measure performance change. Significant degradation confirms the learned dependencies reflect true clinical structure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed diagnostic framework accurately classify AHP caused by non-ocular etiologies, such as neurological or musculoskeletal conditions?
- Basis in paper: [explicit] The authors state that "the diagnostic framework will be extended to encompass a broader range of AHP etiologies, including neurological and musculoskeletal causes, to enhance its generalizability."
- Why unresolved: The current study and the PoseGaze-AHP dataset focus exclusively on ocular-induced AHP; therefore, the model's ability to differentiate or identify compensatory postures from non-ocular origins remains untested.
- What evidence would resolve it: Evaluation of the AHP-CADNet framework on a dataset containing labeled cases of neurological and musculoskeletal AHP to assess diagnostic accuracy and feature importance.

### Open Question 2
- Question: Do the AHP-CADNet and imputation frameworks maintain high performance when integrated into real-world commercial EHR systems with heterogeneous data formats?
- Basis in paper: [explicit] The paper notes that future research requires "integration into commercial EHR systems and evaluation through prospective clinical trials... to assess workflow integration and patient-level outcomes."
- Why unresolved: The current validation relies on a specific dataset (PoseGaze-AHP) derived from research papers, which may not reflect the noise, variability, and documentation inconsistencies of live clinical environments.
- What evidence would resolve it: Successful deployment and accuracy metrics from a prospective clinical trial where the models process live data streams from commercial EHRs.

### Open Question 3
- Question: Can the framework be adapted to model temporal patterns and AHP progression over time?
- Basis in paper: [inferred] The authors identify a key limitation: "the dataset lacks longitudinal data, which restricts the ability to analyze temporal patterns, such as the progression of AHP over time or responses to treatment."
- Why unresolved: The current architectures (AHP-CADNet and the imputation model) are designed for static cross-sectional prediction and lack the temporal components necessary to track disease evolution or treatment efficacy.
- What evidence would resolve it: Incorporating temporal modules (e.g., recurrent layers or time-aware transformers) into the framework and testing on longitudinal patient records to predict AHP changes.

## Limitations
- The study relies on synthetic clinical notes generated by Claude Sonnet 4.0, which may not capture real-world clinical documentation variability
- The PoseGaze-AHP dataset, while larger than previous benchmarks at 496 cases, remains relatively small for deep learning applications
- The 6-10% accuracy improvements from multi-level attention come at 2-3x computational cost, which may not be justified in resource-constrained clinical settings

## Confidence
- **High confidence:** The multi-level attention fusion mechanism's hierarchical contribution (validated through ablation showing 34.3% to 92.3% F1 improvement when adding intra-modal attention)
- **Medium confidence:** The curriculum learning effectiveness (validated through progressive accuracy gains but dependent on deployment data matching training distribution)
- **Medium confidence:** The clinical dependency modeling gains (statistically significant but potentially overfit to the specific PoseGaze-AHP dataset structure)

## Next Checks
1. External validation: Test both frameworks on independent clinical datasets with different missingness patterns and documentation styles to assess real-world transferability
2. Clinical utility assessment: Evaluate whether the 6-10% accuracy improvements from multi-level attention translate to meaningful diagnostic changes in clinical decision-making
3. Robustness testing: Systematically vary the missingness mechanism (MCAR vs. MAR vs. MNAR) in controlled experiments to determine curriculum learning limits and identify failure modes