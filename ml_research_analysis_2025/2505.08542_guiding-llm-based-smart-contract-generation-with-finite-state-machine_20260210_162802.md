---
ver: rpa2
title: Guiding LLM-based Smart Contract Generation with Finite State Machine
arxiv_id: '2505.08542'
source_url: https://arxiv.org/abs/2505.08542
tags:
- smart
- contract
- generation
- contracts
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FSM-SCG, a framework for generating smart
  contracts using large language models guided by finite state machines. The method
  addresses the challenges of effectiveness and security in LLM-generated smart contracts
  by converting user requirements into FSMs, then generating and refining contracts
  through iterative feedback.
---

# Guiding LLM-based Smart Contract Generation with Finite State Machine

## Quick Facts
- arXiv ID: 2505.08542
- Source URL: https://arxiv.org/abs/2505.08542
- Reference count: 23
- Primary result: FSM-guided LLM framework achieves 95.1% compilation success rate and 68% reduction in vulnerability risk scores for smart contracts

## Executive Summary
This paper introduces FSM-SCG, a framework that addresses the challenges of generating secure and compilable smart contracts using large language models. The core innovation is introducing an intermediate finite state machine (FSM) representation between natural language requirements and code generation. By decomposing requirements into states, transitions, variables, and functions before code generation, the framework significantly improves both compilation success rates and security vulnerability scores. The approach combines supervised fine-tuning on a custom dataset with an iterative feedback loop using compilation and static analysis tools.

## Method Summary
FSM-SCG converts natural language requirements into formal finite state machine representations, then generates Solidity code guided by these FSMs. The framework uses supervised fine-tuning (FPFT) on a custom dataset of 30k examples containing requirements, FSMs, and corresponding code. During inference, it follows an R2F2C pattern: Requirements are processed to generate FSMs, which are validated for logical consistency, then translated into Solidity code. The system iteratively refines generated code using feedback from compilation tools (py-solc-x) and security scanners (Slither), creating a feedback loop that improves both syntax correctness and vulnerability reduction.

## Key Results
- Achieves up to 95.1% compilation success rate, significantly outperforming direct generation baselines
- Reduces vulnerability risk scores by approximately 68% compared to existing methods
- FPFT fine-tuning demonstrates clear advantages over LoRA, improving compilation rates by ~15%
- Ablation studies confirm the critical role of both FSM intermediate representation and iterative feedback

## Why This Works (Mechanism)

### Mechanism 1: Intermediate State Abstraction (SmartFSM)
The framework uses an intermediate FSM representation to reduce logical errors in low-resource languages like Solidity. By forcing the LLM to map logic to state transitions before attempting syntax generation, it ensures logical consistency is established before code synthesis begins.

### Mechanism 2: Feedback-Driven Refinement
Iterative feedback using compilation and security analysis tools corrects syntax and security vulnerabilities more effectively than single-pass generation. Detected errors are fed back into the LLM via specialized prompts, triggering targeted regeneration.

### Mechanism 3: Domain-Specific Supervised Fine-Tuning (FPFT)
Full Parameter Fine-Tuning on a task-specific dataset aligns the model's generation capabilities closer to Solidity syntax than general-purpose instruction tuning. The FPFT approach outperforms parameter-efficient methods like LoRA for this domain-specific task.

## Foundational Learning

- **Finite State Machines (FSM) & Mealy Machines**
  - Why needed: SmartFSM is an extension of the Mealy machine, where outputs depend on both state and input. Understanding this is vital for designing transition logic.
  - Quick check: Can you distinguish between a "state" (a condition of the system) and a "transition" (the trigger moving between states)?

- **Smart Contract Security Vectors (Slither)**
  - Why needed: The framework's value proposition relies on reducing Vulnerability Risk Scores using Slither. Understanding issues like "Locked Ether" or "Reentrancy" is essential for interpreting the feedback loop.
  - Quick check: Why is "Locked Ether" a vulnerability, and how would an FSM explicitly define a state to allow withdrawals?

- **Supervised Fine-Tuning (FPFT vs. LoRA)**
  - Why needed: The paper argues specifically for Full Parameter Fine-Tuning over LoRA. Understanding this trade-off is critical for resource allocation.
  - Quick check: Why might updating all model parameters (FPFT) be necessary for a "low-resource" language compared to a high-resource language like Python?

## Architecture Onboarding

- **Component map:** Input Processor -> FSM Generator -> FSM Validator -> Code Generator -> Refinement Loop (Compiler/Slither Feedback)
- **Critical path:** FSM Validation is the most critical step. If an FSM has unreachable states or missing transitions, the generated code will inevitably fail logic checks.
- **Design tradeoffs:** FPFT yields ~15% higher compilation rates than LoRA but requires 8x A6000 GPUs and updates all weights, while LoRA is parameter-efficient but less adaptable to Solidity syntax.
- **Failure signatures:**
  - FSM Hallucination: LLM generates states not grounded in user requirements
  - Feedback Oscillation: Model fixes syntax error but introduces new security vulnerability
  - JSON Parsing Failure: LLM outputs text description instead of required JSON format
- **First 3 experiments:**
  1. Ablation on FSM Validity: Compare "Direct" vs. "FSM" approach on 50 samples to verify if FSM improves logical consistency
  2. Feedback Loop Limit: Test 0, 1, and 3 rounds of feedback to see if performance plateaus after first iteration
  3. Security Scan Comparison: Generate code for simple auction contract and compare Slither output of "Direct" vs. "FSM-SCG" generation

## Open Questions the Paper Calls Out

### Open Question 1
Can FSM-SCG generalize to non-EVM smart contract languages (e.g., Move or Rust) given its dependency on Solidity-specific feedback tools? The methodology relies on Solidity-specific compilers and linters, making extension to other languages challenging.

### Open Question 2
How does the synthetic nature of the fine-tuning dataset impact the model's ability to interpret ambiguous or incomplete real-world user requirements? The dataset is constructed using GPT-4o to reverse-engineer requirements from code, potentially producing cleaner requirements than natural human prompts.

### Open Question 3
Does reliance on static analysis for security feedback leave generated contracts vulnerable to complex business logic flaws that static detectors cannot identify? The reported VRS reduction only accounts for issues detectable by specific static analyzers, potentially missing logic bugs.

## Limitations

- The dataset construction process using GPT-4o is a black box, creating dependency on a specific FSM representation style that may not generalize to real-world requirements
- No validation on truly independent benchmarks of user requirements and corresponding contracts
- Complex vulnerabilities requiring architectural changes may not be adequately addressed by the refinement loop, potentially causing oscillation

## Confidence

- **High Confidence:** Intermediate FSM abstraction and feedback-driven refinement are well-supported by ablation studies and comparative analysis
- **Medium Confidence:** Fine-tuning approach shows clear performance improvements over LoRA, but synthetic dataset quality and overfitting potential introduce uncertainty
- **Low Confidence:** Generalization to real-world user requirements and complex vulnerability resolution remain unproven

## Next Checks

1. **Independent Dataset Validation:** Test FSM-SCG on external benchmarks of user requirements and contracts from real blockchain development forums to verify generalization beyond the constructed dataset.

2. **Complex Vulnerability Analysis:** Systematically generate contracts containing multi-step vulnerabilities and evaluate whether the feedback loop can resolve them or if it oscillates without fixing underlying architectural issues.

3. **Real User Requirement Testing:** Conduct a user study where non-expert users provide natural language requirements, then evaluate generated contract quality and security compared to direct LLM generation without FSM guidance.