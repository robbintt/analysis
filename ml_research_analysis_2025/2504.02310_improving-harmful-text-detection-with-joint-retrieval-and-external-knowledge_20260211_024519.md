---
ver: rpa2
title: Improving Harmful Text Detection with Joint Retrieval and External Knowledge
arxiv_id: '2504.02310'
source_url: https://arxiv.org/abs/2504.02310
tags:
- harmful
- text
- detection
- content
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a joint retrieval framework that integrates
  pre-trained language models with knowledge graphs to improve harmful text detection
  accuracy and robustness. The method combines semantic understanding, contextual
  dependency, and cross-modal information fusion using a dynamic transformer-based
  framework and Graph Attention Networks.
---

# Improving Harmful Text Detection with Joint Retrieval and External Knowledge

## Quick Facts
- arXiv ID: 2504.02310
- Source URL: https://arxiv.org/abs/2504.02310
- Reference count: 22
- Key outcome: Joint retrieval framework integrating PLMs with knowledge graphs achieves 0.92-0.94 accuracy on RealToxicityPrompts vs 0.85-0.87 for BERT/RoBERTa alone

## Executive Summary
This study proposes a joint retrieval framework that combines pre-trained language models with knowledge graphs to improve harmful text detection accuracy and robustness. The method integrates semantic understanding, contextual dependency, and cross-modal information fusion using a dynamic transformer-based framework and Graph Attention Networks. Experiments on the RealToxicityPrompts dataset demonstrate that joint retrieval models significantly outperform single-model baselines, achieving 0.92-0.94 accuracy compared to 0.85-0.87 for BERT/RoBERTa alone. The approach shows strong generalization across training data sizes and multilingual environments, particularly benefiting from knowledge graph integration.

## Method Summary
The framework embeds text via PLMs (BERT/RoBERTa), applies contrastive loss with temperature τ to separate harmful/benign representations, constructs adjacency matrices linking text entities to knowledge graphs, updates features via Graph Attention Networks, and fuses representations using weighted sum (H = λh + (1-λ)h') before classification via cross-entropy. The method uses RealToxicityPrompts dataset with 80/10/10 train/val/test split, toxicity threshold ≥0.5 for harmful label, and applies BERT tokenization with stratified sampling and augmentation (synonym replacement, back translation, random deletion).

## Key Results
- Joint retrieval models achieve 0.92-0.94 accuracy vs 0.85-0.87 for BERT/RoBERTa baselines
- Model maintains higher accuracy than single models with only 10% training data
- Performance degrades for Arabic and German compared to English, indicating language-specific challenges

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Semantic Separation
The framework uses contrastive loss to maximize inter-class distance between harmful and normal text embeddings while minimizing intra-class variance. By explicitly optimizing for separation using temperature parameter τ, the model creates distinct clusters for harmful content, making it easier to identify subtle violations. The contrastive loss is defined as $L_{contrast} = - \sum \log \frac{\exp(\text{sim}(h_i, h_j)/\tau)}{\sum \exp(\text{sim}(h_i, h_k)/\tau)}$, explicitly maximizing distance between positive and negative pairs.

### Mechanism 2: Context Injection via Graph Attention Networks (GAT)
A Knowledge Graph (G=(V,E)) encodes entity relationships, and a dynamic adjacency matrix A is constructed for input text. A GAT updates node features by weighting neighbor influences, allowing the model to "read" context around entities. The GAT update rule is $h'_i = \sum_{j \in N(i)} \alpha_{ij} W h_j$, facilitating extraction of contextual information to detect "hidden harmful text."

### Mechanism 3: Weighted Multi-Source Fusion
The architecture fuses semantic vector h (from LLM) and graph feature vector h' (from GAT) using weighted sum: H = λh + (1-λ)h'. This allows the model to balance "what is said" (text semantics) against "how concepts relate" (knowledge structure), achieving "stronger generalization and robustness" compared to single-source approaches.

## Foundational Learning

- **Concept: Contrastive Learning (InfoNCE Loss)**
  - Why needed here: The paper relies on contrastive loss to drive training process. Without understanding positive/negative pair formation and temperature effects, one cannot debug why model fails on subtle content.
  - Quick check question: If temperature τ approaches 0, how does gradient behavior change regarding hard negatives?

- **Concept: Graph Attention Networks (GAT)**
  - Why needed here: Core innovation integrates GAT to process Knowledge Graph. Engineers must understand attention coefficient computation to interpret why entities are flagged as harmful context.
  - Quick check question: In GAT layer, how does masking (adjacency matrix) prevent model from attending to non-existent relationships?

- **Concept: Late Fusion / Weighted Sum Fusion**
  - Why needed here: Architecture combines distinct modalities (Text and Graph). Understanding feature alignment is critical for implementing final classification layer.
  - Quick check question: Why might simple weighted sum (H = λh + (1-λ)h') fail if magnitudes of h and h' are significantly different?

## Architecture Onboarding

- **Component map:** Input Text T -> BERT/RoBERTa -> Semantic Vector h; T entities -> Knowledge Graph G -> Adjacency Matrix A -> GAT -> Graph Vector h'; Weighted sum H = λh + (1-λ)h' -> Linear classifier + Cross-Entropy Loss

- **Critical path:** Entity-to-Graph Mapping is most fragile component. If input text contains entities not present in Knowledge Graph, adjacency matrix A becomes sparse or empty, rendering GAT branch useless and forcing model to rely solely on LLM branch.

- **Design tradeoffs:** Joint Retrieval (Multimodal) model achieves 0.94 accuracy but slows detection speed to 16.3ms, whereas RoBERTa alone is 11.8ms. Addition of GAT branch adds computational overhead. RoBERTa generally outperforms BERT in this framework (0.92 vs 0.91 accuracy), suggesting choice of base LLM is significant even with external knowledge.

- **Failure signatures:** Multilingual drop shows performance drop for Arabic and German compared to English, indicating Knowledge Graph or entity alignment is English-centric. Data scarcity plateau suggests beyond 70% training data, accuracy gains diminish (approx. 0.95 cap), implying model architecture saturates and requires structural innovation rather than just more data.

- **First 3 experiments:** 1) Replicate Table 1 by running BERT and RoBERTa single models on RealToxicityPrompts to establish performance gap (targeting 0.85-0.87 accuracy). 2) Ablate λ parameter (currently defined as hyperparameter). Test values λ ∈ [0.1, 0.9] to see if balance between semantic and knowledge features should be static or learned. 3) Subsample training data to 10% (as shown in Figure 2) to verify if Joint Retrieval (RoBERTa+KG) actually maintains higher accuracy than single model, confirming robustness claim.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can explainable AI techniques be tailored to this joint retrieval framework to clarify specific contribution of knowledge graph integration in identifying nuanced harmful content? The Conclusion states that "interpretability of the detection process remains an open challenge" and deep learning models "operate as black boxes."

- **Open Question 2:** What specific multilingual pretraining or translation-based augmentation strategies are most effective at closing performance gap for low-resource languages like Arabic and German within this framework? The Conclusion notes a "performance gap" in languages with fewer annotated samples and explicitly suggests exploring "multilingual pretraining approaches" or "translation-based augmentation."

- **Open Question 3:** Does incorporating image and audio analysis into joint retrieval framework significantly improve detection robustness on social media platforms compared to text-only knowledge graph integration? The Abstract lists "expanding multimodal detection capabilities" as future research focus, and Conclusion suggests analyzing harmful content across "text, images, and audio."

## Limitations

- Knowledge graph source and entity linking methodology remain unspecified, creating significant barrier to reproduction
- Model's effectiveness in low-resource languages is unproven, as performance degrades substantially for Arabic and German compared to English
- Architecture assumes trusted knowledge base, potentially vulnerable to knowledge poisoning attacks that could manipulate detection outcomes

## Confidence

- **High Confidence:** Contrastive learning mechanism for semantic separation and GAT-based knowledge integration are well-grounded in established literature with clear mathematical formulations
- **Medium Confidence:** Claimed accuracy improvements (0.92-0.94 vs 0.85-0.87) are plausible given methodology but depend heavily on implementation details not fully specified
- **Low Confidence:** Robustness claims across multilingual environments and low-resource settings are not sufficiently validated, as paper only reports performance drops rather than solutions

## Next Checks

1. Implement ablation studies on λ fusion parameter to determine if weighted sum is optimal or if learned attention would perform better
2. Test model's vulnerability to knowledge graph poisoning by introducing deliberate misinformation into KG and measuring detection accuracy degradation
3. Evaluate cross-lingual transfer by training on English data and testing on unseen low-resource languages to quantify "cold start" problem for entity linking