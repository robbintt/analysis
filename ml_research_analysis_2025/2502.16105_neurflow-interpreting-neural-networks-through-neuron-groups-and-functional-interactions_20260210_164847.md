---
ver: rpa2
title: 'NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional
  Interactions'
arxiv_id: '2502.16105'
source_url: https://arxiv.org/abs/2502.16105
tags:
- neurons
- concept
- neuron
- core
- groups
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes NeurFlow, a framework that interprets neural
  networks by analyzing groups of neurons rather than individual neurons. It identifies
  core concept neurons, clusters them into groups based on shared functional relationships,
  and constructs a hierarchical circuit to represent interactions between these neuron
  groups.
---

# NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional Interactions

## Quick Facts
- arXiv ID: 2502.16105
- Source URL: https://arxiv.org/abs/2502.16105
- Reference count: 30
- Primary result: NeurFlow identifies core concept neurons and constructs hierarchical circuits, showing masking these neurons significantly degrades model performance compared to random masking, with 90%+ overlap with other critical neuron identification methods.

## Executive Summary
NeurFlow presents a framework for interpreting neural networks by analyzing groups of neurons rather than individual neurons. The method identifies core concept neurons that are most influential for specific class representations, clusters them based on shared functional relationships, and constructs a hierarchical circuit to represent interactions between these neuron groups. This approach aims to improve interpretability while reducing computational costs compared to analyzing individual neurons. The framework is automated and requires no human intervention or predefined concept labels.

## Method Summary
NeurFlow constructs hierarchical circuits for neural network interpretation by first identifying core concept neurons for a target neuron using Integrated Gradients attribution on top-activated image patches. These neurons are clustered into semantic groups based on their activation patterns, and similar neurons are grouped together to form a hierarchical circuit. The method operates recursively from the output logit layer down through the network, creating a tree structure where edge weights represent normalized contribution scores between neuron groups.

## Key Results
- Masking core concept neurons identified by NeurFlow causes significantly greater performance degradation than masking random neurons
- The method achieves 90%+ overlap with critical neurons identified by other methods (NeuronMCT, NeuCEPT)
- Results are robust to different values of k (concept size parameter), maintaining >86% overlap across k=30-190
- No human intervention required; the framework automatically identifies and labels concepts

## Why This Works (Mechanism)

### Mechanism 1
Integrated gradients computed over top-activated image patches can identify which upstream neurons causally influence a target neuron's concept. For each neuron a, the framework extracts Va (top-k most activating patches), then computes importance scores T(a, si, Va) using integrated gradients from each candidate neuron si in the previous layer. The top-τ neurons by absolute score are selected as core concept neurons. Knocking these out changes Va significantly more than random neurons. Core assumption: Neurons that contribute high gradient attribution to a target's activation on its concept images are causally necessary for that concept. Evidence anchors: [abstract]: "masking core concept neurons significantly impacts model performance compared to masking random neurons"; [section 4, Figure 6]: "for τ = 1, the correlation consistently exceeds 0.6 in both models" between IG scores and knockout loss.

### Mechanism 2
Clustering visual features by their activation patterns across the preceding layer creates semantically coherent groups that disambiguate polysemantic neurons. Each visual feature vi in Va is represented by a vector r(vi) = [mean(ϕ₁(vi)), ..., mean(ϕₘ(vi))] averaged across all channels. Agglomerative clustering with Silhouette-based cluster count selection groups features that activate the preceding layer similarly. These "semantic groups" separate the multiple concepts a polysemantic neuron encodes. Core assumption: Features that produce similar activation patterns across channels belong to the same semantic concept. Evidence anchors: [section 3.4]: "neurons often exhibit polysemantic behavior... the visual features within a concept Va of neuron a may not share the same meaning"; [section 3.5]: neurons are grouped together if their semantic groups cluster together.

### Mechanism 3
Edge weights normalized within each semantic group quantify how much each upstream neuron contributes to specific aspects of a downstream neuron's concept. For parent neuron a with semantic group Va,j and child neuron si, weight w(a, si, Va,j) = T(a, si, Va,j) / Σ|T(a, s, Va,j)|. This normalizes contributions so they sum to 1 per semantic group, enabling comparison of relative influence. Core assumption: Importance scores computed over a semantic subgroup reflect causal contribution to that specific sub-concept. Evidence anchors: [section 3.4, Equation 4]: explicit weight formula using normalized IG scores; [section 4, Figure 6]: correlation between IG scores and knockout loss validates the underlying attribution.

## Foundational Learning

- Concept: Integrated Gradients (attribution method)
  - Why needed here: The entire core neuron identification relies on understanding how gradients integrated along a path from baseline to input assign attribution to upstream components.
  - Quick check question: Can you explain why integrating gradients along a path satisfies the sensitivity and implementation invariance axioms?

- Concept: Agglomerative Hierarchical Clustering
  - Why needed here: Both semantic group detection and neuron group formation use this to create conceptually coherent clusters without pre-specifying cluster count.
  - Quick check question: What linkage criterion does agglomerative clustering use, and how does the Silhouette score determine optimal cluster count?

- Concept: Neural Circuit Interpretability
  - Why needed here: NeurFlow constructs hierarchical circuits explaining how neuron groups interact; understanding this paradigm contextualizes the contribution.
  - Quick check question: How does a "circuit" differ from simply listing important neurons, and what does an edge weight in a circuit represent?

## Architecture Onboarding

- Component map: Data Augmentation Module -> Core Neuron Identifier -> Semantic Grouper -> Neuron Grouper -> Circuit Builder
- Critical path: Logit neuron (root) -> identify its core neurons -> cluster each neuron's concept -> group neurons by semantic similarity -> repeat recursively for each layer until input
- Design tradeoffs:
  - τ (core neuron count): Lower τ = simpler circuit but may miss important contributors; higher τ = more complete but noisier
  - k (concept size): Paper shows robustness (Table 5: >86% overlap across k=30-190)
  - Multi-scale crops: Captures hierarchical features but increases dataset size ~25x
- Failure signatures:
  - Low correlation between IG scores and knockout loss -> gradients not reliable for attribution in that layer
  - Silhouette scores near zero -> semantic clustering is producing arbitrary groups
  - Retaining core neurons doesn't preserve accuracy -> τ too small or upstream paths broken
- First 3 experiments:
  1. Validate core neuron optimality: For 50 random neurons, compute loss L(S, a) for NeurFlow's Sa vs. 100 random neuron sets of same size; expect NeurFlow to achieve lower loss
  2. Fidelity test: Mask core neurons vs. random neurons in ResNet50 layer4.2 for class "bee"; expect accuracy drop >50% for core neurons vs. <10% for random
  3. Correlation check: Compute Pearson correlation between |T(a, si, Va)| and knockout loss for 500 random neuron combinations; expect r > 0.6 for small τ

## Open Questions the Paper Calls Out

### Open Question 1
Can the definition of "neuron concepts" be expanded to include distributed activation patterns rather than solely relying on top-k activated visual features? Basis in paper: [explicit] Appendix C acknowledges the limitation of defining concepts via top-k activations and suggests that incorporating distributed neural activation patterns is a promising direction for future research. Why unresolved: The current implementation restricts concept identification to the top-k most activated image patches, potentially missing complex features that manifest through distributed but lower-magnitude activation patterns across inputs. Evidence: A modified NeurFlow framework that identifies core concept neurons using distributed activation metrics and demonstrates improved comprehensiveness or fidelity compared to the top-k baseline.

### Open Question 2
How can the NeurFlow framework be adapted for non-CNN architectures, such as Vision Transformers (ViTs) or Large Language Models (LLMs)? Basis in paper: [explicit] Appendix C states that the research primarily focuses on CNNs and leaves the application of the framework to different DNN architectures for future works. Why unresolved: The current methodology relies on definitions specific to convolutional feature maps; applying it to architectures with attention mechanisms or residual connections requires redefining the "neuron" granularity (e.g., attention heads) and the interaction flow. Evidence: Successful application of NeurFlow to a Transformer-based model, demonstrating that core concept neuron groups can be hierarchically clustered and interpreted with fidelity scores comparable to the reported CNN results.

### Open Question 3
Is there an optimal, automated method for determining the threshold τ (number of core concept neurons) to balance circuit simplicity against model performance fidelity? Basis in paper: [inferred] Section 4 and Appendix D.6 discuss the trade-off between simplicity and performance based on τ, noting that while larger τ ensures completeness, the paper relies on fixed values (e.g., 16, 50) without proposing an adaptive selection mechanism. Why unresolved: The fidelity of the retained model varies with τ, but there is currently no protocol to determine the minimal τ required to capture all necessary concepts for a specific layer or class. Evidence: An algorithm that dynamically adjusts τ per layer based on activation statistics or gradient distributions, achieving maximal fidelity with the minimal number of neurons.

## Limitations
- Reliance on Integrated Gradients assumes gradients are reliable indicators of causal importance, which breaks down in deep layers with diminishing gradients
- Semantic clustering effectiveness depends heavily on the discriminative power of preceding layer activations, which varies across architectures
- Multi-scale patch augmentation creates a 25x larger dataset, potentially introducing computational bottlenecks

## Confidence
- High confidence: The core finding that masking identified core concept neurons causes substantially greater performance degradation than masking random neurons
- Medium confidence: The hierarchical circuit construction methodology works as described, though semantic grouping robustness needs more validation
- Low confidence: Claims about generalizability to non-visual domains, as all empirical validation is on image classification tasks

## Next Checks
1. Gradient reliability test: For each layer, compute correlation between IG scores and knockout loss across 100 random neuron combinations; if correlation drops below 0.4 in any layer, the attribution mechanism fails there
2. Clustering sensitivity analysis: Test semantic grouping with perturbed activation vectors (±5% noise) to verify clusters remain stable; instability indicates the method is brittle to activation variations
3. Cross-architecture generalization: Apply the framework to a transformer-based vision model (e.g., ViT) and compare core neuron identification effectiveness; significant degradation would indicate architecture-specific limitations