---
ver: rpa2
title: Leveraging Vulnerabilities in Temporal Graph Neural Networks via Strategic
  High-Impact Assaults
arxiv_id: '2509.25418'
source_url: https://arxiv.org/abs/2509.25418
tags:
- graph
- temporal
- attack
- nodes
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HIA, a restricted black-box adversarial attack
  framework designed to expose vulnerabilities in Temporal Graph Neural Networks (TGNNs).
  Unlike existing methods that use simplistic perturbations, HIA employs a data-driven
  surrogate model to identify structurally and dynamically important nodes, then executes
  a hybrid strategy combining strategic edge injection and targeted deletion to maximize
  TGNN performance degradation while maintaining stealth.
---

# Leveraging Vulnerabilities in Temporal Graph Neural Networks via Strategic High-Impact Assaults

## Quick Facts
- **arXiv ID:** 2509.25418
- **Source URL:** https://arxiv.org/abs/2509.25418
- **Reference count:** 40
- **Primary result:** Introduces HIA, a black-box adversarial attack framework for TGNNs that achieves up to 35.55% MRR degradation on link prediction tasks.

## Executive Summary
This paper introduces HIA, a restricted black-box adversarial attack framework designed to expose vulnerabilities in Temporal Graph Neural Networks (TGNNs). Unlike existing methods that use simplistic perturbations, HIA employs a data-driven surrogate model to identify structurally and dynamically important nodes, then executes a hybrid strategy combining strategic edge injection and targeted deletion to maximize TGNN performance degradation while maintaining stealth. Evaluated on five real-world datasets and four TGNN architectures, HIA achieves up to a 35.55% decrease in Mean Reciprocal Rank (MRR) for link prediction tasks, outperforming state-of-the-art baselines. These results highlight critical vulnerabilities in current TGNNs and emphasize the need for robust defenses that account for both structural and temporal dynamics.

## Method Summary
HIA is a restricted black-box adversarial attack framework for Temporal Graph Neural Networks that combines a data-driven surrogate model with a hybrid perturbation strategy. The method trains a lightweight TGN surrogate to learn edge likelihoods, then identifies high-impact nodes using a composite score of temporal growth and structural centrality. The attack executes a strategic mix of edge injection (adding low-likelihood edges) and deletion (removing high-likelihood edges) to maximize performance degradation while maintaining stealth. The framework is evaluated on five real-world datasets across four TGNN architectures, demonstrating superior performance compared to state-of-the-art baselines.

## Key Results
- HIA achieves up to 35.55% decrease in MRR for link prediction tasks on TGNNs
- Outperforms state-of-the-art baselines across five real-world datasets
- Demonstrates effectiveness against four different TGNN architectures (TGN, JODIE, DySAT, TGAT)
- Shows superior stealth characteristics through KL divergence analysis of degree distributions

## Why This Works (Mechanism)

### Mechanism 1: Surrogate-Guided Likelihood Inversion
- **Claim:** If a surrogate temporal model can accurately predict edge likelihoods, then selectively inverting these predictions (deleting high-likelihood edges, injecting low-likelihood ones) maximizes disruption to victim models that rely on similar structural and temporal dependencies.
- **Mechanism:** HIA trains a lightweight TGN as a surrogate. It deletes edges with likelihood $\hat{y} > \tau_{del}$ (85th percentile) to sever critical learned pathways and injects edges with $\hat{y} < \tau_{threshold}$ (10th percentile) to introduce noise, creating a hybrid perturbation strategy.
- **Core assumption:** The surrogate model's learned priors regarding edge importance transfer effectively to the victim model, despite architectural differences (e.g., TGN vs. DySAT).
- **Evidence anchors:** [abstract] mentions leveraging a "data-driven surrogate model" to identify important nodes and employing a "hybrid perturbation strategy." [Section 4.1] details the TGN surrogate architecture and its role in deriving "transferable priors" like edge likelihood. [corpus] related work "LoReTTA" validates the poisoning threat landscape for CTDGs, but specific evidence validating the *transferability of inverted likelihood priors* specifically via this hybrid method is absent in the provided corpus.
- **Break condition:** If the victim model utilizes a drastically different temporal encoding mechanism (e.g., purely frequency-based) that the surrogate fails to approximate, the transferability of the attack degrades.

### Mechanism 2: Temporal-Structural Impact Score Fusion
- **Claim:** Targeting nodes based on a composite score of temporal growth and static centrality likely disrupts both the dynamic evolution and structural integrity of the graph more effectively than targeting solely based on degree.
- **Mechanism:** The framework calculates an `Impact(v)` score (Eq. 12) as a weighted sum of temporal degree growth ($\Delta d_v(t)$), betweenness centrality ($C_B(v)$), and intra-community degree. This identifies nodes that are not just currently popular but are also structurally critical bridges.
- **Core assumption:** Nodes with rapidly increasing connectivity (high growth rate) are more influential for future predictions than nodes with static high degree (legacy hubs).
- **Evidence anchors:** [Section 4.2.1] argues that "average of past degrees would be susceptible to legacy effects," justifying the use of growth rate $\Delta d_v(t)$. [Section 5.4] Table 6 demonstrates that HIA outperforms simple "Degree" heuristics on WIKI and REDDIT, validating the need for the composite score. [corpus] does not contain specific evidence validating the superiority of combining degree growth with betweenness for adversarial targeting.
- **Break condition:** In graphs where temporal dynamics are negligible (near-static), the degree growth component ($w_1$) becomes noise, potentially reducing efficiency compared to a pure centrality attack.

### Mechanism 3: Community-Aware Target Refinement
- **Claim:** Incorporating community structure refines the attack by distinguishing between local hubs and global bridges, potentially enhancing stealth by keeping perturbations within plausible local clusters while severing global connections.
- **Mechanism:** HIA uses the Leiden algorithm to detect communities. It then prioritizes "Intra-community High-Attraction Nodes" and "Inter-community Bridge Nodes." This ensures perturbations are context-aware.
- **Core assumption:** The graph exhibits distinct community structure (modularity) such that inter-community bridges exist and are vulnerable to deletion.
- **Evidence anchors:** [Section 4.2.3] describes the use of Leiden algorithm to prioritize specific node roles based on community boundaries. [Section 6.4, Table 5(a)] shows that removing Community Detection (CD) worsens the MRR (50.12 vs 46.31), empirically validating the component's contribution. [corpus] no direct evidence in the corpus linking community-aware perturbation to increased attack efficacy.
- **Break condition:** In highly random or fully connected graphs (low modularity), the community detection step yields trivial partitions, rendering the inter/intra-community distinction ineffective.

## Foundational Learning

- **Concept: Temporal Graph Neural Networks (TGNNs)**
  - **Why needed here:** The victim models (TGN, JODIE, DySAT, TGAT) all process time-respecting paths. Understanding that they update node states based on interaction history is required to grasp why deleting historical edges (poisoning) disrupts future inference.
  - **Quick check question:** How does a memory-based TGN update its state differently from a snapshot-based model like DySAT?

- **Concept: Black-box Poisoning Attacks**
  - **Why needed here:** The paper specifies a "restricted black-box" setting. You must understand that the attacker has training data but no model gradients/internals to understand why a "surrogate" is necessary.
  - **Quick check question:** In a poisoning attack, does the attacker modify the model weights or the training data?

- **Concept: Transferability of Adversarial Examples**
  - **Why needed here:** HIA relies on the surrogate model's predictions transferring to the victim. If adversarial examples were not transferable, the surrogate-based approach would fail.
  - **Quick check question:** Why does a perturbation generated for Model A often degrade the performance of Model B in deep learning?

## Architecture Onboarding

- **Component map:** Input: Temporal Graph $G=(V, E, T)$ -> Stage 1 (Surrogate): Train Lightweight TGN -> Extract Node Embeddings $h_v(t)$ & Edge Likelihoods $\hat{y}_{uv}^t$ -> Stage 2 (Selector): Compute Metrics (Degree Growth, Betweenness) -> Run Leiden Algorithm -> Calculate Impact Score $I(v)$ -> Select Target Nodes -> Stage 3 (Attacker): Filter Edges by Likelihood & Target Nodes -> Execute Hybrid Injection/Deletion -> Output Perturbed Graph $G'$.

- **Critical path:** The quality of the **Surrogate Model** (Stage 1) dictates the success of the entire pipeline. If the surrogate's edge likelihoods ($\hat{y}$) do not correlate with the victim's learned distribution, the deletion/injection steps will be random noise.

- **Design tradeoffs:**
  - **Surrogate Complexity vs. Speed:** A deeper surrogate might better approximate the victim but increases the "online" attack generation time (though the paper claims it is efficient).
  - **Budget $\delta$ vs. Stealth:** Higher perturbation rates ($>30\%$) yield diminishing returns in performance degradation (Fig 3) but significantly increase detectability (KL divergence).

- **Failure signatures:**
  - **Low Degradation with High Budget:** Suggests the surrogate failed to transfer (Likelihood thresholds $\tau$ are misaligned with victim).
  - **High TimeCross Metric:** Indicates the attack generated temporally incoherent edges, breaking the "time-respecting path" constraint, which may trigger anomaly detection.

- **First 3 experiments:**
  1. **Baseline Verification:** Run HIA on WIKI dataset with perturbation rate $\delta=0.3$ against a TGN victim. Verify if MRR drops to ~46.31 (Table 2) to ensure the implementation is correct.
  2. **Ablation on Surrogate:** Swap the TGN surrogate for a simpler heuristic (e.g., Preferential Attachment) to measure the performance drop in the attack, confirming the value of the learned surrogate.
  3. **Stealth Analysis:** Measure the "KL divergence" of the degree distribution before and after attack on a sparse graph (e.g., BITCOIN) to ensure the hybrid strategy maintains structural stealth compared to a "Random" attack.

## Open Questions the Paper Calls Out

None

## Limitations
- The framework's effectiveness hinges on the transferability assumption between the surrogate and victim models, which is asserted but not rigorously validated across diverse TGNN architectures in the provided corpus.
- The restricted black-box setting limits generalizability to scenarios where the attacker has more or less information.
- The choice of hyperparameters (like likelihood thresholds τ_del and τ_inject) may require tuning per dataset, and the paper does not provide a systematic method for this.

## Confidence
- **High Confidence:** The hybrid edge injection/deletion strategy is novel and demonstrably outperforms naive random attacks on the evaluated datasets. The theoretical mechanism of disrupting time-respecting paths is sound.
- **Medium Confidence:** The superiority of the composite Impact(v) score over simple heuristics is shown empirically for specific datasets, but the general conditions under which this holds are not fully characterized.
- **Medium Confidence:** The surrogate model provides a reasonable approximation for deriving transferable priors, but the exact correlation between surrogate likelihoods and victim model vulnerabilities is not directly measured.

## Next Checks
1. **Transferability Stress Test:** Systematically vary the architectural gap between the surrogate (e.g., TGN) and victim models (e.g., DySAT, JODIE) to quantify the degradation in attack performance as the difference increases. This would validate the robustness of the transferability assumption.
2. **Hyperparameter Sensitivity Analysis:** Conduct a grid search over the likelihood thresholds (τ_del, τ_inject) and the weighting coefficients (w1, w2) in the Impact(v) score to determine their impact on attack efficacy and to develop a principled method for setting them.
3. **Task Generalization Test:** Evaluate HIA on a node classification task using a TGNN like TGN or TGAT to determine if the framework's core mechanism (disrupting learned temporal-structural dependencies) is effective beyond link prediction.