---
ver: rpa2
title: 'HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid
  Plexus in Pediatric Hydrocephalus'
arxiv_id: '2509.19218'
source_url: https://arxiv.org/abs/2509.19218
tags:
- hydrocephalus
- clinical
- volume
- choroid
- plexus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HyKid is a new dataset for pediatric hydrocephalus research, containing
  3D high-resolution MRI scans, expert-segmented brain tissues (including choroid
  plexus), and structured clinical data extracted from reports. It addresses the shortage
  of public, annotated datasets for this condition.
---

# HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus

## Quick Facts
- arXiv ID: 2509.19218
- Source URL: https://arxiv.org/abs/2509.19218
- Reference count: 17
- 3D high-resolution MRI scans with expert-segmented brain tissues including choroid plexus

## Executive Summary
HyKid is a novel pediatric hydrocephalus dataset containing 48 patients with 3D MRI scans reconstructed from low-resolution clinical acquisitions. The dataset features expert-annotated segmentations of brain structures including the choroid plexus, paired with structured clinical data extracted from radiology reports. The dataset enables detailed volumetric analysis and addresses the shortage of public, annotated datasets for pediatric hydrocephalus research.

## Method Summary
The dataset was created by reconstructing 3D 1mm isotropic MRI volumes from routine low-resolution axial and sagittal scans using the NiftyMIC slice-to-volume registration algorithm. Brain structures were initially segmented using SynthSeg and SPM12, then manually corrected by a neurologist to create gold-standard annotations. Clinical data was extracted from radiology reports using a retrieval-augmented generation framework that combines a knowledge base of hydrocephalus guidelines with a large language model.

## Key Results
- Choroid plexus volume shows strong correlation with total CSF volume, suggesting potential as a clinical biomarker
- Logistic regression model using CPV and TCV features achieved AUC of 0.87 for predicting patient status
- CPV–TCV coupling strength differs significantly between clinical subgroups (R² increased from 0.23 to 0.57 in "Decreased" ventricular volume group)

## Why This Works (Mechanism)

### Mechanism 1: Slice-to-Volume Super-Resolution Reconstruction
Reconstructing 3D high-resolution (1mm isotropic) volumes from routine low-resolution clinical scans enables precise volumetric segmentation. NiftyMIC combines orthogonal axial and sagittal acquisitions (≈7mm slice thickness) into a single isotropic 3D volume through slice-to-volume registration and interpolation, correcting for motion and filling resolution gaps.

### Mechanism 2: Choroid Plexus–Total CSF Volume Coupling as Clinical Biomarker
The correlation strength between choroid plexus volume and total CSF volume reflects clinical status, with stronger linear coupling associated with improvement. The choroid plexus produces CSF, so its volumetric relationship with the entire CSF space captures global fluid balance physiology better than ventricular volume alone.

### Mechanism 3: RAG-Based Structured Clinical Data Extraction
Retrieval-augmented generation reliably converts unstructured radiology reports into structured variables for model training. A knowledge base of 10 hydrocephalus guidelines is vectorized and indexed, then used to augment a large language model that extracts structured fields from clinical text.

## Foundational Learning

- **Slice-to-Volume Registration Fundamentals**
  - Why needed: Understanding how orthogonal 2D slices are transformed and fused into 3D volumes is essential for evaluating reconstruction quality
  - Quick check: Given two orthogonal low-resolution stacks with 7mm slices, what interpolation strategy would minimize blurring while preserving edges?

- **Spearman vs. Pearson Correlation for Non-Linear Relationships**
  - Why needed: The paper reports Spearman's ρ = 0.42 (significant) but linear regression R² = 0.05 (non-significant) for CPV vs. VV
  - Quick check: Why might a monotonic but non-linear relationship yield a significant Spearman correlation but a non-significant linear regression?

- **ANCOVA for Covariate Adjustment**
  - Why needed: The analysis controls for age as a covariate when comparing volume relationships across clinical subgroups
  - Quick check: If age correlates with both CPV and TCV, what would happen to the CPV–TCV relationship if age were not included as a covariate?

## Architecture Onboarding

- **Component map:**
  Raw DICOM Axial/Sagittal → NiftyMIC SVR → 3D 1mm Isotropic NIfTI
                                ↓
  SynthSeg + SPM12 + CP Model → Initial Segmentations → Expert Correction → Gold Standard
                                                                              ↓
  Raw Clinical Reports → RAG Pipeline (zhipu-embedding + FAISS + qwen3) → Structured Labels
                                                                              ↓
                                                    Statistical Analysis: Correlation, ANCOVA, LR

- **Critical path:** Expert segmentation correction is the bottleneck—one neurologist corrected all 48 cases. Automated methods perform poorly on CP (DSC = 0.43) and ventricles in severe cases (DSC = 0.87 with high variance).

- **Design tradeoffs:**
  - NiftyMIC vs. SynthSR: NiftyMIC selected despite more artifacts because SynthSR produced structural distortion
  - VV vs. TCV: TCV provides stronger explanatory power (R² = 0.40 vs. 0.33 in ANCOVA) but requires accurate external CSF segmentation
  - Single-expert annotation: Practical for 48 cases but limits inter-rater reliability assessment

- **Failure signatures:**
  - Severe ventriculomegaly causes automated segmentation failure (DSC drops to 0.67 for ventricles)
  - "Stable" clinical subgroup shows weak CPV–TCV correlation—may reflect heterogeneous pathophysiology
  - RAG extraction may miss negation patterns (e.g., "no improvement" classified as "improved")

- **First 3 experiments:**
  1. Validate RAG extraction accuracy: Manually review a random 20% sample of extracted labels against original reports; calculate precision/recall for each structured field.
  2. Test reconstruction robustness: Run NiftyMIC on scans with simulated increased slice thickness (8–10mm) to quantify minimum input quality thresholds.
  3. Cross-validate CP–CSF biomarker: Train logistic regression on tumor subgroup only, test on congenital subgroup; assess generalization across etiologies.

## Open Questions the Paper Calls Out
None

## Limitations
- Single-expert annotation approach prevents inter-rater reliability assessment
- RAG-based clinical data extraction introduces potential systematic labeling errors
- Dataset size (n=48) limits generalizability across diverse patient populations

## Confidence
- **High Confidence:** SVR reconstruction pipeline and technical implementation
- **High Confidence:** Statistical correlation patterns between CPV and TCV volumes
- **Medium Confidence:** Clinical relevance of CPV–TCV coupling as biomarker
- **Low Confidence:** Reliability of RAG-extracted structured labels

## Next Checks
1. Have a second neurologist independently segment 10 randomly selected cases to establish Dice score variability and identify systematic segmentation differences.
2. Manually review all structured labels for a random 20% sample of cases to calculate precision, recall, and identify systematic extraction errors.
3. Apply the CPV–TCV correlation analysis to an independent pediatric hydrocephalus dataset to test biomarker generalization across institutions and protocols.