---
ver: rpa2
title: Semi-decentralized Federated Time Series Prediction with Client Availability
  Budgets
arxiv_id: '2509.03660'
source_url: https://arxiv.org/abs/2509.03660
tags:
- clients
- client
- data
- availability
- trajectory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses federated learning for time series prediction
  with constraints on client availability and communication budgets. It proposes FedDeCAB,
  a semi-decentralized framework that combines probabilistic client ranking with decentralized
  collaborative optimization.
---

# Semi-decentralized Federated Time Series Prediction with Client Availability Budgets

## Quick Facts
- arXiv ID: 2509.03660
- Source URL: https://arxiv.org/abs/2509.03660
- Reference count: 32
- Primary result: Proposed FedDeCAB framework significantly outperforms baselines under high data heterogeneity, limited communication budgets, and frequent client disconnections.

## Executive Summary
This paper addresses federated learning for time series prediction with constraints on client availability and communication budgets. It proposes FedDeCAB, a semi-decentralized framework that combines probabilistic client ranking with decentralized collaborative optimization. The method uses KL divergence to assess model heterogeneity, applies decaying quadratic weights to balance client contributions, and enables offline clients to optimize with neighboring models via lightweight parameter exchange. Experiments on real-world taxi and vessel trajectory datasets show that FedDeCAB significantly outperforms baselines under high data heterogeneity, limited communication budgets, and frequent client disconnections, achieving lower prediction error and faster convergence.

## Method Summary
FedDeCAB modifies federated averaging by ranking available clients using KL divergence between local and global models, then applying decaying quadratic weights to select the top-K clients for aggregation. Offline clients receive FC-layer parameters from neighboring clients and select the best collaborative model based on empirical loss. The framework compensates for availability imbalances using compensation factors (β, γ) and manages communication budgets through adaptive weight decay. Experiments use LSTM models (128 units) on trajectory datasets with various client availability scenarios.

## Key Results
- FedDeCAB achieves lower RMSE than FedAvg, FedProx, and MOON under high data heterogeneity
- Decaying quadratic weights improve convergence speed while reducing bias in final model
- FC-layer-only exchange reduces communication overhead by 99.2% while maintaining prediction accuracy
- Offline clients show significant improvement through loss-based neighbor model selection

## Why This Works (Mechanism)

### Mechanism 1: KL Divergence as Heterogeneity Proxy for Client Selection
- Claim: Clients with higher KL divergence between their local model and the global model possess more unique data distributions that should be prioritized to prevent global model bias.
- Mechanism: The server computes DKL(normalized local update, previous global model) for each available client, ranking clients by this divergence measure. Higher divergence → higher initial selection weight.
- Core assumption: KL divergence between model parameter distributions correlates with underlying training data distribution differences (Assumption: not formally proven in paper).
- Evidence anchors:
  - [abstract]: "uses KL divergence to assess model heterogeneity, applies decaying quadratic weights to balance client contributions"
  - [Section III.B, Page 3]: "we focus on large data distribution shifts if it is not possible to sample the client over an extended period"
  - [corpus]: Weak direct support; related work on client selection (RIFLES, Adaptive Client Selection) focuses on resource efficiency rather than heterogeneity proxies.
- Break condition: When local models have not trained sufficiently for parameters to reflect data distribution (e.g., very early rounds with few local epochs).

### Mechanism 2: Time-Decaying Quadratic Weight Function
- Claim: Dynamically decaying the preference for high-divergence clients over training rounds balances initial bias reduction against eventual convergence acceleration.
- Mechanism: A quadratic curve with points (0, α), (mt, 1), (2mt, α) assigns weights based on KL-divergence ranking. Parameter α decays by Δα per round. When α ≤ 1, the function switches to linear (lower divergence = higher weight).
- Core assumption: The optimal point to transition from divergence-favoring to convergence-favoring aligns with the decay schedule of α.
- Evidence anchors:
  - [Section IV.A, Page 4-5]: Equation (5-7) defines the quadratic and linear weight functions with explicit decay mechanism.
  - [Page 4]: "Initially, clients with higher DKL are given higher weights to avoid large biases... As the number of global communication rounds increases, the weight function will gradually decay"
  - [corpus]: No direct comparison; semi-decentralized convergence analysis (arxiv:2511.11560) provides theoretical bounds but not adaptive weighting schemes.
- Break condition: When α decays too fast (converges prematurely to suboptimal solution) or too slow (delays convergence, wastes communication budget).

### Mechanism 3: Loss-Based Neighbor Model Selection for Offline Clients
- Claim: Offline clients can improve their local models by selecting the best collaborative model from neighbors based on empirical loss, enabling continued learning without server connectivity.
- Mechanism: Offline client u receives FC-layer parameters {νi} from χ neighbors, computes loss L(ν, Du) on local data for each neighbor model and its own updated model wu_t+1, selects ν* = argmin L(ν, Du). Next local update adds bias term DKL(w, ν*) to penalize deviation from ν*.
- Core assumption: Neighboring clients have geographically or functionally similar data distributions such that their models transfer usefully (Assumption: paper uses trajectory data where geographic proximity implies distribution similarity).
- Evidence anchors:
  - [abstract]: "enables offline clients to optimize with neighboring models via lightweight parameter exchange"
  - [Algorithm 2, Page 6]: Explicit pseudocode for decentralized optimization with loss-based selection.
  - [Section IV.C, Page 6]: "neighboring clients only send the fully connected layers of the model" (~0.8% of parameters).
  - [corpus]: Semi-decentralized FL (arxiv:2511.11560) confirms device-to-device communication can supplement server aggregation, but doesn't validate loss-based neighbor selection specifically.
- Break condition: When all neighbors are also offline, or when neighbor data distributions are fundamentally different (e.g., vessel vs. taxi data in same neighborhood).

## Foundational Learning

- **Concept: Federated Averaging (FedAvg)**
  - Why needed here: FedDeCAB modifies FedAvg's random client selection; understanding the baseline clarifies what's being improved.
  - Quick check question: Can you explain why random client selection in FedAvg underperforms with heterogeneous data and limited availability?

- **Concept: KL Divergence for Distribution Comparison**
  - Why needed here: The core client ranking mechanism relies on KL divergence; misunderstanding this leads to incorrect weight assignments.
  - Quick check question: Given two probability distributions P and Q, what does DKL(P||Q) = 0 indicate, and what happens when P and Q have no overlap?

- **Concept: LSTM for Sequence Prediction**
  - Why needed here: The paper uses LSTM with 128 units for trajectory prediction; the FC-layer exchange mechanism assumes this architecture.
  - Quick check question: In an LSTM model, which layers capture temporal patterns vs. output mappings? Why would FC layers be more portable across clients?

## Architecture Onboarding

- **Component map:**
  Central Server -> Global model aggregator (ServerUpdate) -> KL divergence receiver (Lk values from clients) -> Ranking engine (computes Rk_t weights, samples K clients)
  Online Clients (Ct) -> Local LSTM trainer -> KL divergence computer (DKL between local and global) -> Availability tracker (nk, Ak)
  Offline Clients (Ωt) -> Neighbor discovery module -> FC-layer exchange interface -> Collaborative model selector (loss-based)

- **Critical path:** Client local update -> KL divergence calculation -> Server ranking with decaying weights -> Top-K selection -> Global aggregation. For offline clients: Neighbor parameter exchange -> Loss evaluation -> Collaborative model selection -> Biased local update.

- **Design tradeoffs:**
  - Only transmitting FC layers (0.8% of model) reduces communication overhead but limits knowledge transfer to output layer mappings.
  - Lower decentralized round frequency (50% of centralized rounds) preserves client communication budgets but slows offline client improvement.
  - Quadratic weight decay rate Δα must be tuned to dataset convergence characteristics (no automatic adaptation).

- **Failure signatures:**
  - High variance in global model test loss across rounds -> Likely: α decaying too fast, or client availability too sparse for meaningful ranking.
  - Offline clients showing no improvement -> Check: neighbor connectivity, whether FC-layer parameters are sufficient for loss computation.
  - Late-join clients disrupting convergence -> Check: β compensation not decaying properly, or γ straggler boost too aggressive.

- **First 3 experiments:**
  1. **Baseline comparison under random availability:** Replicate Figure 2/5 conditions (Dirichlet-distributed trajectory availability) with N=40 clients, 20 communication budgets, 0.2 offline probability. Compare FedDeCAB vs. FedAvg, FedProx, MOON. Measure RMSE convergence curves.
  2. **Ablation of decaying quadratic weights:** Disable the quadratic function (set α=1 from start, use linear weights only) and compare convergence speed vs. bias in final model across 3 availability scenarios.
  3. **FC-layer vs. full-model decentralized exchange:** Test offline clients exchanging full LSTM parameters vs. FC-only. Measure communication overhead reduction vs. prediction error tradeoff on vessel trajectory dataset with 50% offline rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can decentralized communication mechanisms be designed to be more robust against extreme connectivity issues and dynamic topologies?
- Basis in paper: [explicit] The conclusion states, "Future work includes the development of more robust decentralized communication mechanisms to improve the performance of FL clients with communication budgets constraints and connectivity issues."
- Why unresolved: The current FedDeCAB framework demonstrates effectiveness in semi-decentralized settings but does not fully explore scenarios where neighbor connectivity is highly volatile or where the network topology fragments severely.
- What evidence would resolve it: Empirical results from simulations involving high node churn rates or sparse, intermittent connectivity graphs showing that the modified mechanism maintains convergence stability comparable to the static neighbor scenario.

### Open Question 2
- Question: Is the restriction of sharing only Fully Connected (FC) layers effective for non-RNN architectures like Transformers or GNNs?
- Basis in paper: [inferred] The paper notes in Section V.D that neighboring clients "only transmit parameters of fully connected (FC) layers," which constitute only 0.8% of the LSTM model parameters. This implies an assumption that the FC layers contain sufficient generalizable knowledge.
- Why unresolved: While this reduces overhead for LSTMs, it is unclear if knowledge transfer via FC layers alone is sufficient for architectures where temporal or structural reasoning is embedded in attention mechanisms or graph layers rather than the final projection.
- What evidence would resolve it: Experiments applying FedDeCAB to Transformer-based trajectory prediction models, comparing performance when sharing only FC layers versus sharing attention weights or the full model.

### Open Question 3
- Question: How does the density of the client neighbor graph impact the convergence speed of the decentralized optimization phase?
- Basis in paper: [inferred] Algorithm 2 relies on an offline client obtaining parameters from "$\chi$ neighboring clients." The paper evaluates performance under specific availability budgets but does not isolate the impact of neighbor density (degree of the connectivity graph).
- Why unresolved: If offline clients are in sparse regions with few or no neighbors, the collaborative optimization term $g_i(w, v^*)$ provides little benefit, potentially causing the "offline" performance to degrade to local-only levels.
- What evidence would resolve it: Ablation studies plotting convergence rate (RMSE over rounds) against varying average neighbor counts per client (e.g., $\chi = 1, 3, 5, 10$) to establish a connectivity threshold for effectiveness.

## Limitations

- The paper lacks precise parameter specifications for the decaying quadratic weight schedule (α, Δα) and compensation mechanisms (β, Δβ, γ), which are critical for reproducing results.
- The definition of "neighboring clients" for decentralized optimization is unclear—the distance metric and connectivity criteria determining which clients can exchange FC layers are not specified.
- No theoretical convergence guarantees are provided for the semi-decentralized variant with loss-based neighbor selection, though similar methods exist in the literature.

## Confidence

- **High confidence** in the general mechanism of KL divergence-based client ranking for heterogeneous data environments, supported by similar approaches in client selection literature.
- **Medium confidence** in the decaying quadratic weight function's effectiveness, as the adaptive transition from bias reduction to convergence acceleration is conceptually sound but lacks ablation studies.
- **Low confidence** in the specific parameter values needed for faithful reproduction, particularly the KL divergence compensation parameters and offline client neighbor discovery thresholds.

## Next Checks

1. **Parameter sensitivity analysis:** Systematically vary α and Δα to determine optimal decay schedules across different data heterogeneity levels and availability patterns.
2. **Neighbor selection robustness:** Test multiple neighbor discovery strategies (distance thresholds, k-nearest neighbors, random selection) to validate the loss-based collaborative model selection mechanism.
3. **Full vs. FC-layer exchange comparison:** Quantify the prediction error tradeoff when offline clients exchange full LSTM parameters versus only FC layers, measuring both communication overhead and model performance.