---
ver: rpa2
title: 'When Genes Speak: A Semantic-Guided Framework for Spatially Resolved Transcriptomics
  Data Clustering'
arxiv_id: '2511.11380'
source_url: https://arxiv.org/abs/2511.11380
tags:
- spatial
- gene
- transcriptomics
- semst
- biological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SemST introduces a novel deep learning framework that integrates
  Large Language Models (LLMs) to embed gene semantics directly into spatial transcriptomics
  clustering. Unlike prior methods that treat genes as isolated numerical features,
  SemST uses LLM-derived embeddings of gene symbols as biologically informed priors,
  which are dynamically fused with spatial features through a Fine-grained Semantic
  Modulation (FSM) module.
---

# When Genes Speak: A Semantic-Guided Framework for Spatially Resolved Transcriptomics Data Clustering

## Quick Facts
- arXiv ID: 2511.11380
- Source URL: https://arxiv.org/abs/2511.11380
- Authors: Jiangkai Long; Yanran Zhu; Chang Tang; Kun Sun; Yuanyuan Liu; Xuesong Yan
- Reference count: 18
- Primary result: SemST integrates LLM-derived gene embeddings with spatial features via FSM module, achieving state-of-the-art clustering performance

## Executive Summary
SemST introduces a novel deep learning framework that integrates Large Language Models (LLMs) to embed gene semantics directly into spatial transcriptomics clustering. Unlike prior methods that treat genes as isolated numerical features, SemST uses LLM-derived embeddings of gene symbols as biologically informed priors, which are dynamically fused with spatial features through a Fine-grained Semantic Modulation (FSM) module. The FSM module performs spot-specific affine transformations to inject high-order biological knowledge into spatial representations, enabling nuanced modulation between gene function and spatial context. Experiments on multiple public datasets demonstrate that SemST achieves state-of-the-art clustering performance, significantly outperforming existing methods. Notably, the FSM module serves as a versatile plug-and-play component that consistently improves the performance of baseline models when integrated.

## Method Summary
SemST constructs dual graphs (spatial proximity and expression similarity) to capture complementary spatial signals, processes them through separate GCN branches, and fuses the outputs. For each spot, top-k expressed genes are formatted into natural language prompts and passed through a frozen Qwen3-4B LLM to obtain biologically meaningful embeddings. The FSM module then applies spot-specific affine transformations (scaling and shifting) to modulate the spatial features using these semantic embeddings. The final representation is optimized using a combination of ZINB reconstruction loss, correlation reduction loss, and spatial regularization loss, with K-means clustering performed on the learned embeddings.

## Key Results
- SemST achieves state-of-the-art clustering performance across 9 public spatial transcriptomics datasets
- FSM module as plug-and-play component improves 9/9 baseline methods on HBC and MBA datasets
- LLM-derived embeddings significantly outperform random, unrelated, and BERT embeddings in clustering accuracy
- Fine-grained semantic modulation via affine transformation consistently outperforms concatenation, addition, and cross-attention fusion strategies

## Why This Works (Mechanism)

### Mechanism 1: LLM-Derived Semantic Embeddings as Biological Priors
- **Claim:** Frozen LLM encodes gene symbols into biologically meaningful representations that outperform generic text encoders
- **Mechanism:** Top-k expressed genes per spot are formatted into natural language prompts and passed through a frozen Qwen3-4B LLM. The final-layer hidden state (H_llm) captures functional relationships between genes (e.g., "Postn" → extracellular matrix; "Ttn"+"Actc1" → cardiac muscle)
- **Core assumption:** Pre-trained biomedical knowledge in LLMs transfers meaningfully to spatial transcriptomics without domain-specific fine-tuning
- **Evidence anchors:**
  - [abstract]: "SemST leverages Large Language Models (LLMs) to enable genes to 'speak' through their symbolic meanings, transforming gene sets within each tissue spot into biologically informed embeddings"
  - [ablation, Table 2]: "Random Emb." and "Unrelated Emb." variants underperform "w/o LLM" baseline; BERT embeddings produce "chaotic" UMAP patterns vs. LLM's smooth biological gradients
  - [corpus]: Related work (GenePT, SGN, OmiCLIP) validates LLM-derived gene embeddings for transcriptomic tasks, but direct validation for spatial domain clustering is limited
- **Break condition:** If gene symbols are highly ambiguous or poorly represented in LLM pre-training corpora, semantic quality degrades

### Mechanism 2: Fine-Grained Semantic Modulation (FSM) via Affine Transformation
- **Claim:** Spot-specific scaling (α) and bias (β) factors enable semantic embeddings to dynamically calibrate spatial features element-wise
- **Mechanism:** MLP projects H_llm → Z_mod ∈ R^(N×2d), split into α and β. Final representation: Z_final = ((1 + α) ⊙ Z_gcn + β)W. This allows biological knowledge to emphasize or suppress specific spatial feature dimensions per spot
- **Core assumption:** A single MLP can learn coordinated scaling and shifting from shared semantic space, with gradients inducing functional specialization during training
- **Evidence anchors:**
  - [Method]: "This affine transformation enables the semantic representation to dynamically modulate each spot's spatial features through fine-grained scaling and shifting"
  - [ablation, Table 2]: FSM outperforms concatenation, addition, and cross-attention fusion strategies across datasets
  - [Table 3]: FSM as plug-and-play module improves 9/9 baseline methods on HBC, 9/9 on MBA
  - [corpus]: No direct corpus validation; this modulation approach appears novel to spatial transcriptomics
- **Break condition:** If α and β gradients collapse (e.g., near-zero variance), modulation becomes trivial

### Mechanism 3: Multi-View Graph Construction for Complementary Spatial Signals
- **Claim:** Dual graphs—spatial proximity (A_spa) and expression similarity (A_fea)—capture different biological relationships that improve clustering when fused
- **Mechanism:** A_spa uses Euclidean distance threshold r; A_fea uses KNN on cosine similarity of expression profiles. Separate GCN branches propagate information, outputs concatenated (Z_gcn = Concat(H_spa, H_fea))
- **Core assumption:** Expression-similar but spatially distant spots share functional domains (e.g., tissue layers)
- **Evidence anchors:**
  - [Method]: "The former excels at modeling microenvironmental interactions, while the latter is well suited for identifying spots that belong to the same layer but are spatially distant"
  - [Method, L_cr]: Correlation reduction loss encourages feature consistency across views while reducing cross-feature correlation
  - [corpus]: Multi-view GCN approaches (Spatial-MGCN, GraphST) are established baselines, validating the dual-graph paradigm
- **Break condition:** If tissue has no layered structure or if expression similarity is noisy, A_fea may introduce spurious connections

## Foundational Learning

- **Concept: Graph Neural Networks (GCN) for Spatial Data**
  - **Why needed here:** SemST uses GCN layers to aggregate neighbor information across two graph topologies. Understanding message passing is essential to debug representation quality
  - **Quick check question:** Can you explain how equation (3) updates node features using neighbor information?

- **Concept: Zero-Inflated Negative Binomial (ZINB) Distribution**
  - **Why needed here:** Spatial transcriptomics data is sparse and over-dispersed; ZINB reconstruction loss (L_zinb) is the primary training objective
  - **Quick check question:** What three parameters does the ZINB distribution require, and why is zero-inflation necessary for this data?

- **Concept: Affine Transformations as Feature Modulation**
  - **Why needed here:** FSM uses learnable scale (α) and shift (β) to modulate features—conceptually similar to FiLM layers in visual reasoning
  - **Quick check question:** Why might element-wise modulation outperform concatenation when fusing heterogeneous modalities (semantics vs. spatial)?

## Architecture Onboarding

- **Component map:** Input: X (expression), S (coordinates), G (gene symbols) → Dual Graph Construction → A_spa, A_fea → Dual GCN Branches → H_spa, H_fea → Concat → Z_gcn → LLM Encoder (frozen) ← Top-k genes per spot → H_llm → FSM Module MLP → α, β → Z_final = ((1+α)⊙Z_gcn+β)W → Decoder → ZINB parameters → L_zinb + γL_cr + λL_s
- **Critical path:** Gene symbol quality → LLM embedding quality → FSM modulation effectiveness → clustering accuracy. The FSM module is the nexus where biological semantics must align with spatial representations
- **Design tradeoffs:**
  - k_g (top genes): Higher values capture more biology but risk redundancy/noise (optimal: 20-30 per ablation)
  - LLM choice: Larger models may improve semantic quality but increase inference cost; Qwen3-4B chosen for single-GPU feasibility
  - Frozen vs. fine-tuned LLM: Frozen preserves pre-trained knowledge but cannot adapt to domain-specific gene relationships
- **Failure signatures:**
  - α/β distributions with near-zero variance → FSM not learning meaningful modulation
  - ARI drops when adding FSM → semantic-spatial misalignment; check L_s weight (spatial regularization)
  - Performance worse than "w/o LLM" → LLM embeddings may be hallucinating; verify prompt quality or switch to gene-summary approach
- **First 3 experiments:**
  1. **Reproduce ablation on one dataset:** Run SemST with and without LLM embeddings on DLPFC 151672. Confirm ΔARI > 10 points matches Table 2
  2. **Test FSM as plug-and-play:** Integrate FSM into GraphST baseline. Verify ARI improvement on HBC dataset (expected: +4.46 per Table 3)
  3. **Parameter sweep on k_g:** Vary k_g ∈ {5, 10, 20, 30, 50} on ME dataset. Confirm performance peaks around 30 (Figure 4)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can an adaptive mechanism be developed to determine the optimal number of highly expressed genes ($k_g$) per spot, rather than relying on a manually tuned global hyperparameter?
- **Basis in paper:** [explicit] The paper analyzes the impact of $k_g$ (Figure 4) and notes that performance varies significantly, peaking at 20 for MBA but 30 for ME/MVC, suggesting the optimal count is data-dependent
- **Why unresolved:** The current implementation treats $k_g$ as a fixed hyperparameter requiring grid search, which may not capture the varying information density or biological heterogeneity across different spots within the same tissue
- **Evidence would resolve it:** A method that dynamically selects $k_g$ based on local expression entropy or variance, demonstrating equal or superior performance to the fixed baseline without manual tuning

### Open Question 2
- **Question:** How do different textual representations of gene information (e.g., pure symbols vs. NCBI summaries) quantitatively affect the trade-off between capturing gene-gene synergy and minimizing LLM hallucination errors?
- **Basis in paper:** [explicit] The supplementary material ("Discussion on Gene Texts") notes that summary-based methods reduce hallucination risk but symbol-based methods may better capture synergistic interactions, showing similar performance
- **Why unresolved:** The paper presents these as competing alternatives with similar outcomes but distinct theoretical advantages, leaving the specific conditions under which one modality outperforms the other undefined
- **Evidence would resolve it:** A comparative error analysis on datasets with known ground-truth interactions, specifically identifying cases where hallucinations degrade summary-based clustering or where symbol-based "synergy" improves it

### Open Question 3
- **Question:** Do the learned affine transformation parameters ($\alpha$ and $\beta$) in the Fine-grained Semantic Modulation (FSM) module correlate with specific biological states or pathway activities?
- **Basis in paper:** [inferred] The paper asserts the FSM module injects "high-order biological knowledge," yet the analysis of the modulation parameters (Figure 6) is limited to their statistical distributions rather than their biological interpretation
- **Why unresolved:** It is currently unclear if the scaling ($\alpha$) and shifting ($\beta$) factors represent explainable biological adjustments (e.g., suppressing immune signals in tumor regions) or merely effective mathematical calibrations
- **Evidence would resolve it:** A correlation study linking high-magnitude values in specific feature dimensions of $\alpha$ and $\beta$ to the activation of known Gene Ontology (GO) terms or pathways in the corresponding spatial domains

### Open Question 4
- **Question:** How does the SemST framework scale to ultra-large spatial transcriptomics datasets (e.g., millions of spots) regarding GPU memory and computational time?
- **Basis in paper:** [inferred] The experiments are conducted on datasets with relatively small spot counts (maximum 5,913 spots in Table 4), while the method relies on GNNs (which scale with graph edges) and pre-computed LLM embeddings
- **Why unresolved:** The feasibility of the proposed FSM and GNN backbone remains untested on modern high-resolution platforms (like Stereo-seq or Xenium) where spot counts often exceed 100,000
- **Evidence would resolve it:** Performance benchmarks (runtime and memory) on a large-scale dataset (e.g., >50,000 spots) showing whether the method converges in a reasonable timeframe without requiring graph subsampling or patch-based processing

## Limitations
- LLM semantic quality depends on gene symbol representation in pre-training corpus; unclear if LLM embeddings transfer meaningfully to spatial clustering beyond text-based tasks
- FSM modulation assumes coordinated α and β learning from shared MLP; no analysis of α/β distributions to confirm functional specialization
- Dual-graph assumption (spatial + expression) may not hold for tissues without layered structure; expression similarity may introduce noise if profiles are noisy

## Confidence
- **High:** Multi-view GCN + FSM as plug-and-play module consistently improves baselines (9/9 on HBC, MBA). FSM outperforms other fusion strategies
- **Medium:** LLM-derived embeddings improve clustering vs. random/unrelated embeddings and generic BERT embeddings. BERT shows chaotic patterns, suggesting LLM provides coherent biological structure
- **Medium:** ZINB reconstruction + correlation reduction loss enables stable training; ARI/NMI/ACC/F1 scores are competitive with state-of-the-art methods

## Next Checks
1. **Verify LLM embedding quality:** Run UMAP visualization on LLM vs. BERT embeddings for DLPFC dataset. Confirm LLM embeddings show smooth biological gradients (not random scatter) as claimed in ablation
2. **Analyze FSM modulation:** Extract α and β distributions after training on ME dataset. Check for non-zero variance and correlation with gene functional categories to confirm meaningful modulation
3. **Test failure conditions:** Run SemST with swapped graph types (spatial → expression, expression → spatial) on MVC dataset. Verify performance degrades, confirming dual-graph complementarity