---
ver: rpa2
title: 'CoRe-Fed: Bridging Collaborative and Representation Fairness via Federated
  Embedding Distillation'
arxiv_id: '2602.00647'
source_url: https://arxiv.org/abs/2602.00647
tags:
- learning
- client
- global
- clients
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness challenges in federated learning
  arising from performance, representation, and collaborative biases caused by heterogeneous
  data distributions and unequal client participation. The proposed CoRe-Fed framework
  jointly mitigates these issues through embedding-level alignment via contrastive
  learning and knowledge distillation, combined with contribution-aware aggregation
  that weights clients based on participation frequency and representational similarity.
---

# CoRe-Fed: Bridging Collaborative and Representation Fairness via Federated Embedding Distillation

## Quick Facts
- arXiv ID: 2602.00647
- Source URL: https://arxiv.org/abs/2602.00647
- Authors: Noorain Mukhtiar; Adnan Mahmood; Quan Z. Sheng
- Reference count: 16
- Primary result: Achieves 6% accuracy improvement while reducing representation and performance fairness disparities by 26-70% on FMNIST and CIFAR-10

## Executive Summary
CoRe-Fed addresses fairness challenges in federated learning arising from heterogeneous data distributions and unequal client participation. The framework jointly mitigates performance, representation, and collaborative biases through embedding-level alignment via contrastive learning and knowledge distillation, combined with contribution-aware aggregation that weights clients based on participation frequency and representational similarity. Extensive experiments show state-of-the-art accuracy improvements (up to 6%) while significantly reducing fairness disparities (26-70%) compared to baselines on Fashion-MNIST and CIFAR-10 datasets.

## Method Summary
CoRe-Fed implements a three-pronged approach: (1) contrastive embedding alignment using NT-Xent loss to maximize cosine similarity between local and global embeddings while pushing away from other clients' embeddings, (2) embedding-level knowledge distillation where local embeddings are refined toward alignment vectors weighted by cosine similarity scores, and (3) sigmoid-modulated contribution-aware aggregation that combines inverse participation frequency with representation alignment weighting. The framework uses 100 clients with 20 participating per round, training for 1000 rounds on partitioned FMNIST and CIFAR-10 datasets using Dirichlet distribution (α=0.5).

## Key Results
- Achieves up to 6% accuracy improvement over baselines
- Reduces representation fairness disparity (D_Cosine) by 26-70%
- Reduces performance fairness disparity (D_Manhattan) by 26-70%
- Maintains strong generalization across heterogeneous client distributions

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Embedding Alignment
- Contrastive learning enforces semantic consistency between local and global representations across heterogeneous clients through NT-Xent loss
- Maximizes cosine similarity between each client embedding and the global embedding while pushing away from other clients' embeddings
- Assumes the averaged global embedding captures meaningful shared semantic structure that should guide local representation learning
- Evidence: Abstract mentions "alignment-driven mechanism promotes semantic consistency between local and global embeddings"

### Mechanism 2: Embedding-Level Knowledge Distillation
- Soft distillation-based refinement reduces representational divergence while preserving client-specific local features
- Each client embedding is updated toward an alignment vector using coefficient β, where A_i is the cosine similarity score
- Assumes local representations contain valuable client-specific information that should be preserved while being guided toward global semantic coherence
- Evidence: Abstract mentions "embedding-level regularization and fairness-aware aggregation"

### Mechanism 3: Sigmoid-Modulated Contribution-Aware Aggregation
- Combines inverse participation frequency with representation alignment weighting to produce more equitable global models
- Aggregation weight w_i = (1/f_i)^γ · σ(k·ρ_i) amplifies underrepresented clients while rewarding semantically aligned updates
- Assumes infrequent participants contribute valuable but underrepresented knowledge and high alignment indicates coherent, high-quality updates
- Evidence: Abstract mentions "dynamic reward-penalty-based aggregation strategy adjusts each client's weight based on participation history and embedding alignment"

## Foundational Learning

- Concept: **Contrastive Learning (InfoNCE/NT-Xent)**
  - Why needed here: Core mechanism for embedding alignment—understanding how positive/negative pair construction and temperature scaling work is essential for tuning τ_c
  - Quick check question: How does temperature τ_c affect the relative penalty on hard negative pairs?

- Concept: **Knowledge Distillation**
  - Why needed here: Soft alignment of representations via distillation coefficients differs fundamentally from hard parameter replacement
  - Quick check question: What happens to local feature preservation if β → 1.0?

- Concept: **Federated Aggregation Schemes (FedAvg limitations)**
  - Why needed here: Understanding why uniform weighting fails under non-IID data motivates the entire contribution-aware design
  - Quick check question: Why does FedAvg inadvertently suppress meaningful updates from underrepresented clients?

## Architecture Onboarding

- Component map: DNN feature extractor → L2-normalized local embedding z_i → Server-side global embedding z_g → Contrastive module (NT-Xent loss) → Distillation module (alignment vector refinement) → Aggregation module (participation frequency + alignment weighting) → Gradient reuse for inactive clients

- Critical path: Server broadcasts ω_t to selected clients C_t → Clients train locally (E epochs), extract z_i → Server computes z_g, contrastive loss L_contrast → Server computes alignment vectors and refines embeddings via distillation → Server computes w_i from (f_i, ρ_i) using Eq. (11) → Aggregate: ω_{t+1} = ω_t − η · Σ w_i · ĝ_i

- Design tradeoffs:
  - High γ: Stronger fairness amplification for infrequent clients, but risks instability from stale updates
  - High k: Sharper sigmoid sensitivity to alignment, may over-penaly legitimately diverse representations
  - Window τ: Longer windows capture more history but reduce responsiveness to participation changes

- Failure signatures:
  - Accuracy instability/noise: Check if γ is too high—amplifying stale updates
  - Slow convergence: Check temperature τ_c or distillation coefficient β settings
  - High inter-client variance persisting: Alignment mechanism not effective; verify contrastive loss computation

- First 3 experiments:
  1. Baseline reproduction: Run CoRe-Fed on FMNIST with Dir(0.5), batch size 50, 1000 rounds; compare accuracy and D_Cosine against qFedAvg and FedMDFG baselines
  2. Ablation validation: Run Re-Fed (representation alignment only) vs. Co-Fed (contribution-aware aggregation only) vs. full CoRe-Fed to isolate component contributions
  3. Hyperparameter sensitivity: Sweep k ∈ {0.5, 2.0} and γ ∈ {0.5, 2.0} on CIFAR-10 to quantify fairness-accuracy tradeoffs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can personalization-aware fairness objectives be designed to effectively balance global collaboration with individual client preferences while maintaining both collaborative and representation fairness?
- Basis in paper: The conclusion states: "One promising direction is the design of personalization-aware fairness objectives that effectively balance global collaboration with individual client preferences."
- Why unresolved: CoRe-Fed focuses on a unified global model; it does not address scenarios where clients require personalized models that reflect their local data distributions while still participating fairly in federation
- What evidence would resolve it: A framework extending CoRe-Fed to produce personalized client models, with experiments showing trade-offs between personalization accuracy and fairness metrics across heterogeneous clients

### Open Question 2
- Question: Does CoRe-Fed generalize to non-vision domains (e.g., natural language, tabular data) and more complex model architectures beyond MLPs and CNNs?
- Basis in paper: All experiments are limited to image classification (FMNIST, CIFAR-10) with simple architectures
- Why unresolved: The contrastive loss and embedding distillation assumptions are validated only on vision tasks; representation spaces and alignment dynamics may differ substantially across domains
- What evidence would resolve it: Experiments on text classification or speech datasets using transformer-based models, comparing CoRe-Fed against the same baselines

### Open Question 3
- Question: What are the privacy implications of sharing client embedding vectors with the server for contrastive alignment and knowledge distillation?
- Basis in paper: The framework claims to preserve data privacy, yet requires clients to send embedding vectors to the server
- Why unresolved: The paper does not analyze or bound information leakage from shared embeddings, nor compare against formal privacy guarantees like differential privacy
- What evidence would resolve it: Membership inference attacks on shared embeddings, or integration of differential privacy mechanisms with analysis of privacy-utility trade-offs

## Limitations

- Exact DNN architecture specifications are referenced rather than defined, requiring cross-referencing prior works
- Gradient reuse mechanism has subtle implementation ambiguities around storage duration and window boundaries
- Critical hyperparameters (γ, k, β, τ_c) are tuned on FMNIST and may not transfer optimally to other datasets
- Contribution-aware aggregation assumes infrequent participation implies valuable underrepresented knowledge, which may not hold in all practical scenarios

## Confidence

- **High confidence:** The contrastive learning mechanism for embedding alignment and knowledge distillation framework are well-established and empirically validated
- **Medium confidence:** The contribution-aware aggregation strategy's fairness benefits are demonstrated but the underlying assumption about infrequent participants' value needs broader validation
- **Medium confidence:** The specific hyperparameter choices (γ=0.5, k=1.0, β=0.5, τ_c=0.07) work well for tested datasets but may require re-tuning for different domains

## Next Checks

1. **Architecture replication check:** Implement the exact CNN/MLP architectures by reverse-engineering from referenced prior works (Wang et al. 2021b; Pan et al. 2023) to ensure faithful reproduction

2. **Gradient reuse boundary validation:** Verify the sliding window implementation matches the paper's intended behavior by testing edge cases with rapidly changing client participation patterns

3. **Cross-dataset hyperparameter transfer:** Evaluate whether the tuned hyperparameters maintain performance on non-vision datasets (e.g., tabular data) to assess generalizability beyond FMNIST/CIFAR-10