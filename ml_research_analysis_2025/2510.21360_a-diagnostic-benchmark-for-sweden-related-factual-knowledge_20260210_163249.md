---
ver: rpa2
title: A Diagnostic Benchmark for Sweden-Related Factual Knowledge
arxiv_id: '2510.21360'
source_url: https://arxiv.org/abs/2510.21360
tags:
- swedish
- language
- dataset
- knowledge
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a manually curated Swedish QA benchmark focused
  on Sweden-specific factual knowledge. Unlike existing translated or LLM-generated
  datasets, it contains 1,293 questions about Swedish personalities and events, many
  with limited international coverage, and includes both Swedish and English versions
  to evaluate cross-lingual consistency.
---

# A Diagnostic Benchmark for Sweden-Related Factual Knowledge

## Quick Facts
- arXiv ID: 2510.21360
- Source URL: https://arxiv.org/abs/2510.21360
- Reference count: 0
- Primary result: Smaller models with concentrated Swedish training match larger multilingual models on factual recall

## Executive Summary
This paper introduces a manually curated Swedish QA benchmark focused on Sweden-specific factual knowledge. Unlike existing translated or LLM-generated datasets, it contains 1,293 questions about Swedish personalities and events, many with limited international coverage, and includes both Swedish and English versions to evaluate cross-lingual consistency. The dataset is used to compare models of varying sizes and degrees of Swedish exposure. Results show that smaller models with stronger Swedish representation (8B–9B) perform on par with much larger multilingual models (27B), and that continued pre-training on Swedish increases factual recall but also leads to catastrophic forgetting of previously known facts. These findings demonstrate the dataset's potential as a diagnostic tool for studying language adaptation and knowledge retention.

## Method Summary
The study evaluates instruction-tuned language models on a manually annotated Swedish QA benchmark containing 1,293 questions about Swedish personalities and events, with both Swedish and English versions. Models tested include Gemma-3 (270M–27B), EuroLLM (1.7B–9B), and LLaMA-3 vs AI Sweden LLaMA (CPT comparison). Evaluation uses exact match, F1, and recall metrics after lowercasing and punctuation removal. Cross-lingual consistency is measured as conditional recall between languages. Continued pre-training experiments compare Swedish CPT models against base LLaMA-3 to assess knowledge gain and forgetting.

## Key Results
- Smaller models with concentrated Swedish training (EuroLLM 9B, AI Sweden LLaMA 8B) achieve factual recall scores comparable to 3× larger multilingual models (Gemma-27B)
- Continued pre-training on Swedish improves domain knowledge but causes 35.80% forgetting of previously known facts
- Cross-lingual factual consistency is limited, with only 68–69% of correct answers matching between languages for the best models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language-specific pre-training density can compensate for model scale in factual recall tasks.
- Mechanism: Models with concentrated exposure to target-language corpora (EuroLLM 9B, AI Sweden LLaMA 8B) achieve recall scores (23.07–23.14) comparable to a 3× larger multilingual model (Gemma-27B at 25.00–25.15), suggesting that parameter count is not the sole determinant of factual knowledge when language coverage is optimized.
- Core assumption: Factual knowledge about region-specific entities is stored in language-associated weights that benefit from concentrated rather than distributed multilingual training.
- Evidence anchors:
  - [abstract] "smaller models with stronger Swedish coverage (8B, 9B) perform comparably to a much larger multilingual model (27B)"
  - [section] Table 1 shows EuroLLM 9B recall (23.07 sv / 25.39 en) vs Gemma-27B (25.00 sv / 25.15 en)
  - [corpus] Weak direct evidence; related papers focus on factual probing methods rather than language-density effects
- Break condition: If facts are stored in language-independent embedding spaces (as suggested by KLAR cited in Related Work), then scale rather than language-specific training would dominate.

### Mechanism 2
- Claim: Continued pre-training (CPT) on target-language data improves domain knowledge but causes partial catastrophic forgetting of previously known facts.
- Mechanism: AI Sweden LLaMA (Swedish CPT) answers 134 questions correctly that base LLaMA misses, but fails on 92 of 257 questions (35.80%) the base model previously answered correctly—including facts about Swedish events with substantial English coverage (e.g., Göteborgsvarvet starting location).
- Core assumption: Knowledge updating during CPT overwrites or suppresses access to existing parametric knowledge rather than purely additive accumulation.
- Evidence anchors:
  - [abstract] "continued pre-training on Swedish generally improves factual knowledge but also leads to forgetting of a part of the previously known information"
  - [section] "AI Sweden LLaMA retains 64.20% of the questions correctly answered by the original model"
  - [corpus] No direct corpus evidence on CPT-induced forgetting in multilingual settings
- Break condition: If replay or regularization methods were applied during CPT, forgetting rates should decrease—this is suggested as future work but not tested.

### Mechanism 3
- Claim: Cross-lingual factual consistency is limited even when models perform well in both languages individually.
- Mechanism: Despite reasonable recall in both languages, only 68–69% of correct answers in one language are also correct in the other for the best models (Gemma-27B, EuroLLM 9B), indicating that factual knowledge is not fully shared across language-specific output pathways.
- Core assumption: Factual knowledge is stored in a partially language-independent representation but accessed through language-specific decoding layers that introduce retrieval variance.
- Evidence anchors:
  - [abstract] "allows to probe cross-lingual factual consistency as [it] contains English translations"
  - [section] "among the correct answers in one language, only up to 68–69% are also correct in the other"
  - [corpus] FIBER (arxiv 2512.11110) corroborates cross-lingual factual probing challenges but doesn't directly validate the 68–69% consistency ceiling
- Break condition: If bypassing final language-specific layers (as Wang et al. 2025 propose in Related Work) improves transfer, then the bottleneck is decoding rather than storage.

## Foundational Learning

- Concept: Catastrophic forgetting
  - Why needed here: The paper's central finding is that CPT on Swedish causes 35.80% forgetting of previously known facts; understanding this phenomenon is essential to interpret the trade-off between knowledge gain and loss.
  - Quick check question: Can you explain why fine-tuning on new data might degrade performance on previously learned tasks?

- Concept: Cross-lingual consistency
  - Why needed here: The dataset explicitly tests whether models give the same factual answer in Swedish and English; the en|sv and sv|en metrics require understanding conditional consistency measurement.
  - Quick check question: If a model answers "Eurovision" correctly in English but "Melodifestivalen" in Swedish for the same factual question, is this an inconsistency or correct cultural localization?

- Concept: Closed-book QA evaluation metrics
  - Why needed here: The paper uses recall, F1, and exact match with minimal answers; understanding why recall can overestimate performance (verbose models with partial errors) is critical for interpreting results.
  - Quick check question: Why might a recall-based metric count a hallucinated answer as correct?

## Architecture Onboarding

- Component map:
  Dataset: 1,293 manually annotated questions (Sommarpratare: 1,190; Sports Events: 102) with Swedish and English versions
  → Evaluation pipeline: Lowercase + punctuation removal → EM / F1 / recall computation → cross-lingual consistency calculation
  → Model families tested: Gemma-3 (270M–27B), EuroLLM (1.7B–9B), LLaMA-3 vs AI Sweden LLaMA (CPT comparison)

- Critical path:
  1. Load dataset from HuggingFace (liu-nlp/swedish-facts-v1)
  2. Apply chat template with "Give a short answer..." prompt (language-matched)
  3. Generate at temperature 0
  4. Compute recall as primary metric; cross-check with EM and F1
  5. For consistency: compute en|sv and sv|en conditional recall

- Design tradeoffs:
  - Manual annotation vs. LLM-generated: Chose manual for cultural authenticity; sacrificed scalability
  - Recall vs. LLM-as-judge: Chose recall for interpretability; accepts partial-credit inflation risk
  - Swedish-only vs. bilingual evaluation: Included English translations specifically to measure cross-lingual consistency

- Failure signatures:
  - Language mismatch: AI Sweden LLaMA answers in Swedish when prompted in English → artificially low English recall (13.00 vs 23.14 Swedish)
  - Verbose contamination: Models that output correct substring plus hallucinations (e.g., Sven-Göran Eriksson example) inflate recall scores
  - Date-dependent facts: Questions about post-cutoff events may be unanswerable for some models

- First 3 experiments:
  1. Baseline evaluation: Run Gemma-27B and EuroLLM-9B on both Swedish and English splits; verify the 68–69% consistency ceiling
  2. CPT forgetting probe: Identify which fact categories (personalities vs. events) show highest forgetting rates when comparing LLaMA-3 vs AI Sweden LLaMA
  3. Metric sensitivity analysis: Compare recall scores against manual review of 50 random samples to quantify verbose-contamination inflation rate

## Open Questions the Paper Calls Out

- Which language adaptation strategies (data proportions, language mixing, replay, regularization, or architectural modifications) most effectively mitigate catastrophic forgetting while enhancing local knowledge?
  - Basis: The conclusion states this benchmark can explore strategies that mitigate forgetting and enhance local knowledge during adaptation.
  - Why unresolved: The paper demonstrates that naive continued pre-training causes forgetting but does not test alternative adaptation approaches.
  - What evidence would resolve it: Systematic comparison of different adaptation strategies on the benchmark, measuring both knowledge gain and retention rates.

- Why does continued pre-training on Swedish cause forgetting of facts that arguably have better Swedish than English coverage (e.g., Göteborgsvarvet's starting location)?
  - Basis: The authors observe this counterintuitive forgetting pattern contradicts expectations that domain-relevant training data should reinforce existing knowledge.
  - Why unresolved: The mechanism behind this phenomenon is not investigated.
  - What evidence would resolve it: Analysis of training data composition, attention patterns on relevant tokens, and comparative experiments with controlled data mixes.

- How well do the largest state-of-the-art commercial LLMs perform on Sweden-specific factual recall and cross-lingual consistency?
  - Basis: The limitations section states resource constraints limited experiments to smaller open-weight models.
  - Why unresolved: The ceiling of performance on this benchmark remains unknown.
  - What evidence would resolve it: Evaluation of frontier models (e.g., GPT-4, Claude, Gemini) on the benchmark with reported scores across both languages.

- How can the benchmark be extended with annotations measuring the degree of English versus Swedish source coverage for each fact?
  - Basis: The limitations section notes this would help distinguish whether model failures stem from lack of training data or poor knowledge transfer.
  - Why unresolved: Without coverage annotations, it is difficult to interpret failure modes.
  - What evidence would resolve it: Corpus analysis quantifying English and Swedish source availability for each question.

## Limitations

- The manual annotation process limits scalability and may introduce subjective bias in defining "minimal answers"
- Recall metric's susceptibility to verbose contamination could artificially inflate performance scores
- Cross-lingual consistency findings based on a relatively small dataset (1,293 questions) may not generalize to broader domains

## Confidence

- **High Confidence**: Smaller models with concentrated Swedish training matching larger multilingual models is well-supported by consistent results across multiple model families
- **Medium Confidence**: The catastrophic forgetting mechanism is plausible but lacks direct evidence beyond the observed 35.80% forgetting rate
- **Low Confidence**: The 68–69% cross-lingual consistency ceiling may be dataset-specific and hasn't been validated on other factual domains

## Next Checks

1. Compare recall scores against manual review of 50 random samples to quantify verbose-contamination inflation rate
2. Replicate CPT forgetting comparison with and without regularization techniques to isolate overwriting vs retrieval issues
3. Test the 68–69% consistency ceiling on a larger, multilingual factual QA dataset to determine if this is a universal property or dataset-specific