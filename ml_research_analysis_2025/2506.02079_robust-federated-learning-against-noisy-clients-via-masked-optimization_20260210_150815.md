---
ver: rpa2
title: Robust Federated Learning against Noisy Clients via Masked Optimization
arxiv_id: '2506.02079'
source_url: https://arxiv.org/abs/2506.02079
tags:
- label
- learning
- noisy
- clients
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MaskedOptim, a robust federated learning
  framework designed to handle clients with varying levels of label noise. The method
  operates in two stages: first detecting noisy clients using a two-component Gaussian
  mixture model, then applying an end-to-end masked optimization strategy that progressively
  refines labels for detected noisy clients.'
---

# Robust Federated Learning against Noisy Clients via Masked Optimization

## Quick Facts
- arXiv ID: 2506.02079
- Source URL: https://arxiv.org/abs/2506.02079
- Reference count: 40
- One-line primary result: Outperforms 16 baselines on CIFAR-10, CIFAR-10-N, AGNews, and Clothing1M with heterogeneous label noise

## Executive Summary
This paper introduces MaskedOptim, a robust federated learning framework designed to handle clients with varying levels of label noise. The method operates in two stages: first detecting noisy clients using a two-component Gaussian mixture model, then applying an end-to-end masked optimization strategy that progressively refines labels for detected noisy clients. Key technical contributions include: (1) a learnable label distribution variable updated via backpropagation, (2) a valid masking mechanism based on the small-loss trick to filter out samples with larger losses, and (3) robust model aggregation using geometric median weights instead of traditional averaging. Extensive experiments on three image datasets and one text dataset with diverse label noise patterns demonstrate that MaskedOptim outperforms sixteen baseline methods. The framework shows particular effectiveness in both robustness and label correction capabilities, with code made publicly available.

## Method Summary
MaskedOptim is a two-stage federated learning framework that addresses heterogeneous label noise across clients. In the first stage (warm-up), all clients train using logit-adjusted cross-entropy for 30 rounds, after which the server collects per-class loss vectors from each client and applies a two-component Gaussian Mixture Model to partition clients into relatively clean and noisy groups. In the second stage, clean clients continue with standard federated averaging while noisy clients employ an end-to-end masked optimization approach. This involves introducing a learnable soft label distribution variable (ỹ) initialized from the original labels, updated via backpropagation through compatibility regularization and entropy minimization, with a valid mask filtering out samples with higher losses. The server aggregates model updates using geometric median weights, and the framework includes a pre-merging step that combines local updates with global model knowledge. The method is evaluated on CIFAR-10, CIFAR-10-N, AGNews, and Clothing1M datasets with various noise types and rates.

## Key Results
- Outperforms 16 baseline methods on CIFAR-10 with symmetric noise (0.0-0.4), achieving up to 9.3% accuracy improvement over FedAvg
- Demonstrates superior label correction accuracy, achieving 71.5% F1-score on Clothing1M's human annotation noise
- Shows robustness across diverse noise patterns including asymmetric, mixed, and systematic noise types
- Maintains strong performance on text classification (AGNews) though slightly behind FedProx in some settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A two-component Gaussian Mixture Model (GMM) applied to per-class loss profiles can partition clients into "clean" and "noisy" groups after a warm-up training phase.
- Mechanism: After warm-up rounds using logit-adjusted cross-entropy, each client transmits a C-dimensional loss vector (average loss per class) to the server. GMM clusters these vectors, assigning clients to S_clean or S_noisy. Clean clients continue vanilla training; noisy clients enter the masked optimization pipeline.
- Core assumption: Label noise correlates with elevated loss values after warm-up, and noise patterns are sufficiently differentiated from clean patterns in loss space.
- Evidence anchors:
  - [section 4.1] "We exploit a two-component Gaussian Mixture Model (GMM) to divide total clients into a relatively clean group and a relatively noisy group."
  - [corpus] Neighboring papers (FNBench, FedNoRo, FedELC) use similar warm-up + loss-based client partitioning, suggesting this is an established heuristic.
- Break condition: If loss distributions of clean and noisy clients significantly overlap (e.g., high Non-IID with similar noise rates), GMM misclassification increases, potentially treating noisy clients as clean.

### Mechanism 2
- Claim: Introducing a learnable soft label distribution per sample, optimized jointly with model weights, can progressively approximate ground-truth labels for noisy clients.
- Mechanism: For each sample in S_noisy, a differentiable variable ỹ initialized from the original label is scaled by constant K and passed through softmax to produce y_d. This soft label is updated via backpropagation through two losses: CE(p, y_d) and compatibility regularization L_comp = -Σ ŷ_c · log(y_d_c). A valid mask filters high-loss samples before applying entropy minimization.
- Core assumption: Original labels ŷ retain partial signal even when noisy, so compatibility prevents y_d from diverging arbitrarily.
- Evidence anchors:
  - [section 4.2] Equations 7-10 describe the initialization and update of ỹ via backpropagation.
  - [section 4.2] "The compatibility regularization loss can be defined as: L_comp = Compatibility(ŷ, ỹ) = -Σ ŷ_c log(y_d_c)."
  - [corpus] FedELC uses similar end-to-end label correction; Joint Optim and SELFIE explore learnable label variables in centralized settings.
- Break condition: If noise rate approaches extreme levels (e.g., >80%) or noise is adversarial, compatibility with ŷ may reinforce incorrect signals.

### Mechanism 3
- Claim: Geometric median aggregation reduces the influence of outlier client updates compared to weighted averaging.
- Mechanism: Instead of FedAvg's weighted average, the server computes the geometric median of uploaded model parameters via iterative weighted averaging based on L2 distances (Algorithm 2). This downweights clients whose parameter vectors are distant from the central tendency.
- Core assumption: Noisy clients produce parameter updates that are geometric outliers relative to clean clients.
- Evidence anchors:
  - [section 4.3] "We robustly aggregate the updated models using the geometric median weights instead of traditional weighted average weights."
  - [section 4.3, Algorithm 2] Pseudocode shows iterative distance-weighted median computation.
  - [corpus] RFA, Krum, and TrimmedMean are cited as prior robust aggregation methods; geometric median specifically from RFA [42].
- Break condition: If noisy client updates are numerous or clustered (Byzantine collusion), geometric median may not isolate them effectively.

## Foundational Learning

- Concept: **Federated Averaging (FedAvg)**
  - Why needed here: The baseline framework MaskedOptim extends; understanding local update + server aggregation is essential.
  - Quick check question: Can you explain why local epochs and client sampling ratio affect convergence in FedAvg?

- Concept: **Label Noise Learning (Small-Loss Trick)**
  - Why needed here: The valid masking mechanism (Equation 12) relies on the assumption that low-loss samples are more likely correctly labeled.
  - Quick check question: Why does early training favor easy/clean samples, and how does the small-loss trick exploit this?

- Concept: **Geometric Median and Robust Statistics**
  - Why needed here: Aggregation method choice directly impacts resilience to noisy clients.
  - Quick check question: How does geometric median differ from coordinate-wise median, and when might each fail?

## Architecture Onboarding

- Component map: Server (orchestrates, aggregates via geometric median, runs GMM, broadcasts) -> Client (Clean: standard local update with logit-adjusted CE; Noisy: end-to-end optimization with learnable label variables, valid masking, triplet loss, pre-merging) -> Communication (loss vectors post-warm-up, model weights each round)

- Critical path:
  1. Warm-up rounds (T_w = 30 by default): All clients train with logit adjustment.
  2. Upload per-class loss vectors → server runs GMM → partition clients.
  3. Stage 2: Clean clients continue vanilla training; noisy clients use masked optimization with learnable labels.
  4. Aggregation: Geometric median applied to uploaded weights.

- Design tradeoffs:
  - Warm-up duration (T_w): Too short → unreliable client detection; too long → wasted computation and delayed noise handling.
  - Mask filter rate (τ = 80%): Higher → more aggressive filtering but risks discarding clean samples.
  - Pre-merge coefficient (ζ = 0.8): Higher → more global knowledge retained but may slow local adaptation.
  - Label learning rate (η = 1000): Requires tuning; differs from model LR.

- Failure signatures:
  - GMM misclassification: Clean clients receive unnecessary masked optimization → underfitting.
  - High noise heterogeneity: Single GMM split fails; consider multi-modal or hierarchical clustering.
  - Aggregation divergence: Geometric median fails to converge (max_iter reached) → fallback to coordinate-wise median or trim.

- First 3 experiments:
  1. **Ablation on masking**: Run with τ = 100% (no mask) vs. τ = 80% on CIFAR-10 symmetric noise (0.0-0.4). Expect precision drop per Table 7.
  2. **Aggregation comparison**: Swap geometric median for FedAvg aggregation on Clothing1M. Measure accuracy gap vs. Table 6.
  3. **Hyperparameter sensitivity sweep**: Vary α, β, ζ, T_w on CIFAR-10-N (human annotation noise). Plot accuracy curves per Figure 2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the MaskedOptim framework effectively generalize to dense prediction tasks such as medical image segmentation?
- Basis in paper: [explicit] The Conclusion explicitly encourages future studies to "further explore the generalization on... different learning tasks like dense prediction."
- Why unresolved: The current evaluation is restricted to image and text classification, which rely on different loss functions and evaluation metrics compared to pixel-level segmentation tasks.
- What evidence would resolve it: Experimental validation on segmentation benchmarks (e.g., ISIC, CamVid) demonstrating robust performance against noisy pixel-level annotations.

### Open Question 2
- Question: Is the "small-loss" masking mechanism effective against malicious, adversarial clients in addition to stochastic noise?
- Basis in paper: [explicit] The Conclusion identifies "extreme scenarios" involving "malicious FL participants" as a necessary direction for future exploration, distinct from the random noise tested.
- Why unresolved: Malicious agents may optimize to produce low-loss but incorrect updates (poisoning), potentially bypassing the valid mask designed to filter high-loss noisy samples.
- What evidence would resolve it: Evaluations of MaskedOptim under targeted adversarial attacks or Byzantine failure scenarios to test the limits of the geometric median aggregation and masking.

### Open Question 3
- Question: How can the framework be adapted to improve performance on natural language processing (NLP) tasks?
- Basis in paper: [inferred] Table 4 shows FedProx outperforms MaskedOptim on text classification, and Section 5.2 acknowledges that improving "robustness when learning on different modalities is one of our future works."
- Why unresolved: The method appears less robust on text data (AGNews) compared to image data, suggesting the small-loss trick or learnable distribution variables may be suboptimal for NLP noise patterns.
- What evidence would resolve it: An ablation study on the valid masking rate $\tau$ specifically for text modalities, or the integration of language-model-specific pre-training techniques.

## Limitations

- The manuscript lacks specification of the constant K in Equation 7-8, which is critical for scaling the learnable label distribution ỹ
- The exact implementation details of the GMM client classification procedure are not provided, potentially affecting reproducibility
- The compatibility regularization formula in Equation 10 is not fully specified mathematically

## Confidence

- High confidence: The geometric median aggregation method (Mechanism 3) and its implementation are well-specified and traceable to RFA [42]
- Medium confidence: The GMM-based client detection (Mechanism 1) is reasonable but sensitive to warm-up duration and noise heterogeneity
- Medium confidence: The learnable label optimization (Mechanism 2) follows established patterns but requires careful hyperparameter tuning (η=1000, K)

## Next Checks

1. **Label distribution stability test**: Run with different K values (e.g., 10, 100, 1000) and monitor ỹ magnitude during training to identify numerical instability thresholds
2. **GMM sensitivity analysis**: Vary warm-up duration T_w from 10-50 rounds and measure client classification accuracy and downstream performance impact
3. **Ablation on compatibility loss**: Remove L_comp from Equation 9 and observe whether label distribution ỹ diverges or converges to degenerate solutions