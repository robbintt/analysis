---
ver: rpa2
title: Bridging the AI Trustworthiness Gap between Functions and Norms
arxiv_id: '2512.20671'
source_url: https://arxiv.org/abs/2512.20671
tags:
- systems
- system
- trustworthiness
- functional
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies a gap between functional and normative approaches
  to trustworthy AI, noting that developers struggle to map regulatory requirements
  to technical implementations. To address this, the authors propose a conceptual
  semantic language that bridges functional AI system properties to normative trustworthiness
  principles from frameworks like the EU AI Act.
---

# Bridging the AI Trustworthiness Gap between Functions and Norms

## Quick Facts
- arXiv ID: 2512.20671
- Source URL: https://arxiv.org/abs/2512.20671
- Reference count: 32
- Primary result: Proposes a conceptual semantic language to bridge functional AI properties and normative trustworthiness principles

## Executive Summary
This paper identifies a critical gap between functional and normative approaches to trustworthy AI, highlighting that developers struggle to map regulatory requirements to technical implementations. The authors propose a conceptual semantic language that would systematically link AI system components' functions to trustworthiness aspects derived from regulatory frameworks like the EU AI Act. This mapping would enable developers to assess compliance and guide implementation decisions. The envisioned tool would support AI system description and generate trustworthiness insights based on relevant standards, though the solution remains at a conceptual stage without empirical validation.

## Method Summary
The paper presents a conceptual framework for bridging the gap between functional AI system properties and normative trustworthiness principles. The proposed approach involves creating a semantic language that maps technical AI components to regulatory requirements through formal specifications. While the paper outlines the theoretical foundation and potential benefits of such a language, it does not provide implementation details, proof-of-concept, or validation through practical application.

## Key Results
- Identifies the gap between functional and normative approaches to AI trustworthiness as a significant challenge for developers
- Proposes a conceptual semantic language to map AI system functions to normative trustworthiness principles from regulatory frameworks
- Envisions a tool that would support AI system description and generate trustworthiness insights based on relevant standards

## Why This Works (Mechanism)
The proposed semantic language works by creating a systematic mapping between technical AI components and regulatory requirements. By formalizing the relationship between what AI systems do (functional properties) and what they should achieve from a trustworthiness perspective (normative principles), developers can more easily translate abstract regulatory requirements into concrete implementation decisions. The semantic approach would provide a common vocabulary and structure for reasoning about trustworthiness across both technical and regulatory domains.

## Foundational Learning
- **Semantic mapping**: Why needed - To translate between technical and regulatory vocabularies; Quick check - Can the mapping handle multiple regulatory frameworks consistently?
- **Trustworthiness principles**: Why needed - To operationalize abstract concepts like fairness and transparency; Quick check - Are the principles specific enough for technical implementation?
- **RDF formalization**: Why needed - To create machine-readable and interoperable specifications; Quick check - Can the formal language capture complex regulatory requirements?
- **Component-function relationships**: Why needed - To link technical architecture to trustworthiness requirements; Quick check - Does the mapping scale across different AI system types?

## Architecture Onboarding
Component map: AI system components -> Functional properties -> Normative principles -> Regulatory requirements -> Trustworthiness insights

Critical path: The mapping process from functional properties to normative principles represents the critical path, as errors or ambiguities here would cascade through the entire system.

Design tradeoffs: Balancing specificity (detailed mappings) against generality (broad applicability), and managing the complexity of translating nuanced regulatory language into formal technical specifications.

Failure signatures: Incomplete or ambiguous mappings that lead to compliance gaps, overly restrictive mappings that limit technical innovation, and mismatches between regulatory intent and technical implementation.

First experiments:
1. Create a small-scale semantic mapping between one regulatory requirement and its technical implementation in a simple AI system
2. Test the mapping with both technical developers and legal experts to identify gaps and ambiguities
3. Develop a prototype tool that can generate basic trustworthiness insights from a described AI system

## Open Questions the Paper Calls Out
None

## Limitations
- The framework remains conceptual without empirical validation or proof-of-concept demonstration
- Assumes developers can meaningfully translate complex normative requirements into functional properties without addressing inherent regulatory ambiguities
- Does not discuss implementation challenges, integration with existing workflows, or validation against real-world use cases

## Confidence
Confidence in the core premise: Medium - While the identified gap is well-documented, the proposed solution lacks practical validation
Confidence in the envisioned tool's utility: Low - The tool description remains abstract without implementation details or testing
Confidence in semantic mapping approach: Medium - The theoretical foundation is sound but untested in practice

## Next Checks
1. Conduct expert interviews with AI developers and legal/regulatory professionals to validate whether the proposed semantic mapping approach addresses their actual pain points in implementing trustworthy AI

2. Develop a prototype implementation of the semantic language using RDF or similar formal specification and test its ability to map between at least three different regulatory frameworks and corresponding technical implementations

3. Perform a case study with a real AI system development project, documenting how the semantic language would have helped bridge the gap between regulatory requirements and technical implementation decisions