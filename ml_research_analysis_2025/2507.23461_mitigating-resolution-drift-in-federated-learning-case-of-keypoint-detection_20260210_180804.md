---
ver: rpa2
title: 'Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection'
arxiv_id: '2507.23461'
source_url: https://arxiv.org/abs/2507.23461
tags:
- resolution
- learning
- resolutions
- high-resolution
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses resolution-drift in federated learning for
  high-resolution regression tasks like human pose estimation. It introduces Resolution
  Adaptive Federated Learning (RAF), which uses heatmap-based knowledge distillation
  to align outputs across multiple resolutions.
---

# Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection

## Quick Facts
- arXiv ID: 2507.23461
- Source URL: https://arxiv.org/abs/2507.23461
- Authors: Taeheon Lim; Joohyung Lee; Kyungjae Lee; Jungchan Cho
- Reference count: 40
- Primary result: Resolution Adaptive Federated Learning (RAF) mitigates resolution drift in federated learning for high-resolution regression tasks like human pose estimation, achieving 27.6% accuracy improvement at low resolution (128×96) while maintaining robustness across unseen resolutions.

## Executive Summary
This paper addresses resolution-drift in federated learning for high-resolution regression tasks like human pose estimation. It introduces Resolution Adaptive Federated Learning (RAF), which uses heatmap-based knowledge distillation to align outputs across multiple resolutions. RAF employs convolution-based positional embeddings to enable Vision Transformers to train effectively on multi-resolution inputs without resolution-specific positional embeddings. Extensive experiments show that RAF mitigates resolution drift, achieving 27.6% accuracy improvement at low resolution (128×96) and maintaining robustness across unseen resolutions.

## Method Summary
RAF integrates into existing federated learning frameworks by replacing Vision Transformer's absolute positional embeddings with convolution-based positional embeddings (GPE + LPE) and adding multi-resolution knowledge distillation during local training. During local training, each image is downsampled to create multiple resolution levels, and an MSE loss between higher-resolution (teacher) and lower-resolution (student) heatmap outputs forces the model to produce consistent outputs across scales. The method maintains FedAvg's O(1/T) convergence rate under certain assumptions and demonstrates practical applicability to real-world federated scenarios with heterogeneous resolution data.

## Key Results
- RAF achieves 27.6% accuracy improvement at low resolution (128×96) compared to baseline FedAvg
- Maintains robustness across unseen resolutions, outperforming both FedAvg and FedProx baselines
- Successfully mitigates resolution drift in federated learning, ensuring clients benefit from FL even when their data has varying resolutions

## Why This Works (Mechanism)

### Mechanism 1
Multi-resolution knowledge distillation acts as a resolution-aware regularizer, preventing client models from overfitting to their native resolution. During local training, each image is downsampled to create multiple resolution levels. The higher-resolution output serves as a "teacher" and the lower-resolution output as a "student." An MSE loss between them (after upsampling the student) forces the model to produce consistent outputs across scales. Gradients are stopped on the teacher branch to prevent collapse. Core assumption: Heatmap outputs at different resolutions encode semantically equivalent spatial information that can be aligned via supervised matching.

### Mechanism 2
Convolution-based positional embeddings enable Vision Transformers to process multi-resolution inputs without resolution-specific positional embedding reinitialization or interpolation. Standard ViT uses absolute positional embeddings (APE) with fixed size tied to input resolution. RAF replaces APE with (1) Global Positional Embedding (GPE): 3×3 depth-wise convolution after patch embedding, and (2) Local Positional Embedding (LPE): 3×3 depth-wise convolution within each attention block. These convolutions adapt automatically to any input spatial dimensions. Core assumption: The spatial context injected by depth-wise convolutions generalizes across resolution changes without requiring explicit position encoding.

### Mechanism 3
RAF maintains FedAvg's O(1/T) convergence rate because the multi-resolution distillation term is convex and Lipschitz-smooth under the feature-converged (lazy-training) assumption. After the backbone features converge (late training), the objective is linearized with respect to the final layer. The distillation term adds a quadratic form that is strictly convex (due to L2 regularization). The Hessian satisfies smoothness and strong-convexity conditions required by FedAvg convergence theory. Core assumption: The shared feature extractor has converged before significant learning occurs in the final layer (lazy-training regime).

## Foundational Learning

- **Federated Learning (FedAvg)**: Why needed here: RAF is built on top of FedAvg; understanding how local updates are aggregated into a global model is essential. Quick check question: Can you explain how FedAvg aggregates client weights and why non-IID data causes client drift?

- **Knowledge Distillation**: Why needed here: RAF's core contribution is multi-resolution KD; understanding teacher-student loss and stop-gradient is required. Quick check question: Why is the teacher output detached from the computation graph during backpropagation?

- **Vision Transformer (ViT) Positional Embeddings**: Why needed here: RAF explicitly addresses ViT's limitation with fixed APE; you need to understand why APE fails on multi-resolution inputs. Quick check question: Why can't a ViT trained with APE at 256×192 directly process 128×96 inputs?

## Architecture Onboarding

- Component map: Backbone (ViTPose encoder with GPE+LPE) -> Decoder (deconvolution head for heatmap) -> Local training loop (multi-resolution KD) -> Server aggregation (FedAvg)

- Critical path: 1. Server broadcasts global weights wt 2. Each client k: downsample local data to create resolution hierarchy 3. Local training: minimize Lk = Ltask + α·Lkd + γ·Lreg 4. Client uploads wk; server aggregates: wt+1 = (1/N) Σ wk 5. Repeat until convergence

- Design tradeoffs: α (distillation weight): Higher α improves resolution robustness but may sacrifice peak accuracy at native resolution; Nk,res (number of resolution levels): More levels improve generalization but increase local compute/memory; Using interpolation at inference: Upsampling low-res inputs to higher resolutions before inference can boost accuracy but requires extra compute

- Failure signatures: Resolution drift: If global model underperforms at certain resolutions vs. single-resolution training, distillation weight may be too low or resolution coverage incomplete; APE not replaced: Model will crash or produce garbage outputs when inference resolution ≠ training resolution; No stop-gradient on teacher: Distillation loss will collapse or destabilize training

- First 3 experiments:
  1. Baseline resolution sensitivity: Train ViTPose with APE on single resolution, test at multiple resolutions. Expect sharp accuracy drop at unseen resolutions.
  2. Resolution drift demonstration: Simulate FL with 3 clients at different resolutions using FedAvg only. Measure global model accuracy at each resolution. Expect degradation vs. homogeneous training.
  3. RAF ablation: Add MRKD (with GPE+LPE) to local training. Compare RAF (FedAvg) vs. Base (FedAvg) across resolutions. Expect +5.4% at 128×96, +3.9% at 512×384.

## Open Questions the Paper Calls Out
- Can the Resolution Adaptive Federated Learning (RAF) framework be effectively generalized to other high-resolution regression tasks beyond human pose estimation?
- Does RAF provide benefits when integrated with Convolutional Neural Network (CNN) backbones, or is its performance tied to the Vision Transformer (ViT) architecture?
- How does RAF perform when resolution heterogeneity is compounded by severe class-level statistical heterogeneity?

## Limitations
- Limited validation of RAF's convergence guarantees in practice; theoretical O(1/T) rate relies on lazy-training assumption not empirically verified
- No ablation on the exact number of resolution levels needed for optimal performance; results suggest 2-3 levels but sensitivity analysis is absent
- Generalization to other regression tasks and different backbone architectures remains untested

## Confidence
- **High**: RAF mitigates resolution drift in FL for pose estimation (Table II accuracy improvements)
- **Medium**: Multi-resolution KD acts as effective regularizer (supported by ablation but mechanism not fully isolated)
- **Low**: RAF maintains FedAvg convergence rate under lazy-training assumption (theoretical claim with no empirical convergence curve validation)

## Next Checks
1. Run RAF on synthetic regression task with known ground truth across resolutions to verify KD prevents overfitting vs. baseline
2. Measure local backbone feature variance across training rounds to test lazy-training assumption required for convergence proof
3. Implement RAF on different backbone (e.g., ConvNeXt) and different regression task (e.g., depth estimation) to test architecture/task generalization