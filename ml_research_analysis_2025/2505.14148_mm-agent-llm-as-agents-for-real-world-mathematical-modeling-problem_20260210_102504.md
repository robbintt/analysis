---
ver: rpa2
title: 'MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem'
arxiv_id: '2505.14148'
source_url: https://arxiv.org/abs/2505.14148
tags:
- modeling
- problem
- task
- mathematical
- momentum
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper formalizes the task of real-world mathematical modeling
  and introduces MM-Agent, an LLM-based agent framework that automates problem analysis,
  model formulation, computational solving, and report generation. To enable evaluation,
  the authors construct MM-Bench, a benchmark of 111 MCM/ICM problems spanning ten
  domains and eight task types.
---

# MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem

## Quick Facts
- arXiv ID: 2505.14148
- Source URL: https://arxiv.org/abs/2505.14148
- Reference count: 40
- This paper introduces MM-Agent, an LLM-based framework for real-world mathematical modeling, and demonstrates 11.88% improvement over human expert solutions on MCM/ICM problems.

## Executive Summary
This paper addresses the challenge of automating real-world mathematical modeling through MM-Agent, a multi-agent framework that decomposes problems, retrieves domain-specific modeling methods, iteratively refines formulations, and generates computational solutions with LaTeX reports. The authors construct MM-Bench, a benchmark of 111 MCM/ICM problems across ten domains and eight task types, to enable evaluation of modeling quality across Analysis, Rigorousness, Practicality, and Result dimensions. MM-Agent employs a hierarchical knowledge library and actor-critic iterative optimization mechanism, achieving superior performance to baselines while maintaining low computational cost. The system also assisted two teams in winning Finalist Awards in MCM/ICM 2025.

## Method Summary
MM-Agent operates through a four-phase pipeline: problem analysis (decomposition into subtasks with dependency DAG construction), mathematical modeling (hierarchical knowledge retrieval via HMML and actor-critic iterative refinement), computational solving (code generation and execution with error feedback), and solution reporting (LaTeX report generation). The Hierarchical Mathematical Modeling Library (HMML) organizes 98 modeling methods across five domains and 17 subdomains using three-tier semantic similarity retrieval. Actor-critic optimization iteratively improves modeling schemes through generation-evaluation cycles. The framework uses mGTE embeddings for retrieval and MLE-Solver for code execution, with evaluation across four dimensions scored 1-10.

## Key Results
- MM-Agent achieves 11.88% improvement over human expert solutions on MCM/ICM problems
- System cost is 36.5% of baselines while maintaining lower runtime (48.2% of baselines)
- Two teams using MM-Agent won Finalist Awards (top 2.0%) in MCM/ICM 2025 among 27,456 teams
- Ablation studies show HMML retrieval and dependency analysis significantly improve modeling rigorousness and result quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical knowledge retrieval improves modeling method selection over flat retrieval.
- Mechanism: The Hierarchical Mathematical Modeling Library (HMML) organizes 98 modeling methods in a three-tier structure (domains → subdomains → method nodes). Given a subtask, depth-first search computes similarity scores at each level, combining node similarity with parent similarity via weighted scoring S(D,N) = ω·Sim(D,N) + (1−ω)·Sim(D,N_parent), enabling both problem-aware and solution-aware retrieval.
- Core assumption: Modeling problems can be mapped to appropriate methods through semantic similarity in a hierarchical knowledge structure.
- Evidence anchors:
  - [abstract] "MM-Agent leverages a hierarchical knowledge library (HMML)... to construct and refine mathematical models"
  - [section 3.2] "HMML encodes 98 high-level modeling schemas... enabling precise task-specific retrieval"
  - [corpus] OR-LLM-Agent (arXiv:2503.10009) addresses similar OR optimization problems but without hierarchical retrieval structure
- Break condition: If task descriptions are ambiguous or if relevant modeling methods are absent from HMML, retrieval quality degrades. No fallback mechanism is described for out-of-distribution problems.

### Mechanism 2
- Claim: Actor-critic iterative optimization produces more rigorous modeling formulations than single-pass generation.
- Mechanism: For each subtask, an actor agent generates an initial modeling scheme M_i^(0). A critic agent evaluates quality and provides targeted feedback F_i^(t). The actor refines the scheme iteratively: M_i^(t+1) = π_θ(M_i^(t), F_i^(t); x_r). This continues for n_r iterations, progressively improving assumption justification and constraint handling.
- Core assumption: LLMs can meaningfully critique and refine mathematical formulations when given structured feedback prompts.
- Evidence anchors:
  - [abstract] "actor-critic iterative optimization mechanism to construct and refine mathematical models"
  - [section 3.3.2] "the critic agent evaluates the quality of the current modeling scheme M_i^(t) and provides targeted feedback"
  - [corpus] Weak corpus evidence—related agent frameworks (Scaling Autonomous Agents via Automatic Reward Modeling, arXiv:2502.12130) use reward modeling rather than structured critic feedback
- Break condition: If critic feedback is superficial or if actor fails to incorporate corrections meaningfully, iteration converges without improvement. Maximum iteration count n_r bounds computation but may terminate prematurely.

### Mechanism 3
- Claim: Task dependency analysis with memory enables coherent multi-subtask solutions.
- Mechanism: The coordinator decomposes problems into subtasks D = {D_1, ..., D_n}, analyzes dependencies to construct a DAG G = (V, E), and executes subtasks sequentially. A memory module H = {(D_i, Q_i)} stores intermediate outputs (modeling scheme M_i, code C_i, results O_i) for downstream tasks to reference.
- Core assumption: Real-world modeling problems can be decomposed into subtasks with identifiable dependencies and sequential execution order.
- Evidence anchors:
  - [section 3.3.1] "the task coordinator agent further leverages task analysis results to construct sequential subtasks with dependency graph"
  - [section 4.3] Ablation shows removing DA (dependency analysis) "significantly reduces MR" (Modeling Rigorousness)
  - [corpus] Exploring Communication Strategies for Collaborative LLM Agents (arXiv:2507.17753) addresses multi-agent coordination but not explicit dependency graphs
- Break condition: If task decomposition produces independent or circular dependencies, or if memory retrieval fails to surface relevant prior outputs, coherence breaks down. No explicit cycle detection or recovery described.

## Foundational Learning

- Concept: **Mathematical Modeling vs. Mathematical Reasoning**
  - Why needed here: The paper explicitly distinguishes modeling (open-ended problem abstraction, assumption design, domain-grounded formulation) from reasoning (solving predefined formulations). MM-Agent targets the former, which lacks ground-truth solutions.
  - Quick check question: Given a problem like "allocate firefighting resources during a forest fire," can you identify what assumptions must be stated before any formulation begins?

- Concept: **Hierarchical Knowledge Organization**
  - Why needed here: HMML's domain/subdomain/method-node structure requires understanding how to organize and traverse knowledge hierarchically. Similarity propagation from child to parent affects retrieval quality.
  - Quick check question: If a subtask matches "Linear Programming" at the method level but poorly matches its parent "Programming Theory," how should the final score be computed?

- Concept: **Actor-Critic Optimization in LLM Systems**
  - Why needed here: Iterative refinement between generation (actor) and evaluation (critic) is central to modeling quality. Understanding prompt design for both roles is critical.
  - Quick check question: What type of feedback should a critic provide that an actor can actually incorporate—numerical scores, textual critique, or both?

## Architecture Onboarding

- Component map:
  - Problem Analysis Phase: Problem Understanding Agent (self-reflection loop) → Coordinator Agent (decomposition) → Task Coordinator Agent (dependency analysis, DAG construction)
  - Mathematical Modeling Phase: HMML Retrieval (DFS similarity search) → Actor Agent (scheme generation) ↔ Critic Agent (evaluation feedback)
  - Computational Solving Phase: Programmer Agent (code generation via MLE-Solver) → Execution Environment (error feedback, nc repair iterations)
  - Solution Reporting Phase: Reporting Agent (outline generation) → LaTeX compilation → Final report assembly
  - Memory Module: Stores H = {(D_i, Q_i)} with Q_i = {M_i, C_i, O_i} for cross-task information transfer

- Critical path:
  1. Input problem F → Problem Understanding → Problem Decomposition → Dependency Analysis (DAG)
  2. For each subtask in topological order: HMML Retrieval → Actor-Critic Iteration (n_r rounds) → Code Generation → Execution → Result Storage in Memory
  3. After all subtasks: Report Outline → LaTeX Generation → Final Report

- Design tradeoffs:
  - **n_r iterations**: More iterations improve rigor but increase cost and latency. Paper uses unspecified default; ablation suggests 2-3 iterations may suffice.
  - **top-K method retrieval**: Larger K provides more options but increases actor context length. Paper retrieves top-K but does not specify K value.
  - **nc code repair attempts**: More attempts handle complex bugs but risk compounding errors. Paper mentions nc iterations without specifying value.
  - **embedding model choice**: Paper uses mGTE; alternatives may change retrieval quality.

- Failure signatures:
  - **Low Modeling Rigorousness (MR) scores**: Likely due to weak dependency analysis or insufficient actor-critic iterations—check DA and HACM ablation results.
  - **Code execution failures**: May indicate missing dataset paths, dependency errors between tasks, or insufficient nc repair budget.
  - **Report incoherence**: Likely memory retrieval failure between subtasks; check if Q_i storage and retrieval paths are correct.
  - **Similar method selection across subtasks**: May indicate HMML retrieval not differentiating task contexts; verify embedding quality and ω weighting.

- First 3 experiments:
  1. **Reproduce ablation on single problem**: Run MM-Agent on one MM-Bench problem with and without HMML to verify retrieval contribution (expected: AE and RBA scores drop without HMML per Figure 4).
  2. **Test HMML retrieval isolation**: Input 5 diverse subtask descriptions, retrieve top-K methods, manually assess relevance—calibrate ω and K if retrieval quality is poor.
  3. **Profile actor-critic iteration convergence**: Run 3 subtasks with n_r = {1, 2, 3, 5} and measure MR score plateau point to determine cost-optimal iteration count.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can mathematical modeling agents be improved to handle higher-order reasoning and interdisciplinary problem-solving more effectively?
- Basis in paper: [explicit] The conclusion states that "challenges remain in higher-order reasoning and interdisciplinary problem-solving" despite MM-Agent's improvements over baselines.
- Why unresolved: Current agent architectures focus on decomposing problems within-domain but lack mechanisms for cross-domain knowledge synthesis and abstract reasoning across disciplinary boundaries.
- What evidence would resolve it: Demonstrated performance gains on benchmark problems requiring integration of concepts from multiple fields (e.g., physics + economics, biology + optimization) with evaluation of cross-domain transfer capabilities.

### Open Question 2
- Question: Can a dedicated mathematical modeling judge LLM provide more consistent and unbiased evaluation than current human-LLM hybrid approaches?
- Basis in paper: [explicit] The paper notes in Broader Impacts: "In future work, we aim to develop a mathematical modeling judge, which could provide more structured, transparent, and consistent evaluations, thereby mitigating annotator bias."
- Why unresolved: Current evaluation relies on subjective human and LLM annotators with varying agreement (Model-Human agreement ranges from 0.5068 to 0.7860 across metrics), particularly low for Result and Bias Analysis.
- What evidence would resolve it: Development and validation of a specialized judge model achieving higher inter-annotator agreement with human experts while reducing evaluation subjectivity and cost.

### Open Question 3
- Question: How can mathematical modeling agents better quantify and integrate psychological, qualitative, and environmental factors that influence real-world systems?
- Basis in paper: [inferred] The case study and ablation results show that Modeling Rigorousness scores remain lower than other metrics (~7.28 vs ~9.00 for Practicality), and the paper acknowledges that "factors such as sudden changes in weather conditions, unexpected crowd dynamics, or minute psychological shifts can be difficult to quantify."
- Why unresolved: Current approaches rely on proxy variables and indirect indicators, but psychological states and environmental factors are inherently subjective and lack standardized quantification methods.
- What evidence would resolve it: Improved modeling scores on problems with significant psychological/environmental components, validated against domain expert assessments of psychological state representations.

## Limitations
- **Evaluation subjectivity**: Human and LLM annotators show varying agreement (0.5068-0.7860), with low consistency on Result and Bias Analysis metrics
- **Out-of-distribution fragility**: HMML retrieval and dependency analysis may fail on problems outside the 98-method scope or with ambiguous decomposition
- **Quantitative gaps**: Modeling Rigorousness scores remain lower (~7.28) than other metrics, indicating challenges with assumption justification and constraint handling

## Confidence
- Method description: High - Clear four-phase pipeline with detailed component specifications
- HMML effectiveness: Medium - Hierarchical retrieval shows improvement but specific hyperparameters (ω, K) unspecified
- Actor-critic iteration: Medium - Iterative refinement described but convergence criteria and optimal iteration count unclear
- Evaluation reliability: Medium - Human-LLM hybrid evaluation shows agreement but significant variance across metrics

## Next Checks
1. Verify HMML library construction with all 98 methods properly organized across domains/subdomains and confirm mGTE embedding model functionality
2. Test actor-critic iteration convergence by running multiple subtasks with varying n_r values to identify optimal iteration count for Modeling Rigorousness
3. Validate memory module by checking Q_i storage/retrieval between dependent subtasks to ensure cross-task information transfer and report coherence