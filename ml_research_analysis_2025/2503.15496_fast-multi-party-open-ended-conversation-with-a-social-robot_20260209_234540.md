---
ver: rpa2
title: Fast Multi-Party Open-Ended Conversation with a Social Robot
arxiv_id: '2503.15496'
source_url: https://arxiv.org/abs/2503.15496
tags:
- robot
- user
- furhat
- conversation
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a conversational system for multi-party interaction
  with a social robot, integrating multimodal perception (voice direction of arrival,
  speaker diarisation, face recognition) with a large language model (LLM) for response
  generation. The system was evaluated on the Furhat robot with 30 participants across
  two scenarios: parallel separate conversations and a shared group discussion.'
---

# Fast Multi-Party Open-Ended Conversation with a Social Robot

## Quick Facts
- arXiv ID: 2503.15496
- Source URL: https://arxiv.org/abs/2503.15496
- Reference count: 40
- Primary result: Multi-party social robot conversation system achieves 92.6% addressee accuracy in parallel settings using multimodal speaker identification

## Executive Summary
This paper presents a conversational system for multi-party interaction with a social robot, integrating multimodal perception (voice direction of arrival, speaker diarisation, face recognition) with a large language model (LLM) for response generation. The system was evaluated on the Furhat robot with 30 participants across two scenarios: parallel separate conversations and a shared group discussion. Results show the system maintained coherent and engaging conversations, achieving 92.6% addressee accuracy in parallel settings and 79.3% in group settings. Face recognition performed reliably (80-94%), but audio-based speaker recognition was limited (18-27%). Participants reported positive engagement and social presence, though technical issues like recognition errors and response latency affected interaction quality.

## Method Summary
The system combines spatial audio processing from a ReSpeaker microphone array with visual face recognition from the Furhat robot camera to identify speakers in multi-party conversations. A Conversation Manager uses GPT-3.5 (in streaming mode) to generate contextually appropriate responses, while a Turn-Taking Module triggers robot responses based on user gaze direction or prolonged silence. The architecture employs Azure Cognitive Services for speech-to-text and speaker identification, with a confidence-weighted fusion mechanism that prioritizes face recognition over voice when conflicts arise. Users must enroll by providing voice samples and face images. The system was evaluated in two scenarios: parallel separate conversations (two users each with the robot) and group conversation (two users sharing one robot conversation).

## Key Results
- Addressee detection accuracy: 92.6% in parallel conversations, 79.3% in group settings
- Speaker recognition accuracy: Face recognition 80-94.7%, voice recognition only 18.4-26.8%
- System latency: Mean 1.35s total, with LLM generation accounting for 0.76s
- Participants reported high engagement and social presence despite technical issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining directional audio with face recognition provides robust speaker identification when audio-based recognition fails in multi-party settings.
- Mechanism: The system uses voice direction of arrival (DoA) from a ReSpeaker microphone array to detect which user is speaking spatially, then fuses this with face recognition from Furhat's camera. When conflicts arise, face recognition takes priority due to higher reliability.
- Core assumption: Users remain in distinct spatial positions with at least 20-degree angular separation from the microphone.
- Evidence anchors:
  - [abstract]: "combines multimodal perception (voice direction of arrival, speaker diarisation, face recognition)"
  - [Section 5.2]: Face recognition achieved 80.0% (group) and 94.7% (parallel) accuracy, while voice recognition achieved only 18.4% and 26.8% respectively.
  - [corpus]: Related work (Addlesee et al., 2024) noted lack of speaker recognition hindered response quality—this system addresses that gap.
- Break condition: If participants move behind the robot or stand closer than 20 degrees apart, DoA accuracy degrades.

### Mechanism 2
- Claim: LLM-based addressee selection maintains conversation coherence by prioritizing the most recent speaker and tracking distinct conversational threads.
- Mechanism: The Conversation Manager prompts GPT-3.5 with conversation history tagged by speaker identity. The model outputs both a response and an explicit addressee selection, enabling the robot to direct gaze and speech appropriately.
- Core assumption: The LLM can correctly infer addressee intent from dialogue context alone, without explicit prosodic or gaze cues from users.
- Evidence anchors:
  - [abstract]: "achieving 92.6% addressee accuracy in parallel settings"
  - [Section 5.1]: Addressee detection was 92.6% correct in parallel but dropped to 79.3% in group settings with overlapping speech.
  - [corpus]: Weak direct corpus evidence on LLM addressee selection; related work focuses on turn-taking models rather than LLM-driven addressing.
- Break condition: Rapid turn-switching or overlapping speech causes the LLM to misattribute context, leading to incorrect addressee selection.

### Mechanism 3
- Claim: Gaze-grounded turn-taking enables non-intrusive robot participation by responding to user eye contact and silence duration.
- Mechanism: The Turn-Taking Module monitors face orientation—if a user looks at the robot after speaking, the robot takes the turn. Prolonged silence also triggers robot response. Interruptions are handled by pausing speech and resuming when the user stops.
- Core assumption: Users signal turn-yielding primarily through gaze rather than prosodic cues or syntax completion.
- Evidence anchors:
  - [Section 3.2]: "The system takes the turn if the robot is looked at by the last speaker or after a prolonged silence."
  - [Section 5.1]: Participants reported that aligned gaze and verbal cues made turn-taking "intuitive and easy to follow."
  - [corpus]: Related work (Skantze 2021, referenced in paper) notes pause-based turn-taking is unreliable—gaze provides complementary signal.
- Break condition: When users don't look at the robot or speak without pause, the robot may miss turn opportunities or respond too late.

## Foundational Learning

- **Speaker Diarisation**:
  - Why needed here: Multi-party conversation requires attributing each utterance to the correct speaker for coherent LLM context.
  - Quick check question: Can you explain why diarisation alone (without absolute identification) is insufficient for maintaining distinct conversation threads?

- **Direction of Arrival (DoA) Estimation**:
  - Why needed here: Microphone arrays provide spatial localization to disambiguate speakers without relying solely on voice characteristics.
  - Quick check question: What happens to DoA accuracy if two speakers are positioned within 20 degrees of each other?

- **LLM Streaming Mode**:
  - Why needed here: Latency is a primary barrier to fluid interaction; streaming reduces perceived delay by returning tokens as generated.
  - Quick check question: Why does streaming help more in parallel conversations than in rapid group discussions?

## Architecture Onboarding

- **Component map**:
  Speaker Awareness -> Transcription -> Diarisation -> Face Tracking -> Turn-Taking -> Conversation Manager -> Interactions
  ReSpeaker mic array -> Azure Speech-to-Text -> Azure Speaker Recognition -> Furhat camera -> Gaze + silence logic -> GPT-3.5 streaming -> Furhat TTS + gaze control

- **Critical path**:
  Audio capture -> DoA detection -> Transcription -> Speaker disambiguation (voice + face fusion) -> LLM context assembly -> Response generation -> Gaze + TTS output. Latency accumulates most at LLM generation (mean 0.76s).

- **Design tradeoffs**:
  - Cloud services (Azure, OpenAI) vs. local processing: Cloud offers accuracy but adds network latency and privacy concerns.
  - Face vs. voice priority: Face recognition is more reliable but requires visual line-of-sight; voice works when faces are occluded.
  - Silence threshold for turn-taking: Shorter thresholds improve responsiveness but risk interrupting users; longer thresholds feel sluggish.

- **Failure signatures**:
  - *Modality conflict*: Robot looks at User A while responding to User B—indicates fusion logic failure.
  - *Unrecognized speaker*: LLM receives "user" label instead of name—diarisation failed or enrollment incomplete.
  - *Response latency >3s*: Check LLM streaming, network, or excessive context length.

- **First 3 experiments**:
  1. **Baseline latency profiling**: Measure end-to-end delay for each module in isolation (transcription, diarisation, LLM, TTS) to identify the bottleneck.
  2. **Modality ablation**: Run conversations with face recognition disabled, then voice recognition disabled, to quantify each modality's contribution to addressee accuracy.
  3. **Turn-taking threshold tuning**: Test different silence durations (0.5s, 1.0s, 1.5s) and gaze-trigger combinations to balance responsiveness vs. interruption rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does multi-party conversation performance scale beyond two users, particularly regarding addressee detection accuracy and turn-taking coherence?
- Basis in paper: [explicit] "Future research should therefore explore larger group settings" (Section 5.4); system only evaluated with exactly two participants.
- Why unresolved: The architecture was designed for two-person interaction; unknown whether LLM context management, speaker diarisation, and gaze-based addressee selection degrade with additional participants.
- What evidence would resolve it: Controlled evaluation with 3–5 participants comparing addressee accuracy, turn-taking success, and perceived coherence against the two-person baseline.

### Open Question 2
- Question: What confidence-weighted multimodal fusion strategies can reduce modality conflicts (e.g., robot looking at one participant while addressing another)?
- Basis in paper: [explicit] "These mismatches highlight the need for confidence-weighted multimodal fusion that can dynamically prioritise the more reliable modality – typically vision – during periods of overlapping speech" (Section 5.2).
- Why unresolved: Current system prioritises face recognition in conflicts but lacks dynamic confidence estimation; optimal fusion mechanism for multi-party settings remains undetermined.
- What evidence would resolve it: Comparative study of fusion approaches (e.g., probabilistic, learned weighting) measuring misalignment rates and user-reported confusion.

### Open Question 3
- Question: How can memory mechanisms be designed so that users perceive personalisation and recall, rather than experiencing the robot as "not remembering" despite architectural capability?
- Basis in paper: [inferred] Participants stated the robot "did not make use of information they had previously shared" even though "the system already included a memory mechanism" (Section 5.3); this gap illustrates a design challenge in LLM-driven systems.
- Why unresolved: Memory exists architecturally but is not consistently surfaced in responses; the interaction between prompt design, retrieval timing, and user perception is unclear.
- What evidence would resolve it: A/B comparison of memory surfacing strategies (e.g., explicit recall phrases vs. implicit context use) with subjective personalisation ratings and objective recall detection by users.

### Open Question 4
- Question: Can prosody-based or prediction-based turn-taking models outperform silence-based turn-taking in fluid multi-party group interactions?
- Basis in paper: [explicit] "The use of silence instead of more sophisticated techniques is justified with the assumption that the users are going to pass the turn through gaze. We plan to experiment with these techniques in the future" (Section 3.2, Turn-Taking Module).
- Why unresolved: Silence-based approach contributed to response latency and missed turn opportunities during rapid shifts; whether more sophisticated models improve fluidity without increasing false interruptions is unknown.
- What evidence would resolve it: Implementation and evaluation of prosodic or predictive turn-taking (e.g., voice activity projection) measuring latency, interruption rate, and perceived responsiveness.

## Limitations

- Voice recognition performance remains a significant bottleneck (18.4-26.8% accuracy), suggesting the multimodal fusion approach compensates for rather than solves the underlying audio recognition problem.
- All evaluation occurred with exactly two participants; the architecture's scalability to larger groups remains unproven.
- The system requires user enrollment (voice samples + face images), which may limit deployment in spontaneous interaction scenarios.

## Confidence

- **High confidence**: The system architecture combining spatial audio, face recognition, and LLM-driven response generation is technically sound and the reported accuracy metrics are plausible given the described methodology.
- **Medium confidence**: The positive subjective feedback from participants (engagement, social presence) is credible but may be influenced by novelty effects common in human-robot interaction studies.
- **Low confidence**: The generalizability of these results to different robot platforms, larger group sizes, or less controlled environments has not been demonstrated.

## Next Checks

1. **Ablation study of recognition modalities**: Systematically disable face recognition and voice recognition in separate trials to quantify each modality's independent contribution to overall addressee accuracy, particularly in overlapping speech conditions.

2. **Cross-robot validation**: Implement the same system architecture on a different social robot platform (e.g., NAO, Pepper, or a custom robot) to test whether the approach generalizes beyond the Furhat embodiment.

3. **Larger group scalability test**: Extend the evaluation to three or four simultaneous users to identify the breaking point of the current architecture and quantify how accuracy degrades with group size.