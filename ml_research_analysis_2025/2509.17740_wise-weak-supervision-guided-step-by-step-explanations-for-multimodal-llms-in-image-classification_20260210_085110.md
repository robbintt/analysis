---
ver: rpa2
title: 'WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs
  in Image Classification'
arxiv_id: '2509.17740'
source_url: https://arxiv.org/abs/2509.17740
tags:
- concept
- reasoning
- concepts
- image
- tree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WISE, a method that reformulates Concept
  Bottleneck Models (CBMs) into Multimodal Chain-of-Thought (MCoT) reasoning chains
  to improve interpretability and accuracy in image classification tasks. WISE uses
  CLIP to score visual salience, constructs Prior Trees from category-typical concepts,
  and builds Affirmation and Elimination Trees for instance-specific reasoning.
---

# WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification

## Quick Facts
- arXiv ID: 2509.17740
- Source URL: https://arxiv.org/abs/2509.17740
- Authors: Yiwen Jiang; Deval Mehta; Siyuan Yan; Yaling Shen; Zimu Wang; Zongyuan Ge
- Reference count: 17
- Primary result: Improves MLLM interpretability by 37% and classification accuracy by up to 2.6% over fine-tuning baselines

## Executive Summary
WISE introduces a novel approach to improving interpretability and accuracy in multimodal image classification by reformulating Concept Bottleneck Models (CBMs) into Multimodal Chain-of-Thought (MCoT) reasoning chains. The method leverages CLIP for visual salience scoring, constructs Prior Trees from category-typical concepts, and builds instance-specific Affirmation and Elimination Trees for step-by-step reasoning. Across ten datasets, WISE demonstrates substantial improvements in both interpretability metrics and classification accuracy while maintaining computational efficiency by dynamically selecting an average of 8 critical concepts per image from a 95% utilized concept bank.

## Method Summary
WISE reformulates CBMs into Multimodal Chain-of-Thought reasoning by using CLIP to score visual salience, constructing Prior Trees from category-typical concepts, and building Affirmation and Elimination Trees for instance-specific reasoning. The method dynamically selects a small set of critical concepts per image (averaging 8) while utilizing 95% of the concept bank, demonstrating both efficiency and generalizability across diverse image classification tasks.

## Key Results
- Improves MLLM interpretability by 37% over baseline approaches
- Achieves up to 2.6% accuracy gains over fine-tuning baselines
- Dynamically selects ~8 critical concepts per image while utilizing 95% of the concept bank

## Why This Works (Mechanism)
WISE works by decomposing complex image classification into interpretable concept-level reasoning chains. The method leverages CLIP's strong visual-text alignment capabilities to identify salient visual regions, then uses these as anchors for constructing hierarchical reasoning trees that mirror human-like step-by-step deduction. By building Prior Trees from category-typical concepts and generating instance-specific Affirmation and Elimination Trees, the system creates transparent reasoning paths that are both explainable and accurate. The weak supervision approach allows the model to learn from noisy or incomplete concept annotations while maintaining high performance.

## Foundational Learning
- **Concept Bottleneck Models (CBMs)**: Why needed - to bridge visual features and semantic concepts for interpretable reasoning; Quick check - verify concept extraction accuracy before reasoning
- **Multimodal Chain-of-Thought (MCoT)**: Why needed - to enable step-by-step interpretable reasoning in multimodal contexts; Quick check - validate each reasoning step independently
- **CLIP-based visual salience scoring**: Why needed - to identify relevant visual regions for concept extraction; Quick check - compare salience scores against human annotations
- **Tree-based reasoning structures**: Why needed - to organize concept relationships hierarchically for systematic reasoning; Quick check - verify tree depth and branching patterns
- **Weak supervision**: Why needed - to learn from noisy or incomplete concept annotations; Quick check - measure annotation noise tolerance
- **Dynamic concept selection**: Why needed - to maintain efficiency while ensuring comprehensive coverage; Quick check - track concept utilization rates

## Architecture Onboarding

**Component Map:** CLIP Vision Encoder -> Visual Salience Scoring -> Concept Extraction -> Prior Tree Construction -> Instance-Specific Tree Generation -> MCoT Reasoning -> Classification

**Critical Path:** The critical path flows from visual feature extraction through salience scoring to concept-based reasoning. CLIP's vision encoder produces embeddings that are scored for salience, which then guide concept extraction. These concepts populate the Prior Tree, from which instance-specific Affirmation and Elimination Trees are generated. The MCoT reasoning chain traverses these trees to produce the final classification decision.

**Design Tradeoffs:** The method trades some computational overhead for interpretability gains. Building and traversing reasoning trees is more computationally intensive than direct classification but provides transparent decision-making. The weak supervision approach accepts some noise tolerance in exchange for reduced annotation burden. Dynamic concept selection optimizes for efficiency but may occasionally miss rare but important concepts.

**Failure Signatures:** Performance degradation may occur when: visual salience scoring fails on domain-specific imagery (e.g., medical or satellite images), concept definitions are ambiguous or overlapping between categories, the Prior Tree structure inadequately captures semantic relationships, or when concept annotations are too noisy for effective weak supervision. The tree-based reasoning may also struggle with highly complex scenes requiring many interdependent concepts.

**First Experiments:** 1) Test on simple binary classification tasks with clear visual concepts; 2) Evaluate concept extraction accuracy on images with known semantic labels; 3) Compare reasoning tree quality against human-annotated reasoning chains on a small validation set.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited evaluation on specialized visual domains (medical imaging, satellite imagery) where visual patterns differ substantially from natural scenes
- Dependence on CLIP-based salience scoring may introduce domain-specific biases affecting reasoning quality
- Concept bank construction assumes effective identification of category-typical concepts, with limited discussion of impact when visual ambiguity exists between categories

## Confidence

**High confidence:** The demonstrated accuracy improvements and interpretability gains on tested datasets; the efficiency of using ~8 concepts per image while leveraging 95% of the concept bank

**Medium confidence:** The generalizability across diverse visual domains; the robustness of reasoning quality under concept ambiguity or noise

**Medium confidence:** The effectiveness of the tree-based reasoning structure in capturing all relevant visual relationships

## Next Checks
1. Test WISE performance on specialized domains (medical imaging, satellite imagery) where visual patterns differ substantially from natural scenes
2. Conduct ablation studies removing CLIP-based salience scoring to quantify its contribution to reasoning quality
3. Evaluate performance with intentionally noisy or incomplete concept annotations to assess robustness to imperfect supervision