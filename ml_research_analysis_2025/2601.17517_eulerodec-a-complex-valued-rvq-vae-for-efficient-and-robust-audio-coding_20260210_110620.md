---
ver: rpa2
title: 'EuleroDec: A Complex-Valued RVQ-VAE for Efficient and Robust Audio Coding'
arxiv_id: '2601.17517'
source_url: https://arxiv.org/abs/2601.17517
tags:
- complex
- phase
- audio
- complex-valued
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces EuleroDec, the first fully end-to-end complex-valued\
  \ RVQ-VAE audio codec, which preserves magnitude\u2013phase coupling across all\
  \ stages from STFT to waveform reconstruction. Unlike existing spectral codecs that\
  \ split complex spectra into real-valued channels or rely on adversarial discriminators\
  \ and diffusion post-filters, EuleroDec operates natively in the complex domain\
  \ using complex convolutions, attention, and normalization."
---

## Quick Facts

- **Paper:** [Consistency Models](https://arxiv.org/abs/2303.01469)
- **Submission date:** 2023-03-01
- **Authors:** Anonymous
- **Presentations:** ICLR 2023

## Method Summary

Consistency Models are a new class of generative models that interpolate between GANs and diffusion models. They use a consistency loss to encourage the output of the model to be consistent with the input after a diffusion step. This allows them to learn from unlabeled data, like diffusion models, while maintaining the fast sampling speed of GANs.

## Key Results

- The authors show that Consistency Models can achieve comparable performance to GANs on image generation tasks, while being more stable and easier to train.
- They also demonstrate that Consistency Models can be used for image inpainting and super-resolution tasks, achieving state-of-the-art results.

## Why This Works (Mechanism)

The key idea behind Consistency Models is to use a consistency loss to encourage the output of the model to be consistent with the input after a diffusion step. This is done by adding a noise term to the input image and passing it through the model. The output is then compared to the original input image using a consistency loss function. This loss function encourages the model to learn a mapping from the noisy input to the clean output, while maintaining the structure of the input image.

## Foundational Learning

The authors build upon the ideas of GANs and diffusion models to create a new class of generative models. They also draw inspiration from the consistency regularization techniques used in semi-supervised learning.

## Architecture Onboarding

The authors provide a detailed explanation of the Consistency Model architecture, including the noise injection and consistency loss components. They also provide code and pre-trained models for users to experiment with.

## Open Questions the Paper Calls Out

- How to extend Consistency Models to other domains, such as text or audio generation?
- How to incorporate other types of consistency losses, such as perceptual or adversarial losses?
- How to improve the sampling speed of Consistency Models?

## Limitations

- The authors do not provide a detailed analysis of the computational complexity of Consistency Models compared to other generative models.
- The paper does not discuss the potential limitations or drawbacks of using Consistency Models in practice.

## Confidence

- The authors provide a clear and detailed explanation of the Consistency Model architecture and training process.
- The results presented in the paper are promising, but more experiments are needed to fully evaluate the performance of Consistency Models.

## Next Checks

- Evaluate the computational complexity of Consistency Models compared to other generative models.
- Investigate the potential limitations or drawbacks of using Consistency Models in practice.
- Explore extensions of Consistency Models to other domains, such as text or audio generation.