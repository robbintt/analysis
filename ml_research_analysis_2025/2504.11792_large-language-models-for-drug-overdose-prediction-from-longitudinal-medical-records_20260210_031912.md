---
ver: rpa2
title: Large Language Models for Drug Overdose Prediction from Longitudinal Medical
  Records
arxiv_id: '2504.11792'
source_url: https://arxiv.org/abs/2504.11792
tags:
- overdose
- data
- medical
- patient
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated large language models (LLMs) for predicting
  drug overdose risk from longitudinal medical records. GPT-4o was tested in zero-shot
  and fine-tuned settings using structured insurance claims data, with predictions
  made for 7-day and 30-day overdose risk.
---

# Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records

## Quick Facts
- arXiv ID: 2504.11792
- Source URL: https://arxiv.org/abs/2504.11792
- Reference count: 25
- LLMs achieved 84.53 F1 score for 7-day overdose prediction, outperforming traditional ML models

## Executive Summary
This study evaluated large language models (LLMs) for predicting drug overdose risk from longitudinal medical records. GPT-4o was tested in zero-shot and fine-tuned settings using structured insurance claims data, with predictions made for 7-day and 30-day overdose risk. Performance was compared against traditional machine learning models (Random Forest and XGBoost). LLMs demonstrated strong zero-shot predictive ability, particularly when provided with detailed medical descriptions. Fine-tuned LLMs outperformed traditional models when using aggregated visit statistics, achieving up to 84.53 F1 score for 7-day predictions. The results highlight LLMs' potential as clinical decision support tools for overdose risk prediction.

## Method Summary
The study used Merative MarketScan Research Databases (2020-2022) to construct patient cohorts for drug overdose prediction. Cases were identified using ICD-10 codes T36-T50 (excluding adverse effects/underdosing) and specific ICD-9 codes, while controls included exposed patients with opioid/stimulant prescriptions or substance use disorder diagnoses. The dataset was split into 900 training, 900 validation, and 900 test samples with a 1:2 case:control ratio. Four prompt formats were tested: detailed descriptive, detailed medical code, summarized descriptive, and summarized medical code. GPT-4o was evaluated in zero-shot mode and after fine-tuning, with results compared to Random Forest and XGBoost baselines trained on 3,700 aggregated features.

## Key Results
- Fine-tuned LLM achieved 84.53 F1 score for 7-day overdose prediction, outperforming XGBoost baseline (78.92 F1)
- Zero-shot LLM with detailed descriptions correctly identified over half of overdose cases in prospective cohorts
- Diagnosis history provided the most predictive signal, with procedures and prescriptions offering incremental recall gains

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning LLMs on aggregated statistical summaries of patient histories can outperform traditional ML models trained on identical feature representations. Pre-trained LLMs bring prior biomedical knowledge and pattern recognition capabilities that, when aligned to the task via fine-tuning, enable more nuanced decision boundaries than tree-based ensembles operating solely on the tabular representation. Core assumption: The LLM's pre-training corpus includes sufficient biomedical and clinical text to inform drug-related risk patterns. Evidence anchors: Fine-tuned LLM achieved F1 score of 84.53 for 7-day window compared to 78.92 for XGBoost; fine-tuning achieves approximately 6-point improvement over best baseline.

### Mechanism 2
Zero-shot LLMs can identify overdose risk by leveraging natural language descriptions of diagnoses and procedures, rather than requiring structured feature engineering. LLMs map clinical text descriptions to latent risk concepts learned during pre-training, enabling inference without gradient updates. Core assumption: The mapping from clinical descriptions to overdose risk is sufficiently represented in pre-training data. Evidence anchors: Zero-shot LLM correctly identified over half of overdose cases; zero-shot with detailed descriptions achieved 56% recall at 30-day window.

### Mechanism 3
Diagnosis history provides the most predictive signal for overdose risk, with procedures and prescriptions offering incremental recall gains. Comorbid conditions (e.g., anxiety, hypertension) correlate with overdose risk; LLMs weight these diagnostic patterns more effectively than isolated prescription counts. Core assumption: Diagnostic codes capture underlying risk factors that prescriptions alone may miss. Evidence anchors: Diagnosis-only achieved F1 of 50.97; combining all three fields improved recall to 51.33%.

## Foundational Learning

- **Longitudinal Claims Data Structure**: Why needed here: The model operates on temporal sequences of diagnoses, procedures, and prescriptions linked by patient ID and encounter ID. Quick check question: Given three tables (diagnosis, procedure, prescription) with patient and encounter IDs, how would you construct a chronologically ordered patient history?

- **Zero-Shot vs. Fine-Tuned Inference**: Why needed here: The paper explicitly compares these paradigms; understanding when each applies is critical for deployment decisions. Quick check question: If you have 100 labeled patients and a pre-trained LLM, would you use zero-shot or fine-tuning? What if you have 10,000?

- **ICD Coding Systems for Overdose Identification**: Why needed here: Case cohort construction depends on correctly filtering ICD-9/ICD-10 codes T36–T50 while excluding adverse effects. Quick check question: A patient has code T40.2X5 (adverse effect). Should they be included in the case cohort? Why or why not?

## Architecture Onboarding

- **Component map**: Data extraction layer (MarketScan claims → patient-level longitudinal records) -> Cohort construction (case/control split with prediction window cutoffs) -> Preprocessing (aggregation by encounter ID, chronological sorting, feature vector construction) -> Prompt serialization (JSON/text conversion in 4 formats) -> Model layer (GPT-4o with optional fine-tuning) -> Evaluation (7-day and 30-day prediction windows)

- **Critical path**: Cohort selection → Cutoff date assignment → Feature aggregation → Prompt formatting → Model inference → Threshold tuning

- **Design tradeoffs**: Detailed visit descriptions improve zero-shot recall but increase token cost ($0.0137/instance vs. $0.0031 for summaries); aggregated summaries with fine-tuning yield best performance but require labeled training data; medical codes reduce token length by ~25% with modest performance drop; more encounters (up to 30) improve context but beyond that performance degrades due to attention dilution

- **Failure signatures**: Zero-shot over-predicts overdose for exposed controls (73.67% accuracy vs. 88.67% for non-exposed); claims data lag prevents real-time prediction; long prompts (>6000 tokens) reduce model focus on critical signals

- **First 3 experiments**:
  1. Baseline replication: Train XGBoost on aggregated features (3,700 dimensions) with 900 training samples. Verify F1 ≈ 78–79 for 7-day window.
  2. Zero-shot probe: Format 30 patient histories as detailed descriptive JSON; query GPT-4o (temp=0.5) for overdose risk. Expect recall ~51–56%.
  3. Fine-tuning comparison: Fine-tune GPT-4o on summarized feature vectors (same 3,700 features as baseline). Target F1 > 84 on 7-day test set. If below baseline, check prompt formatting and label balance.

## Open Questions the Paper Calls Out

- Would incorporating laboratory data improve LLM-based drug overdose prediction performance? Laboratory data was unavailable in the Merative MarketScan dataset used in this study, preventing direct evaluation of its contribution.

- Would increasing training sample size beyond 900 patients significantly enhance fine-tuned LLM predictive capabilities for overdose risk? Fine-tuning costs constrained dataset size, leaving the marginal benefit of larger training sets undetermined.

- Can incorporating minimal supplementary context alongside medical codes enhance interpretability and predictive accuracy? Only two extremes were tested—full descriptions vs. raw codes—without exploring hybrid approaches.

- How do LLMs compare to deep learning sequence models specifically designed for longitudinal medical data in overdose prediction? The study did not include neural sequence models as baselines, leaving their relative performance unknown.

## Limitations

- External validity concerns: Results based on commercial insurance claims (2020-2022) may not generalize to Medicaid, Medicare, or uninsured populations with different demographic distributions.

- Temporal generalizability issues: Drug overdose patterns evolve rapidly, so LLM performance may degrade as drug mixtures and prescribing patterns change beyond the 2020-2022 training window.

- Token constraints: Detailed visit descriptions require up to 6,000+ tokens per patient, approaching GPT-4o's 128K limit when scaled to population sizes, creating deployment bottlenecks.

## Confidence

- **High confidence**: Fine-tuned LLM outperforming traditional ML on aggregated features (84.53 vs 78.92 F1 for 7-day prediction) - directly measured and statistically significant within this dataset.

- **Medium confidence**: Zero-shot LLM correctly identifying >50% of overdose cases - promising but limited by small prospective cohort validation and potential selection bias.

- **Medium confidence**: Diagnosis history as primary predictive signal - supported by ablation study but weak comparative literature foundation.

## Next Checks

1. **Temporal validation**: Test LLM performance on data from 2023-2024 to assess degradation from evolving drug patterns and prescribing trends.

2. **Population generalizability**: Evaluate models on Medicaid/Medicare claims to verify performance across different payer types and demographic distributions.

3. **Real-time feasibility**: Measure prediction latency and cost for processing 10,000+ patient histories daily using detailed vs. summarized prompt formats to assess clinical deployment viability.