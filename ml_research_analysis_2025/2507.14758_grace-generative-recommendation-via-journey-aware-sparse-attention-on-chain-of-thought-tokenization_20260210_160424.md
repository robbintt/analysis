---
ver: rpa2
title: 'GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought
  Tokenization'
arxiv_id: '2507.14758'
source_url: https://arxiv.org/abs/2507.14758
tags:
- item
- attention
- recommendation
- tokenization
- grace
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GRACE introduces a generative recommendation framework that integrates
  Chain-of-Thought tokenization with journey-aware sparse attention to address limitations
  in multi-behavior sequential recommendation. By combining semantic tokens with structured
  product knowledge graph attributes, it enables interpretable and behavior-aligned
  generation.
---

# GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization

## Quick Facts
- arXiv ID: 2507.14758
- Source URL: https://arxiv.org/abs/2507.14758
- Authors: Luyi Ma; Wanjia Zhang; Kai Zhao; Abhishek Kulkarni; Lalitesh Morishetti; Anjana Ganesh; Ashish Ranjan; Aashika Padmanabhan; Jianpeng Xu; Jason Cho; Praveen Kanumala; Kaushiki Nag; Sumit Dutta; Kamiya Motwani; Malay Patel; Evren Korpeoglu; Sushant Kumar; Kannan Achan
- Reference count: 40
- Key outcome: Achieves up to +106.9% HR@10 and +106.7% NDCG@10 improvement on Home domain and +22.1% HR@10 on Electronics domain with up to 48% reduction in attention computation for long sequences

## Executive Summary
GRACE introduces a generative recommendation framework that integrates Chain-of-Thought tokenization with journey-aware sparse attention to address limitations in multi-behavior sequential recommendation. By combining semantic tokens with structured product knowledge graph attributes, it enables interpretable and behavior-aligned generation. The Journey-aware Sparse Attention mechanism selectively attends to compressed, intra-, inter-, and current-context segments, significantly reducing computational overhead while maintaining expressiveness. Experiments on real-world Walmart datasets show GRACE outperforms state-of-the-art baselines, achieving substantial improvements across multiple behavior prediction tasks.

## Method Summary
GRACE combines Chain-of-Thought (CoT) tokenization with Journey-Aware Sparse Attention (JSA) to enable efficient multi-behavior sequential recommendation. The method uses RQ-VAE for hierarchical semantic tokenization of item embeddings, then augments these with deterministic CoT tokens derived from product knowledge graph attributes (Product Type, Price Band, Brand). The JSA mechanism decomposes attention into four strategies—block compression, top-N intra-journey selection, inter-journey transitions, and current-context window—aggregated through learned gates. This allows GRACE to balance fine-grained and coarse-grained context while reducing attention computation by up to 48% on long sequences.

## Key Results
- Achieves up to +106.9% HR@10 and +106.7% NDCG@10 improvement on Home domain
- Achieves +22.1% HR@10 improvement on Electronics domain
- Reduces attention computation by up to 48% for long sequences
- Outperforms state-of-the-art baselines across target behavior prediction, behavior-specific, and behavior-item tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Chain-of-Thought (CoT) tokenization improves recommendation accuracy by providing explicit, deterministic attribute information alongside semantic tokens.
- **Mechanism:** CoT tokens (Product Type, Price Band, Brand) are inserted between behavior tokens and semantic tokens, forming a hierarchical path from coarse-grained to fine-grained information that constrains the generative search space.
- **Core assumption:** Users' shopping decisions follow a navigational hierarchy from high-level categories to specific item details, and this structure can be exploited during token generation.
- **Evidence anchors:**
  - [abstract] "encodes user-item interactions with explicit attributes from product knowledge graphs (e.g., category, brand, price) over semantic tokenization, enabling interpretable and behavior-aligned generation"
  - [section 3.3.1] Removing all CoT tokens causes >50% drop in NDCG@10 compared to GRACE; "w/o CoT & JSA" and "w/o CoT" variants equal MBGen baseline performance
  - [figure 5] Co-occurrence heatmap shows CoT tokens narrow search space, creating concentrated activation zones (e.g., PT=11 aligned with L1=37)
  - [corpus] BLADE paper confirms heterogeneity of user behaviors creates modeling challenges that structured representations may address

### Mechanism 2
- **Claim:** Journey-Aware Sparse Attention (JSA) reduces computational cost while maintaining expressiveness by selectively attending to relevant token segments across multiple temporal scales.
- **Mechanism:** JSA decomposes attention into four trainable components—(1) block compression via MLP, (2) top-N intra-journey block selection based on importance scores, (3) inter-journey transitions using coarse-grained tokens, (4) truncated window for current context—combined through learned gates.
- **Core assumption:** User interaction sequences contain multiple latent "journeys" (coherent intent segments) that can be meaningfully separated and differentially weighted.
- **Evidence anchors:**
  - [abstract] "GRACE also reduces attention computation by up to 48% with long sequences"
  - [table 4] Activated parameters reduced by 32% at length 50, 48% at length 200 compared to full attention
  - [section 3.3.2] Removing compression and intra-journey selection causes largest NDCG drops (3.16 vs 9.92); removing inter-journey hurts behavior-specific tasks (7.30 vs 13.01)
  - [corpus] No direct corpus evidence on JSA specifically; Native Sparse Attention (NSA) cited as inspiration but not evaluated in recommendation context

### Mechanism 3
- **Claim:** Combining CoT tokenization with JSA enables multi-behavior modeling that balances target behavior prediction with behavior-specific and behavior-item tasks.
- **Mechanism:** CoT tokens provide deterministic constraints for target behavior prediction while JSA's multi-scale attention captures both fine-grained intra-journey patterns and coarse inter-journey transitions, with learned gates balancing task objectives.
- **Core assumption:** Different prediction tasks benefit from different attention scales—target behaviors need compressed/selected context, while behavior-specific tasks need inter-journey transitions.
- **Evidence anchors:**
  - [section 3.3.1] "Without JSA, fewer CoT tokens lead to better NDCG scores in the behavior-specific and behavior-item tasks, which is against the trend of the target behavior task... the existence of JSA balances the target behavior prediction and the other two tasks well"
  - [table 5] GRACE improves ATC +62.5% and Click +16.8% on Home; Like behavior improves from 9.00 to 16.97 on Electronics
  - [corpus] Multi-behavior sequential modeling papers (BLADE, Transition-Aware GAT) confirm diverse behaviors require heterogeneous modeling strategies

## Foundational Learning

- **Concept: Residual Quantization (RQ-VAE) for Semantic Tokenization**
  - **Why needed here:** GRACE builds on RQ-VAE to generate hierarchical semantic tokens from item embeddings; understanding how residuals capture coarse-to-fine granularity is essential for debugging token quality.
  - **Quick check question:** Given a 128-dim item embedding, can you explain how RQ-VAE produces a 3-level token sequence and what each level represents?

- **Concept: Sparse Attention Patterns and Block-Based Computation**
  - **Why needed here:** JSA's efficiency gains depend on understanding how block compression, importance scoring, and windowed attention reduce the effective attention matrix size.
  - **Quick check question:** If sequence length L=200, block size l=10, stride d=5, how many blocks are compressed in the multi-journey compression step?

- **Concept: Product Knowledge Graph Traversal**
  - **Why needed here:** CoT tokens are derived from PKG attribute paths; understanding how hierarchical attributes (category → brand → price) form reasoning chains is critical for extending tokenization to new domains.
  - **Quick check question:** How would you construct a CoT token sequence for an item with attributes: category="Electronics > TVs", brand="Samsung", price="$899"?

## Architecture Onboarding

- **Component map:** Input: User behavior-item sequence [(v1,b1), (v2,b2), ...] → Tokenization (Semantic ID via RQ-VAE + K-means, CoT tokens from PKG) → Combined token sequence → Encoder (6 layers with JSA) → Decoder (6 layers) → Output: <BOS> → behavior token → CoT tokens → semantic tokens → <EOS> → Inference with beam search
- **Critical path:**
  1. PKG attribute extraction → CoT token vocabulary construction (pre-computation)
  2. RQ-VAE training on item embeddings → semantic token assignment (pre-computation)
  3. JSA gate initialization and training (learned end-to-end)
  4. Behavior prediction first, then item token generation
- **Design tradeoffs:**
  - **Window size w (current-journey):** w=10 balances local context vs computation; w>20 yields diminishing returns (Figure 4a)
  - **Top-N blocks (intra-journey):** N=3 optimal; N<3 misses context, N>4 introduces noise (Figure 4b)
  - **Beam width:** 10 sufficient; larger beams don't improve performance significantly (Figure 4c)
  - **CoT token selection:** Removing BRAND hurts less than removing all CoT; PRICE and PT are higher-value attributes (Table 3)
- **Failure signatures:**
  - **CoT without JSA:** Performance drops on behavior-specific tasks; model cannot balance multi-task learning
  - **JSA without CoT:** NDCG@10 drops to 4.84 (vs 9.92) on target behavior prediction
  - **Gate collapse:** If all gates converge to ~0.25, sparse attention provides no selective benefit
  - **Token collision:** Random level-3 tokens assigned to prevent semantic ID collisions (implementation detail)
- **First 3 experiments:**
  1. **Tokenization ablation:** Train GRACE with semantic tokens only (no CoT) vs full CoT tokens; measure HR@10/NDCG@10 gap on target behavior prediction to quantify CoT contribution.
  2. **JSA component ablation:** Remove each attention strategy one at a time (compression, intra, inter, current); identify which component drives efficiency vs accuracy tradeoffs.
  3. **Sequence length scaling:** Evaluate activated parameters and HR@10 at sequence lengths 50, 100, 200; verify 32-48% computation reduction claim holds with your data distribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does GRACE's recommendation accuracy scale when applied to extremely long user histories (e.g., >500 interactions) compared to the 50-item truncation used in evaluation?
- **Basis in paper:** [explicit] The authors state that "All item sequences are truncated to 50 for training and evaluating," while noting computational efficiency is tested up to length 200.
- **Why unresolved:** It is unclear if the Journey-aware Sparse Attention mechanism maintains high expressiveness and accuracy when compressing significantly longer, denser interaction sequences, or if valuable historical signals are lost.
- **What evidence would resolve it:** Reporting Hit Rate and NDCG metrics on the Home and Electronics datasets using untruncated sequence lengths or a significantly higher truncation window (e.g., 200–500 items).

### Open Question 2
- **Question:** Can the GRACE framework be modified to effectively model negative feedback behaviors, such as "Remove-from-cart," where it currently underperforms?
- **Basis in paper:** [explicit] Table 5 shows that GRACE scores 27.03 NDCG@10 for "Remove" behaviors, performing worse than the MBGen baseline (33.67).
- **Why unresolved:** The generative objective appears optimized for positive intent (add-to-cart), failing to capture the distinct patterns or penalize items associated with negative retraction behaviors.
- **What evidence would resolve it:** An analysis of attention weights for negative behaviors or the integration of a contrastive loss specifically designed to separate "Add" and "Remove" token trajectories.

### Open Question 3
- **Question:** How sensitive is the Chain-of-Thought (CoT) tokenization to the hierarchical ordering of attributes, and is the [Product Type, Price, Brand] sequence universally optimal?
- **Basis in paper:** [inferred] The paper constructs CoT tokens based on a specific "descending order of scope," assuming a fixed user reasoning path, but does not ablate this ordering.
- **Why unresolved:** Users may reason via Brand first in some domains (e.g., Electronics) but via Category in others (e.g., Home); a fixed hierarchy may bias the model incorrectly.
- **What evidence would resolve it:** Ablation studies comparing NDCG scores across different attribute permutations (e.g., [Brand, Price, Type]) for both the Home and Electronics domains.

## Limitations

- **PKG Attribute Dependency:** Performance critically depends on quality and completeness of product knowledge graph attributes, degrading when metadata is sparse or inconsistent.
- **JSA Journey Segmentation:** The assumption of coherent "journeys" within user interaction sequences is intuitive but not empirically validated, potentially introducing artificial segmentation.
- **Cross-Domain Generalization:** Strong performance on e-commerce domains may not transfer to domains with different interaction patterns or less structured metadata.

## Confidence

**High Confidence:**
- CoT tokenization improves target behavior prediction (50%+ NDCG@10 drops without CoT)
- JSA reduces attention computation (32-48% parameter reduction verified in Table 4)
- Overall HR@10/NDCG@10 improvements over baselines on both datasets

**Medium Confidence:**
- JSA maintains expressiveness while reducing computation (component ablations show balanced task performance)
- CoT tokens create interpretable generation paths (heatmap visualization shows concentrated activation zones)
- Multi-behavior modeling benefits from combined CoT+JSA approach (task-specific performance trends observed)

**Low Confidence:**
- The exact contribution of each JSA component to efficiency vs accuracy (block size/stride parameters missing)
- Generalization to domains with different interaction patterns (only e-commerce tested)
- Optimal hyperparameter settings for diverse recommendation scenarios (window size, top-N values shown but not justified for all contexts)

## Next Checks

1. **Domain Transferability Test:** Evaluate GRACE on non-e-commerce datasets (e.g., movie ratings, music listening history) where PKG attributes are either absent or structurally different to assess generalization limits.

2. **Ablation Study with Missing Metadata:** Systematically remove or corrupt PKG attributes to quantify how performance degrades under realistic metadata sparsity conditions, measuring both accuracy and computational efficiency impacts.

3. **Journey Segmentation Analysis:** Visualize and analyze the actual "journeys" identified by JSA compression on sample user sequences, comparing them against ground truth intent changes or time-based segmentation to validate the segmentation quality.