---
ver: rpa2
title: 'pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch
  Normalization for Class-Imbalanced Data'
arxiv_id: '2511.18066'
source_url: https://arxiv.org/abs/2511.18066
tags:
- federated
- class
- adaptation
- client
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces pFedBBN, a federated learning framework that
  addresses class imbalance and domain shifts in test-time adaptation. The core innovation
  is a class-wise adaptive normalization module that maintains per-class statistics
  to prevent majority-class bias during unsupervised adaptation, combined with a confidence-filtered
  knowledge distillation approach.
---

# pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch Normalization for Class-Imbalanced Data

## Quick Facts
- arXiv ID: 2511.18066
- Source URL: https://arxiv.org/abs/2511.18066
- Reference count: 40
- The paper introduces pFedBBN, a federated learning framework that addresses class imbalance and domain shifts in test-time adaptation, achieving 72.41% and 73.88% accuracy on CIFAR-10-C and CIFAR-100-C respectively under severe non-IID conditions with Dirichlet parameter 0.005.

## Executive Summary
This paper introduces pFedBBN, a federated learning framework designed to tackle the challenges of class imbalance and domain shifts in test-time adaptation. The key innovation is a class-wise adaptive normalization module that maintains per-class statistics to prevent majority-class bias during unsupervised adaptation, combined with a confidence-filtered knowledge distillation approach. The framework also introduces a privacy-preserving similarity-based aggregation strategy using balanced batch normalization statistics to enable personalized client collaboration. Experimental results on CIFAR-10-C and CIFAR-100-C demonstrate significant improvements over state-of-the-art federated learning and test-time adaptation methods, particularly in improving minority-class performance and robustness to distribution shifts.

## Method Summary
pFedBBN is a federated test-time adaptation framework that addresses class imbalance and domain shifts. It replaces standard batch normalization with a Balanced Batch Normalization (BBN) module that tracks per-class feature statistics using pseudo-labels and fuses them into balanced global estimates. Local adaptation employs a teacher-student distillation framework with confidence-filtered pseudo-labels and consistency regularization, updating only the affine parameters of the normalization layers. Personalized aggregation uses BBN statistics to compute pairwise client distances and derive collaboration weights for weighted model aggregation, enabling privacy-preserving and domain-aware federated collaboration.

## Key Results
- pFedBBN achieves 72.41% accuracy on CIFAR-10-C and 73.88% on CIFAR-100-C under severe non-IID conditions (Dirichlet parameter 0.005).
- The framework significantly improves minority-class performance compared to state-of-the-art federated learning and test-time adaptation methods.
- Experimental results demonstrate robustness to distribution shifts and superior handling of class imbalance compared to standard batch normalization approaches.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Per-class normalization statistics (Balanced Batch Normalization) mitigate prediction bias caused by majority-class dominance in class-imbalanced data streams.
- Mechanism: The method replaces standard batch normalization with a module that maintains running mean $\mu_k^{(t)}$ and variance $\sigma_{k}^{2,(t)}$ estimates for each class $k$ using pseudo-labels $\hat{c}_i$ (Eq. 1-3). It then computes balanced global statistics by averaging these per-class estimates (Eq. 4: $\mu^{(t)} = \frac{1}{K}\sum_{k=1}^K \mu_k^{(t)}$). This gives equal weight to minority and majority class feature distributions during normalization.
- Core assumption: The model's pseudo-labels $\hat{c}_i$ (derived from a teacher model) are sufficiently accurate to assign features to the correct class-wise statistics buffers.
- Evidence anchors:
  - [abstract] "balanced batch normalization (BBN) module replaced conventional BN to track per-class feature statistics using pseudo-labels and fuses them into balanced global estimates, mitigating majority-class bias..."
  - [Section 3.1.1] Describes equations for updating per-class statistics (Eq. 1-3) and their balanced fusion (Eq. 4).
  - [corpus] Evidence for this specific class-wise mechanism in federated TTA is weak in the provided corpus. One neighbor ("Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics") analyzes BN statistics but not the class-wise variant.
- Break condition: If pseudo-label accuracy degrades significantly (e.g., under severe domain shift or extreme class imbalance), features will be assigned to incorrect class buffers, corrupting the statistics and potentially worsening bias.

### Mechanism 2
- Claim: Confidence-filtered self-distillation with a frozen source model anchor stabilizes unsupervised adaptation and prevents catastrophic forgetting.
- Mechanism: A teacher-student framework is used. The teacher model $f_t$ provides pseudo-labels. A distillation loss $L_{KD}$ (Eq. 5) updates the student $f_s$ *only* on samples where the teacher's prediction entropy $H(p^{(T)})$ is below a threshold $\delta$. Additionally, a consistency regularization loss $L_{CR}$ (Eq. 6) penalizes divergence of the teacher's predictions from the fixed source model $f_{src}$. Only the affine parameters of the student's normalization layers are updated.
- Core assumption: High-confidence predictions from the teacher model are more likely to be correct, and the source model's behavior serves as a reliable anchor for the source domain.
- Evidence anchors:
  - [abstract] "...confidence-filtered knowledge distillation approach."
  - [Section 3.1.2] Defines $L_{KD}$ using an indicator function on entropy (Eq. 5) and $L_{CR}$ against the source model (Eq. 6).
  - [corpus] FedCTTA (arXiv:2505.13643) and other TTA papers (DATTA, SNAP) address forgetting and stability but use different mechanisms like memory banks or sparse updates. The specific entropy-filtered distillation anchor is a key contribution of this paper.
- Break condition: If the domain shift is so large that the teacher's high-confidence predictions are consistently wrong (high-confidence errors), the distillation will reinforce incorrect knowledge. If the source model's representations are irrelevant to the target domain, the consistency loss may overly constrain adaptation.

### Mechanism 3
- Claim: Similarity-based aggregation using Balanced Batch Normalization statistics enables personalized, privacy-preserving, and domain-aware federated collaboration.
- Mechanism: After local adaptation, clients compute a pairwise distance $D_{ij}$ based on the similarity of their BBN layer mean and variance vectors (Eq. 7). A collaboration weight matrix $W_{ij}$ is derived via softmax (Eq. 8), and each client aggregates a personalized model $\theta_{agg}^{(i)} = \sum_{j=1}^N W_{ij} \theta^{(j)}$ (Eq. 9). This allows clients in similar domains to reinforce each other.
- Core assumption: The BBN statistics (mean and variance vectors) serve as a valid and privacy-preserving proxy for the client's data distribution and domain characteristics.
- Evidence anchors:
  - [abstract] "...privacy-preserving similarity-based aggregation strategy using balanced batch normalization statistics..."
  - [Section 3.2.1-3.2.3] Details the distance metric $D_{ij}$ (Eq. 7), weight matrix $W$ (Eq. 8), and aggregation (Eq. 9). Figure 5 shows clusters forming based on these statistics.
  - [corpus] FedCTTA ("similarity-aware aggregation based on model output distributions") and pFedDSH use different signals (output distributions, sub-hypernetworks) for aggregation.
- Break condition: If BBN statistics are manipulated (e.g., adversarial clients) or are insufficient to capture the nuances of the domain (e.g., domains with similar low-order statistics but different semantic content), the aggregation could be misdirected.

## Foundational Learning

### Concept: Batch Normalization (BN) Statistics as Distribution Proxies
- Why needed here: The paper's core aggregation and adaptation mechanism relies on using the mean and variance computed by normalization layers as a proxy for the data distribution. Understanding how BN statistics capture distributional information is crucial.
- Quick check question: In a standard CNN, if you feed a batch of images from a new domain through the model, what happens to the running mean/variance statistics in the Batch Normalization layers at inference time when they are *not* updated?

### Concept: Non-IID Data and Dirichlet Distribution
- Why needed here: The experiments simulate class imbalance using a Dirichlet distribution. Understanding how the concentration parameter ($\delta$ or $\alpha$) controls the degree of class imbalance and data heterogeneity across clients is key to interpreting the results.
- Quick check question: A Dirichlet parameter of 0.005 (used for "severe" imbalance) results in what kind of class distribution across clients compared to a parameter of 0.1?

### Concept: Teacher-Student Knowledge Distillation
- Why needed here: The local adaptation phase uses this paradigm. The teacher provides guidance (pseudo-labels) for the student to learn, and the process involves specific losses and update rules.
- Quick check question: In a typical self-training setup with knowledge distillation, why is the teacher's model often an exponential moving average (EMA) of the student's weights, or a fixed copy?

## Architecture Onboarding

### Component map
Client-Side BBN Module -> Local Adaptation Engine -> Server-Side/Decentralized Aggregation Logic

### Critical path
(1) Initialize clients with source model and BBN layers -> (2) For each test batch, update per-class stats and run student update -> (3) Periodically, share BBN stats, compute similarity, aggregate model, and distribute personalized models.

### Design tradeoffs
- **BBN vs. Standard BN**: BBN adds complexity (K times the statistic buffers) and relies on pseudo-labels. Standard BN is simpler but fails under imbalance (as shown in results).
- **Personalized vs. Global Aggregation**: Personalized aggregation based on BBN similarity handles heterogeneity better but prevents a single unified global model.
- **Confidence Threshold $\delta$**: A strict threshold prevents noise but may ignore too many samples; a loose threshold allows noise. This is a critical hyperparameter.

### Failure signatures
- **Catastrophic drop in minority class performance**: Pseudo-labels may be failing; check teacher's confidence on minority class samples.
- **Collaboration weight matrix becomes uniform ($W_{ij} \approx 1/N$)**: BBN statistics may not be sufficiently discriminative between clients, or the temperature $\tau$ is too high.
- **Model diverges during local adaptation**: Consistency loss weight might be too low, or the learning rate for BN affine parameters too high.

### First 3 experiments
1. **BBN-only vs. Standard BN Baseline**: Take a pre-trained model. Apply pFedBBN's local BBN adaptation (Mechanism 1) against a standard TENT-style BN update on a held-out, class-imbalanced test set (e.g., CIFAR-10-LT) without federated aggregation. Goal: Isolate and confirm the bias mitigation effect of per-class statistics.
2. **Pseudo-label Accuracy Analysis**: During local adaptation, log the accuracy of the pseudo-labels used for updating BBN statistics against ground truth. Track how this accuracy changes with the severity of domain shift and class imbalance. Goal: Validate the core assumption of Mechanism 1.
3. **Aggregation Similarity Study**: Run pFedBBN on the CIFAR-10-C setup with known domain labels for clients. Visualize the collaboration matrix $W$ (similar to Fig. 5) and quantify its alignment with the ground-truth domain partitioning. Goal: Validate the domain-aware aggregation claim of Mechanism 3.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several are implied by the methodology and experimental setup, particularly regarding the handling of classes with zero samples across the federation and the robustness of the confidence-filtered pseudo-label mechanism under extreme domain shifts.

## Limitations
- The framework relies heavily on the accuracy of pseudo-labels for updating per-class BBN statistics, which may degrade under severe domain shifts or extreme class imbalance.
- The privacy-preserving nature of the similarity-based aggregation using BBN statistics is claimed but not rigorously analyzed against potential adversarial manipulation.
- The method does not address the scenario where a class is entirely absent from the local test streams of all clients, potentially leaving its normalization statistics frozen at source model values.

## Confidence
- **High Confidence**: The experimental results showing pFedBBN's superiority over baseline methods on CIFAR-10-C and CIFAR-100-C are well-supported. The improvement in minority-class performance is a strong and verifiable claim.
- **Medium Confidence**: The mechanism of using per-class BBN statistics to mitigate majority-class bias is logically sound and supported by the equations, but the assumption of reliable pseudo-labels is a significant caveat not fully explored in the paper.
- **Medium Confidence**: The privacy-preserving nature of the similarity-based aggregation using BBN statistics is claimed, but the security against adversarial manipulation of these statistics is not rigorously analyzed.

## Next Checks
1. **Pseudo-label Robustness Test**: Systematically evaluate the accuracy of the pseudo-labels used for BBN updates under varying degrees of domain shift and class imbalance. Quantify how this accuracy correlates with the final model performance to validate the core assumption of Mechanism 1.
2. **Ablation on Aggregation Hyperparameters**: Conduct a thorough ablation study on the temperature parameter $\tau$ for the similarity softmax and the self-weight $\omega_i$ in the aggregation formula. Determine their sensitivity and optimal ranges for different levels of data heterogeneity.
3. **Ablation on Distillation Confidence Threshold**: Perform an ablation study on the entropy confidence threshold $\delta$ for filtering pseudo-labels during distillation. Analyze its impact on the balance between preventing noise and allowing sufficient adaptation, particularly for minority classes.