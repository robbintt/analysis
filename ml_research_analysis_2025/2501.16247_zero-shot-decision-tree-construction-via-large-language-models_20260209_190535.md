---
ver: rpa2
title: Zero-Shot Decision Tree Construction via Large Language Models
arxiv_id: '2501.16247'
source_url: https://arxiv.org/abs/2501.16247
tags:
- data
- decision
- tree
- zero-shot
- trees
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a zero-shot method for constructing decision
  trees using large language models (LLMs), bypassing the need for labeled data. The
  approach leverages LLMs to perform essential operations like attribute discretization,
  probability estimation, and Gini index computation.
---

# Zero-Shot Decision Tree Construction via Large Language Models

## Quick Facts
- arXiv ID: 2501.16247
- Source URL: https://arxiv.org/abs/2501.16247
- Reference count: 15
- Key outcome: Zero-shot decision trees using LLMs outperform baseline zero-shot methods and achieve competitive performance compared to supervised decision trees on tabular datasets, particularly in low-data scenarios.

## Executive Summary
This paper introduces a zero-shot method for constructing decision trees using large language models (LLMs), bypassing the need for labeled data. The approach leverages LLMs to perform essential operations like attribute discretization, probability estimation, and Gini index computation. Experiments show that the proposed zero-shot decision trees outperform baseline zero-shot methods and achieve competitive performance compared to supervised decision trees on tabular datasets, particularly in low-data scenarios. The method provides interpretable models, addressing data scarcity while preserving transparency.

## Method Summary
The method uses LLMs to construct decision trees recursively without training data. For each node, the LLM proposes splits (thresholds for numerical, groupings for categorical) based on feature descriptions and current constraints. The LLM then estimates conditional probabilities for target labels given each split, and the algorithm selects the split minimizing the harmonic mean of child node Gini impurities. The process repeats until reaching maximum depth or when any class probability exceeds 0.9. The approach uses GPT-4o Mini with carefully engineered prompts that provide feature names, types, descriptions, and accumulated constraints to guide split proposals and probability estimation.

## Key Results
- Zero-shot decision trees achieve up to 89% accuracy on tabular datasets without any labeled training data
- Outperforms baseline zero-shot methods (TabLLM) across multiple datasets
- Competitive with supervised decision trees when training data is limited (2-4 instances per feature)
- Performance degrades on out-of-domain datasets (e.g., Presidential Approval 2024 at ~40% accuracy)

## Why This Works (Mechanism)

### Mechanism 1: Knowledge-Driven Attribute Splitting
LLMs propose meaningful feature splits using pre-trained semantic knowledge rather than empirical statistics. The LLM receives feature names, descriptions, types, and constraints, then generates candidate partitions based on encoded domain knowledge. Core assumption: LLM's pre-training contains sufficient domain-relevant knowledge to infer discriminative split points. Break condition: LLM lacks domain-specific knowledge, producing arbitrary or irrelevant splits.

### Mechanism 2: Contextual Probability Estimation
LLMs estimate conditional probabilities for target labels given proposed splits and accumulated constraints, enabling impurity calculation without data. At each node, the LLM is prompted with split definition, previous context, and target labels to output probability estimates. Core assumption: LLMs encode sufficient prior knowledge about feature-target relationships for calibrated probability estimates. Break condition: Systematic miscalibration in probability estimates (e.g., always near 0.5 or 0.9) makes Gini-based split selection uninformative.

### Mechanism 3: Harmonic Mean Aggregation for Split Selection
Using harmonic mean of branch Gini impurities enables effective split selection without access to data counts. The algorithm aggregates impurities via harmonic mean: 2·Gini₁·Gini₂/(Gini₁+Gini₂), penalizing imbalanced splits and promoting homogeneous partitions. Core assumption: Balanced impurity reduction is a reasonable proxy for information gain when branch sizes are unknown. Break condition: Real data distributions have highly imbalanced branch sizes, making harmonic mean suboptimal compared to instance-weighted methods.

## Foundational Learning
- **Concept: CART (Classification and Regression Trees)** - Why needed: The algorithm replicates CART's recursive partitioning logic but replaces data-driven statistics with LLM-derived estimates. Quick check: Can you explain how CART selects splits using Gini impurity and how this differs when branch sizes are unknown?
- **Concept: Zero-Shot Learning with LLMs** - Why needed: The entire approach relies on LLMs performing tasks without task-specific training data; understanding prompt design and failure modes is critical. Quick check: What are common failure modes when using LLMs for zero-shot classification on tabular data (e.g., overconfidence, hallucinated thresholds)?
- **Concept: Prompt Engineering for Structured Outputs** - Why needed: The method requires parsing LLM outputs into numeric thresholds, groupings, and probabilities; prompt design directly affects reliability. Quick check: How would you design a prompt to ensure an LLM outputs a single numeric threshold without extraneous explanation?

## Architecture Onboarding
- **Component map:** Feature descriptions → Split Proposer (LLM) → Probability Estimator (LLM) → Gini Selector (Deterministic) → Branch Creator → Recursive until leaf nodes → Final tree output
- **Critical path:** Input features/descriptions → Split proposals → Probability estimates → Gini selection → Branch creation → Recursive until leaf nodes → Final tree output
- **Design tradeoffs:**
  - Harmonic vs. weighted mean: Harmonic mean avoids requiring instance counts but may mis-rank splits for imbalanced data
  - Tree depth vs. interpretability: Deeper trees improve accuracy; depth must be tuned per dataset
  - Prompt complexity vs. efficiency: Detailed prompts reduce parsing errors but increase token costs
- **Failure signatures:**
  - Early termination: Tree has only 1–2 nodes; likely caused by LLM overconfidence in probability estimates
  - Invalid splits: LLM proposes non-disjoint categorical groupings or thresholds violating constraints
  - Domain mismatch: Performance collapses on datasets outside LLM training knowledge
- **First 3 experiments:**
  1. Reproduce Diabetes dataset results: Compare zero-shot DT (depth=5, 7) vs. TabLLM zero-shot vs. supervised DT (full data)
  2. Ablation on probability calibration: Modify prompts to remove "avoid overconfidence" instructions; measure impact on tree depth and accuracy
  3. Test on out-of-distribution data: Apply method to a domain-specific dataset unlikely in LLM pre-training; analyze failure modes

## Open Questions the Paper Calls Out
- **Question:** Can hybrid approaches that combine zero-shot tree initialization with supervised fine-tuning outperform traditional decision trees in data-rich environments?
  - **Basis:** Section 6.3 states the need to explore "hybrid methods that combine the strengths of both traditional and zero-shot techniques"
  - **Why unresolved:** The current study focuses on zero-shot scenarios; it is unknown if LLM structural priors offer a better starting point for optimization when data is available
  - **Evidence needed:** Experiments comparing hybrid models (LLM structure + data-driven calibration) against standard CART and XGBoost across varying dataset sizes

- **Question:** To what extent can fairness-aware constraints be effectively integrated into the LLM prompting process to mitigate bias in the resulting decision trees?
  - **Basis:** Section 6.3 calls for future research to "integrate fairness-aware algorithms into the tree-building process," noting the risk of bias in probability estimation
  - **Why unresolved:** While the paper identifies that LLMs may embed societal biases into attribute selection, it does not test methods for detecting or reducing this bias during zero-shot construction
  - **Evidence needed:** Evaluation of generated trees using fairness metrics (e.g., demographic parity) comparing standard prompts against prompts with explicit fairness instructions

- **Question:** Does the use of the harmonic mean for aggregating Gini impurities provide a statistically significant advantage over other aggregation heuristics in the absence of instance counts?
  - **Basis:** Section 3.5 states the authors chose harmonic mean over weighted average to balance branch impurities, but no experimental justification provided
  - **Why unresolved:** The harmonic mean was selected to penalize imbalanced splits, but it is unclear if alternative heuristics would yield better tree structures or classification accuracy
  - **Evidence needed:** Ablation study comparing performance of trees constructed using harmonic mean versus other aggregation methods on the same datasets

## Limitations
- **Domain Knowledge Dependency:** Performance may degrade significantly on specialized domains where LLMs lack sufficient training knowledge
- **Prompt Sensitivity:** The method's effectiveness heavily depends on prompt engineering quality with no systematic analysis of prompt variations
- **Computational Cost:** Requires multiple LLM calls per node, potentially making it computationally expensive compared to traditional decision tree algorithms

## Confidence
- **High Confidence:** The zero-shot methodology and its core components (LLM-based splitting, probability estimation, harmonic mean aggregation) are well-specified and reproducible
- **Medium Confidence:** The empirical results showing competitive performance against supervised methods are compelling but limited to specific datasets and may not generalize broadly
- **Low Confidence:** The claim that LLMs can reliably estimate calibrated probabilities for split selection lacks rigorous validation, particularly regarding calibration across different domains

## Next Checks
1. **Prompt Robustness Analysis:** Systematically vary prompt formulations, temperature settings, and instruction specificity to quantify their impact on tree quality and identify failure modes
2. **Cross-Domain Generalization Test:** Apply the method to datasets from diverse domains (medical, financial, industrial) to measure performance degradation and identify knowledge gaps in LLM pre-training
3. **Computational Efficiency Benchmark:** Compare the computational cost (API calls, latency, token usage) against traditional supervised decision tree algorithms on datasets of varying sizes