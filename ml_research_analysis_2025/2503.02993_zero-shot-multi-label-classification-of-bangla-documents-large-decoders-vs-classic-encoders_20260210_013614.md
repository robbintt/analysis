---
ver: rpa2
title: 'Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders Vs.
  Classic Encoders'
arxiv_id: '2503.02993'
source_url: https://arxiv.org/abs/2503.02993
tags:
- bangla
- language
- label
- arxiv
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the performance of large decoder-based language
  models (LLMs) and classic encoder-based models for zero-shot multi-label classification
  of Bangla documents. It establishes a benchmark by testing 32 state-of-the-art models
  on a newly created BanglaNewsNet dataset of 7,245 news articles with 21 labels.
---

# Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders Vs. Classic Encoders

## Quick Facts
- **arXiv ID**: 2503.02993
- **Source URL**: https://arxiv.org/abs/2503.02993
- **Reference count**: 40
- **Primary result**: Neither LLMs nor encoders fully overcome Bangla's linguistic complexity in zero-shot multi-label classification, with F1 scores plateauing around 0.40-0.62.

## Executive Summary
This study establishes a benchmark for zero-shot multi-label classification of Bangla documents by evaluating 32 state-of-the-art models on the newly created BanglaNewsNet dataset. The research compares classic encoder-based approaches (LaBSE, LASER, BanglaTransformer) with large decoder-based language models (Gemma, Gemini, GPT series) across 21 news categories. Results show that while a few models achieve F1 scores around 60%, most struggle with high accuracy, indicating that both LLMs and encoders face significant challenges with Bangla's morphological complexity. Notably, no LLM surpasses the best-performing encoder in embedding-based classification, highlighting the need for further research and tailored approaches for low-resource languages.

## Method Summary
The study evaluates zero-shot multi-label classification using two primary approaches: encoder models that compute cosine similarity between document and label embeddings, and LLM-based classification via structured prompting. The BanglaNewsNet dataset contains 7,245 news articles with 21 labels. Encoders use either "Label+Keywords" or "Explicit-Mentions" strategies to create label embeddings. LLMs receive system prompts defining available labels and user prompts containing document text, with outputs constrained to JSON format for label extraction.

## Key Results
- Encoder models achieve F1 scores around 0.40, with LaBSE performing best at 0.404
- LLMs reach F1 scores up to 0.616 (Gemini-Pro), but show high recall (0.918) with low precision (0.463)
- Gemini-1.5-Flash (8B) outperforms GPT-3.5 (175B), demonstrating scale doesn't guarantee quality for Bangla
- No LLM surpasses the best encoder in embedding-based classification
- Explicit-Mentions label embedding strategy improves F1 by 0.03-0.05 over Label+Keywords

## Why This Works (Mechanism)

### Mechanism 1: Semantic Embedding Alignment for Zero-Shot Transfer
Encoder models perform zero-shot classification by measuring semantic similarity between document embeddings and label embeddings in a shared vector space. A sentence encoder maps both the input document and label definitions into fixed-dimensional vectors. Classification is achieved by computing cosine similarity between document and label embeddings, then applying a threshold for multi-label assignment. The embedding space must preserve cross-lingual semantic meaning sufficiently for Bangla documents and labels.

### Mechanism 2: Instruction-Following for Generative Classification
Large decoder models perform zero-shot MLC via prompted instruction-following, outputting structured label predictions directly. An LLM receives a system prompt defining available labels and a user prompt containing the document text. The model generates a JSON-formatted response containing predicted labels, leveraging pre-trained knowledge and instruction-tuning. The model's instruction-tuning must generalize to Bangla text despite primarily English-centric training.

### Mechanism 3: Label Embedding Enrichment
Augmenting label names with keywords or explicit document mentions improves classification by providing richer semantic context. Two approaches: (1) "Label+Keywords" averages embeddings of label name and associated keywords; (2) "Explicit-Mentions" averages embeddings of articles that explicitly mention the label. Keywords and explicit mentions must accurately represent the label's semantic domain in Bangla.

## Foundational Learning

- **Concept: Zero-Shot Classification**
  - **Why needed here**: The entire paper evaluates models without task-specific training data.
  - **Quick check question**: Can you explain why zero-shot evaluation matters for low-resource languages like Bangla?

- **Concept: Multi-Label vs. Multi-Class Classification**
  - **Why needed here**: Documents receive 1.345 labels on average; evaluation metrics must account for partial matches.
  - **Quick check question**: What's the difference between micro-F1 for multi-label vs. accuracy for single-label tasks?

- **Concept: Precision-Recall Tradeoff in Generative Models**
  - **Why needed here**: LLMs show high recall but low precision (coverage-heavy outputs), skewing result interpretation.
  - **Quick check question**: If a model has R=0.918 and P=0.463, what does this mean for false positives?

## Architecture Onboarding

- **Component map**: Bangla document text + user-defined label set -> Encoder Path (LASER/LaBSE/BanglaTransformer) OR Decoder Path (LLM API) -> Label Embedding (Label name + keywords OR explicit mention articles) -> Cosine similarity OR JSON parsing -> Multi-label output

- **Critical path**: Document ingestion -> embedding generation -> label comparison -> threshold application -> multi-label output

- **Design tradeoffs**:
  - Encoder vs. Decoder: Encoders (LaBSE F1=0.404) are interpretable but lower performance; Decoders (Gemini-Pro F1=0.616) are higher but black-box and recall-biased
  - Model size: Gemini-1.5-Flash (8B, F1=0.571) outperforms GPT-3.5 (175B, F1=0.537), showing scale â‰  quality for Bangla
  - Label embedding: Explicit-Mentions (LaBSE F1=0.404) > Label+Keywords (F1=0.354), suggesting richer context helps

- **Failure signatures**:
  - Low precision with high recall: Model over-generates labels (common in LLMs)
  - F1 plateau at ~0.40 for encoders: Insufficient Bangla representation in pre-training
  - BanglaLlama underperforms Llama baseline: Language-specific fine-tuning may not transfer to zero-shot MLC

- **First 3 experiments**:
  1. **Baseline encoder evaluation**: Run LaBSE, LASER, and BanglaTransformer on BanglaNewsNet with both label embedding methods; expect F1 0.30-0.40.
  2. **LLM scale comparison**: Test Gemini-1.5-Flash (8B), Gemma-2 (27B), and Gemini-1.5-Pro (200B) via API; expect F1 0.55-0.62 with high recall.
  3. **Ablation on label enrichment**: Compare "Label+Keywords" vs. "Explicit-Mentions" across all models; expect Explicit-Mentions to improve F1 by 0.03-0.05.

## Open Questions the Paper Calls Out

- **Open Question 1**: Do the performance rankings between classic encoders and large decoders generalize to domains outside of news articles, such as colloquial social media text or technical documentation? The authors state experiments were conducted on a single dataset, and broader evaluations are necessary to determine whether findings generalize across different domains.

- **Open Question 2**: To what extent does sub-optimal tokenization of Bangla's morphological complexity contribute to the performance gap observed in large language models? The paper concludes that neither encoders nor decoders are fully optimized for Bangla's morphological complexity and highlights this as a critical limitation.

- **Open Question 3**: Can specific prompt engineering or constrained decoding strategies mitigate the low-precision/high-recall trade-off observed in generative models? The results show that while LLMs like Gemini-1.5-Pro achieve high recall (0.918), their precision is often significantly lower (0.463), described as "coverage-heavy outputs."

## Limitations

- The study lacks publicly available BanglaNewsNet dataset, preventing direct reproduction and independent validation of results.
- Research only evaluates 21 predefined labels from a specific news domain, limiting generalizability to broader Bangla text classification tasks.
- The study does not explore mechanisms to force models to be more conservative in their label selection to reduce false positives.

## Confidence

- **High Confidence**: The comparative framework between encoder and decoder approaches is methodologically sound. The observation that no LLM outperforms the best encoder (LaBSE) in embedding-based classification is well-supported by the data.
- **Medium Confidence**: The specific F1 scores reported are accurate for the tested conditions, but may vary with different label embedding strategies or threshold adjustments.
- **Low Confidence**: The exact impact of label embedding enrichment methods cannot be fully assessed without the keyword lists and explicit mention articles.

## Next Checks

1. **Threshold Sensitivity Analysis**: Systematically vary the cosine similarity threshold for encoder models and the confidence threshold for LLM outputs to optimize the precision-recall tradeoff. Measure how F1 score changes across the full threshold range to identify optimal operating points.

2. **Cross-Domain Generalization Test**: Apply the best-performing models (LaBSE and Gemini-Pro) to a different Bangla text corpus (e.g., social media posts or academic abstracts) with the same 21 labels. Evaluate whether the observed performance patterns (low precision, high recall) persist across domains.

3. **Fine-tuning Impact Assessment**: Take the Bangla-specific model (BanglaLlama) and fine-tune it on a small subset of the BanglaNewsNet data. Compare zero-shot vs. few-shot performance to quantify whether domain adaptation can bridge the gap between encoder and decoder approaches.