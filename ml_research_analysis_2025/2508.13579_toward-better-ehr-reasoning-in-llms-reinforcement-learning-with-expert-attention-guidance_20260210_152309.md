---
ver: rpa2
title: 'Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention
  Guidance'
arxiv_id: '2508.13579'
source_url: https://arxiv.org/abs/2508.13579
tags:
- answer
- reasoning
- subquestion
- eag-rl
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving large language
  models (LLMs) for electronic health record (EHR) reasoning in clinical prediction
  tasks. The authors propose EAG-RL, a two-stage training framework that enhances
  LLMs' intrinsic EHR reasoning ability through expert attention guidance.
---

# Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance

## Quick Facts
- **arXiv ID**: 2508.13579
- **Source URL**: https://arxiv.org/abs/2508.13579
- **Reference count**: 40
- **Primary result**: EAG-RL improves LLM EHR reasoning by 14.62% average across clinical prediction tasks while enhancing robustness and cross-dataset generalization.

## Executive Summary
This paper addresses the challenge of improving large language models (LLMs) for electronic health record (EHR) reasoning in clinical prediction tasks. The authors propose EAG-RL, a two-stage training framework that enhances LLMs' intrinsic EHR reasoning ability through expert attention guidance. The framework first constructs high-quality reasoning trajectories using expert-guided Monte Carlo Tree Search, then optimizes the policy via reinforcement learning by aligning the LLM's attention with clinically salient features identified by expert EHR models. Experiments on two real-world EHR datasets show that EAG-RL improves LLMs' intrinsic EHR reasoning ability by an average of 14.62%, while also enhancing robustness to feature perturbations and generalization to unseen clinical domains.

## Method Summary
EAG-RL is a two-stage training framework for improving LLM reasoning on EHR data. Stage 1 uses Expert-Guided Monte Carlo Tree Search (MCTS) to construct high-quality reasoning trajectories, where expert EHR model attention guides the search toward clinically salient features. The top-k trajectories are then used to initialize the LLM policy through supervised fine-tuning. Stage 2 employs reinforcement learning with a composite reward: classification accuracy (R_cls) combined with attention alignment (R_att) measured by Jaccard similarity between LLM and expert feature sets. The training uses GRPO-style optimization with entropy-aware adaptive clipping to prevent premature convergence on suboptimal reasoning paths.

## Key Results
- EAG-RL improves LLM EHR reasoning ability by an average of 14.62% across clinical prediction tasks.
- The framework enhances robustness to feature perturbations and generalization to unseen clinical domains.
- Ablation studies show both stages are critical: removing Stage 1 causes ~2-4 AUROC drop, while removing Stage 2 causes ~4-8 drop.

## Why This Works (Mechanism)

### Mechanism 1: Expert-Guided MCTS for Trajectory Initialization
Monte Carlo Tree Search guided by expert EHR attention produces higher-quality reasoning trajectories than standard sampling, enabling more effective policy initialization. MCTS balances exploration (via UCT criterion) with exploitation while expert model attention provides intermediate rewards (R_att = Jaccard similarity) that steer search toward clinically salient features before backpropagation. Core assumption: Expert EHR models capture clinically meaningful attention patterns that correlate with ground-truth feature importance.

### Mechanism 2: Attention Alignment as Auxiliary Reward Signal
Aligning LLM-identified features with expert-identified features via Jaccard similarity provides denser supervision than sparse outcome-only rewards. Composite reward R = λ·R_cls + (1-λ)·R_att combines classification confidence (R_cls) with feature overlap (R_att). The attention reward provides per-trajectory feedback even when outcome rewards are uninformative. Core assumption: Feature set overlap meaningfully captures alignment of clinical reasoning, not just surface-level keyword matching.

### Mechanism 3: Entropy-Aware Adaptive Clipping for Exploration
Trajectory-specific upper clipping bounds based on token-level entropy prevent premature convergence on overconfident but suboptimal reasoning paths. High-entropy trajectories receive higher ε(τ) ∈ [ε_min, ε_max], permitting larger policy updates; low-entropy trajectories are constrained. This adaptively amplifies learning signals for uncertain but potentially informative clinical patterns. Core assumption: Higher entropy over clinical tokens indicates underexplored but meaningful reasoning patterns rather than noise.

## Foundational Learning

- **Monte Carlo Tree Search (MCTS)**
  - Why needed here: Core mechanism for Stage 1 trajectory construction; navigates exponential reasoning space with bounded computational cost.
  - Quick check question: Can you explain how UCT balances exploitation (high Q-values) versus exploration (low visit counts)?

- **Proximal Policy Optimization variants (GRPO/DAPO)**
  - Why needed here: EAG-RL builds on GRPO-style objectives with group-normalized advantages; understanding clipping mechanics is essential for the adaptive modification.
  - Quick check question: Why does GRPO eliminate the need for a separate critic network compared to standard PPO?

- **Attention Transfer in Knowledge Distillation**
  - Why needed here: Expert model attention serves as the primary supervisory signal; understanding attention-as-knowledge is foundational.
  - Quick check question: How does Jaccard similarity over feature sets compare to KL divergence over attention distributions as an alignment metric?

## Architecture Onboarding

- **Component map:**
  ```
  EHR Data → Prompt Template (P_QD) → LLM Policy
                  ↓
  Expert Model (Concare) → Attention Weights → Feature Set C_exp
                  ↓
  MCTS Module (select/expand/simulate/backprop) → Top-k Trajectories
                  ↓
  Stage 1: SFT on trajectories → Stage 2: RL (GRPO + R_att + adaptive ε(τ))
  ```

- **Critical path:** Stage 1 (MCTS + SFT) → Stage 2 (RL with attention reward). Table 2 shows skipping Stage 1 causes ~2-4 AUROC drop; skipping Stage 2 causes ~4-8 drop. Stage 2 appears more critical for final performance.

- **Design tradeoffs:**
  - λ = 0.6 in R = λ·R_cls + (1-λ)·R_att: Higher λ prioritizes accuracy; lower λ prioritizes clinical alignment
  - Rollout N = 8, depth T = 7: Higher values increase trajectory quality but computational cost grows linearly
  - Expert model choice: Concare is lightweight; more expressive models may provide richer attention but higher inference overhead

- **Failure signatures:**
  - Entropy collapse (uniformly low trajectory diversity): Increase ε_max from 0.4 or add explicit entropy bonus
  - Low feature overlap with expert (R_att < 0.3): Verify EHR preprocessing matches expert model's expected schema
  - Reward hacking (high R_att, low R_cls): Increase λ toward 0.7–0.8

- **First 3 experiments:**
  1. Reproduce Stage 1 in isolation: Run MCTS with expert attention disabled (R_att = 0) versus enabled; expect trajectory reward distribution to shift lower without attention guidance
  2. Ablate R_att in Stage 2: Train with R_cls only, compare to full EAG-RL; expect 2–5% AUROC drop consistent with Table 2
  3. Cross-dataset generalization test: Train on MIMIC-IV, evaluate on TJH; expect EAG-RL to outperform SFT baseline by >5% AUROC (per Figure 5)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can multi-expert distillation, aggregating attention from multiple diverse expert EHR models, improve the robustness and accuracy of LLM reasoning beyond single-expert supervision?
- Basis in paper: [explicit] "we currently consider the knowledge from a single expert EHR model; exploring richer forms of supervision beyond expert attention and incorporating multi-expert distillation could better capture diverse clinical reasoning patterns."
- Why unresolved: The current framework relies solely on Concare as the expert model; whether ensembling attention signals from multiple architectures yields complementary guidance remains untested.
- What evidence would resolve it: Experiments comparing single-expert vs. multi-expert attention alignment across heterogeneous EHR models, measuring both predictive performance and attention stability.

### Open Question 2
- Question: How does EAG-RL's performance scale when applied to larger LLMs (e.g., 13B, 70B parameters), and does the two-stage training remain effective or require architectural adjustments?
- Basis in paper: [explicit] "due to computational resource constraints, we evaluate the performance using models with up to 8B parameters, and scaling to larger models could offer additional insights into the efficacy of EAG-RL."
- Why unresolved: Larger models may have different attention distributions and reasoning capacities that could reduce reliance on expert guidance or require adapted clipping/alignment strategies.
- What evidence would resolve it: Benchmarks on 13B+ parameter models across the same tasks, with ablations on entropy-aware clipping effectiveness and expert attention contribution.

### Open Question 3
- Question: Does EAG-RL generalize to a broader range of clinical prediction tasks beyond binary outcomes (e.g., length-of-stay regression, multi-label diagnosis, medication recommendation)?
- Basis in paper: [inferred] The evaluation is limited to mortality and 30-day readmission (both binary classification). The attention alignment reward (Jaccard similarity) and classification reward formulation are designed for this setting, leaving unclear whether they transfer to regression or multi-class scenarios.
- Why unresolved: Multi-label or continuous outcomes require different reward formulations and feature importance calibration, which the current attention alignment mechanism may not directly support.
- What evidence would resolve it: Experiments extending EAG-RL to regression tasks (e.g., LOS prediction) and multi-label tasks (e.g., ICD code prediction), with adapted reward formulations reported.

### Open Question 4
- Question: What is the sensitivity of EAG-RL's performance to the hyperparameters governing entropy-aware adaptive clipping (ε_min, ε_max, λ in reward combination)?
- Basis in paper: [inferred] The paper fixes ε_min = 0.2, ε_max = 0.4, λ = 0.6 without extensive sensitivity analysis. Given the importance of these for exploration-exploitation balance, their optimal values may vary across datasets or model sizes.
- Why unresolved: No ablation or grid search is presented for these key hyperparameters, leaving unclear whether the chosen values are near-optimal or dataset/task-specific.
- What evidence would resolve it: Systematic hyperparameter sweeps across ε and λ on multiple datasets, with performance variance and stability analysis reported.

## Limitations
- Expert attention quality depends heavily on Concare's architecture and training data matching the target clinical domain, with no validation of correlation with clinician annotations.
- The entropy-based adaptive clipping assumes high entropy indicates underexplored reasoning patterns, but this correlation isn't empirically verified in clinical contexts.
- Cross-dataset generalization improvements may partially reflect dataset-specific artifacts rather than clinically transferable reasoning patterns.

## Confidence
- **High confidence**: The mechanism of combining outcome rewards with attention alignment is technically sound and the ablation studies provide strong evidence for R_att's contribution.
- **Medium confidence**: The MCTS trajectory quality improvement claim relies on expert attention guidance, but the paper doesn't compare against alternative trajectory initialization methods.
- **Low confidence**: The entropy-aware adaptive clipping mechanism's clinical interpretability is unclear without validation that high-entropy trajectories correspond to meaningful clinical uncertainty.

## Next Checks
1. **Expert attention validation**: Conduct a small-scale human evaluation where clinicians rate whether Concare-identified salient features align with their own clinical reasoning on sample trajectories.
2. **Alternative trajectory initialization**: Implement a baseline using random sampling or outcome-only rewards for trajectory generation, then compare trajectory quality metrics (R_cls, R_att) to the expert-guided MCTS approach.
3. **Entropy-uncertainty correlation**: Measure the correlation between trajectory-level entropy and prediction uncertainty (e.g., entropy of predicted probabilities) to validate the adaptive clipping assumption.