---
ver: rpa2
title: LLM-Based Config Synthesis requires Disambiguation
arxiv_id: '2507.12443'
source_url: https://arxiv.org/abs/2507.12443
tags:
- network
- synthesis
- route-map
- user
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses ambiguity in LLM-based network configuration
  synthesis, where overlapping routing policies (route-maps and ACLs) make it difficult
  to determine the correct insertion point for new stanzas without user input. The
  proposed system, Clarify, uses an LLM to synthesize isolated configuration stanzas
  and introduces a Disambiguator module to interactively resolve conflicts by comparing
  behavioral differences.
---

# LLM-Based Config Synthesis requires Disambiguation

## Quick Facts
- arXiv ID: 2507.12443
- Source URL: https://arxiv.org/abs/2507.12443
- Reference count: 40
- The paper introduces Clarify, a system that uses interactive behavioral differentiation to resolve insertion ambiguity in LLM-based network configuration synthesis.

## Executive Summary
The paper addresses a critical ambiguity problem in LLM-based network configuration synthesis, where overlapping routing policies (route-maps and ACLs) make it difficult to determine the correct insertion point for new stanzas without user input. The proposed system, Clarify, uses an LLM to synthesize isolated configuration stanzas and introduces a Disambiguator module to interactively resolve conflicts by comparing behavioral differences. Evaluation on a synthetic network topology showed that GPT-4 successfully synthesized correct stanzas in a single pass, and users were queried a logarithmic number of times (typically 5-6) to resolve ambiguities. Analysis of real networks found that 37.7% of ACLs and 26.7% of route-maps had overlapping rules, confirming ambiguity is a practical problem.

## Method Summary
Clarify uses GPT-4 to synthesize isolated configuration stanzas (route-maps/ACLs) given user intent, generating both a config snippet and formal JSON specification. A verifier (Batfish) checks equivalence between the snippet and spec. The Disambiguator module identifies overlapping rules in the existing configuration and performs binary search to resolve insertion point ambiguity by presenting differential behavioral examples to the user. The system evaluates on a 3-node synthetic topology and analyzes real network configurations for overlap prevalence.

## Key Results
- GPT-4 successfully synthesized correct configuration stanzas in a single pass
- Users required a logarithmic number of queries (typically 5-6) to resolve insertion ambiguities
- 37.7% of ACLs and 26.7% of route-maps in real networks had overlapping rules
- Binary search algorithm efficiently minimized user interaction overhead

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Synthesizing configuration stanzas in isolation (decoupled from the existing config) reduces LLM error modes related to context window noise and complex dependency resolution.
- **Mechanism:** The system prompts the LLM to generate a small, self-contained snippet (e.g., a single route-map stanza) and a corresponding JSON formal specification. A verifier (Batfish) checks equivalence between the snippet and the spec. This isolates synthesis errors from integration errors.
- **Core assumption:** The user's intent can be expressed as a single atomic policy that is functionally independent of the global configuration logic, even if its placement is dependent on it.
- **Evidence anchors:**
  - [abstract] "Clarify... uses an LLM to synthesize isolated configuration stanzas..."
  - [Page 1] "...asking the LLM to synthesize a config snippet in isolation given the intent of a change..."
  - [corpus] **Active Task Disambiguation with LLMs** supports the general difficulty of addressing underspecified problems without decomposition.
- **Break condition:** If the user intent requires modifying multiple interdependent stanzas simultaneously (e.g., "swap the priority of rules X and Y while changing Y's action"), the single-stanza isolation approach may fail.

### Mechanism 2
- **Claim:** Resolving integration ambiguity via behavioral differentiation (showing outcomes) is more effective than asking users to reason about rule syntax or priority directly.
- **Mechanism:** The Disambiguator identifies input packets/routes that trigger different outcomes based on potential insertion points. It presents these "differential examples" to the user (e.g., "Option A: Packet is permitted; Option B: Packet is denied") rather than asking "Should this go before line 10 or after line 20?".
- **Core assumption:** Users understand network behavior (reachability, routing paths) better than the intricate ordering semantics of device configuration languages.
- **Evidence anchors:**
  - [abstract] "...interactively resolve conflicts by comparing behavioral differences."
  - [Page 3] "...helps the user to clarify their preferences through differential examples."
  - [corpus] **AmbiSQL** similarly utilizes interactive resolution for ambiguity, though in the SQL domain rather than network configs.
- **Break condition:** If the behavioral difference is too subtle for a layperson to grasp (e.g., a slight metric change that only affects backup paths), the user may struggle to answer the disambiguation query correctly.

### Mechanism 3
- **Claim:** A binary search algorithm minimizes user interaction overhead to O(log N) even in configurations with high rule overlap.
- **Mechanism:** The system identifies the set of rules that overlap with the new stanza. It effectively bisects this set by asking a single behavioral question, eliminating half the candidate insertion points with each user response.
- **Core assumption:** The "winning" rule for a specific packet can be determined by linear scanning of priorities (first-match semantics), allowing the insertion point to be constrained to a single precise boundary.
- **Evidence anchors:**
  - [abstract] "...users were queried a logarithmic number of times (typically 5-6)..."
  - [Page 5] "...we can use binary search to solve the disambiguation problem... users are queried a logarithmic number of times..."
  - [corpus] Weak/missing specific algorithmic anchors for network binary search in the provided corpus; this appears novel to this specific implementation.
- **Break condition:** If the configuration uses non-linear evaluation (e.g., complex `goto` or `call` statements that jump between contexts), the linear insertion assumption fails, and binary search may not find a valid location.

## Foundational Learning

- **Concept:** **First-Match Semantics (in ACLs/Route-maps)**
  - **Why needed here:** The entire ambiguity problem stems from the fact that in Cisco IOS and similar languages, the *order* of rules determines which action is taken for a packet matching multiple rules. Without understanding this, one cannot understand why "insertion point" matters.
  - **Quick check question:** If a packet matches both Line 5 (Permit) and Line 10 (Deny), which action is taken in a standard ACL?

- **Concept:** **Formal Verification / Symbolic Execution**
  - **Why needed here:** The "Disambiguator" relies on tools like Batfish to mathematically prove that "Input X results in Outcome Y" rather than just simulating traffic. This allows it to find the *exact* packet that exposes a conflict.
  - **Quick check question:** How does a symbolic verifier find a "differential example" compared to a simple traffic simulator?

- **Concept:** **Intent Ambiguity vs. Hallucination**
  - **Why needed here:** Engineers must distinguish between an LLM making up syntax (hallucination) versus the LLM producing valid syntax that has multiple valid interpretations based on placement (ambiguity). The fix for the former is better training; the fix for the latter is interactive clarification.
  - **Quick check question:** An LLM generates a valid route-map stanza, but inserting it breaks the network. Is this a hallucination or an ambiguity failure?

## Architecture Onboarding

- **Component map:** User Interface -> Query Classifier (LLM) -> Synthesizer (LLM) -> Verifier (Batfish) -> Disambiguator Logic
- **Critical path:** The **Verifier-Disambiguator loop**. The system is not just "LLM-to-Config"; the critical innovation is the feedback loop where symbolic analysis challenges the user to refine intent before commit.
- **Design tradeoffs:**
  - **Interactivity vs. Automation:** The system trades fully automated "magic" for correctness by forcing 5-6 user interactions. This is acceptable for high-stakes network changes but may be too slow for bulk updates.
  - **Isolation vs. Context:** Synthesizing in isolation simplifies the prompt but requires a separate, complex "insertion" phase.
- **Failure signatures:**
  - **The "Ping-Pong" Loop:** If the Verifier rejects the snippet repeatedly, the LLM is hallucinating or the user intent is logically impossible.
  - **Empty Overlap:** If the Disambiguator finds no overlapping rules, the insertion is trivial (usually at the end), but if it fails to detect existing overlaps, it introduces silent bugs.
- **First 3 experiments:**
  1. **Overlapping ACL Test:** Create an ACL with 20 overlapping rules (Permit specific subnet, Deny larger range). Task the system to insert a rule that affects a host in the overlap. Verify it asks exactly $\lceil \log_2(20) \rceil$ questions.
  2. **Spec-Code Mismatch:** Intentionally feed the system an intent that is self-contradictory (e.g., "Permit all traffic from X" and "Deny all traffic from X" in one sentence). Observe if the Verifier or LLM catches the logic error.
  3. **Complex Route-Map with Set actions:** Test if the Disambiguator correctly identifies conflicts where the *action* is the same (e.g., permit) but the *modifications* (e.g., set metric) differ based on position.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an LLM effectively replace the symbolic Disambiguator module to resolve configuration conflicts without formal verification tools?
- Basis in paper: [explicit] The authors ask, "A natural question is whether the LLM itself could play the role of the disambiguator," though they hypothesize that symbolic tools are better suited for the task.
- Why unresolved: The paper utilizes a symbolic approach (Batfish) for disambiguation and does not evaluate an LLM's ability to identify behavioral differences or resolve insertion points autonomously.
- What evidence would resolve it: A comparative study measuring the accuracy and user trust of an LLM-based disambiguator versus the proposed symbolic differential testing approach.

### Open Question 2
- Question: Can advanced prompting techniques like Chain-of-Thought or Agentic AI improve the correctness of the initial configuration synthesis beyond standard few-shot prompting?
- Basis in paper: [explicit] Section 7 explicitly asks if using "chain-of-thought, retrieval-augmented generation, graph RAG or even agentic AI" could yield better results than the few-shot examples currently employed.
- Why unresolved: The current prototype relies on few-shot examples combined with verification loops; the utility of more complex reasoning architectures for this specific task remains untested.
- What evidence would resolve it: Evaluation metrics comparing the "single pass" success rate and verification iterations required when using advanced reasoning techniques versus the baseline.

### Open Question 3
- Question: How can the disambiguation algorithm be extended to handle insertion into intermediate positions and for overlapping data structures other than route-maps and ACLs?
- Basis in paper: [explicit] Section 7 lists two necessary improvements: supporting "inserting entries into other data structures... like prefix lists" and handling insertions beyond just the "top or bottom" (intermediate positions).
- Why unresolved: The current Disambiguator prototype is restricted to top/bottom insertion for route-maps and ACLs, limiting its applicability to complex policies requiring middle insertion or nested list modifications.
- What evidence would resolve it: An updated algorithm capable of resolving conflicts in prefix-lists and successfully determining correct insertion points between existing rules in a sequence.

### Open Question 4
- Question: Does the logarithmic query complexity of the disambiguation process remain efficient and manageable for human operators in large-scale, real-world networks?
- Basis in paper: [inferred] The paper evaluates the system on a "small synthetic workload" and notes that "much more experience is required with real operators," implying the user burden in production environments is unknown.
- Why unresolved: While the algorithm is theoretically logarithmic, the cognitive load of answering differential example questions for complex, real-world policy updates has not been validated with human subjects.
- What evidence would resolve it: User studies involving network operators managing production-scale configurations to measure the time taken and error rates during the disambiguation process.

## Limitations
- The evaluation relies heavily on synthetic topologies rather than real operational networks
- Binary search disambiguation assumes first-match semantics without addressing complex routing scenarios with multiple contexts
- Specific prompt engineering techniques for successful isolated stanza synthesis are not fully disclosed

## Confidence

**High Confidence:** The core observation that overlapping routing policies create insertion ambiguity is well-supported by both the 37.7% ACL overlap statistic and the 26.7% route-map overlap finding. The behavioral differentiation approach for disambiguation is conceptually sound and aligned with established HCI principles.

**Medium Confidence:** The logarithmic query efficiency claim is plausible given the binary search approach, but the "typically 5-6 queries" figure needs empirical validation across diverse configuration patterns beyond the synthetic topology.

**Low Confidence:** The assertion that isolated synthesis "reduces LLM error modes" lacks direct comparative evidence against context-aware synthesis approaches, and the specific mechanisms by which the Verifier catches spec-code mismatches are not fully detailed.

## Next Checks

1. **Complex Rule Interaction Test:** Evaluate the system's ability to handle configurations with `goto` or `call` statements that create non-linear rule evaluation paths, where first-match semantics may not apply.

2. **Real Network Deployment Trial:** Deploy the Clarify system in a production network environment with actual network engineers, measuring not just query count but also correctness, time-to-resolution, and user satisfaction compared to manual configuration.

3. **Hallucination vs. Ambiguity Benchmark:** Create a controlled benchmark dataset containing both syntactically invalid LLM outputs (hallucinations) and valid but ambiguous outputs, testing whether the system can reliably distinguish and handle each case appropriately.