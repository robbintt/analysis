---
ver: rpa2
title: 'O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis'
arxiv_id: '2510.12350'
source_url: https://arxiv.org/abs/2510.12350
tags:
- proof
- proofs
- estimate
- able
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "O-Forge is an LLM+CAS framework for proving asymptotic inequalities,\
  \ addressing the challenge that frontier LLMs can suggest plausible but unverified\
  \ proofs. The system decomposes the domain using an LLM, then verifies each subdomain\
  \ with Mathematica\u2019s Resolve function via quantifier elimination."
---

# O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis

## Quick Facts
- arXiv ID: 2510.12350
- Source URL: https://arxiv.org/abs/2510.12350
- Authors: Ayush Khaitan; Vijay Ganesh
- Reference count: 17
- Key outcome: O-Forge is an LLM+CAS framework for proving asymptotic inequalities, addressing the challenge that frontier LLMs can suggest plausible but unverified proofs. The system decomposes the domain using an LLM, then verifies each subdomain with Mathematica's Resolve function via quantifier elimination. Applied to a weak Fenchel-Young inequality, O-Forge correctly decomposes the domain into y ≤ 2 log x and y > 2 log x, enabling trivial proof in each subdomain. For a research-level series estimate from MathOverflow, it decomposes the sum at breakpoints {⌈h⌉, ⌈hm⌉} and verifies each piece, yielding a complete proof. Across ~100 test problems, proofs typically required k ≤ 4 subdomains, and leading-term simplifications were sufficient for Resolve to succeed. The approach moves beyond contest math to produce rigorously verified proofs for research-level asymptotic analysis.

## Executive Summary
O-Forge addresses the challenge that while frontier LLMs can suggest plausible decompositions for proving asymptotic inequalities, these suggestions require rigorous verification. The framework combines LLM-based domain decomposition with Mathematica's Resolve function for automated verification via quantifier elimination. By decomposing the domain into subdomains where inequalities become trivial to prove, O-Forge bridges the gap between heuristic proof suggestions and formal verification. The system has been successfully applied to both contest-level problems and research-level asymptotic analysis from MathOverflow.

## Method Summary
O-Forge is an LLM+CAS framework that proves asymptotic inequalities by first decomposing the domain using a frontier LLM, then verifying each subdomain with Mathematica's Resolve function via quantifier elimination. The approach handles transcendental functions that SMT solvers cannot process by leveraging Mathematica's closed-source quantifier elimination capabilities. For series estimates, the framework performs regime-wise leading-term replacement to simplify summands before verification. The decomposition step is critical - the LLM must propose correct breakpoints or subdomains where the inequality simplifies to a form amenable to automated verification. Across ~100 test problems, the framework typically required k ≤ 4 subdomains for proofs to succeed.

## Key Results
- Correctly decomposes the weak Fenchel-Young inequality into y ≤ 2 log x and y > 2 log x subdomains, enabling trivial proof in each
- Handles research-level series estimates from MathOverflow by decomposing at breakpoints {⌈h⌉, ⌈hm⌉} and verifying each piece
- Empirically requires k ≤ 4 subdomains for ~100 test problems, with leading-term simplifications sufficient for Resolve to succeed
- Successfully moves beyond contest math to produce rigorously verified proofs for research-level asymptotic analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain decomposition transforms intractable asymptotic inequalities into trivial subproblems solvable by first-order logic.
- Mechanism: A frontier LLM proposes a partition D = ∪ᵢ Dᵢ based on heuristic cues (dominant terms, monotonic regimes). Each subdomain Dᵢ is chosen such that the inequality simplifies to a form amenable to automated verification. The CAS then independently verifies ∀x∈Dᵢ: f(x) ≤ C·g(x) for each piece.
- Core assumption: LLMs can reliably propose correct decompositions; the "right" decomposition reduces proof difficulty from research-level to routine.
- Evidence anchors:
  - [abstract]: "decomposes the domain into y ≤ 2 log x and y > 2 log x, enabling trivial proof in each subdomain"
  - [Page 5]: "Within these sub-domains, proving this estimate becomes trivial... the only 'creative' step was to find the correct decomposition"
  - [corpus]: Related work (StepProof, APOLLO) supports step-wise verification but focuses on formal proof assistants rather than CAS-based quantifier elimination.
- Break condition: If the LLM proposes an incorrect or incomplete decomposition, the CAS will return False for some subdomain, requiring re-prompting or manual intervention.

### Mechanism 2
- Claim: Mathematica's Resolve function via quantifier elimination over the reals can rigorously verify inequalities involving transcendental functions that SMT solvers cannot.
- Mechanism: Resolve performs quantifier elimination on formulas of the form ∀x∈Dᵢ: f(x) ≤ C·g(x), searching C over a finite grid (default 1 to 10⁴). It returns True only when it can construct a proof using algebraic and analytic properties of real functions.
- Core assumption: Mathematica's closed-source implementation correctly performs quantifier elimination; the absence of a verifiable proof object is acceptable for the target use case.
- Evidence anchors:
  - [Page 6]: "Z3, which is the most popular SMT solver currently, is unable to handle transcendental functions. CVC5 and MetiTarski... were not able to reliably complete even the simplest proofs"
  - [Page 4, footnote]: "Mathematica's Resolve can often decide formulas involving log and exp using quantifier elimination over the reels, but it does not emit an externally verifiable proof object"
  - [corpus]: CALT paper discusses Transformer-based symbolic computation but does not address verification of transcendental expressions.
- Break condition: Complex expressions without leading-term simplification cause Resolve to attempt closed-form summation (involving gamma functions) and fail; expressions with nested transcendental functions may exceed Resolve's capabilities.

### Mechanism 3
- Claim: Regime-wise leading-term replacement (simplifying numerator/denominator to dominant terms) is necessary and sufficient for Resolve to succeed on series estimates.
- Mechanism: For each subdomain Dᵢ, extract the leading-order term from both numerator and denominator of the summand. The simplified ratio bounds the original expression. This reduction prevents Resolve from attempting symbolic summation and enables direct inequality verification.
- Core assumption: The summand is a rational expression (or can be treated as one); leading-term extraction preserves the asymptotic bound.
- Evidence anchors:
  - [Page 8]: "Without this simplification, Mathematica tries to find a closed form expression for the series in terms of gamma functions, and is then unable to complete proofs using Resolve"
  - [Page 6]: "if d lies between 0 and ⌈h⌉, then the summand can be approximated as (d+1)/h²... In all the above cases, the sum of such approximations over their respective ranges can be trivially shown to be ≪ 1 + log m²"
  - [corpus]: Weak corpus support for this specific simplification strategy; related work focuses on formal verification rather than CAS-specific optimization.
- Break condition: If summands have non-rational structure, or if leading-term extraction is invalid (e.g., oscillating terms, non-positive denominators), the simplification fails and the proof cannot proceed.

## Foundational Learning

- **Concept**: Vinogradov notation (≪) and O-notation
  - Why needed here: The entire framework is designed to prove f ≪ g, meaning ∃C > 0: f(x) ≤ C·g(x). Understanding this is prerequisite to formulating problems and interpreting outputs.
  - Quick check question: Given f(x) = x log x + eʸ and g(x) = xy, does f ≪ g hold when x ≥ 1, y ≥ 0? (Answer: Yes, but the constant C depends on the domain decomposition.)

- **Concept**: Quantifier elimination over the reals
  - Why needed here: Resolve works by eliminating quantifiers from ∀∃ formulas over real-closed fields. Understanding this clarifies what expressions Resolve can handle and why it fails on certain inputs.
  - Quick check question: Can quantifier elimination decide ∀x∈ℝ: x² ≥ 0? What about ∀x∈ℝ: eˣ > 0? (Answer: Yes to both, but the latter requires special handling of transcendental functions.)

- **Concept**: Domain decomposition in asymptotic analysis
  - Why needed here: The core insight is that inequalities which are hard globally become easy locally. Understanding when and how to decompose (e.g., at breakpoints where behavior changes) is essential for debugging LLM proposals.
  - Quick check question: For the inequality xy ≪ x log x + eʸ, why is y = 2 log x a natural breakpoint? What happens if you choose y = log x instead?

## Architecture Onboarding

- Component map: Input parser -> LLM decomposition module -> Simplification module -> CAS verification module -> Aggregator
- Critical path: LLM decomposition proposal → leading-term simplification → Resolve verification. The decomposition is the accuracy bottleneck; simplification is the tractability bottleneck.
- Design tradeoffs:
  - **Formal proof objects vs. practical coverage**: Chose Mathematica (no proof objects) over Lean/Z3 (proof objects but weak transcendental support).
  - **LLM simplification vs. rule-based**: Chose rule-based leading-term extraction over LLM simplification (LLM was "sporadically" correct).
  - **Single LLM call vs. iterative refinement**: Minimizes LLM calls to reduce error propagation; all heavy lifting delegated to CAS.
- Failure signatures:
  - Resolve returns `False` or times out → decomposition may be incorrect, or simplification failed.
  - LLM proposes k > 4 subdomains for 2-3 variable problems → likely over-complicating; consider re-prompting with simpler constraints.
  - Simplification produces non-positive denominators → domain refinement needed to exclude singular regions.
- First 3 experiments:
  1. Reproduce the weak Fenchel-Young inequality (xy ≪ x log x + eʸ) using the CLI: `decomp prove question <id>`. Verify that the LLM proposes {y ≤ 2 log x, y > 2 log x} and Resolve returns True for both.
  2. Test a series estimate from the paper (Eq. 2) using `decomp series series <id>`. Examine whether breakpoints {⌈h⌉, ⌈hm⌉} are proposed and whether leading-term approximations match those in Page 6.
  3. Stress test with a known-false inequality (e.g., x log x ≪ xy for all x, y ≥ 1). Confirm that Resolve returns False and the tool does not falsely claim verification.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the O-Forge framework be extended to produce independently verifiable proof objects (e.g., in Lean 4) rather than relying on Mathematica's closed-source Resolve function?
  - Basis in paper: [explicit] "Resolve does not produce proof objects that can be independently verified... we hope that autoformalization becomes powerful enough in the future that we are able to delegate such proof completions to such a tool."
  - Why unresolved: Current theorem provers and SMT solvers cannot reliably handle transcendental functions (log, exp), which Resolve handles via quantifier elimination.
  - What evidence would resolve it: Development of an autoformalization tool or open-source CAS that can verify asymptotic inequalities involving transcendental functions with exportable proof certificates.

- **Open Question 2**: Does the empirical finding that k ≤ 4 subdomains suffices for most problems hold for asymptotic inequalities with many variables or more complex structures?
  - Basis in paper: [inferred] The authors observe linear growth in decompositions with variables across ~100 test problems but note "there is no a priori reason to expect that" and did not test on high-dimensional or highly non-linear problems.
  - Why unresolved: The empirical evaluation covers a limited dataset, and scaling properties for complex multivariate or nested structures remain unexplored.
  - What evidence would resolve it: Systematic evaluation on problems with ≥5 variables or highly non-linear asymptotic bounds, tracking required subdomain count and failure rates.

- **Open Question 3**: Can reinforcement learning or fine-tuning improve LLM reliability for summand simplification beyond the current leading-term extraction heuristic?
  - Basis in paper: [explicit] "This may not be valid simplification for more complex summands, and perhaps performing RLHF on an off-the-shelf LLM would allow us to obtain correct simplifications more generally."
  - Why unresolved: Frontier LLMs were found unreliable for simplification, and the leading-term method may fail for oscillatory or conditionally convergent series.
  - What evidence would resolve it: Benchmarks on series with non-monotonic or alternating terms, comparing LLM-based vs. heuristic simplification accuracy.

## Limitations
- The framework relies on Mathematica's Resolve function, which does not produce externally verifiable proof objects, creating a black-box verification step
- Empirical evaluation covers only ~100 test problems, limiting understanding of scalability to complex multivariate or highly non-linear asymptotic inequalities
- The leading-term simplification approach may fail for summands with non-rational structure or oscillating terms that cannot be captured by dominant-term extraction

## Confidence
- **High Confidence**: The mechanism of using domain decomposition to transform hard asymptotic proofs into trivial subproblems is well-supported by concrete examples and aligns with established mathematical practice
- **Medium Confidence**: The claim that LLMs can reliably propose correct decompositions is supported by the weak Fenchel-Young example but lacks systematic evaluation across diverse problem types
- **Medium Confidence**: The assertion that leading-term simplification is necessary and sufficient for Resolve success is backed by specific failure analysis but may not generalize to all series forms

## Next Checks
1. **Verification Trace Analysis**: For a representative sample of test problems, instrument the system to log intermediate LLM decompositions and CAS verification attempts, enabling analysis of decomposition quality and CAS failure modes

2. **Alternative LLM Evaluation**: Replace the Gemini API with another frontier LLM (e.g., Claude, GPT-4) using identical prompts to assess whether decomposition quality is LLM-dependent or prompt-dependent

3. **Formal Proof Object Generation**: Implement a post-processing step that converts Mathematica's quantifier elimination results into verifiable proof objects using an interactive theorem prover, addressing the black-box verification limitation