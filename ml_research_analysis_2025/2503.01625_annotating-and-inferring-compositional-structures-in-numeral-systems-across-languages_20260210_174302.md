---
ver: rpa2
title: Annotating and Inferring Compositional Structures in Numeral Systems Across
  Languages
arxiv_id: '2503.01625'
source_url: https://arxiv.org/abs/2503.01625
tags:
- numeral
- systems
- languages
- language
- morpheme
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a coding scheme and workflow for annotating
  and comparing numeral systems across languages, enabling the systematic analysis
  of their compositional structures. The authors annotate numerals from 1 to 40 in
  25 typologically diverse languages, distinguishing surface and underlying morphological
  forms while identifying morpheme boundaries, allomorphs, and internal cognates.
---

# Annotating and Inferring Compositional Structures in Numeral Systems Across Languages

## Quick Facts
- arXiv ID: 2503.01625
- Source URL: https://arxiv.org/abs/2503.01625
- Reference count: 21
- Introduces a coding scheme for annotating numeral systems and shows that allomorphy is the primary source of segmentation errors in automated morpheme analysis.

## Executive Summary
This study presents a systematic framework for annotating and comparing numeral systems across languages, enabling computational analysis of their compositional structures. The authors annotate numerals from 1 to 40 in 25 typologically diverse languages, distinguishing surface and underlying morphological forms while identifying morpheme boundaries, allomorphs, and internal cognates. Automated morpheme segmentation experiments reveal that allomorphy is the primary source of segmentation errors, with performance improving significantly when underlying forms are used. The results show that models like Morfessor outperform simple heuristics and subword tokenization methods, which are ineffective for discovering morphemes in low-resource scenarios.

## Method Summary
The researchers developed a coding scheme using CLDF-formatted wordlists with IPA transcriptions, annotating numerals 1-40 across 25 languages in EDICTOR 3.1. They manually segmented morpheme boundaries, identified allomorphs, and mapped surface forms to underlying representations. Automated morpheme segmentation was performed using Morfessor (MDL-based), LSPE (entropy-based), and simple heuristics, with subword tokenizers (BPE, WordPiece) as baselines. Performance was evaluated using Boundary Precision/Recall (BPR) metrics comparing model output against gold standard annotations, testing both surface and underlying forms.

## Key Results
- Allomorphy is identified as the major source of segmentation errors in automated morpheme analysis
- Morfessor outperforms simple heuristics and subword tokenization methods in low-resource numeral systems
- Performance significantly improves when models are trained on underlying forms rather than surface forms

## Why This Works (Mechanism)

### Mechanism 1
Normalizing surface variation (allomorphy) significantly improves automated morpheme segmentation by reducing vocabulary size while increasing morpheme frequency. By mapping multiple surface variants to a single underlying form, statistical models can identify recurring compositional structures that are otherwise masked by phonetic variation.

### Mechanism 2
Minimum Description Length (MDL) models outperform frequency-based heuristics in low-resource, high-compositionality scenarios because they explicitly optimize for compact lexicon and concise representation. This matches the generative nature of numerals, which are designed to maximize expressivity with minimal morpheme inventories.

### Mechanism 3
Subword tokenization algorithms fail to discover morphemes in low-resource settings due to a mismatch in stopping criteria and local optimization. These algorithms are designed to build vocabularies for compression or NLP performance, not linguistic interpretability, and operate on local co-occurrence patterns that don't align with morpheme boundaries in small datasets.

## Foundational Learning

- **Concept:** Allomorphy vs. Surface Forms
  - **Why needed here:** The paper centers on distinguishing phonetic realization (surface) from abstract morpheme (underlying). Understanding that one meaning can have multiple forms is essential for diagnosing segmentation errors.
  - **Quick check question:** If a model segments "walked" and "ran" differently because of spelling, what linguistic concept is it failing to capture regarding the past tense morpheme?

- **Concept:** Minimum Description Length (MDL)
  - **Why needed here:** Morfessor's success is attributed to MDL principles. The model seeks the shortest possible "code" (grammar + lexicon) to generate observed data.
  - **Quick check question:** Why would a model prefer splitting "re+run" over keeping it as one token in a small dataset, assuming "re" appears in other words?

- **Concept:** Boundary Precision and Recall (BPR)
  - **Why needed here:** This is the specific evaluation metric used. Precision measures "how many predicted boundaries were correct" and Recall measures "how many actual boundaries were found."
  - **Quick check question:** If a model predicts a boundary in every single character position, it would have perfect Recall but terrible Precision. Why?

## Architecture Onboarding

- **Component map:** CLDF wordlists -> EDICTOR annotation -> LinSe processing -> Morfessor/LSPE models -> BPR evaluation
- **Critical path:**
  1. Load raw numeral strings (1-40) into EDICTOR
  2. Manually annotate morpheme boundaries (+) and map surface forms to underlying forms (inline alignment with /)
  3. Export annotated data to CLDF/CSV
  4. Run Morfessor on raw surface forms vs. underlying forms
  5. Calculate F1 scores to quantify the "allomorphy error gap"

- **Design tradeoffs:**
  - Manual vs. Automated: Manual annotation provides gold standard but doesn't scale to thousands of languages
  - Recall vs. Precision: Morfessor is tuned for high precision but tends to undersplit in complex systems
  - Monolingual Training: Models are trained per language, ignoring potential cross-linguistic transfer

- **Failure signatures:**
  - Undersplitting: Morfessor fails to segment German *zwanzig* even with underlying forms
  - Vocabulary Explosion: BPE fails to stop merging, creating "words" spanning multiple numerals
  - Alignment Drift: Improper surface/underlying form alignment causes automated evaluation failures

- **First 3 experiments:**
  1. Replicate the Allomorphy Gap: Train Morfessor on surface forms vs. underlying forms of a high-opacity language to quantify F1 drop
  2. Subword Stress Test: Run BPE on a perfectly regular system with oracle vocabulary size to check if it finds morphemes
  3. Heuristic Baseline: Implement simple Affix model and compare against Morfessor on limited dataset to see when statistical learning beats dictionary lookup

## Open Questions the Paper Calls Out

- **Question:** Can information-theoretic measures be adapted to accurately quantify the morphological complexity of numeral systems?
  - **Basis in paper:** The Conclusion states it "remains an open question if (and how) the morphological complexity of a numeral system or a language in general can be measured."
  - **Why unresolved:** Standard metrics correlated almost perfectly with vocabulary size, failing to capture structural nuances because numeral morphemes don't follow Zipfian distribution.
  - **What evidence would resolve it:** A metric that correlates with intuitive complexity but remains independent of morpheme inventory size.

- **Question:** How can unsupervised morpheme segmentation models be improved to handle allomorphy in low-resource scenarios?
  - **Basis in paper:** Authors identify allomorphy as the "major reason for segmentation errors" and conclude that "handling of allomorphy will therefore be crucial" for future research.
  - **Why unresolved:** Current models perform significantly worse on surface forms compared to underlying forms where allomorphy is manually normalized.
  - **What evidence would resolve it:** A model achieving comparable F1 scores on raw surface forms and normalized underlying forms without prior language knowledge.

- **Question:** Do the statistical correlations between morpheme inventory size and expressivity hold across a typologically balanced sample?
  - **Basis in paper:** The sample is "heavily biased towards Indo-European and Sino-Tibetan languages" and lacks representation from Africa, North America, and Papunesia.
  - **Why unresolved:** Observed patterns rely on a small sample that may not reflect universal tendencies or full diversity of numeral base systems.
  - **What evidence would resolve it:** Replication on expanded dataset including missing macroareas and wider variety of non-decimal bases.

## Limitations

- Manual annotation framework doesn't scale to thousands of languages with numeral systems
- Evaluation confined to fixed range (1-40), excluding higher compositional structures like hundred/thousand multipliers
- Assumes underlying forms can be reliably reconstructed, which may be arbitrary for highly fossilized or lexicalized numerals

## Confidence

- **High:** Allomorphy is the major source of segmentation errors (directly supported by quantitative comparisons)
- **Medium:** Superiority of Morfessor over baselines (controlled experimental setup, but relative performance might shift with different parameters)
- **Low:** Subword tokenization methods are "not viable" in low-resource scenarios (narrow range of settings tested, no exploration of alternative stopping criteria)

## Next Checks

1. **Scalability Test:** Apply annotation framework to larger, more diverse set of languages (50-100) to quantify annotation effort and error rates, testing whether automated alignment methods can approximate manual annotation quality

2. **Boundary Condition:** Test Morfessor and subword tokenization on numeral systems with known extreme allomorphy or non-compositional forms to verify claimed failure modes

3. **Cross-linguistic Transfer:** Train a single Morfessor model on multilingual corpus of numerals and compare performance to monolingual models to assess whether compositional regularities across languages can be exploited