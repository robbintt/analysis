---
ver: rpa2
title: 'Leveraging LLMs for Design Ideation: An AI Tool to Assist Creativity'
arxiv_id: '2512.00010'
source_url: https://arxiv.org/abs/2512.00010
tags:
- ideation
- design
- participants
- creativity
- ideas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores how Generative AI can augment human creativity
  during design ideation by providing structured inspirational stimuli. The authors
  developed ALIA (Analogical LLM Ideation Agent), a tool that uses speech-based interaction
  with a Large Language Model to deliver context-aware prompts derived from synectics
  and dialectics frameworks.
---

# Leveraging LLMs for Design Ideation: An AI Tool to Assist Creativity

## Quick Facts
- arXiv ID: 2512.00010
- Source URL: https://arxiv.org/abs/2512.00010
- Reference count: 2
- Key result: Speech-based AI assistant ALIA improved perceived idea quality during collaborative design ideation when using structured synectics/dialectics prompts

## Executive Summary
This study explores how Generative AI can augment human creativity during design ideation by providing structured inspirational stimuli. The authors developed ALIA (Analogical LLM Ideation Agent), a tool that uses speech-based interaction with a Large Language Model to deliver context-aware prompts derived from synectics and dialectics frameworks. Three pilot studies tested the functionality, leading to refinements like condition-based stimulus delivery during conversational pauses. Experiments compared ideation sessions with and without ALIA assistance across 12 groups (2 participants each). Results showed that participants rated their ideas higher when assisted by ALIA, with 90% reporting medium to high engagement levels. The tool successfully provided timely inspiration without disrupting creative flow, suggesting LLMs can effectively support divergent thinking in collaborative ideation when properly structured and integrated.

## Method Summary
The study developed ALIA, a speech-based AI assistant using Mistral 7b LLM with COSTAR prompting framework. The system follows a four-stage ideation process (starter questions → keyword excursions → analogical triggers → dialectic synthesis) and delivers stimuli only after minimum stage time and 8-second silence are detected. Participants (12 groups of 2) worked on design problems while either using ALIA or traditional methods, with qualitative and quantitative feedback collected on idea quality and engagement.

## Key Results
- Participants rated their ideas as higher quality when assisted by ALIA compared to control groups
- 90% of participants reported medium to high engagement levels with the AI tool
- ALIA successfully provided timely inspiration without disrupting creative flow during ideation sessions

## Why This Works (Mechanism)

### Mechanism 1: Structured Inspirational Stimuli via Synectics and Dialectics
When LLMs deliver contextually relevant, theoretically grounded stimuli during ideation, participants report higher perceived idea quality, provided the stimuli are timed to minimize cognitive disruption. ALIA uses a structured four-stage ideation framework derived from synectics and dialectics. The LLM generates stimuli specific to each stage (e.g., analogies, thesis-antithesis pairs) based on real-time conversation summaries. This guides divergent then convergent thinking cycles, preventing fixation and encouraging novel connections.

### Mechanism 2: Non-Disruptive Speech-Based Interaction with Condition-Based Delivery
Speech-based interaction with an LLM, when coupled with condition-based stimulus delivery, reduces disruption to the creative flow compared to text-based input, leading to higher user engagement. ALIA transcribes spoken conversation in real-time and delivers stimuli only when minimum time has elapsed and 8-second silence is detected. This prevents the AI from interrupting active discussion while maintaining the flow of creative thinking.

### Mechanism 3: Augmenting (Not Automating) Human Creativity with Real-time Context Awareness
LLMs effectively augment human creativity in collaborative ideation when the system is explicitly designed as an assistive partner that respects user agency, rather than an autonomous idea generator. ALIA is framed as an "assistive system" that provides "inspiration" and "unexpected leads" based on user conversation, not final solutions. Users are explicitly reminded they can disregard irrelevant stimuli, ensuring humans remain central to the ideation process.

## Foundational Learning

- **Concept: Synectics and Dialectics as Ideation Frameworks**
  - Why needed: These are the core theoretical engines driving ALIA's prompt generation
  - Quick check: Can you explain how the "thesis-antithesis-synthesis" triad from dialectics would generate a prompt for a team trying to design a "sustainable water bottle"?

- **Concept: Convergent vs. Divergent Thinking**
  - Why needed: The entire ALIA system is architected to guide users through repeated cycles of divergence and convergence
  - Quick check: In the ALIA workflow, which stage is primarily designed to induce *divergent* thinking, and what kind of LLM stimulus would support it?

- **Concept: COSTAR Prompt Engineering Framework**
  - Why needed: The paper explicitly states this framework is used to structure prompts sent to the LLM
  - Quick check: Using the COSTAR framework, how would you structure a prompt to ask an LLM to act as a "critical friend" providing "constructive critique"?

## Architecture Onboarding

- **Component map:** Microphone (speech-to-text) → Summarization → Logic checks (stage time + silence) → LLM API call (Mistral 7b) → Screen display. Parallel path: LDR sensor → Stage advancement → Reset conditions.
- **Critical path:** Audio from users → Speech-to-text → Summarization → Logic checks if (stage_time_elapsed AND 8s_silence_detected) → If true, construct prompt with summary + stage-specific template → Call LLM API → Display response on screen.
- **Design tradeoffs:**
  - Timeliness vs. Disruption: 8-second silence threshold balances providing stimuli without interruption
  - Model Capability vs. Cost/Latency: Mistral 7b chosen for real-time responsiveness
  - Structure vs. Flexibility: Four-stage structure provides guidance but may not fit all problem types
- **Failure signatures:**
  - The "Conversation Stopper": Confusing or off-topic stimuli derail team discussion
  - The "Echo Chamber": LLM suggests generic ideas causing conventional thinking
  - The "Silence Standoff": 8-second trigger interrupts thoughtful pauses
  - The "Handoff Failure": LDR sensor doesn't register user gesture
- **First 3 experiments:**
  1. Ablation Study on Silence Threshold: Test different silence triggers (4s, 8s, 12s) measuring perceived disruption and prompt relevance
  2. Blinded Output Evaluation: Have experts rate anonymized ideas from ALIA-assisted vs control groups on novelty and usefulness
  3. Model Swap Test: Run same system with different LLMs (GPT-3.5, Claude) to evaluate response consistency and quality

## Open Questions the Paper Calls Out
- Does ALIA-assisted ideation result in objectively higher idea novelty and quality compared to traditional methods, despite participants rating them subjectively higher?
- How does the effectiveness of ALIA differ when used by professional designers compared to the novice undergraduate population tested?
- Can the COSTAR prompting framework used by ALIA function effectively across different Large Language Model architectures beyond Mistral 7b?
- How does AI intervention specifically alter the cognitive patterns of convergence and divergence during the ideation process?

## Limitations
- Conclusions rely entirely on participant self-ratings rather than independent evaluation of idea quality
- Small sample size (12 groups) limited to undergraduate students aged 18-20, raising generalizability concerns
- Specific LLM prompts referenced but not fully specified, making exact reproduction difficult

## Confidence
- High confidence: The tool successfully delivered stimuli without disrupting creative flow, evidenced by 90% engagement rate
- Medium confidence: ALIA-assisted groups rated their ideas higher, though based on self-reported measures with potential bias
- Medium confidence: Speech-based interaction with condition-based delivery reduces disruption compared to text-based input

## Next Checks
1. Conduct a blinded evaluation where expert judges rate the novelty and usefulness of ideas generated with and without ALIA assistance
2. Test different silence thresholds (4s, 8s, 12s) across multiple ideation sessions to empirically determine optimal balance
3. Run a comparative study using different LLM backends (Mistral 7b vs GPT-4 vs Claude) to assess dependence on model capability