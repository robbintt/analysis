---
ver: rpa2
title: 'Generating Synthetic Oracle Datasets to Analyze Noise Impact: A Study on Building
  Function Classification Using Tweets'
arxiv_id: '2503.22856'
source_url: https://arxiv.org/abs/2503.22856
tags:
- tweets
- synthetic
- dataset
- noise
- building
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the underexplored impact of sentence-level
  feature noise in social media data for building function classification. To enable
  controlled analysis, we generate a synthetic oracle dataset using an LLM, containing
  only semantically relevant, correctly labeled tweets.
---

# Generating Synthetic Oracle Datasets to Analyze Noise Impact: A Study on Building Function Classification Using Tweets

## Quick Facts
- arXiv ID: 2503.22856
- Source URL: https://arxiv.org/abs/2503.22856
- Reference count: 24
- Key outcome: mBERT outperforms Naïve Bayes on synthetic data (91% vs. 84% accuracy) but performs similarly on real data, highlighting that handling feature noise is more critical than model complexity.

## Executive Summary
This study investigates how sentence-level feature noise in social media data impacts building function classification. To enable controlled analysis, the authors generate a synthetic oracle dataset using an LLM, conditioned on real building metadata and tweet language distributions to ensure realism. They evaluate the dataset using Self-BLEU and perplexity for diversity, and test classifier performance across real, synthetic, and cross-domain settings. Results show that mBERT's contextual learning is severely impaired by feature noise in real data, performing similarly to Naïve Bayes, while on the noise-free synthetic dataset, mBERT significantly outperforms Naïve Bayes. This highlights that handling feature noise is more critical than model complexity. The synthetic dataset provides a controlled environment for future noise injection studies and is publicly available on GitHub.

## Method Summary
The method involves generating a synthetic oracle dataset using Llama-3.3-70B-Instruct to produce tweets conditioned on building metadata from OpenStreetMap (building_tag, building_name, building_city) and real-world tweet language distributions. The dataset is evaluated for diversity using 4-gram Self-BLEU and perplexity, then used to train and test two classifiers (Naïve Bayes and mBERT) under three configurations: Real-world, Synthetic, and Cross-Domain. The study uses building-level 80/20 splits and reports classification metrics (precision, recall, F1, accuracy).

## Key Results
- mBERT significantly outperforms Naïve Bayes on synthetic data (91% vs. 84% accuracy).
- On real data, mBERT performs similarly to Naïve Bayes (65% accuracy), indicating severe degradation from feature noise.
- Synthetic tweets are more repetitive (Self-BLEU 48.37%) than real tweets (40.78%), suggesting a trade-off between semantic correctness and structural diversity.

## Why This Works (Mechanism)

### Mechanism 1: Metadata-Conditioned Grounding
If synthetic data generation is conditioned on specific, real-world metadata attributes (building function, name, city), the resulting text exhibits higher semantic relevance to the target class than heuristically collected real data. The pipeline retrieves structured building attributes from OpenStreetMap and injects them into the LLM prompt, forcing the generative model to produce text describing activities specific to that building type. This effectively filters out sentence-level feature noise prevalent in real geo-tagged datasets.

### Mechanism 2: Isolation of Feature Noise via Oracle Comparison
If a dataset is noise-free (oracle), the performance gap between simple statistical models (Naïve Bayes) and contextual models (mBERT) should reveal the true cost of feature noise in real data. By evaluating models on synthetic data (guaranteed relevant) vs. real data (noisy), the study isolates feature noise as the suppressor of contextual learning. In the synthetic setting, mBERT leverages semantic nuances, while in the noisy real setting, it degrades to keyword-matching levels, closing the gap with Naïve Bayes.

### Mechanism 3: Distributional Realism via Language Constraints
Constraining the language and volume of synthetic tweets to match real-world statistical distributions improves the utility of the synthetic dataset for specific downstream tasks. The pipeline uses a "Tweets Language Distribution" list derived from real datasets to dictate exactly how many tweets per language to generate per building, preserving the multilingual imbalance and frequency seen in the wild.

## Foundational Learning

- **Concept: Weak Supervision & Feature Noise**
  - Why needed: The paper defines the problem as classification under weak supervision, where data is collected via heuristics rather than verified labels. Distinguishing Label Noise (wrong tag) from Feature Noise (irrelevant text content) is critical for interpreting results.
  - Quick check: If a tweet says "I hate waiting here" at a hospital, is this label noise or feature noise if the building is actually a residential home? (Answer: Feature noise—the text is uninformative/misleading relative to the true function).

- **Concept: Contextual vs. Statistical Learning**
  - Why needed: The core finding relies on the difference between Naïve Bayes (frequency-based) and mBERT (context-based). Understanding that transformers rely on semantic relationships which can be "drowned out" by noise is key to seeing why the oracle dataset "unlocks" mBERT.
  - Quick check: Why would mBERT perform only marginally better than Naïve Bayes on noisy data? (Answer: The signal-to-noise ratio is too low for mBERT to form useful contextual representations, forcing it to rely on surface-level keywords).

- **Concept: Synthetic Data Diversity Metrics (Self-BLEU)**
  - Why needed: The paper evaluates synthetic data not just by accuracy, but by Self-BLEU. A high Self-BLEU indicates the LLM is repetitive (mode collapse). Engineers must understand this trade-off: the oracle is "cleaner" but "less diverse" structurally.
  - Quick check: If Self-BLEU is high (48% vs 40% real), what does that imply about the synthetic tweets? (Answer: They are more repetitive in structure/phrasing than real human tweets).

## Architecture Onboarding

- **Component map:** OpenStreetMap metadata -> Preprocessing filter -> LLM Generator -> Evaluation Suite
- **Critical path:** The Metadata Preprocessing (Step 2) is the most fragile component. If the logic for "Ensuring label-tag consistency" fails, the oracle dataset will contain "clean" text for the wrong building function, invalidating the experiment.
- **Design tradeoffs:** Control vs. Diversity (trades natural human diversity for semantic control); Recall vs. Precision (filtering logic removes buildings with complex/multi-functional tags, favoring precision over recall).
- **Failure signatures:** Semantic Drift (LLM generates plausible but factually incorrect details); Domain Gap (models trained only on synthetic data generalize poorly to real data).
- **First 3 experiments:**
  1. Verify Semantic Correctness: Randomly sample 50 generated tweets and manually verify they plausibly describe the activity in the associated Building_tag.
  2. Noise Sensitivity Test: Inject varying amounts of random real tweets into the synthetic training set to observe the degradation curve of mBERT.
  3. Diversity Tuning: Adjust the LLM temperature or persona prompts to lower the Self-BLEU score closer to the real-world baseline (40.78%) without losing semantic correctness.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can techniques like controlled paraphrasing or persona variation increase the structural diversity of synthetic tweets without compromising semantic alignment? (The current generation pipeline results in repetitive sentence structures, creating a domain gap that limits the dataset's utility for transfer learning).

- **Open Question 2:** How do different types and levels of injected noise (e.g., label flipping vs. irrelevant content) individually and jointly impact model performance in a controlled setting? (The synthetic dataset provides a "clean starting point" for systematically injecting noise to isolate individual and combined effects).

- **Open Question 3:** To what extent does explicit geospatial grounding (e.g., city names, location references) in synthetic text influence model performance compared to semantic features alone? (The authors suggest using the dataset to compare performance with and without location-specific references).

- **Open Question 4:** Can the domain gap between clean synthetic data and noisy real-world data be bridged to improve cross-domain generalization? (The discussion notes that models trained on synthetic data "generalize poorly" to real-world tweets).

## Limitations
- The synthetic dataset may trade off structural diversity for semantic correctness, as evidenced by its higher Self-BLEU score, raising questions about whether performance gaps reflect noise reduction alone.
- The effectiveness of metadata grounding depends entirely on the accuracy of OSM tags, with no validation mechanism for detecting erroneous building classifications.
- Cross-domain experiments are vulnerable to domain shift if synthetic data lacks the informal linguistic patterns of real tweets.

## Confidence

- **High confidence:** Comparative performance results showing mBERT outperforming Naïve Bayes on synthetic data (91% vs. 84% accuracy) while performing similarly on real data.
- **Medium confidence:** The claim that feature noise is the primary suppressor of contextual learning, while plausible, cannot definitively exclude other potential confounding factors.
- **Low confidence:** The assertion that the synthetic dataset is "realistic" for robust model training is questionable given the significant Self-BLEU difference.

## Next Checks

1. **Semantic correctness audit:** Manually validate a stratified random sample of 100 synthetic tweets to confirm they accurately describe activities consistent with their assigned building tags.
2. **Controlled noise injection study:** Systematically inject varying proportions of real-world tweets (5%, 10%, 25%, 50%) into the synthetic training set and measure the degradation curve of mBERT performance.
3. **Diversity calibration experiment:** Adjust the LLM generation parameters to reduce the Self-BLEU score of synthetic data to match the real-world baseline (40.78%) while maintaining semantic correctness, then retrain classifiers.