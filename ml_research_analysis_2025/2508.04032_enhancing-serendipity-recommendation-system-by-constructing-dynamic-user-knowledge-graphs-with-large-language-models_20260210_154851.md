---
ver: rpa2
title: Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge
  Graphs with Large Language Models
arxiv_id: '2508.04032'
source_url: https://arxiv.org/abs/2508.04032
tags:
- user
- recommendation
- reasoning
- language
- interests
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the filter bubble problem in recommendation
  systems by leveraging large language models (LLMs) to construct dynamic user knowledge
  graphs and perform two-hop reasoning to identify users'' potential interests. The
  proposed method consists of two stages: (1) dynamic user knowledge graph construction
  using LLMs and two-hop reasoning to infer potential interests, enhanced by multi-agent
  debate to ensure reasoning accuracy; and (2) near-line adaptation with a novel u2i
  retrieval model that integrates i2i retrieval capabilities through multi-task learning.'
---

# Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge Graphs with Large Language Models

## Quick Facts
- **arXiv ID:** 2508.04032
- **Source URL:** https://arxiv.org/abs/2508.04032
- **Reference count:** 40
- **Primary result:** LLM-based dynamic user knowledge graphs + two-hop reasoning + multi-agent debate + hybrid retrieval improves novelty rates by 4-5% and engagement metrics by 0.1-0.3% in industrial deployment.

## Executive Summary
This paper addresses the filter bubble problem in recommendation systems by leveraging large language models (LLMs) to construct dynamic user knowledge graphs and perform two-hop reasoning to identify users' potential interests. The proposed method consists of two stages: (1) dynamic user knowledge graph construction using LLMs and two-hop reasoning to infer potential interests, enhanced by multi-agent debate to ensure reasoning accuracy; and (2) near-line adaptation with a novel u2i retrieval model that integrates i2i retrieval capabilities through multi-task learning. The system was deployed on the Dewu app with tens of millions of users, achieving significant improvements in novelty rates and engagement metrics while maintaining conversion rates.

## Method Summary
The system uses static user profiles and recent search behaviors to construct dynamic user knowledge graphs via LLM reasoning. A two-hop reasoning process first identifies core motivations/demands from behavior, then maps these demands to related product categories. A multi-agent debate process validates the reasoning chain. The LLM's outputs are distilled into a smaller InterestGPT model for efficient inference. A hybrid u2i retrieval model with contrastive learning loss integrates both user-item and item-item retrieval capabilities, allowing the system to recommend items relevant to newly inferred interests while maintaining conversion rates.

## Key Results
- 4.62% increase in exposure novelty rate
- 4.85% increase in click novelty rate
- 0.15% increase in average view duration per person
- 0.07% increase in unique visitor click-through rate
- 0.30% increase in unique visitor interaction penetration

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dynamic user knowledge graphs constructed via LLMs can identify potential interests beyond historical behavior patterns.
- **Mechanism:** The system uses static profiles and recent search behaviors as input nodes to an LLM, which performs two-hop reasoning: identifying core motivations from behavior, then mapping these demands to related product categories. A multi-agent debate validates the reasoning chain.
- **Core assumption:** LLMs possess sufficient world knowledge to infer meaningful connections between user behaviors and latent interests.
- **Evidence anchors:** [abstract] "user static profiles and historical behaviors are utilized to dynamically construct user knowledge graphs via llm. Two-hop reasoning... is then performed on the constructed graphs to identify users' potential interests"
- **Break condition:** If LLM-generated interests are too broad, too narrow, or factually disconnected from actual user preferences, the retrieval model will receive irrelevant signals, degrading recommendation quality.

### Mechanism 2
- **Claim:** Multi-agent debate improves factual validity and reduces hallucinations in LLM reasoning.
- **Mechanism:** Multiple LLM instances independently propose reasoning paths and potential interests, then engage in iterative debate rounds challenging each other's outputs. A consensus answer is reached through cross-validation.
- **Core assumption:** The debate process converges toward more accurate answers by leveraging diverse reasoning paths and critical evaluation.
- **Evidence anchors:** [abstract] "enhanced by multi-agent debate to ensure reasoning accuracy"
- **Break condition:** If debate process fails to converge, introduces new biases, or computational cost outweighs quality gains, the method becomes impractical.

### Mechanism 3
- **Claim:** A hybrid u2i retrieval model with interest-aligned contrastive loss can effectively retrieve items for newly inferred interests without sacrificing conversion rates.
- **Mechanism:** The retrieval model is a dual-tower architecture trained with BCE loss for user-click prediction and a contrastive learning loss that aligns user embeddings (conditioned on interest embeddings) with item embeddings relevant to that interest.
- **Core assumption:** This hybrid loss allows the model to generalize to new interest embeddings while maintaining relevance and conversion performance.
- **Evidence anchors:** [abstract] "u2i (user-to-item) retrieval model that also incorporates i2i (item-to-item) retrieval capabilities"
- **Break condition:** If contrastive loss fails to create well-aligned embedding space for novel interests, retrieved items will be irrelevant. If BCE loss dominates, the model will revert to recommending historically popular items.

## Foundational Learning

- **Concept: Serendipity Recommendation**
  - **Why needed here:** This is the core objective, defined as a combination of unexpectedness and relevance. The entire system architecture is built to achieve this balance.
  - **Quick check question:** How does serendipity differ from simple diversity in recommendations? (Answer: Serendipity requires the unexpected item to also be relevant/interesting to the user, whereas diversity just ensures items in a list are dissimilar).

- **Concept: Knowledge Graph (KG) & Two-Hop Reasoning**
  - **Why needed here:** The proposed method uses an LLM to construct a dynamic KG where nodes are user interests/products and edges are relationships. Understanding multi-hop reasoning is essential to grasp how the model infers latent interests.
  - **Quick check question:** In a KG, what does a two-hop path from a user's historical query to a potential product signify? (Answer: It represents an inference chain, e.g., Query "thermos" -> Core Demand "health preservation" -> Potential Product "multivitamins").

- **Concept: Model Distillation (Supervised Fine-Tuning)**
  - **Why needed here:** The system cannot use a large, slow model for real-time inference at scale. Distilling its knowledge into a smaller, faster model is a critical operational step.
  - **Quick check question:** Why is distillation necessary in this architecture? (Answer: To reduce computational cost and latency for generating user interest profiles in an industrial setting).

## Architecture Onboarding

- **Component map:** Input (User Static Profile + User Historical Behaviors) -> Offline Stage (LLM Builder + Debate Engine + Distillation -> InterestGPT) -> Near-line Stage (InterestGPT generates and caches user potential interest keywords) -> Online Stage (Interest Embedder + Hybrid Retrieval Model + Ranker) -> Output (Final recommendation list)

- **Critical path:** The quality of the entire system hinges on the Offline Stage. If the LLM Builder/Debate Engine fails to produce high-quality, relevant, and surprising potential interests, then both the Near-line cache and the Online Retrieval model will operate on garbage signals, leading to irrelevant recommendations.

- **Design tradeoffs:**
  - **Latency vs. Quality:** Moving from online LLM inference to near-line caching with a distilled model sacrifices real-time personalization on the latest action for system stability and latency.
  - **i2i vs. u2i Retrieval:** A standard i2i model would be simpler but may not leverage global user-item interaction data effectively for conversion. A standard u2i model cannot handle interests not present in training data. The hybrid model is more complex but aims to capture the best of both.

- **Failure signatures:**
  - **Low CTR on Serendipity Channel:** Indicates the LLM is generating irrelevant or uninteresting "potential interests."
  - **Low Novelty Scores:** Indicates the model is not breaking the filter bubble. The contrastive learning loss may be dominated by the BCE loss, or the LLM reasoning may be too conservative.
  - **High Latency:** The near-line cache update is not fast enough, or the InterestGPT model inference is still too slow.

- **First 3 experiments:**
  1. **Offline Evaluation of Interest Generation:** Manually label a sample of LLM-generated potential interests (with and without multi-agent debate) on criteria of "surprise" and "relevance" (Score 0, 1, 2).
  2. **A/B Test of Hybrid Retrieval Model:** Compare the hybrid u2i model against a strong baseline using online metrics like UVCTR, Average Duration, and Novelty Rate.
  3. **Ablation Study on Interest Channel:** Conduct an A/B test comparing the full system (baseline + serendipity channel) against the baseline system alone to measure end-to-end impact.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can LLMs accurately capture users' potential interests when incorporating denser behavioral data (e.g., clicks) rather than just sparse search queries, and does a scaling law exist for the volume of behavioral data?
- **Open Question 2:** How can users' newly inferred interests be effectively integrated into downstream ranking stages (coarse, fine, and re-ranking) to enhance scoring accuracy?
- **Open Question 3:** How can feedback data from the recommendation context be leveraged to calibrate the interests generated by LLMs to prevent excessive divergence and improve relevance?

## Limitations

- The evaluation framework presents novelty improvements without clear baseline comparisons or statistical significance tests.
- System effectiveness is narrowly validated on a single e-commerce platform (Dewu) with specific user demographics, limiting generalizability.
- The multi-agent debate mechanism lacks ablation studies demonstrating its specific contribution beyond standard two-hop reasoning.

## Confidence

- **High Confidence:** The overall industrial deployment and integration of LLMs for serendipity recommendation is technically feasible and demonstrates measurable improvements in business metrics.
- **Medium Confidence:** The two-hop reasoning mechanism can generate novel interests beyond historical behavior patterns, but the specific contribution of multi-agent debate remains uncertain.
- **Low Confidence:** The claim that the hybrid u2i retrieval model can simultaneously achieve high relevance for novel interests AND maintain conversion rates is weakly supported without direct comparisons against strong baselines.

## Next Checks

1. **Ablation Study on Interest Generation Quality:** Conduct a controlled experiment comparing the full LLM+debate pipeline against a baseline LLM without debate, measuring both offline human evaluation scores and online novelty metrics.

2. **Retrieval Model Benchmark Comparison:** Implement and A/B test the hybrid u2i retrieval model against a strong baseline consisting of standard i2i and u2i retrieval models, measuring novelty, CTR, and conversion rate.

3. **Cross-Domain Generalizability Test:** Deploy the system on a different e-commerce platform or content recommendation domain (e.g., news, music) and measure whether the same novelty gains and reasoning quality are achieved.