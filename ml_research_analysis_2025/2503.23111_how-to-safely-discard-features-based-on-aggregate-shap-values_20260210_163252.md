---
ver: rpa2
title: How to safely discard features based on aggregate SHAP values
arxiv_id: '2503.23111'
source_url: https://arxiv.org/abs/2503.23111
tags:
- shap
- values
- lemma
- value
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the soundness of using aggregate SHAP values
  for global feature importance and feature selection. It demonstrates that small
  aggregate SHAP values do not necessarily imply a feature is globally irrelevant,
  providing counterexamples where SHAP values are zero on the data support but the
  function clearly depends on the feature.
---

# How to safely discard features based on aggregate SHAP values

## Quick Facts
- arXiv ID: 2503.23111
- Source URL: https://arxiv.org/abs/2503.23111
- Reference count: 40
- Primary result: Small aggregate SHAP values over data support don't imply feature irrelevance; aggregating over extended support (product of marginals) provides sound feature selection guarantees

## Executive Summary
This paper addresses a fundamental problem in feature selection: determining when a feature can be safely discarded based on aggregate SHAP values. The authors demonstrate that standard SHAP aggregation over the data support can produce zero values even when features are functionally relevant, leading to false negatives in feature selection. They propose aggregating SHAP values over the "extended support" - the product of marginal distributions of the underlying data distribution. This approach ensures that constant-zero SHAP values correctly identify globally irrelevant features. The method is extended to KernelSHAP through a column permutation technique that creates a finite-sample approximation of the extended distribution, enabling practical implementation.

## Method Summary
The method involves computing aggregate KernelSHAP values over an "extended support" to determine feature relevance. Instead of using the original data as background, each feature column is independently permuted to break correlations and simulate the product of marginals distribution. KernelSHAP is then computed using this scrambled data as the background reference. Features with aggregate values below a threshold ε can be safely discarded, with theoretical guarantees that prediction error increases by less than d²ε.

## Key Results
- Small aggregate SHAP values over data support do not imply global feature irrelevance
- Constant-zero SHAP values over extended support guarantee feature can be safely discarded
- Column permutation creates finite-sample approximation of extended distribution for KernelSHAP
- The limit object of KernelSHAP satisfies necessary algebraic properties for soundness

## Why This Works (Mechanism)

### Mechanism 1: Extended Support for Soundness
Standard SHAP evaluates the model f on points outside the data support supp(μ). A function can be "strategically" defined to mask its dependence on a feature within the support, resulting in zero SHAP values there. By forcing the aggregation over the *extended support* supp(μ*)—where features vary independently according to their marginals—this masking is broken. The authors prove that if the SHAP operator Φᵢ is zero over the extended support, the function is strictly determined by the remaining features.

### Mechanism 2: Column Permutation as Extended Distribution Sampling
Randomly permuting each column of a data matrix creates a sample from the extended distribution, satisfying the conditions for safe feature discarding in the finite sample regime. The extended distribution μ* is the product of marginals. In a finite dataset, shuffling each feature column independently destroys inter-feature correlations, effectively sampling from μ*.

### Mechanism 3: KernelSHAP Linear Operator Independence
Aggregate KernelSHAP values computed over the extended distribution provide soundness guarantees regardless of whether KernelSHAP perfectly approximates true SHAP values. The limit object of the KernelSHAP algorithm is a linear combination of value operators. The authors show this operator satisfies the same algebraic properties (specifically regarding the "Shapley Lie algebra") as the true SHAP operator.

## Foundational Learning

- **Concept: Interventional Value Function (vₛ)**
  - Why needed: Understanding that SHAP relies on expectations over marginal distributions (not conditionals) is key to understanding why it evaluates functions "off the data support" and creates the vulnerability this paper addresses.
  - Quick check: Does interventional SHAP assume features are independent when calculating the contribution of a coalition S?

- **Concept: Determined Function**
  - Why needed: This is the formal definition of "discarding a feature." A feature is discarded if the function's output is constant with respect to that feature across the relevant domain.
  - Quick check: If f(x₁, x₂) = x₁ + x₂, is f determined by {x₁} alone?

- **Concept: Solvable Lie Algebra**
  - Why needed: The paper uses this to prove that the SHAP operator Aᵢ is invertible. One needs to know this implies that if Aᵢf = 0, then f must be zero (or in a specific subspace), preventing the "masking" effect.
  - Quick check: Why does proving an operator has a trivial kernel help us determine if a function depends on a specific variable?

## Architecture Onboarding

- **Component map:** Data Matrix X → Column Scrambler → KernelSHAP Explainer → Aggregator → Selector
- **Critical path:** The Scrambler → Explainer interaction. If the explainer is run on raw X instead of X*, the safety guarantees vanish.
- **Design tradeoffs:**
  - Guarantee vs. Context: Using the extended support (X*) breaks feature correlations. This provides theoretical soundness for *discarding* but changes the explanation context.
  - Approximation Error: The method relies on KernelSHAP convergence (η). Very small datasets might introduce high variance in the permutation step.
- **Failure signatures:**
  - The "Ring" Failure: High dependence but zero SHAP values (occurs if using standard aggregation on non-full support data).
  - Regression Collapse: KernelSHAP returning zeros due to insufficient background data samples in the scrambled set.
- **First 3 experiments:**
  1. Validation on Synthetic Counterexample: Implement the "ring" function and verify that standard SHAP fails while Scrambled KernelSHAP succeeds.
  2. Correlation Ablation: Compare feature rankings from standard SHAP vs. Scrambled SHAP on correlated data.
  3. Recovery Test: Train model, discard features with ε threshold using proposed method, retrain, and verify prediction accuracy remains stable.

## Open Questions the Paper Calls Out

- Can the Shapley Lie algebra be applied to derive theoretical properties for SHAP beyond feature selection, such as characterizing feature interactions or stability?
- Is the O(d²) dependency in the approximation bound of Theorem 11 tight, or can it be improved to be linear in dimension?
- Does aggregating SHAP values over the extended support (scrambled data) perform better empirically for feature selection than standard SHAP or established baselines like LOCO?
- Can soundness guarantees be established for aggregate *observational* SHAP values using a modified definition of extended support?

## Limitations
- Paper lacks specific numerical thresholds for determining when an aggregate value is "small enough" to justify feature removal
- Column permutation assumes sufficient sample size for empirical marginals to approximate true distributions
- Theoretical soundness doesn't guarantee practical efficiency or superior performance compared to other selection methods

## Confidence
- **High Confidence:** Mathematical proofs establishing that constant-zero SHAP values over extended support guarantee feature irrelevance
- **Medium Confidence:** Practical effectiveness of column permutation method for approximating extended distribution
- **Low Confidence:** Shapley Lie algebra provides generalizable framework beyond this specific application

## Next Checks
1. Implement the "ring" function counterexample to verify the theoretical findings
2. Test column permutation method across datasets of varying sizes to determine minimum sample requirements
3. Compare feature selection performance against standard SHAP and LOCO on real-world datasets with known ground-truth relevance