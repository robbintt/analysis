---
ver: rpa2
title: 'MDSF: Context-Aware Multi-Dimensional Data Storytelling Framework based on
  Large language Model'
arxiv_id: '2501.01014'
source_url: https://arxiv.org/abs/2501.01014
tags:
- data
- arxiv
- storytelling
- mdsf
- insight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MDSF, a context-aware framework for multi-dimensional
  data storytelling using LLMs. It tackles challenges in automated insight discovery
  and narrative generation by integrating advanced preprocessing, augmented analysis,
  and a scoring mechanism to rank actionable insights.
---

# MDSF: Context-Aware Multi-Dimensional Data Storytelling Framework based on Large language Model

## Quick Facts
- arXiv ID: 2501.01014
- Source URL: https://arxiv.org/abs/2501.01014
- Authors: Chengze Zhang; Changshan Li; Shiyang Gao
- Reference count: 40
- Key outcome: Framework automates multi-dimensional data storytelling with fine-tuned LLMs, achieving Spearman Footrule Distance of 6.82, accuracy of 0.858, and competitive BLEU/ROUGE scores on private datasets

## Executive Summary
MDSF introduces a context-aware framework for automated multi-dimensional data storytelling using large language models. The system addresses challenges in insight discovery and narrative generation through advanced preprocessing, augmented analysis algorithms, and a unique multi-angle scoring mechanism. By fine-tuning LLMs on domain-specific insights and implementing an agent-based context tracking system, MDSF generates coherent narratives while maintaining real-time adaptation to user interactions. Experimental results demonstrate superior performance over existing methods on private business datasets.

## Method Summary
MDSF processes multi-dimensional data through a pipeline that includes data preprocessing with subspace enumeration and aggregation pre-computation, augmented analysis using Prophet, SR-CNN, iForest, and 3-sigma algorithms for pattern detection, and insight extraction with a five-component scoring mechanism. The framework fine-tunes LLaMA3-7B and Qwen2-7B models using LLaMA-Factory on manually ranked insights from a private dataset. An online context-aware agent tracks user editing history and profile to generate real-time narrative continuations. The system evaluates performance across ranking accuracy (Spearman Footstyle Distance), description accuracy, and story generation quality (BLEU/ROUGE scores).

## Key Results
- Achieves Spearman Footstyle Distance of 6.82 on private dataset, outperforming existing methods
- Attains description accuracy of 0.858 through fine-tuned LLM ranking
- Demonstrates competitive BLEU score of 0.825 and ROUGE score of 0.537 on story generation tasks
- User studies show improvements in structure, conclusion extraction, and content richness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The multi-angle scoring mechanism enables effective prioritization of actionable insights from high-dimensional data.
- **Mechanism:** The framework computes five orthogonal scores—Importance, Significance, Surprise, Fatigue, and Interpretability—then applies Top-K selection to surface the most valuable insights for narrative generation.
- **Core assumption:** Quantifiable dimensions of insight quality correlate with human analyst judgment and downstream narrative usefulness.
- **Evidence anchors:** Abstract mentions unique scoring mechanism; Section IV.A.3 details five scoring components with formulas for Imp and srp.
- **Break condition:** Scoring fails when data distributions are uniformly flat or when user feedback signals are sparse.

### Mechanism 2
- **Claim:** Fine-tuning LLMs on domain-specific insight rankings improves both ranking accuracy and description fidelity over base models.
- **Mechanism:** Human experts manually rank auto-discovered insights offline; this ranked data is used to fine-tune LLaMA3-7B and Qwen2-7B via LLaMA-Factory.
- **Core assumption:** Expert ranking preferences transfer to the fine-tuned model and generalize across similar business domains.
- **Evidence anchors:** Abstract mentions fine-tuned LLMs enhance contextual understanding; Section V.A describes fine-tuning process using LLaMA-Factory framework.
- **Break condition:** Fine-tuned models overfit to annotation distribution and fail on out-of-domain insight types.

### Mechanism 3
- **Claim:** The context-aware agent architecture enables coherent real-time story continuation by tracking editing history and user profile.
- **Mechanism:** The Context Agent parses user editing history, profile, and multi-scenario prompts in real time; it retrieves relevant insights from the precomputed library and generates narrative continuations that maintain coherence with prior context.
- **Core assumption:** Editing history and user profile provide sufficient signal to infer user intent and interest areas for dynamic insight selection.
- **Evidence anchors:** Abstract mentions agent-based mechanism for real-time storytelling continuation; Section IV.B.1 describes context encompassing user's editing history and modifications.
- **Break condition:** Context tracking fails when editing sessions span long durations with topic drift or when user profiles contain conflicting preference signals.

## Foundational Learning

- **Concept: Multi-dimensional data model (time, categorical, numerical dimensions)**
  - Why needed here: MDSF processes heterogeneous data types simultaneously; understanding how breakdowns, indicators, and filters operate on dimension subspaces is essential for debugging insight discovery.
  - Quick check question: Given a sales dataset with dimensions {region, month, product_category} and indicator {revenue}, what subspace is enumerated when breaking down by region with a filter on month=January?

- **Concept: Augmented analysis algorithms (Prophet, SR-CNN, iForest, 3-sigma)**
  - Why needed here: These algorithms detect patterns (anomalies, trends, periodicity) that become insight candidates; understanding their outputs helps interpret scoring behavior.
  - Quick check question: Why would SR-CNN be chosen over 3-sigma for time-series anomaly detection in a highly seasonal sales dataset?

- **Concept: LLM fine-tuning workflow (data annotation → training → inference)**
  - Why needed here: MDSF's ranking improvement hinges on the offline annotation and fine-tuning loop; engineers must understand where human-in-the-loop quality gates exist.
  - Quick check question: If the annotation team labels 1,000 insights but 30% have inconsistent rankings across annotators, what downstream effect would this have on the fine-tuned rank model?

## Architecture Onboarding

- **Component map:**
  Offline pipeline: Data sources → Data Parse & Preprocess (subspace enumeration, aggregation pre-computation, trimming) → Augmented Analysis (Prophet/SR-CNN/iForest/3-sigma) → Insight Extract → Manual Annotation → Rank Model Fine-tuning (LLaMA-Factory)
  Online pipeline: User edit context + multi-scenario prompts → Context Agent → Insight library retrieval → Fine-tuned LLM re-ranking → Description generation → Visualization binding → Story output

- **Critical path:** Data preprocessing quality determines insight candidate pool; manual annotation quality determines fine-tuned model effectiveness; context parsing accuracy determines real-time relevance. The annotation step is the highest-leverage quality gate.

- **Design tradeoffs:**
  Precomputation vs. latency: Subspace enumeration and aggregation are precomputed for speed, but limits ad-hoc filter combinations at inference time.
  Base model size vs. deployment cost: Fine-tuning 7B models (LLaMA3, Qwen2) balances performance and inference cost, but underperforms GPT-4 on complex story generation.
  Automation vs. control: Fully automated storytelling reduces manual effort but may miss domain-specific narrative preferences not captured in training data.

- **Failure signatures:**
  Insight pool exhaustion: When Top-K selection returns redundant insights, check Fatigue score weighting and subspace diversity.
  Hallucinated descriptions: If accuracy drops below 0.7, inspect fine-tuning data for label noise or domain drift.
  Context drift: When continuations become incoherent mid-session, verify that edit history window is not truncating critical context.

- **First 3 experiments:**
  1. Validate insight scoring alignment: Run MDSF on a held-out portion of the private dataset; compute correlation between automated scores and human expert rankings (target: Spearman ρ > 0.7).
  2. Ablate fine-tuning contribution: Compare ranking performance (SFD metric) between base LLaMA3-7B and fine-tuned version on InsightBench; quantify improvement delta.
  3. Test context coherence limits: Construct synthetic editing sessions with known topic shifts; measure at which point (number of edits or topic switches) the Context Agent produces irrelevant continuations.

## Open Questions the Paper Calls Out
- **Open Question 1:** How do alternative data partitioning configurations, such as stacking by time periods, impact the training efficiency and performance of MDSF compared to the current temporal split?
  - Basis in paper: Section V.A.1 states that due to space constraints, the authors adopted a specific setup for data partitioning and "leave empirical studies on other configurations for future work."
  - Why unresolved: The paper only utilized a standard split of oldest data for retrieval and newest for testing, leaving the potential benefits of more complex temporal stacking strategies unexplored.
  - What evidence would resolve it: A comparative ablation study showing MDSF performance metrics (SFD, Accuracy) when trained on datasets partitioned by different time-window stacking methods versus the baseline split.

- **Open Question 2:** Can the ranking algorithms be refined to bridge the remaining performance gap between the automated MDSF and manual human annotation?
  - Basis in paper: Table II shows that while MDSF outperforms other models, it still exhibits a Spearman Footstyle Distance (SFD) of 6.82 compared to the manual benchmark of 0.00.
  - Why unresolved: The authors conclude that MDSF has "good accuracy," but the non-zero distance indicates the model still misranks insights relative to human experts.
  - What evidence would resolve it: Demonstration of an updated MDSF version achieving an SFD statistically indistinguishable from 0.00 on the private dataset, or a qualitative analysis of the specific types of insights where the model still fails to match human ranking.

- **Open Question 3:** To what extent does MDSF rely on the bulk data annotation from the private domain to maintain its superior descriptive accuracy?
  - Basis in paper: The high accuracy (0.858) is attributed to a fine-tuning process based on a "bulk data annotation" derived from a specific private company dataset.
  - Why unresolved: It is unclear if the model's high performance on the private dataset transfers effectively to other domains without a similar, resource-intensive annotation phase.
  - What evidence would resolve it: Testing the fine-tuned MDSF model in a zero-shot or few-shot setting on a completely unseen industry domain (e.g., healthcare or scientific data) to evaluate if the descriptive accuracy holds without re-annotation.

## Limitations
- Relies on a private business dataset, making external validation difficult
- Scoring mechanism formulas provided for only two of five components
- Human annotation protocol for insight ranking ground truth not detailed
- Context-aware agent effectiveness depends on assumption that editing history reliably indicates intent

## Confidence
- Multi-angle scoring mechanism effectiveness: Medium confidence
- Fine-tuned LLM ranking improvement: Medium confidence
- Context-aware agent for real-time continuation: Medium confidence

## Next Checks
1. Test MDSF's insight scoring alignment on a public multi-dimensional dataset by comparing automated scores against human expert rankings
2. Implement ablation studies removing individual scoring components to quantify each component's contribution to overall ranking performance
3. Evaluate context coherence limits by constructing synthetic editing sessions with controlled topic shifts and measuring when the Context Agent produces irrelevant continuations