---
ver: rpa2
title: Machine Learning to Predict Digital Frustration from Clickstream Data
arxiv_id: '2512.20438'
source_url: https://arxiv.org/abs/2512.20438
tags:
- frustration
- user
- data
- features
- digital
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research uses machine learning to predict digital frustration
  from clickstream data. Frustration is defined using rules based on rage bursts,
  U-turns, cart churn, search struggle, and long wandering sessions.
---

# Machine Learning to Predict Digital Frustration from Clickstream Data

## Quick Facts
- **arXiv ID**: 2512.20438
- **Source URL**: https://arxiv.org/abs/2512.20438
- **Reference count**: 40
- **Primary result**: XGBoost achieves 90% accuracy, ROC AUC of 0.9579; LSTM achieves 91% accuracy, ROC AUC of 0.9705

## Executive Summary
This paper proposes a machine learning approach to predict digital frustration from e-commerce clickstream data. Frustration is defined through five rule-based heuristics (rage bursts, U-turns, cart churn, search struggle, long wandering) applied to 5.4 million events. The study compares XGBoost with tabular features (n-grams, HVG motifs) against LSTM models using raw interaction sequences. Results show that frustration can be reliably predicted from the first 20-30 user interactions, with LSTM achieving the best performance (91% accuracy, 0.9705 ROC AUC).

## Method Summary
The approach involves sessionizing raw clickstream data, applying rule-based frustration labeling, and training models to predict frustration status. To prevent shortcut learning, sessions are truncated at the first purchase event. Two feature pipelines are developed: tabular features (1/2-grams, HVG motifs) for XGBoost and raw symbol sequences for LSTM. The dataset is balanced to 50/50 frustration vs non-frustration, with sessions filtered to 2-1000 interactions. Models are evaluated on accuracy, F1-score, and ROC AUC metrics.

## Key Results
- LSTM achieves 91% accuracy and 0.9705 ROC AUC, outperforming XGBoost's 90% accuracy and 0.9579 ROC AUC
- Reliable predictions can be made from the first 20-30 interactions in a session
- Feature importance analysis shows n-gram and motif features are most influential for frustration detection
- Truncation at first purchase prevents shortcut learning and ensures models detect behavioral patterns

## Why This Works (Mechanism)

### Mechanism 1: Preventing Shortcut Learning Through Truncation
- **Claim**: Truncating interaction sequences at the first purchase event forces models to learn behavioral patterns rather than relying on purchase status as a shortcut.
- **Mechanism**: By removing the purchase symbol from training features, the architecture prevents classifiers from memorizing the trivial correlation that "sessions containing a purchase are non-frustrated."
- **Core assumption**: Frustration manifests as detectable interaction patterns independent of the final conversion event.
- **Evidence anchors**: Section 3.3 explicitly describes truncation to reduce shortcut learning; Abstract mentions applying frustration rules to 5.4 million events.

### Mechanism 2: Early Detection of Non-Linear Frustration Signals
- **Claim**: Frustration signals accumulate non-linearly, allowing reliable prediction from a relatively short "early window" of user activity.
- **Mechanism**: LSTM aggregates weak signals from individual events into a strong session-level representation, with performance stabilizing after 20-30 interactions.
- **Core assumption**: User intent and emotional state are persistent properties that manifest consistently throughout a session.
- **Evidence anchors**: Section 5.5 shows strong performance (F1 0.87, ROC AUC 0.94) from 20 interactions onward.

### Mechanism 3: HVG Motifs Convert Behavior Sequences into Discriminative Features
- **Claim**: Horizontal Visibility Graph motifs successfully convert irregular time-series behavior into discriminative tabular features for tree-based models.
- **Mechanism**: HVG motifs translate action sequences into probabilistic profiles of local substructures, extracting "shape" information that frequency counts miss.
- **Core assumption**: The order and local context of actions contain significant emotional signal compared to aggregate counts.
- **Evidence anchors**: Section 4.5 describes HVG motifs as going beyond simple n-grams; Section 6.1 shows feature importance results.

## Foundational Learning

- **Concept: Sessionization & Symbolization**
  - **Why needed here**: Raw server logs are unstructured streams requiring grouping by user ID (Sessionization) and mapping diverse actions into standard vocabulary (Symbolization).
  - **Quick check question**: Can you explain why mapping actions to symbols (1, 2, 3...) is necessary for an LSTM but might lose information compared to using raw embeddings?

- **Concept: Shortcut Learning (Label Leakage)**
  - **Why needed here**: This is the primary failure mode addressed in the paper - understanding that models can "cheat" by looking at the result to predict the state.
  - **Quick check question**: If you trained a model to predict "will churn," would including a "cancellation confirmation page view" in the training data constitute leakage?

- **Concept: ROC AUC vs. Accuracy**
  - **Why needed here**: The dataset is balanced artificially (50/50), but real-world data is likely imbalanced (18.9% frustration). Accuracy can be misleading; ROC AUC measures ranking ability across thresholds.
  - **Quick check question**: If the business cost of a False Positive is high, which metric segment (Precision/Recall) should you optimize for?

## Architecture Onboarding

- **Component map**: Raw Clickstream -> Symbolization -> Sessionization -> Labeling Engine -> Truncation Gate -> Feature Fork (Tabular: N-grams/HVG Motifs/Cyclical Time -> XGBoost; Sequence: Embedding Layer -> LSTM) -> Binary Classification Layer
- **Critical path**: The Labeling Engine and Truncation Gate are the most fragile components. If frustration rules don't align with business KPIs, the model optimizes for the wrong goal. If truncation fails, the model overfits to purchase events.
- **Design tradeoffs**:
  - XGBoost: Easier to interpret (SHAP values provided), faster to train, handles missing values well; requires manual feature engineering
  - LSTM: Higher performance (91% vs 90%), handles variable lengths natively; "black box," harder to debug, computationally heavier
- **Failure signatures**:
  - High Train/Low Test: Likely label leakage (did you truncate?)
  - Random Guessing (AUC ~0.5): Check symbolization mapping or label balance
  - High Recall / Low Precision: Model is flagging too many users; frustration threshold may be too low
- **First 3 experiments**:
  1. Baseline Reproduction: Implement XGBoost with 1-gram and 2-gram features only, validate against 90% benchmark
  2. Leakage Test: Remove truncation step, train LSTM, note accuracy inflation, then re-apply truncation to confirm drop
  3. Early Window Simulation: Slice test set to first 15 events, evaluate trained model to see if ROC AUC > 0.90 is maintained

## Open Questions the Paper Calls Out
- How does model performance change when trained and evaluated on the natural, imbalanced distribution rather than the artificial 50/50 balanced dataset?
- Can dedicated models trained specifically on early interaction windows (e.g., first 5 or 10 events) outperform the current method of applying full-sequence LSTM to truncated data?
- Would transformer-based architectures (e.g., TRACE) provide better representation learning for digital frustration compared to the LSTM baseline?

## Limitations
- Data granularity requirements may necessitate specific Coveo dataset versions or proxy-based approximations
- Hyperparameter transparency is limited, potentially affecting reproducibility
- Frustration rules are domain-specific to e-commerce and may not transfer to other domains
- Performance on natural imbalanced distribution (~18.9% frustrated) may differ significantly from balanced evaluation

## Confidence
- **High**: Truncation mechanism to prevent shortcut learning is well-specified and critical
- **High**: Core LSTM vs. XGBoost performance comparison is credible and reproducible
- **Medium**: HVG motif engineering is technically sound but relies on assumptions
- **Medium**: Early-window prediction results are plausible but dataset-dependent

## Next Checks
1. **Leakage Validation**: Train LSTM with and without truncation, document accuracy inflation when truncation is removed
2. **Real-World Imbalance Test**: Evaluate trained model on original imbalanced test set (18.9% positive) to measure true business impact
3. **Domain Transfer Test**: Apply same feature engineering and model architecture to different clickstream dataset, document performance drop to assess generalizability