---
ver: rpa2
title: Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth
arxiv_id: '2507.05510'
source_url: https://arxiv.org/abs/2507.05510
tags:
- treatment
- user
- learning
- r-learner
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing user growth marketing
  campaigns by directly modeling heterogeneous treatment effects on key business metrics.
  The authors propose a deep learning framework that learns to optimize an aggregated
  objective function balancing incremental value and cost using softmax gating for
  user selection.
---

# Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth

## Quick Facts
- arXiv ID: 2507.05510
- Source URL: https://arxiv.org/abs/2507.05510
- Reference count: 40
- Key outcome: Direct optimization of aggregated functions using softmax gating achieves 20%+ improvement over state-of-the-art methods on both marketing and public datasets.

## Executive Summary
This paper addresses the challenge of optimizing user growth marketing campaigns by directly modeling heterogeneous treatment effects on key business metrics. The authors propose a deep learning framework that learns to optimize an aggregated objective function balancing incremental value and cost using softmax gating for user selection. The model jointly optimizes parameters for multiple outcomes rather than treating them separately, enabling more effective resource allocation. Experiments demonstrate that the proposed constrained and direct ranking algorithms significantly outperform state-of-the-art methods (R-learner, Causal Forest) by over 20% in area under cost curve metrics on marketing and public datasets, achieving up to 2x more incremental gain at the same cost level. The approach has been successfully deployed in production across multiple regions.

## Method Summary
The proposed framework directly optimizes an aggregated function that balances incremental value ($\tau_r$) and incremental cost ($\tau_c$) using softmax gating to compute user selection probabilities. The Direct Ranking Model (DRM) applies softmax to model outputs across the entire cohort to obtain selection probabilities, then calculates treatment effects weighted by these probabilities. The optimization maximizes the ratio $\frac{\text{softplus}(\tau_r)}{\text{softplus}(\tau_c)}$ using Adam. A Constrained Ranking variant adds barrier functions to enforce constraints during optimization. The model jointly optimizes multiple outcomes rather than treating them separately, enabling better resource allocation for user growth campaigns.

## Key Results
- The Direct Ranking Model and Constrained Ranking significantly outperform state-of-the-art methods (R-learner, Causal Forest) by over 20% in area under cost curve metrics
- The approach achieves up to 2x more incremental gain at the same cost level compared to existing methods
- The method has been successfully deployed in production across multiple regions
- Demonstrated effectiveness on both marketing datasets and public datasets (US Census, Covertype)

## Why This Works (Mechanism)
The approach works by directly optimizing the business objective rather than estimating individual treatment effects separately. By using softmax gating across the entire cohort, the model learns user selection probabilities that maximize the ratio of incremental value to incremental cost. The joint optimization of multiple outcomes allows the model to make trade-offs between different business metrics rather than optimizing them independently. The softplus function in the denominator prevents numerical instability when costs approach zero, ensuring stable gradient-based optimization.

## Foundational Learning
- **Softmax gating**: Why needed - to compute selection probabilities for users in the cohort. Quick check - verify probabilities sum to 1 across the batch.
- **Softplus function**: Why needed - to prevent numerical instability when denominator approaches zero. Quick check - ensure smooth approximation of ReLU that avoids exploding gradients.
- **Treatment effect modeling**: Why needed - to estimate causal impact of interventions on multiple outcomes. Quick check - validate counterfactual estimation using treatment/control groups.
- **Aggregated function optimization**: Why needed - to directly optimize business metrics rather than individual predictions. Quick check - confirm ratio objective maximizes ROI.
- **Gradient-based optimization with non-differentiable operations**: Why needed - to handle sorting operations in constrained ranking. Quick check - verify straight-through estimator implementation for sorting.
- **Area Under Cost Curve (AUCC)**: Why needed - to evaluate performance of ranking models. Quick check - plot cumulative value vs. cost curves for comparison.

## Architecture Onboarding

**Component Map**: Input features -> Neural Network -> Scores -> Softmax (cohort-level) -> Selection Probabilities -> Weighted Treatment Effects -> Aggregated Objective -> Adam Optimizer

**Critical Path**: The core path is: feature extraction → neural network scoring → softmax gating → weighted treatment effect calculation → aggregated objective optimization. This path directly maps input features to business metrics through the selection probability mechanism.

**Design Tradeoffs**: The paper trades off computational efficiency (full-batch softmax vs. mini-batch) for statistical accuracy in probability estimation. The use of softplus instead of direct ratio prevents numerical instability but adds complexity. Joint optimization of multiple outcomes reduces modularity but enables better trade-offs.

**Failure Signatures**: Numerical instability occurs when cost approaches zero (mitigated by softplus). Softmax scale mismatch happens with mini-batch training vs. full-cohort application. Non-differentiable sorting operations create implementation challenges for the constrained variant.

**First Experiments**:
1. Implement DRM loss with full-batch softmax on US Census data and verify selection probabilities sum to 1
2. Compare direct ratio optimization vs. softplus-stabilized version on synthetic data with varying cost distributions
3. Test gradient flow through softmax gating by visualizing selection probability changes during training

## Open Questions the Paper Calls Out
### Open Question 1
Can multi-armed bandit or Bayesian optimization frameworks improve exploration efficiency over the current epsilon-greedy approach by better leveraging model uncertainty?
- Basis in paper: Future Work section: "As a better approach, we will try to use multi-arm bandit or Bayesian optimization framework to guide our smart explore based on the model uncertainty."
- Why unresolved: Current epsilon-greedy allocates fixed budget percentage to fully randomized exploration, which may be data-inefficient.
- What evidence would resolve it: A/B experiments comparing epsilon-greedy vs. bandit-guided exploration showing improved model performance with less exploration budget.

### Open Question 2
How can deep embedding techniques be adapted specifically for treatment effect models to handle sparse temporal and geographical features?
- Basis in paper: Future Work section: "Various embedding techniques have been used for sparse features while they are not used in treatment effect models. Now that there is a general loss layer to be incorporated with any deep learning structure, we can start to work on embeddings specifically for treatment effect models."
- Why unresolved: Standard embeddings may not capture causal structure; treatment effect models have unique requirements.
- What evidence would resolve it: Empirical comparison showing embeddings designed for causal learning outperform standard embeddings on sparse-feature scenarios.

### Open Question 3
How robust is the proposed approach to violations of the unconfoundedness assumption in real-world observational data?
- Basis in paper: The paper states adherence to unconfoundedness but does not test sensitivity to this assumption, which is critical for real-world deployment where unobserved confounders may exist.
- Why unresolved: Real production systems may have hidden confounders; sensitivity to assumption violations is untested.
- What evidence would resolve it: Simulation studies with controlled confounding, or sensitivity analysis on production data with instrumental variable comparisons.

## Limitations
- The core contribution relies on non-differentiable sorting operations for the Constrained Ranking model, but the gradient estimation strategy is not specified, making exact reproduction challenging.
- Main results on marketing data cannot be independently verified due to undisclosed feature schemas and outcome definitions.
- The regularization term in Equation 5 is described as optional but its implementation when active is unclear.

## Confidence
- **High confidence**: The general framework for optimizing aggregated functions using deep learning and softmax gating is sound and implementable.
- **Medium confidence**: Claims about outperforming R-learner and Causal Forest by 20%+ on public datasets are verifiable, though results may vary with implementation details.
- **Low confidence**: Claims of 2x incremental gain and successful production deployment across multiple regions cannot be independently validated due to reliance on proprietary data.

## Next Checks
1. **Verify non-differentiable sorting implementation**: Implement the Constrained Ranking model using a straight-through estimator for sorting operations and compare performance against Direct Ranking on US Census and Covertype datasets.

2. **Benchmark against baselines**: Replicate the comparison with R-learner and Causal Forest on public datasets, ensuring identical train/test splits and evaluation metrics (AUCC).

3. **Test numerical stability**: Validate that applying softplus to both numerator and denominator prevents gradient explosion when costs approach zero, and compare results with epsilon-stabilization approaches.