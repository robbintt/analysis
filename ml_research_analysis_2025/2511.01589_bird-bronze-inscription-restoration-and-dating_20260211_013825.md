---
ver: rpa2
title: 'BIRD: Bronze Inscription Restoration and Dating'
arxiv_id: '2511.01589'
source_url: https://arxiv.org/abs/2511.01589
tags:
- tapt
- bronze
- inscriptions
- dapt
- zhou
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce BIRD, the first fully encoded bronze inscription dataset
  (41k tokens) with chronological labels and a Glyph Net resource linking 1,078 grapheme-allograph
  pairs. We propose an allograph-aware masked language modeling framework that combines
  domain-adaptive pretraining, task-adaptive pretraining, and a Glyph Net module to
  improve restoration, alongside glyph-biased sampling for dating.
---

# BIRD: Bronze Inscription Restoration and Dating

## Quick Facts
- arXiv ID: 2511.01589
- Source URL: https://arxiv.org/abs/2511.01589
- Reference count: 23
- We introduce BIRD, the first fully encoded bronze inscription dataset (41k tokens) with chronological labels and a Glyph Net resource linking 1,078 grapheme-allograph pairs. We propose an allograph-aware masked language modeling framework that combines domain-adaptive pretraining, task-adaptive pretraining, and a Glyph Net module to improve restoration, alongside glyph-biased sampling for dating. Experiments show that the framework with SikuRoBERTa achieves state-of-the-art results: 49.47% exact match and 73.07% family-level match in restoration, and 86.42% dynasty-level and 77.83% macro-F1 in dating. Glyph Net consistently improves restoration, while glyph-biased sampling enhances dating performance.

## Executive Summary
This paper introduces BIRD (Bronze Inscription Restoration and Dating), a novel framework for restoring damaged characters and dating ancient Chinese bronze inscriptions. The key innovation is an allograph-aware masked language modeling approach that leverages paleographic knowledge through a Glyph Net resource linking grapheme-allograph pairs. By combining domain-adaptive pretraining, task-adaptive pretraining, and specialized regularization techniques, the framework achieves state-of-the-art results on both restoration and dating tasks, demonstrating the potential of integrating paleographic expertise with modern language modeling.

## Method Summary
The framework uses SikuRoBERTa as backbone, first performing domain-adaptive pretraining (DAPT) on a 2.09M token Pre-Qin corpus (freezing bottom 6 layers for 10 epochs), then task-adaptive pretraining (TAPT) on the BIRD dataset with stride-based masking and Glyph Net regularization. The restoration task uses masked language modeling with allograph-aware loss interpolation, while dating uses dynasty-level and period-level classification. Glyph-biased sampling prioritizes historically informative variants during training. The approach specifically addresses the challenges of ultra-short texts and data sparsity in ancient Chinese paleography.

## Key Results
- SikuRoBERTa with full framework achieves 49.47% exact match and 73.07% family-level match in restoration
- Dating accuracy reaches 86.42% at dynasty-level and 77.83% macro-F1
- Glyph Net consistently improves restoration performance across all models
- Glyph-biased sampling yields 2.4 percentage point gains in dating accuracy

## Why This Works (Mechanism)

### Mechanism 1: Allograph Regularization via Glyph Net (GN)
Treating paleographic allographs as unified clusters during training improves restoration accuracy by mitigating data sparsity. The loss interpolation approach prevents the model from treating visually similar forms as entirely distinct classes, effectively softening decision boundaries in low-resource settings. This assumes allographs listed in Glyph Net are functionally interchangeable, which is a simplification of complex paleographic reality.

### Mechanism 2: Glyph-Biased Sampling for Chronological Dating
Prioritizing historically informative glyph variants during masking enhances dynasty classification by forcing the encoder to attend to diachronic orthographic shifts. The weighted sampling probability for "glyph tokens" helps the model capture temporal evolution rather than relying solely on static semantic context. This assumes distinct glyph forms serve as robust markers of specific time periods.

### Mechanism 3: Stride-Based Masking for Short Sequences
Systematic masking preserves sufficient context in ultra-short inscriptions (≤3 characters) by ensuring immediate neighbors remain visible. This prevents context destruction that occurs with standard random masking in BERT-style models, allowing the model to leverage essential local n-gram patterns for formulaic restoration.

## Foundational Learning

**Domain-Adaptive Pretraining (DAPT)**: Needed because the 41k token BIRD dataset is too small to train from scratch. DAPT on the 2.09M token Pre-Qin corpus bridges the gap between modern PLMs and ancient Chinese syntax. Quick check: Why would training on the tiny BIRD dataset alone fail to produce a generalized restoration model?

**The Grapheme-Allograph Distinction**: Essential for understanding the core innovation. The abstract "character" (grapheme) is separated from its physical "variants" (allographs), enabling the Glyph Net logic where different Unicode points are treated as the same class. Quick check: How does treating two visually different characters as the same "family" help the loss function converge faster?

**Exact Match vs. Family-Level Match**: Evaluation requires nuance. Exact match requires predicting the precise variant, while family-level match accepts any historically valid allograph. This distinction is crucial for interpreting the 49.47% vs 73.07% scores. Quick check: If the model predicts a valid allograph but not the exact one found in the gold standard, is it useful for a paleographer?

## Architecture Onboarding

**Component map**: Data Prep (Encoding → Filtering → Deduplication) → DAPT (Pre-Qin) → TAPT (BIRD + Stride Masking + GN Loss) → Inference

**Critical path**: The sequence flows from dataset preparation through domain adaptation, task-specific fine-tuning with allograph regularization, to final evaluation on both restoration and dating tasks.

**Design tradeoffs**: Restoration benefits from normalization (GN), while Dating benefits from differentiation (Biased Sampling). A single model may require different fine-tuning runs for optimal performance on each task. Context vs. damage tradeoff: aggressive masking simulates damage but removes training signal; high stride retains signal but may fail to learn robustness.

**Failure signatures**: Template collapse (model defaults to frequent phrases), cross-era confusion (high misclassification between Spring and Autumn/Warring States), UNK overload (high percentage of unknown tokens indicating vocabulary mapping failure).

**First 3 experiments**: 1) Baseline validation with SikuRoBERTa and standard random masking to establish difficulty floor. 2) Ablation on GN comparing standard MLM loss vs. GN-interpolated loss. 3) Sampling strategy comparison between uniform sampling vs. glyph-biased sampling on dynasty classification.

## Open Questions the Paper Calls Out

**Phonological Supervision**: Can phonetic series embeddings improve restoration for loan characters (tongjiazi) that rely on sound-based substitution? Current token-only MLM cannot detect phonologically-motivated character substitutions common in early Chinese texts.

**Structure-Aware Encodings**: Can Ideographic Description Sequences (IDS) enable component-conditioned restoration of partially damaged glyphs? Token-level masking treats characters atomically, discarding visible subcomponent information that paleographers use.

**Multimodal Archaeological Signals**: Can integrating vessel shape, decorative motifs, and casting techniques improve chronological dating beyond textual features? Current dating relies solely on inscriptional text while traditional practice integrates material culture evidence.

**Generative Architectures**: Can decoder-only LLMs better capture long-range dependencies and support free-form restoration compared to discriminative MLM? Encoder-only architectures are limited to single-position prediction while generative models could enable multi-token coherent restoration.

## Limitations

- Model may exhibit template collapse, defaulting to frequent formulaic phrases for ambiguous damaged sections
- Temporal distribution bias in training data (overrepresentation of Western Zhou) could skew dating predictions
- Assumption that allographs are functionally interchangeable is a significant simplification of complex paleographic reality
- Evaluation relies heavily on simulated damage rather than naturally occurring damaged inscriptions
- Small dataset size (41k tokens) may not capture full diversity of bronze inscriptions
- Glyph Net covers only 1,078 grapheme-allograph pairs, representing a subset of all paleographic variants

## Confidence

**Mechanism 1: Allograph Regularization via Glyph Net**: High confidence - Clear evidence from Section 6.4 Analysis shows GN achieves highest Exact@K scores and effectively reduces sparsity.

**Mechanism 2: Glyph-Biased Sampling for Chronological Dating**: Medium confidence - While gains are demonstrated, weak direct evidence in general NLP corpus for this specific paleographic technique creates uncertainty.

**Mechanism 3: Stride-Based Masking for Short Sequences**: High confidence - Primarily an implementation detail with clear technical justification and evidence showing context preservation.

## Next Checks

1. **Cross-Era Confusion Analysis**: Examine per-class accuracy and confusion matrices for the dating task, particularly focusing on the Spring and Autumn to Warring States transition where stylistic convergence occurs.

2. **Family-Level vs. Exact Match Gap Investigation**: Analyze cases where the model predicts valid allographs but not the exact gold standard variant to determine if they represent reasonable paleographic alternatives or systematic biases.

3. **Out-of-Distribution Testing**: Apply the trained model to naturally damaged bronze inscriptions not included in the BIRD dataset to assess real-world performance and validate simulated damage experiments.