---
ver: rpa2
title: Distillation of Large Language Models via Concrete Score Matching
arxiv_id: '2509.25837'
source_url: https://arxiv.org/abs/2509.25837
tags:
- bolts
- takes
- total
- teacher
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Concrete Score Distillation (CSD), a novel
  knowledge distillation objective for large language models (LLMs) that addresses
  the limitations of existing approaches. Traditional distillation losses either suffer
  from softmax-induced smoothing, which obscures valuable logit information, or restrict
  the optimal solution set by enforcing logit shift invariance.
---

# Distillation of Large Language Models via Concrete Score Matching

## Quick Facts
- **arXiv ID:** 2509.25837
- **Source URL:** https://arxiv.org/abs/2509.25837
- **Reference count:** 40
- **Primary result:** CSD achieves 2.0% improvement in ROUGE-L scores across multiple benchmarks and model sizes (up to 7B parameters)

## Executive Summary
This paper introduces Concrete Score Distillation (CSD), a novel knowledge distillation objective for large language models that addresses fundamental limitations in existing approaches. Traditional distillation losses suffer from either softmax-induced smoothing that obscures logit information or logit shift invariance that restricts optimal solutions. CSD overcomes both issues by matching relative logit differences between student and teacher models across all vocabulary pairs using a discrete score-matching framework. The method provides a broader solution space, allows flexible vocabulary weighting, and achieves computational efficiency through O(|V|) gradient computation. Experimental results demonstrate consistent improvements over recent distillation objectives across task-agnostic and task-specific settings.

## Method Summary
CSD operates by matching the relative logit differences between student and teacher models for all vocabulary pairs, avoiding the softmax-induced smoothing that plagues traditional distillation methods. The approach uses a discrete score-matching framework where the objective function directly compares the logits without applying softmax, preserving the full information content. The method computes gradients efficiently in O(|V|) time, making it scalable to large vocabularies. CSD allows flexible weighting of different vocabulary pairs, enabling task-specific optimization strategies. The framework is designed to be complementary to on-policy techniques, potentially stacking with existing methods for additional performance gains.

## Key Results
- CSD achieves up to 2.0% improvement in ROUGE-L scores compared to state-of-the-art distillation methods
- Consistent performance gains across multiple model sizes (up to 7B parameters) and benchmarks
- Favorable fidelity-diversity trade-offs compared to existing distillation objectives
- Complementary performance when combined with on-policy distillation techniques

## Why This Works (Mechanism)
CSD works by fundamentally changing how distillation objectives match student and teacher behavior. Instead of comparing probability distributions through softmax (which introduces smoothing), CSD directly matches the relative differences in logits across all vocabulary pairs. This discrete score-matching approach preserves the full information content of the teacher's logits while avoiding the logit shift invariance problem that restricts the solution space in traditional methods. By matching relative differences rather than absolute values, CSD allows the student model to find optimal solutions within a broader space. The O(|V|) computational efficiency enables practical application to large vocabularies without prohibitive computational costs.

## Foundational Learning

### Knowledge Distillation
**Why needed:** Understanding the fundamental goal of transferring knowledge from larger teacher models to smaller student models, which forms the basis for CSD's approach
**Quick check:** Can you explain the difference between response-based and feature-based distillation methods?

### Softmax Function and Its Limitations
**Why needed:** Recognizing how softmax induces smoothing that obscures valuable logit information in traditional distillation methods
**Quick check:** What information is lost when applying softmax to logits before computing distillation loss?

### Score Matching
**Why needed:** Understanding the mathematical framework that CSD builds upon to match distributions without density estimation
**Quick check:** How does score matching differ from traditional maximum likelihood estimation?

### Logit Shift Invariance
**Why needed:** Recognizing the fundamental limitation in traditional distillation that restricts the solution space
**Quick check:** What mathematical property causes logit shift invariance in traditional distillation objectives?

## Architecture Onboarding

### Component Map
Teacher LLM -> CSD Objective Function -> Student LLM Training Loop

### Critical Path
1. Teacher model inference to generate logits
2. CSD objective computation comparing relative logit differences
3. Gradient computation and backpropagation to student parameters
4. Student model parameter updates

### Design Tradeoffs
- Discrete score matching vs. probability-based matching: preserves information but requires careful implementation
- Relative logit differences vs. absolute logits: broader solution space but potentially more complex optimization landscape
- O(|V|) computation: computationally efficient but requires careful implementation for large vocabularies
- Flexible weighting vs. uniform weighting: allows task-specific optimization but adds hyperparameter tuning complexity

### Failure Signatures
- If CSD performs worse than traditional methods: likely due to improper hyperparameter tuning or implementation errors in relative logit computation
- If training becomes unstable: check gradient computation and ensure proper scaling of the objective function
- If no improvement over baseline: verify that the teacher model is sufficiently capable and that the relative logit differences are being computed correctly

### First Experiments
1. Implement CSD on a small-scale model (e.g., 125M parameters) with a simple task to verify basic functionality
2. Compare CSD against traditional distillation on a standard benchmark (e.g., summarization) with the same teacher model
3. Perform ablation studies to isolate the contributions of relative logit matching, discrete score matching, and efficient computation

## Open Questions the Paper Calls Out

## Limitations
- Ablation studies do not fully isolate individual contributions of CSD's design choices to performance gains
- Computational efficiency claims lack detailed runtime comparisons with competing methods
- Focus on instruction-following tasks leaves uncertainty about effectiveness in reasoning, coding, or multi-modal applications
- Flexible vocabulary weighting strategies are not thoroughly explored or optimized

## Confidence

**High Confidence:** Theoretical formulation of CSD and its mathematical distinction from traditional distillation objectives is well-established and sound.

**Medium Confidence:** Empirical results showing performance improvements across multiple benchmarks are promising but may be influenced by experimental choices and hyperparameter tuning.

**Medium Confidence:** Computational efficiency claims are theoretically justified but lack comprehensive empirical validation against competing methods.

## Next Checks

1. Conduct controlled ablation studies to isolate the individual contributions of relative logit matching, discrete score matching, and efficient gradient computation to CSD's performance gains.

2. Perform runtime and memory usage comparisons between CSD and existing distillation methods across different model sizes and hardware configurations to validate computational efficiency claims.

3. Test CSD's effectiveness on non-instruction-following tasks such as mathematical reasoning, code generation, and multi-modal understanding to assess broader applicability.