---
ver: rpa2
title: 'DK-Root: A Joint Data-and-Knowledge-Driven Framework for Root Cause Analysis
  of QoE Degradations in Mobile Networks'
arxiv_id: '2511.11737'
source_url: https://arxiv.org/abs/2511.11737
tags:
- learning
- data
- diffusion
- labels
- kpis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of diagnosing root causes of
  Quality of Experience (QoE) degradations in mobile networks using limited expert
  annotations. The proposed DK-Root framework combines data-driven weak supervision
  with knowledge-driven expert guidance to improve root-cause classification accuracy.
---

# DK-Root: A Joint Data-and-Knowledge-Driven Framework for Root Cause Analysis of QoE Degradations in Mobile Networks

## Quick Facts
- arXiv ID: 2511.11737
- Source URL: https://arxiv.org/abs/2511.11737
- Reference count: 39
- Primary result: Achieves 68.30% mean accuracy on root-cause classification of QoE degradations

## Executive Summary
This paper addresses the challenge of diagnosing root causes of Quality of Experience (QoE) degradations in mobile networks using limited expert annotations. The proposed DK-Root framework combines data-driven weak supervision with knowledge-driven expert guidance to improve root-cause classification accuracy. The method leverages abundant but noisy rule-based labels for scalable pretraining and scarce but reliable expert annotations for fine-tuning. Key innovations include a conditional diffusion model for task-specific data augmentation and a supervised contrastive learning strategy for robust representation learning. Experiments on a real-world operator-grade dataset demonstrate state-of-the-art performance, with DK-Root achieving 68.30% mean accuracy compared to 61.13-57.73% for traditional baselines and 51.15-51.25% for recent semi-supervised methods.

## Method Summary
The DK-Root framework employs a three-stage pipeline to classify QoE degradation root causes in mobile networks. Stage I trains a class-conditional diffusion model exclusively on expert-verified samples to generate semantically valid KPI augmentations. Stage II uses these augmentations with rule-based labels to pretrain an encoder via supervised contrastive learning, creating noise-robust representations. Stage III fine-tunes the encoder and classifier using high-fidelity expert labels. The method leverages the scalability of rule-based labels while maintaining accuracy through expert refinement, achieving state-of-the-art performance on operator-grade mobile network data.

## Key Results
- DK-Root achieves 68.30% mean accuracy on 6-class root cause classification
- Outperforms traditional ML baselines (61.13-57.73%) and recent semi-supervised methods (51.15-51.25%)
- Ablation studies confirm effectiveness of conditional diffusion augmentation and three-stage pretrain-fine-tune design
- Semantic-preserving augmentation generates KPIs that maintain physical plausibility while improving diversity

## Why This Works (Mechanism)

### Mechanism 1: Semantic-Preserving Data Augmentation via Conditional Diffusion
The framework uses a class-conditional diffusion model (DDPM) trained on expert data to generate KPI sequences that preserve root-cause semantics. By controlling the diffusion timestep $t$, the model creates "weak" (minor perturbation) and "strong" (significant restructuring) views that remain on the learned data manifold, ensuring physical plausibility. Evidence shows DK-Root(strong) outperforms generic augmentations in Mutual Information (0.5839 vs 0.4712) and clustering quality. The core assumption is that the small expert dataset is representative enough to train a generative model that generalizes to the larger, noisy dataset.

### Mechanism 2: Noise Tolerance via Supervised Contrastive Learning
Direct supervised training on noisy rule-based labels degrades accuracy, whereas Supervised Contrastive Learning creates a robust embedding space by enforcing intra-class compactness among samples sharing the same heuristic label. The loss function pulls together all samples with the same rule-based label and pushes apart samples with different labels, effectively smoothing out labeling errors. The core assumption is that rule-based labels have a higher probability of being correct than incorrect, allowing the signal to outweigh the noise during training. Evidence shows contrastive pre-training maintains higher performance compared to joint training approaches.

### Mechanism 3: Knowledge Refinement via Decoupled Fine-Tuning
The framework decouples representation learning from decision boundary refinement, yielding higher accuracy than joint training. The encoder is first frozen after pretraining to retain generalizable features learned from the large dataset, then fine-tuned with expert labels to "sharpen" decision boundaries without overfitting to noise. The core assumption is that semantic clusters formed during noisy pretraining are sufficiently aligned with true classes for expert labels to successfully refine them. Ablation studies show the decoupled approach significantly outperforms joint training and linear fine-tuning baselines.

## Foundational Learning

### Concept: Denoising Diffusion Probabilistic Models (DDPM)
**Why needed here:** The core augmentation engine relies on understanding how adding Gaussian noise (forward process) and learning to remove it (reverse process) allows for controlled generation.  
**Quick check question:** How does changing the starting timestep $t$ in the reverse diffusion process affect the balance between diversity and fidelity in the generated sample?

### Concept: Supervised Contrastive Learning (SupCon)
**Why needed here:** Standard Cross-Entropy loss fails with noisy labels. Understanding how contrastive losses handle multiple "positive" pairs per anchor is crucial for grasping the noise-robustness strategy.  
**Quick check question:** In SupCon, how does the loss function treat two samples with the same rule-based label but different true underlying labels (label noise)?

### Concept: Mobile Network KPIs (PHY/MAC/RLC/PDCP)
**Why needed here:** The paper argues that generic augmentations fail because they break "protocol-layer constraints." Understanding what RSRP (signal power) or SINR (signal quality) represent is necessary to appreciate why jittering might physically invalidate the data.  
**Quick check question:** Why would randomly scaling the amplitude of a signal strength indicator (like RSRP) potentially violate its physical semantics compared to generating a new sample conditioned on a specific class?

## Architecture Onboarding

### Component map:
Conditional Diffusion Model (U-Net) -> Encoder Backbone (1D-CNN) -> Projection Head -> Classifier Head

### Critical path:
1. **Stage I (Generative):** Train Diffusion Model *only* on Expert Data ($D_e$)
2. **Stage II (Representational):** Freeze Diffusion Model. Generate augmented views for Rule-based Data ($D_r$). Train Encoder with SupCon Loss on $D_r$
3. **Stage III (Discriminative):** Load Pre-trained Encoder. Fine-tune Encoder + Classifier on Expert Data ($D_e$) with Cross-Entropy

### Design tradeoffs:
- **Generative vs. Static Augmentation:** High compute cost for diffusion training vs. significant accuracy gain over jittering/scaling
- **Encoder Capacity:** Must be complex enough to capture cross-layer KPI interactions but fast enough for operational deployment
- **Timestep Sampling:** Split between "weak" ($t < T/5$) and "strong" ($T/5 < t < T/2$) augmentation is heuristic; aggressive strong augmentation might erase class semantics

### Failure signatures:
- **Stage I Failure:** Generated samples look identical to input (overfitting) or are pure noise (underfitting/divergence). Check MSE loss convergence
- **Stage II Failure:** Loss fluctuates wildly or converges to a high value, suggesting the encoder cannot reconcile the noisy rule-based labels (noise ratio too high)
- **Stage III Failure:** Accuracy on expert validation set drops or fails to improve, indicating pre-trained features are not transferable or expert dataset is too small

### First 3 experiments:
1. **Overfit Test (Stage I):** Train the diffusion model on 10 expert samples and verify it can reconstruct them perfectly (sanity check of architecture)
2. **Augmentation Quality Check:** Visualize (t-SNE/PCA) original KPIs vs. "Jittered" vs. "Diffusion-Generated" samples colored by class. Check if diffusion maintains tighter clusters
3. **Ablation Run:** Train the full pipeline vs. a "CNN-full" baseline (mixing all data) on a small subset of the dataset to verify the pretrain-finetune advantage before scaling up

## Open Questions the Paper Calls Out

### Open Question 1
**Question:** How can explicit label-noise modeling be integrated to prevent the amplification of erroneous rule-based signals in high-noise environments?  
**Basis in paper:** The Conclusion states that while the method assumes rule-based labels are reliable, erroneous signals may be amplified in high-noise scenarios, and future research will focus on robust noise correction mechanisms.  
**Why unresolved:** The current framework relies on contrastive learning to implicitly denoise labels but lacks a dedicated mechanism to model or correct systematic errors in rule-based supervision.  
**What evidence would resolve it:** Integration of a noise-adaptation layer or noise-robust loss function, followed by performance evaluation on datasets with synthetically injected high label noise.

### Open Question 2
**Question:** Does the conditional diffusion module overfit when trained exclusively on the extremely scarce expert-verified subset?  
**Basis in paper:** The methodology trains the diffusion model in Stage I using *only* the expert-labeled samples ($D_e$) to ensure semantic consistency, despite diffusion models typically requiring large-scale data to learn complex distributions effectively.  
**Why unresolved:** The paper validates the overall framework but does not analyze the diversity or fidelity of the generated samples relative to the very small size (185 samples) of the diffusion training set.  
**What evidence would resolve it:** An ablation study visualizing the manifold of generated samples and measuring classification performance as the number of diffusion training samples decreases.

### Open Question 3
**Question:** Can the framework maintain performance when applied to QoE degradation scenarios other than the high-latency cases studied?  
**Basis in paper:** The Problem Formulation explicitly states the study focuses on a "representative case of high-latency scenarios," leaving other degradation types (e.g., connection failures) unexamined.  
**Why unresolved:** The KPI signatures and cross-layer interactions for high latency may differ significantly from other failure modes, and it is unclear if the "high-latency" assumption biases the learned representations.  
**What evidence would resolve it:** Experimental results applying DK-Root to datasets characterized by distinct QoE degradation primary indicators (e.g., low throughput or packet loss).

## Limitations
- Core innovation relies on a proprietary dataset from Huawei, preventing independent verification of performance claims
- Diffusion model's effectiveness is contingent on representativeness of small expert dataset (185 samples), with overfitting risk not quantified
- "Semantic preservation" of diffusion model is empirically demonstrated but lacks interpretability of what specific aspects are preserved versus corrupted

## Confidence
- **High Confidence:** Three-stage pretrain-finetune pipeline design and superiority over joint training (CNN-full) is well-supported by ablation studies
- **Medium Confidence:** Mechanism of supervised contrastive learning denoising rule-based labels is theoretically sound, but exact noise tolerance threshold is unknown
- **Low Confidence:** Claim that conditional diffusion augmentation is uniquely necessary for KPI time-series vs. other domains requires more direct comparison studies

## Next Checks
1. **Overfitting Test:** Train the diffusion model on 20 expert samples and measure reconstruction quality and diversity. Verify it does not memorize but generates novel yet plausible samples
2. **Noise Tolerance Test:** Simulate different noise ratios in rule-based labels (e.g., 10%, 30%, 50%) and measure how much SupCon's performance degrades before Stage III fine-tuning can no longer recover
3. **Domain Transfer Test:** Train the entire DK-Root pipeline on a public, similar dataset (e.g., network KPI datasets from Kaggle or academic sources) to assess generalizability beyond the proprietary data