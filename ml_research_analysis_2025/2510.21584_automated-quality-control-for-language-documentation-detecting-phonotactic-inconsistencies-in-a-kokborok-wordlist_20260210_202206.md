---
ver: rpa2
title: 'Automated Quality Control for Language Documentation: Detecting Phonotactic
  Inconsistencies in a Kokborok Wordlist'
arxiv_id: '2510.21584'
source_url: https://arxiv.org/abs/2510.21584
tags:
- data
- gram
- n-gram
- iforest
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an unsupervised anomaly detection approach
  to identify phonotactic inconsistencies in Kokborok language documentation. Using
  character-level and syllable-aware n-gram features with machine learning algorithms
  (One-Class SVM, Isolation Forest, LOF), the study achieves modest precision (0.26-0.29)
  and recall (0.35-0.41) for character-level analysis, with Isolation Forest performing
  best.
---

# Automated Quality Control for Language Documentation: Detecting Phonotactic Inconsistencies in a Kokborok Wordlist

## Quick Facts
- arXiv ID: 2510.21584
- Source URL: https://arxiv.org/abs/2510.21584
- Reference count: 4
- Primary result: Unsupervised anomaly detection achieves F1=0.37 (27% improvement over baseline) for phonotactic inconsistencies in Kokborok wordlist

## Executive Summary
This paper presents an unsupervised machine learning approach to detect phonotactic inconsistencies in low-resource language documentation. Using character-level and syllable-aware n-gram features with machine learning algorithms (One-Class SVM, Isolation Forest, LOF), the study identifies potential transcription errors and borrowings in a Kokborok wordlist. The syllable-aware approach achieves significantly better performance than character-level baselines, demonstrating the value of structural phonotactic features for automated quality control in language documentation.

## Method Summary
The method uses unsupervised anomaly detection to identify phonotactic inconsistencies in Kokborok wordlists. It employs three algorithms (One-Class SVM, Isolation Forest, LOF) with features derived from negative log-likelihood of character and syllable n-grams. The syllable-aware setup segments words into syllables using sonority-based rules and analyzes n-grams within syllables, across boundaries, and at syllable edges. Four aggregation strategies (sum, mean, min, max) plus combined ALL aggregation are tested. The approach flags potential transcription errors and borrowings for manual review by fieldworkers.

## Key Results
- Character-level analysis achieves modest precision (0.26-0.29) and recall (0.35-0.41)
- Isolation Forest consistently outperforms other algorithms across all configurations
- Syllable-aware features achieve maximum F1-score of 0.37 with recall reaching 0.56
- Syllable-aware approach shows 27% improvement over character-level baseline
- Boundary-phoneme analysis with bigram-trigram features and ALL aggregation performs best

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Syllable-aware feature engineering improves detection of phonotactic anomalies compared to character-level baselines.
- Mechanism: By segmenting words into syllables and analyzing n-grams within, across, and at syllable boundaries, the system captures structural phonotactic violations that character-level n-grams miss. Boundary-phoneme analysis treats syllable boundaries as pseudo-phonemes, allowing the model to learn positional constraints at syllable edges.
- Core assumption: Phonotactic anomalies (transcription errors, borrowings) manifest as violations of language-specific syllable structure constraints rather than just rare character sequences.
- Evidence anchors:
  - [abstract]: "syllable-aware features significantly outperform character-level baselines"
  - [section 4.2]: "The syllable-aware approach achieves a maximum F1-score of 0.37, representing a 27% improvement over the character-level baseline. This performance gain is accompanied by significantly higher recall values (0.51-0.56)"
  - [corpus]: Related work on transcription inconsistencies in low-resource ASR (Breaking the Transcription Bottleneck, FMR 0.605) corroborates that fieldwork data presents unique challenges, though no direct corpus evidence exists for syllable-aware vs. character-level comparison in anomaly detection.
- Break condition: If automatic syllabification produces systematic errors for the target language, or if the language has highly variable syllable structures that defy consistent segmentation.

### Mechanism 2
- Claim: Isolation Forest outperforms One-Class SVM and Local Outlier Factor for phonotactic anomaly detection.
- Mechanism: Isolation Forest exploits the property that anomalies require fewer random splits to isolate from the rest of the data. Phonotactic anomalies—being rare and structurally distinct—have shorter average path lengths across decision trees, yielding higher anomaly scores.
- Core assumption: Phonotactic anomalies are "few and different" (sparse, distinguishable from normal patterns) rather than "many and clustered."
- Evidence anchors:
  - [section 4.1]: "The Isolation Forest algorithm consistently outperforms other anomaly detection methods in all combinations of features"
  - [tables 1-2]: All top 10 results in both character-level and syllable-aware configurations use iForest
  - [corpus]: No direct corpus evidence comparing these algorithms for phonotactic or linguistic anomaly detection exists.
- Break condition: If anomalies are dense (numerous) or lie close to normal data in feature space (subtle violations), path-length discrimination degrades.

### Mechanism 3
- Claim: Combining multiple aggregation strategies (ALL aggregation) with bigram-trigram n-gram combinations yields the most robust phonotactic representations.
- Mechanism: Different aggregation methods capture complementary statistical perspectives—sum captures overall anomaly load, mean captures average violation severity, min/max capture extreme violations. Combining them with multiple n-gram orders allows models to leverage both local (bigram) and broader contextual (trigram) phonotactic constraints.
- Core assumption: Anomalous words exhibit detectable statistical irregularities across multiple n-gram scales and aggregation perspectives simultaneously.
- Evidence anchors:
  - [section 4.2]: "The boundary-phoneme analysis type achieves the highest single F1-score (0.37) when combined with bigram and trigram features and ALL aggregation"
  - [section 3.4.3]: "ALL + ALL: We combine all analysis types with all aggregation methods, creating the most comprehensive feature representation"
  - [corpus]: Weak corpus support—no prior work directly validates multi-aggregation strategies for phonotactic anomaly detection.
- Break condition: If the feature space becomes too high-dimensional relative to dataset size, introducing noise that degrades model discrimination.

## Foundational Learning

- Concept: **Phonotactics**
  - Why needed here: The entire approach assumes words that violate language-specific sound sequence constraints are likely transcription errors or borrowings. Understanding what phonotactics are (permissible syllable structures, segment distributions) is prerequisite to interpreting why this method works.
  - Quick check question: Given the sequence /str-/ in English, is this a valid syllable onset? What about /zdr-/? Which would a phonotactic model flag as anomalous for English?

- Concept: **Unsupervised Anomaly Detection**
  - Why needed here: The method has no labeled "error" or "borrowing" examples—it must identify outliers purely from distributional properties. Understanding how One-Class SVM, Isolation Forest, and LOF define "normal" vs. "anomalous" is essential for debugging results.
  - Quick check question: If your training data contains 10% anomalies but your Isolation Forest assumes a contamination rate of 5%, what happens to detection performance?

- Concept: **Negative Log-Likelihood (NLL) from N-gram Models**
  - Why needed here: All features are derived from NLL scores—rare n-grams have high NLL and indicate potential anomalies. Understanding how NLL is computed from frequency counts is necessary to interpret feature values.
  - Quick check question: A bigram appears once in a corpus of 10,000 bigrams. What is its NLL? How does this compare to a bigram appearing 100 times?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Syllabification (if syllable-aware) -> N-gram extraction -> NLL computation -> Aggregation -> Anomaly detection models -> Output

- Critical path:
  1. Input: Wordlist with phonetic transcriptions
  2. Preprocess → Syllabify (if syllable-aware)
  3. Extract n-grams → Compute NLL from corpus statistics
  4. Aggregate NLL scores per word
  5. Apply Isolation Forest (best performer)
  6. Output: Top-k flagged entries for fieldworker verification

- Design tradeoffs:
  - **Character-level vs. Syllable-aware**: Syllable-aware adds preprocessing complexity (syllabification accuracy) but yields 27% F1 improvement
  - **Precision vs. Recall**: System prioritizes recall (0.51-0.56) over precision (0.27-0.29)—acceptable for flagging candidates for human review, not for automated correction
  - **N-gram order**: Higher-order n-grams (trigrams) capture more context but suffer from data sparsity in low-resource settings
  - **Aggregation complexity**: ALL aggregation creates higher-dimensional feature vectors but may introduce noise; simpler aggregations (mean/max) sometimes match or exceed ALL performance

- Failure signatures:
  - **Low precision (many false positives)**: Normal words with rare but valid phonotactic patterns are flagged; expected given modest precision (0.26-0.29)
  - **Missed borrowings**: Loanwords that conform to target language phonotactics will not be detected
  - **Syllabification errors propagate**: Incorrect syllable boundaries corrupt boundary-phoneme and cross-boundary features
  - **Algorithm mismatch**: One-Class SVM or LOF may underperform if data does not match their density/boundary assumptions

- First 3 experiments:
  1. **Baseline replication**: Run character-level trigram analysis with Isolation Forest on the provided Kokborok dataset; verify F1 ≈ 0.29
  2. **Syllable-aware comparison**: Implement automatic syllabification and boundary-phoneme bigram-trigram features with ALL aggregation; target F1 ≈ 0.37
  3. **Algorithm ablation**: Compare Isolation Forest vs. One-Class SVM vs. LOF on the same syllable-aware feature set; confirm iForest dominance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can precision be improved beyond 0.29 while maintaining the high recall (up to 0.56) achieved by syllable-aware approaches?
- Basis: [explicit] The authors state that "precision and recall values remain modest" and that "phonotactic inconsistency detection is inherently difficult, as the distinguishing characteristics of anomalous patterns produce only weak signals in the feature space."
- Why unresolved: Current approaches achieve useful recall but at the cost of many false positives, limiting practical utility for fieldworkers.
- What evidence would resolve it: Novel feature representations or ensemble methods that strengthen anomaly signals while reducing false positives, demonstrated through improved F1-scores on held-out data.

### Open Question 2
- Question: Can phonotactic features distinguish transcription errors from borrowings, which may have different underlying signatures?
- Basis: [inferred] The study groups transcription errors and borrowings together as "anomalies" without attempting to classify them separately.
- Why unresolved: The unsupervised approach flags anomalies but cannot differentiate their etiology, though the paper mentions these have distinct characteristics.
- What evidence would resolve it: A supervised or semi-supervised analysis comparing phonotactic patterns unique to each anomaly type, using expert-annotated data.

### Open Question 3
- Question: How robust is the syllable-aware approach to errors in automatic syllabification for under-described languages?
- Basis: [inferred] The paper applies automatic syllabification based on "language-universal syllable structure constraints" to Kokborok, a language described as "under-described" with uncertain phonology.
- Why unresolved: Incorrect syllabification could propagate errors into the anomaly detection pipeline, but this sensitivity is not evaluated.
- What evidence would resolve it: Ablation studies comparing performance using gold-standard versus automatic syllabification, or analysis of performance degradation under perturbed syllable boundaries.

### Open Question 4
- Question: Does this approach generalize to languages with different phonotactic systems and syllable structures?
- Basis: [inferred] The study evaluates only Kokborok varieties and Bangla, both from the same geographic region with potentially similar constraints.
- Why unresolved: No cross-linguistic validation is presented beyond this specific language group.
- What evidence would resolve it: Replication across diverse language families with varying phonotactic complexity (e.g., tonal languages, polysynthetic languages, languages with complex onset/coda clusters).

## Limitations
- Precision remains modest (0.26-0.29) despite improved recall, limiting practical utility
- Evaluation depends on unknown ground truth annotations and unspecified reference corpus
- Syllabification accuracy not validated for under-described language with uncertain phonology
- No cross-linguistic validation beyond Kokborok and Bangla varieties

## Confidence
- **High**: Isolation Forest consistently outperforms other algorithms across configurations
- **Medium**: Syllable-aware features provide significant improvement over character-level baselines
- **Low**: Multi-aggregation strategies with ALL combination provide optimal feature representation

## Next Checks
1. Obtain ground truth annotations for the Kokborok dataset to verify evaluation metrics and anomaly contamination rate
2. Replicate the syllabification algorithm with multiple sonority hierarchies to assess robustness to implementation choices
3. Test algorithm performance on artificially injected phonotactic anomalies at known contamination rates to verify detection capability