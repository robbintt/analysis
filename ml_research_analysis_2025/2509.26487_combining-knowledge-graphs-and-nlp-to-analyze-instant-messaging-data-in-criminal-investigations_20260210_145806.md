---
ver: rpa2
title: Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal
  Investigations
arxiv_id: '2509.26487'
source_url: https://arxiv.org/abs/2509.26487
tags:
- data
- graph
- search
- knowledge
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes integrating knowledge graphs and NLP to analyze
  instant messaging data in criminal investigations, addressing the challenge of manually
  reviewing large volumes of WhatsApp data. The method combines knowledge graph modeling
  of chat metadata, Whisper-based speech-to-text for audio message transcription,
  and an end-to-end Named Entity Recognition and Linking (NEEL) pipeline for entity
  extraction.
---

# Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal Investigations

## Quick Facts
- arXiv ID: 2509.26487
- Source URL: https://arxiv.org/abs/2509.26487
- Reference count: 27
- The approach integrates knowledge graphs and NLP to analyze WhatsApp data for criminal investigations, showing promise for reducing manual review effort.

## Executive Summary
This paper presents a system that integrates knowledge graphs and NLP to analyze instant messaging data in criminal investigations, specifically addressing the challenge of manually reviewing large volumes of WhatsApp data. The method combines knowledge graph modeling of chat metadata, Whisper-based speech-to-text for audio message transcription, and an end-to-end Named Entity Recognition and Linking (NEEL) pipeline for entity extraction. The system provides two user interfaces: graph querying and visualization via Neo4j, and semantic search via DAVE with faceted search and document exploration. Experimental results show the approach enables effective data exploration and insight generation, though NER performance indicates need for in-domain fine-tuning.

## Method Summary
The approach structures instant messaging dumps into a property graph where nodes represent Participants, Messages, and Chats, enabling relationship traversal rather than manual correlation of search results. Audio attachments are processed using Whisper ASR to generate text transcripts, which undergo the same NLP analysis as text messages. A NEEL pipeline extracts entities (People, Orgs, Locations) and links them to the Knowledge Graph or clusters them for unknown entities, powering the DAVE interface for faceted search filtering. The system stores data in Neo4j for graph visualization and Elasticsearch for semantic search indexing.

## Key Results
- The approach processes 1,296 chats with thousands of entities extracted
- Audio transcriptions contain on average four times more entities than text messages
- NER performance shows F1 scores of 28.8-47.0%, indicating need for in-domain fine-tuning
- Investigators found the solution promising for reducing manual effort and improving evidence analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structuring IM dumps into a property graph exposes relational patterns that syntactic search misses
- Mechanism: Converts flat chat logs into a graph where nodes represent Participants, Messages, and Chats, allowing relationship traversal
- Core assumption: Investigators possess technical literacy to interpret graph visualizations or simplified interfaces can abstract complexity
- Evidence anchors: Abstract states approach "integrates knowledge graphs... to support this analysis by semantically enriching data"; Section 4.1 explains choice of Neo4j for visual interface; related work confirms utility of KGs for context
- Break condition: If metadata is sparse or visualization creates unreadable "hairball" effect

### Mechanism 2
- Claim: Automatic ASR transcription transforms inaccessible audio evidence into searchable text
- Mechanism: Whisper processes audio attachments to generate transcripts subject to same NLP analysis as text messages
- Core assumption: Whisper maintains sufficient accuracy despite background noise and compression artifacts
- Evidence anchors: Abstract mentions "generating transcriptions of voice messages"; Section 5 states audio transcriptions "contain on average four times more entities than text messages"
- Break condition: If audio quality is too poor or language falls outside model's training distribution

### Mechanism 3
- Claim: NEEL enables faceted search, reducing cognitive load of reviewing thousands of messages
- Mechanism: Pipeline extracts entities and links them to KG or clusters unknown entities, powering DAVE interface for entity-type filtering
- Core assumption: NER can accurately identify entities despite informal grammar, abbreviations, and lack of capitalization
- Evidence anchors: Abstract mentions "end-to-end Named Entity Recognition and Linking (NEEL) pipeline for entity extraction"; Section 5 states "median number of distinct entities... can be used to filter out large number of results"
- Break condition: If NER produces excessive false positives, causing noisy filters that hide relevant evidence

## Foundational Learning

- Concept: **Property Graphs (Neo4j)**
  - Why needed here: Understanding node (Chats, Messages, People) and edge (`MENTIONED_IN`, `PARTICIPANT_OF`) structure is required to query data effectively
  - Quick check question: How would you structure a query to find all people who sent a message containing a specific keyword in a group chat?

- Concept: **Named Entity Linking (NEL) vs. NIL Clustering**
  - Why needed here: System must distinguish between known entities (linked to Wikipedia/Graph) and unknown suspects (NIL), grouping mentions together
  - Quick check question: If system finds "Steve" in chat but "Steve" not in database, how does pipeline decide if this "Steve" is same person as "S. Brown" mentioned later?

- Concept: **Word Error Rate (WER) in ASR**
  - Why needed here: To evaluate trade-off between processing speed and risk of transcribing critical evidence incorrectly
  - Quick check question: If Whisper produces transcript with WER of 0.282, how might that impact precision of keyword search for specific proper noun?

## Architecture Onboarding

- Component map: Data Ingestion -> Chat Dumps -> Multimodal Enrichment (Whisper) -> Semantic Enrichment (NEEL) -> Storage (Neo4j & Elasticsearch) -> Interfaces (Neo4j UI & DAVE)
- Critical path: NEEL Pipeline is bottleneck; if entities not extracted and linked correctly, Knowledge Graph becomes disconnected and DAVE faceted search loses filtering power
- Design tradeoffs:
  - Neo4j vs. RDF: Chooses Neo4j for native visualization UI (Section 4.1), trading standardized reasoning capabilities of RDF/OWL
  - Pre-trained vs. Fine-tuned: Uses off-the-shelf Whisper and ITALIAN-LEGAL-BERT for rapid deployment but results in lower F1 scores (Section 5)
- Failure signatures:
  - "Hairball" Effect: Graph visualization becomes unreadable due to high node density
  - Low F1 Score: NER fails to recognize abbreviated names or informal slang
  - NIL Clustering Errors: Distinct people merged into one cluster or one person split into multiple clusters
- First 3 experiments:
  1. Audio Quality Stress Test: Run Whisper on sample of noisy vs. clean voice notes to quantify transcription quality degradation
  2. Baseline NER Evaluation: Manually annotate small gold standard to verify reported F1 scores for specific slang/abbreviations
  3. Query Pattern Validation: Test 30 keywords mentioned in Section 5 and verify if entity filters successfully reduce result set to manageable size

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what degree does in-domain fine-tuning improve NER performance on noisy IMA data?
- Basis in paper: [explicit] Authors report unsatisfactory NER results (F1 28.8%) and explicitly state "in-distribution fine-tuning is necessary" to handle chat-specific peculiarities
- Why unresolved: Current evaluation relies on pre-trained models not optimized for informal syntax found in Instant Messaging Apps
- What evidence would resolve it: Comparative study showing F1 score improvements after fine-tuning transformer on larger, annotated gold standard of IMA data

### Open Question 2
- Question: How does proposed XGboost/Louvain entity clustering method quantitatively compare to established baselines?
- Basis in paper: [explicit] Paper states "A quantitative comparison between our clustering approach and previous work is out of the scope of this paper"
- Why unresolved: While method is implemented, relative effectiveness against other NIL clustering algorithms remains unmeasured
- What evidence would resolve it: Benchmarking results on standard datasets comparing proposed approach's precision and recall against state-of-the-art entity clustering techniques

### Open Question 3
- Question: Can conversational interfaces effectively bridge gap between non-technical investigators and complex graph queries?
- Basis in paper: [explicit] Investigators expressed interest in "conversational search interfaces" to avoid learning Cypher/Neo4j syntax, but prototype is currently in "early" stage
- Why unresolved: Interface is proof-of-concept; effectiveness for generating accurate investigative insights compared to manual querying has not yet been measured
- What evidence would resolve it: User studies evaluating query success rates, time-to-insight, and cognitive load for investigators using conversational versus manual graph querying

## Limitations
- NER performance (F1 28.8-47.0%) indicates significant challenges with informal chat data requiring domain-specific fine-tuning
- Approach may not generalize beyond WhatsApp and Italian language contexts without substantial adaptation
- Paper does not address potential biases in KG construction or handling of missing metadata (deleted messages, encrypted content)

## Confidence

**High Confidence**: Knowledge graph architecture for chat metadata is well-grounded in existing graph database applications and directly addresses known investigative need; dual-interface design (Neo4j + DAVE) represents practical approach to serving different user workflows.

**Medium Confidence**: Multimodal integration of audio transcription with text analysis is technically sound but performance depends heavily on audio quality variations; NEEL pipeline's effectiveness is supported by methodology but limited by reported low F1 scores, suggesting current utility may be more as filtering tool than precise entity extraction.

## Next Checks

1. **Audio Quality Validation**: Test Whisper transcription on stratified sample of forensic audio with varying quality levels (clean, compressed, noisy) to quantify performance degradation and establish quality thresholds for reliable entity extraction.

2. **NER Domain Adaptation**: Conduct small-scale manual annotation study on informal chat text from target jurisdiction to verify if legal-domain model requires retraining on criminal investigation-specific terminology and abbreviations.

3. **Query Effectiveness Assessment**: Have investigators execute realistic investigative queries using both interfaces (graph traversal vs. faceted search) on sample dataset, measuring time-to-insight and comparing results against manual review to quantify efficiency gains.