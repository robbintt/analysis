---
ver: rpa2
title: 'SAM-Fed: SAM-Guided Federated Semi-Supervised Learning for Medical Image Segmentation'
arxiv_id: '2511.14302'
source_url: https://arxiv.org/abs/2511.14302
tags:
- client
- federated
- learning
- semi-supervised
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'SAM-Fed addresses the challenge of reliable pseudo-label generation
  in federated semi-supervised medical image segmentation, where client-side models
  are often lightweight due to computational constraints. It introduces a dual knowledge
  distillation strategy: federated distillation between server and client models,
  and SAM-guided distillation using the high-capacity Segment Anything Model for pixel-level
  supervision.'
---

# SAM-Fed: SAM-Fed: SAM-Guided Federated Semi-Supervised Learning for Medical Image Segmentation

## Quick Facts
- arXiv ID: 2511.14302
- Source URL: https://arxiv.org/abs/2511.14302
- Authors: Sahar Nasirihaghighi; Negin Ghamsarian; Yiping Li; Marcel Breeuwer; Raphael Sznitman; Klaus Schoeffmann
- Reference count: 0
- Primary result: Achieves Dice scores of 86.98% (ISIC2018) and 69.20% (polyps) with SAM-guided federated distillation

## Executive Summary
SAM-Fed addresses the challenge of reliable pseudo-label generation in federated semi-supervised medical image segmentation, where client-side models are often lightweight due to computational constraints. It introduces a dual knowledge distillation strategy: federated distillation between server and client models, and SAM-guided distillation using the high-capacity Segment Anything Model for pixel-level supervision. An adaptive agreement mechanism dynamically selects or weights pseudo-labels based on consensus and confidence between SAM and client predictions. Evaluated on skin lesion and polyp segmentation across homogeneous and heterogeneous client settings, SAM-Fed achieves state-of-the-art performance, with Dice scores of 86.98% (ISIC2018) and 69.20% (polyps) and HD95 scores of 24.67% and 52.81%, respectively, demonstrating robustness and generalizability across diverse architectures and non-IID data distributions.

## Method Summary
SAM-Fed implements a federated semi-supervised learning framework that leverages the Segment Anything Model (SAM) to generate high-quality pseudo-labels for unlabeled medical images. The approach employs a two-stage distillation process: federated distillation where the server model supervises client models through knowledge transfer, and SAM-guided distillation where SAM provides pixel-level supervision. The adaptive agreement mechanism evaluates consensus between SAM and client predictions, dynamically selecting or weighting pseudo-labels based on their confidence and agreement scores. This strategy addresses the limitations of lightweight client models in federated settings while maintaining privacy by keeping data localized. The framework operates across both homogeneous and heterogeneous client architectures, demonstrating flexibility in real-world deployment scenarios.

## Key Results
- Achieves Dice scores of 86.98% on ISIC2018 skin lesion dataset and 69.20% on polyp segmentation
- HD95 scores of 24.67% (skin lesions) and 52.81% (polyps) demonstrate precise boundary delineation
- Outperforms state-of-the-art methods in both homogeneous and heterogeneous client settings
- Shows robustness across non-IID data distributions with consistent performance improvements

## Why This Works (Mechanism)
The dual distillation approach combines the strengths of federated learning's privacy-preserving distributed training with SAM's powerful zero-shot segmentation capabilities. By using SAM as a teacher model for pixel-level supervision, SAM-Fed compensates for the limited capacity of lightweight client models typical in federated settings. The adaptive agreement mechanism ensures only high-quality pseudo-labels are used, filtering out uncertain predictions through consensus evaluation. This architecture enables effective knowledge transfer while maintaining data privacy, addressing the fundamental challenge of limited labeled data in medical imaging federated learning scenarios.

## Foundational Learning
- **Federated Learning**: Distributed training across multiple clients without sharing raw data - needed for privacy preservation in medical imaging, quick check: verify data remains local during training
- **Semi-Supervised Learning**: Learning from both labeled and unlabeled data - needed due to scarcity of annotated medical images, quick check: confirm unlabeled data utilization
- **Knowledge Distillation**: Transferring knowledge from large models to smaller ones - needed to enhance lightweight client models, quick check: validate teacher-student relationship effectiveness
- **Adaptive Agreement Mechanisms**: Dynamic selection based on prediction confidence - needed for reliable pseudo-label filtering, quick check: measure consensus accuracy thresholds
- **Heterogeneous Client Architectures**: Training across different model architectures - needed for realistic deployment scenarios, quick check: test across diverse backbone types
- **Non-IID Data Distributions**: Handling data with varying distributions across clients - needed for real-world medical data, quick check: validate performance across skewed distributions

## Architecture Onboarding

**Component Map**: SAM (teacher) -> Server Model -> Client Models -> Adaptive Agreement Mechanism -> Pseudo-label Selection

**Critical Path**: Data preprocessing → SAM pseudo-label generation → Federated distillation → SAM-guided distillation → Adaptive agreement evaluation → Model update

**Design Tradeoffs**: 
- Privacy vs. performance: Keeping data local vs. using SAM's powerful segmentation
- Computational efficiency vs. accuracy: Lightweight clients vs. SAM's heavy computation
- Flexibility vs. complexity: Supporting heterogeneous architectures vs. increased implementation complexity

**Failure Signatures**: 
- Poor consensus scores indicating unreliable pseudo-labels
- Degradation in performance when SAM's predictions are inconsistent
- Communication bottlenecks in federated aggregation steps

**First Experiments**:
1. Validate SAM's zero-shot performance on medical images before integration
2. Test federated distillation baseline without SAM guidance
3. Evaluate adaptive agreement mechanism's filtering effectiveness with synthetic consensus scenarios

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation limited to only two medical imaging tasks (skin lesion and polyp segmentation), restricting generalizability
- Heterogeneous client experiments use only three different architectures, potentially underrepresenting real-world diversity
- Relatively small number of clients (5-20) compared to typical federated learning deployments with hundreds or thousands of devices
- Reliance on SAM introduces uncertainty about performance across diverse medical imaging modalities
- Adaptive agreement mechanism effectiveness depends on SAM's prediction quality, which may vary with image characteristics

## Confidence
- **High confidence**: Performance improvements over baseline methods on the two evaluated datasets
- **Medium confidence**: Effectiveness of the dual distillation strategy in heterogeneous settings
- **Medium confidence**: Robustness claims across non-IID data distributions

## Next Checks
1. Evaluate SAM-Fed across a broader range of medical imaging tasks (e.g., cardiac MRI, lung CT, brain tumor segmentation) to assess generalizability
2. Test with larger numbers of clients (100+) and more diverse architectural heterogeneity (5+ different backbone types)
3. Conduct ablation studies isolating the contribution of each distillation component and the adaptive agreement mechanism