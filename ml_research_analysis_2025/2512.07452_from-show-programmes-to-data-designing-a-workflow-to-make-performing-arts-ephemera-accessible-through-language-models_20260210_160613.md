---
ver: rpa2
title: 'From Show Programmes to Data: Designing a Workflow to Make Performing Arts
  Ephemera Accessible Through Language Models'
arxiv_id: '2512.07452'
source_url: https://arxiv.org/abs/2512.07452
tags:
- page
- data
- https
- text
- programmes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a workflow to transform theatre programmes
  into structured data using multimodal large language models (LLMs) and a reasoning
  model trained on the Linked Art ontology. The approach achieves over 98% segmentation
  accuracy and 0.98 Levenshtein ratio for text extraction.
---

# From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models

## Quick Facts
- arXiv ID: 2512.07452
- Source URL: https://arxiv.org/abs/2512.07452
- Reference count: 40
- Primary result: >98% segmentation accuracy and 0.98 Levenshtein ratio for transforming theatre programmes into structured RDF data

## Executive Summary
This paper presents a workflow to transform theatre programmes into structured data using multimodal large language models (LLMs) and a reasoning model trained on the Linked Art ontology. The approach achieves over 98% segmentation accuracy and 0.98 Levenshtein ratio for text extraction. The method combines Claude Sonnet 3.7 for transcription with a custom reasoning model (POntAvignon) trained via reinforcement learning to generate RDF triples. The three-tier Work-Production-Show ontology structure enables standardized representation of performing arts data. Results demonstrate the potential for large-scale, interoperable analysis of performing arts ephemera while preserving textual integrity and semantic richness.

## Method Summary
The workflow processes 8,408 pages from 1,535 Festival d'Avignon programmes using a three-stage pipeline: (1) dhSegment lines model with vertical projection for document segmentation, refined by width-based filtering; (2) Claude Sonnet 3.7 via Anthropic batch API for OCR transcription in markdown format; (3) POntAvignon reasoning model (350M parameters) trained via GRPO reinforcement learning to generate RDF triples from the Linked Art ontology extension. The segmentation achieves 99.2% accuracy, while transcription reaches 0.98 document-level Levenshtein ratio. The approach handles both digitized (1971-2002) and born-digital (2007-2022) programmes, with reinforcement learning combining formal property adherence rewards and semantic accuracy rewards from a judge model.

## Key Results
- 99.2% segmentation accuracy across 8,408 pages using dhSegment with pre/post-processing
- 0.98 document-level Levenshtein ratio for text extraction (vs. 0.11 Jaccard score for EasyOCR)
- POntAvignon reasoning model generates ontology-compliant RDF triples with reduced hallucination through GRPO training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Vision-language models (VLMs) outperform traditional OCR for complex, multi-layout documents.
- Mechanism: VLMs return text tokens rather than single characters, enabling detection of hierarchical structure, paragraph recomposition across columns, and table-to-sentence transformation—capabilities absent in conventional OCR pipelines.
- Core assumption: The training data for VLMs includes sufficient document layout diversity to generalize to performing arts ephemera.
- Evidence anchors:
  - [abstract] "achieving over 98% of correct extraction"
  - [section 1.2] Table 3 shows Claude achieving 0.9833 Levenshtein ratio vs. EasyOCR's 0.11 Jaccard word score (Appendix G, Table 5)
  - [corpus] No direct corpus evidence for VLM-vs-OCR comparison in performing arts specifically; related work (SciMantify) addresses PDF semantification but not OCR performance.
- Break condition: Highly degraded scans with substantial ink bleed or handwritten annotations may exceed VLM robustness; the ground truth corpus excluded severely challenging cases.

### Mechanism 2
- Claim: Two-phase segmentation (pre-segmentation + post-segmentation with width-based filtering) substantially improves subpage isolation over single-pass approaches.
- Mechanism: Phase 1 uses dhSegment lines model + vertical projection to identify separators; Phase 2 refines via width-threshold filtering (removing oversegmentation) and layout-based normalization (fixing undersegmentation). Born-digital documents additionally undergo page reordering to match physical reading order.
- Core assumption: Subpages within a document share approximately uniform width, enabling median-width thresholds.
- Evidence anchors:
  - [section 1.1] Table 1: 99.2% correct segmentation across 8,408 pages
  - [section 1.1] Table 2: Post-segmentation improves accuracy from 62.5% to 96.9% on sampled digitized programmes
  - [corpus] Weak external validation; no corpus neighbor directly addresses document segmentation for cultural heritage.
- Break condition: Documents with irregular folding patterns or non-uniform subpage widths will violate the width-threshold heuristic.

### Mechanism 3
- Claim: Reinforcement learning with dual rewards (formal + semantic) trains a small reasoning model to generate ontology-compliant RDF triples with reduced hallucination.
- Mechanism: Formal reward enforces exclusive use of predefined properties (zero reward for violations). Soft reward uses a judge model (Gemma 12b) to grade output against ground truth on a 0–10 scale. GRPO training over 600 steps produces two-phase learning: aggressive constraint acquisition followed by gradual reasoning refinement.
- Core assumption: The ground truth examples are sufficiently representative of edge cases in the target domain.
- Evidence anchors:
  - [section 3] Figure 5 shows reward curve with distinct two-phase pattern
  - [section 3] "The two-phase training process—initial constraint learning followed by reasoning refinement—suggests that domain-specific fine-tuning significantly improves performance"
  - [corpus] No corpus evidence for RL-trained reasoning models in humanities; PanelTR addresses table reasoning via multi-agent discussion, not RL.
- Break condition: Domain shift to programmes in languages or theatrical traditions not represented in training data will degrade both formal compliance and semantic accuracy.

## Foundational Learning

- Concept: **RDF triples and knowledge graphs**
  - Why needed here: POntAvignon outputs RDF triples (subject–property–object) that populate a Wikibase infrastructure; understanding triple structure is prerequisite for debugging annotation failures.
  - Quick check question: Can you explain why `P57 (director) = Guy Rétoré` is a valid triple and what would make it invalid under the Linked Art ontology?

- Concept: **Reinforcement learning with GRPO (Group Relative Policy Optimization)**
  - Why needed here: The reasoning model is trained via online RL where drafts are scored against rewards; understanding reward shaping is essential for extending the ontology or adjusting training.
  - Quick check question: If the formal reward is 0 for any property outside the predefined set, what happens to the policy gradient when all 8 drafts violate this constraint?

- Concept: **Levenshtein distance and ratio for OCR evaluation**
  - Why needed here: The paper uses Levenshtein ratio (0.98) as the primary transcription quality metric; understanding its limitations versus WER/CER is necessary for evaluation design.
  - Quick check question: Why might a high Levenshtein ratio still yield poor named entity extraction?

## Architecture Onboarding

- Component map:
  - PDF programmes (born-digital or digitized) -> image conversion
  - dhSegment lines model -> vertical projection -> width-based filtering -> normalized subpages
  - Claude Sonnet 3.7 via Anthropic batch API -> markdown output
  - POntAvignon (350M parameter reasoning model) -> RDF triples
  - Wikibase infrastructure with reconciliation links to ISNI/VIAF/Geonames/Wikidata

- Critical path: Segmentation accuracy -> transcription quality -> ontology compliance. Errors propagate; segmentation failures corrupt transcription, which corrupts entity extraction.

- Design tradeoffs:
  - Claude API (~$80 for 8,408 pages) vs. open-source VLMs (SmolDocling mentioned but not evaluated)
  - 350M parameter model (efficient, domain-specific) vs. larger generalist models (better zero-shot, higher inference cost)
  - JSON-LD (human-readable, Linked Art native) vs. RDF/XML (broader tooling, steeper learning curve)

- Failure signatures:
  - Oversegmentation: Page width deviates from year-specific median threshold (Table 4)
  - Content policy refusal: Claude rejects image; requires DAN prompt fallback (Appendix E)
  - Property hallucination: POntAvignon generates Wikidata property IDs not in predefined set; formal reward should zero these, but check output logs

- First 3 experiments:
  1. **Segmentation validation on new corpus**: Apply the two-phase pipeline to a different festival's programmes; manually verify ~100 pages to confirm width-threshold generalization.
  2. **VLM comparison**: Run identical transcription prompts with SmolDocling vs. Claude on 30 ground-truth pages; compare Levenshtein ratio and NER precision.
  3. **Ontology stress test**: Feed POntAvignon 10 edge-case programmes (e.g., multilingual, cancelled performances, in-progress works) and analyze where formal vs. soft rewards conflict.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the POntAvignon reasoning model generalize to process theatre programmes from other festivals, venues, and linguistic contexts beyond Festival d'Avignon?
- Basis in paper: [explicit] "A more ambitious project will be to make it a generic structured data generation tool for theatre programmes... accurate automation would require two major developments: Increasing the number and the diversity of the sources beyond the Avignon show programmes, especially in additional languages"
- Why unresolved: Current training data is exclusively French-language Avignon programmes; model has not been validated on other corpora.
- What evidence would resolve it: Evaluation of POntAvignon on diverse theatre programme collections from different countries, languages, and archival traditions.

### Open Question 2
- Question: How can reproducibility be ensured when proprietary LLMs (like Claude Sonnet) are updated and produce non-deterministic outputs?
- Basis in paper: [explicit] "the instability of proprietary LLMs presents significant reproducibility concerns. Model performance may change following updates, and outputs are non-deterministic by design, complicating the validation process."
- Why unresolved: Dependence on closed-source APIs introduces uncontrolled variability; no mitigation strategy proposed.
- What evidence would resolve it: Longitudinal benchmarks tracking extraction quality across API versions, or development of open-source VLM alternatives achieving comparable performance.

### Open Question 3
- Question: Can internal tool-use capabilities be integrated into the reasoning model to automate reconciliation with external authority records (Wikidata, VIAF, ISNI)?
- Basis in paper: [explicit] "Develop internal 'tool use' abilities within the model to perform data reconciliation and, through this, verification. In practice, this could include built-in connections to Wikidata APIs."
- Why unresolved: Current workflow requires post-hoc manual reconciliation; no tool-use architecture has been implemented or tested.
- What evidence would resolve it: Prototype demonstrating automated entity linking accuracy against ground truth with authority file URIs.

## Limitations

- Dependence on proprietary LLMs (Claude) introduces reproducibility concerns and potential performance variability across API versions
- Ground truth corpus is limited to 30 programmes (151 pages) and won't be publicly available until 2028, constraining validation and extension
- Current reasoning model is trained exclusively on French-language Avignon programmes, limiting generalizability to other festivals and languages

## Confidence

- High: Segmentation accuracy (99.2%) and transcription quality (0.98 Levenshtein ratio) are well-validated with clear evidence and reproducible methodology
- Medium: Reinforcement learning approach for ontology compliance shows promise but lacks external validation and depends on proprietary ground truth
- Low: Generalization claims to other festivals and languages are speculative, with no experimental evidence beyond the current corpus

## Next Checks

1. **Validate segmentation on new corpus**: Apply the two-phase pipeline to programmes from a different theatre festival and manually verify segmentation accuracy on 100 pages to test width-threshold generalization
2. **Benchmark transcription alternatives**: Process 30 ground-truth pages with SmolDocling vs. Claude using identical prompts and compare Levenshtein ratios and NER precision scores
3. **Test ontology robustness**: Feed POntAvignon 10 edge-case programmes (multilingual, cancelled performances, in-progress works) and analyze failure patterns where formal vs. soft rewards conflict