---
ver: rpa2
title: 'Hexcute: A Compiler Framework for Automating Layout Synthesis in GPU Programs'
arxiv_id: '2504.16214'
source_url: https://arxiv.org/abs/2504.16214
tags:
- hexcute
- layout
- layouts
- tensor
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Hexcute is a compiler framework that automates layout synthesis
  in GPU programs for deep learning. It addresses the challenge of manually specifying
  optimal tensor layouts, which is time-consuming and error-prone in low-level frameworks
  like CUTLASS.
---

# Hexcute: A Compiler Framework for Automating Layout Synthesis in GPU Programs

## Quick Facts
- **arXiv ID:** 2504.16214
- **Source URL:** https://arxiv.org/abs/2504.16214
- **Reference count:** 40
- **Primary result:** Automates tensor layout inference for GPU kernels, matching cuBLAS/FlashAttention performance while reducing code by 1.27×-7.94× and delivering 2.6× end-to-end speedup on vLLM.

## Executive Summary
Hexcute is a compiler framework that automates layout synthesis for GPU kernels in deep learning workloads. It addresses the challenge of manually specifying optimal tensor layouts in low-level frameworks like CUTLASS by formalizing layout synthesis as a constraint programming problem solved via type inference. Built on a tile-level programming interface with shared memory and register abstractions, Hexcute provides explicit control over dataflow and pipelining while systematically exploring optimal layouts and instructions. The framework achieves performance parity with state-of-the-art libraries while significantly reducing code complexity.

## Method Summary
Hexcute extends Hidet Script with tile-level primitives (copy, gemm, cast, rearrange) and employs a type-inference-based algorithm for thread-value layout synthesis. The approach uses constraint solving to infer optimal tensor layouts, unifies shared memory layouts through layout unification and swizzle selection, and applies an analytical cost model for instruction selection. The framework targets GEMM, Attention, MoE, and Mamba scan operations, evaluating on A100 and H100 GPUs against cuBLAS, CUTLASS, FlashAttention, Triton, and Marlin baselines.

## Key Results
- Matches cuBLAS and FlashAttention performance on GEMM and Attention variants
- Reduces code size by 1.27×-7.94× compared to CUTLASS
- Achieves 6.46× average speedup over Triton for mixed-type MoE operators
- Delivers up to 2.60× speedup on DeepSeek-R1-AWQ and 2.04× on Mamba-based models in vLLM end-to-end evaluations

## Why This Works (Mechanism)
Hexcute's constraint-based type inference algorithm systematically explores the layout space by propagating constraints from performance-critical operations (GEMMs) through the computation graph. The framework leverages tile-level abstractions to expose memory hierarchy control while automating the complex layout decisions that would otherwise require manual optimization. By unifying shared memory layouts and selecting appropriate swizzles, Hexcute eliminates bank conflicts and maximizes memory throughput.

## Foundational Learning
- **Tile-level programming:** Why needed - Provides explicit control over memory hierarchy and dataflow. Quick check - Verify gemm primitive takes tile shapes and layout hints.
- **Constraint-based layout synthesis:** Why needed - Automates the exploration of optimal tensor layouts. Quick check - Confirm constraint generation from instruction semantics and layout algebra.
- **Shared memory layout unification:** Why needed - Prevents bank conflicts and maximizes throughput. Quick check - Ensure unification algorithm merges dependent buffer layouts.
- **Analytical cost modeling:** Why needed - Guides instruction selection for optimal performance. Quick check - Validate cost predictions match measured latencies within 10%.
- **Type inference for layouts:** Why needed - Propagates layout constraints through computation graphs. Quick check - Verify inferred layouts maintain data consistency across operations.
- **Register-layout conflict resolution:** Why needed - Handles multiple connected GEMM operations. Quick check - Confirm rearrange operators or manual annotations resolve conflicts.

## Architecture Onboarding

**Component Map:** Hidet Script DSL -> Hexcute Compiler -> CUDA/PTX Code -> GPU Execution

**Critical Path:** User kernel specification -> Constraint generation -> Layout inference -> Instruction selection -> Code generation -> GPU execution

**Design Tradeoffs:** Manual layout specification vs. automated synthesis (automation reduces development time but requires constraint solving overhead), tile-level control vs. abstraction (fine-grained control vs. ease of use), analytical cost modeling vs. empirical measurement (fast compilation vs. potentially suboptimal choices)

**Failure Signatures:** Permission errors when locking GPU frequency (requires `--privileged` flag), CUDA out-of-memory during compilation with many candidates (reduce `--jobs` or compile sequentially), missing `ldmatrix`/`mma` instructions in generated PTX (verify CUDA version and compute capability targets)

**First Experiments:**
1. Run `run_h100.sh` to reproduce kernel benchmarks and verify Table II performance numbers
2. Execute `run_moe.sh` to confirm MoE layer speedup (Fig. 11) and cost model accuracy (Fig. 12)
3. Perform `run_scan.sh` to validate Mamba scan throughput and compare against Marlin baseline

## Open Questions the Paper Calls Out
- **Multiple GEMM layout conflicts:** Can the framework automatically resolve register-layout conflicts for multiple connected GEMM operations without requiring manual user annotations? The current algorithm requires user annotations for consistent thread arrangements.
- **Shared memory layout complexity:** How can shared-memory layout synthesis be formalized to guarantee sub-exponential search complexity for kernels with highly dependent buffers? Current heuristics reduce complexity but lack theoretical guarantees.
- **Cross-architecture generalization:** Can Hexcute's constraint-based synthesis algorithm effectively map to non-NVIDIA architectures (e.g., AMD CDNA) that lack CuTe layout abstractions? The framework relies heavily on NVIDIA-specific instruction semantics.

## Limitations
- vLLM end-to-end results depend on complete integration code not provided in the artifact
- Hidet version pinning and internal patches are not explicitly specified, creating potential drift risk
- Analytical cost model microbenchmarks are referenced but not directly provided in the artifact

## Confidence
- **High confidence** in constraint-based layout synthesis correctness (matches hand-optimized CUTLASS/FlashAttention)
- **Medium confidence** in MoE and Mamba scan speedups (6.46× vs Triton, 2.60× vs Marlin)
- **Low confidence** in vLLM end-to-end results (2.60× on DeepSeek-R1-AWQ, 2.04× on Jamba-mini) without full integration

## Next Checks
1. Run `run_scan.sh` on both A100 and H100 to reproduce Mamba scan throughput and verify cost model predictions align within 10%
2. Modify MoE kernel to add synthetic layout mismatch and confirm Hexcute produces valid kernel without runtime errors
3. Generate PTX assembly for `gemm_32_32_32_16` shape and manually verify `mma`/`ldmatrix` instruction counts match Table II