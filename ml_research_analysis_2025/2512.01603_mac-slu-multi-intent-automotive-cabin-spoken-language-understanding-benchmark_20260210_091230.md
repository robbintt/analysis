---
ver: rpa2
title: 'MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark'
arxiv_id: '2512.01603'
source_url: https://arxiv.org/abs/2512.01603
tags:
- arxiv
- language
- lalms
- llms
- mac-slu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for more complex and diverse datasets
  for Spoken Language Understanding (SLU) tasks, particularly in the automotive domain,
  and the absence of a unified benchmark for evaluating Large Language Models (LLMs)
  and Large Audio Language Models (LALMs) on these tasks. The core method idea involves
  introducing MAC-SLU, a novel Multi-Intent Automotive Cabin Spoken Language Understanding
  Dataset, which features authentic and complex multi-intent data derived from real-world
  automotive text commands and TTS-synthesized speech.
---

# MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark

## Quick Facts
- arXiv ID: 2512.01603
- Source URL: https://arxiv.org/abs/2512.01603
- Reference count: 0
- Primary result: Introduced a new multi-intent automotive SLU benchmark and showed that E2E LALMs avoid ASR error propagation while SFT significantly outperforms ICL

## Executive Summary
This paper introduces MAC-SLU, a novel multi-intent automotive cabin spoken language understanding dataset featuring complex real-world commands. The authors benchmark leading LLMs and LALMs on this dataset using various paradigms including in-context learning, supervised fine-tuning, and end-to-end approaches. The results demonstrate that while models can complete SLU tasks through in-context learning, their performance significantly lags behind supervised fine-tuning, and that end-to-end LALMs effectively avoid error propagation from speech recognition while achieving comparable performance to pipeline approaches.

## Method Summary
The authors introduce MAC-SLU, a multi-intent automotive cabin SLU dataset with 17,997 training, 1,391 dev, and 1,151 test samples. They evaluate leading open-source LLMs and LALMs using three main approaches: in-context learning (ICL) via vLLM with a specific prompt template, supervised fine-tuning (SFT) using Llama-Factory with LoRA (rank=16, alpha=32), and both end-to-end (E2E) and pipeline paradigms. The dataset contains authentic and complex multi-intent data derived from real-world automotive text commands and TTS-synthesized speech, covering 81 intents and 192 slots.

## Key Results
- E2E LALMs (e.g., Qwen2.5-Omni-7B) achieve 55.60% Overall Accuracy, comparable to pipeline approaches and effectively avoid ASR error propagation
- In-context learning shows significant performance gap compared to supervised fine-tuning, with Qwen2.5-Omni-7B achieving 14.42% OA in ICL vs. 60.73% OA after SFT
- Standard SLU metrics based on exact matching may underestimate model performance due to semantically correct but lexically different predictions

## Why This Works (Mechanism)

### Mechanism 1: E2E LALMs Mitigate ASR Error Propagation
- **Claim:** End-to-End LALMs avoid performance degradation from ASR errors found in pipeline systems
- **Mechanism:** E2E LALMs map audio features directly to semantics, bypassing erroneous intermediate text representations from ASR (e.g., 10.40% CER with Whisper)
- **Core assumption:** LALM's audio encoder aligns audio tokens to semantic tokens more reliably than cascaded systems
- **Evidence:** Qwen2.5-Omni-7B (E2E) achieves 55.60% OA vs. Whisper+Qwen3-8B (Pipeline) at 35.45%
- **Break condition:** If LALM lacks sufficient pre-training on speech-text alignment, performance may fall below even a noisy pipeline

### Mechanism 2: SFT Required to Bridge Generalization Gap
- **Claim:** In-domain SFT is required to bridge generalization gap; ICL alone is insufficient for complex multi-intent reasoning
- **Mechanism:** General-purpose LLMs lack specific schema mapping priors for automotive domain; ICL can activate format-following but fails to robustly bind specific slot values without weight updates
- **Core assumption:** Multi-intent command distribution is sparse in pre-training corpus, requiring parameter updates to ingrain specific ontology
- **Evidence:** Qwen3-32B 10-shot ICL achieves 14.42% OA, while SFT models boost OA up to 60.73%
- **Break condition:** If model scales significantly beyond 32B parameters, ICL vs. SFT gap may narrow

### Mechanism 3: Evaluation Metrics Underestimate Functional Correctness
- **Claim:** Exact-match metrics underestimate LALM functional correctness due to lexical variation
- **Mechanism:** LALMs generate semantically correct responses that differ in phrasing from ground truth labels (e.g., "window" vs. "car window"), penalized by standard metrics
- **Core assumption:** System goal is semantic execution rather than verbatim transcription of intent labels
- **Evidence:** Significant portion of errors arise from semantically correct but differently phrased outputs
- **Break condition:** If downstream system requires strict exact string keys for API triggers, semantic correctness becomes irrelevant

## Foundational Learning

- **Concept:** Pipeline vs. End-to-End (E2E) SLU
  - **Why needed here:** The paper benchmarks these two paradigms directly. Pipeline = Audio → Text → Meaning, while E2E = Audio → Meaning.
  - **Quick check question:** Does the system rely on a distinct transcription step before intent classification? (If yes, it is a Pipeline system)

- **Concept:** Multi-Intent vs. Single-Intent
  - **Why needed here:** MAC-SLU's primary contribution is complex, multi-intent data (up to 5 intents). Traditional metrics assume one intent per utterance.
  - **Quick check question:** If a user says "Play music and navigate home," does the model output one combined label or two distinct semantic frames?

- **Concept:** LoRA (Low-Rank Adaptation)
  - **Why needed here:** The authors use LoRA for SFT. Understanding that this updates only a small subset of weights allows for efficient fine-tuning on consumer hardware.
  - **Quick check question:** Are we updating all parameters of the LLM, or just injecting trainable rank-decomposition matrices?

## Architecture Onboarding

- **Component map:** Mandarin Speech (TTS) → Whisper-Large-V3-Turbo (ASR) + Qwen3 (NLU) → Structured JSON containing Domain, Intent, and Slots
- **Critical path:** The E2E LALM path (e.g., Qwen2.5-Omni) is the critical modernization target, removing dependency on separate high-performance ASR engine
- **Design tradeoffs:**
  - **Pipeline (ASR + LLM):** Higher modularity (can swap ASR/NLU independently), but suffers from compounding errors (CER directly lowers OA)
  - **E2E (LALM):** Better error recovery on noisy speech, but monolithic (harder to debug audio vs. reasoning failures) and currently slightly trails text-only upper bounds
- **Failure signatures:**
  - **ASR Hallucination:** Pipeline models generating intents for words that were not spoken but inferred by "hallucinating" ASR
  - **Format Instability:** ICL-based models failing to output valid JSON structures, whereas SFT models adhere strictly to prompt template
  - **Slot Boundary Errors:** Models identifying correct intent but failing to align slot values
- **First 3 experiments:**
  1. **Text-Only Baseline:** Feed ground-truth text into LLM using prompt template to isolate NLU capability from ASR noise
  2. **Pipeline Robustness Test:** Run pipeline (Whisper + LLM) on test set, compare OA against Text-Only baseline to quantify "Error Propagation Gap"
  3. **E2E Ablation:** Fine-tune small LALM (e.g., Qwen2.5-Omni-3B) vs. 7B counterpart using LoRA to verify if E2E scaling closes gap with text-only baseline

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can evaluation metrics be redesigned to capture semantic correctness in SLU without relying on rigid exact-match string comparisons?
- **Basis in paper:** [explicit] The conclusion explicitly states that future work must focus on "exploring more semantically-aligned evaluation metrics"
- **Why unresolved:** Qualitative analysis shows models often produce semantically correct outputs that are penalized due to lexical differences from ground truth
- **What evidence would resolve it:** Development and validation of new metric using semantic similarity (e.g., embedding-based comparisons) or LLM-based evaluation

### Open Question 2
- **Question:** What specific training methodologies or architectural improvements can close the performance gap between ICL and SFT for LALMs?
- **Basis in paper:** [explicit] Authors identify enhancing "in-context learning capabilities" as primary direction for future work
- **Why unresolved:** Experiments reveal significant disparity where SFT boosts Qwen2.5-Omni-7B's overall accuracy by 47% compared to ICL
- **What evidence would resolve it:** Study demonstrating novel ICL technique or pre-training objective enabling LALMs to achieve SFT-comparable performance (over 55% OA) without weight updates

### Open Question 3
- **Question:** To what extent does reliance on TTS-synthesized speech in MAC-SLU affect generalizability to real-world, noisy automotive environments?
- **Basis in paper:** [inferred] Paper notes in Section 3.2 that "Speech Data Generation" was accomplished via synthesis using clean templates, rather than recording human speakers in vehicle
- **Why unresolved:** Synthetic speech often lacks background noise, channel variability, and prosodic irregularities present in actual driving scenarios
- **What evidence would resolve it:** Comparative evaluation where current SOTA models are tested on supplementary set of human-recorded commands collected in moving vehicle with ambient noise

## Limitations
- All audio data is synthesized via TTS from text transcripts, raising questions about performance on real-world speech patterns, accents, and background noise
- Exact-match metrics may underestimate model performance when predictions are semantically correct but lexically different from ground truth labels
- Fine-tuning experiments lack specific details about learning rates, batch sizes, and training duration, limiting reproducibility

## Confidence

**High Confidence:** Core finding that E2E LALMs avoid ASR error propagation is well-supported by quantitative comparison (Qwen2.5-Omni-7B at 55.60% vs. Whisper+Qwen3-8B at 35.45%). Superiority of SFT over ICL is clearly demonstrated (14.42% vs. 60.73% Overall Accuracy).

**Medium Confidence:** Claim that SFT is necessary to bridge generalization gap assumes pre-training corpora lack sufficient multi-intent automotive examples. Interpretation of semantic correctness vs. exact match involves some subjective judgment.

**Low Confidence:** Scalability assumptions about ICL performance for larger models (beyond 32B parameters) remain speculative since paper doesn't test frontier models.

## Next Checks

1. **Real Speech Validation:** Evaluate best-performing models on small subset of real human-recorded automotive speech data to assess impact of TTS synthesis limitations on reported performance.

2. **Semantic Metric Comparison:** Implement semantic similarity evaluation (e.g., synonym mapping or semantic embeddings) alongside exact match to quantify how much performance is underestimated by strict metrics, particularly for slot filling.

3. **SFT Ablation Study:** Systematically vary SFT hyperparameters (learning rate, batch size, epochs) to establish whether reported performance gains are robust to training configuration or sensitive to specific hyperparameter choices.