---
ver: rpa2
title: 'Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via
  Steering Vectors'
arxiv_id: '2509.06608'
source_url: https://arxiv.org/abs/2509.06608
tags:
- steering
- vectors
- base
- layer
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a mechanistic study of steering vectors trained
  via reinforcement learning to improve mathematical reasoning in large language models.
  By isolating steering vectors at individual transformer layers, the authors show
  that these lightweight interventions can recover a substantial fraction of the performance
  gains from full fine-tuning.
---

# Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors

## Quick Facts
- **arXiv ID:** 2509.06608
- **Source URL:** https://arxiv.org/abs/2509.06608
- **Reference count:** 40
- **Primary result:** Single-layer steering vectors trained via RL can recover substantial fractions of full fine-tuning gains by implementing distinct mechanisms at different transformer layers

## Executive Summary
This paper investigates how reinforcement learning-trained steering vectors improve mathematical reasoning in large language models. By isolating these lightweight interventions at individual transformer layers, the authors reveal distinct mechanisms: last-layer vectors act as first-token substitution biases, penultimate-layer vectors operate primarily through the MLP submodule while bypassing attention, and earlier layers implement unique mechanisms that don't simply propagate downstream. The findings demonstrate that steering vectors can recover a substantial fraction of fine-tuning performance while providing mechanistic interpretability of how different transformer layers contribute to reasoning behavior.

## Method Summary
The authors train single-layer steering vectors via RL with Verifiable Rewards (RLVR) on the DeepScaleR dataset, adding zero-initialized vectors to the residual stream at specific transformer layers. Using RLOO advantage computation with per-prompt baselines, they train vectors independently at each layer (0-27 for Qwen2.5-Math-7B, 0-31 for Llama3.1-8B-It) with 128 prompts × 16 completions per gradient step. Evaluation occurs on six math benchmarks using sampling at τ=1.0, with analysis tools including logit lens, attention ablation, and projection patching to isolate mechanistic effects.

## Key Results
- Last-layer steering vectors act as first-token substitution biases, boosting tokens like "To" and "Step" at the unembedding layer
- Penultimate-layer vectors achieve gains primarily through MLP operations while largely bypassing attention patterns
- Steering vectors at different layers implement distinct mechanisms rather than propagating as virtual downstream directions
- Single-layer steering recovers 10-30% mean accuracy across six math benchmarks, a substantial fraction of full fine-tuning gains

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Last-layer steering vectors act as first-token substitution biases at the unembedding layer, boosting probability of specific opening tokens like "To" or "Step."
- **Mechanism:** The steering vector s_L is added directly to the final hidden state before unembedding, shifting logits for tokens aligned with s_L · W_unembed. Because softmax is sensitive to initial logits and the effect is position-independent, the boost concentrates on the first generated token where it has maximal influence on the subsequent generation trajectory.
- **Core assumption:** The last-layer vector's effect on downstream tokens is secondary to its first-token impact; the model's autoregressive dynamics amplify this initial nudge.
- **Evidence anchors:** [abstract] "the last-layer steering vector acts like a token-substitution bias concentrated on the first generated token, consistently boosting tokens such as 'To' and 'Step'"; [Section 5] "prefixing this token to each prompt reproduces a substantial fraction of the vector's accuracy gain... about 75% of the gain from s27"
- **Break condition:** If first-token prefixing did NOT recover substantial last-layer gains, or if probability shifts were distributed uniformly across positions, the first-token substitution hypothesis would be weakened.

### Mechanism 2
- **Claim:** Penultimate-layer steering vectors achieve most of their benefit through the MLP sublayer while largely bypassing attention.
- **Mechanism:** The steering vector s_{L-1} is added to the residual stream entering the final transformer block. In Qwen, injecting into the value projection of head 1 (V1) alone closes the performance gap. Since the attention-weighted contribution of s_{L-1}W^V_1 W^O_1 enters the residual regardless of attention weights (derived in Appendix I), this is equivalent to adding a fixed vector post-attention. The MLP then processes this enriched representation, preferentially upweighting process words and structural tokens.
- **Core assumption:** Attention patterns remain stable under steering; the vector does not meaningfully alter Q-K interactions.
- **Evidence anchors:** [abstract] "the penultimate-layer vector leaves attention patterns largely intact and instead operates through the MLP and unembedding"; [Section 6] "Skip-Attn preserves over half of the s26 gain, pointing to the MLP as the main contributor"
- **Break condition:** If attention ablation (Skip-Attn) eliminated most of the performance gain, or if single-head V-projection patching failed to recover performance, the MLP-bypass hypothesis would be rejected.

### Mechanism 3
- **Claim:** Steering vectors at different layers do NOT propagate as "virtual" later-layer directions; their induced shifts become nearly orthogonal to layer-specific steering vectors.
- **Mechanism:** A perturbation at layer i passes through intervening nonlinear transformations (LayerNorm, attention, MLP). While Diff-Diff CosSim shows shifts remain clustered around a common direction (never fully orthogonal), Diff-Vector CosSim drops rapidly—propagated shifts are nearly orthogonal to each layer's own trained steering direction. This suggests layers implement distinct learned mechanisms rather than approximating a unified downstream direction.
- **Core assumption:** Orthogonal directions correspond to meaningfully different mechanisms (tested via orthogonal vector training in Appendix F, which failed to match original performance).
- **Evidence anchors:** [Section 4] "Diff-Vector CosSim dropped rapidly with distance from the injection layer: the propagated shifts were nearly orthogonal to each layer's own steering vector"; [Section 4] "orthogonal steering vectors... neither orthogonal vector matched the performance of the original one"
- **Break condition:** If orthogonal vectors at the same layer achieved comparable performance (per Jacob & Turner 2024), or if Diff-Vector CosSim remained high across layers, the distinct-mechanisms-per-layer claim would be undermined.

## Foundational Learning

- **Residual Stream Architecture**
  - Why needed here: Steering vectors are injected into the residual stream; understanding how additive perturbations flow through subsequent layers is essential for interpreting their effects.
  - Quick check question: If you add vector v to the residual stream at layer 5, what components does it pass through before affecting the output logits?

- **RL with Verifiable Rewards (RLVR)**
  - Why needed here: The steering vectors are trained via policy gradient (RLOO) on mathematical reasoning tasks with verifiable rewards. This objective shapes what behaviors get amplified.
  - Quick check question: In RLVR, what is the role of the baseline b(x) in the advantage computation, and why does it matter for steering vector training?

- **Logit Lens Interpretation**
  - Why needed here: The paper uses logit lens (projecting hidden states through unembedding) to read out token-level preferences from steering vectors.
  - Quick check question: Why does logit lens work for the last-layer steering vector but provide limited signal for earlier layers?

## Architecture Onboarding

- **Component map:** Prompts → Sample completions → Math-Verify reward → RLOO advantage → Adam update on single steering vector s_ℓ → Base model forward pass → Add s_ℓ at layer ℓ output → Continue through remaining layers → Unembedding
- **Critical path:**
  1. Select target layer ℓ
  2. Initialize s_ℓ = 0
  3. Train with RLVR objective (128 prompts × 16 completions/step)
  4. Evaluate on 6 math benchmarks at τ=1.0
  5. Analyze via ablation and logit lens
- **Design tradeoffs:**
  - Single-layer vs. all-layer steering: Single-layer isolates mechanisms but achieves lower peak performance
  - Sampling vs. greedy decoding: τ=1.0 matches training distribution; greedy may overestimate single-layer potential
  - Injection point: Pre- vs. post-attention matters; LayerNorm can attenuate vectors (see layers 23-24 anomaly in Qwen)
- **Failure signatures:**
  - Layers 23-24 in Qwen underperform neighbors due to input LayerNorm attenuation (Appendix C)
  - Last-layer steering in Llama shows weaker effects (max cosine similarity 0.12 vs. 0.37 in Qwen)
  - Transferred vectors sometimes degrade performance (negative normalized gain for Qwen2.5-7B-Instruct→Math)
- **First 3 experiments:**
  1. **Replicate single-layer steering curve:** Train s_ℓ at one layer on DeepScaleR subset (100 prompts) and verify performance vs. layer position matches Figure 1 pattern.
  2. **First-token prefixing test:** Take base model, prefix "To" (Qwen) or "Step" (Llama) to all prompts, measure accuracy delta. Compare to last-layer steering gain.
  3. **Attention ablation on penultimate layer:** Implement Skip-Attn for s_{L-1} by adding steering vector post-attention residual. Verify performance retains >50% of full s_{L-1} gain.

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the precise mechanistic roles of mid-layer steering vectors, and why are their effects harder to localize to a single submodule compared to late-layer vectors?
- **Open Question 2:** How does the cooperative multi-head mechanism in Llama's penultimate attention layer function to implement reasoning, given that no single head accounts for the performance gain?
- **Open Question 3:** Why are the effects of steering vectors consistently stronger and cleaner in Qwen models compared to Llama models?

## Limitations

- Single-layer steering vectors achieve substantially lower performance gains than full all-layer fine-tuning
- Analysis focuses primarily on Qwen2.5-Math-7B with limited Llama3.1-8B-It comparisons
- Interpretation relies heavily on logit lens and ablation studies that may not capture all pathway interactions

## Confidence

**High Confidence:**
- Last-layer steering vectors act as first-token substitution biases
- Penultimate-layer vectors operate primarily through MLP sublayer
- Steering vectors at different layers implement distinct mechanisms

**Medium Confidence:**
- Attention patterns remain stable under penultimate-layer steering
- The specific token preferences ("To" for Qwen, "Step" for Llama) are causally linked to performance gains

**Low Confidence:**
- Generalization of layer-specific mechanisms across different model architectures
- Completeness of mechanistic understanding

## Next Checks

1. **Cross-architecture validation:** Train and analyze single-layer steering vectors on an additional transformer family (e.g., Mistral or Gemma) to test whether last-layer first-token biasing and penultimate-layer MLP operation generalize beyond Qwen and Llama architectures.

2. **Multi-layer steering ablation:** Systematically ablate individual layers in trained all-layer steering vectors (not just single-layer) to determine whether the same distinct mechanisms operate when steering is distributed across layers, or whether layer interactions create new effects.

3. **Attention stability measurement:** Directly measure attention pattern changes (e.g., KL divergence between base and steered attention distributions) in the penultimate layer under steering, rather than inferring stability from performance ablation alone.