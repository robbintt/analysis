---
ver: rpa2
title: 'When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism
  Detection'
arxiv_id: '2512.23732'
source_url: https://arxiv.org/abs/2512.23732
tags:
- task
- sexism
- expert
- reasoning
- sexist
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of detecting subtle and context-dependent
  sexism online, which is complicated by noisy, imbalanced datasets and mixed human
  annotations. To improve detection reliability, the authors propose a two-stage framework
  that combines targeted training with selective reasoning.
---

# When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection

## Quick Facts
- arXiv ID: 2512.23732
- Source URL: https://arxiv.org/abs/2512.23732
- Reference count: 40
- Key outcome: Achieved state-of-the-art performance on sexism detection datasets with +2.72% F1 on EXIST Task 1.1 and +4.48%/+1.30% on EDOS Tasks A/B

## Executive Summary
This paper addresses the challenge of detecting subtle and context-dependent sexism online, complicated by noisy, imbalanced datasets and mixed human annotations. The authors propose a two-stage framework that combines targeted training with selective reasoning. The training stage employs class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to stabilize learning under severe class imbalance. At inference, a confidence-aware routing mechanism filters high-confidence predictions while escalating uncertain cases to a Collaborative Expert Judgment (CEJ) module that simulates multi-perspective deliberation among expert personas. Experimental results show this approach achieves state-of-the-art performance on both the EXIST 2025 and EDOS datasets, with improvements especially pronounced for underrepresented or ambiguous cases.

## Method Summary
The approach uses a two-stage framework: first, a specialist model (LLaMA-3.2-3B) is fine-tuned with class-balanced focal loss (β=0.999, γ=2.0) and class-aware batching to handle severe class imbalance. Post-hoc temperature scaling calibrates confidence scores, followed by threshold tuning on development data. Second, a confidence-aware routing mechanism filters high-confidence predictions and escalates uncertain cases to a CEJ module. The CEJ module prompts multiple expert personas (e.g., linguist, psychologist, legal expert) to debate ambiguous cases, with a judge model synthesizing the final decision. The system achieves state-of-the-art results on both binary and multi-class sexism detection tasks.

## Key Results
- Achieved +2.72% F1 improvement on EXIST Task 1.1 compared to baselines
- Improved EDOS Task A by +4.48% and Task B by +1.30% in macro-F1
- CEJ module particularly effective for underrepresented or ambiguous cases
- Gains are most pronounced in binary classification and coarse multi-class settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Targeted training regularization stabilizes decision boundaries for minority classes better than standard fine-tuning
- **Mechanism:** Class-balanced focal loss down-weights easy majority examples while class-aware batching ensures uniform exposure to underrepresented classes
- **Core assumption:** Explicit statistical intervention is needed to learn minority patterns because standard cross-entropy prioritizes overall accuracy over class balance
- **Evidence anchors:** Abstract states integration of strategies to mitigate label imbalance; Section 3.1 describes class-aware batching decoupling batch composition from natural distribution
- **Break condition:** Extremely small datasets may not provide enough signal for minority classes even with regularization

### Mechanism 2
- **Claim:** Confidence-aware routing filters high-certainty predictions, reserving expensive reasoning for ambiguous cases
- **Mechanism:** Uses margin m(x) = p^(1)(x) - p^(2)(x) between top predicted classes to determine routing
- **Core assumption:** Model's softmax probability serves as reliable proxy for epistemic uncertainty, with errors primarily in low-confidence regions
- **Evidence anchors:** Abstract describes dynamic routing mechanism; Section 3.2 explains margin-based filtering for multi-class settings
- **Break condition:** Poorly calibrated base model may misroute errors directly to users instead of CEJ module

### Mechanism 3
- **Claim:** Multi-persona deliberation activates latent reasoning capabilities in LLMs, resolving subtle context single-prompt classification misses
- **Mechanism:** Forces model to adopt distinct personas and engage in structured debate before judge synthesis
- **Core assumption:** Instruction-tuned LLMs possess relevant domain knowledge that remains latent during standard classification but can be elicited through role-based context
- **Evidence anchors:** Abstract mentions prompting multiple personas and consolidating reasoning; Section 3.3 describes approximating expert structure to activate reasoning
- **Break condition:** Tasks requiring strict adherence to specific annotation guidelines may suffer from variance introduced by creative deliberation

## Foundational Learning

- **Concept: Class-Aware Batch Sampling**
  - **Why needed here:** Sexism datasets are severely imbalanced with many "not sexist" and few "sexist" examples
  - **Quick check question:** How does decoupling batch composition from the dataset's natural distribution specifically prevent the gradient from being dominated by the majority class?

- **Concept: Probability Calibration (Temperature Scaling)**
  - **Why needed here:** Routing mechanism relies on confidence scores, but raw softmax outputs are often overconfident
  - **Quick check question:** Why is a model's raw softmax output often a poor estimate of true correctness probability, and how does scaling the logits (z(x)/T) fix this?

- **Concept: Chain-of-Thought via Role-Play**
  - **Why needed here:** Subtle sexism is contextual and zero-shot classification often fails to weigh different interpretations
  - **Quick check question:** Why might prompting a model as a "Legal Expert" yield different results than prompting it as a "Psychologist" for the same text, and why is synthesizing these views beneficial?

## Architecture Onboarding

- **Component map:** Specialist Model -> Router -> CEJ Module (Personas -> Debate -> Summarizer -> Judge)
- **Critical path:** Threshold tuning on development set - improper τ_conf or τ_margin settings can cause either too many expensive CEJ calls or errors slipping through
- **Design tradeoffs:** Efficiency vs. granularity (CEJ is computationally expensive but boosts performance on binary/coarse multi-class while degrading on fine-grained tasks); Variance vs. consistency (debate introduces stochasticity that may hurt strict annotation boundaries)
- **Failure signatures:** Performance collapse on fine-grained tasks (Task C) suggests CEJ over-generalizes compared to strict definitions; Routing loop occurs if judge model returns low confidence without fallback
- **First 3 experiments:**
  1. **Calibration Check:** Train specialist model with and without CB-Focal loss, plot confidence histograms to verify routed population corresponds to ambiguous/incorrect predictions
  2. **Router Sensitivity:** Sweep τ_conf and τ_margin to plot "Percentage Routed" vs "F1 Score" curve, identify inflection point of diminishing returns
  3. **Persona Ablation:** Run CEJ on fixed ambiguous examples, removing one persona at a time to identify which perspectives drive F1 gains

## Open Questions the Paper Calls Out

- **Open Question 1:** Can combining CEJ module with data-level augmentation methods (e.g., DDA) improve performance on fine-grained classification tasks with severe class imbalance?
- **Open Question 2:** Why does CEJ degrade performance for categories requiring subtle annotation-specific distinctions (e.g., EDOS categories 4.1 and 4.2), and can persona design mitigate this?
- **Open Question 3:** How does CEJ computational overhead scale with the number of personas, and is there a performance-optimal subset of personas?
- **Open Question 4:** Does the confidence-aware routing threshold generalize across datasets with different annotation disagreement distributions?

## Limitations
- CEJ module introduces computational overhead and potential variance in fine-grained classification
- Thresholds (τ_conf, τ_margin) and temperature scaling parameter T are tuned but not reported, limiting reproducibility
- Approach shows degraded performance on highly specific sub-categories (Task C), particularly categories 4.1 and 4.2

## Confidence

- **High Confidence:** Effectiveness of class-balanced focal loss and class-aware batching for minority class stabilization
- **Medium Confidence:** Reliability of confidence-aware routing mechanism as proxy for epistemic uncertainty
- **Medium Confidence:** CEJ module's ability to resolve contextual ambiguity through multi-perspective deliberation

## Next Checks
1. **Calibration Verification:** Train specialist model with and without class-balanced focal loss, then plot confidence histograms on dev set to confirm routed instances correspond to ambiguous/incorrect predictions
2. **Threshold Sensitivity Analysis:** Systematically sweep τ_conf and τ_margin to identify inflection point where additional routing yields diminishing returns in macro-F1
3. **Persona Impact Assessment:** Conduct ablation study removing individual personas from CEJ module to quantify their specific contributions to observed F1 improvements