---
ver: rpa2
title: 'The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process'
arxiv_id: '2509.03528'
source_url: https://arxiv.org/abs/2509.03528
tags:
- prolific
- process
- italian
- lawmaking
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ProLiFIC, a comprehensive event log dataset
  capturing the Italian lawmaking process from 1987 to 2022. The dataset transforms
  unstructured textual records from the Normattiva portal into structured event logs
  using LLMs, addressing the challenge of limited accessible data for process mining
  in legal domains.
---

# The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process

## Quick Facts
- **arXiv ID:** 2509.03528
- **Source URL:** https://arxiv.org/abs/2509.03528
- **Authors:** Matilde Contestabile; Chiara Ferrara; Alberto Giovannetti; Giovanni Parrillo; Andrea Vandin
- **Reference count:** 9
- **Primary result:** ProLiFIC dataset provides structured event logs for 4,395 Italian laws (1987-2022) extracted from unstructured Normattiva text using LLMs

## Executive Summary
This paper introduces ProLiFIC, a comprehensive event log dataset capturing the Italian lawmaking process from 1987 to 2022. The dataset transforms unstructured textual records from the Normattiva portal into structured event logs using LLMs, addressing the challenge of limited accessible data for process mining in legal domains. ProLiFIC includes metadata and event sequences for 4,395 laws, enabling detailed process-oriented analyses. Preliminary findings reveal significant procedural changes over time, such as reduced use of the "sede deliberante" mechanism and variations in legislative durations across legislatures. The dataset is publicly available under a CC BY-NC 4.0 license, supporting empirical research and transparency in legislative workflows.

## Method Summary
ProLiFIC was created by extracting unstructured *lavori preparatori* (preparatory works) documents from the Normattiva portal and processing them through an automated pipeline powered by Large Language Models. The LLM pipeline identifies legislative activities (Presentation, Assignment, Committee examination, etc.) and extracts structured metadata (chamber, committee, person, timestamp) from each text chunk. Each event is paired with its original text for validation and explainability. The dataset underwent cleaning to correct approximately 156 factual problems, and 77 laws were excluded due to unresolvable ambiguities. The final dataset consists of metadata and event sequences for 4,395 laws spanning 35 years of Italian legislative history.

## Key Results
- LLMs successfully transformed unstructured Italian legal text into structured event logs with sufficient fidelity for process mining
- Comparative analysis revealed significant procedural changes: *sede deliberante* usage declined from 53% to 16% across different legislatures
- Median legislative duration increased from 133 to 202 days in the more recent legislatures
- Process maps generated from the dataset clearly visualize these structural changes in legislative workflow

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs can transform unstructured Italian legal text into structured event logs with sufficient fidelity for process mining.
- **Mechanism:** The pipeline extracts *lavori preparatori* from Normattiva, then uses LLMs' natural language understanding to identify and classify legislative activities along with metadata. Each event is paired with the original text chunk for validation and explainability.
- **Core assumption:** The LLM can reliably distinguish between activity types and extract structured attributes from domain-specific Italian legal language without extensive labeled training data.
- **Evidence anchors:**
  - [abstract] "Created from unstructured data from the Normattiva portal and structured using large language models (LLMs)"
  - [section 1] "dataset has been meticulously created using an automated pipeline powered by Large Language Models (LLMs)"
  - [corpus] Related work shows similar LLM/NLP pipelines for legal text structuring, suggesting feasibility but not direct validation of this specific approach.
- **Break condition:** If LLM extraction error rates exceed acceptable thresholds for process mining, discovered process models would be unreliable. The paper notes 77 laws were excluded due to "unresolvable ambiguities," suggesting edge cases exist.

### Mechanism 2
- **Claim:** Structured event logs enable comparative temporal analysis of legislative procedure evolution across decades.
- **Mechanism:** By standardizing events with timestamps and activity types across 4,395 laws spanning 35 years, ProLiFIC allows process mining tools to generate process maps that reveal procedural pathway frequencies and durations. Comparing maps from different legislatures exposes structural changes.
- **Core assumption:** The mapping from heterogeneous source documents to standardized event types preserves enough semantic consistency for cross-temporal comparison.
- **Evidence anchors:**
  - [section 3] "This change is clearly visible in the process maps: the mentioned path is present in Figure 1 (a), while it is absent in Figure 1 (b)"
  - [section 3] "sede deliberante... accounted for 53% of approved laws in the earlier legislatures... dropped to just 16% in the later legislatures"
  - [corpus] Mining Legal Arguments paper demonstrates similar automated detection of judicial reasoning patterns at scale, supporting plausibility of comparative process analysis.
- **Break condition:** If event type definitions or recording practices changed substantively over 1987-2022 within Normattiva itself, observed procedural shifts could conflate documentation changes with actual procedural changes.

### Mechanism 3
- **Claim:** Concurrent event resolution via timestamp micro-adjustments preserves event ordering for process discovery.
- **Mechanism:** Events sharing the same calendar-day timestamp are incrementally adjusted by one-minute offsets to maintain sequential ordering in the event log, ensuring process mining algorithms can trace valid pathways.
- **Core assumption:** Day-level granularity in source data reflects true event ordering when adjusted; the micro-adjustment heuristic does not systematically distort process structure.
- **Evidence anchors:**
  - [section 3, Figure 1 caption] "For each case_id, we identified contemporary events, and incrementally adjusted their timestamps by one minute to preserve their order in the event log"
  - [corpus] No direct corpus evidence on timestamp adjustment heuristics in legal process mining; this appears to be an implementation choice specific to this dataset.
- **Break condition:** If original timestamp ambiguities are frequent and ordering assumptions are incorrect, derived process models may contain spurious or missing edges.

## Foundational Learning

- **Concept:** Process Mining (PM) fundamentals — event logs, case IDs, activities, timestamps, process discovery
  - **Why needed here:** ProLiFIC is explicitly designed as a PM dataset; understanding PM primitives (traces, variants, process maps) is required to use it effectively.
  - **Quick check question:** Can you explain what a "trace" is in process mining and how it differs from an "event"?

- **Concept:** Italian legislative procedure basics (bicameralism, navetta, sede deliberante)
  - **Why needed here:** The dataset captures domain-specific workflows; interpreting process maps requires knowing why laws shuttle between chambers or what committee deliberating powers mean.
  - **Quick check question:** What is the *navetta* (shuttle) mechanism and why does it create loops in the legislative event sequence?

- **Concept:** LLM-based information extraction evaluation
  - **Why needed here:** The dataset is LLM-generated; users should understand validation approaches (human-in-the-loop, spot-checking chunks, error analysis) to assess reliability.
  - **Quick check question:** How would you design a sampling strategy to estimate the error rate of LLM-extracted activity types?

## Architecture Onboarding

- **Component map:** Normattiva portal (unstructured documents) -> LLM extraction pipeline -> Data cleaning (correction of 156 problems) -> Output: Metadata table + Event log table + Original text chunks -> Analysis tools (Fluxicon Disco) -> Distribution (Zenodo, GitHub)
- **Critical path:** Load event log → filter by legislature/law type → (optional) resolve concurrent timestamps → feed to process mining tool → interpret discovered process maps against domain knowledge.
- **Design tradeoffs:**
  - Day-level timestamp granularity vs. finer-grained temporal analysis
  - Inclusion of original text chunks for explainability vs. dataset size/complexity
  - CC BY-NC license enables research use but restricts commercial applications
  - Focus on procedural events excludes richer political metadata present in ILMA dataset
- **Failure signatures:**
  - High rate of "unclassifiable" events suggests LLM extraction gaps
  - Process maps with missing expected activities may indicate filtering issues or real procedural shifts — requires domain expertise to distinguish
  - Median duration anomalies (e.g., very short paths for complex laws) may indicate incomplete event capture
- **First 3 experiments:**
  1. **Reproduce Figure 1:** Load event log for legislatures X–XI and XVII–XVIII separately; generate process maps in Disco; verify sede deliberante frequency decline (53% → 16%).
  2. **Duration distribution analysis:** Compute and plot legislative duration distributions for ordinary laws vs. decree conversions across all legislatures; test for statistically significant shifts.
  3. **Validation sampling:** Randomly sample 50 events; manually verify activity classification accuracy by cross-referencing original text chunks; estimate error bounds.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the specific causal drivers and broader impacts of the observed decline in the *sede deliberante* mechanism on legislative efficiency?
- **Basis in paper:** [explicit] The authors state, "A deeper analysis of the reasons and impacts behind this change is beyond the scope of this paper," referring to the drop in *sede deliberante* usage from 53% to 16%.
- **Why unresolved:** The paper identifies the trend and its correlation with increased median durations but does not investigate the political or procedural causes.
- **What evidence would resolve it:** A regression analysis incorporating political variables (e.g., government stability, party coalitions) alongside the process metrics provided in ProLiFIC.

### Open Question 2
- **Question:** Which specific procedural steps act as the primary bottlenecks in the modern Italian lawmaking process?
- **Basis in paper:** [explicit] The introduction lists "the identification of procedural bottlenecks by pinpointing inefficiencies in legislative workflows" as a key application facilitated by ProLiFIC.
- **Why unresolved:** The paper provides aggregate median durations and process maps but does not isolate specific steps responsible for delays in the recent, slower legislatures.
- **What evidence would resolve it:** A fine-grained temporal analysis of waiting times between consecutive events (e.g., Assignment to Committee examination) across different legislatures.

### Open Question 3
- **Question:** What is the accuracy and reliability of LLM-based extraction pipelines when applied to complex, unstructured legal texts like the *lavori preparatori*?
- **Basis in paper:** [inferred] The dataset relies on an "automated pipeline powered by Large Language Models" to structure text, and while chunks are provided for "explainability," the paper does not quantify the extraction error rate.
- **Why unresolved:** The paper asserts the dataset is "high quality" but excludes 77 laws due to "unresolvable ambiguities" without defining the precision of the automated extraction for the included 4,395 laws.
- **What evidence would resolve it:** A validation study comparing a sample of the LLM-generated event logs against a manually curated "gold standard" ground truth.

## Limitations
- LLM extraction accuracy for domain-specific Italian legal terminology remains unverified; the paper does not report precision/recall metrics for activity classification
- The 77 excluded laws due to "unresolvable ambiguities" suggest systematic extraction challenges, but their characteristics and potential bias are not analyzed
- Concurrent event resolution via timestamp micro-adjustments is a heuristic that may distort true process structure if ordering assumptions are incorrect

## Confidence
- **High confidence:** Dataset completeness and documentation quality (4,395 laws with full metadata and linked text chunks)
- **Medium confidence:** Overall feasibility of LLM-based legal event extraction based on related work, but **Low confidence** in specific accuracy rates without reported validation
- **Medium confidence:** Procedural insights from process maps, but **Low confidence** that all observed changes reflect actual legislative evolution rather than documentation changes

## Next Checks
1. Sample 100 random events and manually verify LLM-assigned activity types against original text chunks to estimate classification accuracy
2. Cross-validate event sequence ordering by comparing LLM-extracted timelines against a small sample of manually processed laws from different decades
3. Analyze the 77 excluded laws to determine if they represent specific legislative types, chambers, or time periods that could bias overall dataset representativeness