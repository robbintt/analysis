---
ver: rpa2
title: 'Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration
  of Scaling Laws by Difficulty'
arxiv_id: '2508.19069'
source_url: https://arxiv.org/abs/2508.19069
tags:
- reasoning
- chain
- arxiv
- data
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies a scaling law by difficulty in LLM reasoning:
  excessive low-difficulty training data impairs abstraction, while high-difficulty
  data enhances it. To address this, it proposes the Structured Solution Template
  (SST) framework, which explicitly teaches procedural reasoning through three stages:
  fine-tuning with structured solution-template chains and weighted loss, prompt-time
  injection of solution templates as cognitive scaffolds, and integrated curriculum
  fine-tuning with self-reflection.'
---

# Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration of Scaling Laws by Difficulty

## Quick Facts
- **arXiv ID:** 2508.19069
- **Source URL:** https://arxiv.org/abs/2508.19069
- **Reference count:** 5
- **Primary result:** Structured Solution Templates (SST) improve LLM reasoning accuracy on hard math problems by enforcing procedural abstraction and efficient planning.

## Executive Summary
This paper investigates how training data difficulty affects LLM reasoning abstraction and proposes the Structured Solution Template (SST) framework to address scaling law limitations. The authors identify a U-shaped scaling law where excessive low-difficulty data impairs abstraction, while high-difficulty data enhances it. SST introduces weighted procedural supervision, prompt-time cognitive scaffolding, and curriculum fine-tuning to explicitly teach reasoning procedures. Experiments show SST significantly improves accuracy on GSM8K (+6.2 points) and AIME24 (+2.2 points) while increasing reasoning efficiency.

## Method Summary
The SST framework employs three stages: (1) Supervised fine-tuning with weighted loss on procedural tokens extracted from solution templates, (2) Training a lightweight chain generator via LoRA to inject solution templates as cognitive scaffolds during inference, and (3) Integrated curriculum fine-tuning using Group Relative Policy Optimization on hard problems. The method addresses the scaling law by difficulty by enforcing procedural abstraction through structured supervision and externalized planning, with a small generator model offloading planning from the main solver.

## Key Results
- SST improves GSM8K accuracy by up to 6.2 points compared to standard fine-tuning
- AIME24 accuracy increases by 2.2 points with SST framework
- Token efficiency improves significantly (-62.4% on GSM8K) through prompt-time chain injection
- Weighted procedural supervision recovers and improves performance lost by adding `<chain>` tokens without weighting

## Why This Works (Mechanism)

### Mechanism 1: Difficulty-Induced Abstraction
High-difficulty training data enforces procedural abstraction, while excessive low-difficulty synthetic data encourages brittle surface-pattern matching. When models train on simple variations, the loss landscape favors memorizing shallow heuristics over learning generalizable procedures. High-difficulty problems constrain solutions to require multi-step logic, forcing algorithmic abstraction to minimize loss.

### Mechanism 2: Weighted Procedural Supervision
Amplifying loss on explicit procedural tokens (`<chain>...</chain>`) shifts model focus from surface fluency to logical structure. Standard SFT treats all tokens equally, but weighting chain tokens prioritizes learning the "how" (reasoning steps) over the "what" (contextual filler). The linear decay schedule prevents overfitting to template structure exclusively.

### Mechanism 3: Externalized Cognitive Scaffolding
Decoupling planning from execution via a lightweight generator improves reasoning efficiency and accuracy on complex tasks. A small LoRA-adapted model generates high-level plans (chains) prepended to the solver's context, offloading "what to do" planning from the solver. This allows the solver to focus on "how to do it," acting as a context-based guide on hard tasks and a compression mechanism on easy tasks.

## Foundational Learning

- **Concept: Scaling Laws & Data Mixing**
  - **Why needed here:** The paper challenges standard "more data is better" scaling laws by introducing "Scaling Law by Difficulty," essential for understanding curriculum design.
  - **Quick check question:** Does adding 10k easy examples to a dataset of 1k hard examples typically improve or degrade performance on a held-out test of hard problems? (Answer: Degrade)

- **Concept: Token-Level Loss Weighting**
  - **Why needed here:** SST framework modifies standard Cross-Entropy loss, requiring understanding that not all tokens contribute equally to the gradient.
  - **Quick check question:** In SST loss function, if weight $w(t)$ is set to 2.0 for chain tokens, how does the gradient for those tokens compare to standard tokens? (Answer: Twice as large)

- **Concept: Model Steering (In-Context Scaffolding)**
  - **Why needed here:** Stage 2 uses inference-time prompting to steer the main model without changing its weights.
  - **Quick check question:** How does the "Chain Generator" in Stage 2 affect the weights of the main "Solver" model during inference? (Answer: It does not; steering is purely via context injection)

## Architecture Onboarding

- **Component map:** Data Curation Pipeline -> Chain Generator -> Solver Model -> Curriculum Builder
- **Critical path:**
  1. Stage 1 (SFT): Train Solver on weighted `<chain>` data
  2. Stage 2 (Generator): Train LoRA Generator on extracted chains
  3. Stage 3 (GRPO): Rejection sample hard problems → Generate Chains → Synthesize solutions → Run Group Relative Policy Optimization

- **Design tradeoffs:**
  - Efficiency vs. Accuracy: Stage 2 injection reduces GSM8K accuracy (73.79 vs 78.62) in exchange for massive token savings (-62.4%)
  - Generator Size: Using 1.5B planner for 1.5B solver assumes planning task is simpler than execution

- **Failure signatures:**
  - Template Stiffness: If weighted loss is too high or decay is too slow, model may output rigid, unhelpful chains for novel problems
  - Distribution Mismatch: If Chain Generator trained on different domain than test domain, scaffolding will fail

- **First 3 experiments:**
  1. Replicate Scaling Law: Fine-tune baseline on increasing amounts of template-generated easy data to verify performance drop
  2. Weight Ablation: Train Stage 1 with $w_{initial}$ = 1.0, 2.0, and 4.0 to find optimal weighting for abstraction
  3. Inference Efficiency: Run Stage 2 inference on GSM8K with and without Chain Generator to measure token-reduction vs accuracy trade-off

## Open Questions the Paper Calls Out
- The current framework is primarily evaluated on mathematics, and its generalization to other complex reasoning tasks warrants further exploration.
- The identified "Scaling Law by Difficulty" may be specific to template-based synthetic data generation rather than a universal learning constraint.

## Limitations
- Data difficulty calibration lacks objective validation criteria for labeling problems as "easy" vs "hard"
- Architecture dependency: All experiments use 1.5B models, limiting generalization to other model sizes
- Generalization scope remains unproven beyond mathematical and cross-domain reasoning tasks

## Confidence
- **High Confidence:** Core empirical findings (SST improving accuracy on GSM8K/AIME24, token efficiency gains)
- **Medium Confidence:** Theoretical mechanism of "difficulty-induced abstraction" relies on indirect evidence
- **Medium Confidence:** Three-stage curriculum design necessity not rigorously proven through ablation studies

## Next Checks
1. Recreate the U-shaped scaling law by systematically varying easy vs hard data proportions with validated difficulty labels
2. Apply SST to 7B or 13B model using same 1.5B generator to test efficiency gains persistence
3. Use chain-of-thought attribution or activation patching to verify injected chains are actually used as reasoning scaffolds on hard AIME problems