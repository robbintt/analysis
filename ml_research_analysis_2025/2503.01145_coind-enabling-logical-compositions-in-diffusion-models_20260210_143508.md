---
ver: rpa2
title: 'CoInD: Enabling Logical Compositions in Diffusion Models'
arxiv_id: '2503.01145'
source_url: https://arxiv.org/abs/2503.01145
tags:
- attributes
- attribute
- logical
- conditional
- oind
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of enabling diffusion models to
  generate data with arbitrary logical compositions of statistically independent attributes,
  even when only a subset of compositions is observed during training. The authors
  show that standard conditional diffusion models fail at this task due to violations
  of conditional independence assumptions, particularly under non-uniform or partial
  support.
---

# CoInD: Enabling Logical Compositions in Diffusion Models

## Quick Facts
- **arXiv ID**: 2503.01145
- **Source URL**: https://arxiv.org/abs/2503.01145
- **Reference count**: 40
- **Primary result**: COIND achieves 52.38% conformity score on unseen compositions versus 7.40% for baselines on Colored MNIST with diagonal partial support

## Executive Summary
This paper addresses the challenge of generating data with arbitrary logical compositions of statistically independent attributes when only partial support is observed during training. Standard conditional diffusion models fail at this task because they learn spurious correlations from training data rather than the true causal independence structure. The authors propose COIND, which explicitly enforces conditional independence between attribute marginals by minimizing Fisher's divergence between joint and marginal distributions. Experiments on synthetic and real datasets demonstrate that COIND significantly outperforms baselines in generating accurate and diverse samples for complex logical compositions, including those involving the NOT operation.

## Method Summary
COIND extends classifier-free diffusion models by adding an independence loss term L_CI that enforces conditional independence between attribute marginals. During training, for each batch, two random attributes are selected and the model computes scores for four conditions: individual attributes, their combination, and the empty condition. The L_CI term minimizes the squared difference between the sum of individual scores and the joint score, effectively enforcing p(Ci,Cj|X) = p(Ci|X)p(Cj|X). This pairwise approximation scales linearly with the number of attributes while maintaining theoretical guarantees under certain conditions. At inference, logical compositions (AND, OR, NOT) are computed via algebraic combinations of attribute scores, enabled by the enforced independence.

## Key Results
- On Colored MNIST with diagonal partial support, COIND achieves 52.38% conformity score versus 7.40% for baselines on unseen compositions
- For logical compositions involving AND and NOT operations on Shapes3D and CelebA, COIND consistently outperforms baselines by 20-40 percentage points in conformity score
- COIND provides fine-grained control over attribute intensity through score modulation without affecting independent attributes, demonstrated on CelebA smile intensity control
- The method scales linearly with the number of attributes while maintaining compositional accuracy across all tested datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Enforcing conditional independence between attribute marginals during training enables correct logical composition at inference by ensuring the model learns true factorized distributions rather than spurious training correlations.
- Mechanism: The L_CI term directly minimizes Fisher's divergence between the joint distribution pθ(X|C) and the product of conditionally independent marginals. Mathematically, L_CI = ||sθ(X,Cj,Ck) - sθ(X,Cj) - sθ(X,Ck) + sθ(X,∅)||². When L_CI → 0, the model satisfies pθ(C|X) = ∏pθ(Ci|X), enabling the score decomposition formulas for AND, OR, and NOT operations to produce correct compositions.
- Core assumption: Attributes C₁, C₂, ..., Cₙ are causally independent in the true data-generating process (the causal graph has no edges between attribute nodes, only from attributes to X).
- Evidence anchors:
  - [abstract]: "explicitly enforces statistical independence between the conditional marginal distributions by minimizing Fisher's divergence between the joint and marginal distributions"
  - [section 4, Eq. 9]: "LCI is the Fisher divergence between the joint and the product of marginals... LCI = 0 iff pθ(X|C) = [causal factorization]"
  - [corpus]: No direct corpus support for this mechanism; related work on compositional generation (Compositional World Knowledge, Diffusion Models with Double Guidance) doesn't use independence enforcement
- Break condition: When the true underlying causal graph has dependencies between attributes, enforcing conditional independence will produce incorrect marginals that don't match the data distribution.

### Mechanism 2
- Claim: Pairwise conditional independence approximation maintains compositional capability while reducing computational complexity from O(n) to O(1) per batch.
- Mechanism: Instead of enforcing mutual independence across all n attributes (requiring n forward passes per sample), CoInD randomly selects two attributes (i, j) per batch and enforces pθ(Ci,Cj|X) = pθ(Ci|X)pθ(Cj|X). The Hammond & Sun (2006) result suggests this pairwise enforcement is equivalent to full mutual independence under broad conditions.
- Core assumption: Pairwise conditional independence implies mutual conditional independence (Hammond & Sun, 2006).
- Evidence anchors:
  - [section 4]: "we approximate the mutual conditional independence with pairwise conditional independence (Hammond & Sun, 2006)"
  - [Appendix C.2, Tables 3-4]: Shows theoretical loss (Eq. 10) and practical loss (Eq. 11) achieve similar results, validating the approximation
  - [corpus]: No corpus papers address this specific approximation technique
- Break condition: If Hammond & Sun equivalence conditions don't hold for the data distribution, pairwise approximation may not guarantee full independence, leading to residual compositional failures.

### Mechanism 3
- Claim: Once conditionally independent marginals are learned, arbitrary logical compositions can be computed via score decomposition without retraining or architecture changes.
- Mechanism: Logical operations map to algebraic combinations of scores:
  - AND (∧): ∇log p(X|C₁∧C₂) = ∇log p(X|C₁) + ∇log p(X|C₂) - ∇log p(X)
  - NOT (¬): ∇log p(X|C₁∧¬C₂) = ∇log p(X) + ∇log p(X|C₁) - ∇log p(X|C₂)
  - Control intensity γ: Modulates attribute strength without affecting independent attributes
- Core assumption: The decomposition formulas are valid only when p(C|X) = ∏p(Ci|X), which L_CI enforces.
- Evidence anchors:
  - [section 2, Eqs. 1-3]: Full derivation of score decomposition for AND, NOT, and intensity control
  - [Figure 4b]: Strong negative correlation (r² implied) between JSD and conformity score confirms that lower independence violation = better composition
  - [Figure 7]: Shows γ control over smile intensity without affecting gender attributes (unlike baselines which leak correlated features)
  - [corpus: Diffusion Models with Double Guidance]: Addresses dataset aggregation but relies on guidance scaling rather than independence enforcement
- Break condition: If independence is imperfectly enforced (JSD > 0), score decomposition will blend attributes incorrectly—for example, "smiling" + "male" may produce female-associated features due to training correlations.

## Foundational Learning

- Concept: **Classifier-Free Guidance (CFG)**
  - Why needed here: CoInD is implemented entirely within the CFG framework. L_CI requires computing scores for four conditions (ci, cj, ci,j, c∅) from the same network, which CFG enables through conditional dropout during training. Without CFG fluency, the implementation won't make sense.
  - Quick check question: Why does CFG jointly train p(X|C) and p(X) in one network, and how does the conditional dropout probability puncond affect both distributions?

- Concept: **Fisher Divergence and Score Matching**
  - Why needed here: The theoretical justification rests on Fisher divergence properties: D_Fisher(p,q) = E_p[||∇log p - ∇log q||²]. Understanding that score-matching objectives upper-bound Wasserstein distance (Kwon et al., 2022, cited in paper) explains why minimizing L_CI enforces independence.
  - Quick check question: What does it mean for Fisher divergence to be zero, and why does this imply the two distributions are identical?

- Concept: **Causal Graphs and Conditional Independence**
  - Why needed here: The paper attributes standard model failure to "unobserved confounding" during training (Figure 2b). When selection bias creates p(Ci,Cj) ≠ p(Ci)p(Cj), standard likelihood training learns incorrect marginals p_train(X|Ci) ≠ p_true(X|Ci). Understanding d-separation clarifies why enforcing independence during training recovers the true causal structure.
  - Quick check question: In Figure 2, why does the training-time confounder make C₁ and C₂ conditionally dependent given X, and how does L_CI break this spurious dependence?

## Architecture Onboarding

- Component map:
  ```
  CoInD Training Pipeline
  ├── Data Loader: Returns (x₀, c) where c = [c₁, c₂, ..., cₙ]
  ├── CFG Masking: For each cᵢ, set to ∅ with probability puncond (default 0.2)
  ├── Noise Forward: xₜ = √ᾱₜ·x₀ + √(1-ᾱₜ)·ε
  ├── L_score: ||ε - εθ(xₜ, t, c)||²
  ├── L_CI computation:
  │   ├── Sample random pair (i, j) from attribute indices
  │   ├── Construct 4 condition vectors:
  │   │   ├── c_i: only cᵢ retained, others = ∅
  │   │   ├── c_j: only cⱼ retained, others = ∅  
  │   │   ├── c_i,j: only cᵢ, cⱼ retained, others = ∅
  │   │   └── c_∅: all = ∅
  │   └── L_CI = ||εθ(c_i) + εθ(c_j) - εθ(c_i,j) - εθ(c_∅)||²
  └── Total: L_final = L_score + λ × L_CI
  ```

- Critical path:
  1. Start with pretrained CFG diffusion model (or train from scratch)
  2. Identify attribute indices in condition embedding space
  3. Implement Algorithm 1 lines 4-11 (pairwise L_CI)
  4. Tune λ: Start with λ = L_score/L_CI from vanilla model, explore [0.1, 10]
  5. Validate: Compute JSD on held-out samples; target JSD < 0.3 for good composition

- Design tradeoffs:
  - **λ magnitude**: Low λ preserves image quality but compositional accuracy suffers; high λ enforces independence but may collapse to prior (Figure 8 shows CS peaks then drops)
  - **Pairwise vs full L_CI**: Pairwise is 4 forward passes regardless of n attributes; full would require 2ⁿ passes—pairwise is only practical option for n > 5
  - **Training from scratch vs fine-tuning**: Paper shows both work (Tables 2, 6). Fine-tuning is faster but requires matching the pretrained model's noise schedule

- Failure signatures:
  - **JSD stuck > 0.5**: λ too low or learning rate too small for L_CI gradients; increase λ or use separate learning rates
  - **CS drops as λ increases**: Model ignoring conditions and sampling from p(X); λ exceeded threshold, reduce it
  - **Correlated features in outputs**: Even with low JSD, training data had extreme partial support; may need data augmentation or weaker λ combined with longer training
  - **Mode collapse**: Only generates seen compositions; λ too high or training too short for marginals to converge

- First 3 experiments:
  1. **Colored MNIST diagonal partial support reproduction**: Train vanilla CFG and CoInD (λ=1.0) with only diagonal attribute pairs observed. Measure CS on unseen off-diagonal pairs. Target: vanilla ~7% CS, CoInD ~50% CS (per Table 1, Figure 4a).
  2. **λ sweep with JSD monitoring**: Train 5 models with λ ∈ {0, 0.2, 0.5, 1.0, 2.0}. Plot JSD and CS vs λ. Expected: U-shaped CS curve with peak around λ=0.5-1.0; JSD monotonically decreasing. This validates the λ selection procedure.
  3. **CelebA orthogonal support with fine-tuning**: Fine-tune SD1.5 or train from scratch on CelebA with all combinations except "smiling male" removed. Evaluate FID and CS on held-out smiling males. Verify γ control increases smile intensity without introducing gender-correlated features (Figure 7 reproduction).

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the principles of CoInD be extended to **open-set compositions** where attributes are not pre-defined or explicitly labeled during training?
  - Basis in paper: [explicit] The authors explicitly list this as a limitation in Appendix F.5, noting that "state-of-the-art generative models seek to operate without pre-defined attributes... and generate open-set compositions," whereas CoInD currently requires a closed set $C$.
  - Why unresolved: The current framework relies on a finite Cartesian product of attribute values ($C_{train} \subset C$) and requires attribute-specific classifiers for evaluation and independence enforcement.
  - What evidence would resolve it: A successful application of CoInD to latent feature spaces or text-conditional generation that handles novel attribute concepts not present in the training label space.

- **Open Question 2**: How does CoInD behave when the underlying data generation process violates the assumption of **statistically independent attributes**?
  - Basis in paper: [inferred] The paper explicitly assumes the true causal graph (Fig 2a) involves independent attributes to derive the training objective. It addresses confounding during training but does not discuss scenarios where attributes are intrinsically correlated (e.g., "male" and "mustache") in the true distribution.
  - Why unresolved: Enforcing conditional independence on attributes that are truly dependent could theoretically distort the learned distribution or reduce sample fidelity.
  - What evidence would resolve it: Experiments on datasets with known, inherent attribute correlations, measuring the trade-off between logical compositionality and distributional fidelity.

- **Open Question 3**: Does the explicit enforcement of conditional independence provide a **computational advantage or bottleneck** when scaling to large-scale, uncurated datasets?
  - Basis in paper: [inferred] The authors note that "scaling the datasets without inductive biases... is insufficient" and demonstrate results on smaller datasets (Colored MNIST, Shapes3D) and fine-tuning. The scalability of the $L_{CI}$ loss term itself to massive datasets remains unquantified.
  - Why unresolved: While the method scales linearly with the number of attributes, the interaction between the Fisher divergence minimization and large-batch training dynamics on massive, noisy data is unknown.
  - What evidence would resolve it: Training curves and convergence rates of CoInD on a large-scale dataset (e.g., LAION) compared to standard classifier-free guidance.

## Limitations

- The Hammond & Sun (2006) pairwise approximation assumes specific conditions that aren't verified for these datasets; the equivalence may break for complex attribute distributions
- The method requires known attribute index mapping in the condition embedding space, limiting generalization to datasets without explicit attribute labels
- Results depend heavily on proper λ tuning, and the optimal value appears dataset-specific (CelebA requires higher λ than Shapes3D)

## Confidence

- **High confidence**: The L_CI objective correctly enforces conditional independence when attributes are truly independent in the data-generating process (supported by mathematical derivation and experimental JSD scores)
- **Medium confidence**: Pairwise approximation is sufficient for mutual independence (based on Hammond & Sun result but no direct empirical validation against full L_CI)
- **Medium confidence**: Score decomposition formulas produce correct compositions (derivation is sound, but assumes perfect independence enforcement)

## Next Checks

1. Compare CoInD against full L_CI (enforcing independence across all attribute subsets) on a small n=3 dataset to quantify approximation error
2. Test on a dataset with known attribute dependencies (e.g., "smiling" and "wearing lipstick") to verify the method fails gracefully rather than producing incorrect compositions
3. Evaluate whether CoInD maintains compositional accuracy when fine-tuned on a dataset with different noise schedules or diffusion architectures than the pretrained model