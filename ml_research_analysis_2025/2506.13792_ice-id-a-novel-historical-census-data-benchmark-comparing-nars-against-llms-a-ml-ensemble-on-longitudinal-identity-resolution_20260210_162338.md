---
ver: rpa2
title: 'ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs,
  \& a ML Ensemble on Longitudinal Identity Resolution'
arxiv_id: '2506.13792'
source_url: https://arxiv.org/abs/2506.13792
tags:
- data
- nars
- census
- records
- same
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ICE-ID is a 220-year benchmark of Icelandic census records for
  historical identity resolution, featuring hierarchical geography, kinship links,
  and longitudinal variation. It supports within- and across-census matching with
  200 k expert-verified clusters.
---

# ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \& a ML Ensemble on Longitudinal Identity Resolution

## Quick Facts
- **arXiv ID:** 2506.13792
- **Source URL:** https://arxiv.org/abs/2506.13792
- **Reference count:** 38
- **One-line primary result:** ICE-ID is a 220-year benchmark of Icelandic census records for historical identity resolution, featuring hierarchical geography, kinship links, and longitudinal variation.

## Executive Summary
ICE-ID introduces a novel benchmark for historical identity resolution, comprising 220 years of Icelandic census data with hierarchical geography, kinship links, and longitudinal variation. The benchmark enables within- and across-census matching with 200k expert-verified clusters. We compare handcrafted rules, an ML ensemble (XGBoost, LightGBM, CatBoost, Random Forest), and NARS (Non-Axiomatic Reasoning System). NARS achieves competitive pairwise accuracy (F1≈0.98) and outperforms ML in clustering diagnostics (ARI), with better temporal robustness. By releasing ICE-ID and reproducible code, we enable research on non-stationary, genealogical record linkage, highlighting the value of symbolic reasoning for robust, interpretable entity resolution.

## Method Summary
The ICE-ID benchmark spans 220 years of Icelandic census data (1703–1920) and includes two subtasks: intra-census linkage (within same wave) and cross-census linkage (across decades). The dataset features hierarchical geography, kinship links, and longitudinal variation. Methods compared include an ML ensemble (XGBoost, LightGBM, CatBoost, Random Forest) and NARS (Non-Axiomatic Reasoning System). The ML ensemble averages probabilities from four tree-based models, while NARS uses a pattern pool to store atomic judgments with truth values and applies inference rules for scoring. Performance is evaluated using pairwise metrics (Precision, Recall, F1, Accuracy, ROC-AUC) and clustering diagnostics (ARI-CC, ARI-Agg).

## Key Results
- NARS achieves competitive pairwise accuracy (F1≈0.98) and outperforms ML in clustering diagnostics (ARI).
- The ML ensemble attains near-perfect pairwise metrics but negligible clustering coherence, revealing a key limitation.
- NARS demonstrates better temporal robustness compared to ML models under distribution shift.

## Why This Works (Mechanism)
The benchmark's strength lies in its longitudinal nature, capturing temporal distribution shifts in naming conventions, administrative geographies, and data completeness. NARS's symbolic reasoning framework, with truth values (frequency, confidence) and pattern inference, enables robust handling of non-stationary data. The ML ensemble's high pairwise accuracy but poor clustering coherence highlights the challenge of forming consistent identity clusters across time. The ICE-ID benchmark provides a controlled environment to study these phenomena, enabling research on non-stationary, genealogical record linkage.

## Foundational Learning
- **Concept: Non-Axiomatic Reasoning System (NARS)**
  - **Why needed here**: NARS is the core symbolic reasoning framework used in the paper. Understanding its basic operation—learning from examples as patterns with truth values (frequency, confidence) and performing inference—is essential to grasp how it differs from standard ML.
  - **Quick check question**: Can you explain what the `frequency` and `confidence` components of a NARS truth value represent?

- **Concept: Entity Resolution (Record Linkage)**
  - **Why needed here**: This is the core problem. It involves identifying records from different data sources (or, in this case, different census years) that refer to the same real-world entity. The paper evaluates both pairwise matching accuracy (F1) and the quality of the final clusters (ARI).
  - **Quick check question**: What is the key difference between evaluating identity resolution with pairwise metrics (like F1) versus clustering metrics (like ARI)?

- **Concept: Temporal Distribution Shift**
  - **Why needed here**: The paper's key challenge is longitudinal data spanning 220 years. Models are trained on early census data and tested on later data, which introduces "drift" in naming conventions, administrative geographies, and data completeness. A model's ability to handle this non-stationarity is a central finding.
  - **Quick check question**: In the ICE-ID benchmark, how are the train, validation, and test splits constructed to simulate this real-world problem?

## Architecture Onboarding
- **Component map**: Data Ingestion & Preprocessing -> ML Ensemble (XGBoost, LightGBM, CatBoost, Random Forest) -> Pairwise Evaluation + Clustering Diagnostics; Data Ingestion & Preprocessing -> NARS (Pattern Pool, Inference Engine) -> Pairwise Evaluation + Clustering Diagnostics
- **Critical path**: For the NARS system, the critical path for onboarding is: Feature Engineering (pair transformation to atomic judgments) -> Learning Mechanism (truth-value initialization/update from labeled pairs) -> Scoring & Inference (pattern matching and inference for final similarity belief)
- **Design tradeoffs**: ML Ensemble: High accuracy on known data distributions but poor generalization under temporal drift and no inherent clustering coherence. Requires labeled pairs for training. NARS: Competitive accuracy with better temporal robustness and superior clustering coherence (ARI). Simpler, does not require GPU resources. Novel, less standard approach.
- **Failure signatures**: ML Ensemble: F1 score remains high (>0.90), but Adjusted Rand Index (ARI) is near zero. This indicates the model is good at pairwise classification but fails to form consistent clusters of identities. Performance may drop significantly (>30% F1) on test data from a much later time period than training data. NARS: Performance could degrade if the atomic patterns generated are too sparse or if the inference rules fail to generalize to unseen name variations or demographic changes.
- **First 3 experiments**:
    1. **Reproduce Baseline Metrics**: Run the provided ML ensemble code on the ICE-ID `across-census` task. Verify that you achieve high F1 (>0.98) but near-zero ARI as reported. This validates your setup.
    2. **Probe Temporal Robustness**: Take the trained ML ensemble and evaluate its performance separately on each census wave in the test set (1901-1920). Plot F1 score vs. census year. You should observe a degradation trend as you move further from the training data's time period.
    3. **Analyze NARS Pattern Pool**: After training NARS, inspect the contents of the `PatternPool`. Identify the top patterns with the highest expectation (e = c(f-0.5)+0.5). Are they intuitive (e.g., high weight on name and birth year) or do they capture more complex, non-obvious signals from the data? This provides insight into the system's learned "reasoning."

## Open Questions the Paper Calls Out
None

## Limitations
- The ML ensemble's strong pairwise accuracy paired with near-zero clustering coherence reveals a fundamental limitation of supervised models on longitudinal data with temporal drift.
- The paper's findings are constrained to Icelandic census records, raising questions about generalizability to other languages, cultures, or record types.
- The temporal split (pre-1870 training, 1870–1920 testing) assumes a linear progression of naming and administrative changes, which may not capture all real-world complexities.

## Confidence
- **High confidence**: ICE-ID benchmark construction, pairwise evaluation metrics, and the ML ensemble's performance pattern (high F1, near-zero ARI) are clearly described and reproducible with the provided data.
- **Medium confidence**: The NARS system's conceptual framework and comparative advantages (better temporal robustness, superior clustering coherence) are supported, but precise algorithmic details and hyperparameters are not fully specified.
- **Low confidence**: Generalizability of NARS to other domains, languages, or record types beyond Icelandic census data is not empirically demonstrated.

## Next Checks
1. **Probe Temporal Robustness**: Train the ML ensemble on pre-1870 data and evaluate F1 scores separately on each census wave from 1870–1920. Plot F1 vs. census year to quantify degradation and compare against NARS.
2. **Inspect NARS Pattern Pool**: After training, extract the top 20 patterns by expectation value. Verify they capture intuitive signals (e.g., name + birthyear matches) and assess whether they reveal non-obvious, domain-specific reasoning.
3. **Simulate Administrative Changes**: Introduce synthetic changes to county/district boundaries in a held-out subset of ICE-ID. Re-run both NARS and ML ensemble to measure relative robustness to shifting hierarchical geography.