---
ver: rpa2
title: 'TruthTensor: Evaluating LLMs through Human Imitation on Prediction Market
  under Drift and Holistic Reasoning'
arxiv_id: '2601.13545'
source_url: https://arxiv.org/abs/2601.13545
tags:
- evaluation
- drift
- reasoning
- market
- truthtensor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TruthTensor introduces a dynamic evaluation framework that measures
  LLM performance as human-imitation systems operating in live prediction markets.
  Instead of static benchmarks, it evaluates models on forward-looking events with
  unknown outcomes, preventing data contamination and forcing genuine reasoning assessment.
---

# TruthTensor: Evaluating LLMs through Human Imitation on Prediction Market under Drift and Holistic Reasoning

## Quick Facts
- **arXiv ID:** 2601.13545
- **Source URL:** https://arxiv.org/abs/2601.13545
- **Reference count:** 40
- **Primary result:** Evaluates LLMs as human-imitation systems in live prediction markets, tracking drift and calibration across 500+ real markets

## Executive Summary
TruthTensor introduces a dynamic evaluation framework that measures LLM performance as human-imitation systems operating in live prediction markets. Instead of static benchmarks, it evaluates models on forward-looking events with unknown outcomes, preventing data contamination and forcing genuine reasoning assessment. The framework tracks multiple drift dimensions—narrative, temporal, and confidence—while measuring calibration, risk sensitivity, and reasoning coherence over time. Experiments across 500+ real markets show that models with similar accuracy can differ markedly in calibration, drift, and risk-sensitivity, highlighting the need for multi-dimensional evaluation.

## Method Summary
The framework anchors evaluation to live prediction markets to prevent data contamination and forces genuine reasoning. It tracks drift dimensions (narrative, temporal, confidence) while measuring calibration, risk sensitivity, and reasoning coherence over time. The system compares model outputs to market-implied probabilities, serving as a scalable ground truth for human-like reasoning. A Holistic Human Imitation Score (HHIS) rewards models exhibiting similar calibration and risk profiles to the aggregated human crowd.

## Key Results
- Models with similar accuracy can differ markedly in calibration, drift, and risk-sensitivity
- Forward-looking evaluation prevents data contamination inherent in static benchmarks
- Drift measurement reveals reasoning stability that accuracy metrics alone miss
- Market grounding provides scalable, continuous evaluation against human reasoning

## Why This Works (Mechanism)

### Mechanism 1: Contamination-Resistant Evaluation via Forward-Looking Tasks
Evaluating models on forward-looking prediction markets mitigates data contamination inherent in static benchmarks, forcing genuine reasoning rather than recall. The system anchors evaluation to events with unknown outcomes (future predictions) that could not have existed in training data, preventing memorization from inflating performance scores. This assumes successful forecasting requires generative reasoning capabilities rather than pattern matching against historical analogues.

### Mechanism 2: Drift Measurement as a Proxy for Reasoning Stability
Tracking drift (narrative, temporal, confidence) provides a signal for reasoning coherence that accuracy metrics alone miss. The system queries the model repeatedly over time for the same event, quantifying the divergence between the model's probability shifts and actual market information flow. High Narrative Drift indicates the model is changing its story without new data, while high Temporal Drift indicates over-sensitivity to noise.

### Mechanism 3: Market Grounding for Human Imitation
Comparing model outputs to market-implied probabilities serves as a scalable, continuous ground truth for human-like reasoning. Instead of waiting for event resolution, the system compares the model's probabilistic trajectory against the market's price trajectory. The Human Imitation Score (HHIS) rewards models that exhibit similar calibration and risk profiles to the aggregated human crowd.

## Foundational Learning

- **Concept: Proper Scoring Rules (Brier Score)**
  - Why needed: You cannot evaluate probabilistic forecasts using simple accuracy. If a model says "70% chance," it needs credit for being calibrated, not just for the binary outcome.
  - Quick check: If an event happens, did the model predict it with 100% certainty (overconfident) or 60% (calibrated)?

- **Concept: Data Contamination (Leakage)**
  - Why needed: Understanding why static benchmarks fail is critical. If a model saw the test questions during training, its performance is memorization, not intelligence.
  - Quick check: How can we verify a model is reasoning rather than reciting, given we don't know its exact training data?

- **Concept: Distribution Shift / Concept Drift**
  - Why needed: The paper argues that model behavior changes over time (temporal/narrative drift). You must understand that statistical relationships in the world change, and models must adapt or maintain coherence.
  - Quick check: Does the model's reasoning hold up as the context window slides or as time passes, or does the story change randomly?

## Architecture Onboarding

- **Component map:** Define Locked Prompt -> Ingest Market Data -> Agent Generates JSON Decision -> System Computes Drift/Scores -> Log to Leaderboard
- **Critical path:** Define Locked Prompt → Ingest Market Data → Agent Generates JSON Decision → System Computes Drift/Scores → Log to Leaderboard
- **Design tradeoffs:**
  - Observation vs. Execution Mode: Execution provides stronger "skin in the game" signals but introduces execution risk/slippage
  - Token Budget: Constraining tokens lowers cost but may truncate the "reasoning trace" required to explain complex forecasts
  - Market Liquidity: High liquidity ensures accurate ground truth but limits available markets
- **Failure signatures:**
  - High Narrative Drift: The agent changes its reasoning logic for the same event across successive runs without new news
  - Overconfidence: The agent outputs probabilities near 0.0 or 1.0 on low-information events
  - Formatting Collapse: The agent fails to output the strictly required JSON structure, breaking the evaluation loop
- **First 3 experiments:**
  1. Sanity Check (Baseline Alignment): Run a capable model in Observation Mode. Verify that its probability estimates generally correlate with market prices.
  2. Drift Stress Test: Query the model on the same static market state 10 times with slightly varied context ordering. Measure Narrative Drift to see if reasoning is stable or stochastic.
  3. Token Constraint Analysis: Evaluate a single model's HHIS score under varying token limits (e.g., 500 vs 4000 tokens) to measure degradation of reasoning quality vs. cost.

## Open Questions the Paper Calls Out

### Open Question 1
Can incorporating persona-driven digital twins improve the evaluation of agentic systems compared to the current market-aligned forecasting approach?
- Basis: The conclusion states future iterations could extend beyond market-aligned forecasting to incorporate persona-driven digital twins
- Why unresolved: The current framework anchors evaluation to live prediction markets as the sole "human imitation" baseline
- What evidence would resolve it: A comparative study showing that agents evaluated against specific personas exhibit higher correlation with actual human decision-making patterns than those evaluated against market aggregates

### Open Question 2
Does the performance ranking of models remain stable across prediction markets with different liquidity profiles or demographic compositions?
- Basis: The evaluation relies exclusively on Polymarket, a crypto-based platform, which may introduce specific liquidity and demographic biases
- Why unresolved: The paper does not validate the framework on other market types
- What evidence would resolve it: Replicating the benchmark on a distinct platform (e.g., a sports betting exchange) and measuring the correlation of model rankings

### Open Question 3
Does minimizing "narrative drift" in prediction markets transfer to improved reasoning stability in non-market, long-horizon tasks?
- Basis: The paper posits drift as a central evaluation dimension for general reasoning, but only validates it within the specific context of financial market prediction
- Why unresolved: It is unclear if the "Narrative Drift Score" is a domain-specific artifact or a general proxy for reasoning coherence
- What evidence would resolve it: Correlating model drift scores from TruthTensor with performance on longitudinal, non-financial reasoning benchmarks

## Limitations

- The framework's reliance on prediction market prices as ground truth introduces significant uncertainty when markets are illiquid, manipulated, or subject to herding behavior
- The Narrative Consistency metric ($D_n$) remains underspecified—only conceptually described without a concrete implementation
- The evaluation assumes models can meaningfully participate in high-entropy, socially-grounded domains, but performance may degrade in low-information or ambiguous events

## Confidence

**High Confidence:** The contamination-resistant evaluation mechanism (forward-looking tasks preventing data leakage) is logically sound and well-supported by the literature on static benchmark limitations. The drift measurement framework and its three dimensions (narrative, temporal, confidence) are clearly specified and mathematically operationalized.

**Medium Confidence:** The market grounding assumption—that prediction market prices efficiently aggregate information and serve as valid human reasoning baselines—is reasonable but depends heavily on market quality. The Holistic Human Imitation Score (HHIS) formula is explicit, but its weighting choices appear somewhat arbitrary without extensive ablation studies.

**Low Confidence:** The framework's ability to distinguish genuine reasoning from advanced analogical retrieval remains uncertain. If models retrieve highly isomorphic historical precedents rather than generating new reasoning, the "contamination-resistant" claim weakens. Additionally, token budget constraints may truncate reasoning traces needed to explain complex forecasts.

## Next Checks

1. **Market Quality Validation:** Run the same evaluation framework on prediction markets with varying liquidity levels (high vs. low) to quantify how market irrationality affects model rankings.

2. **Drift Metric Completeness:** Implement and test the missing Narrative Consistency function ($D_n$) using multiple candidate definitions to assess which operationalization best captures genuine reasoning drift versus superficial variation.

3. **Contamination Resistance Test:** Create a controlled experiment where models are evaluated on events with varying degrees of historical precedent availability in their training data. Measure whether performance correlates with precedent availability.