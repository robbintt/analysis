---
ver: rpa2
title: 'GTG: Generalizable Trajectory Generation Model for Urban Mobility'
arxiv_id: '2502.01107'
source_url: https://arxiv.org/abs/2502.01107
tags:
- trajectory
- road
- travel
- data
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GTG, a generalizable trajectory generation
  model for urban mobility. The method addresses the challenge of cross-city trajectory
  generation by learning invariant mobility patterns.
---

# GTG: Generalizable Trajectory Generation Model for Urban Mobility

## Quick Facts
- arXiv ID: 2502.01107
- Source URL: https://arxiv.org/abs/2502.01107
- Reference count: 34
- Key outcome: GTG achieves lower values across all evaluation metrics (distance, radius, location frequency, Hausdorff, DTW, EDT, and EDR) for cross-city trajectory generation compared to baseline methods.

## Executive Summary
This paper introduces GTG, a generalizable trajectory generation model designed to address the challenge of generating realistic urban mobility trajectories in new cities without requiring target city data. The method leverages Space Syntax theory to extract city-invariant road representations and employs disentangled adversarial training to separate semantic and domain features. Through extensive experiments on three real-world datasets (Beijing, Xi'an, and Chengdu), GTG demonstrates superior generalization ability compared to existing models, significantly outperforming them across all evaluation metrics for cross-city trajectory generation.

## Method Summary
GTG tackles cross-city trajectory generation by first extracting city-invariant road representations using Space Syntax features (Total Depth, Integration, Connectivity, Choice) combined with basic road attributes. The model partitions road networks into subgraphs using Metis, aggregates them with a Spatial Aggregation Graph Attention Network (SAGAT), and employs disentangled adversarial training where a semantic encoder predicts travel costs and a domain encoder is trained to fool a domain discriminator. Preference learning is achieved through unsupervised shortest path search and iterative preference updates. The model is trained on source city data and can generate trajectories for target cities using only the target city's road network.

## Key Results
- GTG achieves lower values across all evaluation metrics (distance, radius, location frequency, Hausdorff, DTW, EDT, and EDR) compared to baseline methods
- The model demonstrates strong generalization capability by generating trajectories in new cities without requiring target city trajectory data
- Experiments on three real-world datasets (Beijing, Xi'an, and Chengdu) show consistent performance improvements across all cross-city transfer scenarios

## Why This Works (Mechanism)
GTG works by learning city-invariant representations that capture fundamental mobility patterns rather than city-specific features. The Space Syntax features provide topological and geometric properties that remain consistent across different urban layouts, while the disentangled adversarial training ensures the semantic encoder learns domain-invariant representations for travel cost prediction. The preference learning component captures human mobility preferences by comparing generated trajectories with optimal paths, allowing the model to generate realistic trajectories that reflect actual travel behavior patterns.

## Foundational Learning
- Space Syntax Theory: Provides topological and geometric road network features that are invariant across cities; needed to extract city-invariant representations; quick check: verify Total Depth and Integration values make sense for road networks
- Adversarial Domain Adaptation: Separates domain-invariant semantic features from domain-specific features; needed to prevent overfitting to source city; quick check: domain discriminator accuracy should be near random (0.5) after training
- Graph Neural Networks: Processes road network structure and relationships; needed to aggregate local subgraph information; quick check: node embeddings should capture local road network topology
- Map Matching: Aligns GPS trajectories to road networks; needed to create accurate training data; quick check: matched trajectories should follow drivable paths
- Shortest Path Algorithms: Generates trajectories based on learned travel costs and preferences; needed for trajectory generation; quick check: generated paths should be physically drivable
- Statistical Divergence Measures: Evaluates distribution similarity between generated and real trajectories; needed for macro-level performance assessment; quick check: JSD values should be lower for better models

## Architecture Onboarding
- Component Map: Road Network + Space Syntax Features -> SAGAT -> Disentangled Encoders (Semantic + Domain) -> Adversarial Training -> Travel Cost Prediction -> Preference Learning -> Shortest Path Search -> Generated Trajectories
- Critical Path: Data Preparation (Space Syntax + SAGAT features) -> Disentangled Representation Learning -> Preference Learning -> Trajectory Generation
- Design Tradeoffs: SAGAT vs GCN for aggregation (SAGAT preserves spatial relationships), adversarial training vs direct domain adaptation (better disentanglement), unsupervised preference learning vs supervised (no need for target city labels)
- Failure Signatures: Poor cross-city transfer (high JSD/micro distances) indicates semantic encoder leaking domain information; Space Syntax computation errors (incorrect Total Depth/Integration values); preference learning divergence (oscillating trajectory quality)
- First Experiments: 1) Verify Space Syntax feature computation on small test network; 2) Test domain discriminator accuracy on source vs target cities; 3) Validate trajectory generation quality by comparing JSD values against baseline methods

## Open Questions the Paper Calls Out
None

## Limitations
- Model architecture details are underspecified, particularly SAGAT hyperparameters and Metis partition counts
- Space Syntax computation complexity (O(NÂ²)) may not scale well to larger cities
- Map-matching implementation details are referenced but not fully described
- OD pair sampling strategy for generation is not specified, potentially impacting diversity and coverage

## Confidence
- **High confidence**: The core concept of using Space Syntax features for city-invariant representations is well-established
- **Medium confidence**: The disentangled adversarial training approach for domain-invariant representations is sound
- **Medium confidence**: The preference learning via shortest path comparison is methodologically valid

## Next Checks
1. Verify SAGAT implementation with specific hyperparameters matches the paper's performance on source city training
2. Test domain discriminator accuracy on source vs target cities to confirm effective disentanglement of semantic and domain features
3. Validate trajectory generation quality by comparing JSD and micro metric distributions against reported values for all cross-city combinations