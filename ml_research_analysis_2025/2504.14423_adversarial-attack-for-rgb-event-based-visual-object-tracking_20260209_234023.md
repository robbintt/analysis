---
ver: rpa2
title: Adversarial Attack for RGB-Event based Visual Object Tracking
arxiv_id: '2504.14423'
source_url: https://arxiv.org/abs/2504.14423
tags:
- adversarial
- event
- tracking
- attack
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the first adversarial attack method for RGB-Event
  based visual object tracking. The authors address the vulnerability of multi-modal
  tracking systems by designing cross-modal adversarial attacks tailored to different
  Event data representations (voxels and frames).
---

# Adversarial Attack for RGB-Event based Visual Object Tracking

## Quick Facts
- **arXiv ID:** 2504.14423
- **Source URL:** https://arxiv.org/abs/2504.14423
- **Reference count:** 40
- **Primary result:** First adversarial attack method for RGB-Event based visual object tracking, achieving up to 70% reduction in precision rate

## Executive Summary
This paper introduces the first adversarial attack framework targeting RGB-Event based visual object tracking systems. The authors design attack strategies tailored to different event data representations - voxels and frames - exploiting the unique characteristics of event cameras. For voxel representations, they propose a two-step approach combining regional voxel injection with gradient-guided spatial optimization. For RGB-Event frames, they develop cross-modal universal perturbations by integrating gradient information from both modalities. The attacks significantly degrade tracking performance across three benchmark datasets, revealing critical vulnerabilities in multi-modal tracking systems.

## Method Summary
The attack method targets CEUTrack, a Transformer-based RGB-Event tracker, through two primary strategies. For event voxels, the attack first injects invalid voxels into target regions (AdvInit), then optimizes their spatial-temporal coordinates using PGD with sign gradients (GradOpt). For RGB-Event frames, a cross-modal universal perturbation is optimized by fusing gradients from both modalities in a two-step process. Temporal perturbation propagation maintains attack consistency across frames by transferring historical perturbations as initialization for subsequent frames. The adversarial loss combines focal, L1, and GIoU terms with target attraction and ground-truth repulsion objectives.

## Key Results
- Achieves up to 70% reduction in precision rate on RGB-Event tracking benchmarks
- Cross-modal universal perturbations outperform unimodal attacks by exploiting gradient information from both RGB and Event modalities
- Temporal perturbation propagation maintains attack effectiveness across sequential frames
- Significant performance degradation observed across three datasets: COESOT, FE108, and VisEvent

## Why This Works (Mechanism)

### Mechanism 1
Injecting event voxels into target regions followed by gradient-guided spatial coordinate perturbation disrupts event-based localization. The attack exploits the sparse, discrete nature of event voxels by first injecting N_v voxels into a predefined target attack region (simulating invalid voxel distribution), then applying PGD optimization to perturb spatial-temporal coordinates (x, y, t) of the initialized adversarial voxels. The adversarial loss L_adv minimizes distance to a target position while maximizing distance from ground-truth.

### Mechanism 2
Cross-modal universal perturbations leveraging gradient information from both RGB and Event modalities achieve stronger attacks than unimodal perturbations. A two-step training process: (1) learn universal perturbation η from RGB frame modality using adversarial loss optimization; (2) further optimize η using Event frame modality while stacking the optimized perturbation back onto RGB frames. This creates a shared perturbation space that exploits cross-modal feature interactions.

### Mechanism 3
Temporal perturbation propagation maintains attack consistency across sequential frames, disrupting tracking coherence. Historical perturbations are transferred as initialization for subsequent frame attacks: V^t_adv = V^t_ori + (V^{t-1}_ori - V^{t-1}_adv). This leverages the temporal continuity inherent in video tracking, ensuring perturbations accumulate rather than reset.

## Foundational Learning

- **Concept:** Event Camera Representations (Voxels vs. Frames)
  - **Why needed here:** The attack strategy differs fundamentally based on whether events are discretized into spatio-temporal voxel grids V ∈ R^{H×W×T} or accumulated into 2D event frames F ∈ R^{H×W}. Voxel attacks perturb coordinates; frame attacks use image-space perturbations.
  - **Quick check question:** Given an event stream E = {(x_k, y_k, t_k, p_k)}, can you explain why voxel representations enable coordinate-space attacks while frame representations require pixel-space perturbations?

- **Concept:** Projected Gradient Descent (PGD) for Adversarial Attacks
  - **Why needed here:** PGD iteratively updates perturbations in the gradient direction with projection to maintain ε-bounded perturbations. The paper uses PGD with sign(gradient) for both RGB and event coordinate optimization.
  - **Quick check question:** In Equation 2, why does the projection operation Proj_ε constrain perturbations, and what happens if ε is set too large for event voxel coordinates?

- **Concept:** Multi-Modal Tracking Loss Functions
  - **Why needed here:** The adversarial loss L_adv builds on tracking losses (L_focal, L_L1, L_GIoU). Understanding standard tracking objectives is prerequisite to designing effective adversarial objectives that maximize prediction error.
  - **Quick check question:** How does L_adv (Equation 4) differ from standard tracking loss (Equation 3), and why does it include both target attraction and ground-truth repulsion terms?

## Architecture Onboarding

- **Component map:** Input Layer (RGB frames + Event stream) -> Perturbation Module (AdvInit + GradOpt for voxels; Cross-modal universal perturbation for frames) -> Temporal Propagation (historical perturbation buffer) -> Loss Computation (adversarial loss L_adv) -> Target Tracker (CEUTrack)

- **Critical path:**
  1. Initialize: Retrieve RGB frame I^t and Event voxel/frame from search region
  2. Inject: For voxels, inject N_v voxels into target region S(x,y,w,h)
  3. Iterate (M=10 iterations): Compute gradients R_rgb, R_event via L_adv; update with PGD step α=1, boundary ε=8-10
  4. Propagate: Apply temporal perturbation from frame t-1 as initialization
  5. Output: Adversarial RGB I* and Event V* samples

- **Design tradeoffs:**
  - Voxel vs. Frame attack selection: Voxel attacks require coordinate-space optimization (computationally lighter but representation-specific); frame attacks enable universal perturbations (more transferable but require multi-modal gradient integration)
  - Iteration count M: Higher M improves attack success but increases latency (Fig. 6 shows convergence at M=10)
  - Perturbation budget ε: Larger ε improves attack but risks detectability (ε=10 for RGB, ε=8 for Event used in experiments)

- **Failure signatures:**
  - Low PR reduction on Event voxels: May indicate voxelization resolution mismatch or insufficient injected voxels N_v
  - Cross-modal attack underperforms unimodal: Gradient conflict between modalities; consider decoupled optimization schedules
  - Temporal propagation unstable: Check perturbation accumulation bounds; historical perturbations may exceed ε when transferred

- **First 3 experiments:**
  1. Unimodal baseline validation: Attack Event voxels only (no RGB) on COESOT using AdvInit+GradOpt; verify PR drops from 12.6% baseline (Table I shows 6.9% achieved)
  2. Ablation of adversarial loss: Compare L_adv vs. standard track loss on RGB-Event frame attack; Table III/IV shows adversarial loss achieves 70.3-70.7% PR reduction vs. 69.2-70.3% for track loss
  3. Temporal propagation analysis: Run attack with and without Equation 5 temporal transfer on RGB-Event voxel; Fig. 4 shows temporal perturbation significantly weakens tracking coherence over time

## Open Questions the Paper Calls Out

- **How can effective defense mechanisms be designed to specifically protect RGB-Event trackers against cross-modal adversarial attacks?**
  - The authors state in Related Works and Conclusion that "There is an urgent need to investigate... corresponding defense mechanisms" and hope to "motivate attention to the adversarial robustness."
  - This paper focuses exclusively on the attack formulation (optimizing perturbations) and validating the vulnerability of existing trackers, without proposing or testing any defensive strategies.

- **Does the vulnerability of event data vary significantly across different tracking architectures beyond the Transformer-based CEUTrack?**
  - The Conclusion notes, "In the future, we plan to explore more RGB-Event-based visual tracking model architectures to further reveal the security."
  - The experimental validation is restricted to the CEUTrack framework; it is unclear if CNN-based or Graph-based event trackers exhibit the same sensitivity to voxel injection and spatial optimization.

- **Can the proposed digital perturbations for Event voxels be realized as physical attacks in real-world environments?**
  - The methodology relies on digital optimization and injection of voxels on benchmark datasets, implicitly assuming the attacker can manipulate the data stream directly.
  - Modifying discrete voxel coordinates (x, y, t) digitally is straightforward, but reproducing these precise spatio-temporal perturbations via physical stimuli (e.g., light sources) aimed at an event camera remains an unaddressed challenge.

## Limitations

- The white-box nature of attacks assumes full access to model gradients and architecture, which may not reflect realistic threat models
- The perturbation budgets (ε=8-10) appear effective but could be detectable in practical applications
- Evaluation focuses on a single tracker (CEUTrack), limiting generalizability to other RGB-Event tracking architectures

## Confidence

- **High Confidence:** The basic mechanism of adversarial attacks on tracking systems (PR reduction up to 70%) is well-established and consistently demonstrated across datasets
- **Medium Confidence:** The cross-modal universal perturbation approach shows promise but requires more validation across diverse tracking architectures to confirm general effectiveness
- **Low Confidence:** The specific implementation details for voxel coordinate perturbation (particularly handling discrete vs. continuous coordinate updates) are not fully specified and may impact reproducibility

## Next Checks

1. **Cross-Architecture Transferability:** Test the attack method against at least two other RGB-Event tracking architectures (e.g., Mamba-FETrack V2, CM3AE) to validate attack generalizability beyond CEUTrack

2. **Black-Box Attack Evaluation:** Implement and evaluate transfer-based black-box attacks where the target tracker architecture is unknown, assessing practical attack feasibility

3. **Detection Robustness Analysis:** Measure attack detectability through perturbation visibility metrics and evaluate defensive strategies like input preprocessing or adversarial training on the tracking model