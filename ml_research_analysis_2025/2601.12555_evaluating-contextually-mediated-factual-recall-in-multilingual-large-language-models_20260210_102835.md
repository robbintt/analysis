---
ver: rpa2
title: Evaluating Contextually Mediated Factual Recall in Multilingual Large Language
  Models
arxiv_id: '2601.12555'
source_url: https://arxiv.org/abs/2601.12555
tags:
- contextual
- language
- factual
- direct
- names
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates contextually mediated factual recall in
  multilingual LLMs, addressing the gap between direct factual queries and natural
  language use where facts are accessed through context. The authors construct controlled
  prompts that embed target entities indirectly within naturalistic contexts while
  preserving the underlying facts, and compare synthetic names versus real names across
  five languages (English, Arabic, Japanese, Korean, Chinese) and nine relation types.
---

# Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models

## Quick Facts
- arXiv ID: 2601.12555
- Source URL: https://arxiv.org/abs/2601.12555
- Authors: Yihong Liu; Bingyu Xiong; Hinrich SchÃ¼tze
- Reference count: 19
- Primary result: Contextual mediation consistently degrades factual recall across all languages and relations, with larger models showing greater robustness to this effect.

## Executive Summary
This paper investigates how factual recall performance changes when entities are referenced indirectly through context rather than being explicitly named in prompts. The authors construct controlled experiments across five languages (English, Arabic, Japanese, Korean, Chinese) comparing direct factual queries with contextually mediated prompts that embed target entities within naturalistic contexts. Using nine relation types and synthetic versus real names, they find that contextual mediation degrades performance consistently across all conditions, with larger models showing reduced sensitivity to this effect. The study reveals that surrounding context dominates over name surface forms in determining recall accuracy.

## Method Summary
The authors evaluate 9 multilingual LLMs (LLaMA, Qwen3, Gemma-3) across 5 languages using the KLAR dataset containing 1,742 facts across 9 relation types. They implement direct query templates where entities are explicitly named and contextual query templates using two-sentence structures with placeholder names and surrounding context. Synthetic names are generated via ChatGPT-5.2 and filtered through Infini-gram to ensure zero corpus occurrence. Evaluation uses 3-shot prompting, greedy decoding, and exact-match accuracy where predictions are correct if the gold answer appears as a prefix of the generated output. The key comparison measures the degradation in accuracy when moving from direct to contextual query formats.

## Key Results
- Contextual mediation consistently degrades factual recall across all languages and relations, with accuracy ranging from approximately 35-95% depending on relation and model size.
- Larger models exhibit greater robustness to contextual mediation, showing reduced performance gaps between direct and contextual queries.
- The influence of real names versus synthetic names is mixed and unsystematic, indicating that contextual cues rather than name surface forms primarily drive performance.
- Relations like native_language and capital are most sensitive to contextual mediation, while continent remains largely stable regardless of query format.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual mediation degrades factual recall because it introduces an additional referential resolution step before accessing stored facts.
- Mechanism: When entities are referenced indirectly through placeholder names and context, the model must resolve what entity is being referred to before accessing the factual association. This extra processing step competes for attention and introduces failure points not present in direct queries where the entity is explicitly named.
- Core assumption: Models have the factual knowledge stored; failures stem from retrieval pathway, not missing knowledge.
- Evidence anchors: Abstract finding of consistent degradation; section 4.2 showing lower accuracy for contextual queries; related work on LLM sensitivity to contextual information.

### Mechanism 2
- Claim: Larger model scale improves robustness to contextual mediation through stronger internal representations and redundant retrieval pathways.
- Mechanism: Increased parameters correlate with better entity/relation representations and more effective integration of contextual cues. Larger models may have redundant pathways for accessing the same factual knowledge, making retrieval less brittle when the access route changes.
- Core assumption: Scale improvements extend to context-dependent retrieval, not just isolated fact lookup.
- Evidence anchors: Abstract noting reduced performance gaps in larger models; section 4.2 showing scale benefits; Liu et al. (2025c) on knowledge acquisition correlating with pretraining exposure.

### Mechanism 3
- Claim: Name surface forms and linguistic origin have minimal systematic impact on contextually mediated factual recall; surrounding context dominates.
- Mechanism: When queries are embedded in naturalistic context, model attention prioritizes contextual framing over demographic or frequency-based signals encoded in names. Using synthetic names controls for name-specific associations, and absence of systematic differences between synthetic and real names suggests model doesn't rely heavily on name-based priors.
- Core assumption: Name-related biases don't override contextual processing demands.
- Evidence anchors: Abstract noting mixed effects of real vs synthetic names; section 5.2 showing context drives performance; Wei et al. (2024) and Manchanda & Shivaswamy (2025) documenting name biases in other contexts.

## Foundational Learning

- Concept: **Factual Knowledge Probing**
  - Why needed here: Understanding how models store and recall facts is baseline for interpreting contextual mediation effects.
  - Quick check question: Can you explain the difference between querying a fact directly ("What is the capital of France?") and through context ("After arriving in France, Alex goes to the political capital. Which city?")?

- Concept: **Referential Resolution in Context**
  - Why needed here: Core challenge in contextual mediation is resolving what entity a placeholder name refers to before accessing facts.
  - Quick check question: In the prompt "Alex is at border control checking Emmanuel Macron's documents. Which country of citizenship does Alex see?", what must the model resolve before answering?

- Concept: **Cross-Lingual Consistency**
  - Why needed here: Paper evaluates five languages; understanding how factual recall varies across languages is essential for interpreting results.
  - Quick check question: Why might a model recall a fact correctly in English but fail in Arabic even when the underlying fact is language-independent?

## Architecture Onboarding

- Component map:
  - KLAR Dataset -> Direct Query Templates -> Contextual Query Templates -> Synthetic Name Generator -> Evaluation Pipeline (vLLM + 3-shot prompting)

- Critical path:
  1. Select fact from KLAR dataset
  2. Generate direct query using language-specific template
  3. Generate contextual query by embedding entity in context sentence with synthetic/real name
  4. Run both queries through model with 3 in-context examples
  5. Compare exact-match accuracy to compute degradation

- Design tradeoffs:
  - **Synthetic vs Real Names**: Synthetic names control for pretraining exposure but may not reflect real-world distributions; real names are more naturalistic but introduce confounds
  - **Template Design**: Fixed templates enable controlled comparison but may not capture natural linguistic diversity
  - **Language Coverage**: Five typologically diverse languages provide breadth, but low-resource languages are underrepresented

- Failure signatures:
  - Relation-specific sensitivity: native_language, capital, headquarters_location show largest degradation
  - Family-specific scale effects: Qwen shows inconsistent scale benefits unlike LLaMA and Gemma
  - Contextual-mediation failures: Cases where direct query succeeds but contextual fails (Table 3); these isolate retrieval pathway issues

- First 3 experiments:
  1. Replicate direct vs contextual comparison on subset of 50 facts from 3 relations to validate degradation pattern
  2. Test whether increasing in-context examples (from 3 to 5 or 10) reduces contextual mediation gap
  3. Evaluate capital relation across all 5 languages with both synthetic and real names to verify unsystematic name effects

## Open Questions the Paper Calls Out

- What mechanisms explain why larger models exhibit greater robustness to contextual mediation, and why does this effect vary across model families (e.g., Qwen shows weaker scaling effects)?
- How does the candidate space size of different relation types systematically affect robustness to contextual mediation?
- How do closed-source commercial models perform under contextually mediated factual recall compared to open-source models evaluated?
- How do sociolinguistic factors such as name frequency and demographic variation influence contextually mediated factual recall?

## Limitations
- Limited set of 9 relation types and 5 languages may miss broader linguistic phenomena and naming pattern interactions.
- Exact-match accuracy with greedy decoding may underestimate performance by not accounting for semantically equivalent alternative answers.
- Synthetic name generation, while methodologically sound, may not fully capture real-world naming complexity and their interaction with model knowledge.
- KLAR dataset composition and specific selection criteria for the 1,742 facts are not fully disclosed, raising questions about potential sampling bias.

## Confidence

**High Confidence**: 
- Contextual mediation consistently degrades factual recall across all tested languages and relations
- Larger models show greater robustness to contextual mediation, particularly LLaMA and Gemma families
- Contextual cues dominate over name surface forms in driving performance

**Medium Confidence**:
- Family-specific scale effects, particularly inconsistent benefits in Qwen models
- Relation-specific sensitivity patterns (native_language, capital, headquarters_location being most affected)

**Low Confidence**:
- Minimal systematic impact of name surface forms and linguistic origin on contextually mediated factual recall (based on limited common names)
- Claim that surrounding context plays more dominant role than name surface forms (not definitively proven across all name distributions)

## Next Checks

1. **Dataset Diversity Validation**: Replicate evaluation using larger, more diverse factual knowledge dataset (e.g., WikiData subset) to verify observed patterns hold across different fact distributions and test whether KLAR dataset composition influenced results.

2. **Alternative Evaluation Protocol**: Implement fuzzy matching evaluation protocol that accounts for semantically equivalent answers and alternative surface forms to determine whether exact-match accuracy underestimates model performance, particularly for contextual queries where valid alternative expressions may be more common.

3. **Extended Name Set Analysis**: Systematically test broader range of names including rare names, names with different linguistic origins, and names with varying frequency distributions to determine whether observed lack of name effects holds across more diverse naming patterns and identify potential boundary conditions.