---
ver: rpa2
title: 'Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar
  Hand Gesture Recognition'
arxiv_id: '2506.22443'
source_url: https://arxiv.org/abs/2506.22443
tags:
- rule
- rl-net
- gesture
- interpretability
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work applies RL-Net, a neuro-symbolic model, to radar-based
  hand gesture recognition for the first time, bridging the gap between interpretability
  and performance. RL-Net learns interpretable rule lists through neural optimization,
  offering a "gray-box" alternative to fully transparent rule-based systems and black-box
  deep learning models.
---

# Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition

## Quick Facts
- **arXiv ID**: 2506.22443
- **Source URL**: https://arxiv.org/abs/2506.22443
- **Reference count**: 20
- **Primary result**: RL-Net achieves 93.03% F1 score on radar hand gesture recognition while maintaining interpretable rule sets

## Executive Summary
This work introduces RL-Net, a neurosymbolic model that bridges the interpretability-performance gap in radar-based hand gesture recognition. By learning interpretable rule lists through neural optimization, RL-Net offers a "gray-box" alternative that outperforms both fully transparent rule-based systems and black-box deep learning models. The method was validated on a 60 GHz FMCW radar dataset with 31,000 gesture samples across 12 users and five gesture classes, demonstrating strong performance while maintaining compact, interpretable rule sets suitable for personalized gesture sensing applications.

## Method Summary
RL-Net employs a neurosymbolic approach that combines neural network optimization with rule-based output generation. The model learns interpretable rule lists by optimizing neural parameters that govern rule selection and hierarchy. This "gray-box" architecture maintains the performance benefits of deep learning while producing human-readable rules. The system was trained and evaluated on radar micro-Doppler signatures from a 60 GHz FMCW radar, with transfer learning capabilities enabling personalized adaptation across different users.

## Key Results
- Achieved 93.03% F1 score on radar hand gesture recognition task
- Outperformed transparent MIRA model (79.7% F1) while maintaining interpretability
- Surpassed XentricAI GRU model (90.2% F1) after transfer learning for personalized adaptation

## Why This Works (Mechanism)
RL-Net's effectiveness stems from its neurosymbolic architecture that leverages neural networks for optimization while preserving rule-based interpretability. The neural optimization process learns optimal rule hierarchies and selection criteria, allowing the model to capture complex patterns in radar micro-Doppler signatures while maintaining human-readable output. This approach combines the pattern recognition capabilities of deep learning with the transparency of rule-based systems, enabling both high performance and interpretability in gesture recognition tasks.

## Foundational Learning
1. **Radar Micro-Doppler Signatures**: Time-frequency representations of moving objects captured by FMCW radar, essential for understanding how gesture movements translate to radar signals
   - Why needed: Provides the fundamental input representation for gesture recognition
   - Quick check: Verify understanding of spectrogram generation from radar data

2. **Neurosymbolic AI**: Hybrid AI approach combining neural networks with symbolic reasoning/rule systems
   - Why needed: Enables both high-performance pattern recognition and interpretable output
   - Quick check: Confirm understanding of how neural optimization drives rule learning

3. **Transfer Learning**: Technique for adapting pre-trained models to new users or domains with limited data
   - Why needed: Critical for personalized gesture recognition across different users
   - Quick check: Validate understanding of how model parameters are fine-tuned for individual users

## Architecture Onboarding

**Component Map**: Input features -> Neural Rule Optimizer -> Rule Selection Layer -> Interpretable Rule List -> Classification Output

**Critical Path**: Radar micro-Doppler input → Feature extraction → Neural rule optimization → Rule hierarchy learning → Gesture classification

**Design Tradeoffs**: Performance vs. interpretability balance, training stability vs. rule complexity, generalization vs. personalization capability

**Failure Signatures**: Training instability indicating hyperparameter sensitivity, rule set explosion suggesting overfitting, performance degradation during transfer learning

**First Experiments**:
1. Train RL-Net on full dataset to establish baseline performance metrics
2. Evaluate rule interpretability by manually inspecting learned rule sets
3. Test transfer learning capability with limited user-specific data

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the generalizability of RL-Net across different radar frequencies and gesture vocabularies. The current validation was limited to a single 60 GHz FMCW radar dataset with five gesture classes, raising questions about performance consistency with other sensor configurations or more complex gesture sets. Training stability issues reported in the study suggest potential sensitivity to hyperparameter selection, which could impact reproducibility across different experimental setups.

## Limitations
- Performance generalizability across different radar frequencies remains untested
- Limited validation to only five gesture classes may not reflect real-world complexity
- Training stability issues suggest potential sensitivity to hyperparameter selection

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Interpretability of learned rules | High |
| Benchmark performance claims | Medium |
| Personalized adaptation effectiveness | Medium |

## Next Checks
1. Test RL-Net on multiple radar datasets operating at different frequencies (sub-60 GHz) and with varying numbers of gesture classes to assess generalizability
2. Conduct ablation studies to identify which components of the neural optimization process contribute most to performance stability and rule interpretability
3. Perform cross-user validation with limited training data per user to quantify the trade-off between personalization effectiveness and data efficiency