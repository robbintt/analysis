---
ver: rpa2
title: 'Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware
  Dawid-Skene for Multi-Label Tasks in Autonomous Driving'
arxiv_id: '2510.01126'
source_url: https://arxiv.org/abs/2510.01126
tags:
- driving
- language
- arxiv
- large
- vlms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a game-theoretic fusion method for multi-label
  understanding of ego-view dashcam video in autonomous driving. The method, Shapley-credited
  Context-Aware Dawid-Skene with Agreement, learns per-model, per-label, context-conditioned
  reliabilities from historical data and aggregates model reports using agreement-weighted
  log-likelihood ratios, contextual priors, and a public reputation state updated
  via Shapley-based team credit.
---

# Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving

## Quick Facts
- **arXiv ID**: 2510.01126
- **Source URL**: https://arxiv.org/abs/2510.01126
- **Reference count**: 40
- **Primary result**: 47-55% improvement in F1 scores over single VLMs and state-of-the-art baselines on ego-view dashcam video understanding

## Executive Summary
This study presents a game-theoretic fusion method for multi-label understanding of ego-view dashcam video in autonomous driving. The method, Shapley-credited Context-Aware Dawid-Skene with Agreement, learns per-model, per-label, context-conditioned reliabilities from historical data and aggregates model reports using agreement-weighted log-likelihood ratios, contextual priors, and a public reputation state updated via Shapley-based team credit. To enable task specialization, 1,000 real-world dashcam clips with structured annotations (scene description, manoeuvre recommendation, rationale) were curated through an automatic pipeline that fuses HDD ground truth, vehicle kinematics, and YOLOv11 + BoT-SORT tracking, guided by a three-step chain-of-thought prompt. Three heterogeneous VLMs were fine-tuned with LoRA. Empirically, the fusion achieved 3.4× improvement over single VLM baselines and 2.2× over vanilla Dawid-Skene fusion.

## Method Summary
The framework fuses outputs from three heterogeneous VLMs (VLAAD, VideoLLaMA2, VideoLLaVA) fine-tuned with LoRA on structured dashcam annotations. A LLaMA-3.2 prompt maps free-form VLM text to a 14-label ontology. The fusion engine computes context-conditioned reliabilities using kernel-weighted Beta-Bernoulli pooling on CLIP embeddings of nearest historical neighbors, applies agreement-weighted log-likelihood ratios with correlation guardrails, and updates model reputations via Shapley marginal contributions. The system achieves Hamming distance reduction of 23% and 47-55% improvement in F1 scores over baselines.

## Key Results
- 3.4× improvement over single VLM baselines
- 2.2× improvement over vanilla Dawid-Skene fusion
- 23% reduction in Hamming distance compared to state-of-the-art fusion methods

## Why This Works (Mechanism)

### Mechanism 1: Context-Conditioned Reliability Estimation
The system maps input video frames to CLIP embedding space and identifies K nearest neighbors from historical labeled rounds. Using Beta-Bernoulli pooling, it calculates posterior reliability estimates for each model and label specific to that neighborhood. This allows the aggregator to weight model outputs based on their competence in similar visual contexts, mitigating hallucinations in novel scenarios.

### Mechanism 2: Shapley-Credited Reputation Dynamics
The framework models aggregation as a repeated forecasting game, calculating Shapley values to measure the marginal contribution of adding a model to a coalition. This drives a public reputation vector via exponential weight updates, suppressing consistently low-value contributors and rewarding models that uniquely solve difficult cases.

### Mechanism 3: Agreement-Guardrailed Log-Likelihoods
Each model's report is converted to a Log-Likelihood Ratio (LLR), then adjusted based on pairwise error correlations from recent windows. If models tend to make the same mistakes together, their agreeing signals are shrunk to prevent double-counting correlated errors.

## Foundational Learning

- **Dawid-Skene Model (Probabilistic Truth Serum)**: Understanding how to invert "noisy reports" into "latent truth" using confusion matrices (sensitivity/specificity) is essential for understanding the paper's reliability estimation. *Quick check*: If a model has high sensitivity but low specificity for a label, how does that affect the posterior probability when it reports "Yes"?

- **Shapley Values (Coalitional Game Theory)**: The "reputation" of VLMs is based on their marginal contribution to a coalition, not average accuracy. *Quick check*: In a 3-model system, if Models A and B always vote "Yes" and Model C flips a coin, what is the marginal contribution of Model A to the coalition {B, C}?

- **Beta-Bernoulli Conjugate Priors**: The paper uses Beta-Bernoulli pooling to smooth reliability estimates. *Quick check*: Why is a conjugate prior (Beta) preferred over a point estimate when dealing with sparse historical data in specific contexts?

## Architecture Onboarding

- **Component map**: Dashcam Video -> 3 VLMs (VLAAD, VideoLLaMA2, VideoLLaVA) -> LLaMA-3.2 label mapper -> Fusion Engine (Memory Bank + Reliability Module + Aggregator) -> Calibrated probabilities per label

- **Critical path**: The interaction between the Reliability Module and the Aggregator. If context retrieval (CLIP) fails to find relevant neighbors, reliability estimates default to priors, and the system loses adaptability.

- **Design tradeoffs**: The system runs 3 large VLMs in parallel, requiring significant GPU memory (2x A6000 used) and inference latency. The Shapley update relies on learning rate η and window size, where too high η causes reputation volatility and too small prevents adaptation to drift.

- **Failure signatures**: "Herding" Collapse if all VLMs are fine-tuned on the same biased data, potentially overwhelming the correlation guardrail. Cold Start issues in initial rounds or novel contexts where kernel-weighted reliabilities have high variance.

- **First 3 experiments**:
  1. **Sanity Check (Static Weights)**: Run fusion with fixed uniform weights w = [0.33, 0.33, 0.33] to verify dynamic Shapley updates drive performance gains
  2. **Context Ablation**: Replace CLIP-embedding neighbor search with global average reliability to verify "Context-Aware" contribution
  3. **Correlation Stress Test**: Manually inject correlated errors into two models for a specific label to verify correlation guardrail effectiveness

## Open Questions the Paper Calls Out

1. **Distribution Shift Performance**: How does the framework perform under significant distribution shift (night, rain, unfamiliar geographic regions) compared to HDD training distribution? The conclusion identifies this as a key limitation requiring evaluation on held-out datasets with adverse conditions.

2. **Scalability to Larger Ensembles**: Can the Shapley-credited reputation mechanism scale computationally and maintain performance gains when extended beyond three VLMs to larger ensembles? The conclusion states this is planned future work, noting current design choices may constrain performance in complex scenarios.

3. **Error Correlation Robustness**: How robust is the framework when model errors are strongly correlated rather than largely independent? The paper assumes largely independent reports but doesn't evaluate scenarios with high, structured error correlation across models.

4. **Unlabeled Sequence Performance**: Can the framework maintain calibrated performance during extended unlabeled sequences where ground truth is unavailable for reputation and reliability updates? The conclusion identifies reliance on regular ground-truth labels as a limitation.

## Limitations
- Relies heavily on historical data, which may not generalize to novel driving scenarios or domain shifts
- Automatic annotation pipeline introduces potential cascading errors from perception components
- Requires maintaining memory bank of historical data, creating storage and computational overhead
- Limited evaluation to single dataset (Honda HRI Driving Dataset) without systematic stress-testing across adverse conditions

## Confidence

**High Confidence**:
- Architectural framework combining VLM outputs with context-aware reliability estimation and game-theoretic reputation updates is technically sound
- Ablation results showing performance gains from individual components are internally consistent

**Medium Confidence**:
- 3.4× improvement over baselines is statistically significant within evaluated dataset
- 2.2× improvement over vanilla Dawid-Skene fusion is valid for specific ontology and dataset

**Low Confidence**:
- Generalizability to other driving datasets and real-world conditions
- Robustness to concept drift and changing error correlation patterns
- Practical deployment feasibility given computational requirements

## Next Checks

1. **Domain Transfer Validation**: Evaluate the system on a different autonomous driving dataset (nuScenes, Waymo Open Dataset) without retraining VLM models. Measure performance degradation and identify whether context-aware reliability estimation degrades gracefully across domains.

2. **Concept Drift Simulation**: Create synthetic test cases where error correlations shift systematically over time. Monitor whether Shapley reputation mechanism adapts appropriately or whether reputation updates become unstable.

3. **Real-time Performance Validation**: Deploy the system on hardware representative of actual autonomous vehicles (targeting inference times <100ms per frame). Measure end-to-end latency, GPU memory utilization, and verify real-time performance while processing 30fps video streams.