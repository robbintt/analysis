---
ver: rpa2
title: Training-Free Generation of Diverse and High-Fidelity Images via Prompt Semantic
  Space Optimization
arxiv_id: '2511.19811'
source_url: https://arxiv.org/abs/2511.19811
tags:
- diversity
- prompt
- diffusion
- image
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of low diversity in text-to-image
  diffusion models, which often generate repetitive outputs due to mode collapse.
  The authors propose Token-Prompt Space Optimization (TPSO), a training-free and
  model-agnostic method that introduces learnable offsets in the token embedding space
  to explore underrepresented regions, while using a prompt-level semantic constraint
  to maintain fidelity.
---

# Training-Free Generation of Diverse and High-Fidelity Images via Prompt Semantic Space Optimization

## Quick Facts
- **arXiv ID:** 2511.19811
- **Source URL:** https://arxiv.org/abs/2511.19811
- **Reference count:** 27
- **Primary result:** TPSO achieves Recall 0.618, MSS 0.158, Vendi 6.705, FID 18.191 vs baseline (0.542, 0.231, 5.558, 20.093)

## Executive Summary
This paper addresses mode collapse in text-to-image diffusion models by introducing Token-Prompt Space Optimization (TPSO), a training-free method that enhances diversity while maintaining fidelity. TPSO learns token-level offsets to explore underrepresented embedding regions, constrained by prompt-level semantic alignment to prevent quality degradation. The method demonstrates substantial improvements across multiple diversity and quality metrics on MS-COCO using SD1.5, SD2.1, and SD3.5 models.

## Method Summary
TPSO optimizes learnable token offsets in CLIP's text encoder to generate variant prompt embeddings that steer diffusion sampling along diverse trajectories. The method uses a semantic alignment loss to keep variants close to the original prompt (cosine similarity ≥ 0.80) while maximizing pairwise diversity among variants. A progressive scheduler injects optimized embeddings during early denoising steps (r ∈ [0.3, 0.5]), then linearly interpolates back to original embeddings for refinement. This training-free approach operates entirely at inference time through iterative optimization of N variants per prompt.

## Key Results
- **Diversity gains:** Recall improves from 0.542 to 0.618; MSS drops from 0.231 to 0.158; Vendi rises from 5.558 to 6.705
- **Quality preservation:** FID slightly improves from 20.093 to 18.191; CLIP score maintained at 31.700 vs baseline 31.660
- **Cross-model consistency:** Similar gains achieved across SD1.5, SD2.1 (DDPM), and SD3.5 (rectified flow) architectures

## Why This Works (Mechanism)

### Mechanism 1: Token-Level Offset Exploration
- **Claim:** Learnable token-level offsets enable escape from dominant modes in the learned distribution.
- **Mechanism:** The method adds learnable parameters ε to fixed token embeddings (e_token + ε), which are optimized to produce variant prompt embeddings v' = f(E(e_token + ε)). These variants induce different CFG guidance directions d_c^(k), steering the diffusion process along alternative latent trajectories that explore underrepresented regions of the embedding space.
- **Core assumption:** The token embedding space contains semantically valid but underutilized regions that correspond to plausible visual variations not frequently sampled by the base model.
- **Evidence anchors:** [abstract] "TPSO introduces learnable parameters to explore underrepresented regions of the token embedding space, reducing the tendency of the model to repeatedly generate samples from strong modes"; [section 4.1, Eq. 5-6] Defines variant token embeddings and their mapping to prompt-level embeddings; [corpus] "OSCAR" paper similarly addresses diversity in flow-based models through orthogonal stochastic control, suggesting mode collapse is a recognized problem across architectures.
- **Break condition:** If token offsets grow too large or optimization diverges, semantic consistency breaks (see Figure 2b showing semantic drift between "cat" and "lion").

### Mechanism 2: Prompt-Level Semantic Constraints
- **Claim:** Prompt-level semantic constraints prevent distribution shift while allowing diversity exploration.
- **Mechanism:** A semantic alignment loss L_semantic constrains cosine similarity between original (v) and variant (v') prompt embeddings to remain within a tolerance band around threshold κ (e.g., 0.80 ± 0.01). This creates a "semantic consistency surface" that bounds exploration to meaning-preserving regions.
- **Core assumption:** CLIP prompt embedding space is structured such that cosine similarity correlates with semantic preservation, and a fixed threshold can reliably separate valid from invalid variations.
- **Evidence anchors:** [abstract] "prompt-level space provides a global semantic constraint that regulates distribution shifts, preventing quality degradation"; [section 4.2, Eq. 7] Explicit formulation of semantic alignment loss with κ threshold; [corpus] No direct corpus validation of cosine-similarity-based semantic constraints; assumption remains unverified in related work.
- **Break condition:** If κ is set too low (e.g., 0.70), CLIP scores drop substantially (30.610 vs baseline 31.700); if too high (0.90), diversity gains collapse (Vendi: 5.201 vs 7.559 at κ=0.70).

### Mechanism 3: Progressive Embedding Scheduling
- **Claim:** Progressive embedding scheduling balances diversity injection (early denoising) with fidelity preservation (late refinement).
- **Mechanism:** The scheduler applies optimized embeddings only during early timesteps (t > T(1-r)), with linear interpolation back to original embeddings. This exploits diffusion's coarse-to-fine structure: early steps determine global structure (where diversity matters), late steps refine texture (where original embeddings preserve quality).
- **Core assumption:** Diffusion sampling exhibits a coarse-to-fine property where semantic content is determined early and fine details are refined later; this property holds across SD1.5, SD2.1 (DDPM-based) and SD3.5 (rectified flow).
- **Evidence anchors:** [section 4.3, Eq. 10-11] Defines α_t scheduling with ratio parameter r; [Table 3] Negative r (-0.4) causes severe quality degradation (FID: 63.527) with minimal diversity gain, validating early-stage injection hypothesis; [corpus] No corpus papers explicitly validate coarse-to-fine diffusion properties; assumption relies on conventional wisdom.
- **Break condition:** Late-stage injection (r < 0) produces minimal diversity gains and noticeable quality degradation.

## Foundational Learning

- **Concept: CLIP Text Encoder Architecture (Token vs Prompt Embeddings)**
  - **Why needed here:** TPSO operates at two levels: token embeddings (fixed per vocabulary entry, e_n = M[i_n]) and prompt embeddings (contextualized via transformer E). Understanding this distinction is essential for grasping where learnable offsets are applied.
  - **Quick check question:** Given tokens ["a", "cute", "cat"], which level produces the same embedding for "cat" regardless of context, and which level produces different embeddings for "cat" in "a cute cat" vs "the cat slept"?

- **Concept: Classifier-Free Guidance (CFG) Direction**
  - **Why needed here:** TPSO's core insight is that mode collapse stems from CFG direction d_c being anchored to a single prompt embedding. Diversifying the source of d_c enables diverse generation.
  - **Quick check question:** In the CFG formula ε̂_θ(x_t, c) = ε_θ(x_t, ∅) + ω(ε_θ(x_t, c) - ε_θ(x_t, ∅)), what does the term in parentheses represent, and how does TPSO modify it?

- **Concept: Mode Collapse in Conditional Generation**
  - **Why needed here:** The paper frames diversity as an explicit counter to mode collapse. Without this conceptual grounding, the optimization objectives appear unmotivated.
  - **Quick check question:** Why does noise resampling fail to address mode collapse, according to the authors' hypothesis about strong modes in learned distributions?

## Architecture Onboarding

- **Component map:** Input Prompt → Tokenizer → {i_1, ..., i_N} → CLIP Token Encoder (frozen) → e_token = {e_1, ..., e_N} → + Learnable Offsets ε (initialized N(0, 10^-4)) → Variant Token Embeddings (e_token + ε) → CLIP Prompt Encoder E → CLIP Projector f → v' → Optimization Loop (Algorithm 1): Compute L_semantic (cosine similarity to original v), Compute L_div (pairwise diversity among N variants), Update ε via Adam on L_joint → Progressive Scheduler (ratio r) → Scheduled embedding y*_t → Diffusion Model → Generated Image

- **Critical path:** Token offset initialization → semantic convergence check → scheduled injection during sampling. The optimization loop (Algorithm 1) is the only non-standard component; everything else reuses existing pipeline components.

- **Design tradeoffs:**
  - **κ (semantic retention):** Lower = more diversity, lower CLIP score. Paper recommends 0.80 as balance point.
  - **λ (diversity weight):** Higher = more intra-prompt variation, gradual CLIP decline. Tested range: 0-10.
  - **r (schedule ratio):** Higher = more timesteps with optimized embeddings. Recommended [0.3, 0.5]. Negative values break the mechanism.
  - **N (number of variants):** More variants = more diverse outputs per prompt, but linear increase in optimization compute.

- **Failure signatures:**
  - **Semantic drift:** Generated images mix characteristics (e.g., cat-lion hybrids) → κ too low or optimization unconstrained.
  - **No diversity gain:** Outputs remain repetitive → r too small, λ too low, or optimization not converging.
  - **Quality degradation:** Artifacts or blurring → r too high (injection into refinement stages) or offsets too large.
  - **Optimization divergence:** L_semantic never converges → learning rate too high or initialization variance too large.

- **First 3 experiments:**
  1. **Baseline comparison on single prompt:** Run SD1.5 with 10 different seeds vs TPSO with N=10 variants. Compute pairwise MSS between outputs. Expect: baseline MSS ~0.23, TPSO MSS ~0.16.
  2. **κ sensitivity sweep:** Fix λ=5.0, r=0.4, vary κ ∈ {0.70, 0.75, 0.80, 0.85, 0.90} on 1k captions. Plot CLIP score vs Vendi score tradeoff curve. Expect: inverse relationship, optimal around κ=0.80.
  3. **Schedule ablation (r values):** Compare r ∈ {-0.4, 0.2, 0.4, 0.6} on FID and Recall. Expect: r=-0.4 catastrophically fails (FID >60), r=0.4-0.6 provides best diversity-quality balance.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the limitations section, several implicit questions emerge:

1. **Computational Efficiency:** The optimization overhead for learning offsets is not analyzed, leaving questions about real-time applicability and whether optimization can be accelerated or made adaptive.

2. **Semantic Interpretability:** While Figure 2b shows smooth transitions between "cat" and "lion" embeddings, the paper doesn't analyze whether discovered directions correspond to meaningful visual attributes (style, pose, lighting) or remain uninterpretable.

3. **Prompt-Dependent Hyperparameters:** The paper uses uniform settings (κ=0.80, λ=5.0, r=0.4) across all prompts without investigating whether simpler or more abstract prompts require different constraint levels.

4. **Edge Case Behavior:** The method is evaluated on common objects and scenes, but its performance on abstract concepts, rare entities, or highly specific compositions where dominant modes may be weak or absent remains unexplored.

## Limitations

- **Semantic consistency assumption:** The method relies on cosine similarity in CLIP embedding space to ensure semantic preservation, but this assumption lacks corpus validation and may not generalize across prompt types or languages.
- **Diffusion-specific mechanism:** The progressive scheduling approach assumes diffusion's coarse-to-fine property transfers across architectures (DDPM vs rectified flow), but theoretical justification for this transfer is absent.
- **Optimization overhead:** The paper doesn't analyze computational cost or latency, leaving questions about real-time applicability and whether optimization steps can be reduced.

## Confidence

**High confidence:** The diversity quality tradeoff demonstrated through controlled experiments (κ and r sweeps) appears robust. The empirical results showing improvements across multiple metrics (Recall, Vendi, MSS, FID) with different diffusion models are convincing.

**Medium confidence:** The mechanism for how token offsets escape strong modes is plausible but not definitively proven. The paper shows this works empirically but doesn't provide theoretical analysis of the embedding space geometry or why specific offset magnitudes (N(0, 10^-4)) are optimal.

**Low confidence:** The semantic alignment assumption lacks corpus validation. While the paper demonstrates effectiveness with κ=0.80, there's no evidence this threshold generalizes across different prompt types, languages, or CLIP model versions.

## Next Checks

1. **Semantic Robustness Test:** Conduct human evaluation comparing outputs from TPSO with κ=0.70, 0.80, 0.90 on 100 diverse prompts (different domains, complexity levels). Measure semantic preservation rates and correlate with CLIP cosine similarity to validate the semantic consistency assumption.

2. **Cross-Architecture Transfer:** Apply TPSO to non-Diffusion models (e.g., GANs or flow-based models) and measure whether the progressive scheduling mechanism provides similar benefits. This would test whether the method relies on diffusion-specific properties or generalizes to broader conditional generation.

3. **Embedding Space Analysis:** Perform systematic analysis of the token embedding space to identify whether underutilized regions truly correspond to semantically valid variations. Use nearest-neighbor analysis and interpolation paths to characterize the embedding manifold structure that TPSO exploits.