---
ver: rpa2
title: 'AI PB: A Grounded Generative Agent for Personalized Investment Insights'
arxiv_id: '2510.20099'
source_url: https://arxiv.org/abs/2510.20099
tags:
- system
- component
- data
- retrieval
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AI PB is a production-scale, on-premises generative agent for retail
  finance that proactively delivers personalized, grounded investment insights. It
  uses deterministic routing between internal and external models based on data sensitivity,
  hybrid retrieval combining sparse and dense search with domain-specific embeddings,
  and a multi-layer recommendation engine.
---

# AI PB: A Grounded Generative Agent for Personalized Investment Insights

## Quick Facts
- arXiv ID: 2510.20099
- Source URL: https://arxiv.org/abs/2510.20099
- Reference count: 2
- Primary result: On-premises generative agent achieving 91.2% factuality, 98.4% safety, and 18% engagement lift in retail finance

## Executive Summary
AI PB is a production-scale, on-premises generative agent for retail finance that proactively delivers personalized, grounded investment insights. It uses deterministic routing between internal and external models based on data sensitivity, hybrid retrieval combining sparse and dense search with domain-specific embeddings, and a multi-layer recommendation engine. Guard-based safety filtering ensures compliance, with 98.4% safety score in human QA. Over 300 QA-reviewed responses showed 91.2% factuality and 85.7% alignment. A/B testing increased feed engagement by 18% and reduced repetitive content by 23%. The system serves tens of thousands of daily events while maintaining full auditability and regulatory compliance.

## Method Summary
AI PB employs a deterministic orchestrator that routes requests to 20 components based on intent classification and PII sensitivity. Components interface with 48 enterprise modules connecting to AltiBase, Oracle, PostgreSQL, OpenSearch, and legacy TR systems. A hybrid retriever combines sparse (OpenSearch) and dense (NMIXX financial embeddings) search, with evidence templates serialized into responses. The Qwen3-32B model with LoRA+ORPO alignment generates grounded responses, validated by a post-generation citation checker. Shinhan-Guard (Llama Guard 3 fine-tuned) filters all I/O for safety. A three-layer recommender (rules + sequential modeling + contextual bandits) ranks proactive insights in the "Today Feed."

## Key Results
- Factuality: 91.2% across 300+ human-reviewed responses
- Safety: 98.4% safety score in human QA evaluation
- Performance: p95 latency 13.9s; guard rejection <2%; feed engagement +18%; repetitive content -23%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deterministic component-level routing prevents PII egress and enables regulatory compliance.
- Mechanism: The orchestrator identifies components by predefined metadata (not runtime prompt inspection). Components tagged as PII-linked route exclusively to internal models; non-PII components may use external models (e.g., GPT-4o). This creates a static, auditable boundary.
- Core assumption: Component metadata accurately reflects data sensitivity, and no PII leaks through non-PII-tagged paths.
- Evidence anchors:
  - [abstract] "deterministically routes between internal and external LLMs based on data sensitivity"
  - [section 4] "Routing is handled by a deterministic policy rather than run-time prompt inspection... If the component accesses any PII-linked source, generation occurs via the internal model path."
  - [corpus] FinVault (arxiv 2601.07853) discusses financial agent safety in execution-grounded environments, reinforcing that explicit routing boundaries matter, though does not validate this specific approach.
- Break condition: If component tagging is incomplete or PII appears in unexpected modules (e.g., logs, embeddings), the routing guarantee fails.

### Mechanism 2
- Claim: Hybrid retrieval with domain-specific embeddings and post-generation validation reduces hallucinations.
- Mechanism: Sparse retrieval (OpenSearch) handles symbolic keyword matching; dense retrieval (NMIXX, finance-specialized) captures semantic relevance. Retrieved passages are serialized into evidence templates. A post-generation validator requires each statement to contain at least one reference token.
- Core assumption: The evidence templates cover the necessary factual ground, and reference-token presence correlates with actual factuality.
- Evidence anchors:
  - [abstract] "hybrid retrieval combining sparse and dense search with domain-specific embeddings"
  - [section 5] "This approach reduces hallucination by over 30% relative to vanilla prompting in internal tests."
  - [corpus] Mala, Gezici, and Giannotti (2025) is cited on hybrid retrieval for hallucination mitigation; no independent validation of the 30% claim in corpus.
- Break condition: If retrieval indices are stale (>15 min refresh) or NMIXX misinterprets temporal/financial semantics, grounding degrades.

### Mechanism 3
- Claim: A three-layer recommender (rules + sequential modeling + contextual bandits) improves engagement and reduces content repetition.
- Mechanism: Rule-based layer enforces domain logic (owned tickers, time-decay). Sequential model (BERT4Rec-style) predicts next interest from interaction sequences. Contextual bandit layer adjusts rankings in real-time using click/dwell signals, with a limited trust budget to balance exploration and reliability.
- Core assumption: User intent is reasonably captured by recent sequences, and click/dwell signals proxy relevance.
- Evidence anchors:
  - [abstract] "A/B testing increased feed engagement by 18% and reduced repetitive content by 23%"
  - [section 6] "In A/B testing, this hybrid approach increased daily feed engagement by 18% and reduced repetitive content by 23% compared with rule-based baselines."
  - [corpus] Li et al. (2010) on contextual bandits for news recommendation is cited; supports plausibility but not financial-domain validation.
- Break condition: If exploration budget is too aggressive, users see irrelevant insights; if too conservative, personalization stagnates.

## Foundational Learning

- Concept: Hybrid Retrieval (Sparse + Dense)
  - Why needed here: The system anchors every generation to retrieved evidence; understanding BM25 (sparse) vs. embedding-based (dense) tradeoffs is essential for debugging grounding failures.
  - Quick check question: Can you explain why a query like "Samsung Electronics Q3 2025 operating profit" might need both keyword matching and semantic expansion?

- Concept: Contextual Multi-Armed Bandits
  - Why needed here: The recommendation layer uses bandits for real-time ranking adjustments; engineers must understand exploration-exploitation tradeoffs to tune the trust budget.
  - Quick check question: What happens if the exploration rate is set too high in a low-noise environment like financial insights?

- Concept: Guard Models (Safety Classifiers)
  - Why needed here: Shinhan-Guard filters all I/O; understanding fine-tuned Llama Guard 3 behavior helps diagnose false positives/negatives in compliance scenarios.
  - Quick check question: If the guard rejects 15% of queries instead of <2%, what are the first three things you would check?

## Architecture Onboarding

- Component map:
  - User query → Orchestrator → Component (20) → Modules (48) → Data sources (AltiBase, Oracle, PostgreSQL, OpenSearch, TR)
  - Evidence templates ← Hybrid Retriever (OpenSearch + NMIXX)
  - Qwen3-32B (ORPO) → Post-generation validator → Shinhan-Guard → Response
  - Feed items ← Rule-based → Sequential RS → Contextual bandit → "Today Feed"

- Critical path:
  1. User query → Orchestrator identifies component → checks PII flag.
  2. If PII: internal model path; else: may route externally.
  3. Query → Hybrid retrieval → evidence templates.
  4. Generator (Qwen3-32B ORPO) produces grounded response.
  5. Post-generation validator checks reference tokens.
  6. Shinhan-Guard filters output; if rejected, fallback to safe templates.
  7. For proactive insights: pre-generated items ranked by three-layer recommender → pushed to "Today Feed."

- Design tradeoffs:
  - Latency vs. factuality: Extensive retrieval improves grounding but increases latency; pre-generation amortizes this for the feed.
  - Internal vs. external models: Internal (Qwen3-32B) ensures zero PII egress but may lag behind frontier models in fluency; external used only for non-PII stylistic tasks.
  - Exploration vs. reliability in bandits: Limited trust budget prevents erratic rankings but may slow adaptation to new user interests.

- Failure signatures:
  - High guard rejection (>2%): Likely overly broad guard thresholds or novel prompt patterns; check Shinhan-Guard F1 on recent queries.
  - Missing citations in output: Retrieval index may be stale or NMIXX embeddings misaligned; check refresh interval and embedding drift.
  - Repetitive feed content: Rule-based layer may not be down-weighting read items correctly; verify time-decay and deduplication logic.

- First 3 experiments:
  1. **Ablate the retrieval path**: Disable dense retrieval (NMIXX) and measure hallucination rate on a held-out set of 100 queries; compare to hybrid baseline.
  2. **Stress-test the guard**: Inject adversarial prompts (toxicity, PII leakage, prompt injection) and measure Shinhan-Guard F1; identify failure modes.
  3. **Tune the bandit exploration budget**: Run a controlled A/B test with 1.5× and 0.5× current exploration rates; track engagement and complaint rates over two weeks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the grounding-versus-latency trade-off be optimized dynamically based on query complexity and real-time system load?
- Basis in paper: [explicit] Authors state: "Extensive retrieval improves factuality but increases latency; proactive pre-generation amortizes this cost" but offer no adaptive solution.
- Why unresolved: The current design uses static pre-generation for efficiency; no mechanism adapts retrieval depth or latency targets per query type.
- What evidence would resolve it: Experiments varying retrieval depth and measuring latency-factuality curves under load, ideally with a learned routing policy.

### Open Question 2
- Question: How should the three recommendation layers (rule-based, sequential, contextual bandit) be weighted or combined optimally for different user segments?
- Basis in paper: [inferred] The hybrid recommender reports +18% engagement and -23% repetition, but the paper provides no ablation or learned weighting across layers.
- Why unresolved: It is unclear whether gains come from rules, sequential modeling, bandits, or their interaction, nor how to tune per-segment.
- What evidence would resolve it: Ablation studies isolating each layer and optimization of layer weights per cohort, with segment-wise engagement metrics.

### Open Question 3
- Question: Can the deterministic, PII-driven routing policy generalize across jurisdictions with different data-residency and privacy regimes?
- Basis in paper: [inferred] The system is designed under Korean financial regulations; routing is hard-coded to PII-linked sources. Cross-border applicability is unstated.
- Why unresolved: Other regimes may define sensitivity differently or allow controlled external processing, requiring policy adaptation rather than wholesale reuse.
- What evidence would resolve it: Simulation or pilot deployment under alternate regulatory schemas with revised routing metadata and safety evaluation.

## Limitations
- The 30% hallucination reduction claim lacks independent validation and relies on internal benchmarks.
- Safety guard's 98.4% score depends on proprietary evaluation protocols not publicly disclosed.
- Routing policy assumes perfect component tagging, which may not hold in practice.

## Confidence
- **High Confidence**: Core architectural claims (hybrid retrieval, deterministic routing, three-layer recommender) are technically sound and align with established practices in retrieval-augmented generation and recommendation systems.
- **Medium Confidence**: Performance metrics (latency, engagement gains) are plausible given the described infrastructure but rely on internal benchmarks that cannot be independently verified.
- **Low Confidence**: The 30% hallucination reduction and safety guard's 98.4% score require external validation; the lack of transparency around evaluation protocols and proprietary components makes these claims difficult to assess.

## Next Checks
1. **Hallucination Ablation Study**: Disable dense retrieval (NMIXX) and measure hallucination rate on a held-out set of 100 queries; compare to hybrid baseline to verify the claimed 30% reduction.
2. **Guard Robustness Test**: Inject adversarial prompts (toxicity, PII leakage, prompt injection) and measure Shinhan-Guard F1; identify failure modes and false-positive rates.
3. **Bandit Exploration Sensitivity**: Run a controlled A/B test with 1.5× and 0.5× current exploration rates; track engagement and complaint rates over two weeks to assess the robustness of the 18% engagement gain claim.