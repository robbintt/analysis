---
ver: rpa2
title: 'Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models'
arxiv_id: '2511.09682'
source_url: https://arxiv.org/abs/2511.09682
tags:
- reasoning
- audio
- safety
- arxiv
- jailbreak
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the safety of audio reasoning models (ARMs)
  against jailbreak attacks, which aim to elicit harmful responses from target models.
  The authors propose Rebellion, a novel reasoning training method that trains ARMs
  to be robust to worst-case representation drift induced by audio jailbreaks.
---

# Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models

## Quick Facts
- **arXiv ID:** 2511.09682
- **Source URL:** https://arxiv.org/abs/2511.09682
- **Reference count:** 0
- **Primary result:** Novel reasoning training method that protects audio reasoning models against jailbreak attacks while maintaining benign task performance

## Executive Summary
This paper addresses the safety of audio reasoning models (ARMs) against jailbreak attacks, which aim to elicit harmful responses from target models. The authors propose Rebellion, a novel reasoning training method that trains ARMs to be robust to worst-case representation drift induced by audio jailbreaks. Rebellion achieves this by optimizing a loss function that minimizes safety loss under the impact of worst-case representation drift and benign reasoning loss. The results demonstrate that Rebellion can protect against advanced audio jailbreak without compromising performance on benign tasks. Specifically, Rebellion reduces harmful scores on Rephrasing and Advwave by 50.56% and 25% absolute, respectively, while maintaining the same level of benign accuracy.

## Method Summary
Rebellion is a reasoning training method designed to enhance the safety of audio reasoning models against jailbreak attacks. The approach optimizes a loss function that simultaneously minimizes safety loss under worst-case representation drift (caused by audio jailbreaks) and benign reasoning loss. This dual-objective training enables the model to maintain performance on legitimate tasks while becoming more resistant to adversarial inputs designed to bypass safety measures. The training process incorporates both clean and adversarially perturbed audio samples to build robustness against representation shifts.

## Key Results
- Rebellion reduces harmful responses by 50.56% on Rephrasing attack and 25% on Advwave attack
- Maintains the same level of benign accuracy on non-adversarial tasks
- Rebellion-trained models exhibit "think twice" behavior, performing safety reasoning before responding to longer suffix audio jailbreaks

## Why This Works (Mechanism)
The Rebellion mechanism works by explicitly training audio reasoning models to handle representation drift caused by adversarial audio perturbations. By incorporating worst-case scenarios into the training objective, the model learns to maintain safety reasoning capabilities even when the input audio has been subtly modified to evade detection. The dual-loss optimization ensures that safety considerations are integrated into the reasoning process rather than being an afterthought, leading to more robust decision-making in the face of adversarial inputs.

## Foundational Learning

**Adversarial audio jailbreaks:** Techniques that modify audio inputs to bypass safety mechanisms and elicit harmful responses. Why needed: Understanding the threat model is crucial for developing effective defenses. Quick check: Verify that the evaluated attacks (Rephrasing and Advwave) represent realistic attack scenarios.

**Representation drift:** Changes in the feature space caused by adversarial perturbations that can confuse model reasoning. Why needed: Addressing representation drift is essential for maintaining model reliability under attack. Quick check: Confirm that the training data includes diverse adversarial examples that induce meaningful representation changes.

**Dual-objective optimization:** Training approach that balances safety and performance objectives simultaneously. Why needed: Prevents safety improvements from coming at the cost of benign task performance. Quick check: Verify that both safety and benign accuracy metrics are tracked throughout training.

## Architecture Onboarding

**Component map:** Audio input → Adversarial perturbation layer → Reasoning module → Safety classifier + Task output
**Critical path:** The adversarial perturbation layer and reasoning module interaction is most critical, as it directly affects the model's ability to maintain safety under attack.
**Design tradeoffs:** The paper balances safety improvement against potential performance degradation on benign tasks, achieving a solution that maintains both objectives.
**Failure signatures:** The primary failure mode would be a model that becomes overly conservative and fails to complete benign tasks, or one that remains vulnerable to novel attack types.
**First experiments:**
1. Baseline evaluation of ARM performance on clean audio inputs
2. Attack success rate evaluation using Rephrasing and Advwave methods
3. Performance comparison of Rebellion-trained models against baseline models under adversarial conditions

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on specific threat model of adversarial audio perturbations designed for jailbreaking
- Results may not generalize to other types of attacks or safety threats
- Limited evaluation scope with only two attack methods (Rephrasing and Advwave)
- Does not address transferability of defenses to other attack vectors or real-world deployment scenarios

## Confidence
- **High confidence** in Rebellion's effectiveness against the specific evaluated jailbreak attacks
- **Medium confidence** in the maintenance of benign task performance
- **Medium confidence** in the "think twice" behavioral observation
- **Low confidence** in generalizability to other attack types or real-world scenarios

## Next Checks
1. Evaluate Rebellion's robustness against a broader range of audio jailbreak techniques beyond Rephrasing and Advwave, including black-box and transfer-based attacks
2. Test the trained models in realistic deployment scenarios with varying audio quality and background noise conditions
3. Conduct ablation studies to isolate which components of the Rebellion training objective contribute most to the observed safety improvements