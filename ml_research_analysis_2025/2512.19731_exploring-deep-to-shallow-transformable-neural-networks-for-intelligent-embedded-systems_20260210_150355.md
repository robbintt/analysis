---
ver: rpa2
title: Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded
  Systems
arxiv_id: '2512.19731'
source_url: https://arxiv.org/abs/2512.19731
tags:
- search
- training
- networks
- transformable
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Double-Win NAS, a novel deep-to-shallow transformable
  neural architecture search (NAS) paradigm for resource-constrained embedded systems.
  The core idea is to first explore deep networks for high accuracy, then equivalently
  transform them into shallow networks to improve hardware efficiency without accuracy
  loss.
---

# Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems

## Quick Facts
- **arXiv ID:** 2512.19731
- **Source URL:** https://arxiv.org/abs/2512.19731
- **Authors:** Xiangzhong Luo; Weichen Liu
- **Reference count:** 40
- **Primary result:** Introduces Double-Win NAS, achieving up to 0.8% higher accuracy with 1.3× speedup on embedded systems

## Executive Summary
This paper introduces Double-Win NAS, a novel deep-to-shallow transformable neural architecture search paradigm designed for resource-constrained embedded systems. The approach first explores deep networks for high accuracy, then transforms them into equivalent shallow networks to improve hardware efficiency without accuracy loss. By combining a hybrid transformable search space with linear and non-linear MBConv operators and a sandwich-inspired differentiable search algorithm, the method achieves significant improvements over state-of-the-art NAS approaches. Extensive experiments on NVIDIA Jetson platforms demonstrate up to 0.8% higher accuracy with 1.3× inference speedup compared to FBNet-C, while also supporting elastic resolution switching without accuracy degradation.

## Method Summary
The paper presents a two-stage approach: first searching deep networks for accuracy, then transforming them into shallow networks for efficiency. The core innovation is a hybrid transformable search space containing both linear and non-linear MBConv operators, enabling deep-to-shallow transformations. A sandwich-inspired differentiable search algorithm explores multiple single-path sub-networks to ensure fairness and prevent search collapse. The method also includes hybrid transformable training to gradually eliminate non-linearity and arbitrary-resolution elastic training with cross-resolution distillation for runtime resolution switching. Experiments on NVIDIA Jetson AGX Xavier and Jetson Nano platforms with ImageNet datasets demonstrate significant performance improvements over existing NAS methods.

## Key Results
- Achieves up to 0.8% higher accuracy compared to FBNet-C on NVIDIA Jetson AGX Xavier
- Provides 1.3× inference speedup while maintaining accuracy
- Supports arbitrary-resolution elastic switching without accuracy loss
- Demonstrates effectiveness on both ImageNet and ImageNet-100 datasets

## Why This Works (Mechanism)
The deep-to-shallow transformable approach works by first exploring the high-accuracy potential of deep networks, then finding equivalent shallow representations that maintain accuracy while improving hardware efficiency. The hybrid search space with both linear and non-linear MBConv operators enables this transformation by providing the necessary flexibility. The sandwich-inspired search algorithm ensures exploration of diverse architectures and prevents the search process from collapsing into suboptimal solutions. Hybrid transformable training gradually removes non-linearities to stabilize accuracy during transformation, while cross-resolution distillation enables the model to maintain performance across different input resolutions at runtime.

## Foundational Learning

**Neural Architecture Search (NAS)** - Automated methods for designing neural network architectures. *Why needed:* Traditional hand-crafted architectures may not be optimal for specific hardware constraints. *Quick check:* Can evaluate multiple architectures simultaneously through weight sharing.

**Mobile Inverted Bottleneck Conv (MBConv)** - Efficient building block for mobile vision models using depthwise separable convolutions with expansion layers. *Why needed:* Provides computational efficiency for embedded systems. *Quick check:* Balance between accuracy and FLOPs can be tuned via expansion ratio.

**Differentiable Architecture Search** - Gradient-based approach to NAS that treats architecture selection as a continuous optimization problem. *Why needed:* More efficient than reinforcement learning or evolutionary approaches. *Quick check:* Uses softmax over operations to enable gradient flow.

**Sandwich Rule in NAS** - Strategy that evaluates multiple sub-networks of different sizes to ensure fair search. *Why needed:* Prevents search bias toward either very shallow or very deep architectures. *Quick check:* Requires evaluating at least one supernet, one medium, and one tiny sub-network.

## Architecture Onboarding

**Component Map:** Input -> MBConv Blocks (linear/non-linear) -> Output; Elastic Resolution Path: High-Res -> Low-Res -> High-Res

**Critical Path:** The sandwich-inspired differentiable search algorithm is critical, as it ensures exploration of diverse architectures and prevents search collapse that would undermine the entire transformable approach.

**Design Tradeoffs:** Linear vs. non-linear MBConv operators (accuracy vs. hardware efficiency), deep vs. shallow architectures (performance vs. resource constraints), fixed vs. elastic resolution (simplicity vs. flexibility).

**Failure Signatures:** Search collapse to homogeneous architectures, accuracy degradation during deep-to-shallow transformation, resolution-specific performance drops, excessive memory consumption during training.

**First Experiments:**
1. Validate sandwich rule effectiveness by comparing search results with and without it
2. Test deep-to-shallow transformation on a simple architecture before full search
3. Evaluate cross-resolution distillation impact on resolution switching capability

## Open Questions the Paper Calls Out

None specified in the source material.

## Limitations

- Evaluation limited to NVIDIA Jetson platforms, potentially limiting generalizability to other embedded hardware
- Focus on image classification tasks with ImageNet datasets, leaving performance on other vision tasks unexplored
- Hybrid transformable search space may introduce implementation complexity compared to traditional NAS approaches

## Confidence

**High confidence:** Claims regarding sandwich-inspired search algorithm effectiveness in avoiding search collapse and ensuring fairness across sub-networks.

**Medium confidence:** Claims about arbitrary-resolution elastic training capability and its practical utility in real-world embedded applications.

**Medium confidence:** Claims regarding general superiority of deep-to-shallow transformable approach compared to existing state-of-the-art NAS methods.

## Next Checks

1. Evaluate the proposed approach on additional embedded hardware platforms (e.g., ARM-based systems, FPGAs) to assess hardware generalizability.
2. Test the transformable networks on diverse computer vision tasks beyond image classification, such as object detection or semantic segmentation.
3. Conduct ablation studies to quantify individual contributions of linear/non-linear MBConv operators and elastic resolution training to overall performance.