---
ver: rpa2
title: Generative Foundation Model for Structured and Unstructured Electronic Health
  Records
arxiv_id: '2508.16054'
source_url: https://arxiv.org/abs/2508.16054
tags:
- data
- clinical
- structured
- patient
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GDP is a multimodal foundation model that encodes structured EHR
  time-series with CNN-Transformer and unstructured notes with BioClinicalBERT, fused
  via cross-attention into an LLM backbone. It is pretrained to generate clinical
  narratives while performing masked feature and next-time-step prediction, then fine-tuned
  for clinical predictions.
---

# Generative Foundation Model for Structured and Unstructured Electronic Health Records

## Quick Facts
- arXiv ID: 2508.16054
- Source URL: https://arxiv.org/abs/2508.16054
- Reference count: 0
- GDP achieves AUROC of 0.923 (HF), 0.817 (T2DM), and 0.627 (30-day readmission) with narrative generation ROUGE-L = 0.135 and BERTScore-F1 = 0.545

## Executive Summary
GDP is a multimodal foundation model that unifies structured EHR time-series and unstructured clinical notes through cross-attention fusion. The model encodes structured data using a CNN-Transformer encoder and unstructured notes via BioClinicalBERT, then fuses them into an LLM backbone for joint pretraining and fine-tuning. GDP demonstrates strong performance on clinical prediction tasks (HF, T2DM, 30-day readmission) and generates high-quality clinical narratives, with blinded human evaluation showing excellent scores on faithfulness, fluency, and clinical utility.

## Method Summary
GDP employs a multimodal architecture combining structured EHR time-series data with unstructured clinical notes. Structured data is encoded using a CNN-Transformer encoder that captures temporal patterns, while unstructured text is processed through BioClinicalBERT. The two modalities are fused via cross-attention mechanisms into an LLM backbone. The model is pretrained using masked feature prediction and next-time-step prediction objectives, then fine-tuned for specific clinical prediction tasks. Additionally, GDP can generate clinical narratives, producing comprehensive summaries that integrate structured and unstructured data.

## Key Results
- Clinical prediction performance: AUROC of 0.923 for heart failure, 0.817 for type 2 diabetes, and 0.627 for 30-day readmission
- Narrative generation quality: ROUGE-L = 0.135 and BERTScore-F1 = 0.545 on generated clinical summaries
- Human evaluation scores: Faithfulness 4.4/5, Fluency 4.6/5, and Clinical Utility 4.3/5 from blinded clinicians

## Why This Works (Mechanism)
The multimodal fusion architecture allows GDP to leverage complementary information from structured EHR time-series and unstructured clinical narratives. The CNN-Transformer encoder captures temporal dependencies and patterns in structured data, while BioClinicalBERT processes the semantic and clinical context from unstructured notes. Cross-attention mechanisms enable bidirectional information flow between modalities, allowing the model to contextualize structured data with narrative information and vice versa. This comprehensive representation enables more accurate clinical predictions and generates narratives that better reflect the full clinical picture.

## Foundational Learning
- **Cross-modal attention mechanisms**: Why needed - to fuse structured and unstructured data representations; Quick check - verify attention weights show meaningful modality interactions
- **Temporal encoding for time-series data**: Why needed - EHR data has inherent temporal structure; Quick check - test with shuffled time-series to confirm temporal sensitivity
- **Clinical language understanding**: Why needed - medical terminology and context are domain-specific; Quick check - evaluate performance on clinical concept extraction tasks
- **Instruction-tuned LLM adaptation**: Why needed - to enable zero-shot and few-shot learning capabilities; Quick check - test on clinical Q&A benchmarks without task-specific fine-tuning
- **Multimodal pretraining objectives**: Why needed - to create unified representations before task-specific adaptation; Quick check - compare with single-modality baselines
- **Clinical narrative generation**: Why needed - to produce interpretable, comprehensive clinical summaries; Quick check - human evaluation of generated summaries against reference standards

## Architecture Onboarding

**Component Map:**
Structured EHR (CNN-Transformer) → Cross-Attention → LLM Backbone → Clinical Predictions/Narratives
Unstructured Notes (BioClinicalBERT) → Cross-Attention → LLM Backbone

**Critical Path:**
The critical path involves encoding both structured and unstructured modalities, fusing them through cross-attention mechanisms, and routing the combined representation to either prediction heads or narrative generation components. The cross-attention layers are crucial as they enable the model to selectively focus on relevant information from both modalities.

**Design Tradeoffs:**
- Multimodal fusion vs. computational complexity: Cross-attention enables rich interactions but increases parameter count and inference time
- Pretraining objectives: Masked prediction vs. next-time-step prediction balance representation learning vs. task-specific performance
- Encoder specialization: Separate encoders for structured vs. unstructured data preserve modality-specific features but require careful fusion design

**Failure Signatures:**
- Poor performance on prediction tasks may indicate inadequate cross-modal fusion or insufficient pretraining
- Low-quality narratives suggest problems with LLM backbone adaptation or modality alignment
- Mode collapse where model favors one modality over another indicates imbalanced training or attention mechanisms

**3 First Experiments:**
1. Ablation study removing cross-attention to quantify multimodal benefits
2. Single-modality baselines (structured-only vs. unstructured-only) to measure complementary value
3. Temporal generalization test using historical data from different time periods

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can GDP leverage its instruction-tuned architecture for zero-shot or few-shot clinical task performance via prompting alone, without task-specific fine-tuning?
- Basis in paper: The authors state: "One is to explore the zero-shot and few-shot learning potential of GDP. As an instruction-tuned LLM fused with clinical data, GDP-Instruct might be able to handle new tasks via prompting... systematic evaluation on benchmark clinical Q&A datasets or few-shot prediction tasks (like those in the recent EHRSHOT challenge) would be informative."
- Why unresolved: Only preliminary anecdotal chat experiments were conducted; no systematic zero-shot evaluation was performed.
- What evidence would resolve it: Benchmarking GDP-Instruct on standardized few-shot clinical prediction tasks and Q&A datasets without additional fine-tuning.

### Open Question 2
- Question: How does GDP performance generalize to external healthcare systems beyond the single-center MIMIC-IV dataset?
- Basis in paper: The authors acknowledge: "Our evaluations were on a single-center dataset (MIMIC-IV) of ICU and hospital inpatients."
- Why unresolved: MIMIC-IV represents one academic medical center's ICU population; model may not generalize to community hospitals, different EHR systems, or international healthcare settings.
- What evidence would resolve it: Multi-center external validation studies measuring AUROC/AUPRC on held-out institutions with different patient populations and EHR schemas.

### Open Question 3
- Question: Can incorporating additional modalities such as medical imaging or genomics improve GDP's predictive accuracy and narrative quality?
- Basis in paper: The authors state: "GDP's architecture could, in theory, be extended with additional encoders for these modalities... but we did not incorporate or test those. Incorporating imaging data... is a promising direction for making the model even more comprehensive."
- Why unresolved: Current GDP only fuses structured EHR time-series and text; imaging, waveforms (ECG/EEG), and genomics were not evaluated.
- What evidence would resolve it: Ablation studies adding dedicated encoders for chest X-rays or genomic profiles, measuring improvements in prediction tasks and summary completeness.

## Limitations
- Evaluated exclusively on single-center Mayo Clinic EHR data, limiting generalizability across different healthcare systems
- Limited to three clinical prediction tasks without extensive testing on diverse clinical endpoints or longitudinal outcomes
- Human evaluation of narrative quality lacks detailed inter-rater reliability metrics and standardized clinical utility assessment frameworks
- Substantial computational requirements may limit real-world deployment feasibility
- No explicit temporal drift analysis for evolving clinical documentation patterns

## Confidence

**Clinical Prediction Performance**: Medium
- Strong AUROC values but lack of external validation
- Modest performance on 30-day readmission (AUROC 0.627)

**Narrative Generation Quality**: Medium
- High human evaluation scores but subjective assessment
- Absence of standardized clinical utility metrics

**Multimodal Architecture**: High
- Well-specified technical design with clear component interactions
- Sound theoretical foundation for cross-modal fusion

## Next Checks
1. **External Validation**: Evaluate GDP performance on at least two independent EHR datasets from different healthcare systems to assess generalizability across documentation practices and patient populations.

2. **Temporal Robustness Testing**: Assess model performance on historical EHR data spanning multiple years to evaluate temporal generalization and identify potential concept drift in clinical documentation patterns.

3. **Resource Efficiency Analysis**: Conduct comprehensive computational resource profiling including training time, inference latency, and memory requirements across different hardware configurations to establish deployment feasibility thresholds.