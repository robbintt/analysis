---
ver: rpa2
title: 'LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language
  Model'
arxiv_id: '2512.21595'
source_url: https://arxiv.org/abs/2512.21595
tags:
- data
- llm-i2i
- items
- recommendation
- llm-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLM-I2I addresses data sparsity and noise issues in Item-to-Item
  (I2I) recommendation models by integrating a Large Language Model (LLM)-based data
  generator and discriminator. The generator synthesizes user-item interactions, particularly
  for long-tail items, while the discriminator filters noisy or low-quality interactions.
---

# LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model

## Quick Facts
- arXiv ID: 2512.21595
- Source URL: https://arxiv.org/abs/2512.21595
- Authors: Yinfu Feng; Yanjing Wu; Rong Xiao; Xiaoyi Zen
- Reference count: 7
- Primary result: 6.02% increase in recall number (RN) and 1.22% improvement in gross merchandise value (GMV) on large-scale e-commerce platform

## Executive Summary
LLM-I2I addresses data sparsity and noise issues in Item-to-Item (I2I) recommendation models by integrating a Large Language Model (LLM)-based data generator and discriminator. The generator synthesizes user-item interactions, particularly for long-tail items, while the discriminator filters noisy or low-quality interactions. This data-centric approach enhances training data quality without modifying existing model architectures. Evaluated on industry (AEDS) and academic (ARD) datasets, LLM-I2I improves recommendation accuracy, especially for long-tail items. Deployed on a large-scale e-commerce platform, it achieves significant improvements in recall and GMV compared to existing I2I models.

## Method Summary
LLM-I2I employs two LLM components - a generator and discriminator - to augment and clean training data for I2I recommendation models. The generator is fine-tuned with a weighted loss function that prioritizes long-tail items (α=4.0 for long-tail, β=1.0 for others) to synthesize user-item interactions. The discriminator is fine-tuned to classify user-item pairs as positive or negative interactions, filtering synthetic pairs with confidence below 1.0. The augmented data (original + filtered synthetic) is then used to train standard I2I models like Swing and BPR. The framework uses Llama2-7B-Chat as the base LLM and is evaluated on both public (ARD) and proprietary (AEDS) datasets.

## Key Results
- On AEDS dataset: Recall@10 improved from 0.0729 to 0.0739 (approximately 1.37% increase)
- On ARD dataset: Recall@10 improved from 0.0651 to 0.0739 (approximately 13.36% increase)
- Long-tail item performance: Recall@10 for long-tail items improved from 0.0061 to 0.0099 (approximately 62.3% increase)
- Swing + LLM-I2I achieved 18.57% improvement in Recall@5 on AEDS compared to baseline Swing
- Real-world deployment: 6.02% increase in recall number (RN) and 1.22% improvement in gross merchandise value (GMV)

## Why This Works (Mechanism)

### Mechanism 1
Weighted loss prioritizes long-tail item pattern learning, improving sparse-item recommendations. The generator's supervised fine-tuning applies a long-tail-aware loss function with α=4.0 for long-tail items and β=1.0 for others. This upweights gradient signals from rare items, forcing the LLM to better capture their co-occurrence patterns despite limited training examples. Core assumption: Long-tail items share learnable sequential patterns that an LLM can generalize from sparse examples. Break condition: If long-tail items have no meaningful co-occurrence patterns (purely random purchases), weighting will amplify noise rather than signal.

### Mechanism 2
Discriminator-based quality filtering improves synthetic data utility beyond generation alone. The discriminator is fine-tuned to classify user-item pairs as positive/negative interactions. Only synthetic pairs receiving "Yes" with confidence=1.0 are retained. This removes low-quality generations that would otherwise corrupt training. Core assumption: The discriminator learns a meaningful signal for interaction quality beyond surface patterns. Break condition: If discriminator confidence is miscalibrated or biased toward popular items, filtering may reduce diversity and amplify popularity bias.

### Mechanism 3
Augmented training data transfers to downstream I2I models without architecture changes. Fused real+synthetic data replaces original training corpus. I2I models (Swing, BPR, etc.) compute item similarities from this enriched interaction graph. More co-occurrence evidence for sparse items yields better similarity estimates. Core assumption: Synthetic interactions approximate true user preferences sufficiently to improve item similarity computation. Break condition: If synthetic data distribution diverges significantly from real user behavior, similarity computations become biased and overall recall may degrade.

## Foundational Learning

- **Item-to-Item Collaborative Filtering**: Why needed here: LLM-I2I augments I2I models; understanding how item similarity is computed from co-occurrence data is prerequisite. Quick check question: Can you explain why items with sparse co-occurrence data have unreliable similarity scores in standard I2I methods?

- **Supervised Fine-Tuning (SFT) of LLMs**: Why needed here: Both generator and discriminator are LLMs fine-tuned on domain-specific interaction data. Quick check question: What is the difference between pre-training and supervised fine-tuning, and why might a pre-trained LLM perform poorly on e-commerce recommendation without SFT?

- **Long-tail Distribution in Recommendation**: Why needed here: The paper explicitly targets long-tail items; understanding this phenomenon explains the motivation and evaluation focus. Quick check question: In a typical e-commerce dataset, approximately what percentage of items might receive fewer than 5 interactions, and why does this challenge I2I models?

## Architecture Onboarding

- **Component map**: User history + Item features -> LLM Generator -> Candidate items -> LLM Discriminator -> Filtered synthetic pairs -> Fused data -> I2I model -> Item similarity index

- **Critical path**:
  1. Prepare training data with long-tail item identification (bottom 20% by frequency)
  2. Fine-tune generator with weighted loss (α=4.0, β=1.0) on user sequences
  3. Fine-tune discriminator on positive/negative interaction pairs
  4. Generate synthetic interactions for each user (last 10 items as context)
  5. Filter with discriminator (keep only confidence=1.0 "Yes")
  6. Fuse with original data; train downstream I2I model
  7. Build inverted index for online serving

- **Design tradeoffs**:
  - Generator recall number: More synthetic items per user increases coverage but risks distribution drift
  - Discriminator threshold: Higher threshold improves quality but reduces synthetic data volume
  - Context window length: Paper uses 10 recent items; longer context may improve generation but increases LLM inference cost
  - Base LLM choice: Larger models may improve generation quality but increase fine-tuning and inference costs

- **Failure signatures**:
  - Synthetic data volume too high → model overfits to synthetic patterns, overall recall degrades
  - Discriminator threshold too low → noisy interactions corrupt similarity estimates
  - Long-tail weight too aggressive → generator produces unrealistic long-tail recommendations
  - No performance gain on popular items → potential distribution mismatch between synthetic and real data

- **First 3 experiments**:
  1. Ablation validation: Replicate Table 5 on a small dataset; confirm that removing generator, discriminator, or long-tail loss each degrades performance
  2. Threshold sensitivity: Sweep discriminator confidence threshold [0.5, 0.7, 0.9, 1.0] and plot Recall@10 vs. synthetic data volume to find optimal operating point
  3. Long-tail weight tuning: Test α ∈ {2.0, 4.0, 8.0} with β=1.0 fixed; measure both overall Recall@10 and long-tail-specific recall to identify over/under-weighting

## Open Questions the Paper Calls Out
- Can the proposed LLM-I2I framework maintain its effectiveness in non-e-commerce domains (e.g., news or short video recommendations) where item text features are sparse or less descriptive?
- Would replacing the discriminator's random negative sampling with "hard" negative sampling improve the filter's ability to distinguish subtle noise from genuine user preferences?

## Limitations
- Proprietary AEDS dataset prevents independent verification of the claimed 6.02% RN and 1.22% GMV improvements
- Exact prompt templates are only visually depicted, requiring interpretation for reproduction
- No sensitivity analysis presented for the specific long-tail weighting parameters (α=4.0, β=1.0)

## Confidence
- **High Confidence**: The core data augmentation and denoising mechanisms are technically sound and well-explained with strong internal validation
- **Medium Confidence**: Weighted loss for long-tail item learning is supported by results but specific parameter choices appear arbitrary
- **Low Confidence**: Real-world impact metrics (GMV improvement) cannot be independently verified due to proprietary dataset

## Next Checks
1. Replicate ablation study on public dataset: Recreate Table 5's ablation analysis on ARD to verify that removing generator, discriminator, or long-tail loss each degrades performance as reported
2. Prompt template validation: Test the impact of different prompt formulations on generation quality by creating variations of the shown template and measuring synthetic data utility through discriminator confidence scores
3. Threshold sensitivity analysis: Conduct a systematic sweep of discriminator confidence thresholds (0.5, 0.7, 0.9, 1.0) to identify the optimal balance between synthetic data volume and quality, plotting Recall@10 against synthetic data percentage