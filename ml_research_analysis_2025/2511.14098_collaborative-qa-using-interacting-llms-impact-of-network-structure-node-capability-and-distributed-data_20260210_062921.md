---
ver: rpa2
title: Collaborative QA using Interacting LLMs. Impact of Network Structure, Node
  Capability and Distributed Data
arxiv_id: '2511.14098'
source_url: https://arxiv.org/abs/2511.14098
tags:
- llms
- network
- which
- each
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a theoretical and experimental framework
  for modeling information diffusion in networks of interacting LLMs performing collaborative
  question-answering. The authors propose a mean-field dynamics model for directed
  networks, augmented with a randomized utility model to parameterize transition probabilities
  between truthful, hallucinating, and "don't know" states.
---

# Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data

## Quick Facts
- **arXiv ID:** 2511.14098
- **Source URL:** https://arxiv.org/abs/2511.14098
- **Authors:** Adit Jain; Vikram Krishnamurthy; Yiming Zhang
- **Reference count:** 29
- **Primary result:** Introduces a theoretical and experimental framework for modeling information diffusion in networks of interacting LLMs performing collaborative question-answering, showing power-law structures outperform chain/tree topologies.

## Executive Summary
This paper introduces a theoretical and experimental framework for modeling information diffusion in networks of interacting LLMs performing collaborative question-answering. The authors propose a mean-field dynamics model for directed networks, augmented with a randomized utility model to parameterize transition probabilities between truthful, hallucinating, and "don't know" states. They derive conditions for the existence and uniqueness of fixed points and analyze how incentives (test-time compute) affect equilibrium truthfulness. Empirically, they study 100 open-source LLMs on three semi-synthetic datasets (fiction, knowledge cutoff, event-based QA), showing that: (1) truthful population state increases with compute and model capability, (2) influential node placement with correct data improves truthful outcomes, (3) power-law network structures outperform chain/tree topologies, and (4) the framework accurately predicts population state dynamics. The work provides both theoretical insights and practical guidance for designing robust LLM networks.

## Method Summary
The method uses 100 LLaMa-3.1-8B LLM instances in a directed graph topology with power-law degree distribution. The network runs 10 rounds of parallel interactions where each node answers questions based on local context and neighbor answers. Population states (truthful, hallucinating, don't know) are tracked over time. The mean-field ODE model with randomized utility model (RUM) predicts transition probabilities between states. Parameters are fit using logistic regression on observed transitions. Datasets are semi-synthetic: fiction from Project Gutenberg, knowledge cutoff from Wikipedia edits, and event-based from news articles. Questions are multiple-choice with three possible answers.

## Key Results
- Truthful population state increases with test-time compute and model capability
- Placing correct data on influential (high-degree) nodes improves truthful outcomes
- Power-law network structures outperform chain or tree topologies in spreading factual consistency
- The mean-field framework accurately predicts population state dynamics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The collective behavior of a large network of LLMs can be approximated as a deterministic dynamical system using Mean-Field Dynamics (MFD), allowing for the prediction of "truthful population state" ($\rho_T$) over time.
- **Mechanism:** Instead of tracking individual stochastic interactions between $N$ agents (combinatorially complex), the system tracks the evolution of the *distribution* of states (Truthful, Hallucinating, Don't Know) across the population. An ODE governs how the proportion of agents in each state changes based on transition rates derived from neighbor influences.
- **Core assumption:** The network is sufficiently large for the "mean field" (average neighbor influence) to accurately represent the specific local neighborhood of any given node (law of large numbers).
- **Evidence anchors:**
  - [abstract] "We model the LLM with a latent state... and extend a tractable analytical model considering an MFD to model the diffusion of information in a directed network of LLMs."
  - [Section 2.2] "To handle the combinatorial complexity of modeling information diffusion in large networks, we derive an ordinary differential equation (ODE) that approximates the average behavior of agents using a mean-field approach..."
  - [corpus] Corpus evidence is tangential; neighbors focus on static network embeddings or LLM reference bias rather than dynamic population modeling.
- **Break condition:** The approximation degrades in very small networks (e.g., $N < 20$) where specific edge connections dominate over average degree distributions, or if agents have highly heterogeneous, non-stationary transition logic.

### Mechanism 2
- **Claim:** An LLM's decision to switch its state (e.g., from "Don't Know" to "Hallucinating") follows a Randomized Utility Model (RUM), enabling the estimation of transition probabilities via logistic regression on context and peer influence.
- **Mechanism:** The LLM is modeled as a rational agent maximizing a utility function. The utility of an answer is the sum of a deterministic component (features of the context/neighbors) and a random component (Gumbel noise). This noise assumption naturally yields a Multinomial Logit (softmax) probability for choosing a state, which serves as the transition kernel ($\kappa$) for the MFD.
- **Core assumption:** The "noise" in an LLM's decision-making process fits a Gumbel distribution, satisfying the Independence of Irrelevant Alternatives (IIA) property.
- **Evidence anchors:**
  - [abstract] "...randomized utility model (RUM) from economics to create a generative model... To specify the probabilities that govern the dynamics of the MFD, we propose a randomized utility model."
  - [Section 2.3] "The key idea underpinning RUM is that the realized utility for an LLM for providing state estimate $z$ is corrupted by additive noise... With the IIA property, one obtains the multinomial logit choice rule."
  - [corpus] No direct validation of RUM for LLMs found in corpus; corpus neighbors focus on logic circuits and graph distances.
- **Break condition:** If LLM outputs exhibit strong "sycophancy" or deterministic rigidity that violates the IIA property (e.g., preference for A over B changes strictly due to presence of C), the Multinomial Logit transition estimates will be biased.

### Mechanism 3
- **Claim:** The equilibrium "truthfulness" of the network is contingent on the placement of correct data on high-degree (influential) nodes and the specific topology (Power-law > Chain/Tree).
- **Mechanism:** Information spreads via "social influence" modeled in the utility function. High out-degree nodes (hubs) act as superspreaders. If hubs hold the correct context, they pull the mean-field equilibrium toward the Truthful state ($\rho_T \to 1$). If hubs are uniformed or hallucinating, they drag the network into error. Power-law structures provide these hubs naturally, unlike chains or trees.
- **Core assumption:** The network structure allows for "influential" nodes to exist and that LLMs weigh inputs from neighbors (weighted by the network structure) significantly in their utility calculation.
- **Evidence anchors:**
  - [abstract] "...Power-law network structures outperform chain or tree structures in spreading factual consistency."
  - [Section 3.2, Exp 3] "It can be seen that placing the correct data on influential nodes leads to an improved proportion of truthful nodes..."
  - [corpus] "Structurally Human, Semantically Biased..." (Corpus ID 87933) supports the idea that structure impacts LLM outputs, though focused on reference graphs rather than interaction dynamics.
- **Break condition:** If the base model capability is too low to process the context even when provided (low $\eta(u)$), or if the framing of the question is ambiguous to the point of randomizing the "utility" regardless of neighbor input.

## Foundational Learning

- **Concept: Mean-Field Approximation (MFA)**
  - **Why needed here:** The paper replaces $N$ interacting stochastic agents with a deterministic ODE describing population density. Without understanding MFA, the leap from "100 chatting bots" to "differential equations" appears unmotivated.
  - **Quick check question:** If you have 10 agents vs 10,000 agents, in which case does the Mean-Field ODE prediction likely fail?

- **Concept: Multinomial Logit (MNL) & IIA**
  - **Why needed here:** The paper uses MNL to model LLM transition probabilities. Understanding that MNL implies a specific independence property (IIA) is crucial for diagnosing when the "Random Utility" assumption might fail.
  - **Quick check question:** Why does the paper assume Gumbel noise specifically, rather than Gaussian noise, for the utility model?

- **Concept: Network Centrality & Degree Distribution**
  - **Why needed here:** The paper claims "Power-law" networks work best. This requires understanding that Power-law distributions create "hubs" (high degree nodes) whereas Poisson (Erdos-Renyi) distributions do not.
  - **Quick check question:** Why would placing "correct context" on a high-degree node have a different systemic effect than placing it on a low-degree node in a scale-free network?

## Architecture Onboarding

- **Component map:**
  1. Context Distributor: Slices documents into "distributed contexts" (correct, incorrect, missing) and assigns them to nodes.
  2. Agent Pool: $N=100$ LLM instances (e.g., LLaMa3-8B).
  3. Interaction Layer: A directed graph topology (Power-law/Chain/Tree) governing message passing.
  4. State Evaluator: Classifies agent outputs into Truthful (T), Hallucination (H), or Don't Know (D) based on Ground Truth.
  5. ODE/MFD Solver: Fits parameters to observed transitions to predict $\rho_T$.

- **Critical path:**
  1. Initialize network topology.
  2. Assign contexts (Data Placement).
  3. Interaction Loop: Node $i$ receives neighbor answer $z_j$ $\to$ updates internal utility $\to$ outputs new answer $z_i$.
  4. Converge to Fixed Point $\theta^*$.

- **Design tradeoffs:**
  - Topology: Chain/Tree is easier to implement but prone to error propagation at bottlenecks; Power-law is robust if hubs are truthful, but fragile if hubs hallucinate.
  - Privacy vs. Accuracy: Distributing documents (high privacy) requires higher test-time compute/deliberation to match the accuracy of a centralized context.

- **Failure signatures:**
  - Hallucination Cascade: $\rho_H$ converges to $>0.5$. Often caused by high-degree nodes receiving "incorrect context" or models with low capability ($u$) processing ambiguous data.
  - Stagnation: $\rho_D$ (Don't Know) remains high. Caused by lack of "Incentive" (test-time compute) or fragmented contexts where no agent has sufficient information to trigger a state switch.

- **First 3 experiments:**
  1. Topology Stress Test: Run the same QA task on Chain vs. Power-law topologies. Measure the difference in $\rho_T$ after 10 rounds.
  2. Adversarial Hub Injection: Place "incorrect context" specifically on the highest-degree node in a Power-law network. Measure the drop in $\rho_T$ compared to random placement.
  3. Compute Scaling: Increase the "deliberation steps" (incentive $u$) for all agents. Plot $\rho_T$ vs. compute tokens to verify the concavity claimed in Section 3.2 (Exp 1).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do dynamic networks utilizing preferential attachment create a "Glass-Ceiling Effect" where influential nodes gatekeep information from smaller models?
- **Basis in paper:** [explicit] The conclusion suggests extending dynamic networks to analyze the "Glass-Ceiling Effect, wherein influential nodes have privileged information."
- **Why unresolved:** The current study focuses on static network topologies and does not model the evolution of influence or information access over time.
- **What evidence would resolve it:** Simulation of dynamic graphs where edge formation depends on node accuracy and size, tracking if low-degree nodes are systematically excluded from truth.

### Open Question 2
- **Question:** How does the "Strength of Weak Ties" theory inform the optimal distribution of datasets across a network for knowledge retrieval tasks?
- **Basis in paper:** [explicit] Future work suggests studying optimal dataset distribution on a graph from the perspective of the "Strength of Weak Ties."
- **Why unresolved:** The paper currently distributes data randomly or by centrality but has not tested sparse, bridging connections as a specific data placement strategy.
- **What evidence would resolve it:** Comparative experiments where data is clustered vs. distributed across "weak tie" edges, measuring global retrieval accuracy.

### Open Question 3
- **Question:** Can multi-agent reinforcement learning (MARL) be employed to incentivize agents to improve communication adaptively and converge faster?
- **Basis in paper:** [explicit] The authors propose examining "Incentivization of Agents" and employing MARL to improve communication adaptively.
- **Why unresolved:** The current framework assumes fixed transition probabilities based on a Random Utility Model rather than learned, adaptive policies.
- **What evidence would resolve it:** Implementation of a reward signal based on truthfulness in a MARL setup, analyzing if agents learn distinct communication protocols.

## Limitations

- The RUM-based transition model may not generalize to diverse LLM architectures and prompting strategies, particularly regarding the Gumbel noise and IIA property assumptions.
- Mean-field approximation has limitations in small networks (< 20 nodes) where individual agent heterogeneity significantly impacts outcomes.
- Semi-synthetic datasets may not capture all real-world failure modes, particularly those involving ambiguous or highly contextual information.

## Confidence

- **High Confidence:** The theoretical framework (MFD with RUM) is mathematically sound and the proof of existence/uniqueness of fixed points is rigorous. The experimental observation that power-law networks outperform chain/tree topologies is consistently reproducible across datasets.
- **Medium Confidence:** The empirical correlation between test-time compute and truthfulness improvement, while demonstrated, requires more systematic ablation studies to isolate compute effects from other factors like prompt engineering or model-specific optimizations.
- **Medium Confidence:** The claim that "correct data placement on influential nodes improves truthful outcomes" is supported by experiments but depends heavily on the specific network topology and may not generalize to networks with different degree distributions or clustering coefficients.

## Next Checks

1. **RUM Assumption Validation:** Conduct systematic experiments varying the distribution of noise in LLM decision-making (e.g., through temperature scaling) and measure violations of the Independence of Irrelevant Alternatives property. Compare predicted vs. actual transition probabilities under different noise regimes.

2. **Network Size Scaling:** Replicate the main experiments (Topology Stress Test and Compute Scaling) with network sizes ranging from 10 to 1000 nodes. Measure the deviation between mean-field predictions and observed population states to identify the threshold where MFA breaks down.

3. **Adversarial Context Injection:** Design an experiment where incorrect contexts are strategically placed on high-degree nodes in power-law networks, and measure the time-to-convergence for truthful information when correct contexts are placed on low-degree nodes. This would validate the robustness claim and identify the minimum compute threshold needed to overcome hub misinformation.