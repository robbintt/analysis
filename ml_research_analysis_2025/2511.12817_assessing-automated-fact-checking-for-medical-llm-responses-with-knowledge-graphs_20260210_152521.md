---
ver: rpa2
title: Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge
  Graphs
arxiv_id: '2511.12817'
source_url: https://arxiv.org/abs/2511.12817
tags:
- medical
- faith
- language
- evaluation
- factuality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the reliability and viability of using
  medical knowledge graphs (KGs) for automated factuality evaluation of LLM-generated
  medical responses. The authors introduce FAITH, a reference-free framework that
  decomposes responses into atomic medical claims, links them to a medical KG, and
  scores them based on evidence paths.
---

# Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs

## Quick Facts
- arXiv ID: 2511.12817
- Source URL: https://arxiv.org/abs/2511.12817
- Reference count: 24
- Introduces FAITH, a reference-free framework achieving Pearson's ρ = 0.696 correlation with clinician judgments for medical LLM factuality evaluation

## Executive Summary
This paper investigates using medical knowledge graphs (KGs) for automated factuality evaluation of LLM-generated medical responses. The authors introduce FAITH, a reference-free framework that decomposes responses into atomic medical claims, links them to a medical KG, and scores them based on evidence paths. Experiments on four medical QA tasks demonstrate that FAITH achieves considerably higher correlations with clinician judgments compared to baselines like BLEU-4, and can effectively distinguish LLMs with varying capabilities while being robust to textual variations.

## Method Summary
FAITH operates without reference answers by decomposing responses into atomic claims using GPT-4o with multi-phase prompting (entity identification → relation determination). Medical entities are mapped to UMLS Concept Unique Identifiers (CUIs) for standardized matching with KG nodes. The framework finds shortest paths between entity pairs in the KG and computes factuality scores using semantic similarity of path relations to claim predicates, entity centrality (PageRank), and relation co-occurrence statistics. Claims with unmatched entities are conservatively labeled "unverifiable" and excluded. The method aggregates individual claim scores to produce response-level factuality assessments.

## Key Results
- FAITH achieves Pearson's ρ = 0.696 correlation with clinician judgments, compared to BLEU-4's ρ = 0.081
- Demonstrates superior performance in distinguishing LLMs with different capabilities
- Shows robustness to textual variations with coefficient of variation under paraphrasing of 0.014±0.005
- Can effectively identify factuality errors at the claim level, enabling selective intervention to enhance LLM responses

## Why This Works (Mechanism)

### Mechanism 1: Atomic Claim Decomposition
Decomposing LLM responses into structured triplets (subject, relation, object) enables targeted fact verification rather than holistic text comparison. GPT-4o extracts medical entities and their relationships using multi-phase prompting, with multi-round prompting for recall and critical analysis prompts for precision. The extraction LLM can reliably identify atomic claims without introducing errors that propagate downstream.

### Mechanism 2: Entity Resolution via UMLS Standardization
Mapping free-text medical entities to canonical CUIs bridges terminology variations between LLM outputs and KG nodes. UMLS API normalizes entities from both claims and KG nodes to standardized CUIs, enabling matching despite surface-form differences. UMLS coverage is sufficient for the medical domain, with entities not in UMLS being acceptable losses.

### Mechanism 3: Path-Based Factuality Scoring
Factuality correlates with the semantic congruence and structural properties of KG evidence paths connecting claim entities. Shortest paths between entity pairs are scored using relation semantic similarity, entity centrality (PageRank), and relation co-occurrence statistics. Shortest paths capture the most salient evidential connections, with higher scores indicating stronger evidential support.

## Foundational Learning

- **Concept: Knowledge Graph Traversal**
  - Why needed here: Understanding how entities connect via relations enables comprehension of why path-based scoring works for fact verification.
  - Quick check question: Given entities A and B in a KG, what makes one path "better evidence" than another for verifying a claim (A, relation, B)?

- **Concept: Entity Resolution/Normalization**
  - Why needed here: Grasping why 'haemoptysis' and 'Hemoptysis' must map to the same node explains the UMLS integration design choice.
  - Quick check question: Why would simple string matching fail for medical entity linking, and what role do CUIs play?

- **Concept: Reference-Free Evaluation**
  - Why needed here: FAITH's key advantage over BLEU/ROUGE is operating without ground-truth references—understanding this distinction clarifies the practical motivation.
  - Quick check question: Why can't BLEU evaluate a medical response when no "gold standard" answer exists?

## Architecture Onboarding

- **Component map:** Claim Extractor (GPT-4o) → Entity Resolver (UMLS API) → KG Traverser (shortest path) → Scorer (semantic similarity + PageRank + co-occurrence) → Aggregator
- **Critical path:** Claim extraction quality directly gates all downstream modules; UMLS availability is a hard dependency for entity matching.
- **Design tradeoffs:** Shortest-path constraint (computational tractability vs. potentially missing multi-hop evidence); conservative 'unverifiable' labeling (precision vs. recall in fact coverage); GPT-4o for extraction (cost/quality tradeoff—paper shows GPT-4o-mini nearly matches it).
- **Failure signatures:** High 'unverifiable' rate (KG coverage gap); low correlation with clinician judgments on specific relation types; CV spike under paraphrasing (extraction instability).
- **First 3 experiments:**
  1. **Sanity check:** Run FAITH on 5 sample responses; verify claim extraction produces valid triplets and UMLS returns CUIs for >80% of entities.
  2. **Robustness test:** Paraphrase 10 responses using GPT-4o; confirm FAITH scores have CV <0.02.
  3. **Correlation validation:** On a held-out set, compute Pearson correlation between FAITH scores and human annotations; target ρ >0.6.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can integrating multiple medical knowledge graphs reduce false negatives from incomplete coverage? The study tested individual KGs but did not explore combined coverage or fusion strategies.

- **Open Question 2:** How can factuality be assessed for claims with entities that cannot be matched to any KG node? The paper conservatively excludes ~5-10% of claims rather than attempting partial verification.

- **Open Question 3:** Does exploring paths beyond the shortest path improve factuality scoring accuracy? The authors constrain search to shortest paths due to computational tractability, acknowledging exhaustive search is intractable.

- **Open Question 4:** How do errors in the claim extraction module propagate to final factuality assessments? The paper evaluates extraction quality separately but does not quantify end-to-end error propagation to FAITH scores.

## Limitations
- FAITH cannot verify claims involving knowledge absent from the KG, leading to potential false negatives
- Performance depends on the quality of the upstream medical claim extraction module, with errors propagating through the system
- Computational requirements may limit scalability, though the paper reports processing times under a minute per response

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| FAITH's mechanism of decomposing responses into atomic claims and using KG paths for factuality scoring is technically sound | High |
| The robustness results under paraphrasing are promising but may not hold across different styles or subdomains | Medium |
| The scalability claims to large KGs like UMLS are based on processing times that need production workload verification | Low |

## Next Checks

1. **Cross-domain robustness test:** Apply FAITH to non-medical QA datasets (e.g., scientific literature or legal documents) to assess generalizability beyond the medical domain.

2. **Cost-benefit analysis:** Measure computational overhead and API costs for full-scale deployment, comparing GPT-4o extraction against the reported near-equivalent GPT-4o-mini performance.

3. **Clinician preference study:** Conduct user studies comparing FAITH's explainability features against traditional reference-based metrics to validate practical utility claims.