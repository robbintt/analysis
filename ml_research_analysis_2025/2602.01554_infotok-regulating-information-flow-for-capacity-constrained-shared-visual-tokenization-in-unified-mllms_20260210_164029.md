---
ver: rpa2
title: 'InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual
  Tokenization in Unified MLLMs'
arxiv_id: '2602.01554'
source_url: https://arxiv.org/abs/2602.01554
tags:
- infotok
- visual
- unified
- generation
- shared
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InfoTok addresses the challenge of shared visual tokenization in
  unified multimodal large language models (MLLMs), where a single visual tokenizer
  must support both image understanding and generation tasks. The core idea is to
  use information regularization based on the Information Bottleneck (IB) principle
  to explicitly control the information flow from images to shared tokens, promoting
  compact yet sufficient tokens that prioritize reusable structure over high-entropy
  variations.
---

# InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs

## Quick Facts
- arXiv ID: 2602.01554
- Source URL: https://arxiv.org/abs/2602.01554
- Reference count: 18
- InfoTok improves FID from 14.4 to 12.0 and CKA from 0.24 to 0.27 on Harmon MLLM

## Executive Summary
InfoTok addresses the challenge of shared visual tokenization in unified multimodal large language models (MLLMs), where a single visual tokenizer must support both image understanding and generation tasks. The core idea is to use information regularization based on the Information Bottleneck (IB) principle to explicitly control the information flow from images to shared tokens, promoting compact yet sufficient tokens that prioritize reusable structure over high-entropy variations. InfoTok formulates tokenization as controlling information dependencies via mutual information terms, instantiated through variational IB estimation. Experiments show that InfoTok consistently improves both understanding and generation performance across three representative unified MLLMs (Harmon, OpenUni, Show-o2) without introducing additional training data. On benchmarks such as Geneval and WISE, InfoTok yields significant gains, e.g., FID scores improving from 14.4 to 12.0 and CKA from 0.24 to 0.27 on Harmon. Theoretical grounding supports that information-regularized tokenization provides a principled foundation for learning a shared token space.

## Method Summary
InfoTok introduces information regularization to unified MLLMs by applying the Information Bottleneck principle to shared visual tokenization. The method adds lightweight task-specific projections (f_u, f_g) on top of shared visual tokens, which are then used to compute IB objectives for both understanding and generation tasks. These projections enable explicit control over information flow through compactness (KL divergence to prior), sufficiency (negative log-likelihood), and alignment (contrastive estimation) terms. During training, gradients from these objectives backpropagate through the projections to regularize the shared visual encoder. At inference, projections are removed and the original visual encoder is used directly. The approach is applied to three unified MLLMs (Harmon, OpenUni, Show-o2) and evaluated on understanding benchmarks (GQA, SEED, POPE, MME, MMV2, MMMU, UniBench) and generation benchmarks (Geneval, Geneval++, WISE).

## Key Results
- InfoTok improves generation FID scores from 14.4 to 12.0 on Harmon MLLM
- CKA (linear alignment) increases from 0.24 to 0.27 on Harmon with InfoTok
- InfoTok achieves consistent improvements across understanding and generation tasks on all three tested unified MLLMs (Harmon, OpenUni, Show-o2)
- InfoTok works with both continuous (Harmon) and discrete (Show-o2) visual tokenizers

## Why This Works (Mechanism)

### Mechanism 1: Information Bottleneck Regularization for Capacity Allocation
- **Claim**: Explicitly regulating information flow via IB principle yields tokens that prioritize reusable structure over high-entropy variations.
- **Mechanism**: The visual tokenizer operates as a capacity-constrained learner. InfoTok adds a regularization term that upper-bounds I(Z;I) via KL divergence to a prior (typically N(0,I)), forcing the encoder to discard redundant input information while preserving task-relevant content. This shifts tokenization from indiscriminate compression toward budget allocation for semantically valuable features.
- **Core assumption**: The paper assumes that high-entropy visual variations (e.g., texture noise) are less transferable across understanding and generation than structural cues (e.g., object boundaries, compositional relations).
- **Evidence anchors**:
  - [abstract] "the token budget should prioritize reusable structure over hard-to-exploit high-entropy variations and redundancy"
  - [section 3.2.3] "Minimizing these KL terms encourages compact projected tokens by suppressing redundant input information"
  - [corpus] "Slot-MLLM: Object-Centric Visual Tokenization" explores object-centric slots as reusable structural units, indirectly supporting the structural-prior hypothesis.
- **Break condition**: If the Lagrange multiplier β is set too low, the compression term dominates and strips task-relevant information; if too high, redundancy persists. The paper does not provide automated β tuning—this remains a hyperparameter.

### Mechanism 2: Dual-Task IB Extension with Task-Facing Projections
- **Claim**: Attaching lightweight task-specific projections allows IB regularization to jointly shape a shared token space for understanding and generation.
- **Mechanism**: Instead of applying IB directly to shared tokens Z, InfoTok projects them via deterministic mappings (f_u, f_g) to task-facing representations (Ź_u, Ź_g). Separate IB objectives (L^(u)_IB, L^(g)_IB) are then applied, each with its own sufficiency term targeting understanding or generation outputs. Gradients propagate back through projections to regularize Venc. Since f_u, f_g are deterministic, I(Z;Y^GT) ≥ max(I(Ź_u;Y^GT_u), I(Ź_g;Y^GT_g)) (Eq. 12), so constraining projected tokens induces corresponding constraints on shared tokens.
- **Core assumption**: Task-facing projections can expose distinct information requirements without fragmenting the shared representation. The paper assumes deterministic projections do not collapse information needed by the other task.
- **Evidence anchors**:
  - [section 3.2.2] "To make task requirements explicit when imposing information constraints, we attach lightweight task-specific projections on top of the visual tokens"
  - [section 3.3.2] "I(Z;Y^GT) ≥ max(I(Ź_u;Y^GT_u), I(Ź_g;Y^GT_g)), which shows that regularizing the task-facing tokens induces corresponding information constraints on the shared encoder outputs"
  - [corpus] Corpus lacks direct evidence for dual-task IB extensions in MLLMs; this appears novel to the paper.
- **Break condition**: If f_u or f_g have insufficient capacity, they may fail to expose task-relevant information, weakening regularization. The paper does not ablate projection dimensionality.

### Mechanism 3: Cross-Modal Alignment via Contrastive Estimation
- **Claim**: Maximizing mutual information between visual tokens and text tokens improves coherence in unified next-token prediction.
- **Mechanism**: InfoTok adds an alignment term Î(Ź;T) using InfoNCE contrastive loss. For each branch, it aggregates a visual embedding from the posterior mean (Z̄_u, Z̄_g) and computes similarity with paired text embeddings against negative samples. This encourages visual tokens to reside in a space compatible with textual representations, reinforcing cross-modal consistency.
- **Core assumption**: Contrastive similarity in embedding space translates to improved task performance on understanding and generation. The paper assumes negative sampling strategies adequately approximate the true marginal distribution.
- **Evidence anchors**:
  - [section 3.2.3] "To encourage coherent interaction with text, we maximize I(Ź;T) using a contrastive estimator"
  - [table 5] Ablation shows C&S&A (with alignment) outperforms C&S alone on most benchmarks (e.g., Harmon Geneval: 0.84 → 0.85)
  - [corpus] "Unified Multimodal Understanding via Byte-Pair Visual Encoding" aligns visual tokens with text via byte-pair encoding, supporting cross-modal alignment as beneficial.
- **Break condition**: If negative samples are too easy or too hard, contrastive gradients become uninformative. Temperature τ and batch size affect estimator quality—these are not ablated in detail.

## Foundational Learning

- **Concept: Information Bottleneck Principle**
  - **Why needed here**: InfoTok's core objective is derived from IB. Without understanding the compression–relevance trade-off (minimize I(Z;X) while maximizing I(Z;Y)), the loss terms (KL, sufficiency) appear unmotivated.
  - **Quick check question**: Given a representation Z of input X for predicting Y, does increasing I(Z;X) always help prediction? Why might we want to reduce it?

- **Concept: Variational Inference and Reparameterization**
  - **Why needed here**: The paper uses variational posterior q_ϕ(Ź|I) parameterized as Gaussian with reparameterization trick. Understanding how to bound MI via variational approximations is essential to implement the loss.
  - **Quick check question**: Why can't we compute I(Ź;I) directly? How does a variational bound make it tractable?

- **Concept: Contrastive Learning (InfoNCE)**
  - **Why needed here**: The alignment term uses InfoNCE to estimate I(Ź;T). Understanding negative sampling, temperature scaling, and how InfoNCE bounds MI is necessary to debug alignment loss behavior.
  - **Quick check question**: In InfoNCE, what happens if all negative samples are very dissimilar to the anchor? How does temperature affect gradient magnitude?

## Architecture Onboarding

- **Component map**:
  - Venc: Shared visual encoder (continuous or discrete). Takes image I → produces shared tokens Z.
  - f_u, f_g: Lightweight task-specific projections (MLPs). Map Z → Ź_u, Ź_g during training only. Removed at inference.
  - q_ϕ(Ź|I): Variational posterior over projected tokens (Gaussian with mean μ_ϕ(I), variance σ²_ϕ(I)). Sampled via reparameterization.
  - p_θ(Y^GT_u|Ź_u), p_θ(Y^GT_g|Ź_g): Variational decoders for sufficiency terms (predict understanding/generation targets).
  - L_InfoTok: Combined regularization = L^(u)_InfoTok + L^(g)_InfoTok, each comprising KL (compactness) + negative log-likelihood (sufficiency) + InfoNCE (alignment).
  - L_Total = L_MLLM + λ L_InfoTok: Joint objective. λ controls regularization strength.

- **Critical path**:
  1. Image I → Venc → shared tokens Z
  2. Z → f_u / f_g → Ź_u / Ź_g
  3. Sample Ź via reparameterization from q_ϕ(Ź|I)
  4. Compute KL(q_ϕ || prior) for compactness
  5. Pass Ź to variational decoders, compute log-likelihood for sufficiency
  6. Compute InfoNCE between mean(μ_ϕ) and text embeddings for alignment
  7. Backprop through projections to Venc
  8. Inference: discard projections, use Venc directly

- **Design tradeoffs**:
  - **Projection dimensionality**: Larger projections may expose more task-relevant info but increase compute. Paper does not specify dimensions—assume same as Z or reduced.
  - **β_u, β_g, α_u, α_g**: Control strength of sufficiency vs. alignment vs. compactness. Paper uses same β across tasks in ablations but does not publish exact values. **Assumption**: These require per-model tuning.
  - **Prior choice**: Standard Gaussian N(0,I). Alternative priors (e.g., learned, mixture) not explored.
  - **Continuous vs. discrete tokenizers**: InfoTok works on both (Harmon: continuous; Show-o2: discrete). For discrete tokens, variational relaxation is needed—paper uses Gaussian relaxation over quantized embeddings.

- **Failure signatures**:
  - **Over-regularization (λ too high)**: Tokens become too compact, losing perceptual detail → generation FID degrades, understanding may hold or improve slightly.
  - **Under-regularization (λ too low)**: No meaningful change from baseline; standard fine-tuning behavior (oscillatory gains/losses as in Table 5 "Finetune" rows).
  - **Misaligned α/β**: If sufficiency dominates (β large), tokens may retain high-entropy details → worse understanding; if compactness dominates, generation suffers.
  - **Projection bottleneck**: If f_u/f_g too narrow, gradients cannot effectively regularize Venc → minimal gains.

- **First 3 experiments**:
  1. **Baseline sanity check**: Reproduce Harmon or Show-o2 baseline scores on Geneval + one understanding benchmark (e.g., GQA). Verify training pipeline matches paper (same data, 1/10 learning rate, 16×L40S).
  2. **InfoTok ablation (C vs. C&S vs. C&S&A)**: Implement InfoTok on Harmon with 3 configs. Measure Geneval, GQA, WISE. Confirm C&S yields gains and alignment adds stability. Use Table 5 as reference.
  3. **λ sweep**: Fix β=1.0, α=0.1 (placeholder), sweep λ ∈ {0.1, 0.5, 1.0, 2.0}. Plot FID vs. understanding score (e.g., GQA). Identify Pareto front. This reveals regularization strength sweet spot for your compute budget.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does InfoTok's effectiveness vary when applied to unified MLLMs with frozen visual-language backbones versus fully trainable fusion architectures?
- Basis in paper: [explicit] The paper notes in Analysis 2 that "InfoTok yields smaller gains on OpenUni [frozen VLM] but delivers substantial... improvements on Harmon... [trainable LLM]."
- Why unresolved: The authors suggest training signals from both tasks are necessary for IB regularization to shape the shared space, but they do not determine if modified regularization constraints could recover performance on frozen-backbone models.
- What evidence would resolve it: Ablation studies applying InfoTok to additional frozen-backbone unified models (e.g., variants of VILA-U) with adapted regularization targets.

### Open Question 2
- Question: Does the variational Gaussian assumption used in InfoTok limit performance when regularizing discrete visual tokenizers?
- Basis in paper: [inferred] The method models the variational posterior $q_\phi(\tilde{Z}|I)$ as a Gaussian, but Analysis 3 notes Show-o2 uses a "discrete tokenizer" and exhibits different performance trends than the continuous Harmon.
- Why unresolved: The theoretical formulation relies on continuous distributions (reparameterization trick), creating a potential mismatch when the underlying token space is fundamentally discrete.
- What evidence would resolve it: Comparative analysis of InfoTok against discrete IB formulations on discrete-token architectures like Show-o2.

### Open Question 3
- Question: How sensitive is the trade-off between image understanding and generation performance to the Lagrange multipliers ($\alpha, \beta$) in the InfoTok objective?
- Basis in paper: [inferred] The paper introduces $\alpha$ (alignment) and $\beta$ (sufficiency) to balance the objective (Eq. 5), but reports results primarily on fixed or implicitly tuned settings without analyzing sensitivity.
- Why unresolved: It is unclear if the observed "balance" is robust or if minor changes in hyperparameters would disproportionately favor one task (e.g., understanding) over the other.
- What evidence would resolve it: A sensitivity analysis plotting understanding and generation benchmark scores against varying values of $\alpha$ and $\beta$.

## Limitations
- The paper does not specify exact hyperparameter values (λ, α_u/α_g, β_u/β_g, InfoNCE temperature τ) or detailed architectural dimensions for projection heads and variational decoders, making faithful reproduction challenging without extensive hyperparameter tuning.
- The theoretical claims regarding the effectiveness of dual-task IB extensions and task-facing projections are novel and lack direct supporting evidence in the corpus, representing a potential overclaim.
- The paper does not provide a comprehensive ablation study on projection capacity or automated β tuning, leaving critical design choices underspecified.

## Confidence
- **High confidence**: The core mechanism of using IB regularization for compactness and sufficiency in shared tokenization is well-grounded in information theory and supported by experimental improvements across three MLLM models.
- **Medium confidence**: The extension to dual-task IB with task-facing projections is logically sound and shows gains, but lacks direct ablation evidence and has no clear corpus precedent.
- **Low confidence**: The paper does not provide sufficient detail on hyperparameter settings or architectural specifications to guarantee exact reproduction of reported results.

## Next Checks
1. **Hyperparameter sensitivity sweep**: Systematically vary λ (overall regularization weight) and β (compactness Lagrange multiplier) to identify optimal settings and verify that gains are not due to lucky initialization or overfitting.
2. **Projection capacity ablation**: Test different dimensionalities for task-facing projections f_u and f_g to determine if gains persist with minimal projection capacity, isolating the contribution of the IB mechanism versus increased model capacity.
3. **Negative sampling strategy analysis**: Vary the number and difficulty of negative samples in the InfoNCE alignment term to assess the robustness of contrastive alignment and identify failure modes from poor negative sampling.