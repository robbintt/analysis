---
ver: rpa2
title: Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area
  Index Forecasting
arxiv_id: '2511.20004'
source_url: https://arxiv.org/abs/2511.20004
tags:
- forecasting
- sundial
- lstm
- time
- foundation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether a pre-trained time series foundation
  model (Sundial) can outperform a task-specific supervised model (LSTM) for Leaf
  Area Index (LAI) forecasting without any task-specific tuning. Using the HiQ dataset
  (US, 2000-2022), they compare Sundial against statistical baselines, ARIMA, and
  a supervised LSTM across various input context window sizes.
---

# Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting

## Quick Facts
- arXiv ID: 2511.20004
- Source URL: https://arxiv.org/abs/2511.20004
- Authors: Peining Zhang; Hongchen Qin; Haochen Zhang; Ziqi Guo; Guiling Wang; Jinbo Bi
- Reference count: 7
- Primary result: Zero-shot Sundial outperforms supervised LSTM for LAI forecasting when input context windows span ≥2 full seasonal cycles

## Executive Summary
This paper investigates whether a pre-trained time series foundation model (Sundial) can outperform a task-specific supervised model (LSTM) for Leaf Area Index (LAI) forecasting without any task-specific tuning. Using the HiQ dataset (US, 2000-2022), they compare Sundial against statistical baselines, ARIMA, and a supervised LSTM across various input context window sizes. They find that Sundial, in a zero-shot setting, can surpass the supervised LSTM when given sufficiently long input context windows (covering more than one or two full seasonal cycles). At the largest tested window (1024 time steps), Sundial achieves RMSE of 0.140 and R² of 97.32%, outperforming LSTM's best performance of RMSE 0.143 and R² 97.34% at window size 64. This demonstrates that general-purpose foundation models can serve as effective "plug-and-play" forecasters in agricultural applications, potentially eliminating the need for resource-intensive task-specific training.

## Method Summary
The authors evaluate Sundial, a pre-trained time series foundation model, in a zero-shot setting against supervised baselines for LAI forecasting. They use the HiQ dataset covering CONUS from 2000-2022 with 5km resolution and 8-day temporal cadence. The study tests multiple input context window sizes (32 to 1024 timesteps) and forecast horizons (1 to 12 steps) using a sliding window approach. They implement a 2-layer LSTM with 64 hidden units as the supervised baseline and compare against statistical methods including persistence, linear interpolation, and ARIMA. Performance is evaluated using RMSE, R², MAE, MAPE, and CVRMSE metrics, with missing value handling through normalization and masking in loss computation.

## Key Results
- Sundial in zero-shot setting outperforms supervised LSTM when input context window covers more than one or two full seasonal cycles (T_in ≥ 512 timesteps)
- At T_in=1024, Sundial achieves RMSE 0.140 and R² 97.32%, surpassing LSTM's best performance (RMSE 0.143, R² 97.34%) at T_in=64
- Sundial shows substantially slower degradation for multi-step forecasting compared to LSTM
- Model demonstrates robustness to missing data, with RMSE increases of 12.8-57.1% depending on missing data ratio and window size

## Why This Works (Mechanism)

### Mechanism 1
Extended context windows enable foundation models to capture pixel-specific phenological signatures through in-context learning. Sundial treats the historical input window as a continuous context prompt, deducing underlying dynamics (seasonality, trend, anomalies) without weight updates. With T_in ≥ 512 (≈11 years), the model can observe multiple complete seasonal cycles, allowing it to identify site-specific patterns like drought responses that global models smooth over. Core assumption: The pre-training corpus contained sufficient seasonal/cyclical time series to encode transferable phenological priors. Break condition: Context window < 512 timesteps or application to pixels with <11 years of historical data.

### Mechanism 2
Instance-level adaptation in foundation models outperforms dataset-level generalization for heterogeneous spatial domains. Supervised LSTM learns "global average" patterns across training pixels, excelling when context is incomplete but failing to capture local anomalies. Sundial performs per-instance inference, using each pixel's unique history as context to construct a localized forecasting model on-the-fly. Core assumption: Heterogeneity across pixels is large enough that global averages are suboptimal; local context contains sufficient signal. Break condition: Highly homogeneous domains where global averages are near-optimal; or contexts where local anomalies dominate but history is unrepresentative.

### Mechanism 3
Foundation models retain long-range temporal structure more effectively than LSTMs for extended forecast horizons. LSTM hidden states degrade over long horizons due to sequential processing limits. Sundial's transformer-based architecture processes context holistically, preserving multi-scale temporal relationships for autoregressive multi-step generation. Core assumption: The foundation model's pre-training architecture supports long-range dependency capture better than 2-layer LSTM with 64 hidden units. Break condition: Very short horizons (H=1) where LSTM's compact learned representations match foundation model performance.

## Foundational Learning

- **In-Context Learning (ICL) for Time Series**
  - Why needed here: Sundial operates zero-shot by treating historical sequences as prompts, analogous to text prompts in LLMs. Understanding ICL explains why no fine-tuning is required and why context length matters critically.
  - Quick check question: Can you explain why a frozen model can adapt to new data distributions without gradient updates?

- **Seasonal Cycle Coverage**
  - Why needed here: LAI exhibits strong 8-day cadence seasonality. The paper shows that context windows must span ≥2 full cycles (~512 timesteps) for foundation models to infer pixel-specific phenology. Shorter windows leave models "under-informed."
  - Quick check question: Given 8-day temporal resolution, how many timesteps constitute one full annual seasonal cycle?

- **Zero-Shot Transfer vs. Supervised Generalization**
  - Why needed here: The core comparison is between a model that transfers pre-trained priors (Sundial) vs. one that learns from labeled data (LSTM). Understanding this tradeoff is essential for deployment decisions.
  - Quick check question: What types of domains might favor supervised training over zero-shot transfer, given the context window constraints identified?

## Architecture Onboarding

- **Component map**: Input Layer -> Sundial Backbone -> Output Layer
- **Critical path**: 
  1. Load HiQ dataset (CONUS subset, 5km resolution, 8-day cadence, 2000-2022)
  2. Normalize per-pixel using training-period mean/std
  3. Construct sliding windows with T_in ∈ {32, 64, 128, 256, 512, 1024} and H ∈ {1, 4, 8, 12}
  4. Pass context to Sundial checkpoint (publicly available, no modification)
  5. Generate autoregressive forecasts; mask missing values in loss computation

- **Design tradeoffs**:
  - Longer T_in improves Sundial performance monotonically but requires ≥11 years of history—limits applicability to data-sparse regions
  - LSTM excels at short windows (T_in=64) but degrades with longer context—better for short-history deployments
  - Sundial inference cost higher than lightweight LSTM baseline

- **Failure signatures**:
  - Context window too short (<512): Sundial underperforms LSTM significantly (RMSE 0.185 vs. 0.140 at T_in=64)
  - High missing data ratio (>20%): RMSE increases 12.8-25.6% depending on window size
  - Missing data at 40%: RMSE increases 36.7-57.1%

- **First 3 experiments**:
  1. **Baseline validation**: Replicate Table 1 results for your local HiQ subset—confirm RMSE crossover at T_in ≥ 512 before any customization.
  2. **Missing data stress test**: Apply Table 2 protocol (5%, 10%, 20%, 40% masking) on your target pixels to establish robustness bounds for your data quality.
  3. **Horizon scaling test**: Fix T_in=512 and sweep H ∈ {1, 4, 8, 12} to verify whether multi-step degradation matches Figure 5 patterns for your application horizon.

## Open Questions the Paper Calls Out
None

## Limitations
- Zero-shot advantage critically depends on having ≥512 timesteps (≈11 years) of history, substantially limiting applicability to regions with sparse historical records
- All experiments use a single dataset (HiQ, US, 5km resolution, 8-day cadence), with transferability to different crop types, geographic regions, or temporal resolutions unverified
- Specific architectural details of Sundial (number of layers, attention mechanisms, pre-training objectives) are not provided, limiting understanding of its superior long-range dependency capture

## Confidence
- **High Confidence**: Zero-shot Sundial outperforms supervised LSTM when T_in ≥ 512 timesteps; multi-step forecasting degradation is slower for Sundial than LSTM; missing data impacts are quantified and predictable
- **Medium Confidence**: Instance-level in-context learning is the mechanism for superior performance; pre-training corpus contained sufficient seasonal/cyclical patterns; performance generalizes to other agricultural time series
- **Low Confidence**: Sundial can serve as universal "plug-and-play" forecaster across all agricultural domains; context window requirement cannot be reduced through fine-tuning; performance maintains advantage with non-US or different resolution datasets

## Next Checks
1. **Fine-tuning Experiment**: Apply 1-2 epochs of supervised fine-tuning to Sundial with T_in=64. Compare whether fine-tuned performance matches or exceeds zero-shot performance at T_in=1024, determining if training resources can be substantially reduced while maintaining accuracy.

2. **Cross-Dataset Transfer**: Test Sundial on an independent LAI dataset from a different geographic region or crop type (e.g., European crop monitoring data). Measure zero-shot performance degradation and determine whether dataset-specific fine-tuning is required for practical deployment.

3. **Context Window Reduction Study**: Systematically test whether pre-training task modifications (e.g., masked seasonal reconstruction) can reduce the minimum effective context window from 512 to 256 or 128 timesteps, expanding applicability to regions with shorter historical records.