---
ver: rpa2
title: Conformal Prediction for Indoor Positioning with Correctness Coverage Guarantees
arxiv_id: '2505.01810'
source_url: https://arxiv.org/abs/2505.01810
tags:
- positioning
- indoor
- prediction
- conformal
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of uncertainty quantification
  and reliability in deep learning-based indoor positioning systems, where traditional
  methods struggle with poor generalization, overfitting, and lack of interpretability.
  The authors apply conformal prediction (CP) to transform model uncertainty into
  non-conformity scores, constructing prediction sets that provide statistical guarantees
  for correctness coverage.
---

# Conformal Prediction for Indoor Positioning with Correctness Coverage Guarantees

## Quick Facts
- arXiv ID: 2505.01810
- Source URL: https://arxiv.org/abs/2505.01810
- Reference count: 7
- Primary result: CP provides statistical guarantees for indoor positioning accuracy with up to 15% improvement in reliability compared to traditional uncertainty quantification methods.

## Executive Summary
This paper addresses the challenge of uncertainty quantification and reliability in deep learning-based indoor positioning systems, where traditional methods struggle with poor generalization, overfitting, and lack of interpretability. The authors apply conformal prediction (CP) to transform model uncertainty into non-conformity scores, constructing prediction sets that provide statistical guarantees for correctness coverage. They introduce conformal risk control for path navigation tasks to manage false discovery rate (FDR) and false negative rate (FNR), along with a conformal p-value framework to control the proportion of position-error points.

Experiments on the UJIIndoLoc dataset using lightweight models (MobileNetV1, VGG19, MobileNetV2, ResNet50, and EfficientNet) demonstrate that CP effectively approximates target coverage with up to 15% improvement in positioning reliability compared to traditional uncertainty quantification methods. The model achieved approximately 100% accuracy on training data and 85% on testing data, with EfficientNet showing superior performance through smaller prediction set sizes indicating greater certainty. The conformal prediction framework provides model-agnostic, distribution-free guarantees under exchangeability assumptions, enabling system designers to make precise reliability-accuracy trade-offs that were previously impossible in indoor positioning applications.

## Method Summary
The authors apply Split Conformal Prediction to indoor positioning, using lightweight CNNs trained on WiFi RSSI fingerprints from the UJIIndoLoc dataset. The framework computes Euclidean distance non-conformity scores between predicted and actual coordinates on a calibration set, then constructs prediction sets containing the true position with probability $1-\alpha$. For path navigation, they introduce conformal risk control to manage FDR and FNR by optimizing a threshold parameter. The system uses 70% training, 10% calibration, and 20% test data splits, with models trained from scratch using Adam optimizer (lr=1e-3, batch=512, 15 epochs) and MSE loss for coordinates.

## Key Results
- CP provides statistical coverage guarantees for indoor positioning, ensuring the true position is contained within prediction sets with probability $1-\alpha$
- EfficientNet achieved approximately 100% accuracy on training data and 85% on testing data, with superior performance through smaller prediction set sizes
- Conformal risk control framework successfully managed FDR and FNR for path navigation tasks
- CP improved positioning reliability by up to 15% compared to traditional uncertainty quantification methods
- The framework provides model-agnostic, distribution-free guarantees under exchangeability assumptions

## Why This Works (Mechanism)

### Mechanism 1: Finite-Sample Coverage via Quantile Regression
- **Claim:** The system provides a statistical guarantee that the true position is contained within the prediction set with probability $1-\alpha$, regardless of the underlying deep learning model's accuracy or the data distribution.
- **Mechanism:** The method utilizes Split Conformal Prediction. A held-out calibration set computes non-conformity scores (Euclidean distance between predicted and ground truth coordinates). The $1-\alpha$ quantile of these scores defines a threshold $\hat{q}$. During inference, this threshold constructs a prediction set (spatial region) around the model's estimate.
- **Core assumption:** Exchangeability: The joint distribution of calibration and test data must remain invariant under permutation. If WiFi signal distributions drift over time or due to environmental changes, this assumption degrades.
- **Evidence anchors:** [abstract]: "...CP transforms the uncertainty of the model into a non-conformity score, constructs prediction sets to ensure correctness coverage, and provides statistical guarantees." [section 3.1]: "This approach guarantees that the prediction sets satisfy the coverage condition in (1), irrespective of the model used or the unknown distribution of the data..." [corpus]: Related work Class Adaptive Conformal Training supports the general validity of CP frameworks for maintaining coverage guarantees in deep learning.
- **Break condition:** Severe distribution shift (e.g., furniture rearrangement or device change) between calibration and deployment that violates exchangeability, causing empirical coverage to drop below the target $1-\alpha$.

### Mechanism 2: Conformal Risk Control for Navigation
- **Claim:** For path navigation, the framework allows designers to explicitly bound the expected False Discovery Rate (FDR) or False Negative Rate (FNR) by optimizing a threshold parameter $\lambda$.
- **Mechanism:** This utilizes Conformal Risk Control. Instead of a binary prediction set, a loss function $L(\lambda)$ is defined (e.g., penalizing large errors on path points). A threshold $\hat{\lambda}$ is selected such that the empirical risk on the calibration set bounds the expected risk on test data by $\beta$.
- **Core assumption:** Monotonicity: The loss function must be non-increasing in $\lambda$ and right-continuous. Assumption: The loss function accurately captures the cost of navigation errors (e.g., MSE properly weights the severity of wrong turns).
- **Evidence anchors:** [abstract]: "We also introduce conformal risk control for path navigation tasks to manage the false discovery rate (FDR) and the false negative rate (FNR)." [section 3.2]: "By applying our conformal risk control framework, we can determine a threshold $\hat{\lambda}_{FDR}$ that guarantees $FDR(\hat{\lambda}_{FDR}) \le \beta_{FDR}$." [corpus]: Corpus evidence for this specific risk control mechanism is weak; neighbor papers focus on standard coverage.
- **Break condition:** Attempting to control FDR and FNR simultaneously with a single threshold, which the paper notes may be impossible, leading to conflicting threshold requirements.

### Mechanism 3: Uncertainty-Aware Model Selection
- **Claim:** The size of the prediction set serves as a reliable, model-agnostic metric for uncertainty, allowing system designers to select architectures (e.g., EfficientNet) that provide the tightest valid regions.
- **Mechanism:** While coverage (probability of containing truth) is fixed by $\alpha$, the efficiency (size of the set) depends on the base model's calibration. A model that generalizes better produces lower non-conformity scores on the calibration set, resulting in a smaller quantile threshold $\hat{q}$ and thus tighter prediction sets.
- **Core assumption:** Assumption: A smaller prediction set size strictly correlates with "superior performance" and higher certainty in the physical environment, implying the calibration set is representative of the operational domain.
- **Evidence anchors:** [abstract]: "EfficientNet showing superior performance through smaller prediction set sizes indicating greater certainty." [section 4.1.3]: "...size of the prediction set reflects the model's performance and indicates the degree of uncertainty." [corpus]: Feature Fitted Online Conformal Prediction discusses efficiency in time series, supporting the concept of adaptive set sizes.
- **Break condition:** A model is overconfident (overfitted) on the specific calibration split but fails in deployment; while coverage is statistically guaranteed, the sets might become large or unreliable in validity if the calibration split was an outlier.

## Foundational Learning

- **Concept: Exchangeability**
  - **Why needed here:** It is the minimal assumption required for the mathematical proof of the coverage guarantee. Without it, the quantile threshold calculated on past data has no statistical link to future test data.
  - **Quick check question:** If I collect WiFi data today for calibration and deploy the system next month after a new WiFi access point is installed, is the exchangeability assumption maintained?

- **Concept: Non-Conformity Score ($s_i$)**
  - **Why needed here:** This score translates the model's raw output (coordinates) into a measure of "strangeness" or error. Defining this correctly (e.g., Euclidean distance vs. probability margin) determines the shape and utility of the prediction set.
  - **Quick check question:** For indoor positioning, why is Euclidean distance often a better non-conformity score than simple classification probability?

- **Concept: Split Conformal Prediction**
  - **Why needed here:** This specific variant (vs. Full CP) is chosen for computational efficiency, requiring only a single pass over the calibration data, which is critical for real-time positioning.
  - **Quick check question:** What is the trade-off of using Split CP compared to Full CP regarding data usage and computational cost?

## Architecture Onboarding

- **Component map:** RSSI Vectors -> Lightweight CNN (EfficientNet/MobileNet) -> Coordinate Prediction ($\hat{x}, \hat{y}$) -> Euclidean Distance Calculation on Calibration Set -> Quantile Threshold ($\hat{q}$) -> Prediction Set Construction -> Output (C(X_test))

- **Critical path:**
  1. **Data Partitioning:** Strictly separate Training (70%), Calibration (10%), and Test (20%) sets to prevent data leakage.
  2. **Score Calculation:** Generate non-conformity scores using the trained model on the *unseen* calibration set.
  3. **Quantile Selection:** Compute the $\lceil (n+1)(1-\alpha) \rceil / n$ quantile of these scores.

- **Design tradeoffs:**
  - **$\alpha$ (Significance Level):** Lower $\alpha$ yields higher coverage (reliability) but larger prediction sets (lower precision).
  - **Model Selection:** EfficientNet minimizes set size (efficiency) while VGG19 may offer higher raw accuracy but with higher uncertainty (larger sets).
  - **FDR vs FNR:** In navigation, you must prioritize between avoiding wrong turns (FDR) or ensuring all correct paths are identified (FNR); you generally cannot minimize both simultaneously.

- **Failure signatures:**
  - **Conservative Sets:** Prediction sets cover the entire building. *Diagnosis:* Exchangeability violated or model is untrained.
  - **Coverage Collapse:** Empirical coverage < $1-\alpha$. *Diagnosis:* Calibration set too small or severe distribution shift.
  - **Empty Sets:** Model is overconfident; calibration scores were likely lower than test scores.

- **First 3 experiments:**
  1. **Baseline Coverage Check:** Train MobileNetV1 on UJIIndoLoc. Compute non-conformity scores on calibration split. Verify if test set coverage approximates $1-\alpha$ (e.g., 0.9).
  2. **Set Size Benchmark:** Compare EfficientNet vs. VGG19. Measure average prediction set size at fixed $\alpha$. Expect EfficientNet to yield smaller sets.
  3. **Risk Control Validation:** Implement conformal risk control for a path segment. Vary $\beta$ and observe the trade-off in FDR vs. FNR to find the operational sweet spot.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the conformal prediction framework perform when the exchangeability assumption is violated due to environmental changes, device heterogeneity, or temporal drift in indoor positioning scenarios?

## Limitations
- The framework relies on exchangeability between calibration and test data, which can be violated by real-world indoor environmental changes, potentially degrading coverage guarantees.
- Computational overhead of prediction set construction may be prohibitive for real-time positioning systems requiring high-frequency updates.
- Calibration set size sensitivity affects quantile threshold reliability, with limited calibration data leading to conservative or unreliable coverage guarantees.

## Confidence

**High Confidence Claims:**
- Split Conformal Prediction correctly implements finite-sample coverage guarantees under exchangeability assumptions
- EfficientNet demonstrates smaller prediction set sizes compared to VGG19, indicating better uncertainty calibration
- Calibration methodology for computing non-conformity scores is standard and well-established

**Medium Confidence Claims:**
- 15% improvement in positioning reliability versus traditional methods needs independent validation across different indoor environments
- Conformal risk control for FDR/FNR management works as described, though implementation details for navigation tasks are not fully specified
- Relationship between prediction set size and actual positioning error in physical space requires further empirical validation

**Low Confidence Claims:**
- Generalization of results to different indoor positioning datasets beyond UJIIndoLoc
- Real-time performance and computational feasibility in production systems with continuous data streams

## Next Checks

1. **Temporal Robustness Test:** Split the UJIIndoLoc dataset chronologically rather than randomly. Apply CP and measure coverage degradation to quantify sensitivity to temporal distribution shifts common in real deployments.

2. **Set Size vs. Error Correlation:** For each model, compute the correlation between prediction set size and actual positioning error on the test set. Verify whether smaller sets consistently correspond to lower error in physical coordinates, not just coverage metrics.

3. **Multi-Environment Generalization:** Train and validate the CP framework on at least two different indoor positioning datasets (e.g., UJIIndoLoc and another public dataset). Compare coverage guarantees and efficiency metrics to assess environmental generalization.