---
ver: rpa2
title: Artificial Intelligence (AI) and the Relationship between Agency, Autonomy,
  and Moral Patiency
arxiv_id: '2504.08853'
source_url: https://arxiv.org/abs/2504.08853
tags:
- moral
- agency
- systems
- agents
- autonomy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper critically examines the nature of agency in AI systems,
  arguing that while current AI exhibits sophisticated behaviors, it lacks genuine
  agency and autonomy. Through a systematic analysis of basic, autonomous, and moral
  agency, the authors demonstrate that AI systems operate within rigid pre-programmed
  boundaries rather than demonstrating true goal-directed behavior and environmental
  responsiveness.
---

# Artificial Intelligence (AI) and the Relationship between Agency, Autonomy, and Moral Patiency

## Quick Facts
- arXiv ID: 2504.08853
- Source URL: https://arxiv.org/abs/2504.08853
- Reference count: 16
- Primary result: Current AI systems lack genuine agency and autonomy despite sophisticated behaviors

## Executive Summary
This paper presents a critical examination of agency in AI systems, challenging common assumptions about their capabilities. Through systematic analysis of different types of agency - basic, autonomous, and moral - the authors argue that current AI systems operate within rigid pre-programmed boundaries rather than demonstrating true goal-directed behavior. The paper introduces a novel perspective by suggesting that moral agency and moral patiency could potentially be decoupled in future AI systems, challenging traditional philosophical frameworks.

The analysis has significant implications for how we understand and develop AI systems, suggesting the need for more nuanced frameworks for evaluating artificial agency. The authors emphasize that while AI exhibits sophisticated behaviors, it fundamentally lacks the autonomous decision-making capabilities that characterize genuine agency.

## Method Summary
The paper employs a philosophical analysis approach, examining the nature of agency through systematic evaluation of current AI capabilities. The authors develop a framework for understanding different types of agency (basic, autonomous, and moral) and apply this framework to analyze existing AI systems. They draw on established philosophical concepts while considering contemporary AI developments to reach their conclusions about the limitations of artificial agency.

## Key Results
- Current AI systems operate within pre-programmed boundaries rather than demonstrating true goal-directed behavior
- Traditional assumption that moral agency implies moral patiency is challenged
- Future AI systems could potentially achieve limited moral agency without consciousness

## Why This Works (Mechanism)
The paper's argument rests on distinguishing between sophisticated behavior and genuine agency. By establishing clear criteria for different types of agency and systematically applying these to current AI systems, the authors demonstrate that AI lacks the autonomous decision-making capabilities necessary for true agency. Their mechanism for understanding this involves analyzing how AI systems respond to their environment versus how they pursue independent goals.

## Foundational Learning
1. Basic Agency: The fundamental capacity for goal-directed behavior
   - Why needed: Establishes baseline requirements for agency
   - Quick check: Can the system pursue goals independently?

2. Autonomous Agency: The ability to make independent decisions
   - Why needed: Differentiates between programmed responses and autonomous choices
   - Quick check: Does the system operate beyond pre-defined parameters?

3. Moral Agency: The capacity to make ethical decisions
   - Why needed: Critical for understanding AI's potential moral status
   - Quick check: Can the system evaluate and respond to ethical considerations?

## Architecture Onboarding

Component Map:
Philosophical Framework -> Agency Types -> AI System Analysis -> Moral Implications

Critical Path:
1. Establish agency definitions
2. Apply to current AI systems
3. Analyze moral implications
4. Consider future possibilities

Design Tradeoffs:
- Theoretical rigor vs. practical applicability
- Current capabilities vs. future potential
- Philosophical tradition vs. technological innovation

Failure Signatures:
- Over-attributing agency to sophisticated behaviors
- Underestimating AI's potential for autonomous decision-making
- Conflating moral patiency with moral agency

First Experiments:
1. Analyze decision-making processes in current AI systems
2. Test system responses to novel scenarios
3. Evaluate goal-pursuit capabilities in constrained environments

## Open Questions the Paper Calls Out
None

## Limitations
- Relies heavily on philosophical frameworks rather than empirical demonstrations
- Does not fully address rapid advancements in AI technology
- Theoretical framework may not capture unique characteristics of modern AI systems

## Confidence
- Current AI agency claims: High
- Future AI capabilities: Medium
- Moral agency/patiency decoupling: Low
- Practical implications: Medium

## Next Checks
1. Examine recent developments in large language models and their capacity for autonomous goal-directed behavior
2. Investigate empirical studies on AI decision-making processes that go beyond pre-programmed boundaries
3. Analyze case studies of AI systems demonstrating unexpected or emergent behaviors in real-world applications