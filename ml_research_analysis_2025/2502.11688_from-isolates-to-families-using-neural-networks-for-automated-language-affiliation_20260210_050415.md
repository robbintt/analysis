---
ver: rpa2
title: 'From Isolates to Families: Using Neural Networks for Automated Language Affiliation'
arxiv_id: '2502.11688'
source_url: https://arxiv.org/abs/2502.11688
tags:
- language
- languages
- data
- affiliation
- families
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a neural network approach to automated language
  affiliation, classifying languages into families using lexical and grammatical data.
  The method uses Dolgopolsky sound classes to vectorize wordlists from Lexibank and
  grammatical features from Grambank, then trains feed-forward neural networks on
  known language families.
---

# From Isolates to Families: Using Neural Networks for Automated Language Affiliation

## Quick Facts
- arXiv ID: 2502.11688
- Source URL: https://arxiv.org/abs/2502.11688
- Reference count: 23
- Primary result: Neural networks achieved 87.75% balanced accuracy classifying 1,057 languages into 29 families using combined lexical-grammatical data

## Executive Summary
This study presents a neural network approach to automated language affiliation, classifying languages into families using lexical and grammatical data. The method uses Dolgopolsky sound classes to vectorize wordlists from Lexibank and grammatical features from Grambank, then trains feed-forward neural networks on known language families. The combined lexical-grammatical model achieved 87.75% balanced accuracy, outperforming lexical-only (83.73%) and grammatical-only (68.11%) models. The approach successfully identified deep genealogical relationships and provided preliminary classifications for linguistic isolates, though the authors emphasize this should complement rather than replace traditional comparative methods.

## Method Summary
The method converts lexical data from Lexibank into vector representations using Dolgopolsky sound classes, keeping only the first two consonants per word and one-hot encoding them. Grammatical features from Grambank are binary/ternary encoded and one-hot vectorized. These are concatenated and fed into a feed-forward neural network with two hidden layers (size = 4 × number of families), ReLU activation, weighted CrossEntropy loss, and Adam optimizer. The model is trained on 80% of data with stratified splitting and early stopping, evaluated using balanced accuracy across 29 families with ≥5 members each.

## Key Results
- Combined lexical-grammatical model achieved 87.75% balanced accuracy on 1,057 languages
- Outperformed lexical-only (83.73%) and grammatical-only (68.11%) models
- Correctly classified early-branching Indo-European subgroups and Sino-Tibetan languages
- When tested on four linguistic isolates, tended to classify them as unclassified, aligning with their uncertain status

## Why This Works (Mechanism)

### Mechanism 1: Sound Class Abstraction for Cross-Linguistic Comparison
- Claim: Converting phonetic segments to Dolgopolsky sound classes enables meaningful comparison across languages despite phonological variation over millennia.
- Mechanism: The 10 Dolgopolsky classes group sounds that frequently undergo sound changes together, reducing noise from superficial phonetic differences while preserving genealogical signal. Only the first two consonants are retained, prioritizing the most stable positions.
- Core assumption: Languages sharing cognate vocabulary will show higher similarity in their sound class distributions even after 5,000–8,000 years of divergence.

### Mechanism 2: Complementary Information from Lexical and Grammatical Data
- Claim: Combining lexical and grammatical data improves classification accuracy by capturing different aspects of language history.
- Mechanism: Lexical data captures genealogical inheritance better (cognates persist), while grammatical data reflects both inheritance and areal contact patterns; together they provide more robust classification signals through concatenation.
- Core assumption: The 4+ point improvement from combination (87.75% vs 83.73%) indicates the two sources provide partially non-overlapping information.

### Mechanism 3: Supervised Learning on Established Classifications
- Claim: Training on languages with known genealogical affiliations enables the model to learn implicit patterns that generalize to unclassified languages.
- Mechanism: The network learns distributional patterns in sound classes and grammatical features that correlate with family membership, then applies these to predict affiliations for held-out languages or historical data.
- Core assumption: Feature distributions characterizing language families are learnable from examples and generalize across time depths.

## Foundational Learning

- Concept: Sound Classes / Consonant Classes
  - Why needed here: The entire vectorization approach depends on understanding that phonetic sounds can be grouped by their likelihood of mutual change, enabling comparison across distantly related languages.
  - Quick check question: Why would comparing raw phonetic transcriptions fail to detect deep relationships, and how does sound class conversion address this?

- Concept: The Comparative Method in Historical Linguistics
  - Why needed here: The paper positions its work as complementary to traditional comparative linguistics; understanding the manual workflow clarifies what the network automates.
  - Quick check question: What distinguishes "proof of relationship" (affiliation) from subgrouping, and why does affiliation still lack formalization?

- Concept: Balanced Accuracy for Multi-Class Imbalanced Data
  - Why needed here: Evaluation uses balanced accuracy because families vary greatly in size; standard accuracy would be misleading.
  - Quick check question: Why would raw accuracy inflate performance when many languages belong to a few large families like Indo-European?

## Architecture Onboarding

- Component map: Lexibank -> Swadesh-100 concepts -> segments -> Dolgopolsky classes (10) -> first 2 consonants -> one-hot vectors -> concatenated (~2000-dim) -> Grambank -> 195 typological features -> binary/ternary -> one-hot (~390-dim) -> Combined: Concatenated (~2390-dim) -> 2 hidden layers (size = 4×29 families), ReLU, weighted CrossEntropy loss, Adam (lr=1e-3), batch 2048, early stopping at 500 epochs no improvement

- Critical path:
  1. Acquire CLDF-standardized data from Lexibank/Grambank
  2. Convert lexical forms: segment -> phonetic standardization -> Dolgopolsky class -> first 2 consonants -> one-hot
  3. Convert grammatical features to one-hot vectors
  4. Concatenate word vectors per language
  5. Train with 80/20 stratified split, weighted loss, early stopping
  6. Evaluate balanced accuracy per family

- Design tradeoffs:
  - First 2 consonants only: sacrifices information for robustness to sound change (per Dolgopolsky)
  - Combined vs lexical-only: Combined improves accuracy but limits coverage; lexical-only better when grammatical misleads (Uto-Aztecan)
  - Simple 2-layer architecture: fast, avoids overfitting on ~1000 languages

- Failure signatures:
  - Grammatical model classifying by areal patterns (Sinitic -> Hmong-Mien; Northern Uto-Aztecan -> Cariban)
  - Combined worse than lexical-only when grammatical data drags predictions down
  - Inconsistent isolate predictions across data sources

- First 3 experiments:
  1. Replicate baseline comparison on 1,057 languages: confirm combined (87.75%) > lexical (83.73%) > grammatical (68.11%)
  2. Ablate sound class depth: test 1 consonant vs 2 vs all segments to quantify robustness tradeoff
  3. Hold out entire family from training: measure whether model correctly predicts "unclassified" vs misassigns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can neural network models for language affiliation be made interpretable to identify which specific lexical items or grammatical features drive individual classification decisions?
- Basis in paper: [explicit] "This points also to the major drawbacks of the neural network approach, as it does not allow us to directly determine the concrete words or grammatical features that contribute to a particular decision."
- Why unresolved: The feed-forward architecture produces classifications without inherent mechanisms for feature attribution, limiting linguistic validation of model predictions.
- What evidence would resolve it: Integration of interpretability methods (e.g., attention mechanisms, SHAP values) that highlight which input features most influence specific language family assignments.

### Open Question 2
- Question: Why does grammatical data alone fail for certain language families (e.g., Uto-Aztecan at 10% accuracy) while performing adequately for others, and what determines this variability?
- Basis in paper: [explicit] "These dynamics remain understudied, and we lack further case studies to analyze the behavior of grammatical data in large-scale classification settings."
- Why unresolved: The authors observe that grammatical features may reflect areality rather than genealogy, but systematic patterns of failure across families are not explained.
- What evidence would resolve it: Comparative analysis correlating grammatical model accuracy with contact intensity, geographic isolation, and feature borrowing rates across families.

### Open Question 3
- Question: How can automated language affiliation methods be improved for small language families where training data is scarce?
- Basis in paper: [explicit] "Data for many small language families is scarce... All models showed that classification is much more difficult for small language families."
- Why unresolved: The supervised learning approach requires sufficient training examples per family, creating a fundamental data imbalance problem.
- What evidence would resolve it: Experiments with few-shot learning, data augmentation techniques, or transfer learning from well-documented families to under-resourced ones.

## Limitations

- Limited language coverage: The model trains on only 29 families with ≥5 members, excluding many smaller families and isolates
- Sound class effectiveness: No empirical validation that Dolgopolsky sound classes preserve genealogical signal in neural architectures over 5,000-8,000 years
- Grammatical data reliability: Cannot distinguish inherited from contact-induced grammatical patterns, leading to areal misclassifications

## Confidence

- High Confidence: Combined model accuracy (87.75%) outperforms lexical-only (83.73%) and grammatical-only (68.11%) on the 1,057-language test set; ability to correctly classify early-branching Indo-European subgroups
- Medium Confidence: Sound class vectorization preserves genealogical signal over deep time; grammatical data provides complementary information when not dominated by areal patterns; predictions for linguistic isolates align with their uncertain status
- Low Confidence: Effectiveness of Dolgopolsky sound classes specifically in neural networks; ability to distinguish inherited from contact-induced grammatical patterns; reliability of classifications for languages outside training data scope

## Next Checks

1. **Family Holdout Validation**: Systematically hold out entire language families from training and measure whether the model predicts "unclassified" versus misassigning to other families, testing generalization capability.

2. **Sound Class Ablation Study**: Compare model performance using 1 consonant vs 2 consonants vs all consonants in Dolgopolsky classes to quantify the robustness-information tradeoff and validate the truncation decision.

3. **Grammatical Feature Analysis**: Identify specific grammatical features driving areal misclassifications (e.g., Sinitic→Hmong-Mien) and test whether filtering features based on areal diffusion improves classification accuracy.