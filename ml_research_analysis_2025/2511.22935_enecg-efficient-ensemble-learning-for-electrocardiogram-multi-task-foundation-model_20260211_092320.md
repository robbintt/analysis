---
ver: rpa2
title: 'EnECG: Efficient Ensemble Learning for Electrocardiogram Multi-task Foundation
  Model'
arxiv_id: '2511.22935'
source_url: https://arxiv.org/abs/2511.22935
tags:
- ensemble
- tasks
- enecg
- performance
- multiple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EnECG is a lightweight ensemble framework that integrates multiple
  ECG foundation models using a Mixture-of-Experts gating network and LoRA-based fine-tuning
  to perform multi-task ECG analysis efficiently. The approach combines specialized
  models to capture diverse cardiac features while minimizing computational overhead,
  addressing the challenge of resource-intensive full fine-tuning of large-scale ECG
  models.
---

# EnECG: Efficient Ensemble Learning for Electrocardiogram Multi-task Foundation Model

## Quick Facts
- arXiv ID: 2511.22935
- Source URL: https://arxiv.org/abs/2511.22935
- Reference count: 31
- Primary result: Ensemble of frozen ECG foundation models with LoRA + MoE achieves strong multi-task ECG performance under 10 GB GPU memory and >10 samples/s throughput.

## Executive Summary
EnECG is a lightweight ensemble framework for multi-task electrocardiogram (ECG) analysis that combines multiple frozen foundation models using a Mixture-of-Experts gating network and LoRA-based fine-tuning. By freezing large ECG models and only adapting output layers with LoRA, EnECG achieves strong performance across five clinical tasks while maintaining low computational overhead. The approach addresses the challenge of resource-intensive full fine-tuning of large-scale ECG models, enabling efficient deployment in clinical settings.

## Method Summary
EnECG integrates five frozen ECG foundation models (TimesNet, DLinear, MOMENT, TEMPO, ECG-FM) through a Mixture-of-Experts gating network that produces ensemble weights based on sampled ECG leads. Each model receives a task-specific feedforward output layer, and LoRA is applied only to these new parameters (and optionally base model upper layers) for efficient adaptation. The final prediction aggregates individual model outputs weighted by the MoE gating network. The framework is trained on the MIMIC-IV-ECG dataset with 70/20/10 train/validation/test splits, targeting both clinical performance and computational efficiency.

## Key Results
- 38% improvement in RR interval estimation compared to baseline methods
- 76% accuracy in 15-class arrhythmia detection
- Maintains GPU memory usage below 10 GB while achieving inference speeds of over 10 samples per second

## Why This Works (Mechanism)
The framework works by leveraging the complementary strengths of multiple specialized ECG models while avoiding expensive full fine-tuning through LoRA adapters. The MoE gating network dynamically weights model contributions based on input characteristics, allowing the ensemble to capture diverse cardiac features more effectively than any single model. This approach maintains high performance while dramatically reducing computational requirements.

## Foundational Learning
- **MIMIC-IV-ECG dataset structure**: Contains 800,035 diagnostic ECGs from 161,352 patients; each recording is 10 seconds at 500 Hz across 12 leads. Why needed: Understanding input dimensions and task distribution is crucial for proper preprocessing and model adaptation.
- **LoRA (Low-Rank Adaptation)**: Parameter-efficient fine-tuning technique using low-rank decomposition (Î”W = BA) to update only a small subset of weights. Why needed: Enables adaptation of large models without full fine-tuning, maintaining computational efficiency.
- **Mixture-of-Experts (MoE) gating**: Neural network that selects and weights expert models based on input characteristics. Why needed: Dynamically combines model strengths and captures diverse cardiac features for improved ensemble performance.

## Architecture Onboarding
- **Component map**: MIMIC-IV-ECG -> Base Models (TimesNet, DLinear, MOMENT, TEMPO, ECG-FM) -> LoRA Adapters -> MoE Gating Network -> Ensemble Output
- **Critical path**: Input ECG -> Base Model Processing -> LoRA-Adapted Output Layers -> MoE Weight Generation -> Weighted Ensemble Prediction
- **Design tradeoffs**: Freezing base models preserves pre-trained knowledge but limits adaptation; LoRA balances efficiency with performance; MoE adds complexity but enables dynamic weighting.
- **Failure signatures**: Shape mismatches at ensemble stage, out-of-memory errors despite frozen base models, inconsistent task output dimensions.
- **Exactly 3 first experiments**:
  1. Verify all model outputs align correctly and MoE weights sum to one per sample using dummy labels
  2. Perform hyperparameter sweep on LoRA rank and MoE gating depth to achieve efficiency targets
  3. Compare ensemble performance to individual base models on RR interval estimation and arrhythmia detection

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Exact LoRA hyperparameters (rank, scaling, target modules, learning rate) are unspecified, requiring parameter search for reproduction
- MoE gating network architecture and lead sampling strategy details are omitted
- Label extraction pipelines for potassium abnormality and arrhythmia detection are approximated from clinical notes and labs

## Confidence
- **High** confidence in the conceptual validity of freezing foundation models and using LoRA+MoE for efficient multi-task learning
- **Medium** confidence in the specific performance figures due to missing training and hyperparameter details
- **Low** confidence in exact reproducibility without access to implementation code and complete LoRA/MoE settings

## Next Checks
1. Implement the pipeline with dummy labels to verify that all model outputs align correctly and that the MoE weights sum to one per sample
2. Perform a hyperparameter sweep on LoRA rank and MoE gating depth to see if reported efficiency (GPU memory, throughput) can be achieved
3. Compare ensemble performance to individual base models on a subset of tasks to confirm that gains in RR interval estimation and arrhythmia detection are reproducible