---
ver: rpa2
title: Disentangling Polysemantic Channels in Convolutional Neural Networks
arxiv_id: '2504.12939'
source_url: https://arxiv.org/abs/2504.12939
tags:
- channel
- channels
- concepts
- concept
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of interpreting convolutional\
  \ neural networks (CNNs) by tackling polysemantic channels\u2014those that encode\
  \ multiple unrelated concepts\u2014which hinder mechanistic interpretability. The\
  \ authors propose an algorithm to disentangle such channels into multiple monosemantic\
  \ channels, each responding to a single concept."
---

# Disentangling Polysemantic Channels in Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2504.12939
- Source URL: https://arxiv.org/abs/2504.12939
- Reference count: 29
- Primary result: Algorithm to disentangle polysemantic CNN channels into monosemantic channels, improving interpretability and feature visualization quality

## Executive Summary
This paper addresses the challenge of interpreting convolutional neural networks by tackling polysemantic channels—those that encode multiple unrelated concepts—which hinder mechanistic interpretability. The authors propose an algorithm to disentangle such channels into multiple monosemantic channels, each responding to a single concept. The method leverages the observation that different concepts within the same channel exhibit distinct activation patterns in the preceding layer. By restructuring weights in the CNN, the approach creates new channels that isolate individual concepts, enhancing interpretability and enabling clearer feature visualizations.

## Method Summary
The authors propose a method to identify and disentangle polysemantic channels in CNNs. They first identify candidate channels that respond to multiple classes using relevance metrics. For each candidate, they compute Average Relevance Vectors (ARVs) showing how preceding layer channels contribute to activation for different classes. Low cosine similarity between ARVs indicates polysemanticity. The disentanglement process inserts a new intermediate layer with three channels per polysemantic channel: two for the isolated concepts (created by selectively zeroing weights based on concept-specific relevance) and one residual channel (connected with weight -1) to preserve original functionality. The method is demonstrated on a ResNet-50 trained on ImageNet.

## Key Results
- Disentangled channels produce more interpretable feature visualizations compared to original polysemantic channels
- Quantitative analysis shows disentangled channels accurately mimic original channel's activation for one concept while suppressing the other
- Residual channel shows minimal activation (~0%), indicating minimal information loss during disentanglement
- Method successfully isolates distinct concepts like "digital clock" and "cauliflower" that were originally encoded in the same channel

## Why This Works (Mechanism)

### Mechanism 1: γ-Polysemanticity Identification via Preceding Layer Activation Patterns
- **Claim**: Polysemantic channels can be identified by comparing how they receive information from the previous layer across different classes.
- **Mechanism**: The method computes Average Relevance Vectors (ARV) that capture how each channel in layer l-1 contributes to activating a target channel in layer l for images from a specific class. Low cosine similarity between ARVs for different classes indicates the channel responds to distinct concepts rather than a shared one.
- **Core assumption**: Superposition preferentially occurs in sparse configurations where unrelated concepts rarely co-occur, AND semantically distinct concepts will exhibit different activation pathways in preceding layers.
- **Evidence anchors**:
  - [abstract]: "utilizing that different concepts within the same channel exhibit distinct activation patterns in the previous layer"
  - [section 3.1]: "polysemanticity can be caused by superposition, which preferably occurs in sparse configurations...scenario (2) (polysemanticity) occurs predominantly if relevant channel activations in l-1 are different for images from t1 and t2"
  - [corpus]: Limited direct corpus support; neighbor paper on Polysemanticity Index uses clustering-based approach rather than inter-layer analysis
- **Break condition**: Method may produce false positives when unrelated concepts coincidentally share similar activation pathways, or false negatives when semantically related concepts (e.g., dog breeds) have different ARVs despite sharing a concept.

### Mechanism 2: Selective Weight Masking for Concept Isolation
- **Claim**: Zeroing weights responsible for one concept creates channels that respond selectively to a single concept.
- **Mechanism**: For each channel i in layer l-1, compare its relevance to both concepts using a ρ-weighted threshold (Ineq. 5). If channel i is primarily relevant for concept 2, zero its connection to the new channel meant to detect concept 1. This surgically removes activation pathways for unwanted concepts.
- **Core assumption**: Input×Gradient attribution correctly identifies which preceding channels contribute to each concept, AND linear weight manipulation suffices to isolate non-linearly learned concepts.
- **Evidence anchors**:
  - [section 3.2]: "we first set weights from l-1 to the weights originally going from l-1 to c...we have now deleted the connections to channels in l-1 that contribute to detecting concept 2"
  - [Table 1]: Disentangled channels show 114%/125% relative activation for target concepts versus -9%/-21% for non-target concepts
  - [corpus]: Concurrent work (PURE, cited as [5]) uses "virtual" disentanglement without explicit weight restructuring, limiting comparability
- **Break condition**: Method fails when attribution incorrectly assigns relevance, when concepts share many common pathways, or when nonlinear feature interactions cannot be captured by linear masking.

### Mechanism 3: Residual Channel for Function Preservation
- **Claim**: A negatively-weighted residual channel prevents double-encoding while preserving original network function.
- **Mechanism**: Features not exclusively associated with either concept get encoded in both disentangled channels. The residual channel keeps only ambiguous weights and connects with weight -1, subtracting double-counted information to recover the original channel's exact activation.
- **Core assumption**: Features not exclusively associated with either concept represent shared information that should only contribute once.
- **Evidence anchors**:
  - [section 3.2]: "the third channel is connected to the original channel c in layer l with a weight of −1, it accounts for this double encoding"
  - [Table 1]: Residual channel shows ~0% activation for both concepts, confirming minimal unique information
  - [corpus]: No direct corpus support for this specific architectural pattern
- **Break condition**: If genuinely important shared features exist, the residual subtraction may discard useful information.

## Foundational Learning

- **Concept: Input×Gradient Attribution**
  - Why needed here: Core method (Eq. 1) for computing how preceding layer channels contribute to target channel activation.
  - Quick check question: Why does multiplying activation by gradient capture relevance rather than using gradient alone?

- **Concept: Cosine Similarity in High-Dimensional Spaces**
  - Why needed here: Used to quantify ARV pattern differences; γ threshold determines polysemanticity classification.
  - Quick check question: What does cosine similarity of 0.47 (channel #1660's ARVs) indicate about the relationship between "digital clock" and "cauliflower" activation pathways?

- **Concept: Weight Masking vs. Weight Learning**
  - Why needed here: Disentanglement uses hard weight zeroing rather than fine-tuning; understanding this distinction is critical.
  - Quick check question: How does zeroing weights based on attribution differ from training new concept-specific filters?

## Architecture Onboarding

- **Component map**:
  Original: layer l-1 → layer l (contains polysemantic channel c)
  Modified: layer l-1 → layer l' (new intermediate layer with 3 channels) → layer l
  l' channels: disentangled_1, disentangled_2, residual (connects to l with weight -1)
  All other channels in l' connect via identity to l

- **Critical path**:
  1. Identify candidate channels via class relevance (Ineq. 2 with τ=0.03, p=0.75)
  2. Compute ARVs for relevant class pairs (Eq. 3)
  3. Apply γ-polysemanticity test (Ineq. 4 with γ=0.5)
  4. Auto-select ρ via activation ratio maximization (Eq. 6)
  5. Construct l' with masked weights per Ineq. 5
  6. Validate on held-out images via density plots

- **Design tradeoffs**:
  - Higher γ → more inclusive but more false positives
  - Last layer focus → cleaner semantics but limited to high-level features (method "may work better in later layers")
  - Input×Gradient vs. LRP/IG → simpler but potentially less accurate
  - Automatic ρ selection → data-dependent, may overfit to training distribution

- **Failure signatures**:
  - Disentangled channels activate similarly for both concepts (ρ too low or attribution failed)
  - Large residual activations indicate poor concept separation
  - MACO visualizations show mixed concepts (observed: "some cauliflower patterns still lightly visible")
  - Performance drop on downstream tasks suggests over-pruning

- **First 3 experiments**:
  1. Replicate channel #1660 disentanglement; plot activation density distributions for digital clock and cauliflower images across original and disentangled channels.
  2. Vary γ (0.3, 0.5, 0.7) and measure correlation between ARV cosine similarity and WordNet path similarity to validate semantic meaningfulness.
  3. Apply to an earlier convolutional layer (e.g., ResNet-50 layer3) and compare feature visualization clarity; expect reduced effectiveness due to less semantically-aligned concepts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the disentanglement method be effectively extended to handle channels responding to more than two concepts via recursive application?
- Basis in paper: [explicit] The conclusion states the method is "Currently only applied to the common form of disentanglement of two concepts," and anticipates it is "easily extendable to more classes, e.g., through a recursive application."
- Why unresolved: The authors currently only validate the two-concept case; the recursive extension is proposed but not yet implemented or tested.
- What evidence would resolve it: Successful qualitative and quantitative disentanglement results on channels identified as relevant for three or more distinct classes.

### Open Question 2
- Question: How can the hyperparameters ($\tau$, $\gamma$, and $p$) be set automatically rather than relying on handpicked values?
- Basis in paper: [explicit] The conclusion identifies that future work could explore "potential methods for setting them automatically," as they are currently "highly application-specific."
- Why unresolved: The current work relies on manual selection based on domain knowledge (e.g., WordNet similarity) to establish a proof of concept.
- What evidence would resolve it: An algorithm or heuristic that sets these parameters dynamically while maintaining or improving the specificity of disentangled channels.

### Open Question 3
- Question: Does the reliance on class labels for identifying polysemanticity limit the method's applicability to earlier layers where features are less semantic?
- Basis in paper: [explicit] The conclusion notes the "formulation of polysemanticity is based on class labels," leading to the assumption that the method "may work better in later layers."
- Why unresolved: The experiments focused on the penultimate layer, leaving the performance on earlier, less semantically defined layers unexplored.
- What evidence would resolve it: Analysis of disentanglement quality in intermediate layers (e.g., mid-level ResNet blocks) where concepts may not map cleanly to ImageNet classes.

## Limitations

- Method assumes superposition occurs in sparse configurations where unrelated concepts rarely co-occur - this may not hold for all architectures or datasets
- Input×Gradient attribution may incorrectly identify relevance patterns, especially for nonlinearly interacting concepts
- Automatic ρ selection could overfit to training distribution without guarantees of generalization
- No quantitative evaluation of how disentanglement affects downstream task performance

## Confidence

- Medium confidence: Mechanism 1 (γ-polysemanticity identification) - limited direct corpus support
- Medium confidence: Mechanism 2 (selective weight masking) - concurrent work uses different approaches
- High confidence: Mechanism 3 (residual channel preservation) - straightforward implementation with clear validation

## Next Checks

1. Test disentanglement on an earlier convolutional layer (layer3) and compare feature visualization clarity to the last layer; expect reduced effectiveness due to less semantically-aligned concepts
2. Vary γ threshold (0.3, 0.5, 0.7) and measure correlation between ARV cosine similarity and WordNet path similarity to validate semantic meaningfulness of polysemanticity detection
3. Apply disentanglement to a ResNet-50 trained on a different dataset (e.g., CIFAR-10) to assess method robustness across data distributions and semantic granularities