---
ver: rpa2
title: 'Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch
  Pipeline'
arxiv_id: '2502.06888'
source_url: https://arxiv.org/abs/2502.06888
tags:
- experts
- layer
- inference
- expert
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Klotski is an efficient inference engine for Mixture-of-Experts
  (MoE) models that addresses the challenge of deploying large MoE models in resource-constrained
  environments. It proposes an expert-aware multi-batch pipeline paradigm that minimizes
  pipeline bubbles by orchestrating multi-batch computations based on the heterogeneous
  computation and I/O requirements of hot and cold experts.
---

# Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline

## Quick Facts
- **arXiv ID**: 2502.06888
- **Source URL**: https://arxiv.org/abs/2502.06888
- **Reference count**: 40
- **One-line primary result**: Klotski achieves up to 85.12x higher throughput than state-of-the-art techniques for MoE inference.

## Executive Summary
Klotski is an inference engine for Mixture-of-Experts models that addresses the challenge of deploying large MoE models in resource-constrained environments. It introduces an expert-aware multi-batch pipeline paradigm that minimizes pipeline bubbles by orchestrating multi-batch computations based on the heterogeneous computation and I/O requirements of hot and cold experts. By prioritizing hot experts and overlapping their computation with cold expert transfers, Klotski achieves significant throughput improvements while maintaining low latency.

## Method Summary
Klotski proposes an expert-aware multi-batch pipeline that partitions computations by experts rather than batches, prioritizing hot experts to minimize pipeline bubbles. The system measures hardware-specific compute and transfer times to determine an optimal batch group size n through inequality constraints. A correlation-aware prefetcher identifies hot experts using activation path history, enabling prefetch during attention computation. The execution runtime manages four CUDA streams (weight prefetch, expert transfer, KV cache prefetch, KV cache store) synchronized at key points. The approach combines adaptive tensor placement, 4-bit quantization, and expert correlation tables to achieve near-bubble-free execution.

## Key Results
- Achieves up to 85.12x higher throughput compared to state-of-the-art techniques
- Maintains 58.89% accuracy in hot expert prediction while achieving significant gains
- Demonstrates effectiveness on Mixtral-8x7B and Mixtral-8x22B models with resource-constrained hardware

## Why This Works (Mechanism)

### Mechanism 1: Expert-Aware Multi-Batch Pipeline Orchestration
Partitioning computations by experts (not batches) and prioritizing hot experts minimizes both inter-layer and intra-layer pipeline bubbles. While computing attention across multiple batches, prefetch only the gate and K hot experts. After gate computation, reorder expert computations: hot experts first (already prefetched), then cold experts in transfer order. This overlaps the high I/O demand of cold experts with the high compute demand of hot experts. Core assumption: A small number of "hot" experts handle the majority of tokens across multiple batches, and their activation patterns are predictable or discoverable.

### Mechanism 2: Constraint-Sensitive I/O-Compute Planning via Inequality Constraints
Computing the minimum batch group size n that satisfies four overlapping inequalities yields a near-bubble-free pipeline without excessive KV cache. The planner measures hardware-specific compute (t_c_A, t_c_G, t_c_E) and transfer (t_I/O_A, t_I/O_G, t_I/O_E) times, then solves inequalities to find the smallest integer n ensuring: (I) gate weights ready before gate compute, (II) hot experts ready before hot expert compute, (III) cold experts ready before cold expert compute, (IV) next attention weights ready before next attention compute. Core assumption: I/O and compute times are stable and measurable for a given hardware/model/batch configuration.

### Mechanism 3: Correlation-Aware Expert Prefetcher Using Activation Path History
Recording expert activation correlations across layers during warmup and updating them online enables accurate hot expert identification. During pre-run, record frequency relationships between experts activated at layer i and layer i+1 into a correlation table. At inference, for each token, look up expert tendency based on previous l layers' selections, aggregate across all tokens in the batch group, and prefetch top-K experts. Update table during inference to adapt to task-specific patterns. Core assumption: Expert selection exhibits cross-layer correlation patterns that persist within a task.

## Foundational Learning

### Concept: Pipeline Bubbles (Inter-layer vs Intra-layer)
Why needed: Klotski's central claim is bubble minimization; understanding that inter-layer bubbles occur between attention and MoE layers (due to I/O > compute for attention), while intra-layer bubbles occur within expert layers (due to I/O > compute per expert), is prerequisite to grasping the solution.
Quick check: On a system where single expert transfer takes 21ms and attention compute takes 2.6ms (Mixtral-8×7B on RTX 3090), which bubble type dominates if you only prefetch the full MoE layer during attention?

### Concept: Hot/Cold Expert Distribution
Why needed: The paradigm exploits asymmetric expert utilization; without this phenomenon, the hot-first reordering strategy would not provide computational overlap for cold expert I/O.
Quick check: If experts 1 and 3 handle 53.7% of tokens in a layer (as in Mixtral layer 14), and you have 8 batches each with top-2 routing, how many tokens approximately will hot experts 1 and 3 process combined?

### Concept: CUDA Stream Overlap and Asynchrony
Why needed: Klotski orchestrates four CUDA streams (weight prefetch, expert transfer, KV cache prefetch, KV cache store); understanding that streams enable concurrent execution is necessary to implement the paradigm.
Quick check: If the weight prefetch stream is slower than expected due to PCIe contention, which synchronization point in Algorithm 1 would cause a GPU stall first?

## Architecture Onboarding

### Component map:
Adaptive Tensor Placement -> Constraint-Sensitive I/O-Compute Planner -> Correlation-Aware Expert Prefetcher -> Expert-Aware Multi-Batch Pipeline Paradigm -> Execution Runtime

### Critical path:
1. Offline: Load model, measure compute/I/O times, cache measurements locally
2. Offline/Warmup: Build initial expert correlation table via pre-run on sampled data
3. Online request: Planner computes optimal n from cached measurements + constraints
4. Online execution: For each layer, attention computes across n batches while prefetching gate + K hot experts; gate computes; experts compute in hot-first, transfer-order sequence
5. Online update: Expert correlation table updated with actual selections

### Design tradeoffs:
- Larger n → better I/O overlap but larger KV cache memory pressure; planner finds minimum viable n
- Correlation path length l → higher l improves prediction but increases table lookup complexity and memory; paper uses l=1
- Quantization (4-bit HQQ) → reduces I/O time, enabling smaller n, but adds dequantization overhead; minimal throughput impact per experiments
- Prefetch accuracy vs. robustness → Klotski does not rely on perfect accuracy (58.89% achieved); multi-batch overlap provides redundancy

### Failure signatures:
- **OOM with large batch size**: KV cache exceeds VRAM; n was computed but batch size too large; reduce n or enable sparse attention
- **Low throughput despite correct n**: PCIe bandwidth saturation or thermal throttling causes measured times to drift; re-profile hardware
- **High intra-layer bubbles**: Hot expert prediction consistently wrong; correlation table stale or input distribution shifted; trigger warmup re-run
- **High inter-layer bubbles**: Gate weights not ready in time; inequality (4) violated; increase n or check DRAM→VRAM bandwidth

### First 3 experiments:
1. **Baseline profiling**: Run Mixtral-8x7B with batch_size=4, n=15 on RTX 3090; measure throughput, verify pipeline via profiler (should show minimal bubbles per Figure 15b); compare against simple overlap baseline
2. **Ablation: n sensitivity**: For batch_size ∈ {4, 8, 16, 32}, compute optimal n via planner, then sweep n from 3 to 15; plot throughput to validate inequality constraints predict the plateau region
3. **Prefetch accuracy vs. throughput**: Disable expert correlation prefetcher (random hot expert selection); measure throughput drop; then vary l ∈ {1, 2, 4} and measure both accuracy and throughput to confirm robustness claim

## Open Questions the Paper Calls Out

### Open Question 1
How can a generalized sparse KV cache strategy be developed to eliminate the new bubbles introduced by massive KV cache loads in multi-batch attention layers? The paper aims to address this in future work by developing a generalized and efficient sparse KV cache strategy for Klotski, noting that massive KV caches currently create bubbles within attention computations. As the number of batches (n) increases to reduce MoE bubbles, the corresponding linear growth in KV cache introduces new loading costs that stall the pipeline.

### Open Question 2
How does Klotski's performance degrade under adversarial inputs or domain shifts where the "hot expert" assumption fails and expert selection follows a uniform distribution? The paper analyzes a "worst-case scenario" where all tokens select cold experts, rendering prefetching ineffective, but dismisses the probability as "very low" without empirical testing of such distributions. The constraint-sensitive planner (Eq. 4-7) relies on t_hot_E > 0 to overlap I/O; if hot experts do not exist (uniform access), the inequalities fail, potentially destroying throughput.

### Open Question 3
Can the I/O-compute planner be made dynamic to adjust the batch group size (n) on a layer-by-layer basis rather than relying on a global static value? The paper determines n using inequalities that depend on static measurements of computation and I/O times, yet notes that the "queue Q of activated experts... is not fixed." A static n optimized for the heaviest layer may be suboptimal for layers with fewer activated experts or different computation/I/O ratios, wasting memory or creating latency.

## Limitations
- Heavy reliance on consistent hot expert patterns across multiple batches (58.89% prefetch accuracy)
- Hardware measurement dependency that may break with thermal throttling or PCIe variability
- Task-specific expert correlation tables without validation across diverse workloads

## Confidence

**High confidence**: The pipeline bubble characterization and basic multi-batch computation framework are well-supported by experimental results. The hardware measurement and inequality constraint approach appears sound.

**Medium confidence**: The hot/cold expert orchestration mechanism is logically coherent but depends on the critical assumption that hot expert patterns remain stable across batches. The 58.89% prefetch accuracy, while sufficient for claimed gains, represents a significant source of variability.

**Low confidence**: The generalization of expert correlation tables across different tasks and the long-term stability of the online update mechanism are not thoroughly validated. The paper doesn't address catastrophic failure modes when correlation patterns suddenly change.

## Next Checks

1. **Distribution Shift Robustness Test**: Run the same model with progressively diverse input corpora (news articles, code, medical texts) and measure how hot expert prediction accuracy and throughput degrade. This validates whether the 58.89% accuracy is task-specific or generalizable.

2. **Hardware Variability Stress Test**: Simulate thermal throttling and PCIe contention by running concurrent memory-intensive processes while measuring actual I/O times versus planned times. Track how often the computed n becomes suboptimal and measure the resulting bubble increase.

3. **Batch Diversity Sensitivity Analysis**: Generate synthetic batches with varying expert activation patterns (some with concentrated hot experts, others with uniform activation) and measure throughput across this spectrum. This reveals the mechanism's sensitivity to the underlying hot/cold distribution assumption.