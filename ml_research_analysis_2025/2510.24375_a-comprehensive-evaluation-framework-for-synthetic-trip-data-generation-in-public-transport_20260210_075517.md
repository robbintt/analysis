---
ver: rpa2
title: A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in
  Public Transport
arxiv_id: '2510.24375'
source_url: https://arxiv.org/abs/2510.24375
tags:
- data
- synthetic
- privacy
- real
- utility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a comprehensive Representativeness-Privacy-Utility\
  \ (RPU) framework to evaluate synthetic public transport trip data generation. The\
  \ framework assesses data quality across three dimensions\u2014representativeness,\
  \ privacy, and utility\u2014and three hierarchical levels: record, group, and population."
---

# A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport

## Quick Facts
- arXiv ID: 2510.24375
- Source URL: https://arxiv.org/abs/2510.24375
- Reference count: 17
- Primary result: Introduces a Representativeness-Privacy-Utility framework to benchmark 12 generative models for public transport synthetic data, finding no single model excels across all dimensions.

## Executive Summary
This study develops a comprehensive evaluation framework for synthetic public transport trip data generation, addressing the critical need to balance data utility with privacy protection. The framework assesses synthetic data across three dimensions—representativeness (how well it mirrors real data), privacy (protection against re-identification), and utility (performance on downstream tasks)—at three hierarchical levels (record, group, and population). Using Hong Kong MTR smart card data, the authors benchmark 12 generative models including statistical approaches (Bayesian Networks, Gaussian Mixture Models), deep generative models (CTGAN, WGAN-GP, VAE, Diffusion), and privacy-enhanced variants. Results reveal inherent trade-offs: while some models excel at representativeness, they often compromise privacy, and vice versa. CTGAN emerged as the most balanced performer, offering strong results across all three dimensions.

## Method Summary
The study evaluates synthetic trip data generation using a Representativeness-Privacy-Utility (RPU) framework applied to Hong Kong MTR Octopus card data. The data includes anonymized passenger IDs, origin-destination pairs, start/end times, and day of week for approximately 140,000 trips. The evaluation employs 12 generative models spanning statistical approaches (Bayesian Networks, GMM, Copula), deep generative models (CTGAN, WGAN-GP, VAE, Diffusion, Flows, LLM), and privacy-enhanced variants (Priv-BN, PATE-GAN). Representativeness is measured using Jensen-Shannon Divergence, Earth Mover's Distance, and Kullback-Leibler Divergence on marginal and conditional distributions, plus logical consistency checks. Privacy is assessed via Membership Inference Attacks using Random Forest classifiers and k-NN distance ratios. Utility is evaluated through Train-on-Synthetic-Test-on-Real (TSTR) tasks using Gradient Boosting Regressors and clustering similarity metrics. All models are evaluated at record, group, and population levels with normalized scoring for comparison.

## Key Results
- No single model excels across all three RPU dimensions, revealing inherent trade-offs between privacy and utility
- CTGAN achieves the most balanced performance, ranking in the top tier for representativeness, privacy, and utility simultaneously
- Standard statistical models (Bayesian Network, GMM) show strong representativeness but poor privacy protection
- Privacy-enhanced models (PATE-GAN, Priv-BN) improve privacy but significantly degrade utility
- Diffusion models struggle with the dataset due to one-hot encoded features being incompatible with Gaussian noise assumptions

## Why This Works (Mechanism)
The RPU framework works by systematically decomposing the synthetic data evaluation problem into three orthogonal dimensions, each capturing a distinct aspect of data quality. Representativeness ensures the synthetic data preserves the statistical properties and logical constraints of real trip patterns. Privacy protection prevents attackers from distinguishing between real and synthetic records, protecting individual privacy. Utility guarantees that downstream analytical tasks (like demand prediction or anomaly detection) perform effectively on synthetic data. By evaluating at record, group, and population levels, the framework captures both micro-level fidelity and macro-level distributional accuracy, providing a comprehensive assessment that single-dimension evaluations cannot achieve.

## Foundational Learning
- **Smart Card Data Preprocessing:** Converting timestamps to "minutes past midnight" and applying one-hot encoding to categorical variables is essential for model compatibility and meaningful distance calculations in privacy metrics.
  - *Why needed:* Raw timestamp formats and categorical station names must be transformed into numerical representations that models can process while preserving temporal and spatial relationships.
  - *Quick check:* Verify that generated synthetic data maintains valid time sequences (start time < end time) and that station encodings preserve spatial relationships.

- **Membership Inference Attack (MIA):** Using a Random Forest classifier to distinguish between real training data and synthetic data serves as a proxy for memorization and privacy leakage.
  - *Why needed:* Direct measurement of privacy risk is impossible; MIA provides an empirical estimate of how much a model has memorized training examples.
  - *Quick check:* Plot KDE curves comparing distances between synthetic data and training vs. holdout sets; significant overlap indicates poor privacy.

- **Train-on-Synthetic-Test-on-Real (TSTR):** Training predictive models on synthetic data and evaluating on real data quantifies the practical utility loss from using synthetic instead of real data.
  - *Why needed:* This approach measures the end-to-end impact of synthetic data generation on real analytical tasks without requiring access to sensitive real data during evaluation.
  - *Quick check:* Compare prediction accuracy on real data when trained on synthetic vs. real training sets; smaller degradation indicates better utility preservation.

## Architecture Onboarding

**Component Map:** Data Preprocessing -> Model Training -> RPU Evaluation -> Result Aggregation

**Critical Path:** The evaluation pipeline follows a sequential flow where properly preprocessed data must be fed into generative models, which then produce synthetic data that undergoes comprehensive RPU assessment before final comparison and ranking.

**Design Tradeoffs:** The framework balances comprehensiveness against computational cost. Including 12 diverse models provides broad coverage but requires significant computational resources. The three-level evaluation provides granularity but multiplies the number of metrics to compute. The choice of MIA over more sophisticated privacy attacks favors practicality over completeness.

**Failure Signatures:** 
- High distributional similarity with low MIA scores suggests the model has learned general patterns rather than memorizing specific instances
- Invalid time sequences or impossible origin-destination pairs indicate preprocessing or model architecture issues
- CTGAN's strong performance across all dimensions suggests deep generative models with proper categorical handling can achieve better trade-offs than pure statistical or privacy-enhanced approaches

**First Experiments:**
1. Preprocess a small subset of smart card data using the specified timestamp conversion and one-hot encoding pipeline to verify data compatibility
2. Train a basic Bayesian Network and CTGAN on the preprocessed data to establish baseline and benchmark performance
3. Implement the MIA evaluation (Algorithm 1) using a Random Forest classifier to assess privacy protection levels across different models

## Open Questions the Paper Calls Out
- Can hybrid architectures that explicitly integrate statistical components with deep generative networks achieve a superior balance of Representativeness, Privacy, and Utility compared to pure deep learning models?
- Do the observed trade-offs between privacy and utility remain consistent when the RPU framework is applied to transport datasets containing more sensitive personal information or different network structures?
- How does the performance ranking of generative models change when the evaluation includes a more exhaustive set of privacy attack vectors and domain-specific utility tasks?

## Limitations
- Framework validation is limited to a single real-world dataset (Hong Kong MTR), potentially limiting generalizability to different transit systems or geographic contexts
- Several deep generative models are described as "customized" without complete architectural specifications, hindering exact reproduction
- Privacy evaluation relies primarily on Membership Inference Attacks, which may not capture all practical privacy vulnerabilities like attribute inference or re-identification attacks

## Confidence
- **High Confidence:** The RPU framework structure and core methodology for calculating representativeness and utility metrics are clearly specified and reproducible
- **Medium Confidence:** Relative model rankings within the tested dataset are reliable, but generalizability across different transit datasets requires validation
- **Medium Confidence:** Privacy evaluation methodology is sound, but the specific threat model (MIA) may not represent all practical privacy concerns

## Next Checks
1. Apply the RPU framework to a different public transit dataset (e.g., London Oyster or New York MetroCard) to assess generalizability of model rankings
2. Request complete architectural details for the "customized" deep generative models, particularly MLP structures in Diffusion models and specific LLM implementations
3. Supplement MIA evaluation with attribute inference attacks and k-anonymity/differential privacy guarantees to provide more comprehensive privacy assessment