---
ver: rpa2
title: Deep Learning-based Scalable Image-to-3D Facade Parser for Generating Thermal
  3D Building Models
arxiv_id: '2508.04406'
source_url: https://arxiv.org/abs/2508.04406
tags:
- images
- facade
- data
- image
- building
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the Scalable Image-to-3D Facade Parser (SI3FP),
  a pipeline for generating thermal LoD3.1 building models by extracting facade geometries
  from images using computer vision and deep learning. Unlike existing methods that
  rely on segmentation and projection, SI3FP directly models geometric primitives
  in the orthographic image plane, reducing perspective distortions and providing
  a unified interface.
---

# Deep Learning-based Scalable Image-to-3D Facade Parser for Generating Thermal 3D Building Models

## Quick Facts
- **arXiv ID**: 2508.04406
- **Source URL**: https://arxiv.org/abs/2508.04406
- **Reference count**: 40
- **Primary result**: Achieved approximately 5% error in window-to-wall ratio estimates for thermal building model generation

## Executive Summary
This paper presents the Scalable Image-to-3D Facade Parser (SI3FP), a pipeline for generating thermal LoD3.1 building models by extracting facade geometries from images using computer vision and deep learning. Unlike existing methods that rely on segmentation and projection, SI3FP directly models geometric primitives in the orthographic image plane, reducing perspective distortions and providing a unified interface. Tested on typical Swedish residential buildings, SI3FP achieved approximately 5% error in window-to-wall ratio estimates, demonstrating sufficient accuracy for early-stage renovation analysis. The pipeline supports both sparse data (e.g., Google Street View) and dense data (e.g., hand-held camera) sources. SI3FP facilitates large-scale energy renovation planning and has broader applications in urban development and planning.

## Method Summary
SI3FP processes facade images through two paths: StreetView (sparse data) and Camera2D (dense data). For StreetView, it clusters panoramas by building plane associations, aligns images, and generates orthographic projections. For dense data, it uses COLMAP for SfM reconstruction, trains NeRF for surface modeling, and renders orthographic views. A ResNet-50 RetinaNet detects windows in the orthographic images, with ensemble-based fusion aggregating multi-view detections. The output is a HoneybeeJSON thermal 3D model. The method uses pre-trained RetinaNet fine-tuned on LSAA dataset, with detection thresholds τconf=0.2, τiou=0.3, Nmin=2, τscore2=0.4.

## Key Results
- Achieved ~5% error in window-to-wall ratio estimates, suitable for early-stage renovation analysis
- Demonstrated effectiveness on typical Swedish residential buildings with LiDAR validation
- Supported both sparse data (Google Street View) and dense data (handheld camera) sources
- Robustness improved through ensemble-based fusion for multi-view aggregation

## Why This Works (Mechanism)

### Mechanism 1: Orthographic Transformation as a Unified Geometric Interface
Converting perspective images to orthographic projection significantly reduces geometric distortion and simplifies parameterization of facade features. This forces parallel lines to remain parallel and establishes constant pixel-to-metric scale, allowing 2D bounding box detections to map directly to 3D thermal properties. Core assumption: building facade is locally planar and approximately flat.

### Mechanism 2: Ensemble-based Multi-View Fusion for Sparse Data
Aggregating detections from multiple noisy sparse views improves robustness against occlusions compared to single-view selection. The system aligns multiple partial orthographic images and clusters detections using spatial overlap (IoU), requiring detections to appear in at least two source images to be validated. Core assumption: occlusions are view-dependent, making valid features visible in at least some views.

### Mechanism 3: NeRF-based Surface Projection for Dense Data
Neural Radiance Fields generate high-quality geometry reconstruction without artifacts of traditional mesh-based photogrammetry. Instead of constructing meshes with holes or noise, the pipeline trains NeRF from dense images and synthesizes orthographic views by querying the NeRF volume along rays perpendicular to the facade plane. Core assumption: SfM pose estimation is sufficiently accurate to train NeRF, and facade normal is correctly identified.

## Foundational Learning

**Concept: Perspective vs. Orthographic Projection**
- Why needed: Core mechanism corrects "converging lines" distortion of standard photos to get accurate measurements
- Quick check: If a window is 5 meters away and another identical one is 10 meters away, how would they appear differently in a perspective image vs. an orthographic image?

**Concept: Neural Radiance Fields (NeRF)**
- Why needed: Used in Camera2D path to create 3D model from photos without expensive LiDAR, specifically to generate orthographic view
- Quick check: What does a NeRF model actually output for a given 3D coordinate and viewing direction (as opposed to a mesh)?

**Concept: Structure-from-Motion (SfM)**
- Why needed: Essential for Camera2D path to estimate camera poses and determine "real-world" scale before NeRF training
- Quick check: How do you translate the relative scale of an SfM reconstruction into absolute metric units (e.g., meters) for thermal simulation?

## Architecture Onboarding

**Component map**: Google Street View API (Sparse) OR Dense Handheld Images -> StreetView Path (Plane Clustering -> Image Alignment) OR Camera2D Path (COLMAP -> NeRF Training) -> Orthographic Projection (Algo 1/5) -> Unified 2D Facade Image -> ResNet-50 RetinaNet (Window Detection) -> Ensemble Fusion (Algo 6) -> HoneybeeJSON (Thermal 3D Model)

**Critical path**: The Orthographic Projection step. If plane normal is wrong (StreetView) or NeRF convergence is poor (Camera2D), resulting 2D image will have scale errors, rendering thermal simulation invalid.

**Design tradeoffs**: StreetView offers high scalability but prone to occlusion and missing facades (~30% missing in tests). Camera2D provides high accuracy and completeness but requires high data collection effort (300-500 images per building) and compute cost (~2 hours for SfM).

**Failure signatures**: Balconies cause massive occlusion, dropping F1-scores from ~0.9 to ~0.75. Glass/Reflections make NeRF and SfM struggle, creating "ghost" geometry or holes. Parallax Errors in StreetView occur when objects protrude significantly from facade plane.

**First 3 experiments**:
1. Validate "Local Coordinate Reference Points" logic by comparing known physical distance to pixel distance in generated orthographic image
2. Run RetinaNet on synthetic ortho image (without perspective distortion) to separate detection errors from projection errors
3. Artificially remove StreetView images to test "break point" of Ensemble Fusion algorithm (when N<2 valid views cause failure)

## Open Questions the Paper Calls Out
None

## Limitations
- Orthographic projection mechanism has limited validity for curved or heavily ornamented facades where single plane assumption breaks down
- Ensemble fusion method cannot recover facades entirely missing from sparse dataset (~30% of buildings had no Street View coverage)
- NeRF approach struggles with transparent/reflective surfaces, potentially creating artifacts in thermal property estimation

## Confidence

**High Confidence**: 5% WWR error rate claim supported by quantitative LiDAR validation on Swedish residential buildings. Orthographic transformation mechanism for reducing perspective distortion is theoretically sound and demonstrated through controlled experiments.

**Medium Confidence**: Ensemble-based fusion algorithm shows robust performance on occluded facades in tested dataset but lacks comparative validation against alternative multi-view aggregation methods. NeRF-to-orthographic rendering pipeline validated internally but not benchmarked against traditional photogrammetry.

**Low Confidence**: Claims about system's scalability to millions of buildings remain untested beyond ~70-building Swedish dataset. Computational efficiency estimates (2-hour NeRF training) may not generalize to diverse architectural styles and geographic regions.

## Next Checks
1. **Architectural Generalization Test**: Apply SI3FP to buildings with non-rectangular facades (circular towers, gabled roofs) to validate orthographic plane assumption across diverse geometries.

2. **Data Availability Sensitivity Analysis**: Systematically vary number of available Street View images per facade to quantify exact point where N<2 valid views causes ensemble method to fail.

3. **Thermal Simulation Accuracy Validation**: Compare LoD3.1 thermal models generated by SI3FP against actual energy consumption data from renovated buildings to verify practical utility for renovation planning.