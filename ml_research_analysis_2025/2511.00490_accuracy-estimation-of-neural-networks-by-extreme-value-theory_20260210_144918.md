---
ver: rpa2
title: Accuracy estimation of neural networks by extreme value theory
arxiv_id: '2511.00490'
source_url: https://arxiv.org/abs/2511.00490
tags:
- value
- neural
- error
- extreme
- theory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies extreme value theory to quantify the large errors
  of neural network approximations. The absolute error E beyond a high threshold u
  is shown to be approximately generalized Pareto distributed, enabling estimation
  of the exceedance probability P(E x) and mean excess E[E - u | E u].
---

# Accuracy estimation of neural networks by extreme value theory

## Quick Facts
- **arXiv ID:** 2511.00490
- **Source URL:** https://arxiv.org/abs/2511.00490
- **Reference count:** 13
- **Primary result:** EVT-based estimators provide much sharper tail probability bounds than Markov's inequality for quantifying large neural network approximation errors

## Executive Summary
This paper introduces a statistical framework using extreme value theory (EVT) to quantify large errors in neural network approximations. The method models the tail of the absolute error distribution beyond a high threshold as a generalized Pareto distribution (GPD), enabling estimation of exceedance probabilities and mean excess values. Applied to American put option pricing, the approach yields more precise tail risk estimates than traditional Markov bounds, with estimated probabilities of mispricing beyond 0.33 cents at 0.26% and average excess of 0.36 cents when exceeding this threshold.

## Method Summary
The method computes absolute errors between a trained neural network and ground truth evaluator across test samples, then applies order statistics to estimate the upper endpoint and GPD shape parameter of the error distribution's tail. A new maximum-likelihood-based estimator for the shape parameter is derived that guarantees negativity with probability one, appropriate for bounded errors. The framework estimates exceedance probability P(E > x) and mean excess E[E - u | E > u] beyond threshold u, providing interpretable risk metrics for high-stakes applications.

## Key Results
- EVT-based exceedance probability estimates (0.26% ± 0.03 for errors > 0.33 cents) are much sharper than Markov bounds
- Estimated mean excess of 0.03 ± 0.003 cents when errors exceed threshold matches empirical observations
- The proposed shape parameter estimator guarantees γ < 0 with probability one, consistent with bounded error distributions
- Framework successfully applies to 5-dimensional American put option pricing problem

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EVT provides sharper tail bounds than Markov inequalities
- Mechanism: Models exceedances beyond threshold u as GPD for parametric estimation of P(E > x) and mean excess
- Core assumption: Error distribution satisfies Pickands-Balkema-de Haan conditions with finite upper endpoint
- Evidence anchors: Abstract shows EVT outperforms Markov; Section 3 provides GPD-based equations; corpus neighbor paper supports EVT approach for extreme errors

### Mechanism 2
- Claim: Negative shape parameter γ is theoretically justified for bounded NN errors
- Mechanism: Continuous errors on compact domain imply boundedness (γ ≤ 0); new estimator enforces γ < 0 via log terms
- Core assumption: Errors follow Weibull max-domain of attraction with bounded support
- Evidence anchors: Theorem 1 guarantees γ < 0; Section 2 discusses bounded error behavior; corpus lacks direct validation

### Mechanism 3
- Claim: EVT enables estimation of maximum error magnitude and mean excess for interpretable risk metrics
- Mechanism: Uses order statistics to estimate upper endpoint x* and integrates fitted GPD for conditional mean excess
- Core assumption: Proper threshold selection (k/N ≈ 0.01) with consistent estimator conditions
- Evidence anchors: Section 3 provides mean excess estimator; Section 4.2 reports numerical results; corpus shows financial ML applications but no EVT validation

## Foundational Learning

- **Pickands-Balkema-de Haan Theorem (POT Theorem)**: Justifies approximating exceedances over high threshold as GPD - Given X with CDF F and threshold u, what does the theorem say about P(X - u ≤ x | X > u) as u → x*?
- **Order Statistics for Endpoint Estimation**: Estimator uses top k order statistics - Which order statistics are used in the endpoint estimator?
- **Max-Domain of Attraction and Shape Parameter Interpretation**: Sign of γ determines tail behavior - What does negative γ < 0 imply about upper endpoint x*?

## Architecture Onboarding

**Component map**: Input -> Error Sampling -> Order Statistics -> Threshold Selection -> Endpoint/Shape Estimation -> EVT Outputs

**Critical path**: 1) Generate sufficient error samples 2) Implement order-statistics estimators 3) Validate GPD fit quality

**Design tradeoffs**: 
- Threshold choice (k): smaller k → higher variance but more extreme threshold; larger k → more data but potential GPD violation
- Test set size N: larger N improves tail estimation but increases computational cost
- Training vs. test domain: C_test ⊂ C_train avoids boundary degradation but may miss extrapolation risk

**Failure signatures**: 
- γ ≥ 0 (if not using constrained estimator): suggests misspecification or unbounded error
- Unstable γ or x* over k variation: threshold too low or insufficient data
- Negative or nonsensical mean excess: check γ < -1 for theoretical mean existence

**First 3 experiments**:
1. Apply EVT pipeline to synthetic Beta-distributed errors and verify parameter recovery
2. Compute γ and x* over range of k values and plot stability to identify plateau region
3. Compare EVT-estimated P(E > x) to Markov bounds on real NN for American option pricing

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How to optimally select threshold k to minimize mean squared error across different NN architectures?
- Basis: Paper suggests k/N ≈ 0.01 as reasonable choice but lacks formalized adaptive rule
- Why unresolved: Bias-variance tradeoff in k selection currently handled by rules of thumb
- What evidence would resolve: Theoretical analysis or empirical study demonstrating adaptive k minimization criteria

### Open Question 2
- Question: Does GPD assumption hold effectively for high-dimensional NN approximation tasks?
- Basis: Experiments limited to 5-dimensional option pricing; paper notes analysis on d-dimensional space without extensive dimensionality testing
- Why unresolved: Curse of dimensionality may affect error distribution and estimator convergence rates
- What evidence would resolve: Experiments on high-dimensional tasks (image/language models) verifying γ < 0 condition robustness

### Open Question 3
- Question: Can endpoint estimate reliability be improved for extreme tail probability estimation?
- Basis: Paper notes exceedance probability cannot be reliably estimated beyond 0.01% quantile due to endpoint estimation uncertainties
- Why unresolved: Uncertainty in x* creates bottleneck for quantifying most extreme errors
- What evidence would resolve: Modified endpoint estimator or Bayesian approach with robust confidence intervals for extreme tail

## Limitations
- New shape estimator primarily validated on American put option pricing, generalization unknown
- Crucial hyperparameter k (270) lacks systematic sensitivity analysis across datasets
- Key implementation details (activation functions, learning rate, binomial tree granularity) unspecified
- Unclear how well method extrapolates to out-of-distribution inputs or adversarial scenarios

## Confidence
- **High**: Theoretical EVT framework and negative shape constraint for bounded errors
- **Medium**: Application results for option pricing and comparison to Markov bounds
- **Low**: Universality and robustness of new estimator across diverse tasks and domains

## Next Checks
1. Apply EVT pipeline to synthetic Beta-distributed errors and verify parameter recovery
2. Compute γ and x* over range of k values and plot stability to identify plateau region
3. Compare EVT-estimated P(E > x) to Markov bounds on real NN for American option pricing