---
ver: rpa2
title: 'LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models'
arxiv_id: '2508.08300'
source_url: https://arxiv.org/abs/2508.08300
tags:
- priors
- bayesian
- inference
- language
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper demonstrates that Large Language Models can automate
  Bayesian inference workflows. Two experiments show LLMs can: (1) elicit appropriate
  prior distributions from natural language descriptions of beliefs, and (2) fully
  specify both priors and likelihood functions from holistic problem descriptions.'
---

# LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models

## Quick Facts
- arXiv ID: 2508.08300
- Source URL: https://arxiv.org/abs/2508.08300
- Reference count: 9
- LLM-BI framework automates Bayesian inference by translating natural language into probabilistic model specifications

## Executive Summary
This paper introduces LLM-BI, a framework that leverages Large Language Models to automate Bayesian inference workflows. The system can elicit appropriate prior distributions from natural language descriptions of beliefs and fully specify both priors and likelihood functions from holistic problem descriptions. Using Bayesian linear regression with synthetic data, the framework achieves accurate posterior inference comparable to manually specified models, significantly lowering barriers to Bayesian modeling for non-experts.

## Method Summary
The LLM-BI framework uses an LLM (Gemini v2.5) to parse natural language inputs and generate structured JSON specifications for Bayesian models. The pipeline accepts user belief statements or problem descriptions, prompts the LLM to output distribution specifications, dynamically constructs PyMC models from the JSON output, and executes MCMC inference. The system validates generated distributions against a constrained vocabulary (Normal, HalfNormal, Uniform, Exponential) and parses formula strings to construct likelihoods, enabling fully automated Bayesian inference from natural language inputs.

## Key Results
- LLM successfully elicited priors from natural language, translating "probably around 0, but could reasonably be as low as -25 or as high as 25" into α ~ N(0, 12.5)
- LLM correctly formulated complete Bayesian linear regression model including both priors and likelihood from holistic problem description
- Posterior inference achieved r-hat=1.0 and parameter recovery within 94% HDI, with posterior means within 0.1 of ground truth values

## Why This Works (Mechanism)

### Mechanism 1: Semantic-to-Distribution Mapping
LLMs can translate natural language descriptions of uncertainty into valid probability distributions by parsing textual belief statements and mapping uncertainty descriptors to distribution families with appropriate parameterizations. The system leverages the LLM's internalized statistical knowledge to reason bidirectionally between verbal uncertainty expressions and mathematical specifications.

### Mechanism 2: Holistic Model Synthesis
LLMs can generate complete probabilistic model specifications from unified problem narratives by parsing consolidated descriptions to identify variable roles, functional relationships, error structures, and parameter constraints. The LLM outputs structured JSON objects with separate priors and likelihood keys that can be directly consumed by probabilistic programming backends.

### Mechanism 3: Posterior Validity via Well-Specified Models
When LLMs correctly specify priors that encode user beliefs and likelihoods that match the data-generating process, standard MCMC samplers can efficiently explore the posterior. With sufficient data, the likelihood dominates minor differences in prior specification, yielding convergent chains and accurate parameter recovery comparable to manually specified models.

## Foundational Learning

- **Bayesian Linear Regression**: Understanding how priors on (α, β, σ) combine with Gaussian likelihood to produce posteriors is essential. Quick check: If your prior on β is N(2, 1) but the true slope is -5, what happens to your posterior with n=10 observations? With n=1000?
- **Prior Elicitation Semantics**: Mapping phrases like "probably around," "very unlikely," and "must be positive" to distributional choices. Quick check: A user says "I'm 95% sure the value is between 10 and 30, and values near 20 are most plausible." What distribution family and parameters capture this?
- **MCMC Convergence Diagnostics**: To interpret whether r-hat ≈ 1.0 and ESS values indicate trustworthy inference. Quick check: You run 4 chains and get r-hat = 1.15 for parameter α. What does this indicate, and what might you change?

## Architecture Onboarding

- **Component map**: Natural language interface -> LLM prompter -> JSON validation -> PyMC model construction -> MCMC sampling -> Posterior diagnostics
- **Critical path**: User text → Prompt template → LLM API call → JSON validation → PyMC model construction → MCMC sampling → Posterior diagnostics. The JSON parsing step is the most fragile.
- **Design tradeoffs**: Constrained distribution vocabulary reduces LLM error modes but limits expressivity; JSON output format enables parsing but requires validation; single LLM call for full model is elegant but harder to debug.
- **Failure signatures**: LLM returns markdown-wrapped JSON instead of raw JSON; LLM chooses incompatible distribution/parameter combinations; LLM hallucinates variable names not present in user description; generated priors have insufficient support for true parameters.
- **First 3 experiments**: 1) Replicate Experiment I with your own belief statements, varying specificity and observing posterior widths with n=20 vs. n=500. 2) Test edge cases like multi-modal priors or constraints like "β must be between 0 and 1." 3) Compare LLM outputs across multiple calls to catalog distribution of distribution choices.

## Open Questions the Paper Calls Out

- Can the LLM-BI framework accurately specify complex hierarchical or non-linear models beyond simple linear regression? The study validates only Bayesian linear regression as a proof-of-concept.
- How can the pipeline ensure reproducibility given the inherent stochasticity of LLM outputs? Footnote notes that repeating experiments yields different distribution choices.
- Does LLM-elicited prior knowledge significantly improve inference accuracy in sparse-data regimes compared to weakly informative defaults? Current experiments used 100 data points where signal overwhelmed prior differences.

## Limitations

- Distribution vocabulary constraints limit the framework to four distribution families, potentially inadequately representing complex user beliefs or multi-modal uncertainties
- JSON parsing brittleness creates a failure mode where malformed LLM output breaks the pipeline
- Low-data regime performance remains unknown since experiments use n=100 observations where likelihood dominates

## Confidence

- **High confidence**: Core demonstration that LLMs can generate valid prior specifications from natural language and complete model structures from holistic descriptions
- **Medium confidence**: Claim that this significantly lowers barriers to Bayesian modeling for non-experts
- **Low confidence**: Generalization to non-linear models, hierarchical structures, or custom likelihood functions beyond simple linear regression

## Next Checks

1. Systematically vary specificity of user belief statements (vague vs. precise) and quantify how posterior widths change with n=20 vs. n=500 observations
2. Run the same prompt 10 times and catalog the distribution of distribution choices to characterize LLM variability and hallucination modes
3. Test beliefs that imply multi-modal priors or complex constraints (e.g., "β must be between 0 and 1") to evaluate the constrained distribution vocabulary's expressivity