---
ver: rpa2
title: Bayesian Neural Networks for Functional ANOVA model
arxiv_id: '2510.00545'
source_url: https://arxiv.org/abs/2510.00545
tags:
- bayesian-tpnn
- anov
- have
- table
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the computational burden of functional ANOVA
  models with tensor product neural networks (TPNN) by proposing a Bayesian framework
  (Bayesian-TPNN) that learns the model architecture (number and structure of TPNNs)
  alongside the parameters. The core idea is to treat the architecture as a learnable
  parameter and use an MCMC algorithm to explore higher-order interactions efficiently.
---

# Bayesian Neural Networks for Functional ANOVA model

## Quick Facts
- arXiv ID: 2510.00545
- Source URL: https://arxiv.org/abs/2510.00545
- Reference count: 40
- Proposes Bayesian framework for functional ANOVA with tensor product neural networks (TPNN) that learns model architecture alongside parameters

## Executive Summary
This paper addresses the computational burden of functional ANOVA models with tensor product neural networks by proposing a Bayesian framework that learns the model architecture alongside the parameters. The method treats the architecture as a learnable parameter and uses MCMC to explore higher-order interactions efficiently. The approach demonstrates superior prediction performance and uncertainty quantification compared to baseline models on multiple real datasets, while also achieving better component selection performance on synthetic datasets.

## Method Summary
The proposed Bayesian-TPNN framework learns both the parameters and architecture of tensor product neural networks simultaneously using a modified MCMC algorithm. The key innovation is treating the architecture selection as part of the inference process, allowing the model to explore higher-order interactions without exhaustive search. The method incorporates a sum-to-zero constraint for identifiability and uses a two-step MCMC algorithm: first learning the architecture with a Langevin proposal, then learning the parameters conditioned on the architecture. A modified version of TPNN with ridge-like regularizers is introduced to satisfy theoretical requirements.

## Key Results
- Superior prediction performance compared to baseline models on multiple real datasets
- Better uncertainty quantification through Bayesian framework
- Improved component selection performance on synthetic datasets, particularly for identifying higher-order interactions
- Proven posterior consistency under specified conditions

## Why This Works (Mechanism)
The method works by simultaneously learning the model architecture and parameters through MCMC, avoiding the need for exhaustive search over all possible interaction terms. By treating architecture as a learnable parameter and incorporating the sum-to-zero constraint, the model can identify and estimate higher-order interactions efficiently. The Bayesian framework provides natural uncertainty quantification while the modified TPNN structure ensures theoretical consistency.

## Foundational Learning
- **Functional ANOVA decomposition**: Why needed - to understand the basis of the model; Quick check - verify understanding of main effects and interaction terms
- **Tensor product neural networks**: Why needed - core modeling approach; Quick check - confirm grasp of how tensor products enable interaction modeling
- **Bayesian inference with MCMC**: Why needed - method for simultaneous architecture and parameter learning; Quick check - understand Metropolis-Hastings acceptance criterion
- **Sum-to-zero constraint**: Why needed - ensures model identifiability; Quick check - verify understanding of constraint implementation
- **Posterior consistency**: Why needed - theoretical foundation; Quick check - confirm understanding of conditions for consistency
- **Langevin dynamics**: Why needed - proposal mechanism for MCMC; Quick check - understand relationship to gradient information

## Architecture Onboarding
- **Component map**: Data -> Pre-trained models (XGB, SHAP) -> $p_{input}$ initialization -> MCMC (architecture learning) -> MCMC (parameter learning) -> Predictions with uncertainty
- **Critical path**: MCMC algorithm that alternates between architecture selection and parameter learning
- **Design tradeoffs**: Computational efficiency vs. exhaustive search; theoretical consistency vs. practical implementation; fixed $p_{input}$ vs. adaptive learning
- **Failure signatures**: Poor acceptance rates in MCMC; unstable predictions with large step sizes; degradation in performance when higher-order interactions are present
- **Three first experiments**: 1) Verify MCMC convergence on simple synthetic data, 2) Compare prediction accuracy against baseline models on real data, 3) Test sensitivity to step size in Langevin proposals

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can $p_{input}$ be updated adaptively during MCMC inference rather than relying on a fixed distribution from pre-trained models?
- Basis in paper: [explicit] The conclusion states, "It would be interesting to update $p_{input}$ along with the other parameters... [e.g.,] proportional to the number of basis functions... We will pursue this algorithm in the near future."
- Why unresolved: The current method fixes $p_{input}$ using external importance measures (SHAP/XGB), which requires a separate pre-training step and may not capture the dynamic interactions during inference.
- What evidence would resolve it: Demonstration of an MCMC scheme where $p_{input}(j)$ adapts based on the current model state, showing maintained or improved accuracy without external pre-training.

### Open Question 2
- Question: Does the posterior consistency of Bayesian-TPNN hold when the sum-to-zero condition is defined with respect to the empirical distribution?
- Basis in paper: [inferred] Section 3.3 states, "To avoid unnecessary technical difficulties, we assume that $\phi(x|\Theta_k)$... satisfies the sum-to-zero condition with respect to the uniform distribution."
- Why unresolved: The theoretical proof relies on the uniform distribution for tractability, but the actual implementation (Eq. 6) uses the empirical distribution $\mu_n$ to enforce the sum-to-zero constraint, creating a gap between theory and practice.
- What evidence would resolve it: A theoretical extension of Theorem 3 that establishes consistency under the empirical measure or a bounded error analysis between the two approaches.

### Open Question 3
- Question: How does the choice of the Langevin proposal step size affect the mixing and stability of the MCMC algorithm in high-dimensional parameter spaces?
- Basis in paper: [inferred] Appendix C.3 notes that "overly large step sizes in the Langevin proposal can degrade the prediction performance due to poor acceptance and unstable exploration."
- Why unresolved: While the paper identifies sensitivity to step size, it relies on manual selection (e.g., 0.01) without providing a principled method for scaling it with the dimensionality of the weights or the number of hidden nodes $K$.
- What evidence would resolve it: An analysis or ablation study showing how the optimal step size scales with network complexity ($K$ and $p$) or an adaptive step-size integration.

## Limitations
- The theoretical proof of posterior consistency relies on uniform distribution assumptions that differ from practical implementation using empirical distributions
- Computational complexity of MCMC algorithm may still be prohibitive for very high-dimensional problems with many potential higher-order interactions
- Performance comparisons are primarily against baseline models rather than state-of-the-art alternatives

## Confidence
- Prediction performance claims: High
- Uncertainty quantification claims: Medium
- Theoretical consistency proof: High
- Component selection performance: Medium
- Computational efficiency claims: Medium

## Next Checks
1. Benchmark against recent state-of-the-art functional ANOVA methods on diverse real-world datasets
2. Conduct sensitivity analysis on prior specifications and their impact on model performance
3. Evaluate scalability on high-dimensional problems with varying levels of sparsity in higher-order interactions