---
ver: rpa2
title: 'SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with
  Clinical Validation in COPD Reporting'
arxiv_id: '2507.16145'
source_url: https://arxiv.org/abs/2507.16145
tags:
- copd
- diagnostic
- clinical
- data
- spirollm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SpiroLLM is the first multimodal large language model that can
  understand spirogram time series for COPD diagnosis. It fuses visual spirogram features
  with PFT metrics and demographics using a SpiroEncoder and SpiroProjector, then
  generates clinical reports via a large language model.
---

# SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting

## Quick Facts
- arXiv ID: 2507.16145
- Source URL: https://arxiv.org/abs/2507.16145
- Reference count: 40
- Primary result: Achieved AUROC of 0.8977 for COPD diagnosis from spirogram time series

## Executive Summary
SpiroLLM is the first multimodal large language model designed to understand spirogram time series for COPD diagnosis. It fuses visual spirogram features extracted by a CNN-BiLSTM encoder with PFT metrics and demographics, then generates clinical reports via a fine-tuned LLM. Trained on 18,416 UK Biobank samples, it significantly outperformed baseline models, demonstrating that raw spirogram waveforms encode diagnostic information beyond discrete PFT metrics. The multimodal design maintained high diagnostic accuracy even when PFT text was removed, confirming the visual modality's independent value.

## Method Summary
SpiroLLM uses a SpiroEncoder (CNN-BiLSTM) to extract morphological features from flow-volume curves, which are then projected to the LLM's embedding space via a SpiroProjector (MLP). Demographics and PFT metrics are combined with these projected visual features to generate clinical reports. The model was trained using semi-automated gold-standard reports synthesized through a pipeline of Qwen-VL for curve description, SpiroUtils for metric calculation, RAG over GOLD guidelines, and DeepSeek-V3 synthesis. Training used parameter-efficient fine-tuning with LoRA adapters while freezing the encoder and LLM backbone, optimized with AdamW and cosine annealing.

## Key Results
- Achieved AUROC of 0.8977 for COPD diagnosis, significantly outperforming text-only baselines
- Multimodal design maintained 100% valid response rate and high diagnostic accuracy when PFT text was removed
- Expert evaluation found reports of high quality with precise interpretation of pulmonary function curve morphology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Raw spirogram waveforms encode diagnostic information that discrete PFT metrics cannot fully capture.
- Mechanism: The SpiroEncoder (CNN-BiLSTM) learns morphological features from flow-volume curves, particularly attending to the descending limb where airflow obstruction manifests as concavity. These visual patterns complement numerical thresholds.
- Core assumption: The visual encoder extracts features correlated with COPD pathology that generalize beyond the UK Biobank population.
- Evidence anchors:
  - Input masking experiments showed multimodal design maintained 100% valid response rate and high diagnostic accuracy even when PFT text was removed
  - Achieved approximately 4.0% absolute improvement in sensitivity, highlighting the distinct clinical value of visual modality
  - Related work TS-Reasoner addresses time-series reasoning but not clinical signals

### Mechanism 2
- Claim: Cross-modal projection enables the LLM to "interpret" rather than merely "recognize" visual features.
- Mechanism: The SpiroProjector (MLP) maps SpiroEncoder outputs to the LLM's embedding space. Pre-training with frozen encoder and LLM weights aligns visual features with textual morphological descriptions.
- Core assumption: The pre-training alignment sufficiently bridges the modality gap for downstream diagnostic reasoning.
- Evidence anchors:
  - The SpiroProjector projects time-series features into a dimensional space aligned with the LLM's feature space
  - The model explicitly learns to identify characteristic morphological landmarks of airflow limitation
  - GEM uses similar encoder-projector paradigm for ECG understanding

### Mechanism 3
- Claim: Semi-automated report synthesis provides viable supervision signals for medical LLM fine-tuning.
- Mechanism: A pipeline combining Qwen-VL (curve description), SpiroUtils (metric calculation), RAG over GOLD guidelines, and DeepSeek-V3 synthesis generates training targets.
- Core assumption: The synthesized reports sufficiently approximate expert-authored clinical logic and style for the LLM to learn transferable diagnostic reasoning.
- Evidence anchors:
  - The synthesis process significantly reduces manual annotation cost while ensuring authoritativeness of diagnostic logic
  - Expert evaluation found reports of high quality with precise interpretation and description
  - No direct corpus evidence; synthesis-based supervision is paper-specific

## Foundational Learning

- Concept: **Multimodal Projection/Alignment**
  - Why needed here: SpiroLLM fuses continuous time-series signals with discrete LLM token space. Understanding how projectors map between embedding spaces is essential for debugging alignment failures.
  - Quick check question: Can you explain why a linear or shallow MLP projector might suffice for alignment when the encoder is pre-trained, versus when training end-to-end from scratch?

- Concept: **Parameter-Efficient Fine-Tuning (LoRA)**
  - Why needed here: The paper freezes both SpiroEncoder and LLM backbone, updating only SpiroProjector and LoRA adapters. This reduces computational cost and mitigates catastrophic forgetting.
  - Quick check question: What is the trade-off between LoRA rank (r) and representational capacity? How would you detect underfitting vs. overfitting in this setup?

- Concept: **Clinical Evaluation Metrics Beyond NLP Similarity**
  - Why needed here: The paper explicitly rejects BLEU/ROUGE in favor of "LLM-as-a-Judge" across six clinical dimensions. This approach better captures diagnostic accuracy in medical contexts.
  - Quick check question: Why might a high BLEU score correlate poorly with diagnostic accuracy in this domain?

## Architecture Onboarding

- Component map:
  Raw Spirogram → SpiroEncoder (CNN-BiLSTM) → Feature Embeddings → SpiroProjector (MLP) → LLM Backbone → Report
  Demographics + PFT Metrics → Text Prompt ←

- Critical path:
  1. Encoder quality: If SpiroEncoder fails to extract discriminative features, downstream performance degrades regardless of LLM capacity
  2. Projector alignment: Pre-training the projector is essential; random initialization yields poor cross-modal grounding
  3. Prompt construction: Demographics + PFT values + projected visual tokens must be correctly assembled

- Design tradeoffs:
  - Frozen vs. fine-tuned encoder: Freezing preserves pre-trained features but may limit adaptation to domain-specific nuances
  - Semi-automated vs. expert-annotated reports: Synthesis scales but may lack nuanced clinical judgment; expert annotation is costly but authoritative
  - Text-only vs. multimodal: Text-only achieves comparable AUROC but lower sensitivity; multimodal adds robustness to missing data

- Failure signatures:
  - Text-only model collapse under masking: Valid response rate drops from 100% to 13.4% when PFT values are removed
  - Terminology imprecision: Experts flagged "non-fully reversible airflow obstruction" as potentially unjustified without bronchodilator reversibility test data
  - Population bias risk: Training on predominantly white British UK Biobank participants may limit generalization

- First 3 experiments:
  1. Ablate the projector: Replace the pre-trained SpiroProjector with a randomly initialized version and measure AUROC/sensitivity drop
  2. Mask individual input modalities: Systematically remove visual tokens, PFT metrics, and demographics to isolate each modality's contribution
  3. Cross-population validation: Evaluate on a non-UK Biobank cohort to assess generalization and identify potential biases

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on semi-automated report synthesis for training supervision, which may propagate systematic biases without expert validation at scale
- Trained exclusively on UK Biobank participants (predominantly white British), raising concerns about generalizability to other populations
- Clinical impact assessment limited to UK Biobank data without external validation in real-world clinical settings or diverse populations

## Confidence

- **High confidence**: The multimodal architecture design is technically sound and the reported AUROC of 0.8977 is statistically robust within the UK Biobank dataset
- **Medium confidence**: The superiority of visual modality is well-demonstrated, though clinical significance needs external validation
- **Low confidence**: Claims about interpretability and transparent decision-making are partially supported but require clinical expert validation beyond limited expert panel assessment

## Next Checks
1. **Cross-population external validation**: Test SpiroLLM on a non-UK Biobank cohort to assess generalizability and identify potential demographic biases in performance
2. **Expert-annotated report comparison**: Generate a small subset of reports using expert clinicians rather than the synthesis pipeline, then compare these to SpiroLLM outputs on factual accuracy, terminology precision, and clinical reasoning quality
3. **Real-world deployment pilot**: Conduct a prospective study in a clinical setting where SpiroLLM assists respiratory specialists, measuring inter-observer agreement, diagnostic accuracy improvements, and time savings compared to standard practice