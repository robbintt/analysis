---
ver: rpa2
title: A Judge-Aware Ranking Framework for Evaluating Large Language Models without
  Ground Truth
arxiv_id: '2601.21817'
source_url: https://arxiv.org/abs/2601.21817
tags:
- judge
- ranking
- comparisons
- judges
- unweighted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a statistical framework for ranking large
  language models (LLMs) using pairwise comparisons from multiple judge LLMs, addressing
  the issue of heterogeneous judge reliability. The authors extend the Bradley-Terry-Luce
  model by incorporating judge-specific discrimination parameters to jointly estimate
  model quality and judge reliability without requiring ground-truth labels.
---

# A Judge-Aware Ranking Framework for Evaluating Large Language Models without Ground Truth

## Quick Facts
- arXiv ID: 2601.21817
- Source URL: https://arxiv.org/abs/2601.21817
- Reference count: 8
- Introduces a statistical framework for ranking LLMs using pairwise comparisons from multiple judge LLMs, incorporating judge-specific discrimination parameters to improve ranking accuracy and uncertainty quantification without ground-truth labels.

## Executive Summary
This paper addresses the challenge of ranking large language models using pairwise comparisons from multiple judge LLMs with heterogeneous reliability. The authors extend the Bradley-Terry-Luce model by incorporating judge-specific discrimination parameters, enabling joint estimation of model quality scores and judge reliabilities without requiring ground-truth labels. The framework establishes identifiability and proves consistency and asymptotic normality of the maximum likelihood estimator, allowing principled uncertainty quantification through confidence intervals. Across multiple benchmarks including MT-Bench, Chatbot Arena, and a newly collected dataset with 45 models, the method improves agreement with human preferences and achieves higher data efficiency compared to unweighted baselines.

## Method Summary
The framework extends the Bradley-Terry-Luce model by incorporating judge-specific discrimination parameters γ_k, where the probability of model i beating model j under judge k follows P(Y=1|i,j,k) = σ(γ_k(s_i - s_j)). The parameters (quality scores s and discrimination parameters γ) are estimated via maximum likelihood with normalization constraints (∑s_i = 0, ∑log(γ_k) = 0). The optimization uses Adam with projection onto the constraint set, and confidence intervals are constructed using the observed Fisher information matrix. The approach addresses heterogeneous judge reliability by automatically down-weighting unreliable judges in the likelihood.

## Key Results
- Improves agreement with human preferences compared to unweighted BTL baselines across multiple benchmarks
- Achieves higher data efficiency, requiring fewer comparisons to reach accurate rankings
- Produces confidence intervals that are on average 13.5% narrower than standard BTL models while maintaining proper coverage
- Correctly places GPT-4 first in Chatbot Arena rankings where unweighted methods showed discrepancies

## Why This Works (Mechanism)

### Mechanism 1
Modeling judge-specific discrimination parameters reduces ranking bias by automatically down-weighting unreliable judges. Each judge k has a discrimination parameter γ_k that scales the effective signal in their comparisons: P(Y=1|i,j,k) = σ(γ_k(s_i - s_j)). High-γ judges amplify small quality differences into decisive preferences; low-γ judges contribute near-random noise. The MLE automatically down-weights unreliable judges through the likelihood because noisy observations produce smaller gradients toward incorrect score separations. Core assumption: Judge reliability is consistent across comparison contexts (γ_k is judge-level, not task-level). Evidence: Unweighted BTL shows systematic under-coverage that worsens with T; weighted model maintains ~95% coverage. Break condition: If judges systematically disagree in structured ways (e.g., adversarial judges with inverted preferences), discrimination parameters alone cannot capture this.

### Mechanism 2
Joint estimation of model scores and judge reliabilities is identifiable with appropriate normalization. The parameters are only identifiable up to affine transformations (s → as + b, γ → γ/a). Normalization constraints (∑s_i = 0, ∑log(γ_k) = 0) fix location and scale, yielding unique MLE solutions. This works because the likelihood depends only on products γ_k(s_i - s_j), so global rescaling cancels out of pairwise probabilities. Core assumption: At least some quality scores differ (Assumption 3.1); otherwise γ becomes unidentifiable. Evidence: Formal identifiability proof showing transformation equivalence class and normalization constraints render parameters unique. Break condition: If the comparison graph is disconnected, scores in separate components become unanchored relative to each other regardless of normalization.

### Mechanism 3
Asymptotic normality enables calibrated confidence intervals for rankings. The MLE satisfies √T(θ̂_T - θ_0) → N(0, Σ_θ_0). This follows from standard M-estimation theory under i.i.d. design. The Fisher information matrix captures how comparison frequencies n_ijk and outcome uncertainty jointly determine estimation precision. Plugging in θ̂_T yields Wald intervals with proper asymptotic coverage. Core assumption: I.i.d. random design where each (model pair, judge) triple is sampled uniformly. Evidence: Formal statement of consistency and asymptotic normality, average CI width reduced 13.5% vs. unweighted baseline while maintaining coverage. Break condition: If comparison sampling is non-uniform, the covariance structure may not reflect the plug-in estimator, leading to miscoverage.

## Foundational Learning

- **Bradley-Terry-Luce (BTL) model basics**: The entire framework extends BTL; without understanding the base model (P(i beats j) = σ(s_i - s_j)), the discrimination extension is opaque. Quick check: Given scores s_A = 0.5, s_B = -0.3, what is P(A beats B) in standard BTL?

- **Maximum likelihood estimation with equality constraints**: The normalization constraints are enforced during optimization via projection; understanding constrained MLE is essential for implementation. Quick check: Why can't we simply optimize s and γ without constraints? What would happen to the likelihood landscape?

- **Wald confidence intervals and Fisher information**: The paper's uncertainty quantification relies on inverting the observed information matrix; practitioners need this for reporting ranking uncertainty. Quick check: If the Fisher information for a parameter is low, what happens to the Wald CI width? What comparison structure would cause low information for a specific model's score?

## Architecture Onboarding

- **Component map**: Comparison triples (i, j, k, y) → Likelihood module with weighted BCE → MLE optimization with constraints → Inference layer with Fisher information → Output scores, judge reliabilities, and confidence intervals

- **Critical path**: 1. Verify comparison graph connectivity via BFS, 2. Initialize s_i uniformly, α_k = 0, 3. Run Adam with projection until convergence, 4. Compute information matrix Hessian at MLE, 5. Report scores, judge reliabilities, and confidence intervals

- **Design tradeoffs**: Tie handling (current: y=0.5 contribution to both sides), judge budget vs. comparison budget (more judges increase K but provide diverse reliability signals), constraint enforcement (projection after each Adam step vs. Lagrangian formulation)

- **Failure signatures**: Disconnected graph (some models incomparable), γ_k → 0 (numerical instability), all scores equal (γ parameters unidentifiable), coverage collapse under misspecification (if judge heterogeneity is not discriminability-type)

- **First 3 experiments**: 1. Synthetic validation: Generate data from known (s_0, γ_0), fit model, verify MSE decays as O(1/T) and CIs achieve nominal coverage, 2. Ablation on judge heterogeneity: Fit both weighted and unweighted models, compute Spearman correlation with held-out human rankings, 3. Sample efficiency curve: Subsample comparisons at varying T and K, plot correlation with full-data reference scores

## Open Questions the Paper Calls Out

- **Multi-dimensional quality attributes**: Future work includes incorporating multi-dimensional quality attributes of candidate models. The current model estimates only a single quality score per model, which conflates potentially orthogonal capabilities. What evidence would resolve it: An extension of the identifiability theory and MLE to vector-valued scores, with empirical validation showing the multi-dimensional model captures variance that the scalar model cannot.

- **Task-specific judge reliability**: Introducing task-specific scores that allow judge reliability to vary across tasks rather than remain static. The current model assumes each judge has one discrimination parameter γ_k across all comparisons, but judges may be more reliable for certain task categories. What evidence would resolve it: A comparative study showing task-dependent γ_k estimates improve correlation with human ground truth, particularly on heterogeneous benchmarks spanning diverse task types.

- **Judge-candidate overlap**: The paper notes "Judges may be external evaluators or overlap with the candidate set" but does not analyze how self-evaluation or strategic behavior affects identifiability and bias. What evidence would resolve it: Experiments comparing rankings when judges are excluded from candidates versus included, analyzing systematic score shifts and theoretical bounds on bias under partial overlap.

## Limitations
- The assumption that judge reliability is solely captured by a multiplicative discrimination parameter may not account for systematic judge biases or context-dependent reliability shifts.
- The identifiability proof relies on specific normalization constraints that may not generalize to all practical scenarios.
- The asymptotic theory assumes i.i.d. random design, but real-world comparison sampling is often non-uniform, potentially affecting confidence interval coverage.

## Confidence

- **High confidence**: MLE consistency and asymptotic normality results (Theorem 3.4) - follow standard M-estimation theory
- **Medium confidence**: Identifiability proof (Theorem 3.2) - mathematically sound but relies on assumptions about quality score separation
- **Medium confidence**: Empirical improvements in ranking accuracy and CI width reduction - demonstrated across multiple benchmarks but with limited head-to-head comparisons

## Next Checks

1. **Synthetic stress test**: Generate data with known systematic judge biases (e.g., adversarial judges with inverted preferences) to evaluate whether discrimination parameters alone can detect and correct for such structured disagreement.

2. **Coverage robustness**: Test confidence interval coverage under non-i.i.d. sampling designs (e.g., stratified sampling where some model pairs are oversampled) to assess robustness to real-world data collection patterns.

3. **Scalability analysis**: Evaluate model performance and computational efficiency as the number of models K and judges J increases, particularly focusing on the growth rate of the Fisher information matrix computation and the stability of the MLE.