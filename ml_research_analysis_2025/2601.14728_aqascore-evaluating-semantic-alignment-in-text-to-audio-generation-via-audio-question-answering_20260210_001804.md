---
ver: rpa2
title: 'AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio
  Question Answering'
arxiv_id: '2601.14728'
source_url: https://arxiv.org/abs/2601.14728
tags:
- text
- audio
- events
- sound
- described
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AQAScore introduces a probabilistic semantic verification framework
  for evaluating text-to-audio generation by reformulating alignment assessment as
  audio question answering. Instead of relying on embedding similarity, it computes
  the log-probability of a "Yes" response to targeted semantic queries, enabling fine-grained
  detection of missing or incorrect sound events.
---

# AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering

## Quick Facts
- arXiv ID: 2601.14728
- Source URL: https://arxiv.org/abs/2601.14728
- Reference count: 40
- Primary result: Reformulates TTA alignment assessment as audio question answering to compute log-probabilities of "Yes" responses, outperforming CLAPScore on human-rated relevance and compositional reasoning benchmarks.

## Executive Summary
AQAScore introduces a probabilistic semantic verification framework for evaluating text-to-audio generation by reformulating alignment assessment as audio question answering. Instead of relying on embedding similarity, it computes the log-probability of a "Yes" response to targeted semantic queries, enabling fine-grained detection of missing or incorrect sound events. Evaluated across human-rated relevance, pairwise comparison, and compositional reasoning benchmarks, AQAScore consistently achieves higher correlation with human judgments than CLAPScore and generative prompting baselines, particularly in capturing subtle semantic inconsistencies and temporal/attribute reasoning. Performance scales with the capability of underlying audio-aware large language models, demonstrating backbone-agnostic effectiveness and strong perceptual alignment.

## Method Summary
AQAScore evaluates text-to-audio alignment by prompting an Audio-aware Large Language Model (ALLM) with a specific question about whether the audio contains the sound events described in the text, then computing the softmax-normalized probability of a "Yes" response. The framework uses log-probabilities of "Yes" and "No" tokens to calculate a continuous score between 0 and 1, eliminating the need for training and enabling zero-shot evaluation. The method leverages the compositional reasoning capabilities of modern ALLMs to assess not just presence of events but also their attributes and temporal relationships, outperforming traditional embedding similarity approaches like CLAPScore.

## Key Results
- Achieves higher correlation with human judgments than CLAPScore on RELATE (LCC 0.475 vs 0.301) and PAM (LCC 0.478 vs 0.252)
- Outperforms generative prompting baselines (AUC 0.856 vs 0.512 on Baton) and demonstrates superior compositional reasoning on CompA benchmarks
- Shows backbone-agnostic effectiveness with Qwen2.5-Omni-7B generally outperforming other tested models
- Maintains strong performance across diverse evaluation settings including human-rated relevance, pairwise comparison, and attribute/temporal reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1: Probabilistic Binary Verification
AQAScore achieves higher alignment with human perception because it reformulates audio-text assessment as a targeted verification task (Yes/No probability) rather than a global similarity score. The method prompts an ALLM with a specific question and computes the softmax-normalized probability of the "Yes" token, forcing fine-grained decisions about sound events, temporal order, and attributes rather than producing a single embedding vector.

### Mechanism 2: Leverage of Compositional Reasoning in ALLMs
AQAScore's superior performance on compositional reasoning (temporal order, attribute binding) is due to its reliance on the inherent reasoning capabilities of modern ALLMs, which go beyond simple feature matching. The question-answering format forces the ALLM to process the entire description, identify constituent events, check for their presence, and verify their stated order and attributes within the audio stream.

### Mechanism 3: Backbone Scaling and Agnostic Architecture
The framework's effectiveness is backbone-agnostic, meaning it can leverage any capable ALLM, and its performance scales with the capability (size, training data) of that backbone. The standardized question-answering prompt and simple log-probability calculation make the protocol independent of specific ALLM architecture, allowing future improvements to directly benefit the evaluation metric.

## Foundational Learning

**Audio-aware Large Language Models (ALLMs)**
- Why needed: These are the core engine of AQAScore, capable of taking audio and text as input and producing text outputs for audio question answering tasks
- Quick check: Can you name at least two ALLMs mentioned in the paper and explain how they differ in terms of training data?

**Log-probability of a token**
- Why needed: AQAScore's primary output is the log-probability the model assigns to the "Yes" token, fundamental for extracting and interpreting model confidence
- Quick check: How is the final AQAScore derived from the log-probabilities of the "Yes" and "No" tokens?

**CLAPScore and embedding similarity**
- Why needed: This is the primary baseline that AQAScore is designed to outperform, using cosine similarity of audio and text embeddings from a shared CLAP space
- Quick check: Why does CLAPScore struggle to distinguish between "a dog barking before thunder" and "thunder before a dog barking"?

## Architecture Onboarding

**Component map:**
- Input audio-text pair → Prompt Constructor → ALLM Backbone → Log-Probability Extractor → Score Calculator → Output AQAScore

**Critical path:**
The choice of ALLM backbone and the quality of its probability calibration are most critical factors. The paper shows Qwen2.5-Omni-7B generally outperforms other tested models.

**Design tradeoffs:**
- Backbone Strength vs. Inference Cost: More capable models provide better correlation but are more computationally expensive
- Generative vs. Probabilistic: Log-probability provides more continuous metrics but requires model access, excluding proprietary APIs
- Robustness vs. Sensitivity: Framework is robust to minor prompt variations but sensitive to significant changes in prompt template design

**Failure signatures:**
- Low correlation with human judgment indicates weak or miscalibrated backbone
- Poor performance on compositional tasks suggests backbone lacks temporal reasoning
- Overconfidence on incorrect pairs indicates poorly calibrated model

**First 3 experiments:**
1. Baseline Comparison: Compute AQAScore using Qwen2.5-Omni-3B and compare correlation with human ratings from RELATE against CLAPScore baseline
2. Ablation on Question Template: Evaluate impact of different prompt templates on final score using 3-4 variations and report standard deviation
3. Compositional Reasoning Test: Use AQAScore to evaluate audio-text pairs from CompA benchmark to verify ability to distinguish correct vs. incorrect temporal orders

## Open Questions the Paper Calls Out

**Open Question 1:** Can AQAScore be effectively utilized as a human-aligned reward model to optimize text-to-audio generation systems through reinforcement learning? The authors suggest this promising direction given AQAScore's strong human correlation, but its stability and gradient behavior when used as a loss signal during training are unknown.

**Open Question 2:** How can AQAScore be extended to evaluate perceptual dimensions beyond semantic relevance, such as stylistic consistency, emotion, and timbre, particularly in music generation? The current binary verification approach may not capture subjective qualities like emotional resonance or musicality.

**Open Question 3:** Why does instruction-tuning for chat capabilities (e.g., in AF3-Chat) degrade the probabilistic calibration required for AQAScore compared to base or reasoning-oriented models? The paper hypothesizes chat-tuning may inadvertently collapse the model's internal probability distribution, but specific mechanisms are not isolated.

## Limitations

- Relies heavily on underlying ALLM's calibration and reasoning capability, cannot correct for fundamental reasoning failures
- Requires access to token-level log-probabilities, excluding proprietary models like GPT-4-Audio and limiting practical deployment
- May not capture perceptual dimensions beyond semantic relevance such as stylistic consistency and emotion

## Confidence

**High Confidence (LCC > 0.75 on RELATE):**
- Correlation results with human judgments are robust across multiple benchmarks and comparison metrics
- Backbone-agnostic architecture claim is well-supported with consistent improvements across ALLM variants

**Medium Confidence (LCC ~ 0.45-0.75 on RELATE):**
- Superiority over CLAPScore on compositional reasoning is demonstrated but absolute performance leaves room for improvement
- Zero-shot nature is a strength but may limit adaptability to domain-specific tasks

**Low Confidence (LCC < 0.45 on RELATE):**
- Scalability claim assumes continued improvements in audio reasoning and maintained log-probability access
- Robustness to prompt variations is shown but not extensively explored across diverse question types

## Next Checks

1. **Backbone Robustness Test:** Evaluate AQAScore using a different ALLM architecture (e.g., transformer-based model trained specifically for audio understanding) to confirm backbone-agnostic effectiveness across fundamentally different model families.

2. **Domain Transfer Evaluation:** Apply AQAScore to evaluate text-to-audio generation in a specialized domain (e.g., medical audio synthesis or environmental sound design) to assess whether framework maintains strong correlation with domain-expert human judgments.

3. **Calibration Stability Analysis:** Systematically test how AQAScore performance degrades when using chat-tuned or otherwise probability-calibration-compromised ALLM variants, quantifying relationship between model calibration quality and evaluation metric reliability.