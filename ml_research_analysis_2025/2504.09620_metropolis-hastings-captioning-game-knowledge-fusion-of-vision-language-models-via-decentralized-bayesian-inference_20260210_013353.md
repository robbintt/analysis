---
ver: rpa2
title: 'Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models
  via Decentralized Bayesian Inference'
arxiv_id: '2504.09620'
source_url: https://arxiv.org/abs/2504.09620
tags:
- mhcg
- agent
- agents
- learning
- coco
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the Metropolis-Hastings Captioning Game (MHCG),
  a method for fusing knowledge between vision-language models (VLMs) through a decentralized
  Bayesian inference process inspired by emergent communication. The approach treats
  two pre-trained VLMs as agents that communicate by alternately proposing captions
  for images and accepting/rejecting them based on the Metropolis-Hastings algorithm.
---

# Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference

## Quick Facts
- **arXiv ID:** 2504.09620
- **Source URL:** https://arxiv.org/abs/2504.09620
- **Reference count:** 19
- **Key outcome:** MHCG achieves consistent improvements in reference-free metrics when fusing VLMs pre-trained on different datasets (COCO and CC3M), outperforming fine-tuning and ensemble approaches while maintaining original knowledge.

## Executive Summary
This paper proposes the Metropolis-Hastings Captioning Game (MHCG), a method for fusing knowledge between vision-language models (VLMs) through a decentralized Bayesian inference process inspired by emergent communication. The approach treats two pre-trained VLMs as agents that communicate by alternately proposing captions for images and accepting/rejecting them based on the Metropolis-Hastings algorithm. Through this iterative process, the agents learn from each other's plausible captions while mitigating catastrophic forgetting. Experiments demonstrate that MHCG achieves consistent improvements in reference-free evaluation metrics when fusing VLMs pre-trained on different datasets (COCO and CC3M), particularly in cross-dataset captioning tasks.

## Method Summary
MHCG frames VLM fusion as a decentralized Bayesian inference problem where two agents alternately act as speaker and listener. The speaker proposes captions from its decoder distribution, while the listener evaluates proposals using the Metropolis-Hastings acceptance ratio based on the likelihood of the proposed caption given its latent representation. The method uses Inter-ProbVLM to enable Bayesian inference over variable-length captions while preserving architectural heterogeneity between agents. LoRA and DER++ are employed to prevent catastrophic forgetting while allowing knowledge acquisition from partner agent captions. The approach achieves knowledge fusion without increasing inference time, as the learned models can operate independently after training.

## Key Results
- MHCG outperforms fine-tuning and ensemble approaches, particularly in cross-dataset captioning tasks
- The method achieves consistent improvements in reference-free metrics when fusing VLMs pre-trained on different datasets (COCO and CC3M)
- Category-level analysis shows that MHCG agents effectively balance retaining their original knowledge while acquiring complementary information from their counterparts

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The Metropolis-Hastings acceptance-rejection process enables decentralized posterior estimation over captions without requiring direct parameter merging or ensemble inference.
- **Mechanism:** One agent (speaker) proposes a caption from its decoder distribution q(c|z; ξ). The listener evaluates the proposal against its own latent representation using acceptance ratio R ≈ p(z_listener | c_proposed; ϕ) / p(z_listener | c_current; ϕ). This implements MCMC sampling from the joint posterior p(c | z_A, z_B), letting agents converge toward mutually plausible captions.
- **Core assumption:** The approximate posterior q(c|z; ξ) reasonably approximates the true posterior p(c|z; ϕ), enabling tractable acceptance ratios.
- **Evidence anchors:**
  - [abstract] "agents alternate between proposing and judging image captions, probabilistically accepting or rejecting them based on the Metropolis-Hastings algorithm"
  - [section 3.1] Equation (3) and Algorithm 1 lines 14-20
  - [corpus] "Co-Creative Learning via Metropolis-Hastings Interaction" applies similar MH interaction to human-AI symbol emergence, suggesting generalization of the mechanism
- **Break condition:** If q(c|z; ξ) poorly approximates p(c|z; ϕ), acceptance ratios become unreliable. May occur with severely mismatched pre-training distributions or collapsed decoder distributions.

### Mechanism 2
- **Claim:** Probabilistic modeling of VLMs via Inter-ProbVLM enables Bayesian inference over variable-length captions while preserving architectural heterogeneity between agents.
- **Mechanism:** Each VLM is wrapped with probabilistic adapters (ProbVLM style): image encoder produces distributional embeddings q(z|o; ψ), text encoder produces p(z|c; ϕ), and text decoder provides q(c|z; ξ). This creates a shared latent space z where acceptance ratios can be computed without requiring identical architectures.
- **Core assumption:** Latent representations z_A and z_B from different VLMs can serve as sufficient statistics for caption quality evaluation across both agents.
- **Evidence anchors:**
  - [abstract] "framing VLM fusion as decentralized Bayesian inference"
  - [section 3.2] Equations (9)-(11) and Table 1 define the generative process
  - [corpus] No direct corpus evidence on Inter-ProbVLM specifically; related work on VLM fusion (FUSE-RSVLM, strategic fusion methods) uses different architectural approaches
- **Break condition:** If latent spaces are fundamentally misaligned (e.g., different modalities, severely different pre-training objectives), p(z|c) estimates may not transfer meaningfully between agents.

### Mechanism 3
- **Claim:** LoRA and DER++ jointly prevent catastrophic forgetting while allowing knowledge acquisition from partner agent captions.
- **Mechanism:** LoRA constrains parameter updates to low-rank subspaces, limiting deviation from pre-trained knowledge. DER++ maintains a replay buffer of past (z, c, h) tuples and adds regularization terms (Equation 8) that penalize deviation from previous model outputs during learning from accepted proposals.
- **Core assumption:** The acceptance-rejection mechanism filters out captions that would cause harmful knowledge overwriting, making continual learning methods more effective.
- **Evidence anchors:**
  - [abstract] "mitigating catastrophic forgetting via Low Rank Adaptation and Dark Experience Replay++"
  - [section 3.1] Learning paragraph and Equation (8)
  - [section 4.5] "MHCG selects the most semantically plausible captions...enabling effective parameter updates" and Table 4 shows MHCG retains more original knowledge than Fine-tune
  - [corpus] No direct corpus evidence on DER++ for VLM fusion
- **Break condition:** If acceptance rate is too high (weak filtering) or replay buffer is undersized, DER++ may not prevent forgetting. If LoRA rank is too restrictive, knowledge fusion may be limited.

## Foundational Learning

- **Concept: Metropolis-Hastings Algorithm**
  - **Why needed here:** Core sampling mechanism enabling decentralized posterior inference without centralized coordination.
  - **Quick check question:** Can you explain why the acceptance ratio min(1, p(proposed)/p(current)) guarantees convergence to the target distribution?

- **Concept: Probabilistic Generative Models with Latent Variables**
  - **Why needed here:** Inter-ProbVLM treats captions and images as observed variables with shared latent representations, enabling likelihood-based acceptance decisions.
  - **Quick check question:** Can you derive the generative process p(o, c) = ∫ p(o|z)p(c|z)p(z) dz and explain why the posterior p(z|o,c) is typically intractable?

- **Concept: Catastrophic Forgetting in Sequential Learning**
  - **Why needed here:** Knowledge fusion inherently involves sequential learning from partner agent outputs, risking overwriting of pre-trained knowledge.
  - **Quick check question:** Why does standard SGD on new data tend to overwrite previously learned representations, and how does experience replay address this?

## Architecture Onboarding

- **Component map:** Image encoder (ψ) -> Latent z -> Text decoder (ξ) for proposals OR Text encoder (ϕ) for evaluation
- **Critical path:** Perception (encode image → z) → Proposal (decode z → caption) → Judgment (compute acceptance ratio via text encoder) → Learning (update decoder/encoder with LoRA+DER++ if accepted)
- **Design tradeoffs:**
  - Higher acceptance threshold → more selective learning but slower convergence
  - Larger LoRA rank → more fusion capacity but greater forgetting risk
  - Larger DER++ buffer → better retention but higher memory/slowdown
  - Assumption: Paper uses (r=8, α=16, dropout=0.1) for LoRA and (α=β=0.05) for DER++; these are not systematically ablated
- **Failure signatures:**
  - Weight averaging fails catastrophically with different pre-training (OPS=0.035 in Table 7) → do not attempt direct parameter merging
  - Fine-tuning without acceptance filtering shows rapid forgetting (Table 4: BLEU drops from 31.6 to 9.6)
  - If likelihood (Figure 2) does not increase over iterations, check acceptance rate and latent space alignment
- **First 3 experiments:**
  1. **Baseline reproduction:** Run MHCG between two agents pre-trained on COCO vs CC3M; verify log-likelihood increases (Figure 2) and reference-free metrics improve (Table 3)
  2. **Ablation: Acceptance mechanism:** Compare MHCG vs Fine-tune (r=1 always accept) on vocabulary retention using category-level metrics; expect MHCG to show higher CF1S on original categories
  3. **Scaling test:** Partition COCO into COCO-a/COCO-b as in Experiment 2; verify cross-category vocabulary sharing without inference time increase (Table 7)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Metropolis-Hastings Captioning Game (MHCG) be effectively scaled to decentralized systems with more than two agents?
- **Basis in paper:** [explicit] The conclusion explicitly states that "scaling to multiple agents could enhance decentralized knowledge fusion" as a necessary extension.
- **Why unresolved:** The current formulation and experiments are restricted to a two-agent interaction (speaker/listener), leaving the convergence behavior and communication overhead in multi-agent topologies unknown.
- **What evidence would resolve it:** A theoretical extension of the MH acceptance rule for $N$ agents and empirical results demonstrating stable knowledge fusion across a network of three or more VLMs.

### Open Question 2
- **Question:** How does MHCG perform when fusing VLMs trained on different languages or datasets with severe class imbalances?
- **Basis in paper:** [explicit] The conclusion identifies that "integrating VLMs trained in different languages or with imbalanced datasets remains a challenge."
- **Why unresolved:** The experiments utilized English-only datasets (COCO and CC3M) with relatively standard distributions, failing to validate the method's robustness to cross-lingual semantic alignment or extreme data skew.
- **What evidence would resolve it:** Experiments fusing multilingual VLMs or agents trained on heavily imbalanced data, analyzing the resulting vocabulary alignment and category-level recall.

### Open Question 3
- **Question:** How dependent is the algorithm's convergence on the accuracy of the probabilistic approximation used in the acceptance step?
- **Basis in paper:** [inferred] Equation (3) relies on the approximation $p(c|z) \approx q(c|z)$ to calculate the acceptance probability $R$, but the paper does not analyze how errors in this density estimation affect the MCMC sampling quality.
- **Why unresolved:** If the probabilistic adapter (ProbVLM) produces poorly calibrated likelihoods, the acceptance/rejection logic may fail to select the most plausible captions, potentially degrading knowledge fusion.
- **What evidence would resolve it:** An ablation study measuring the correlation between the quality of the approximate posterior $q(c|z)$ and the final captioning performance or MCMC mixing statistics.

## Limitations

- The paper lacks systematic ablation studies for key hyperparameters (LoRA rank, DER++ coefficients, acceptance thresholds), making it unclear how robust the approach is to these design choices.
- Category-level analysis relies on pre-defined COCO synonym sets that may not capture all relevant knowledge differences between datasets.
- The claim about scalability to multiple VLMs without increased inference time is only theoretically supported, with experiments limited to two-agent systems.

## Confidence

- **High**: The MHCG mechanism's core claim that probabilistic acceptance filtering enables knowledge fusion while mitigating forgetting (supported by Table 4 and category-level retention metrics)
- **Medium**: The claim that MHCG outperforms fine-tuning and ensemble methods across all metrics (consistent improvement shown, but some baselines have edge cases)
- **Low**: The scalability claim that MHCG scales to arbitrary numbers of VLMs without increased inference time (only two-agent experiments presented)

## Next Checks

1. **Ablation study**: Systematically vary LoRA rank (r=4, 8, 16) and DER++ coefficients (α=β=0.01, 0.05, 0.1) to identify optimal settings and robustness boundaries
2. **Multi-agent extension**: Test MHCG with 3+ agents pre-trained on different datasets to verify the claim about scaling without inference overhead
3. **Latent space analysis**: Quantify alignment between z_A and z_B spaces using mutual information or cross-encoding metrics to validate the core assumption about shared latent representations