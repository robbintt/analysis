---
ver: rpa2
title: 'PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction
  and Semantic Anchoring in Robotic Manipulation'
arxiv_id: '2508.05976'
source_url: https://arxiv.org/abs/2508.05976
tags:
- primitives
- point
- manipulation
- semantic
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PASG, a closed-loop framework for automated
  geometric primitive extraction and semantic anchoring in robotic manipulation. PASG
  addresses the fragmentation between high-level task semantics and low-level geometric
  features by combining automatic primitive extraction through geometric feature aggregation
  with VLM-driven semantic anchoring.
---

# PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation

## Quick Facts
- arXiv ID: 2508.05976
- Source URL: https://arxiv.org/abs/2508.05976
- Reference count: 40
- Primary result: Achieves 77.83% success rate in robotic manipulation tasks versus 84.67% for human annotations

## Executive Summary
PASG introduces a closed-loop framework that bridges the gap between high-level task semantics and low-level geometric features in robotic manipulation. The framework combines automatic geometric primitive extraction through feature aggregation with VLM-driven semantic anchoring to enable cross-category detection of keypoints and axes. By dynamically coupling geometric primitives with functional affordances and incorporating a self-correction mechanism, PASG addresses the fragmentation between semantic understanding and geometric representation that has traditionally challenged robotic manipulation systems.

## Method Summary
The framework operates through a closed-loop architecture that first extracts geometric primitives automatically from object point clouds using geometric feature aggregation techniques. These primitives are then semantically anchored through a fine-tuned VLM (Qwen2.5VL-PA) that maps geometric features to functional affordances and task-relevant semantics. The self-correction mechanism allows the system to refine its understanding iteratively, improving accuracy over time. The approach enables cross-category generalization, meaning the system can identify relevant geometric features and their semantic meanings across different object types without requiring category-specific training.

## Key Results
- Achieved 77.83% success rate in six manipulation tasks on RoboTwin simulation platform
- Outperformed baseline geometric extraction methods by enabling semantic anchoring
- Fine-tuned Qwen2.5VL-PA model achieved 77.8% overall accuracy on spatial-semantic reasoning benchmark (+33.9% improvement)

## Why This Works (Mechanism)
The framework's effectiveness stems from its closed-loop design that iteratively refines geometric-primitive-to-semantic mappings. By combining automatic geometric feature aggregation with VLM-driven semantic anchoring, the system creates bidirectional links between low-level geometry and high-level task semantics. The self-correction mechanism allows continuous improvement by incorporating feedback from task execution, while the cross-category detection capability leverages the VLM's understanding of functional relationships rather than relying on object-specific templates.

## Foundational Learning
- **Geometric Feature Aggregation**: Why needed - to automatically extract meaningful geometric primitives from raw point cloud data without manual labeling. Quick check - verify extracted primitives align with known object geometries across multiple categories.
- **VLM-Driven Semantic Anchoring**: Why needed - to map geometric primitives to task-relevant semantic meanings using visual-language understanding. Quick check - test cross-category generalization on unseen object types.
- **Closed-Loop Refinement**: Why needed - to iteratively improve primitive extraction and semantic mapping through feedback from task execution. Quick check - measure performance improvement over successive iterations.
- **Cross-Category Detection**: Why needed - to enable generalization across different object categories without category-specific training. Quick check - validate performance consistency across diverse object families.
- **Self-Correction Mechanism**: Why needed - to automatically identify and correct errors in primitive extraction or semantic anchoring. Quick check - assess error reduction rates during iterative refinement.

## Architecture Onboarding

**Component Map**: Raw Point Cloud -> Geometric Feature Aggregation -> Primitive Extraction -> VLM Semantic Anchoring -> Functional Mapping -> Task Execution -> Feedback Loop

**Critical Path**: The core execution flow moves from geometric primitive extraction through semantic anchoring to task execution, with the feedback loop enabling iterative refinement.

**Design Tradeoffs**: The framework trades computational complexity for improved semantic understanding, relying on VLMs that require significant processing power but provide rich semantic context. The closed-loop design increases system complexity but enables self-improvement.

**Failure Signatures**: Common failure modes include incorrect primitive extraction from noisy point clouds, VLM misinterpretation of geometric features, and inadequate semantic anchoring for novel object categories. The self-correction mechanism helps mitigate these issues but may struggle with completely novel scenarios.

**First Experiments**:
1. Test primitive extraction accuracy across 5 diverse object categories
2. Validate cross-category semantic anchoring with known geometric primitives
3. Measure iterative improvement rates in the closed-loop system

## Open Questions the Paper Calls Out
None

## Limitations
- All experiments conducted in simulation, raising questions about real-world applicability
- Framework dependency on VLMs may limit robustness to ambiguous semantic inputs
- Cross-category detection capability claimed but not extensively validated across diverse object categories

## Confidence
- High confidence: The closed-loop framework architecture and its components are well-defined
- Medium confidence: Simulation results and benchmark improvements are reliable within the tested environment
- Low confidence: Real-world applicability and robustness to diverse scenarios remain unproven

## Next Checks
1. Conduct real-robot experiments on at least 3 different manipulation tasks to validate sim-to-real transfer
2. Perform ablation studies to quantify the contribution of each framework component (geometric feature aggregation, VLM-driven anchoring, self-correction)
3. Test framework robustness with ambiguous or noisy semantic inputs across varied object categories