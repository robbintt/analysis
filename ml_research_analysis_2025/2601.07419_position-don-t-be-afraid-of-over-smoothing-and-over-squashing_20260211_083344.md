---
ver: rpa2
title: 'Position: Don''t be Afraid of Over-Smoothing And Over-Squashing'
arxiv_id: '2601.07419'
source_url: https://arxiv.org/abs/2601.07419
tags:
- graph
- over-smoothing
- over-squashing
- learning
- message
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper challenges the practical relevance of over-smoothing
  and over-squashing in graph neural networks. Through extensive experiments on standard
  benchmarks, the authors show that performance degradation in deep GNNs is not consistently
  linked to these phenomena.
---

# Position: Don't be Afraid of Over-Smoothing And Over-Squashing

## Quick Facts
- **arXiv ID**: 2601.07419
- **Source URL**: https://arxiv.org/abs/2601.07419
- **Reference count**: 40
- **Primary result**: Performance degradation in deep GNNs stems from uninformative receptive fields, not over-smoothing or over-squashing.

## Executive Summary
This paper challenges the widely held belief that over-smoothing and over-squashing are the primary causes of performance degradation in deep graph neural networks. Through extensive experiments on standard benchmarks, the authors demonstrate that these phenomena do not consistently correlate with accuracy loss. Instead, they propose that performance issues arise when receptive fields grow beyond the problem radius—the k-hop neighborhood containing label-relevant information. The paper advocates for a paradigm shift toward analyzing the localization and factorisation of label-relevant information in graph learning tasks.

## Method Summary
The study evaluates GCN, GCNII, GATv2, GIN, GraphSAGE, and their variants with over-smoothing (PairNorm, G²) and over-squashing (SDRF, BORF, EGP) mitigations across 8 node classification and 4 graph classification datasets. Hyperparameter search spans depths 2-64 with cross-validation on training+validation splits. Performance is measured via classification accuracy, while over-smoothing (MAD, Dirichlet energy) and over-squashing (curvature) metrics are computed on final embeddings. The experiments systematically test whether mitigation techniques improve accuracy beyond shallow baselines.

## Key Results
- Optimal GNN depth clusters at 2-8 layers across datasets and mitigation strategies
- Accuracy degradation often occurs before over-smoothing measures (MAD, Dirichlet energy) collapse
- Over-squashing mitigation techniques show no consistent accuracy improvements despite measurable curvature reduction
- Performance correlates poorly with traditional over-smoothing and over-squashing metrics

## Why This Works (Mechanism)

### Mechanism 1: Uninformative Receptive Fields
Performance degradation in deep GNNs often stems from uninformative receptive fields, not over-smoothing. As message passing layers increase, the receptive field grows beyond the "problem radius" (the k-hop neighborhood containing label-relevant information). Adding layers incorporates noise from distant nodes without adding predictive signal, degrading accuracy before representations collapse. Label-relevant information is localized within a small k-hop neighborhood for most practical tasks.

### Mechanism 2: Information Factorisation
Over-squashing mitigation fails because label-relevant information factorizes across receptive fields. Over-squashing definitions assume the joint distribution over a node's receptive field must be observed holistically. In practice, information factorizes—node embeddings can process neighborhood subsets independently. Fixed-size representations suffice when high-order interactions between distant nodes are absent. Real-world graph learning tasks rarely require modeling complex interaction effects across the entire receptive field simultaneously.

### Mechanism 3: Non-Relevant Bottlenecks
Curvature-based bottleneck mitigation does not consistently improve accuracy on standard benchmarks. Rewiring techniques (SDRF, BORF, EGP) reduce negative curvature to ease information flow through bottleneck edges. However, low-curvature edges often separate structural communities whose labels correlate within-community—inter-community information exchange through bottlenecks isn't task-relevant. Bottleneck edges connect regions whose label distributions are conditionally independent given local structure.

## Foundational Learning

- **Message Passing Neural Networks and Receptive Fields**: Understanding that each layer expands the receptive field exponentially (|N^(L)(v)| = O(e^L)) is prerequisite to grasping why over-squashing was hypothesized as problematic. Quick check: For a node with average degree 10, approximately how many nodes are in its 3-hop receptive field?

- **Over-Smoothing Measures (MAD, Dirichlet Energy)**: The paper empirically shows these metrics correlate poorly with accuracy. Understanding what they measure (representation similarity across nodes) vs. what they don't (task-relevant information preservation) clarifies the authors' argument. Quick check: If MAD approaches zero (all representations converge), does this guarantee poor classification performance? What does the paper's data suggest?

- **Graph Curvature and Structural Bottlenecks**: Curvature-based rewiring is a dominant over-squashing mitigation strategy. Understanding that negative curvature indicates bottlenecks (edges connecting sparsely-overlapping neighborhoods) is essential to evaluate the paper's critique. Quick check: Would you expect curvature-based rewiring to help on a graph where communities share the same label? Why or why not?

## Architecture Onboarding

- **Component map**: Base GNN (GCN, GATv2, GraphSAGE, GIN) -> Over-smoothing mitigations (PairNorm, GCNII, G²) -> Over-squashing mitigations (SDRF, BORF, EGP) -> Alternatives for long-range (Graph Transformers, virtual nodes)

- **Critical path**: Task analysis before architecture selection: Quantify problem radius and information localization. Start shallow: Tables 1-3 show optimal depths cluster at 2-8 layers across datasets and mitigation strategies. Measure degradation pattern: If accuracy drops before MAD/distance metrics collapse, suspect uninformative receptive fields, not over-smoothing.

- **Design tradeoffs**: Depth vs. noise: More layers = larger receptive field = more potential noise from irrelevant nodes. Mitigation overhead: Rewiring techniques add preprocessing cost; mitigation models (GCNII, G²) add per-layer compute. Paper shows marginal accuracy gains rarely justify this. Alternative architectures: Graph Transformers handle long-range dependencies more directly than deep MPNNs, but with higher computational cost.

- **Failure signatures**: Accuracy collapses to random baseline (e.g., 31.9% on Cora at 16+ layers for standard GCN) while MAD remains elevated → uninformative receptive fields, not over-smoothing. Rewiring produces measurable curvature improvement but no accuracy gain → bottleneck edges not task-relevant. GCNII/G² maintain accuracy at depth but don't improve over shallow baseline → problem radius already captured at depth 2-4.

- **First 3 experiments**:
  1. Establish shallow baseline: Train GCN/GAT at depths 2, 4, 8 on your task with proper hyperparameter search. Identify optimal depth.
  2. Diagnostic: Accuracy vs. MAD curve: At each depth, plot test accuracy alongside MAD (3-hop) or Dirichlet energy. If accuracy degrades before smoothing metrics collapse, the problem is receptive field relevance.
  3. Mitigation ablation: Add one mitigation (e.g., PairNorm or GCNII) and re-run depth sweep. If optimal depth and peak accuracy don't meaningfully improve, architectural over-smoothing is not your bottleneck—revisit feature engineering, graph construction, or task formulation.

## Open Questions the Paper Calls Out

- Can we develop statistics that quantify the localization and factorization of label-relevant information to predict the necessary receptive field size for a given task? The authors explicitly advocate for a paradigm shift towards "diligent analysis of learning tasks using statistics that measure the localisation and factorisation of label-relevant information."

- Do real-world graph learning tasks exist where unique, relevant information is strictly localized in distant nodes, thereby validating the theoretical necessity of long-range interaction modeling? The authors call for research to find "real-world examples, in which such phenomena can be observed and measured."

- Does the joint distribution of label-relevant information in graph receptive fields generally factorize into independent marginals? The authors suggest exploring "potential factorisation of the label distribution over k-hop receptive fields to assess the importance of a joint observation of the whole receptive field."

## Limitations

- Current measures (e.g., Dirichlet energy, curvature) quantify structural phenomena like smoothing or squashing but fail to measure if the lost information is actually relevant to the prediction task.

- Dataset selection may bias results toward tasks with inherently localized label-relevant information, potentially missing cases where long-range interactions are genuinely necessary.

- Study focuses on MPNN architectures, potentially missing cases where curvature-based bottlenecks genuinely matter for other GNN variants like Graph Transformers.

## Confidence

- **High Confidence**: Performance degradation before representation collapse indicates uninformative receptive fields (empirical observation across multiple datasets).
- **Medium Confidence**: Label-relevant information factorizes across receptive fields (theoretical argument supported by empirical absence of correlation between curvature and accuracy).
- **Low Confidence**: Over-smoothing and over-squashing are not practical problems requiring mitigation (conclusion based on standard benchmarks that may not represent all real-world scenarios).

## Next Checks

1. **Problem Radius Measurement**: Develop and apply empirical methods to measure the actual k-hop neighborhood containing label-relevant information for each dataset, then compare optimal GNN depth to this measured radius.

2. **Factorisation Quantification**: Create statistical tests to measure the degree of factorisation in label-relevant information across nodes, and correlate this with whether over-squashing mitigations help or hurt.

3. **Long-Range Dependency Stress Test**: Design synthetic benchmarks with known long-range dependencies to validate when curvature-based rewiring and deep architectures become necessary.