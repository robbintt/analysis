---
ver: rpa2
title: Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer
  Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic
  3D-TBP Images
arxiv_id: '2506.03420'
source_url: https://arxiv.org/abs/2506.03420
tags:
- lesion
- skin
- lesions
- features
- malignant
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of skin cancer detection using
  3D-Total Body Photography (TBP) images that simulate non-dermoscopic smartphone
  conditions. The proposed hybrid framework combines deep learning models (EVA02 transformer
  and EdgeNeXtSAC convolutional hybrid) with engineered metadata and synthetic lesion
  augmentation.
---

# Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images

## Quick Facts
- arXiv ID: 2506.03420
- Source URL: https://arxiv.org/abs/2506.03420
- Reference count: 23
- Primary result: pAUC of 0.1755 above 80% TPR using hybrid ensemble of deep models and GBDT

## Executive Summary
This study addresses skin cancer detection using 3D-Total Body Photography images simulating non-dermoscopic smartphone conditions. The proposed hybrid framework combines deep learning models (EVA02 transformer and EdgeNeXtSAC convolutional hybrid) with engineered metadata and synthetic lesion augmentation. A key innovation is the segmentation-assisted classification approach, which improves lesion localization through joint classification and segmentation training using a dual-head architecture with attention mechanisms. The ensemble approach integrates image-based model predictions with gradient-boosted decision trees trained on 214 engineered features including patient-specific metrics and geometric descriptors. Synthetic malignant lesions generated via Stable Diffusion address class imbalance.

## Method Summary
The approach uses two image models: EVA02-small for binary classification and 3-class classification, and EdgeNeXtSAC with a dual-head architecture combining classification and segmentation decoders. Both models are trained on ISIC 2024 SLICE-3D data with 3-fold Stratified Group K-Fold, incorporating 1:1 batch balancing and synthetic malignant lesions. The segmentation-assisted classification uses a combined loss function incorporating classification, CAM, and segmentation terms with attention mechanisms. Image model outputs are fused with 214 engineered metadata features and fed into a GBDT ensemble (LightGBM, XGBoost, CatBoost) trained with 3×5-fold cross-validation. Gaussian noise injection on external prediction features provides regularization.

## Key Results
- Achieved pAUC of 0.1755 above 80% TPR, highest among tested configurations
- Segmentation-assisted classification improves lesion localization through joint training
- GBDT ensemble integrates image model softmax outputs with 214 engineered features
- Synthetic malignant lesions via Stable Diffusion address severe class imbalance
- 3D-TBP images simulate challenging non-dermoscopic smartphone capture conditions

## Why This Works (Mechanism)
The hybrid approach leverages complementary strengths: deep learning models capture spatial patterns in skin lesions while engineered metadata provides clinical context. The segmentation-assisted classification explicitly learns lesion boundaries alongside classification, improving localization accuracy. The ensemble combines image-based predictions with patient-specific features, capturing both visual and clinical patterns. Synthetic lesions address class imbalance without introducing domain shift, while attention mechanisms in the dual-head architecture focus learning on lesion regions.

## Foundational Learning
- **3D-Total Body Photography (TBP)**: Comprehensive body imaging capturing multiple views of lesions in real-world conditions. Needed to simulate clinical workflows and capture lesion context. Quick check: verify dataset contains multiple images per patient with varied perspectives.
- **Partial AUC (pAUC)**: Evaluation metric focusing on high-sensitivity region of ROC curve. Needed for clinical applications where missing malignant cases is unacceptable. Quick check: confirm pAUC calculation correctly normalizes to [0.0, 0.2] range.
- **Segmentation-assisted classification**: Joint training of classification and segmentation tasks. Needed to improve lesion localization and reduce false positives. Quick check: verify dual-head architecture properly shares backbone features between tasks.
- **Stratified Group K-Fold**: Cross-validation method preserving class distribution while preventing patient-level data leakage. Needed for reliable evaluation with patient-level dependencies. Quick check: confirm no patient_id appears in both train and validation folds.
- **Gradient Boosted Decision Trees (GBDT)**: Ensemble learning method combining multiple decision trees. Needed to integrate heterogeneous features (image predictions + metadata). Quick check: verify feature importance distribution and regularization effectiveness.

## Architecture Onboarding
**Component Map**: ISIC Data -> EVA02 + EdgeNeXtSAC -> Softmax Outputs -> 214 Engineered Features -> GBDT Ensemble -> pAUC Evaluation
**Critical Path**: Image Model Training (3-fold) -> Feature Engineering (174 features) -> GBDT Training (45 models) -> Ensemble Prediction
**Design Tradeoffs**: 
- Segmentation decoder adds complexity but improves localization
- 174 engineered features increase interpretability but require domain expertise
- 3×5-fold GBDT ensemble reduces variance but increases computational cost
**Failure Signatures**: 
- Data leakage across patients causes inflated metrics
- Class imbalance leads to degenerate classifiers
- Overfitting to image features in GBDT ensemble
**First Experiments**:
1. Train EVA02-small binary classifier with 3-fold Group K-Fold to verify basic image model performance
2. Generate 10 synthetic malignant lesions using Stable Diffusion to validate generation pipeline
3. Train single LightGBM model on 214 features to verify feature integration before full ensemble

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic lesion generation code and prompts are not publicly available, preventing independent verification
- Heavy reliance on external ISIC data for transfer learning introduces potential domain shift
- pAUC evaluation at high TPR may not fully capture clinical utility trade-offs
- Engineered feature set lacks detailed implementation specifications

## Confidence
- **High confidence**: Architectural framework combining image models with metadata-driven GBDT ensemble is sound and well-documented
- **Medium confidence**: Segmentation-assisted classification improvement is plausible but depends on implementation details
- **Low confidence**: Synthetic lesion generation approach cannot be independently verified due to missing implementation details

## Next Checks
1. Implement strict patient-level stratification in all cross-validation splits to verify no patient ID appears across training and validation sets
2. Generate a small set of synthetic malignant lesions using Stable Diffusion and conduct blind review by dermatologists to evaluate clinical plausibility
3. Perform ablation studies on the 214 engineered features to identify which contribute most to GBDT ensemble's performance