---
ver: rpa2
title: Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal
  Alignment
arxiv_id: '2505.13175'
source_url: https://arxiv.org/abs/2505.13175
tags:
- time
- series
- alignment
- forecasting
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of using large language models
  (LLMs) for time series forecasting by proposing a novel cross-modal alignment framework
  called Structure-Guided Cross-Modal Alignment (SGCMA). The key insight is that effective
  alignment should leverage the structural consistency between time series and language
  sequences rather than just token-level features.
---

# Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment

## Quick Facts
- arXiv ID: 2505.13175
- Source URL: https://arxiv.org/abs/2505.13175
- Reference count: 40
- Primary result: SGCMA achieves 4.0-5.9% reductions in MSE/MAE compared to LLM-based baselines

## Executive Summary
This paper addresses the challenge of using large language models (LLMs) for time series forecasting by proposing a novel cross-modal alignment framework called Structure-Guided Cross-Modal Alignment (SGCMA). The key insight is that effective alignment should leverage the structural consistency between time series and language sequences rather than just token-level features. SGCMA achieves this through two main components: (1) Structure Alignment, which transfers language-derived state transition structures to time series using HMM and MEMM models, and (2) Semantic Alignment, which aligns temporal patches with language tokens through cross-attention weighted by state probabilities. Experiments across multiple benchmarks demonstrate state-of-the-art performance, with SGCMA achieving significant improvements over existing methods including 4.0-5.9% reductions in MSE/MAE compared to LLM-based baselines, and strong performance in few-shot and zero-shot forecasting scenarios. The framework shows that carefully designed sequence-level structural alignment is sufficient to activate frozen LLMs for effective time series forecasting.

## Method Summary
SGCMA is a cross-modal alignment framework that enables frozen LLMs to perform time series forecasting by leveraging structural similarities between time series and language sequences. The method consists of three main components: (1) Structure Alignment, which uses HMM and MEMM models to transfer language-derived state transition structures to time series; (2) Semantic Alignment, which aligns temporal patches with language tokens through cross-attention weighted by state probabilities; and (3) a frozen LLM backbone (GPT-2) that performs the actual forecasting. The approach extracts structural priors from text corpora using HMM, then uses a MEMM-like decoder to regularize time series sequential decoding while allowing local feature adaptation. Finally, it aligns time series patches to semantic LLM token space through state-dependent cross-attention, enabling the LLM to process numerical sequences as "language-like" inputs.

## Key Results
- SGCMA achieves 4.0-5.9% reductions in MSE/MAE compared to LLM-based baselines
- Strong performance in few-shot and zero-shot forecasting scenarios
- Outperforms existing methods across multiple benchmarks including Traffic, ETT, and Exchange Rate datasets
- Demonstrates that sequence-level structural alignment is sufficient to activate frozen LLMs for time series forecasting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Transferring structural priors (state transition dynamics) from natural language to time series improves the LLM's ability to process numerical sequences by rendering them "language-like."
- **Mechanism:** An Hidden Markov Model (HMM) is trained on text to learn a global transition matrix ($A_{text}$). This matrix is transferred to the time series domain ($A_{time}$) to regularize the sequential decoding of time series patches, ensuring the temporal sequence mimics linguistic transition dynamics (e.g., syntax).
- **Core assumption:** Time series and language share analogous latent Markovian structures (e.g., "rising → stable → falling" parallels "pronoun → verb → noun").
- **Evidence anchors:** [abstract] Mentions exploiting "shared sequence structure" and transferring "structural priors from natural language." [3.1] Describes extracting transition matrix $A_{text}$ and emission matrix $B_{text}$ from text via HMM.
- **Break condition:** If the time series data is non-Markovian (long-term dependencies only) or chaotic, the first-order assumption of the HMM prior may over-constrain the model.

### Mechanism 2
- **Claim:** A Maximum Entropy Markov Model (MEMM)-like approach allows the time series model to adhere to linguistic structure while adapting to local temporal features.
- **Mechanism:** Instead of a standard HMM, the paper uses a Transformer-based MEMM. It calculates patch probabilities based on local features ($\gamma$) and then recursively refines them using the transition prior ($A_{time}$) and the previous state probability ($\tilde{\gamma}_{p-1}$). This biases the sequence structure toward the language prior while allowing the current patch content to influence the state.
- **Core assumption:** The frozen transition matrix $A_{time}$ (learned from text) serves as a valid "hot-start" or inductive bias for temporal clustering.
- **Evidence anchors:** [3.2] "Structure-regularized Sequential Decoding" using Eq. 8: $\tilde{\gamma}_p = \text{Softmax}((\tilde{\gamma}_{p-1}^\top \times A_{time})^\top \odot \gamma_p)$. [Figure 5] Visualizes the adjustment of state probabilities when combining patch embeddings with the transition prior.
- **Break condition:** If the shallow Transformer encoder fails to extract meaningful features ($\gamma_p$ becomes noise), the recursive application of the transition matrix may amplify errors (error propagation).

### Mechanism 3
- **Claim:** Aligning time series patches to the semantic space of LLM tokens via "soft" state-dependent cross-attention activates the LLM's reasoning capabilities.
- **Mechanism:** The model identifies the top-$k$ tokens for each hidden state from the HMM emission matrix. It computes an aligned embedding for a time series patch by performing a weighted average of cross-attention outputs, where weights are the posterior state probabilities ($\tilde{\gamma}_p$) derived from Mechanism 2.
- **Core assumption:** The top-$k$ tokens associated with a hidden state (e.g., tokens for a "noun" state) provide a meaningful semantic anchor for a time series patch mapped to that structural state.
- **Evidence anchors:** [3.3] Describes retrieving top-$k$ tokens and using expected value weighting (Eq. 11). [abstract] States "cross-attention between temporal patches and top-k language tokens within each state."
- **Break condition:** If the HMM states are polysemous or the top-$k$ tokens are generic (e.g., stopwords), the semantic grounding will be weak, leading to poor LLM performance.

## Foundational Learning

- **Concept: Hidden Markov Models (HMMs)**
  - **Why needed here:** Used to extract the "structural prior" (transition matrix) from text. Without understanding HMM states and transitions, the source of the structural guidance in Section 3.1 is opaque.
  - **Quick check question:** Can you explain the difference between an emission probability and a transition probability in the context of a sentence?

- **Concept: Maximum Entropy Markov Models (MEMMs)**
  - **Why needed here:** The paper modifies the standard HMM approach for time series using a MEMM-like formulation (Section 3.2). You must understand that MEMMs allow the transition to depend on the *current observation features* (unlike HMMs).
  - **Quick check question:** In an MEMM, does the probability of moving to state $S_t$ depend only on $S_{t-1}$, or also on the input observation at $t$?

- **Concept: Cross-Modal Alignment (Patching & Embedding)**
  - **Why needed here:** The core task is mapping numerical patches to the LLM's vector space. Understanding how patching works (splitting time series into segments) is prerequisite to understanding how semantic alignment (Section 3.3) is applied.
  - **Quick check question:** Why is "patching" used instead of feeding raw time-steps into the LLM? (Hint: Context window and semantic density).

## Architecture Onboarding

- **Component map:** HMM Pre-trainer -> Structural Aligner -> Semantic Aligner -> Frozen LLM
- **Critical path:** The "Hot-start" initialization. The $A_{time}$ matrix must be successfully initialized from $A_{text}$ (Section 3.2). If this transfer fails or dimensions mismatch, the MEMM cannot regularize the time series sequence.
- **Design tradeoffs:**
  - **State Count ($N$):** Fixed at 100 in experiments. Section 4.4 / Figure 6 shows high $N$ helps complex datasets (Traffic with 862 channels) but is less critical for simple ones (ETT with 7 channels).
  - **Frozen vs. Fine-tuned:** The architecture relies on the LLM remaining frozen (Section 3.4). This trades off potential peak performance for generalization and efficiency.
- **Failure signatures:**
  - **L1 Distance Spike:** If the L1 distance between the transition matrix of text and the learned TS matrix is high (Section 4.4 mentions low distance 0.046 as success), the structural alignment has failed to impose language-like properties.
  - **State Collapse:** If the MEMM collapses all patches to a single state probability, the semantic alignment reduces to a single set of tokens, losing temporal nuance.
- **First 3 experiments:**
  1. **Sanity Check (Visualization):** Replicate Figure 4. Visualize the state transition graph for Text vs. Time Series. Verify that "green edges" (shared transitions) exist.
  2. **Ablation (Structure vs. Semantic):** Replicate Table 5. Disable the Structure Alignment (use uniform weights) to confirm performance drops. This validates the core hypothesis.
  3. **Hyperparameter Sensitivity:** Run a sweep on the number of latent states $N$ (e.g., [20, 50, 100, 200]) on a high-channel dataset like Traffic to find the scaling inflection point suggested in Figure 6.

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Reliance on HMM assumption that time series and language share analogous latent Markovian structures, which may not hold for non-Markovian or chaotic data
- Fixed state count of 100 may not scale optimally across all datasets, particularly those with very high channel counts
- Frozen LLM approach may limit peak performance compared to fine-tuning strategies

## Confidence

**High Confidence (Mechanistic Understanding):** The paper clearly explains the three core mechanisms - structural alignment via HMM transfer, MEMM-based sequential decoding, and semantic alignment through state-dependent cross-attention. The mathematical formulations are explicit and reproducible.

**Medium Confidence (Empirical Validation):** The experimental results show SGCMA outperforming baselines with 4.0-5.9% reductions in MSE/MAE, but the validation is primarily comparative rather than diagnostic. The paper doesn't provide ablation studies that isolate the contribution of each mechanism or analyze failure modes.

**Low Confidence (Foundational Assumptions):** The critical assumption that time series and language share analogous latent structures is asserted rather than empirically validated. The paper demonstrates structural transfer but doesn't prove this transfer is semantically meaningful for forecasting.

## Next Checks

1. **Structural Validity Analysis:** Perform an ablation where the HMM structure is randomized or mismatched between text and time series. Measure whether performance degrades proportionally to the L1 distance between transition matrices, directly testing the structural alignment hypothesis.

2. **Feature Quality Assessment:** Analyze the Transformer encoder's patch embeddings ($\gamma_p$) when the MEMM decoding fails. Create synthetic time series with known patterns that should trigger specific states, and verify the model correctly identifies them versus random assignment.

3. **Semantic Grounding Validation:** For each HMM state, analyze the semantic coherence of the top-k tokens and their relevance to the time series patches assigned to that state. Create a human-annotated validation set where annotators judge whether the token-patch associations are meaningful, particularly for states that show high forecasting error.