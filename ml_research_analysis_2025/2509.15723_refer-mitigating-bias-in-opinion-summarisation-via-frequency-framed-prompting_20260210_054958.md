---
ver: rpa2
title: 'REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting'
arxiv_id: '2509.15723'
source_url: https://arxiv.org/abs/2509.15723
tags:
- refer
- frequency
- prompting
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses bias in opinion summarisation by large language
  models (LLMs), where generated summaries often fail to proportionally represent
  diverse viewpoints. Drawing from cognitive science research showing that frequency-based
  representations reduce human statistical reasoning biases, the authors introduce
  REFER (Frequency Framed Prompting), which explicitly instructs models to first quantify
  opinion distributions using concrete frequency information before generating balanced
  summaries.
---

# REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting
## Quick Facts
- arXiv ID: 2509.15723
- Source URL: https://arxiv.org/abs/2509.15723
- Authors: Nannan Huang; Haytham M. Fayek; Xiuzhen Zhang
- Reference count: 26
- Key outcome: Frequency-framed prompting significantly improves fairness in opinion summarisation by explicitly quantifying opinion distributions before generating balanced summaries

## Executive Summary
This paper addresses bias in opinion summarisation where large language models (LLMs) often fail to proportionally represent diverse viewpoints in generated summaries. Drawing from cognitive science research showing that frequency-based representations reduce human statistical reasoning biases, the authors introduce REFER (Frequency Framed Prompting), which explicitly instructs models to first quantify opinion distributions using concrete frequency information before generating balanced summaries. Systematic experiments across multiple datasets, models, and prompting frameworks demonstrate that REFER significantly improves fairness in opinion summarisation, particularly for larger models and when combined with stronger reasoning instructions like Chain-of-Thought. The approach achieves consistent improvements across fairness metrics (SPD, BUR, UER, SOF) and shows larger effects than differences between base prompting frameworks.

## Method Summary
The REFER framework uses zero-shot prompting with frequency-framed instructions to improve proportional representation in opinion summarisation. The approach explicitly instructs models to first determine how many reviews/documents fall into each opinion category using concrete frequency statements, then generate balanced summaries that reflect these distributions. The method was evaluated on FairSumm (political tweets) and Amazon Reviews 2023 datasets using multiple prompting frameworks (Direct, Fair Prefix, Persona, Chain-of-Thought, Agent) with both small (8B) and large (70B) language models. Evaluation used four fairness metrics: SPD, BUR, UER, and SOF, with GPT-4o-mini for sentence classification and BARTScore for token-based metrics.

## Key Results
- REFER consistently improves fairness metrics (SPD, BUR, UER, SOF) across all tested models and datasets
- Larger models (70B) show significantly better REFER performance than smaller models (8B), which often fail to follow sequential instructions
- Chain-of-Thought augmentation (CoT-R) provides additional improvements over standalone REFER
- REFER achieves larger fairness improvements than differences between base prompting frameworks (Direct, Fair Prefix, Persona)

## Why This Works (Mechanism)
### Mechanism 1: Reference Class Specification
Frequency-framed prompts improve proportional representation by forcing explicit enumeration of opinion categories with concrete denominators. Prompts like "determine how many reviews out of {n} are {category}" replace abstract "be balanced" instructions with specific comparison groups, reducing ambiguity in what proportional representation means.

### Mechanism 2: Numerical Anchoring Reduces Estimation Variance
Pre-computed frequency counts provide numerical anchors that constrain subsequent proportion estimation during text generation. Explicit frequency statements ("4 out of 8 are positive") create concrete targets before generative decoding begins, reducing drift toward model priors or salience-driven oversampling.

### Mechanism 3: Sequential Deliberation via Reasoning Separation
Decomposing the task into frequency analysis followed by summarization engages more deliberate processing, reducing intuitive/heuristic-driven biases. The two-phase structure (count first, then summarize) mirrors dual-process interventions that improve human reasoning by separating quantitative analysis from narrative generation.

## Foundational Learning
- **Concept: Second-order vs. First-order Fairness Metrics** - The paper distinguishes between metrics measuring broad representation (BUR, UER) versus those detecting systematic bias patterns relative to input distributions (SPD, SOF). Understanding this distinction is critical for interpreting Table 1 results.
- **Concept: Chain-of-Thought Prompting (CoT)** - CoT-R shows the strongest improvements. You need to understand baseline CoT ("Let's think step by step") to see how REFER extends it with frequency-framed reasoning.
- **Concept: Instruction-Following Capacity Scaling** - Results show REFER effectiveness correlates with model size (8B fails, 70B succeeds). This relates to emergent instruction-following capabilities in larger models.

## Architecture Onboarding
- **Component map:** Input Documents → REFER Prompt Construction → Model (Frequency Analysis Phase) → Model (Summary Generation Phase) → Decomposed Summary Sentences → Fairness Metric Calculation
- **Critical path:** The frequency analysis instruction must be executed and its output must influence the summary. Breaks occur at either step.
- **Design tradeoffs:** REFER vs. Oracle (ground-truth frequencies): Oracle is more fair but requires labeled data; REFER is end-user deployable without labels. CoT-R vs. Agent-R: CoT-R is simpler and more effective; Agent-R adds complexity without proportional gains.
- **Failure signatures:** Output begins with qualitative assessment rather than frequency counts → instruction-following failure. Summary word count shows high variance → model not consistently following length constraints.
- **First 3 experiments:** 1) Replicate Direct Prompting vs. REFER comparison on GPT-4o-mini with your own review dataset, measuring SPD and SOF. 2) Add CoT-R condition and verify that Chain-of-Thought augmentation provides statistically significant improvements over standalone REFER. 3) Test boundary condition: at what model scale does the frequency analysis step begin to execute reliably?

## Open Questions the Paper Calls Out
1. Can automated prompt generation techniques significantly enhance REFER's fairness performance compared to manually crafted prompts?
2. Do LLMs process frequency-framed prompts using computational mechanisms analogous to human statistical reasoning?
3. How can the REFER framework be adapted to effectively mitigate bias in smaller language models (<10B parameters)?

## Limitations
- The study focuses exclusively on binary opinion spaces and assumes equal treatment of all opinions is the desired outcome
- The evaluation framework using BARTScore-based metrics introduces potential circularity since the same model is used for both classification and measurement
- Temperature=0.001 setting may suppress natural variation that could reveal different failure modes under more typical generation conditions

## Confidence
- **High confidence**: Larger models show greater REFER effectiveness, aligning with established scaling laws for instruction-following capabilities
- **Medium confidence**: Mechanism claims about numerical anchoring and sequential deliberation are theoretically plausible but lack direct causal evidence
- **Low confidence**: Generality of REFER across different types of bias (gender, age, etc.) is asserted but not demonstrated

## Next Checks
1. Systematically test whether 70B models occasionally skip frequency analysis under different prompt formulations
2. Measure whether improved fairness metrics from REFER translate to better downstream outcomes in real applications
3. Re-run experiments with weighted fairness metrics that account for opinion prevalence or importance