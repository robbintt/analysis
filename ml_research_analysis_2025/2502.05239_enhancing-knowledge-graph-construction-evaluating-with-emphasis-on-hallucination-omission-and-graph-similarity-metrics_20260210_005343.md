---
ver: rpa2
title: 'Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination,
  Omission, and Graph Similarity Metrics'
arxiv_id: '2502.05239'
source_url: https://arxiv.org/abs/2502.05239
tags:
- graph
- knowledge
- arxiv
- graphs
- construction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates knowledge graph construction using large language
  models, specifically comparing Mistral's original and fine-tuned versions through
  zero-shot and few-shot learning. The authors introduce refined evaluation metrics
  including BERTScore-based graph similarity with a 95% threshold, and improved hallucination/omission
  detection using Optimal Edit Paths.
---

# Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics

## Quick Facts
- arXiv ID: 2502.05239
- Source URL: https://arxiv.org/abs/2502.05239
- Reference count: 40
- Key outcome: Fine-tuned Mistral significantly improves knowledge graph construction accuracy while reducing hallucinations and omissions, but shows reduced generalization capabilities.

## Executive Summary
This paper presents a comprehensive evaluation framework for knowledge graph construction using large language models, specifically comparing Mistral's original and fine-tuned versions. The authors introduce refined evaluation metrics including BERTScore-based graph similarity with a 95% threshold and improved hallucination/omission detection using Optimal Edit Paths. Through experiments on WebNLG and KELM-sub datasets, the study demonstrates that fine-tuned Mistral significantly enhances graph construction accuracy while reducing errors, though it exhibits reduced generalization capabilities on certain datasets.

## Method Summary
The paper introduces a multi-faceted evaluation framework for knowledge graph construction that combines traditional metrics with novel approaches. The methodology includes BERTScore-based graph similarity with a 95% threshold for evaluating structural accuracy, Optimal Edit Paths for detecting hallucinations and omissions in generated graphs, and comparative analysis of zero-shot versus few-shot learning approaches. The evaluation is conducted on two datasets (WebNLG and KELM-sub) using both original and fine-tuned Mistral models, with performance measured across multiple dimensions including accuracy, hallucination rates, and omission frequencies.

## Key Results
- Fine-tuned Mistral significantly improves knowledge graph construction accuracy compared to original models
- The 95% BERTScore threshold effectively captures graph similarity while maintaining computational efficiency
- Optimal Edit Paths method provides more precise detection of hallucinations and omissions in generated graphs
- Fine-tuned models show reduced generalization capabilities on KELM-sub dataset, indicating potential overfitting
- Zero-shot learning approaches demonstrate competitive performance with few-shot methods in certain scenarios

## Why This Works (Mechanism)

## Foundational Learning

**Knowledge Graph Construction** - Process of creating structured representations from unstructured text using LLMs. Why needed: Forms the foundation for evaluating model performance in converting natural language to structured data. Quick check: Verify input text is properly parsed into subject-predicate-object triples.

**BERTScore-Based Similarity** - Metric using contextual embeddings to compare generated graphs with ground truth. Why needed: Provides more nuanced evaluation than exact match metrics. Quick check: Ensure similarity scores above 0.95 meet threshold criteria.

**Optimal Edit Paths** - Method for identifying minimal changes between generated and reference graphs. Why needed: Enables precise detection of hallucinations and omissions. Quick check: Validate path calculations correctly identify mismatched triples.

**Zero-Shot vs Few-Shot Learning** - Comparison of model performance without vs with minimal examples. Why needed: Determines most effective training approach for graph construction. Quick check: Confirm consistent prompt formatting across both approaches.

**Hallucination Detection** - Process of identifying factually incorrect information in generated graphs. Why needed: Critical for ensuring reliability of constructed knowledge graphs. Quick check: Verify false triples are correctly flagged as hallucinations.

## Architecture Onboarding

**Component Map**: Text Input -> Mistral Model -> Graph Generation -> Evaluation Metrics -> Performance Assessment

**Critical Path**: The most critical sequence is Text Input → Mistral Model → Graph Generation → BERTScore Evaluation → Hallucination/Omission Detection, as this directly measures the core functionality of converting text to accurate knowledge graphs.

**Design Tradeoffs**: The framework balances between computational efficiency (using BERTScore threshold) and accuracy (detailed edit path analysis). While the 95% threshold speeds up evaluation, it may miss subtle structural differences. The fine-tuning approach improves accuracy but reduces generalization, requiring careful consideration of use-case requirements.

**Failure Signatures**: Common failure modes include generation of factually incorrect triples (hallucinations), missing valid relationships (omissions), and structural inconsistencies between generated and reference graphs. Performance degradation on KELM-sub suggests potential overfitting to training data patterns.

**First Experiments**: 
1. Run baseline evaluation using original Mistral on WebNLG dataset to establish performance benchmarks
2. Implement BERTScore threshold comparison with ground truth to validate similarity scoring
3. Test Optimal Edit Paths method on sample hallucinations to verify detection accuracy

## Open Questions the Paper Calls Out
The paper suggests several future research directions including integration of human evaluation for more comprehensive assessment, development of synonym-aware evaluation metrics, and investigation of methods to improve generalization capabilities of fine-tuned models while maintaining accuracy gains.

## Limitations
- Limited dataset scope (WebNLG and KELM-sub) may not capture full range of real-world knowledge graph construction scenarios
- Automated metrics without human evaluation integration may miss nuanced quality issues in generated graphs
- Potential biases in training data and evaluation metrics not addressed, affecting reliability of conclusions
- Fine-tuned models show reduced generalization capabilities, suggesting possible overfitting to specific datasets

## Confidence

**High Confidence**: The experimental methodology and metric definitions are clearly presented and reproducible. The observed improvements in graph construction accuracy and reduced hallucinations/omissions with fine-tuned Mistral are supported by quantitative evidence.

**Medium Confidence**: The generalization limitations and performance degradation on KELM-sub are reported, but the underlying causes and implications require further investigation. The effectiveness of the proposed evaluation metrics in real-world applications remains to be validated.

**Low Confidence**: The paper's suggestions for future research directions (synonym-aware assessments, human evaluation integration) are reasonable but lack concrete implementation details or preliminary validation.

## Next Checks
1. Conduct human evaluation studies to validate the automated metric results and assess real-world applicability of the fine-tuned models.

2. Test the fine-tuned Mistral model on additional, diverse knowledge graph construction datasets to better understand generalization capabilities and potential overfitting.

3. Implement and evaluate synonym-aware assessment methods as suggested, comparing results with current metrics to determine practical improvements in evaluation accuracy.