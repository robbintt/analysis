---
ver: rpa2
title: Leveraging Pre-trained Large Language Models with Refined Prompting for Online
  Task and Motion Planning
arxiv_id: '2504.21596'
source_url: https://arxiv.org/abs/2504.21596
tags:
- planning
- task
- execution
- action
- prompting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents LLM-PAS, a closed-loop planning and acting system
  for robotic task and motion planning that leverages pre-trained large language models
  (LLMs) to handle execution anomalies. The system transfers part of the constraint-checking
  process from the planning phase to execution, allowing exploration of the constraint
  space and more accurate anomaly feedback.
---

# Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning

## Quick Facts
- **arXiv ID**: 2504.21596
- **Source URL**: https://arxiv.org/abs/2504.21596
- **Reference count**: 35
- **Primary result**: LLM-PAS, a closed-loop TAMP system using FLP prompting, successfully handles Object Loss, Action Blocking, and State Change anomalies with up to 100% success rates in some scenarios, outperforming other LLM-based reactive planners.

## Executive Summary
This paper presents LLM-PAS, a closed-loop planning and acting system for robotic task and motion planning that leverages pre-trained large language models (LLMs) to handle execution anomalies. The system transfers part of the constraint-checking process from the planning phase to execution, allowing exploration of the constraint space and more accurate anomaly feedback. When anomalies occur that cannot be resolved by the executor, LLM-PAS uses a First Look Prompting (FLP) method to generate effective PDDL goals for replanning. Experimental results show that LLM-PAS successfully handles Object Loss, Action Blocking, and State Change anomalies with high success rates (up to 100% in some scenarios) and outperforms other LLM-based reactive planners in both simulation and real-world environments.

## Method Summary
LLM-PAS is a three-component system: (1) PDDLStream planner generates action sequences; (2) CSubBT executor handles robust execution with constraint space exploration; (3) LLM module uses First Look Prompting (FLP) to generate PDDL goals for replanning. FLP is two-step: anomaly-only initial prompt → refined prompt with action library + environment status + first look plan → PDDL goals. The system shifts constraint checking from planning to execution via CSubBTs, allowing real-time exploration of geometric constraints. When the executor encounters unresolvable anomalies, the LLM module reasons about likely causes and generates new PDDL goals for replanning.

## Key Results
- LLM-PAS successfully handles Object Loss, Action Blocking, and State Change anomalies with high success rates (up to 100% in some scenarios)
- Outperforms other LLM-based reactive planners in both simulation and real-world environments
- FLP approach reduces invalid PDDL generation frequency compared to single-prompt methods
- System demonstrates robustness in ALFRED benchmark tasks and blocks world problems

## Why This Works (Mechanism)

### Mechanism 1: Deferred Constraint Checking in Execution
- Shifting geometric constraint validation from initial planning to execution allows robust handling of sensor inaccuracies and dynamic environments
- CSubBTs perform "constraint space exploration" during execution, adjusting parameters like robot base position or grasp approach in real-time
- Break condition: High-latency sensor processing or mechanical failure prevents CSubBT from iterating through feasible grasp poses within reasonable time window

### Mechanism 2: First Look Prompting (FLP) for Replanning
- Two-stage prompting strategy isolates logical reasoning from contextual noise, resulting in more reliable PDDL goal generation
- Initial prompt provides only anomaly information for raw reasoning, then refined prompt adds action library and environmental context
- Break condition: Complex environmental states where anomaly is inherently ambiguous without full context, causing hallucinated solutions

### Mechanism 3: Closed-Loop Anomaly Recovery
- Integrates LLM reasoning with TAMP planners to resolve "open-world" anomalies that deterministic executors cannot handle
- CSubBT reports "unsatisfiable constraints" to LLM, which reasons about likely causes and generates new PDDL goals
- Break condition: LLM suggests recovery action not defined in PDDL domain file or physically impossible for robot hardware

## Foundational Learning

**PDDLStream (Task and Motion Planning)**
- Why needed: Base planner combining symbolic logic with continuous geometric sampling; understand why LLM only replaces goals rather than whole planner
- Quick check: Can you distinguish between a "static literal" (geometric fact) and a "fluent literal" (state variable) in a PDDL domain file?

**Behavior Trees (BTs)**
- Why needed: System executes plans via CSubBTs; understand tick-based execution and fallback mechanisms to debug anomaly reporting
- Quick check: How does a Behavior Tree handle a node returning "RUNNING" versus "FAILURE"?

**In-Context Learning / Chain-of-Thought (CoT)**
- Why needed: FLP method relies on CoT; understand how intermediate reasoning steps in prompts improve LLM output quality
- Quick check: Does providing a step-by-step example in a prompt guarantee the LLM will follow that logic structure for completely novel inputs?

## Architecture Onboarding

**Component map**: PDDLStream (Planner) -> CSubBT (Executor) -> LLM Module (Reasoner)

**Critical path**: 
1. Plan: PDDLStream generates plan → Convert to CSubBT
2. Execute: CSubBT runs actions; if sensor error → Internal parameter adjustment
3. Detect: If unresolvable → CSubBT returns failure code + anomaly info
4. Repair: LLM (FLP) generates new PDDL goal → PDDLStream replans

**Design tradeoffs**:
- Latency vs. Robustness: Transferring constraint checks to execution speeds up initial planning but shifts latency to robot's physical movement phase
- Generalizability vs. Reliability: Using LLM for replanning covers more edge cases than hardcoded rules, but introduces non-determinism and potential syntax errors

**Failure signatures**:
- Infinite Loops: LLM suggests checking same location repeatedly
- Syntax Errors: LLM generates logically correct goals but with invalid PDDL syntax
- Executor Deadlock: CSubBT continuously tries to re-sample impossible geometric constraint without timing out

**First 3 experiments**:
1. Single Step vs. FLP: Run "Object Loss" scenario using single-prompt method vs. FLP; verify FLP reduces syntax errors and generates more comprehensive search goals
2. Constraint Space Exploration: In simulation, obscure target object slightly; verify CSubBT adjusts robot base/joints to find feasible grasp before calling LLM
3. Action Blocking: Physically block target location (e.g., put object in microwave); confirm system detects blockage and LLM suggests moving obstructing object first

## Open Questions the Paper Calls Out
- Can FLP maintain effectiveness when scaling to significantly more complex, long-horizon TAMP tasks with larger action libraries and more diverse anomaly types?
- How can the system be made robust to repeated LLM failures where generated PDDL goals contain syntax errors or lead to deadlocks?
- How would integrating multimodal LLMs enhance the system's ability to interpret environmental anomalies and generate more contextually informed replanning goals?

## Limitations
- Limited evaluation to three specific anomaly types (Object Loss, Action Blocking, State Change) without testing more complex or cascading anomalies
- No reported failure rates for invalid PDDL syntax generated by the LLM, which could lead to system crashes in production deployments
- System's robustness to truly novel environments where action preconditions differ from training scenarios remains unclear

## Confidence
- **High Confidence**: Architectural design of shifting constraint checking from planning to execution is technically sound and supported by related work
- **Medium Confidence**: FLP prompting strategy is well-motivated theoretically and shows improvements in controlled experiments, but lacks independent replication
- **Low Confidence**: Generalizability of LLM-generated PDDL goals to novel environments and behavior under edge cases remain largely unverified

## Next Checks
1. Implement both single-prompt and FLP methods, run side-by-side on Object Loss scenario, and compare success rates and invalid PDDL generation frequency
2. In simulation, place objects in partially occluded locations and verify CSubBT adjusts robot configuration parameters to find feasible grasps before escalating to LLM
3. Physically block a target location with an object, then verify the system correctly detects the blockage and the LLM suggests moving the obstructing object first