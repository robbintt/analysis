---
ver: rpa2
title: 'From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices'
arxiv_id: '2507.23536'
source_url: https://arxiv.org/abs/2507.23536
tags:
- memory
- peft
- methods
- dora
- galore
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks parameter-efficient fine-tuning (PEFT) methods
  on edge-deployed convolutional neural networks (CNNs), focusing on depthwise-separable
  architectures like MobileNetV2 and V3. The study evaluates LoRA, DoRA, and GaLore
  against traditional fine-tuning (FFT) and batch-norm-only updates (BN+H) across
  tasks including distribution shift adaptation and unseen class handling.
---

# From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices

## Quick Facts
- arXiv ID: 2507.23536
- Source URL: https://arxiv.org/abs/2507.23536
- Authors: Georg Slamanig; Francesco Corti; Olga Saukh
- Reference count: 12
- Primary result: PEFT methods on depthwise CNNs achieve only half the memory efficiency of LLMs due to activation memory dominance, but can reduce FLOPs by up to 95%.

## Executive Summary
This paper benchmarks parameter-efficient fine-tuning (PEFT) methods on edge-deployed convolutional neural networks, focusing on depthwise-separable architectures like MobileNetV2 and V3. The study evaluates LoRA, DoRA, and GaLore against traditional fine-tuning and batch-norm-only updates across tasks including distribution shift adaptation and unseen class handling. Results show that PEFT methods are only half as memory-efficient on depthwise CNNs compared to large language models, but can reduce FLOPs during model updates by up to 95%. LoRA consistently offers the best trade-off between accuracy and computational cost, while GaLore delivers robust accuracy with fewer training iterations but higher computational complexity.

## Method Summary
The study benchmarks LoRA, DoRA, and GaLore against full fine-tuning (FFT) and batch-norm-only updates on MobileNetV2/V3 and ResNet-18 architectures pre-trained on ImageNet and CIFAR-10. Models are fine-tuned on CIFAR-10-C (brightness, impulse noise) and Visual Wake Words datasets. The authors use Hugging Face PEFT library for LoRA/DoRA, GaLore pre-release implementation, and custom PyTorch profiler to measure peak memory (broken into parameters, gradients, activations, optimizer, temporary) and FLOPs. Default settings use rank r=4, α=4, with training runs of 5 epochs and early stopping with 10-epoch patience.

## Key Results
- LoRA achieves 80% FLOPs reduction on MobileNetV3 while maintaining strong accuracy across adaptation tasks
- PEFT methods achieve only 22-48% memory reduction on MobileNets vs 67% on ResNet-18 due to activation memory dominance
- GaLore shows most consistent accuracy across different fine-tuning tasks with FFT-comparable performance
- DoRA shows 29-58% memory overhead vs LoRA with no accuracy benefits on edge CNNs

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Weight Decomposition Reduces Trainable Parameters
LoRA achieves the best accuracy-efficiency trade-off by decomposing weight updates into low-rank matrices. Weight update ΔW = AB^T where A ∈ R^(d×r), B ∈ R^(d×r) with r ≪ d. Gradients computed only for low-rank factors, not full weight matrix. Core assumption: weight updates lie in a low-rank subspace. Evidence: abstract states LoRA offers best trade-off; Section 2 explains low-rank decomposition reduces parameters and computational complexity. Break condition: when pre-trained model performs poorly and task diverges significantly, low-rank capacity insufficient (accuracy drop up to 50% vs FFT on hard tasks like impulse noise).

### Mechanism 2: Depthwise Separable Convolutions Shift Memory Bottleneck to Activations
PEFT methods achieve only half the memory efficiency on depthwise-separable CNNs compared to LLMs because activations, not gradients/optimizer states, dominate memory. DSCs split filters by input channel, reducing forward FLOPs by factor of 1/C_in. However, backward pass computes both input gradient (no reduction) and weight gradient (reduced), creating 20:1 backward-to-forward FLOPs ratio vs 2:1 for standard convolutions. Core assumption: memory bottleneck location determines PEFT effectiveness. Evidence: abstract states PEFT are only half as memory-efficient on depthwise CNNs; Figure 1 shows activation maps primary contributor to peak memory. Break condition: for standard convolutions, gradients/optimizer states dominate, so PEFT achieves 67% memory reduction vs only 22-48% for MobileNets.

### Mechanism 3: SVD-Based Gradient Projection Enables Robust Adaptation at Computational Cost
GaLore achieves FFT-comparable accuracy with fewer iterations but incurs 10-30% FLOPs overhead from SVD operations. Projects gradient G via SVD: G ≈ Σσ_i u_i v_i^T, dynamically truncating rank based on threshold ε. Maintains full-rank weight updates while using low-rank gradient representation. Core assumption: gradient space has low intrinsic dimensionality even when weight updates don't. Evidence: abstract states GaLore delivers robust accuracy with fewer iterations but higher computational complexity; Section 4 shows SVD operation introduces 10-30% FLOPs overhead. Break condition: when pre-fine-tuning accuracy already high, higher rank settings may degrade GaLore performance (up to 6% worse than LoRA).

## Foundational Learning

- **Depthwise Separable Convolutions (DSCs)**: Core architecture for edge CNNs but fundamentally alter training dynamics. Understanding their 20:1 backward-to-forward ratio explains why PEFT efficiency differs from LLMs. Quick check: Given a 3×3 convolution with 64 input and 128 output channels, what is the FLOPs reduction ratio of DSC vs standard convolution? (Answer: ~8-9× for inference, but backward pass asymmetry persists)

- **Low-Rank Matrix Decomposition**: Core mathematical foundation of LoRA/DoRA. Without this, you cannot reason about rank selection or capacity trade-offs. Quick check: If a weight matrix W is 1024×1024 and rank r=8, how many parameters does LoRA require vs full fine-tuning? (Answer: 2×1024×8 = 16,384 vs 1,048,576, ~64× reduction)

- **PyTorch Memory Groups (PARAM, GRAD, ACT, OPT, TEMP)**: Paper's profiling framework attributes memory to specific groups; understanding this enables targeted optimization. Quick check: Which memory group dominates for MobileNetV2 during training, and which for ResNet-18? (Answer: ACT for MobileNetV2, GRAD+OPT for ResNet-18)

## Architecture Onboarding

- **Component map**: Pre-trained CNN -> PEFT wrapper (LoRA/DoRA adapter modules or GaLore optimizer wrapper) -> Custom profiler -> Fine-tuning on downstream task
- **Critical path**: Load pre-trained CNN -> Wrap with PEFT method -> Profile single forward-backward pass with 224×224 image -> Extract peak memory by group and FLOPs breakdown -> Fine-tune on downstream task with early stopping
- **Design tradeoffs**:
  - LoRA: Lowest FLOPs (80% reduction on MobileNetV3), moderate memory (22-67% reduction), longer convergence (~2× iterations)
  - DoRA: 29-58% memory overhead vs LoRA, no accuracy gain on edge CNNs
  - GaLore: Most robust accuracy (FFT-comparable), fastest convergence, but 10-30% FLOPs overhead and 1.13-2× memory vs LoRA
  - BN+H: Most memory efficient (52-85% reduction), but fails on hard adaptation tasks (up to 40% accuracy gap)
- **Failure signatures**: LoRA/DoRA accuracy drops 20% on hard tasks (impulse noise, Gaussian noise) when pre-trained model has low initial accuracy; DoRA shows no benefit over LoRA on edge CNNs despite LLM literature claims; GaLore degrades with high rank when pre-fine-tuning accuracy already high; all PEFT methods: only 22-48% memory reduction on MobileNets vs 67% on ResNet-18
- **First 3 experiments**:
  1. Baseline profiling: Run profiler on MobileNetV2 + ResNet-18 with all PEFT methods at rank=4, single 224×224 image. Compare memory breakdown by group to verify DSC vs standard convolution hypothesis.
  2. Rank sensitivity sweep: Fine-tune MobileNetV2 (ImageNet pretrained) on VWW and CIFAR-10-C (brightness + impulse noise) with ranks {5,10,15,20,25,30}. Measure accuracy convergence and identify break points where LoRA fails but GaLore succeeds.
  3. Hard adaptation stress test: Compare LoRA vs GaLore on impulse noise corruption where paper shows 20% accuracy gap. Test hypothesis: does increasing LoRA rank recover performance, or is full-rank gradient projection essential?

## Open Questions the Paper Calls Out
- How can the backward pass computation for depthwise-separable convolutions be optimized to mitigate the high FLOPs overhead identified in PEFT updates? (Page 7 notes the "approximate 20:1 ratio between the FLOPs required for the forward pass and the backward pass," explicitly stating this "underscores the need for further investigation into optimizing backward pass FLOPs for DSC models.")
- Do the accuracy and resource efficiency trade-offs observed in PEFT-enabled CNNs generalize to lightweight Vision Transformers deployed on edge devices? (Authors state in Limitations section that while they focused on CNNs, "generalization to other edge-relevant architectures like lightweight transformers remains unexplored.")
- How does model quantization impact the relative performance and memory overhead of adapter-based PEFT methods compared to full fine-tuning on physical edge hardware? (Limitations section lists "quantization is not considered" and "on-device profiling" as missing elements.)

## Limitations
- Analysis restricted to MobileNetV2/V3 and ResNet-18 architectures, leaving uncertainty about findings on other edge-optimized designs like EfficientNet or ConvNext
- Study benchmarks three corruption types on CIFAR-10-C but does not comprehensively test full range of natural distribution shifts edge devices encounter
- Results rely on PyTorch profilers for floating-point operations, which may not accurately reflect memory latency or energy consumption of quantized models on dedicated edge hardware

## Confidence
- **High confidence**: LoRA consistently provides the best accuracy-efficiency trade-off across all tested scenarios
- **Medium confidence**: GaLore achieves FFT-comparable accuracy with fewer iterations but higher computational complexity
- **Medium confidence**: PEFT methods are only half as memory-efficient on depthwise CNNs compared to LLMs
- **Low confidence**: DoRA provides no accuracy benefits over LoRA on edge CNNs despite promising results on LLMs

## Next Checks
1. Benchmark LoRA/DoRA/GaLore on EfficientNet-B0 and ConvNext-Tiny using the same CIFAR-10-C and VWW datasets to determine if activation memory dominance persists across different edge CNN designs
2. Cross-validate the memory profiling methodology by comparing results against alternative tools like NVIDIA Nsight Systems or PyTorch's built-in memory tracker to ensure the activation-vs-gradient breakdown is accurate
3. Re-implement DoRA using the original architecture from the LLM literature and test on both MobileNetV2 and ResNet-18 to determine if the observed lack of benefit is architecture-specific or method-specific