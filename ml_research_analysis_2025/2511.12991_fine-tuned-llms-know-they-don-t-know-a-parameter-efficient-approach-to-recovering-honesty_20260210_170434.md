---
ver: rpa2
title: 'Fine-Tuned LLMs Know They Don''t Know: A Parameter-Efficient Approach to Recovering
  Honesty'
arxiv_id: '2511.12991'
source_url: https://arxiv.org/abs/2511.12991
tags:
- honesty
- neurons
- hcnr
- task
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the degradation of honesty in large language
  models (LLMs) caused by supervised fine-tuning (SFT). The authors find that SFT
  does not impair models' self-knowledge of their knowledge boundaries but rather
  their ability to express this awareness.
---

# Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty

## Quick Facts
- **arXiv ID**: 2511.12991
- **Source URL**: https://arxiv.org/abs/2511.12991
- **Reference count**: 9
- **Primary result**: HCNR recovers 33.25% of honesty degradation with 2.23x speedup and 10x less data vs baselines

## Executive Summary
This paper addresses the degradation of honesty in large language models (LLMs) caused by supervised fine-tuning (SFT). The authors find that SFT does not impair models' self-knowledge of their knowledge boundaries but rather their ability to express this awareness. To solve this, they propose Honesty-Critical Neurons Restoration (HCNR), a parameter-efficient framework that identifies and restores neurons governing honest expression to their pre-trained state while using Hessian-guided compensation to maintain task performance. Experiments on four QA tasks and five LLM families show that HCNR recovers 33.25% of compromised honesty with at least 2.23x speedup and over 10x less data compared to baseline methods.

## Method Summary
The paper proposes HCNR, a two-stage framework to recover honesty in fine-tuned LLMs. Stage 1 identifies honesty-critical neurons using Fisher Information Matrix diagonal elements as importance scores, then selects neurons with high honesty sensitivity and low task sensitivity. Stage 2 applies Hessian-guided compensation to these restored neurons to maintain task performance. The method uses only 128 samples for both honesty and task sensitivity estimation, making it highly parameter-efficient. The framework is evaluated across four QA tasks and five LLM families, demonstrating significant recovery of honesty without substantial performance degradation.

## Key Results
- HCNR recovers 33.25% of honesty degradation in fine-tuned LLMs
- Achieves at least 2.23x speedup and over 10x less data usage compared to baseline methods
- Successfully restores honest expression across four QA tasks (HotpotQA, Natural Questions, MedMCQA, BioASQ) and five LLM families
- Maintains domain task accuracy while improving F1 scores for unanswerable question detection

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Boundary Representations Survive SFT
Supervised fine-tuning degrades honest self-expression without corrupting internal knowledge-boundary representations. SFT shifts output-layer behavior while leaving the geometric structure of answerable/unanswerable representations linearly separable in hidden states. Linear probes trained on base models transfer to fine-tuned models with high AUROC, indicating the underlying boundary-encoding subspace is preserved.

### Mechanism 2: Fisher-Weighted Neuron Prioritization Isolates Honesty-Critical Parameters
Diagonal Fisher Information Matrix (FIM) elements provide an unbiased importance estimate for identifying neurons that govern honesty expression with minimal task interference. Under assumptions that SFT parameter increments have zero mean and isotropic covariance, expected honesty-loss change scales with FIM diagonal elements. Priority score $r_{j,k} = s^{\text{hon}}_{j,k} \cdot \log(s^{\text{hon}}_{j,k} / s^{\text{task}}_{j,k})$ selects neurons with high honesty sensitivity and low task sensitivity.

### Mechanism 3: Hessian-Guided Compensation Realigns Restored Neurons with Task Pathways
Restoring honesty-critical neurons to pre-training values causes activation misalignment with downstream-task neurons; Hessian-derived compensation vectors correct this with minimal honesty re-interference. Compensation term $c_{j,k}$ uses Hessian inverse to project the SFT-induced weight shift onto directions that minimize activation distance between restored and original parameters.

## Foundational Learning

- **Fisher Information Matrix (Diagonal Approximation)**: Core to neuron importance scoring; understanding FIM is essential for grasping why gradient squared expectations measure parameter sensitivity.
  - Quick check: Explain why $E[(\partial W_{j,k} L)^2]$ approximates curvature information under the paper's assumptions.

- **Optimal Brain Surgeon (OBS) / Second-Order Pruning Theory**: Hessian-guided compensation in Stage 2 directly derives from OBS principles.
  - Quick check: In OBS, why does the Hessian inverse appear in the optimal weight update for minimizing output change after perturbation?

- **Linear Probing and Representation Geometry**: The paper's core claim relies on probe transferability as evidence for preserved knowledge-boundary structure.
  - Quick check: If a linear probe trained on model A transfers to model B with high accuracy, what does this imply about the relationship between their representation spaces?

## Architecture Onboarding

- **Component map**: Fisher importance calculator -> Priority ranking -> Cross-layer perturbation filter -> Neuron mask generator -> Hessian estimator -> Compensation vector computer -> Conditional weight merger

- **Critical path**: 
  1. Compute $s^{\text{hon}}_{j,k}$ and $s^{\text{task}}_{j,k}$ using 128 samples each
  2. Rank neurons by $r_{j,k}$; select top $R_{IW} \times d'$ per layer
  3. Rank layers by perturbation $d_j$; select top $R_{CW} \times L$ layers
  4. Restore selected neurons $(j,k) \in A_{hc}$ to $W^{\text{orig}}_{j,k}$
  5. Compute Hessian of $d_{\text{hon}}$ and compensation vectors $c_{j,k}$
  6. Apply final weights per Equation (10)

- **Design tradeoffs**:
  - $R_{IW}$ (in-weight ratio): Higher â†’ more honesty recovery but diminishing returns; saturates quickly
  - $R_{CW}$ (cross-weight ratio): Optimal ~0.3; higher values degrade performance (over-restoration)
  - Data size: Plateaus at ~128 samples; more data yields negligible gain

- **Failure signatures**:
  - Task accuracy drops >2%: Likely $R_{IW}$ too high or "w/o Task" priority used
  - Honesty F1 <60: Check if compensation disabled or $R_{CW} < 0.2$
  - Inconsistent results across runs: Fisher/Hessian estimates unstable on too-few samples

- **First 3 experiments**:
  1. Reproduce Figure 3 probe transfer on your target model family before applying HCNR to validate the preservation assumption holds
  2. Ablate Stage 2 (set compensation to zero) on a held-out honesty benchmark to quantify compensation contribution
  3. Sweep $R_{IW} \in \{0.3, 0.5, 0.7\}$ and $R_{CW} \in \{0.2, 0.4, 0.6\}$ on a validation split to find optimal tradeoff for your domain task

## Open Questions the Paper Calls Out

- **Does the dissociation between self-knowledge (awareness) and self-expression persist in models significantly larger than 8B parameters?**
  - Experiments were restricted to 7B and 8B models (Llama, Qwen, Mistral)
  - The geometry of knowledge boundaries and the efficacy of Fisher-based neuron identification may change with scale
  - Replicating the linear probe transferability experiments on 70B+ models would resolve this

- **Can HCNR be adapted to recover calibrated confidence levels rather than solely binary refusal behaviors?**
  - The evaluation focuses on binary F1 scores and Refusal$\Delta$ (refusal rate differences)
  - Real-world honesty often requires expressing degrees of uncertainty (e.g., "I am 60% sure") rather than just refusing to answer
  - Testing the restored models on benchmarks requiring probabilistic confidence estimation would resolve this

- **Is the "spurious degradation" mechanism (intact awareness, damaged expression) applicable to other alignment dimensions like safety?**
  - The paper focuses exclusively on honesty, though SFT is known to degrade other safety traits
  - Safety-critical neurons might be more entangled with task capabilities than honesty neurons, potentially complicating the restoration process
  - Applying the HCNR framework to safety benchmarks to verify if safety awareness is similarly preserved after SFT would resolve this

## Limitations

- The paper's core claim that SFT preserves internal knowledge-boundary representations while degrading honest expression relies on linear probe transferability, but neighbor research questions whether LLMs genuinely encode such signals
- The Fisher importance estimation validity depends on isotropic covariance assumption for SFT parameter increments, which is not empirically validated
- Hessian computation scalability is a concern for larger models, as the paper doesn't clarify computational approximations used for inverting potentially millions of parameters

## Confidence

- **High confidence**: The experimental results showing HCNR recovers 33.25% of compromised honesty with 2.23x speedup and 10x less data are reproducible and well-validated across four QA tasks and five LLM families
- **Medium confidence**: The two-stage mechanism (preservation + compensation) is internally consistent and supported by ablation evidence, but relies on several theoretical assumptions (Fisher isotropy, Hessian local quadraticity) that are not directly validated
- **Low confidence**: The specific numerical values for F1 gains and efficiency metrics would require careful replication, as they depend on precise dataset construction, hyperparameter tuning, and implementation details not fully specified

## Next Checks

1. **Probe transferability validation**: Before applying HCNR, verify that linear probes trained on your base model transfer to your fine-tuned model with high AUROC. If transfer fails, the preservation assumption does not hold for your specific architecture or domain.

2. **Hessian stability test**: Run HCNR with and without compensation on a small held-out honesty benchmark. If compensation causes instability or performance degradation, investigate Hessian conditioning and consider regularization or diagonal approximation.

3. **Hyperparameter sensitivity sweep**: Systematically vary $R_{IW}$ (in-weight ratio) and $R_{CW}$ (cross-weight ratio) on your validation split to find the optimal tradeoff for your domain task. Monitor both honesty recovery and domain accuracy to avoid over-restoration.