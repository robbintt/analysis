---
ver: rpa2
title: Abusive music and song transformation using GenAI and LLMs
arxiv_id: '2601.15348'
source_url: https://arxiv.org/abs/2601.15348
tags:
- music
- arxiv
- vocal
- song
- lyrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a generative AI framework to transform abusive
  music by replacing explicit vocals with AI-generated, content-safe alternatives
  while preserving musical integrity. The approach uses Demucs for vocal-instrumental
  separation, Suno AI for vocal replacement, and GPT-4 for lyrical detoxification.
---

# Abusive music and song transformation using GenAI and LLMs

## Quick Facts
- arXiv ID: 2601.15348
- Source URL: https://arxiv.org/abs/2601.15348
- Reference count: 40
- Generative AI framework transforms abusive music by replacing explicit vocals with AI-generated, content-safe alternatives while preserving musical integrity

## Executive Summary
This study presents a novel generative AI framework for transforming abusive music content by replacing explicit vocals with AI-generated, content-safe alternatives. The approach leverages Demucs for vocal-instrumental separation, Suno AI for vocal replacement, and GPT-4 for lyrical detoxification, demonstrating significant reductions in aggressive sentiment scores (63.3-85.6%) across four diverse songs. Acoustic analysis reveals consistent improvements in vocal quality metrics including Harmonic to Noise Ratio and Cepstral Peak Prominence, while maintaining musical coherence throughout the transformation process.

## Method Summary
The framework employs a three-stage approach: first, Demucs separates vocals from instrumental tracks; second, GPT-4 rewrites explicit lyrics into non-offensive alternatives while preserving artistic meaning; third, Suno AI generates new vocals for the transformed lyrics. The evaluation uses both sentiment analysis metrics (VADER, TextBlob, Empath) and acoustic features (Harmonic to Noise Ratio, Cepstral Peak Prominence, shimmer) to assess improvements. The system was tested on four songs spanning different genres and time periods, with particular attention to both verse and chorus sections to ensure consistent content transformation across the entire track.

## Key Results
- Sentiment analysis reductions of 63.3-85.6% in aggression scores across all tested songs
- Major improvements in chorus sections with up to 88.6% reduction in aggressive content
- Acoustic quality improvements including HNR increase from 3.06 to 8.43 dB and CPP from 19.50 to 24.61

## Why This Works (Mechanism)
The framework works by systematically addressing each component of abusive music: first isolating problematic vocals, then rewriting harmful lyrics while preserving musical meaning, and finally generating high-quality replacement vocals that maintain artistic integrity. The combination of advanced vocal separation (Demucs), sophisticated language understanding (GPT-4), and realistic voice synthesis (Suno AI) creates a comprehensive pipeline that transforms content without sacrificing musical quality.

## Foundational Learning
- Vocal separation using Demucs - separates vocals from instrumental tracks to isolate content needing modification; quick check: verify clean separation with minimal artifacts
- Lyrical detoxification via GPT-4 - rewrites explicit content into acceptable alternatives while maintaining semantic meaning; quick check: compare original and transformed lyrics for preserved meaning
- Voice synthesis with Suno AI - generates realistic vocals for new lyrics maintaining musical coherence; quick check: ensure synthetic vocals match original timbre and style
- Acoustic feature analysis (HNR, CPP, shimmer) - quantifies vocal quality improvements objectively; quick check: measure baseline metrics before and after transformation
- Sentiment analysis metrics (VADER, TextBlob, Empath) - quantifies reduction in aggressive content; quick check: validate automated metrics with human annotation

## Architecture Onboarding
- Component map: Audio Input -> Demucs (Vocal Separation) -> GPT-4 (Lyrical Detox) -> Suno AI (Vocal Generation) -> Final Output
- Critical path: Vocal separation accuracy directly impacts lyrical rewriting quality, which determines voice synthesis success
- Design tradeoffs: Real-time processing vs. quality (current system optimized for offline batch processing)
- Failure signatures: Poor vocal separation causes lyrical context loss; inadequate lyrical rewriting breaks musical meaning; voice synthesis artifacts reduce listening quality
- First experiments: 1) Test vocal separation on diverse music genres, 2) Evaluate lyrical rewriting across different abuse types, 3) Benchmark voice synthesis quality against original vocals

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on automated sentiment analysis without human perceptual validation
- Extremely limited sample size (4 songs) lacking genre diversity
- Does not address potential loss of artistic intent or cultural context

## Confidence
- Technical vocal quality enhancement: High
- Sentiment reduction metrics: Medium
- Overall framework effectiveness for real-world deployment: Low

## Next Checks
1. Conduct blinded human listening tests comparing original and transformed versions across diverse listener demographics
2. Expand evaluation to include 50+ songs across multiple genres and decades
3. Implement longitudinal studies tracking how transformed content affects listener behavior and attitudes compared to original versions