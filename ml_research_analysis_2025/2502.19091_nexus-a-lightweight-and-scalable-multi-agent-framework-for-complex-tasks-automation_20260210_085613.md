---
ver: rpa2
title: 'Nexus: A Lightweight and Scalable Multi-Agent Framework for Complex Tasks
  Automation'
arxiv_id: '2502.19091'
source_url: https://arxiv.org/abs/2502.19091
tags:
- design
- runs
- nexus
- synth
- impl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Nexus, a lightweight Python framework for building
  and managing LLM-based Multi-Agent Systems (MASs) that can be easily configured
  via YAML files. Nexus introduces a flexible multi-supervisor hierarchy to support
  scalable task delegation and uses a simplified workflow design that reduces the
  need for programming expertise.
---

# Nexus: A Lightweight and Scalable Multi-Agent Framework for Complex Tasks Automation

## Quick Facts
- **arXiv ID**: 2502.19091
- **Source URL**: https://arxiv.org/abs/2502.19091
- **Reference count**: 40
- **Primary result**: Lightweight Python MAS framework achieving state-of-the-art performance across coding, math, and EDA domains with 99% HumanEval pass rate and 100% MATH problem solutions

## Executive Summary
Nexus introduces a lightweight, YAML-configurable Python framework for building and managing LLM-based Multi-Agent Systems (MASs) with hierarchical task decomposition. The framework employs a flexible multi-supervisor hierarchy where root supervisors decompose complex tasks into subtasks delegated to specialized Task Supervisors or Worker agents. Through self-verifying workflows with specialized reviewer agents and tool-augmented reasoning, Nexus achieves exceptional performance across diverse domains including 99% pass rate on HumanEval coding tasks, perfect solutions on all tested MATH problems, and successful timing closure in EDA with 30% power savings.

## Method Summary
The Nexus framework enables MAS construction through YAML configuration files that define agent hierarchies, roles, and tool access patterns. Core components include a root Supervisor for workflow orchestration, optional Task Supervisors for intermediate coordination, and Worker agents for domain-specific execution with external tool access. The framework implements a directed acyclic graph model (Γ = (V, E)) ensuring unique parent-child relationships and clear responsibility chains. Workers follow observe-reason-act loops with chain-of-thought reasoning, and the system supports self-verifying workflows where Coder, Reviewer, and Verification agents iteratively refine solutions. The framework is installable via pip and designed for maximum flexibility with role-based memory scoping and extensible tool integration.

## Key Results
- Achieved 99% pass rate on HumanEval and 100% on VerilogEval-Human coding benchmarks
- Successfully solved all five randomly selected MATH problems versus baseline LLM solving only two
- Attained timing closure in EDA with average power savings of nearly 30% across VTR benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical task decomposition through multi-supervisor architecture enables scalable handling of complex tasks.
- Mechanism: A root Supervisor decomposes high-level prompts into subtasks, delegating to Task Supervisors or Worker agents based on specialization. The parent function φ: V \ {s} → V ensures unique directed paths from root to any agent, preventing circular dependencies and maintaining clear responsibility chains.
- Core assumption: Task complexity can be reduced through recursive decomposition without losing solution coherence.
- Evidence anchors:
  - [abstract]: "flexible multi-supervisor hierarchy... divide-and-conquer approach enables efficient handling of highly complex tasks"
  - [section 3.1]: "Γ = (V, E)... captures the relationships between various agents" with formal constraints on parent-child relationships
  - [corpus]: Related work on hierarchical MAS exists (e.g., "Adaptive Multi-Agent Reasoning via Automated Workflow Generation"), but Nexus-specific hierarchy formalization is novel to this paper
- Break condition: Tasks requiring tightly coupled inter-agent state dependencies may not decompose cleanly; deeply nested hierarchies could increase latency without quality gains.

### Mechanism 2
- Claim: Self-verifying workflows with specialized reviewer agents improve output correctness over single-pass generation.
- Mechanism: For coding tasks, a Coder generates solutions, a Reviewer checks syntax/compilation, and a Verification agent runs tests. Errors propagate back for iterative refinement. The paper reports 10.42%→27.63% functional pass rate improvements across benchmarks.
- Core assumption: Independent verification agents catch errors the generator cannot self-diagnose.
- Evidence anchors:
  - [abstract]: "99% pass rate on HumanEval and 100% on VerilogEval-Human, outperforming cutting-edge reasoning language models such as o3-mini"
  - [section 4.2.1, Table 1]: Ablation study showing baseline Claude 3.5 v1 at 87.80% vs. Nexus at 96.95% on HumanEval
  - [corpus]: Similar verification-in-the-loop approaches appear in related RTL generation work (AIvril, MAGE), but Nexus applies this pattern across domains
- Break condition: Verification requires executable test oracles; tasks without objective correctness criteria (e.g., open-ended creative writing) may not benefit equally.

### Mechanism 3
- Claim: Tool-augmented reasoning with iterative feedback loops enables domains requiring precise computation or external validation.
- Mechanism: Worker agents invoke domain tools (SymPy for symbolic math, Vivado CLI for EDA), returning results to supervisors for strategy refinement. The MATH case study shows baseline solving 2/5 problems vs. Nexus solving 5/5 through SymPy-aided verification.
- Core assumption: LLMs can correctly interpret tool outputs and incorporate feedback without cascading errors.
- Evidence anchors:
  - [section 4.3, Table 3]: "Nexus-based workflow successfully solved all five problems, whereas the baseline LLM correctly solved only two"
  - [appendix A]: Full trace showing iterative correction from incorrect 3465/32 → 5/32 → correct 3/16 probability answer
  - [corpus]: "PiERN: Token-Level Routing" addresses tool integration but through routing rather than agent hierarchy; corpus evidence on tool-augmented MAS is emerging but limited
- Break condition: Tool invocation latency may dominate for simple tasks; incorrect tool usage can compound rather than correct errors.

## Foundational Learning

- Concept: **ReAct paradigm (Reasoning + Action)**
  - Why needed here: Each Nexus agent follows an observe-reason-act loop with chain-of-thought reasoning before action. Understanding this pattern is prerequisite to designing effective agent behaviors.
  - Quick check question: Can you trace how a Reviewer agent would process a syntax error report and formulate a corrective prompt?

- Concept: **Directed acyclic graphs for hierarchical control**
  - Why needed here: The formal model Γ = (V, E) with level function ℓ(v) = ℓ(φ(v)) + 1 defines how tasks flow. Misunderstanding parent-child constraints leads to invalid architectures.
  - Quick check question: Given a 4-level hierarchy with one root supervisor, what is the maximum number of Task Supervisors that can be direct children of the root?

- Concept: **Role-based access control for shared memory**
  - Why needed here: The global Memory mechanism enforces scope—Supervisors have global access, Workers confined to event history, Task Supervisors access their subtree. Incorrect scoping causes information leakage or starvation.
  - Quick check question: If a Worker agent at level 3 needs information from a sibling Worker at level 3, what path must the request take?

## Architecture Onboarding

- Component map: **User prompt → Supervisor planning (CoT) → Task delegation → Worker tool invocation → Result synthesis → User feedback loop**
- Critical path: User prompt → Supervisor planning (CoT) → Task delegation → Worker tool invocation → Result synthesis → User feedback loop. The longest path in terms of iterations is the error-correction cycle: Worker → Tool → Error → Supervisor → revised delegation → Worker.
- Design tradeoffs:
  - **Depth vs. latency**: More hierarchical levels improve specialization but increase coordination overhead.
  - **Self-verification vs. external oracle**: Self-verifying workflows (coder generates own tests) are autonomous but may miss edge cases; external oracles are more reliable but require human input.
  - **YAML vs. Python**: YAML reduces code for simple architectures; Python API required for dynamic agent creation or complex control flow.
- Failure signatures:
  - **Infinite delegation loops**: Supervisor repeatedly reassigns same task without progress. Mitigation: iteration caps or progress metrics.
  - **Tool invocation failures**: Misconfigured paths or missing dependencies. Mitigation: pre-flight checks, sandboxed environments.
  - **Memory scoping errors**: Workers accessing stale or unauthorized state. Mitigation: explicit scope validation in memory reads.
- First 3 experiments:
  1. **Minimal two-agent architecture**: Replicate Listing 1 (Supervisor + CodeAnalyzer + CodeRefactorer) with a simple refactoring task. Verify agent communication via `display_agent_graph()` output.
  2. **Self-verification on HumanEval subset**: Run the Figure 3 workflow on 5 HumanEval problems. Compare pass rates with and without the Reviewer agent to quantify verification contribution.
  3. **YAML configuration migration**: Convert the Python architecture from experiment 1 to YAML (per Listing 2). Confirm behavioral equivalence and measure configuration time reduction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Nexus performance generalize across different underlying LLMs beyond Claude 3.5 Sonnet?
- Basis in paper: [inferred] All experiments exclusively used Claude 3.5 Sonnet v1 or v2, with no evaluation of framework behavior with other models (GPT-4, Llama, open-source alternatives).
- Why unresolved: The framework's architecture and supervisor-agent coordination patterns may interact differently with models that have varying reasoning capabilities, context windows, or instruction-following behaviors.
- What evidence would resolve it: Systematic evaluation using identical Nexus architectures with multiple LLM backends on the same benchmark suites (HumanEval, VerilogEval, MATH).

### Open Question 2
- Question: What is the statistical robustness of the MATH dataset findings given the extremely limited sample size?
- Basis in paper: [inferred] Only five randomly selected level-5 problems were tested from the MATH dataset, yet the paper generalizes that "Nexus-based architectures display robust proficiency in complex reasoning."
- Why unresolved: A sample of 5 problems cannot establish statistically significant claims about mathematical reasoning capabilities, especially given the diversity of problem types in MATH.
- What evidence would resolve it: Evaluation on the full MATH benchmark or a statistically representative sample (hundreds of problems) with confidence intervals reported.

### Open Question 3
- Question: What are the computational costs (token usage, latency, API calls) of Nexus workflows compared to baseline single-agent approaches?
- Basis in paper: [inferred] The paper claims Nexus requires "significantly less effort to create and deploy" but provides no quantitative analysis of inference costs, token consumption, or execution time versus direct model querying.
- Why unresolved: Multi-agent systems inherently introduce coordination overhead and additional LLM calls; the cost-efficiency tradeoff remains unquantified.
- What evidence would resolve it: Detailed cost analysis reporting token counts, API calls, and wall-clock time for Nexus versus baseline across all experiments.

## Limitations

- Performance metrics heavily depend on Claude 3.5 Sonnet's capabilities, with no evaluation across different LLM backends
- Critical implementation details remain unspecified including exact system prompts, iteration limits, and complete tool implementations
- Success relies on external tools functioning correctly, with no documented error handling for malformed tool outputs or failures

## Confidence

- **High confidence**: The hierarchical multi-supervisor architecture design is well-formalized and the YAML configuration approach is technically sound. The basic agent communication patterns and memory scoping mechanisms can be verified independently of LLM performance.
- **Medium confidence**: Domain-specific performance claims (99% HumanEval, 100% MATH, 30% power savings) are plausible given the methodology but depend heavily on Claude 3.5 Sonnet's capabilities and the specific evaluation harness implementations, which are not fully disclosed.
- **Low confidence**: Cross-domain generalization claims and the assertion that Nexus "outperforms cutting-edge reasoning language models" lack comparative baselines with other MAS frameworks on identical tasks, making the relative performance assessment uncertain.

## Next Checks

- **Check 1**: Implement the same hierarchical architecture using a different LLM (e.g., GPT-4 or open-source models) while keeping all other components identical. Measure performance degradation/gains to isolate framework contribution from model capability effects.
- **Check 2**: Create stress tests that force tool invocation failures (e.g., invalid SymPy inputs, non-existent file paths) and verify that the agent hierarchy gracefully handles these errors without infinite loops or crashes. Document the error propagation and recovery mechanisms.
- **Check 3**: Run the complete HumanEval evaluation suite with three different temperature settings (0.1, 0.7, 1.0) while measuring both functional pass rate and token consumption. This quantifies the trade-off between solution quality and computational cost, revealing whether the reported results represent optimal or merely achievable performance.