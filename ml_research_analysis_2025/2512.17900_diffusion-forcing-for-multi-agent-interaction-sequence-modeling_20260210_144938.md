---
ver: rpa2
title: Diffusion Forcing for Multi-Agent Interaction Sequence Modeling
arxiv_id: '2512.17900'
source_url: https://arxiv.org/abs/2512.17900
tags:
- motion
- agent
- prediction
- partner
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MAGNet, a unified autoregressive diffusion
  framework for multi-agent motion generation that can handle diverse interaction
  tasks including dyadic prediction, partner inpainting, joint future prediction,
  and polyadic scenarios with three or more agents. The key innovation is representing
  motion tokens that encode both latent pose and inter-agent transformations, enabling
  the model to generate coherent coordinated motion by explicitly modeling coupling
  between agents during denoising.
---

# Diffusion Forcing for Multi-Agent Interaction Sequence Modeling

## Quick Facts
- arXiv ID: 2512.17900
- Source URL: https://arxiv.org/abs/2512.17900
- Reference count: 40
- Introduces MAGNet, a unified diffusion framework for multi-agent motion generation that handles dyadic prediction, partner inpainting, joint future prediction, and polyadic scenarios with three or more agents.

## Executive Summary
This paper presents MAGNet, a unified autoregressive diffusion framework for multi-agent motion generation that can handle diverse interaction tasks including dyadic prediction, partner inpainting, joint future prediction, and polyadic scenarios with three or more agents. The key innovation is representing motion tokens that encode both latent pose and inter-agent transformations, enabling the model to generate coherent coordinated motion by explicitly modeling coupling between agents during denoising. Trained on diverse datasets spanning contact sports, dance, and social interactions, MAGNet performs competitively with specialized methods on dyadic benchmarks while naturally scaling to polyadic interactions.

## Method Summary
MAGNet introduces a novel approach to multi-agent interaction modeling by treating motion tokens as joint representations of agent poses and inter-agent transformations. The model operates in a latent space using an autoencoder architecture, with motion tokens concatenated along the time dimension for autoregressive generation. During training, the model learns to predict coupled motion tokens by jointly denoising observed and generated tokens. The framework uses a unified representation that can handle different interaction types through the same architecture, with inter-agent transformations encoded as offsets between consecutive frames. The autoregressive diffusion process generates coherent multi-agent sequences by modeling the temporal evolution of these coupled tokens.

## Key Results
- MAGNet achieves strong performance across metrics including Fréchet distance (0.05 on DD100), foot skating (0.58), and interpenetration (0.12)
- The model demonstrates competitive results with specialized methods on dyadic benchmarks while scaling naturally to polyadic interactions
- Supports ultra-long generation (hundreds of steps) and agentic turn-taking sampling strategies

## Why This Works (Mechanism)
The effectiveness of MAGNet stems from its unified representation that encodes both pose and inter-agent relationships within each motion token. By explicitly modeling the coupling between agents through inter-agent transformations during the denoising process, the model can generate coordinated motion that respects physical constraints and interaction dynamics. The autoregressive diffusion framework allows for flexible generation strategies while maintaining temporal coherence, and the latent space representation provides computational efficiency for handling multiple agents simultaneously.

## Foundational Learning
- **Diffusion Models**: Generate data by iteratively denoising from random noise; needed for robust generation with controllable sampling strategies
- **Autoregressive Generation**: Predict future tokens based on previous ones; required for temporal coherence in motion sequences
- **Multi-Agent Interaction Modeling**: Represent relationships between multiple agents; essential for generating coordinated motion
- **Latent Space Representations**: Encode data in compressed form; enables computational efficiency when handling multiple agents
- **Inter-agent Transformations**: Model spatial relationships between agents; crucial for maintaining realistic interactions
- **Coupled Token Denoising**: Jointly process multiple agents' representations; ensures coordinated generation of multi-agent sequences

## Architecture Onboarding

**Component Map**: Input frames -> Autoencoder encoder -> Motion tokens -> Diffusion U-Net -> Output tokens -> Autoencoder decoder -> Generated frames

**Critical Path**: Observed frames → Motion token encoding → Diffusion denoising → Token generation → Pose reconstruction → Interaction output

**Design Tradeoffs**: The unified token representation balances expressivity with computational efficiency, while the autoregressive approach trades parallel generation speed for temporal coherence. The latent space encoding reduces dimensionality but requires careful autoencoder design.

**Failure Signatures**: Loss of coordination between agents, unrealistic inter-agent distances, temporal inconsistencies in motion, and breakdown of interaction dynamics at longer generation horizons.

**First Experiments**: 1) Generate single-agent motion to verify basic autoencoder and diffusion functionality, 2) Test dyadic interaction generation on simple datasets, 3) Evaluate inter-agent distance preservation during generation.

## Open Questions the Paper Calls Out
None

## Limitations
- Requires complete observation of all agents during training, limiting real-world applicability
- Fixed temporal windows (100 frames for dyadic, 200 frames for polyadic) may constrain generalizability
- Computational overhead scales linearly with agent count, potentially limiting real-time applications

## Confidence
**High Confidence**: The core diffusion-based autoregressive architecture and its ability to generate coherent multi-agent motion sequences. The experimental results showing competitive performance on dyadic benchmarks and novel capabilities for polyadic interactions are well-supported.

**Medium Confidence**: The scalability claims to polyadic scenarios and ultra-long generation capabilities. While results are presented, the sample diversity and robustness across varied interaction types could benefit from additional validation.

**Medium Confidence**: The assertion that MAGNet can replace specialized models for different multi-agent tasks. The evidence shows competitive performance but doesn't fully establish superiority across all considered metrics and datasets.

## Next Checks
1. Test MAGNet's performance on datasets with partial agent observability to evaluate real-world applicability and robustness to missing data
2. Evaluate the model's ability to maintain coherent interactions beyond the 200-frame training window through extended generation experiments with quantitative metrics tracking interaction quality decay
3. Compare computational efficiency and generation quality against state-of-the-art specialized models on the same hardware to validate the practical advantages of the unified approach