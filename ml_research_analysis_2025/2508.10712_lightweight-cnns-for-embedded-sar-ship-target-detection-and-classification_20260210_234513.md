---
ver: rpa2
title: Lightweight CNNs for Embedded SAR Ship Target Detection and Classification
arxiv_id: '2508.10712'
source_url: https://arxiv.org/abs/2508.10712
tags:
- data
- ship
- detection
- stripmap
- ships
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates lightweight CNN models for on-board SAR
  ship detection directly on raw or range-compressed data, bypassing computationally
  heavy image focusing. A YOLO-style architecture built on ResNet blocks is applied
  to Stripmap raw data and IW range-compressed data, with varying model sizes to meet
  FPGA deployment constraints.
---

# Lightweight CNNs for Embedded SAR Ship Target Detection and Classification

## Quick Facts
- **arXiv ID**: 2508.10712
- **Source URL**: https://arxiv.org/abs/2508.10712
- **Reference count**: 17
- **Primary result**: Lightweight YOLO-style CNNs achieve real-time SAR ship detection on embedded FPGA hardware, with 98% accuracy for Stripmap mode and F1.30 up to 0.87 for IW range-compressed data.

## Executive Summary
This work presents a novel approach for on-board SAR ship detection using lightweight convolutional neural networks, bypassing computationally expensive image focusing by processing raw or range-compressed data directly. The authors propose a YOLO-style architecture based on ResNet blocks, tailored for both Stripmap raw data and IW range-compressed data, with model sizes optimized for deployment on resource-constrained FPGAs. The smallest Stripmap model achieves 98% ship detection accuracy and is successfully deployed on a Xilinx Zynq UltraScale+ MPSoC ZCU104 FPGA at 3527 FPS, surpassing real-time requirements. For IW data, the approach yields competitive off-shore detection (F1.30 up to 0.87) and supports binary classification between ships and windmills. However, performance degrades near shore due to complex backscatter and ambiguous labels, highlighting the need for more diverse training datasets. Overall, the study demonstrates the feasibility of real-time, embedded SAR ship detection with reduced data downlink, while identifying key areas for further improvement in robustness and generalization.

## Method Summary
The authors developed lightweight CNN models for on-board SAR ship detection, applying a YOLO-style architecture built on ResNet blocks to both Stripmap raw data and IW range-compressed data. To meet FPGA deployment constraints, multiple model sizes were explored, with the smallest achieving 98% ship detection accuracy on Stripmap data. The models were trained on diverse datasets, including public SAR ship datasets and simulated data, with data augmentation and transfer learning employed to improve generalization. The Stripmap model was successfully deployed on a Xilinx Zynq UltraScale+ MPSoC ZCU104 FPGA, operating at 3527 FPS. For IW data, larger input sizes and model complexity were required to maintain detection performance, with successful binary classification between ships and windmills. The approach avoids computationally heavy image focusing, enabling real-time processing on embedded hardware.

## Key Results
- 98% ship detection accuracy achieved with the smallest Stripmap model on embedded FPGA hardware.
- Real-time processing demonstrated at 3527 FPS on Xilinx Zynq UltraScale+ MPSoC ZCU104 FPGA.
- IW range-compressed data yields F1.30 up to 0.87 for offshore ship detection and supports binary classification between ships and windmills.

## Why This Works (Mechanism)
The approach works by leveraging lightweight CNN architectures that can process raw or range-compressed SAR data directly, avoiding the computational burden of image focusing. By using a YOLO-style framework with ResNet blocks, the models efficiently extract spatial features relevant for ship detection. The choice of input size and model depth is carefully balanced to meet the computational constraints of embedded FPGA deployment, enabling real-time processing. Data augmentation and transfer learning further enhance model generalization across different SAR modes and target types.

## Foundational Learning
- **SAR imaging basics**: Understanding how SAR systems capture and process signals is essential to appreciate the advantage of processing raw or range-compressed data directly.
- **YOLO object detection**: Knowledge of YOLO's single-shot detection mechanism is critical for understanding the model architecture and its suitability for real-time deployment.
- **ResNet blocks**: Familiarity with residual connections and their role in enabling deep networks without degradation is key to understanding model design choices.
- **FPGA deployment constraints**: Awareness of resource limitations and optimization strategies for embedded hardware is necessary to grasp the model sizing and performance tradeoffs.
- **Data augmentation**: Understanding how simulated and augmented data can improve model robustness and generalization in SAR applications.

## Architecture Onboarding
- **Component map**: Raw/Range-compressed SAR data -> CNN backbone (ResNet blocks) -> YOLO detection head -> Output (bounding boxes, classes)
- **Critical path**: Input preprocessing (if any) -> Feature extraction via CNN backbone -> Object detection via YOLO head -> Post-processing (non-max suppression)
- **Design tradeoffs**: Smaller models reduce computational load for FPGA deployment but may sacrifice detection accuracy; larger inputs improve detection but increase resource requirements.
- **Failure signatures**: Near-shore detection performance drops due to complex backscatter and ambiguous labels; models may struggle with cluttered or ambiguous coastal scenes.
- **First experiments**: 1) Test detection accuracy on a held-out validation set for both Stripmap and IW data. 2) Profile model latency and resource utilization on target FPGA. 3) Evaluate classification performance on a binary ship vs. windmill test set.

## Open Questions the Paper Calls Out
- How can the models be improved to handle near-shore detection, where complex backscatter and ambiguous labels currently degrade performance?
- What is the impact of limited training data diversity on the robustness of the models in varied environmental conditions and target scenarios?
- Can the approach be generalized to detect and classify other target types (e.g., small boats, platforms) beyond ships and windmills?

## Limitations
- Near-shore detection performance is significantly degraded due to complex backscatter and ambiguous training labels.
- Reported success on IW data is limited to offshore scenarios, and binary classification between ships and windmills may not generalize to other target types.
- The approach's generalizability to other SAR modes, sensor configurations, and target types remains uncertain without further validation.

## Confidence
- **High**: Technical feasibility of deploying lightweight CNN models for on-board SAR ship detection on embedded FPGA hardware is well-supported by successful implementation and real-time performance.
- **Medium**: Detection accuracy and classification results are promising, but limitations in coastal and complex scenes temper overall confidence.
- **Low**: Generalizability of the approach to other SAR modes, sensor configurations, and target types is not fully established and requires further validation.

## Next Checks
1. Test the models on SAR data from diverse sensors, modes, and environmental conditions to assess robustness.
2. Expand the training dataset to include more coastal and ambiguous scenes with precise labeling to address near-shore performance issues.
3. Evaluate the models' ability to detect and classify additional target types (e.g., small boats, platforms) and in the presence of clutter or interference.