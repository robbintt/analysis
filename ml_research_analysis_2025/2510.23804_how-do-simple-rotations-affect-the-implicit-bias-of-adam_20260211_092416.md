---
ver: rpa2
title: How do simple rotations affect the implicit bias of Adam?
arxiv_id: '2510.23804'
source_url: https://arxiv.org/abs/2510.23804
tags:
- data
- adam
- rotations
- decision
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how data rotations affect the implicit
  bias of Adam and similar adaptive gradient methods. The authors show that even small
  rotations of the input data distribution can cause Adam to learn linear decision
  boundaries that generalize worse than those learned by gradient descent, reversing
  Adam's typical advantage in learning richer, more complex decision boundaries.
---

# How do simple rotations affect the implicit bias of Adam?
## Quick Facts
- arXiv ID: 2510.23804
- Source URL: https://arxiv.org/abs/2510.23804
- Reference count: 40
- Primary result: Data rotations can make Adam learn simpler, worse-generalizing decision boundaries compared to gradient descent

## Executive Summary
This paper investigates how data rotations affect the implicit bias of Adam and similar adaptive gradient methods. The authors demonstrate that even small rotations of the input data distribution can cause Adam to learn linear decision boundaries that generalize worse than those learned by gradient descent, effectively reversing Adam's typical advantage in learning richer, more complex decision boundaries. They provide theoretical analysis for binary classification with 2-layer ReLU networks and empirical validation in more general settings. To address this sensitivity, they propose EGOP (expected gradient outer product) reparameterization, which makes the optimization process invariant to data rotations and restores Adam's ability to learn nonlinear decision boundaries similar to the Bayes-optimal predictor.

## Method Summary
The paper examines how data rotations affect Adam's implicit bias by showing that rotations in data space can induce rotations in parameter space that change the optimization trajectory. For a 2-layer ReLU network in a binary classification setting, the authors prove that when data is rotated, Adam learns a different, potentially simpler decision boundary compared to gradient descent. To counteract this, they propose EGOP reparameterization, which transforms the parameter space based on the eigenvectors of the expected gradient outer product matrix. This transformation ensures that rotations in data space induce equivalent rotations in parameter space, making the optimization invariant to data rotations and restoring Adam's ability to learn complex decision boundaries.

## Key Results
- Small rotations of input data distribution can cause Adam to learn linear decision boundaries that generalize worse than those learned by gradient descent
- The phenomenon is theoretically proven for 2-layer ReLU networks in binary classification tasks
- EGOP reparameterization successfully restores Adam's ability to learn nonlinear decision boundaries similar to the Bayes-optimal predictor by making optimization invariant to data rotations

## Why This Works (Mechanism)
The core mechanism relates to how adaptive gradient methods like Adam maintain per-parameter learning rates based on historical gradient magnitudes. When data is rotated, the gradient directions change, but Adam's accumulated statistics from previous iterations create an implicit bias toward simpler solutions. This happens because the rotated gradients interact differently with Adam's adaptive learning rates, effectively steering the optimization toward decision boundaries that are simpler than optimal. The EGOP reparameterization works by aligning the parameter space with the data's intrinsic geometry, ensuring that rotations in data space correspond to equivalent rotations in parameter space, thus maintaining the intended optimization trajectory.

## Foundational Learning
- **Implicit bias in optimization**: Why needed - understanding how optimization algorithms implicitly prefer certain solutions even when multiple optima exist; Quick check - can you explain why gradient descent and Adam might converge to different solutions on the same loss landscape?
- **Adaptive gradient methods (Adam)**: Why needed - these methods maintain per-parameter learning rates that create the sensitivity to data rotations; Quick check - how does Adam's adaptive learning rate mechanism differ from standard gradient descent?
- **Expected Gradient Outer Product (EGOP)**: Why needed - this mathematical construct captures the geometry of the optimization landscape in a rotation-invariant way; Quick check - can you compute the EGOP matrix for a simple linear model?
- **Rotation invariance**: Why needed - understanding when and why certain transformations should not affect the learned model; Quick check - what properties must a learning algorithm have to be rotation-invariant?
- **ReLU networks and piecewise linear decision boundaries**: Why needed - the theoretical analysis focuses on this architecture where rotation effects are particularly visible; Quick check - how does the decision boundary of a 2-layer ReLU network differ from that of a linear classifier?

## Architecture Onboarding
- **Component map**: Data rotation -> Parameter space transformation (EGOP) -> Optimization trajectory -> Decision boundary complexity
- **Critical path**: The sequence from data preprocessing through optimization to final decision boundary formation, where rotation sensitivity enters between data rotation and parameter updates
- **Design tradeoffs**: EGOP reparameterization provides rotation invariance but introduces computational overhead from eigenvalue decomposition; simpler alternatives like data normalization may help but don't fully solve the problem
- **Failure signatures**: Adam learning unexpectedly simple (often linear) decision boundaries when data is rotated, particularly when the Bayes-optimal boundary is nonlinear
- **First experiments**: 1) Verify rotation sensitivity by training Adam on rotated vs. original data with known nonlinear Bayes-optimal boundary; 2) Test EGOP reparameterization on a 2-layer ReLU network with synthetic rotated data; 3) Compare decision boundary complexity between Adam with and without EGOP on rotated MNIST or similar dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis is limited to a specific 2-layer ReLU network binary classification setting, constraining generalizability
- EGOP reparameterization introduces computational overhead through eigenvalue decomposition without extensive discussion of practical implications
- The paper doesn't extensively validate the method's effectiveness across diverse architectures and real-world datasets

## Confidence
- **High confidence**: Adam's sensitivity to data rotations and its tendency to learn simpler decision boundaries under rotation is well-supported by both theory and experiments
- **Medium confidence**: The theoretical analysis for the 2-layer ReLU case is rigorous, but extrapolation to other architectures should be done cautiously
- **Medium confidence**: EGOP's effectiveness in restoring Adam's performance is demonstrated, but the method's robustness across diverse scenarios needs more validation

## Next Checks
1. Test EGOP reparameterization on deeper networks (3+ layers) and convolutional architectures to verify its effectiveness beyond 2-layer networks
2. Evaluate the computational overhead of EGOP in large-scale settings and compare wall-clock training times against standard Adam
3. Investigate whether data normalization/standardization can serve as a simpler alternative to EGOP for mitigating rotation sensitivity