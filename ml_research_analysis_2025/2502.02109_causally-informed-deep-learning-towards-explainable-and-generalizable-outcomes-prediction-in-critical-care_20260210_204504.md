---
ver: rpa2
title: Causally-informed Deep Learning towards Explainable and Generalizable Outcomes
  Prediction in Critical Care
arxiv_id: '2502.02109'
source_url: https://arxiv.org/abs/2502.02109
tags:
- causal
- variables
- prediction
- data
- outcomes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a causally-informed deep learning model, cDEEP,
  to improve both interpretability and generalizability of deep learning models for
  early prediction of six critical care outcomes. The approach integrates causal discovery
  to identify direct causal relationships among clinical variables and outcomes, enhancing
  interpretability and improving performance in out-of-distribution testing.
---

# Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care

## Quick Facts
- arXiv ID: 2502.02109
- Source URL: https://arxiv.org/abs/2502.02109
- Authors: Yuxiao Cheng; Xinxin Song; Ziqian Wang; Qin Zhong; Kunlun He; Jinli Suo
- Reference count: 40
- Key outcome: Achieves AUROC 0.915 for AKI prediction with 80.1% reduction in input variables

## Executive Summary
This paper introduces cDEEP, a causally-informed deep learning framework for early prediction of six critical care outcomes. The method combines causal discovery with deep learning to identify direct causal relationships among clinical variables and outcomes, enhancing both interpretability and out-of-distribution generalizability. By restricting model inputs to only causal parents of the outcome, cDEEP theoretically guarantees optimal worst-case performance under distribution shift and provides explicit causal pathways for clinical interpretation.

## Method Summary
cDEEP jointly learns Variable-to-Variable (V2V) and Variable-to-Outcome (V2O) graphs using a differentiable relaxation of discrete causal structures via Gumbel-Softmax. The model encodes time-series and static clinical data, applies a learned causal probability matrix to select only direct causal parents of each outcome, and decodes predictions through separate MLP heads. An auxiliary task predicts future variables to stabilize graph learning. The framework uses a graph regularizer to prevent dense connections and enables computation of Controlled Direct Effects for patient-specific causal interpretation.

## Key Results
- Achieves high accuracy for six outcomes: AKI (AUROC 0.915), Circulatory Failure (0.892), Acute Liver Failure (0.925), Sepsis (0.859), Mechanical Ventilation (0.815), ARDS (0.688)
- Reduces input variables by 80.1% while maintaining strong performance
- Outperforms baseline models in out-of-distribution testing, particularly for age-based splits
- Provides explicit causal pathways (e.g., chloride → BUN → circulatory failure) for clinical interpretation

## Why This Works (Mechanism)

### Mechanism 1
Restricting model inputs to direct causal parents of the outcome theoretically guarantees optimal worst-case performance under distribution shift. The model assumes OOD data results from interventions on non-causal variables, allowing it to ignore spurious correlations. The core assumption is that distribution shifts arise from interventions on variables that are not direct causes of the outcome. Break condition: if the environment shift involves a mechanism change in a core causal parent (e.g., new treatment alters biomarker-outcome relationship).

### Mechanism 2
Jointly learning V2V and V2O graphs enables explicit causal pathway interpretation unavailable in standard correlation-based attention. Unlike post-hoc explainability, this architecture explicitly models the path X_a → X_b → Y by separating the graph into edges among variables and edges to outcomes. The core assumption is that the underlying clinical system adheres to a Directed Acyclic Graph structure. Break condition: if variables are mediators rather than confounders and the model misidentifies edge direction.

### Mechanism 3
Continuous relaxation of discrete causal graphs using Gumbel-Softmax allows end-to-end gradient descent on graph structure. Causal graph discovery typically requires discrete selection (edge exists/doesn't exist), but cDEEP uses a "Causal Probability Matrix" and Gumbel-Softmax trick to estimate these as differentiable functions. The core assumption is that the differentiable relaxation sufficiently approximates discrete graph sampling. Break condition: if the temperature parameter is poorly tuned, the model may produce ambiguous soft graphs rather than discrete decisions.

## Foundational Learning

- **Structural Causal Models (SCMs)**: Why needed here - the entire premise relies on distinguishing causal parents from spurious correlates. Quick check: Can you explain why P(Y|X) might change across hospitals even if the causal mechanism P(Y|do(X)) is stable?

- **Gumbel-Softmax / Concrete Distribution**: Why needed here - understanding how the system learns graph topology requires knowing how to backpropagate through discrete sampling. Quick check: How does the Gumbel-Softmax trick allow gradients to flow through a sampling step that is normally non-differentiable?

- **Granger Causality vs. Structural Causality**: Why needed here - the paper references Granger causality in the context of "helping prediction" but builds Structural Causal Models. Quick check: In a time-series context, why is temporal precedence (Granger) insufficient to prove direct causation (Structural)?

## Architecture Onboarding

- **Component map**: Input (time-series + static vars) -> Shared Attention Encoder + MLP Encoder -> Causal Layer (Gumbel-Softmax matrix) -> Decoder (separate MLP heads for outcomes and future variable prediction)

- **Critical path**: 1) Forward pass of EHR data through Encoders, 2) Application of Causal Probability Matrix to filter inputs, 3) Decoder predicts risks, 4) Loss calculation + Graph Regularizer

- **Design tradeoffs**: cDEEP (causal vars only) has better theoretical generalizability, but cDEEP-full (using all vars, just graph-informed) often achieves higher raw accuracy. Computing CDE for every patient is expensive; cumulative window graph reduces this cost.

- **Failure signatures**: Dense graphs if regularization weight is too low, looking like standard DL model. Collapse to correlation if graph optimization step is ignored.

- **First 3 experiments**: 1) Sanity Check: Train cDEEP and LSTM on training split, verify cDEEP retains competitive AUROC (>0.90 for AKI), 2) Generalization Stress Test: Evaluate on "Age > 75" OOD split, cDEEP should decay slower than LSTM, 3) Visual Validity: Extract top 5 variables in V2O graph for AKI, check if "Creatinine" and "Urea Nitrogen" appear as parents.

## Open Questions the Paper Calls Out

- Can the cDEEP framework be effectively extended to incorporate unstructured data modalities, such as medical imaging, to further enhance diagnostic capability? The current architecture uses specific encoders designed for structured EHR data; integrating high-dimensional imaging requires novel fusion architectures.

- How can the model be adapted to factor in medical interventions to suggest potentially effective treatments, thereby broadening its role from predictive assessment to actionable insights? The current model predicts outcomes based on observational data but does not explicitly model the counterfactual impact of specific treatments.

- Can the predictive performance for outcomes with high rates of missing diagnostic criteria, specifically ARDS, be improved by addressing the exclusion of prediction windows? The current method excludes time windows where ground-truth labeling criteria are missing, severely reducing the training dataset size.

## Limitations

- Generalizability guarantee critically depends on unverifiable assumption that distribution shifts occur only through interventions on non-causal variables
- Requires substantial hyperparameter tuning (graph regularization weight, Gumbel-Softmax temperature) with limited guidance
- Computational cost increases significantly when computing patient-specific causal effects

## Confidence

- **High Confidence**: In-distribution performance metrics (AUROC values around 0.90-0.95 for most outcomes)
- **Medium Confidence**: Out-of-distribution performance improvements demonstrated but depend on specific dataset splits
- **Medium Confidence**: Causal pathway interpretability is visually compelling but clinical validity requires external validation
- **Low Confidence**: Theoretical worst-case generalization guarantee assumes ideal conditions that may not reflect real-world complexity

## Next Checks

1. **Temporal Validation**: Test whether learned causal graphs remain stable when trained on different time periods within the same hospital to assess temporal generalizability

2. **Mechanism Robustness**: Systematically introduce simulated interventions on both causal and non-causal variables to verify model's sensitivity aligns with theoretical expectations

3. **Clinical Face Validity**: Have clinical experts review the top-10 most influential causal pathways for each outcome to assess whether identified relationships align with medical knowledge