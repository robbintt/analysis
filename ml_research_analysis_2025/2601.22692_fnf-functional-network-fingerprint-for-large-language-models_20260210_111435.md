---
ver: rpa2
title: 'FNF: Functional Network Fingerprint for Large Language Models'
arxiv_id: '2601.22692'
source_url: https://arxiv.org/abs/2601.22692
tags:
- functional
- networks
- network
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Functional Network Fingerprint (FNF), a training-free
  method for detecting whether a suspect large language model (LLM) is derived from
  a victim model by measuring consistency in their functional network activity. Inspired
  by functional brain networks in neuroscience, FNF uses Independent Component Analysis
  to identify groups of co-activating neurons within LLMs and computes Spearman rank
  correlations between their temporal activation patterns.
---

# FNF: Functional Network Fingerprint for Large Language Models

## Quick Facts
- arXiv ID: 2601.22692
- Source URL: https://arxiv.org/abs/2601.22692
- Reference count: 21
- Primary result: A training-free method to detect model derivation by measuring functional consistency between large language models

## Executive Summary
FNF introduces a novel approach to intellectual property protection for large language models by identifying functional consistency between models using Independent Component Analysis and Spearman rank correlations. Inspired by functional brain networks in neuroscience, FNF measures the co-activation patterns of neuron groups across models to determine lineage relationships. The method demonstrates remarkable robustness against various model modifications including fine-tuning, pruning, and parameter permutation, while requiring only a few input samples to function effectively.

## Method Summary
FNF operates by first collecting activation patterns from multiple layers of a large language model across several input samples. These activations undergo Independent Component Analysis to identify functional components representing groups of co-activating neurons. The temporal activation patterns of these components are then compared using Spearman rank correlation to quantify functional consistency between models. The method processes activations through a series of transformations: raw activations → ICA decomposition → component temporal patterns → correlation matrix → consistency score. This training-free approach makes it particularly practical for real-world applications where victim model access may be limited.

## Key Results
- Achieved high consistency scores (0.9642-0.9997) for models sharing common origins while producing low scores (0.17-0.38) for unrelated models
- Successfully identified model lineage relationships even after fine-tuning, pruning, and parameter permutation attacks
- Outperformed traditional methods like CKA in detecting model relationships, particularly in cases involving weight repackaging attacks

## Why This Works (Mechanism)
FNF leverages the principle that models sharing a common origin maintain consistent functional activation patterns despite architectural modifications or training adjustments. By decomposing activations into independent components and analyzing their temporal correlations, the method captures the fundamental computational patterns that persist across model transformations. This approach is analogous to how functional brain networks maintain consistent activity patterns despite structural changes, allowing FNF to identify underlying model relationships that may not be apparent through weight-based comparisons alone.

## Foundational Learning
- **Independent Component Analysis (ICA)**: A statistical technique that separates mixed signals into independent source components, essential for identifying functional neuron groups without supervision. Quick check: Verify that components capture meaningful activation patterns by visualizing their temporal behavior.
- **Spearman Rank Correlation**: A non-parametric measure of monotonic relationships between variables, used here to compare temporal activation patterns. Quick check: Ensure correlation values appropriately distinguish between related and unrelated models.
- **Functional Consistency**: The concept that models with shared origins maintain similar computational patterns despite modifications. Quick check: Test whether consistency scores degrade predictably with increasing model divergence.

## Architecture Onboarding

**Component Map**: Input samples → Model activations → ICA decomposition → Component temporal patterns → Spearman correlation → Consistency score

**Critical Path**: The method's critical path involves collecting activations from multiple layers, applying ICA to identify functional components, and computing correlations between component temporal patterns. This sequence must be maintained to preserve the functional relationships that FNF measures.

**Design Tradeoffs**: FNF trades computational efficiency for robustness by using ICA, which can be computationally intensive but provides superior component separation compared to simpler methods. The choice of Spearman correlation over Pearson correlation adds robustness to non-linear relationships but may miss some linear patterns.

**Failure Signatures**: FNF may fail when models are trained on fundamentally different data distributions, when activation patterns are dominated by noise, or when models are modified in ways that alter their fundamental computational approach. Low consistency scores in these cases could be either true negatives or false negatives depending on the context.

**First Experiments**:
1. Test FNF on models with known relationships (parent-child models) to establish baseline performance
2. Apply controlled modifications (fine-tuning, pruning) to assess degradation in consistency scores
3. Compare FNF performance against traditional methods like CKA on identical datasets

## Open Questions the Paper Calls Out
The paper acknowledges several open questions regarding FNF's practical deployment, including its performance against adaptive, real-world attacks and its scalability to state-of-the-art models with billions of parameters. The authors also highlight the need to investigate how input sample quality and diversity affect accuracy, particularly in scenarios with biased or unrepresentative data distributions.

## Limitations
- Performance against sophisticated, adaptive attacks in real-world production environments remains unclear
- Potential sensitivity to noise or artifacts in activation patterns when models are heavily compressed
- Lack of evaluation on state-of-the-art LLMs with billions of parameters raises scalability concerns

## Confidence
- **High**: Core claim that FNF reliably detects model lineage is well-supported by empirical results across multiple architectures
- **Medium**: Practical deployment confidence is limited by lack of evaluation in dynamic, adversarial settings
- **Medium**: Scalability and performance on cutting-edge models not thoroughly established

## Next Checks
1. Test FNF's robustness against adaptive, real-world attacks such as gradient-based model stealing or adversarial fine-tuning
2. Evaluate scalability and performance on state-of-the-art LLMs (e.g., GPT-4, Claude) with billions of parameters
3. Investigate the impact of input sample quality and diversity on FNF's accuracy, including scenarios with biased or unrepresentative data distributions