---
ver: rpa2
title: Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing
  Churn
arxiv_id: '2506.00592'
source_url: https://arxiv.org/abs/2506.00592
tags:
- continual
- learning
- churn
- c-chain
- plasticity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of plasticity loss in continual
  reinforcement learning, where agents gradually lose their ability to adapt to new
  tasks. The authors propose a new perspective by studying the connection between
  plasticity loss and churn - the variability of network outputs for out-of-batch
  data during mini-batch training.
---

# Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn

## Quick Facts
- arXiv ID: 2506.00592
- Source URL: https://arxiv.org/abs/2506.00592
- Reference count: 40
- One-line primary result: C-CHAIN significantly outperforms PPO, TRAC, weight clipping, and L2 regularization on multiple continual RL benchmarks by reducing churn and preventing NTK rank collapse.

## Executive Summary
This paper addresses the critical problem of plasticity loss in continual reinforcement learning, where agents gradually lose their ability to adapt to new tasks. The authors identify a novel connection between plasticity loss and churn - the variability of network outputs for out-of-batch data during mini-batch training. They propose Continual Churn Approximated Reduction (C-CHAIN), a method that reduces churn during continual RL training by minimizing the difference between network outputs for training and reference data, effectively decorrelating gradients and adjusting step sizes.

## Method Summary
C-CHAIN is implemented on top of a base RL algorithm (PPO in the experiments) and adds a churn reduction loss term that operates on two disjoint batches: a training batch and a reference batch. The method computes the standard RL gradient on the training batch and, in parallel, computes a churn reduction gradient on the reference batch. These gradients are combined to update the network parameters. The churn reduction loss is designed to suppress off-diagonal entries in the Neural Tangent Kernel (NTK) matrix, decorrelating gradients and providing an adaptive step-size effect. An auto-tuning mechanism dynamically adjusts the churn reduction coefficient to maintain a fixed ratio between the churn loss and the base RL loss.

## Key Results
- On ProcGen environments, C-CHAIN achieved an aggregate score of 101.792 compared to 55.049 for the next best method (TRAC), with statistical significance.
- C-CHAIN significantly outperformed vanilla PPO, TRAC, weight clipping, and L2 regularization across OpenAI Gym Control, ProcGen, DeepMind Control Suite, and MinAtar benchmarks.
- The method demonstrated effectiveness in continuous control tasks and different RL algorithms beyond PPO.
- In continual supervised learning (MNIST variants), C-CHAIN underperformed compared to simple regularization methods like L2 initialization.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Plasticity loss in continual RL is driven by a vicious cycle where NTK matrix rank collapse leads to exacerbated churn, destabilizing learning on new tasks.
- Mechanism: As the agent learns sequential tasks, the empirical Neural Tangent Kernel (NTK) matrix loses rank due to simplicity bias and gradient correlation from prior tasks. This rank decrease amplifies churn (uncontrolled output changes for out-of-batch data), which in turn corrupts the function landscape for future data distributions, creating a feedback loop that destroys stability and convergence.
- Core assumption: The rank of the empirical NTK matrix is a reliable indicator of plasticity, and the observed rank decrease is causal to performance degradation.
- Evidence anchors: [abstract] "...loss of plasticity is accompanied by the exacerbation of churn due to the gradual rank decrease of the Neural Tangent Kernel (NTK) matrix..."; [section 4.2] "...the rank decrease of the NTK matrix and the exacerbation of churn operate in a vicious cycle... leads to even less stable learning and worse approximation results..."

### Mechanism 2
- Claim: Minimizing churn decorrelates gradients by explicitly suppressing off-diagonal entries in the NTK matrix.
- Mechanism: C-CHAIN adds a churn-reduction loss term. Its gradient includes a component (term ① in the paper) that takes the gradient of the NTK kernel between reference and training data. Minimizing this effectively pushes the off-diagonal entries of the NTK matrix toward zero, which decorrelates gradients and helps prevent the identified rank collapse.
- Core assumption: The gradient of the churn reduction loss can effectively capture and minimize the gradient correlations represented by the NTK off-diagonals.
- Evidence anchors: [section 4.3] "The ① term... takes the gradient of the kernel N_θ(\bar{x}, x)... As a result, the off-diagonal entries in the NTK matrix N_θ... are suppressed to zero for minimization."; [section 5.2] "This indicates that suppressing the off-diagonal entries of the NTK (i.e., the ① term) is critical to C-CHAIN."

### Mechanism 3
- Claim: Churn reduction provides an adaptive step-size effect by projecting reference data gradients onto training data gradients.
- Mechanism: A second component (term ②) of the C-CHAIN gradient is -(ḡᵀg)g, which is the projection of the reference data gradient (ḡ) onto the training data gradient (g). This term adaptively regulates the magnitude of the regular training gradient, dampening or accelerating updates based on gradient correlation.
- Core assumption: This projection provides beneficial adaptive scaling rather than adding noise or interference.
- Evidence anchors: [section 4.3] "The ② term... can be interpreted as the projection of ḡ on g... This term could either dampen or accelerate the regular gradient..."; [section 5.2] "The two components [projective and orthogonal] contribute collectively... the projective component is beneficial..."

## Foundational Learning

- **Concept: Neural Tangent Kernel (NTK) Matrix**
  - Why needed here: The paper uses the empirical NTK as the primary diagnostic tool. Its rank correlates with plasticity loss, and its off-diagonal entries are the target of the proposed method's gradient decorrelation effect.
  - Quick check question: What is the relationship between the rank of the empirical NTK matrix and plasticity loss in this paper?

- **Concept: Churn**
  - Why needed here: Churn is the core quantity the method aims to reduce. It is defined as network output variability for out-of-batch data induced by mini-batch training, and is formalized via the NTK matrix.
  - Quick check question: How does the paper formally define churn, and how is it connected to the NTK matrix?

- **Concept: Plasticity Loss in Continual RL**
  - Why needed here: This is the fundamental problem being solved. It's crucial to distinguish it from catastrophic forgetting; it's about the loss of ability to adapt to *new* tasks (forward transfer), measured by declining performance on later tasks in a sequence.
  - Quick check question: How is plasticity loss empirically identified in the paper's continual learning setting?

## Architecture Onboarding

- **Component map**: Shared data buffer -> B_train and B_ref sampling -> PPO gradient computation on B_train -> C-CHAIN gradient computation on B_ref -> Combined gradient update

- **Critical path**: 
  1. From a shared data buffer, sample two disjoint batches: B_train and B_ref.
  2. Compute the standard PPO gradient on B_train.
  3. **In parallel**, compute the C-CHAIN gradient on B_ref by minimizing the churn caused by the PPO update.
  4. Combine the gradients and update the network parameters.

- **Design tradeoffs**:
  - B_ref size: Larger batches may provide more stable churn estimates but increase compute. The paper notes its effect is similar to increasing the regularization coefficient.
  - β (relative loss scale): Controls regularization strength. Must be tuned; too high can constrain learning, too low may be ineffective. The auto-tuner simplifies this.
  - Compute: Adds the cost of a second gradient computation step per update.

- **Failure signatures**:
  - Performance degradation compared to vanilla PPO, especially on early tasks (sign of over-regularization).
  - No improvement in the approximate rank of the NTK matrix or the sum of absolute off-diagonal values.
  - Instability in the loss curves if the churn estimate is noisy.

- **First 3 experiments**:
  1. **Sanity Check - NTK Rank:** On a simple continual Gym task (e.g., CartPole), train both a vanilla PPO and C-CHAIN agent. Plot the approximate rank of the NTK matrix over time to verify that C-CHAIN successfully maintains higher rank.
  2. **Ablation - Gradient Components:** Implement the two ablated versions of C-CHAIN ("Proj Only" and "Orth Only") from Section 5.2. Run on a ProcGen environment to confirm that the orthogonal (decorrelation) component is the primary driver of performance gains.
  3. **Sensitivity Analysis - β:** Test a range of β values (e.g., 1000, 1e4, 1e5) on a single environment to understand the sensitivity of the method and confirm the effectiveness of the proposed auto-tuning mechanism.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can C-CHAIN effectively mitigate plasticity loss in large-scale, real-world applications such as robotics or Large Language Models (LLMs) fine-tuned via Reinforcement Learning from Human Feedback (RLHF)?
- Basis in paper: [explicit] Section 6 states that applying churn reduction to these domains is a direction for future work to address plasticity loss and forgetting.
- Why unresolved: The experimental scope is limited to standard RL benchmarks (Gym, ProcGen, MinAtar, DMC), which lack the complexity and scale of robotics or language modeling.
- What evidence would resolve it: Successful application of C-CHAIN during the continuous fine-tuning of an LLM or a robotic control policy, demonstrating sustained adaptability compared to standard optimization methods.

### Open Question 2
- Question: Can Hessian estimation be utilized to realize churn reduction more directly and effectively than the current gradient projection method?
- Basis in paper: [explicit] Section 6 notes that Equation 11 suggests an interesting direction for realizing churn reduction via Hessian estimation, potentially offering a more direct approach.
- Why unresolved: The proposed C-CHAIN method relies on gradient projections to suppress off-diagonal NTK entries, but the authors have not yet implemented or tested a Hessian-based variant.
- What evidence would resolve it: A comparative analysis of C-CHAIN against a variant that explicitly estimates the Hessian to minimize churn, measuring both performance and computational overhead.

### Open Question 3
- Question: Why does C-CHAIN underperform compared to simple regularization methods (like L2 Init) in continual supervised learning tasks?
- Basis in paper: [inferred] Appendix A.4 shows C-CHAIN underperforms relative to baselines on Permuted/RandomLabel-MNIST. The authors hypothesize this is due to the "chain effect" of churn being less severe in these tasks, but this is unverified.
- Why unresolved: The theoretical mechanism is designed to be general, yet the empirical results suggest a discrepancy in efficacy between the RL and supervised learning domains tested.
- What evidence would resolve it: A study analyzing the gradient correlation and churn dynamics in more complex continual supervised learning benchmarks to determine if the "churn accumulation" hypothesis explains the performance gap.

## Limitations

- The NTK rank-churn causal mechanism is hypothesized but not empirically validated with ablation studies; other factors may contribute to plasticity preservation.
- The auto-tuning mechanism for λ_π is not rigorously evaluated; only three fixed β values are reported without comparing to the dynamic version.
- Results are based on the PPO algorithm; generalization to other RL methods is demonstrated but not systematically analyzed.
- C-CHAIN underperforms simple regularization methods in continual supervised learning tasks, suggesting domain-specific limitations.

## Confidence

- **High**: C-CHAIN improves performance over strong baselines in continual RL benchmarks (empirical results).
- **Medium**: Churn reduction through NTK off-diagonal suppression is the primary mechanism (supported by ablation but not definitively isolated).
- **Low**: The auto-tuning mechanism is necessary and effective (not empirically validated).

## Next Checks

1. **Ablation Study**: Run a controlled experiment on ProcGen to isolate the relative contributions of the decorrelation (NTK suppression) and projection (adaptive step-size) components. Measure performance and NTK rank changes separately.

2. **NTK-Churn Validation**: Design an experiment that directly manipulates NTK rank (e.g., via synthetic data or architectural constraints) and measures the resulting impact on churn and plasticity loss, to establish causal links.

3. **Auto-Tuning Evaluation**: Implement and test the proposed auto-tuning mechanism (dynamic β adjustment) on a benchmark suite. Compare its performance and stability to the three fixed β values reported in the paper.