---
ver: rpa2
title: 'Extrapolation Merging: Keep Improving With Extrapolation and Merging'
arxiv_id: '2503.04834'
source_url: https://arxiv.org/abs/2503.04834
tags:
- merging
- performance
- extrapolation
- exme
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving large language
  model (LLM) performance without requiring additional computational resources or
  labeled data. The authors propose Extrapolation Merging (ExMe), a method that combines
  model extrapolation and merging techniques.
---

# Extrapolation Merging: Keep Improving With Extrapolation and Merging

## Quick Facts
- arXiv ID: 2503.04834
- Source URL: https://arxiv.org/abs/2503.04834
- Reference count: 9
- Key outcome: Method improves LLM performance without extra training data or compute by combining model extrapolation and merging

## Executive Summary
This paper introduces Extrapolation Merging (ExMe), a method that enhances large language model performance by combining model extrapolation with checkpoint merging. The approach leverages multiple checkpoints from supervised fine-tuning, extrapolates each to explore different optimization directions, and merges the best extrapolations to balance strengths and weaknesses. Experiments across seven tasks show consistent improvements over baseline merging methods, with ExMe achieving up to 3.23 points improvement on Qwen2-7B and demonstrating greater robustness than single-direction extrapolation.

## Method Summary
ExMe operates by first fine-tuning a base model to generate multiple checkpoints, then applying model extrapolation to push parameters further along the optimization direction implied by each checkpoint. The method selects the two best-performing checkpoints, extrapolates each with five different α values (0.1-0.5), evaluates all results, and merges the top two extrapolated models using weighted averaging with nine β values (0.1-0.9). The final model is selected based on overall performance across the benchmark suite. This approach requires no additional training data or computational resources beyond the initial SFT phase.

## Key Results
- ExMe consistently improves model performance across seven benchmarks compared to baseline merging methods
- The method achieves 3.23 points improvement on Qwen2-7B and 2.87 points on Qwen1.5-14B in average score
- ExMe demonstrates greater robustness by balancing the strengths and weaknesses of extrapolated models
- The method successfully recovers performance in some domains where single-direction extrapolation caused regression

## Why This Works (Mechanism)

### Mechanism 1: Extrapolation as Inverse Interpolation
The method treats an SFT checkpoint as a weighted average of the base model and an unknown "superior" model, then infers that superior model via extrapolation. Given Θ_strong = λΘ_EXPO + (1−λ)Θ_weak, solving for Θ_EXPO yields Θ_EXPO = Θ_strong + α(Θ_strong − Θ_weak), where α = 1/λ − 1. This linearly amplifies the parameter delta between SFT and base, pushing further along the optimization direction. The core assumption is that the optimization trajectory from base to SFT is approximately linear in parameter space.

### Mechanism 2: Multi-Path Optimization via Checkpoint Diversity
Selecting multiple high-performing SFT checkpoints and extrapolating each independently explores different optimization directions, reducing local-optimum risk. Different checkpoints emphasize different capabilities (e.g., one stronger on math, another on code). Extrapolating both preserves these distinct directions. Merging then combines complementary strengths rather than averaging within a single narrow basin. The core assumption is that top-performing checkpoints represent meaningfully different optimization trajectories.

### Mechanism 3: Robustness Through Merging of Extrapolated Models
Merging two extrapolated models balances their strengths and mitigates task-specific regressions introduced by single-direction extrapolation. Single extrapolation can over-amplify certain capabilities while degrading others. Weighted merging with β interpolates between two extrapolated models, smoothing extremes and recovering robustness. The core assumption is that the performance surface is locally convex enough that interpolation between two improved points does not catastrophically interfere.

## Foundational Learning

- **Concept: Linear Weight Merging / Model Averaging**
  - Why needed here: ExMe builds directly on the idea that Θ_merged = Σλ_i Θ_i. Without this baseline, extrapolation's inverse formulation won't make sense.
  - Quick check question: If you merge two models with λ=0.3 and 1−λ=0.7, which model dominates the merged result?

- **Concept: Parameter Delta and Optimization Direction**
  - Why needed here: Extrapolation amplifies the vector (Θ_SFT − Θ_base). Understanding parameter deltas as directional updates is essential.
  - Quick check question: If Θ_SFT improves on task A but degrades on task B relative to Θ_base, what happens when you extrapolate with α > 0?

- **Concept: Supervised Fine-Tuning Checkpoints and Capability Trade-offs**
  - Why needed here: ExMe selects top checkpoints by *overall* performance, acknowledging that different checkpoints have different capability profiles.
  - Quick check question: Why might two checkpoints from the same SFT run have different strengths on math vs. code benchmarks?

## Architecture Onboarding

- **Component map:**
  1. Base model (pretrained LLM)
  2. SFT stage → saves multiple checkpoints (Θ_ckpt1...Θ_cktpn)
  3. Checkpoint evaluator → selects top-2 by average benchmark score (Θ_SFT-1, Θ_SFT-2)
  4. Extrapolator → computes Θ_EXPO-i = Θ_SFT-i + α(Θ_SFT-i − Θ_base) for α ∈ {0.1, 0.2, ..., 0.5}
  5. Extrapolation selector → picks best-2 extrapolated models by average score
  6. Merger → computes Θ_ExMe = β Θ_EXPO-1 + (1−β) Θ_EXPO-2 for β ∈ {0.1, ..., 0.9}
  7. Final selector → picks best merged model by evaluation

- **Critical path:**
  1. Fine-tune base model on instruction dataset (alpaca-gpt4-data-zh/en)
  2. Evaluate all saved checkpoints on the target benchmark suite
  3. Select top-2 checkpoints; extrapolate each with 5 α values (0.1–0.5)
  4. Evaluate all 10 extrapolated models; select top-2
  5. Merge with 9 β values (0.1–0.9); evaluate all 9 candidates
  6. Return best-performing merged model

- **Design tradeoffs:**
  - α range: Paper uses 0.1–0.5. Larger α amplifies delta more aggressively but risks overshooting and degradation.
  - β selection: Smaller β (favoring the stronger extrapolated model) generally works best (optimal β = 0.1–0.2 across all four models).
  - Number of checkpoints merged: Paper merges only two, citing prior work that merging more models often degrades performance.
  - Checkpoint selection criterion: Overall average score, not individual task maxima. This prioritizes generalists over specialists.

- **Failure signatures:**
  - Extrapolation consistently degrades performance when the SFT model is weaker than base on a task.
  - Monotonic performance drop as β increases when extrapolated models have large performance gaps (>2 points).
  - Regression on multiple-choice benchmarks (CMMLU, MMLU) persists through ExMe due to SFT data style mismatch.

- **First 3 experiments:**
  1. **Baseline extrapolation sweep:** For a single SFT checkpoint, sweep α ∈ {0.1, 0.2, ..., 1.0} on 2–3 benchmarks (e.g., HumanEval, GSM8K). Plot performance vs. α to identify the "rise then fall" pattern and optimal α range.
  2. **Two-checkpoint extrapolation + merge:** Select top-2 SFT checkpoints, extrapolate each with α ∈ {0.1, ..., 0.5}, merge with β ∈ {0.1, ..., 0.9}. Compare final ExMe model against: (a) best SFT checkpoint, (b) best single extrapolation, (c) simple weighted merge of SFT checkpoints without extrapolation.
  3. **Ablation on β sensitivity:** For the best pair of extrapolated models, plot overall performance vs. β. Test whether the "smaller β is better" pattern holds across different base model families (e.g., Qwen vs. Llama vs. Mistral).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the effectiveness of model merging and model extrapolation be validated through rigorous mathematical proofs rather than just empirical observation?
- Basis in paper: The Limitation section states that the work relies on methods that "lack rigorous mathematical proofs" and that such proofs have not been provided in the current study.
- Why unresolved: The authors note that while experimental results validate the effectiveness, the theoretical mathematical foundations for why these parameter adjustments yield better performance remain unexplored.
- What evidence would resolve it: A formal theoretical framework or proof demonstrating the convexity or optimization properties of the loss landscape when applying extrapolation and merging operations.

### Open Question 2
- Question: How can the identification and removal of redundant parameters improve the efficiency and performance of the Extrapolation Merging (ExMe) framework?
- Basis in paper: The authors explicitly state in the Limitation section that the current process involves all parameters "without identifying or addressing the impact of redundant parameters," identifying this as a direction for future optimization.
- Why unresolved: The current implementation applies extrapolation and merging across the entire parameter space, potentially processing noise or redundant weights that could be pruned.
- What evidence would resolve it: Experiments integrating parameter pruning or masking techniques (like DARE) into the ExMe pipeline to determine if selectively merging parameters yields superior results.

### Open Question 3
- Question: To what extent does the specific composition of the SFT dataset limit the effectiveness of ExMe in preventing performance regression on out-of-distribution tasks?
- Basis in paper: The paper notes performance declines in specific benchmarks (e.g., CMMLU, MMLU) and attributes this to the "instructional style" and "lack of diversity" in the SFT datasets, acknowledging the method does not fundamentally solve this data limitation.
- Why unresolved: The paper demonstrates that ExMe amplifies the optimization direction of the SFT, suggesting that if the SFT causes forgetting in certain domains, ExMe might exacerbate rather than mitigate it.
- What evidence would resolve it: Ablation studies using SFT datasets with varying degrees of domain diversity to observe if ExMe consistently fails to recover performance in underrepresented domains.

## Limitations

- The linear extrapolation assumption may break down for larger α values or models with very different optimization trajectories, as the paper only tests α up to 0.5.
- SFT checkpoint selection relies on benchmark performance, which could lead to overfitting to evaluation tasks if checkpoints are not held out properly.
- The method's effectiveness on non-instruction-tuned models (e.g., base LLMs without SFT) remains unverified.

## Confidence

- **High Confidence:** The merging mechanism works as described (linear weighted averaging of parameters). This is well-established in the literature.
- **Medium Confidence:** The extrapolation mechanism's effectiveness is demonstrated empirically but relies on the unverified assumption of linear optimization trajectories in parameter space.
- **Medium Confidence:** The claim that ExMe consistently improves performance across all tested models and tasks is supported by results but may not generalize to all model families or benchmark suites.

## Next Checks

1. **Trajectory Linearity Test:** Systematically vary α from 0.1 to 1.0 on a single SFT checkpoint and plot performance vs. α to verify the "rise then fall" pattern and identify where linearity breaks down.

2. **Multi-Task Generalization:** Test ExMe on a held-out benchmark suite (not used in checkpoint selection) to verify that improvements generalize beyond the selection criteria.

3. **Scaling Behavior Analysis:** Apply ExMe to larger models (e.g., 30B+ parameters) to test whether the method scales effectively or if computational overhead becomes prohibitive.