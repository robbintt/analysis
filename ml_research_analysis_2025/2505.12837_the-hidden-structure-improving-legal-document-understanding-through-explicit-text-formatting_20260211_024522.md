---
ver: rpa2
title: The Hidden Structure -- Improving Legal Document Understanding Through Explicit
  Text Formatting
arxiv_id: '2505.12837'
source_url: https://arxiv.org/abs/2505.12837
tags:
- legal
- input
- prompt
- contract
- gpt-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how explicit input text structure and prompt
  engineering affect LLM performance on legal question-answering tasks. It compares
  GPT-4o and GPT-4.1 using various input formats (original CUAD text, cleaned text,
  Azure OCR output, GPT-4o Vision text, and Markdown) and two prompting strategies
  (user-centric vs.
---

# The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting

## Quick Facts
- arXiv ID: 2505.12837
- Source URL: https://arxiv.org/abs/2505.12837
- Reference count: 40
- Primary result: GPT-4.1's exact-match accuracy improves by ~30 percentage points when using structured Markdown inputs with system-centric prompts

## Executive Summary
This study demonstrates that explicit input text structure and prompt engineering significantly impact LLM performance on legal question-answering tasks. Using the CUAD contract dataset, the authors compare GPT-4o and GPT-4.1 across five input formats and two prompting strategies. The results reveal that GPT-4.1 is highly sensitive to input structure, with well-structured Markdown improving exact-match accuracy by ~20 percentage points compared to cleaned text. Further optimization through system-centric prompts elevates performance by an additional ~10-13 percentage points. GPT-4o shows greater robustness to input variations but achieves lower absolute accuracy. The findings highlight the importance of structured data and prompt design in legal document processing.

## Method Summary
The study evaluates legal question-answering using the CUAD dataset with 928 questions across four contract clause types. Five input modalities are tested: original CUAD text, regex-cleaned text, Azure OCR output, GPT-4o Vision text, and GPT-4o Vision Markdown. Two prompting strategies are compared: user-centric (generic system prompt) and system-centric (structure-aware instructions in system prompt). GPT-4o and GPT-4.1 are evaluated via Azure OpenAI API. Exact-match accuracy is measured by requiring both correct Yes/No responses and verbatim clause citations. The vision-parse library generates Markdown from PDFs with temperature=0.2 and detailed_extraction=True.

## Key Results
- GPT-4.1 achieves 48% accuracy on cleaned text but improves to 66-67% with structured inputs
- System-centric prompts with structure awareness boost GPT-4.1 accuracy by an additional ~10-13 percentage points
- Markdown format achieves the highest overall accuracy at 79% exact-match
- GPT-4o demonstrates robustness across formats but lower peak accuracy (~47-48%)
- Structure sensitivity is model-dependent, with GPT-4.1 showing dramatic performance variations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explicit text structuring (specifically Markdown) improves exact-match accuracy in legal QA, contingent on the specific LLM version.
- **Mechanism:** Legal documents rely on hierarchical relationships (sections, clauses) for semantic meaning. Converting inputs to structured Markdown likely preserves these boundaries, reducing ambiguity that arises when models must infer structure from flat, cleaned text.
- **Core assumption:** The model possesses the capacity to interpret formatting syntax (like headers) as semantic separators if the syntax is explicitly provided.
- **Evidence anchors:**
  - [abstract] "GPT-4.1's performance is markedly sensitive... well-structured formats... improve exact-match accuracy by ~20 percentage points."
  - [section 3.2] "GPT-4.1 achieved a relatively low accuracy of 48% [on cleaned text]... markedly improved to 66-67% [on well-structured inputs]."
  - [corpus] "Structured Attention Matters..." suggests input format influences document comprehension in multimodal models, supporting the general sensitivity to structure.
- **Break condition:** If the model is robust to input variations (like GPT-4o in this study), the performance delta from structuring diminishes or vanishes.

### Mechanism 2
- **Claim:** Relocating task instructions to the system prompt enhances the model's ability to utilize structured input.
- **Mechanism:** System prompts likely function as persistent "anchor" instructions that define the operating parameters for the entire context window. By explicitly declaring the input format (e.g., "You will receive structured Markdown"), the model is primed to parse the input using the correct internal representation logic, rather than inferring the format from the user turn.
- **Core assumption:** The specific LLM architecture assigns higher attention weight or persistence to instructions in the system prompt compared to the user prompt.
- **Evidence anchors:**
  - [abstract] "Optimizing the system prompt... further elevates GPT-4.1's accuracy by an additional ~10-13 percentage points."
  - [section 3.1.4] "This strategy aims to leverage the system prompt for persistent instructions and prime the model to specifically anticipate... structural characteristics."
  - [corpus] No direct corpus evidence for system vs. user prompt weighting; mechanism relies on paper's internal analysis.
- **Break condition:** If the prompt context window is saturated or if the model treats system and user prompts with equal attention, the location effect disappears.

### Mechanism 3
- **Claim:** Vision-based extraction creates higher-fidelity text representations than standard OCR for LLM processing.
- **Mechanism:** Traditional OCR extracts characters but often loses spatial relationships (layout). Vision-Language Models (VLMs) like GPT-4o Vision can interpret the visual "gestalt" of a document (tables, headers) and reconstruct it into a semantic format (Markdown) that explicitly encodes the lost layout.
- **Core assumption:** The VLM's internal vision encoder is sufficiently accurate to transcribe text without introducing hallucinations that degrade downstream performance.
- **Evidence anchors:**
  - [section 3.1.3] "GPT-4o Vision... configured to output plain text... [and] Markdown... aims to assess the quality of text extraction... potentially offering better structural preservation."
  - [section 4.1] "The reliance on rudimentary OCR... can significantly impair the analytical capacity... The superior textual output from advanced vision models... suggests a tangible return on investment."
- **Break condition:** If the source document is of very low image quality (e.g., heavy noise, handwriting) where text recognition fails, the vision-to-structure pipeline may introduce errors that negate formatting benefits.

## Foundational Learning

- **Concept:** **Exact-Match Accuracy (EM-Acc.)**
  - **Why needed here:** This is the strict metric used to evaluate success. It differs from semantic similarity; the model must cite the *verbatim* clause. Understanding this explains why "cleaning" text (which might alter whitespace or breaks) or hallucinating paraphrases results in a score of 0.
  - **Quick check question:** Does the evaluation allow for semantically equivalent but wording-different answers? (No).

- **Concept:** **Structure Sensitivity (Model Drift)**
  - **Why needed here:** The paper highlights that newer models (GPT-4o) are not universally "better" at this specific task; they are more robust but less accurate than GPT-4.1 when GPT-4.1 is optimized. Learners must grasp that model updates can change sensitivity profiles (robustness vs. peak performance).
  - **Quick check question:** Why might a "better" model (GPT-4o) score lower than an older model (GPT-4.1) on a specific task?

- **Concept:** **Prompt Architecture (System vs. User)**
  - **Why needed here:** The 10-13 percentage point gain comes not from *what* was asked, but *where* it was placed (System Prompt). Learners need to distinguish between the conversational turn (User) and the governing context (System).
  - **Quick check question:** Where should you place the "rules of engagement" for a document processing task to ensure they apply to the entire input?

## Architecture Onboarding

- **Component map:**
  1. **Ingestion Layer:** PDF/Image input.
  2. **Extraction Layer:** Choice between `AzureOCR_TXT` (low fidelity) vs. `GPT-4oVision_MD` (high fidelity/structured).
  3. **Prompt Constructor:** `System_Prompt` (Structure Advisory + Task) + `User_Prompt` (Data).
  4. **Inference Engine:** Target Model (GPT-4.1 vs. GPT-4o).
  5. **Evaluator:** Bipartite Check (Yes/No + Verbatim Citation).

- **Critical path:** The pipeline fails if `GPT-4.1` is paired with `RegexCleanTXT` (unstructured) and a `User-Centric` prompt. The critical success path is `GPT-4.1` + `Vision_MD` + `System-Centric` prompt.

- **Design tradeoffs:**
  - **Speed vs. Accuracy:** Using Vision-based Markdown extraction is likely slower and more expensive than simple text scraping but yields ~20pp higher accuracy on sensitive models.
  - **Robustness vs. Peak Performance:** GPT-4o offers robustness against bad data (easier integration) but lower ceiling (50% accuracy). GPT-4.1 offers high performance (79%) but requires strict data hygiene.

- **Failure signatures:**
  - **"Robustness Trap":** Achieving ~47-48% accuracy consistently across all formats (indicates you are likely using GPT-4o or have failed to prompt GPT-4.1 correctly).
  - **"Structure Collapse":** Significant drop in GPT-4.1 performance (to ~48%) indicates the input pipeline is stripping line breaks or feeding raw OCR text without structural markers.

- **First 3 experiments:**
  1. **Baseline Validation:** Replicate the "User-Centric" + "Cleaned Text" setup to confirm the low baseline (~48%) for your target model.
  2. **Isolate Structure:** Keep the prompt constant (User-Centric) but swap input to `Vision_MD` to quantify the pure formatting gain (hypothesis: jump to ~67%).
  3. **Full Optimization:** Shift to `System-Centric` prompt with `Vision_MD` to verify the "meta-cognitive priming" boost (hypothesis: jump to ~79%).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the observed structural sensitivities of GPT-4.1 and the robustness of GPT-4o generalize to other model architectures (e.g., Claude, Llama, Gemini)?
- Basis in paper: [explicit] The authors explicitly call for extending the analysis to "diverse models" and "open-source alternatives" to determine if these traits are idiosyncratic or generalizable.
- Why unresolved: The study was restricted to two specific OpenAI models accessed via Azure.
- What evidence would resolve it: Replicating the experimental design using the same CUAD excerpts and prompts across different leading model families.

### Open Question 2
- Question: Does structured input formatting benefit generative legal tasks (e.g., drafting, argumentation) as significantly as it benefits extractive tasks like clause identification?
- Basis in paper: [explicit] The authors acknowledge the study focused on extraction and explicitly list "Legal Document Drafting" and "Legal Reasoning" as necessary avenues for future research.
- Why unresolved: The "exact-match" metric used here tests retrieval precision, not the synthesis or logic required for drafting.
- What evidence would resolve it: Applying the same input format variables (Markdown vs. Cleaned TXT) to benchmarks requiring generative legal outputs.

### Open Question 3
- Question: Can LLMs effectively utilize more granular structural features, such as intra-document cross-references and nested clausal dependencies, if explicitly encoded?
- Basis in paper: [explicit] The authors admit the study focused on "macroscopic" elements (headings, lists) while "deeply nested clausal hierarchies... remain largely unexplored territories."
- Why unresolved: Markdown captures visual hierarchy well but may fail to represent the logical/legal scope of definitions or cross-references.
- What evidence would resolve it: Testing inputs enriched with explicit semantic linking (e.g., knowledge graphs or linked XML) against standard Markdown.

### Open Question 4
- Question: How does the variability of the vision-extraction step impact the reliability of the downstream question-answering performance?
- Basis in paper: [inferred] The authors note the "vision-to-markdown pipeline" specifics were not analyzed as variables and "uncontrolled variations" in this upstream process could introduce confounders.
- Why unresolved: The Markdown input was generated by a specific tool (vision-parse) using GPT-4o, conflating the extraction quality with the format utility.
- What evidence would resolve it: Ablation studies comparing manual "gold-standard" Markdown against automated vision-generated Markdown to isolate formatting effects from extraction errors.

## Limitations
- Results are specific to GPT-4.1 and GPT-4o, with unknown generalizability to other model architectures
- Exact regex pattern and specific CUAD contract subset remain unspecified, creating reproducibility barriers
- Evaluation relies entirely on exact-match accuracy, potentially missing semantically equivalent correct answers
- Vision-extraction pipeline quality is not independently analyzed, conflating formatting benefits with extraction quality

## Confidence
- **High Confidence:** GPT-4.1's sensitivity to input structure - directly supported by quantitative results showing 48% â†’ 66-67% improvement
- **Medium Confidence:** System prompt optimization benefits - supported by results but lacks external validation of the underlying architecture assumption
- **Low Confidence:** Vision-based extraction superiority - only compared against basic OCR, not alternative high-quality extraction methods

## Next Checks
1. **Cross-Model Validation:** Test the same structured input and prompt optimization on GPT-4o (the "robust" model) and GPT-5/Claude to determine if structure sensitivity is model-version-specific or a general LLM characteristic
2. **Structure-Fidelity Tradeoff:** Systematically degrade Markdown quality (remove headers, flatten hierarchy) to identify the minimum structural features needed for performance gains, separating true structure benefits from formatting artifacts
3. **Semantic vs. Exact Accuracy:** Re-evaluate the same dataset using semantic similarity metrics (BERTScore, BLEU) alongside exact-match to determine if the strict evaluation misses correctly answered but non-verbatim responses