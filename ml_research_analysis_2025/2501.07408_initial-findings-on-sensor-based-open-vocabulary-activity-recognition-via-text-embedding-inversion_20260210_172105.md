---
ver: rpa2
title: Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text
  Embedding Inversion
arxiv_id: '2501.07408'
source_url: https://arxiv.org/abs/2501.07408
tags:
- activity
- activities
- ov-har
- data
- recognition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitation of conventional human activity
  recognition (HAR) classifiers that can only recognize activities present in their
  training data. The proposed Open Vocabulary HAR (OV-HAR) framework converts activities
  into natural language descriptions, encodes them as fixed-size embeddings, and trains
  a regression model to map sensor data to these embeddings.
---

# Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion

## Quick Facts
- arXiv ID: 2501.07408
- Source URL: https://arxiv.org/abs/2501.07408
- Reference count: 12
- Primary result: Macro F1-scores of 0.472±0.019 for IMU and 0.462±0.021 for pressure data in UTD-MHAD dataset, demonstrating ability to recognize unseen activities without few-shot learning

## Executive Summary
This paper addresses the fundamental limitation of conventional human activity recognition (HAR) classifiers that can only recognize activities present in their training data. The proposed Open Vocabulary HAR (OV-HAR) framework converts activities into natural language descriptions, encodes them as fixed-size embeddings, and trains a regression model to map sensor data to these embeddings. The model then uses a pre-trained embedding inversion model to decode the embeddings back into natural language descriptions of activities. The method was evaluated on vision (pose), IMU, and pressure sensor data from three datasets, achieving competitive performance in recognizing unseen activities without requiring few-shot learning or fine-tuning.

## Method Summary
The method converts activity labels into natural language descriptions by decomposing them into atomic motions using LLaMA 3, then encoding these descriptions into 768-dimensional embeddings using gtr-t5-base. A regression model (based on ALS-HAR architecture) maps sensor data to these embeddings using MSE loss. At inference, a frozen vec2text model decodes the regressed embeddings back into natural language descriptions, which can be optionally mapped to discrete classes using LLaMA 3. The approach enables recognition of unseen activities by leveraging the semantic similarity encoded in the embedding space.

## Key Results
- OV-HAR achieved macro F1-scores of 0.472±0.019 for IMU and 0.462±0.021 for pressure data in UTD-MHAD dataset
- Outperformed baseline lookup table, few-shot contemporary classifier, and LLM-based classifier approaches
- Successfully recognized 6 unseen activities in UTD-MHAD without requiring fine-tuning or few-shot learning
- Demonstrated robust generalization across modalities (IMU, pose, pressure sensors)

## Why This Works (Mechanism)

### Mechanism 1
Mapping sensor data to semantic text embeddings enables recognition of activities not seen during training. The model regresses sensor inputs to a 768-dimensional embedding representing the activity's natural language description. Because embeddings encode semantic similarity, unseen activities composed of familiar atomic motions map near their training-space equivalents, enabling recovery via nearest-neighbor lookup or inversion. Core assumption: Unseen activities can be decomposed into atomic motions present in the training set; their semantic embeddings lie within the convex hull of training embeddings.

### Mechanism 2
A frozen pre-trained embedding inversion model can decode sensor-derived embeddings into natural language without autoregressive generation overhead. Vec2Text, pretrained on GTR text inversion, takes the regressed 768-dim vector and reconstructs the descriptive sentence. This bypasses autoregressive LLM decoding, avoiding sequential token dependency and error propagation. Core assumption: The regression model produces embeddings sufficiently close to the true text embedding manifold that vec2text was trained on.

### Mechanism 3
Decomposing activity labels into atomic motions via LLM enables compositional generalization. LLaMA 3 breaks activity class into atomic motions. Training embeddings are constructed from these decomposed descriptions. At inference, regressed embeddings implicitly represent atomic motion sequences, allowing the system to describe novel activity compositions. Core assumption: Atomic motions form a shared vocabulary across seen and unseen activities; LLM decomposition is consistent and complete.

## Foundational Learning

- **Text Embeddings (Sentence Transformers)**: Why needed: OV-HAR relies on gtr-t5-base to encode activity descriptions into a fixed 768-dim vector space where semantic similarity maps to geometric proximity. Quick check: Can you explain why cosine similarity in embedding space correlates with semantic similarity between activity descriptions?

- **Regression vs Classification in Sensor Learning**: Why needed: Unlike standard HAR that outputs one-hot class vectors, OV-HAR treats activity prediction as continuous regression to an embedding, requiring MSE loss and different evaluation metrics. Quick check: Why does MSE loss on embeddings enable generalization to unseen classes better than cross-entropy on fixed labels?

- **Embedding Inversion**: Why needed: The vec2text model inverts embeddings back to text; understanding its constraints (trained on specific embedding distributions, limited reconstruction fidelity) is critical for diagnosing output quality. Quick check: What happens if you pass an out-of-distribution embedding to an inversion model?

## Architecture Onboarding

- **Component map**: Sensor encoder (1D Conv → MaxPool → Flatten → BiLSTM → FC) → Regression to 768-dim embedding → Frozen vec2text model → Natural language description → Optional LLaMA 3 class mapping

- **Critical path**: 1) Collect activity labels → decompose to atomic motions via LLaMA 3 → 2) Generate text descriptions → encode with gtr-t5-base → store as training targets → 3) Train sensor encoder to regress sensor windows (5s) to embeddings (MSE loss) → 4) At inference: sensor → regressed embedding → vec2text → description → optional LLM class mapping

- **Design tradeoffs**: 5-second windows capture full motion sequences but reduce temporal granularity vs. standard 0.5s windows; frozen vec2text avoids LLM training cost but limits domain adaptation; atomic motion decomposition enables compositionality but constrains test activities to known atomic sets

- **Failure signatures**: Incoherent text output: regression embedding diverges from text manifold; wrong class assignment despite plausible description: LLM class mapper confusion; near-zero performance on specific modalities: sensor encoder underfitting

- **First 3 experiments**: 1) Validate embedding regression quality: Train on subset of classes, compute cosine similarity between predicted and ground-truth embeddings; target >0.7 average similarity before enabling inversion; 2) Ablate atomic motion decomposition: Compare using full activity descriptions vs. atomic motion sequences for embedding generation; measure F1 delta on held-out activities; 3) Stress-test inversion boundary: Synthesize embeddings at increasing distances from training manifold (add Gaussian noise); measure text reconstruction BLEU/semantic similarity to identify break points

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework generalize to activities composed of atomic motions not present in the training set? The authors restricted test activities to those "entirely described by atomic motions derived from the training set activities." This remains untested for activities requiring fundamentally new motion primitives.

### Open Question 2
Can unsupervised or contrastive learning techniques improve the model's semantic understanding of activity relationships? The current implementation relies on standard regression (MSE loss), which may not fully capture the semantic structure of the embedding space compared to contrastive approaches.

### Open Question 3
Would a dedicated open-vocabulary dataset with complex, overlapping activities reveal different performance limitations? Existing datasets designed for discrete classification may not sufficiently challenge the generative capabilities of the text-embedding inversion pipeline.

## Limitations
- Dependency on training set's atomic motion vocabulary limits recognition of activities requiring novel motions
- Modest performance (macro F1 ~0.47) indicates significant room for improvement
- 5-second window requirement may reduce temporal resolution compared to standard HAR approaches
- Architectural details for ALS-HAR encoder are underspecified, affecting reproducibility
- Reliance on frozen text inversion models limits domain adaptation capabilities

## Confidence

**High Confidence**: The core mechanism of mapping sensor data to semantic embeddings and back is technically sound and supported by empirical results showing better performance than baselines on open-vocabulary tasks.

**Medium Confidence**: Claims about computational efficiency relative to autoregressive LLMs are plausible but lack direct benchmarking evidence. Performance metrics show the approach works but are not state-of-the-art.

**Low Confidence**: Claims about compositional generalization through atomic motion decomposition lack direct validation; the paper assumes but doesn't rigorously test whether complex unseen activities can be reliably constructed from training atomic motions.

## Next Checks

1. **Embedding Distribution Validation**: Train the regression model on a subset of classes, then measure the cosine similarity between predicted and ground-truth embeddings for both seen and unseen activities. Target >0.7 average similarity before enabling inversion to ensure embeddings remain within the text manifold.

2. **Atomic Motion Decomposition Ablation**: Systematically compare using full activity descriptions versus atomic motion sequences for embedding generation. Measure the F1-score difference on held-out activities to quantify the benefit (or cost) of explicit decomposition.

3. **Inversion Boundary Stress Test**: Synthesize embeddings at controlled distances from the training manifold by adding Gaussian noise to predicted embeddings. Measure text reconstruction quality (BLEU/semantic similarity) to identify the operational boundary where inversion fails, informing model reliability estimates.