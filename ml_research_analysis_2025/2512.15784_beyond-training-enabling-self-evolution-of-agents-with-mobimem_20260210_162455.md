---
ver: rpa2
title: 'Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM'
arxiv_id: '2512.15784'
source_url: https://arxiv.org/abs/2512.15784
tags:
- memory
- task
- agent
- profile
- execution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'MOBIMEM addresses the challenge of enabling post-deployment self-evolution
  of LLM agents without costly model retraining. It introduces a memory-centric architecture
  with three specialized memory primitives: Profile Memory (using a distance-graph
  structure for efficient user preference alignment), Experience Memory (multi-level
  templates for capability generalization), and Action Memory (caching interaction
  sequences for efficiency).'
---

# Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM

## Quick Facts
- arXiv ID: 2512.15784
- Source URL: https://arxiv.org/abs/2512.15784
- Authors: Zibin Liu; Cheng Zhang; Xi Zhao; Yunfei Feng; Bingyu Bai; Dahu Feng; Erhu Feng; Yubin Xia; Haibo Chen
- Reference count: 40
- One-line primary result: MOBIMEM achieves 83.1% profile alignment with 23.83ms retrieval time (280× faster than GraphRAG), improves task success rates by up to 50.3%, and reduces latency by up to 9× on mobile devices.

## Executive Summary
MOBIMEM introduces a memory-centric architecture enabling LLM agents to self-evolve after deployment without costly model retraining. The system addresses three key challenges in agent evolution: user preference alignment through Profile Memory using a distance-graph structure, capability generalization via Experience Memory with multi-level templates, and execution efficiency through Action Memory caching interaction sequences. Evaluated on AndroidWorld and 50 real-world apps, MOBIMEM demonstrates significant improvements in personalization, capability, and efficiency through memory-driven evolution rather than model retraining.

## Method Summary
MOBIMEM employs a three-layer architecture: a Multi-agent Layer with specialized components (Profile Updater, Experience Generator, Task Rewriter, Operator), a Memory Layer with three specialized memory primitives (Profile Memory using DisGraph for user preferences, Experience Memory with multi-level templates for task logic, and Action Memory with ActTree/ActChain for cached interactions), and an OS Integration Layer providing services like task scheduling, record-and-replay, exception handling, and perception/execution. The system uses embedding-based retrieval, template abstraction, and cache validation mechanisms to enable continuous self-evolution while maintaining efficiency on resource-constrained mobile devices.

## Key Results
- Profile Memory achieves 83.1% profile alignment with 23.83ms retrieval time (280× faster than GraphRAG)
- Experience Memory improves task success rates by up to 50.3% through multi-level template abstraction
- Action Memory reduces end-to-end latency by up to 9× on mobile devices through prefix-suffix caching

## Why This Works (Mechanism)

### Mechanism 1: DisGraph for Efficient User Profile Retrieval
A distance-graph (DisGraph) structure achieves high profile alignment (83.1%) with low retrieval latency (23.83ms) by shifting semantic information from edges to nodes. The graph uses two node types (concepts, entities) with semantic-free edges. Retrieval uses embedding-based starting point selection followed by breadth-first search (BFS) traversal. This avoids LLM calls during retrieval, unlike GraphRAG which requires expensive model inference for edge traversal.

Core assumption: Relationships between profile elements correlate with graph path distance; shorter paths indicate higher relevance for user preference alignment.

### Mechanism 2: Multi-Level Experience Templates for Capability Generalization
Experience Memory with multi-level templates improves task success rates (up to 50.3%) by abstracting execution patterns into reusable templates with parameter slots. Templates separate invariant control flow from variable parameters. High-level templates describe task-level logic; low-level templates specify concrete UI actions. Task Rewriter fills parameter slots using current task context.

Core assumption: Similar tasks share invariant control flow patterns that can be abstracted while preserving task-specific variability through parameterization.

### Mechanism 3: Action Memory with ActTree and ActChain for Execution Efficiency
Action Memory reduces end-to-end latency (up to 9× on mobile devices) by caching action sequences in tree (prefix reuse) and chain (prefix-suffix reuse) structures. ActTree enables prefix reuse when tasks share initial action sequences within the same app. ActChain enables both prefix and suffix reuse when tasks are bound to experience templates with identified invariant steps.

Core assumption: Tasks within the same application or bound to the same template share substantial action subsequences that remain valid across executions.

## Foundational Learning

- Concept: Graph-based memory structures (vs. vector-only retrieval)
  - Why needed here: DisGraph relies on understanding how graph topology encodes relationships; unlike pure RAG, edges represent connectivity not semantics.
  - Quick check question: Can you explain why BFS traversal from embedding-selected nodes captures contextual relevance without semantic edges?

- Concept: Template abstraction and parameterization
  - Why needed here: Experience Memory requires decomposing task execution into invariant control logic and variable parameter slots.
  - Quick check question: Given a "book hotel" task, can you identify which steps are invariant (e.g., navigation) vs. variable (e.g., dates, location)?

- Concept: Cache validity and staleness detection
  - Why needed here: Action Memory must detect when cached actions are invalid due to UI changes; understanding fuzzy matching on UI hierarchy properties is critical.
  - Quick check question: What UI properties (resource ID, class, text) would you use to verify a cached "click search button" action is still valid?

## Architecture Onboarding

- Component map: Multi-agent Layer (Profile Updater, Experience Generator, Task Rewriter, Operator) → Memory Layer (Profile Memory with DisGraph, Experience Memory with templates, Action Memory with ActTree/ActChain) → OS Integration Layer (Agent Scheduler, AgentRR, Exception Handler, Perception/Execution Services).

- Critical path: User task input → Profile Memory retrieval + Experience Memory template matching (parallel) → Task Rewriter parameter filling → Action Memory cache lookup → Operator execution (with fallback to LLM reasoning on cache miss) → Action Memory update + Experience Memory template synthesis.

- Design tradeoffs:
  1. DisGraph: Single LLM call for updates (slower writes, ~6s) vs. zero-LLM retrieval (fast reads, ~23ms). Trade-off acceptable for read-heavy profile access.
  2. Experience templates: Manual authoring (higher accuracy, ~0.2 person-hrs) vs. automatic synthesis (lower accuracy, zero human effort). Choice depends on task coverage requirements.
  3. Action Memory: Aggressive caching (higher reuse, staleness risk) vs. conservative verification (lower reuse, safety). Threshold tuning via Replay Predictor.

- Failure signatures:
  1. Profile retrieval returns irrelevant entities → Check embedding quality for starting node selection; verify DisGraph concept-entity links are not overly broad.
  2. Template parameter filling produces incorrect task descriptions → Inspect Task Rewriter LLM prompts; validate slot extraction from task context.
  3. Action cache replay causes UI errors → Examine correctness check fuzzy matching thresholds; check for app updates or dynamic content changes.

- First 3 experiments:
  1. Replicate Profile Memory retrieval benchmark (500 historical tasks, 30 test tasks) comparing DisGraph vs. Vanilla RAG vs. GraphRAG on alignment and latency.
  2. Evaluate Experience Memory template impact on AndroidWorld tasks with at least two agent models (e.g., UI-TARS-1.5-7B, GUI-Owl-7B), measuring success rate improvement.
  3. Test Action Memory reuse rates across 8 task categories with ActTree (prefix-only) vs. ActChain (prefix-suffix) using both human-crafted and LLM-generated templates, measuring latency reduction on mobile hardware (Snapdragon 8 Elite or equivalent).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MOBIMEM’s performance and memory architecture translate to non-mobile environments, such as desktop or web-browser automation?
- Basis in paper: [explicit] The Discussion section states the core mechanisms are platform-agnostic and lists desktop (Microsoft UI Automation) and web (DOM) as potential targets, but the evaluation is restricted to Android mobile environments.
- Why unresolved: The complexity of desktop UI hierarchies and web DOM structures differs significantly from mobile UIs, potentially affecting ActTree efficiency and DisGraph retrieval accuracy.
- What evidence would resolve it: Benchmark results from MOBIMEM deployed on a desktop environment (e.g., Windows) or web automation framework, comparing task success rates and latency against the mobile results.

### Open Question 2
- Question: Does the Profile Memory's reliance on a vector database for initial node selection become a latency bottleneck as the user profile scales beyond 100,000 nodes?
- Basis in paper: [inferred] Table 3 shows retrieval latency increases from 8.77 ms to 1291.28 ms as nodes grow from 100 to 100,000, which the paper attributes primarily to the vector database search rather than graph traversal.
- Why unresolved: While 1.29 seconds is currently deemed "acceptable," continued long-term use could generate profiles exceeding this size, potentially violating the strict latency requirements of on-device agents.
- What evidence would resolve it: Stress testing the DisGraph retrieval latency with synthetic profiles containing 500,000 to 1,000,000 entities to observe if the vector search scaling remains linear or degrades.

### Open Question 3
- Question: How does the automated synthesis of experience templates impact the long-term reliability of the Experience Memory?
- Basis in paper: [inferred] Section 4.2 describes the "Experience Generator" using an LLM to synthesize templates, while Table 4 shows automatically synthesized templates have slightly lower accuracy (60.1%) than human-crafted ones (63.5%).
- Why unresolved: The paper does not analyze whether low-quality or hallucinated templates accumulate over time, potentially degrading the agent's capability or requiring manual cleanup.
- What evidence would resolve it: A longitudinal study measuring the "template acceptance rate" and task success rate drift over thousands of automated synthesis iterations without human intervention.

## Limitations
- The DisGraph profile retrieval mechanism's effectiveness depends heavily on the quality of embedding representations for concept-entity relationships, which is not extensively validated across diverse user profile types
- Action Memory's staleness detection relies on fuzzy matching thresholds that may not generalize well to rapidly changing UI states or frequently updated applications
- The performance gap between human-crafted and LLM-generated experience templates (77.3% vs 54.4% reuse rates) suggests significant quality variance that may limit scalability

## Confidence
- **High confidence**: The 280× latency improvement over GraphRAG baselines for profile retrieval is well-supported by the direct comparison of inference-free BFS traversal versus LLM-dependent graph navigation
- **Medium confidence**: The 50.3% task success rate improvement from experience templates is demonstrated but relies on specific AndroidWorld task distributions that may not represent all mobile application domains
- **Medium confidence**: The 9× latency reduction claim depends on specific mobile hardware characteristics and may vary significantly with different device capabilities

## Next Checks
1. **Cross-profile generalization test**: Evaluate DisGraph retrieval performance across diverse user profile types (entertainment, productivity, shopping) to verify the 83.1% alignment rate generalizes beyond AndroidWorld-specific profiles
2. **UI dynamism stress test**: Systematically measure Action Memory performance degradation under controlled UI changes (resource ID shifts, layout modifications) to quantify staleness detection reliability
3. **Template generation scalability assessment**: Compare success rates and development overhead between human-crafted and LLM-generated templates across 10+ diverse task categories to establish when each approach is preferable