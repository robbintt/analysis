---
ver: rpa2
title: Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation
arxiv_id: '2601.01026'
source_url: https://arxiv.org/abs/2601.01026
tags:
- classification
- learning
- data
- images
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of automated acute lymphoblastic
  leukemia (ALL) diagnosis by proposing an attention-based CNN system that combines
  EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for classifying malignant
  versus healthy cells from microscopic blood images. The approach incorporates comprehensive
  data augmentation, focal loss for class imbalance, and patient-wise data splitting
  to ensure robust evaluation.
---

# Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation

## Quick Facts
- arXiv ID: 2601.01026
- Source URL: https://arxiv.org/abs/2601.01026
- Reference count: 11
- Primary result: Achieves 97.89% F1-score and 97.89% accuracy on ALL cell classification using attention-based CNN

## Executive Summary
This study presents a novel attention-based convolutional neural network system for classifying malignant versus healthy cells in acute lymphoblastic leukemia (ALL) diagnosis. The approach combines EfficientNetV2-B3 with Squeeze-and-Excitation attention mechanisms, incorporating comprehensive data augmentation and focal loss to address class imbalance. The system demonstrates state-of-the-art performance on the C-NMC 2019 dataset while using significantly fewer parameters than baseline methods, with attention visualizations providing interpretable insights into diagnostically relevant cellular features.

## Method Summary
The proposed system integrates EfficientNetV2-B3 with Squeeze-and-Excitation (SE) attention mechanisms to create an attention-based CNN for ALL cell classification. The methodology employs extensive data augmentation techniques including geometric transformations, color jittering, and noise injection to address the limited sample size challenge. Focal loss is utilized to handle class imbalance between malignant and healthy cells, while patient-wise data splitting ensures robust evaluation by preventing data leakage across patients. The model is trained on the C-NMC 2019 dataset and validated through 100-iteration Monte Carlo experiments to ensure statistical significance.

## Key Results
- Achieves 97.89% F1-score and 97.89% accuracy on C-NMC 2019 dataset
- Demonstrates up to 4.67% improvement over baseline methods
- Uses 89% fewer parameters than VGG16 while maintaining superior performance
- Monte Carlo experiments show statistically significant improvements (p<0.001)

## Why This Works (Mechanism)
The attention-based CNN effectively focuses on diagnostically relevant cellular features by combining EfficientNetV2-B3's efficient feature extraction with Squeeze-and-Excitation mechanisms that recalibrate channel-wise feature responses. The comprehensive data augmentation pipeline addresses the limited sample size challenge inherent in medical imaging datasets, while focal loss mitigates the impact of class imbalance between malignant and healthy cells. The patient-wise data splitting strategy prevents overfitting and ensures the model generalizes well to unseen patients, which is critical for clinical deployment.

## Foundational Learning
- **Attention Mechanisms**: Used to focus on diagnostically relevant features in cellular images
  - Why needed: Helps the model identify critical regions for ALL classification
  - Quick check: Visualize attention maps to verify focus on relevant cellular structures

- **Data Augmentation**: Employs geometric and color transformations to expand training data
  - Why needed: Addresses limited sample size in medical imaging datasets
  - Quick check: Verify augmented samples maintain biological plausibility

- **Focal Loss**: Adapts standard cross-entropy to handle class imbalance
  - Why needed: Malignant cells are typically underrepresented in training data
  - Quick check: Monitor class-specific performance metrics during training

- **Patient-wise Data Splitting**: Ensures evaluation samples come from unseen patients
  - Why needed: Prevents data leakage and ensures clinical relevance
  - Quick check: Verify no patient overlap between training and validation sets

- **Monte Carlo Validation**: Uses repeated random sampling for statistical validation
  - Why needed: Provides robust performance estimates and significance testing
  - Quick check: Confirm stable performance across multiple iterations

- **EfficientNetV2 Architecture**: Provides efficient feature extraction with fewer parameters
  - Why needed: Balances computational efficiency with classification accuracy
  - Quick check: Monitor parameter count and inference time

## Architecture Onboarding

**Component Map**: Input Images -> Data Augmentation -> EfficientNetV2-B3 -> Squeeze-and-Excitation -> Focal Loss -> Output Classification

**Critical Path**: Data augmentation → EfficientNetV2-B3 feature extraction → SE attention recalibration → Focal loss optimization

**Design Tradeoffs**: The system prioritizes accuracy and interpretability over computational efficiency, using attention mechanisms that increase model complexity but provide valuable visualization insights. The choice of EfficientNetV2-B3 balances parameter efficiency with strong baseline performance.

**Failure Signatures**: Potential failures include overfitting to specific cellular appearances due to limited dataset diversity, attention mechanisms focusing on irrelevant features if training data is noisy, and class imbalance causing bias toward the majority class despite focal loss.

**3 First Experiments**:
1. Visualize attention maps on validation samples to verify focus on diagnostically relevant features
2. Perform ablation study removing SE attention mechanisms to quantify their contribution
3. Test model performance on a small subset of out-of-distribution samples to assess generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Validated exclusively on C-NMC 2019 dataset, limiting generalizability to other ALL datasets
- Does not address inter-observer variability in ground truth labeling
- Computational efficiency claims based solely on parameter count without comprehensive inference analysis

## Confidence
- **High confidence**: Technical implementation of attention-based CNN architecture and data augmentation pipeline
- **Medium confidence**: Reported performance metrics due to limited external validation
- **Medium confidence**: Clinical applicability given controlled dataset conditions

## Next Checks
1. External validation on independent ALL datasets from different clinical centers to assess generalizability
2. Ablation studies to quantify individual contributions of attention mechanisms, focal loss, and data augmentation
3. Clinical feasibility assessment including inference time, computational requirements, and workflow integration comparison