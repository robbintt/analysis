---
ver: rpa2
title: On-site estimation of battery electrochemical parameters via transfer learning
  based physics-informed neural network approach
arxiv_id: '2503.22396'
source_url: https://arxiv.org/abs/2503.22396
tags:
- parameters
- pinn
- phase
- battery
- parameter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a two-phase framework for estimating lithium-ion
  battery electrochemical parameters using Physics-Informed Neural Networks (PINNs)
  combined with transfer learning. In the first phase, a PINN is trained using only
  physical principles of the single particle model (SPM) without requiring field data.
---

# On-site estimation of battery electrochemical parameters via transfer learning based physics-informed neural network approach

## Quick Facts
- **arXiv ID**: 2503.22396
- **Source URL**: https://arxiv.org/abs/2503.22396
- **Reference count**: 22
- **Primary result**: 3.89% relative error in estimating active material volume fractions on degraded NMC cell with 106.1 ms per iteration on Raspberry Pi

## Executive Summary
This work presents a two-phase framework for estimating lithium-ion battery electrochemical parameters using Physics-Informed Neural Networks (PINNs) combined with transfer learning. The approach first trains a PINN using only physical principles of the single particle model (SPM) without requiring field data, then fine-tunes critical parameters like diffusion coefficients and active material volume fractions using real voltage profiles. By freezing most network parameters during fine-tuning, the method achieves real-time performance suitable for battery management systems while maintaining accuracy. Experimental validation demonstrates successful parameter estimation on a degraded NMC cell with computational times compatible with edge device deployment.

## Method Summary
The framework employs a DeepONet architecture to map current profiles to lithium concentration fields, trained in two phases. Phase 1 trains the network on SPM physical equations (Fick's law, boundary conditions, initial conditions) for 50,000 epochs without any field data. Phase 2 freezes the DeepONet weights and fine-tunes only the feed-forward network layers and learnable physical parameters (diffusion coefficients and active material volume fractions) using real voltage data. The method uses self-adaptive loss weighting to balance PDE residuals, boundary conditions, and voltage errors, enabling efficient convergence. The decoupled electrode structure and hard constraint transformation for initial conditions ensure physical consistency while maintaining computational efficiency.

## Key Results
- Achieved 3.89% relative error in estimating active material volume fractions on a degraded NMC cell
- Voltage RMSE of 8.94 mV in simulation and 8.25 mV on hardware implementation
- Computational time of 42.51 ms per iteration in simulation and 106.1 ms on Raspberry Pi 5
- Real-time parameter estimation feasible for battery management system deployment

## Why This Works (Mechanism)
The two-phase transfer learning approach works by first learning the universal physics of battery behavior through the SPM equations without requiring field data, creating a robust foundation that generalizes across different operating conditions. By freezing the DeepONet weights during fine-tuning, the method preserves this learned physics while only adjusting the final layers and critical parameters to match specific cell characteristics from voltage data. The self-adaptive loss weighting ensures proper balance between different physical constraints during training, preventing any single term from dominating and causing non-physical solutions. This architecture allows the model to leverage the efficiency of learned physics while maintaining the flexibility to adapt to individual cell variations through parameter estimation.

## Foundational Learning

- **Concept**: Single Particle Model (SPM) & Electrochemical Parameters
  - **Why needed here**: The entire PINN is built on the equations of the SPM. Understanding its assumptions (e.g., uniform current distribution, neglected electrolyte dynamics) and what parameters like diffusion coefficients ($D_i$) and active material volume fractions ($\epsilon_i$) physically represent is crucial to interpret the model's outputs and limitations.
  - **Quick check question**: Can you explain why the SPM might fail to accurately model a battery cell during a very fast (high C-rate) charge or discharge event?

- **Concept**: DeepONet Architecture
  - **Why needed here**: The paper uses a DeepONet, which is a specific neural network architecture designed to learn operators (mappings from functions to functions). It is used here to map a current profile function to the lithium concentration field over time and space. Understanding its split into branch and trunk networks is key to understanding the model's inputs.
  - **Quick check question**: In a DeepONet, which part of the network processes the input function (e.g., the current profile) and which part processes the coordinates (e.g., time and radius) where you want to evaluate the output?

- **Concept**: Inverse Problems in Machine Learning
  - **Why needed here**: The core task is parameter estimation, which is an inverse problem: inferring unknown internal parameters ($D_i, \epsilon_i$) from observable external data (voltage). This is different from a forward problem (predict voltage from known parameters). The loss function is designed specifically to solve this inverse problem.
  - **Quick check question**: In this paper, what is the primary observable data used in the loss function to guide the estimation of the unknown electrochemical parameters during the fine-tuning phase?

## Architecture Onboarding

- **Component map**: Input Layer (t, r, i_t, SOC_0) -> DeepONet (branch network processes current function, trunk network processes (t, r, i_t)) -> Combined output -> FFNN layers -> Predicted concentration c(t, r) -> Physics-Informed Loss Module (computes PDE residuals, boundary conditions, voltage error) -> Optimization Loop

- **Critical path**: Phase 1 Training (50k epochs on SPM equations) → Freeze DeepONet Weights → Initialize Trainable Parameters (D, ε) → Phase 2 Fine-tuning with voltage data (Adam optimizer, adaptive learning rates) → Converged Parameter Estimates

- **Design tradeoffs**: Physics vs. Data tradeoff uses SPM simplification for computational efficiency but may miss electrolyte dynamics at high C-rates. Frozen Weights vs. Adaptability tradeoff drastically reduces computational cost but assumes pre-learned physics is universally applicable. Soft Constraints vs. Hard Constraints tradeoff provides flexibility but may imperfectly satisfy boundary conditions.

- **Failure signatures**: Divergent Loss occurs if adaptive loss weighting fails and one term dominates. Slow/No Convergence in Phase 2 happens if initial parameter guesses are too far from true values or voltage data is sparse. High Error on Test Data indicates overfitting to training voltage profile rather than learning true physics.

- **First 3 experiments**: 1) Baseline Phase 1 Check: Train PINN from scratch on simulated SPM data and verify accurate concentration and voltage prediction before parameter estimation. 2) Single Parameter Estimation: Artificially change one parameter in simulated dataset and test Phase 2 recovery capability. 3) Edge Device Deployment: Port Phase 2 fine-tuning to Raspberry Pi and measure actual iteration times and convergence.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of input current profile impact the observability and convergence speed of specific electrochemical parameters during the fine-tuning phase?
  - **Basis in paper**: [explicit] The authors state in the conclusion that "a sensitivity analysis among the current profile and each updated parameter is required for this task, as well as including realistic current profiles in the training procedure."
  - **Why unresolved**: The current validation relies primarily on standard constant current charge profiles, whereas field data often involves dynamic discharge profiles which may alter parameter identifiability.
  - **What evidence would resolve it**: A comparative study of parameter estimation accuracy and convergence rates using dynamic loading profiles (e.g., drive cycles) versus static charge profiles.

- **Open Question 2**: Can the framework maintain real-time performance on edge devices when extended to include electrolyte dynamics?
  - **Basis in paper**: [explicit] The conclusion notes that "a more faithful representation of the cell will be made integrating other internal dynamics, like the electrolyte behaviour."
  - **Why unresolved**: The current Single Particle Model (SPM) neglects electrolyte dynamics to reduce computational cost; adding these physics increases the complexity of the partial differential equations and network structure.
  - **What evidence would resolve it**: Implementation of a Physics-Informed Neural Network based on an Enhanced SPM or P2D model, benchmarked for iteration time on the Raspberry Pi 5.

- **Open Question 3**: Does simultaneously tuning stoichiometric limits (θ_min/max) alongside active material volume fractions (ε) improve estimation accuracy for highly degraded cells?
  - **Basis in paper**: [inferred] The experimental results attribute the higher relative error in the negative electrode to changes in θ_100,n, stating, "The issue can be solved by adding the stoichiometric parameters to the fine-tuning process, at the cost of a more complex hyperparameter adjusting."
  - **Why unresolved**: While identified as a solution, the authors did not implement this due to increased complexity, leaving the trade-off between hyperparameter difficulty and accuracy gains unexplored.
  - **What evidence would resolve it**: Experimental results from degraded cells where stoichiometric parameters are treated as trainable variables, demonstrating error reduction relative to the fixed-parameter approach.

## Limitations
- SPM simplifications neglect electrolyte dynamics and may not accurately model fast charge/discharge cycles or cells with significant electrolyte resistance
- DeepONet architecture details require access to supplementary materials for complete reproducibility
- Self-adaptive loss weighting mechanism adds complexity and potential instability if gradient balancing fails
- Success demonstrated only on a single degraded NMC cell type, raising questions about generalizability across different chemistries

## Confidence
- **High Confidence**: The two-phase training framework with frozen DeepONet weights is technically sound and the computational efficiency claims (42.51 ms simulation, 106.1 ms on Raspberry Pi) are well-supported by experimental validation
- **Medium Confidence**: The inverse problem formulation and parameter estimation accuracy (3.89% relative error) are convincing for the tested case, but may not generalize across different battery chemistries or degradation patterns
- **Low Confidence**: The model's performance under real-world BMS constraints (noisy voltage measurements, varying temperatures, multiple aging mechanisms) is not demonstrated

## Next Checks
1. Test the complete framework on a second battery chemistry (e.g., LFP) with different aging mechanisms to verify generalizability beyond the NMC case
2. Implement the full system on an actual battery management system with real voltage sensor noise and temperature variations to validate edge deployment claims
3. Compare the computational efficiency and accuracy against traditional parameter estimation methods (e.g., genetic algorithms, particle filters) under identical hardware constraints