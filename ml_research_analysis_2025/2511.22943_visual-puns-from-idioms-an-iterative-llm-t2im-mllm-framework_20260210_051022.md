---
ver: rpa2
title: 'Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework'
arxiv_id: '2511.22943'
source_url: https://arxiv.org/abs/2511.22943
tags:
- visual
- idiom
- arxiv
- t2im
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of generating and evaluating
  idiom-based visual puns by introducing an iterative framework that combines large
  language models (LLMs), text-to-image models (T2IMs), and multimodal LLMs (MLLMs).
  The method iteratively generates detailed visual prompts, synthesizes images, infers
  idioms from the images, and refines prompts until recognition succeeds or a step
  limit is reached.
---

# Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework

## Quick Facts
- **arXiv ID**: 2511.22943
- **Source URL**: https://arxiv.org/abs/2511.22943
- **Reference count**: 0
- **Primary result**: Iterative LLM-T2IM-MLLM framework generates idiom-based visual puns; MLLM choice is primary performance driver (GPT: up to 79.8% accuracy)

## Executive Summary
This work introduces an iterative framework combining large language models (LLMs), text-to-image models (T2IMs), and multimodal LLMs (MLLMs) to generate visual puns from idioms. The method iteratively refines visual prompts based on MLLM feedback until recognition succeeds or reaches iteration limits. Using 1,000 idioms, the framework creates a dataset of visual pun images with paired prompts for benchmarking. Experiments across 10 LLMs and 10 MLLMs with one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver, with GPT achieving the highest accuracy (up to 79.8%), followed by Gemini. Claude performs best on average for prompt generation. Open-source MLLMs like Gemma are competitive with closed models, and iterative refinement within 2-3 rounds yields the most improvement.

## Method Summary
The framework uses an iterative four-step loop: (1) an LLM generates detailed visual prompts from idioms and prior edit suggestions, (2) a T2IM (Qwen-Image, 1024×1024) synthesizes images, (3) an MLLM infers the idiom from the image, and (4) an LLM judge checks semantic equivalence. The process repeats until recognition succeeds or after 5 iterations. The method relies on LLM-based linguistic decomposition to bridge figurative meanings to concrete visual elements, with MLLM feedback driving iterative refinement. The framework addresses the challenge of generating and evaluating idiom-based visual puns by capturing both literal and figurative meanings.

## Key Results
- MLLM choice is the primary performance driver: GPT achieves highest accuracies (up to 79.8%), with performance gaps exceeding 50 points between top and bottom MLLMs
- Iterative refinement yields diminishing returns after 2-3 rounds, with the first update contributing +4.0–+9.5 points
- Claude performs best on average for prompt generation, while Gemma (open-source MLLM) is competitive with closed models
- The framework demonstrates that linguistic guidance and targeted updates are key to successful visual pun generation

## Why This Works (Mechanism)

### Mechanism 1
Iterative refinement with MLLM feedback improves idiom-to-visual alignment more than single-shot generation. The MLLM detects when generated images fail to convey the target idiom and produces specific edit suggestions (missing objects, composition changes). The LLM incorporates these into the next prompt, progressively narrowing the semantic gap. Core assumption: MLLM can reliably articulate why recognition failed and suggest actionable visual edits. Evidence: [abstract] "iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds"; [Section 3.3, Table 3] "first update contributes +4.0–+9.5 points; later updates have diminishing returns"; [corpus] Neighbor papers show LLMs struggle with figurative-literal disambiguation (FMR 0.55–0.58). Break condition: If MLLM cannot reliably recognize idioms or produce coherent edit suggestions, feedback loop degrades into noise.

### Mechanism 2
MLLM visual understanding capacity is the primary bottleneck, not prompt quality or T2IM choice. Given sufficiently detailed prompts, variance in recognition accuracy across MLLMs (24–79.8%) far exceeds variance across LLMs (46.8–57.6%). The MLLM must integrate literal objects with metaphorical context—requiring compositional visual reasoning. Core assumption: Prompts generated by mid-tier LLMs are "good enough" that further improvements yield diminishing returns. Evidence: [abstract] "MLLM choice is the primary performance driver: GPT achieves the highest accuracies"; [Section 3.2] "The best–worst MLLM gap at a fixed LLM can exceed 50 points (e.g., with Claude as LLM: 79.8 vs. 29.4)"; [corpus] Related work on idiom processing in transformers (FMR 0.54–0.58) focuses on text-only models. Break condition: If T2IM quality degrades significantly, prompt detail may no longer compensate, shifting bottleneck back to generation.

### Mechanism 3
LLM-based linguistic decomposition bridges figurative meaning to concrete visual elements. The LLM decomposes an idiom into literal components (e.g., "butterflies" + "stomach") and figurative context ("nervousness"), then generates a prompt combining both. This externalizes the metaphorical reasoning that T2IMs lack. Core assumption: LLM correctly identifies both literal referents and their metaphorical mapping. Evidence: [abstract] "an LLM to generate visual prompts from idioms"; [Section 1, Fig. 1] "An LLM bridges literal and metaphorical meanings of an idiom, generating prompts that guide a T2IM"; [Section 3.3, Table 3] "+LLM: one-shot LLM-generated prompt... improves accuracy by +7.3–+15.3 points on every MLLM"; [corpus] Corpus lacks direct evidence on decomposition quality. Break condition: If idioms require cultural knowledge or context not captured in LLM's training, decomposition may be incomplete or incorrect.

## Foundational Learning

- **Non-compositional language understanding**: Idioms have meanings not derivable from constituent words. Understanding that "butterflies in stomach" ≠ insects in digestive system is prerequisite to correct visual pun design. Quick check: Can you explain why translating idioms word-by-word typically fails?

- **Iterative refinement / closed-loop feedback**: The pipeline relies on generating, evaluating, and refining. Understanding convergence criteria and when to stop iterating is essential. Quick check: Given Table 3 shows negligible gains after iteration 3, what would you set as the default max iterations?

- **Multimodal grounding**: The system must translate linguistic concepts to visual outputs and back. Understanding how visual representations encode semantic information is core to debugging failures. Quick check: If MLLM consistently misrecognizes images of a specific idiom, how would you diagnose whether the issue is in generation or recognition?

## Architecture Onboarding

- **Component map**: Idiom → LLM-prompt → T2IM → MLLM-infer → LLM-eval → (if fail) MLLM-update → next iteration
- **Critical path**: Idiom → LLM-prompt → T2IM → MLLM-infer → LLM-eval → (if fail) MLLM-update → next iteration
- **Design tradeoffs**: Single T2IM (Qwen-Image) isolates LLM/MLLM effects but limits generalizability claims; Max 5 iterations balances performance vs. cost; diminishing returns after 2–3 updates; Top-1 accuracy metric is strict
- **Failure signatures**: Low accuracy across all MLLM/LLM pairs → check idiom corpus difficulty or prompt template; High variance across MLLMs with fixed LLM → visual reasoning is bottleneck; High variance across LLMs with fixed MLLM → prompt decomposition is bottleneck; Early saturation → MLLM-update may produce low-quality suggestions
- **First 3 experiments**: (1) Reproduce main result: Run 100 idioms through pipeline with GPT (MLLM) + Claude (LLM); verify ~79.8% accuracy; (2) Ablate iterations: Compare 1-shot vs. 5-iteration on same 100 idioms; confirm +15–20 point gain; (3) Swap MLLM tier: Replace GPT with Gemma; measure accuracy drop to quantify MLLM contribution

## Open Questions the Paper Calls Out
- **Cross-lingual idioms**: Can the framework generalize to idioms in other languages (e.g., Chinese chengyu), and how do cultural differences affect visual pun generation and recognition?
- **Human evaluation**: Does MLLM-based idiom recognition accuracy correlate with human judgments of visual pun quality (e.g., capturing both literal and figurative meanings)?
- **T2IM diversity**: How does the iterative framework perform across diverse text-to-image models beyond Qwen-Image, particularly in controlled experiments beyond the 50-idiom case study?

## Limitations
- Reliance on a single T2IM configuration (Qwen-Image) limits generalizability claims
- Automatic, MLLM-based evaluation without human validation may not reflect true visual pun quality
- All experiments use only 1,000 English idioms, limiting cross-cultural and cross-linguistic applicability

## Confidence
- **High confidence** in MLLM being the primary performance driver (strong empirical evidence across 10 MLLMs with fixed LLM showing 24-79.8% accuracy range)
- **Medium confidence** in iterative refinement effectiveness (diminishing returns after 2-3 iterations documented, but limited ablation across different idiom types)
- **Low confidence** in LLM prompt quality being "good enough" (no direct comparison to expert-crafted prompts or human performance baseline)

## Next Checks
1. **Cross-T2IM validation**: Run the same pipeline with at least two additional T2IMs (e.g., DALL-E 3, Midjourney) to verify MLLM remains the primary bottleneck when T2IM quality varies
2. **Human evaluation baseline**: Have human judges generate visual prompts for 100 idioms and compare recognition accuracy against the best LLM-performing system to establish absolute performance levels
3. **Error analysis on iterations**: Categorize recognition failures by iteration (e.g., "literal-only interpretation," "missing contextual elements") to identify systematic weaknesses in the MLLM update mechanism