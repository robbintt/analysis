---
ver: rpa2
title: Scaling Vision Transformers for Functional MRI with Flat Maps
arxiv_id: '2510.13768'
source_url: https://arxiv.org/abs/2510.13768
tags:
- fmri
- data
- photo
- flat
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces flat map representations as a high-fidelity,
  structured input format for training fMRI foundation models. By transforming 4D
  volumetric fMRI data into sequences of 2D cortical flat maps, the authors bridge
  the modality gap between fMRI and natural images, enabling the use of standard vision
  transformer architectures.
---

# Scaling Vision Transformers for Functional MRI with Flat Maps

## Quick Facts
- arXiv ID: 2510.13768
- Source URL: https://arxiv.org/abs/2510.13768
- Reference count: 40
- This paper introduces flat map representations as a high-fidelity, structured input format for training fMRI foundation models, achieving strong downstream decoding performance across multiple tasks.

## Executive Summary
This paper introduces flat map representations as a high-fidelity, structured input format for training fMRI foundation models. By transforming 4D volumetric fMRI data into sequences of 2D cortical flat maps, the authors bridge the modality gap between fMRI and natural images, enabling the use of standard vision transformer architectures. They train spatiotemporal masked autoencoders (MAE) on 2.3K hours of Human Connectome Project data and observe strict power law scaling of reconstruction performance with dataset size—a hallmark of effective foundation models.

## Method Summary
The method converts volumetric fMRI into 2D cortical flat maps using surface mapping (fsLR) and pycortex tools, creating a 224×560 grid with ~77K valid pixels. Spatiotemporal masked autoencoders are then trained on these flat maps using a tube masking strategy (90% of patches masked). The model learns to reconstruct masked spatiotemporal patches, implicitly denoising the data while learning global functional dependencies. Downstream tasks are evaluated using an attentive probe (cross-attention pooling + linear classifier) on frozen encoder outputs.

## Key Results
- Power law scaling observed: Reconstruction performance strictly improves with dataset size (L ∝ N^(-0.016))
- Strong downstream performance: HCP cognitive state decoding (98.8% accuracy), UK Biobank sex classification (84.6%), Natural Scenes Dataset CLIP classification (21.0%)
- Flat maps preserve full cortical signal while reducing modeling complexity compared to volumetric approaches
- Small models (12.4M parameters) perform comparably to larger ones (88.6M parameters), suggesting current data bottlenecks model capacity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Representing 4D fMRI as 2D cortical flat maps likely preserves signal fidelity while reducing modeling complexity relative to volumetric approaches.
- **Mechanism:** By projecting the cortical surface (a 2D manifold) onto a flat plane, the model retains full spatial resolution (~77K valid pixels) without needing to learn the complex 3D folding structure of the brain from scratch. This injects a structural prior (local cortical neighborhoods are functionally related) similar to parcellation but without the ~100x dimensionality loss.
- **Core assumption:** The biological signal of interest resides primarily on the cortical sheet, and the distortion introduced by flattening does not destroy the spatial relationships required for feature learning.
- **Evidence anchors:**
  - [Page 1]: "This flat map representation maintains the full cortical fMRI signal... while also explicitly injecting the inductive bias of local cortical neighborhoods."
  - [Page 3]: "Structured signal can be reconstructed while unstructured noise cannot."
  - [corpus]: *From Flat to Round...* highlights the tradeoffs of flattening vs. retaining 3D structure, suggesting this representation choice is a critical active area of research.
- **Break condition:** If the signal of interest relies heavily on deep subcortical structures or complex 3D geometric relationships destroyed by the flattening projection, performance will degrade.

### Mechanism 2
- **Claim:** High-ratio masking (90%) in the spatiotemporal MAE forces the learning of global functional dependencies rather than local interpolation.
- **Mechanism:** With only 10% of patches visible, the model cannot solve the reconstruction task via simple local smoothing. It must build a global internal model of brain dynamics (likely functional networks) to infer missing activity. This results in the "implicit denoising" effect where outputs are smoother (less noisy) than inputs.
- **Core assumption:** fMRI noise is uncorrelated high-frequency structure, while neural signal is correlated low-frequency structure, allowing the model to separate the two during reconstruction.
- **Evidence anchors:**
  - [Page 3]: "The predictions are notably smoother compared to the noisy target data... Structured signal can be reconstructed while unstructured noise cannot."
  - [Page 2]: "A large fraction of the image patches are first masked... The model is trained to minimize the MSE loss."
  - [corpus]: *Adapting HFMCA to Graph Data* discusses SSL for generalizable fMRI, supporting the efficacy of self-supervised objectives in data-scarce neuroimaging domains.
- **Break condition:** If the masking ratio is too low, the model collapses to local interpolation; if too high or if patches are too small, computational cost explodes without semantic gain.

### Mechanism 3
- **Claim:** Standardizing fMRI into image/video formats unlocks "off-the-shelf" scaling properties observed in computer vision.
- **Mechanism:** By conforming to the ViT input format (patch sequences), the system leverages optimized architectures that exhibit predictable power-law scaling with data volume. The paper demonstrates that increasing HCP training data strictly lowers validation loss according to a power law (L ∝ N^(-0.016)).
- **Core assumption:** The optimization dynamics and scaling laws of natural images transfer to physiological time-series data when formatted similarly.
- **Evidence anchors:**
  - [Abstract]: "We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law."
  - [Page 4]: "In-distribution reconstruction obeys a strict power law."
  - [corpus]: *Comparing and Scaling fMRI Features* explicitly examines scaling behavior in fMRI features, reinforcing that representation choice dictates scaling potential.
- **Break condition:** Scaling breaks when moving out-of-distribution; the paper notes OOD performance (on NSD) saturates faster than in-distribution (HCP) performance.

## Foundational Learning

- **Concept:** **Cortical Surface Reconstruction & Flat Maps**
  - **Why needed here:** The core innovation is the data representation. You must understand that fMRI is natively 3D volumes, but this method resamples it to a 2D surface (fsaverage) and then "unfolds" the cortical sheet into a flat image (using tools like pycortex).
  - **Quick check question:** Does a "flat map" preserve the distance between the frontal and occipital lobes?

- **Concept:** **Spatiotemporal Masked Autoencoders (MAE)**
  - **Why needed here:** The training objective. You need to understand that the model hides (masks) 90% of the input (both in space and time) and is tasked with reconstructing the missing pixels.
  - **Quick check question:** Why does the paper use a "tube masking" strategy derived from VideoMAE?

- **Concept:** **Scaling Laws**
  - **Why needed here:** The validation metric. The paper proves success not just by accuracy, but by demonstrating a predictable logarithmic improvement in loss as data increases.
  - **Quick check question:** If doubling the dataset size lowers the loss by a fixed factor, is the model scaling effectively?

## Architecture Onboarding

- **Component map:** Preprocessed fMRI -> Surface Mapping (fsLR) -> Flat Map (Pycortex, 224×560 grid) -> Patchification (16×16×16 spacetime patches) -> Encoder (ViT, 10% visible patches) -> Decoder (lightweight ViT) -> Probe (Attentive probe) -> Downstream tasks
- **Critical path:** The handling of "background" pixels (the ~40% of the flat map image that isn't brain) is the distinct implementation detail. The system must exclude these from the loss calculation and potentially the patch embedding process to avoid training on geometry rather than signal.
- **Design tradeoffs:**
  - Patch Size: Reducing temporal patch size (p_t) improves accuracy (finer granularity) but increases compute/memory (more tokens)
  - Data Diversity vs. Scale: The paper notes that simply adding more HCP data (scale) did not improve OOD performance on NSD indefinitely, suggesting diversity is the bottleneck, not just size
  - Model Size: Surprisingly, smaller models (12.4M params) performed comparably to larger ones (88.6M params), suggesting the current data/representation may bottleneck before model capacity does
- **Failure signatures:**
  - Loss Saturation: Validation loss goes down, but OOD decoding accuracy (e.g., UKBB) flattens or drops as the model overfits to HCP-specific dynamics
  - Spatial Smoothing: Model outputs look visually "correct" but lack high-frequency details, effectively acting as a Gaussian blur
- **First 3 experiments:**
  1. Reconstruction Visualization: Train on a small subset of HCP, visualize the reconstruction of masked patches. Confirm the model learns anatomy (folds/regions) and not just noise.
  2. Scaling Law Verification: Train identical architectures on 500K vs 1M vs 2M frames and plot the final validation loss on a log-log plot to verify the power law.
  3. Temporal Ablation: Compare p_t=16 (full clip patch) vs p_t=4 (smaller temporal patches) on the "HCP State Decoding" task to quantify the speed/accuracy tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does increasing the diversity of pretraining data (beyond HCP) restore strict power-law scaling for out-of-distribution (OOD) downstream tasks?
- Basis: [explicit] The authors note that while in-distribution reconstruction scales with data, OOD performance on NSD saturates, raising the possibility that "HCP is insufficiently diverse to support learning truly generalizable representations."
- Why unresolved: The paper demonstrates that simply scaling up similar data (HCP) improves in-distribution metrics but fails to linearly improve transfer learning performance, breaking a key promise of foundation models.
- What evidence would resolve it: Pretraining the model on a multi-site dataset with heterogeneous acquisition parameters and subjects, then re-evaluating the scaling laws for OOD decoding benchmarks.

### Open Question 2
- Question: Why does the largest model architecture (ViT-L) underperform compared to smaller models (ViT-B) in the current experimental setup?
- Basis: [explicit] The authors state, "Surprisingly, we find that relatively small models are sufficient... The largest model (ViT-L) performs notably worse."
- Why unresolved: This contradicts standard deep learning scaling laws where performance improves with parameter count. It suggests the model may be overfitting the limited diversity of the HCP dataset or requires different regularization/training strategies.
- What evidence would resolve it: A hyperparameter sweep specifically for the ViT-L architecture (e.g., varying regularization, training duration, or learning rates) to determine if the performance drop is an optimization issue or a fundamental constraint of the data modality.

### Open Question 3
- Question: How does the performance of flat map representations compare to native 4D volumetric approaches in terms of computational efficiency and retention of subcortical information?
- Basis: [explicit] The authors list "implementing direct comparisons to alternative parcellation and volume based modeling approaches" as an active research direction.
- Why unresolved: While flat maps preserve full cortical signal, the flattening process excludes subcortical structures often relevant in clinical neuroscience. The trade-off between the "inductive bias" of flat maps and the "native" completeness of 4D volumes remains unquantified.
- What evidence would resolve it: A controlled benchmark comparing fm-MAE against a 4D volume transformer (like Swin4D) on identical tasks, specifically including tasks dependent on subcortical activity.

## Limitations

- Flat map representation excludes subcortical structures, which may contain relevant signals for certain analyses
- The decoder architecture details are not fully specified, affecting exact reproducibility
- OOD performance (NSD/UKBB) plateaus despite continued in-distribution improvement, suggesting data diversity limitations
- No direct comparison to volumetric approaches to quantify representation-specific advantages

## Confidence

- **High**: Power law scaling behavior with dataset size (empirically observed and well-established in vision literature)
- **High**: Flat maps enable use of standard ViT architectures without architectural modifications
- **Medium**: Flat maps preserve full cortical signal while reducing complexity (based on design choice but not explicitly validated against volumetric alternatives)
- **Medium**: 90% masking ratio optimally forces global dependency learning (supported by reconstruction quality but not systematically ablated)
- **Low**: Flat maps are definitively superior to volumetric approaches (no direct comparison provided)

## Next Checks

1. Compare flat-map vs. volumetric MAE approaches on identical downstream tasks to quantify representation-specific gains
2. Systematically vary masking ratios (70%, 80%, 90%, 95%) and patch sizes to identify optimal spatiotemporal reconstruction tradeoffs
3. Validate that downstream performance generalizes across diverse MRI acquisition protocols beyond HCP/UKBB/NSD to test real-world applicability