---
ver: rpa2
title: 'HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training'
arxiv_id: '2601.10940'
source_url: https://arxiv.org/abs/2601.10940
tags:
- client
- server
- memory
- optimization
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'HOSL proposes a hybrid-order split learning framework that addresses
  the memory bottleneck in LLM fine-tuning on resource-constrained edge devices. The
  method strategically partitions optimization: the client employs zeroth-order (ZO)
  optimization to eliminate memory-intensive backpropagation and activation storage,
  while the server uses first-order (FO) optimization to ensure rapid convergence.'
---

# HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training

## Quick Facts
- arXiv ID: 2601.10940
- Source URL: https://arxiv.org/abs/2601.10940
- Reference count: 40
- Key outcome: HOSL reduces client GPU memory by up to 3.7× while achieving accuracy within 0.20%-4.23% of FO baseline and outperforming ZO baseline by up to 15.55%.

## Executive Summary
HOSL proposes a hybrid-order split learning framework that addresses the memory bottleneck in LLM fine-tuning on resource-constrained edge devices. The method strategically partitions optimization: the client employs zeroth-order (ZO) optimization to eliminate memory-intensive backpropagation and activation storage, while the server uses first-order (FO) optimization to ensure rapid convergence. Theoretical analysis establishes an O(√d_c/(T√Q)) convergence rate, where d_c is the client-side parameter dimension, demonstrating improved performance with more computation offloaded to the server. Extensive experiments on OPT-125M and OPT-1.3B models across six tasks show HOSL reduces client GPU memory by up to 3.7× compared to fully FO methods while achieving accuracy within 0.20%-4.23% of the FO baseline and outperforming the ZO baseline by up to 15.55%.

## Method Summary
HOSL is a hybrid-order split learning framework for LLM fine-tuning where the client uses zeroth-order (ZO) optimization and the server uses first-order (FO) optimization. The client employs in-place ZO gradient estimation via finite differences, eliminating backpropagation and activation storage. The server performs standard FO updates with backpropagation. The method partitions the model at layer k (e.g., k=5), with the client handling the first k layers and the server handling the remaining layers. Training proceeds in three phases: (1) client performs Q perturbation cycles for ZO gradient estimation, (2) server updates its parameters using FO optimization with unperturbed activations, and (3) client applies the accumulated ZO gradient update. The framework uses seed-based perturbation vectors to ensure reproducibility while maintaining memory efficiency.

## Key Results
- HOSL reduces client GPU memory by up to 3.7× compared to fully FO methods (1.38 GB vs 2.23 GB for OPT-125M on SST-2)
- Achieves accuracy within 0.20%-4.23% of the FO baseline across six tasks
- Outperforms the ZO baseline by up to 15.55% on tasks like SST-2
- Theoretical convergence rate O(√d_c/(T√Q)) improves with more computation offloaded to server
- Server memory bottleneck identified as logits tensor for large models with large vocabulary (45.98 GB for OPT-1.3B on BoolQ)

## Why This Works (Mechanism)

### Mechanism 1: Asymmetric Hybrid Optimization for Memory-Convergence Tradeoff
HOSL splits optimization methods across the network boundary, using ZO optimization on the client for memory efficiency and FO optimization on the server for convergence. The client performs only forward passes with in-place parameter perturbations, eliminating backpropagation and activation storage. The server maintains standard FO optimization with backpropagation. This design preserves client-side memory efficiency while maintaining near-baseline convergence. The mechanism works because server-side FO updates provide exact gradients for the server parameters while client-side ZO updates, though noisier, are sufficient for the smaller client parameter space.

### Mechanism 2: In-Place ZO Gradient Estimation Eliminates Activation Storage
The client uses MeZO-style gradient estimation: ĝ = (L(θ+εz) - L(θ-εz)) / 2ε · z, where z is a random perturbation vector. Multiple perturbations (Q) are averaged for variance reduction. Crucially, the client operates in inference mode—no computational graph is constructed. Parameters are perturbed in-place using seeded random vectors, and activations are never stored. This eliminates the memory overhead of storing activations for backpropagation, reducing client memory to inference-level requirements.

### Mechanism 3: Dimension-Dependent Convergence via Server Offloading
The convergence rate scales with client-side dimension d_c rather than full model dimension, enabling faster convergence when more computation is offloaded to the server. The theoretical analysis shows convergence rate O(√(d_c/TQ)). Server FO updates are exact and dimension-independent at the client; client ZO updates incur dimension-dependent variance. By reducing d_c (placing more layers on the server), the dimensional penalty is minimized, leading to better convergence properties than pure ZO optimization.

## Foundational Learning

- **Concept: Split Learning (SL) fundamentals** - Understanding where activations flow and what must be exchanged is prerequisite to reasoning about memory savings. Can you explain why FO-based SL still requires client-side activation storage even though computation is partitioned?
- **Concept: Zeroth-Order (ZO) optimization and gradient estimation** - The core client-side mechanism; understanding finite-difference gradient estimation and its variance properties is essential. Why does ZO gradient estimation require 2Q forward passes per update, and what happens to variance as Q increases?
- **Concept: Memory components in LLM training** - The paper's Appendix derives detailed memory calculations; practitioners need to understand which components (parameters, gradients, activations, KV cache, logits) dominate memory at different split points. For a 12-layer model with split at layer 5, can you estimate which component dominates server-side memory: stored activations or logits?

## Architecture Onboarding

- **Component map:**
  Client (layers 1-k) -> Server (layers k+1 to L)
  Client: θ_c parameters, ZO optimizer (MeZO), No activation store, Random seeds (Q)
  Server: θ_s parameters, FO optimizer (SGD), Stores activations, Backprop graph
  Communication: h (activations) → server, L (scalar losses) ← server, h (unperturbed) → server, ack ← server

- **Critical path:**
  1. Initialize model, partition at cut layer k, distribute θ_c and θ_s
  2. For each iteration: sample batch, perform Q perturbation cycles (positive/negative forward passes), accumulate ZO gradients
  3. Forward pass with original θ_c, send to server for FO update
  4. After server acknowledgment, apply accumulated ZO update to θ_c
  5. Repeat until convergence

- **Design tradeoffs:**
  | Decision | Effect |
  |----------|--------|
  | Lower k (fewer client layers) | Smaller d_c → faster convergence, but less privacy; client memory unchanged (dominated by early layers + embeddings) |
  | Higher Q (more perturbations) | Lower variance → better accuracy, but 2× more forward passes per iteration |
  | Larger batch size | Better gradient estimates, but linear memory increase (especially logits on server) |

- **Failure signatures:**
  - Client OOM with long sequences → KV cache exceeds available memory; reduce batch size or sequence length
  - Accuracy plateaus well below FO baseline → d_c may be too large; move split point earlier or increase Q
  - Non-reproducible results across runs → seeded perturbation vectors not regenerating correctly; verify seed handling in ZOUPDATE
  - Server OOM with large vocab models → logits tensor (BSV) dominates; this is the primary server bottleneck for models like OPT-1.3B on BoolQ (Table II shows 45.98 GB server memory)

- **First 3 experiments:**
  1. **Memory profiling baseline:** Run HOSL on OPT-125M with SST-2, measure client GPU memory at each phase. Compare against FO-FO and ZO-ZO baselines. Validate 1.38 GB client memory matches theoretical estimate (Section IX-B).
  2. **Ablation on split point k:** Vary k ∈ {3, 5, 7} on OPT-125M, plot accuracy vs. d_c. Confirm convergence improves as d_c decreases (per Remark 2).
  3. **Perturbation count Q sweep:** Test Q ∈ {1, 5, 10, 20} on a single task (e.g., CB). Plot accuracy and wall-clock time. Identify point of diminishing returns where additional Q does not justify extra forward passes.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does data heterogeneity (non-IID data) impact the convergence and accuracy of HOSL in a multi-client federated setting? The conclusion explicitly identifies this as a limitation: "our analysis assumes a single client and does not address data heterogeneity in a federated setting."

- **Open Question 2:** Can the wall-clock training latency caused by sequential ZO perturbation passes be reduced to make HOSL competitive with FO training in time-critical applications? The authors note: "One limitation of HOSL is the increased number of forward passes required for ZO gradient estimation on the client side, which may increase wall-clock training time."

- **Open Question 3:** How does the requirement to transmit smashed data 2Q+1 times per iteration impact communication efficiency compared to standard Split Learning? The algorithm requires the client to send activations to the server for every positive and negative perturbation (2Q times) plus one clean forward pass (Phase 2), inferred from Section III.

## Limitations
- Convergence analysis depends on strong assumptions about smoothness and bounded variance that may not hold in practice for large-scale language models.
- Memory savings calculations are theoretical and assume ideal conditions; practical implementations may face additional overhead.
- The perturbation-based gradient estimation introduces additional computational overhead that may become prohibitive for very large models or sequence lengths.

## Confidence
- **High Confidence:** Memory reduction mechanism (eliminating backpropagation and activation storage via ZO optimization), basic experimental setup (task selection, model sizes, split point), and the fundamental trade-off between client memory and convergence rate.
- **Medium Confidence:** The specific convergence rate O(√(d_c/TQ)) and the claim that it improves with increased server offloading, and accuracy preservation within 0.20%-4.23% of FO baseline across all tasks.
- **Low Confidence:** The absolute memory savings figures (1.38 GB vs 2.23 GB for OPT-125M SST-2) and the server memory bottleneck claim (45.98 GB for OPT-1.3B BoolQ) depend heavily on specific implementation details.

## Next Checks
1. **Convergence validation:** Replicate the accuracy vs. client parameter dimension (d_c) experiment from Figure 3 across all six tasks, verifying that accuracy improves as more layers are offloaded to the server as predicted by the O(√(d_c/TQ)) convergence rate.

2. **Memory measurement validation:** Implement independent memory profiling of the client and server components during HOSL training on OPT-125M SST-2, measuring peak GPU memory usage for all components (parameters, gradients, activations, logits, KV cache) and comparing against the theoretical estimates in Appendix IX-B.

3. **Perturbation variance analysis:** Conduct a controlled experiment varying Q from 1 to 20 on a representative task, measuring both accuracy and wall-clock time per iteration, and plotting the variance of the ZO gradient estimator against the number of perturbations to validate the variance reduction claims.