---
ver: rpa2
title: 'ViTSP: A Vision Language Models Guided Framework for Large-Scale Traveling
  Salesman Problems'
arxiv_id: '2509.23465'
source_url: https://arxiv.org/abs/2509.23465
tags:
- optimality
- runtime
- seconds
- instances
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ViTSP, a vision language model (VLM)-guided
  framework for solving large-scale Traveling Salesman Problems (TSPs). ViTSP leverages
  pre-trained VLMs to visually identify promising subproblems from TSP instances,
  which are then optimized using exact solvers to improve the global solution.
---

# ViTSP: A Vision Language Models Guided Framework for Large-Scale Traveling Salesman Problems

## Quick Facts
- arXiv ID: 2509.23465
- Source URL: https://arxiv.org/abs/2509.23465
- Reference count: 40
- ViTSP achieves average optimality gaps below 0.2% on TSPLIB instances (1k-88k nodes)

## Executive Summary
This paper proposes ViTSP, a vision language model (VLM)-guided framework for solving large-scale Traveling Salesman Problems (TSPs). ViTSP leverages pre-trained VLMs to visually identify promising subproblems from TSP instances, which are then optimized using exact solvers to improve the global solution. Unlike learning-based approaches that require training and struggle with out-of-distribution instances, ViTSP bypasses dedicated model training and maintains effectiveness across diverse TSP instances. Experiments on real-world TSPLIB instances show that ViTSP consistently outperforms existing learning-based methods and reduces LKH-3's gaps by 12-100% under the same runtime budget.

## Method Summary
ViTSP works by converting TSP instances into visual representations (node coordinates) and using a pre-trained VLM to identify promising subregions containing high-value nodes. The VLM outputs bounding box coordinates that define subproblems, which are then solved using exact solvers like Concorde. The framework iteratively extracts and solves subproblems, using the solutions to guide the global search. This approach avoids the need for training specialized models while leveraging the VLM's ability to recognize spatial patterns and promising node clusters.

## Key Results
- Achieves average optimality gaps below 0.2% on TSPLIB instances ranging from 1,000 to 88,000 nodes
- Outperforms existing learning-based methods across all tested instance sizes
- Reduces LKH-3's optimality gaps by 12-100% under equivalent runtime constraints
- Demonstrates effectiveness on very-large-scale instances where traditional solvers struggle

## Why This Works (Mechanism)
ViTSP leverages pre-trained VLMs' ability to recognize spatial patterns and identify promising regions in TSP instances without requiring task-specific training. The VLM's visual reasoning capability allows it to detect clusters of high-value nodes and spatial relationships that traditional solvers might miss. By decomposing large instances into smaller, manageable subproblems, the framework combines the VLM's pattern recognition with exact solvers' optimality guarantees, achieving better overall solutions than either approach alone.

## Foundational Learning
- Traveling Salesman Problem fundamentals: why needed - core optimization problem being solved; quick check - understand NP-hardness and solution approaches
- Vision Language Models: why needed - understand VLM capabilities for visual reasoning; quick check - review VLM architecture and pre-training objectives
- Exact TSP solvers (Concorde, LKH-3): why needed - understand baseline performance and limitations; quick check - compare solver approaches and performance characteristics
- Subproblem decomposition strategies: why needed - grasp how breaking down problems aids solution; quick check - analyze decomposition benefits and trade-offs

## Architecture Onboarding

**Component Map**: TSP instance → VLM visual encoder → Bounding box selection → Subproblem extraction → Exact solver → Global solution update → (iterate)

**Critical Path**: VLM inference → Subproblem definition → Exact solver execution → Solution integration → Termination check

**Design Tradeoffs**: Uses pre-trained VLMs to avoid training overhead vs. potential limitations in specialized reasoning; focuses on bounding box selection vs. more complex region definitions; balances VLM guidance with exact solver precision

**Failure Signatures**: Poor VLM subregion selection leading to suboptimal subproblems; excessive computational overhead from VLM inference on large instances; integration issues between VLM solutions and global search

**3 First Experiments**:
1. Test VLM accuracy on identifying high-value node clusters in synthetic TSP instances
2. Compare bounding box vs. sequence-based selection strategies on small instances
3. Evaluate VLM-guided decomposition vs. random decomposition on mid-sized TSPLIB instances

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the visual guidance framework be effectively generalized to other combinatorial optimization problems with more complex constraints, such as Capacitated Vehicle Routing Problems (CVRP)?
- Basis in paper: The authors state that "the promising results from ViTSP suggest opportunities to expand our framework to other routing problems" because TSP serves as a base case.
- Why unresolved: It is unclear if 2D visual prompts alone can capture high-dimensional constraints (e.g., capacity, time windows) required for effective subproblem identification in VRP.
- What evidence would resolve it: Successful application of ViTSP to standard CVRP benchmarks, demonstrating performance competitive with or superior to VRP-specific learning-based heuristics.

### Open Question 2
- Question: What specific visual features or reasoning heuristics do VLMs utilize to identify promising sub-regions, and can this "black box" decision-making be interpreted?
- Basis in paper: The conclusion notes that "interpreting how the decomposition is determined lies beyond our current scope and remains an important future direction."
- Why unresolved: The study validates the *utility* of VLMs for optimization but does not explain the internal logic driving the selection of coordinate sets.
- What evidence would resolve it: An interpretability analysis (e.g., attention visualization) correlating VLM-selected regions with structural TSP properties like edge crossings or node density.

### Open Question 3
- Question: Would integrating alternative selection operations, such as sequence-based selection, improve performance over the current box-region approach in dense or specific instance types?
- Basis in paper: The ablation study notes that random sequence selection outperformed ViTSP in early stages on the `pla85900` instance, suggesting "potential value of alternative operations beyond the box-region selection."
- Why unresolved: The current implementation restricts the VLM to outputting box coordinates ($x_{min}, x_{max}, \dots$), potentially limiting the search space compared to sequence-based neighborhood operators.
- What evidence would resolve it: A modified ViTSP framework allowing VLMs to select arbitrary node sequences, showing faster convergence on dense instances.

## Limitations
- Relies on VLM's ability to accurately identify promising subproblems across diverse TSP instances without thorough validation
- Computational overhead of VLM inference for large-scale instances is not explicitly discussed
- Does not provide detailed analysis of VLM performance on different types of TSP instances (Euclidean vs non-Euclidean, clustered vs uniformly distributed)

## Confidence
High: Experimental results show consistent performance improvements over baseline solvers across multiple instance sizes and benchmarks
Medium: The approach demonstrates effectiveness but lacks detailed analysis of VLM decision-making and computational overhead
Low: Generalization to other combinatorial optimization problems remains untested and uncertain

## Next Checks
1. Conduct ablation studies comparing different VLM selection strategies (bounding box vs sequence-based) on dense TSP instances
2. Analyze computational overhead of VLM inference across different instance scales to quantify practical runtime benefits
3. Test ViTSP framework on non-Euclidean TSP instances to evaluate robustness to different problem structures