---
ver: rpa2
title: A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured
  Customer Reviews
arxiv_id: '2601.19214'
source_url: https://arxiv.org/abs/2601.19214
tags:
- suggestions
- extraction
- clustering
- suggestion
- hybrid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a hybrid pipeline for actionable suggestion
  mining from customer reviews, combining a high-recall RoBERTa classifier with an
  instruction-tuned LLM. The classifier uses a precision-recall surrogate loss to
  reduce unrecoverable false negatives, while the LLM handles extraction, categorization,
  clustering, and summarization.
---

# A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews

## Quick Facts
- arXiv ID: 2601.19214
- Source URL: https://arxiv.org/abs/2601.19214
- Reference count: 19
- Hybrid pipeline achieves high extraction accuracy (BERTScore 0.92, BLEURT 0.89) and cluster coherence (AMI 0.67)

## Executive Summary
This paper presents a hybrid pipeline for actionable suggestion mining from customer reviews, combining a high-recall RoBERTa classifier with an instruction-tuned LLM. The classifier uses a precision-recall surrogate loss to reduce unrecoverable false negatives, while the LLM handles extraction, categorization, clustering, and summarization. Experiments show the hybrid approach outperforms prompt-only, rule-based, and classifier-only baselines, achieving high extraction accuracy and cluster coherence. Human evaluations confirm high interpretability and faithfulness across all pipeline stages. The method generalizes well across domains but requires domain adaptation for optimal precision.

## Method Summary
The hybrid pipeline processes customer reviews through a two-stage architecture. First, a RoBERTa-base classifier with precision-recall surrogate loss identifies reviews containing actionable suggestions. The classifier is trained with a hybrid objective combining cross-entropy loss with a precision-recall approximation across 25 thresholds. Reviews passing this filter are then processed by an instruction-tuned LLM (Gemma-3-27B, Q4_K_M quantized) which extracts suggestions, categorizes them, clusters similar suggestions, and generates summaries. The pipeline uses classifier gating to reduce LLM hallucination risk and computational costs while maintaining extraction quality.

## Key Results
- Extraction accuracy: BERTScore 0.92, BLEURT 0.89, Exact F1 0.87, Fuzzy F1 0.93
- Cluster coherence: Adjusted Mutual Information 0.67 (vs 0.49 for prompt-only)
- Cross-domain performance varies: Precision drops to 0.58 in finance and 0.55 in automotive
- Human evaluations show high interpretability (4.3/5) and faithfulness (4.2/5) across all stages

## Why This Works (Mechanism)

### Mechanism 1: Precision-Recall Surrogate Loss
The classifier uses a hybrid loss combining cross-entropy with a differentiable precision approximation across 25 thresholds. This directly optimizes the precision-recall curve rather than relying solely on cross-entropy, improving recall while maintaining calibrated probabilities. Removing the PR surrogate reduces recall to 0.8873 (-3.49%) with negligible precision change.

### Mechanism 2: Classifier Gating
The high-recall RoBERTa classifier filters reviews before LLM processing, reducing hallucination risk and computational cost. By constraining the LLM's input space to relevant documents, the pipeline minimizes opportunities for the LLM to infer non-existent suggestions from mixed-intent text.

### Mechanism 3: LLM-Based Clustering
Unlike embedding-based methods, the LLM performs global theme discovery by reasoning jointly over all suggestions within a category. This produces more coherent and interpretable clusters, achieving AMI=0.67 versus 0.49 for prompt-only approaches.

## Foundational Learning

- **Recall-oriented loss functions**: Why needed - Standard cross-entropy treats false positives and false negatives symmetrically; this pipeline explicitly prioritizes recall because missed suggestions cannot be recovered downstream. Quick check - Can you explain why a 3.49% recall gain might matter more operationally than a 3.49% precision gain in this context?

- **LLM hallucination and span inconsistency**: Why needed - The hybrid architecture is motivated by known LLM failure modes—generating content not grounded in input (hallucination) and producing unstable extraction boundaries. Quick check - What specific failure does classifier gating mitigate, and what failure modes does it not address?

- **Quantization for local deployment**: Why needed - The paper emphasizes practical deployability; quantization reduces memory by 2.4× without significant quality loss. Quick check - What tradeoff does quantization introduce, and how would you detect if it's degrading your pipeline?

## Architecture Onboarding

- **Component map**: Raw reviews -> RoBERTa classifier (PR surrogate loss) -> Gemma-3-27B LLM (extraction -> categorization -> clustering -> summarization)
- **Critical path**: Classifier recall -> extraction fidelity -> cluster coherence. If classifier recall drops, everything downstream misses signal. If extraction is noisy, clustering fragments.
- **Design tradeoffs**: Rewritten suggestions improve clustering stability but make span-matching metrics misleading—use semantic metrics instead. High-recall classifier admits more false positives; LLM must handle noise gracefully.
- **Failure signatures**: Cross-domain precision drops with domain-specific terminology triggering false positives; sarcastic phrasing and multi-step implied requests cause classifier errors; LLM mis-clusters closely related but distinct suggestions when terminology overlaps.
- **First 3 experiments**:
  1. Train classifier with and without PR surrogate loss on your domain; measure recall delta and statistical significance
  2. Run trained classifier on held-out domain sample; if precision drops below ~0.7, plan domain-adaptive fine-tuning
  3. Compare LLM-based clustering vs SBERT+HDBSCAN on 100-suggestion sample; have domain experts rate cluster interpretability

## Open Questions the Paper Calls Out

1. **Domain adaptation effectiveness**: Can domain-adaptive pre-training or adapter layers effectively close the precision gap in specialized industries (e.g., finance, automotive) without sacrificing the high recall achieved by the current RoBERTa classifier? The paper demonstrates precision drops to 0.58 in finance and 0.55 in automotive but does not implement domain adaptation techniques.

2. **Lightweight prompt tuning**: Can lightweight prompt tuning or constrained decoding strategies reduce "cross-topic bleed-over" in clustering without requiring manual prompt engineering for each new domain? Current prompts can occasionally misassign suggestions to closely related but distinct themes.

3. **Efficient local deployment**: Can smaller, instruction-tuned models (<8B parameters) achieve necessary extraction fidelity and semantic stability to replace the 27B model? The paper currently relies on resource-intensive 27B parameter model, leaving lightweight deployment feasibility unproven.

## Limitations

- Proprietary datasets prevent independent validation and faithful reproduction
- Fixed category list and full prompt templates are not disclosed
- Domain adaptation challenges acknowledged but not systematically addressed
- Cross-domain precision drops significantly in specialized industries (0.58 in finance, 0.55 in automotive)

## Confidence

- **High confidence**: Extraction accuracy metrics (BERTScore 0.92, BLEURT 0.89) and clustering coherence (AMI 0.67) are well-supported by systematic comparisons to baselines
- **Medium confidence**: Cross-domain generalization claims, demonstrated on limited out-of-domain samples without fine-tuning
- **Low confidence**: Operational deployment guidance, particularly regarding computational costs at scale and real-world performance variability

## Next Checks

1. Run classifier ablation test with and without PR surrogate loss on your domain data to verify the claimed 3.49% recall improvement
2. Test the trained classifier on a held-out domain sample to measure precision degradation and determine if domain-adaptive fine-tuning is needed
3. Compare LLM-based clustering vs SBERT+HDBSCAN on a 100-suggestion sample from your domain, having experts rate cluster interpretability to validate the paper's clustering claims for your use case