---
ver: rpa2
title: 'RECALL-MM: A Multimodal Dataset of Consumer Product Recalls for Risk Analysis
  using Computational Methods and Large Language Models'
arxiv_id: '2503.23213'
source_url: https://arxiv.org/abs/2503.23213
tags:
- product
- recall
- design
- hazard
- hazards
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops RECALL-MM, a multimodal dataset of 6,874 consumer
  product recalls (2000-2024) from the CPSC database, augmented with LLM-generated
  classifications and visual descriptions. The dataset captures over 546 million affected
  SKUs and enables data-driven risk assessment in engineering design.
---

# RECALL-MM: A Multimodal Dataset of Consumer Product Recalls for Risk Analysis using Computational Methods and Large Language Models

## Quick Facts
- arXiv ID: 2503.23213
- Source URL: https://arxiv.org/abs/2503.23213
- Reference count: 40
- Primary result: LLM-augmented multimodal recall dataset enabling data-driven risk assessment with visual hazard prediction (RA=0.73)

## Executive Summary
This study introduces RECALL-MM, a comprehensive multimodal dataset of 6,874 consumer product recalls (2000-2024) from the US Consumer Product Safety Commission database. The dataset is augmented with LLM-generated classifications and visual descriptions, capturing over 546 million affected SKUs. Through three case studies, the authors demonstrate practical applications including embedding-based pattern discovery, 3D visualization of recall landscapes, and LLM-based hazard prediction from product images. The work provides a scalable framework for integrating historical recall data into safer engineering design processes while highlighting both the potential and limitations of automated hazard assessment.

## Method Summary
The authors constructed RECALL-MM by fetching CPSC recall data (2000-2024) via API, filtering for entries with product images, and standardizing to a 9-field schema. GPT-4o was used to refine recall descriptions, generate visual_product_description from images, and classify entries into predefined product categories, hazard types, and remedy classifications. Human validation established ground truth through majority voting across three annotators, achieving Cohen's Kappa scores of 0.82-0.91. Text embeddings were generated using sentence-transformers/all-MiniLM-L6-v2, visualized via t-SNE dimensionality reduction, and used to evaluate LLM-based hazard prediction through a relaxed accuracy metric that accounts for multi-label scenarios.

## Key Results
- Fire, falling, and choking hazards dominate the recall landscape, with home appliances and toys showing highest recall frequencies
- Embedding recall descriptions reveals cross-domain hazard patterns, with baby products and sports recreation showing semantic overlap
- LLM-based hazard prediction from visual descriptions achieves 0.73 relaxed accuracy overall, but drops to 0.32 for non-visible hazards like poisoning
- 3D visualization of recall data enables product designers to situate new ideas within the historical recall landscape

## Why This Works (Mechanism)

### Mechanism 1: Semantic Embedding for Pattern Discovery
- Claim: Text embeddings of recall descriptions can reveal hazard patterns that transcend predefined product categories
- Mechanism: Sentence-BERT (all-MiniLM-L6-v2) encodes recall descriptions into dense vectors preserving semantic similarity. t-SNE then projects these into 2D/3D space where similar failure modes cluster together, enabling visualization of cross-domain hazard relationships
- Core assumption: Semantic similarity in recall text correlates with similar underlying failure modes
- Evidence anchors: "embedding recall descriptions to uncover hazard patterns" [abstract]; "all-MiniLM-L6-v2 model... generates fixed-length dense vector representations optimized for capturing semantic similarity" [section 3.2.1]; "Fig. 5b highlights a case where recall descriptions from different domains show considerable overlap... baby_products and sports_recreation share similarities in recall descriptions" [section 4.2.1]
- Break condition: When textual descriptions are misleading, sparse, or don't capture the true physical failure mode (e.g., latent material defects)

### Mechanism 2: LLM-Based Visual Hazard Prediction
- Claim: LLMs can predict hazards from visual product descriptions with moderate accuracy, but performance varies significantly by hazard type
- Mechanism: GPT-4o generates textual descriptions from product images, then predicts hazards based on learned visual-hazard associations. The Relaxed Accuracy (RA) metric evaluates whether the ground truth hazard appears within the predicted set
- Core assumption: Observable product features correlate with hazard types; visual inspection alone is sufficient for some hazard categories
- Evidence anchors: "LLM-based hazard prediction from product images, achieving a relaxed accuracy of 0.73 across hazard categories" [abstract]; "choking (0.93) and crash (0.91) hazards... poisoning hazard class yields the lowest RA score of 0.32" [section 4.2.3]; "certain hazards, like poisoning, may not be visually apparent and thus are underrepresented in LLM predictions" [section 4.2.3]
- Break condition: Non-visible hazards (poisoning, chemical contamination, latent electrical faults) cannot be reliably predicted from visual inspection alone

### Mechanism 3: Data Augmentation via LLM Classification
- Claim: LLM-generated classifications can reliably structure unstructured recall data when validated against human annotators
- Mechanism: GPT-4o assigns product categories, hazard types, and remedy classifications from predefined schemas. Human validation establishes ground truth through majority voting across three annotators
- Core assumption: LLM classification outputs can achieve near-human consistency when schemas are well-defined
- Evidence anchors: "Cohen's Kappa... almost perfect agreement across all three classification tasks, with coefficients of 0.82 for product classification, 0.91 for hazard classification, and 0.90 for remedies classification" [section 4.1]; "GPT-4o outputs were validated against this schema, with type and value constraints applied" [section 3.1]
- Break condition: When LLM training data lacks coverage of niche product categories or emerging hazard types not in the predefined schema

## Foundational Learning

- Concept: Sentence Embeddings (SBERT)
  - Why needed here: Core to visualizing recall patterns and enabling similarity search across 6,874 products
  - Quick check question: Can you explain why dense embeddings preserve semantic similarity better than bag-of-words representations for recall text?

- Concept: t-SNE Dimensionality Reduction
  - Why needed here: Required for projecting high-dimensional embeddings into interpretable 2D/3D visualizations that reveal clusters
  - Quick check question: Why does t-SNE preserve local structure better than PCA, and what tradeoffs does this introduce?

- Concept: Relaxed Accuracy Metric
  - Why needed here: Handles multi-label prediction evaluation when ground truth provides only single labels per entry
  - Quick check question: Why is this metric appropriate when the model may predict multiple valid hazards that weren't recorded in the original recall data?

## Architecture Onboarding

- Component map: CPSC API -> date/image filtering -> 6,874 entries -> GPT-4o augmentation -> 9-field structured records -> Sentence-BERT embedding -> t-SNE visualization -> LLM hazard prediction

- Critical path:
  1. Data curation: Filter CPSC data (2000-2024, API-accessible, has images)
  2. LLM augmentation: Generate classifications + visual descriptions via GPT-4o
  3. Human validation: 3 annotators Ã— 100 samples per classification task, compute Cohen's Kappa
  4. Embedding: Encode text fields using all-MiniLM-L6-v2
  5. Visualization: Apply t-SNE for 2D/3D projections
  6. Evaluation: Compute Relaxed Accuracy for hazard predictions

- Design tradeoffs:
  - Model size: all-MiniLM-L6-v2 chosen for efficiency; larger models may improve embedding quality
  - Visualization: t-SNE preserves local structure well but distorts global relationships vs. UMAP
  - Single-label ground truth: Recall data provides one hazard per entry, but products may have multiple concurrent hazards (addressed via RA metric)

- Failure signatures:
  - Non-visible hazards (poisoning: 0.32 RA) indicate visual-only prediction is insufficient
  - Convex hull analysis shows toys_children has highest diversity (11.85 normalized area), suggesting heterogeneous risk profiles
  - Temporal peak ~2005 with post-2020 uptick may reflect external factors (regulation, supply chain)

- First 3 experiments:
  1. Compare embedding models: Benchmark all-MiniLM-L6-v2 vs. larger SBERT variants using clustering coherence metrics (e.g., Silhouette score on hazard classes)
  2. Isolate visual contribution: Test hazard prediction using raw images with a Vision-Language Model vs. text descriptions to quantify information loss
  3. Expand ground truth: Annotate a subset with multi-label hazards to evaluate whether RA metric conceals false positive overprediction

## Open Questions the Paper Calls Out

- Can recall-informed tools be effectively integrated into real-world engineering design workflows? [explicit] The authors state that "validating their effectiveness in real-world design and safety processes remains an open opportunity" requiring engagement with industry practitioners. Why unresolved: The current work demonstrates technical feasibility on static historical data but lacks validation of usability or impact in live design environments. What evidence would resolve it: User studies with industry practitioners measuring where they derive value and how the tools alter design outcomes.

- Do visual cues provide stronger signals than textual descriptions for automated hazard prediction? [explicit] The paper suggests future studies could use Visual Language Models (VLMs) to "determine whether visual or textual cues provide stronger signals." Why unresolved: Case Study 3 analyzed textual descriptions of images rather than comparing direct image analysis against text-based predictions. What evidence would resolve it: A comparative benchmark evaluating VLM performance (direct image input) against text-only LLM predictions on the dataset.

- How can automated hazard prediction be improved for non-visible risks like chemical poisoning? [explicit] Results highlight the model's failure to predict "poisoning" (Relaxed Accuracy 0.32) and note the limitation that "certain hazards... may not be visually apparent." Why unresolved: Visual inspection and generated descriptions often fail to capture latent hazards such as chemical composition or internal material properties. What evidence would resolve it: A multimodal approach integrating material specifications or safety data sheets (SDS) into the prediction pipeline.

- Do hazard patterns generalize across international regulatory environments? [explicit] The authors propose augmenting the CPSC dataset with OECD Global Recalls data to facilitate "comparative studies across regulatory environments and cultural contexts." Why unresolved: The current dataset is restricted to US recalls, potentially missing global trends or region-specific failure modes. What evidence would resolve it: Cross-national analysis comparing the RECALL-MM dataset against global recall data to identify convergent or divergent hazard trends.

## Limitations

- Visual-only hazard prediction performs poorly for non-visible risks (poisoning: 0.32 RA), indicating fundamental limitations for chemical and latent hazards
- Single-label ground truth constraint means actual hazard co-occurrence is underrepresented, potentially masking real-world risk complexity
- Unspecified t-SNE hyperparameters and GPT-4o prompt configurations may affect reproducibility of reported visualizations and predictions

## Confidence

- **High Confidence**: Dataset construction methodology (6,874 entries, 546M SKUs), human validation of LLM classifications (Cohen's Kappa 0.82-0.91), and identification of fire/falling/choking as top hazards
- **Medium Confidence**: Semantic embedding patterns and cross-domain hazard relationships, as these depend on t-SNE parameterization and interpretation
- **Low Confidence**: LLM-based visual hazard prediction for non-visible hazards (poisoning, electrical), given RA scores below 0.40 suggest unreliable performance

## Next Checks

1. Replicate hazard prediction using raw product images with a vision-language model to quantify information loss from text-only descriptions
2. Annotate a subset of recalls with multi-label hazards to evaluate whether relaxed accuracy metric masks systematic under-prediction of concurrent risks
3. Benchmark alternative embedding models (e.g., all-MiniLM-L12-v2) using clustering coherence metrics to assess sensitivity to model choice