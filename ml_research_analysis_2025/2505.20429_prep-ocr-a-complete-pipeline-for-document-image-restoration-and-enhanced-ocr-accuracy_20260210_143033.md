---
ver: rpa2
title: 'PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced
  OCR Accuracy'
arxiv_id: '2505.20429'
source_url: https://arxiv.org/abs/2505.20429
tags:
- image
- text
- pages
- images
- restoration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PreP-OCR is a two-stage pipeline combining document image restoration
  with semantic-aware post-OCR correction to enhance text extraction from degraded
  historical documents. It synthesizes training data by rendering clean text with
  diverse fonts and layouts, then applying randomized degradation operations.
---

# PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy

## Quick Facts
- **arXiv ID:** 2505.20429
- **Source URL:** https://arxiv.org/abs/2505.20429
- **Reference count:** 26
- **Primary result:** Reduces character error rates by 63.9-70.3% on 13,831 pages of historical documents

## Executive Summary
PreP-OCR is a two-stage pipeline that combines document image restoration with semantic-aware post-OCR correction to enhance text extraction from degraded historical documents. It synthesizes training data by rendering clean text with diverse fonts and layouts, then applying randomized degradation operations. An image restoration model trained on this synthetic data uses multi-directional patch extraction and fusion to process large images. A ByT5 post-OCR model, fine-tuned on synthetic historical text pairs, corrects remaining OCR errors. Experiments on 13,831 pages of historical documents in English, French, and Spanish show the pipeline reduces character error rates by 63.9-70.3% compared to OCR on raw images.

## Method Summary
PreP-OCR employs a two-stage approach to enhance OCR accuracy on degraded historical documents. First, it uses a synthetic data generation pipeline to create paired clean and degraded document images, simulating realistic degradation through randomized sequences of blurs, stains, and morphological operations. A diffusion-based restoration model (ResShift) is trained on these synthetic pairs and processes large images through multi-directional patch extraction with median fusion to suppress artifacts. Second, a ByT5-based post-OCR correction model addresses residual character-level errors, fine-tuned on synthetic text pairs with errors injected based on real OCR mistake distributions.

## Key Results
- Reduces character error rates by 63.9-70.3% on 13,831 pages of historical documents
- Achieves optimal CER reduction of 70.3% when using the ByT5 corrector with multi-directional patch fusion
- Outperforms alternative restoration models (DiffIR) in terms of OCR accuracy despite lower pixel-level PSNR metrics

## Why This Works (Mechanism)

### Mechanism 1
Training an image restoration model on synthetically degraded document pairs enables generalization to real historical documents without requiring ground-truth clean images for the target domain. The pipeline renders clean text with diverse fonts and layouts, then applies a randomized sequence of degradation operations (noise, blur, stains, morphological changes). A diffusion-based model (ResShift) learns to map these degraded synthetic instances back to their clean source, creating a robust inverse function for visual artifacts.

**Core assumption:** The distribution of synthetic degradation sufficiently approximates the manifold of real-world historical damage.

**Evidence anchors:** Synthetic data generation method that simulates realistic document degradation with operations applied in random order.

**Break condition:** If real documents contain degradation types outside the synthetic parameter space, the restoration model may fail or hallucinate structure.

### Mechanism 2
Multi-directional patch extraction followed by median fusion suppresses boundary artifacts and stochastic noise inherent in patch-based image processing. Large images are scanned in four directions. The model restores overlapping patches, discards the high-error border regions, and retains the center. The final pixel value is the median of the four predictions from different scanning passes.

**Core assumption:** Restoration errors are spatially correlated or stochastic, meaning the "true" signal is the consistent value across different views while errors are outliers.

**Evidence anchors:** Uses multi-directional patch extraction and fusion to process large images, consolidating consistent pixel values while suppressing outlier predictions.

**Break condition:** If the model produces identical, systematic hallucinations in all four scanning directions, the median operation will preserve the error rather than discard it.

### Mechanism 3
A byte-level sequence-to-sequence model (ByT5) corrects residual semantic and character-level errors that persist after visual restoration, particularly for traditional OCR engines. The post-OCR module is fine-tuned on synthetic text pairs where errors are injected into clean text based on statistical distributions derived from real OCR mistakes. ByT5 processes raw bytes, allowing it to handle rare historical characters without an out-of-vocabulary token issue.

**Core assumption:** OCR errors are systematic and linguistically recoverable, meaning the surrounding context provides sufficient signal to distinguish between visually similar but semantically distinct character sequences.

**Evidence anchors:** Addresses remaining OCR errors, with CER dropping significantly for Tesseract outputs while GPT-4o's CER generally increases due to hallucinations.

**Break condition:** If the input text contains unconventional character forms or errors that span contexts longer than the model's window, correction may fail.

## Foundational Learning

**Concept: Diffusion Models for Image Restoration (ResShift)**
*Why needed:* The paper selects ResShift as the restoration backbone over GANs or standard Transformers. Understanding that it predicts the "residual" between degraded and clean images is key to debugging visual output.
*Quick check:* Does the model predict the clean image directly, or does it predict the noise/residual to be added to the degraded input?

**Concept: Byte-Level Tokenization (ByT5)**
*Why needed:* Historical documents often contain archaic symbols or glyphs missing from standard vocabularies. ByT5 tokenizes text into bytes (256 possible tokens) rather than words or sub-words, ensuring no character is unknown.
*Quick check:* Why would a BPE-based tokenizer struggle with a rare 15th-century ligature compared to a byte-level model?

**Concept: Character Error Rate (CER) & Alignment (RETAS)**
*Why needed:* The paper relies on CER to prove the 63-70% improvement. You must understand that evaluating OCR requires aligning the predicted stream to the ground truth stream to count insertions, deletions, and substitutions.
*Quick check:* If an OCR system skips an entire paragraph, how does CER penalize this compared to Word Error Rate (WER)?

## Architecture Onboarding

**Component map:** Synthetic Generator -> Restoration Backbone (ResShift) -> Fusion Layer -> OCR Engine -> Correction Head (ByT5)

**Critical path:** Real Image -> Resize to 1216px width -> Multi-direction Patch Extraction (256x256) -> ResShift Restoration -> Median Fusion -> Tesseract OCR -> ByT5 Correction -> Final Text

**Design tradeoffs:**
- **ResShift vs. DiffIR:** ResShift is chosen despite DiffIR having higher Aggregated Masked PSNR on synthetic tests. ResShift yielded better OCR accuracy, suggesting pixel-perfect reconstruction is less important than legibility for OCR.
- **Tesseract vs. LLM-OCR:** The paper recommends Tesseract for the pipeline. While GPT-4o performs better on raw images, its tendency to hallucinate makes it incompatible with the Post-OCR corrector, which assumes "character-level errors" rather than "fabricated facts."
- **Fusion Cost:** Multi-direction median fusion quadruples inference time (11.3s -> 45s) but is required to suppress artifacts.

**Failure signatures:**
- **Ink Bleeding/Shadows:** The restoration model may interpret ink shadows from the reverse page as text glyphs.
- **LLM Hallucination Loop:** If GPT-4o is used, the post-corrector may increase CER because it is trained to fix spelling, not remove semantically plausible but factually false hallucinations.
- **Font Uniqueness:** Unconventional fonts not present in the 1,060-font synthetic training set may fail to restore.

**First 3 experiments:**
1. **Synthetic Validation:** Train ResShift on the synthetic set. Verify that "Central-128" PSNR is higher than "Full Patch" PSNR to confirm the border-effect hypothesis before running full fusion.
2. **Ablation on Fusion:** Run a degraded page through Single-Median vs. Multi-Median fusion. Visually inspect for boundary lines and log the time cost to validate the tradeoff.
3. **Correction Generalization:** Take the trained ByT5 model and run it on raw Tesseract output (no image restoration) vs. restored output. Quantify how much of the 63% error reduction comes from visual restoration vs. textual correction.

## Open Questions the Paper Calls Out

### Open Question 1
Can the PreP-OCR pipeline be effectively adapted for non-Latin writing systems, such as Cyrillic, Arabic, or East Asian scripts?
*Basis in paper:* The authors state in the Limitations section that "performance on non-Latin writing systems (e.g., Cyrillic, Arabic, or East Asian scripts) remains untested."
*Why unresolved:* The current experiments and synthetic data generation were restricted to English, French, and Spanish, leaving the pipeline's efficacy on character sets with different morphological structures unknown.
*What evidence would resolve it:* Evaluation of the pipeline on a dataset of degraded historical documents in a non-Latin language using synthetic training data generated for that specific script.

### Open Question 2
How can the post-OCR correction module be modified to effectively handle the unique error patterns and "hallucinations" produced by LLM-based OCR engines?
*Basis in paper:* The paper notes that the post-OCR correction module "assumes error distributions derived from traditional OCR systems," and observes that applying it to GPT-4o outputs actually increased CER because hallucinations "evade detection by the correction model."
*Why unresolved:* The current ByT5 model is trained on character-level noise typical of traditional OCR, rendering it ineffective—or even harmful—when applied to the semantically plausible but factually incorrect text generated by LLMs.
*What evidence would resolve it:* Development of a post-OCR training regime that simulates semantic hallucinations and layout errors, followed by a demonstration of reduced CER on LLM-based OCR outputs.

### Open Question 3
To what extent does the inclusion of specific fonts in the synthetic training data limit the restoration of documents with highly unconventional or unseen typefaces?
*Basis in paper:* The authors acknowledge that "restoration capability for text is likely dependent on the fonts included in the synthetic training data, and may not adequately restore images containing highly unconventional character forms."
*Why unresolved:* While the method uses diverse fonts, it is unclear if the model generalizes to rare historical typefaces that differ geometrically from the standard fonts used in the synthetic rendering process.
*What evidence would resolve it:* A comparative analysis of restoration quality on documents using rare typefaces excluded from the synthetic font list versus those included, potentially measuring the drop in PSNR or CER.

## Limitations

- The synthetic degradation model's ability to generalize to real historical document damage remains unverified without paired real-degraded/clean document data for validation.
- The multi-directional patch fusion approach increases inference time fourfold (11.3s → 45s), creating a significant computational tradeoff that may limit practical deployment.
- The post-OCR correction model's effectiveness is constrained by its assumption that OCR errors are systematic and contextually recoverable, potentially failing on unconventional character forms or long-range contextual errors.

## Confidence

- **High Confidence:** The 63.9-70.3% CER reduction is empirically validated on the 13,831-page historical document dataset across three languages.
- **Medium Confidence:** The claim that ResShift outperforms DiffIR for OCR accuracy despite lower synthetic PSNR metrics requires further validation.
- **Low Confidence:** The assertion that synthetic degradation distributions fully capture real-world historical document damage patterns cannot be independently verified without access to paired real degraded/clean document datasets.

## Next Checks

1. **Real-Domain Degradation Transfer Test:** Acquire a small set of paired real degraded/clean historical document pages or conduct a human evaluation study where restoration experts assess whether synthetic-degraded synthetic-clean pairs capture the complexity of real document damage patterns.

2. **Computational Efficiency Benchmark:** Profile the full pipeline on varying document sizes and hardware configurations to quantify the exact cost-benefit tradeoff of the multi-directional fusion approach versus single-direction processing.

3. **Correction Robustness Evaluation:** Test the ByT5 post-correction model on OCR outputs containing unconventional historical character forms and long-range contextual errors to measure its failure modes and establish clear operational boundaries.