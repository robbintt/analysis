---
ver: rpa2
title: Estimating Commonsense Plausibility through Semantic Shifts
arxiv_id: '2502.13464'
source_url: https://arxiv.org/abs/2502.13464
tags:
- commonsense
- compass
- plausibility
- language
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ComPaSS, a discriminative framework for commonsense
  plausibility estimation that measures semantic shifts when augmenting sentences
  with commonsense-related information. Unlike generative approaches that rely on
  likelihoods or verbalized judgments, ComPaSS quantifies plausibility by computing
  similarity between embeddings of original sentences and their commonsense-augmented
  counterparts, with plausible augmentations inducing minimal semantic shifts.
---

# Estimating Commonsense Plausibility through Semantic Shifts

## Quick Facts
- **arXiv ID**: 2502.13464
- **Source URL**: https://arxiv.org/abs/2502.13464
- **Reference count**: 28
- **Primary result**: Discriminative framework ComPaSS outperforms generative baselines on commonsense plausibility estimation through semantic shift measurement.

## Executive Summary
This paper introduces ComPaSS, a discriminative framework for estimating commonsense plausibility by measuring semantic shifts when augmenting sentences with commonsense-related information. Unlike generative approaches that rely on likelihoods or verbalized judgments, ComPaSS quantifies plausibility by computing similarity between embeddings of original sentences and their commonsense-augmented counterparts. The framework consistently outperforms baseline generative methods across multiple backbones including LLMs and VLMs, with particular strength in vision-grounded commonsense tasks where VLMs mitigate reporting bias inherent in text-only models.

## Method Summary
ComPaSS estimates commonsense plausibility through a discriminative approach that constructs anchor sentences (base context without commonsense details) and candidate sentences (augmented with the detail being evaluated). Both sentences are encoded using backbone models (LM or VLM), and similarity is computed via cosine similarity or dot product. Higher similarity indicates the augmentation is consistent with commonsense knowledge and thus produces smaller semantic deviation. The framework supports both template-based construction for structured inputs and GPT-4 for free-form questions. Performance is enhanced through contrastive pre-training, which sharpens semantic discriminability in embedding space.

## Key Results
- ComPaSS consistently outperforms baseline generative methods on commonsense plausibility tasks across multiple backbones
- VLMs achieve superior performance on vision-grounded commonsense tasks by mitigating reporting bias
- Contrastive pre-training significantly enhances performance by sharpening models' ability to capture semantic nuances
- Encoder-based models with millions of parameters achieve comparable or superior results to much larger decoder-only models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Plausible commonsense augmentations induce minimal semantic shifts in embedding space.
- Mechanism: ComPaSS constructs anchor and candidate sentences, then computes embedding similarity. Higher similarity indicates the augmentation is consistent with commonsense knowledge.
- Core assumption: Sentence embeddings encode commonsense knowledge such that implausible additions shift representations more substantially than plausible ones.
- Evidence anchors: [abstract] "Plausible augmentations induce minimal shifts in semantics, while implausible ones result in substantial deviations."
- Break condition: If embeddings do not reliably encode commonsense information (e.g., for rare or culturally-specific knowledge), semantic shifts may not correlate with plausibility.

### Mechanism 2
- Claim: Contrastive pre-training improves ComPaSS by sharpening semantic discriminability in embedding space.
- Mechanism: Contrastive learning trains models to distinguish semantically similar from dissimilar instances, producing embeddings with sharper separability.
- Core assumption: The improved discriminability from contrastive learning transfers to commonsense plausibility distinctions.
- Evidence anchors: [abstract] "contrastive pre-training sharpens backbone models' ability to capture semantic nuances, thereby further enhancing ComPaSS."
- Break condition: Contrastive pre-training on non-commonsense objectives may not transfer; domain mismatch could reduce benefits.

### Mechanism 3
- Claim: VLMs outperform text-only LMs on vision-grounded commonsense tasks by mitigating reporting bias.
- Mechanism: Text corpora underrepresent visually obvious attributes, causing LMs to learn skewed distributions. VLMs trained on image-text pairs receive explicit visual grounding for these attributes.
- Core assumption: Visual information encodes commonsense attributes more reliably than text alone for visually-perceivable properties.
- Evidence anchors: [abstract] "VLMs yield superior performance to LMs, when integrated with ComPaSS, on vision-grounded commonsense tasks."
- Break condition: For non-visual commonsense (abstract reasoning, causal chains), VLM advantages may diminish or disappear.

## Foundational Learning

- **Concept**: Semantic embeddings and cosine similarity
  - Why needed here: ComPaSS relies entirely on comparing sentence embeddings; understanding how similarity captures semantic relatedness is essential for interpreting results.
  - Quick check question: Can you explain why cosine similarity is preferred over Euclidean distance for comparing embeddings of different-length sentences?

- **Concept**: Reporting bias in language corpora
  - Why needed here: Understanding why LMs fail on "obvious" commonsense (e.g., penguin color) motivates the VLM approach and helps diagnose failures.
  - Quick check question: Why might "black sheep" appear more frequently in text than "white sheep" despite white sheep being more common in reality?

- **Concept**: Contrastive learning objectives
  - Why needed here: The paper's results hinge on contrastive pre-training improving performance; understanding what this training does to embedding space explains why it helps.
  - Quick check question: What property do contrastive learning objectives enforce in the embedding space that would help distinguish plausible from implausible augmentations?

## Architecture Onboarding

- **Component map**: Sentence Constructor -> Encoder -> Similarity Scorer -> Ranker
- **Critical path**: Sentence construction quality -> encoder choice (contrastive-pretrained VLM for visual commonsense, contrastive-pretrained LM for general) -> similarity computation
- **Design tradeoffs**:
  - VLM vs LM: VLMs better for visual attributes but require image-text pre-training data; LMs more general but suffer reporting bias
  - Template vs GPT-4 construction: Templates are deterministic and fast; GPT-4 handles free-form inputs but adds API cost and variability
  - Single template vs ensemble: Ensemble improves LLM results (score-level averaging recommended) but adds computation; VLMs benefit less from ensembling
  - Encoder-only vs decoder-only: Encoder models are parameter-efficient (millions vs billions); decoders offer flexibility but require PromptReps for good embeddings without contrastive training
- **Failure signatures**:
  - Vanilla models without contrastive pre-training performing near or below baseline likelihood methods
  - Verbalization methods producing inconsistent rankings even with capable LLMs
  - LM likelihood methods overestimating idiomatic collocations (e.g., "black sheep" problem)
  - Score degradation on non-visual commonsense when using VLMs
- **First 3 experiments**:
  1. Reproduce the reporting bias case study: Apply ComPaSS with both CLIP and a text-only LM to the sheep color ranking task. Verify that CLIP correctly ranks "white" higher while the LM overestimates "black."
  2. Ablate contrastive pre-training: Compare vanilla RoBERTa vs. SimCSE-RoBERTa on the CoDa dataset using identical templates. Expect substantial performance drop without contrastive learning.
  3. Test template sensitivity: For a single LM backbone, compare word-level collocation vs. sentence-level template performance on ViComTe. Sentence-level should consistently outperform word-level.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can calibration techniques be developed to enable ComPaSS to make absolute pointwise plausibility judgments rather than only comparative assessments?
- **Open Question 2**: Can template generation for sentence construction be automated to improve generalization across diverse commonsense tasks?
- **Open Question 3**: How does ComPaSS perform on non-visual commonsense domains such as causal reasoning, social norms, or temporal knowledge?
- **Open Question 4**: How can inherited biases from backbone LLMs and VLMs be identified and mitigated in ComPaSS's plausibility rankings?

## Limitations
- Framework's effectiveness depends critically on quality of sentence constructorâ€”poor templates or verbalization can undermine even strong backbone models
- GPT-4-based approach for free-form inputs introduces variability that may not generalize to all domains
- Computational efficiency claims comparing millions vs billions of parameters don't account for inference costs of different model types

## Confidence

- **High Confidence**: Semantic shift principle, VLM advantage on visual attributes, template sensitivity findings
- **Medium Confidence**: Contrastive pre-training benefits, parameter efficiency claims, GPT-4 verbalization effectiveness
- **Low Confidence**: Performance on non-visual commonsense domains, generalization to out-of-domain commonsense knowledge, long-term stability of ranking consistency

## Next Checks
1. **Domain Generalization Test**: Apply ComPaSS to abstract commonsense tasks (causal reasoning, social inference) where visual grounding is irrelevant. Measure whether VLM advantages persist or whether LM performance catches up, revealing the true scope of the visual commonsense benefit.
2. **Cross-Corpus Robustness**: Evaluate ComPaSS on multiple commonsense benchmarks beyond the three tested datasets. Compare performance consistency across domains with varying commonsense distributions to validate the framework's generality.
3. **Reporting Bias Aversion**: Design controlled experiments testing whether ComPaSS with VLMs systematically corrects for reporting bias across different visual attribute types. Use datasets where ground truth distributions are known to differ from text frequency to quantitatively measure bias correction.