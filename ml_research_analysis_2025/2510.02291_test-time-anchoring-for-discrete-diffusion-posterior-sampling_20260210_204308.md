---
ver: rpa2
title: Test-Time Anchoring for Discrete Diffusion Posterior Sampling
arxiv_id: '2510.02291'
source_url: https://arxiv.org/abs/2510.02291
tags:
- diffusion
- posterior
- sampling
- discrete
- anchored
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Anchored Posterior Sampling (APS), a training-free
  method for solving inverse problems using pretrained discrete diffusion models.
  The key challenge is guiding the reverse diffusion process to match noisy measurements
  without retraining the model.
---

# Test-Time Anchoring for Discrete Diffusion Posterior Sampling

## Quick Facts
- **arXiv ID:** 2510.02291
- **Source URL:** https://arxiv.org/abs/2510.02291
- **Reference count:** 40
- **Primary result:** Introduces Anchored Posterior Sampling (APS), achieving state-of-the-art results among discrete diffusion samplers on inverse problems while requiring no retraining

## Executive Summary
This paper addresses the challenge of posterior sampling for inverse problems using pretrained discrete diffusion models without retraining. The key innovation is a two-stage test-time optimization approach: quantized expectation for gradient-like updates in discrete embedding space, and anchored remasking for adaptive token unmasking. On linear and nonlinear inverse problems, APS achieves state-of-the-art performance among discrete diffusion samplers, often outperforming continuous baselines while using 66× fewer steps.

## Method Summary
APS operates on pretrained masked discrete diffusion models by freezing the backbone and optimizing lightweight logits at test time. The method combines quantized expectation (computing expected embeddings and using straight-through estimation for gradients) with anchored remasking (selecting high-confidence tokens from posterior estimates for early unmasking). This enables efficient posterior sampling for inverse problems like super-resolution, deblurring, HDR, and stylization without the computational cost of exact MCMC methods. The approach achieves strong results by leveraging pretrained generative priors while incorporating measurement consistency through variational bounds.

## Key Results
- On FFHQ super-resolution, APS improves PSNR by 4.74% and LPIPS by 7.16% over prior discrete methods
- Achieves state-of-the-art performance among discrete diffusion samplers on linear (super-resolution, deblurring) and nonlinear (HDR, stylization) inverse problems
- Uses only 15 diffusion steps (66× fewer than continuous methods) while maintaining competitive quality
- Demonstrates successful generalization to text-guided image editing and diffusion language models

## Why This Works (Mechanism)

### Mechanism 1: Quantized Expectation
- **Claim:** Enables gradient-like guidance in discrete token space by computing expected embeddings over the codebook
- **Core assumption:** Measurement operator composed with decoder is locally smooth enough that expected embedding provides reasonable surrogate
- **Evidence:** Abstract mentions "gradient-like updates in discrete embedding space"; §3.1 introduces quantized expectation to approximate measurement term; Split Gibbs Discrete Diffusion (arXiv:2503.01161) uses split Gibbs samplers as alternative
- **Break condition:** Poorly structured codebook or highly non-smooth measurement operator causes gradient guidance to fail

### Mechanism 2: Anchored Remasking
- **Claim:** Improves decoding by selecting tokens based on posterior confidence rather than prior confidence
- **Core assumption:** Joint posterior encodes cross-token dependencies that identify semantically important positions better than independent prior confidence
- **Evidence:** Abstract mentions "adaptively unmasks important tokens early"; §3.2 explains leveraging joint posterior to identify anchor tokens; §C.3.1 shows standard remasking favors background regions
- **Break condition:** Posterior optimization diverges or threshold schedule poorly tuned, causing wrong tokens to be anchored

### Mechanism 3: Variational Bound Decomposition
- **Claim:** Enables test-time optimization without backpropagating through large denoiser
- **Core assumption:** Pretrained model closely approximates unconditional prior; adaptation gap is bounded
- **Evidence:** §3 Theorem 3.3 provides full derivation of test-time bound; §3 Implication 3.4 states test-time training only updates lightweight terms
- **Break condition:** Weak pretrained prior (poor domain coverage) causes loose bound and non-convergent adapted posterior

## Foundational Learning

- **Masked Discrete Diffusion:** Forward process gradually replaces tokens with `[MASK]`; reverse process learns to predict categorical distributions. State space is $S = V^L$ where $V = \{1, ..., K, K+1\}$ includes mask token.
  - *Why needed:* APS operates on masked diffusion models; understanding forward/reverse dynamics is essential
  - *Quick check:* Given forward transition $q(z_t^l|x) = \text{Cat}(\alpha_t x_l + (1-\alpha_t) m)$, what happens as $t \to 1$?

- **Inverse Problems and Posterior Sampling:** Goal is to sample from $p(x|y) \propto p(y|x)p(x)$ where $y = A(D(x)) + \sigma\epsilon$. Requires balancing prior (generative quality) with likelihood (measurement consistency).
  - *Why needed:* APS is a method for solving inverse problems; entire formulation assumes Bayesian framing
  - *Quick check:* Why is exact posterior sampling intractable for high-dimensional discrete spaces?

- **VQ-VAE and Lookup-Free Quantization (LFQ):** Encoder produces embeddings $e \in \mathbb{R}^{L \times d}$ which are quantized to nearest codebook entries. LFQ uses binary codebooks with $\text{sign}(e)$ for quantization, avoiding learned codebooks.
  - *Why needed:* APS relies on token embedding structure; straight-through estimator applied to LFQ quantization
  - *Quick check:* Why does LFQ with binary embeddings avoid vocabulary size degradation issue?

## Architecture Onboarding

- **Component map:** Pretrained denoiser $x_\theta(z_t)$ -> Adaptation logits $\phi_t^{(i)}$ -> LFQ quantizer -> Decoder $D(\cdot)$ -> Measurement operator $A(\cdot)$ -> Anchor selector

- **Critical path:**
  1. Initialize $z_1 \leftarrow \{m\}^L$ (all masked)
  2. For each timestep $t$ (cosine schedule, typically 15 steps):
     - **Stage 1 (Quantized Expectation):** Run $M=100$ Adam steps on loss $L = L_{recon} + \lambda_p L_{perceptual}$ with $\eta=1.0$
     - **Stage 2 (Anchored Remasking):** Compute posterior confidence, select anchors, update $z_s$
  3. Decode final $z_0$ via $D(\cdot)$

- **Design tradeoffs:**
  - Fewer diffusion steps ($T=15$) vs. quality: Trades asymptotic correctness for speed (66× fewer steps)
  - Perceptual loss weight $\lambda_p$: $10^{-3}$ balances LPIPS vs. PSNR; higher values distort structure
  - Optimization steps per timestep: Saturation at ~100 steps; diminishing returns beyond

- **Failure signatures:**
  - Over-smoothed outputs: Measurement operator misaligned with prior; try reducing $\lambda_p$
  - Artifacts in textured regions: Tokenizer reconstruction limits; requires better base tokenizer
  - Wrong semantic content: Standard remasking active; verify anchor selection uses posterior not prior
  - Divergence during optimization: Learning rate too high or loss weight imbalance

- **First 3 experiments:**
  1. **Sanity check on VQ-VAE reconstruction:** Feed ground truth through encoder → LFQ → decoder. Quality sets upper bound for APS.
  2. **Ablation of quantized expectation vs. direct sampling:** Compare APS-I (quantized expectation only) vs. baseline sampling.
  3. **Fixed vs. adaptive threshold schedule:** Test $\tau_t$ as fixed vs. cosine schedule.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can discrete diffusion posterior samplers achieve asymptotically exact samples while maintaining computational tractability, or is the variational approximation fundamental to scalability?
  - *Basis:* Paper states "our approach sacrifices asymptotic correctness in favor of scalable posterior inference"
  - *Unresolved:* Exact MCMC methods "remain computationally infeasible at scale" but bias introduced is not characterized
  - *Evidence needed:* Theoretical analysis of approximation gap; comparison against exact samplers on small-scale problems

- **Open Question 2:** How much of APS's performance gains are attributable to the specific tokenizer (MagVIT-v2 with LFQ) versus algorithmic innovations?
  - *Basis:* Limitations section notes "MMaDA uses MagVIT-v2 tokenizer which has limited reconstruction quality compared to modern visual tokenizers"
  - *Unresolved:* Only evaluates on one tokenizer; unclear if quantized expectation transfers to tokenizers with different codebook structures
  - *Evidence needed:* Ablation experiments applying APS to alternative tokenizers (e.g., FLUX, SD3.5)

- **Open Question 3:** Can anchored remasking schedules be learned or adapted online per-sample rather than using fixed cosine thresholds?
  - *Basis:* Anchored remasking uses cosine schedule adapted from MMaDA; token selection strategy critically impacts which tokens get unmasked early
  - *Unresolved:* Different inverse problems may benefit from different anchoring priorities; adaptive threshold is fixed rather than content-aware
  - *Evidence needed:* Experiments comparing fixed schedules against learned or measurement-conditioned threshold functions

## Limitations

- Relies on critical approximation that expected embedding is sufficient statistic for posterior inference over high-dimensional discrete token sequences
- Anchored remasking depends on well-tuned threshold schedule that is only vaguely specified as following "MMaDA's cosine schedule"
- Claims about generalization to text-guided editing and diffusion language models are mentioned but not empirically validated in main text

## Confidence

- **High confidence:** Claims about computational efficiency gains (66× fewer steps, linear vs. exponential complexity)
- **Medium confidence:** Claims about state-of-the-art performance on inverse problems (quantitative results but lack extensive ablation studies)
- **Low confidence:** Claims about generalization to text-guided editing and diffusion language models (not empirically validated)

## Next Checks

1. **Approximation error analysis:** Measure KL divergence between true posterior over token sequences and approximation induced by quantized expectation across varying codebook sizes and measurement operators.

2. **Anchor selection stability:** Evaluate anchor selection consistency across multiple optimization runs with different random seeds; compute overlap ratio of selected anchor positions and correlation between anchor stability and final output quality.

3. **Threshold schedule ablation:** Systematically vary anchored remasking threshold schedule (fixed vs. adaptive, different functional forms) and measure impact on PSNR/LPIPS across all benchmark tasks.