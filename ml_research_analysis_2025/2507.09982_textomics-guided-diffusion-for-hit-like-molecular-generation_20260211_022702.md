---
ver: rpa2
title: TextOmics-Guided Diffusion for Hit-like Molecular Generation
arxiv_id: '2507.09982'
source_url: https://arxiv.org/abs/2507.09982
tags:
- molecular
- molecules
- generation
- textual
- todi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of generating hit-like molecules
  with therapeutic potential by integrating omics data and molecular textual descriptions.
  The authors introduce TextOmics, a heterogeneous benchmark dataset that establishes
  one-to-one correspondences between omics expressions and molecular textual descriptions,
  and propose ToDi, a generative framework that leverages diffusion models conditioned
  on both modalities to produce biologically relevant, chemically valid molecules.
---

# TextOmics-Guided Diffusion for Hit-like Molecular Generation

## Quick Facts
- arXiv ID: 2507.09982
- Source URL: https://arxiv.org/abs/2507.09982
- Reference count: 40
- Primary result: ToDi achieves 100% validity, 98.45% uniqueness, 97.30% novelty, and improved structural similarity for hit-like molecular generation

## Executive Summary
This work addresses the challenge of generating hit-like molecules with therapeutic potential by integrating omics data and molecular textual descriptions. The authors introduce TextOmics, a heterogeneous benchmark dataset that establishes one-to-one correspondences between omics expressions and molecular textual descriptions, and propose ToDi, a generative framework that leverages diffusion models conditioned on both modalities to produce biologically relevant, chemically valid molecules. ToDi uses two encoders (OmicsEn and TextEn) to capture biological and semantic features, and a diffusion-based generator (DiffGen) for controllable molecular generation. Experiments show ToDi outperforms state-of-the-art baselines across multiple metrics, demonstrating strong performance in both omics- and text-guided settings, as well as in zero-shot therapeutic molecule generation.

## Method Summary
ToDi integrates omics expressions and molecular textual descriptions through a dual-encoder architecture. OmicsEn (VAE) encodes gene expression profiles into latent representations ZO capturing phenotype-level drug response features. TextEn (frozen SciBERT) extracts semantic embeddings ZD from molecular descriptions. DiffGen, a diffusion-based generator, produces molecular SELFIES representations conditioned on the joint Z representation, aiming to generate molecules that exhibit functional interactions with the corresponding induced omics expression. The model is trained with a combined loss function including reconstruction loss, negative log-likelihood for token correctness, and cosine alignment for biological relevance.

## Key Results
- ToDi achieves 100% validity, 98.45% uniqueness, 97.30% novelty, and improved structural similarity metrics compared to state-of-the-art baselines
- Ablation studies demonstrate the importance of both omics and textual guidance, with full ToDi outperforming omics-only or text-only variants
- Zero-shot therapeutic molecule generation on DiseaseSign dataset shows promise for rare disease applications
- Computational efficiency: trained on RTX 3090 with 1e-4 learning rate for all components

## Why This Works (Mechanism)

### Mechanism 1
- SELFIES serves as a syntactically robust bridging representation enabling one-to-one alignment between heterogeneous modalities (omics and text)
- Unlike SMILES, SELFIES embeds chemical valency rules directly into the string grammar, guaranteeing that every generated token sequence decodes to a valid molecular graph
- This eliminates the need for post-hoc validity filtering during diffusion-based generation

### Mechanism 2
- Dual-encoder conditioning provides complementary guidance signals—biological context from omics and semantic constraints from text—that jointly improve molecular relevance
- OmicsEn (VAE) encodes gene expression profiles into latent representations ZO capturing phenotype-level drug response features
- TextEn (frozen SciBERT) extracts semantic embeddings ZD from molecular descriptions, fused via cross-attention and broadcast concatenation

### Mechanism 3
- Conditional diffusion with token-level guidance enables controllable generation while maintaining distributional coverage of chemical space
- DiffGen performs reverse diffusion conditioned on joint Z representation, processing noisy SELFIES embeddings with cross-attention over ZD and concatenated ZO
- The training objective combines reconstruction loss, negative log-likelihood for token correctness, and cosine alignment for biological relevance

## Foundational Learning

- **VAE latent space and KL divergence regularization**: OmicsEn uses a VAE to compress 978-dimensional gene expression profiles into meaningful latent representations ZO. Understanding the evidence lower bound (ELBO) and the β-weighted KL term is essential for tuning the encoder-decoder balance. Quick check: Can you explain why increasing β in the KL term might cause posterior collapse, and how to diagnose it during training?

- **Cross-attention mechanisms for multimodal fusion**: DiffGen fuses textual and omics guidance via cross-attention (ZD as key/value, Xt as query) and broadcast concatenation (ZO). Understanding attention patterns helps debug conditioning failures. Quick check: Given query Xt and key ZD, what would attention weights near uniform indicate about the conditioning signal quality?

- **Diffusion model training objective (noise prediction vs. score matching)**: DiffGen estimates conditional distributions Pθ(Xt−1 | Xt, Z) through iterative denoising. Understanding the training-inference discrepancy is critical for debugging generation failures. Quick check: During inference, what happens if the noise schedule differs from training? How would you detect this failure mode?

## Architecture Onboarding

- Component map: E (978 genes) -> OmicsEn (VAE) -> ZO (latent) ; C (text tokens) -> TextEn (SciBERT-frozen) -> ZD (768 dim) ; Xt (noisy SELFIES) + ZD (cross-attention) + ZO (concat) -> DiffGen (Transformer) -> X̂0 (predicted clean embedding)

- Critical path: 1) Omics expression E → VAE encoder → ZO (reparameterized sampling) 2) Text description C → SciBERT → ZD (frozen) 3) SELFIES tokens → vocabulary remapping → R → Xt (noisy embedding) 4) Xt + ZD + ZO → Transformer → X̂0 5) X̂0 → decode → predicted SELFIES tokens → validate with RDKit

- Design tradeoffs: SELFIES vs. SMILES guarantees validity but increases sequence length (~2-3× verbosity), requiring vocabulary remapping to compress; Frozen vs. fine-tuned TextEn preserves pretrained semantic knowledge but limits domain adaptation to chemical language; λ weighting higher λ strengthens omics alignment but may over-constrain generation diversity

- Failure signatures: Low validity (<100%) indicates SELFIES decoding failure or vocabulary mapping corruption; High similarity but low novelty suggests model may be memorizing training samples; Omics reconstruction drift if reconstructed omics profiles diverge from originals indicates VAE encoder may be undertrained

- First 3 experiments: 1) OmicsEn reconstruction sanity check: train VAE alone, visualize original vs. reconstructed gene expression profiles via PCA 2) Ablation on conditioning modalities: compare ToDi (full), ToDiw/o T (omics-only), ToDiw/o O (text-only) on ChemInduced test set 3) Zero-shot transfer test: apply pretrained ToDi to DiseaseSign (Alzheimer's) using patient symptom narratives instead of structured molecular descriptions

## Open Questions the Paper Calls Out

- Can ToDi-generated molecules demonstrate biological activity and therapeutic efficacy in in vitro or in vivo screenings? The authors identify that generated molecules have not undergone experimental validation as a primary limitation, relying entirely on computational metrics rather than biological assays.

- Can ToDi effectively generalize to rare diseases with limited data, such as Gaucher disease, without extensive dedicated datasets? The authors identify the lack of investigation into rare diseases as a limitation and propose establishing dedicated datasets as future work.

- Can the textual description pipeline be automated to scale the TextOmics dataset without sacrificing the semantic accuracy currently ensured by manual expert verification? The manual verification process introduces a bottleneck for scaling the dataset to cover the vast chemical space.

## Limitations

- TextOmics benchmark construction relies on BioT5 generation followed by manual verification without reported inter-annotator agreement rates or quality control procedures
- Dual-encoder architecture's weighting mechanism uses fixed λ=0.3 without systematic sensitivity analysis across diverse molecular classes
- Diffusion model's step count (T=2000) is presented as sufficient without ablation studies demonstrating the relationship between step count and molecular complexity

## Confidence

**High Confidence**: The SELFIES representation guarantees 100% molecular validity through syntactic encoding of chemical valency rules; the dual-encoder architecture successfully captures complementary biological and semantic features from omics and text modalities; ToDi achieves superior performance metrics compared to baseline generative models

**Medium Confidence**: The one-to-one correspondence claim in TextOmics relies on manual verification without reported inter-annotator agreement; the diffusion model's T=2000 steps are sufficient for all molecular complexity levels without systematic ablation; the λ=0.3 weighting provides optimal omics-text trade-off without sensitivity analysis

**Low Confidence**: The vocabulary-aware remapping strategy's compression efficiency for long SELFIES sequences is unproven; the zero-shot therapeutic molecule generation performance on DiseaseSign dataset lacks comparison to established clinical standards; the computational efficiency claims are based on single hardware configuration without scalability analysis

## Next Checks

1. **Benchmark Construction Validation**: Reconstruct the TextOmics dataset using the same BioT5 generation pipeline and perform blind manual verification with multiple annotators. Calculate inter-annotator agreement rates and establish quality control thresholds to validate the claimed one-to-one correspondence reliability.

2. **Diffusion Step Sensitivity Analysis**: Systematically vary the diffusion step count T across different molecular complexity ranges (simple vs. complex ring structures) while monitoring validity, novelty, and structural similarity metrics. Identify the minimum T that maintains performance for therapeutic-sized molecules.

3. **Cross-Modality Ablation with Conflict Testing**: Design controlled experiments where omics and text modalities provide conflicting guidance (e.g., omics suggests polar molecules while text specifies lipophilic groups). Measure how the cosine alignment term handles modality conflicts and whether the model exhibits pathological behavior or gradient instability.