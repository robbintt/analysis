---
ver: rpa2
title: 'Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction'
arxiv_id: '2511.03466'
source_url: https://arxiv.org/abs/2511.03466
tags:
- https
- extraction
- relation
- language
- patterns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Kastor addresses the challenge of fine-tuning small language models
  for relation extraction in specialized domains using SHACL shapes. The method refines
  the traditional validation task by evaluating all possible property combinations
  from a shape and selecting the optimal combination for each training example, enhancing
  model generalization.
---

# Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction

## Quick Facts
- arXiv ID: 2511.03466
- Source URL: https://arxiv.org/abs/2511.03466
- Reference count: 40
- Primary result: Achieves 10% F1 score improvement on shape-based relation extraction using small language models

## Executive Summary
Kastor addresses the challenge of fine-tuning small language models for relation extraction in specialized domains using SHACL shapes. The method refines the traditional validation task by evaluating all possible property combinations from a shape and selecting the optimal combination for each training example, enhancing model generalization. An iterative learning process with human annotation refines noisy knowledge bases to uncover new, relevant facts. Kastor achieves significant performance improvements, including a 10% increase in F1 scores, and demonstrates better pattern extension capacity and discovery rates compared to previous approaches. The framework is open, reusable, and shows promise for scaling to large datasets.

## Method Summary
Kastor uses DBpedia 2022.09 data (6M+ abstracts + graphs) and SHACL shapes with 7 datatype properties for dbo:Person entities. The framework employs BART-base (140M params) with TurtleLight linearization and inverse square root scheduler. Key innovations include filtering non-entailed triples via wikicheck (removing ~40% of data), training on example-specific property subsets rather than rigid maximal schemas, and implementing an active learning loop with human annotation to convert false positives into discoveries. The system uses 10-fold cross-validation on 1200 examples (900/100/100 split) and achieves 8-minute training on V100 GPUs.

## Key Results
- 10% increase in F1 scores compared to baseline approaches
- Discovery rate improves from 0.32 to 0.68 through active learning
- Better pattern extension capacity and discovery rates than previous methods
- Achieves high performance while using only small language models

## Why This Works (Mechanism)

### Mechanism 1: Achievable Pattern Conditioning
Training on flexible, example-specific graph subsets rather than rigid maximal schemas reduces hallucination rates and improves generalization. Instead of forcing models to extract all properties for every entity, the framework identifies the powerset of properties available in specific text and trains the model to map input text only to verifiable property subsets. This prevents spurious correlations where models must invent missing data to satisfy rigid schemas.

### Mechanism 2: Graph-Text Alignment (Noise Filtering)
Filtering training pairs where text does not explicitly entail graph triples significantly lowers factual hallucination rates. The system uses a wikicheck module to verify that property values in DBpedia graphs actually appear in paired Wikipedia abstracts, removing non-entailed triples (approximately 40% of initial dataset). This ensures models learn from text that supports the graph rather than noisy pairs.

### Mechanism 3: Active Learning Discovery Loop
A single pass of human annotation on model errors converts false positives into discoveries, effectively de-biasing the model for knowledge base completion. An initial model is trained on filtered data, generates predictions classified as false positives, and human annotators identify factually correct triples missing from the original knowledge base. Retraining on this corrected dataset improves the model's ability to predict valid triples previously absent from ground truth.

## Foundational Learning

- **Concept: RDF Graphs & SHACL Shapes**
  - Why needed here: The entire framework is structured around extracting data conforming to specific SHACL shapes (schema). Understanding that a Shape defines required and optional properties is essential for grasping pattern-based extraction.
  - Quick check question: Can you distinguish between a "maximal shape" (requiring all properties) and an "achievable pattern" (a subset of properties)?

- **Concept: Seq2Seq (Encoder-Decoder) Models**
  - Why needed here: Kastor uses BART-base, an encoder-decoder architecture, framing the task as translation from natural language abstracts to linearized TurtleLight syntax graphs.
  - Quick check question: Why is an encoder-decoder model (like BART) preferred over an encoder-only model (like BERT) for generating structured graph outputs?

- **Concept: Hallucination Taxonomy**
  - Why needed here: The paper introduces detailed error classification (Factual Hallucination, Abusive Completion, etc.) to quantify model failures. Understanding these categories is required to interpret error analysis.
  - Quick check question: What is the difference between "Factual Hallucination" (value not in text) and "Abusive Completion" (value partially in text but logically extended incorrectly)?

## Architecture Onboarding

- **Component map:** Input (Wikipedia Abstract + DBpedia Graph) → Sampler → Wikicheck (Filter non-entailed triples) → Rule Materializer (Add inferred triples) → BART-base (SLM fine-tuned with TurtleLight) → Active Learning Loop (Predict → Annotate FP/FN → Retrain)

- **Critical path:** The strict alignment filter (wikicheck). If bypassed, the model trains on noisy pairs where text does not support the graph, leading immediately to high hallucination rates.

- **Design tradeoffs:**
  - Strict vs. Noisy Data: Trades data volume (losing 40% of training examples) for data quality (ensuring text entails graph)
  - Schema Rigidity: Moving from single maximal shape to example-specific subsets increases pattern variety (128 combinations) but may reduce model confidence on specific patterns due to sparse examples

- **Failure signatures:**
  - High AC (Abusive Completion) rate: Model generates dates that look plausible but use invalid days/months found nowhere in text
  - Low r_tll (Turtle Light syntax score): Model fails to close brackets or predicates correctly, indicating linearization syntax is too complex

- **First 3 experiments:**
  1. Baseline Validation: Run wikicheck module on 100 abstract-graph pairs to verify entailment logic and measure drop-out rate
  2. Pattern Ablation: Train minimal model on "Maximal Shape" only vs. "Achievable Pattern" on small fold to observe F1 delta and hallucination types
  3. Syntax Stress Test: Verify TurtleLight linearization by feeding model simple text and checking if output is parsable RDF before full fine-tuning

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the framework be effectively adapted to handle object properties rather than just datatype properties? The current error typology and graph linearization are optimized for literals; object properties introduce entity linking challenges not addressed in current implementation.

- **Open Question 2:** Does incorporating annotated error data via contrastive learning reduce specific marginal errors, such as abusive completions? The active learning loop improved general F1 scores but did not significantly reduce rate of persistent marginal errors.

- **Open Question 3:** Can sampling strategies based on RDF-pattern distribution improve model's ability to handle long-tail of rare property combinations? Current study relies on random sampling which may under-represent rare patterns in dataset's long-tail distribution.

## Limitations

- Reliance on wikicheck module for filtering non-entailed triples is critical but underspecified in implementation details
- Active learning loop effectiveness depends on human annotation quality and availability, which may not scale to larger datasets
- Current framework optimized for datatype properties; object properties and entity linking challenges remain unaddressed

## Confidence

- **High confidence:** Mechanism of using achievable patterns instead of maximal shapes is well-supported by error analysis showing reduced hallucination rates
- **Medium confidence:** Active learning discovery loop shows promise in small-scale experiments but scalability to larger datasets remains untested
- **Medium confidence:** 10% F1 improvement claim is based on controlled experiments but generalization to other domains or shapes is unverified

## Next Checks

1. Implement and test the wikicheck module on a sample of 100 abstract-graph pairs to verify entailment logic and measure the drop-out rate
2. Conduct a pattern ablation study: Train models on maximal shapes only versus achievable patterns to observe the delta in F1 scores and hallucination types
3. Perform a syntax stress test by verifying the TurtleLight linearization with simple text inputs to ensure the model can generate parsable RDF before full fine-tuning