---
ver: rpa2
title: 'NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal
  Neurological Disorder Classification'
arxiv_id: '2506.14970'
source_url: https://arxiv.org/abs/2506.14970
tags:
- clinical
- data
- disease
- expert
- multi-modal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of accurately diagnosing neurological
  disorders, particularly Parkinson's disease and idiopathic REM sleep behavior disorder,
  by leveraging multi-modal MRI data (anatomical, diffusion tensor imaging, and functional
  MRI) alongside clinical and serum biomarkers. To overcome the limitations of existing
  deep learning approaches in integrating diverse data modalities, the authors propose
  NeuroMoE, a transformer-based Mixture-of-Experts framework.
---

# NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification

## Quick Facts
- arXiv ID: 2506.14970
- Source URL: https://arxiv.org/abs/2506.14970
- Authors: Wajih Hassan Raza; Aamir Bader Shah; Yu Wen; Yidan Shen; Juan Diego Martinez Lemus; Mya Caryn Schiess; Timothy Michael Ellmore; Renjie Hu; Xin Fu
- Reference count: 35
- Primary result: Achieves 82.47% validation accuracy in Parkinson's disease and iRBD classification using multi-modal MRI data

## Executive Summary
This paper addresses the challenge of accurately diagnosing neurological disorders, particularly Parkinson's disease and idiopathic REM sleep behavior disorder, by leveraging multi-modal MRI data alongside clinical and serum biomarkers. To overcome the limitations of existing deep learning approaches in integrating diverse data modalities, the authors propose NeuroMoE, a transformer-based Mixture-of-Experts framework. This framework employs modality-specific transformers for feature extraction from each MRI type, a gating mechanism that dynamically integrates expert outputs based on clinical features, and an MoE block to adaptively weight modality-specific predictions. Experimental results demonstrate that NeuroMoE achieves a validation accuracy of 82.47%, outperforming baseline methods by over 10%, highlighting its potential to improve ND diagnosis by effectively combining multi-modal clinical data.

## Method Summary
NeuroMoE integrates transformer-based feature extraction with a Mixture-of-Experts architecture for multi-modal neurological disorder classification. The framework processes anatomical MRI (aMRI), diffusion tensor imaging (DTI), and functional MRI (fMRI) through modality-specific transformer encoders, while clinical and serum biomarkers pass through a shared fully connected network. A gating network conditioned on clinical features dynamically weights four expert predictors (one per modality plus one for clinical/serum data) using softmax-normalized coefficients. The model incorporates a regularization term to prevent expert collapse and ensure balanced utilization across modalities. The framework is trained end-to-end using a weighted cross-entropy loss function that combines prediction loss with regularization for balanced expert utilization.

## Key Results
- NeuroMoE achieves 82.47% validation accuracy, outperforming baseline methods by over 10%
- Gating mechanism removal reduces accuracy from 82.47% to 65.17% (17.3% absolute reduction)
- Regularization ensures balanced expert utilization (17-27% range across modalities)
- fMRI expert contributes most to performance (4.74% accuracy drop when removed)

## Why This Works (Mechanism)

### Mechanism 1: Modality-Specific Transformer Encoding with Spatial Preservation
- Claim: Separating encoders per MRI modality improves feature extraction by allowing each to learn modality-specific spatial patterns.
- Mechanism: Each MRI type (aMRI, DTI, fMRI) is processed by its own transformer encoder with patch embeddings (4×4×4 voxels) and positional encodings, followed by K Multi-Head Self-Attention (MHSA) layers and feed-forward networks. This preserves spatial relationships critical for detecting disease patterns.
- Core assumption: Different MRI modalities encode structurally distinct information requiring separate parameter learning.
- Evidence anchors:
  - [abstract]: "Our framework employs transformer encoders to capture spatial relationships within volumetric MRI data while utilizing modality-specific experts for targeted feature extraction."
  - [Section IV.C]: "we design modality-specific encoders: each MRI modality gets a dedicated encoder to learn different parameters and focus on modality-specific features due to their unique characteristics"
  - [corpus]: Weak direct evidence—neighbor papers focus on single-modality or alternative architectures (GCN for ASD), not multi-encoder transformer designs for MRI.
- Break condition: If modalities share fundamentally similar spatial-statistical properties, separate encoders would add parameters without benefit. Ablation shows fMRI removal causes only 4.74% accuracy drop, suggesting partial redundancy.

### Mechanism 2: Clinical-Feature-Driven Dynamic Gating
- Claim: A gating network conditioned on clinical features adaptively weights modality-specific experts, improving patient-specific predictions.
- Mechanism: Clinical/serum features pass through a two-layer gating network with ReLU and dropout, outputting softmax-normalized weights (w₁–w₄). Final prediction P_out = Σw_i·P_i dynamically emphasizes relevant modalities per patient.
- Core assumption: Clinical biomarkers contain information about which imaging modalities are most diagnostically relevant for each patient.
- Evidence anchors:
  - [Section IV.D]: "the gating network adaptively determines their contributions by computing a set of weighting coefficients based on clinical features"
  - [Section V.B, ablation]: Removing gating drops accuracy from 82.47% to 65.17%—a 17.3% absolute reduction, the largest single-component loss
  - [corpus]: ASDFormer paper uses mixture-of-experts but for pooling strategies, not clinical-feature-driven gating; limited external validation.
- Break condition: If clinical features lack predictive relationship to optimal modality weighting, gating becomes noise. The regularization term R_balance forces uniform utilization, which may mask this failure mode.

### Mechanism 3: Regularized Expert Utilization for Balanced Multi-Modal Learning
- Claim: Explicit regularization prevents expert collapse and ensures all modalities contribute meaningfully.
- Mechanism: The regularization term R_balance = (1/4)Σ(average weight for expert k - 0.25)² penalizes deviation from uniform expert utilization, promoting balanced learning across modalities.
- Core assumption: All modalities contain complementary diagnostic information; no single modality is universally sufficient.
- Evidence anchors:
  - [Section IV.D, Equation 3]: Regularization formula explicitly defined
  - [Fig. 4]: Expert utilization ranges 17-27% with regularization, showing balanced contribution; clinical/serum expert slightly higher (~27%)
  - [corpus]: Med-MoE and Flex-MoE papers (cited) address missing data robustness but not explicit utilization balancing—mechanism may be novel to this domain.
- Break condition: If one modality is genuinely more informative for all patients, regularization degrades performance by forcing suboptimal weight distribution.

## Foundational Learning

- **Concept: Mixture-of-Experts (MoE) Architecture**
  - Why needed here: Understanding how sparse expert activation enables scalable multi-modal learning without quadratic parameter growth.
  - Quick check question: Can you explain why MoE differs from a simple ensemble of models? (Answer: MoE uses a learnable gating function to weight outputs dynamically per input, not averaging fixed models.)

- **Concept: Transformer Positional Encodings for Volumetric Data**
  - Why needed here: The paper extends 2D vision transformers to 3D MRI volumes; understanding how positional information is preserved is critical.
  - Quick check question: Why can't you apply a standard vision transformer directly to 3D MRI patches? (Answer: 3D spatial relationships require 3D positional embeddings; 2D transformers lose depth-wise adjacency information.)

- **Concept: Multi-Modal Fusion Strategies (Early vs. Late)**
  - Why needed here: NeuroMoE uses late fusion (modality-specific features combined at MoE level); distinguishing from early fusion informs design choices.
  - Quick check question: What is the tradeoff between concatenating raw modalities vs. combining learned representations? (Answer: Early fusion captures cross-modal correlations but requires aligned data; late fusion allows modality-specific preprocessing and handles missing modalities better.)

## Architecture Onboarding

- **Component map:**
  Input Layer -> 3× MRI transformers (patch→embed→MHSA×K→mean-pool) + 1× FCN for clinical/serum -> MoE Block (4× expert FFNs + gating network) -> Weighted sum aggregation -> Softmax output

- **Critical path:**
  1. Data preprocessing (MNI registration, brain extraction, motion correction) — garbage-in amplifies through pipeline
  2. Patch embedding quality — positional embeddings must correctly encode 3D spatial indices
  3. Gating weight computation — if clinical features are missing/imputed poorly, entire adaptive fusion fails
  4. Regularization strength — too high forces uniform weights; too low allows expert collapse

- **Design tradeoffs:**
  - **Number of experts = number of modalities (4):** Ensures specialization but prevents cross-modal experts
  - **Shared clinical/serum encoder:** Reduces parameters but assumes similar feature structure (low-dimensional tabular)
  - **30% dropout in clinical encoder:** Prevents overfitting on small dataset (N=113) but may underfit if signal is strong
  - **Cosine-annealing LR scheduler:** Good for convergence but sensitive to total epoch count

- **Failure signatures:**
  - Gating weights collapse to single expert (all ~1.0 for one modality) → check R_balance coefficient
  - Validation accuracy plateaus ~65% → likely gating disabled or clinical encoder removed (matches ablation)
  - Large train-val gap → reduce dropout, check data augmentation
  - fMRI expert dominates despite regularization → fMRI may have stronger signal; verify DTI/aMRI preprocessing quality

- **First 3 experiments:**
  1. **Baseline sanity check:** Run each single-modality encoder + classifier without MoE to confirm modality-specific performance hierarchy (paper shows fMRI: 58.78% > aMRI: 56.25% ≈ DTI: 56.82%)
  2. **Gating ablation:** Compare with gating removed (uniform weights) vs. learned gating to quantify adaptive fusion contribution (expect ~17% gap per ablation)
  3. **Regularization sweep:** Test R_balance coefficients (0, 0.01, 0.1, 1.0) to find optimal expert utilization balance; monitor per-expert weight variance

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (N=113) limits generalizability and increases overfitting risk, despite regularization and dropout
- Fixed train/validation/test split (50%/25%/25%) without cross-validation reduces robustness estimates
- Computational complexity of 4 separate transformer encoders may hinder real-world clinical deployment
- Regularization forcing balanced expert utilization may degrade performance if one modality is truly dominant

## Confidence
- **High Confidence:** MoE framework design, ablation methodology, and overall accuracy improvements over baselines (82.47% vs 72.4%)
- **Medium Confidence:** Clinical-feature-driven gating mechanism's effectiveness (large ablation impact but small dataset)
- **Medium Confidence:** Modality-specific transformer benefits (logical design but limited comparative ablation)
- **Low Confidence:** Generalization to larger, more diverse populations (single-center, limited sample)

## Next Checks
1. Perform 5-fold cross-validation to establish confidence intervals for accuracy and validate consistency across splits
2. Test robustness to missing modalities (simulate incomplete data) to evaluate gating mechanism's adaptive capabilities
3. Compare against clinical expert diagnosis on held-out test set to establish real-world diagnostic utility