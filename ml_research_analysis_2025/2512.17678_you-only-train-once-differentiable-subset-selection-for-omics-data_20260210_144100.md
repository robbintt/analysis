---
ver: rpa2
title: 'You Only Train Once: Differentiable Subset Selection for Omics Data'
arxiv_id: '2512.17678'
source_url: https://arxiv.org/abs/2512.17678
tags:
- selection
- genes
- yoto
- gene
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents YOTO, a novel end-to-end differentiable framework
  for gene subset selection in single-cell transcriptomics. The core innovation is
  jointly learning to select discrete gene subsets and perform prediction within a
  single architecture, establishing a closed feedback loop where the prediction task
  directly guides gene selection.
---

# You Only Train Once: Differentiable Subset Selection for Omics Data

## Quick Facts
- arXiv ID: 2512.17678
- Source URL: https://arxiv.org/abs/2512.17678
- Reference count: 5
- Key outcome: YOTO outperforms state-of-the-art baselines in gene subset selection for single-cell transcriptomics, achieving superior F1-score, AUPRC, and accuracy across multiple subset sizes (16-256 genes) while maintaining biological interpretability.

## Executive Summary
This paper introduces YOTO, a novel end-to-end differentiable framework for gene subset selection in single-cell transcriptomics. The core innovation is jointly learning to select discrete gene subsets and perform prediction within a single architecture, establishing a closed feedback loop where the prediction task directly guides gene selection. YOTO employs a differentiable ranking mechanism based on Gumbel-Softmax and Plackett-Luce models to select top-k genes, while a multi-task learning design allows simultaneous optimization across related objectives. Evaluated on COVID-19 PBMC and mouse VISp datasets, YOTO consistently outperforms state-of-the-art baselines in F1-score, AUPRC, and accuracy across multiple gene subset sizes (16-256 genes).

## Method Summary
YOTO learns to select gene subsets through a differentiable ranking mechanism using Gumbel-Softmax relaxation and Plackett-Luce models. The framework maintains a learnable score vector for each gene, applies a differentiable permutation to rank genes, and selects the top-k using a binary mask with straight-through estimation. A shared encoder processes the selected genes, feeding into task-specific heads for multi-task learning. The model optimizes a joint loss across all tasks, with temperature annealing controlling the selection stochasticity. This end-to-end approach ensures the prediction task directly guides gene selection while maintaining sparsity throughout training.

## Key Results
- YOTO consistently outperforms state-of-the-art baselines (PERSIST, HARDKSTL, Top-k) in F1-score, AUPRC, and accuracy across multiple gene subset sizes (16-256 genes)
- Multi-task YOTO achieves 91.5% F1-score with only 1 training instance for difficult tasks, compared to 87.4% for single-task models requiring 3-6 instances
- Ablation study confirms improvements stem from sparse, fully differentiable selection rather than architectural differences
- YOTO demonstrates superior performance in handling imbalanced data and yields compact, meaningful gene subsets without requiring separate downstream classifiers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** End-to-end gradient flow through discrete gene selection improves subset quality by coupling selection directly to task performance.
- **Mechanism:** A learnable score vector $s$ assigns importance to each gene. A differentiable permutation matrix $\pi(s)$ ranks genes using Gumbel-Softmax combined with Plackett-Luce, enabling backpropagation through ranking. The straight-through trick applies a binary mask in the forward pass (discrete selection) while using the relaxed continuous mask in the backward pass (gradient flow).
- **Core assumption:** Gradients from downstream prediction loss contain meaningful signal for identifying which genes contribute to task performance.
- **Evidence anchors:**
  - [abstract] "the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation"
  - [Section 3.1] "Using the straight-through trick (Bengio et al., 2013), we ensure that YOTO only uses information coming from selected genes by using a binary mask in the forward pass"
  - [corpus] Weak direct evidence; neighbor papers focus on foundation models and multi-omics integration rather than differentiable selection mechanisms.
- **Break condition:** If prediction task gradients are noisy or uninformative (e.g., random labels, excessive regularization), selection quality degrades.

### Mechanism 2
- **Claim:** Enforcing strict sparsity during training—not just at inference—forces the model to learn genuinely informative gene subsets.
- **Mechanism:** Unlike PERSIST's temperature-controlled mask that remains non-sparse during training, YOTO's binary mask $\Gamma_k(s)$ allows only top-$k$ genes to contribute. This prevents the model from "cheating" by spreading information across many low-contributing genes.
- **Core assumption:** The selected subset contains sufficient information for the task; genes outside the top-$k$ are not essential.
- **Evidence anchors:**
  - [Section 1] "YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers"
  - [Section 4.4.4] Ablation shows YOTO matches/exceeds PERSIST under identical architecture, confirming sparse selection—not architecture size—drives improvements
  - [corpus] No direct comparison; related work does not address sparse vs. non-sparse training masks.
- **Break condition:** When $k$ is extremely small (e.g., 16 genes) and task requires diverse signals, strict sparsity may hurt performance compared to soft selection.

### Mechanism 3
- **Claim:** Multi-task learning discovers gene subsets that generalize across biological signals by exploiting shared structure.
- **Mechanism:** A shared encoder processes selected genes, feeding task-specific heads. The joint loss $L = \frac{1}{T}\sum_t L_t$ optimizes all tasks simultaneously. Tasks with incomplete labels still refine the shared representation.
- **Core assumption:** Related tasks share relevant gene-level features; optimizing jointly improves generalization over single-task learning.
- **Evidence anchors:**
  - [abstract] "multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another"
  - [Section 4.4.2] Multi-task YOTO outperforms single-task baselines on difficult tasks (patient ID, fine-grained cell types) while requiring only 1 training instance vs. 3-6 for baselines
  - [corpus] Neighbor paper "Subset-Contrastive Multi-Omics Network Embedding" supports shared representation benefits but in different context.
- **Break condition:** If tasks are contradictory or require completely disjoint gene sets, joint optimization may yield compromised subsets.

## Foundational Learning

- **Concept: Gumbel-Softmax relaxation**
  - **Why needed here:** Enables gradients to flow through discrete gene selection. Without it, ranking/selection operations are non-differentiable.
  - **Quick check question:** Can you explain why adding Gumbel noise and applying softmax approximates sampling from a categorical distribution?

- **Concept: Plackett-Luce ranking model**
  - **Why needed here:** Provides a probabilistic framework for learning gene rankings where higher scores yield higher selection probability.
  - **Quick check question:** How does the sequential selection in Plackett-Luce differ from independent softmax over all items?

- **Concept: Straight-through estimator**
  - **Why needed here:** Allows discrete forward pass (true sparsity) while maintaining continuous backward pass (gradient flow).
  - **Quick check question:** What happens to gradient estimates if the forward and backward functions are completely different?

## Architecture Onboarding

- **Component map:**
  ```
  Input genes X → [Subset Selection: scores s → permutation π(s) → mask Γ_k(s)] 
                → [Shared Encoder E] → latent z 
                → [Task Heads H_1...H_T] → predictions ŷ_1...ŷ_T
  ```

- **Critical path:**
  1. Initialize learnable gene scores $s$ (one per gene)
  2. Forward: compute $\pi(s)$, extract top-$k$ mask $\Gamma_k(s)$, apply mask to input
  3. Encode masked input → latent representation
  4. Predict via task-specific heads
  5. Backward: gradients flow through relaxed $\pi(s)$ to update $s$

- **Design tradeoffs:**
  - **Temperature τ:** High τ = stochastic exploration; low τ = deterministic selection. Paper uses exponential annealing.
  - **Subset size k:** Smaller k = harder optimization but more compact panels. Paper tests 16-256.
  - **Encoder capacity:** Must support multi-task learning but ablation shows architecture size is not the key driver.

- **Failure signatures:**
  - **Score collapse:** All gene scores converge to similar values → effectively random selection. Check score variance during training.
  - **Task domination:** One task's loss dominates gradient signal → selected genes optimize only that task. Monitor per-task loss ratios.
  - **Extreme k underperformance:** At k=16, YOTO underperforms in ablation (Table 4). May need multi-task setting or larger k.

- **First 3 experiments:**
  1. **Smoke test:** Single-task classification on a small dataset (e.g., VISp with k=64). Verify F1 improves over 100 epochs and selected genes stabilize.
  2. **Ablation check:** Compare YOTO vs. PERSIST under identical architecture on single task. Confirm YOTO's sparse selection is the difference-maker (replicate Table 4 pattern).
  3. **Multi-task sanity:** Train on COVID-PBMC with all three tasks. Verify single model matches/exceeds task-specific baselines and inspect selected genes for biological plausibility.

## Open Questions the Paper Calls Out
- **Question:** Can YOTO generalize to other high-dimensional omics domains such as proteomics, epigenomics, and multi-omics integration?
- **Question:** Are the gene subsets selected by YOTO biologically interpretable and do they correspond to known disease mechanisms or pathways?
- **Question:** How does YOTO perform on extremely constrained gene panels (k < 16) where individual gene choice critically impacts performance?

## Limitations
- **Architectural specifics** (High uncertainty): Key hyperparameters for encoder and task heads are unspecified, making exact replication difficult
- **Optimization configuration** (Medium uncertainty): Optimizer type, learning rate, and batch size not reported
- **Annealing schedules** (Medium uncertainty): Temperature decay and subset size progression lack precise definitions

## Confidence
- **High confidence** in core mechanism (differentiable gene selection + multi-task learning produces compact, predictive subsets)
- **Medium confidence** in ablation study conclusions (limited architectural details make complete verification challenging)
- **Medium confidence** in generalization claims (results show strong performance but sample size across datasets is limited)

## Next Checks
1. Implement and test the straight-through estimator with varying temperature schedules to verify gradient flow through discrete selection
2. Conduct ablation comparing YOTO vs. PERSIST under identical architecture on single-task setting to isolate sparse selection effect
3. Analyze learned gene subsets for biological coherence by comparing selected genes across related tasks (e.g., cell types vs. disease status)