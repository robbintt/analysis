---
ver: rpa2
title: 'RTBAgent: A LLM-based Agent System for Real-Time Bidding'
arxiv_id: '2502.00792'
source_url: https://arxiv.org/abs/2502.00792
tags:
- bidding
- rtbagent
- advertising
- data
- budget
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RTBAgent is the first LLM-based agent system for real-time bidding,
  addressing the limitations of rule-based and RL methods in dynamic online advertising
  environments. It introduces a two-step decision-making process that integrates CTR
  estimation, expert bidding strategies, multi-memory retrieval, and daily reflection
  to dynamically adjust bidding prices.
---

# RTBAgent: A LLM-based Agent System for Real-Time Bidding

## Quick Facts
- arXiv ID: 2502.00792
- Source URL: https://arxiv.org/abs/2502.00792
- Authors: Leng Cai; Junxuan He; Yikai Li; Junjie Liang; Yuanping Lin; Ziming Quan; Yawen Zeng; Jin Xu
- Reference count: 40
- RTBAgent is the first LLM-based agent system for real-time bidding, significantly outperforming traditional and RL-based methods

## Executive Summary
RTBAgent introduces the first LLM-based agent system for real-time bidding in online advertising, addressing the limitations of traditional rule-based and reinforcement learning approaches. The system implements a two-step decision-making process that integrates CTR estimation, expert bidding strategies, multi-memory retrieval, and daily reflection to dynamically adjust bidding prices in response to market changes. Evaluated on the iPinYou dataset, RTBAgent achieved up to 12.75% more clicks under constrained budgets while providing interpretable decision-making insights.

## Method Summary
RTBAgent employs a two-step decision-making framework where the agent first estimates the click-through rate (CTR) for each impression using a specialized CTR prediction model, then determines the optimal bid price using LLM-driven reasoning. The system integrates multi-memory retrieval to access historical bidding data and expert strategies, while implementing a daily reflection mechanism to learn from previous bidding outcomes. The agent leverages Llama-3-8B as its reasoning backbone, combining it with domain-specific knowledge and expert heuristics to make informed bidding decisions in real-time environments.

## Key Results
- Achieved 12.75% more clicks compared to traditional methods under the same budget constraints
- Significantly outperformed both rule-based and reinforcement learning baselines across all evaluation metrics
- Demonstrated superior budget utilization and click-through rate performance on the iPinYou dataset
- Provided interpretable decision-making insights through generated bidding explanations

## Why This Works (Mechanism)
The system succeeds by leveraging LLM reasoning capabilities to dynamically adjust to market changes rather than relying on static rules or pre-trained policies. The two-step process allows for separate optimization of CTR estimation and bid price determination, while multi-memory retrieval provides contextual awareness of historical performance. The daily reflection mechanism enables continuous learning and adaptation to evolving market conditions.

## Foundational Learning
- **Real-Time Bidding (RTB)**: Automated auction system where ad impressions are bought in real-time, requiring decisions within milliseconds
  - *Why needed*: Forms the fundamental problem domain where latency and decision quality are critical
  - *Quick check*: Understanding auction mechanics, budget constraints, and performance metrics

- **CTR Prediction Models**: Machine learning models that estimate the probability of user engagement with ads
  - *Why needed*: Provides essential input for bid price determination based on expected value
  - *Quick check*: Familiarity with logistic regression, gradient boosting, and deep learning approaches

- **LLM-Based Decision Making**: Using large language models for reasoning and decision-making tasks
  - *Why needed*: Enables dynamic adaptation and complex reasoning beyond rule-based systems
  - *Quick check*: Understanding prompt engineering, context management, and inference constraints

- **Multi-Memory Retrieval**: Accessing and integrating multiple knowledge sources during decision-making
  - *Why needed*: Provides comprehensive context by combining historical data and expert strategies
  - *Quick check*: Understanding embedding-based retrieval and context window management

- **Daily Reflection Mechanism**: Systematic evaluation and learning from previous decisions
  - *Why needed*: Enables continuous improvement and adaptation to market changes
  - *Quick check*: Understanding feedback loops and performance monitoring systems

## Architecture Onboarding

Component Map: CTR Model -> Multi-Memory Retriever -> LLM Reasoning -> Bid Price Determination -> Daily Reflection

Critical Path: Impression arrives → CTR prediction → Memory retrieval → LLM reasoning → Bid decision → Performance tracking → Daily reflection

Design Tradeoffs:
- Model size vs. inference latency (Llama-3-8B chosen over smaller/faster alternatives)
- Memory retrieval frequency vs. computational overhead
- Reflection granularity vs. learning effectiveness
- Rule-based safety vs. LLM flexibility

Failure Signatures:
- High latency in memory retrieval causing missed bidding opportunities
- LLM reasoning producing inconsistent bids across similar impressions
- Daily reflection not capturing meaningful patterns due to insufficient data
- Budget exhaustion before campaign completion due to aggressive bidding

3 First Experiments:
1. A/B test comparing CTR predictions from traditional ML models vs. LLM-enhanced predictions
2. Ablation study removing daily reflection to measure its impact on long-term performance
3. Latency benchmark testing different LLM model sizes under real-time constraints

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can small-scale LLMs (1B–3B parameters) maintain the decision-making quality of larger models while satisfying the strict latency constraints of Real-Time Bidding (RTB)?
- Basis in paper: [explicit] The "Limitations" section states that response time is currently "not as swift as desired" and suggests that employing models with smaller parameter sizes (1B or 3B) is a "promising direction."
- Why unresolved: The paper primarily evaluates models like GPT-3.5 and Llama-3-8B; the trade-off between the inference speed of tiny models and their reasoning capability for complex bidding adjustments remains untested.
- What evidence would resolve it: Benchmarking the click-through performance and inference latency of 1B–3B parameter models against the Llama-3-8B baseline in the same RTB environment.

### Open Question 2
- Question: How can multi-agent systems based on LLMs enhance bidding effectiveness compared to the current single-agent framework?
- Basis in paper: [explicit] The "Conclusion" explicitly maps out future research focusing on "the application of multi-agent systems based on LLMs in RTB" to better fit market competitiveness.
- Why unresolved: The current RTBAgent operates as a single entity; the potential benefits or complexities arising from collaboration or competition between multiple specialized agents are purely speculative at this stage.
- What evidence would resolve it: Designing a multi-agent experiment (e.g., separate agents for budget allocation vs. market analysis) and comparing the resulting KPIs and adaptability against the single-agent baseline.

### Open Question 3
- Question: To what extent does Retrieval-Augmented Generation (RAG) improve the agent's performance by compensating for the lack of internal bidding knowledge in pre-trained LLMs?
- Basis in paper: [explicit] The "Limitations" section notes that "current LLMs have not yet encompassed a richer set of bidding knowledge" and suggests that utilizing strategies like RAG "might lead to greater enhancements."
- Why unresolved: The current system relies on static expert strategies and internal reflection; it does not dynamically retrieve external domain knowledge, which limits its ability to handle novel or complex market dynamics.
- What evidence would resolve it: An ablation study comparing the current memory retrieval mechanism against a RAG-enhanced system using a database of bidding textbooks or historical case studies.

## Limitations
- Experimental evaluation conducted only on a single public dataset (iPinYou), limiting generalizability to other real-world advertising environments
- Potential computational overhead and latency concerns associated with multi-memory retrieval and reflection components not thoroughly addressed
- Interpretability claims rely on LLM-generated explanations that may not always align with actual decision-making processes

## Confidence

**High Confidence**: The technical architecture and two-step decision-making process are well-defined and theoretically sound.

**Medium Confidence**: The performance improvements over baseline methods are demonstrated but require validation on additional datasets and real-world deployments.

**Medium Confidence**: The interpretability benefits are presented but need more rigorous validation of the quality and accuracy of generated explanations.

## Next Checks
1. Conduct experiments on additional RTB datasets with varying characteristics (different industries, bid landscapes, and inventory types) to assess generalizability.
2. Perform ablation studies to quantify the individual contributions of multi-memory retrieval and daily reflection components to overall performance.
3. Implement latency and computational cost analysis to evaluate the system's feasibility in high-frequency bidding environments with sub-second response requirements.