---
ver: rpa2
title: 'HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs'
arxiv_id: '2503.04822'
source_url: https://arxiv.org/abs/2503.04822
tags:
- graph
- heterophilic
- graphs
- methods
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce HeTGB, a novel benchmark for heterophilic text-attributed
  graphs, addressing the lack of comprehensive datasets that combine heterophilic
  structures with rich textual content. HeTGB includes five real-world datasets spanning
  domains like web pages, social networks, and e-commerce, with nodes enriched by
  extensive textual descriptions.
---

# HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs

## Quick Facts
- arXiv ID: 2503.04822
- Source URL: https://arxiv.org/abs/2503.04822
- Reference count: 40
- Authors: Shujie Li, Yuxia Wu, Chuan Shi, Yuan Fang
- Primary result: Novel benchmark introducing five real-world datasets combining heterophilic structures with rich textual content, demonstrating superior performance of heterophily-specific GNNs and LLM-derived features

## Executive Summary
This paper introduces HeTGB, a comprehensive benchmark designed to address the lack of datasets that combine heterophilic graph structures with rich textual content. The benchmark comprises five real-world datasets spanning domains such as web pages, social networks, and e-commerce, where nodes are enriched with extensive textual descriptions. The authors systematically evaluate various methods including GNN-based, PLM-based, and co-training approaches on node classification tasks, revealing significant performance gaps between standard GNNs and heterophily-specific methods. The findings highlight the challenges of modeling complex structural-semantic interplay in heterophilic text-attributed graphs and provide insights for future research directions in this emerging field.

## Method Summary
HeTGB introduces five real-world datasets specifically designed to capture heterophilic text-attributed graph scenarios across diverse domains. The benchmark includes comprehensive evaluation protocols covering GNN-based methods (both standard and heterophily-specific), PLM-based approaches (including zero-shot, fine-tuned, and co-training variants), and hybrid co-training frameworks. The evaluation framework systematically measures performance across multiple metrics while also analyzing computational efficiency and the interplay between structural and semantic information. The datasets are made publicly available to facilitate reproducibility and further research in the field.

## Key Results
- Heterophily-specific GNNs and LLM-derived features significantly outperform standard GNNs on node classification tasks
- Fine-tuned LLMs and heterophily-aware co-training methods like LLM4HeG achieve strong performance, though at higher computational cost
- The benchmark reveals substantial challenges in modeling the complex interplay between heterophilic structures and textual semantics
- Performance gaps highlight the need for specialized methods that can effectively integrate structural and semantic information

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its ability to capture the inherent tension between heterophilic graph structures (where connected nodes belong to different classes) and rich textual attributes that may provide complementary or contradictory information. Standard GNNs, which assume homophily, struggle because they propagate information from neighbors that often belong to different classes. PLMs, while powerful at capturing semantic patterns, typically lose structural information when using flattening techniques. The benchmark demonstrates that methods which can effectively bridge this gap - either through heterophily-aware message passing or through careful integration of PLM features with graph structure - achieve superior performance.

## Foundational Learning
- **Heterophily vs Homophily**: Understanding the fundamental difference between graphs where connected nodes share similar attributes (homophily) versus those where they differ (heterophily). Why needed: Most existing GNN methods assume homophily, making heterophilic graphs challenging.
- **Text-Attributed Graphs (TAGs)**: Graphs where nodes carry rich textual attributes in addition to structural information. Why needed: Provides richer semantic context but complicates the integration of structure and content.
- **PLM-Enhanced GNNs**: Methods that leverage pre-trained language models to extract semantic features from text attributes and integrate them with graph neural networks. Why needed: Offers powerful semantic understanding but faces challenges in preserving structural information.
- **Co-Training Frameworks**: Approaches that jointly train GNNs and PLMs to leverage both structural and semantic information. Why needed: Potentially captures complementary strengths but introduces computational complexity.
- **Heterophily-Ratio**: A metric measuring the degree of heterophily in a graph. Why needed: Helps characterize graph properties and understand method performance across different levels of heterophily.
- **Tokenization Strategies**: Methods for encoding graph data into formats suitable for language models. Why needed: Critical for PLM-based approaches to effectively capture structural dependencies.

## Architecture Onboarding

**Component Map**: Data Preparation -> GNN Methods -> PLM Methods -> Co-Training Methods -> Evaluation

**Critical Path**: The evaluation pipeline follows a sequential flow where datasets are prepared, various method categories are applied independently, co-training methods are implemented as hybrid approaches, and final performance is measured across multiple metrics including accuracy and computational efficiency.

**Design Tradeoffs**: The benchmark prioritizes comprehensive method coverage over single-method optimization, balancing between standard approaches and novel heterophily-aware techniques. It emphasizes real-world applicability through diverse datasets but accepts the computational overhead of co-training methods as necessary for capturing complex structural-semantic relationships.

**Failure Signatures**: Poor performance on heterophilic datasets indicates methods that over-rely on neighborhood aggregation (standard GNNs) or those that lose structural information through improper tokenization (PLM-based methods). Computational bottlenecks in co-training suggest inefficient integration strategies between GNNs and PLMs.

**First Experiments**:
1. Baseline evaluation of standard GNNs (GCN, GAT) on all five HeTGB datasets to establish performance floors
2. Zero-shot evaluation of PLMs to assess inherent semantic understanding without fine-tuning
3. Comparative analysis of heterophily-specific GNNs (H2GCN, CPGNN) against standard variants

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** Can adaptive co-training frameworks be developed to dynamically balance graph-based message passing with PLM-driven semantic reasoning to better capture complex heterophilic relationships?
- **Basis in paper:** [explicit] The authors state in Section 6 that "One key avenue is the development of adaptive co-training frameworks that can better integrate graph-based message passing with PLM-driven reasoning."
- **Why unresolved:** Current co-training methods often rely on fixed integration strategies or simply use PLMs for feature extraction without adaptive alignment. The "interplay between graph structures and textual attributes" remains a challenge (Section 1).
- **What evidence would resolve it:** The development of a co-training model that dynamically adjusts the weight of structural vs. semantic signals based on local homophily ratios, demonstrating superior performance on HeTGB compared to static models like G2P2 or LLM4HeG.

### Open Question 2
- **Question:** How can structure-aware tokenization strategies be designed to preserve structural dependencies when encoding graph data for Large Language Models?
- **Basis in paper:** [explicit] Section 6 identifies "designing graph tokenization strategies" as a promising direction to "bridge the gap in PLMs" and enhance their ability to capture heterophilic structures.
- **Why unresolved:** Current PLM-based methods typically use "flattening techniques" (Section 4.2) which result in a "loss of structural information," contributing to poor zero-shot performance (Section 5.3).
- **What evidence would resolve it:** A novel tokenization method that encodes node neighborhood topology into the prompt, resulting in LLMs successfully distinguishing between homophilic and heterophilic neighbors without fine-tuning.

### Open Question 3
- **Question:** Can parameter-efficient fine-tuning (PEFT) strategies be optimized to reduce the high computational cost of co-training methods while maintaining high expressiveness?
- **Basis in paper:** [inferred] Section 5.5 highlights a significant "tradeoff between model expressiveness and efficiency," noting that co-training methods incur "substantially higher computational costs." Section 6 explicitly calls for "parameter-efficient... fine-tuning strategy."
- **Why unresolved:** While LoRA was used for PLMs, the combination of GNN training and PLM fine-tuning remains computationally expensive, posing "challenges for scalability in large-scale graph applications."
- **What evidence would resolve it:** A benchmarked method on HeTGB that reduces training/inference time by >50% compared to full co-training methods (like GraphGPT) while achieving comparable accuracy on the node classification task.

### Open Question 4
- **Question:** Does explicitly enforcing alignment between graph structures and semantic features improve the performance of heterophily-aware co-training methods?
- **Basis in paper:** [inferred] Section 5.4 notes that the state-of-the-art heterophily-specific method LLM4HeG "does not explicitly consider the alignment between graph structures and semantic features," implying this is a missed opportunity for enhancement.
- **Why unresolved:** It is uncertain if adding explicit alignment mechanisms (common in homophilic TAGs) helps in heterophilic contexts where "linked nodes belong to distinct classes" (Section 1).
- **What evidence would resolve it:** An ablation study on HeTGB showing that adding a contrastive loss to align structural and semantic embeddings improves accuracy over the baseline LLM4HeG.

## Limitations
- The benchmark focuses exclusively on heterophilic graphs with text attributes, limiting generalizability to homophilic settings or graphs with other attribute types
- Only five real-world datasets are included across specific domains, potentially limiting scenario diversity
- The evaluation framework does not explore the full spectrum of potential approaches for handling heterophilic text-attributed graphs

## Confidence
- High confidence: Heterophily-specific GNNs and LLM-derived features significantly outperform standard GNNs on benchmark datasets
- Medium confidence: Fine-tuned LLMs and heterophily-aware co-training methods achieve strong performance based on limited experiments
- Medium confidence: Benchmark effectively highlights challenges in modeling structural-semantic interplay through observed performance gaps

## Next Checks
1. Evaluate the benchmark's performance on additional heterophilic text-attributed graphs from diverse domains not covered in the current study
2. Conduct ablation studies to quantify the individual contributions of textual features and structural heterophily to model performance
3. Compare the benchmark's performance against state-of-the-art methods for homophilic text-attributed graphs to assess the specific challenges posed by heterophily