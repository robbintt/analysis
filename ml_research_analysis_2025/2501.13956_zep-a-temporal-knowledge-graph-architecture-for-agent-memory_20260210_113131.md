---
ver: rpa2
title: 'Zep: A Temporal Knowledge Graph Architecture for Agent Memory'
arxiv_id: '2501.13956'
source_url: https://arxiv.org/abs/2501.13956
tags:
- memory
- knowledge
- graph
- entity
- edges
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Zep, a memory layer service for AI agents
  that leverages a temporally-aware knowledge graph architecture to address the limitations
  of static document retrieval in enterprise applications. Zep's core component, Graphiti,
  dynamically synthesizes unstructured conversational data and structured business
  data while maintaining historical relationships.
---

# Zep: A Temporal Knowledge Graph Architecture for Agent Memory

## Quick Facts
- arXiv ID: 2501.13956
- Source URL: https://arxiv.org/abs/2501.13956
- Reference count: 30
- Key result: Zep achieves 94.8% accuracy on Deep Memory Retrieval benchmark, surpassing MemGPT's 93.4%, with 90% latency reduction

## Executive Summary
Zep introduces a temporal knowledge graph architecture for AI agent memory that addresses the limitations of static document retrieval in enterprise applications. The system leverages Graphiti, a temporally-aware knowledge graph engine that dynamically synthesizes unstructured conversational data and structured business data while maintaining historical relationships. By implementing a three-tier hierarchical graph structure (episodes, entities, communities) and hybrid retrieval methods, Zep demonstrates significant improvements in accuracy and efficiency for complex temporal reasoning tasks and long-term context maintenance.

## Method Summary
Zep implements a temporal knowledge graph architecture centered on Graphiti, which maintains bi-temporal tracking with T (chronological) and T' (transactional) timelines. The system ingests conversations by creating episode nodes, extracting entities through a hybrid approach combining embedding similarity, full-text search, and LLM resolution, then extracting facts with temporal information. A three-tier graph structure organizes raw messages as episodes, extracted entities and facts as semantic nodes, and clustered communities with summaries. Retrieval combines semantic, lexical, and graph traversal searches, followed by reranking and context construction. The system is evaluated on Deep Memory Retrieval and LongMemEval benchmarks using GPT-4o for judging.

## Key Results
- Achieved 94.8% accuracy on Deep Memory Retrieval benchmark, surpassing MemGPT's 93.4%
- Demonstrated up to 18.5% accuracy improvements on LongMemEval temporal-reasoning questions
- Reduced response latency by 90% compared to baseline implementations through hierarchical graph organization

## Why This Works (Mechanism)

### Mechanism 1: Bi-temporal Edge Management
Temporal knowledge graphs with bi-temporal tracking improve memory retrieval accuracy for evolving conversations compared to static document retrieval. Graphiti maintains two timelines (T and T') and stores four timestamps per edge (t_valid, t_invalid, t'_created, t'_expired). When new facts contradict existing ones with temporal overlap, edges are invalidated rather than deleted, preserving history. This assumes enterprise memory tasks require reasoning about when facts became true or ceased to be true, not just current state. Evidence shows Graphiti consistently prioritizes new information for edge invalidation, though comparative validation specifically for agent memory remains limited.

### Mechanism 2: Hierarchical Graph Abstraction
Hierarchical graph organization (episodes → entities → communities) enables retrieval at appropriate abstraction levels, reducing context token usage. Raw messages become Episode nodes, LLM extracts entities and facts into the Semantic Subgraph, and label propagation clustering creates Community nodes with summaries. This multi-scale abstraction mirrors human memory and improves relevance filtering for LLM context windows. Evidence shows 90% latency reduction through context size reduction from 115k to ~1.6k tokens, though gains are marginal for short conversations (<60 messages).

### Mechanism 3: Hybrid Retrieval with Reranking
Hybrid search (semantic + lexical + graph traversal) with reranking improves recall-precision balance for complex temporal queries. Three search functions run in parallel (cosine similarity, BM25, BFS), with results merged via reranker using RRF, MMR, or cross-encoders before context construction. Different query types benefit from different similarity signals, and combining them captures more relevant context. Evidence shows 18.5% accuracy improvement on temporal-reasoning questions versus full-context baseline, though optimal reranking strategies remain under-researched.

## Foundational Learning

### Knowledge Graph Fundamentals
Nodes, edges, incidence functions, and traversals are prerequisite to understanding Zep's graph G=(N, E, φ) architecture. Quick check: Can you explain the difference between an entity node and an episode node in Zep's schema?

### Bi-temporal Data Modeling
Zep's temporal extraction tracks four timestamps per edge; understanding valid-time vs. transaction-time is essential for debugging temporal queries. Quick check: When would t_invalid differ from t'_expired?

### Hybrid Retrieval Methods
Zep combines vector similarity, BM25, and BFS; each serves different query patterns. Quick check: Why might BM25 outperform cosine similarity for entity name matching?

## Architecture Onboarding

### Component Map
Episode ingestion → Entity extraction/resolution → Fact extraction → Temporal extraction → Graph write → Community update (periodic refresh)

### Critical Path
Raw messages are processed with n=4 context, entities are extracted and embedded with BGE-m3, resolved via hybrid search + LLM, facts are extracted with temporal data (valid_at, invalid_at), edge invalidation is handled, and the graph is written to Neo4j with Lucene indexes.

### Design Tradeoffs
Label propagation vs. Leiden: Faster dynamic updates but requires periodic full refreshes. Predefined Cypher vs. LLM-generated queries: Schema consistency at cost of flexibility. Cross-encoder reranking: Highest accuracy but adds latency and LLM cost.

### Failure Signatures
Entity resolution failures: Duplicate nodes for same entity (check embedding similarity threshold). Temporal extraction errors: Incorrect t_valid/t_invalid on relative dates (verify t_ref propagation). Community drift: Stale summaries after many additions (trigger full refresh).

### First 3 Experiments
1. Ingest a 50-message conversation; verify entity resolution merged duplicate mentions of the same person.
2. Query with a temporal reasoning question ("What did user say about X before date Y?"); inspect returned edges and their t_valid/t_invalid fields.
3. Compare latency and accuracy of RRF reranking vs. cross-encoder on 20 LongMemEval-style queries.

## Open Questions the Paper Calls Out

### Open Question 1
Can domain-specific ontologies improve knowledge extraction accuracy in temporal knowledge graphs like Graphiti, particularly for specialized enterprise verticals? While current research on LLM-generated knowledge graphs has primarily operated without formal ontologies, domain-specific ontologies present significant potential and warrant further exploration within the Graphiti framework.

### Open Question 2
Why does Zep underperform on single-session-assistant question types, and what architectural modifications could address this regression? The decrease in performance for single-session-assistant questions—17.7% for gpt-4o and 9.06% for gpt-4o-mini—represents a notable exception to Zep's otherwise consistent improvements, suggesting further research and engineering work is needed.

### Open Question 3
How does Zep's temporal knowledge graph perform when synthesizing conversation history with structured business data, and what benchmarks can adequately evaluate this capability? Notably, no existing benchmarks adequately assess Zep's capability to process and synthesize conversation history with structured business data, despite the system being designed for this purpose.

### Open Question 4
Can fine-tuned models for entity and edge extraction match or exceed general-purpose LLM performance on Graphiti prompts while reducing latency and cost? Research has already demonstrated the value of fine-tuned models for LLM-based entity and edge extraction within the GraphRAG paradigm, and similar models fine-tuned for Graphiti prompts may enhance knowledge extraction, particularly for complex conversations.

## Limitations
- Temporal extraction reliability is demonstrated through aggregated accuracy gains but lacks detailed analysis of edge invalidation correctness across diverse temporal query patterns
- Entity resolution quality may create duplicates in edge cases, particularly for homonyms or entities with similar names but different contexts
- Community detection stability requires periodic full refreshes, but optimal refresh intervals and long-term quality degradation are not specified

## Confidence
**High Confidence**: Hierarchical graph organization effectiveness, hybrid retrieval benefits, latency improvements from reduced context usage
**Medium Confidence**: Temporal knowledge graph advantages for evolving conversations, bi-temporal edge invalidation logic, entity resolution approach effectiveness
**Low Confidence**: Community detection implementation details, optimal reranking strategy selection, long-term temporal reasoning reliability across extended conversations

## Next Checks
1. Create synthetic conversations with known temporal conflicts and verify Graphiti correctly invalidates edges with temporal overlap while preserving historical relationships
2. Test entity resolution on conversations containing homonyms, abbreviations, and context-dependent entity references to measure duplicate entity creation rate
3. Run long-running ingestion experiments (100+ conversations) and measure community quality degradation over time to quantify impact of community drift on retrieval accuracy for multi-session queries