---
ver: rpa2
title: Automatic Cough Analysis for Non-Small Cell Lung Cancer Detection
arxiv_id: '2507.19174'
source_url: https://arxiv.org/abs/2507.19174
tags:
- cancer
- cough
- learning
- healthy
- lung
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the use of automatic cough analysis as
  a non-invasive screening tool for distinguishing non-small cell lung cancer (NSCLC)
  patients from healthy controls. Audio recordings from 227 participants were analyzed
  using machine learning and deep learning techniques, including support vector machines
  (SVM), convolutional neural networks (CNN), and transfer learning with VGG16.
---

# Automatic Cough Analysis for Non-Small Cell Lung Cancer Detection

## Quick Facts
- arXiv ID: 2507.19174
- Source URL: https://arxiv.org/abs/2507.19174
- Authors: Chiara Giangregorio; Cristina Maria Licciardello; Vanja Miskovic; Leonardo Provenzano; Alessandra Laura Giulia Pedrocchi; Andra Diana Dumitrascu; Arsela Prelaj; Marina Chiara Garassino; Emilia Ambrosini; Simona Ferrante
- Reference count: 34
- Primary result: CNN achieved 0.83 accuracy in distinguishing NSCLC patients from healthy controls using cough audio analysis

## Executive Summary
This study investigates automatic cough analysis as a non-invasive screening tool for Non-Small Cell Lung Cancer (NSCLC) detection. Using audio recordings from 227 participants, the researchers applied machine learning and deep learning techniques to classify coughs from NSCLC patients versus healthy controls. The best-performing model, a CNN, achieved 0.83 accuracy on the test set, while SHAP analysis provided interpretability by identifying key acoustic features like MFCC coefficients and crest factor. The study demonstrates AI's potential for early NSCLC detection, though larger and more diverse datasets are needed for validation.

## Method Summary
The study collected cough audio recordings from 227 participants (118 NSCLC patients, 109 healthy controls) at 16kHz, preprocessed to 12kHz with loudness normalization and low-pass filtering. Cough events were segmented using the Orlandic algorithm. Two analysis pipelines were implemented: machine learning extracted 39 acoustic features (MFCCs, spectral characteristics, etc.) for SVM/XGBoost/Logistic Regression models with 5-fold CV, while deep learning generated 128-band mel-spectrograms for CNN and VGG16 models. Models were evaluated on a held-out test set (10% of data) using accuracy, precision, recall, F1-score, and fairness metrics (Equalized Odds Difference).

## Key Results
- CNN achieved highest performance with 0.83 accuracy on test set, outperforming SVM (0.78 accuracy) and transfer learning (0.77 validation accuracy)
- SHAP analysis identified MFCC mean0, MFCC mean2, MFCC mean9, and crest factor as most influential features for SVM classification
- Fairness evaluation showed minor disparities: age EOD of 0.15 and gender EOD of 0.09
- SVM showed promise for low-computational-power settings with interpretable results

## Why This Works (Mechanism)

### Mechanism 1
NSCLC-related changes in respiratory physiology (airflow dynamics, vocal tract behavior, mucus production) alter cough sound characteristics, creating discriminative patterns in spectral/temporal features that ML models learn to identify. The core assumption is that cough acoustics reflect disease state rather than demographic confounders.

### Mechanism 2
CNNs capture hierarchical patterns in mel-spectrograms that distinguish NSCLC from healthy coughs more effectively than handcrafted features. The model learns spatial hierarchies from time-frequency representations that encode disease signatures.

### Mechanism 3
SHAP analysis on SVM models identifies interpretable acoustic features (MFCCs, crest factor) that drive classification decisions, enabling clinical trust by showing which features contribute most to predictions.

## Foundational Learning

- **Mel-Frequency Cepstral Coefficients (MFCCs)**: Core acoustic features identified by SHAP as most discriminative; represent vocal tract shape and energy across perceptual frequency bands. Quick check: Can you explain why MFCCs use a mel-scale rather than linear frequency bands, and what coefficients 0-16 represent?

- **Mel-spectrograms**: Input representation for CNN; transforms 1D audio into 2D time-frequency image amenable to convolutional processing. Quick check: How does a mel-spectrogram differ from a standard spectrogram, and why might this representation benefit respiratory sound classification?

- **SHAP (Shapley Additive Explanations)**: Provides model-agnostic feature importance; enables clinical trust by showing which acoustic features drive predictions. Quick check: In a SHAP summary plot, what does the x-axis represent and how do you interpret high vs low feature values (red vs blue points)?

## Architecture Onboarding

- **Component map**: Audio acquisition (mobile/web app, 16kHz) → Preprocessing (loudness normalization, low-pass filter, 12kHz downsample) → Cough segmentation (Orlandic algorithm) → Dual pipeline: ML path (39 acoustic features → correlation filtering → SVM/XGBoost/LR) OR DL path (Mel-spectrogram → CNN/VGG16 → Dense → Sigmoid) → Evaluation (5-fold CV + held-out test + fairness metrics)

- **Critical path**: Cough segmentation quality cascades to all downstream; train/test split integrity (small test set ≈23 samples); SHAP interpretability pipeline must use same preprocessing as inference model

- **Design tradeoffs**: CNN (0.83 accuracy, 0.92 cancer recall) vs SVM (0.78 accuracy, 0.83 cancer recall): CNN better for sensitivity; SVM offers interpretability and low-compute deployment. VGG16 transfer learning underperformed (0.77 validation)—ImageNet weights may not transfer well to acoustic spectrograms

- **Failure signatures**: CNN test accuracy exceeding validation accuracy (0.83 vs 0.78) warrants investigation; significant age imbalance (p<0.0001) between groups; smoking status confound (57.6% cancer vs 21.1% healthy "ever smoked")

- **First 3 experiments**: 1) Validate preprocessing pipeline by inspecting 10 random segmented cough events; 2) Establish baseline with stratified 5-fold CV and log per-fold metrics; 3) Probe confounding variables by training auxiliary classifier to predict age group from cough features

## Open Questions the Paper Calls Out
- Can automatic cough analysis effectively detect NSCLC at early clinical stages (I-II) rather than solely advanced stages (IIIB-IV)?
- Does the model distinguish NSCLC-specific acoustic features from respiratory changes caused solely by smoking habits?
- To what extent does the significant age disparity between the study cohorts bias the model's classification performance?
- What factors explain the discrepancy where the CNN model performed better on the held-out test set than during cross-validation?

## Limitations
- Significant age imbalance (median 71y vs 45y) between cancer and healthy groups may cause model to learn age rather than disease
- Small test set (~23 samples) yields unstable metrics and limits generalizability
- Large smoking status imbalance (57.6% cancer vs 21.1% healthy "ever smoked") creates confounding risk
- Dataset not publicly available, preventing independent validation

## Confidence
- **High confidence**: CNN architecture and evaluation methodology are clearly specified and achieve best performance
- **Medium confidence**: SVM results may be confounded by age/smoking factors despite interpretability benefits
- **Medium confidence**: Fairness evaluation shows minor disparities but age EOD (0.15) indicates demographic bias

## Next Checks
1. **Confounding analysis**: Train auxiliary models to predict age and smoking status from cough features; implement age-matched sub-analysis if high accuracy achieved
2. **Cross-validation stability**: Replicate training with 5-fold stratified CV on full dataset; report per-fold metrics and feature distributions
3. **External validation**: Test trained models on independent dataset (different hospital, time period, or population) to verify generalization