---
ver: rpa2
title: 'Zero-shot Generalization in Inventory Management: Train, then Estimate and
  Decide'
arxiv_id: '2411.00515'
source_url: https://arxiv.org/abs/2411.00515
tags:
- demand
- inventory
- parameter
- lead
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the Train, then Estimate and Decide (TED) framework
  to train and deploy Generally Capable Agents (GCAs) in inventory management with
  unknown parameters. The framework uses a Super-MDP formulation to capture uncertainty
  in problem parameters, trains a GCA (GC-LSN) on a broad range of instances, estimates
  parameters during deployment, and applies the trained policy without retraining.
---

# Zero-shot Generalization in Inventory Management: Train, then Estimate and Decide

## Quick Facts
- arXiv ID: 2411.00515
- Source URL: https://arxiv.org/abs/2411.00515
- Reference count: 40
- Primary result: GC-LSN outperforms traditional policies by 0.5-8.8% when parameters are known; matches or beats state-of-the-art online learning algorithms within 200-2000 periods when parameters are unknown

## Executive Summary
This paper introduces the Train, then Estimate and Decide (TED) framework for zero-shot generalization in inventory management. TED trains a Generally Capable Agent (GCA) on a Super-MDP that captures uncertainty across multiple inventory problem instances, then deploys the trained policy by estimating unknown parameters from observations. The framework enables inventory systems to apply learned policies without retraining when parameters are unknown, achieving near-optimal performance through parameter estimation during deployment. Empirical results show GC-LSN outperforms traditional policies and matches state-of-the-art online learning algorithms, even surpassing clairvoyant benchmarks early in the planning horizon.

## Method Summary
The TED framework operates in three phases: Train, Estimate, and Decide. During training, Super-DCL samples parameterizations from a bounded parameter space P̂ and simulates MDP instances to train a GCA (GC-LSN) that conditions on both state and parameters. The neural network architecture takes (state, parameter) pairs as input and outputs actions via a classifier trained with Cross-Entropy Loss. During deployment, Kaplan-Meier estimation handles censored demand while empirical frequencies estimate lead times. The trained GCA receives estimated parameters and current state to select actions without retraining. The approach assumes bounded parameter spaces and Lipschitz continuity to provide theoretical guarantees on performance degradation when parameters are estimated rather than known.

## Key Results
- GC-LSN outperforms base-stock and capped base-stock policies by 0.5-8.8% in known-parameter settings
- GC-LSN-E matches or exceeds state-of-the-art online learning algorithms within 200-2000 periods in unknown-parameter settings
- GC-LSN-E surpasses clairvoyant benchmarks (C-BSP) early in the planning horizon (200-500 periods)
- Performance degrades gracefully as true parameters deviate from training bounds (5-10% cost increase at moderate deviations)

## Why This Works (Mechanism)

### Mechanism 1
The Super-MDP formulation enables a single policy to handle multiple inventory problem instances by treating each parameterization as a member of a broader MDP population. Instead of solving each MDP instance separately, the Super-MDP M_S = (P, S, A, H, F) captures all possible MDPs arising from parameterizations p ∈ P. The GCA learns a mapping π_S: S × P → A that conditions on both state and parameters. This works under the core assumption that problem parameters can be bounded a priori and the parameter space admits a metric where small parameter differences induce bounded changes in dynamics and costs (Lipschitz condition).

### Mechanism 2
Super-DCL trains a GCA to generalize across parameterizations by incorporating parameters as input features and using domain randomization during training. The algorithm extends Deep Controlled Learning by sampling parameterizations from P̂, simulating MDPs for each, and training a neural network classifier to map (state, parameterization) pairs to near-optimal actions. Uniform sampling over P̂ aims to cover the true parameter space, allowing the agent to effectively apply learned distinctions during testing by recognizing similar parameter patterns.

### Mechanism 3
Consistent parameter estimators combined with the GCA achieve near-optimal performance as observations accumulate. During deployment, estimators Y map observations O_t to parameter estimates p̂_t, which are fed to the trained GCA. Under Lipschitz conditions and consistent estimators, the per-period cost gap is bounded by a weighted sum of parameter estimation errors. As the estimator converges, the performance gap shrinks, explaining why GC-LSN-E surpasses clairvoyant benchmarks early in the horizon as parameter estimates improve.

## Foundational Learning

- **Concept: Markov Decision Processes (MDPs)**
  - Why needed here: The Super-MDP builds on classical MDPs; understanding states, actions, transitions, and policies is prerequisite
  - Quick check question: Given an MDP tuple (S, A, f, C, s_0), can you describe how a policy π maps states to actions and how costs accumulate?

- **Concept: Lipschitz continuity and parameterization distance**
  - Why needed here: The theoretical guarantees (Theorem 1) rely on small parameter changes inducing bounded changes in dynamics and costs
  - Quick check question: If two parameterizations p_i and p_j differ by distance d, what does it mean for transition functions f_{p_i} and f_{p_j} to be Lipschitz with constant L_f?

- **Concept: Censored demand and Kaplan-Meier estimation**
  - Why needed here: Real-world inventory often observes sales, not true demand; understanding non-parametric estimation under censoring is critical
  - Quick check question: When demand is censored by stockouts, why does naive empirical distribution under-estimate true demand? How does Kaplan-Meier address this?

## Architecture Onboarding

- **Component map**: Super-MDP constructor → parameter sampler (P̂, Ĥ) → Super-DCL (simulator + classifier) → GCA weights (GC-LSN) → Observation buffer → Kaplan-Meier/empirical frequencies → parameter estimates p̂_t → State encoder → feature concatenation (state + p̂_t) → GCA inference → action

- **Critical path**: 1) Define P̂ bounds based on domain knowledge; 2) Train GC-LSN via Super-DCL with uniform sampling over P̂; 3) At deployment, initialize with robust parameterization; then update estimates each period and query GC-LSN

- **Design tradeoffs**: Wider P̂ improves coverage but increases compute (longer training, larger action space); narrower P̂ risks missing true parameters. Discrete parameters fix network input dimensions; extrapolation to unseen values is not supported. Simulation depth H vs. budget M: deeper simulations improve action estimates but slow training.

- **Failure signatures**: True parameters outside P̂: performance degrades as p or μ move beyond training bounds. Inconsistent estimators: performance gap does not shrink over time; check censoring patterns. Non-Lipschitz costs: theoretical guarantees may not hold.

- **First 3 experiments**: 1) Validate GC-LSN on Case 1 with known parameters; compare vs. base-stock and capped base-stock to confirm baseline performance. 2) Deploy GC-LSN-E with unknown demand on Lyu et al. (2024) test bed; track profit vs. horizon to verify estimation-policy coupling. 3) Stress-test robustness: vary μ and p beyond training bounds; plot relative cost gap vs. C-BSP to identify degradation thresholds.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the TED framework maintain robustness and theoretical guarantees when applied to inventory settings with Service Level Agreement (SLA) constraints? The conclusion states TED can be extended to SLA settings where ensuring the Lipschitz property becomes more nuanced. This remains unresolved because SLA penalty functions often violate the Lipschitz smoothness required for theoretical guarantees, potentially breaking zero-shot generalization bounds.

- **Open Question 2**: How can the TED framework be adapted to handle non-stationary demand environments where the underlying distribution evolves dynamically rather than repeating cyclically? The conclusion suggests exploring experimental cases where demand distributions evolve but remain unknown, requiring alternative estimators beyond Kaplan-Meier. This is unresolved because Kaplan-Meier assumes the distribution is static within the estimation window, while time-series forecasting models like ARIMA would be needed for drifting distributions.

- **Open Question 3**: How can the framework be extended to handle scenarios where structural problem parameters—such as the demand cycle length (K) or the presence of order crossover (l)—are unknown? Assumption 3 explicitly states the model assumes we know the cycle length K and whether lead times are deterministic or stochastic, identifying a limitation in current structural knowledge. This is unresolved because learning or estimating these structural parameters from raw data involves a combinatorial search space not addressed by current parameterization distance metrics.

## Limitations

- Super-MDP formulation relies on a priori bounded parameter spaces and Lipschitz continuity, which may not hold in real-world inventory systems with unbounded or discontinuous dynamics
- Approach uses discrete parameter grids for network inputs, preventing extrapolation to unseen parameter values beyond training bounds
- Domain randomization coverage depends heavily on sampling budget and may leave gaps for rare but plausible parameter combinations

## Confidence

- **High confidence**: Known-parameter performance gains (0.5-8.8% over base-stock), simulation-based deployment results, basic algorithmic components
- **Medium confidence**: Theoretical guarantees under Lipschitz conditions, estimation accuracy bounds, robustness claims to parameter deviations
- **Low confidence**: Real-world applicability with non-stationary parameters, performance with highly censored data, scalability to high-dimensional parameter spaces

## Next Checks

1. Test extrapolation failure by evaluating trained policies on parameter values 20-30% beyond training bounds to quantify performance degradation
2. Measure estimator convergence under extreme censoring (90%+ stockout rate) to identify when Kaplan-Meier becomes unreliable
3. Validate Lipschitz assumptions by computing actual parameter-to-cost gradients across the training space to check theoretical guarantee applicability