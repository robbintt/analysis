---
ver: rpa2
title: Hard Negative Sampling via Large Language Models for Recommendation
arxiv_id: '2504.04726'
source_url: https://arxiv.org/abs/2504.04726
tags:
- negative
- hard
- hnlmrec
- semantic
- negatives
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HNLMRec, a novel framework that addresses
  the issue of false hard negatives in traditional recommendation systems by leveraging
  large language models (LLMs) for semantic negative sampling. The method generates
  negative samples that are behaviorally distinct yet semantically relevant to user
  preferences by integrating collaborative filtering signals into LLMs via supervised
  fine-tuning.
---

# Hard Negative Sampling via Large Language Models for Recommendation

## Quick Facts
- arXiv ID: 2504.04726
- Source URL: https://arxiv.org/abs/2504.04726
- Authors: Chu Zhao; Enneng Yang; Yuting Liu; Jianzhe Zhao; Guibing Guo
- Reference count: 40
- One-line primary result: HNLMRec improves NDCG@20 by 7.89% on Toys & Games and 7.91% on CDs & Vinyl compared to best baseline with LightGCN backbone

## Executive Summary
This paper addresses the critical issue of False Hard Negative Samples (FHNS) in recommendation systems, where semantically similar items are incorrectly classified as negatives despite being relevant to user preferences. The proposed HNLMRec framework leverages large language models to generate semantically meaningful negative samples that maintain behavioral distinction while avoiding FHNS. Through a two-stage pipeline combining supervised fine-tuning of LLMs with traditional collaborative filtering backbones, HNLMRec demonstrates significant performance improvements across multiple real-world datasets while mitigating popularity bias and handling sparse data conditions effectively.

## Method Summary
HNLMRec employs a two-stage pipeline to generate semantically relevant hard negatives. First, it performs supervised fine-tuning of Llama3-8B-Instruct using LoRA, training on hybrid prompts that combine collaborative filtering signals with semantic profiles. The fine-tuning uses InfoNCE loss against CF-mined hard negatives. In the second stage, the fine-tuned LLM generates hard negative embeddings offline, which are then projected through a self-attention and MLP layer before being used to train the recommendation backbone with BPR loss plus alignment objectives. The method operates on four real-world datasets with preprocessing that filters low ratings and removes sparse users/items, achieving substantial improvements in Recall@10/20 and NDCG@10/20 metrics.

## Key Results
- Improves NDCG@20 by 7.89% on Toys & Games dataset with LightGCN backbone
- Improves NDCG@10 by 7.91% on CDs & Vinyl dataset with LightGCN backbone
- Demonstrates robust performance under sparse data conditions and on unpopular items
- Effectively mitigates popularity bias compared to traditional methods

## Why This Works (Mechanism)
The method works by leveraging LLMs' semantic understanding to generate negatives that are behaviorally distinct yet semantically relevant, addressing the core problem of FHNS. Traditional CF methods often misclassify semantically similar items as negatives, leading to noisy training signals. By integrating collaborative signals into the LLM through supervised fine-tuning, HNLMRec creates a semantic embedding space that respects both behavioral patterns and semantic relevance. The alignment loss in the second stage ensures that the generated negatives are properly positioned in the embedding space to provide meaningful contrastive learning signals without introducing false negatives.

## Foundational Learning
- **False Hard Negative Sampling (FHNS)**: When semantically similar but behaviorally relevant items are incorrectly classified as negatives, degrading model performance. Why needed: FHNS is a fundamental problem in CF that leads to noisy training signals. Quick check: Compute overlap between generated negatives and held-out positives (should be < 5%).
- **Supervised Fine-Tuning (SFT) with LoRA**: Parameter-efficient adaptation of LLMs using low-rank adaptation techniques. Why needed: Enables integration of collaborative signals into LLMs without full model retraining. Quick check: Verify SFT loss decreases and embeddings align with collaborative signals.
- **InfoNCE Loss**: Contrastive loss that pulls similar items together while pushing dissimilar items apart. Why needed: Provides effective training signal for aligning semantic and collaborative embeddings. Quick check: Monitor InfoNCE loss during SFT and ensure it converges.

## Architecture Onboarding

Component map: User profiles + Item profiles -> LLM SFT -> Hard negative embeddings -> Projector -> Backbone (MF/NGCF/LightGCN) -> Recommendations

Critical path: The SFT stage is critical as it establishes the semantic understanding needed for proper negative sampling. The alignment loss in the second stage ensures generated negatives are properly positioned for effective contrastive learning.

Design tradeoffs: The method trades computational cost (offline generation of hard negatives) for improved semantic quality of negatives. Using LoRA enables parameter-efficient fine-tuning but may limit the model's ability to fully capture complex collaborative patterns.

Failure signatures: Poor performance indicates either FHNS (high overlap between negatives and positives) or semantic-collaborative misalignment (divergent embedding distributions). Monitor both during training.

First experiments:
1. Train backbone to convergence and extract embeddings to establish baseline performance
2. Implement SFT stage with small dataset subset to verify alignment loss works correctly
3. Generate hard negatives and compute similarity with held-out positives to check FHNS rate

## Open Questions the Paper Calls Out
None

## Limitations
- Missing critical hyperparameters (temperature values, loss weights, LoRA configurations) make faithful reproduction challenging
- Method's effectiveness may be limited to specific backbones and negative sampling strategies used in experiments
- Computational cost of offline hard negative generation and LLM fine-tuning may be prohibitive for some applications

## Confidence

| Claim | Confidence |
|-------|------------|
| HNLMRec significantly outperforms traditional methods | High |
| Experimental setup is clearly specified | Medium |
| Claims about robustness to data sparsity are supported | Low |

## Next Checks
1. Conduct hyperparameter sensitivity analysis varying τc, τs, λ1, λ2, and LoRA configurations to identify optimal settings
2. Perform ablation study comparing HNLMRec's performance using different hard negative mining strategies (DNS vs. MixGCF)
3. Apply the method to a new dataset (MovieLens) with a different backbone (NeuMF) to evaluate generalization and scalability