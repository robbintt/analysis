---
ver: rpa2
title: Better Rates for Private Linear Regression in the Proportional Regime via Aggressive
  Clipping
arxiv_id: '2505.16329'
source_url: https://arxiv.org/abs/2505.16329
tags:
- have
- which
- then
- where
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides the first tight bounds for differentially private
  linear regression in the proportional regime (where the number of training samples
  n is proportional to the input dimension d) by considering a clipping regime where
  clipping happens frequently. The authors analyze a one-pass DP-SGD algorithm with
  aggressive clipping (where the clipping constant Cclip is of the same order as the
  typical per-sample gradients) and establish a deterministic equivalent for the DP-SGD
  trajectory in terms of ordinary differential equations (ODEs).
---

# Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping

## Quick Facts
- arXiv ID: 2505.16329
- Source URL: https://arxiv.org/abs/2505.16329
- Authors: Simone Bombari; Inbar Seroussi; Marco Mondelli
- Reference count: 40
- Primary result: First tight bounds for differentially private linear regression in the proportional regime (n ∝ d) via aggressive clipping

## Executive Summary
This paper provides the first tight bounds for differentially private linear regression in the proportional regime (where the number of training samples n is proportional to the input dimension d) by considering a clipping regime where clipping happens frequently. The authors analyze a one-pass DP-SGD algorithm with aggressive clipping (where the clipping constant C_clip is of the same order as the typical per-sample gradients) and establish a deterministic equivalent for the DP-SGD trajectory in terms of ordinary differential equations (ODEs). This approach leads to constant-order upper bounds on the test risk in the proportional regime, which is an improvement over prior work that diverges logarithmically in n or the failure probability. The analysis is sharp enough to identify optimal hyperparameters and learning rate schedules, demonstrating the optimality of aggressive clipping and the benefits of fast-decaying learning rates and private noise scheduling.

## Method Summary
The paper analyzes a one-pass DP-SGD algorithm with aggressive clipping for differentially private linear regression in the proportional regime. The method uses a clipping constant C_clip proportional to typical gradient norms (c√d), coordinated with learning rate and noise schedules. The key innovation is establishing a deterministic equivalent for the DP-SGD trajectory via coupled ODEs, enabling precise risk bounds. The noise schedule satisfies ρ²σ_k² = η_k² - η_{k+1}², coupling privacy budget with learning rate decay. The analysis shows that aggressive clipping with appropriate learning rate compensation yields optimal trade-offs between descent efficiency and privacy noise.

## Key Results
- First tight bounds for DP linear regression in the proportional regime (n ∝ d)
- Constant-order upper bounds on test risk (vs logarithmic divergence in prior work)
- Demonstration that aggressive clipping (C_clip = O(√d)) is optimal in this regime
- Identification of optimal learning rate schedules (polynomial decay with α ≈ ln ln(1/γ))
- Deterministic ODE characterization of DP-SGD trajectory in high dimensions

## Why This Works (Mechanism)

### Mechanism 1: Aggressive Clipping with Learning Rate Compensation
Setting C_clip proportional to typical gradient norms (rather than much larger) reduces injected noise while maintaining descent dynamics, yielding tighter risk bounds in the proportional regime. By reducing C_clip to O(√d) and compensating with larger η such that η·c remains constant, the descent term stays effective while noise term shrinks. The descent reduction factor μ_c(θ) approaches a constant for small c, preserving optimization signal. Core assumption: gradient distribution is sufficiently symmetric; data covariance Σ is well-conditioned (κ = λ_max/λ_min = Θ(1)).

### Mechanism 2: Homogenized SDE to Deterministic ODE Mapping
The stochastic DP-SGD trajectory converges to a deterministic equivalent described by coupled ODEs, enabling precise risk bounds. Via Doob decomposition, the discrete DP-SGD updates decompose into predictable drift + martingale noise. In high dimensions (n,d → ∞, d/n → γ), martingale terms concentrate, leaving ODE dynamics. Three terms in SDE: (i) gradient descent via μ_c, (ii) SGD noise via ν_c, (iii) private noise via c²σ². Core assumption: Gaussian data; one-pass DP-SGD; η(t) bounded above by 2/γ for stability.

### Mechanism 3: Coordinated Learning Rate and Noise Decay Scheduling
Polynomial learning rate decay (η(t) ∝ (1-t)^α) with coordinated noise scheduling via ρ²σ_k² = η_k² - η_{k+1}² improves over output perturbation, optimally with α ≈ ln ln(1/γ). Output perturbation adds all noise at end; decaying schedules spread noise across iterations while reducing it near convergence. The ODE analysis reveals risk scales as O(γ·ln(1/γ)/(1+α)) for descent term and O(γ²·ln²(1/γ)/(ρ²(1+α)²)) for noise term—faster decay reduces both. Core assumption: Privacy budget ρ = Θ(1) constant-order; γ = d/n sufficiently small.

## Foundational Learning

- **Concept: Zero-Concentrated Differential Privacy (zCDP)**
  - Why needed: The paper uses zCDP rather than (ε,δ)-DP. Understanding Rényi divergence and the amplification-by-iteration argument is essential to follow the privacy proof.
  - Quick check: Can you explain why zCDP allows tracking privacy loss additively across iterations, and how it converts to (ε,δ)-DP?

- **Concept: Gradient Clipping Bias-Variance Trade-off**
  - Why needed: The aggressive clipping regime creates bias (μ_c < 1 reduces descent speed) but reduces variance (less noise injection). The paper's main contribution is characterizing this trade-off precisely.
  - Quick check: If clipping threshold C_clip is halved while learning rate η is doubled, what happens to the effective descent direction and the privacy noise magnitude?

- **Concept: High-Dimensional Proportional Regime Asymptotics**
  - Why needed: All results assume n,d → ∞ with d/n → γ. This is neither classical (fixed d) nor overparameterized (d ≫ n) but a middle regime where ODE approximations become exact.
  - Quick check: Why does the martingale term vanish as n,d → ∞ in the Doob decomposition, and why doesn't this happen in finite dimensions?

## Architecture Onboarding

- **Component map:**
  - Algorithm 1 (DP-SGD) -> H-DP-SGD (SDE) -> ODE System (4.9) -> Hyperparameter relationship (4.2)

- **Critical path:**
  1. Verify data assumptions (Gaussian, well-conditioned Σ, normalized tr(Σ)=d)
  2. Set privacy budget ρ, derive target zCDP guarantee
  3. Choose schedule α based on γ = d/n (larger α for smaller γ)
  4. Set c = O(1), compute η(0) = C·ln(1/γ)/(c·λ_min)
  5. Verify stability: η(0) < 2/γ
  6. Run one-pass Algorithm 1, output θ_n

- **Design tradeoffs:**
  - Small c (aggressive clipping): Less noise, slower descent—requires larger η to compensate
  - Large α (fast decay): Better asymptotic rates, but worse for moderate n—Figure 3 shows crossover
  - Output perturbation (α=0): Simpler, no intermediate noise, but worse rates for large n

- **Failure signatures:**
  - Risk diverges if η(0) > 2/γ (adaptive cap activates, breaking ODE equivalence)
  - Risk saturates at O(1) if c too large (noise dominates per Theorem 2 lower bounds)
  - Last-iterate noise spike if η(1) > 0 (treat via Proposition 4.4 correction)

- **First 3 experiments:**
  1. Validate ODE convergence: Run Algorithm 1 with d ∈ {100, 1000, 10000}, fixed γ=0.1, plot R(θ_k) vs ODE bounds R(t), R̅(t)—verify convergence as d increases
  2. Hyperparameter sweep: Fix d=1000, vary c ∈ [0.1, 10] and η(0) ∈ [0.1, 100], heatmap of final risk—verify diagonal band η·c ≈ ln(1/γ) is optimal
  3. Schedule comparison: Run α ∈ {0, 0.5, 1, 2} for varying n with fixed d=1000, plot R(θ_p) vs n—verify crossover where larger α becomes optimal

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the analysis of aggressive clipping and the ODE-based deterministic equivalent be extended to data distributions beyond Gaussian, such as sub-Gaussian data with well-behaved tails? The current proofs rely explicitly on Gaussian assumptions for deriving µ_c and ν_c functions and concentration bounds; the universality of the ODE characterization remains unproven for broader distribution classes.

- **Open Question 2:** What are the optimal learning rate and noise schedules in the general proportional regime where γ = d/n remains constant (not vanishing)? The theoretical analysis explicitly assumes γ → 0, and the ODE solutions become more complex when γ is non-negligible relative to eigenvalue ratios.

- **Open Question 3:** Can the homogenized DP-SGD methodology provide sharp test risk bounds for private logistic regression or other generalized linear models? The quadratic loss structure enables closed-form solutions for the coupled ODEs; non-quadratic losses introduce additional non-linearities in the SDE/ODE dynamics that require new analysis techniques.

## Limitations
- The analysis relies heavily on high-dimensional asymptotics (n,d → ∞ with d/n → γ), with limited empirical validation beyond synthetic Gaussian data
- Privacy analysis uses zCDP rather than pure (ε,δ)-DP, requiring conversion that may affect practical applicability
- The optimal hyperparameter relationship (η·c ∝ ln(1/γ)) is derived asymptotically and may not hold for moderate n/d ratios

## Confidence

- **High Confidence:** The improvement over prior logarithmic divergence bounds in the proportional regime; the ODE characterization of the DP-SGD trajectory
- **Medium Confidence:** The optimality of aggressive clipping and the specific η·c trade-off; the benefits of polynomial learning rate decay with noise scheduling
- **Low Confidence:** Practical performance on non-Gaussian data; robustness to ill-conditioned covariance matrices; extension beyond linear regression

## Next Checks

1. **Robustness to Covariance Conditioning:** Repeat experiments with κ ∈ {10, 100, 1000} to verify Theorem 3 bounds hold beyond κ = Θ(1)
2. **Last Iterate Analysis:** Validate Proposition 4.4's correction for the last iterate noise spike by comparing ODE predictions with actual DP-SGD trajectories for t ∈ [0.9, 1.0]
3. **Cross-Distribution Testing:** Test the algorithm on non-Gaussian data distributions (e.g., Laplace, t-distribution) to assess sensitivity to the Gaussian assumption in the analysis