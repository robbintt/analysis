---
ver: rpa2
title: A Data-Driven Multi-Objective Approach for Predicting Mechanical Performance,
  Flowability, and Porosity in Ultra-High-Performance Concrete (UHPC)
arxiv_id: '2512.21610'
source_url: https://arxiv.org/abs/2512.21610
tags:
- uhpc
- strength
- data
- performance
- included
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: A data-driven multi-objective machine learning framework was developed
  to predict the mechanical performance, flowability, and porosity of ultra-high-performance
  concrete (UHPC). The framework integrated XGBoost with hyperparameter tuning, outlier
  detection, and SHAP-based feature selection, trained on 1,201 data points from 17
  mixture design parameters.
---

# A Data-Driven Multi-Objective Approach for Predicting Mechanical Performance, Flowability, and Porosity in Ultra-High-Performance Concrete (UHPC)

## Quick Facts
- arXiv ID: 2512.21610
- Source URL: https://arxiv.org/abs/2512.21610
- Reference count: 40
- Key outcome: A data-driven multi-objective machine learning framework was developed to predict the mechanical performance, flowability, and porosity of ultra-high-performance concrete (UHPC). The framework integrated XGBoost with hyperparameter tuning, outlier detection, and SHAP-based feature selection, trained on 1,201 data points from 17 mixture design parameters. Results showed high predictive accuracy with R² values of 0.94, 0.99, 0.97, 0.91, and 0.89 for compressive strength, flexural strength, tensile strength, flowability, and porosity, respectively. Outlier removal and feature selection improved model performance. A GUI was developed to support UHPC mix design, reducing the need for extensive experimental testing.

## Executive Summary
This paper presents a comprehensive data-driven multi-objective machine learning framework for predicting the mechanical performance, flowability, and porosity of ultra-high-performance concrete (UHPC). The framework employs XGBoost as the core prediction engine, enhanced by a two-stage data refinement process involving outlier detection using Isolation Forest and feature selection via SHAP analysis. Trained on a dataset of 1,201 UHPC mixture designs with 17 input parameters, the model achieves high predictive accuracy across five target properties. The study demonstrates that data cleaning and feature selection significantly improve model performance and interpretability. A user-friendly GUI was developed to facilitate practical implementation by engineers, reducing the need for extensive experimental testing.

## Method Summary
The study developed a multi-objective regression framework using XGBoost to predict five UHPC properties: compressive strength, flexural strength, tensile strength, flowability, and porosity. The methodology involved a two-stage process: (1) initial XGBoost model training on raw data with hyperparameter tuning via random search and 10-fold cross-validation, and (2) data refinement through multicollinearity filtering (Pearson correlation > 0.7), outlier detection using Isolation Forest (10% contamination), and feature selection using SHAP analysis. The dataset consisted of 1,201 samples with 17 mixture design parameters. Models were evaluated using R², RMSE, MAE, and MaxAE metrics on a held-out 30% test set.

## Key Results
- XGBoost achieved high predictive accuracy with R² values of 0.94 (compressive strength), 0.99 (flexural strength), 0.97 (tensile strength), 0.91 (flowability), and 0.89 (porosity) on test sets
- The two-stage data refinement process reduced RMSE for compressive strength from 11.73 to 8.01 and for porosity from 1.76 to 1.17
- Out of 21 tested algorithms, XGBoost showed the best performance after hyperparameter tuning
- SHAP analysis identified curing age, water-to-binder ratio, and steel fiber content as the most influential features for compressive strength prediction

## Why This Works (Mechanism)

### Mechanism 1
A two-stage data refinement process (outlier detection + feature selection) improves generalization compared to training on raw data. Isolation Forest identifies anomalies via shorter average path lengths in random binary trees; SHAP analysis quantifies per-feature contribution to predictions, enabling removal of low-impact inputs. The retrained XGBoost on cleaned data (Model 2) reduces noise and dimensionality, which appears to lower RMSE and maintain or improve R² on test sets. Core assumption: Outliers identified by Isolation Forest represent noise rather than valid extreme cases; removing them does not discard rare but important mixture designs. Evidence anchors: Table 8 shows RMSE reduction from 11.73 to 8.01 for compressive strength and from 1.76 to 1.17 for porosity when comparing Model 1 to Model 2. Break condition: If outlier removal shrinks the training set significantly (>15–20%) or if domain experts flag removed points as valid edge cases, the contamination ratio (currently 10%) should be reduced or replaced with domain-informed filtering.

### Mechanism 2
XGBoost with random search hyperparameter tuning and 10-fold cross-validation achieves higher predictive accuracy than 20 other tested algorithms for UHPC properties. Gradient boosting iteratively corrects residual errors from prior trees, capturing non-linear interactions among mixture components. Random search samples hyperparameter configurations more efficiently than grid search, while K-fold CV provides robust performance estimates by averaging across multiple train/validation splits. Core assumption: The 70/30 train-test split and 10-fold CV adequately represent model generalization despite the modest dataset size (1,201 points); no severe distribution shift exists between training and future data. Evidence anchors: Table 4 shows XGBoost achieving Test R² = 0.94 and RMSE = 8.62 for compressive strength, outperforming Random Forest, Gradient Boosting, Extra Tree, and CatBoost. Break condition: If cross-validation scores show high variance across folds (>10% R² fluctuation), this suggests data heterogeneity; consider stratified sampling or increasing dataset size rather than relying solely on hyperparameter tuning.

### Mechanism 3
SHAP-based feature selection identifies physically meaningful mixture components, improving model interpretability and enabling targeted mix design optimization. SHAP values allocate prediction credit among input features using game-theoretic Shapley values, revealing directional effects (positive/negative contribution) for each mixture parameter across the dataset. Core assumption: SHAP importance rankings generalize to unseen mixture designs; features with low SHAP contribution are genuinely non-influential rather than having context-dependent effects. Evidence anchors: Fig. 5 and Section 4.4 describe how curing age, water-to-binder ratio, and steel fiber content dominate compressive strength prediction, while coarse aggregate and hydration temperature show minimal impact and were excluded. Break condition: If excluded features are later found to have strong interaction effects (e.g., coarse aggregate affects strength only at specific fiber contents), consider re-including them or using interaction-aware SHAP variants.

## Foundational Learning

- Concept: **Gradient Boosting (XGBoost)**
  - Why needed here: Core prediction engine; understanding how boosting sequentially corrects errors helps diagnose overfitting and tune depth/learning rate.
  - Quick check question: Can you explain why a lower learning rate (e.g., 0.01) combined with more trees might improve generalization compared to a higher learning rate with fewer trees?

- Concept: **Isolation Forest for Outlier Detection**
  - Why needed here: Used to clean the dataset before retraining; understanding its unsupervised nature prevents misinterpreting its output as error probability.
  - Quick check question: In Isolation Forest, why are outliers typically isolated in fewer splits than normal points, and how does the contamination parameter affect the threshold?

- Concept: **SHAP (SHapley Additive exPlanations)**
  - Why needed here: Drives feature selection and interpretability; understanding local vs. global explanations ensures correct use of summary plots vs. individual predictions.
  - Quick check question: If a feature has near-zero mean SHAP value but high variance across instances, what might this indicate about its role in the model?

## Architecture Onboarding

- Component map: Data Ingestion → Z-normalization → 70/30 split → Initial XGBoost (Model 1) → Multicollinearity reduction → Isolation Forest (10% contamination) → SHAP feature selection → Refined XGBoost (Model 2) → Evaluation (MAE, RMSE, R², MaxAE) → GUI deployment

- Critical path: 1. Data collection and standardization (17 input features, 5 output targets) 2. Baseline model comparison (21 algorithms with default hyperparameters) 3. XGBoost selection → hyperparameter tuning 4. Data cleaning (outlier removal, feature selection via SHAP) 5. Model 2 retraining and validation (including out-of-set test)

- Design tradeoffs:
  - **Contamination ratio (10%)**: Higher values remove more noise but risk losing valid data; requires calibration against domain knowledge.
  - **Feature exclusion based on SHAP**: Reduces overfitting but may discard context-dependent effects; trade-off between simplicity and completeness.
  - **70/30 split vs. cross-validation**: 70/30 provides a held-out test set for final evaluation; 10-fold CV guides hyperparameter selection but increases computational cost.

- Failure signatures:
  - High training R² (>0.95) with low test R² (<0.80): Likely overfitting; reduce max_depth, increase regularization (lambda_l1/l2), or expand dataset.
  - SHAP shows counter-intuitive feature directions (e.g., water increasing compressive strength): May indicate data quality issues or unaccounted confounding variables.
  - Out-of-set validation error >20%: Model may not generalize; investigate distribution shift in input features or target ranges.

- First 3 experiments:
  1. **Baseline reproduction**: Train Model 1 (raw data, default XGBoost) on the 1,201-point dataset; confirm reported test R² (~0.94 for compressive strength) using the same 70/30 split.
  2. **Ablation study on outlier removal**: Compare Model 2 performance with contamination ratios of 5%, 10%, and 15%; track RMSE and R² to identify optimal noise-to-signal balance.
  3. **Feature sensitivity test**: Re-train Model 2 with previously excluded features (e.g., coarse aggregate, hydration temperature) reinstated; quantify impact on R² and SHAP importance to validate exclusion decisions.

## Open Questions the Paper Calls Out

- **Question**: Can deep learning methods coupled with explainable AI techniques improve the predictability and interpretability of UHPC properties beyond the current XGBoost framework?
  - **Basis in paper**: The authors explicitly state that future research should use "explainable AI methods like deep learning" to enhance model interpretability and user trust.
  - **Why unresolved**: While the current XGBoost model showed high accuracy (R² > 0.89), the authors acknowledge that improving interpretability is necessary to encourage adoption by material designers and construction engineers.
  - **What evidence would resolve it**: A comparative study evaluating the performance and explainability of deep learning models versus the XGBoost model on the same dataset.

- **Question**: How can machine learning frameworks be integrated with Life Cycle Assessment (LCA) to evaluate the economic and environmental impacts of different UHPC compositions?
  - **Basis in paper**: The authors suggest that future studies should combine machine learning and LCA to assess UHPC compositions' economic and environmental impacts to facilitate green infrastructure development.
  - **Why unresolved**: The current study focused exclusively on predicting mechanical performance, flowability, and porosity, without incorporating sustainability metrics or cost analysis into the multi-objective framework.
  - **What evidence would resolve it**: A new model framework that includes carbon footprint and cost as additional target variables alongside mechanical properties.

- **Question**: What is the impact of combining machine learning with multiscale modeling on the understanding of microstructural-macroscopic connections in UHPC?
  - **Basis in paper**: The authors propose that future studies use machine learning combined with multiscale modeling to study UHPC behavior, specifically noting the benefit of microstructural-macroscopic connections.
  - **Why unresolved**: The current data-driven approach relies solely on mixture design inputs (macroscopic) and lacks integration of microstructural data or physics-based modeling to explain the underlying mechanisms.
  - **What evidence would resolve it**: A hybrid model that successfully correlates microstructural features (e.g., pore size distribution) with macroscopic mechanical properties to provide physical insights.

- **Question**: What simplified tools or methodologies can be developed to allow practical engineers to implement data-driven UHPC design without requiring advanced AI expertise?
  - **Basis in paper**: The authors note that implementing the current technique without AI is difficult and state that more research is needed to provide practical engineers with a simple tool for specific applications.
  - **Why unresolved**: Although a GUI was developed, the underlying complexity of the XGBoost model, SHAP analysis, and hyperparameter tuning may still present a barrier to field engineers.
  - **What evidence would resolve it**: The development of a user-friendly decision-support system or simplified analytical equations derived from the complex model for field deployment.

## Limitations
- The core dataset (1,201 UHPC mixtures) is not publicly available, requiring reconstruction from literature sources or direct author access
- Outlier detection relies on Isolation Forest with a fixed 10% contamination ratio, which may inadvertently remove valid extreme mixtures without domain expertise validation
- Feature exclusion based on SHAP values assumes no context-dependent interactions; low-SHAP features might still be important in specific mixture regions but were removed for simplicity
- Model generalizability is demonstrated on a single dataset; no external validation on chemically or formulationally different UHPC mixes is provided

## Confidence
- **High confidence**: XGBoost achieves high R² (>0.90) on test sets for most targets; the two-stage data refinement (outlier removal + SHAP selection) demonstrably reduces RMSE across targets
- **Medium confidence**: Claims about interpretability via SHAP are supported, but physical validation of excluded features is limited to correlation and importance scores rather than mechanistic testing
- **Low confidence**: The optimal contamination ratio (10%) and exact feature exclusion criteria are not experimentally justified beyond reported performance gains

## Next Checks
1. **Dataset Reconstruction**: Reconstruct the 1,201-point dataset from cited references; verify Z-score normalization and 70/30 split match the paper's methodology
2. **Ablation on Outlier Threshold**: Retrain Model 2 with contamination ratios of 5%, 10%, and 15%; track RMSE and R² to quantify robustness of the 10% choice
3. **External Generalization Test**: Apply the trained model to a small, chemically distinct UHPC dataset (if available) to assess performance drop and distribution shift effects