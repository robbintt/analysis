---
ver: rpa2
title: An Unsupervised Deep Explainable AI Framework for Localization of Concurrent
  Replay Attacks in Nuclear Reactor Signals
arxiv_id: '2508.09162'
source_url: https://arxiv.org/abs/2508.09162
tags:
- replay
- data
- attack
- time
- signals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an unsupervised explainable AI framework
  for detecting and localizing replay attacks in nuclear reactor signals. The method
  combines a deep autoencoder trained on normal reactor data with a customized windowSHAP
  algorithm to identify falsified signals, timing, and duration in real time.
---

# An Unsupervised Deep Explainable AI Framework for Localization of Concurrent Replay Attacks in Nuclear Reactor Signals

## Quick Facts
- arXiv ID: 2508.09162
- Source URL: https://arxiv.org/abs/2508.09162
- Reference count: 40
- An unsupervised AI framework achieves >95% accuracy in detecting and localizing concurrent replay attacks in nuclear reactor signals

## Executive Summary
This paper introduces a framework that detects and localizes replay attacks in nuclear reactor signals using an unsupervised deep learning approach. The method combines an LSTM autoencoder trained on normal reactor data with a customized windowSHAP algorithm to identify which signals were falsified, when the attack occurred, and for how long. Tested on six concurrent replay attack scenarios using real data from Purdue's PUR-1 reactor, the framework successfully identifies attack timing and duration with over 95% accuracy, even under complex non-stationary conditions like reactor SCRAM events.

## Method Summary
The framework employs a two-stage training approach: first training an LSTM autoencoder on normal operational data, then transfer-learning on SCRAM data to handle transients. During deployment, it processes multivariate time series through 10-second sliding windows, computing reconstruction errors via MAE/MSE. When errors exceed a threshold (0.15), a modified windowSHAP algorithm with dynamic baselines identifies which signals and time windows contributed most to the anomaly. This enables both detection and temporal localization of replay attacks without requiring labeled attack data.

## Key Results
- Achieved over 95% accuracy in detecting and characterizing concurrent replay attacks
- Successfully identified which of six signals were replayed and attack duration
- Maintained performance under non-stationary conditions including reactor SCRAM events
- Demonstrated ability to localize attacks temporally with ~10-second resolution

## Why This Works (Mechanism)

### Mechanism 1: Reconstruction Error as a Proxy for Inter-Signal Consistency
An LSTM-based autoencoder trained on normal multivariate reactor data fails to reconstruct replay attack inputs accurately because falsified signals maintain individual patterns but violate learned cross-correlations between sensors. The core assumption is that normal reactor operation exhibits consistent, learnable relationships among signals that replay attacks will disrupt.

### Mechanism 2: WindowSHAP for Temporal Attribution
The method divides time series into non-overlapping 10-second windows and treats each as a single unit for Shapley value calculation. Positive Shapley values indicate deviation from expected baseline; negative values indicate consistency. This modified approach makes computation feasible while preserving temporal attribution capability.

### Mechanism 3: Dynamic Baseline for Non-Stationary Conditions
Standard SHAP occludes features with global averages, which is inappropriate for rapid transients like SCRAM. The framework sets the baseline to expected signal behavior during the event, dynamically updated as the event evolves. This enables meaningful interpretation of Shapley values during non-stationary reactor conditions.

## Foundational Learning

- **Concept: Autoencoders for Anomaly Detection**
  - Why needed here: The framework relies on the principle that an autoencoder trained only on normal data will reconstruct normal inputs well and anomalous inputs poorly. Understanding this asymmetry is essential for interpreting reconstruction errors.
  - Quick check question: If you train an autoencoder on data containing both normal and anomalous samples, what happens to its ability to detect anomalies?

- **Concept: Shapley Values and Feature Attribution**
  - Why needed here: SHAP provides a game-theoretic approach to quantifying each feature's contribution to a model output. Understanding additive feature attribution is necessary to interpret the windowSHAP results.
  - Quick check question: If a feature has a Shapley value of zero, does that mean it had no influence on the output, or that its influence balanced out across different coalitions?

- **Concept: Non-Stationary vs. Stationary Time Series**
  - Why needed here: The paper explicitly addresses non-stationary reactor signals where statistical properties change over time. Standard anomaly detection methods often assume stationarity and may fail under transient conditions.
  - Quick check question: Why would a method that thresholds based on fixed mean and variance fail during a reactor SCRAM event?

## Architecture Onboarding

- **Component map**: Data Preprocessing -> Module 1 (LSTM Autoencoder) -> Module 2 (Error Analysis) -> Module 3 (XAI Attribution)
- **Critical path**: 1) Collect and normalize historical normal operation data across all reactor modes 2) Train autoencoder to minimize reconstruction error 3) Transfer-learn on SCRAM data to refine transient reconstruction 4) During deployment: compute reconstruction error → if above threshold, invoke windowSHAP → analyze Shapley values to identify falsified signals and attack duration
- **Design tradeoffs**: Window size (10s) trades temporal precision for computational feasibility; threshold (0.15) balances sensitivity and false positives; dynamic baseline accuracy depends on expected transient behavior knowledge; unsupervised approach cannot distinguish replay attacks from other anomalies
- **Failure signatures**: High false positives during normal transients if threshold is too low; missed attacks if replayed signals are weakly correlated; incorrect signal attribution if baseline does not match actual reactor state; ~10-second lag in attack end detection
- **First 3 experiments**: 1) Baseline reconstruction test: train AE on full-cycle data only; measure reconstruction error on held-out normal SCRAM data 2) Single-signal replay validation: inject replay on one signal during SCRAM; verify windowSHAP correctly identifies it 3) Multi-signal concurrent attack test: inject concurrent replay on all six target signals; verify identification and Shapley value patterns

## Open Questions the Paper Calls Out

### Open Question 1
Can a Point Kinetics Equation (PKE) model replace event-specific baselines to generalize the framework for arbitrary transient conditions? The current method relies on dynamic baselines tailored to known events like SCRAMs, limiting applicability to unscripted operational states.

### Open Question 2
How does increasing input dimensions affect the computational scalability and real-time latency of the windowSHAP module? While effective for 9 signals, the combinatorial complexity of Shapley values may introduce latency in high-dimensional industrial systems.

### Open Question 3
Can the temporal distribution of Shapley values reliably distinguish replay attacks from False Data Injection (FDI) or sensor malfunctions? The framework currently localizes replay attacks but does not explicitly validate classification against other anomalies.

### Open Question 4
How does the framework perform under realistic network impairments like packet loss or transmission delays? Real-world networks are unreliable; missing data could distort the LSTM's reconstruction errors and subsequent SHAP explanations.

## Limitations
- Dynamic baseline generation for windowSHAP during SCRAM events is not fully specified, creating reproducibility gaps
- Results validated on a single reactor (PUR-1) with proprietary data; generalizability remains untested
- 10-second window size limits attack detection granularity to ~10-second intervals
- Framework cannot distinguish replay attacks from other anomalies without additional domain rules

## Confidence

- **High confidence**: Reconstruction error mechanism for anomaly detection (well-established in autoencoder literature)
- **Medium confidence**: WindowSHAP temporal localization accuracy (methodologically sound but specific validation limited to this dataset)
- **Medium confidence**: Dynamic baseline effectiveness (adaptation is logical but empirical validation is reactor-specific)

## Next Checks

1. **Baseline sensitivity test**: Vary the dynamic baseline generation method (physics model vs. empirical average) and measure impact on SHAP attribution accuracy
2. **Cross-domain transfer**: Apply the framework to a different multivariate time series dataset (e.g., power grid signals) and compare detection/localization performance
3. **Attack indistinguishability test**: Evaluate whether the framework can differentiate replay attacks from sensor faults by analyzing reconstruction error patterns and SHAP attribution differences