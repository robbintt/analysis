---
ver: rpa2
title: Edge Attention Module for Object Classification
arxiv_id: '2502.03103'
source_url: https://arxiv.org/abs/2502.03103
tags:
- pooling
- have
- attention
- proposed
- max-min
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an Edge Attention Module (EAM) for object
  classification that uses a novel Max-Min pooling technique to extract edge information
  from images. The EAM is designed to address challenges like class imbalance and
  inter-class similarity by focusing on salient edge features.
---

# Edge Attention Module for Object Classification

## Quick Facts
- **arXiv ID:** 2502.03103
- **Source URL:** https://arxiv.org/abs/2502.03103
- **Reference count:** 40
- **Primary result:** Achieves 95.5% accuracy on Caltech-101 and 86% on Caltech-256, outperforming state-of-the-art models.

## Executive Summary
This paper introduces the Edge Attention Module (EAM), a novel approach to object classification that leverages edge information extracted via a Max-Min pooling operation. The EAM is designed to address challenges like class imbalance and inter-class similarity by focusing on salient edge features. Experiments on Caltech-101, Caltech-256, CIFAR-100, and Tiny ImageNet-200 datasets demonstrate that the proposed EAM framework outperforms state-of-the-art models like PiT, CBAM, and ConvNext, setting new benchmarks on Caltech datasets.

## Method Summary
The Edge Attention Module (EAM) uses a novel Max-Min pooling technique to extract edge information from images. This operation computes the deviation between maximum and minimum intensity values within a 5x5 window, which is crucial for object classification. The EAM is integrated as a parallel branch splitting from the 2nd-to-last convolutional block of pretrained CNNs. It passes through Max-Min pooling, three convolutional layers, and Global Average Pooling (GAP), before being concatenated with the main branch's GAP output. The framework is flexible, allowing for multiple EAMs, and is validated through Grad-CAM heatmaps and 5-fold cross-validation.

## Key Results
- Achieves 95.5% accuracy on Caltech-101, outperforming state-of-the-art models.
- Sets a new benchmark with 86% accuracy on Caltech-256.
- Demonstrates robustness on CIFAR-100 and Tiny ImageNet-200 datasets.
- Validated through Grad-CAM heatmaps and 5-fold cross-validation.

## Why This Works (Mechanism)
The EAM works by focusing on edge information, which is crucial for distinguishing objects, especially in datasets with high inter-class similarity. The Max-Min pooling operation captures the deviation between maximum and minimum intensity values, effectively highlighting salient edge features. By integrating this as a parallel branch, the model can leverage both the original features and the edge-enhanced features, leading to improved classification accuracy.

## Foundational Learning
- **Max-Min Pooling:** A custom pooling operation that computes the deviation between maximum and minimum intensity values within a window. Why needed: To extract edge information effectively. Quick check: Verify that the operation produces non-zero values on sample images.
- **Edge Attention Module (EAM):** A parallel branch that processes edge information extracted by Max-Min pooling. Why needed: To focus on salient edge features for improved classification. Quick check: Ensure the EAM branch is correctly integrated and produces meaningful features.
- **Global Average Pooling (GAP):** Reduces spatial dimensions while retaining important features. Why needed: To prepare features for concatenation with the main branch. Quick check: Verify that GAP outputs are of the expected size.
- **Stratified Data Splitting:** Ensures each class is proportionally represented in train, validation, and test sets. Why needed: To handle class imbalance effectively. Quick check: Confirm that the split maintains class proportions.
- **Early Stopping:** Prevents overfitting by halting training when validation loss stops improving. Why needed: To ensure model generalization. Quick check: Monitor validation loss and ensure it plateaus before stopping.
- **Grad-CAM Heatmaps:** Visualizes the regions of an image that contribute most to the classification decision. Why needed: To validate the model's focus on relevant features. Quick check: Generate heatmaps and verify they highlight important regions.

## Architecture Onboarding
- **Component Map:** Input Image -> Pre-trained CNN Backbone -> EAM Branch (Max-Min Pool -> 3 Conv Layers -> GAP) -> Concatenation with Main Branch GAP -> Classifier
- **Critical Path:** Input -> Backbone -> EAM (if used) -> GAP -> Concatenation -> Classifier
- **Design Tradeoffs:** The EAM introduces additional parameters and computational overhead but significantly improves accuracy, especially on datasets with class imbalance and high inter-class similarity.
- **Failure Signatures:** Vanishing gradients or zero outputs in the EAM branch due to homogeneous images or small pooling windows. Overfitting on Caltech-256 if base model layers are not frozen.
- **First Experiments:**
    1. Implement and validate the Max-Min pooling layer on sample images.
    2. Test EAM integration on Caltech-101 using DenseNet-121 with the 65-15-20 stratified split.
    3. Evaluate layer freezing on Caltech-256 to prevent overfitting.

## Open Questions the Paper Calls Out
None

## Limitations
- The exact configuration of the EAM branch, particularly the number of filters for the three convolutional layers, is not fully specified.
- The specific optimizer used is not explicitly named, though the learning rate schedule suggests Adam.
- The exact configuration for "2EAMs" is described loosely, leading to potential variations in results.

## Confidence
- **High Confidence:** The core innovation of the Max-Min pooling operation and its integration as a parallel attention branch are clearly described. The reported performance improvements are statistically significant and reproducible.
- **Medium Confidence:** The overall framework and training procedure are well-specified, but minor variations in the EAM's internal architecture or optimizer choice could slightly affect the final accuracy.
- **Low Confidence:** None for the core claims; the uncertainties are primarily architectural details.

## Next Checks
1. Implement and validate the Max-Min pooling layer on sample images to ensure it produces non-zero, meaningful edge deviation values.
2. Reproduce the DenseNet-121 + 1xEAM configuration on Caltech-101 using the 65-15-20 stratified split to verify the reported 95.5% accuracy.
3. Confirm that freezing 50% of the base model's layers on Caltech-256 prevents overfitting, as indicated by stable validation loss and improved generalization.