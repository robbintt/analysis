---
ver: rpa2
title: 'Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to
  Images'
arxiv_id: '2502.06434'
source_url: https://arxiv.org/abs/2502.06434
tags:
- dataset
- images
- pruning
- labels
- distillation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies critical flaws in large-scale dataset compression
  evaluation, showing that existing dataset distillation methods relying on soft labels
  often underperform simple random baselines. The authors establish a fair benchmark
  by unifying evaluation protocols and demonstrate that an overemphasis on soft labels
  diverts focus from the intrinsic value of image data.
---

# Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images

## Quick Facts
- arXiv ID: 2502.06434
- Source URL: https://arxiv.org/abs/2502.06434
- Reference count: 40
- Primary result: Achieves up to 45.5% accuracy on ImageNet-1K with only 100 images per class using hard labels only

## Executive Summary
This paper identifies critical flaws in large-scale dataset compression evaluation, showing that existing dataset distillation methods relying on soft labels often underperform simple random baselines. The authors establish a fair benchmark by unifying evaluation protocols and demonstrate that an overemphasis on soft labels diverts focus from the intrinsic value of image data. They propose the Prune, Combine, and Augment (PCA) framework, which exclusively uses hard labels and applies pruning insights to select representative, balanced, and "easy" images. PCA combines images and applies scaling-law-aware augmentation to enhance performance without requiring pretrained models or storing soft labels. Extensive experiments on ImageNet-1K show that PCA consistently surpasses both random baselines and state-of-the-art methods across various model architectures, achieving up to 45.5% accuracy with only 100 images per class. The framework reduces storage and computational costs while shifting research focus back to the images themselves, paving the way for more balanced and accessible dataset compression techniques.

## Method Summary
The PCA framework operates in three stages: (1) Prune - uses EL2N (Error L2-Norm) metric to select "easy" samples with strict class balance, (2) Combine - merges selected images into composite images (typically 2x2 grids), and (3) Augment - applies patch extraction during augmentation to preserve sample simplicity while following scaling-law principles. The method exclusively uses hard labels, eliminating soft-label information leakage from pretrained models. EL2N scores are computed using early training dynamics (10 epochs), and augmentation uses patch extraction rather than patch shuffling to maintain the "easy" property of selected samples. The framework is evaluated on ImageNet-1K with various IPC (Images Per Class) configurations.

## Key Results
- Random selection with soft labels achieves competitive performance to SOTA methods, revealing soft-label information leakage
- PCA with hard labels achieves up to 45.5% accuracy on ImageNet-1K with only 100 images per class
- EL2N-based pruning consistently outperforms other metrics (Forgetting score, AUM) across soft and hard label settings
- Patch extraction augmentation outperforms patch shuffling by 9.9% at IPC-10
- Cross-architecture generalization shows PCA-selected datasets maintain performance across different model architectures

## Why This Works (Mechanism)

### Mechanism 1: Soft-Label Information Leakage Masking Image Quality
Soft labels from pretrained models provide sufficient signal for student networks to learn even from random noise, thereby masking deficiencies in compressed image quality. Distillation training with soft labels transfers predictive distributions from a teacher model. The student optimizes to match these distributions, gaining class-relevant knowledge directly from the labels rather than image features. This external knowledge source inflates performance metrics without requiring meaningful image content. Break condition: If soft labels are unavailable (hard-label-only evaluation), performance collapses dramatically—SRe2L drops from 33.5% to 1.5% (Table 5).

### Mechanism 2: Easy-Sample Selection via Low-Entropy Pruning
Selecting "easy" samples (low EL2N scores) with strict class balance produces compressed datasets that align with scaling laws for small data regimes. EL2N (Error L2-Norm) measures prediction error early in training. Low EL2N samples are easier to classify and provide clearer gradient signal. At extreme compression ratios (99%+ pruning), selecting easy samples maintains learnability, while class balance prevents bias toward majority classes. Break condition: If the pruning metric (e.g., Forgetting score) has poor discriminability—many samples share identical scores—selection becomes random within that score band (see Appendix D.4).

### Mechanism 3: Scaling-Law-Aware Patch Extraction Preserving Sample Simplicity
Patch extraction during augmentation, rather than patch shuffling, preserves the "easy" property of selected samples by constraining crop scope. Combined images contain multiple selected samples. Random patch shuffling increases entropy and complexity, violating pruning rules. Patch extraction confines RandomResizedCrop to within a single patch, preventing the creation of unnecessarily complex training examples. This aligns augmentation with the scaling-law principle that small datasets benefit from simpler samples. Break condition: If crop ratio r is too large (r→1.0), augmentation provides insufficient variability; if too small (r→0.01), entropy increases and performance degrades (Table 11).

## Foundational Learning

- **Concept: EL2N (Error L2-Norm) as Sample Difficulty Metric**
  - Why needed here: PCA uses EL2N to rank samples; understanding how it measures "easiness" is essential for selecting appropriate pruning metrics.
  - Quick check question: Given a model with 90% accuracy, which sample would have lower EL2N: one predicted at 0.95 confidence for the correct class, or one at 0.55 confidence?

- **Concept: Soft Labels vs. Hard Labels in Knowledge Distillation**
  - Why needed here: The paper's central critique is that soft labels inflate performance; distinguishing what each provides clarifies when hard-label-only evaluation is appropriate.
  - Quick check question: If a teacher model outputs [0.7, 0.2, 0.1] for a 3-class problem, what information is lost when converting to a hard label?

- **Concept: Shannon Entropy as Dataset Complexity Measure**
  - Why needed here: The paper uses entropy to justify patch extraction over shuffling; understanding entropy quantifies why certain augmentations violate pruning rules.
  - Quick check question: A dataset where all samples produce identical predictions has what entropy value? How does random cropping typically affect entropy?

## Architecture Onboarding

- **Component map:**
  EL2N scorer -> sample ranking -> strict class-balanced selection -> selected samples -> N-way image composition -> combined image -> RandomResizedCrop with limited crop ratio -> standard augmentations (flip, Cutout preferred)

- **Critical path:**
  1. Compute EL2N scores using early training dynamics (10 epochs on full dataset)
  2. Select top-k samples per class (k = IPC value)
  3. Combine N selected images into composite images
  4. Configure augmentation pipeline with patch extraction strategy

- **Design tradeoffs:**
  - EL2N vs. AUM: EL2N requires only 10 epochs; AUM needs full training (90 epochs) for margin accumulation—EL2N is more efficient
  - Patch extraction vs. shuffling: Extraction preserves simplicity; shuffling increases diversity but violates scaling law
  - Cutout vs. CutMix/Mixup: Cutout maintains label integrity; label mixing degrades performance in small data regimes

- **Failure signatures:**
  - Performance collapses to random baseline levels: Check if soft labels were accidentally included
  - Class imbalance in selected subset: Verify strict balance enforcement
  - High variance across runs: Forgetting score may lack discriminability (many zeros)
  - Performance degrades with smaller IPC: Augmentation may be violating scaling law (check crop ratio)

- **First 3 experiments:**
  1. **Baseline validation:** Run random selection + hard labels on ImageNet-1K IPC-10 with standard augmentation—target ~4.6% to confirm environment matches paper
  2. **Pruning metric comparison:** Compare EL2N vs. Forgetting vs. AUM on IPC-50 hard-label setup—expect EL2N and AUM ~31%, Forgetting significantly lower
  3. **Augmentation ablation:** Test patch extraction vs. patch shuffling on PCA-selected IPC-10 dataset—expect ~18% improvement gap

## Open Questions the Paper Calls Out

### Open Question 1
Can the "scaling-law-aware" augmentation strategies, specifically patch extraction, be theoretically optimized rather than relying on heuristic design? The authors state in the Limitations section that "our augmentation procedures... are heuristically designed. While they demonstrate strong empirical effectiveness, their optimality is not theoretically guaranteed." A theoretical analysis linking patch extraction entropy bounds to generalization error, or a counter-example proving sub-optimality in specific data regimes, would resolve this.

### Open Question 2
How does the PCA framework perform when applied to high-quality synthetic or pre-distilled datasets rather than the original raw dataset? Appendix G notes, "There is significant value in considering pruning on potentially high-performing distilled datasets... or on generated datasets (e.g., diffusion-based DD methods)." Experimental benchmarks comparing PCA on original ImageNet data versus PCA applied to outputs from diffusion models or dataset distillation methods like YOCO would resolve this.

### Open Question 3
Can dataset compression frameworks like PCA be adapted to explicitly optimize for non-accuracy metrics such as model robustness or fairness? Appendix G states, "Future frameworks might also jointly optimize additional metrics, such as robustness, fairness, or interpretability, while maintaining the same compressed dataset constraint." Experiments measuring out-of-distribution robustness or class-wise fairness metrics on models trained with PCA-compressed datasets would resolve this.

### Open Question 4
What is the optimal interchange of modules within the PCA framework regarding pruning metrics and combining strategies? Appendix G mentions, "Given that the proposed PCA functions as a framework, there is potential to explore different choices of the modules, such as pruning metrics, combining strategies, and specific augmentation methods." A systematic ablation study or meta-analysis comparing diverse pruning metrics paired with alternative combining strategies would resolve this.

## Limitations
- Soft-label leakage inflating performance metrics is well-demonstrated, but PCA's superiority is largely shown within its own evaluation protocol, limiting direct comparison with existing methods
- The optimal grid size for image combination and exact patch extraction implementation details remain underspecified, potentially affecting reproducibility
- The relationship between early-training error and long-term sample quality could be theoretically stronger to support the easy-sample selection principle

## Confidence

- **High Confidence:** Soft-label leakage inflating performance metrics; random baselines with soft labels can match or exceed SOTA methods with hard labels. This is directly demonstrated through controlled ablation studies.
- **Medium Confidence:** EL2N-based pruning consistently selecting better samples than random baselines; the easy-sample selection principle aligns with scaling laws for small datasets. While empirical results support this, the theoretical grounding connecting early-training error to long-term sample quality could be stronger.
- **Medium Confidence:** Patch extraction outperforming patch shuffling in augmentation; the entropy-based justification is reasonable but the augmentation design remains somewhat heuristic without extensive ablation on the exact crop ratio parameters.

## Next Checks
1. **Soft-label ablation verification:** Replicate the controlled experiment showing random selection with soft labels achieving competitive accuracy (Table 5) to confirm the magnitude of soft-label leakage effect.
2. **Cross-architecture generalization:** Test PCA-selected IPC-100 dataset on architectures not used in the original evaluation (e.g., ConvNeXt, EfficientNet) to verify the claimed cross-architecture performance claims.
3. **Grid size sensitivity analysis:** Systematically vary the image combination grid size (1x2, 2x2, 3x3) while keeping IPC constant to quantify the impact on final accuracy and identify optimal configuration.