---
ver: rpa2
title: Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability
arxiv_id: '2512.24842'
source_url: https://arxiv.org/abs/2512.24842
tags:
- triangulation
- causal
- predicate
- language
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Triangulation is an acceptance rule for mechanistic interpretability
  that requires necessity (ablating a proposed circuit degrades target behavior),
  sufficiency (patching from predicate-aligned sources transfers behavior), and invariance
  (causal effects remain stable across predicate-preserving environments) across multiple
  languages, scripts, and cultures. It formalizes this as an approximate transformation
  score over interchange interventions, grounding it in causal abstraction theory
  while providing empirical falsifiers for surface-cue mechanisms.
---

# Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability

## Quick Facts
- **arXiv ID:** 2512.24842
- **Source URL:** https://arxiv.org/abs/2512.24842
- **Reference count:** 16
- **Primary result:** Triangulation is an acceptance rule for mechanistic interpretability that requires necessity, sufficiency, and invariance across multiple languages, scripts, and cultures.

## Executive Summary
Triangulation provides a framework for validating mechanistic interpretability claims in multilingual settings by requiring circuits to demonstrate necessity (ablating them degrades target behavior), sufficiency (patching from predicate-aligned sources transfers behavior), and invariance (causal effects remain stable across predicate-preserving environments) across multiple languages, scripts, and cultures. It formalizes this as an approximate transformation score over interchange interventions, grounding it in causal abstraction theory while providing empirical falsifiers for surface-cue mechanisms. The framework applies to multilingual translation and extends naturally to multimodal settings, filtering spurious circuits that pass single-environment tests but fail cross-lingual invariance.

## Method Summary
The framework constructs reference families with predicate-preserving variants across languages, runs circuit discovery per environment using methods like EAP-IG or ACDC, fits translation maps for cross-lingual patching, and evaluates acceptance via interchange interventions. The triangulation score T_tri combines necessity (ablation drop), sufficiency (predicate-swap transfer), and invariance (stability across environments plus failure on cue-only falsifiers). Acceptance requires T_tri ≥ η, with explicit stress tests to validate predicate preservation and detect spurious circuits.

## Key Results
- Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance
- The framework operationalizes approximate causal abstraction via interchange interventions between low-level transformer mechanisms and abstract predicate-level models
- Valid multilingual mechanisms may combine shared cross-lingual components with language-specific adapter subcircuits, provided translated patching transfers predicate-level effects

## Why This Works (Mechanism)

### Mechanism 1: Cross-Environment Invariance as Spurious Circuit Filter
- Claim: Circuits that rely on surface cues (language identity, script, punctuation) will fail cross-lingual stability tests even if they pass single-environment patching.
- Mechanism: When a circuit causally depends on the predicate Z rather than nuisance C, patching between predicate-matched inputs across environments should produce small effects (|Δswap| ≤ ε). Surface-cue circuits show large effects under cue-only falsifiers.
- Core assumption: Reference families genuinely preserve predicates (Assumption 1: π(rk) = π(x) for all family members).

### Mechanism 2: Approximate Causal Abstraction via Interchange Interventions
- Claim: Triangulation score Ttri operationalizes whether a low-level mechanism behaves like an abstract predicate-level mechanism under a distribution of interventions.
- Mechanism: Ttri = EI~P[Sim(τ(Solve(LI)), τ(Solve(Hω(I))))] — expected similarity between low-level and abstract outcomes under interchange interventions (knockout, predicate-swap, stability, cue-only).
- Core assumption: The abstract model H implements invariant prediction: conditional on Z, behavior is independent of environment E.

### Mechanism 3: Mechanism-Class Architecture (Shared + Language-Specific Adapters)
- Claim: Valid multilingual mechanisms may combine shared cross-lingual components with language-specific adapter subcircuits, provided translated patching transfers predicate-level effects.
- Mechanism: A mechanism class C = {Ce}e∈E with translation maps {Te←e'} supports stable abstraction-level intervention semantics even with heterogeneous low-level implementations. Acceptance requires min_e Ttri(e) ≥ η.
- Core assumption: Translation maps can be learned on predicate-matched pairs without leakage into acceptance evaluation.

## Foundational Learning

- **Concept:** Structural Causal Models (SCMs) and intervention distributions
  - Why needed: The entire framework formalizes transformer forward passes as SCMs with exogenous (Z, E) and endogenous (X, V, Y, M) variables; interchange interventions are operations on this structure.
  - Quick check: Given an SCM with variables (Z, E, X, V, Y), what does it mean to intervene on V versus condition on V?

- **Concept:** Causal Abstraction (exact and approximate transformation)
  - Why needed: Triangulation is defined as an approximate transformation score; understanding when low-level interventions commute with high-level semantic changes is the theoretical foundation.
  - Quick check: If L is a transformer and H is an abstract predicate model, what must hold for H to be an exact causal abstraction of L?

- **Concept:** Activation Patching / Interchange Interventions
  - Why needed: The operational tests (necessity via knockout, sufficiency via predicate-swap patching) are all interchange interventions; translated patching extends this cross-lingually.
  - Quick check: For a base input xb and source xs, what does Ipatch(C; xb ← xs) do, and why might cross-language patching require translation maps?

## Architecture Onboarding

- **Component map:** Predicate function π(X) → Z extracts semantic property; Reference family R(x) = {r1,...,rK} provides predicate-preserving variants; Candidate circuit C ⊆ {1,...,m} selects internal sites; Mechanism class {Ce} + translation maps {Te←e'} enables cross-env alignment; Task score M(Y) measures behavioral metric; Intervention families include I_KO, I_patch, I_stability, I_cue.

- **Critical path:** 1. Construct reference families with predicate audits (checkers + stress tests), 2. Run automatic discovery per environment → {Ce}, 3. Fit translation maps on held-out predicate-matched pairs, 4. Sample interventions I ~ P, compute Sim(I) for each, 5. Estimate Ttri via Beta-Binomial posterior; check per-environment scores.

- **Design tradeoffs:** Stricter η thresholds reduce false positives but may reject genuine circuits with language-specific components; larger reference families increase compute but improve invariance signal; LLM judges for predicate checking risk circularity; rule-based/human checks preferred.

- **Failure signatures:** Lexicalization failure (T_incl ∩ supp(pθ) = ∅), agreement failure (M(x) > 0 but output gender is binary), cue sensitivity (|Δcue| > ε or stability violations → spurious circuit).

- **First 3 experiments:** 1. Pilot on FairTranslate EN→FR with 2-language reference family (EN, DE); verify predicate checkers achieve κ ≥ 0.8 on stress-test violations, 2. Compare acceptance rates: single-environment patching vs. triangulation on the same discovered circuits; quantify false-positive reduction, 3. Ablation study: remove cue-only falsifiers from P and measure increase in accepted circuits that fail manual cross-lingual inspection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does triangulation achieve a superior trade-off between accepting genuine mechanisms and rejecting spurious circuits compared to single-environment patching or causal scrubbing baselines?
- Basis: Section 4.4 states the key question is whether triangulation achieves a better trade-off, rejecting circuits that fail cross-lingual invariance while retaining circuits that pass it.
- Why unresolved: The paper provides a protocol but does not present comparative empirical results.
- What evidence would resolve it: Experimental data showing triangulation's false positive/negative rates on known ground-truth circuits compared to baselines.

### Open Question 2
- Question: How should the framework handle non-uniqueness when multiple redundant circuits satisfy the necessity, sufficiency, and invariance criteria?
- Basis: Discussion section notes triangulation identifies sufficient mechanisms but does not guarantee uniqueness if effects are redundant.
- Why unresolved: The acceptance rule validates mechanism classes but lacks a constraint to distinguish between functionally equivalent but structurally distinct implementations.
- What evidence would resolve it: An extension of the triangulation score incorporating minimality or complexity penalties that reliably selects the canonical circuit.

### Open Question 3
- Question: How sensitive is the triangulation score to imperfect predicate preservation in reference families, particularly for low-resource languages?
- Basis: Discussion warns that poor-quality families can mislead and notes that using LLM judges for semantic preservation risks circularity.
- Why unresolved: While stress tests are proposed, the tolerance of the method to the inevitable noise in semantic translation or style transfer for complex predicates remains unquantified.
- What evidence would resolve it: A sensitivity analysis correlating triangulation acceptance rates with measured predicate-preservation error rates across different language pairs.

## Limitations
- Translation map fidelity across tokenizers/languages remains critical and unknown; off-manifold patching collapse could invalidate cross-lingual transfer claims.
- Reference family quality directly impacts invariance tests; poor predicate preservation will cause false rejections of genuine circuits.
- Acceptance thresholds (τ_N, τ_S, ε, η) are not empirically grounded; without calibration studies, the framework risks arbitrary filtering.

## Confidence
- **High Confidence:** The theoretical foundation connecting triangulation to causal abstraction theory is sound.
- **Medium Confidence:** Cross-environment invariance as a spurious circuit filter is promising but requires careful reference family construction.
- **Low Confidence:** Quantitative claims about false-positive reduction and specific threshold values cannot be verified without replication data.

## Next Checks
1. **Translation Map Stress Test:** Systematically vary translation map quality and measure impact on T_tri scores for known circuits to identify failure points.
2. **Reference Family Auditing:** Construct deliberately flawed reference families with subtle predicate violations and verify the framework rejects them at higher rates than clean families.
3. **Threshold Calibration:** Run triangulation acceptance on circuits with known ground truth across multiple η values and plot precision-recall curves to identify optimal thresholds and placebo-adjusted baselines.