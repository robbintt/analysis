---
ver: rpa2
title: 'Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals
  from Fetal Electrocardiograms'
arxiv_id: '2504.13233'
source_url: https://arxiv.org/abs/2504.13233
tags:
- signals
- fecg
- data
- signal
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Auto-FEDUS, an autoregressive generative
  model that maps fetal electrocardiogram (FECG) signals to corresponding Doppler
  ultrasound (DUS) waveforms for fetal health monitoring. The model leverages dilated
  causal convolutions to capture both short and long-range temporal dependencies in
  physiological signals, enabling high-fidelity cross-modal signal generation.
---

# Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms

## Quick Facts
- **arXiv ID:** 2504.13233
- **Source URL:** https://arxiv.org/abs/2504.13233
- **Reference count:** 10
- **Primary result:** Auto-FEDUS outperforms GANs on cross-modal DUS generation from FECG with 4.5 bpm Bland-Altman limit for heart rate estimation

## Executive Summary
Auto-FEDUS is an autoregressive generative model that maps fetal electrocardiogram (FECG) signals to corresponding Doppler ultrasound (DUS) waveforms for fetal health monitoring. The model leverages dilated causal convolutions to capture both short and long-range temporal dependencies in physiological signals, enabling high-fidelity cross-modal signal generation. Evaluated on a clinical dataset, Auto-FEDUS outperforms conventional generative architectures (autoencoder, LSTM-GAN, DCGAN, WGAN-GP) across time and frequency domain metrics. Generated DUS signals closely resemble real data in morphology and spectral characteristics, with a Bland-Altman limit of 4.5 bpm for heart rate estimation. A quality assessment model classified all generated segments as good quality. This approach addresses data scarcity in DUS monitoring and supports generalizable fetal health monitoring models.

## Method Summary
Auto-FEDUS is a cross-modal generative model that maps low-frequency FECG signals (250 Hz) to high-frequency DUS waveforms (2 kHz) using autoregressive modeling with dilated causal convolutions. The architecture consists of an initial causal convolution followed by 5 residual blocks with exponentially increasing dilation rates (1, 2, 4, 8, 16). The model is trained on heartbeat-level pairs from a Leipzig University Hospital dataset (5 subjects, 20-27 weeks gestation) using MSE loss with leave-one-subject-out cross-validation. Performance is evaluated through time-domain metrics (RMSE, MAE), frequency-domain metrics (Spectral Entropy, Fréchet Distance), and a downstream FHR estimation task with Bland-Altman analysis.

## Key Results
- Auto-FEDUS outperforms DCGAN, WGAN-GP, and LSTM-GAN baselines across all evaluation metrics
- Generated DUS signals achieve a Bland-Altman limit of agreement of 4.5 bpm for heart rate estimation
- Generated segments classified as high quality by a dedicated quality assessment model
- Model can generate up to 3-beat sequences with maintained quality before degradation occurs

## Why This Works (Mechanism)

### Mechanism 1: Dilated Causal Convolutions for Long-Range Dependency Capture
- **Claim:** Dilated causal convolutions enable the model to capture both short-term waveform details and long-term cardiac cycle dependencies without increasing computational complexity.
- **Core assumption:** The temporal relationship between electrical (FECG) and mechanical (DUS) cardiac activity is consistent and can be modeled as a deterministic function of past inputs.
- **Evidence anchors:** [abstract] "...leveraging a neural temporal network based on dilated causal convolutions... effectively captures both short and long-range dependencies..."; [section] "Methodology" section and Figure 2 describe the residual blocks and dilation rates.
- **Break condition:** Performance degrades when unmodeled physiological variability (e.g., sudden fetal movement, stochastic heart rate variability) introduces elements not present in the input FECG.

### Mechanism 2: Autoregressive Signal-to-Signal Mapping
- **Claim:** An autoregressive approach is more effective than GANs for this cross-modal, low-to-high frequency extrapolation task because it directly models the conditional probability of each DUS sample given the input FECG and previously generated DUS samples.
- **Core assumption:** A deterministic, sample-by-sample generation process guided by a reconstruction loss can produce high-fidelity waveforms, assuming the training data has high signal-to-noise ratio and precise temporal alignment.
- **Evidence anchors:** [abstract] "...novel autoregressive generative model designed to map fetal electrocardiogram (FECG) signals to corresponding DUS waveforms..."; [section] "Related Work" and "Methodology" compare with GANs; "Experiments" show Auto-FEDUS outperforming them on most metrics.
- **Break condition:** The mechanism produces overly smooth outputs if the conditional distribution of DUS given FECG is highly multimodal.

### Mechanism 3: Learning Cross-Modal Physiological Correlation
- **Claim:** The model succeeds by learning the inherent correlation between the electrical (FECG) and mechanical (DUS) aspects of cardiac activity.
- **Core assumption:** The temporal lag between electrical and mechanical signals is consistent enough to be estimated and corrected via cross-correlation of their envelopes.
- **Evidence anchors:** [abstract] "...learn the cross-modality signal-to-signal extrapolation by capturing the inherent correlation between electrical and mechanical cardiac activities."; [section] "Methodology - Study's Workflow" details alignment.
- **Break condition:** Performance degrades on unrepresented pathological cases or when signal acquisition variability is not captured in the model's conditioning.

## Foundational Learning

- **Concept: Causal Convolutions**
  - **Why needed:** Ensures each output sample is generated only from current and past inputs, preventing information leakage from the future.
  - **Quick check:** If you flip a time-series signal and pass it through a standard (non-causal) convolutional layer, the output at a given time step will be identical to the original output at the corresponding step from the end. How would the output of a *causal* convolution differ?

- **Concept: Dilated Convolutions**
  - **Why needed:** Expands the model's receptive field efficiently, integrating information from far back in signal history without parameter explosion.
  - **Quick check:** A 1D convolutional layer has kernel size 3 and dilation rate 4. Which input indices contribute to calculating the output at time step `t`?

- **Concept: Autoregressive (AR) Modeling**
  - **Why needed:** The chosen generative paradigm where the model generates output one sample at a time, conditioned on input and its own previous outputs.
  - **Quick check:** In a pure autoregressive model `p(x) = product(p(x_t | x_<t))`, what is the primary disadvantage compared to a model that can generate all time steps in parallel?

## Architecture Onboarding

- **Component map:** Input FECG Signal → Initial Causal Conv (64 filters, kernel 20) → Residual Block 1 (D=1) → ... → Residual Block 5 (D=16) → Output Head → Generated DUS
- **Critical path:** `Input → Initial Causal Conv → Residual Block 1 (D=1) → ... → Residual Block 5 (D=16) → Output Head → Generated DUS`
- **Design tradeoffs:**
  - Chose AR over GAN for stability and better limited-data performance
  - Used dilation (rates up to 16) for large receptive field with only 5 residual blocks
  - Trained on single beats; can autoregressively generate up to 3-beat sequences well but quality degrades beyond that
- **Failure signatures:**
  - Oversmoothing: Generated DUS lacks fine-grained detail, appearing averaged
  - Temporal drift: Generated signal's timing or morphology slowly diverges in longer sequences
  - Misalignment: Incorrect temporal offset between electrical and mechanical events if not properly aligned
- **First 3 experiments:**
  1. Sanity check on public surrogate data: Retrain on public dataset with paired ECG and PPG/arterial blood pressure to verify dilated causal convolution implementation
  2. Ablation on dilation: Create variants with standard (non-dilated) causal convolutions vs. proposed dilations and compare performance
  3. Receptive field limit test: Systematically evaluate generation quality for sequences of increasing length (1, 2, 3, 4+ beats) to pinpoint exact sequence length where quality metrics fail

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can synthetic DUS signals generated by Auto-FEDUS effectively augment datasets to improve the performance of downstream fetal monitoring tasks, specifically gestational age estimation and heartbeat segmentation?
- **Basis in paper:** [explicit] The authors state, "For future work, we will... assess the benefits of generated DUS signals in developing and improving the performance of various fetal monitoring tasks, including gestational age estimation and heartbeat segmentation."
- **Why unresolved:** The current study validates synthetic signal quality and FHR estimation accuracy but does not evaluate the utility of generated data for training models on segmentation or age estimation tasks.
- **What evidence would resolve it:** A comparative study showing machine learning models trained on a mix of real and Auto-FEDUS-generated data achieve higher accuracy in segmentation and gestational age estimation than models trained on real data alone.

### Open Question 2
- **Question:** How can the Auto-FEDUS architecture be enhanced to conditionally generate DUS signals that reflect specific demographic factors, signal quality levels, or the presence of pathological birth defects?
- **Basis in paper:** [explicit] The authors list as a key plan to "enhance Auto-FEDUS's capability to conditionally account for a range of factors, including demographic considerations, signal quality, and the potential presence of birth defects."
- **Why unresolved:** The current implementation functions as a direct cross-modal translator without explicit mechanisms to control specific output characteristics or simulate pathologies.
- **What evidence would resolve it:** A modified architecture that accepts conditional inputs (e.g., pathology labels) and successfully generates distinct DUS morphologies validated by clinicians as representative of specified conditions.

### Open Question 3
- **Question:** Does the model's performance and efficiency remain robust when evaluated on larger, multi-center datasets and streamlined for deployment on portable, low-power devices?
- **Basis in paper:** [explicit] The paper notes, "Once additional cross-setting datasets become available, the model's performance can be further evaluated and streamlined for deployment on portable devices, enabling real-time generation."
- **Why unresolved:** The current validation is limited to a single hospital dataset with only five subjects, and processing time (0.97 ms/recording) is reported on a server-grade Tesla P100 GPU rather than edge hardware.
- **What evidence would resolve it:** Evaluation results from diverse external datasets and benchmarks demonstrating real-time generation latency and battery usage on target portable hardware.

## Limitations

- **Dataset size and generalizability:** Trained and evaluated on only 5 subjects (20-27 weeks gestation), raising concerns about overfitting and generalizability to broader gestational ages and pathological cases.
- **Temporal drift in long sequences:** Quality degradation occurs beyond 3-beat sequences, but the rate of autoregressive error accumulation is not quantified.
- **Alignment methodology:** The paper describes using cross-correlation for signal alignment but doesn't specify how alignment errors are handled or their impact on model performance.

## Confidence

- **High Confidence:** The core claim that dilated causal convolutions can capture long-range dependencies is well-supported by the architecture description.
- **Medium Confidence:** The claim about cross-modal correlation learning is supported by qualitative waveform similarity but would benefit from ablation studies isolating the conditioning effect.
- **Low Confidence:** Claims about addressing data scarcity and generalizable monitoring models are speculative given the single-center, small-subject study design without external validation.

## Next Checks

1. **External validation study:** Test Auto-FEDUS on a completely independent dataset with different subjects, gestational ages, and acquisition conditions to verify generalizability.
2. **Ablation of conditioning input:** Train the model without FECG input (unconditional generation) to quantify how much performance gain comes specifically from the cross-modal conditioning versus autoregressive modeling alone.
3. **Robustness to misalignment:** Systematically introduce artificial temporal offsets between FECG and DUS pairs during training to measure performance degradation and determine alignment tolerance limits.