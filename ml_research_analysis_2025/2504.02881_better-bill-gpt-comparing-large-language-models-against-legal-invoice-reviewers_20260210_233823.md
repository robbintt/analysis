---
ver: rpa2
title: 'Better Bill GPT: Comparing Large Language Models against Legal Invoice Reviewers'
arxiv_id: '2504.02881'
source_url: https://arxiv.org/abs/2504.02881
tags:
- invoice
- legal
- human
- llms
- reviewers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares the performance of Large Language Models (LLMs)
  against human invoice reviewers in legal billing compliance tasks. Benchmarking
  state-of-the-art LLMs against a ground truth set by expert legal professionals,
  the research evaluates accuracy, speed, and cost-effectiveness.
---

# Better Bill GPT: Comparing Large Language Models against Legal Invoice Reviewers

## Quick Facts
- arXiv ID: 2504.02881
- Source URL: https://arxiv.org/abs/2504.02881
- Reference count: 9
- LLMs achieved 92% accuracy vs humans' 72% ceiling in legal invoice review tasks

## Executive Summary
This study demonstrates that Large Language Models significantly outperform human reviewers in legal invoice compliance tasks across accuracy, speed, and cost metrics. LLMs achieved up to 92% accuracy in invoice approval decisions, surpassing experienced lawyers' 72% ceiling, and reached F-scores of 81% in line-item classification versus 43% for humans. The computational models completed reviews in as fast as 3.6 seconds per invoice compared to 194-316 seconds for human reviewers, while reducing costs by 99.97%. These findings indicate that LLMs represent a transformative shift in legal spend management, though important implementation considerations remain.

## Method Summary
The research benchmarked state-of-the-art LLMs against human invoice reviewers using a ground truth set established by expert legal professionals. Performance was evaluated across three key dimensions: accuracy in invoice approval decisions, speed of review completion, and cost-effectiveness. The study compared LLMs' performance metrics against experienced lawyers' benchmarks, measuring both binary approval accuracy and more nuanced line-item classification through F-scores. Cost calculations incorporated both direct labor expenses and processing time requirements for human reviewers versus automated systems.

## Key Results
- LLMs achieved 92% accuracy in invoice approval decisions versus human reviewers' 72% ceiling
- F-scores reached 81% for LLM line-item classification compared to 43% for human reviewers
- Processing time reduced from 194-316 seconds per invoice for humans to 3.6 seconds for LLMs
- Cost per invoice decreased from $4.27 for humans to mere cents for automated systems

## Why This Works (Mechanism)
Legal invoice review involves pattern recognition and rule application that aligns well with LLM capabilities. The structured nature of billing codes, fee arrangements, and compliance requirements provides clear decision boundaries that LLMs can learn effectively. LLMs excel at processing large volumes of text data, identifying anomalies, and applying consistent judgment criteria across thousands of invoices. The automation eliminates human fatigue, maintains consistent attention to detail, and scales processing capacity without proportional cost increases.

## Foundational Learning
- Legal billing compliance frameworks - why needed: Understanding regulatory requirements and standard billing practices; quick check: Familiarity with common billing code violations and approval criteria
- Invoice review workflows - why needed: Knowledge of how legal professionals evaluate billing entries; quick check: Understanding of line-item scrutiny and approval hierarchies
- Cost-benefit analysis in legal operations - why needed: Context for interpreting efficiency gains; quick check: Ability to calculate ROI for automation implementations
- LLM performance metrics - why needed: Understanding accuracy, precision, recall, and F-score interpretations; quick check: Familiarity with statistical evaluation methods for classification tasks
- Natural Language Processing fundamentals - why needed: Background on how LLMs process and classify text; quick check: Understanding of transformer architectures and fine-tuning processes

## Architecture Onboarding

**Component Map:**
Legal invoice data -> LLM processing pipeline -> Classification module -> Decision output

**Critical Path:**
Invoice ingestion -> Text preprocessing -> Feature extraction -> Classification prediction -> Compliance validation

**Design Tradeoffs:**
The study prioritized accuracy and speed over interpretability, accepting that LLMs function as black boxes. This tradeoff maximizes efficiency but may limit explainability for audit purposes. The architecture emphasizes batch processing capabilities rather than real-time decision making, trading immediate responsiveness for throughput optimization.

**Failure Signatures:**
Model degradation may occur with novel billing scenarios not present in training data, unusual formatting variations, or complex multi-jurisdictional compliance requirements. Performance may also suffer when dealing with handwritten notes or poorly scanned documents. The system may exhibit overconfidence in borderline cases where human judgment would typically seek clarification.

**3 First Experiments:**
1. Test model performance on progressively smaller subsets of training data to establish minimum viable dataset size
2. Compare different fine-tuning approaches using legal-specific versus general-purpose LLMs
3. Evaluate model robustness by introducing controlled variations in invoice formatting and presentation

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on ground truth established by expert legal professionals, creating potential circular validation
- Speed comparisons don't account for quality assurance steps or error correction requirements
- Cost savings calculations assume full automation without human oversight or review processes
- Study doesn't address LLM performance on novel or ambiguous billing scenarios requiring contextual judgment

## Confidence
- High confidence: Speed and cost metrics are based on direct measurements and straightforward calculations
- Medium confidence: Accuracy comparisons are reliable but depend on quality and comprehensiveness of ground truth data
- Medium confidence: F-score comparisons are valid but may not capture all aspects of practical utility

## Next Checks
1. Conduct blind validation studies where independent legal experts verify LLM decisions without knowing the source, to test for potential bias in ground truth data
2. Implement longitudinal study tracking real-world performance over 6-12 months, including error rates and necessary human interventions
3. Test LLM performance on more diverse set of billing scenarios, including edge cases and novel situations not well-represented in training data