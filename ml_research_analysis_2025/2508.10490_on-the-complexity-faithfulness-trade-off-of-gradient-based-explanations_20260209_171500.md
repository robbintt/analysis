---
ver: rpa2
title: On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations
arxiv_id: '2508.10490'
source_url: https://arxiv.org/abs/2508.10490
tags:
- explanation
- relu
- spatial
- power
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a spectral framework to analyze the complexity-faithfulness
  trade-off in gradient-based explanations. It formalizes explanation complexity via
  the Expected Frequency (EF), measuring high-frequency content in gradients, and
  introduces the Explanation Gap as a metric for faithfulness by quantifying deviations
  between surrogates and the original model.
---

# On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations

## Quick Facts
- arXiv ID: 2508.10490
- Source URL: https://arxiv.org/abs/2508.10490
- Authors: Amir Mehrpanah; Matteo Gamba; Kevin Smith; Hossein Azizpour
- Reference count: 40
- This paper introduces a spectral framework to analyze the complexity-faithfulness trade-off in gradient-based explanations.

## Executive Summary
This paper introduces a spectral framework to analyze the complexity-faithfulness trade-off in gradient-based explanations. It formalizes explanation complexity via the Expected Frequency (EF), measuring high-frequency content in gradients, and introduces the Explanation Gap as a metric for faithfulness by quantifying deviations between surrogates and the original model. The authors connect these metrics to the power spectrum tail of ReLU networks, showing that sharper transitions (heavier spectral tails) increase EF and reduce faithfulness. They propose a Smooth Parameterization (SP) of ReLU, controlled by a smoothness parameter β, to reduce high-frequency reliance, validated across datasets and architectures. Results demonstrate that lower β yields simpler explanations (lower EF) and reduced explanation gaps, offering a principled approach to balance interpretability and fidelity. This framework provides a unified, hyperparameter-free method for evaluating and improving gradient-based explanations.

## Method Summary
The method replaces standard ReLU activations with a Smooth Parameterization (SP) using SoftPlus(x; β) = (1/β)·ln(1+exp(β·x)), where β controls smoothness (higher β approximates ReLU). Networks are trained with accuracy caps to ensure fair comparison across β values. VanillaGrad explanations are computed and transformed via 2D Fourier Transform to analyze spatial power spectra. The Expected Frequency (EF) metric quantifies explanation complexity by integrating frequency-weighted spectral density. The Explanation Gap (ΔEF) measures faithfulness by comparing EF between original models and surrogate methods like SmoothGrad or GradCAM. The framework leverages neural tangent kernel theory to connect network spectral properties to explanation complexity.

## Key Results
- Replacing ReLU with SP(β) reduces explanation complexity (lower EF) and improves faithfulness (lower ΔEF)
- Lower β values produce smoother, less grainy explanations while maintaining competitive accuracy
- The power spectrum tail of ReLU networks directly correlates with explanation complexity
- SmoothGrad and other surrogate methods increase the explanation gap by altering the spectral signature
- The framework provides a unified, hyperparameter-free method for evaluating gradient-based explanations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explanation "noise" is not random but a structural artifact of a network's reliance on high-frequency components.
- **Mechanism:** The sharp transitions inherent in ReLU activation functions create a "heavy tail" in the network's power spectrum (TPS). This heavy tail is theoretically linked to a heavy tail in the Spatial Power Spectrum (TSPS) of the input gradient. A heavier spectral tail corresponds to higher "Expected Frequency" (EF), manifesting visually as complex, grainy explanations.
- **Core assumption:** The input data (e.g., images) exhibits high spatial feature correlation, allowing spectral properties of the kernel to transfer to the gradient.
- **Evidence anchors:**
  - [abstract] "authors connect these metrics to the power spectrum tail of ReLU networks, showing that sharper transitions (heavier spectral tails) increase EF..."
  - [section 3.3] "Theorem 1... establishes a relationship between the tails of two power spectra: the tail of the spatial power spectrum of the input gradient and the tail of the power spectrum of the network itself."
  - [corpus] Weak support; corpus focuses on general XAI faithfulness and ReLU optimization, not this specific spectral mechanism.
- **Break condition:** If the network architecture uses smooth activations by default (e.g., GELU in ViTs), the "heavy tail" effect is dampened, and the link between ReLU sharpness and explanation complexity weakens.

### Mechanism 2
- **Claim:** Replacing ReLU with a Smooth Parameterization (SP) allows control over explanation complexity without post-hoc filtering.
- **Mechanism:** By convolving the ReLU function with a Gaussian (approximated via SoftPlus with specific β), the network learns functions with faster-decaying spectral tails. This reduces the high-frequency content in the VanillaGrad explanation (lower EF) directly, avoiding the need for surrogate models that might lie about the model's behavior.
- **Core assumption:** SoftPlus(x; β) effectively approximates ReLU convolved with a Gaussian, and the kernel perspective (NTK) holds for finite-width networks.
- **Evidence anchors:**
  - [abstract] "proposes a Smooth Parameterization (SP) of ReLU... results demonstrate that lower β yields simpler explanations (lower EF) and reduced explanation gaps."
  - [section 3.4] "Lemma 1... f_φ, exhibits a heavier tail in its power spectrum compared to f_ξ [the smoothed version]."
  - [corpus] Not explicitly covered in provided neighbors; mechanism is specific to this paper's framework.
- **Break condition:** If accuracy caps are not enforced during training, SP networks may converge to different baselines, making fairness comparisons difficult; additionally, excessive smoothing may degrade classification accuracy.

### Mechanism 3
- **Claim:** Post-hoc explanation methods (surrogates) trade complexity for faithfulness, quantifiable by an "Explanation Gap."
- **Mechanism:** Methods like SmoothGrad or GradCAM implicitly create smooth surrogates by acting as low-pass filters on the gradient signal. This suppresses high-frequency noise (lowering EF) but alters the spectral signature compared to the original model. The paper quantifies this unfaithfulness as ΔEF, the absolute change in Expected Frequency between the original model and the surrogate.
- **Core assumption:** The "Explanation Gap" defined via spectral deviation (ΔEF) is a reliable proxy for functional faithfulness.
- **Evidence anchors:**
  - [abstract] "introduces the Explanation Gap as a metric for faithfulness by quantifying deviations between surrogates and the original model."
  - [section 4.1] "Let f̃ denote a (typically implicit) surrogate model... We define the explanation gap as the squared L2-norm of the difference..."
  - [corpus] Consistent with "Walk the Talk?" which highlights the risk of LLM explanations misrepresenting reasoning; however, this paper offers a spectral metric rather than a behavioral one.
- **Break condition:** If a post-hoc method happens to align perfectly with the original model's spectral profile, the gap is zero, but this is rare for methods explicitly designed to smooth gradients.

## Foundational Learning

- **Concept: Fourier Transform & Power Spectrum**
  - **Why needed here:** The entire framework relies on analyzing functions in the frequency domain to define "complexity" (Expected Frequency) and "sharpness" (Tail of Power Spectrum).
  - **Quick check question:** How does the decay rate of a power spectrum relate to the smoothness of the original signal in the spatial domain?

- **Concept: Gradient-based Explanations (VanillaGrad vs. Surrogates)**
  - **Why needed here:** You must distinguish between raw gradients (faithful but noisy) and surrogate-based methods (smooth but potentially unfaithful) to understand the trade-off the paper addresses.
  - **Quick check question:** Why does VanillaGrad reflect the "true" complexity of the model while SmoothGrad introduces an "explanation gap"?

- **Concept: ReLU vs. SoftPlus (Smooth Parameterization)**
  - **Why needed here:** The proposed intervention involves replacing the sharp ReLU with a smoothed variant (SoftPlus) to regularize the spectral tail.
  - **Quick check question:** As the β parameter in SoftPlus increases, does the activation function become sharper or smoother relative to standard ReLU?

## Architecture Onboarding

- **Component map:**
  Image datasets -> ConvNet with SP(β) activation -> VanillaGrad computation -> 2D FFT -> Power Spectrum analysis -> EF calculation

- **Critical path:**
  1. Implement the Smooth Parameterization (SP) activation using the SoftPlus approximation: SoftPlus(x; β) = (1/β)·ln(1 + e^(β·x)).
  2. Train networks with varying β (e.g., 0.1 to 50, where higher β ≈ ReLU).
  3. Compute VanillaGrad for test images.
  4. Apply 2D FFT to the gradients and compute the Expected Frequency (EF) metric using Eq. (1).

- **Design tradeoffs:**
  - **Complexity vs. Accuracy:** Lower β reduces explanation complexity (good) but may cap validation accuracy (bad). You must decide on an acceptable accuracy drop.
  - **Strictness vs. Stability:** The paper uses an accuracy cap for early stopping to ensure fair comparison. Without this, ReLU networks may outperform SP networks simply due to better convergence properties of standard initialization.

- **Failure signatures:**
  - **Spectral Leakage:** If input sizes vary drastically without proper handling, the EF metric may not be comparable across datasets.
  - **Initialization Bias:** If not carefully controlled (e.g., via the accuracy cap), results might reflect initialization luck rather than the spectral properties of the activation function.

- **First 3 experiments:**
  1. **Validation of EF:** Train a standard ReLU CNN and an SP(β=0.9) CNN on CIFAR10. Plot the spatial power spectrum of the gradients. Verify that the ReLU model has a heavier tail (higher spectral density at high frequencies).
  2. **Visual Inspection:** Generate VanillaGrad maps for both models. Confirm visually that the SP model produces smoother, less grainy saliency maps without any post-hoc smoothing.
  3. **Gap Analysis:** Apply SmoothGrad to both models. Calculate ΔEF for both. Verify if the SP model maintains a lower "Explanation Gap" compared to the ReLU model when post-hoc smoothing is applied.

## Open Questions the Paper Calls Out
1. Can the power spectrum tail be utilized as a differentiable objective in neural architecture search (NAS) to systematically optimize for interpretability?
2. How do architectural choices like skip connections and batch normalization theoretically alter the power spectrum tail independent of the activation function?
3. Is the link between the network's power spectrum and gradient complexity preserved in data domains with low spatial autocorrelation (e.g., tabular data)?

## Limitations
- The spectral framework assumes data stationarity and sufficient spatial correlation for power spectrum properties to transfer from kernels to gradients
- The Smooth Parameterization's NTK approximation relies on infinite-width networks, but experiments use finite-width CNNs
- The accuracy cap methodology introduces selection bias where only networks reaching the cap are compared

## Confidence
- **High confidence**: The empirical relationship between β and EF (lower β → lower EF), the core observation that ReLU creates high-frequency spectral tails, and the basic spectral analysis methodology are well-supported by experiments across multiple datasets.
- **Medium confidence**: The theoretical connection between TPS and TSPS via Theorem 1 is mathematically sound but relies on strong assumptions about data and network behavior. The Explanation Gap as a faithfulness metric is conceptually valid but may not fully capture functional faithfulness in all scenarios.
- **Low confidence**: The NTK-based justification for why SoftPlus reduces spectral tails (Lemma 1) is theoretically sound for infinite-width networks but its practical implications for finite networks require more rigorous validation.

## Next Checks
1. **Data stationarity test**: Apply the EF metric to non-image datasets (e.g., tabular or time-series) to verify the framework's assumptions about spatial correlation don't break down.
2. **Finite-width validation**: Train networks with varying widths (from narrow to wide) and verify if the TPS-TSPS relationship holds consistently, or if it breaks down at practical widths.
3. **Alternative smoothness metrics**: Compare the Smooth Parameterization approach against other smoothness-inducing methods (e.g., spectral regularization, smooth activations like GELU) to isolate whether the benefits come from spectral properties or general smoothness.