---
ver: rpa2
title: 'Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph:
  Hybrid QA Generation and Diversity Analysis'
arxiv_id: '2507.06571'
source_url: https://arxiv.org/abs/2507.06571
tags:
- image
- multimodal
- generation
- text
- food
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multimodal question answering framework for
  the food domain that combines a large-scale multimodal knowledge graph (MMKG) with
  generative AI. The MMKG links 13,000 recipes, 3,000 ingredients, 140,000 relations,
  and 14,000 images, and is used to generate 40,000 QA pairs via templates and LLM
  augmentation.
---

# Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis

## Quick Facts
- **arXiv ID:** 2507.06571
- **Source URL:** https://arxiv.org/abs/2507.06571
- **Reference count:** 7
- **Primary result:** Multimodal QA system combining MMKG with generative AI achieves 16.2% BERTScore improvement, 37.8% FID reduction, and 31.1% CLIP alignment boost

## Executive Summary
This paper presents a multimodal question answering framework for the food domain that combines a large-scale multimodal knowledge graph (MMKG) with generative AI. The MMKG links 13,000 recipes, 3,000 ingredients, 140,000 relations, and 14,000 images, and is used to generate 40,000 QA pairs via templates and LLM augmentation. The framework jointly fine-tunes Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large, achieving significant improvements in text-image alignment and diversity metrics. It also includes diagnostics to detect hallucinations and image-text mismatches, reducing the latter from 35.2% to 7.3%. A hybrid retrieval-generation strategy balances accuracy and latency, achieving 94.1% accurate image reuse and 85% adequacy in synthesis.

## Method Summary
The system builds a Multimodal Knowledge Graph (MMKG) by aggregating food datasets and scraping images via Selenium and SPARQL from DBpedia and Wikidata. It generates 40,000 QA pairs using 40 templates (20 one-hop, 20 two-hop) plus LLM augmentation, then jointly fine-tunes LLaMA 3.1-8B and Stable Diffusion 3.5-Large on 2,000 aligned QA-image pairs for 15 epochs. The framework implements a hybrid retrieval-generation pipeline with LLaVA-based hallucination detection, using CLIP for image-text consistency checks. The system routes queries between retrieval (for known entities) and generation (for novel compositions) based on confidence thresholds.

## Key Results
- 16.2% improvement in BERTScore (text generation quality)
- 37.8% reduction in FID (image realism and diversity)
- 31.1% boost in CLIP alignment (text-image consistency)
- 94.1% accurate image reuse rate with hybrid strategy
- 85% adequacy in generated image synthesis

## Why This Works (Mechanism)

### Mechanism 1: Structured Knowledge Grounding via MMKG
The Multimodal Knowledge Graph constrains the output space by providing explicit entity-relation triples (recipes, ingredients, images) that anchor responses in verified graph data rather than relying solely on the LLM's internal weights. This reduces factual hallucinations by mapping natural language queries to structured entities before generation. The entity linking and standardization pipeline must be sufficiently accurate to prevent garbage-in-garbage-out errors during graph retrieval.

### Mechanism 2: Joint Text-Image Alignment
Jointly fine-tuning LLaMA and Stable Diffusion on aligned QA-image pairs synchronizes their semantic representations, improving cross-modal consistency. The text encoder learns to produce prompts that better guide the image generator, while the image generator learns to prioritize food-specific visual features identified by the text model. The assumption is that 2,000 fine-tuning samples are sufficient to shift the priors of large models without catastrophic forgetting.

### Mechanism 3: Hybrid Retrieval-Generation Routing
A dynamic routing strategy between retrieval (for known entities) and generation (for novel compositions) balances latency and accuracy. The system checks the MMKG for existing high-confidence image-retrieval matches first, falling back to generative AI when needed. This preserves high accuracy for common items while maintaining flexibility for novel queries.

## Foundational Learning

- **Multimodal Knowledge Graphs (MMKG)**
  - Why needed here: Standard text-only KGs cannot retrieve images; nodes must link to both text attributes and image URIs
  - Quick check question: Can you sketch a triple that links a recipe node to both a text ingredient list and an image file path?

- **CLIP (Contrastive Language-Image Pre-training) Alignment**
  - Why needed here: The paper uses CLIP scores to measure "alignment"; CLIP embeds text and images into the same vector space
  - Quick check question: If the system generates an image of a "burger" but the text says "salad," would the CLIP score go up or down?

- **Hybrid RAG (Retrieval-Augmented Generation)**
  - Why needed here: This architecture balances retrieving fixed images (fast, accurate but rigid) versus generating them (slow, flexible but prone to hallucination)
  - Quick check question: In this system, which strategy is likely faster for the query "Show me a picture of a Big Mac": retrieval or generation?

## Architecture Onboarding

- **Component map:** Ingestion (Selenium/SPARQL) -> MMKG (13k Recipes/Ingredients) -> QA Generator (Templates + LLaVA/DeepSeek) -> 40k QA Pairs -> Model Backbone (LLaMA 3.1-8B + Stable Diffusion 3.5) -> Diagnostics (CLIP + LLaVA) -> Hybrid Router -> Returns (Text, Image)

- **Critical path:** The alignment between LLaMA output and Stable Diffusion input; if LLaMA hallucinates an ingredient, SD will likely generate visually inconsistent images failing subsequent CLIP checks

- **Design tradeoffs:** Precision vs. Diversity (template QA is precise but repetitive; LLM QA is diverse but risky); Speed vs. Control (pure retrieval is fast but limited; generation is slow but comprehensive)

- **Failure signatures:** High FID indicates unrealistic images; low BERTScore suggests text model drift; hallucination spike detected when LLaVA QA consistency check returns low scores

- **First 3 experiments:**
  1. Verify Data Integrity: Run SPARQL queries on MMKG to confirm Recipe nodes correctly link to Ingredient nodes and Image paths for 10 random recipes
  2. Probe the Router: Input queries clearly in dataset vs. novel queries and log whether Hybrid Router selects Retrieval or Generation
  3. Stress Test Hallucination: Generate image for complex recipe, then use diagnostic pipeline to ask LLaVA questions about generated image to detect missing ingredients

## Open Questions the Paper Calls Out
- How effectively does the hybrid retrieval-generation pipeline generalize to cuisines and visual styles not represented in the current MMKG without threshold recalibration?
- What are the false positive and false negative rates of the LLaVA-based hallucination detection framework across different food complexity levels?
- How do human judgments of answer quality, image realism, and multimodal coherence correlate with the automated metrics used (BERTScore, FID, CLIP, clustering indices)?

## Limitations
- The hybrid retrieval-generation strategy hinges on a confidence threshold that must be carefully tuned and may not generalize seamlessly to new cuisines or visual styles without further calibration
- The framework relies on accurate entity linking and standardization, which could fail with ambiguous or novel ingredient descriptions
- No human evaluation is conducted; all reported improvements rely on automated metrics that may not capture perceived coherence or trustworthiness

## Confidence
- **High Confidence (9/10):** Quantitative results showing BERTScore, FID, and CLIP improvements are well-supported
- **Medium Confidence (7/10):** Structured knowledge grounding mechanism is plausible but relies on unvalidated entity linking accuracy
- **Low Confidence (5/10):** Joint fine-tuning claims lack specification of training configuration and composition details

## Next Checks
1. Verify Entity Linking Accuracy: Run SPARQL queries on 50 random recipes to confirm ingredient standardization and entity relationships
2. Stress Test Hybrid Router: Input 100 queries spanning known to novel cases, logging confidence scores and routing decisions
3. Validate Hallucination Detection: Generate images for 20 complex recipes and measure actual hallucination rates against claimed reductions