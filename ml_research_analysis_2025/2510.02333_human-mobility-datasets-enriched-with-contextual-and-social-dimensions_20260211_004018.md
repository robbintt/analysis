---
ver: rpa2
title: Human Mobility Datasets Enriched With Contextual and Social Dimensions
arxiv_id: '2510.02333'
source_url: https://arxiv.org/abs/2510.02333
tags:
- data
- trajectories
- semantic
- mobility
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces two publicly available datasets of semantically
  enriched human trajectories, built from real GPS traces sourced from OpenStreetMap
  and enhanced with contextual layers such as stops, moves, POIs, inferred transportation
  modes, and weather data. A novel feature is the inclusion of synthetic social media
  posts generated by Large Language Models, enabling multimodal and semantic mobility
  analysis.
---

# Human Mobility Datasets Enriched With Contextual and Social Dimensions

## Quick Facts
- arXiv ID: 2510.02333
- Source URL: https://arxiv.org/abs/2510.02333
- Reference count: 28
- Key outcome: Introduces two semantically enriched human trajectory datasets (Paris, NYC) with stops, moves, POIs, transport modes, weather, and synthetic social media posts, validated via high sentiment analysis accuracy (98.9%, 98.5%, 97.0%).

## Executive Summary
This work presents two publicly available datasets of semantically enriched human trajectories built from real GPS traces sourced from OpenStreetMap. The datasets include contextual layers such as stops, moves, points of interest (POIs), inferred transportation modes, and weather data. A novel feature is the inclusion of synthetic social media posts generated by Large Language Models, enabling multimodal and semantic mobility analysis. The datasets are available in both tabular and RDF formats, supporting semantic reasoning and FAIR data practices. The pipeline is open-source and reproducible, facilitating dataset customization for research in behavior modeling, mobility prediction, and LLM-based applications.

## Method Summary
The pipeline processes raw GPS trajectories from OSM by applying preprocessing filters (minimum 10-minute duration, sampling ≥1 per 2 minutes), then segments trajectories into semantic stops and moves using configurable parameters (10-minute stop threshold, 0.2 km spatial radius). Stops are enriched with nearby POIs (within 50m), moves are classified with inferred transportation modes using a Random Forest classifier trained on GeoLife kinematic features, and weather data is joined from Meteostat API. Synthetic social media posts are generated using Llama-3.3-70B-Instruct prompted with POI attributes and synthetic user metadata. The resulting datasets are exported in both tabular (Pandas) and RDF knowledge graph formats with explicit ontologies.

## Key Results
- Successfully generated semantically enriched trajectory datasets for Paris (581 trajectories) and NYC (18,765 trajectories)
- Achieved high sentiment analysis accuracy (98.9%, 98.5%, 97.0%) on synthetic social media posts
- Demonstrated utility for multimodal and semantic mobility analysis through FAIR-compliant RDF representation
- Average POI enrichment shows 2.40-3.73 POIs per stop, varying by city density

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partitioning raw GPS trajectories into semantic units (stops/moves) enables multi-layer contextual enrichment that supports downstream analysis tasks.
- Mechanism: The pipeline applies a stop-and-move segmentation criterion with configurable parameters (minimum 10-minute stop duration, 0.2 km maximum spatial radius) to partition trajectories, then enriches stops with nearby POIs (within 50m) and moves with inferred transportation modes via a Random Forest classifier trained on GeoLife kinematic features.
- Core assumption: The selected thresholds capture meaningful human activity patterns rather than GPS noise or micro-movements.
- Evidence anchors:
  - [abstract] "Each dataset includes contextual layers such as stops, moves, points of interest (POIs), inferred transportation modes, and weather data"
  - [section 2.3] "This yields 969 stops (mean duration: 193.96 ± 833.72 minutes) and 1479 moves (mean distance covered: 9.45 ± 12.18 km) for Paris"
  - [corpus] Massive-STEPS also segments semantic trajectories but relies on check-in data rather than continuous GPS traces

### Mechanism 2
- Claim: LLM-generated synthetic social media posts can plausibly represent user activity context when grounded in POI attributes.
- Mechanism: Llama-3.3-70B-Instruct is prompted with POI names/categories from stop centroids plus synthetic user metadata (gender, age, ethnicity, platform), using temperature=0.9 to encourage diversity while instructing avoidance of generic sentence starters.
- Core assumption: POI proximity at stop locations sufficiently represents actual user activities for generating coherent social content.
- Evidence anchors:
  - [abstract] "Sentiment analysis on the generated social media posts achieved high accuracy (98.9%, 98.5%, and 97.0%)"
  - [section 2.4] "posts are generated based on characteristics derived from the nearest POIs to trajectory stop segment centroids, primarily using POIs' names and categories as indicative context"
  - [corpus] No direct corpus evidence for LLM-generated social media in mobility datasets—this approach appears novel in this domain

### Mechanism 3
- Claim: RDF knowledge graph representation enables semantic reasoning and LLM-compatible querying beyond tabular formats.
- Mechanism: Entities (users, trajectories, stops, moves, POIs) are modeled as RDF triples with explicit relationships, supporting SPARQL queries, symbolic reasoning, and integration with embedding-based approaches.
- Core assumption: The ontology structure captures essential mobility semantics for target downstream tasks.
- Evidence anchors:
  - [abstract] "The datasets are available in both tabular and Resource Description Framework (RDF) formats, supporting semantic reasoning and FAIR data practices"
  - [section 2.5] "This transformation converts raw GPS traces into structured, context-aware mobility data that captures user routines, activities, movement patterns"
  - [corpus] UrbanKG also uses knowledge graphs for urban mobility but focuses on rule-enhanced prediction rather than dataset provision

## Foundational Learning

- Concept: **Stop-and-Move Trajectory Model**
  - Why needed here: Fundamental representation converting continuous GPS traces into discrete semantic units for enrichment
  - Quick check question: Can you explain why a 10-minute stop threshold might miss brief but meaningful activities (e.g., ATM visit, coffee pickup)?

- Concept: **RDF/SPARQL and Knowledge Graphs**
  - Why needed here: Required to leverage the semantic reasoning capabilities and query the RDF dataset format effectively
  - Quick check question: How would you structure a SPARQL query to find all users who visited museums on rainy days?

- Concept: **LLM Prompting for Synthetic Data Generation**
  - Why needed here: Quality of synthetic posts depends on prompt design, temperature settings, and context formatting
  - Quick check question: Why might temperature=0.9 produce more realistic social media posts than temperature=0.1, and when would lower temperature be preferable?

## Architecture Onboarding

- **Component map:**
  GPS collection quality → preprocessing thresholds determine usable data volume → segmentation parameters define stop/move statistics → POI radius affects activity inference confidence → transport classifier depends on GeoLife training data → LLM prompts control social media realism → ontology design constrains query expressiveness

- **Critical path:**
  GPS collection quality → preprocessing thresholds determine usable data volume → segmentation parameters define stop/move statistics → POI radius affects activity inference confidence → transport classifier depends on GeoLife training data → LLM prompts control social media realism → ontology design constrains query expressiveness

- **Design tradeoffs:**
  - Stop duration (10 min): Longer = fewer but more meaningful stops; shorter = more granularity but noise risk
  - POI proximity (50m): Larger = more POIs per stop but lower association confidence
  - LLM temperature (0.9): Higher = diverse output but coherence risk; lower = consistent but repetitive
  - RDF vs Tabular: RDF enables reasoning/FAIR compliance; tabular is simpler for ML pipelines

- **Failure signatures:**
  - High trajectory rejection rate → check duration/sampling thresholds against your data
  - Low POI counts per stop (avg 2.40–3.73) → may indicate POI sparsity or restrictive radius
  - Sentiment analysis errors on generated posts → inspect for foreign language tokens or LLM hallucinations
  - Sparse RDF query results → verify ontology mappings and triple completeness

- **First 3 experiments:**
  1. **Validate segmentation:** Sample 20 trajectories, manually annotate stop/move boundaries, compare against algorithm output to assess if 10min/0.2km parameters suit your use case
  2. **Test LLM output quality:** Generate posts for identical stops using varied temperatures (0.5, 0.7, 0.9, 1.1); evaluate diversity-coherence tradeoff via sentiment consistency and manual review
  3. **Query RDF knowledge graph:** Write SPARQL queries for domain-specific patterns (e.g., "walking trips to restaurants on sunny days") to verify ontology supports your research questions before scaling up

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effectively can LLMs leverage the RDF knowledge graph representation to automate the generation of accurate SPARQL queries for complex mobility questions?
- Basis in paper: [explicit] The paper states in Section 3 that recent studies in automatic SPARQL generation "could be directly applied to the semantic layers of our dataset," identifying this as a promising role for the resource.
- Why unresolved: While the authors provide the RDF structure and identify the potential, they do not execute or benchmark LLM performance on semantic querying tasks using their specific knowledge graph.
- What evidence would resolve it: A benchmark evaluation of an LLM's ability to translate natural language questions into valid SPARQL queries that execute correctly over the dataset.

### Open Question 2
- Question: Do machine learning models trained on the synthetic social media posts transfer effectively to real-world human mobility analysis tasks?
- Basis in paper: [inferred] The paper validates sentiment analysis scores internally (98.9% accuracy) but notes the posts are synthetic. The open question is whether this "realistic" synthetic data serves as a valid proxy for training models intended for deployment on real social media traces.
- Why unresolved: The authors demonstrated that the synthetic posts are internally consistent and sentiment-rich, but they did not test if models trained on this data generalize to non-synthetic ground truth data.
- What evidence would resolve it: Training a mobility or sentiment model on the synthetic dataset and evaluating its performance on a separate dataset containing actual user-generated social media content.

### Open Question 3
- Question: To what extent does the inclusion of synthetic social media dimensions increase the risk of user re-identification compared to standard trajectory data?
- Basis in paper: [explicit] The introduction explicitly notes that "each added semantic layer increases the risk of re-identification," yet the paper introduces a novel, rich layer (social media) without quantifying this specific risk.
- Why unresolved: The paper focuses on the utility and realism of the synthetic text but leaves the specific privacy trade-offs introduced by the LLM-generated content unanalyzed.
- What evidence would resolve it: Running re-identification attack simulations on the raw trajectories versus the semantically enriched versions to measure the privacy loss attributable to the synthetic posts.

### Open Question 4
- Question: Does the semantic enrichment pipeline generalize effectively to urban environments with sparse Points of Interest (POI) data coverage?
- Basis in paper: [inferred] The methodology (Section 2.1) relies on associating stops with nearby POIs and transportation modes. The paper applies the pipeline to two major Western cities with abundant OSM data, leaving the pipeline's robustness in data-scarce regions untested.
- Why unresolved: The success of the "stop" enrichment depends on the density of the underlying POI map, which may vary significantly in cities unlike Paris or New York.
- What evidence would resolve it: Applying the pipeline to a city with low OSM coverage and measuring the percentage of stops that can be successfully enriched with semantic attributes.

## Limitations

- Transport mode classification accuracy is not explicitly reported, only that it uses Random Forest on GeoLife features
- LLM-generated social media posts occasionally contain foreign language tokens or unrealistic place names, indicating potential hallucination risks
- RDF query performance and scalability for large trajectory datasets is not evaluated, with complex SPARQL queries potentially facing computational bottlenecks

## Confidence

- High confidence: Dataset construction pipeline (segmentation, enrichment steps) and FAIR compliance claims (RDF format, public availability)
- Medium confidence: Transport mode classification quality (lacks performance metrics) and LLM post generation utility (validated only through sentiment analysis)
- Low confidence: RDF query performance claims and social media post realism for downstream LLM applications

## Next Checks

1. **Transport mode validation:** Run the Random Forest classifier on a manually labeled subset of moves from both datasets to measure actual classification accuracy
2. **RDF query benchmarking:** Execute progressively complex SPARQL queries on the Paris dataset to measure response times and identify query optimization needs
3. **LLM post evaluation:** Generate posts for 100 randomly sampled stops using different temperature settings, then have human annotators rate coherence and activity relevance on a 5-point scale