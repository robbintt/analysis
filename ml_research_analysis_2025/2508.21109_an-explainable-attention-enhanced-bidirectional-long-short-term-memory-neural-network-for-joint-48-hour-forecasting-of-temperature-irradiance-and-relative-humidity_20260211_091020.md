---
ver: rpa2
title: An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural
  Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity
arxiv_id: '2508.21109'
source_url: https://arxiv.org/abs/2508.21109
tags:
- temperature
- relative
- humidity
- irradiance
- solar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a deep learning framework using a stacked\
  \ bidirectional long short-term memory (BiLSTM) network with attention to jointly\
  \ forecast temperature, solar irradiance, and relative humidity 48 hours ahead.\
  \ The model was trained on historical meteorological data (2019\u20132022) and evaluated\
  \ on 2023 data."
---

# An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity

## Quick Facts
- arXiv ID: 2508.21109
- Source URL: https://arxiv.org/abs/2508.21109
- Reference count: 0
- Mean absolute errors of 1.3°C for temperature, 31 W/m² for irradiance, and 6.7% for humidity on 2023 test data

## Executive Summary
This study introduces a deep learning framework using a stacked bidirectional long short-term memory (BiLSTM) network with attention to jointly forecast temperature, solar irradiance, and relative humidity 48 hours ahead. The model was trained on historical meteorological data (2019–2022) and evaluated on 2023 data. Cyclical time features were encoded to capture solar and monthly periodicity. The approach achieved mean absolute errors of 1.3°C for temperature, 31 W/m² for irradiance, and 6.7% for humidity, outperforming existing numerical weather prediction and machine learning benchmarks. Integrated gradients provided feature importance insights, and attention weights revealed temporal dependencies, enhancing interpretability. By combining multivariate forecasting, attention-based learning, and explainability, this work advances data-driven weather prediction for smart HVAC control and energy trading.

## Method Summary
The approach uses a stacked BiLSTM with attention to jointly forecast temperature, irradiance, and relative humidity. Historical meteorological data (2019-2022) was augmented with cyclical time encodings (sine/cosine transformations of month and solar hour) to capture periodic patterns. The model processes sequences bidirectionally to integrate contextual information from both past and future cyclical features. An attention mechanism dynamically weights timestep contributions to improve accuracy and interpretability. The model outputs predictions for all three variables at each future timestep through a time-distributed dense layer. Training used 22 past timesteps with a learning rate of 0.0031 and batch size of 64.

## Key Results
- Achieved MAE of 1.32°C for temperature, 31.51 W/m² for irradiance, and 6.71% for humidity on 2023 test data
- Outperformed existing numerical weather prediction and machine learning benchmarks
- Demonstrated superior performance for longer forecast horizons (beyond 20 timesteps) compared to single-variable models
- Integrated gradients analysis revealed physical relationships between variables (e.g., humidity affecting temperature through latent heat transfer)

## Why This Works (Mechanism)

### Mechanism 1: Bidirectional Temporal Context Integration
Processing sequences in both forward and backward directions enables the model to leverage known future cyclical features (solar hour, month) while maintaining temporal dependency learning. Standard LSTMs process input only forward (past to future), which limits exploitation of future cyclical inputs. BiLSTM layers process bidirectionally, integrating contextual information from the entire input window to capture patterns spanning the forecast horizon.

### Mechanism 2: Attention-Based Timestep Importance Weighting
A custom attention mechanism after the final BiLSTM layer improves accuracy by dynamically weighting timestep contributions, preventing irrelevant historical data from diluting the learning signal. Attention scores are computed per timestep via two dense layers (64 → 1 units), normalized via softmax, then multiplied with BiLSTM outputs. This allows the model to focus on the most important sequence portions, particularly beneficial for longer horizons.

### Mechanism 3: Joint Multivariate Forecasting with Cross-Variable Dependencies
Simultaneously predicting temperature, irradiance, and relative humidity captures physical interdependencies between variables, improving accuracy over single-variable models. The model outputs all three variables at each future timestep through a time-distributed dense layer, allowing shared hidden representations to learn cross-variable correlations (e.g., humidity affects temperature through latent heat transfer).

## Foundational Learning

- **Concept: Cyclical Feature Encoding (Sine/Cosine Transformation)**
  - **Why needed here**: Raw numeric representations of time (e.g., month 1 vs. 12) fail to capture periodicity. Sine/cosine encoding ensures January and December are close in feature space, preserving diurnal and seasonal cycles critical for weather prediction.
  - **Quick check question**: Given hour=23 and hour=0, would a raw numeric encoding correctly represent their temporal proximity? If not, what transformation is required?

- **Concept: Bidirectional LSTM Hidden States**
  - **Why needed here**: Understanding that BiLSTM produces 2× hidden units (forward + backward) is essential for sizing downstream layers. The attention mechanism operates on shape [batch, timesteps, 2×units].
  - **Quick check question**: If a BiLSTM layer has 8 forward units, what is the dimensionality of its output at each timestep?

- **Concept: Integrated Gradients for Feature Attribution**
  - **Why needed here**: This explainability technique attributes predictions to input features by accumulating gradients along an interpolation path from a baseline to the actual input. The paper uses it to show which features (and timesteps) most influence each output variable.
  - **Quick check question**: What baseline would be appropriate for weather data when computing Integrated Gradients—zeros, the training mean, or something else? Why does the choice matter?

## Architecture Onboarding

- **Component map**: Input [batch, Np+Nf timesteps, 7 features] → Stacked BiLSTM (2 layers × 16 units) → Attention (Dense(64) → Dense(1) → Softmax) → Time-distributed Dense(3) → Output [batch, Nf timesteps, 3 variables]

- **Critical path**: Data preprocessing → Min-Max scale meteorological features; sine/cosine encode time features → Sequence construction → Np=22 past timesteps + Nf=48 future timesteps → Model training → Learning rate 0.0031, batch size 64, MAE-weighted loss → Inference → Output 48-hour forecasts for all three variables

- **Design tradeoffs**: BiLSTM vs. unidirectional LSTM (BiLSTM doubles parameters but enables future-context utilization); Joint vs. separate models (Joint prediction shares representations but requires careful loss balancing across variables with different scales); Attention complexity (Two additional dense layers add ~65 parameters per timestep but provide interpretability and potential accuracy gains)

- **Failure signatures**: Irradiance MAE rising sharply after ~20 timesteps (Expected due to cloud cover unpredictability; if excessive, consider adding cloud-related features or reducing irradiance forecast horizon); Uniform attention weights (Indicates attention not learning; check gradient flow, increase attention layer capacity, or verify softmax is applied correctly); Overfitting to training years (If test MAE significantly exceeds training MAE, increase dropout or reduce model capacity)

- **First 3 experiments**: Ablation on attention (Train identical architecture without attention; compare per-timestep MAE to quantify attention contribution); Hyperparameter sensitivity (Vary Np from 12 to 48 to determine optimal context window); Cross-variable importance validation (Mask one input variable and measure prediction degradation for each output; compare to Integrated Gradients rankings for consistency)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed attention weight peak at the final input timesteps represent a learned reliance on cyclical features or an architectural artifact?
- Basis in paper: [explicit] Page 5 states the peak "could either be an artifact, or an indication of the diminishing influence of past meteorological features balanced by increased weight on the cyclical features."
- Why unresolved: The authors visualize the peak but do not perform ablation studies to determine if it is a boundary effect of the BiLSTM or a meaningful feature attribution.
- What evidence would resolve it: Ablation studies varying sequence length or removing cyclical features to see if the peak shifts or disappears.

### Open Question 2
- Question: Can the model's irradiance forecasting accuracy be improved by incorporating direct cloud cover data or sky imagery?
- Basis in paper: [inferred] The authors attribute the rising MAE for irradiance to the "chaotic and highly variable phenomenon" of cloud cover (Page 5), implying the current historical variables are insufficient.
- Why unresolved: The current input relies on historical point measurements and time, lacking spatial or visual context of approaching weather fronts.
- What evidence would resolve it: Comparative study including satellite-derived cloud motion vectors or local sky-camera data as input features.

### Open Question 3
- Question: Does the forecast accuracy translate into tangible energy savings when integrated into a real-time Model Predictive Control (MPC) loop?
- Basis in paper: [inferred] The abstract and conclusion emphasize potential benefits for "energy-efficient building control," but the study only validates forecast error (MAE), not control performance.
- Why unresolved: Lower MAE does not always guarantee better control outcomes due to latency, actuator dynamics, or specific error sensitivity in MPC cost functions.
- What evidence would resolve it: Simulation or physical deployment of an HVAC MPC system comparing the proposed model's control performance against standard benchmarks.

## Limitations
- Geographical specificity not explicitly stated (Athens, Greece implied by author affiliation)
- Training configuration details incomplete (epochs, optimizer, exact loss function unspecified)
- Superiority claims based on comparison with unspecified baseline models

## Confidence
- **High Confidence**: Core architectural design (BiLSTM + attention + joint forecasting) is well-specified and technically sound. Reported MAE values are internally consistent with model capabilities.
- **Medium Confidence**: Superiority claims over existing methods are based on comparison with unspecified benchmarks, limiting independent verification.
- **Low Confidence**: Interpretability claims from Integrated Gradients depend heavily on baseline selection and implementation details not provided.

## Next Checks
1. **Data Source Verification**: Confirm exact NASA POWER API coordinates and data collection timeframe to ensure exact replication of environmental conditions.
2. **Hyperparameter Reproduction**: Replicate the CMA-ES hyperparameter search process to verify that Np=22, dropout=0.053, and learning rate=0.0031 are truly optimal for this architecture.
3. **Baseline Comparison Replication**: Implement and train the specified baseline models to independently verify the claimed performance improvements.