---
ver: rpa2
title: On Space Folds of ReLU Neural Networks
arxiv_id: '2502.09954'
source_url: https://arxiv.org/abs/2502.09954
tags:
- space
- folding
- networks
- activation
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first quantitative measure of space folding
  in ReLU neural networks. The authors analyze how straight paths in the Euclidean
  input space map to the Hamming activation space, where convexity can be lost due
  to non-convex folding behavior.
---

# On Space Folds of ReLU Neural Networks

## Quick Facts
- arXiv ID: 2502.09954
- Source URL: https://arxiv.org/abs/2502.09954
- Reference count: 14
- One-line primary result: Introduces the first quantitative measure of space folding in ReLU neural networks, showing that deeper networks exhibit higher folding values when well-trained.

## Executive Summary
This paper introduces the first quantitative measure of space folding in ReLU neural networks, analyzing how straight paths in Euclidean input space map to Hamming activation space. The authors prove that convexity is generally lost in deeper networks, giving rise to non-convex folding behavior. They introduce a novel space folding measure based on range metrics from random walk theory, computing the ratio of maximum to total Hamming distance changes along paths in activation space. Empirically, they demonstrate that space folding increases with network depth for well-trained models, providing valuable insights into how ReLU networks process input information through geometric folding transformations.

## Method Summary
The authors develop a space folding measure χ(Γ) that quantifies deviation from flatness by comparing maximum Hamming distance reached along a path versus total distance traveled in activation space. The method involves interpolating points between input pairs, performing forward passes through the network, binarizing all hidden layer activations, and computing Hamming distances between consecutive activation patterns. The measure is then aggregated across paths and classes. Theoretical contributions include proving the equivalence of convexity notions between input and activation spaces, establishing that space folding effects are observable only in networks with at least two hidden layers.

## Key Results
- Space folding measure χ quantifies deviation from convexity in ReLU networks, bounded between 0 (flat) and 1 (maximally folded)
- Depth-folding correlation: Pearson coefficient of 0.987 between network depth and aggregated median folding values for well-trained models
- Width scaling: Larger networks show increased proportion of folded paths (0.35±0.1 to 0.97±0.04) without substantially changing folding magnitudes
- Theoretical proof: Single-layer networks preserve convexity between input and activation spaces, making space folding effects observable only in networks with ≥2 hidden layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Space folding effects manifest only in networks with at least two hidden layers because single-layer networks preserve convexity between input and activation spaces.
- Mechanism: ReLU networks partition input space into linear regions separated by hyperplanes. The paper proves (Lemma 1) that for first-layer hyperplanes intersecting the entire input space, convexity in Euclidean input space is equivalent to convexity in Hamming activation space. Deeper layers introduce non-convex mappings where straight lines in input space map to curved paths in activation space.
- Core assumption: The activation pattern captures meaningful geometric structure; binarization of neuron activations preserves the relevant topology.
- Evidence anchors:
  - [abstract] "the convexity of straight lines is generally lost, giving rise to non-convex folding behavior"
  - [section 4, Lemma 1] Proves convexity equivalence, with direct consequence that "space folding effects are observable only in networks with at least two hidden layers"
  - [corpus] Related work "The Space Between: On Folding, Symmetries and Sampling" extends folding analysis, but the corpus lacks independent validation of the minimum-depth requirement.
- Break condition: If a network's first layer hyperplanes do not span the input space (e.g., bottlenecks), the convexity equivalence proof may not hold, potentially invalidating the depth-floor claim.

### Mechanism 2
- Claim: The space folding measure χ(Γ) quantifies deviation from flatness by comparing the maximum Hamming distance reached along a path versus the total distance traveled.
- Mechanism: In Euclidean space, walking a straight line monotonically increases distance from the origin. In Hamming activation space, this monotonicity can break—a straight line in input space may map to a path that doubles back, causing Hamming distance to decrease. The measure computes χ(Γ) = 1 - (max_i d_H(π_i, π_1)) / (Σ d_H(π_i, π_{i+1})), where higher values indicate more folding.
- Core assumption: The ratio of range metrics meaningfully captures geometric folding rather than artifacts of discrete sampling or network architecture idiosyncrasies.
- Evidence anchors:
  - [section 5] Defines r1(Γ) as maximum Hamming distance and r2(Γ) as total path distance; χ = 1 - r1/r2
  - [section 6.1, Fig. 6] Shows Hamming distance decreasing along a path in CantorNet (dotted line), demonstrating non-convexity
  - [corpus] Weak external validation—corpus papers reference folding conceptually but do not independently validate this specific metric construction.
- Break condition: If intermediate sampling points are too sparse, the path may skip regions entirely; if too dense, computational cost explodes without accuracy gain.

### Mechanism 3
- Claim: Well-trained deeper networks exhibit higher maximal folding values, while larger networks show increased proportion of folded paths rather than higher folding magnitudes.
- Mechanism: Depth enables hierarchical feature abstraction through repeated folding operations. Experiments on MNIST show Pearson correlation of 0.987 between depth and aggregated median folding values for well-trained networks. However, scaling width (2×300 vs. 2×30) increases the ratio of paths exhibiting folding (0.35±0.1 to 0.97±0.04) without substantially changing folding magnitudes.
- Core assumption: High validation accuracy indicates meaningful learning rather than memorization; folding correlates with generalization capacity.
- Evidence anchors:
  - [section 6.1] "the aggregated median of maximas of non-zero space folding... obtaining the Pearson correlation coefficient 0.987"
  - [section 6.1] Networks with lower accuracy showed "much lower" folding values
  - [corpus] No corpus papers replicate the depth-folding correlation; external validation is absent.
- Break condition: Correlation does not imply causation—depth may be a proxy for other architectural factors; adversarial robustness experiments (suggested in Section 7) are needed to test generalization links.

## Foundational Learning

- Concept: Hamming distance on binary vectors
  - Why needed here: The activation space is constructed as a binary hypercube where each neuron's state is 0 (inactive) or 1 (active). Folding is measured via Hamming distance changes.
  - Quick check question: Given activation patterns (0,1,1,0) and (1,1,0,0), what is their Hamming distance? (Answer: 2)

- Concept: Linear regions in ReLU networks
  - Why needed here: ReLU networks partition input space into polyhedral regions where the network behaves as an affine function. Crossing region boundaries changes activation patterns.
  - Quick check question: Why does a ReLU network create piecewise-linear decision boundaries? (Answer: Each region applies a different affine transformation)

- Concept: Range metrics from random walk theory
  - Why needed here: The folding measure adapts the "diameter of walk" concept (max-min excursion) to quantify how far a path deviates from direct monotonic traversal.
  - Quick check question: For a walk with steps (+1, -1, +1, +1), what is the maximum absolute amplitude? (Answer: 2, reached at step 4)

## Architecture Onboarding

- Component map:
  - Input pair -> interpolation -> forward passes -> binarization -> Hamming sequence -> range metrics -> χ value -> aggregation across pairs

- Critical path: Input pair → interpolation → forward passes → binarization → Hamming sequence → range metrics → χ value → aggregation across pairs

- Design tradeoffs:
  - Sampling density (n) vs. computational cost: Theorem bounds n ≤ N (hidden neurons), but optimal placement at region boundaries is unsolved
  - Full pairwise computation (O(|C₁|·|C₂|)) vs. cluster-based approximation: Preliminary results (Appendix C) suggest 5 clusters per class preserves accuracy
  - Local (per-path) vs. global (supremum over all paths) folding: Global measure Φ_N is theoretically defined but computationally intractable

- Failure signatures:
  - χ ≈ 0 for all paths: Network may be undertrained, too shallow (< 2 hidden layers), or inputs may lie in a single linear region
  - Inconsistent results across random seeds: Deeper networks (6+, 10 layers) show training instability; folding values drop with poor accuracy
  - All paths show χ = 0 despite depth: Check that binarization is applied to all hidden layers, not just the first

- First 3 experiments:
  1. **Baseline on CantorNet (k=2)**: Reproduce Figure 6—interpolate between (0, 0.75) and (1, 0.75), compute χ. Expected: χ ≈ 0.7. Validates implementation.
  2. **Depth sweep on MNIST**: Train networks with architectures {2×30, 3×20, 4×15, 5×12, 6×10}, compute aggregated folding. Expected: Positive correlation with depth for well-trained networks (r > 0.95).
  3. **Width vs. depth comparison**: Compare 2×300 vs. 3×200 on folding ratio (paths with χ > 0). Expected: Similar χ magnitudes but ratio increases from ~0.35 to ~0.99.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the space folding measure behave when applied to non-MLP architectures, specifically binary neural networks and transformer models with ReLU activations?
- Basis in paper: [explicit] Section 7 explicitly identifies extending the study to "binary neural networks" and "transformer-like architectures with ReLUs" as a direction for future work.
- Why unresolved: The current theoretical proofs and empirical validation (CantorNet, MNIST) are restricted to standard feed-forward ReLU MLPs.
- What evidence would resolve it: Empirical results showing the distribution of $\chi$ values for binary networks or ReLU-transformers compared to standard MLP baselines.

### Open Question 2
- Question: How is the space folding measure affected by adversarial perturbations and data augmentation techniques?
- Basis in paper: [explicit] Section 7 suggests investigating "folding effects between an image from a selected class and its adversarial perturbation" as well as for data augmentation.
- Why unresolved: The paper only analyzes clean samples from MNIST and CantorNet; it does not quantify how small, targeted input perturbations alter the folding path or magnitude.
- What evidence would resolve it: A comparative analysis of $\chi$ values calculated between clean samples and their adversarially attacked counterparts.

### Open Question 3
- Question: Can the computational efficiency of the measure be improved by optimizing the sampling of intermediate points to ensure traversal of distinct linear regions?
- Basis in paper: [explicit] Section 5 notes that evenly spacing points is "suboptimal" and Section 7 proposes exploring methods to ensure "each intermediate point falls into a distinct linear region."
- Why unresolved: The current algorithm relies on linear interpolation with a fixed number of steps, which is computationally expensive and may miss distinct regions or oversample redundant ones.
- What evidence would resolve it: An algorithm that dynamically samples points based on linear region boundaries, demonstrating reduced complexity ($< O(n \cdot N)$) without loss of accuracy.

### Open Question 4
- Question: How does the space folding measure correlate with generalization when models are trained on corrupted data (e.g., random labels) or with different optimization settings?
- Basis in paper: [explicit] Section 7 asks to examine the measure on "networks trained with random labels" and investigates the impact of "different learning rates and optimization techniques."
- Why unresolved: The paper hypothesizes a link between folding and generalization based on depth, but has not validated this against standard generalization failure modes like fitting random noise.
- What evidence would resolve it: Experiments showing the trajectory of the folding measure $\chi$ during the training of networks on datasets with varying ratios of random labels.

## Limitations
- Single-seed validation: The depth-folding correlation (Pearson 0.987) is based on a single random seed (seed=4), raising concerns about robustness.
- Theoretical minimum depth: The requirement for ≥2 hidden layers is proven but not empirically validated across diverse architectures.
- Binarization information loss: The approach may lose activation magnitude information that could be relevant for folding behavior.

## Confidence
- High confidence: The mathematical framework for space folding measure (χ) and its properties are rigorously defined and theoretically sound. The CantorNet experiments are reproducible with provided weights.
- Medium confidence: The depth-folding correlation results are convincing but based on limited random seeds. The claim that well-trained networks show higher folding is supported but requires more rigorous ablation studies.
- Low confidence: The generalization implications remain speculative. The link between folding and adversarial robustness is suggested but not tested.

## Next Checks
1. **Multi-seed validation**: Reproduce depth-folding correlation across all five random seeds (0-4) to verify stability. Compute 95% confidence intervals for the Pearson correlation coefficient.

2. **Adversarial robustness test**: Generate adversarial examples for networks at different depths. Measure whether higher-folding networks show greater or lesser robustness compared to lower-folding counterparts, testing the generalization hypothesis.

3. **Alternative binarization schemes**: Compare the binary activation space approach against continuous distance measures in the full activation space. Test whether magnitude information provides complementary insights to the folding measure.