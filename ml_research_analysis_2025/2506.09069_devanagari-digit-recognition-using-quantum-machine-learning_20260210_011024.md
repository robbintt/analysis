---
ver: rpa2
title: Devanagari Digit Recognition using Quantum Machine Learning
arxiv_id: '2506.09069'
source_url: https://arxiv.org/abs/2506.09069
tags:
- quantum
- devanagari
- hybrid
- classical
- digit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents the first application of hybrid quantum-classical
  machine learning to Devanagari handwritten digit recognition, combining a convolutional
  neural network for feature extraction with a 10-qubit variational quantum circuit
  for classification. The model achieves 99.80% test accuracy and 0.2893 test loss
  on the DHCD dataset, surpassing classical baselines with significantly fewer parameters
  (2.34 million total, only 100 in the quantum component).
---

# Devanagari Digit Recognition using Quantum Machine Learning

## Quick Facts
- **arXiv ID:** 2506.09069
- **Source URL:** https://arxiv.org/abs/2506.09069
- **Reference count:** 17
- **Primary result:** First hybrid quantum-classical ML application to Devanagari digit recognition achieving 99.80% test accuracy

## Executive Summary
This paper introduces the first hybrid quantum-classical machine learning approach for Devanagari handwritten digit recognition, combining a convolutional neural network with a 10-qubit variational quantum circuit. The model achieves 99.80% test accuracy on the DHCD dataset while using significantly fewer parameters than classical baselines. By leveraging quantum superposition and entanglement, the architecture demonstrates improved discrimination of visually similar Devanagari digits while maintaining computational efficiency. The work establishes quantum-enhanced architectures as viable for regional script recognition tasks and opens promising directions for low-resource language settings.

## Method Summary
The approach uses a CNN feature extractor (4 convolutional layers) to process 28×28 grayscale images, producing 2048-dimensional feature vectors that are linearly projected to 1024 dimensions and L2-normalized for amplitude embedding into 10 qubits. A variational quantum circuit with 5 layers applies RY and RZ rotations followed by ring-topology CNOT entanglement, measuring 55 observables (10 single-qubit Z and 45 pairwise ZZ operators). The resulting quantum features pass through a classical linear classifier. Training uses AdamW optimization with label smoothing regularization on the DHCD dataset (20,000 images, 10 classes), augmented with rotations, translations, flips, and elastic transforms.

## Key Results
- Achieves 99.80% test accuracy and 0.2893 test loss on DHCD dataset
- Uses only 100 quantum parameters versus 2.34 million total parameters
- Outperforms classical baselines with ablation study showing 99.03% accuracy without quantum component
- Demonstrates quantum advantage for visually similar digit classes (3, 5, 6) through entanglement-enhanced discrimination

## Why This Works (Mechanism)

### Mechanism 1
Amplitude embedding compresses 1024-dimensional classical features into 10-qubit quantum states, enabling compact representation of high-dimensional data manifolds. The CNN extracts 2048 features → linear projection to 1024 → L2 normalization → amplitude encoding where each of the 2^10 = 1024 basis state amplitudes stores one feature value. This preserves relative feature magnitudes while reducing the classical layer's output to a normalized quantum state. Core assumption: The 1024-dimensional feature vector sufficiently captures digit-discriminative information after CNN extraction; amplitude normalization does not destroy critical class boundary information.

### Mechanism 2
Ring-entanglement topology via CNOT gates creates correlated qubit states that enhance multi-feature discrimination for visually similar Devanagari digits. Each variational layer applies RY/RZ rotations (individual qubit feature transformation) followed by CNOT gates in ring topology (CNOT(0,1), CNOT(1,2), ..., CNOT(9,0)). This creates pairwise entanglement enabling the circuit to learn joint feature correlations—critical for distinguishing similar curved strokes in Classes 3, 5, 6. Core assumption: Entanglement provides expressive power beyond classical correlations; ring topology is sufficient (vs. all-to-all or other topologies).

### Mechanism 3
Measuring 55 Pauli-Z observables (10 single-qubit + 45 pairwise ZZ correlations) extracts quantum-enhanced features for final classification. Post-measurement, the 55-dimensional quantum feature vector q captures both individual qubit states and their correlations. A classical linear layer (W ∈ R^10×55) maps these to 10 class logits. This hybrid readout allows quantum circuit to learn expressive representations while keeping quantum parameters low (100). Core assumption: The 55 observables are sufficient to encode class-discriminative information; pairwise ZZ correlations add value beyond single-qubit measurements alone.

## Foundational Learning

- **Concept: Amplitude Embedding**
  - **Why needed here:** Encodes classical data into quantum state amplitudes; requires understanding that n qubits can represent 2^n amplitudes, and that normalization is mandatory.
  - **Quick check question:** Given 16 features and 4 qubits, can you perform amplitude embedding? What happens if the feature vector norm is zero?

- **Concept: Variational Quantum Circuits (VQCs)**
  - **Why needed here:** The quantum classifier is trained via classical optimization; parameters are rotation angles, not fixed gate sequences.
  - **Quick check question:** If gradient computation returns near-zero for all quantum parameters after 10 epochs, what phenomenon might be occurring?

- **Concept: Hybrid Quantum-Classical Backpropagation**
  - **Why needed here:** Gradients flow from classical loss through quantum measurements back to CNN weights; requires automatic differentiation across quantum-classical boundary.
  - **Quick check question:** In PennyLane, what does `qml.probs` return, and how does it differ from `qml.expval(qml.PauliZ(0))`?

## Architecture Onboarding

- **Component map:** Input (28×28 grayscale) → CNN (4 conv layers: 32→64→128→128 filters, ReLU, MaxPool) → Flatten (2048-dim) → Linear projection (2048→1024) → L2 normalize → Amplitude Embedding (10 qubits) → VQC (5 variational layers × {RY, RZ, CNOT ring}) → Measure 55 observables (⟨Z⟩, ⟨ZZ⟩) → Linear classifier (55→10) → Softmax + Label-smoothed CrossEntropy

- **Critical path:** CNN feature extraction → dimensionality matching for quantum input → amplitude encoding fidelity → entanglement depth → observable measurement → classification head. The 1024-dim projection is the bottleneck; mismatch here causes embedding failure.

- **Design tradeoffs:**
  - **Qubit count vs. feature resolution:** 10 qubits = 1024 amplitudes; increasing qubits requires wider projection but may improve accuracy (paper shows 4→6→8→10 qubits: 99.47%→99.80%).
  - **Quantum depth vs. trainability:** d=5 chosen empirically; deeper circuits risk barren plateaus.
  - **Dropout=0.0 + label smoothing=0.05:** Regularization delegated to label smoothing; may need dropout if overfitting observed on smaller datasets.

- **Failure signatures:**
  - **NaN loss during training:** Check L2 normalization (ε=10⁻⁸ prevents division by zero); verify amplitude embedding input has non-zero norm.
  - **Validation accuracy plateaus ~95%:** Likely underfitting—increase quantum depth or qubit count.
  - **Class 3/6 confusion persists:** These digits share curved strokes; consider data augmentation targeting rotation/elastic transforms or adding ZZ observables between specific qubit pairs.

- **First 3 experiments:**
  1. **Reproduce 10-qubit baseline:** Train on DHCD digits with hyperparameters from Table 4 (lr=10⁻³, batch=32, depth=5); verify 99.80% test accuracy within ±0.1%.
  2. **Ablate quantum component:** Replace VQC with classical linear layer (1024→55→10); confirm accuracy drops to ~99.03% as reported in ablation.
  3. **Qubit scaling study:** Train 4, 6, 8, 10-qubit models; plot accuracy vs. qubit count to verify the paper's scaling trend (99.47%→99.67%→99.70%→99.80%).

## Open Questions the Paper Calls Out

### Open Question 1
How does the hybrid model perform when deployed on actual noisy quantum hardware compared to classical simulation? All experiments used PennyLane simulations; no actual quantum hardware was used. Running the same architecture on IBM Q or Rigetti devices and comparing accuracy, stability, and convergence metrics against simulated results would resolve this.

### Open Question 2
Can the hybrid architecture scale effectively to recognize all 46 Devanagari character classes (digits plus consonants)? Only 10 digit classes were tested; the 36 consonant classes with their complex ligatures remain unexplored. Training and evaluating the model on the complete DHCD dataset and reporting accuracy, F1-scores, and parameter efficiency across all 46 classes would resolve this.

### Open Question 3
How does model performance scale with increased qubit count and circuit depth beyond 10 qubits? Experiments were limited to 4, 6, 8, and 10 qubits; scalability trends remain unknown. Systematic experiments with 12, 16, and 20+ qubits showing accuracy, training time, and parameter efficiency trends would resolve this.

### Open Question 4
Does the hybrid approach generalize to other under-resourced regional scripts beyond Devanagari? Only Devanagari was tested; transferability to linguistically distinct scripts is unknown. Applying the architecture to scripts like Bengali, Tamil, or Gurmukhi using comparable datasets and reporting performance metrics would resolve this.

## Limitations
- All experiments performed on quantum simulators, not actual quantum hardware, leaving noise resilience untested
- Limited ablation study comparing only against classical linear classifier, not state-of-the-art classical CNN architectures
- Scalability concerns for larger character sets beyond 10 digits, with no analysis of computational complexity for expanded alphabets

## Confidence

- **High confidence:** The core architecture specification (CNN + amplitude embedding + 10-qubit VQC with ring entanglement) is clearly documented and reproducible. The training methodology and hyperparameter choices are sufficiently detailed for replication.
- **Medium confidence:** The claimed accuracy superiority over classical methods is supported by ablation results, but lacks direct comparison to classical SOTAs on identical datasets and splits. The mechanism explanations are plausible but not experimentally validated within the paper.
- **Low confidence:** The practical deployment implications on NISQ hardware are not addressed—the results are simulation-based, and no analysis of noise resilience or real quantum device performance is provided.

## Next Checks

1. **Reproduce the 10-qubit baseline accuracy** on the exact DHCD split (13,600/3,400/3,000) to verify the 99.80% claim within ±0.1% tolerance.

2. **Benchmark against classical SOTA** by training a comparable-sized classical CNN (matching the 2.34M parameters) on identical data splits and comparing both accuracy and parameter efficiency.

3. **Test scaling to larger scripts** by applying the architecture to Devanagari consonants (36 classes) and measuring accuracy degradation vs. qubit count, to validate the amplitude embedding approach beyond digits.