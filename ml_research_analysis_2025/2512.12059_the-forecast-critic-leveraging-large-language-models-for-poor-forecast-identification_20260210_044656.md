---
ver: rpa2
title: 'The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification'
arxiv_id: '2512.12059'
source_url: https://arxiv.org/abs/2512.12059
tags:
- forecast
- time
- historical
- series
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Forecast Critic leverages Large Language Models (LLMs) to automatically
  identify poor forecasts in time series data by evaluating visual plots and incorporating
  contextual information. We systematically assess LLM performance on detecting common
  forecast errors (trend misalignment, vertical shifts, stretched/compressed periodicity,
  and spike errors) using both synthetic and real-world data from the M5 dataset.
---

# The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification

## Quick Facts
- arXiv ID: 2512.12059
- Source URL: https://arxiv.org/abs/2512.12059
- Reference count: 35
- Primary result: LLM-based system achieves F1 score of 0.88 on synthetic forecast error detection, with 10% higher sCRPS for flagged real-world forecasts

## Executive Summary
The Forecast Critic system leverages Large Language Models to automatically identify poor forecasts in time series data by evaluating visual plots and incorporating contextual information. The approach systematically assesses LLM performance on detecting common forecast errors including trend misalignment, vertical shifts, periodicity distortions, and spike errors using both synthetic and real-world data from the M5 dataset. The system demonstrates solid performance on synthetic data with an F1 score of 0.88, slightly below human expert performance (F1: 0.97), while successfully flagging real-world forecasts with significantly higher sCRPS scores.

## Method Summary
The Forecast Critic system employs LLMs to analyze forecast visualizations by evaluating plots against predefined error categories. The methodology involves generating synthetic forecast errors (trend misalignment, vertical shifts, periodicity distortions, and spikes) to create a controlled test environment. The system evaluates both text-only and multi-modal LLM variants, with the latter incorporating visual plot analysis alongside contextual information. For real-world validation, the system processes forecasts from the M5 dataset, comparing LLM-flagged forecasts against sCRPS metrics to assess practical effectiveness. The evaluation framework includes systematic error injection, human expert benchmarking, and comprehensive performance metrics across different error types and model architectures.

## Key Results
- Best-performing LLM achieves F1 score of 0.88 on synthetic data, compared to human expert F1 of 0.97
- LLMs reliably identify trend modifications and vertical translations but struggle with periodicity distortions
- Multi-modal LLMs correctly flag missing or spurious spikes with F1 scores up to 0.84 when provided promotional context
- Real-world forecasts flagged as unreasonable have at least 10% higher sCRPS than reasonable ones

## Why This Works (Mechanism)
The system works by leveraging LLMs' pattern recognition capabilities on visual forecast plots, combined with contextual information processing. LLMs can identify visual anomalies in forecast visualizations that correspond to common forecasting errors. The multi-modal approach allows LLMs to process both the visual representation of forecasts and associated contextual metadata (such as promotional events), enabling more accurate error detection. The systematic error categorization allows for targeted evaluation of LLM performance across different error types, revealing both strengths (trend and vertical shift detection) and weaknesses (periodicity distortion identification).

## Foundational Learning
- **Time series forecasting fundamentals**: Understanding forecast error types and evaluation metrics (sCRPS) is essential for designing the error detection framework and interpreting results
- **LLM multi-modal capabilities**: Knowledge of how LLMs process visual information alongside text is crucial for understanding the system's architecture and performance variations between text-only and multi-modal models
- **Synthetic data generation techniques**: Understanding controlled error injection methods is necessary for replicating the systematic evaluation and creating diverse test scenarios
- **Performance metric interpretation**: Familiarity with F1 scores, precision, recall, and their application to error detection tasks is needed to evaluate system effectiveness

## Architecture Onboarding

**Component map**: Data Generator -> Synthetic Error Injector -> Visual Plot Creator -> LLM Evaluator -> Performance Metrics -> Results Analysis

**Critical path**: The system generates synthetic forecast errors, creates visual representations, processes these through LLMs, and evaluates detection performance against ground truth labels. The most critical components are the synthetic error generation (ensuring representative test cases) and the multi-modal LLM processing (the core detection mechanism).

**Design tradeoffs**: The choice between text-only and multi-modal LLMs involves balancing computational cost against detection accuracy. Visual plot analysis provides richer information but requires more processing power and may introduce latency. The system prioritizes accuracy over speed, accepting higher computational costs for improved error detection performance.

**Failure signatures**: The system shows systematic struggles with periodicity distortion detection, suggesting LLMs have difficulty recognizing complex temporal patterns. Performance degradation on real-world data compared to synthetic indicates sensitivity to noise and complexity. The gap between synthetic (F1: 0.88) and human (F1: 0.97) performance suggests limitations in LLM's ability to match expert-level pattern recognition.

**First experiments**:
1. Test LLM performance on individual error types to identify specific weaknesses in the detection pipeline
2. Compare text-only versus multi-modal LLM performance on the same synthetic dataset to quantify the value of visual information
3. Evaluate the impact of different contextual information levels on spike error detection accuracy

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Performance gap between synthetic (F1: 0.88) and real-world data suggests LLM performance may degrade with complexity and noise
- Systematic struggle with periodicity distortions indicates LLMs cannot reliably detect all common forecast error types
- Reliance on visual plot analysis raises questions about scalability for high-volume forecasting environments
- Limited real-world validation covers only M5 dataset and specific error types, restricting generalizability

## Confidence
- Core claims about LLM effectiveness on synthetic data: Medium
- Real-world validation results: Medium
- Performance gap analysis: Medium
- Scalability and deployment feasibility: Low

## Next Checks
1. Evaluate LLM performance across diverse forecasting domains beyond retail sales (e.g., energy demand, financial markets) to assess generalizability
2. Implement systematic study of computational costs and latency for processing large forecast batches to determine practical deployment feasibility
3. Conduct controlled experiment comparing LLM-identified poor forecasts against ground-truth model performance metrics across multiple forecasting algorithms to validate correlation between LLM flags and actual forecast quality