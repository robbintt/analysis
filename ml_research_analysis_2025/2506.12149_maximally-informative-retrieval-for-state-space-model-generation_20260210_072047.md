---
ver: rpa2
title: Maximally-Informative Retrieval for State Space Model Generation
arxiv_id: '2506.12149'
source_url: https://arxiv.org/abs/2506.12149
tags:
- arxiv
- documents
- retrieval
- document
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selecting the most informative
  documents for retrieval-augmented generation (RAG) when processing large datasets
  with bounded model resources. The authors propose Retrieval In-Context Optimization
  (RICO), a method that uses gradients from state space models (SSMs) to learn the
  optimal mixture of documents for a given query.
---

# Maximally-Informative Retrieval for State Space Model Generation

## Quick Facts
- arXiv ID: 2506.12149
- Source URL: https://arxiv.org/abs/2506.12149
- Reference count: 20
- One-line primary result: RICO achieves comparable retrieval metrics to BM25 without fine-tuning and often outperforms fine-tuned dense retrievers like E5 on final prediction quality

## Executive Summary
This paper addresses the challenge of selecting the most informative documents for retrieval-augmented generation (RAG) when processing large datasets with bounded model resources. The authors propose Retrieval In-Context Optimization (RICO), a method that uses gradients from state space models (SSMs) to learn the optimal mixture of documents for a given query. Unlike traditional RAG systems that rely on external heuristics, RICO leverages direct feedback from the model by optimizing document weights to minimize question perplexity.

Theoretically, the authors show that top-k retrieval with model gradients can approximate their optimization procedure and provide connections to the leave-one-out loss. Empirically, they demonstrate that RICO achieves comparable retrieval-side metrics to BM25 without fine-tuning and often outperforms fine-tuned dense retrievers like E5 in terms of final prediction quality. The method is particularly effective in long-context scenarios, where it can significantly improve generation quality compared to concatenating full documents.

## Method Summary
RICO reformulates document retrieval as a continuous optimization problem by leveraging the separable dynamics of state space models. For each query, the method precomputes hidden states for all documents in the corpus, then uses gradient descent to learn optimal scalar weights for a linear combination of these states. The optimization minimizes query perplexity through token-level loss, treating retrieval as finding the most informative document mixture rather than selecting individual documents. The method can operate as a reranker over candidate sets or generate directly from learned state mixtures, enabling handling of contexts longer than the model's training context length.

## Key Results
- Achieves comparable nDCG@10 to BM25 without any fine-tuning on MS MARCO, HotpotQA, MuSiQue, and 2WikiMultihopQA datasets
- Outperforms fine-tuned dense retriever E5 on final prediction quality in long-context scenarios, with 97% relative F1 improvement on TriviaQA
- Requires only one forward pass per document for state indexing, making retrieval a linear-time operation over the document index

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval can be reformulated as a continuous optimization problem by leveraging the separability of state space model dynamics.
- Mechanism: In SSMs, the output can be decomposed as a linear function of context hidden states (yt = CtAt:τ+1hc + Cthq). This allows treating document retrieval as finding optimal scalar weights αi for a linear combination of precomputed document states, rather than solving a combinatorial ordering problem.
- Core assumption: The loss landscape in the direction of document states is approximately convex.
- Evidence anchors:
  - [abstract]: "leverages the separability of model dynamics to frame retrieval as a continuous optimization problem"
  - [section 3.2]: Shows the decomposition yt = CtAt:τ+1hc + Cthq where outputs depend on context only through hidden state hc
  - [corpus]: Weak corpus support; related papers focus on retrieval optimization through query decomposition or contrastive learning, not state-space decomposition.
- Break condition: Non-convex loss landscapes causing gradient descent to converge to poor local minima; failure of the linearity assumption when document order significantly affects A matrices.

### Mechanism 2
- Claim: The inner product between document states and loss gradients provides an upper bound on leave-one-out loss, enabling efficient top-k retrieval.
- Mechanism: Initialize document weights uniformly, then compute ∂L/∂h. The k largest inner products ⟨hdi, -∂L/∂h⟩ approximate one gradient descent step and identify documents most likely to reduce query perplexity. Document states are precomputed, making retrieval a linear-time operation over the index.
- Core assumption: Query perplexity (question likelihood) serves as a reliable proxy for answer likelihood when ground truth answers are unavailable at retrieval time.
- Evidence anchors:
  - [abstract]: "document weights are learned by minimizing query perplexity through gradient descent on token-level losses"
  - [section 3.4]: Proposition 3.1 proves the gradient inner product upper-bounds leave-one-out loss under convexity
  - [corpus]: Cross-encoder distillation approaches (arXiv:2505.19274) similarly use model feedback for retrieval, but require quadratic model calls; RICO's gradient approach is more efficient.
- Break condition: Misalignment between question loss and answer loss (e.g., the model prefers seeing the question repeated rather than the answer, as shown in Appendix C.3 Figure 9).

### Mechanism 3
- Claim: Generating directly from learned state mixtures enables handling contexts longer than training context length.
- Mechanism: Instead of concatenating documents as tokens, compute the weighted sum of hidden states h̄(α) = Σαihdi and continue generation from this learned state. This bypasses the context window constraint while preserving information from relevant documents.
- Core assumption: The learned linear combination of document states preserves sufficient information for generation, even when individual state dimensions are compressed or subsampled.
- Evidence anchors:
  - [abstract]: "often outperforms fine-tuned dense retrievers like E5 on final prediction quality, particularly in long-context scenarios"
  - [section 4.2, Table 3]: On TriviaQA, learned state generation achieves 97% relative F1 improvement over concatenation methods
  - [corpus]: No direct corpus comparison; neighboring papers do not address state-based generation for long-context RAG.
- Break condition: Information loss from state compression; incompatibility between the learned state distribution and the model's expected state statistics.

## Foundational Learning

- Concept: State Space Models (SSMs) and their recurrent formulation
  - Why needed here: RICO exploits the specific mathematical structure of SSMs where hidden states can be linearly combined. Without understanding ht = Atht-1 + Btxt, the separability property is opaque.
  - Quick check question: Can you explain why SSMs allow decomposing the output into separate contributions from context and query, while standard softmax attention does not?

- Concept: Gradient-based optimization and chain rule
  - Why needed here: The method requires computing ∂L/∂αi via chain rule through hidden states. Understanding gradient flow is essential for debugging why certain documents receive low weights.
  - Quick check question: If document weights α are initialized uniformly and you perform one gradient step with learning rate η, what determines which documents receive increased weights?

- Concept: Leave-one-out loss and influence functions
  - Why needed here: The theoretical justification connects gradient inner products to leave-one-out loss. This framing helps understand when the method will correctly identify informative vs. redundant documents.
  - Quick check question: Why does the gradient-based retrieval score upper-bound the leave-one-out loss, and what assumption is required for this bound to be tight?

## Architecture Onboarding

- Component map: Document Encoder -> State Index -> Query Processor -> Weight Optimizer -> Generator
- Critical path: 1) Offline: Precompute and index document states (one forward pass per document) 2) Online: Process query → compute ∂L/∂h → initialize weights (uniform or BM25 warm-start) → iterate gradient updates → retrieve/generate 3) Latency bottleneck: Gradient computation requires full forward+backward pass (192-522ms for Mamba2 models, vs. 2-39ms for BM25/E5)
- Design tradeoffs:
  - Warm start vs. uniform initialization: BM25 warm-start places weights in potentially better local minima but adds retriever dependency; uniform is model-pure but may converge slowly for large document stores
  - State compression: Subsampling layers (e.g., 10/64 for Mamba2-2.7b) reduces memory ~6x with minimal accuracy loss; aggressive compression degrades retrieval quality
  - Reranking vs. full retrieval: RICO is most efficient as a reranker over 10-20 candidates; full index retrieval requires state storage that scales linearly with corpus size
- Failure signatures:
  1. Question-answer loss misalignment: Model assigns high weight to documents that repeat the question rather than provide answers (Appendix C.3, Figure 9)
  2. Redundant information preference: Without conditioning on existing context, retriever may score documents containing information already in the query
  3. Language incompatibility: Multilingual retrievers may return documents the model cannot process; RICO naturally filters these (Appendix C.3)
  4. State memory overflow: Full state indexing for Mamba2-130m requires ~1M parameters per document; practical limit is a few thousand documents without compression
- First 3 experiments:
  1. Single-step gradient retrieval validation: Implement the simplified version (no iteration, uniform init) on HotpotQA with 10 ground-truth candidates. Compare nDCG@10 against BM25 baseline. Expected: ~5% below multi-step version per Figure 3.
  2. Loss landscape convexity check: For 100 query-document pairs, visualize question loss as a function of single document weight αi. Verify approximate convexity and that relevant documents produce lower loss than spurious ones (replicate Figure 6).
  3. Long-context state generation test: On TriviaQA subset where full documents exceed context length, compare: (a) truncation, (b) BM25 top-k concatenation, (c) learned state generation. Measure F1 via Ragchecker. Expected: state generation should show substantial gains per Table 3.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the internal SSM state representation be compressed or indexed to allow RICO to scale to document stores containing millions of entries?
- Basis in paper: [explicit] The Discussion section states that the "memory cost of indexing the full SSM state currently prevents us from indexing document stores larger than a few thousand documents."
- Why unresolved: While the authors tested layer subsampling, they note that "further research is needed" to determine if the state can be compressed further without losing the signal required for effective gradient-based retrieval.
- What evidence would resolve it: A retrieval mechanism using RICO that operates efficiently on a corpus comparable in size to standard industrial benchmarks (e.g., MS MARCO full passage corpus) without a significant drop in nDCG.

### Open Question 2
- Question: How can the proxy loss function be modified to better align with the oracle (answer) loss, particularly in failure cases involving repetition or complex entities?
- Basis in paper: [inferred] The Discussion notes that "there are times when the question loss does not align with the true answer loss," and Appendix C.3 shows failure cases where the model minimizes question perplexity by attending to repetitive or spurious contexts rather than facts.
- Why unresolved: Minimizing query perplexity does not guarantee the model has retrieved the specific evidence needed for the ground-truth answer, leading to suboptimal ranking.
- What evidence would resolve it: A reformulated unsupervised objective that correlates more strongly with answer likelihood than the current question perplexity metric.

### Open Question 3
- Question: Can test-time context optimization via learned attention masks be efficiently extended to standard Transformer architectures with softmax attention?
- Basis in paper: [explicit] Appendix A concludes that initial experiments on Phi-3.5-instruct "suggest interesting future investigation into whether test-time context optimization can be efficiently applied to transformers as well."
- Why unresolved: The core method relies on the linear recurrence of SSMs; the non-linearity of softmax attention in Transformers prevents a direct application of the theory.
- What evidence would resolve it: A demonstration that learning block attention masks for Transformers improves generation quality without the computational overhead of processing full contexts for every gradient step.

## Limitations
- The method's efficiency is limited by per-query gradient computation latency (192-522ms for Mamba2 models vs. 2-39ms for traditional methods)
- State indexing requirements scale linearly with corpus size, creating memory constraints even with layer compression
- The assumed convexity of the loss landscape is not proven, potentially leading to suboptimal local minima

## Confidence
*High Confidence:* The core mechanism of decomposing SSM outputs into context and query contributions is mathematically well-founded and supported by the model architecture. The empirical improvements in retrieval metrics and long-context generation are clearly demonstrated.

*Medium Confidence:* The theoretical connection between gradient inner products and leave-one-out loss is sound under convexity assumptions, but the practical tightness of this bound across diverse query types remains uncertain.

*Low Confidence:* The long-context generation mechanism shows impressive results but lacks comparative analysis against alternative state-based approaches. The information preservation properties of linear state combinations for generation tasks require further theoretical characterization.

## Next Checks
1. **Loss Landscape Verification**: For 100 random query-document pairs, systematically vary document weights α and record question perplexity. Plot loss surfaces to empirically verify convexity and identify any pathological non-convex regions that could trap gradient descent.

2. **Cross-Model Generalization**: Apply RICO to a non-SSM transformer model (e.g., Llama) by extracting and optimizing intermediate hidden states. Compare retrieval performance to establish whether the method's benefits extend beyond the specific state space model architecture.

3. **Memory-Accuracy Tradeoff Analysis**: Systematically evaluate retrieval quality across different state compression levels (varying layer subsampling ratios and dimensions). Determine the minimum viable state representation that maintains competitive performance, establishing practical deployment boundaries for large-scale applications.