---
ver: rpa2
title: 'AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence'
arxiv_id: '2504.04430'
source_url: https://arxiv.org/abs/2504.04430
tags:
- agitb
- input
- intelligence
- such
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AGITB introduces a novel benchmark for evaluating artificial general
  intelligence by focusing on low-level, signal-based prediction rather than high-level
  task performance. It comprises twelve automated tests grounded in axioms that reflect
  core computational properties observed in biological systems, such as determinism,
  adaptability, and generalization.
---

# AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence

## Quick Facts
- arXiv ID: 2504.04430
- Source URL: https://arxiv.org/abs/2504.04430
- Authors: Matej Šprogar
- Reference count: 5
- Primary result: Introduces twelve-axiom framework evaluating low-level signal prediction; claims no contemporary AI system passes all criteria.

## Executive Summary
AGITB introduces a novel benchmark for evaluating artificial general intelligence by focusing on low-level, signal-based prediction rather than high-level task performance. It comprises twelve automated tests grounded in axioms that reflect core computational properties observed in biological systems, such as determinism, adaptability, and generalization. The framework evaluates models on their ability to learn and predict temporal sequences of binary inputs without relying on prior knowledge, pretraining, or symbolic representations. Unlike existing benchmarks, AGITB avoids conventional correctness metrics, instead employing self-referential comparisons and requiring models to satisfy all twelve axioms. Preliminary application shows that no contemporary AI system meets all criteria, indicating that AGITB provides a structured means of assessing progress toward general intelligence. The benchmark is designed to resist brute-force or memorization-based strategies and emphasizes autonomous learning across previously unseen environments.

## Method Summary
AGITB evaluates models using twelve axioms targeting fundamental computational properties, requiring models to process 10-bit binary inputs through predict/update API calls. The benchmark employs self-referential evaluation, comparing independently instantiated model copies rather than measuring against ground truth. Tests include uninformed start (Axiom 1), determinism (Axiom 2), trace preservation (Axiom 3), temporal sensitivity (Axiom 4), refractory period constraints (Axiom 5), saturation limits (Axiom 6), temporal adaptability (Axiom 7), content sensitivity (Axiom 8), context sensitivity (Axiom 9), denoising capability (Axiom 10), generalization (Axiom 11), and real-time liveness (Axiom 12). Each axiom is tested across 5,000 trials using 7-step sequences, with success defined by relative consistency between model instances rather than absolute accuracy thresholds.

## Key Results
- No contemporary AI system satisfies all twelve axioms simultaneously
- Binary signal representation ensures maximum grounding while avoiding symbol grounding problems
- Self-referential evaluation approach eliminates need for external correctness metrics
- All-or-nothing requirement creates high-bar filter resistant to narrow capability aggregation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-referential evaluation avoids the need for external correctness metrics that conflate AGI with narrow AI performance.
- Mechanism: AGITB compares independently instantiated copies of a model under controlled conditions rather than measuring accuracy against ground truth. Success is defined by relative consistency between model instances, not absolute performance thresholds.
- Core assumption: Models that satisfy all twelve axioms simultaneously possess capabilities that exceed narrow, task-specific intelligence.
- Evidence anchors:
  - [abstract] "employs self-referential comparisons and requiring models to satisfy all twelve axioms"
  - [Section 3.1] "AGITB addresses this problem by employing a self-referential evaluation approach, in which the model under test is compared against itself"
  - [corpus] Weak direct evidence; related benchmarks (ARC-AGI-2) still use task-performance metrics rather than self-referential comparison.
- Break condition: If a narrow system passes all twelve tests through task-specific engineering rather than general learning, the self-referential approach fails to discriminate AGI.

### Mechanism 2
- Claim: Low-level binary signal prediction bypasses the symbol grounding problem that invalidates higher-level language-based benchmarks.
- Mechanism: By operating on 10-bit binary inputs with no semantic content, models must derive structure purely from temporal correlations without relying on pre-encoded knowledge or externally grounded symbols.
- Core assumption: Intelligence emerges from the ability to extract structure from raw sensory data, as biological cortices do with spike trains.
- Evidence anchors:
  - [abstract] "evaluates models on their ability to learn and predict temporal sequences of binary inputs without relying on prior knowledge, pretraining, or symbolic representations"
  - [Section 3] "A neural spike by itself contains the smallest amount of information possible and is, as such, grounded but free of other semantics"
  - [corpus] Related work (Some things to know about achieving AGI) similarly argues current GenAI models fail because they "cast every problem as a language pattern learning problem."
- Break condition: If binary signals can be mapped to symbols by the model designer through encoding conventions, the grounding advantage is lost.

### Mechanism 3
- Claim: The all-or-nothing twelve-axiom requirement creates a high-bar filter that individual narrow capabilities cannot satisfy through aggregation.
- Mechanism: Each axiom targets a distinct computational property (determinism, temporal sensitivity, generalization, real-time constraints). While narrow systems may pass individual tests, the conjunction requires integrated adaptive learning across all dimensions simultaneously.
- Core assumption: General intelligence requires synergistic integration of multiple low-level capabilities rather than additive specialization.
- Evidence anchors:
  - [abstract] "no contemporary AI system meets all criteria, indicating that AGITB provides a structured means of assessing progress toward general intelligence"
  - [Section 3.1] "the simultaneous satisfaction of all twelve requirements is believed to demand capabilities beyond narrow intelligence"
  - [corpus] No corpus papers explicitly test conjunctive axiom-based evaluation; most use task-accumulation approaches.
- Break condition: If future systems satisfy all axioms through modular combination of narrow components without genuine integration, the conjunctive filter would yield false positives.

## Foundational Learning

- Concept: **Symbol Grounding Problem**
  - Why needed here: AGITB's core design motivation is avoiding the problem that symbols (including numbers in ARC, words in LLMs) derive meaning from human interpretation rather than intrinsic model experience.
  - Quick check question: Can you explain why a model that processes the digit "5" doesn't inherently understand "fiveness" vs. a model that processes raw binary spikes?

- Concept: **Temporal Sequence Learning vs. Static Pattern Matching**
  - Why needed here: AGITB evaluates prediction across time steps with order-dependent learning (Axiom 4: Time), fundamentally different from static input-output mapping benchmarks.
  - Quick check question: Why does Axiom 4 (input order sensitivity) rule out architectures that treat inputs as unordered sets?

- Concept: **Autoregressive Generation with Feedback**
  - Why needed here: AGITB's learning definition (Definition 5) requires models to autoregressively reproduce sequences after exposure, with each prediction feeding back into the model state.
  - Quick check question: How does autoregressive generation differ from one-shot prediction, and why does AGITB require the former for demonstrating learning?

## Architecture Onboarding

- Component map:
  Model Interface -> Axiom Tests -> Evaluation Harness -> Search Space

- Critical path:
  1. Implement model class satisfying the API (predict + update)
  2. Verify uninformed start (Axiom 1) — all instances begin in identical configuration with no environment-specific knowledge
  3. Pass determinism and trace tests (Axioms 2-3) — ensure reproducible, non-repeating state evolution
  4. Satisfy temporal learning requirements (Axioms 4-9) — demonstrate order sensitivity, variable-length sequence learning, context-dependent adaptation
  5. Clear generalization and denoising thresholds (Axioms 10-11) — outperform constant baselines systematically across 5,000 trials
  6. Maintain real-time liveness (Axiom 12) — bounded update time regardless of model complexity

- Design tradeoffs:
  - Tabula rasa initialization vs. architectural bias: Complete uninformedness risks degeneracy; some learning-inducing structure may be necessary while avoiding environment-specific priors
  - Fixed 7-step sequences: Long enough to resist memorization, short enough for computational tractability; may miss capabilities requiring longer temporal horizons
  - Binary representation: Maximally grounded but limits semantic richness; may under-test abstraction capabilities

- Failure signatures:
  - LLMs fail Axiom 1 (pretraining violates uninformed start) and Axiom 3 (context window discards information, violating permanent trace)
  - Symbolic programs fail Axiom 1 (program code constitutes prior knowledge)
  - Standard ANNs fail Axiom 1 (random initialization introduces implicit structure) and lack autonomous update mechanisms
  - Models that slow down with accumulated experience fail Axiom 12

- First 3 experiments:
  1. Baseline characterization: Run a simple n-gram predictor through AGITB to identify which axioms it fails and why; document failure modes.
  2. Axiom isolation test: Build a minimal model that passes only Axiom 1-3 (uninformed, deterministic, trace-preserving) to understand the substrate requirements before tackling learning.
  3. Generalization probe: Implement a model that passes Axioms 1-9, then systematically test denoising (Axiom 10) vs. generalization (Axiom 11) to determine if they require distinct mechanisms or share computational substrates.

## Open Questions the Paper Calls Out
None

## Limitations
- Self-referential evaluation may not truly discriminate AGI from sophisticated narrow AI systems
- Binary signal representation may be too impoverished to capture higher-order cognitive capabilities
- Definition of "uninformed start" lacks clear operational criteria for distinguishing permissible vs. impermissible architectural bias

## Confidence
- **High confidence**: The benchmark's design principles (self-referential evaluation, low-level signal processing, all-axiom requirement) are internally consistent and address known limitations of existing benchmarks.
- **Medium confidence**: The claim that no contemporary AI system passes all twelve axioms appears valid based on the strict requirements, though systematic testing across diverse model architectures would strengthen this assertion.
- **Low confidence**: The assertion that AGITB provides a structured means of "assessing progress toward general intelligence" assumes that passing the benchmark equates to progress toward AGI, which conflates capability demonstration with intelligence measurement.

## Next Checks
1. Empirical Axiom Isolation: Systematically test a diverse set of existing AI architectures against individual AGITB axioms to create a detailed failure mode taxonomy.
2. Transferability Assessment: Evaluate whether models that pass AGITB's axioms on one signal type can generalize to other grounded representations.
3. Grounding Validation: Conduct controlled experiments to verify that AGITB's binary signals are indeed "maximally grounded" and not inadvertently encoding structure through implementation choices.