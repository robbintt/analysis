---
ver: rpa2
title: A Framework for Uncertainty Quantification Based on Nearest Neighbors Across
  Layers
arxiv_id: '2506.19895'
source_url: https://arxiv.org/abs/2506.19895
tags:
- uncertainty
- layer
- each
- metrics
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a post-hoc framework for quantifying uncertainty
  in neural network predictions by analyzing nearest-neighbor class distributions
  across layers. The method retrieves training samples with similar activation vectors
  at each layer and introduces two uncertainty metrics: Decision Change (DC), which
  tracks the stability of dominant class predictions across layers, and Layer Uncertainty
  (LU), which measures class ambiguity using entropy.'
---

# A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers

## Quick Facts
- arXiv ID: 2506.19895
- Source URL: https://arxiv.org/abs/2506.19895
- Authors: Miguel N. Font; José L. Jorro-Aragoneses; Carlos M. Alaíz
- Reference count: 24
- Primary result: Post-hoc uncertainty quantification framework using nearest-neighbor class distributions across layers; DC+LU metrics outperform softmax confidence, especially on CIFAR-10

## Executive Summary
This paper introduces a post-hoc framework for quantifying uncertainty in neural network predictions by analyzing nearest-neighbor class distributions across layers. The method retrieves training samples with similar activation vectors at each layer and introduces two uncertainty metrics: Decision Change (DC), which tracks the stability of dominant class predictions across layers, and Layer Uncertainty (LU), which measures class ambiguity using entropy. Evaluated on MNIST and CIFAR-10 datasets, the approach outperforms softmax-based confidence, especially in challenging classification tasks. The combined DC+LU metrics achieve higher AUROC and AUPR for both success and error detection compared to softmax alone, demonstrating improved uncertainty estimation particularly in lower-accuracy regimes.

## Method Summary
The framework stores activation vectors from all training samples at each layer in a Training Activation Repository (TAR). For each query sample, it retrieves k nearest neighbors per layer using Bray-Curtis distance and builds a Prediction Behavior Analysis Table (PBAT). From PBAT, it computes Decision Change (DC) by counting dominant class changes across consecutive layers and Layer Uncertainty (LU) by calculating Shannon entropy of neighbor class distributions. A logistic regression model combines these metrics with softmax confidence to classify correct vs. incorrect predictions. The method is model-agnostic and interpretable, offering complementary uncertainty signals by examining internal network dynamics rather than just final outputs.

## Key Results
- On CIFAR-10, DC+LU metrics achieve 73.80% AUROC vs 71.33% for softmax baseline
- LU alone outperforms softmax on AUROC for both MNIST (92.55% vs 90.03%) and CIFAR-10 (72.30% vs 71.33%)
- Framework particularly effective in lower-accuracy regimes where softmax confidence degrades
- Optimal neighborhood size varies: k=3 for DC on MNIST, k=20 for LU on MNIST and both on CIFAR-10

## Why This Works (Mechanism)

### Mechanism 1
Prediction stability across layers correlates with classification correctness. For each layer, retrieve k training samples with similar activation vectors. Track whether the dominant class (most frequent label among neighbors) changes between consecutive layers. Frequent changes signal unstable internal representations. Correct predictions exhibit more stable neighbor class distributions across layers than incorrect ones. Evidence: On CIFAR-10, DC alone achieves AUROC of 71.13% vs softmax baseline of 71.33%. Break condition: If the model's representations are highly non-monotonic, DC may lose discriminative power.

### Mechanism 2
Local neighborhood class entropy reflects prediction confidence within each layer. Compute Shannon entropy of class distribution among k nearest neighbors at each layer. Low entropy (neighbors concentrated in one class) indicates high-confidence regions; high entropy indicates ambiguous boundary regions. Samples in ambiguous regions of feature space have neighbors from multiple classes. Evidence: LU alone outperforms softmax on AUROC for both MNIST (92.55% vs 90.03%) and CIFAR-10 (72.30% vs 71.33%). Break condition: If k is too small, entropy estimates become noisy; if k is too large, local structure is washed out.

### Mechanism 3
Combining DC and LU captures complementary uncertainty signals absent from final softmax output. DC captures temporal (cross-layer) instability; LU captures spatial (within-layer) ambiguity. Softmax only reflects final-layer confidence. Logistic regression on [DC, LU] or [SM, DC, LU] vectors yields better error detection. Uncertainty manifests both as instability across layers and as ambiguity within layers—and these are not fully captured by softmax. Evidence: For CIFAR-10, the combined metrics outperform the softmax baseline across all metrics. SM+DC+LU achieves 73.80% AUROC vs 71.33% for softmax alone. Break condition: If DC and LU are highly correlated, their combination provides diminishing returns.

## Foundational Learning

- Concept: k-Nearest Neighbors in Feature Space
  - Why needed here: The entire framework depends on retrieving similar training samples via distance metrics in activation space.
  - Quick check question: Given activation vectors [1,0] and [0,1], what distance metric would return different neighbor rankings than Euclidean distance?

- Concept: Shannon Entropy for Discrete Distributions
  - Why needed here: LU is computed as entropy over neighbor class labels; you must interpret low vs high entropy.
  - Quick check question: If 5 neighbors have class labels [A,A,A,B,B], what is the entropy? What if they were [A,B,C,D,E]?

- Concept: Feedforward Neural Network Layer Activations
  - Why needed here: You must extract and store activations from each layer to build the Training Activation Repository.
  - Quick check question: For a CNN with conv→pool→conv→pool→fc→softmax, how many distinct activation tensors would you store per input?

## Architecture Onboarding

- Component map: Training model -> Build TAR by forward-passing training data -> Extract query activations -> Retrieve neighbors per layer -> Populate PBAT -> Compute DC/LU -> Aggregate with logistic regression

- Critical path: (1) Train model → (2) Build TAR by forward-passing all training data → (3) At inference, extract query activations → (4) Retrieve neighbors per layer → (5) Populate PBAT → (6) Compute DC/LU → (7) Aggregate for final uncertainty score

- Design tradeoffs:
  - Distance metric: Bray–Curtis used; Euclidean/Cosine configurable—empirically validate per dataset
  - Neighborhood size (k): Table 1 shows optimal k varies (k=3 for DC on MNIST, k=20 for LU on MNIST, k=20 for both on CIFAR-10). Larger k smooths estimates but may dilute local signal
  - Storage vs speed: TAR requires O(n × L × d) storage (n=samples, L=layers, d=activation dim); retrieval is O(n) per query without indexing
  - Layer selection: Paper uses all layers; Assumption: pruning layers may reduce noise but also lose signal—untested

- Failure signatures:
  - High accuracy regime (MNIST: 98.39%): DC underperforms (AUROC 83.67% vs softmax 90.03%)—stable predictions reduce DC's discriminability
  - Small k on complex data: Increased variance in entropy estimates
  - Non-representative TAR: If training set doesn't cover query distribution, neighbors are uninformative
  - Very deep networks: More layers increase DC sensitivity; may need layer sampling or aggregation

- First 3 experiments:
  1. Reproduce Table 2 on MNIST subset: Train CNN, build TAR for 1000 training samples, compute DC/LU for 200 test samples, compare AUROC against softmax. Validates implementation
  2. Vary k (3, 5, 10, 20) on a validation split: Plot AUROC vs k for DC and LU separately. Confirms optimal neighborhood size
  3. Test on a different architecture (e.g., ResNet-18 on CIFAR-10): Assess model-agnostic claim—does DC+LU still outperform softmax? Check if layer count affects DC calibration

## Open Questions the Paper Calls Out

### Open Question 1
Can the layer-wise nearest-neighbor framework effectively quantify uncertainty in non-feedforward architectures like RNNs or Transformers? The authors list "using it in other architectures like RNNs or transformers" as a promising direction for future work. This remains unresolved as the current evaluation is restricted to Convolutional Neural Networks (CNNs), and it is unclear if the concept of "layers" and activation vectors translates effectively to attention mechanisms or recurrent states.

### Open Question 2
How does the framework perform in distinguishing Out-of-Distribution (OoD) samples compared to in-distribution misclassifications? The authors acknowledge "using it for Out-of-Distribution (OoD) Detection" as a specific extension of this work. This remains unresolved as the paper only evaluates the detection of incorrect predictions on test sets known to the model, rather than analyzing how the metrics react to data from entirely different distributions.

### Open Question 3
Can approximate nearest neighbor search or case condensation reduce the computational overhead without degrading the quality of uncertainty estimates? The authors identify computational overhead as a "key limitation" and suggest strategies like "approximate nearest neighbor search" or "case condensation." This remains unresolved as it is untested whether reducing the precision of the neighbor retrieval process preserves the integrity of the decision change and entropy calculations.

## Limitations
- Computational overhead from storing and querying full activation repositories, scaling poorly with dataset size and model depth
- Limited dataset diversity (only MNIST and CIFAR-10) constraining generalizability claims
- No evaluation of out-of-distribution or adversarial robustness, leaving uncertainty quantification incomplete for realistic deployment scenarios

## Confidence
- Framework performance claims: Medium (limited dataset diversity, no ablation studies)
- Model-agnostic superiority: Low confidence (no testing on ResNets or Transformers)
- DC+LU combination effectiveness: Medium (novel combination, but correlation untested)

## Next Checks
1. Ablation on layer selection: Test whether using only intermediate layers maintains or improves performance, and quantify storage/compute savings
2. Cross-architecture robustness: Apply the framework to a ResNet-18 on CIFAR-10 and a Transformer on a text task; compare DC+LU vs softmax AUROC
3. Distance metric sensitivity: Replace Bray-Curtis with Euclidean and Cosine distances; report performance changes and identify which metric is optimal per dataset