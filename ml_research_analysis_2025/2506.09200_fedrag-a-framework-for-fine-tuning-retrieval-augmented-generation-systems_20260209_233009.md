---
ver: rpa2
title: 'FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems'
arxiv_id: '2506.09200'
source_url: https://arxiv.org/abs/2506.09200
tags:
- fine-tuning
- https
- fedrag
- knowledge
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedRAG is a framework for fine-tuning Retrieval-Augmented Generation
  (RAG) systems across centralized and federated architectures. It supports state-of-the-art
  fine-tuning methods like RALT and LSR, offers seamless integration with popular
  RAG ecosystem tools (HuggingFace, Unsloth, LlamaIndex), and provides a simple interface
  for converting centralized training tasks to federated ones.
---

# FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems

## Quick Facts
- arXiv ID: 2506.09200
- Source URL: https://arxiv.org/abs/2506.09200
- Authors: Val Andrei Fajardo; David B. Emerson; Amandeep Singh; Veronica Chatrath; Marcelo Lotif; Ravi Theja; Alex Cheung; Izuki Matsuba
- Reference count: 40
- Primary result: FedRAG improves MMLU global facts performance from 22.0% to 30.5% average across two runs

## Executive Summary
FedRAG is a comprehensive framework for fine-tuning Retrieval-Augmented Generation (RAG) systems across both centralized and federated architectures. The framework integrates state-of-the-art fine-tuning methods like RALT (Retrieval-Augmented Language Model Training) and LSR (Language Model Supervised Retriever training) with popular RAG ecosystem tools including HuggingFace, Unsloth, and LlamaIndex. FedRAG addresses a critical gap in available tools by enabling researchers to efficiently fine-tune RAG systems while maintaining reproducibility. A lightweight experiment demonstrates the effectiveness of RALT fine-tuning on the MMLU global facts benchmark, with a development roadmap including future features like MCP knowledge store integration and ReSearch generator training.

## Method Summary
FedRAG provides a unified framework for fine-tuning RAG systems by integrating RALT and LSR methods with federated learning capabilities. The framework supports various retriever types (including sentence transformers and DRAGON+), generator models (including quantized Llama2-7B via Unsloth), and knowledge stores (including Qdrant). The lightweight experiment used DRAGON+ dual-encoder retriever, 4-bit quantized Llama2-7B generator with QLoRA, and a Wikipedia-based knowledge store to fine-tune on Web Questions dataset and evaluate on MMLU global facts. The framework allows seamless conversion of centralized training tasks to federated settings using Flower, with local training on client devices and global aggregation via federated averaging.

## Key Results
- RALT fine-tuning improved MMLU global facts benchmark performance from 22.0% to 30.5% average across two runs
- Framework supports both centralized and federated fine-tuning with minimal code changes
- Seamless integration with popular RAG ecosystem tools (HuggingFace, Unsloth, LlamaIndex)
- Lightweight experiment validates effectiveness of RALT approach on knowledge-intensive tasks

## Why This Works (Mechanism)

### Mechanism 1: Retrieval-Augmented Language Model Training (RALT)
Fine-tuning the generator with retrieved context improves RAG system performance on knowledge-intensive tasks. The generator is trained on instruction examples that include context retrieved by the retriever from the knowledge store, conditioning it to better integrate retrieved information when generating responses. Evidence shows RALT improves MMLU global facts from 22.0% to 30.5%. Break condition: If retriever provides irrelevant context, generator may learn to rely on noisy signals.

### Mechanism 2: Language Model Supervised Retriever Training (LSR)
Fine-tuning the retriever using generator feedback improves retrieval quality by aligning retrieval scores with generation utility. Two distributions are formed—retrieval scores and generator conditional probabilities—and the KL divergence between them is minimized. The generator's conditional probabilities guide the retriever to rank chunks by actual usefulness. Break condition: If generator produces unreliable probability estimates, retriever learns to optimize for incorrect signals.

### Mechanism 3: Federated Averaging for Decentralized RAG Fine-Tuning
Centralized RAG fine-tuning tasks can be converted to federated settings with minimal code changes while preserving model quality. Each client performs local fine-tuning on private data, and model updates are aggregated via federated averaging without centralizing raw data. Break condition: Highly heterogeneous client data may cause federated averaging to converge poorly or produce worse results than centralized training.

## Foundational Learning

- **RAG System Components (Retriever, Generator, Knowledge Store)**: Why needed: FedRAG's architecture assumes understanding how these three components interact through retrieval to generation. Quick check: Can you explain what happens when a user query enters a RAG system, step by step?

- **Instruction Fine-Tuning**: Why needed: RALT is specialized instruction fine-tuning with retrieved context. Understanding standard instruction tuning helps grasp why additional context matters. Quick check: What is the difference between pre-training and instruction fine-tuning, and why does the latter improve task performance?

- **Federated Learning Basics (Local Training, Global Aggregation)**: Why needed: Converting centralized training to federated requires understanding that clients train locally and share only model updates. Quick check: Why does federated averaging preserve privacy, and what is one scenario where it might fail to converge?

## Architecture Onboarding

- **Component map**:
  ```
  fed_rag/core/ → RAGSystem, RAGConfig
  fed_rag/retrievers/ → HFSentenceTransformerRetriever
  fed_rag/generators/ → UnslothFastModelGenerator
  fed_rag/knowledge_stores/ → QdrantKnowledgeStore
  fed_rag/trainers/ → HuggingFaceTrainerForRALT, HuggingFaceTrainerForLSR
  fed_rag/trainer_managers/ → HuggingFaceRAGTrainerManager
  fed_rag/fl_tasks/ → FLTask objects
  fed_rag/evals/ → Benchmarker, Benchmarks (MMLU)
  ```

- **Critical path**:
  1. Assemble RAGSystem from KnowledgeStore + Retriever + Generator
  2. Populate knowledge store with embedded chunks using retriever's context encoder
  3. Create Trainer objects (RALT for generator, LSR for retriever)
  4. Use TrainerManager to orchestrate which model trains while the other is frozen
  5. (Optional) Extract FLTask from manager and deploy with Flower for federated training
  6. Evaluate with Benchmarker using benchmarks like MMLU

- **Design tradeoffs**:
  - RALT vs. LSR vs. Both: RA-DIT yields greatest gains but doubles training time; start with RALT if compute-constrained
  - Centralized vs. Federated: Federated preserves privacy but introduces communication overhead and potential convergence issues with non-IID data
  - Generator size: 4-bit quantized Llama2-7B used; larger generators may improve quality but require more GPU memory and longer training

- **Failure signatures**:
  - High run-to-run variability: Caused by sampling parameters; fix by setting deterministic sampling (temperature=0) during evaluation
  - No improvement after fine-tuning: Check retriever quality first—is retrieved context actually relevant?
  - Federated training diverges: Client data may be too heterogeneous; start with homogeneous simulated clients

- **First 3 experiments**:
  1. Establish baseline: Run RAGSystem without fine-tuning on MMLU global facts (100 examples); record exact match accuracy
  2. Apply RALT fine-tuning: Fine-tune generator on Web Questions dataset using HuggingFaceTrainerForRALT with QLoRA; re-evaluate on MMLU; compare to baseline
  3. Federated conversion test: Convert RALT trainer to FLTask and run with 2-3 simulated clients (split Web Questions data); verify federated model achieves comparable performance to centralized training

## Open Questions the Paper Calls Out

### Open Question 1
How does adapting RAG systems to knowledge provided by third-party Model Context Protocol (MCP) providers affect system performance and reliability? The development roadmap states that integrating an MCP RAG system will "pave the way for studying the effects of adapting RAG systems to knowledge provided by third-party MCP providers." This remains unresolved as MCP integration is a planned future feature with no implementation or evaluation yet.

### Open Question 2
How does the performance of federated fine-tuning via FedRAG compare to centralized fine-tuning in terms of convergence speed and final accuracy? While the framework validates centralized fine-tuning (improving MMLU scores) and provides code for federated conversion, no experimental results from federated runs are presented. This comparison remains unverified by empirical data.

### Open Question 3
Can the ReSearch method (reinforcement learning with search) be successfully integrated as a generator trainer within the FedRAG framework? The roadmap lists "ReSearch generator trainer" as a high-priority item to equip generator LLMs with "reasoning infused with search." This specific implementation is a planned future feature, with current version supporting only RALT and LSR trainers.

## Limitations
- Limited empirical validation with only two runs on a subset (100 examples) of the MMLU benchmark
- Missing hyperparameter details (learning rate, batch size, epochs, sampling parameters) creating reproducibility barriers
- Evaluation focuses solely on generator fine-tuning (RALT) without examining retriever fine-tuning (LSR) or the combined RA-DIT approach

## Confidence

- **High Confidence**: The framework architecture and design principles are sound, building on established RAG fine-tuning methods with clear integration patterns and reasonable abstractions
- **Medium Confidence**: The technical implementation appears correct based on described components and interactions, though lightweight experiment provides limited validation of actual performance gains
- **Low Confidence**: Claims about federated performance relative to centralized training are entirely unsupported by empirical evidence in the paper

## Next Checks

1. Reproduce the MMLU global facts experiment with 5+ runs and report mean ± standard deviation to quantify the claimed improvement from 22.0% to 30.5%
2. Evaluate LSR fine-tuning on the same dataset to compare retriever improvement against the generator-only RALT results
3. Conduct a small federated experiment (3-5 simulated clients) to verify that federated averaging preserves the performance gains observed in centralized training