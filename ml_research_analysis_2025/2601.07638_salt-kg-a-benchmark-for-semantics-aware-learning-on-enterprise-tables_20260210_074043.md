---
ver: rpa2
title: 'SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables'
arxiv_id: '2601.07638'
source_url: https://arxiv.org/abs/2601.07638
tags:
- tabular
- data
- learning
- relational
- sales
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SALT-KG extends the SALT relational prediction benchmark by integrating
  structured operational business knowledge from a metadata knowledge graph, enabling
  semantics-aware learning on enterprise tables. This graph layer captures field-level
  descriptions, business object types, and declarative relationships, allowing models
  to reason over both tabular data and contextual semantics.
---

# SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables

## Quick Facts
- arXiv ID: 2601.07638
- Source URL: https://arxiv.org/abs/2601.07638
- Authors: Isaiah Onando Mulang; Felix Sasaki; Tassilo Klein; Jonas Kolk; Nikolay Grechanov; Johannes Hoffart
- Reference count: 40
- Primary result: Semantics-aware learning on enterprise tables via metadata knowledge graph yields modest accuracy gains but exposes architectural gaps

## Executive Summary
SALT-KG extends the SALT relational prediction benchmark by integrating structured operational business knowledge from a metadata knowledge graph, enabling semantics-aware learning on enterprise tables. This graph layer captures field-level descriptions, business object types, and declarative relationships, allowing models to reason over both tabular data and contextual semantics. Empirical evaluation shows that metadata-derived features yield only modest improvements in classical prediction metrics but consistently reveal gaps in models' ability to exploit semantic alignment and contextual relationships. The benchmark highlights the need for architectures that integrate relational structure with declarative schema semantics to advance tabular foundation models grounded in enterprise knowledge.

## Method Summary
SALT-KG combines SALT's multi-table transactional data with an Operational Business Knowledge Graph (OBKG) containing schema descriptions and business object types. The method extracts textual metadata (CDS Views, fields, object node types) via SPARQL queries, embeds them using text-embedding-3-large, reduces dimensionality with PCA (16-64 components), and concatenates the semantic vectors with raw tabular features before prediction. The benchmark evaluates 8 target prediction tasks (e.g., SalesOffice, Plant) using 21 input features across tree-based and neural baselines, measuring performance with Mean Reciprocal Rank (MRR).

## Key Results
- Metadata-derived features yield only modest improvements in prediction accuracy (ΔMRR typically <0.05)
- Tree-based models (XGBoost, LightGBM) show stable but minimal gains from semantic features
- Neural models exhibit higher variance in response to semantic features, suggesting greater sensitivity to semantic alignment
- Current architectures struggle to meaningfully leverage declarative schema semantics despite successful feature fusion

## Why This Works (Mechanism)

### Mechanism 1
Integrating a Metadata Knowledge Graph (OBKG) with relational tables allows models to condition predictions on contextual semantics rather than relying solely on statistical correlations from raw data. The system extracts textual descriptions of tables (CDS Views), fields, and business object types from the OBKG via SPARQL queries. These texts are embedded into high-dimensional vectors, reduced via PCA, and concatenated with raw tabular features (early fusion) before being passed to the predictor. The core assumption is that text embeddings of schema metadata contain recoverable semantic signals that generalize across specific data instances. Evidence shows semantic grounding modifies inductive biases rather than raw predictive accuracy, though if PCA reduction discards nuanced semantic distinctions, the signal degrades into noise.

### Mechanism 2
Reframing tabular prediction as "semantics-conditioned reasoning" exposes the inability of current architectures to exploit declarative schema knowledge, even if raw accuracy gains are modest. By explicitly separating the "relational layer" (joins/foreign keys) from the "operational business knowledge layer" (declarative descriptions), the benchmark isolates the model's capacity to use semantic definitions. The OBKG provides field-level semantics that are absent in pure relational benchmarks. The core assumption is that models possess the internal architecture necessary to map semantic definitions to numerical reasoning steps. Evidence indicates current models treat semantic embeddings as generic dense features without aligning them to specific query columns, failing to improve reasoning.

### Mechanism 3
Semantic augmentation modifies the inductive biases of deep learning models differently than tree-based models, revealing structural limitations in how neural nets handle heterogeneous feature types. Tree-based models handle categorical splits natively and remain stable, while neural models receive the concatenated semantic vector, which changes their learned representation but leads to inconsistent performance gains. The core assumption is that the semantic vector provides a regularization effect or auxiliary signal that neural networks can theoretically integrate better than trees, despite current instability. Evidence shows high variance in delta MRR for neural methods like AutoGluon versus stability in XGBoost, though if the dataset's ontological depth is too shallow, the semantic signal is insufficient to guide the neural network.

## Foundational Learning

- **Concept: Knowledge Graph Embedding & Fusion**
  - **Why needed here:** The core of SALT-KG is the fusion of high-dimensional text embeddings (from the KG) with tabular features. You must understand how text-embedding-3-large and PCA work to compress semantic meaning into a vector compatible with a tabular row.
  - **Quick check question:** Can you explain why reducing semantic embeddings to 16–64 dimensions via PCA might be necessary before concatenating them with tabular features?

- **Concept: Relational vs. Declarative Semantics**
  - **Why needed here:** The paper distinguishes between *how* data joins (relational) and *what* data means (declarative). Understanding this separation is crucial to diagnosing why models fail to exploit the OBKG context.
  - **Quick check question:** If a model predicts "Sales Office" correctly using only "Sales Organization" IDs, is it using declarative semantics or statistical correlation? (Answer: likely statistical correlation).

- **Concept: Inductive Bias in Tabular Models**
  - **Why needed here:** The results show tree-based models react differently to semantic context than neural models. You need to grasp why neural nets might theoretically benefit more from semantic context despite current poor performance.
  - **Quick check question:** Why might a decision tree be less sensitive to a dense semantic vector description of a column than a neural network layer?

## Architecture Onboarding

- **Component map:** Source Layer (SALT tables + OBKG) -> Extraction Layer (SPARQL queries) -> Semantic Encoder (text-embedding-3-large + PCA) -> Tabular Encoder (native/ intrinsic) -> Fusion Layer (concatenation) -> Head (target predictors)

- **Critical path:**
  1. Verify the SPARQL join: Ensure every column in the SALT table has a corresponding node in the OBKG (approx. 990 fields mapped).
  2. Monitor the PCA projection: Ensure the explained variance ratio is sufficient to retain meaning in the 16–64 component range.
  3. Check the fusion tensor shapes: Ensure the semantic vector aligns with the batch size of the tabular data during concatenation.

- **Design tradeoffs:**
  - Vector Dimensions: The paper notes higher dimensions lead to "noise amplification" and "weak signal utilization." Start with 32 components as a safe midpoint.
  - Model Selection: If priority is stability, use XGBoost/CatBoost (low sensitivity to semantics). If priority is researching semantic integration, use CARTE or AutoGluon (higher sensitivity/variance).
  - Ontological Depth: The current OBKG has limited "higher-order abstraction" (e.g., class hierarchies). Do not expect the model to infer complex transitive relationships not present in the graph.

- **Failure signatures:**
  - Semantic Noise: Performance degradation (negative ΔMRR) when adding KG features, particularly in LightGBM or GraphSAGE.
  - Fusion Mismatch: Models failing to converge if the semantic vector scale dwarfs the tabular feature scale (normalization required).
  - Shallow Reasoning: The model improves on frequent classes (Sales Office) but fails on rare classes (Customer Payment Terms), indicating it relies on statistical priors rather than semantic definitions.

- **First 3 experiments:**
  1. Baseline Stability Check: Run XGBoost on raw SALT data vs. SALT + KG features. Confirm that ΔMRR is near zero (as per paper results) to validate your pipeline.
  2. Dimensionality Sensitivity: Sweep PCA components [16, 32, 64, 128] on a neural baseline (e.g., AutoGluon) to identify the "noise amplification" threshold.
  3. Ablation on Semantic Modalities: Train models using *only* OBKG embeddings (no raw tabular data) to verify if any signal exists purely in the schema descriptions.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the choice of embedding strategy and fusion method affect the utilization of Operational Business Knowledge Graph (OBKG) signals in tabular models?
- **Basis in paper:** [explicit] The authors explicitly "leave these as open research questions," specifically citing the need to "investigate the strength of the signals obtained from the OBKG and the effectiveness of the embedding representation used."
- **Why unresolved:** The paper utilized a baseline approach (text-embedding-3-large with PCA and early fusion) which resulted in only modest improvements, leaving the potential of optimized representations unexplored.
- **What evidence would resolve it:** Ablation studies comparing various text encoders or graph-based embedding techniques against the baseline, demonstrating significant performance gains on the SALT-KG tasks.

### Open Question 2
- **Question:** What model architectures can successfully unify relational structure with declarative schema semantics to move beyond simple feature-level concatenation?
- **Basis in paper:** [explicit] The conclusion states a "need for future work on architectures that unify relational, semantic, and linguistic understanding" and notes that current graph-based models show inconsistency.
- **Why unresolved:** Current baselines rely on early fusion or standard relational encoders which fail to fully exploit semantic alignment, resulting in models that modify inductive biases without significantly improving accuracy.
- **What evidence would resolve it:** The development of a model that processes the OBKG topology jointly with tabular data, achieving substantial performance increases over standard tree-based and neural baselines.

### Open Question 3
- **Question:** To what extent does increasing the ontological depth and cross-entity abstraction of the underlying dataset enable models to internalize higher-order context?
- **Basis in paper:** [inferred] The authors note that the current "relational scaffold... provides limited ontological depth" and suggest future work must "introduce ontological structure... to enable models internalize higher-order context."
- **Why unresolved:** The current SALT-KG dataset limits semantics to direct relationships, constraining the ability to evaluate if models can leverage richer class hierarchies or transitivity for generalization.
- **What evidence would resolve it:** Evaluation of models on an extended version of SALT-KG containing deeper class hierarchies, showing that semantic grounding improves predictive accuracy as ontological richness increases.

## Limitations
- Current OBKG lacks sufficient ontological depth (shallow class hierarchies and few transitive relationships)
- Modest accuracy improvements suggest current architectures struggle to meaningfully leverage declarative semantics
- Benchmark may not fully stress-test models' ability to reason over complex enterprise knowledge due to limited semantic richness

## Confidence
- **High**: The benchmark architecture and data integration pipeline are sound and reproducible.
- **Medium**: The claim about neural models having greater sensitivity to semantic alignment is supported by variance in results but requires further investigation to confirm causality.
- **Medium**: The assertion that current models fail to exploit semantic context is demonstrated empirically but the underlying architectural reasons remain partially speculative.

## Next Checks
1. Conduct an ablation study comparing models trained on raw SALT data, SALT + KG features, and KG features alone to quantify the isolated contribution of semantic context.
2. Test alternative semantic fusion strategies (late fusion, attention-based weighting) to determine if the modest improvements stem from the fusion method rather than semantic features themselves.
3. Evaluate model performance on synthetic tables with artificially enhanced semantic depth to determine whether performance plateaus due to inherent architectural limitations or insufficient ontological richness.