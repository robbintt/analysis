---
ver: rpa2
title: 'Polish-ASTE: Aspect-Sentiment Triplet Extraction Datasets for Polish'
arxiv_id: '2502.20046'
source_url: https://arxiv.org/abs/2502.20046
tags:
- datasets
- sentiment
- polish
- aspect
- aste
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two new datasets for Aspect-Sentiment Triplet
  Extraction (ASTE) in Polish, covering hotel and product reviews. The datasets are
  designed to facilitate research in under-resourced languages and are compatible
  with existing English ASTE datasets.
---

# Polish-ASTE: Aspect-Sentiment Triplet Extraction Datasets for Polish

## Quick Facts
- arXiv ID: 2502.20046
- Source URL: https://arxiv.org/abs/2502.20046
- Authors: Marta Lango; Borys Naglik; Mateusz Lango; Iwo Naglik
- Reference count: 0
- Primary result: Introduces two new ASTE datasets for Polish covering hotel and product reviews, demonstrating the increased difficulty of ASTE tasks in Polish compared to English.

## Executive Summary
This paper introduces two new datasets for Aspect-Sentiment Triplet Extraction (ASTE) in Polish, covering hotel and product reviews. The datasets are designed to facilitate research in under-resourced languages and are compatible with existing English ASTE datasets. The annotation guidelines and inter-annotator agreement are detailed, and the datasets are made publicly available under a permissive license. Experiments with two ASTE methods (GTS and EPISA) combined with two Polish language models (HerBERT and TrelBERT) show that the Polish datasets are more challenging than their English counterparts, with lower performance metrics (F1 scores around 40-45% vs. 63-68% for English). This highlights the need for further research in ASTE for Slavic languages.

## Method Summary
The authors created two new datasets for Polish Aspect-Sentiment Triplet Extraction (ASTE) by annotating existing hotel and product review datasets. They developed detailed annotation guidelines for identifying aspects, sentiments, and their relationships in Polish text. The datasets were annotated by multiple annotators with careful attention to inter-annotator agreement. The resulting datasets were then used to evaluate two ASTE methods (GTS and EPISA) combined with two Polish language models (HerBERT and TrelBERT). The performance of these models on the Polish datasets was compared to their performance on equivalent English datasets to assess the relative difficulty of the task across languages.

## Key Results
- Two new ASTE datasets for Polish were created, covering hotel and product reviews (2,253 and 2,416 samples respectively)
- Performance of ASTE models on Polish datasets (F1 scores around 40-45%) was significantly lower than on equivalent English datasets (63-68% F1)
- The Polish datasets are more challenging, highlighting the need for further research in ASTE for Slavic languages

## Why This Works (Mechanism)
The creation of domain-specific Polish ASTE datasets enables direct comparison of model performance across languages and domains. By using established annotation guidelines and ensuring high inter-annotator agreement, the datasets provide a reliable benchmark for evaluating ASTE methods. The compatibility with existing English datasets allows for meaningful cross-lingual analysis, revealing language-specific challenges in aspect extraction and sentiment classification.

## Foundational Learning
- **Aspect-Sentiment Triplet Extraction (ASTE)**: The task of identifying aspect terms, sentiment expressions, and their relationships within text. Needed for fine-grained sentiment analysis in NLP applications.
- **Inter-annotator agreement**: A measure of consistency between different human annotators, used to assess the quality and reliability of annotated datasets. Critical for ensuring dataset validity.
- **Language model adaptation**: The process of fine-tuning pre-trained language models for specific downstream tasks. Essential for achieving good performance on domain-specific NLP tasks.
- **Cross-lingual comparison**: Evaluating model performance across different languages to identify language-specific challenges and opportunities for transfer learning.

## Architecture Onboarding
- **Component map**: Raw text -> Tokenization -> Aspect extraction -> Sentiment classification -> Triplet generation
- **Critical path**: Tokenization → Aspect extraction → Sentiment classification → Triplet generation
- **Design tradeoffs**: The study used established ASTE methods rather than developing new approaches, prioritizing dataset creation and cross-lingual comparison over method innovation.
- **Failure signatures**: Lower performance on Polish datasets compared to English suggests challenges with aspect extraction and sentiment classification in morphologically rich languages.
- **First experiments**:
  1. Evaluate additional ASTE methods on the Polish datasets to establish a more comprehensive baseline
  2. Perform cross-lingual transfer learning experiments using English datasets as training data
  3. Fine-tune more recent Polish language models (e.g., based on RoBERTa or DeBERTa) on the ASTE task

## Open Questions the Paper Calls Out
None

## Limitations
- Relatively small dataset sizes (2,253 and 2,416 samples) may limit generalizability and model performance
- Only two ASTE methods and two Polish language models were evaluated, potentially missing state-of-the-art approaches
- Focus on only two domains (hotels and products) limits applicability to other domains and text types

## Confidence
- High confidence: Creation and public release of Polish ASTE datasets, detailed annotation process, comparative analysis with English datasets
- Medium confidence: Performance metrics of evaluated models given limited methods and language models tested
- Low confidence: Generalizability of results to other Slavic languages or uncovered domains

## Next Checks
1. Conduct experiments with additional ASTE methods and more recent Polish language models to establish a more comprehensive baseline for the datasets
2. Perform cross-lingual experiments using the English ASTE datasets as training data to evaluate the effectiveness of transfer learning in this context
3. Expand the dataset to include additional domains and text types to improve generalizability and create a more robust resource for the NLP community