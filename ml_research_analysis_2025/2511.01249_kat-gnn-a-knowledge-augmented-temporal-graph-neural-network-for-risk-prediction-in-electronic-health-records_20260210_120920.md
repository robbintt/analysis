---
ver: rpa2
title: 'KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction
  in Electronic Health Records'
arxiv_id: '2511.01249'
source_url: https://arxiv.org/abs/2511.01249
tags:
- graph
- edges
- prediction
- temporal
- diagnosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'KAT-GNN is a graph-based framework for risk prediction using electronic
  health records (EHRs). It constructs modality-specific patient graphs (e.g., diagnoses,
  measurements) and enriches them with two knowledge sources: ontology-driven edges
  from SNOMED CT and co-occurrence priors from EHRs.'
---

# KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records

## Quick Facts
- **arXiv ID:** 2511.01249
- **Source URL:** https://arxiv.org/abs/2511.01249
- **Reference count:** 39
- **Primary result:** KAT-GNN achieves state-of-the-art AUROC of 0.9269±0.0029 for CAD prediction and 0.9230±0.0070 for MIMIC-III mortality prediction using knowledge-augmented temporal graphs.

## Executive Summary
KAT-GNN is a graph-based framework for risk prediction using electronic health records (EHRs). It constructs modality-specific patient graphs (e.g., diagnoses, measurements) and enriches them with two knowledge sources: ontology-driven edges from SNOMED CT and co-occurrence priors from EHRs. A time-aware transformer captures longitudinal dynamics from the graph-encoded representations. Evaluated on three datasets and tasks (CAD prediction with CGRD, mortality prediction with MIMIC-III/IV), KAT-GNN achieved state-of-the-art performance: AUROC 0.9269±0.0029 for CAD, 0.9230±0.0070 for MIMIC-III mortality, and 0.8849±0.0089 for MIMIC-IV mortality, outperforming established baselines like GRASP and RETAIN. Ablation studies confirmed that both knowledge augmentation and temporal modeling significantly contributed to performance gains.

## Method Summary
KAT-GNN constructs bipartite patient graphs with visit nodes connected to clinical entity nodes (diagnoses or measurements), then augments these with ontology-driven edges from SNOMED CT and co-occurrence priors from EHRs. Continuous measurements are discretized into quantile bins to create discrete nodes. Each modality-specific graph is encoded using GNN (GCN, GAT, or GATv2), then processed by a time-aware transformer that combines local (time-decay) and global (query-based) attention mechanisms. Adaptive late fusion combines modality representations before final prediction. The framework is trained end-to-end with Adam optimizer, dropout, and OneCycleLR scheduler on RTX 4090 hardware.

## Key Results
- **CAD prediction (CGRD):** AUROC 0.9269±0.0029, outperforming baselines including GRASP and RETAIN
- **Mortality prediction (MIMIC-III):** AUROC 0.9230±0.0070, showing 0.0153 improvement over strongest baseline
- **Mortality prediction (MIMIC-IV):** AUROC 0.8849±0.0089, with significant AUPRC gains from temporal and knowledge components

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dual-source knowledge augmentation reduces sparsity while preserving patient-specific structure.
- **Mechanism:** Two complementary edge sources: (1) SNOMED CT ontology edges connect semantically related concepts via lowest-common-subsumer depth; (2) Co-occurrence edges (lift > 1) capture empirical associations from EHR statistics. These enrich sparse patient graphs without over-densification.
- **Core assumption:** Semantic relatedness in SNOMED CT hierarchy correlates with clinical relevance for prediction tasks.
- **Evidence anchors:**
  - [abstract] "enriches them with two knowledge sources: ontology-driven edges from SNOMED CT and co-occurrence priors from EHRs"
  - [Section II.C] Equation 1 defines semantic distance via LCS; edges selected from top-percentage most similar pairs
  - [Section IV.C] Diagnosis graph peaks at 3% ontology edges (AUROC 0.7649), degrades at 10% (0.7526)
  - [corpus] DynaGraph paper confirms "graph models allow us to capture hidden dependencies" but doesn't specifically validate SNOMED augmentation
- **Break condition:** Excessive edge addition (>5-10%) introduces redundancy; ontology mapping quality depends on SNOMED CT coverage for your clinical domain.

### Mechanism 2
- **Claim:** Modality-specific graphs with quantile discretization preserve clinical semantics better than unified representations.
- **Mechanism:** Separate diagnosis graphs (CCS categorical codes) and measurement graphs (continuous values discretized into bins). Each maintains bipartite visit-structure and sequential temporal edges. Quantile bins encode intensity (e.g., "Very High" creatinine) as discrete nodes.
- **Core assumption:** Discretization preserves discriminative information; 10 bins balances granularity vs. sparsity.
- **Evidence anchors:**
  - [abstract] "constructs modality-specific patient graphs (e.g., diagnoses, measurements)"
  - [Section II.B.2] Measurement nodes: "discretized into B quantile-based bins... each item-bin pair modeled as unique node"
  - [Section IV.B] Performance improves 1→10 bins (AUROC 0.9198→0.9227), declines at 25 bins (0.9213)
  - [corpus] Weak direct evidence; related work on multimodal EHR modeling exists but doesn't validate discretization strategy
- **Break condition:** Measurement items with non-monotonic clinical relationships may bin poorly; rare measurements create sparse bins.

### Mechanism 3
- **Claim:** Time-aware dual attention captures both recent-visit recency and long-range trajectory patterns.
- **Mechanism:** Local attention weights visits by proximity to prediction date (via tanh-projected time intervals). Global attention uses learned query from averaged embeddings to score long-range dependencies. Final representation combines both.
- **Core assumption:** Clinical events closer to prediction date carry different information than distant events; both matter.
- **Evidence anchors:**
  - [abstract] "time-aware transformer is employed to capture longitudinal dynamics"
  - [Section II.E.2] Equations 6-14 define local (time decay) and global (query-based) attention mechanisms
  - [Section IV.F] Adding time-aware transformer: AUROC 0.9184→0.9269, AUPRC 0.6618→0.6764 (p<0.001)
  - [corpus] THCM-CAL and DynaGraph papers emphasize temporal modeling importance but use different mechanisms
- **Break condition:** Very short patient histories (<3 visits) provide insufficient temporal signal; irregular visit spacing requires careful interval encoding.

## Foundational Learning

- **Concept:** Graph Neural Networks (GCN, GAT, GATv2)
  - **Why needed here:** Core encoder for patient graphs. Paper compares all three; GCN performs best on diagnosis graphs, GAT slightly better on MIMIC-IV mortality.
  - **Quick check question:** Can you explain why attention-based GNNs might help heterogeneous clinical graphs vs. standard GCN aggregation?

- **Concept:** Medical Ontologies (SNOMED CT, CCS, ICD mappings)
  - **Why needed here:** Ontology-driven edge construction requires navigating SNOMED CT hierarchy. CCS codes abstract ICD-9/10 to unified categories (276 codes vs. thousands).
  - **Quick check question:** What is a "lowest common subsumer" in an ontology, and why does depth correlate with semantic similarity?

- **Concept:** Bipartite Graph Construction
  - **Why needed here:** Patient graphs use bipartite structure (visit nodes ↔ clinical entity nodes) plus sequential temporal edges. This differs from homogeneous patient-similarity graphs.
  - **Quick check question:** Why might bipartite visit-entity structure preserve more temporal information than homogeneous entity-only graphs?

## Architecture Onboarding

- **Component map:**
  Raw EHR → Preprocessing (ICD→CCS, lab binning)
          → Graph Construction (diagnosis graph, measurement graph)
          → Edge Augmentation (SNOMED edges, co-occurrence edges)
          → GNN Encoder (per modality)
          → Time-Aware Attention (local + global)
          → Adaptive Fusion (learned modality weights)
          → Prediction Head

- **Critical path:** Graph construction → edge augmentation → time-aware attention. Errors in graph structure (wrong mappings, bad discretization) propagate through entire pipeline.

- **Design tradeoffs:**
  - **Unified vs. modality-specific graphs:** Separate graphs avoid over-densification but limit cross-modality message passing
  - **Ontology vs. co-occurrence edges:** Ontology provides domain knowledge but limited coverage; co-occurrence captures cohort patterns but may overfit
  - **GCN vs. GAT:** GCN simpler/faster; GAT adaptive but more parameters
  - **Discretization bins:** 10 optimal in this study; domain-specific tuning required

- **Failure signatures:**
  - AUROC degrades with >5% ontology edges (over-densification)
  - AUPRC drops with excessive bins (sparse nodes, weak gradients)
  - Short histories (<3 visits) show minimal temporal attention benefit
  - Random edges perform worse than ontology edges (validates semantic signal)

- **First 3 experiments:**
  1. **Reproduce single-modality baseline:** Build diagnosis graph only (no augmentation, no temporal module) on MIMIC-III mortality. Verify ~0.76 AUROC (Table III, 0% KG edges baseline).
  2. **Ablate edge augmentation:** Add ontology edges at 1%, 3%, 5% thresholds. Confirm peak at 3% for diagnosis graph, then test co-occurrence edges separately.
  3. **Validate temporal module:** Compare GCN encoder with vs. without time-aware attention on full dual-graph setup. Expect ~0.008 AUROC gain per Table VI.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can a unified, heterogeneous multimodal graph architecture outperform the current modality-specific approach without succumbing to overparameterization or sparsity issues?
- **Basis in paper:** [explicit] The authors state, "Future work could explore scalable multimodal graph architectures to balance representational richness with efficiency," noting that the current separate graphs limit direct cross-modality communication.
- **Why unresolved:** The paper maintains separate graphs (diagnosis vs. measurement) to manage dimensionality and sparsity, explicitly identifying the trade-off as a limitation.
- **What evidence would resolve it:** A study implementing a cross-modal graph attention mechanism that shows statistically significant performance improvements over the current late-fusion approach while maintaining comparable memory efficiency.

### Open Question 2
- **Question:** How can laboratory test entities be mapped to ontologies (e.g., SNOMED CT) with higher reliability than keyword-based search to prevent semantic noise?
- **Basis in paper:** [explicit] The paper identifies that "ontology integration for laboratory tests is constrained by the lack of a standardized approach... The keyword-based mapping approach... is susceptible to semantic noise," which resulted in inconsistent AUPRC improvements.
- **Why unresolved:** Unlike diagnosis codes (ICD/CCS), laboratory test standards like LOINC lack direct, high-coverage mappings to the SNOMED hierarchy used for knowledge augmentation.
- **What evidence would resolve it:** Implementation of a standardized coding alignment method (e.g., LOINC-to-SNOMED) that yields consistent, statistically significant AUPRC gains in the measurement graph ablation studies.

### Open Question 3
- **Question:** Does the discretization of continuous laboratory values into quantile bins result in information loss compared to continuous representation methods?
- **Basis in paper:** [inferred] The method "discretized each measurement item into B quantile-based bins" to fit continuous data into a discrete graph structure. While ablations tested the *number* of bins (finding 10 optimal), they did not compare this discretization strategy against continuous-value modeling approaches.
- **Why unresolved:** Discretizing continuous vital signs or lab values may obscure subtle gradients or outliers that are clinically significant but fall within the same bin.
- **What evidence would resolve it:** A comparative ablation study where edge weights or node features represent continuous values (e.g., via Gaussian embedding or direct value encoding) demonstrating higher fidelity in risk prediction than the best-performing discretized model.

### Open Question 4
- **Question:** Can the threshold for knowledge augmentation (e.g., top 3% vs. 5%) be determined dynamically or learned end-to-end rather than manually tuned?
- **Basis in paper:** [inferred] The paper notes that "excessive augmentation (e.g., 10%) reduced performance" and different modalities required different optimal thresholds (3% for diagnosis, 5% for measurement), suggesting a sensitivity that requires manual calibration.
- **Why unresolved:** The current implementation relies on static hyperparameter tuning to balance semantic enrichment against graph over-densification, which may not generalize efficiently to new datasets without extensive re-tuning.
- **What evidence would resolve it:** The development of a learnable edge-pruning mechanism or an adaptive density constraint that automatically converges on the optimal graph connectivity for a given dataset.

## Limitations
- Knowledge augmentation performance depends heavily on ontology coverage and quality, which varies across clinical domains
- The optimal edge percentages (3% for diagnosis, 5% for measurement) require manual tuning and may not generalize
- Private CGRD dataset limits full reproducibility; SNOMED CT mapping quality affects ontology edge construction
- Discretization strategy (10 quantile bins) may not be optimal for all measurement types or clinical contexts

## Confidence

- **High Confidence:** Performance improvements from temporal modeling (0.008-0.010 AUROC gain, p<0.001) are well-supported by ablation studies and consistent across datasets.
- **Medium Confidence:** Knowledge augmentation benefits are demonstrated but may vary with ontology quality and cohort composition. The 3%/5% edge thresholds show strong performance but represent one optimal point in a broader parameter space.
- **Medium Confidence:** Modality-specific graph construction with discretization is empirically validated but lacks extensive comparison to alternative continuous representations or unified graph approaches.

## Next Checks

1. **Generalize Knowledge Augmentation:** Apply KAT-GNN to a different clinical domain (e.g., oncology or diabetes) using a different ontology (e.g., OMOP CDM or MeSH) to validate whether the 3%/5% edge thresholds remain optimal or require domain-specific tuning.

2. **Validate Discretization Sensitivity:** Systematically vary the number of quantile bins (5, 10, 15, 20) on MIMIC-IV mortality prediction to confirm the 10-bin sweet spot and identify whether certain measurement types benefit from alternative discretization strategies.

3. **Test Temporal Module Robustness:** Evaluate KAT-GNN on patients with varying history lengths (<5 visits vs. >20 visits) to determine the minimum temporal signal required for time-aware attention to provide meaningful performance gains, and assess whether alternative temporal encoding methods (e.g., relative time embeddings) could further improve results.