---
ver: rpa2
title: Performance of GPT-5 in Brain Tumor MRI Reasoning
arxiv_id: '2508.10865'
source_url: https://arxiv.org/abs/2508.10865
tags:
- tumor
- brain
- reasoning
- gpt-5
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the performance of GPT-5 family models (GPT-4o,
  GPT-5, GPT-5-mini, GPT-5-nano) on brain tumor MRI visual question answering (VQA)
  tasks derived from the BraTS dataset. The benchmark involved triplanar MRI mosaics
  and structured clinical features converted into standardized yes/no and multiple-choice
  questions for glioblastoma, meningioma, and brain metastases cases.
---

# Performance of GPT-5 in Brain Tumor MRI Reasoning

## Quick Facts
- arXiv ID: 2508.10865
- Source URL: https://arxiv.org/abs/2508.10865
- Reference count: 20
- Primary result: GPT-5 family models achieved moderate (35-44%) accuracy on structured brain tumor VQA tasks, insufficient for clinical use

## Executive Summary
This study evaluated GPT-5 family models (GPT-4o, GPT-5, GPT-5-mini, GPT-5-nano) on brain tumor MRI visual question answering tasks derived from the BraTS dataset. The benchmark used triplanar MRI mosaics and structured clinical features converted into standardized yes/no and multiple-choice questions for glioblastoma, meningioma, and brain metastases cases. Models were assessed in a zero-shot chain-of-thought setting for accuracy on both visual and reasoning tasks. Results showed GPT-5-mini achieved the highest macro-average accuracy (44.19%), followed by GPT-5 (43.71%), GPT-4o (41.49%), and GPT-5-nano (35.85%), with performance varying by tumor subtype.

## Method Summary
The study used BraTS MRI volumes (GLI, MEN, MET cohorts) with four sequences per case (T1c, T1w, T2w, T2-FLAIR). Images were aligned to RAS orientation, tumor centroids computed from segmentation masks, and triplanar slices extracted through centroids. These were concatenated into 2D mosaics with percentile-based intensity clipping. Radiology reports were parsed into structured features using rule-based extraction, then converted to yes/no and multiple-choice questions. Models were evaluated using zero-shot chain-of-thought prompting ("Let's think step by step") and final letter answers were scored against ground truth keys.

## Key Results
- GPT-5-mini achieved highest macro-average accuracy at 44.19%
- GPT-5-nano significantly underperformed at 35.85% compared to other variants
- No single model dominated across all tumor cohorts
- Performance levels (35-44%) were insufficient for clinical use
- Accuracy varied substantially by tumor subtype

## Why This Works (Mechanism)

### Mechanism 1: Zero-shot chain-of-thought prompting
- Forces generation of intermediate reasoning steps to map visual features to clinical concepts
- Decomposes complex visual tasks into sub-steps using structured vocabulary
- Core assumption: Models possess sufficient medical knowledge to generate accurate reasoning
- Break condition: Overinterpretation of ambiguous features when visual evidence is weak

### Mechanism 2: Triplanar mosaic compression
- Concatenates axial, sagittal, and coronal slices through tumor centroid into single 2D image
- Enables 2D vision encoders to approximate 3D spatial reasoning
- Core assumption: Tumor centroid accurately calculated and diagnostic features captured in three planes
- Break condition: Pathology outside three planes or diffuse tumor infiltration missed

### Mechanism 3: Structured feature parsing
- Converts unstructured radiology reports into grounded multiple-choice questions
- Constrains output space for deterministic accuracy calculation
- Core assumption: Rule-based parser correctly maps text to ground truth with meaningful distractors
- Break condition: Text-image contradictions create unfair penalization

## Foundational Learning

- **Concept: Visual Question Answering (VQA) in Medicine**
  - Why needed: Distinguishes between visual perception errors and reasoning logic errors
  - Quick check: Can you explain why a model might correctly identify tumor location but fail on "ring enhancement" question?

- **Concept: Zero-Shot Evaluation**
  - Why needed: Results reflect pre-trained capability, not potential upper bound
  - Quick check: Would 35.85% accuracy metric still be valid if GPT-5-nano was fine-tuned?

- **Concept: Triplanar Representation**
  - Why needed: Input is static 2D composite, not video or 3D tensor
  - Quick check: How does concatenating three orthogonal slices help 2D encoder approximate 3D understanding?

## Architecture Onboarding

- **Component map:** BraTS MRI Volumes + Reports -> RAS Alignment -> Centroid Calculation -> Triplanar Mosaic -> Parser -> Feature Extraction -> Prompt Builder -> GPT-4o/5 Family -> Rationale -> Final Answer -> Ground Truth Scoring

- **Critical path:** Centroid extraction is single point of failure; incorrect centroid misses lesion entirely

- **Design tradeoffs:**
  - Mosaic vs 3D: Trades native 3D reasoning for compatibility with standard 2D transformers
  - CoT vs Direct: Trades latency for potential reasoning fidelity (may increase distraction)
  - Nano vs Mini: GPT-5-nano underperforms by ~8%, suggesting capability collapse below certain parameter count

- **Failure signatures:**
  - Visual Hallucination: Rationale describes features not present in provided slices
  - Over-reasoning: Rationale argues for feature A but final answer selects feature B
  - Slice Ambiguity: Model answers "Unknown" when question requires slice view not provided

- **First 3 experiments:**
  1. Visual Grounding Test: Evaluate on questions answerable from text alone to measure visual vs linguistic reasoning
  2. Input Ablation: Compare single axial slice vs triplanar mosaic performance
  3. Prompt Ablation: Compare CoT vs direct prompting accuracy

## Open Questions the Paper Calls Out

1. **Human expert comparison:** How does GPT-5 performance compare to human neuroradiologists on identical VQA items? (Section 4.1 notes absence of human comparator limits clinical interpretability)

2. **CoT effect uncertainty:** Does zero-shot chain-of-thought prompting improve or impair accuracy compared to direct answering? (Section 4.1 states net effect remains uncertain without direct-answer baseline)

3. **Open-form task capability:** Can GPT-5 models maintain performance on open-form free-text VQA tasks rather than forced-choice questions? (Section 4.2 suggests dataset could enable more nuanced evaluations)

## Limitations

- Grounding ambiguity from rule-based parser potentially misaligning visual evidence with textual ground truth
- Generalizability gap - zero-shot evaluation shows insufficient clinical performance without exploring fine-tuning
- Input constraint - triplanar mosaic lossy compression misses 3D spatial context and diffuse pathologies

## Confidence

- **High Confidence:** Methodology for triplanar mosaics and zero-shot CoT evaluation protocol
- **Medium Confidence:** GPT-5-mini achieving highest accuracy (44.19%) from presented data
- **Low Confidence:** Claim that CoT may encourage overinterpretation lacks ablation study evidence

## Next Checks

1. Visual Grounding Test: Evaluate models on questions answerable from text alone to quantify visual vs linguistic reasoning contribution

2. Input Representation Ablation: Compare single axial slice vs triplanar mosaic performance to isolate value of composite 2D view

3. Prompt Engineering Ablation: Repeat benchmark with direct prompting (no "Let's think step by step") to determine CoT effect on accuracy