---
ver: rpa2
title: Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization
  for Remote Sensing Object Recognition
arxiv_id: '2509.07495'
source_url: https://arxiv.org/abs/2509.07495
tags:
- adversarial
- examples
- attacks
- images
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating transferable adversarial
  examples for remote sensing object recognition, focusing on non-targeted attacks
  where the goal is to mislead models without specifying a target class. The authors
  propose a novel framework that combines local mixing and logits optimization to
  enhance adversarial transferability across diverse model architectures.
---

# Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition

## Quick Facts
- **arXiv ID**: 2509.07495
- **Source URL**: https://arxiv.org/abs/2509.07495
- **Reference count**: 40
- **One-line primary result**: Achieves up to 17.28% improvement in black-box attack success rate over existing methods on FGSCR-42 and MTARSI datasets

## Executive Summary
This paper addresses the challenge of generating transferable adversarial examples for remote sensing object recognition, focusing on non-targeted attacks where the goal is to mislead models without specifying a target class. The authors propose a novel framework that combines local mixing and logits optimization to enhance adversarial transferability across diverse model architectures. Their local mixing strategy blends small regions of different images to preserve global semantic information while increasing input diversity, differing from global blending or region-swapping approaches. They adapt logits-based optimization to non-targeted attacks to mitigate gradient vanishing issues common with cross-entropy loss and add a perturbation smoothing loss to suppress high-frequency noise that can impair transferability. Experiments on FGSCR-42 and MTARSI datasets show their method consistently outperforms 12 state-of-the-art approaches, achieving up to 17.28% improvement in black-box attack success rate over existing methods, particularly when attacking heterogeneous architectures.

## Method Summary
The method builds on Momentum Iterative FGSM (MI-FGSM) framework, combining three key innovations: local mixing, logit loss optimization, and perturbation smoothing. Local mixing blends rectangular regions from two images using weight η, preserving global semantics while increasing diversity. The logit loss directly minimizes the true-class logit value to avoid softmax saturation and gradient vanishing. A smoothing loss with mean convolution filter suppresses high-frequency perturbation components that exploit surrogate-specific patterns. The optimization runs for T=30 iterations with M=25 transformation rounds per iteration, using ε=16 perturbation budget and λ=200 smoothing weight.

## Key Results
- Achieves up to 17.28% improvement in black-box attack success rate over existing methods
- Local mixing improves transferability by 2-5% compared to global mixing approaches
- Logit loss shows 6-10% performance gain over cross-entropy loss on heterogeneous targets
- Perturbation smoothing particularly effective against Inception-ResNet-v2 architecture (44.54% vs 34.47% without smoothing)

## Why This Works (Mechanism)

### Mechanism 1: Local Mixing Preserves Semantics While Increasing Diversity
- Claim: Blending local regions rather than global images maintains class-relevant semantic information while reducing surrogate model overfitting.
- Mechanism: Random rectangular regions from two images are blended with weight η, while non-selected regions remain unchanged from the original. This is repeated M times per iteration with different augmentation operations (rotation, scaling, etc.), and gradients are averaged across all transformed samples.
- Core assumption: Remote sensing images contain spatially-distributed semantic features where local perturbations to mixed regions do not destroy the class identity needed for meaningful gradient computation.
- Evidence anchors: [abstract] "merely blends local regions to preserve global semantic information"; [Section 3.3] Eq. 6 defines the local mixing operation with binary mask R_i, and Section 3.5 describes averaging gradients over M transformation rounds; [corpus] Weak direct evidence; related work on local shuffle attacks (arXiv:2511.00831) explores similar spatial operations but in VLP models
- Break condition: If mixing regions systematically overlap critical object features across iterations, semantic consistency degrades and gradients become misleading.

### Mechanism 2: Logit Loss Avoids Softmax Saturation
- Claim: Directly minimizing the true-class logit maintains stronger gradients during iterative optimization compared to cross-entropy loss.
- Mechanism: Use L_logit = -z_y where z_y is the logit (pre-softmax) value for the true class, bypassing the softmax operation that causes gradient vanishing when logits become extreme.
- Core assumption: Gradient vanishing from softmax saturation is a primary bottleneck limiting transferability in iterative attacks, and removing this bottleneck yields more transferable perturbations.
- Evidence anchors: [abstract] "adapt the logit loss from targeted attacks to non-targeted scenarios, mitigating the gradient vanishing problem"; [Section 3.4] Explicitly states "it bypasses the softmax operation that causes gradient vanishing"; Table 9 shows "only CE" underperforms "All" by 6-10% on heterogeneous targets; [corpus] No direct corpus support; gradient vanishing in CE loss is a known property but specific evidence for transferability gains is limited to this paper's experiments
- Break condition: Assumption holds while logit values remain in a range where CE would saturate; break if surrogate model already produces low-confidence predictions.

### Mechanism 3: Smoothing Loss Suppresses Model-Specific High-Frequency Artifacts
- Claim: Penalizing high-frequency components in the perturbation reduces overfitting to surrogate model decision boundaries that don't transfer.
- Mechanism: Apply a k×k mean convolution kernel as a low-pass filter to the perturbation, then minimize L_smooth = ||LowPassFilter(δ)||_1 weighted by λ.
- Core assumption: High-frequency perturbation components exploit surrogate-specific patterns that differ across architectures; suppressing them encourages more universal perturbation directions.
- Evidence anchors: [abstract] "perturbation smoothing loss is applied to suppress high-frequency noise to further enhance transferability"; [Section 3.4] Eq. 9-10 define the smoothing loss; Table 8 shows removing smoothing drops ASR on Inception-ResNet-v2 from 44.54% to 34.47%; [corpus] Indirect support from arXiv:2508.05689 noting that "adversarial examples often overfit to surrogate models"
- Break condition: If target models share similar high-frequency sensitivity patterns with the surrogate, smoothing may reduce attack potency without transferability gains.

## Foundational Learning

- Concept: **Transfer-based black-box attacks**
  - Why needed here: The entire method assumes you can generate adversarial examples on an accessible surrogate model and transfer them to unknown target models.
  - Quick check question: Can you explain why transferability fails when perturbations overfit to surrogate-specific features?

- Concept: **Iterative gradient-based optimization (PGD/MIM)**
  - Why needed here: The method builds on momentum iterative FGSM; understanding momentum accumulation and clipping is essential for implementing Algorithm 1.
  - Quick check question: What does the Clip_{x,ε} operation do in Eq. 13, and why is it necessary?

- Concept: **Loss function behavior under optimization**
  - Why needed here: Understanding why cross-entropy saturates (softmax compression to [0,1]) vs. why logit loss maintains gradient magnitude is central to the contribution.
  - Quick check question: When does softmax output approach a one-hot distribution, and what happens to the gradient w.r.t. logits in that regime?

## Architecture Onboarding

- Component map:
  - Input pipeline: Clean images + perturbation δ → Data augmentation (Table 1) → Local mixing (Eq. 6, repeated M=25 times) → Mixed image batches
  - Loss computation: Mixed images → Surrogate model → Logit output → L_logit (Eq. 8) + λ·L_smooth (Eq. 9-10)
  - Optimization loop: Average gradients across M batches → Momentum update (Eq. 12) → Perturbation update (Eq. 13) → Clip to ε-ball

- Critical path: The gradient flow from L_total through the locally-mixed images back to δ determines perturbation quality. If mixing destroys semantic consistency or loss provides weak gradients, the entire attack degrades.

- Design tradeoffs:
  - Higher M (transformation rounds) improves transferability but increases compute linearly; paper uses M=25 with plateau observed beyond
  - Higher λ (smoothing weight) improves transfer to heterogeneous architectures (especially Inception-ResNet-v2) but may reduce same-architecture ASR
  - Mixing ratio η=0.5 balanced performance; η→0 reverts to no mixing

- Failure signatures:
  - White-box ASR < 95%: Check loss computation (verify logit extraction, loss weights)
  - Black-box ASR on similar architectures (e.g., ResNet-34→ResNet-50) low: Check mixing implementation, M setting
  - Black-box ASR on heterogeneous architectures (e.g., DenseNet→Inception-ResNet-v2) low: Check smoothing loss weight λ, verify low-pass filter implementation
  - Gradient magnitudes approaching zero during iteration: Switch from CE to logit loss

- First 3 experiments:
  1. **Reproduce single surrogate baseline**: Use ResNet-34 on MTARSI, compare white-box ASR and black-box ASR against all 5 target models against Table 3 values to verify implementation.
  2. **Ablate mixing strategy**: Compare Local-Mix vs. Admix vs. No-Mix using same surrogate (e.g., DenseNet-121) on FGSCR-42; expect ~2-5% improvement over Admix per Tables 6-7.
  3. **Validate loss contribution**: Using Inception-ResNet-v2 as surrogate, compare "All" vs. "w/o Smo." vs. "only CE" on FGSCR-42; expect largest gap on heterogeneous targets per Tables 8-9.

## Open Questions the Paper Calls Out

- Question: Can the local mixing and logits optimization framework be effectively adapted for transferable targeted adversarial attacks in remote sensing?
- Basis in paper: [explicit] The abstract and methodology sections explicitly state the study focuses on "non-targeted attacks" and adapts logit loss specifically for this scenario, leaving targeted attacks unaddressed.
- Why unresolved: The proposed logit loss formulation minimizes the true class logit to induce misclassification, whereas targeted attacks require maximizing a specific target class logit; the interaction of local mixing with this distinct optimization goal remains untested.
- What evidence would resolve it: Experimental results applying the method to targeted attack settings on the FGSCR-42 and MTARSI datasets, measuring target class success rates against surrogate and black-box models.

- Question: Does the perturbation smoothing loss provide robustness against advanced defense mechanisms such as adversarial training or input purification?
- Basis in paper: [inferred] The paper claims to reveal "vulnerabilities" to provide insights for "enhancing robustness," yet the experiments only validate attack success rates against undefended standard models (VGG, ResNet, etc.) and do not test against any defense strategies.
- Why unresolved: While the smoothing loss suppresses high-frequency noise to aid transferability between architectures, it is unclear if the resulting perturbations are resilient to defense-specific transformations or robust training regimes mentioned in the related work.
- What evidence would resolve it: Evaluating the generated adversarial examples against defended models (e.g., adversarially trained ResNets or detection-based defenses) to measure defense evasion rates.

- Question: Does the local mixing strategy generalize to remote sensing tasks that rely on global spatial relationships, such as object detection?
- Basis in paper: [inferred] The introduction explicitly links object recognition to "higher-level applications" like target detection, but the method is only validated on object recognition (classification) datasets (FGSCR-42 and MTARSI).
- Why unresolved: The local mixing strategy blends regions of different images to preserve global semantics for classification, but this operation might disrupt the bounding box alignment or global context required for detection tasks.
- What evidence would resolve it: Applying the local mixing framework to remote sensing object detection benchmarks (e.g., DOTA) to assess if the transferability of perturbations holds for localization tasks.

## Limitations
- Several critical implementation details remain underspecified, including exact dimensions of local mixing regions, kernel size for smoothing loss, and precise data augmentation parameters
- The paper assumes standard MI-FGSM hyperparameters without explicit values for momentum decay (μ), which could affect reproducibility
- While showing strong empirical performance, theoretical justification for why local mixing outperforms global mixing in remote sensing contexts is limited to empirical observation rather than formal analysis

## Confidence
- **High Confidence**: The local mixing mechanism preserves semantics while increasing diversity, supported by clear mathematical formulation and ablation studies showing 2-5% improvement over global mixing approaches
- **Medium Confidence**: Logit loss effectively mitigates gradient vanishing, with ablation studies showing 6-10% performance gaps, though theoretical analysis of softmax saturation's impact on transferability remains limited
- **Medium Confidence**: Smoothing loss suppresses high-frequency artifacts that reduce transferability, with quantitative evidence showing performance degradation when removed, though the optimal kernel size and its architectural sensitivity are unclear

## Next Checks
1. **Ablation Study Replication**: Replicate Tables 8-9 by implementing "All", "w/o Smo.", and "only CE" variants on Inception-ResNet-v2 surrogate to verify the 10% performance gap and smoothing's architectural sensitivity
2. **Mixing Region Sensitivity**: Systematically vary the local mixing region size (from 5% to 50% of image area) to identify the optimal scale and confirm the paper's claim about local vs. global mixing benefits
3. **Kernel Size Impact**: Test different smoothing kernel sizes (k=3, 5, 7) to quantify the trade-off between perturbation suppression and transferability across heterogeneous architectures