---
ver: rpa2
title: 'BarrierBench : Evaluating Large Language Models for Safety Verification in
  Dynamical Systems'
arxiv_id: '2511.09363'
source_url: https://arxiv.org/abs/2511.09363
tags:
- barrier
- systems
- controller
- synthesis
- verification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents BarrierBench, a benchmark of 100 dynamical systems
  designed to evaluate large language models (LLMs) for safety verification via barrier
  certificates. The authors introduce an agentic framework integrating retrieval,
  synthesis, and verification agents to guide LLM-based barrier certificate synthesis.
---

# BarrierBench : Evaluating Large Language Models for Safety Verification in Dynamical Systems

## Quick Facts
- arXiv ID: 2511.09363
- Source URL: https://arxiv.org/abs/2511.09363
- Reference count: 40
- Primary result: Agentic framework achieves >90% success rate synthesizing barrier certificates, outperforming single-prompt LLM approaches by 49 percentage points

## Executive Summary
BarrierBench introduces a benchmark of 100 dynamical systems designed to evaluate large language models (LLMs) for safety verification via barrier certificates. The authors present an agentic framework that integrates retrieval, synthesis, and verification agents to guide LLM-based barrier certificate synthesis. Their experiments demonstrate that this approach achieves over 90% success rate in generating valid certificates, substantially outperforming single-prompt LLM approaches. The framework successfully handles linear, nonlinear, discrete-time, and continuous-time systems, including 68 controlled systems requiring barrier-controller co-synthesis.

## Method Summary
The framework employs a three-agent architecture: a Retrieval Agent that queries a database of solved problems to find structurally similar examples, a Synthesis Agent (Claude Sonnet 4 or ChatGPT-4o) that proposes barrier certificates and controllers based on system dynamics and retrieval context, and a Verifier Agent that performs sample-based filtering (5,000 points) followed by formal SMT solving using Z3, cvc5, or Yices. The system iterates through up to 5 main attempts with 4 refinement steps each, using verification feedback to adjust coefficients (râ‰¤2) or structural terms (r>2). The approach is evaluated on BarrierBench, a dataset of 100 systems spanning 1D-8D with various topologies and control requirements.

## Key Results
- Framework achieves >90% success rate synthesizing valid barrier certificates
- Outperforms single-prompt baseline by 49 percentage points (90% vs 41% for Claude, 17% for GPT-4o)
- Successfully handles 68 controlled systems requiring barrier-controller co-synthesis
- 54.4% of solved problems completed on first attempt using retrieval-augmented generation
- 10% of problems unsolved due to SMT solver timeouts on complex nonlinear dynamics

## Why This Works (Mechanism)

### Mechanism 1: Retrieval-Augmented Analogical Reasoning
Providing structurally similar, previously solved problems significantly increases first-attempt success rates. The Retrieval Agent uses feature-based filtering followed by LLM-based ranking to select analogous examples, grounding the Synthesis Agent and reducing the search space. The pre-trained LLM adapts mathematical structures from retrieved solutions to new problems when properly prompted.

### Mechanism 2: Iterative Counter-Example Guided Refinement
Transforming verification failures into natural language feedback enables iterative certificate repair. The Verifier Agent provides specific violated conditions and counter-examples when barriers fail, allowing the Synthesis Agent to adjust coefficients or structural terms in subsequent iterations based on this concrete feedback.

### Mechanism 3: Hierarchical Verification Filtering
Decoupling verification into lightweight sample checks followed by formal SMT solving optimizes computational resources. The Verifier Agent first tests candidates on 5,000 sampled points, only proceeding to expensive formal verification for statistically promising candidates. This prevents wasted effort on trivially flawed barriers while maintaining rigorous safety guarantees.

## Foundational Learning

- **Concept: Barrier Certificates (Control Theory)**
  - Why needed: These are the core objects synthesized to prove system safety. A barrier $B(x)$ must satisfy $B(x) \le 0$ for initial states, $B(x) > 0$ for unsafe states, and possess specific derivative conditions to ensure invariance.
  - Quick check: Given a continuous system $\dot{x} = f(x)$, what is the condition on $\nabla B(x) \cdot f(x)$ required to prove safety on the boundary $B(x)=0$?

- **Concept: Satisfiability Modulo Theories (SMT) Solving**
  - Why needed: SMT solvers (Z3, Yices) serve as the ground truth verifier, checking mathematical satisfiability rather than approximation. Understanding this distinction is crucial for appreciating the framework's rigor.
  - Quick check: Why is an SMT solver preferred over a standard gradient descent optimizer for verifying the absolute safety of a generated barrier?

- **Concept: Agentic Workflows & RAG**
  - Why needed: The 90% success rate stems from the specialized agent architecture rather than LLM capability alone. Understanding how retrieval-augmented generation injects "memory" into the process is key.
  - Quick check: In this architecture, does the Retrieval Agent fetch the solution to the current problem, or an analogy to guide the Synthesis Agent?

## Architecture Onboarding

- **Component map:** User/Database -> Retrieval Agent -> Synthesis Agent -> Verifier Agent (Sample Check -> SMT Solver) -> Feedback to Synthesis Agent

- **Critical path:** The Feedback Loop. If the Verifier Agent cannot generate actionable counter-examples (e.g., times out or returns `Unknown`), the Synthesis Agent cannot refine its guess, and the loop breaks.

- **Design tradeoffs:**
  - Sample Size (N=5000): Higher N catches bad candidates early but slows iteration
  - Refinement Limit (R=4): Higher limits solve complex systems but increase latency and token costs
  - Template Freedom: Allowing complex templates solves more problems but risks solver timeouts

- **Failure signatures:**
  - Solver Timeout: Dynamics or barrier structure too complex for SMT solver within time limit
  - Hallucination: Synthesis Agent outputs barriers with undefined variables or syntax errors
  - Stagnation: Agent cycles through same invalid templates due to misleading context or ignored feedback

- **First 3 experiments:**
  1. Baseline Validation: Run `Baseline (Single Prompt)` vs `Full Framework` on 10 linear systems to reproduce 41% vs 90% gap
  2. Ablation on Retrieval: Disable Retrieval Agent and measure drop in "First-Try" success rates
  3. Stress Test Non-Linearity: Run framework on unsolved complex nonlinear cases to characterize solver vs LLM failure modes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework adapt to verify systems with highly complex, non-polynomial dynamics (trigonometric and exponential terms) where SMT solvers time out?
- Basis: Section 6 states 10 unsolved cases involve complex trigonometric and exponential terms causing computational difficulties
- Why unresolved: Current verification relies on standard SMT solvers struggling with decidability and complexity of these structures
- Evidence needed: Framework modification successfully verifying the 10 currently unsolved systems

### Open Question 2
- Question: To what extent can the architecture decouple synthesis performance from the specific foundation model used?
- Basis: Section 4.4 shows 90% success with Claude Sonnet 4 but only 46% with ChatGPT-4o
- Why unresolved: Framework's success still appears heavily contingent on specific LLM despite architectural improvements
- Evidence needed: Comparable success rates across multiple state-of-the-art LLMs using the same framework

### Open Question 3
- Question: What are the theoretical convergence guarantees for the iterative refinement loop, and when is "Best partial solution" sufficient for practical safety?
- Basis: Algorithm returns "Best partial solution" upon failure with no completeness claims
- Why unresolved: Search is heuristic, driven by LLM reasoning rather than systematic or exhaustive search
- Evidence needed: Theoretical analysis or empirical study quantifying false negative rate for specific system classes

## Limitations

- The retrieval database's initial composition and feature extraction methodology remain underspecified
- Sample-based verification (N=5000) may mask edge-case failures in safety-critical applications
- 10% solver timeout rate indicates the approach struggles with certain nonlinear dynamics regardless of LLM guidance

## Confidence

- **High confidence**: The agentic framework's architecture and superiority over single-prompt baselines (49 percentage point improvement) are well-supported by experimental results
- **Medium confidence**: Mechanisms of retrieval-augmented reasoning and iterative refinement are plausible given success rate data, but paper doesn't fully characterize when each succeeds versus fails
- **Low confidence**: Claims about handling 68 controlled systems lack detailed analysis of failure modes specific to this harder subset

## Next Checks

1. **Retrieval Ablation**: Disable the Retrieval Agent entirely and rerun on full BarrierBench to quantify performance drop attributable to RAG versus iterative refinement alone

2. **Database Dependency Test**: Measure success rates with empty retrieval database versus populated version to determine if performance depends on curated examples

3. **Solver Stress Test**: Systematically characterize the 10% timeout failures by testing progressively more complex barrier templates to identify specific mathematical constructs that trigger solver timeouts