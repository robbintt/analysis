---
ver: rpa2
title: 'SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection
  with Adversarial Strategy'
arxiv_id: '2512.13458'
source_url: https://arxiv.org/abs/2512.13458
tags:
- domain
- source
- emotion
- ssas
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses cross-subject EEG-based emotion recognition,
  a challenging task due to inter-individual variability and potential negative transfer
  from source domains. The authors propose SSAS, a two-stage framework combining source
  selection (SS) and adversarial strategies (AS).
---

# SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy

## Quick Facts
- arXiv ID: 2512.13458
- Source URL: https://arxiv.org/abs/2512.13458
- Authors: Yici Liu; Qi Wei Oung; Hoi Leong Lee
- Reference count: 40
- Primary result: State-of-the-art cross-subject EEG emotion recognition with up to 7% accuracy improvement

## Executive Summary
This paper tackles the challenging problem of cross-subject EEG-based emotion recognition, where significant inter-individual variability in brain signals can lead to negative transfer when using multiple source domains. The authors propose SSAS, a two-stage framework that first selects beneficial source domains and then performs adversarial training to align distributions across subjects. The approach demonstrates substantial performance gains on benchmark datasets SEED and SEED-IV, addressing both negative transfer issues and domain distribution mismatch that plague existing methods.

## Method Summary
SSAS employs a two-stage approach: source selection (SS) and adversarial strategy (AS). In the first stage, SS uses domain labels to identify source domains that will contribute positively to the target domain performance by simulating the domain adaptation process. The second stage implements adversarial training where a domain discriminator is trained to distinguish between source and target domains while the feature extractor learns to produce domain-invariant representations. This adversarial alignment is combined with emotion classification objectives to improve cross-subject generalization. The framework is evaluated on two benchmark EEG emotion recognition datasets, showing significant improvements over state-of-the-art methods.

## Key Results
- Achieves state-of-the-art performance on SEED and SEED-IV datasets with up to 7% accuracy improvement
- Effectively mitigates negative transfer from detrimental source domains through selective source domain utilization
- Demonstrates robustness through comprehensive ablation studies and hyperparameter sensitivity analysis
- Shows improved generalization across diverse subjects compared to existing cross-subject emotion recognition methods

## Why This Works (Mechanism)
The method works by addressing two critical challenges in cross-subject EEG emotion recognition: negative transfer from irrelevant source domains and distribution mismatch between subjects. By first selecting beneficial source domains through a simulated domain adaptation process, SSAS ensures that only relevant information is transferred. The adversarial strategy then aligns the feature distributions across domains while maintaining emotion-relevant information, creating domain-invariant representations that generalize well to new subjects.

## Foundational Learning

1. **Cross-subject domain adaptation**: Transferring knowledge across different subjects' EEG signals where individual variability creates distinct data distributions. Needed because subjects exhibit unique brain patterns, making direct model transfer ineffective.

2. **Adversarial domain alignment**: Using GAN-like training where feature extractor and domain discriminator compete to produce domain-invariant features. Needed to reduce domain shift while preserving emotion-relevant information.

3. **Negative transfer prevention**: Identifying and excluding source domains that would harm target domain performance. Needed because blindly including all available source data can degrade rather than improve performance.

4. **Domain selection criteria**: Evaluating source domain utility based on simulated adaptation performance. Needed to systematically identify which source subjects will benefit the target recognition task.

5. **Multi-task optimization**: Jointly optimizing domain alignment and emotion classification objectives. Needed to ensure that domain invariance doesn't come at the cost of emotion discrimination capability.

6. **EEG signal variability**: Understanding individual differences in neural patterns for emotion processing. Needed to design appropriate adaptation strategies for this highly variable signal type.

## Architecture Onboarding

**Component Map**: EEG signals -> Feature Extractor -> Domain Discriminator + Emotion Classifier -> Output
- Feature Extractor: Extracts domain-invariant features through adversarial training
- Domain Discriminator: Distinguishes between source and target domains during adversarial training
- Emotion Classifier: Predicts emotion categories from extracted features

**Critical Path**: Feature Extractor (SS) -> Adversarial Training (AS) -> Domain-Invariant Features -> Emotion Classification
The source selection stage filters beneficial domains before the adversarial training stage aligns distributions and performs classification.

**Design Tradeoffs**: Two-stage approach vs. end-to-end training; explicit domain selection vs. implicit handling; computational overhead vs. performance gains. The two-stage design adds complexity but provides better control over negative transfer.

**Failure Signatures**: Poor source domain selection leading to degraded performance; adversarial training instability; overfitting to source domains; failure to maintain emotion-relevant information during domain alignment.

**First Experiments**:
1. Validate source selection effectiveness by comparing with random selection baseline
2. Test adversarial training alone without source selection to measure individual contribution
3. Evaluate performance on leave-one-subject-out cross-validation to assess generalization

## Open Questions the Paper Calls Out

The paper does not explicitly identify open questions beyond its scope.

## Limitations

- Domain selection relies on labeled source domain information, limiting applicability to real-world scenarios with unlabeled source data
- Computational efficiency of the two-stage framework compared to simpler alternatives is not thoroughly evaluated
- Limited cross-corpus validation raises questions about generalizability beyond SEED and SEED-IV datasets
- Specific contribution of source selection versus adversarial training to overall performance improvement is not clearly delineated

## Confidence

- **High confidence** in the reported accuracy improvements over baseline methods on benchmark datasets
- **Medium confidence** in the generalizability of results across different EEG datasets due to limited cross-corpus validation
- **Medium confidence** in the effectiveness of source selection strategy given the reliance on domain labels
- **Low confidence** in the practical applicability of the method without access to labeled source domains

## Next Checks

1. Test SSAS performance on additional EEG emotion recognition datasets beyond SEED and SEED-IV to verify cross-dataset generalizability

2. Implement and evaluate a variant of the source selection strategy using only unlabeled source domains to assess real-world applicability

3. Conduct computational complexity analysis comparing the two-stage framework with single-stage alternatives to establish practical deployment feasibility