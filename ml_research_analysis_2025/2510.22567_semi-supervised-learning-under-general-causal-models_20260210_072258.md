---
ver: rpa2
title: Semi-Supervised Learning under General Causal Models
arxiv_id: '2510.22567'
source_url: https://arxiv.org/abs/2510.22567
tags:
- causal
- data
- learning
- unlabelled
- semi-supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semi-supervised learning
  (SSL) in complex causal settings where features and labels have flexible causal
  relationships. The authors propose a unified framework that leverages the Independent
  Causal Mechanisms (ICM) principle to exploit unlabelled data effectively.
---

# Semi-Supervised Learning under General Causal Models

## Quick Facts
- **arXiv ID:** 2510.22567
- **Source URL:** https://arxiv.org/abs/2510.22567
- **Reference count:** 40
- **Primary result:** A unified framework that uses causal generative models based on Independent Causal Mechanisms to effectively leverage unlabelled data for semi-supervised classification across 7 causal structures, outperforming existing SSL methods on both synthetic and real-world datasets.

## Executive Summary
This paper tackles semi-supervised learning (SSL) in complex causal settings where features and labels have flexible causal relationships. The authors propose a unified framework that leverages the Independent Causal Mechanisms (ICM) principle to exploit unlabelled data effectively. They categorize causal structures into five types based on the Markov Blanket of the label and design corresponding causal generative models for each category. The framework uses these models to generate synthetic labelled data, which augments the training set for improved predictive performance. Experiments on both synthetic and real-world datasets demonstrate that the proposed method outperforms existing SSL approaches, with notable improvements in classification accuracy across various causal structures.

## Method Summary
The method begins by categorizing the causal graph into one of five types based on the Markov Blanket topology (parents X_C, children X_E, spouses X_S of label Y). For each category, the joint distribution P(X,Y) is factorized according to the Directed Acyclic Graph (DAG), and each factor is modelled using one of six scenario rules (A-F). The model parameters are optimized via a Maximum Mean Discrepancy (MMD) loss for features and Binary Cross-Entropy (BCE) for labels. For the joint approach (GCGAN-SSL), a Gumbel-Softmax sampling strategy is used to generate labels from P(Y|X_C) for unlabelled data. Synthetic data D_G is generated by ancestor sampling and used to augment the training set for the final classifier.

## Key Results
- The proposed method consistently outperforms the labelled-only baseline (P-SUP) across all 7 causal graph structures in synthetic experiments.
- On real-world datasets (Breast Cancer Wisconsin, Sachs RAF), the method shows improved classification accuracy over existing SSL approaches.
- The disjoint approach (CGAN-SSL) is generally more stable than the joint approach (GCGAN-SSL), which can underperform due to issues with the Gumbel-Softmax sampling strategy.

## Why This Works (Mechanism)
The method works by leveraging the ICM principle, which states that causal mechanisms are independent. By factorizing the joint distribution according to the causal graph and modelling each factor separately, the framework can generate high-quality synthetic data that respects the underlying causal structure. This allows the model to effectively learn from unlabelled data, improving classification performance even with limited labelled examples.

## Foundational Learning
- **Independent Causal Mechanisms (ICM):** The assumption that causal mechanisms are independent of each other. *Why needed:* Forms the theoretical foundation for exploiting unlabelled data in SSL. *Quick check:* Verify that the factorized model can generate realistic synthetic data.
- **Markov Blanket:** The set of variables that shields the label from the rest of the variables in the graph. *Why needed:* Used to categorize causal structures and determine the appropriate generative model. *Quick check:* Confirm that the identified Markov Blanket accurately captures the relevant dependencies.
- **Maximum Mean Discrepancy (MMD):** A kernel-based distance measure used to compare distributions. *Why needed:* Used to optimize the generative models by minimizing the discrepancy between real and synthetic feature distributions. *Quick check:* Monitor MMD loss during training to ensure it decreases.
- **Gumbel-Softmax:** A continuous relaxation of the discrete Gumbel-Max trick used for differentiable sampling. *Why needed:* Enables the joint modelling approach (GCGAN-SSL) to generate labels for unlabelled data. *Quick check:* Monitor the entropy of the Gumbel-Softmax samples to detect mode collapse.

## Architecture Onboarding
- **Component map:** Data (D_l, D_u, D_v, D_t) -> Causal Structure Identification -> SCM Parameter Estimation (via MMD) -> Synthetic Data Generation (D_G) -> Classifier Training (on D_l âˆª D_G) -> Evaluation (on D_t)
- **Critical path:** The generation of high-quality synthetic data (D_G) via the trained SCM models is the critical path, as it directly impacts the performance of the final classifier.
- **Design tradeoffs:** The method trades off model complexity for interpretability and theoretical guarantees based on the ICM principle. The disjoint approach (CGAN-SSL) is simpler but may miss some joint dependencies, while the joint approach (GCGAN-SSL) is more complex but can capture richer relationships.
- **Failure signatures:** Poor performance on CG1 (violating anticausal assumptions), instability in GCGAN-SSL due to Gumbel-Softmax variance, and scalability issues with high-dimensional data.
- **First 3 experiments:**
  1. Train a classifier only on the available labelled data D_l (P-SUP) to establish the lower-bound performance.
  2. Generate a batch of synthetic data from the trained causal generative model and qualitatively inspect samples or quantitatively compare their feature distributions to the real unlabelled data.
  3. Run the full pipeline using the correct causal graph and a deliberately incorrect graph (e.g., flipping all arrows) and compare the final classification accuracy.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can the framework be extended to learn the causal structure simultaneously with the classifier, removing the requirement for prior domain knowledge?
- **Open Question 2:** Under what specific data conditions does the joint GCGAN-SSL approach outperform the disjoint CGAN-SSL approach?
- **Open Question 3:** How does the performance of the MMD-based structural modelling scale with high-dimensional feature spaces?

## Limitations
- The framework assumes the Markov Blanket structure is identifiable from data, but the paper doesn't specify how to reliably estimate this from limited labelled data.
- The choice of Gumbel-Softmax temperature and the hard/soft sampling strategy for the joint approach (GCGAN-SSL) significantly impacts stability but remains underspecified.
- The method's performance on high-dimensional or categorical features is not validated beyond the 2D continuous synthetic data and two real-world datasets used.

## Confidence
- **High confidence:** The theoretical foundation based on the ICM principle and the categorization of causal structures by Markov Blanket topology are well-established concepts.
- **Medium confidence:** The experimental results demonstrating improvements over P-SUP baselines across multiple causal structures are promising, but the small sample sizes (n=40 labelled) limit generalizability.
- **Low confidence:** The scalability of the approach to complex, high-dimensional real-world scenarios and the robustness of causal structure identification from limited data remain unproven.

## Next Checks
1. **Ablation on Markov Blanket estimation:** Evaluate classification accuracy when the assumed causal graph category is deliberately mismatched with the true structure, quantifying the sensitivity to structure identification errors.
2. **High-dimensional stress test:** Apply the framework to a dataset with 10+ features and compare performance against established SSL methods (e.g., MixMatch, FixMatch) to assess scalability.
3. **Causal mechanism robustness:** Measure the impact of violating ICM assumptions (e.g., by introducing hidden confounders between Y and X_E) on synthetic data quality and downstream classification accuracy.