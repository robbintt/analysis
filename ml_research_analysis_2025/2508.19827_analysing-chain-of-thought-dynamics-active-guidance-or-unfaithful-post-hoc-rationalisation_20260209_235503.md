---
ver: rpa2
title: 'Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc
  Rationalisation?'
arxiv_id: '2508.19827'
source_url: https://arxiv.org/abs/2508.19827
tags:
- answer
- confidence
- reasoning
- gpqa
- csqa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates Chain-of-Thought (CoT) reasoning dynamics
  in soft-reasoning tasks across different model types. The core finding is that distilled-reasoning
  models heavily rely on CoT, frequently changing their initial answers and showing
  increasing confidence throughout reasoning steps.
---

# Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?

## Quick Facts
- arXiv ID: 2508.19827
- Source URL: https://arxiv.org/abs/2508.19827
- Reference count: 40
- Key outcome: Distilled-reasoning models rely heavily on CoT for reasoning, while instruction-tuned and reasoning models often use CoT as post-hoc justification rather than active guidance.

## Executive Summary
This study investigates Chain-of-Thought (CoT) reasoning dynamics across different model types on soft-reasoning tasks. The research reveals that distilled-reasoning models depend significantly on CoT, frequently changing their initial answers and showing increasing confidence through reasoning steps. In contrast, instruction-tuned and reasoning models demonstrate less answer revision and use CoT more for justification than active problem-solving. A critical finding is that CoT can be causally influential in the reasoning process without being faithful to the model's actual internal reasoning, challenging existing definitions of CoT faithfulness based solely on causal dependence.

## Method Summary
The researchers analyzed CoT dynamics by examining how different model types (distilled-reasoning, instruction-tuned, and reasoning models) approach soft-reasoning tasks. They measured answer consistency, confidence changes, and the frequency of answer revisions throughout the reasoning process. The study employed proxy measures to assess faithfulness and conducted counterfactual interventions to analyze causal influence. Four types of soft-reasoning tasks were used: counting, temporal, semantic, and entailment tasks, with a focus on English-language scenarios.

## Key Results
- Distilled-reasoning models heavily rely on CoT, frequently changing initial answers and showing increasing confidence through reasoning steps
- Instruction-tuned and reasoning models change answers less often, using CoT primarily for post-hoc justification
- CoT can be causally influential without being faithful to the model's actual reasoning process, and vice versa

## Why This Works (Mechanism)
The study reveals that different model training paradigms lead to distinct CoT usage patterns. Distilled-reasoning models, trained to mimic reasoning behaviors, internalize CoT as an essential reasoning scaffold, making it both causally influential and necessary for their problem-solving approach. Instruction-tuned and reasoning models, however, develop more sophisticated internal reasoning capabilities that may operate independently of their generated CoT, leading to cases where CoT serves as rationalization rather than active guidance. This mechanism suggests that the relationship between generated reasoning traces and actual internal computation varies significantly based on training methodology and model architecture.

## Foundational Learning

**Causal Influence vs. Faithfulness**: Understanding whether CoT affects model decisions versus whether it accurately reflects internal reasoning. Why needed: To properly evaluate the utility and reliability of CoT explanations. Quick check: Compare model performance with and without CoT, then assess if CoT matches internal reasoning states.

**Soft-reasoning Tasks**: Classification of reasoning problems that require gradual inference rather than discrete logical steps. Why needed: To study CoT dynamics in realistic, complex reasoning scenarios. Quick check: Verify task difficulty and ambiguity levels across counting, temporal, semantic, and entailment domains.

**Model Distillation Effects**: How training models to mimic reasoning behaviors affects their dependence on explicit reasoning traces. Why needed: To understand why distilled models show different CoT dynamics. Quick check: Compare CoT usage patterns between distilled and non-distilled versions of similar models.

**Proxy Measurement of Faithfulness**: Using observable metrics like answer consistency and confidence changes to infer internal reasoning faithfulness. Why needed: Direct access to internal reasoning processes is unavailable in most models. Quick check: Validate proxy measures against known faithful CoT examples.

## Architecture Onboarding

**Component Map**: Model -> CoT Generator -> Reasoning Steps -> Answer -> Confidence Score
**Critical Path**: Input → Initial Answer → CoT Generation → Answer Revision → Final Answer
**Design Tradeoffs**: The study prioritizes understanding reasoning dynamics over optimizing performance, accepting measurement noise from proxy faithfulness metrics to capture real-world CoT usage patterns.
**Failure Signatures**: Models that show high confidence in incorrect answers despite CoT, or CoT that appears as rationalization rather than genuine reasoning guidance.
**First Experiments**:
1. Ablation study comparing model performance with complete CoT removal versus selective step removal
2. Confidence calibration analysis comparing initial versus final answer confidence across model types
3. Human evaluation of CoT faithfulness versus automated proxy metrics

## Open Questions the Paper Calls Out

None identified in the source material.

## Limitations

The CoT dynamics observed may be influenced by task-specific characteristics of the four soft-reasoning tasks, limiting generalizability to other domains. The analysis of faithfulness relies on proxy measures rather than direct access to internal reasoning processes, creating potential measurement noise. The study focuses exclusively on English-language tasks and does not address multilingual or multimodal reasoning scenarios.

## Confidence

**High confidence**: The observed differences in CoT dynamics between distilled-reasoning models versus instruction-tuned/reasoning models are robust across multiple metrics and tasks
**Medium confidence**: The distinction between causal influence and faithfulness is theoretically sound and empirically supported, though the operational definitions used are necessarily imperfect proxies
**Medium confidence**: The claim that CoT can be causally influential without being faithful (and vice versa) is well-supported, though the relative prevalence of these scenarios across model types could benefit from larger-scale validation

## Next Checks

1. Conduct ablation studies on the four soft-reasoning tasks by systematically removing or modifying CoT steps to measure causal impact on final answer accuracy across all model types
2. Extend the analysis to a broader set of reasoning tasks including mathematical problem-solving, commonsense reasoning, and multi-step planning to test generalizability of observed dynamics
3. Implement controlled experiments comparing model performance with and without CoT generation, using both human evaluation and automated faithfulness metrics to validate the causal-influence versus faithfulness distinction