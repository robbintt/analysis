---
ver: rpa2
title: Data-Driven vs Traditional Approaches to Power Transformer's Top-Oil Temperature
  Estimation
arxiv_id: '2501.16831'
source_url: https://arxiv.org/abs/2501.16831
tags:
- temperature
- top-oil
- power
- quantile
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes machine learning methods for forecasting power
  transformer top-oil temperature using historical measurements. The authors compare
  artificial neural networks (ANNs), Time-series Dense Encoder (TiDE), and Temporal
  Convolutional Networks (TCN) against the IEC 60076-7 standard model.
---

# Data-Driven vs Traditional Approaches to Power Transformer's Top-Oil Temperature Estimation

## Quick Facts
- arXiv ID: 2501.16831
- Source URL: https://arxiv.org/abs/2501.16831
- Reference count: 30
- Primary result: Machine learning models (ANN, TiDE, TCN) outperform IEC 60076-7 standard for transformer top-oil temperature forecasting

## Executive Summary
This study proposes machine learning methods for forecasting power transformer top-oil temperature using historical measurements. The authors compare artificial neural networks (ANNs), Time-series Dense Encoder (TiDE), and Temporal Convolutional Networks (TCN) against the IEC 60076-7 standard model. All three deep learning approaches outperform the IEC standard, with ANN achieving the best performance at 1.49°C mean absolute error for top-oil temperature. The models are also extended to estimate temperature rise over ambient. Additionally, the authors explore quantile regression to construct prediction intervals, with the best-performing model successfully estimating conditional quantiles that provide sufficient coverage.

## Method Summary
The study employs autoregressive time-series forecasting to predict power transformer top-oil temperature and temperature rise over ambient. Three deep learning models (ANN, TiDE, TCN) are trained and compared against the IEC 60076-7 standard physics-based model. Models use 2-8 hour look-back windows on 190 days of 5-minute interval measurements including load factor, ambient temperature, and historical top-oil temperature. The ANN architecture uses 8 layers with 128 neurons and ReLU activation. Models are trained using manual feature scaling and validated autoregressively, using previous predictions as inputs when future measurements are unavailable.

## Key Results
- ANN achieved 1.49°C mean absolute error for top-oil temperature forecasting, outperforming IEC standard model
- All three ML models (ANN, TiDE, TCN) outperformed the IEC 60076-7 standard model
- TiDE model achieved 0.73 mean coverage for 98% prediction intervals using quantile regression
- ANN with 4-hour look-back window performed best among all configurations tested

## Why This Works (Mechanism)

### Mechanism 1: Data-Driven Learning of Thermal Dynamics
Machine learning models can learn complex thermal behavior directly from historical operational data, capturing non-linear relationships that simplified physics-based models may miss. By training on time-series data, models like ANN, TiDE, and TCN learn a mapping function from past data to future temperature, bypassing the need for explicit transformer-specific thermal parameters required by IEC standard.

### Mechanism 2: Autoregressive Multi-Step Forecasting
Models forecast future temperatures by recursively using their own predictions as inputs for subsequent time steps. A model predicts the next time step based on historical data, then uses this prediction concatenated with covariates to predict the following step, enabling generation of full trajectories without future ground-truth data.

### Mechanism 3: Uncertainty Quantification via Quantile Regression
By training models to minimize an asymmetric "pinball" loss function, they can predict conditional quantiles of the temperature distribution, enabling construction of prediction intervals that quantify forecast uncertainty. Training separate models for different quantiles allows creation of intervals that should contain the true value with specified probability.

## Foundational Learning

- **Time-Series Forecasting (Autoregression)**: Why needed here - The core task is predicting future values based on sequences of past values. Quick check question: How does an autoregressive model generate a prediction for time t+2?

- **Quantile Regression & Prediction Intervals**: Why needed here - The paper advances beyond point estimates to probabilistic forecasting for uncertainty estimation. Quick check question: If a model is trained to minimize the quantile loss for α = 0.9, what type of prediction error is it penalizing more heavily?

- **Physics-Informed vs. Data-Driven Modeling**: Why needed here - The central comparison is between IEC 60076-7 standard (physics-based) and ML models. Quick check question: What is a primary advantage of the IEC standard model compared to ANN, TiDE, and TCN models?

## Architecture Onboarding

- **Component map**: Inputs (past top-oil temp, load factor, future ambient/load forecasts) -> Core Model (ANN/TiDE/TCN) -> Output Layer (point estimate or quantile regression outputs)

- **Critical path**: Quality of top-oil temperature forecast depends most critically on quality and alignment of input covariates, particularly ambient temperature forecast

- **Design tradeoffs**: ANN vs. TiDE/TCN (simpler vs. better long-term dependency capture), Point Estimate vs. Quantile Regression (uncertainty vs. training difficulty), Look-back Window length (context vs. complexity)

- **Failure signatures**: Systematic under/over-estimation (under-capacity model or data mismatch), Low prediction interval coverage (overconfident model), Error accumulation in autoregressive forecasting (unstable model or insufficient training sequences)

- **First 3 experiments**: 
  1. Implement IEC 60076-7 standard model using differential equation as baseline benchmark
  2. Replicate ANN with 8 layers, 128 neurons, ReLU activation and compare MAE to reported 1.49°C
  3. Extend best ANN to quantile regression with three output neurons and evaluate prediction interval coverage

## Open Questions the Paper Calls Out

### Open Question 1
Can Physics-Informed Neural Networks (PINNs) outperform proposed data-driven models in generalizing to unseen operational cases? The authors state future steps should include comparing purely data-driven methods against PINNs, which can exploit physical equations to generalize better to unseen cases.

### Open Question 2
Can conformalized quantile regression successfully provide valid prediction interval coverage for transformer temperature estimation where standard quantile regression failed? The Discussion notes estimated conditional prediction intervals failed to satisfy coverage requirements and suggests combining quantile regression with conformalized prediction intervals.

### Open Question 3
How does the assumption of continuous natural convection cooling (ONAN) impact model accuracy during periods of forced air cooling? The Methodology section states information on cooling stages was unavailable, leading to assumption of constant natural convection, potentially masking errors during high-load periods.

## Limitations

- Specific numerical parameters for IEC 60076-7 standard model not provided, limiting exact replication of baseline comparison
- Definition of "manual scaling" for feature normalization is ambiguous
- Paper does not specify exact architecture details for TiDE and TCN, only relative performance
- Quantile regression for uncertainty quantification showed poor calibration in some models (ANN coverage of 0.16 vs. target of 0.98)

## Confidence

- **High Confidence**: Core finding that ML models outperform IEC standard on tested dataset (based on clear MAE comparisons in Table 5)
- **Medium Confidence**: Autoregressive forecasting mechanism and potential for error accumulation (well-established technique)
- **Low Confidence**: Success of quantile regression for uncertainty quantification (paper's own admission of poor calibration in some models)

## Next Checks

1. Implement and validate IEC 60076-7 baseline model using reasonable default parameters for ONAN cooling to establish performance benchmark
2. Reproduce ANN model architecture and training procedure, comparing validation MAE to reported 1.49°C
3. Extend ANN to perform quantile regression, evaluate prediction interval coverage, and test different calibration techniques to improve coverage from reported 0.16