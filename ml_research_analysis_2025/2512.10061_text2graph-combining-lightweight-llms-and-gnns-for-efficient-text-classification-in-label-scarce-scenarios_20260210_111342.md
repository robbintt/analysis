---
ver: rpa2
title: 'Text2Graph: Combining Lightweight LLMs and GNNs for Efficient Text Classification
  in Label-Scarce Scenarios'
arxiv_id: '2512.10061'
source_url: https://arxiv.org/abs/2512.10061
tags:
- graph
- classification
- text
- performance
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Text2Graph, an open-source Python framework
  that combines lightweight LLMs with GNNs for efficient text classification, particularly
  in label-scarce scenarios. The method converts unstructured text into a graph structure,
  uses LLMs to label a subset of nodes, and then propagates these labels across the
  graph using a GCN.
---

# Text2Graph: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios

## Quick Facts
- arXiv ID: 2512.10061
- Source URL: https://arxiv.org/abs/2512.10061
- Reference count: 22
- Combines lightweight LLMs with GNNs to achieve F1-macro scores of 0.80-0.85 while reducing energy consumption by 85-99% compared to full LLM labeling

## Executive Summary
Text2Graph is an open-source framework that addresses the high computational cost of LLM-based text classification by combining lightweight LLMs with graph neural networks (GNNs). The approach converts text documents into a graph structure, uses a small LLM to label a subset of nodes, and propagates these labels across the graph using a GCN. Tested on five datasets (Ohsumed, Reuters 8/52, AG News, IMDB), the method achieves competitive performance (F1-macro 0.80-0.85) while consuming significantly less energy (0.006-0.100 kWh) and producing lower CO2 emissions than full LLM annotation. The modular design allows easy customization of components like feature extractors and edge construction methods.

## Method Summary
The Text2Graph framework converts unstructured text documents into a graph where nodes represent documents and edges capture semantic relationships. Feature extraction uses all-MiniLM-L6-v2 sentence embeddings, while edges are constructed using either Minimum Spanning Tree (MST) from cosine distance matrices or k-nearest neighbors (k=5). A random 10% of nodes are selected for labeling by LLaMA3.1-8B with temperature t=0.0. These labeled nodes serve as seed data for a 2-layer GCN (16 hidden channels, 500 epochs, lr=10⁻³) that propagates labels to unlabeled nodes. The framework includes `codecarbon` integration for tracking energy consumption and CO2 emissions throughout the pipeline.

## Key Results
- Achieves F1-macro scores of 0.80-0.85 on five benchmark datasets while using 85-99% less energy than full LLM labeling
- Energy consumption ranges from 0.006-0.100 kWh across datasets, with corresponding CO2 emissions of 0.001-0.028 kg
- Outperforms random baseline by 15-25% F1-macro and approaches full LLM performance (0.84-0.88) at a fraction of the computational cost
- Demonstrates that graph-based label propagation offers a sustainable alternative to resource-intensive LLM annotation

## Why This Works (Mechanism)
The method leverages graph structure to propagate sparse LLM-generated labels efficiently. By converting text into a graph where semantically similar documents are connected, the GCN can infer labels for unlabeled nodes based on their neighbors. The MST edge construction reduces noise while preserving semantic relationships, and the GCN's message-passing mechanism effectively distributes label information across the graph. This approach exploits the homophily principle in text data, where documents with similar content tend to share labels.

## Foundational Learning
**Graph Neural Networks**: Neural networks that operate on graph-structured data through message passing between nodes. Needed to propagate labels across the document graph. Quick check: Can the GCN accurately predict node labels given only a small subset of labeled nodes?

**Sentence Embeddings**: Dense vector representations capturing semantic meaning of text passages. Needed to convert documents into comparable feature vectors for graph construction. Quick check: Do cosine distances between embeddings align with human-perceived semantic similarity?

**Minimum Spanning Tree**: Graph construction technique that connects all nodes with minimal total edge weight, reducing noise while preserving connectivity. Needed to create sparse yet informative document graphs. Quick check: Does MST produce fewer disconnected components than kNN with small k values?

**Label Propagation**: Semi-supervised learning technique where labels spread from labeled to unlabeled nodes through graph structure. Needed to leverage the small set of LLM-labeled nodes across the entire dataset. Quick check: Does label accuracy improve with more labeled nodes up to a point of diminishing returns?

**Energy Monitoring**: Measurement of computational resource consumption during model execution. Needed to quantify environmental impact and efficiency gains. Quick check: Does `codecarbon` tracking align with hardware-specific power measurements?

## Architecture Onboarding
**Component Map**: Documents -> Sentence Embeddings -> Graph Construction (MST/kNN) -> Node Sampling -> LLM Labeling -> GCN Training -> Label Prediction

**Critical Path**: The pipeline depends on accurate initial embeddings and effective graph construction. Poor embeddings or disconnected graphs will prevent successful label propagation regardless of GCN quality.

**Design Tradeoffs**: MST reduces noise but may miss weak semantic connections; kNN preserves more relationships but can create disconnected components. Random sampling is simple but risks missing minority classes; stratified sampling would be more robust but requires knowing class distributions.

**Failure Signatures**: 
- Low F1-macro scores despite successful LLM labeling indicate poor graph construction or disconnected components
- High energy consumption relative to performance suggests inefficient sampling or unnecessary LLM queries
- Missing minority classes in predictions reveal sampling bias or class imbalance issues

**First Experiments**:
1. Test graph connectivity after MST construction on a small subset to verify propagation is possible
2. Compare F1-macro scores with varying node sampling rates (5%, 10%, 20%) to identify optimal trade-off
3. Measure energy consumption differences between MST and kNN edge construction methods

## Open Questions the Paper Calls Out
**Open Question 1**: What is the acceptable trade-off between energy consumption and model performance in zero-shot text classification, and how should practitioners quantify this balance?
The paper demonstrates the trade-off exists but does not propose a formal framework or metric for determining optimal operating points across different application contexts.

**Open Question 2**: Can active learning-based sampling strategies effectively mitigate class representativeness problems in graph-based label propagation for datasets with many classes?
The authors identify class representativeness as a significant challenge, noting that for Reuters 52, 18 classes are always missing while 8 are missing 80% of the time, but no active learning approach was tested.

**Open Question 3**: Does committee-based labeling with multiple lightweight LLMs provide more reliable pseudo-labels for graph propagation while maintaining energy efficiency?
The authors propose exploring committee-based labeling to reduce individual model bias, but only single-model labeling was tested in the current framework.

**Open Question 4**: Would more complex graph construction methods (e.g., heterogeneous document-word graphs, attention-weighted edges) improve label propagation accuracy compared to MST and kNN approaches?
The paper notes kNN was not significantly more beneficial than MST and acknowledges alternative construction methods exist, but only tests MST and kNN.

## Limitations
- Evaluation focuses on homogeneous domains (news, biomedical, reviews), limiting generalizability to noisy or multilingual corpora
- 10% random sampling risks missing minority classes, especially problematic in high-cardinality datasets like Reuters-52
- Environmental metrics rely on `codecarbon` estimates rather than hardware-specific measurements
- Performance comparisons lack direct zero-shot LLM baselines on the same datasets

## Confidence
- F1-macro performance claims: Medium-High (competitive scores on established benchmarks)
- Energy/CO2 savings claims: Medium (based on estimation tools with inherent variance)
- Generalizability across domains: Low-Medium (tested only on homogeneous text corpora)

## Next Checks
1. Replicate experiments with stratified sampling to ensure minority class coverage and compare F1-macro stability
2. Run energy/CO2 measurements on specific hardware using power meters to validate `codecarbon` estimates
3. Test Text2Graph on noisy or multilingual datasets (e.g., tweets, code-switching text) to assess robustness beyond homogeneous domains