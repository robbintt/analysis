---
ver: rpa2
title: 'Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal
  and Predictive Analysis of Socio-academic and Economic Factors'
arxiv_id: '2508.00785'
source_url: https://arxiv.org/abs/2508.00785
tags:
- cgpa
- academic
- students
- factors
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of predicting student CGPA by
  considering a comprehensive set of socio-academic and economic factors. A novel
  approach was taken by integrating machine learning, causal analysis, and Explainable
  AI (XAI) techniques to identify the key predictors of academic performance.
---

# Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors

## Quick Facts
- **arXiv ID:** 2508.00785
- **Source URL:** https://arxiv.org/abs/2508.00785
- **Reference count:** 5
- **Primary result:** Integrated ML, causal analysis, and XAI to predict CGPA using socio-academic factors, achieving 98.68% accuracy with Random Forest.

## Executive Summary
This study develops an explainable AI framework for predicting student CGPA by analyzing socio-academic and economic factors. The researchers collected survey data from 1,050 students and applied machine learning models alongside causal discovery algorithms and interpretability techniques. Ridge Regression and Random Forest emerged as top performers, with Random Forest achieving 98.68% classification accuracy. The framework identifies critical predictors including study hours, scholarships, parental education, and prior academic performance through causal analysis using PC, GES, and GRaSP algorithms. A web application was developed to provide personalized predictions and actionable recommendations to students and educators.

## Method Summary
The study integrates machine learning, causal analysis, and Explainable AI (XAI) techniques to predict student CGPA from socio-academic and economic factors. The methodology involves collecting survey data from 1,050 students, applying regression and classification models (Ridge Regression and Random Forest), conducting causal discovery using algorithms like PC, GES, and GRaSP, and generating interpretable explanations through SHAP and LIME methods. The approach constructs a hypothesis graph from literature and validates it using data-driven causal algorithms, then applies local surrogate models for instance-level explanations.

## Key Results
- Ridge Regression achieved MAE of 0.12 in predicting CGPA
- Random Forest attained 98.68% classification accuracy for CGPA prediction
- Causal analysis identified study hours, scholarships, parental education, and prior academic performance as critical predictors
- SHAP and LIME methods provided interpretable feature importance and local explanations
- Web application developed for personalized predictions and recommendations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating causal discovery algorithms (PC, GES) with hypothesis graphs filters spurious correlations, identifying features with structural influence on CGPA.
- **Mechanism:** The system constructs a hypothesis graph from literature, then uses data-driven algorithms (PC, GES, GRaSP) to test conditional independence. If an edge survives pruning (e.g., Study Hours → CGPA), it is treated as a validated structural driver rather than a mere correlation.
- **Core assumption:** The observational data satisfies the Causal Markov Condition and Faithfulness.
- **Evidence anchors:**
  - [Page 17]: "The PC algorithm revealed intricate relationships... SH affected C, CS, and CGPA... GES algorithm identified critical dependencies where FE affected FJ."
  - [Abstract]: "Causal analysis using algorithms like PC, GES, and GRaSP... highlighted critical factors including study hours, scholarships."
- **Break condition:** If the dataset contains latent confounders that violate the Markov assumption, the causal direction may be inverted or spurious.

### Mechanism 2
- **Claim:** Local surrogate models (LIME) provide instance-level "actionability" that global feature importance cannot, allowing specific interventions for individual students.
- **Mechanism:** LIME perturbs the feature set of a single student and fits a simple interpretable model locally to approximate how the complex model behaves in the neighborhood of that specific student.
- **Core assumption:** The complex black-box model is locally linear.
- **Evidence anchors:**
  - [Page 19]: "LIME analysis indicated that... key features like PSR, SH, and GS had the most impact, with PSR and SH contributing negatively."
  - [Page 11]: "LIME generates a local surrogate model... by sampling the feature space around the instance x."
- **Break condition:** If the model is highly non-linear with complex interactions, the linear local surrogate may misrepresent the true feature effect.

### Mechanism 3
- **Claim:** Ensemble classification (Random Forest) outperforms linear regression for categorical performance prediction by capturing non-linear interactions between socioeconomic and academic variables.
- **Mechanism:** Random Forest aggregates multiple decision trees trained on bootstrapped data samples, capturing thresholds that linear Ridge Regression misses.
- **Core assumption:** The academic performance classes are separable by axis-aligned decision boundaries inherent to tree-based models.
- **Evidence anchors:**
  - [Page 15]: "Random Forest outperformed in classification, attaining an F1-score near perfection and an accuracy of 98.68%."
  - [Page 14]: "Ridge Regression demonstrated strong predictive accuracy... R-squared value of 0.0029."
- **Break condition:** If the relationship between factors and CGPA is strictly additive and linear without interaction effects, Random Forest could lead to overfitting.

## Foundational Learning

- **Concept:** Causal Directed Acyclic Graphs (DAGs) & Conditional Independence
  - **Why needed here:** To interpret the PC/GES results on Page 17. You must understand that $X \perp Y | Z$ implies no direct edge $X \to Y$.
  - **Quick check question:** If Study Hours (SH) and CGPA are correlated, but independent given "Motivation", does a Causal DAG contain a direct edge from SH to CGPA? (Answer: No, Motivation mediates it).

- **Concept:** SHAP (SHapley Additive exPlanations) Values
  - **Why needed here:** To interpret the "Force Plot" in Figure 11a. You need to know that Shapley values distribute the "payout" (prediction deviation from base value) fairly among features.
  - **Quick check question:** In a model with base value 0.72, if a feature increases the prediction to 0.80, is its SHAP value positive or negative? (Answer: Positive).

- **Concept:** Regularization (L2/Ridge)
  - **Why needed here:** To understand why Ridge Regression was selected. L2 regularization shrinks coefficients of correlated features toward each other to prevent overfitting.
  - **Quick check question:** If two features are perfectly correlated, how does Ridge Regression handle their coefficients compared to standard Linear Regression? (Answer: Ridge shrinks them; OLS makes them unstable/arbitrary).

## Architecture Onboarding

- **Component map:** Data Ingestion (Google Forms → CSV Dataset) → Processing Core (Python → Causal Discovery + ML Models) → Interpretability Layer (SHAP/LIME) → Application Layer (Node.js/Express ↔ ReactJS) → Storage (MySQL)

- **Critical path:**
  1. Data Quality Check: The paper reports 1,050 entries with no nulls (Page 7). Ensure new data follows the same encoding schema.
  2. Model Selection: The architecture splits into Regression (Ridge, MAE 0.12) and Classification (RF, 98.68% Acc). The low R² (0.0029) for regression suggests reliance on the Classification/RF path.
  3. Feedback Loop: User inputs → Model → Prediction → Feedback Storage (Page 6) for model refinement.

- **Design tradeoffs:**
  - Regression vs. Classification: Interpretability (Ridge is easier to explain globally) vs. Accuracy (RF is higher).
  - Causal vs. Pure ML: Adding causal graphs adds computation and theoretical assumptions but prevents recommending impossible interventions.

- **Failure signatures:**
  - Low Variance Explanation: If R² remains near zero, the model is essentially guessing the mean CGPA.
  - XAI Instability: If LIME explanations for similar students are contradictory, the local surrogate model is unstable.
  - Data Drift: The dataset is specific to Bangladesh. Deploying on US/UK data without retraining will fail.

- **First 3 experiments:**
  1. Baseline Replication: Train Ridge Regression on the provided dataset. Verify if MAE ≈ 0.12 and R² ≈ 0.0029.
  2. Sensitivity Analysis: Run the PC algorithm with different significance levels to see if causal edges are stable.
  3. A/B Test Explanations: Generate recommendations using Global Feature Importance vs. Local LIME. Test which users find more "actionable".

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the causal influences of socio-academic factors on CGPA evolve when analyzed through longitudinal data rather than cross-sectional surveys?
- Basis in paper: [explicit] The authors state, "extending the approach to include longitudinal analysis could offer deeper insights into the evolving impact of critical features on academic success."
- Why unresolved: The current study relies on a one-time survey of 1,050 students.
- What evidence would resolve it: Time-series data tracking the same cohort across multiple semesters.

### Open Question 2
- Question: To what extent does the inclusion of behavioral and socio-emotional variables improve the predictive accuracy and causal explanation of student CGPA?
- Basis in paper: [explicit] The conclusion notes that "external factors such as emotional well-being or unforeseen disruptions were not included" and suggests exploring "behavioral or socio-emotional factors" in future work.
- Why unresolved: The current feature set was limited to demographic, academic, and economic factors.
- What evidence would resolve it: Comparative model performance analysis adding validated metrics for stress, resilience, and emotional well-being.

### Open Question 3
- Question: Can the high predictive accuracy (98.68%) and identified causal structures be generalized to diverse student populations outside the specific Bangladeshi university context?
- Basis in paper: [inferred] The paper acknowledges the "dataset's scope was constrained to specific variables and contexts, potentially limiting the generalizability of findings across broader populations."
- Why unresolved: The model was trained and tested on a dataset from a specific region.
- What evidence would resolve it: External validation studies applying the trained models to datasets from international or varied institutional contexts.

## Limitations

- The exceptionally high Random Forest accuracy (98.68%) raises concerns about potential overfitting or data leakage
- Causal discovery results rely on assumptions about observational data that may not hold in practice
- The low R² value (0.0029) for Ridge Regression suggests the regression model explains minimal variance in CGPA

## Confidence

- **ML Prediction Performance:** Medium confidence - Lack of detailed validation methodology and exceptionally high score warrant skepticism
- **Causal Discovery Validity:** Low-Medium confidence - Methodologically sound but relies on observational data without interventional validation
- **XAI Explanations:** Medium confidence - Standard implementations but effectiveness depends on underlying model quality
- **Practical Applicability:** Low confidence - Web application described but not evaluated with end users

## Next Checks

1. **Independent Validation:** Split the dataset into training, validation, and independent test sets to verify the 98.68% accuracy is reproducible and not inflated by data leakage or overfitting.

2. **Causal Robustness Testing:** Perform sensitivity analysis by varying significance levels in the PC algorithm and testing for stability of key causal edges (e.g., Study Hours → CGPA) across multiple runs.

3. **External Generalization:** Test the model architecture on a dataset from a different educational context (e.g., Western university data) to assess whether the causal relationships and predictive patterns hold across different socio-economic environments.