---
ver: rpa2
title: 'FormaRL: Enhancing Autoformalization with no Labeled Data'
arxiv_id: '2508.18914'
source_url: https://arxiv.org/abs/2508.18914
tags:
- zhang
- wang
- formarl
- yang
- autoformalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FormaRL, a reinforcement learning framework
  for autoformalization that requires only unlabeled data. The method integrates syntax
  checks from the Lean compiler and consistency checks from large language models
  to compute rewards, and employs the GRPO algorithm to update the formalizer.
---

# FormaRL: Enhancing Autoformalization with no Labeled Data

## Quick Facts
- **arXiv ID:** 2508.18914
- **Source URL:** https://arxiv.org/abs/2508.18914
- **Reference count:** 24
- **Primary result:** Reinforcement learning framework for autoformalization using only unlabeled data, achieving 4-6x improvement in proof generation accuracy

## Executive Summary
FormaRL introduces a novel reinforcement learning approach to autoformalization that operates without labeled data. The method combines syntax validation from the Lean compiler with consistency checks from large language models to create a reward signal for training. The framework is evaluated on both ProofNet and a newly introduced uproof dataset, demonstrating substantial improvements in proof generation accuracy. The approach addresses a significant challenge in the field by eliminating the need for expensive labeled training data while maintaining strong performance on both in-distribution and out-of-distribution proof tasks.

## Method Summary
FormaRL employs a reinforcement learning framework where the formalizer receives rewards based on two key checks: syntax validation from the Lean compiler and consistency verification from large language models. The method uses the GRPO (Group Relative Policy Optimization) algorithm to update the formalizer based on these computed rewards. A critical innovation is the integration of syntax checks, which provide precise error signals, and consistency checks, which ensure semantic correctness. The framework operates entirely on unlabeled data, making it scalable and practical for real-world applications where labeled data is scarce or expensive to obtain.

## Key Results
- Qwen2.5-Coder-7B-Instruct achieves 4-6x improvement in pass@1 accuracy on ProofNet and uproof datasets
- Out-of-distribution performance on uproof: 9.6% pass@1 and 33.6% pass@16 accuracy
- FormaRL outperforms existing open-source autoformalizers on both in-distribution and out-of-distribution tasks
- Method requires only 859 unlabeled statements for training while maintaining strong performance

## Why This Works (Mechanism)
The effectiveness of FormaRL stems from its dual-reward system that combines precise syntactic validation with semantic consistency checking. Syntax checks from the Lean compiler provide exact error locations and types, enabling targeted corrections during training. Consistency checks from large language models ensure that generated proofs are not only syntactically correct but also semantically meaningful and aligned with mathematical reasoning. This combination creates a rich reward signal that guides the formalizer toward generating both correct and useful proofs. The reinforcement learning framework allows continuous improvement without requiring labeled examples, making the approach scalable and adaptable to new domains.

## Foundational Learning

**Reinforcement Learning** - Why needed: To train without labeled data by using reward signals
- Quick check: GRPO algorithm converges on unlabeled data

**Syntax Validation** - Why needed: To ensure generated proofs are formally correct in Lean
- Quick check: Lean compiler accepts generated proofs

**Consistency Checking** - Why needed: To verify semantic correctness beyond syntax
- Quick check: LLM confirms proof validity

**Formalization** - Why needed: To convert natural language proofs to formal proofs
- Quick check: Proof successfully type-checked by Lean

**Reward Shaping** - Why needed: To balance multiple objectives in training
- Quick check: Both syntax and consistency rewards contribute to improvement

## Architecture Onboarding

**Component Map:** Natural Language Problem -> Formalizer (LLM) -> Lean Compiler -> Consistency LLM -> Reward Computation -> GRPO Update -> Formalizer

**Critical Path:** Input problem → Formalizer generation → Lean syntax check → LLM consistency check → Reward calculation → GRPO policy update

**Design Tradeoffs:** Uses LLM-based consistency checks (computationally expensive but flexible) vs. rule-based methods (faster but less adaptable); relies on Lean compiler (precise but system-specific) vs. custom validators (more general but potentially less accurate)

**Failure Signatures:** Syntax check failures indicate generation errors; consistency check failures suggest semantic issues; poor reward signals may indicate need for hyperparameter tuning; distribution shift problems may require additional training data

**First Experiments:**
1. Test syntax validation accuracy on random formal statements
2. Evaluate consistency check reliability with known valid/invalid proofs
3. Verify GRPO convergence on small proof dataset

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions, but implicit areas for future work include extending the approach to other formal systems beyond Lean, scaling to more complex mathematical domains, and optimizing the computational efficiency of the consistency checking process.

## Limitations

- Reliance on Lean compiler limits generalizability to other formal systems
- Computational overhead from LLM consistency checks not extensively discussed
- uproof dataset focuses on undergraduate-level proofs, may not capture advanced mathematical complexity
- Method performance on highly complex proofs beyond current evaluation scope

## Confidence

**High:** Effectiveness of proposed method in improving autoformalization accuracy
**High:** Validity of experimental results and comparisons
**Medium:** Generalizability to formal systems beyond Lean
**Medium:** Scalability to more complex proof tasks
**Low:** Discussion of computational costs and efficiency
**Low:** Potential bias in consistency checking with LLMs

## Next Checks

1. Evaluate method on formal systems beyond Lean to assess generalizability
2. Conduct detailed analysis of computational costs and runtime efficiency
3. Test approach on advanced mathematical proof tasks beyond undergraduate level