---
ver: rpa2
title: Dissecting Judicial Reasoning in U.S. Copyright Damage Awards
arxiv_id: '2601.09459'
source_url: https://arxiv.org/abs/2601.09459
tags:
- legal
- reasoning
- damages
- copyright
- judicial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a discourse-based LLM framework that combines
  Rhetorical Structure Theory with agentic workflows to analyze judicial reasoning
  in copyright damage awards. The approach outperforms traditional methods, achieving
  77.1% accuracy and 76.5% F1 score in identifying punitive damage considerations
  while providing more nuanced legal reasoning explanations.
---

# Dissecting Judicial Reasoning in U.S. Copyright Damage Awards

## Quick Facts
- arXiv ID: 2601.09459
- Source URL: https://arxiv.org/abs/2601.09459
- Reference count: 40
- Primary result: 77.1% accuracy and 76.5% F1 score in identifying punitive damage considerations in copyright awards

## Executive Summary
This study introduces a discourse-based LLM framework that combines Rhetorical Structure Theory (RST) with agentic workflows to analyze judicial reasoning in copyright damage awards. The approach outperforms traditional methods by parsing judicial opinions into hierarchical discourse structures, revealing previously undetectable patterns in how judges prioritize and weight factors across jurisdictions. The methodology addresses key challenges in computational legal analysis by enabling systematic extraction of reasoning patterns from large corpora of opinions, offering practical tools for litigation strategy, empirical legal scholarship, and policy evaluation of statutory frameworks.

## Method Summary
The framework employs a three-stage pipeline: (1) Dataset Construction with expert annotation and LLM-based section segmentation; (2) Discourse Analysis using RST parsing to create hierarchical tree structures; (3) Agentic Feature Extraction with iterative prompt optimization. The system processes LexisNexis copyright cases, segments opinions into functional sections, linearizes RST trees into natural language context, and uses an LLM agent to iteratively refine extraction prompts. ChatGPT-4o-mini serves as the core model with temperature=0, achieving 77.1% accuracy and 76.5% F1 score on punitive damage classification.

## Key Results
- Agentic LLM framework achieves 77.1% accuracy and 76.5% F1 score in identifying punitive damage considerations
- RST-based discourse context improves precision from 0.522 to 0.619 by reducing false positives
- 100% recall achieved while maintaining high precision through hierarchical discourse analysis

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Discourse Context (Tree-of-Discourse)
The system linearizes the path from a text span up the RST tree to the root, creating discourse-aware context that distinguishes nucleus (core argument) from satellite (supporting detail). This prevents keyword matching errors where terms like "willful" might appear as elaborative context rather than primary justification.

### Mechanism 2: Iterative Prompt Optimization (Agentic Feedback Loop)
A Plan Optimizer uses gradient-descent-style prompt refinement to improve extraction reliability. The LLM agent generates an extraction plan, executes it against a validation set, and automatically revises prompts to fix error logic before final runs.

### Mechanism 3: Dual-Layer Annotation Filtering
Pre-filtering irrelevant cases and segmenting opinions via LLMs reduces noise before complex discourse analysis. LLM-based section segmentation with 92% accuracy focuses the RST parser only on relevant sections like "Analysis of The Relief."

## Foundational Learning

- **Rhetorical Structure Theory (RST)**: The structural representation the system "sees." Without understanding nucleus vs. satellite, you cannot debug why the model prioritizes one sentence over another. *Quick check: In "The court awarded damages because the infringement was willful," which part is the nucleus?*

- **Agentic Workflows (Plan-and-Execute)**: The system plans how to classify rather than just classifying. Understanding the separation between Planner (generating strategy) and Executor (running strategy) is required to debug logic vs. execution errors. *Quick check: Does the Plan Executor update LLM weights or only follow instructions?*

- **Punitive vs. Statutory Damages**: The target variable is subtle. "Willful" infringement allows enhanced statutory damages but isn't automatically "punitive" in intent. *Quick check: If a judge awards $30,000 (standard maximum) for willful infringement without explicitly stating "deterrence," does the system classify it as punitive?*

## Architecture Onboarding

- **Component map**: Data Ingestion -> Preprocessor -> RST Parser -> Linearizer -> Agentic Core (Plan Optimizer -> Plan Executor) -> Evaluator
- **Critical path**: The RST Linearization is the unique dependency. If the parser fails or linearization prompt is weak, the LLM receives garbage context, breaking the "ToD" advantage.
- **Design tradeoffs**: Interpretability vs. Complexity (LLM explanations add explainability but another failure point); Data Size vs. Precision (50 cases allow high-precision annotation but limit statistical power).
- **Failure signatures**: Keyword Hallucination (outputs "True" solely because "willful" appears); Segmentation Drift (mislabels "Analysis of Damages" as "Background Facts").
- **First 3 experiments**: (1) Run Section Labeler on 10 cases to verify "Analysis of Damages" isolation; (2) Ablation test: RST context vs. flattened text on single case; (3) Run Plan Optimizer 3 times on same feature to test convergence reliability.

## Open Questions the Paper Calls Out

### Open Question 1
Can hybrid RST parsing approaches combining automated analysis with expert validation enhance structural accuracy and reduce systematic biases? Current RST parsing accuracy limitations may affect discourse tree quality, potentially introducing systematic biases.

### Open Question 2
How do judicial reasoning patterns vary across federal district courts, state courts, and different circuit jurisdictions? Analysis focuses primarily on federal circuit court decisions, which may not fully capture patterns in district or state court opinions.

### Open Question 3
How do judicial reasoning patterns evolve temporally in response to Supreme Court precedents, legislative amendments, or technological developments? Current study provides cross-sectional analysis without accounting for temporal evolution in legal standards.

### Open Question 4
Does the discourse-based LLM framework maintain comparable performance when extracting factors beyond punitive damage, such as market value assessment or deterrence objectives? Framework was validated on single binary classification task; generalizability to multi-class reasoning extraction remains untested.

## Limitations
- Small annotated corpus (50 cases for experiments) constrains statistical power for jurisdictional variation claims
- RST parser integration represents critical dependency without fully characterized performance on legal text
- Binary classification of "punitive consideration" oversimplifies nuanced judicial reasoning with mixed statutory and punitive rationales

## Confidence
- **High Confidence**: Agentic LLM framework outperforms traditional methods (77.1% accuracy vs. 63.4% Random baseline) and reduces false positives through RST context
- **Medium Confidence**: Claims about revealing "previously undetectable patterns" are supported by methodology but limited by small sample size
- **Low Confidence**: Assertions about offering "practical tools for litigation strategy" extend beyond empirical evidence of academic analysis

## Next Checks
1. **RST Parser Performance Validation**: Test Chistova 2024 parser on 20 diverse legal opinions, measuring accuracy in identifying nucleus/satellite relationships with manual expert verification
2. **Cross-Validation with Expanded Corpus**: Replicate classification using 5-fold cross-validation on full 203-case annotated set to assess accuracy stability
3. **Ablation Study of Agentic Components**: Systematically disable ToD linearization, Plan Optimizer, and Section Segmentation to quantify each component's marginal contribution