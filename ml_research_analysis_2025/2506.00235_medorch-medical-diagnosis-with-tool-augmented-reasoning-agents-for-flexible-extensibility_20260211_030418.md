---
ver: rpa2
title: 'MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible
  Extensibility'
arxiv_id: '2506.00235'
source_url: https://arxiv.org/abs/2506.00235
tags:
- reasoning
- medorch
- medical
- clinical
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MedOrch is a modular, agent-based framework for medical diagnosis
  that dynamically orchestrates specialized tools and reasoning agents to provide
  transparent, customizable decision support. It employs a reasoning-driven approach
  that enables autonomous information gathering, tool selection, and multimodal integration
  without requiring task-specific training.
---

# MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility

## Quick Facts
- arXiv ID: 2506.00235
- Source URL: https://arxiv.org/abs/2506.00235
- Reference count: 40
- Primary result: Modular, tool-augmented reasoning framework achieving 93.26% accuracy on Alzheimer's diagnosis while maintaining complete audit trails

## Executive Summary
MedOrch is a modular, agent-based framework for medical diagnosis that dynamically orchestrates specialized tools and reasoning agents to provide transparent, customizable decision support. It employs a reasoning-driven approach that enables autonomous information gathering, tool selection, and multimodal integration without requiring task-specific training. The framework maintains complete audit trails of all intermediate steps and reasoning pathways while generating multiple diagnostic trajectories to explore alternative hypotheses.

Evaluated across Alzheimer's disease diagnosis (93.26% accuracy), chest X-ray interpretation (61.2% Macro AUC, 25.5% Macro F1), and multimodal visual question answering (54.47% accuracy), MedOrch demonstrates competitive performance while offering superior transparency and flexibility compared to specialized baselines. The system achieves significant accuracy improvements through multiple reasoning trajectories and can be easily adapted to new medical domains through modular tool registration without architectural changes.

## Method Summary
MedOrch is a framework that uses a reasoning model (GPT-4o or o1-mini) to generate diagnostic reasoning chains while dynamically invoking specialized tools through special tokens ([IMAGE_QUERY], [SQL_QUERY], etc.). The framework maintains a tool registry containing tool descriptions and usage examples, which are injected into the reasoning model's context for in-context learning. When the model generates a tool-call token, a query router extracts and dispatches the request to the appropriate agent (web search, coding sandbox, Text2SQL, RAG, or domain-specific medical agents). Tool outputs are reintegrated into the reasoning context, and the process repeats until the model emits a final conclusion. The system can generate multiple independent reasoning trajectories per case and maintains complete audit trails of all steps.

## Key Results
- Alzheimer's diagnosis accuracy: 93.26% (best@5) vs 88.71% (best@1) on 3-class classification
- Chest X-ray interpretation: 61.2% Macro AUC, 25.5% Macro F1 across 14 thoracic pathologies
- Multimodal visual QA accuracy: 54.47% on EHRXQA benchmark combining images and tables
- Multi-trajectory strategy improves accuracy by 4.55 percentage points through exploration of alternative hypotheses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In-context learning enables dynamic tool invocation without task-specific fine-tuning
- Mechanism: The reasoning model generates specialized tool-calling tokens during inference based on system prompts that describe tool capabilities. A three-step protocol (query routing → tool execution → results integration) reinserts tool outputs into the reasoning chain.
- Core assumption: The base LLM has sufficient reasoning capability to map clinical questions to appropriate tools via prompt-based instructions alone.
- Evidence anchors: [section 3.2] Tool tokens generated via in-context learning without fine-tuning; [abstract] Autonomous information gathering without task-specific training.

### Mechanism 2
- Claim: Multiple reasoning trajectories improve diagnostic accuracy by exploring alternative hypotheses
- Mechanism: MedOrch generates N independent reasoning paths per case (default N=5), each potentially invoking different tools in different sequences. Performance improves when the correct diagnosis appears in at least one trajectory.
- Core assumption: Different initial conditions or reasoning strategies yield partially independent diagnostic conclusions, such that errors are not perfectly correlated across trajectories.
- Evidence anchors: [section 4.2.3] Accuracy rises from 88.71% (best@1) to 93.26% (best@5) on three-class diagnosis.

### Mechanism 3
- Claim: Modular tool registration enables domain extensibility without architectural changes
- Mechanism: A tool registry maintains structured representations (semantic descriptions, I/O specs, usage examples) of all available agents. New tools are added via configuration updates; the reasoning model accesses them through the same token-generation protocol without retraining.
- Core assumption: Tools have well-defined interfaces that can be adequately described in natural language for the reasoning model to understand when and how to invoke them.
- Evidence anchors: [section 3.1] New tools added through registry without architectural modifications; [section 4.1] Fixed reasoning model with registered tools across all three tasks.

## Foundational Learning

- Concept: In-context learning for tool use
  - Why needed here: The system relies on the base model's ability to follow instructions for when and how to invoke tools, without fine-tuning.
  - Quick check question: Given a prompt describing a SQL tool with example invocations, can the model correctly generate a SQL query token for a new natural-language question?

- Concept: Multi-step reasoning with external state
  - Why needed here: Each tool call adds information to the context; the model must integrate these outputs into subsequent reasoning steps without losing coherence.
  - Quick check question: After receiving tool output "CSF ratio=0.62," does the model correctly incorporate this into its diagnostic chain rather than ignoring it or hallucinating different values?

- Concept: Tool registry design patterns
  - Why needed here: Engineers must understand how to structure tool descriptions (inputs, outputs, examples) so the reasoning model can select appropriate tools.
  - Quick check question: For a new "drug interaction checker" tool, what minimal information must be included in the registry entry for successful invocation?

## Architecture Onboarding

- Component map:
  Reasoning model (GPT-4o/o1-mini) -> Tool registry -> Query router -> (General agents: Web-search, Coding, Text2SQL, RAG) -> (Domain-specific agents: Medical Image Analysis, Medical Imaging QA, Clinical Knowledge Graph, Longitudinal Data Analysis) -> Results integrator

- Critical path:
  1. Clinical question enters system
  2. Reasoning model generates chain-of-thought, potentially emitting tool-call tokens
  3. Query router extracts and dispatches tool requests
  4. Agent executes and returns structured output
  5. Output reintegrated into reasoning context
  6. Steps 2-5 repeat until model emits final conclusion
  7. (Optional) Multiple trajectories generated and aggregated

- Design tradeoffs:
  - best@5 vs. best@1: Higher accuracy but 5x inference cost; may not be practical for real-time clinical use
  - Transparency vs. latency: Full audit trails require logging all intermediate steps, increasing storage and potentially revealing sensitive reasoning paths
  - General-purpose vs. specialized agents: General tools (web search, coding) add flexibility but may produce less reliable outputs than validated clinical tools

- Failure signatures:
  - Infinite tool-call loops: Model repeatedly requests information without converging; implement max-turn limits
  - Tool invocation errors: Generated queries incompatible with tool interfaces; add schema validation
  - Hallucinated tool outputs: Model generates plausible-looking but fictitious results; ensure all tool outputs are explicitly labeled as external

- First 3 experiments:
  1. Validate single-agent tool invocation: Test Text2SQL agent with 50 sample questions; measure SQL correctness and execution success rate
  2. Measure trajectory diversity: Run same clinical question 10 times; compare tool invocation sequences and final diagnoses to assess independence
  3. Ablate tool registry: Remove domain-specific agents (e.g., Medical Image Analysis) and measure performance drop on imaging tasks to quantify contribution of specialized tools

## Open Questions the Paper Calls Out

- Question: How can the system autonomously identify the most accurate diagnostic trajectory during inference without access to ground truth labels, given the significant performance gap between the "best@5" (93.26%) and "best@1" (88.71%) evaluation strategies?
- Basis in paper: Table 1 and Section 4.2.3 report that selecting the best of 5 trajectories yields substantially higher accuracy than a single attempt or majority voting, but this assumes an oracle selector.
- Question: Can MedOrch close the performance gap with template-based baselines on structured EHR data reasoning (Table QA) without sacrificing its zero-shot, training-free design?
- Basis in paper: Table 4 shows MedOrch achieves 78.70% accuracy on Table-related questions, lagging behind the BM25 baseline (83.33%), which relies on manual SQL templates.
- Question: How does the reasoning model's tool selection accuracy and latency degrade as the tool registry scales to encompass a significantly larger set of specialized medical instruments?
- Basis in paper: Section 3.1 states that the tool registry is injected into the reasoning model's context, and the Conclusion proposes extending the framework to "broader clinical scenarios."

## Limitations
- Limited generalization evidence across medical domains beyond three tested tasks
- No quantitative analysis of hallucination rates or error propagation through reasoning chains
- Multi-trajectory strategy untested for providing genuinely independent diagnostic perspectives
- Heavy dependence on external tool reliability and integration complexity for clinical deployment

## Confidence

- **High confidence** in modular architecture design and basic tool-augmentation mechanism, supported by clear implementation details and logical reasoning about tool token generation
- **Medium confidence** in reported accuracy improvements from multiple trajectories, though lack of diversity analysis and clinical validation limits certainty
- **Medium confidence** in framework's extensibility claims, given only three domain examples and no systematic evaluation of tool registration
- **Low confidence** in system reliability and safety for clinical deployment due to absence of hallucination analysis and clinician evaluation studies

## Next Checks

1. **Diversity analysis of multiple trajectories:** Run 50+ trials on same clinical cases and compute pairwise similarity of tool invocation sequences and final diagnoses to quantify independence of reasoning paths.

2. **Controlled hallucination audit:** Create test cases with known ground truth answers and deliberately query tools about non-existent patient data or rare conditions; measure hallucination rates and audit trail effectiveness.

3. **Clinical expert evaluation study:** Have practicing physicians review system outputs (single trajectory and best@5) for 100 randomly selected cases from test sets; measure agreement with gold labels and assessment of reasoning transparency.