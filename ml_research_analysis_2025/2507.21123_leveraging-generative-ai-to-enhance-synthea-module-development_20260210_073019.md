---
ver: rpa2
title: Leveraging Generative AI to Enhance Synthea Module Development
arxiv_id: '2507.21123'
source_url: https://arxiv.org/abs/2507.21123
tags:
- disease
- module
- synthea
- requirement
- profile
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study demonstrates the use of large language models (LLMs)
  to assist in developing Synthea modules for synthetic health data generation. A
  four-stage methodology was developed: disease profile generation, initial module
  creation, validation, and iterative refinement.'
---

# Leveraging Generative AI to Enhance Synthea Module Development

## Quick Facts
- **arXiv ID:** 2507.21123
- **Source URL:** https://arxiv.org/abs/2507.21123
- **Reference count:** 40
- **Primary result:** LLM-assisted methodology generates Synthea modules with clinical accuracy scores approaching 100% after iterative refinement, significantly reducing development time while maintaining clinical fidelity.

## Executive Summary
This study demonstrates a methodology for using large language models (LLMs) to assist in developing Synthea modules for synthetic health data generation. The approach employs a four-stage pipeline: disease profile generation, initial module creation, validation, and iterative refinement. Using Claude 3.5 Sonnet, GPT-4o, and Gemini 1.5 Pro, the methodology generated hyperthyroidism modules with clinical accuracy scores approaching 100% after multiple refinement iterations. The approach significantly reduces development time while maintaining clinical fidelity, though human oversight remains essential for validating medical codes and ensuring realistic population distributions.

## Method Summary
The methodology employs a four-stage pipeline: (1) LLM generates a disease profile with 45 numbered requirements from curated medical sources, (2) LLM generates initial Synthea module with ~50K token context including reference documentation and example modules, (3) automated Level 1 structural validation and LLM-based Level 2 clinical accuracy scoring, (4) batch feedback of 10 lowest-scoring requirements for iterative regeneration. The process typically requires 5-10 iterations to converge on clinical accuracy scores approaching 100%. Human expert review remains necessary for verifying medical codes and ensuring realistic population distributions.

## Key Results
- Progressive refinement improved clinical accuracy from ~40% to near 100% over 10 iterations
- Claude 3.5 Sonnet achieved highest Level 2 clinical accuracy with lowest standard deviation (~5%)
- Gemini 1.5 Pro showed highest initial scores but 40% JSON invalidity rate requiring more fixes
- All three tested LLMs (Claude, GPT-4o, Gemini) showed significant improvement through successive iterations
- Methodology significantly reduced development time while maintaining clinical fidelity

## Why This Works (Mechanism)

### Mechanism 1: Progressive Refinement via Structured Feedback
Iterative feedback cycles systematically improve module clinical accuracy from ~40% to near 100% over multiple iterations. Validation identifies errors → lowest-scoring requirements selected → feedback compiled into targeted prompt → LLM regenerates module → re-validation creates improvement trajectory. Core assumption: LLMs can interpret structured error descriptions and make localized corrections without degrading unrelated module sections. Evidence: A progressive refinement approach with clinical validation improved module quality from ~40% to near 100% clinical accuracy over 10 iterations. Break condition: If corrections introduce new errors faster than they fix existing ones, or if LLM cannot interpret batched feedback coherently.

### Mechanism 2: Disease Profile as Ground Truth Anchor
Explicit numbered requirements in disease profiles enable traceability, targeted scoring, and focused refinement. Curated clinical sources + LLM extraction → numbered requirements → each module state tagged with `requirement_number` → validation scores each requirement independently → lowest scores prioritized for next iteration. Core assumption: Disease profiles capture sufficient clinical fidelity; requirement granularity matches Synthea state complexity. Evidence: Using an explicit disease profile anchors the Synthea module in medical reality and enables the LLM to focus solely on bridging the gap between medical knowledge and the structured format. Break condition: If disease profiles omit critical clinical pathways or contain incorrect quantitative parameters, modules will encode these errors faithfully.

### Mechanism 3: Multi-Level Validation Separation
Separating structural validation (Level 1) from clinical validation (Level 2) allows focused debugging and prevents cascading errors. Level 1 checks JSON syntax, path integrity, transition completeness, temporal logic → Level 2 scores clinical accuracy against disease profile → staged feedback prevents mixing structural fixes with clinical corrections. Core assumption: Structural and clinical errors are sufficiently independent to address sequentially. Evidence: Level 1 validation focuses on verifying that the module adheres to the basic structural requirements while Level 2 involves validating the module's states, transitions, and parameters against the disease profile. Break condition: If structural and clinical errors are deeply coupled, sequential validation may miss root causes.

## Foundational Learning

- **Concept: Synthea State Machine Architecture**
  - Why needed here: LLM outputs must conform to Synthea's JSON state machine model; understanding state types, transitions, and ordering constraints is prerequisite to validating modules.
  - Quick check question: Can you explain why every Encounter state must be paired with an EncounterEnd, and what happens clinically if they are not?

- **Concept: Medical Terminology Systems (SNOMED CT, RxNorm, LOINC)**
  - Why needed here: LLMs frequently hallucinate medical codes; understanding code structure helps identify invalid codes during review.
  - Quick check question: Given an LLM-generated RxNorm code for methimazole, how would you verify its validity?

- **Concept: LLM Context and Output Constraints**
  - Why needed here: Modules can exceed output token limits (4096-8192), requiring continuation splicing; understanding token budgets prevents truncation failures.
  - Quick check question: What happens when an LLM output is truncated mid-JSON, and what splicing strategy would you use to reconstruct valid JSON?

## Architecture Onboarding

- **Component map:**
  Disease Profile Generator: LLM + curated clinical sources → numbered requirements document
  Module Generator: LLM + Synthea reference + example modules + disease profile → JSON module
  Level 1 Validator: Custom Python unit tests for Synthea structural rules
  Level 2 Validator: Independent LLM session scores each requirement (0.0-1.0 scale)
  Feedback Compiler: Selects 10 lowest-scoring requirements → generates targeted improvement prompt
  Continuation Handler: Splices multi-part LLM outputs into valid JSON

- **Critical path:**
  Disease profile generation → Initial module generation → L1 validation → L2 validation → Identify lowest-scoring requirements → Batch feedback → Regenerate module → Repeat (typically 5-10 iterations) → Human expert review → Code verification → Production

- **Design tradeoffs:**
  Claude (best reviewer precision, SD ~5%) vs. Gemini (highest initial scores, but 40% JSON invalidity rate)
  Batch size of 10 problems per iteration balances focus vs. comprehensive coverage
  Automated validation reduces cost but cannot replace human clinical review

- **Failure signatures:**
  Medical code hallucinations (SNOMED, RxNorm, LOINC codes that do not exist)
  Unreachable states (orphan states with no incoming transitions)
  Missing EncounterEnd states (encounters spanning months)
  State proliferation (modules growing from 70 to 109+ states without clinical justification)
  JSON truncation causing invalid syntax at output boundaries

- **First 3 experiments:**
  1. Generate initial hyperthyroidism modules with all three LLMs (GPT-4o, Claude, Gemini), compare L1 warning counts and L2 scores to establish baseline quality differences.
  2. Run 10-iteration progressive refinement on a single LLM's output, plot L2 score trajectory to verify convergence behavior.
  3. Implement standalone medical code verification step (query RxNorm/SNOMED APIs) on final module to quantify hallucination rate before any human review.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Level 3 population validation be effectively integrated into the progressive refinement workflow to ensure synthetic populations match real-world epidemiological distributions?
- Basis in paper: A third level of module validation, not considered in this study, involves evaluating the population produced by running the model and determining whether that population aligns with expected demographic and clinical distributions.
- Why unresolved: Population validation was excluded due to computational time required to generate large synthetic populations on each iteration.
- What evidence would resolve it: Implementing post-iteration Level 3 validation with statistical comparison of synthetic population demographics, incidence rates, and treatment outcomes against established epidemiological benchmarks.

### Open Question 2
- Question: How can hallucinated medical codes (SNOMED CT, RxNorm, ICD-10) in LLM-generated modules be systematically detected and corrected?
- Basis in paper: While the LLMs can create structurally valid modules with plausible clinical pathways, the codes generated for diagnoses, procedures, and medications are frequently incorrect. A follow-on step to detect and replace hallucinated codes is necessary.
- Why unresolved: No automated code verification mechanism was implemented; current methodology requires manual code review.
- What evidence would resolve it: A validated post-processing pipeline that cross-references generated codes against authoritative terminology databases, with measured accuracy improvement in production-ready modules.

### Open Question 3
- Question: Can the methodology be extended to model comorbidities and disease interactions across multiple concurrent conditions?
- Basis in paper: The current approach treats each disease module in isolation, without considering interactions with other conditions or comorbidities. This limits the realism of the synthetic patient data.
- Why unresolved: Each module is generated independently without cross-module coordination or dependency modeling beyond simple attribute sharing.
- What evidence would resolve it: Successfully generating interconnected modules for conditions with known comorbidities (e.g., diabetes-cardiovascular disease) where treatment decisions in one module appropriately influence trajectories in another.

### Open Question 4
- Question: Would fine-tuning LLMs on existing validated Synthea modules improve generation quality compared to out-of-the-box prompting?
- Basis in paper: Synthea has fewer than 90 validated modules... conceivably useful for fine-tuning. However, there is a problem creating input-output pairs needed for fine-tuning.
- Why unresolved: Fine-tuning was not pursued; the challenge of reconstructing clinical knowledge inputs for existing modules remains unsolved.
- What evidence would resolve it: A comparative study measuring L1/L2 scores, state complexity, and clinical accuracy between fine-tuned and prompted models across multiple disease domains.

## Limitations
- Human oversight remains essential for validating medical codes
- Methodology treats each disease module in isolation without considering interactions or comorbidities
- Level 3 population validation was excluded due to computational time requirements

## Confidence
- **High:** Progressive refinement improves clinical accuracy scores over iterations (10 iterations, ~40%→near 100%)
- **High:** LLM-generated modules can achieve clinical accuracy approaching 100% with refinement
- **Medium:** Claude 3.5 Sonnet provides best validation precision with lowest standard deviation
- **Medium:** Methodology significantly reduces development time compared to manual creation
- **Low:** Current approach cannot detect or correct hallucinated medical codes without human review

## Next Checks
1. Implement medical code verification pipeline to quantify and correct LLM-generated code hallucinations
2. Run population-level validation on refined modules to assess epidemiological realism
3. Test multi-condition module generation with comorbidities to evaluate cross-module interaction capabilities