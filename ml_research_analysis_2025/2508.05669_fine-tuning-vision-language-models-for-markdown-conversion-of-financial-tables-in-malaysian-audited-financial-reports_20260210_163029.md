---
ver: rpa2
title: Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables
  in Malaysian Audited Financial Reports
arxiv_id: '2508.05669'
source_url: https://arxiv.org/abs/2508.05669
tags:
- financial
- markdown
- table
- fine-tuning
- tables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study fine-tuned Qwen2.5-VL-7B, a vision-language model, to
  convert Malaysian audited financial tables into structured Markdown. The approach
  used supervised fine-tuning with LoRA on a domain-specific dataset of 2,152 image-text
  pairs, including rotated augmentations.
---

# Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports

## Quick Facts
- arXiv ID: 2508.05669
- Source URL: https://arxiv.org/abs/2508.05669
- Reference count: 12
- Fine-tuned Qwen2.5-VL-7B to convert Malaysian audited financial tables into structured Markdown with 92.20% accuracy

## Executive Summary
This study fine-tuned Qwen2.5-VL-7B, a vision-language model, to convert Malaysian audited financial tables into structured Markdown. The approach used supervised fine-tuning with LoRA on a domain-specific dataset of 2,152 image-text pairs, including rotated augmentations. Performance was evaluated using a criteria-based LLM-as-a-judge and a novel Markdown Tree-Edit-Distance-based Similarity (TEDS) metric on a held-out test set of 100 tables. The fine-tuned model achieved 92.20% overall accuracy and 96.53% Markdown TEDS score, significantly outperforming the base model, larger VLMs, reasoning-enabled models, and proprietary models like GPT-4o and Gemini 2.5 Flash, while also reducing inference time.

## Method Summary
The research employed supervised fine-tuning of Qwen2.5-VL-7B using LoRA adapters on a curated dataset of 2,152 image-text pairs extracted from Malaysian audited financial reports. The dataset was augmented with rotated versions to improve robustness. A novel evaluation framework was developed, combining an LLM-as-a-judge system with a custom TEDS metric to assess Markdown conversion quality. The model was tested against a held-out set of 100 tables and compared with various baseline models including larger VLMs, reasoning models, and proprietary solutions.

## Key Results
- Fine-tuned model achieved 92.20% overall accuracy on test set
- Markdown TEDS score of 96.53% significantly outperformed all baselines
- Reduced inference time compared to larger VLMs and proprietary models

## Why This Works (Mechanism)
The success stems from domain-specific fine-tuning on financial tables from Malaysian audited reports, which captures the unique formatting and content patterns. The LoRA-based fine-tuning approach allows efficient adaptation without full model retraining. The combination of LLM-as-a-judge and TEDS metrics provides comprehensive evaluation of both structural and semantic accuracy in the Markdown output.

## Foundational Learning
- **Vision-Language Models**: Why needed - to process both visual table structure and textual content simultaneously; Quick check - verify model can extract both visual layout and text from table images
- **LoRA Fine-Tuning**: Why needed - enables efficient model adaptation with fewer parameters; Quick check - confirm fine-tuned weights are significantly smaller than full model
- **Tree-Edit-Distance Metrics**: Why needed - quantifies structural differences between generated and reference Markdown; Quick check - ensure TEDS score correlates with human judgment
- **Data Augmentation**: Why needed - improves model robustness to rotated and varied table orientations; Quick check - verify performance improvement with augmented vs. non-augmented training
- **LLM-as-a-Judge**: Why needed - provides automated evaluation aligned with task-specific criteria; Quick check - validate judge consistency across multiple runs
- **Domain-Specific Datasets**: Why needed - captures unique patterns in financial reporting; Quick check - ensure dataset represents full variability of target domain

## Architecture Onboarding

Component Map: Image -> VLM Encoder -> LoRA Adapter -> Decoder -> Markdown Output

Critical Path: Image input → Vision encoder → LoRA-adapted cross-attention → Language decoder → Structured Markdown generation

Design Tradeoffs: LoRA enables efficient fine-tuning but may limit adaptation capacity compared to full fine-tuning. Domain-specific training improves performance on target task but reduces generalizability.

Failure Signatures: Poor handling of rotated tables, incorrect cell alignment, loss of table structure, failure on tables with unusual formatting or mixed languages.

First Experiments:
1. Test base model on 10 sample tables to establish baseline performance
2. Evaluate LoRA fine-tuning impact on 10 validation samples during training
3. Compare inference speed of fine-tuned vs. base model on identical hardware

## Open Questions the Paper Calls Out
None

## Limitations
- Limited generalizability beyond Malaysian audited financial report domain
- Dataset restricted to single jurisdiction and document type
- LLM-as-a-judge evaluation introduces potential subjectivity
- Markdown TEDS metric lacks validation against human annotations

## Confidence
- High confidence in comparative performance results against base model and other VLMs on same dataset
- Medium confidence in relative superiority claims against proprietary models (not tested under identical conditions)
- Medium confidence in inference time reduction (hardware configurations not specified)
- Low confidence in real-world applicability beyond Malaysian financial reporting context

## Next Checks
1. Test fine-tuned model on diverse dataset of financial tables from multiple countries, languages, and reporting standards to assess cross-domain robustness
2. Conduct human evaluation studies to validate LLM-as-a-judge and TEDS metric results against ground truth annotations
3. Benchmark model performance and inference time on standardized hardware to enable fair comparisons with proprietary solutions