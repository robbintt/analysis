---
ver: rpa2
title: 'Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for
  Code Generation'
arxiv_id: '2502.12492'
source_url: https://arxiv.org/abs/2502.12492
tags:
- arxiv
- data
- reasoning
- lora
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles code generation, a complex System 2 task, by
  addressing two key challenges: the difficulty of exploring intricate reasoning processes
  and the heterogeneous data distribution that complicates robust model training.
  The authors propose the BDC framework, which uses an MC-Tree-Of-Agents algorithm
  to explore System 2 knowledge via mutual boosting among multiple LLMs, disentangle
  heterogeneous data into clusters, and generate customized problem solvers through
  an input-aware hypernetwork that weights over composable LoRA experts.'
---

# Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation

## Quick Facts
- arXiv ID: 2502.12492
- Source URL: https://arxiv.org/abs/2502.12492
- Reference count: 11
- Primary result: BDC framework achieves 10% accuracy gains over single LLM agents on APPS and CodeContest datasets

## Executive Summary
This paper tackles code generation for competitive programming by addressing two key challenges: the difficulty of exploring intricate reasoning processes and the heterogeneous data distribution that complicates robust model training. The authors propose the BDC framework, which uses an MC-Tree-Of-Agents algorithm to explore System 2 knowledge via mutual boosting among multiple LLMs, disentangle heterogeneous data into clusters, and generate customized problem solvers through an input-aware hypernetwork that weights over composable LoRA experts. Empirical results show that BDC outperforms baseline methods on APPS and CodeContest datasets, achieving accuracy gains of up to 10% over single LLM agents and demonstrating robustness across varying difficulty levels.

## Method Summary
The BDC framework consists of a three-stage pipeline: (1) MC-Tree-Of-Agents exploration where multiple LLMs iteratively explore reasoning processes using P-UCB selection, pruning, and refinement to collect System 2 knowledge; (2) K-means clustering of collected reasoning data by semantic embeddings to disentangle heterogeneous patterns into separate clusters; (3) Input-aware hypernetwork that generates rank-wise weights over composable LoRA experts, creating customized solvers based on problem characteristics. The approach uses Meta-llama-3.1-instruct-8b as the base model with GPT-4o-mini and Claude-3.5-Sonnet as exploration agents.

## Key Results
- BDC achieves 10% accuracy gains over single LLM agents on APPS and CodeContest datasets
- Demonstrates robustness across difficulty levels with consistent performance improvements
- Outperforms baseline methods on both pass rate and accuracy metrics

## Why This Works (Mechanism)
The framework succeeds by combining three complementary mechanisms: (1) mutual boosting among multiple LLMs during exploration captures diverse reasoning strategies through iterative refinement; (2) clustering disentangles heterogeneous data distribution, allowing specialized LoRA experts to focus on distinct problem patterns; (3) input-aware hypernetwork dynamically composes the most relevant experts for each problem, creating customized solutions rather than one-size-fits-all approaches.

## Foundational Learning
**Monte Carlo Tree Search**: Why needed - Systematic exploration of reasoning space for complex problems; Quick check - Tree depth and node expansion patterns should show increasing refinement with iterations
**Mutual Boosting**: Why needed - Multiple agents correct each other's errors through iterative refinement; Quick check - Compare single-agent vs multi-agent exploration quality metrics
**P-UCB Selection**: Why needed - Balances exploration-exploitation in MCTS for code generation; Quick check - Track selection frequency and reward distribution across tree nodes
**K-means Clustering**: Why needed - Disentangles heterogeneous data into meaningful patterns; Quick check - Cluster separation metrics (silhouette score) should indicate clear boundaries
**LoRA Adaptation**: Why needed - Enables efficient specialization of base model for distinct problem types; Quick check - Per-cluster expert performance variance should be substantial
**Input-Aware Hypernetwork**: Why needed - Dynamically composes specialized experts based on problem characteristics; Quick check - Hypernetwork weights should correlate with cluster membership

## Architecture Onboarding
**Component Map**: MCTS Exploration -> K-means Clustering -> LoRA Experts -> Input-Aware Hypernetwork -> Customized Solver
**Critical Path**: The most compute-intensive path is MCTS exploration, requiring multiple LLM calls per problem with iterative refinement, followed by hypernetwork computation during inference
**Design Tradeoffs**: The framework trades inference efficiency (weighted combination of multiple LoRA experts) for accuracy gains from specialized experts, while using clustering to minimize the number of experts needed
**Failure Signatures**: 
- Exploration collapse: MCTS tree becomes shallow with uniform node selection
- Cluster ambiguity: K-means produces overlapping clusters with poor separation
- Expert collapse: All LoRA experts show similar performance regardless of cluster assignment
- Hypernetwork overfitting: Training loss decreases but test performance degrades
**First Experiments**:
1. Implement basic MCTS with P-UCB selection on a simple code generation benchmark to validate mutual boosting mechanism
2. Apply K-means clustering to collected data and verify distinct performance patterns across resulting clusters
3. Train input-aware hypernetwork and test whether it learns to select appropriate expert combinations for held-out problems

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Critical hyperparameters for MCTS (exploration constant, discount factor, pruning thresholds) are unspecified
- Code LLM encoder for clustering embeddings is not identified
- LoRA configuration parameters (rank, layers, alpha values) are not provided
- Hypernetwork architecture details (depth, width, activation functions) are absent

## Confidence
- **High confidence**: The overall three-stage pipeline architecture is clearly described and represents a novel approach to code generation
- **Medium confidence**: The general methodology for each stage (P-UCB selection, K-means clustering, rank-wise weighted aggregation) is sufficiently detailed
- **Low confidence**: Specific implementation details critical for reproduction are largely unspecified

## Next Checks
1. **Implementation Validation**: Reconstruct the MC-Tree-Of-Agents algorithm with reasonable default hyperparameters and validate on a small code generation benchmark to ensure the mutual boosting and pruning mechanisms function as intended
2. **Cluster Quality Assessment**: Apply the K-means clustering with the specified code LLM encoder and evaluate whether clusters show meaningful separation in embedding space and whether LoRA experts trained on different clusters exhibit distinct performance patterns
3. **Hypernetwork Generalization**: Test the input-aware hypernetwork on held-out problems to verify it learns to select appropriate expert combinations rather than memorizing cluster-to-expert mappings, using cross-validation across APPS difficulty levels