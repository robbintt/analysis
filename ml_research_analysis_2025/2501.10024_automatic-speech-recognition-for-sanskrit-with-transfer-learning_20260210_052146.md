---
ver: rpa2
title: Automatic Speech Recognition for Sanskrit with Transfer Learning
arxiv_id: '2501.10024'
source_url: https://arxiv.org/abs/2501.10024
tags:
- sanskrit
- speech
- learning
- recognition
- whisper
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a transfer learning approach to develop an\
  \ Automatic Speech Recognition (ASR) model for Sanskrit, an ancient language with\
  \ limited digital resources. The authors fine-tuned OpenAI's Whisper model on the\
  \ V\xAFaksa\u02DCncayah."
---

# Automatic Speech Recognition for Sanskrit with Transfer Learning

## Quick Facts
- arXiv ID: 2501.10024
- Source URL: https://arxiv.org/abs/2501.10024
- Reference count: 20
- Primary result: Achieved 15.42% WER on Sanskrit ASR using Whisper fine-tuning with transfer learning

## Executive Summary
This paper presents a transfer learning approach for developing an Automatic Speech Recognition (ASR) model for Sanskrit using OpenAI's Whisper model. The authors fine-tuned Whisper on the Vāksañcayah dataset containing over 78 hours of Sanskrit audio recordings, achieving a Word Error Rate of 15.42% on the test set. The approach significantly outperforms previous methods for Sanskrit ASR and demonstrates robust performance on out-of-domain test sets. An online demo was created to showcase the model's capabilities for public evaluation.

## Method Summary
The authors employed a transfer learning approach by fine-tuning OpenAI's Whisper model on the Vāksañcayah Sanskrit dataset. The process involved hyperparameter optimization to improve model performance, with careful attention to adapting the multilingual model to the specific characteristics of Sanskrit speech. The fine-tuning was conducted on the 78+ hour audio corpus, with the model being evaluated on both in-domain and out-of-domain test sets to assess its generalization capabilities.

## Key Results
- Achieved 15.42% Word Error Rate on test set, outperforming previous Sanskrit ASR methods
- Demonstrated robust performance on out-of-domain test sets, indicating real-world applicability
- Showed effectiveness of transfer learning approach for low-resource languages like Sanskrit

## Why This Works (Mechanism)
The transfer learning approach works by leveraging pre-trained representations from Whisper, which has been trained on diverse multilingual data. By fine-tuning these representations on Sanskrit-specific data, the model can adapt to the unique phonological and grammatical features of the language while retaining the general speech recognition capabilities learned from the broader training. The hyperparameter optimization further refines the model's ability to handle Sanskrit's specific characteristics, resulting in improved performance over training from scratch or using less optimized configurations.

## Foundational Learning
- Transfer Learning: Why needed - Leverages pre-trained models for low-resource languages; Quick check - Compare fine-tuned vs. from-scratch training
- Hyperparameter Optimization: Why needed - Identifies optimal model configurations for specific tasks; Quick check - Grid search or Bayesian optimization results
- Word Error Rate (WER): Why needed - Standard metric for ASR performance evaluation; Quick check - Manual transcription comparison
- Sanskrit Diglossia: Why needed - Classical vs. Vedic variants require different modeling approaches; Quick check - Cross-dialect performance analysis

## Architecture Onboarding

Component Map:
Whisper Base Model -> Fine-tuning Layer -> Hyperparameter Optimization -> Evaluation Pipeline

Critical Path:
Sanskrit audio input → Whisper feature extraction → Fine-tuning adaptation → WER calculation → Model deployment

Design Tradeoffs:
- Computational resources vs. model accuracy
- Training time vs. hyperparameter exploration depth
- Dataset size vs. generalization capability

Failure Signatures:
- High WER on out-of-domain data indicates overfitting
- Poor performance on specific Sanskrit dialects suggests insufficient dialect representation
- Computational constraints limiting fine-tuning iterations

First Experiments:
1. Compare WER on Vedic vs. Classical Sanskrit samples
2. Test model performance across different speaker demographics
3. Evaluate computational requirements for fine-tuning vs. inference

## Open Questions the Paper Calls Out
None

## Limitations
- Results may not generalize beyond the specific Sanskrit corpus used
- 78-hour training dataset remains limited compared to major language datasets
- Computational requirements may pose accessibility challenges for researchers
- Potential biases in dataset not addressed
- Performance across different Sanskrit dialects not thoroughly evaluated

## Confidence
- High confidence in technical implementation of transfer learning with Whisper
- Medium confidence in absolute WER values due to potential dataset-specific optimizations
- Medium confidence in out-of-domain performance claims without detailed cross-validation
- Low confidence in real-world applicability claims without user testing data

## Next Checks
1. Evaluate the model on multiple Sanskrit datasets including Vedic Sanskrit to test cross-dialect generalization
2. Conduct speaker diversity testing across age, gender, and regional backgrounds to assess bias and robustness
3. Perform ablation studies to quantify the contribution of transfer learning versus dataset size to the improved WER