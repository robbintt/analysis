---
ver: rpa2
title: Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving
arxiv_id: '2509.02718'
source_url: https://arxiv.org/abs/2509.02718
tags:
- cost
- performance
- perf
- routing
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first training-free online routing algorithm
  for high-volume, budget-constrained multi-LLM serving. The algorithm uses Approximate
  Nearest Neighbor Search (ANNS) to efficiently estimate query features from historical
  data, then performs a one-time optimization over a small set of initial queries
  to learn routing weights that guide subsequent routing decisions.
---

# Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving

## Quick Facts
- arXiv ID: 2509.02718
- Source URL: https://arxiv.org/abs/2509.02718
- Authors: Fangzhou Wu; Sandeep Silwal
- Reference count: 40
- This paper introduces the first training-free online routing algorithm for high-volume, budget-constrained multi-LLM serving.

## Executive Summary
This paper presents a novel training-free online routing algorithm designed to optimize multi-LLM serving systems under budget constraints. The algorithm leverages Approximate Nearest Neighbor Search (ANNS) to efficiently estimate query features from historical data, then performs a one-time optimization over a small set of initial queries to learn routing weights that guide subsequent routing decisions. The method is particularly suited for high-volume, budget-constrained scenarios where training-based approaches may be impractical. Theoretical analysis establishes competitive ratio guarantees of 1-o(1) compared to the offline optimum under natural assumptions, while extensive experiments demonstrate significant performance improvements over existing baselines.

## Method Summary
The algorithm operates by first using ANNS to estimate query features from historical data, which captures the essential characteristics of incoming queries without requiring explicit feature extraction. It then performs a one-time optimization over a small subset of initial queries to determine optimal routing weights that balance performance, cost, and throughput considerations. These learned weights guide all subsequent routing decisions in an online fashion, making the approach both computationally efficient and effective at runtime. The method is training-free, eliminating the need for costly model retraining or fine-tuning, and is designed to work effectively even with limited historical data.

## Key Results
- Achieves competitive ratio of 1-o(1) compared to offline optimum under natural assumptions
- Outperforms all baselines with average improvement of 3.55x in performance
- Delivers 1.85x improvement in cost efficiency and nearly 4.25x in throughput

## Why This Works (Mechanism)
The algorithm's effectiveness stems from its intelligent combination of ANNS-based feature estimation with one-time optimization. By leveraging historical query patterns through ANNS, the system can quickly identify which LLM model is best suited for each incoming query without expensive online computations. The one-time optimization over initial queries creates a robust routing policy that adapts to the specific characteristics of the deployment environment. This approach is particularly effective because it balances the exploration needed to understand query patterns with the exploitation of learned routing weights, all while remaining computationally efficient and avoiding the overhead of continuous training.

## Foundational Learning

1. **Approximate Nearest Neighbor Search (ANNS)**: Fast similarity search technique for high-dimensional data that enables efficient query feature estimation from historical patterns.
   - Why needed: To quickly estimate query features without explicit feature extraction
   - Quick check: Verify ANNS can handle query volume with acceptable latency

2. **Competitive Analysis Framework**: Theoretical framework for evaluating online algorithms against offline optimal solutions.
   - Why needed: To establish theoretical guarantees for the routing algorithm
   - Quick check: Validate competitive ratio assumptions hold in practice

3. **Budget-Constrained Optimization**: Mathematical formulation for balancing multiple objectives under resource constraints.
   - Why needed: To optimize routing decisions considering performance, cost, and throughput
   - Quick check: Test optimization stability across different budget scenarios

4. **Online Algorithm Design**: Strategies for making decisions with incomplete information about future inputs.
   - Why needed: To handle the sequential nature of query arrivals
   - Quick check: Evaluate algorithm performance under different arrival patterns

## Architecture Onboarding

**Component Map**: Historical Data -> ANNS Feature Estimator -> Initial Query Optimizer -> Routing Weight Calculator -> Query Router -> LLM Models

**Critical Path**: Query Arrival → ANNS Feature Estimation → Routing Decision → LLM Execution → Response Delivery

**Design Tradeoffs**: 
- Training-free vs. accuracy: Sacrifices some potential optimization for practical deployability
- One-time optimization vs. adaptive learning: Reduces computational overhead at the cost of some responsiveness to changing patterns
- ANNS approximation vs. exact features: Trades minor accuracy for significant speed improvements

**Failure Signatures**:
- Degraded performance when query distribution shifts significantly from historical patterns
- Suboptimal routing decisions when budget constraints are poorly specified
- Performance bottlenecks when ANNS cannot handle query volume efficiently

**First 3 Experiments**:
1. Validate ANNS feature estimation accuracy against ground truth query features
2. Test one-time optimization convergence and stability across different initial query subsets
3. Measure routing decision latency under various query arrival rates

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical competitive ratio relies on specific assumptions about query distribution that may not hold in all real-world scenarios
- Dependence on historical data could pose challenges in cold-start situations or when query distributions shift significantly
- Real-world applicability across diverse application domains remains to be thoroughly validated beyond tested benchmarks

## Confidence
- Performance improvement claims (3.55x, 1.85x, 4.25x): Medium - supported by empirical results but may vary across deployment environments
- Theoretical competitive ratio guarantees: High - well-established through rigorous analysis
- Robustness claims across varying query volumes: Medium - supported by experiments but needs additional stress testing

## Next Checks
1. Test the algorithm's performance under dynamic query distribution shifts to evaluate its adaptability in real-world scenarios where query patterns evolve over time
2. Conduct extensive cold-start experiments to assess the algorithm's effectiveness when limited historical data is available
3. Validate the algorithm across diverse application domains (e.g., code generation, medical Q&A, creative writing) to confirm its generalizability beyond the tested benchmarks