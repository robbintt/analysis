---
ver: rpa2
title: Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing
  in Video Question Answering
arxiv_id: '2504.02417'
source_url: https://arxiv.org/abs/2504.02417
tags:
- question
- relationship
- target
- graph
- message
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method for video question answering that leverages
  static relationships through intra-type and inter-type message passing. It constructs
  a dual graph for intra-type reasoning and a heterogeneous graph for inter-type reasoning,
  using question-guided message passing to update node and edge representations.
---

# Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing in Video Question Answering

## Quick Facts
- **arXiv ID**: 2504.02417
- **Source URL**: https://arxiv.org/abs/2504.02417
- **Reference count**: 40
- **Primary result**: Proposes TAMP model using dual graph for intra-type and heterogeneous graph for inter-type message passing, achieving 45.92% accuracy on ANetQA and 60.42% on Next-QA

## Executive Summary
This paper introduces the TAMP (Type-Aware Message Passing) framework for video question answering that leverages static relationships through dual and heterogeneous graph structures. The approach constructs a dual graph to enable relationship-centered learning for intra-type reasoning and a heterogeneous graph to capture inter-type interactions between objects and relationships. By employing question-guided message passing with iterative updates, the model effectively reasons about both within-class and between-class context. Experimental results demonstrate significant improvements over state-of-the-art models on two video QA datasets, with ablation studies confirming the importance of both intra-type and inter-type message passing components.

## Method Summary
The TAMP framework processes video frames using Faster R-CNN to extract top-80 objects with visual features, bounding boxes, and class labels. It constructs an initial graph connecting objects and their relationships, then transforms this into two complementary structures: a dual graph for intra-type reasoning (by converting relationships to nodes) and a heterogeneous graph for inter-type reasoning (by categorizing nodes and edges). Question-guided message passing iteratively updates node and edge representations over 3 iterations, with attention weights determined by question instructions. The dual branch outputs pd and the heterogeneous branch outputs ph, which are fused via weighted summation and passed through a classifier to predict answers.

## Key Results
- Achieves 45.92% accuracy on ANetQA, outperforming ClipBERT (44.05%), All-in-One (42.63%), and Video-Q (42.50%)
- Achieves 60.42% accuracy on Next-QA, significantly surpassing ClipBERT (55.13%) and STVQA (54.92%)
- Ablation study confirms both intra-type (1.6% gain) and inter-type (1.3% gain) message passing components are essential
- Performance peaks at exactly 3 iterations of message passing, with degradation observed at 4-5 iterations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Converting edges to nodes in a dual graph enables relationship-centered learning that captures semantic context among relationships sharing the same object.
- Mechanism: The dual graph Gα = {V, E} transforms relationships (originally edges) into nodes (V = {xi→j}), and objects (originally nodes) into edges (E). When two relationships xi→j and xk→l share the same object xi, they become connected nodes in the dual graph. This allows message passing within the relationship class to aggregate context from semantically related relationships.
- Core assumption: Relationships that share objects have meaningful semantic relationships with each other that benefit question answering.
- Evidence anchors:
  - [abstract]: "constructs a dual graph for intra-type message passing reasoning"
  - [section III.B]: "It not only maintains the structure of the original graph but also reverses the roles of nodes and edges, allowing the model to learn in a relationship-centered way across different video scenes"
  - [corpus]: Related work on graph message passing (XIMP, GSSMs) supports cross-graph reasoning but does not specifically validate dual graph transformation for video QA
- Break condition: When relationships sharing objects have no semantic connection, dual graph edges add noise; when video has few overlapping relationships, dual graph becomes sparse.

### Mechanism 2
- Claim: Type-specific message passing matrices in heterogeneous graphs enable specialized transformation behaviors for different relationship categories.
- Mechanism: The heterogeneous graph Gh = {V, E, U, R} assigns category labels to both nodes (U = Person, Non-Person) and edges (R = spatial, temporal, contact). Message passing uses type-specific weight matrices computed via basis decomposition (Ws2r = Σ αφ(xu→v)i Bi), allowing the model to learn distinct transformation behaviors per relationship type while sharing basis blocks for parameter efficiency.
- Core assumption: Different object and relationship types benefit from specialized, learnable transformation functions rather than shared weights.
- Evidence anchors:
  - [abstract]: "builds a heterogeneous graph based on static relationships for inter-type message passing reasoning"
  - [section III.E]: "Ws2rφ(u→v) represents the learnable weight matrix of relationship category φ(xu→v), and this matrix's calculation is inspired by the idea of basis decomposition"
  - [corpus]: XIMP validates cross-graph inter-message passing for molecular property prediction; weak direct evidence for heterogeneous graphs in video QA
- Break condition: When relationship categories are poorly defined or imbalanced, type-specific weights may overfit; when |U| + |R| ≤ 2, heterogeneous structure provides no benefit.

### Mechanism 3
- Claim: Iterative question-guided attention accumulates multi-hop reasoning paths with optimal depth at 3 iterations.
- Mechanism: At each iteration l, question instruction cl is computed via attention over question words (cl = Σ αl,z · hz). This instruction guides attention weights α(xj, q) and β(v, q) that determine which neighbors contribute to node/relationship updates. The iterative process (z(l+1) = z(l) + σ(Σ α·Wz(l))) accumulates reasoning paths over 3 hops before performance degrades.
- Core assumption: Question words provide discriminative guidance for selecting relevant visual relationships across multiple reasoning steps.
- Evidence anchors:
  - [abstract]: "question-guided message passing to update node and edge representations"
  - [section IV.D]: Ablation shows accuracy peaks at 3 iterations (45.92% ANetQA, 60.85% Next-QA), dropping to 44.73% and 59.81% at 5 iterations
  - [corpus]: Cross-Modal State-Space Graph Reasoning supports question-guided attention in multimodal summarization; Message-Passing State-Space Models validate iterative refinement benefits
- Break condition: When questions are ambiguous or don't reference specific objects/relationships, attention provides weak guidance; beyond 3 iterations, oversmoothing degrades node discriminability.

## Foundational Learning

- Concept: Dual Graph Transformation
  - Why needed here: Understanding how edge-to-node transformation enables relationship-centered message passing, which is the core innovation for intra-type reasoning.
  - Quick check question: Given objects A, B, C with relationships A→B and B→C, what are the nodes and edges in the dual graph?

- Concept: Basis Decomposition for Parameter Sharing
  - Why needed here: The heterogeneous graph uses basis decomposition to learn type-specific weights while avoiding parameter explosion across relationship categories.
  - Quick check question: If you have 3 basis blocks and 5 relationship types, how many learnable parameters does basis decomposition require versus learning independent weight matrices?

- Concept: Attention-Guided Message Passing
  - Why needed here: Question-guided attention determines which neighbors contribute to updates; understanding this is critical for debugging why certain objects are emphasized.
  - Quick check question: In equation α(xj, q) = exp(WT[h·z(l)xj; c(l)]) / Σ exp(...), what happens to attention weights when c(l) is orthogonal to all neighbor features?

## Architecture Onboarding

- Component map:
  - **Input Processing**: Video → Faster R-CNN (80 objects) → [visual vi, bbox bi, class ci] features; Question → BiLSTM → question embedding q
  - **Dual Graph Branch**: Initial graph G0 → edge-to-node transformation → dual graph G → 3 iterations intra-type message passing → pd
  - **Heterogeneous Graph Branch**: Initial graph G0 → type assignment (ϕ, φ functions) → heterogeneous graph Gh → 3 iterations inter-type message passing → ph
  - **Answer Prediction**: pd + ph → single-hop attention (λd, γh) → classifier → answer

- Critical path:
  1. Faster R-CNN detection quality (determines all downstream entities and relationships)
  2. Question instruction generation at each iteration (guides all attention weights)
  3. Exactly 3 message passing iterations (ablation-validated peak performance)
  4. Feature fusion λdpd + γhph (combines intra-type and inter-type clues)

- Design tradeoffs:
  - **Iteration count**: 3 iterations balance reasoning depth vs oversmoothing (4-5 iterations degrade accuracy 0.5-1.2%)
  - **Top-80 objects**: Limits computation but may miss rare objects relevant to long-tail questions
  - **Dual + heterogeneous graphs**: Doubles graph construction cost but provides complementary signals (ablation: 45.92% vs 44.32% intra-only vs 44.06% inter-only)
  - **Frozen ROIAlign layers**: Faster training but may limit object feature adaptation to QA task

- Failure signatures:
  - **Attribute questions underperform** (36.21% vs 40.14% All-in-One): suggests static relationship focus misses fine-grained visual attributes
  - **Action questions underperform** (73.39% vs 74.96% ClipBERT): indicates limited motion/dynamic modeling
  - **Similar object confusion** (raft↔river, table↔raft in Figure 7): suggests insufficient object discrimination or over-reliance on relationship context
  - **Training instability**: Monitor exponential moving average; if loss oscillates, reduce learning rate below 0.008

- First 3 experiments:
  1. **Validate Faster R-CNN recall**: Extract objects from 50 sample videos and compute recall against ground-truth annotated objects; if <70%, consider increasing top-k from 80 or fine-tuning detector
  2. **Replicate iteration ablation**: Train models with l=1,2,3,4,5 iterations on ANetQA validation split; confirm 3-iteration peak and document performance variance across random seeds
  3. **Visualize attention failure cases**: For incorrect predictions in Figure 7, plot attention weights α(xj, q) and question instruction c(l) to identify whether failure stems from poor question guidance or insufficient object features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can object attributes and dynamic events be effectively integrated into the TAMP framework to address current limitations in attribute and action-oriented question answering?
- Basis in paper: [explicit] The Conclusion states, "In future research, we can integrate target attributes and events into the existing framework," and the Qualitative Analysis mentions a focus on "integrating object attributes and events more deeply."
- Why unresolved: The current model relies on static relationship extraction, resulting in lower accuracy on attribute and action questions compared to baselines like All-in-One and ClipBERT.
- What evidence would resolve it: An extension of the TAMP model that includes attribute and event modules, demonstrating improved accuracy on "attribute" and "action" categories in the ANetQA dataset.

### Open Question 2
- Question: Does the effective representation of attributes and motion features have a positive correlation with the performance of the TAMP model?
- Basis in paper: [explicit] In the "Performance on ANetQA" section, the authors note: "future work of this method will verify whether the effective representation of attributes and motion has a positive correlation with the performance of TAMP."
- Why unresolved: The authors observed performance drops in these specific categories but did not empirically validate the correlation within their architectural constraints.
- What evidence would resolve it: A statistical analysis correlating the quality of attribute/motion feature representations with the final QA accuracy scores on relevant question types.

### Open Question 3
- Question: How can the static relationship modeling approach be adapted to better distinguish between visually similar objects (e.g., "raft" vs. "table") and handle dynamic scene transitions?
- Basis in paper: [inferred] The Qualitative Analysis (Fig. 7) highlights failures where the model confuses similar objects or misinterprets dynamic contexts (e.g., "raft" vs. "river"), suggesting the static graph structure lacks necessary discriminative power.
- Why unresolved: The reliance on static relationships via Faster R-CNN features appears insufficient for disambiguating fine-grained visual differences or rapid temporal changes.
- What evidence would resolve it: Improved qualitative results on the specific failure cases shown in Fig. 7, supported by higher accuracy on "verify" and "action" questions in the Next-QA dataset.

## Limitations
- The model's performance on attribute questions (36.21%) lags significantly behind overall accuracy, indicating limitations in fine-grained visual attribute reasoning
- Static relationship extraction via Faster R-CNN fails to capture dynamic motion features, resulting in underperformance on action questions compared to motion-aware baselines
- The dual graph transformation, while theoretically motivated, lacks direct empirical validation showing it is essential versus alternative relationship modeling approaches

## Confidence

- **High confidence**: The dual graph transformation mechanism for intra-type message passing (supported by ablation showing intra-type component contributes 1.6% accuracy gain)
- **Medium confidence**: The heterogeneous graph with basis decomposition for inter-type message passing (supported by citation network but limited direct video QA validation)
- **Medium confidence**: Question-guided attention with 3 iterations as optimal (validated by ablation but sensitive to dataset characteristics)

## Next Checks

1. **Mechanism isolation ablation**: Design controlled experiments that separately disable dual graph transformation, basis decomposition, and question-guided attention to quantify individual contribution of each mechanism to overall performance gains.

2. **Cross-dataset generalization**: Evaluate the model on additional video QA datasets (such as TGIF-QA or MarioQA) to assess whether accuracy gains generalize beyond ANetQA and Next-QA, particularly for attribute and action questions where current performance lags.

3. **Attention visualization and error analysis**: For a sample of incorrect predictions, generate attention weight visualizations and question instruction vectors to identify whether failures stem from poor question guidance, insufficient object features, or over-reliance on relationship context rather than object discrimination.