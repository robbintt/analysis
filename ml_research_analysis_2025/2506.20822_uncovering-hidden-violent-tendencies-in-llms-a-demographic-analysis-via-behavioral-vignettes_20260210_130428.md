---
ver: rpa2
title: 'Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral
  Vignettes'
arxiv_id: '2506.20822'
source_url: https://arxiv.org/abs/2506.20822
tags:
- llms
- violence
- violent
- social
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates six large language models (LLMs) on their
  responses to morally ambiguous conflict scenarios using the validated Violent Behavior
  Vignette Questionnaire (VBVQ). To assess potential bias, we introduced persona-based
  prompts varying race, age, and geographic identity in the United States.
---

# Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes

## Quick Facts
- arXiv ID: 2506.20822
- Source URL: https://arxiv.org/abs/2506.20822
- Reference count: 15
- Six LLMs show polite, nonviolent surface responses but reveal hidden violent tendencies through sequence likelihood analysis, especially under demographic variation.

## Executive Summary
This study evaluates large language models (LLMs) on their responses to morally ambiguous conflict scenarios using the validated Violent Behavior Vignette Questionnaire (VBVQ). By introducing persona-based prompts varying race, age, and geographic identity in the United States, the research uncovers a gap between surface-level alignment and internal tendencies. While LLMs consistently generate polite, nonviolent responses on the surface, sequence likelihood analysis reveals hidden violent tendencies, particularly under demographic variation. Notably, LLMs predict younger individuals (15 years old) as less likely to respond violently, contradicting criminological findings. These findings raise concerns about fairness and reliability in high-stakes violence detection applications.

## Method Summary
The study uses the Violent Behavior Vignette Questionnaire (VBVQ), a validated social science instrument containing 10 morally ambiguous conflict scenarios. Researchers created 1,080 persona-conditioned prompts by crossing 6 races, 6 US counties, and 3 ages (15/25/35) with the vignettes. Six LLMs were evaluated using zero-shot prompting with the instruction "Put yourself in this situation and answer as if you are a {Race}, {Age Group} from {Location}." Responses were evaluated through BERTScore F1 against reference categories and through sequence likelihood analysis with softmax-normalized Top-Rank Rates. Kruskal-Wallis tests identified demographic effects on semantic similarity scores.

## Key Results
- LLMs generated consistently polite, nonviolent responses on the surface across all demographic variations
- Sequence likelihood analysis revealed hidden violent tendencies, especially under demographic variation
- LLMs predicted younger individuals (15 years old) as less likely to respond violently, contradicting criminological findings
- Response patterns varied inconsistently by location and race, with some models showing politically correct overcorrection

## Why This Works (Mechanism)

### Mechanism 1: Sequence Likelihood Probing of Internal Preferences
Surface-level text generation diverges from internal token probability distributions, revealing latent response tendencies that alignment training suppresses but does not erase. The method computes softmax-normalized likelihoods over human-labeled response categories (PA/NV/VI) including paraphrased variants, then aggregates Top-Rank Rates to identify which response type the model probabilistically favors regardless of decoded output. Core assumption: Token-level log probabilities reflect internal preference rankings that survive instruction tuning.

### Mechanism 2: Persona-Conditioned Demographic Stress Testing
Varying demographic personas (race, age, geographic location) while holding vignette constant exposes inconsistent moral reasoning and embedded sociocultural biases. A fixed prompt template generates 1,080 unique persona-conditioned inputs across 10 vignettes; Kruskal-Wallis tests then identify statistically significant demographic effects on semantic similarity scores. Core assumption: Demographic tokens activate coherent internal representations of social groups.

### Mechanism 3: Validated Instrument Transfer from Social Science
The Violent Behavior Vignette Questionnaire (VBVQ), originally validated for human subjects, provides standardized morally ambiguous scenarios that elicit interpretable response distributions comparable to established criminological baselines. Ten everyday conflict vignettes with 10 response options ranging from passive to violent are presented under three formats; BERTScore against human-labeled reference categories quantifies semantic alignment. Core assumption: VBVQ validity transfers across populations and modalities.

## Foundational Learning

- Concept: Sequence likelihood / log-probability extraction from autoregressive models
  - Why needed here: The core diagnostic depends on accessing raw token probabilities before sampling
  - Quick check question: Given model output logits [2.1, -0.5, 1.3] for tokens A, B, C, what is the softmax probability of token A?

- Concept: Instruction tuning and alignment training objectives
  - Why needed here: The paper's central claim is that alignment suppresses but does not eliminate internal preferences
  - Quick check question: Why might an RLHF-tuned model generate "I would stay calm" while assigning higher likelihood to a confrontational response?

- Concept: BERTScore and semantic similarity for open-ended evaluation
  - Why needed here: Free-form responses require automated comparison to reference categories
  - Quick check question: Why use a model fine-tuned on MNLI for semantic similarity rather than raw embedding cosine similarity?

## Architecture Onboarding

- Component map: VBVQ vignette dataset (10 scenarios) -> Persona prompt template (6 races × 3 ages × 6 locations) -> LLM inference (5 models, temperature 0.7, 5 samples per prompt) -> Output branches: (1) Categorical selection, (2) Open-text generation -> BERTScore against PA/NV/VI references, (3) Log-prob extraction -> Softmax normalization -> Top-Rank Rate aggregation -> Kruskal-Wallis significance testing per demographic dimension

- Critical path: Log-probability extraction is the bottleneck; GPT-4o-mini was excluded because its API does not expose token-level logits

- Design tradeoffs: Paraphrased reference variants increase semantic coverage but introduce LLM-generated noise; temperature 0.7 enables response diversity but complicates reproducibility; zero-shot setting avoids prompt engineering contamination but may underutilize model capacity

- Failure signatures:
  1. Inconsistent location patterns across models with no coherent signal suggests insufficient geographic knowledge
  2. Age inversions (15-year-olds rated less violent than 25/35-year-olds) indicate safety overcorrection
  3. High Top-Rank Rate for VI with low BERTScore alignment indicates likelihood-output decoupling

- First 3 experiments:
  1. Replicate Top-Rank Rate computation on a single vignette with fixed persona to verify log-prob extraction pipeline
  2. Ablate paraphrased references (use human labels only) on one model to quantify semantic noise contribution
  3. Test a new demographic dimension (e.g., gender) on two models to validate whether methodology generalizes

## Open Questions the Paper Calls Out

### Open Question 1
How does LLM performance on violence detection compare between hypothetical vignettes and real-world social media data? The authors state the next step is to "take real world social media posts and create similar vignettes to assess the response to a real world situation." This remains unresolved because the current study relied on the VBVQ, a validated but hypothetical instrument.

### Open Question 2
To what extent does the use of community-specific slang and terminology affect LLMs' ability to accurately interpret violent intent? The authors note the need to "create vignettes with the help of teenagers and young adults to include vignettes that utilize important slang terms." This remains unresolved because the current vignettes may lack the linguistic markers specific to youth demographics in the US.

### Open Question 3
What mechanistic factors cause the observed divergence between polite surface-level text generation and hidden violent sequence likelihoods? The authors conclude that "future work should examine the gap between hidden tendencies and surface-level alignment." This remains unresolved because it is unclear if instruction tuning simply camouflages pre-training biases or if the models are engaging in distinct reasoning processes.

## Limitations

- Instrument Validity Transfer: VBVQ was validated on Canadian offenders, raising uncertainty about cultural generalization to US demographics
- API Access Constraints: GPT-4o-mini excluded due to token-level probability extraction limitations, creating model coverage gaps
- Semantic Reference Quality: Reliance on LLM-generated paraphrases introduces potential semantic drift and reference noise

## Confidence

**High Confidence**: The methodological framework for comparing surface outputs (BERTScore alignment) with internal preferences (Top-Rank Rate from log-probabilities) is technically sound and well-specified.

**Medium Confidence**: The claim that LLMs exhibit "hidden violent tendencies" revealed through likelihood analysis is supported by the methodology but requires careful interpretation.

**Low Confidence**: The criminological interpretation of age effects (15-year-olds rated less violent than 25/35-year-olds contradicting established findings) requires stronger validation.

## Next Checks

1. **Cross-Cultural Vignette Validation**: Test the same VBVQ vignettes on models fine-tuned with US-specific data to assess whether observed demographic patterns persist when cultural context aligns with the prompt geography.

2. **Human Baseline Replication**: Administer the VBVQ vignettes to human subjects across the same demographic dimensions to establish whether LLM response patterns meaningfully diverge from human moral reasoning.

3. **Safety Filter Ablation Test**: Compare Top-Rank Rate distributions between models with known safety training differences (base vs. instruction-tuned versions) on identical vignettes to determine whether likelihood discrepancies primarily reflect safety alignment versus genuine moral reasoning differences.