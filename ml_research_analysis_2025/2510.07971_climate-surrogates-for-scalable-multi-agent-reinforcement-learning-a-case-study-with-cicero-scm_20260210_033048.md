---
ver: rpa2
title: 'Climate Surrogates for Scalable Multi-Agent Reinforcement Learning: A Case
  Study with CICERO-SCM'
arxiv_id: '2510.07971'
source_url: https://arxiv.org/abs/2510.07971
tags:
- country
- climate
- surrogate
- policy
- marl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a framework that replaces the climate module
  of a multi-agent reinforcement learning (MARL) climate policy game with a fast,
  learned surrogate of the high-fidelity CICERO-SCM model. To do so, it generates
  20,000 perturbed multi-gas emission pathways, trains three RNN variants (LSTM, GRU,
  TCN) on 1.22 million samples, and evaluates them in a MARL climate-mitigation setting.
---

# Climate Surrogates for Scalable Multi-Agent Reinforcement Learning: A Case Study with CICERO-SCM
## Quick Facts
- arXiv ID: 2510.07971
- Source URL: https://arxiv.org/abs/2510.07971
- Reference count: 40
- Key outcome: Surrogate climate model achieves near-simulator accuracy and >100× end-to-end speedups in MARL climate policy games.

## Executive Summary
This study introduces a framework that replaces the climate module of a multi-agent reinforcement learning (MARL) climate policy game with a fast, learned surrogate of the high-fidelity CICERO-SCM model. By training RNN variants (LSTM, GRU, TCN) on 1.22 million samples from 20,000 perturbed emission pathways, the surrogate achieves near-simulator accuracy (RMSE ≈ 0.0004 K, R² ≈ 0.99) and is ~1000× faster per step. In MARL training, this translates into >100× end-to-end speed-ups while preserving policy consistency: policies learned with the surrogate match those learned with the simulator in both tractable 4-agent and intractable 10-agent scenarios.

## Method Summary
The method involves generating 20,000 perturbed multi-gas emission pathways and training three RNN variants (LSTM, GRU, TCN) on 1.22 million samples to approximate CICERO-SCM's temperature response. The surrogate is then integrated into a MARL climate-mitigation game. The approach leverages the surrogate's speed to enable large-scale MARL experiments that were previously computationally prohibitive, while validating policy consistency against the full simulator where tractable.

## Key Results
- Surrogate achieves near-simulator accuracy (RMSE ≈ 0.0004 K, R² ≈ 0.99)
- Surrogate is ~1000× faster per step than CICERO-SCM
- MARL training with surrogate yields >100× end-to-end speedups while preserving policy consistency

## Why This Works (Mechanism)
The framework works by decoupling the computationally expensive climate simulation from the MARL training loop. The surrogate, trained on extensive perturbed emission pathways, captures the essential dynamics of CICERO-SCM with high fidelity. This allows the MARL agents to explore and learn policies in a climate environment that is both fast and accurate, enabling experiments at scales that would be infeasible with the full simulator.

## Foundational Learning
- **CICERO-SCM**: Simple Climate Model used for policy analysis; needed for generating training data and ground truth; quick check: reproduces IPCC-style projections
- **MARL climate policy games**: Multi-agent RL setups for climate mitigation; needed for testing surrogate in realistic decision-making contexts; quick check: agents learn to balance emissions and warming
- **RNN surrogates (LSTM, GRU, TCN)**: Sequence models for approximating climate dynamics; needed for fast, differentiable climate predictions; quick check: low RMSE on held-out data

## Architecture Onboarding
- **Component map**: Emission paths → Surrogate RNN → Temperature forecasts → MARL agents → Policy actions
- **Critical path**: Surrogate inference during MARL training loop
- **Design tradeoffs**: Accuracy vs. speed; model complexity vs. generalization
- **Failure signatures**: Surrogate divergence under out-of-distribution emissions; policy degradation in MARL
- **First experiments**: 1) Validate surrogate on held-out emission pathways; 2) Compare MARL policies with/without surrogate; 3) Stress-test surrogate with extreme emission scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Surrogate generalization to radically different forcing scenarios is untested
- MARL experiments use stylized emission controls, not real-world policy levers
- No explicit uncertainty quantification for surrogate's policy impact estimates

## Confidence
- Surrogate accuracy: High (RMSE ≈ 0.0004 K, R² ≈ 0.99)
- Policy consistency (4-agent): Medium-high
- Policy consistency (10-agent): Medium (intractability with full simulator limits validation)

## Next Checks
1. Test surrogate performance on out-of-distribution emission pathways (e.g., abrupt policy shifts or extreme forcings) to assess robustness.
2. Quantify and propagate surrogate prediction uncertainty through the MARL training pipeline.
3. Compare MARL policy outcomes with those from a well-established climate-economic integrated assessment model (e.g., DICE or FUND) to validate real-world relevance.