---
ver: rpa2
title: 'Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature
  Alignment'
arxiv_id: '2503.09774'
source_url: https://arxiv.org/abs/2503.09774
tags:
- merging
- gw-smm
- accuracy
- task
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GW-SMM, a novel approach to model merging
  that leverages the Gromov-Wasserstein distance to align feature distributions across
  multiple automated scoring models. The method addresses the challenge of deploying
  separate neural networks for each assessment task, which increases storage demands
  and computational costs in educational settings.
---

# Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature Alignment

## Quick Facts
- arXiv ID: 2503.09774
- Source URL: https://arxiv.org/abs/2503.09774
- Authors: Luyang Fang; Ehsan Latif; Haoran Lu; Yifan Zhou; Ping Ma; Xiaoming Zhai
- Reference count: 40
- One-line primary result: GW-SMM reduces storage requirements by half while improving automated scoring accuracy through principled model merging.

## Executive Summary
This paper addresses the computational burden of deploying separate neural networks for each automated scoring task in educational settings. The proposed GW-SMM approach uses Gromov-Wasserstein distance to quantify similarity between feature distributions across multiple pre-trained scoring models, enabling intelligent selection of compatible models for merging. By combining only shared layers while preserving separate classification heads, GW-SMM achieves significant storage reduction (50%) without compromising accuracy, demonstrating superior performance compared to GPT-o1-based merging with statistically significant improvements in key metrics.

## Method Summary
GW-SMM extracts [CLS] token embeddings from fine-tuned BERT-base models on their respective assessment tasks, then computes pairwise Gromov-Wasserstein distances to quantify structural similarity between feature distributions. The method identifies the most compatible models (typically pairs or trios) based on smallest distances, then merges them using the TIES-MERGING framework. This framework computes task vectors (fine-tuned minus pre-trained weights), prunes conflicting parameters, and combines shared backbones while maintaining separate classification heads for each task's unique scoring requirements.

## Key Results
- Achieved higher micro F1 score (0.6872 vs 0.6271) compared to GPT-o1-based merging
- Demonstrated statistically significant improvements in micro F1 (p=0.04) and per-label accuracy (p=0.01)
- Reduced storage requirements by 50% without significant accuracy loss
- Maintained better macro F1 score (0.5414 vs 0.4895) and exact match accuracy (0.5419 vs 0.4883)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GW distance provides principled, data-driven model selection compared to human intuition or task descriptions
- Core assumption: Structural similarity of feature representations reliably indicates parameter compatibility
- Evidence: GW distance compares distributions even when they reside in different latent spaces, identifying clusters of structurally similar models
- Break condition: Feature similarity may not correlate with parameter compatibility, causing poor merged model performance

### Mechanism 2
- Claim: TIES-MERGING reduces destructive interference through pruning conflicting parameters
- Core assumption: Task-specific knowledge is encoded in sparse parameters that can be isolated and integrated
- Evidence: Pruning redundant or conflicting parameters within task vectors preserves essential task-specific information
- Break condition: Aggressive pruning may remove critical nuances, or tasks may be fundamentally incompatible

### Mechanism 3
- Claim: Separate classification heads preserve item-specific scoring accuracy
- Core assumption: Feature extraction knowledge is more transferable than classification decision boundaries
- Evidence: Unified feature extractor benefits from broader data while separate heads maintain task-specific scoring
- Break condition: Merged backbone may become poor feature extractor due to averaging effects

## Foundational Learning

- **Optimal Transport & Gromov-Wasserstein Distance**: GW measures cost of aligning two distributions based on internal geometry rather than direct point-to-point distance. Quick check: How does GW distance differ from Euclidean distance between feature means?

- **Task Arithmetic & Model Merging**: Model merging operates on task vectors (fine-tuned weights minus pre-trained weights). Quick check: What constitutes a "task vector" in this context?

- **Multi-Label Classification with Transformers (BERT)**: BERT models process text into embeddings using classification heads for multiple rubric dimensions. Quick check: Why use multi-label classification for scoring student responses?

## Architecture Onboarding

- **Component map**: Feature Extractor -> GW-Similarity Engine -> Merging Planner -> Merger (TIES-MERGING)

- **Critical path**: 
  1. Extract [CLS] embeddings from fine-tuned models
  2. Compute pairwise GW distances with entropic regularization
  3. Convert distances to similarities and determine optimal grouping
  4. Apply TIES-MERGING to produce merged models with separate heads

- **Design tradeoffs**: 
  - Storage vs. Accuracy: More merging saves space but risks accuracy loss
  - GW vs. Human Knowledge: Data-driven approach vs. semantic task understanding
  - Parameter Pruning Level: Balances interference removal with knowledge preservation

- **Failure signatures**: 
  - Performance collapse indicating incompatible models forced together
  - High GW distance with good performance suggesting metric limitations
  - Merged backbone becoming poor feature extractor

- **First 3 experiments**:
  1. Replicate pairwise GW distance calculation to verify similarity matrix
  2. Implement baseline merge (parameter averaging) for most/least similar pairs
  3. Fine-tune merged models on combined data to test recovery potential

## Open Questions the Paper Calls Out
None

## Limitations
- Implementation details of TIES-MERGING framework remain unclear
- GW distance computation relies on unspecified hyperparameters
- Limited comparison to other model merging baselines
- Focus on specific educational assessment domain with small datasets

## Confidence

**High Confidence**: Separate classification heads architecture is clearly specified and standard in multi-task learning.

**Medium Confidence**: GW distance for model selection combined with TIES-MERGING methodology is sound but implementation details are unclear.

**Low Confidence**: Claim that GW distance provides superior selection over human intuition needs further validation.

## Next Checks

1. Replicate GW similarity matrix computation on the provided dataset to verify model grouping decisions.

2. Develop complete TIES-MERGING implementation with specified pruning thresholds and test merging most/least compatible pairs.

3. Evaluate GW-SMM performance against standard merging approaches (parameter averaging, adapters) and individual fine-tuning.