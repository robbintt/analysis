---
ver: rpa2
title: A Hybrid Multi-Agent Prompting Approach for Simplifying Complex Sentences
arxiv_id: '2506.11681'
source_url: https://arxiv.org/abs/2506.11681
tags:
- sentences
- rabbit
- sentence
- when
- simplification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a hybrid multi-agent prompting approach to
  transform complex sentences into simplified, executable instructions while preserving
  semantic integrity. The method uses three specialized LLM agents: one for decomposition,
  one for semantic/lexical evaluation, and one for iterative revision.'
---

# A Hybrid Multi-Agent Prompting Approach for Simplifying Complex Sentences

## Quick Facts
- **arXiv ID**: 2506.11681
- **Source URL**: https://arxiv.org/abs/2506.11681
- **Reference count**: 24
- **Primary result**: Multi-agent approach achieves 70% simplification success rate vs 48% for single-agent baseline

## Executive Summary
This paper proposes a hybrid multi-agent prompting approach to transform complex sentences into simplified, executable instructions while preserving semantic integrity. The method uses three specialized LLM agents: one for decomposition, one for semantic/lexical evaluation, and one for iterative revision. Evaluated on 100 sentences from a video game design dataset, the approach successfully simplified 70% of complex sentences, outperforming a single-agent baseline at 48%. Simplified sentences enabled more accurate code generation in game engines, though general-purpose LLMs still struggled with highly constrained descriptions.

## Method Summary
The hybrid multi-agent system employs three specialized LLM agents working sequentially: Agent 1 decomposes complex sentences into cause-action sequences using meta-instruction prompting with chain-of-thought reasoning; Agent 2 evaluates semantic similarity (>95% threshold) and lexical similarity (≤40% threshold) to validate transformation quality; Agent 3 is invoked only when Agent 2 reports semantic score <95%, applying rule-guided transformations for temporal and mathematical logic. The system uses a threshold-based quality gating mechanism where outputs are accepted only if semantic similarity exceeds 95% and lexical similarity remains below 40%.

## Key Results
- Multi-agent approach simplified 70% of complex sentences vs 48% for single-agent baseline
- Simplified sentences enabled more accurate code generation in game engines
- General-purpose LLMs struggled with highly constrained descriptions despite improved clarity
- Abstract actions (e.g., "try to make sure") and ambiguous roles caused system failures

## Why This Works (Mechanism)

### Mechanism 1: Role-Based Specialization in Multi-Agent Architectures
Distributing simplification tasks across specialized agents improves decomposition quality compared to single-agent prompting. Three agents operate sequentially: (1) Agent 1 decomposes complex sentences into cause-action sequences using meta-instruction prompting with chain-of-thought; (2) Agent 2 evaluates semantic similarity (>95% threshold) and lexical similarity (≤40% threshold) to validate transformation quality; (3) Agent 3 is invoked only when Agent 2 reports semantic score <95%, applying rule-guided transformations for temporal and mathematical logic.

### Mechanism 2: Threshold-Based Quality Gating with Semantic and Lexical Scores
Combining semantic similarity (>95%) and lexical similarity (≤40%) thresholds effectively filters acceptable simplifications while rejecting near-identical outputs. Agent 2 computes two independent similarity metrics. High semantic score ensures meaning preservation; low lexical score confirms structural transformation occurred. If semantic >95 AND lexical ≤40, output is accepted. If semantic >95 AND lexical >95, classified as "cannot convert" (no transformation needed).

### Mechanism 3: Hybrid Prompting Combining Chain-of-Thought with Meta-Prompting
Combining chain-of-thought reasoning with meta-prompting and directional stimulus prompting improves handling of temporal dynamics and mathematical conditional logic. Agent 1 uses meta-instruction-based prompts with explicit "Let's think step by step" reasoning to decompose sentences into cause-action pairs. Agent 3 integrates directional stimulus prompting, meta-prompting, and CoT to handle specialized cases involving temporal triggers, rate calculations, and conditional arithmetic operations.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) Prompting**
  - Why needed here: Both Agent 1 and Agent 3 rely on CoT to decompose complex sentences into sequential reasoning steps. Understanding how to design effective CoT prompts is essential for modifying or extending the simplification agents.
  - Quick check question: Can you explain why "Let's think step by step" improves decomposition of "When a fox sees the rabbit touch a carrot, it chases it until the rabbit moves"?

- **Concept: Multi-Agent Role-Based Architecture**
  - Why needed here: The system's effectiveness depends on properly defining agent roles, coordination patterns, and interaction strategies. Engineers need to understand when to add new agents versus modifying existing ones.
  - Quick check question: What would happen if you merged Agent 1 and Agent 3 into a single agent with combined prompts?

- **Concept: Semantic vs. Lexical Similarity Metrics**
  - Why needed here: The quality gating mechanism depends on correctly interpreting and calibrating these thresholds. Misunderstanding their meanings could lead to accepting poor simplifications or rejecting valid ones.
  - Quick check question: Why does a high lexical similarity score (>95) with high semantic similarity indicate a "cannot convert" case rather than a successful simplification?

## Architecture Onboarding

- **Component map**: Input sentence → Agent 1 decomposition → Agent 2 evaluation → Comparator decision → (if rejected) Agent 3 revision → Agent 2 re-evaluation → Output or "cannot convert" classification
- **Critical path**: Input sentence flows through sequential agent processing with threshold-based gating determining whether to accept, reject, or trigger revision
- **Design tradeoffs**:
  - Modularity vs. latency: Three-agent sequential pipeline improves quality but increases inference time and cost compared to single-agent approach
  - Specialization vs. generalization: Agent 3's rule-guided transformations handle mathematical/temporal cases well but may miss patterns outside its designed scope
  - Threshold precision vs. recall: The 95/40 thresholds prioritize high-quality simplifications (70% success) at the cost of rejecting some potentially valid transformations
- **Failure signatures**:
  - Abstract action failures: Sentences with "try to," "make sure," or intent-based verbs produce uninterpretable outputs
  - Ambiguous actor failures: Sentences lacking clearly defined main player or subject cause simplification breakdown
  - Over-constraint in downstream code generation: Simplified sentences with many explicit constraints overwhelm general-purpose LLMs during code generation, though domain-specific engines handle them better
- **First 3 experiments**:
  1. Baseline replication: Run the single-agent approach (Agent 1 only) on the 100-sentence dataset to confirm the 48% success rate and identify which sentence types fail most frequently
  2. Threshold sensitivity analysis: Vary the semantic threshold (90%, 95%, 98%) and lexical threshold (30%, 40%, 50%) to understand impact on success rate and output quality
  3. Agent 3 ablation: Disable Agent 3 and analyze which sentence categories (conditional, sequential, miscellaneous) show the largest performance degradation, validating the multi-agent benefit claim

## Open Questions the Paper Calls Out

### Open Question 1
How can the multi-agent framework be adapted to successfully simplify sentences containing abstract actions or ambiguous roles? The authors identify "abstract actions or ambiguous roles" as a key challenge, noting the system fails to interpret words like "try" and convert them into concrete game actions. This remains unresolved because the current prompting strategy relies on explicit cause-and-effect decomposition, which lacks mechanisms for resolving intent behind subjective or non-deterministic verbs.

### Open Question 2
To what extent does the prompt design overfit to the video game domain, and can it generalize to other sentence structures? The conclusion states that the "current prompt design is closely tied to the dataset, which can lead to overfitting," and suggests future work must address "more diverse sentence structures." This is unresolved because the prompts were iteratively refined specifically for the GameChangineer application, potentially creating a dependency on that specific logic structure.

### Open Question 3
Does the increased constraint count in simplified sentences negatively impact the code generation accuracy of general-purpose LLMs? The authors observe that while simplified sentences reduce ambiguity, they "increases the number of constraints," and general-purpose LLMs often struggle when descriptions contain "too many constraints." It is unclear if the "simplification" trades one problem (linguistic complexity) for another (procedural verbosity) for general models.

## Limitations

- **Generalizability concerns**: The 70% success rate on a video game design dataset with 100 sentences may not extend to other domains or sentence types
- **Threshold calibration uncertainty**: The 95% semantic similarity and 40% lexical similarity thresholds were determined empirically but without systematic exploration of alternative values
- **Evaluation method limitations**: The paper relies on LLM-based semantic similarity evaluation rather than human judgment for the 70% success metric

## Confidence

**High Confidence**: The core finding that multi-agent architectures outperform single-agent approaches for sentence simplification (70% vs 48% success rates) is well-supported by the experimental results.

**Medium Confidence**: The effectiveness of the threshold-based quality gating mechanism (semantic >95% AND lexical ≤40%) is demonstrated but may be domain-specific.

**Low Confidence**: Claims about the general applicability of this approach to other types of complex natural language instructions beyond game design scenarios.

## Next Checks

1. **Cross-Domain Validation**: Apply the same three-agent architecture to a different domain (e.g., legal text simplification or technical documentation) with at least 100 sentences to test whether the 70% success rate generalizes beyond game design instructions.

2. **Threshold Sensitivity Analysis**: Systematically vary the semantic similarity threshold (90%, 95%, 98%) and lexical similarity threshold (30%, 40%, 50%) across the full dataset to quantify the impact on success rate, precision, and recall.

3. **Human Evaluation Comparison**: Conduct blind human evaluation of a random sample of 50 simplified sentences (25 accepted, 25 rejected by the system) to compare LLM-based similarity scores against human judgments of semantic preservation and simplification quality.