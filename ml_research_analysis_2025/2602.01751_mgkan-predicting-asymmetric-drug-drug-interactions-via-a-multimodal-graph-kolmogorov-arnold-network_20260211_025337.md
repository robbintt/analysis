---
ver: rpa2
title: 'MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph
  Kolmogorov-Arnold Network'
arxiv_id: '2602.01751'
source_url: https://arxiv.org/abs/2602.01751
tags:
- network
- drug
- mgkan
- asymmetric
- fusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MGKAN is a Graph Kolmogorov-Arnold Network that addresses asymmetric\
  \ drug-drug interaction prediction by integrating three network views\u2014an asymmetric\
  \ DDI network, a co-interaction network, and a biochemical similarity network\u2014\
  with direction-aware message passing. By replacing conventional MLPs with KAN-driven\
  \ basis functions, MGKAN captures nonlinear, role-specific patterns more effectively."
---

# MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network

## Quick Facts
- arXiv ID: 2602.01751
- Source URL: https://arxiv.org/abs/2602.01751
- Reference count: 0
- Primary result: AUROC scores of 99.08 and 98.09 on two DrugBank datasets for specific-direction DDI prediction

## Executive Summary
MGKAN introduces a Graph Kolmogorov-Arnold Network architecture for predicting asymmetric drug-drug interactions. The model integrates three network views—an asymmetric DDI network, co-interaction network, and biochemical similarity network—with direction-aware message passing. By replacing conventional MLPs with KAN-driven basis functions, MGKAN captures nonlinear, role-specific patterns more effectively. The model outperforms seven state-of-the-art baselines, achieving exceptional performance on two benchmark DrugBank datasets.

## Method Summary
MGKAN constructs three network views: an asymmetric DDI network for direct interactions, a co-interaction network capturing second-order topological relations, and a biochemical similarity network based on drug targets, enzymes, and transporters. Each view is processed through a GKAN encoder that uses learnable B-spline basis functions with direction-aware message passing (separating source and target embeddings). The three resulting embeddings are fused through an attention-based linear fusion combined with KAN-based nonlinear fusion, then passed through a bilinear decoder to predict directed interactions. The model is trained with binary cross-entropy loss using 1:1 negative sampling on transductive link prediction splits.

## Key Results
- Achieves AUROC of 99.08 and 98.09 on DS1 and DS2 for specific-direction prediction
- AUPRC scores of 98.94 and 97.62 demonstrate strong performance on imbalanced data
- Ablation studies confirm KAN-based fusion module and multi-view architecture are critical contributors
- Outperforms seven state-of-the-art baselines including DGAT-DDI and DRGATAN

## Why This Works (Mechanism)

### Mechanism 1
Replacing conventional MLPs with KAN-driven learnable basis functions enables more expressive nonlinear modeling of drug relationships than fixed activation functions. KAN uses B-spline basis functions with learnable coefficients ck that transform messages before aggregation, allowing the network to adapt the shape of nonlinearities during training rather than relying on fixed activations like ReLU or SiLU.

### Mechanism 2
Multi-view network construction captures complementary structural and biochemical information that no single view provides alone. Three views—(1) asymmetric DDI network for direct interactions, (2) co-interaction network for higher-order topological relations, (3) biochemical similarity network for semantic features—are encoded separately then fused.

### Mechanism 3
Direction-aware message passing with separate source and target embeddings preserves asymmetric semantics that symmetric aggregation destroys. For each drug, out-neighbor aggregation produces source embedding SN, in-neighbor aggregation produces target embedding TN; these are kept separate through fusion and combined via bilinear decoder.

## Foundational Learning

- **Message Passing in Directed Graphs**: MGKAN distinguishes out-neighbors (drugs the source affects) from in-neighbors (drugs affecting the target); standard undirected GNN aggregations cannot capture this. Quick check: Given a directed edge A→B, which node's embedding should incorporate information about this edge when computing A's source role vs. A's target role?

- **B-spline Basis Functions**: KAN replaces fixed activations with weighted sums of B-spline bases; understanding how ck coefficients control the shape of ϕ(·) is essential for debugging learning dynamics. Quick check: If all learned ck are near zero except one, what happens to the expressivity of the KAN layer?

- **Asymmetric vs. Symmetric DDI Prediction**: Task 1 (specific-direction) predicts whether u→v exists; Task 2 (asymmetric-direction) classifies among u→v, v→u, or none—different evaluation protocols require different interpretations. Quick check: If a model achieves 95% accuracy on symmetric DDI prediction, can you directly compare this to asymmetric-direction accuracy? Why or why not?

## Architecture Onboarding

- **Component map**: Drug features X → GKAN encoder on asymmetric DDI network → SN, TN; GKAN encoder on co-interaction networks → SC, TC; GKAN encoder on similarity network → ZS; Attention-based fusion + KAN-based nonlinear fusion → final S, T; Bilinear decoder → probability ŷ(u→v)

- **Critical path**: Feature extraction → direction-aware GKAN encoding on all three views → fusion module combining attention and KAN → bilinear scoring. The KAN layers in both encoding and fusion are the primary innovation.

- **Design tradeoffs**: Expressivity vs. overfitting: KAN's learnable basis functions increase capacity but require sufficient training data; the paper uses DrugBank datasets with 1:1 negative sampling—verify data scale before deploying on smaller datasets. Multi-view vs. complexity: Three views require three separate GKAN encoders; ablation suggests all contribute, but computational cost scales linearly with views. Transductive setting: Paper uses transductive split (all nodes visible during training); inductive deployment for new drugs requires retraining or architecture modification.

- **Failure signatures**: If AUROC is high but AUPRC is low: Check negative sampling ratio; 1:1 may not reflect real DDI sparsity. If w/o KAN variant matches full MGKAN: Dataset may be too small or too simple to benefit from KAN expressivity. If asymmetric-direction task fails but specific-direction succeeds: Direction distinction may not be well-represented in the data; inspect edge direction annotations.

- **First 3 experiments**: 1) Reproduce ablation on one dataset: Train MGKAN and w/o KAN variant on DS1; confirm that KAN removal causes measurable AUROC drop. 2) Vary negative sampling ratio: Test 1:1 vs. 1:3 vs. 1:10 negative-to-positive ratios; observe whether high AUROC masks precision issues at higher sparsity. 3) Single-view baseline: Train using only asymmetric DDI network (no co-interaction, no similarity); quantify contribution of multi-view architecture vs. KAN alone.

## Open Questions the Paper Calls Out

### Open Question 1
How can MGKAN be extended to multi-relation DDI prediction where interactions have multiple semantic types (e.g., pharmacokinetic vs. pharmacodynamic) rather than binary directionality? The conclusion states: "Future work will extend MGKAN to multi-relation DDI prediction and incorporate richer drug modalities." This requires architectural changes to handle multi-label or hierarchical relation classification.

### Open Question 2
What richer drug modalities beyond targets, enzymes, and transporters could enhance MGKAN's predictive accuracy? The conclusion explicitly calls for "incorporat[ing] richer drug modalities." Molecular structures (SMILES, 2D/3D graphs), side-effect profiles, and gene expression signatures remain unexplored integration candidates.

### Open Question 3
Does MGKAN generalize to DDI databases beyond DrugBank with different interaction coverage and sparsity patterns? The paper evaluates only DS1 and DS2 from DrugBank; no external validation on databases like TWOSIDES, OFFSIDES, or clinically-oriented DDI sources is reported.

### Open Question 4
Can the learned KAN basis functions provide interpretable insights into the biological mechanisms underlying asymmetric DDIs? The paper emphasizes KAN's "learnable basis functions" for nonlinear modeling but does not analyze what patterns these functions capture or whether they align with known pharmacological mechanisms.

## Limitations

- KAN's learnability advantage may not generalize to smaller or noisier DDI datasets where overfitting becomes a concern
- Transductive evaluation setting provides upper bound performance but doesn't guarantee inductive capability for new drugs
- 1:1 negative sampling ratio may not reflect real-world DDI sparsity and could inflate performance metrics

## Confidence

- **High confidence**: Multi-view architecture contribution; direction-aware message passing; bilinear decoder design
- **Medium confidence**: KAN-driven fusion module effectiveness; biochemical similarity network construction
- **Low confidence**: Generalization to inductive settings; performance under realistic negative sampling ratios; robustness to noisy or incomplete drug feature data

## Next Checks

1. **Ablation on negative sampling ratio**: Train MGKAN with 1:1, 1:3, and 1:10 negative-to-positive ratios to assess AUROC/AUPRC stability and determine if high AUROC masks precision issues under realistic sparsity.

2. **Inductive capability test**: Hold out a subset of drugs completely during training and evaluate MGKAN's ability to predict DDIs involving unseen drugs, comparing to transductive performance.

3. **Single-view + KAN vs. multi-view + MLP**: Train a single asymmetric DDI network with KAN fusion against the full multi-view MGKAN to isolate whether multi-view architecture or KAN mechanism drives the primary performance gains.