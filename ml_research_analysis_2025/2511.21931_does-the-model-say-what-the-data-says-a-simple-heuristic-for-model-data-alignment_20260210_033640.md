---
ver: rpa2
title: Does the Model Say What the Data Says? A Simple Heuristic for Model Data Alignment
arxiv_id: '2511.21931'
source_url: https://arxiv.org/abs/2511.21931
tags:
- data
- feature
- causal
- methods
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a simple, computationally efficient framework
  to evaluate whether machine learning models align with the underlying data structure
  they learn from. The approach draws inspiration from Rubin's Potential Outcomes
  Framework to quantify how strongly each feature separates two outcome groups in
  binary classification, providing a data-derived baseline for feature importance.
---

# Does the Model Say What the Data Says? A Simple Heuristic for Model Data Alignment

## Quick Facts
- arXiv ID: 2511.21931
- Source URL: https://arxiv.org/abs/2511.21931
- Authors: Henry Salgado; Meagan R. Kendall; Martine Ceberio
- Reference count: 20
- Primary result: Framework quantifies model-data alignment via rank correlation between data-derived SMD rankings and model-based feature importance (Spearman's ρ: 0.607–0.952)

## Executive Summary
This paper introduces a computationally efficient framework to assess whether machine learning models align with the underlying data structure they learn from. The approach computes standardized mean differences (SMD) for each feature to create a data-derived baseline ranking of discriminative power in binary classification tasks. This baseline is then compared against model-based feature importance rankings from decision trees and SHAP values using Spearman's rank correlation. Experimental results show moderate to strong alignment between data-level and model-level feature importance rankings, with correlation values ranging from 0.607 to 0.952 across two datasets. The method provides a scalable diagnostic tool for practitioners to validate model behavior against data-driven patterns.

## Method Summary
The framework computes standardized mean differences for each feature in binary classification by partitioning data by outcome class, calculating means and variances within each class, and normalizing by pooled standard deviation. Features are ranked by absolute SMD magnitude to create a data-derived baseline. This ranking is compared against model-based feature importance rankings from decision trees (information gain) and neural networks (SHAP values) using Spearman's rank correlation. The approach is designed for binary classification with preprocessing including median imputation, categorical encoding, and standardization for neural networks.

## Key Results
- Moderate to strong alignment between data-level and model-level feature importance rankings (Spearman's ρ: 0.607–0.952)
- Decision tree and SHAP explanations show consistent alignment patterns with SMD-derived rankings
- Lower alignment on Titanic dataset (ρ ≈ 0.6) attributed to models capturing non-linear interactions not visible in univariate SMD
- Strong alignment on Diabetes dataset (ρ ≈ 0.95) indicates models prioritize features with clear univariate separation

## Why This Works (Mechanism)

### Mechanism 1: Data-Derived Baseline via Standardized Mean Difference
Computing standardized mean differences for each feature provides a model-agnostic baseline ranking of discriminative power that can be compared against model explanations. For binary classification, the method partitions data by outcome class, computes mean and variance for each feature within each class, then calculates the difference between class means normalized by pooled standard deviation. Features are ranked by absolute SMD magnitude. Core assumption: Features with larger univariate separation between outcome groups should, in a well-aligned model, correspond to higher model-assigned importance.

### Mechanism 2: Rank Correlation as Alignment Metric
Spearman's rank correlation between data-level SMD rankings and model-level importance rankings (e.g., SHAP, decision tree importance) quantifies model-data alignment. After computing both ranking lists, Spearman's ρ measures monotonic agreement. Values above 0.7 indicate strong alignment; values between 0.4–0.7 suggest moderate alignment with potential divergence. Core assumption: High rank correlation implies the model has learned to prioritize statistically discriminative features present in raw data.

### Mechanism 3: Divergence as Interaction Detector
Lower alignment between SMD and model explanations can signal that the model is capturing legitimate non-linear or interactive patterns invisible to univariate SMD. When model-based importance diverges from univariate SMD rankings, this may indicate the model has learned higher-order relationships (e.g., sex × class interactions in Titanic data) that require multivariate analysis to detect. Core assumption: Not stated as proven; the paper hypothesizes that divergence "may reflect" interaction learning rather than model failure.

## Foundational Learning

- Concept: **Rubin's Potential Outcomes Framework**
  - Why needed here: The paper draws inspiration from causal inference theory to conceptualize feature effects as separation between potential outcome groups. Understanding ACE (Average Causal Effect) helps contextualize why SMD is a descriptive proxy, not a causal estimator.
  - Quick check question: Can you explain why SMD approximates group separation but does not satisfy the requirements for causal identification?

- Concept: **Effect Size and Standardized Mean Difference (Cohen's d)**
  - Why needed here: The core mechanism relies on computing pooled standard deviation and normalizing mean differences. Understanding effect size interpretation (small ≈ 0.2, medium ≈ 0.5, large ≈ 0.8) helps assess practical significance of feature separation.
  - Quick check question: Given two features with identical SMD values but different variances within groups, which would you trust more for alignment comparison and why?

- Concept: **Spearman's Rank Correlation**
  - Why needed here: Alignment is quantified via rank correlation, not Pearson correlation. Understanding that Spearman's ρ measures monotonic (not linear) relationships is essential for interpreting alignment results.
  - Quick check question: If SMD ranks feature A as #1 and SHAP ranks it #3, while both agree feature B is #2, what is the maximum possible Spearman correlation?

## Architecture Onboarding

- Component map: Data preprocessing (imputation → encoding → scaling) -> SMD computation (mean/variance → pooled SD → standardized difference) -> Model training (Decision Tree → MLP) -> Explanation extraction (feature importance → SHAP) -> Alignment evaluation (Spearman correlation)

- Critical path:
  1. Load and preprocess data (missing value imputation, encoding, train-test split)
  2. Compute SMD rankings on full training data (model-independent)
  3. Train models on training split
  4. Extract feature importance from trained models
  5. Compute Spearman correlation between SMD ranking and each model's importance ranking
  6. Visualize via scatter plots (rank-rank comparison)

- Design tradeoffs:
  - **Univariate vs. multivariate**: SMD captures only marginal feature effects; interactions require extension (not implemented)
  - **Binary only**: Current framework limited to binary classification; multiclass/regression require adaptation
  - **Computational efficiency vs. depth**: SMD is O(n) per feature; SHAP is O(2^n features) for exact computation, O(samples × features) for KernelExplainer approximation
  - **Descriptive vs. causal**: SMD identifies statistical association, not causal mechanisms; confounded features may rank highly

- Failure signatures:
  - **Very low correlation (< 0.3)**: May indicate model learning spurious patterns, severe data leakage, or SMD being inappropriate for the data structure
  - **Very high correlation (> 0.98)**: May indicate model is effectively memorizing univariate patterns without learning useful interactions—potential underfitting
  - **Sharp disagreement on top-ranked feature**: Investigate whether feature has interaction effects, data quality issues, or whether model is exploiting a proxy variable

- First 3 experiments:
  1. **Baseline replication**: Replicate Titanic and Diabetes experiments with identical hyperparameters; verify Spearman correlations fall within reported ranges (0.607–0.952)
  2. **Interaction stress test**: Inject a known interaction feature into a synthetic dataset where univariate SMD ranks both A and B low but the interaction is highly predictive. Verify that model explanations rank the interaction components higher than SMD alone would predict
  3. **Confounded feature test**: Add a feature that is strongly correlated with outcome only through a confounder. Observe whether SMD ranks this feature highly and whether model explanations also prioritize it

## Open Questions the Paper Calls Out
- How can the SMD-based alignment framework be generalized for multi-class classification and continuous regression outcomes?
- Can the heuristic be extended to distinguish direct feature effects from those that are confounded or mediated by other variables?
- How does the univariate data baseline align with models that rely primarily on non-linear feature interactions?

## Limitations
- Binary classification restriction prevents application to regression and multiclass problems without methodological extension
- Univariate SMD approach cannot capture feature interactions or multivariate patterns
- Descriptive rather than causal approach may prioritize confounded or mediated features

## Confidence
- **High confidence**: SMD computation methodology, Spearman correlation interpretation, hyperparameter specifications
- **Medium confidence**: Alignment interpretation (moderate vs strong correlation thresholds), divergence detection as interaction indicator
- **Low confidence**: Cross-dataset generalizability beyond Titanic/Diabetes, causal interpretation limitations

## Next Checks
1. **Implementation fidelity test**: Replicate all experiments with explicit categorical encoding and documented SHAP background sampling; verify reported correlation ranges (0.607–0.952)
2. **Interaction detection validation**: Create synthetic dataset with known feature interactions where univariate SMD ranks features low but interactions are highly predictive; test whether model explanations correctly identify interaction importance
3. **Confounding sensitivity analysis**: Construct dataset with spurious feature-outcome correlation via confounding variable; assess whether SMD and model explanations both prioritize these non-causal features, confirming the descriptive limitation