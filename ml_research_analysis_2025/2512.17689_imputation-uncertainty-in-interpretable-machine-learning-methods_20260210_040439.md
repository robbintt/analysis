---
ver: rpa2
title: Imputation Uncertainty in Interpretable Machine Learning Methods
arxiv_id: '2512.17689'
source_url: https://arxiv.org/abs/2512.17689
tags:
- imputation
- linear
- mice
- data
- learner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how different missing data imputation strategies
  affect the reliability of interpretable machine learning (IML) methods, specifically
  focusing on variance estimation and confidence interval coverage. While prior work
  addressed bias in IML under missing data, it overlooked imputation uncertainty's
  impact on variance.
---

# Imputation Uncertainty in Interpretable Machine Learning Methods

## Quick Facts
- arXiv ID: 2512.17689
- Source URL: https://arxiv.org/abs/2512.17689
- Authors: Pegah Golchian; Marvin N. Wright
- Reference count: 40
- Single imputation methods artificially reduce variance estimates for interpretable ML methods, leading to poor confidence interval coverage.

## Executive Summary
This paper investigates how missing data imputation strategies affect the reliability of interpretable machine learning (IML) methods. While prior work addressed bias in IML under missing data, it overlooked imputation uncertainty's impact on variance. The authors extend the "learner uncertainty" framework to incorporate imputation uncertainty and evaluate permutation feature importance, partial dependence plots, and Shapley values under various missing data patterns (MCAR, MAR, MNAR) and imputation methods (single imputation via mean and MissForest, multiple imputation via MICE with PMM and RF). The results show that multiple imputation is crucial for valid uncertainty quantification in IML methods when data contain missing values, and that naive single imputation methods can severely distort interpretation.

## Method Summary
The authors evaluated IML methods (permutation feature importance, partial dependence plots, and Shapley values) under various missing data patterns (MCAR, MAR, MNAR) and imputation strategies (mean imputation, MissForest, MICE PMM, MICE RF). They generated synthetic data from linear and non-linear DGPs with Toeplitz covariance, introduced missingness at 10%, 20%, and 40% levels, and compared single vs. multiple imputation approaches. The study used 1000 experiment repetitions with linear regression and XGBoost models, applying Rubin's rules to pool variance across imputations and bootstrap/subsampling for resampling. Coverage probabilities were evaluated against the nominal 95% level.

## Key Results
- Single imputation (especially mean imputation) consistently underestimated variance and led to poor confidence interval coverage, particularly for Shapley values and permutation importance
- Multiple imputation (MICE) provided much better coverage, with MICE PMM performing best for linear models and MICE RF for non-linear ones
- MissForest can overestimate feature importance, likely due to overfitting
- Mean imputation artificially reduces feature variance, causing important features to appear insignificant

## Why This Works (Mechanism)

### Mechanism 1: Variance Deflation in Single Imputation
Single imputation methods treat imputed values as fixed, known quantities rather than estimates, ignoring "imputation uncertainty" and artificially reducing total variance. Mean imputation specifically centers missing values, artificially lowering feature variance and shrinking effect size estimates.

### Mechanism 2: Uncertainty Propagation via Rubin's Rules
Multiple imputation recovers nominal coverage probabilities by explicitly modeling and pooling the uncertainty of the imputation process. By generating m different imputed datasets, MICE captures "between-imputation variance" and combines it with within-imputation variance using Rubin's rules.

### Mechanism 3: Congruence Between Imputation Model and Data Generating Process
The statistical efficiency of the explanation depends on matching the imputation algorithm to the underlying data structure. MICE PMM assumes linear relationships and performs well on linear DGPs, while MICE RF captures non-linear interactions and performs better on non-linear DGPs.

## Foundational Learning

- **Learner Uncertainty (vs. Model Uncertainty)**: Accounts for variance introduced by model training process (resampling data), not just variance of explanation for a single fixed model. *Why needed*: The paper builds on "learner uncertainty" (Molnar et al.) to incorporate imputation uncertainty.
- **Missing Data Mechanisms (MCAR, MAR, MNAR)**: The validity of imputation and resulting confidence intervals depend on why data is missing. *Quick check*: If a patient's weight is missing because they are too heavy to use the scale, is this MCAR, MAR, or MNAR? (Answer: MNAR).
- **Global Model-Agnostic Interpretation (PDP, PFI, SHAP)**: These are the specific explanation tools being tested. *Quick check*: Which method requires re-running the model on permuted data to calculate importance? (Answer: PFI).

## Architecture Onboarding

- **Component map**: Input -> Imputer (Single/Multiple) -> Resampler (Bootstrap/Subsampling) -> Learner (Linear/XGBoost) -> Explainer (PDP/PFI/SHAP) -> Aggregator (Rubin's Rules)
- **Critical path**: The "MI Boot" approach is the computational bottleneck. You must run the resampling/modeling/explanation loop k times for each of the m imputed datasets.
- **Design tradeoffs**: Mean Imputation is fastest but dangerous (yields narrow CIs that are statistically invalid). MICE RF provides best performance for complex data but is computationally heavy and may overfit if m is small.
- **Failure signatures**: Coverage Collapse (CIs cover ground truth < 80% of time), Feature Attenuation (important features appear insignificant), CI Implosion (confidence intervals shrink as missingness increases).
- **First 3 experiments**: 1) Validation of Variance Adjustment: Replicate comparison of adjusted vs. unadjusted variance on complete data. 2) Linearity Sensitivity Check: Run simulation on purely linear DGP using MICE PMM vs. MICE RF. 3) Coverage Stress Test: Generate MNAR data with 40% missingness and compare coverage of MICE vs. MissForest.

## Open Questions the Paper Calls Out

### Open Question 1
Does the high coverage observed with Multiple Imputation (MICE) persist when using resampling techniques that do not underestimate variance, or is the performance an artifact of error cancellation? The Discussion notes that MICE tends to overestimate variance while bootstrap underestimates it; the authors state these effects "cancel out" in their experiments.

### Open Question 2
How can valid confidence intervals for IML methods be constructed under Missing Not At Random (MNAR) mechanisms? The Results section states that for MNAR patterns, "the performance of all methods is considerably worse," indicating current imputation models fail to capture the necessary uncertainty.

### Open Question 3
Does the recommended multiple imputation approach scale effectively to high-dimensional settings or deep neural networks? The authors restricted analysis to XGBoost and linear models due to "computational restrictions" and limited SHAP calculations to specific efficient methods.

## Limitations
- Findings hinge on assumption that imputation model is correctly specified for missing data mechanism (MAR/MCAR)
- Computational cost of multiple imputation with bootstrapping is substantial, potentially limiting scalability
- Performance gap between single and multiple imputation could narrow if dataset is extremely large

## Confidence
- **High Confidence**: Core claim that single imputation leads to variance underestimation and poor CI coverage is well-supported by simulation results
- **Medium Confidence**: Recommendation that MICE PMM is optimal for linear models and MICE RF for non-linear models is plausible but may be sensitive to specific data structure
- **Medium Confidence**: Observation that MissForest can overestimate feature importance due to overfitting is supported by real data example

## Next Checks
1. **MNAR Robustness**: Test coverage of MICE and MissForest under severe MNAR conditions (40% missingness where missingness depends on true value) to quantify breakdown of multiple imputation
2. **Small Sample Sensitivity**: Evaluate performance of MICE RF vs. MICE PMM on very small dataset (n=100) to confirm RF's flexibility can lead to overfitting during imputation
3. **Computational Scaling**: Measure runtime of MI Boot with m=40 imputations and k=20 resamples on dataset with 10,000 observations to assess practical feasibility