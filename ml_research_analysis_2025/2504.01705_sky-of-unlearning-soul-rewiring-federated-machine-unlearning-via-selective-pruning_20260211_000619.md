---
ver: rpa2
title: 'Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective
  Pruning'
arxiv_id: '2504.01705'
source_url: https://arxiv.org/abs/2504.01705
tags:
- unlearning
- learning
- data
- drones
- pruning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SoUL, a federated unlearning framework designed
  for Internet of Drones (IoD) networks to efficiently remove the influence of unlearned
  data while preserving model performance. The framework uses a selective pruning
  algorithm that identifies and removes neurons most affected by unlearning while
  retaining those crucial for learning, reducing computational and communication overhead.
---

# Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning

## Quick Facts
- arXiv ID: 2504.01705
- Source URL: https://arxiv.org/abs/2504.01705
- Reference count: 28
- Achieves approximately 87% accuracy on CIFAR-10 while reducing training time by 40% compared to FedAU in IoD networks

## Executive Summary
This paper proposes SoUL, a federated unlearning framework designed for Internet of Drones (IoD) networks to efficiently remove the influence of unlearned data while preserving model performance. The framework uses a selective pruning algorithm that identifies and removes neurons most affected by unlearning while retaining those crucial for learning, reducing computational and communication overhead. Evaluations using CIFAR-10 and AlexNet on a simulated IoD network show that SoUL achieves approximately 87% accuracy, outperforming FedAU and matching Retrain's performance. Additionally, SoUL reduces total training time by approximately 40% compared to FedAU, demonstrating its effectiveness in resource-constrained IoD environments.

## Method Summary
SoUL operates in federated learning settings where clients need to unlearn specific data without full retraining. The framework combines federated learning with selective pruning at two levels: local models are pruned using L1-norm before transmission to reduce size from ~10MB to ~2.5MB, and at the server, a selective pruning algorithm identifies neurons important for unlearning but not for learning. The unlearning process involves creating perturbed versions of unlearning data (D'u) by randomly relabeling the original unlearning data (Du) and combining it with remaining data (Dr). The framework uses an unlearning coefficient α to balance between the global model and the unlearning model during aggregation.

## Key Results
- Achieves approximately 87% accuracy on CIFAR-10 after unlearning, outperforming FedAU and matching Retrain's performance
- Reduces total training time (computation + communication) by approximately 40% compared to FedAU baseline
- Maintains effectiveness in resource-constrained IoD environments with 50 simulated drones

## Why This Works (Mechanism)
SoUL works by selectively pruning neurons that are most affected by unlearning while preserving those crucial for learning. The selective pruning algorithm identifies neurons using L1-norm masks at a threshold of β=0.20, creating a pruning mask that removes neurons important for unlearning but not for learning. This approach reduces model size and computational overhead while maintaining accuracy on remaining data.

## Foundational Learning
- **Federated Learning**: Distributed model training across multiple clients without centralizing data - needed for IoD networks where drones have local data storage and limited communication
- **Machine Unlearning**: Removal of specific data influence from trained models - needed to address privacy concerns and remove adversarial/sensitive data
- **Selective Pruning**: Targeted removal of neurons based on importance criteria - needed to reduce model size while preserving critical knowledge
- **L1-norm based pruning**: Uses absolute weight values to determine neuron importance - needed for efficient identification of removable neurons
- **α-weighted model aggregation**: Balances between original and unlearning models - needed to control the extent of unlearning

Quick check: Verify that pruning preserves accuracy by comparing pre- and post-pruning performance on validation data.

## Architecture Onboarding

Component Map: Local models (L1-pruned) -> Global aggregation -> Selective pruning (server) -> Updated global model

Critical Path: Client training → L1-pruning → Model upload → Global aggregation → Selective pruning → Model broadcast → Client update

Design Tradeoffs:
- Aggressive pruning reduces communication overhead but risks accuracy degradation
- Higher α values preserve more original knowledge but reduce unlearning effectiveness
- Local pruning vs server pruning balances computational load across network

Failure Signatures:
- Accuracy drops below 87% indicate excessive pruning or incorrect mask computation
- No training time reduction suggests pruning is not actually reducing model size or is adding overhead
- Unlearning failure shows when removed data still influences model predictions

First Experiments:
1. Test accuracy sensitivity to different β values (pruning threshold) to find optimal balance
2. Compare performance across different α values to understand unlearning vs accuracy tradeoff
3. Profile communication vs computation time separately to verify speedup source

## Open Questions the Paper Calls Out
None

## Limitations
- Data partitioning strategy (IID vs non-IID) and unlearning data selection mechanism across drones are not specified
- Specific α value used for achieving 87% accuracy is not clearly stated, only providing a range
- L1-pruning implementation details for local models are unspecified, making it difficult to reproduce exact results

## Confidence

High Confidence:
- Overall methodology and framework design - the selective pruning algorithm and unlearning approach are clearly described

Medium Confidence:
- Accuracy claims (~87%) - while competitive with baselines, the exact experimental setup and hyperparameters are partially unspecified
- Training time reduction (~40%) - depends heavily on unmentioned implementation details of pruning procedures

## Next Checks

1. Implement multiple data partitioning strategies (IID and non-IID) to test robustness of SoUL's performance claims across different distributions

2. Conduct ablation studies varying α values within the specified range to identify optimal performance and understand trade-offs

3. Profile computational overhead of selective pruning at server vs communication benefits from reduced model size to verify the claimed 40% speedup is attributable to SoUL's design rather than implementation artifacts