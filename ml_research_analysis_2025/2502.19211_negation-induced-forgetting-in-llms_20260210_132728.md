---
ver: rpa2
title: Negation-Induced Forgetting in LLMs
arxiv_id: '2502.19211'
source_url: https://arxiv.org/abs/2502.19211
tags:
- effect
- llms
- task
- were
- polarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether Large Language Models (LLMs) exhibit
  negation-induced forgetting (NIF), a cognitive bias where negating incorrect information
  leads to greater memory impairment than affirming correct information. The researchers
  adapted an experimental framework from human studies to test NIF in ChatGPT-3.5,
  GPT-4o mini, and Llama3-70b-instruct.
---

# Negation-Induced Forgetting in LLMs

## Quick Facts
- arXiv ID: 2502.19211
- Source URL: https://arxiv.org/abs/2502.19211
- Reference count: 4
- Key outcome: ChatGPT-3.5 exhibited significant negation-induced forgetting, GPT-4o-mini showed marginal NIF, while Llama3-70b did not show the effect.

## Executive Summary
This study investigates whether Large Language Models exhibit negation-induced forgetting (NIF), a cognitive bias where negating incorrect information leads to greater memory impairment than affirming correct information. The researchers adapted an experimental framework from human studies to test NIF in ChatGPT-3.5, GPT-4o mini, and Llama3-70b-instruct. Results showed that ChatGPT-3.5 exhibited significant NIF, with negated information being less likely to be recalled than affirmed information. GPT-4o-mini showed a marginally significant NIF effect, while Llama3-70b did not exhibit NIF. The findings suggest that similar cognitive biases may emerge in LLMs through their training routines, without explicit human-like reasoning mechanisms.

## Method Summary
The study adapted a human cognitive paradigm (Zang et al., 2023) to test NIF in LLMs. Three models were tested: ChatGPT-3.5, GPT-4o mini, and Llama3-70b-instruct. Each model completed a four-phase evaluation: (1) Study Phase - presented a 62-sentence story about two university students, (2) Verification Task - answered 22 yes/no questions about story content, (3) Filler Task - HTML coding distraction, and (4) Free Recall Task - recalled as much of the story as possible. The analysis compared memory failure rates between affirmed (Yes responses) and negated (No responses) information using mixed-effects models with subject and item as random intercepts.

## Key Results
- ChatGPT-3.5 showed significant negation-induced forgetting, with negated information recalled significantly worse than affirmed information.
- GPT-4o-mini exhibited a marginally significant NIF effect (p = 0.07).
- Llama3-70b did not show NIF, possibly due to ceiling effects in verification accuracy.
- The effect was replicated from human studies, suggesting similar cognitive biases may emerge in LLMs through training routines rather than explicit reasoning mechanisms.

## Why This Works (Mechanism)

### Mechanism 1: Attention Weight Suppression for Negated Contexts
- Claim: Transformer attention mechanisms may allocate lower weights to information appearing in negation contexts, reducing its salience in subsequent retrieval.
- Mechanism: When negation markers (e.g., "No" responses, "not") appear in context windows, attention heads distribute focus away from the negated proposition's core semantic content, weakening its representation in the residual stream.
- Core assumption: Negation tokens create a distributed attention pattern that deprioritizes the negated information's key entities and relations.
- Evidence anchors:
  - [abstract] "negating incorrect attributes of an object or event leads to diminished recall of this object or event compared to affirming correct attributes"
  - [section 1] "the attention mechanisms in the transformer architecture, which might distribute focus differently for information appearing in the context of negation, reducing its prominence in subsequent processing"
  - [corpus] Weak direct evidence; neighbor papers discuss forgetting but not negation-specific attention patterns
- Break condition: If negation is handled via explicit logical operators rather than distributed attention (e.g., in fine-tuned reasoning models), NIF should attenuate or disappear.

### Mechanism 2: Statistical Training Regularities for Negation
- Claim: Pre-training corpora contain statistical patterns where negated statements are followed by topic shifts or corrections, training models to deprioritize negated content for continuation.
- Mechanism: Next-token prediction on web text learns that negated information is often subsequently corrected or abandoned, implicitly training the model to weight negated propositions lower in its internal representations.
- Core assumption: The statistical distribution of negation in training data encodes a "relevance demotion" signal that persists in downstream behavior.
- Evidence anchors:
  - [abstract] "similar cognitive biases may emerge in these models through their training routines, without explicit human-like reasoning mechanisms"
  - [section 1] "the statistical patterns learned during training could inherently weight negated information differently, leading to apparent 'forgetting'"
  - [corpus] Weak; no direct corpus evidence for training distribution effects on negation
- Break condition: If models are trained on corpora where negated information is consistently reinforced (e.g., legal or scientific text with explicit corrections), NIF should diminish.

### Mechanism 3: Contextual Memory Interference from Verification Task
- Claim: The verification task creates a retrieval competition where "No" responses generate weaker memory traces than "Yes" responses due to reduced semantic re-encoding.
- Mechanism: Affirming a statement ("Yes, X is true") re-encodes X's semantic content, strengthening its representation. Negating ("No, X is false") re-encodes the negation frame but not X's core content, yielding a weaker trace for later free recall.
- Core assumption: Free recall depends on the strength of semantic re-encoding during verification, not just initial exposure.
- Evidence anchors:
  - [section 2.4.2] "significant main effect of polarity on memory failure, F(1, 647) = 4.64, p = .03"
  - [section 2.3] Table 1 shows affirmative responses (Yes) vs. negative responses (No) to verification questions
  - [corpus] Negligible; corpus neighbors do not address verification-induced memory effects
- Break condition: If models use explicit working memory buffers or external retrieval, the effect should disappear. Check whether model performance on affirmed vs. negated items diverges when recall is cued rather than free.

## Foundational Learning

- Concept: **Negation-Induced Forgetting (NIF) in human cognition**
  - Why needed here: The entire paper adapts a human cognitive paradigm; understanding the original effect in humans (Mayo et al., 2014; Zang et al., 2023) is prerequisite to interpreting LLM results.
  - Quick check question: Can you explain why saying "No, she didn't drink red wine" impairs later recall that wine was consumed at all, compared to saying "Yes, she drank white wine"?

- Concept: **Transformer attention and context encoding**
  - Why needed here: The proposed mechanism hinges on how attention distributes across negation contexts; without this, you cannot evaluate the paper's theoretical claims.
  - Quick check question: In a transformer, how does the presence of a negation token in a sequence affect the attention distribution over the negated content's tokens?

- Concept: **Free recall vs. cued recall paradigms**
  - Why needed here: The NIF effect is measured via free recall; understanding why free recall is sensitive to encoding strength (while cued recall may not be) clarifies what the results imply about memory representation.
  - Quick check question: Why might a model show NIF in free recall but not in a multiple-choice recognition task?

## Architecture Onboarding

- Component map: Story text (62 sentences) -> Verification questions (22 statements, yes/no responses) -> Optional filler task -> Free recall prompt

- Critical path:
  1. Replicate Zang et al. (2023) materials (story + verification statements)
  2. Run each model through Study -> Verification -> Filler -> Free Recall pipeline
  3. Score recall by sentence components; compute failure rates per condition (affirmed vs. negated)
  4. Fit mixed-effects models with Polarity as fixed effect, Subject and Item as random intercepts

- Design tradeoffs:
  - Proprietary models (GPT-3.5, GPT-4o-mini) limit mechanistic interpretability; open-weights (Llama3) allow probing but showed no NIF in this study
  - Ceiling effects in newer models (GPT-4o-mini, Llama3: 93-95% accuracy) may mask NIF; consider harder materials or longer delays
  - Treating chat sessions as "participants" conflates model behavior with prompt sensitivity

- Failure signatures:
  - No NIF observed: Check for ceiling effects (failure rates near zero); verify that verification accuracy is high enough to include observations
  - Inconsistent across models: Consider model size, instruction tuning, or context window differences
  - High variance across runs: Increase N (â‰¥80 per condition based on power analysis in section 3)

- First 3 experiments:
  1. Replicate the pilot with GPT-3.5 (N=100) to confirm NIF; log attention patterns if accessible via API
  2. Test whether NIF appears in Llama3-70B with degraded materials (longer story, more fillers) to reduce ceiling effects
  3. Compare free recall vs. cued recognition in GPT-4o-mini to test whether NIF is retrieval-specific or representation-level

## Open Questions the Paper Calls Out

- Question: How does negation-induced forgetting vary systematically across different model sizes, architectures, and training data distributions?
  - Basis in paper: [explicit] "Future research should systematically examine how NIF varies across model sizes, architectures and training data distributions."
  - Why unresolved: Only three models were tested (ChatGPT-3.5, GPT-4o-mini, Llama3-70B), with inconsistent results across them; the sample is too limited for broad conclusions.
  - What evidence would resolve it: A large-scale benchmark testing multiple LLM families with controlled variations in parameter count, architecture type, and training corpora.

- Question: Can basic next-word prediction alone account for NIF, or does the effect require more complex architectural features?
  - Basis in paper: [explicit] "Adapting the paradigm to simpler autoregressive LLMs could help determine whether even basic next-word prediction can account for NIF."
  - Why unresolved: Current results cannot disentangle whether NIF arises from fundamental sequence prediction or from attention mechanisms specific to transformer architectures.
  - What evidence would resolve it: Testing simple n-gram models, small RNNs, and minimal transformers on the same NIF paradigm to identify the minimal architecture that exhibits the effect.

- Question: Does instruction tuning amplify or mitigate negation-induced forgetting in LLMs?
  - Basis in paper: [explicit] "Investigating whether instruction tuning amplifies or mitigates this effect could offer insights into how training strategies shape memory biases in LLMs."
  - Why unresolved: The tested models differ in training procedures, but the specific contribution of instruction tuning to NIF remains unknown.
  - What evidence would resolve it: Comparing base models against their instruction-tuned variants (e.g., Llama-3 base vs. instruct) using identical experimental protocols.

## Limitations
- The effect was only significant in ChatGPT-3.5 and marginally in GPT-4o-mini, while absent in Llama3-70B, raising questions about generalizability across architectures.
- Materials (story and verification statements) were not fully specified in the paper, requiring reconstruction from external sources.
- Proprietary models limit mechanistic interpretability, preventing direct inspection of attention patterns or internal representations.

## Confidence
- High confidence: The pilot study successfully replicated the NIF paradigm in LLMs, with clear statistical evidence of the effect in ChatGPT-3.5 and descriptive trends in GPT-4o-mini.
- Medium confidence: The absence of NIF in Llama3-70B may reflect ceiling effects or model-specific differences, but could also indicate the effect is not robust across architectures.
- Low confidence: The proposed mechanisms (attention suppression, training regularities, verification-induced interference) are speculative and not directly tested; they remain plausible but unverified explanations for the observed patterns.

## Next Checks
1. Reconstruct and pre-register the exact story and verification materials from Zang et al. (2023) to ensure faithful replication.
2. Test whether NIF appears in Llama3-70B when using materials designed to avoid ceiling effects (e.g., longer delay, more filler items, or degraded story quality).
3. Compare free recall vs. cued recognition performance in GPT-4o-mini to determine whether NIF is a retrieval-specific phenomenon or reflects deeper representation-level forgetting.