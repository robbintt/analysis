---
ver: rpa2
title: A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical
  Patterns in Temporal Knowledge Graphs
arxiv_id: '2506.14235'
source_url: https://arxiv.org/abs/2506.14235
tags:
- structural
- information
- events
- historical
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of predicting future events in
  temporal knowledge graphs by integrating both structural and semantic information.
  Previous methods focused on either graph structure or semantic reasoning, neglecting
  the complementary benefits of combining both.
---

# A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs

## Quick Facts
- arXiv ID: 2506.14235
- Source URL: https://arxiv.org/abs/2506.14235
- Reference count: 35
- Primary result: Proposed MESH framework achieves up to 44.36% MRR, 49.81% H@3, and 64.21% H@10 on ICEWS14, outperforming state-of-the-art methods by integrating structural and semantic information.

## Executive Summary
This paper addresses the challenge of predicting future events in temporal knowledge graphs (TKGs) by proposing the Multi-Expert Structural-Semantic Hybrid (MESH) framework. The framework tackles the limitation of existing methods that focus solely on either graph structure or semantic reasoning by adaptively fusing both perspectives. MESH employs three expert modules - two event-aware experts for historical and non-historical events, and a prediction expert that dynamically weights these based on event type - to achieve superior performance on standard TKG reasoning benchmarks.

## Method Summary
MESH uses a two-stage training procedure: first pre-training a GCN-based structural encoder (RE-GCN) and freezing it, then training an LLM-based semantic encoder (LLaMA-2-7B with MLP adapter) alongside two event-aware expert modules and a prediction expert. The framework generates separate structural and semantic query representations, which are adaptively fused based on whether events are historical (recurring) or non-historical (new). The prediction expert learns to weight the outputs of the two event-aware experts without requiring explicit event type classification.

## Key Results
- MESH achieves up to 44.36% MRR, 49.81% H@3, and 64.21% H@10 on ICEWS14 dataset
- Outperforms state-of-the-art methods by significant margins across all metrics
- Statistical analysis confirms prediction expert effectively differentiates between historical and non-historical events (p < 0.001)
- Simplest expert configuration (1,1) performs best, with more complex combinations leading to overfitting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Adaptive fusion of structural and semantic information is required because graph-based and LLM-based methods have complementary strengths for different event types (historical vs. non-historical).
- **Mechanism:** A dual-encoder system generates two query representations: $q_g$ from a GCN-based structural encoder and $q_l$ from an LLM-based semantic encoder. Event-aware expert modules then learn to combine these representations, guided by the intuition that historical events benefit from LLM semantic context while non-historical events rely more on graph evolution patterns.
- **Core assumption:** The fundamental reasoning patterns for historical (recurrence) and non-historical (evolution) events are sufficiently distinct that a static, one-size-fits-all fusion of information sources is suboptimal.
- **Evidence anchors:**
  - [abstract]: "Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives."
  - [Section 4.6, Table 5]: "Graph-based methods like RE-GCN demonstrate strong capability in capturing evolution patterns... LLM-based models (e.g., GenTKG) excel particularly at modeling historical events... MESH achieves consistent improvements in both scenarios."
  - [corpus]: Related work (e.g., "Integrate Temporal Graph Learning into LLM-based Temporal Knowledge Graph Model") also addresses hybrid approaches, confirming the problem's relevance.
- **Break condition:** If a dataset is heavily dominated by a single event type, the adaptive mechanism's benefit diminishes, and a simpler, fixed fusion strategy may suffice.

### Mechanism 2
- **Claim:** The distinction between historical and non-historical events can be learned implicitly through a prediction expert's weighting mechanism, avoiding error-prone explicit classification.
- **Mechanism:** A prediction expert module computes dynamic weights $\alpha$ for each event-aware expert based on the structural query representation $q_g$. Instead of a hard classifier, the model learns to up-weight the "historical expert" for historical events and the "non-historical expert" for new events, with the training objective encouraging this specialization.
- **Core assumption:** The structural query $q_g$ is a sufficient proxy for event type and the model can learn a reliable mapping from $q_g$ to the optimal expert weights without explicit supervision.
- **Evidence anchors:**
  - [Section 3.5]: "To address this limitation, we design a prediction expert that adaptively integrates information from different kinds of experts without explicit type classification."
  - [Section 4.6, Table 6]: Statistical analysis shows "the mean value of $\alpha_1$ [weight for historical expert] for historical events is relatively higher than that for non-historical events," with a significant p-value (p < 0.001), validating the learned differentiation.
  - [corpus]: Specific corpus evidence for the "implicit vs. explicit" argument is weak; the claim is primarily supported by the paper's internal analysis.
- **Break condition:** If the structural encoder is weak and $q_g$ lacks discriminative power, the gating signal will be uninformative, leading to poor expert selection.

### Mechanism 3
- **Claim:** A non-generative, encoder-only use of LLMs provides high-value semantic information at a fraction of the computational cost of generative approaches.
- **Mechanism:** The framework uses an LLM to process textual prompts about entities and relations, extracting the hidden states from the last transformer layer as semantic embeddings ($H^{LLM}$). These high-dimensional embeddings are compressed by an adapter MLP and used directly for prediction, bypassing the expensive token-by-token generation of typical LLM methods.
- **Core assumption:** The knowledge required for TKG reasoning is sufficiently captured in the frozen LLM's embeddings and can be effectively transferred to the prediction task via a small adapter network.
- **Evidence anchors:**
  - [Section 3.3.2]: "Motivated by this, we adopt an LLM-based approach to encode entities and relations efficiently... we extract the hidden states from the last transformer layers of the LLM to obtain semantic representations".
  - [Section 4.2, Table 2 text]: "our model significantly reduces the inference cost... our approach completes the same task within minutes."
  - [corpus]: Related work in the corpus (e.g., "Event-CausNet") also leverages LLMs for knowledge extraction, supporting the value of LLM-based semantics. The non-generative efficiency is a specific claim of this paper.
- **Break condition:** Performance is capped by the base LLM's capacity. If the chosen LLM (e.g., LLaMA-2-7B) lacks domain knowledge for the TKG's specific entities, the semantic signal will be weak.

## Foundational Learning

- **Concept: Temporal Knowledge Graph (TKG)**
  - **Why needed here:** This is the fundamental data structure the entire paper operates on. A TKG is a sequence of static knowledge graphs, each associated with a timestamp. Understanding that events are quadruples `(subject, relation, object, time)` is non-negotiable.
  - **Quick check question:** How does a TKG differ from a static Knowledge Graph, and what is the formal representation of a single event?

- **Concept: Graph Convolutional Networks (GCN) for TKGs**
  - **Why needed here:** This is the structural backbone of the MESH framework. You must understand how a GCN aggregates information from a node's neighbors to create entity embeddings, and how this is applied recurrently over time (as in RE-GCN) to capture temporal dependencies.
  - **Quick check question:** What is the core operation a GCN performs on a node's features, and how does a recurrent GCN (like RE-GCN) extend this for temporal data?

- **Concept: Mixture of Experts (MoE) and Gating Networks**
  - **Why needed here:** The "Multi-Expert" part of MESH is a direct implementation of this concept. You need to understand how a set of "expert" networks specialize on different parts of the data, and how a "gating network" learns to route an input to the appropriate expert(s).
  - **Quick check question:** In a basic MoE layer, what are the roles of the expert networks versus the gating network? What does the gating network's output represent?

## Architecture Onboarding

- **Component map:** Entity/relation IDs and names, sub-graph structure -> Parallel GCN-based structural encoder and LLM-based semantic encoder -> Two separate ConvTransE decoders produce structural ($q_g$) and semantic ($q_l$) query representations -> Two event-aware experts (one for historical, one for non-historical) -> Prediction expert weights the outputs -> Final prediction

- **Critical path:** **Semantic/Structural Encodings $\rightarrow$ Query Representations ($q_g, q_l$) $\rightarrow$ Event-Aware Expert Fusion $\rightarrow$ Prediction Expert Weighting $\rightarrow$ Final Logits.** The performance hinges on the quality of $q_g$ and $q_l$ and the prediction expert's ability to correctly weight the two event-aware experts.

- **Design tradeoffs:**
  - **Encoder Choice:** The paper uses RE-GCN and LLaMA-2-7B but shows results with TiRGN and Stella. Stronger encoders improve performance but increase training cost. The GCN is frozen after pre-training to maintain stability and reduce cost.
  - **Expert Complexity:** Ablation studies (Table 7) show that more experts (e.g., (2,2), (3,3)) do not improve performance. The simplest (1,1) configuration is optimal, suggesting overfitting or redundancy with more experts.
  - **Implicit vs. Explicit Type Classification:** The design avoids a separate classifier for event type. This reduces complexity and potential error propagation but relies entirely on the model learning the distinction end-to-end.

- **Failure signatures:**
  - **Dominant Event Type:** If the dataset is skewed heavily towards one event type (e.g., mostly historical), the model may collapse to relying on a single expert.
  - **Weak Structural Signal:** If $q_g$ is uninformative, the Prediction Expert cannot distinguish event types, and the adaptive fusion fails.
  - **LLM Mismatch:** If the LLM lacks domain knowledge (e.g., for obscure entities), the semantic path provides little value, and performance may degrade to the GCN baseline.

- **First 3 experiments:**
  1. **Baseline Reproduction:** Implement the "Naive" and "LLM-MLP" baselines on ICEWS14. This verifies your data pipeline and gives a quick performance target. These simple models are surprisingly strong.
  2. **Ablation Study (w/o Semantic Info, w/o Structural Info):** Run the full MESH model, then disable each encoder path. This quantifies the individual contribution of structural and semantic information and confirms they are both necessary for peak performance.
  3. **Event-Type Analysis:** Replicate the experiment from Table 5. Split the test set into historical and non-historical events and evaluate performance. This is the most direct way to validate the core claim that the model handles different event types differently.

## Open Questions the Paper Calls Out

- **Question:** Can the MESH framework maintain its efficiency and performance improvements when integrated with significantly larger or more advanced foundational models (e.g., GPT-4) compared to the current LLaMA-2-7B and RE-GCN backbones?
- **Question:** Does the optimality of the single-expert configuration (M=1, N=1) persist in TKGs with higher relation diversity or multi-modal data, or does it simply reflect the characteristics of the ICEWS datasets?
- **Question:** Is the binary historical indicator $I$ sufficient for distinguishing event types, or does the hard threshold fail to capture "quasi-historical" events that are semantically similar but structurally distinct?
- **Question:** To what extent does the framework generalize to domains where "historical patterns" (recurrence) are rare, such as high-frequency financial transactions or novel scientific discoveries?

## Limitations

- The framework's performance is bounded by the capacity of the underlying encoders (LLaMA-2-7B, RE-GCN), and it remains unclear if the adaptive fusion mechanism scales effectively with much larger models.
- The optimality of the single-expert configuration (M=1, N=1) is only validated on the ICEWS datasets and may not generalize to TKGs with significantly more relation types or complex temporal structures.
- The binary historical indicator may fail to capture nuanced "quasi-historical" events that are semantically similar but structurally distinct, potentially limiting the model's ability to generalize in dynamic scenarios.
- The framework's effectiveness in domains where historical patterns are rare (e.g., financial transactions, scientific discoveries) remains untested, as all experiments are conducted on political event datasets.

## Confidence

- **High confidence:** The core empirical finding that combining structural and semantic information improves TKG reasoning performance (Table 2, Table 5). The statistical significance of event-type differentiation is also well-supported (Table 6).
- **Medium confidence:** The mechanism explanation for why adaptive fusion outperforms static fusion, as this relies heavily on qualitative interpretation of results rather than controlled ablation studies.
- **Medium confidence:** The efficiency claims regarding non-generative LLM usage, as these are compared to generative approaches but lack direct benchmarks against other non-generative hybrid methods.

## Next Checks

1. **Prediction Expert Isolation:** Run an ablation study where the prediction expert is replaced with a fixed weighting scheme (e.g., 0.5/0.5 or event-type classifier-based weights). Compare performance to assess whether the learned gating mechanism provides significant benefit beyond the event-aware experts themselves.

2. **Dataset Balance Sensitivity:** Create a modified ICEWS14 test set where the ratio of historical to non-historical events is artificially skewed (e.g., 90/10 vs 50/50). Evaluate whether MESH performance degrades as the dataset becomes dominated by one event type, testing the break condition for Mechanism 1.

3. **Structural Encoder Sensitivity:** Repeat the full experiment using a different structural encoder (e.g., TiRGN from Table 3) while keeping the semantic encoder and prediction expert architecture constant. This validates whether the framework's performance gains are robust to structural encoder choice or specific to RE-GCN.