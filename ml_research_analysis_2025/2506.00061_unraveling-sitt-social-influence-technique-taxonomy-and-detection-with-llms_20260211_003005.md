---
ver: rpa2
title: 'Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs'
arxiv_id: '2506.00061'
source_url: https://arxiv.org/abs/2506.00061
tags:
- social
- techniques
- przyk
- influence
- definicja
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study presents the Social Influence Technique Taxonomy (SITT),\
  \ a framework of 58 techniques organized into nine categories, designed to detect\
  \ subtle forms of social influence in textual content. Using a hierarchical multi-label\
  \ classification setup, we benchmarked five LLMs\u2014GPT-4o, Claude 3.5, Llama-3.1,\
  \ Mixtral, and PLLuM\u2014on a 746-dialogue corpus annotated by 11 experts."
---

# Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs

## Quick Facts
- arXiv ID: 2506.00061
- Source URL: https://arxiv.org/abs/2506.00061
- Reference count: 40
- Primary result: Presented SITT framework with 58 techniques; achieved F1 scores of 0.45 (categories) and 0.31 (techniques) with Claude 3.5

## Executive Summary
This study introduces the Social Influence Technique Taxonomy (SITT), a comprehensive framework of 58 social influence techniques organized into 9 categories, designed for detecting subtle manipulation in textual dialogues. Using a hierarchical multi-label classification approach, the authors benchmark five large language models on a 746-dialogue corpus annotated by 11 experts in Polish and translated to English. The results reveal significant limitations in current LLMs' ability to detect nuanced social influence techniques, with overall performance remaining modest despite using sophisticated prompting strategies. The work highlights the need for domain-specific fine-tuning and extended datasets to improve detection of context-sensitive techniques.

## Method Summary
The study employed zero-shot hierarchical multi-label classification where models first predicted broad categories (9 total) of social influence, then selected specific techniques (58 total) from only those predicted categories. The SITT dataset contained 746 dialogues with an average of 3 categories and 2.9 techniques per dialogue. Five LLMs were evaluated: GPT-4o, Claude 3.5 Sonnet, Llama-3.1-70B, Mixtral-8x22B, and PLLuM-8x7B. The approach used definition-driven in-context learning with prompts containing full taxonomy definitions and examples. Performance was measured using Micro-F1, Precision, Recall, and Jaccard scores.

## Key Results
- Claude 3.5 achieved highest performance: F1 0.45 for categories and 0.31 for techniques
- Overall model performance remained limited, particularly for context-sensitive techniques
- "Context modification" category showed consistently lowest scores (F1 ~0.07-0.17)
- GPT-4o produced identical scores for Polish and English, suggesting translation artifacts
- Models showed high precision but low recall, flagging only obvious influence while missing subtle cues

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Constrained Decoding
The system filters technique predictions through category prediction to reduce complexity from 58 to ~4-8 techniques per dialogue. This works under the assumption that category detection is reliable enough to not filter out correct answers. The mechanism fails when category prediction has low recall, creating an error cascade where missing a category guarantees missing all its techniques.

### Mechanism 2: Definition-Driven In-Context Learning
Zero-shot detection is achieved by injecting definitions and examples for all 58 techniques into the prompt context. This aligns model token prediction with the specific SITT taxonomy rather than generic usage. The mechanism strains under subtle distinctions where two techniques rely on tone or subtext not captured in text definitions.

### Mechanism 3: Translation-Augmented Generalization
The architecture leverages translation to utilize English-centric LLMs on Polish data, hypothesizing that social influence signals transfer across languages. The mechanism may introduce noise or "double-exposure" artifacts where the translation model alters manipulation nuance, potentially explaining identical scores for GPT-4o on Polish and English.

## Foundational Learning

**Hierarchical Multi-Label Classification** - Why needed: Real-world manipulation is complex with multiple labels per instance (average 3 categories, 2.9 techniques). Quick check: If a model predicts Category A and Technique 1, but ground truth is Category A and Technique 2, does it get partial credit for the category?

**Context Window Saturation & Prompt Engineering** - Why needed: The SITT taxonomy contains 58 techniques with definitions, risking context limits or attention dilution. Quick check: Why might a model fail to distinguish between "Framing" and "Valence framing" if both definitions are in the same prompt?

**Annotation Agreement & Subjectivity** - Why needed: Social influence is subjective while "ground truth" labels are used for evaluation. Quick check: How does subjectivity of "social influence" differ from objectivity of "sentiment analysis," and how might this affect ground truth labels?

## Architecture Onboarding

**Component map:** Data Ingestion -> Translation Layer (GPT-4o) -> English Dialogues -> Prompt Assembler -> Inference Engine (LLM) -> Category List -> Filter -> Technique List -> Evaluator

**Critical path:** Category Prediction is the bottleneck. A false negative at category stage guarantees a false negative at technique stage. If the model fails to detect "Appeal to Consistency," it will never look for "Foot-in-the-door."

**Design tradeoffs:** Hierarchical classification reduces complexity but creates error propagation. Zero-shot prompting preserves flexibility but lacks sufficient grounding for this specific taxonomy without fine-tuning.

**Failure signatures:** "Context" blindness with lowest scores in "Context modification" category, over-cautiousness with high precision but low recall, and language coupling with GPT-4o's identical scores for Polish and English.

**First 3 experiments:**
1. Flat vs. Hierarchical Ablation: Bypass category filter to quantify error propagation vs. simplification benefits
2. Context Augmentation for "Context": Append synthetic metadata to improve detection of context-dependent techniques
3. Cross-Model Consistency Check: Use different translation model to isolate whether identical scores were due to translation artifacts

## Open Questions the Paper Calls Out
- How does domain-specific fine-tuning improve detection for underrepresented categories like "Context modification" and "Consistency"?
- Can sentence-level annotations train models to accurately explain and pinpoint specific textual evidence for techniques?
- Does incorporating diverse external contexts during inference improve detection accuracy for techniques relying on implicit information?

## Limitations
- Hierarchical error propagation creates cascading failures where missed categories guarantee missed techniques
- Subjectivity in social influence annotation affects ground truth reliability without clear inter-annotator agreement metrics
- Translation-dependent evaluation introduces potential confounds and may create model overfitting to translation patterns

## Confidence
**High Confidence** (Robust evidence):
- Hierarchical two-step classification methodology is clearly specified
- SITT taxonomy of 58 techniques across 9 categories is well-defined
- Claude 3.5 achieved highest reported performance metrics

**Medium Confidence** (Limited evidence):
- Translation augmentation mechanism effectiveness based on single translation model
- Zero-shot prompting approach sufficiency for complex taxonomy
- Context sensitivity limitations inferred from category-level performance

**Low Confidence** (Minimal evidence):
- Generalizability to languages beyond Polish/English
- Scalability to larger, more diverse dialogue corpora
- Long-term robustness to evolving social influence techniques

## Next Checks
1. **Flat vs Hierarchical Ablation Study** - Bypass category filter to classify all 58 techniques directly, isolating error propagation penalty
2. **Context Augmentation Experiment** - Systematically append synthetic metadata to dialogue text for "Context modification" category to measure improvement
3. **Cross-Translation Consistency Test** - Use different translation model to evaluate GPT-4o, determining whether identical scores were due to translation artifacts