---
ver: rpa2
title: LLM-Friendly Knowledge Representation for Customer Support
arxiv_id: '2510.10331'
source_url: https://arxiv.org/abs/2510.10331
tags:
- data
- knowledge
- llms
- format
- customer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a novel approach to improve LLM performance
  in customer support tasks by transforming complex business workflows into an Intent,
  Context, and Action (ICA) pseudocode format. This LLM-friendly representation simplifies
  the understanding of business logic and enables better reasoning over policies and
  workflows.
---

# LLM-Friendly Knowledge Representation for Customer Support

## Quick Facts
- arXiv ID: 2510.10331
- Source URL: https://arxiv.org/abs/2510.10331
- Reference count: 4
- Authors: Hanchen Su; Wei Luo; Wei Han; Yu Elaine Liu; Yufeng Wayne Zhang; Cen Mia Zhao; Ying Joy Zhang; Yashar Mehdad

## Executive Summary
This paper addresses the challenge of improving Large Language Model (LLM) performance in customer support tasks by transforming complex business workflows into an Intent, Context, and Action (ICA) pseudocode format. The approach simplifies the understanding of business logic and enables better reasoning over policies and workflows. To overcome data scarcity, the authors develop a synthetic data generation strategy that creates supervised fine-tuning data with minimal human involvement. The method combines ICA reformatting with fine-tuning smaller open-source LLMs, significantly enhancing accuracy while reducing latency.

## Method Summary
The proposed approach transforms complex business workflows into Intent, Context, and Action (ICA) pseudocode format, which simplifies business logic understanding and improves reasoning capabilities. To address the scarcity of training data, the authors develop a synthetic data generation strategy that creates supervised fine-tuning data with minimal human involvement. The approach combines ICA reformatting with fine-tuning smaller open-source LLMs using synthetic data. Internal experiments demonstrate that ICA format and Chain-of-Thought reasoning improve model accuracy, with fine-tuned smaller models achieving performance comparable to larger LLMs but with much lower latency.

## Key Results
- ICA format and Chain-of-Thought reasoning significantly improve model accuracy in customer support tasks
- Fine-tuned smaller models achieve performance comparable to larger LLMs with much lower latency
- Online evaluations show 13% reduction in manual processing time compared to baseline

## Why This Works (Mechanism)
The ICA pseudocode format breaks down complex business workflows into three essential components: Intent (what the customer wants), Context (relevant information and constraints), and Action (what steps to take). This structured representation aligns with how humans naturally process and reason about business logic, making it easier for LLMs to understand and execute complex workflows. The synthetic data generation strategy creates diverse training examples that cover edge cases and rare scenarios, improving the model's ability to handle real-world customer support situations.

## Foundational Learning
- **Intent, Context, and Action (ICA) pseudocode format**: A structured representation of business workflows that simplifies complex logic for LLM understanding. Why needed: To break down complex business workflows into digestible components. Quick check: Can the model correctly identify and separate intent, context, and action components in sample workflows.
- **Chain-of-Thought (CoT) reasoning**: A prompting technique that encourages step-by-step reasoning. Why needed: To improve the model's ability to follow complex logical sequences in customer support scenarios. Quick check: Does the model show improved accuracy on multi-step reasoning tasks compared to direct answer generation.
- **Synthetic data generation**: Automated creation of training data that mimics real customer interactions. Why needed: To overcome data scarcity and create diverse training examples covering edge cases. Quick check: Does the model perform well on real-world test cases after training on synthetic data?

## Architecture Onboarding
**Component Map**: Customer Query -> ICA Reformatting -> Synthetic Data Generation -> Fine-tuning -> Deployed Model
**Critical Path**: ICA Reformatting → Synthetic Data Generation → Fine-tuning → Inference
**Design Tradeoffs**: The approach trades off model size for accuracy through fine-tuning, choosing smaller models with specialized training over larger general-purpose models. This reduces latency and operational costs while maintaining comparable performance.
**Failure Signatures**: Poor performance may manifest as inability to correctly parse complex business rules, failure to handle edge cases, or generation of incorrect actions based on misinterpreted context.
**First Experiments**: 
1. Test ICA reformatting accuracy on sample business workflows
2. Validate synthetic data quality through human evaluation
3. Compare fine-tuned model performance against baseline LLM on standard customer support benchmarks

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation results are based on internal experiments and online A/B tests within a single organization, lacking independent verification
- The synthetic data generation strategy's quality control mechanisms and representativeness compared to actual customer interactions are not fully specified
- Long-term performance monitoring and potential degradation over time are not addressed

## Confidence
- High confidence: The theoretical framework of ICA pseudocode representation and its potential to simplify complex business workflows
- Medium confidence: The effectiveness of synthetic data generation strategy for SFT, based on internal validation
- Medium confidence: The claimed performance improvements (13% reduction in manual processing time), pending independent verification

## Next Checks
1. Conduct external validation studies with diverse customer support datasets from multiple organizations to verify generalizability of results
2. Perform detailed ablation studies to quantify the individual contributions of ICA formatting versus synthetic data fine-tuning to overall performance improvements
3. Implement long-term monitoring of deployed systems to assess sustained performance, potential degradation over time, and real-world cost-benefit analysis beyond initial deployment metrics