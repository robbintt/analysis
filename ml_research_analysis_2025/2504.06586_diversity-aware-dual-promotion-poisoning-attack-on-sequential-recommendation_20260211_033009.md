---
ver: rpa2
title: Diversity-aware Dual-promotion Poisoning Attack on Sequential Recommendation
arxiv_id: '2504.06586'
source_url: https://arxiv.org/abs/2504.06586
tags:
- attack
- item
- recommendation
- items
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data poisoning attacks in sequential
  recommender systems (SRSs), where attackers inject crafted interactions to promote
  specific target items. Existing attacks often degrade recommendation accuracy and
  produce repetitive poisoning sequences, limiting their stealthiness and effectiveness.
---

# Diversity-aware Dual-promotion Poisoning Attack on Sequential Recommendation

## Quick Facts
- arXiv ID: 2504.06586
- Source URL: https://arxiv.org/abs/2504.06586
- Reference count: 40
- Primary result: DDSP outperforms state-of-the-art poisoning attacks in both effectiveness and stealthiness on three real-world datasets.

## Executive Summary
This paper addresses the problem of data poisoning attacks in sequential recommender systems (SRSs), where attackers inject crafted interactions to promote specific target items. Existing attacks often degrade recommendation accuracy and produce repetitive poisoning sequences, limiting their stealthiness and effectiveness. The authors propose a Diversity-aware Dual-promotion Sequential Poisoning (DDSP) method that simultaneously promotes both the target item and user-preferred items while minimizing harm to recommendation accuracy. Extensive experiments on three real-world datasets show that DDSP outperforms state-of-the-art attack methods in both attack effectiveness and stealthiness.

## Method Summary
DDSP introduces a dual-promotion attack objective using Mean Squared Error (MSE) to minimize the score gap between user-preferred items and the target item, preventing the conflict where the target's gain is the preferred item's loss. Additionally, it employs a diversity-aware sequence generation strategy with re-ranking to reduce item repetition and enhance the authenticity of generated sequences. The method uses a surrogate model (SASRec) to approximate the victim model, iteratively generates poisoning sequences through auto-regressive generation with diversity constraints, and jointly trains the surrogate with the combined loss of recommendation accuracy and attack objectives.

## Key Results
- DDSP achieves higher Hit Ratios (e.g., 0.0429 vs. 0.0245 for SSL-attack on Beauty dataset) while maintaining better recommendation performance.
- The diversity-aware re-ranking strategy significantly improves attack effectiveness by establishing wider sequential dependencies.
- Removing the diversity component degrades attack performance, validating its importance in creating authentic sequences.

## Why This Works (Mechanism)

### Mechanism 1
Standard attacks (e.g., pairwise loss) push the target item toward user but inadvertently push user-preferred items away to maximize the margin. DDSP proposes minimizing the score gap (ŷ_{ui} - ŷ_{ut})². If the target score is lower than the preferred item score (Δ > 0), the target embedding moves toward the user; if the target score is higher (Δ < 0), the preferred item embedding moves toward the user. This prevents the conflict where t's gain is i's loss.

### Mechanism 2
While MSE reduces the score gap, contrastive regularization explicitly treats user-preferred items as positive samples and unrelated items as negative samples for the target item. It maximizes the mutual information between the target t and preferred items i in the embedding space, aligning the target item with user-preferred items in the embedding space.

### Mechanism 3
Standard auto-regressive generation tends to over-sample the target item because of the optimized objective. DDSP calculates a sequence score r(s̃_u) = (1-λ)·Relevance + λ·Diversity. By selecting the next item based on this combined score, it forces the inclusion of diverse items, increasing the target's co-occurrence with various other items and preventing "mode collapse" (repetitive sequences).

## Foundational Learning

- **Bi-level Optimization**: The paper frames the poisoning attack as a bi-level problem (optimizing the attack objective subject to the model training objective). Understanding this helps explain why standard attacks conflict with model training and why DDSP's "joint" optimization is an innovation. Quick check: Can you explain why standard attack losses (like pairwise ranking loss) conflict with the model's own training loss (like BPR) in a bi-level setup?

- **Auto-regressive Sequence Generation**: The method generates fake user interaction histories token-by-token. Understanding auto-regression is necessary to grasp why the model tends to repeat items (the problem) and how re-ranking interrupts this loop. Quick check: In a standard auto-regressive model, why might maximizing the probability of a target item lead to repetitive loops?

- **Gradient Conflict/Alignment**: The core theoretical contribution is resolving the gradient conflict between L_rec and L_atk. Without understanding gradient direction (pulling vs. pushing embeddings), the justification for using MSE over Cross-Entropy remains opaque. Quick check: If a loss function updates a parameter such that vector A moves away from vector B, how would you mathematically describe the gradient's influence on the distance ||A - B||?

## Architecture Onboarding

- **Component map**: Surrogate Model -> Attack Optimizer -> Sequence Generator -> Re-ranking Module -> Victim Model
- **Critical path**: 1) Pre-train Surrogate Model on observed clean data (S'). 2) Iterative Loop: a) Generate candidate poisoning sequences using Generator + Re-ranker. b) Update Surrogate Model using the combined Loss (L = L_rec + L_atk + ηL_reg) on S' ∪ S_fake. 3) Inject final optimized S_fake into the Victim Model.
- **Design tradeoffs**: Greedy vs. Beam Search: Greedy search is faster but may find local optima in sequence diversity/relevance. Beam search (width B) explores more paths but costs B× computation. Diversity Weight (λ): Low λ results in repetitive, easy-to-detect sequences. High λ creates diverse but potentially incoherent sequences.
- **Failure signatures**: Stealth Failure: Recommendation accuracy (Rec H@10) drops significantly. Effectiveness Failure: Attack Hit Ratio (Atk H@10) is low. Authenticity Failure: Generated sequences contain the target item repeated consecutively.
- **First 3 experiments**: 1) Baseline Comparison: Run DDSP against Random, Bandwagon, and SOTA on Beauty/Toys datasets. 2) Ablation Study: Remove Contrastive Regularization (w/o CL) and Diversity Re-ranking (w/o DIV) separately. 3) Hyperparameter Sensitivity: Vary the diversity weight λ (e.g., 0.01 to 1.0) and plot Attack HR vs. λ.

## Open Questions the Paper Calls Out

### Open Question 1
Does the proposed DDSP method maintain its efficacy when targeting popular or medium-popularity items rather than solely unpopular items? The evaluation restricts the target item to the "least-popular set," leaving the attack's performance on items that already possess significant visibility or interaction history untested.

### Open Question 2
How resilient is the DDSP attack against specific defense strategies designed to detect or filter poisoned sequences? While DDSP aims for stealthiness by preserving recommendation accuracy, it is unclear if the generated sequences are sophisticated enough to bypass dedicated anomaly detection or robust aggregation algorithms.

### Open Question 3
To what extent does a significant structural divergence between the surrogate model and the victim model impact the attack's transferability? Real-world black-box scenarios may involve complex, proprietary model architectures that differ drastically from standard surrogates, potentially reducing the effectiveness of the dual-promotion alignment.

## Limitations

- The primary uncertainty lies in the surrogate model assumption: the paper relies on a white-box surrogate (SASRec) to approximate the black-box victim's behavior without ablation or sensitivity analysis for different victim models.
- The dual-promotion objective's theoretical elegance (MSE gradient alignment) is not empirically validated through gradient visualization or ablation on the loss function's individual terms.
- The diversity mechanism's effectiveness depends heavily on the diversity weight λ, but the paper lacks a systematic hyperparameter sensitivity study across all datasets.

## Confidence

- **High Confidence**: The core dual-promotion objective using MSE loss and its theoretical motivation; the experimental methodology and dataset preparation; the diversity-aware re-ranking strategy's basic implementation.
- **Medium Confidence**: The contrastive regularization's contribution to attack performance; the transferability of attacks from surrogate to victim models; the stealthiness claims based on recommendation accuracy metrics.
- **Low Confidence**: The exact impact of beam search width B on attack effectiveness; the negative sampling strategy for contrastive regularization; the selection criteria for "unpopular" target items.

## Next Checks

1. **Gradient Alignment Verification**: Visualize and compare the gradients of the MSE-based dual-promotion loss versus the standard pairwise loss on a held-out validation set to empirically confirm the "non-conflicting" claim.

2. **Victim Model Ablation**: Test DDSP's transferability by using different surrogate architectures (e.g., BERT4Rec) and different victim models (e.g., GRU4Rec) to quantify the impact of the surrogate assumption.

3. **Diversity Weight Sensitivity**: Conduct a comprehensive sweep of the diversity weight λ (e.g., 0.01 to 1.0 in smaller increments) and plot attack HR vs. λ to identify the optimal balance between diversity and relevance, and test if the "sweet spot" varies across datasets.