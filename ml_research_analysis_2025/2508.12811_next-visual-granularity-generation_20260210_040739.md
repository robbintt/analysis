---
ver: rpa2
title: Next Visual Granularity Generation
arxiv_id: '2508.12811'
source_url: https://arxiv.org/abs/2508.12811
tags:
- generation
- structure
- image
- visual
- granularity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Next Visual Granularity (NVG) generation,
  a framework that decomposes images into structured sequences of tokens at varying
  granularity levels. Unlike traditional methods that treat images as flat sequences
  or pyramids, NVG explicitly models hierarchical structure through multi-stage tokenization
  guided by data-driven clustering.
---

# Next Visual Granularity Generation

## Quick Facts
- **arXiv ID**: 2508.12811
- **Source URL**: https://arxiv.org/abs/2508.12811
- **Reference count**: 26
- **Key outcome**: NVG achieves state-of-the-art FID scores (3.30→3.03, 2.57→2.44, 2.09→2.06) compared to VAR series across all model sizes on ImageNet

## Executive Summary
This paper introduces Next Visual Granularity (NVG) generation, a framework that decomposes images into structured sequences of tokens at varying granularity levels. Unlike traditional methods that treat images as flat sequences or pyramids, NVG explicitly models hierarchical structure through multi-stage tokenization guided by data-driven clustering. This enables coarse-to-fine generation where global layout is refined into fine details, improving control and fidelity. Trained on ImageNet, NVG achieves state-of-the-art FID scores compared to the VAR series across all model sizes, with better IS and recall. The approach supports explicit structure-guided generation and demonstrates strong scaling behavior, offering a structured alternative to diffusion and autoregressive models for controllable image synthesis.

## Method Summary
NVG encodes images to latents and applies a fully data-driven clustering approach to progressively group visually similar tokens, constructing a visual granularity sequence (VGS) where each stage has fewer unique tokens. A lightweight rectified flow model generates hierarchical structure embeddings from noise, while a larger transformer predicts the final canvas given current state and structure. The framework uses multi-granularity quantization and trains with final-canvas supervision to avoid error accumulation. The structure generator is 1/4 the size of the content generator, justified as "simpler" due to low-dimensional embeddings. The approach differs from VAR by decomposing images by visual granularity rather than spatial resolution.

## Key Results
- State-of-the-art FID scores: 3.30→3.03, 2.57→2.44, 2.09→2.06 across NVG-d16, d20, d24 vs VAR baselines
- Better IS and recall metrics compared to VAR series
- Strong scaling behavior from d16 to d24 models
- Supports explicit structure-guided generation with layout manipulation capabilities

## Why This Works (Mechanism)

### Mechanism 1: Semantic Clustering over Spatial Pyramids
Instead of downsampling pixels like VAR, NVG clusters latent tokens based on feature similarity using greedy pairing. This forces early-stage tokens to represent coherent semantic regions (e.g., foreground vs. background) rather than blurred pixel blocks. The assumption is that feature similarity in latent space correlates with perceptual similarity, allowing global layout inference from few clustered tokens.

### Mechanism 2: Structure-Aware Positional Encoding
Standard transformers lack inductive bias for hierarchical image structure. NVG extends Rotary Position Embedding (RoPE) with "structure ID" - tokens within the same cluster at a specific stage share structural position. This allows attention layers to process global layout independently of fine-grained details, treating structure map as "soft" segmentation.

### Mechanism 3: Final-Canvas Supervision (Residual Refinement)
Predicting immediate next steps causes error accumulation. Instead, NVG predicts final canvas given current canvas - the difference implicitly defines required residual tokens. This acts as residual correction mechanism similar to diffusion models but in discrete token space, providing stronger learning signal than step-wise teacher forcing.

## Foundational Learning

- **Vector Quantization (VQ) & Residual Quantization (RQ)**: Multi-granularity quantized autoencoder maps continuous latents to discrete codebook entries, with residual quantization stacking coarse-to-fine approximations. Quick check: How does codebook size (4096) relate to number of unique tokens (2^i) at each stage?
- **Rectified Flow / Flow Matching**: Structure generator is lightweight rectified flow model that transports noise to structure embedding space straighter than standard diffusion. Quick check: Why is flow model suitable for generating low-dimensional (8-channel) structure embeddings vs autoregressive approach?
- **RoPE (Rotary Position Embeddings)**: Paper extends RoPE to be "structure-aware." Quick check: In standard RoPE, position is spatial (x,y). In NVG, what extra dimension does "structure ID" encode?

## Architecture Onboarding

- **Component map**: Tokenizer (Encoder + VQ) → Structure Generator (flow model) → Content Generator (transformer)
- **Critical path**: Construction (Offline: Run clustering on dataset to build ground truth VGS) → Structure Training (Train flow model to predict bit-wise structure embeddings) → Content Training (Train transformer with Final-Canvas loss + CE loss) → Inference (Generate Structure → Sample Content iteratively)
- **Design tradeoffs**: Structure generator is 1/4 content size (justified as "simpler" due to low dimension); Greedy k=2 pairing is efficient but might miss global optimum; "Partial Noise" inpainting superior to "Pure Noise" for structure generation
- **Failure signatures**: Removing Final Canvas prediction causes rapid overfitting (around epoch 25); Cold start fails if structure generator cannot make first binary split; Cluster drift produces inconsistent segmentations across similar images
- **First 3 experiments**: Visualize cluster hierarchy by running tokenizer on validation images and checking structure maps at stages 0, 2, 4, 8; Ablate content objective by training to predict next tokens vs final canvas and plotting validation loss; Test structure inpainting by running structure generator with fixed early stages and random noise for later stages

## Open Questions the Paper Calls Out

- Can hierarchical structure generation be distilled into a single step without degrading quality of visual granularity sequence? (Footnote in Table 1 mentions this as future work)
- How can NVG framework be extended to video generation to ensure temporal consistency by tracking structured regions over time? (Proposed in Section 5.1 for physical-aware video generation)
- Does replacing greedy clustering strategy with optimal transport or graph cuts improve semantic hierarchy of visual granularity sequence? (Authors mention "simple yet efficient greedy strategy" as "initial exploration")

## Limitations

- Single dataset evaluation on ImageNet-256 without validation on other domains or fine-grained datasets
- Claims about semantic clustering quality lack direct ablation beyond reconstruction fidelity improvement
- Technical implementation gaps including unverified 2025 reference for RePA technique
- No analysis of clustering stability or variance across runs

## Confidence

**High Confidence Claims**
- NVG achieves state-of-the-art FID scores on ImageNet-256 compared to VAR baselines
- Multi-granularity tokenization approach is technically novel and produces structured sequences
- Framework supports explicit hierarchical control with structure-aware generation

**Medium Confidence Claims**
- Semantic clustering mechanism meaningfully improves generation quality beyond spatial pyramids
- Residual prediction mechanism is superior to teacher-forcing for preventing overfitting
- Structure generator being smaller is optimal

**Low Confidence Claims**
- Structure embeddings capture interpretable semantic layouts
- Approach generalizes to other domains beyond ImageNet-256
- Scaling behavior demonstrates fundamental advantages of multi-granularity approach

## Next Checks

1. **Semantic Clustering Ablation**: Train NVG variant using VAR-style spatial downsampling instead of feature-space clustering. Compare not just FID but also semantic consistency metrics to isolate clustering mechanism contribution.

2. **Teacher-Forcing Control**: Implement direct next-token prediction baseline for content generator with identical architecture but standard autoregressive training. Compare overfitting curves and final FID to validate residual prediction advantage.

3. **Cross-Domain Generalization**: Evaluate NVG-d20 on CIFAR-10 and FFHQ-256 using ImageNet-trained checkpoint (no fine-tuning). Measure FID degradation and qualitative quality to assess hierarchical structure generalization.