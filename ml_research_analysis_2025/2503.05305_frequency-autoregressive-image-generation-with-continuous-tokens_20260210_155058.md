---
ver: rpa2
title: Frequency Autoregressive Image Generation with Continuous Tokens
arxiv_id: '2503.05305'
source_url: https://arxiv.org/abs/2503.05305
tags:
- generation
- image
- arxiv
- autoregressive
- tokenizer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FAR, a frequency progressive autoregressive
  image generation method that addresses limitations in existing autoregressive approaches.
  FAR leverages spectral dependency in images, generating progressively from low to
  high frequencies, which naturally satisfies autoregressive causality and preserves
  spatial locality.
---

# Frequency Autoregressive Image Generation with Continuous Tokens

## Quick Facts
- **arXiv ID:** 2503.05305
- **Source URL:** https://arxiv.org/abs/2503.05305
- **Reference count:** 40
- **Key outcome:** FAR achieves comparable quality to diffusion models with only 10 inference steps versus 256+ for competitors, while maintaining structural consistency

## Executive Summary
This paper introduces FAR, a frequency progressive autoregressive image generation method that addresses limitations in existing autoregressive approaches. FAR leverages spectral dependency in images, generating progressively from low to high frequencies, which naturally satisfies autoregressive causality and preserves spatial locality. The method combines FAR with continuous tokens, introducing techniques to handle optimization challenges and improve efficiency. Experiments on ImageNet show FAR achieves comparable quality to state-of-the-art methods with only 10 inference steps versus 256+ for competitors, while maintaining structural consistency. FAR also demonstrates strong text-to-image generation capabilities using smaller models and fewer steps.

## Method Summary
FAR uses a frequency-progressive autoregressive approach with continuous tokens. The method decomposes images into frequency levels (low to high) and generates them progressively. A VAE encodes images to continuous latents, which are then decomposed using spectral filtering into F=10 frequency levels. An AR transformer predicts all tokens per frequency level, conditioned on previous levels. A small diffusion MLP head predicts the full image distribution conditioned on current frequency level. The model uses frequency-aware loss weights and mask mechanisms during training, with progressively fewer diffusion sampling steps allocated to earlier frequency levels (40â†’100 steps average 70). The approach is evaluated on ImageNet for class-conditional generation and JourneyDB for text-to-image tasks.

## Key Results
- FAR achieves comparable FID/IS scores to diffusion models while using only 10 inference steps versus 256+ for competitors
- FAR-B/L/H models (172M/406M/791M parameters) demonstrate scalable performance
- The method maintains structural consistency and improves efficiency through frequency-aware training schedules
- FAR shows strong text-to-image generation capabilities on JourneyDB with smaller models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Frequency-progressive generation satisfies autoregressive causality better than raster-scan or random ordering.
- **Mechanism:** The model decomposes images into frequency levels (low to high). It predicts the next frequency level $x_{i+1}$ conditioned on all previous levels $x_{\le i}$, rather than predicting spatially adjacent tokens. This leverages the "spectral dependency" where high-frequency details (edges, textures) naturally build upon low-frequency structures (shapes, colors).
- **Core assumption:** Images possess an inherent hierarchical structure where details are conditionally dependent on global structures, and neural networks exhibit "spectral bias" (learning low frequencies faster).
- **Evidence anchors:**
  - [abstract]: "...generating progressively from low to high frequencies, which naturally satisfies autoregressive causality and preserves spatial locality."
  - [section]: Page 4, Section 4.1 "Spectral dependency... higher-frequency components build upon lower-frequency foundations..."
  - [corpus]: Corpus neighbors (e.g., "Direction-Aware Diagonal...") explore alternative orderings to fix raster-scan issues, validating that regression direction is a critical, unsolved problem in visual AR.

### Mechanism 2
- **Claim:** Modeling the full image distribution $p(x|x_i)$ instead of the residual $p(x_{i+1}|x_i)$ simplifies the optimization of the diffusion loss head.
- **Mechanism:** Instead of forcing a small MLP to learn the complex distribution of a frequency residual, the authors task it with predicting the full image distribution conditioned on the current frequency level $x_i$. The ground truth is then filtered to derive the next step's input.
- **Core assumption:** A small denoising MLP has sufficient capacity to model the full image distribution when conditioned on low-frequency priors, but struggles with the abstract concept of "frequency residuals."
- **Evidence anchors:**
  - [abstract]: "...introducing techniques to handle optimization challenges..."
  - [section]: Page 5, Section 4.2 "We propose to directly model p(x | xi)... This approach simplifies the optimization complexity..."
  - [corpus]: Weak support. While "Fast Autoregressive Models..." discusses continuous latents, it does not explicitly validate this specific "predict-full-then-filter" simplification strategy.

### Mechanism 3
- **Claim:** Frequency-aware mask schedules and diffusion step allocation reduce training cost and accelerate inference.
- **Mechanism:** During training, lower frequency levels (which are information-sparse) use higher mask ratios. During inference, fewer diffusion sampling steps are allocated to low-frequency levels (e.g., 40 steps) vs. high-frequency (e.g., 100 steps).
- **Core assumption:** Low-frequency information (global structure) is easier to synthesize and requires less compute than high-frequency texture.
- **Evidence anchors:**
  - [abstract]: "...addresses limitations... efficiency... 10 inference steps versus 256+ for competitors"
  - [section]: Page 5, Section 4.2 "allocates progressively fewer steps to earlier frequency levels... saves 30% inference time."
  - [corpus]: Weak support. Neighbor papers focus on tokenizer efficiency or architectural parallelism, not dynamic step scheduling based on frequency.

## Foundational Learning

- **Concept: Spectral Bias in Neural Networks**
  - **Why needed here:** FAR relies on the network's tendency to fit low-frequency components before high-frequency ones. Without this, the "low-to-high" regression direction offers no optimization advantage.
  - **Quick check question:** How does the rate of convergence differ when fitting a neural network to a smooth gradient versus a checkerboard pattern?

- **Concept: Autoregressive Causality**
  - **Why needed here:** Standard raster-scan AR violates causality for images (e.g., the top-right pixel depends on the bottom-left in a raster scan). FAR uses frequency to define a strict causal order (you cannot have the detail without the shape).
  - **Quick check question:** In a raster-scan AR model, which spatial pixels does the first pixel of the second row theoretically depend on during inference?

- **Concept: Diffusion as a Loss Function (Diffusion Loss)**
  - **Why needed here:** Unlike discrete AR which uses Cross-Entropy, continuous AR requires modeling a continuous distribution $p(x|z)$. FAR uses a small diffusion model as the loss head instead of a simple MSE.
  - **Quick check question:** Why is a standard L2 loss insufficient for modeling the multi-modal distribution of possible valid image patches for a given context?

## Architecture Onboarding

- **Component map:** Input Image -> VAE -> Spectral Filter ($x_1$) -> AR Transformer -> Diffusion Head (predicts $x$) -> Filter Prediction -> Next Step Input

- **Critical path:** Input Image $\to$ VAE $\to$ Spectral Filter ($x_1$) $\to$ AR Transformer $\to$ Diffusion Head (predicts $x$) $\to$ Filter Prediction $\to$ Next Step Input

- **Design tradeoffs:**
  - **Spatial vs. Fourier Filtering:** Fourier is theoretically cleaner but authors found spatial down/up-sampling to yield similar performance with simpler implementation (Page 11, Section G).
  - **Token Format:** Continuous tokens avoid VQ information loss but require the complexity of a diffusion loss head.
  - **Diversity vs. Consistency:** High mask ratios improve diversity but risk structural inconsistency; the frequency-aware loss weights balance this.

- **Failure signatures:**
  - **"Washed out" outputs:** Indicates failure to generate high-frequency components (likely insufficient sampling steps or capacity for later levels).
  - **Geometric hallucination:** Indicates failure in early low-frequency steps (spectral filter or AR transformer failing to capture global structure).
  - **Artifacts with RQ:** The paper explicitly warns that combining VAR (Residual Quantization) with continuous tokens causes severe artifacts (Page 7, Table 4).

- **First 3 experiments:**
  1. **Filter Ablation:** Compare image quality when using simple down/up-sampling vs. strict Fourier masking to verify spectral dependency.
  2. **Loss Simplification:** Compare training convergence when predicting $p(x_{i+1}|x_i)$ (residual) vs. $p(x|x_i)$ (full image) to validate the optimization trick.
  3. **Inference Scaling:** Plot FID/IS vs. inference steps (e.g., 4, 6, 10 steps) to demonstrate the efficiency of the frequency-progressive schedule.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the FAR framework be modified to improve generative diversity (Recall) and close the performance gap in FID compared to standard diffusion models?
- **Basis in paper:** [explicit] The authors explicitly note in the results section that "the lag in the FID metric is attributed to the slightly lower diversity (indicated by the Recall metric)."
- **Why unresolved:** While the mask mechanism improves diversity over the baseline, the fundamental frequency progression or the specific diffusion loss simplification may still constrain the mode coverage of the learned distribution.
- **What evidence would resolve it:** An ablation study introducing stochasticity mechanisms or architectural changes that successfully increase the Recall score without degrading the Inception Score (IS) or Precision.

### Open Question 2
- **Question:** Can FAR maintain its efficiency advantages (10 steps) and spectral consistency when scaled to the massive model sizes and web-scale datasets used by state-of-the-art text-to-image models?
- **Basis in paper:** [inferred] The paper states it "does not intend to demonstrate that FAR achieves cutting-edge performance" in T2I, utilizing "much smaller model size, data scale, [and] training compute" than competitors like SD3 or Parti.
- **Why unresolved:** It is unclear if the spectral dependency prior and the small diffusion MLP (used for per-token distribution) scale effectively to capture the complex latent distributions of multi-billion parameter models.
- **What evidence would resolve it:** Training results from a FAR model scaled to ~1B+ parameters on a dataset of billions of image-text pairs, comparing sample quality and efficiency against contemporary large-scale diffusion or flow models.

### Open Question 3
- **Question:** Does the strategy of predicting the full target image distribution $p(x|x_i)$ at every step, rather than the frequency residual, limit the model's capacity to learn precise, high-frequency corrections?
- **Basis in paper:** [inferred] The paper proposes simplifying the optimization target from $p(x_{i+1}|x_i)$ to $p(x|x_i)$ (followed by filtering) to ease optimization, but does not analyze if this "relaxation" introduces capacity redundancy or limits fine-grained detail refinement.
- **Why unresolved:** Predicting the full image at every frequency level requires the model to re-predict low-frequency information that is already known, potentially wasting model capacity that could be used for high-frequency details.
- **What evidence would resolve it:** A comparison of convergence speed and high-frequency detail fidelity between the current implementation and a variant explicitly trained to predict the frequency residual (difference) at each step.

## Limitations
- The spectral decomposition mechanism relies on neural networks' spectral bias without rigorous empirical validation
- Experimental comparisons to other autoregressive methods are limited to relatively few baselines
- Text-to-image results are presented primarily on GenEval without comprehensive human evaluation
- Interaction issues between continuous tokens and discrete tokenizers like VAR are acknowledged but not fully resolved

## Confidence
**High Confidence:** The core mechanism of frequency-progressive generation (Mechanism 1) and its empirical demonstration on ImageNet (achieving competitive FID/IS with ~10 steps versus 256+ for competitors) are well-supported by experimental results.

**Medium Confidence:** The optimization simplification (Mechanism 2 - predicting full distribution vs. residual) and the efficiency gains from frequency-aware step allocation (Mechanism 3) are logically sound but have limited ablation evidence.

**Low Confidence:** The text-to-image generation capabilities and the handling of continuous tokens with diffusion loss heads are less thoroughly validated, with limited comparative analysis against specialized text-to-image models.

## Next Checks
1. **Spectral Bias Validation:** Design a controlled experiment comparing training convergence rates for networks fitting low-frequency versus high-frequency image components directly to empirically verify the foundational assumption.

2. **Full vs. Residual Prediction Ablation:** Implement and compare two variants - one predicting $p(x_{i+1}|x_i)$ (residual) and another predicting $p(x|x_i)$ (full distribution) - while controlling for all other variables.

3. **Hybrid Tokenizer Analysis:** Investigate the artifact issues mentioned when combining VAR with continuous tokens through systematic experiments varying quantization granularity and diffusion MLP capacity.