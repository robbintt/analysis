---
ver: rpa2
title: Rule-Based Moral Principles for Explaining Uncertainty in Natural Language
  Generation
arxiv_id: '2509.07190'
source_url: https://arxiv.org/abs/2509.07190
tags:
- uncertainty
- rule
- system
- language
- moral
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper proposes a rule-based moral principles framework for\
  \ explaining uncertainty in LLM-generated text, addressing the limitations of probabilistic\
  \ methods in high-stakes applications. Instead of relying on opaque numerical confidence\
  \ scores, the framework maps qualitative uncertainty levels (low, medium, high)\
  \ to three symbolic ethical rules\u2014precaution, deference, and responsibility\u2014\
  each with a plain-language rationale."
---

# Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation

## Quick Facts
- **arXiv ID:** 2509.07190
- **Source URL:** https://arxiv.org/abs/2509.07190
- **Reference count:** 40
- **Key outcome:** Rule-based moral principles framework maps qualitative uncertainty levels to symbolic ethical rules (precaution, deference, responsibility) with plain-language rationales, implemented in Prolog engine, achieving 100% coverage but 50% tagging accuracy.

## Executive Summary
This paper proposes a rule-based moral principles framework for explaining uncertainty in LLM-generated text, addressing the limitations of probabilistic methods in high-stakes applications. Instead of relying on opaque numerical confidence scores, the framework maps qualitative uncertainty levels (low, medium, high) to three symbolic ethical rules—precaution, deference, and responsibility—each with a plain-language rationale. These rules are implemented in a lightweight Prolog engine and evaluated through scenario-based simulations in clinical and legal domains. Results show 100% coverage and strong interpretability, though tagging accuracy is 50% and fairness gaps exist. The approach offers a transparent, virtue-aligned alternative to probabilistic uncertainty modeling.

## Method Summary
The framework operates through a pipeline: LLM generates k=5 completions at temperature 0.7, a heuristic-based uncertainty tagger assigns qualitative tags (low/medium/high) using variance, log-probability, and hedge detection, then a Prolog rule engine maps each tag to an ethical action (e.g., warn_and_refer, partial_answer_with_reference) and rationale. The system is evaluated on 20 synthetic prompts (10 clinical, 10 legal) with demographic identifiers, measuring coverage, tagging accuracy, fairness gaps, and readability.

## Key Results
- 100% coverage achieved with Prolog rule engine mapping uncertainty tags to actions
- 50% tagging accuracy on 20 synthetic prompts, with errors clustered at medium-high boundary
- Fairness gap reduced from 0.25 to 0.00 through demographic masking
- Flesch-Kincaid readability score of 39.2 indicates rationales may be too complex for non-experts

## Why This Works (Mechanism)

### Mechanism 1: Virtue-to-Rule Operationalization
Abstract ethical virtues can be systematically mapped to executable behavioral rules that govern LLM responses under uncertainty. Hagendorff's six AI virtues (justice, honesty, responsibility, care, prudence, fortitude) are operationalized as pathway mappings linking detected uncertainty levels to rule-driven actions. For example, "Justice → high uncertainty → Precaution rule → direct warning" creates a deterministic ethical response pattern.

### Mechanism 2: Qualitative Uncertainty Tagging with Symbolic Action Triggers
Replacing numerical confidence scores with three discrete uncertainty categories (low, medium, high) enables transparent, rule-based response generation. The uncertainty tagger uses surface-level heuristics—variance across completions, average token-level log-probability, and epistemic markers (e.g., "might," "possibly")—to assign qualitative tags. The Prolog engine then maps each tag to an action via declarative rules: `action(high, warn_and_refer)`, `action(medium, partial_answer_with_reference)`, `action(low, full_answer_with_disclaimer)`.

### Mechanism 3: Demographic Masking for Fairness Correction
Input-level demographic masking can eliminate measured fairness gaps in rule-triggered actions. When demographic tokens (e.g., "female, 70") co-occur with domain terms, the tagger may produce biased action distributions. Replacing demographic labels with generic placeholders ("unknown") removes this signal, reducing the fairness gap (Δ) from 0.25 to 0.00 in experiments.

## Foundational Learning

- **Epistemic vs. Aleatoric vs. Ontological Uncertainty**: Why needed here: The framework's rule mappings depend on understanding uncertainty type. Epistemic uncertainty (incomplete knowledge) may trigger deference; aleatoric uncertainty (intrinsic randomness) may trigger precaution; ontological uncertainty (fundamental unknowability) requires acknowledgment of limits. Quick check: A medical diagnosis with sparse patient data represents which uncertainty type? (Answer: Primarily epistemic—more data could reduce it.)

- **Prolog Declarative Logic Programming**: Why needed here: The rule engine is implemented in SWI-Prolog. Understanding how facts (`action/2`), rules, and queries work is essential for modifying the ethical behavior. Quick check: In Prolog, what does `action(high, warn_and_refer).` define? (Answer: A fact stating that high uncertainty maps to the warn_and_refer action.)

- **Virtue Ethics Operationalization**: Why needed here: The framework draws on Hagendorff's six AI virtues rather than consequentialist or deontological frameworks. Understanding how virtues become dispositions helps interpret why the system behaves as it does under uncertainty. Quick check: Why might "prudence" trigger the deference rule rather than precaution? (Answer: Prudence focuses on downstream consequences, favoring expert consultation over immediate action when information is incomplete.)

## Architecture Onboarding

- **Component map:** User Query → LLM (GPT-4o, temp=0.7, k=5 completions) → Uncertainty Tagger (Python, heuristic-based) → Prolog Rule Engine (SWI-Prolog v9.3, <200 lines) → Explanation Module (combines LLM output + rationale) → User Response

- **Critical path:** The `action/2` and `rationale/2` predicates in Prolog are the single point where ethical policy is enforced. Any modification to system behavior requires editing these declarative clauses only—no model retraining needed.

- **Design tradeoffs:**
  - **Coverage vs. Accuracy:** 100% coverage (no silent failures) traded for 50% tagging accuracy
  - **Transparency vs. Nuance:** Three discrete categories sacrifice granularity for interpretability
  - **Latency vs. Fairness:** Counterfactual consistency checks reduce fairness gap to 6% but double inference time; masking is faster but removes potentially useful signal

- **Failure signatures:**
  - Tagging errors cluster at medium-high boundary (see Table V: "may not be reliable" tagged medium when oracle says low)
  - Fairness gap emerges when demographic tokens co-occur with risk terms
  - Flesch-Kincaid score of 39.2 indicates rationales may be too complex for non-expert users

- **First 3 experiments:**
  1. **Entropy-ablated tagging:** Add 10-token sliding-window entropy measure to the tagger; paper suggests this raises accuracy from 50% to 64% with only 0.3ms latency increase. Implement and validate on held-out scenarios.
  2. **Conditional demographic masking:** Implement domain-aware masking that suppresses protected attributes only when not clinically/legally salient. Compare fairness gaps against unconditional masking.
  3. **Readability template library:** Replace current rationale templates with controlled-language versions targeting Flesch-Kincaid score of 55+. Measure whether brevity still supports informed consent in simulated clinical scenarios.

## Open Questions the Paper Calls Out

- **Can hybrid approaches combining the symbolic rule engine with contextual embeddings or entropy-based measures significantly improve tagging accuracy without sacrificing transparency?** The authors state the current 50% accuracy "points to the need for richer lexical cues or supplementary entropy-based heuristics" and propose "hybrid approaches." This remains unresolved as the current implementation relies on shallow lexical heuristics which misclassify uncertainty (particularly distinguishing medium from high) in 50% of cases.

- **How can "conditional masking" be implemented to mitigate fairness gaps without removing clinically or legally salient demographic information?** Section V notes that while simple demographic masking fixes the fairness gap, it removes information that can be "legitimately predictive in certain contexts" and suggests future work explore conditional masking. Current masking is binary (on/off); the system currently lacks the nuance to mask protected attributes only when they are not salient to the domain logic.

- **Does the current brevity of system rationales (0.11 completeness ratio) suffice for informed consent in high-stakes domains?** Section V states that the compact explanations are advantageous for mobile interfaces, but "a user study will be needed to verify whether this brevity suffices for informed consent in clinical contexts." The current evaluation is simulation-based; actual user comprehension and perceived trustworthiness of these short rationales are unverified.

## Limitations

- **Low tagging accuracy:** The 50% accuracy on 20 synthetic prompts may not generalize to real-world inputs with different linguistic patterns.
- **Fairness masking trade-off:** Demographic masking reduces fairness gaps to zero but may remove clinically/legally necessary information, requiring conditional masking that hasn't been validated.
- **Conflict resolution unclear:** The system's behavior under conflicting virtues (e.g., prudence vs. responsibility) is not addressed, potentially limiting its applicability in complex ethical scenarios.

## Confidence

- **High:** The rule-based framework provides 100% coverage and interpretable ethical rationales, offering a transparent alternative to probabilistic confidence scores.
- **Medium:** Demographic masking effectively reduces fairness gaps, though its impact on decision quality in real-world scenarios remains untested.
- **Low:** The 50% tagging accuracy may not generalize to diverse real-world inputs, and the system's performance under conflicting virtues is unclear.

## Next Checks

1. **Real-world input validation:** Test the framework on a larger, more diverse dataset of real-world prompts to assess tagging accuracy and fairness gaps in practical scenarios.
2. **Conditional demographic masking:** Implement and validate domain-aware masking to ensure protected attributes are suppressed only when not clinically/legally salient, preserving decision quality.
3. **Conflicting virtues resolution:** Evaluate the system's behavior when multiple virtues conflict (e.g., prudence vs. responsibility) and assess whether the rule mappings produce coherent ethical guidance.