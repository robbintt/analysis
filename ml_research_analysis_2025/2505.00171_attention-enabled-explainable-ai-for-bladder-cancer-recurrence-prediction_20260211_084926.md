---
ver: rpa2
title: Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction
arxiv_id: '2505.00171'
source_url: https://arxiv.org/abs/2505.00171
tags:
- recurrence
- data
- attention
- prediction
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of non-muscle-invasive bladder
  cancer (NMIBC) recurrence prediction, where current tools show poor accuracy (0.55-0.61
  concordance index) and lack personalized insights. The authors propose a deep learning
  framework integrating vector embeddings and attention mechanisms to improve both
  prediction performance and interpretability.
---

# Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction

## Quick Facts
- arXiv ID: 2505.00171
- Source URL: https://arxiv.org/abs/2505.00171
- Reference count: 26
- Primary result: 70% accuracy on NMIBC recurrence prediction, outperforming conventional statistical methods

## Executive Summary
This paper addresses the challenge of predicting non-muscle-invasive bladder cancer (NMIBC) recurrence, where current tools show poor accuracy (0.55-0.61 concordance index) and lack personalized insights. The authors propose a deep learning framework integrating vector embeddings and attention mechanisms to improve both prediction performance and interpretability. Vector embeddings capture complex relationships between categorical variables like smoking status and intravesical treatments, while attention mechanisms highlight the most influential features for each patient. The model achieves 70% accuracy on tabular data, outperforming conventional statistical methods and identifying new predictive factors such as surgical duration and hospital stay.

## Method Summary
The method uses a neural network with trainable vector embeddings for categorical variables, followed by a feature-level attention mechanism and dense layers with ReLU, dropout, and batch normalization. The model was trained on 356 patients (after SMOTE) from the PHOTO RCT trial, with 23 variables including tumor characteristics, smoking history, surgical time, and hospital stay. The attention mechanism computes patient-specific feature weights using learnable parameters with softmax normalization, enabling interpretable risk stratification. Hyperparameter optimization was performed via Optuna framework.

## Key Results
- 70% accuracy achieved on NMIBC recurrence prediction, outperforming Logistic Regression (52%), Feedforward NN (55%), and TabNet (63%)
- Identified new predictive factors including surgical duration and hospital stay, not captured by conventional statistical models
- Attention-based explanations provide clinician-friendly, patient-specific insights into recurrence risk

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Vector embeddings capture semantic hierarchies in categorical clinical data better than one-hot encoding.
- **Mechanism:** By mapping categorical variables into a continuous hyper-dimensional vector space, the model learns distance metrics where categories with similar recurrence risk profiles organize spatially.
- **Core assumption:** Clinical categories possess latent "semantic" relationships (severity or risk gradients) that are linearly or geometrically representable in vector space.
- **Evidence anchors:**
  - [Section III.B]: "...embeddings map categories into a hyper-dimensional vector space, capturing subtle hierarchies..."
  - [Section III.B]: Fig. 1 visualizes this 3D space, showing "Never" smokers farthest from the origin (lowest risk) and "Current" closest.
- **Break condition:** If categorical variables are purely nominal with no intrinsic ordinal or risk relationship, embeddings offer little advantage over one-hot encoding.

### Mechanism 2
- **Claim:** Feature-level attention mechanisms enable dynamic, patient-specific risk stratification.
- **Mechanism:** An additive attention module computes scalar alignment scores for each feature embedding, normalizing them via softmax into weights that create a weighted sum where the model selectively amplifies specific features for a specific individual's prediction.
- **Core assumption:** The predictive importance of a clinical feature varies significantly between patients rather than being static across a population.
- **Evidence anchors:**
  - [Section III.C]: "For example, a patient with extensive smoking history may elicit larger α_i values for smoking-related variables..."
  - [Section IV.C]: "In patient 1, the model focuses on age... whereas for patient 2, it prioritizes the number of cigarettes..."
- **Break condition:** If features are uniformly informative across all patients, attention weights will flatten to uniform values.

### Mechanism 3
- **Claim:** Integration of non-clinical procedural features (surgical duration, hospital stay) via deep learning uncovers latent risk factors.
- **Mechanism:** The deep network combines these continuous variables with clinical embeddings, detecting interactions between procedure logistics and recurrence risk that linear statistical models miss.
- **Core assumption:** Procedural factors act as proxies for case complexity or physiological stress, which correlate with recurrence susceptibility.
- **Evidence anchors:**
  - [Abstract]: "...identifying new predictive factors such as surgical duration and hospital stay..."
  - [Section IV.B]: "Surgical time, age, and total cigarettes smoked emerge as the three most influential factors."
- **Break condition:** If these features correlate strongly with a confounder not in the dataset rather than the outcome itself, the model learns spurious correlations.

## Foundational Learning

- **Concept: Vector Embeddings (nn.Embedding)**
  - **Why needed here:** Essential to move beyond one-hot encoding by mapping integer indices representing categories to dense vectors that capture the "distance" between risk factors.
  - **Quick check question:** If "Smoker" is index 1 and "Non-Smoker" is index 2, how does an embedding layer prevent the model from thinking 2 is "twice" 1?

- **Concept: Additive Attention (Bahdanau-style)**
  - **Why needed here:** The paper uses a specific attention formulation (s_i = w^T tanh(Wx + b)) that learns a "search" query over input features.
  - **Quick check question:** In this architecture, what acts as the "query" that the features are attending to?

- **Concept: SMOTE (Synthetic Minority Over-Sampling Technique)**
  - **Why needed here:** The paper uses a 40/60 split and applies SMOTE to balance classes by generating synthetic samples through interpolation.
  - **Quick check question:** Why might SMOTE be dangerous if the minority class samples are outliers rather than a tight cluster?

## Architecture Onboarding

- **Component map:** Input Layer (Categorical → Embedding Layers; Numerical → Normalization; Binary → Passthrough) → Fusion Layer (Concatenation) → Attention Block (Linear → tanh → Linear → Softmax) → Weighting (Element-wise multiplication) → Predictor (Dense Layers with ReLU, Dropout, BatchNorm → Sigmoid Output)
- **Critical path:** The dimensionality of the Embedding Layers - too low loses subtle risk gradients, too high causes overfitting on small dataset.
- **Design tradeoffs:**
  - Listwise Deletion vs. Imputation: Authors chose to drop missing data (reducing n from 500 to 296) rather than impute, guaranteeing data integrity but sacrificing statistical power.
  - Interpretability vs. Complexity: Custom attention block allows patient-specific heatmaps but may underperform optimized "black box" Gradient Boosting on pure accuracy.
- **Failure signatures:**
  - Attention Collapse: Heatmap shows uniform grey bars for all patients, indicating attention mechanism failed to learn distinct priorities.
  - Embedding Cluster: Visualization (t-SNE/PCA) of embeddings shows random scattering rather than risk-based clustering.
- **First 3 experiments:**
  1. Baseline vs. Attention: Train two models—one with attention block ablated (replaced by Dense layer) and one with it. Compare validation accuracy to quantify performance "cost" of interpretability.
  2. Embedding Dimensionality Sweep: Run Optuna to find optimal embedding dimension for "Smoking Status" and "Intravesical Treatment" features specifically.
  3. Feature Perturbation: Systematically shuffle "Surgical Time" during inference to validate claim that it is a top predictor.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do attention-based feature importance rankings compare to post-hoc explainability methods like SHAP or LIME for this specific model?
- **Basis in paper:** Authors state they "plan to explore [SHAP] in future work to validate and compare against the attention-based rankings."
- **Why unresolved:** Current study relies exclusively on integrated attention weights without benchmarking against established post-hoc explanation tools.
- **What evidence would resolve it:** Comparative analysis of feature attribution consistency between model's internal attention weights and SHAP value calculations on same patient cohort.

### Open Question 2
- **Question:** Does integration of genomic or imaging biomarkers significantly enhance predictive fidelity over current tabular-only framework?
- **Basis in paper:** Authors list "incorporating genomic or imaging biomarkers" as specific direction for future work.
- **Why unresolved:** Current model limited to clinical, demographic, and lifestyle tabular data, omitting biological imaging or molecular data.
- **What evidence would resolve it:** Performance metrics (accuracy, C-index) of multi-modal version including pathology images or genomic sequences compared to tabular baseline.

### Open Question 3
- **Question:** Can inherently interpretable models like Tsetlin Machine provide comparable prediction accuracy while offering more transparent, rule-based explanations?
- **Basis in paper:** Authors propose exploring "inherently interpretable models, such as the Tsetlin Machine."
- **Why unresolved:** Unknown if logic-based approaches can match 70% accuracy of neural architecture on this complex dataset.
- **What evidence would resolve it:** Benchmark study comparing accuracy and clinical utility of Tsetlin Machine's propositional rules against attention-based neural network.

## Limitations

- Small sample size (n=356 post-SMOTE) constrains generalizability of embedding-based semantic relationships and attention-based feature importance scores.
- Critical architectural details underspecified (embedding dimensions, layer counts, hyperparameters), making exact reproduction difficult.
- Clinical interpretability claims rely on qualitative heatmaps without validation against ground-truth causal mechanisms.

## Confidence

- **High confidence:** Fundamental approach of combining embeddings with attention for tabular data is well-established and performance improvement over baselines is demonstrated.
- **Medium confidence:** Identification of new predictive factors (surgical duration, hospital stay) appears supported by data, though causal interpretation requires caution.
- **Low confidence:** Semantic hierarchy captured by embeddings for categorical variables is primarily theoretical with limited empirical validation beyond visualization.

## Next Checks

1. Perform ablation studies comparing attention-enabled model against identical architecture without attention to quantify interpretability "cost" in accuracy.
2. Validate attention-based feature importance through patient-out perturbation experiments - systematically shuffling each top feature and measuring accuracy drop.
3. Test model generalization by training on one hospital's data and evaluating on another's, given procedural features' potential site-specific nature.