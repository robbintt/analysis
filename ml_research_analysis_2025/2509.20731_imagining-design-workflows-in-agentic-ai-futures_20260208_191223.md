---
ver: rpa2
title: Imagining Design Workflows in Agentic AI Futures
arxiv_id: '2509.20731'
source_url: https://arxiv.org/abs/2509.20731
tags:
- design
- designers
- could
- agents
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated designers' expectations and needs regarding
  agentic AI integration into design workflows, particularly for inspiration gathering
  and ideation. Using design fiction and a novel "Flip-Flap story cards" method, ten
  professional designers imagined collaborating with an AI agent (Idy) in a creativity
  platform (I-space).
---

# Imagining Design Workflows in Agentic AI Futures

## Quick Facts
- arXiv ID: 2509.20731
- Source URL: https://arxiv.org/abs/2509.20731
- Reference count: 40
- Primary result: Designers envision AI agents playing multiple roles (coordinator, resource steward, reframer, guardian, creative catalyst) depending on task complexity, preferring AI to handle routine tasks while retaining creative control.

## Executive Summary
This study investigates how professional designers envision collaborating with agentic AI in design workflows, specifically for inspiration gathering and ideation. Using design fiction and a novel "Flip-Flap story cards" method, ten designers imagined working with an AI agent (Idy) in a creativity platform (I-space). The research reveals designers prefer AI to handle routine tasks while retaining creative control, and desire multimodal interactions beyond text prompts. A conceptual framework was developed to guide human-AI collaboration by mapping authority, agency, and involvement dimensions. The findings highlight the importance of adaptable, context-aware AI agents that support rather than replace designers' creative processes.

## Method Summary
The study employed a design fiction approach with ten professional designers (5 male, 5 female) recruited from large enterprises. Participants engaged in one-hour one-on-one sessions using 21 "Flip-Flap" story cards depicting scenarios with an AI agent named Idy in a creativity platform called I-space. The cards included narrative frames, flip sections revealing potential solutions, and flip-flap sections for participant critique. Data collection involved think-aloud protocols and post-session worksheets. Analysis used Braun & Clarke's 6-phase reflexive thematic analysis on transcribed sessions, focusing on AI roles, authority distribution, and communication preferences.

## Key Results
- Designers envision AI agents adopting five distinct roles: Coordinator, Resource Steward, Reframer, Guardian, and Creative Catalyst
- Designers prefer AI to handle routine tasks while retaining creative control over high-stakes decisions
- A conceptual framework maps five dimensions (Cognitive Complexity, Degree of Collaboration, Creative Agency, Responsibility, Involvement) to calibrate AI authority
- Participants desire multimodal interactions beyond text prompts, including sketches, annotations, and voice commands

## Why This Works (Mechanism)

### Mechanism 1: Role-Specific Agent Adaptation
If an AI agent dynamically adopts distinct roles (e.g., Coordinator, Steward, Guardian, Reframer, Catalyst) based on the phase of the design workflow, user cognitive load is reduced and trust is maintained compared to a monolithic assistant. The system maps task attributes (e.g., "routine" vs. "creative") to a specific agent persona. For instance, during inspiration gathering, the agent acts as a "Resource Steward" to tag and organize files, whereas during ideation, it switches to "Creative Catalyst" to offer divergent suggestions. This role-switching prevents the AI from overstepping boundaries (e.g., making creative decisions during administrative tasks).

### Mechanism 2: Authority-Agency Alignment Framework
If user control is calibrated along five dimensions (Cognitive Complexity, Degree of Collaboration, Creative Agency, Responsibility, Involvement), the system can autonomously handle mundane tasks while preserving human creative ownership. The system evaluates a task against the framework. For "mundane" tasks (low complexity, low creative agency), the AI acts autonomously. For "creative" tasks (high complexity, high stakes), the AI reduces its "Involvement" and "Creative Agency" to a support role, preventing the "over-reliance" or "fixation" designers fear.

### Mechanism 3: Multimodal Intent Bridging
If an agent accepts multimodal inputs (sketches, annotations, voice) rather than relying solely on text prompts, the "intent gap"—the friction between a designer's visual thought and the AI's output—is significantly reduced. The interface allows designers to circle elements ("annotations") or sketch rough concepts. The agent uses these visual cues as constraints or references, bypassing the need for perfect prompt engineering. This directly addresses the "soft conversations or discussions" text prompts often miss.

## Foundational Learning

**Concept: Agentic AI vs. Generative AI**
Why needed here: The paper pivots from standard GenAI (prompt-response) to Agentic AI (goal-oriented autonomy). Without this distinction, the proposed "roles" and "autonomy" mechanisms make little sense.
Quick check: Does the system execute a single command (GenAI) or plan and execute a workflow to achieve a goal (Agentic)?

**Concept: Design Fiction / Speculative Design**
Why needed here: The methodology uses fictional scenarios ("Idy" in "I-space") to elicit requirements. Understanding this explains why the "mechanisms" are derived from imagined needs rather than A/B testing.
Quick check: Is the data sourced from historical logs or structured imagination of future possibilities?

**Concept: Design Fixation**
Why needed here: This is the core pain point the "Guardian" and "Reframer" roles aim to solve. It refers to the designer getting stuck on an initial idea or existing stimulus.
Quick check: Does the proposed feature help the user diverge (reframe) or converge (fixate)?

## Architecture Onboarding

**Component map:**
Input Layer (Voice, Sketch, Text, Annotations) -> Context Engine (detects design phase) -> Role Orchestrator (assigns persona) -> Authority Controller (enforces permissions) -> Interface (Canvas/UI with AI Lenses)

**Critical path:**
1. User uploads inspiration/inputs (multimodal)
2. Context Engine analyzes input type and project state
3. Role Orchestrator assigns a persona (e.g., "Resource Steward" for messy uploads)
4. Authority Controller checks creative stakes (Low -> Autonomous organization; High -> Wait for approval)
5. Output rendered in UI with version history tracking ("Guardian" function)

**Design tradeoffs:**
- Context Awareness vs. Privacy: To act as a "Guardian," the agent must monitor all browsing/activity. The tradeoff is user privacy vs. proactive assistance.
- Proactivity vs. Flow: A "Reframer" must interrupt to be useful. If timing is wrong, this breaks flow.
- Multimodality vs. Interpretability: Allowing sketches increases input bandwidth but introduces ambiguity in interpretation.

**Failure signatures:**
- "Helicopter Agent": The AI interrupts high-stakes creative synthesis with unsolicited "Catalyst" suggestions (Failure of Authority Controller)
- "Amnesia Loop": The agent fails to recall previous context or assets, forcing the designer to re-upload or re-explain intent (Failure of Guardian role)
- "Generic Output": The system ignores visual annotations and defaults to generic text-based image generation (Failure of Multimodal Intent)

**First 3 experiments:**
1. Role Validation: Prototype the "Resource Steward" only. Measure time saved on file organization vs. manual sorting. (Validates Mechanism 1)
2. Authority Slider: Build a UI toggle for "Creative Agency" (Low to High). Test if users prefer "Suggest" mode over "Auto-execute" for image generation. (Validates Mechanism 2)
3. Annotation Parsing: Compare the accuracy of "sketch-based refinement" vs. "text-prompt refinement" for a specific UI element. (Validates Mechanism 3)

## Open Questions the Paper Calls Out

**Open Question 1:** How does the proposed conceptual framework for authority distribution affect the efficiency and creative quality of outcomes in live design projects?
Basis in paper: [explicit] The authors state, "In future research, we aim to validate and test our framework... and identify the effects of A-AICSTs on the design process."
Why unresolved: The current study utilized design fiction and speculative methods rather than deploying functional agents in real-world workflows.
What evidence would resolve it: Empirical data from field studies or controlled experiments where designers use functional agentic tools structured by this framework.

**Open Question 2:** Which specific multimodal interaction techniques (e.g., sketching, voice, annotations) most effectively convey design intent to agentic AI compared to text prompts?
Basis in paper: [explicit] The authors propose a design direction to "Deploy AI agents capable of interpreting multimodal inputs... and provide scaffolding," but did not test these interfaces.
Why unresolved: The study identified the need for multimodality through user preferences but did not implement or evaluate specific technical solutions.
What evidence would resolve it: Usability studies measuring task alignment, cognitive load, and communication friction when designers use multimodal vs. text-based inputs.

**Open Question 3:** How do expectations of agentic AI roles (such as "Guardian" or "Reframer") differ for freelance designers or those in small-to-medium enterprises compared to the large-enterprise context studied?
Basis in paper: [inferred] The authors note a limitation that the participant sample was restricted to one country and large enterprises, suggesting the findings may not be fully representative.
Why unresolved: The specific needs and agency preferences of designers in different organizational structures and cultural contexts remain unexplored.
What evidence would resolve it: Replicating the study with a diverse participant pool including freelancers and SMEs to compare desired AI roles and authority levels.

## Limitations
- Small sample size of ten professional designers limits generalizability
- "Flip-Flap" story cards may have constrained participants' imaginations rather than eliciting truly novel requirements
- Findings focus specifically on inspiration gathering and ideation phases, leaving unclear how they apply to other design stages
- Authority-agency framework lacks empirical validation through actual implementation and testing

## Confidence

**High Confidence:** The identification of distinct AI agent roles (Coordinator, Steward, Guardian, Reframer, Catalyst) and designers' preference for AI to handle routine tasks while retaining creative control. These findings are well-supported by participant quotes and align with established design practice concerns.

**Medium Confidence:** The 5-dimensional authority framework and its proposed mapping to task attributes. While theoretically coherent and grounded in participant feedback, the framework's practical utility and robustness across different design contexts remain untested.

**Low Confidence:** The multimodal interaction mechanisms and their specific implementation details. The paper provides limited evidence that designers can effectively communicate intent through sketches and annotations, and the technical feasibility of such systems is not demonstrated.

## Next Checks

1. **Role Validation Through Implementation:** Develop a prototype implementing one specific AI role (e.g., Resource Steward for file organization) and measure actual time savings and user satisfaction compared to manual methods. This would validate whether the theoretical role actually delivers practical benefits.

2. **Framework Testing in Varied Contexts:** Apply the 5-dimensional authority framework to different design tasks beyond inspiration gathering and ideation (e.g., prototyping, user testing) to test its generalizability and identify edge cases where the framework breaks down.

3. **Multimodal Intent Interpretation Accuracy:** Build a proof-of-concept system that accepts sketches and annotations as inputs and measure the accuracy of intent interpretation compared to text-only prompts across multiple design tasks. This would validate whether multimodal inputs genuinely reduce the intent gap.