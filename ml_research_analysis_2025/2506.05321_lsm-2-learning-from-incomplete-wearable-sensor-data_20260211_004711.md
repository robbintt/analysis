---
ver: rpa2
title: 'LSM-2: Learning from Incomplete Wearable Sensor Data'
arxiv_id: '2506.05321'
source_url: https://arxiv.org/abs/2506.05321
tags:
- data
- sensor
- missingness
- learning
- wearable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LSM-2 with Adaptive and Inherited Masking
  (AIM), a novel self-supervised learning approach that learns robust representations
  directly from incomplete wearable sensor data without requiring explicit imputation.
  The method uses learnable mask tokens to model both existing and artificially introduced
  missingness, enabling robust handling of fragmented real-world data during inference.
---

# LSM-2: Learning from Incomplete Wearable Sensor Data

## Quick Facts
- arXiv ID: 2506.05321
- Source URL: https://arxiv.org/abs/2506.05321
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on diverse tasks with less than 27% performance degradation under targeted missingness scenarios

## Executive Summary
LSM-2 with Adaptive and Inherited Masking (AIM) introduces a self-supervised learning approach that learns robust representations directly from incomplete wearable sensor data without requiring explicit imputation. The method uses learnable mask tokens to model both existing and artificially introduced missingness, enabling robust handling of fragmented real-world data during inference. Pre-trained on 40 million hours of day-long multimodal sensor data, LSM-2 with AIM achieves state-of-the-art performance across diverse tasks including classification, regression, and generative modeling.

## Method Summary
LSM-2 employs a ViT-1D encoder-decoder architecture (25M params) trained with Adaptive and Inherited Masking (AIM) on day-long multimodal wearable sensor sequences. The method processes 1440-minute sequences with 26 features from 5 sensors, using 10-minute patches to create 3744 tokens. AIM combines inherited masks (marking pre-existing missingness) with artificial masks (80% random, 50% temporal slice, or 50% sensor slice strategies) through a hybrid approach that uses fixed dropout for efficiency and attention masking for flexibility. The model reconstructs only artificially masked positions while learning to semantically encode missingness through shared mask tokens.

## Key Results
- Achieves state-of-the-art performance across classification, regression, and generative modeling tasks
- Demonstrates superior scaling performance with less than 27% degradation across all 12 ablation settings
- Shows particular excellence at long-term context tasks like hypertension prediction with nocturnal advantages
- Maintains high performance under targeted missingness scenarios with less than 27% degradation

## Why This Works (Mechanism)

### Mechanism 1: Inherited Masking with Learnable Tokens
Representing existing missingness as learned mask tokens enables the model to handle real-world data gaps without imputation artifacts. The inherited mask directly marks pre-existing missing data positions, receiving shared learnable mask tokens trained alongside artificial masks. This teaches the model to semantically encode "missingness" rather than interpolate through it.

### Mechanism 2: Adaptive Attention-Dropout Hybrid
Combining fixed-ratio dropout removal with flexible attention masking enables efficient processing of variable-length inherited masks. Standard MAE dropout assumes fixed mask counts, but inherited masks vary per sample. AIM sets D=0.5N as a fixed dropout lower bound, then uses attention masking to suppress additional inherited mask tokens.

### Mechanism 3: Mixed Artificial Masking Strategy
Training with diverse mask types improves generalization to heterogeneous missingness patterns in real deployments. Three complementary strategies model distinct real-world causes: (1) 80% random masking for sensor noise, (2) 50% temporal slices for device off-body, (3) 50% signal slices for individual sensor disabled.

## Foundational Learning

- **Masked Autoencoders (MAE)**: Understanding baseline MAE is prerequisite as AIM extends this framework by adding inherited masks and hybrid masking. Quick check: In standard MAE, why are masked tokens dropped before encoding rather than processed with a mask embedding?

- **Transformer Attention Masking**: Required to understand how AIM uses attention masks to suppress variable numbers of inherited mask tokens. Quick check: What is the computational complexity difference between processing N tokens with attention masking vs. processing N-D tokens via dropout?

- **Missing Data Mechanisms (MCAR, MAR, MNAR)**: Essential for understanding why wearable missingness is non-random and why imputation approaches fail. Quick check: Why would linear interpolation introduce systematic bias when missingness correlates with user behavior?

## Architecture Onboarding

- **Component map**: Raw sensor data (1440 minutes × 26 features) → 1D ViT patches (10-minute windows → 3744 tokens) → Inherited mask from NaN positions + Artificial mask (mixed strategy) → Adaptive masking (D=0.5N dropout + attention mask) → 12-layer encoder (384 hidden dim) → 4-layer decoder → MSE loss on artificial masks only

- **Critical path**: 1) Identify inherited mask from raw data missingness, 2) Apply artificial mask strategy to observed tokens, 3) Execute adaptive masking with dropout and attention mask, 4) Encode visible tokens, decode with mask tokens reinserted, 5) Compute MSE loss only on artificially masked positions, 6) Downstream: average-pool only non-inherited-masked token embeddings

- **Design tradeoffs**: Efficiency vs. flexibility through D=0.5N dropout cap, minutely aggregation vs. raw signals due to storage constraints, shared kernel vs. sensor-specific encoders ignoring inter-sensor correlations

- **Failure signatures**: Missingness distribution shift causing performance degradation, imputation dependency in baselines leading to artificial superiority, linear probe saturation requiring fine-tuning for certain tasks

- **First 3 experiments**: 1) Visualize learned mask token embeddings vs. data token embeddings, 2) Compare LSM-2 vs. LSM-2-without-inheritance on held-out test data with natural missingness, 3) Replicate Figure 6 experiments removing specific sensors or time windows

## Open Questions the Paper Calls Out

- Can the LSM-2 model generalize effectively to open datasets like All of Us, and how does it handle distribution shifts caused by device-specific missingness patterns?

- How can the modeling framework be extended to capture longer-term physiological periodicities, such as weekly or seasonal patterns, beyond the current day-level context?

- Is the Adaptive and Inherited Masking (AIM) strategy effective when applied directly to raw, high-frequency sensor waveforms rather than pre-aggregated features?

## Limitations

- Reliance on private, massive-scale pre-training data (40 million hours) that cannot be independently verified or reproduced
- Efficiency optimization through fixed dropout (D=0.5N) trades reconstruction fidelity for computational tractability
- Evaluation constrained by availability of only internal datasets with natural missingness patterns

## Confidence

**High Confidence** in: (1) The fundamental problem of missingness in wearable data, (2) Architectural design choices for handling variable missingness, (3) Qualitative observation about nocturnal data for hypertension

**Medium Confidence** in: (1) Superiority over baselines given proprietary datasets, (2) Specific contribution of each AIM component, (3) Robustness claims across 12 ablation settings

**Low Confidence** in: (1) Absolute magnitude of performance improvements without independent replication, (2) Scaling behavior beyond 40M-hour regime, (3) Behavior with unseen sensor types or missingness patterns

## Next Checks

1. **External Dataset Validation**: Apply LSM-2 to an independent public multimodal wearable dataset with natural missingness to verify inherited masking advantage

2. **Missingness Distribution Stress Test**: Systematically vary inference missingness patterns to include types not present in pre-training and measure performance degradation

3. **Fine-tuning vs. Linear Probe Comparison**: For tasks with weaker performance, compare frozen encoder + linear probe versus full fine-tuning to clarify representation quality limitations