---
ver: rpa2
title: 'MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting
  in Malware Classification'
arxiv_id: '2501.01110'
source_url: https://arxiv.org/abs/2501.01110
tags:
- malware
- samples
- replay
- malcl
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MalCL, a generative replay-based continual
  learning system designed to address catastrophic forgetting in malware classification.
  By employing a GAN with feature matching loss and innovative replay sample selection
  schemes, MalCL effectively generates high-quality synthetic malware samples to retain
  knowledge of previously learned malware families while adapting to new ones.
---

# MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting in Malware Classification

## Quick Facts
- **arXiv ID:** 2501.01110
- **Source URL:** https://arxiv.org/abs/2501.01110
- **Reference count:** 4
- **Primary result:** MalCL achieves 55% average accuracy on Windows malware, outperforming prior generative replay models by 28%

## Executive Summary
This paper introduces MalCL, a generative replay-based continual learning system designed to address catastrophic forgetting in malware classification. By employing a GAN with feature matching loss and innovative replay sample selection schemes, MalCL effectively generates high-quality synthetic malware samples to retain knowledge of previously learned malware families while adapting to new ones. Evaluations on Windows (EMBER) and Android (AZ-Class) malware datasets in class-incremental learning scenarios show substantial performance improvements over existing methods. Specifically, MalCL achieves an average accuracy of 55% on Windows malware, outperforming prior generative replay models by 28%. The study also highlights the importance of dataset balance and strategic task set construction for optimizing continual learning performance in malware classification.

## Method Summary
MalCL addresses catastrophic forgetting in malware classification by using a GAN with feature matching loss to generate synthetic malware samples for replay. The system trains a generator and discriminator on each task's data, then uses the classifier's intermediate layer logits to select high-quality replay samples based on L1 distance to per-class mean logit vectors. This approach ensures balanced replay buffers across malware families. The method is evaluated in class-incremental scenarios where new malware families are introduced across multiple tasks, with the model required to classify all observed families at test time.

## Key Results
- MalCL achieves 55% average accuracy on Windows malware (EMBER), outperforming prior generative replay models (GR/BI-R) by 28%
- Strategic task ordering (assigning larger classes to initial tasks) improves accuracy from 55% to 74%
- Feature Matching Loss and per-class replay sample selection (L1 to CMean Logits) are critical components for performance gains
- Dataset imbalance significantly impacts performance, with better results on the more balanced AZ-Class dataset

## Why This Works (Mechanism)

### Mechanism 1
Feature Matching Loss (FML) produces higher-quality synthetic malware samples than standard Binary Cross Entropy (BCE) loss for generative replay. FML extracts intermediate features from the discriminator's hidden layer for both real and synthetic samples, then minimizes the distance between their average representations. This shifts training from optimizing the final discriminator output to matching richer internal feature distributions. Core assumption: Intermediate discriminator features capture malware characteristics more faithfully than binary real/fake discrimination alone. Evidence anchors: Abstract mentions FML for high-quality sample generation; formula (13) defines FML mathematically. Break condition: If discriminator features are too shallow or lack semantic meaning, FML may not improve over BCE.

### Mechanism 2
Selecting replay samples based on L1 distance to per-class mean logit vectors yields better continual learning performance than global selection or label-based selection. The classifier's intermediate layer produces logit representations for each sample. By computing the per-class mean logit vector and selecting synthetic samples with minimum L1 distance to their respective class centroids, replay samples align more closely with original data distributions in the classifier's learned feature space. Core assumption: The classifier's hidden representations form meaningful class clusters where proximity to centroids indicates sample quality. Evidence anchors: Results show L1 to CMean Logits achieved 74% accuracy vs. 55% for previous best; formula (11) defines the selection process. Break condition: Per-batch mean selection (L1 to BMean) failed because it does not enforce per-class balance, leading to mode collapse where some classes receive zero replay samples.

### Mechanism 3
Strategic task ordering—assigning larger classes with more samples to initial tasks—substantially reduces catastrophic forgetting. Early tasks with abundant samples allow the GAN to learn more stable, generalizable feature distributions. These foundational representations persist through subsequent tasks, providing higher-quality replay buffers for originally well-represented classes. Core assumption: Initial task quality dominates replay buffer quality, and larger sample counts yield better generator convergence. Evidence anchors: Results show 74% accuracy when assigning "giant" classes to Task 1 vs. 55% with random ordering; discussion confirms large classes first mitigates CF impact. Break condition: If early large classes are not representative of later distributions, this strategy may bias the model toward initial classes at the expense of generalization.

## Foundational Learning

- **Concept:** Catastrophic Forgetting in Neural Networks
  - **Why needed here:** The entire paper frames MalCL as a solution to CF, where sequential training on new malware families degrades detection of older ones. Without understanding CF, the replay mechanism's purpose is unclear.
  - **Quick check question:** If you train a classifier on Task A (classes 1-50), then Task B (classes 51-55) without replay, what happens to accuracy on classes 1-50?

- **Concept:** Generative Adversarial Networks (GANs) and Mode Collapse
  - **Why needed here:** MalCL uses a GAN for generative replay. Understanding generator-discriminator dynamics and mode collapse (where the generator produces limited sample diversity) is essential for diagnosing replay quality issues.
  - **Quick check question:** Why might a GAN produce synthetic samples for only 10 of 50 malware families, and how does the paper's selection scheme address this?

- **Concept:** Class-Incremental Learning Scenarios
  - **Why needed here:** The paper evaluates MalCL in class-incremental settings where new classes appear across tasks, and the model must classify all observed classes at test time. This differs from task-incremental learning where task identity is known.
  - **Quick check question:** In class-incremental evaluation after Task 3 (classes 1-60), should the model output predictions over 60 classes or only the 5 classes from Task 3?

## Architecture Onboarding

- **Component map:** Generator (G) -> Discriminator (D) -> Classifier (C) -> Replay Selection Module
- **Critical path:** 1. Train GAN on Task i data (Generator Gi, Discriminator Di) 2. Train Classifier Ci on Task i data 3. Generate synthetic samples from Gi 4. Select replay samples using Ci's logits (L1 to per-class mean recommended) 5. For Task i+1: combine replay samples with new data → train Gi+1, Ci+1
- **Design tradeoffs:** FML vs. BCE: FML yields ~2-4% accuracy gain but requires extracting intermediate discriminator features; implementation complexity increases. Per-class vs. global selection: Per-class (L1 to CMean) ensures balanced replay but requires computing class centroids; global (L1 to BMean) is simpler but risks mode collapse. Task ordering: Large classes first improves accuracy (74% vs. 55%) but may not reflect real-world malware emergence patterns.
- **Failure signatures:** Accuracy on early tasks drops sharply (e.g., "None" baseline: 0.6% minimum) → CF not mitigated; check replay buffer quality. Some classes receive zero replay samples → mode collapse; switch from global to per-class selection. Large accuracy variance across random seeds → dataset imbalance; apply task ordering or class balancing.
- **First 3 experiments:** 1. Baseline comparison: Run None, Joint, GR, BI-R, and MalCL on EMBER with random task assignment (50 classes → 5 classes × 10 tasks). Confirm MalCL achieves ~55% mean accuracy vs. GR/BI-R ~27%. 2. Ablate selection scheme: Compare L2 to Labels, L1 to CMean Logits, and L1 to BMean Logits on EMBER. Expect L1 to CMean to outperform; verify per-class coverage (Figure 5 shows BMean produces samples for fewer classes). 3. Task ordering impact: Assign 50 largest classes to Task 1, then random 5-class tasks. Compare accuracy (expect ~74%) against random ordering (~55%). Confirm this closing the gap toward Joint baseline (88.7%).

## Open Questions the Paper Calls Out

### Open Question 1
How can the global selection scheme be improved to overcome mode collapse and generate synthetic samples for all malware classes rather than only a subset? Basis in paper: Authors plan to work on improving the global selection scheme in the future. Why unresolved: The L1 to BMean Logits scheme performed poorly, producing samples for only a few classes, but the authors identified this as a future work direction without proposing a solution. What evidence would resolve it: A modified selection scheme that demonstrably generates balanced samples across all classes, with improved accuracy metrics compared to current global selection.

### Open Question 2
Can hybrid training approaches that merge generative replay with joint training narrow the performance gap between MalCL (55% average accuracy) and the Joint baseline (88.7%)? Basis in paper: Authors aim to develop more advanced generative models and investigate hybrid training approaches that merge the advantages of GR and joint training. Why unresolved: The authors explicitly identify the performance gap with Joint baseline as a promising direction for future research. What evidence would resolve it: A hybrid approach showing statistically significant accuracy improvement over standard MalCL while maintaining privacy advantages over pure joint training.

### Open Question 3
What specific mechanisms could be developed to better handle dataset imbalance in malware classification continual learning? Basis in paper: Dataset imbalance can weaken MalCL's learning retention and accuracy, suggesting the need for strategies to handle class imbalances effectively in CL models. Why unresolved: The paper demonstrates that dataset imbalance negatively affects performance but doesn't propose solutions. What evidence would resolve it: Adaptations to MalCL that maintain consistent performance across datasets with varying class imbalance ratios, measured by per-class accuracy metrics.

### Open Question 4
How can adaptive mechanisms be designed to proactively anticipate and counter shifts in malware tactics in a continual learning framework? Basis in paper: Authors will explore adaptive mechanisms to proactively anticipate and counter shifts in malware tactics, further bolstering MalCL's robustness. Why unresolved: While mentioned as future work, the current system is reactive to new malware rather than anticipatory. What evidence would resolve it: Modified MalCL architecture that predicts emerging malware characteristics and demonstrates improved performance on novel malware families compared to the current reactive approach.

## Limitations

- **Architecture hyperparameters unspecified:** Filter counts, kernel sizes, hidden dimensions, and noise vector size are not detailed, preventing exact reproduction
- **Training configuration gaps:** Training durations, synthetic sample counts per class, replay buffer sizes, and task class ordering seeds are unspecified
- **Code availability:** Implementation code is unavailable until paper presentation, blocking direct validation

## Confidence

- **High:** MalCL improves accuracy over GR/BI-R baselines (55% vs. ~27%) on EMBER and AZ-Class datasets
- **Medium:** Feature Matching Loss provides modest gains (~2-4% accuracy) over BCE; limited ablation in corpus
- **Low:** Task ordering strategy's effectiveness beyond EMBER dataset; no corpus validation for this domain-specific approach

## Next Checks

1. **Ablation on EMBER:** Compare MalCL with Feature Matching Loss, BCE, and baseline GR/BI-R to confirm the reported 55% vs. 27% accuracy gap
2. **Replay Sample Selection:** Evaluate L1 to CMean Logits vs. L1 to BMean Logits on class coverage and per-class accuracy to verify mode collapse prevention
3. **Task Ordering Impact:** Construct task sets with large classes first vs. random assignment on EMBER; measure mean accuracy and verify the 74% vs. 55% difference