---
ver: rpa2
title: Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization
arxiv_id: '2601.12117'
source_url: https://arxiv.org/abs/2601.12117
tags:
- policy
- learning
- optimization
- problem
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses high variance in policy evaluation when some
  treatment propensities are small, which can mislead policy optimization. The authors
  propose a weight-clipping estimator (OCDR) that optimally truncates small propensity
  scores to balance bias-variance trade-off.
---

# Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization

## Quick Facts
- **arXiv ID:** 2601.12117
- **Source URL:** https://arxiv.org/abs/2601.12117
- **Reference count:** 40
- **Primary result:** Proposed OCDRL algorithm outperforms baselines in both computational efficiency and statistical performance, including applications to insurance targeting.

## Executive Summary
This paper addresses the high variance problem in offline policy learning when some treatment propensities are small, which can mislead policy optimization. The authors propose an Optimized Clipped Doubly Robust (OCDR) estimator that optimally truncates small propensity scores to balance bias-variance trade-off. They reformulate the resulting bilevel, discontinuous optimization problem as a Heaviside composite optimization problem and solve it efficiently using a progressive integer programming method. Theoretical analysis shows the OCDR estimator's clipping threshold directly tightens suboptimality bounds in policy learning.

## Method Summary
The method addresses offline policy learning by first splitting data into two parts: one for estimating rewards and another for policy optimization. The OCDR estimator is constructed by optimally clipping inverse propensity scores to minimize empirical MSE. The policy optimization problem is then reformulated as a Heaviside composite optimization problem using upper-semicontinuous approximations of discontinuous indicators. A Progressive Integer Programming (PIP) algorithm solves this problem efficiently by iteratively solving restricted mixed integer programs, fixing most binary variables based on current solution values rather than solving the full problem at once.

## Key Results
- OCDRL algorithm demonstrates superior performance compared to baseline methods in computational efficiency and statistical performance
- The closed-form clipping threshold derived from Proposition 5 enables tractable single-level optimization
- Numerical experiments show effectiveness in insurance targeting applications
- PIP method scales to large sample sizes where standard MIP fails, finding solutions in under 1800 seconds for N ≥ 1500

## Why This Works (Mechanism)

### Mechanism 1: Variance Reduction via Optimized Weight Clipping
Standard doubly robust estimators suffer from variance inflation when inverse propensity scores are large (i.e., propensities are small). The OCDR mechanism truncates these large IPS values using a threshold $\hat{\tau}(g)$ that minimizes the empirical MSE upper bound. This transforms a difficult bilevel optimization into a single-level optimization with a closed-form expression for the clipping threshold.

### Mechanism 2: Discontinuous Optimization via Heaviside Reformulation
The OCDR objective involves indicator functions which are discrete and discontinuous. By expressing these as composite functions involving the Heaviside step function, the paper constructs an upper-semicontinuous approximation. This creates a well-defined optimization landscape where local optimality can be guaranteed.

### Mechanism 3: Scalable Computation via Progressive Integer Programming
A full MIP formulation would require binary variables for every sample and treatment combination, leading to exponential complexity. PIP exploits the structure of the HSCOP by solving a sequence of restricted MIPs where most binary variables are fixed based on the value of the Heaviside function at the current solution.

## Foundational Learning

- **Concept: Inverse Propensity Weighting (IPW) & Doubly Robust (DR) Estimators**
  - Why needed: Understanding that $DR = IPW + ModelCorrection$ is necessary to see why clipping the IPW term affects the MSE
  - Quick check: If a propensity score $e(x) \approx 0$, what happens to the variance of a standard DR estimator? (Answer: It explodes/increases inversely)

- **Concept: Bias-Variance Trade-off in MSE**
  - Why needed: The OCDR estimator explicitly optimizes this trade-off
  - Quick check: Does increasing the clipping threshold $\tau$ increase or decrease the bias of the estimator? (Answer: It increases bias)

- **Concept: Mixed Integer Programming (MIP)**
  - Why needed: The final policy optimization problem is non-convex and discontinuous
  - Quick check: Why is solving a full MIP for large $N$ computationally infeasible? (Answer: The number of binary variables scales with $N$, leading to combinatorial explosion)

## Architecture Onboarding

- **Component map:** Data Splitter -> Reward Estimator -> OCDR Constructor -> HSCOP Formulator -> PIP Solver
- **Critical path:** The derivation of the closed-form $\hat{\tau}(g)$ is the bridge that makes the optimization tractable. Without this, the objective would be bilevel (optimizing policy and tuning hyperparameter), breaking the single-level HSCOP formulation.
- **Design tradeoffs:** The $\delta$ bands in PIP determine how many integer variables are active. Narrower bands make the problem easier but risk missing the true optimal region; wider bands are harder. The update rules control this adaptively.
- **Failure signatures:** High-dimensional covariates may cause overfitting and solver struggles; numerical instability can occur if propensities are extremely close to zero; PIP may stagnate if "in-between" sets remain large.
- **First 3 experiments:**
  1. Generate synthetic data and show that standard DR selects suboptimal policies while OCDR selects the true optimal policy under weak overlap
  2. Plot MSE as a function of clipping threshold $\tau$ and verify the calculated $\hat{\tau}(g)$ aligns with empirical minimum
  3. Vary sample size $N$ and compare wall-clock time and solution quality between standard MIP and PIP

## Open Questions the Paper Calls Out

### Open Question 1
Can the OCDR estimator and its closed-form clipping threshold be adapted to settings where the propensity scores are unknown and must be estimated from the data? The derivation relies on known inverse propensity weights, and estimation errors would alter the bias-variance trade-off, potentially invalidating the current threshold formula and theoretical guarantees.

### Open Question 2
How can the Heaviside composite optimization formulation be extended to accommodate non-linear policy classes beyond the linear policy class currently considered? The reformulation relies on the linear form, and non-linear policy representations would break the piecewise affine structure required for the current MIP formulation.

### Open Question 3
What is the theoretical suboptimality gap when the Progressive Integer Programming (PIP) algorithm finds a local optimum rather than the global maximizer assumed in the statistical analysis? Theorem 1 bounds regret relative to a global maximizer, but PIP may converge to a local maximizer of the upper-semicontinuous approximation.

## Limitations
- The OCDR estimator assumes overlap and bounded propensities; extreme violations could degrade performance
- The PIP algorithm's efficiency depends on problem-specific hyperparameters that are not fully specified
- Theoretical analysis assumes fixed reward models; model misspecification could impact bounds

## Confidence
- Core claims around OCDR's MSE improvement and PIP's scalability: **High confidence** given explicit formulas and computational results
- HSCOP reformulation: **Medium confidence** because while mathematically rigorous, the upper-semicontinuous approximation and its convergence guarantees are not extensively validated
- Applicability to high-dimensional or non-linear settings: **Low confidence** as this remains an open question

## Next Checks
1. **Threshold Sensitivity:** On a fixed dataset, plot MSE as a function of clipping threshold τ and verify the closed-form solution from Proposition 5 aligns with empirical minimum
2. **Computational Scaling:** Vary sample size N (e.g., 500, 1000, 2000) and compare wall-clock time and solution quality between PIP and standard MIP solvers
3. **Non-linear Policy Extension:** Implement a kernelized or neural network-based policy class and evaluate whether OCDR + PIP can still find good solutions within reasonable time