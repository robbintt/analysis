---
ver: rpa2
title: Leveraging LLM For Synchronizing Information Across Multilingual Tables
arxiv_id: '2504.02559'
source_url: https://arxiv.org/abs/2504.02559
tags:
- information
- table
- tables
- language
- gold
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of synchronizing multilingual
  Wikipedia tables, particularly for low-resource languages, where information is
  often outdated or incomplete. The authors propose using large language models (LLMs)
  for multilingual information synchronization, employing a task decomposition strategy
  to improve coherence and accuracy.
---

# Leveraging LLM For Synchronizing Information Across Multilingual Tables

## Quick Facts
- arXiv ID: 2504.02559
- Source URL: https://arxiv.org/abs/2504.02559
- Reference count: 26
- This paper proposes using large language models (LLMs) for multilingual information synchronization, particularly addressing outdated Wikipedia tables in low-resource languages, and introduces a task decomposition strategy that significantly outperforms existing baselines.

## Executive Summary
This paper addresses the challenge of synchronizing multilingual Wikipedia tables, particularly for low-resource languages, where information is often outdated or incomplete. The authors propose using large language models (LLMs) for multilingual information synchronization, employing a task decomposition strategy to improve coherence and accuracy. They introduce an Information Updation dataset simulating real-world Wikipedia table updates and develop novel evaluation metrics. The proposed LLM-based approach, especially with hierarchical task decomposition, significantly outperforms existing baselines, achieving 1.79% improvement in Information Updation and 20.58% in Information Addition tasks.

## Method Summary
The method employs a hierarchical task decomposition strategy where the multilingual table synchronization task is broken down into sequential subtasks: translation to English, knowledge graph conversion, merge/alignment, update, and back-translation. All steps use zero-shot prompting without fine-tuning. The pipeline processes source and reference tables through each stage, with intermediate knowledge graph representations enabling better alignment and conflict resolution. A multi-voting ensemble (InfoSync + GPT-3.5 + Gemini) evaluates alignment, while semantic evaluation uses a 3-LLM ensemble (Gemini 1.5 Flash Pro, GPT-4, GPT-3.5) averaging similarity scores.

## Key Results
- Hierarchical task decomposition achieves 1.79% improvement in Information Updation and 20.58% in Information Addition compared to baselines
- Single-prompt approaches produce suboptimal results, while decomposition enhances coherence and accuracy
- The method demonstrates LLMs' strength in dynamically updating and enriching data across architectures
- Translation to English as pivot language adds no new errors while leveraging stronger LLM reasoning capabilities

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Task Decomposition for Complex Reasoning
Decomposing the multilingual synchronization task into sequential subtasks improves coherence and accuracy over single-prompt approaches. The pipeline splits the problem into Translation → Knowledge Graph Conversion → Merge/Alignment → Update → Back-translation. Each step receives structured output from the previous step, reducing cognitive load per prompt and enabling focused reasoning. LLMs perform better on narrow, well-defined subtasks than on complex multi-step instructions in a single prompt.

### Mechanism 2: Knowledge Graph Intermediate Representation
Converting tables to knowledge graphs before merging improves alignment and conflict resolution. KGs provide explicit entity-relationship structure, enabling LLMs to recognize semantic equivalence (e.g., "Birthdate" ≈ "Date of Birth") through graph topology rather than surface text matching. Graph structure activates more systematic reasoning patterns in LLMs than tabular representations.

### Mechanism 3: English as Pivot Language for Cross-Lingual Transfer
Translating all tables to English before processing leverages stronger LLM reasoning capabilities in high-resource settings. Most SOTA LLMs are trained predominantly on English data, yielding better semantic understanding and reasoning in English. Translation enables unified processing regardless of source language pair, and translation quality is sufficient that information loss during pivot-translation is less costly than degraded reasoning in low-resource languages.

## Foundational Learning

- **Zero-shot prompting with instruction decomposition**: Why needed - The entire method relies on zero-shot prompts for each pipeline stage without fine-tuning. Understanding how to craft clear, scoped instructions is prerequisite. Quick check - Can you explain why zero-shot was chosen over few-shot for this task? (Answer: Avoids bias toward exemplar categories; marginal improvements don't justify cost.)

- **Knowledge graph construction from semi-structured data**: Why needed - Tables must be converted to KGs as an intermediate step. Understanding entity-relationship extraction from key-value pairs is essential. Quick check - Given a table with keys [Name, Birth date, Profession], what would the corresponding KG structure look like?

- **Multi-stage error propagation in pipelines**: Why needed - Table 3 shows errors compound across stages (239 → 400). Recognizing where errors originate informs optimization priorities. Quick check - Which pipeline stage introduces the most errors in this system? (Answer: KG construction and merging stages add the most.)

## Architecture Onboarding

- **Component map**: Source Table (Li) → Translation (→ English) → KG Construction → Merge/Align → Update → Table Conversion → Back-Translation → Output Table (Li); Reference Table (Lj) follows same path. Alignment Evaluation: Multi-voting ensemble (InfoSync + GPT-3.5 + Gemini). Update Evaluation: LLM-based semantic comparison (averaged across 3 models).

- **Critical path**: KG Construction → Merge/Align (Table 3 shows these stages add 72+72=144 errors, the largest jumps). Optimization here yields highest ROI.

- **Design tradeoffs**: Pipeline complexity vs. accuracy - More stages improve addition/update (+20.58%) but increase deletion errors (0.35 → 0.45). Closed-source vs. open-source models - Gemini 1.5 Flash Pro achieves best results; LLaMA 3.0 lags slightly but offers transparency. Zero-shot vs. few-shot - Zero-shot chosen for generalizability; few-shot showed only marginal gains at higher cost.

- **Failure signatures**: Missing Information - Reference tables lack source data (145 baseline errors). Redundant Information - KG stage fails to remove outdated data (+66 redundant rows). Outdated Information (Full/Partial) - Merge stage doesn't resolve conflicts (adds 16 full + 9 partial outdated rows).

- **First 3 experiments**: 1) Replicate alignment evaluation on 50 table pairs to validate multi-voting F1 (target: ~93% as reported in Table 2). 2) Ablate KG conversion step: Compare direct table merging vs. KG-mediated merging on 20 instances to quantify error reduction claim. 3) Test translation quality: Manually evaluate English pivot translation for 10 low-resource language pairs (Afrikaans, Cebuano) to verify "no new errors" claim from Table 3.

## Open Questions the Paper Calls Out

- How can the trade-off between improved information addition and increased deletion errors in hierarchical task decomposition be mitigated? The proposed multi-prompt decomposition strategy improves addition scores (20.58%) but causes a slight increase in deletion errors (0.45) compared to simpler baselines, indicating a specific failure mode in the pipeline's logic.

- Can integrating LLMs with rule-based methods or external knowledge graphs improve factual accuracy beyond zero-shot prompting? While this paper demonstrates that zero-shot LLMs outperform the rule-based InfoSync baseline, it does not explore whether a hybrid approach could combine the generalization of LLMs with the precision of rule-based constraints.

- Does the mandatory translation of tables into English as an intermediate step introduce semantic loss or bias compared to direct cross-lingual synchronization? The methodology relies on translating all tables to English because "LLMs perform better reasoning over knowledge graphs" in English, but the Limitations section notes that pre-training data may not capture nuances in low-resource languages.

- How well does the proposed decomposition strategy generalize to highly complex information structures and extremely low-resource languages outside the current dataset? The current INFO UPDATE dataset contains a limited number of instances for very low-resource languages (e.g., Afrikaans, Cebuano), making it difficult to confirm if the zero-shot approach remains robust as data availability vanishes.

## Limitations
- Error propagation across pipeline stages remains a critical limitation, with cumulative errors increasing from 239 to 400 despite individual stage improvements.
- Zero-shot prompting effectiveness across diverse language pairs is uncertain, particularly for low-resource languages with limited training data in the LLM.
- The INFO UPDATE dataset, while carefully constructed, represents only 950 instances across 14 languages, limiting generalization to truly low-resource languages.

## Confidence
- **High**: Task decomposition improves over single-prompt approaches (Table 2: +1.79% updation, +20.58% addition); English pivot translation introduces no new errors (Table 3: 239→239).
- **Medium**: KG intermediate representation improves alignment over direct table merging; hierarchical pipeline outperforms baselines overall.
- **Low**: Zero-shot prompting across all language pairs without domain adaptation; multi-voting ensemble evaluation reliability across diverse table structures.

## Next Checks
1. **Error Propagation Analysis**: Instrument the pipeline to log error sources at each stage for 50 instances, quantifying which transformations introduce the most errors and whether certain error types cluster predictably.
2. **Direct vs. Pivot Translation**: Manually evaluate 20 instances where both direct translation (Afrikaans→Cebuano) and pivot translation (Afrikaans→English→Cebuano) are possible, measuring semantic drift and reasoning quality differences.
3. **Low-Resource Generalization**: Test the pipeline on 10 Wikipedia table pairs from languages not represented in the INFO UPDATE dataset, evaluating whether performance degrades predictably with training data scarcity.