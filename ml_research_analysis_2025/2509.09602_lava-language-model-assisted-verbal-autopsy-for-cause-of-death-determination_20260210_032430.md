---
ver: rpa2
title: 'LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination'
arxiv_id: '2509.09602'
source_url: https://arxiv.org/abs/2509.09602
tags:
- verbal
- autopsy
- accuracy
- cause
- causes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LA-VA combines LLM-based predictions with embedding-based classifiers
  and probabilistic models for cause-of-death determination from verbal autopsies.
  Using GPT-5 with structured prompts and post-hoc calibration, the method achieved
  top-1 accuracies of 48.6% (adults), 50.5% (children), and 53.5% (neonates) across
  11,978 cases from the PHMRC dataset, outperforming traditional baselines by 5-10%.
---

# LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination

## Quick Facts
- arXiv ID: 2509.09602
- Source URL: https://arxiv.org/abs/2509.09602
- Reference count: 25
- Primary result: LLM-enhanced VA achieves 48.6-53.5% accuracy across adult, child, and neonate categories

## Executive Summary
LAVA presents a novel approach to cause-of-death determination using language models for verbal autopsy analysis. The method combines GPT-5 predictions with embedding-based classifiers and probabilistic models, achieving state-of-the-art performance on the PHMRC dataset. By leveraging structured prompts and post-hoc calibration, the system improves both individual case predictions and population-level cause-specific mortality fraction accuracy. The approach demonstrates particular strength in identifying distinctive causes like maternal mortality and injuries.

## Method Summary
LA-VA employs a hybrid approach combining LLM-based predictions with embedding-based classifiers and probabilistic models. The system uses GPT-5 with structured prompts to classify verbal autopsy narratives, then applies post-hoc calibration to improve population-level accuracy. The method processes 11,978 cases from the PHMRC dataset across adult, child, and neonate categories, comparing performance against traditional machine learning baselines.

## Key Results
- Top-1 accuracy: 48.6% (adults), 50.5% (children), 53.5% (neonates)
- Outperforms traditional baselines by 5-10 percentage points
- CSMF accuracy improved through post-hoc calibration without affecting individual predictions
- Performance correlates positively with narrative length
- Highest accuracy for distinctive conditions like maternal mortality and injuries

## Why This Works (Mechanism)
The approach leverages large language models' ability to understand complex medical narratives and identify subtle symptom patterns that traditional classifiers miss. GPT-5's contextual understanding, combined with structured prompting, allows for more nuanced interpretation of verbal autopsy data. The calibration step ensures that while individual predictions may be uncertain, the overall population-level distribution of causes remains accurate, which is crucial for public health surveillance.

## Foundational Learning
- **Verbal Autopsy (VA)**: Structured interviews conducted with caregivers of the deceased to determine likely cause of death. Needed because medical certification is often unavailable in resource-limited settings. Quick check: Understand why VA is essential in low-resource mortality surveillance.
- **PHMRC Dataset**: Standardized VA dataset with physician-coded causes of death. Provides gold standard for VA method validation. Quick check: Review PHMRC's role as benchmark dataset.
- **Cause-Specific Mortality Fraction (CSMF)**: Proportion of deaths from each cause in a population. Critical for public health planning. Quick check: Understand difference between individual and population-level accuracy.

## Architecture Onboarding

**Component Map**: LLM prediction -> Embedding classifier -> Probabilistic model -> Post-hoc calibration

**Critical Path**: Verbal autopsy narrative → GPT-5 structured prompt → LLM classification → Calibration adjustment → Final cause assignment

**Design Tradeoffs**: Uses GPT-5's contextual understanding vs. traditional feature-based ML; balances individual prediction accuracy with population-level CSMF accuracy; trades computational cost for improved accuracy

**Failure Signatures**: Poor performance on causes with overlapping symptoms; reduced accuracy for shorter narratives; potential bias toward causes better represented in training data

**First Experiments**:
1. Test LA-VA on a held-out subset of PHMRC data with varying narrative lengths
2. Compare LA-VA performance against physician review on identical cases
3. Evaluate calibration effectiveness by comparing pre- and post-calibration CSMF accuracy

## Open Questions the Paper Calls Out
None identified in source material.

## Limitations
- Reported accuracies (48.6-53.5%) below the 70% threshold for medical decision-making
- Cannot definitively isolate whether improvements stem from LLM capabilities vs. prompting/calibration
- Dataset represents curated cases with medical records, not typical real-world VA conditions

## Confidence

**High confidence**: LLM-enhanced approach outperforms traditional baselines; calibration improves population-level accuracy; performance correlates with narrative length

**Medium confidence**: Cause-specific performance patterns; claim that approach "generalizes to low-resource settings" requires additional validation

**Medium confidence**: Assertion that structured prompting is essential for LLM performance

## Next Checks
1. Test LA-VA on independently collected VA datasets from different geographical regions and healthcare systems
2. Conduct head-to-head comparison with human physicians performing the same VA classification task
3. Evaluate LA-VA's performance on VA interviews without medical records or conducted significantly later after death