---
ver: rpa2
title: An Anytime Algorithm for Good Arm Identification
arxiv_id: '2310.10359'
source_url: https://arxiv.org/abs/2310.10359
tags:
- apgai
- algorithm
- when
- good
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes APGAI, an anytime and parameter-free algorithm
  for the Good Arm Identification (GAI) problem in stochastic bandits. The GAI problem
  aims to identify one arm whose average performance exceeds a given threshold, if
  it exists.
---

# An Anytime Algorithm for Good Arm Identification

## Quick Facts
- arXiv ID: 2310.10359
- Source URL: https://arxiv.org/abs/2310.10359
- Reference count: 13
- Primary result: Proposes APGAI, an anytime parameter-free algorithm for Good Arm Identification that achieves lower error rates than uniform sampling when no good arms exist

## Executive Summary
This paper introduces APGAI, an anytime algorithm for the Good Arm Identification (GAI) problem in stochastic bandits. GAI aims to identify any arm whose average performance exceeds a given threshold, if such an arm exists. APGAI operates without requiring prior knowledge of budget or confidence level and works across fixed-confidence, fixed-budget, and anytime settings. The algorithm uses an adaptive sampling strategy based on empirical transportation costs to balance exploration between likely good arms and verification of the absence of good arms.

The core innovation is the use of adaptive sampling that concentrates on the most informative arms when no good arms exist, achieving better error rates than uniform sampling. The paper provides theoretical guarantees including upper bounds on error probability, unverifiable sample complexity, and expected sampling complexity when combined with GLR stopping rules. Extensive empirical evaluation demonstrates APGAI's strong performance across synthetic and real-world datasets.

## Method Summary
APGAI maintains empirical means and counts for each arm, computing transportation costs W⁺ and W⁻ that represent evidence for and against an arm being good. The algorithm switches between two modes: when all arms appear below the threshold, it pulls the arm with smallest W⁻ to verify the absence of good arms; when some arm appears above threshold, it pulls the arm with largest W⁺ to confirm good arm quality. The GLR stopping rule monitors these costs against a calibrated threshold using the Lambert W function. For practical robustness, a forced exploration heuristic is added to mitigate outlier stopping times on instances with dissimilar good arm gaps.

## Key Results
- APGAI achieves lower error rates than uniform sampling when no good arms exist through adaptive verification
- Theoretical upper bounds on probability of error, unverifiable sample complexity, and expected sampling complexity at any confidence level
- Good empirical performance across synthetic and real-world datasets including RNA-sequencing applications
- Provides comprehensive comparisons with existing GAI algorithms across all settings with new theoretical guarantees

## Why This Works (Mechanism)

### Mechanism 1: Dual-Mode Adaptive Sampling
- **Claim**: APGAI achieves lower error rates than uniform sampling when no good arms exist by adaptively concentrating samples on the most informative arms.
- **Mechanism**: The algorithm switches between two modes based on whether the maximum empirical mean exceeds threshold θ. When all arms appear below θ, it pulls the arm with smallest W⁻ (evidence against being good), effectively "verifying" the absence of good arms. When some arm appears above θ, it pulls the arm with largest W⁺ (evidence for being good), confirming its quality.
- **Core assumption**: Arms have 1-sub-Gaussian distributions with means bounded away from θ.
- **Evidence anchors**:
  - [abstract]: "APGAI can be straightforwardly used in fixed-confidence and fixed-budget settings... They show that adaptive strategies can be more efficient in detecting the absence of good arms than uniform sampling"
  - [section 2]: Sampling rule described as at+1 ∈ arg mina W⁻a(t) when max μ̂ ≤ θ, otherwise arg maxa W⁺a(t)
  - [corpus]: Limited external validation; corpus shows moderate relevance (FMR=0.49) with no citations
- **Break condition**: Fails when arms have means extremely close to θ (small gaps) or non-sub-Gaussian distributions with heavy tails.

### Mechanism 2: Generalized Likelihood Ratio Stopping
- **Claim**: Combining APGAI with a GLR stopping rule provides fixed-confidence guarantees with bounded expected sample complexity.
- **Mechanism**: The stopping rule monitors transportation costs W⁺ and W⁻ against threshold c(t,δ). Stopping occurs when either: (1) max W⁺ exceeds threshold (confidence a good arm exists), or (2) min W⁻ exceeds threshold (confidence no good arms exist).
- **Core assumption**: Threshold function c(t,δ) is properly calibrated using the Lambert W function to maintain δ-correctness.
- **Evidence anchors**:
  - [section 5]: "Combined with GLR stopping Eq. (6) using threshold Eq. (7), APGAI is δ-correct"
  - [theorem 8]: Non-asymptotic upper bound on expected sample complexity: Eν[τδ] ≤ Cμ(δ) + Kπ²/6 + 1
  - [corpus]: No direct corpus evidence on GLR stopping for GAI
- **Break condition**: Sub-optimal performance when multiple good arms have dissimilar gaps (greedy focus on suboptimal good arm).

### Mechanism 3: Forced Exploration Mitigation (Empirical Fix)
- **Claim**: Adding forced exploration to APGAI reduces outlier stopping times when good arms have dissimilar means.
- **Mechanism**: Periodically sample under-explored arms (those with pull counts below √t) before applying the main sampling rule, ensuring all arms receive minimum exploration.
- **Core assumption**: Assumption: The forced exploration rate √t is sufficient to detect all good arms without significantly degrading performance on easier instances.
- **Evidence anchors**:
  - [appendix I.5]: "Table 14 shows that adding forced exploration significantly reduce the mean and the variance of the stopping time on instances where APGAI was prone to large outliers"
  - [corpus]: No corpus evidence; this is an empirical fix without theoretical guarantees
- **Break condition**: May unnecessarily increase sample complexity on instances with similar good arm gaps.

## Foundational Learning

- **Concept: Stochastic Multi-Armed Bandits**
  - **Why needed here**: Core framework; arms represent options with unknown reward distributions, sequential sampling decisions must be made under uncertainty.
  - **Quick check question**: Can you explain the exploration-exploitation tradeoff and how it differs between regret minimization and pure exploration settings?

- **Concept: Pure Exploration Settings (Fixed-Confidence vs Fixed-Budget vs Anytime)**
  - **Why needed here**: APGAI operates in the anytime setting but provides guarantees across all three; understanding these distinctions is essential for proper deployment.
  - **Quick check question**: For a given confidence δ=0.05, would a fixed-confidence algorithm guarantee fewer total samples than a fixed-budget algorithm with T=1000?

- **Concept: Sub-Gaussian Distributions**
  - **Why needed here**: All theoretical guarantees assume 1-sub-Gaussian reward distributions; violation breaks concentration bounds.
  - **Quick check question**: What properties does a 1-sub-Gaussian distribution have? Give an example of a distribution that is NOT sub-Gaussian.

## Architecture Onboarding

- **Component map**:
  Input: threshold θ, arm set A (size K)
  ↓
  Initialization: Pull each arm once
  ↓
  Main Loop:
    Update empirical means μ̂a(t) and counts Na(t)
    Compute transportation costs: W⁺a(t), W⁻a(t)
    Determine mode: max μ̂a(t) > θ ?
    Select next arm: at+1 = arg max W⁺ OR arg min W⁻
    Optional: Check GLR stopping condition
  ↓
  Output: Recommendation ât (arm or ∅)

- **Critical path**:
  1. Initialization quality (first K samples) significantly impacts early recommendations
  2. Mode determination (max μ̂a vs θ) controls sampling strategy
  3. Transportation cost calculation precision (floating point) affects arm selection
  4. Stopping threshold calibration (if using fixed-confidence mode)

- **Design tradeoffs**:
  - **Memory vs Computation**: O(K) memory, O(K) per-iteration computation; suitable for moderate K (paper tests K=18, K=100)
  - **Anytime vs Optimality**: Sacrifices asymptotic optimality for anytime guarantees (suboptimal by constant factors when good arms exist)
  - **Simplicity vs Robustness**: Simple index-based approach may fail on adversarial instances; forced exploration adds robustness but increases complexity

- **Failure signatures**:
  - **High variance in stopping time**: Good arms with dissimilar gaps → greedily fixates on harder-to-verify arm
  - **Recommendation oscillation**: Arms with means near threshold θ → frequent mode switches
  - **No stopping in fixed-confidence mode**: Incorrect threshold c(t,δ) or non-sub-Gaussian rewards

- **First 3 experiments**:
  1. **Sanity check**: Implement APGAI on Gaussian instance with K=5, one clearly good arm (μ=0.8, θ=0.5), verify it correctly identifies the good arm and stops before uniform sampling would
  2. **Stress test**: Run on instance with no good arms (all μ<θ), verify error rate decreases as ~exp(-t/H₁) and that it correctly returns ∅
  3. **Regression test**: Compare with uniform sampling on instance from Table 6 (e.g., IsA1), confirm APGAI achieves lower empirical error at budget T=500

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can APGAI achieve a better non-asymptotic error dependency than H₁(μ) when good arms exist, and what finer proof techniques are required to demonstrate this?
- Basis in paper: [explicit] The authors state on Page 9, "We conjecture that APGAI could have a better dependency than H₁(μ) when there are good arms, yet our non-asymptotic analysis is not tight enough to reveal it. Proving this conjecture is an interesting direction for future work that requires finer non-asymptotic arguments."
- Why unresolved: Current theoretical bounds for the non-asymptotic regime rely on proof techniques that do not capture the algorithm's distinct behavior when good arms exist versus when they do not.
- What evidence would resolve it: A formal proof showing the non-asymptotic probability of error scales with a complexity term smaller than H₁(μ) (e.g., H_θ(μ)) for instances with good arms.

### Open Question 2
- Question: Is it possible to formally prove that the greediness of APGAI prevents it from achieving the asymptotically optimal rate 2 min_{a ∈ A_θ} Δ_a^{-2} in instances with multiple good arms?
- Basis in paper: [explicit] In Appendix F.3.1 (Page 60), regarding the algorithm's inability to switch from a hard good arm to an easy one, the authors state: "Formally proving such a negative result is an interesting direction for future work."
- Why unresolved: The discussion suggests APGAI cannot recover from unlucky initial draws that cause it to fixate on a suboptimal good arm, but this is currently supported only by intuition and specific examples, not a general theorem.
- What evidence would resolve it: A rigorous lower bound showing that for specific classes of instances, the expected sample complexity of APGAI is strictly worse than the information-theoretic optimal lower bound.

### Open Question 3
- Question: What is the maximal hardness of an instance for which an algorithm can guarantee a bounded time-uniform probability of error?
- Basis in paper: [explicit] On Page 14 (and Appendix B.4), regarding Corollary 20, the authors note: "An interesting direction for future work is to characterize the maximal hardness of an instance on which an algorithm can obtain time-uniform guarantees."
- Why unresolved: The authors provide an upper bound on the time-uniform probability of error but conjecture that this bound becomes vacuous (greater than one) for instances where H₁(μ) is large.
- What evidence would resolve it: A theoretical characterization of the boundary conditions on H₁(μ) or instance complexity beyond which time-uniform guarantees are mathematically impossible.

### Open Question 4
- Question: Can the Good Arm Identification problem be effectively extended to structured bandit settings, such as linear or infinitely-armed bandits, in a tractable and meaningful manner?
- Basis in paper: [explicit] In the Perspectives section (Page 21), the authors suggest: "Investigating the GAI problem on e.g. linear or infinitely-armed bandits would be interesting subsequent work."
- Why unresolved: The current work focuses on unstructured multi-armed bandits, whereas many applications involve inherent structure that could theoretically reduce the sample complexity if leveraged correctly.
- What evidence would resolve it: The formulation of a GAI algorithm for structured bandits (e.g., linear) with corresponding upper bounds on sample complexity that depend on the structure parameters rather than just the number of arms.

## Limitations

- Anytime guarantees come with constant-factor suboptimality when good arms exist, trading asymptotic efficiency for practical anytime behavior
- Forced exploration is presented as an empirical fix without theoretical guarantees, potentially masking deeper algorithmic limitations
- GLR stopping threshold relies on precise Lambert W function calculations, with numerical instability as a potential failure point
- Performance degrades significantly on instances with multiple good arms having dissimilar gaps (greedy focus on hardest-to-verify arm)

## Confidence

- **High Confidence**: Core mechanism of adaptive sampling based on transportation costs (verified through theorem statements and algorithm description)
- **Medium Confidence**: Anytime error bounds and expected sample complexity guarantees (some constants depend on unspecified properties of arm distributions)
- **Medium Confidence**: Empirical performance claims (results depend on specific implementations and random seeds not fully disclosed)
- **Low Confidence**: Forced exploration heuristic effectiveness without theoretical backing

## Next Checks

1. Reproduce Figure 2(a) for IsA1 instance to verify the anytime error decay curve matches the claimed exp(-t/H₁) behavior
2. Test APGAI on an instance with no good arms (all means below threshold) to verify the verification mechanism works and error rate decreases appropriately
3. Compare stopping times on an instance with dissimilar good arm gaps to quantify the greedy focus problem and assess forced exploration mitigation effectiveness