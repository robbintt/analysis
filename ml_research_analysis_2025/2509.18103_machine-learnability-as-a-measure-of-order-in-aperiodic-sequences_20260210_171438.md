---
ver: rpa2
title: Machine Learnability as a Measure of Order in Aperiodic Sequences
arxiv_id: '2509.18103'
source_url: https://arxiv.org/abs/2509.18103
tags:
- prime
- performance
- pixels
- accuracy
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using a U-Net model trained on Ulam spiral
  images to measure learnability of prime number distributions across different numerical
  ranges. The key idea is that if prime patterns become more regular at higher numbers,
  as number theory conjectures suggest, then machine learning models should learn
  more effectively from higher-number spirals.
---

# Machine Learnability as a Measure of Order in Aperiodic Sequences

## Quick Facts
- arXiv ID: 2509.18103
- Source URL: https://arxiv.org/abs/2509.18103
- Reference count: 10
- Primary result: Models trained on higher-number Ulam spirals (up to 500M) outperform those trained on lower ranges (25M), suggesting prime distributions become more learnable at larger magnitudes.

## Executive Summary
This paper proposes measuring the learnability of prime number distributions using a U-Net model trained on Ulam spiral images. The central hypothesis is that prime patterns become more regular at higher numbers, as number theory conjectures suggest, making them more amenable to machine learning. By training identical models on spirals containing primes up to 25M, 50M, 100M, 200M, 300M, 400M, and 500M, and evaluating them across all ranges, the study demonstrates that models trained on higher-number spirals achieve superior accuracy, precision, and recall scores. This supports the idea that prime distributions exhibit more stable statistical geometry at larger scales, though the model appears to shift from pattern-based prime identification at low numbers to elimination-based composite detection at high numbers.

## Method Summary
The study uses a U-Net architecture with a ResNet-34 encoder to perform self-supervised binary inpainting on Ulam spiral images. Given 30% visible pixels (Bernoulli mask), the model reconstructs the full binary image where white=prime, black=composite. Seven Ulam spiral images covering ranges from 25M to 500M are generated, each split into 350 non-overlapping 256x256 blocks (300 train, 50 validation). Models are trained on different numerical ranges and cross-evaluated to measure learnability differences. The loss function combines soft mean class accuracy (α=1.0) and binary cross-entropy (β=0.5). Evaluation uses hard threshold at 0.5 and reports accuracy, macro F1, and per-class precision/recall/F1 with bootstrap confidence intervals.

## Key Results
- Models trained on 500M data significantly outperform those trained on 25M data when evaluated on most test sets, with 500M-trained models achieving better macro F1 scores.
- Per-class breakdown reveals white F1 peaks for 25M-trained models on 25M test data, while black F1 peaks for 500M-trained models across most test sets.
- The performance gradient suggests prime distributions become more learnable at higher magnitudes, supporting number-theoretic conjectures about asymptotic regularization.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Models trained on higher-number Ulam spiral regions achieve better cross-range performance because prime distributions exhibit more stable statistical geometry at larger scales.
- **Mechanism:** Local irregularities diminish relative to global density laws (Prime Number Theorem, Bombieri-Vinogradov), reducing noise the model must filter.
- **Core assumption:** Noise-reduction effects from number-theoretic conjectures are continuous enough to be detectable at scales ≤500M.
- **Evidence anchors:** 500M-trained models outperform 25M-trained models across most test sets; chaotic irregularities of small primes "average out" with increasing n.
- **Break condition:** If models trained at 500M significantly underperform on held-out regions >1B, the detectable-regularity hypothesis fails at tested scales.

### Mechanism 2
- **Claim:** The model shifts classification strategy based on numerical range—direct prime pattern recognition at low numbers versus composite elimination at high numbers.
- **Mechanism:** At low numbers, modular patterns create distinctive prime signatures; at high numbers, the model learns to identify likely composites and assigns primality by exclusion.
- **Core assumption:** Precision/recall asymmetries reflect genuine strategy shift, not merely class-imbalance artifacts.
- **Evidence anchors:** White F1 peaks for 25M-trained models on 25M test data; black F1 peaks for 500M-trained models across most test sets.
- **Break condition:** If top-k binarization eliminates the precision/recall asymmetry, the shift is an artifact of threshold selection.

### Mechanism 3
- **Claim:** Sparse inpainting with 30% pixel visibility forces the model to internalize long-range spatial dependencies rather than memorizing local patterns.
- **Mechanism:** Random Bernoulli masking prevents overfitting to local pixel adjacency; reconstruction requires inferring global spiral geometry.
- **Core assumption:** 30% masking is sufficient to require structural learning but not so aggressive as to make the task impossible.
- **Evidence anchors:** Network designed to infer global structure from sparse evidence; augmentation via rotation was abandoned due to negative/no effect.
- **Break condition:** If models with 70%+ visibility show equivalent cross-range generalization, sparsity is not the driving factor.

## Foundational Learning

- **Concept: Prime Number Theorem (density ~1/ln x)**
  - **Why needed here:** Interprets why prime pixel proportion drops from ~6% to ~5% across ranges and establishes theoretical basis for asymptotic regularization.
  - **Quick check question:** Given a 256×256 block centered at n=400M, approximately what fraction of pixels should be prime? (~5.3% via 1/ln(4×10⁸) ≈ 1/19.8)

- **Concept: Class-imbalanced segmentation metrics (precision/recall/F1 vs. accuracy)**
  - **Why needed here:** Raw accuracy is misleading when ~95% of pixels are composite; meaningful evaluation requires per-class decomposition.
  - **Quick check question:** A model predicts all pixels black and achieves 95% accuracy—why is this a trivial baseline? (It has zero recall for primes; F1=0 for minority class)

- **Concept: U-Net encoder-decoder with skip connections**
  - **Why needed here:** Understanding how multi-scale features propagate; encoder captures abstract patterns, decoder reconstructs spatial detail.
  - **Quick check question:** What information do skip connections transmit that would be lost in a pure encoder-decoder? (High-resolution spatial detail from early encoder layers to corresponding decoder stages)

## Architecture Onboarding

- **Component map:**
  Input (256×256 grayscale block) → Bernoulli mask (30% visible) → masked input tensor → ResNet-34 encoder → multi-scale feature maps → U-Net decoder with skip connections → 256×256 probability map → Sigmoid activation → binary prediction per pixel

- **Critical path:** Data generation (Ulam spiral → 350 blocks) → masking → forward pass → loss computation → backprop → validation (hard MCA thresholded at 0.5) → best model selection

- **Design tradeoffs:**
  - ResNet-34 vs. larger encoders: Chosen for replicability; larger models would improve accuracy but obscure comparative learnability signal
  - 256×256 blocks: Balance between local detail and global context; too small loses diagonal structure, too large reduces sample count
  - No rotation augmentation: Preserved orientation-specific patterns (Ulam diagonals are not rotation-invariant)

- **Failure signatures:**
  - Models collapsing to "predict all black" → Soft-MCA not properly weighted, or BCE dominating
  - Large train/validation gap on same range → Overfitting to local artifacts; increase masking ratio
  - No performance gradient across training ranges → Dataset contamination or insufficient range separation

- **First 3 experiments:**
  1. Replicate 25M vs. 500M training on a single shared test set (e.g., 100M blocks) with fixed seed to confirm performance gap; report macro F1 and per-class precision/recall with bootstrap CIs.
  2. Ablate masking ratio (10%, 30%, 50%, 70% visible) on 100M data to test whether sparsity drives structural learning; plot macro F1 vs. mask ratio.
  3. Apply top-k binarization (force 5% white) during evaluation to isolate density-awareness from pattern-learning; if performance gradient disappears, mechanism 2 is artifact, not strategy shift.

## Open Questions the Paper Calls Out

- **Open Question 1:** Do false positive classifications (composites misidentified as primes) correspond to specific algebraic loci, such as quadratic polynomial diagonals or "near-prime" clusters?
  - **Basis in paper:** [explicit] The authors state that "misclassifications of the model... may be more mathematically informative than its successes," suggesting they may signal "quadratic polynomial diagonals" or products of small factors.
  - **Why unresolved:** The current study focuses on aggregate accuracy metrics rather than performing a systematic spatial or algebraic analysis of the specific error pixels.
  - **What evidence would resolve it:** Mapping the coordinates of false positive pixels back to integer values and testing for over-representation on prime-rich polynomials or semiprime distributions.

- **Open Question 2:** Do the internal representations learned by models trained on low numbers differ structurally from those trained on high numbers in terms of encoding local irregularities versus asymptotic density laws?
  - **Basis in paper:** [explicit] The paper notes that "further work should also investigate whether the representations learned by models at different scales... correspond to distinct number-theoretic phenomena."
  - **Why unresolved:** The paper compares performance outputs but does not conduct feature analysis to verify if the models are actually learning distinct features.
  - **What evidence would resolve it:** Comparing activation maps or using dimensionality reduction on the latent space of models from different training ranges against known number-theoretic features.

- **Open Question 3:** Can this machine learning framework be effectively applied to identify regions of "strong" and "weak" primes or semiprimes for cryptographic analysis?
  - **Basis in paper:** [explicit] The abstract and conclusion explicitly mention the "potential for investigating the patterns in strong and weak primes for cryptographic purposes."
  - **Why unresolved:** The current experiment treats all primes as a single class without distinguishing between them based on cryptographic properties or factorization difficulty.
  - **What evidence would resolve it:** Retraining or probing the model on datasets specifically labeled for cryptographic strength to see if distinct patterns emerge for these subclasses.

- **Open Question 4:** Is the observed increase in learnability at higher magnitudes intrinsic to the prime sequence, or is it an artifact of the Ulam spiral's specific two-dimensional projection?
  - **Basis in paper:** [inferred] The study relies exclusively on the Ulam spiral visualization method.
  - **Why unresolved:** It is possible that the specific geometry of the Ulam spiral introduces or amplifies patterns at specific scales that might not exist in the sequence itself.
  - **What evidence would resolve it:** Replicating the experiment using alternative representations (e.g., Sacks spiral) or 1D sequence learning models to see if the performance trend persists.

## Limitations

- The interpretation that performance gradients reflect number-theoretic regularization cannot be fully confirmed without testing on ranges beyond 500M to verify asymptotic behavior.
- The claim about strategy shift (pattern recognition vs. composite elimination) rests on precision/recall asymmetries that could be artifacts of the hard threshold at 0.5 rather than genuine learned behavior.
- The mechanism claiming that 30% masking uniquely enables structural learning is not validated through ablation studies varying mask ratios or comparing to alternative regularization methods.

## Confidence

- **High Confidence:** The experimental methodology is sound—identical architectures, controlled training ranges, and cross-evaluation design. The observed performance gradient is robust and replicable.
- **Medium Confidence:** The interpretation that this gradient reflects number-theoretic regularization is plausible given the Prime Number Theorem and related conjectures, but alternative explanations cannot be ruled out without testing on ranges beyond 500M.
- **Low Confidence:** The specific mechanism of strategy shift and the claim that 30% masking uniquely enables structural learning are not yet validated through ablation or alternative experimental designs.

## Next Checks

1. **Out-of-range generalization test:** Train models on 500M data and evaluate on held-out regions at 1B+ to determine if the learnability advantage extends beyond the training range, confirming asymptotic regularization rather than scale-specific artifacts.

2. **Masking ratio ablation:** Systematically vary the Bernoulli mask ratio (10%, 30%, 50%, 70%) during training on 100M data to test whether sparse inpainting is necessary for structural learning or merely convenient regularization.

3. **Threshold invariance analysis:** Apply top-k binarization (force 5% white pixels) during evaluation to determine if precision/recall asymmetries persist, which would validate the strategy-shift interpretation versus threshold artifacts.