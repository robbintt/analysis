---
ver: rpa2
title: Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI
  Tutor Dialogues
arxiv_id: '2510.13862'
source_url: https://arxiv.org/abs/2510.13862
tags:
- affective
- turns
- learning
- affect
- learners
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces an ensemble-LLM framework to analyze the
  affective dynamics of student-AI tutor interactions at scale. By applying three
  frontier LLMs (Gemini, GPT-4o, Claude) to 16,986 conversational turns from PyTutor,
  the system generates zero-shot affect annotations including valence, arousal, learning-helpfulness,
  and emotion labels.
---

# Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues

## Quick Facts
- arXiv ID: 2510.13862
- Source URL: https://arxiv.org/abs/2510.13862
- Reference count: 26
- Key outcome: Ensemble of three LLMs produces zero-shot affect annotations for 16,986 turns, revealing students typically experience mildly positive affect with short-lived emotions and quick rebounds from negative states.

## Executive Summary
This study presents an ensemble-LLM framework to automatically characterize affect in student-AI tutor dialogues at scale. The system applies three frontier LLMs (Gemini, GPT-4o, Claude) to annotate valence, arousal, learning-helpfulness, and emotion labels for each conversational turn. By fusing these annotations through rank-weighted intra-model pooling and cross-model consensus, the framework produces robust affect profiles. Analysis reveals students maintain mildly positive affect with moderate arousal, experience frequent confusion and curiosity, and show rapid emotional transitions with positive states being slightly more stable than negative ones.

## Method Summary
The study collected 16,986 conversational turns from 261 students across three institutions using the PyTutor platform. Three frontier LLMs (Gemini 2.0 Flash, GPT-4o mini, Claude 3.5 Sonnet) performed zero-shot affect annotation using standardized prompts. The ensemble framework fused model outputs through rank-weighted pooling within each model (K=5 labels with linear decay) and then applied cross-model averaging for scalar ratings and plurality voting for discrete labels. Affect dynamics were analyzed using first-order Markov chains with valence discretized into tertiles, computing transition probabilities and expected dwell times.

## Key Results
- Students maintain mildly positive affect (median valence=5) with moderate arousal (median=5-6)
- Confusion (22.15%) and curiosity (15.83%) are the most frequent emotions
- Emotional states are short-lived with neutral moments often acting as upward-turning points
- Negative emotions resolve quickly, frequently rebounding into positive states
- Valence and arousal are weakly correlated (ρ=0.22), supporting their conceptual independence

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hierarchical ensemble fusion across multiple frontier LLMs reduces annotation bias from any single model's idiosyncrasies while preserving domain-specific emotion vocabulary.
- **Mechanism:** Three-stage pipeline: (1) each LLM independently generates ranked emotion labels + scalar VAL ratings via zero-shot inference; (2) rank-weighted pooling within each model; (3) cross-model averaging for scalars and plurality voting for labels.
- **Core assumption:** Each model's biases are partially uncorrelated, so consensus approximates a more reliable estimate than any single annotator.
- **Evidence anchors:**
  - [abstract]: "These estimates are fused through rank-weighted intra-model pooling and plurality consensus across models to produce robust emotion profiles."
  - [section II.B]: "We therefore opt for automatic annotation via an ensemble of frontier LLMs, leveraging their broad pre-training to minimize single-annotator bias while still acknowledging model idiosyncrasies."
  - [corpus]: Related work on LLM affective behavior (Chain-of-Affective paper, FMR=0.61) suggests LLMs exhibit structured affective patterns but with model-specific variance—supporting ensemble rationale.
- **Break condition:** If model biases are correlated (e.g., shared training data or similar fine-tuning objectives), ensemble gains diminish; ablation studies (not conducted here) would be needed to verify.

### Mechanism 2
- **Claim:** Rank-weighted intra-model pooling captures mixed-emotion states better than single-label classification, reflecting psychological findings that emotions co-occur.
- **Mechanism:** Each model outputs up to K=5 ranked labels; weights decay linearly (w_r ∝ K-r+1), then weighted means produce per-model scalar scores before cross-model aggregation.
- **Core assumption:** Higher-ranked outputs reflect greater model confidence or prominence of that emotion in the turn.
- **Evidence anchors:**
  - [section II.B]: "Rank r receives a linearly decaying weight w_r ∝ K_m − r+1 (normalized so Σr wr = 1). Weighted means yield per-model scores."
  - [section I]: Notes that traditional corpora "force single-label decisions—choices at odds with mixed-emotion findings."
  - [corpus]: No direct corpus evidence on rank-weighting specifically; this is a methodological contribution requiring validation.
- **Break condition:** If ranking order is arbitrary or model confidence doesn't correlate with rank, weights introduce noise rather than signal.

### Mechanism 3
- **Claim:** First-order Markov chains capture affective transition dynamics with interpretable state persistence and rebound patterns.
- **Mechanism:** Discretize valence into tertiles (negative/neutral/positive); estimate 3×3 transition matrix via frequency counts with Laplace smoothing; compute expected dwell time as 1/(1-P_ss).
- **Core assumption:** Affect transitions are primarily first-order—next state depends mainly on current state, not longer history.
- **Evidence anchors:**
  - [section II.C]: "We model discrete affect transitions as a first-order Markov chain with state space {positive, neutral, negative}... compute expected dwell time in each state as dwell(s) = 1/(1-P_ss)."
  - [results]: "Neutral behaves as a gateway with a slight positivity bias (P_neu→pos = 0.38 vs. P_neu→neg = 0.33)."
  - [corpus]: DASKT paper (FMR=0.51) similarly models affect dynamics temporally, supporting Markovian approaches for educational contexts.
- **Break condition:** If affective dynamics exhibit longer-range dependencies (e.g., session-level momentum), first-order models underfit; authors acknowledge this limitation in Section V.

## Foundational Learning

- **Concept: Valence-Arousal-Dominance (VAD) dimensional emotion model**
  - Why needed here: The paper extends VAD with a learning-helpfulness axis; understanding the base dimensional approach is prerequisite to interpreting VAL scores.
  - Quick check question: Can you explain why valence and arousal alone might insufficiently capture learning-relevant emotions?

- **Concept: Markov chain fundamentals (transition matrix, dwell time, Laplace smoothing)**
  - Why needed here: Temporal analysis relies on first-order Markov assumptions; interpreting transition probabilities and dwell times requires fluency.
  - Quick check question: What does a self-loop probability P_ss = 0.57 imply about expected dwell time in that state?

- **Concept: Ensemble consensus methods (plurality voting vs. averaging)**
  - Why needed here: The fusion pipeline treats discrete labels and scalar ratings differently; understanding when to use which consensus strategy is critical.
  - Quick check question: Why might plurality voting outperform averaging for categorical emotion labels?

## Architecture Onboarding

- **Component map:** PyTutor conversational logs (16,986 turns, 261 students, 3 institutions) -> Three parallel LLM annotators (Gemini 2.0 Flash, GPT-4o mini, Claude 3.5 Sonnet) -> Intra-model rank-weighted pooling -> Inter-model scalar averaging + plurality label consensus -> Descriptive statistics + Temporal modeling (first-order Markov transitions) -> Turn-level affect profiles + transition matrices

- **Critical path:** 1. Preprocess raw chat logs into turn-level student/tutor pairs 2. Execute zero-shot inference across all three LLMs with standardized prompt 3. Apply hierarchical fusion to produce unified annotations 4. Bin valence into tertiles for Markov analysis 5. Estimate transition probabilities and compute dwell times

- **Design tradeoffs:**
  - K=5 top labels: Higher K captures more nuance but dilutes weights; no ablation reported
  - Linear vs. exponential decay: Linear chosen for simplicity; alternative weighting schemes untested
  - First-order vs. higher-order Markov: First-order is interpretable but may miss longer-range dependencies (acknowledged limitation)
  - Zero-shot vs. few-shot prompting: Zero-shot chosen for scalability; few-shot might improve calibration

- **Failure signatures:**
  - Low inter-model agreement: Indicates ambiguous turns or prompt mismatch
  - Persistent negative dwell times: Signals tutor responses failing to repair affect
  - Excessive "neutral" labeling: May indicate model reluctance to commit to polarity
  - Session boundary artifacts: 60-min inactivity threshold may split coherent learning episodes

- **First 3 experiments:**
  1. **Human validation study:** Stratified sample of 200–500 turns with multiple human annotators; compute Cohen's kappa, ICC, and Fleiss' kappa between ensemble labels and human gold standard to assess annotation fidelity (authors explicitly flag this as priority future work).
  2. **Ablation by model:** Compare ensemble performance against each individual model to quantify marginal contribution; identify if one model dominates or if diversity is genuinely beneficial.
  3. **Higher-order Markov comparison:** Fit second-order and hidden semi-Markov models to same data; compare AIC/BIC and predictive accuracy to determine if first-order assumption is justified or overly restrictive.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How accurately do ensemble-LLM affect annotations reflect learners' true emotional states compared to human-annotated ground truth?
- Basis in paper: [explicit] The authors state: "the absence of human-annotated gold data means we cannot yet determine how faithfully ensemble-derived labels reflect learners' true affective states; a stratified, human-coded reference set will be essential for validation."
- Why unresolved: No human annotations were collected for the 16,986 turns; the study relied entirely on LLM-derived labels without validation against ground truth.
- What evidence would resolve it: A stratified sample of turns annotated by trained human raters, with inter-rater reliability metrics and comparison to ensemble predictions via accuracy, F1, or correlation coefficients.

### Open Question 2
- Question: What is the marginal contribution of each model in the ensemble, and can smaller or fewer models achieve comparable robustness?
- Basis in paper: [explicit] "We did not conduct ablation studies to quantify each model's individual contribution or correctness—analyses that could guide more efficient and accurate ensemble design."
- Why unresolved: The ensemble fuses outputs from three models without systematic comparison to single-model or two-model configurations.
- What evidence would resolve it: Ablation experiments evaluating annotation quality (against human labels) and consensus stability for each model alone and in all subset combinations.

### Open Question 3
- Question: Would targeted tutor interventions at neutral-affect transition points measurably improve learning outcomes or emotional trajectories?
- Basis in paper: [inferred] The authors note neutral moments "more often steering students upward than downward, suggesting opportunities for tutors to intervene at precisely these junctures," but do not test whether such interventions would be effective.
- Why unresolved: The study is observational; no interventions were deployed or evaluated.
- What evidence would resolve it: A controlled experiment where an AI tutor responds differently at neutral-valence turns, with outcome measures including learning gains, session persistence, and subsequent affective state distributions.

### Open Question 4
- Question: Do higher-order or duration-aware models (e.g., hidden semi-Markov models, neural sequence models) reveal affective dynamics that first-order Markov chains miss?
- Basis in paper: [explicit] "Our temporal modeling relied on a first-order Markov chain, which may miss longer-range dependencies and state-duration patterns; applying higher-order Markov models, hidden semi-Markov models, or neural sequence models could capture richer affective dynamics."
- Why unresolved: Only first-order transition probabilities were computed; dwell-time distributions and longer-range dependencies were not explicitly modeled.
- What evidence would resolve it: Comparisons of model fit (e.g., AIC/BIC) and predictive accuracy for next-state prediction across first-order, higher-order, and duration-sensitive models on held-out sessions.

## Limitations
- Lack of human validation for LLM-generated affect annotations
- Assumption of first-order Markov dynamics for affect transitions
- Zero-shot approach may miss domain-specific affect nuances
- No ablation studies to quantify marginal contributions of individual models

## Confidence
- Descriptive findings (affect distributions, emotion frequencies): High
- Transition dynamics interpretation: Medium
- Affect stability and rebound patterns: Medium (pending human validation)
- Claims about intervention opportunities: Low (observational only)

## Next Checks
1. Human validation study: Stratified sample of 200-500 turns with multiple annotators; compute Cohen's kappa, ICC, and Fleiss' kappa between ensemble labels and human gold standard.
2. Ablation study: Compare ensemble performance against individual models to quantify marginal contributions and identify potential model dominance.
3. Higher-order Markov comparison: Fit second-order and hidden semi-Markov models to determine if first-order assumption is justified or overly restrictive.