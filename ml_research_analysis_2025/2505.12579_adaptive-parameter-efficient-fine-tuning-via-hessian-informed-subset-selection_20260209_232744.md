---
ver: rpa2
title: Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection
arxiv_id: '2505.12579'
source_url: https://arxiv.org/abs/2505.12579
tags:
- pareto
- ours
- frontier
- peft
- parameter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of selecting the most effective
  subset of parameters to train in parameter-efficient fine-tuning (PEFT) methods
  for large models. The core idea is to formulate subset selection as a multi-task
  optimization problem, balancing model performance and parameter count, and solve
  it via Pareto optimality.
---

# Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection

## Quick Facts
- arXiv ID: 2505.12579
- Source URL: https://arxiv.org/abs/2505.12579
- Reference count: 40
- This paper proposes a method to adaptively select the most effective subset of parameters to train in PEFT methods, using Hessian-informed loss reduction to formulate subset selection as a multi-task optimization problem solved via Pareto optimality.

## Executive Summary
This paper addresses the challenge of selecting which parameters to train in parameter-efficient fine-tuning (PEFT) methods for large models. The authors formulate subset selection as a multi-task optimization problem balancing model performance and parameter count, which they transform into a 0-1 knapsack problem using Hessian-informed loss reduction computed without backpropagation. They propose AdaPEFT, which identifies influential parameter groups early in training and transfers this selection to larger models. Empirically, AdaPEFT achieves a Pareto frontier closely matching exhaustive search and outperforms fixed PEFT methods across various tasks and model sizes.

## Method Summary
AdaPEFT estimates per-parameter-group loss reduction using a second-order Taylor expansion computed via quadratic curve fitting from multiple forward passes at scaled learning rates. This estimation is performed without backpropagation, requiring only 4K+1 forward passes every O(K) iterations through a "lazy updating" scheme. The multi-task optimization problem (minimize loss, minimize parameters) is transformed into a 0-1 knapsack problem where the accumulated per-parameter influence (APPI) serves as the value term and parameter count as the weight. The method computes influence patterns on small proxy models early in training and transfers these patterns to larger target models, achieving adaptive parameter-efficient fine-tuning without the computational cost of exhaustive search.

## Key Results
- AdaPEFT achieves a Pareto frontier closely matching exhaustive search while requiring significantly less computation
- The method outperforms fixed PEFT methods (LoRA, BitFit) across RoBERTa, GPT2, and ViT architectures on NLU and NLG tasks
- Influence patterns identified early in training on small models transfer successfully to larger models and longer training horizons
- AdaPEFT demonstrates consistent performance improvements on GLUE tasks, E2E generation, and CIFAR-100 classification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** AdaPEFT estimates per-parameter-group loss reduction using a second-order Taylor expansion, computed without backpropagation via quadratic curve fitting.
- **Mechanism:** For each parameter group \(w^{(k)}\), the loss change from a gradient step is approximated as \(\Delta L^{(k)}(\eta) \approx -\eta G^{(k)\top}g^{(k)} + \frac{\eta^2}{2} g^{(k)\top} H^{(k)} g^{(k)}\). Multiple forward passes at scaled learning rates \(\hat{\eta}_j \in \{-2\eta, -\eta, \eta, 2\eta\}\) fit a quadratic curve, extracting \(G^{(k)\top}g^{(k)}\) and \(g^{(k)\top}H^{(k)}g^{(k)}\). The optimal per-group learning rate \(\eta^* = \frac{G^{(k)\top}g^{(k)}}{g^{(k)\top}H^{(k)}g^{(k)}}\) maximizes loss reduction, yielding the value term for the knapsack problem.
- **Core Assumption:** The quadratic approximation error is \(o(\eta^2)\) and negligible for typical learning rates; the curvature term \(g^\top H g > 0\) for influential groups.
- **Evidence Anchors:**
  - [Abstract]: "transform this into a 0-1 knapsack problem using Hessian-informed loss reduction, computed without backpropagation"
  - [Section 2.3, p.4]: "loss reduction from this w(k) is \(L(w_{t+1}; \eta) - L(w_t) \approx \Delta L^{(k),t}(\eta) := -\eta G^\top_{(k),t}g_{(k),t} + \frac{\eta^2}{2} g^\top_{(k),t}H_{(k),t}g_{(k),t}\)"
  - [Algorithm 1, p.5]: "Fit a quadratic curve from \(\{\hat{\eta}_j\} \to \{\mathcal{L}_j - \mathcal{L}_0\}\); Derive \(G^\top_{(k),t}g_{(k),t}\) and \(g^\top_{(k),t}H_{(k)}g_{(k),t}\)"

### Mechanism 2
- **Claim:** Parameter subset selection reduces to a 0-1 knapsack problem solvable by greedy approximation, with accumulated per-parameter influence (APPI) as value and parameter count as weight.
- **Mechanism:** The multi-task problem (minimize loss, minimize parameters) is scalarized via the \(\epsilon\)-constraint method into \(\max_A \sum_k I_k \cdot V_k\) subject to \(\sum_k W_k I_k \leq W\), where \(V_k = \sum_t \frac{(G^\top_{(k),t}g_{(k),t})^2}{g^\top_{(k),t}H_{(k)}g_{(k),t} \cdot |w^{(k)}|}\) (Equation 14) and \(W_k = |w^{(k)}|\). The greedy solution sorts groups by APPI descending and selects the top groups under budget.
- **Core Assumption:** The greedy approximation yields a near-Pareto-optimal frontier; Theorem 2.2 guarantees Pareto optimality only for the refined \(\epsilon\)-constraint solution (exhaustive search).
- **Evidence Anchors:**
  - [Abstract]: "formulate subset selection as a multi-task optimization problem... solve it via Pareto optimality"
  - [Section 2.4, p.5]: "(11) is essentially the 0-1 knapsack problem — a classical NP-complete combinatorial problem"
  - [Section 3.2, p.6]: "Approximate solutions... greedy approximation [14]... sort \(\{w^{(k)}\}_k\) by APPI_k in descending order"

### Mechanism 3
- **Claim:** Influence patterns identified early in training on small models transfer to larger models and longer training horizons.
- **Mechanism:** APPI is computed for the first 10% of iterations on a smaller proxy model (e.g., GPT2-small). Groups are ranked and selected under budget, then the same active set is used for full training on the larger target model (e.g., GPT2-large).
- **Core Assumption:** Relative influence rankings stabilize early in training and scale consistently within the same architecture.
- **Evidence Anchors:**
  - [Abstract]: "selected subset empirically transfers across training horizons and model sizes"
  - [Section 4.2, p.7]: "consistent pattern of PPI and APPI across iterations, shortly after the initialization"
  - [Section 5, p.8]: "active sets selected by (small model, short horizon) consistently give good Pareto frontier for (large models, long horizon)"

## Foundational Learning

- **Concept: Second-order Taylor Expansion**
  - **Why needed here:** Core to estimating loss reduction without explicit Hessian. Understanding the approximation's validity range (small \(\eta\), positive curvature) is essential for diagnosing failures.
  - **Quick check question:** For a scalar function \(f(x) = x^4\), is the second-order Taylor expansion around \(x=0\) informative for \(\eta=1\)? What does this imply about learning rate magnitude?

- **Concept: Pareto Optimality**
  - **Why needed here:** The method balances two conflicting objectives; dominance and frontier concepts explain why the two-step refinement of \(\epsilon\)-constraint solutions is necessary (Theorem 2.2).
  - **Quick check question:** Given solutions A (loss=0.5, params=1%) and B (loss=0.4, params=5%), which dominate? Which lie on the Pareto frontier?

- **Concept: 0-1 Knapsack Problem**
  - **Why needed here:** Provides the combinatorial framing for subset selection. The greedy approximation (value/weight) is the practical solver.
  - **Quick check question:** With items (value=10, weight=5), (8,4), (6,3) and capacity=7, what does the greedy algorithm select? Is it optimal?

## Architecture Onboarding

- **Component Map:**
  - PPI Calculator (Algorithm 1) -> APPI Accumulator -> Greedy Knapsack Solver -> PEFT Training Loop

- **Critical Path:**
  1. Run Algorithm 1 on proxy model for 10% of target training steps
  2. Accumulate APPI with smoothing
  3. Select active set via greedy knapsack under budget
  4. Transfer active set to target model; run full PEFT training

- **Design Tradeoffs:**
  - **Lazy update frequency:** Every O(K) iterations amortizes overhead to O(1), but reduces temporal resolution
  - **Proxy model size:** Smaller is cheaper but may misestimate influence; paper uses base/small variants
  - **Budget \(\epsilon\):** Too low misses critical groups; too high sacrifices efficiency gains

- **Failure Signatures:**
  - **Low R² (<0.99) or negative curvature:** Curve fitting unreliable; check gradient scale or learning rate
  - **Flat APPI distribution:** No group differentiation; may indicate architectural mismatch or task unsuitability
  - **Pareto frontier divergence between proxy and target:** Transfer assumption violated; consider proxy-target alignment or direct estimation

- **First 3 Experiments:**
  1. **Replicate visualization (RoBERTa-base/SST2):** Run Algorithm 1 for 10% training; plot PPI heatmap and APPI curves to verify early stabilization and group differentiation (Figures 1, 3)
  2. **Pareto validation:** Compare greedy-selected vs. exhaustive-search Pareto frontiers on same setup (Figure 5, left column) to confirm approximation quality
  3. **Transfer test (GPT2-small→large/E2E):** Select active set on GPT2-small with 10% budget; transfer to GPT2-medium and GPT2-large; compare perplexity against LoRA, BitFit baselines (Table 4)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the optimal granularity of parameter grouping be determined, given that sub-optimal grouping may cause AdaPEFT to fail?
- **Basis in paper:** [explicit] The discussion states, "We note the success of AdaPEFT depends on the grouping of parameters: a sub-optimal grouping strategy may fail to lead to good performance even with AdaPEFT."
- **Why unresolved:** The current paper relies on heuristic groupings derived from existing methods (e.g., LoRA, BitFit) without proposing a method to discover the fundamental unit of influence.
- **What evidence would resolve it:** A systematic study comparing different grouping granularities (e.g., individual weights vs. layers vs. modules) and their resulting Pareto frontiers.

### Open Question 2
- **Question:** How does the inclusion of structural PEFT methods (like adapters or prompt tuning) in the search space affect the knapsack selection and performance?
- **Basis in paper:** [explicit] The related work section suggests, "By taking more PEFT methods into consideration... we allow a larger search space for A and expect better performance... without noticeably increasing the computational cost."
- **Why unresolved:** The experiments are limited to weight-based modifications (LoRA, bias, norm), leaving the interaction between discrete architectural additions and the Hessian-informed selection unexplored.
- **What evidence would resolve it:** Empirical results integrating adapters or prompt tuning parameters into the "active set" selection pool and evaluating the resulting Pareto optimality.

### Open Question 3
- **Question:** Can alternative multi-task optimization formulations, such as linear scalarization, provide theoretical guarantees or better empirical efficiency than the \(\epsilon\)-constraint method for subset selection?
- **Basis in paper:** [explicit] The authors mention in Section D, "There may be multi-task optimization methods that can be directly applicable to our problems," noting linear scalarization as a standard solution with potential challenges.
- **Why unresolved:** The paper focuses on the \(\epsilon\)-constraint method to derive the knapsack problem, leaving the comparative efficiency and theoretical properties of other multi-task scalarization techniques unexplored.
- **What evidence would resolve it:** A comparative analysis of solution quality and computational cost between the knapsack formulation and a linear scalarization approach for subset selection.

## Limitations
- The quadratic approximation is theoretically valid only for small learning rates and positive curvature, yet the method uses fixed scaling factors without adaptive calibration
- The greedy knapsack solution is only guaranteed to approximate the Pareto frontier, not match it exactly—Theorem 2.2's optimality applies to the exhaustive refinement, not the practical greedy method
- Transfer of influence patterns from small to large models assumes architectural and task alignment, yet different patterns are shown across ViT, RoBERTa, and GPT2 architectures

## Confidence

- **High Confidence:** The mathematical formulation of PPI via second-order Taylor expansion and its transformation into a knapsack problem is well-specified and reproducible. The experimental demonstration of early PPI stabilization and the consistent outperformance of AdaPEFT over fixed PEFT baselines are empirically supported.
- **Medium Confidence:** The claim that influence patterns transfer across model sizes within the same architecture is supported by results, but the method's sensitivity to architectural differences is not thoroughly explored. The approximation quality of the greedy knapsack solution relative to exhaustive search is validated on selected tasks but not systematically across all experimental conditions.
- **Low Confidence:** The practical frequency and impact of curve fitting failures (negative curvature or poor fit) are not reported, making it difficult to assess real-world reliability. The exact integration details of GeN AdamW with the quadratic approximation are unspecified, potentially affecting reproducibility of the training phase.

## Next Checks

1. **Curve Fitting Robustness:** Run Algorithm 1 on RoBERTa-base/SST2 for 10% training; log and report the percentage of iterations where \(R^2 < 0.99\) or \(g^\top H g \leq 0\). Analyze whether these failures correlate with specific parameter groups or learning rate scales.

2. **Knapsack Approximation Quality:** For RoBERTa-base/SST2, compare the greedy-selected Pareto frontier against the exhaustive search frontier (as in Figure 5, left column). Quantify the loss-efficiency trade-off gap and determine if it exceeds acceptable thresholds for practical applications.

3. **Cross-Architecture Transfer Failure:** Select influential groups on RoBERTa-base using AdaPEFT, then attempt to transfer this active set to a different architecture (e.g., ViT) on a related task (e.g., SST2→CIFAR100). Measure performance degradation relative to architecture-matched selection to validate the assumption of architectural alignment.