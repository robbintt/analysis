---
ver: rpa2
title: 'Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based
  Multi-Agent Systems'
arxiv_id: '2508.19919'
source_url: https://arxiv.org/abs/2508.19919
tags:
- stereotype
- stereotypes
- agent
- biases
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the emergence of stereotypes in LLM-based
  multi-agent systems through a novel experimental framework simulating workplace
  interactions. Despite starting with neutral conditions and identical agents, the
  study finds that stereotypes emerge spontaneously through multi-agent interactions,
  with effects intensifying with more interaction rounds and the introduction of hierarchical
  structures.
---

# Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems

## Quick Facts
- arXiv ID: 2508.19919
- Source URL: https://arxiv.org/abs/2508.19919
- Authors: Jingyu Guo; Yingying Xu
- Reference count: 5
- Primary result: Stereotypes emerge spontaneously in LLM multi-agent systems through interaction, even with neutral starting conditions and identical agents.

## Executive Summary
This paper demonstrates that stereotypes emerge spontaneously in LLM-based multi-agent systems through multi-agent interactions, rather than solely from training data biases. Using a novel workplace simulation framework with neutral conditions (numerical agent IDs, uniform task performance), the study finds that stereotypes form as an emergent property of how agents navigate social information under cognitive constraints. The research identifies four quantitative metrics (RSI, GBC, CAI, SII) showing consistent stereotype formation across different LLM architectures, with effects intensifying through increased interaction rounds and hierarchical structures.

## Method Summary
The study builds a multi-agent system where agents interact in a workplace simulation with numerically-identified agents and tasks classified by warmth-competence framework. Agents execute tasks with fixed success probability (p0=0.8), broadcast outcomes, and communicate through bilateral, group, and global messages. The system runs in two phases: random task assignment baseline followed by hierarchical phase with a supervisor agent allocating tasks based on accumulated history. After N episodes, peer evaluations are collected and parsed to extract structured mappings for computing four stereotype indices. The framework was tested across Claude, GPT, Mistral, Gemini, and DeepSeek architectures.

## Key Results
- Stereotypes emerge spontaneously from neutral conditions with identical agents and uniform task performance
- Stereotype effects intensify with increased interaction rounds and hierarchical structures (mean RSI increases from ~0.7 to ~0.9)
- Four quantitative metrics consistently measure stereotype formation: RSI (mean 0.79), GBC (mean 0.55), CAI (mean 0.22), SII (mean 0.41)
- Patterns are consistent across different LLM architectures, demonstrating universal emergent property

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Stereotypes emerge through explore-exploit trade-offs in social learning, even without pre-existing biases.
- Mechanism: Agents face cognitive constraints when processing social information. To efficiently navigate multi-agent interactions, they develop simplified heuristics (stereotypes) that reduce computational complexity of evaluating each agent individually. These heuristics persist because they provide "good enough" decisions with minimal cognitive cost.
- Core assumption: The paper draws on theoretical work (Bai, Griffiths, and Fiske 2024) but does not empirically validate this specific mechanism; it infers from observed outcomes.
- Evidence anchors:
  - [abstract] "stereotype formation in AI systems may arise as an emergent property of multi-agent interactions, rather than merely from training data biases"
  - [Introduction] "stereotypes could emerge even in theoretically unbiased environments, as a natural consequence of how agents navigate social information and make decisions under constraints"
  - [corpus] Related work on stereotype formation (Bai et al. 2025) shows explicitly unbiased LLMs still form biased associations, supporting the emergence hypothesis.
- Break condition: If agents are given unlimited reasoning compute and explicit instructions to evaluate each agent independently without generalization, stereotype indices should approach zero.

### Mechanism 2
- Claim: Self-reinforcing feedback loops amplify initial random variations into persistent stereotypes.
- Mechanism: Early random task outcomes create initial associations. Agents observe these patterns, form tentative stereotypes, then act on them. When a supervisor agent allocates tasks based on observed history, it preferentially assigns tasks to agents it perceives as successful, creating confirmation loops. This transforms noise into signal.
- Core assumption: The paper demonstrates correlation (stereotypes increase with interaction rounds and hierarchical control) but does not isolate the feedback loop mechanism experimentally.
- Evidence anchors:
  - [Results] "The GBC demonstrates an even stronger feedback effect, with AI-assigned scenarios maintaining consistently higher values (≈ 0.6–0.8) compared to random assignment (≈ 0.3–0.5)"
  - [Results] "RSI reveals a striking amplification of stereotypes when task allocation is controlled by the boss agent (mean ≈ 0.9) compared to random assignment (mean ≈ 0.7)"
  - [corpus] Corpus papers on LLM bias (Kotek et al. 2023, An et al. 2024) document training data bias but do not address multi-agent feedback dynamics directly.
- Break condition: If task outcomes are hidden from agents and supervisor, or if task assignment remains uniformly random regardless of perceived performance, stereotype amplification should plateau rather than intensify.

### Mechanism 3
- Claim: Hierarchical decision-making authority accelerates stereotype crystallization through concentrated judgment.
- Mechanism: A single supervisor agent making allocation decisions for all agents creates a bottleneck where its biases propagate system-wide. Unlike distributed decision-making where biases might average out, hierarchical structures amplify individual judgment patterns. The supervisor's interpretations of agent performance become self-fulfilling through assignment patterns.
- Core assumption: The paper shows hierarchical conditions increase stereotype metrics but does not prove this is caused by concentrated authority vs. other factors like increased task-relevant communication.
- Evidence anchors:
  - [abstract] "stereotype effects intensify with increased interaction rounds and decision-making power, particularly after introducing hierarchical structures"
  - [Results] "GPT showed perfect (100%) strong stereotype formation with a boss agent versus 94% without"
  - [corpus] Limited corpus evidence on hierarchical multi-agent bias; neighboring papers focus on single-model outputs rather than structural effects.
- Break condition: If supervisor decisions are made through ensemble voting across multiple independent agents, or if supervisor rotation prevents any single agent from accumulating decision authority, stereotype amplification should decrease.

## Foundational Learning

- Concept: **Stereotype Content Model (warmth-competence framework)**
  - Why needed here: The paper's job classification and analysis metrics (SII) are built on this two-dimensional model. Without understanding warmth vs. competence dimensions, you cannot interpret the experimental design or results.
  - Quick check question: Can you explain why a "data scientist" is classified as warm-and-competent while a "manager" is cold-and-competent, and how this affects stereotype formation analysis?

- Concept: **Meta-analysis and aggregate vs. individual-level analysis**
  - Why needed here: The paper's key finding—uniform distribution across aggregated experiments but strong stereotypes in individual runs—requires understanding why meta-analysis reveals neutral conditions while single runs show bias emergence.
  - Quick check question: Why does the paper find near-uniform person-job associations in aggregated data but 0.8-1.0 scores in single experiments? What does this tell you about stereotype emergence?

- Concept: **ReAct framework (Reasoning + Acting)**
  - Why needed here: The agent architecture builds directly on ReAct's observation-thought-action cycle. Understanding this pattern is necessary to replicate or modify the experimental system.
  - Quick check question: How does the f_c caller agent extension enable compatibility with LLMs lacking native function-calling? What role does the observation-thought-action chain play in stereotype formation?

## Architecture Onboarding

- Component map:
  - **Agent Layer**: ReAct-based agents with numerical identifiers (person_1, person_2...), each running identical LLM with neutral prompts
  - **Task System**: Task pool T with uniform random assignment, fixed success probability p0=0.8 across all agent-task pairs
  - **Communication Layer**: Bilateral conversations, small-group discussions (k participants), global messages—queued and delivered in next episode broadcast
  - **History Store**: Interaction history H = {h1, h2, ...} containing task records, messages, system notifications
  - **Supervisor Agent** (hierarchical extension): Maps Hi → T × A for task allocation based on observed patterns
  - **Evaluation System**: Parser agent extracts Agent-Role and Role-Agent mappings from qualitative assessments

- Critical path:
  1. Initialize agents with numerical IDs and neutral system prompts
  2. Run random task assignment episodes (baseline phase)
  3. Agents execute tasks → outcomes broadcast → communication phase
  4. Introduce supervisor agent (if hierarchical condition)
  5. Supervisor assigns tasks based on accumulated history
  6. After N episodes, trigger peer evaluation
  7. Parser agent extracts structured mappings
  8. Compute RSI, GBC, CAI, SII indices

- Design tradeoffs:
  - **Numerical vs. demographic identifiers**: Paper trades external validity for internal validity—numerical IDs eliminate training data bias but abstract away real-world demographic dynamics. Ablation study validates this works.
  - **Fixed success probability vs. skill-based variation**: Using p0=0.8 uniformly ensures stereotype emergence isn't confounded by actual performance differences, but limits realism.
  - **Synchronized vs. asynchronous communication**: Queued message delivery prevents immediate reactions and ensures cumulative observation-based judgments, but slows interaction dynamics.

- Failure signatures:
  - **No stereotype emergence**: Check if task outcomes are actually random, if agents can observe each other's outcomes, if communication channels are functioning. Paper shows stereotypes emerge reliably, so failure suggests implementation bug.
  - **Stereotypes present in ablation control**: If numerical ID experiments show same bias levels as demographic experiments, neutral prompt design has failed.
  - **Uniform across conditions**: If hierarchical vs. random conditions show no difference, supervisor agent decision-making may not be influencing task allocation.
  - **Model-specific patterns only**: If only one LLM shows stereotype formation, suggests model-specific bias rather than emergent property.

- First 3 experiments:
  1. **Baseline replication**: Run 10 agents, 20 episodes, random task assignment, no supervisor. Compute all four indices. Target: RSI ~0.7, SII ~0.4. Verify aggregated runs show uniform distribution while individual runs show specialization.
  2. **Ablation validation**: Run identical setup with demographic profiles instead of numerical IDs. Confirm significantly higher bias indices, validating that main experiment achieves neutral conditions.
  3. **Hierarchical comparison**: Run same 10 agents, 20 episodes, but introduce supervisor agent at episode 10. Compare stereotype indices before/after supervisor introduction. Target: RSI increase from ~0.7 to ~0.9 post-supervisor.

## Open Questions the Paper Calls Out

- **What specific computational mechanisms drive spontaneous stereotype emergence in LLM multi-agent interactions?**
  - The abstract states "the need for future research to explore the underlying mechanisms of this phenomenon"
  - The paper demonstrates that stereotypes emerge from neutral conditions and identifies contributing factors (interaction rounds, hierarchies), but does not isolate the computational processes by which neutral interactions produce stereotypical role-person associations.
  - Controlled ablation experiments isolating candidate mechanisms (e.g., pattern-completion heuristics, social learning, explore-exploit trade-offs) with causal manipulation would resolve this.

- **What interventions can effectively mitigate or prevent emergent stereotyping in LLM-based multi-agent systems?**
  - The abstract explicitly calls for developing "strategies to mitigate its ethical impacts"
  - The paper comprehensively documents stereotype emergence across conditions and models but proposes and tests no mitigation approaches.
  - Experimental comparisons showing specific interventions (modified prompts, interaction protocols, architectural constraints, debiasing objectives) significantly reduce RSI, GBC, CAI, and SII scores while preserving task performance would resolve this.

- **Do stereotype formation patterns generalize to multi-agent systems in domains beyond workplace simulations?**
  - The experimental framework exclusively uses workplace tasks and occupational stereotypes based on the warmth-competence model, leaving generalizability to other high-stakes domains untested.
  - Healthcare, education, or legal contexts have different task structures and social dynamics that may produce different stereotyping patterns.
  - Replication studies applying the same multi-agent framework with task sets and role categories from non-workplace domains, comparing resulting indices to workplace baselines, would resolve this.

## Limitations
- Experiments use simplified workplace simulations with abstract numerical identifiers rather than real demographic dynamics
- Study does not isolate specific computational mechanisms driving stereotype emergence
- Limited investigation of scalability to larger populations or more complex organizational structures

## Confidence
- **High**: Stereotypes emerge spontaneously in multi-agent systems from neutral conditions
- **Medium**: Specific mechanisms (explore-exploit trade-offs, feedback loops, hierarchical concentration) contribute to stereotype formation
- **Low**: Generalizability to real-world organizational contexts and long-term stability of emergent patterns

## Next Checks
1. **Mechanism Isolation Experiment**: Run parallel conditions varying only one factor (e.g., supervisor presence vs. random assignment) while keeping interaction rounds constant, to isolate which mechanism drives the strongest stereotype amplification.

2. **Longer Time Horizon Study**: Extend experiments beyond 20 episodes to test whether stereotypes stabilize, reverse, or intensify over extended interaction periods, and whether initial patterns persist.

3. **Heterogeneous Agent Performance**: Introduce agent-specific task success probabilities to test whether performance differences create compounding bias effects beyond the uniform performance baseline studied here.