---
ver: rpa2
title: Automatic Construction of Pattern Classifiers Capable of Continuous Incremental
  Learning and Unlearning Tasks Based on Compact-Sized Probabilistic Neural Network
arxiv_id: '2501.00725'
source_url: https://arxiv.org/abs/2501.00725
tags:
- tasks
- learning
- pattern
- cs-pnn
- unlearning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a compact-sized probabilistic neural network
  (CS-PNN) for pattern classification tasks. The network is constructed using a one-pass,
  data-driven algorithm that automatically determines the network structure and parameters
  without hyperparameter tuning.
---

# Automatic Construction of Pattern Classifiers Capable of Continuous Incremental Learning and Unlearning Tasks Based on Compact-Sized Probabilistic Neural Network

## Quick Facts
- arXiv ID: 2501.00725
- Source URL: https://arxiv.org/abs/2501.00725
- Reference count: 37
- Primary result: A one-pass, data-driven algorithm constructs a compact probabilistic neural network (CS-PNN) for pattern classification that achieves similar accuracy to MLPs while using 4-46% of the RBF units of the original PNN model.

## Executive Summary
This paper proposes a compact-sized probabilistic neural network (CS-PNN) for pattern classification tasks that automatically determines its structure and parameters without hyperparameter tuning. The network is constructed using a one-pass, data-driven algorithm that dynamically varies its structure as new data arrives or classes are removed. The CS-PNN is capable of continuous incremental learning and unlearning tasks, maintaining reasonable classification accuracy even when classes are continuously added and removed.

## Method Summary
The CS-PNN is constructed using a one-pass algorithm that processes training samples sequentially. For each sample, the network calculates the maximal distance (dmax) among all current centroid-input pairs, updates the radius σ = dmax/k (where k is the current number of classes), and classifies the sample. If correctly classified, the winning centroid is updated via averaging; if misclassified, a new RBF unit is added with the sample as its centroid. This eliminates the threshold hyperparameter θ used in prior work. The subnet-based architecture allows straightforward class-wise unlearning by simply removing the corresponding subnet and its RBFs.

## Key Results
- CS-PNN uses 4-46% of the RBF units compared to the original PNN model while achieving similar classification performance to MLPs in standard tasks
- The network exhibits sufficient capability in continuous class incremental learning and unlearning tasks
- Maintains reasonable classification accuracy even when classes are continuously added and removed
- Demonstrated effectiveness across nine publicly available datasets including MNIST and ionosphere

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A compact-sized PNN can be constructed automatically without hyperparameter tuning by adding RBF units only when incoming training data is misclassified.
- Mechanism: During construction, each training sample is passed through the current network. If correctly classified, the centroid of the maximally activated RBF is updated via averaging. If misclassified, a new RBF unit is added with the sample as its centroid.
- Core assumption: Misclassification reliably indicates insufficient pattern space coverage rather than label noise or inherent class overlap.
- Evidence anchors: Section 2.4 states the algorithm adds RBFs when data is incorrectly classified rather than using a manually given threshold.

### Mechanism 2
- Claim: A dynamically varying RBF radius (σ = dmax/k) enables the network to adapt to continuously changing pattern spaces during incremental learning.
- Mechanism: The radius σ is recalculated for each RBF whenever new data arrives, where dmax is the maximal distance among all current centroid-input pairs and k is the current number of classes.
- Core assumption: The pattern space can be reasonably approximated by dividing Dmax equally among classes as hyperspheres.
- Evidence anchors: Section 2.4 describes how dmax is updated to track the varying pattern space whenever new data arrives.

### Mechanism 3
- Claim: The subnet-based architecture of PNNs enables straightforward class-wise unlearning without catastrophic forgetting.
- Mechanism: Each output class corresponds to a distinct subnet containing only the RBFs assigned to that class. Unlearning a class simply removes the corresponding subnet and its RBFs.
- Core assumption: Class representations are sufficiently separable that removing one subnet does not degrade decision boundaries for remaining classes.
- Evidence anchors: Section 2.1 explains that each RBF node is connected only to a single output node corresponding to the same class.

## Foundational Learning

- Concept: **Probabilistic Neural Networks (PNN) and Radial Basis Functions**
  - Why needed here: CS-PNN is built on standard PNN architecture; understanding RBF activation (hj(x) = exp(-||x - cj||²/2σ²)) is essential for following the construction algorithm.
  - Quick check question: Can you explain why a smaller σ value makes an RBF more selective?

- Concept: **Class Incremental Learning (CIL) vs. Instance Incremental Learning (IIL)**
  - Why needed here: The paper evaluates both scenarios; CIL is harder because only partial class data is available at each step.
  - Quick check question: In CIL, why must the classifier re-estimate the pattern space for unknown classes?

- Concept: **Catastrophic Forgetting**
  - Why needed here: The paper positions CS-PNN as a solution to catastrophic forgetting in DNNs; understanding this problem clarifies the motivation.
  - Quick check question: Why do DNNs suffer from catastrophic forgetting while PNNs do not?

## Architecture Onboarding

- Component map:
  - Input layer: Nd units (one per feature dimension)
  - Hidden layer: Variable number of RBF units (hj), each storing a centroid vector cj
  - Output layer: Nc units (one per class), each with a dedicated subnet of RBFs
  - Weight connections: Input-to-hidden weights = centroid values; hidden-to-output = binary (1 if same class, 0 otherwise)

- Critical path:
  1. Initialize with first training sample → creates first subnet and RBF
  2. For each subsequent sample: compute dmax, update σ, classify, then either add RBF or update centroid
  3. For unlearning: identify subnet(s) or RBF(s) to remove and delete directly
  4. For testing: recompute dmax and σ for each test sample, classify via max output

- Design tradeoffs:
  - Network compactness vs. accuracy: CS-PNN uses 4-46% of original PNN RBFs but may sacrifice some accuracy
  - Simplicity vs. optimality: No hyperparameter tuning is convenient but may not yield optimal σ for all datasets
  - Memory vs. speed: Fewer RBFs than original PNN but still more than MLP-NN (e.g., 3684 vs. 1058 hidden units for MNIST)

- Failure signatures:
  - Rapid RBF growth: Indicates label noise or insufficient initial σ
  - Accuracy drop after unlearning: Suggests class overlap was handled by the removed subnet
  - Large accuracy gap between CIL final stage and standard task: Pattern space estimation is inherently difficult with partial class data

- First 3 experiments:
  1. Reproduce standard classification on a small dataset (e.g., ionosphere) to verify CS-PNN achieves comparable accuracy with fewer RBFs than original PNN
  2. Run CIL with 2-4 classes added per task on MNIST; compare accuracy trajectory against iCaRL baseline to observe catastrophic forgetting
  3. Execute CUIL scenario (unlearn floor(Nc/2) classes, then re-learn them) and measure both accuracy fluctuation and RBF count changes to validate structural adaptability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CS-PNN perform when applied to large-scale databases with a significantly higher number of classes than those tested in this study?
- Basis in paper: The conclusion states, "Future work is directed to investigate cases with more classes as well as larger databases than those used in this study."
- Why unresolved: The simulation study was limited to datasets with a maximum of 26 classes and moderate sample sizes, leaving the scalability to modern high-dimensional benchmarks unproven.
- What evidence would resolve it: Performance metrics (accuracy, number of hidden units, training time) evaluated on large-scale datasets (e.g., ImageNet) with hundreds or thousands of classes.

### Open Question 2
- Question: Can parallel computing implementation effectively reduce the CS-PNN testing latency to match or exceed that of compact Multilayer Perceptrons (MLPs)?
- Basis in paper: The text notes that "implementing it in a parallel computing environment... is, therefore, currently under investigation for the CS-PNN case" to alleviate testing mode drawbacks.
- Why unresolved: While the authors cite previous analytical work suggesting parallelism helps, they have not yet provided empirical evidence of the actual speedup or resource overhead for the proposed CS-PNN specifically.
- What evidence would resolve it: Empirical comparison of inference throughput and latency between a parallelized CS-PNN implementation and optimized MLP baselines on identical hardware.

### Open Question 3
- Question: What specific geometric or statistical properties of the 'isolet' and 'sat' datasets cause the significant accuracy drops observed during Continuous Unlearning and Incremental Learning (CUIL) tasks?
- Basis in paper: The authors observe that accuracy "considerably dropped" for these two datasets during CUIL and speculate that "pattern space separation for these two cases was more challenging," but provide no definitive cause.
- Why unresolved: The proposed dynamic radius heuristic (σ = dmax/k) may fail to adapt appropriately when the underlying data distribution or inter-class distances change significantly during the unlearning/relearning cycles.
- What evidence would resolve it: An analysis of the decision boundaries and RBF radius evolution during CUIL for these datasets, potentially leading to a modified radius update rule that stabilizes accuracy.

## Limitations
- The adaptive radius mechanism (σ = dmax/k) assumes uniform class distribution and may fail with imbalanced or overlapping classes
- The claim of "no catastrophic forgetting" relies on the subnet architecture, but empirical validation only shows stability across 3-class sequences rather than long incremental chains
- The method's scalability to high-dimensional or non-tabular data (e.g., raw images) remains unverified beyond MNIST

## Confidence

- Standard classification performance claims: **High** (supported by 9 dataset experiments with quantitative comparisons)
- Incremental learning robustness: **Medium** (limited to 3-class sequences; no long-term forgetting analysis)
- Unlearning capability: **Medium** (tested only on CUIL with half-class removals; real-world noise scenarios not explored)

## Next Checks

1. Test CS-PNN on long incremental sequences (5+ classes) to measure cumulative forgetting beyond the reported 3-class limit.
2. Evaluate performance under noisy label conditions to verify the misclassification-triggered RBF addition doesn't overfit to corrupted samples.
3. Benchmark against state-of-the-art continual learning methods (e.g., iCaRL, EWC) on standard incremental learning benchmarks like CORe50 or miniImageNet.