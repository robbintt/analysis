---
ver: rpa2
title: Segment Any RGB-Thermal Model with Language-aided Distillation
arxiv_id: '2505.01950'
source_url: https://arxiv.org/abs/2505.01950
tags:
- segmentation
- semantic
- feature
- fusion
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of applying the Segment Anything
  Model (SAM) to RGB-thermal (RGB-T) semantic segmentation, which is critical for
  scene understanding in adverse conditions. The proposed SARTM framework customizes
  SAM2 for RGB-T data by introducing LoRA layers for modality adaptation, an auxiliary
  semantic segmentation head, and a language-aided distillation module using CLIP
  to guide cross-modal feature fusion.
---

# Segment Any RGB-Thermal Model with Language-aided Distillation

## Quick Facts
- **arXiv ID:** 2505.01950
- **Source URL:** https://arxiv.org/abs/2505.01950
- **Reference count:** 40
- **Primary result:** Achieves state-of-the-art 89.88% mIoU on PST900 benchmark for RGB-thermal semantic segmentation

## Executive Summary
This paper introduces SARTM, a framework that extends Segment Anything Model (SAM) to RGB-thermal semantic segmentation through modality adaptation and cross-modal distillation. The approach customizes SAM2 with LoRA layers for thermal processing, an auxiliary segmentation head for multi-scale feature fusion, and a language-aided distillation module using CLIP to align semantic representations across modalities. Extensive experiments on three benchmarks demonstrate significant performance improvements over existing methods, with 89.88% mIoU on PST900.

## Method Summary
SARTM adapts SAM2 for RGB-thermal data through three key innovations: LoRA-based modality adaptation that preserves SAM's generalization while enabling thermal processing, an auxiliary semantic segmentation head that combines multi-scale features for improved context, and a cross-modal knowledge distillation module using CLIP language embeddings to align semantic representations. The framework maintains SAM2's image encoder while adding modality-specific parameters, fuses features through a Feature Relation Module and Feature Fusion Module, and employs dual prediction paths with weighted losses for training stability.

## Key Results
- Achieves 89.88% mIoU on PST900 benchmark, outperforming existing methods
- Ablation studies show 3.64% mIoU drop when removing language guidance and 4.96% drop without auxiliary segmentation head
- Optimal LoRA rank of 16 identified through systematic ablation, with performance degradation at higher ranks
- Cross-modal knowledge distillation significantly improves semantic consistency across RGB and thermal modalities

## Why This Works (Mechanism)

### Mechanism 1: LoRA-based Modality Adaptation
Low-Rank Adaptation layers enable SAM2 to process thermal modalities while preserving pretrained generalization. LoRA decomposes weight updates into low-rank matrices (W_a and W_b with rank r â‰ª d) that are trained independently per modality while the backbone remains frozen. This creates an efficient adaptation pathway that modifies attention behavior for thermal features without catastrophic forgetting of RGB representations.

### Mechanism 2: Cross-Modal Knowledge Distillation via CLIP Semantic Alignment
The Cross-Modal Knowledge Distillation module extracts class name embeddings via CLIP's text encoder and aligns them with visual features through KL divergence on self-similarity matrices. This implicit relation transfer forces the student to learn intra-class consistency that mirrors the teacher's semantic structure, reducing cross-modal semantic ambiguity.

### Mechanism 3: Dual-Path Multi-Scale Feature Fusion
Combining a modified SAM2 mask decoder with an auxiliary segmentation head, both consuming multi-scale feature pyramids, improves segmentation precision through complementary prediction pathways. The auxiliary head compensates for SAM2's original mask decoder limitations in semantic segmentation by providing scale-invariant features through FPN-style fusion.

## Foundational Learning

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed here: Understanding LoRA decomposition is essential for tuning rank parameters and diagnosing under/over-parameterization during modality adaptation
  - Quick check question: Given d=512 and rank r=16, how many trainable parameters does LoRA add per modality? (Answer: 16,384 for Q and V combined)

- **Concept: Knowledge Distillation with KL Divergence**
  - Why needed here: The CMKD module relies on aligning self-similarity distributions rather than direct feature matching
  - Quick check question: Why use self-similarity matrices instead of direct feature alignment? (Answer: To transfer relational knowledge rather than enforcing exact feature matching across modalities)

- **Concept: Feature Pyramid Networks (FPN)**
  - Why needed here: The multi-scale architecture follows FPN principles for cross-scale feature aggregation
  - Quick check question: In Eq. 8, why upsample F_{i+1} before addition to Z_i? (Answer: To match spatial dimensions for element-wise fusion)

## Architecture Onboarding

- **Component map:** Input (RGB + Thermal) -> Patch Embedding -> Frozen SAM2 Encoder + LoRA Layers -> Feature Pyramid Network -> Cross-Modal Fusion -> Dual Prediction Paths -> Loss Aggregation

- **Critical path:** LoRA adaptation quality determines thermal encoding; CMKD alignment determines semantic consistency; auxiliary head fusion determines scale-invariant prediction quality; loss weight balance determines training stability

- **Design tradeoffs:**
  - LoRA rank: Rank 16 optimal; higher ranks risk overfitting
  - Auxiliary head: FPN outperforms alternatives but adds computation
  - Loss weights: w_1=0.008, w_2=10000, w_3=100 optimal; extreme values degrade performance
  - Freezing strategy: Encoder frozen with LoRA preserves generalization

- **Failure signatures:**
  - LoRA underfitting: Rank < 8 shows lower mAcc
  - LoRA overfitting: Rank > 32 shows degraded mIoU
  - Missing language guidance: 3.64 mIoU drop on PST900
  - Missing auxiliary head: 4.96 mIoU drop on PST900
  - Loss imbalance: Extreme weights drop mIoU by 3-5 points

- **First 3 experiments:**
  1. LoRA rank sweep: Train with ranks [4, 8, 16, 32] to confirm rank=16 optimum
  2. CMKD ablation: Disable L_se and L_cr losses individually to measure degradation
  3. Inference latency test: Measure FPS with/without auxiliary head to assess tradeoff

## Open Questions the Paper Calls Out
None

## Limitations
- Performance relies on specific data characteristics and hyperparameter tuning
- CLIP-based distillation effectiveness may break down for specialized thermal categories
- Dual-path architecture's gains depend critically on auxiliary head design and loss weight balance

## Confidence
- **High Confidence:** Overall architecture design is sound and well-supported by ablation studies
- **Medium Confidence:** Mechanism explanations are detailed but lack theoretical guarantees
- **Low Confidence:** Cross-modal generalization claims based on limited dataset diversity

## Next Checks
1. Test SARTM on thermal datasets from different domains to verify cross-domain generalization
2. Create controlled test cases where thermal features contain information absent from RGB to measure LoRA adaptation limits
3. Profile inference latency with full dual-path architecture vs. single-path variants to assess deployment tradeoffs