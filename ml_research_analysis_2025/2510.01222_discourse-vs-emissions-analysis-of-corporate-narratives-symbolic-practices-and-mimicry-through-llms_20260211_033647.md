---
ver: rpa2
title: 'Discourse vs emissions: Analysis of corporate narratives, symbolic practices,
  and mimicry through LLMs'
arxiv_id: '2510.01222'
source_url: https://arxiv.org/abs/2510.01222
tags:
- climate
- firms
- commitment
- commitments
- net-zero
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study uses large language models to analyze climate-related
  narratives in sustainability reports of 828 U.S. firms.
---

# Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs

## Quick Facts
- arXiv ID: 2510.01222
- Source URL: https://arxiv.org/abs/2510.01222
- Reference count: 12
- Primary result: LLM-based analysis of 828 U.S. firm sustainability reports reveals symbolic climate commitments decoupled from quantitative targets and widespread mimetic disclosure practices.

## Executive Summary
This study uses large language models to analyze climate-related narratives in sustainability reports of 828 U.S. firms. Four classifiers (sentiment, commitment, specificity, and target ambition) extract narrative indicators, which are linked to firm attributes such as emissions, market capitalization, and sector. Results show that risk-focused narratives often align with explicit commitments, but quantitative targets (e.g., net-zero pledges) remain decoupled from tone. Larger and higher-emitting firms disclose more commitments and actions than peers, though inconsistently with quantitative targets. Widespread similarity in disclosure styles suggests mimetic behavior, reducing differentiation and decision usefulness. LLMs effectively reveal symbolic practices and highlight the need for stronger regulation to connect commitments with verifiable transition strategies.

## Method Summary
The study collects sustainability and annual reports from 828 U.S. firms, extracts climate-relevant paragraphs using keyword filtering, and applies four pre-trained ClimateBERT classifiers to label paragraphs by sentiment (risk/opportunity/neutral), commitment (explicit vs. general), specificity (general vs. specific), and target ambition (net-zero vs. reduction targets). Report-level indicators are derived by aggregating paragraph-level classifications using threshold rules. These narrative indicators are then correlated with firm-level attributes (emissions, market cap, sector) and clustered to identify common disclosure profiles and patterns of mimetic behavior.

## Key Results
- Risk-oriented climate narratives correlate with explicit commitments and specific disclosures, but not with quantitative targets
- Larger and higher-emitting firms disclose more commitments and actions than peers, though inconsistently with quantitative targets
- Widespread similarity in disclosure styles suggests mimetic behavior, reducing differentiation and decision usefulness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Risk-oriented climate narratives correlate with explicit commitments and specific disclosures, but not with quantitative targets.
- **Mechanism**: Firms facing material climate exposure adopt defensive framing (risk tone) and operationalize commitments through specific actions, yet stop short of binding quantitative goals—suggesting strategic ambiguity.
- **Core assumption**: Assumption: Risk framing reflects genuine material exposure rather than purely performative communication.
- **Evidence anchors**:
  - [abstract]: "risk-focused narratives often align with explicit commitments, but quantitative targets (e.g., net-zero pledges) remain decoupled from tone"
  - [section 4.1.1]: Sentiment-commitment correlation ρ=−0.42 (risk tone → commitment); sentiment-netzero ρ=−0.09 (no relationship)
  - [corpus]: Related work (Bingler et al. 2023) similarly finds "cheap talk" patterns—commitments without operational depth
- **Break condition**: If risk framing were purely symbolic, correlation with specificity (ρ=−0.32) would be near-zero; the negative correlation suggests at least partial substantive alignment.

### Mechanism 2
- **Claim**: Larger and higher-emitting firms show higher disclosure maturity (commitment + specificity) but inconsistent target linkage.
- **Mechanism**: Regulatory scrutiny and stakeholder pressure scale with firm size and emissions intensity, forcing more detailed disclosures—but firms strategically limit binding commitments to retain operational flexibility.
- **Core assumption**: Assumption: Larger firms face asymmetric pressure relative to their emissions impact.
- **Evidence anchors**:
  - [abstract]: "larger and higher-emitting firms disclose more commitments and actions than peers, though inconsistently with quantitative targets"
  - [section 4.2]: Commitment rises from 80.6% (Cap_1) to 100% (Cap_8); specificity from 68.5% to 95.2%. Yet 35.5% of specific-commitment firms lack any target.
  - [corpus]: Limited direct corroboration—corpus papers focus on disclosure tools, not firm-size mechanisms
- **Break condition**: If regulatory pressure alone drove behavior, target adoption should scale similarly to commitment; the decoupling suggests strategic restraint.

### Mechanism 3
- **Claim**: Mimetic isomorphism produces sector-wide convergence in disclosure style, reducing information value.
- **Mechanism**: Firms benchmark against industry peers rather than tailoring disclosures to actual performance, leading to standardized narratives that obscure differentiation—consistent with institutional theory.
- **Core assumption**: Assumption: Convergence in narrative patterns across heterogeneous firm characteristics indicates imitation, not shared material constraints.
- **Evidence anchors**:
  - [abstract]: "widespread similarity in disclosure styles suggests mimetic behavior, reducing differentiation and decision usefulness"
  - [section 4.1.3]: Cluster analysis reveals 10 profiles capturing 828 firms; high-emission clusters (3,7) show similar narratives despite different target strength
  - [section 5.2]: H6 supported—"limited differences observed across emissions, firm size, and sector... suggest mimicry effects"
  - [corpus]: Huang et al. (2025b) explicitly documents imitation in ESG disclosure; Aerts et al. (2006) finds intra-industry environmental reporting imitation
- **Break condition**: If convergence reflected common regulatory requirements rather than peer imitation, variation should persist within sectors by firm-specific factors; the observed homogeneity favors mimetic explanation.

## Foundational Learning

- **Concept: Fine-tuned domain-specific classifiers vs. general-purpose LLMs**
  - Why needed here: The paper uses ClimateBERT models pre-trained on climate text, not generic LLMs. This improves precision for climate-specific semantics (e.g., "net-zero" vs. "reduction").
  - Quick check question: Why would a general sentiment classifier misclassify "net-zero by 2050" as neutral instead of ambitious?

- **Concept: Paragraph-level classification with threshold aggregation**
  - Why needed here: Classifiers operate on paragraphs; report-level labels require aggregation rules (e.g., >30% risk = "risk orientation"). Understanding this prevents misinterpreting report labels as document-level embeddings.
  - Quick check question: A report with 28% risk paragraphs and 25% opportunity paragraphs would be classified as what? (Answer: neutral)

- **Concept: Spearman correlation for ordinal categorical variables**
  - Why needed here: Narrative labels (risk < neutral < opportunity) are ordinal; Spearman captures monotonic relationships where Pearson would fail.
  - Quick check question: Why is ρ=−0.42 between sentiment and commitment considered "weak" despite statistical significance?

## Architecture Onboarding

- **Component map**: Text extraction -> Keyword filtering -> Paragraph classification -> Threshold aggregation -> Firm-level merge -> Correlation/clustering analysis
- **Critical path**: Keyword filtering → paragraph classification → threshold aggregation → firm-level merge → cluster analysis. Errors in keyword filtering propagate silently.
- **Design tradeoffs**:
  - Cross-sectional design (single report per firm) limits temporal insight but reduces complexity
  - Threshold choices (e.g., 40% for commitment) are arbitrary but tested for robustness; alternative thresholds may change classifications
  - Manual report collection ensures relevance but limits scalability
- **Failure signatures**:
  - High missing Scope 3 data (355/828) biases emission-intensity analyses
  - Firms with identical narrative profiles but vastly different emissions suggest mimicry, not model failure
  - Non-committed firms with net-zero targets (51.8%) indicate label semantic gaps—commitment detection misses informal pledges
- **First 3 experiments**:
  1. **Reproduce correlation matrix with alternative thresholds** (e.g., 35% commitment) to test robustness of weak correlations
  2. **Train a simple classifier to predict emissions from narrative features**—high error would confirm authors' finding that narratives cannot proxy for performance
  3. **Within-sector similarity analysis**: Calculate pairwise narrative distance within vs. across sectors to quantify mimicry strength (expect lower intra-sector variance)

## Open Questions the Paper Calls Out

- **Open Question 1**: How do corporate climate disclosure strategies and maturity evolve over longer observation windows (e.g., four years or more)?
  - **Basis in paper**: [explicit] The authors state the analysis relies on a cross-sectional dataset and explicitly call for "future time-series studies" to capture how strategies change over time.
  - **Why unresolved**: The current study is static (mostly 2023–2024 data) and assumes narrative stability, preventing the observation of strategic adaptation or policy effects over time.
  - **What evidence would resolve it**: Longitudinal panel data tracking the same firms' narrative indicators and emissions across multiple years.

- **Open Question 2**: To what extent do LLM-derived narrative classifications correlate with actual, verified climate performance?
  - **Basis in paper**: [explicit] The "Limitations and future research" section suggests "comparing narrative-based classifications with actual climate performance."
  - **Why unresolved**: This study links narratives to firm attributes (size, sector) and self-reported emissions, but does not validate if "specific" or "committed" narratives lead to better environmental outcomes.
  - **What evidence would resolve it**: A study combining the LLM narrative scores with ex-post verified emission reduction data or physical climate risk metrics.

- **Open Question 3**: Can richer embedding-based text analysis capture disclosure nuances missed by the predefined classification labels used in this study?
  - **Basis in paper**: [explicit] The authors propose "applying richer embedding-based text analysis to capture disclosure nuance beyond predefined classification labels."
  - **Why unresolved**: The current method relies on four specific classifiers (sentiment, commitment, etc.) and threshold-based aggregation, which may obscure subtle symbolic language or "cheap talk" that semantic embeddings could detect.
  - **What evidence would resolve it**: A comparative methodology applying vector-based text similarity measures alongside the current classifiers to identify discrepancies in nuance.

## Limitations
- Cross-sectional design prevents causal inference about how narratives evolve with regulation or performance over time
- Keyword-based filtering may miss relevant paragraphs with synonyms or context-dependent language
- Missing Scope 3 emissions (307 firms) creates systematic bias in emission-intensity analyses

## Confidence
- **High**: Findings on commitment-specification decoupling (H2), and mimicry reducing differentiation (H6) - supported by robust correlations and clustering patterns
- **Medium**: Risk-tone correlation with commitments (H1) - statistically significant but weak effect size suggests multiple drivers
- **Medium**: Size/emissions correlation with disclosure maturity (H4/H5) - patterns hold but reverse causality possible
- **Low**: Net-zero targets not linked to risk tone (H3) - sample limited to 69 firms, making conclusions tentative

## Next Checks
1. Test classifier robustness by varying aggregation thresholds (±5%) and re-running correlation analysis
2. Train a predictive model using narrative features to forecast emissions - low predictive power would confirm current findings
3. Quantify intra-sector narrative similarity using pairwise distance metrics to measure mimicry strength beyond cluster patterns