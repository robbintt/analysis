---
ver: rpa2
title: 'Making Dialogue Grounding Data Rich: A Three-Tier Data Synthesis Framework
  for Generalized Referring Expression Comprehension'
arxiv_id: '2512.02791'
source_url: https://arxiv.org/abs/2512.02791
tags:
- data
- dialogue
- referring
- expression
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of data scarcity in Dialogue-Based
  Generalized Referring Expression Comprehension (GREC), where models must ground
  expressions and unlimited targets in complex visual scenes while resolving coreference
  across long dialogues. The high cost of dialogue annotation limits the availability
  of in-domain training data, hindering model performance under distribution shift
  between training and evaluation domains.
---

# Making Dialogue Grounding Data Rich: A Three-Tier Data Synthesis Framework for Generalized Referring Expression Comprehension

## Quick Facts
- arXiv ID: 2512.02791
- Source URL: https://arxiv.org/abs/2512.02791
- Reference count: 0
- The paper achieves a 20% increase in precision over baseline methods for Dialogue-Based Generalized Referring Expression Comprehension using synthetic data synthesis.

## Executive Summary
This paper addresses the data scarcity problem in Dialogue-Based Generalized Referring Expression Comprehension (GREC), where models must ground expressions and unlimited targets in complex visual scenes while resolving coreference across long dialogues. The high cost of dialogue annotation limits in-domain training data, hindering model performance under distribution shift between training and evaluation domains. To address this, the authors propose a three-tier data synthesis framework: (1) template-based short expression generation, (2) AI-generated compositional expressions using GPT-4, and (3) full multi-turn dialogues with coreference chains synthesized using a fine-tuned Qwen2-VL model. This approach balances realism and controllability to produce scalable supervision for dialogue-conditioned grounding.

## Method Summary
The three-tier synthesis framework generates scalable supervision for dialogue-conditioned grounding by progressively increasing linguistic complexity while maintaining structural validity. Tier 1 uses template-based expressions with compositional attribute slots for unambiguous references. Tier 2 employs GPT-4 to generate compositional expressions under constrained grammars for linguistic diversity. Tier 3 utilizes a fine-tuned Qwen2-VL model (trained on VisPro corpus) to produce multi-turn dialogues with explicit coreference chains. The framework is evaluated on the Minecraft-based MDC-R benchmark, where fine-tuning on synthetic data yields substantial improvements over prior approaches, including better performance than training on out-of-domain data despite using far fewer samples.

## Key Results
- 20% increase in precision compared to baseline methods for Dialogue-Based GREC
- Fine-tuning on synthesized data outperforms training on out-of-domain data (e.g., gRefCOCO) despite using far fewer samples
- Template data (19k samples) achieves higher Mean F1 (42.8) than gRefCOCO (209k samples) at 19.1

## Why This Works (Mechanism)

### Mechanism 1: Tiered Complexity Ladder for Grounding
- **Claim:** Progressive data synthesis from controlled templates to free-form dialogue improves grounding by scaling supervision while maintaining structural validity.
- **Mechanism:** Three-tier synthesis creates a curriculum: (1) template-based expressions guarantee unambiguous references via compositional attribute slots; (2) GPT-4 generated expressions introduce linguistic diversity under constrained grammars; (3) fine-tuned Qwen2-VL produces multi-turn dialogues with explicit coreference chains. This balances controllability (lower tiers) with realism (higher tiers).
- **Core assumption:** Models can transfer grounding skills from simpler synthetic expressions to complex dialogue contexts.
- **Evidence anchors:**
  - [abstract] "three-tier data-synthesis method that balances realism and controllability"
  - [section 3] "these sources constitute a ladder of expressiveness—from controlled single-turn mentions to dialogue references"
  - [corpus] Limited direct evidence; neighbor papers focus on dialogue retrieval and planning, not grounding curricula.
- **Break condition:** If target domain requires reasoning patterns absent from all three tiers, the ladder will plateau before real-world performance.

### Mechanism 2: In-Domain Synthetic Supervision Beats Out-of-Domain Real Data
- **Claim:** Synthetic data matching target domain distribution outperforms larger quantities of mismatched real data.
- **Mechanism:** The Minecraft environment has consistent visual primitives (11×11 grid, 7 block colors, programmatically generated bounding boxes). Synthesized expressions reference these exact structures, reducing distribution shift. In contrast, gRefCOCO contains natural images with different spatial vocabularies and object categories.
- **Core assumption:** Domain-specific visual and linguistic patterns matter more for grounding than raw data quantity.
- **Evidence anchors:**
  - [section 4.4] "fine-tuning on the synthesized data gives superior results to training on out-of-domain data (e.g., gRefCOCO), despite using far fewer samples"
  - [table 2] Template (19k) outperforms gRefCOCO (209k) on Mean F1: 42.8 vs. 19.1
  - [corpus] No direct corpus evidence on synthetic vs. real data tradeoffs for grounding.
- **Break condition:** If target domain has uncontrollable visual variation (natural scenes, unbounded objects), template-based synthesis becomes infeasible.

### Mechanism 3: Fine-Tuned Dialogue Generator for Coreference Consistency
- **Claim:** Off-the-shelf LLMs exhibit limited coreference tracking; fine-tuning on visual coreference corpora enables coherent multi-turn dialogue synthesis.
- **Mechanism:** Qwen2-VL is fine-tuned with LoRA adapters on VisPro (visual pronoun coreference corpus) to learn mapping from (image, bounding box, expression) → coreference-consistent dialogue. The adapter learns Δθ = AB where A ∈ R^(d×r), B ∈ R^(r×d), enabling dialogue generation that maintains reference chains across turns.
- **Core assumption:** Coreference patterns learned from external corpora transfer to the target Minecraft domain.
- **Evidence anchors:**
  - [section 3.2] "recent work indicates that off-the-shelf LLMs exhibit limited coreference tracking. We therefore fine-tune a Qwen2-VL on external coreference-aware dialogue corpora"
  - [section 4.4] AI-Dialogue (1k) achieves higher Mean F1 (24.8) than Template (1k) at 18.6
  - [corpus] Neighbor papers on dialogue systems do not address coreference-grounded synthesis.
- **Break condition:** If coreference resolution requires domain-specific world knowledge not captured in training corpus, generated dialogues will have inconsistent reference chains.

## Foundational Learning

- **Concept: Referring Expression Comprehension (REC) vs. Generalized REC (GREC)**
  - Why needed here: GREC allows zero or multiple targets per expression, unlike standard REC which assumes exactly one. The paper's evaluation uses F1 and Precision@(F1=1, IoU≥0.5), which account for variable target counts.
  - Quick check question: Given "pick up those three boxes" in a scene with four boxes, what should a GREC model output?

- **Concept: Coreference Resolution in Dialogue**
  - Why needed here: The model must resolve pronouns and definite descriptions across dialogue turns (e.g., "it" referring to "the red block" from turn 2). The paper finds models struggle with full dialogue context vs. mention-only.
  - Quick check question: In a 5-turn dialogue where turn 3 mentions "the blue one" and turn 5 says "move it left," what must the model track?

- **Concept: Distribution Shift in Vision-Language Tasks**
  - Why needed here: The core problem is mismatch between training (gRefCOCO natural images) and evaluation (Minecraft structured scenes). Synthetic data bridges this by matching target domain statistics.
  - Quick check question: Why might a model trained on COCO images fail to ground "the second green block from the top" in a grid environment?

## Architecture Onboarding

- **Component map:**
Scene Simulator -> Bounding Box Extraction -> ID Recovery (render-and-compare)
        ↓
Tier 1: Template Engine -> Short expressions with slot filling
Tier 2: GPT-4 + Constraints -> Compositional expressions with JSON parsing
Tier 3: Fine-tuned Qwen2-VL -> Multi-turn dialogues with coreference chains
        ↓
Data Integration -> Training samples (dialogue, image, bounding boxes)
        ↓
Qwen2-VL-7B or MDETR-Longformer -> Fine-tuning with LoRA
        ↓
MDC-R Benchmark Evaluation -> F1, Precision@(F1=1, IoU≥0.5)

- **Critical path:** Scene simulation -> Bounding box + ID extraction -> Expression synthesis at appropriate tier -> Model fine-tuning -> Evaluation. The ID recovery step (render-and-compare MAE) is essential for aligning synthesized expressions with ground truth.

- **Design tradeoffs:**
  - Template data: High controllability, large scale (19k), but limited linguistic diversity -> highest F1 in isolation
  - AI-Short: More natural language, but requires GPT-4 API costs and JSON validation
  - AI-Dialogue: Most realistic, but combining with Template data causes distribution mismatch (Table 3 shows performance drop)
  - Data quantity vs. quality: 19k Template > 1k Template by 24+ F1 points

- **Failure signatures:**
  - Full dialogue context underperforms mention-only: indicates coreference resolution failure (model cannot reliably resolve antecedents)
  - Template + AI-Dialogue combination degrades performance: distributional mismatch between short-expression format and dialogue text
  - ICL (In-Context Learning) collapses to near-zero (0.5 F1): suggests task requires fine-tuning, not prompting alone

- **First 3 experiments:**
  1. **Ablate by tier:** Train separate models on Template-only (19k), AI-Short-only (1k), AI-Dialogue-only (1k) to isolate each tier's contribution. Expected: Template highest F1, AI-Dialogue highest linguistic realism.
  2. **Scale Template data:** Train with 1k, 5k, 10k, 19k Template samples to establish scaling curve. Critical for deciding annotation budget allocation.
  3. **Probe coreference resolution:** Compare Full Dialogue vs. Mention Only settings on AI-Dialogue model. If gap persists, coreference fine-tuning needs additional data or architectural changes (e.g., explicit coreference modeling module).

## Open Questions the Paper Calls Out
- Can distribution-aware training methods effectively mitigate the biases that arise when combining heterogeneous REC and GREC synthetic data sources?
- Why does the Mention-only setting consistently outperform Full Dialogue context across all model configurations, and how can dialogue context be leveraged more effectively for grounding?
- Does the three-tier synthesis framework transfer effectively to real-world visual grounding domains beyond the controlled Minecraft environment?

## Limitations
- The effectiveness assumes grounding skills transfer from simpler expressions to complex dialogue contexts, but may not generalize to domains requiring reasoning patterns absent from all tiers.
- Evaluation is limited to a single domain (Minecraft) with structured scenes, constraining generalization claims to other visual environments.
- Coreference resolution remains problematic - Full Dialogue context underperforms Mention Only despite fine-tuning, but the paper does not investigate why this gap persists.

## Confidence
- **High confidence** in the data synthesis methodology - The three-tier approach is well-specified with clear implementation details for each tier, and the systematic evaluation across different data combinations provides strong empirical support.
- **Medium confidence** in domain transfer claims - While results show synthetic data outperforms out-of-domain real data, this conclusion is based on a single target domain with highly controlled visual properties, limiting broader applicability.
- **Low confidence** in coreference resolution improvements - The evaluation shows Full Dialogue context underperforms Mention Only, suggesting coreference tracking remains problematic despite fine-tuning, but the paper does not investigate why this gap persists.

## Next Checks
1. **Cross-domain generalization test**: Evaluate the synthetic-data fine-tuned model on a natural image dataset (e.g., gRefCOCO test split) to assess whether the grounding skills transfer beyond the structured Minecraft environment. This would validate whether the curriculum approach generalizes to less controlled visual domains.

2. **Coreference resolution ablation**: Implement an explicit coreference resolution module (separate from the vision-language model) and compare its performance against the baseline's implicit coreference handling. This would isolate whether the coreference gap stems from model architecture or data quality.

3. **Template data scaling study**: Systematically vary Template data quantity (1k, 5k, 10k, 19k) while keeping AI-generated data constant to establish precise scaling curves. This would determine the optimal data mixture ratio and whether additional Template data continues providing returns beyond 19k samples.