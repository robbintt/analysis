---
ver: rpa2
title: 'CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood
  Defect Detection'
arxiv_id: '2504.11305'
source_url: https://arxiv.org/abs/2504.11305
tags:
- detection
- wood
- feature
- defect
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents CFIS-YOLO, a lightweight multi-scale fusion
  network for edge-deployable wood defect detection. The method introduces three key
  innovations: a lightweight Content-Aware ReAssembly of Features (CARAFE) operator
  for dynamic feature recombination, a FasterBlock module integrated into the C2f
  structure using partial convolutions for reduced computational redundancy, and a
  novel Inner-SIoU loss function combining internal intersection-over-union with angular
  constraints for improved small object localization.'
---

# CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection

## Quick Facts
- **arXiv ID:** 2504.11305
- **Source URL:** https://arxiv.org/abs/2504.11305
- **Reference count:** 8
- **Primary result:** 77.5% mAP@0.5 on wood defect dataset, 135 FPS at 17.3% power on edge device

## Executive Summary
This paper introduces CFIS-YOLO, a lightweight object detection architecture optimized for edge deployment in wood defect detection applications. The authors propose three key innovations: a Content-Aware ReAssembly of Features (CARAFE) operator for dynamic feature upsampling, a FasterBlock module using partial convolutions to reduce computational redundancy, and an Inner-SIoU loss function that combines internal IoU with angular constraints. When evaluated on a public wood defect dataset, CFIS-YOLO achieves 77.5% mean Average Precision, outperforming the baseline YOLOv10s by 4 percentage points. The model demonstrates practical edge deployment capability, achieving 135 FPS on SOPHON BM1684X devices while reducing power consumption to 17.3% of the original implementation, with only a 0.5 percentage point drop in mAP due to quantization.

## Method Summary
CFIS-YOLO builds upon the YOLOv10 architecture with targeted modifications to enhance both detection accuracy and computational efficiency. The model integrates three main innovations: CARAFE operator replaces standard upsampling in the neck for dynamic feature recombination based on local context; FasterBlock modules replace standard C2f modules in both backbone and neck, using partial convolutions (processing only 25% of channels) to significantly reduce FLOPs while preserving spatial information; and Inner-SIoU loss combines auxiliary bounding boxes with angular constraints to improve small object localization. The complete architecture achieves a balance between lightweight deployment requirements and high detection accuracy, specifically addressing the challenges of wood defect detection where objects vary in size and require precise localization.

## Key Results
- Achieves 77.5% mAP@0.5 on public wood defect dataset, a 4pp improvement over YOLOv10s baseline
- Reduces model parameters from 8.07M to 7.01M (1.06M reduction) while improving mAP from 73.5% to 75.6%
- Deploys on SOPHON BM1684X edge devices at 135 FPS with only 0.5pp mAP degradation from quantization

## Why This Works (Mechanism)

### Mechanism 1: CARAFE Dynamic Upsampling
Content-aware feature reassembly improves multi-scale defect detection by reducing semantic information loss during upsampling compared to fixed-kernel interpolation methods. The two-stage process first predicts adaptive kernels based on local feature content, then applies these kernels to weight pixel contributions by semantic relevance rather than spatial distance alone. This is particularly effective for wood defects where edge boundaries (knots, cracks) require adaptive kernel weighting due to variability in wood texture patterns and defect morphologies.

### Mechanism 2: FasterBlock with Partial Convolution
Reducing convolution to a subset of channels (PConv) maintains spatial feature extraction while cutting FLOPs by approximately 16×, enabling edge deployment without accuracy collapse. The approach splits input tensors, processes through FasterBlocks with PConv (processing only first/last 25% of channels), and concatenates outputs—preserving feature diversity while eliminating redundant computation across similar feature channels. This assumes feature maps contain significant redundancy across channels, with spatial information sufficiently captured by partial channel processing.

### Mechanism 3: Inner-SIoU Loss with Angular Constraints
Combining auxiliary bounding boxes with angular alignment accelerates convergence and improves small-object localization by explicitly penalizing directional misalignment. The loss computes IoU over scaled auxiliary boxes (γ ∈ [0.5, 1.5]) to capture internal overlap, then adds SIoU's distance and shape losses. Angular alignment prioritizes directional correction before positional optimization—when angular deviation is large, distance penalty weight decreases. This addresses small defects' sensitivity to minor bounding box offsets and guides faster axis alignment.

## Foundational Learning

- **Concept: Feature Pyramid Networks (FPN) and multi-scale fusion**
  - Why needed here: CFIS-YOLO builds on YOLOv10's neck architecture; understanding how features propagate across scales (P3, P4, P5) is prerequisite to grasping why CARAFE replaces upsampling
  - Quick check question: Can you explain why small defects benefit from higher-resolution feature maps, and how standard upsampling (bilinear/nearest) might lose edge information?

- **Concept: IoU variants and bounding box regression**
  - Why needed here: The paper assumes CIoU limitations (missing angular difference) motivate Inner-SIoU; understanding GIoU→DIoU→CIoU evolution clarifies what each term captures
  - Quick check question: What does CIoU add over DIoU, and why might angular difference still be missing?

- **Concept: Model quantization for edge deployment**
  - Why needed here: Edge deployment converts FP32→FP16/INT8; the 0.5pp mAP drop on BM1684X results from quantization, not architecture
  - Quick check question: Why does FP16 quantization typically cause minor accuracy degradation, and when would INT8 be preferred despite higher risk?

## Architecture Onboarding

- **Component map:** Input (640×640) -> Backbone (C2f_FNB + SCDown) -> multi-scale features -> Neck: CARAFE upsampling + Concat fusion with skip connections -> C2f_FNB refinement -> Detection heads -> bbox + class predictions -> Inner-SIoU loss computation

- **Critical path:** Input passes through backbone with C2f_FNB modules replacing standard C2f (using FasterBlock with PConv), generating multi-scale features. Bottom-up features are upsampled via CARAFE (kernel prediction → content reassembly), then concatenated with skip connections and refined through C2f_FNB. Detection heads produce bbox and class predictions using the Inner-SIoU loss function.

- **Design tradeoffs:**
  - CARAFE kernel size (k_up): Larger kernels expand receptive field but increase compute quadratically. Paper uses default values; tuning needed for new domains
  - PConv channel ratio (r=1/4): Aggressive reduction may underfit complex textures; r=1/3 or 1/2 may be safer for diverse defect types
  - Inner-SIoU scaling factor (γ): Controls auxiliary box size; γ<1 tightens focus on small objects but may miss context

- **Failure signatures:**
  - CARAFE overfitting: Validation mAP diverges from training; heatmaps show excessive focus on texture noise rather than defect boundaries
  - PConv information loss: Recall drops significantly (false negatives increase) while precision stays stable
  - Inner-SIoU instability: Training loss oscillates without convergence; check γ and λ_1, λ_2 hyperparameters

- **First 3 experiments:**
  1. Baseline ablation: Run YOLOv10s on target dataset to establish mAP/FPS baseline; compare to paper's 73.5% mAP
  2. Single-module integration: Add C2f_FNB first (largest param reduction, +2.1pp mAP gain per paper); verify parameter count drops ~1M and FPS improves
  3. Edge deployment dry-run: Convert trained model to ONNX, then to target edge format (e.g., TFLite/TensorRT); measure quantization impact on mAP before full integration

## Open Questions the Paper Calls Out

### Open Question 1
How does CFIS-YOLO maintain detection accuracy under variable industrial environmental conditions, such as low lighting, dust, or motion blur? The authors explicitly state in the Conclusion that "the model's robustness under extreme conditions such as poor lighting or low image quality remains unverified." The experiments were conducted on the VŠB-TUO dataset, which likely contains high-quality, controlled imagery, leaving the model's performance in non-ideal "wild" industrial settings unknown.

### Open Question 2
Does the efficiency of CFIS-YOLO transfer to other edge computing platforms with different architectures, such as GPU-based edge devices or low-power microcontrollers? The Conclusion lists "testing deployment on more edge devices" as a future research direction. The deployment tests were restricted to a single hardware platform (SOPHON BM1684X with a TPU architecture); the performance on other common edge AI accelerators (e.g., NVIDIA Jetson, Raspberry Pi) remains unconfirmed.

### Open Question 3
Can the model maintain high mAP when trained on the full wood defect spectrum, including the rare classes (Quartzity, Blue stain, Overgrown) that were excluded from this study? Section 3.1.2 states that the authors "Excluding three rarely occurring defects... used 3,465 images," implying the reported 77.5% mAP reflects a simplified 7-class problem rather than the full industrial requirement. Rare classes often suffer from sample imbalance; excluding them avoids the challenge of few-shot detection, making it unclear if the model is viable for comprehensive quality control.

### Open Question 4
Why does the combination of the CARAFE and C2f_FNB modules result in a lower mAP (75.1%) than using the C2f_FNB module alone (75.6%)? Table 1 shows a performance dip in Experiment 5 compared to Experiment 3, which the paper attributes to "partial functional overlap" without providing a definitive mechanism for this negative interaction. The paper demonstrates that the full three-module integration works, but fails to explain the specific feature conflicts or gradient issues that cause the two-module intermediate state to fail.

## Limitations
- The study lacks ablation studies isolating each component's contribution from the YOLOv10 baseline
- CARAFE operator's effectiveness for wood defect detection lacks direct corpus validation, relying on general computer vision literature
- Inner-SIoU loss function shows improvement but has no direct corpus validation for defect detection tasks
- Limited to a single wood defect dataset without cross-domain generalization testing

## Confidence
- **High Confidence:** The computational efficiency claims (135 FPS, 17.3% power reduction) are well-supported by direct measurements on specified hardware
- **Medium Confidence:** The architectural innovations (CARAFE, FasterBlock, Inner-SIoU) are theoretically sound but lack direct corpus validation for defect detection
- **Low Confidence:** The claim that Inner-SIoU specifically improves "small object localization" for wood defects is supported by results but not rigorously isolated from other architectural changes

## Next Checks
1. Run ablation study isolation experiments with only C2f_FNB, only CARAFE, and only Inner-SIoU to quantify individual contributions to the 4pp mAP improvement
2. Test CFIS-YOLO on publicly available wood defect datasets (e.g., SWD, LWD) to verify consistent performance across different defect types and imaging conditions
3. Measure mAP at different quantization levels (FP32→FP16→INT8) on BM1684X to characterize the tradeoff curve and identify optimal deployment precision