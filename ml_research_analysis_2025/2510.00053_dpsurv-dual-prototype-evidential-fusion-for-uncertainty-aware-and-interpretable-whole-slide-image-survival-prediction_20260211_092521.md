---
ver: rpa2
title: 'DPsurv: Dual-Prototype Evidential Fusion for Uncertainty-Aware and Interpretable
  Whole-Slide Image Survival Prediction'
arxiv_id: '2510.00053'
source_url: https://arxiv.org/abs/2510.00053
tags:
- survival
- component
- learning
- evidence
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DPsurv, a dual-prototype evidential fusion
  network for interpretable whole-slide image (WSI) survival prediction. It addresses
  the challenges of limited interpretability and predictive uncertainty in existing
  WSI survival analysis methods by combining patch prototype-guided Gaussian mixture
  models with component prototype-based evidential modeling.
---

# DPsurv: Dual-Prototype Evidential Fusion for Uncertainty-Aware and Interpretable Whole-Slide Image Survival Prediction

## Quick Facts
- arXiv ID: 2510.00053
- Source URL: https://arxiv.org/abs/2510.00053
- Reference count: 40
- Primary result: Dual-prototype evidential fusion network achieves C-index of 0.685 and integrated Brier score of 0.288 on TCGA cancer datasets

## Executive Summary
DPsurv introduces a novel dual-prototype evidential fusion framework for interpretable whole-slide image survival prediction. The method addresses critical limitations in existing WSI survival analysis approaches by providing uncertainty quantification and interpretable risk factor identification. By combining patch prototype-guided Gaussian mixture models with component prototype-based evidential modeling, DPsurv generates survival intervals with calibrated uncertainty while maintaining high discriminative performance. The framework's interpretability features include patch prototype assignment maps and component-wise relative risk aggregation, enabling transparent insights into decision-making pathways for clinical applications.

## Method Summary
DPsurv employs a dual-prototype architecture that processes whole-slide images through two complementary prototype systems. The first component uses patch-level prototypes to guide a Gaussian mixture model that captures local tissue patterns and their relationships to survival outcomes. The second component implements component prototype-based evidential modeling that aggregates patch-level information into clinically meaningful tissue components while quantifying predictive uncertainty. These two prototype streams are fused through an evidential framework that produces uncertainty-aware survival intervals rather than point estimates. The entire system is trained end-to-end, with interpretability emerging naturally from the prototype assignment process and component aggregation, providing clinicians with transparent views into both the features driving predictions and the confidence levels associated with each prediction.

## Key Results
- Achieved highest mean concordance index (0.685) among state-of-the-art methods across five TCGA cancer types
- Lowest mean integrated Brier score (0.288) demonstrating superior calibration and uncertainty quantification
- Generated interpretable outputs including patch prototype assignment maps and component prototypes that provide clinical insights

## Why This Works (Mechanism)
The dual-prototype architecture works by capturing both fine-grained patch-level patterns and higher-level tissue component relationships. Patch prototypes identify local morphological features associated with survival outcomes, while component prototypes aggregate these into clinically meaningful tissue types. The evidential fusion framework naturally quantifies uncertainty by modeling both aleatoric uncertainty (inherent randomness in survival times) and epistemic uncertainty (model uncertainty). This dual approach enables the network to make confident predictions when evidence is strong while providing appropriately wide intervals when uncertainty is high. The interpretability emerges from the prototype assignment process, where each patch is assigned to specific prototypes and components, creating a transparent mapping between input features and predictions.

## Foundational Learning
- **Gaussian Mixture Models**: Used to capture local tissue patterns at patch level; needed for probabilistic modeling of morphological features; quick check: verify cluster assignments align with known tissue types
- **Evidential Deep Learning**: Framework for uncertainty quantification through Dempster-Shafer theory; needed to produce calibrated survival intervals; quick check: test uncertainty estimates on out-of-distribution samples
- **Whole-Slide Image Processing**: Pyramidal image structure and patch extraction strategies; needed to handle gigapixel pathology images; quick check: validate patch sampling covers all tissue regions
- **Survival Analysis Metrics**: C-index for discrimination and integrated Brier score for calibration; needed for proper evaluation of survival predictions; quick check: compare against random survival forest baselines
- **Prototype Learning**: Learnable cluster centers for interpretable feature representation; needed to create human-understandable risk factors; quick check: visualize prototype assignment maps for clinical validation
- **Component Aggregation**: Hierarchical combination of patch-level features into tissue components; needed for clinically meaningful risk assessment; quick check: verify component prototypes match pathological expertise

## Architecture Onboarding

Component Map: Input WSI -> Patch Extraction -> Patch Prototype Assignment -> Component Prototype Aggregation -> Evidential Fusion -> Survival Interval Output

Critical Path: The evidential fusion module serves as the critical component, combining patch prototype evidence with component prototype evidence to produce final survival predictions with uncertainty quantification.

Design Tradeoffs: The dual-prototype approach balances interpretability against model complexity, requiring careful regularization to prevent overfitting on limited WSI data. The choice between patch-level and component-level prototypes involves tradeoffs between granularity and clinical interpretability.

Failure Signatures: Poor performance typically manifests as overconfident predictions on uncertain cases or failure to capture rare but clinically important tissue patterns. The evidential framework should naturally detect these failures through high uncertainty estimates.

First Experiments: (1) Baseline comparison using only patch prototypes without evidential fusion; (2) Ablation study removing component prototypes to quantify their contribution; (3) Uncertainty calibration test on held-out TCGA samples to verify interval coverage

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability limited by reliance on TCGA data, which may not represent real-world clinical populations or institutional variations
- Interpretability mechanisms require clinical validation to confirm alignment with pathological expertise rather than training artifacts
- Performance on rare cancer subtypes and underrepresented patient populations remains untested

## Confidence
- Discriminative performance (C-index): High
- Calibration metrics (integrated Brier score): Medium
- Clinical utility of uncertainty estimates: Medium
- Interpretability feature reliability: Medium

## Next Checks
- External validation on multi-institutional datasets with different scanning protocols and staining procedures
- Clinician evaluation studies to determine alignment between interpretable outputs and pathological expertise
- Ablation studies isolating individual contributions of patch prototype and component prototype components to performance and interpretability