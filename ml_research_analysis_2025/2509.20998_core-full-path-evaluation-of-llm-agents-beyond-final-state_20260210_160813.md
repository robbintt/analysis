---
ver: rpa2
title: 'CORE: Full-Path Evaluation of LLM Agents Beyond Final State'
arxiv_id: '2509.20998'
source_url: https://arxiv.org/abs/2509.20998
tags:
- state
- agent
- path
- harmful
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CORE, a framework for evaluating LLM agents
  beyond final outcomes by analyzing their full execution paths. The key contribution
  is modeling tasks as deterministic finite automata (DFAs) over tool-use sequences,
  enabling principled assessment of intermediate behaviors like safety and efficiency.
---

# CORE: Full-Path Evaluation of LLM Agents Beyond Final State

## Quick Facts
- **arXiv ID:** 2509.20998
- **Source URL:** https://arxiv.org/abs/2509.20998
- **Reference count:** 40
- **Primary result:** CORE framework evaluates LLM agents on full execution paths using deterministic finite automata, revealing performance differences missed by final-state benchmarks.

## Executive Summary
This paper introduces CORE, a framework for evaluating LLM agents beyond final outcomes by analyzing their full execution paths. The key contribution is modeling tasks as deterministic finite automata (DFAs) over tool-use sequences, enabling principled assessment of intermediate behaviors like safety and efficiency. Five metrics are introduced: Path Correctness, Path Correctness-Kendall's tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency. Experiments across 14 simulated worlds show that CORE reveals performance differences between agents that final-state evaluation misses, with GPT-o4-mini achieving highest scores (PC=0.812, Eff=0.748) while smaller models show lower path correctness and higher harmful calls.

## Method Summary
CORE represents tasks as deterministic finite automata where valid tool-use sequences form accepted paths. The framework evaluates agent execution traces by comparing them to manually verified golden paths using normalized Levenshtein distance (Path Correctity), augmented with Kendall's tau for ordering (PC-KTC). Prefix Criticality weights early harmful calls more heavily using geometric decay. Harmful-Call Rate measures fraction of invalid actions, while Efficiency captures optimal path adherence. The method requires constructing DFA specifications for each task, enumerating golden paths, and running agents to collect action sequences for metric computation.

## Key Results
- GPT-o4-mini achieved highest scores: PC=0.812, Efficiency=0.748 across 14 simulated worlds
- Smaller models showed lower path correctness and higher harmful calls (Qwen2.5-0.5B: PC=0.508)
- CORE detected skipped preconditions and compensating actions that BFCL state-check missed (Legal Compliance: 100% BFCL vs 0.408 PC)
- High BFCL but low CORE scores indicate agents reach correct final state via invalid paths
- Low Efficiency with high PC indicates redundant reads/exploration in otherwise correct agents

## Why This Works (Mechanism)

### Mechanism 1: DFA-Based State-Space Encodes Valid Action Sequences
- **Claim:** Modeling tasks as deterministic finite automata (DFAs) over tool invocations enables detection of intermediate errors that final-state evaluation misses.
- **Mechanism:** Each task θ = (p, q₀, A) induces a DFA = (Q, A, α, q₀, F) where undefined transitions are marked as harmful. As the agent executes actions, the DFA tracks control state transitions, logging harmful calls without blocking subsequent valid progress. This produces a labeled execution trace that distinguishes progress steps, self-loops (reads), and harmful attempts.
- **Core assumption:** Tasks can be decomposed into discrete action alphabets with identifiable preconditions and state-dependent validity constraints.
- **Evidence anchors:**
  - [abstract] "We propose a framework based on deterministic finite automata (DFAs) that encodes tasks as sets of valid tool-use paths, enabling principled assessment of agent behavior."
  - [section 2.2] Equations (1)-(2) formalize action space and DFA structure; harmful transitions leave state unchanged but are recorded.
  - [corpus] Related work "TRAJECT-Bench" similarly advocates trajectory-aware evaluation, suggesting convergent validation of the approach.
- **Break condition:** Tasks with continuous control, fine-grained timing dependencies, or effects not expressible as symbolic state-action pairs fall outside DFA expressivity.

### Mechanism 2: Normalized Levenshtein Distance Captures Structured Deviations
- **Claim:** Edit-distance-based similarity (PC metric) provides graded alignment scores that meaningfully correspond to missing, redundant, or incorrect tool calls.
- **Mechanism:** After condensation removes state-preserving self-loops, the agent path ả is compared to golden paths using NLD(x,y) = 2·LD(x,y) / (|x|+|y|+LD). The max similarity PC(a) = max_{gold} (1 - NLD) yields scores in [0,1]. Insertions capture unnecessary calls, deletions capture skipped steps, substitutions capture parameter errors.
- **Core assumption:** Golden paths A_gold are correctly specified and non-empty; token-level matching appropriately penalizes parameter mismatches.
- **Evidence anchors:**
  - [section 3] "Edit operations in Levenshtein distance computation correspond to meaningful deviations in agent behavior."
  - [section C] Proves NLD is a metric with triangle inequality, establishing theoretical foundations.
  - [corpus] Weak direct corpus evidence for Levenshtein specifically; this is a methodological contribution.
- **Break condition:** If multiple valid paths exist with similar lengths but different semantics, max-over-references may select a non-canonical alignment.

### Mechanism 3: Geometric Weighting Captures Causal Criticality
- **Claim:** Position-weighted harm penalties (Prefix Criticality) reflect that early errors have higher causal impact than late errors.
- **Mechanism:** PrefixCrit_β(a) = 1 - c(β,N)·Σ(m_k·β^k) where m_k indicates harm at step k and β∈(0,1) controls decay. Smaller β emphasizes early mistakes. This captures that early harmful calls (e.g., opening wrong valve before watering) can invalidate entire subsequent trajectories.
- **Core assumption:** Causal impact of errors decays exponentially with sequence position; this reflects deployment realities in systems with irreversible state changes.
- **Evidence anchors:**
  - [section 3] "Early harmful calls might more severe since they can propagate errors and invalidate subsequent steps."
  - [section 4, example C] Demonstrates high prefix criticality (0.938) when necessary intermediate action is omitted early in robotic manipulation.
  - [corpus] No direct corpus validation of geometric weighting scheme.
- **Break condition:** Tasks where late errors are equally or more catastrophic (e.g., final authorization step in security-critical workflows) may be misweighted.

## Foundational Learning

- **Concept: Deterministic Finite Automata (DFA)**
  - Why needed here: CORE represents tasks as DFAs with states Q, action alphabet A, transition function α, and accepting states F. Understanding state transitions, partial transition functions, and accepting paths is essential for constructing task-specific DFAs.
  - Quick check question: Given a DFA with states {q0, q1, q2}, alphabet {A, B}, and transitions δ(q0,A)=q1, δ(q1,B)=q2, what happens on input sequence [A, A]?

- **Concept: Levenshtein/Edit Distance**
  - Why needed here: Path Correctness metric relies on normalized Levenshtein distance to quantify sequence alignment. Understanding insertion, deletion, and substitution operations and their costs is necessary for interpreting PC scores.
  - Quick check question: Compute Levenshtein distance between sequences [A, B, C] and [A, X, B, C]. What does each edit operation represent in agent evaluation context?

- **Concept: Kendall's Tau Rank Correlation**
  - Why needed here: PC-KTC metric augments token similarity with ordering agreement. Kendall's τ measures concordance/discordance in rank orderings of matched tokens between agent and reference paths.
  - Quick check question: If matched progress tokens appear at positions [1, 3, 5] in reference and [2, 4, 5] in agent path, are these orderings concordant or discordant?

## Architecture Onboarding

- **Component map:**
  1. World Specification Module: Defines (T, Q) — tool interfaces with signatures/documentation, and valid world states
  2. Task Encoder: For each prompt θ=(p, q₀, A), constructs DFA with partial transition function; enumerates golden paths A_gold
  3. Execution Tracer: Records raw agent action sequence a=(a₁,...,a_N), mapping function calls to action space A
  4. Path Condenser: C(a) removes self-loops while preserving progress and harmful steps
  5. DFA Simulator: Left-to-right pass labels transitions as progress/self-loop/harmful
  6. Metric Computer: Calculates PC, PC-KTC, PrefixCrit, HarmRate, Efficiency
  7. HLR Generator (optional): Produces harm-local refinement candidates for augmented PC+HLR scoring

- **Critical path:** Task DFA construction → Golden path enumeration → Agent execution → Condensation → DFA labeling → Metric computation

- **Design tradeoffs:**
  - **Alphabet granularity:** Finer-grained action distinctions (e.g., parameter-specific tokens) increase DFA size but capture more precise failures; coarser abstractions are more tractable but miss parameter errors
  - **Golden path set size:** Larger A_gold improves coverage of valid approaches but increases PC computation; paper uses loop-free harm-free paths which bounds search
  - **Prefix decay β:** Lower β (e.g., 0.25) heavily penalizes early errors; higher β distributes penalty more evenly. Default not specified; experiment with β∈{0.25, 0.5, 0.75}
  - **HLR vs. pure golden:** HLR reduces spurious penalties for localized mistakes but admits non-canonical references; paper recommends reporting both PC and PC+HLR

- **Failure signatures:**
  - High BFCL State % + low PC: Agent reaches correct final state but via invalid path (skipped preconditions, compensating pairs)
  - High PC + low PC-KTC: Correct operations in wrong order
  - High HarmRate + high PrefixCrit: Many harmful calls late in execution (less causally severe)
  - Low Efficiency + high PC: Agent succeeds but with redundant reads/exploration
  - Very short traces + low PC-KTC: Premature termination (common in smallest models like Qwen2.5-0.5B)

- **First 3 experiments:**
  1. **Baseline validation:** Implement DFA for a simple world (e.g., Farm Rover with 6 tools: unlock_safety, move, scan, open_valve, water, log). Generate golden path, execute known failure modes (skip unlock, wrong order, redundant scans), verify CORE metrics capture deviations while BFCL state-check passes.
  2. **Model stratification check:** Run 3+ LLM variants (large/small) on 5+ worlds, confirm CORE produces meaningful stratification (paper shows GPT-o4-mini PC=0.812 vs. Qwen2.5-0.5B PC=0.508). Check correlation between model size and Efficiency/HarmRate.
  3. **Discrepancy diagnosis:** Identify world-task pairs where BFCL-State ≥95% but PC <0.6 (e.g., Legal Compliance in paper: 100% BFCL, 0.408 PC). Manually inspect traces to confirm skipped preconditions or compensating actions.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the CORE framework be effectively scaled to multifaceted, real-world environments where factors like fine-grained timing and continuous control challenge the discrete DFA abstraction?
- **Basis in paper:** [explicit] The authors state that reliance on the DFA abstraction might be a bottleneck in complex environments and note they are "actively integrating our method in a real-world smart-farming installation."
- **Why unresolved:** The current experiments rely on simulated worlds with discrete state/action symbols, whereas physical deployments involve continuous variables and spatiotemporal complexity not easily expressed as simple automata.
- **What evidence would resolve it:** Successful application of CORE metrics in a physical robotics or IoT deployment, showing that the DFA can be extended to handle continuous state spaces without excessive manual engineering.

### Open Question 2
- **Question:** How should CORE metrics be statistically adapted to provide robust evaluation in stochastic environments where agent behavior varies across multiple rollouts?
- **Basis in paper:** [explicit] The limitations section notes that "stochastic environments may also warrant distributional versions of the scores (means/quantiles over rollouts)."
- **Why unresolved:** The current framework evaluates single execution paths against a deterministic automaton, but stochastic worlds introduce variance that single-path metrics cannot capture.
- **What evidence would resolve it:** A formulation of CORE metrics that incorporates variance (e.g., confidence intervals over Harmful-Call Rate) and demonstrates stability across repeated trials in a non-deterministic simulation.

### Open Question 3
- **Question:** Do state-of-the-art large language models (>>10B parameters) exhibit different failure modes, such as reduced harmful-call rates or improved efficiency, when evaluated under the CORE framework?
- **Basis in paper:** [explicit] The authors limit their evaluation to smaller models (≤10B) "leaving larger models to future work," specifically focusing on deployment-aware scenarios.
- **Why unresolved:** It is unknown if the specific failure modes detected in smaller models (e.g., skipped preconditions, redundancy) persist or amplify in models with greater reasoning capabilities.
- **What evidence would resolve it:** Benchmarking frontier models (e.g., GPT-4 class) on the CORE simulated worlds to compare their Path Correctness and Efficiency scores against the reported smaller model baselines.

### Open Question 4
- **Question:** Can the construction of task-specific DFAs be automated to remove the manual bottleneck currently required for defining valid paths and state transitions?
- **Basis in paper:** [inferred] The experimental setup relies on "manually verified, prompt-specific DFA[s]," and the limitations section highlights that scaling to multifaceted environments is currently a bottleneck.
- **Why unresolved:** Manual DFA construction limits the scalability of the framework to new tasks and domains, suggesting a need for algorithmic generation of these automata from natural language or environment specifications.
- **What evidence would resolve it:** An automated pipeline that translates task descriptions into DFAs that yield CORE metric scores statistically indistinguishable from those derived from human-verified automata.

## Limitations
- **DFA expressivity limits:** Symbolic state-action representation may not capture continuous control, timing dependencies, or fine-grained effects
- **Manual DFA construction:** Golden path enumeration and DFA specification require manual verification without standardized procedures
- **β parameter uncertainty:** Geometric decay assumption in Prefix Criticality lacks empirical justification across task types

## Confidence
- **High confidence:** DFA encoding of valid tool-use paths and the mechanism for detecting skipped preconditions
- **Medium confidence:** Path Correctness metric validity (Levenshtein distance is well-established, but normalization and max-over-golden alignment need more validation)
- **Medium confidence:** Prefix Criticality weighting scheme (geometric decay is intuitive but task-dependent; no ablation on β values provided)
- **Low confidence:** Efficiency metric interpretation (ℓ*/n ratio assumes golden paths represent optimal behavior, but no analysis of optimality gaps)

## Next Checks
1. **DFA expressivity boundary test:** Implement tasks requiring fine-grained timing or continuous parameters (e.g., robotic arm with velocity control) to identify where symbolic DFA representation breaks down
2. **Golden path generation protocol:** Develop and apply systematic procedure for enumerating all valid harm-free paths per task, then measure how PC varies with A_gold size/completeness
3. **β parameter sensitivity analysis:** Run experiments across β ∈ {0.25, 0.5, 0.75} on tasks with known early vs. late error criticality to identify optimal weighting for different domain types