---
ver: rpa2
title: Automated Hierarchical Graph Construction for Multi-source Electronic Health
  Records
arxiv_id: '2509.06576'
source_url: https://arxiv.org/abs/2509.06576
tags:
- codes
- embeddings
- data
- mash
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MASH (Multi-source Automated Structured Hierarchy) is a fully automated
  framework that harmonizes heterogeneous Electronic Health Record (EHR) data across
  institutions and constructs clinically meaningful hierarchies. It addresses the
  dual challenges of code harmonization and hierarchy construction in multi-institutional
  EHR systems.
---

# Automated Hierarchical Graph Construction for Multi-source Electronic Health Records

## Quick Facts
- arXiv ID: 2509.06576
- Source URL: https://arxiv.org/abs/2509.06576
- Reference count: 40
- Key outcome: MASH framework harmonizes heterogeneous EHR codes across institutions and constructs clinically meaningful hierarchies using neural optimal transport, hyperbolic embeddings, and recursive grouping.

## Executive Summary
MASH (Multi-source Automated Structured Hierarchy) addresses the dual challenges of code harmonization and hierarchy construction in multi-institutional EHR systems. The framework integrates co-occurrence statistics, semantic information from biomedical language models, and existing hierarchies to produce interpretable hierarchical graphs for diagnoses, medications, and laboratory tests. Applied to real-world EHR data from VA and MGB, MASH successfully harmonizes institution-specific codes and produces the first automated hierarchies for VA's extensive set of local laboratory codes.

## Method Summary
MASH operates in three stages: First, neural optimal transport aligns institution-specific embeddings into a shared representation using a three-layer MLP. Second, the aligned embeddings are projected into hyperbolic space and optimized using combined additivity, contrastive, and information-preserving losses. Third, recursive k-means clustering on a distance criterion matrix recovers the latent tree structure. The method leverages SPPMI matrices from co-occurrence statistics, CODER semantic embeddings, and existing ontologies (PheCode, RxNorm, LOINC) for supervision.

## Key Results
- MASH achieves AUC of 0.982 for similarity detection in embedding quality evaluation
- Hierarchy alignment shows NMI up to 0.947 and ARI up to 0.719 against reference ontologies
- Near-perfect GPT-4o hierarchy (0.977) and divergence (0.980) scores demonstrate semantic coherence

## Why This Works (Mechanism)

### Mechanism 1: Neural Optimal Transport Alignment
- **Claim:** Neural OT aligns institution-specific embeddings better than linear methods
- **Mechanism:** Block coordinate descent alternates between updating neural mapping T via SGD and coupling matrix π via linear programming
- **Core assumption:** Overlapping codes provide sufficient supervision for alignment
- **Evidence anchors:** Abstract mentions "neural optimal transport"; Algorithm 1 details BCD optimization
- **Break condition:** Non-convex optimization may converge to local minima; minimal code overlap degrades quality

### Mechanism 2: Hyperbolic Embeddings for Hierarchies
- **Claim:** Hyperbolic embeddings capture hierarchical relationships more efficiently than Euclidean space
- **Mechanism:** Exponential volume growth in hyperbolic space allows compact representation of deep hierarchies
- **Core assumption:** Medical code hierarchies are approximately tree-structured
- **Evidence anchors:** Abstract mentions "learned hyperbolic embeddings"; additivity and contrastive losses refined with InfoNCE
- **Break condition:** Non-tree-like relationships violate additivity assumption

### Mechanism 3: Recursive Grouping with k-means
- **Claim:** Recursive grouping recovers latent tree structure from hyperbolic embeddings
- **Mechanism:** D_ij criterion measures sibling/parent-child relationships by testing distance differences to all other nodes
- **Core assumption:** Hyperbolic distances approximately satisfy additivity property
- **Evidence anchors:** Definition 1 defines bottom sets; NMI up to 0.947 and ARI up to 0.719 for hierarchy alignment
- **Break condition:** Poor OT alignment or hyperbolic learning causes noisy D_ij values

## Foundational Learning

- **Concept: Optimal Transport (OT)**
  - Why needed here: Core alignment mechanism between VA and MGB embedding spaces
  - Quick check question: Can you explain why a doubly stochastic coupling matrix π ensures mass conservation in the transport plan?

- **Concept: Hyperbolic Geometry (Lorentz Model)**
  - Why needed here: Stage II projects embeddings into hyperbolic space
  - Quick check question: Why does volume grow exponentially with radius in hyperbolic space, making it suitable for tree-like structures?

- **Concept: SPPMI (Shifted Positive Pointwise Mutual Information)**
  - Why needed here: Input representation derived from co-occurrence statistics
  - Quick check question: Given co-occurrence matrix C, how would you compute the SPPMI matrix, and what does SVD decomposition yield?

## Architecture Onboarding

- **Component map:** Data preprocessing (SPPM) -> Stage I (Neural OT alignment) -> Stage II (Hyperbolic projection) -> Stage III (Recursive grouping)
- **Critical path:** Stage I alignment quality → Stage II hyperbolic embedding fidelity → Stage III hierarchy recovery
- **Design tradeoffs:** d=300 embedding dimension balances expressiveness vs. computational cost; 30-day co-occurrence window captures clinical episodes; rare code thresholds remove noise but may exclude rare diseases
- **Failure signatures:** Low NMI/ARI despite high embedding AUC indicates Stage III clustering issues; poor local lab code integration suggests insufficient LOINC mappings; GPT-4o divergence score < 0.95 indicates hierarchical structure violations
- **First 3 experiments:**
  1. Reproduce baseline comparison on simulated SPPMI matrices to validate pipeline without VA/MGB data
  2. Ablate each loss component (additivity, contrastive, information-preserving) to measure contribution
  3. Test alignment quality with reduced code overlap to measure robustness to heterogeneous institutions

## Open Questions the Paper Calls Out

### Open Question 1: Federated EHR Adaptation
- Question: How can MASH be adapted for federated EHR environments without sharing patient-level data?
- Basis: Discussion mentions "directions for future research, particularly in federated EHR environments"
- Why unresolved: Current neural OT requires centralized access to embedding matrices
- Evidence needed: Modified OT algorithm operating on decentralized statistics with comparable performance

### Open Question 2: LLM Integration for Partial Supervision
- Question: How can advanced LLMs like GPT-5 be integrated to provide partial supervision for codes lacking curated hierarchies?
- Basis: Discussion suggests MASH "could be further refined by more effectively leveraging advances in large language models"
- Why unresolved: Current framework relies on existing ontologies for supervision
- Evidence needed: Ablation study with LLM-derived loss constraints showing improved hierarchy construction

### Open Question 3: Manual Category Constraints
- Question: To what extent does manual pre-definition of high-level categories constrain novel hierarchical structures?
- Basis: Supplementary notes manual definition of top-level categories before automated grouping
- Why unresolved: Manual step imposes prior that may prevent identifying valid cross-domain clusters
- Evidence needed: Comparison of quality scores and expert review between constrained and fully unsupervised approaches

## Limitations
- Primary reliance on private VA/MGB EHR data limits independent validation
- Hierarchy evaluation relies on limited reference ontologies covering only 20-33% of codes
- Neural OT alignment performance degrades significantly with minimal code overlap between institutions
- No validation of whether constructed hierarchies improve downstream clinical tasks

## Confidence
- **High Confidence:** Embedding quality claims (AUC of 0.982) well-supported by simulation results
- **Medium Confidence:** Hierarchy alignment metrics (NMI up to 0.947, ARI up to 0.719) methodologically sound but limited by incomplete ground truth
- **Low Confidence:** Claims about clinical interpretability rely heavily on GPT-4o evaluation without independent validation

## Next Checks
1. Apply MASH to open EHR datasets with known hierarchies (e.g., MIMIC-III with ICD-9 mappings) for independent validation
2. Conduct systematic ablation study removing each component to quantify individual contributions
3. Test whether hierarchies constructed by MASH improve performance on clinically relevant tasks like diagnosis prediction