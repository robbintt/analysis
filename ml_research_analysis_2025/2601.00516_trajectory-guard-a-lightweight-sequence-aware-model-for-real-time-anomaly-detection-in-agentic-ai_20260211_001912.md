---
ver: rpa2
title: Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly
  Detection in Agentic AI
arxiv_id: '2601.00516'
source_url: https://arxiv.org/abs/2601.00516
tags:
- trajectory
- anomaly
- trajectories
- loss
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Trajectory Guard addresses the challenge of detecting anomalous\
  \ agent trajectories\u2014plans that fail due to contextual misalignment or structural\
  \ incoherence\u2014by introducing a lightweight, sequence-aware Siamese Recurrent\
  \ Autoencoder. It jointly learns contextual task-trajectory alignment via contrastive\
  \ learning and structural validity via sequence reconstruction, enabling unified\
  \ detection of both \"wrong plan for this task\" and \"malformed plan structure.\"\
  \ Evaluated on synthetic benchmarks and real-world failure logs, the model achieves\
  \ F1-scores of 0.88\u20130.94 on balanced sets and recall of 0.86\u20130.92 on imbalanced\
  \ external benchmarks, with 32 ms inference latency\u201417\u201327\xD7 faster than\
  \ LLM Judge baselines\u2014making it suitable for real-time safety verification\
  \ in production agent deployments."
---

# Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI

## Quick Facts
- **arXiv ID**: 2601.00516
- **Source URL**: https://arxiv.org/abs/2601.00516
- **Reference count**: 4
- **Primary result**: Achieves F1-scores of 0.88–0.94 on balanced sets and recall of 0.86–0.92 on imbalanced benchmarks with 32 ms inference latency—17–27× faster than LLM Judge baselines.

## Executive Summary
Trajectory Guard introduces a lightweight, sequence-aware Siamese Recurrent Autoencoder that detects anomalous agent trajectories by jointly learning contextual task-trajectory alignment and structural validity. The model addresses two failure modes—plans that fail due to contextual misalignment ("wrong plan for this task") and structural incoherence ("malformed plan structure")—through a hybrid loss function combining contrastive learning and sequence reconstruction. Evaluated on synthetic benchmarks and real-world failure logs, it demonstrates real-time safety verification capability suitable for production agent deployments.

## Method Summary
Trajectory Guard employs a Siamese architecture with two towers: a Task Tower that encodes task descriptions into 128-dimensional embeddings using SentenceTransformer and MLP projection, and a Trajectory Tower that encodes and reconstructs agent trajectory sequences using a GRU encoder-decoder. The model learns through a hybrid loss function combining Triplet Margin contrastive loss (for task-trajectory alignment) and mean squared reconstruction loss (for sequence validity). Training uses in-batch negative sampling for efficiency, and anomaly detection is performed by combining contrastive distance and reconstruction error into a unified score. The approach achieves real-time performance (32 ms latency) while maintaining high detection accuracy across diverse benchmark datasets.

## Key Results
- Achieves F1-scores of 0.88–0.94 on balanced synthetic benchmarks
- Maintains recall of 0.86–0.92 on imbalanced external benchmarks (3,802 RAS-Eval, 184 Who&When samples)
- Delivers 32 ms inference latency—17–27× faster than LLM Judge baselines
- Ablation study confirms hybrid loss achieves F1=0.92 vs. 0.82 (contrastive only) or 0.75 (reconstruction only)
- Performance degrades on long trajectories (>10 steps): F1 drops from 0.96 to 0.87

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Loss for Dual Failure Mode Detection
- Claim: Joint optimization of contrastive and reconstruction losses enables detection of both contextual misalignment and structural incoherence.
- Mechanism: Contrastive loss aligns task and trajectory embeddings in shared latent space, while reconstruction loss forces GRU decoder to learn valid sequence "grammar." Anomalies trigger either high contrastive distance (contextual mismatch) or high reconstruction error (structural invalidity).
- Core assumption: Contextual and structural failures manifest as separable signals in the respective loss dimensions.
- Evidence anchors: Ablation study shows hybrid loss achieves F1=0.92 vs. 0.82 (contrastive only) or 0.75 (reconstruction only).

### Mechanism 2: Sequence-Aware Encoding via GRU Autoencoder
- Claim: Recurrent encoding preserves step-order information that mean-pooling destroys, enabling detection of sequentially incoherent plans.
- Mechanism: GRU encoder compresses trajectory sequences into a fixed 128-dim "thought vector." Decoder must reconstruct original sequence, penalizing invalid orderings. Captures dependencies like "delete file before opening it" that bag-of-steps methods miss.
- Core assumption: 128-dim bottleneck is sufficient to encode trajectory structure for typical plan lengths.
- Evidence anchors: VAE and Isolation Forest on mean-pooled embeddings achieve F1 < 0.70.

### Mechanism 3: In-Batch Negative Sampling for Contrastive Learning
- Claim: Using other trajectories in the same batch as negatives provides efficient, diverse hard negatives without explicit negative mining.
- Mechanism: For batch size N, each task embedding serves as anchor, its paired trajectory as positive, and N-1 other trajectories as negatives. Creates (N-1) negative pairs per anchor per batch, scaling contrastive signal efficiently.
- Core assumption: In-batch trajectories are sufficiently diverse to serve as meaningful negatives (not near-duplicates of the positive).
- Evidence anchors: Contrastive-only model achieved F1 ≈ 0.82, demonstrating learning signal from this sampling strategy.

## Foundational Learning

- **Triplet Margin Loss / Contrastive Learning**:
  - Why needed here: Core mechanism for learning task-trajectory alignment; understanding margin, anchor/positive/negative structure is essential for debugging alignment failures.
  - Quick check question: Given a batch of 16 (task, trajectory) pairs, how many triplet combinations does in-batch sampling create per anchor?

- **Sequence-to-Sequence Autoencoders (GRU)**:
  - Why needed here: Trajectory Tower architecture; reconstruction loss depends on understanding encoder-decoder information flow and bottleneck dynamics.
  - Quick check question: Why might a GRU autoencoder achieve low reconstruction loss on anomalous trajectories with repeated patterns?

- **Siamese Network Architectures**:
  - Why needed here: Two-tower design requires understanding weight sharing (none here—separate towers) and how to combine signals from parallel branches.
  - Quick check question: Should the Task Tower and Trajectory Tower share weights? Why or why not for this application?

## Architecture Onboarding

- **Component map**:
  - Task Tower: SentenceTransformer (all-MiniLM-L6-v2, 384-dim) → MLP projection → 128-dim task vector vₜ
  - Trajectory Tower: Step embeddings → GRU encoder (128 hidden) → thought vector vₛ → GRU decoder → reconstructed sequence
  - Loss aggregation: L = L_contrastive + α · L_reconstruction (α = 0.5)
  - Inference: Combined anomaly score from (1) task-trajectory cosine distance and (2) reconstruction error

- **Critical path**:
  1. Embedding quality: SentenceTransformer must produce meaningful step representations for trajectory sequences
  2. GRU encoding: 128-dim bottleneck must capture sequence structure (confirmed degradation at 10+ steps)
  3. Threshold calibration: Anomaly threshold selected on held-out validation set to maximize F1

- **Design tradeoffs**:
  - GRU vs. attention: Paper acknowledges attention mechanisms may help with long trajectories; current GRU chosen for speed (32ms latency)
  - α weighting: Static 0.5 weight; ablation shows both losses necessary but optimal weighting unexplored
  - Embedder choice: all-MiniLM-L6-v2 (384-dim) chosen for efficiency; larger embedders untested

- **Failure signatures**:
  - Long trajectories (>10 steps): Reconstruction error increases for valid sequences, raising false positives
  - Format transfer: Paper notes "negative transfer across trajectory formats"—Galileo (NL commands) vs. AgentAlign (JSON tool calls)
  - Large-scale attacks: Recall drops to 0.86 on RAS-Eval (3,802 samples) vs. 0.92 on Who&When (184 samples)

- **First 3 experiments**:
  1. Reproduce ablation: Train contrastive-only, reconstruction-only, and hybrid models on validation split; confirm F1 gap (0.82/0.75/0.92)
  2. Latency profiling: Measure per-component latency (embedding, GRU encode, GRU decode, loss computation) on CPU vs. GPU to identify bottlenecks
  3. Long-trajectory analysis: Bin test set by step count (2–5, 6–10, 11+) and measure precision/recall degradation curve; test attention-based encoder as replacement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating attention mechanisms resolve the performance degradation observed on trajectories exceeding 10 steps?
- Basis in paper: [explicit] The authors identify the fixed-size GRU vector as an information bottleneck for long sequences and state future work could incorporate attention mechanisms.
- Why unresolved: The current error analysis quantifies the drop (F1 0.96 vs. 0.87) but does not implement or test the proposed architectural solution.
- What evidence would resolve it: A comparison of F1-scores on the 11+ step subset using a Transformer-based encoder versus the current GRU architecture.

### Open Question 2
- Question: Does training on GPT-5 synthesized anomalies limit generalizability to diverse real-world attack vectors?
- Basis in paper: [explicit] The paper acknowledges the risk of circularity due to reliance on synthetic data and notes lower recall (0.86) on the large-scale RAS-Eval benchmark.
- Why unresolved: It is unclear if the model learns the specific "grammar" of the GPT-5 perturbations rather than universal properties of agent failure.
- What evidence would resolve it: Evaluation on a dataset of human-generated adversarial attacks or "zero-day" agent failures excluded from the synthesis process.

### Open Question 3
- Question: How does Trajectory Guard compare in efficiency and accuracy to quantized Small Language Models (SLMs)?
- Basis in paper: [explicit] Future work includes "benchmarking against quantized LLMs to position our approach within evolving AI safety standards."
- Why unresolved: The current comparison uses full-precision LLM Judges; quantized models may offer a competitive middle ground between the lightweight RNN and heavy LLMs.
- What evidence would resolve it: Benchmarking latency (ms) and F1-scores against a 4-bit quantized judge (e.g., Llama-3-8B-Quantized) on identical hardware.

### Open Question 4
- Question: Is the static loss weight ($\alpha=0.5$) optimal for distinguishing contextual versus structural anomalies?
- Basis in paper: [inferred] The ablation study validates the hybrid loss against isolated components but does not test sensitivity to the specific weighting coefficient.
- Why unresolved: Contextual misalignment and structural incoherence are distinct failure modes that may require dynamic or asymmetric weighting to optimize detection.
- What evidence would resolve it: A hyperparameter sweep of $\alpha$ analyzed separately on the "contextual anomaly" and "structural anomaly" subsets of the test set.

## Limitations
- Architecture specification gaps: MLP layer details (activations, normalization) and GRU decoder generation mode (teacher forcing schedule, autoregressive decoding) are unspecified, potentially affecting reproducibility.
- Threshold calibration: The paper states thresholds are tuned for max F1 but doesn't specify the optimization method or validation set composition, making it unclear how robust the 0.88–0.94 F1 range is across datasets.
- Generalization across formats: While performance drops on external benchmarks (0.86–0.92 recall) are acknowledged, the mechanism for "negative transfer across trajectory formats" is not empirically characterized.

## Confidence
- **High confidence**: Dual failure mode detection (contrastive + reconstruction) and real-time inference capability (32 ms latency). These are directly measured with clear baselines.
- **Medium confidence**: Long-trajectory degradation (F1: 0.96 → 0.87) and format transfer issues. Acknowledged but not deeply characterized.
- **Low confidence**: Exact inference scoring mechanism combining contrastive distance and reconstruction error, and the precise impact of MLP/GAT encoder alternatives.

## Next Checks
1. **Ablation replication**: Train contrastive-only, reconstruction-only, and hybrid models on validation split; confirm F1 gap (0.82/0.75/0.92) and measure individual loss contributions to total anomaly score.
2. **Long-trajectory stress test**: Stratify validation/test by sequence length (2–5, 6–10, 11+ steps); measure precision/recall degradation curve and test attention-based encoder as replacement for fixed-size GRU bottleneck.
3. **Cross-format generalization**: Evaluate on synthetic format-shifted data (Galileo → AgentAlign structure or vice versa) without fine-tuning; measure performance drop to quantify negative transfer magnitude.