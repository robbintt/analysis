---
ver: rpa2
title: 'KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language
  Model'
arxiv_id: '2502.20350'
source_url: https://arxiv.org/abs/2502.20350
tags:
- drug
- knowledge
- biomedical
- information
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KEDRec-LM is a large language model designed for explainable drug
  recommendation, addressing the challenge of integrating structured biomedical knowledge
  with unstructured literature to improve drug-disease relationship reasoning. The
  method combines knowledge graph sampling from DRKG, retrieval-augmented generation
  for literature mining, and knowledge distillation to train a specialized LLaMA model.
---

# KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language Model

## Quick Facts
- arXiv ID: 2502.20350
- Source URL: https://arxiv.org/abs/2502.20350
- Reference count: 32
- KEDRec-LM achieves highest F1 scores for drug selection and ROUGE scores for rationale generation on expRxRec and MIMIC-III datasets

## Executive Summary
KEDRec-LM addresses the critical challenge of integrating structured biomedical knowledge with unstructured clinical literature for explainable drug recommendation. The method leverages knowledge graph sampling from DRKG, retrieval-augmented generation for literature mining, and knowledge distillation to train a specialized LLaMA model. Experimental results demonstrate state-of-the-art performance on both drug selection (F1 scores of 88.05 on expRxRec, 69.19 on MIMIC-III) and rationale generation (ROUGE scores of 35.11, 35.17, and 34.03 for ROUGE-1, ROUGE-2, and ROUGE-L respectively on expRxRec). The study highlights the importance of combining multiple knowledge sources and developing tailored biomedical reasoning models for accurate and interpretable drug recommendations.

## Method Summary
KEDRec-LM combines knowledge graph sampling from DRKG, retrieval-augmented generation for literature mining, and knowledge distillation to train a specialized LLaMA model for drug recommendation. The method integrates structured biomedical knowledge with unstructured clinical literature to improve drug-disease relationship reasoning. The approach demonstrates effectiveness in generating both accurate drug recommendations and interpretable rationales for these recommendations.

## Key Results
- Highest F1 scores for drug selection: 88.05 on expRxRec dataset, 69.19 on MIMIC-III dataset
- Superior ROUGE scores for rationale generation: 35.11 ROUGE-1, 35.17 ROUGE-2, 34.03 ROUGE-L on expRxRec
- Outperforms baseline models including GNN, SafeDrug, and BioGPT when enriched with Clinical Trials and PubMed Central data

## Why This Works (Mechanism)
KEDRec-LM works by effectively integrating multiple knowledge sources through knowledge distillation, allowing the model to leverage both structured biomedical knowledge (from DRKG) and unstructured clinical literature (from PubMed Central and Clinical Trials). The retrieval-augmented generation component enables the model to dynamically incorporate relevant literature during the recommendation process, while the knowledge distillation process ensures the specialized LLaMA model captures essential reasoning patterns for drug-disease relationships.

## Foundational Learning
- Knowledge Graph Sampling (DRKG): Needed to provide structured biomedical relationships between drugs and diseases; quick check: verify graph connectivity and coverage of target drug-disease pairs
- Retrieval-Augmented Generation: Required to dynamically incorporate relevant clinical literature; quick check: measure retrieval relevance and latency
- Knowledge Distillation: Essential for transferring knowledge from larger models to specialized LLaMA architecture; quick check: compare performance before and after distillation

## Architecture Onboarding

**Component Map:** Input (Patient Data) -> Knowledge Graph Sampler -> Literature Retriever -> LLM (LLaMA) -> Output (Drug Recommendation + Rationale)

**Critical Path:** Patient data flows through knowledge graph sampling to enrich context, then through literature retrieval to gather supporting evidence, and finally through the distilled LLaMA model to generate both drug recommendations and rationales.

**Design Tradeoffs:** The approach balances between comprehensive knowledge integration and computational efficiency through selective knowledge graph sampling and focused knowledge distillation, rather than using the full DRKG graph or larger base models.

**Failure Signatures:** Poor performance may occur when knowledge graph coverage is insufficient for rare diseases, when literature retrieval fails to find relevant documents, or when the distilled model cannot adequately capture complex drug-disease relationships.

**Three First Experiments:**
1. Evaluate model performance with individual knowledge sources disabled to quantify their relative contributions
2. Test model robustness on out-of-distribution patient cases not well-represented in training data
3. Compare rationale quality through automated metrics versus clinical expert assessment

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to broader clinical settings or rare disease conditions remains unknown
- Knowledge distillation may inherit limitations from base LLaMA model architecture
- Computational overhead and latency implications for real-time clinical applications are not addressed

## Confidence
- Performance metrics on tested datasets: Medium
- Knowledge integration effectiveness: Medium
- Explainability and clinical interpretability: Low
- Generalizability to new clinical scenarios: Low

## Next Checks
1. Test KEDRec-LM on at least two additional independent clinical datasets from different healthcare systems to assess generalizability and potential domain shift effects.

2. Conduct a blinded study with practicing physicians to evaluate whether the generated rationales are clinically meaningful, accurate, and useful for decision-making, beyond automated ROUGE score assessments.

3. Systematically remove individual knowledge components (DRKG, Clinical Trials, PubMed Central) to quantify their relative contributions and identify potential redundancy or overfitting to specific knowledge sources.