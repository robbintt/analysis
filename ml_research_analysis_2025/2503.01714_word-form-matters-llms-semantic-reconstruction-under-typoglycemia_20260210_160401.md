---
ver: rpa2
title: 'Word Form Matters: LLMs'' Semantic Reconstruction under Typoglycemia'
arxiv_id: '2503.01714'
source_url: https://arxiv.org/abs/2503.01714
tags:
- word
- form
- semantic
- attention
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how large language models (LLMs) process
  scrambled words, a phenomenon known as Typoglycemia, by analyzing the roles of word
  form and contextual information in semantic reconstruction. The authors introduce
  SemRecScore, a metric measuring semantic reconstruction quality by comparing the
  original word's token representation with the final subword token's representation
  at each layer.
---

# Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia

## Quick Facts
- **arXiv ID:** 2503.01714
- **Source URL:** https://arxiv.org/abs/2503.01714
- **Reference count:** 12
- **Primary result:** LLMs reconstruct scrambled word semantics primarily through word form information, with minimal reliance on contextual cues.

## Executive Summary
This study investigates how large language models process scrambled words (Typoglycemia) by analyzing the relative roles of word form and contextual information in semantic reconstruction. The authors introduce SemRecScore, a metric measuring semantic reconstruction quality by comparing original word token representations with final subword token representations across model layers. Through controlled experiments with LLaMA models (1B, 3B, 70B) varying Scramble Ratio and Context Integrity, they find that word form is the primary reconstruction driver while contextual information plays a minimal role. The study reveals specialized attention heads dedicated to word form processing, with attention allocation following cyclic patterns across layers, differing fundamentally from human readers' adaptive strategies.

## Method Summary
The study uses the SQuAD dataset, selecting 20,000 samples and filtering to 7,556 qualified words (10+ characters, single-token after tokenization). A 5×5 matrix tests Scramble Ratio (0-1) and Context Integrity (0-1) conditions. SemRecScore measures semantic reconstruction as cosine similarity between original and final subword token representations per layer. AttentionSelf quantifies attention to word form by aggregating attention weights. The analysis evaluates LLaMA-3.2-1B/3B-Instruct and LLaMA-3.3-70B-Instruct across all layers without training—purely analytical evaluation of existing models under controlled scrambling conditions.

## Key Results
- Word form is the primary driver of semantic reconstruction, with SemRecScore degrading proportionally to Scramble Ratio while remaining largely insensitive to Context Integrity levels
- Specific attention heads (H2, H3 early; H12, H26 mid; H14, H24, H25 late) specialize in processing word form information
- Attention allocation to word form follows cyclic patterns across layers in 1B/3B models, with 70B showing extended low-attention plateaus and late surges
- Semantic reconstruction quality plateaus at SR≥0.75, suggesting inherent limitations in handling severe scrambling

## Why This Works (Mechanism)

### Mechanism 1: Word Form as Primary Reconstruction Driver
- **Claim:** LLMs reconstruct scrambled word semantics primarily through word form information, with contextual cues playing a minimal role.
- **Mechanism:** The model's semantic reconstruction ability (measured via SemRecScore) degrades proportionally with increased scramble ratio (SR), while remaining largely insensitive to context integrity (CI) levels—even when CI=0.
- **Core assumption:** The cosine similarity between original and scrambled token representations accurately captures semantic reconstruction quality.
- **Evidence anchors:** [abstract] "identifying word form as the core factor in this process"; [Section 6.1] "word form plays a dominant role" with SemRecScore differences of ~30% between SR=0.25 and SR=1 at final layers; [Section 6.2] "curves for different CI levels are almost over-lapping" indicating minimal context impact.

### Mechanism 2: Specialized Form-Sensitive Attention Heads
- **Claim:** Specific attention heads are dedicated to processing word form information, with their activation increasing as scrambling severity rises.
- **Mechanism:** Rather than uniformly distributing attention, LLMs concentrate word-form processing in identifiable heads (e.g., H14, H24, H25 in final layers; H2, H3 in early layers; H12, H26 driving cyclic patterns).
- **Core assumption:** AttentionSelf metric (aggregated attention to subword tokens) accurately reflects word-form processing intensity.
- **Evidence anchors:** [abstract] "LLMs rely on specialized attention heads to extract and process word form information"; [Section 7.2] Heatmaps show "specific heads consistently focus on word form" across SR levels; [Section 7.2] "more such attention heads are activated" as SR increases.

### Mechanism 3: Cyclic Attention Allocation Across Layers
- **Claim:** Attention to word form follows a non-monotonic, cyclic pattern across layers rather than steadily increasing.
- **Mechanism:** 1B/3B models show clear cyclic AttentionSelf fluctuations; 70B model exhibits an extended low-attention plateau mid-network before a late surge, suggesting scale-dependent processing strategies.
- **Core assumption:** The observed cyclic pattern reflects intentional computational resource allocation rather than training artifacts.
- **Evidence anchors:** [Section 7.1] "attention allocation to word form follows a cyclic pattern across layers"; [Figure 3] Shows oscillating AttentionSelf curves for 1B/3B models; [Section 7.1] 70B model's "prolonged low AttentionSelf" and late surge differs from smaller models.

## Foundational Learning

- **Concept: Typoglycemia phenomenon**
  - Why needed here: Understanding that humans read scrambled words by combining word shape recognition with contextual inference provides the theoretical grounding for comparing human vs. LLM strategies.
  - Quick check question: Can you explain why preserving first and last letters is critical for human word recognition under scrambling?

- **Concept: Subword tokenization and semantic aggregation**
  - Why needed here: SemRecScore depends on comparing the final subword token's representation to the original word token, assuming the final subword carries integrated meaning.
  - Quick check question: Why does the paper focus on the *last* subword token rather than averaging across all subwords in a scrambled sequence?

- **Concept: Attention head specialization**
  - Why needed here: The paper's core finding depends on accepting that individual attention heads can develop functional specialization (e.g., form-sensitive vs. context-sensitive).
  - Quick check question: How would you design an experiment to test whether a specific attention head is genuinely "form-sensitive" versus just happening to attend to certain token positions?

## Architecture Onboarding

- **Component map:** Input: Scrambled text → Tokenizer (creates subword sequence) → Embedding layer → Layers 0-N with attention heads (some form-sensitive: H2, H3 early; H12, H26 mid; H14, H24, H25 late) → Measurement: SemRecScore per-layer via cosine similarity; AttentionSelf per-head → Output: Final-layer representation compared to original token

- **Critical path:**
  1. Scrambled word enters → splits into subwords → Layer 0 shows low SemRecScore (no reconstruction yet)
  2. Early layers: Form-sensitive heads (H2, H3) begin attending to subword sequence
  3. Middle layers: Cyclic attention pattern with continued SemRecScore increase
  4. Late layers: Final form-sensitive heads (H14, H24, H25) complete reconstruction; SemRecScore reaches peak

- **Design tradeoffs:**
  - Word form reliance provides robustness to scrambling but limits adaptive context use
  - Fixed attention patterns offer predictable behavior but sacrifice human-like flexibility
  - 70B model's late-layer attention surge may indicate capacity for alternative interpretations but risks discarding reconstructed semantics

- **Failure signatures:**
  - High SR (≥0.75): SemRecScore plateaus at ~0.5-0.6, indicating incomplete reconstruction
  - 70B model at SR=1: Late-layer SemRecScore *declines* rather than stabilizing, suggesting semantic drift
  - Context removal (CI=0): Minimal impact on its own, but combined with high SR may compound errors

- **First 3 experiments:**
  1. **Baseline replication:** Run SemRecScore analysis on LLaMA-3.2-1B with SR∈{0, 0.25, 0.5, 0.75, 1} at CI=1; verify cyclic attention pattern and final-layer head specialization (H14, H24, H25).
  2. **Context stress test:** Fix SR=0.75 and vary CI∈{0, 0.25, 0.5, 0.75, 1}; quantify whether any CI level produces SemRecScore improvements >5% (testing claim of minimal context impact).
  3. **Head ablation study:** Identify top-3 form-sensitive heads via AttentionSelf; selectively mask them and measure SemRecScore degradation across SR levels to confirm causal role.

## Open Questions the Paper Calls Out

- **Open Question 1:** Do the identified semantic reconstruction mechanisms generalize to model architectures beyond the LLaMA family? [explicit] The authors state in the Limitations section that "experiments are confined to the LLaMA model family, leaving open the question of whether these mechanisms generalize to other architectures." Why unresolved: The study only validated the role of word form and specialized attention heads on specific decoder-only LLaMA models (1B, 3B, 70B). What evidence would resolve it: Applying the SemRecScore metric and attention analysis to encoder-only (e.g., BERT) or encoder-decoder (e.g., T5) models to see if form-sensitive heads persist.

- **Open Question 2:** Does the reliance on word form persist in morphologically rich or non-English languages? [explicit] The Limitations section notes the analysis is "limited to English, and it remains uncertain whether morphologically rich languages exhibit similar dependencies on word form." Why unresolved: Internal word structures vary significantly across languages (e.g., agglutinative languages), which could alter the balance between form reliance and contextual inference. What evidence would resolve it: Conducting controlled scrambling experiments across diverse languages (e.g., Finnish, Turkish) to compare SemRecScore trends against the English baseline.

- **Open Question 3:** How do LLMs utilize word form information under perturbation types other than internal scrambling, such as deletions or phonetic errors? [explicit] The paper acknowledges focusing "specifically on typoglycemia-style scrambling," whereas "other perturbations, such as deletions or phonetic errors, may lead to different reconstruction patterns." Why unresolved: It is unclear if the specialized attention heads identified are robust to missing characters or noise, or if they are specific to permutation errors. What evidence would resolve it: Analyzing attention head activation and SemRecScore when characters are deleted or substituted rather than just scrambled.

## Limitations

- Findings are based on LLaMA models only (1B, 3B, 70B), limiting generalizability to other architectures
- Analysis is restricted to English text, leaving unclear whether morphologically rich languages show similar word-form dependencies
- Cyclic attention patterns observed in smaller models disappear in 70B, suggesting scale-dependent behaviors that aren't fully explained
- The assumption that cosine similarity captures semantic reconstruction quality remains unverified against alternative metrics

## Confidence

- **High confidence:** Word form is the dominant factor in semantic reconstruction (supported by consistent SemRecScore degradation with SR and minimal CI impact across multiple conditions)
- **Medium confidence:** Specialized attention heads process word form information (while heatmaps show head-specific patterns, the causal relationship and generalizability across seeds/models remain unproven)
- **Medium confidence:** Cyclic attention allocation across layers (observed in 1B/3B models but absent in 70B; unclear if this is a robust architectural feature or training artifact)
- **Low confidence:** LLMs' strategy differs fundamentally from human readers (comparison is qualitative; no direct human behavioral data is presented alongside LLM results)

## Next Checks

1. **Cross-architecture replication:** Apply SemRecScore and AttentionSelf analysis to alternative LLM architectures (e.g., BERT, GPT-2, Mistral) to verify whether word form specialization and cyclic patterns are LLaMA-specific or general phenomena. Test with multiple random seeds to assess stability of identified form-sensitive heads.

2. **Multilingual and morphological complexity testing:** Evaluate the same SR/CI matrix on morphologically rich languages (e.g., Turkish, Finnish) where word form and context may interact differently. Measure whether context integrity becomes more influential as morphological complexity increases, challenging the paper's claim of minimal context impact.

3. **Semantic drift validation:** For the 70B model's late-layer SemRecScore decline at high SR, conduct ablation studies where identified form-sensitive heads are selectively masked. If head removal prevents semantic drift, this confirms their role in maintaining reconstruction quality; if not, the decline may reflect inherent limitations in handling extreme scrambling rather than specialized processing failure.