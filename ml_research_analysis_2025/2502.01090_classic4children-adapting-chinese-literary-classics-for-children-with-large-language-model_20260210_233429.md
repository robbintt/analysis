---
ver: rpa2
title: 'Classic4Children: Adapting Chinese Literary Classics for Children with Large
  Language Model'
arxiv_id: '2502.01090'
source_url: https://arxiv.org/abs/2502.01090
tags:
- text
- children
- chinese
- instructchild
- readability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a method called InstructChild to adapt Chinese
  literary classics into child-friendly text by leveraging large language models (LLMs).
  The approach integrates three key techniques: fine-grained instruction tuning incorporating
  character personality and narrative structure, refinement using a readability metric
  (Red-CN) as reward, and lookahead decoding strategy during inference.'
---

# Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model

## Quick Facts
- arXiv ID: 2502.01090
- Source URL: https://arxiv.org/abs/2502.01090
- Reference count: 34
- Introduces InstructChild method that outperforms GPT-4o, GLM-4 by up to 4.93 points on Red-CN readability metric

## Executive Summary
This paper introduces InstructChild, a method for adapting Chinese literary classics into child-friendly text using large language models. The approach combines fine-grained instruction tuning with personality and narrative structure, refinement using a custom readability metric (Red-CN) as reward, and lookahead decoding strategy. Using the Classic4Children dataset based on the Four Great Classical Novels, experiments show InstructChild significantly outperforms existing LLMs across automatic metrics (BLEU, BERTScore) and human evaluations.

## Method Summary
InstructChild uses a three-stage approach on a Qwen2-7B-Instruct backbone. First, LoRA fine-tuning (rank=8) incorporates character personality traits (Big Five Personality Traits) and entity-relation triplets extracted via GPT-4o into integrative instructions. Second, DPO refinement optimizes generation toward higher Red-CN readability scores using preference pairs. Third, lookahead decoding generates multiple candidates and selects tokens based on Red-CN scores to improve real-time readability.

## Key Results
- InstructChild outperforms GPT-4o, GLM-4, and other LLMs on BLEU-1/2, BERTScore (P/R/F1), and Red-CN metrics
- Achieves up to 4.93 points improvement on Red-CN readability metric compared to GPT-4o
- Ablation studies show personality information and narrative structure contribute 0.71 points to Red-CN improvement
- Human evaluation shows superior performance across Fluency, Content Preservation, Character Clarity, and Narrative Efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting explicit character personality profiles and narrative structure into instruction tuning improves child-friendly adaptation quality
- Mechanism: Prepend Big Five Personality Traits scores (1-5 scale with descriptions) and entity-relation triplets to input text as structured context before LoRA fine-tuning
- Core assumption: Children's reading preferences align with vivid character depictions and simplified plot structures that can be captured via BFPT scoring and triplet extraction
- Evidence anchors: [abstract] "we first obtain the characters' personalities and narrative structure as additional information for fine-grained instruction tuning"; [section 4.5.2] "By removing personality information and narrative structure from the integrative instruction, there is a decline in performance on all metrics"

### Mechanism 2
- Claim: A custom readability metric (Red-CN) used as reinforcement learning reward aligns output with children's reading levels
- Mechanism: Red-CN combines (1) adverb/conjunction proportion (target=5), (2) character frequency (target=85), and (3) length ratio via Gaussian-normalized rewards
- Core assumption: The target values (5 for adverbs/conjunctions, 85 for character frequency) derived from expert-adapted texts generalize across all four classical novels
- Evidence anchors: [section 3.2.1] "we analyze expert-adapted child-friendly literary classics and find that these two indicators typically cluster around values of 5 and 85 per sentence"; [section 4.5.2] "the refinement stage improves performance, particularly on the Red-CN metric"

### Mechanism 3
- Claim: Lookahead decoding improves real-time readability by evaluating candidate token sequences against the reward function before selection
- Mechanism: At each decoding step t, generate L candidate sequences with n future tokens, compute G(ŷ<t-1+n) = Red-CN score, then select yt via: f(yt) = log p(yt|y<t, Ins) + λ·max_L(G(ŷ<t-1+n))
- Core assumption: The readability metric computed over partial sequences (n=20 tokens) correlates with final output quality
- Evidence anchors: [section 3.3] "the core idea involves forecasting potential subsequent tokens and then adjusting the selection process toward higher readability scores"; [section 4.5.2] "we notice a slight performance improvement when applying the lookahead decoding strategy"

## Foundational Learning

- Concept: **Big Five Personality Traits (BFPT)**
  - Why needed here: Enables systematic personality scoring of literary characters (openness, conscientiousness, extraversion, agreeableness, neuroticism) to inject into prompts
  - Quick check question: Can you explain why BFPT might be culturally biased for Chinese literary figures, and how that could affect adaptation quality?

- Concept: **Direct Preference Optimization (DPO)**
  - Why needed here: Replaces complex RLHF pipelines with a simpler loss that directly optimizes policy using ranked preference pairs derived from Red-CN scores
  - Quick check question: Given two outputs with Red-CN scores 72 and 75, how would DPO use this pair during training?

- Concept: **LoRA (Low-Rank Adaptation)**
  - Why needed here: Enables fine-tuning of 7B-parameter Qwen2 without modifying frozen weights, reducing GPU memory requirements
  - Quick check question: What happens to LoRA adapters if you change the base model from Qwen2-7B-Instruct to a different LLM family?

## Architecture Onboarding

- Component map: Original text -> GPT-4o API (personality scoring + triplet extraction) -> Integrative instruction assembly -> LoRA fine-tuning (rank=8, 3 epochs) -> DPO refinement (1,000 instances, K=4 candidates) -> Lookahead decoding (L=5, n=20, λ=1)

- Critical path: Personality/triplet extraction quality → Instruction tuning convergence → DPO reward signal quality → Lookahead decoding hyperparameters (L, n, λ)

- Design tradeoffs:
  - Higher L/n improves readability but increases inference latency (section 6: "lookahead decoding strategy incurs substantial computational overhead")
  - Gaussian normalization in Red-CN centers rewards on target values but may over-penalize valid stylistic variations
  - Using GPT-4o for metadata extraction adds API dependency and cost

- Failure signatures:
  - If Red-CN target values don't match your target age group, outputs will be misaligned regardless of training quality
  - If personality extraction fails (e.g., minor characters), instruction becomes noisy
  - If LoRA rank is too low (currently 8), model may underfit the child-friendly style

- First 3 experiments:
  1. **Reproduce baseline comparison**: Run Qwen2-7B-Instruct with standard fine-tuning (no personality/triplets) to verify the 4.93 Red-CN gap reported vs. GPT-4o
  2. **Ablate lookahead decoding**: Compare L=1 (disabled) vs. L=5 vs. L=10 on Red-CN and BLEU metrics to quantify the inference-time contribution
  3. **Validate Red-CN targets**: Manually evaluate 50 samples at different character frequency targets (70, 85, 100) with child readers to verify the 85 assumption generalizes beyond expert-adapted texts

## Open Questions the Paper Calls Out

1. **Balance between simplification and clarity**: The paper notes that while InstructChild simplifies character relationships, this can sometimes lead to misunderstandings, and finding the right balance is crucial for future research.

2. **Computational efficiency**: Lookahead decoding incurs substantial computational overhead, and the paper suggests knowledge distillation as a potential solution to mitigate these costs.

3. **Full chapter sequence adaptation**: Current focus is on paragraph fragments due to model input length limitations, with future work needed to consider full chapter sequences for better narrative coherence.

## Limitations

- Red-CN target parameters (5 for adverb/conjunction proportion, 85 for character frequency) derived from a single expert-adapted text corpus may not generalize across different age groups or literary styles
- Quality of personality extraction using GPT-4o is critical but unverified, with errors potentially propagating through the entire pipeline
- Computational overhead of lookahead decoding may limit practical deployment despite performance benefits

## Confidence

**High Confidence**: The superiority of InstructChild over baseline LLMs (GPT-4o, GLM-4) is well-supported by both automatic metrics (BLEU, BERTScore) and human evaluations across multiple dimensions. The ablation studies demonstrating the contribution of each component (personality/triplets, Red-CN refinement, lookahead decoding) provide strong empirical evidence for the proposed mechanisms.

**Medium Confidence**: The generalizability of Red-CN's target parameters beyond the expert-adapted texts used for derivation is uncertain. While the Gaussian-normalized reward function provides theoretical justification, the assumption that these specific values (5 and 85) are optimal for all children's adaptations requires further validation across different age groups and literary genres.

**Low Confidence**: The cultural appropriateness of applying Western Big Five Personality Traits to Chinese literary characters remains unaddressed. Without validation of BFPT's applicability to Chinese literature, the personality-based instruction tuning may introduce systematic biases or inaccuracies in character portrayal.

## Next Checks

1. **Cross-Cultural Validation of Personality Scoring**: Test InstructChild's adaptation quality using personality descriptors from culturally validated Chinese personality frameworks (e.g., indigenous Chinese personality models) versus Big Five. Compare Red-CN scores and human evaluations to quantify any systematic bias introduced by Western personality constructs.

2. **Age Group Parameter Sensitivity Analysis**: Systematically vary Red-CN's target parameters (character frequency targets of 70, 85, and 100) and evaluate outputs with different child age groups (6-8, 9-12, 13-15 years). Measure whether the original 85 target is universally optimal or if parameter tuning is required for different developmental stages.

3. **Computational Efficiency Trade-off Analysis**: Conduct a systematic ablation study on lookahead decoding parameters (L=1, 2, 5, 10; n=10, 20, 30) measuring the relationship between computational overhead (tokens/second), Red-CN improvement, and inference latency. Identify the Pareto-optimal configuration balancing quality gains against practical deployment constraints.