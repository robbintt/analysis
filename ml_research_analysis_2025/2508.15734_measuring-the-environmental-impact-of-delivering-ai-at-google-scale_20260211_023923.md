---
ver: rpa2
title: Measuring the environmental impact of delivering AI at Google Scale
arxiv_id: '2508.15734'
source_url: https://arxiv.org/abs/2508.15734
tags:
- energy
- prompt
- consumption
- emissions
- serving
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first comprehensive measurement of AI serving
  environmental metrics in a production environment. The authors developed a full-stack
  methodology that accounts for active AI accelerator power, host system energy, idle
  machine capacity, and data center overhead to measure energy, carbon emissions,
  and water consumption of AI inference workloads.
---

# Measuring the environmental impact of delivering AI at Google Scale

## Quick Facts
- arXiv ID: 2508.15734
- Source URL: https://arxiv.org/abs/2508.15734
- Authors: Cooper Elsworth; Keguo Huang; David Patterson; Ian Schneider; Robert Sedivy; Savannah Goodman; Ben Townsend; Parthasarathy Ranganathan; Jeff Dean; Amin Vahdat; Ben Gomes; James Manyika
- Reference count: 40
- Primary result: First comprehensive measurement of AI serving environmental metrics in production, showing median text prompt consumes 0.24 Wh energy, 0.03 gCO2e, 0.26 mL water

## Executive Summary
This paper presents the first comprehensive measurement of AI serving environmental metrics in a production environment, developing a full-stack methodology that accounts for active AI accelerator power, host system energy, idle machine capacity, and data center overhead. Applied to Google's Gemini Apps, the study finds that existing narrow measurement approaches significantly underestimate AI serving environmental impact, with the comprehensive approach revealing 2.4x higher energy consumption per prompt. Over one year, Google's software efficiency efforts and clean energy procurement reduced energy consumption by 33x and carbon footprint by 44x per median prompt, demonstrating that systemic optimizations across the entire serving stack can dramatically reduce environmental impact.

## Method Summary
The methodology measures AI inference workloads using internal telemetry to track PSU power consumption (P_total, P_host, P_accel), machine allocation time (t_total, t_idle), and prompt counts (Q). Total energy is calculated as E_total = Σ(P_total × t_total × PUE), incorporating data center overhead through PUE (1.09 fleet average) and water usage through WUE (1.15 L/kWh). The approach includes active compute energy, idle machine capacity, and facility overhead to provide a comprehensive environmental footprint. Metrics are normalized by prompt count and reported as median values to avoid skew from high-token outliers.

## Key Results
- Median Gemini Apps text prompt consumes 0.24 Wh energy, 0.03 gCO2e, and 0.26 mL water
- Comprehensive measurement approach reveals 2.4x higher energy consumption than narrow accelerator-only benchmarks
- Software efficiency efforts and clean energy procurement drove 33x reduction in per-prompt energy and 44x reduction in carbon footprint over one year
- Idle machine capacity and data center overhead account for significant portions of total environmental impact

## Why This Works (Mechanism)

### Mechanism 1: Full-Stack Energy Attribution
A comprehensive measurement boundary that includes idle capacity and data center overhead reveals significantly higher energy costs per prompt than narrow accelerator-only benchmarks. Total energy is calculated as the sum of active accelerator power, host CPU/DRAM, idle machine capacity (reserved for latency/availability), and facility overhead (PUE). This contrasts with existing approaches that often measure only the active accelerator during a benchmark task. The energy consumed by idle machines and facility overhead is causally attributable to the inference workload because these resources are provisioned explicitly to serve it.

### Mechanism 2: Compound Efficiency Scaling
Significant per-prompt energy reduction (33x over one year) is achieved through compounding optimizations across the model, serving system, and hardware stack. Efficiency gains are multiplicative, with "smarter" architectures (e.g., Mixture-of-Experts), efficient algorithms (quantization), and optimized serving (speculative decoding) reducing total operations per prompt. These software gains are then amplified by hardware efficiency (performance/watt) and improved machine utilization.

### Mechanism 3: Operational Metrics Coupling
Environmental impact (Carbon and Water) is mechanically coupled to energy consumption through facility efficiency metrics (PUE, WUE) and grid emission factors, not just compute load. Emissions and water use are derived values, with carbon calculated as Energy × EmissionFactor + Embodied, and water as (Energy - Overhead) × WUE. Improvements in facility cooling or procuring cleaner grid power directly reduce environmental output even if compute energy remains constant.

## Foundational Learning

- **Power Usage Effectiveness (PUE)**
  - Why needed here: This metric bridges the gap between "machine energy" and "total facility energy." Without understanding PUE, one cannot comprehend why the "Comprehensive Approach" yields 0.24 Wh instead of just the active compute draw.
  - Quick check question: If a server consumes 1000W and the data center PUE is 1.1, what is the total facility power draw required to support that server?

- **Market-Based vs. Location-Based Emissions**
  - Why needed here: The paper cites a 44x reduction in carbon footprint, which is heavily influenced by "clean energy procurement." Understanding the distinction is vital to interpreting this number (Market-based allows crediting for purchased renewables).
  - Quick check question: Does a "Market-Based" calculation reflect the physical carbon intensity of the local grid at the time of the query, or the contracted energy attributes of the provider?

- **Utilization vs. Efficiency**
  - Why needed here: The paper distinguishes between making the model faster (efficiency) and keeping the machines busy (utilization). High utilization amortizes the static overhead of idle capacity across more prompts.
  - Quick check question: Why does serving prompts at "batch size 1" (low utilization) typically result in higher energy-per-prompt metrics compared to a production environment with dynamic batching?

## Architecture Onboarding

- **Component map**: Active Compute (TPUs + Host) -> Provisioning Layer (Idle capacity) -> Facility Layer (Cooling/Power) -> Telemetry (PSU sensors)
- **Critical path**: 1) Instrument PSU-level power meters collecting P_host and P_accel 2) Track machine state with t_total, t_idle, and prompt attribution 3) Apply fleetwide PUE/WUE to normalize and calculate median E_total/prompt
- **Design tradeoffs**: Latency vs. Energy (low latency requires more idle machines), Precision vs. Generalizability (fleet averages vs. site-specific data)
- **Failure signatures**: Using mean instead of median skews results, omitting idle machine energy underreports by ~2.4x, inconsistent PUE/WUE application introduces seasonal bias
- **First 3 experiments**: 1) Run "Existing Approach" vs. "Comprehensive Approach" on your workload to quantify "Hidden Energy" gap 2) Measure ratio of t_idle to t_total to determine idle cost vs. model inefficiency 3) Recalculate per-prompt carbon/water by varying PUE and emission factor to identify key reduction drivers

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the environmental impact of AI model training compared to inference, and how should a comprehensive measurement methodology be adapted for training workloads? The study specifically considers inference and serving energy consumption, leaving training measurement to future work.

- **Open Question 2**: How do multimodal prompts (images, audio, video) compare to text prompts in energy consumption, emissions, and water usage? The study exclusively reports metrics for "median Gemini Apps text prompt" with no discussion of other modalities.

- **Open Question 3**: How significant is data center networking energy consumption in the total AI serving environmental footprint, and at what scale does it become material? The paper states networking energy is estimated to be negligible for text prompts but provides no quantitative analysis.

- **Open Question 4**: Can the comprehensive measurement methodology proposed here be standardized for cross-provider comparisons, and what governance mechanisms would enable adoption? The authors advocate for widespread adoption of comprehensive frameworks but acknowledge the lack of agreed-upon methodologies.

## Limitations

- The methodology relies on internal Google infrastructure and proprietary data that limits external validation and generalization to other providers
- Attribution of idle machine energy to specific prompts assumes perfect resource isolation, which may not hold in multi-tenant serving environments
- Use of fleet-wide averages for PUE (1.09) and WUE (1.15 L/kWh) masks site-specific variations that could significantly affect per-prompt metrics

## Confidence

- **High Confidence**: The full-stack energy attribution mechanism is well-supported by internal telemetry data and produces internally consistent results. The 33x energy reduction claim is directly traceable to documented software efficiency improvements.
- **Medium Confidence**: The carbon footprint reduction (44x) heavily depends on market-based emission factors and clean energy procurement claims that are difficult to verify externally.
- **Low Confidence**: The generalization of these findings to other cloud providers or on-premise deployments is uncertain due to Google's specific infrastructure advantages.

## Next Checks

1. **External Validation Study**: Replicate the comprehensive measurement methodology on a different cloud provider's inference workload to test the generality of the 2.4x hidden energy multiplier and compare efficiency pathways.

2. **Boundary Attribution Audit**: Conduct a controlled experiment measuring the sensitivity of per-prompt metrics to different idle energy attribution schemes (perfect isolation vs. shared multi-tenant models) to validate the causal attribution assumption.

3. **Temporal Stability Analysis**: Track the PUE, WUE, and emission factor variability over a 12-month period to quantify the uncertainty introduced by facility efficiency fluctuations and grid energy mix changes on the reported environmental impact metrics.