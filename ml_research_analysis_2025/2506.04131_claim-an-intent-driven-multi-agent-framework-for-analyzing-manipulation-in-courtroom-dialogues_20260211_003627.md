---
ver: rpa2
title: 'CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in
  Courtroom Dialogues'
arxiv_id: '2506.04131'
source_url: https://arxiv.org/abs/2506.04131
tags:
- manipulation
- courtroom
- legal
- claim
- techniques
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses manipulation detection in courtroom dialogues,
  introducing LegalCon, a dataset of 1,063 annotated conversations, and CLAIM, a two-stage
  Intent-driven Multi-agent framework. CLAIM combines Intent-Driven Chain-of-Thought
  prompting with specialized agents (Detector, Analyzer, Evidence, and Meta) to analyze
  manipulation, identifying primary manipulators and techniques.
---

# CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues

## Quick Facts
- arXiv ID: 2506.04131
- Source URL: https://arxiv.org/abs/2506.04131
- Reference count: 37
- Primary result: Intent-driven multi-agent framework outperforms baselines in manipulation detection (0.731 accuracy), manipulator identification (0.609 accuracy), and technique classification (0.3618 Jaccard)

## Executive Summary
This paper addresses manipulation detection in courtroom dialogues through a novel two-stage framework called CLAIM. The framework combines Intent-Driven Chain-of-Thought prompting with specialized multi-agent reasoning to analyze manipulative behavior in legal conversations. Using a newly curated dataset (LegalCon) of 1,063 annotated courtroom dialogues, the authors demonstrate that their approach outperforms baseline models across three manipulation detection tasks: binary manipulation classification, primary manipulator identification, and multi-label technique classification.

## Method Summary
CLAIM employs a two-stage approach: Stage 1 uses Intent-Driven Chain-of-Thought prompting to extract speaker intents from courtroom dialogues, creating structured reasoning scaffolds. Stage 2 deploys four specialized agents—Detector (manipulation classification), Analyzer (manipulator and technique identification), Evidence (validation), and Meta (aggregation)—each powered by Mistral-7B fine-tuned via QLoRA on the LegalCon dataset. Agents operate independently but share intermediate outputs to collaboratively arrive at final judgments, with the framework specifically optimized for long courtroom conversations.

## Key Results
- Manipulation detection accuracy: 0.731 (baseline: 0.657)
- Primary manipulator identification accuracy: 0.609 (baseline: 0.558)
- Technique identification Jaccard coefficient: 0.3618 (baseline: 0.3158)
- All three tasks show statistically significant improvements over baseline models
- Performance varies by manipulation technique, with emotional manipulation being most detectable

## Why This Works (Mechanism)

### Mechanism 1: Intent-Driven Chain-of-Thought Prompting
- Extracting speaker intent before manipulation analysis improves detection accuracy
- Intent summaries serve as structured reasoning scaffolds that provide context about speaker motivations
- Core assumption: Manipulation is often embedded in speaker intent and rhetorical strategy rather than overt statements
- Evidence: Intent summaries provide intermediate reasoning scaffolds for subsequent analysis (Section 4.1)

### Mechanism 2: Specialized Multi-Agent Decomposition
- Decomposing manipulation analysis across specialized agents outperforms single-model prompting
- Four agents handle distinct subtasks and share intermediate outputs for collaborative refinement
- Core assumption: Manipulation analysis requires context-aware, multi-step reasoning that exceeds single-model capacity
- Evidence: Each agent operates independently but shares intermediate outputs with other agents (Section 4.2)

### Mechanism 3: Domain-Specific Fine-Tuning
- Legal-domain fine-tuning improves manipulation reasoning over generic models
- Mistral-7B fine-tuned on LegalCon using QLoRA adapts to legal discourse patterns and manipulation techniques
- Core assumption: Legal manipulation detection requires domain-specific linguistic and procedural knowledge
- Evidence: Fine-tuning optimizes agent performance for legal-domain reasoning (Section 4.2, 5.2)

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) Prompting
  - Why needed here: Stage 1 uses intent-driven CoT to extract speaker goals
  - Quick check question: Can you explain why CoT prompting might help an LLM infer latent intent versus direct prompting?

- **Concept**: Multi-Agent LLM Orchestration
  - Why needed here: CLAIM's second stage relies on four agents with defined roles and communication patterns
  - Quick check question: What failure modes could emerge if the Meta agent receives conflicting outputs from Analyzer and Evidence agents?

- **Concept**: Parameter-Efficient Fine-Tuning (PEFT/QLoRA)
  - Why needed here: Agents use Mistral-7B fine-tuned via QLoRA on LegalCon
  - Quick check question: What are the memory and performance tradeoffs between QLoRA and full fine-tuning for a 7B parameter model?

## Architecture Onboarding

- **Component map**: Dialogue → Intent-Driven CoT → Intent summaries → Detector/Analyzer/Evidence/Meta agents → Final judgment
- **Critical path**: Dialogue input → Intent-Driven CoT → Intent summaries → Detector Agent → Manipulation present? → Analyzer Agent → Manipulator + Techniques → Evidence Agent → Validated findings → Meta Agent → Final labels
- **Design tradeoffs**: Two-stage approach adds computational overhead but enables interpretability; specialized agents increase coordination complexity but enable task-specific reasoning; QLoRA saves memory but may underfit
- **Failure signatures**: Low technique identification accuracy (Jaccard: 0.3618), manipulator misattribution (ACC: 0.609), degradation on short dialogues
- **First 3 experiments**: Ablate Stage 1 to quantify intent extraction contribution; run each agent independently to assess collaboration value; test cross-domain transfer to non-courtroom datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would incorporating multimodal signals (tone, pauses, facial expressions) significantly improve manipulation detection accuracy in courtroom settings over text-only analysis?
- Basis: Multi-modal frameworks can be explored to yield deeper insights into manipulation dynamics
- Why unresolved: Current framework processes only textual transcripts, yet courtroom manipulation often relies on paralinguistic cues

### Open Question 2
- Question: Can manipulation detection models trained on English courtroom dialogues transfer effectively to other languages and legal systems?
- Basis: Multi-lingual transcripts can be incorporated to enhance diversity and enable cross-cultural analysis
- Why unresolved: LegalCon contains only English transcripts from US courts; manipulation strategies may differ across cultures

### Open Question 3
- Question: How can subjective disagreement in manipulation annotation be systematically reduced without sacrificing label validity?
- Basis: Technique identification shows low inter-annotator agreement (Krippendorff's Alpha 0.41)
- Why unresolved: Manipulation is inherently subjective with no well-defined standard limits distinguishing manipulative behaviors

### Open Question 4
- Question: Does CLAIM's advantage persist on shorter, informal legal interactions rather than long courtroom dialogues?
- Basis: Framework optimized for long conversations (~1000 words average) and may struggle with shorter dialogues
- Why unresolved: Multi-stage architecture may introduce unnecessary complexity for shorter exchanges

## Limitations
- **Annotation subjectivity**: Technique identification shows moderate inter-annotator agreement (Jaccard 0.3618), suggesting inherent subjectivity limits model performance ceiling
- **Hardware constraints**: QLoRA fine-tuning performed on RTX 3060 (12GB) imposes memory limitations affecting batch size and potential overfitting
- **Generalization gaps**: Framework optimized for long courtroom dialogues and may struggle to generalize to shorter or non-legal conversations

## Confidence
- **High confidence**: Two-stage intent-driven framework architecture and task decomposition
- **Medium confidence**: Quantitative performance improvements over baselines
- **Low confidence**: Technique identification performance and cross-domain generalization

## Next Checks
1. **Cross-domain robustness test**: Evaluate CLAIM on non-legal manipulation datasets to quantify domain-specific overfitting
2. **Intent extraction ablation study**: Compare full CLAIM performance against ablated version without Stage 1 intent summaries
3. **Fine-tuning capacity experiment**: Test whether full fine-tuning vs. QLoRA improves technique identification Jaccard coefficient beyond 0.3618