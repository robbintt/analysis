---
ver: rpa2
title: GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking
arxiv_id: '2502.13766'
source_url: https://arxiv.org/abs/2502.13766
tags:
- cultural
- copyrigth
- average
- answer
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GIMMICK, a comprehensive benchmark to assess
  the cultural knowledge of large vision-language models (LVLMs) and large language
  models (LLMs) across 144 countries and six global regions. The benchmark includes
  six tasks built on three novel datasets spanning 728 unique cultural events, evaluating
  31 state-of-the-art models from 500M to 78B parameters.
---

# GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking

## Quick Facts
- arXiv ID: 2502.13766
- Source URL: https://arxiv.org/abs/2502.13766
- Reference count: 40
- Primary result: Introduces a comprehensive benchmark evaluating cultural knowledge of LVLMs and LLMs across 144 countries, revealing strong Western cultural biases

## Executive Summary
This paper introduces GIMMICK, a comprehensive benchmark to assess the cultural knowledge of large vision-language models (LVLMs) and large language models (LLMs) across 144 countries and six global regions. The benchmark includes six tasks built on three novel datasets spanning 728 unique cultural events, evaluating 31 state-of-the-art models from 500M to 78B parameters. Experiments reveal strong Western cultural biases across models and tasks, with performance improving significantly with model size. Multimodal input consistently outperforms single-modality approaches, and external geographic cues further improve results, especially for underrepresented regions.

## Method Summary
The benchmark evaluates 31 models on six tasks across three datasets: CIVQA (image-based cultural origin QA), CVVQA (video-based cultural origin QA), and CKQA/COQA (text-based cultural knowledge QA). Models are tested with image-only, text-only, and multimodal inputs, with and without geographic hints. Evaluation uses relaxed accuracy for discriminative tasks and an LLM-judge setup for generative CKQA tasks. The benchmark is built on 728 Cultural Events and Facets from the UNESCO ICH dataset, with 6,857 images and 993 videos. Inference uses greedy decoding with a 512-token limit, and video tasks use 10-second clips centered on the frame most similar to the reference image.

## Key Results
- Strong Western cultural biases observed across all models and tasks, with up to 14.72pp performance difference between Western and Sub-Saharan African instances
- Model scale significantly improves performance on complex cultural tasks, with moderate to strong Pearson correlations (except for COQAR)
- Multimodal input (text+image) consistently outperforms single-modality approaches, and geographic hints further boost performance across model sizes
- Models perform better on tangible cultural aspects (e.g., food) than intangible ones (e.g., rituals), with closed models achieving 30% accuracy on food vs. 8-10% on rituals

## Why This Works (Mechanism)

### Mechanism 1: Training Data Distribution Shapes Cultural Knowledge
- **Claim:** Models exhibit strong Western cultural biases because their training corpora are disproportionately sourced from Western contexts.
- **Core assumption:** The distribution of cultural knowledge in the training data directly correlates with downstream task performance.
- **Evidence anchors:** Strong Western bias observed across models and tasks; performance disparities up to 14.72pp between Western and Sub-Saharan African instances.
- **Break condition:** Would break if models trained on culturally balanced corpora still exhibited Western bias.

### Mechanism 2: Model Scale Enables Nuanced Cultural Pattern Recognition
- **Claim:** Increasing model parameters significantly improves performance on complex cultural tasks by enhancing capacity to capture fine-grained cultural associations.
- **Core assumption:** Cultural knowledge is distributed and benefits from the non-linear pattern-matching capabilities of larger neural architectures.
- **Evidence anchors:** Performance improves significantly with model size; moderate to strong Pearson correlations across tasks except COQAR.
- **Break condition:** Would be undermined if performance gains from scale were uniform across all regions.

### Mechanism 3: Multimodality and Contextual Cues Provide Complementary Cultural Signals
- **Claim:** Combining visual and textual inputs, and providing explicit geographic hints, improves cultural understanding by offering disambiguating context.
- **Core assumption:** Cultural knowledge is inherently multimodal and benefits from grounded, context-aware reasoning.
- **Evidence anchors:** Text+image inputs consistently yield highest performance; country hints consistently boost performance across model sizes.
- **Break condition:** Would fail if models treated modalities independently or if geographic hints introduced noise.

## Foundational Learning

- **Concept: Cultural Bias in AI Systems**
  - **Why needed here:** To interpret benchmark's regional performance disparities as reflection of data and algorithmic biases
  - **Quick check question:** Can you explain why a model might excel at identifying a Western festival but fail on a Sub-Saharan ritual, even if both are presented with similar image quality?

- **Concept: Multimodal Fusion Architectures**
  - **Why needed here:** To understand how LVLMs integrate visual and textual streams to produce unified cultural representations
  - **Quick check question:** In a typical LVLM, where does the fusion of visual and textual cultural cues primarily occur?

- **Concept: Evaluation Metrics for Generative Tasks**
  - **Why needed here:** The paper uses "relaxed accuracy" and an "LVLM-as-a-Judge" setup; understanding limitations is crucial for assessing reliability
  - **Quick check question:** Why might exact string match accuracy be a poor metric for evaluating open-ended answers about cultural events?

## Architecture Onboarding

- **Component map:** CIVQA, CVVQA, COQA/CKQA datasets → six tasks (image/video/text cultural origin/knowledge QA) → evaluation via relaxed accuracy and LLM-judge → performance analysis across model sizes, modalities, and regions

- **Critical path:** To onboard, run COQA tasks in text-only and image-only modes on small model (e.g., Qwen2 VL 2B) for baseline cultural knowledge and modality synergy. Then test CIVQA with/without geographic hints to understand cue integration.

- **Design tradeoffs:** Benchmark relies on synthetic VQA data generated by GPT-4o and human annotation, balancing scalability with quality but introducing potential annotation noise. Relaxed accuracy favors recall but may over-estimate model competence.

- **Failure signatures:**
  1. Modality Asymmetry: Model performs well on text-only but fails with images, indicating poor visual grounding
  2. Hint Over-reliance: Model shows dramatic improvement only with explicit country hints, suggesting cannot infer cultural context from content alone
  3. Aspect-Specific Collapse: Near-random performance on "rituals" but above-chance on "food," highlighting failure to grasp intangible cultural concepts

- **First 3 experiments:**
  1. Modality Ablation: Evaluate mid-sized LVLM on all COQA and CKQA tasks across I, T, and I+T settings to quantify performance delta from modality fusion
  2. Scale Sensitivity Analysis: Plot performance gap between best (Western) and worst (Sub-Saharan African) regions across four model size groups for CIVQA task
  3. Hint Impact by Region: For large open-source model, run CIVQA with no hints, region hints, and country hints to calculate relative performance gain for each region

## Open Questions the Paper Calls Out
- **English-Only Benchmark Limitation:** Whether English is truly an upper bound for models pretrained on large portions of non-English data, requiring testing of multilingual LVLMs in their dominant pre-training languages
- **Cultural Knowledge Loss in LVLM Conversion:** Why text-only LLM backbones perform better than their LVLM counterparts on text-only tasks, suggesting degradation of cultural knowledge during multimodal conversion
- **Intangible vs Tangible Cultural Aspects:** Why models struggle more with understanding intangible cultural aspects (rituals, traditions) compared to tangible ones (food, tools), requiring investigation into whether this stems from data limitations or model architecture

## Limitations
- Western-centric synthetic data generation using GPT-4o may propagate Western biases into benchmark questions and answers
- Metric limitations for generative tasks (relaxed accuracy and LLM-as-a-Judge) may not fully capture cultural understanding and could over-estimate performance
- Proprietary model configurations (system prompts, API settings) are not fully specified, making exact replication challenging

## Confidence
- **High confidence:** Observed Western cultural bias across models and tasks is robust; correlation between model scale and improved performance on complex cultural tasks is well-supported
- **Medium confidence:** Multimodal input and geographic cues improve cultural understanding, but effect magnitudes vary; models struggle more with intangible cultural aspects, but requires further validation
- **Low confidence:** Specific mechanisms by which model scale leads to better cultural pattern recognition are not fully elucidated

## Next Checks
1. Re-evaluate a subset of CIVQA and CVVQA tasks using a culturally diverse human annotator pool to assess potential bias introduced by GPT-4o-generated data
2. Implement cross-metric validation for CKQA tasks by comparing LLM-judge scores with human-annotated responses using standardized rubric for cultural understanding
3. Conduct modality-specific ablation study on high-performing model by systematically disabling visual and textual streams during CIVQA and CVVQA inference to measure individual contributions