---
ver: rpa2
title: An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection
  in Digital Social Networks
arxiv_id: '2507.05271'
source_url: https://arxiv.org/abs/2507.05271
tags:
- learning
- features
- sexist
- contrastive
- content
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of implicit sexism detection in
  social media, which is challenging due to the subtle and context-dependent nature
  of such content. The authors propose ASCEND, an Adaptive Supervised Contrastive
  lEarning framework that uses a threshold-based contrastive learning approach to
  refine the embedding space by selectively pulling together semantically similar
  texts.
---

# An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks

## Quick Facts
- arXiv ID: 2507.05271
- Source URL: https://arxiv.org/abs/2507.05271
- Authors: Mohammad Zia Ur Rehman; Aditya Shah; Nagendra Kumar
- Reference count: 39
- Primary result: ASCEND achieves average Macro F1 improvements of 9.86%, 29.63%, and 32.51% over existing methods across three sexism detection tasks.

## Executive Summary
This paper addresses implicit sexism detection in social media by proposing ASCEND, an Adaptive Supervised Contrastive lEarning framework. The key innovation is a threshold-based approach that selectively treats same-label pairs as positive samples only when their cosine similarity exceeds a learnable threshold, improving embedding space quality. ASCEND combines RoBERTa feature extraction with word-level attention and auxiliary perception features (sentiment, emotion, toxicity) to detect subtle sexist content that often goes unnoticed by conventional methods. Evaluations on EXIST2021 and MLSC datasets show significant performance gains, with Macro F1 scores reaching 0.7905 on the binary sexism task.

## Method Summary
ASCEND uses a RoBERTa-large encoder for feature extraction, applying word-level attention to the hidden states before classification. The framework implements supervised contrastive learning with a threshold-based positive pair selection mechanism - samples with the same label are only treated as positive pairs if their cosine similarity exceeds a learnable threshold τ. Additional perception features (sentiment from VADER, emotion from NRCLex, toxicity from ToxicBert) are concatenated with the textual embeddings. The model is trained using a combined loss of supervised contrastive loss and cross-entropy loss. Key hyperparameters include threshold τ=0.7 (from ablation studies), and perception features adding 20 dimensions to the final representation.

## Key Results
- Macro F1 scores of 0.7905, 0.5620, and 0.5520 on Tasks 1, 2, and 3 of EXIST2021 respectively
- Outperforms XLM-R and MuSeD by 9.86%, 29.63%, and 32.51% average across all three tasks
- Ablation shows threshold τ=0.7 optimal (F1=0.7905), while τ=1.0 degrades to 0.7779
- Toxicity features contribute most significantly to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Threshold-Based Positive Pair Selection
ASCEND selectively treats same-label pairs as positive samples only when their cosine similarity exceeds a learnable threshold τ. This filters noisy positive pairs that share labels but are semantically dissimilar, improving embedding space quality. The mechanism is validated by ablation showing τ=0.7 achieves optimal F1 (0.7905) while τ=1.0 degrades performance to 0.7779.

### Mechanism 2: Word-Level Attention Over RoBERTa Hidden States
The framework computes attention-weighted sums over the final hidden state sequence using a learned context vector uw, rather than relying solely on the [CLS] token. This context-sensitive token weighting captures subtle sexist cues better than pooled representations alone. Ablation confirms its contribution: removing word-level attention drops Macro F1 from 0.7905 to 0.7783.

### Mechanism 3: Auxiliary Perception Features
ASCEND incorporates sentiment (VADER), emotion (NRCLex), and toxicity (ToxicBert) features as orthogonal cues. These external feature extractors generate vectors concatenated with textual embeddings before classification. Ablation studies show toxicity features have the largest impact, with their removal causing the most significant F1 drop (0.7905 → 0.7782).

## Foundational Learning

- Concept: Supervised Contrastive Loss
  - Why needed here: Core to ASCEND's embedding refinement by pulling same-class samples together and pushing different-class samples apart
  - Quick check question: Given a batch of 4 samples [A, B, C, D] with labels [1, 1, 0, 0], which pairs contribute to the numerator of the contrastive loss for sample A?

- Concept: Cosine Similarity and Thresholding
  - Why needed here: Determines which same-label pairs qualify as positive samples for contrastive learning
  - Quick check question: If embeddings are L2-normalized, what is the range of cosine similarity values, and what does τ=0.7 imply about vector alignment?

- Concept: Multi-label Classification with Joint Loss Optimization
  - Why needed here: Final loss combines contrastive loss and cross-entropy for balanced embedding space and classification performance
  - Quick check question: If contrastive loss decreases but cross-entropy increases, what might this indicate about embedding space separability vs. class boundary quality?

## Architecture Onboarding

- Component map: Input preprocessing → RoBERTa tokenizer → RoBERTa encoder → [CLS] + hidden states L → Word-Level Attention → wla_feats → concat with [CLS] → cls_aug → concat with S + E + T → Classifier head

- Critical path: 1) Threshold parameter τ must be learnable to adapt during training 2) Positive pair matrix must be recomputed each batch using both labels AND cosine similarity 3) Gradient must flow through both loss branches simultaneously

- Design tradeoffs: Threshold value τ=0.7 optimal per ablation; lower increases false positives, higher increases false negatives. Toxicity features most impactful; emotion and sentiment add marginal gains. Three external feature extractors add inference overhead.

- Failure signatures: Macro F1 stagnates around 0.73-0.76 suggests threshold may be ineffective; high recall but low precision indicates threshold too low; significant performance degradation on Spanish data suggests perception features don't transfer well.

- First 3 experiments: 1) Reproduce threshold ablation (0.5, 0.6, 0.7, 0.8, 0.9, 1.0) on validation split 2) Run binary classification with/without perception features on target dataset 3) Test generalization: train on EXIST2021, evaluate on held-out domain

## Open Questions the Paper Calls Out
1. How can explainability methods be integrated to verify model relies on relevant semantic cues rather than spurious correlations?
2. Does the optimal cosine similarity threshold of 0.7 generalize to low-resource languages or distinct social media domains?
3. Can the adaptive contrastive learning mechanism be effectively adapted for multimodal sexism detection?

## Limitations
- Hyperparameter specifications incomplete: learning rate, batch size, optimizer settings, weight decay, and warmup steps not provided
- Temperature parameter for contrastive loss scaling and word-level attention architecture details unspecified
- Evaluation relies heavily on existing datasets which may not represent full diversity of implicit sexism
- Toxicity features may not generalize well to Spanish content due to VADER/NRCLex English focus

## Confidence

- High Confidence: Core architectural components clearly described and validated through ablation studies with substantial performance improvements
- Medium Confidence: Threshold-based positive pair selection mechanism shows strong empirical support but exact learning dynamics of τ remain unclear
- Low Confidence: Generalization claims across languages and domains lack extensive cross-platform validation

## Next Checks

1. Implement ASCEND with threshold parameter τ initialized at 0.7 and monitor its value during training to verify it's being updated through backpropagation

2. Train complete model on EXIST2021 and evaluate on held-out dataset from different social platform to assess cross-domain generalization

3. Conduct targeted ablation studies removing individual perception features specifically on Spanish subset of EXIST2021 to determine if toxicity features extracted by ToxicBert contribute meaningfully to Spanish implicit sexism detection