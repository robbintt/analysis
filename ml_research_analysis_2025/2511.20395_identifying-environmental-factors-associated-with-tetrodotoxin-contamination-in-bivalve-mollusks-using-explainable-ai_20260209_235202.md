---
ver: rpa2
title: Identifying environmental factors associated with tetrodotoxin contamination
  in bivalve mollusks using eXplainable AI
arxiv_id: '2511.20395'
source_url: https://arxiv.org/abs/2511.20395
tags:
- contamination
- bivalve
- features
- mollusks
- water
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an explainable deep learning model to predict
  tetrodotoxin (TTX) contamination in bivalve mollusks using environmental data from
  the Dutch Zeeland estuary. The model used 35 days of meteorological and hydrological
  features as inputs to predict the presence of TTX above regulatory limits.
---

# Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI

## Quick Facts
- arXiv ID: 2511.20395
- Source URL: https://arxiv.org/abs/2511.20395
- Reference count: 11
- Primary result: Developed an explainable deep learning model predicting TTX contamination in bivalves with AUC 0.93 using environmental data

## Executive Summary
This study developed an explainable deep learning model to predict tetrodotoxin (TTX) contamination in bivalve mollusks using environmental data from the Dutch Zeeland estuary. The LSTM-based model used 35 days of meteorological and hydrological features to predict TTX presence above regulatory limits. The model achieved strong predictive performance with an AUC of 0.93 and identified key environmental drivers including sunrise/sunset times, global radiation, water temperature, and chloride concentration. These findings suggest that sunlight exposure and solar intensity play important roles in TTX contamination, potentially linked to bacterial or algal activity, providing valuable tools for early warning of shellfish contamination risks.

## Method Summary
The study collected environmental data including meteorological and hydrological parameters over 35-day windows, which served as inputs to a Long Short-Term Memory (LSTM) neural network. The model was trained to predict the presence of TTX contamination above regulatory limits in bivalve mollusks from the Dutch Zeeland estuary. Explainable AI techniques were applied to identify which environmental features most strongly influenced model predictions. The dataset was split into training and held-out test sets for validation, with performance evaluated using area under the curve (AUC) and specificity/sensitivity metrics.

## Key Results
- LSTM model achieved AUC of 0.93 on held-out test set
- Model achieved 83% specificity at 90% sensitivity for predicting contamination above Action Limit
- Key environmental drivers identified: time of sunrise/sunset, global radiation, water temperature, and chloride concentration
- Model provides valuable tool for early warning of TTX risks in shellfish

## Why This Works (Mechanism)
The model works by learning temporal patterns in environmental data that correlate with TTX contamination events. The LSTM architecture is particularly suited for this task because it can capture dependencies across the 35-day input window, identifying how changes in environmental conditions precede contamination. The explainable AI component reveals that factors like sunlight exposure (through sunrise/sunset timing and global radiation) and water temperature are critical predictors, suggesting these conditions may promote bacterial or algal TTX production that subsequently accumulates in bivalves.

## Foundational Learning
- LSTM networks for sequential data: needed to capture temporal dependencies across 35-day environmental windows; quick check: verify model can predict next-day values in validation set
- Explainable AI methods: needed to interpret complex deep learning predictions and identify key environmental drivers; quick check: confirm top features align with domain knowledge
- Area under curve (AUC) metric: needed to evaluate binary classification performance across all thresholds; quick check: compare AUC to baseline models
- Sensitivity/specificity tradeoff: needed to understand practical detection limits for monitoring applications; quick check: calculate false positive/negative rates at operating point
- Regulatory limit thresholds: needed to frame predictions in terms of actionable contamination levels; quick check: verify Action Limit definitions match local standards

## Architecture Onboarding
Component map: Environmental data inputs (35-day window) -> LSTM network -> Binary classification output -> Explainable AI interpretation
Critical path: Data preprocessing → Feature engineering (35-day aggregation) → LSTM prediction → Model interpretation
Design tradeoffs: Longer time windows might capture more context but increase complexity; shorter windows might miss important temporal patterns. The 35-day window represents a balance between capturing sufficient environmental history while maintaining model tractability.
Failure signatures: Poor performance on test set suggests overfitting or insufficient temporal context; misclassification of borderline cases may indicate threshold sensitivity; inconsistent environmental patterns may reduce model reliability.
First experiments:
1. Test model performance with varying time window lengths (15, 35, 60 days) to optimize temporal context
2. Evaluate model sensitivity to missing environmental data through controlled data removal experiments
3. Compare LSTM performance against simpler temporal models (ARIMA, random forest) as baselines

## Open Questions the Paper Calls Out
None

## Limitations
- Model trained on single geographic location (Dutch Zeeland estuary), limiting generalizability
- 35-day time window was empirically determined and may not be optimal for other regions
- Cannot establish causal relationships or identify specific microbial/algal sources of TTX
- Practical implementation in monitoring programs requires additional real-world validation

## Confidence
- **High confidence**: Predictive model performance metrics (AUC 0.93, 83% specificity at 90% sensitivity) and environmental factor identification are well-supported
- **Medium confidence**: Interpretation of sunlight, temperature, and chloride as primary contamination factors requires further geographic validation
- **Medium confidence**: Model utility for early warning applications supported but needs operational testing

## Next Checks
1. Validate model's predictive performance using independent datasets from other geographic regions with different environmental conditions and bivalve species
2. Conduct controlled laboratory experiments to test hypothesized relationships between identified environmental factors and TTX production by potential bacterial or algal sources
3. Implement model in operational monitoring program to assess practical utility for early warning and compare performance against existing monitoring approaches