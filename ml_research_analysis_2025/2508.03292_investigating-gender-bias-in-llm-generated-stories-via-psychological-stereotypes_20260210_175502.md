---
ver: rpa2
title: Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes
arxiv_id: '2508.03292'
source_url: https://arxiv.org/abs/2508.03292
tags:
- uni00000013
- gender
- uni00000011
- bias
- uni00000010
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates gender bias in large language models (LLMs)
  by examining how psychological stereotypes influence narrative generation. The authors
  introduce a new dataset, StereoBias-Stories (SBS), containing 148,082 short stories
  generated by five LLMs (OPENAI and DEEPSEEK -R1 families) under four prompt conditions:
  no attribute, single attribute, two attributes, or six attributes.'
---

# Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes

## Quick Facts
- **arXiv ID**: 2508.03292
- **Source URL**: https://arxiv.org/abs/2508.03292
- **Reference count**: 40
- **Primary result**: LLM-generated stories show strong male bias in unconditioned prompts, but conditioning on psychological attributes reduces this bias; combining stereotypes amplifies gender-specific effects while mixing opposing stereotypes neutralizes bias.

## Executive Summary
This study investigates gender bias in large language models by examining how psychological stereotypes influence narrative generation. The authors introduce a new dataset, StereoBias-Stories (SBS), containing 148,082 short stories generated by five LLMs under four prompt conditions with 28 psychological attributes. Using a gender contribution metric that counts gendered identifiers in text, the study finds that models are strongly biased toward male characters in unconditioned prompts, but conditioning on any attribute—even gender-neutral ones—significantly reduces this bias. When multiple stereotypical attributes are combined, female stereotypes further reduce bias while male stereotypes amplify it, and mixing opposing stereotypes neutralizes the effect.

## Method Summary
The study uses five LLMs (OpenAI and DeepSeek R1 families) to generate 148,082 short stories with four prompt conditions: no attribute, single attribute, two attributes, or six attributes. These attributes are based on 25 psychological gender stereotypes and three task-related story endings. Stories are generated with temperature=0.7, beams=2, max_tokens=3000 using a children's story prompt template. Gender bias is measured using a gender contribution metric (CG) that counts gendered words, with gender gap (C_Male - C_Female) as the primary bias indicator. The dataset is validated through lexical quality metrics, user studies, and LLM-based evaluations.

## Key Results
- Unconditioned prompts show strong male bias (average gap ~0.23) across all models, with GPT-4o showing the highest bias.
- Conditioning on any attribute reduces male bias significantly, with two-attribute prompts showing average gap reduction to ~0.16.
- Combining multiple stereotypes from same gender category amplifies bias effects; opposing stereotypes neutralize each other (FF stereotypes reduce gap by ~0.25, MM stereotypes increase gap by ~0.15).
- Larger models show stronger alignment with established psychological gender categorizations (R1-70B: 64.5% alignment, GPT-4o: 64.7%).
- Sentiment plays a role: positive sentiments reduce male bias, while negative and neutral sentiments amplify it for male stereotypes.

## Why This Works (Mechanism)

### Mechanism 1: Attribute Conditioning Disrupts Default Narrative Patterns
Providing any attribute constraint in prompts reduces baseline male bias by introducing competing objectives that dilute bias concentration. Unconditioned prompts trigger learned statistical patterns from training data that disproportionately feature male characters, while attribute specifications redirect the model's sampling distribution away from these defaults.

### Mechanism 2: Stereotype Reinforcement Through Semantic Clustering
Stereotypical attributes cluster in semantic space along gender dimensions. When multiple same-category attributes appear together, they reinforce the associated gender direction in the model's representation, increasing the probability of selecting gender-aligned character types and language patterns. Opposing stereotypes create competing activation that cancels directional bias.

### Mechanism 3: Scaling Enables Psychological Alignment Through Representation Complexity
Increased model capacity allows more nuanced representation of subtle semantic associations learned from training data, including culturally embedded stereotype patterns documented in psychology literature. Larger models develop more structured internal representations that better capture the statistical regularities linking specific attributes to gender categories.

## Foundational Learning

- **Concept: Gender contribution metric (CG and Gap)**
  - Why needed here: This is the paper's core measurement approach for quantifying gender representation in stories.
  - Quick check question: If a story contains 10 male identifiers and 5 female identifiers, what is the Gender Gap?

- **Concept: Psychological stereotype grounding**
  - Why needed here: The paper's innovation is grounding attributes in established psychology literature rather than arbitrary selection.
  - Quick check question: Why might "leadership" and "assertiveness" both map to male stereotypes in psychological research, and how does sentiment categorization interact with this?

- **Concept: Prompt conditioning as experimental control**
  - Why needed here: The study design uses four prompt conditions as experimental manipulations for bias measurement.
  - Quick check question: What is the purpose of including gender-neutral attributes (e.g., "neglectful") in the analysis, and how do they serve as a comparison group?

## Architecture Onboarding

- **Component map:** Prompt construction -> Story generation pipeline -> Gender extraction layer -> Bias computation engine -> Quality validation suite
- **Critical path:** Define attribute pool with psychological grounding -> Design balanced prompt sampling strategy -> Generate stories across all model-condition combinations -> Apply gender identifier extraction -> Compute gap metrics and statistical significance tests -> Validate story quality and attribute expression
- **Design tradeoffs:** Binary gender limitation (excludes non-binary representations), lexicon-based metric (doesn't capture character agency or roles), English-only, multi-attribute sparsity
- **Failure signatures:** R1-7B shows near-zero baseline bias but poor attribute expression suggesting generation quality issues; multi-attribute condition shows increased gap relative to two-attribute; sentiment analysis limited to lexical categorization
- **First 3 experiments:** 1) Replicate single-attribute analysis on target model with systematic coverage of stereotyped attributes; 2) Test stereotype combination effects with controlled FF, MM, FM combinations; 3) Validate psychological alignment for your model family by computing per-attribute ∆Gap scores

## Open Questions the Paper Calls Out

- How does gender bias manifest in LLM-generated narratives when including non-binary or gender-diverse identities, and does the "attribute mitigation" effect observed in binary contexts persist? (Paper acknowledges binary gender framework limitation)

- To what extent does the structural complexity or framing of the prompt influence the gender bias observed in the output? (Paper notes this wasn't studied despite acknowledging prompt structure affects bias)

- Does the frequency of gendered identifiers correlate with the agency or power dynamics of characters in the generated stories? (Paper acknowledges identifier-counting method oversimplifies complex portrayals of gender roles and agency)

- Do the observed psychological stereotype alignments and bias amplification effects transfer to languages with grammatical gender or different cultural frameworks? (Paper lists cross-lingual and cultural generalization as limitations)

## Limitations

- Binary gender framework excludes non-binary and gender-diverse identities, limiting generalizability to diverse gender representations.
- Gender contribution metric relies solely on gendered word counts without capturing character agency, narrative roles, or power dynamics.
- Attribution of bias patterns to training corpus statistics versus model architecture remains speculative and unconfirmed.
- Multi-attribute analysis suffers from combinatorial sparsity despite large sample size, potentially limiting statistical power for complex attribute interactions.

## Confidence

- **High confidence:** Single-attribute conditioning consistently reduces baseline male bias across all models
- **Medium confidence:** Stereotype combination effects (reinforcement vs. neutralization) are supported but may involve non-linear interactions
- **Medium confidence:** Scaling effects showing larger models better align with psychological frameworks are demonstrated but correlation doesn't establish causation

## Next Checks

1. Replicate single-attribute analysis on your target model with systematic coverage of male-stereotyped, female-stereotyped, and neutral attributes to establish baseline behavior.
2. Test stereotype combination effects by generating stories with controlled FF, MM, FM, FFF, MMM, FFM, and MMF attribute combinations to verify reinforcement and neutralization patterns.
3. Validate psychological alignment for your model family by computing per-attribute ∆Gap scores and comparing against established benchmarks from the study.