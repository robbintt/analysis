---
ver: rpa2
title: 'RETAIL: Towards Real-world Travel Planning for Large Language Models'
arxiv_id: '2508.15335'
source_url: https://arxiv.org/abs/2508.15335
tags:
- travel
- planning
- user
- information
- plans
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces RETAIL, a novel dataset for real-world travel
  planning that addresses three key challenges: implicit user queries, environmental
  factors, and all-in-one plan generation. RETAIL covers 10,182 real-world cases with
  UGC-enriched POI information and environmental awareness.'
---

# RETAIL: Towards Real-world Travel Planning for Large Language Models

## Quick Facts
- arXiv ID: 2508.15335
- Source URL: https://arxiv.org/abs/2508.15335
- Reference count: 21
- Introduces RETAIL dataset and TGMA framework achieving 2.72% pass rate vs 1.0% baseline

## Executive Summary
This paper addresses the challenge of real-world travel planning for large language models by introducing RETAIL, a comprehensive dataset covering 10,182 real-world cases across 24 Chinese cities. The dataset incorporates user-generated content-enriched POI information and environmental awareness to simulate realistic travel planning scenarios. The authors propose TGMA, a topic-guided multi-agent framework that significantly improves travel plan generation by addressing three key challenges: implicit user queries, environmental factors, and all-in-one itinerary generation.

## Method Summary
The research introduces RETAIL, a novel dataset designed to address real-world travel planning challenges including implicit user queries, environmental factors, and all-in-one plan generation. The dataset comprises 10,182 dialogues across four scenario types: single-turn, single-turn+revision, multi-turn, and multi-turn+revision. To tackle these challenges, the authors propose TGMA (Topic-Guided Multi-Agent) framework, which combines topic-guided interaction logic with a three-agent architecture. The framework includes an Intent Detection Agent for requirement extraction, an Overall Plan Agent using ReAct for high-level planning, and a Detailed Plan Agent for POI enrichment. The model is fine-tuned on Qwen2.5-7B-Instruct and evaluated using 13 specific constraints covering both commonsense and user preference requirements.

## Key Results
- TGMA achieves 2.72% pass rate compared to 1.0% for existing models
- TGMA with Chain-of-Thought achieves 9.6% final pass rate
- Significant improvements in decision-making support and travel plan generation quality

## Why This Works (Mechanism)
The TGMA framework succeeds by structuring the complex travel planning task into manageable components through topic-guided interaction and multi-agent collaboration. The topic-guided interaction logic maintains dialogue context across 8 states, enabling the system to handle implicit queries and environmental factors effectively. The three-agent architecture decomposes the problem: intent detection extracts user requirements, the overall plan agent creates high-level day allocation and attraction planning, and the detailed plan agent enriches the plan with specific POI information, timing, and costs. This structured approach allows the model to handle the complexity of real-world travel planning while maintaining coherence across multiple domains and constraints.

## Foundational Learning
- **Topic-Guided Interaction Logic**: Manages dialogue flow across 8 states (Attraction, Restaurant, Hotel, Transportation, Weather domains) - needed for context-aware topic selection in multi-turn conversations; quick check: verify state transitions handle implicit queries correctly.
- **ReAct Framework**: Combines reasoning and acting for step-by-step planning - needed for systematic day allocation and attraction selection; quick check: ensure intermediate reasoning steps are generated before actions.
- **Multi-Agent Collaboration**: Three specialized agents work together (Intent Detection, Overall Plan, Detailed Plan) - needed to decompose complex travel planning into manageable subtasks; quick check: verify information flow between agents produces coherent final plans.
- **Constraint-Based Evaluation**: 13 specific metrics covering commonsense and user preferences - needed to measure real-world planning quality beyond standard NLP metrics; quick check: validate each constraint passes/fails according to defined rules.

## Architecture Onboarding

**Component Map:**
Knowledge Base (60,279 POIs) -> Intent Detection Agent -> Overall Plan Agent (ReAct) -> Detailed Plan Agent -> Constraint Evaluation

**Critical Path:**
User Query -> Topic-Guided State Selection -> Intent Detection -> Overall Plan (Day Allocation + Attraction Selection) -> Detailed Plan (POI Enrichment + Timing) -> Final Plan Validation

**Design Tradeoffs:**
- Multi-agent architecture increases complexity but enables specialized handling of different planning aspects
- Topic-guided logic provides structure but may struggle with unexpected query patterns
- Knowledge base integration ensures accuracy but requires extensive data collection
- Constraint-based evaluation is rigorous but may be overly strict (9.6% pass rate indicates difficulty)

**Failure Signatures:**
- Near-zero final pass rate (baseline ~1%) indicates Time Interval and POI Validation constraints are primary blockers
- User preference constraint failures suggest intent detection accuracy issues
- Multi-turn incoherence indicates topic-guided logic context management problems

**3 First Experiments:**
1. Test topic-guided interaction logic with sample inputs across all 8 states to verify context-aware topic selection
2. Validate individual constraint checking on sample plans to verify exact pass/fail criteria
3. Conduct ablation studies removing one agent at a time to verify each component's contribution

## Open Questions the Paper Calls Out
None

## Limitations
- Data collection requires extensive web scraping of Chinese travel platforms and simulated dialogue generation using GPT-4o, limiting reproducibility outside well-resourced labs
- Effectiveness depends heavily on prompt engineering for three specialized agents and topic-guided interaction logic, but exact prompt templates are not provided
- Evaluation involves 13 specific constraints with precise validation rules only partially defined, making independent verification difficult

## Confidence
- **High confidence**: Dataset construction methodology and overall framework architecture are clearly specified and conceptually sound
- **Medium confidence**: Dialogue quality metrics are standard and verifiable, but correlation with real-world planning quality is indirect
- **Low confidence**: Exact reproduction of fine-tuning procedure and constraint validation logic is challenging without complete specifications

## Next Checks
1. Implement and validate individual constraint checking (particularly Time Interval and POI Validation) on a small sample of generated plans to verify exact pass/fail criteria
2. Test the topic-guided interaction logic with sample inputs across all 8 states to ensure context-aware topic selection works as intended before full framework integration
3. Conduct ablation studies removing one agent at a time (Intent Detection, Overall Plan, Detailed Plan) to verify the necessity and contribution of each component to overall pass rate improvement