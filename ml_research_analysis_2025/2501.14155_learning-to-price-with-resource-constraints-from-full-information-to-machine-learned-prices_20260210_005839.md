---
ver: rpa2
title: 'Learning to Price with Resource Constraints: From Full Information to Machine-Learned
  Prices'
arxiv_id: '2501.14155'
source_url: https://arxiv.org/abs/2501.14155
tags:
- regret
- hybridt
- information
- bound
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies dynamic pricing with resource constraints,
  addressing the challenge of balancing exploration and exploitation under knapsack
  constraints. The authors introduce three algorithms tailored to different informational
  settings: (1) a Boundary Attracted Re-solve Method for full information, achieving
  logarithmic regret without requiring non-degeneracy; (2) an online learning algorithm
  for scenarios with no prior information, attaining optimal $O(\sqrt{T})$ regret;
  and (3) an estimate-then-select re-solve algorithm that leverages machine-learned
  informed prices with known upper bound of estimation errors.'
---

# Learning to Price with Resource Constraints: From Full Information to Machine-Learned Prices

## Quick Facts
- **arXiv ID**: 2501.14155
- **Source URL**: https://arxiv.org/abs/2501.14155
- **Reference count**: 40
- **Key outcome**: Three algorithms for dynamic pricing with resource constraints across different information settings, achieving logarithmic to optimal square-root regret bounds

## Executive Summary
This paper addresses dynamic pricing under knapsack resource constraints, a problem where firms must simultaneously optimize revenue and manage limited inventory across multiple products. The authors develop a unified framework that adapts to three distinct informational scenarios: full demand information, online learning with no prior information, and scenarios with machine-learned informed prices. The key innovation is bridging the gap between these settings through algorithms that achieve regret bounds ranging from $O(\log T)$ in the full information case to $O(\sqrt{T})$ in the online learning case, with an intermediate regime when informed prices with error bounds are available.

The theoretical contributions include novel regret analysis techniques that handle the exploration-exploitation tradeoff under capacity constraints, with particular attention to cases where optimal solutions lie near the boundary of feasible regions. The work demonstrates that informed prices with reasonable estimation error bounds can significantly improve learning efficiency, reducing regret from square-root to logarithmic scaling in favorable cases. The algorithms are validated through numerical experiments showing their effectiveness across various problem configurations.

## Method Summary
The authors propose three complementary algorithms tailored to different information availability scenarios. The Boundary Attracted Re-solve Method operates in the full information setting, using a re-solving approach that attracts the optimal solution away from capacity constraints to avoid degeneracy issues. For the online learning setting with no prior information, they develop an algorithm that maintains separate exploration and exploitation phases, carefully balancing the need to learn demand patterns against the goal of maximizing revenue. The third algorithm, estimate-then-select re-solve, leverages machine-learned informed prices with known estimation error bounds to achieve intermediate regret performance between the full information and online learning extremes.

All three algorithms share a common structure of iteratively updating price decisions based on observed demand and capacity usage, but differ in how they initialize and update their estimates. The theoretical analysis establishes regret bounds that depend on problem parameters including the inverse of the constraint matrix norm, the number of products, and the quality of informed prices when available. The methods handle both linear and exponential demand models, with careful treatment of cases where optimal solutions may lie on or near the boundary of the feasible region.

## Key Results
- Boundary Attracted Re-solve Method achieves $O(\zeta^2n^2\|B^{-1}\|^2\log T)$ regret in full information setting without requiring non-degeneracy
- Online learning algorithm attains optimal $O((\zeta^2 + \|B^{-1}\|^2)\sqrt{T})$ regret when no prior information is available
- Estimate-then-select algorithm achieves $O(\min\{\rho\sqrt{T}, (\epsilon_0)^2T + C'\log T\})$ regret when informed prices with error bound $\epsilon_0$ are available
- Numerical experiments validate effectiveness across various scenarios, demonstrating robustness to different problem configurations

## Why This Works (Mechanism)
The algorithms work by carefully balancing exploration and exploitation while respecting resource constraints. In the full information case, the boundary attracted re-solve method modifies the optimization objective to pull solutions away from constraint boundaries, preventing degeneracy and enabling logarithmic regret. The online learning algorithm uses confidence bounds that expand near capacity limits, ensuring sufficient exploration in critical regions. When informed prices are available, the estimate-then-select approach uses these as initial estimates, reducing the exploration needed to converge to near-optimal solutions.

## Foundational Learning
- **Knapsack constraints in pricing**: These resource limitations model real-world inventory constraints where total sales across products must respect capacity limits - essential for realistic revenue management applications.
- **Regret minimization in constrained settings**: The framework extends classic multi-armed bandit analysis to handle coupled constraints, requiring new techniques for balancing exploration with capacity management.
- **Boundary behavior analysis**: Understanding when optimal solutions lie near constraint boundaries is crucial for designing algorithms that avoid degeneracy and achieve strong regret bounds.
- **Machine-learned priors in online learning**: Incorporating informed prices with error bounds bridges the gap between full information and online learning, showing how ML predictions can accelerate learning.

## Architecture Onboarding

**Component Map**: Full Info -> Boundary Attracted Re-solve -> Log Regret; No Info -> Online Learning -> Sqrt Regret; ML Prices -> Estimate-Select -> Intermediate Regret

**Critical Path**: Demand observation → Constraint check → Price update → Revenue calculation → Regret computation

**Design Tradeoffs**: Full information algorithms achieve better regret bounds but require accurate demand models; online learning algorithms are more robust but converge slower; ML-informed approaches offer a middle ground but depend on prediction quality.

**Failure Signatures**: Poor performance when optimal solutions frequently lie on constraint boundaries; degradation when informed price error bounds are underestimated; computational intractability for problems with many products and constraints.

**First Experiments**:
1. Compare regret scaling across the three algorithms on synthetic linear demand instances
2. Test algorithm robustness when true demand deviates from assumed parametric forms
3. Evaluate sensitivity of the estimate-then-select algorithm to errors in the provided ε₀ bound

## Open Questions the Paper Calls Out
None

## Limitations
- Performance of estimate-then-select algorithm critically depends on quality of machine-learned informed prices and accuracy of ε₀ error bound estimation
- Assumption of full-information demand models may not hold when demand is censored or partially observed due to stockouts
- Computational complexity for large-scale problems with many products and capacity constraints is not thoroughly analyzed
- Logarithmic regret bound relies on assumption that optimal solution is bounded away from boundary, which may not be realistic in practice

## Confidence
- **High**: Theoretical regret bounds and algorithm performance under stated assumptions
- **Medium**: Practical applicability of algorithms when assumptions are violated
- **Medium**: Computational efficiency for large-scale instances

## Next Checks
1. Empirical evaluation of algorithm performance when demand models deviate from assumed parametric forms
2. Sensitivity analysis of the estimate-then-select algorithm to errors in the provided ε₀ bound
3. Scalability tests measuring computational time as problem size increases in terms of products and constraints