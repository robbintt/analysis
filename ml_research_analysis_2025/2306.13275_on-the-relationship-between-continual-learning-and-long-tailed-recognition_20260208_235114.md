---
ver: rpa2
title: On The Relationship Between Continual Learning and Long-Tailed Recognition
arxiv_id: '2306.13275'
source_url: https://arxiv.org/abs/2306.13275
tags:
- learning
- head
- tail
- cltr
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work bridges continual learning and long-tailed recognition\
  \ by showing that training on imbalanced data yields parameters close to those trained\
  \ only on head classes, with the distance scaling as O(1/\u221AIF). This insight\
  \ motivates CLTR, a framework that sequentially learns head and tail classes using\
  \ standard continual learning methods to prevent forgetting."
---

# On The Relationship Between Continual Learning and Long-Tailed Recognition

## Quick Facts
- arXiv ID: 2306.13275
- Source URL: https://arxiv.org/abs/2306.13275
- Reference count: 40
- Primary result: Proves LTR can be reformulated as CL problem; CL objective upper-bounds balanced LTR loss, ensuring systematic improvements

## Executive Summary
This work establishes a theoretical and practical connection between continual learning (CL) and long-tailed recognition (LTR) by showing that training on imbalanced data yields parameters close to those trained only on head classes, with the distance scaling as O(1/√IF). This insight motivates CLTR, a framework that sequentially learns head and tail classes using standard continual learning methods to prevent forgetting. The paper proves that minimizing the continual learning objective provides an upper bound for the balanced long-tailed recognition loss, ensuring systematic performance improvements. Experiments on CIFAR100-LT, CIFAR10-LT, ImageNet-LT, and Caltech256 validate the theoretical predictions, with CLTR achieving strong results across various benchmarks.

## Method Summary
The method reformulates LTR as a CL problem by partitioning the dataset into head and tail classes based on sample cardinality, then sequentially learning these partitions using standard CL methods. The theoretical foundation shows that weights trained on long-tailed data converge to a bounded neighborhood of head-only weights, and that CL regularization prevents catastrophic forgetting while learning tail classes. The framework uses standard CL methods (EWC, LwF, GPM, SGP) with sufficient regularization weights to ensure the CL objective upper-bounds the balanced LTR loss.

## Key Results
- Proves weights trained on long-tailed data converge within O(1/√IF) of head-only weights
- Shows LTR can be reformulated as sequential CL problem with forgetting prevention
- Demonstrates CL objective upper-bounds balanced LTR loss under specific conditions
- Achieves strong performance on CIFAR100-LT, CIFAR10-LT, ImageNet-LT, and Caltech256 benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Gradient Dominance Drives Weight Convergence Near Head-Only Solution
- Claim: Training on long-tailed data produces weights within O(1/√IF) of weights trained on head classes alone.
- Mechanism: Head classes dominate gradient updates due to sample abundance; tail contribution diminishes as IF grows. The total loss L(D) ≈ γL(D_H) + (1-γ)L(D_T) with γ→1 for IF≫1, forcing convergence toward head-only optimum.
- Core assumption: L2 regularization bounds parameter growth; loss function is either convex (Theorem 3.3) or satisfies KL property with exponent 1/2 for feedforward networks (Theorem 3.5).
- Evidence anchors:
  - [abstract] "weights converge to a bounded neighborhood of those trained exclusively on the Head, with the bound scaling as the inverse square root of the imbalance factor"
  - [Section 3.2-3.3, Theorems 3.3, 3.5] Formal proofs for convex and deep network cases
  - [corpus] Weak direct validation; neighbor papers address long-tailed learning but don't replicate this specific bound
- Break condition: IF approaching 1 (balanced data) removes head dominance; very small datasets may violate smoothness assumptions.

### Mechanism 2: Sequential Partition Learning as Continual Learning Reformulation
- Claim: LTR can be reformulated as a CL problem where partitions are learned sequentially with forgetting prevention.
- Mechanism: Partition dataset by cardinality (|D₁| ≫ |D₂| ≫ ... ≫ |Dₙ|). Each partition becomes a "task" in CL stream. CL regularization prevents catastrophic forgetting of earlier (larger) partitions while learning smaller ones.
- Core assumption: Partitions can be ordered such that each is sufficiently balanced internally (Assumption 3.6).
- Evidence anchors:
  - [abstract] "CLTR...employs standard off-the-shelf CL methods to address LTR problems by sequentially learning Head and Tail classes"
  - [Section 3.5, Proposition 3.8] Formal equivalence between LTR and CL objectives
  - [corpus] Related work on long-tailed CL exists (ViRN paper) but uses different mechanisms
- Break condition: Highly overlapping class distributions across partitions; excessive partitions causing cumulative forgetting beyond CL method capacity.

### Mechanism 3: CL Objective Upper-Bounds Balanced Loss
- Claim: Minimizing the CL loss systematically minimizes the balanced LTR loss (Theorem 3.10).
- Mechanism: CL loss L_CL = L_task + αD_Φ + βD_Ψ. Under Assumption 3.9 (local smoothness, strong convexity, calibration), either the parameter penalty (β ≥ β_min) or output penalty (α ≥ α_min) ensures L_bal(θ) ≤ L_CL(θ) + constant.
- Core assumption: Assumption 3.9 holds in neighborhood N of θ*_H; thresholds β_min, α_min are satisfied by standard CL methods.
- Evidence anchors:
  - [abstract] "minimizing the continual learning objective provides an upper bound for the balanced long-tailed recognition loss"
  - [Section 3.6, Theorem 3.10] Complete proof with explicit threshold conditions
  - [Appendix F.3] Empirical estimation shows β_min ≈ 0.1, α_min ≈ 10^-4, easily satisfied by EWC (β~10-10³), LwF (α~10^-2 to 1)
- Break condition: CL regularization weights too small (β < β_min AND α < α_min); loss landscape violates KL property.

## Foundational Learning
- Concept: **Long-tailed distributions and imbalance factor (IF)**
  - Why needed here: Core problem definition; all theorems scale with IF.
  - Quick check question: Given class sizes [1000, 100, 10], what is IF? (Answer: 100)

- Concept: **Catastrophic forgetting in sequential learning**
  - Why needed here: CLTR's central challenge; CL methods exist to prevent this.
  - Quick check question: If you fine-tune a head-trained model on tail data, what happens to head performance? (Answer: Degradation due to forgetting)

- Concept: **Bregman divergences (parameter-space and output-space)**
  - Why needed here: Theoretical framework for CL regularization (D_Ψ, D_Φ in Theorem 3.10).
  - Quick check question: What Bregman divergence corresponds to L2 regularization? (Answer: Squared Euclidean distance)

## Architecture Onboarding
- Component map: Long-tailed dataset D → Partition (by cardinality) → [D₁ (largest), D₂, ..., Dₙ] → Sequential CL training: Task 1 on D₁, Task 2 on D₂ with CL regularization, ... → Final model θ*_HT
- Critical path:
  1. Partition dataset ensuring |D_i| ≫ |D_{i+1}| (Algorithm A1)
  2. Train on D₁ (head) first
  3. For each subsequent partition, apply CL method (EWC/LwF/GPM/SGP/etc.) with sufficient regularization weights
  4. Verify β ≥ β_min or α ≥ α_min (typically automatic with standard CL hyperparameters)

- Design tradeoffs:
  - More partitions → smaller internal IF but more forgetting risk
  - Larger replay memory M → better retention but re-introduces imbalance
  - Stronger CL regularization → better head retention but potentially slower tail learning

- Failure signatures:
  - Head accuracy drops >5% after tail learning → insufficient CL regularization
  - Tail accuracy remains poor → CL method overly restrictive or partition sizes too different
  - Training diverges → learning rate too high for CL regularization terms

- First 3 experiments:
  1. **Sanity check**: Replicate Theorem 3.3 bound on MNIST-LT—plot ||θ* - θ*_H|| vs 1/√IF, verify linear scaling (R² > 0.95 per Fig. 4).
  2. **Minimal CLTR**: CIFAR100-LT with 2 partitions, LwF (α=0.01), measure head vs tail accuracy degradation compared to baseline.
  3. **Threshold validation**: Train with EWC using β ∈ {0.01, 0.1, 1, 10} on CIFAR100-LT (IF=100), verify performance plateaus when β > β_min ≈ 0.1.

## Open Questions the Paper Calls Out
- How can the assumptions underlying the O(1/√IF) bound be relaxed while maintaining theoretical guarantees? (Theorem 3.3 requires convexity, Theorem 3.5 requires KL property)
- Can the CLTR framework be extended to tasks beyond classification, such as object detection or semantic segmentation?
- What is the optimal partitioning strategy for CLTR in terms of number of partitions and boundary selection?
- How do the theoretical constants (C, M, L^H_sm, m_Ψ, c_Φ) behave in practice, and can tighter bounds be derived?

## Limitations
- Theoretical analysis relies on convexity or KL property assumptions that may not hold for all deep architectures
- Optimal partitioning strategy remains an open question with no principled selection method provided
- Constants in theoretical bounds remain loosely characterized, making practical predictions difficult

## Confidence
- **High**: Gradient dominance mechanism (Theorem 3.3 and 3.5 bounds hold mathematically)
- **Medium**: Sequential partition learning equivalence (Proposition 3.8 depends on Assumption 3.6 validity)
- **Medium**: CL objective upper-bound (Theorem 3.10 requires Assumption 3.9, thresholds estimated empirically)

## Next Checks
1. **Architecture robustness test**: Apply CLTR to vision transformers (ViTs) on ImageNet-LT to verify whether KL property and gradient dominance mechanisms generalize beyond feedforward networks.

2. **Partition sensitivity analysis**: Systematically vary partition boundaries (different numbers of partitions, different class orderings) on CIFAR100-LT to quantify robustness to Assumption 3.6 violations.

3. **Dynamic imbalance test**: Evaluate CLTR on datasets with temporally evolving imbalance (classes gaining/losing samples over time) to test whether the static partitioning approach remains effective.