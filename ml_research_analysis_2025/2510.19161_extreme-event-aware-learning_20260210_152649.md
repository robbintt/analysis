---
ver: rpa2
title: "Extreme Event Aware ($\u03B7$-) Learning"
arxiv_id: '2510.19161'
source_url: https://arxiv.org/abs/2510.19161
tags:
- extreme
- data
- learning
- events
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of learning to predict and generate
  rare, extreme events in complex dynamical systems when such events are absent from
  training data. Standard supervised learning approaches struggle in this scenario
  because they perform well in data-rich regions but fail to capture the correct output
  statistics in data-scarce extreme regions, leading to high epistemic uncertainty.
---

# Extreme Event Aware ($η$-) Learning

## Quick Facts
- arXiv ID: 2510.19161
- Source URL: https://arxiv.org/abs/2510.19161
- Authors: Kai Chang; Themistoklis P. Sapsis
- Reference count: 40
- Key outcome: A framework that enables learning and generating rare extreme events in complex systems even when such events are absent from training data, by incorporating prior statistical information through an observable indicative of extremeness.

## Executive Summary
The paper addresses a critical limitation in supervised learning where standard approaches fail to capture extreme event statistics in data-scarce regions, leading to high epistemic uncertainty. The authors introduce Extreme Event Aware (η-) learning, a framework that incorporates prior statistical information about extreme events through an observable indicative of extremeness. This statistical regularization ensures the learned model fits observed data while enforcing consistency with prescribed extreme event statistics, enabling the generation of unprecedented extreme events even when training data lack extremes.

The theoretical foundation is based on optimal transport theory, which establishes that η-learning optimally minimizes the Wasserstein distance between the learned model's output distribution and the true distribution in the extreme region. Numerical experiments on toy problems and real-world precipitation downscaling demonstrate that η-learning successfully captures extreme event statistics and generates physically plausible, unprecedented extreme scenarios, outperforming standard supervised learning approaches in data-scarce regimes.

## Method Summary
η-learning is a framework that augments standard supervised learning with prior statistical information about extreme events. The approach uses an observable that indicates extremeness to regularize the learning process, ensuring that the learned model not only fits the observed data but also matches prescribed extreme event statistics. This is achieved through a statistical regularization term that enforces consistency between the model's output distribution and the target distribution in extreme regions. The framework is grounded in optimal transport theory, which provides theoretical guarantees that η-learning minimizes the Wasserstein distance between the learned and true distributions in the extreme region. The method is implemented through a modified loss function that balances data fidelity with statistical consistency for extreme events.

## Key Results
- η-learning successfully generates unprecedented extreme events even when training data contains no extreme events
- The framework outperforms standard supervised learning approaches in data-scarce extreme regions
- Real-world precipitation downscaling experiments demonstrate physically plausible extreme event generation
- Theoretical guarantees based on optimal transport ensure optimal minimization of Wasserstein distance in extreme regions

## Why This Works (Mechanism)
η-learning works by incorporating prior statistical knowledge about extreme events directly into the learning objective. Unlike standard supervised learning that only minimizes prediction error on available data, η-learning adds a regularization term that enforces consistency with known extreme event statistics. This is achieved through an observable that quantifies extremeness, which is used to weight the contribution of different data points to the loss function. The optimal transport foundation ensures that the learned model's output distribution matches the true distribution not just in the bulk of the data but specifically in the extreme tails where rare events occur. This statistical regularization effectively guides the model to extrapolate correctly in data-scarce regions while maintaining fidelity to observed data.

## Foundational Learning
- Optimal Transport Theory: Provides mathematical foundation for measuring distributional distances
  - Why needed: Enables theoretical guarantees about distributional consistency in extreme regions
  - Quick check: Verify Wasserstein distance minimization through numerical experiments

- Statistical Regularization: Technique for incorporating prior knowledge into learning objectives
  - Why needed: Allows enforcement of extreme event statistics without requiring training data
  - Quick check: Test sensitivity to regularization strength parameter

- Observable-based Extremeness: Quantification of how "extreme" a data point is
  - Why needed: Provides weighting mechanism for loss function in different data regions
  - Quick check: Validate observable correlates with actual extremeness across domains

- Wasserstein Distance: Metric for comparing probability distributions
  - Why needed: Enables optimization of distributional similarity rather than just pointwise error
  - Quick check: Compare with other distributional metrics (KL divergence, total variation)

## Architecture Onboarding

**Component Map:** Data → Observable Function → Regularized Loss → Model Parameters → Predictions

**Critical Path:** Training data flows through the observable function to compute extremeness weights, which are combined with prediction errors to form the regularized loss. This loss is minimized to update model parameters, producing predictions that respect both observed data and extreme event statistics.

**Design Tradeoffs:** The framework trades computational complexity (additional regularization term) for improved extreme event modeling capability. The choice of observable function and regularization strength involves balancing data fidelity against statistical consistency requirements.

**Failure Signatures:** Poor extreme event generation when prior statistical information is inaccurate; overfitting to observed data when regularization is too weak; failure to capture moderate events when regularization is too strong.

**First Experiments:**
1. Toy problem with known extreme distribution to verify theoretical guarantees
2. Ablation study varying regularization strength on synthetic data
3. Comparison with standard supervised learning on precipitation downscaling task

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness heavily depends on quality and availability of prior statistical information about extreme events
- Framework focuses on one specific observable indicative of extremeness, limiting generalizability
- Optimal transport theory may not fully capture real-world complexities with multiple interacting factors
- Computational efficiency for real-time applications remains unexplored

## Confidence

**High confidence in:**
- Mathematical framework of η-learning and its foundation in optimal transport theory
- General problem statement about standard supervised learning failing in extreme event prediction
- Basic experimental methodology

**Medium confidence in:**
- Claim that η-learning can generate "unprecedented" extreme events
- Effectiveness across different types of extreme events
- Scalability to high-dimensional problems

**Low confidence in:**
- Practical applicability when prior statistical information is imperfect or unavailable
- Computational efficiency for real-time applications
- Robustness of generated extreme events to perturbations in prior information

## Next Checks

1. Conduct ablation studies systematically varying the quality and quantity of prior statistical information to quantify its impact on prediction accuracy and extreme event generation.

2. Test the framework on multiple types of extreme events (e.g., financial crashes, power grid failures, medical emergencies) to assess generalizability across domains.

3. Implement cross-validation experiments where training data contains only moderate events, then evaluate whether the model can predict rare events that fall outside the training distribution by multiple standard deviations.