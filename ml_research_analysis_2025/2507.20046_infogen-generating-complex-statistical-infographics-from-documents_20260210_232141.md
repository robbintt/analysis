---
ver: rpa2
title: 'Infogen: Generating Complex Statistical Infographics from Documents'
arxiv_id: '2507.20046'
source_url: https://arxiv.org/abs/2507.20046
tags:
- metadata
- data
- text
- subchart
- infographics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the task of generating complex statistical
  infographics from text-heavy documents, a problem not previously addressed in the
  literature. The authors curate Infodat, a benchmark dataset linking documents to
  detailed infographic metadata, and propose Infogen, a two-stage framework that first
  generates metadata using fine-tuned LLMs (with DPO alignment and a ranker for selection),
  then produces infographic code via iterative coder and feedback modules.
---

# Infogen: Generating Complex Statistical Infographics from Documents

## Quick Facts
- arXiv ID: 2507.20046
- Source URL: https://arxiv.org/abs/2507.20046
- Reference count: 40
- Primary result: Two-stage LLM framework achieves 74.69% subchart accuracy and 89.56% statistical accuracy on complex infographic generation

## Executive Summary
This paper addresses the underexplored problem of generating complex statistical infographics from text-heavy documents. The authors introduce Infogen, a two-stage framework that first generates structured metadata using fine-tuned LLMs with DPO alignment, then converts this metadata into infographic code. They curate Infodat, a benchmark dataset of 3,463 text-metadata pairs from Pew Research infographics. Evaluations show Infogen (large) significantly outperforms direct prompting and fine-tuning baselines on both automatic and human metrics, demonstrating the value of intermediate metadata generation for complex infographic synthesis.

## Method Summary
Infogen employs a two-stage approach: (1) Metadata Generation - fine-tuned LLMs (Qwen-2, LLAMA 3, Phi-3) generate structured metadata including title, insights, sub-chart types, data, and layout details, with DPO alignment using synthetic preferences from GPT-3.5 Turbo and selection via a fine-tuned ranker; (2) Code Generation - GPT-4o generates Plotly/Plotnine code from metadata, refined through up to 5 iterations of a feedback loop with a LLAMA-3 feedback agent. The framework is trained on Infodat (80:5:15 train/val/test split) using QLoRA with batch_size=2, grad_accum=4, lr=2e-4, max_steps=524, AdamW 8-bit, weight_decay=0.01 on A100 80GB.

## Key Results
- Infogen (large) achieves 74.69% subchart accuracy and 89.56% statistical accuracy on Infodat test set
- Outperforms prompting (GPT-4o, GPT-4o-mini) and fine-tuning baselines (Qwen-2, Phi-3) on all metrics
- Receives highest human evaluation scores for readability (4.37/5), visual appeal (4.28/5), and data accuracy (4.47/5)
- Demonstrates robustness through ranker selection from multiple model outputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Intermediate metadata generation improves complex infographic synthesis over direct text-to-code approaches
- Mechanism: Decomposes task into text-to-metadata and metadata-to-code stages, forcing content planning before rendering
- Core assumption: Structured intermediate representations lead to more accurate multi-subchart outputs than end-to-end generation
- Evidence anchors: Abstract states framework generates metadata then converts to code; Section 4.1 shows C = g(f(T)) process; limited corpus evidence on decomposition efficacy
- Break condition: Hallucinated metadata propagates errors to final code; ranker and feedback loop are mitigation layers

### Mechanism 2
- Claim: DPO with synthetically generated preferences improves metadata quality over fine-tuning alone
- Mechanism: Creates synthetic preference dataset using GPT-3.5 Turbo to rank metadata outputs, then applies DPO loss
- Core assumption: GPT-3.5 Turbo preferences correlate with ground-truth metadata quality
- Evidence anchors: Section 4.2b describes synthetic preference creation; Section 6.1 shows Phi-3 (DPO) performs far better than without DPO; no corpus precedent for DPO in infographic generation
- Break condition: If preference judge systematically misranks outputs, DPO amplifies errors

### Mechanism 3
- Claim: Fine-tuned ranker LLM selecting among multiple model outputs improves robustness and reduces hallucinations
- Mechanism: Three DPO-aligned LLMs generate candidates, ranker (fine-tuned LLAMA 3 70B) selects best based on heuristics like correct subchart count/type
- Core assumption: At least one candidate produces near-correct metadata; ranker can reliably identify it
- Evidence anchors: Section 4.2c explains ranker evaluation process; Section 6.1 shows Infogen outperforms individual small models; no direct corpus precedent
- Break condition: If all candidates incorrect, ranker cannot recover correct answer

## Foundational Learning

- Concept: **Direct Preference Optimization (DPO)**
  - Why needed here: Aligns fine-tuned LLMs with task-specific quality preferences without training separate reward model
  - Quick check question: Can you explain how DPO differs from RLHF and why a synthetic preference dataset might introduce bias?

- Concept: **Multi-agent LLM pipelines with iterative feedback**
  - Why needed here: Code generation uses up to 5 iterations of coder-feedback loop to refine outputs
  - Quick check question: How would you instrument the feedback loop to log which constraints fail most often and at which iteration?

- Concept: **Evaluation metrics for structured generation**
  - Why needed here: Introduces custom metrics (sub-chart accuracy, statistical accuracy, ROUGE-L variants) because standard metrics don't capture infographic fidelity
  - Quick check question: Why might statistical accuracy alone be insufficient for evaluating infographic utility?

## Architecture Onboarding

- Component map: Input text → Metadata candidates (3 LLMs) → Ranker selection → Coder generates initial code → Feedback loop (≤5 iterations) → Final infographic code → Render
- Critical path: The ranker's selection and feedback loop's termination condition are key control points
- Design tradeoffs: Performance vs. inference cost (1.5× higher for Infogen large); synthetic vs. human preferences for scalability; dataset size vs. generalization
- Failure signatures: Incorrect subchart count propagates layout errors; overlapping text indicates feedback loop failed; hallucinated statistics trace back to metadata generation
- First 3 experiments:
  1. Reproduce metadata generation baseline: Fine-tune single LLM on Infodat, evaluate vs. few-shot GPT-4o
  2. Ablate DPO vs. fine-tuning only: Compare QLoRA-only vs. QLoRA+DPO for one model
  3. Stress-test feedback loop: Run on held-out documents, log iteration count, constraint failures, final accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can InfoGen maintain high statistical and subchart accuracy in specialized, high-stakes domains like healthcare or finance without extensive domain-specific fine-tuning?
- Basis in paper: Explicitly lists "expanding to healthcare and finance" as future direction; states current dataset limitations affect generalizability in diverse domains
- Why unresolved: Training data from Pew Research may not capture medical or financial reporting conventions
- What evidence would resolve it: Evaluation on medical/financial reports without fine-tuning vs. domain-specific fine-tuning

### Open Question 2
- Question: How can context-aware template selection be integrated into metadata generation stage to improve user adaptability?
- Basis in paper: Limitations note lack of support for customized template selection based on context
- Why unresolved: Current framework generates layout implicitly rather than from user-selectable template library
- What evidence would resolve it: Modified framework conditioning on user-provided template ID, validated by user study

### Open Question 3
- Question: To what extent does iterative feedback module fail to correct "syntactically correct but visually misaligned" code?
- Basis in paper: Acknowledges misalignments can cause infographics to miss key data structure details; admits code generation not explicitly evaluated
- Why unresolved: Evaluation focuses on final image, unclear if module truly understands spatial alignment
- What evidence would resolve it: Ablation study reporting rate of visual alignment errors persisting after max iterations vs. initial code

## Limitations
- Dataset size (3,463 samples) and Pew Research specificity may limit transfer to other infographic styles/topics
- Synthetic preference dataset quality unverified; DPO formulation uses fixed β without sensitivity analysis
- Feedback loop convergence behavior across diverse inputs not characterized
- DPO alignment benefits depend on judge reliability; ranker heuristics may not capture all correctness criteria

## Confidence
- High confidence: Sub-chart and statistical accuracy improvements over baselines; human evaluation ranking of Infogen (large) as best
- Medium confidence: DPO alignment benefits (synthetic preference quality unverified); ranker effectiveness (heuristics not fully specified)
- Low confidence: Generalization to unseen infographic domains; robustness to varied text lengths and styles

## Next Checks
1. Audit synthetic preference dataset: Sample ranked pairs and verify GPT-3.5 Turbo preferences align with ground-truth metadata quality
2. Characterize feedback loop convergence: Run on held-out documents, log iteration counts, constraint failures, final accuracy to identify failure patterns
3. Test domain transfer: Apply Infogen to infographics from different sources (government reports, news articles) and measure accuracy drop