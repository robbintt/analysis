---
ver: rpa2
title: Multi-Modal Camera-Based Detection of Vulnerable Road Users
arxiv_id: '2509.06333'
source_url: https://arxiv.org/abs/2509.06333
tags:
- detection
- thermal
- class
- training
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a multimodal detection framework for vulnerable
  road users (VRUs) using YOLOv8, combining RGB and thermal infrared cameras. The
  method leverages fine-tuning on KITTI, BDD100K, and Teledyne FLIR datasets with
  class re-weighting, partial backbone freezing, and augmentation to improve detection
  of under-represented VRU classes.
---

# Multi-Modal Camera-Based Detection of Vulnerable Road Users

## Quick Facts
- **arXiv ID**: 2509.06333
- **Source URL**: https://arxiv.org/abs/2509.06333
- **Reference count**: 33
- **Primary result**: Multimodal YOLOv8 framework combining RGB and thermal infrared cameras achieves robust VRU detection with 640px resolution, partial backbone freezing, and class-weighted losses

## Executive Summary
This study proposes a multimodal detection framework for vulnerable road users (VRUs) using YOLOv8, combining RGB and thermal infrared cameras. The method leverages fine-tuning on KITTI, BDD100K, and Teledyne FLIR datasets with class re-weighting, partial backbone freezing, and augmentation to improve detection of under-represented VRU classes. Experimental results show that 640-pixel resolution and partial backbone freezing optimize accuracy and efficiency, while class-weighted losses enhance recall for rare VRUs. Thermal models achieve the highest precision, and RGB-to-thermal augmentation boosts recall. The framework demonstrates robust VRU detection performance, particularly in challenging lighting and weather conditions, highlighting the potential of multimodal approaches to improve VRU safety at intersections.

## Method Summary
The framework uses YOLOv8m with 640px input resolution, trained on combined KITTI, BDD100K, and Teledyne FLIR datasets. The model employs partial backbone freezing (6 layers), class-weighted loss functions, and light augmentations. RGB-to-thermal image translation augments the thermal dataset. Separate RGB and thermal models are trained and combined via late fusion for inference. The approach maps heterogeneous labels to 7 standardized classes and optimizes for real-time edge deployment.

## Key Results
- 640px resolution improves mAP50 from 0.377 to 0.531 compared to 320px
- Partial backbone freezing (6 layers) optimizes accuracy-efficiency trade-off
- Class-weighted losses increase recall for rare VRU classes (0.300 to 0.480)
- Thermal RGB-TIR model achieves highest recall (0.689) compared to baseline Thermal (0.638)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Partial backbone freezing (6 layers) optimizes the accuracy-efficiency trade-off compared to full backbone freezing (10 layers) or full fine-tuning.
- **Mechanism**: Freezing early layers retains pre-trained low-level features (edges, textures from COCO), while training later layers allows the model to adapt high-level representations to novel VRU shapes and thermal patterns without overfitting or excessive computation.
- **Core assumption**: The pre-trained feature extractor (COCO weights) contains transferable general features that do not require re-learning for the target VRU domain.
- **Evidence anchors**: [abstract] "...partial backbone freezing optimise accuracy and efficiency..."; [section 4.2, Table 5] Freezing 6 layers yields mAP50 0.481 vs 0.459 for 10 layers; Recall 0.440 vs 0.316.

### Mechanism 2
- **Claim**: Class-weighted loss functions increase detection recall for rare VRU classes (scooters, motorcycles) by counteracting dataset bias toward dominant classes (cars).
- **Mechanism**: By assigning higher penalty weights to misclassifications of minority classes, the optimizer is forced to update gradients to favor these classes, shifting the decision boundary to reduce false negatives on rare categories.
- **Core assumption**: Increasing the loss weight for minority classes does not catastrophically degrade the feature extraction capability for majority classes.
- **Evidence anchors**: [abstract] "...class-weighted losses enhance recall for rare VRUs."; [section 4.3, Table 8] Adjusted 7-class model recall jumps from 0.300 to 0.480.

### Mechanism 3
- **Claim**: RGB-to-Thermal image translation acts as an effective data augmentation strategy to improve recall when real thermal data is limited.
- **Mechanism**: Converting abundant RGB images to synthetic thermal representations exposes the model to a wider variance of poses and contexts (from BDD100K/KITTI) in the thermal domain, improving generalization despite the "domain gap" of synthetic textures.
- **Core assumption**: Synthetic thermal textures retain sufficient structural information (shapes/gradients) to be useful for learning spatial features, even if absolute temperature values are inaccurate.
- **Evidence anchors**: [abstract] "...RGB-to-thermal augmentation boosts recall."; [section 4.5, Table 11] Thermal RGB-TIR model achieves highest recall (0.689) compared to baseline Thermal (0.638).

## Foundational Learning

- **Concept: Class Imbalance & Cost-Sensitive Learning**
  - **Why needed here**: The combined dataset is dominated by cars (~817k instances) vs scooters (~41 instances). Standard training ignores rare classes; understanding loss re-weighting is required to fix this.
  - **Quick check question**: Why would a model trained on this dataset predict "Car" for a "Scooter" if standard Cross-Entropy loss is used?

- **Concept: Transfer Learning & Layer Freezing**
  - **Why needed here**: The study relies on YOLOv8 pre-trained on COCO. Understanding which layers to freeze determines if the model retains general features or overfits to the specific KITTI/FLIR datasets.
  - **Quick check question**: What happens to the model's ability to detect generic features if you freeze *all* layers (including the detection head)?

- **Concept: Multimodal Sensor Fusion (Late Fusion)**
  - **Why needed here**: The system uses separate RGB and Thermal models. Understanding how to combine their confidence scores is critical for the final output.
  - **Quick check question**: If the RGB model is confident but the Thermal model is not (due to warm weather), how should a late-fusion system weigh these conflicting inputs?

## Architecture Onboarding

- **Component map**: RGB Camera + Thermal Infrared (TIR) Camera -> YOLOv8m Backbone (CSPDarknet) -> Path Aggregation Network (PAN) -> Decoupled Head (7 custom classes) -> Late Fusion module

- **Critical path**: Data Unification (mapping heterogeneous labels) -> Augmentation (Albumentations + RGB-to-Thermal translation) -> Training (fine-tuning with frozen backbone + Class-Weighted loss) -> Inference (parallel RGB/Thermal -> Fusing bounding boxes)

- **Design tradeoffs**: Resolution (320 vs 640): 640px is required for small VRU detection (mAP +50%), but increases compute cost significantly. Precision vs Recall: Class weighting increases Recall (safety-critical: don't miss VRUs) but slightly lowers Precision (more false positives). Heavy vs Light Augmentation: Heavy augmentation degraded metrics; Light augmentation provided the best robustness-to-accuracy ratio.

- **Failure signatures**: Low Recall on Scooters: Indicates class weights are insufficient or training data is too sparse. High Box Loss on Thermal: Suggests synthetic RGB-to-Thermal images may have misaligned bounding boxes or poor texture fidelity. False Positives in Snow: Suggests weather augmentation parameters may be too aggressive or distinct from test conditions.

- **First 3 experiments**: 1) Resolution Sensitivity Test: Train on 320px vs 640px to confirm if compute budget allows for the accuracy gain required for small objects. 2) Freezing Ablation: Compare 0, 6, and 10 frozen layers to identify the optimal point between retaining COCO features and learning VRU-specific thermal features. 3) Weighted Loss Calibration: Train a baseline model, then apply calculated class weights to verify if Recall improves for minority classes without destroying mAP for Cars/Pedestrians.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the integration of active sensing modalities, such as LiDAR or radar, provide significant performance gains over the RGB-thermal baseline? [explicit] The conclusion states future work will extend the approach through the "integration of additional sensing modalities such as radar or LiDAR."

- **Open Question 2**: To what extent does incorporating temporal tracking and trajectory prediction enhance the system's ability to prevent VRU-vehicle conflicts? [explicit] The authors suggest that "incorporation of temporal tracking and trajectory prediction could further enhance the system's ability to anticipate and prevent VRUâ€“vehicle conflicts."

- **Open Question 3**: Can the heavy augmentation regime be optimized to improve adverse-weather robustness without sacrificing the mAP performance observed in the baseline? [inferred] Table 10 shows that heavy augmentation caused a drop in mAP (0.412) compared to the baseline (0.531), even though it qualitatively improved detection in adverse weather (Fig 3).

## Limitations

- Limited empirical evidence for the independent contribution of each mechanism (backbone freezing, class weighting, augmentation)
- Class weighting strategy effectiveness not validated for the most underrepresented classes like scooters
- RGB-to-thermal augmentation implementation and impact on thermal-only models remains unclear
- Heavy augmentation regime degraded mAP performance despite qualitative weather robustness improvements

## Confidence

- **High Confidence**: Resolution impact (640px improves mAP50 from 0.377 to 0.531) - supported by direct ablation results
- **Medium Confidence**: Partial backbone freezing benefits - supported by Table 5 results but limited to this specific dataset
- **Medium Confidence**: Class-weighted loss improving recall - supported by Table 8 but lacks validation on most rare classes
- **Low Confidence**: RGB-to-thermal augmentation effectiveness - cited improvement exists but synthetic data quality not validated

## Next Checks

1. **Per-class recall validation**: Run inference on the test set and calculate recall specifically for scooters, motorcycles, and cyclists to verify if class weighting actually improves the rarest categories rather than just averaging across classes.

2. **Synthetic thermal data quality assessment**: Compare bounding box quality and thermal contrast between real and RGB-to-thermal translated images to verify the synthetic data is teaching correct features rather than introducing noise.

3. **Cross-dataset generalization test**: Evaluate the trained model on a held-out subset of Teledyne FLIR thermal data that wasn't used in training to verify the augmentation strategy actually improves generalization rather than overfitting to synthetic patterns.