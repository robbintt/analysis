---
ver: rpa2
title: Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant
  Ventricular Arrhythmias in AMI Patients
arxiv_id: '2510.17172'
source_url: https://arxiv.org/abs/2510.17172
tags:
- features
- feature
- were
- ventricular
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a hybrid predictive framework that combines
  a large-scale ECG foundation model (ECGFounder) with an interpretable XGBoost classifier
  to predict in-hospital malignant ventricular arrhythmias (VT/VF) in acute myocardial
  infarction (AMI) patients. The framework extracts 150-dimensional diagnostic probability
  features from raw ECG data and uses them to train an XGBoost model.
---

# Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients

## Quick Facts
- arXiv ID: 2510.17172
- Source URL: https://arxiv.org/abs/2510.17172
- Reference count: 0
- Primary result: Hybrid ECGFonder + XGBoost model achieves AUC 0.801 for predicting in-hospital VT/VF in AMI patients

## Executive Summary
This study presents a hybrid predictive framework that combines a large-scale ECG foundation model (ECGFounder) with an interpretable XGBoost classifier to predict in-hospital malignant ventricular arrhythmias (VT/VF) in acute myocardial infarction (AMI) patients. The approach extracts 150-dimensional diagnostic probability features from raw ECG data and uses these features to train an interpretable XGBoost model. The framework achieved an AUC of 0.801 and F1-score of 0.391 on the test set, outperforming baseline models including KNN, RNN, and end-to-end 1D-CNN approaches. SHAP analysis demonstrated that the model's key features align with established clinical knowledge, identifying "premature ventricular complexes" as a risk predictor and "normal sinus rhythm" as a protective factor.

## Method Summary
The framework leverages ECGFonder, a foundation model trained on 24-hour Holter ECG recordings, to extract diagnostic probability features from 12-lead ECG segments. These 150-dimensional feature vectors serve as input to an XGBoost classifier, which predicts the occurrence of in-hospital VT/VF within 24 hours of admission. The study retrospectively analyzed data from 1,183 AMI patients across two periods (2016-2019 for training/validation and 2020-2023 for testing). The hybrid approach combines the ECGFonder's ability to capture complex ECG patterns with XGBoost's interpretability, allowing clinicians to understand which features drive predictions. The model was evaluated against several baselines including KNN, RNN, and 1D-CNN approaches.

## Key Results
- Hybrid ECGFonder + XGBoost model achieved AUC of 0.801 and F1-score of 0.391
- Outperformed baseline models: KNN (AUC 0.677), RNN (AUC 0.676), and end-to-end 1D-CNN (AUC 0.720)
- SHAP analysis identified clinically meaningful features including premature ventricular complexes as risk predictor and normal sinus rhythm as protective factor
- Model demonstrates improved interpretability compared to black-box alternatives while maintaining competitive performance

## Why This Works (Mechanism)
The hybrid approach combines the strengths of pre-trained foundation models with interpretable machine learning. ECGFonder, trained on large-scale ECG data, captures complex temporal and morphological patterns that are difficult to engineer manually. By extracting diagnostic probability features from this foundation model, the approach transfers knowledge from a broad ECG understanding to the specific task of VT/VF prediction. XGBoost then provides interpretability through feature importance scores while maintaining strong predictive performance. This combination addresses the dual challenges of ECG complexity and clinical interpretability that often limit pure deep learning approaches in healthcare settings.

## Foundational Learning
- **ECG Foundation Models**: Pre-trained models on large ECG datasets that capture general ECG patterns and can be fine-tuned for specific tasks. Why needed: ECG signals contain complex temporal patterns that are difficult to capture with small datasets alone. Quick check: Verify the foundation model was trained on diverse ECG data from multiple sources.
- **Feature Extraction from Deep Models**: Using intermediate layer outputs or final predictions as features for downstream models. Why needed: Combines the pattern recognition of deep learning with the interpretability and efficiency of traditional ML. Quick check: Confirm feature dimensions match between foundation model and downstream classifier.
- **SHAP Analysis**: Shapley additive explanations for interpreting model predictions by quantifying feature contributions. Why needed: Provides clinically interpretable explanations that align with medical knowledge. Quick check: Verify SHAP values are consistent across multiple model runs.
- **Imbalanced Classification**: Techniques for handling datasets where one class significantly outnumbers the other. Why needed: VT/VF events are rare, making standard training approaches problematic. Quick check: Review class distribution and whether appropriate techniques were applied.
- **Temporal ECG Analysis**: Understanding patterns in ECG signals over time, particularly for arrhythmia prediction. Why needed: Arrhythmias often develop gradually, requiring temporal context. Quick check: Confirm whether temporal features or sequential models were incorporated.
- **Interpretability vs Performance Trade-offs**: Balancing model accuracy with clinical understandability. Why needed: Clinicians need to trust and understand predictions for adoption. Quick check: Compare performance of interpretable vs black-box models on the same task.

## Architecture Onboarding

**Component Map**: Raw ECG -> ECGFonder Foundation Model -> 150D Feature Vector -> XGBoost Classifier -> VT/VF Prediction

**Critical Path**: The foundation model processes raw ECG data to extract diagnostic probabilities, which serve as features for the XGBoost classifier. This path is critical because it transforms complex ECG patterns into interpretable features while maintaining predictive power.

**Design Tradeoffs**: The hybrid approach sacrifices some potential performance from pure deep learning to gain interpretability through XGBoost. While an end-to-end 1D-CNN achieved AUC 0.720, the hybrid approach improved to 0.801 by leveraging pre-trained knowledge while maintaining explainability. The choice of 150 features represents a balance between information richness and model complexity.

**Failure Signatures**: Model performance may degrade when encountering ECG patterns significantly different from the foundation model's training distribution. The moderate F1-score (0.391) suggests challenges with false positives/negatives, potentially due to rare event prediction or subtle arrhythmia precursors not captured by current feature extraction.

**First Experiments**: 1) Ablation study removing foundation model features to assess their contribution to performance; 2) Cross-validation with different train/test splits to evaluate stability; 3) Feature importance analysis varying XGBoost hyperparameters to understand robustness of SHAP-identified features.

## Open Questions the Paper Calls Out
None

## Limitations
- Moderate performance metrics (AUC 0.801, F1-score 0.391) indicate room for improvement in clinical applicability
- Single-center dataset (First Affiliated Hospital of Xinjiang Medical University) may introduce population-specific biases
- Relatively modest dataset size (1,183 patients) for deep learning applications, potentially limiting generalizability

## Confidence
- **High confidence**: The methodology for combining foundation models with interpretable classifiers is technically sound and well-executed
- **Medium confidence**: The performance metrics and comparative analysis against baseline models are reliable within the study context
- **Medium confidence**: The clinical interpretability of SHAP-identified features aligns with established medical knowledge

## Next Checks
1. External validation on independent multi-center datasets with diverse demographic representation
2. Prospective clinical validation to assess real-world performance and workflow integration
3. Temporal validation to ensure model stability across different time periods and evolving clinical practices