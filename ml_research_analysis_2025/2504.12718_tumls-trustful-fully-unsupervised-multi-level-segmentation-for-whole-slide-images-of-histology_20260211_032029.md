---
ver: rpa2
title: 'TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide
  Images of Histology'
arxiv_id: '2504.12718'
source_url: https://arxiv.org/abs/2504.12718
tags:
- segmentation
- image
- unsupervised
- nucleus
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents TUMLS, a trustful fully unsupervised multi-level
  segmentation framework for whole slide images (WSIs) in histopathology. It addresses
  challenges in digital pathology including labor-intensive annotations, high computational
  costs, and lack of uncertainty estimation in predictions.
---

# TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide Images of Histology

## Quick Facts
- arXiv ID: 2504.12718
- Source URL: https://arxiv.org/abs/2504.12718
- Reference count: 20
- Outperforms all unsupervised methods on MoNuSeg with F1=77.46% and Jaccard=63.35%

## Executive Summary
TUMLS introduces a trustful fully unsupervised multi-level segmentation framework for whole slide images in histopathology. It addresses the labor-intensive annotation bottleneck and lack of uncertainty estimation in existing methods by using an autoencoder for tissue identification at low resolution, selecting representative patches based on uncertainty measures, and performing unsupervised nuclei segmentation at higher resolution without ML algorithms. The framework integrates seamlessly into clinical workflows, providing interpretable cross-level insights while maintaining transparency through uncertainty-aware segmentation. Evaluated on the UPENN-GBM dataset, the autoencoder achieved MSE of 0.0016, while the nucleus segmentation on MoNuSeg dataset outperformed all unsupervised approaches with F1 score of 77.46%.

## Method Summary
The TUMLS framework operates in two complementary levels. At the low-resolution level (WSI Level 12), 16×16 pixel patches are extracted, filtered for background, and processed through a ResNet18-based autoencoder to learn tissue-specific features. The encoder's 256-dimensional latent representations are clustered using K-means with k determined by hierarchical clustering dendrogram cuts, and representative patches are selected based on their distance to cluster centroids as an uncertainty proxy. At the high-resolution level (WSI Level 18), selected patches (1024×1024 pixels) undergo stain normalization using the Macenko method, hematoxylin channel extraction, multi-class Otsu thresholding, and morphological post-processing including opening, closing, median blur, and custom demerging operations to generate nuclei masks. The approach eliminates the need for annotations while providing uncertainty-aware segmentation for improved reliability.

## Key Results
- Autoencoder achieves MSE of 0.0016 on UPENN-GBM dataset for tissue identification
- Nucleus segmentation achieves F1 score of 77.46% and Jaccard score of 63.35% on MoNuSeg dataset
- Outperforms all unsupervised methods while matching some supervised approaches
- Eliminates annotation requirements and reduces reliance on deep learning for interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Autoencoder latent representations enable unsupervised tissue discrimination without annotations.
- Mechanism: The AE learns to reconstruct low-resolution patches; the encoder's bottleneck forces compression of salient spatial features into a 256-dimensional latent vector. These embeddings are then clustered via K-means with k determined by hierarchical clustering dendrogram cuts. Distance from cluster centroids serves as an uncertainty proxy.
- Core assumption: Reconstruction loss correlates with retention of diagnostically relevant tissue features rather than noise or artifacts.
- Evidence anchors:
  - [abstract] "TUMLS adopts an autoencoder (AE) as a feature extractor to identify the different tissue types within low-resolution training data."
  - [section 3.2] "The patches are clustered with K-means based on these attributes (the hyperparameter k is determined by the optimal cut of the hierarchical clustering dendrogram)."
  - [corpus] Related work (Paper 25591) uses Vision Transformers with autoencoders for WSI risk stratification, suggesting AE-based feature extraction is an active research direction, though direct validation of clustering efficacy remains limited.
- Break condition: If validation MSE does not decrease or if cluster assignments produce visually indistinguishable tissue groups, the latent representation is insufficiently discriminative.

### Mechanism 2
- Claim: Centroid distance provides a tractable uncertainty estimate for representative patch selection.
- Mechanism: After clustering, patches closest to their assigned centroid are considered most "certain" representatives of that tissue class. Normalized distance serves as a confidence score, allowing the system to flag ambiguous cases for human review.
- Core assumption: Cluster compactness correlates with prediction confidence; outliers within clusters represent uncertain or misclassified samples.
- Evidence anchors:
  - [abstract] "It selects representative patches from each identified group based on an uncertainty measure."
  - [section 3.2] "using the uncertainty-aware approach (based on distance to centroids), N best representative patches (closest to the centroid) for each tissue are provided."
  - [corpus] No direct corpus evidence validates centroid-distance as uncertainty proxy in pathology; this remains an assumption requiring empirical calibration.
- Break condition: If selected representatives show high visual heterogeneity or poor downstream segmentation quality, the uncertainty measure is miscalibrated.

### Mechanism 3
- Claim: Non-ML nuclei segmentation achieves competitive performance with superior generalization across datasets.
- Mechanism: The pipeline combines stain normalization (Macenko), hematoxylin channel extraction, multi-class Otsu thresholding, and morphological post-processing (opening, closing, median blur, custom demerging). Three mask variants are generated and evaluated.
- Core assumption: Nuclear staining intensity and morphology are sufficiently consistent across H&E-stained samples that fixed algorithmic thresholds generalize without dataset-specific tuning.
- Evidence anchors:
  - [abstract] "unsupervised nuclei segmentation in their respective higher-resolution space without using any ML algorithms."
  - [section 4.2, Table 3] TUMLS achieves F1=77.46%, outperforming all unsupervised methods and matching some supervised approaches on MoNuSeg.
  - [corpus] Limited corpus comparison; Paper 41401 notes generalization challenges in DL pathology models, indirectly supporting non-ML approaches for cross-dataset stability.
- Break condition: If performance degrades significantly on unstained, poorly stained, or non-H&E samples, stain-dependency is a critical failure mode.

## Foundational Learning

- Concept: **Autoencoder representations**
  - Why needed here: Enables unsupervised feature extraction without labels; understanding reconstruction vs. discriminative learning is essential for debugging latent space quality.
  - Quick check question: Can you explain why minimizing reconstruction loss might not guarantee clustering-friendly embeddings?

- Concept: **Hierarchical clustering and dendrogram cutting**
  - Why needed here: Determines the number of tissue clusters (k) automatically; requires understanding linkage methods and distance metrics.
  - Quick check question: How would you validate that the dendrogram cut produces meaningful tissue distinctions rather than arbitrary groupings?

- Concept: **Otsu's multi-class thresholding**
  - Why needed here: Core nuclei segmentation step; separates foreground (nuclei) from background without training data.
  - Quick check question: What happens to Otsu thresholding when intensity distributions are multimodal or heavily skewed?

## Architecture Onboarding

- Component map:
  - **High-level pipeline**: WSI → Patch extraction (level 12, 16×16) → Background filtering → AE training → Encoder feature extraction → K-means clustering → Uncertainty-based representative selection
  - **Low-level pipeline**: Selected patches (level 18, 1024×1024) → Denoising → Stain normalization + Hematoxylin extraction → Multi-class Otsu → Morphological post-processing → 3 mask variants
  - **Cross-level insights**: Feature extraction (GLCM, morphological) → Visualization and comparison plots

- Critical path: AE reconstruction quality → meaningful clusters → correct representative selection → nuclei segmentation accuracy. Breaks at AE if latent features are non-discriminative.

- Design tradeoffs:
  - 2-level architecture reduces redundancy vs. finer multi-level granularity
  - Non-ML nuclei segmentation improves interpretability and speed vs. potential accuracy ceiling
  - Pre-decision halting (no final diagnosis) increases clinician trust vs. incomplete automation

- Failure signatures:
  - High validation MSE (>0.005) suggests AE overfitting or insufficient capacity
  - Cluster centroids with high intra-cluster variance indicate poor tissue separation
  - Nuclei masks with large merged regions suggest demerging algorithm failure
  - Background filter leakage (tissue edges in patches) contaminates clustering

- First 3 experiments:
  1. Reproduce AE training on UPENN-GBM subset; verify MSE <0.002 and visually inspect reconstruction quality across epochs.
  2. Run clustering on held-out patches; validate tissue groupings via expert visual inspection and silhouette score analysis.
  3. Apply nuclei segmentation to MoNuSeg samples; compare 3 mask variants against ground truth to identify optimal configuration per organ type.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of the low-level nucleus segmentation be improved while maintaining the framework's unsupervised and non-deep learning nature?
- Basis in paper: [explicit] The conclusion states, "Future work will focus on improving the accuracy of low-level nucleus segmentation," acknowledging the performance gap with supervised methods.
- Why unresolved: While competitive (F1 77.46%), the unsupervised method still trails behind state-of-the-art supervised approaches (e.g., F1 82.5%).
- What evidence would resolve it: A modification to the non-ML pipeline (e.g., advanced thresholding or morphological operations) that achieves an F1 score exceeding 80% on the MoNuSeg dataset without annotations.

### Open Question 2
- Question: Can the selection of the most representative levels and patches be automated to optimize segmentation efficiency across different scanner types?
- Basis in paper: [explicit] The authors explicitly identify "automating the selection of the most representative levels" as a goal for future work.
- Why unresolved: The current implementation relies on empirically set levels (level 12 to 18) and patch sizes, which may not generalize to all WSI formats or tissues without manual adjustment.
- What evidence would resolve it: A dynamic level-selection algorithm that maintains or improves the current F1 and MSE scores on the UPENN-GBM dataset while reducing manual configuration parameters.

### Open Question 3
- Question: Is it possible to adapt the color-based segmentation pipeline to effectively process unstained histological samples or those with alternative staining protocols?
- Basis in paper: [explicit] The limitations section notes the pipeline "is highly dependent on hematoxylin and eosin (H&E) staining, which limits its effectiveness for unstained histological samples."
- Why unresolved: The denoising and thresholding steps (e.g., hematoxylin channel extraction) rely specifically on H&E color properties, making them incompatible with other inputs.
- What evidence would resolve it: Successful application of the TUMLS framework on non-H&E datasets (e.g., immunohistochemistry) demonstrating statistically similar clustering and segmentation performance.

## Limitations

- Centroid distance as uncertainty measure lacks empirical validation in pathology domain
- Stain-dependent nuclei segmentation limits generalizability to non-H&E samples
- Pre-decision halting requirement limits autonomy in clinical workflows

## Confidence

- **High confidence**: AE reconstruction quality (MSE=0.0016 verified on UPENN-GBM), MoNuSeg segmentation performance (F1=77.46% verified on standard benchmark)
- **Medium confidence**: Clustering-based tissue discrimination (validated via visual inspection but lacks quantitative clustering metrics), centroid-distance uncertainty estimation (conceptually sound but unvalidated)
- **Low confidence**: Cross-dataset generalizability (limited testing beyond UPENN-GBM and MoNuSeg), scalability to extremely large WSIs (computational requirements not fully characterized)

## Next Checks

1. **Uncertainty calibration**: Quantitatively evaluate whether centroid distance correlates with actual segmentation error rates by comparing against ground truth on a subset of MoNuSeg samples with known uncertainties.

2. **Stain generalization**: Test the pipeline on non-H&E stained samples or synthetic variations in staining intensity to measure performance degradation and identify failure modes.

3. **Clinical workflow integration**: Conduct a small-scale validation with pathologists to assess whether the cross-level insights and uncertainty estimates meaningfully improve diagnostic confidence compared to traditional approaches.