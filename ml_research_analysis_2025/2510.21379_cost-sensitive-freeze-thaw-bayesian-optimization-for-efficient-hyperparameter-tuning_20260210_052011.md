---
ver: rpa2
title: Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter
  Tuning
arxiv_id: '2510.21379'
source_url: https://arxiv.org/abs/2510.21379
tags:
- learning
- utility
- performance
- normalized
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces cost-sensitive freeze-thaw Bayesian optimization
  (CFBO) to address hyperparameter optimization (HPO) where users want to balance
  computational cost against performance improvement. The method introduces a utility
  function representing user preferences for this trade-off, which can be estimated
  from preference data.
---

# Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning

## Quick Facts
- arXiv ID: 2510.21379
- Source URL: https://arxiv.org/abs/2510.21379
- Reference count: 40
- Key outcome: CFBO significantly outperforms relevant baselines in achieving better cost-performance trade-offs, with normalized regret improvements of 0.2-0.9 across different utility functions while maintaining comparable performance in conventional HPO settings.

## Executive Summary
This paper introduces cost-sensitive freeze-thaw Bayesian optimization (CFBO) to address hyperparameter optimization (HPO) where users want to balance computational cost against performance improvement. The method introduces a utility function representing user preferences for this trade-off, which can be estimated from preference data. CFBO employs a novel acquisition function based on expected utility improvement and an adaptive stopping criterion that terminates optimization when improvement becomes unlikely relative to cost. To enhance sample efficiency, the approach uses transfer learning with LC mixup on Prior-Fitted Networks for learning curve extrapolation.

## Method Summary
CFBO is a cost-sensitive multi-fidelity HPO method that optimizes a user-defined utility function balancing validation performance against computational cost. It uses a Prior-Fitted Network (PFN) trained with LC mixup for learning curve extrapolation, an acquisition function that maximizes expected utility improvement, and an adaptive stopping criterion based on regret and probability of improvement. The method operates in a freeze-thaw paradigm, dynamically pausing and resuming training of different configurations based on predicted future performance.

## Key Results
- CFBO achieves normalized regret improvements of 0.2-0.9 across different utility functions compared to baselines
- The method maintains comparable performance to state-of-the-art in conventional HPO settings (α=0)
- Transfer learning with LC mixup significantly enhances sample efficiency, particularly in cost-sensitive settings

## Why This Works (Mechanism)

### Mechanism 1: Utility-Driven Acquisition Function
The proposed acquisition function dynamically selects hyperparameter configurations that maximize expected utility improvement by computing the expected improvement of utility through Monte Carlo sampling of learning curves. This balances exploration and exploitation while considering both performance and cost.

### Mechanism 2: Adaptive Stopping Criterion
The adaptive stopping criterion automatically halts HPO near maximum utility by using a regret estimate relative to observed utilities, with an adaptive threshold that increases with the probability of improvement, allowing continuation when improvement seems likely.

### Mechanism 3: Transfer Learning with LC Mixup
Transfer learning using LC mixup on Prior-Fitted Networks enhances learning curve extrapolation accuracy, especially in early BO stages, by creating synthetic learning curves through interpolation between existing curves from different datasets and configurations.

## Foundational Learning

- **Freeze-Thaw Bayesian Optimization (FTBO)**: Why needed: CFBO builds on freeze-thaw paradigm for dynamic pausing/resuming of training. Quick check: Explain the core loop of freeze-thaw BO and how it differs from standard multi-fidelity methods like Hyperband.

- **Expected Improvement (EI) Acquisition Function**: Why needed: CFBO modifies standard EI for utility maximization. Quick check: In standard BO for maximization, what does EI measure and how is improvement defined?

- **Prior-Fitted Networks (PFNs)**: Why needed: PFNs serve as surrogate models for learning curve extrapolation. Quick check: What is a PFN, how is it trained, and what's its advantage over Gaussian Process surrogates?

## Architecture Onboarding

- **Component map**: User Preference & Utility Function -> LC Extrapolator (PFN) -> Acquisition Function -> Adaptive Stopping Criterion

- **Critical path**: At each budget step, the Acquisition Function queries the LC Extrapolator for predictions, calculates expected utility improvement for all configurations, selects the best one, and after updating context, the Adaptive Stopping Criterion queries the extrapolator again to compute probability of improvement and determine if the loop should terminate.

- **Design tradeoffs**:
  - Utility Function: Complex functions better capture user needs but require more preference data
  - LC Mixup: Aggressive mixup increases sample efficiency but risks unrealistic curves
  - Adaptive Threshold Parameters (β, γ): Control sensitivity of stopping criterion

- **Failure signatures**:
  1. Premature Stopping: Surrogate inaccuracy in early stages leads to low probability of improvement
  2. Failure to Stop: Utility function weak penalty or threshold set too high
  3. Suboptimal Configuration Selection: Acquisition function fails to balance exploration/exploitation

- **First 3 experiments**:
  1. Baseline Reproduction (α=0): Run CFBO with no cost penalty to replicate standard multi-fidelity HPO
  2. Utility Sensitivity: Vary penalty coefficient α on PD1 benchmark to visualize stopping point shifts
  3. Ablation of Transfer Learning: Compare CFBO with/without LC mixup on PD1 to quantify transfer learning contribution

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness of LC mixup depends on synthetic curves being representative of real curves
- Utility function estimation from preference data relies on Bradley-Terry model assumptions
- Adaptive stopping criterion's reliability depends entirely on LC extrapolator accuracy

## Confidence
- **High Confidence**: Core freeze-thaw BO framework and adaptive stopping criterion are well-established
- **Medium Confidence**: Specific implementation details of LC mixup and PFN training are not fully specified
- **Low Confidence**: Limited direct evidence for LC mixup superiority over other methods

## Next Checks
1. **Ablation of LC Mixup**: Compare CFBO with and without LC mixup on PD1 benchmark to isolate its contribution
2. **Utility Function Sensitivity Analysis**: Systematically vary penalty coefficient (α) and power (c) on a single task to visualize performance shifts
3. **Early-Stage Extrapolation Quality**: Plot PFN's predicted learning curves against actual curves in first few budget steps for representative test tasks