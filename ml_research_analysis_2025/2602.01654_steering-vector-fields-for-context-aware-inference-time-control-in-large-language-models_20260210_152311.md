---
ver: rpa2
title: Steering Vector Fields for Context-Aware Inference-Time Control in Large Language
  Models
arxiv_id: '2602.01654'
source_url: https://arxiv.org/abs/2602.01654
tags:
- steering
- response
- question
- vector
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Steering Vector Fields (SVF) introduces a context-dependent approach
  to inference-time control in large language models by learning a differentiable
  concept boundary whose local normal defines the steering direction at each activation,
  replacing static vectors with a representation-conditioned vector field. To ensure
  coherent multi-layer interventions, SVF aligns representations from different layers
  into a shared low-dimensional concept space and trains a single cross-layer boundary.
---

# Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models

## Quick Facts
- arXiv ID: 2602.01654
- Source URL: https://arxiv.org/abs/2602.01654
- Authors: Jiaqian Li; Yanshu Li; Kuan-Hao Huang
- Reference count: 40
- One-line primary result: Context-dependent steering vectors outperform static vectors on multiple LLMs and steering tasks, with significant gains in accuracy and steerable rate.

## Executive Summary
Steering Vector Fields (SVF) introduces a novel approach to inference-time control in large language models by learning a context-dependent vector field whose local normal defines the steering direction at each activation. This method replaces static steering vectors with a representation-conditioned vector field, enabling more accurate and robust control. SVF aligns representations from different layers into a shared low-dimensional concept space and trains a single cross-layer boundary, supporting long-form generation and multi-attribute control.

## Method Summary
SVF learns a differentiable concept boundary whose local normal defines the steering direction at each activation, replacing static vectors with a representation-conditioned vector field. To ensure coherent multi-layer interventions, SVF aligns representations from different layers into a shared low-dimensional concept space and trains a single cross-layer boundary. This formulation supports long-form generation by refreshing directions during decoding and enables multi-attribute control through soft composition of boundaries. Across multiple LLMs and steering tasks, SVF improves both accuracy and steerable rate compared to baselines.

## Key Results
- Raised NARCISSISM's steerable rate from ~50% to 87.6%
- Achieved 96.8% on MYOPIC
- Preserved model utility while improving generalization to out-of-distribution prompts

## Why This Works (Mechanism)
SVF's effectiveness stems from its context-dependent approach, which learns a vector field that adapts to the current activation context. By aligning representations from different layers into a shared concept space, SVF ensures coherent multi-layer interventions. The use of a single cross-layer boundary simplifies the model while maintaining accuracy, and the ability to refresh directions during long-form generation enhances stability.

## Foundational Learning
1. **Vector Fields**: Why needed - To model continuous steering directions; Quick check - Verify the smoothness of the learned vector field.
2. **Concept Boundaries**: Why needed - To define the regions for steering; Quick check - Test the boundary's ability to separate concepts.
3. **Low-Dimensional Concept Space**: Why needed - To reduce complexity and improve generalization; Quick check - Ensure the space captures essential concept variations.
4. **Cross-Layer Alignment**: Why needed - To ensure consistent steering across layers; Quick check - Validate the alignment preserves semantic meaning.
5. **Soft Composition**: Why needed - To combine multiple attributes without interference; Quick check - Test the composition's stability with different attribute combinations.
6. **Representation Conditioning**: Why needed - To adapt steering to context; Quick check - Assess the conditioning's responsiveness to input changes.

## Architecture Onboarding
- **Component Map**: Input -> Representation Alignment -> Concept Boundary Learning -> Steering Vector Field -> Output
- **Critical Path**: Input representations are aligned, a concept boundary is learned, and the resulting vector field guides the steering process.
- **Design Tradeoffs**: Single cross-layer boundary simplifies the model but may limit flexibility for complex concepts.
- **Failure Signatures**: Poor alignment may lead to inconsistent steering, while overly complex boundaries could overfit.
- **First Experiments**:
  1. Test SVF on a simple binary classification task to validate basic functionality.
  2. Evaluate the vector field's smoothness by checking for abrupt changes in direction.
  3. Assess the impact of representation conditioning by comparing performance with and without it.

## Open Questions the Paper Calls Out
None

## Limitations
- The empirical scope is bounded to narrow concept sets and short-form tasks.
- The low-dimensional concept space may fail for highly entangled attributes.
- The single cross-layer boundary may not capture multi-level conceptual abstraction.
- Stability under continuous long-form generation is not fully characterized.

## Confidence
- **High**: Layer alignment into a shared concept space; preservation of model utility; improvement over static steering vectors in tested settings.
- **Medium**: Long-form generation stability; soft composition for multi-attribute control; generalization to OOD prompts.
- **Low**: Robustness under continuous generation over extended contexts; performance in high-dimensional or highly entangled attribute spaces; theoretical guarantees for boundary coherence across arbitrary concepts.

## Next Checks
1. Test SVF on highly entangled or multi-faceted concepts to assess interference in soft composition.
2. Conduct long-context decoding trials with frequent steering refreshes to measure drift or instability.
3. Perform ablation studies on the low-dimensional concept space size to quantify sensitivity to representation dimensionality.