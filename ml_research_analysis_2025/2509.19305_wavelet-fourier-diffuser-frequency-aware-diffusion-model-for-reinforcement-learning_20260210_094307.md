---
ver: rpa2
title: 'Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement
  Learning'
arxiv_id: '2509.19305'
source_url: https://arxiv.org/abs/2509.19305
tags:
- diffusion
- frequency
- learning
- arxiv
- wfdiffuser
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies a frequency shift problem in sequence modeling-based
  offline reinforcement learning, where existing approaches focusing solely on time-domain
  features inadvertently introduce shifts in low-frequency components, leading to
  trajectory instability and degraded performance. To address this, the authors propose
  Wavelet Fourier Diffuser (WFDiffuser), a novel framework that integrates Discrete
  Wavelet Transform to decompose trajectories into low- and high-frequency components,
  and employs Short-Time Fourier Transform with cross attention mechanisms to extract
  frequency-domain features and facilitate cross-frequency interaction.
---

# Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement Learning

## Quick Facts
- arXiv ID: 2509.19305
- Source URL: https://arxiv.org/abs/2509.19305
- Reference count: 40
- Primary result: Achieves state-of-the-art 84 average normalized returns on D4RL benchmark, outperforming Decision Diffuser (81.8) and CQL (77.6)

## Executive Summary
This paper addresses frequency shift problems in sequence modeling-based offline reinforcement learning by proposing Wavelet Fourier Diffuser (WFDiffuser), a novel framework that decomposes trajectories into low- and high-frequency components using Discrete Wavelet Transform. The method employs separate diffusion models for each frequency component with cross-attention mechanisms to facilitate cross-frequency interaction, achieving state-of-the-art performance on D4RL benchmark tasks. The approach effectively mitigates frequency shifts in low-frequency components during training, resulting in smoother, more stable trajectories and improved decision-making performance.

## Method Summary
WFDiffuser decomposes trajectories into low- and high-frequency components using Discrete Wavelet Transform (Haar filters), then employs separate diffusion models for each component with cross-attention conditioning. The framework uses Short-Time Fourier Transform to extract frequency-domain features and facilitate cross-frequency interaction. During training, the model minimizes reconstruction loss in the wavelet domain, while inference generates actions through inverse dynamics prediction from reconstructed trajectories. The method operates on D4RL datasets with history length H=96, using return-conditioned diffusion with classifier-free guidance.

## Key Results
- Achieves 84 average normalized returns on D4RL benchmark, outperforming Decision Diffuser (81.8) and CQL (77.6)
- Ablation study shows WFDiffuser outperforms variants processing only low-frequency (51.5) or high-frequency (86.1) components alone
- Effectively reduces frequency shift in low-frequency range during training, as shown in frequency-domain loss analysis
- Demonstrates improved trajectory stability and smoother decision-making compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1: Frequency Decomposition for Specialized Denoising
The framework applies Discrete Wavelet Transform using Haar filters to split trajectories into low-frequency approximation and high-frequency detail components. Separate diffusion models are trained on these sub-trajectories, isolating global trends from local variations and preventing averaging effects from blurring critical low-frequency structures. This specialized modeling reduces errors in low-frequency components that correlate with trajectory stability.

### Mechanism 2: Cross-Frequency Alignment via Fourier Fusion
The Cross Fourier Fusion Conditioner uses Short-Time Fourier Transform to extract spectral features from both sub-trajectories, employing cross-attention where high-frequency components query and attend to low-frequency keys. This forces the high-frequency diffusion model to condition its generation on the structural constraints of the low-frequency component, ensuring local variations align with global trajectory trends.

### Mechanism 3: Spectral Loss Reduction
By reconstructing trajectories via Inverse DWT from components explicitly regularized in their respective spectral bands, WFDiffuser minimizes the systematic error (frequency shift) that time-domain-only diffusion introduces in low-frequency bands. The approach directly addresses the concentration of training loss in low-frequency components observed in standard diffusion methods.

## Foundational Learning

- **Discrete Wavelet Transform (DWT)**: Core signal processing step that splits trajectories into approximation and detail coefficients. Why needed: Cannot understand architecture without grasping how signals are downsampled into low/high-frequency components. Quick check: If you apply Haar DWT to a sequence of 96 state vectors, what are the dimensions of the resulting $\tau_{low}$ and $\tau_{high}$ tensors?

- **Classifier-Free Guidance in Diffusion**: Conditional diffusion process where the model generates trajectories based on returns and frequency features. Why needed: Critical for understanding how the condition $y(\tau)$ is injected via guidance scale $\omega$ for inference logic. Quick check: In Equation (15), what happens to the generated sample if the guidance scale $\omega$ is set to 0?

- **Cross-Attention Mechanics**: The CFFC block relies on cross-attention to fuse frequency features. Why needed: Understanding Query/Key/Value roles explains how the model "aligns" high-freq details to low-freq trends. Quick check: In the CFFC block, which frequency component provides the "Query" and which provides the "Key", and what does this imply about the direction of information flow?

## Architecture Onboarding

- **Component map**: Input $\tau$ (states) -> DWT Block (splits $\tau \to \tau_{low}, \tau_{high}$) -> CFFC Block (extracts STFT features, applies cross-attention to produce $Con_{low}, Con_{high}$) -> Diffusion Models (LFD/HFD take noise + conditions to produce denoised sub-trajectories) -> IDWT Block (reconstructs $\tau_{low}, \tau_{high} \to \tau^0$) -> Inverse Dynamics (maps $(s_t, s_{t+1}) \to a_t$)

- **Critical path**: The dependency flow moves from DWT -> CFFC -> Diffusion Models. If the CFFC outputs ($Con$) are uninformative (e.g., constant zeros), the diffusion models will essentially operate unconditionally, leading to the "frequency shift" errors the paper claims to solve.

- **Design tradeoffs**: 
  - Haar vs. Complex Wavelets: Haar, Daubechies, and Morlet perform similarly, with Haar slightly ahead due to simplicity and speed
  - Separate vs. Unified Diffusion: Two separate models (LFD, HFD) isolate low-freq error reduction more effectively than a unified model that might capture cross-dependencies implicitly

- **Failure signatures**: 
  - Frequency Mismatch: If ablation "None-freq" behavior is observed, high-freq model is ignoring low-freq context, resulting in unstable trajectories
  - Reconstruction Artifacts: Jittery IDWT output indicates padding/decimation logic issues in the DWT layer

- **First 3 experiments**:
  1. DWT Sanity Check: Feed a known trajectory (e.g., sine wave) through DWT and IDWT blocks without diffusion model to verify reconstruction error is near zero
  2. Ablation on CFFC: Run Hopper environment with CFFC block disabled (setting $Con$ to zero) to compare low-frequency loss against full model
  3. Hyperparameter $\omega$ Sweep: Sweep guidance scale $\omega$ (0.0 to 2.0) on medium-difficulty task to find sweet spot between trajectory diversity and condition adherence

## Open Questions the Paper Calls Out
None

## Limitations
- Core claim about "frequency shift" problems lacks direct experimental ablation evidence; effect is inferred from frequency-domain loss analysis rather than explicit time-domain reconstruction comparisons
- Performance improvements may stem from architectural choices beyond frequency modeling (separate models, return conditioning) rather than the frequency approach specifically
- Method's effectiveness on online RL settings or non-stationary environments is not evaluated, limiting generalizability claims

## Confidence

- **High confidence**: WFDiffuser architecture is correctly implemented and achieves state-of-the-art results on D4RL offline RL tasks
- **Medium confidence**: Frequency shift hypothesis and its mitigation via wavelet decomposition is plausible based on frequency-domain loss analysis but requires direct experimental validation
- **Medium confidence**: Cross-frequency alignment mechanism improves stability, though ablation study only shows relative performance without explaining underlying mechanism

## Next Checks

1. **Frequency shift ablation**: Implement standard time-domain diffusion variant without frequency decomposition, measure low-frequency loss ratio during training, and compare directly to WFDiffuser's frequency-domain performance

2. **CFFC necessity test**: Train variant with disabled cross-attention (high-freq model operates independently) and quantify degradation in low-frequency component stability and overall return performance

3. **Spectral analysis validation**: For fixed trajectory, compute and compare power spectral density of trajectories generated by WFDiffuser versus Decision Diffuser to empirically verify reduced low-frequency error concentration