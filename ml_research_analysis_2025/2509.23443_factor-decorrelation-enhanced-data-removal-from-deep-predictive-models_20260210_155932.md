---
ver: rpa2
title: Factor Decorrelation Enhanced Data Removal from Deep Predictive Models
arxiv_id: '2509.23443'
source_url: https://arxiv.org/abs/2509.23443
tags:
- removal
- data
- unlearning
- feature
- decoremoval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DecoRemoval, a method for enhancing deep
  predictive models by integrating factor decorrelation and loss perturbation to improve
  data removal under out-of-distribution scenarios. The approach employs Random Fourier
  Features for spatial mapping and dimensionality reduction, reducing feature redundancy
  while preserving discriminative information.
---

# Factor Decorrelation Enhanced Data Deletion from Deep Predictive Models

## Quick Facts
- arXiv ID: 2509.23443
- Source URL: https://arxiv.org/abs/2509.23443
- Reference count: 40
- Introduces DecoRemoval, achieving accuracy and F1 scores close to full retraining while significantly outperforming baselines under out-of-distribution data deletion

## Executive Summary
This paper presents DecoRemoval, a novel method that enhances deep predictive models for data deletion by integrating factor decorrelation with loss perturbation. The approach uses Random Fourier Features for spatial mapping and dimensionality reduction, reducing feature redundancy while preserving discriminative information. DecoRemoval employs a smoothed data removal mechanism with loss perturbation to ensure privacy and prevent information leakage during removal. Experiments on five datasets demonstrate that DecoRemoval consistently achieves accuracy and F1 scores close to full retraining while significantly outperforming baselines such as Certified Removal, SISA, DP-SGD, SSD, and Certified Unlearning, particularly under large-scale data removal and noisy, high-dimensional conditions.

## Method Summary
DecoRemoval integrates factor decorrelation and loss perturbation to improve data removal from deep predictive models, especially under out-of-distribution scenarios. The method employs Random Fourier Features for spatial mapping and dimensionality reduction, reducing feature redundancy while preserving discriminative information. A smoothed data removal mechanism with loss perturbation ensures privacy and prevents information leakage during removal. This approach enables efficient and robust data deletion without the need for full retraining, maintaining model performance while enhancing privacy guarantees.

## Key Results
- DecoRemoval achieves accuracy and F1 scores close to full retraining across five tested datasets (MNIST, CIFAR-10, SST-2, ESS, CGSS)
- Significantly outperforms baseline methods (Certified Removal, SISA, DP-SGD, SSD, Certified Unlearning) in data deletion tasks
- Demonstrates superior robustness and efficiency, especially under large-scale data removal and noisy, high-dimensional data conditions

## Why This Works (Mechanism)
The method works by combining factor decorrelation with loss perturbation to create a more robust and privacy-preserving data deletion mechanism. Random Fourier Features enable efficient dimensionality reduction while preserving discriminative information, reducing the impact of redundant features during deletion. The smoothed loss perturbation approach ensures that the deletion process does not introduce significant information leakage, maintaining model privacy while achieving performance comparable to full retraining.

## Foundational Learning

**Random Fourier Features**: Used for efficient dimensionality reduction by mapping data to a randomized feature space
- Why needed: Reduces computational complexity while preserving discriminative information during deletion
- Quick check: Verify that dimensionality reduction maintains class separation in feature space

**Factor Decorrelation**: Technique to reduce redundancy among features in the model
- Why needed: Minimizes the impact of correlated features during data deletion
- Quick check: Confirm that feature correlation coefficients decrease after decorrelation

**Loss Perturbation**: Adding noise to the loss function during deletion
- Why needed: Provides privacy guarantees by preventing exact reconstruction of deleted data
- Quick check: Measure membership inference attack success rate before and after deletion

## Architecture Onboarding

**Component map**: Input data -> Random Fourier Features mapping -> Dimensionality reduction -> Decorrelation layer -> Loss perturbation -> Model update

**Critical path**: The sequence from dimensionality reduction through decorrelation to loss perturbation is essential for maintaining performance while ensuring privacy during deletion

**Design tradeoffs**: Balances computational efficiency (via dimensionality reduction) against information preservation, and privacy guarantees (via loss perturbation) against model accuracy

**Failure signatures**: Degraded performance on out-of-distribution data indicates insufficient decorrelation; high membership inference success rates suggest inadequate privacy protection

**3 first experiments**:
1. Compare deletion performance with and without Random Fourier Features dimensionality reduction
2. Test deletion accuracy across varying levels of the smoothing hyperparameter λ
3. Evaluate feature correlation before and after decorrelation under deletion conditions

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Scalability of Random Fourier Features-based dimensionality reduction in extremely high-dimensional or multimodal data scenarios remains untested
- The smoothing hyperparameter λ and dimensionality reduction parameter m require careful tuning, but systematic guidance across diverse data regimes is lacking
- Experimental scope focuses on relatively standard image and tabular datasets, leaving questions about performance under complex, real-world distribution shifts and domain-specific noise patterns

## Confidence

**High confidence**: Core claim that DecoRemoval achieves accuracy and F1 scores close to full retraining while significantly outperforming baseline methods (Certified Removal, SISA, DP-SGD, SSD, Certified Unlearning) on the tested datasets.

**Medium confidence**: Robustness and efficiency claims under large-scale data removal and noisy, high-dimensional data, due to limited diversity in experimental conditions and potential hyperparameter sensitivity.

**Medium confidence**: Assertion of privacy preservation via smoothed loss perturbation, as empirical privacy leakage metrics were not provided.

## Next Checks

1. Conduct experiments on multimodal and extremely high-dimensional datasets (e.g., hyperspectral imagery, medical imaging with multiple modalities) to assess scalability of the dimensionality reduction and decorrelation components.

2. Perform ablation studies systematically varying λ and m across multiple datasets to provide clear guidance on hyperparameter tuning and robustness to parameter choice.

3. Evaluate privacy leakage using established metrics (e.g., membership inference attack success rates) to empirically validate the privacy-preserving claims of the smoothed data removal mechanism.