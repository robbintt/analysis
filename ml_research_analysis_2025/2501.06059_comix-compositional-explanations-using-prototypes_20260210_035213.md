---
ver: rpa2
title: 'COMIX: Compositional Explanations using Prototypes'
arxiv_id: '2501.06059'
source_url: https://arxiv.org/abs/2501.06059
tags:
- image
- b-cos
- training
- comix
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes COMIX, a novel compositional explanation method
  that addresses the challenge of interpreting neural network decisions by decomposing
  images into human-understandable concepts and tracing them back to training data.
  Unlike post-hoc explanation methods, COMIX provides by-design interpretability by
  classifying images based on learned concepts and matching them to corresponding
  regions in training images.
---

# COMIX: Compositional Explanations using Prototypes

## Quick Facts
- arXiv ID: 2501.06059
- Source URL: https://arxiv.org/abs/2501.06059
- Reference count: 17
- Key outcome: COMIX achieves 48.82% improvement in C-insertion score on ImageNet compared to baselines while maintaining competitive accuracy

## Executive Summary
COMIX introduces a novel compositional explanation method that addresses the interpretability challenge in neural network decisions by decomposing images into human-understandable concepts and tracing them back to training data. Unlike post-hoc explanation methods, COMIX provides by-design interpretability through its architecture that classifies images based on learned concepts and matches them to corresponding regions in training images. The method leverages B-cos networks, an inherently interpretable architecture, to extract class-defining features and establish meaningful connections with training data.

## Method Summary
COMIX operates through a multi-stage process that begins with extracting class-defining concepts from training data using B-cos networks. These concepts are then matched to specific regions in training images, creating a prototype-based representation. During inference, test images are decomposed into segments, and each segment is compared against the learned prototypes to generate compositional explanations. The method ensures fidelity, sparsity, necessity, and sufficiency of explanations through its design, while also incorporating k-means clustering and filtering strategies to manage computational complexity. This approach enables zero-shot learning capabilities and shows promise for applications in safety-critical domains like medical imaging.

## Key Results
- 48.82% improvement in C-insertion score on ImageNet compared to state-of-the-art baselines
- Competitive accuracy maintained while providing interpretable explanations
- Robust performance demonstrated across multiple datasets
- Promising results for zero-shot learning applications

## Why This Works (Mechanism)
COMIX's effectiveness stems from its fundamental design principle of by-design interpretability rather than post-hoc explanation generation. By decomposing images into human-understandable concepts and establishing direct connections to training data, the method creates explanations that are both faithful to the model's decision process and comprehensible to humans. The use of B-cos networks as the underlying architecture ensures that the extracted features are inherently interpretable, while the prototype-matching mechanism provides a clear traceable path from input to decision.

## Foundational Learning
- **B-cos networks**: Why needed - Provides inherently interpretable architecture for feature extraction; Quick check - Verify that extracted features align with human-understandable concepts
- **Prototype-based representation**: Why needed - Enables compositional explanations through learned concepts; Quick check - Confirm that prototypes capture class-defining features
- **Segment-based decomposition**: Why needed - Allows local interpretability by breaking down images into interpretable parts; Quick check - Ensure segments maintain semantic coherence
- **k-means clustering**: Why needed - Reduces computational complexity while preserving explanation quality; Quick check - Validate that clustering maintains relevant information
- **Similarity matching**: Why needed - Establishes connection between test segments and training prototypes; Quick check - Verify that matched prototypes are semantically relevant
- **Zero-shot learning capability**: Why needed - Enables classification of unseen classes through compositional reasoning; Quick check - Test on classes not present in training data

## Architecture Onboarding

Component map: Input Image -> Segment Extraction -> B-cos Network -> Prototype Generation -> Similarity Matching -> Compositional Explanation

Critical path: Image segmentation → Feature extraction via B-cos networks → Prototype matching → Explanation generation

Design tradeoffs: COMIX trades computational efficiency for interpretability by requiring similarity computations against training data. The method uses k-means clustering and filtering to mitigate this cost, but computational burden remains significant for large-scale applications.

Failure signatures: Explanations may become less reliable when:
- Training data lacks diversity in representing concepts
- Input images contain novel combinations of features
- Computational shortcuts (clustering) oversimplify complex relationships

3 first experiments:
1. Test COMIX on simple synthetic datasets where ground truth explanations are known
2. Evaluate explanation quality on standard interpretability benchmarks like ImageNet with known failure modes
3. Assess zero-shot learning capabilities on datasets with clear compositional structures

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Significant computational complexity due to similarity computations against all training data
- Potential performance constraints from reliance on B-cos networks compared to state-of-the-art black-box models
- Need for more extensive validation in safety-critical medical imaging applications

## Confidence
- C-insertion score improvement (48.82%): High confidence based on reported results
- By-design interpretability claim: High confidence supported by architectural choices
- Zero-shot learning and medical imaging applications: Medium confidence requiring more validation

## Next Checks
1. Conduct user studies with domain experts to evaluate practical utility and comprehensibility of COMIX explanations in real-world scenarios
2. Benchmark COMIX's computational efficiency against other interpretable methods on larger-scale datasets to quantify the trade-off between interpretability and runtime
3. Test COMIX's robustness to adversarial examples and out-of-distribution samples to assess explanation reliability under challenging conditions