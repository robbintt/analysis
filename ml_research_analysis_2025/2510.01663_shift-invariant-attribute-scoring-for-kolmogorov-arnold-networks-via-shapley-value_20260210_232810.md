---
ver: rpa2
title: Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via Shapley
  Value
arxiv_id: '2510.01663'
source_url: https://arxiv.org/abs/2510.01663
tags:
- pruning
- shapkan
- vanilla
- shapley
- neurons
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of pruning Kolmogorov-Arnold
  Networks (KANs) in a way that is robust to input coordinate shifts and preserves
  node importance rankings. Traditional magnitude-based pruning methods are unreliable
  for KANs because they are sensitive to shifts in input parameterization, leading
  to inconsistent importance scores and suboptimal pruning decisions.
---

# Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via Shapley Value

## Quick Facts
- **arXiv ID**: 2510.01663
- **Source URL**: https://arxiv.org/abs/2510.01663
- **Reference count**: 28
- **Primary result**: Proposes ShapKAN, a pruning framework using Shapley value attribution to enable shift-invariant node importance assessment in KANs

## Executive Summary
This paper addresses the challenge of pruning Kolmogorov-Arnold Networks (KANs) in a way that remains robust to input coordinate shifts. Traditional magnitude-based pruning methods are unreliable for KANs because they are sensitive to shifts in input parameterization, leading to inconsistent importance scores and suboptimal pruning decisions. The authors propose ShapKAN, a pruning framework that leverages Shapley value attribution to assess node importance in a shift-invariant manner, ensuring consistent importance rankings regardless of input parameterization.

## Method Summary
ShapKAN introduces a shift-invariant pruning framework for KANs by employing Shapley value attribution to quantify node importance. Unlike magnitude-based approaches that are vulnerable to input parameterization shifts, ShapKAN measures each node's actual contribution to the network's output. The method calculates Shapley values for each node by evaluating marginal contributions across all possible node coalitions, providing a principled way to assess importance that remains invariant under coordinate transformations. This approach preserves the interpretability advantages of KANs while enabling effective network compression through principled node pruning.

## Key Results
- ShapKAN preserves true node importance rankings under input coordinate shifts
- The method improves generalization capacity compared to vanilla KAN pruning
- ShapKAN more accurately recovers ground truth symbolic functions under covariate shift conditions

## Why This Works (Mechanism)
ShapKAN leverages the mathematical properties of Shapley values from cooperative game theory to provide shift-invariant importance scoring. Shapley values measure a node's marginal contribution to the network output across all possible subsets of nodes, ensuring that importance rankings remain consistent regardless of how input coordinates are transformed. This approach directly addresses the fundamental limitation of magnitude-based pruning in KANs, where weight magnitudes can change arbitrarily under coordinate transformations while the underlying function remains unchanged.

## Foundational Learning

**Kolmogorov-Arnold Networks (KANs)**: A type of neural network architecture that learns multi-dimensional functions through compositions of univariate functions, offering improved interpretability compared to traditional networks.

*Why needed*: Understanding KAN architecture is essential as the paper addresses pruning specifically for this network type.

*Quick check*: Can you explain how KANs differ from standard feedforward networks in terms of function representation?

**Shapley Value Attribution**: A method from cooperative game theory that fairly distributes gains among players based on their marginal contributions to all possible coalitions.

*Why needed*: Forms the theoretical foundation for shift-invariant importance scoring in ShapKAN.

*Quick check*: Do you understand how Shapley values ensure fair attribution in cooperative games?

**Input Coordinate Shift**: Transformations of input features that preserve the underlying function but can alter weight magnitudes in traditional pruning methods.

*Why needed*: The core problem ShapKAN addresses - ensuring pruning decisions remain consistent under such transformations.

*Quick check*: Can you provide an example of how input coordinate shifts might affect traditional pruning methods?

## Architecture Onboarding

**Component Map**: Input Features -> KAN Layers -> Output -> Shapley Value Computation -> Node Importance Ranking -> Pruning Decision

**Critical Path**: The method's effectiveness depends on accurate Shapley value computation, which requires evaluating marginal contributions across all node subsets. This computational bottleneck determines the practical scalability of ShapKAN.

**Design Tradeoffs**: Computational efficiency vs. theoretical soundness - Shapley value computation is computationally expensive but provides provably shift-invariant importance scores. The tradeoff favors theoretical robustness over computational speed.

**Failure Signatures**: If Shapley values fail to capture true node contributions (e.g., due to approximation errors), the pruning decisions may become suboptimal despite theoretical guarantees. High computational cost may also limit practical deployment.

**First Experiments**:
1. Apply ShapKAN to a simple synthetic KAN with known ground truth function and verify that importance rankings remain consistent under various input coordinate transformations.
2. Compare pruning performance (generalization capacity) of ShapKAN against magnitude-based pruning on a benchmark dataset under covariate shift conditions.
3. Evaluate computational overhead of ShapKAN on KANs of increasing depth and width to establish practical scalability limits.

## Open Questions the Paper Calls Out
None

## Limitations
- Computational scalability challenges due to Shapley value computation complexity
- Limited validation on complex real-world datasets with unknown underlying functions
- Potential performance degradation in high-dimensional feature spaces

## Confidence
- **High confidence**: Theoretical motivation and shift-invariance properties of Shapley value attribution
- **Medium confidence**: Synthetic dataset results and ground truth function recovery
- **Medium confidence**: Generalization capacity claims without extensive real-world validation

## Next Checks
1. Apply ShapKAN to real-world datasets with known feature importance patterns (e.g., UCI repository datasets with feature relevance annotations) to validate practical effectiveness
2. Conduct ablation studies comparing ShapKAN against magnitude-based pruning under various input parameterizations to quantify the practical impact of shift-invariance
3. Benchmark computational overhead and scalability of ShapKAN on larger KAN architectures (depth >10, width >100) to assess deployment feasibility in resource-constrained environments