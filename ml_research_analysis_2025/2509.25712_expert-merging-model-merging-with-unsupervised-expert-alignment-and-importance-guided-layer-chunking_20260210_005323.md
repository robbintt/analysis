---
ver: rpa2
title: 'Expert Merging: Model Merging with Unsupervised Expert Alignment and Importance-Guided
  Layer Chunking'
arxiv_id: '2509.25712'
source_url: https://arxiv.org/abs/2509.25712
tags:
- merging
- expert
- task
- coefficients
- coefficient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Expert Merging introduces a training-light method for model merging
  that learns layer-wise coefficients to align hidden states and logits of merged
  models with domain experts on unlabeled data. The method incorporates coefficient
  regularization for stability and task-weighted losses for controllable trade-offs.
---

# Expert Merging: Model Merging with Unsupervised Expert Alignment and Importance-Guided Layer Chunking

## Quick Facts
- arXiv ID: 2509.25712
- Source URL: https://arxiv.org/abs/2509.25712
- Reference count: 22
- Outperforms training-free and prior training-based baselines with state-of-the-art averages (58.45 on InternVL, 63.63 on Qwen2-VL, 48.71 on Mistral)

## Executive Summary
Expert Merging introduces a training-light method for model merging that learns layer-wise coefficients to align hidden states and logits of merged models with domain experts on unlabeled data. The method incorporates coefficient regularization for stability and task-weighted losses for controllable trade-offs. Expert Merging++ extends this with importance-guided chunking, allocating more chunk-wise coefficients to high-importance layers while keeping low-importance layers lightweight. Evaluated across MLLM backbones (InternVL, Qwen2-VL) and LLM backbone (Mistral), the approach consistently outperforms training-free and prior training-based baselines.

## Method Summary
Expert Merging learns layer-wise coefficients to align hidden states and logits of merged models with domain experts using unlabeled data. The method employs coefficient regularization to ensure stability and task-weighted losses to enable controllable trade-offs between different tasks. Expert Merging++ builds upon this foundation by introducing importance-guided chunking, which allocates more chunk-wise coefficients to high-importance layers while maintaining lightweight processing for low-importance layers. This approach achieves state-of-the-art performance across multiple model families while maintaining practical advantages for real-world deployment.

## Key Results
- Achieves state-of-the-art averages: 58.45 on InternVL, 63.63 on Qwen2-VL, 48.71 on Mistral
- Outperforms both training-free and prior training-based baselines consistently
- Surpasses supervised Mixture Training in some cases, with particularly strong gains in grounding tasks

## Why This Works (Mechanism)
The method works by learning optimal layer-wise coefficients that align the merged model's hidden states and logits with those of specialized domain experts. By using unlabeled data during training, the approach avoids the need for extensive labeled datasets while still achieving strong alignment. The coefficient regularization prevents instability during training, while task-weighted losses allow for fine-tuned control over performance across different tasks. The importance-guided chunking in Expert Merging++ further optimizes resource allocation by focusing computational effort on the most critical layers.

## Foundational Learning
- Layer-wise coefficient learning: Essential for aligning merged models with domain experts; quick check: verify coefficient convergence during training
- Coefficient regularization: Prevents training instability; quick check: monitor coefficient magnitude and distribution
- Task-weighted losses: Enables controllable trade-offs between tasks; quick check: validate loss weight impact on task-specific performance
- Importance-guided chunking: Optimizes resource allocation; quick check: confirm chunk allocation matches importance scores
- Hidden state alignment: Critical for maintaining expert capabilities; quick check: compare hidden state distributions pre/post-merging
- Logit alignment: Ensures task-specific outputs remain accurate; quick check: verify logit distributions match expert models

## Architecture Onboarding

Component Map:
Input Data -> Coefficient Learning Module -> Regularization Layer -> Task-Weighted Loss Function -> Merged Model Output

Critical Path:
1. Input unlabeled data passes through both merged and expert models
2. Hidden states and logits are extracted and compared
3. Layer-wise coefficients are updated to minimize alignment loss
4. Regularization ensures coefficient stability
5. Task-weighted losses provide multi-task control

Design Tradeoffs:
- Training-light vs. full fine-tuning: Expert Merging prioritizes efficiency while maintaining strong performance
- Layer-wise vs. global coefficients: Layer-wise approach provides finer control but increases complexity
- Importance-guided vs. uniform chunking: Guided approach optimizes resources but requires accurate importance scoring

Failure Signatures:
- Coefficient explosion or collapse indicates regularization issues
- Performance degradation on specific tasks suggests imbalanced task-weighted losses
- Memory issues during training may indicate inefficient chunking strategy

First Experiments:
1. Verify coefficient convergence on a small model pair
2. Test task-weighted loss impact on single-task performance
3. Validate importance score accuracy on a subset of layers

## Open Questions the Paper Calls Out
None

## Limitations
- Coefficient regularization effectiveness may not generalize across all model architectures
- Importance-guided chunking relies on importance scores that may not transfer well to novel tasks
- Performance on extremely long-context scenarios and very large model collections remains untested

## Confidence
- High confidence in effectiveness for tested model families (InternVL, Qwen2-VL, Mistral) on standard tasks
- Medium confidence in coefficient regularization's contribution to stability across diverse architectures
- Medium confidence in training-light approach's practical advantages versus full fine-tuning
- Low confidence in performance on novel task distributions not represented in evaluation set

## Next Checks
1. Test coefficient regularization effectiveness on additional model architectures (e.g., Llama, Claude variants)
2. Evaluate performance degradation when applying importance-guided chunking to tasks with significantly different characteristics
3. Assess scalability limits by testing with model collections containing 10+ specialized models